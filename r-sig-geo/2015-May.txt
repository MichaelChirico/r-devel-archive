From sadaouimahrez at outlook.com  Fri May  1 00:12:56 2015
From: sadaouimahrez at outlook.com (sadaoui)
Date: Thu, 30 Apr 2015 15:12:56 -0700 (MST)
Subject: [R-sig-Geo] Delimit a polygon for the region which is> 1000 m from
 my raster altitude
Message-ID: <1430431976871-7588147.post@n2.nabble.com>

*Hello,
I am new to this forum

My goal is to define a polygon for the region> 1000 m from raster of
altitude
  then export to shapefile.

I tried with this code:

#import the raster: (attachment)

library (raster)
map <- raster ("Adige.tif")

#Delimit the area (> 1000 m) with the "contour"


contour (map, add = T, levels = c (1000))


but I can not export the contour to shapefile

thank you in advance for helping me

sadaoui*



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Delimit-a-polygon-for-the-region-which-is-1000-m-from-my-raster-altitude-tp7588147.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From macqueen1 at llnl.gov  Fri May  1 01:02:11 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 30 Apr 2015 23:02:11 +0000
Subject: [R-sig-Geo] Delimit a polygon for the region which is> 1000 m
 from my raster altitude
In-Reply-To: <1430431976871-7588147.post@n2.nabble.com>
References: <1430431976871-7588147.post@n2.nabble.com>
Message-ID: <D1680198.12746D%macqueen1@llnl.gov>

Look into the help page for the contour function in the raster package
It refers to
  RasterToContour

Follow the example given in ?RasterToContour
(copied here)
f <- system.file("external/test.grd", package="raster")
r <- raster(f)
x <- rasterToContour(r, levels=500)
class(x)
plot(r)
plot(x, add=TRUE)


Then see:
class(x)

Then x can be written to a shapefile using writeOGR in the rgdal package.


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 4/30/15, 3:12 PM, "sadaoui" <sadaouimahrez at outlook.com> wrote:

>*Hello,
>I am new to this forum
>
>My goal is to define a polygon for the region> 1000 m from raster of
>altitude
>  then export to shapefile.
>
>I tried with this code:
>
>#import the raster: (attachment)
>
>library (raster)
>map <- raster ("Adige.tif")
>
>#Delimit the area (> 1000 m) with the "contour"
>
>
>contour (map, add = T, levels = c (1000))
>
>
>but I can not export the contour to shapefile
>
>thank you in advance for helping me
>
>sadaoui*
>
>
>
>--
>View this message in context:
>http://r-sig-geo.2731867.n2.nabble.com/Delimit-a-polygon-for-the-region-wh
>ich-is-1000-m-from-my-raster-altitude-tp7588147.html
>Sent from the R-sig-geo mailing list archive at Nabble.com.
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at r-project.org
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From sadaouimahrez at outlook.com  Fri May  1 15:02:16 2015
From: sadaouimahrez at outlook.com (sadaoui)
Date: Fri, 1 May 2015 06:02:16 -0700 (MST)
Subject: [R-sig-Geo] Delimit a polygon for the region which is> 1000 m
 from my raster altitude
In-Reply-To: <D1680198.12746D%macqueen1@llnl.gov>
References: <1430431976871-7588147.post@n2.nabble.com>
	<D1680198.12746D%macqueen1@llnl.gov>
Message-ID: <1430485336885-7588149.post@n2.nabble.com>

Thank you very much "MacQueen, Don"  for your answer.

I have followed your instructions from this script :

library(raster)
library(sp)

f <- system.file("external/test.grd", package="raster")
r <- raster(f)

# add contour

x <- rasterToContour(r,levels=500)
class(x)
plot(r)
plot(x, add=TRUE)

#export contour to shapefile

library(rgdal)

writeOGR(x, ".", "contour", driver="ESRI Shapefile")


but when I open the shapefile, is a  lines not a polygons? My goal is to
have the polygon areas for altitude> 500m.

I thought to "rasterToPolygons"

library(raster)
library(sp)
f <- system.file("external/test.grd", package="raster")
r <- raster(f)

# add polygon

library(rgeos)

pol <- rasterToPolygons(r, fun=function(x){x>500})

plot(pol, add=T, col='red')

#export polygon to shapefile

library(rgdal)

writeOGR(pol, ".", "polygon", driver="ESRI Shapefile")



but the result, it displays a shapefile with polygons for each pixel

I just want  a polygons to areas where are> 500m, not for each pixel.

Thank you again 







--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Delimit-a-polygon-for-the-region-which-is-1000-m-from-my-raster-altitude-tp7588147p7588149.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From sharx at ucla.edu  Fri May  1 17:08:14 2015
From: sharx at ucla.edu (sharx)
Date: Fri, 1 May 2015 08:08:14 -0700 (MST)
Subject: [R-sig-Geo] Using gdistance to compute a least cost path which
 avoids certain cells entirely, no matter the distance
In-Reply-To: <821236528.9038145.1430234253585.JavaMail.yahoo@mail.yahoo.com>
References: <1430181071767-7588118.post@n2.nabble.com>
	<821236528.9038145.1430234253585.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+QLGtwa1U5769v8jRbJx4k6MqaanW5WuhKFhhE-YnTv6UcB8Q@mail.gmail.com>

Hi Jacob,

Thank you for the quick response! In the example where we want the animal
to "go ten times as far to avoid crossing a road", would the non-road cells
be assigned a resistance of 0? Or a resistance of 1?

If I know that the animal only has enough to time to travel, say, 5000
meters from one point to the next, is it correct to assign road cell
resistance 5000 (given units in meters) and non-road cells a resistance of
1? By taking into account the 30 m raster cell size, do you mean we should
multiply 5000 by 30 for the road resistance?

Again, thank you so much for your help!

Best,
Sharon

On Tue, Apr 28, 2015 at 8:25 AM, R-sig-geo mailing list [via R-sig-geo] <
ml-node+s2731867n7588123h51 at n2.nabble.com> wrote:

> Hi Sharon,
> "Going ten times as far to avoid crossing a road" would require for each
> pair of points you measure the direct distance first and then make the road
> crossing value as 10x this value, taking into account you have set the road
> width to 30.
> Best,
> Jacob
>
>
>      On Monday, 27 April 2015, 18:35, sharx <[hidden email]
> <http:///user/SendEmail.jtp?type=node&node=7588123&i=0>> wrote:
>
>
>  Hi all,
>
> I have some data of GPS locations of an animal and want to construct paths
> between those coordinates. The goal is to obtain animal movement paths
> that
> the cross the fewest roads possible by using shortestPath(), and assigning
> resistance values to a raster of the animal's habitat. Ideally this means
> that the path would show animals going out of their way to avoid roads,
> even
> going ten times the distance they would have by crossing roads. I have
> experimented with different resistance values with limited success.
>
> Below is an example. Blue points are coordinates. Purple lines are roads.
> Red line is the least cost path calculated, which goes through several
> roads
> unnecessarily. Green line is the path I would like to generate.
> <
> http://r-sig-geo.2731867.n2.nabble.com/file/n7588118/leastcost-example.png>
>
>
> With my current results, I have achieved some avoidance of roads, but
> cannot
> construct a path that goes too much extraneous distance in order to avoid
> roads. When setting the non-road cell resistance to 0, however, I got an
> extraordinarily complicated set of paths, perhaps due to values of
> infinity
> when calculating the transition matrix.
>
> *Could anyone could give me an idea as to how to choose these resistance
> values, or how shortestPath() calculates with regards to the transition
> matrix values and the actual distance in meters? *
>
> I have created a raster called cost from a shapefile of roads in
> projection
> NAD83, and using extract(), I have assigned much higher resistance values
> to
> each cell of the raster cost if the cell contains a road. Here the cost of
> non-road cells is 2^-20 and the cost of road cells is 10^100.
>
> Here is my code:
>
> library(raster)
> cost <-rasterize(rd, r.30m, field=2^-20)
> numbers <- extract(cost, rd, cellnumbers=TRUE, buffer=30)
> cellnum <- unlist(numbers)
> cost[cellnum] <- 10^100
>
> library(gdistance)
> ## Produce transition matrices, and correct because 8 directions
> trCost <- transition(1/cost, mean, directions=8)
> trCost <- geoCorrection(trCost, type="c")
>
> # Iterate between a list of coordinate pairs, use shortestPath() to get a
> path for each pair
> #Each element of the list coords contains two points that straddle a road.
> # For each pair of points, calculate the least cost path between them.
> getpath <- function(coords) {
>   c = unlist(coords)
>   pt1 = c(c[1], c[3])
>   pt2 = c(c[2], c[4])
>   if (sqrt((pt1[1]-pt2[1])^2 + (pt1[2]-pt2[2])^2) <= sqrt(2*30^2)) {
>     return(SpatialLines(list(Lines(Line(rbind(pt1,pt2)), ID="1"))))
>   } # if the points are in the same raster cell, return a straight line
> between them (a least cost path will not work)
>   return(shortestPath(trCost, pt1, pt2, output="SpatialLines"))
> }
>
> paths <- numeric(0)
> for (i in 1:length(coords[[1]])){
>   c=lapply(coords, "[[", i)
>   paths <- c(paths, getpath(c))
> }
>
> #Code end
>
> Thank you for your help in advance!
>
> Best,
> Sharon
>
>
>
> --
> View this message in context:
> http://r-sig-geo.2731867.n2.nabble.com/Using-gdistance-to-compute-a-least-cost-path-which-avoids-certain-cells-entirely-no-matter-the-distae-tp7588118.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> [hidden email] <http:///user/SendEmail.jtp?type=node&node=7588123&i=1>
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> [hidden email] <http:///user/SendEmail.jtp?type=node&node=7588123&i=2>
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> ------------------------------
>  If you reply to this email, your message will be added to the discussion
> below:
>
> http://r-sig-geo.2731867.n2.nabble.com/Using-gdistance-to-compute-a-least-cost-path-which-avoids-certain-cells-entirely-no-matter-the-distae-tp7588118p7588123.html
>  To unsubscribe from Using gdistance to compute a least cost path which
> avoids certain cells entirely, no matter the distance, click here
> <http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=7588118&code=c2hhcnhAdWNsYS5lZHV8NzU4ODExOHwxMjg5NzgzNjgz>
> .
> NAML
> <http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>




--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Using-gdistance-to-compute-a-least-cost-path-which-avoids-certain-cells-entirely-no-matter-the-distae-tp7588118p7588150.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From famuvie at alumni.uv.es  Fri May  1 22:06:21 2015
From: famuvie at alumni.uv.es (=?windows-1252?Q?Facundo_Mu=F1oz?=)
Date: Fri, 01 May 2015 22:06:21 +0200
Subject: [R-sig-Geo] Using gdistance to compute a least cost path which
 avoids certain cells entirely, no matter the distance
In-Reply-To: <CA+QLGtwa1U5769v8jRbJx4k6MqaanW5WuhKFhhE-YnTv6UcB8Q@mail.gmail.com>
References: <1430181071767-7588118.post@n2.nabble.com>	<821236528.9038145.1430234253585.JavaMail.yahoo@mail.yahoo.com>
	<CA+QLGtwa1U5769v8jRbJx4k6MqaanW5WuhKFhhE-YnTv6UcB8Q@mail.gmail.com>
Message-ID: <5543DCBD.5040207@alumni.uv.es>

Hi Sharon,

note that if the road is "thin" (i.e. it takes only one or two pixels
wide), and if you use the function "mean" when creating the transition
layer, then it will always be possible to cross the roads.

I faced a similar problem, where I wanted to model an absolute barrier
(impossible to cross), and found it more convenient to work with
permeability rasters (rather than cost). So I can define permeability =
0 for barriers (i.e. infinte cost). Moreover, I defined a transition
function that returns the mean when both cells have non-zero values, but
returns zero if not.

?acu.-


El 01/05/2015 a las 17:08, sharx escribi?:
> Hi Jacob,
>
> Thank you for the quick response! In the example where we want the animal
> to "go ten times as far to avoid crossing a road", would the non-road cells
> be assigned a resistance of 0? Or a resistance of 1?
>
> If I know that the animal only has enough to time to travel, say, 5000
> meters from one point to the next, is it correct to assign road cell
> resistance 5000 (given units in meters) and non-road cells a resistance of
> 1? By taking into account the 30 m raster cell size, do you mean we should
> multiply 5000 by 30 for the road resistance?
>
> Again, thank you so much for your help!
>
> Best,
> Sharon
>
> On Tue, Apr 28, 2015 at 8:25 AM, R-sig-geo mailing list [via R-sig-geo] <
> ml-node+s2731867n7588123h51 at n2.nabble.com> wrote:
>
>> Hi Sharon,
>> "Going ten times as far to avoid crossing a road" would require for each
>> pair of points you measure the direct distance first and then make the road
>> crossing value as 10x this value, taking into account you have set the road
>> width to 30.
>> Best,
>> Jacob
>>
>>
>>      On Monday, 27 April 2015, 18:35, sharx <[hidden email]
>> <http:///user/SendEmail.jtp?type=node&node=7588123&i=0>> wrote:
>>
>>
>>  Hi all,
>>
>> I have some data of GPS locations of an animal and want to construct paths
>> between those coordinates. The goal is to obtain animal movement paths
>> that
>> the cross the fewest roads possible by using shortestPath(), and assigning
>> resistance values to a raster of the animal's habitat. Ideally this means
>> that the path would show animals going out of their way to avoid roads,
>> even
>> going ten times the distance they would have by crossing roads. I have
>> experimented with different resistance values with limited success.
>>
>> Below is an example. Blue points are coordinates. Purple lines are roads.
>> Red line is the least cost path calculated, which goes through several
>> roads
>> unnecessarily. Green line is the path I would like to generate.
>> <
>> http://r-sig-geo.2731867.n2.nabble.com/file/n7588118/leastcost-example.png>
>>
>>
>> With my current results, I have achieved some avoidance of roads, but
>> cannot
>> construct a path that goes too much extraneous distance in order to avoid
>> roads. When setting the non-road cell resistance to 0, however, I got an
>> extraordinarily complicated set of paths, perhaps due to values of
>> infinity
>> when calculating the transition matrix.
>>
>> *Could anyone could give me an idea as to how to choose these resistance
>> values, or how shortestPath() calculates with regards to the transition
>> matrix values and the actual distance in meters? *
>>
>> I have created a raster called cost from a shapefile of roads in
>> projection
>> NAD83, and using extract(), I have assigned much higher resistance values
>> to
>> each cell of the raster cost if the cell contains a road. Here the cost of
>> non-road cells is 2^-20 and the cost of road cells is 10^100.
>>
>> Here is my code:
>>
>> library(raster)
>> cost <-rasterize(rd, r.30m, field=2^-20)
>> numbers <- extract(cost, rd, cellnumbers=TRUE, buffer=30)
>> cellnum <- unlist(numbers)
>> cost[cellnum] <- 10^100
>>
>> library(gdistance)
>> ## Produce transition matrices, and correct because 8 directions
>> trCost <- transition(1/cost, mean, directions=8)
>> trCost <- geoCorrection(trCost, type="c")
>>
>> # Iterate between a list of coordinate pairs, use shortestPath() to get a
>> path for each pair
>> #Each element of the list coords contains two points that straddle a road.
>> # For each pair of points, calculate the least cost path between them.
>> getpath <- function(coords) {
>>   c = unlist(coords)
>>   pt1 = c(c[1], c[3])
>>   pt2 = c(c[2], c[4])
>>   if (sqrt((pt1[1]-pt2[1])^2 + (pt1[2]-pt2[2])^2) <= sqrt(2*30^2)) {
>>     return(SpatialLines(list(Lines(Line(rbind(pt1,pt2)), ID="1"))))
>>   } # if the points are in the same raster cell, return a straight line
>> between them (a least cost path will not work)
>>   return(shortestPath(trCost, pt1, pt2, output="SpatialLines"))
>> }
>>
>> paths <- numeric(0)
>> for (i in 1:length(coords[[1]])){
>>   c=lapply(coords, "[[", i)
>>   paths <- c(paths, getpath(c))
>> }
>>
>> #Code end
>>
>> Thank you for your help in advance!
>>
>> Best,
>> Sharon
>>
>>
>>
>> --
>> View this message in context:
>> http://r-sig-geo.2731867.n2.nabble.com/Using-gdistance-to-compute-a-least-cost-path-which-avoids-certain-cells-entirely-no-matter-the-distae-tp7588118.html
>> Sent from the R-sig-geo mailing list archive at Nabble.com.
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> [hidden email] <http:///user/SendEmail.jtp?type=node&node=7588123&i=1>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> [hidden email] <http:///user/SendEmail.jtp?type=node&node=7588123&i=2>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>> ------------------------------
>>  If you reply to this email, your message will be added to the discussion
>> below:
>>
>> http://r-sig-geo.2731867.n2.nabble.com/Using-gdistance-to-compute-a-least-cost-path-which-avoids-certain-cells-entirely-no-matter-the-distae-tp7588118p7588123.html
>>  To unsubscribe from Using gdistance to compute a least cost path which
>> avoids certain cells entirely, no matter the distance, click here
>> <http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=7588118&code=c2hhcnhAdWNsYS5lZHV8NzU4ODExOHwxMjg5NzgzNjgz>
>> .
>> NAML
>> <http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>>
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Using-gdistance-to-compute-a-least-cost-path-which-avoids-certain-cells-entirely-no-matter-the-distae-tp7588118p7588150.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From jmblanco at ub.edu  Sat May  2 13:37:09 2015
From: jmblanco at ub.edu (=?windows-1252?Q?=22Jos=E9_M=2E_Blanco_Moreno=22?=)
Date: Sat, 02 May 2015 13:37:09 +0200
Subject: [R-sig-Geo] Delimit a polygon for the region which is>,
	1000 m from my raster altitude
In-Reply-To: <mailman.9.1430560803.22795.r-sig-geo@r-project.org>
References: <mailman.9.1430560803.22795.r-sig-geo@r-project.org>
Message-ID: <5544B6E5.6000902@ub.edu>

You can try fiddling a bit with:

pol2 <- rasterToPolygons(r, fun=function(x){x>6}, dissolve = TRUE)

pol3 <- gBuffer(pol2,width=1e-5, byid=FALSE)

Where the width is sufficiently small as to not affect the general shape. However, it yields very jagged polygons, which I do not know if it is what you intend.

Best wishes,

Jos? M. Blanco

El 02/05/2015 a las 12:00, r-sig-geo-request at r-project.org<mailto:r-sig-geo-request at r-project.org> escribi?:

Subject: Re: [R-sig-Geo] Delimit a polygon for the region which is>
        1000 m from my raster altitude
Message-ID: <1430485336885-7588149.post at n2.nabble.com><mailto:1430485336885-7588149.post at n2.nabble.com>
Content-Type: text/plain; charset=us-ascii

Thank you very much "MacQueen, Don"  for your answer.

I have followed your instructions from this script :

library(raster)
library(sp)

f <- system.file("external/test.grd", package="raster")
r <- raster(f)

# add contour

x <- rasterToContour(r,levels=500)
class(x)
plot(r)
plot(x, add=TRUE)

#export contour to shapefile

library(rgdal)

writeOGR(x, ".", "contour", driver="ESRI Shapefile")


but when I open the shapefile, is a  lines not a polygons? My goal is to
have the polygon areas for altitude> 500m.

I thought to "rasterToPolygons"

library(raster)
library(sp)
f <- system.file("external/test.grd", package="raster")
r <- raster(f)

# add polygon

library(rgeos)

pol <- rasterToPolygons(r, fun=function(x){x>500})

plot(pol, add=T, col='red')

#export polygon to shapefile

library(rgdal)

writeOGR(pol, ".", "polygon", driver="ESRI Shapefile")



but the result, it displays a shapefile with polygons for each pixel

I just want  a polygons to areas where are> 500m, not for each pixel.

Thank you again






--
---------------------------------------
Jos? M. Blanco-Moreno
Dept. de Biologia Vegetal (Bot?nica)
Facultat de Biologia
Universitat de Barcelona
Av. Diagonal 643
08028 Barcelona
SPAIN
---------------------------------------
phone: (+34) 934 039 871
fax: (+34) 934 112 842
---------------------------------------


L'amistat ?s com una novel?la, s?n
paraules ben dites. -Montserrat Roig
(Barcelona 1946-1991)



Aquest correu electr?nic i els annexos poden contenir informaci? confidencial o protegida legalment i est? adre?at exclusivament a la persona o entitat destinat?ria. Si no sou el destinatari final o la persona encarregada de rebre?l, no esteu autoritzat a llegir-lo, retenir-lo, modificar-lo, distribuir-lo, copiar-lo ni a revelar-ne el contingut. Si heu rebut aquest correu electr?nic per error, us preguem que n?informeu al remitent i que elimineu del sistema el missatge i el material annex que pugui contenir. Gr?cies per la vostra col?laboraci?.

Este correo electr?nico y sus anexos pueden contener informaci?n confidencial o legalmente protegida y est? exclusivamente dirigido a la persona o entidad destinataria. Si usted no es el destinatario final o la persona encargada de recibirlo, no est? autorizado a leerlo, retenerlo, modificarlo, distribuirlo, copiarlo ni a revelar su contenido. Si ha recibido este mensaje electr?nico por error, le rogamos que informe al remitente y elimine del sistema el mensaje y el material anexo que pueda contener. Gracias por su colaboraci?n.

This email message and any documents attached to it may contain confidential or legally protected material and are intended solely for the use of the individual or organization to whom they are addressed. We remind you that if you are not the intended recipient of this email message or the person responsible for processing it, then you are not authorized to read, save, modify, send, copy or disclose any of its contents. If you have received this email message by mistake, we kindly ask you to inform the sender of this and to eliminate both the message and any attachments it carries from your account. Thank you for your collaboration.

	[[alternative HTML version deleted]]


From sadaouimahrez at outlook.com  Sat May  2 21:16:47 2015
From: sadaouimahrez at outlook.com (sadaoui)
Date: Sat, 2 May 2015 12:16:47 -0700 (MST)
Subject: [R-sig-Geo] Delimit a polygon for the region which is>,
 1000 m from my raster altitude
In-Reply-To: <5544B6E5.6000902@ub.edu>
References: <5544B6E5.6000902@ub.edu>
Message-ID: <1430594207896-7588153.post@n2.nabble.com>

Thank you very much  "Jos? M. Blanco Moreno" for your answer.


I have followed your instructions from this script :

library(raster)
library(sp)
f <- system.file("external/test.grd", package="raster")
r <- raster(f)

# add polygon

library(rgeos)
pol2 <- rasterToPolygons(r, fun=function(x){x>500}, dissolve = TRUE) 
pol3 <- gBuffer(pol2,width=0, byid=FALSE) 
plot(r)

plot(pol3,add=TRUE,border='blue',lwd=2,col="red",axes=TRUE) 
title("area > 500m")


I have had the result as I want a polygon for the area> 500m.

But, 
I found a problem to export this polygon (pol3)

#export polygon to shapefile

library(rgdal)
writeOGR(pol3, ".", "polygon3", driver="ESRI Shapefile")

Error in writeOGR(pol3, ".", "polygon3", driver = "ESRI Shapefile") : 
  obj must be a SpatialPointsDataFrame, SpatialLinesDataFrame or
    SpatialPolygonsDataFrame

it has not recognized as a polygon!!! I don't know why?

thank you for helping me to the last key






--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Re-Delimit-a-polygon-for-the-region-which-is-1000-m-from-my-raster-altitude-tp7588152p7588153.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From r.hijmans at gmail.com  Sat May  2 21:35:51 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sat, 2 May 2015 12:35:51 -0700
Subject: [R-sig-Geo] Delimit a polygon for the region which is>,
 1000 m from my raster altitude
In-Reply-To: <1430594207896-7588153.post@n2.nabble.com>
References: <5544B6E5.6000902@ub.edu>
	<1430594207896-7588153.post@n2.nabble.com>
Message-ID: <CANtt_hwwv04E3sfz1hCM3_63sHBRM9c-Vca1NiSVQQ3iRef7SA@mail.gmail.com>

" it has not recognized as a polygon!!! I don't know why? "

That is not true:

> class(pol3)
[1] "SpatialPolygons"
attr(,"package")
[1] "sp"

It is not a 'SpatialPolygonsDataFrame'

You can write it with:

shapefile(pol3, "polygon3.shp")

or use the SpatialPolygons object to create a SpatialPolygonsDataFrame
and then use writeOGR (that is what the shapefile function does for
you).

Robert


On Sat, May 2, 2015 at 12:16 PM, sadaoui <sadaouimahrez at outlook.com> wrote:
> Thank you very much  "Jos? M. Blanco Moreno" for your answer.
>
>
> I have followed your instructions from this script :
>
> library(raster)
> library(sp)
> f <- system.file("external/test.grd", package="raster")
> r <- raster(f)
>
> # add polygon
>
> library(rgeos)
> pol2 <- rasterToPolygons(r, fun=function(x){x>500}, dissolve = TRUE)
> pol3 <- gBuffer(pol2,width=0, byid=FALSE)
> plot(r)
>
> plot(pol3,add=TRUE,border='blue',lwd=2,col="red",axes=TRUE)
> title("area > 500m")
>
>
> I have had the result as I want a polygon for the area> 500m.
>
> But,
> I found a problem to export this polygon (pol3)
>
> #export polygon to shapefile
>
> library(rgdal)
> writeOGR(pol3, ".", "polygon3", driver="ESRI Shapefile")
>
> Error in writeOGR(pol3, ".", "polygon3", driver = "ESRI Shapefile") :
>   obj must be a SpatialPointsDataFrame, SpatialLinesDataFrame or
>     SpatialPolygonsDataFrame
>
> it has not recognized as a polygon!!! I don't know why?
>
> thank you for helping me to the last key
>
>
>
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Re-Delimit-a-polygon-for-the-region-which-is-1000-m-from-my-raster-altitude-tp7588152p7588153.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From sadaouimahrez at outlook.com  Sat May  2 23:10:36 2015
From: sadaouimahrez at outlook.com (sadaoui)
Date: Sat, 2 May 2015 14:10:36 -0700 (MST)
Subject: [R-sig-Geo] Delimit a polygon for the region which is>,
 1000 m from my raster altitude
In-Reply-To: <CANtt_hwwv04E3sfz1hCM3_63sHBRM9c-Vca1NiSVQQ3iRef7SA@mail.gmail.com>
References: <5544B6E5.6000902@ub.edu>
	<1430594207896-7588153.post@n2.nabble.com>
	<CANtt_hwwv04E3sfz1hCM3_63sHBRM9c-Vca1NiSVQQ3iRef7SA@mail.gmail.com>
Message-ID: <1430601036539-7588155.post@n2.nabble.com>

Thank you "Robert Hijmans",

it works with this function ;

shapefile(pol3, "polygon3.shp") 


but I want to have the corresponding data to this shapefile.

I tried, as did you say :

"or use the SpatialPolygons object to create a SpatialPolygonsDataFrame
and then use writeOGR (that is what the shapefile function does for
you). "

I tried to follow this solution :

http://gis.stackexchange.com/questions/61633/r-convert-a-spatial-polygon-objet-to-spatial-polygon-data-frame

but I can not convert the spatial polygon to SpatialPolygonsDataFrame. sorry
i am a beginner in this field. 

thank you







--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Re-Delimit-a-polygon-for-the-region-which-is-1000-m-from-my-raster-altitude-tp7588152p7588155.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From r.hijmans at gmail.com  Sun May  3 02:50:05 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sat, 2 May 2015 17:50:05 -0700
Subject: [R-sig-Geo] Delimit a polygon for the region which is>,
 1000 m from my raster altitude
In-Reply-To: <1430601036539-7588155.post@n2.nabble.com>
References: <5544B6E5.6000902@ub.edu>
	<1430594207896-7588153.post@n2.nabble.com>
	<CANtt_hwwv04E3sfz1hCM3_63sHBRM9c-Vca1NiSVQQ3iRef7SA@mail.gmail.com>
	<1430601036539-7588155.post@n2.nabble.com>
Message-ID: <CANtt_hzZ-SSDD=buE6Gdi_xKXt=F0BU1Ui_5voxdpK2kTJtcQQ@mail.gmail.com>

If you want to keep the raster cell values, you could do

shapefile(pol2, "polygon2.shp")

and use that file.


On Sat, May 2, 2015 at 2:10 PM, sadaoui <sadaouimahrez at outlook.com> wrote:
> Thank you "Robert Hijmans",
>
> it works with this function ;
>
> shapefile(pol3, "polygon3.shp")
>
>
> but I want to have the corresponding data to this shapefile.
>
> I tried, as did you say :
>
> "or use the SpatialPolygons object to create a SpatialPolygonsDataFrame
> and then use writeOGR (that is what the shapefile function does for
> you). "
>
> I tried to follow this solution :
>
> http://gis.stackexchange.com/questions/61633/r-convert-a-spatial-polygon-objet-to-spatial-polygon-data-frame
>
> but I can not convert the spatial polygon to SpatialPolygonsDataFrame. sorry
> i am a beginner in this field.
>
> thank you
>
>
>
>
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Re-Delimit-a-polygon-for-the-region-which-is-1000-m-from-my-raster-altitude-tp7588152p7588155.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From sadaouimahrez at outlook.com  Sun May  3 11:00:29 2015
From: sadaouimahrez at outlook.com (sadaoui)
Date: Sun, 3 May 2015 02:00:29 -0700 (MST)
Subject: [R-sig-Geo] Delimit a polygon for the region which is>,
 1000 m from my raster altitude
In-Reply-To: <CANtt_hzZ-SSDD=buE6Gdi_xKXt=F0BU1Ui_5voxdpK2kTJtcQQ@mail.gmail.com>
References: <5544B6E5.6000902@ub.edu>
	<1430594207896-7588153.post@n2.nabble.com>
	<CANtt_hwwv04E3sfz1hCM3_63sHBRM9c-Vca1NiSVQQ3iRef7SA@mail.gmail.com>
	<1430601036539-7588155.post@n2.nabble.com>
	<CANtt_hzZ-SSDD=buE6Gdi_xKXt=F0BU1Ui_5voxdpK2kTJtcQQ@mail.gmail.com>
Message-ID: <1430643629981-7588157.post@n2.nabble.com>

Ok thank you  Robert Hijmans


If you want to keep the raster cell values, you could do

shapefile(pol2, "polygon2.shp")

and use that file.


On Sat, May 2, 2015 at 2:10 PM, sadaoui &lt;sadaouimahrez@&gt; wrote:
> Thank you "Robert Hijmans",
>
> it works with this function ;
>
> shapefile(pol3, "polygon3.shp")
>
>
> but I want to have the corresponding data to this shapefile.
>
> I tried, as did you say :
>
> "or use the SpatialPolygons object to create a SpatialPolygonsDataFrame
> and then use writeOGR (that is what the shapefile function does for
> you). "
>
> I tried to follow this solution :
>
> http://gis.stackexchange.com/questions/61633/r-convert-a-spatial-polygon-objet-to-spatial-polygon-data-frame
>
> but I can not convert the spatial polygon to SpatialPolygonsDataFrame.
> sorry
> i am a beginner in this field.
>
> thank you
>
>
>
>
>
>
>
> --
> View this message in context:
> http://r-sig-geo.2731867.n2.nabble.com/Re-Delimit-a-polygon-for-the-region-which-is-1000-m-from-my-raster-altitude-tp7588152p7588155.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo@
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo@
https://stat.ethz.ch/mailman/listinfo/r-sig-geo





--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Re-Delimit-a-polygon-for-the-region-which-is-1000-m-from-my-raster-altitude-tp7588152p7588157.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From hatvaniig at gmail.com  Sun May  3 13:39:34 2015
From: hatvaniig at gmail.com (=?UTF-8?Q?Istv=C3=A1n_G=C3=A1bor_Hatvani?=)
Date: Sun, 3 May 2015 13:39:34 +0200
Subject: [R-sig-Geo] taking zonal anisotropy into account in gstat
Message-ID: <CAPU-C+Uy+N9RCHc5WRnct5fQX4SODwnweZ9L0pUV5Q_3Az1_Ww@mail.gmail.com>

Dear Colleagues,

I would like to ask for some help.

Does anyone have an idea, is it possible to take zonal anisotropy into
account during kriging in *gstat*, such as in the paper found in the link
below in my GoogleDrive? I did not find any argument concerning this
question.

https://drive.google.com/folderview?id=0B0GWyljhqBgKYnM4LWR1SjFlNU0&usp=sharing

I did manage to plot it in another program, but I am not satisfied with it.

Thank you for your help in advance!

Best regards,

Istvan

	[[alternative HTML version deleted]]


From mozzie070 at gmail.com  Sun May  3 19:42:45 2015
From: mozzie070 at gmail.com (mozzie)
Date: Sun, 3 May 2015 10:42:45 -0700 (MST)
Subject: [R-sig-Geo] Is Fisher z transformation applicable for the z score
 of Moran's I in function sp.correlogram?
Message-ID: <1430674965030-7588159.post@n2.nabble.com>

Dear all,

I'm currious about if Fisher z transformation could be used to determine
that wheter two distinct z score of  Moran's I have statistically
significant difference?

For example, follows are my result :

Spatial correlogram
method: Moran's I
             estimate expectation    variance standard deviate Pr(I) two
sided    
1 (5300)   0.06365873 -0.00018871  0.00017095           4.8833      
1.043e-06 ***
2 (4631)   0.02206724 -0.00021598  0.00022252           1.4938         
0.1352    
3 (3981)  -0.01431569 -0.00025126  0.00027118          -0.8541         
0.3931    
4 (3433)   0.01341846 -0.00029138  0.00033019           0.7545         
0.4506    
5 (2898)   0.02451172 -0.00034518  0.00040564           1.2342         
0.2171    
6 (2393)  -0.00115558 -0.00041806  0.00049807          -0.0330         
0.9736    
7 (1969)   0.01015559 -0.00050813  0.00060344           0.4341         
0.6642    
8 (1630)  -0.00541672 -0.00061387  0.00072303          -0.1786         
0.8582    
9 (1330)   0.01078355 -0.00075245  0.00088182           0.3885         
0.6977    
10 (1094) -0.00027244 -0.00091491  0.00106462           0.0197         
0.9843    
---

Can I use the standard deviate column for Fisher z transformation?



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Is-Fisher-z-transformation-applicable-for-the-z-score-of-Moran-s-I-in-function-sp-correlogram-tp7588159.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From mozzie070 at gmail.com  Sun May  3 20:00:23 2015
From: mozzie070 at gmail.com (mozzie)
Date: Sun, 3 May 2015 11:00:23 -0700 (MST)
Subject: [R-sig-Geo] Is Fisher z transformation applicable for the z
 score of Moran's I in function sp.correlogram?
In-Reply-To: <1430674965030-7588159.post@n2.nabble.com>
References: <1430674965030-7588159.post@n2.nabble.com>
Message-ID: <1430676023224-7588160.post@n2.nabble.com>

Sorry, I made some mistake in the previous post.
My question is:
*Can I use the estimate column for Fisher z transformation?
*
Spatial correlogram 
method: Moran's I
             estimate expectation    variance standard deviate Pr(I) two
sided    
1 (5300)   0.06365873 -0.00018871  0.00017095           4.8833      
1.043e-06 ***
2 (4631)   0.02206724 -0.00021598  0.00022252           1.4938         
0.1352    
3 (3981)  -0.01431569 -0.00025126  0.00027118          -0.8541         
0.3931    
4 (3433)   0.01341846 -0.00029138  0.00033019           0.7545         
0.4506    
5 (2898)   0.02451172 -0.00034518  0.00040564           1.2342         
0.2171    
6 (2393)  -0.00115558 -0.00041806  0.00049807          -0.0330         
0.9736    
7 (1969)   0.01015559 -0.00050813  0.00060344           0.4341         
0.6642    
8 (1630)  -0.00541672 -0.00061387  0.00072303          -0.1786         
0.8582    
9 (1330)   0.01078355 -0.00075245  0.00088182           0.3885         
0.6977    
10 (1094) -0.00027244 -0.00091491  0.00106462           0.0197         
0.9843    
---




--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Is-Fisher-z-transformation-applicable-for-the-z-score-of-Moran-s-I-in-function-sp-correlogram-tp7588159p7588160.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Sun May  3 20:24:44 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 3 May 2015 20:24:44 +0200
Subject: [R-sig-Geo] Is Fisher z transformation applicable for the z
 score of Moran's I in function sp.correlogram?
In-Reply-To: <1430676023224-7588160.post@n2.nabble.com>
References: <1430674965030-7588159.post@n2.nabble.com>
	<1430676023224-7588160.post@n2.nabble.com>
Message-ID: <alpine.LFD.2.11.1505032023010.17006@reclus.nhh.no>

No, Moran's I is *not* a correlation coefficient, see publications by 
Hepple, Tiefelsdorf and others.

Roger

On Sun, 3 May 2015, mozzie wrote:

> Sorry, I made some mistake in the previous post.
> My question is:
> *Can I use the estimate column for Fisher z transformation?
> *
> Spatial correlogram
> method: Moran's I
>             estimate expectation    variance standard deviate Pr(I) two
> sided
> 1 (5300)   0.06365873 -0.00018871  0.00017095           4.8833
> 1.043e-06 ***
> 2 (4631)   0.02206724 -0.00021598  0.00022252           1.4938
> 0.1352
> 3 (3981)  -0.01431569 -0.00025126  0.00027118          -0.8541
> 0.3931
> 4 (3433)   0.01341846 -0.00029138  0.00033019           0.7545
> 0.4506
> 5 (2898)   0.02451172 -0.00034518  0.00040564           1.2342
> 0.2171
> 6 (2393)  -0.00115558 -0.00041806  0.00049807          -0.0330
> 0.9736
> 7 (1969)   0.01015559 -0.00050813  0.00060344           0.4341
> 0.6642
> 8 (1630)  -0.00541672 -0.00061387  0.00072303          -0.1786
> 0.8582
> 9 (1330)   0.01078355 -0.00075245  0.00088182           0.3885
> 0.6977
> 10 (1094) -0.00027244 -0.00091491  0.00106462           0.0197
> 0.9843
> ---
>
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Is-Fisher-z-transformation-applicable-for-the-z-score-of-Moran-s-I-in-function-sp-correlogram-tp7588159p7588160.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From edzer.pebesma at uni-muenster.de  Sun May  3 20:42:08 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 03 May 2015 20:42:08 +0200
Subject: [R-sig-Geo] taking zonal anisotropy into account in gstat
In-Reply-To: <CAPU-C+Uy+N9RCHc5WRnct5fQX4SODwnweZ9L0pUV5Q_3Az1_Ww@mail.gmail.com>
References: <CAPU-C+Uy+N9RCHc5WRnct5fQX4SODwnweZ9L0pUV5Q_3Az1_Ww@mail.gmail.com>
Message-ID: <55466C00.7090601@uni-muenster.de>

You can "fake" it with a geometrically anisotropic model that has a very
large range in the direction where you want it to disappear, as in:

library(sp)
demo(meuse,ask=FALSE,echo=FALSE)
library(gstat)
v = variogram(log(zinc)~1, meuse, alpha = c(0,45,90,135))
vm = vgm(.25, "Sph", 1000, anis = c(45, 0.5))
plot(v, vm, main = "geometric")
zonal = vgm(.5, "Sph", 1e9, anis = c(45, 1/1e6))
# range is 1e9, effectively infinity, in 45 direction;
# it is 1e9/1e6 = 1000 in 135 direction.
vm = vgm(.25, "Sph", 1000, add.to = zonal)
plot(v, vm, main = "zonal")


On 05/03/2015 01:39 PM, Istv?n G?bor Hatvani wrote:
> Dear Colleagues,
> 
> I would like to ask for some help.
> 
> Does anyone have an idea, is it possible to take zonal anisotropy into
> account during kriging in *gstat*, such as in the paper found in the link
> below in my GoogleDrive? I did not find any argument concerning this
> question.
> 
> https://drive.google.com/folderview?id=0B0GWyljhqBgKYnM4LWR1SjFlNU0&usp=sharing
> 
> I did manage to plot it in another program, but I am not satisfied with it.
> 
> Thank you for your help in advance!
> 
> Best regards,
> 
> Istvan
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150503/61fd351c/attachment.bin>

From mozzie070 at gmail.com  Mon May  4 06:36:52 2015
From: mozzie070 at gmail.com (mozzie)
Date: Sun, 3 May 2015 21:36:52 -0700 (MST)
Subject: [R-sig-Geo] Is Fisher z transformation applicable for the z
 score of Moran's I in function sp.correlogram?
In-Reply-To: <alpine.LFD.2.11.1505032023010.17006@reclus.nhh.no>
References: <1430674965030-7588159.post@n2.nabble.com>
	<1430676023224-7588160.post@n2.nabble.com>
	<alpine.LFD.2.11.1505032023010.17006@reclus.nhh.no>
Message-ID: <1430714212236-7588163.post@n2.nabble.com>

Thanks,
so it is there no way for comparing two Moran's I value of different lags or
data frame?



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Is-Fisher-z-transformation-applicable-for-the-z-score-of-Moran-s-I-in-function-sp-correlogram-tp7588159p7588163.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From davesanjay at gmail.com  Mon May  4 14:01:48 2015
From: davesanjay at gmail.com (Dr Sanjay Dave)
Date: Mon, 4 May 2015 17:31:48 +0530
Subject: [R-sig-Geo] Data excess from KNB
Message-ID: <CAMmLDePC3MEcoCwaQQebOWntarUrR3DhAWxQtJbFhzzMOu7cRw@mail.gmail.com>

Hi all,

I have downloaded Kepler and have my credential made in KNB as well. While
accessing data from local/ KNB, I am getting no results. While accessing
data from KNB, I get message 301 Moved permanently. While trying to access
data by announcing Login Anonymously also returns error 301 Moved
permanently.

Kindly guide me what went wrong or what changes should be made. I am trying
to access data from KNB as Unaffiliated.

Thanking you in advance.

-- 
Dr. Sanjay Dave
Head
Department of Biotechnology
Hem. North Gujarat University
Patan - 384 265 (Gujarat)
India
Cell 09377719703

	[[alternative HTML version deleted]]


From aasdelat at aim.com  Mon May  4 14:36:36 2015
From: aasdelat at aim.com (Antonio Serrano)
Date: Mon, 4 May 2015 08:36:36 -0400
Subject: [R-sig-Geo] Interactive maps (fwd)
In-Reply-To: <3B520EAC4F77E4438AAC3F67FC99E0093E9E5133@WAXMXOLYMB007.WAX.wa.lcl>
Message-ID: <14d1eed96a2-5e93-1751d@webprd-m05.mail.aol.com>


Hi:

Thank you, Ranil, but these two solutions imply to generate again the map within R, but the map I have to use already exists, and has to be produced by a Fortran program.

So, I think Barry's solution is more apropriate for my problem.

 

Antonio Serrano
aasdelat at aim.com
?

 

 

-----Original Message-----
From: Dhammapala, Ranil (ECY) (ECY) <rdha461 at ecy.wa.gov>
To: aasdelat <aasdelat at aim.com>; Bowman, Clint (ECY) (ECY) <cbow461 at ECY.WA.GOV>
Sent: Thu, Apr 30, 2015 9:36 pm
Subject: RE: [R-sig-Geo] Interactive maps (fwd)


Antonio,

One possible solution that I haven?t investigated, and one (more
cumbersome) that I've worked on:

Easy, untried one first:

Can you use the
two R functions "rMaps" (http://rmaps.github.io/) and "identify"
(http://stat.ethz.ch/R-manual/R-devel/library/graphics/html/identify.html) to
get what you want?

Tried & tested solution:

We did something similar using
a Google maps API and Javascript on a web page to allow users click on a map &
have the coordinates passed to R. You will need to install a web server called
"rApache" on a Linux system for this. 

Have a look at the html code of the
web page http://bglookup.cee.wsu.edu and see how the Javascript passes off the
coordinates of the user-selected map point, to the R function. Once in R, you
access these arguments using POST$lat and POST$lon (based on variable names used
in this example).

The R library "hwriter" is very helpful in formatting R
program output for web
pages.

HTH

Ranil//

~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~
Ranil
Dhammapala, PhD
Acting Manager, Science and Engineering Section
Air Quality
Program, Washington Department of Ecology 
P.O Box 47600, Olympia, WA
98504-7600
Tel: 360-407-6807   Fax: 360-407-7534
Email:
ranil.dhammapala at ecy.wa.gov
~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~


-----Original
Message-----
From: Clint Bowman [mailto:clint at ecy.wa.gov] 
Sent: Wednesday,
April 29, 2015 8:03 AM
To: Dhammapala, Ranil (ECY)
Subject: [R-sig-Geo]
Interactive maps (fwd)

It sounds as if in the email below Antonio is trying
to do what is being done with the background design value map.  He may benefit
from your experience.

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality
Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360)
407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

       
USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:       
300 Desmond Drive, Lacey, WA 98503-1274

---------- Forwarded message
----------
Date: Wed, 29 Apr 2015 06:36:13
From: Antonio Serrano via R-sig-Geo
<r-sig-geo at r-project.org>
Reply-To: Antonio Serrano <aasdelat at aim.com>
To:
r-sig-geo at r-project.org
Subject: [R-sig-Geo] Interactive maps
Resent-Date:
Wed, 29 Apr 2015 06:36:59 -0700
Resent-From: <cbow461 at ecy.wa.gov>


  
Hello, all:

     I'm new in this forum. I have been redirected here from the
r-help forum.

     Well, I have the challenge to produce an interactive
map.

     I have a map which has been produced by a Fortran program. I have
the sources of this Fortran program and can produce the map in many formats:
eps, ps, png, jpeg, svg, etc.

     I have to load the map in R, which has to
display it on the screen.

     Then, the user clicks on a point on the map,
and then, R has to retrieve the longitude and latitude where the user has just
clicked.

     And then, R has to look for some information corresponding to
that location, process that information, and present it to the user in another
graphic.

     And the point is: what format and metainformation has to have
the map to be correctly read by R and to retrieve longitude and latitude when
the user clicks, and not "figure" coordinates?.

     I am thinking on
inoculating some metainformation into the map, from the fortran program, and
read and interpret it from R, but there is perhaps a more "correct" way to do
this.


Antonio Serrano
aasdelat at aim.com
?


 	[[alternative HTML
version deleted]]

_______________________________________________
R-sig-Geo
mailing
list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



	[[alternative HTML version deleted]]


From aasdelat at aim.com  Mon May  4 14:41:30 2015
From: aasdelat at aim.com (Antonio Serrano)
Date: Mon, 4 May 2015 08:41:30 -0400
Subject: [R-sig-Geo] Interactive maps
In-Reply-To: <CANVKczNa_ejfb4HS+O=a9=j3OtAiVDMtRsn3P5-GV7nH9snq6Q@mail.gmail.com>
Message-ID: <14d1ef21310-5e93-175ba@webprd-m05.mail.aol.com>


 Hi:

   Thank you Barry. Your solution is adequate for my problem.

   My map is divided in rectangles which sides are measured in degrees (longitude and latitude), not km. Each rectangle (and not each pixel) is associated with more information that has to be located, porcessed and presented to the user when he clicks in a rectangle.

   I will try it.

 
Thank you very much.

Antonio Serrano
aasdelat at aim.com
?

 

 

-----Original Message-----
From: Barry Rowlingson <b.rowlingson at lancaster.ac.uk>
To: Antonio Serrano <aasdelat at aim.com>
Cc: r-sig-geo <r-sig-geo at r-project.org>
Sent: Wed, Apr 29, 2015 5:02 pm
Subject: Re: [R-sig-Geo] Interactive maps


On Wed, Apr 29, 2015 at 2:36 PM, Antonio Serrano via
R-sig-Geo
<r-sig-geo at r-project.org> wrote:

I suspect we may need some
clarification...

>     I have a map which has been produced by a Fortran
program. I have the sources of this Fortran program and can produce the map in
many formats: eps, ps, png, jpeg, svg, etc.

 So the "map" is an image file,
and every pixel is the same
rectangular (not necessarily square) size in
degrees of latitude and
longitude? And you know those coordinates? Or
equivalently you know
the limits of the map in lat-long and how many pixels it
is?

>     And the point is: what format and metainformation has to have the
map to be correctly read by R and to retrieve longitude and latitude when the
user clicks, and not "figure" coordinates?.
>
>     I am thinking on
inoculating some metainformation into the map, from the fortran program, and
read and interpret it from R, but there is perhaps a more "correct" way to do
this.

You can georeference any image by creating a companion "world"
file.
This is usually the image file with a "w" on the extension, so the
world
file for foo.png is foo.pngw. Details of the world file format
are in various
places, try here:

https://en.wikipedia.org/wiki/World_file

Its a simple
text file with only a few lines.

Once you have created that, then the image
and its world file make up
a GDAL-compatible raster data source. Which means
you can read it in
once you have the `raster` and `rgdal` packages installed,
and its
location is known. When you plot it, it will plot at that
location,
and if you do locator(type="p") and click somewhere you will get
a
returned value in the image's geographic coordinates system.

The big
problem will be if the assumptions I mention above are not
true. If you have a
grid of 100km squares, then those grid cells have
different sizes in degrees as
you go north-south. If that's not the
case then the above will work
fine.

Barry




>
> Antonio Serrano
> aasdelat at aim.com
> ?
>
>
>  
[[alternative HTML version deleted]]
>
>
_______________________________________________
> R-sig-Geo mailing list
>
R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



	[[alternative HTML version deleted]]


From SWalbridge at esri.com  Mon May  4 15:36:17 2015
From: SWalbridge at esri.com (Shaun Walbridge)
Date: Mon, 4 May 2015 13:36:17 +0000
Subject: [R-sig-Geo] Data excess from KNB
In-Reply-To: <CAMmLDePC3MEcoCwaQQebOWntarUrR3DhAWxQtJbFhzzMOu7cRw@mail.gmail.com>
References: <CAMmLDePC3MEcoCwaQQebOWntarUrR3DhAWxQtJbFhzzMOu7cRw@mail.gmail.com>
Message-ID: <D16CED52.238D7%swalbridge@esri.com>

Dr. Dave,

This list is for issues regarding spatial R. You?ll have better luck using
the support systems for the Kepler project:
  https://kepler-project.org/users/support

Or, if the issue is specific to KNB, try the KNB contact email at:
knb-help at nceas.ucsb.edu

-- 
Shaun Walbridge
c: 805.722.9025 t: @scw <http://twitter.com/scw>





On 5/4/15, 8:01 AM, "Dr Sanjay Dave" <davesanjay at gmail.com> wrote:

>Hi all,
>
>I have downloaded Kepler and have my credential made in KNB as well. While
>accessing data from local/ KNB, I am getting no results. While accessing
>data from KNB, I get message 301 Moved permanently. While trying to access
>data by announcing Login Anonymously also returns error 301 Moved
>permanently.
>
>Kindly guide me what went wrong or what changes should be made. I am
>trying
>to access data from KNB as Unaffiliated.
>
>Thanking you in advance.
>
>-- 
>Dr. Sanjay Dave
>Head
>Department of Biotechnology
>Hem. North Gujarat University
>Patan - 384 265 (Gujarat)
>India
>Cell 09377719703
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at r-project.org
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From kat.emidio at gmail.com  Mon May  4 16:16:35 2015
From: kat.emidio at gmail.com (Katia)
Date: Mon, 4 May 2015 10:16:35 -0400
Subject: [R-sig-Geo] diversity zones
References: <CABFLJOmP0Y9D_R5XiFE=BGrr8as052t8QBcNFr0eas-=c9hJQw@mail.gmail.com>
Message-ID: <42190A7B-A94B-4B18-930C-C6C70D48039E@gmail.com>



> 
> Dear all,
> 
> I am trying to create a diversiy zones based on tree species distribution,  from neighboor analysis. I identify the 20th neighboor from each one of my tree species, and counted the richness associated to each one. I also have the associated distance to each kth tree... So, my study area is 100x100 m..As I want zone areas, how can I divide this area, so it can represent the richnees found? From 265 species, I am interested to do this for 30 one, generating maps for each one.
> 
> I though to use the Dirichlet tessellation, but it is a little hard to me, to imagine how to do it...
> 
> Any tips  are welcome!!!
> 
> 
> -- 
> K?tia Em?dio da Silva DSc
> Eng. Florestal
> Manaus/AM
> 
> 
> 
> Forestry Engineer
> Manaus/AM-Brazil


From oscar.perpinan at gmail.com  Tue May  5 13:34:40 2015
From: oscar.perpinan at gmail.com (=?UTF-8?Q?Oscar_Perpi=C3=B1an?=)
Date: Tue, 5 May 2015 13:34:40 +0200
Subject: [R-sig-Geo] Problem reading a HDF5 file with readGDAL in Windows
Message-ID: <CAMLL7bnJbepHdXFRSA-gCcB=q5NZLCexUZhLx-QTWHhO28wkkg@mail.gmail.com>

Hello,

I am trying to read a HDF5 file whose variable name contains '//'. I have no
problem in a Linux machine, but 'readGDAL' throws an error in Windows. If I
am not wrong, it is because the initialize method of the 'GDALReadOnlyDataset'
class includes a call to 'normalizePath'.

For example, the next code works in Linux but fails in Windows (it uses this
file
ftp://atrain.sci.gsfc.nasa.gov/data/s4pa//OMI/OMCLDO2_CPR.003/2015/125/OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.he5
)

x <- readGDAL("HDF5:OMI.L2.CloudOMCLDO2Strip200kmAlongClo
udSat.2015.05.05.020752Z.v003.he5://HDFEOS/SWATHS/
CloudFractionAndPressure/Data_Fields/ChiSquaredOfFit")

Is there any way to circumvent this problem?

Thanks in advance.

Oscar.
-----------------------------------------------------------------
Oscar Perpi??n Lamigueiro
Dpto. Ing. El?ctrica, Electr?nica, Autom?tica y F?sica Aplicada (ETSIDI-UPM)
Grupo de Sistemas Fotovoltaicos (IES-UPM)
URL: http://oscarperpinan.github.io

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Tue May  5 14:21:17 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 05 May 2015 12:21:17 +0000
Subject: [R-sig-Geo] Problem reading a HDF5 file with readGDAL in Windows
In-Reply-To: <CAMLL7bnJbepHdXFRSA-gCcB=q5NZLCexUZhLx-QTWHhO28wkkg@mail.gmail.com>
References: <CAMLL7bnJbepHdXFRSA-gCcB=q5NZLCexUZhLx-QTWHhO28wkkg@mail.gmail.com>
Message-ID: <CAAcGz99yW13Q9PTRbd+SX+z3RsyRG=tofwiUnCFTqcfJ2XkMhw@mail.gmail.com>

Are you sure you have the HDF5 driver in Windows?  Do you build yourself
against your own GDAL or against OSGeo4W?  (It's not in the CRAN
windows-build).

This is the error the CRAN build gives (though it's actually not
recognizing the driver):

"... does not exist in the file system, and is not recognised as a
supported dataset name."

(gdalinfo works fine with your subdataset string here on my Windows8 with
OSGeo4W. )

Cheers, Mike.




On Tue, 5 May 2015 at 21:35 Oscar Perpi?an <oscar.perpinan at gmail.com> wrote:

> Hello,
>
> I am trying to read a HDF5 file whose variable name contains '//'. I have
> no
> problem in a Linux machine, but 'readGDAL' throws an error in Windows. If I
> am not wrong, it is because the initialize method of the
> 'GDALReadOnlyDataset'
> class includes a call to 'normalizePath'.
>
> For example, the next code works in Linux but fails in Windows (it uses
> this
> file
>
> ftp://atrain.sci.gsfc.nasa.gov/data/s4pa//OMI/OMCLDO2_CPR.003/2015/125/OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.he5
> )
>
> x <- readGDAL("HDF5:OMI.L2.CloudOMCLDO2Strip200kmAlongClo
> udSat.2015.05.05.020752Z.v003.he5://HDFEOS/SWATHS/
> CloudFractionAndPressure/Data_Fields/ChiSquaredOfFit")
>
> Is there any way to circumvent this problem?
>
> Thanks in advance.
>
> Oscar.
> -----------------------------------------------------------------
> Oscar Perpi??n Lamigueiro
> Dpto. Ing. El?ctrica, Electr?nica, Autom?tica y F?sica Aplicada
> (ETSIDI-UPM)
> Grupo de Sistemas Fotovoltaicos (IES-UPM)
> URL: http://oscarperpinan.github.io
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From johnbaums at gmail.com  Tue May  5 14:28:42 2015
From: johnbaums at gmail.com (John Baumgartner)
Date: Tue, 5 May 2015 22:28:42 +1000
Subject: [R-sig-Geo] Problem reading a HDF5 file with readGDAL in Windows
In-Reply-To: <CAMLL7bnJbepHdXFRSA-gCcB=q5NZLCexUZhLx-QTWHhO28wkkg@mail.gmail.com>
References: <CAMLL7bnJbepHdXFRSA-gCcB=q5NZLCexUZhLx-QTWHhO28wkkg@mail.gmail.com>
Message-ID: <CACpmSOsMWhL2AJyWaKJviAVhfqoQxLBx8krmgAw8TudB9uEV4A@mail.gmail.com>

Not a remedy, but the following might be a workable alternative...

ncdf4::nc_open("OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.he5")$var$`Data
Fields/ChiSquaredOfFit`

I'm not familiar with HDF5 structure, so not sure of possible downsides.

Cheers,
John

On Tue, May 5, 2015 at 9:34 PM, Oscar Perpi?an <oscar.perpinan at gmail.com>
wrote:

> Hello,
>
> I am trying to read a HDF5 file whose variable name contains '//'. I have
> no
> problem in a Linux machine, but 'readGDAL' throws an error in Windows. If I
> am not wrong, it is because the initialize method of the
> 'GDALReadOnlyDataset'
> class includes a call to 'normalizePath'.
>
> For example, the next code works in Linux but fails in Windows (it uses
> this
> file
>
> ftp://atrain.sci.gsfc.nasa.gov/data/s4pa//OMI/OMCLDO2_CPR.003/2015/125/OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.he5
> )
>
> x <- readGDAL("HDF5:OMI.L2.CloudOMCLDO2Strip200kmAlongClo
> udSat.2015.05.05.020752Z.v003.he5://HDFEOS/SWATHS/
> CloudFractionAndPressure/Data_Fields/ChiSquaredOfFit")
>
> Is there any way to circumvent this problem?
>
> Thanks in advance.
>
> Oscar.
> -----------------------------------------------------------------
> Oscar Perpi??n Lamigueiro
> Dpto. Ing. El?ctrica, Electr?nica, Autom?tica y F?sica Aplicada
> (ETSIDI-UPM)
> Grupo de Sistemas Fotovoltaicos (IES-UPM)
> URL: http://oscarperpinan.github.io
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From edoardo.baldoni at gmail.com  Tue May  5 15:08:26 2015
From: edoardo.baldoni at gmail.com (Edoardo Baldoni)
Date: Tue, 5 May 2015 20:08:26 +0700
Subject: [R-sig-Geo] Blank polygons in stplot
Message-ID: <CAOcqoUN2oFaka4jO2Pb3VGpe56v=REH0B05Z3z0bHjUQrar9iw@mail.gmail.com>

Hi all,

I am using the function stplot to visualize data in STFDFs and find that
the function does not seem to work properly when the STFDF is subsetted. In
particular, the output of the plot function seems to miss some data as
SpatialPolygons that should appear as colored are instead just
white-colored (blank). Is there any bug in the code or am I missing
something ?

The  issue can be replicated using the example presented at page 17 of the
spacetime article in the Journal of Statistical Software:

library("spacetime")
library("maps")
library("plotKML")
 states.m <- map("state", plot = FALSE, fill = TRUE)
IDs <- sapply(strsplit(states.m$names, ":"), function(x) x[1])
library("maptools")
 states <- map2SpatialPolygons(states.m, IDs = IDs)
yrs <- 1970:1986
 time <- as.POSIXct(paste(yrs, "-01-01", sep = ""), tz = "GMT")
library("plm")
data("Produc")
Produc.st <- STFDF(states[-8], time, Produc[order(Produc[2], Produc[1]),])
 library("RColorBrewer")
 stplot(Produc.st[,'1970/1972' , "unemp"], col.regions = SAGA_pal[[4]])

The difference between the code above and the one of the article is the
color used and the STFDF that here is subsetted. The state of Washington in
1971 appears blank while it should be colored according to the palette
color. This error comes out with every STFDF I use.
Can anyone help me fixing the issue ?

Thanks

Edoardo

	[[alternative HTML version deleted]]


From roman.lustrik at gmail.com  Tue May  5 15:37:48 2015
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Tue, 5 May 2015 15:37:48 +0200
Subject: [R-sig-Geo] Blank polygons in stplot
In-Reply-To: <CAOcqoUN2oFaka4jO2Pb3VGpe56v=REH0B05Z3z0bHjUQrar9iw@mail.gmail.com>
References: <CAOcqoUN2oFaka4jO2Pb3VGpe56v=REH0B05Z3z0bHjUQrar9iw@mail.gmail.com>
Message-ID: <CAHT1vphoyHwh=TFCMt8ZsQczxWyVatgr_cLSHSbiAdhv2O_rvQ@mail.gmail.com>

Hum, the values for Washington are near 10 (black) according to the palette
you specify.

> SAGA_pal[4]
$SG_COLORS_RED_BLACK
 [1] "#FF0000" "#F10000" "#E40000" "#D60000" "#C90000" "#BB0000" "#AE0000"
"#A10000" "#930000" "#860000" "#780000" "#6B0000" "#5D0000" "#500000"
[15] "#430000" "#350000" "#280000" "#1A0000" "#0D0000" "#000000"

> was <- as.data.frame(Produc.st[,'1970/1972' , "unemp"])
> was[was$sp.ID == "washington", ]
           V1       V2      sp.ID       time    endTime timeIndex unemp
45  -120.3957 47.37073 washington 1970-01-01 1971-01-01         1   9.1
93  -120.3957 47.37073 washington 1971-01-01 1972-01-01         2  10.0
141 -120.3957 47.37073 washington 1972-01-01 1973-01-01         3   9.5

Cheers,
Roman



On Tue, May 5, 2015 at 3:08 PM, Edoardo Baldoni <edoardo.baldoni at gmail.com>
wrote:

> Hi all,
>
> I am using the function stplot to visualize data in STFDFs and find that
> the function does not seem to work properly when the STFDF is subsetted. In
> particular, the output of the plot function seems to miss some data as
> SpatialPolygons that should appear as colored are instead just
> white-colored (blank). Is there any bug in the code or am I missing
> something ?
>
> The  issue can be replicated using the example presented at page 17 of the
> spacetime article in the Journal of Statistical Software:
>
> library("spacetime")
> library("maps")
> library("plotKML")
>  states.m <- map("state", plot = FALSE, fill = TRUE)
> IDs <- sapply(strsplit(states.m$names, ":"), function(x) x[1])
> library("maptools")
>  states <- map2SpatialPolygons(states.m, IDs = IDs)
> yrs <- 1970:1986
>  time <- as.POSIXct(paste(yrs, "-01-01", sep = ""), tz = "GMT")
> library("plm")
> data("Produc")
> Produc.st <- STFDF(states[-8], time, Produc[order(Produc[2], Produc[1]),])
>  library("RColorBrewer")
>  stplot(Produc.st[,'1970/1972' , "unemp"], col.regions = SAGA_pal[[4]])
>
> The difference between the code above and the one of the article is the
> color used and the STFDF that here is subsetted. The state of Washington in
> 1971 appears blank while it should be colored according to the palette
> color. This error comes out with every STFDF I use.
> Can anyone help me fixing the issue ?
>
> Thanks
>
> Edoardo
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
In God we trust, all others bring data.

	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Tue May  5 15:58:48 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 05 May 2015 15:58:48 +0200
Subject: [R-sig-Geo] Blank polygons in stplot
In-Reply-To: <CAOcqoUN2oFaka4jO2Pb3VGpe56v=REH0B05Z3z0bHjUQrar9iw@mail.gmail.com>
References: <CAOcqoUN2oFaka4jO2Pb3VGpe56v=REH0B05Z3z0bHjUQrar9iw@mail.gmail.com>
Message-ID: <5548CC98.7050806@uni-muenster.de>



On 05/05/2015 03:08 PM, Edoardo Baldoni wrote:
> Hi all,
> 
> I am using the function stplot to visualize data in STFDFs and find that
> the function does not seem to work properly when the STFDF is subsetted. In
> particular, the output of the plot function seems to miss some data as
> SpatialPolygons that should appear as colored are instead just
> white-colored (blank). Is there any bug in the code or am I missing
> something ?
> 
> The  issue can be replicated using the example presented at page 17 of the
> spacetime article in the Journal of Statistical Software:
> 
> library("spacetime")
> library("maps")
> library("plotKML")
>  states.m <- map("state", plot = FALSE, fill = TRUE)
> IDs <- sapply(strsplit(states.m$names, ":"), function(x) x[1])
> library("maptools")
>  states <- map2SpatialPolygons(states.m, IDs = IDs)
> yrs <- 1970:1986
>  time <- as.POSIXct(paste(yrs, "-01-01", sep = ""), tz = "GMT")
> library("plm")
> data("Produc")
> Produc.st <- STFDF(states[-8], time, Produc[order(Produc[2], Produc[1]),])
>  library("RColorBrewer")
>  stplot(Produc.st[,'1970/1972' , "unemp"], col.regions = SAGA_pal[[4]])
> 
> The difference between the code above and the one of the article is the
> color used and the STFDF that here is subsetted. The state of Washington in
> 1971 appears blank while it should be colored according to the palette
> color. This error comes out with every STFDF I use.
> Can anyone help me fixing the issue ?

Thanks! For now only specifying "at" will help, as in

stplot(Produc.st[,'1970/1972' , "unemp"], col.regions = SAGA_pal[[4]],
at = 3:11)

or else update to the spacetime version that fixed this with

devtools::install_github("edzer/spacetime")


> 
> Thanks
> 
> Edoardo
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150505/50cb3442/attachment.bin>

From edoardo.baldoni at gmail.com  Tue May  5 16:24:36 2015
From: edoardo.baldoni at gmail.com (Edoardo Baldoni)
Date: Tue, 5 May 2015 21:24:36 +0700
Subject: [R-sig-Geo] Blank polygons in stplot
In-Reply-To: <5548CC98.7050806@uni-muenster.de>
References: <CAOcqoUN2oFaka4jO2Pb3VGpe56v=REH0B05Z3z0bHjUQrar9iw@mail.gmail.com>
	<5548CC98.7050806@uni-muenster.de>
Message-ID: <CAOcqoUNthEqx6VvJ6xYwAd78Z0uHsuYbrwmOCpvHdGer2Mjxgg@mail.gmail.com>

Thanks Edzer, this package is most useful
and thanks Roman

Edoardo

2015-05-05 20:58 GMT+07:00 Edzer Pebesma <edzer.pebesma at uni-muenster.de>:

>
>
> On 05/05/2015 03:08 PM, Edoardo Baldoni wrote:
> > Hi all,
> >
> > I am using the function stplot to visualize data in STFDFs and find that
> > the function does not seem to work properly when the STFDF is subsetted.
> In
> > particular, the output of the plot function seems to miss some data as
> > SpatialPolygons that should appear as colored are instead just
> > white-colored (blank). Is there any bug in the code or am I missing
> > something ?
> >
> > The  issue can be replicated using the example presented at page 17 of
> the
> > spacetime article in the Journal of Statistical Software:
> >
> > library("spacetime")
> > library("maps")
> > library("plotKML")
> >  states.m <- map("state", plot = FALSE, fill = TRUE)
> > IDs <- sapply(strsplit(states.m$names, ":"), function(x) x[1])
> > library("maptools")
> >  states <- map2SpatialPolygons(states.m, IDs = IDs)
> > yrs <- 1970:1986
> >  time <- as.POSIXct(paste(yrs, "-01-01", sep = ""), tz = "GMT")
> > library("plm")
> > data("Produc")
> > Produc.st <- STFDF(states[-8], time, Produc[order(Produc[2],
> Produc[1]),])
> >  library("RColorBrewer")
> >  stplot(Produc.st[,'1970/1972' , "unemp"], col.regions = SAGA_pal[[4]])
> >
> > The difference between the code above and the one of the article is the
> > color used and the STFDF that here is subsetted. The state of Washington
> in
> > 1971 appears blank while it should be colored according to the palette
> > color. This error comes out with every STFDF I use.
> > Can anyone help me fixing the issue ?
>
> Thanks! For now only specifying "at" will help, as in
>
> stplot(Produc.st[,'1970/1972' , "unemp"], col.regions = SAGA_pal[[4]],
> at = 3:11)
>
> or else update to the spacetime version that fixed this with
>
> devtools::install_github("edzer/spacetime")
>
>
> >
> > Thanks
> >
> > Edoardo
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi),  University of M?nster,
> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> Journal of Statistical Software:   http://www.jstatsoft.org/
> Computers & Geosciences:   http://elsevier.com/locate/cageo/
> Spatial Statistics Society http://www.spatialstatistics.info
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

	[[alternative HTML version deleted]]


From nessnjor at gmail.com  Tue May  5 17:54:59 2015
From: nessnjor at gmail.com (Kristin)
Date: Tue, 5 May 2015 08:54:59 -0700 (MST)
Subject: [R-sig-Geo] Predict gam in a loop on multiple raster stacks and
 keeping identical layer names
Message-ID: <1430841299362-7588176.post@n2.nabble.com>


I have a gam model with predictor names (variables) par, chl, sst, lat and
lon. The model I called "gammodel".
Then I have predictors for 96 day period in raster stacks: "stackpar",
"stackchl", "stacksst"
-that is 3 different raster stacks  - each one with 96 layers.
lat and lon are fixed in time and are each a separated raster with the
central value of each cell as a value in the raster. 
All stacks and rasters have same extent, dimention, projection etc. 
dim (84 840  96)

I want predict for each day for each pixel in a loop and create an output as
a raster stack of predictions for each of the 96 days
Something like this: 

Stack <- stack()
lenght(Stack) <-96              

for(i in 1:96) {
  Predictors <- stack(stackchl[[i]],stacksst[[i]],stackpar[[i]],lat, lon)
  Pred <- predict(Predictors,gammodel, na.rm=TRUE, type="response")
  Stack[i] <- Pred
}

I?m not sure I?m doing the loop correct? Any suggestions of improvement?

BUT the main problem is that the layers for each predictive varaible have
names which 
do not fit with the model. When I run it outside the loop for a single
layer:
 
Error in eval(expr, envir, enclos) : object 'par' not found
In addition: Warning message:
In predict.gam(model, blockvals, ...) :
  not all required variables have been supplied in  newdata!

I have tried to rename the layers in each raster stack like this: 
names (par)=rep("par",96) 
But the names are changed to: par.1, par.2, par.3, etc..
So they do not fit the variable name in the gam model itself. 

all the best and thanks in advance


 





--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Predict-gam-in-a-loop-on-multiple-raster-stacks-and-keeping-identical-layer-names-tp7588176.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From r.hijmans at gmail.com  Tue May  5 19:19:04 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 5 May 2015 10:19:04 -0700
Subject: [R-sig-Geo] Predict gam in a loop on multiple raster stacks and
 keeping identical layer names
In-Reply-To: <1430841299362-7588176.post@n2.nabble.com>
References: <1430841299362-7588176.post@n2.nabble.com>
Message-ID: <CANtt_hyL-ME5_BLwFk_kwkeVpu++EpfDNe-3gcY9AZh=cjnkbA@mail.gmail.com>

Kristin, I think you can do something like this:

lst <- list()

for(i in 1:96) {
  Predictors <- stack(stackchl[[i]], stacksst[[i]], stackpar[[i]], lat, lon)
  names(Predictos) <- c('chl', 'sst', 'par', 'lat', 'lon')
  lst[[i]] <- predict(Predictors, gammodel, na.rm=TRUE, type="response")
}

s <- stack(lst)

On Tue, May 5, 2015 at 8:54 AM, Kristin <nessnjor at gmail.com> wrote:
>
> I have a gam model with predictor names (variables) par, chl, sst, lat and
> lon. The model I called "gammodel".
> Then I have predictors for 96 day period in raster stacks: "stackpar",
> "stackchl", "stacksst"
> -that is 3 different raster stacks  - each one with 96 layers.
> lat and lon are fixed in time and are each a separated raster with the
> central value of each cell as a value in the raster.
> All stacks and rasters have same extent, dimention, projection etc.
> dim (84 840  96)
>
> I want predict for each day for each pixel in a loop and create an output as
> a raster stack of predictions for each of the 96 days
> Something like this:
>
> Stack <- stack()
> lenght(Stack) <-96
>
> for(i in 1:96) {
>   Predictors <- stack(stackchl[[i]],stacksst[[i]],stackpar[[i]],lat, lon)
>   Pred <- predict(Predictors,gammodel, na.rm=TRUE, type="response")
>   Stack[i] <- Pred
> }
>
> I?m not sure I?m doing the loop correct? Any suggestions of improvement?
>
> BUT the main problem is that the layers for each predictive varaible have
> names which
> do not fit with the model. When I run it outside the loop for a single
> layer:
>
> Error in eval(expr, envir, enclos) : object 'par' not found
> In addition: Warning message:
> In predict.gam(model, blockvals, ...) :
>   not all required variables have been supplied in  newdata!
>
> I have tried to rename the layers in each raster stack like this:
> names (par)=rep("par",96)
> But the names are changed to: par.1, par.2, par.3, etc..
> So they do not fit the variable name in the gam model itself.
>
> all the best and thanks in advance
>
>
>
>
>
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Predict-gam-in-a-loop-on-multiple-raster-stacks-and-keeping-identical-layer-names-tp7588176.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Tue May  5 19:24:21 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 5 May 2015 10:24:21 -0700
Subject: [R-sig-Geo] Problem reading a HDF5 file with readGDAL in Windows
In-Reply-To: <CACpmSOsMWhL2AJyWaKJviAVhfqoQxLBx8krmgAw8TudB9uEV4A@mail.gmail.com>
References: <CAMLL7bnJbepHdXFRSA-gCcB=q5NZLCexUZhLx-QTWHhO28wkkg@mail.gmail.com>
	<CACpmSOsMWhL2AJyWaKJviAVhfqoQxLBx8krmgAw8TudB9uEV4A@mail.gmail.com>
Message-ID: <CANtt_hz39G2KLP5aQ9uwHhC3qG81zVMne91X-=eSU6dHDd+uMg@mail.gmail.com>

In which case you can change the extension to '.nc' and do

library(raster)
library(ncdf4)
x <- raster("E:/downloads/OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.nc",
var='Data Fields/ChiSquaredOfFit')

Robert

On Tue, May 5, 2015 at 5:28 AM, John Baumgartner <johnbaums at gmail.com> wrote:
> Not a remedy, but the following might be a workable alternative...
>
> ncdf4::nc_open("OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.he5")$var$`Data
> Fields/ChiSquaredOfFit`
>
> I'm not familiar with HDF5 structure, so not sure of possible downsides.
>
> Cheers,
> John
>
> On Tue, May 5, 2015 at 9:34 PM, Oscar Perpi?an <oscar.perpinan at gmail.com>
> wrote:
>
>> Hello,
>>
>> I am trying to read a HDF5 file whose variable name contains '//'. I have
>> no
>> problem in a Linux machine, but 'readGDAL' throws an error in Windows. If I
>> am not wrong, it is because the initialize method of the
>> 'GDALReadOnlyDataset'
>> class includes a call to 'normalizePath'.
>>
>> For example, the next code works in Linux but fails in Windows (it uses
>> this
>> file
>>
>> ftp://atrain.sci.gsfc.nasa.gov/data/s4pa//OMI/OMCLDO2_CPR.003/2015/125/OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.he5
>> )
>>
>> x <- readGDAL("HDF5:OMI.L2.CloudOMCLDO2Strip200kmAlongClo
>> udSat.2015.05.05.020752Z.v003.he5://HDFEOS/SWATHS/
>> CloudFractionAndPressure/Data_Fields/ChiSquaredOfFit")
>>
>> Is there any way to circumvent this problem?
>>
>> Thanks in advance.
>>
>> Oscar.
>> -----------------------------------------------------------------
>> Oscar Perpi??n Lamigueiro
>> Dpto. Ing. El?ctrica, Electr?nica, Autom?tica y F?sica Aplicada
>> (ETSIDI-UPM)
>> Grupo de Sistemas Fotovoltaicos (IES-UPM)
>> URL: http://oscarperpinan.github.io
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Tue May  5 19:28:29 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 5 May 2015 10:28:29 -0700
Subject: [R-sig-Geo] Problem reading a HDF5 file with readGDAL in Windows
In-Reply-To: <CANtt_hz39G2KLP5aQ9uwHhC3qG81zVMne91X-=eSU6dHDd+uMg@mail.gmail.com>
References: <CAMLL7bnJbepHdXFRSA-gCcB=q5NZLCexUZhLx-QTWHhO28wkkg@mail.gmail.com>
	<CACpmSOsMWhL2AJyWaKJviAVhfqoQxLBx8krmgAw8TudB9uEV4A@mail.gmail.com>
	<CANtt_hz39G2KLP5aQ9uwHhC3qG81zVMne91X-=eSU6dHDd+uMg@mail.gmail.com>
Message-ID: <CANtt_hwbg9u1aqtH18d299bnrt_Qkdb=N2OwYS7av+91eFvSng@mail.gmail.com>

Even better (renaming not necessary):

x <- raster("E:/downloads/OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.he5",
var='Data Fields/ChiSquaredOfFit', ncdf=TRUE)

Best, Robert

On Tue, May 5, 2015 at 10:24 AM, Robert J. Hijmans <r.hijmans at gmail.com> wrote:
> In which case you can change the extension to '.nc' and do
>
> library(raster)
> library(ncdf4)
> x <- raster("E:/downloads/OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.nc",
> var='Data Fields/ChiSquaredOfFit')
>
> Robert
>
> On Tue, May 5, 2015 at 5:28 AM, John Baumgartner <johnbaums at gmail.com> wrote:
>> Not a remedy, but the following might be a workable alternative...
>>
>> ncdf4::nc_open("OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.he5")$var$`Data
>> Fields/ChiSquaredOfFit`
>>
>> I'm not familiar with HDF5 structure, so not sure of possible downsides.
>>
>> Cheers,
>> John
>>
>> On Tue, May 5, 2015 at 9:34 PM, Oscar Perpi?an <oscar.perpinan at gmail.com>
>> wrote:
>>
>>> Hello,
>>>
>>> I am trying to read a HDF5 file whose variable name contains '//'. I have
>>> no
>>> problem in a Linux machine, but 'readGDAL' throws an error in Windows. If I
>>> am not wrong, it is because the initialize method of the
>>> 'GDALReadOnlyDataset'
>>> class includes a call to 'normalizePath'.
>>>
>>> For example, the next code works in Linux but fails in Windows (it uses
>>> this
>>> file
>>>
>>> ftp://atrain.sci.gsfc.nasa.gov/data/s4pa//OMI/OMCLDO2_CPR.003/2015/125/OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.he5
>>> )
>>>
>>> x <- readGDAL("HDF5:OMI.L2.CloudOMCLDO2Strip200kmAlongClo
>>> udSat.2015.05.05.020752Z.v003.he5://HDFEOS/SWATHS/
>>> CloudFractionAndPressure/Data_Fields/ChiSquaredOfFit")
>>>
>>> Is there any way to circumvent this problem?
>>>
>>> Thanks in advance.
>>>
>>> Oscar.
>>> -----------------------------------------------------------------
>>> Oscar Perpi??n Lamigueiro
>>> Dpto. Ing. El?ctrica, Electr?nica, Autom?tica y F?sica Aplicada
>>> (ETSIDI-UPM)
>>> Grupo de Sistemas Fotovoltaicos (IES-UPM)
>>> URL: http://oscarperpinan.github.io
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From eugeneby at alumni.upenn.edu  Tue May  5 19:37:50 2015
From: eugeneby at alumni.upenn.edu (eugeneby)
Date: Tue, 5 May 2015 10:37:50 -0700 (MST)
Subject: [R-sig-Geo] Question about inhomogeneous k-functions
Message-ID: <1430847470079-7588180.post@n2.nabble.com>

Good afternoon everyone! I'm new to this forum and was hoping to get some
clarity about running k-function analysis in R.

I would like to see whether hospitals in a certain state are clustered,
dispersed or randomly distributed. I could just use the regular Ripley's
k-function analysis to examine the spatial distribution of the hospitals and
simulate confidence envelopes using the envelope command.

However, it won't be surprising to find that hospitals are clustered, as
more will be located in areas where the population (or population density)
is higher. So my question is whether there any way for R to take into
consideration a raster file showing the different population densities in
various parts of my study region when simulating confidence envelopes? Is
this what the Kinhom function does? And if so, how do I get it to read my
raster file? 

Thank you!





--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Question-about-inhomogeneous-k-functions-tp7588180.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From r.hijmans at gmail.com  Tue May  5 20:22:20 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 5 May 2015 11:22:20 -0700
Subject: [R-sig-Geo] adding a scale
In-Reply-To: <48fc-553e4f00-41-7f986f00@133731765>
References: <553B6E28.6080807@gmx.de>
	<48fc-553e4f00-41-7f986f00@133731765>
Message-ID: <CANtt_hxvNmDTxkpc1p97+tgoWOO=EVjsVM1xN_qLJXJ02M3G7Q@mail.gmail.com>

There is also a 'scalebar' function in the raster package (I have not
compared the two)

Robert

On Mon, Apr 27, 2015 at 7:59 AM, Gilles Benjamin Leduc <gbl1 at hi.is> wrote:
>
>  Not to bad hint :p
>
> So From this one, I modified the function to get it work correctly:
>
> #############################################################################################################################################################################
> ####                                                                                     Scale                                                                                               ####
> #############################################################################################################################################################################
>
> scalebar <- function(loc,length,unit="km" ,degrees = TRUE,cex=par("cex"), ...) {
>         if(missing(loc)) stop("loc is missing")
>         if(missing(length)) stop("length is missing")
>         z <- c(0,length/c(4,2,4/3,1),length*1.1)+loc[1]
>         if(degrees == TRUE) length<-180*(acos((cos(length/6371)-sin(loc[2]*pi/180)*sin(loc[2]*pi/180))/(cos(loc[2]*pi/180)*cos(loc[2]*pi/180))))/pi
>         x <- c(0,length/c(4,2,4/3,1),length*1.1)+loc[1]
>         y <- c(0,length/(10*3:1))+loc[2]
>         cols <- rep(c("black","white"),2)
>         for (i in 1:4) rect(x[i],y[1],x[i+1],y[2],col=cols[i])
>          for (i in 1:5) segments(x[i],y[2],x[i],y[3])
>          labels <- z[c(1,3)]-loc[1]
> labels <- append(labels,paste(z[5]-loc[1],unit))
> text(x[c(1,3,5)],y[4],labels=labels,cex,pos=3,offset=0) }
>
>
> and pushed it in my package https://github.com/giby/Linarius if someone wanna try. I could do some improve to support other units, I'll do that latter on.
>
> Thanks a lot for help
>
> Benjamin
>
> On Saturday, April 25, 2015 10:36 GMT, Guido Schulz <gosz at gmx.de> wrote:
>
>> You may want to check out this paper "Auxiliary Cartographic Functions
>> in R: North Arrow, Scale Bar, and Label with a Leader Arrow"
>> (http://www.jstatsoft.org/v19/c01/paper).
>>
>> It provides functions to add arrow and scale bar for plot.
>>
>>
>> Am 24.04.2015 um 14:10 schrieb Gilles Benjamin Leduc:
>> > Hi again, > > So, I use the plot() function. > I read a shapefile, that I convert in GPS coordinates like this: > > readOGR(dsn=S50V_STRANDLINA_24122014_ISN2004/IS50V_STRANDLINA_SHP", layer="is50v_strandlina_flakar_24122014")->IslHD
>> > spTransform(IslHD,CRS(" +proj=nglat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 "))->IslHD > > then plot : plot(IslHD) > > I tried several stuff for making a scale, results were either ugly or wrong? > The function Scalebar make a cute scale but really absurd? > > Any idea? > > Best regards
>> > > Benjamin   >  >  > On Thursday, April 23, 2015 05:18 GMT, Frede Aakmann T?gersen <frtog at vestas.com> wrote: >  >> Hi Benjamin
>> >>
>> >> Yes, there are several ways to do that. But it depends on which kind of plotting function you used. Usually it is a setting of an argument of the plotting function.
>> >>
>> >> I cannot help you more since I don't more than the information you provided in your email.
>> >>
>> >> If you want more help from this list please provide a small example showing which functions you used with information on which package(s) they belong. Then you'll probably get more help.
>> >>
>> >> The small example you can probably find in the example section on the help page for the plotting function.
>> >>
>> >> Best Regards
>> >>
>> >> Frede Aakmann T?gersen
>> >> Specialist, M.Sc., Ph.D.
>> >> Plant Performance & Modeling
>> >>
>> >> Technology & Service Solutions
>> >> T +45 9730 5135
>> >> M +45 2547 6050
>> >> frtog at vestas.com
>> >> http://www.vestas.com
>> >>
>> >> Company reg. name: Vestas Wind Systems A/S
>> >> This e-mail is subject to our e-mail disclaimer statement.
>> >> Please refer to www.vestas.com/legal/notice
>> >> If you have received this e-mail in error please contact the sender.
>> > >>
>> >> -----Original Message-----
>> >> From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Gilles Benjamin Leduc
>> >> Sent: 23. april 2015 02:46
>> >> To: r-sig-geo at r-project.org
>> >> Subject: [R-sig-Geo] adding a scale
>> >>
>> >> Hi all,
>> >>
>> >> I am ploting map from shapefiles (curently read with readOGR from rgdal). >> My PhD supervisor asked me to add a scale? Before going in crazy computation and the arrow function I wonder? Is there a function that can do it automatically (or easily) >>
>> >> Thanks in advance >>
>> >> Benjamin
>> >>
>> >> _______________________________________________
>> >> R-sig-Geo mailing list
>> >> R-sig-Geo at r-project.org
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> > >
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From marcelino.delacruz at upm.es  Tue May  5 22:32:49 2015
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Tue, 05 May 2015 22:32:49 +0200
Subject: [R-sig-Geo] Question about inhomogeneous k-functions
In-Reply-To: <1430847470079-7588180.post@n2.nabble.com>
References: <1430847470079-7588180.post@n2.nabble.com>
Message-ID: <554928F1.3050301@upm.es>

Hi eugeneby,


This is quite easy, using rgdal, maptools and spatstat.

See this example:

library(sp)
library(rgdal)
library(maptools)
library(spatstat)

# read external grid with rgdal; for example this data on package sp
x <- readGDAL(system.file("external/test.ag", package="sp")[1])

#transform to "im" format of spatstat

x.im<- as(x, "im")

plot(x.im)

# you should transform the values to correspond to the desired density 
of hospitals with arithmetic operations, for example:

x.im2<- x.im/10e7

plot(x.im2)

# And now you rpoispp to simulate random locations of hospitals an use 
this to compute envelopes

rpoispp(x.im2)

points(rpoispp(x.im2))


HTH,

MArcelino


El 05/05/2015 a las 19:37, eugeneby escribi?:
> Good afternoon everyone! I'm new to this forum and was hoping to get some
> clarity about running k-function analysis in R.
>
> I would like to see whether hospitals in a certain state are clustered,
> dispersed or randomly distributed. I could just use the regular Ripley's
> k-function analysis to examine the spatial distribution of the hospitals and
> simulate confidence envelopes using the envelope command.
>
> However, it won't be surprising to find that hospitals are clustered, as
> more will be located in areas where the population (or population density)
> is higher. So my question is whether there any way for R to take into
> consideration a raster file showing the different population densities in
> various parts of my study region when simulating confidence envelopes? Is
> this what the Kinhom function does? And if so, how do I get it to read my
> raster file?
>
> Thank you!
>
>
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Question-about-inhomogeneous-k-functions-tp7588180.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From eugeneby at alumni.upenn.edu  Tue May  5 23:13:24 2015
From: eugeneby at alumni.upenn.edu (eugeneby)
Date: Tue, 5 May 2015 14:13:24 -0700 (MST)
Subject: [R-sig-Geo] Question about inhomogeneous k-functions
In-Reply-To: <554928F1.3050301@upm.es>
References: <1430847470079-7588180.post@n2.nabble.com>
	<554928F1.3050301@upm.es>
Message-ID: <1430860404902-7588183.post@n2.nabble.com>

Thank you so much for your quick and helpful reply!
If I may, a couple follow up questions:
1. Instead of the rpoispp(x.im2), should I use
rpoint(260,x.im2,win=BoundaryPolygonsOW) to generate random point patterns
which contain the same number of points as in the original pattern (i.e.,
260)? Because the rpoispp command generates a ridiculously large number of
points and it doesn't seem that there's a simple way to indicate the number
of points that should be generated.
2. Should I then manually simply use the Kest command to calculate the
k-function for each of the, say, 99 simulations and compare my original
pattern with the min and max of these k-functions at different distances? Or
is there code which does that automatically? E.g., 
Envelopes <- spatstat::envelope(pp, Kinhom, lambda=x.im2, nsim=99,
correction="Ripley")?
(where pp is my original point pattern).
Thanks so much!
All the best,
~Eugene



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Question-about-inhomogeneous-k-functions-tp7588180p7588183.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From mdsumner at gmail.com  Tue May  5 23:20:33 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 05 May 2015 21:20:33 +0000
Subject: [R-sig-Geo] Problem reading a HDF5 file with readGDAL in Windows
In-Reply-To: <CANtt_hwbg9u1aqtH18d299bnrt_Qkdb=N2OwYS7av+91eFvSng@mail.gmail.com>
References: <CAMLL7bnJbepHdXFRSA-gCcB=q5NZLCexUZhLx-QTWHhO28wkkg@mail.gmail.com>
	<CACpmSOsMWhL2AJyWaKJviAVhfqoQxLBx8krmgAw8TudB9uEV4A@mail.gmail.com>
	<CANtt_hz39G2KLP5aQ9uwHhC3qG81zVMne91X-=eSU6dHDd+uMg@mail.gmail.com>
	<CANtt_hwbg9u1aqtH18d299bnrt_Qkdb=N2OwYS7av+91eFvSng@mail.gmail.com>
Message-ID: <CAAcGz98nLecgUzoAkpFxynN4FNhQc-_+0ETa8U2u0=tKh36Q_Q@mail.gmail.com>

On Wed, 6 May 2015 at 03:28 Robert J. Hijmans <r.hijmans at gmail.com> wrote:

> Even better (renaming not necessary):
>
> x <-
> raster("E:/downloads/OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.he5",
> var='Data Fields/ChiSquaredOfFit', ncdf=TRUE)
>
> Best, Robert
>


But only if you build and install ncdf4 yourself (or use DP's one off-CRAN:
http://cirrus.ucsd.edu/~pierce/ncdf/)

There's no ncdf4 for Windows on CRAN.

Robert's solution doesn't work for me on Windows with ncdf (though I am
sure it it would if I build ncdf with NetCDF4).

(I feel like I've missed something here . . .)

Cheers, Mike.


>
> On Tue, May 5, 2015 at 10:24 AM, Robert J. Hijmans <r.hijmans at gmail.com>
> wrote:
> > In which case you can change the extension to '.nc' and do
> >
> > library(raster)
> > library(ncdf4)
> > x <- raster("E:/downloads/
> OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.nc",
> > var='Data Fields/ChiSquaredOfFit')
> >
> > Robert
> >
> > On Tue, May 5, 2015 at 5:28 AM, John Baumgartner <johnbaums at gmail.com>
> wrote:
> >> Not a remedy, but the following might be a workable alternative...
> >>
> >>
> ncdf4::nc_open("OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.he5")$var$`Data
> >> Fields/ChiSquaredOfFit`
> >>
> >> I'm not familiar with HDF5 structure, so not sure of possible downsides.
> >>
> >> Cheers,
> >> John
> >>
> >> On Tue, May 5, 2015 at 9:34 PM, Oscar Perpi?an <
> oscar.perpinan at gmail.com>
> >> wrote:
> >>
> >>> Hello,
> >>>
> >>> I am trying to read a HDF5 file whose variable name contains '//'. I
> have
> >>> no
> >>> problem in a Linux machine, but 'readGDAL' throws an error in Windows.
> If I
> >>> am not wrong, it is because the initialize method of the
> >>> 'GDALReadOnlyDataset'
> >>> class includes a call to 'normalizePath'.
> >>>
> >>> For example, the next code works in Linux but fails in Windows (it uses
> >>> this
> >>> file
> >>>
> >>>
> ftp://atrain.sci.gsfc.nasa.gov/data/s4pa//OMI/OMCLDO2_CPR.003/2015/125/OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.he5
> >>> )
> >>>
> >>> x <- readGDAL("HDF5:OMI.L2.CloudOMCLDO2Strip200kmAlongClo
> >>> udSat.2015.05.05.020752Z.v003.he5://HDFEOS/SWATHS/
> >>> CloudFractionAndPressure/Data_Fields/ChiSquaredOfFit")
> >>>
> >>> Is there any way to circumvent this problem?
> >>>
> >>> Thanks in advance.
> >>>
> >>> Oscar.
> >>> -----------------------------------------------------------------
> >>> Oscar Perpi??n Lamigueiro
> >>> Dpto. Ing. El?ctrica, Electr?nica, Autom?tica y F?sica Aplicada
> >>> (ETSIDI-UPM)
> >>> Grupo de Sistemas Fotovoltaicos (IES-UPM)
> >>> URL: http://oscarperpinan.github.io
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-Geo mailing list
> >>> R-sig-Geo at r-project.org
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>>
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at r-project.org
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From r.hijmans at gmail.com  Wed May  6 00:07:23 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 5 May 2015 15:07:23 -0700
Subject: [R-sig-Geo] Problem reading a HDF5 file with readGDAL in Windows
In-Reply-To: <CAAcGz98nLecgUzoAkpFxynN4FNhQc-_+0ETa8U2u0=tKh36Q_Q@mail.gmail.com>
References: <CAMLL7bnJbepHdXFRSA-gCcB=q5NZLCexUZhLx-QTWHhO28wkkg@mail.gmail.com>
	<CACpmSOsMWhL2AJyWaKJviAVhfqoQxLBx8krmgAw8TudB9uEV4A@mail.gmail.com>
	<CANtt_hz39G2KLP5aQ9uwHhC3qG81zVMne91X-=eSU6dHDd+uMg@mail.gmail.com>
	<CANtt_hwbg9u1aqtH18d299bnrt_Qkdb=N2OwYS7av+91eFvSng@mail.gmail.com>
	<CAAcGz98nLecgUzoAkpFxynN4FNhQc-_+0ETa8U2u0=tKh36Q_Q@mail.gmail.com>
Message-ID: <CANtt_hxz92yiWm6v-RrUabjKFOcBUYynfHGLNFt7wfBYBmQrHA@mail.gmail.com>

Yes, you need the ncdf4 package (apart from build your own options
that I would not generally recommend). That's why I explicitly did
`library(ncdf4)`. On windows that indeed means downloading it from
http://cirrus.ucsd.edu/~pierce/ncdf/ and unzipping the content to the
right folder ("install from local zip file" in Rgui). Just a tiny bit
of additional effort.

Robert

On Tue, May 5, 2015 at 2:20 PM, Michael Sumner <mdsumner at gmail.com> wrote:
>
>
> On Wed, 6 May 2015 at 03:28 Robert J. Hijmans <r.hijmans at gmail.com> wrote:
>>
>> Even better (renaming not necessary):
>>
>> x <-
>> raster("E:/downloads/OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.he5",
>> var='Data Fields/ChiSquaredOfFit', ncdf=TRUE)
>>
>> Best, Robert
>
>
>
> But only if you build and install ncdf4 yourself (or use DP's one off-CRAN:
> http://cirrus.ucsd.edu/~pierce/ncdf/)
>
> There's no ncdf4 for Windows on CRAN.
>
> Robert's solution doesn't work for me on Windows with ncdf (though I am sure
> it it would if I build ncdf with NetCDF4).
>
> (I feel like I've missed something here . . .)
>
> Cheers, Mike.
>
>>
>>
>> On Tue, May 5, 2015 at 10:24 AM, Robert J. Hijmans <r.hijmans at gmail.com>
>> wrote:
>> > In which case you can change the extension to '.nc' and do
>> >
>> > library(raster)
>> > library(ncdf4)
>> > x <-
>> > raster("E:/downloads/OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.nc",
>> > var='Data Fields/ChiSquaredOfFit')
>> >
>> > Robert
>> >
>> > On Tue, May 5, 2015 at 5:28 AM, John Baumgartner <johnbaums at gmail.com>
>> > wrote:
>> >> Not a remedy, but the following might be a workable alternative...
>> >>
>> >>
>> >> ncdf4::nc_open("OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.he5")$var$`Data
>> >> Fields/ChiSquaredOfFit`
>> >>
>> >> I'm not familiar with HDF5 structure, so not sure of possible
>> >> downsides.
>> >>
>> >> Cheers,
>> >> John
>> >>
>> >> On Tue, May 5, 2015 at 9:34 PM, Oscar Perpi?an
>> >> <oscar.perpinan at gmail.com>
>> >> wrote:
>> >>
>> >>> Hello,
>> >>>
>> >>> I am trying to read a HDF5 file whose variable name contains '//'. I
>> >>> have
>> >>> no
>> >>> problem in a Linux machine, but 'readGDAL' throws an error in Windows.
>> >>> If I
>> >>> am not wrong, it is because the initialize method of the
>> >>> 'GDALReadOnlyDataset'
>> >>> class includes a call to 'normalizePath'.
>> >>>
>> >>> For example, the next code works in Linux but fails in Windows (it
>> >>> uses
>> >>> this
>> >>> file
>> >>>
>> >>>
>> >>> ftp://atrain.sci.gsfc.nasa.gov/data/s4pa//OMI/OMCLDO2_CPR.003/2015/125/OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.he5
>> >>> )
>> >>>
>> >>> x <- readGDAL("HDF5:OMI.L2.CloudOMCLDO2Strip200kmAlongClo
>> >>> udSat.2015.05.05.020752Z.v003.he5://HDFEOS/SWATHS/
>> >>> CloudFractionAndPressure/Data_Fields/ChiSquaredOfFit")
>> >>>
>> >>> Is there any way to circumvent this problem?
>> >>>
>> >>> Thanks in advance.
>> >>>
>> >>> Oscar.
>> >>> -----------------------------------------------------------------
>> >>> Oscar Perpi??n Lamigueiro
>> >>> Dpto. Ing. El?ctrica, Electr?nica, Autom?tica y F?sica Aplicada
>> >>> (ETSIDI-UPM)
>> >>> Grupo de Sistemas Fotovoltaicos (IES-UPM)
>> >>> URL: http://oscarperpinan.github.io
>> >>>
>> >>>         [[alternative HTML version deleted]]
>> >>>
>> >>> _______________________________________________
>> >>> R-sig-Geo mailing list
>> >>> R-sig-Geo at r-project.org
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >>>
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> _______________________________________________
>> >> R-sig-Geo mailing list
>> >> R-sig-Geo at r-project.org
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From thi_veloso at yahoo.com.br  Wed May  6 03:48:32 2015
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Wed, 6 May 2015 01:48:32 +0000 (UTC)
Subject: [R-sig-Geo] Faster way to get raster average?
Message-ID: <673401754.791703.1430876912015.JavaMail.yahoo@mail.yahoo.com>

Hi all,
I am working with some terabytes of CMIP5 climate files.?Each file is a netcdf with multiple layers (timesteps) representing monthly data.?
For each file, I need to extract the average value of the raster and put all values in a data frame. This is my current approach:---------------
library(raster)
# make up some datacmip <- brick(nc=150, nr=114, nl=1872)cmip <- setValues(cmip, matrix(rep(1:17100, 1872), nc=1872))
# get mean values (area average) as data framescmip.mean <- as.data.frame(cellStats(cmip, mean, na.rm=T))---------------
which works pretty fast in this example:
> system.time(as.data.frame(cellStats(cmip, mean, na.rm=T)))
   user  system elapsed 
  0.069   0.012   0.081 
However, the calculation with my actual data is substantially slower:
> system.time(as.data.frame(cellStats(cmip, mean, na.rm=T)))
   user  system elapsed 
  4.600   1.105   5.704 
Since I will have to deal with thousands of files, here comes my question: is there a faster way to get a the average value of a?raster???
Many thanks,
--
Thiago V. dos Santos
PhD student
Land and Atmospheric Science
University of Minnesota
http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
Phone: (612) 323 9898
	[[alternative HTML version deleted]]


From thi_veloso at yahoo.com.br  Wed May  6 04:08:04 2015
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Wed, 6 May 2015 02:08:04 +0000 (UTC)
Subject: [R-sig-Geo] Faster way to get raster average?
In-Reply-To: <673401754.791703.1430876912015.JavaMail.yahoo@mail.yahoo.com>
References: <673401754.791703.1430876912015.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <903060401.795226.1430878084649.JavaMail.yahoo@mail.yahoo.com>

Oh, I forgot to mention that I work on a quad-core Mac with 12GB.
So, if multi-core can potentially accelerate cellStats, or whatever function is faster to get a raster average, I would be glad to see some examples on how to implement it.?Greetings,
--
Thiago V. dos Santos
PhD student
Land and Atmospheric Science
University of Minnesota
http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
Phone: (612) 323 9898 


     On Tuesday, May 5, 2015 8:48 PM, Thiago V. dos Santos <thi_veloso at yahoo.com.br> wrote:
   

 Hi all,
I am working with some terabytes of CMIP5 climate files.?Each file is a netcdf with multiple layers (timesteps) representing monthly data.?
For each file, I need to extract the average value of the raster and put all values in a data frame. This is my current approach:---------------
library(raster)
# make up some datacmip <- brick(nc=150, nr=114, nl=1872)cmip <- setValues(cmip, matrix(rep(1:17100, 1872), nc=1872))
# get mean values (area average) as data framescmip.mean <- as.data.frame(cellStats(cmip, mean, na.rm=T))---------------
which works pretty fast in this example:
> system.time(as.data.frame(cellStats(cmip, mean, na.rm=T)))
? user? system elapsed 
? 0.069? 0.012? 0.081 
However, the calculation with my actual data is substantially slower:
> system.time(as.data.frame(cellStats(cmip, mean, na.rm=T)))
? user? system elapsed 
? 4.600? 1.105? 5.704 
Since I will have to deal with thousands of files, here comes my question: is there a faster way to get a the average value of a?raster???
Many thanks,
--
Thiago V. dos Santos
PhD student
Land and Atmospheric Science
University of Minnesota
http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
Phone: (612) 323 9898
??? [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


  
	[[alternative HTML version deleted]]


From giuseppe.amatulli at gmail.com  Wed May  6 04:55:23 2015
From: giuseppe.amatulli at gmail.com (Giuseppe Amatulli)
Date: Tue, 5 May 2015 22:55:23 -0400
Subject: [R-sig-Geo] Fwd: Summer school: SPATIO-TEMPORAL ANALYSIS AND BIG
 DATA PROCESSING USING FREE AND OPEN SOURCE SOFTWARE
In-Reply-To: <CAKoiDHKEYTdLfFcAB2YeZAMvS9HsNMeLk0OCk8+6T=FWxfagWg@mail.gmail.com>
References: <CAKoiDHKEYTdLfFcAB2YeZAMvS9HsNMeLk0OCk8+6T=FWxfagWg@mail.gmail.com>
Message-ID: <CAKoiDHKXMXHbSj_HZRO0Mr-FVPbBPMXvzvmUhxL_QJ8qKQHoGA@mail.gmail.com>

HI,
Apologies for cross-posting:

*spatial-ecology* in collaboration with Department of Ecology, Evolution,
and Marine Biology <https://www.eemb.ucsb.edu/> at University of
California, Santa Barbara <http://www.ucsb.edu/> is organizing a Summer
school

*Summer school: SPATIO-TEMPORAL ANALYSIS AND BIG DATA PROCESSING USING FREE
AND OPEN SOURCE SOFTWARE *(basic and advanced levels)

Over the last few decades there has been an explosion in the availability
of data for environmental research, and in particular for spatio-temporal
analysis. We are now able to address a number of important questions, both
new and old, with unprecedented rigor and generality. Leveraging these
exciting new data streams requires tools and increasingly complex
workflows. This 6-day course introduces a set of free and open source
software (BASH, AWK ,GDAL, GRASS, R, Python, PKTOOLS, OFGT) to perform
spatio-temporal analysis and modelling of environmental data in a Linux
environment. We also introduce multi-core, cloud and cluster computation
procedures using High Performance Computing - Amazon Web Services. The
course consists of a set of lectures and practical hands-on sessions in
which participants perform spatial and temporal analysis using Geographic
Information System and Remote Sensing concepts. Although courses focuses on
the command line instead of the graphical user interface, *no prior
experience with programming or command line interfaces is assumed or
required*. To cater to students with prior programming experience, we will
hold parallel sessions that introduce more advanced material (e.g. parallel
processing) . Our main focus is on teaching self learning and problem
solving more than the use of specific tools (see: our teaching method
<http://www.spatial-ecology.net/giuseppe/publications/Amatulli_et_al_OGRS.pdf>
) so participants will be able to progress and adapt to learn the newest
available data science techniques.

*Dates/Location: 16-17-20-21-22 of July / Santa Barbara
<https://www.google.com/maps/place/University+of+California,+Santa+Barbara/@34.413963,-119.848947,14z/data=%214m2%213m1%211s0x0:0x4e956b7e5cb6cec2>
- USA California.*

Registration & info at www.spatial-ecology.net
<http://www.spatial-ecology.net/dokuwiki/doku.php?id=wiki:upcomingSantBab>

-- 
Giuseppe Amatulli, Ph.D.

Department of Ecology and Evolutionary Biology, Yale University.
Jetz Lab, OML Room 405

P.O. Box 208106
165 PROSPECT ST
New Haven, CT 06520-8106
Teaching: spatial-ecology.net
Work:  http://sbsc.yale.edu/giuseppe-amatulli
<http://www.spatial-ecology.net>



-- 
Giuseppe Amatulli, Ph.D.

Department of Ecology and Evolutionary Biology, Yale University.
Jetz Lab, OML Room 405

P.O. Box 208106
165 PROSPECT ST
New Haven, CT 06520-8106
Teaching: spatial-ecology.net
Work:  http://sbsc.yale.edu/giuseppe-amatulli
<http://www.spatial-ecology.net>

	[[alternative HTML version deleted]]


From r.hijmans at gmail.com  Wed May  6 06:27:45 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 5 May 2015 21:27:45 -0700
Subject: [R-sig-Geo] Faster way to get raster average?
In-Reply-To: <673401754.791703.1430876912015.JavaMail.yahoo@mail.yahoo.com>
References: <673401754.791703.1430876912015.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CANtt_hz0nEXsqCxVOUbffNMak6_R+WgjjRG77GZHY8cpHagaEw@mail.gmail.com>

This suggest that most of the time is spend on reading data from disk.
It could be more efficient to do this in one step.

m <- .colMeans(getValues(cmip), nrow(cmip), ncol(cmip), na.rm=FALSE)

I do not think there is much more you can do beyond that --- although
a solid state hard disk could help.

( I am guessing that na.rm=FALSE is tiny bit faster, and that you do
not need it to be TRUE. )

Robert

On Tue, May 5, 2015 at 6:48 PM, Thiago V. dos Santos
<thi_veloso at yahoo.com.br> wrote:
> Hi all,
> I am working with some terabytes of CMIP5 climate files. Each file is a netcdf with multiple layers (timesteps) representing monthly data.
> For each file, I need to extract the average value of the raster and put all values in a data frame. This is my current approach:---------------
> library(raster)
> # make up some datacmip <- brick(nc=150, nr=114, nl=1872)cmip <- setValues(cmip, matrix(rep(1:17100, 1872), nc=1872))
> # get mean values (area average) as data framescmip.mean <- as.data.frame(cellStats(cmip, mean, na.rm=T))---------------
> which works pretty fast in this example:
>> system.time(as.data.frame(cellStats(cmip, mean, na.rm=T)))
>    user  system elapsed
>   0.069   0.012   0.081
> However, the calculation with my actual data is substantially slower:
>> system.time(as.data.frame(cellStats(cmip, mean, na.rm=T)))
>    user  system elapsed
>   4.600   1.105   5.704
> Since I will have to deal with thousands of files, here comes my question: is there a faster way to get a the average value of a raster ?
> Many thanks,
> --
> Thiago V. dos Santos
> PhD student
> Land and Atmospheric Science
> University of Minnesota
> http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
> Phone: (612) 323 9898
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From kmb56 at berkeley.edu  Wed May  6 06:49:15 2015
From: kmb56 at berkeley.edu (Kenny Bell)
Date: Tue, 5 May 2015 21:49:15 -0700
Subject: [R-sig-Geo] Faster way to get raster average?
In-Reply-To: <CANtt_hz0nEXsqCxVOUbffNMak6_R+WgjjRG77GZHY8cpHagaEw@mail.gmail.com>
References: <673401754.791703.1430876912015.JavaMail.yahoo@mail.yahoo.com>
	<CANtt_hz0nEXsqCxVOUbffNMak6_R+WgjjRG77GZHY8cpHagaEw@mail.gmail.com>
Message-ID: <CALOjXYRP4WY_cKdrJs3ku6PtW1izVxegv=JPtBuNBixs50gM0Q@mail.gmail.com>

You could also try out RRO with MKL
<http://mran.revolutionanalytics.com/download/#download>, which I have
found speeds up some basic computations on multicore machines.

On Tue, May 5, 2015 at 9:27 PM, Robert J. Hijmans <r.hijmans at gmail.com>
wrote:

> This suggest that most of the time is spend on reading data from disk.
> It could be more efficient to do this in one step.
>
> m <- .colMeans(getValues(cmip), nrow(cmip), ncol(cmip), na.rm=FALSE)
>
> I do not think there is much more you can do beyond that --- although
> a solid state hard disk could help.
>
> ( I am guessing that na.rm=FALSE is tiny bit faster, and that you do
> not need it to be TRUE. )
>
> Robert
>
> On Tue, May 5, 2015 at 6:48 PM, Thiago V. dos Santos
> <thi_veloso at yahoo.com.br> wrote:
> > Hi all,
> > I am working with some terabytes of CMIP5 climate files. Each file is a
> netcdf with multiple layers (timesteps) representing monthly data.
> > For each file, I need to extract the average value of the raster and put
> all values in a data frame. This is my current approach:---------------
> > library(raster)
> > # make up some datacmip <- brick(nc=150, nr=114, nl=1872)cmip <-
> setValues(cmip, matrix(rep(1:17100, 1872), nc=1872))
> > # get mean values (area average) as data framescmip.mean <-
> as.data.frame(cellStats(cmip, mean, na.rm=T))---------------
> > which works pretty fast in this example:
> >> system.time(as.data.frame(cellStats(cmip, mean, na.rm=T)))
> >    user  system elapsed
> >   0.069   0.012   0.081
> > However, the calculation with my actual data is substantially slower:
> >> system.time(as.data.frame(cellStats(cmip, mean, na.rm=T)))
> >    user  system elapsed
> >   4.600   1.105   5.704
> > Since I will have to deal with thousands of files, here comes my
> question: is there a faster way to get a the average value of a raster ?
> > Many thanks,
> > --
> > Thiago V. dos Santos
> > PhD student
> > Land and Atmospheric Science
> > University of Minnesota
> >
> http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
> > Phone: (612) 323 9898
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Kendon Bell
Email: kmb56 at berkeley.edu
Phone: (510) 612-3375

Ph.D. Student
Department of Agricultural & Resource Economics
University of California, Berkeley

Graduate Student Researcher
Energy Biosciences Institute
http://www.energybiosciencesinstitute.org/

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Wed May  6 07:22:29 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 06 May 2015 05:22:29 +0000
Subject: [R-sig-Geo] Faster way to get raster average?
In-Reply-To: <CANtt_hz0nEXsqCxVOUbffNMak6_R+WgjjRG77GZHY8cpHagaEw@mail.gmail.com>
References: <673401754.791703.1430876912015.JavaMail.yahoo@mail.yahoo.com>
	<CANtt_hz0nEXsqCxVOUbffNMak6_R+WgjjRG77GZHY8cpHagaEw@mail.gmail.com>
Message-ID: <CAAcGz99Z7CVN6TRxbkG2LOMPgR41cJ=sE7+MZnuORiD8thZPmQ@mail.gmail.com>

Sometimes it can be best to use the NetCDF tools more directly, you can
approach the speed of the already in memory case by slurping in the array
and reshaping to a matrix (like Robert's example, but I think my row/col
specification is correct):

library(raster)
cmip <- brick(nc=150, nr=114, nl=1872)
cmip <- setValues(cmip, matrix(rep(1:17100, 1872), nc=1872))
writeRaster(cmip, "example.nc")

 ## in memory from our example
 system.time(r1 <- cellStats(cmip, mean, na.rm = TRUE))
#   user  system elapsed
#   0.08    0.00    0.07
## from disk
 cmipdisk <- brick("example.nc")
 system.time(r2 <- cellStats(cmipdisk, mean, na.rm = TRUE))
#   user  system elapsed
#   4.89    0.34    5.24
## in memory, but from disk (so yes we are IO-bound)
system.time(r3 <- .colMeans(getValues(cmipdisk), nrow(cmipdisk) *
ncol(cmipdisk), nlayers(cmipdisk), na.rm=TRUE))
#   user  system elapsed
#   4.71    0.31    5.03

## avoid raster completely is faster, even with apply
system.time(r4 <- apply(get.var.ncdf(open.ncdf("example.nc"), "variable"),
3, mean, na.rm = TRUE))
#   user  system elapsed
#  2.56    0.19    2.75
#
## reshape to avoid apply (second fastest to already in memory)
system.time(r5 <- .colMeans(matrix(get.var.ncdf(open.ncdf("example.nc"),
"variable"), nrow = prod(dim(cmip)[1:2])), nrow(cmipdisk) *
 ncol(cmipdisk), nlayers(cmipdisk), na.rm=FALSE))
#   user  system elapsed
#   1.25    0.10    1.36
#
 max(abs(r1 - r2))
#[1] 0
max(abs(r2 - r3))
#[1] 0
max(abs(r3 - r4))
#[1] 0
max(abs(r4 - r5))
#[1] 0


You can replace ncdf with ncdf4 or RNetCDF with a slight change of
open/getvar functions.

Cheers, Mike.

On Wed, 6 May 2015 at 14:28 Robert J. Hijmans <r.hijmans at gmail.com> wrote:

> This suggest that most of the time is spend on reading data from disk.
> It could be more efficient to do this in one step.
>
> m <- .colMeans(getValues(cmip), nrow(cmip), ncol(cmip), na.rm=FALSE)
>
> I do not think there is much more you can do beyond that --- although
> a solid state hard disk could help.
>
> ( I am guessing that na.rm=FALSE is tiny bit faster, and that you do
> not need it to be TRUE. )
>
> Robert
>
> On Tue, May 5, 2015 at 6:48 PM, Thiago V. dos Santos
> <thi_veloso at yahoo.com.br> wrote:
> > Hi all,
> > I am working with some terabytes of CMIP5 climate files. Each file is a
> netcdf with multiple layers (timesteps) representing monthly data.
> > For each file, I need to extract the average value of the raster and put
> all values in a data frame. This is my current approach:---------------
> > library(raster)
> > # make up some datacmip <- brick(nc=150, nr=114, nl=1872)cmip <-
> setValues(cmip, matrix(rep(1:17100, 1872), nc=1872))
> > # get mean values (area average) as data framescmip.mean <-
> as.data.frame(cellStats(cmip, mean, na.rm=T))---------------
> > which works pretty fast in this example:
> >> system.time(as.data.frame(cellStats(cmip, mean, na.rm=T)))
> >    user  system elapsed
> >   0.069   0.012   0.081
> > However, the calculation with my actual data is substantially slower:
> >> system.time(as.data.frame(cellStats(cmip, mean, na.rm=T)))
> >    user  system elapsed
> >   4.600   1.105   5.704
> > Since I will have to deal with thousands of files, here comes my
> question: is there a faster way to get a the average value of a raster ?
> > Many thanks,
> > --
> > Thiago V. dos Santos
> > PhD student
> > Land and Atmospheric Science
> > University of Minnesota
> >
> http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
> > Phone: (612) 323 9898
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From oscar.perpinan at gmail.com  Wed May  6 07:44:31 2015
From: oscar.perpinan at gmail.com (=?UTF-8?Q?Oscar_Perpi=C3=B1an?=)
Date: Wed, 6 May 2015 07:44:31 +0200
Subject: [R-sig-Geo] Problem reading a HDF5 file with readGDAL in Windows
In-Reply-To: <CAAcGz99yW13Q9PTRbd+SX+z3RsyRG=tofwiUnCFTqcfJ2XkMhw@mail.gmail.com>
References: <CAMLL7bnJbepHdXFRSA-gCcB=q5NZLCexUZhLx-QTWHhO28wkkg@mail.gmail.com>
	<CAAcGz99yW13Q9PTRbd+SX+z3RsyRG=tofwiUnCFTqcfJ2XkMhw@mail.gmail.com>
Message-ID: <CAMLL7b=0PvcndyMOf3JybQOnqYdkxiBn4kG86Z0XXFt2KsAh7g@mail.gmail.com>

Hi,


> Are you sure you have the HDF5 driver in Windows?  Do you build yourself
> against your own GDAL or against OSGeo4W?  (It's not in the CRAN
> windows-build).
>

I will check it later.

This is the error the CRAN build gives (though it's actually not
> recognizing the driver):
>
> "... does not exist in the file system, and is not recognised as a
> supported dataset name."
>

Exactly. And if I run traceback() after it, I find that it's the
'GDAL.open' function that is giving the error. In the error message I see
that the 'normalizePath' function is changing the variable name. For
example, if I use a file with a variable named "//DSSF", it gives:
"C:\Users\xxxx\AppData\Local\Temp\RtmpsD81tO\HDF5:201407291200:\DSSF"

Thanks

Oscar.

	[[alternative HTML version deleted]]


From oscar.perpinan at gmail.com  Wed May  6 07:53:16 2015
From: oscar.perpinan at gmail.com (=?UTF-8?Q?Oscar_Perpi=C3=B1an?=)
Date: Wed, 6 May 2015 07:53:16 +0200
Subject: [R-sig-Geo] Problem reading a HDF5 file with readGDAL in Windows
In-Reply-To: <CANtt_hwbg9u1aqtH18d299bnrt_Qkdb=N2OwYS7av+91eFvSng@mail.gmail.com>
References: <CAMLL7bnJbepHdXFRSA-gCcB=q5NZLCexUZhLx-QTWHhO28wkkg@mail.gmail.com>
	<CACpmSOsMWhL2AJyWaKJviAVhfqoQxLBx8krmgAw8TudB9uEV4A@mail.gmail.com>
	<CANtt_hz39G2KLP5aQ9uwHhC3qG81zVMne91X-=eSU6dHDd+uMg@mail.gmail.com>
	<CANtt_hwbg9u1aqtH18d299bnrt_Qkdb=N2OwYS7av+91eFvSng@mail.gmail.com>
Message-ID: <CAMLL7bknDfLL0ypNDsoNE+2wQrBbKOJ-Dcr6J4ZxkbpC8WTkNQ@mail.gmail.com>

>
> Even better (renaming not necessary):
>
> x <-
> raster("E:/downloads/OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.he5",
> var='Data Fields/ChiSquaredOfFit', ncdf=TRUE)
> >> Not a remedy, but the following might be a workable alternative...
> >>
> >>
> ncdf4::nc_open("OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.he5")$var$`Data
> >> Fields/ChiSquaredOfFit`
>

Thanks. It works with the file of the example. But it fails with this one
(even on a Linux machine):
https://www.dropbox.com/s/3zmhbtcpf7ly4nw/201407291200

> x <- raster('201407291200', var = 'DSSF', ncdf = TRUE)
Error in R_nc4_open: NetCDF: Can't open HDF5 attribute
....
> x <- raster('201407291200', var = '//DSSF', ncdf = TRUE)
Error in R_nc4_open: NetCDF: Can't open HDF5 attribute
....

However, I can open this file in Linux with:

x <- readGDAL('HDF5:201407291200://DSSF')

Best,

Oscar.

	[[alternative HTML version deleted]]


From r.hijmans at gmail.com  Wed May  6 08:06:02 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 5 May 2015 23:06:02 -0700
Subject: [R-sig-Geo] Problem reading a HDF5 file with readGDAL in Windows
In-Reply-To: <CAMLL7bknDfLL0ypNDsoNE+2wQrBbKOJ-Dcr6J4ZxkbpC8WTkNQ@mail.gmail.com>
References: <CAMLL7bnJbepHdXFRSA-gCcB=q5NZLCexUZhLx-QTWHhO28wkkg@mail.gmail.com>
	<CACpmSOsMWhL2AJyWaKJviAVhfqoQxLBx8krmgAw8TudB9uEV4A@mail.gmail.com>
	<CANtt_hz39G2KLP5aQ9uwHhC3qG81zVMne91X-=eSU6dHDd+uMg@mail.gmail.com>
	<CANtt_hwbg9u1aqtH18d299bnrt_Qkdb=N2OwYS7av+91eFvSng@mail.gmail.com>
	<CAMLL7bknDfLL0ypNDsoNE+2wQrBbKOJ-Dcr6J4ZxkbpC8WTkNQ@mail.gmail.com>
Message-ID: <CANtt_hyDtBy3Tkdvy_6Je0puAkS+QrBs6tt9oUtPAw-HA6DZwA@mail.gmail.com>

It works for me. I get:


> library(raster)
Loading required package: sp
> library(ncdf4)

> raster("E:/downloads/201407291200", ncdf=T, varname='DSSF')
class       : RasterLayer
dimensions  : 651, 1701, 1107351  (nrow, ncol, ncell)
resolution  : 1, 1  (x, y)
extent      : 0.5, 1701.5, 0.5, 651.5  (xmin, xmax, ymin, ymax)
coord. ref. : NA
data source : E:\downloads\201407291200
names       : DSSF
zvar        : DSSF


> sessionInfo()
R version 3.2.0 RC (2015-04-08 r68161)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252    LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                           LC_TIME=English_United
States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] ncdf4_1.12    raster_2.3-41 sp_1.0-17

loaded via a namespace (and not attached):
[1] grid_3.2.0      lattice_0.20-31
>


On Tue, May 5, 2015 at 10:53 PM, Oscar Perpi?an
<oscar.perpinan at gmail.com> wrote:
>> Even better (renaming not necessary):
>>
>> x <-
>> raster("E:/downloads/OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.he5",
>> var='Data Fields/ChiSquaredOfFit', ncdf=TRUE)
>> >> Not a remedy, but the following might be a workable alternative...
>> >>
>> >>
>> >> ncdf4::nc_open("OMI.L2.CloudOMCLDO2Strip200kmAlongCloudSat.2015.05.05.020752Z.v003.he5")$var$`Data
>> >> Fields/ChiSquaredOfFit`
>
>
> Thanks. It works with the file of the example. But it fails with this one
> (even on a Linux machine):
> https://www.dropbox.com/s/3zmhbtcpf7ly4nw/201407291200
>
>> x <- raster('201407291200', var = 'DSSF', ncdf = TRUE)
> Error in R_nc4_open: NetCDF: Can't open HDF5 attribute
> ....
>> x <- raster('201407291200', var = '//DSSF', ncdf = TRUE)
> Error in R_nc4_open: NetCDF: Can't open HDF5 attribute
> ....
>
> However, I can open this file in Linux with:
>
> x <- readGDAL('HDF5:201407291200://DSSF')
>
> Best,
>
> Oscar.


From oscar.perpinan at gmail.com  Wed May  6 08:22:12 2015
From: oscar.perpinan at gmail.com (=?UTF-8?Q?Oscar_Perpi=C3=B1an?=)
Date: Wed, 6 May 2015 08:22:12 +0200
Subject: [R-sig-Geo] Problem reading a HDF5 file with readGDAL in Windows
In-Reply-To: <CANtt_hyDtBy3Tkdvy_6Je0puAkS+QrBs6tt9oUtPAw-HA6DZwA@mail.gmail.com>
References: <CAMLL7bnJbepHdXFRSA-gCcB=q5NZLCexUZhLx-QTWHhO28wkkg@mail.gmail.com>
	<CACpmSOsMWhL2AJyWaKJviAVhfqoQxLBx8krmgAw8TudB9uEV4A@mail.gmail.com>
	<CANtt_hz39G2KLP5aQ9uwHhC3qG81zVMne91X-=eSU6dHDd+uMg@mail.gmail.com>
	<CANtt_hwbg9u1aqtH18d299bnrt_Qkdb=N2OwYS7av+91eFvSng@mail.gmail.com>
	<CAMLL7bknDfLL0ypNDsoNE+2wQrBbKOJ-Dcr6J4ZxkbpC8WTkNQ@mail.gmail.com>
	<CANtt_hyDtBy3Tkdvy_6Je0puAkS+QrBs6tt9oUtPAw-HA6DZwA@mail.gmail.com>
Message-ID: <CAMLL7bkvgaW3QxHX0DWJGtKvyjrCnXQz3CcpJJz1AovwC3NA5Q@mail.gmail.com>

Not for me, and I cannot understand why:

> r <- raster("~/Dropbox/share/201407291200", ncdf=T, varname='DSSF')
Error in R_nc4_open: NetCDF: Can't open HDF5 attribute
Error in ncdf4::nc_open(filename) :
  Error in nc_open trying to open file
/home/oscar/Dropbox/share/201407291200
> sessionInfo()
R version 3.2.0 (2015-04-16)
Platform: i586-pc-linux-gnu (32-bit)
Running under: Debian GNU/Linux 8 (jessie)

locale:
 [1] LC_CTYPE=es_ES.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=es_ES.UTF-8        LC_COLLATE=es_ES.UTF-8
 [5] LC_MONETARY=es_ES.UTF-8    LC_MESSAGES=es_ES.UTF-8
 [7] LC_PAPER=es_ES.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=es_ES.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] ncdf4_1.13    raster_2.3-40 sp_1.0-14

loaded via a namespace (and not attached):
[1] compiler_3.2.0  tools_3.2.0     grid_3.2.0      lattice_0.20-27

	[[alternative HTML version deleted]]


From Rainer at krugs.de  Wed May  6 10:00:09 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Wed, 06 May 2015 10:00:09 +0200
Subject: [R-sig-Geo] Faster way to get raster average?
In-Reply-To: <673401754.791703.1430876912015.JavaMail.yahoo@mail.yahoo.com>
	(Thiago V. dos Santos's message of "Wed, 6 May 2015 01:48:32 +0000
	(UTC)")
References: <673401754.791703.1430876912015.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <m2lhh29lva.fsf@krugs.de>

"Thiago V. dos Santos" <thi_veloso at yahoo.com.br> writes:

> Hi all,
> I am working with some terabytes of CMIP5 climate files.?Each file is
> a netcdf with multiple layers (timesteps) representing monthly data.?
> For each file, I need to extract the average value of the raster and
> put all values in a data frame. This is my current
> approach:---------------
> library(raster)
> # make up some datacmip <- brick(nc=150, nr=114, nl=1872)cmip <- setValues(cmip, matrix(rep(1:17100, 1872), nc=1872))
> # get mean values (area average) as data framescmip.mean <- as.data.frame(cellStats(cmip, mean, na.rm=T))---------------
> which works pretty fast in this example:
>> system.time(as.data.frame(cellStats(cmip, mean, na.rm=T)))
>    user  system elapsed 
>   0.069   0.012   0.081 
> However, the calculation with my actual data is substantially slower:
>> system.time(as.data.frame(cellStats(cmip, mean, na.rm=T)))
>    user  system elapsed 
>   4.600   1.105   5.704 
> Since I will have to deal with thousands of files, here comes my question: is there a faster way to get a the average value of a?raster???

I am not an expert on netcdf files, but I would probably look outside R
to do these calculations. GRASS, and possibly even gdal, come to
mind. Depending on how often you have to do the calculations, putting
them into a spatial database and do the calculations there might be an
option?

Concerning paralelization: if, as Robert points out, the disk access is
the bottleneck (memory allocation in R will also take some time,
depending on the size of the individual map), paralelization will not
speed up (possibly even slow it down). In this case, your option is an
SSD, or a raid, and, as you are using a Mac, an internal or Thunderbolt
raid (all faster then even USB 3) - and definitely not an USB 2.0 HDD.

Otherwise, just using mcapply() over all maps would help.

Cheers,

Rainer


> Many thanks,
> --
> Thiago V. dos Santos
> PhD student
> Land and Atmospheric Science
> University of Minnesota
> http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
> Phone: (612) 323 9898
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 494 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150506/2f4d3235/attachment.bin>

From Rainer at krugs.de  Wed May  6 10:02:49 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Wed, 06 May 2015 10:02:49 +0200
Subject: [R-sig-Geo] Faster way to get raster average?
In-Reply-To: <903060401.795226.1430878084649.JavaMail.yahoo@mail.yahoo.com>
	(Thiago V. dos Santos's message of "Wed, 6 May 2015 02:08:04 +0000
	(UTC)")
References: <673401754.791703.1430876912015.JavaMail.yahoo@mail.yahoo.com>
	<903060401.795226.1430878084649.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <m2h9rq9lqu.fsf@krugs.de>

"Thiago V. dos Santos" <thi_veloso at yahoo.com.br> writes:

> Oh, I forgot to mention that I work on a quad-core Mac with 12GB.

> So, if multi-core can potentially accelerate cellStats, or whatever
> function is faster to get a raster average, I would be glad to see
> some examples on how to implement it.?Greetings,

The key question is: how often do you have to do the calculations and if
it would be feasible to just let them run for a few days and be done
with it - optimization takes time!

Cheers,

Rainer

> --
> Thiago V. dos Santos
> PhD student
> Land and Atmospheric Science
> University of Minnesota
> http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
> Phone: (612) 323 9898 
>
>
>      On Tuesday, May 5, 2015 8:48 PM, Thiago V. dos Santos <thi_veloso at yahoo.com.br> wrote:
>    
>
>  Hi all,
> I am working with some terabytes of CMIP5 climate files.?Each file is a netcdf with multiple layers (timesteps) representing monthly data.?
> For each file, I need to extract the average value of the raster and put all values in a data frame. This is my current approach:---------------
> library(raster)
> # make up some datacmip <- brick(nc=150, nr=114, nl=1872)cmip <- setValues(cmip, matrix(rep(1:17100, 1872), nc=1872))
> # get mean values (area average) as data framescmip.mean <- as.data.frame(cellStats(cmip, mean, na.rm=T))---------------
> which works pretty fast in this example:
>> system.time(as.data.frame(cellStats(cmip, mean, na.rm=T)))
> ? user? system elapsed 
> ? 0.069? 0.012? 0.081 
> However, the calculation with my actual data is substantially slower:
>> system.time(as.data.frame(cellStats(cmip, mean, na.rm=T)))
> ? user? system elapsed 
> ? 4.600? 1.105? 5.704 
> Since I will have to deal with thousands of files, here comes my
> question: is there a faster way to get a the average value of
> a?raster???
> Many thanks,
> --
> Thiago V. dos Santos
> PhD student
> Land and Atmospheric Science
> University of Minnesota
> http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
> Phone: (612) 323 9898
> ??? [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>   
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 494 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150506/faaf01b9/attachment.bin>

From nessnjor at gmail.com  Wed May  6 12:19:42 2015
From: nessnjor at gmail.com (Kristin)
Date: Wed, 6 May 2015 03:19:42 -0700 (MST)
Subject: [R-sig-Geo] Predict gam in a loop on multiple raster stacks and
 keeping identical layer names
In-Reply-To: <CANtt_hyL-ME5_BLwFk_kwkeVpu++EpfDNe-3gcY9AZh=cjnkbA@mail.gmail.com>
References: <1430841299362-7588176.post@n2.nabble.com>
	<CANtt_hyL-ME5_BLwFk_kwkeVpu++EpfDNe-3gcY9AZh=cjnkbA@mail.gmail.com>
Message-ID: <1430907582844-7588198.post@n2.nabble.com>

Thank you very much for the help Robert!
Works wonders. 
-Such a simple addition to the loop to fix the naming of layers :). 
This raster package is so brilliant. 
atb, Kristin



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Predict-gam-in-a-loop-on-multiple-raster-stacks-and-keeping-identical-layer-names-tp7588176p7588198.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From bymanh at gmail.com  Wed May  6 13:56:10 2015
From: bymanh at gmail.com (Byman HIkanyona)
Date: Wed, 6 May 2015 13:56:10 +0200
Subject: [R-sig-Geo] Faster way to get raster average?
In-Reply-To: <m2h9rq9lqu.fsf@krugs.de>
References: <673401754.791703.1430876912015.JavaMail.yahoo@mail.yahoo.com>
	<903060401.795226.1430878084649.JavaMail.yahoo@mail.yahoo.com>
	<m2h9rq9lqu.fsf@krugs.de>
Message-ID: <CAF2H4=ZFSXT27EXNZPnLK5EZRLmfMGDG4Mx_DjSbKBMobQp_Ag@mail.gmail.com>

Hi,

My approach, in brief, is similar to what Micheal  Summer suggested, i.e
using the netcdf tools (CDO, NCO, etc.). Whether in Linux, Mac,or windows.
these tools run more efficiently - memory use and speed. I sometimes use R
to automate the run since most are run on (DOS prompt like environment,
batch). You can also 'pipe' the operation for example in CDO to avoid
saving extra files. For example (CDO - windows) '*R* CMD BATCH cdo ensmean
ifile[1-100] ofile'  computes the ensemble mean of 100 files listed and
saves the result in output file, which you can read using Raster packages. I
don't know if this helps.

Cheers, Byman

On Wed, May 6, 2015 at 10:02 AM, Rainer M Krug <Rainer at krugs.de> wrote:

> "Thiago V. dos Santos" <thi_veloso at yahoo.com.br> writes:
>
> > Oh, I forgot to mention that I work on a quad-core Mac with 12GB.
>
> > So, if multi-core can potentially accelerate cellStats, or whatever
> > function is faster to get a raster average, I would be glad to see
> > some examples on how to implement it. Greetings,
>
> The key question is: how often do you have to do the calculations and if
> it would be feasible to just let them run for a few days and be done
> with it - optimization takes time!
>
> Cheers,
>
> Rainer
>
> > --
> > Thiago V. dos Santos
> > PhD student
> > Land and Atmospheric Science
> > University of Minnesota
> >
> http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
> > Phone: (612) 323 9898
> >
> >
> >      On Tuesday, May 5, 2015 8:48 PM, Thiago V. dos Santos <
> thi_veloso at yahoo.com.br> wrote:
> >
> >
> >  Hi all,
> > I am working with some terabytes of CMIP5 climate files. Each file is a
> netcdf with multiple layers (timesteps) representing monthly data.
> > For each file, I need to extract the average value of the raster and put
> all values in a data frame. This is my current approach:---------------
> > library(raster)
> > # make up some datacmip <- brick(nc=150, nr=114, nl=1872)cmip <-
> setValues(cmip, matrix(rep(1:17100, 1872), nc=1872))
> > # get mean values (area average) as data framescmip.mean <-
> as.data.frame(cellStats(cmip, mean, na.rm=T))---------------
> > which works pretty fast in this example:
> >> system.time(as.data.frame(cellStats(cmip, mean, na.rm=T)))
> >   user  system elapsed
> >   0.069  0.012  0.081
> > However, the calculation with my actual data is substantially slower:
> >> system.time(as.data.frame(cellStats(cmip, mean, na.rm=T)))
> >   user  system elapsed
> >   4.600  1.105  5.704
> > Since I will have to deal with thousands of files, here comes my
> > question: is there a faster way to get a the average value of
> > a raster ?
> > Many thanks,
> > --
> > Thiago V. dos Santos
> > PhD student
> > Land and Atmospheric Science
> > University of Minnesota
> >
> http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
> > Phone: (612) 323 9898
> >     [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
> Biology, UCT), Dipl. Phys. (Germany)
>
> Centre of Excellence for Invasion Biology
> Stellenbosch University
> South Africa
>
> Tel :       +33 - (0)9 53 10 27 44
> Cell:       +33 - (0)6 85 62 59 98
> Fax :       +33 - (0)9 58 10 27 44
>
> Fax (D):    +49 - (0)3 21 21 25 22 44
>
> email:      Rainer at krugs.de
>
> Skype:      RMkrug
>
> PGP: 0x0F52F982
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


-- 
*"The highest reward for a person's toil is not what they get for it, but
what they become by it."*
*--John Ruskin,*
*British art critic*

Byman Hamududu

	[[alternative HTML version deleted]]


From godina at dal.ca  Wed May  6 16:35:18 2015
From: godina at dal.ca (Aurelie C.Godin)
Date: Wed, 6 May 2015 07:35:18 -0700 (MST)
Subject: [R-sig-Geo] stplot - legend/classes of categorical vairable
In-Reply-To: <54F74B15.2060305@uni-muenster.de>
References: <b20ce355c0118fa346cff2f0b331763c@posteo.de>
	<54F74B15.2060305@uni-muenster.de>
Message-ID: <1430922918180-7588200.post@n2.nabble.com>

I'm getting strange behavior in the bar legend with factors ...
I cut my data into intervals and plotted results using stplot, however now
the levels are not appearing in the same order as levels(factor)...?

For example, I get the same problem here:
library(spacetime)
example(STFDF)
set.seed(42) 
gridded(stfdf at sp) = TRUE 
stfdf$f = factor(sample(c("a", "b", "c"), 12, replace = TRUE))
levels(stfdf$f)
levels(stfdf$f)<-c('0','(0,5]','(5,25]')
levels(stfdf$f)
library(RColorBrewer)
stplot(stfdf[,,"f"], col.regions = brewer.pal(3, "Accent")) 

Thoughts on how to fix this?



-----
Aurelie Cosandey-Godin
Ph.D. Student, Department of Biology, Dalhousie University
Industrial Graduate Fellow, WWF-Canada
Email: godina at dal.ca | Web: wormlab.biology.dal.ca

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/stplot-legend-classes-of-categorical-vairable-tp7587860p7588200.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From edzer.pebesma at uni-muenster.de  Wed May  6 18:25:46 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 06 May 2015 18:25:46 +0200
Subject: [R-sig-Geo] stplot - legend/classes of categorical vairable
In-Reply-To: <1430922918180-7588200.post@n2.nabble.com>
References: <b20ce355c0118fa346cff2f0b331763c@posteo.de>	<54F74B15.2060305@uni-muenster.de>
	<1430922918180-7588200.post@n2.nabble.com>
Message-ID: <554A408A.8070401@uni-muenster.de>



On 05/06/2015 04:35 PM, Aurelie C.Godin wrote:
> I'm getting strange behavior in the bar legend with factors ...
> I cut my data into intervals and plotted results using stplot, however now
> the levels are not appearing in the same order as levels(factor)...?
> 
> For example, I get the same problem here:
> library(spacetime)
> example(STFDF)
> set.seed(42) 
> gridded(stfdf at sp) = TRUE 
> stfdf$f = factor(sample(c("a", "b", "c"), 12, replace = TRUE))
> levels(stfdf$f)
> levels(stfdf$f)<-c('0','(0,5]','(5,25]')
> levels(stfdf$f)
> library(RColorBrewer)
> stplot(stfdf[,,"f"], col.regions = brewer.pal(3, "Accent")) 
> 
> Thoughts on how to fix this?

I'm not sure what you had expected: do you want them to decrease, in
value, from top to bottom? sp::spplot does it the same way stplot does now.

> 
> 
> 
> -----
> Aurelie Cosandey-Godin
> Ph.D. Student, Department of Biology, Dalhousie University
> Industrial Graduate Fellow, WWF-Canada
> Email: godina at dal.ca | Web: wormlab.biology.dal.ca
> 
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/stplot-legend-classes-of-categorical-vairable-tp7587860p7588200.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150506/7a0f5ae5/attachment.bin>

From godina at dal.ca  Wed May  6 18:51:35 2015
From: godina at dal.ca (Aurelie C.Godin)
Date: Wed, 6 May 2015 09:51:35 -0700 (MST)
Subject: [R-sig-Geo] stplot - legend/classes of categorical vairable
In-Reply-To: <554A408A.8070401@uni-muenster.de>
References: <b20ce355c0118fa346cff2f0b331763c@posteo.de>
	<54F74B15.2060305@uni-muenster.de>
	<1430922918180-7588200.post@n2.nabble.com>
	<554A408A.8070401@uni-muenster.de>
Message-ID: <F666F5D7-7118-4142-AA1D-AC3A2116B2DB@dal.ca>

I'm not sure what you had expected: do you want them to decrease, in
value, from top to bottom? sp::spplot does it the same way stplot does now.
In the key with factor c("a", "b", "c?), ?a" appears at the bottom, followed by ?b" and ?c? (bottom to top), but when these are changed for c('0','(0,5]','(5,25]') , then their order in the key are different e.g., ?a" = ?0? is appearing at the top rather than the bottom and the key is not in order i.e., now from bottom to top: (0,5], (5,25] , 0.

I?m not sure what you mean by :
sp::spplot does it the same way stplot does now.

On May 6, 2015, at 1:27 PM, edzer [via R-sig-geo] <ml-node+s2731867n7588201h68 at n2.nabble.com<mailto:ml-node+s2731867n7588201h68 at n2.nabble.com>> wrote:



On 05/06/2015 04:35 PM, Aurelie C.Godin wrote:

> I'm getting strange behavior in the bar legend with factors ...
> I cut my data into intervals and plotted results using stplot, however now
> the levels are not appearing in the same order as levels(factor)...?
>
> For example, I get the same problem here:
> library(spacetime)
> example(STFDF)
> set.seed(42)
> gridded(stfdf at sp) = TRUE
> stfdf$f = factor(sample(c("a", "b", "c"), 12, replace = TRUE))
> levels(stfdf$f)
> levels(stfdf$f)<-c('0','(0,5]','(5,25]')
> levels(stfdf$f)
> library(RColorBrewer)
> stplot(stfdf[,,"f"], col.regions = brewer.pal(3, "Accent"))
>
> Thoughts on how to fix this?
I'm not sure what you had expected: do you want them to decrease, in
value, from top to bottom? sp::spplot does it the same way stplot does now.

>
>
>
> -----
> Aurelie Cosandey-Godin
> Ph.D. Student, Department of Biology, Dalhousie University
> Industrial Graduate Fellow, WWF-Canada
> Email: [hidden email]<x-msg://2/user/SendEmail.jtp?type=node&node=7588201&i=0> | Web: wormlab.biology.dal.ca<http://wormlab.biology.dal.ca>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/stplot-legend-classes-of-categorical-vairable-tp7587860p7588200.html
> Sent from the R-sig-geo mailing list archive at Nabble.com<http://Nabble.com>.
>
> _______________________________________________
> R-sig-Geo mailing list
> [hidden email]<x-msg://2/user/SendEmail.jtp?type=node&node=7588201&i=1>
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
--
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info<http://www.spatialstatistics.info/>


_______________________________________________
R-sig-Geo mailing list
[hidden email]<x-msg://2/user/SendEmail.jtp?type=node&node=7588201&i=2>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

[http://r-sig-geo.2731867.n2.nabble.com/images/icon_attachment.gif] signature.asc (501 bytes) Download Attachment<http://r-sig-geo.2731867.n2.nabble.com/attachment/7588201/0/signature.asc>


________________________________
If you reply to this email, your message will be added to the discussion below:
http://r-sig-geo.2731867.n2.nabble.com/stplot-legend-classes-of-categorical-vairable-tp7587860p7588201.html
To unsubscribe from stplot - legend/classes of categorical vairable, click here<http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=7587860&code=Z29kaW5hQGRhbC5jYXw3NTg3ODYwfDE5MzkwMjI1NTk=>.
NAML<http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>


--

Aurelie Cosandey-Godin, PhD
Dalhousie University, Department of Biology
godina at dal.ca<mailto:godina at dal.ca> | m: +1 902 499-0984





-----
Aurelie Cosandey-Godin, Ph.D.
Postdoctoral Research Fellow, Department of Biology, Dalhousie University
godina at dal.ca | wormlab.biology.dal.ca

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/stplot-legend-classes-of-categorical-vairable-tp7587860p7588202.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From edzer.pebesma at uni-muenster.de  Wed May  6 19:04:50 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 06 May 2015 19:04:50 +0200
Subject: [R-sig-Geo] stplot - legend/classes of categorical vairable
In-Reply-To: <F666F5D7-7118-4142-AA1D-AC3A2116B2DB@dal.ca>
References: <b20ce355c0118fa346cff2f0b331763c@posteo.de>	<54F74B15.2060305@uni-muenster.de>	<1430922918180-7588200.post@n2.nabble.com>	<554A408A.8070401@uni-muenster.de>
	<F666F5D7-7118-4142-AA1D-AC3A2116B2DB@dal.ca>
Message-ID: <554A49B2.7060604@uni-muenster.de>



On 05/06/2015 06:51 PM, Aurelie C.Godin wrote:
> I'm not sure what you had expected: do you want them to decrease, in
> value, from top to bottom? sp::spplot does it the same way stplot does now.
> In the key with factor c("a", "b", "c?), ?a" appears at the bottom, followed by ?b" and ?c? (bottom to top), but when these are changed for c('0','(0,5]','(5,25]') , then their order in the key are different e.g., ?a" = ?0? is appearing at the top rather than the bottom and the key is not in order i.e., now from bottom to top: (0,5], (5,25] , 0.
> 

I can't reproduce this; what is your sessionInfo()? Maybe updating
spacetime helps?

> I?m not sure what you mean by :
> sp::spplot does it the same way stplot does now.
> 
> On May 6, 2015, at 1:27 PM, edzer [via R-sig-geo] <ml-node+s2731867n7588201h68 at n2.nabble.com<mailto:ml-node+s2731867n7588201h68 at n2.nabble.com>> wrote:
> 
> 
> 
> On 05/06/2015 04:35 PM, Aurelie C.Godin wrote:
> 
>> I'm getting strange behavior in the bar legend with factors ...
>> I cut my data into intervals and plotted results using stplot, however now
>> the levels are not appearing in the same order as levels(factor)...?
>>
>> For example, I get the same problem here:
>> library(spacetime)
>> example(STFDF)
>> set.seed(42)
>> gridded(stfdf at sp) = TRUE
>> stfdf$f = factor(sample(c("a", "b", "c"), 12, replace = TRUE))
>> levels(stfdf$f)
>> levels(stfdf$f)<-c('0','(0,5]','(5,25]')
>> levels(stfdf$f)
>> library(RColorBrewer)
>> stplot(stfdf[,,"f"], col.regions = brewer.pal(3, "Accent"))
>>
>> Thoughts on how to fix this?
> I'm not sure what you had expected: do you want them to decrease, in
> value, from top to bottom? sp::spplot does it the same way stplot does now.
> 
>>
>>
>>
>> -----
>> Aurelie Cosandey-Godin
>> Ph.D. Student, Department of Biology, Dalhousie University
>> Industrial Graduate Fellow, WWF-Canada
>> Email: [hidden email]<x-msg://2/user/SendEmail.jtp?type=node&node=7588201&i=0> | Web: wormlab.biology.dal.ca<http://wormlab.biology.dal.ca>
>>
>> --
>> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/stplot-legend-classes-of-categorical-vairable-tp7587860p7588200.html
>> Sent from the R-sig-geo mailing list archive at Nabble.com<http://Nabble.com>.
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> [hidden email]<x-msg://2/user/SendEmail.jtp?type=node&node=7588201&i=1>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi),  University of M?nster,
> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> Journal of Statistical Software:   http://www.jstatsoft.org/
> Computers & Geosciences:   http://elsevier.com/locate/cageo/
> Spatial Statistics Society http://www.spatialstatistics.info<http://www.spatialstatistics.info/>
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> [hidden email]<x-msg://2/user/SendEmail.jtp?type=node&node=7588201&i=2>
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> [http://r-sig-geo.2731867.n2.nabble.com/images/icon_attachment.gif] signature.asc (501 bytes) Download Attachment<http://r-sig-geo.2731867.n2.nabble.com/attachment/7588201/0/signature.asc>
> 
> 
> ________________________________
> If you reply to this email, your message will be added to the discussion below:
> http://r-sig-geo.2731867.n2.nabble.com/stplot-legend-classes-of-categorical-vairable-tp7587860p7588201.html
> To unsubscribe from stplot - legend/classes of categorical vairable, click here<http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=7587860&code=Z29kaW5hQGRhbC5jYXw3NTg3ODYwfDE5MzkwMjI1NTk=>.
> NAML<http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
> 
> 
> --
> 
> Aurelie Cosandey-Godin, PhD
> Dalhousie University, Department of Biology
> godina at dal.ca<mailto:godina at dal.ca> | m: +1 902 499-0984
> 
> 
> 
> 
> 
> -----
> Aurelie Cosandey-Godin, Ph.D.
> Postdoctoral Research Fellow, Department of Biology, Dalhousie University
> godina at dal.ca | wormlab.biology.dal.ca
> 
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/stplot-legend-classes-of-categorical-vairable-tp7587860p7588202.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150506/b14c7c29/attachment.bin>

From GodinA at Dal.Ca  Wed May  6 19:18:57 2015
From: GodinA at Dal.Ca (Aurelie Cosandey Godin)
Date: Wed, 6 May 2015 17:18:57 +0000
Subject: [R-sig-Geo] stplot - legend/classes of categorical vairable
In-Reply-To: <554A49B2.7060604@uni-muenster.de>
References: <b20ce355c0118fa346cff2f0b331763c@posteo.de>
	<54F74B15.2060305@uni-muenster.de>
	<1430922918180-7588200.post@n2.nabble.com>
	<554A408A.8070401@uni-muenster.de>
	<F666F5D7-7118-4142-AA1D-AC3A2116B2DB@dal.ca>
	<554A49B2.7060604@uni-muenster.de>
Message-ID: <C99AC6D0-0B47-45CF-91AC-AC6E9B438BC7@dal.ca>

It didn?t seem to have fix the issue, here?s my sessionInfo()
Does the key in the correct order for you?

R version 3.1.3 (2015-03-09)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.10.2 (Yosemite)

locale:
[1] en_CA.UTF-8/en_CA.UTF-8/en_CA.UTF-8/C/en_CA.UTF-8/en_CA.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] RColorBrewer_1.0-5 sp_1.1-0           xts_0.9-7          zoo_1.7-11
[5] lattice_0.20-30    spacetime_1.1-4

loaded via a namespace (and not attached):
[1] grid_3.1.3          INLA_0.0-1428997066 intervals_0.15.0    Matrix_1.1-5
[5] splines_3.1.3       tools_3.1.3

On May 6, 2015, at 2:04 PM, Edzer Pebesma <edzer.pebesma at uni-muenster.de<mailto:edzer.pebesma at uni-muenster.de>> wrote:



On 05/06/2015 06:51 PM, Aurelie C.Godin wrote:
I'm not sure what you had expected: do you want them to decrease, in
value, from top to bottom? sp::spplot does it the same way stplot does now.
In the key with factor c("a", "b", "c?), ?a" appears at the bottom, followed by ?b" and ?c? (bottom to top), but when these are changed for c('0','(0,5]','(5,25]') , then their order in the key are different e.g., ?a" = ?0? is appearing at the top rather than the bottom and the key is not in order i.e., now from bottom to top: (0,5], (5,25] , 0.


I can't reproduce this; what is your sessionInfo()? Maybe updating
spacetime helps?

I?m not sure what you mean by :
sp::spplot does it the same way stplot does now.

On May 6, 2015, at 1:27 PM, edzer [via R-sig-geo] <ml-node+s2731867n7588201h68 at n2.nabble.com<mailto:ml-node+s2731867n7588201h68 at n2.nabble.com><mailto:ml-node+s2731867n7588201h68 at n2.nabble.com>> wrote:



On 05/06/2015 04:35 PM, Aurelie C.Godin wrote:

I'm getting strange behavior in the bar legend with factors ...
I cut my data into intervals and plotted results using stplot, however now
the levels are not appearing in the same order as levels(factor)...?

For example, I get the same problem here:
library(spacetime)
example(STFDF)
set.seed(42)
gridded(stfdf at sp) = TRUE
stfdf$f = factor(sample(c("a", "b", "c"), 12, replace = TRUE))
levels(stfdf$f)
levels(stfdf$f)<-c('0','(0,5]','(5,25]')
levels(stfdf$f)
library(RColorBrewer)
stplot(stfdf[,,"f"], col.regions = brewer.pal(3, "Accent"))

Thoughts on how to fix this?
I'm not sure what you had expected: do you want them to decrease, in
value, from top to bottom? sp::spplot does it the same way stplot does now.




-----
Aurelie Cosandey-Godin
Ph.D. Student, Department of Biology, Dalhousie University
Industrial Graduate Fellow, WWF-Canada
Email: [hidden email]<x-msg://2/user/SendEmail.jtp?type=node&node=7588201&i=0> | Web: wormlab.biology.dal.ca<http://wormlab.biology.dal.ca><http://wormlab.biology.dal.ca>

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/stplot-legend-classes-of-categorical-vairable-tp7587860p7588200.html
Sent from the R-sig-geo mailing list archive at Nabble.com<http://Nabble.com><http://Nabble.com>.

_______________________________________________
R-sig-Geo mailing list
[hidden email]<x-msg://2/user/SendEmail.jtp?type=node&node=7588201&i=1>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

--
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info<http://www.spatialstatistics.info/>


_______________________________________________
R-sig-Geo mailing list
[hidden email]<x-msg://2/user/SendEmail.jtp?type=node&node=7588201&i=2>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

[http://r-sig-geo.2731867.n2.nabble.com/images/icon_attachment.gif] signature.asc (501 bytes) Download Attachment<http://r-sig-geo.2731867.n2.nabble.com/attachment/7588201/0/signature.asc>


________________________________
If you reply to this email, your message will be added to the discussion below:
http://r-sig-geo.2731867.n2.nabble.com/stplot-legend-classes-of-categorical-vairable-tp7587860p7588201.html
To unsubscribe from stplot - legend/classes of categorical vairable, click here<http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=7587860&code=Z29kaW5hQGRhbC5jYXw3NTg3ODYwfDE5MzkwMjI1NTk=>.
NAML<http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>


--

Aurelie Cosandey-Godin, PhD
Dalhousie University, Department of Biology
godina at dal.ca<mailto:godina at dal.ca> | m: +1 902 499-0984





-----
Aurelie Cosandey-Godin, Ph.D.
Postdoctoral Research Fellow, Department of Biology, Dalhousie University
godina at dal.ca | wormlab.biology.dal.ca

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/stplot-legend-classes-of-categorical-vairable-tp7587860p7588202.html
Sent from the R-sig-geo mailing list archive at Nabble.com.

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


--
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


--

Aurelie Cosandey-Godin, PhD
Dalhousie University, Department of Biology
godina at dal.ca<mailto:godina at dal.ca> | m: +1 902 499-0984


	[[alternative HTML version deleted]]


From GodinA at Dal.Ca  Wed May  6 20:46:44 2015
From: GodinA at Dal.Ca (Aurelie Cosandey Godin)
Date: Wed, 6 May 2015 18:46:44 +0000
Subject: [R-sig-Geo] temporal aggregate STFDF of class SpatialPixels
Message-ID: <4F55696A-5567-49F7-97B9-6906BF913604@dal.ca>

I?m having a hard time to figure out how to aggregate my STFDF of class SpatialPixels by time. I have yet been successful with the different codes provided in the vignettes, including 'Spatio-temporal overlay and aggregation?. Below an example of what I did so far with some reproducible data (n=50). Ultimately, what I would like to get is 2 maps showing the mean & sd per grid cells for the time-serie.
I would be grateful for any tips and/or further references.

library(rgdal)
library(spacetime)
library(maptools)
library(fields)

### create spacetime SpatialPoints
km.proj<-"+proj=utm +zone=20 +ellps=GRS80 +datum=NAD83 +units=km +no_defs"
sp0 <- SpatialPoints(cbind(smp[2:3]), CRS(km.proj))
smp$date<-as.Date(smp$caught_date)
o <- order(smp$date)
ord.smp <- smp[o, ]
st <- STIDF(sp0, ord.smp$date, data.frame(counts=ord.smp$lamnaN))
class(st);dim(st)

### create spacetime SpatialPixel
yrs <- as.xts(ts(2000:2001, start = 2000, end = 2001))
grid <- maptools::Sobj_SpatialGrid(sp0, maxDim = 20)$SG
st.grid <- STF(as(grid, "SpatialPixels"), yrs)
class(st.grid);dim(st.grid)

### over and calculate sum per grid cells per time (year)
o <- over(st, st.grid, timeInterval = TRUE)
nG <- length(st.grid);nG ###length(grid)*length(yrs)
xx <- rep(as.numeric(NA), nG)
xx[na.omit(unique(o))] <- tapply(st$counts, o, sum)

### now create STFDF
st.df <- STFDF(as(grid, "SpatialPixels"), yrs, data.frame(counts=xx))
class(st.df)

### plot results - sum per year per grid cells - ok
stplot(st.df[,,"counts"],col.regions=tim.colors(100))

### aggreggate by year & calculate mean & sd per grid cells ? ?
x = aggregate(st, st.grid, mean, na.rm=TRUE)
dim(x)

### ?smp' dataset from dput

structure(list(caught_date = structure(c(11553, 11493, 11163,
11230, 11136, 11167, 11555, 11175, 11203, 11151, 11156, 11494,
11511, 11119, 11509, 11185, 11152, 11496, 11519, 11146, 11530,
11551, 11531, 11553, 11561, 11180, 11171, 11537, 11510, 11547,
11123, 11178, 11167, 11145, 11158, 11503, 11532, 11116, 11494,
11136, 11486, 11553, 11594, 11541, 11554, 11136, 11140, 11552,
11528, 11187), class = "Date"), lon.1 = c(358.793648700216, 286.892896235879,
798.310180942244, 549.135889360351, 295.491807527005, 297.923053440568,
365.705980463698, 489.067053994588, 638.516556834411, 307.730448797207,
294.464328249258, 251.169144523995, 398.925128181111, 538.810507777824,
458.43921795352, 589.642893203881, 296.060530322952, 334.149870988617,
628.07289715988, 415.236403654722, 619.379291660565, 584.897269766797,
783.592928906592, 355.008272601906, 482.690947723179, 647.435430118951,
430.425648481571, 847.641625291344, 401.994005499202, 849.144604908023,
567.613658701662, 506.717635075427, 786.341895915623, 431.46321495197,
512.221678849205, 573.011188860812, 794.547821664531, 530.926063605998,
546.115559907762, 953.86614046656, 529.363903413769, 839.737718985791,
462.472901159312, 397.595046444824, 966.694817988262, 294.261805585718,
979.492106837036, 263.295370991572, 259.877252483983, 993.483814446571
), lat.1 = c(4699.31441351726, 4443.69642631574, 4841.4992143951,
4723.96662541948, 4597.16267100868, 4634.13120981602, 4701.033132503,
4738.61419257583, 4699.26053767776, 4635.71561133898, 4656.45644873692,
4392.93208529894, 4533.90089738162, 4612.86525216596, 4629.53486779131,
4757.6919040132, 4663.8228674752, 4459.17290316713, 4739.79501424199,
4829.82694893005, 4769.25379674495, 4918.69835234919, 4839.01123475013,
4712.35633026013, 4890.39979182653, 4790.17886139686, 4737.10188206371,
4877.29908563213, 4544.96262443328, 4873.66909269475, 4648.24420006752,
4888.53665975929, 4837.27011731383, 4703.77559588887, 4740.45970235832,
4526.1637933126, 4833.92057390398, 4520.316776434, 4551.84626738515,
4753.56467869758, 4546.20917123179, 4875.03924698965, 4614.7125586109,
4728.25897543145, 4940.46683542445, 4600.89803274237, 4719.95341291182,
4590.73349116477, 4350.0552020377, 4955.49038457206), lamnaN = c(0.132403257435239,
0.00986449910759576, 1.44198417375472, 24.0597205187391, 0.0896519212396812,
0.558793472572878, 0.157906364505386, 17.5795994790222, 2.35809137691014,
0.24964640218761, 0.0939528058140439, 0.0416547606589983, 0.014734211447768,
6.2508641477239, 0.0199380386844502, 13.5418886687007, 0.00328074837168618,
2.94167877888201, 0.0204603488249901, 0.00913488409772878, 0.0136811391853637,
10.582767887804, 1.53626363359338, 0.00438555392968387, 6.48135523554447,
1.38300940781837, 1.14603348696184, 3.90203176489085, 0.00928059417734763,
4.72367397453852, 1.66075463850196, 2.83411594233376, 15.12151247069,
13.5492935783335, 3.76539649494977, 31.0406032243628, 20.6771788315206,
7.61020373367985, 0.0957017085403933, 1.70078928840253, 0.60206011946782,
7.66127313641195, 0.194463222598053, 0.372038964017632, 0.142217215957269,
0.343157214996115, 0.359141531218846, 0.204396194758893, 0.00577353772801701,
0.228668002958544)), .Names = c("caught_date", "lon.1", "lat.1",
"lamnaN"), row.names = c(6598L, 3679L, 18824L, 13966L, 4099L,
4150L, 6819L, 10682L, 16557L, 4763L, 4015L, 860L, 7834L, 13567L,
9535L, 15199L, 4070L, 5879L, 16300L, 8151L, 16057L, 15114L, 18640L,
6500L, 10467L, 16703L, 8680L, 19355L, 7949L, 19374L, 14597L,
11803L, 18666L, 8734L, 12069L, 14687L, 18756L, 13277L, 13795L,
20088L, 13112L, 19159L, 9675L, 7719L, 20285L, 4072L, 20252L,
1536L, 1740L, 20418L), class = "data.frame?)

--

Aurelie Cosandey-Godin, PhD
Dalhousie University, Department of Biology
godina at dal.ca<mailto:godina at dal.ca> | m: +1 902 499-0984


	[[alternative HTML version deleted]]


From GodinA at Dal.Ca  Wed May  6 21:16:30 2015
From: GodinA at Dal.Ca (Aurelie Cosandey Godin)
Date: Wed, 6 May 2015 19:16:30 +0000
Subject: [R-sig-Geo] stplot - legend/classes of categorical vairable
In-Reply-To: <554A618A.50005@uni-muenster.de>
References: <b20ce355c0118fa346cff2f0b331763c@posteo.de>
	<54F74B15.2060305@uni-muenster.de>
	<1430922918180-7588200.post@n2.nabble.com>
	<554A408A.8070401@uni-muenster.de>
	<F666F5D7-7118-4142-AA1D-AC3A2116B2DB@dal.ca>
	<554A49B2.7060604@uni-muenster.de>
	<C99AC6D0-0B47-45CF-91AC-AC6E9B438BC7@dal.ca>
	<554A618A.50005@uni-muenster.de>
Message-ID: <AD05413A-0ED7-4961-99A5-38A547FF67FA@dal.ca>

Thanks Edzer! Must be an issue with my current session?
Aurelie

On May 6, 2015, at 3:46 PM, Edzer Pebesma <edzer.pebesma at uni-muenster.de<mailto:edzer.pebesma at uni-muenster.de>> wrote:

Aurelie, please find the plot attached (off-list, pls reply Cc: to list)

On 05/06/2015 07:18 PM, Aurelie Cosandey Godin wrote:
It didn?t seem to have fix the issue, here?s my sessionInfo()
Does the key in the correct order for you?

R version 3.1.3 (2015-03-09)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.10.2 (Yosemite)

locale:
[1] en_CA.UTF-8/en_CA.UTF-8/en_CA.UTF-8/C/en_CA.UTF-8/en_CA.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] RColorBrewer_1.0-5 sp_1.1-0           xts_0.9-7          zoo_1.7-11

[5] lattice_0.20-30    spacetime_1.1-4

loaded via a namespace (and not attached):
[1] grid_3.1.3          INLA_0.0-1428997066 intervals_0.15.0
Matrix_1.1-5
[5] splines_3.1.3       tools_3.1.3

On May 6, 2015, at 2:04 PM, Edzer Pebesma
<edzer.pebesma at uni-muenster.de<mailto:edzer.pebesma at uni-muenster.de> <mailto:edzer.pebesma at uni-muenster.de>>
wrote:



On 05/06/2015 06:51 PM, Aurelie C.Godin wrote:
I'm not sure what you had expected: do you want them to decrease, in
value, from top to bottom? sp::spplot does it the same way stplot
does now.
In the key with factor c("a", "b", "c?), ?a" appears at the bottom,
followed by ?b" and ?c? (bottom to top), but when these are changed
for c('0','(0,5]','(5,25]') , then their order in the key are
different e.g., ?a" = ?0? is appearing at the top rather than the
bottom and the key is not in order i.e., now from bottom to top:
(0,5], (5,25] , 0.


I can't reproduce this; what is your sessionInfo()? Maybe updating
spacetime helps?

I?m not sure what you mean by :
sp::spplot does it the same way stplot does now.

On May 6, 2015, at 1:27 PM, edzer [via R-sig-geo]
<ml-node+s2731867n7588201h68 at n2.nabble.com<mailto:ml-node+s2731867n7588201h68 at n2.nabble.com>
<mailto:ml-node+s2731867n7588201h68 at n2.nabble.com><mailto:ml-node+s2731867n7588201h68 at n2.nabble.com>>
wrote:



On 05/06/2015 04:35 PM, Aurelie C.Godin wrote:

I'm getting strange behavior in the bar legend with factors ...
I cut my data into intervals and plotted results using stplot,
however now
the levels are not appearing in the same order as levels(factor)...?

For example, I get the same problem here:
library(spacetime)
example(STFDF)
set.seed(42)
gridded(stfdf at sp) = TRUE
stfdf$f = factor(sample(c("a", "b", "c"), 12, replace = TRUE))
levels(stfdf$f)
levels(stfdf$f)<-c('0','(0,5]','(5,25]')
levels(stfdf$f)
library(RColorBrewer)
stplot(stfdf[,,"f"], col.regions = brewer.pal(3, "Accent"))

Thoughts on how to fix this?
I'm not sure what you had expected: do you want them to decrease, in
value, from top to bottom? sp::spplot does it the same way stplot
does now.




-----
Aurelie Cosandey-Godin
Ph.D. Student, Department of Biology, Dalhousie University
Industrial Graduate Fellow, WWF-Canada
Email: [hidden
email]<x-msg://2/user/SendEmail.jtp?type=node&node=7588201&i=0> |
Web: wormlab.biology.dal.ca<http://wormlab.biology.dal.ca>
<http://wormlab.biology.dal.ca><http://wormlab.biology.dal.ca>

--
View this message in context:
http://r-sig-geo.2731867.n2.nabble.com/stplot-legend-classes-of-categorical-vairable-tp7587860p7588200.html
Sent from the R-sig-geo mailing list archive at Nabble.com
<http://Nabble.com><http://Nabble.com>.

_______________________________________________
R-sig-Geo mailing list
[hidden email]<x-msg://2/user/SendEmail.jtp?type=node&node=7588201&i=1>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

--
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society
http://www.spatialstatistics.info<http://www.spatialstatistics.info/>


_______________________________________________
R-sig-Geo mailing list
[hidden email]<x-msg://2/user/SendEmail.jtp?type=node&node=7588201&i=2>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

[http://r-sig-geo.2731867.n2.nabble.com/images/icon_attachment.gif]
signature.asc (501 bytes) Download
Attachment<http://r-sig-geo.2731867.n2.nabble.com/attachment/7588201/0/signature.asc>


________________________________
If you reply to this email, your message will be added to the
discussion below:
http://r-sig-geo.2731867.n2.nabble.com/stplot-legend-classes-of-categorical-vairable-tp7587860p7588201.html
To unsubscribe from stplot - legend/classes of categorical vairable,
click
here<http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=7587860&code=Z29kaW5hQGRhbC5jYXw3NTg3ODYwfDE5MzkwMjI1NTk=>.
NAML<http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>


--

Aurelie Cosandey-Godin, PhD
Dalhousie University, Department of Biology
godina at dal.ca<mailto:godina at dal.ca> | m: +1 902 499-0984





-----
Aurelie Cosandey-Godin, Ph.D.
Postdoctoral Research Fellow, Department of Biology, Dalhousie University
godina at dal.ca | wormlab.biology.dal.ca

--
View this message in context:
http://r-sig-geo.2731867.n2.nabble.com/stplot-legend-classes-of-categorical-vairable-tp7587860p7588202.html
Sent from the R-sig-geo mailing list archive at Nabble.com.

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


--
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org> <mailto:R-sig-Geo at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

|-- |

*Aurelie Cosandey-Godin, PhD*
Dalhousie University, Department of Biology
godina at dal.ca<mailto:godina at dal.ca> <mailto:godina at dal.ca> | m: +1 902 499-0984


--
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info
<stplot.png>


--

Aurelie Cosandey-Godin, PhD
Dalhousie University, Department of Biology
godina at dal.ca<mailto:godina at dal.ca> | m: +1 902 499-0984


	[[alternative HTML version deleted]]


From paul.ziyu.ma at gmail.com  Thu May  7 11:15:09 2015
From: paul.ziyu.ma at gmail.com (Ziyu Ma)
Date: Thu, 7 May 2015 11:15:09 +0200
Subject: [R-sig-Geo] Proj4string for NASA GPW v3 and Blue Marble world city
	light map?
Message-ID: <CAK3B57hLjMzcC5uz6GEp94TSC_Fdf+__rONaWsnRjif9FL_pCQ@mail.gmail.com>

Dear all,

I was working with a project concerning human population, using data from
the Population Density Grid, version 3.

I have hard time understanding the spatial reference from this metadata
page:

http://sedac.ciesin.columbia.edu/data/set/gpw-v3-population-density/metadata

Can I translate this into a proj4string so that I can use it as a CRS in R?

Also, just out of curiosity, what it the spatial reference for NASA's Blue
Marble maps, like the famous world city light map? Can I also use a
proj4string to describe it?

Thank you very much.

Cheers,
Ma

Ziyu Ma
PhD Student
Ecoinformatics & Biodiversity,
Department of Bioscience, Aarhus University
Ny Munkegade 114, DK-8000 Aarhus C, Denmark

	[[alternative HTML version deleted]]


From SWalbridge at esri.com  Thu May  7 17:11:54 2015
From: SWalbridge at esri.com (Shaun Walbridge)
Date: Thu, 7 May 2015 15:11:54 +0000
Subject: [R-sig-Geo] Proj4string for NASA GPW v3 and Blue Marble world
 city light map?
In-Reply-To: <CAK3B57hLjMzcC5uz6GEp94TSC_Fdf+__rONaWsnRjif9FL_pCQ@mail.gmail.com>
References: <CAK3B57hLjMzcC5uz6GEp94TSC_Fdf+__rONaWsnRjif9FL_pCQ@mail.gmail.com>
Message-ID: <D170F882.25694%swalbridge@esri.com>

The specific projection information is contained within the raster
datasets you download, in the related ASCII, Bil or GRID file. The
metadata you see on that page is just a human readable representation of
the data coverage, not intended to directly map to the full spatial
reference.

-- 
Shaun Walbridge
GIS Developer




On 5/7/15, 5:15 AM, "Ziyu Ma" <paul.ziyu.ma at gmail.com> wrote:

>Dear all,
>
>I was working with a project concerning human population, using data from
>the Population Density Grid, version 3.
>
>I have hard time understanding the spatial reference from this metadata
>page:
>
>http://sedac.ciesin.columbia.edu/data/set/gpw-v3-population-density/metada
>ta
>
>Can I translate this into a proj4string so that I can use it as a CRS in
>R?
>
>Also, just out of curiosity, what it the spatial reference for NASA's Blue
>Marble maps, like the famous world city light map? Can I also use a
>proj4string to describe it?
>
>Thank you very much.
>
>Cheers,
>Ma
>
>Ziyu Ma
>PhD Student
>Ecoinformatics & Biodiversity,
>Department of Bioscience, Aarhus University
>Ny Munkegade 114, DK-8000 Aarhus C, Denmark
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at r-project.org
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From edzer.pebesma at uni-muenster.de  Thu May  7 18:46:40 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 07 May 2015 18:46:40 +0200
Subject: [R-sig-Geo] temporal aggregate STFDF of class SpatialPixels
In-Reply-To: <4F55696A-5567-49F7-97B9-6906BF913604@dal.ca>
References: <4F55696A-5567-49F7-97B9-6906BF913604@dal.ca>
Message-ID: <554B96F0.8050006@uni-muenster.de>

Aurelie, it is not so clear to me what is wrong with x, and why

x.sd = aggregate(st, st.grid, sd, na.rm=TRUE)

is not your standard deviation map (NA when n=1).

On 05/06/2015 08:46 PM, Aurelie Cosandey Godin wrote:
> I?m having a hard time to figure out how to aggregate my STFDF of class SpatialPixels by time. I have yet been successful with the different codes provided in the vignettes, including 'Spatio-temporal overlay and aggregation?. Below an example of what I did so far with some reproducible data (n=50). Ultimately, what I would like to get is 2 maps showing the mean & sd per grid cells for the time-serie.
> I would be grateful for any tips and/or further references.
> 
> library(rgdal)
> library(spacetime)
> library(maptools)
> library(fields)
> 
> ### create spacetime SpatialPoints
> km.proj<-"+proj=utm +zone=20 +ellps=GRS80 +datum=NAD83 +units=km +no_defs"
> sp0 <- SpatialPoints(cbind(smp[2:3]), CRS(km.proj))
> smp$date<-as.Date(smp$caught_date)
> o <- order(smp$date)
> ord.smp <- smp[o, ]
> st <- STIDF(sp0, ord.smp$date, data.frame(counts=ord.smp$lamnaN))
> class(st);dim(st)
> 
> ### create spacetime SpatialPixel
> yrs <- as.xts(ts(2000:2001, start = 2000, end = 2001))
> grid <- maptools::Sobj_SpatialGrid(sp0, maxDim = 20)$SG
> st.grid <- STF(as(grid, "SpatialPixels"), yrs)
> class(st.grid);dim(st.grid)
> 
> ### over and calculate sum per grid cells per time (year)
> o <- over(st, st.grid, timeInterval = TRUE)
> nG <- length(st.grid);nG ###length(grid)*length(yrs)
> xx <- rep(as.numeric(NA), nG)
> xx[na.omit(unique(o))] <- tapply(st$counts, o, sum)
> 
> ### now create STFDF
> st.df <- STFDF(as(grid, "SpatialPixels"), yrs, data.frame(counts=xx))
> class(st.df)
> 
> ### plot results - sum per year per grid cells - ok
> stplot(st.df[,,"counts"],col.regions=tim.colors(100))
> 
> ### aggreggate by year & calculate mean & sd per grid cells ? ?
> x = aggregate(st, st.grid, mean, na.rm=TRUE)
> dim(x)
> 
> ### ?smp' dataset from dput
> 
> structure(list(caught_date = structure(c(11553, 11493, 11163,
> 11230, 11136, 11167, 11555, 11175, 11203, 11151, 11156, 11494,
> 11511, 11119, 11509, 11185, 11152, 11496, 11519, 11146, 11530,
> 11551, 11531, 11553, 11561, 11180, 11171, 11537, 11510, 11547,
> 11123, 11178, 11167, 11145, 11158, 11503, 11532, 11116, 11494,
> 11136, 11486, 11553, 11594, 11541, 11554, 11136, 11140, 11552,
> 11528, 11187), class = "Date"), lon.1 = c(358.793648700216, 286.892896235879,
> 798.310180942244, 549.135889360351, 295.491807527005, 297.923053440568,
> 365.705980463698, 489.067053994588, 638.516556834411, 307.730448797207,
> 294.464328249258, 251.169144523995, 398.925128181111, 538.810507777824,
> 458.43921795352, 589.642893203881, 296.060530322952, 334.149870988617,
> 628.07289715988, 415.236403654722, 619.379291660565, 584.897269766797,
> 783.592928906592, 355.008272601906, 482.690947723179, 647.435430118951,
> 430.425648481571, 847.641625291344, 401.994005499202, 849.144604908023,
> 567.613658701662, 506.717635075427, 786.341895915623, 431.46321495197,
> 512.221678849205, 573.011188860812, 794.547821664531, 530.926063605998,
> 546.115559907762, 953.86614046656, 529.363903413769, 839.737718985791,
> 462.472901159312, 397.595046444824, 966.694817988262, 294.261805585718,
> 979.492106837036, 263.295370991572, 259.877252483983, 993.483814446571
> ), lat.1 = c(4699.31441351726, 4443.69642631574, 4841.4992143951,
> 4723.96662541948, 4597.16267100868, 4634.13120981602, 4701.033132503,
> 4738.61419257583, 4699.26053767776, 4635.71561133898, 4656.45644873692,
> 4392.93208529894, 4533.90089738162, 4612.86525216596, 4629.53486779131,
> 4757.6919040132, 4663.8228674752, 4459.17290316713, 4739.79501424199,
> 4829.82694893005, 4769.25379674495, 4918.69835234919, 4839.01123475013,
> 4712.35633026013, 4890.39979182653, 4790.17886139686, 4737.10188206371,
> 4877.29908563213, 4544.96262443328, 4873.66909269475, 4648.24420006752,
> 4888.53665975929, 4837.27011731383, 4703.77559588887, 4740.45970235832,
> 4526.1637933126, 4833.92057390398, 4520.316776434, 4551.84626738515,
> 4753.56467869758, 4546.20917123179, 4875.03924698965, 4614.7125586109,
> 4728.25897543145, 4940.46683542445, 4600.89803274237, 4719.95341291182,
> 4590.73349116477, 4350.0552020377, 4955.49038457206), lamnaN = c(0.132403257435239,
> 0.00986449910759576, 1.44198417375472, 24.0597205187391, 0.0896519212396812,
> 0.558793472572878, 0.157906364505386, 17.5795994790222, 2.35809137691014,
> 0.24964640218761, 0.0939528058140439, 0.0416547606589983, 0.014734211447768,
> 6.2508641477239, 0.0199380386844502, 13.5418886687007, 0.00328074837168618,
> 2.94167877888201, 0.0204603488249901, 0.00913488409772878, 0.0136811391853637,
> 10.582767887804, 1.53626363359338, 0.00438555392968387, 6.48135523554447,
> 1.38300940781837, 1.14603348696184, 3.90203176489085, 0.00928059417734763,
> 4.72367397453852, 1.66075463850196, 2.83411594233376, 15.12151247069,
> 13.5492935783335, 3.76539649494977, 31.0406032243628, 20.6771788315206,
> 7.61020373367985, 0.0957017085403933, 1.70078928840253, 0.60206011946782,
> 7.66127313641195, 0.194463222598053, 0.372038964017632, 0.142217215957269,
> 0.343157214996115, 0.359141531218846, 0.204396194758893, 0.00577353772801701,
> 0.228668002958544)), .Names = c("caught_date", "lon.1", "lat.1",
> "lamnaN"), row.names = c(6598L, 3679L, 18824L, 13966L, 4099L,
> 4150L, 6819L, 10682L, 16557L, 4763L, 4015L, 860L, 7834L, 13567L,
> 9535L, 15199L, 4070L, 5879L, 16300L, 8151L, 16057L, 15114L, 18640L,
> 6500L, 10467L, 16703L, 8680L, 19355L, 7949L, 19374L, 14597L,
> 11803L, 18666L, 8734L, 12069L, 14687L, 18756L, 13277L, 13795L,
> 20088L, 13112L, 19159L, 9675L, 7719L, 20285L, 4072L, 20252L,
> 1536L, 1740L, 20418L), class = "data.frame?)
> 
> --
> 
> Aurelie Cosandey-Godin, PhD
> Dalhousie University, Department of Biology
> godina at dal.ca<mailto:godina at dal.ca> | m: +1 902 499-0984
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150507/bbba807f/attachment.bin>

From GodinA at Dal.Ca  Thu May  7 21:25:01 2015
From: GodinA at Dal.Ca (Aurelie Cosandey Godin)
Date: Thu, 7 May 2015 19:25:01 +0000
Subject: [R-sig-Geo] temporal aggregate STFDF of class SpatialPixels
In-Reply-To: <554B96F0.8050006@uni-muenster.de>
References: <4F55696A-5567-49F7-97B9-6906BF913604@dal.ca>
	<554B96F0.8050006@uni-muenster.de>
Message-ID: <F4312C4A-C60C-4B00-BA8C-CEBCEC61EDFE@dal.ca>

Thanks Edzer,
Yes?! I must of starred at this way too long? A follow-up question though is what is the most efficient way to quickly plot the result on one map (not index by time)? If I use stplot as below, results are still index by year (albeit now summarized). Do I need to create a new SpatialPixelsDataFrame? Or is there a clever way to do so while keeping the space-time format?
Thank you!

x = aggregate(st, st.grid, mean, na.rm=TRUE)
summary(x at data$counts)
x.sd = aggregate(st, st.grid, sd, na.rm=TRUE)
summary(x.sd at data$counts)

stplot(x[,,"counts"],col.regions=tim.colors(100))
stplot(x.sd[,,"counts"],col.regions=tim.colors(100))



On May 7, 2015, at 1:46 PM, Edzer Pebesma <edzer.pebesma at uni-muenster.de<mailto:edzer.pebesma at uni-muenster.de>> wrote:

Aurelie, it is not so clear to me what is wrong with x, and why

x.sd = aggregate(st, st.grid, sd, na.rm=TRUE)

is not your standard deviation map (NA when n=1).

On 05/06/2015 08:46 PM, Aurelie Cosandey Godin wrote:
I?m having a hard time to figure out how to aggregate my STFDF of class SpatialPixels by time. I have yet been successful with the different codes provided in the vignettes, including 'Spatio-temporal overlay and aggregation?. Below an example of what I did so far with some reproducible data (n=50). Ultimately, what I would like to get is 2 maps showing the mean & sd per grid cells for the time-serie.
I would be grateful for any tips and/or further references.

library(rgdal)
library(spacetime)
library(maptools)
library(fields)

### create spacetime SpatialPoints
km.proj<-"+proj=utm +zone=20 +ellps=GRS80 +datum=NAD83 +units=km +no_defs"
sp0 <- SpatialPoints(cbind(smp[2:3]), CRS(km.proj))
smp$date<-as.Date(smp$caught_date)
o <- order(smp$date)
ord.smp <- smp[o, ]
st <- STIDF(sp0, ord.smp$date, data.frame(counts=ord.smp$lamnaN))
class(st);dim(st)

### create spacetime SpatialPixel
yrs <- as.xts(ts(2000:2001, start = 2000, end = 2001))
grid <- maptools::Sobj_SpatialGrid(sp0, maxDim = 20)$SG
st.grid <- STF(as(grid, "SpatialPixels"), yrs)
class(st.grid);dim(st.grid)

### over and calculate sum per grid cells per time (year)
o <- over(st, st.grid, timeInterval = TRUE)
nG <- length(st.grid);nG ###length(grid)*length(yrs)
xx <- rep(as.numeric(NA), nG)
xx[na.omit(unique(o))] <- tapply(st$counts, o, sum)

### now create STFDF
st.df <- STFDF(as(grid, "SpatialPixels"), yrs, data.frame(counts=xx))
class(st.df)

### plot results - sum per year per grid cells - ok
stplot(st.df[,,"counts"],col.regions=tim.colors(100))

### aggreggate by year & calculate mean & sd per grid cells ? ?
x = aggregate(st, st.grid, mean, na.rm=TRUE)
dim(x)

### ?smp' dataset from dput

structure(list(caught_date = structure(c(11553, 11493, 11163,
11230, 11136, 11167, 11555, 11175, 11203, 11151, 11156, 11494,
11511, 11119, 11509, 11185, 11152, 11496, 11519, 11146, 11530,
11551, 11531, 11553, 11561, 11180, 11171, 11537, 11510, 11547,
11123, 11178, 11167, 11145, 11158, 11503, 11532, 11116, 11494,
11136, 11486, 11553, 11594, 11541, 11554, 11136, 11140, 11552,
11528, 11187), class = "Date"), lon.1 = c(358.793648700216, 286.892896235879,
798.310180942244, 549.135889360351, 295.491807527005, 297.923053440568,
365.705980463698, 489.067053994588, 638.516556834411, 307.730448797207,
294.464328249258, 251.169144523995, 398.925128181111, 538.810507777824,
458.43921795352, 589.642893203881, 296.060530322952, 334.149870988617,
628.07289715988, 415.236403654722, 619.379291660565, 584.897269766797,
783.592928906592, 355.008272601906, 482.690947723179, 647.435430118951,
430.425648481571, 847.641625291344, 401.994005499202, 849.144604908023,
567.613658701662, 506.717635075427, 786.341895915623, 431.46321495197,
512.221678849205, 573.011188860812, 794.547821664531, 530.926063605998,
546.115559907762, 953.86614046656, 529.363903413769, 839.737718985791,
462.472901159312, 397.595046444824, 966.694817988262, 294.261805585718,
979.492106837036, 263.295370991572, 259.877252483983, 993.483814446571
), lat.1 = c(4699.31441351726, 4443.69642631574, 4841.4992143951,
4723.96662541948, 4597.16267100868, 4634.13120981602, 4701.033132503,
4738.61419257583, 4699.26053767776, 4635.71561133898, 4656.45644873692,
4392.93208529894, 4533.90089738162, 4612.86525216596, 4629.53486779131,
4757.6919040132, 4663.8228674752, 4459.17290316713, 4739.79501424199,
4829.82694893005, 4769.25379674495, 4918.69835234919, 4839.01123475013,
4712.35633026013, 4890.39979182653, 4790.17886139686, 4737.10188206371,
4877.29908563213, 4544.96262443328, 4873.66909269475, 4648.24420006752,
4888.53665975929, 4837.27011731383, 4703.77559588887, 4740.45970235832,
4526.1637933126, 4833.92057390398, 4520.316776434, 4551.84626738515,
4753.56467869758, 4546.20917123179, 4875.03924698965, 4614.7125586109,
4728.25897543145, 4940.46683542445, 4600.89803274237, 4719.95341291182,
4590.73349116477, 4350.0552020377, 4955.49038457206), lamnaN = c(0.132403257435239,
0.00986449910759576, 1.44198417375472, 24.0597205187391, 0.0896519212396812,
0.558793472572878, 0.157906364505386, 17.5795994790222, 2.35809137691014,
0.24964640218761, 0.0939528058140439, 0.0416547606589983, 0.014734211447768,
6.2508641477239, 0.0199380386844502, 13.5418886687007, 0.00328074837168618,
2.94167877888201, 0.0204603488249901, 0.00913488409772878, 0.0136811391853637,
10.582767887804, 1.53626363359338, 0.00438555392968387, 6.48135523554447,
1.38300940781837, 1.14603348696184, 3.90203176489085, 0.00928059417734763,
4.72367397453852, 1.66075463850196, 2.83411594233376, 15.12151247069,
13.5492935783335, 3.76539649494977, 31.0406032243628, 20.6771788315206,
7.61020373367985, 0.0957017085403933, 1.70078928840253, 0.60206011946782,
7.66127313641195, 0.194463222598053, 0.372038964017632, 0.142217215957269,
0.343157214996115, 0.359141531218846, 0.204396194758893, 0.00577353772801701,
0.228668002958544)), .Names = c("caught_date", "lon.1", "lat.1",
"lamnaN"), row.names = c(6598L, 3679L, 18824L, 13966L, 4099L,
4150L, 6819L, 10682L, 16557L, 4763L, 4015L, 860L, 7834L, 13567L,
9535L, 15199L, 4070L, 5879L, 16300L, 8151L, 16057L, 15114L, 18640L,
6500L, 10467L, 16703L, 8680L, 19355L, 7949L, 19374L, 14597L,
11803L, 18666L, 8734L, 12069L, 14687L, 18756L, 13277L, 13795L,
20088L, 13112L, 19159L, 9675L, 7719L, 20285L, 4072L, 20252L,
1536L, 1740L, 20418L), class = "data.frame?)

--

Aurelie Cosandey-Godin, PhD
Dalhousie University, Department of Biology
godina at dal.ca<mailto:godina at dal.ca><mailto:godina at dal.ca> | m: +1 902 499-0984


[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


--
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


--

Aurelie Cosandey-Godin, PhD
Dalhousie University, Department of Biology
godina at dal.ca<mailto:godina at dal.ca> | m: +1 902 499-0984


	[[alternative HTML version deleted]]


From Wade.A.Wall at usace.army.mil  Thu May  7 23:15:05 2015
From: Wade.A.Wall at usace.army.mil (Wall, Wade A ERDC-RDE-CERL-IL)
Date: Thu, 7 May 2015 21:15:05 +0000
Subject: [R-sig-Geo] Importing Netcdf files,
	but losing spatial reference data
Message-ID: <C1524BE4BF45454293B8DF38FB9B5ECA35C1E359@MS-EX1VKS.erdc.dren.mil>

Hi all,

I am importing netcdf4 files using brick() from the raster package, but am losing the spatial reference data.

Example code.

tmpBrick <- brick("SomeNetcdfFile.nc")

Am I doing something wrong here? I would prefer not to use open.ncdf(), but if I have to do so and then convert to a brick object, then I guess I can do it.

Thanks for any information,

Wade



	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Fri May  8 00:18:00 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 07 May 2015 22:18:00 +0000
Subject: [R-sig-Geo] Importing Netcdf files,
	but losing spatial reference data
In-Reply-To: <C1524BE4BF45454293B8DF38FB9B5ECA35C1E359@MS-EX1VKS.erdc.dren.mil>
References: <C1524BE4BF45454293B8DF38FB9B5ECA35C1E359@MS-EX1VKS.erdc.dren.mil>
Message-ID: <CAAcGz99kyJt5kftOhHjLJis-V-S+TURNhdrFQpONhp3viCbS1A@mail.gmail.com>

We really need at least the print suumary of tmpBrick and a description of
the file, please include the output of open.ncdf() or other ncdump -h
equivalent.

Cheers, Mike

On Fri, May 8, 2015, 07:15 Wall, Wade A ERDC-RDE-CERL-IL <
Wade.A.Wall at usace.army.mil> wrote:

> Hi all,
>
> I am importing netcdf4 files using brick() from the raster package, but am
> losing the spatial reference data.
>
> Example code.
>
> tmpBrick <- brick("SomeNetcdfFile.nc")
>
> Am I doing something wrong here? I would prefer not to use open.ncdf(),
> but if I have to do so and then convert to a brick object, then I guess I
> can do it.
>
> Thanks for any information,
>
> Wade
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From carr at nimbios.org  Fri May  8 16:36:35 2015
From: carr at nimbios.org (Eric Carr)
Date: Fri, 8 May 2015 10:36:35 -0400
Subject: [R-sig-Geo] Proj4string for NASA GPW v3 and Blue Marble world
 city light map?
In-Reply-To: <D170F882.25694%swalbridge@esri.com>
References: <CAK3B57hLjMzcC5uz6GEp94TSC_Fdf+__rONaWsnRjif9FL_pCQ@mail.gmail.com>
	<D170F882.25694%swalbridge@esri.com>
Message-ID: <CA+XavVBuP63Nt99KtTZWbAKvique6-+PgNoAKM87UmGXyshOrw@mail.gmail.com>

They also have this page:
http://sedac.ciesin.columbia.edu/data/set/gpw-v3-population-density/metadata

On Thu, May 7, 2015 at 11:11 AM, Shaun Walbridge <SWalbridge at esri.com>
wrote:

> The specific projection information is contained within the raster
> datasets you download, in the related ASCII, Bil or GRID file. The
> metadata you see on that page is just a human readable representation of
> the data coverage, not intended to directly map to the full spatial
> reference.
>
> --
> Shaun Walbridge
> GIS Developer
>
>
>
>
> On 5/7/15, 5:15 AM, "Ziyu Ma" <paul.ziyu.ma at gmail.com> wrote:
>
> >Dear all,
> >
> >I was working with a project concerning human population, using data from
> >the Population Density Grid, version 3.
> >
> >I have hard time understanding the spatial reference from this metadata
> >page:
> >
> >
> http://sedac.ciesin.columbia.edu/data/set/gpw-v3-population-density/metada
> >ta
> >
> >Can I translate this into a proj4string so that I can use it as a CRS in
> >R?
> >
> >Also, just out of curiosity, what it the spatial reference for NASA's Blue
> >Marble maps, like the famous world city light map? Can I also use a
> >proj4string to describe it?
> >
> >Thank you very much.
> >
> >Cheers,
> >Ma
> >
> >Ziyu Ma
> >PhD Student
> >Ecoinformatics & Biodiversity,
> >Department of Bioscience, Aarhus University
> >Ny Munkegade 114, DK-8000 Aarhus C, Denmark
> >
> >       [[alternative HTML version deleted]]
> >
> >_______________________________________________
> >R-sig-Geo mailing list
> >R-sig-Geo at r-project.org
> >https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From karlashikev at gmail.com  Fri May  8 19:46:24 2015
From: karlashikev at gmail.com (Karla Shikev)
Date: Fri, 8 May 2015 14:46:24 -0300
Subject: [R-sig-Geo] overlap between shapefiles
Message-ID: <CAPU4_4pP0W8KJXeeEHZEYLNQ7vJt9kpDFZ8DPcgC80S9Wh7D8Q@mail.gmail.com>

Dear all,

I'd like to take two shapefiles and to calculate the area of overlap based
on some world projection. Any suggestions about possible functions?

Thanks!

Karla

	[[alternative HTML version deleted]]


From jbaldwin at fs.fed.us  Fri May  8 19:55:51 2015
From: jbaldwin at fs.fed.us (Baldwin, Jim -FS)
Date: Fri, 8 May 2015 17:55:51 +0000
Subject: [R-sig-Geo] [R-sig-eco] area of range overlap
In-Reply-To: <CAPU4_4obwwkmg36u-AmoTywAUxBt8ZLix6uQdBmr=VLCAOuLDg@mail.gmail.com>
References: <CAPU4_4obwwkmg36u-AmoTywAUxBt8ZLix6uQdBmr=VLCAOuLDg@mail.gmail.com>
Message-ID: <DDC5EC9B78340042B0D5A0C3789D45691A58DBC5@001FSN2MPN1-061.001f.mgd2.msft.net>

As you've sent the same question to both lists, please report your results to both lists.


-----Original Message-----
From: R-sig-ecology [mailto:r-sig-ecology-bounces at r-project.org] On Behalf Of Karla Shikev
Sent: Friday, May 08, 2015 10:38 AM
To: r-sig-ecology at r-project.org
Subject: [R-sig-eco] area of range overlap

Dear all,

I'd like to take two shapefiles with the distribution two different species and to calculate the area of range overlap based on some world projection.
Any suggestions about possible functions?

Thanks!

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-ecology mailing list
R-sig-ecology at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-ecology


From macqueen1 at llnl.gov  Fri May  8 21:10:09 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 8 May 2015 19:10:09 +0000
Subject: [R-sig-Geo] overlap between shapefiles
In-Reply-To: <CAPU4_4pP0W8KJXeeEHZEYLNQ7vJt9kpDFZ8DPcgC80S9Wh7D8Q@mail.gmail.com>
References: <CAPU4_4pP0W8KJXeeEHZEYLNQ7vJt9kpDFZ8DPcgC80S9Wh7D8Q@mail.gmail.com>
Message-ID: <D17257CE.128076%macqueen1@llnl.gov>

In the rgeos package there are  gIntersects() and gIntersection(), that
might be enough to get you started.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 5/8/15, 10:46 AM, "Karla Shikev" <karlashikev at gmail.com> wrote:

>Dear all,
>
>I'd like to take two shapefiles and to calculate the area of overlap based
>on some world projection. Any suggestions about possible functions?
>
>Thanks!
>
>Karla
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at r-project.org
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From tephilippi at gmail.com  Fri May  8 21:30:55 2015
From: tephilippi at gmail.com (Tom Philippi)
Date: Fri, 8 May 2015 12:30:55 -0700
Subject: [R-sig-Geo] overlap between shapefiles
In-Reply-To: <D17257CE.128076%macqueen1@llnl.gov>
References: <CAPU4_4pP0W8KJXeeEHZEYLNQ7vJt9kpDFZ8DPcgC80S9Wh7D8Q@mail.gmail.com>
	<D17257CE.128076%macqueen1@llnl.gov>
Message-ID: <CALyPt8xCxL9oCajLeRhsW45iSne-dEB=OEYKq15S=K1svD99AQ@mail.gmail.com>

To add to Don's recommendation, after you have the 3rd SpatialPolygons
object of the overlap or intersection, you may need to spTransform() them
to a projection where area makes sense, then use rgeos::gArea to compute
the areas.  Which projections to use depends on the spatial scale and
general location of your rangemaps: there is no single best answer.

Tom 2

On Fri, May 8, 2015 at 12:10 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:

> In the rgeos package there are  gIntersects() and gIntersection(), that
> might be enough to get you started.
>
> -Don
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
>
>
>
> On 5/8/15, 10:46 AM, "Karla Shikev" <karlashikev at gmail.com> wrote:
>
> >Dear all,
> >
> >I'd like to take two shapefiles and to calculate the area of overlap based
> >on some world projection. Any suggestions about possible functions?
> >
> >Thanks!
> >
> >Karla
> >
> >       [[alternative HTML version deleted]]
> >
> >_______________________________________________
> >R-sig-Geo mailing list
> >R-sig-Geo at r-project.org
> >https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From tech_dev at wildintellect.com  Sat May  9 03:56:52 2015
From: tech_dev at wildintellect.com (Alex Mandel)
Date: Fri, 08 May 2015 18:56:52 -0700
Subject: [R-sig-Geo] Proj4string for NASA GPW v3 and Blue Marble world
 city light map?
In-Reply-To: <CA+XavVBuP63Nt99KtTZWbAKvique6-+PgNoAKM87UmGXyshOrw@mail.gmail.com>
References: <CAK3B57hLjMzcC5uz6GEp94TSC_Fdf+__rONaWsnRjif9FL_pCQ@mail.gmail.com>	<D170F882.25694%swalbridge@esri.com>
	<CA+XavVBuP63Nt99KtTZWbAKvique6-+PgNoAKM87UmGXyshOrw@mail.gmail.com>
Message-ID: <554D6964.7020700@wildintellect.com>

Specifically,
http://sedac.ciesin.columbia.edu/data/set/gpw-v3-population-density/metadata#Spatial_Reference_Information

The answer is EPSG:4326
http://epsg.io/4326 (compare this to the info above)

CRS("+init=epsg:4326")

will do, no need for the whole proj string.

This is often the case with world wide data sets.

Enjoy,
Alex

On 05/08/2015 07:36 AM, Eric Carr wrote:
> They also have this page:
> http://sedac.ciesin.columbia.edu/data/set/gpw-v3-population-density/metadata
> 
> On Thu, May 7, 2015 at 11:11 AM, Shaun Walbridge <SWalbridge at esri.com>
> wrote:
> 
>> The specific projection information is contained within the raster
>> datasets you download, in the related ASCII, Bil or GRID file. The
>> metadata you see on that page is just a human readable representation of
>> the data coverage, not intended to directly map to the full spatial
>> reference.
>>
>> --
>> Shaun Walbridge
>> GIS Developer
>>
>>
>>
>>
>> On 5/7/15, 5:15 AM, "Ziyu Ma" <paul.ziyu.ma at gmail.com> wrote:
>>
>>> Dear all,
>>>
>>> I was working with a project concerning human population, using data from
>>> the Population Density Grid, version 3.
>>>
>>> I have hard time understanding the spatial reference from this metadata
>>> page:
>>>
>>>
>> http://sedac.ciesin.columbia.edu/data/set/gpw-v3-population-density/metada
>>> ta
>>>
>>> Can I translate this into a proj4string so that I can use it as a CRS in
>>> R?
>>>
>>> Also, just out of curiosity, what it the spatial reference for NASA's Blue
>>> Marble maps, like the famous world city light map? Can I also use a
>>> proj4string to describe it?
>>>
>>> Thank you very much.
>>>
>>> Cheers,
>>> Ma
>>>
>>> Ziyu Ma
>>> PhD Student
>>> Ecoinformatics & Biodiversity,
>>> Department of Bioscience, Aarhus University
>>> Ny Munkegade 114, DK-8000 Aarhus C, Denmark
>>>


From paul.ziyu.ma at gmail.com  Sat May  9 16:29:38 2015
From: paul.ziyu.ma at gmail.com (Ziyu Ma)
Date: Sat, 9 May 2015 16:29:38 +0200
Subject: [R-sig-Geo] Proj4string for NASA GPW v3 and Blue Marble world
 city light map?
In-Reply-To: <554D6964.7020700@wildintellect.com>
References: <CAK3B57hLjMzcC5uz6GEp94TSC_Fdf+__rONaWsnRjif9FL_pCQ@mail.gmail.com>
	<D170F882.25694%swalbridge@esri.com>
	<CA+XavVBuP63Nt99KtTZWbAKvique6-+PgNoAKM87UmGXyshOrw@mail.gmail.com>
	<554D6964.7020700@wildintellect.com>
Message-ID: <CAK3B57jXhRaZKEZumcNb6dJs2mhOcYqYBsGy4r8tBthpJEZVNA@mail.gmail.com>

Thank you all very much. This was very helpful!

Ziyu Ma
PhD Student
Ecoinformatics & Biodiversity,
Department of Bioscience, Aarhus University
Ny Munkegade 114, DK-8000 Aarhus C, Denmark


On Sat, May 9, 2015 at 3:56 AM, Alex Mandel <tech_dev at wildintellect.com>
wrote:

> Specifically,
>
> http://sedac.ciesin.columbia.edu/data/set/gpw-v3-population-density/metadata#Spatial_Reference_Information
>
> The answer is EPSG:4326
> http://epsg.io/4326 (compare this to the info above)
>
> CRS("+init=epsg:4326")
>
> will do, no need for the whole proj string.
>
> This is often the case with world wide data sets.
>
> Enjoy,
> Alex
>
> On 05/08/2015 07:36 AM, Eric Carr wrote:
> > They also have this page:
> >
> http://sedac.ciesin.columbia.edu/data/set/gpw-v3-population-density/metadata
> >
> > On Thu, May 7, 2015 at 11:11 AM, Shaun Walbridge <SWalbridge at esri.com>
> > wrote:
> >
> >> The specific projection information is contained within the raster
> >> datasets you download, in the related ASCII, Bil or GRID file. The
> >> metadata you see on that page is just a human readable representation of
> >> the data coverage, not intended to directly map to the full spatial
> >> reference.
> >>
> >> --
> >> Shaun Walbridge
> >> GIS Developer
> >>
> >>
> >>
> >>
> >> On 5/7/15, 5:15 AM, "Ziyu Ma" <paul.ziyu.ma at gmail.com> wrote:
> >>
> >>> Dear all,
> >>>
> >>> I was working with a project concerning human population, using data
> from
> >>> the Population Density Grid, version 3.
> >>>
> >>> I have hard time understanding the spatial reference from this metadata
> >>> page:
> >>>
> >>>
> >>
> http://sedac.ciesin.columbia.edu/data/set/gpw-v3-population-density/metada
> >>> ta
> >>>
> >>> Can I translate this into a proj4string so that I can use it as a CRS
> in
> >>> R?
> >>>
> >>> Also, just out of curiosity, what it the spatial reference for NASA's
> Blue
> >>> Marble maps, like the famous world city light map? Can I also use a
> >>> proj4string to describe it?
> >>>
> >>> Thank you very much.
> >>>
> >>> Cheers,
> >>> Ma
> >>>
> >>> Ziyu Ma
> >>> PhD Student
> >>> Ecoinformatics & Biodiversity,
> >>> Department of Bioscience, Aarhus University
> >>> Ny Munkegade 114, DK-8000 Aarhus C, Denmark
> >>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From martin.brandt at mailbox.org  Sat May  9 17:54:51 2015
From: martin.brandt at mailbox.org (Martin Brandt)
Date: Sat, 9 May 2015 08:54:51 -0700 (MST)
Subject: [R-sig-Geo] summing rasters with a condition given by other rasters
Message-ID: <1431186891305-7588222.post@n2.nabble.com>

I have the following issue to solve:
There is a MODIS NDVI time series with 23 images for one year, named ndvi_01
to ndvi_23, stored in a raster brick called MODIS.NDVI.2010. Then i have a
raster with integer values from 1-23 representing the start of the growing
season (SOS), and the end (EOS), e.g. SOS = 13 and EOS = 21 for one pixel.
What i am trying to do is to create a raster (let's call it SEASON) which
sums all NDVI values from ndvi_01 to ndvi_23 which are between SOS and EOS,
for the example pixel that would be ndvi_13 to ndvi_21.

Is this possible with the raster package?

kind regards,
Martin 



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/summing-rasters-with-a-condition-given-by-other-rasters-tp7588222.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From thi_veloso at yahoo.com.br  Sat May  9 19:05:42 2015
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Sat, 9 May 2015 17:05:42 +0000 (UTC)
Subject: [R-sig-Geo] Faster way to get raster average?
In-Reply-To: <CAF2H4=ZFSXT27EXNZPnLK5EZRLmfMGDG4Mx_DjSbKBMobQp_Ag@mail.gmail.com>
References: <CAF2H4=ZFSXT27EXNZPnLK5EZRLmfMGDG4Mx_DjSbKBMobQp_Ag@mail.gmail.com>
Message-ID: <842747104.3291606.1431191142053.JavaMail.yahoo@mail.yahoo.com>

Thank you all for the responses. All of them helped me to learn new approaches.
Since I wanted to stick to R (even though I call CDO from R), I ended up adopting Michael's suggestion to reshape data as a matrix before taking the averages.
While relatively hard to read and understand, the time saved in the operation will probably make a huge difference in the final script looping through thousands of files.?Greetings,
--
Thiago V. dos Santos
PhD student
Land and Atmospheric Science
University of Minnesota
http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
Phone: (612) 323 9898 


     On Wednesday, May 6, 2015 7:25 AM, Byman HIkanyona <bymanh at gmail.com> wrote:
   

 Hi, 

My approach, in brief, is similar to what Micheal? Summer suggested, i.e using the netcdf tools (CDO, NCO, etc.). Whether in Linux, Mac,or windows. these tools run more efficiently - memory use and speed. I sometimes use R to automate the run since most are run on (DOS prompt like environment, batch). You can also 'pipe' the operation for example in CDO to avoid saving extra files. For example (CDO - windows) 'R CMD BATCH cdo?ensmean?ifile[1-100]?ofile'? computes the ensemble mean of 100 files listed and saves the result in output file, which you can read using Raster packages. I don't know if this helps.

Cheers, Byman

On Wed, May 6, 2015 at 10:02 AM, Rainer M Krug <Rainer at krugs.de> wrote:

"Thiago V. dos Santos" <thi_veloso at yahoo.com.br> writes:

> Oh, I forgot to mention that I work on a quad-core Mac with 12GB.

> So, if multi-core can potentially accelerate cellStats, or whatever
> function is faster to get a raster average, I would be glad to see
> some examples on how to implement it.?Greetings,

The key question is: how often do you have to do the calculations and if
it would be feasible to just let them run for a few days and be done
with it - optimization takes time!

Cheers,

Rainer

> --
> Thiago V. dos Santos
> PhD student
> Land and Atmospheric Science
> University of Minnesota
> http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
> Phone: (612) 323 9898
>
>
>? ? ? On Tuesday, May 5, 2015 8:48 PM, Thiago V. dos Santos <thi_veloso at yahoo.com.br> wrote:
>
>
>? Hi all,
> I am working with some terabytes of CMIP5 climate files.?Each file is a netcdf with multiple layers (timesteps) representing monthly data.?
> For each file, I need to extract the average value of the raster and put all values in a data frame. This is my current approach:---------------
> library(raster)
> # make up some datacmip <- brick(nc=150, nr=114, nl=1872)cmip <- setValues(cmip, matrix(rep(1:17100, 1872), nc=1872))
> # get mean values (area average) as data framescmip.mean <- as.data.frame(cellStats(cmip, mean, na.rm=T))---------------
> which works pretty fast in this example:
>> system.time(as.data.frame(cellStats(cmip, mean, na.rm=T)))
> ? user? system elapsed
> ? 0.069? 0.012? 0.081
> However, the calculation with my actual data is substantially slower:
>> system.time(as.data.frame(cellStats(cmip, mean, na.rm=T)))
> ? user? system elapsed
> ? 4.600? 1.105? 5.704
> Since I will have to deal with thousands of files, here comes my
> question: is there a faster way to get a the average value of
> a?raster???
> Many thanks,
> --
> Thiago V. dos Santos
> PhD student
> Land and Atmospheric Science
> University of Minnesota
> http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
> Phone: (612) 323 9898
> ??? [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
>? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :? ? ? ?+33 - (0)9 53 10 27 44
Cell:? ? ? ?+33 - (0)6 85 62 59 98
Fax :? ? ? ?+33 - (0)9 58 10 27 44

Fax (D):? ? +49 - (0)3 21 21 25 22 44

email:? ? ? Rainer at krugs.de

Skype:? ? ? RMkrug

PGP: 0x0F52F982

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo





-- 
"The highest reward for a person's toil is not what they get for it, but what they become by it."
--John Ruskin,
British art critic

Byman Hamududu



  
	[[alternative HTML version deleted]]


From sadaouimahrez at outlook.com  Sun May 10 00:35:57 2015
From: sadaouimahrez at outlook.com (sadaoui)
Date: Sat, 9 May 2015 15:35:57 -0700 (MST)
Subject: [R-sig-Geo] Multiply 2 raster without considering cells with NA
Message-ID: <1431210957367-7588224.post@n2.nabble.com>

Hello, 

I try to multiply 2 raster (temperature and precipitation) with "overay"
function, but the problem at the same time it multiplies the NA values, then
it gives a false result.

I tried with this code ;

library(raster) ;
T = getData('worldclim', var='tmean', res=0.5, lon=5, lat=45)/10
MeanT=mean(T)
MeanT
# values      : -11.60833, 23.35833  (min, max)

P= getData('worldclim', var='prec', res=0.5, lon=5, lat=45)
cumulP=sum(P) #values      : 10, 2883  (min, max)

r <- overlay(MeanT, cumulP, fun=function(x,y){return(y/(x+10))})
r # values      : -108000, 318000  (min, max)

Normally I find the results : ~[0-120]

I searched this page :
http://www.inside-r.org/packages/cran/raster/docs/overlay
but is not mentioned.

it is mentioned in the  the "calc" function  but it is applicable only for a
single raster : http://www.inside-r.org/packages/cran/raster/docs/calc

Thank you in advance for helping me make a calculation between two raster
without counting NA values.

Best regards



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Multiply-2-raster-without-considering-cells-with-NA-tp7588224.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From btupper at bigelow.org  Sun May 10 04:26:39 2015
From: btupper at bigelow.org (Ben Tupper)
Date: Sat, 9 May 2015 22:26:39 -0400
Subject: [R-sig-Geo] summing rasters with a condition given by other
	rasters
In-Reply-To: <1431186891305-7588222.post@n2.nabble.com>
References: <1431186891305-7588222.post@n2.nabble.com>
Message-ID: <930D04EF-2AAC-43C5-8F50-48E109E587E4@bigelow.org>


On May 9, 2015, at 11:54 AM, Martin Brandt <martin.brandt at mailbox.org> wrote:

> I have the following issue to solve:
> There is a MODIS NDVI time series with 23 images for one year, named ndvi_01
> to ndvi_23, stored in a raster brick called MODIS.NDVI.2010. Then i have a
> raster with integer values from 1-23 representing the start of the growing
> season (SOS), and the end (EOS), e.g. SOS = 13 and EOS = 21 for one pixel.
> What i am trying to do is to create a raster (let's call it SEASON) which
> sums all NDVI values from ndvi_01 to ndvi_23 which are between SOS and EOS,
> for the example pixel that would be ndvi_13 to ndvi_21.
> 
> Is this possible with the raster package?
> 

On May 9, 2015, at 11:54 AM, Martin Brandt <martin.brandt at mailbox.org> wrote:

> I have the following issue to solve:
> There is a MODIS NDVI time series with 23 images for one year, named ndvi_01
> to ndvi_23, stored in a raster brick called MODIS.NDVI.2010. Then i have a
> raster with integer values from 1-23 representing the start of the growing
> season (SOS), and the end (EOS), e.g. SOS = 13 and EOS = 21 for one pixel.
> What i am trying to do is to create a raster (let's call it SEASON) which
> sums all NDVI values from ndvi_01 to ndvi_23 which are between SOS and EOS,
> for the example pixel that would be ndvi_13 to ndvi_21.
> 
> Is this possible with the raster package?
> 

Hi,

I think it is possible.  Here is one way using the calc() function in the raster package.

# create a multiple layer brick
b <- brick(system.file("external/rlogo.grd", package="raster"))
# add layers
b <- addLayer(b,b,b)
b
# class       : RasterStack 
# dimensions  : 77, 101, 7777, 9  (nrow, ncol, ncell, nlayers)
# resolution  : 1, 1  (x, y)
# extent      : 0, 101, 0, 77  (xmin, xmax, ymin, ymax)
# coord. ref. : +proj=merc 
# names       : red.1, green.1, blue.1, red.2, green.2, blue.2, red.3, green.3, blue.3 
# min values  :     0,       0,      0,     0,       0,      0,     0,       0,      0 
# max values  :   255,     255,    255,   255,     255,    255,   255,     255,    255 

# define the sos and eos by indexed position
sos <- 3  # blue.1
eos <- 8  # green.3

# define a function to sum along that segment of pixels
# @param x a vector of pixels at a particular location
# @param from index of the first pixel of the segment to sum
# @param to index of the last pixel in the segment to sum
# @param ... other arguments for sum()
# @return the sum of pixels long the segment from:to
sum_segment <- function(x, from = sos, to = eos, ...) {
   sum(x[from:to],...)
}

# apply the function across the entire brick
s <- calc(b, sum_segment)
s
# class       : RasterLayer 
# dimensions  : 77, 101, 7777  (nrow, ncol, ncell)
# resolution  : 1, 1  (x, y)
# extent      : 0, 101, 0, 77  (xmin, xmax, ymin, ymax)
# coord. ref. : +proj=merc 
# data source : in memory
# names       : layer 
# values      : 0, 1530  (min, max)

Does that do what you want?

Cheers,
Ben

> kind regards,
> Martin 
> 
> 
> 
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/summing-rasters-with-a-condition-given-by-other-rasters-tp7588222.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From martin.brandt at mailbox.org  Sun May 10 13:37:44 2015
From: martin.brandt at mailbox.org (Martin Brandt)
Date: Sun, 10 May 2015 04:37:44 -0700 (MST)
Subject: [R-sig-Geo] summing rasters with a condition given by other
	rasters
In-Reply-To: <930D04EF-2AAC-43C5-8F50-48E109E587E4@bigelow.org>
References: <1431186891305-7588222.post@n2.nabble.com>
	<930D04EF-2AAC-43C5-8F50-48E109E587E4@bigelow.org>
Message-ID: <1431257864941-7588226.post@n2.nabble.com>

Hi Ben,

many thanks for the detailed answer. The code works fine, but when I use
rasters for eos and sos instead of numbers, i get an error:



b <- brick(system.file("external/rlogo.grd", package="raster"))

b <- addLayer(b,b,b)
b

sos <- raster(system.file("external/rlogo.grd", package="raster"))
eos <- raster(system.file("external/rlogo.grd", package="raster"))


sum_segment <- function(x, from = sos, to = eos, ...) {
  sum(x[from:to],...)
}

 s <- calc(b, sum_segment)

Error in .calcTest(x[1:5], fun, na.rm, forcefun, forceapply) : 
  cannot use this function

am I doing something wrong?




--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/summing-rasters-with-a-condition-given-by-other-rasters-tp7588222p7588226.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From dmarcelino at live.com  Sun May 10 17:31:14 2015
From: dmarcelino at live.com (Daniel Marcelino)
Date: Sun, 10 May 2015 12:31:14 -0300
Subject: [R-sig-Geo] Issue with ogrInfo
Message-ID: <CAAjbdiJ0n8C9g=z=km5BvMPfmB1nVMvM-WHt2f=u-Cp2=bQB9g@mail.gmail.com>

Dear all, I'm having the following issue when trying to read a
topographical json file:
The file is here
https://github.com/kjhealy/uk-elections/blob/master/maps/topo_wpc.json

> uk.map <- readOGR(dsn = "maps/topo_wpc.json", layer = "wpc")
Error in ogrInfo(dsn = dsn, layer = layer, encoding = encoding,
use_iconv = use_iconv,  :
  Cannot open file

> traceback()
5: .Call("ogrInfo", as.character(dsn), as.character(layer), PACKAGE = "rgdal")
4: ogrInfo(dsn = dsn, layer = layer, encoding = encoding, use_iconv = use_iconv,
       swapAxisOrder = swapAxisOrder, require_geomType = require_geomType)
3: withCallingHandlers(expr, message = function(c)
invokeRestart("muffleMessage"))
2: suppressMessages(ogr_info <- ogrInfo(dsn = dsn, layer = layer,
       encoding = encoding, use_iconv = use_iconv, swapAxisOrder =
swapAxisOrder,
       require_geomType = require_geomType))
1: readOGR(dsn = "maps/topo_wpc.json", layer = "wpc")


> sessionInfo()
R version 3.2.0 Patched (2015-04-19 r68207)
Platform: x86_64-apple-darwin10.8.0 (64-bit)
Running under: OS X 10.8.5 (Mountain Lion)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] rgdal_0.9-2 sp_1.1-0

loaded via a namespace (and not attached):
 [1] MASS_7.3-40      colorspace_1.2-6 scales_0.2.4     plyr_1.8.1
 [5] tools_3.2.0      gtable_0.1.2     reshape2_1.4.1   Rcpp_0.11.5
 [9] ggplot2_1.0.1    grid_3.2.0       stringr_0.6.2    digest_0.6.8
[13] proto_0.3-10     munsell_0.4.2    lattice_0.20-31


From Roger.Bivand at nhh.no  Sun May 10 17:58:18 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 10 May 2015 17:58:18 +0200
Subject: [R-sig-Geo] Issue with ogrInfo
In-Reply-To: <CAAjbdiJ0n8C9g=z=km5BvMPfmB1nVMvM-WHt2f=u-Cp2=bQB9g@mail.gmail.com>
References: <CAAjbdiJ0n8C9g=z=km5BvMPfmB1nVMvM-WHt2f=u-Cp2=bQB9g@mail.gmail.com>
Message-ID: <alpine.LFD.2.11.1505101755110.16405@reclus.nhh.no>

On Sun, 10 May 2015, Daniel Marcelino wrote:

> Dear all, I'm having the following issue when trying to read a
> topographical json file:

The file is not recognised by OGR either, so is probably not conforming to 
geojson expectations. It declares itself as HTML, but within github puts 
boundaries on a map background, so I think the file is trying to do much 
more than simply represent Welsh parliamentary constituencies.

Roger

> The file is here
> https://github.com/kjhealy/uk-elections/blob/master/maps/topo_wpc.json
>
>> uk.map <- readOGR(dsn = "maps/topo_wpc.json", layer = "wpc")
> Error in ogrInfo(dsn = dsn, layer = layer, encoding = encoding,
> use_iconv = use_iconv,  :
>  Cannot open file
>
>> traceback()
> 5: .Call("ogrInfo", as.character(dsn), as.character(layer), PACKAGE = "rgdal")
> 4: ogrInfo(dsn = dsn, layer = layer, encoding = encoding, use_iconv = use_iconv,
>       swapAxisOrder = swapAxisOrder, require_geomType = require_geomType)
> 3: withCallingHandlers(expr, message = function(c)
> invokeRestart("muffleMessage"))
> 2: suppressMessages(ogr_info <- ogrInfo(dsn = dsn, layer = layer,
>       encoding = encoding, use_iconv = use_iconv, swapAxisOrder =
> swapAxisOrder,
>       require_geomType = require_geomType))
> 1: readOGR(dsn = "maps/topo_wpc.json", layer = "wpc")
>
>
>> sessionInfo()
> R version 3.2.0 Patched (2015-04-19 r68207)
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
> Running under: OS X 10.8.5 (Mountain Lion)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] rgdal_0.9-2 sp_1.1-0
>
> loaded via a namespace (and not attached):
> [1] MASS_7.3-40      colorspace_1.2-6 scales_0.2.4     plyr_1.8.1
> [5] tools_3.2.0      gtable_0.1.2     reshape2_1.4.1   Rcpp_0.11.5
> [9] ggplot2_1.0.1    grid_3.2.0       stringr_0.6.2    digest_0.6.8
> [13] proto_0.3-10     munsell_0.4.2    lattice_0.20-31
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From btupper at bigelow.org  Sun May 10 19:02:15 2015
From: btupper at bigelow.org (Ben Tupper)
Date: Sun, 10 May 2015 13:02:15 -0400
Subject: [R-sig-Geo] summing rasters with a condition given by other
	rasters
In-Reply-To: <1431257864941-7588226.post@n2.nabble.com>
References: <1431186891305-7588222.post@n2.nabble.com>
	<930D04EF-2AAC-43C5-8F50-48E109E587E4@bigelow.org>
	<1431257864941-7588226.post@n2.nabble.com>
Message-ID: <C14A32AC-C486-4515-A723-3F456424A8B6@bigelow.org>

Hi,

On May 10, 2015, at 7:37 AM, Martin Brandt <martin.brandt at mailbox.org> wrote:

> Hi Ben,
> 
> many thanks for the detailed answer. The code works fine, but when I use
> rasters for eos and sos instead of numbers, i get an error:
> 
> 
> 
> b <- brick(system.file("external/rlogo.grd", package="raster"))
> 
> b <- addLayer(b,b,b)
> b
> 
> sos <- raster(system.file("external/rlogo.grd", package="raster"))
> eos <- raster(system.file("external/rlogo.grd", package="raster"))
> 
> 
> sum_segment <- function(x, from = sos, to = eos, ...) {
>  sum(x[from:to],...)
> }
> 
> s <- calc(b, sum_segment)
> 
> Error in .calcTest(x[1:5], fun, na.rm, forcefun, forceapply) : 
>  cannot use this function
> 
> am I doing something wrong?

Yes, as tempting as it is to do otherwise you really do have to use numeric position indices.  Inside the function sum_segment the value of x is simple a numeric vector. Within the scope of the function the context of the pixels embedded in the raster object is temporarily "lost" - they are just a vector of numbers.  

To work with the calc() function you must first compute the position indices for sos and eos using which().

sos <- which(names(b) == "blue.1")  # you would substitue the name of your layer for blue.1
eos <- which(names(b) == "green.3") # and again for green.3

Cheers,
Ben


> 
> 
> 
> 
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/summing-rasters-with-a-condition-given-by-other-rasters-tp7588222p7588226.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From b.rowlingson at lancaster.ac.uk  Sun May 10 19:12:40 2015
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sun, 10 May 2015 18:12:40 +0100
Subject: [R-sig-Geo] Issue with ogrInfo
In-Reply-To: <CAAjbdiJ0n8C9g=z=km5BvMPfmB1nVMvM-WHt2f=u-Cp2=bQB9g@mail.gmail.com>
References: <CAAjbdiJ0n8C9g=z=km5BvMPfmB1nVMvM-WHt2f=u-Cp2=bQB9g@mail.gmail.com>
Message-ID: <CANVKczNtUAc4C6W0A=Dt1G4weHVBHyHLUGVA2izT5YrTgLX+YA@mail.gmail.com>

On Sun, May 10, 2015 at 4:31 PM, Daniel Marcelino <dmarcelino at live.com> wrote:
> Dear all, I'm having the following issue when trying to read a
> topographical json file:

 That's a **topological**  (not topographical) geojson file. Instead
of recording each polygon separately, and thus duplicating common
boundaries, a topojson file stores all the line segments once, and
then defines polygons as which sequence of line segments draws the
polygon.

 I'm guessing your ogr library doesn't have topojson support. Does the
output of ogrDrivers() agree with me?

 Solution is usually "use gdal/ogr tools to convert to plain old
geojson (ogr2ogr)"


Barry


From b.rowlingson at lancaster.ac.uk  Sun May 10 19:14:50 2015
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sun, 10 May 2015 18:14:50 +0100
Subject: [R-sig-Geo] Issue with ogrInfo
In-Reply-To: <CANVKczNtUAc4C6W0A=Dt1G4weHVBHyHLUGVA2izT5YrTgLX+YA@mail.gmail.com>
References: <CAAjbdiJ0n8C9g=z=km5BvMPfmB1nVMvM-WHt2f=u-Cp2=bQB9g@mail.gmail.com>
	<CANVKczNtUAc4C6W0A=Dt1G4weHVBHyHLUGVA2izT5YrTgLX+YA@mail.gmail.com>
Message-ID: <CANVKczM2-1h_fva8ewijM6h6kXW53EhRNMsRRViCUBGy5nh-ug@mail.gmail.com>

On Sun, May 10, 2015 at 6:12 PM, Barry Rowlingson
<b.rowlingson at lancaster.ac.uk> wrote:

>  Solution is usually "use gdal/ogr tools to convert to plain old
> geojson (ogr2ogr)"

 Actually that's a really stupid solution. If ogr2ogr can do it, you
need the support in the first place! Doh!

 You need a separate tool. Something here might help:

http://recology.info/2015/01/geojson-topojson-io/

>
> Barry


From Roger.Bivand at nhh.no  Sun May 10 19:38:53 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 10 May 2015 19:38:53 +0200
Subject: [R-sig-Geo] Issue with ogrInfo
In-Reply-To: <CANVKczNtUAc4C6W0A=Dt1G4weHVBHyHLUGVA2izT5YrTgLX+YA@mail.gmail.com>
References: <CAAjbdiJ0n8C9g=z=km5BvMPfmB1nVMvM-WHt2f=u-Cp2=bQB9g@mail.gmail.com>
	<CANVKczNtUAc4C6W0A=Dt1G4weHVBHyHLUGVA2izT5YrTgLX+YA@mail.gmail.com>
Message-ID: <alpine.LFD.2.11.1505101936170.18367@reclus.nhh.no>

On Sun, 10 May 2015, Barry Rowlingson wrote:

> On Sun, May 10, 2015 at 4:31 PM, Daniel Marcelino <dmarcelino at live.com> wrote:
>> Dear all, I'm having the following issue when trying to read a
>> topographical json file:
>
> That's a **topological**  (not topographical) geojson file. Instead
> of recording each polygon separately, and thus duplicating common
> boundaries, a topojson file stores all the line segments once, and
> then defines polygons as which sequence of line segments draws the
> polygon.
>
> I'm guessing your ogr library doesn't have topojson support. Does the
> output of ogrDrivers() agree with me?
>
> Solution is usually "use gdal/ogr tools to convert to plain old
> geojson (ogr2ogr)"

Right, but while the geojson driver does read topojson from 1.11, ogrinfo 
says no-go. On inspecting the file, it appears only to contain lost of 
links to other stuff and no geometries that I (or OGR) recognise. The 
geometries must be hidden in one of the links, but are not exposed.

Roger

>
>
> Barry
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From martin.brandt at mailbox.org  Sun May 10 22:42:24 2015
From: martin.brandt at mailbox.org (Martin Brandt)
Date: Sun, 10 May 2015 13:42:24 -0700 (MST)
Subject: [R-sig-Geo] summing rasters with a condition given by other
	rasters
In-Reply-To: <C14A32AC-C486-4515-A723-3F456424A8B6@bigelow.org>
References: <1431186891305-7588222.post@n2.nabble.com>
	<930D04EF-2AAC-43C5-8F50-48E109E587E4@bigelow.org>
	<1431257864941-7588226.post@n2.nabble.com>
	<C14A32AC-C486-4515-A723-3F456424A8B6@bigelow.org>
Message-ID: <1431290544770-7588233.post@n2.nabble.com>

Hi Ben,

thanks again, I see, but i'm not sure if i understand it correctly. The
thing is that each pixel in the rasters sos and eos has different values,
i.e. the start of season and end of season is not the same for each pixel.
Thus, I cannot really define eos and sos but need to use the given rasters
containing the values..

cheers,
Martin




--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/summing-rasters-with-a-condition-given-by-other-rasters-tp7588222p7588233.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From simone.ruzza12 at gmail.com  Sun May 10 23:56:09 2015
From: simone.ruzza12 at gmail.com (Simone Ruzza)
Date: Sun, 10 May 2015 23:56:09 +0200
Subject: [R-sig-Geo] slope for rarefaction curve
Message-ID: <CADZVqoasWW_MT_EVcHOs=b9ZgXoX=_6y4FWr9pQE4x=tj6sLiA@mail.gmail.com>

Dear all,

apologies for the total beginner's question. I was wondering if anyone
can give some advice on how to calculate the slope for the last 10% of
the records of a rarefaction curve computed with rarefy from vegan.
Here is a graphic representation of what I would like to do:

https://dl.dropboxusercontent.com/u/33966347/figure.JPG

I have seen that this has been done in a recent paper and I was
wondering if anyone may have any code snippet to do that. Sorry, maybe
this is something really obvious but I have not quite understood how
to do it.

thanks!

Simone


From simone.ruzza12 at gmail.com  Sun May 10 23:57:08 2015
From: simone.ruzza12 at gmail.com (Simone Ruzza)
Date: Sun, 10 May 2015 23:57:08 +0200
Subject: [R-sig-Geo] slope for rarefaction curve
In-Reply-To: <CADZVqoasWW_MT_EVcHOs=b9ZgXoX=_6y4FWr9pQE4x=tj6sLiA@mail.gmail.com>
References: <CADZVqoasWW_MT_EVcHOs=b9ZgXoX=_6y4FWr9pQE4x=tj6sLiA@mail.gmail.com>
Message-ID: <CADZVqoaacTnWETi9ceEh8JZTUixV3SzAByXvqjjPjy=1veV0JQ@mail.gmail.com>

Apologies for this e-mail, I accidentally sent it to wrong R list! I
am subscribed to multiple lists.

Cheers,

Simone

On Sun, May 10, 2015 at 11:56 PM, Simone Ruzza <simone.ruzza12 at gmail.com> wrote:
> Dear all,
>
> apologies for the total beginner's question. I was wondering if anyone
> can give some advice on how to calculate the slope for the last 10% of
> the records of a rarefaction curve computed with rarefy from vegan.
> Here is a graphic representation of what I would like to do:
>
> https://dl.dropboxusercontent.com/u/33966347/figure.JPG
>
> I have seen that this has been done in a recent paper and I was
> wondering if anyone may have any code snippet to do that. Sorry, maybe
> this is something really obvious but I have not quite understood how
> to do it.
>
> thanks!
>
> Simone


From btupper at bigelow.org  Mon May 11 01:37:50 2015
From: btupper at bigelow.org (Ben Tupper)
Date: Sun, 10 May 2015 19:37:50 -0400
Subject: [R-sig-Geo] summing rasters with a condition given by other
	rasters
In-Reply-To: <1431290544770-7588233.post@n2.nabble.com>
References: <1431186891305-7588222.post@n2.nabble.com>
	<930D04EF-2AAC-43C5-8F50-48E109E587E4@bigelow.org>
	<1431257864941-7588226.post@n2.nabble.com>
	<C14A32AC-C486-4515-A723-3F456424A8B6@bigelow.org>
	<1431290544770-7588233.post@n2.nabble.com>
Message-ID: <ACF6B42D-3412-40E6-B88C-02835C07A218@bigelow.org>

Hi Martin,

On May 10, 2015, at 4:42 PM, Martin Brandt <martin.brandt at mailbox.org> wrote:

> Hi Ben,
> 
> thanks again, I see, but i'm not sure if i understand it correctly. The
> thing is that each pixel in the rasters sos and eos has different values,
> i.e. the start of season and end of season is not the same for each pixel.
> Thus, I cannot really define eos and sos but need to use the given rasters
> containing the values..
> 

Oooooo.  I think I see what you are after.  I'll bet there are better ways, but my brute force and ignorance approach would be to prepend your start-of-season raster (sos) and end-of-season raster (eos) to your raster data. I would still use calc but modify the sum_segment function.  After the computation I would then drop the sos and eos layer form the data.  Note that sos and eos still have to be numeric indices into the layers of the data, b.

library(raster)
# create a multiple layer brick
b <- brick(system.file("external/rlogo.grd", package="raster"))
# add layers
b <- addLayer(b,b,b)
b
# class       : RasterStack 
# dimensions  : 77, 101, 7777, 9  (nrow, ncol, ncell, nlayers)
# resolution  : 1, 1  (x, y)
# extent      : 0, 101, 0, 77  (xmin, xmax, ymin, ymax)
# coord. ref. : +proj=merc 
# names       : red.1, green.1, blue.1, red.2, green.2, blue.2, red.3, green.3, blue.3 
# min values  :     0,       0,      0,     0,       0,      0,     0,       0,      0 
# max values  :   255,     255,    255,   255,     255,    255,   255,     255,    255 

# define the sos and eos by indexed position
# sos will range from 1 to 4
sos <- raster(matrix(sample(1:4, ncell(b), replace = TRUE), nrow = nrow(b), ncol = ncol(b)),
   template = b)
   
#eos will range from 6 to 9
eos <-  raster(matrix(sample(6:nlayers(b), ncell(b), replace = TRUE), nrow = nrow(b), ncol = ncol(b)),
   template = b)

# prepend sos and eos to your data
b <- addLayer(sos, eos, b)

# define the summing function - add 2 to account for sos and eos at the start
sum_segment <- function(x, ...) {
   sum(x[(x[1]+2):(x[2] + 2)],...)
}

# run the computation
s <- calc(b, sum_segment)

#restore b
b <- dropLayer(b, c(1,2))

s
#class       : RasterLayer 
#dimensions  : 77, 101, 7777  (nrow, ncol, ncell)
#resolution  : 1, 1  (x, y)
#extent      : 0, 101, 0, 77  (xmin, xmax, ymin, ymax)
#coord. ref. : +proj=merc 
#data source : in memory
#names       : layer 
#values      : 0, 2295  (min, max)

b
#class       : RasterStack 
#dimensions  : 77, 101, 7777, 9  (nrow, ncol, ncell, nlayers)
#resolution  : 1, 1  (x, y)
#extent      : 0, 101, 0, 77  (xmin, xmax, ymin, ymax)
#coord. ref. : +proj=merc 
#names       : red.1, green.1, blue.1, red.2, green.2, blue.2, red.3, green.3, blue.3 
#min values  :     0,       0,      0,     0,       0,      0,     0,       0,      0 
#max values  :   255,     255,    255,   255,     255,    255,   255,     255,    255 

You might be able to do something similar with the overlay(). If that doesn't do it then we'll both have to wait for someone to come to our rescue!

Cheers,
Ben








> cheers,
> Martin
> 
> 
> 
> 
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/summing-rasters-with-a-condition-given-by-other-rasters-tp7588222p7588233.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From b.rowlingson at lancaster.ac.uk  Mon May 11 10:46:10 2015
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 11 May 2015 09:46:10 +0100
Subject: [R-sig-Geo] Issue with ogrInfo
In-Reply-To: <alpine.LFD.2.11.1505101936170.18367@reclus.nhh.no>
References: <CAAjbdiJ0n8C9g=z=km5BvMPfmB1nVMvM-WHt2f=u-Cp2=bQB9g@mail.gmail.com>
	<CANVKczNtUAc4C6W0A=Dt1G4weHVBHyHLUGVA2izT5YrTgLX+YA@mail.gmail.com>
	<alpine.LFD.2.11.1505101936170.18367@reclus.nhh.no>
Message-ID: <CANVKczO2-a+s-AGEoOSc91bqQhnmqNYnUZ1dHwnzRhHUtQAZhQ@mail.gmail.com>

If you go far enough into the file (which appears to be without line
breaks, so somewhere on line 1... You'll see:

"arcs":[[[7533,1255],[-1,8],[0,4],[2,3],[-1,8],[2,2],[-2,2],[-1,0],[-1,1] .....

which I think is the geometry (arcs have a start point and then x-y deltas).

I can read this file if I first convert to geojson using the command
line converter:

 $ topojson-geojson topo_wpc.json

which gives me wpc.json, and then in R:

 > d=readOGR("./wpc.json","OGRGeoJSON")
OGR data source with driver: GeoJSON
Source: "./wpc.json", layer: "OGRGeoJSON"
with 632 features and 3 fields
Feature type: wkbPolygon with 2 dimensions

Hmmmm

Barry




On Sun, May 10, 2015 at 6:38 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Sun, 10 May 2015, Barry Rowlingson wrote:
>
>> On Sun, May 10, 2015 at 4:31 PM, Daniel Marcelino <dmarcelino at live.com>
>> wrote:
>>>
>>> Dear all, I'm having the following issue when trying to read a
>>> topographical json file:
>>
>>
>> That's a **topological**  (not topographical) geojson file. Instead
>> of recording each polygon separately, and thus duplicating common
>> boundaries, a topojson file stores all the line segments once, and
>> then defines polygons as which sequence of line segments draws the
>> polygon.
>>
>> I'm guessing your ogr library doesn't have topojson support. Does the
>> output of ogrDrivers() agree with me?
>>
>> Solution is usually "use gdal/ogr tools to convert to plain old
>> geojson (ogr2ogr)"
>
>
> Right, but while the geojson driver does read topojson from 1.11, ogrinfo
> says no-go. On inspecting the file, it appears only to contain lost of links
> to other stuff and no geometries that I (or OGR) recognise. The geometries
> must be hidden in one of the links, but are not exposed.
>
> Roger
>
>>
>>
>> Barry
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Mon May 11 12:52:09 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 11 May 2015 12:52:09 +0200
Subject: [R-sig-Geo] Issue with ogrInfo
In-Reply-To: <CANVKczO2-a+s-AGEoOSc91bqQhnmqNYnUZ1dHwnzRhHUtQAZhQ@mail.gmail.com>
References: <CAAjbdiJ0n8C9g=z=km5BvMPfmB1nVMvM-WHt2f=u-Cp2=bQB9g@mail.gmail.com>
	<CANVKczNtUAc4C6W0A=Dt1G4weHVBHyHLUGVA2izT5YrTgLX+YA@mail.gmail.com>
	<alpine.LFD.2.11.1505101936170.18367@reclus.nhh.no>
	<CANVKczO2-a+s-AGEoOSc91bqQhnmqNYnUZ1dHwnzRhHUtQAZhQ@mail.gmail.com>
Message-ID: <alpine.LFD.2.11.1505111250430.2091@reclus.nhh.no>

On Mon, 11 May 2015, Barry Rowlingson wrote:

> If you go far enough into the file (which appears to be without line
> breaks, so somewhere on line 1... You'll see:
>
> "arcs":[[[7533,1255],[-1,8],[0,4],[2,3],[-1,8],[2,2],[-2,2],[-1,0],[-1,1] .....
>
> which I think is the geometry (arcs have a start point and then x-y deltas).

Support for geometries like these may be coming to OGR, I think curves 
were also discussed. Using the converter here seems the best way forward.

Roger

>
> I can read this file if I first convert to geojson using the command
> line converter:
>
> $ topojson-geojson topo_wpc.json
>
> which gives me wpc.json, and then in R:
>
> > d=readOGR("./wpc.json","OGRGeoJSON")
> OGR data source with driver: GeoJSON
> Source: "./wpc.json", layer: "OGRGeoJSON"
> with 632 features and 3 fields
> Feature type: wkbPolygon with 2 dimensions
>
> Hmmmm
>
> Barry
>
>
>
>
> On Sun, May 10, 2015 at 6:38 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> On Sun, 10 May 2015, Barry Rowlingson wrote:
>>
>>> On Sun, May 10, 2015 at 4:31 PM, Daniel Marcelino <dmarcelino at live.com>
>>> wrote:
>>>>
>>>> Dear all, I'm having the following issue when trying to read a
>>>> topographical json file:
>>>
>>>
>>> That's a **topological**  (not topographical) geojson file. Instead
>>> of recording each polygon separately, and thus duplicating common
>>> boundaries, a topojson file stores all the line segments once, and
>>> then defines polygons as which sequence of line segments draws the
>>> polygon.
>>>
>>> I'm guessing your ogr library doesn't have topojson support. Does the
>>> output of ogrDrivers() agree with me?
>>>
>>> Solution is usually "use gdal/ogr tools to convert to plain old
>>> geojson (ogr2ogr)"
>>
>>
>> Right, but while the geojson driver does read topojson from 1.11, ogrinfo
>> says no-go. On inspecting the file, it appears only to contain lost of links
>> to other stuff and no geometries that I (or OGR) recognise. The geometries
>> must be hidden in one of the links, but are not exposed.
>>
>> Roger
>>
>>>
>>>
>>> Barry
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From b.rowlingson at lancaster.ac.uk  Mon May 11 13:42:09 2015
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 11 May 2015 12:42:09 +0100
Subject: [R-sig-Geo] Issue with ogrInfo
In-Reply-To: <bddac5dd60884c47b648469b5d39ae2e@EX-0-HT0.lancs.local>
References: <CAAjbdiJ0n8C9g=z=km5BvMPfmB1nVMvM-WHt2f=u-Cp2=bQB9g@mail.gmail.com>
	<CANVKczNtUAc4C6W0A=Dt1G4weHVBHyHLUGVA2izT5YrTgLX+YA@mail.gmail.com>
	<alpine.LFD.2.11.1505101936170.18367@reclus.nhh.no>
	<CANVKczO2-a+s-AGEoOSc91bqQhnmqNYnUZ1dHwnzRhHUtQAZhQ@mail.gmail.com>
	<bddac5dd60884c47b648469b5d39ae2e@EX-0-HT0.lancs.local>
Message-ID: <CANVKczM=byFt=0wDzdYxeDPiNE6GBy3p8Exk64a8eZFyV-QQuA@mail.gmail.com>

On Mon, May 11, 2015 at 11:52 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Mon, 11 May 2015, Barry Rowlingson wrote:
>
>> If you go far enough into the file (which appears to be without line
>> breaks, so somewhere on line 1... You'll see:
>>
>> "arcs":[[[7533,1255],[-1,8],[0,4],[2,3],[-1,8],[2,2],[-2,2],[-1,0],[-1,1] .....
>>
>> which I think is the geometry (arcs have a start point and then x-y deltas).
>
> Support for geometries like these may be coming to OGR, I think curves
> were also discussed. Using the converter here seems the best way forward.

Following the info from the original source of this file I see someone
has already done the conversion for us:

https://github.com/martinjc/UK-GeoJSON

contains admin boundaries for various UK electoral regions, as plain
geojson and topojson.

Sadly none of this affects the outcome of the election :(

Barry


From brendan.malone at sydney.edu.au  Tue May 12 08:23:35 2015
From: brendan.malone at sydney.edu.au (Brendan Malone)
Date: Tue, 12 May 2015 06:23:35 +0000
Subject: [R-sig-Geo] Raster package issue when using calc and clusterR
Message-ID: <uuelc3t96ntpajfibppwedlj.1431411811167@email.android.com>



Hi everyone,

I have come into a bit of a problem when using the clusterR function from raster. My problem is on a much larger scale but I can recreate it more-or-less with the example below:

require(raster)
a <- raster(matrix(c(12,11,11,
                     11,11,11,
                     11,11,13),nrow=3))

b <- raster(matrix(c(12,12,12,
                     11,12,12,
                     14,12,13),nrow=3))

c <- raster(matrix(c(13,9,13,
                     11,13,13,
                     13,11,13),nrow=3))

d <- raster(matrix(c(10,10,10,
                     11,10,10,
                     10,10,10),nrow=3))

stk <- stack(a,b,c,d)

#works
calc(stk, function(x) tabulate(x, nbins=15))

#works
beginCluster(3)
f1<- function(x) tabulate(x, nbins=15)
clusterR(stk, calc, args=list(fun=f1))
endCluster()

#Does not work
beginCluster(3)
param<- 15
f1<- function(x) tabulate(x, nbins=param)
clusterR(stk, calc, args=list(fun=f1, param=15))
endCluster()

#Does not work
beginCluster(3)
param<- 15
f1<- function(x) tabulate(x, nbins=param)
clusterR(stk, calc, args=list(fun=f1))
endCluster()


I am a little mystified as to why the last two examples do not work. Ideally in this example I would like to change the number of bins on the fly, but presently I cannot and do not know why. The scale of my problem really requires me to use the clusterR function.
 Maybe the answer is glaring me in the face. Maybe someone could share their wisdom on this perhaps.

Regards,

Brendan


	[[alternative HTML version deleted]]


From rafael.wueest at gmail.com  Tue May 12 09:34:10 2015
From: rafael.wueest at gmail.com (=?windows-1252?Q?Rafael_W=FCest?=)
Date: Tue, 12 May 2015 09:34:10 +0200
Subject: [R-sig-Geo] Raster package issue when using calc and clusterR
In-Reply-To: <uuelc3t96ntpajfibppwedlj.1431411811167@email.android.com>
References: <uuelc3t96ntpajfibppwedlj.1431411811167@email.android.com>
Message-ID: <5551ACF2.3030904@gmail.com>

Hi Malone

try the export argument of the clusterR function.

beginCluster(3)
param<- 15
f1<- function(x) tabulate(x, nbins=param)
clusterR(stk, calc, args=list(fun=f1), export = 'param')
endCluster()

Is this what you are after?

HTH, Rafael

On 12/05/2015 08:23, Brendan Malone wrote:
>
>
> Hi everyone,
>
> I have come into a bit of a problem when using the clusterR function from raster. My problem is on a much larger scale but I can recreate it more-or-less with the example below:
>
> require(raster)
> a <- raster(matrix(c(12,11,11,
>                       11,11,11,
>                       11,11,13),nrow=3))
>
> b <- raster(matrix(c(12,12,12,
>                       11,12,12,
>                       14,12,13),nrow=3))
>
> c <- raster(matrix(c(13,9,13,
>                       11,13,13,
>                       13,11,13),nrow=3))
>
> d <- raster(matrix(c(10,10,10,
>                       11,10,10,
>                       10,10,10),nrow=3))
>
> stk <- stack(a,b,c,d)
>
> #works
> calc(stk, function(x) tabulate(x, nbins=15))
>
> #works
> beginCluster(3)
> f1<- function(x) tabulate(x, nbins=15)
> clusterR(stk, calc, args=list(fun=f1))
> endCluster()
>
> #Does not work
> beginCluster(3)
> param<- 15
> f1<- function(x) tabulate(x, nbins=param)
> clusterR(stk, calc, args=list(fun=f1, param=15))
> endCluster()
>
> #Does not work
> beginCluster(3)
> param<- 15
> f1<- function(x) tabulate(x, nbins=param)
> clusterR(stk, calc, args=list(fun=f1))
> endCluster()
>
>
> I am a little mystified as to why the last two examples do not work. Ideally in this example I would like to change the number of bins on the fly, but presently I cannot and do not know why. The scale of my problem really requires me to use the clusterR function.
>   Maybe the answer is glaring me in the face. Maybe someone could share their wisdom on this perhaps.
>
> Regards,
>
> Brendan
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Rafael W?est
rafael.wueest at gmail.com
http://www.rowueest.net


From martin.brandt at mailbox.org  Tue May 12 15:28:08 2015
From: martin.brandt at mailbox.org (Martin Brandt)
Date: Tue, 12 May 2015 06:28:08 -0700 (MST)
Subject: [R-sig-Geo] summing rasters with a condition given by other
	rasters
In-Reply-To: <ACF6B42D-3412-40E6-B88C-02835C07A218@bigelow.org>
References: <1431186891305-7588222.post@n2.nabble.com>
	<930D04EF-2AAC-43C5-8F50-48E109E587E4@bigelow.org>
	<1431257864941-7588226.post@n2.nabble.com>
	<C14A32AC-C486-4515-A723-3F456424A8B6@bigelow.org>
	<1431290544770-7588233.post@n2.nabble.com>
	<ACF6B42D-3412-40E6-B88C-02835C07A218@bigelow.org>
Message-ID: <1431437288303-7588242.post@n2.nabble.com>

Hi Ben,

this works perfectly! thanks a lot for your help!

cheers,
Martin




--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/summing-rasters-with-a-condition-given-by-other-rasters-tp7588222p7588242.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From bibiko at eva.mpg.de  Tue May 12 19:07:17 2015
From: bibiko at eva.mpg.de (=?utf-8?Q?Hans-J=C3=B6rg_Bibiko?=)
Date: Tue, 12 May 2015 19:07:17 +0200
Subject: [R-sig-Geo] Replace a polygon by a new one of a
	SpatialPolygonsDataFrame
Message-ID: <AD627E01-3DD6-4146-9056-74F3903D81AF@eva.mpg.de>

Dear all,

I believe I do not see the forest for the trees. Since hours I've been trying something very basal. Maybe someone could give me an hint.

Imaging the following scenario:

I have a SpatialPolygonsDataFrame which contains lots of spatial polygons and associated data. Now I'd like to replace one polygon (a list of a Polygons-class) of that SpatialPolygonsDataFrame by a new one. How can I do this.


Here is a very na?ve, reproducible example:

Task: Replace the Polygons showing "Western Sahara" of the data set "world_simpl" by a new one which only shows its rectangle (bbox).

---------------------------------------------------------------
library(maptools)
data(wrld_simpl)

#wrld_simpl[237,] := Western Sahara
r <- bbox(wrld_simpl[237,])

theID <- wrld_simpl[237,]@polygons[[1]]@ID

# create the new spatial polygon (a rectangle of bbox coordinates) 
theNew <- list(Polygons(list(Polygon(cbind(c(r[1,1],r[1,1],r[1,2],r[1,2]),c(r[2,1],r[2,2],r[2,2],r[2,1])))), theID))

# now I thought that one can do the this:
wrld_simpl[237,]@polygons <- theNew

---------------------------------------------------------------

But the last line does't work albeit the class and list resp. are of the same structure. :/

Old:
> str(wrld_simpl[237,]@polygons)
List of 1
 $ :Formal class 'Polygons' [package "sp"] with 5 slots
  .. ..@ Polygons :List of 1
  .. .. ..$ :Formal class 'Polygon' [package "sp"] with 5 slots
  .. .. .. .. ..@ labpt  : num [1:2] -13.1 24.7
  .. .. .. .. ..@ area   : num 24
  .. .. .. .. ..@ hole   : logi FALSE
  .. .. .. .. ..@ ringDir: int 1
  .. .. .. .. ..@ coords : num [1:23, 1:2] -15.7 -17 -17.1 -16.9 -16.7 ...
  .. ..@ plotOrder: int 1
  .. ..@ labpt    : num [1:2] -13.1 24.7
  .. ..@ ID       : chr "ESH"
  .. ..@ area     : num 24


New:
> str(theNew)
List of 1
 $ :Formal class 'Polygons' [package "sp"] with 5 slots
  .. ..@ Polygons :List of 1
  .. .. ..$ :Formal class 'Polygon' [package "sp"] with 5 slots
  .. .. .. .. ..@ labpt  : num [1:2] -14.3 10.5
  .. .. .. .. ..@ area   : num 159
  .. .. .. .. ..@ hole   : logi FALSE
  .. .. .. .. ..@ ringDir: int 1
  .. .. .. .. ..@ coords : num [1:5, 1:2] -17.05 -17.05 -8.67 -8.67 -17.05 ...
  .. ..@ plotOrder: int 1
  .. ..@ labpt    : num [1:2] -14.3 10.5
  .. ..@ ID       : chr "ESH"
  .. ..@ area     : num 159

?

I really appreciate any help someone can provide!

Cheers, Hans


From b.rowlingson at lancaster.ac.uk  Tue May 12 19:23:28 2015
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 12 May 2015 18:23:28 +0100
Subject: [R-sig-Geo] Replace a polygon by a new one of a
	SpatialPolygonsDataFrame
In-Reply-To: <AD627E01-3DD6-4146-9056-74F3903D81AF@eva.mpg.de>
References: <AD627E01-3DD6-4146-9056-74F3903D81AF@eva.mpg.de>
Message-ID: <CANVKczOqfm9Q6=OSPNSDaVod_og6Jtx=JHxbnmrGY_3=z6v8rQ@mail.gmail.com>

This works: create a new SpatialPolygonsDataFrame with just your new
geometry, copying the data from the old geometry, and then use cbind
and selection to create a new object:

theNew <- list(Polygons(list(Polygon(cbind(c(r[1,1],r[1,1],r[1,2],r[1,2],r[1,1]),c(r[2,1],r[2,2],r[2,2],r[2,1],r[2,1])))),
theID))
# just the ws row:
ws = wrld_simpl[237,]

# create a single row SPDF with new geom and old data:
wsb = SpatialPolygonsDataFrame(SpatialPolygons(theNew),data=ws at data)
proj4string(wsb)=proj4string(wrld_simpl)

# create complete new object:
wrld_simpl=rbind(wrld_simpl[-237,], wsb)

(note I had to change your construction of theNew since I got a
"polygon not closed" error).

as written the wsb row will be at the end, but you can tweak that with
some clever subsetting and indexing.


Barry



On Tue, May 12, 2015 at 6:07 PM, Hans-J?rg Bibiko <bibiko at eva.mpg.de> wrote:
> Dear all,
>
> I believe I do not see the forest for the trees. Since hours I've been trying something very basal. Maybe someone could give me an hint.
>
> Imaging the following scenario:
>
> I have a SpatialPolygonsDataFrame which contains lots of spatial polygons and associated data. Now I'd like to replace one polygon (a list of a Polygons-class) of that SpatialPolygonsDataFrame by a new one. How can I do this.
>
>
> Here is a very na?ve, reproducible example:
>
> Task: Replace the Polygons showing "Western Sahara" of the data set "world_simpl" by a new one which only shows its rectangle (bbox).
>
> ---------------------------------------------------------------
> library(maptools)
> data(wrld_simpl)
>
> #wrld_simpl[237,] := Western Sahara
> r <- bbox(wrld_simpl[237,])
>
> theID <- wrld_simpl[237,]@polygons[[1]]@ID
>
> # create the new spatial polygon (a rectangle of bbox coordinates)
> theNew <- list(Polygons(list(Polygon(cbind(c(r[1,1],r[1,1],r[1,2],r[1,2]),c(r[2,1],r[2,2],r[2,2],r[2,1])))), theID))
>
> # now I thought that one can do the this:
> wrld_simpl[237,]@polygons <- theNew
>
> ---------------------------------------------------------------
>
> But the last line does't work albeit the class and list resp. are of the same structure. :/
>
> Old:
>> str(wrld_simpl[237,]@polygons)
> List of 1
>  $ :Formal class 'Polygons' [package "sp"] with 5 slots
>   .. ..@ Polygons :List of 1
>   .. .. ..$ :Formal class 'Polygon' [package "sp"] with 5 slots
>   .. .. .. .. ..@ labpt  : num [1:2] -13.1 24.7
>   .. .. .. .. ..@ area   : num 24
>   .. .. .. .. ..@ hole   : logi FALSE
>   .. .. .. .. ..@ ringDir: int 1
>   .. .. .. .. ..@ coords : num [1:23, 1:2] -15.7 -17 -17.1 -16.9 -16.7 ...
>   .. ..@ plotOrder: int 1
>   .. ..@ labpt    : num [1:2] -13.1 24.7
>   .. ..@ ID       : chr "ESH"
>   .. ..@ area     : num 24
>
>
> New:
>> str(theNew)
> List of 1
>  $ :Formal class 'Polygons' [package "sp"] with 5 slots
>   .. ..@ Polygons :List of 1
>   .. .. ..$ :Formal class 'Polygon' [package "sp"] with 5 slots
>   .. .. .. .. ..@ labpt  : num [1:2] -14.3 10.5
>   .. .. .. .. ..@ area   : num 159
>   .. .. .. .. ..@ hole   : logi FALSE
>   .. .. .. .. ..@ ringDir: int 1
>   .. .. .. .. ..@ coords : num [1:5, 1:2] -17.05 -17.05 -8.67 -8.67 -17.05 ...
>   .. ..@ plotOrder: int 1
>   .. ..@ labpt    : num [1:2] -14.3 10.5
>   .. ..@ ID       : chr "ESH"
>   .. ..@ area     : num 159
>
> ?
>
> I really appreciate any help someone can provide!
>
> Cheers, Hans
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From edzer.pebesma at uni-muenster.de  Tue May 12 19:48:03 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 12 May 2015 19:48:03 +0200
Subject: [R-sig-Geo] Replace a polygon by a new one of a
	SpatialPolygonsDataFrame
In-Reply-To: <AD627E01-3DD6-4146-9056-74F3903D81AF@eva.mpg.de>
References: <AD627E01-3DD6-4146-9056-74F3903D81AF@eva.mpg.de>
Message-ID: <55523CD3.3040302@uni-muenster.de>

On 05/12/2015 07:07 PM, Hans-J?rg Bibiko wrote:
> Dear all,
> 
> I believe I do not see the forest for the trees. Since hours I've been trying something very basal. Maybe someone could give me an hint.
> 
> Imaging the following scenario:
> 
> I have a SpatialPolygonsDataFrame which contains lots of spatial polygons and associated data. Now I'd like to replace one polygon (a list of a Polygons-class) of that SpatialPolygonsDataFrame by a new one. How can I do this.
> 
> 
> Here is a very na?ve, reproducible example:
> 
> Task: Replace the Polygons showing "Western Sahara" of the data set "world_simpl" by a new one which only shows its rectangle (bbox).
> 
> ---------------------------------------------------------------
> library(maptools)
> data(wrld_simpl)
> 
> #wrld_simpl[237,] := Western Sahara
> r <- bbox(wrld_simpl[237,])
> 
> theID <- wrld_simpl[237,]@polygons[[1]]@ID
> 
> # create the new spatial polygon (a rectangle of bbox coordinates) 
> theNew <- list(Polygons(list(Polygon(cbind(c(r[1,1],r[1,1],r[1,2],r[1,2]),c(r[2,1],r[2,2],r[2,2],r[2,1])))), theID))
> 
> # now I thought that one can do the this:
> wrld_simpl[237,]@polygons <- theNew

The "[<-" method for Spatial* objects is limited to work on attributes.
Try:

wrld_simpl at polygons[237] <- theNew

> 
> ---------------------------------------------------------------
> 
> But the last line does't work albeit the class and list resp. are of the same structure. :/
> 
> Old:
>> str(wrld_simpl[237,]@polygons)
> List of 1
>  $ :Formal class 'Polygons' [package "sp"] with 5 slots
>   .. ..@ Polygons :List of 1
>   .. .. ..$ :Formal class 'Polygon' [package "sp"] with 5 slots
>   .. .. .. .. ..@ labpt  : num [1:2] -13.1 24.7
>   .. .. .. .. ..@ area   : num 24
>   .. .. .. .. ..@ hole   : logi FALSE
>   .. .. .. .. ..@ ringDir: int 1
>   .. .. .. .. ..@ coords : num [1:23, 1:2] -15.7 -17 -17.1 -16.9 -16.7 ...
>   .. ..@ plotOrder: int 1
>   .. ..@ labpt    : num [1:2] -13.1 24.7
>   .. ..@ ID       : chr "ESH"
>   .. ..@ area     : num 24
> 
> 
> New:
>> str(theNew)
> List of 1
>  $ :Formal class 'Polygons' [package "sp"] with 5 slots
>   .. ..@ Polygons :List of 1
>   .. .. ..$ :Formal class 'Polygon' [package "sp"] with 5 slots
>   .. .. .. .. ..@ labpt  : num [1:2] -14.3 10.5
>   .. .. .. .. ..@ area   : num 159
>   .. .. .. .. ..@ hole   : logi FALSE
>   .. .. .. .. ..@ ringDir: int 1
>   .. .. .. .. ..@ coords : num [1:5, 1:2] -17.05 -17.05 -8.67 -8.67 -17.05 ...
>   .. ..@ plotOrder: int 1
>   .. ..@ labpt    : num [1:2] -14.3 10.5
>   .. ..@ ID       : chr "ESH"
>   .. ..@ area     : num 159
> 
> ?
> 
> I really appreciate any help someone can provide!
> 
> Cheers, Hans
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info



-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150512/6cc7b8a7/attachment.bin>

From bibiko at eva.mpg.de  Tue May 12 20:19:14 2015
From: bibiko at eva.mpg.de (=?iso-8859-1?Q?Hans-J=F6rg_Bibiko?=)
Date: Tue, 12 May 2015 20:19:14 +0200
Subject: [R-sig-Geo] Replace a polygon by a new one of a
	SpatialPolygonsDataFrame
In-Reply-To: <55523CD3.3040302@uni-muenster.de>
References: <AD627E01-3DD6-4146-9056-74F3903D81AF@eva.mpg.de>
	<55523CD3.3040302@uni-muenster.de>
Message-ID: <4B85CC51-73BA-4F31-9F79-5EAA6E02B402@eva.mpg.de>

Thanks a lot!!!

@Edzer: wrld_simpl at polygons[237] <- theNew
doesn't work. Also due to [<- declaration

@Barry: Yes, removing the old entry and adding the new one via rbind works :) - of course. The clue is to recreate the entire SpatialPolygonsDataFrame. (And sorry for a non-closed polygon ;) )

For the records, I ended up with the following (also in terms of not changing the plot order and the indices):

library(maptools)
data(wrld_simpl)

r <- bbox(wrld_simpl[237,])

theID <- wrld_simpl[237,]@polygons[[1]]@ID

theNew <- list(Polygons(list(
	Polygon(cbind(c(r[1,1],r[1,1],r[1,2],r[1,2],r[1,1]),c(r[2,1],r[2,2],r[2,2],r[2,1],r[2,1])))), 
	theID))

# item which has to be replaced
replace_index <- 237

ws <- wrld_simpl[replace_index,]
wsb <- SpatialPolygonsDataFrame(SpatialPolygons(theNew), data=ws at data)
proj4string(wsb) <- proj4string(wrld_simpl)

wrld_simpl_new <- rbind(wrld_simpl[1:(replace_index-1),], wsb, 
	wrld_simpl[(replace_index+1):dim(wrld_simpl)[1],])

wrld_simpl_new at plotOrder <- wrld_simpl at plotOrder

plot(wrld_simpl[237, ])
plot(wrld_simpl_new[237,], border="red", add=T)


Again, thanks a lot, you saved my day :)

Best, Hans


From bibiko at eva.mpg.de  Tue May 12 21:00:00 2015
From: bibiko at eva.mpg.de (=?utf-8?Q?Hans-J=C3=B6rg_Bibiko?=)
Date: Tue, 12 May 2015 21:00:00 +0200
Subject: [R-sig-Geo] Replace a polygon by a new one of a
	SpatialPolygonsDataFrame [CORRECTION]
In-Reply-To: <4B85CC51-73BA-4F31-9F79-5EAA6E02B402@eva.mpg.de>
References: <AD627E01-3DD6-4146-9056-74F3903D81AF@eva.mpg.de>
	<55523CD3.3040302@uni-muenster.de>
	<4B85CC51-73BA-4F31-9F79-5EAA6E02B402@eva.mpg.de>
Message-ID: <CD91F36D-7492-4A5B-BB9B-A5A6792F85B8@eva.mpg.de>

!! CORRECTION !!

> @Edzer: wrld_simpl at polygons[237] <- theNew
> doesn't work. Also due to [<- declaration

This is NOT true since I tried unfortunately 

wrld_simpl[237] <- theNew

instead of

wrld_simpl at polygons[237] <- theNew


As Edzer suggested this works like a charm! 

To reproduce it, here is the code:

library(maptools)
data(wrld_simpl)

plot(wrld_simpl[237,])

r <- bbox(wrld_simpl[237,])

theID <- wrld_simpl[237,]@polygons[[1]]@ID

theNew <- list(Polygons(list(
	Polygon(cbind(c(r[1,1],r[1,1],r[1,2],r[1,2],r[1,1]),c(r[2,1],r[2,2],r[2,2],r[2,1],r[2,1])))), 
	theID))

wrld_simpl at polygons[237] <- theNew

plot(wrld_simpl[237,], border="red", add=T)


Sorry for the confusion!

Notwithstanding many thanks!

Kind regards, Hans

From antonio.rrz at gmail.com  Wed May 13 21:18:46 2015
From: antonio.rrz at gmail.com (Antonio Rodriges)
Date: Wed, 13 May 2015 22:18:46 +0300
Subject: [R-sig-Geo] Multiply 2 raster without considering cells with NA
In-Reply-To: <1431210957367-7588224.post@n2.nabble.com>
References: <1431210957367-7588224.post@n2.nabble.com>
Message-ID: <CAPrLoNcAwEJed2grSQMqwa+8o-pQwWo9141n=yv1HvrJVCVZ0A@mail.gmail.com>

Try smth like this (I did not run that and not sure in syntax)
r <- overlay(MeanT, cumulP, fun=function(x,y){if (isNA(x) || isNA(y))
return NA else return(y/(x+10))})
Kind regards,
Antonio Rodriges


2015-05-10 1:35 GMT+03:00 sadaoui <sadaouimahrez at outlook.com>:
> Hello,
>
> I try to multiply 2 raster (temperature and precipitation) with "overay"
> function, but the problem at the same time it multiplies the NA values, then
> it gives a false result.
>
> I tried with this code ;
>
> library(raster) ;
> T = getData('worldclim', var='tmean', res=0.5, lon=5, lat=45)/10
> MeanT=mean(T)
> MeanT
> # values      : -11.60833, 23.35833  (min, max)
>
> P= getData('worldclim', var='prec', res=0.5, lon=5, lat=45)
> cumulP=sum(P) #values      : 10, 2883  (min, max)
>
> r <- overlay(MeanT, cumulP, fun=function(x,y){return(y/(x+10))})
> r # values      : -108000, 318000  (min, max)
>
> Normally I find the results : ~[0-120]
>
> I searched this page :
> http://www.inside-r.org/packages/cran/raster/docs/overlay
> but is not mentioned.
>
> it is mentioned in the  the "calc" function  but it is applicable only for a
> single raster : http://www.inside-r.org/packages/cran/raster/docs/calc
>
> Thank you in advance for helping me make a calculation between two raster
> without counting NA values.
>
> Best regards
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Multiply-2-raster-without-considering-cells-with-NA-tp7588224.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Thu May 14 03:29:12 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 13 May 2015 18:29:12 -0700
Subject: [R-sig-Geo] Multiply 2 raster without considering cells with NA
In-Reply-To: <CAPrLoNcAwEJed2grSQMqwa+8o-pQwWo9141n=yv1HvrJVCVZ0A@mail.gmail.com>
References: <1431210957367-7588224.post@n2.nabble.com>
	<CAPrLoNcAwEJed2grSQMqwa+8o-pQwWo9141n=yv1HvrJVCVZ0A@mail.gmail.com>
Message-ID: <CANtt_hz4uMrw=fnJxrmCVtnn4Roi4e4gdZwebd00doySFf+t7g@mail.gmail.com>

These would seem to be plausible, and correct, values. I do not think
there is anything wrong NA values. The extreme values are because you
divide by a fraction. How would you expect the results to be
non-negative if you divide by negative values?

Antonio's answer is incorrect, as division with an NA value already
returns an NA value, there is no need to add a conditional statement
to deal with that.

You could use calc by first using stack, but overlay is probably clearer here.

Or use an algebraic formulation:

r <- cumulP / (MeanT+10)

Robert

On Wed, May 13, 2015 at 12:18 PM, Antonio Rodriges
<antonio.rrz at gmail.com> wrote:
> Try smth like this (I did not run that and not sure in syntax)
> r <- overlay(MeanT, cumulP, fun=function(x,y){if (isNA(x) || isNA(y))
> return NA else return(y/(x+10))})
> Kind regards,
> Antonio Rodriges
>
>
> 2015-05-10 1:35 GMT+03:00 sadaoui <sadaouimahrez at outlook.com>:
>> Hello,
>>
>> I try to multiply 2 raster (temperature and precipitation) with "overay"
>> function, but the problem at the same time it multiplies the NA values, then
>> it gives a false result.
>>
>> I tried with this code ;
>>
>> library(raster) ;
>> T = getData('worldclim', var='tmean', res=0.5, lon=5, lat=45)/10
>> MeanT=mean(T)
>> MeanT
>> # values      : -11.60833, 23.35833  (min, max)
>>
>> P= getData('worldclim', var='prec', res=0.5, lon=5, lat=45)
>> cumulP=sum(P) #values      : 10, 2883  (min, max)
>>
>> r <- overlay(MeanT, cumulP, fun=function(x,y){return(y/(x+10))})
>> r # values      : -108000, 318000  (min, max)
>>
>> Normally I find the results : ~[0-120]
>>
>> I searched this page :
>> http://www.inside-r.org/packages/cran/raster/docs/overlay
>> but is not mentioned.
>>
>> it is mentioned in the  the "calc" function  but it is applicable only for a
>> single raster : http://www.inside-r.org/packages/cran/raster/docs/calc
>>
>> Thank you in advance for helping me make a calculation between two raster
>> without counting NA values.
>>
>> Best regards
>>
>>
>>
>> --
>> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Multiply-2-raster-without-considering-cells-with-NA-tp7588224.html
>> Sent from the R-sig-geo mailing list archive at Nabble.com.
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From dupouey at nancy.inra.fr  Thu May 14 23:48:35 2015
From: dupouey at nancy.inra.fr (Jean-Luc Dupouey)
Date: Thu, 14 May 2015 23:48:35 +0200
Subject: [R-sig-Geo] gIntersection versus intersect
Message-ID: <55551833.7030307@nancy.inra.fr>

For intersecting two polygon layers, is there any advantage of using 
gIntersection (from the rgeos package) instead of intersect (from the 
raster package)? After a few tests, it appears that intersect is a 
little bit faster. Moreover, intersect automatically calculates the 
associated dataframe, while gIntersection leaves the user making it.

Thanks for your awer(s).

Jean-Luc


From r.hijmans at gmail.com  Fri May 15 05:39:36 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 14 May 2015 20:39:36 -0700
Subject: [R-sig-Geo] gIntersection versus intersect
In-Reply-To: <55551833.7030307@nancy.inra.fr>
References: <55551833.7030307@nancy.inra.fr>
Message-ID: <CANtt_hw4OEf8VSEyfWDw6TgmO1a_iDgOijcMh3baqzEbu3kCMA@mail.gmail.com>

Jean-Luc.

It is as you say, intersect returns Spatial*DataFrame objects whereas
gIntersect does not the DataFrame bits.
This pattern is also true for raster functions aggregate, union,
erase, cover and crop (see section XIV in ?'raster-package') which all
have their analogues in rgeos that they build on.
intersect uses gIntersection so it should not be faster.

Robert

On Thu, May 14, 2015 at 2:48 PM, Jean-Luc Dupouey <dupouey at nancy.inra.fr> wrote:
> For intersecting two polygon layers, is there any advantage of using
> gIntersection (from the rgeos package) instead of intersect (from the raster
> package)? After a few tests, it appears that intersect is a little bit
> faster. Moreover, intersect automatically calculates the associated
> dataframe, while gIntersection leaves the user making it.
>
> Thanks for your awer(s).
>
> Jean-Luc
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From kimofos at yahoo.com  Fri May 15 11:43:59 2015
From: kimofos at yahoo.com (Mohammad Abdel-Razek)
Date: Fri, 15 May 2015 09:43:59 +0000 (UTC)
Subject: [R-sig-Geo] Converting large RasterStack to CSVs fast
Message-ID: <2063927095.199245.1431683039822.JavaMail.yahoo@mail.yahoo.com>

Hi
I got a function to convert ndvi raster stack to CSVs. Each stack is divided into 100 subset, which is convert to csv. The code works for small raster stack, for large ones, I cannot load them into the memory, then it takes massive time to do the task. 

is there a better way to do it? 

The code is below:

require(gdal) 
require(raster) 

exportCSV <- function () { 
? tif <- list.files(pattern='NDVI.tif$') 
? wd <- getwd() 
? ModisTile<-? substr(wd, nchar(wd)-5, nchar(wd)) 
? nImages <- length(tif) 
? cat(paste("Stacking images ...", "\n")) 
? s <- stack(tif) 
? cat(paste("Loading values to RAM memory ...", "\n")) 
#this step is skipped in case of large stacks, then it takes very long time 
? s <- readAll(s) 
#create the subsets bounding coordinates 
? borders <- extent(s) 
? Xmin <- borders at xmin 
? Xmax <- borders at xmax 
? Ymin <- borders at ymin 
? Ymax <- borders at ymax 
? xIncreament <-(Xmax-Xmin)/10 
? yIncreament <-(Ymax-Ymin)/10 
? cat(paste("Subsetting and writing NDVI values ...", "\n")) 
? for (i in 1:10) { 
??? for (j in 1:10) { 
????? clip_xmin <- Xmin + xIncreament*(i-1) 
????? clip_xmax <- Xmin + xIncreament*i 
????? clip_ymin <- Ymin + yIncreament*(j-1) 
????? clip_ymax <- Ymin + yIncreament*j 
????? c_xmin <- format(round(clip_xmin,6), nsmall=6) 
????? c_xmax <- format(round(clip_xmax,6), nsmall=6) 
????? c_ymin <- format(round(clip_ymin,6), nsmall=6) 
????? c_ymax <- format(round(clip_ymax,6), nsmall=6)???? 
????? 
????? subset <- extent(c(clip_xmin, clip_xmax, clip_ymin, clip_ymax)) 
????? c <- crop(s, subset) 
????? p <- as.data.frame(rasterToPoints(c)) 
????? csvName <- paste0(ModisTile, "_Xmin_",c_xmin, "_Xmax_",c_xmax, "_Ymin_",c_ymin, "_Ymax_",c_ymax,".csv") 
????? cat(paste("Writing Subset... MOIDS Tile:", ModisTile,", X", i, "Y", j, "\n")) 
????? write.table(p, csvName, row.names=F, sep=";", dec=".") 
??? } 
? } 
} 

Best, 
Mohammad?PhD Candidate  Institute of Crop Science and Resource Protection - Crop Science Research Group
Katzenburgweg 5 - 53115 Bonn - Germany
 Tel.: +49 (0) 228 73 3258?????? Fax: +49 (0) 228 73 2870
abdelrazek at uni-bonn.de??????? http://www.lap.uni-bonn.de

	[[alternative HTML version deleted]]


From comunello.eder at gmail.com  Fri May 15 13:41:57 2015
From: comunello.eder at gmail.com (=?UTF-8?Q?=C3=89der_Comunello?=)
Date: Fri, 15 May 2015 07:41:57 -0400
Subject: [R-sig-Geo] Issue with ogrInfo
Message-ID: <CABmC8g=ZAFGTu=RJ6BaZjD76gstYwrRJ=rRPqPCuE6WDKVkaqQ@mail.gmail.com>

Hello,

I think the problem is that your link is recovering only html code from
github site. It's necessary to modify it to get the "real" JSON file.

### <code r>
sapply(c("rgeos", "maptools", "rgdal"), require, char=T)
url0 <- "
https://github.com/kjhealy/uk-elections/blob/master/maps/topo_wpc.json"
download.file(url0, dest=basename(url0), mode="wb")
# downloaded 26 KB

uk.map <- readOGR(basename(url0), "wpc")
# Error in ogrInfo(dsn = dsn, layer = layer, encoding = encoding, use_iconv
= use_iconv,  :
#   Cannot open file

url1 <- "
https://raw.githubusercontent.com/kjhealy/uk-elections/master/maps/topo_wpc.json
"
download.file(url1, dest=basename(url0), mode="wb")
# downloaded 2.3 MB

uk.map <- readOGR(basename(url1), "wpc")
# OGR data source with driver: GeoJSON
# Source: "topo_wpc.json", layer: "wpc"
# with 632 features
# It has 2 fields

plot(uk.map)
### </code>

?der Comunello <c <comunello.eder at gmail.com>omunello.eder at gmail.com>
Dourados, MS - [22 16.5'S, 54 49'W]

	[[alternative HTML version deleted]]


From comunello.eder at gmail.com  Fri May 15 18:35:44 2015
From: comunello.eder at gmail.com (=?UTF-8?Q?=C3=89der_Comunello?=)
Date: Fri, 15 May 2015 12:35:44 -0400
Subject: [R-sig-Geo] Converting large RasterStack to CSVs fast
In-Reply-To: <2063927095.199245.1431683039822.JavaMail.yahoo@mail.yahoo.com>
References: <2063927095.199245.1431683039822.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CABmC8gmd8aV6WBRpXRGnwbmRht8Z_MX3WWd9=N999RzoaZVoRA@mail.gmail.com>

Hello, Mohammad!

You may have some improvement in performance avoiding "for statements" and
using a "vectorized" code. You could try something like the code below.

If you can test with your data, i would appreciate if you inform the
results.

### <code r>
require(rgdal); require(raster)

getwd()
### download some data to test
getData("worldclim", var = "tmin", res = 10) ### tmin
fn <- dir("wc10", patt=".bil$", full=T)
fn <- fn[order(nchar(fn), fn)]; fn
#  [1] "wc10/tmin1.bil"  "wc10/tmin2.bil"  "wc10/tmin3.bil"  ...

### read images
s <- stack(fn) ### dimensions  : 900, 2160, 1944000, 12  (nrow, ncol,
ncell, nlayers)
fromDisk(s)

### extents of subsets
bor <- extent(s); bor
res <- 45 ### subsets resolution
X   <- unique(c(seq(bor at xmin, bor at xmax, by=res), bor at xmax)); X
Y   <- unique(c(seq(bor at ymin, bor at ymax, by=res), bor at ymax)); Y
ext <- cbind(expand.grid(Xmin=X[-length(X)], Ymin=Y[-length(Y)]),
             expand.grid(Xmax=X[-1], Ymax=Y[-1]))[,c(1,3,2,4)]
head(ext); nrow(ext)

plot(s, 1)
system.time(
sapply(1:nrow(ext), function(i) {
     mask <- ext[i,]
     subset <- with(mask, extent(c(Xmin, Xmax, Ymin, Ymax)))
     plot(subset, add=T)
     text(rowMeans(mask[,1:2]), rowMeans(mask[,3:4]), lab=i)
     c <- crop(s, subset)
     write.table(as.data.frame(rasterToPoints(c)), paste0("p",i,".txt"), )
}))
#    user  system elapsed
#  213.79    7.00  224.94

txt <- dir(patt="^p[0-9]+.txt$")
txt <- txt[order(nchar(txt), txt)]; txt
#  [1] "p1.txt"  "p2.txt"  "p3.txt"  "p4.txt"  ...

### </code>


Cheers,

?der Comunello <c <comunello.eder at gmail.com>omunello.eder at gmail.com>
Dourados, MS - [22 16.5'S, 54 49'W]



?der Comunello <c <comunello.eder at gmail.com>omunello.eder at gmail.com>
Dourados, MS - [22 16.5'S, 54 49'W]

2015-05-15 5:43 GMT-04:00 Mohammad Abdel-Razek via R-sig-Geo <
r-sig-geo at r-project.org>:

> Hi
> I got a function to convert ndvi raster stack to CSVs. Each stack is
> divided into 100 subset, which is convert to csv. The code works for small
> raster stack, for large ones, I cannot load them into the memory, then it
> takes massive time to do the task.
>
> is there a better way to do it?
>
> The code is below:
>
> require(gdal)
> require(raster)
>
> exportCSV <- function () {
>   tif <- list.files(pattern='NDVI.tif$')
>   wd <- getwd()
>   ModisTile<-  substr(wd, nchar(wd)-5, nchar(wd))
>   nImages <- length(tif)
>   cat(paste("Stacking images ...", "\n"))
>   s <- stack(tif)
>   cat(paste("Loading values to RAM memory ...", "\n"))
> #this step is skipped in case of large stacks, then it takes very long time
>   s <- readAll(s)
> #create the subsets bounding coordinates
>   borders <- extent(s)
>   Xmin <- borders at xmin
>   Xmax <- borders at xmax
>   Ymin <- borders at ymin
>   Ymax <- borders at ymax
>   xIncreament <-(Xmax-Xmin)/10
>   yIncreament <-(Ymax-Ymin)/10
>   cat(paste("Subsetting and writing NDVI values ...", "\n"))
>   for (i in 1:10) {
>     for (j in 1:10) {
>       clip_xmin <- Xmin + xIncreament*(i-1)
>       clip_xmax <- Xmin + xIncreament*i
>       clip_ymin <- Ymin + yIncreament*(j-1)
>       clip_ymax <- Ymin + yIncreament*j
>       c_xmin <- format(round(clip_xmin,6), nsmall=6)
>       c_xmax <- format(round(clip_xmax,6), nsmall=6)
>       c_ymin <- format(round(clip_ymin,6), nsmall=6)
>       c_ymax <- format(round(clip_ymax,6), nsmall=6)
>
>       subset <- extent(c(clip_xmin, clip_xmax, clip_ymin, clip_ymax))
>       c <- crop(s, subset)
>       p <- as.data.frame(rasterToPoints(c))
>       csvName <- paste0(ModisTile, "_Xmin_",c_xmin, "_Xmax_",c_xmax,
> "_Ymin_",c_ymin, "_Ymax_",c_ymax,".csv")
>       cat(paste("Writing Subset... MOIDS Tile:", ModisTile,", X", i, "Y",
> j, "\n"))
>       write.table(p, csvName, row.names=F, sep=";", dec=".")
>     }
>   }
> }
>
> Best,
> Mohammad PhD Candidate  Institute of Crop Science and Resource Protection
> - Crop Science Research Group
> Katzenburgweg 5 - 53115 Bonn - Germany
>  Tel.: +49 (0) 228 73 3258       Fax: +49 (0) 228 73 2870
> abdelrazek at uni-bonn.de        http://www.lap.uni-bonn.de
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From gustavodalposso at hotmail.com  Fri May 15 21:09:07 2015
From: gustavodalposso at hotmail.com (Gustavo Dalposso)
Date: Fri, 15 May 2015 19:09:07 +0000
Subject: [R-sig-Geo] create a shapefile
Message-ID: <SNT152-W5068688FE73BB915BA33D2BBC70@phx.gbl>

Hello friends of R


I have a map in BMP format (a figure).
 The map consists of 14 areas.
 I have the location of two coordinates. (x1, y1) and (x2, y2)
 See the attached image.

 Question: Is it possible to create a shapefile? Which package I use?

Atte.
Gustavo Henrique Dalposso 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150515/df1e9d08/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: map.JPG
Type: image/jpeg
Size: 11778 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150515/df1e9d08/attachment.jpe>

From incorpld at onda.com.br  Fri May 15 21:44:13 2015
From: incorpld at onda.com.br (Felinto COSTA)
Date: Fri, 15 May 2015 16:44:13 -0300
Subject: [R-sig-Geo] create a shapefile
In-Reply-To: <SNT152-W5068688FE73BB915BA33D2BBC70@phx.gbl>
References: <SNT152-W5068688FE73BB915BA33D2BBC70@phx.gbl>
Message-ID: <55564C8D.1040504@onda.com.br>

Gustavo.

Se vc. tiver esse mapa em formato CAD (dxf ou dwg) pode usar o Cad2Shape 
(http://www.guthcad.com.au/cad2shape.htm).
Ele permite algumas utiliza??es em sua vers?o "free".
Se n?o tiver, tente passar para os formatos de CAD usando, talvez, o 
Img2Cad (http://www.img2cad.com/).
J? usei apenas o primeiro.

Felinto COSTA


On 15/5/2015 16:09, Gustavo Dalposso wrote:
> Hello friends of R
>
>
> I have a map in BMP format (a figure).
> The map consists of 14 areas.
> I have the location of two coordinates. (x1, y1) and (x2, y2)
> See the attached image.
>
> Question: Is it possible to create a shapefile? Which package I use?
>
> Atte.
> Gustavo Henrique Dalposso
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


	[[alternative HTML version deleted]]


From mark.vankleunen at uni-konstanz.de  Sat May 16 12:48:05 2015
From: mark.vankleunen at uni-konstanz.de (Mark van Kleunen)
Date: Sat, 16 May 2015 12:48:05 +0200
Subject: [R-sig-Geo] gbif error message in package dismo
Message-ID: <55572065.3090506@uni-konstanz.de>

Hello,

I am trying to use the gbif function to download GBIF records. Half a year
ago, this function worked without any problems, but now I get an error
message that I do not understand. I am using R3.2 for Windows and downloaded
the latest dismo version. If I use the example syntax provided by ?gbif, the
following error message appears.

> gs <- gbif('Batrachoseps', 'luciae', sp=TRUE)

Loading required namespace: jsonlite
0-300-600-900-1200-1500-1800-1928 records
Error in (function (classes, fdef, mtable)  :
   unable to find an inherited method for function ?bind? for signature
?"data.frame", "data.frame"?
  
A Google search for this error message did not reveal anything useful. Does
anyone know how to solve this problem?

best wishes,
Mark


From comunello.eder at gmail.com  Sat May 16 16:53:49 2015
From: comunello.eder at gmail.com (=?UTF-8?Q?=C3=89der_Comunello?=)
Date: Sat, 16 May 2015 10:53:49 -0400
Subject: [R-sig-Geo] gbif error message in package dismo
In-Reply-To: <55572065.3090506@uni-konstanz.de>
References: <55572065.3090506@uni-konstanz.de>
Message-ID: <CABmC8gmndoEH0Q_9xAQxcjPiT5yMRPNyb_C9LFCa6+s8HL=pnA@mail.gmail.com>

Hello, Mark!

I'm using R 3.1.3 and the error is slightly different. In my case I could
solve the problem with a manual conversion.

### <code r>

### The command works when you don't use the argument "sp=T"!
gb   <- gbif('Batrachoseps', 'luciae') # 1928

### The problem would be invalid coordinates in database...
gbif('Batrachoseps', 'luciae', geo=T, sp=T, download=F) # 1928
gb.sp  <- gbif('Batrachoseps', 'luciae', geo=T, sp=T) # Don't work!
# 0-300-600-900-1200-1500-1800-1928 records
# Error in na.fail.default(list(lon = c(-121.94704, -121.85457, -121.57892,
 :
#   missing values in object

### In fact, there are three invalid coordinates that could cause problem
in the sp conversion!
err  <- which(!complete.cases(cbind(gb$lon, gb$lat))) # [1]  647 1892 1894
gb[err, 1:5]

### But you can download the data and use a "manual" conversion...
### First eliminate the problem!
gb.sp <- gb[-err,] # 1925
coordinates(gb.sp) <- ~lon+lat
class(gb.sp) # [1] "SpatialPointsDataFrame"
plot(gb.sp)
### </code>

?der Comunello <c <comunello.eder at gmail.com>omunello.eder at gmail.com>
Dourados, MS - [22 16.5'S, 54 49'W]

2015-05-16 6:48 GMT-04:00 Mark van Kleunen <mark.vankleunen at uni-konstanz.de>
:

> Hello,
>
> I am trying to use the gbif function to download GBIF records. Half a year
> ago, this function worked without any problems, but now I get an error
> message that I do not understand. I am using R3.2 for Windows and
> downloaded
> the latest dismo version. If I use the example syntax provided by ?gbif,
> the
> following error message appears.
>
>  gs <- gbif('Batrachoseps', 'luciae', sp=TRUE)
>>
>
> Loading required namespace: jsonlite
> 0-300-600-900-1200-1500-1800-1928 records
> Error in (function (classes, fdef, mtable)  :
>   unable to find an inherited method for function ?bind? for signature
> ?"data.frame", "data.frame"?
>  A Google search for this error message did not reveal anything useful.
> Does
> anyone know how to solve this problem?
>
> best wishes,
> Mark
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From johnwasige at gmail.com  Sat May 16 18:15:59 2015
From: johnwasige at gmail.com (John Wasige)
Date: Sat, 16 May 2015 18:15:59 +0200
Subject: [R-sig-Geo] Count Pixel with Specific of Values Appearing
 Sequentially in Rasterstack
In-Reply-To: <CANtt_hzOvZWwSCbLFPg2E4iGsE_LOOsxJtO_sQU=A0c5GzGFrg@mail.gmail.com>
References: <1708199815.2649533.1429978230870.JavaMail.yahoo@mail.yahoo.com>
	<CANtt_hzOvZWwSCbLFPg2E4iGsE_LOOsxJtO_sQU=A0c5GzGFrg@mail.gmail.com>
Message-ID: <CAJgdCD5eTskKruW7SSu_tvAKyg-bRomOaQ5syFBMjjOsC3yJsg@mail.gmail.com>

Hi Robert!

I have used your script to count pixels with Specific of Values Appearing
Sequentially in Rasterstack and it works well. It seems not to work for a
situation where am interest in values less than a specific of Value e.g.,
<0 or >0 and are not Appearing Sequentially in Rasterstack. Do you have an
idea how I can deal with counting non Sequential Values Appearing  in
Rasterstack in Rasterstack?

Thanks for your help

John

On Sun, Apr 26, 2015 at 4:44 AM, Robert J. Hijmans <r.hijmans at gmail.com>
wrote:

> Arnold,
>
> In cases like this you can make a function that computes this for a
> vector, test that function, including for a vector of NA values, and,
> if it works, use calc.
>
> # counting runs of 255
> run <- function(x) {
>   x[x != 255] <- NA
>   r <- rle(x)
>   w <- which(!is.na(r$values))
>   ifelse(length(w) > 0, max(r$lengths), 0)
> }
>
> run(rep(NA, 5))
> run(c(255, rep(NA, 5), 255, 255))
> run(rep(255, 5))
>
> # looking good, let's use it
>
> b <- brick(system.file("external/rlogo.grd", package="raster"))
> x <- calc(b, run)
> plot(x)
>
>
> Robert
>
> On Sat, Apr 25, 2015 at 9:10 AM, Arnold Salvacion via R-sig-Geo
> <r-sig-geo at r-project.org> wrote:
> > Dear Colleagues,
> > Any idea on how to count the number of times a particular number (e.g.
> 1) appears consecutively within each pixel of a raster stack/brick? I found
> a similar question online (
> http://grokbase.com/t/r/r-sig-geo/1459p0s978/error-when-attempting-to-use-rle-in-calc-in-raster-package)
> but was not able to view/get any answer to solve such problem.
> > Thanks in advance.
> > Arnold
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
John Wasige
"Birds born in a Cage think Flying is an illness."

	[[alternative HTML version deleted]]


From michael.ernst.rose at gmail.com  Sun May 17 11:50:08 2015
From: michael.ernst.rose at gmail.com (Michael E. Rose)
Date: Sun, 17 May 2015 11:50:08 +0200
Subject: [R-sig-Geo] self-made WX in lagsarlm
In-Reply-To: <555861F7.4040001@gmail.com>
References: <555861F7.4040001@gmail.com>
Message-ID: <55586450.8010308@gmail.com>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150517/245b0afb/attachment.html>

From martin.brandt at mailbox.org  Sun May 17 13:10:20 2015
From: martin.brandt at mailbox.org (Martin Brandt)
Date: Sun, 17 May 2015 04:10:20 -0700 (MST)
Subject: [R-sig-Geo] summing rasters with a condition given by other
	rasters
In-Reply-To: <1431437288303-7588242.post@n2.nabble.com>
References: <1431186891305-7588222.post@n2.nabble.com>
	<930D04EF-2AAC-43C5-8F50-48E109E587E4@bigelow.org>
	<1431257864941-7588226.post@n2.nabble.com>
	<C14A32AC-C486-4515-A723-3F456424A8B6@bigelow.org>
	<1431290544770-7588233.post@n2.nabble.com>
	<ACF6B42D-3412-40E6-B88C-02835C07A218@bigelow.org>
	<1431437288303-7588242.post@n2.nabble.com>
Message-ID: <1431861020571-7588263.post@n2.nabble.com>

There's another issue:

using Ben's great function:

sum_segment <- function(x, ...) {
sum(x[(x[1]+2):(x[2] + 2)],...)
}

what to do if the rasters in the brick contain NA values?

I thought about replacing them with 0:

b <- reclassify(b, cbind(NA, 0))

however, if I want means instead of sums

sum_segment <- function(x, ...) {
mean(x[(x[1]+2):(x[2] + 2)],...)
}

this influences the result.....is there a solution to simply omit pixels
with NAs when the mean or sum in the function are calculated?




--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/summing-rasters-with-a-condition-given-by-other-rasters-tp7588222p7588263.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From comunello.eder at gmail.com  Sun May 17 13:46:26 2015
From: comunello.eder at gmail.com (=?UTF-8?Q?=C3=89der_Comunello?=)
Date: Sun, 17 May 2015 07:46:26 -0400
Subject: [R-sig-Geo] gbif error message in package dismo
In-Reply-To: <55576583.804@uni-konstanz.de>
References: <55572065.3090506@uni-konstanz.de>
	<CABmC8gk2iHDS7GSiA-T4Y-njnrxsN_LrnLM3vkqj3SVe74pe0g@mail.gmail.com>
	<55576583.804@uni-konstanz.de>
Message-ID: <CABmC8gkufEDnHE9qqEB=3tOUN-0d=3rNmsExMFWoySjiQOxdQw@mail.gmail.com>

Hi, Mark!

These are my sessionInfo() results printed after the code execution:

###
R version 3.1.3 (2015-03-09)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 8 x64 (build 9200)

locale:
[1] LC_COLLATE=Portuguese_Brazil.1252  LC_CTYPE=Portuguese_Brazil.1252
 LC_MONETARY=Portuguese_Brazil.1252
[4] LC_NUMERIC=C                       LC_TIME=Portuguese_Brazil.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] dismo_1.0-12  raster_2.3-40 sp_1.1-0

loaded via a namespace (and not attached):
[1] grid_3.1.3        jsonlite_0.9.16   lattice_0.20-31   rstudio_0.98.1103
rstudioapi_0.3.1
[6] tools_3.1.3
###

?Could you paste your sessionInfo() results? Other idea is try to run a
short search and paste the traceback() results.? Something like...
gb   <- gbif('Batrachoseps', 'luciae', start=1, end=30)
traceback()



?der Comunello <c <comunello.eder at gmail.com>omunello.eder at gmail.com>
Dourados, MS - [22 16.5'S, 54 49'W]

2015-05-16 11:42 GMT-04:00 Mark van Kleunen <mark.vankleunen at uni-konstanz.de
>:

>  Hi ?der,
>
> thanks for your response. I tried your code without the "sp=T" argument,
> but it does not solve the problem. I also ran it in R 3.1.3, but it did not
> make a difference.
>
> > ### The command works when you don't use the argument "sp=T"!
> > gb   <- gbif('Batrachoseps', 'luciae') # 1928
> 0-300-600-900-1200-1500-1800-1928 records
> Error in (function (classes, fdef, mtable)  :
>   unable to find an inherited method for function ?bind? for signature
> ?"data.frame", "data.frame"?
>
> best wishes,
> Mark
>
>

	[[alternative HTML version deleted]]


From sharx at ucla.edu  Sun May 17 19:42:30 2015
From: sharx at ucla.edu (sharx)
Date: Sun, 17 May 2015 10:42:30 -0700 (MST)
Subject: [R-sig-Geo] Calculating a path which avoids certain cells entirely,
 no matter the distance
Message-ID: <1431884550286-7588265.post@n2.nabble.com>

Hi all, 

I have some data of GPS locations of an animal and want to construct paths
between those coordinates. The goal is to obtain animal movement paths that
the cross the fewest roads possible meaning that the paths would show
animals going far out of their way to avoid roads. Below is an example. 
<http://r-sig-geo.2731867.n2.nabble.com/file/n7588265/leastcost-example.png> 

Blue points are coordinates. Purple lines are roads. The green line is the
path I would like to generate. The red line is one of the least cost paths I
calculated, which goes through several roads unnecessarily.

Could anyone give me some ideas of how to go about this? I have experimented
with different parameters of resistance/permeability using a transition
matrix and shortestPath() in package gdistance unsuccessfully, which I have
detailed here:
http://r-sig-geo.2731867.n2.nabble.com/Using-gdistance-to-compute-a-least-cost-path-which-avoids-certain-cells-entirely-no-matter-the-distae-td7588118.html

Does anyone have any other ideas of how to go about this?

Thank you! Any help is much appreciated.

Sharon



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Calculating-a-path-which-avoids-certain-cells-entirely-no-matter-the-distance-tp7588265.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Mon May 18 10:19:32 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 18 May 2015 10:19:32 +0200
Subject: [R-sig-Geo] self-made WX in lagsarlm
In-Reply-To: <55586450.8010308@gmail.com>
References: <555861F7.4040001@gmail.com> <55586450.8010308@gmail.com>
Message-ID: <alpine.LFD.2.11.1505181000001.3000@reclus.nhh.no>

On Sun, 17 May 2015, Michael E. Rose wrote:

> 
> Dear colleagues,
> 
> I would like to estimate a spatial Durbin model with two different weight
> matrices (the second one being standardized, the first one not).
> 
> Hence, I used lagsarlm(..., type="mixed", ...) and wanted to create WX
> myself using create_WX():
> 
> WX <- create_WX(X, average.listw, prefix = "lag")
> 
> X is the matrix of regressors and average.listw is a listw object created
> with mat2listw(..., style="M").

Be careful with using matrices created elsewhere, as you may not have the 
insight you believe into the structures involved (row/column order is not 
infrequently changed). style="M" is equivalent to unknown, and should be 
known.

> 
> Now my problem is: How can I add WX to the regression formula? Simply adding
> the names of WX doesn't work, since WX is not a data.frame which can be
> added to the dataset specified in lagsarlm(..., data= ...).
>

This isn't the real problem. This will actually be the fact that the 
impacts (see references to ?spdep::impacts) are unknown, as the reduced 
form - data generation process of what you want to do is:

y = (I - rho_{Lag} W)^{-1} (Xb + WXg + W*Xd + e)

where W is the weights object in the lag model applied to the dependent 
variable, g are the spatial Durbin coefficients. W* is your extra weights 
object, for which none of b, g, or d may be inferred from directly as 
the impacts of changes in X on y are filtered through (I - rho_{Lag} 
W)^{-1}.

y = (I - rho_{Lag} W)^{-1} (Xb + W*Xd + e)

is a lag model, and

y = (I - rho_{Lag} W)^{-1} ([X, WX][b,g] + W*[X, WX][c,d] + e)

is an augmented spatial Durbin, for both of which something is known about 
impacts.

Adding a matrix to a formula is trivial by comparison:

library(spdep)
data(oldcol)
lw <- nb2listw(COL.nb, style="W")
X <- model.matrix(CRIME ~ INC + HOVAL, data=COL.OLD)
class(X)
WX <- create_WX(X, lw)
class(WX)
lm(CRIME ~ INC + HOVAL + WX, data=COL.OLD)

and equivalently elsewhere, but until you resolve the impacts, do not use 
models including a coefficient on the spatially lagged dependent variable.

Roger

> Any help is greatly appreciated!
> Michael
> 
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From tim.appelhans at gmail.com  Mon May 18 14:24:34 2015
From: tim.appelhans at gmail.com (Tim Appelhans)
Date: Mon, 18 May 2015 14:24:34 +0200
Subject: [R-sig-Geo] problem with sp.layout in latest version of sp
Message-ID: <5559DA02.3020604@gmail.com>

Dear list,
a while ago I implemented a function (rgb2spLayout) to convert an RGB 
RasterBrick/*Stack to a list which can then be used with spplot via the 
sp.layout argument in order to e.g. plot points on a Bing/Google Earth 
image. The code for the function is based on this blogpost:

https://procomun.wordpress.com/2013/04/24/stamen-maps-with-spplot/

and the function is part of a package called "Rsenal" and can be found here:

https://github.com/environmentalinformatics-marburg/Rsenal/blob/master/R/rgb2spLayout.R

This has been working like a charm until the latest update of sp from 
1.0-17 to 1.1-0. According to the change log (and the comparison of the 
spplot.R sources for the two versions), there have been some changes to 
spplot, including changes to sp.layout. The spicific error message I now 
get when I run the example from ?rgb2spLayout is

"Error using packet 1 unused argument (first = FALSE)"

I cannot figure out why things go haywire now, so any hints regarding a 
fix for this would be much appreciated.

Best
Tim

-- 
#####################################
Tim Appelhans
Department of Geography
Environmental Informatics
Philipps Universit?t Marburg
Deutschhausstra?e 12
35032 Marburg (Paketpost: 35037 Marburg)
Germany

Tel +49 (0) 6421 28-25957

http://environmentalinformatics-marburg.de/


From edzer.pebesma at uni-muenster.de  Mon May 18 15:36:49 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 18 May 2015 15:36:49 +0200
Subject: [R-sig-Geo] problem with sp.layout in latest version of sp
In-Reply-To: <5559DA02.3020604@gmail.com>
References: <5559DA02.3020604@gmail.com>
Message-ID: <5559EAF1.4080203@uni-muenster.de>

Thanks; this should now be fixed in sp on r-forge (rev 1646).

On 05/18/2015 02:24 PM, Tim Appelhans wrote:
> Dear list,
> a while ago I implemented a function (rgb2spLayout) to convert an RGB
> RasterBrick/*Stack to a list which can then be used with spplot via the
> sp.layout argument in order to e.g. plot points on a Bing/Google Earth
> image. The code for the function is based on this blogpost:
> 
> https://procomun.wordpress.com/2013/04/24/stamen-maps-with-spplot/
> 
> and the function is part of a package called "Rsenal" and can be found
> here:
> 
> https://github.com/environmentalinformatics-marburg/Rsenal/blob/master/R/rgb2spLayout.R
> 
> 
> This has been working like a charm until the latest update of sp from
> 1.0-17 to 1.1-0. According to the change log (and the comparison of the
> spplot.R sources for the two versions), there have been some changes to
> spplot, including changes to sp.layout. The spicific error message I now
> get when I run the example from ?rgb2spLayout is
> 
> "Error using packet 1 unused argument (first = FALSE)"
> 
> I cannot figure out why things go haywire now, so any hints regarding a
> fix for this would be much appreciated.
> 
> Best
> Tim
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150518/f6ccb638/attachment.bin>

From juta.kawalerowicz at nuffield.ox.ac.uk  Mon May 18 16:10:09 2015
From: juta.kawalerowicz at nuffield.ox.ac.uk (Juta Kawalerowicz)
Date: Mon, 18 May 2015 15:10:09 +0100
Subject: [R-sig-Geo] Spatial overlay vs. extract and aggregation methods
In-Reply-To: <953e32ee-c98c-4dac-8113-290d30054b5f@HUB02.ad.oak.ox.ac.uk>
References: <CAHMizkNV7mDN0psgLnC8A3VpTRqNhHjWwkXOuaRM6cmO+8jj1Q@mail.gmail.com>
	<953e32ee-c98c-4dac-8113-290d30054b5f@HUB02.ad.oak.ox.ac.uk>
Message-ID: <CAHMizkO4Hz0e8DAakEYWuSdL99uGrNSV+0REJBFOahhyZ_K4ow@mail.gmail.com>

P.S I found a solution which involves overlay and is faster than raster and
extract functions. I think it may be useful in situations when you try to
aggregate (many) small units over boundaries of some larger units,
conditioned on smaller units being completely nested within larger ones
(i.e there are no cases where a small unit falls in more than one larger
unit). I used this to recalculate boundaries between 2001 and 2011 UK
census, using 2001 Output Areas as spdf1 and electoral boundaries 2011 as
spdf2.

1) calculate centroids for spdf1, overlay with spdf2

nc.sids <- readShapeSpatial(system.file("shapes/sids.shp",
package="maptools")[1],
                            IDvar="FIPSNO", proj4string=CRS("+proj=longlat
+ellps=clrk66"))

nc.sids <- nc.sids[c("FIPSNO", "NAME" ,"BIR74")]

centroids = gCentroid(nc.sids,byid=TRUE)
overlay<-over(centroids, nc.sids)
sapply(over(nc.sids, geometry(centroids), returnList = TRUE), length)

vect<-(overlay[[1]])
for (i in 1:length(vect)){
  nc.sids$overlay[i]<-vect[i]
}

aggregated<-tapply(nc.sids at data$BIR74, nc.sids at data$overlay, sum)
cor(nc.sids at data$BIR74, aggregated)




On Tue, Apr 28, 2015 at 1:47 PM, Edzer Pebesma <
edzer.pebesma at uni-muenster.de> wrote:

>
>
> On 04/23/2015 07:04 PM, Juta Kawalerowicz wrote:
> > Hi,
> >
> > I have a spatial polygon data frame (spdf1) and try to aggregate
> > information from it over polygons in a larger spatial polygon data
> > frame(spdf2). I wanted to run some simple test to see that my code is
> sound
> > (on nc.sids from maptools), but run into a problem which I don't
> > understand. As far as I can see, there are 2 ways to do this:
> >
> > 1) rasterise the smaller spdf1, extract and calculate over larger spdf2
> >
> > library(maptools)
> > library(raster)
> > nc.sids <- readShapeSpatial(system.file("shapes/sids.shp",
> > package="maptools")[1],
> >                             IDvar="FIPSNO",
> proj4string=CRS("+proj=longlat
> > +ellps=clrk66"))
> >
> > #plot(nc.sids)
> > r<-raster(ncol=180, nrow=180)
> > extent(r)<-extent(nc.sids)
> > rp<-rasterize(nc.sids, r, 'BIR74')
> > plot(rp)
> > plot(nc.sids, add=TRUE)
> >
> > #this will take time on larger files...
> > v <- extract(rp, nc.sids, weights=TRUE)
> > res<-sapply(v, function(x) if (!is.null(x)) {sum(apply(x, 1, prod),
> > na.rm=TRUE) / sum(x[,2])} else NA )
> > cor(res, nc.sids$BIR74)
> > #seems to be working ok.
> >
> > 2) use over function from sp package
> >
> > overlay<-over(nc.sids, nc.sids)
> > #this should return the same indices of nc.sids which fall inside
> nc.sids -
> > basically should be falling within itself for each polygon, right? But
> this
> > is not what I get.
>
> no, it uses gIntersects and picks the first intersecting polygon, which
> might well be a neighbour. (Actually, over(nc.sids, geometry(nc.sids))
> should return indexes and this call the corresponding attribute entries;
> this is a bug, now fixed in rgeos on r-forge).
>
> https://stat.ethz.ch/pipermail/r-sig-geo/2015-April/022636.html
>
> has some pointers to the weighted aggregation problem of non-matching
> polygons; sp 1.1-0 has the rgeos implementation mentioned
> there, as option with sp::aggregate; see the last example of
>
> example(aggregate).
>
> >
> > Any hints would be greatly appreciated.
> >
> > Cheers,
> > Juta
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi),  University of M?nster,
> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> Journal of Statistical Software:   http://www.jstatsoft.org/
> Computers & Geosciences:   http://elsevier.com/locate/cageo/
> Spatial Statistics Society http://www.spatialstatistics.info
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

	[[alternative HTML version deleted]]


From tim.appelhans at gmail.com  Mon May 18 16:54:37 2015
From: tim.appelhans at gmail.com (Tim Appelhans)
Date: Mon, 18 May 2015 16:54:37 +0200
Subject: [R-sig-Geo] problem with sp.layout in latest version of sp
In-Reply-To: <5559EAF1.4080203@uni-muenster.de>
References: <5559DA02.3020604@gmail.com> <5559EAF1.4080203@uni-muenster.de>
Message-ID: <5559FD2D.4020003@gmail.com>

Thank you very much Edzer! All solved :-)

On 18.05.2015 15:36, Edzer Pebesma wrote:
> Thanks; this should now be fixed in sp on r-forge (rev 1646).
>
> On 05/18/2015 02:24 PM, Tim Appelhans wrote:
>> Dear list,
>> a while ago I implemented a function (rgb2spLayout) to convert an RGB
>> RasterBrick/*Stack to a list which can then be used with spplot via the
>> sp.layout argument in order to e.g. plot points on a Bing/Google Earth
>> image. The code for the function is based on this blogpost:
>>
>> https://procomun.wordpress.com/2013/04/24/stamen-maps-with-spplot/
>>
>> and the function is part of a package called "Rsenal" and can be found
>> here:
>>
>> https://github.com/environmentalinformatics-marburg/Rsenal/blob/master/R/rgb2spLayout.R
>>
>>
>> This has been working like a charm until the latest update of sp from
>> 1.0-17 to 1.1-0. According to the change log (and the comparison of the
>> spplot.R sources for the two versions), there have been some changes to
>> spplot, including changes to sp.layout. The spicific error message I now
>> get when I run the example from ?rgb2spLayout is
>>
>> "Error using packet 1 unused argument (first = FALSE)"
>>
>> I cannot figure out why things go haywire now, so any hints regarding a
>> fix for this would be much appreciated.
>>
>> Best
>> Tim
>>
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
#####################################
Tim Appelhans
Department of Geography
Environmental Informatics
Philipps Universit?t Marburg
Deutschhausstra?e 12
35032 Marburg (Paketpost: 35037 Marburg)
Germany

Tel +49 (0) 6421 28-25957

http://environmentalinformatics-marburg.de/


	[[alternative HTML version deleted]]


From comunello.eder at gmail.com  Mon May 18 17:22:54 2015
From: comunello.eder at gmail.com (=?UTF-8?Q?=C3=89der_Comunello?=)
Date: Mon, 18 May 2015 11:22:54 -0400
Subject: [R-sig-Geo] summing rasters with a condition given by other
	rasters
In-Reply-To: <1431861020571-7588263.post@n2.nabble.com>
References: <1431186891305-7588222.post@n2.nabble.com>
	<930D04EF-2AAC-43C5-8F50-48E109E587E4@bigelow.org>
	<1431257864941-7588226.post@n2.nabble.com>
	<C14A32AC-C486-4515-A723-3F456424A8B6@bigelow.org>
	<1431290544770-7588233.post@n2.nabble.com>
	<ACF6B42D-3412-40E6-B88C-02835C07A218@bigelow.org>
	<1431437288303-7588242.post@n2.nabble.com>
	<1431861020571-7588263.post@n2.nabble.com>
Message-ID: <CABmC8gnJFpEa8C+caKEEjkwTFsdijvbD0xy55dgHTGoGxEOtbg@mail.gmail.com>

Hello, Martin!

Did you try use mean() function with "na.rm=T" argument?

?der Comunello <c <comunello.eder at gmail.com>omunello.eder at gmail.com>
Dourados, MS - [22 16.5'S, 54 49'W]

2015-05-17 7:10 GMT-04:00 Martin Brandt <martin.brandt at mailbox.org>:

> There's another issue:
>
> using Ben's great function:
>
> sum_segment <- function(x, ...) {
> sum(x[(x[1]+2):(x[2] + 2)],...)
> }
>
> what to do if the rasters in the brick contain NA values?
>
> I thought about replacing them with 0:
>
> b <- reclassify(b, cbind(NA, 0))
>
> however, if I want means instead of sums
>
> sum_segment <- function(x, ...) {
> mean(x[(x[1]+2):(x[2] + 2)],...)
> }
>
> this influences the result.....is there a solution to simply omit pixels
> with NAs when the mean or sum in the function are calculated?
>
>
>
>
> --
> View this message in context:
> http://r-sig-geo.2731867.n2.nabble.com/summing-rasters-with-a-condition-given-by-other-rasters-tp7588222p7588263.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From martin.brandt at mailbox.org  Mon May 18 18:22:11 2015
From: martin.brandt at mailbox.org (Martin Brandt)
Date: Mon, 18 May 2015 09:22:11 -0700 (MST)
Subject: [R-sig-Geo] summing rasters with a condition given by other
	rasters
In-Reply-To: <CABmC8gnJFpEa8C+caKEEjkwTFsdijvbD0xy55dgHTGoGxEOtbg@mail.gmail.com>
References: <1431186891305-7588222.post@n2.nabble.com>
	<930D04EF-2AAC-43C5-8F50-48E109E587E4@bigelow.org>
	<1431257864941-7588226.post@n2.nabble.com>
	<C14A32AC-C486-4515-A723-3F456424A8B6@bigelow.org>
	<1431290544770-7588233.post@n2.nabble.com>
	<ACF6B42D-3412-40E6-B88C-02835C07A218@bigelow.org>
	<1431437288303-7588242.post@n2.nabble.com>
	<1431861020571-7588263.post@n2.nabble.com>
	<CABmC8gnJFpEa8C+caKEEjkwTFsdijvbD0xy55dgHTGoGxEOtbg@mail.gmail.com>
Message-ID: <1431966131868-7588272.post@n2.nabble.com>

Hi Eder,

yes, i tried to include na.rm:

sum_segment <- function(x, ...) {
 mean(x[(x[1]+2):(x[2] + 2)], na.rm=TRUE)
} 

but as long my stack contains any NA values, the function will not run with
calc:
> s <- calc(b, sum_segment)
Error in .calcTest(x[1:5], fun, na.rm, forcefun, forceapply) : 
  cannot use this function

or

> s <- calc(b, sum_segment, na.rm=T)
Error in .calcTest(x[1:5], fun, na.rm, forcefun, forceapply) : 
  cannot use this function. Perhaps add '...' or 'na.rm' to the function
arguments?

not sure how to make the function run and ignore all NAs..





--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/summing-rasters-with-a-condition-given-by-other-rasters-tp7588222p7588272.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From btupper at bigelow.org  Mon May 18 18:55:59 2015
From: btupper at bigelow.org (Ben Tupper)
Date: Mon, 18 May 2015 12:55:59 -0400
Subject: [R-sig-Geo] summing rasters with a condition given by other
	rasters
In-Reply-To: <1431966131868-7588272.post@n2.nabble.com>
References: <1431186891305-7588222.post@n2.nabble.com>
	<930D04EF-2AAC-43C5-8F50-48E109E587E4@bigelow.org>
	<1431257864941-7588226.post@n2.nabble.com>
	<C14A32AC-C486-4515-A723-3F456424A8B6@bigelow.org>
	<1431290544770-7588233.post@n2.nabble.com>
	<ACF6B42D-3412-40E6-B88C-02835C07A218@bigelow.org>
	<1431437288303-7588242.post@n2.nabble.com>
	<1431861020571-7588263.post@n2.nabble.com>
	<CABmC8gnJFpEa8C+caKEEjkwTFsdijvbD0xy55dgHTGoGxEOtbg@mail.gmail.com>
	<1431966131868-7588272.post@n2.nabble.com>
Message-ID: <962541C1-745C-485B-BAF1-D273DB11F8A8@bigelow.org>

Hi Martin,

On May 18, 2015, at 12:22 PM, Martin Brandt <martin.brandt at mailbox.org> wrote:

> Hi Eder,
> 
> yes, i tried to include na.rm:
> 
> sum_segment <- function(x, ...) {
> mean(x[(x[1]+2):(x[2] + 2)], na.rm=TRUE)
> } 
> 
> but as long my stack contains any NA values, the function will not run with
> calc:
>> s <- calc(b, sum_segment)
> Error in .calcTest(x[1:5], fun, na.rm, forcefun, forceapply) : 
>  cannot use this function
> 
> or
> 
>> s <- calc(b, sum_segment, na.rm=T)
> Error in .calcTest(x[1:5], fun, na.rm, forcefun, forceapply) : 
>  cannot use this function. Perhaps add '...' or 'na.rm' to the function
> arguments?
> 
> not sure how to make the function run and ignore all NAs..
> 

This function is designed to accept further arguments for other functions within the its body.  So, if you pass na.rm = TRUE to sum_segment() then it will trickle down, so to speak, to sum().  The following should work for sum or mean.

sum_segment <- function(x, ...) {
  sum(x[(x[1]+2):(x[2] + 2)],...)
}

mean_segment <- function(x, ...) {
  mean(x[(x[1]+2):(x[2] + 2)],...)
}


s <- calc(b, sum_segment, na.rm = TRUE)
m <- calc(b, mean_segment, na.rm = TRUE)

s
#class       : RasterLayer 
# dimensions  : 77, 101, 7777  (nrow, ncol, ncell)
# resolution  : 1, 1  (x, y)
# extent      : 0, 101, 0, 77  (xmin, xmax, ymin, ymax)
# coord. ref. : +proj=merc 
# data source : in memory
# names       : layer 
# values      : 0, 2295  (min, max)

m
# class       : RasterLayer 
# dimensions  : 77, 101, 7777  (nrow, ncol, ncell)
# resolution  : 1, 1  (x, y)
# extent      : 0, 101, 0, 77  (xmin, xmax, ymin, ymax)
# coord. ref. : +proj=merc 
# data source : in memory
# names       : layer 
# values      : 0, 255  (min, max)



If that doesn't work (whether you use mean() or sum()) then something else is happening and you'll want to post a small runnable example of what you are doing.   
 
Cheers,
Ben

> 
> 
> 
> 
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/summing-rasters-with-a-condition-given-by-other-rasters-tp7588222p7588272.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From comunello.eder at gmail.com  Mon May 18 21:51:34 2015
From: comunello.eder at gmail.com (=?UTF-8?Q?=C3=89der_Comunello?=)
Date: Mon, 18 May 2015 15:51:34 -0400
Subject: [R-sig-Geo] summing rasters with a condition given by other
	rasters
In-Reply-To: <962541C1-745C-485B-BAF1-D273DB11F8A8@bigelow.org>
References: <1431186891305-7588222.post@n2.nabble.com>
	<930D04EF-2AAC-43C5-8F50-48E109E587E4@bigelow.org>
	<1431257864941-7588226.post@n2.nabble.com>
	<C14A32AC-C486-4515-A723-3F456424A8B6@bigelow.org>
	<1431290544770-7588233.post@n2.nabble.com>
	<ACF6B42D-3412-40E6-B88C-02835C07A218@bigelow.org>
	<1431437288303-7588242.post@n2.nabble.com>
	<1431861020571-7588263.post@n2.nabble.com>
	<CABmC8gnJFpEa8C+caKEEjkwTFsdijvbD0xy55dgHTGoGxEOtbg@mail.gmail.com>
	<1431966131868-7588272.post@n2.nabble.com>
	<962541C1-745C-485B-BAF1-D273DB11F8A8@bigelow.org>
Message-ID: <CABmC8gk0Bx5=Zw5RyC8Z_JPt_jObh5sAMM1g7W8wGf6m5tJLgg@mail.gmail.com>

Hello, listers!

I did some tests that could be useful... Ben's solution worked  for me!

### <code r>
require(raster)

### Simulating some data to test...

do.r <- function(x) raster(matrix(sample(x, 100, replace = TRUE), 10, 10))

{
     set.seed(765)
     sos <- do.r(1:15); eos <- do.r(20:23)
     b   <- brick(sapply(1:23, function(x) do.r(c(0:255, rep(NA, 10)))))
### put some NA's
     names(b) <- paste0("ndvi_", formatC(1:23, wid=2, flag=0))
}

### Visualizing...
{
     par(mfrow=c(1,2))
     plot(sos); text(sos, getValues(sos), cex=.5)
     plot(eos); text(eos, getValues(eos), cex=.5)
     par(mfrow=c(1,1))
}

### Using Ben Tupper's solution
b2 <- addLayer(sos, eos, b)

mean_segment <- function(x, ...) {
  mean(x[(x[1]+2):(x[2] + 2)],...)
}

res1 <- calc(b2, mean_segment, na.rm=T)
res1 # it seems correct!
# class       : RasterLayer
# dimensions  : 10, 10, 100  (nrow, ncol, ncell)
# resolution  : 0.1, 0.1  (x, y)
# extent      : 0, 1, 0, 1  (xmin, xmax, ymin, ymax)
# coord. ref. : NA
# data source : in memory
# names       : layer
# values      : 58.875, 190.4167  (min, max)

### Other approach...
dfi  <- data.frame(sos=getValues(sos), eos=getValues(eos))
dfb  <- as.data.frame(b)
res2 <- sapply(1:nrow(dfi), function(x) rowMeans(dfb[x, seq(dfi$sos[x],
dfi$eos[x])], na.rm=T))

### Comparing results...
head(cbind(res1=res1[], res2))
#        res1      res2
# 1 127.30769 127.30769
# 2 108.41176 108.41176
# 3 117.46154 117.46154
# 4  88.06667  88.06667
# 5 109.71429 109.71429
# 6 113.57143 113.57143

### </code>

Best regards,


?der Comunello <c <comunello.eder at gmail.com>omunello.eder at gmail.com>
Dourados, MS - [22 16.5'S, 54 49'W]

2015-05-18 12:55 GMT-04:00 Ben Tupper <btupper at bigelow.org>:

> Hi Martin,
>
> On May 18, 2015, at 12:22 PM, Martin Brandt <martin.brandt at mailbox.org>
> wrote:
>
> > Hi Eder,
> >
> > yes, i tried to include na.rm:
> >
> > sum_segment <- function(x, ...) {
> > mean(x[(x[1]+2):(x[2] + 2)], na.rm=TRUE)
> > }
> >
> > but as long my stack contains any NA values, the function will not run
> with
> > calc:
> >> s <- calc(b, sum_segment)
> > Error in .calcTest(x[1:5], fun, na.rm, forcefun, forceapply) :
> >  cannot use this function
> >
> > or
> >
> >> s <- calc(b, sum_segment, na.rm=T)
> > Error in .calcTest(x[1:5], fun, na.rm, forcefun, forceapply) :
> >  cannot use this function. Perhaps add '...' or 'na.rm' to the function
> > arguments?
> >
> > not sure how to make the function run and ignore all NAs..
> >
>
> This function is designed to accept further arguments for other functions
> within the its body.  So, if you pass na.rm = TRUE to sum_segment() then it
> will trickle down, so to speak, to sum().  The following should work for
> sum or mean.
>
> sum_segment <- function(x, ...) {
>   sum(x[(x[1]+2):(x[2] + 2)],...)
> }
>
> mean_segment <- function(x, ...) {
>   mean(x[(x[1]+2):(x[2] + 2)],...)
> }
>
>
> s <- calc(b, sum_segment, na.rm = TRUE)
> m <- calc(b, mean_segment, na.rm = TRUE)
>
> s
> #class       : RasterLayer
> # dimensions  : 77, 101, 7777  (nrow, ncol, ncell)
> # resolution  : 1, 1  (x, y)
> # extent      : 0, 101, 0, 77  (xmin, xmax, ymin, ymax)
> # coord. ref. : +proj=merc
> # data source : in memory
> # names       : layer
> # values      : 0, 2295  (min, max)
>
> m
> # class       : RasterLayer
> # dimensions  : 77, 101, 7777  (nrow, ncol, ncell)
> # resolution  : 1, 1  (x, y)
> # extent      : 0, 101, 0, 77  (xmin, xmax, ymin, ymax)
> # coord. ref. : +proj=merc
> # data source : in memory
> # names       : layer
> # values      : 0, 255  (min, max)
>
>
>
> If that doesn't work (whether you use mean() or sum()) then something else
> is happening and you'll want to post a small runnable example of what you
> are doing.
>
> Cheers,
> Ben
>
> >
> >
> >
> >
> > --
> > View this message in context:
> http://r-sig-geo.2731867.n2.nabble.com/summing-rasters-with-a-condition-given-by-other-rasters-tp7588222p7588272.html
> > Sent from the R-sig-geo mailing list archive at Nabble.com.
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From michael.ernst.rose at gmail.com  Mon May 18 21:56:21 2015
From: michael.ernst.rose at gmail.com (Michael E. Rose)
Date: Mon, 18 May 2015 21:56:21 +0200
Subject: [R-sig-Geo] self-made WX in lagsarlm
In-Reply-To: <alpine.LFD.2.11.1505181000001.3000@reclus.nhh.no>
References: <555861F7.4040001@gmail.com> <55586450.8010308@gmail.com>
	<alpine.LFD.2.11.1505181000001.3000@reclus.nhh.no>
Message-ID: <555A43E5.6040506@gmail.com>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150518/06e691ff/attachment.html>

From Andy.Bunn at wwu.edu  Mon May 18 21:57:53 2015
From: Andy.Bunn at wwu.edu (Andy Bunn)
Date: Mon, 18 May 2015 19:57:53 +0000
Subject: [R-sig-Geo] how to fit corSpher with gls?
Message-ID: <D17F90FD.3A465%andy.bunn@wwu.edu>

Hello all, I'm playing around with using gls and appropriate corr
structure to model spatial autocorrelation in the residuals of a
regression. Below I have an example of a regression of y~x where the
residuals are spatially autocorrelated. I then try to fit a gls() model
with a spherical correlation structure using parameters from a fitted
variogram to the residuals of y~x. My expectation is that I would find the
std error on my estimate of x to decrease and AIC to decrease with the
spatial structure modeled correctly. But I think I am not specifying the
terms correctly on the call to corSpher().

Advice appreciated -Andy

# ~~~~~~~~~~~~~~~
# goal:
# create a variable y that is a function of x and spatially
# autocorrelated noise (espsilon)
# model y~x and show that the residuals are not iid
# apply a gls model with appropriate corr structure

rm(list=ls())
library(gstat)
library(sp)
library(nlme)
library(spdep)
library(ncf)

set.seed(234)
# generate the spatially autocorrelated error term, epsilon
n <- 200
epsilon <- rnorm(n,0,1)

easting <- runif(n,0,100)
northing <- runif(n,0,100)
points <- cbind(easting,northing)
dnb <- dnearneigh(points, 0, 150)
dsts <- nbdists(dnb, points)
idw <- lapply(dsts, function(x) 1/x^1.5) # p=1.5
lw <- nb2listw(dnb, glist=idw, style="W")

rho <- 0.95
inv <- invIrW(lw, rho)

epsilon <- inv %*% epsilon
epsilon <- scale(epsilon[,1])


# generate x as noise.
x <- rnorm(n)
# generate y as a function of x and epsilon (which is spatially
autocorrelated)
B0 <- 10
B1 <- 2
y <- B0 + B1*x + epsilon

# Create a spatial object
dat <- data.frame(easting,northing,y,x)
coordinates(dat)<-c('easting','northing')

# Fit a model (we don't know about spatial component)
lm1 <- lm(y~x, dat)
coefficients(summary(lm1))

# Add residuals to the SPDF dat
dat$lmResids <- residuals(lm1)

# Map the rediduals
bubble(dat, zcol = 'lmResids')

# Test them for spatial autocorrelation using moran.test,
# a correlogram and a variogram.

# Moran's I test
w <- knn2nb(knearneigh(dat, k=8))
moran.test(dat$lmResids, nb2listw(w))

# Moran's I correlogram
residsI <- spline.correlog(x=coordinates(dat)[,1], y=coordinates(dat)[,2],
                         z=dat$lmResids, resamp=20)
plot(residsI)

# Variogram
lmResidsVar <- variogram(lmResids~1, data=dat)
plot(lmResidsVar)
sph.model <- vgm(psill=1, model="Sph", range=20, nugget=0.3)
sph.fit <- fit.variogram(object = lmResidsVar, model = sph.model)
plot(lmResidsVar,model=sph.fit)

# Refit a model with an approparite correlation structure.
gls1 <- gls(y~x,data=dat) # same as ols above (lm1)

# How to get the right corSpher structure?
# I think I should give it values from the variogram fit above
# but that appears to be incorrect!
cs1 <- corSpher(value=c(17,0.3),nugget=TRUE)
gls2 <- gls(y~x,data=dat,correlation=cs1)

summary(gls1)
summary(gls2)





>


From Andy.Bunn at wwu.edu  Tue May 19 00:03:15 2015
From: Andy.Bunn at wwu.edu (Andy Bunn)
Date: Mon, 18 May 2015 22:03:15 +0000
Subject: [R-sig-Geo] how to fit corSpher with gls?
Message-ID: <D17FAF5E.3A494%andy.bunn@wwu.edu>

Ugh! Forgot to specify the form of the object. Fixed below.

On 5/18/15, 12:57 PM, "Andy Bunn" <Andy.Bunn at wwu.edu> wrote:

>Hello all, I'm playing around with using gls and appropriate corr
>structure to model spatial autocorrelation in the residuals of a
>regression. Below I have an example of a regression of y~x where the
>residuals are spatially autocorrelated. I then try to fit a gls() model
>with a spherical correlation structure using parameters from a fitted
>variogram to the residuals of y~x. My expectation is that I would find the
>std error on my estimate of x to decrease and AIC to decrease with the
>spatial structure modeled correctly. But I think I am not specifying the
>terms correctly on the call to corSpher().
>
>Advice appreciated -Andy
>
># ~~~~~~~~~~~~~~~
># goal:
># create a variable y that is a function of x and spatially
># autocorrelated noise (espsilon)
># model y~x and show that the residuals are not iid
># apply a gls model with appropriate corr structure
>
>rm(list=ls())
>library(gstat)
>library(sp)
>library(nlme)
>library(spdep)
>library(ncf)
>
>set.seed(234)
># generate the spatially autocorrelated error term, epsilon
>n <- 200
>epsilon <- rnorm(n,0,1)
>
>easting <- runif(n,0,100)
>northing <- runif(n,0,100)
>points <- cbind(easting,northing)
>dnb <- dnearneigh(points, 0, 150)
>dsts <- nbdists(dnb, points)
>idw <- lapply(dsts, function(x) 1/x^1.5) # p=1.5
>lw <- nb2listw(dnb, glist=idw, style="W")
>
>rho <- 0.95
>inv <- invIrW(lw, rho)
>
>epsilon <- inv %*% epsilon
>epsilon <- scale(epsilon[,1])
>
>
># generate x as noise.
>x <- rnorm(n)
># generate y as a function of x and epsilon (which is spatially
>autocorrelated)
>B0 <- 10
>B1 <- 2
>y <- B0 + B1*x + epsilon
>
># Create a spatial object
>dat <- data.frame(easting,northing,y,x)
>coordinates(dat)<-c('easting','northing')
>
># Fit a model (we don't know about spatial component)
>lm1 <- lm(y~x, dat)
>coefficients(summary(lm1))
>
># Add residuals to the SPDF dat
>dat$lmResids <- residuals(lm1)
>
># Map the rediduals
>bubble(dat, zcol = 'lmResids')
>
># Test them for spatial autocorrelation using moran.test,
># a correlogram and a variogram.
>
># Moran's I test
>w <- knn2nb(knearneigh(dat, k=8))
>moran.test(dat$lmResids, nb2listw(w))
>
># Moran's I correlogram
>residsI <- spline.correlog(x=coordinates(dat)[,1], y=coordinates(dat)[,2],
>                         z=dat$lmResids, resamp=20)
>plot(residsI)
>
># Variogram
>lmResidsVar <- variogram(lmResids~1, data=dat)
>plot(lmResidsVar)
>sph.model <- vgm(psill=1, model="Sph", range=20, nugget=0.3)
>sph.fit <- fit.variogram(object = lmResidsVar, model = sph.model)
>plot(lmResidsVar,model=sph.fit)




# Refit a model with an approparite correlation structure.
# Corr structure with range and nugget from above and specifying
# the form
cs1 <- corSpher(c(17,0.3),form=~easting+northing,nugget=TRUE)
gls1 <- gls(y~x,data=dat,correlation=cs1)
summary(gls1)
# add the residuals to the spatial dat object
dat$glsResids <- residuals(gls2,type="normalized")
# Moran's I test comes back clean
moran.test(dat$glsResids, nb2listw(w))











>
># Refit a model with an approparite correlation structure.
>gls1 <- gls(y~x,data=dat) # same as ols above (lm1)
>
># How to get the right corSpher structure?
># I think I should give it values from the variogram fit above
># but that appears to be incorrect!
>cs1 <- corSpher(value=c(17,0.3),nugget=TRUE)
>gls2 <- gls(y~x,data=dat,correlation=cs1)
>
>summary(gls1)
>summary(gls2)
>
>
>
>
>
>>
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at r-project.org
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Andy.Bunn at wwu.edu  Tue May 19 00:06:38 2015
From: Andy.Bunn at wwu.edu (Andy Bunn)
Date: Mon, 18 May 2015 22:06:38 +0000
Subject: [R-sig-Geo] how to fit corSpher with gls?
In-Reply-To: <D17FAF5E.3A494%andy.bunn@wwu.edu>
References: <D17FAF5E.3A494%andy.bunn@wwu.edu>
Message-ID: <D17FB020.3A499%andy.bunn@wwu.edu>

One more typo. Here is the complete script:

library(gstat)
library(sp)
library(nlme)
library(spdep)
library(ncf)



set.seed(234)
# generate the spatially autocorrelated error term, epsilon
n <- 200
epsilon <- rnorm(n,0,1)

easting <- runif(n,0,100)
northing <- runif(n,0,100)
points <- cbind(easting,northing)
dnb <- dnearneigh(points, 0, 150)
dsts <- nbdists(dnb, points)
idw <- lapply(dsts, function(x) 1/x^1.5) # p=1.5
lw <- nb2listw(dnb, glist=idw, style="W")

rho <- 0.95
inv <- invIrW(lw, rho)

epsilon <- inv %*% epsilon
epsilon <- scale(epsilon[,1])


# generate x as noise.
x <- rnorm(n)
# generate y as a function of x and epsilon (which is spatially
autocorrelated)
B0 <- 10
B1 <- 2
y <- B0 + B1*x + epsilon

# Create a spatial object
dat <- data.frame(easting,northing,y,x)
coordinates(dat)<-c('easting','northing')

# Fit a model (we don't know about spatial component)
lm1 <- lm(y~x, dat)
coefficients(summary(lm1))

# Add residuals to the SPDF dat
dat$lmResids <- residuals(lm1)

# Map the rediduals
bubble(dat, zcol = 'lmResids')

# Test them for spatial autocorrelation using moran.test,
# a correlogram and a variogram.

# Moran's I test
w <- knn2nb(knearneigh(dat, k=8))
moran.test(dat$lmResids, nb2listw(w))

# Moran's I correlogram
residsI <- spline.correlog(x=coordinates(dat)[,1], y=coordinates(dat)[,2],
                         z=dat$lmResids, resamp=20)
plot(residsI)

# Variogram
lmResidsVar <- variogram(lmResids~1, data=dat)
plot(lmResidsVar)
sph.model <- vgm(psill=1, model="Sph", range=20, nugget=0.3)
sph.fit <- fit.variogram(object = lmResidsVar, model = sph.model)
plot(lmResidsVar,model=sph.fit)

# Refit a model with an approparite correlation structure.
# Corr structure with range and nugget from above and specifying
# the form
cs1 <- corSpher(c(17,0.3),form=~easting+northing,nugget=TRUE)
gls1 <- gls(y~x,data=dat,correlation=cs1)

summary(gls1)

# add the residuals to the spatial dat object
dat$glsResids <- residuals(gls1,type="normalized")

# Map the rediduals from gls
bubble(dat, zcol = 'glsResids')

# Moran's I test
moran.test(dat$glsResids, nb2listw(w))
# Moran's I correlogram
residsI <- spline.correlog(x=coordinates(dat)[,1], y=coordinates(dat)[,2],
                         z=dat$glsResids, resamp=20)
plot(residsI)






On 5/18/15, 3:03 PM, "Andy Bunn" <Andy.Bunn at wwu.edu> wrote:

>Ugh! Forgot to specify the form of the object. Fixed below.
>
>On 5/18/15, 12:57 PM, "Andy Bunn" <Andy.Bunn at wwu.edu> wrote:
>
>>Hello all, I'm playing around with using gls and appropriate corr
>>structure to model spatial autocorrelation in the residuals of a
>>regression. Below I have an example of a regression of y~x where the
>>residuals are spatially autocorrelated. I then try to fit a gls() model
>>with a spherical correlation structure using parameters from a fitted
>>variogram to the residuals of y~x. My expectation is that I would find
>>the
>>std error on my estimate of x to decrease and AIC to decrease with the
>>spatial structure modeled correctly. But I think I am not specifying the
>>terms correctly on the call to corSpher().
>>
>>Advice appreciated -Andy
>>
>># ~~~~~~~~~~~~~~~
>># goal:
>># create a variable y that is a function of x and spatially
>># autocorrelated noise (espsilon)
>># model y~x and show that the residuals are not iid
>># apply a gls model with appropriate corr structure
>>
>>rm(list=ls())
>>library(gstat)
>>library(sp)
>>library(nlme)
>>library(spdep)
>>library(ncf)
>>
>>set.seed(234)
>># generate the spatially autocorrelated error term, epsilon
>>n <- 200
>>epsilon <- rnorm(n,0,1)
>>
>>easting <- runif(n,0,100)
>>northing <- runif(n,0,100)
>>points <- cbind(easting,northing)
>>dnb <- dnearneigh(points, 0, 150)
>>dsts <- nbdists(dnb, points)
>>idw <- lapply(dsts, function(x) 1/x^1.5) # p=1.5
>>lw <- nb2listw(dnb, glist=idw, style="W")
>>
>>rho <- 0.95
>>inv <- invIrW(lw, rho)
>>
>>epsilon <- inv %*% epsilon
>>epsilon <- scale(epsilon[,1])
>>
>>
>># generate x as noise.
>>x <- rnorm(n)
>># generate y as a function of x and epsilon (which is spatially
>>autocorrelated)
>>B0 <- 10
>>B1 <- 2
>>y <- B0 + B1*x + epsilon
>>
>># Create a spatial object
>>dat <- data.frame(easting,northing,y,x)
>>coordinates(dat)<-c('easting','northing')
>>
>># Fit a model (we don't know about spatial component)
>>lm1 <- lm(y~x, dat)
>>coefficients(summary(lm1))
>>
>># Add residuals to the SPDF dat
>>dat$lmResids <- residuals(lm1)
>>
>># Map the rediduals
>>bubble(dat, zcol = 'lmResids')
>>
>># Test them for spatial autocorrelation using moran.test,
>># a correlogram and a variogram.
>>
>># Moran's I test
>>w <- knn2nb(knearneigh(dat, k=8))
>>moran.test(dat$lmResids, nb2listw(w))
>>
>># Moran's I correlogram
>>residsI <- spline.correlog(x=coordinates(dat)[,1],
>>y=coordinates(dat)[,2],
>>                         z=dat$lmResids, resamp=20)
>>plot(residsI)
>>
>># Variogram
>>lmResidsVar <- variogram(lmResids~1, data=dat)
>>plot(lmResidsVar)
>>sph.model <- vgm(psill=1, model="Sph", range=20, nugget=0.3)
>>sph.fit <- fit.variogram(object = lmResidsVar, model = sph.model)
>>plot(lmResidsVar,model=sph.fit)
>
>
>
>
># Refit a model with an approparite correlation structure.
># Corr structure with range and nugget from above and specifying
># the form
>cs1 <- corSpher(c(17,0.3),form=~easting+northing,nugget=TRUE)
>gls1 <- gls(y~x,data=dat,correlation=cs1)
>summary(gls1)
># add the residuals to the spatial dat object
>dat$glsResids <- residuals(gls2,type="normalized")
># Moran's I test comes back clean
>moran.test(dat$glsResids, nb2listw(w))
>
>
>
>
>
>
>
>
>
>
>
>>
>># Refit a model with an approparite correlation structure.
>>gls1 <- gls(y~x,data=dat) # same as ols above (lm1)
>>
>># How to get the right corSpher structure?
>># I think I should give it values from the variogram fit above
>># but that appears to be incorrect!
>>cs1 <- corSpher(value=c(17,0.3),nugget=TRUE)
>>gls2 <- gls(y~x,data=dat,correlation=cs1)
>>
>>summary(gls1)
>>summary(gls2)
>>
>>
>>
>>
>>
>>>
>>
>>_______________________________________________
>>R-sig-Geo mailing list
>>R-sig-Geo at r-project.org
>>https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From srinivasv at feralindia.org  Tue May 19 12:47:16 2015
From: srinivasv at feralindia.org (Srinivas V)
Date: Tue, 19 May 2015 16:17:16 +0530
Subject: [R-sig-Geo] Fitting a basic structural model to a raster brick
Message-ID: <555B14B4.30300@feralindia.org>

Dear Members
I'm trying to write a function to fit a basic structural model to a 
raster brick of NDVI data. I looked up earlier post and figured out the 
use of wrapper functions and calc(). However I have not been very 
successful.
library(raster)
f <- system.file("extdata/modisraster.grd", package="bfast")
modisbrick<-brick(f)
modisbrick<-setZ(modisbrick,as.Date(strptime(paste(substr(names(modisbrick),start=2, 
stop=12)),"%Y.%m.%d")))
xStructTS <- function(x) {
   fit <- StructTS((x),type="level")
   return(fit$fitted[1])}

r1.structs<- calc(modisbrick, fun=function(x){
   res <- (apply(x, 2, xStructTS))
   return(res)
})

r1.structs

Returns a brick with levels not a problem so far. However when I change 
the class of the model I get errors.


### Change type from level to BSM ###
xStructTS <- function(x) {
   fit <- StructTS((x),type="BSM")
   return(fit$fitted[1])}
r1.structs<- calc(modisbrick, fun=function(x){
   res <- (apply(x, 2, xStructTS))
   return(res)
})
Error in .calcTest(x[1:5], fun, na.rm, forcefun, forceapply) : cannot 
use this function
Not sure why I'm getting this error message, the data does not have any 
NA. Is this error related to the the class of structural model? How do I 
overcome this error?

Second actual NDVI data for which I'm writting the function has NAs due 
to a cropping and masking. Any suggestion to fix this error and also 
address issues of NAs is greatly appreciated.

Thanks

-- 

Srinivas Vaidyanathan
Senior Research Fellow
Foundation for Ecological Research, Advocacy & Learning

Web: www.feralindia.org


	[[alternative HTML version deleted]]


From loic.dutrieux at wur.nl  Tue May 19 16:47:20 2015
From: loic.dutrieux at wur.nl (Dutrieux, Loic)
Date: Tue, 19 May 2015 14:47:20 +0000
Subject: [R-sig-Geo] Fitting a basic structural model to a raster brick
In-Reply-To: <555B14B4.30300@feralindia.org>
References: <555B14B4.30300@feralindia.org>
Message-ID: <1432046840143.57518@wur.nl>

Hi Srinivas, 

I do not think calc handles the z dimension by itself, you need to format the time-series within the function you're giving to calc().
I got an example below kind of working but it is so slow that I suspect something is not going right with it. I think the key is to figure the right formatting for the time-series you give to StructTS().

library(raster)
library(bfast)
library(zoo)
f <- system.file("extdata/modisraster.grd", package="bfast")
modisbrick<-brick(f)
modisbrick<-setZ(modisbrick,as.Date(strptime(paste(substr(names(modisbrick),start=2, stop=12)),"%Y.%m.%d")))


time <- getZ(modisbrick)

xStructTS <- function(x) {
  ts <- bfastts(x, time, type='16-day')
  fun <- function(ts) {
    StructTS(ts, type = 'BSM')$fitted[1]
  }
  fit <- sapply(ts, fun)
  return(fit)
}

r1.structs<- calc(modisbrick, fun=xStructTS) # Extremely slow

r1.structs



You can try to find the right formatting for the StructTS function by working on a single vector.

ts <- zoo(t(modisbrick[1]), time) 
StructTS(ts, type = 'BSM') # Returns an error about frequency of the data

ts  <- bfastts(t(modisbrick[1]), time, type='16-day')
StructTS(ts, type = 'BSM') # Works but really slowly


Hope it helps,
Lo?c
 
________________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of Srinivas V <srinivasv at feralindia.org>
Sent: Tuesday, May 19, 2015 12:47 PM
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] Fitting a basic structural model to a raster brick

Dear Members
I'm trying to write a function to fit a basic structural model to a
raster brick of NDVI data. I looked up earlier post and figured out the
use of wrapper functions and calc(). However I have not been very
successful.
library(raster)
f <- system.file("extdata/modisraster.grd", package="bfast")
modisbrick<-brick(f)
modisbrick<-setZ(modisbrick,as.Date(strptime(paste(substr(names(modisbrick),start=2,
stop=12)),"%Y.%m.%d")))
xStructTS <- function(x) {
   fit <- StructTS((x),type="level")
   return(fit$fitted[1])}

r1.structs<- calc(modisbrick, fun=function(x){
   res <- (apply(x, 2, xStructTS))
   return(res)
})

r1.structs

Returns a brick with levels not a problem so far. However when I change
the class of the model I get errors.


### Change type from level to BSM ###
xStructTS <- function(x) {
   fit <- StructTS((x),type="BSM")
   return(fit$fitted[1])}
r1.structs<- calc(modisbrick, fun=function(x){
   res <- (apply(x, 2, xStructTS))
   return(res)
})
Error in .calcTest(x[1:5], fun, na.rm, forcefun, forceapply) : cannot
use this function
Not sure why I'm getting this error message, the data does not have any
NA. Is this error related to the the class of structural model? How do I
overcome this error?

Second actual NDVI data for which I'm writting the function has NAs due
to a cropping and masking. Any suggestion to fix this error and also
address issues of NAs is greatly appreciated.

Thanks

--

Srinivas Vaidyanathan
Senior Research Fellow
Foundation for Ecological Research, Advocacy & Learning

Web: www.feralindia.org


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

From amit.boshale at yahoo.com  Tue May 19 16:54:30 2015
From: amit.boshale at yahoo.com (Amit Boshale)
Date: Tue, 19 May 2015 14:54:30 +0000 (UTC)
Subject: [R-sig-Geo] Processing best quality MODIS pixels only (MODIS
	package)
Message-ID: <2098391359.3362106.1432047270602.JavaMail.yahoo@mail.yahoo.com>

Hello!
I use MODIS package to smooth MODIS NDVI raster time series. 
Just wanted to try how would it look like if I used the best qulity pixels only.makeWeights function took about two days and resulted in raster stack of zeros. According to MODIS, the best qulity is 0, hence I used 0 as the threshold, is that correct? Is there a multicore version of makeWeights function?
Best,Amit
library("MODIS")path=("E:/NDVI/Indonesia")
#stack ndvi images, following MODIS package example
ndvi = preStack(pattern = "*_NDVI.tif", path = path)
timeInfo <- orgTime(ndvi,nDays=16,begin="2000049",end="2015049",pillow=40)
#Restack evi
ndvi <- preStack(files=ndvi,timeInfo=timeInfo)
#stack Vegtation index quality layers
VIqual <- stack(preStack(path=path, pattern="*_VI_Quality.tif", timeInfo=timeInfo))
bitShift = 2
bitMask = 15 
threshold=0 # based on MODIS documentation, quality 0 is the best
wt <- makeWeights(VIqual,bitShift,bitMask,threshold,decodeOnly=FALSE)
#stack composite day of the year layers
inT <- stack(preStack(path=path, pattern="*_composite_day_of_the_year.tif", timeInfo=timeInfo))
nodes <- 4
library(snow)
beginCluster(nodes)
system.time(whittaker.raster(vi=ndvi, wt=wt, inT=inT, timeInfo=timeInfo, lambda=500))
endCluster()



	[[alternative HTML version deleted]]


From p.agarwal at duke.edu  Tue May 19 20:54:23 2015
From: p.agarwal at duke.edu (Pankaj Agarwal)
Date: Tue, 19 May 2015 18:54:23 +0000
Subject: [R-sig-Geo] Input data for kriging with gstat
Message-ID: <BY2PR0501MB1670298E482942E05AF72A14A9C30@BY2PR0501MB1670.namprd05.prod.outlook.com>

Hi,

I am working on preparing input data set for kriging using the gstat package in order to interpolate missing data values.  Following along the example in the manual, I have been able to go through the steps with the meuse and meuse.grid data package.   I am not sure how I would need to prepare my own data set for use in the function:

x <- krige(log(zinc)~1, meuse, meuse.grid, model = m, beta = 5.9)

Since the meuse and meuse.grid data set is used as is in the function, do I have to prepare my data set similar to these?

My data has level of measured air pollutant at the county centroid and the corresponding Long/Lat location.  There are data for a few counties but missing for several, so I am trying to interpolate the missing values.  I have already projected the Long/Lat using the rgdal package.  Here is part of the data set that I have.


[1] 2.67190 2.67190 2.67190 3.12994 2.67190 2.87500 2.67190      NA      NA     NA......


   Longitude Latitude
1  -76.94736 35.51745
2  -79.26456 35.73348
3  -78.71155 34.28487
4  -80.25679 36.10971
5  -77.10624 35.83633
6  -80.81196 35.21543
7  -78.97348 36.37938
8  -79.41320 36.07369
9  -81.19022 35.89239
10 -81.10411 36.49739

....

How would I convert or use my data set to an equivalent of meuse and meuse.grid so that I could use the "krige" and other functions.

Thank you,

- Pankaj

----------------------------------------------------------------
Pankaj Agarwal, M.S
Bioinformatician
Database Analyst II
Surgical Sciences Applied Therapeutics Section
Department of Surgery
Duke University
919-244-6389
p.agarwal at duke.edu<mailto:p.agarwal at duke.edu>


	[[alternative HTML version deleted]]


From zuzulaz at gmail.com  Tue May 19 21:32:09 2015
From: zuzulaz at gmail.com (zuzana zajkova)
Date: Tue, 19 May 2015 21:32:09 +0200
Subject: [R-sig-Geo] Kriging - model selection
Message-ID: <CADQCJLD=1KOwxYE89DS627D5bGic346WJCC0THAUDjjPdnp+5w@mail.gmail.com>

Dear all,

I would like to perform interpolation of my data, using kriging. I am
pretty new to this field, I would appreciate any advice.

After reading various sources about how to do this kind of analysis in R, i
came out with the code below. What I am struggling with, is the selection
of the "correct" variogram model and parameters which would best fit my
data.

So far, I am most convinced with the linear model using "gstat" package (as
there is a linear correlation between value and longitude), although I am
not sure with the "range" parameter.

I tried two packages, "kriging" and "gstat", here is the code I used.

I welcome any recommendation about which model and parameters to use.
Thank you,

Zuzana


#####################
###### KRIGING ######
#####################


> dput(ddd)
 structure(list(value = c(-15.63, -15.85, -15.66, -15.59, -15.75,
                         -15.67, -15.92, -16.1, -15.94, -15.86, -16.34,
-15.79, -15.74,
                         -16.35, -16.32, -16.34, -16.93, -16.33, -16.09,
-16.15, -16.07,
                         -16.32, -16.14, -16.11, -16.42, -16.06, -16.09,
-15.67), lat = c(7.1840870481035,

7.99259507438396, 11.9797581011895, 7.49274296840517, 9.67854016040156,

12.2741332643094, 8.21606349541263, 7.79878658231986, 7.2680142040734,

7.79600014665774, 6.88856759081784, 2.71471364119849, 3.98276218734202,

9.14251390940468, 7.40818160773457, 6.74255907653643, 17.2606233919273,

13.5775247347178, 15.1123203521451, 10.5186702866744, 7.49287138877741,

11.6415159877501, 7.37141449045903, 10.4795385344797, 11.7311433605838,

7.69341033361702, 5.83759526736964, 6.99439199170752), lon =
c(-37.9137449718093,

-35.3295205743433, -35.7977158093952, -41.4601218055409, -38.6729750935733,

-39.6048692841313, -34.5682210607579, -36.3718007962673, -33.1684288611563,

-40.9943844182636, -30.76067153812, -34.1185676916864, -37.1053996472096,

-32.2766293664428, -33.7449877248086, -34.5910032927336, -23.8938102400732,

-37.0736715552604, -33.9073649895551, -34.0622219110843, -34.656850099908,

-32.4980341080834, -40.5035367177989, -34.3580298956927, -33.1636537431894,

-39.8857782758382, -36.3770793693717, -45.0208499705794)), .Names =
c("value",

"lat", "lon"), row.names = c(21L, 53L, 98L, 131L, 171L, 232L,

263L, 312L, 344L, 383L, 413L, 445L, 511L, 538L, 568L, 629L, 669L,

708L, 729L, 800L, 837L, 853L, 882L, 943L, 988L, 1037L, 1057L,

1095L), class = "data.frame")


##############################
library(kriging)
library(fields)
##############################

kriged.ddd <- kriging(ddd$lon, ddd$lat, ddd$value,  pixels=300)

plot(kriged.ddd$semivariogram)

r <- range(kriged.ddd$map$pred)

## plot
image(kriged.ddd, xlim = extendrange(ddd$lon), ylim = extendrange(ddd$lat),
      zlim = r, col=topo.colors(100), add=F)
points(ddd$lon, ddd$lat, pch=21, col="white", bg="grey20" )
image.plot(kriged.ddd, col=topo.colors(100), legend.only=TRUE, zlim=r,
horizontal=T, legend.shrink=0.3)


##############################
library(gstat)
##############################

coordinates(ddd) = ~lon+lat
plot(ddd)

x.range <- as.numeric(range(ddd at coords[,1])) # lon
y.range <- as.numeric(range(ddd at coords[,2])) # lat

## expand grid
grd <- expand.grid(x=seq(from=x.range[1], to=x.range[2], by=0.5),
                   y=seq(from=y.range[1], to=y.range[2], by=0.5))

# grd2 <- expand.grid(x=seq(from=x.range[1], to=x.range[2], by=1),
#                    y=seq(from=y.range[1], to=y.range[2], by=1))

## convert grid to SpatialPixel class
coordinates(grd) <- ~ x+y
gridded(grd) <- TRUE

# coordinates(grd2) <- ~ x+y
# gridded(grd2) <- TRUE

## test the grid and points
plot(grd, cex=1.5)
points(ddd, pch=1, col="red", cex=1)

## construction of a semivariogram model
variogcloud<-variogram(value~1, locations=ddd, data=ddd, cloud=TRUE)
plot(variogcloud)

semivariog <- variogram(value~1, locations=ddd, data=ddd)
plot(semivariog)

## estimation of semivariogram parameters and fit the model

# linear
model.variog.lin <- vgm(psill=1, model="Lin", nugget=0.02) ## range???
model.variog.lin
plot(semivariog, model.variog.lin, plot.numbers=T)
fit.variog.lin <- fit.variogram(semivariog, model.variog.lin)
fit.variog.lin
plot(semivariog, fit.variog.lin, plot.numbers=T)

# spherical
model.variog.sph <- vgm(psill=0.05, model="Sph", nugget=0.01, range=4)
model.variog.sph
plot(semivariog, model.variog.sph, plot.numbers=T)
fit.variog.sph <- fit.variogram(semivariog, model.variog.sph)
fit.variog.sph
plot(semivariog, fit.variog.sph, plot.numbers=T)

# exponencial
model.variog.exp <- vgm(psill=0.05,model="Exp", nugget=0.01, range=3)
model.variog.exp
plot(semivariog, model.variog.exp, plot.numbers=T)
fit.variog.exp <- fit.variogram(semivariog, model.variog.exp)
fit.variog.exp
plot(semivariog, fit.variog.exp, plot.numbers=T)


####### plots

## linear semivariogram model
# krig.lin <- krige(formula=value ~ 1, locations=ddd, newdata=grd,
model=model.variog.lin)
krig.lin <- krige(formula=value ~ 1, locations=ddd, newdata=grd,
model=fit.variog.lin)
krig.output.lin=as.data.frame(krig.lin)
names(krig.output.lin)[1:3] <- c("long","lat","var1.pred.lin")
plot.lin <- ggplot(data=krig.output.lin,aes(x=long,y=lat))
layer.lin <- c(geom_tile(data=krig.output.lin, aes(fill=var1.pred.lin)))
plot.lin+
  layer.lin+
    scale_fill_gradientn(colours=topo.colors(100),
limits=range(range(krig.output.lin$var1.pred.lin), range(ddd$value)))+
  coord_equal()+
  theme_bw()+
  geom_point(data=data.frame(ddd), aes(x=lon, y=lat),  fill="black",
colour="black", shape=21, size=4)+
  geom_point(data=data.frame(ddd), aes(x=lon, y=lat,  fill=value),
colour="black", shape=21, size=3.5)

## spherical semivariogram model
krig.sph <- krige(formula=value ~ 1, locations=ddd, newdata=grd,
model=model.variog.sph)
# krig.sph <- krige(formula=value ~ 1, locations=ddd, newdata=grd,
model=fit.variog.sph)
krig.output.sph=as.data.frame(krig.sph)
names(krig.output.sph)[1:3] <- c("long","lat","var1.pred.sph")
plot.sph <- ggplot(data=krig.output.sph,aes(x=long, y=lat))
layer.sph <- c(geom_tile(data=krig.output.sph, aes(fill=var1.pred.sph)))
plot.sph+
  layer.sph+
  scale_fill_gradientn(colours=topo.colors(100),
limits=range(range(krig.output.sph$var1.pred.sph), range(ddd$value)))+
  coord_equal()+
  theme_bw()+
  geom_point(data=data.frame(ddd), aes(x=lon, y=lat),  fill="black",
colour="black", shape=21, size=4)+
  geom_point(data=data.frame(ddd), aes(x=lon, y=lat,  fill=value),
colour="black", shape=21, size=3.5)

## exponential semivariogram model
krig.exp <- krige(formula=value ~ 1, locations=ddd, newdata=grd,
model=model.variog.exp)
# krig.exp <- krige(formula=value ~ 1, locations=ddd, newdata=grd,
model=fit.variog.exp)
krig.output.exp=as.data.frame(krig.exp)
names(krig.output.exp)[1:3] <- c("long","lat","var1.pred.exp")
plot.exp <- ggplot(data=krig.output.exp,aes(x=long,y=lat))
layer.exp <- c(geom_tile(data=krig.output.exp,aes(fill=var1.pred.exp)))
plot.exp+
  layer.exp+
 scale_fill_gradientn(colours=topo.colors(100),
limits=range(range(krig.output.exp$var1.pred.exp), range(ddd$value)))+
  coord_equal()+
  theme_bw()+
  geom_point(data=data.frame(ddd), aes(x=lon, y=lat),  fill="black",
colour="black", shape=21, size=4)+
  geom_point(data=data.frame(ddd), aes(x=lon, y=lat,  fill=value),
colour="black", shape=21, size=3.5)




<zuzanazajkova at ub.edu>

	[[alternative HTML version deleted]]


From matteo.mattiuzzi at boku.ac.at  Tue May 19 21:53:40 2015
From: matteo.mattiuzzi at boku.ac.at (Matteo Mattiuzzi)
Date: Tue, 19 May 2015 21:53:40 +0200
Subject: [R-sig-Geo] Processing best quality MODIS pixels only (MODIS
	package)
In-Reply-To: <2098391359.3362106.1432047270602.JavaMail.yahoo@mail.yahoo.com>
References: <2098391359.3362106.1432047270602.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <555BB0E40200002700027037@gwia2.boku.ac.at>

Dear Amit,
Thats correct, if you want to use only pixel of 0000 quality you have to set 0 as threshold (everything > than threshold is set to 0 weight). But for what I remember, and this might explains your result with all 0s, is that 0000 does not exist in MODIS data despite the fact that it is described so on the website. You can use the decodeOnly=TRUE option to see the exact values of your quality layers, but I guess you will not find any values lower than 1.
If you run whittaker.raster, you can feed also argument of the makeWeights function. If you use a cluster this step is parallelized automatically.
I gave a short look to makeWeights now, probably I can do some little speed improvements.

It should be possible to do:

library("MODIS")
path=("E:/NDVI/Indonesia")
#stack ndvi images, following MODIS package example
ndvi = preStack(pattern = "*_NDVI.tif", path = path)
timeInfo <- orgTime(ndvi,nDays=16,begin="2000049",end="2015049",pillow=40)
#Restack evi
ndvi <- preStack(files=ndvi,timeInfo=timeInfo)
# You don't need to stack here, it is done with stack(...quick=TRUE) within whittaker.raster.
wt  <- preStack(path=path, pattern="*_VI_Quality.tif$", timeInfo=timeInfo)
inT <- preStack(path=path, pattern="*_composite_day_of_the_year.tif", timeInfo=timeInfo)
nodes <- 4
library(snow)
beginCluster(nodes)
system.time(whittaker.raster(vi=ndvi, wt = wt, inT = inT, timeInfo = timeInfo, lamba = 500, bitShift = 2, bitMask = 15, threshold = 1))
endCluster()

Matteo


>>> Amit Boshale <amit.boshale at yahoo.com> 05/19/15 4:54 PM >>>
Hello!
I use MODIS package to smooth MODIS NDVI raster time series. 
Just wanted to try how would it look like if I used the best qulity pixels only.makeWeights function took about two days and resulted in raster stack of zeros. According to MODIS, the best qulity is 0, hence I used 0 as the threshold, is that correct? Is there a multicore version of makeWeights function?
Best,Amit
library("MODIS")path=("E:/NDVI/Indonesia")
#stack ndvi images, following MODIS package example
ndvi = preStack(pattern = "*_NDVI.tif", path = path)
timeInfo <- orgTime(ndvi,nDays=16,begin="2000049",end="2015049",pillow=40)
#Restack evi
ndvi <- preStack(files=ndvi,timeInfo=timeInfo)
#stack Vegtation index quality layers
VIqual <- stack(preStack(path=path, pattern="*_VI_Quality.tif", timeInfo=timeInfo))
bitShift = 2
bitMask = 15 
threshold=0 # based on MODIS documentation, quality 0 is the best
wt <- makeWeights(VIqual,bitShift,bitMask,threshold,decodeOnly=FALSE)
#stack composite day of the year layers
inT <- stack(preStack(path=path, pattern="*_composite_day_of_the_year.tif", timeInfo=timeInfo))
nodes <- 4
library(snow)
beginCluster(nodes)
system.time(whittaker.raster(vi=ndvi, wt=wt, inT=inT, timeInfo=timeInfo, lambda=500))
endCluster()


From michael.ernst.rose at gmail.com  Wed May 20 01:23:32 2015
From: michael.ernst.rose at gmail.com (Michael E. Rose)
Date: Wed, 20 May 2015 01:23:32 +0200
Subject: [R-sig-Geo] How to use create_WX() correctly
Message-ID: <555BC5F4.7090600@gmail.com>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150520/7563dec8/attachment.html>

From antonio.bubbico at gmail.com  Wed May 20 11:16:26 2015
From: antonio.bubbico at gmail.com (Antonio Bubbico)
Date: Wed, 20 May 2015 11:16:26 +0200
Subject: [R-sig-Geo] calculate marginal effects of a spatial tobit model
	using sartobit
Message-ID: <CABW+3tBakQ8WkjyQrqtYMsS-D=BH08_cao0UoqEyWTpeiFeutQ@mail.gmail.com>

Hello,

I am using the function sartobit to calculate a spatial tobit model. I
would also like to calculate marginal effects, but I don't t know if there
is a  built-in function able to make it.

Thanks.
-- 
*Dr Antonio Bubbico*
Postdoctoral Researcher




*School of Agriculture and Food ScienceUniversity College DublinBelfield,
Dublin 4Ireland*

Tel: +353899528966
e-mail: a <marija.banovic at ucd.ie>ntonio.bubbico at gmail.com
Room: 1.27

	[[alternative HTML version deleted]]


From roman.lustrik at gmail.com  Wed May 20 11:20:54 2015
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Wed, 20 May 2015 11:20:54 +0200
Subject: [R-sig-Geo] calculate marginal effects of a spatial tobit model
 using sartobit
In-Reply-To: <CABW+3tBakQ8WkjyQrqtYMsS-D=BH08_cao0UoqEyWTpeiFeutQ@mail.gmail.com>
References: <CABW+3tBakQ8WkjyQrqtYMsS-D=BH08_cao0UoqEyWTpeiFeutQ@mail.gmail.com>
Message-ID: <CAHT1vphjYRwZ6FY2L3Q=mVcvdWDtJNQNfPHCie0KgOp5s3+EYw@mail.gmail.com>

Hi,

see

library(sos)
findFn("tobit")

which returns some results that might be of interest to you.

Cheers,
Roman


On Wed, May 20, 2015 at 11:16 AM, Antonio Bubbico <antonio.bubbico at gmail.com
> wrote:

> Hello,
>
> I am using the function sartobit to calculate a spatial tobit model. I
> would also like to calculate marginal effects, but I don't t know if there
> is a  built-in function able to make it.
>
> Thanks.
> --
> *Dr Antonio Bubbico*
> Postdoctoral Researcher
>
>
>
>
> *School of Agriculture and Food ScienceUniversity College DublinBelfield,
> Dublin 4Ireland*
>
> Tel: +353899528966
> e-mail: a <marija.banovic at ucd.ie>ntonio.bubbico at gmail.com
> Room: 1.27
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
In God we trust, all others bring data.

	[[alternative HTML version deleted]]


From antonio.bubbico at gmail.com  Wed May 20 11:25:48 2015
From: antonio.bubbico at gmail.com (Antonio Bubbico)
Date: Wed, 20 May 2015 11:25:48 +0200
Subject: [R-sig-Geo] calculate marginal effects of a spatial tobit model
 using sartobit
In-Reply-To: <CAHT1vphjYRwZ6FY2L3Q=mVcvdWDtJNQNfPHCie0KgOp5s3+EYw@mail.gmail.com>
References: <CABW+3tBakQ8WkjyQrqtYMsS-D=BH08_cao0UoqEyWTpeiFeutQ@mail.gmail.com>
	<CAHT1vphjYRwZ6FY2L3Q=mVcvdWDtJNQNfPHCie0KgOp5s3+EYw@mail.gmail.com>
Message-ID: <CABW+3tAfaJC8qfbJoExu4cQFPX6Xn0Jfhw+PL-B8D+kh64hRSw@mail.gmail.com>

thanks but nothing new from there

2015-05-20 11:20 GMT+02:00 Roman Lu?trik <roman.lustrik at gmail.com>:

> Hi,
>
> see
>
> library(sos)
> findFn("tobit")
>
> which returns some results that might be of interest to you.
>
> Cheers,
> Roman
>
>
> On Wed, May 20, 2015 at 11:16 AM, Antonio Bubbico <
> antonio.bubbico at gmail.com> wrote:
>
>> Hello,
>>
>> I am using the function sartobit to calculate a spatial tobit model. I
>> would also like to calculate marginal effects, but I don't t know if there
>> is a  built-in function able to make it.
>>
>> Thanks.
>> --
>> *Dr Antonio Bubbico*
>> Postdoctoral Researcher
>>
>>
>>
>>
>> *School of Agriculture and Food ScienceUniversity College DublinBelfield,
>> Dublin 4Ireland*
>>
>> Tel: +353899528966
>> e-mail: a <marija.banovic at ucd.ie>ntonio.bubbico at gmail.com
>> Room: 1.27
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
>
> --
> In God we trust, all others bring data.
>



-- 
*Dr Antonio Bubbico*
Postdoctoral Researcher




*School of Agriculture and Food ScienceUniversity College DublinBelfield,
Dublin 4Ireland*

Tel: +353899528966
e-mail: a <marija.banovic at ucd.ie>ntonio.bubbico at gmail.com
Room: 1.27

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Wed May 20 11:53:06 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 20 May 2015 11:53:06 +0200
Subject: [R-sig-Geo] calculate marginal effects of a spatial tobit model
 using sartobit
In-Reply-To: <CABW+3tAfaJC8qfbJoExu4cQFPX6Xn0Jfhw+PL-B8D+kh64hRSw@mail.gmail.com>
References: <CABW+3tBakQ8WkjyQrqtYMsS-D=BH08_cao0UoqEyWTpeiFeutQ@mail.gmail.com>
	<CAHT1vphjYRwZ6FY2L3Q=mVcvdWDtJNQNfPHCie0KgOp5s3+EYw@mail.gmail.com>
	<CABW+3tAfaJC8qfbJoExu4cQFPX6Xn0Jfhw+PL-B8D+kh64hRSw@mail.gmail.com>
Message-ID: <alpine.LFD.2.11.1505201148110.26612@reclus.nhh.no>

On Wed, 20 May 2015, Antonio Bubbico wrote:

> thanks but nothing new from there

The current version of spatialprobit::sartobit returns components total, 
direct and indirect, but they are all filled with logical NAs by default, 
when computeMarginalEffects=FALSE. Unfortunately, this is the same (NAs) 
when it is TRUE too, so I'd suggest contacting the package maintainer, 
and/or examining the source code of the function.

Roger

>
> 2015-05-20 11:20 GMT+02:00 Roman Lu?trik <roman.lustrik at gmail.com>:
>
>> Hi,
>>
>> see
>>
>> library(sos)
>> findFn("tobit")
>>
>> which returns some results that might be of interest to you.
>>
>> Cheers,
>> Roman
>>
>>
>> On Wed, May 20, 2015 at 11:16 AM, Antonio Bubbico <
>> antonio.bubbico at gmail.com> wrote:
>>
>>> Hello,
>>>
>>> I am using the function sartobit to calculate a spatial tobit model. I
>>> would also like to calculate marginal effects, but I don't t know if there
>>> is a  built-in function able to make it.
>>>
>>> Thanks.
>>> --
>>> *Dr Antonio Bubbico*
>>> Postdoctoral Researcher
>>>
>>>
>>>
>>>
>>> *School of Agriculture and Food ScienceUniversity College DublinBelfield,
>>> Dublin 4Ireland*
>>>
>>> Tel: +353899528966
>>> e-mail: a <marija.banovic at ucd.ie>ntonio.bubbico at gmail.com
>>> Room: 1.27
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>
>>
>> --
>> In God we trust, all others bring data.
>>
>
>
>
> -- 
> *Dr Antonio Bubbico*
> Postdoctoral Researcher
>
>
>
>
> *School of Agriculture and Food ScienceUniversity College DublinBelfield,
> Dublin 4Ireland*
>
> Tel: +353899528966
> e-mail: a <marija.banovic at ucd.ie>ntonio.bubbico at gmail.com
> Room: 1.27
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From amit.boshale at yahoo.com  Wed May 20 13:49:09 2015
From: amit.boshale at yahoo.com (Amit Boshale)
Date: Wed, 20 May 2015 11:49:09 +0000 (UTC)
Subject: [R-sig-Geo] Processing best quality MODIS pixels only (MODIS
	package)
In-Reply-To: <555BB0E40200002700027037@gwia2.boku.ac.at>
References: <555BB0E40200002700027037@gwia2.boku.ac.at>
Message-ID: <840394359.4478448.1432122549210.JavaMail.yahoo@mail.yahoo.com>

Dear Matteo,
Many thanks for the help!?
I just tried it on a small raster stack and it worked. The resulting time series looks better. I will keep trying with other threshold values(2,3,etc.)to compare the resulting graphs for improved visual interpretation.?
Best,Amit


 


     Matteo Mattiuzzi <matteo.mattiuzzi at boku.ac.at> schrieb am 21:53 Dienstag, 19.Mai 2015:
   

 Dear Amit,
Thats correct, if you want to use only pixel of 0000 quality you have to set 0 as threshold (everything > than threshold is set to 0 weight). But for what I remember, and this might explains your result with all 0s, is that 0000 does not exist in MODIS data despite the fact that it is described so on the website. You can use the decodeOnly=TRUE option to see the exact values of your quality layers, but I guess you will not find any values lower than 1.
If you run whittaker.raster, you can feed also argument of the makeWeights function. If you use a cluster this step is parallelized automatically.
I gave a short look to makeWeights now, probably I can do some little speed improvements.

It should be possible to do:

library("MODIS")
path=("E:/NDVI/Indonesia")
#stack ndvi images, following MODIS package example
ndvi = preStack(pattern = "*_NDVI.tif", path = path)
timeInfo <- orgTime(ndvi,nDays=16,begin="2000049",end="2015049",pillow=40)
#Restack evi
ndvi <- preStack(files=ndvi,timeInfo=timeInfo)
# You don't need to stack here, it is done with stack(...quick=TRUE) within whittaker.raster.
wt? <- preStack(path=path, pattern="*_VI_Quality.tif$", timeInfo=timeInfo)
inT <- preStack(path=path, pattern="*_composite_day_of_the_year.tif", timeInfo=timeInfo)
nodes <- 4
library(snow)
beginCluster(nodes)
system.time(whittaker.raster(vi=ndvi, wt = wt, inT = inT, timeInfo = timeInfo, lamba = 500, bitShift = 2, bitMask = 15, threshold = 1))
endCluster()

Matteo


>>> Amit Boshale <amit.boshale at yahoo.com> 05/19/15 4:54 PM >>>
Hello!
I use MODIS package to smooth MODIS NDVI raster time series. 
Just wanted to try how would it look like if I used the best qulity pixels only.makeWeights function took about two days and resulted in raster stack of zeros. According to MODIS, the best qulity is 0, hence I used 0 as the threshold, is that correct? Is there a multicore version of makeWeights function?
Best,Amit
library("MODIS")path=("E:/NDVI/Indonesia")
#stack ndvi images, following MODIS package example
ndvi = preStack(pattern = "*_NDVI.tif", path = path)
timeInfo <- orgTime(ndvi,nDays=16,begin="2000049",end="2015049",pillow=40)
#Restack evi
ndvi <- preStack(files=ndvi,timeInfo=timeInfo)
#stack Vegtation index quality layers
VIqual <- stack(preStack(path=path, pattern="*_VI_Quality.tif", timeInfo=timeInfo))
bitShift = 2
bitMask = 15 
threshold=0 # based on MODIS documentation, quality 0 is the best
wt <- makeWeights(VIqual,bitShift,bitMask,threshold,decodeOnly=FALSE)
#stack composite day of the year layers
inT <- stack(preStack(path=path, pattern="*_composite_day_of_the_year.tif", timeInfo=timeInfo))
nodes <- 4
library(snow)
beginCluster(nodes)
system.time(whittaker.raster(vi=ndvi, wt=wt, inT=inT, timeInfo=timeInfo, lambda=500))
endCluster()





  
	[[alternative HTML version deleted]]


From Jason.Brown at kc.frb.org  Wed May 20 16:11:16 2015
From: Jason.Brown at kc.frb.org (Brown, Jason)
Date: Wed, 20 May 2015 14:11:16 +0000
Subject: [R-sig-Geo] Recovering GWR Predicted Values from GGWR function
Message-ID: <42F4267FAAD1BC4F968DAE5034E9AF0F1A398F20@NR3PWPGLCD2O.rb.win.frb.org>

Hello,

I'm estimating a Poisson GWR using the ggwr function.  I would like to recover the predicted values implied by the gwr model.  However, thus far I've only been able to recover the fitted values from the global model using $lm$fitted.values.  These obviously are the same values I get from a standard Poisson model. Is it possible to get the gwr predicted values instead?

Thank you,
Jason



	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Wed May 20 20:27:46 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 20 May 2015 20:27:46 +0200
Subject: [R-sig-Geo] Recovering GWR Predicted Values from GGWR function
In-Reply-To: <42F4267FAAD1BC4F968DAE5034E9AF0F1A398F20@NR3PWPGLCD2O.rb.win.frb.org>
References: <42F4267FAAD1BC4F968DAE5034E9AF0F1A398F20@NR3PWPGLCD2O.rb.win.frb.org>
Message-ID: <alpine.LFD.2.11.1505202022550.15946@reclus.nhh.no>

On Wed, 20 May 2015, Brown, Jason wrote:

> Hello,
>
> I'm estimating a Poisson GWR using the ggwr function.  I would like to 
> recover the predicted values implied by the gwr model.  However, thus 
> far I've only been able to recover the fitted values from the global 
> model using $lm$fitted.values.  These obviously are the same values I 
> get from a standard Poisson model. Is it possible to get the gwr 
> predicted values instead?

No, they are not provided. They would only be available if the data points 
and the fit points were identical, or if newdata was available (and was 
admitted by the function, which it is not). The aim of spgwr has always 
been to explore the weaknesses of GWR as a technique, not to help people 
use it, so no provision for GLM-GWR predictions is likely to be 
forthcoming here (there are no coefficient standard errors either).

Hope this clarifies,

Roger

>
> Thank you,
> Jason
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From tkeitt at utexas.edu  Wed May 20 20:33:59 2015
From: tkeitt at utexas.edu (Tim Keitt)
Date: Wed, 20 May 2015 13:33:59 -0500
Subject: [R-sig-Geo] Change in proj strings?
Message-ID: <CANnL8go1qn-C3w0Y1a7y=jLTfsZybNTRo3QG0wEj4_rYx33LpQ@mail.gmail.com>

I get: Error in CRS("+proj=longlat") : major axis or radius = 0 or not given

Never seen that before. What's the fix?

THK
http://www.keittlab.org/

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Wed May 20 21:02:32 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 20 May 2015 21:02:32 +0200
Subject: [R-sig-Geo] Change in proj strings?
In-Reply-To: <CANnL8go1qn-C3w0Y1a7y=jLTfsZybNTRo3QG0wEj4_rYx33LpQ@mail.gmail.com>
References: <CANnL8go1qn-C3w0Y1a7y=jLTfsZybNTRo3QG0wEj4_rYx33LpQ@mail.gmail.com>
Message-ID: <alpine.LFD.2.11.1505202037230.15946@reclus.nhh.no>

On Wed, 20 May 2015, Tim Keitt wrote:

> I get: Error in CRS("+proj=longlat") : major axis or radius = 0 or not given
>
> Never seen that before. What's the fix?

Depending on platform, you see different consequences.

When PROJ.4 parses a string defining a spatial reference system, it wants 
something to give it a metric. The +ellps= tag is one such. In PROJ_LIB, 
there used to be a file (proj_def.dat), which contained +ellps=WGS84 as a 
default. On seeing any incoming string without any tags giving ellipsoid 
details, the default was used.

The PROJ.4 trunk still has proj_def.dat, and up to and including 4.8.0, it 
was always shipped in the source and binaries (like Debian proj-data). 
Because the file seems to have been left out of 4.9.*RC* and 4.9.1, anyone 
deleting PROJ_LIB before installing the new version will lose access to 
the defaults. You can avoid using this file by saying:

CRS("+proj=longlat +no_defs")

and indeed that is why +init= generated parsed strings have +no_defs (no 
defaults) set - they ignore proj_def.dat.

I've entered a PROJ.4 ticket #274 about missing proj_def.dat in released 
4.9.1, and posted on the proj list without response so far.

CRAN installed the Debian 4.9.1 packages on Monday with considerable 
fall-out, and many package maintainers have been contacted (some as early 
as the RC for 4.9.* by me and Edzer).

One way to look at this is as a wake-up call reminding us that a metric 
really is needed in a spatial reference system definition. However, PROJ.4 
has broken its earlier practice of providing a reasonable default, very 
likely by mistake.

The current status for CRAN is that Windows and Snow Leopard rgdal binary 
packages include proj_def.dat, OSX Mavericks does not (but will be rebuilt 
today, thanks to Simon Urbanek, so may get it - hard to inject 
automatically), and installs of rgdal from source depend on the platform 
PROJ.4. The recent Debian release is without proj_def.dat. The file itself 
may be added to PROJ_LIB manually, and downloaded from:

http://trac.osgeo.org/proj/browser/trunk/proj/nad/proj_def.dat

(unchanged in 14 years and very simple). I have no idea how it got lost 
from the PROJ.4 source distribution, but it isn't in proj-4.9.1/nad of:

http://download.osgeo.org/proj/proj-4.9.1.tar.gz

These things are sent to try us ...

Roger

>
> THK
> http://www.keittlab.org/
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From cvergara at proyectos.uct.cl  Wed May 20 21:16:54 2015
From: cvergara at proyectos.uct.cl (CRISTIAN ANDRES VERGARA FERNANDEZ)
Date: Wed, 20 May 2015 14:16:54 -0500
Subject: [R-sig-Geo] how to find temporally invariant cluster (TIC) using R.
Message-ID: <CAD2SsrTiT-OX=s4pCAiECM=Aw15+pvjX63DHecizj7BsoLyEtQ@mail.gmail.com>

Hi everyone,

This is my first post so my apologize if I break any of the rules, or good
practices for posting a question. I read the suggestions, but I may make a
mistake anyway.

I am interested in doing a radiometric normalization using the TIC method
described in:

Chen, X,, L. Vierling, and D. Deering. 2005. A simple and effective
radiometric correction method to improve landscape change detection across
sensors and cross time. Remote Sensing of Environment 98, 63-79 pp.

basically what I need to do is to find the temporally invariant cluster
between two images (at least 2). by the means of a pixel based scatterplot
and a point density map. Then I need to identify the value of the pixels
that are in the center of the clusters. In my case, I am using landsat
images (b1 2000 v/s b1 1986)

I would like to perform this analysis using R, but I have not sucessed.

My first approach was to plot directly using the raster package.

plot(b1_2000, b1_1986) However i can not do the density map later using the
basic plot function.

Then I used the smothScatter function which allows to perform a density map
but I could not do it using a raster object, so I exported the raster as
txt in ARCGIS and then I read it in R

reflex1 <- (read.table("00_reflex.txt", sep = " ", skip = 6))
reflex2 <- (read.table("00_reflex.txt", sep = " ", skip = 6))

Later, I did the scatterplot showing the density of the pixels using the
smoothScatter function.

lab.palette <- colorRampPalette(c("blue", "orange", "red"), space = "Lab")
smoothScatter(reflex1, reflex2, colramp = lab.palette)

However, I am not able to set the scale and the color of the density map
easily, I may use the Transformation  and the colramp options but are not
very handy.

Now, I trying to do it using the ggplot2 package using the Stat_density2d
function but it seems that ggplot2 works only with dataframes. I am also
thinking that the  GeoXp package may be useful for this work.

I would like to ask you, which is the best approach for doing this analysis
using R?

Many thanks in advance

Cristi?n

	[[alternative HTML version deleted]]


From tkeitt at utexas.edu  Wed May 20 21:44:03 2015
From: tkeitt at utexas.edu (Tim Keitt)
Date: Wed, 20 May 2015 14:44:03 -0500
Subject: [R-sig-Geo] Change in proj strings?
In-Reply-To: <alpine.LFD.2.11.1505202037230.15946@reclus.nhh.no>
References: <CANnL8go1qn-C3w0Y1a7y=jLTfsZybNTRo3QG0wEj4_rYx33LpQ@mail.gmail.com>
	<alpine.LFD.2.11.1505202037230.15946@reclus.nhh.no>
Message-ID: <CANnL8gqH5MNs17oyG2QPgPAouydd2fUqz=s+tpF6vEZBccW6PA@mail.gmail.com>

http://www.keittlab.org/

On Wed, May 20, 2015 at 2:02 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Wed, 20 May 2015, Tim Keitt wrote:
>
>  I get: Error in CRS("+proj=longlat") : major axis or radius = 0 or not
>> given
>>
>> Never seen that before. What's the fix?
>>
>
> Depending on platform, you see different consequences.
>
> When PROJ.4 parses a string defining a spatial reference system, it wants
> something to give it a metric. The +ellps= tag is one such. In PROJ_LIB,
> there used to be a file (proj_def.dat), which contained +ellps=WGS84 as a
> default. On seeing any incoming string without any tags giving ellipsoid
> details, the default was used.
>
> The PROJ.4 trunk still has proj_def.dat, and up to and including 4.8.0, it
> was always shipped in the source and binaries (like Debian proj-data).
> Because the file seems to have been left out of 4.9.*RC* and 4.9.1, anyone
> deleting PROJ_LIB before installing the new version will lose access to the
> defaults. You can avoid using this file by saying:
>
> CRS("+proj=longlat +no_defs")
>
> and indeed that is why +init= generated parsed strings have +no_defs (no
> defaults) set - they ignore proj_def.dat.
>
> I've entered a PROJ.4 ticket #274 about missing proj_def.dat in released
> 4.9.1, and posted on the proj list without response so far.
>
> CRAN installed the Debian 4.9.1 packages on Monday with considerable
> fall-out, and many package maintainers have been contacted (some as early
> as the RC for 4.9.* by me and Edzer).
>
> One way to look at this is as a wake-up call reminding us that a metric
> really is needed in a spatial reference system definition. However, PROJ.4
> has broken its earlier practice of providing a reasonable default, very
> likely by mistake.
>
> The current status for CRAN is that Windows and Snow Leopard rgdal binary
> packages include proj_def.dat, OSX Mavericks does not (but will be rebuilt
> today, thanks to Simon Urbanek, so may get it - hard to inject
> automatically), and installs of rgdal from source depend on the platform
> PROJ.4. The recent Debian release is without proj_def.dat. The file itself
> may be added to PROJ_LIB manually, and downloaded from:
>
> http://trac.osgeo.org/proj/browser/trunk/proj/nad/proj_def.dat
>
> (unchanged in 14 years and very simple). I have no idea how it got lost
> from the PROJ.4 source distribution, but it isn't in proj-4.9.1/nad of:
>
> http://download.osgeo.org/proj/proj-4.9.1.tar.gz
>
> These things are sent to try us ...
>

Thanks. Right or wrong, that omission is going to break a lot of code.

THK


>
> Roger
>
>
>> THK
>> http://www.keittlab.org/
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
>

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Thu May 21 09:50:29 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 21 May 2015 09:50:29 +0200
Subject: [R-sig-Geo] How to use create_WX() correctly
In-Reply-To: <555BC5F4.7090600@gmail.com>
References: <555BC5F4.7090600@gmail.com>
Message-ID: <alpine.LFD.2.11.1505210931450.2842@reclus.nhh.no>

On Wed, 20 May 2015, Michael E. Rose wrote:

> Dear all,
> 
> I seem to have a serious problem with create_WX().
> 
> library(spdep)
> data(oldcol)
> lw <- nb2listw(COL.nb, style="W")
> X <- COL.OLD[, c("INC", "HOVAL")]
> WX <- create_WX(X, lw)
> creates a matrix with the last row being NA only. Why is that? However,
> building X using
> 
> X <- model.matrix(CRIME ~ INC + HOVAL, data=COL.OLD)
> WX <- create_WX(X, lw)
> 
> everything works, but both X look exactly similar to each other (except for
> the attribute and the "(Intercept)" column.

The original use scenario for create_WX() was for internal calculations in 
GNS, SDM, SDEM and SLX models. It was expected that the first argument 
would be taken from model.matrix(), but partly ignored the possibility 
that the formula could be without an intercept. If the style of the 
spatial weights is W (row-standardised), the lagged intercept needed to be 
dropped, but other cases led to index mis-counting. So yes, this was a 
bug. From SVN revision 634 on R-forge, users can now do:

library(spdep)
data(oldcol)
lw <- nb2listw(COL.nb, style="W")
X <- COL.OLD[, c("INC", "HOVAL")]
WX <- create_WX(X, lw, prefix="my_lag")
head(WX)
X1 <- model.matrix(CRIME ~ INC + HOVAL - 1, data=COL.OLD)
WX1 <- create_WX(X1, lw, prefix="my_lag1")
head(WX1)
X2 <- model.matrix(CRIME ~ INC + HOVAL, data=COL.OLD)
WX2 <- create_WX(X2, lw, prefix="my_lag2")
head(WX2)

and get the same values in the WX* matrices.

With regard to impacts in the current model:

y = (I - \rho W)^{-1}(Xb + W*Xd)

where W != W*, I believe that a unit change in x_r (the r_th covariate) 
will be S(W)_r = (I - \rho W)^{-1}(Ib_r + W*d_r). If your number of 
observations (n) is moderate, you can calculate this as a dense matrix, 
taking the mean of the diagonal of S(W)_r as the direct impacts and the 
sum of all the elements in S(W)_r divided by n as the total impacts.

You could also do this by predicting with the original data as newdata, 
saving the prediction, incrementing x_r by 1 and replacing its lag in W*X 
by the lag of the incremented values, and predicing with the incremented 
newdata. The mean of the difference between the predictions is the total 
impact. See LeSage & Pace 2009 for details.

It will be wrong to see x_r and W*x_r as separate variables in terms of 
impacts, as the unit increment of x_r enters both terms.

Hope this helps,

Roger

> 
> Kind regards,
> Michael
> 
> 
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From comunello.eder at gmail.com  Thu May 21 13:52:22 2015
From: comunello.eder at gmail.com (=?UTF-8?Q?=C3=89der_Comunello?=)
Date: Thu, 21 May 2015 07:52:22 -0400
Subject: [R-sig-Geo] gbif error message in package dismo
Message-ID: <CABmC8g=xM3axo=M5Bz4DDV=M7r+0y2cUZZGRJDbAmtVB9EpqFQ@mail.gmail.com>

Hello, Mark!

Could you update your packages and rerun the test? My guess is an issue
with {jsonlite} version when it tries binds the searches (nrecs=300)...

update.packages(ask=T)

?
================================================
?der Comunello
PhD Student in Agricultural Systems Engineering (USP/Esalq)
Brazilian Agricultural Research Corporation (Embrapa)
Dourados, MS, Brazil [22 16.5'S, 54 49.0'W]


2015-05-21 2:48 GMT-04:00 Mark van Kleunen <mark.vankleunen at uni-konstanz.de>
:

>  Dear Eder,
>
> The output of sessionInfo() is:
>
> > sessionInfo()
> R version 3.1.3 (2015-03-09)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
> Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252
> LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
>  [1] rworldmap_1.3-1  mapproj_1.2-2    maps_2.3-9       geosphere_1.3-11
> rgdal_0.9-1      rgbif_0.8.0
>  [7] shapefiles_0.7   foreign_0.8-61   XML_3.98-1.1     dismo_1.0-12
> rgeos_0.3-6      raster_2.3-0
> [13] maptools_0.8-30  sp_1.0-15
>
> loaded via a namespace (and not attached):
>  [1] chron_2.3-45     colorspace_1.2-4 data.table_1.9.4 digest_0.6.4
> fields_7.1       ggplot2_1.0.0
>  [7] grid_3.1.3       gtable_0.1.2     httr_0.5         jsonlite_0.9.12
> lattice_0.20-29  magrittr_1.5
> [13] MASS_7.3-35      munsell_0.4.2    plyr_1.8.1       proto_0.3-10
> Rcpp_0.11.3      reshape2_1.4
> [19] scales_0.2.4     spam_1.0-1       stringr_0.6.2    tools_3.1.3
> whisker_0.3-2
> >
>
> Interestingly, when I use "end=30)", then the error message does not
> appear.
> So,
> gb   <- gbif('Batrachoseps', 'luciae', start=1, end=30)
> > traceback()
> No traceback available
>
> When I set end=1000, then I get again the error message:
> > gb   <- gbif('Batrachoseps', 'luciae', start=1, end=1000)
> 0-300-600-900-1000 records
> Error in (function (classes, fdef, mtable)  :
>   unable to find an inherited method for function ?bind? for signature
> ?"data.frame", "data.frame"?
>
> Does this information provide any insight into what the problem might be?
>
> best,
> Mark
>
>
>

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Thu May 21 14:20:33 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 21 May 2015 14:20:33 +0200
Subject: [R-sig-Geo] Change in proj strings?
In-Reply-To: <CANnL8gqH5MNs17oyG2QPgPAouydd2fUqz=s+tpF6vEZBccW6PA@mail.gmail.com>
References: <CANnL8go1qn-C3w0Y1a7y=jLTfsZybNTRo3QG0wEj4_rYx33LpQ@mail.gmail.com>
	<alpine.LFD.2.11.1505202037230.15946@reclus.nhh.no>
	<CANnL8gqH5MNs17oyG2QPgPAouydd2fUqz=s+tpF6vEZBccW6PA@mail.gmail.com>
Message-ID: <alpine.LFD.2.11.1505211417180.2842@reclus.nhh.no>

Released: rgdal_0.9-3 (source) resolving the omitted proj_def.dat in PROJ 
4.9.1 issue is now on the central CRAN server, and will propagate to 
mirrors shortly. Binaries for Windows and OSX will be available in due 
course. Please let me know if this breaks anything else.

Roger

On Wed, 20 May 2015, Tim Keitt wrote:

> http://www.keittlab.org/
>
> On Wed, May 20, 2015 at 2:02 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Wed, 20 May 2015, Tim Keitt wrote:
>>
>>  I get: Error in CRS("+proj=longlat") : major axis or radius = 0 or not
>>> given
>>>
>>> Never seen that before. What's the fix?
>>>
>>
>> Depending on platform, you see different consequences.
>>
>> When PROJ.4 parses a string defining a spatial reference system, it wants
>> something to give it a metric. The +ellps= tag is one such. In PROJ_LIB,
>> there used to be a file (proj_def.dat), which contained +ellps=WGS84 as a
>> default. On seeing any incoming string without any tags giving ellipsoid
>> details, the default was used.
>>
>> The PROJ.4 trunk still has proj_def.dat, and up to and including 4.8.0, it
>> was always shipped in the source and binaries (like Debian proj-data).
>> Because the file seems to have been left out of 4.9.*RC* and 4.9.1, anyone
>> deleting PROJ_LIB before installing the new version will lose access to the
>> defaults. You can avoid using this file by saying:
>>
>> CRS("+proj=longlat +no_defs")
>>
>> and indeed that is why +init= generated parsed strings have +no_defs (no
>> defaults) set - they ignore proj_def.dat.
>>
>> I've entered a PROJ.4 ticket #274 about missing proj_def.dat in released
>> 4.9.1, and posted on the proj list without response so far.
>>
>> CRAN installed the Debian 4.9.1 packages on Monday with considerable
>> fall-out, and many package maintainers have been contacted (some as early
>> as the RC for 4.9.* by me and Edzer).
>>
>> One way to look at this is as a wake-up call reminding us that a metric
>> really is needed in a spatial reference system definition. However, PROJ.4
>> has broken its earlier practice of providing a reasonable default, very
>> likely by mistake.
>>
>> The current status for CRAN is that Windows and Snow Leopard rgdal binary
>> packages include proj_def.dat, OSX Mavericks does not (but will be rebuilt
>> today, thanks to Simon Urbanek, so may get it - hard to inject
>> automatically), and installs of rgdal from source depend on the platform
>> PROJ.4. The recent Debian release is without proj_def.dat. The file itself
>> may be added to PROJ_LIB manually, and downloaded from:
>>
>> http://trac.osgeo.org/proj/browser/trunk/proj/nad/proj_def.dat
>>
>> (unchanged in 14 years and very simple). I have no idea how it got lost
>> from the PROJ.4 source distribution, but it isn't in proj-4.9.1/nad of:
>>
>> http://download.osgeo.org/proj/proj-4.9.1.tar.gz
>>
>> These things are sent to try us ...
>>
>
> Thanks. Right or wrong, that omission is going to break a lot of code.
>
> THK
>
>
>>
>> Roger
>>
>>
>>> THK
>>> http://www.keittlab.org/
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From kimofos at yahoo.com  Fri May 22 13:51:29 2015
From: kimofos at yahoo.com (Mohammad Abdel-Razek)
Date: Fri, 22 May 2015 11:51:29 +0000 (UTC)
Subject: [R-sig-Geo] Converting large RasterStack to CSVs fast
In-Reply-To: <mailman.9.1431770403.17365.r-sig-geo@r-project.org>
References: <mailman.9.1431770403.17365.r-sig-geo@r-project.org>
Message-ID: <1598157920.372596.1432295489967.JavaMail.yahoo@mail.yahoo.com>

Hello Comunello!
Thanks for the reply. Your vectorized code is faster than the one I have, by a margin of 5%, which is an improvement. I think the limiting step is clipping. Is there any paralleled? version of clip?
Mohammad
?
From: "r-sig-geo-request at r-project.org" <r-sig-geo-request at r-project.org>
 To: r-sig-geo at r-project.org 
 Sent: Saturday, May 16, 2015 12:00 PM
 Subject: R-sig-Geo Digest, Vol 141, Issue 16
   
Send R-sig-Geo mailing list submissions to
??? r-sig-geo at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
??? https://stat.ethz.ch/mailman/listinfo/r-sig-geo
or, via email, send a message with subject or body 'help' to
??? r-sig-geo-request at r-project.org

You can reach the person managing the list at
??? r-sig-geo-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-Geo digest..."


Today's Topics:

? 1. Re: Issue with ogrInfo (?der Comunello)
? 2. Re: Converting large RasterStack to CSVs fast (?der Comunello)
? 3. create a shapefile (Gustavo Dalposso)
? 4. Re: create a shapefile (Felinto COSTA)


----------------------------------------------------------------------

Message: 1
Date: Fri, 15 May 2015 07:41:57 -0400
From: ?der Comunello <comunello.eder at gmail.com>
To: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] Issue with ogrInfo
Message-ID:
??? <CABmC8g=ZAFGTu=RJ6BaZjD76gstYwrRJ=rRPqPCuE6WDKVkaqQ at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Hello,

I think the problem is that your link is recovering only html code from
github site. It's necessary to modify it to get the "real" JSON file.

### <code r>
sapply(c("rgeos", "maptools", "rgdal"), require, char=T)
url0 <- "
https://github.com/kjhealy/uk-elections/blob/master/maps/topo_wpc.json"
download.file(url0, dest=basename(url0), mode="wb")
# downloaded 26 KB

uk.map <- readOGR(basename(url0), "wpc")
# Error in ogrInfo(dsn = dsn, layer = layer, encoding = encoding, use_iconv
= use_iconv,? :
#? Cannot open file

url1 <- "
https://raw.githubusercontent.com/kjhealy/uk-elections/master/maps/topo_wpc.json
"
download.file(url1, dest=basename(url0), mode="wb")
# downloaded 2.3 MB

uk.map <- readOGR(basename(url1), "wpc")
# OGR data source with driver: GeoJSON
# Source: "topo_wpc.json", layer: "wpc"
# with 632 features
# It has 2 fields

plot(uk.map)
### </code>

?der Comunello <c <comunello.eder at gmail.com>omunello.eder at gmail.com>
Dourados, MS - [22 16.5'S, 54 49'W]

??? [[alternative HTML version deleted]]



------------------------------

Message: 2
Date: Fri, 15 May 2015 12:35:44 -0400
From: ?der Comunello <comunello.eder at gmail.com>
To: "r-sig-geo at r-project.org" <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Converting large RasterStack to CSVs fast
Message-ID:
??? <CABmC8gmd8aV6WBRpXRGnwbmRht8Z_MX3WWd9=N999RzoaZVoRA at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Hello, Mohammad!

You may have some improvement in performance avoiding "for statements" and
using a "vectorized" code. You could try something like the code below.

If you can test with your data, i would appreciate if you inform the
results.

### <code r>
require(rgdal); require(raster)

getwd()
### download some data to test
getData("worldclim", var = "tmin", res = 10) ### tmin
fn <- dir("wc10", patt=".bil$", full=T)
fn <- fn[order(nchar(fn), fn)]; fn
#? [1] "wc10/tmin1.bil"? "wc10/tmin2.bil"? "wc10/tmin3.bil"? ...

### read images
s <- stack(fn) ### dimensions? : 900, 2160, 1944000, 12? (nrow, ncol,
ncell, nlayers)
fromDisk(s)

### extents of subsets
bor <- extent(s); bor
res <- 45 ### subsets resolution
X? <- unique(c(seq(bor at xmin, bor at xmax, by=res), bor at xmax)); X
Y? <- unique(c(seq(bor at ymin, bor at ymax, by=res), bor at ymax)); Y
ext <- cbind(expand.grid(Xmin=X[-length(X)], Ymin=Y[-length(Y)]),
? ? ? ? ? ? expand.grid(Xmax=X[-1], Ymax=Y[-1]))[,c(1,3,2,4)]
head(ext); nrow(ext)

plot(s, 1)
system.time(
sapply(1:nrow(ext), function(i) {
? ? mask <- ext[i,]
? ? subset <- with(mask, extent(c(Xmin, Xmax, Ymin, Ymax)))
? ? plot(subset, add=T)
? ? text(rowMeans(mask[,1:2]), rowMeans(mask[,3:4]), lab=i)
? ? c <- crop(s, subset)
? ? write.table(as.data.frame(rasterToPoints(c)), paste0("p",i,".txt"), )
}))
#? ? user? system elapsed
#? 213.79? ? 7.00? 224.94

txt <- dir(patt="^p[0-9]+.txt$")
txt <- txt[order(nchar(txt), txt)]; txt
#? [1] "p1.txt"? "p2.txt"? "p3.txt"? "p4.txt"? ...

### </code>


Cheers,

?der Comunello <c <comunello.eder at gmail.com>omunello.eder at gmail.com>
Dourados, MS - [22 16.5'S, 54 49'W]



?der Comunello <c <comunello.eder at gmail.com>omunello.eder at gmail.com>
Dourados, MS - [22 16.5'S, 54 49'W]

2015-05-15 5:43 GMT-04:00 Mohammad Abdel-Razek via R-sig-Geo <
r-sig-geo at r-project.org>:

> Hi
> I got a function to convert ndvi raster stack to CSVs. Each stack is
> divided into 100 subset, which is convert to csv. The code works for small
> raster stack, for large ones, I cannot load them into the memory, then it
> takes massive time to do the task.
>
> is there a better way to do it?
>
> The code is below:
>
> require(gdal)
> require(raster)
>
> exportCSV <- function () {
>? tif <- list.files(pattern='NDVI.tif$')
>? wd <- getwd()
>? ModisTile<-? substr(wd, nchar(wd)-5, nchar(wd))
>? nImages <- length(tif)
>? cat(paste("Stacking images ...", "\n"))
>? s <- stack(tif)
>? cat(paste("Loading values to RAM memory ...", "\n"))
> #this step is skipped in case of large stacks, then it takes very long time
>? s <- readAll(s)
> #create the subsets bounding coordinates
>? borders <- extent(s)
>? Xmin <- borders at xmin
>? Xmax <- borders at xmax
>? Ymin <- borders at ymin
>? Ymax <- borders at ymax
>? xIncreament <-(Xmax-Xmin)/10
>? yIncreament <-(Ymax-Ymin)/10
>? cat(paste("Subsetting and writing NDVI values ...", "\n"))
>? for (i in 1:10) {
>? ? for (j in 1:10) {
>? ? ? clip_xmin <- Xmin + xIncreament*(i-1)
>? ? ? clip_xmax <- Xmin + xIncreament*i
>? ? ? clip_ymin <- Ymin + yIncreament*(j-1)
>? ? ? clip_ymax <- Ymin + yIncreament*j
>? ? ? c_xmin <- format(round(clip_xmin,6), nsmall=6)
>? ? ? c_xmax <- format(round(clip_xmax,6), nsmall=6)
>? ? ? c_ymin <- format(round(clip_ymin,6), nsmall=6)
>? ? ? c_ymax <- format(round(clip_ymax,6), nsmall=6)
>
>? ? ? subset <- extent(c(clip_xmin, clip_xmax, clip_ymin, clip_ymax))
>? ? ? c <- crop(s, subset)
>? ? ? p <- as.data.frame(rasterToPoints(c))
>? ? ? csvName <- paste0(ModisTile, "_Xmin_",c_xmin, "_Xmax_",c_xmax,
> "_Ymin_",c_ymin, "_Ymax_",c_ymax,".csv")
>? ? ? cat(paste("Writing Subset... MOIDS Tile:", ModisTile,", X", i, "Y",
> j, "\n"))
>? ? ? write.table(p, csvName, row.names=F, sep=";", dec=".")
>? ? }
>? }
> }
>
> Best,
> Mohammad PhD Candidate? Institute of Crop Science and Resource Protection
> - Crop Science Research Group
> Katzenburgweg 5 - 53115 Bonn - Germany
>? Tel.: +49 (0) 228 73 3258? ? ? Fax: +49 (0) 228 73 2870
> abdelrazek at uni-bonn.de? ? ? ? http://www.lap.uni-bonn.de
>
>? ? ? ? [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

??? [[alternative HTML version deleted]]



------------------------------

Message: 3
Date: Fri, 15 May 2015 19:09:07 +0000
From: Gustavo Dalposso <gustavodalposso at hotmail.com>
To: "r-sig-geo at r-project.org" <r-sig-geo at r-project.org>
Subject: [R-sig-Geo] create a shapefile
Message-ID: <SNT152-W5068688FE73BB915BA33D2BBC70 at phx.gbl>
Content-Type: text/plain; charset="iso-8859-1"

Hello friends of R


I have a map in BMP format (a figure).
 The map consists of 14 areas.
 I have the location of two coordinates. (x1, y1) and (x2, y2)
 See the attached image.

 Question: Is it possible to create a shapefile? Which package I use?

Atte.
Gustavo Henrique Dalposso ??? ??? ??? ? ??? ??? ? 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150515/df1e9d08/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: map.JPG
Type: image/jpeg
Size: 11778 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150515/df1e9d08/attachment-0001.jpe>

------------------------------

Message: 4
Date: Fri, 15 May 2015 16:44:13 -0300
From: Felinto COSTA <incorpld at onda.com.br>
To: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] create a shapefile
Message-ID: <55564C8D.1040504 at onda.com.br>
Content-Type: text/plain; charset="UTF-8"

Gustavo.

Se vc. tiver esse mapa em formato CAD (dxf ou dwg) pode usar o Cad2Shape 
(http://www.guthcad.com.au/cad2shape.htm).
Ele permite algumas utiliza?s em sua vers?"free".
Se n?tiver, tente passar para os formatos de CAD usando, talvez, o 
Img2Cad (http://www.img2cad.com/).
J?sei apenas o primeiro.

Felinto COSTA


On 15/5/2015 16:09, Gustavo Dalposso wrote:
> Hello friends of R
>
>
> I have a map in BMP format (a figure).
> The map consists of 14 areas.
> I have the location of two coordinates. (x1, y1) and (x2, y2)
> See the attached image.
>
> Question: Is it possible to create a shapefile? Which package I use?
>
> Atte.
> Gustavo Henrique Dalposso
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


??? [[alternative HTML version deleted]]



------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


------------------------------

End of R-sig-Geo Digest, Vol 141, Issue 16
******************************************


  
	[[alternative HTML version deleted]]


From amit.boshale at yahoo.com  Fri May 22 14:04:57 2015
From: amit.boshale at yahoo.com (Amit Boshale)
Date: Fri, 22 May 2015 12:04:57 +0000 (UTC)
Subject: [R-sig-Geo] Processing best quality MODIS pixels only (MODIS
	package)
In-Reply-To: <840394359.4478448.1432122549210.JavaMail.yahoo@mail.yahoo.com>
References: <555BB0E40200002700027037@gwia2.boku.ac.at>
	<840394359.4478448.1432122549210.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1969532926.507749.1432296297551.JavaMail.yahoo@mail.yahoo.com>

Dear Matteo,
I just found out something interesting. As I mentioned in my previous email, I tried the code you proposed and could see the diffference from the old code, basically a smoother plot. However, the plot didn't change corresponding to differenct quality thresohold (1, 2, 3, 4 and 5). 

Then I realized that the smoother time series was due to larger Lambda. It was misspled in the code, hence MODIS package took a default value of 5000 rather than the 500 I used in the code. 

It might be due to the presence of another threshold (outlier removal) used in MODIS package 0.10-18, hence the package ignored the value. In your newst package (0.10-23) outlier threshold variable name is changed. But the new package doesn't allow for using cluster (it throughs an error), so I couldn't try.
Hope the remark could be helpful in any future improvments :D
Best,Amit
 


     Amit Boshale <amit.boshale at yahoo.com> schrieb am 13:49 Mittwoch, 20.Mai 2015:
   

 Dear Matteo,
Many thanks for the help!?
I just tried it on a small raster stack and it worked. The resulting time series looks better. I will keep trying with other threshold values(2,3,etc.)to compare the resulting graphs for improved visual interpretation.?
Best,Amit


 


     Matteo Mattiuzzi <matteo.mattiuzzi at boku.ac.at> schrieb am 21:53 Dienstag, 19.Mai 2015:
   

 Dear Amit,
Thats correct, if you want to use only pixel of 0000 quality you have to set 0 as threshold (everything > than threshold is set to 0 weight). But for what I remember, and this might explains your result with all 0s, is that 0000 does not exist in MODIS data despite the fact that it is described so on the website. You can use the decodeOnly=TRUE option to see the exact values of your quality layers, but I guess you will not find any values lower than 1.
If you run whittaker.raster, you can feed also argument of the makeWeights function. If you use a cluster this step is parallelized automatically.
I gave a short look to makeWeights now, probably I can do some little speed improvements.

It should be possible to do:

library("MODIS")
path=("E:/NDVI/Indonesia")
#stack ndvi images, following MODIS package example
ndvi = preStack(pattern = "*_NDVI.tif", path = path)
timeInfo <- orgTime(ndvi,nDays=16,begin="2000049",end="2015049",pillow=40)
#Restack evi
ndvi <- preStack(files=ndvi,timeInfo=timeInfo)
# You don't need to stack here, it is done with stack(...quick=TRUE) within whittaker.raster.
wt? <- preStack(path=path, pattern="*_VI_Quality.tif$", timeInfo=timeInfo)
inT <- preStack(path=path, pattern="*_composite_day_of_the_year.tif", timeInfo=timeInfo)
nodes <- 4
library(snow)
beginCluster(nodes)
system.time(whittaker.raster(vi=ndvi, wt = wt, inT = inT, timeInfo = timeInfo, lamba = 500, bitShift = 2, bitMask = 15, threshold = 1))
endCluster()

Matteo


>>> Amit Boshale <amit.boshale at yahoo.com> 05/19/15 4:54 PM >>>
Hello!
I use MODIS package to smooth MODIS NDVI raster time series. 
Just wanted to try how would it look like if I used the best qulity pixels only.makeWeights function took about two days and resulted in raster stack of zeros. According to MODIS, the best qulity is 0, hence I used 0 as the threshold, is that correct? Is there a multicore version of makeWeights function?
Best,Amit
library("MODIS")path=("E:/NDVI/Indonesia")
#stack ndvi images, following MODIS package example
ndvi = preStack(pattern = "*_NDVI.tif", path = path)
timeInfo <- orgTime(ndvi,nDays=16,begin="2000049",end="2015049",pillow=40)
#Restack evi
ndvi <- preStack(files=ndvi,timeInfo=timeInfo)
#stack Vegtation index quality layers
VIqual <- stack(preStack(path=path, pattern="*_VI_Quality.tif", timeInfo=timeInfo))
bitShift = 2
bitMask = 15 
threshold=0 # based on MODIS documentation, quality 0 is the best
wt <- makeWeights(VIqual,bitShift,bitMask,threshold,decodeOnly=FALSE)
#stack composite day of the year layers
inT <- stack(preStack(path=path, pattern="*_composite_day_of_the_year.tif", timeInfo=timeInfo))
nodes <- 4
library(snow)
beginCluster(nodes)
system.time(whittaker.raster(vi=ndvi, wt=wt, inT=inT, timeInfo=timeInfo, lambda=500))
endCluster()





   

  
	[[alternative HTML version deleted]]


From srinivasv at feralindia.org  Fri May 22 15:21:29 2015
From: srinivasv at feralindia.org (Srinivas V)
Date: Fri, 22 May 2015 18:51:29 +0530
Subject: [R-sig-Geo] Fitting a basic structural model to a raster brick
In-Reply-To: <1432046840143.57518@wur.nl>
References: <555B14B4.30300@feralindia.org> <1432046840143.57518@wur.nl>
Message-ID: <555F2D59.5060605@feralindia.org>

Hi Lo?c,
Thanks for the response. I took a few pixels and checked it converting 
it to a vector the errors were due formatting of the time-series.
As you have pointed out the revised script is very slow and I suspect it 
is slow because it returns a raster layer instead of a brick, it should 
have the same number of layers as the original brick. Caused by sapply? 
How do I resolve this?

Thanks for your advice.
Regrads

Srinivas Vaidyanathan
Senior Research Fellow
Foundation for Ecological Research, Advocacy & Learning

Web:www.feralindia.org  

On Tuesday 19 May 2015 08:17 PM, Dutrieux, Loic wrote:
> Hi Srinivas,
>
> I do not think calc handles the z dimension by itself, you need to format the time-series within the function you're giving to calc().
> I got an example below kind of working but it is so slow that I suspect something is not going right with it. I think the key is to figure the right formatting for the time-series you give to StructTS().
>
> library(raster)
> library(bfast)
> library(zoo)
> f <- system.file("extdata/modisraster.grd", package="bfast")
> modisbrick<-brick(f)
> modisbrick<-setZ(modisbrick,as.Date(strptime(paste(substr(names(modisbrick),start=2, stop=12)),"%Y.%m.%d")))
>
>
> time <- getZ(modisbrick)
>
> xStructTS <- function(x) {
>    ts <- bfastts(x, time, type='16-day')
>    fun <- function(ts) {
>      StructTS(ts, type = 'BSM')$fitted[1]
>    }
>    fit <- sapply(ts, fun)
>    return(fit)
> }
>
> r1.structs<- calc(modisbrick, fun=xStructTS) # Extremely slow
>
> r1.structs
>
>
>
> You can try to find the right formatting for the StructTS function by working on a single vector.
>
> ts <- zoo(t(modisbrick[1]), time)
> StructTS(ts, type = 'BSM') # Returns an error about frequency of the data
>
> ts  <- bfastts(t(modisbrick[1]), time, type='16-day')
> StructTS(ts, type = 'BSM') # Works but really slowly
>
>
> Hope it helps,
> Lo?c
>   
> ________________________________________
> From: R-sig-Geo<r-sig-geo-bounces at r-project.org>  on behalf of Srinivas V<srinivasv at feralindia.org>
> Sent: Tuesday, May 19, 2015 12:47 PM
> To:r-sig-geo at r-project.org
> Subject: [R-sig-Geo] Fitting a basic structural model to a raster brick
>
> Dear Members
> I'm trying to write a function to fit a basic structural model to a
> raster brick of NDVI data. I looked up earlier post and figured out the
> use of wrapper functions and calc(). However I have not been very
> successful.
> library(raster)
> f <- system.file("extdata/modisraster.grd", package="bfast")
> modisbrick<-brick(f)
> modisbrick<-setZ(modisbrick,as.Date(strptime(paste(substr(names(modisbrick),start=2,
> stop=12)),"%Y.%m.%d")))
> xStructTS <- function(x) {
>     fit <- StructTS((x),type="level")
>     return(fit$fitted[1])}
>
> r1.structs<- calc(modisbrick, fun=function(x){
>     res <- (apply(x, 2, xStructTS))
>     return(res)
> })
>
> r1.structs
>
> Returns a brick with levels not a problem so far. However when I change
> the class of the model I get errors.
>
>
> ### Change type from level to BSM ###
> xStructTS <- function(x) {
>     fit <- StructTS((x),type="BSM")
>     return(fit$fitted[1])}
> r1.structs<- calc(modisbrick, fun=function(x){
>     res <- (apply(x, 2, xStructTS))
>     return(res)
> })
> Error in .calcTest(x[1:5], fun, na.rm, forcefun, forceapply) : cannot
> use this function
> Not sure why I'm getting this error message, the data does not have any
> NA. Is this error related to the the class of structural model? How do I
> overcome this error?
>
> Second actual NDVI data for which I'm writting the function has NAs due
> to a cropping and masking. Any suggestion to fix this error and also
> address issues of NAs is greatly appreciated.
>
> Thanks
>
> --
>
> Srinivas Vaidyanathan
> Senior Research Fellow
> Foundation for Ecological Research, Advocacy & Learning
>
> Web:www.feralindia.org
>
>
>          [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


	[[alternative HTML version deleted]]


From aspiringbodhisattva at gmail.com  Fri May 22 16:21:53 2015
From: aspiringbodhisattva at gmail.com (Mike)
Date: Fri, 22 May 2015 10:21:53 -0400
Subject: [R-sig-Geo] poly over poly spatial / rgeos function; memory tips
Message-ID: <CAF97oXtETX8NRA+f2BVa7DLuDV8E4mEW44vcDdrSXbeGo=cOMg@mail.gmail.com>

Hi all, big fan of the listserv, learning a lot.

I've a few hopefully questions about the sp and rgeos packages.

#1 I've had success using %over% in the sp packages, but can't seem to find
the help for poly-poly (spatial poly data frame or spatial poly over the
same), implemented in rgeos.  Where is that explained?  I can't seem to get
it to return an aggregation in the way poly over points does, where I can
use fun=sum to aggregate a number of data frame columns at once.  I've read
a number of 3rd party explanations and poked in a few books, but haven't
found much on poly poly data aggregation with over.

#2 for large geometries, any suggestions of way to be more efficient in
general in spatial work?  I love the gRelate function (see below), but for
attempting to aggregate ~2000 3mile buffers over ~200,000 NC census blocks,
gRelate seems to fail more often than not.  (I really only need OVER in
this case, but have tried work arounds since, in #1, I can't get over to
work poly-poly the way I need).

Thanks!  More detail and specific case below.

Best,
Mike
UNC Epidemiology

====

Context:

I'm working on porting an environmental epidemiology project done in Arc
and STATA to all R.  Relevant context - we have point exposures (in this
case, industrial hog operations) with 3 mile buffers to represent their
exposure radius (red dots and pink buffers in the map, from gBuffer after
spTransform).  Exclusion criteria (blue shapes) are (1) counties that only
border IHOs-less counties (grey) and the five most populous cities (where
IHOs are never cited) - that's done through the fantastic gRelate function
(see below for code).

IHOblob = gUnionCascaded(hasIHOcounties)
#plot(IHOblob) #can plot this to check it out.
touch.v = gRelate(noIHOcounties, IHOblob, byid = T)
str(touch.v)
counties.not.touching<-(touch.v %in% c("FF2FF1212")) #DE-91M is super cool.
notouchIHOcounties = noIHOcounties[counties.not.touching,]
plot(notouchIHOcounties, co="light blue", lwd=0.6, add=T)

See image for a quick visual of what's going on:
http://i.imgur.com/4m6CgW8.png

The analysis, however, is happening at the census block level.  Here's
where I have two challenges I'm hoping to get some help with.

#1 poly over poly dataframe aggregation:  I understand that the %over%
function for poly-poly is implemented in rgeos instead of sp (see table
below).  Sp's over help clarifies how arguments need to be aligned or
stripped of data frames to get what you want.  So, for instance, as a test
case, here's successful code to aggregate the *point* data on IHOs to their
respective counties (if there's a better way to do this, Please let me
know):
NC.counties.shp at data = data.frame(c(NC.counties.shp at data,
over(NC.counties.shp, IHOs.spdf, fun=sum)))

Over implementations: http://i.imgur.com/X8Im2gI.png

However, the goal for the census blocks is to aggregate various
quantitative variables from IHOs within 3 miles (hence the buffer) of any
point on the edge.  I can imagine some brute force looping methods using
the gRelate function, or distance, but can't seem to nail it in one pass
with over the way I might with QGIS or Arc.  In the below case,
IHOs.3mibuff.spdf is now a spatial poly data frame, as are the study
blocks.  When I try passing the first argument (counties or blocks) as just
a geometry, I still get a matrix of named rows and some single aggregated
number - but not all the aggregated columns in the data frame.
test <-over(NC.studyblocks.shp at polygons, IHOs.3mibuff.spdf, fun=sum) ??
test <-over(NC.studyblocks.shp, IHOs.3mibuff.spdf, fun=sum) ??

#2 Issues with memory.  I've read a few tip sets on generic size best
practices that aren't spatial specific, but if anyone has any tips, I'd
love to hear them.  I seem to have had some success with gc() after large
subsetting.  In (probably miscoding) the analysis of gRelate of 200,000
blocks and 2,000 buffer circles, I eat up 6gigs with ease.

Best wishes, again,
mike
-- 
---
Mike Dolan Fliss, MSW
mike.dolan.fliss at gmail.com
UNC-CH Epidemiology PhD student
NC public health advocate!

	[[alternative HTML version deleted]]


From aspiringbodhisattva at gmail.com  Fri May 22 16:41:15 2015
From: aspiringbodhisattva at gmail.com (Mike)
Date: Fri, 22 May 2015 10:41:15 -0400
Subject: [R-sig-Geo] poly %over% poly in rgeos; memory tips
Message-ID: <CAF97oXvZu9MRSVNJcZj3b9NJ+7ETyA0+6tWqopi+PGKMK5j1vQ@mail.gmail.com>

Hi all, big fan of the listserv, learning a lot.

I've a few hopefully questions about the sp and rgeos packages.

#1 I've had success using %over% in the sp packages, but can't seem to find
the help for poly-poly (spatial poly data frame or spatial poly over the
same), implemented in rgeos.  Where is that explained?  I can't seem to get
it to return an aggregation in the way poly over points does, where I can
use fun=sum to aggregate a number of data frame columns at once.  I've read
a number of 3rd party explanations and poked in a few books, but haven't
found much on poly poly data aggregation with over.

#2 for large geometries, any suggestions of way to be more efficient in
general in spatial work?  I love the gRelate function (see below), but for
attempting to aggregate ~2000 3mile buffers over ~200,000 NC census blocks,
gRelate seems to fail more often than not.  (I really only need OVER in
this case, but have tried work arounds since, in #1, I can't get over to
work poly-poly the way I need).

Thanks!  More detail and specific case below.

Best,
Mike
UNC Epidemiology

====

Context:

I'm working on porting an environmental epidemiology project done in Arc
and STATA to all R.  Relevant context - we have point exposures (in this
case, industrial hog operations) with 3 mile buffers to represent their
exposure radius (red dots and pink buffers in the map, from gBuffer after
spTransform).  Exclusion criteria (blue shapes) are (1) counties that only
border IHOs-less counties (grey) and the five most populous cities (where
IHOs are never cited) - that's done through the fantastic gRelate function
(see below for code).

IHOblob = gUnionCascaded(hasIHOcounties)
#plot(IHOblob) #can plot this to check it out.
touch.v = gRelate(noIHOcounties, IHOblob, byid = T)
str(touch.v)
counties.not.touching<-(touch.v %in% c("FF2FF1212")) #DE-91M is super cool.
notouchIHOcounties = noIHOcounties[counties.not.touching,]
plot(notouchIHOcounties, co="light blue", lwd=0.6, add=T)

See image for a quick visual of what's going on:
http://i.imgur.com/4m6CgW8.png

The analysis, however, is happening at the census block level.  Here's
where I have two challenges I'm hoping to get some help with.

#1 poly over poly dataframe aggregation:  I understand that the %over%
function for poly-poly is implemented in rgeos instead of sp (see table
below).  Sp's over help clarifies how arguments need to be aligned or
stripped of data frames to get what you want.  So, for instance, as a test
case, here's successful code to aggregate the *point* data on IHOs to their
respective counties (if there's a better way to do this, Please let me
know):
NC.counties.shp at data = data.frame(c(NC.counties.shp at data,
over(NC.counties.shp, IHOs.spdf, fun=sum)))

Over implementations: http://i.imgur.com/X8Im2gI.png

However, the goal for the census blocks is to aggregate various
quantitative variables from IHOs within 3 miles (hence the buffer) of any
point on the edge.  I can imagine some brute force looping methods using
the gRelate function, or distance, but can't seem to nail it in one pass
with over the way I might with QGIS or Arc.  In the below case,
IHOs.3mibuff.spdf is now a spatial poly data frame, as are the study
blocks.  When I try passing the first argument (counties or blocks) as just
a geometry, I still get a matrix of named rows and some single aggregated
number - but not all the aggregated columns in the data frame.
test <-over(NC.studyblocks.shp at polygons, IHOs.3mibuff.spdf, fun=sum) ??
test <-over(NC.studyblocks.shp, IHOs.3mibuff.spdf, fun=sum) ??

#2 Issues with memory.  I've read a few tip sets on generic size best
practices that aren't spatial specific, but if anyone has any tips, I'd
love to hear them.  I seem to have had some success with gc() after large
subsetting.  In (probably miscoding) the analysis of gRelate of 200,000
blocks and 2,000 buffer circles, I eat up 6gigs with ease.

Best wishes, again,
mike

	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Fri May 22 17:50:22 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 22 May 2015 17:50:22 +0200
Subject: [R-sig-Geo] poly %over% poly in rgeos; memory tips
In-Reply-To: <CAF97oXvZu9MRSVNJcZj3b9NJ+7ETyA0+6tWqopi+PGKMK5j1vQ@mail.gmail.com>
References: <CAF97oXvZu9MRSVNJcZj3b9NJ+7ETyA0+6tWqopi+PGKMK5j1vQ@mail.gmail.com>
Message-ID: <555F503E.3040508@uni-muenster.de>

Mike, you may want to read two recent threads:

https://stat.ethz.ch/pipermail/r-sig-geo/2015-April/022624.html
https://stat.ethz.ch/pipermail/r-sig-geo/2015-April/022663.html

When you try to aggregate, instead of using over(), have you used
sp::aggregate directly, for instance with option areaWeighted = TRUE?

If memory is a bottle neck, I'd suggest to either buy more of it, or
choose a workflow that needs less of it, like PostGIS with SQL.

On 05/22/2015 04:41 PM, Mike wrote:
> Hi all, big fan of the listserv, learning a lot.
> 
> I've a few hopefully questions about the sp and rgeos packages.
> 
> #1 I've had success using %over% in the sp packages, but can't seem to find
> the help for poly-poly (spatial poly data frame or spatial poly over the
> same), implemented in rgeos.  Where is that explained?  I can't seem to get
> it to return an aggregation in the way poly over points does, where I can
> use fun=sum to aggregate a number of data frame columns at once.  I've read
> a number of 3rd party explanations and poked in a few books, but haven't
> found much on poly poly data aggregation with over.
> 
> #2 for large geometries, any suggestions of way to be more efficient in
> general in spatial work?  I love the gRelate function (see below), but for
> attempting to aggregate ~2000 3mile buffers over ~200,000 NC census blocks,
> gRelate seems to fail more often than not.  (I really only need OVER in
> this case, but have tried work arounds since, in #1, I can't get over to
> work poly-poly the way I need).
> 
> Thanks!  More detail and specific case below.
> 
> Best,
> Mike
> UNC Epidemiology
> 
> ====
> 
> Context:
> 
> I'm working on porting an environmental epidemiology project done in Arc
> and STATA to all R.  Relevant context - we have point exposures (in this
> case, industrial hog operations) with 3 mile buffers to represent their
> exposure radius (red dots and pink buffers in the map, from gBuffer after
> spTransform).  Exclusion criteria (blue shapes) are (1) counties that only
> border IHOs-less counties (grey) and the five most populous cities (where
> IHOs are never cited) - that's done through the fantastic gRelate function
> (see below for code).
> 
> IHOblob = gUnionCascaded(hasIHOcounties)
> #plot(IHOblob) #can plot this to check it out.
> touch.v = gRelate(noIHOcounties, IHOblob, byid = T)
> str(touch.v)
> counties.not.touching<-(touch.v %in% c("FF2FF1212")) #DE-91M is super cool.
> notouchIHOcounties = noIHOcounties[counties.not.touching,]
> plot(notouchIHOcounties, co="light blue", lwd=0.6, add=T)
> 
> See image for a quick visual of what's going on:
> http://i.imgur.com/4m6CgW8.png
> 
> The analysis, however, is happening at the census block level.  Here's
> where I have two challenges I'm hoping to get some help with.
> 
> #1 poly over poly dataframe aggregation:  I understand that the %over%
> function for poly-poly is implemented in rgeos instead of sp (see table
> below).  Sp's over help clarifies how arguments need to be aligned or
> stripped of data frames to get what you want.  So, for instance, as a test
> case, here's successful code to aggregate the *point* data on IHOs to their
> respective counties (if there's a better way to do this, Please let me
> know):
> NC.counties.shp at data = data.frame(c(NC.counties.shp at data,
> over(NC.counties.shp, IHOs.spdf, fun=sum)))
> 
> Over implementations: http://i.imgur.com/X8Im2gI.png
> 
> However, the goal for the census blocks is to aggregate various
> quantitative variables from IHOs within 3 miles (hence the buffer) of any
> point on the edge.  I can imagine some brute force looping methods using
> the gRelate function, or distance, but can't seem to nail it in one pass
> with over the way I might with QGIS or Arc.  In the below case,
> IHOs.3mibuff.spdf is now a spatial poly data frame, as are the study
> blocks.  When I try passing the first argument (counties or blocks) as just
> a geometry, I still get a matrix of named rows and some single aggregated
> number - but not all the aggregated columns in the data frame.
> test <-over(NC.studyblocks.shp at polygons, IHOs.3mibuff.spdf, fun=sum) ??
> test <-over(NC.studyblocks.shp, IHOs.3mibuff.spdf, fun=sum) ??
> 
> #2 Issues with memory.  I've read a few tip sets on generic size best
> practices that aren't spatial specific, but if anyone has any tips, I'd
> love to hear them.  I seem to have had some success with gc() after large
> subsetting.  In (probably miscoding) the analysis of gRelate of 200,000
> blocks and 2,000 buffer circles, I eat up 6gigs with ease.
> 
> Best wishes, again,
> mike
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150522/84439dbb/attachment.bin>

From rotundo.jose at gmail.com  Fri May 22 18:16:36 2015
From: rotundo.jose at gmail.com (=?UTF-8?Q?Jos=C3=A9_Luis_Rotundo?=)
Date: Fri, 22 May 2015 13:16:36 -0300
Subject: [R-sig-Geo] Problem plotting state borders
Message-ID: <CADBY2pp+ERa4cjLbjF8U8wPzp4XMXJvLZq=6v25izxXiBPPGxw@mail.gmail.com>

Dear List,

I want to plot a US county level map with counties colored according a
categorical variable. I was successful for the most part, but when
trying to add state level borders, to make the map look better, the
borders do not follow the geographical limits.

Here is the link to the map I ended up with: http://imgur.com/UqcpVBW

If you want to reproduce the what I am doing, the data is here:
http://www.filedropper.com/data_4

Below is the code I am using.

Thanks a lot in advance for any help to solve this problem.

Jos? L. Rotundo
CONICET
Facultad de Ciencias Agrarias
Univ. Nacional de Rosario
Zavalla, Santa Fe
Argentina

#############################################################
# Pick the colors for the categorical values
colors = c("#CC0000", "#FF9999", "#E0E0E0", "#99FF99", "#00CC00")

#Creates a new variable with the categories.
data$colorBuckets <- as.numeric(cut(data$Slope, c(-0.30, -0.20, -0.10, 0.10,
                                                    0.20, 0.30)))

# Put a 3 (equivalent to slope 0) when there is NA's
data$colorBuckets[is.na(data$colorBuckets)] <- 3

# Matches the values of FIPS with the color categories
colorsmatched <- data$colorBuckets

library(mapproj)
# Map colored counties according the categories
map("county", col = colors[colorsmatched], fill = TRUE, resolution = 0,
    lty = 0, projection = "polyconic")

# Add border around each county
map("county", col = "gray", fill = FALSE, add = TRUE, lty = 1, lwd = 0.2,
    projection = "polyconic")

# Add border to each state (THIS IS THE PROBLEMATIC STEP)
map("state", col = "black", fill = FALSE, add = TRUE, lty = 1, lwd = 0.4,
           projection = "polyconic")

################################################################


From smithtiffanyt at gmail.com  Fri May 22 21:54:03 2015
From: smithtiffanyt at gmail.com (Tiffany Smith)
Date: Fri, 22 May 2015 15:54:03 -0400
Subject: [R-sig-Geo] grid.text with rasterVis::layerplot
Message-ID: <41C5BAE4-1367-424C-AA2C-A10BB13A0CAA@gmail.com>

Below is a chunk of code that plots a rasterStack with 6 layers; I am trying to put labels a-f in the bottom right corner of each plot. The code below only shows the letter ?a?, how do I get different letters to show in the bottom left corner of each of the 6 plots as I use levelplot?

levelplot(positive,par.settings=myTheme,names.attr=c("","","","","",""))+layer(sp.lines(conus))+layer(sp.lines(n.am))+layer(grid.text(c("a.","b.","c.","d.","e.","f."),.95,.1))

Thanks,
Tiffany
	[[alternative HTML version deleted]]


From tim.appelhans at gmail.com  Sat May 23 00:32:19 2015
From: tim.appelhans at gmail.com (Tim Appelhans)
Date: Sat, 23 May 2015 00:32:19 +0200
Subject: [R-sig-Geo] grid.text with rasterVis::layerplot
In-Reply-To: <41C5BAE4-1367-424C-AA2C-A10BB13A0CAA@gmail.com>
References: <41C5BAE4-1367-424C-AA2C-A10BB13A0CAA@gmail.com>
Message-ID: <555FAE73.4020306@gmail.com>

Hey Tiffany,
what I usually do is to 'loop' through the layers, create one plot each 
and then combine them back together (using Rsenal::latticeCombineGrid()).
As a side-effect this means that you need to specify explicitly how the 
data range is to be color coded using 'at =' as otherwise you will end 
up with a colorkey that is only representative of the first panel (as 
per default each layer will be streched between its min and max values).

So for a reproducible piece of code (taken from the help page of 
rasterVis::levelplot) it would look something like this (it is hard to 
help without a reproducible example):

## to install Rsenal:
## library(devtools)
## instal_github("environmentalinformatics-marburg/Rsenal")
library(Rsenal)
library(rasterVis)

f <- system.file("external/test.grd", package="raster")
r <- raster(f)
s <- stack(r, r+500, r-500)

labs <- c("a.", "b.", "c.")

p_lst <- lapply(seq(nlayers(s)), function(i) {

   levelplot(s[[i]], par.settings = envinmr.theme(),
             at = seq(-500, 2200, 100), margin = FALSE,
             panel = function(...) {
               panel.levelplot(...)
               panel.text(x = 178500, y = 329500,
                          labels = labs[i], adj = c(0, 0))
             })

})

latticeCombineGrid(p_lst)

If you additionally put yout '+ layer(...)' calls inside the lapply, 
they will also be added to each panel.

Cheers,
Tim

On 22.05.2015 21:54, Tiffany Smith wrote:
> Below is a chunk of code that plots a rasterStack with 6 layers; I am trying to put labels a-f in the bottom right corner of each plot. The code below only shows the letter ?a?, how do I get different letters to show in the bottom left corner of each of the 6 plots as I use levelplot?
>
> levelplot(positive,par.settings=myTheme,names.attr=c("","","","","",""))+layer(sp.lines(conus))+layer(sp.lines(n.am))+layer(grid.text(c("a.","b.","c.","d.","e.","f."),.95,.1))
>
> Thanks,
> Tiffany
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
#####################################
Tim Appelhans
Department of Geography
Environmental Informatics
Philipps Universit?t Marburg
Deutschhausstra?e 12
35032 Marburg (Paketpost: 35037 Marburg)
Germany

Tel +49 (0) 6421 28-25957

http://environmentalinformatics-marburg.de/


From plawrencenw at gmail.com  Sat May 23 00:43:51 2015
From: plawrencenw at gmail.com (Patrick Lawrence)
Date: Fri, 22 May 2015 16:43:51 -0600
Subject: [R-sig-Geo] Combining random effects with a spatial autocorrelation
	structure in gamm
Message-ID: <CAGG7F76rgDhQqqPe6TJ2C9vNmYCrXdGMHbSgzUm=KPH5kge7Pw@mail.gmail.com>

This may be more appropriate in the SIG-mixed-models list, but given the
spatial component I thought I'd try here first.

I have an agricultural dataset that contains lattice data spread out in 4
non-contiguous fields.  Each field has the approximate dimensions of 43 x
43 cells.  My model is trying to explain yields as a function of several
continuous spatial covariates and one temporal covariate (the dataset spans
multiple years).

Given the spatiotemporal structure, I have correlation within years,
correlation within fields, and then sub-field correlations.  Ideally, I
could use a Conditional Autoregressive structure that was nested within
fields along with a year random effect, however there doesn't appear to be
an easy way to do this.  Therefore, I'm trying to use the year and field
random effects (crossed) plus a variogram-like correlation structure.
Within the gamm function (in mgcv), I can do this, although it takes ~ 46
hrs per run on a 64 gb ram machine.  This isn't ideal, but my main concern
is whether, when I have multiple random effects *and *such a correlation
structure, the output from the gamm function is reliable.

Can anyone speak to the reliability of gamm with all these added components
or possibly suggest an alternative?

Thanks,
Patrick

	[[alternative HTML version deleted]]


From comunello.eder at gmail.com  Sat May 23 13:21:20 2015
From: comunello.eder at gmail.com (=?UTF-8?Q?=C3=89der_Comunello?=)
Date: Sat, 23 May 2015 07:21:20 -0400
Subject: [R-sig-Geo] Problem plotting state borders
In-Reply-To: <CADBY2pp+ERa4cjLbjF8U8wPzp4XMXJvLZq=6v25izxXiBPPGxw@mail.gmail.com>
References: <CADBY2pp+ERa4cjLbjF8U8wPzp4XMXJvLZq=6v25izxXiBPPGxw@mail.gmail.com>
Message-ID: <CABmC8gmBwY1yGBAVSCufQN1ZxPOTzRDGf-He8qYt+q8_A3AsaQ@mail.gmail.com>

Hello, Jos? luis!

I ran your code, but I did not notice the error reported. It's working fine
for me.

sessionInfo()
R version 3.1.3 (2015-03-09)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 8 x64 (build 9200)

locale:
[1] LC_COLLATE=Portuguese_Brazil.1252  LC_CTYPE=Portuguese_Brazil.1252
 LC_MONETARY=Portuguese_Brazil.1252
[4] LC_NUMERIC=C                       LC_TIME=Portuguese_Brazil.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] mapproj_1.2-2 maps_2.3-9

loaded via a namespace (and not attached):
[1] tools_3.1.3

?
================================================
?der Comunello
PhD Student in Agricultural Systems Engineering (USP/Esalq)
Brazilian Agricultural Research Corporation (Embrapa)
Dourados, MS, Brazil [22 16.5'S, 54 49.0'W]



?

2015-05-22 12:16 GMT-04:00 Jos? Luis Rotundo <rotundo.jose at gmail.com>:

> Dear List,
>
> I want to plot a US county level map with counties colored according a
> categorical variable. I was successful for the most part, but when
> trying to add state level borders, to make the map look better, the
> borders do not follow the geographical limits.
>
> Here is the link to the map I ended up with: http://imgur.com/UqcpVBW
>
> If you want to reproduce the what I am doing, the data is here:
> http://www.filedropper.com/data_4
>
> Below is the code I am using.
>
> Thanks a lot in advance for any help to solve this problem.
>
> Jos? L. Rotundo
> CONICET
> Facultad de Ciencias Agrarias
> Univ. Nacional de Rosario
> Zavalla, Santa Fe
> Argentina
>
> #############################################################
> # Pick the colors for the categorical values
> colors = c("#CC0000", "#FF9999", "#E0E0E0", "#99FF99", "#00CC00")
>
> #Creates a new variable with the categories.
> data$colorBuckets <- as.numeric(cut(data$Slope, c(-0.30, -0.20, -0.10,
> 0.10,
>                                                     0.20, 0.30)))
>
> # Put a 3 (equivalent to slope 0) when there is NA's
> data$colorBuckets[is.na(data$colorBuckets)] <- 3
>
> # Matches the values of FIPS with the color categories
> colorsmatched <- data$colorBuckets
>
> library(mapproj)
> # Map colored counties according the categories
> map("county", col = colors[colorsmatched], fill = TRUE, resolution = 0,
>     lty = 0, projection = "polyconic")
>
> # Add border around each county
> map("county", col = "gray", fill = FALSE, add = TRUE, lty = 1, lwd = 0.2,
>     projection = "polyconic")
>
> # Add border to each state (THIS IS THE PROBLEMATIC STEP)
> map("state", col = "black", fill = FALSE, add = TRUE, lty = 1, lwd = 0.4,
>            projection = "polyconic")
>
> ################################################################
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150523/6c008e0a/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: rotundo2.png
Type: image/png
Size: 30065 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150523/6c008e0a/attachment.png>

From comunello.eder at gmail.com  Sat May 23 15:17:16 2015
From: comunello.eder at gmail.com (=?UTF-8?Q?=C3=89der_Comunello?=)
Date: Sat, 23 May 2015 09:17:16 -0400
Subject: [R-sig-Geo] Problem plotting state borders
In-Reply-To: <CADBY2pp9HHWdvVAiK5i1hVzsRVtg74qAx4SytBdQB5-6g97bdw@mail.gmail.com>
References: <CADBY2pp+ERa4cjLbjF8U8wPzp4XMXJvLZq=6v25izxXiBPPGxw@mail.gmail.com>
	<CABmC8gmBwY1yGBAVSCufQN1ZxPOTzRDGf-He8qYt+q8_A3AsaQ@mail.gmail.com>
	<CADBY2pp9HHWdvVAiK5i1hVzsRVtg74qAx4SytBdQB5-6g97bdw@mail.gmail.com>
Message-ID: <CABmC8g=u=5uZzQzPNR0SSkg3fqcFJCxabjHKkJz8Z8ttrEJz5A@mail.gmail.com>

Hi, Jos? Luis!

Probably not! I tested (R console vs. R Studio) and got the same result.
Did you try update the packages? Could you paste your sessionInfo()
information in the next email?

?
================================================
?der Comunello
PhD Student in Agricultural Systems Engineering (USP/Esalq)
Brazilian Agricultural Research Corporation (Embrapa)
Dourados, MS, Brazil [22 16.5'S, 54 49.0'W]




2015-05-23 7:39 GMT-04:00 Jos? Luis Rotundo <rotundo.jose at gmail.com>:

> Hi ?der,
> Thanks a lot for your response. I cannot understand why this is happening.
> Using that exactly same code I end up with the map with straight-lined
> borders.
>
> It may have to do with me using R Studio instead of R??
>
> Thanks again,
> Jos?
> El may 23, 2015 12:21 PM, "?der Comunello" <comunello.eder at gmail.com>
> escribi?:
>
>> Hello, Jos? luis!
>>
>> I ran your code, but I did not notice the error reported. It's working
>> fine for me.
>>
>> sessionInfo()
>> R version 3.1.3 (2015-03-09)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 8 x64 (build 9200)
>>
>> locale:
>> [1] LC_COLLATE=Portuguese_Brazil.1252  LC_CTYPE=Portuguese_Brazil.1252
>>  LC_MONETARY=Portuguese_Brazil.1252
>> [4] LC_NUMERIC=C                       LC_TIME=Portuguese_Brazil.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] mapproj_1.2-2 maps_2.3-9
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.1.3
>>
>> ?
>> ================================================
>> ?der Comunello
>> PhD Student in Agricultural Systems Engineering (USP/Esalq)
>> Brazilian Agricultural Research Corporation (Embrapa)
>> Dourados, MS, Brazil [22 16.5'S, 54 49.0'W]
>>
>>
>> 2015-05-22 12:16 GMT-04:00 Jos? Luis Rotundo <rotundo.jose at gmail.com>:
>>
>>> Dear List,
>>>
>>> I want to plot a US county level map with counties colored according a
>>> categorical variable. I was successful for the most part, but when
>>> trying to add state level borders, to make the map look better, the
>>> borders do not follow the geographical limits.
>>>
>>> Here is the link to the map I ended up with: http://imgur.com/UqcpVBW
>>>
>>> If you want to reproduce the what I am doing, the data is here:
>>> http://www.filedropper.com/data_4
>>>
>>> Below is the code I am using.
>>>
>>> Thanks a lot in advance for any help to solve this problem.
>>>
>>> Jos? L. Rotundo
>>> CONICET
>>> Facultad de Ciencias Agrarias
>>> Univ. Nacional de Rosario
>>> Zavalla, Santa Fe
>>> Argentina
>>>
>>> #############################################################
>>> # Pick the colors for the categorical values
>>> colors = c("#CC0000", "#FF9999", "#E0E0E0", "#99FF99", "#00CC00")
>>>
>>> #Creates a new variable with the categories.
>>> data$colorBuckets <- as.numeric(cut(data$Slope, c(-0.30, -0.20, -0.10,
>>> 0.10,
>>>                                                     0.20, 0.30)))
>>>
>>> # Put a 3 (equivalent to slope 0) when there is NA's
>>> data$colorBuckets[is.na(data$colorBuckets)] <- 3
>>>
>>> # Matches the values of FIPS with the color categories
>>> colorsmatched <- data$colorBuckets
>>>
>>> library(mapproj)
>>> # Map colored counties according the categories
>>> map("county", col = colors[colorsmatched], fill = TRUE, resolution = 0,
>>>     lty = 0, projection = "polyconic")
>>>
>>> # Add border around each county
>>> map("county", col = "gray", fill = FALSE, add = TRUE, lty = 1, lwd = 0.2,
>>>     projection = "polyconic")
>>>
>>> # Add border to each state (THIS IS THE PROBLEMATIC STEP)
>>> map("state", col = "black", fill = FALSE, add = TRUE, lty = 1, lwd = 0.4,
>>>            projection = "polyconic")
>>>
>>> ################################################################
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>

	[[alternative HTML version deleted]]


From comunello.eder at gmail.com  Sat May 23 16:26:48 2015
From: comunello.eder at gmail.com (=?UTF-8?Q?=C3=89der_Comunello?=)
Date: Sat, 23 May 2015 10:26:48 -0400
Subject: [R-sig-Geo] Problem plotting state borders
In-Reply-To: <CABmC8g=u=5uZzQzPNR0SSkg3fqcFJCxabjHKkJz8Z8ttrEJz5A@mail.gmail.com>
References: <CADBY2pp+ERa4cjLbjF8U8wPzp4XMXJvLZq=6v25izxXiBPPGxw@mail.gmail.com>
	<CABmC8gmBwY1yGBAVSCufQN1ZxPOTzRDGf-He8qYt+q8_A3AsaQ@mail.gmail.com>
	<CADBY2pp9HHWdvVAiK5i1hVzsRVtg74qAx4SytBdQB5-6g97bdw@mail.gmail.com>
	<CABmC8g=u=5uZzQzPNR0SSkg3fqcFJCxabjHKkJz8Z8ttrEJz5A@mail.gmail.com>
Message-ID: <CABmC8gmSBDX6wSH3FUV76FLOBCfNw6H49uN8uo28R03RXFf+Hw@mail.gmail.com>

Jos? Luis, hi again!

??In addition, you may find this article interesting:

"Choosing the right map projection"
https://source.opennews.org/en-US/learning/choosing-right-map-projection/



?
================================================
?der Comunello
PhD Student in Agricultural Systems Engineering (USP/Esalq)
Brazilian Agricultural Research Corporation (Embrapa)
Dourados, MS, Brazil [22 16.5'S, 54 49.0'W]

	[[alternative HTML version deleted]]


From comunello.eder at gmail.com  Sat May 23 16:55:47 2015
From: comunello.eder at gmail.com (=?UTF-8?Q?=C3=89der_Comunello?=)
Date: Sat, 23 May 2015 10:55:47 -0400
Subject: [R-sig-Geo] Converting large RasterStack to CSVs fast
In-Reply-To: <1598157920.372596.1432295489967.JavaMail.yahoo@mail.yahoo.com>
References: <mailman.9.1431770403.17365.r-sig-geo@r-project.org>
	<1598157920.372596.1432295489967.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CABmC8gnxZyy5yGFMPqHSXzca4VgdFb8NP9m+WQMozxsSyyJo1g@mail.gmail.com>

Hi, Mohammad!

I'm sorry, I expected a better result! I tried an alternative, but I got a
worst result! I added it at the end of the previous script.

I'll try to think of something better, if I succeed I?ll post here.

### <code r>
require(rgdal); require(raster)

getwd()
### download some data to test
getData("worldclim", var = "tmin", res = 10) ### tmin
fn <- dir("wc10", patt=".bil$", full=T)
fn <- fn[order(nchar(fn), fn)]; fn
#  [1] "wc10/tmin1.bil"  "wc10/tmin2.bil"  "wc10/tmin3.bil"  ...

### read images
s <- stack(fn) ### dimensions  : 900, 2160, 1944000, 12  (nrow, ncol,
ncell, nlayers)
fromDisk(s)

### extents of subsets
bor <- extent(s); bor
res <- 45 ### subsets resolution
X   <- unique(c(seq(bor at xmin, bor at xmax, by=res), bor at xmax)); X
Y   <- unique(c(seq(bor at ymin, bor at ymax, by=res), bor at ymax)); Y
ext <- cbind(expand.grid(Xmin=X[-length(X)], Ymin=Y[-length(Y)]),
             expand.grid(Xmax=X[-1], Ymax=Y[-1]))[,c(1,3,2,4)]
head(ext); nrow(ext)

plot(s, 1)
system.time(
sapply(1:nrow(ext), function(i) {
     mask <- ext[i,]
     subset <- with(mask, extent(c(Xmin, Xmax, Ymin, Ymax)))
     plot(subset, add=T)
     text(rowMeans(mask[,1:2]), rowMeans(mask[,3:4]), lab=i)
     c <- crop(s, subset)
     write.table(as.data.frame(rasterToPoints(c)), paste0("p",i,".txt"), )
}))
#    user  system elapsed
#   80.94    2.60   86.11

txt <- dir(patt="^p[0-9]+.txt$")
txt <- txt[order(nchar(txt), txt)]; txt
#  [1] "p1.txt"  "p2.txt"  "p3.txt"  "p4.txt"  ...

##########################################################
### Added code ############################################
###########################################################
plot(s, 1)
system.time(
sapply(1:nrow(ext), function(i) {
     mask <- ext[i,]
     subset <- with(mask, extent(c(Xmin, Xmax, Ymin, Ymax)))
     plot(subset, add=T)
     text(rowMeans(mask[,1:2]), rowMeans(mask[,3:4]), lab=i)
     cells <- cellsFromExtent(s, subset)
     c <- data.frame(xyFromCell(s, cells), extract(s, cells))
     write.table(c, paste0("pp",i,".txt"))
})
)
#    user  system elapsed
#  318.86   16.63  338.15

### </code>


?
================================================
?der Comunello
PhD Student in Agricultural Systems Engineering (USP/Esalq)
Brazilian Agricultural Research Corporation (Embrapa)
Dourados, MS, Brazil [22 16.5'S, 54 49.0'W]




2015-05-22 7:51 GMT-04:00 Mohammad Abdel-Razek <kimofos at yahoo.com>:

> Hello Comunello!
>
> Thanks for the reply. Your vectorized code is faster than the one I have,
> by a margin of 5%, which is an improvement. I think the limiting step is
> clipping. Is there any paralleled  version of clip?
>
> Mohammad
>
>

	[[alternative HTML version deleted]]


From rotundo.jose at gmail.com  Sat May 23 17:15:37 2015
From: rotundo.jose at gmail.com (=?UTF-8?Q?Jos=C3=A9_Luis_Rotundo?=)
Date: Sat, 23 May 2015 12:15:37 -0300
Subject: [R-sig-Geo] Problem plotting state borders
In-Reply-To: <CABmC8g=u=5uZzQzPNR0SSkg3fqcFJCxabjHKkJz8Z8ttrEJz5A@mail.gmail.com>
References: <CADBY2pp+ERa4cjLbjF8U8wPzp4XMXJvLZq=6v25izxXiBPPGxw@mail.gmail.com>
	<CABmC8gmBwY1yGBAVSCufQN1ZxPOTzRDGf-He8qYt+q8_A3AsaQ@mail.gmail.com>
	<CADBY2pp9HHWdvVAiK5i1hVzsRVtg74qAx4SytBdQB5-6g97bdw@mail.gmail.com>
	<CABmC8g=u=5uZzQzPNR0SSkg3fqcFJCxabjHKkJz8Z8ttrEJz5A@mail.gmail.com>
Message-ID: <CADBY2ponGDghKiN3QXLET9PxiKrFMLxn3vByNPdHOV9CdBQKEw@mail.gmail.com>

Hi Eder,

Thanks again for your effort. I ran again the script and got the same
straight lines as borders.

Here is my session info as you requested. I am new to R and GIS so do
not know how to interpret it.

R version 3.2.0 (2015-04-16)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 8 x64 (build 9200)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] maptools_0.8-36  sp_1.1-0         mapproj_1.2-2    ggmap_2.4
[5] ggplot2_1.0.1    maps_2.3-9       data.table_1.9.4

loaded via a namespace (and not attached):
 [1] Rcpp_0.11.6         magrittr_1.5        MASS_7.3-40
munsell_0.4.2
 [5] colorspace_1.2-6    geosphere_1.3-13    lattice_0.20-31
rjson_0.2.15
 [9] jpeg_0.1-8          stringr_1.0.0       plyr_1.8.2
tools_3.2.0
[13] grid_3.2.0          gtable_0.1.2        png_0.1-7
digest_0.6.8
[17] RJSONIO_1.3-0       reshape2_1.4.1      stringi_0.4-1
RgoogleMaps_1.2.0.7
[21] scales_0.2.4        foreign_0.8-63      chron_2.3-45        proto_0.3-10


Cheers,

Jose.

PS. Thanks for the link on projections!





2015-05-23 10:17 GMT-03:00 ?der Comunello <comunello.eder at gmail.com>:
> Hi, Jos? Luis!
>
> Probably not! I tested (R console vs. R Studio) and got the same result. Did
> you try update the packages? Could you paste your sessionInfo() information
> in the next email?
>
> ================================================
> ?der Comunello
> PhD Student in Agricultural Systems Engineering (USP/Esalq)
> Brazilian Agricultural Research Corporation (Embrapa)
> Dourados, MS, Brazil [22 16.5'S, 54 49.0'W]
>
>
>
>
> 2015-05-23 7:39 GMT-04:00 Jos? Luis Rotundo <rotundo.jose at gmail.com>:
>>
>> Hi ?der,
>> Thanks a lot for your response. I cannot understand why this is happening.
>> Using that exactly same code I end up with the map with straight-lined
>> borders.
>>
>> It may have to do with me using R Studio instead of R??
>>
>> Thanks again,
>> Jos?
>>
>> El may 23, 2015 12:21 PM, "?der Comunello" <comunello.eder at gmail.com>
>> escribi?:
>>>
>>> Hello, Jos? luis!
>>>
>>> I ran your code, but I did not notice the error reported. It's working
>>> fine for me.
>>>
>>> sessionInfo()
>>> R version 3.1.3 (2015-03-09)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> Running under: Windows 8 x64 (build 9200)
>>>
>>> locale:
>>> [1] LC_COLLATE=Portuguese_Brazil.1252  LC_CTYPE=Portuguese_Brazil.1252
>>> LC_MONETARY=Portuguese_Brazil.1252
>>> [4] LC_NUMERIC=C                       LC_TIME=Portuguese_Brazil.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] mapproj_1.2-2 maps_2.3-9
>>>
>>> loaded via a namespace (and not attached):
>>> [1] tools_3.1.3
>>>
>>> ================================================
>>> ?der Comunello
>>> PhD Student in Agricultural Systems Engineering (USP/Esalq)
>>> Brazilian Agricultural Research Corporation (Embrapa)
>>> Dourados, MS, Brazil [22 16.5'S, 54 49.0'W]
>>>
>>>
>>> 2015-05-22 12:16 GMT-04:00 Jos? Luis Rotundo <rotundo.jose at gmail.com>:
>>>>
>>>> Dear List,
>>>>
>>>> I want to plot a US county level map with counties colored according a
>>>> categorical variable. I was successful for the most part, but when
>>>> trying to add state level borders, to make the map look better, the
>>>> borders do not follow the geographical limits.
>>>>
>>>> Here is the link to the map I ended up with: http://imgur.com/UqcpVBW
>>>>
>>>> If you want to reproduce the what I am doing, the data is here:
>>>> http://www.filedropper.com/data_4
>>>>
>>>> Below is the code I am using.
>>>>
>>>> Thanks a lot in advance for any help to solve this problem.
>>>>
>>>> Jos? L. Rotundo
>>>> CONICET
>>>> Facultad de Ciencias Agrarias
>>>> Univ. Nacional de Rosario
>>>> Zavalla, Santa Fe
>>>> Argentina
>>>>
>>>> #############################################################
>>>> # Pick the colors for the categorical values
>>>> colors = c("#CC0000", "#FF9999", "#E0E0E0", "#99FF99", "#00CC00")
>>>>
>>>> #Creates a new variable with the categories.
>>>> data$colorBuckets <- as.numeric(cut(data$Slope, c(-0.30, -0.20, -0.10,
>>>> 0.10,
>>>>                                                     0.20, 0.30)))
>>>>
>>>> # Put a 3 (equivalent to slope 0) when there is NA's
>>>> data$colorBuckets[is.na(data$colorBuckets)] <- 3
>>>>
>>>> # Matches the values of FIPS with the color categories
>>>> colorsmatched <- data$colorBuckets
>>>>
>>>> library(mapproj)
>>>> # Map colored counties according the categories
>>>> map("county", col = colors[colorsmatched], fill = TRUE, resolution = 0,
>>>>     lty = 0, projection = "polyconic")
>>>>
>>>> # Add border around each county
>>>> map("county", col = "gray", fill = FALSE, add = TRUE, lty = 1, lwd =
>>>> 0.2,
>>>>     projection = "polyconic")
>>>>
>>>> # Add border to each state (THIS IS THE PROBLEMATIC STEP)
>>>> map("state", col = "black", fill = FALSE, add = TRUE, lty = 1, lwd =
>>>> 0.4,
>>>>            projection = "polyconic")
>>>>
>>>> ################################################################
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>



-- 

Jos? L. Rotundo
CONICET
Facultad de Ciencias Agrarias
Univ. Nacional de Rosario
Zavalla, Santa Fe
Argentina


From oscar.perpinan at gmail.com  Sat May 23 17:28:40 2015
From: oscar.perpinan at gmail.com (=?UTF-8?Q?Oscar_Perpi=C3=B1an?=)
Date: Sat, 23 May 2015 17:28:40 +0200
Subject: [R-sig-Geo] grid.text with rasterVis::layerplot
In-Reply-To: <555FAE73.4020306@gmail.com>
References: <41C5BAE4-1367-424C-AA2C-A10BB13A0CAA@gmail.com>
	<555FAE73.4020306@gmail.com>
Message-ID: <CAMLL7bkJ4-kfF+bNHDVqSNg19066Qktcd+VoE46SK6h+d8YjDQ@mail.gmail.com>

Hi,

It is easier with the panel.number function. Following the example proposed
by Tim:

library(rasterVis)

f <- system.file("external/test.grd", package="raster")
r <- raster(f)
s <- stack(r, r+500, r-500)

labs <- c("a.", "b.", "c.")

levelplot(s) + layer(grid.text(labs[panel.number()], .95, .1))

Best,

Oscar.

-----------------------------------------------------------------
Oscar Perpi??n Lamigueiro
Dpto. Ing. El?ctrica, Electr?nica, Autom?tica y F?sica Aplicada (ETSIDI-UPM)
Grupo de Sistemas Fotovoltaicos (IES-UPM)
URL: http://oscarperpinan.github.io

	[[alternative HTML version deleted]]


From mark.vankleunen at uni-konstanz.de  Sun May 24 10:35:10 2015
From: mark.vankleunen at uni-konstanz.de (Mark van Kleunen)
Date: Sun, 24 May 2015 10:35:10 +0200
Subject: [R-sig-Geo] gbif error message in package dismo
In-Reply-To: <CABmC8g=xM3axo=M5Bz4DDV=M7r+0y2cUZZGRJDbAmtVB9EpqFQ@mail.gmail.com>
References: <CABmC8g=xM3axo=M5Bz4DDV=M7r+0y2cUZZGRJDbAmtVB9EpqFQ@mail.gmail.com>
Message-ID: <55618D3E.2090507@uni-konstanz.de>

Hello Eder,

Indeed, the update of the jsonlite package did the trick; now I can 
download all gbif occurrences. Thanks a lot for your help!

best wishes,
Mark

On 21/05/2015 13:52, ?der Comunello wrote:
> Hello, Mark!
>
> Could you update your packages and rerun the test? My guess is an 
> issue with {jsonlite} version when it tries binds the searches 
> (nrecs=300)...
>
> update.packages(ask=T)
>
> ?
> ================================================
> ?der Comunello
> PhD Student in Agricultural Systems Engineering (USP/Esalq)
> Brazilian Agricultural Research Corporation (Embrapa)
> Dourados, MS, Brazil [22 16.5'S, 54 49.0'W]
>
>
> 2015-05-21 2:48 GMT-04:00 Mark van Kleunen 
> <mark.vankleunen at uni-konstanz.de 
> <mailto:mark.vankleunen at uni-konstanz.de>>:
>
>     Dear Eder,
>
>     The output of sessionInfo() is:
>
>     > sessionInfo()
>     R version 3.1.3 (2015-03-09)
>     Platform: x86_64-w64-mingw32/x64 (64-bit)
>     Running under: Windows 7 x64 (build 7601) Service Pack 1
>
>     locale:
>     [1] LC_COLLATE=English_United Kingdom.1252 LC_CTYPE=English_United
>     Kingdom.1252
>     [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
>     [5] LC_TIME=English_United Kingdom.1252
>
>     attached base packages:
>     [1] stats     graphics  grDevices utils     datasets methods   base
>
>     other attached packages:
>      [1] rworldmap_1.3-1  mapproj_1.2-2 maps_2.3-9      
>     geosphere_1.3-11 rgdal_0.9-1 rgbif_0.8.0
>      [7] shapefiles_0.7   foreign_0.8-61   XML_3.98-1.1
>     dismo_1.0-12     rgeos_0.3-6      raster_2.3-0
>     [13] maptools_0.8-30  sp_1.0-15
>
>     loaded via a namespace (and not attached):
>      [1] chron_2.3-45     colorspace_1.2-4 data.table_1.9.4
>     digest_0.6.4     fields_7.1 ggplot2_1.0.0
>      [7] grid_3.1.3       gtable_0.1.2     httr_0.5 jsonlite_0.9.12 
>     lattice_0.20-29  magrittr_1.5
>     [13] MASS_7.3-35      munsell_0.4.2    plyr_1.8.1 proto_0.3-10    
>     Rcpp_0.11.3      reshape2_1.4
>     [19] scales_0.2.4     spam_1.0-1       stringr_0.6.2
>     tools_3.1.3      whisker_0.3-2
>     >
>
>     Interestingly, when I use "end=30)", then the error message does
>     not appear.
>     So,
>     gb   <- gbif('Batrachoseps', 'luciae', start=1, end=30)
>     > traceback()
>     No traceback available
>
>     When I set end=1000, then I get again the error message:
>     > gb   <- gbif('Batrachoseps', 'luciae', start=1, end=1000)
>     0-300-600-900-1000 records
>     Error in (function (classes, fdef, mtable)  :
>       unable to find an inherited method for function ?bind? for
>     signature ?"data.frame", "data.frame"?
>
>     Does this information provide any insight into what the problem
>     might be?
>
>     best,
>     Mark
>
>

-- 
Prof. Dr Mark van Kleunen
Ecology, Department of Biology
University of Konstanz
Universit?tsstrasse 10
D 78457 Konstanz
Germany

Office M803
Tel.: +49 (0)7531 88 2997 (direct)
       +49 (0)7531 88 2105 (secretary)
Fax:  +49 (0)7531 88 3430

E-mail: mark.vankleunen at uni-konstanz.de
http://cms.uni-konstanz.de/vkleunen/


	[[alternative HTML version deleted]]


From rob.andronaco at lifesavingvictoria.com.au  Sun May 24 14:00:22 2015
From: rob.andronaco at lifesavingvictoria.com.au (Robert)
Date: Sun, 24 May 2015 05:00:22 -0700 (MST)
Subject: [R-sig-Geo] Regional count data age standardisation
Message-ID: <1432468822254-7588318.post@n2.nabble.com>

Hi there,

I've been looking for an R script/ tutorial that will enable me to iterate
through a number of areas with the different age populations and case count
data in order to derive a single summary to compare area rates.

I would be very grateful if someone could please point me to some resources
and examples.

Regards

Rob 





--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Regional-count-data-age-standardisation-tp7588318.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From edzer.pebesma at uni-muenster.de  Sun May 24 14:32:16 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 24 May 2015 14:32:16 +0200
Subject: [R-sig-Geo] poly %over% poly in rgeos; memory tips
In-Reply-To: <555F503E.3040508@uni-muenster.de>
References: <CAF97oXvZu9MRSVNJcZj3b9NJ+7ETyA0+6tWqopi+PGKMK5j1vQ@mail.gmail.com>
	<555F503E.3040508@uni-muenster.de>
Message-ID: <5561C4D0.70601@uni-muenster.de>

In
http://stackoverflow.com/questions/30409001/how-does-spatial-polygon-over-polygon-work-to-when-aggregating-values-in-r

OP follows this up with a reproducible example.

It seems to be a bug in rgeos::over that was fixed a month ago, but is
still in the CRAN version.

On 05/22/2015 05:50 PM, Edzer Pebesma wrote:
> Mike, you may want to read two recent threads:
> 
> https://stat.ethz.ch/pipermail/r-sig-geo/2015-April/022624.html
> https://stat.ethz.ch/pipermail/r-sig-geo/2015-April/022663.html
> 
> When you try to aggregate, instead of using over(), have you used
> sp::aggregate directly, for instance with option areaWeighted = TRUE?
> 
> If memory is a bottle neck, I'd suggest to either buy more of it, or
> choose a workflow that needs less of it, like PostGIS with SQL.
> 
> On 05/22/2015 04:41 PM, Mike wrote:
>> Hi all, big fan of the listserv, learning a lot.
>>
>> I've a few hopefully questions about the sp and rgeos packages.
>>
>> #1 I've had success using %over% in the sp packages, but can't seem to find
>> the help for poly-poly (spatial poly data frame or spatial poly over the
>> same), implemented in rgeos.  Where is that explained?  I can't seem to get
>> it to return an aggregation in the way poly over points does, where I can
>> use fun=sum to aggregate a number of data frame columns at once.  I've read
>> a number of 3rd party explanations and poked in a few books, but haven't
>> found much on poly poly data aggregation with over.
>>
>> #2 for large geometries, any suggestions of way to be more efficient in
>> general in spatial work?  I love the gRelate function (see below), but for
>> attempting to aggregate ~2000 3mile buffers over ~200,000 NC census blocks,
>> gRelate seems to fail more often than not.  (I really only need OVER in
>> this case, but have tried work arounds since, in #1, I can't get over to
>> work poly-poly the way I need).
>>
>> Thanks!  More detail and specific case below.
>>
>> Best,
>> Mike
>> UNC Epidemiology
>>
>> ====
>>
>> Context:
>>
>> I'm working on porting an environmental epidemiology project done in Arc
>> and STATA to all R.  Relevant context - we have point exposures (in this
>> case, industrial hog operations) with 3 mile buffers to represent their
>> exposure radius (red dots and pink buffers in the map, from gBuffer after
>> spTransform).  Exclusion criteria (blue shapes) are (1) counties that only
>> border IHOs-less counties (grey) and the five most populous cities (where
>> IHOs are never cited) - that's done through the fantastic gRelate function
>> (see below for code).
>>
>> IHOblob = gUnionCascaded(hasIHOcounties)
>> #plot(IHOblob) #can plot this to check it out.
>> touch.v = gRelate(noIHOcounties, IHOblob, byid = T)
>> str(touch.v)
>> counties.not.touching<-(touch.v %in% c("FF2FF1212")) #DE-91M is super cool.
>> notouchIHOcounties = noIHOcounties[counties.not.touching,]
>> plot(notouchIHOcounties, co="light blue", lwd=0.6, add=T)
>>
>> See image for a quick visual of what's going on:
>> http://i.imgur.com/4m6CgW8.png
>>
>> The analysis, however, is happening at the census block level.  Here's
>> where I have two challenges I'm hoping to get some help with.
>>
>> #1 poly over poly dataframe aggregation:  I understand that the %over%
>> function for poly-poly is implemented in rgeos instead of sp (see table
>> below).  Sp's over help clarifies how arguments need to be aligned or
>> stripped of data frames to get what you want.  So, for instance, as a test
>> case, here's successful code to aggregate the *point* data on IHOs to their
>> respective counties (if there's a better way to do this, Please let me
>> know):
>> NC.counties.shp at data = data.frame(c(NC.counties.shp at data,
>> over(NC.counties.shp, IHOs.spdf, fun=sum)))
>>
>> Over implementations: http://i.imgur.com/X8Im2gI.png
>>
>> However, the goal for the census blocks is to aggregate various
>> quantitative variables from IHOs within 3 miles (hence the buffer) of any
>> point on the edge.  I can imagine some brute force looping methods using
>> the gRelate function, or distance, but can't seem to nail it in one pass
>> with over the way I might with QGIS or Arc.  In the below case,
>> IHOs.3mibuff.spdf is now a spatial poly data frame, as are the study
>> blocks.  When I try passing the first argument (counties or blocks) as just
>> a geometry, I still get a matrix of named rows and some single aggregated
>> number - but not all the aggregated columns in the data frame.
>> test <-over(NC.studyblocks.shp at polygons, IHOs.3mibuff.spdf, fun=sum) ??
>> test <-over(NC.studyblocks.shp, IHOs.3mibuff.spdf, fun=sum) ??
>>
>> #2 Issues with memory.  I've read a few tip sets on generic size best
>> practices that aren't spatial specific, but if anyone has any tips, I'd
>> love to hear them.  I seem to have had some success with gc() after large
>> subsetting.  In (probably miscoding) the analysis of gRelate of 200,000
>> blocks and 2,000 buffer circles, I eat up 6gigs with ease.
>>
>> Best wishes, again,
>> mike
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> 
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150524/159a2da9/attachment.bin>

From jrkrideau at inbox.com  Sun May 24 14:39:52 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 24 May 2015 04:39:52 -0800
Subject: [R-sig-Geo] Regional count data age standardisation
In-Reply-To: <1432468822254-7588318.post@n2.nabble.com>
Message-ID: <3F2CF557CB7.00000136jrkrideau@inbox.com>

This sounds fairly easy (?sum, ?summary? etc) , perhaps too easy.

I think we need some idea of the format of your data and what actual summary stats you need. 

We also, need some idea of what the substantive question is, and perhaps tins such as whether or not a region needs to be weighted and so on.

Please have a look at these links for some suggestions on how to frame a question for the R-Help list. In particular read about dput(). http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html


This is the most acceptable way to supply example data to the list.  If your data set is too large to post, a representative sample is fine.



John Kane
Kingston ON Canada


> -----Original Message-----
> From: rob.andronaco at lifesavingvictoria.com.au
> Sent: Sun, 24 May 2015 05:00:22 -0700 (MST)
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] Regional count data age standardisation
> 
> Hi there,
> 
> I've been looking for an R script/ tutorial that will enable me to
> iterate
> through a number of areas with the different age populations and case
> count
> data in order to derive a single summary to compare area rates.
> 
> I would be very grateful if someone could please point me to some
> resources
> and examples.
> 
> Regards
> 
> Rob
> 
> 
> 
> 
> 
> --
> View this message in context:
> http://r-sig-geo.2731867.n2.nabble.com/Regional-count-data-age-standardisation-tp7588318.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From sadaouimahrez at outlook.com  Sun May 24 22:37:03 2015
From: sadaouimahrez at outlook.com (sadaoui)
Date: Sun, 24 May 2015 13:37:03 -0700 (MST)
Subject: [R-sig-Geo] What is the metric projection equivalent to WGS 84
Message-ID: <1432499823645-7588321.post@n2.nabble.com>

Hello, 


what is the good  projection to be used, in order to calculate the area
(square meters ) of my polygons that are found in different places of the
world map.

best regards



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/What-is-the-metric-projection-equivalent-to-WGS-84-tp7588321.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From tkeitt at utexas.edu  Mon May 25 00:10:47 2015
From: tkeitt at utexas.edu (Tim Keitt)
Date: Sun, 24 May 2015 17:10:47 -0500
Subject: [R-sig-Geo] What is the metric projection equivalent to WGS 84
In-Reply-To: <1432499823645-7588321.post@n2.nabble.com>
References: <1432499823645-7588321.post@n2.nabble.com>
Message-ID: <CANnL8gpiJLun3y_Sg5BmUayFrhD+Vr_7AJW-bHJYpm7qRgJrTw@mail.gmail.com>

I would suggest UTM if your polygons are not large.

THK

http://www.keittlab.org/

On Sun, May 24, 2015 at 3:37 PM, sadaoui <sadaouimahrez at outlook.com> wrote:

> Hello,
>
>
> what is the good  projection to be used, in order to calculate the area
> (square meters ) of my polygons that are found in different places of the
> world map.
>
> best regards
>
>
>
> --
> View this message in context:
> http://r-sig-geo.2731867.n2.nabble.com/What-is-the-metric-projection-equivalent-to-WGS-84-tp7588321.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Mon May 25 01:35:41 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Sun, 24 May 2015 23:35:41 +0000
Subject: [R-sig-Geo] What is the metric projection equivalent to WGS 84
In-Reply-To: <1432499823645-7588321.post@n2.nabble.com>
References: <1432499823645-7588321.post@n2.nabble.com>
Message-ID: <CAAcGz990dgH7hx4ZzSUzR-=0TV1bT54ni0hHqZ_iCsdjdKrkmg@mail.gmail.com>

On Mon, 25 May 2015 at 06:37 sadaoui <sadaouimahrez at outlook.com> wrote:

> Hello,
>
>
> what is the good  projection to be used, in order to calculate the area
> (square meters ) of my polygons that are found in different places of the
> world map.
>

You can always use Lambert Azimuthal Equal Area (LAEA) for any region - but
it's best if it's a generally localized area (i.e. no larger than a
hemisphere) since it's likely the approximations applied to representing
the polygons won't be robust near the edges (vertices too far apart stray
from great circles).

This applies generally though, if you have rectangular cells defined in
longlat not many projections will stay sane unless you have sufficient
intermediate vertices between the corners.

Safest is to reproject every polygon to its local centre, and use that LAEA
(+proj=laea +lon_0=centerlon +lat_0=centerlat +ellps=WGS84 for example) for
individual calculations on each polygon. But it depends on what your data
are and how they are represented and distributed in space. Given the
limitations baked into polygon representations it's not possible to give an
answer that will always work.

There are global projections that are equal area - Sinusoidal and Albers
Equal Area Conic, but still you can get bitten by topology so checking the
visually what's happening is important.

These guides might be helpful:

http://egsc.usgs.gov/isb//pubs/MapProjections/projections.html

http://www.georeference.org/doc/guide_to_selecting_map_projections.htm

Cheers, Mike.


> best regards
>
>
>
> --
> View this message in context:
> http://r-sig-geo.2731867.n2.nabble.com/What-is-the-metric-projection-equivalent-to-WGS-84-tp7588321.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From jerome.mathieu at upmc.fr  Mon May 25 12:53:39 2015
From: jerome.mathieu at upmc.fr (=?ISO-8859-1?Q?J=E9rome_Mathieu?=)
Date: Mon, 25 May 2015 12:53:39 +0200
Subject: [R-sig-Geo] What is the metric projection equivalent to WGS 84
In-Reply-To: <CAAcGz990dgH7hx4ZzSUzR-=0TV1bT54ni0hHqZ_iCsdjdKrkmg@mail.gmail.com>
References: <1432499823645-7588321.post@n2.nabble.com>
	<CAAcGz990dgH7hx4ZzSUzR-=0TV1bT54ni0hHqZ_iCsdjdKrkmg@mail.gmail.com>
Message-ID: <CALEhSiTFL_EQBWM3KczxZwv3x=PQ6N-2yDp15MNhenUwBzYL=Q@mail.gmail.com>

I think you can also use the function

areaPolygon in the R package geosphere,

which doesn't require projected data to calculate the area of polygons (as
far as I understand).

Jerome

2015-05-25 1:35 GMT+02:00 Michael Sumner <mdsumner at gmail.com>:

> On Mon, 25 May 2015 at 06:37 sadaoui <sadaouimahrez at outlook.com> wrote:
>
> > Hello,
> >
> >
> > what is the good  projection to be used, in order to calculate the area
> > (square meters ) of my polygons that are found in different places of the
> > world map.
> >
>
> You can always use Lambert Azimuthal Equal Area (LAEA) for any region - but
> it's best if it's a generally localized area (i.e. no larger than a
> hemisphere) since it's likely the approximations applied to representing
> the polygons won't be robust near the edges (vertices too far apart stray
> from great circles).
>
> This applies generally though, if you have rectangular cells defined in
> longlat not many projections will stay sane unless you have sufficient
> intermediate vertices between the corners.
>
> Safest is to reproject every polygon to its local centre, and use that LAEA
> (+proj=laea +lon_0=centerlon +lat_0=centerlat +ellps=WGS84 for example) for
> individual calculations on each polygon. But it depends on what your data
> are and how they are represented and distributed in space. Given the
> limitations baked into polygon representations it's not possible to give an
> answer that will always work.
>
> There are global projections that are equal area - Sinusoidal and Albers
> Equal Area Conic, but still you can get bitten by topology so checking the
> visually what's happening is important.
>
> These guides might be helpful:
>
> http://egsc.usgs.gov/isb//pubs/MapProjections/projections.html
>
> http://www.georeference.org/doc/guide_to_selecting_map_projections.htm
>
> Cheers, Mike.
>
>
> > best regards
> >
> >
> >
> > --
> > View this message in context:
> >
> http://r-sig-geo.2731867.n2.nabble.com/What-is-the-metric-projection-equivalent-to-WGS-84-tp7588321.html
> > Sent from the R-sig-geo mailing list archive at Nabble.com.
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


-- 
J?r?me Mathieu
Ma?tre de Conf?rence
UMR iEES

Universit? Pierre et Marie Curie-Paris6
B?t. A - 7?me Etage - Case 237
7 quai St.-Bernard
F-75252 Paris Cedex 05
porte 715

tel: 01 44 27 34 22

	[[alternative HTML version deleted]]


From stevenhuyi at gmail.com  Tue May 26 10:59:30 2015
From: stevenhuyi at gmail.com (stevenhuyi)
Date: Tue, 26 May 2015 01:59:30 -0700 (MST)
Subject: [R-sig-Geo] a problem with creating a neighbours list
Message-ID: <1432630770670-7588325.post@n2.nabble.com>

Hi everyone,
I have a  simple problem, which I know will have a simple solution, but I
just can't tackle it. 

I have a shapefile with regions, including an attribute containing a
regional id. I used the following R script to create a neighbours list:

anhui <- readShapePoly("endemic.shp")
zzz<- poly2nb(anhui,row.names=anhui$COUNTY_ID)
nb2INLA("anhui.graph", zzz)
Anhui.adj <- paste(getwd(),"/Anhui.graph",sep="")

However, the Anhui.adj file is just as follows
31
1 5 3 4 5 6 7
2 2 3 7
3 3 1 2 7
4 2 1 5
...

the id number is not the original id number in my shapefile (which are
actually 1289, 1290,...). Is there a way to get a neighbours list that is
created using the original id number? Thanks for your help.

Yi




--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/a-problem-with-creating-a-neighbours-list-tp7588325.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From sadaouimahrez at outlook.com  Tue May 26 14:25:37 2015
From: sadaouimahrez at outlook.com (sadaoui)
Date: Tue, 26 May 2015 05:25:37 -0700 (MST)
Subject: [R-sig-Geo] What is the metric projection equivalent to WGS 84
In-Reply-To: <CALEhSiTFL_EQBWM3KczxZwv3x=PQ6N-2yDp15MNhenUwBzYL=Q@mail.gmail.com>
References: <1432499823645-7588321.post@n2.nabble.com>
	<CAAcGz990dgH7hx4ZzSUzR-=0TV1bT54ni0hHqZ_iCsdjdKrkmg@mail.gmail.com>
	<CALEhSiTFL_EQBWM3KczxZwv3x=PQ6N-2yDp15MNhenUwBzYL=Q@mail.gmail.com>
Message-ID: <1432643137272-7588326.post@n2.nabble.com>


Thank you,  Tim Keitt, Michael Sumner and J?rome Mathieu for your helpful
answers.

I can calculate the area with all of your suggestions (WGS 84 / UTM), I also
find the function 
areaPolygon in the R package geosphere, proposed by J?rome, very
interesting,
it allows you to calculate the area (m2) without changing the projection
(WGS84).

thank you again

Best regards

Mahrez



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/What-is-the-metric-projection-equivalent-to-WGS-84-tp7588321p7588326.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From johnwasige at gmail.com  Tue May 26 19:41:07 2015
From: johnwasige at gmail.com (John Wasige)
Date: Tue, 26 May 2015 19:41:07 +0200
Subject: [R-sig-Geo] residuals from linear regression of two rasterstack -
	time series
Message-ID: <CAJgdCD5pbYsjZKnvtHq0z5F7wpFOMyP8DWJRU_1Baw17Tw39TQ@mail.gmail.com>

Hi every body! I need your help. How can calculate residuals from linear
regression of two rasterstack - time series? Thanks for your help

-- 
John Wasige

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Tue May 26 20:45:33 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 26 May 2015 20:45:33 +0200
Subject: [R-sig-Geo] a problem with creating a neighbours list
In-Reply-To: <1432630770670-7588325.post@n2.nabble.com>
References: <1432630770670-7588325.post@n2.nabble.com>
Message-ID: <alpine.LFD.2.11.1505262041050.29332@reclus.nhh.no>

On Tue, 26 May 2015, stevenhuyi wrote:

> Hi everyone,
> I have a  simple problem, which I know will have a simple solution, but I
> just can't tackle it.
>
> I have a shapefile with regions, including an attribute containing a
> regional id. I used the following R script to create a neighbours list:

Please always state which package functions come from, here maptools:

>
> anhui <- readShapePoly("endemic.shp")

and here spdep:

> zzz<- poly2nb(anhui,row.names=anhui$COUNTY_ID)
> nb2INLA("anhui.graph", zzz)
> Anhui.adj <- paste(getwd(),"/Anhui.graph",sep="")
>

This is what spdep::nb2INLA() provides - why would you need your COUNTY_ID 
character value? In INLA, you usually would set idx to 1:n, not character 
ID values, I think?

Roger

> However, the Anhui.adj file is just as follows
> 31
> 1 5 3 4 5 6 7
> 2 2 3 7
> 3 3 1 2 7
> 4 2 1 5
> ...
>
> the id number is not the original id number in my shapefile (which are
> actually 1289, 1290,...). Is there a way to get a neighbours list that is
> created using the original id number? Thanks for your help.
>
> Yi
>
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/a-problem-with-creating-a-neighbours-list-tp7588325.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From antonio.bubbico at gmail.com  Tue May 26 23:49:19 2015
From: antonio.bubbico at gmail.com (Antonio Bubbico)
Date: Tue, 26 May 2015 22:49:19 +0100
Subject: [R-sig-Geo] calculate marginal effects of a spatial tobit model
 using sartobit
In-Reply-To: <alpine.LFD.2.11.1505201148110.26612@reclus.nhh.no>
References: <CABW+3tBakQ8WkjyQrqtYMsS-D=BH08_cao0UoqEyWTpeiFeutQ@mail.gmail.com>
	<CAHT1vphjYRwZ6FY2L3Q=mVcvdWDtJNQNfPHCie0KgOp5s3+EYw@mail.gmail.com>
	<CABW+3tAfaJC8qfbJoExu4cQFPX6Xn0Jfhw+PL-B8D+kh64hRSw@mail.gmail.com>
	<alpine.LFD.2.11.1505201148110.26612@reclus.nhh.no>
Message-ID: <CABW+3tBn7TfeK-gALEGsNuqjmxxT9jYUJXhoZErvLFVTW5=Kzw@mail.gmail.com>

thank you very much Roger.

I have another question that is related to the spatialprobit models.

As suggested by LeSage and Pace, In order to select the best model among
models with different weight matrices, I would consider
the Bayesian posterior model probabilities and I would rely on the model
with the highest probability.

Now which value given back by the *sartobit *should I use? beta or rho?

Thanks.


2015-05-20 10:53 GMT+01:00 Roger Bivand <Roger.Bivand at nhh.no>:

> On Wed, 20 May 2015, Antonio Bubbico wrote:
>
>  thanks but nothing new from there
>>
>
> The current version of spatialprobit::sartobit returns components total,
> direct and indirect, but they are all filled with logical NAs by default,
> when computeMarginalEffects=FALSE. Unfortunately, this is the same (NAs)
> when it is TRUE too, so I'd suggest contacting the package maintainer,
> and/or examining the source code of the function.
>
> Roger
>
>
>
>> 2015-05-20 11:20 GMT+02:00 Roman Lu?trik <roman.lustrik at gmail.com>:
>>
>>  Hi,
>>>
>>> see
>>>
>>> library(sos)
>>> findFn("tobit")
>>>
>>> which returns some results that might be of interest to you.
>>>
>>> Cheers,
>>> Roman
>>>
>>>
>>> On Wed, May 20, 2015 at 11:16 AM, Antonio Bubbico <
>>> antonio.bubbico at gmail.com> wrote:
>>>
>>>  Hello,
>>>>
>>>> I am using the function sartobit to calculate a spatial tobit model. I
>>>> would also like to calculate marginal effects, but I don't t know if
>>>> there
>>>> is a  built-in function able to make it.
>>>>
>>>> Thanks.
>>>> --
>>>> *Dr Antonio Bubbico*
>>>> Postdoctoral Researcher
>>>>
>>>>
>>>>
>>>>
>>>> *School of Agriculture and Food ScienceUniversity College
>>>> DublinBelfield,
>>>> Dublin 4Ireland*
>>>>
>>>> Tel: +353899528966
>>>> e-mail: a <marija.banovic at ucd.ie>ntonio.bubbico at gmail.com
>>>> Room: 1.27
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>
>>>
>>>
>>> --
>>> In God we trust, all others bring data.
>>>
>>>
>>
>>
>> --
>> *Dr Antonio Bubbico*
>> Postdoctoral Researcher
>>
>>
>>
>>
>> *School of Agriculture and Food ScienceUniversity College DublinBelfield,
>> Dublin 4Ireland*
>>
>> Tel: +353899528966
>> e-mail: a <marija.banovic at ucd.ie>ntonio.bubbico at gmail.com
>> Room: 1.27
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>



-- 
*Dr Antonio Bubbico*
Postdoctoral Researcher




*School of Agriculture and Food ScienceUniversity College DublinBelfield,
Dublin 4Ireland*

Tel: +353899528966
e-mail: a <marija.banovic at ucd.ie>ntonio.bubbico at gmail.com
Room: 1.27

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Wed May 27 00:25:06 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Tue, 26 May 2015 22:25:06 +0000
Subject: [R-sig-Geo] Hole attribute in Polygon lost when made into Polygons
	object?
Message-ID: <D18A40D1.12B520%macqueen1@llnl.gov>

I must be missing something basic
(either in understanding, or possibly being blind to a typo!)

Here is the example data:

m1 <-structure(c(2.8, 8, 8.2, 3.9, 1.6,
    9.2, 6.8, 3, 1.1, 4.2),
   .Dim = c(5L, 2L))


Pnh <- Polygon(m1, hole=FALSE)
Ph  <-  Polygon(m1, hole=TRUE)

Pnhs <- Polygons(list(Pnh), ID=1)
Phs <- Polygons(list(Ph), ID=1)



Then:
> Pnh at hole
[1] FALSE
> Ph at hole
[1] TRUE

> Pnhs at Polygons[[1]]@hole
[1] FALSE
> Phs at Polygons[[1]]@hole
[1] FALSE

It appears that the hole attribute has been lost??


sp_1.1-0
R 3.1.2

Thanks
-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


From mdsumner at gmail.com  Wed May 27 01:10:26 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 26 May 2015 23:10:26 +0000
Subject: [R-sig-Geo] Hole attribute in Polygon lost when made into
 Polygons object?
In-Reply-To: <D18A40D1.12B520%macqueen1@llnl.gov>
References: <D18A40D1.12B520%macqueen1@llnl.gov>
Message-ID: <CAAcGz9_Su2T8j9rh8sJ0siWxauHupyW3z+=HNyL4yNQE=py-5Q@mail.gmail.com>

On Wed, 27 May 2015 at 08:26 MacQueen, Don <macqueen1 at llnl.gov> wrote:

> I must be missing something basic
> (either in understanding, or possibly being blind to a typo!)
>
> Here is the example data:
>
> m1 <-structure(c(2.8, 8, 8.2, 3.9, 1.6,
>     9.2, 6.8, 3, 1.1, 4.2),
>    .Dim = c(5L, 2L))
>
>
> Pnh <- Polygon(m1, hole=FALSE)
> Ph  <-  Polygon(m1, hole=TRUE)
>
> Pnhs <- Polygons(list(Pnh), ID=1)
> Phs <- Polygons(list(Ph), ID=1)
>
>
>
> Then:
> > Pnh at hole
> [1] FALSE
> > Ph at hole
> [1] TRUE
>
> > Pnhs at Polygons[[1]]@hole
> [1] FALSE
> > Phs at Polygons[[1]]@hole
> [1] FALSE
>
> It appears that the hole attribute has been lost??
>
>
>


I believe that the hole attribute only makes sense when it's relative to at
least one other Polygon object. If you combine your Pnh and Ph in the same
Polygons object, the hole status is preserved (despite this being a broken
object, see below):

 sapply(Polygons(list(Pnh, Ph), ID = 1)@Polygons, slot, "hole")
[1] FALSE  TRUE

If you create a Polygons object with just one Polygon that is a 'hole',
there's nothing for it to be a hole of (there's no 'background'  in sp).  I
presume this happens internally when a new Polygons is initialized with
just one ring, it makes no sense for the hole attribute  to be TRUE (the sp
source is here src/sp_xports.c but I'm not au fait with that).

Note that both of your Polygon objects are identical, so you get a nonsense
object:


rgeos::gIsValid(SpatialPolygons(list(Polygons(list(Pnh, Ph), ID = 1))))
[1] FALSE
Warning message:
In RGEOSUnaryPredFunc(spgeom, byid, "rgeos_isvalid") :
  Self-intersection at or near point 1.6000000000000001 4.2000000000000002

Also, you can see the different ways the topology is treated by creating a
hole, and then offset that to incorrectly overlap
it's background. With usePolypath the topology of the situation is more
clearly represented
x1 <- Polygon(m1, hole=FALSE)
x2  <-  Polygon((m1 + 3) / 1.5, hole=TRUE)
p1 <- SpatialPolygons(list(Polygons(list(x1, x2), ID = 1)))

op <- par(mfrow = c(2, 2))
plot(p1, col = "grey", usePolypath = TRUE, main = "ok, polypath TRUE")
plot(p1, col = "grey", usePolypath = FALSE, main = "ok, polypath FALSE")

## now with a hole, but incorrectly overlapping

y1 <- Polygon(m1, hole=FALSE)
y2  <-  Polygon((m1 + 4) / 1.5, hole=TRUE)
p2 <- SpatialPolygons(list(Polygons(list(y1, y2), ID = 1)))

plot(p2, col = "grey", usePolypath = TRUE, main = "broken, polypath TRUE")
plot(p2, col = "grey", usePolypath = FALSE, main = "broken, polypath FALSE")
par(op)

Does that help?

Cheers, Mike.



> sp_1.1-0
> R 3.1.2
>
> Thanks
> -Don
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Wed May 27 01:52:01 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Tue, 26 May 2015 23:52:01 +0000
Subject: [R-sig-Geo] Hole attribute in Polygon lost when made into
 Polygons object?
In-Reply-To: <CAAcGz9_Su2T8j9rh8sJ0siWxauHupyW3z+=HNyL4yNQE=py-5Q@mail.gmail.com>
References: <D18A40D1.12B520%macqueen1@llnl.gov>
	<CAAcGz9_Su2T8j9rh8sJ0siWxauHupyW3z+=HNyL4yNQE=py-5Q@mail.gmail.com>
Message-ID: <D18A53E4.12B542%macqueen1@llnl.gov>

That makes sense, i.e., I did not realize that an  individual Polygon object can be a hole or not, as specified when it is created, but within a Polygons object there can be no hole Polygon unless there is also another non-hole Polygon.

Thanks
-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


From: Michael Sumner <mdsumner at gmail.com<mailto:mdsumner at gmail.com>>
Date: Tuesday, May 26, 2015 at 4:10 PM
To: dh m <macqueen1 at llnl.gov<mailto:macqueen1 at llnl.gov>>, "R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>" <R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>>
Subject: Re: [R-sig-Geo] Hole attribute in Polygon lost when made into Polygons object?



On Wed, 27 May 2015 at 08:26 MacQueen, Don <macqueen1 at llnl.gov<mailto:macqueen1 at llnl.gov>> wrote:
I must be missing something basic
(either in understanding, or possibly being blind to a typo!)

Here is the example data:

m1 <-structure(c(2.8, 8, 8.2, 3.9, 1.6,
    9.2, 6.8, 3, 1.1, 4.2),
   .Dim = c(5L, 2L))


Pnh <- Polygon(m1, hole=FALSE)
Ph  <-  Polygon(m1, hole=TRUE)

Pnhs <- Polygons(list(Pnh), ID=1)
Phs <- Polygons(list(Ph), ID=1)



Then:
> Pnh at hole
[1] FALSE
> Ph at hole
[1] TRUE

> Pnhs at Polygons[[1]]@hole
[1] FALSE
> Phs at Polygons[[1]]@hole
[1] FALSE

It appears that the hole attribute has been lost??





I believe that the hole attribute only makes sense when it's relative to at least one other Polygon object. If you combine your Pnh and Ph in the same Polygons object, the hole status is preserved (despite this being a broken object, see below):

 sapply(Polygons(list(Pnh, Ph), ID = 1)@Polygons, slot, "hole")
[1] FALSE  TRUE

If you create a Polygons object with just one Polygon that is a 'hole', there's nothing for it to be a hole of (there's no 'background'  in sp).  I presume this happens internally when a new Polygons is initialized with just one ring, it makes no sense for the hole attribute  to be TRUE (the sp source is here src/sp_xports.c but I'm not au fait with that).

Note that both of your Polygon objects are identical, so you get a nonsense object:


rgeos::gIsValid(SpatialPolygons(list(Polygons(list(Pnh, Ph), ID = 1))))
[1] FALSE
Warning message:
In RGEOSUnaryPredFunc(spgeom, byid, "rgeos_isvalid") :
  Self-intersection at or near point 1.6000000000000001 4.2000000000000002

Also, you can see the different ways the topology is treated by creating a hole, and then offset that to incorrectly overlap
it's background. With usePolypath the topology of the situation is more clearly represented
x1 <- Polygon(m1, hole=FALSE)
x2  <-  Polygon((m1 + 3) / 1.5, hole=TRUE)
p1 <- SpatialPolygons(list(Polygons(list(x1, x2), ID = 1)))

op <- par(mfrow = c(2, 2))
plot(p1, col = "grey", usePolypath = TRUE, main = "ok, polypath TRUE")
plot(p1, col = "grey", usePolypath = FALSE, main = "ok, polypath FALSE")

## now with a hole, but incorrectly overlapping

y1 <- Polygon(m1, hole=FALSE)
y2  <-  Polygon((m1 + 4) / 1.5, hole=TRUE)
p2 <- SpatialPolygons(list(Polygons(list(y1, y2), ID = 1)))

plot(p2, col = "grey", usePolypath = TRUE, main = "broken, polypath TRUE")
plot(p2, col = "grey", usePolypath = FALSE, main = "broken, polypath FALSE")
par(op)

Does that help?

Cheers, Mike.


sp_1.1-0
R 3.1.2

Thanks
-Don

--
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Wed May 27 07:18:27 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 27 May 2015 07:18:27 +0200
Subject: [R-sig-Geo] Hole attribute in Polygon lost when made into
 Polygons object?
In-Reply-To: <D18A40D1.12B520%macqueen1@llnl.gov>
References: <D18A40D1.12B520%macqueen1@llnl.gov>
Message-ID: <alpine.LFD.2.11.1505270713210.3948@reclus.nhh.no>

On Wed, 27 May 2015, MacQueen, Don wrote:

> I must be missing something basic
> (either in understanding, or possibly being blind to a typo!)
>
> Here is the example data:
>
> m1 <-structure(c(2.8, 8, 8.2, 3.9, 1.6,
>    9.2, 6.8, 3, 1.1, 4.2),
>   .Dim = c(5L, 2L))
>
>
> Pnh <- Polygon(m1, hole=FALSE)
> Ph  <-  Polygon(m1, hole=TRUE)
>
> Pnhs <- Polygons(list(Pnh), ID=1)
> Phs <- Polygons(list(Ph), ID=1)
>
>
>
> Then:
>> Pnh at hole
> [1] FALSE
>> Ph at hole
> [1] TRUE
>
>> Pnhs at Polygons[[1]]@hole
> [1] FALSE
>> Phs at Polygons[[1]]@hole
> [1] FALSE
>
> It appears that the hole attribute has been lost??
>

Yes, by design. A Polygons object is like an OGC/SFS MultiPolygon or 
Polygon object, and must have at least one exterior ring (non-hole 
sp:Polygon object). If the only Polygon object in a Polygons object has 
its hole slot set to TRUE, this is treated as a misunderstanding and 
silently changed to FALSE (and ring direction reversed if need be). Please 
see the note in ?"Polygons-class".

Hope this clarifies,

Roger

>
> sp_1.1-0
> R 3.1.2
>
> Thanks
> -Don
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From antonio.bubbico at gmail.com  Wed May 27 12:55:56 2015
From: antonio.bubbico at gmail.com (Antonio Bubbico)
Date: Wed, 27 May 2015 11:55:56 +0100
Subject: [R-sig-Geo] distance between municipalities and provincial capital
Message-ID: <CABW+3tA1NPqPQ8XUmuUBpS0Hf9Ka16vKDxL12L=6zDmuMavkEA@mail.gmail.com>

Hello,

I have data from a census where the observations are the municipalities. I
would like to calculate the distance of each municipality by its own
provincial capital.

Have you some suggestions?

-- 
*Dr Antonio Bubbico*
Postdoctoral Researcher




*School of Agriculture and Food ScienceUniversity College DublinBelfield,
Dublin 4Ireland*

Tel: +353899528966
e-mail: a <marija.banovic at ucd.ie>ntonio.bubbico at gmail.com
Room: 1.27

	[[alternative HTML version deleted]]


From loic.dutrieux at wur.nl  Wed May 27 13:30:30 2015
From: loic.dutrieux at wur.nl (Dutrieux, Loic)
Date: Wed, 27 May 2015 11:30:30 +0000
Subject: [R-sig-Geo] distance between municipalities and provincial
 capital
In-Reply-To: <CABW+3tA1NPqPQ8XUmuUBpS0Hf9Ka16vKDxL12L=6zDmuMavkEA@mail.gmail.com>
References: <CABW+3tA1NPqPQ8XUmuUBpS0Hf9Ka16vKDxL12L=6zDmuMavkEA@mail.gmail.com>
Message-ID: <1432726230660.12354@wur.nl>

Hi Antonio,

Probably gDistance from rgeos package.

Cheers,
Lo?c
________________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of Antonio Bubbico <antonio.bubbico at gmail.com>
Sent: Wednesday, May 27, 2015 12:55 PM
To: R-sig-geo mailing list
Subject: [R-sig-Geo] distance between municipalities and provincial capital

Hello,

I have data from a census where the observations are the municipalities. I
would like to calculate the distance of each municipality by its own
provincial capital.

Have you some suggestions?

--
*Dr Antonio Bubbico*
Postdoctoral Researcher




*School of Agriculture and Food ScienceUniversity College DublinBelfield,
Dublin 4Ireland*

Tel: +353899528966
e-mail: a <marija.banovic at ucd.ie>ntonio.bubbico at gmail.com
Room: 1.27

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From smithtiffanyt at gmail.com  Wed May 27 15:26:15 2015
From: smithtiffanyt at gmail.com (Tiffany Smith)
Date: Wed, 27 May 2015 09:26:15 -0400
Subject: [R-sig-Geo] grid.text with rasterVis::layerplot
In-Reply-To: <CAMLL7bkJ4-kfF+bNHDVqSNg19066Qktcd+VoE46SK6h+d8YjDQ@mail.gmail.com>
References: <41C5BAE4-1367-424C-AA2C-A10BB13A0CAA@gmail.com>
	<555FAE73.4020306@gmail.com>
	<CAMLL7bkJ4-kfF+bNHDVqSNg19066Qktcd+VoE46SK6h+d8YjDQ@mail.gmail.com>
Message-ID: <9EAC4116-D753-4F02-898B-45FE9D2341E7@gmail.com>

Thanks so much, that worked perfectly!
> On May 23, 2015, at 11:28 AM, Oscar Perpi?an <oscar.perpinan at gmail.com> wrote:
> 
> Hi,
> 
> It is easier with the panel.number function. Following the example proposed by Tim:
> 
> library(rasterVis)
> 
> f <- system.file("external/test.grd", package="raster")
> r <- raster(f)
> s <- stack(r, r+500, r-500)
> 
> labs <- c("a.", "b.", "c.")
> 
> levelplot(s) + layer(grid.text(labs[panel.number()], .95, .1))
> 
> Best,
> 
> Oscar.
> 
> -----------------------------------------------------------------
> Oscar Perpi??n Lamigueiro
> Dpto. Ing. El?ctrica, Electr?nica, Autom?tica y F?sica Aplicada (ETSIDI-UPM)
> Grupo de Sistemas Fotovoltaicos (IES-UPM)
> URL: http://oscarperpinan.github.io <http://oscarperpinan.github.io/>

	[[alternative HTML version deleted]]


From sglish at hotmail.com  Thu May 28 12:28:25 2015
From: sglish at hotmail.com (Chris English)
Date: Thu, 28 May 2015 06:28:25 -0400
Subject: [R-sig-Geo] STIDF - endTime, STI -> Track
Message-ID: <BAY172-W53AAAD09FA73E6FA62B9FC5CA0@phx.gbl>

Hi,

I am wondering about the role of endTime in STIDF objects. ?I am examining eye tracking data (previously cleaned of blinks) in relation to?
presented stimuli that is for some subjects an optical illusion and for others not. ?I want to examine where they were looking and when.

My process is to make a STIDF from the eye tracking data case and a STSDF of the stimuli that was presented where and for how long,
convert the STIDF to a Track then do some 'over' analysis.

If I build my endTime for the STIDF using the delta() function on N samples, I think I get something like N-1 endTimes, or every sample
is an endTime so N = N.

If instead I am thinking of endTime(s) as an interval during which there is a cross hair and some tangential stimulus on the screen and
endTime is when a subject responds in some manner I can't build an STDIF due to the following test:

> eye_5v1_stidf <- STIDF(eye_5v1_sp, eye_5v1_time, eye_5v1_data,
+ eye_5v1_endTime)
Error: nrow(object at time) == length(object at endTime) is not TRUE
> nrow(eye_5v1_time)
[1] 4724
> length(eye_5v1_endTime)
[1] 63
>?

Indeed, it is not true. But what information do I have in endTime other than my sensor sampling rate adjusted for blinks? ?What I hoped to
achieve was to compare the spacetime aspects of the Track data through time periods consistent with the time periods in the STSDF.
Perhaps 'over' takes care of this for me and I don't have to attend if I just accept that endTime in the case of the STIDF is the end of each
sample.

The eye tracking data I am examining is fairly simple: x, y, cumulative sum of samples in ms, duration between samples; from which
an STI can be constructed. ?Not much more data than where the eyes were when. ?It would seem that there would be a lot of simple sensor
data of this sort so I wonder if Track can relax its requirement of STIDF to allow STI.?

Thank you in advance for your time and consideration.

Cheers,

Chris



?


 		 	   		  

From macqueen1 at llnl.gov  Thu May 28 21:58:21 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 28 May 2015 19:58:21 +0000
Subject: [R-sig-Geo] Hole attribute in Polygon lost when made into
 Polygons object?
In-Reply-To: <alpine.LFD.2.11.1505270713210.3948@reclus.nhh.no>
References: <D18A40D1.12B520%macqueen1@llnl.gov>
	<alpine.LFD.2.11.1505270713210.3948@reclus.nhh.no>
Message-ID: <D18CB42A.12C07F%macqueen1@llnl.gov>

Thanks, Roger, it does clarify.
-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 5/26/15, 10:18 PM, "Roger Bivand" <Roger.Bivand at nhh.no> wrote:

>On Wed, 27 May 2015, MacQueen, Don wrote:
>
>> I must be missing something basic
>> (either in understanding, or possibly being blind to a typo!)
>>
>> Here is the example data:
>>
>> m1 <-structure(c(2.8, 8, 8.2, 3.9, 1.6,
>>    9.2, 6.8, 3, 1.1, 4.2),
>>   .Dim = c(5L, 2L))
>>
>>
>> Pnh <- Polygon(m1, hole=FALSE)
>> Ph  <-  Polygon(m1, hole=TRUE)
>>
>> Pnhs <- Polygons(list(Pnh), ID=1)
>> Phs <- Polygons(list(Ph), ID=1)
>>
>>
>>
>> Then:
>>> Pnh at hole
>> [1] FALSE
>>> Ph at hole
>> [1] TRUE
>>
>>> Pnhs at Polygons[[1]]@hole
>> [1] FALSE
>>> Phs at Polygons[[1]]@hole
>> [1] FALSE
>>
>> It appears that the hole attribute has been lost??
>>
>
>Yes, by design. A Polygons object is like an OGC/SFS MultiPolygon or
>Polygon object, and must have at least one exterior ring (non-hole
>sp:Polygon object). If the only Polygon object in a Polygons object has
>its hole slot set to TRUE, this is treated as a misunderstanding and
>silently changed to FALSE (and ring direction reversed if need be).
>Please 
>see the note in ?"Polygons-class".
>
>Hope this clarifies,
>
>Roger
>
>>
>> sp_1.1-0
>> R 3.1.2
>>
>> Thanks
>> -Don
>>
>>
>
>-- 
>Roger Bivand
>Department of Economics, Norwegian School of Economics,
>Helleveien 30, N-5045 Bergen, Norway.
>voice: +47 55 95 93 55; fax +47 55 95 91 00
>e-mail: Roger.Bivand at nhh.no
>


From dave.gregovich at alaska.gov  Fri May 29 02:37:02 2015
From: dave.gregovich at alaska.gov (Gregovich, Dave P (DFG))
Date: Fri, 29 May 2015 00:37:02 +0000
Subject: [R-sig-Geo] Setting raster x- and y-resolutions equal
Message-ID: <174524AB15B8E6478D6F927B2131B09B8E20373A@SOAJNUEXMB3.soa.alaska.gov>

Hello,
I have a stack of about 40 rasters with about 1 X 10^7 cells in each. I did not realize it, but it turns out the x-resolution and y-resolution differ at about the 13th decimal point. And I would like to feed this stack into a function (dynatopmodel::upslope.area) that requires xres(x)==yres(x).
Because of the minute difference between the x- and y- resolutions, I am fine just setting the x- and y- resolutions equal to each other. That would save me the time of resampling all of the bands of the stack. However, this does not seem to be working for me when I try to reproduce the problem, as shown below using a single band that mimics a single band from the stack I am working with:

library(raster);library(rgdal)
options(digits=20)

#Example 1, my situation, which is not working....
rast <- raster(nrows=4072, ncols=3111, xmn=656419.81022503704298, xmx=730403.88166906696279,
                                                                ymn=794177.97668560303282,ymx=891016.01555416302290)
rast[] <- rnorm(1:ncell(rast))
proj4string(rast) <- '+init=epsg:26931'
xres(rast);yres(rast)
res(rast)<-c(xres(rast),xres(rast))
#xres and yres differ!!!!....
res(rast)

#and then two examples that work, Example 2, with a raster of the same size but resetting the resolution to res(rast) <- c(5,5)....
rast <- raster(nrows=4072, ncols=3111, xmn=656419.81022503704298, xmx=730403.88166906696279,
                                                                ymn=794177.97668560303282,ymx=891016.01555416302290)
rast[] <- rnorm(1:ncell(rast))
proj4string(rast) <- '+init=epsg:26931'
xres(rast);yres(rast)
res(rast)<-c(5,5)
#new resolution as expected....
res(rast)

#and example 3, with a raster 100X smaller...
rast <- raster(nrows=407, ncols=311, xmn=65641.981022503704298, xmx=73040.388166906696279,
                                                                ymn=79417.797668560303282,ymx=89101.601555416302290)
rast[] <- rnorm(1:ncell(rast))
proj4string(rast) <- '+init=epsg:26931'
xres(rast);yres(rast)
res(rast)<-c(xres(rast),xres(rast))
res(rast)

#salient session info

R version 3.1.3 (2015-03-09)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1
raster_2.3-33      sp_1.0-17  rgdal_0.9-2

Thanks kindly for any help you can provide, r-sig-geo!
__________________________________
Dave Gregovich
Research Analyst
Alaska Department of Fish and Game
Wildlife Conservation Division
Douglas, AK 99821
(907) 465-4291
dave.gregovich at alaska.gov
__________________________________


	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Fri May 29 12:13:31 2015
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 29 May 2015 11:13:31 +0100
Subject: [R-sig-Geo] Javascript All The Things!
Message-ID: <CANVKczPb+SQg4TfKaRx1XeqEVw3a=gqM9UV2bceEPWeYQbAUXQ@mail.gmail.com>

[Apologies for the memey subject: http://knowyourmeme.com/memes/x-all-the-y]

Developers can't fail to have noticed the rise of Javascript, both in
the browser and outside of it. But it has now crept into R, and into
R-spatial packages.

Javascript, like most languages, has its right to exist and its place.
I'm just not sure that using it to call functionality that exists
perfectly well elsewhere in R is the place.

 For example, there is a Javascript library called "turf.js" that does
GIS operations like polygon overlay, buffering, point-in-polygon etc.
That's great, because now my web mapping interface can do those in the
browser. The user can draw a polygon, the browser can select the data
and do something with it without a round-trip and a load on the
server. Brilliant. That same Javascript can also run perfectly well
outside a browser via a JS interpreter such as node or V8, so its
possible to use turf.js to write javascript scripts to do GIS
operations. Again, brilliant. If you are a JS programmer developing
systems in JS that need this, you've now got it.

 Now there is a package (V8) to run Javascript in  R. Great. If
there's some JS functionality you want to call. But why should you use
it to access functionality you've got in a perfectly good R package
already? The turf.js code has been wrapped in the "lawn" package, so
you can call turf's GIS functions from R. Some people on twitter seem
to think this is novel, and suddenly you can now do "GIS in R!". They
seem to have not noticed we've been doing it for the past umpteen
years with things like gpclib, and lately rgeos.

 Why use "lawn" instead of "rgeos"? Twitter isn't a good place for
such discussions, and all I've got out of people there are things like
"but if you have a geoJSON workflow". I'm not sure that makes sense.
geoJSON, if you don't know, is the lingua franca of spatial data in JS
(and is supported by GDAL/OGR). But if you are going to read your data
into R at some point its going to get converted out of geoJSON into
native R formats. There's overheads both ways. I've not benchmarked
any of this yet, but I have a hunch data conversion and interfacing to
JS is going to be slow compared to native rgeos calculations. The lawn
package web page seems to concur.

 Another example of "JS All The Things"  manifested today. The rgbif
package uses rgeos to read WKT data. But a recent change from the
author replaced that with some JS code. So now instead of calling
rgeos::readWKT, this happens:

read_wkt <- function(wkt) {
terr$eval(sprintf("var out = terrwktparse.parse('%s');", wkt))
terr$get("out")
}

where `terr` is a handle to the JS code. Again, I've not benchmarked
it, but there appears to be a lot of string conversion and passing of
data from one world to another. Plus there's the overhead of loading
in a completely new language interpreter via a dependency on the V8
package, compared to loading in some clean C code.

 So I'm mind-boggled. Why is this happening? Is it just that JS is
trendy? Is it that there is a surfeit of JS programmers? Is it
speculative "because I can" development? Should R-spatial data look at
this as evolution and consider the future of sp classes?

 Discuss. Maybe its something those of us at the Geostat Summer School
in August can have a good chat about, although I don't think anyone
from the JS side of things will be there... Maybe in 2016....

Barry


From stevenhuyi at gmail.com  Fri May 29 13:00:28 2015
From: stevenhuyi at gmail.com (stevenhuyi)
Date: Fri, 29 May 2015 04:00:28 -0700 (MST)
Subject: [R-sig-Geo] to forecast a disease risk using a dynamic model
Message-ID: <1432897228573-7588373.post@n2.nabble.com>

Hi everyone,

I'm recently struggling with exploring a model to forecast the
schistosomiasis risk. Let me introduce the data I have first.
Parasitological data, including number of infected individuals and
population at risk, are available in a province from 1997 to 2010 at the
county level (i.e., polygon data in county) as well as some risk factors
(e.g., temperature, rainfall, and wetness). I want to forecast the disease
risk, that's the risks in 2011,2012, and etc. 

What comes to me first is the time series model (i.e., ARIMA) or Karman
filtering, but schistosomiasis often occurred in clusters, so the spatial
correlation should be considered. Besides,as the parasitologcal data are
count data, it would be better to fit the data using a Poisson or negative
binomial distribution. Unfortunately, either time series model or karman
filtering can tackle these. I tried the LINA package in R the other day. It
can take into account the issues that I'm concerned about, but it seems that
it can only smooth the data using the historical data, it cannot forecast. 
I have some references, but no example is related to forecast. 

A popular idea to fit spatiotemporal data is to use a hierarchical model,
which is composed of a data level model, a state level model that produce
the data, and finally a parameter level which exists in the former two level
models. Many statistician advocates this model, like Noel Cressie. I think
this would be my target. However, it seems that there is no R package that
can implement the hierarchical model for the polygon data, I know some can
deal with point data like spTimer (but it still cannot deal with count
data).  

What I said above might not be correct and welcome your comments and, most
of all, please give me some suggestions on how to forecast the disease risk
and to implement it, hopefully, in R. Thank you so much, guys! Have a nice
weekend.



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/to-forecast-a-disease-risk-using-a-dynamic-model-tp7588373.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From elaine at transloc.com  Fri May 29 18:20:05 2015
From: elaine at transloc.com (Elaine McVey)
Date: Fri, 29 May 2015 12:20:05 -0400
Subject: [R-sig-Geo] Missing projection file?
Message-ID: <CAC9tk27bJYBEDUqHn7K1MKbna6yhO5bNvzoQa2pv0ses8JuuOg@mail.gmail.com>

I'm new to the list and getting started with using R for geospatial data.
I'm having a problem I can't solve in which the projection file seems to be
missing.  This is the error I get:

proj4string(d) <- CRS("+init=epsg:28992")

Error in CRS("+init=epsg:28992") : no system list, errno: 2


It's confusing because when I load the package, it seems to successfully
autodetect the PROJ.4 files:

> library(rgdal)
rgdal: version: 0.9-2, (SVN revision 526)
Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 1.11.2, released 2015/02/10
Path to GDAL shared files:
Loaded PROJ.4 runtime: Rel. 4.9.1, 04 March 2015, [PJ_VERSION: 491]
Path to PROJ.4 shared files: (autodetected)


But when I do this, it returns zero:

.Call("PROJcopyEPSG", tempfile(), PACKAGE = "rgdal")


The only answer I've found from googling this is that epsg has to be
lowercase, which it is in my code.

I'm on a Mac running Yosemite, with R 3.2.0, and working inside RStudio
(version 0.99.441).  Other packages and versions from my session info:

rgeos_0.3-8          ggmap_2.4            ggplot2_1.0.1        rgdal_0.9-2
         leaflet_0.0.15       tidyr_0.2.0          dplyr_0.4.1
 UScensus2010blk_1.00 UScensus2010_0.11    foreign_0.8-63
maptools_0.8-36      sp_1.1-0

Can anyone help me figure this out?  I'm surprised I didn't find more on
this problem, as I can't be the only one having it . . .

---

Elaine McVey
Data Scientist
Transloc

	[[alternative HTML version deleted]]


From zua3 at cornell.edu  Fri May 29 19:41:43 2015
From: zua3 at cornell.edu (Zia Uddin Ahmed)
Date: Fri, 29 May 2015 17:41:43 +0000
Subject: [R-sig-Geo] Help: contvert multiband 16 bit tif  to 8 band tif
In-Reply-To: <5373437E.3030806@spatial-analyst.net>
References: <CAA2guuz+Xb9BTOYSbP-gEwJv+G2om959x-0q2LbSFY7tR7mZWQ@mail.gmail.com>,
	<5373437E.3030806@spatial-analyst.net>
Message-ID: <BY2PR04MB629083D7B84084BB0BE1D6C88C90@BY2PR04MB629.namprd04.prod.outlook.com>

Dear,
Does anyone know how to convert multiband (5 bands) 16 bit unsigned integer  (tif file)  to 8 band tif with R? Help will be appreciated.
Thanks
Zia

________________________________________
From: r-sig-geo-bounces at r-project.org <r-sig-geo-bounces at r-project.org> on behalf of Tomislav Hengl <hengl at spatial-analyst.net>
Sent: Wednesday, May 14, 2014 6:20 AM
To: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] Spatio temporal Kriging

Technically speaking it is OK to predict in future (prepare a stfdfObj
object with spacetime coordinates in future, then run krigeST), but I
would assume that the prediction variance will be large (well this
depends on your variogram / temporal nugget and temporal range of
spatial autocorrelation). Consider for example the prediction models for
weather in the Netherlands:
http://www.knmi.nl/waarschuwingen_en_verwachtingen/ensemble.html
As you get further from the measurement horizon, the confidence limits
become wider and wider.

Also, I do not know how much is krigeST applicable to non-Gaussian data.

PS: Sending more focused questions that refer to some specific line in
the code / or specific topic of broad interest are usually more
efficient on R-sig-geo (see: "Do your homework before posting" in
http://www.r-project.org/posting-guide.html).

T. (Tom) Hengl
Url: http://www.wageningenur.nl/en/Persons/dr.-T-Tom-Hengl.htm
Network: http://profiles.google.com/tom.hengl
Publications: http://scholar.google.com/citations?user=2oYU7S8AAAAJ

On 9-5-2014 12:55, Franklin Tchakounte wrote:
> Hello
>
> i am exercising (would like) to use spatiotemporal kriging to predict
> in the future the rate of populations in neighborhoods in towns. I
> have values for population rate in 2011, 2012, 2013, 2014 for many
> neighbourhoods and i need to know the corresponding values in 2015 and
> 2016 with the spatio temporal kriging using R.
> I would to know (if possible) how to apply extrapolation (spatio
> temporal kriging) with R from the beginning to the end.
>
> i have attached the actual R code with the help of Graeler and data file.
>
> Thank you a lot
>
> Franklin
>
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From edzer.pebesma at uni-muenster.de  Sat May 30 00:56:27 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sat, 30 May 2015 00:56:27 +0200
Subject: [R-sig-Geo] STIDF - endTime, STI -> Track
In-Reply-To: <BAY172-W53AAAD09FA73E6FA62B9FC5CA0@phx.gbl>
References: <BAY172-W53AAAD09FA73E6FA62B9FC5CA0@phx.gbl>
Message-ID: <5568EE9B.50502@uni-muenster.de>



On 05/28/2015 12:28 PM, Chris English wrote:
> Hi,
> 
> I am wondering about the role of endTime in STIDF objects.  I am examining eye tracking data (previously cleaned of blinks) in relation to 
> presented stimuli that is for some subjects an optical illusion and for others not.  I want to examine where they were looking and when.
> 
> My process is to make a STIDF from the eye tracking data case and a STSDF of the stimuli that was presented where and for how long,
> convert the STIDF to a Track then do some 'over' analysis.
> 
> If I build my endTime for the STIDF using the delta() function on N samples, I think I get something like N-1 endTimes, or every sample
> is an endTime so N = N.
> 
> If instead I am thinking of endTime(s) as an interval during which there is a cross hair and some tangential stimulus on the screen and
> endTime is when a subject responds in some manner I can't build an STDIF due to the following test:
> 
>> eye_5v1_stidf <- STIDF(eye_5v1_sp, eye_5v1_time, eye_5v1_data,
> + eye_5v1_endTime)
> Error: nrow(object at time) == length(object at endTime) is not TRUE
>> nrow(eye_5v1_time)
> [1] 4724
>> length(eye_5v1_endTime)
> [1] 63
>>  

endTime is meant to give the end time of the time interval an
observation refers to, and so the number of endTime s has to be
identical to the number of time instances (number of observations). I
guess you figure that out.

> 
> Indeed, it is not true. But what information do I have in endTime other than my sensor sampling rate adjusted for blinks?  What I hoped to
> achieve was to compare the spacetime aspects of the Track data through time periods consistent with the time periods in the STSDF.
> Perhaps 'over' takes care of this for me and I don't have to attend if I just accept that endTime in the case of the STIDF is the end of each
> sample.
> 
> The eye tracking data I am examining is fairly simple: x, y, cumulative sum of samples in ms, duration between samples; from which
> an STI can be constructed.  Not much more data than where the eyes were when.  It would seem that there would be a lot of simple sensor
> data of this sort so I wonder if Track can relax its requirement of STIDF to allow STI. 

Good point - I wonder that too. For now, you could feed it a data.frame
with zero columns, e.g. data.frame(matrix(nrow=n, ncol=0))

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150530/051cf842/attachment.bin>

From mdsumner at gmail.com  Sat May 30 17:04:16 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Sat, 30 May 2015 15:04:16 +0000
Subject: [R-sig-Geo] Javascript All The Things!
In-Reply-To: <CANVKczPb+SQg4TfKaRx1XeqEVw3a=gqM9UV2bceEPWeYQbAUXQ@mail.gmail.com>
References: <CANVKczPb+SQg4TfKaRx1XeqEVw3a=gqM9UV2bceEPWeYQbAUXQ@mail.gmail.com>
Message-ID: <CAAcGz98ygbD1uhWYb2vgACYSNj7ZUucOCbicXG7YQpXzBFKxmw@mail.gmail.com>

Surely you understand that standard x-y polygon operations are
fundamentally simplistic? Polygons are a special case where you dumb down a
2D topology into a 1D geometry.

This is no surprise, how many tracking packages are there (dozens), how
many surface packages are there (rgl).

Javascript has a few shining lights in D3 and htmlwidgets. It's not an R
revolution it's a latent GIS one.

What are you really talking about?

Cheers, Mike.

On Fri, 29 May 2015 at 20:13 Barry Rowlingson <b.rowlingson at lancaster.ac.uk>
wrote:

> [Apologies for the memey subject:
> http://knowyourmeme.com/memes/x-all-the-y]
>
> Developers can't fail to have noticed the rise of Javascript, both in
> the browser and outside of it. But it has now crept into R, and into
> R-spatial packages.
>
> Javascript, like most languages, has its right to exist and its place.
> I'm just not sure that using it to call functionality that exists
> perfectly well elsewhere in R is the place.
>
>  For example, there is a Javascript library called "turf.js" that does
> GIS operations like polygon overlay, buffering, point-in-polygon etc.
> That's great, because now my web mapping interface can do those in the
> browser. The user can draw a polygon, the browser can select the data
> and do something with it without a round-trip and a load on the
> server. Brilliant. That same Javascript can also run perfectly well
> outside a browser via a JS interpreter such as node or V8, so its
> possible to use turf.js to write javascript scripts to do GIS
> operations. Again, brilliant. If you are a JS programmer developing
> systems in JS that need this, you've now got it.
>
>  Now there is a package (V8) to run Javascript in  R. Great. If
> there's some JS functionality you want to call. But why should you use
> it to access functionality you've got in a perfectly good R package
> already? The turf.js code has been wrapped in the "lawn" package, so
> you can call turf's GIS functions from R. Some people on twitter seem
> to think this is novel, and suddenly you can now do "GIS in R!". They
> seem to have not noticed we've been doing it for the past umpteen
> years with things like gpclib, and lately rgeos.
>
>  Why use "lawn" instead of "rgeos"? Twitter isn't a good place for
> such discussions, and all I've got out of people there are things like
> "but if you have a geoJSON workflow". I'm not sure that makes sense.
> geoJSON, if you don't know, is the lingua franca of spatial data in JS
> (and is supported by GDAL/OGR). But if you are going to read your data
> into R at some point its going to get converted out of geoJSON into
> native R formats. There's overheads both ways. I've not benchmarked
> any of this yet, but I have a hunch data conversion and interfacing to
> JS is going to be slow compared to native rgeos calculations. The lawn
> package web page seems to concur.
>
>  Another example of "JS All The Things"  manifested today. The rgbif
> package uses rgeos to read WKT data. But a recent change from the
> author replaced that with some JS code. So now instead of calling
> rgeos::readWKT, this happens:
>
> read_wkt <- function(wkt) {
> terr$eval(sprintf("var out = terrwktparse.parse('%s');", wkt))
> terr$get("out")
> }
>
> where `terr` is a handle to the JS code. Again, I've not benchmarked
> it, but there appears to be a lot of string conversion and passing of
> data from one world to another. Plus there's the overhead of loading
> in a completely new language interpreter via a dependency on the V8
> package, compared to loading in some clean C code.
>
>  So I'm mind-boggled. Why is this happening? Is it just that JS is
> trendy? Is it that there is a surfeit of JS programmers? Is it
> speculative "because I can" development? Should R-spatial data look at
> this as evolution and consider the future of sp classes?
>
>  Discuss. Maybe its something those of us at the Geostat Summer School
> in August can have a good chat about, although I don't think anyone
> from the JS side of things will be there... Maybe in 2016....
>
> Barry
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Sun May 31 04:10:14 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Sun, 31 May 2015 02:10:14 +0000
Subject: [R-sig-Geo] Javascript All The Things!
In-Reply-To: <CAAcGz98ygbD1uhWYb2vgACYSNj7ZUucOCbicXG7YQpXzBFKxmw@mail.gmail.com>
References: <CANVKczPb+SQg4TfKaRx1XeqEVw3a=gqM9UV2bceEPWeYQbAUXQ@mail.gmail.com>
	<CAAcGz98ygbD1uhWYb2vgACYSNj7ZUucOCbicXG7YQpXzBFKxmw@mail.gmail.com>
Message-ID: <CAAcGz9_6uQfUv0_kkEuGnN6Y2jmrCAwx5Cw1jrN4NRxH4dpmqA@mail.gmail.com>

I'm really sorry to Barry and the list, this was really rude and
inappropriate.

I appreciate the stimulus for discussion, and I have some contributions but
will leave them for now.

Apologies. Mike

On Sun, 31 May 2015 at 01:04 Michael Sumner <mdsumner at gmail.com> wrote:

> Surely you understand that standard x-y polygon operations are
> fundamentally simplistic? Polygons are a special case where you dumb down a
> 2D topology into a 1D geometry.
>
> This is no surprise, how many tracking packages are there (dozens), how
> many surface packages are there (rgl).
>
> Javascript has a few shining lights in D3 and htmlwidgets. It's not an R
> revolution it's a latent GIS one.
>
> What are you really talking about?
>
> Cheers, Mike.
>
> On Fri, 29 May 2015 at 20:13 Barry Rowlingson <
> b.rowlingson at lancaster.ac.uk> wrote:
>
>> [Apologies for the memey subject:
>> http://knowyourmeme.com/memes/x-all-the-y]
>>
>> Developers can't fail to have noticed the rise of Javascript, both in
>> the browser and outside of it. But it has now crept into R, and into
>> R-spatial packages.
>>
>> Javascript, like most languages, has its right to exist and its place.
>> I'm just not sure that using it to call functionality that exists
>> perfectly well elsewhere in R is the place.
>>
>>  For example, there is a Javascript library called "turf.js" that does
>> GIS operations like polygon overlay, buffering, point-in-polygon etc.
>> That's great, because now my web mapping interface can do those in the
>> browser. The user can draw a polygon, the browser can select the data
>> and do something with it without a round-trip and a load on the
>> server. Brilliant. That same Javascript can also run perfectly well
>> outside a browser via a JS interpreter such as node or V8, so its
>> possible to use turf.js to write javascript scripts to do GIS
>> operations. Again, brilliant. If you are a JS programmer developing
>> systems in JS that need this, you've now got it.
>>
>>  Now there is a package (V8) to run Javascript in  R. Great. If
>> there's some JS functionality you want to call. But why should you use
>> it to access functionality you've got in a perfectly good R package
>> already? The turf.js code has been wrapped in the "lawn" package, so
>> you can call turf's GIS functions from R. Some people on twitter seem
>> to think this is novel, and suddenly you can now do "GIS in R!". They
>> seem to have not noticed we've been doing it for the past umpteen
>> years with things like gpclib, and lately rgeos.
>>
>>  Why use "lawn" instead of "rgeos"? Twitter isn't a good place for
>> such discussions, and all I've got out of people there are things like
>> "but if you have a geoJSON workflow". I'm not sure that makes sense.
>> geoJSON, if you don't know, is the lingua franca of spatial data in JS
>> (and is supported by GDAL/OGR). But if you are going to read your data
>> into R at some point its going to get converted out of geoJSON into
>> native R formats. There's overheads both ways. I've not benchmarked
>> any of this yet, but I have a hunch data conversion and interfacing to
>> JS is going to be slow compared to native rgeos calculations. The lawn
>> package web page seems to concur.
>>
>>  Another example of "JS All The Things"  manifested today. The rgbif
>> package uses rgeos to read WKT data. But a recent change from the
>> author replaced that with some JS code. So now instead of calling
>> rgeos::readWKT, this happens:
>>
>> read_wkt <- function(wkt) {
>> terr$eval(sprintf("var out = terrwktparse.parse('%s');", wkt))
>> terr$get("out")
>> }
>>
>> where `terr` is a handle to the JS code. Again, I've not benchmarked
>> it, but there appears to be a lot of string conversion and passing of
>> data from one world to another. Plus there's the overhead of loading
>> in a completely new language interpreter via a dependency on the V8
>> package, compared to loading in some clean C code.
>>
>>  So I'm mind-boggled. Why is this happening? Is it just that JS is
>> trendy? Is it that there is a surfeit of JS programmers? Is it
>> speculative "because I can" development? Should R-spatial data look at
>> this as evolution and consider the future of sp classes?
>>
>>  Discuss. Maybe its something those of us at the Geostat Summer School
>> in August can have a good chat about, although I don't think anyone
>> from the JS side of things will be there... Maybe in 2016....
>>
>> Barry
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>

	[[alternative HTML version deleted]]


From johnwasige at gmail.com  Sun May 31 09:01:32 2015
From: johnwasige at gmail.com (John Wasige)
Date: Sun, 31 May 2015 09:01:32 +0200
Subject: [R-sig-Geo] slope map and intercept map
Message-ID: <CAJgdCD4wn7upepT_4bhAWE7Gvkqod4WpDS0CRw85rmVktJNWjw@mail.gmail.com>

Hello guys, Could somebody help with an Idea on how I can generate a slope
map and intercept map from a raster stack time series in R. Thanks

?John?

	[[alternative HTML version deleted]]


From erdal.karaca.de at gmail.com  Sun May 31 09:58:14 2015
From: erdal.karaca.de at gmail.com (Erdal Karaca)
Date: Sun, 31 May 2015 09:58:14 +0200
Subject: [R-sig-Geo] decrease sampling rate of GPS track observations
Message-ID: <CAFXiavbMeJ8XYukQzUkLJPaoY_AQ6czG3Cr7m+J-4bXgLG-3EA@mail.gmail.com>

Hi all,
I have a GPS track with a sampling rate of 1 observation per second.
I would like to decrease the number of observations to, for example, 1
observation per 10/20/30 sec or drop all observations between turning
points. What function/package would be best suited?

Thanks.

Best regards,
Erdal

	[[alternative HTML version deleted]]


From loic.dutrieux at wur.nl  Sun May 31 11:21:35 2015
From: loic.dutrieux at wur.nl (Dutrieux, Loic)
Date: Sun, 31 May 2015 09:21:35 +0000
Subject: [R-sig-Geo] slope map and intercept map
In-Reply-To: <CAJgdCD4wn7upepT_4bhAWE7Gvkqod4WpDS0CRw85rmVktJNWjw@mail.gmail.com>
References: <CAJgdCD4wn7upepT_4bhAWE7Gvkqod4WpDS0CRw85rmVktJNWjw@mail.gmail.com>
Message-ID: <1433064095267.60486@wur.nl>

Hi John,

Have a look at the help of the calc function (?raster::calc). The last example of the help is precisely what you want to do, I think.

Cheers,
Lo?c
________________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of John Wasige <johnwasige at gmail.com>
Sent: Sunday, May 31, 2015 9:01 AM
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] slope map and intercept map

Hello guys, Could somebody help with an Idea on how I can generate a slope
map and intercept map from a raster stack time series in R. Thanks

?John?

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

From johnwasige at gmail.com  Sun May 31 13:35:16 2015
From: johnwasige at gmail.com (John Wasige)
Date: Sun, 31 May 2015 13:35:16 +0200
Subject: [R-sig-Geo] Residual maps in R
Message-ID: <CAJgdCD5dku6hk8MkbVqsxOmWeF8HcQQEohqKodDVir03FZ70Sw@mail.gmail.com>

Hello guys, Could somebody help with an Idea on how I can generate residual
maps from multiple
?linear ?
regression model of raster stack time series in R.
Thanks

John

	[[alternative HTML version deleted]]


From dgr2 at cornell.edu  Sun May 31 16:59:16 2015
From: dgr2 at cornell.edu (D G. Rossiter)
Date: Sun, 31 May 2015 14:59:16 +0000
Subject: [R-sig-Geo] slope map and intercept map
Message-ID: <3F68D4E9-99C1-4413-BE23-159283AF311C@cornell.edu>

John, re: your request "Hello guys, Could somebody help with an Idea on how I can generate a slope map and intercept map from a raster stack time series in R. Thanks?

It would help a lot if you would do some work yourself first and then write the list with your ideas and what is confusing or blocking you, with a minimal example. We can?t even tell why you need a ?slope and intercept?. Are you looking for a trend? Do you want the trend per-pixel or within some neighbourhood? What is the application? What R packages are you using and what is the data structure? And most importantly, what did you try, what happened, why was that not satsifactory?

I have a somewhat similar comment to ?decrease sampling rate of GPS track? from Erdal Karaca. Did you make any attempt yourself? If so, what and why was it not satisfactory?

D G (David) Rossiter
Adjunct Associate Professor
Section of Soil & Crop Sciences
Cornell University
Ithaca, NY (USA)


From basille.web at ase-research.org  Sun May 31 17:40:28 2015
From: basille.web at ase-research.org (Mathieu Basille)
Date: Sun, 31 May 2015 11:40:28 -0400
Subject: [R-sig-Geo] decrease sampling rate of GPS track observations
In-Reply-To: <CAFXiavbMeJ8XYukQzUkLJPaoY_AQ6czG3Cr7m+J-4bXgLG-3EA@mail.gmail.com>
References: <CAFXiavbMeJ8XYukQzUkLJPaoY_AQ6czG3Cr7m+J-4bXgLG-3EA@mail.gmail.com>
Message-ID: <556B2B6C.9030202@ase-research.org>

Hi Erdal,

Your best shot is probably to use adehabitatLT, prepare your track as a 
regular trajectory (i.e. with perfectly equal time lags, and missing 
observations present in the trajectory), and then use 'subsample'.

Look at the vignette of adehabitatLT [1] for the first steps to get a 
regular trajectory.

Hope this helps,
Mathieu.


[1] 
http://cran.r-project.org/web/packages/adehabitatLT/vignettes/adehabitatLT.pdf



Le 31/05/2015 03:58, Erdal Karaca a ?crit :
> Hi all,
> I have a GPS track with a sampling rate of 1 observation per second.
> I would like to decrease the number of observations to, for example, 1
> observation per 10/20/30 sec or drop all observations between turning
> points. What function/package would be best suited?
>
> Thanks.
>
> Best regards,
> Erdal
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 

~$ whoami
Mathieu Basille
http://ase-research.org/basille

~$ locate --details
University of Florida \\
Fort Lauderdale Research and Education Center
(+1) 954-577-6314

~$ fortune
? Le tout est de tout dire, et je manque de mots
Et je manque de temps, et je manque d'audace. ?
  -- Paul ?luard


From Roger.Bivand at nhh.no  Sun May 31 19:59:05 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 31 May 2015 19:59:05 +0200
Subject: [R-sig-Geo] Pre-GDAL 2: rgdal changes
Message-ID: <alpine.LFD.2.11.1505311943450.25089@reclus.nhh.no>

The second beta of GDAL 2 is now available, and as of revision 535 on 
R-Forge, the legacy rgdal package passes R CMD check with either GDAL 
1.11.2 (or earlier) or GDAL 2.0.0 beta 2.

One or two issues are known (Integer64 in vector fields and FIDs not 
supported in R; gdalDrivers() reports both raster and vector drivers; the 
MapInfo File TAB driver doesn't work for writing, ...), but others remain 
to be discovered.

For those who need rgdal in production, and can install the 2.0.0 beta, it 
would be a really good use of time to identify issues now, rather than 
when GDAL 2 starts to become the standard, stable release. Anyone else 
needing an itch to scratch is also, of course, welcome to contribute.

The rgdal package will continue to condition on GDAL 1 or 2, so hopefully 
those users who do not need to move to GDAL 2 will not be affected. 
However, it is worth noting that GDAL is maintained by very, very, few 
volunteers (even plural is questionable here), and when they feel that 
backporting fixed from GDAL 2 to GDAL 1 is taking time from more important 
things, you will be stranded with EOL software.

So please consider taking the time to contribute to the idenfication of 
issues in the development version of rgdal built against GDAL 2 and/or 1, 
available for anonymous SVN checkout at:

svn checkout svn://scm.r-forge.r-project.org/svnroot/rgdal/trunk

Enjoy!

Roger

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From edzer.pebesma at uni-muenster.de  Sun May 31 22:03:23 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 31 May 2015 22:03:23 +0200
Subject: [R-sig-Geo] Javascript All The Things!
In-Reply-To: <CANVKczPb+SQg4TfKaRx1XeqEVw3a=gqM9UV2bceEPWeYQbAUXQ@mail.gmail.com>
References: <CANVKczPb+SQg4TfKaRx1XeqEVw3a=gqM9UV2bceEPWeYQbAUXQ@mail.gmail.com>
Message-ID: <556B690B.1070102@uni-muenster.de>

Barry, nice observation.

I've also seen some student groups do amazing things with the MEAN
stack, meaning javascript everywhere (JSON database, server side, client
side).

I think that one of the reasons many people now choose to work with R is
that you can do your complete workflow in it. Convenient. However, a lot
of scripts and packages written Today are utterly unreadable [*],
terribly inefficient, or both. There are still people programming
everything in FORTRAN, because they believe it is the best. It is the
best for them, which means they are right.

Right now, when you receive a Spatial* object from someone, you pretty
well know what it is. At least you could know. If you'd receive a JSON
object that claims to have a lot of (multi)polygons with holes, you may
still need to do quite a bit of checking. But then, if this is enough of
a nuisance, it might improve pretty quickly. There will always be people
trying to push new technologies beyond their limits. Whether they
succeed will depend on community and industrial support.

The Google Earth Engine API is an example where remote sensing
researchers with very little programming experience can do computations
on massive earth observation data sets (complete Landsat and MODIS
archives) within no time, most of them using the javascript API.

In http://journal.r-project.org/archive/2013-1/ooms.pdf Jeroen Ooms
makes some good remarks about package versioning, something that the JS
people seem to have done well in some respects (learning from Java).

Thanks for the x-all-the-y meme link!

[*] unintended, or even intended, full with %>% and . symbols.

On 05/29/2015 12:13 PM, Barry Rowlingson wrote:
> [Apologies for the memey subject: http://knowyourmeme.com/memes/x-all-the-y]
> 
> Developers can't fail to have noticed the rise of Javascript, both in
> the browser and outside of it. But it has now crept into R, and into
> R-spatial packages.
> 
> Javascript, like most languages, has its right to exist and its place.
> I'm just not sure that using it to call functionality that exists
> perfectly well elsewhere in R is the place.
> 
>  For example, there is a Javascript library called "turf.js" that does
> GIS operations like polygon overlay, buffering, point-in-polygon etc.
> That's great, because now my web mapping interface can do those in the
> browser. The user can draw a polygon, the browser can select the data
> and do something with it without a round-trip and a load on the
> server. Brilliant. That same Javascript can also run perfectly well
> outside a browser via a JS interpreter such as node or V8, so its
> possible to use turf.js to write javascript scripts to do GIS
> operations. Again, brilliant. If you are a JS programmer developing
> systems in JS that need this, you've now got it.
> 
>  Now there is a package (V8) to run Javascript in  R. Great. If
> there's some JS functionality you want to call. But why should you use
> it to access functionality you've got in a perfectly good R package
> already? The turf.js code has been wrapped in the "lawn" package, so
> you can call turf's GIS functions from R. Some people on twitter seem
> to think this is novel, and suddenly you can now do "GIS in R!". They
> seem to have not noticed we've been doing it for the past umpteen
> years with things like gpclib, and lately rgeos.
> 
>  Why use "lawn" instead of "rgeos"? Twitter isn't a good place for
> such discussions, and all I've got out of people there are things like
> "but if you have a geoJSON workflow". I'm not sure that makes sense.
> geoJSON, if you don't know, is the lingua franca of spatial data in JS
> (and is supported by GDAL/OGR). But if you are going to read your data
> into R at some point its going to get converted out of geoJSON into
> native R formats. There's overheads both ways. I've not benchmarked
> any of this yet, but I have a hunch data conversion and interfacing to
> JS is going to be slow compared to native rgeos calculations. The lawn
> package web page seems to concur.
> 
>  Another example of "JS All The Things"  manifested today. The rgbif
> package uses rgeos to read WKT data. But a recent change from the
> author replaced that with some JS code. So now instead of calling
> rgeos::readWKT, this happens:
> 
> read_wkt <- function(wkt) {
> terr$eval(sprintf("var out = terrwktparse.parse('%s');", wkt))
> terr$get("out")
> }
> 
> where `terr` is a handle to the JS code. Again, I've not benchmarked
> it, but there appears to be a lot of string conversion and passing of
> data from one world to another. Plus there's the overhead of loading
> in a completely new language interpreter via a dependency on the V8
> package, compared to loading in some clean C code.
> 
>  So I'm mind-boggled. Why is this happening? Is it just that JS is
> trendy? Is it that there is a surfeit of JS programmers? Is it
> speculative "because I can" development? Should R-spatial data look at
> this as evolution and consider the future of sp classes?
> 
>  Discuss. Maybe its something those of us at the Geostat Summer School
> in August can have a good chat about, although I don't think anyone
> from the JS side of things will be there... Maybe in 2016....
> 
> Barry
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150531/a09dbea0/attachment.bin>

