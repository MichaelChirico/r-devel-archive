From srinivasraghav at gmail.com  Mon Feb  2 09:19:13 2009
From: srinivasraghav at gmail.com (srinivasa raghavan)
Date: Mon, 2 Feb 2009 03:19:13 -0500
Subject: [R-sig-Geo] Personal invitation from srinivasa raghavan
Message-ID: <20090202031913.2107738861@unyk.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090202/bae0d257/attachment.pl>

From c.anwesha at gmail.com  Mon Feb  2 10:38:45 2009
From: c.anwesha at gmail.com (Anwesha Chakrabarti)
Date: Mon, 2 Feb 2009 15:08:45 +0530
Subject: [R-sig-Geo] help
Message-ID: <a28956f70902020138w1cb4c417i36100e199d2c3eb9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090202/ed653da5/attachment.pl>

From r.hijmans at gmail.com  Mon Feb  2 12:10:03 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Mon, 2 Feb 2009 19:10:03 +0800
Subject: [R-sig-Geo] help
In-Reply-To: <a28956f70902020138w1cb4c417i36100e199d2c3eb9@mail.gmail.com>
References: <a28956f70902020138w1cb4c417i36100e199d2c3eb9@mail.gmail.com>
Message-ID: <dc22b2570902020310y326e9a3av8bb6df3b3cb3d6a7@mail.gmail.com>

I think you have to loop over time ( "i"  in your case, which
presumably is a variable in your environment ).

something like:

for (i in 1:length(dat[1,1,])) {
   vz<-as.vector(dat[,,i])
   oz<-interpp(vx,vy,vz,ox,oy,linear=TRUE)
   Kolkata[i]<-oz$z
}



On Mon, Feb 2, 2009 at 5:38 PM, Anwesha Chakrabarti <c.anwesha at gmail.com> wrote:
> hi;
> i just started using R and need to do the following.
> i want to plot weather data (which is in a .netCDF file).
> i was trying to plot some climate data for westbengal region and then i
> tried to interpolate the data for kolkata (which will be a subset of the
> oroginal data for westbengal).
>
> i tried the following commands
> graphics.off()
> library(ncdf)
> library(akima)
> ncdata<-open.ncdf("A2.TREFHT-gis.westbengal.nc")
> lon<-get.var.ncdf(ncdata,"lon")
> lat<-get.var.ncdf(ncdata,"lat")
> time<-get.var.ncdf(ncdata,"time")
> dat <- get.var.ncdf(ncdata,"TREFHT")
> Kolkata <- array(dim=length(time))
>  vx<-as.vector(matrix(lon,nrow=length(lon),ncol=length(lat)))
> vy<-as.vector(matrix(lat,nrow=length(lon),ncol=length(lat),byrow=TRUE))
> vz<-as.vector(dat[,,i])
>  ox<-as.vector(88)
> oy<-as.vector(22)
> oz<-interpp(vx,vy,vz,ox,oy,linear=TRUE)
> Kolkata[i]<-oz$z
>  Kolkata<-Kolkata-273
> plot(Kolkata,type="l")
>
> now the command are working fine but producing the plot for a single day
> only. whereas i want to plot the data for the entire time period and want a
> line diagram.
> so my question is how can i do that? please help.
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From r.hijmans at gmail.com  Mon Feb  2 12:21:30 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Mon, 2 Feb 2009 19:21:30 +0800
Subject: [R-sig-Geo] Vector to raster conversion...
In-Reply-To: <alpine.LRH.2.00.0901301728120.25553@reclus.nhh.no>
References: <49832832.5050406@ucdavis.edu>
	<alpine.LRH.2.00.0901301728120.25553@reclus.nhh.no>
Message-ID: <dc22b2570902020321y1749d84flc1f582f3dc02da40@mail.gmail.com>

Dear Jonathan,

The raster package (under development at R-forge) has pointsToRaster,
linesToRaster and polygonsToRaster. The latter function takes an sp
polygons object and a raster RasterLayer of any resolution. It should
handle polygon holes (if they are flagged as such in the sp polygons
object). Roger pointed out last week that it would be good to compare
the results of the algorithm in raster with that of starspan. Even if
the results were the same, there is a lot to say for a C based
algorithm. Particularly if it can do row by row (or other blocks)
processing at a higher speed. I would be interested in using that in
the raster package and please contact me directly about that if you
wish.

Robert



On Sat, Jan 31, 2009 at 12:43 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Fri, 30 Jan 2009, Jonathan Greenberg wrote:
>
>> Question:
>>
>>  If I have a polygon shapefile, and I want to rasterize each polygon given
>> a certain grid cell resolution, is there a way to do this completely within
>> R?  I'm considering porting our vector<->raster bridge "starspan"
>> (http://starspan.casil.ucdavis.edu/doku/doku.php) to R code, but this is a
>> critical portion of the algorithm.  If the answer is "yes" -- does that
>> answer include "weird" polygons like donuts?
>
> Jonathan,
>
> In principle, the overlay() method in the sp package for "SpatialPolygon"
> and "SpatialPoints" objects, specifically the:
>
> sp:::pointsInSpatialPolygons
>
> function is where to start. The underlying assumption is that raster cell
> support can be cast to cell centre point support. This function first finds
> candidate polygons by testing polygon bounding boxes, then hands off to:
>
> sp:::pointsInPolys2
>
> which calls:
>
> sp:::pointsInPolygons
>
> Here you can see that hole handling at the per-ring stage is attempted, but
> does depend on the imported rings declaring their hole status correctly. It
> is possible to use checkPolygonsHoles() in maptools, but this takes time.
>
> Hope this helps, porting starspans would be very welcome - I guess users at
> the moment use it loose-coupled by reading and writing files.
>
> The overlay methods are open to optimisation (you'll see that bits of
> sp:::pointsInSpatialPolygons moves heavier-lifting out to C).
>
> Roger
>
>>
>> --j
>>
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From etiennebr at gmail.com  Tue Feb  3 16:17:29 2009
From: etiennebr at gmail.com (Etienne Bellemare Racine)
Date: Tue, 03 Feb 2009 10:17:29 -0500
Subject: [R-sig-Geo] Clip a raster
Message-ID: <49886009.9030002@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090203/2bfdbb5b/attachment.pl>

From p.w.van.horssen at buwa.nl  Wed Feb  4 11:21:36 2009
From: p.w.van.horssen at buwa.nl (Peter van Horssen)
Date: Wed, 04 Feb 2009 11:21:36 +0100
Subject: [R-sig-Geo] symbols in spplot
Message-ID: <49896C30.1070903@buwa.nl>

Dear all,

I have a plot problem which is related to the 'contourlines on a plot  
question' from a while ago.

I have a  map with 144 polygons (squares), for each square we calculate 
the mean flight direction (of birds).
What I try to plot is a map with the samplesize as a
greyscale in the polgons and an arrow on top depicting the mean 
direction of that square.
The polygonmap with greyscale is easily plotted with spplot.
The arrows with mean direction are a bit more difficult. Most sources
point towards the 'grid' package or towards arrows(). Both draw arrows
with xy pairs (form > to) in graph coordinates.
However 'mysymbols' in the library TeachingDemos plots a arrow symbol
with a direction 'dir' (in radians) and a fixed length, just what I need.
Unfortunately these arrows only plot with 'plot' command (see attached 
code) and therefore do not allign
with the plot resulting from ssplot. As you can see  the arrows are 
plotted  as a pch 'symbol'.

I tried to construct a 'sp.points' element for the sp.layout
with the my.symbols ( .....) argument but this doesn't work
The arrow.sp$pch is NULL and when I manually force the my.symbol(..) in 
it by :
####
arrow.sp$pch <- 
my.symbols(raster.midpoint$raster.mid.x1,raster.midpoint$raster.mid.x2,ms.arrows, 
angle= Data$rad, inches=0.5, adj=0.5, lwd=1.5, code = 2, col = 'blue')
####
the spplot command generates an error

Question:
is there an obvious solution tot this (relative simple) problem ?
if not, is there a way to 'allign' de plots from spplot and plot (the 
arrowplot) ?



thanks in advance


##plot raster##
radarcirkels.sp <- list("sp.polygons", radarcirkels)
circle2.sp <- list("sp.polygons", circle2, add= TRUE)
turbines.sp <- list("sp.points", turbines, pch=18, add= TRUE, col = red')
metmast.sp <- list("sp.points", metmast, pch = 19, col = 'red', add= TRUE)
turbine.radar.layout <- list(radarcirkels.sp, circle2.sp, turbines.sp, 
metmast.sp)
colors <- shadepalette("darkgreen","white",n=20)
spplot (raster1["n"],col.regions=colors,at=c(0,10,50,100,200,300), 
sp.layout = turbine.radar.layout)

##plot arrows ##
library(TeachingDemos)
plot(raster)
plot(radarcirkels, add=TRUE)
plot(circle2, add= TRUE)
plot(turbines, pch=18, add= TRUE, col = 'red')
plot(metmast, pch = 19, col = 'blue', add= TRUE)
plot(raster,pch=my.symbols(raster.midpoint$raster.mid.x1,raster.midpoint$raster.mid.x2, 

      ms.arrows, angle= Data$rad, inches=0.5, adj=0.5, lwd=1.5, code = 
2, col = 'blue'), add=TRUE)

-- 
================================
Peter van Horssen
Bureau Waardenburg bv
Adviseurs voor ecologie & milieu
Postbus 365
4100 AJ Culemborg
Tel: 0345-512710
Fax: 0345-519849
e-mail: p.w.van.horssen at buwa.nl
================================

---------------------------- DISCLAIMER -------------------------- 
De informatie verzonden met dit e-mail bericht is uitsluitend bestemd voor de geadresseerde. Openbaarmaking, vermenigvuldiging, verspreiding en/of verstrekking aan derden is niet toegestaan. Gebruik van deze informatie door anderen dan de geadresseerde is verboden. U wordt verzocht bij onjuiste adressering de afzender direct te informeren door het bericht te retourneren.



From Roger.Bivand at nhh.no  Wed Feb  4 11:46:49 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 4 Feb 2009 11:46:49 +0100 (CET)
Subject: [R-sig-Geo] symbols in spplot
In-Reply-To: <49896C30.1070903@buwa.nl>
References: <49896C30.1070903@buwa.nl>
Message-ID: <alpine.LRH.2.00.0902041138140.1343@reclus.nhh.no>

On Wed, 4 Feb 2009, Peter van Horssen wrote:

> Dear all,
>
> I have a plot problem which is related to the 'contourlines on a plot 
> question' from a while ago.
>
> I have a  map with 144 polygons (squares), for each square we calculate the 
> mean flight direction (of birds).
> What I try to plot is a map with the samplesize as a
> greyscale in the polgons and an arrow on top depicting the mean direction of 
> that square.
> The polygonmap with greyscale is easily plotted with spplot.
> The arrows with mean direction are a bit more difficult. Most sources
> point towards the 'grid' package or towards arrows(). Both draw arrows
> with xy pairs (form > to) in graph coordinates.
> However 'mysymbols' in the library TeachingDemos plots a arrow symbol
> with a direction 'dir' (in radians) and a fixed length, just what I need.
> Unfortunately these arrows only plot with 'plot' command (see attached code) 
> and therefore do not allign
> with the plot resulting from ssplot. As you can see  the arrows are plotted 
> as a pch 'symbol'.

If you try to use only base graphics, you may find this easier to sort out 
initially - so make the greyscale plot with image() if the data are 
gridded or plot() if irregular polygons - more intervention will be needed 
to choose the colours and to provide a legend, then overplot using 
my.symbols(), which seems to be a base graphics function, if I've found 
the right one. Otherwise you'll need to find a way to draw the arrows by 
for example constructing a SpatialLines object of arrows, and using 
sp.lines in the sp.layout= argument.

Hope this helps,

Roger

>
> I tried to construct a 'sp.points' element for the sp.layout
> with the my.symbols ( .....) argument but this doesn't work
> The arrow.sp$pch is NULL and when I manually force the my.symbol(..) in it by 
> :
> ####
> arrow.sp$pch <- 
> my.symbols(raster.midpoint$raster.mid.x1,raster.midpoint$raster.mid.x2,ms.arrows, 
> angle= Data$rad, inches=0.5, adj=0.5, lwd=1.5, code = 2, col = 'blue')
> ####
> the spplot command generates an error
>
> Question:
> is there an obvious solution tot this (relative simple) problem ?
> if not, is there a way to 'allign' de plots from spplot and plot (the 
> arrowplot) ?
>
>
>
> thanks in advance
>
>
> ##plot raster##
> radarcirkels.sp <- list("sp.polygons", radarcirkels)
> circle2.sp <- list("sp.polygons", circle2, add= TRUE)
> turbines.sp <- list("sp.points", turbines, pch=18, add= TRUE, col = red')
> metmast.sp <- list("sp.points", metmast, pch = 19, col = 'red', add= TRUE)
> turbine.radar.layout <- list(radarcirkels.sp, circle2.sp, turbines.sp, 
> metmast.sp)
> colors <- shadepalette("darkgreen","white",n=20)
> spplot (raster1["n"],col.regions=colors,at=c(0,10,50,100,200,300), sp.layout 
> = turbine.radar.layout)
>
> ##plot arrows ##
> library(TeachingDemos)
> plot(raster)
> plot(radarcirkels, add=TRUE)
> plot(circle2, add= TRUE)
> plot(turbines, pch=18, add= TRUE, col = 'red')
> plot(metmast, pch = 19, col = 'blue', add= TRUE)
> plot(raster,pch=my.symbols(raster.midpoint$raster.mid.x1,raster.midpoint$raster.mid.x2,
>     ms.arrows, angle= Data$rad, inches=0.5, adj=0.5, lwd=1.5, code = 2, col 
> = 'blue'), add=TRUE)
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Wed Feb  4 12:38:32 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 4 Feb 2009 12:38:32 +0100 (CET)
Subject: [R-sig-Geo] Clip a raster
In-Reply-To: <49886009.9030002@gmail.com>
References: <49886009.9030002@gmail.com>
Message-ID: <alpine.LRH.2.00.0902041222430.1343@reclus.nhh.no>

On Tue, 3 Feb 2009, Etienne Bellemare Racine wrote:

> Is it possible to clip a raster after having it read with readGDAL ?
> Instead of using region.dim() and offset(), I would like to clip it "on
> the fly" to visualize statistics associated with objects of different
> size. The clip is square -specified with upper left and lower right
> corners- and fit with the pixels size. If you have an interactive way,
> I'm even more interested.

For an interactive method for a SpatialGrid* object, try:

library(sp)
data(meuse.grid)
coordinates(meuse.grid) <- c("x", "y")
gridded(meuse.grid) <- TRUE
fullgrid(meuse.grid) <- TRUE
bbox(meuse.grid)
image(meuse.grid, "dist", breaks=seq(0,1,0.1), 
col=heat.colors(10))
# interactive choice of rectangle of interest, ll and ur
pts <- locator(2)
pts
points(pts)
grd <- getGridTopology(meuse.grid)
gi <- getGridIndex(coordinates(pts), grd)
cd <- slot(grd, "cells.dim")
ys <- sort(ceiling(gi / cd[1]))
xs <- sort(gi %% cd[1])
meuse_sub <- meuse.grid[ys[1]:ys[2], xs[1]:xs[2]]
bbox(meuse_sub)
image(meuse_sub, "dist", breaks=seq(0,1,0.1), 
col=grey.colors(10),
   add=TRUE)

What you call clipping is the "[" operator here.

Hope this helps,

Roger

>
> Etienne
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From b.rowlingson at lancaster.ac.uk  Wed Feb  4 16:15:33 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 4 Feb 2009 15:15:33 +0000
Subject: [R-sig-Geo] The geonames.org server changed / geonames package
In-Reply-To: <3125260B4A3E4758AFD14F6DA6B87ACA@pcibed193>
References: <Acl9cksZK1ev7yR0R6eQ4I4Rh0a2Fg==>
	<3125260B4A3E4758AFD14F6DA6B87ACA@pcibed193>
Message-ID: <d8ad40b50902040715t27317200r8faae907f491f401@mail.gmail.com>

2009/1/23 Tomislav Hengl <T.Hengl at uva.nl>:

> Just to let you know that geonames.org server changed from "ws.geonames.org" to "ws5.geonames.org"
>
> See the info at: http://www.geonames.org/export/
>
> Maybe you should add to your R package "geonames" an option to specify the server name manually,
> e.g.:
>
> setGNserver <- "ws5.geonames.org"

  I think they've changed it back now, but I added the option to
change it using R's options() function:

 > GNtimezone(32,34)
   rawOffset dstOffset gmtOffset lng lat
 1         2         0         2  34  32
 > options(geonamesHost="ws5.geonames.org")
 > GNtimezone(32,34)
   rawOffset dstOffset gmtOffset lng lat
 1         2         0         2  34  32

to prove it did something:

> options(geonamesHost="wtf.huh")
> GNtimezone(32,34)
Error in url(url, open = "r") : cannot open the connection
In addition: Warning message:
In url(url, open = "r") :
  cannot open: HTTP status was '504 Gateway Time-out'

 It's changed in SVN on r-forge now, that should build a new package
version (0.8) and web page docs overnight.

Barry



From pandit.ram at gmail.com  Wed Feb  4 17:41:58 2009
From: pandit.ram at gmail.com (Ram Pandit)
Date: Wed, 4 Feb 2009 10:41:58 -0600
Subject: [R-sig-Geo] Help to generate diagnostic plots from spatial
	regression
Message-ID: <4ec06e730902040841s781728f1s2883aea87bac9238@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090204/17a514e5/attachment.pl>

From Roger.Bivand at nhh.no  Wed Feb  4 19:02:14 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 4 Feb 2009 19:02:14 +0100 (CET)
Subject: [R-sig-Geo] Help to generate diagnostic plots from spatial
 regression
In-Reply-To: <4ec06e730902040841s781728f1s2883aea87bac9238@mail.gmail.com>
References: <4ec06e730902040841s781728f1s2883aea87bac9238@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0902041857350.1343@reclus.nhh.no>

On Wed, 4 Feb 2009, Ram Pandit wrote:

> Dear all,
>
> Pardon me for my limited knowledge in R.  I am trying to generate the plot
> of fitted value vs. residual from a spatial regression like in ordinary
> regression, if possible.  I tried the followings but did not get what I want
> (different diagnostic plots that can be generated by plot() in linear
> regression). Any hints will be appreciated.
>
>> library(spdep)
> fit1<-lagsarlm(y~x1+x2+x3,data=data1,weight file,zero.policy=TRUE)
> # I defined the appropriate data file and weight file
> summary(fit1)
> library(car)
> plot(fit1)
> # it gives me following error
> Error in plot.window(...) : need finite 'xlim' values
> In addition: Warning messages:
> 1: In min(x) : no non-missing arguments to min; returning Inf
> 2: In max(x) : no non-missing arguments to max; returning -Inf
> 3: In min(x) : no non-missing arguments to min; returning Inf
> 4: In max(x) : no non-missing arguments to max; returning -Inf
> # when I do-
> plot(fit1$fit, fit1$res)
> # it gives the plot of fit1$fit vs. Index ( i guess the observation number)

There is no plot() method for an object of class "sarlm", so you get sent 
to the default method. For what it's worth, you could try:

plot(fit1$lm.target)

which will use the correct method, but disregarding the spatial 
coefficient and using an inappropriate hat matrix. There is a paper by 
Haining describing diagnostic plots for spatial regression models, but 
no-one has implemented them.

Roger

>
> Thank you.
>
> Ram Pandit
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From r.hijmans at gmail.com  Thu Feb  5 10:16:26 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Thu, 5 Feb 2009 17:16:26 +0800
Subject: [R-sig-Geo] Clip a raster
In-Reply-To: <alpine.LRH.2.00.0902041222430.1343@reclus.nhh.no>
References: <49886009.9030002@gmail.com>
	<alpine.LRH.2.00.0902041222430.1343@reclus.nhh.no>
Message-ID: <dc22b2570902050116u767fa873pc93755f69c7e4ae9@mail.gmail.com>

Etienne,

I added a function "clickBbox" to the raster package for increased interactivity

#install.packages("raster", repos="http://R-Forge.R-project.org")
require(raster)

# read a raster file from disk
filename <- system.file("pictures/Rlogo.jpg", package="rgdal")
r <- rasterFromFile(filename, TRUE)
plot(r)

# If you want, for example, the mean of the values of the clipped area,
# use the below click on the image (map) twice to create a rectangle

mean( crop(r, clickBbox())[] )


Best, Robert


On Wed, Feb 4, 2009 at 7:38 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Tue, 3 Feb 2009, Etienne Bellemare Racine wrote:
>
>> Is it possible to clip a raster after having it read with readGDAL ?
>> Instead of using region.dim() and offset(), I would like to clip it "on
>> the fly" to visualize statistics associated with objects of different
>> size. The clip is square -specified with upper left and lower right
>> corners- and fit with the pixels size. If you have an interactive way,
>> I'm even more interested.
>
> For an interactive method for a SpatialGrid* object, try:
>
> library(sp)
> data(meuse.grid)
> coordinates(meuse.grid) <- c("x", "y")
> gridded(meuse.grid) <- TRUE
> fullgrid(meuse.grid) <- TRUE
> bbox(meuse.grid)
> image(meuse.grid, "dist", breaks=seq(0,1,0.1), col=heat.colors(10))
> # interactive choice of rectangle of interest, ll and ur
> pts <- locator(2)
> pts
> points(pts)
> grd <- getGridTopology(meuse.grid)
> gi <- getGridIndex(coordinates(pts), grd)
> cd <- slot(grd, "cells.dim")
> ys <- sort(ceiling(gi / cd[1]))
> xs <- sort(gi %% cd[1])
> meuse_sub <- meuse.grid[ys[1]:ys[2], xs[1]:xs[2]]
> bbox(meuse_sub)
> image(meuse_sub, "dist", breaks=seq(0,1,0.1), col=grey.colors(10),
>  add=TRUE)
>
> What you call clipping is the "[" operator here.
>
> Hope this helps,
>
> Roger
>
>>
>> Etienne
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From p.w.van.horssen at buwa.nl  Thu Feb  5 10:37:17 2009
From: p.w.van.horssen at buwa.nl (Peter van Horssen)
Date: Thu, 05 Feb 2009 10:37:17 +0100
Subject: [R-sig-Geo] symbols in spplot
In-Reply-To: <alpine.LRH.2.00.0902041138140.1343@reclus.nhh.no>
References: <49896C30.1070903@buwa.nl>
	<alpine.LRH.2.00.0902041138140.1343@reclus.nhh.no>
Message-ID: <498AB34D.4090408@buwa.nl>

Thanks Roger,

your trick worked, reworking the polygon data to a raster and plotting 
the file with image()
and then plotting the rest with plot(...., add=TRUE) works great (see 
attached code).
It shows that the famous KISS principle (keep is simple, stupid ) also 
applies to plotting maps
in R .......

Peter

## code
image(rasterdata["n"], col=colors)
plot(radarcirkels, add=TRUE)
plot(circle2, add= TRUE)
plot(turbines, pch=18, add= TRUE, col = 'red')
plot(metmast, pch = 19, col = 'blue', add= TRUE)
plot(raster,pch=my.symbols(raster.midpoint$raster.mid.x1,raster.midpoint$raster.mid.x2,
      ms.arrows, angle= Data$rad, inches=0.5, adj=0.5, lwd=1.5, code = 
2, col = 'blue'), lty="blank",
    add=TRUE)
##code

Roger Bivand schreef:
> On Wed, 4 Feb 2009, Peter van Horssen wrote:
>
>> Dear all,
>>
>> I have a plot problem which is related to the 'contourlines on a plot 
>> question' from a while ago.
>>
>> I have a  map with 144 polygons (squares), for each square we 
>> calculate the mean flight direction (of birds).
>> What I try to plot is a map with the samplesize as a
>> greyscale in the polgons and an arrow on top depicting the mean 
>> direction of that square.
>> The polygonmap with greyscale is easily plotted with spplot.
>> The arrows with mean direction are a bit more difficult. Most sources
>> point towards the 'grid' package or towards arrows(). Both draw arrows
>> with xy pairs (form > to) in graph coordinates.
>> However 'mysymbols' in the library TeachingDemos plots a arrow symbol
>> with a direction 'dir' (in radians) and a fixed length, just what I 
>> need.
>> Unfortunately these arrows only plot with 'plot' command (see 
>> attached code) and therefore do not allign
>> with the plot resulting from ssplot. As you can see  the arrows are 
>> plotted as a pch 'symbol'.
>
> If you try to use only base graphics, you may find this easier to sort 
> out initially - so make the greyscale plot with image() if the data 
> are gridded or plot() if irregular polygons - more intervention will 
> be needed to choose the colours and to provide a legend, then overplot 
> using my.symbols(), which seems to be a base graphics function, if 
> I've found the right one. Otherwise you'll need to find a way to draw 
> the arrows by for example constructing a SpatialLines object of 
> arrows, and using sp.lines in the sp.layout= argument.
>
> Hope this helps,
>
> Roger
>
>>
>> I tried to construct a 'sp.points' element for the sp.layout
>> with the my.symbols ( .....) argument but this doesn't work
>> The arrow.sp$pch is NULL and when I manually force the my.symbol(..) 
>> in it by :
>> ####
>> arrow.sp$pch <- 
>> my.symbols(raster.midpoint$raster.mid.x1,raster.midpoint$raster.mid.x2,ms.arrows, 
>> angle= Data$rad, inches=0.5, adj=0.5, lwd=1.5, code = 2, col = 'blue')
>> ####
>> the spplot command generates an error
>>
>> Question:
>> is there an obvious solution tot this (relative simple) problem ?
>> if not, is there a way to 'allign' de plots from spplot and plot (the 
>> arrowplot) ?
>>
>>
>>
>> thanks in advance
>>
>>
>> ##plot raster##
>> radarcirkels.sp <- list("sp.polygons", radarcirkels)
>> circle2.sp <- list("sp.polygons", circle2, add= TRUE)
>> turbines.sp <- list("sp.points", turbines, pch=18, add= TRUE, col = 
>> red')
>> metmast.sp <- list("sp.points", metmast, pch = 19, col = 'red', add= 
>> TRUE)
>> turbine.radar.layout <- list(radarcirkels.sp, circle2.sp, 
>> turbines.sp, metmast.sp)
>> colors <- shadepalette("darkgreen","white",n=20)
>> spplot (raster1["n"],col.regions=colors,at=c(0,10,50,100,200,300), 
>> sp.layout = turbine.radar.layout)
>>
>> ##plot arrows ##
>> library(TeachingDemos)
>> plot(raster)
>> plot(radarcirkels, add=TRUE)
>> plot(circle2, add= TRUE)
>> plot(turbines, pch=18, add= TRUE, col = 'red')
>> plot(metmast, pch = 19, col = 'blue', add= TRUE)
>> plot(raster,pch=my.symbols(raster.midpoint$raster.mid.x1,raster.midpoint$raster.mid.x2, 
>>
>>     ms.arrows, angle= Data$rad, inches=0.5, adj=0.5, lwd=1.5, code = 
>> 2, col = 'blue'), add=TRUE)
>>
>>
>


-- 
================================
Peter van Horssen
Bureau Waardenburg bv
Adviseurs voor ecologie & milieu
Postbus 365
4100 AJ Culemborg
Tel: 0345-512710
Fax: 0345-519849
e-mail: p.w.van.horssen at buwa.nl
================================

---------------------------- DISCLAIMER -------------------------- 
De informatie verzonden met dit e-mail bericht is uitsluitend bestemd voor de geadresseerde. Openbaarmaking, vermenigvuldiging, verspreiding en/of verstrekking aan derden is niet toegestaan. Gebruik van deze informatie door anderen dan de geadresseerde is verboden. U wordt verzocht bij onjuiste adressering de afzender direct te informeren door het bericht te retourneren.



From tord.snall at ekol.slu.se  Thu Feb  5 11:16:42 2009
From: tord.snall at ekol.slu.se (=?ISO-8859-1?Q?Tord_Sn=E4ll?=)
Date: Thu, 05 Feb 2009 11:16:42 +0100
Subject: [R-sig-Geo] ArcView shape files and GeoBUGS
Message-ID: <498ABC8A.4090804@ekol.slu.se>

Dear all,
I would like to read in ArcView (or ArcGIS) shape files from which I 
will pick information if fitting a geostatistical model using WinBUGS. 
In the GeoBUGS Used Manual it says
"GeoBUGS does not have an option for loading ArcView shape files 
directly. However, Ms Yue Cui at the University of Minnesota has written 
programs in Splus and R for converting shape files into the GeoBUGS 
Splus format so that they can be loaded in GeoBUGS 
(http://www.biostat.umn.edu/~yuecui/). "

Unfortunately this site is unavailable, and the Biostatstics homepage at 
University of Minnesota does not say anything about neither BUGS nor Ms 
Yue Cui.

Does anyone know whether this code has been included in any R library, 
or does anyone know how to get in touch with Ms Yue Cui? I find some old 
questions about this is the archive, but at that time no one seemed to 
know about this.

Thanks,
Tord

-- 

Tord Sn?ll
Department of Ecology
Swedish University of Agricultural Sciences (SLU)
P.O. 7044, SE-750 07 Uppsala, Sweden
Office/Mobile/Fax
+46-18-672612/+46-76-7662612/+46-18-673537
E-mail: tord.snall at ekol.slu.se 
www.ekol.slu.se/staff_tordsnall



From r.hijmans at gmail.com  Thu Feb  5 13:12:19 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Thu, 5 Feb 2009 20:12:19 +0800
Subject: [R-sig-Geo] ArcView shape files and GeoBUGS
In-Reply-To: <498ABC8A.4090804@ekol.slu.se>
References: <498ABC8A.4090804@ekol.slu.se>
Message-ID: <dc22b2570902050412q10981cffgd76614b4a1c33d15@mail.gmail.com>

I think this is it:
http://www.biostat.umn.edu/~brad/yuecui/index.html
http://www.biostat.umn.edu/~brad/yuecui/convert.r



#/09/23/03 The only different btw this convert.r and convert.s is that
#in convert.s, we us AsciiToInt("character")-AsciiToInt("0") to change
#character into numeric, in convert.r, we use type.convert("character")
#to do this.

#/09/23/03
#This version of convert.s corrects the problems found in convert2&3.s

#Tried every combination of options for scan, the following doesn't work.
#checking by comparing the number of observations in fortest and in .cgm file
#fortest<-scan("test.cgm",what=list(name=""),widths=c(90),multi.line=F,sep="\n")
#source("convert.r")

convert<-function(cgmfile)
  {
#outfile <- "test.txt"
 outfile<-paste(cgmfile,".txt",sep="")

#This one works
#fortest<-scan("test.cgm",what=list(name=""),sep="\n")
 fortest<-scan(paste(cgmfile,".cgm",sep=""),what=list(name=""),sep="\n")

fortest<-fortest$name
fortest<-fortest[grep("VIS",fortest)]
fortest<-as.matrix(fortest)

totpolyn<-length(fortest[grep("POLYGON_SET",fortest)])

polyn<-0
count<-0;
indicator<-0;
#First tried rep(0,1000), but there is a polygon with 167 rows, so we get
#167*3*2=1002 coordinates in one polygon. Error occurs with NA output
coord<-rep(0,5000)

write(paste("map:",totpolyn,"\n"),outfile)
for (i in 1:totpolyn) {
    write(paste( i, paste("grid",i,sep="")),outfile,append=T)
  }


for (i in 1:length(fortest)){
  for(j in (1:nchar(fortest[i]))){
      letter<-substring(fortest[i],j,j)
      #At first try to use AsciiToInt,stupid
      #if (AsciiToInt(letter)<=AsciiToInt("9")&
      #    AsciiToInt(letter)>=AsciiToInt("0"))
      if(letter<="9"&letter>="0"){
                         if (indicator==0) {count<-count+1;
                                            indicator<- 1
                                         }
                            coord[count]<-coord[count]*10+
                                 type.convert(letter)
                                 }
      #add the following else if statement because if and only when
      #a POLYGON_SET is encounted, polyn is increased by 1
      else if (letter=="P"){ polyn<-polyn+1;indicator<-0}

      #a CLOSEVIS is encounted, output the coordinates set, this is
      #done independently with increase of polyn since a POLYGON_SET may
      #consist of several small polygons
      else if(letter=="C"){
        coordmat<-cbind(rep(paste("grid",polyn,sep=""),count/2),
                        coord[2*(1:(count/2))-1],
                        coord[2*(1:(count/2))])

        if (polyn == 1) { write("",outfile,append=T)}
        else            { write(c(NA,NA,NA),outfile,append=T)}
        write(t(coordmat),outfile,append=T,ncol=3)
        #polyn<-polyn+1
        #the above statement is not right because 2 CLOSEVIS may lie in one
        #same polygon, but we output a polygon coordinates set whenever a
        #CLOSEVIS is encountered, although it may have the same label,
        #denoted by "grid&polyn" with previous or next coordinate sets.

        count<-0
        indicator<-0
        coord<-rep(0,5000)
        #if(grep("\r",substring(fortest[i],j+1,nchar(fortest[i]))))
        #break
       }

      else        indicator<-0
   }
}
write("END",outfile,append=T)
}



On Thu, Feb 5, 2009 at 6:16 PM, Tord Sn?ll <tord.snall at ekol.slu.se> wrote:
> Dear all,
> I would like to read in ArcView (or ArcGIS) shape files from which I will
> pick information if fitting a geostatistical model using WinBUGS. In the
> GeoBUGS Used Manual it says
> "GeoBUGS does not have an option for loading ArcView shape files directly.
> However, Ms Yue Cui at the University of Minnesota has written programs in
> Splus and R for converting shape files into the GeoBUGS Splus format so that
> they can be loaded in GeoBUGS (http://www.biostat.umn.edu/~yuecui/). "
>
> Unfortunately this site is unavailable, and the Biostatstics homepage at
> University of Minnesota does not say anything about neither BUGS nor Ms Yue
> Cui.
>
> Does anyone know whether this code has been included in any R library, or
> does anyone know how to get in touch with Ms Yue Cui? I find some old
> questions about this is the archive, but at that time no one seemed to know
> about this.
>
> Thanks,
> Tord
>
> --
>
> Tord Sn?ll
> Department of Ecology
> Swedish University of Agricultural Sciences (SLU)
> P.O. 7044, SE-750 07 Uppsala, Sweden
> Office/Mobile/Fax
> +46-18-672612/+46-76-7662612/+46-18-673537
> E-mail: tord.snall at ekol.slu.se www.ekol.slu.se/staff_tordsnall
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From tord.snall at ekol.slu.se  Thu Feb  5 14:56:35 2009
From: tord.snall at ekol.slu.se (=?ISO-8859-1?Q?Tord_Sn=E4ll?=)
Date: Thu, 05 Feb 2009 14:56:35 +0100
Subject: [R-sig-Geo] Summary: ArcView shape files and GeoBUGS
In-Reply-To: <498AB859.9090806@ekol.slu.se>
References: <498AB859.9090806@ekol.slu.se>
Message-ID: <498AF013.3090803@ekol.slu.se>

Thanks to you all for prompt replies!

As evident from the replies pasted below there are different solutions 
to this problem.

cheers,
Tord

------------------------------------------------------------------------------
"There are some tools avaiable to transform maps to \pkg{GeoBUGS}
format: the function \code{sp2WB} of package \pkg{maptools} can
transform \code{SpatialPolygons} object to the S-Plus mapin \pkg{R}
\citep{R}, or the ArcGIS extension of W. Thogmartin and colleagues what
helps users to develop adjacency
matrice.\footnote{http://www.umesc.usgs.gov/management/dss/adjacency
\_tool.html}."

my tool (maps2winbugs) has other functions as well to prepare maps for
geobugs
unfortunately it works just on MS Windows

Also:
http://maps2winbugs.sourceforge.net/

all the best
Norbert

------------------------------------------------------------------------------ 


If you are using R, you can use the function sp2WB in maptools to
convert your data into a format that WB can import from a shapefile.
Look at the manual page of sp2WB.

Hope this helps,

Virgilio

P.S: THis is the example in that manual page:

 xx <- readShapePoly(system.file("shapes/sids.shp",
package="maptools")[1],
      IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
     plot(xx, border="blue", axes=TRUE, las=1)
     sp2WB(as(xx, "SpatialPolygons"), filename="NC.map")
     x <- readAsciiGrid(system.file("grids/test.ag",
package="maptools")[1])
     xp <- as(x, "SpatialPixelsDataFrame")
     pp <- as.SpatialPolygons.SpatialPixels(xp)
     sp2WB(pp, filename="test.map")

------------------------------------------------------------------------------ 


Tord. Have found the easiest way to address this issue is to read the shape
files into R, then convert them into splus format, which bugs will import.
Following is the code:

library(maptools) # loads sp library too
library(maps)

# read in shape files (single folder with all associated files, no
extension)
x<-readShapePoly("C:\\xxx\\xxx\\xx\\")
# display the shapefile
plot(x) 
# convert the shape file into splus format to import into GeoBugs
sp2WB(x, "C:\\xxx\\xxxx\\xxxx\\xxxx.txt") # note '.txt' extension

Cheers
Charles

------------------------------------------------------------------------------ 

Dear Tord,

You can use R to convert a shapefile into a format readable from 
GeoBUGS. There are several R packages to handle geographical 
information. An easy way to convert a .shp file into what GeoBUGS refers 
to as SPLUS format  could be:

1) Load library maptools in R
library(maptools)

2) Import the shapefile into R:
object.shp <- readShapePoly("C:/mydir/myshapefile.shp", IDvar="area_id")

3) Export it in Splus format
sp2WB(as(object.shp, "SpatialPolygons"), filename="myname.txt")

Hope this helps.
Juanjo
------------------------------------------------------------------------------ 

Hi, I had the same problem and one solution is download the program 
maps2WinBUGS is free or you can look the libraries maps and maptools in 
R  the maptools package allows the importation of ArcView shape files to 
R (readShapePoly function) and also the export of maps to WinBUGS format 
with the function sp2WB. Both spatstat and splancs have functionality 
for mapping point process data.
Chao.
------------------------------------------------------------------------------ 


Dear Tord,

Look at the example in the manual page of function sp2WB (package
maptools). I believe that it is what you need.

Hope this helps.
Virgilio

------------------------------------------------------------------------------ 


I think this is it:
http://www.biostat.umn.edu/~brad/yuecui/index.html
http://www.biostat.umn.edu/~brad/yuecui/convert.r


#/09/23/03 The only different btw this convert.r and convert.s is that
#in convert.s, we us AsciiToInt("character")-AsciiToInt("0") to change
#character into numeric, in convert.r, we use type.convert("character")
#to do this.

#/09/23/03
#This version of convert.s corrects the problems found in convert2&3.s

#Tried every combination of options for scan, the following doesn't work.
#checking by comparing the number of observations in fortest and in .cgm file
#fortest<-scan("test.cgm",what=list(name=""),widths=c(90),multi.line=F,sep="\n")
#source("convert.r")

convert<-function(cgmfile)
  {
#outfile <- "test.txt"
 outfile<-paste(cgmfile,".txt",sep="")

#This one works
#fortest<-scan("test.cgm",what=list(name=""),sep="\n")
 fortest<-scan(paste(cgmfile,".cgm",sep=""),what=list(name=""),sep="\n")

fortest<-fortest$name
fortest<-fortest[grep("VIS",fortest)]
fortest<-as.matrix(fortest)

totpolyn<-length(fortest[grep("POLYGON_SET",fortest)])

polyn<-0
count<-0;
indicator<-0;
#First tried rep(0,1000), but there is a polygon with 167 rows, so we get
#167*3*2=1002 coordinates in one polygon. Error occurs with NA output
coord<-rep(0,5000)

write(paste("map:",totpolyn,"\n"),outfile)
for (i in 1:totpolyn) {
    write(paste( i, paste("grid",i,sep="")),outfile,append=T)
  }


for (i in 1:length(fortest)){
  for(j in (1:nchar(fortest[i]))){
      letter<-substring(fortest[i],j,j)
      #At first try to use AsciiToInt,stupid
      #if (AsciiToInt(letter)<=AsciiToInt("9")&
      #    AsciiToInt(letter)>=AsciiToInt("0"))
      if(letter<="9"&letter>="0"){
                         if (indicator==0) {count<-count+1;
                                            indicator<- 1
                                         }
                            coord[count]<-coord[count]*10+
                                 type.convert(letter)
                                 }
      #add the following else if statement because if and only when
      #a POLYGON_SET is encounted, polyn is increased by 1
      else if (letter=="P"){ polyn<-polyn+1;indicator<-0}

      #a CLOSEVIS is encounted, output the coordinates set, this is
      #done independently with increase of polyn since a POLYGON_SET may
      #consist of several small polygons
      else if(letter=="C"){
        coordmat<-cbind(rep(paste("grid",polyn,sep=""),count/2),
                        coord[2*(1:(count/2))-1],
                        coord[2*(1:(count/2))])

        if (polyn == 1) { write("",outfile,append=T)}
        else            { write(c(NA,NA,NA),outfile,append=T)}
        write(t(coordmat),outfile,append=T,ncol=3)
        #polyn<-polyn+1
        #the above statement is not right because 2 CLOSEVIS may lie in one
        #same polygon, but we output a polygon coordinates set whenever a
        #CLOSEVIS is encountered, although it may have the same label,
        #denoted by "grid&polyn" with previous or next coordinate sets.

        count<-0
        indicator<-0
        coord<-rep(0,5000)
        #if(grep("\r",substring(fortest[i],j+1,nchar(fortest[i]))))
        #break
       }

      else        indicator<-0
   }
}
write("END",outfile,append=T)
}
------------------------------------------------------------------------------
Hi Tord,

I think you will find the extract you require in this paper
https://beardocs.baylor.edu/bitstream/2104/3955/1/john_mcbride_phd.pdf

Search the document for Yue Cui and it will bring you to the page.

I have used the code myself and it does work.

Hope it helps.  

Karen
------------------------------------------------------------------------------
I believe that you are would like to convert a shapefile
into a BUGS map, correct?  If so, download maps2WinBugs and follow the tutorial
on how to do so. Just Google the program and it will pop right up.

Erinn

------------------------------------------------------------------------------



Tord Sn?ll wrote:
> Dear all,
> I would like to read in ArcView (or ArcGIS) shape files from which I 
> will pick information if fitting a geostatistical model using WinBUGS. 
> In the GeoBUGS Used Manual it says
> "GeoBUGS does not have an option for loading ArcView shape files 
> directly. However, Ms Yue Cui at the University of Minnesota has 
> written programs in Splus and R for converting shape files into the 
> GeoBUGS Splus format so that they can be loaded in GeoBUGS 
> (http://www.biostat.umn.edu/~yuecui/). "
>
> Unfortunately this site is unavailable, and the Biostatstics homepage 
> at University of Minnesota does not say anything about neither BUGS or 
> Ms Yue Cui.
>
> Does anyone have this R code, or can point me to Ms Yue Cui?
>
> Thanks,
> Tord
>

-- 

Tord Sn?ll
Department of Ecology / Swedish Species Information Centre
Swedish University of Agricultural Sciences (SLU)
P.O. 7044, SE-750 07 Uppsala, Sweden
Office/Mobile/Fax
+46-18-672612/+46-76-7662612/+46-18-673537
E-mail: tord.snall at ekol.slu.se 
www.ekol.slu.se/staff_tordsnall
www.artdata.slu.se/personal/fototsn.asp



From Roger.Bivand at nhh.no  Thu Feb  5 18:59:18 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 5 Feb 2009 18:59:18 +0100 (CET)
Subject: [R-sig-Geo] Summary: ArcView shape files and GeoBUGS
In-Reply-To: <498AF013.3090803@ekol.slu.se>
References: <498AB859.9090806@ekol.slu.se> <498AF013.3090803@ekol.slu.se>
Message-ID: <alpine.LRH.2.00.0902051854140.23121@reclus.nhh.no>

On Thu, 5 Feb 2009, Tord Sn?ll wrote:

> Thanks to you all for prompt replies!
>
> As evident from the replies pasted below there are different solutions to 
> this problem.
>
> cheers,
> Tord
>

Thanks for a very full summary, keeping the threaded information together. 
Just two more comments - the next release of maptools will also have a 
readSplus() function contributed by Virgilio G?mez Rubio to read maps 
exported from WinBUGS into a SpatialPolygons object. Also, if the goal is 
to create spatial weights in WinBUGS, you can export listw and nb objects 
from spdep using listw2WB() and nb2WB(), maybe removing the need for 
importing the map, having created the weights using one of the variants 
in spdep.

Roger

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From hzambran.newsgroups at gmail.com  Thu Feb  5 20:12:37 2009
From: hzambran.newsgroups at gmail.com (Mauricio Zambrano)
Date: Thu, 5 Feb 2009 20:12:37 +0100
Subject: [R-sig-Geo] krige problem: IDW + irregular blocks
Message-ID: <63d616b0902051112v6db14648ta0169ef681ec35c8@mail.gmail.com>

Dear List,

I need to carry out an IDW interpolation of precipitation values
within a basin. I want to obtain the mean value in each one of the
subcatchments, which are defined as polygons in a shapefile.

I would like to know:

How can I transform the subcatchments polygons (class
"SpatialPolygonsDataFrame" ) into a "data.frame" that can be used by
the "block" parameter of the "krige" function ?

So far, I've tried:

1) SubCatchments.shp <- readShapePoly(SubCatchmentsShp.fname, proj4string=p4s)
2) centroids <- coordinates(SubCatchments.shp)
3) pp.idw.block <- krige(value~1, locations=centroids, block=SubCatchments.shp)

Steps 1 and 2 are ok, but in step 3 I get the error:

Error en function (classes, fdef, mtable)  :
  unable to find an inherited method for function "krige", for
signature "formula", "matrix"

because "SubCatchments.shp" class is "SpatialPolygonsDataFrame' and
not 'data.frame'


Any help will be appreciated.

Thanks in advance,

Mauricio
-- 
?=============================================
Linux user #454569 -- Ubuntu user #17469
=============================================?
"A journey of a thousand miles
begins with a single step"
(Lao Tse)



From hzambran.newsgroups at gmail.com  Fri Feb  6 13:08:15 2009
From: hzambran.newsgroups at gmail.com (Mauricio Zambrano)
Date: Fri, 6 Feb 2009 13:08:15 +0100
Subject: [R-sig-Geo] IDW + irregular blocks: Different results for different
	approaches ?
Message-ID: <63d616b0902060408j35838256xbbba2be282504749@mail.gmail.com>

Dear list,

Trying to find out a solution for obtaining the mean of interpolated
values within several polygons I found 2 ways for solving it, but the
results are slightly different:

Using the meuse dataset and a gstat example:

r1 = cbind(c(180114, 180553, 181127, 181477, 181294, 181007, 180409,
180162, 180114), c(332349, 332057, 332342, 333250, 333558, 333676,
332618, 332413, 332349))
r2 = cbind(c(180042, 180545, 180553, 180314, 179955, 179142, 179437,
179524, 179979, 180042), c(332373, 332026, 331426, 330889, 330683,
331133, 331623, 332152, 332357, 332373))
r3 = cbind(c(179110, 179907, 180433, 180712, 180752, 180329, 179875,
179668, 179572, 179269, 178879, 178600, 178544, 179046, 179110),
c(331086, 330620, 330494, 330265, 330075, 330233, 330336, 330004,
329783, 329665, 329720, 329933, 330478, 331062, 331086))

sr1=Polygons(list(Polygon(r1)),"r1")
sr2=Polygons(list(Polygon(r2)),"r2")
sr3=Polygons(list(Polygon(r3)),"r3")
sr=SpatialPolygons(list(sr1,sr2,sr3))
srdf=SpatialPolygonsDataFrame(sr, data.frame(cbind(1:3,5:3),
row.names=c("r1","r2","r3")))

data(meuse)
coordinates(meuse) = ~x+y
data(meuse.grid)
coordinates(meuse.grid) = ~x+y
gridded(meuse.grid) = TRUE


# 1st Approach: Interpolating with IDW using the 'mueuse.grid' as
'newdata' and then 'overlay'

x.idw <- krige(log(zinc)~1, locations=meuse, newdata=meuse.grid)
# Getting the mean values in each polygon
overlay(x.idw["var1.pred"], srdf, fn = mean)

# var1.pred
#X1    5.8697
#X2    5.6525
#X3    5.8536

# 2nd Approach: Interpolating with IDW using the 3 polygons as 'newdata'

x.idw.block <- krige(log(zinc)~1, locations=meuse, newdata=srdf )
# Getting the mean values in each polygon
x.idw.block["var1.pred"]@data

#var1.pred
#r1    5.9090
#r2    5.6700
#r3    5.8564


I would really appreciate if you can give some hint about why the
results are different for each polygon.

Thanks in advance,

Mauricio

-- 
?=============================================
Linux user #454569 -- Ubuntu user #17469
=============================================?
"A journey of a thousand miles
begins with a single step"
(Lao Tse)



From ba208 at exeter.ac.uk  Fri Feb  6 20:37:51 2009
From: ba208 at exeter.ac.uk (baptiste auguie)
Date: Fri, 6 Feb 2009 19:37:51 +0000
Subject: [R-sig-Geo] basic rgl plotting question
Message-ID: <516D1664-2039-4E96-8554-3B87E04CE5AD@exeter.ac.uk>

Dear all,

I hope this is a good place for this question, i usually post on R-help.

I'm trying to visualize spherical harmonics on a sphere using the rgl  
package. I created a function that generates a data.frame of the format,

         x y       z     col
1 0.00000 0 1.00000 0.50000
2 0.10629 0 0.99433 0.65709
3 0.21138 0 0.97740 0.79829
4 0.31408 0 0.94940 0.90930
5 0.41321 0 0.91063 0.97888
6 0.50767 0 0.86155 1.00000
...

I've tried to plot the surface of the sphere defined by the x y z grid  
with colors defined by col. So far, my best shot is quite ugly (using  
spheres3d and one color only). Here's my code,


require(orthopolynom) # needed for the legendre polynomials
library(rgl)

sphericalHarmonics <- function(l, m, theta=seq(0, 2*pi, length=10),  
phi=seq(0, pi, length=10)){
	
	Pl <- lapply(legendre.polynomials(l), as.function)
	Pl.phi <- lapply(Pl, do.call, list(x=cos(phi)))
	
a1 <- (2*l+1) / (4*pi)
a2 <- factorial(l-m) / factorial(l+m)

Ymn <- as.data.frame(sapply(Pl.phi, "*",  e2=sqrt(a1*a2) *  
exp(1i*m*theta)))
names(Ymn) <- paste("l", seq(1, l+1), sep="")
return(Ymn)
}

sphericalHarmonics(1, 1) # OK this works

theta.phi <- expand.grid(theta=seq(0, 2*pi, length=60), phi=seq(0, pi,  
length=30)) # generates a uniform polar grid

ylm <- sphericalHarmonics(3, 3, theta.phi$theta, theta.phi$phi)

spherical2cartesian <- function(tp, r=1){
	with(tp, data.frame(
	x =  r * sin(theta) * cos(phi),
	y = r * sin(theta) * sin(phi),
	z = r * cos(theta) )	)
}

xyz <- spherical2cartesian(theta.phi) # polar to cartesian

mdf <- data.frame(xyz, ylm)

# draw shperes in an rgl window
mdf <- within(mdf, col  <- Im(l3))
mdf$col <- (mdf$col + abs(min(mdf$col)) )
mdf$col <- mdf$col/max(mdf$col)

with(mdf, spheres3d(x, y, z, radius=3,  color=rgb(col, 0, 0)))

Any advice would be gratefully appreciated!

Baptiste

_____________________________

Baptiste Augui?

School of Physics
University of Exeter
Stocker Road,
Exeter, Devon,
EX4 4QL, UK

Phone: +44 1392 264187

http://newton.ex.ac.uk/research/emag



From yong.li at unimelb.edu.au  Sun Feb  8 07:58:18 2009
From: yong.li at unimelb.edu.au (Yong Li)
Date: Sun, 08 Feb 2009 17:58:18 +1100
Subject: [R-sig-Geo] Interpolcation option: IDW or OK?
In-Reply-To: <mailman.11.1233918003.17036.r-sig-geo@stat.math.ethz.ch>
Message-ID: <86DBA0678E017341B449A62F258E29561549C2@IS-EX-BEV3.unimelb.edu.au>

Hi ALL,

I have been with the attached dataset and R code to use OK to
interpolate soil OLSEN P spatial distribution for a couple of weeks. So
far I have not found a satisfactory solution using OK or local OK or
block OK, compared to IDW method. However theoretically OK is always
better than IDW as also a journal editor advised me in my submitted
manuscript.

Normally if we do not find a significant spatial structure for a soil
variable, we may choose IDW or other methods. How is your guys' opinion
on this or may you help me to find a better solution using OK with my
dataset?
I appreciate any help.

Regards

Yong Li
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Ordinary_Kriging_yongji.r
Type: application/octet-stream
Size: 6045 bytes
Desc: Ordinary_Kriging_yongji.r
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090208/43e3d06d/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: yongji2000-GK.csv
Type: application/octet-stream
Size: 70441 bytes
Desc: yongji2000-GK.csv
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090208/43e3d06d/attachment-0001.obj>

From edzer.pebesma at uni-muenster.de  Sun Feb  8 23:40:52 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 08 Feb 2009 23:40:52 +0100
Subject: [R-sig-Geo] Interpolcation option: IDW or OK?
In-Reply-To: <86DBA0678E017341B449A62F258E29561549C2@IS-EX-BEV3.unimelb.edu.au>
References: <86DBA0678E017341B449A62F258E29561549C2@IS-EX-BEV3.unimelb.edu.au>
Message-ID: <498F5F74.5060207@uni-muenster.de>

Yong Li wrote:
> Hi ALL,
>
> I have been with the attached dataset and R code to use OK to
> interpolate soil OLSEN P spatial distribution for a couple of weeks. So
> far I have not found a satisfactory solution using OK or local OK or
> block OK, compared to IDW method. However theoretically OK is always
> better than IDW as also a journal editor advised me in my submitted
> manuscript.
>   
"always better" is quite a strong statement. It does have a minimum 
variance property, but only under a number of assumptions that need to 
hold. IDW has not a naturally quantified variance, but has e.g. the nice 
property that the interpolated values do stay within the data range, 
which is not true for OK.
> Normally if we do not find a significant spatial structure for a soil
> variable, we may choose IDW or other methods. How is your guys' opinion
> on this or may you help me to find a better solution using OK with my
> dataset?
>   
Why would IDW be useful when no significant spatial structure is 
present? Why not use the global mean as predictor?

Other questions are whether variables exist out there that have no 
spatial structure, and also what significance means in your comment. 
Should we conclude that spatial correlation is zero when it is not 
significant? I would say no.
> I appreciate any help.
>   
And I'm looking for more opinions--anything!
> Regards
>
> Yong Li
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de



From yong.li at unimelb.edu.au  Mon Feb  9 00:36:13 2009
From: yong.li at unimelb.edu.au (Yong Li)
Date: Mon, 09 Feb 2009 10:36:13 +1100
Subject: [R-sig-Geo] FW:  Interpolcation option: IDW or OK?
Message-ID: <86DBA0678E017341B449A62F258E29561549C3@IS-EX-BEV3.unimelb.edu.au>

Hi Edzer,

I would say the spatial structure is regarded not significant when c0/c0+c1 is very much greater than 75%. In my case I used even distance intervals and calculated c0/c0+c1 for log(OLSENP) greater than 85%. I knew this index sometimes is very fragile, very much depending on how we fit the model.

However when I zoomed in by using variable distance intervals (boundaries=c(100,200,300,400,600,900,1000,1500,2000))and maxdist=2000 meters, I found a pretty good model-fitted experimental variogram. But the local OK interpolation using such a fitted model did not make sense when compared the predictions to the observations as in most areas values of OLSENP were severely underestimated. You may have seen my code with which I have tried the nested models, but unfortunately no luck either. I maybe think the parameters for local ordinary kriging are not optimized, but I have tried lots of sets of nmin, nmax and maxdist and did see the hopeful end.

The journal editor insists in OK being better than IDW. I need to collect my evidence to defend my IDW choice. That is my intention raised such a question in our forum here.

Cheers

Yong

-----Original Message-----
From: Edzer Pebesma [mailto:edzer.pebesma at uni-muenster.de] 
Sent: Monday, 9 February 2009 9:41 AM
To: Yong Li
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] Interpolcation option: IDW or OK?

Yong Li wrote:
> Hi ALL,
>
> I have been with the attached dataset and R code to use OK to
> interpolate soil OLSEN P spatial distribution for a couple of weeks. So
> far I have not found a satisfactory solution using OK or local OK or
> block OK, compared to IDW method. However theoretically OK is always
> better than IDW as also a journal editor advised me in my submitted
> manuscript.
>   
"always better" is quite a strong statement. It does have a minimum 
variance property, but only under a number of assumptions that need to 
hold. IDW has not a naturally quantified variance, but has e.g. the nice 
property that the interpolated values do stay within the data range, 
which is not true for OK.
> Normally if we do not find a significant spatial structure for a soil
> variable, we may choose IDW or other methods. How is your guys' opinion
> on this or may you help me to find a better solution using OK with my
> dataset?
>   
Why would IDW be useful when no significant spatial structure is 
present? Why not use the global mean as predictor?

Other questions are whether variables exist out there that have no 
spatial structure, and also what significance means in your comment. 
Should we conclude that spatial correlation is zero when it is not 
significant? I would say no.
> I appreciate any help.
>   
And I'm looking for more opinions--anything!
> Regards
>
> Yong Li
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de



From edzer.pebesma at uni-muenster.de  Mon Feb  9 09:08:14 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 09 Feb 2009 09:08:14 +0100
Subject: [R-sig-Geo] FW:  Interpolcation option: IDW or OK?
In-Reply-To: <86DBA0678E017341B449A62F258E29561549C3@IS-EX-BEV3.unimelb.edu.au>
References: <86DBA0678E017341B449A62F258E29561549C3@IS-EX-BEV3.unimelb.edu.au>
Message-ID: <498FE46E.6050407@uni-muenster.de>

Yong Li wrote:
> Hi Edzer,
>
> I would say the spatial structure is regarded not significant when c0/c0+c1 is very much greater than 75%. In my case I used even distance intervals and calculated c0/c0+c1 for log(OLSENP) greater than 85%. I knew this index sometimes is very fragile, very much depending on how we fit the model.
>
> However when I zoomed in by using variable distance intervals (boundaries=c(100,200,300,400,600,900,1000,1500,2000))and maxdist=2000 meters, I found a pretty good model-fitted experimental variogram. But the local OK interpolation using such a fitted model did not make sense when compared the predictions to the observations as in most areas values of OLSENP were severely underestimated. You may have seen my code with which I have tried the nested models, but unfortunately no luck either. I maybe think the parameters for local ordinary kriging are not optimized, but I have tried lots of sets of nmin, nmax and maxdist and did see the hopeful end.
>
> The journal editor insists in OK being better than IDW. I need to collect my evidence to defend my IDW choice. That is my intention raised such a question in our forum here.
>   
I cannot find evidence in your data for such a claim; the cross 
validation statistics (rmse) seem to favour OK with your nested model.

In your first email, you stated the following:
>> Normally if we do not find a significant spatial structure for a soil
>> variable, we may choose IDW or other methods. 
What is the argumentation behind this? Who claimed this?

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de



From aloboaleu at gmail.com  Mon Feb  9 15:06:24 2009
From: aloboaleu at gmail.com (Agustin Lobo)
Date: Mon, 09 Feb 2009 15:06:24 +0100
Subject: [R-sig-Geo] error rgdal library if used from within Grass plugin
	(Windows)
Message-ID: <49903860.8060406@gmail.com>

Hi!

The following error only occurs if the R (2.7.2) session is started
from a GRASS shell opened through the QGIS GRASS plugin in windows.
The error does not occur If R is started form its own icon
or by double click in the .RData  object,  but then the spgrass6
package would not find the GRASS environment.

It also works in linux.
The involved  commands  are:

1. Start  QGIS
2. Star GRASS plugin and open mapset
3.  Open Grass Shell
4.  Run R and execute require(spgrass6)

>>>>
>>>> Loading required package: spgrass6
>>>> Loading required package: sp
>>>> Loading required package: rgdal
>>>> Error in fun(...) :
>>>>         GDAL Error 1: Can't load requested DLL:
>>>> C:\OSGeo4W\bin\gdalplugins\gdal_ECW_JP2ECW.dll
>>>> 126: N?o foi poss?vel encontrar o m?dulo especificado.
>>>>
>>>>
>>>>
>>>> Error : .onLoad failed in 'loadNamespace' for 'rgdal'
>>>> Erro: package 'rgdal' could not be loaded

Any help appreciated.

Agus

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Roger.Bivand at nhh.no  Mon Feb  9 16:21:25 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 9 Feb 2009 16:21:25 +0100 (CET)
Subject: [R-sig-Geo] error rgdal library if used from within Grass
 plugin (Windows)
In-Reply-To: <49903860.8060406@gmail.com>
References: <49903860.8060406@gmail.com>
Message-ID: <alpine.LRH.2.00.0902091618410.12628@reclus.nhh.no>

On Mon, 9 Feb 2009, Agustin Lobo wrote:

> Hi!
>
> The following error only occurs if the R (2.7.2) session is started
> from a GRASS shell opened through the QGIS GRASS plugin in windows.
> The error does not occur If R is started form its own icon
> or by double click in the .RData  object,  but then the spgrass6
> package would not find the GRASS environment.
>
> It also works in linux.
> The involved  commands  are:
>
> 1. Start  QGIS
> 2. Star GRASS plugin and open mapset
> 3.  Open Grass Shell
> 4.  Run R and execute require(spgrass6)
>
>>>>> 
>>>>> Loading required package: spgrass6
>>>>> Loading required package: sp
>>>>> Loading required package: rgdal
>>>>> Error in fun(...) :
>>>>>         GDAL Error 1: Can't load requested DLL:
>>>>> C:\OSGeo4W\bin\gdalplugins\gdal_ECW_JP2ECW.dll
>>>>> 126: N?o foi poss?vel encontrar o m?dulo especificado.
>>>>> 
>>>>> 
>>>>> 
>>>>> Error : .onLoad failed in 'loadNamespace' for 'rgdal'
>>>>> Erro: package 'rgdal' could not be loaded

Which rgdal binary from where? This really is a question for osgeo4w, 
which is bleeding edge at the moment. Are you using the early draft rgdal 
binary built against a specific osgeo4w version and available from my 
website? Can we settle this off-list until osgeo4w stabilises?

Roger

>
> Any help appreciated.
>
> Agus
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From T.Hengl at uva.nl  Mon Feb  9 16:55:51 2009
From: T.Hengl at uva.nl (Tomislav Hengl)
Date: Mon, 9 Feb 2009 16:55:51 +0100
Subject: [R-sig-Geo] FW:  Interpolcation option: IDW or OK?
In-Reply-To: <498FE46E.6050407@uni-muenster.de>
References: <86DBA0678E017341B449A62F258E29561549C3@IS-EX-BEV3.unimelb.edu.au>
	<498FE46E.6050407@uni-muenster.de>
Message-ID: <ECA350872DC649129EF25F1C51EBCFFA@pcibed193>


Dear Yong Li,

I hope you will not mind me joining this interesting discussion. 

If there is no evident spatial auto-correlation structure (pure nugget effect), IDW/OK are as good
as randomly drawing a value from the global (normal) distribution. You can even test this using
cross-validation! In principle, there is no justification to use distance-based interpolators if
there is no evident spatial auto-correlation structure (maybe only the moving-window kriging, as
implemented in e.g. Vesper, or stratified kriging techniques could discover some local spatial
dependence). In addition, IDW should be considered an outdated technique, applicable only for
situations where the variogram is close to linear (e.g. elevation data and similar smooth surfaces).

What you should really consider using are the globaly available free maps/images (e.g. MODIS EVI,
SRTM DEM parameters etc.), and then see if you can explain some of the variability in your target
variable. 

But there will always be situations (especially in DSM applications) where you simply can not
explain much of the target variability, neither with auxiliary maps nor with spatial
auto-correlation. What to do then? I guess you simply have to collect more samples / more auxiliary
maps and then try again.

HTH

T. Hengl

See also:

Compendium of Global datasets:
http://spatial-analyst.net/wiki/index.php?title=Global_datasets

Regression-kriging:
http://spatial-analyst.net/wiki/index.php?title=Regression-kriging

Pebesma, E., 2006. The Role of External Variables and GIS Databases in Geostatistical Analysis.
Transactions in GIS, 10(4): 615-632.
http://dx.doi.org/10.1111/j.1467-9671.2006.01015.x 


> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
> Of Edzer Pebesma
> Sent: Monday, February 09, 2009 9:08 AM
> To: Yong Li
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] FW: Interpolcation option: IDW or OK?
> 
> Yong Li wrote:
> > Hi Edzer,
> >
> > I would say the spatial structure is regarded not significant when c0/c0+c1 is very much greater
> than 75%. In my case I used even distance intervals and calculated c0/c0+c1 for log(OLSENP)
> greater than 85%. I knew this index sometimes is very fragile, very much depending on how we fit
> the model.
> >
> > However when I zoomed in by using variable distance intervals
> (boundaries=c(100,200,300,400,600,900,1000,1500,2000))and maxdist=2000 meters, I found a pretty
> good model-fitted experimental variogram. But the local OK interpolation using such a fitted model
> did not make sense when compared the predictions to the observations as in most areas values of
> OLSENP were severely underestimated. You may have seen my code with which I have tried the nested
> models, but unfortunately no luck either. I maybe think the parameters for local ordinary kriging
> are not optimized, but I have tried lots of sets of nmin, nmax and maxdist and did see the hopeful
> end.
> >
> > The journal editor insists in OK being better than IDW. I need to collect my evidence to defend
> my IDW choice. That is my intention raised such a question in our forum here.
> >
> I cannot find evidence in your data for such a claim; the cross
> validation statistics (rmse) seem to favour OK with your nested model.
> 
> In your first email, you stated the following:
> >> Normally if we do not find a significant spatial structure for a soil
> >> variable, we may choose IDW or other methods.
> What is the argumentation behind this? Who claimed this?
> 
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
> http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From r.m.krug at gmail.com  Mon Feb  9 16:58:26 2009
From: r.m.krug at gmail.com (Rainer M Krug)
Date: Mon, 9 Feb 2009 17:58:26 +0200
Subject: [R-sig-Geo] Calculating descriptive stats from many maps
Message-ID: <fb7c7e870902090758n66f987fk122de94146c13fe4@mail.gmail.com>

Hi

I have 25000 maps, generated by simulation predictions, covering the
same area, and would like to calculate some descriptive stats, like
mean, standard deviation, median, quartiles of all cells, to create a
"variability map".

Is there an easy way of doing this in R?

Thanks,

Rainer

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Faculty of Science
Natural Sciences Building
Private Bag X1
University of Stellenbosch
Matieland 7602
South Africa



From T.Hengl at uva.nl  Mon Feb  9 17:33:51 2009
From: T.Hengl at uva.nl (Tomislav Hengl)
Date: Mon, 9 Feb 2009 17:33:51 +0100
Subject: [R-sig-Geo] Calculating descriptive stats from many maps
In-Reply-To: <fb7c7e870902090758n66f987fk122de94146c13fe4@mail.gmail.com>
References: <fb7c7e870902090758n66f987fk122de94146c13fe4@mail.gmail.com>
Message-ID: <D0BA11FFBCAD490B9D79F65EAC48FDE9@pcibed193>


Dear Rainer,

This is of course possible in R, and can be done in several ways:

1) for example, you can derive the average value using the rowSums function:

> maps$Nsum <- rowSums(maps at data, na.rm=T, dims=1)
> maps$avg <- maps$Nsum/(length(names(meuse.grid at data))-1)

You could also loop the sd, mean and quantile function over a range of cells:

> for(i in length(names(maps at data))) {
> maps at data$sd[i] <- sd(maps at data[i,])
> maps at data$mean[i] <- mean(maps at data[i,])
...
> }

This could take a lot of time!

2) if your maps are rather large, try also using the SAGA function:

> rsaga.get.usage(lib = "geostatistics_grid", module=5)
SAGA CMD 2.0.3
library path:   C:/Progra~1/saga_vc/modules
library name:   geostatistics_grid
module name :   Statistics for Grids

This is probably the fastest method you can use.

HTH

T. Hengl

> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
> Of Rainer M Krug
> Sent: Monday, February 09, 2009 4:58 PM
> To: R-sig-Geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] Calculating descriptive stats from many maps
> 
> Hi
> 
> I have 25000 maps, generated by simulation predictions, covering the
> same area, and would like to calculate some descriptive stats, like
> mean, standard deviation, median, quartiles of all cells, to create a
> "variability map".
> 
> Is there an easy way of doing this in R?
> 
> Thanks,
> 
> Rainer
> 
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
> Biology, UCT), Dipl. Phys. (Germany)
> 
> Centre of Excellence for Invasion Biology
> Faculty of Science
> Natural Sciences Building
> Private Bag X1
> University of Stellenbosch
> Matieland 7602
> South Africa
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From Roger.Bivand at nhh.no  Mon Feb  9 18:05:25 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 9 Feb 2009 18:05:25 +0100 (CET)
Subject: [R-sig-Geo] Calculating descriptive stats from many maps
In-Reply-To: <D0BA11FFBCAD490B9D79F65EAC48FDE9@pcibed193>
References: <fb7c7e870902090758n66f987fk122de94146c13fe4@mail.gmail.com>
	<D0BA11FFBCAD490B9D79F65EAC48FDE9@pcibed193>
Message-ID: <alpine.LRH.2.00.0902091800170.15636@reclus.nhh.no>

On Mon, 9 Feb 2009, Tomislav Hengl wrote:

>
> Dear Rainer,
>
> This is of course possible in R, and can be done in several ways:
>
> 1) for example, you can derive the average value using the rowSums function:
>
>> maps$Nsum <- rowSums(maps at data, na.rm=T, dims=1)
>> maps$avg <- maps$Nsum/(length(names(meuse.grid at data))-1)
>
> You could also loop the sd, mean and quantile function over a range of cells:
>
>> for(i in length(names(maps at data))) {
>> maps at data$sd[i] <- sd(maps at data[i,])
>> maps at data$mean[i] <- mean(maps at data[i,])
> ...
>> }
>
> This could take a lot of time!

Tom, Rainer,

Yes, using sapply(slot(maps, "data"), summary) or similar, you get the 
map-wise statistics. But have I misunderstood, or are the statistics in 
question cell-wise? This would involve stacking subset areas for all 25' 
maps, wouldn't it? Brutally, a loop in readGDAL() from rgdal with offset= 
and region.dim= shifted? Is there a canned way to do this in the R-forge 
raster package (by the way, regularly one of the R-forge packages showing 
most developer activity)?

Roger

>
> 2) if your maps are rather large, try also using the SAGA function:
>
>> rsaga.get.usage(lib = "geostatistics_grid", module=5)
> SAGA CMD 2.0.3
> library path:   C:/Progra~1/saga_vc/modules
> library name:   geostatistics_grid
> module name :   Statistics for Grids
>
> This is probably the fastest method you can use.
>
> HTH
>
> T. Hengl
>
>> -----Original Message-----
>> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
>> Of Rainer M Krug
>> Sent: Monday, February 09, 2009 4:58 PM
>> To: R-sig-Geo at stat.math.ethz.ch
>> Subject: [R-sig-Geo] Calculating descriptive stats from many maps
>>
>> Hi
>>
>> I have 25000 maps, generated by simulation predictions, covering the
>> same area, and would like to calculate some descriptive stats, like
>> mean, standard deviation, median, quartiles of all cells, to create a
>> "variability map".
>>
>> Is there an easy way of doing this in R?
>>
>> Thanks,
>>
>> Rainer
>>
>> --
>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
>> Biology, UCT), Dipl. Phys. (Germany)
>>
>> Centre of Excellence for Invasion Biology
>> Faculty of Science
>> Natural Sciences Building
>> Private Bag X1
>> University of Stellenbosch
>> Matieland 7602
>> South Africa
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From yong.li at unimelb.edu.au  Tue Feb 10 00:40:40 2009
From: yong.li at unimelb.edu.au (Yong Li)
Date: Tue, 10 Feb 2009 10:40:40 +1100
Subject: [R-sig-Geo] Interpolcation option: IDW or OK?
In-Reply-To: <498FE46E.6050407@uni-muenster.de>
Message-ID: <86DBA0678E017341B449A62F258E29561549C6@IS-EX-BEV3.unimelb.edu.au>

Many thanks for the message, Edzer.

-----Original Message-----
From: Edzer Pebesma [mailto:edzer.pebesma at uni-muenster.de] 
Sent: Monday, 9 February 2009 7:08 PM
To: Yong Li
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: FW: [R-sig-Geo] Interpolcation option: IDW or OK?

Yong Li wrote:
> Hi Edzer,
>
> I would say the spatial structure is regarded not significant when
c0/c0+c1 is very much greater than 75%. In my case I used even distance
intervals and calculated c0/c0+c1 for log(OLSENP) greater than 85%. I
knew this index sometimes is very fragile, very much depending on how we
fit the model.
>
> However when I zoomed in by using variable distance intervals
(boundaries=c(100,200,300,400,600,900,1000,1500,2000))and maxdist=2000
meters, I found a pretty good model-fitted experimental variogram. But
the local OK interpolation using such a fitted model did not make sense
when compared the predictions to the observations as in most areas
values of OLSENP were severely underestimated. You may have seen my code
with which I have tried the nested models, but unfortunately no luck
either. I maybe think the parameters for local ordinary kriging are not
optimized, but I have tried lots of sets of nmin, nmax and maxdist and
did see the hopeful end.
>
> The journal editor insists in OK being better than IDW. I need to
collect my evidence to defend my IDW choice. That is my intention raised
such a question in our forum here.
>   
I cannot find evidence in your data for such a claim; the cross 
validation statistics (rmse) seem to favour OK with your nested model.

YONGLI==================================================================
====
Could you have a look at the predictions generated by my nested model
and compare to the observations? The values were severely
underestimated. 
YONGLI==================================================================
====

In your first email, you stated the following:
>> Normally if we do not find a significant spatial structure for a soil
>> variable, we may choose IDW or other methods. 
What is the argumentation behind this? Who claimed this?

YONGLI==================================================================
====
Could you have a look at "Mueller et al. (2004) Map Quality for Ordinary
Kriging and Inverse Distance Weighted Interpolation. Soil Sci. Soc. Am.
J. 68:2042-2047."? 
YONGLI==================================================================
====

Regards,

Yong Li



From r.hijmans at gmail.com  Tue Feb 10 03:07:11 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Tue, 10 Feb 2009 10:07:11 +0800
Subject: [R-sig-Geo] Calculating descriptive stats from many maps
In-Reply-To: <alpine.LRH.2.00.0902091800170.15636@reclus.nhh.no>
References: <fb7c7e870902090758n66f987fk122de94146c13fe4@mail.gmail.com>
	<D0BA11FFBCAD490B9D79F65EAC48FDE9@pcibed193>
	<alpine.LRH.2.00.0902091800170.15636@reclus.nhh.no>
Message-ID: <dc22b2570902091807m4698caf7xbe79e562da35bce2@mail.gmail.com>

Dear Rainer,

This is how can you can do it with the raster package

# install.packages("raster", repos="http://R-Forge.R-project.org")
require(raster)

# Try it for a few files first..
n <- 10

# create a list (or vector) of file names, e.g. :
fn <- list()
for (i in 1:n) { fn[i] <- paste('myfile', i, '.tif', sep='') }

# make a RasterStack
s <- stack(fn)

r1 <- mCalc(s, fun=mean)
r2 <- mCalc(s, fun=sd)

#r can be plotted, coerced to sp objects, etc.
plot(r1)

# or saved to file
r1 <- setFilename(r1, 'cellmeans.tif')
r1 <- writeRaster(r1, format='GTiff')


Robert


On Tue, Feb 10, 2009 at 1:05 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Mon, 9 Feb 2009, Tomislav Hengl wrote:
>
>>
>> Dear Rainer,
>>
>> This is of course possible in R, and can be done in several ways:
>>
>> 1) for example, you can derive the average value using the rowSums
>> function:
>>
>>> maps$Nsum <- rowSums(maps at data, na.rm=T, dims=1)
>>> maps$avg <- maps$Nsum/(length(names(meuse.grid at data))-1)
>>
>> You could also loop the sd, mean and quantile function over a range of
>> cells:
>>
>>> for(i in length(names(maps at data))) {
>>> maps at data$sd[i] <- sd(maps at data[i,])
>>> maps at data$mean[i] <- mean(maps at data[i,])
>>
>> ...
>>>
>>> }
>>
>> This could take a lot of time!
>
> Tom, Rainer,
>
> Yes, using sapply(slot(maps, "data"), summary) or similar, you get the
> map-wise statistics. But have I misunderstood, or are the statistics in
> question cell-wise? This would involve stacking subset areas for all 25'
> maps, wouldn't it? Brutally, a loop in readGDAL() from rgdal with offset=
> and region.dim= shifted? Is there a canned way to do this in the R-forge
> raster package (by the way, regularly one of the R-forge packages showing
> most developer activity)?
>
> Roger
>
>>
>> 2) if your maps are rather large, try also using the SAGA function:
>>
>>> rsaga.get.usage(lib = "geostatistics_grid", module=5)
>>
>> SAGA CMD 2.0.3
>> library path:   C:/Progra~1/saga_vc/modules
>> library name:   geostatistics_grid
>> module name :   Statistics for Grids
>>
>> This is probably the fastest method you can use.
>>
>> HTH
>>
>> T. Hengl
>>
>>> -----Original Message-----
>>> From: r-sig-geo-bounces at stat.math.ethz.ch
>>> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
>>> Of Rainer M Krug
>>> Sent: Monday, February 09, 2009 4:58 PM
>>> To: R-sig-Geo at stat.math.ethz.ch
>>> Subject: [R-sig-Geo] Calculating descriptive stats from many maps
>>>
>>> Hi
>>>
>>> I have 25000 maps, generated by simulation predictions, covering the
>>> same area, and would like to calculate some descriptive stats, like
>>> mean, standard deviation, median, quartiles of all cells, to create a
>>> "variability map".
>>>
>>> Is there an easy way of doing this in R?
>>>
>>> Thanks,
>>>
>>> Rainer
>>>
>>> --
>>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
>>> Biology, UCT), Dipl. Phys. (Germany)
>>>
>>> Centre of Excellence for Invasion Biology
>>> Faculty of Science
>>> Natural Sciences Building
>>> Private Bag X1
>>> University of Stellenbosch
>>> Matieland 7602
>>> South Africa
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From r.hijmans at gmail.com  Tue Feb 10 05:44:57 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Tue, 10 Feb 2009 12:44:57 +0800
Subject: [R-sig-Geo] FW: Interpolcation option: IDW or OK?
In-Reply-To: <ECA350872DC649129EF25F1C51EBCFFA@pcibed193>
References: <86DBA0678E017341B449A62F258E29561549C3@IS-EX-BEV3.unimelb.edu.au>
	<498FE46E.6050407@uni-muenster.de>
	<ECA350872DC649129EF25F1C51EBCFFA@pcibed193>
Message-ID: <dc22b2570902092044w29078ad6yad92a971f376b662@mail.gmail.com>

Why not use cross-validation to empirically determine which method
performs best for this dataset (in addition to asking if they are
better than a random draw)?  Robert

2009/2/9 Tomislav Hengl <T.Hengl at uva.nl>:
>
> Dear Yong Li,
>
> I hope you will not mind me joining this interesting discussion.
>
> If there is no evident spatial auto-correlation structure (pure nugget effect), IDW/OK are as good
> as randomly drawing a value from the global (normal) distribution. You can even test this using
> cross-validation! In principle, there is no justification to use distance-based interpolators if
> there is no evident spatial auto-correlation structure (maybe only the moving-window kriging, as
> implemented in e.g. Vesper, or stratified kriging techniques could discover some local spatial
> dependence). In addition, IDW should be considered an outdated technique, applicable only for
> situations where the variogram is close to linear (e.g. elevation data and similar smooth surfaces).
>
> What you should really consider using are the globaly available free maps/images (e.g. MODIS EVI,
> SRTM DEM parameters etc.), and then see if you can explain some of the variability in your target
> variable.
>
> But there will always be situations (especially in DSM applications) where you simply can not
> explain much of the target variability, neither with auxiliary maps nor with spatial
> auto-correlation. What to do then? I guess you simply have to collect more samples / more auxiliary
> maps and then try again.
>
> HTH
>
> T. Hengl
>
> See also:
>
> Compendium of Global datasets:
> http://spatial-analyst.net/wiki/index.php?title=Global_datasets
>
> Regression-kriging:
> http://spatial-analyst.net/wiki/index.php?title=Regression-kriging
>
> Pebesma, E., 2006. The Role of External Variables and GIS Databases in Geostatistical Analysis.
> Transactions in GIS, 10(4): 615-632.
> http://dx.doi.org/10.1111/j.1467-9671.2006.01015.x
>
>
>> -----Original Message-----
>> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
>> Of Edzer Pebesma
>> Sent: Monday, February 09, 2009 9:08 AM
>> To: Yong Li
>> Cc: r-sig-geo at stat.math.ethz.ch
>> Subject: Re: [R-sig-Geo] FW: Interpolcation option: IDW or OK?
>>
>> Yong Li wrote:
>> > Hi Edzer,
>> >
>> > I would say the spatial structure is regarded not significant when c0/c0+c1 is very much greater
>> than 75%. In my case I used even distance intervals and calculated c0/c0+c1 for log(OLSENP)
>> greater than 85%. I knew this index sometimes is very fragile, very much depending on how we fit
>> the model.
>> >
>> > However when I zoomed in by using variable distance intervals
>> (boundaries=c(100,200,300,400,600,900,1000,1500,2000))and maxdist=2000 meters, I found a pretty
>> good model-fitted experimental variogram. But the local OK interpolation using such a fitted model
>> did not make sense when compared the predictions to the observations as in most areas values of
>> OLSENP were severely underestimated. You may have seen my code with which I have tried the nested
>> models, but unfortunately no luck either. I maybe think the parameters for local ordinary kriging
>> are not optimized, but I have tried lots of sets of nmin, nmax and maxdist and did see the hopeful
>> end.
>> >
>> > The journal editor insists in OK being better than IDW. I need to collect my evidence to defend
>> my IDW choice. That is my intention raised such a question in our forum here.
>> >
>> I cannot find evidence in your data for such a claim; the cross
>> validation statistics (rmse) seem to favour OK with your nested model.
>>
>> In your first email, you stated the following:
>> >> Normally if we do not find a significant spatial structure for a soil
>> >> variable, we may choose IDW or other methods.
>> What is the argumentation behind this? Who claimed this?
>>
>> --
>> Edzer Pebesma
>> Institute for Geoinformatics (ifgi), University of M?nster
>> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
>> 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
>> http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From r.m.krug at gmail.com  Tue Feb 10 09:29:25 2009
From: r.m.krug at gmail.com (Rainer M Krug)
Date: Tue, 10 Feb 2009 10:29:25 +0200
Subject: [R-sig-Geo] Calculating descriptive stats from many maps
In-Reply-To: <dc22b2570902091807m4698caf7xbe79e562da35bce2@mail.gmail.com>
References: <fb7c7e870902090758n66f987fk122de94146c13fe4@mail.gmail.com>
	<D0BA11FFBCAD490B9D79F65EAC48FDE9@pcibed193>
	<alpine.LRH.2.00.0902091800170.15636@reclus.nhh.no>
	<dc22b2570902091807m4698caf7xbe79e562da35bce2@mail.gmail.com>
Message-ID: <fb7c7e870902100029kf6e436du542afd36c4067f2f@mail.gmail.com>

Thanks a lot to all of you.

You are right Roger, I need cell-wise statistics

I like the idea of the "raster" package, and I will try it out just now.

Concerning SAGA: I'll look into that if "raster" does not work (or is to slow).

I'll report back

Rainer


On Tue, Feb 10, 2009 at 4:07 AM, Robert Hijmans <r.hijmans at gmail.com> wrote:
> Dear Rainer,
>
> This is how can you can do it with the raster package
>
> # install.packages("raster", repos="http://R-Forge.R-project.org")
> require(raster)
>
> # Try it for a few files first..
> n <- 10
>
> # create a list (or vector) of file names, e.g. :
> fn <- list()
> for (i in 1:n) { fn[i] <- paste('myfile', i, '.tif', sep='') }
>
> # make a RasterStack
> s <- stack(fn)
>
> r1 <- mCalc(s, fun=mean)
> r2 <- mCalc(s, fun=sd)
>
> #r can be plotted, coerced to sp objects, etc.
> plot(r1)
>
> # or saved to file
> r1 <- setFilename(r1, 'cellmeans.tif')
> r1 <- writeRaster(r1, format='GTiff')
>
>
> Robert
>
>
> On Tue, Feb 10, 2009 at 1:05 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> On Mon, 9 Feb 2009, Tomislav Hengl wrote:
>>
>>>
>>> Dear Rainer,
>>>
>>> This is of course possible in R, and can be done in several ways:
>>>
>>> 1) for example, you can derive the average value using the rowSums
>>> function:
>>>
>>>> maps$Nsum <- rowSums(maps at data, na.rm=T, dims=1)
>>>> maps$avg <- maps$Nsum/(length(names(meuse.grid at data))-1)
>>>
>>> You could also loop the sd, mean and quantile function over a range of
>>> cells:
>>>
>>>> for(i in length(names(maps at data))) {
>>>> maps at data$sd[i] <- sd(maps at data[i,])
>>>> maps at data$mean[i] <- mean(maps at data[i,])
>>>
>>> ...
>>>>
>>>> }
>>>
>>> This could take a lot of time!
>>
>> Tom, Rainer,
>>
>> Yes, using sapply(slot(maps, "data"), summary) or similar, you get the
>> map-wise statistics. But have I misunderstood, or are the statistics in
>> question cell-wise? This would involve stacking subset areas for all 25'
>> maps, wouldn't it? Brutally, a loop in readGDAL() from rgdal with offset=
>> and region.dim= shifted? Is there a canned way to do this in the R-forge
>> raster package (by the way, regularly one of the R-forge packages showing
>> most developer activity)?
>>
>> Roger
>>
>>>
>>> 2) if your maps are rather large, try also using the SAGA function:
>>>
>>>> rsaga.get.usage(lib = "geostatistics_grid", module=5)
>>>
>>> SAGA CMD 2.0.3
>>> library path:   C:/Progra~1/saga_vc/modules
>>> library name:   geostatistics_grid
>>> module name :   Statistics for Grids
>>>
>>> This is probably the fastest method you can use.
>>>
>>> HTH
>>>
>>> T. Hengl
>>>
>>>> -----Original Message-----
>>>> From: r-sig-geo-bounces at stat.math.ethz.ch
>>>> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
>>>> Of Rainer M Krug
>>>> Sent: Monday, February 09, 2009 4:58 PM
>>>> To: R-sig-Geo at stat.math.ethz.ch
>>>> Subject: [R-sig-Geo] Calculating descriptive stats from many maps
>>>>
>>>> Hi
>>>>
>>>> I have 25000 maps, generated by simulation predictions, covering the
>>>> same area, and would like to calculate some descriptive stats, like
>>>> mean, standard deviation, median, quartiles of all cells, to create a
>>>> "variability map".
>>>>
>>>> Is there an easy way of doing this in R?
>>>>
>>>> Thanks,
>>>>
>>>> Rainer
>>>>
>>>> --
>>>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
>>>> Biology, UCT), Dipl. Phys. (Germany)
>>>>
>>>> Centre of Excellence for Invasion Biology
>>>> Faculty of Science
>>>> Natural Sciences Building
>>>> Private Bag X1
>>>> University of Stellenbosch
>>>> Matieland 7602
>>>> South Africa
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Faculty of Science
Natural Sciences Building
Private Bag X1
University of Stellenbosch
Matieland 7602
South Africa



From Mark.Trinder at rpsgroup.com  Tue Feb 10 13:49:29 2009
From: Mark.Trinder at rpsgroup.com (Mark Trinder)
Date: Tue, 10 Feb 2009 12:49:29 -0000
Subject: [R-sig-Geo] animal path analysis
Message-ID: <605F55D8070C094AA2E2A9CBA2767A3C035672FC@EXMB1.eur.rpsgroup.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090210/7b6fbffa/attachment.pl>

From Sandra.Burmeier at umwelt.uni-giessen.de  Tue Feb 10 15:14:32 2009
From: Sandra.Burmeier at umwelt.uni-giessen.de (Sandra Burmeier)
Date: Tue, 10 Feb 2009 15:14:32 +0100
Subject: [R-sig-Geo] Moran's I for grid data?
Message-ID: <49918BC8.4010806@umwelt.uni-giessen.de>

Hi,

I have some questions concerning the calculation of Moran?s I for 
grid-based data.

I?m a plant ecologist analysing the small-scale composition of 
populations of a certain plant species. That is, I?m intending to 
compare the spatial distribution of adult plants, juvenile plants, 
seedlings and seeds in the seed bank. I have sampled several populations 
in 1x4-m-plots which were subdivided by a 20x20-cm-grid, and my data are 
aggregated values for the grid cells (e.g. 5 adult plants in cell 1, 12 
plants in cell 2 and so on).
The questions I would like to answer are the following:
(1) Do adults, juveniles etc. are aggregated within the plots 
(visualisation of the data in a simple map strongly suggests they are)?
(2) Is the level of aggregation (the average size of the clumps) the 
same for different life stages, i.e. do adults and juvenile clump on the 
same scale?

My plan was to calculate Moran?s I values (to answer question 1) and 
draw individual spatial correlograms for the different life stages and 
then compare the graphs (to answer question 2) ? but is that appropriate 
for my grid-based data?

In case it is, I have some more questions. So far, I?ve used the package 
spdep, calculated Moran?s I using the function moran.test (using 
knn-objects with the nearest 2, 3 and 4 neighbours ? any guidelines here 
on how many make sense?) and plotted the results using sp.correlogram:
/xy.A2.07 <-cbind(A2.07$x,A2.07$y)/
/xy.A2.07 <-matrix(xy.A2.07,ncol=2)/
/xy.A2.07.knn <- knearneigh(xy.A2.07, k=2) # I?ve also tried k=3 and k=4/
/xy.A2.07.nb <- knn2nb(xy.A2.07.knn)/
/xy.A2.07.lw <- nb2listw(xy.A2.07.nb,style="B")/
/moran.test(A2.07$Ara_bl,xy.A2.07.lw) /
/corr.A2.07.bl <- sp.correlogram(xy.A2.07.nb, A2.07$Ara_bl, method = 
"I", order=6, zero.policy=TRUE, style="B")/
/print.spcor(corr.A2.07.bl, "bonferroni")/
/plot.spcor(corr.A2.07.bl)/

Is there any possibility to define the lag-distances used by 
sp.correlogram? Or at least to find out what they are (in terms of the 
map units used, in my case centimetres)?

I am new to both spatial statistics and R, so these questions may be 
rather trivial - my apologies if they are. However, I am really 
wondering whether my approach is appropriate for the kind of data I?m 
dealing with and, if it isn?t, which other method would be suitable.

I would greatly appreciate any help!

Many thanks,
Sandra

-- 
Sandra Burmeier
PhD-Student
Justus-Liebig-University Giessen
Division of Landscape Ecology and Landscape Planning
Heinrich-Buff-Ring 26-32
35392 Giessen
Germany
E-mail: sandra.burmeier at umwelt.uni-giessen.de
http://www.uni-giessen.de/landscape

From Roger.Bivand at nhh.no  Tue Feb 10 23:24:59 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 10 Feb 2009 23:24:59 +0100 (CET)
Subject: [R-sig-Geo] Moran's I for grid data?
In-Reply-To: <49918BC8.4010806@umwelt.uni-giessen.de>
References: <49918BC8.4010806@umwelt.uni-giessen.de>
Message-ID: <alpine.LRH.2.00.0902102234140.21723@reclus.nhh.no>

On Tue, 10 Feb 2009, Sandra Burmeier wrote:

> Hi,
>
> I have some questions concerning the calculation of Moran?s I for 
> grid-based data.
>
> I?m a plant ecologist analysing the small-scale composition of 
> populations of a certain plant species. That is, I?m intending to 
> compare the spatial distribution of adult plants, juvenile plants, 
> seedlings and seeds in the seed bank. I have sampled several populations 
> in 1x4-m-plots which were subdivided by a 20x20-cm-grid, and my data are 
> aggregated values for the grid cells (e.g. 5 adult plants in cell 1, 12 
> plants in cell 2 and so on).
> The questions I would like to answer are the following:
> (1) Do adults, juveniles etc. are aggregated within the plots 
> (visualisation of the data in a simple map strongly suggests they are)?
> (2) Is the level of aggregation (the average size of the clumps) the 
> same for different life stages, i.e. do adults and juvenile clump on the 
> same scale?
>
> My plan was to calculate Moran?s I values (to answer question 1) and 
> draw individual spatial correlograms for the different life stages and 
> then compare the graphs (to answer question 2) ? but is that appropriate 
> for my grid-based data?
>
> In case it is, I have some more questions. So far, I?ve used the package 
> spdep, calculated Moran?s I using the function moran.test (using 
> knn-objects with the nearest 2, 3 and 4 neighbours ? any guidelines here 
> on how many make sense?) and plotted the results using sp.correlogram:
> /xy.A2.07 <-cbind(A2.07$x,A2.07$y)/
> /xy.A2.07 <-matrix(xy.A2.07,ncol=2)/
> /xy.A2.07.knn <- knearneigh(xy.A2.07, k=2) # I?ve also tried k=3 and k=4/
> /xy.A2.07.nb <- knn2nb(xy.A2.07.knn)/
> /xy.A2.07.lw <- nb2listw(xy.A2.07.nb,style="B")/
> /moran.test(A2.07$Ara_bl,xy.A2.07.lw) /
> /corr.A2.07.bl <- sp.correlogram(xy.A2.07.nb, A2.07$Ara_bl, method = 
> "I", order=6, zero.policy=TRUE, style="B")/
> /print.spcor(corr.A2.07.bl, "bonferroni")/
> /plot.spcor(corr.A2.07.bl)/
>
> Is there any possibility to define the lag-distances used by 
> sp.correlogram? Or at least to find out what they are (in terms of the 
> map units used, in my case centimetres)?

Sandra,

There are several questions here, none of which have obvious answers, so 
they involve choices motivated by domain and discipline tradition 
(GIScientists would call this "ontology"), as well as other knowledge of 
features of the phenomena that may not have been measured as such (the 
influence by distance attenuation is the key one here).

You are using aggregates, so the distances between the "points" within the 
grid cells gets aggregated. Think of a cluster of 20 plants very close 
together, but where 5 fall into each of 4 neighbouring grid cells - you'll 
see that the grid cells may both be a typical way to represent the 
phenomena, but may not be an ideal operationalisation. Shift the origin of 
the grid by 10cm in each direction, and all the plants are in one cell. So 
aggregation has its price. Had you had the point locations of the adults 
and juveniles, you might rather have done a point pattern analysis, 
probably a Kcross() in the spatstat terminology to see the 
cross-interpoint distance relations between adults and juveniles. Since 
you don't, you need to try to grasp the "support" of your observations 
firmly.

It seems to be areal support - that is, the aggregated observations are 
counts of phenomena by plot and grid cell. Are there covariates at the 
plot and grid cell level - is this a hierarchical problem?

Since the grid cells are regular, you'd need to find a good reason to 
choose anything other than first order contiguity (rook or queen style), 
or equivalently distance with a threshold just greater than the edge 
neighbour inter-centre distance for the rook style, or the corner 
neighbour inter-centre distance for the queen style. That is, knearneigh() 
is not appropriate here, I feel.

The confusion that exists in the use of the correlogram seems to relate to 
its use in geostatistics, and other areas in which the data have point 
support. If they do have point support, the inter-point distances can be 
interpreted directly. If on the other hand, the observations have areal 
support, using the centroids of the areas as "quasi" point support is 
possible, say, for triangulation or other graph based methods, but becomes 
problematic if distance is simply multiples of the resolution of a regular 
grid (with areal support).

Cliff & Ord (full references given on ?sp.correlogram) felt strongly that 
instead of trying to interpret "quasi" distance, it is better to examine 
autocorrelation for orders of neighbours, first order, second order are 
neighbours of neighbours, and so on. That is what sp.correlogram() does. 
The ncf and pgirmess packages provide correlog() functions that are 
distance based, but implicitly assume point support, or at least that the 
variable isn't an aggregate count (I would argue).

Finally, the Moran test is based on an underlying simultaneous 
autoregressive model, where the data generation process is driven by a 
covariance matrix containing the crossproduct of the inverse of the 
spatial operator, say (I - rho W). W are the spatial weights in matrix 
form, and are typically very sparse. However, the inverse is dense, that 
is, each observation *is* related to every other, but with a weight that 
attenuates as one steps out through the graph of neighbours - under 
certain conditions the inverse can be written as the sum of an infinite 
power series:

(I - rho W)^-1 = sum rho^0 W^0 + rho^1 W^1 + rho^2 W^2 + rho^3 W^3 + ...

In that case, the underlying model for first order autocorrelation 
may already include what the correlogram is trying to get hold of, but in 
graph terms, not distance terms.

The Getis-Ord G statistic tries to get at this problem, but again runs up 
against the areal/point support problem.

So in addition to point process analysis on the data before aggregation, 
you could also arguably look at the analysis of regular (experimental) 
plots (although agricultural trials would say measure crop yields per unit 
area, not just counts, and relate them to experimental covariates, say 
treatments).

Note that your aggregated data do seem to be counts anyway, so that the 
assumption that their residuals are Normally distributed may be quite 
brave. Unfortunately, there are few tried tests for autocorrelation in 
count variables (or in the residuals from GLM).

In summary, your question: "but is that appropriate for my grid-based 
data?" is central here. I don't think that there is a quick fix; getting 
anywhere will need a good deal of thought, it certainly doesn't seem 
trival to me. I would guess that plant ecologists might have a literature 
giving accepted recipies for this, but are they the same recipies that 
people doing agricultural trials would choose, or those that spatial 
epidemiologists would prefer? The underlying problem may well be support, 
that gridding and aggregating isn't necessarily a helpful way of 
operationalising this kind of research question.

Hope this helps,

Roger

>
> I am new to both spatial statistics and R, so these questions may be 
> rather trivial - my apologies if they are. However, I am really 
> wondering whether my approach is appropriate for the kind of data I?m 
> dealing with and, if it isn?t, which other method would be suitable.
>
> I would greatly appreciate any help!
>
> Many thanks,
> Sandra
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From greenberg at ucdavis.edu  Wed Feb 11 00:32:52 2009
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Tue, 10 Feb 2009 15:32:52 -0800
Subject: [R-sig-Geo] Problems freeing rgdal driver...
Message-ID: <49920EA4.4050005@ucdavis.edu>

A few months back I was getting some help with adapting R for doing 
tiled processing of remote sensing data, and I made some serious 
headway, but there is a lingering problem I keep scratching my head at.  
First off, a quick recap of the base algorithm:

1) Let i = input raster, f() some function to apply to i, and o the 
output raster, such that o = f(i)
2) i is read in "tiles", each tile read from the input we'll call i_tile 
(to make it simplest, assume I'm just reading i one line at a time) -- 
this process is performed using readGDAL(...offset=c(j, 0),...) where j 
is the current line I'm reading.  o_tile = f(i_tile), which is written 
using *writeBin* (not writeGDAL).
3) This produces a flat binary file of the sort that Arc binary rasters 
or ENVI rasters use.

So I produce the binary file, but the portion I'm getting a bit hung up 
on is the production of the little text header which completes the file 
(.hdr/.prj for an ESRI raster, .hdr for an ENVI raster, note that the 
.hdr is different between arc and envi).  For this example, let's try to 
make an ENVI header.  Remember i_tile is one of the readGDAL objects of 
a tiled subset of image of filename i:

***

  gp <- gridparameters(i_tile)
  cellsize <- gp$cellsize
  offset <- gp$cellcentre.offset
  dims <- gp$cells.dim
  dims[[2]]=rows
  nbands <- 1
  tempopen <- GDAL.open(i)
  file_projection <- getProjectionRef(tempopen)
  GDAL.close(tempopen)
# This was from Roger Bivand
  d.drv <- new("GDALDriver", "ENVI")
  tds.out <- new("GDALTransientDataset", driver = d.drv, rows = 
dims[2],cols = dims[1], bands = nbands, type = "Float32")
  gt <- c(offset[1] - 0.5 * cellsize[1], cellsize[1], 0.0,offset[2] + 
(dims[2] -0.5) * cellsize[2], 0.0, -cellsize[2])
  .Call("RGDAL_SetGeoTransform", tds.out, gt, PACKAGE = "rgdal")
  .Call("RGDAL_SetProject", tds.out, file_projection, PACKAGE = "rgdal")
  fn <- tempfile()
  saveDataset(tds.out, fn)
  GDAL.close(tds.out)
  GDAL.close(d.drv)
 
  temporary_dir=dirname(fn)
  outdir=dirname(outfile)
 
  fnhdr<-as.character(paste(basename(fn),outfile_hdr,sep=''))
  outhdr<-as.character(paste(basename(rasteroutput),outfile_hdr,sep=''))

  setwd(temporary_dir)

  file.rename(fnhdr,outhdr)
  file.copy(outhdr,outdir,overwrite=TRUE)

***

So this WORKS the first time I run it, but the SECOND time it is run 
(without quitting out of R) I get the following error:
 >   d.drv <- new("GDALDriver", "ENVI")
Error in .local(.Object, ...) : No driver registered with name: ENVI

It seems like there is some lingering open driver or something 
someplace, but for the life of me I can't tell where it is.  You can see 
that I did a GDAL.close(d.drv) but that doesn't seem to be sufficient.  
Thoughts?

By the way, the full algorithm would deal with RS data of an arbitrary 
number of samples, lines and bands (e.g. hyperspectral processing would 
be completely feasible).  I'm happy to send the script to the list once 
the bugs are worked out!  Thanks!

--j


From r.hijmans at gmail.com  Wed Feb 11 01:29:34 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Wed, 11 Feb 2009 08:29:34 +0800
Subject: [R-sig-Geo] Problems freeing rgdal driver...
In-Reply-To: <49920EA4.4050005@ucdavis.edu>
References: <49920EA4.4050005@ucdavis.edu>
Message-ID: <dc22b2570902101629x6a8a3171hdc88ac20455841cf@mail.gmail.com>

Hi Jonathan,

I ran into the same problem when writing the writeRaster function in
the raster package (and see the incipient RemoteSensing package on
R-forge that uses it); which is very similar.

This is the problem:

> driver = new("GDALDriver", "GTiff")
> GDAL.close(driver)
>
> driver = new("GDALDriver", "GTiff")
Error in .local(.Object, ...) : No driver registered with name: GTiff
> GDAL.close(driver)
>

But it does not always happen right away; for some reason.


If you omit

  GDAL.close(d.drv)

It will work.

Robert


On Wed, Feb 11, 2009 at 7:32 AM, Jonathan Greenberg
<greenberg at ucdavis.edu> wrote:
> A few months back I was getting some help with adapting R for doing tiled
> processing of remote sensing data, and I made some serious headway, but
> there is a lingering problem I keep scratching my head at.  First off, a
> quick recap of the base algorithm:
>
> 1) Let i = input raster, f() some function to apply to i, and o the output
> raster, such that o = f(i)
> 2) i is read in "tiles", each tile read from the input we'll call i_tile (to
> make it simplest, assume I'm just reading i one line at a time) -- this
> process is performed using readGDAL(...offset=c(j, 0),...) where j is the
> current line I'm reading.  o_tile = f(i_tile), which is written using
> *writeBin* (not writeGDAL).
> 3) This produces a flat binary file of the sort that Arc binary rasters or
> ENVI rasters use.
>
> So I produce the binary file, but the portion I'm getting a bit hung up on
> is the production of the little text header which completes the file
> (.hdr/.prj for an ESRI raster, .hdr for an ENVI raster, note that the .hdr
> is different between arc and envi).  For this example, let's try to make an
> ENVI header.  Remember i_tile is one of the readGDAL objects of a tiled
> subset of image of filename i:
>
> ***
>
>  gp <- gridparameters(i_tile)
>  cellsize <- gp$cellsize
>  offset <- gp$cellcentre.offset
>  dims <- gp$cells.dim
>  dims[[2]]=rows
>  nbands <- 1
>  tempopen <- GDAL.open(i)
>  file_projection <- getProjectionRef(tempopen)
>  GDAL.close(tempopen)
> # This was from Roger Bivand
>  d.drv <- new("GDALDriver", "ENVI")
>  tds.out <- new("GDALTransientDataset", driver = d.drv, rows = dims[2],cols
> = dims[1], bands = nbands, type = "Float32")
>  gt <- c(offset[1] - 0.5 * cellsize[1], cellsize[1], 0.0,offset[2] +
> (dims[2] -0.5) * cellsize[2], 0.0, -cellsize[2])
>  .Call("RGDAL_SetGeoTransform", tds.out, gt, PACKAGE = "rgdal")
>  .Call("RGDAL_SetProject", tds.out, file_projection, PACKAGE = "rgdal")
>  fn <- tempfile()
>  saveDataset(tds.out, fn)
>  GDAL.close(tds.out)
>  GDAL.close(d.drv)
>
>  temporary_dir=dirname(fn)
>  outdir=dirname(outfile)
>
>  fnhdr<-as.character(paste(basename(fn),outfile_hdr,sep=''))
>  outhdr<-as.character(paste(basename(rasteroutput),outfile_hdr,sep=''))
>
>  setwd(temporary_dir)
>
>  file.rename(fnhdr,outhdr)
>  file.copy(outhdr,outdir,overwrite=TRUE)
>
> ***
>
> So this WORKS the first time I run it, but the SECOND time it is run
> (without quitting out of R) I get the following error:
>>   d.drv <- new("GDALDriver", "ENVI")
> Error in .local(.Object, ...) : No driver registered with name: ENVI
>
> It seems like there is some lingering open driver or something someplace,
> but for the life of me I can't tell where it is.  You can see that I did a
> GDAL.close(d.drv) but that doesn't seem to be sufficient.  Thoughts?
>
> By the way, the full algorithm would deal with RS data of an arbitrary
> number of samples, lines and bands (e.g. hyperspectral processing would be
> completely feasible).  I'm happy to send the script to the list once the
> bugs are worked out!  Thanks!
>
> --j
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From greenberg at ucdavis.edu  Wed Feb 11 01:39:06 2009
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Tue, 10 Feb 2009 16:39:06 -0800
Subject: [R-sig-Geo] Problems freeing rgdal driver...
In-Reply-To: <dc22b2570902101629x6a8a3171hdc88ac20455841cf@mail.gmail.com>
References: <49920EA4.4050005@ucdavis.edu>
	<dc22b2570902101629x6a8a3171hdc88ac20455841cf@mail.gmail.com>
Message-ID: <49921E2A.2070005@ucdavis.edu>

Genius, eliminating the

GDAL.close(d.drv)

does, indeed, work!

--j

Robert Hijmans wrote:
> Hi Jonathan,
>
> I ran into the same problem when writing the writeRaster function in
> the raster package (and see the incipient RemoteSensing package on
> R-forge that uses it); which is very similar.
>
> This is the problem:
>
>   
>> driver = new("GDALDriver", "GTiff")
>> GDAL.close(driver)
>>
>> driver = new("GDALDriver", "GTiff")
>>     
> Error in .local(.Object, ...) : No driver registered with name: GTiff
>   
>> GDAL.close(driver)
>>
>>     
>
> But it does not always happen right away; for some reason.
>
>
> If you omit
>
>   GDAL.close(d.drv)
>
> It will work.
>
> Robert
>
>
> On Wed, Feb 11, 2009 at 7:32 AM, Jonathan Greenberg
> <greenberg at ucdavis.edu> wrote:
>   
>> A few months back I was getting some help with adapting R for doing tiled
>> processing of remote sensing data, and I made some serious headway, but
>> there is a lingering problem I keep scratching my head at.  First off, a
>> quick recap of the base algorithm:
>>
>> 1) Let i = input raster, f() some function to apply to i, and o the output
>> raster, such that o = f(i)
>> 2) i is read in "tiles", each tile read from the input we'll call i_tile (to
>> make it simplest, assume I'm just reading i one line at a time) -- this
>> process is performed using readGDAL(...offset=c(j, 0),...) where j is the
>> current line I'm reading.  o_tile = f(i_tile), which is written using
>> *writeBin* (not writeGDAL).
>> 3) This produces a flat binary file of the sort that Arc binary rasters or
>> ENVI rasters use.
>>
>> So I produce the binary file, but the portion I'm getting a bit hung up on
>> is the production of the little text header which completes the file
>> (.hdr/.prj for an ESRI raster, .hdr for an ENVI raster, note that the .hdr
>> is different between arc and envi).  For this example, let's try to make an
>> ENVI header.  Remember i_tile is one of the readGDAL objects of a tiled
>> subset of image of filename i:
>>
>> ***
>>
>>  gp <- gridparameters(i_tile)
>>  cellsize <- gp$cellsize
>>  offset <- gp$cellcentre.offset
>>  dims <- gp$cells.dim
>>  dims[[2]]=rows
>>  nbands <- 1
>>  tempopen <- GDAL.open(i)
>>  file_projection <- getProjectionRef(tempopen)
>>  GDAL.close(tempopen)
>> # This was from Roger Bivand
>>  d.drv <- new("GDALDriver", "ENVI")
>>  tds.out <- new("GDALTransientDataset", driver = d.drv, rows = dims[2],cols
>> = dims[1], bands = nbands, type = "Float32")
>>  gt <- c(offset[1] - 0.5 * cellsize[1], cellsize[1], 0.0,offset[2] +
>> (dims[2] -0.5) * cellsize[2], 0.0, -cellsize[2])
>>  .Call("RGDAL_SetGeoTransform", tds.out, gt, PACKAGE = "rgdal")
>>  .Call("RGDAL_SetProject", tds.out, file_projection, PACKAGE = "rgdal")
>>  fn <- tempfile()
>>  saveDataset(tds.out, fn)
>>  GDAL.close(tds.out)
>>  GDAL.close(d.drv)
>>
>>  temporary_dir=dirname(fn)
>>  outdir=dirname(outfile)
>>
>>  fnhdr<-as.character(paste(basename(fn),outfile_hdr,sep=''))
>>  outhdr<-as.character(paste(basename(rasteroutput),outfile_hdr,sep=''))
>>
>>  setwd(temporary_dir)
>>
>>  file.rename(fnhdr,outhdr)
>>  file.copy(outhdr,outdir,overwrite=TRUE)
>>
>> ***
>>
>> So this WORKS the first time I run it, but the SECOND time it is run
>> (without quitting out of R) I get the following error:
>>     
>>>   d.drv <- new("GDALDriver", "ENVI")
>>>       
>> Error in .local(.Object, ...) : No driver registered with name: ENVI
>>
>> It seems like there is some lingering open driver or something someplace,
>> but for the life of me I can't tell where it is.  You can see that I did a
>> GDAL.close(d.drv) but that doesn't seem to be sufficient.  Thoughts?
>>
>> By the way, the full algorithm would deal with RS data of an arbitrary
>> number of samples, lines and bands (e.g. hyperspectral processing would be
>> completely feasible).  I'm happy to send the script to the list once the
>> bugs are worked out!  Thanks!
>>
>> --j
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>


From horning at amnh.org  Wed Feb 11 07:40:58 2009
From: horning at amnh.org (Ned Horning)
Date: Wed, 11 Feb 2009 09:40:58 +0300
Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
Message-ID: <499272FA.30902@amnh.org>

Greetings,

I am trying to read an image from GRASS using the spgrass6 command 
readRAST6 and then convert it into a data.frame object so I can use it 
with randomForest. The byte image I'm reading is 2732 rows x 3058 
columns x 3 bands. It's a small subset of a larger image I would like to 
use eventually. I have no problem reading the image using readRAST6 but 
when I try to convert it to a data.frame object my linux system 
resources (1BG RAM, 3GB swap) nearly get maxed out and it runs for a 
couple hours before I kill the process. The image is less than 25MB so 
I'm surprised it requires this level of memory. Can someone let me know 
why this is. Should I use something other than the GRASS interface for 
this? These are the commands I'm using:

spot <- readRAST6(c(?subset.red?, ?subset.green?, ?subset.blue?))
spot_frame <- as(spot, ?data.frame?)

Any help would be appreciated.

All the best,

Ned


From T.Hengl at uva.nl  Wed Feb 11 10:22:57 2009
From: T.Hengl at uva.nl (Hengl, T.)
Date: Wed, 11 Feb 2009 10:22:57 +0100
Subject: [R-sig-Geo] Reading SVG files into R (as spatial polygons/lines)
Message-ID: <37382E8DCB905042969BA78541F6570624D6B6@kwek.ic.uva.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090211/ae32bfe2/attachment.pl>

From Roger.Bivand at nhh.no  Wed Feb 11 10:09:35 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 11 Feb 2009 10:09:35 +0100
Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
References: <499272FA.30902@amnh.org>
Message-ID: <AD51AB79BC327C40AB2C7EB75D57A3C40512E7@TOLAR.valuta.nhh.no>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090211/8a266d5f/attachment.pl>

From ba208 at exeter.ac.uk  Wed Feb 11 10:41:09 2009
From: ba208 at exeter.ac.uk (baptiste auguie)
Date: Wed, 11 Feb 2009 09:41:09 +0000
Subject: [R-sig-Geo] Reading SVG files into R (as spatial polygons/lines)
In-Reply-To: <37382E8DCB905042969BA78541F6570624D6B6@kwek.ic.uva.nl>
References: <37382E8DCB905042969BA78541F6570624D6B6@kwek.ic.uva.nl>
Message-ID: <EA83BDC8-3DEC-46A4-8FF2-12B5D2E262B7@exeter.ac.uk>

Hi,

Perhaps you could try converting to postscript and then importing into  
R with the grImport package? It seems a bit redundant (the postscript  
is going to be converted back into some XML thing) but it might just  
work for simple outlines.

Paul Murrell has a tutorial for this,

http://www.stat.auckland.ac.nz/~paul/R/grImport/import.pdf

(I haven't tried it for SVG pictures)

Hope this helps,

baptiste

On 11 Feb 2009, at 09:22, Hengl, T. wrote:

>
> Dear list,
>
> I discovered recently that Wikipedia has an extensive list of  
> various administrative/political/thematic/historic maps (which are  
> regularly updated!):
>
> http://en.wikipedia.org/wiki/Wikipedia:Blank_maps
>
> The maps are provided in PNG and SVG (Scalable Vector Graphics)  
> formats. The later being recently promoted as the most prefer format  
> for web-graphics (I completely agree). The SVG format is a type of  
> XML, thus it can be directly read to R using the XML package. If I  
> look at the elements of e.g. http://upload.wikimedia.org/wikipedia/commons/0/03/BlankMap-World6.svg 
>  map, I can see that a polygon is coded as:
>
> ----------------------------------------------
> ...
> <g id='fr'>
>                <g class='landxx coastxx fr fx' id='fx'>
>                        <path d='M 1258.5363,351.42953 C  
> 1258.2153,351.09353 1257.8553,350.80453 1257.4563,350.56553 C  
> 1257.5503,351.13153 1257.9293,351.52653 1258.5363,351.42953'  
> id='path2166'/>
> ...
> ----------------------------------------------
>
> which is some small polygon of France. So these are obviously  
> coordinates (the Robinson projection system) of the nodes of that  
> polygon and "id" is it's unique ID.
>
> The issue is how to read a SVG into a GIS/R (see also http://wiki.svg.org/GIS_in_SVG)? 
>  I could not find any 'easy way' do this, although it seems that  
> conversion SVG to GML and then to OGR formats should go easy. I  
> guess that it should not be too complicated to sort all polygons and  
> create a "SpatialPolygonsDataFrame". Did anybody already try  
> something similar?
>
>
> Thanks!
>
> Tom Hengl
> http://spatial-analyst.net
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

_____________________________

Baptiste Augui?

School of Physics
University of Exeter
Stocker Road,
Exeter, Devon,
EX4 4QL, UK

Phone: +44 1392 264187

http://newton.ex.ac.uk/research/emag


From Virgilio.Gomez at uclm.es  Wed Feb 11 12:35:20 2009
From: Virgilio.Gomez at uclm.es (Virgilio Gomez Rubio)
Date: Wed, 11 Feb 2009 12:35:20 +0100
Subject: [R-sig-Geo] [Fwd: Announce: One-day meeting on environmental and
 spatial statistics]
Message-ID: <1234352120.7189.1.camel@Virgilio-Gomez>

Dear all,

Perhaps these events are of interest to some of you.

Best wishes,

Virgilio

--------- Mensaje reenviado --------
De: Dr Sujit Sahu <S.K.Sahu at SOTON.AC.UK>
Reply-to: Dr Sujit Sahu <S.K.Sahu at SOTON.AC.UK>
Para: allstat at JISCMAIL.AC.UK
Asunto: Announce: One-day meeting on environmental and spatial
statistics
Fecha: Wed, 11 Feb 2009 11:00:39 +0000

One-day meeting on environmental and spatial statistics  
Date:  June 19, 2009
Venue: Southampton, UK. 

The meeting is partially sponsored by the Environmental Statistics Section 
of the Royal Statistical Society and the 
Southampton Statistical Sciences Research Institute (S3RI).

The emphasis of the meeting is on environmental applications where 
methodology is drawn from spatial (and possibly temporal) statistics. 
Agreed speakers are Alan Gelfand (Duke University, USA), 
Adrian Bowman (Glasgow), Serge Guillas (UCL), 
Gavin Shaddick (Bath), Li Chen (Bristol), Mark Brewer (BioSS).


This meeting is to be preceded by a three-day (June 16-18) 
short-course on Hierarchical Modelling of Spatial and Temporal 
Data jointly given  by  Prof Alan Gelfand (Duke University, USA) 
and Sujit Sahu (University of Southampton, UK). 

Registration is now open for both the events.   

Further information can be obtained from:  

http://www.s3ri.soton.ac.uk/courses/environmental/
http://www.s3ri.soton.ac.uk/courses/hierarchicalmodelling/

and enquiries at s3ri.soton.ac.uk.


From yong.li at unimelb.edu.au  Wed Feb 11 12:50:04 2009
From: yong.li at unimelb.edu.au (Yong Li)
Date: Wed, 11 Feb 2009 22:50:04 +1100
Subject: [R-sig-Geo] FW:  Interpolation option: IDW or OK?
In-Reply-To: <mailman.11.1234263603.17929.r-sig-geo@stat.math.ethz.ch>
Message-ID: <86DBA0678E017341B449A62F258E29561549CA@IS-EX-BEV3.unimelb.edu.au>

Hi Edzer,

I found a problem with gstat "krige" prediction if I am correct this
time. For example, with OLSENP variable in my dataset, I developed a
theoretical model for log(OLSENP) variogram: model=exp, c0=0.2019,
c1=0.2218 and Range=162 meters. By using this model, I predicted the
OLSENP surface using gstat krige and ArcGIS Spatial Analyst with the
same nmax and found the results are significantly different. gstat
significantly underestimated values (here is where I had an idea to use
IDW), but Spatial Analyst gave very reliable predictions. I would like
you to double check the algorithms behind gstat. 

By the way, I start to puzzle because I used gstat to calculate other
variables in my dataset, such as total nitrogen and extractable
potassium and also I used gstat to run a series regression-kriging to
predict soil organic matter distribution and submitted to a journal
already.
     
I appreciate you could give me your response as soon as possible.

Regards

Yong Li

-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
r-sig-geo-request at stat.math.ethz.ch
Sent: Tuesday, 10 February 2009 10:00 PM
To: r-sig-geo at stat.math.ethz.ch
Subject: R-sig-Geo Digest, Vol 66, Issue 10

Send R-sig-Geo mailing list submissions to
	r-sig-geo at stat.math.ethz.ch

To subscribe or unsubscribe via the World Wide Web, visit
	https://stat.ethz.ch/mailman/listinfo/r-sig-geo
or, via email, send a message with subject or body 'help' to
	r-sig-geo-request at stat.math.ethz.ch

You can reach the person managing the list at
	r-sig-geo-owner at stat.math.ethz.ch

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-Geo digest..."


Today's Topics:

   1. error rgdal library if used from within Grass plugin
      (Windows) (Agustin Lobo)
   2. Re: error rgdal library if used from within Grass plugin
      (Windows) (Roger Bivand)
   3. Re: FW:  Interpolcation option: IDW or OK? (Tomislav Hengl)
   4. Calculating descriptive stats from many maps (Rainer M Krug)
   5. Re: Calculating descriptive stats from many maps (Tomislav Hengl)
   6. Re: Calculating descriptive stats from many maps (Roger Bivand)
   7. Interpolcation option: IDW or OK? (Yong Li)
   8. Re: Calculating descriptive stats from many maps (Robert Hijmans)
   9. Re: FW: Interpolcation option: IDW or OK? (Robert Hijmans)
  10. Re: Calculating descriptive stats from many maps (Rainer M Krug)


----------------------------------------------------------------------

Message: 1
Date: Mon, 09 Feb 2009 15:06:24 +0100
From: Agustin Lobo <aloboaleu at gmail.com>
Subject: [R-sig-Geo] error rgdal library if used from within Grass
	plugin	(Windows)
To: r-sig-geo at stat.math.ethz.ch
Message-ID: <49903860.8060406 at gmail.com>
Content-Type: text/plain; charset=iso-8859-1; format=flowed

Hi!

The following error only occurs if the R (2.7.2) session is started
from a GRASS shell opened through the QGIS GRASS plugin in windows.
The error does not occur If R is started form its own icon
or by double click in the .RData  object,  but then the spgrass6
package would not find the GRASS environment.

It also works in linux.
The involved  commands  are:

1. Start  QGIS
2. Star GRASS plugin and open mapset
3.  Open Grass Shell
4.  Run R and execute require(spgrass6)

>>>>
>>>> Loading required package: spgrass6
>>>> Loading required package: sp
>>>> Loading required package: rgdal
>>>> Error in fun(...) :
>>>>         GDAL Error 1: Can't load requested DLL:
>>>> C:\OSGeo4W\bin\gdalplugins\gdal_ECW_JP2ECW.dll
>>>> 126: N?o foi poss?vel encontrar o m?dulo especificado.
>>>>
>>>>
>>>>
>>>> Error : .onLoad failed in 'loadNamespace' for 'rgdal'
>>>> Erro: package 'rgdal' could not be loaded

Any help appreciated.

Agus

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



------------------------------

Message: 2
Date: Mon, 9 Feb 2009 16:21:25 +0100 (CET)
From: Roger Bivand <Roger.Bivand at nhh.no>
Subject: Re: [R-sig-Geo] error rgdal library if used from within Grass
	plugin (Windows)
To: Agustin.Lobo at ija.csic.es
Cc: r-sig-geo at stat.math.ethz.ch
Message-ID: <alpine.LRH.2.00.0902091618410.12628 at reclus.nhh.no>
Content-Type: text/plain; charset="iso-8859-1"; Format="flowed"

On Mon, 9 Feb 2009, Agustin Lobo wrote:

> Hi!
>
> The following error only occurs if the R (2.7.2) session is started
> from a GRASS shell opened through the QGIS GRASS plugin in windows.
> The error does not occur If R is started form its own icon
> or by double click in the .RData  object,  but then the spgrass6
> package would not find the GRASS environment.
>
> It also works in linux.
> The involved  commands  are:
>
> 1. Start  QGIS
> 2. Star GRASS plugin and open mapset
> 3.  Open Grass Shell
> 4.  Run R and execute require(spgrass6)
>
>>>>> 
>>>>> Loading required package: spgrass6
>>>>> Loading required package: sp
>>>>> Loading required package: rgdal
>>>>> Error in fun(...) :
>>>>>         GDAL Error 1: Can't load requested DLL:
>>>>> C:\OSGeo4W\bin\gdalplugins\gdal_ECW_JP2ECW.dll
>>>>> 126: N?o foi poss?vel encontrar o m?dulo especificado.
>>>>> 
>>>>> 
>>>>> 
>>>>> Error : .onLoad failed in 'loadNamespace' for 'rgdal'
>>>>> Erro: package 'rgdal' could not be loaded

Which rgdal binary from where? This really is a question for osgeo4w, 
which is bleeding edge at the moment. Are you using the early draft
rgdal 
binary built against a specific osgeo4w version and available from my 
website? Can we settle this off-list until osgeo4w stabilises?

Roger

>
> Any help appreciated.
>
> Agus
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

------------------------------

Message: 3
Date: Mon, 9 Feb 2009 16:55:51 +0100
From: "Tomislav Hengl" <T.Hengl at uva.nl>
Subject: Re: [R-sig-Geo] FW:  Interpolcation option: IDW or OK?
To: <r-sig-geo at stat.math.ethz.ch>
Message-ID: <ECA350872DC649129EF25F1C51EBCFFA at pcibed193>
Content-Type: text/plain;	charset="windows-1250"


Dear Yong Li,

I hope you will not mind me joining this interesting discussion. 

If there is no evident spatial auto-correlation structure (pure nugget
effect), IDW/OK are as good
as randomly drawing a value from the global (normal) distribution. You
can even test this using
cross-validation! In principle, there is no justification to use
distance-based interpolators if
there is no evident spatial auto-correlation structure (maybe only the
moving-window kriging, as
implemented in e.g. Vesper, or stratified kriging techniques could
discover some local spatial
dependence). In addition, IDW should be considered an outdated
technique, applicable only for
situations where the variogram is close to linear (e.g. elevation data
and similar smooth surfaces).

What you should really consider using are the globaly available free
maps/images (e.g. MODIS EVI,
SRTM DEM parameters etc.), and then see if you can explain some of the
variability in your target
variable. 

But there will always be situations (especially in DSM applications)
where you simply can not
explain much of the target variability, neither with auxiliary maps nor
with spatial
auto-correlation. What to do then? I guess you simply have to collect
more samples / more auxiliary
maps and then try again.

HTH

T. Hengl

See also:

Compendium of Global datasets:
http://spatial-analyst.net/wiki/index.php?title=Global_datasets

Regression-kriging:
http://spatial-analyst.net/wiki/index.php?title=Regression-kriging

Pebesma, E., 2006. The Role of External Variables and GIS Databases in
Geostatistical Analysis.
Transactions in GIS, 10(4): 615-632.
http://dx.doi.org/10.1111/j.1467-9671.2006.01015.x 


> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
> Of Edzer Pebesma
> Sent: Monday, February 09, 2009 9:08 AM
> To: Yong Li
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] FW: Interpolcation option: IDW or OK?
> 
> Yong Li wrote:
> > Hi Edzer,
> >
> > I would say the spatial structure is regarded not significant when
c0/c0+c1 is very much greater
> than 75%. In my case I used even distance intervals and calculated
c0/c0+c1 for log(OLSENP)
> greater than 85%. I knew this index sometimes is very fragile, very
much depending on how we fit
> the model.
> >
> > However when I zoomed in by using variable distance intervals
> (boundaries=c(100,200,300,400,600,900,1000,1500,2000))and maxdist=2000
meters, I found a pretty
> good model-fitted experimental variogram. But the local OK
interpolation using such a fitted model
> did not make sense when compared the predictions to the observations
as in most areas values of
> OLSENP were severely underestimated. You may have seen my code with
which I have tried the nested
> models, but unfortunately no luck either. I maybe think the parameters
for local ordinary kriging
> are not optimized, but I have tried lots of sets of nmin, nmax and
maxdist and did see the hopeful
> end.
> >
> > The journal editor insists in OK being better than IDW. I need to
collect my evidence to defend
> my IDW choice. That is my intention raised such a question in our
forum here.
> >
> I cannot find evidence in your data for such a claim; the cross
> validation statistics (rmse) seem to favour OK with your nested model.
> 
> In your first email, you stated the following:
> >> Normally if we do not find a significant spatial structure for a
soil
> >> variable, we may choose IDW or other methods.
> What is the argumentation behind this? Who claimed this?
> 
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
> http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



------------------------------

Message: 4
Date: Mon, 9 Feb 2009 17:58:26 +0200
From: Rainer M Krug <r.m.krug at gmail.com>
Subject: [R-sig-Geo] Calculating descriptive stats from many maps
To: R-sig-Geo at stat.math.ethz.ch
Message-ID:
	<fb7c7e870902090758n66f987fk122de94146c13fe4 at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

Hi

I have 25000 maps, generated by simulation predictions, covering the
same area, and would like to calculate some descriptive stats, like
mean, standard deviation, median, quartiles of all cells, to create a
"variability map".

Is there an easy way of doing this in R?

Thanks,

Rainer

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Faculty of Science
Natural Sciences Building
Private Bag X1
University of Stellenbosch
Matieland 7602
South Africa



------------------------------

Message: 5
Date: Mon, 9 Feb 2009 17:33:51 +0100
From: "Tomislav Hengl" <T.Hengl at uva.nl>
Subject: Re: [R-sig-Geo] Calculating descriptive stats from many maps
To: <R-sig-Geo at stat.math.ethz.ch>
Message-ID: <D0BA11FFBCAD490B9D79F65EAC48FDE9 at pcibed193>
Content-Type: text/plain;	charset="windows-1250"


Dear Rainer,

This is of course possible in R, and can be done in several ways:

1) for example, you can derive the average value using the rowSums
function:

> maps$Nsum <- rowSums(maps at data, na.rm=T, dims=1)
> maps$avg <- maps$Nsum/(length(names(meuse.grid at data))-1)

You could also loop the sd, mean and quantile function over a range of
cells:

> for(i in length(names(maps at data))) {
> maps at data$sd[i] <- sd(maps at data[i,])
> maps at data$mean[i] <- mean(maps at data[i,])
...
> }

This could take a lot of time!

2) if your maps are rather large, try also using the SAGA function:

> rsaga.get.usage(lib = "geostatistics_grid", module=5)
SAGA CMD 2.0.3
library path:   C:/Progra~1/saga_vc/modules
library name:   geostatistics_grid
module name :   Statistics for Grids

This is probably the fastest method you can use.

HTH

T. Hengl

> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
> Of Rainer M Krug
> Sent: Monday, February 09, 2009 4:58 PM
> To: R-sig-Geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] Calculating descriptive stats from many maps
> 
> Hi
> 
> I have 25000 maps, generated by simulation predictions, covering the
> same area, and would like to calculate some descriptive stats, like
> mean, standard deviation, median, quartiles of all cells, to create a
> "variability map".
> 
> Is there an easy way of doing this in R?
> 
> Thanks,
> 
> Rainer
> 
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
> Biology, UCT), Dipl. Phys. (Germany)
> 
> Centre of Excellence for Invasion Biology
> Faculty of Science
> Natural Sciences Building
> Private Bag X1
> University of Stellenbosch
> Matieland 7602
> South Africa
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



------------------------------

Message: 6
Date: Mon, 9 Feb 2009 18:05:25 +0100 (CET)
From: Roger Bivand <Roger.Bivand at nhh.no>
Subject: Re: [R-sig-Geo] Calculating descriptive stats from many maps
To: Tomislav Hengl <T.Hengl at uva.nl>
Cc: R-sig-Geo at stat.math.ethz.ch
Message-ID: <alpine.LRH.2.00.0902091800170.15636 at reclus.nhh.no>
Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed

On Mon, 9 Feb 2009, Tomislav Hengl wrote:

>
> Dear Rainer,
>
> This is of course possible in R, and can be done in several ways:
>
> 1) for example, you can derive the average value using the rowSums
function:
>
>> maps$Nsum <- rowSums(maps at data, na.rm=T, dims=1)
>> maps$avg <- maps$Nsum/(length(names(meuse.grid at data))-1)
>
> You could also loop the sd, mean and quantile function over a range of
cells:
>
>> for(i in length(names(maps at data))) {
>> maps at data$sd[i] <- sd(maps at data[i,])
>> maps at data$mean[i] <- mean(maps at data[i,])
> ...
>> }
>
> This could take a lot of time!

Tom, Rainer,

Yes, using sapply(slot(maps, "data"), summary) or similar, you get the 
map-wise statistics. But have I misunderstood, or are the statistics in 
question cell-wise? This would involve stacking subset areas for all 25'

maps, wouldn't it? Brutally, a loop in readGDAL() from rgdal with
offset= 
and region.dim= shifted? Is there a canned way to do this in the R-forge

raster package (by the way, regularly one of the R-forge packages
showing 
most developer activity)?

Roger

>
> 2) if your maps are rather large, try also using the SAGA function:
>
>> rsaga.get.usage(lib = "geostatistics_grid", module=5)
> SAGA CMD 2.0.3
> library path:   C:/Progra~1/saga_vc/modules
> library name:   geostatistics_grid
> module name :   Statistics for Grids
>
> This is probably the fastest method you can use.
>
> HTH
>
> T. Hengl
>
>> -----Original Message-----
>> From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
>> Of Rainer M Krug
>> Sent: Monday, February 09, 2009 4:58 PM
>> To: R-sig-Geo at stat.math.ethz.ch
>> Subject: [R-sig-Geo] Calculating descriptive stats from many maps
>>
>> Hi
>>
>> I have 25000 maps, generated by simulation predictions, covering the
>> same area, and would like to calculate some descriptive stats, like
>> mean, standard deviation, median, quartiles of all cells, to create a
>> "variability map".
>>
>> Is there an easy way of doing this in R?
>>
>> Thanks,
>>
>> Rainer
>>
>> --
>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
>> Biology, UCT), Dipl. Phys. (Germany)
>>
>> Centre of Excellence for Invasion Biology
>> Faculty of Science
>> Natural Sciences Building
>> Private Bag X1
>> University of Stellenbosch
>> Matieland 7602
>> South Africa
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



------------------------------

Message: 7
Date: Tue, 10 Feb 2009 10:40:40 +1100
From: Yong Li <yong.li at unimelb.edu.au>
Subject: [R-sig-Geo] Interpolcation option: IDW or OK?
To: Edzer Pebesma <edzer.pebesma at uni-muenster.de>
Cc: r-sig-geo at stat.math.ethz.ch
Message-ID:
	
<86DBA0678E017341B449A62F258E29561549C6 at IS-EX-BEV3.unimelb.edu.au>
Content-Type: text/plain; charset=us-ascii

Many thanks for the message, Edzer.

-----Original Message-----
From: Edzer Pebesma [mailto:edzer.pebesma at uni-muenster.de] 
Sent: Monday, 9 February 2009 7:08 PM
To: Yong Li
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: FW: [R-sig-Geo] Interpolcation option: IDW or OK?

Yong Li wrote:
> Hi Edzer,
>
> I would say the spatial structure is regarded not significant when
c0/c0+c1 is very much greater than 75%. In my case I used even distance
intervals and calculated c0/c0+c1 for log(OLSENP) greater than 85%. I
knew this index sometimes is very fragile, very much depending on how we
fit the model.
>
> However when I zoomed in by using variable distance intervals
(boundaries=c(100,200,300,400,600,900,1000,1500,2000))and maxdist=2000
meters, I found a pretty good model-fitted experimental variogram. But
the local OK interpolation using such a fitted model did not make sense
when compared the predictions to the observations as in most areas
values of OLSENP were severely underestimated. You may have seen my code
with which I have tried the nested models, but unfortunately no luck
either. I maybe think the parameters for local ordinary kriging are not
optimized, but I have tried lots of sets of nmin, nmax and maxdist and
did see the hopeful end.
>
> The journal editor insists in OK being better than IDW. I need to
collect my evidence to defend my IDW choice. That is my intention raised
such a question in our forum here.
>   
I cannot find evidence in your data for such a claim; the cross 
validation statistics (rmse) seem to favour OK with your nested model.

YONGLI==================================================================
====
Could you have a look at the predictions generated by my nested model
and compare to the observations? The values were severely
underestimated. 
YONGLI==================================================================
====

In your first email, you stated the following:
>> Normally if we do not find a significant spatial structure for a soil
>> variable, we may choose IDW or other methods. 
What is the argumentation behind this? Who claimed this?

YONGLI==================================================================
====
Could you have a look at "Mueller et al. (2004) Map Quality for Ordinary
Kriging and Inverse Distance Weighted Interpolation. Soil Sci. Soc. Am.
J. 68:2042-2047."? 
YONGLI==================================================================
====

Regards,

Yong Li



------------------------------

Message: 8
Date: Tue, 10 Feb 2009 10:07:11 +0800
From: Robert Hijmans <r.hijmans at gmail.com>
Subject: Re: [R-sig-Geo] Calculating descriptive stats from many maps
To: R-sig-Geo at stat.math.ethz.ch
Message-ID:
	<dc22b2570902091807m4698caf7xbe79e562da35bce2 at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

Dear Rainer,

This is how can you can do it with the raster package

# install.packages("raster", repos="http://R-Forge.R-project.org")
require(raster)

# Try it for a few files first..
n <- 10

# create a list (or vector) of file names, e.g. :
fn <- list()
for (i in 1:n) { fn[i] <- paste('myfile', i, '.tif', sep='') }

# make a RasterStack
s <- stack(fn)

r1 <- mCalc(s, fun=mean)
r2 <- mCalc(s, fun=sd)

#r can be plotted, coerced to sp objects, etc.
plot(r1)

# or saved to file
r1 <- setFilename(r1, 'cellmeans.tif')
r1 <- writeRaster(r1, format='GTiff')


Robert


On Tue, Feb 10, 2009 at 1:05 AM, Roger Bivand <Roger.Bivand at nhh.no>
wrote:
> On Mon, 9 Feb 2009, Tomislav Hengl wrote:
>
>>
>> Dear Rainer,
>>
>> This is of course possible in R, and can be done in several ways:
>>
>> 1) for example, you can derive the average value using the rowSums
>> function:
>>
>>> maps$Nsum <- rowSums(maps at data, na.rm=T, dims=1)
>>> maps$avg <- maps$Nsum/(length(names(meuse.grid at data))-1)
>>
>> You could also loop the sd, mean and quantile function over a range
of
>> cells:
>>
>>> for(i in length(names(maps at data))) {
>>> maps at data$sd[i] <- sd(maps at data[i,])
>>> maps at data$mean[i] <- mean(maps at data[i,])
>>
>> ...
>>>
>>> }
>>
>> This could take a lot of time!
>
> Tom, Rainer,
>
> Yes, using sapply(slot(maps, "data"), summary) or similar, you get the
> map-wise statistics. But have I misunderstood, or are the statistics
in
> question cell-wise? This would involve stacking subset areas for all
25'
> maps, wouldn't it? Brutally, a loop in readGDAL() from rgdal with
offset=
> and region.dim= shifted? Is there a canned way to do this in the
R-forge
> raster package (by the way, regularly one of the R-forge packages
showing
> most developer activity)?
>
> Roger
>
>>
>> 2) if your maps are rather large, try also using the SAGA function:
>>
>>> rsaga.get.usage(lib = "geostatistics_grid", module=5)
>>
>> SAGA CMD 2.0.3
>> library path:   C:/Progra~1/saga_vc/modules
>> library name:   geostatistics_grid
>> module name :   Statistics for Grids
>>
>> This is probably the fastest method you can use.
>>
>> HTH
>>
>> T. Hengl
>>
>>> -----Original Message-----
>>> From: r-sig-geo-bounces at stat.math.ethz.ch
>>> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
>>> Of Rainer M Krug
>>> Sent: Monday, February 09, 2009 4:58 PM
>>> To: R-sig-Geo at stat.math.ethz.ch
>>> Subject: [R-sig-Geo] Calculating descriptive stats from many maps
>>>
>>> Hi
>>>
>>> I have 25000 maps, generated by simulation predictions, covering the
>>> same area, and would like to calculate some descriptive stats, like
>>> mean, standard deviation, median, quartiles of all cells, to create
a
>>> "variability map".
>>>
>>> Is there an easy way of doing this in R?
>>>
>>> Thanks,
>>>
>>> Rainer
>>>
>>> --
>>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
>>> Biology, UCT), Dipl. Phys. (Germany)
>>>
>>> Centre of Excellence for Invasion Biology
>>> Faculty of Science
>>> Natural Sciences Building
>>> Private Bag X1
>>> University of Stellenbosch
>>> Matieland 7602
>>> South Africa
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School
of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



------------------------------

Message: 9
Date: Tue, 10 Feb 2009 12:44:57 +0800
From: Robert Hijmans <r.hijmans at gmail.com>
Subject: Re: [R-sig-Geo] FW: Interpolcation option: IDW or OK?
To: Tomislav Hengl <T.Hengl at uva.nl>
Cc: r-sig-geo at stat.math.ethz.ch
Message-ID:
	<dc22b2570902092044w29078ad6yad92a971f376b662 at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

Why not use cross-validation to empirically determine which method
performs best for this dataset (in addition to asking if they are
better than a random draw)?  Robert

2009/2/9 Tomislav Hengl <T.Hengl at uva.nl>:
>
> Dear Yong Li,
>
> I hope you will not mind me joining this interesting discussion.
>
> If there is no evident spatial auto-correlation structure (pure nugget
effect), IDW/OK are as good
> as randomly drawing a value from the global (normal) distribution. You
can even test this using
> cross-validation! In principle, there is no justification to use
distance-based interpolators if
> there is no evident spatial auto-correlation structure (maybe only the
moving-window kriging, as
> implemented in e.g. Vesper, or stratified kriging techniques could
discover some local spatial
> dependence). In addition, IDW should be considered an outdated
technique, applicable only for
> situations where the variogram is close to linear (e.g. elevation data
and similar smooth surfaces).
>
> What you should really consider using are the globaly available free
maps/images (e.g. MODIS EVI,
> SRTM DEM parameters etc.), and then see if you can explain some of the
variability in your target
> variable.
>
> But there will always be situations (especially in DSM applications)
where you simply can not
> explain much of the target variability, neither with auxiliary maps
nor with spatial
> auto-correlation. What to do then? I guess you simply have to collect
more samples / more auxiliary
> maps and then try again.
>
> HTH
>
> T. Hengl
>
> See also:
>
> Compendium of Global datasets:
> http://spatial-analyst.net/wiki/index.php?title=Global_datasets
>
> Regression-kriging:
> http://spatial-analyst.net/wiki/index.php?title=Regression-kriging
>
> Pebesma, E., 2006. The Role of External Variables and GIS Databases in
Geostatistical Analysis.
> Transactions in GIS, 10(4): 615-632.
> http://dx.doi.org/10.1111/j.1467-9671.2006.01015.x
>
>
>> -----Original Message-----
>> From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
>> Of Edzer Pebesma
>> Sent: Monday, February 09, 2009 9:08 AM
>> To: Yong Li
>> Cc: r-sig-geo at stat.math.ethz.ch
>> Subject: Re: [R-sig-Geo] FW: Interpolcation option: IDW or OK?
>>
>> Yong Li wrote:
>> > Hi Edzer,
>> >
>> > I would say the spatial structure is regarded not significant when
c0/c0+c1 is very much greater
>> than 75%. In my case I used even distance intervals and calculated
c0/c0+c1 for log(OLSENP)
>> greater than 85%. I knew this index sometimes is very fragile, very
much depending on how we fit
>> the model.
>> >
>> > However when I zoomed in by using variable distance intervals
>> (boundaries=c(100,200,300,400,600,900,1000,1500,2000))and
maxdist=2000 meters, I found a pretty
>> good model-fitted experimental variogram. But the local OK
interpolation using such a fitted model
>> did not make sense when compared the predictions to the observations
as in most areas values of
>> OLSENP were severely underestimated. You may have seen my code with
which I have tried the nested
>> models, but unfortunately no luck either. I maybe think the
parameters for local ordinary kriging
>> are not optimized, but I have tried lots of sets of nmin, nmax and
maxdist and did see the hopeful
>> end.
>> >
>> > The journal editor insists in OK being better than IDW. I need to
collect my evidence to defend
>> my IDW choice. That is my intention raised such a question in our
forum here.
>> >
>> I cannot find evidence in your data for such a claim; the cross
>> validation statistics (rmse) seem to favour OK with your nested
model.
>>
>> In your first email, you stated the following:
>> >> Normally if we do not find a significant spatial structure for a
soil
>> >> variable, we may choose IDW or other methods.
>> What is the argumentation behind this? Who claimed this?
>>
>> --
>> Edzer Pebesma
>> Institute for Geoinformatics (ifgi), University of M?nster
>> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
>> 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
>> http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



------------------------------

Message: 10
Date: Tue, 10 Feb 2009 10:29:25 +0200
From: Rainer M Krug <r.m.krug at gmail.com>
Subject: Re: [R-sig-Geo] Calculating descriptive stats from many maps
To: Robert Hijmans <r.hijmans at gmail.com>
Cc: R-sig-Geo at stat.math.ethz.ch
Message-ID:
	<fb7c7e870902100029kf6e436du542afd36c4067f2f at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

Thanks a lot to all of you.

You are right Roger, I need cell-wise statistics

I like the idea of the "raster" package, and I will try it out just now.

Concerning SAGA: I'll look into that if "raster" does not work (or is to
slow).

I'll report back

Rainer


On Tue, Feb 10, 2009 at 4:07 AM, Robert Hijmans <r.hijmans at gmail.com>
wrote:
> Dear Rainer,
>
> This is how can you can do it with the raster package
>
> # install.packages("raster", repos="http://R-Forge.R-project.org")
> require(raster)
>
> # Try it for a few files first..
> n <- 10
>
> # create a list (or vector) of file names, e.g. :
> fn <- list()
> for (i in 1:n) { fn[i] <- paste('myfile', i, '.tif', sep='') }
>
> # make a RasterStack
> s <- stack(fn)
>
> r1 <- mCalc(s, fun=mean)
> r2 <- mCalc(s, fun=sd)
>
> #r can be plotted, coerced to sp objects, etc.
> plot(r1)
>
> # or saved to file
> r1 <- setFilename(r1, 'cellmeans.tif')
> r1 <- writeRaster(r1, format='GTiff')
>
>
> Robert
>
>
> On Tue, Feb 10, 2009 at 1:05 AM, Roger Bivand <Roger.Bivand at nhh.no>
wrote:
>> On Mon, 9 Feb 2009, Tomislav Hengl wrote:
>>
>>>
>>> Dear Rainer,
>>>
>>> This is of course possible in R, and can be done in several ways:
>>>
>>> 1) for example, you can derive the average value using the rowSums
>>> function:
>>>
>>>> maps$Nsum <- rowSums(maps at data, na.rm=T, dims=1)
>>>> maps$avg <- maps$Nsum/(length(names(meuse.grid at data))-1)
>>>
>>> You could also loop the sd, mean and quantile function over a range
of
>>> cells:
>>>
>>>> for(i in length(names(maps at data))) {
>>>> maps at data$sd[i] <- sd(maps at data[i,])
>>>> maps at data$mean[i] <- mean(maps at data[i,])
>>>
>>> ...
>>>>
>>>> }
>>>
>>> This could take a lot of time!
>>
>> Tom, Rainer,
>>
>> Yes, using sapply(slot(maps, "data"), summary) or similar, you get
the
>> map-wise statistics. But have I misunderstood, or are the statistics
in
>> question cell-wise? This would involve stacking subset areas for all
25'
>> maps, wouldn't it? Brutally, a loop in readGDAL() from rgdal with
offset=
>> and region.dim= shifted? Is there a canned way to do this in the
R-forge
>> raster package (by the way, regularly one of the R-forge packages
showing
>> most developer activity)?
>>
>> Roger
>>
>>>
>>> 2) if your maps are rather large, try also using the SAGA function:
>>>
>>>> rsaga.get.usage(lib = "geostatistics_grid", module=5)
>>>
>>> SAGA CMD 2.0.3
>>> library path:   C:/Progra~1/saga_vc/modules
>>> library name:   geostatistics_grid
>>> module name :   Statistics for Grids
>>>
>>> This is probably the fastest method you can use.
>>>
>>> HTH
>>>
>>> T. Hengl
>>>
>>>> -----Original Message-----
>>>> From: r-sig-geo-bounces at stat.math.ethz.ch
>>>> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
>>>> Of Rainer M Krug
>>>> Sent: Monday, February 09, 2009 4:58 PM
>>>> To: R-sig-Geo at stat.math.ethz.ch
>>>> Subject: [R-sig-Geo] Calculating descriptive stats from many maps
>>>>
>>>> Hi
>>>>
>>>> I have 25000 maps, generated by simulation predictions, covering
the
>>>> same area, and would like to calculate some descriptive stats, like
>>>> mean, standard deviation, median, quartiles of all cells, to create
a
>>>> "variability map".
>>>>
>>>> Is there an easy way of doing this in R?
>>>>
>>>> Thanks,
>>>>
>>>> Rainer
>>>>
>>>> --
>>>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
>>>> Biology, UCT), Dipl. Phys. (Germany)
>>>>
>>>> Centre of Excellence for Invasion Biology
>>>> Faculty of Science
>>>> Natural Sciences Building
>>>> Private Bag X1
>>>> University of Stellenbosch
>>>> Matieland 7602
>>>> South Africa
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School
of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Faculty of Science
Natural Sciences Building
Private Bag X1
University of Stellenbosch
Matieland 7602
South Africa



------------------------------

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


End of R-sig-Geo Digest, Vol 66, Issue 10


From r.hijmans at gmail.com  Wed Feb 11 13:12:41 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Wed, 11 Feb 2009 20:12:41 +0800
Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
In-Reply-To: <AD51AB79BC327C40AB2C7EB75D57A3C40512E7@TOLAR.valuta.nhh.no>
References: <499272FA.30902@amnh.org>
	<AD51AB79BC327C40AB2C7EB75D57A3C40512E7@TOLAR.valuta.nhh.no>
Message-ID: <dc22b2570902110412v3130519aiff3deaf23e29ce32@mail.gmail.com>

Ned,

This is an example of running a RandomForest prediction with the
raster package (for the simple case that there are no NA values in the
raster data; if there are, you have to into account that "predict'
does not return any values (not even NA) for those cells).

Robert

#install.packages("raster", repos="http://R-Forge.R-project.org")
require(raster)
require(randomForest)

# for single band files
spot <- stack('b1.tif', 'b2.tif', 'b3.tif')
# for multiple band files
# spot <- stackFromFiles(c('bands.tif', 'bands.tif', 'bands.tif'), c(1,2,3) )

# simulate random points and values to model with
xy <- xyFromCell(spot, round(runif(100) * ncell(spot)))
response <- runif(100) * 100
# read values of raster layers at points, and bind to respinse
trainvals <- cbind(response, xyValues(spot, xy))

# run RandomForest
randfor <- randomForest(response ~ b1 + b2 + b3, data=trainvals)

# apply the prediction, row by row
predrast <- setRaster(spot)
filename(predrast) <- 'RF_pred.grd'
for (r in 1:nrow(spot)) {
	spot <- readRow(spot, r)
	rowvals <- values(spot, names=TRUE)
# this next line should not be necessary, but it is
# I'll fix that
	colnames(rowvals) <- c('b1', 'b2', 'b3')
	pred <- predict(randfor, rowvals)
	predrast <- setValues(predrast, pred, r)
	predrast <- writeRaster(predrast, overwrite=TRUE)
}

plot(predrast)




On Wed, Feb 11, 2009 at 5:09 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> Ned:
>
>
> The three bands are most likely treated as 4-byte integers, so the object
> will be 2732 by 3058 by 3 by 4 plus a little bit. That's 100MB. They may
> get copied too. There are no single byte user-level containers for you
> (there is a raw data type, but you can't calculate with it). Possibly
> saying spot_frame <- slot(spot, "data") will save one copying operation,
> but its hard to tell - your choice of method first adds inn all the
> coordinates, which are 8-byte numbers, so more than doubles its size and
> makes more copies (to 233MB for each copy). Running gc() several times
> manually between steps often helps by making the garbage collector more
> aggressive.
>
> I would watch the developments in the R-Forge package "raster", which
> builds on some of these things, and try to see how that works. If you have
> the GDAL-GRASS plugin for rasters, you can use readGDAL to read from GRASS
> - which would work with raster package functions now. Look at the code of
> recent readRAST6 to see which incantations are needed. If you are going to
> use randomForest for prediction, you can use smaller tiles until you find
> an alternative solution. Note that feeding a data frame of integers to a
> model fitting or prediction function will result in coercion to a
> matrix of doubles, so your subsequent workflow should take that into
> account.
>  Getting more memory is another option, and may be very cost and especially
> time effective - at the moment your machine is swapping. Buying memory may
> save you time programming around too little memory.
>
> Hope this helps,
>
> Roger
>
>
> ---
> Roger Bivand, NHH, Helleveien 30, N-5045 Bergen,
> Roger.Bivand at nhh.no
>
>
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Ned Horning
> Sent: Wed 11.02.2009 07:40
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
>
> Greetings,
>
> I am trying to read an image from GRASS using the spgrass6 command
> readRAST6 and then convert it into a data.frame object so I can use it
> with randomForest. The byte image I'm reading is 2732 rows x 3058
> columns x 3 bands. It's a small subset of a larger image I would like to
> use eventually. I have no problem reading the image using readRAST6 but
> when I try to convert it to a data.frame object my linux system
> resources (1BG RAM, 3GB swap) nearly get maxed out and it runs for a
> couple hours before I kill the process. The image is less than 25MB so
> I'm surprised it requires this level of memory. Can someone let me know
> why this is. Should I use something other than the GRASS interface for
> this? These are the commands I'm using:
>
> spot <- readRAST6(c("subset.red", "subset.green", "subset.blue"))
> spot_frame <- as(spot, "data.frame")
>
> Any help would be appreciated.
>
> All the best,
>
> Ned
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From b.rowlingson at lancaster.ac.uk  Wed Feb 11 13:25:56 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 11 Feb 2009 12:25:56 +0000
Subject: [R-sig-Geo] Reading SVG files into R (as spatial polygons/lines)
In-Reply-To: <EA83BDC8-3DEC-46A4-8FF2-12B5D2E262B7@exeter.ac.uk>
References: <37382E8DCB905042969BA78541F6570624D6B6@kwek.ic.uva.nl>
	<EA83BDC8-3DEC-46A4-8FF2-12B5D2E262B7@exeter.ac.uk>
Message-ID: <d8ad40b50902110425x29a0c89u7443430738563c8a@mail.gmail.com>

2009/2/11 baptiste auguie <ba208 at exeter.ac.uk>:
> Hi,
>
> Perhaps you could try converting to postscript and then importing into R
> with the grImport package? It seems a bit redundant (the postscript is going
> to be converted back into some XML thing) but it might just work for simple
> outlines.

 And heaven only knows what projection the data will be in after
PostScript has played with it...

 You could try reading the XML and getting the coords out - but
beware! SVG can do all sorts of things. Some of the polygons in one of
the wikipedia examples I looked at are grouped into SVG <g> tags with
"translate" parameters, so all those coords need shifting. I think you
really need to process the SVG rather than try to parse it.

 I've not looked to see what the python script here does:
   http://gsl-nagoya-u.net/appendix/software/worldmap/

Barry


From horning at amnh.org  Wed Feb 11 16:16:00 2009
From: horning at amnh.org (Ned Horning)
Date: Wed, 11 Feb 2009 18:16:00 +0300
Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
In-Reply-To: <dc22b2570902110412v3130519aiff3deaf23e29ce32@mail.gmail.com>
References: <499272FA.30902@amnh.org>	
	<AD51AB79BC327C40AB2C7EB75D57A3C40512E7@TOLAR.valuta.nhh.no>
	<dc22b2570902110412v3130519aiff3deaf23e29ce32@mail.gmail.com>
Message-ID: <4992EBB0.20400@amnh.org>

Robert and Roger,

Thanks for the information and pointers. The raster package looks quite 
interesting and I'll try to get up to speed on some of its capabilities. 
Are the man pages the best way to do that or is that a single document 
available?

I made some progress but still have some questions. I followed the steps 
laid out by Robert and everything went fine except I ran into an error 
with "predrast <- setValues(predrast, pred, r)" in the for loop when I 
tried processing one line at a time and "r <- setValues(r, pred)" when I 
ran the full image in one go. The error was: "values must be a vector." 
Any idea what I'm doing wrong?

I tried to read the GRASS files directly but got a message saying it is 
not a supported file format. Can you confirm that is the case or am I 
doing something wrong? I was able to read a tiff version of the image. I 
am able to run gdalinfo on GRASS files just fine from a terminal window.

Thanks again for the help.

Ned


Robert Hijmans wrote:
> Ned,
>
> This is an example of running a RandomForest prediction with the
> raster package (for the simple case that there are no NA values in the
> raster data; if there are, you have to into account that "predict'
> does not return any values (not even NA) for those cells).
>
> Robert
>
> #install.packages("raster", repos="http://R-Forge.R-project.org")
> require(raster)
> require(randomForest)
>
> # for single band files
> spot <- stack('b1.tif', 'b2.tif', 'b3.tif')
> # for multiple band files
> # spot <- stackFromFiles(c('bands.tif', 'bands.tif', 'bands.tif'), c(1,2,3) )
>
> # simulate random points and values to model with
> xy <- xyFromCell(spot, round(runif(100) * ncell(spot)))
> response <- runif(100) * 100
> # read values of raster layers at points, and bind to respinse
> trainvals <- cbind(response, xyValues(spot, xy))
>
> # run RandomForest
> randfor <- randomForest(response ~ b1 + b2 + b3, data=trainvals)
>
> # apply the prediction, row by row
> predrast <- setRaster(spot)
> filename(predrast) <- 'RF_pred.grd'
> for (r in 1:nrow(spot)) {
> 	spot <- readRow(spot, r)
> 	rowvals <- values(spot, names=TRUE)
> # this next line should not be necessary, but it is
> # I'll fix that
> 	colnames(rowvals) <- c('b1', 'b2', 'b3')
> 	pred <- predict(randfor, rowvals)
> 	predrast <- setValues(predrast, pred, r)
> 	predrast <- writeRaster(predrast, overwrite=TRUE)
> }
>
> plot(predrast)
>
>
>
>
> On Wed, Feb 11, 2009 at 5:09 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>   
>> Ned:
>>
>>
>> The three bands are most likely treated as 4-byte integers, so the object
>> will be 2732 by 3058 by 3 by 4 plus a little bit. That's 100MB. They may
>> get copied too. There are no single byte user-level containers for you
>> (there is a raw data type, but you can't calculate with it). Possibly
>> saying spot_frame <- slot(spot, "data") will save one copying operation,
>> but its hard to tell - your choice of method first adds inn all the
>> coordinates, which are 8-byte numbers, so more than doubles its size and
>> makes more copies (to 233MB for each copy). Running gc() several times
>> manually between steps often helps by making the garbage collector more
>> aggressive.
>>
>> I would watch the developments in the R-Forge package "raster", which
>> builds on some of these things, and try to see how that works. If you have
>> the GDAL-GRASS plugin for rasters, you can use readGDAL to read from GRASS
>> - which would work with raster package functions now. Look at the code of
>> recent readRAST6 to see which incantations are needed. If you are going to
>> use randomForest for prediction, you can use smaller tiles until you find
>> an alternative solution. Note that feeding a data frame of integers to a
>> model fitting or prediction function will result in coercion to a
>> matrix of doubles, so your subsequent workflow should take that into
>> account.
>>  Getting more memory is another option, and may be very cost and especially
>> time effective - at the moment your machine is swapping. Buying memory may
>> save you time programming around too little memory.
>>
>> Hope this helps,
>>
>> Roger
>>
>>
>> ---
>> Roger Bivand, NHH, Helleveien 30, N-5045 Bergen,
>> Roger.Bivand at nhh.no
>>
>>
>>
>> -----Original Message-----
>> From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Ned Horning
>> Sent: Wed 11.02.2009 07:40
>> To: r-sig-geo at stat.math.ethz.ch
>> Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
>>
>> Greetings,
>>
>> I am trying to read an image from GRASS using the spgrass6 command
>> readRAST6 and then convert it into a data.frame object so I can use it
>> with randomForest. The byte image I'm reading is 2732 rows x 3058
>> columns x 3 bands. It's a small subset of a larger image I would like to
>> use eventually. I have no problem reading the image using readRAST6 but
>> when I try to convert it to a data.frame object my linux system
>> resources (1BG RAM, 3GB swap) nearly get maxed out and it runs for a
>> couple hours before I kill the process. The image is less than 25MB so
>> I'm surprised it requires this level of memory. Can someone let me know
>> why this is. Should I use something other than the GRASS interface for
>> this? These are the commands I'm using:
>>
>> spot <- readRAST6(c("subset.red", "subset.green", "subset.blue"))
>> spot_frame <- as(spot, "data.frame")
>>
>> Any help would be appreciated.
>>
>> All the best,
>>
>> Ned
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>     
>
>


From edzer.pebesma at uni-muenster.de  Wed Feb 11 16:35:44 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 11 Feb 2009 16:35:44 +0100
Subject: [R-sig-Geo] FW:  Interpolation option: IDW or OK?
In-Reply-To: <86DBA0678E017341B449A62F258E29561549CA@IS-EX-BEV3.unimelb.edu.au>
References: <86DBA0678E017341B449A62F258E29561549CA@IS-EX-BEV3.unimelb.edu.au>
Message-ID: <4992F050.1050104@uni-muenster.de>

I can think of two reasons, without having looked at anything else than 
your message:
1. Range=162 may mean a different thing for the exponential model; for 
gstat it means the range parameter as in c1(1-exp(h/a)). This is all 
documented. In ArcGIS it might mean something like c1(1-exp(h/(3a)); for 
you the responsibility to verify this.
2. setting nmax does not necessarly lead to uniquely defined 
neighbourhoods; think of data on a grid.

I understand and do recognize your worries. gstat has been in the open 
source for over 10 years now; before you spread fear, uncertainty and 
doubt I would have appreciated it if you had kept your observations and 
questions directed to this list more factual, and reproducable/verifiable.

Also note that gstat allows YOU to double check the underlying 
algorithms; this in contrast to the other software you mention. You're 
suggesting now to 1000+ subscribers that this burden lies with me, and 
worse, that I didn't do this.
--
Edzer

Yong Li wrote:
> Hi Edzer,
>
> I found a problem with gstat "krige" prediction if I am correct this
> time. For example, with OLSENP variable in my dataset, I developed a
> theoretical model for log(OLSENP) variogram: model=exp, c0=0.2019,
> c1=0.2218 and Range=162 meters. By using this model, I predicted the
> OLSENP surface using gstat krige and ArcGIS Spatial Analyst with the
> same nmax and found the results are significantly different. gstat
> significantly underestimated values (here is where I had an idea to use
> IDW), but Spatial Analyst gave very reliable predictions. I would like
> you to double check the algorithms behind gstat. 
>
> By the way, I start to puzzle because I used gstat to calculate other
> variables in my dataset, such as total nitrogen and extractable
> potassium and also I used gstat to run a series regression-kriging to
> predict soil organic matter distribution and submitted to a journal
> already.
>      
> I appreciate you could give me your response as soon as possible.
>
> Regards
>
> Yong Li
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
> r-sig-geo-request at stat.math.ethz.ch
> Sent: Tuesday, 10 February 2009 10:00 PM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: R-sig-Geo Digest, Vol 66, Issue 10
>
> Send R-sig-Geo mailing list submissions to
> 	r-sig-geo at stat.math.ethz.ch
>
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> or, via email, send a message with subject or body 'help' to
> 	r-sig-geo-request at stat.math.ethz.ch
>
> You can reach the person managing the list at
> 	r-sig-geo-owner at stat.math.ethz.ch
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-Geo digest..."
>
>
> Today's Topics:
>
>    1. error rgdal library if used from within Grass plugin
>       (Windows) (Agustin Lobo)
>    2. Re: error rgdal library if used from within Grass plugin
>       (Windows) (Roger Bivand)
>    3. Re: FW:  Interpolcation option: IDW or OK? (Tomislav Hengl)
>    4. Calculating descriptive stats from many maps (Rainer M Krug)
>    5. Re: Calculating descriptive stats from many maps (Tomislav Hengl)
>    6. Re: Calculating descriptive stats from many maps (Roger Bivand)
>    7. Interpolcation option: IDW or OK? (Yong Li)
>    8. Re: Calculating descriptive stats from many maps (Robert Hijmans)
>    9. Re: FW: Interpolcation option: IDW or OK? (Robert Hijmans)
>   10. Re: Calculating descriptive stats from many maps (Rainer M Krug)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Mon, 09 Feb 2009 15:06:24 +0100
> From: Agustin Lobo <aloboaleu at gmail.com>
> Subject: [R-sig-Geo] error rgdal library if used from within Grass
> 	plugin	(Windows)
> To: r-sig-geo at stat.math.ethz.ch
> Message-ID: <49903860.8060406 at gmail.com>
> Content-Type: text/plain; charset=iso-8859-1; format=flowed
>
> Hi!
>
> The following error only occurs if the R (2.7.2) session is started
> from a GRASS shell opened through the QGIS GRASS plugin in windows.
> The error does not occur If R is started form its own icon
> or by double click in the .RData  object,  but then the spgrass6
> package would not find the GRASS environment.
>
> It also works in linux.
> The involved  commands  are:
>
> 1. Start  QGIS
> 2. Star GRASS plugin and open mapset
> 3.  Open Grass Shell
> 4.  Run R and execute require(spgrass6)
>
>   
>>>>> Loading required package: spgrass6
>>>>> Loading required package: sp
>>>>> Loading required package: rgdal
>>>>> Error in fun(...) :
>>>>>         GDAL Error 1: Can't load requested DLL:
>>>>> C:\OSGeo4W\bin\gdalplugins\gdal_ECW_JP2ECW.dll
>>>>> 126: N?o foi poss?vel encontrar o m?dulo especificado.
>>>>>
>>>>>
>>>>>
>>>>> Error : .onLoad failed in 'loadNamespace' for 'rgdal'
>>>>> Erro: package 'rgdal' could not be loaded
>>>>>           
>
> Any help appreciated.
>
> Agus
>
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From Roger.Bivand at nhh.no  Wed Feb 11 16:57:37 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 11 Feb 2009 16:57:37 +0100 (CET)
Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
In-Reply-To: <4992EBB0.20400@amnh.org>
References: <499272FA.30902@amnh.org>
	<AD51AB79BC327C40AB2C7EB75D57A3C40512E7@TOLAR.valuta.nhh.no>
	<dc22b2570902110412v3130519aiff3deaf23e29ce32@mail.gmail.com>
	<4992EBB0.20400@amnh.org>
Message-ID: <alpine.LRH.2.00.0902111651500.24749@reclus.nhh.no>

On Wed, 11 Feb 2009, Ned Horning wrote:

> Robert and Roger,
>
> Thanks for the information and pointers. The raster package looks quite 
> interesting and I'll try to get up to speed on some of its capabilities. Are 
> the man pages the best way to do that or is that a single document available?
>
> I made some progress but still have some questions. I followed the steps laid 
> out by Robert and everything went fine except I ran into an error with 
> "predrast <- setValues(predrast, pred, r)" in the for loop when I tried 
> processing one line at a time and "r <- setValues(r, pred)" when I ran the 
> full image in one go. The error was: "values must be a vector." Any idea what 
> I'm doing wrong?
>
> I tried to read the GRASS files directly but got a message saying it is 
> not a supported file format. Can you confirm that is the case or am I 
> doing something wrong? I was able to read a tiff version of the image. I 
> am able to run gdalinfo on GRASS files just fine from a terminal window.

Could you quote verbatim what the actual fname= argument was that you used 
in readGDAL for the plugin - the incantation isn't obvious?

In readRAST6() it is:

paste(gg$GISDBASE, gg$LOCATION_NAME, mapset, "cellhd", vname[1], sep="/")

where all of GISDBASE, LOCATION_NAME, and mapset need to be discovered - 
you can use gmeta6() for the first two, and .g_findfile() for the third, 
please read the code in spgrass6 to see how they work.

Roger

>
> Thanks again for the help.
>
> Ned
>
>
> Robert Hijmans wrote:
>> Ned,
>> 
>> This is an example of running a RandomForest prediction with the
>> raster package (for the simple case that there are no NA values in the
>> raster data; if there are, you have to into account that "predict'
>> does not return any values (not even NA) for those cells).
>> 
>> Robert
>> 
>> #install.packages("raster", repos="http://R-Forge.R-project.org")
>> require(raster)
>> require(randomForest)
>> 
>> # for single band files
>> spot <- stack('b1.tif', 'b2.tif', 'b3.tif')
>> # for multiple band files
>> # spot <- stackFromFiles(c('bands.tif', 'bands.tif', 'bands.tif'), c(1,2,3) 
>> )
>> 
>> # simulate random points and values to model with
>> xy <- xyFromCell(spot, round(runif(100) * ncell(spot)))
>> response <- runif(100) * 100
>> # read values of raster layers at points, and bind to respinse
>> trainvals <- cbind(response, xyValues(spot, xy))
>> 
>> # run RandomForest
>> randfor <- randomForest(response ~ b1 + b2 + b3, data=trainvals)
>> 
>> # apply the prediction, row by row
>> predrast <- setRaster(spot)
>> filename(predrast) <- 'RF_pred.grd'
>> for (r in 1:nrow(spot)) {
>> 	spot <- readRow(spot, r)
>> 	rowvals <- values(spot, names=TRUE)
>> # this next line should not be necessary, but it is
>> # I'll fix that
>> 	colnames(rowvals) <- c('b1', 'b2', 'b3')
>> 	pred <- predict(randfor, rowvals)
>> 	predrast <- setValues(predrast, pred, r)
>> 	predrast <- writeRaster(predrast, overwrite=TRUE)
>> }
>> 
>> plot(predrast)
>> 
>> 
>> 
>> 
>> On Wed, Feb 11, 2009 at 5:09 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> 
>>> Ned:
>>> 
>>> 
>>> The three bands are most likely treated as 4-byte integers, so the object
>>> will be 2732 by 3058 by 3 by 4 plus a little bit. That's 100MB. They may
>>> get copied too. There are no single byte user-level containers for you
>>> (there is a raw data type, but you can't calculate with it). Possibly
>>> saying spot_frame <- slot(spot, "data") will save one copying operation,
>>> but its hard to tell - your choice of method first adds inn all the
>>> coordinates, which are 8-byte numbers, so more than doubles its size and
>>> makes more copies (to 233MB for each copy). Running gc() several times
>>> manually between steps often helps by making the garbage collector more
>>> aggressive.
>>> 
>>> I would watch the developments in the R-Forge package "raster", which
>>> builds on some of these things, and try to see how that works. If you have
>>> the GDAL-GRASS plugin for rasters, you can use readGDAL to read from GRASS
>>> - which would work with raster package functions now. Look at the code of
>>> recent readRAST6 to see which incantations are needed. If you are going to
>>> use randomForest for prediction, you can use smaller tiles until you find
>>> an alternative solution. Note that feeding a data frame of integers to a
>>> model fitting or prediction function will result in coercion to a
>>> matrix of doubles, so your subsequent workflow should take that into
>>> account.
>>>  Getting more memory is another option, and may be very cost and 
>>> especially
>>> time effective - at the moment your machine is swapping. Buying memory may
>>> save you time programming around too little memory.
>>> 
>>> Hope this helps,
>>> 
>>> Roger
>>> 
>>> 
>>> ---
>>> Roger Bivand, NHH, Helleveien 30, N-5045 Bergen,
>>> Roger.Bivand at nhh.no
>>> 
>>> 
>>> 
>>> -----Original Message-----
>>> From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Ned Horning
>>> Sent: Wed 11.02.2009 07:40
>>> To: r-sig-geo at stat.math.ethz.ch
>>> Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
>>> 
>>> Greetings,
>>> 
>>> I am trying to read an image from GRASS using the spgrass6 command
>>> readRAST6 and then convert it into a data.frame object so I can use it
>>> with randomForest. The byte image I'm reading is 2732 rows x 3058
>>> columns x 3 bands. It's a small subset of a larger image I would like to
>>> use eventually. I have no problem reading the image using readRAST6 but
>>> when I try to convert it to a data.frame object my linux system
>>> resources (1BG RAM, 3GB swap) nearly get maxed out and it runs for a
>>> couple hours before I kill the process. The image is less than 25MB so
>>> I'm surprised it requires this level of memory. Can someone let me know
>>> why this is. Should I use something other than the GRASS interface for
>>> this? These are the commands I'm using:
>>> 
>>> spot <- readRAST6(c("subset.red", "subset.green", "subset.blue"))
>>> spot_frame <- as(spot, "data.frame")
>>> 
>>> Any help would be appreciated.
>>> 
>>> All the best,
>>> 
>>> Ned
>>> 
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> 
>>> 
>>> 
>>>
>>>        [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>> 
>> 
>> 
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From paallen at attglobal.net  Wed Feb 11 19:08:28 2009
From: paallen at attglobal.net (paallen at attglobal.net)
Date: Wed, 11 Feb 2009 18:08:28 +0000
Subject: [R-sig-Geo] Plot xyzm PostGIS Lines in rgl?
Message-ID: <200902111808.n1BI8hIX023536@hypatia.math.ethz.ch>

Hi all,

I have been plotting the midpoints of some
chemical analysis from drill holes in rgl and very
happy with the 3D symbolization capabilites.  Now
I want to try and plot some 3D lines of the drill
holes so I can symbolize some long intervals (not
usefull to plot as 3d  points).  

My data is in a PostGIS PostgreSQL database as
xyzm polylines.  What is the best way to get this
kind of data into R?  Should I export the data to
a shape file (pgsql2shp) then import with
readShapeSpatial?  I tried readOGR but apparentl
on windows it doesn't have the PG driver.  Or
should I bring the postgresql table in as text
like this:

Library(RODBC)
c <- odbcConnect("drill_hole_database")
d <- sqlQuery(c, "Select hole_id,
AsEWKT(hole_3dline_geom) as 3dline_txt FROM
drill_holes;")
d
hole_id		3dline_txt
ddh-1		SRID=32618:LINESTRING(4000 4000 325 0, 4000
4000 300 25, 4000 4000 250 75)
ddh-2		SRID=32618:LINESTRING(5000 5000 410 0, 5000
5000 350 60)

Of course my real data sets have more attributes,
vertices and the drill holes are curved!

With either the text or Spatial option I am having
problems re-formating the line vertices into the
lines3d format required by the rgl package.

If I can just get a good grip on managing spatial
data in R and symbolizing 3d data in rgl it will
save me a fortune.  3D mine/geology software is
expensive and typically has very limited
statistics beyond geostatistics.

thanks,

Phillip J. Allen
Chief Geochemist


From horning at amnh.org  Wed Feb 11 19:40:28 2009
From: horning at amnh.org (Ned Horning)
Date: Wed, 11 Feb 2009 21:40:28 +0300
Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
In-Reply-To: <alpine.LRH.2.00.0902111651500.24749@reclus.nhh.no>
References: <499272FA.30902@amnh.org>
	<AD51AB79BC327C40AB2C7EB75D57A3C40512E7@TOLAR.valuta.nhh.no>
	<dc22b2570902110412v3130519aiff3deaf23e29ce32@mail.gmail.com>
	<4992EBB0.20400@amnh.org>
	<alpine.LRH.2.00.0902111651500.24749@reclus.nhh.no>
Message-ID: <49931B9C.7080407@amnh.org>

Roger,

I used the path to the full path to the image.
spot <- 
stack('/home/nedhorning/IPY/ak_grassdata/293318101_1_1_0/PERMANENT/cellhd/subset.red', 
'/home/nedhorning/IPY/ak_grassdata/293318101_1_1_0/PERMANENT/cellhd/subset.green', 
'/home/nedhorning/IPY/ak_grassdata/293318101_1_1_0/PERMANENT/cellhd/subset.blue')

GDAL Error 4: not recognized as a supported file format.

Ned

Roger Bivand wrote:
> On Wed, 11 Feb 2009, Ned Horning wrote:
>
>> Robert and Roger,
>>
>> Thanks for the information and pointers. The raster package looks 
>> quite interesting and I'll try to get up to speed on some of its 
>> capabilities. Are the man pages the best way to do that or is that a 
>> single document available?
>>
>> I made some progress but still have some questions. I followed the 
>> steps laid out by Robert and everything went fine except I ran into 
>> an error with "predrast <- setValues(predrast, pred, r)" in the for 
>> loop when I tried processing one line at a time and "r <- 
>> setValues(r, pred)" when I ran the full image in one go. The error 
>> was: "values must be a vector." Any idea what I'm doing wrong?
>>
>> I tried to read the GRASS files directly but got a message saying it 
>> is not a supported file format. Can you confirm that is the case or 
>> am I doing something wrong? I was able to read a tiff version of the 
>> image. I am able to run gdalinfo on GRASS files just fine from a 
>> terminal window.
>
> Could you quote verbatim what the actual fname= argument was that you 
> used in readGDAL for the plugin - the incantation isn't obvious?
>
> In readRAST6() it is:
>
> paste(gg$GISDBASE, gg$LOCATION_NAME, mapset, "cellhd", vname[1], sep="/")
>
> where all of GISDBASE, LOCATION_NAME, and mapset need to be discovered 
> - you can use gmeta6() for the first two, and .g_findfile() for the 
> third, please read the code in spgrass6 to see how they work.
>
> Roger
>
>>
>> Thanks again for the help.
>>
>> Ned
>>
>>
>> Robert Hijmans wrote:
>>> Ned,
>>>
>>> This is an example of running a RandomForest prediction with the
>>> raster package (for the simple case that there are no NA values in the
>>> raster data; if there are, you have to into account that "predict'
>>> does not return any values (not even NA) for those cells).
>>>
>>> Robert
>>>
>>> #install.packages("raster", repos="http://R-Forge.R-project.org")
>>> require(raster)
>>> require(randomForest)
>>>
>>> # for single band files
>>> spot <- stack('b1.tif', 'b2.tif', 'b3.tif')
>>> # for multiple band files
>>> # spot <- stackFromFiles(c('bands.tif', 'bands.tif', 'bands.tif'), 
>>> c(1,2,3) )
>>>
>>> # simulate random points and values to model with
>>> xy <- xyFromCell(spot, round(runif(100) * ncell(spot)))
>>> response <- runif(100) * 100
>>> # read values of raster layers at points, and bind to respinse
>>> trainvals <- cbind(response, xyValues(spot, xy))
>>>
>>> # run RandomForest
>>> randfor <- randomForest(response ~ b1 + b2 + b3, data=trainvals)
>>>
>>> # apply the prediction, row by row
>>> predrast <- setRaster(spot)
>>> filename(predrast) <- 'RF_pred.grd'
>>> for (r in 1:nrow(spot)) {
>>>     spot <- readRow(spot, r)
>>>     rowvals <- values(spot, names=TRUE)
>>> # this next line should not be necessary, but it is
>>> # I'll fix that
>>>     colnames(rowvals) <- c('b1', 'b2', 'b3')
>>>     pred <- predict(randfor, rowvals)
>>>     predrast <- setValues(predrast, pred, r)
>>>     predrast <- writeRaster(predrast, overwrite=TRUE)
>>> }
>>>
>>> plot(predrast)
>>>
>>>
>>>
>>>
>>> On Wed, Feb 11, 2009 at 5:09 PM, Roger Bivand <Roger.Bivand at nhh.no> 
>>> wrote:
>>>
>>>> Ned:
>>>>
>>>>
>>>> The three bands are most likely treated as 4-byte integers, so the 
>>>> object
>>>> will be 2732 by 3058 by 3 by 4 plus a little bit. That's 100MB. 
>>>> They may
>>>> get copied too. There are no single byte user-level containers for you
>>>> (there is a raw data type, but you can't calculate with it). Possibly
>>>> saying spot_frame <- slot(spot, "data") will save one copying 
>>>> operation,
>>>> but its hard to tell - your choice of method first adds inn all the
>>>> coordinates, which are 8-byte numbers, so more than doubles its 
>>>> size and
>>>> makes more copies (to 233MB for each copy). Running gc() several times
>>>> manually between steps often helps by making the garbage collector 
>>>> more
>>>> aggressive.
>>>>
>>>> I would watch the developments in the R-Forge package "raster", which
>>>> builds on some of these things, and try to see how that works. If 
>>>> you have
>>>> the GDAL-GRASS plugin for rasters, you can use readGDAL to read 
>>>> from GRASS
>>>> - which would work with raster package functions now. Look at the 
>>>> code of
>>>> recent readRAST6 to see which incantations are needed. If you are 
>>>> going to
>>>> use randomForest for prediction, you can use smaller tiles until 
>>>> you find
>>>> an alternative solution. Note that feeding a data frame of integers 
>>>> to a
>>>> model fitting or prediction function will result in coercion to a
>>>> matrix of doubles, so your subsequent workflow should take that into
>>>> account.
>>>>  Getting more memory is another option, and may be very cost and 
>>>> especially
>>>> time effective - at the moment your machine is swapping. Buying 
>>>> memory may
>>>> save you time programming around too little memory.
>>>>
>>>> Hope this helps,
>>>>
>>>> Roger
>>>>
>>>>
>>>> ---
>>>> Roger Bivand, NHH, Helleveien 30, N-5045 Bergen,
>>>> Roger.Bivand at nhh.no
>>>>
>>>>
>>>>
>>>> -----Original Message-----
>>>> From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Ned Horning
>>>> Sent: Wed 11.02.2009 07:40
>>>> To: r-sig-geo at stat.math.ethz.ch
>>>> Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
>>>>
>>>> Greetings,
>>>>
>>>> I am trying to read an image from GRASS using the spgrass6 command
>>>> readRAST6 and then convert it into a data.frame object so I can use it
>>>> with randomForest. The byte image I'm reading is 2732 rows x 3058
>>>> columns x 3 bands. It's a small subset of a larger image I would 
>>>> like to
>>>> use eventually. I have no problem reading the image using readRAST6 
>>>> but
>>>> when I try to convert it to a data.frame object my linux system
>>>> resources (1BG RAM, 3GB swap) nearly get maxed out and it runs for a
>>>> couple hours before I kill the process. The image is less than 25MB so
>>>> I'm surprised it requires this level of memory. Can someone let me 
>>>> know
>>>> why this is. Should I use something other than the GRASS interface for
>>>> this? These are the commands I'm using:
>>>>
>>>> spot <- readRAST6(c("subset.red", "subset.green", "subset.blue"))
>>>> spot_frame <- as(spot, "data.frame")
>>>>
>>>> Any help would be appreciated.
>>>>
>>>> All the best,
>>>>
>>>> Ned
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>
>>>>
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>
>>>
>>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From horning at amnh.org  Wed Feb 11 19:43:50 2009
From: horning at amnh.org (Ned Horning)
Date: Wed, 11 Feb 2009 21:43:50 +0300
Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
Message-ID: <49931C66.6070502@amnh.org>

Robert,

Using predrast <- setValues(predrast, as.vector(pred), r) I got another 
error: values must be numeric, integer or logical.

class(pred) = "factor"
dim(pred) = NULL
class(v) = "character"
length(v) == ncol(spot) = TRUE

Ned

Robert Hijmans wrote:
> Strange. You could try
>       predrast <- setValues(predrast, as.vector(pred), r)
>
> But it would be good to know what pred is.
>
> Can you do this:
>
> class(pred)
> dim(pred)
> v <- as.vector(pred)
> class(v)
> length(v) == ncol(spot)
>
>
> Robert
>
>
>
>
> On Wed, Feb 11, 2009 at 11:16 PM, Ned Horning <horning at amnh.org> wrote:
>   
>> Robert and Roger,
>>
>> Thanks for the information and pointers. The raster package looks quite
>> interesting and I'll try to get up to speed on some of its capabilities. Are
>> the man pages the best way to do that or is that a single document
>> available?
>>
>> I made some progress but still have some questions. I followed the steps
>> laid out by Robert and everything went fine except I ran into an error with
>> "predrast <- setValues(predrast, pred, r)" in the for loop when I tried
>> processing one line at a time and "r <- setValues(r, pred)" when I ran the
>> full image in one go. The error was: "values must be a vector." Any idea
>> what I'm doing wrong?
>>
>> I tried to read the GRASS files directly but got a message saying it is not
>> a supported file format. Can you confirm that is the case or am I doing
>> something wrong? I was able to read a tiff version of the image. I am able
>> to run gdalinfo on GRASS files just fine from a terminal window.
>>
>> Thanks again for the help.
>>
>> Ned
>>
>>
>> Robert Hijmans wrote:
>>     
>>> Ned,
>>>
>>> This is an example of running a RandomForest prediction with the
>>> raster package (for the simple case that there are no NA values in the
>>> raster data; if there are, you have to into account that "predict'
>>> does not return any values (not even NA) for those cells).
>>>
>>> Robert
>>>
>>> #install.packages("raster", repos="http://R-Forge.R-project.org")
>>> require(raster)
>>> require(randomForest)
>>>
>>> # for single band files
>>> spot <- stack('b1.tif', 'b2.tif', 'b3.tif')
>>> # for multiple band files
>>> # spot <- stackFromFiles(c('bands.tif', 'bands.tif', 'bands.tif'),
>>> c(1,2,3) )
>>>
>>> # simulate random points and values to model with
>>> xy <- xyFromCell(spot, round(runif(100) * ncell(spot)))
>>> response <- runif(100) * 100
>>> # read values of raster layers at points, and bind to respinse
>>> trainvals <- cbind(response, xyValues(spot, xy))
>>>
>>> # run RandomForest
>>> randfor <- randomForest(response ~ b1 + b2 + b3, data=trainvals)
>>>
>>> # apply the prediction, row by row
>>> predrast <- setRaster(spot)
>>> filename(predrast) <- 'RF_pred.grd'
>>> for (r in 1:nrow(spot)) {
>>>        spot <- readRow(spot, r)
>>>        rowvals <- values(spot, names=TRUE)
>>> # this next line should not be necessary, but it is
>>> # I'll fix that
>>>        colnames(rowvals) <- c('b1', 'b2', 'b3')
>>>        pred <- predict(randfor, rowvals)
>>>        predrast <- setValues(predrast, pred, r)
>>>        predrast <- writeRaster(predrast, overwrite=TRUE)
>>> }
>>>
>>> plot(predrast)
>>>
>>>
>>>
>>>
>>> On Wed, Feb 11, 2009 at 5:09 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>>
>>>       
>>>> Ned:
>>>>
>>>>
>>>> The three bands are most likely treated as 4-byte integers, so the object
>>>> will be 2732 by 3058 by 3 by 4 plus a little bit. That's 100MB. They may
>>>> get copied too. There are no single byte user-level containers for you
>>>> (there is a raw data type, but you can't calculate with it). Possibly
>>>> saying spot_frame <- slot(spot, "data") will save one copying operation,
>>>> but its hard to tell - your choice of method first adds inn all the
>>>> coordinates, which are 8-byte numbers, so more than doubles its size and
>>>> makes more copies (to 233MB for each copy). Running gc() several times
>>>> manually between steps often helps by making the garbage collector more
>>>> aggressive.
>>>>
>>>> I would watch the developments in the R-Forge package "raster", which
>>>> builds on some of these things, and try to see how that works. If you
>>>> have
>>>> the GDAL-GRASS plugin for rasters, you can use readGDAL to read from
>>>> GRASS
>>>> - which would work with raster package functions now. Look at the code of
>>>> recent readRAST6 to see which incantations are needed. If you are going
>>>> to
>>>> use randomForest for prediction, you can use smaller tiles until you find
>>>> an alternative solution. Note that feeding a data frame of integers to a
>>>> model fitting or prediction function will result in coercion to a
>>>> matrix of doubles, so your subsequent workflow should take that into
>>>> account.
>>>>  Getting more memory is another option, and may be very cost and
>>>> especially
>>>> time effective - at the moment your machine is swapping. Buying memory
>>>> may
>>>> save you time programming around too little memory.
>>>>
>>>> Hope this helps,
>>>>
>>>> Roger
>>>>
>>>>
>>>> ---
>>>> Roger Bivand, NHH, Helleveien 30, N-5045 Bergen,
>>>> Roger.Bivand at nhh.no
>>>>
>>>>
>>>>
>>>> -----Original Message-----
>>>> From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Ned Horning
>>>> Sent: Wed 11.02.2009 07:40
>>>> To: r-sig-geo at stat.math.ethz.ch
>>>> Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
>>>>
>>>> Greetings,
>>>>
>>>> I am trying to read an image from GRASS using the spgrass6 command
>>>> readRAST6 and then convert it into a data.frame object so I can use it
>>>> with randomForest. The byte image I'm reading is 2732 rows x 3058
>>>> columns x 3 bands. It's a small subset of a larger image I would like to
>>>> use eventually. I have no problem reading the image using readRAST6 but
>>>> when I try to convert it to a data.frame object my linux system
>>>> resources (1BG RAM, 3GB swap) nearly get maxed out and it runs for a
>>>> couple hours before I kill the process. The image is less than 25MB so
>>>> I'm surprised it requires this level of memory. Can someone let me know
>>>> why this is. Should I use something other than the GRASS interface for
>>>> this? These are the commands I'm using:
>>>>
>>>> spot <- readRAST6(c("subset.red", "subset.green", "subset.blue"))
>>>> spot_frame <- as(spot, "data.frame")
>>>>
>>>> Any help would be appreciated.
>>>>
>>>> All the best,
>>>>
>>>> Ned
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>
>>>>
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>
>>>>         
>>>       
>>     
>
>


From greenberg at ucdavis.edu  Wed Feb 11 22:15:57 2009
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Wed, 11 Feb 2009 13:15:57 -0800
Subject: [R-sig-Geo] Open source GIS cataloging software?
Message-ID: <4993400D.6020107@ucdavis.edu>

Sorry for the cross-posting.  I was wondering if anyone has a unix 
(preferably) or windows program that can spider a directory, recursively 
searching for raster and vector data, and create bounding box polygons 
for each raster/vector it finds, with attributes indicating the 
path-to-file.  Thanks!

--j

-- 

Jonathan A. Greenberg, PhD
Postdoctoral Scholar
Center for Spatial Technologies and Remote Sensing (CSTARS)
University of California, Davis
One Shields Avenue
The Barn, Room 250N
Davis, CA 95616
Cell: 415-794-5043
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307


From mdsumner at utas.edu.au  Wed Feb 11 22:45:05 2009
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Thu, 12 Feb 2009 08:45:05 +1100
Subject: [R-sig-Geo] Open source GIS cataloging software?
In-Reply-To: <4993400D.6020107@ucdavis.edu>
References: <4993400D.6020107@ucdavis.edu>
Message-ID: <499346E1.6010909@utas.edu.au>

That is an interesting idea, you could do it with rgdal - but you will 
need carefuly handling of directory data sources vs. file data sources, 
but that could be a clean up operation once the first pass is done.

The vector and raster drivers will auto-detect the format, so there's no 
need to invoke specially for each type. For ease of access to the 
greatest number of drivers it might be easiest to use FWTools, and 
invoke the command line tools from R and parse their output for more 
information.

This R function will list every file, and file.info() can be used to 
determine which are folders and so on.

allfiles <- list.files(recursive = TRUE, full.names = TRUE)

ogrinfo and gdalinfo (FWTools) will tell you the layers/rasters present 
in a folder. I've been thinking of doing something like this for a 
while, so I might have a go at it.

HTH

Regards, Mike


Jonathan Greenberg wrote:
> Sorry for the cross-posting.  I was wondering if anyone has a unix 
> (preferably) or windows program that can spider a directory, 
> recursively searching for raster and vector data, and create bounding 
> box polygons for each raster/vector it finds, with attributes 
> indicating the path-to-file.  Thanks!
>
> --j
>
> ------------------------------------------------------------------------
>
>
> No virus found in this incoming message.
> Checked by AVG - www.avg.com 
> Version: 8.0.234 / Virus Database: 270.10.23/1947 - Release Date: 02/10/09 17:44:00
>
>


From debeaudette at ucdavis.edu  Wed Feb 11 22:48:49 2009
From: debeaudette at ucdavis.edu (Dylan Beaudette)
Date: Wed, 11 Feb 2009 13:48:49 -0800
Subject: [R-sig-Geo] Open source GIS cataloging software?
In-Reply-To: <4993400D.6020107@ucdavis.edu>
References: <4993400D.6020107@ucdavis.edu>
Message-ID: <200902111348.49566.dylan.beaudette@gmail.com>

On Wednesday 11 February 2009, Jonathan Greenberg wrote:
> Sorry for the cross-posting.  I was wondering if anyone has a unix
> (preferably) or windows program that can spider a directory, recursively
> searching for raster and vector data, and create bounding box polygons
> for each raster/vector it finds, with attributes indicating the
> path-to-file.  Thanks!
>
> --j

Nice idea. I think that a simple python script should be able to do this, 
using the gdal/ogr module. Note that the bounding boxes will only be useful 
if: 
1) the data are all in the same coordinate system
2) the data all contain enough SRS information to convert to a common 
coordinate system

I'd ask on the GDAL list.

Dylan

-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341


From b.rowlingson at lancaster.ac.uk  Thu Feb 12 00:31:56 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 11 Feb 2009 23:31:56 +0000
Subject: [R-sig-Geo] Open source GIS cataloging software?
In-Reply-To: <200902111348.49566.dylan.beaudette@gmail.com>
References: <4993400D.6020107@ucdavis.edu>
	<200902111348.49566.dylan.beaudette@gmail.com>
Message-ID: <d8ad40b50902111531o1bb73c96rdab9ed5f72271c86@mail.gmail.com>

2009/2/11 Dylan Beaudette <debeaudette at ucdavis.edu>:

> Nice idea. I think that a simple python script should be able to do this,
> using the gdal/ogr module. Note that the bounding boxes will only be useful
> if:
> 1) the data are all in the same coordinate system
> 2) the data all contain enough SRS information to convert to a common
> coordinate system

hup ho, here we go - a little python script. This one just does ogr.
Save as 'catalogger.py' and run with 'python catalogger.py
/path/to/maps'. The output is just raw python dicts at the moment, but
easy enough to turn into a CSV file. Some notes:

 * shapefiles appear lots of times since the .dbf, .shx and .shp
(maybe others) all seem to be valid ogr descriptors.
 * shapefiles are also sub-layers of the directories they are in
 * extents for multi-layer ogr datasources are only meaningful if the
SRSs are the same.

import ogr

def testOgr(filepath):
    try:
        f = ogr.Open(filepath)
        extent = [None,None,None,None]
        for i in range(f.GetLayerCount()):
            l = f.GetLayer(i)
            e = l.GetExtent()
            extent=[max(e[j],extent[j]) for j in range(4)]
        return {'Name': f.GetName(), 'Extent': extent, 'Layers':
f.GetLayerCount()}
    except:
        return None

import os

def dirwalk(dir):
    "walk a directory tree, using a generator"
    for f in os.listdir(dir):
        fullpath = os.path.join(dir,f)
        if os.path.isdir(fullpath) and not os.path.islink(fullpath):
            for x in dirwalk(fullpath):  # recurse into subdir
                yield x
        else:
            yield fullpath


def ogrWalk(path):
    for p in dirwalk(path):
        t = testOgr(p)
        if t:
            print t

if __name__=="__main__":
    import sys
    path = sys.argv[1]
    ogrWalk(path)


From horning at amnh.org  Thu Feb 12 07:30:51 2009
From: horning at amnh.org (Ned Horning)
Date: Thu, 12 Feb 2009 09:30:51 +0300
Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
In-Reply-To: <dc22b2570902111429y4be75d83sb111931fd67b4a6d@mail.gmail.com>
References: <499272FA.30902@amnh.org>	
	<AD51AB79BC327C40AB2C7EB75D57A3C40512E7@TOLAR.valuta.nhh.no>	
	<dc22b2570902110412v3130519aiff3deaf23e29ce32@mail.gmail.com>	
	<4992EBB0.20400@amnh.org>	
	<dc22b2570902110728te2cb8b6x1912aeadf1558952@mail.gmail.com>	
	<4993114A.7030602@amnh.org>
	<dc22b2570902111429y4be75d83sb111931fd67b4a6d@mail.gmail.com>
Message-ID: <4993C21B.6050304@amnh.org>

Robert,

This worked - thanks. It's always uplifting to see an actual image after 
working on something for a while. Now I can start playing with 
parameters and playing with different approaches. I'm just (re)starting 
my R education and I'm pretty slow getting the hang of it but your 
examples help a lot. They also give me more avenues to discover other 
functionality and different ways of doing things. I hope I can keep 
working with R and GRASS until I know it this time. My goal is to get to 
the point where I can be productive with these packages and start 
training other folks.

The raster package looks very nice and I'll keep an eye on its 
development. One step that I am currently doing in GRASS is to read a 
Shapefile with training data (polygons with an integer attribute 
representing a land cover type) and then randomly create 100 points 
within each set of polygons representing a specific land cover type. I 
do this for each land cover type and then concatenate the results into a 
text file. This file has the coordinates that I use in xyValues to get 
the pixels values from the SPOT image. Is there a way to do this 
sampling using the raster package or another R package that you are 
familiar with? In GRASS I convert the Shapefile to a raster image before 
doing the random sampling and it would be nice if I could skip this step.

All the best,

Ned

Robert Hijmans wrote:
> I see, in my example, I had a single quantitative variable but you
> probably have land cover classes or something like that. If the
> classes are in fact numbers stored as text then use
>
> pred <- as.numeric(pred)
>
> but if you have words such as 'forest', 'crops', 'water' you could do
> something like
>
> ...
>    pred <- predict(randfor, rowvals)
>    pred[pred=='forest'] <- 1
>    pred[pred=='crops'] <- 2
>    pred[pred=='water'] <- 3
>    pred <- as.numeric(pred)
>    predrast <- setValues(predrast, pred, r)
> ...
>
> not pretty, you could also fit RF with classes that can be interpreted
> as numbers..
> Make sure you do not get:
>
> Warning message:
> NAs introduced by coercion
>
>
> which would suggest that some character values could not be
> transformed to numbers.
>
> On Thu, Feb 12, 2009 at 1:56 AM, Ned Horning <horning at amnh.org> wrote:
>   
>> Robert,
>>
>> Using predrast <- setValues(predrast, as.vector(pred), r) I got another
>> error: values must be numeric, integer or logical.
>>
>> class(pred) = "factor"
>> dim(pred) = NULL
>> class(v) = "character"
>> length(v) == ncol(spot) = TRUE
>>
>>
>>
>>
>>
>> Ned
>>
>> Robert Hijmans wrote:
>>     
>>> Strange. You could try
>>>      predrast <- setValues(predrast, as.vector(pred), r)
>>>
>>> But it would be good to know what pred is.
>>>
>>> Can you do this:
>>>
>>> class(pred)
>>> dim(pred)
>>> v <- as.vector(pred)
>>> class(v)
>>> length(v) == ncol(spot)
>>>
>>>
>>> Robert
>>>
>>>
>>>
>>>
>>> On Wed, Feb 11, 2009 at 11:16 PM, Ned Horning <horning at amnh.org> wrote:
>>>
>>>       
>>>> Robert and Roger,
>>>>
>>>> Thanks for the information and pointers. The raster package looks quite
>>>> interesting and I'll try to get up to speed on some of its capabilities.
>>>> Are
>>>> the man pages the best way to do that or is that a single document
>>>> available?
>>>>
>>>> I made some progress but still have some questions. I followed the steps
>>>> laid out by Robert and everything went fine except I ran into an error
>>>> with
>>>> "predrast <- setValues(predrast, pred, r)" in the for loop when I tried
>>>> processing one line at a time and "r <- setValues(r, pred)" when I ran
>>>> the
>>>> full image in one go. The error was: "values must be a vector." Any idea
>>>> what I'm doing wrong?
>>>>
>>>> I tried to read the GRASS files directly but got a message saying it is
>>>> not
>>>> a supported file format. Can you confirm that is the case or am I doing
>>>> something wrong? I was able to read a tiff version of the image. I am
>>>> able
>>>> to run gdalinfo on GRASS files just fine from a terminal window.
>>>>
>>>> Thanks again for the help.
>>>>
>>>> Ned
>>>>
>>>>
>>>> Robert Hijmans wrote:
>>>>
>>>>         
>>>>> Ned,
>>>>>
>>>>> This is an example of running a RandomForest prediction with the
>>>>> raster package (for the simple case that there are no NA values in the
>>>>> raster data; if there are, you have to into account that "predict'
>>>>> does not return any values (not even NA) for those cells).
>>>>>
>>>>> Robert
>>>>>
>>>>> #install.packages("raster", repos="http://R-Forge.R-project.org")
>>>>> require(raster)
>>>>> require(randomForest)
>>>>>
>>>>> # for single band files
>>>>> spot <- stack('b1.tif', 'b2.tif', 'b3.tif')
>>>>> # for multiple band files
>>>>> # spot <- stackFromFiles(c('bands.tif', 'bands.tif', 'bands.tif'),
>>>>> c(1,2,3) )
>>>>>
>>>>> # simulate random points and values to model with
>>>>> xy <- xyFromCell(spot, round(runif(100) * ncell(spot)))
>>>>> response <- runif(100) * 100
>>>>> # read values of raster layers at points, and bind to respinse
>>>>> trainvals <- cbind(response, xyValues(spot, xy))
>>>>>
>>>>> # run RandomForest
>>>>> randfor <- randomForest(response ~ b1 + b2 + b3, data=trainvals)
>>>>>
>>>>> # apply the prediction, row by row
>>>>> predrast <- setRaster(spot)
>>>>> filename(predrast) <- 'RF_pred.grd'
>>>>> for (r in 1:nrow(spot)) {
>>>>>       spot <- readRow(spot, r)
>>>>>       rowvals <- values(spot, names=TRUE)
>>>>> # this next line should not be necessary, but it is
>>>>> # I'll fix that
>>>>>       colnames(rowvals) <- c('b1', 'b2', 'b3')
>>>>>       pred <- predict(randfor, rowvals)
>>>>>       predrast <- setValues(predrast, pred, r)
>>>>>       predrast <- writeRaster(predrast, overwrite=TRUE)
>>>>> }
>>>>>
>>>>> plot(predrast)
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On Wed, Feb 11, 2009 at 5:09 PM, Roger Bivand <Roger.Bivand at nhh.no>
>>>>> wrote:
>>>>>
>>>>>
>>>>>           
>>>>>> Ned:
>>>>>>
>>>>>>
>>>>>> The three bands are most likely treated as 4-byte integers, so the
>>>>>> object
>>>>>> will be 2732 by 3058 by 3 by 4 plus a little bit. That's 100MB. They
>>>>>> may
>>>>>> get copied too. There are no single byte user-level containers for you
>>>>>> (there is a raw data type, but you can't calculate with it). Possibly
>>>>>> saying spot_frame <- slot(spot, "data") will save one copying
>>>>>> operation,
>>>>>> but its hard to tell - your choice of method first adds inn all the
>>>>>> coordinates, which are 8-byte numbers, so more than doubles its size
>>>>>> and
>>>>>> makes more copies (to 233MB for each copy). Running gc() several times
>>>>>> manually between steps often helps by making the garbage collector more
>>>>>> aggressive.
>>>>>>
>>>>>> I would watch the developments in the R-Forge package "raster", which
>>>>>> builds on some of these things, and try to see how that works. If you
>>>>>> have
>>>>>> the GDAL-GRASS plugin for rasters, you can use readGDAL to read from
>>>>>> GRASS
>>>>>> - which would work with raster package functions now. Look at the code
>>>>>> of
>>>>>> recent readRAST6 to see which incantations are needed. If you are going
>>>>>> to
>>>>>> use randomForest for prediction, you can use smaller tiles until you
>>>>>> find
>>>>>> an alternative solution. Note that feeding a data frame of integers to
>>>>>> a
>>>>>> model fitting or prediction function will result in coercion to a
>>>>>> matrix of doubles, so your subsequent workflow should take that into
>>>>>> account.
>>>>>>  Getting more memory is another option, and may be very cost and
>>>>>> especially
>>>>>> time effective - at the moment your machine is swapping. Buying memory
>>>>>> may
>>>>>> save you time programming around too little memory.
>>>>>>
>>>>>> Hope this helps,
>>>>>>
>>>>>> Roger
>>>>>>
>>>>>>
>>>>>> ---
>>>>>> Roger Bivand, NHH, Helleveien 30, N-5045 Bergen,
>>>>>> Roger.Bivand at nhh.no
>>>>>>
>>>>>>
>>>>>>
>>>>>> -----Original Message-----
>>>>>> From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Ned Horning
>>>>>> Sent: Wed 11.02.2009 07:40
>>>>>> To: r-sig-geo at stat.math.ethz.ch
>>>>>> Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
>>>>>>
>>>>>> Greetings,
>>>>>>
>>>>>> I am trying to read an image from GRASS using the spgrass6 command
>>>>>> readRAST6 and then convert it into a data.frame object so I can use it
>>>>>> with randomForest. The byte image I'm reading is 2732 rows x 3058
>>>>>> columns x 3 bands. It's a small subset of a larger image I would like
>>>>>> to
>>>>>> use eventually. I have no problem reading the image using readRAST6 but
>>>>>> when I try to convert it to a data.frame object my linux system
>>>>>> resources (1BG RAM, 3GB swap) nearly get maxed out and it runs for a
>>>>>> couple hours before I kill the process. The image is less than 25MB so
>>>>>> I'm surprised it requires this level of memory. Can someone let me know
>>>>>> why this is. Should I use something other than the GRASS interface for
>>>>>> this? These are the commands I'm using:
>>>>>>
>>>>>> spot <- readRAST6(c("subset.red", "subset.green", "subset.blue"))
>>>>>> spot_frame <- as(spot, "data.frame")
>>>>>>
>>>>>> Any help would be appreciated.
>>>>>>
>>>>>> All the best,
>>>>>>
>>>>>> Ned
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>      [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>
>>>>>>
>>>>>>
>>>>>>             
>>>>>           
>>>>         
>>>       
>>     
>
>


From r.hijmans at gmail.com  Thu Feb 12 07:40:52 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Thu, 12 Feb 2009 14:40:52 +0800
Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
In-Reply-To: <4993C21B.6050304@amnh.org>
References: <499272FA.30902@amnh.org>
	<AD51AB79BC327C40AB2C7EB75D57A3C40512E7@TOLAR.valuta.nhh.no>
	<dc22b2570902110412v3130519aiff3deaf23e29ce32@mail.gmail.com>
	<4992EBB0.20400@amnh.org>
	<dc22b2570902110728te2cb8b6x1912aeadf1558952@mail.gmail.com>
	<4993114A.7030602@amnh.org>
	<dc22b2570902111429y4be75d83sb111931fd67b4a6d@mail.gmail.com>
	<4993C21B.6050304@amnh.org>
Message-ID: <dc22b2570902112240u42157f07u154e0f1bcb1fc187@mail.gmail.com>

Hi Ned,

Good to hear that. For your other question, have a look at:

require(maptools)
?readShapePoly

require(sp)
?sample.Polygons

Robert


On Thu, Feb 12, 2009 at 2:30 PM, Ned Horning <horning at amnh.org> wrote:
> Robert,
>
> This worked - thanks. It's always uplifting to see an actual image after
> working on something for a while. Now I can start playing with parameters
> and playing with different approaches. I'm just (re)starting my R education
> and I'm pretty slow getting the hang of it but your examples help a lot.
> They also give me more avenues to discover other functionality and different
> ways of doing things. I hope I can keep working with R and GRASS until I
> know it this time. My goal is to get to the point where I can be productive
> with these packages and start training other folks.
>
> The raster package looks very nice and I'll keep an eye on its development.
> One step that I am currently doing in GRASS is to read a Shapefile with
> training data (polygons with an integer attribute representing a land cover
> type) and then randomly create 100 points within each set of polygons
> representing a specific land cover type. I do this for each land cover type
> and then concatenate the results into a text file. This file has the
> coordinates that I use in xyValues to get the pixels values from the SPOT
> image. Is there a way to do this sampling using the raster package or
> another R package that you are familiar with? In GRASS I convert the
> Shapefile to a raster image before doing the random sampling and it would be
> nice if I could skip this step.
>
> All the best,
>
> Ned
>
> Robert Hijmans wrote:
>>
>> I see, in my example, I had a single quantitative variable but you
>> probably have land cover classes or something like that. If the
>> classes are in fact numbers stored as text then use
>>
>> pred <- as.numeric(pred)
>>
>> but if you have words such as 'forest', 'crops', 'water' you could do
>> something like
>>
>> ...
>>   pred <- predict(randfor, rowvals)
>>   pred[pred=='forest'] <- 1
>>   pred[pred=='crops'] <- 2
>>   pred[pred=='water'] <- 3
>>   pred <- as.numeric(pred)
>>   predrast <- setValues(predrast, pred, r)
>> ...
>>
>> not pretty, you could also fit RF with classes that can be interpreted
>> as numbers..
>> Make sure you do not get:
>>
>> Warning message:
>> NAs introduced by coercion
>>
>>
>> which would suggest that some character values could not be
>> transformed to numbers.
>>
>> On Thu, Feb 12, 2009 at 1:56 AM, Ned Horning <horning at amnh.org> wrote:
>>
>>>
>>> Robert,
>>>
>>> Using predrast <- setValues(predrast, as.vector(pred), r) I got another
>>> error: values must be numeric, integer or logical.
>>>
>>> class(pred) = "factor"
>>> dim(pred) = NULL
>>> class(v) = "character"
>>> length(v) == ncol(spot) = TRUE
>>>
>>>
>>>
>>>
>>>
>>> Ned
>>>
>>> Robert Hijmans wrote:
>>>
>>>>
>>>> Strange. You could try
>>>>     predrast <- setValues(predrast, as.vector(pred), r)
>>>>
>>>> But it would be good to know what pred is.
>>>>
>>>> Can you do this:
>>>>
>>>> class(pred)
>>>> dim(pred)
>>>> v <- as.vector(pred)
>>>> class(v)
>>>> length(v) == ncol(spot)
>>>>
>>>>
>>>> Robert
>>>>
>>>>
>>>>
>>>>
>>>> On Wed, Feb 11, 2009 at 11:16 PM, Ned Horning <horning at amnh.org> wrote:
>>>>
>>>>
>>>>>
>>>>> Robert and Roger,
>>>>>
>>>>> Thanks for the information and pointers. The raster package looks quite
>>>>> interesting and I'll try to get up to speed on some of its
>>>>> capabilities.
>>>>> Are
>>>>> the man pages the best way to do that or is that a single document
>>>>> available?
>>>>>
>>>>> I made some progress but still have some questions. I followed the
>>>>> steps
>>>>> laid out by Robert and everything went fine except I ran into an error
>>>>> with
>>>>> "predrast <- setValues(predrast, pred, r)" in the for loop when I tried
>>>>> processing one line at a time and "r <- setValues(r, pred)" when I ran
>>>>> the
>>>>> full image in one go. The error was: "values must be a vector." Any
>>>>> idea
>>>>> what I'm doing wrong?
>>>>>
>>>>> I tried to read the GRASS files directly but got a message saying it is
>>>>> not
>>>>> a supported file format. Can you confirm that is the case or am I doing
>>>>> something wrong? I was able to read a tiff version of the image. I am
>>>>> able
>>>>> to run gdalinfo on GRASS files just fine from a terminal window.
>>>>>
>>>>> Thanks again for the help.
>>>>>
>>>>> Ned
>>>>>
>>>>>
>>>>> Robert Hijmans wrote:
>>>>>
>>>>>
>>>>>>
>>>>>> Ned,
>>>>>>
>>>>>> This is an example of running a RandomForest prediction with the
>>>>>> raster package (for the simple case that there are no NA values in the
>>>>>> raster data; if there are, you have to into account that "predict'
>>>>>> does not return any values (not even NA) for those cells).
>>>>>>
>>>>>> Robert
>>>>>>
>>>>>> #install.packages("raster", repos="http://R-Forge.R-project.org")
>>>>>> require(raster)
>>>>>> require(randomForest)
>>>>>>
>>>>>> # for single band files
>>>>>> spot <- stack('b1.tif', 'b2.tif', 'b3.tif')
>>>>>> # for multiple band files
>>>>>> # spot <- stackFromFiles(c('bands.tif', 'bands.tif', 'bands.tif'),
>>>>>> c(1,2,3) )
>>>>>>
>>>>>> # simulate random points and values to model with
>>>>>> xy <- xyFromCell(spot, round(runif(100) * ncell(spot)))
>>>>>> response <- runif(100) * 100
>>>>>> # read values of raster layers at points, and bind to respinse
>>>>>> trainvals <- cbind(response, xyValues(spot, xy))
>>>>>>
>>>>>> # run RandomForest
>>>>>> randfor <- randomForest(response ~ b1 + b2 + b3, data=trainvals)
>>>>>>
>>>>>> # apply the prediction, row by row
>>>>>> predrast <- setRaster(spot)
>>>>>> filename(predrast) <- 'RF_pred.grd'
>>>>>> for (r in 1:nrow(spot)) {
>>>>>>      spot <- readRow(spot, r)
>>>>>>      rowvals <- values(spot, names=TRUE)
>>>>>> # this next line should not be necessary, but it is
>>>>>> # I'll fix that
>>>>>>      colnames(rowvals) <- c('b1', 'b2', 'b3')
>>>>>>      pred <- predict(randfor, rowvals)
>>>>>>      predrast <- setValues(predrast, pred, r)
>>>>>>      predrast <- writeRaster(predrast, overwrite=TRUE)
>>>>>> }
>>>>>>
>>>>>> plot(predrast)
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> On Wed, Feb 11, 2009 at 5:09 PM, Roger Bivand <Roger.Bivand at nhh.no>
>>>>>> wrote:
>>>>>>
>>>>>>
>>>>>>
>>>>>>>
>>>>>>> Ned:
>>>>>>>
>>>>>>>
>>>>>>> The three bands are most likely treated as 4-byte integers, so the
>>>>>>> object
>>>>>>> will be 2732 by 3058 by 3 by 4 plus a little bit. That's 100MB. They
>>>>>>> may
>>>>>>> get copied too. There are no single byte user-level containers for
>>>>>>> you
>>>>>>> (there is a raw data type, but you can't calculate with it). Possibly
>>>>>>> saying spot_frame <- slot(spot, "data") will save one copying
>>>>>>> operation,
>>>>>>> but its hard to tell - your choice of method first adds inn all the
>>>>>>> coordinates, which are 8-byte numbers, so more than doubles its size
>>>>>>> and
>>>>>>> makes more copies (to 233MB for each copy). Running gc() several
>>>>>>> times
>>>>>>> manually between steps often helps by making the garbage collector
>>>>>>> more
>>>>>>> aggressive.
>>>>>>>
>>>>>>> I would watch the developments in the R-Forge package "raster", which
>>>>>>> builds on some of these things, and try to see how that works. If you
>>>>>>> have
>>>>>>> the GDAL-GRASS plugin for rasters, you can use readGDAL to read from
>>>>>>> GRASS
>>>>>>> - which would work with raster package functions now. Look at the
>>>>>>> code
>>>>>>> of
>>>>>>> recent readRAST6 to see which incantations are needed. If you are
>>>>>>> going
>>>>>>> to
>>>>>>> use randomForest for prediction, you can use smaller tiles until you
>>>>>>> find
>>>>>>> an alternative solution. Note that feeding a data frame of integers
>>>>>>> to
>>>>>>> a
>>>>>>> model fitting or prediction function will result in coercion to a
>>>>>>> matrix of doubles, so your subsequent workflow should take that into
>>>>>>> account.
>>>>>>>  Getting more memory is another option, and may be very cost and
>>>>>>> especially
>>>>>>> time effective - at the moment your machine is swapping. Buying
>>>>>>> memory
>>>>>>> may
>>>>>>> save you time programming around too little memory.
>>>>>>>
>>>>>>> Hope this helps,
>>>>>>>
>>>>>>> Roger
>>>>>>>
>>>>>>>
>>>>>>> ---
>>>>>>> Roger Bivand, NHH, Helleveien 30, N-5045 Bergen,
>>>>>>> Roger.Bivand at nhh.no
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> -----Original Message-----
>>>>>>> From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Ned Horning
>>>>>>> Sent: Wed 11.02.2009 07:40
>>>>>>> To: r-sig-geo at stat.math.ethz.ch
>>>>>>> Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
>>>>>>>
>>>>>>> Greetings,
>>>>>>>
>>>>>>> I am trying to read an image from GRASS using the spgrass6 command
>>>>>>> readRAST6 and then convert it into a data.frame object so I can use
>>>>>>> it
>>>>>>> with randomForest. The byte image I'm reading is 2732 rows x 3058
>>>>>>> columns x 3 bands. It's a small subset of a larger image I would like
>>>>>>> to
>>>>>>> use eventually. I have no problem reading the image using readRAST6
>>>>>>> but
>>>>>>> when I try to convert it to a data.frame object my linux system
>>>>>>> resources (1BG RAM, 3GB swap) nearly get maxed out and it runs for a
>>>>>>> couple hours before I kill the process. The image is less than 25MB
>>>>>>> so
>>>>>>> I'm surprised it requires this level of memory. Can someone let me
>>>>>>> know
>>>>>>> why this is. Should I use something other than the GRASS interface
>>>>>>> for
>>>>>>> this? These are the commands I'm using:
>>>>>>>
>>>>>>> spot <- readRAST6(c("subset.red", "subset.green", "subset.blue"))
>>>>>>> spot_frame <- as(spot, "data.frame")
>>>>>>>
>>>>>>> Any help would be appreciated.
>>>>>>>
>>>>>>> All the best,
>>>>>>>
>>>>>>> Ned
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-Geo mailing list
>>>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>     [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-Geo mailing list
>>>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>
>>>
>>
>>
>
>


From Roger.Bivand at nhh.no  Thu Feb 12 08:14:19 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 12 Feb 2009 08:14:19 +0100 (CET)
Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
In-Reply-To: <dc22b2570902112240u42157f07u154e0f1bcb1fc187@mail.gmail.com>
References: <499272FA.30902@amnh.org>
	<AD51AB79BC327C40AB2C7EB75D57A3C40512E7@TOLAR.valuta.nhh.no>
	<dc22b2570902110412v3130519aiff3deaf23e29ce32@mail.gmail.com>
	<4992EBB0.20400@amnh.org>
	<dc22b2570902110728te2cb8b6x1912aeadf1558952@mail.gmail.com>
	<4993114A.7030602@amnh.org>
	<dc22b2570902111429y4be75d83sb111931fd67b4a6d@mail.gmail.com>
	<4993C21B.6050304@amnh.org>
	<dc22b2570902112240u42157f07u154e0f1bcb1fc187@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0902120809260.2930@reclus.nhh.no>

On Thu, 12 Feb 2009, Robert Hijmans wrote:

> Hi Ned,
>
> Good to hear that. For your other question, have a look at:
>
> require(maptools)
> ?readShapePoly

Or more generally readOGR() in rgdal for another use of the underlying 
shapelib code.

>
> require(sp)
> ?sample.Polygons
>

Most likely the spsample() method will be enough, without having to pick a 
specific method - but if necessary the Polygons objects can be dissolved 
using unionSpatialPolygons() in maptools.

Roger

> Robert
>
>
> On Thu, Feb 12, 2009 at 2:30 PM, Ned Horning <horning at amnh.org> wrote:
>> Robert,
>>
>> This worked - thanks. It's always uplifting to see an actual image after
>> working on something for a while. Now I can start playing with parameters
>> and playing with different approaches. I'm just (re)starting my R education
>> and I'm pretty slow getting the hang of it but your examples help a lot.
>> They also give me more avenues to discover other functionality and different
>> ways of doing things. I hope I can keep working with R and GRASS until I
>> know it this time. My goal is to get to the point where I can be productive
>> with these packages and start training other folks.
>>
>> The raster package looks very nice and I'll keep an eye on its development.
>> One step that I am currently doing in GRASS is to read a Shapefile with
>> training data (polygons with an integer attribute representing a land cover
>> type) and then randomly create 100 points within each set of polygons
>> representing a specific land cover type. I do this for each land cover type
>> and then concatenate the results into a text file. This file has the
>> coordinates that I use in xyValues to get the pixels values from the SPOT
>> image. Is there a way to do this sampling using the raster package or
>> another R package that you are familiar with? In GRASS I convert the
>> Shapefile to a raster image before doing the random sampling and it would be
>> nice if I could skip this step.
>>
>> All the best,
>>
>> Ned
>>
>> Robert Hijmans wrote:
>>>
>>> I see, in my example, I had a single quantitative variable but you
>>> probably have land cover classes or something like that. If the
>>> classes are in fact numbers stored as text then use
>>>
>>> pred <- as.numeric(pred)
>>>
>>> but if you have words such as 'forest', 'crops', 'water' you could do
>>> something like
>>>
>>> ...
>>>   pred <- predict(randfor, rowvals)
>>>   pred[pred=='forest'] <- 1
>>>   pred[pred=='crops'] <- 2
>>>   pred[pred=='water'] <- 3
>>>   pred <- as.numeric(pred)
>>>   predrast <- setValues(predrast, pred, r)
>>> ...
>>>
>>> not pretty, you could also fit RF with classes that can be interpreted
>>> as numbers..
>>> Make sure you do not get:
>>>
>>> Warning message:
>>> NAs introduced by coercion
>>>
>>>
>>> which would suggest that some character values could not be
>>> transformed to numbers.
>>>
>>> On Thu, Feb 12, 2009 at 1:56 AM, Ned Horning <horning at amnh.org> wrote:
>>>
>>>>
>>>> Robert,
>>>>
>>>> Using predrast <- setValues(predrast, as.vector(pred), r) I got another
>>>> error: values must be numeric, integer or logical.
>>>>
>>>> class(pred) = "factor"
>>>> dim(pred) = NULL
>>>> class(v) = "character"
>>>> length(v) == ncol(spot) = TRUE
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> Ned
>>>>
>>>> Robert Hijmans wrote:
>>>>
>>>>>
>>>>> Strange. You could try
>>>>>     predrast <- setValues(predrast, as.vector(pred), r)
>>>>>
>>>>> But it would be good to know what pred is.
>>>>>
>>>>> Can you do this:
>>>>>
>>>>> class(pred)
>>>>> dim(pred)
>>>>> v <- as.vector(pred)
>>>>> class(v)
>>>>> length(v) == ncol(spot)
>>>>>
>>>>>
>>>>> Robert
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On Wed, Feb 11, 2009 at 11:16 PM, Ned Horning <horning at amnh.org> wrote:
>>>>>
>>>>>
>>>>>>
>>>>>> Robert and Roger,
>>>>>>
>>>>>> Thanks for the information and pointers. The raster package looks quite
>>>>>> interesting and I'll try to get up to speed on some of its
>>>>>> capabilities.
>>>>>> Are
>>>>>> the man pages the best way to do that or is that a single document
>>>>>> available?
>>>>>>
>>>>>> I made some progress but still have some questions. I followed the
>>>>>> steps
>>>>>> laid out by Robert and everything went fine except I ran into an error
>>>>>> with
>>>>>> "predrast <- setValues(predrast, pred, r)" in the for loop when I tried
>>>>>> processing one line at a time and "r <- setValues(r, pred)" when I ran
>>>>>> the
>>>>>> full image in one go. The error was: "values must be a vector." Any
>>>>>> idea
>>>>>> what I'm doing wrong?
>>>>>>
>>>>>> I tried to read the GRASS files directly but got a message saying it is
>>>>>> not
>>>>>> a supported file format. Can you confirm that is the case or am I doing
>>>>>> something wrong? I was able to read a tiff version of the image. I am
>>>>>> able
>>>>>> to run gdalinfo on GRASS files just fine from a terminal window.
>>>>>>
>>>>>> Thanks again for the help.
>>>>>>
>>>>>> Ned
>>>>>>
>>>>>>
>>>>>> Robert Hijmans wrote:
>>>>>>
>>>>>>
>>>>>>>
>>>>>>> Ned,
>>>>>>>
>>>>>>> This is an example of running a RandomForest prediction with the
>>>>>>> raster package (for the simple case that there are no NA values in the
>>>>>>> raster data; if there are, you have to into account that "predict'
>>>>>>> does not return any values (not even NA) for those cells).
>>>>>>>
>>>>>>> Robert
>>>>>>>
>>>>>>> #install.packages("raster", repos="http://R-Forge.R-project.org")
>>>>>>> require(raster)
>>>>>>> require(randomForest)
>>>>>>>
>>>>>>> # for single band files
>>>>>>> spot <- stack('b1.tif', 'b2.tif', 'b3.tif')
>>>>>>> # for multiple band files
>>>>>>> # spot <- stackFromFiles(c('bands.tif', 'bands.tif', 'bands.tif'),
>>>>>>> c(1,2,3) )
>>>>>>>
>>>>>>> # simulate random points and values to model with
>>>>>>> xy <- xyFromCell(spot, round(runif(100) * ncell(spot)))
>>>>>>> response <- runif(100) * 100
>>>>>>> # read values of raster layers at points, and bind to respinse
>>>>>>> trainvals <- cbind(response, xyValues(spot, xy))
>>>>>>>
>>>>>>> # run RandomForest
>>>>>>> randfor <- randomForest(response ~ b1 + b2 + b3, data=trainvals)
>>>>>>>
>>>>>>> # apply the prediction, row by row
>>>>>>> predrast <- setRaster(spot)
>>>>>>> filename(predrast) <- 'RF_pred.grd'
>>>>>>> for (r in 1:nrow(spot)) {
>>>>>>>      spot <- readRow(spot, r)
>>>>>>>      rowvals <- values(spot, names=TRUE)
>>>>>>> # this next line should not be necessary, but it is
>>>>>>> # I'll fix that
>>>>>>>      colnames(rowvals) <- c('b1', 'b2', 'b3')
>>>>>>>      pred <- predict(randfor, rowvals)
>>>>>>>      predrast <- setValues(predrast, pred, r)
>>>>>>>      predrast <- writeRaster(predrast, overwrite=TRUE)
>>>>>>> }
>>>>>>>
>>>>>>> plot(predrast)
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> On Wed, Feb 11, 2009 at 5:09 PM, Roger Bivand <Roger.Bivand at nhh.no>
>>>>>>> wrote:
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>>
>>>>>>>> Ned:
>>>>>>>>
>>>>>>>>
>>>>>>>> The three bands are most likely treated as 4-byte integers, so the
>>>>>>>> object
>>>>>>>> will be 2732 by 3058 by 3 by 4 plus a little bit. That's 100MB. They
>>>>>>>> may
>>>>>>>> get copied too. There are no single byte user-level containers for
>>>>>>>> you
>>>>>>>> (there is a raw data type, but you can't calculate with it). Possibly
>>>>>>>> saying spot_frame <- slot(spot, "data") will save one copying
>>>>>>>> operation,
>>>>>>>> but its hard to tell - your choice of method first adds inn all the
>>>>>>>> coordinates, which are 8-byte numbers, so more than doubles its size
>>>>>>>> and
>>>>>>>> makes more copies (to 233MB for each copy). Running gc() several
>>>>>>>> times
>>>>>>>> manually between steps often helps by making the garbage collector
>>>>>>>> more
>>>>>>>> aggressive.
>>>>>>>>
>>>>>>>> I would watch the developments in the R-Forge package "raster", which
>>>>>>>> builds on some of these things, and try to see how that works. If you
>>>>>>>> have
>>>>>>>> the GDAL-GRASS plugin for rasters, you can use readGDAL to read from
>>>>>>>> GRASS
>>>>>>>> - which would work with raster package functions now. Look at the
>>>>>>>> code
>>>>>>>> of
>>>>>>>> recent readRAST6 to see which incantations are needed. If you are
>>>>>>>> going
>>>>>>>> to
>>>>>>>> use randomForest for prediction, you can use smaller tiles until you
>>>>>>>> find
>>>>>>>> an alternative solution. Note that feeding a data frame of integers
>>>>>>>> to
>>>>>>>> a
>>>>>>>> model fitting or prediction function will result in coercion to a
>>>>>>>> matrix of doubles, so your subsequent workflow should take that into
>>>>>>>> account.
>>>>>>>>  Getting more memory is another option, and may be very cost and
>>>>>>>> especially
>>>>>>>> time effective - at the moment your machine is swapping. Buying
>>>>>>>> memory
>>>>>>>> may
>>>>>>>> save you time programming around too little memory.
>>>>>>>>
>>>>>>>> Hope this helps,
>>>>>>>>
>>>>>>>> Roger
>>>>>>>>
>>>>>>>>
>>>>>>>> ---
>>>>>>>> Roger Bivand, NHH, Helleveien 30, N-5045 Bergen,
>>>>>>>> Roger.Bivand at nhh.no
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> -----Original Message-----
>>>>>>>> From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Ned Horning
>>>>>>>> Sent: Wed 11.02.2009 07:40
>>>>>>>> To: r-sig-geo at stat.math.ethz.ch
>>>>>>>> Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
>>>>>>>>
>>>>>>>> Greetings,
>>>>>>>>
>>>>>>>> I am trying to read an image from GRASS using the spgrass6 command
>>>>>>>> readRAST6 and then convert it into a data.frame object so I can use
>>>>>>>> it
>>>>>>>> with randomForest. The byte image I'm reading is 2732 rows x 3058
>>>>>>>> columns x 3 bands. It's a small subset of a larger image I would like
>>>>>>>> to
>>>>>>>> use eventually. I have no problem reading the image using readRAST6
>>>>>>>> but
>>>>>>>> when I try to convert it to a data.frame object my linux system
>>>>>>>> resources (1BG RAM, 3GB swap) nearly get maxed out and it runs for a
>>>>>>>> couple hours before I kill the process. The image is less than 25MB
>>>>>>>> so
>>>>>>>> I'm surprised it requires this level of memory. Can someone let me
>>>>>>>> know
>>>>>>>> why this is. Should I use something other than the GRASS interface
>>>>>>>> for
>>>>>>>> this? These are the commands I'm using:
>>>>>>>>
>>>>>>>> spot <- readRAST6(c("subset.red", "subset.green", "subset.blue"))
>>>>>>>> spot_frame <- as(spot, "data.frame")
>>>>>>>>
>>>>>>>> Any help would be appreciated.
>>>>>>>>
>>>>>>>> All the best,
>>>>>>>>
>>>>>>>> Ned
>>>>>>>>
>>>>>>>> _______________________________________________
>>>>>>>> R-sig-Geo mailing list
>>>>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>     [[alternative HTML version deleted]]
>>>>>>>>
>>>>>>>> _______________________________________________
>>>>>>>> R-sig-Geo mailing list
>>>>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>
>>>
>>
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From PJ at DCE.AU.DK  Thu Feb 12 09:29:34 2009
From: PJ at DCE.AU.DK (Peter Jepsen)
Date: Thu, 12 Feb 2009 09:29:34 +0100
Subject: [R-sig-Geo] How to move an island?!
Message-ID: <BF9B6C436B8F26458D7F5FC295C7770101CCC24D@gere.svf.au.dk>

Dear all,

I have only just begun plotting on maps, so please bear with me. I am
plotting a map of Denmark in which each county is colorcoded by its
incidence of a particular disease. I am using the map data found at
http://biogeo.berkeley.edu/bgm/gdatares.php. The map is perfect, but the
island of Bornholm, which is located far east of the rest of Denmark, is
in its rightful place. To make the map look better, I want to move it
northwest and put a box around it - this is common practice for maps of
Denmark, in case you wonder.

I thought that I could simply find the coordinates for Bornholm and
change them by subtraction/addition, but I can't make it work. 

For simplicity, I first create a separate dataset for Bornholm:

born <- dmk[dmk[[3]]=="Bornholm",]
> class(born)
[1] "SpatialPolygonsDataFrame"
attr(,"package")
[1] "sp"

The output from the command -slot(born, "polygons")- is long and pasted
at the bottom of this mail. Bornholm is made up of 5 polygons. How do I
access and change the coordinates?  

----
> sessionInfo()
R version 2.8.1 (2008-12-22) 
i386-pc-mingw32 

locale:
LC_COLLATE=Danish_Denmark.1252;LC_CTYPE=Danish_Denmark.1252;LC_MONETARY=
Danish_Denmark.1252;LC_NUMERIC=C;LC_TIME=Danish_Denmark.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


other attached packages:
[1] RColorBrewer_1.0-2 maptools_0.7-18    sp_0.9-29
foreign_0.8-30    
[5] chron_2.3-28       reshape_0.8.2      plyr_0.1.4         epiR_0.9-14


loaded via a namespace (and not attached):
[1] grid_2.8.1      lattice_0.17-20
----
Thank you in advance for any help!

Kind regards,
Peter Jepsen, MD.




> slot(born,"polygons")
[[1]]
An object of class "Polygons"
Slot "Polygons":
[[1]]
An object of class "Polygon"
Slot "labpt":
[1] 14.93360 55.18284

Slot "area":
[1] 0.02132633

Slot "hole":
[1] FALSE

Slot "ringDir":
[1] 1

Slot "coords":
           [,1]     [,2]
  [1,] 14.74450 55.25941
  [2,] 14.74954 55.26576
  [3,] 14.75460 55.27808
  [4,] 14.75489 55.27881
  [5,] 14.75441 55.28239
  [6,] 14.75381 55.28687
  [7,] 14.75334 55.29034
  [8,] 14.77223 55.30014
  [9,] 14.77590 55.29659
 [10,] 14.77639 55.29427
 [11,] 14.77480 55.29263
 [12,] 14.77608 55.29094
 [13,] 14.78393 55.28999
 [14,] 14.78513 55.28917
 [15,] 14.78525 55.28828
 [16,] 14.78637 55.28833
 [17,] 14.79954 55.27936
 [18,] 14.80229 55.27904
 [19,] 14.80276 55.27554
 [20,] 14.80441 55.27561
 [21,] 14.80461 55.27444
 [22,] 14.81148 55.26933
 [23,] 14.81180 55.26692
 [24,] 14.81396 55.26702
 [25,] 14.81659 55.25968
 [26,] 14.82223 55.25358
 [27,] 14.82505 55.25293
 [28,] 14.82914 55.25199
 [29,] 14.83412 55.24869
 [30,] 14.84561 55.24796
 [31,] 14.85450 55.24211
 [32,] 14.87069 55.23971
 [33,] 14.87092 55.23798
 [34,] 14.87394 55.23811
 [35,] 14.87913 55.23555
 [36,] 14.87980 55.23404
 [37,] 14.88147 55.23028
 [38,] 14.88653 55.22743
 [39,] 14.90632 55.22203
 [40,] 14.91248 55.22152
 [41,] 14.91856 55.22101
 [42,] 14.93965 55.21001
 [43,] 14.94801 55.20969
 [44,] 14.95554 55.21334
 [45,] 14.96859 55.21518
 [46,] 14.97698 55.21123
 [47,] 14.97758 55.20655
 [48,] 14.98081 55.20669
 [49,] 14.98628 55.20021
 [50,] 14.98658 55.19793
 [51,] 14.98815 55.19799
 [52,] 14.99110 55.19450
 [53,] 14.99268 55.19233
 [54,] 15.00000 55.18967
 [55,] 15.00427 55.18813
 [56,] 15.01794 55.17828
 [57,] 15.02075 55.17723
 [58,] 15.03137 55.17327
 [59,] 15.03702 55.17277
 [60,] 15.04160 55.17237
 [61,] 15.04540 55.16927
 [62,] 15.04712 55.16787
 [63,] 15.05378 55.16531
 [64,] 15.05790 55.16372
 [65,] 15.06153 55.15981
 [66,] 15.07202 55.15820
 [67,] 15.07648 55.15446
 [68,] 15.09657 55.14877
 [69,] 15.10328 55.14748
 [70,] 15.10368 55.14431
 [71,] 15.09584 55.14398
 [72,] 15.09640 55.13950
 [73,] 15.09696 55.13501
 [74,] 15.08913 55.13469
 [75,] 15.08969 55.13020
 [76,] 15.09025 55.12572
 [77,] 15.08242 55.12539
 [78,] 15.08299 55.12091
 [79,] 15.08355 55.11643
 [80,] 15.07572 55.11610
 [81,] 15.07628 55.11161
 [82,] 15.07684 55.10713
 [83,] 15.06902 55.10680
 [84,] 15.06958 55.10232
 [85,] 15.06176 55.10199
 [86,] 15.05393 55.10166
 [87,] 15.04611 55.10133
 [88,] 15.03828 55.10099
 [89,] 15.03046 55.10066
 [90,] 15.02263 55.10033
 [91,] 15.01481 55.09999
 [92,] 15.00699 55.09966
 [93,] 14.99916 55.09932
 [94,] 14.99859 55.10381
 [95,] 14.99077 55.10347
 [96,] 14.98294 55.10313
 [97,] 14.98237 55.10761
 [98,] 14.97455 55.10728
 [99,] 14.97397 55.11176
[100,] 14.97340 55.11624
[101,] 14.97282 55.12072
[102,] 14.97225 55.12521
[103,] 14.97168 55.12969
[104,] 14.96385 55.12935
[105,] 14.96327 55.13383
[106,] 14.95544 55.13349
[107,] 14.94761 55.13316
[108,] 14.94703 55.13764
[109,] 14.93920 55.13730
[110,] 14.93137 55.13696
[111,] 14.93079 55.14144
[112,] 14.92296 55.14110
[113,] 14.91513 55.14076
[114,] 14.91455 55.14524
[115,] 14.90672 55.14490
[116,] 14.89889 55.14456
[117,] 14.89830 55.14904
[118,] 14.89772 55.15352
[119,] 14.89714 55.15800
[120,] 14.89655 55.16248
[121,] 14.90439 55.16282
[122,] 14.90381 55.16731
[123,] 14.90322 55.17179
[124,] 14.89539 55.17144
[125,] 14.88755 55.17110
[126,] 14.87971 55.17076
[127,] 14.87913 55.17524
[128,] 14.87129 55.17490
[129,] 14.87070 55.17938
[130,] 14.87012 55.18386
[131,] 14.86953 55.18834
[132,] 14.86894 55.19282
[133,] 14.86836 55.19730
[134,] 14.86051 55.19696
[135,] 14.85993 55.20144
[136,] 14.86777 55.20178
[137,] 14.86718 55.20626
[138,] 14.86659 55.21075
[139,] 14.85875 55.21040
[140,] 14.85816 55.21488
[141,] 14.85032 55.21454
[142,] 14.84247 55.21419
[143,] 14.83462 55.21384
[144,] 14.83522 55.20937
[145,] 14.82737 55.20902
[146,] 14.82678 55.21350
[147,] 14.81893 55.21315
[148,] 14.81834 55.21763
[149,] 14.81050 55.21729
[150,] 14.80990 55.22177
[151,] 14.80206 55.22142
[152,] 14.80146 55.22590
[153,] 14.79361 55.22555
[154,] 14.78577 55.22520
[155,] 14.78636 55.22072
[156,] 14.77852 55.22037
[157,] 14.77792 55.22485
[158,] 14.77007 55.22450
[159,] 14.76947 55.22898
[160,] 14.76887 55.23346
[161,] 14.76827 55.23794
[162,] 14.76767 55.24242
[163,] 14.76707 55.24690
[164,] 14.76647 55.25138
[165,] 14.76587 55.25586
[166,] 14.76527 55.26034
[167,] 14.75742 55.25999
[168,] 14.74957 55.25964
[169,] 14.74450 55.25941


[[2]]
An object of class "Polygon"
Slot "labpt":
[1] 14.74174 55.25531

Slot "area":
[1] 1.212006e-06

Slot "hole":
[1] FALSE

Slot "ringDir":
[1] 1

Slot "coords":
         [,1]     [,2]
[1,] 14.74079 55.25474
[2,] 14.74210 55.25639
[3,] 14.74232 55.25481
[4,] 14.74079 55.25474



Slot "plotOrder":
[1] 1 2

Slot "labpt":
[1] 14.93360 55.18284

Slot "ID":
[1] "9"

Slot "area":
[1] 0.02132754


[[2]]
An object of class "Polygons"
Slot "Polygons":
[[1]]
An object of class "Polygon"
Slot "labpt":
[1] 14.78569 55.18178

Slot "area":
[1] 0.01632464

Slot "hole":
[1] FALSE

Slot "ringDir":
[1] 1

Slot "coords":
           [,1]     [,2]
  [1,] 14.74450 55.25941
  [2,] 14.74957 55.25964
  [3,] 14.75742 55.25999
  [4,] 14.76527 55.26034
  [5,] 14.76587 55.25586
  [6,] 14.76647 55.25138
  [7,] 14.76707 55.24690
  [8,] 14.76767 55.24242
  [9,] 14.76827 55.23794
 [10,] 14.76887 55.23346
 [11,] 14.76947 55.22898
 [12,] 14.77007 55.22450
 [13,] 14.77792 55.22485
 [14,] 14.77852 55.22037
 [15,] 14.78636 55.22072
 [16,] 14.78577 55.22520
 [17,] 14.79361 55.22555
 [18,] 14.80146 55.22590
 [19,] 14.80206 55.22142
 [20,] 14.80990 55.22177
 [21,] 14.81050 55.21729
 [22,] 14.81834 55.21763
 [23,] 14.81893 55.21315
 [24,] 14.82678 55.21350
 [25,] 14.82737 55.20902
 [26,] 14.83522 55.20937
 [27,] 14.83462 55.21384
 [28,] 14.84247 55.21419
 [29,] 14.85032 55.21454
 [30,] 14.85816 55.21488
 [31,] 14.85875 55.21040
 [32,] 14.86659 55.21075
 [33,] 14.86718 55.20626
 [34,] 14.86777 55.20178
 [35,] 14.85993 55.20144
 [36,] 14.86051 55.19696
 [37,] 14.86836 55.19730
 [38,] 14.86894 55.19282
 [39,] 14.86953 55.18834
 [40,] 14.87012 55.18386
 [41,] 14.87070 55.17938
 [42,] 14.87129 55.17490
 [43,] 14.87913 55.17524
 [44,] 14.87971 55.17076
 [45,] 14.88755 55.17110
 [46,] 14.89539 55.17144
 [47,] 14.90322 55.17179
 [48,] 14.90381 55.16731
 [49,] 14.90439 55.16282
 [50,] 14.89655 55.16248
 [51,] 14.89714 55.15800
 [52,] 14.89772 55.15352
 [53,] 14.89830 55.14904
 [54,] 14.89889 55.14456
 [55,] 14.89947 55.14008
 [56,] 14.90005 55.13559
 [57,] 14.89222 55.13525
 [58,] 14.89281 55.13077
 [59,] 14.88498 55.13043
 [60,] 14.88439 55.13491
 [61,] 14.88381 55.13939
 [62,] 14.88322 55.14387
 [63,] 14.87539 55.14353
 [64,] 14.86756 55.14318
 [65,] 14.85973 55.14284
 [66,] 14.85190 55.14249
 [67,] 14.84407 55.14215
 [68,] 14.83624 55.14180
 [69,] 14.83565 55.14628
 [70,] 14.82782 55.14594
 [71,] 14.82841 55.14146
 [72,] 14.82057 55.14111
 [73,] 14.81275 55.14076
 [74,] 14.81334 55.13628
 [75,] 14.80551 55.13593
 [76,] 14.80610 55.13145
 [77,] 14.79827 55.13110
 [78,] 14.79044 55.13075
 [79,] 14.78262 55.13041
 [80,] 14.77479 55.13005
 [81,] 14.77538 55.12557
 [82,] 14.76756 55.12522
 [83,] 14.76696 55.12970
 [84,] 14.75913 55.12935
 [85,] 14.75130 55.12900
 [86,] 14.74348 55.12865
 [87,] 14.73565 55.12830
 [88,] 14.73505 55.13277
 [89,] 14.72722 55.13242
 [90,] 14.72662 55.13690
 [91,] 14.72602 55.14138
 [92,] 14.71819 55.14103
 [93,] 14.71758 55.14551
 [94,] 14.70975 55.14516
 [95,] 14.70351 55.14487
 [96,] 14.70161 55.14808
 [97,] 14.70150 55.14925
 [98,] 14.70396 55.16602
 [99,] 14.70121 55.17632
[100,] 14.70552 55.17652
[101,] 14.70491 55.18100
[102,] 14.70003 55.18077
[103,] 14.69929 55.18353
[104,] 14.70236 55.18701
[105,] 14.69951 55.19428
[106,] 14.70310 55.19444
[107,] 14.70249 55.19892
[108,] 14.70225 55.20072
[109,] 14.70455 55.20477
[110,] 14.70318 55.21014
[111,] 14.70527 55.21257
[112,] 14.70851 55.21272
[113,] 14.70809 55.21585
[114,] 14.70936 55.21733
[115,] 14.70820 55.22176
[116,] 14.71488 55.22731
[117,] 14.71952 55.23575
[118,] 14.72118 55.23582
[119,] 14.72101 55.23705
[120,] 14.73076 55.24552
[121,] 14.73948 55.25308
[122,] 14.74079 55.25474
[123,] 14.74232 55.25481
[124,] 14.74210 55.25639
[125,] 14.74450 55.25941



Slot "plotOrder":
[1] 1

Slot "labpt":
[1] 14.78569 55.18178

Slot "ID":
[1] "78"

Slot "area":
[1] 0.01632464


[[3]]
An object of class "Polygons"
Slot "Polygons":
[[1]]
An object of class "Polygon"
Slot "labpt":
[1] 15.07812 55.06290

Slot "area":
[1] 0.01516297

Slot "hole":
[1] FALSE

Slot "ringDir":
[1] 1

Slot "coords":
           [,1]     [,2]
  [1,] 15.10328 55.14748
  [2,] 15.11661 55.14492
  [3,] 15.12046 55.14214
  [4,] 15.14019 55.14267
  [5,] 15.14262 55.13884
  [6,] 15.14372 55.13885
  [7,] 15.14395 55.13698
  [8,] 15.14862 55.13717
  [9,] 15.14859 55.13269
 [10,] 15.15228 55.13227
 [11,] 15.15289 55.12834
 [12,] 15.15345 55.12386
 [13,] 15.14562 55.12353
 [14,] 15.14617 55.11905
 [15,] 15.14673 55.11456
 [16,] 15.14531 55.11247
 [17,] 15.14700 55.10990
 [18,] 15.14783 55.10560
 [19,] 15.14816 55.10296
 [20,] 15.14824 55.10228
 [21,] 15.14860 55.10119
 [22,] 15.14878 55.09883
 [23,] 15.14894 55.09663
 [24,] 15.15135 55.09673
 [25,] 15.15702 55.09211
 [26,] 15.15731 55.09067
 [27,] 15.15512 55.08769
 [28,] 15.15869 55.08134
 [29,] 15.15641 55.07892
 [30,] 15.15115 55.07870
 [31,] 15.15160 55.07509
 [32,] 15.15010 55.07415
 [33,] 15.14389 55.07389
 [34,] 15.14430 55.07052
 [35,] 15.14239 55.06932
 [36,] 15.13662 55.06908
 [37,] 15.13720 55.06625
 [38,] 15.13755 55.06459
 [39,] 15.12936 55.06428
 [40,] 15.12991 55.05979
 [41,] 15.13042 55.05565
 [42,] 15.12265 55.05499
 [43,] 15.12321 55.05050
 [44,] 15.11539 55.05017
 [45,] 15.11595 55.04569
 [46,] 15.11650 55.04121
 [47,] 15.10869 55.04088
 [48,] 15.10957 55.03604
 [49,] 15.11614 55.02894
 [50,] 15.11816 55.02788
 [51,] 15.11873 55.02328
 [52,] 15.11893 55.02163
 [53,] 15.11708 55.01969
 [54,] 15.11950 55.01705
 [55,] 15.11992 55.01417
 [56,] 15.11203 55.01398
 [57,] 15.11257 55.00961
 [58,] 15.10478 55.00917
 [59,] 15.10528 55.00509
 [60,] 15.09753 55.00436
 [61,] 15.09805 55.00013
 [62,] 15.09028 54.99955
 [63,] 15.09084 54.99507
 [64,] 15.08304 54.99474
 [65,] 15.08360 54.99025
 [66,] 15.07579 54.98993
 [67,] 15.06799 54.98959
 [68,] 15.06019 54.98926
 [69,] 15.05239 54.98893
 [70,] 15.05182 54.99342
 [71,] 15.04402 54.99308
 [72,] 15.03622 54.99275
 [73,] 15.03565 54.99723
 [74,] 15.02785 54.99690
 [75,] 15.02005 54.99657
 [76,] 15.01948 55.00105
 [77,] 15.01167 55.00071
 [78,] 15.00387 55.00038
 [79,] 14.99607 55.00004
 [80,] 14.99550 55.00452
 [81,] 14.99493 55.00901
 [82,] 14.99436 55.01349
 [83,] 14.99379 55.01797
 [84,] 14.99322 55.02245
 [85,] 15.00103 55.02279
 [86,] 15.00046 55.02727
 [87,] 15.00827 55.02761
 [88,] 15.00770 55.03209
 [89,] 15.01551 55.03243
 [90,] 15.01495 55.03691
 [91,] 15.01438 55.04139
 [92,] 15.01381 55.04587
 [93,] 15.00600 55.04554
 [94,] 15.00543 55.05002
 [95,] 15.01324 55.05035
 [96,] 15.01267 55.05484
 [97,] 15.01211 55.05932
 [98,] 15.01154 55.06380
 [99,] 15.01935 55.06413
[100,] 15.01879 55.06862
[101,] 15.01822 55.07310
[102,] 15.01765 55.07758
[103,] 15.02547 55.07792
[104,] 15.02490 55.08240
[105,] 15.02434 55.08688
[106,] 15.02377 55.09136
[107,] 15.01595 55.09103
[108,] 15.01538 55.09551
[109,] 15.01481 55.09999
[110,] 15.02263 55.10033
[111,] 15.03046 55.10066
[112,] 15.03828 55.10099
[113,] 15.04611 55.10133
[114,] 15.05393 55.10166
[115,] 15.06176 55.10199
[116,] 15.06958 55.10232
[117,] 15.06902 55.10680
[118,] 15.07684 55.10713
[119,] 15.07628 55.11161
[120,] 15.07572 55.11610
[121,] 15.08355 55.11643
[122,] 15.08299 55.12091
[123,] 15.08242 55.12539
[124,] 15.09025 55.12572
[125,] 15.08969 55.13020
[126,] 15.08913 55.13469
[127,] 15.09696 55.13501
[128,] 15.09640 55.13950
[129,] 15.09584 55.14398
[130,] 15.10368 55.14431
[131,] 15.10328 55.14748



Slot "plotOrder":
[1] 1

Slot "labpt":
[1] 15.07812 55.06290

Slot "ID":
[1] "139"

Slot "area":
[1] 0.01516297


[[4]]
An object of class "Polygons"
Slot "Polygons":
[[1]]
An object of class "Polygon"
Slot "labpt":
[1] 14.73583 55.10616

Slot "area":
[1] 0.004280022

Slot "hole":
[1] FALSE

Slot "ringDir":
[1] 1

Slot "coords":
          [,1]     [,2]
 [1,] 14.73563 55.06969
 [2,] 14.73503 55.07418
 [3,] 14.72813 55.07386
 [4,] 14.72706 55.07502
 [5,] 14.72662 55.07830
 [6,] 14.72602 55.08278
 [7,] 14.71820 55.08243
 [8,] 14.71038 55.08207
 [9,] 14.70978 55.08656
[10,] 14.70196 55.08620
[11,] 14.70135 55.09068
[12,] 14.69338 55.09008
[13,] 14.69308 55.09368
[14,] 14.69630 55.09442
[15,] 14.69563 55.09721
[16,] 14.69024 55.09824
[17,] 14.68483 55.09653
[18,] 14.68445 55.09930
[19,] 14.68746 55.10255
[20,] 14.69439 55.10326
[21,] 14.69785 55.10672
[22,] 14.70006 55.11415
[23,] 14.69727 55.12097
[24,] 14.70293 55.12499
[25,] 14.70315 55.12683
[26,] 14.70434 55.12688
[27,] 14.70372 55.13150
[28,] 14.70503 55.14230
[29,] 14.70351 55.14487
[30,] 14.70975 55.14516
[31,] 14.71758 55.14551
[32,] 14.71819 55.14103
[33,] 14.72602 55.14138
[34,] 14.72662 55.13690
[35,] 14.72722 55.13242
[36,] 14.73505 55.13277
[37,] 14.73565 55.12830
[38,] 14.74348 55.12865
[39,] 14.75130 55.12900
[40,] 14.75913 55.12935
[41,] 14.76696 55.12970
[42,] 14.76756 55.12522
[43,] 14.76816 55.12074
[44,] 14.77598 55.12109
[45,] 14.77658 55.11661
[46,] 14.77717 55.11213
[47,] 14.77777 55.10765
[48,] 14.78559 55.10800
[49,] 14.78619 55.10352
[50,] 14.78678 55.09904
[51,] 14.78738 55.09456
[52,] 14.77956 55.09421
[53,] 14.78015 55.08973
[54,] 14.77233 55.08937
[55,] 14.76451 55.08902
[56,] 14.75669 55.08867
[57,] 14.75729 55.08419
[58,] 14.75789 55.07971
[59,] 14.75848 55.07523
[60,] 14.75067 55.07488
[61,] 14.75127 55.07040
[62,] 14.74345 55.07005
[63,] 14.73563 55.06969



Slot "plotOrder":
[1] 1

Slot "labpt":
[1] 14.73583 55.10616

Slot "ID":
[1] "173"

Slot "area":
[1] 0.004280022


[[5]]
An object of class "Polygons"
Slot "Polygons":
[[1]]
An object of class "Polygon"
Slot "labpt":
[1] 14.89665 55.08017

Slot "area":
[1] 0.02517117

Slot "hole":
[1] FALSE

Slot "ringDir":
[1] 1

Slot "coords":
           [,1]     [,2]
  [1,] 14.99550 55.00452
  [2,] 14.98769 55.00419
  [3,] 14.97989 55.00385
  [4,] 14.97208 55.00352
  [5,] 14.97151 55.00800
  [6,] 14.96371 55.00766
  [7,] 14.95590 55.00732
  [8,] 14.95068 55.00710
  [9,] 14.94791 55.00845
 [10,] 14.94752 55.01147
 [11,] 14.94222 55.01124
 [12,] 14.93953 55.01255
 [13,] 14.93914 55.01561
 [14,] 14.93133 55.01527
 [15,] 14.92353 55.01493
 [16,] 14.92295 55.01941
 [17,] 14.91555 55.01909
 [18,] 14.91435 55.01989
 [19,] 14.90696 55.02165
 [20,] 14.90676 55.02321
 [21,] 14.90142 55.02298
 [22,] 14.89988 55.02291
 [23,] 14.89881 55.02392
 [24,] 14.89837 55.02735
 [25,] 14.89292 55.02711
 [26,] 14.89037 55.02849
 [27,] 14.88998 55.03149
 [28,] 14.88216 55.03126
 [29,] 14.88159 55.03563
 [30,] 14.87378 55.03529
 [31,] 14.87319 55.03977
 [32,] 14.86538 55.03943
 [33,] 14.85757 55.03908
 [34,] 14.85699 55.04356
 [35,] 14.84917 55.04322
 [36,] 14.84136 55.04287
 [37,] 14.83355 55.04252
 [38,] 14.82574 55.04218
 [39,] 14.82515 55.04666
 [40,] 14.81734 55.04631
 [41,] 14.81675 55.05079
 [42,] 14.80894 55.05045
 [43,] 14.80408 55.05023
 [44,] 14.80223 55.05097
 [45,] 14.80098 55.05120
 [46,] 14.80053 55.05458
 [47,] 14.79272 55.05423
 [48,] 14.78491 55.05388
 [49,] 14.77709 55.05353
 [50,] 14.77650 55.05801
 [51,] 14.76869 55.05766
 [52,] 14.76080 55.05784
 [53,] 14.76028 55.06179
 [54,] 14.75246 55.06144
 [55,] 14.75186 55.06592
 [56,] 14.74405 55.06557
 [57,] 14.73813 55.06530
 [58,] 14.73604 55.06666
 [59,] 14.73563 55.06969
 [60,] 14.74345 55.07005
 [61,] 14.75127 55.07040
 [62,] 14.75067 55.07488
 [63,] 14.75848 55.07523
 [64,] 14.75789 55.07971
 [65,] 14.75729 55.08419
 [66,] 14.75669 55.08867
 [67,] 14.76451 55.08902
 [68,] 14.77233 55.08937
 [69,] 14.78015 55.08973
 [70,] 14.77956 55.09421
 [71,] 14.78738 55.09456
 [72,] 14.78678 55.09904
 [73,] 14.78619 55.10352
 [74,] 14.78559 55.10800
 [75,] 14.77777 55.10765
 [76,] 14.77717 55.11213
 [77,] 14.77658 55.11661
 [78,] 14.77598 55.12109
 [79,] 14.76816 55.12074
 [80,] 14.76756 55.12522
 [81,] 14.77538 55.12557
 [82,] 14.77479 55.13005
 [83,] 14.78262 55.13041
 [84,] 14.79044 55.13075
 [85,] 14.79827 55.13110
 [86,] 14.80610 55.13145
 [87,] 14.80551 55.13593
 [88,] 14.81334 55.13628
 [89,] 14.81275 55.14076
 [90,] 14.82057 55.14111
 [91,] 14.82841 55.14146
 [92,] 14.82782 55.14594
 [93,] 14.83565 55.14628
 [94,] 14.83624 55.14180
 [95,] 14.84407 55.14215
 [96,] 14.85190 55.14249
 [97,] 14.85973 55.14284
 [98,] 14.86756 55.14318
 [99,] 14.87539 55.14353
[100,] 14.88322 55.14387
[101,] 14.88381 55.13939
[102,] 14.88439 55.13491
[103,] 14.88498 55.13043
[104,] 14.89281 55.13077
[105,] 14.89222 55.13525
[106,] 14.90005 55.13559
[107,] 14.89947 55.14008
[108,] 14.89889 55.14456
[109,] 14.90672 55.14490
[110,] 14.91455 55.14524
[111,] 14.91513 55.14076
[112,] 14.92296 55.14110
[113,] 14.93079 55.14144
[114,] 14.93137 55.13696
[115,] 14.93920 55.13730
[116,] 14.94703 55.13764
[117,] 14.94761 55.13316
[118,] 14.95544 55.13349
[119,] 14.96327 55.13383
[120,] 14.96385 55.12935
[121,] 14.97168 55.12969
[122,] 14.97225 55.12521
[123,] 14.97282 55.12072
[124,] 14.97340 55.11624
[125,] 14.97397 55.11176
[126,] 14.97455 55.10728
[127,] 14.98237 55.10761
[128,] 14.98294 55.10313
[129,] 14.99077 55.10347
[130,] 14.99859 55.10381
[131,] 14.99916 55.09932
[132,] 15.00699 55.09966
[133,] 15.01481 55.09999
[134,] 15.01538 55.09551
[135,] 15.01595 55.09103
[136,] 15.02377 55.09136
[137,] 15.02434 55.08688
[138,] 15.02490 55.08240
[139,] 15.02547 55.07792
[140,] 15.01765 55.07758
[141,] 15.01822 55.07310
[142,] 15.01879 55.06862
[143,] 15.01935 55.06413
[144,] 15.01154 55.06380
[145,] 15.01211 55.05932
[146,] 15.01267 55.05484
[147,] 15.01324 55.05035
[148,] 15.00543 55.05002
[149,] 15.00600 55.04554
[150,] 15.01381 55.04587
[151,] 15.01438 55.04139
[152,] 15.01495 55.03691
[153,] 15.01551 55.03243
[154,] 15.00770 55.03209
[155,] 15.00827 55.02761
[156,] 15.00046 55.02727
[157,] 15.00103 55.02279
[158,] 14.99322 55.02245
[159,] 14.99379 55.01797
[160,] 14.99436 55.01349
[161,] 14.99493 55.00901
[162,] 14.99550 55.00452



Slot "plotOrder":
[1] 1

Slot "labpt":
[1] 14.89665 55.08017

Slot "ID":
[1] "2"

Slot "area":
[1] 0.02517117


From horning at amnh.org  Thu Feb 12 10:09:54 2009
From: horning at amnh.org (Ned Horning)
Date: Thu, 12 Feb 2009 12:09:54 +0300
Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
In-Reply-To: <alpine.LRH.2.00.0902120809260.2930@reclus.nhh.no>
References: <499272FA.30902@amnh.org>
	<AD51AB79BC327C40AB2C7EB75D57A3C40512E7@TOLAR.valuta.nhh.no>
	<dc22b2570902110412v3130519aiff3deaf23e29ce32@mail.gmail.com>
	<4992EBB0.20400@amnh.org>
	<dc22b2570902110728te2cb8b6x1912aeadf1558952@mail.gmail.com>
	<4993114A.7030602@amnh.org>
	<dc22b2570902111429y4be75d83sb111931fd67b4a6d@mail.gmail.com>
	<4993C21B.6050304@amnh.org>
	<dc22b2570902112240u42157f07u154e0f1bcb1fc187@mail.gmail.com>
	<alpine.LRH.2.00.0902120809260.2930@reclus.nhh.no>
Message-ID: <4993E762.8000801@amnh.org>

Roger and Robert,

Thanks for the help. Once again I am close but I can't figure out how to 
use the attribute data to control the sampling. I'd like to stratify the 
sampling by attribute value. In the Shapefile I have an integer 
attribute "covertype". There can be several polygons with the same 
covertype ID. What I want to do is get 100 sample points from polygons 
of covertype=1, 100 points from polygons of covertype=2... Is that 
possible? I looked at readShapePoly, readORG, and the suite of tools in 
spsample and but didn't see what I was looking for.

It looks like overlay() is a good way to assign the value of covertype 
to coordinate pairs.

One solution to fix all of this is to have a separate Shapefile for each 
covertype but I'd like to avoid that if possible.

Ned

Roger Bivand wrote:
> On Thu, 12 Feb 2009, Robert Hijmans wrote:
>
>> Hi Ned,
>>
>> Good to hear that. For your other question, have a look at:
>>
>> require(maptools)
>> ?readShapePoly
>
> Or more generally readOGR() in rgdal for another use of the underlying 
> shapelib code.
>
>>
>> require(sp)
>> ?sample.Polygons
>>
>
> Most likely the spsample() method will be enough, without having to 
> pick a specific method - but if necessary the Polygons objects can be 
> dissolved using unionSpatialPolygons() in maptools.
>
> Roger
>
>> Robert
>>
>>
>> On Thu, Feb 12, 2009 at 2:30 PM, Ned Horning <horning at amnh.org> wrote:
>>> Robert,
>>>
>>> This worked - thanks. It's always uplifting to see an actual image 
>>> after
>>> working on something for a while. Now I can start playing with 
>>> parameters
>>> and playing with different approaches. I'm just (re)starting my R 
>>> education
>>> and I'm pretty slow getting the hang of it but your examples help a 
>>> lot.
>>> They also give me more avenues to discover other functionality and 
>>> different
>>> ways of doing things. I hope I can keep working with R and GRASS 
>>> until I
>>> know it this time. My goal is to get to the point where I can be 
>>> productive
>>> with these packages and start training other folks.
>>>
>>> The raster package looks very nice and I'll keep an eye on its 
>>> development.
>>> One step that I am currently doing in GRASS is to read a Shapefile with
>>> training data (polygons with an integer attribute representing a 
>>> land cover
>>> type) and then randomly create 100 points within each set of polygons
>>> representing a specific land cover type. I do this for each land 
>>> cover type
>>> and then concatenate the results into a text file. This file has the
>>> coordinates that I use in xyValues to get the pixels values from the 
>>> SPOT
>>> image. Is there a way to do this sampling using the raster package or
>>> another R package that you are familiar with? In GRASS I convert the
>>> Shapefile to a raster image before doing the random sampling and it 
>>> would be
>>> nice if I could skip this step.
>>>
>>> All the best,
>>>
>>> Ned
>>>
>>> Robert Hijmans wrote:
>>>>
>>>> I see, in my example, I had a single quantitative variable but you
>>>> probably have land cover classes or something like that. If the
>>>> classes are in fact numbers stored as text then use
>>>>
>>>> pred <- as.numeric(pred)
>>>>
>>>> but if you have words such as 'forest', 'crops', 'water' you could do
>>>> something like
>>>>
>>>> ...
>>>>   pred <- predict(randfor, rowvals)
>>>>   pred[pred=='forest'] <- 1
>>>>   pred[pred=='crops'] <- 2
>>>>   pred[pred=='water'] <- 3
>>>>   pred <- as.numeric(pred)
>>>>   predrast <- setValues(predrast, pred, r)
>>>> ...
>>>>
>>>> not pretty, you could also fit RF with classes that can be interpreted
>>>> as numbers..
>>>> Make sure you do not get:
>>>>
>>>> Warning message:
>>>> NAs introduced by coercion
>>>>
>>>>
>>>> which would suggest that some character values could not be
>>>> transformed to numbers.
>>>>
>>>> On Thu, Feb 12, 2009 at 1:56 AM, Ned Horning <horning at amnh.org> wrote:
>>>>
>>>>>
>>>>> Robert,
>>>>>
>>>>> Using predrast <- setValues(predrast, as.vector(pred), r) I got 
>>>>> another
>>>>> error: values must be numeric, integer or logical.
>>>>>
>>>>> class(pred) = "factor"
>>>>> dim(pred) = NULL
>>>>> class(v) = "character"
>>>>> length(v) == ncol(spot) = TRUE
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> Ned
>>>>>
>>>>> Robert Hijmans wrote:
>>>>>
>>>>>>
>>>>>> Strange. You could try
>>>>>>     predrast <- setValues(predrast, as.vector(pred), r)
>>>>>>
>>>>>> But it would be good to know what pred is.
>>>>>>
>>>>>> Can you do this:
>>>>>>
>>>>>> class(pred)
>>>>>> dim(pred)
>>>>>> v <- as.vector(pred)
>>>>>> class(v)
>>>>>> length(v) == ncol(spot)
>>>>>>
>>>>>>
>>>>>> Robert
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> On Wed, Feb 11, 2009 at 11:16 PM, Ned Horning <horning at amnh.org> 
>>>>>> wrote:
>>>>>>
>>>>>>
>>>>>>>
>>>>>>> Robert and Roger,
>>>>>>>
>>>>>>> Thanks for the information and pointers. The raster package 
>>>>>>> looks quite
>>>>>>> interesting and I'll try to get up to speed on some of its
>>>>>>> capabilities.
>>>>>>> Are
>>>>>>> the man pages the best way to do that or is that a single document
>>>>>>> available?
>>>>>>>
>>>>>>> I made some progress but still have some questions. I followed the
>>>>>>> steps
>>>>>>> laid out by Robert and everything went fine except I ran into an 
>>>>>>> error
>>>>>>> with
>>>>>>> "predrast <- setValues(predrast, pred, r)" in the for loop when 
>>>>>>> I tried
>>>>>>> processing one line at a time and "r <- setValues(r, pred)" when 
>>>>>>> I ran
>>>>>>> the
>>>>>>> full image in one go. The error was: "values must be a vector." Any
>>>>>>> idea
>>>>>>> what I'm doing wrong?
>>>>>>>
>>>>>>> I tried to read the GRASS files directly but got a message 
>>>>>>> saying it is
>>>>>>> not
>>>>>>> a supported file format. Can you confirm that is the case or am 
>>>>>>> I doing
>>>>>>> something wrong? I was able to read a tiff version of the image. 
>>>>>>> I am
>>>>>>> able
>>>>>>> to run gdalinfo on GRASS files just fine from a terminal window.
>>>>>>>
>>>>>>> Thanks again for the help.
>>>>>>>
>>>>>>> Ned
>>>>>>>
>>>>>>>
>>>>>>> Robert Hijmans wrote:
>>>>>>>
>>>>>>>
>>>>>>>>
>>>>>>>> Ned,
>>>>>>>>
>>>>>>>> This is an example of running a RandomForest prediction with the
>>>>>>>> raster package (for the simple case that there are no NA values 
>>>>>>>> in the
>>>>>>>> raster data; if there are, you have to into account that "predict'
>>>>>>>> does not return any values (not even NA) for those cells).
>>>>>>>>
>>>>>>>> Robert
>>>>>>>>
>>>>>>>> #install.packages("raster", repos="http://R-Forge.R-project.org")
>>>>>>>> require(raster)
>>>>>>>> require(randomForest)
>>>>>>>>
>>>>>>>> # for single band files
>>>>>>>> spot <- stack('b1.tif', 'b2.tif', 'b3.tif')
>>>>>>>> # for multiple band files
>>>>>>>> # spot <- stackFromFiles(c('bands.tif', 'bands.tif', 'bands.tif'),
>>>>>>>> c(1,2,3) )
>>>>>>>>
>>>>>>>> # simulate random points and values to model with
>>>>>>>> xy <- xyFromCell(spot, round(runif(100) * ncell(spot)))
>>>>>>>> response <- runif(100) * 100
>>>>>>>> # read values of raster layers at points, and bind to respinse
>>>>>>>> trainvals <- cbind(response, xyValues(spot, xy))
>>>>>>>>
>>>>>>>> # run RandomForest
>>>>>>>> randfor <- randomForest(response ~ b1 + b2 + b3, data=trainvals)
>>>>>>>>
>>>>>>>> # apply the prediction, row by row
>>>>>>>> predrast <- setRaster(spot)
>>>>>>>> filename(predrast) <- 'RF_pred.grd'
>>>>>>>> for (r in 1:nrow(spot)) {
>>>>>>>>      spot <- readRow(spot, r)
>>>>>>>>      rowvals <- values(spot, names=TRUE)
>>>>>>>> # this next line should not be necessary, but it is
>>>>>>>> # I'll fix that
>>>>>>>>      colnames(rowvals) <- c('b1', 'b2', 'b3')
>>>>>>>>      pred <- predict(randfor, rowvals)
>>>>>>>>      predrast <- setValues(predrast, pred, r)
>>>>>>>>      predrast <- writeRaster(predrast, overwrite=TRUE)
>>>>>>>> }
>>>>>>>>
>>>>>>>> plot(predrast)
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> On Wed, Feb 11, 2009 at 5:09 PM, Roger Bivand 
>>>>>>>> <Roger.Bivand at nhh.no>
>>>>>>>> wrote:
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>>
>>>>>>>>> Ned:
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> The three bands are most likely treated as 4-byte integers, so 
>>>>>>>>> the
>>>>>>>>> object
>>>>>>>>> will be 2732 by 3058 by 3 by 4 plus a little bit. That's 
>>>>>>>>> 100MB. They
>>>>>>>>> may
>>>>>>>>> get copied too. There are no single byte user-level containers 
>>>>>>>>> for
>>>>>>>>> you
>>>>>>>>> (there is a raw data type, but you can't calculate with it). 
>>>>>>>>> Possibly
>>>>>>>>> saying spot_frame <- slot(spot, "data") will save one copying
>>>>>>>>> operation,
>>>>>>>>> but its hard to tell - your choice of method first adds inn 
>>>>>>>>> all the
>>>>>>>>> coordinates, which are 8-byte numbers, so more than doubles 
>>>>>>>>> its size
>>>>>>>>> and
>>>>>>>>> makes more copies (to 233MB for each copy). Running gc() several
>>>>>>>>> times
>>>>>>>>> manually between steps often helps by making the garbage 
>>>>>>>>> collector
>>>>>>>>> more
>>>>>>>>> aggressive.
>>>>>>>>>
>>>>>>>>> I would watch the developments in the R-Forge package 
>>>>>>>>> "raster", which
>>>>>>>>> builds on some of these things, and try to see how that works. 
>>>>>>>>> If you
>>>>>>>>> have
>>>>>>>>> the GDAL-GRASS plugin for rasters, you can use readGDAL to 
>>>>>>>>> read from
>>>>>>>>> GRASS
>>>>>>>>> - which would work with raster package functions now. Look at the
>>>>>>>>> code
>>>>>>>>> of
>>>>>>>>> recent readRAST6 to see which incantations are needed. If you are
>>>>>>>>> going
>>>>>>>>> to
>>>>>>>>> use randomForest for prediction, you can use smaller tiles 
>>>>>>>>> until you
>>>>>>>>> find
>>>>>>>>> an alternative solution. Note that feeding a data frame of 
>>>>>>>>> integers
>>>>>>>>> to
>>>>>>>>> a
>>>>>>>>> model fitting or prediction function will result in coercion to a
>>>>>>>>> matrix of doubles, so your subsequent workflow should take 
>>>>>>>>> that into
>>>>>>>>> account.
>>>>>>>>>  Getting more memory is another option, and may be very cost and
>>>>>>>>> especially
>>>>>>>>> time effective - at the moment your machine is swapping. Buying
>>>>>>>>> memory
>>>>>>>>> may
>>>>>>>>> save you time programming around too little memory.
>>>>>>>>>
>>>>>>>>> Hope this helps,
>>>>>>>>>
>>>>>>>>> Roger
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> ---
>>>>>>>>> Roger Bivand, NHH, Helleveien 30, N-5045 Bergen,
>>>>>>>>> Roger.Bivand at nhh.no
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> -----Original Message-----
>>>>>>>>> From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Ned 
>>>>>>>>> Horning
>>>>>>>>> Sent: Wed 11.02.2009 07:40
>>>>>>>>> To: r-sig-geo at stat.math.ethz.ch
>>>>>>>>> Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
>>>>>>>>>
>>>>>>>>> Greetings,
>>>>>>>>>
>>>>>>>>> I am trying to read an image from GRASS using the spgrass6 
>>>>>>>>> command
>>>>>>>>> readRAST6 and then convert it into a data.frame object so I 
>>>>>>>>> can use
>>>>>>>>> it
>>>>>>>>> with randomForest. The byte image I'm reading is 2732 rows x 3058
>>>>>>>>> columns x 3 bands. It's a small subset of a larger image I 
>>>>>>>>> would like
>>>>>>>>> to
>>>>>>>>> use eventually. I have no problem reading the image using 
>>>>>>>>> readRAST6
>>>>>>>>> but
>>>>>>>>> when I try to convert it to a data.frame object my linux system
>>>>>>>>> resources (1BG RAM, 3GB swap) nearly get maxed out and it runs 
>>>>>>>>> for a
>>>>>>>>> couple hours before I kill the process. The image is less than 
>>>>>>>>> 25MB
>>>>>>>>> so
>>>>>>>>> I'm surprised it requires this level of memory. Can someone 
>>>>>>>>> let me
>>>>>>>>> know
>>>>>>>>> why this is. Should I use something other than the GRASS 
>>>>>>>>> interface
>>>>>>>>> for
>>>>>>>>> this? These are the commands I'm using:
>>>>>>>>>
>>>>>>>>> spot <- readRAST6(c("subset.red", "subset.green", "subset.blue"))
>>>>>>>>> spot_frame <- as(spot, "data.frame")
>>>>>>>>>
>>>>>>>>> Any help would be appreciated.
>>>>>>>>>
>>>>>>>>> All the best,
>>>>>>>>>
>>>>>>>>> Ned
>>>>>>>>>
>>>>>>>>> _______________________________________________
>>>>>>>>> R-sig-Geo mailing list
>>>>>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>     [[alternative HTML version deleted]]
>>>>>>>>>
>>>>>>>>> _______________________________________________
>>>>>>>>> R-sig-Geo mailing list
>>>>>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>
>>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From Roger.Bivand at nhh.no  Thu Feb 12 10:39:16 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 12 Feb 2009 10:39:16 +0100 (CET)
Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
In-Reply-To: <4993E762.8000801@amnh.org>
References: <499272FA.30902@amnh.org>
	<AD51AB79BC327C40AB2C7EB75D57A3C40512E7@TOLAR.valuta.nhh.no>
	<dc22b2570902110412v3130519aiff3deaf23e29ce32@mail.gmail.com>
	<4992EBB0.20400@amnh.org>
	<dc22b2570902110728te2cb8b6x1912aeadf1558952@mail.gmail.com>
	<4993114A.7030602@amnh.org>
	<dc22b2570902111429y4be75d83sb111931fd67b4a6d@mail.gmail.com>
	<4993C21B.6050304@amnh.org>
	<dc22b2570902112240u42157f07u154e0f1bcb1fc187@mail.gmail.com>
	<alpine.LRH.2.00.0902120809260.2930@reclus.nhh.no>
	<4993E762.8000801@amnh.org>
Message-ID: <alpine.LRH.2.00.0902121035040.3944@reclus.nhh.no>

On Thu, 12 Feb 2009, Ned Horning wrote:

> Roger and Robert,
>
> Thanks for the help. Once again I am close but I can't figure out how to use 
> the attribute data to control the sampling. I'd like to stratify the sampling 
> by attribute value. In the Shapefile I have an integer attribute "covertype". 
> There can be several polygons with the same covertype ID. What I want to do 
> is get 100 sample points from polygons of covertype=1, 100 points from 
> polygons of covertype=2... Is that possible? I looked at readShapePoly, 
> readORG, and the suite of tools in spsample and but didn't see what I was 
> looking for.
>
> It looks like overlay() is a good way to assign the value of covertype to 
> coordinate pairs.
>
> One solution to fix all of this is to have a separate Shapefile for each 
> covertype but I'd like to avoid that if possible.

If you subset the SpatialPolygonsDataFrame object by covertype, and then 
spsample() for the subset, you might get a bit nearer. Subset using the [ 
operator as for data.frames:

X_forest <- X[X$covertype="forest",]
forest_pts <- spsample(X_forest, n=100)

(untried)

Using lapply, you could probably step along the factor (categorical) 
levels of covertype if there are many and (say) n is fixed.

Roger


>
> Ned
>
> Roger Bivand wrote:
>> On Thu, 12 Feb 2009, Robert Hijmans wrote:
>> 
>>> Hi Ned,
>>> 
>>> Good to hear that. For your other question, have a look at:
>>> 
>>> require(maptools)
>>> ?readShapePoly
>> 
>> Or more generally readOGR() in rgdal for another use of the underlying 
>> shapelib code.
>> 
>>> 
>>> require(sp)
>>> ?sample.Polygons
>>> 
>> 
>> Most likely the spsample() method will be enough, without having to pick a 
>> specific method - but if necessary the Polygons objects can be dissolved 
>> using unionSpatialPolygons() in maptools.
>> 
>> Roger
>> 
>>> Robert
>>> 
>>> 
>>> On Thu, Feb 12, 2009 at 2:30 PM, Ned Horning <horning at amnh.org> wrote:
>>>> Robert,
>>>> 
>>>> This worked - thanks. It's always uplifting to see an actual image after
>>>> working on something for a while. Now I can start playing with parameters
>>>> and playing with different approaches. I'm just (re)starting my R 
>>>> education
>>>> and I'm pretty slow getting the hang of it but your examples help a lot.
>>>> They also give me more avenues to discover other functionality and 
>>>> different
>>>> ways of doing things. I hope I can keep working with R and GRASS until I
>>>> know it this time. My goal is to get to the point where I can be 
>>>> productive
>>>> with these packages and start training other folks.
>>>> 
>>>> The raster package looks very nice and I'll keep an eye on its 
>>>> development.
>>>> One step that I am currently doing in GRASS is to read a Shapefile with
>>>> training data (polygons with an integer attribute representing a land 
>>>> cover
>>>> type) and then randomly create 100 points within each set of polygons
>>>> representing a specific land cover type. I do this for each land cover 
>>>> type
>>>> and then concatenate the results into a text file. This file has the
>>>> coordinates that I use in xyValues to get the pixels values from the SPOT
>>>> image. Is there a way to do this sampling using the raster package or
>>>> another R package that you are familiar with? In GRASS I convert the
>>>> Shapefile to a raster image before doing the random sampling and it would 
>>>> be
>>>> nice if I could skip this step.
>>>> 
>>>> All the best,
>>>> 
>>>> Ned
>>>> 
>>>> Robert Hijmans wrote:
>>>>> 
>>>>> I see, in my example, I had a single quantitative variable but you
>>>>> probably have land cover classes or something like that. If the
>>>>> classes are in fact numbers stored as text then use
>>>>> 
>>>>> pred <- as.numeric(pred)
>>>>> 
>>>>> but if you have words such as 'forest', 'crops', 'water' you could do
>>>>> something like
>>>>> 
>>>>> ...
>>>>>   pred <- predict(randfor, rowvals)
>>>>>   pred[pred=='forest'] <- 1
>>>>>   pred[pred=='crops'] <- 2
>>>>>   pred[pred=='water'] <- 3
>>>>>   pred <- as.numeric(pred)
>>>>>   predrast <- setValues(predrast, pred, r)
>>>>> ...
>>>>> 
>>>>> not pretty, you could also fit RF with classes that can be interpreted
>>>>> as numbers..
>>>>> Make sure you do not get:
>>>>> 
>>>>> Warning message:
>>>>> NAs introduced by coercion
>>>>> 
>>>>> 
>>>>> which would suggest that some character values could not be
>>>>> transformed to numbers.
>>>>> 
>>>>> On Thu, Feb 12, 2009 at 1:56 AM, Ned Horning <horning at amnh.org> wrote:
>>>>> 
>>>>>> 
>>>>>> Robert,
>>>>>> 
>>>>>> Using predrast <- setValues(predrast, as.vector(pred), r) I got another
>>>>>> error: values must be numeric, integer or logical.
>>>>>> 
>>>>>> class(pred) = "factor"
>>>>>> dim(pred) = NULL
>>>>>> class(v) = "character"
>>>>>> length(v) == ncol(spot) = TRUE
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> Ned
>>>>>> 
>>>>>> Robert Hijmans wrote:
>>>>>> 
>>>>>>> 
>>>>>>> Strange. You could try
>>>>>>>     predrast <- setValues(predrast, as.vector(pred), r)
>>>>>>> 
>>>>>>> But it would be good to know what pred is.
>>>>>>> 
>>>>>>> Can you do this:
>>>>>>> 
>>>>>>> class(pred)
>>>>>>> dim(pred)
>>>>>>> v <- as.vector(pred)
>>>>>>> class(v)
>>>>>>> length(v) == ncol(spot)
>>>>>>> 
>>>>>>> 
>>>>>>> Robert
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> On Wed, Feb 11, 2009 at 11:16 PM, Ned Horning <horning at amnh.org> 
>>>>>>> wrote:
>>>>>>> 
>>>>>>> 
>>>>>>>> 
>>>>>>>> Robert and Roger,
>>>>>>>> 
>>>>>>>> Thanks for the information and pointers. The raster package looks 
>>>>>>>> quite
>>>>>>>> interesting and I'll try to get up to speed on some of its
>>>>>>>> capabilities.
>>>>>>>> Are
>>>>>>>> the man pages the best way to do that or is that a single document
>>>>>>>> available?
>>>>>>>> 
>>>>>>>> I made some progress but still have some questions. I followed the
>>>>>>>> steps
>>>>>>>> laid out by Robert and everything went fine except I ran into an 
>>>>>>>> error
>>>>>>>> with
>>>>>>>> "predrast <- setValues(predrast, pred, r)" in the for loop when I 
>>>>>>>> tried
>>>>>>>> processing one line at a time and "r <- setValues(r, pred)" when I 
>>>>>>>> ran
>>>>>>>> the
>>>>>>>> full image in one go. The error was: "values must be a vector." Any
>>>>>>>> idea
>>>>>>>> what I'm doing wrong?
>>>>>>>> 
>>>>>>>> I tried to read the GRASS files directly but got a message saying it 
>>>>>>>> is
>>>>>>>> not
>>>>>>>> a supported file format. Can you confirm that is the case or am I 
>>>>>>>> doing
>>>>>>>> something wrong? I was able to read a tiff version of the image. I am
>>>>>>>> able
>>>>>>>> to run gdalinfo on GRASS files just fine from a terminal window.
>>>>>>>> 
>>>>>>>> Thanks again for the help.
>>>>>>>> 
>>>>>>>> Ned
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Robert Hijmans wrote:
>>>>>>>> 
>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> Ned,
>>>>>>>>> 
>>>>>>>>> This is an example of running a RandomForest prediction with the
>>>>>>>>> raster package (for the simple case that there are no NA values in 
>>>>>>>>> the
>>>>>>>>> raster data; if there are, you have to into account that "predict'
>>>>>>>>> does not return any values (not even NA) for those cells).
>>>>>>>>> 
>>>>>>>>> Robert
>>>>>>>>> 
>>>>>>>>> #install.packages("raster", repos="http://R-Forge.R-project.org")
>>>>>>>>> require(raster)
>>>>>>>>> require(randomForest)
>>>>>>>>> 
>>>>>>>>> # for single band files
>>>>>>>>> spot <- stack('b1.tif', 'b2.tif', 'b3.tif')
>>>>>>>>> # for multiple band files
>>>>>>>>> # spot <- stackFromFiles(c('bands.tif', 'bands.tif', 'bands.tif'),
>>>>>>>>> c(1,2,3) )
>>>>>>>>> 
>>>>>>>>> # simulate random points and values to model with
>>>>>>>>> xy <- xyFromCell(spot, round(runif(100) * ncell(spot)))
>>>>>>>>> response <- runif(100) * 100
>>>>>>>>> # read values of raster layers at points, and bind to respinse
>>>>>>>>> trainvals <- cbind(response, xyValues(spot, xy))
>>>>>>>>> 
>>>>>>>>> # run RandomForest
>>>>>>>>> randfor <- randomForest(response ~ b1 + b2 + b3, data=trainvals)
>>>>>>>>> 
>>>>>>>>> # apply the prediction, row by row
>>>>>>>>> predrast <- setRaster(spot)
>>>>>>>>> filename(predrast) <- 'RF_pred.grd'
>>>>>>>>> for (r in 1:nrow(spot)) {
>>>>>>>>>      spot <- readRow(spot, r)
>>>>>>>>>      rowvals <- values(spot, names=TRUE)
>>>>>>>>> # this next line should not be necessary, but it is
>>>>>>>>> # I'll fix that
>>>>>>>>>      colnames(rowvals) <- c('b1', 'b2', 'b3')
>>>>>>>>>      pred <- predict(randfor, rowvals)
>>>>>>>>>      predrast <- setValues(predrast, pred, r)
>>>>>>>>>      predrast <- writeRaster(predrast, overwrite=TRUE)
>>>>>>>>> }
>>>>>>>>> 
>>>>>>>>> plot(predrast)
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> On Wed, Feb 11, 2009 at 5:09 PM, Roger Bivand <Roger.Bivand at nhh.no>
>>>>>>>>> wrote:
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Ned:
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> The three bands are most likely treated as 4-byte integers, so the
>>>>>>>>>> object
>>>>>>>>>> will be 2732 by 3058 by 3 by 4 plus a little bit. That's 100MB. 
>>>>>>>>>> They
>>>>>>>>>> may
>>>>>>>>>> get copied too. There are no single byte user-level containers for
>>>>>>>>>> you
>>>>>>>>>> (there is a raw data type, but you can't calculate with it). 
>>>>>>>>>> Possibly
>>>>>>>>>> saying spot_frame <- slot(spot, "data") will save one copying
>>>>>>>>>> operation,
>>>>>>>>>> but its hard to tell - your choice of method first adds inn all the
>>>>>>>>>> coordinates, which are 8-byte numbers, so more than doubles its 
>>>>>>>>>> size
>>>>>>>>>> and
>>>>>>>>>> makes more copies (to 233MB for each copy). Running gc() several
>>>>>>>>>> times
>>>>>>>>>> manually between steps often helps by making the garbage collector
>>>>>>>>>> more
>>>>>>>>>> aggressive.
>>>>>>>>>> 
>>>>>>>>>> I would watch the developments in the R-Forge package "raster", 
>>>>>>>>>> which
>>>>>>>>>> builds on some of these things, and try to see how that works. If 
>>>>>>>>>> you
>>>>>>>>>> have
>>>>>>>>>> the GDAL-GRASS plugin for rasters, you can use readGDAL to read 
>>>>>>>>>> from
>>>>>>>>>> GRASS
>>>>>>>>>> - which would work with raster package functions now. Look at the
>>>>>>>>>> code
>>>>>>>>>> of
>>>>>>>>>> recent readRAST6 to see which incantations are needed. If you are
>>>>>>>>>> going
>>>>>>>>>> to
>>>>>>>>>> use randomForest for prediction, you can use smaller tiles until 
>>>>>>>>>> you
>>>>>>>>>> find
>>>>>>>>>> an alternative solution. Note that feeding a data frame of integers
>>>>>>>>>> to
>>>>>>>>>> a
>>>>>>>>>> model fitting or prediction function will result in coercion to a
>>>>>>>>>> matrix of doubles, so your subsequent workflow should take that 
>>>>>>>>>> into
>>>>>>>>>> account.
>>>>>>>>>>  Getting more memory is another option, and may be very cost and
>>>>>>>>>> especially
>>>>>>>>>> time effective - at the moment your machine is swapping. Buying
>>>>>>>>>> memory
>>>>>>>>>> may
>>>>>>>>>> save you time programming around too little memory.
>>>>>>>>>> 
>>>>>>>>>> Hope this helps,
>>>>>>>>>> 
>>>>>>>>>> Roger
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> ---
>>>>>>>>>> Roger Bivand, NHH, Helleveien 30, N-5045 Bergen,
>>>>>>>>>> Roger.Bivand at nhh.no
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> -----Original Message-----
>>>>>>>>>> From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Ned Horning
>>>>>>>>>> Sent: Wed 11.02.2009 07:40
>>>>>>>>>> To: r-sig-geo at stat.math.ethz.ch
>>>>>>>>>> Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
>>>>>>>>>> 
>>>>>>>>>> Greetings,
>>>>>>>>>> 
>>>>>>>>>> I am trying to read an image from GRASS using the spgrass6 command
>>>>>>>>>> readRAST6 and then convert it into a data.frame object so I can use
>>>>>>>>>> it
>>>>>>>>>> with randomForest. The byte image I'm reading is 2732 rows x 3058
>>>>>>>>>> columns x 3 bands. It's a small subset of a larger image I would 
>>>>>>>>>> like
>>>>>>>>>> to
>>>>>>>>>> use eventually. I have no problem reading the image using readRAST6
>>>>>>>>>> but
>>>>>>>>>> when I try to convert it to a data.frame object my linux system
>>>>>>>>>> resources (1BG RAM, 3GB swap) nearly get maxed out and it runs for 
>>>>>>>>>> a
>>>>>>>>>> couple hours before I kill the process. The image is less than 25MB
>>>>>>>>>> so
>>>>>>>>>> I'm surprised it requires this level of memory. Can someone let me
>>>>>>>>>> know
>>>>>>>>>> why this is. Should I use something other than the GRASS interface
>>>>>>>>>> for
>>>>>>>>>> this? These are the commands I'm using:
>>>>>>>>>> 
>>>>>>>>>> spot <- readRAST6(c("subset.red", "subset.green", "subset.blue"))
>>>>>>>>>> spot_frame <- as(spot, "data.frame")
>>>>>>>>>> 
>>>>>>>>>> Any help would be appreciated.
>>>>>>>>>> 
>>>>>>>>>> All the best,
>>>>>>>>>> 
>>>>>>>>>> Ned
>>>>>>>>>> 
>>>>>>>>>> _______________________________________________
>>>>>>>>>> R-sig-Geo mailing list
>>>>>>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>>
>>>>>>>>>>     [[alternative HTML version deleted]]
>>>>>>>>>> 
>>>>>>>>>> _______________________________________________
>>>>>>>>>> R-sig-Geo mailing list
>>>>>>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>> 
>>>>>> 
>>>>> 
>>>>> 
>>>> 
>>>> 
>>> 
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> 
>> 
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From horning at amnh.org  Thu Feb 12 11:22:39 2009
From: horning at amnh.org (Ned Horning)
Date: Thu, 12 Feb 2009 13:22:39 +0300
Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
In-Reply-To: <alpine.LRH.2.00.0902121035040.3944@reclus.nhh.no>
References: <499272FA.30902@amnh.org>
	<AD51AB79BC327C40AB2C7EB75D57A3C40512E7@TOLAR.valuta.nhh.no>
	<dc22b2570902110412v3130519aiff3deaf23e29ce32@mail.gmail.com>
	<4992EBB0.20400@amnh.org>
	<dc22b2570902110728te2cb8b6x1912aeadf1558952@mail.gmail.com>
	<4993114A.7030602@amnh.org>
	<dc22b2570902111429y4be75d83sb111931fd67b4a6d@mail.gmail.com>
	<4993C21B.6050304@amnh.org>
	<dc22b2570902112240u42157f07u154e0f1bcb1fc187@mail.gmail.com>
	<alpine.LRH.2.00.0902120809260.2930@reclus.nhh.no>
	<4993E762.8000801@amnh.org>
	<alpine.LRH.2.00.0902121035040.3944@reclus.nhh.no>
Message-ID: <4993F86F.8010100@amnh.org>

Roger,

Thanks - It looks like this will do the trick. I had to change 
[X$covertype="forest",] to [X$covertype=="forest",] but it appears to 
work just fine.

Ned

Roger Bivand wrote:
> On Thu, 12 Feb 2009, Ned Horning wrote:
>
>> Roger and Robert,
>>
>> Thanks for the help. Once again I am close but I can't figure out how 
>> to use the attribute data to control the sampling. I'd like to 
>> stratify the sampling by attribute value. In the Shapefile I have an 
>> integer attribute "covertype". There can be several polygons with the 
>> same covertype ID. What I want to do is get 100 sample points from 
>> polygons of covertype=1, 100 points from polygons of covertype=2... 
>> Is that possible? I looked at readShapePoly, readORG, and the suite 
>> of tools in spsample and but didn't see what I was looking for.
>>
>> It looks like overlay() is a good way to assign the value of 
>> covertype to coordinate pairs.
>>
>> One solution to fix all of this is to have a separate Shapefile for 
>> each covertype but I'd like to avoid that if possible.
>
> If you subset the SpatialPolygonsDataFrame object by covertype, and 
> then spsample() for the subset, you might get a bit nearer. Subset 
> using the [ operator as for data.frames:
>
> X_forest <- X[X$covertype="forest",]
> forest_pts <- spsample(X_forest, n=100)
>
> (untried)
>
> Using lapply, you could probably step along the factor (categorical) 
> levels of covertype if there are many and (say) n is fixed.
>
> Roger
>
>
>>
>> Ned
>>
>> Roger Bivand wrote:
>>> On Thu, 12 Feb 2009, Robert Hijmans wrote:
>>>
>>>> Hi Ned,
>>>>
>>>> Good to hear that. For your other question, have a look at:
>>>>
>>>> require(maptools)
>>>> ?readShapePoly
>>>
>>> Or more generally readOGR() in rgdal for another use of the 
>>> underlying shapelib code.
>>>
>>>>
>>>> require(sp)
>>>> ?sample.Polygons
>>>>
>>>
>>> Most likely the spsample() method will be enough, without having to 
>>> pick a specific method - but if necessary the Polygons objects can 
>>> be dissolved using unionSpatialPolygons() in maptools.
>>>
>>> Roger
>>>
>>>> Robert
>>>>
>>>>
>>>> On Thu, Feb 12, 2009 at 2:30 PM, Ned Horning <horning at amnh.org> wrote:
>>>>> Robert,
>>>>>
>>>>> This worked - thanks. It's always uplifting to see an actual image 
>>>>> after
>>>>> working on something for a while. Now I can start playing with 
>>>>> parameters
>>>>> and playing with different approaches. I'm just (re)starting my R 
>>>>> education
>>>>> and I'm pretty slow getting the hang of it but your examples help 
>>>>> a lot.
>>>>> They also give me more avenues to discover other functionality and 
>>>>> different
>>>>> ways of doing things. I hope I can keep working with R and GRASS 
>>>>> until I
>>>>> know it this time. My goal is to get to the point where I can be 
>>>>> productive
>>>>> with these packages and start training other folks.
>>>>>
>>>>> The raster package looks very nice and I'll keep an eye on its 
>>>>> development.
>>>>> One step that I am currently doing in GRASS is to read a Shapefile 
>>>>> with
>>>>> training data (polygons with an integer attribute representing a 
>>>>> land cover
>>>>> type) and then randomly create 100 points within each set of polygons
>>>>> representing a specific land cover type. I do this for each land 
>>>>> cover type
>>>>> and then concatenate the results into a text file. This file has the
>>>>> coordinates that I use in xyValues to get the pixels values from 
>>>>> the SPOT
>>>>> image. Is there a way to do this sampling using the raster package or
>>>>> another R package that you are familiar with? In GRASS I convert the
>>>>> Shapefile to a raster image before doing the random sampling and 
>>>>> it would be
>>>>> nice if I could skip this step.
>>>>>
>>>>> All the best,
>>>>>
>>>>> Ned
>>>>>
>>>>> Robert Hijmans wrote:
>>>>>>
>>>>>> I see, in my example, I had a single quantitative variable but you
>>>>>> probably have land cover classes or something like that. If the
>>>>>> classes are in fact numbers stored as text then use
>>>>>>
>>>>>> pred <- as.numeric(pred)
>>>>>>
>>>>>> but if you have words such as 'forest', 'crops', 'water' you 
>>>>>> could do
>>>>>> something like
>>>>>>
>>>>>> ...
>>>>>>   pred <- predict(randfor, rowvals)
>>>>>>   pred[pred=='forest'] <- 1
>>>>>>   pred[pred=='crops'] <- 2
>>>>>>   pred[pred=='water'] <- 3
>>>>>>   pred <- as.numeric(pred)
>>>>>>   predrast <- setValues(predrast, pred, r)
>>>>>> ...
>>>>>>
>>>>>> not pretty, you could also fit RF with classes that can be 
>>>>>> interpreted
>>>>>> as numbers..
>>>>>> Make sure you do not get:
>>>>>>
>>>>>> Warning message:
>>>>>> NAs introduced by coercion
>>>>>>
>>>>>>
>>>>>> which would suggest that some character values could not be
>>>>>> transformed to numbers.
>>>>>>
>>>>>> On Thu, Feb 12, 2009 at 1:56 AM, Ned Horning <horning at amnh.org> 
>>>>>> wrote:
>>>>>>
>>>>>>>
>>>>>>> Robert,
>>>>>>>
>>>>>>> Using predrast <- setValues(predrast, as.vector(pred), r) I got 
>>>>>>> another
>>>>>>> error: values must be numeric, integer or logical.
>>>>>>>
>>>>>>> class(pred) = "factor"
>>>>>>> dim(pred) = NULL
>>>>>>> class(v) = "character"
>>>>>>> length(v) == ncol(spot) = TRUE
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> Ned
>>>>>>>
>>>>>>> Robert Hijmans wrote:
>>>>>>>
>>>>>>>>
>>>>>>>> Strange. You could try
>>>>>>>>     predrast <- setValues(predrast, as.vector(pred), r)
>>>>>>>>
>>>>>>>> But it would be good to know what pred is.
>>>>>>>>
>>>>>>>> Can you do this:
>>>>>>>>
>>>>>>>> class(pred)
>>>>>>>> dim(pred)
>>>>>>>> v <- as.vector(pred)
>>>>>>>> class(v)
>>>>>>>> length(v) == ncol(spot)
>>>>>>>>
>>>>>>>>
>>>>>>>> Robert
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> On Wed, Feb 11, 2009 at 11:16 PM, Ned Horning 
>>>>>>>> <horning at amnh.org> wrote:
>>>>>>>>
>>>>>>>>
>>>>>>>>>
>>>>>>>>> Robert and Roger,
>>>>>>>>>
>>>>>>>>> Thanks for the information and pointers. The raster package 
>>>>>>>>> looks quite
>>>>>>>>> interesting and I'll try to get up to speed on some of its
>>>>>>>>> capabilities.
>>>>>>>>> Are
>>>>>>>>> the man pages the best way to do that or is that a single 
>>>>>>>>> document
>>>>>>>>> available?
>>>>>>>>>
>>>>>>>>> I made some progress but still have some questions. I followed 
>>>>>>>>> the
>>>>>>>>> steps
>>>>>>>>> laid out by Robert and everything went fine except I ran into 
>>>>>>>>> an error
>>>>>>>>> with
>>>>>>>>> "predrast <- setValues(predrast, pred, r)" in the for loop 
>>>>>>>>> when I tried
>>>>>>>>> processing one line at a time and "r <- setValues(r, pred)" 
>>>>>>>>> when I ran
>>>>>>>>> the
>>>>>>>>> full image in one go. The error was: "values must be a 
>>>>>>>>> vector." Any
>>>>>>>>> idea
>>>>>>>>> what I'm doing wrong?
>>>>>>>>>
>>>>>>>>> I tried to read the GRASS files directly but got a message 
>>>>>>>>> saying it is
>>>>>>>>> not
>>>>>>>>> a supported file format. Can you confirm that is the case or 
>>>>>>>>> am I doing
>>>>>>>>> something wrong? I was able to read a tiff version of the 
>>>>>>>>> image. I am
>>>>>>>>> able
>>>>>>>>> to run gdalinfo on GRASS files just fine from a terminal window.
>>>>>>>>>
>>>>>>>>> Thanks again for the help.
>>>>>>>>>
>>>>>>>>> Ned
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Robert Hijmans wrote:
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> Ned,
>>>>>>>>>>
>>>>>>>>>> This is an example of running a RandomForest prediction with the
>>>>>>>>>> raster package (for the simple case that there are no NA 
>>>>>>>>>> values in the
>>>>>>>>>> raster data; if there are, you have to into account that 
>>>>>>>>>> "predict'
>>>>>>>>>> does not return any values (not even NA) for those cells).
>>>>>>>>>>
>>>>>>>>>> Robert
>>>>>>>>>>
>>>>>>>>>> #install.packages("raster", 
>>>>>>>>>> repos="http://R-Forge.R-project.org")
>>>>>>>>>> require(raster)
>>>>>>>>>> require(randomForest)
>>>>>>>>>>
>>>>>>>>>> # for single band files
>>>>>>>>>> spot <- stack('b1.tif', 'b2.tif', 'b3.tif')
>>>>>>>>>> # for multiple band files
>>>>>>>>>> # spot <- stackFromFiles(c('bands.tif', 'bands.tif', 
>>>>>>>>>> 'bands.tif'),
>>>>>>>>>> c(1,2,3) )
>>>>>>>>>>
>>>>>>>>>> # simulate random points and values to model with
>>>>>>>>>> xy <- xyFromCell(spot, round(runif(100) * ncell(spot)))
>>>>>>>>>> response <- runif(100) * 100
>>>>>>>>>> # read values of raster layers at points, and bind to respinse
>>>>>>>>>> trainvals <- cbind(response, xyValues(spot, xy))
>>>>>>>>>>
>>>>>>>>>> # run RandomForest
>>>>>>>>>> randfor <- randomForest(response ~ b1 + b2 + b3, data=trainvals)
>>>>>>>>>>
>>>>>>>>>> # apply the prediction, row by row
>>>>>>>>>> predrast <- setRaster(spot)
>>>>>>>>>> filename(predrast) <- 'RF_pred.grd'
>>>>>>>>>> for (r in 1:nrow(spot)) {
>>>>>>>>>>      spot <- readRow(spot, r)
>>>>>>>>>>      rowvals <- values(spot, names=TRUE)
>>>>>>>>>> # this next line should not be necessary, but it is
>>>>>>>>>> # I'll fix that
>>>>>>>>>>      colnames(rowvals) <- c('b1', 'b2', 'b3')
>>>>>>>>>>      pred <- predict(randfor, rowvals)
>>>>>>>>>>      predrast <- setValues(predrast, pred, r)
>>>>>>>>>>      predrast <- writeRaster(predrast, overwrite=TRUE)
>>>>>>>>>> }
>>>>>>>>>>
>>>>>>>>>> plot(predrast)
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> On Wed, Feb 11, 2009 at 5:09 PM, Roger Bivand 
>>>>>>>>>> <Roger.Bivand at nhh.no>
>>>>>>>>>> wrote:
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> Ned:
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> The three bands are most likely treated as 4-byte integers, 
>>>>>>>>>>> so the
>>>>>>>>>>> object
>>>>>>>>>>> will be 2732 by 3058 by 3 by 4 plus a little bit. That's 
>>>>>>>>>>> 100MB. They
>>>>>>>>>>> may
>>>>>>>>>>> get copied too. There are no single byte user-level 
>>>>>>>>>>> containers for
>>>>>>>>>>> you
>>>>>>>>>>> (there is a raw data type, but you can't calculate with it). 
>>>>>>>>>>> Possibly
>>>>>>>>>>> saying spot_frame <- slot(spot, "data") will save one copying
>>>>>>>>>>> operation,
>>>>>>>>>>> but its hard to tell - your choice of method first adds inn 
>>>>>>>>>>> all the
>>>>>>>>>>> coordinates, which are 8-byte numbers, so more than doubles 
>>>>>>>>>>> its size
>>>>>>>>>>> and
>>>>>>>>>>> makes more copies (to 233MB for each copy). Running gc() 
>>>>>>>>>>> several
>>>>>>>>>>> times
>>>>>>>>>>> manually between steps often helps by making the garbage 
>>>>>>>>>>> collector
>>>>>>>>>>> more
>>>>>>>>>>> aggressive.
>>>>>>>>>>>
>>>>>>>>>>> I would watch the developments in the R-Forge package 
>>>>>>>>>>> "raster", which
>>>>>>>>>>> builds on some of these things, and try to see how that 
>>>>>>>>>>> works. If you
>>>>>>>>>>> have
>>>>>>>>>>> the GDAL-GRASS plugin for rasters, you can use readGDAL to 
>>>>>>>>>>> read from
>>>>>>>>>>> GRASS
>>>>>>>>>>> - which would work with raster package functions now. Look 
>>>>>>>>>>> at the
>>>>>>>>>>> code
>>>>>>>>>>> of
>>>>>>>>>>> recent readRAST6 to see which incantations are needed. If 
>>>>>>>>>>> you are
>>>>>>>>>>> going
>>>>>>>>>>> to
>>>>>>>>>>> use randomForest for prediction, you can use smaller tiles 
>>>>>>>>>>> until you
>>>>>>>>>>> find
>>>>>>>>>>> an alternative solution. Note that feeding a data frame of 
>>>>>>>>>>> integers
>>>>>>>>>>> to
>>>>>>>>>>> a
>>>>>>>>>>> model fitting or prediction function will result in coercion 
>>>>>>>>>>> to a
>>>>>>>>>>> matrix of doubles, so your subsequent workflow should take 
>>>>>>>>>>> that into
>>>>>>>>>>> account.
>>>>>>>>>>>  Getting more memory is another option, and may be very cost 
>>>>>>>>>>> and
>>>>>>>>>>> especially
>>>>>>>>>>> time effective - at the moment your machine is swapping. Buying
>>>>>>>>>>> memory
>>>>>>>>>>> may
>>>>>>>>>>> save you time programming around too little memory.
>>>>>>>>>>>
>>>>>>>>>>> Hope this helps,
>>>>>>>>>>>
>>>>>>>>>>> Roger
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> ---
>>>>>>>>>>> Roger Bivand, NHH, Helleveien 30, N-5045 Bergen,
>>>>>>>>>>> Roger.Bivand at nhh.no
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> -----Original Message-----
>>>>>>>>>>> From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Ned 
>>>>>>>>>>> Horning
>>>>>>>>>>> Sent: Wed 11.02.2009 07:40
>>>>>>>>>>> To: r-sig-geo at stat.math.ethz.ch
>>>>>>>>>>> Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
>>>>>>>>>>>
>>>>>>>>>>> Greetings,
>>>>>>>>>>>
>>>>>>>>>>> I am trying to read an image from GRASS using the spgrass6 
>>>>>>>>>>> command
>>>>>>>>>>> readRAST6 and then convert it into a data.frame object so I 
>>>>>>>>>>> can use
>>>>>>>>>>> it
>>>>>>>>>>> with randomForest. The byte image I'm reading is 2732 rows x 
>>>>>>>>>>> 3058
>>>>>>>>>>> columns x 3 bands. It's a small subset of a larger image I 
>>>>>>>>>>> would like
>>>>>>>>>>> to
>>>>>>>>>>> use eventually. I have no problem reading the image using 
>>>>>>>>>>> readRAST6
>>>>>>>>>>> but
>>>>>>>>>>> when I try to convert it to a data.frame object my linux system
>>>>>>>>>>> resources (1BG RAM, 3GB swap) nearly get maxed out and it 
>>>>>>>>>>> runs for a
>>>>>>>>>>> couple hours before I kill the process. The image is less 
>>>>>>>>>>> than 25MB
>>>>>>>>>>> so
>>>>>>>>>>> I'm surprised it requires this level of memory. Can someone 
>>>>>>>>>>> let me
>>>>>>>>>>> know
>>>>>>>>>>> why this is. Should I use something other than the GRASS 
>>>>>>>>>>> interface
>>>>>>>>>>> for
>>>>>>>>>>> this? These are the commands I'm using:
>>>>>>>>>>>
>>>>>>>>>>> spot <- readRAST6(c("subset.red", "subset.green", 
>>>>>>>>>>> "subset.blue"))
>>>>>>>>>>> spot_frame <- as(spot, "data.frame")
>>>>>>>>>>>
>>>>>>>>>>> Any help would be appreciated.
>>>>>>>>>>>
>>>>>>>>>>> All the best,
>>>>>>>>>>>
>>>>>>>>>>> Ned
>>>>>>>>>>>
>>>>>>>>>>> _______________________________________________
>>>>>>>>>>> R-sig-Geo mailing list
>>>>>>>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>     [[alternative HTML version deleted]]
>>>>>>>>>>>
>>>>>>>>>>> _______________________________________________
>>>>>>>>>>> R-sig-Geo mailing list
>>>>>>>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>
>>
>>
>


From Roger.Bivand at nhh.no  Thu Feb 12 11:26:20 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 12 Feb 2009 11:26:20 +0100 (CET)
Subject: [R-sig-Geo] How to move an island?!
In-Reply-To: <BF9B6C436B8F26458D7F5FC295C7770101CCC24D@gere.svf.au.dk>
References: <BF9B6C436B8F26458D7F5FC295C7770101CCC24D@gere.svf.au.dk>
Message-ID: <alpine.LRH.2.00.0902121057100.3944@reclus.nhh.no>

On Thu, 12 Feb 2009, Peter Jepsen wrote:

> Dear all,
>
> I have only just begun plotting on maps, so please bear with me. I am
> plotting a map of Denmark in which each county is colorcoded by its
> incidence of a particular disease. I am using the map data found at
> http://biogeo.berkeley.edu/bgm/gdatares.php. The map is perfect, but the
> island of Bornholm, which is located far east of the rest of Denmark, is
> in its rightful place. To make the map look better, I want to move it
> northwest and put a box around it - this is common practice for maps of
> Denmark, in case you wonder.

It strikes me that you could use layout() in base graphics - not elegant, 
and needs care, but may provide a framework. The limitation is that you 
seem to have to operate in non-overlapping rectangles:

library(rgdal)
dnk <- readOGR(".", "DNK2")
ID_bornholm <- (1:248 %in% which(dnk$NAME_1 == "Bornholm"))
# find the relative width of Bornholm and the rest of Denmark, about 1/10
diff(t(bbox(dnk[!ID_bornholm,])))[1]
diff(t(bbox(dnk[ID_bornholm,])))[1]
ly <- layout(cbind(matrix(rep(1, 180), ncol=10), c(rep(0, 14), 2, 2, 0, 
0)))
opar <- par(mar=c(1,1,1,0))
plot(dnk[!ID_bornholm,])
box()
par(mar=c(1,0,1,1))
plot(dnk[ID_bornholm,])
box()
layout(1)
par(opar)

The scale isn't quite correct, but could be improved by fine tuning. Just 
using an index and subsetting only at plotting lets you add attributes to 
the original data frame, and keeps things in the same place until they 
need to be separated. I think that this is more robust than shifting the 
coordinates, though you could use elide() methods in maptools to do:

library(maptools)
bornholm <- dnk[ID_bornholm,]
rdnk <- dnk[!ID_bornholm,]
bbox(rdnk)
bbox(bornholm)
ebornholm <- elide(bornholm, shift=c(-2.4, 2.4))
bbox(ebornholm)
summary(ebornholm)
proj4string(ebornholm) <- CRS(proj4string(rdnk))
summary(ebornholm)
ednk <- spRbind(rdnk, ebornholm)
plot(ednk, axes=TRUE)
# your choice of box, click on SW and NE corners
xy <- locator(2)
rect(xy$x[1], xy$y[1], xy$x[2], xy$y[2])

But the geographer in me worries about putting Bornholm on land in Sweden 
- if you run this object out with writeOGR and the KML driver and view in 
Google Earth, it is just south of Bollebygd.

Hope this helps,

Roger

>
> I thought that I could simply find the coordinates for Bornholm and
> change them by subtraction/addition, but I can't make it work.
>
> For simplicity, I first create a separate dataset for Bornholm:
>
> born <- dmk[dmk[[3]]=="Bornholm",]
>> class(born)
> [1] "SpatialPolygonsDataFrame"
> attr(,"package")
> [1] "sp"
>
> The output from the command -slot(born, "polygons")- is long and pasted
> at the bottom of this mail. Bornholm is made up of 5 polygons. How do I
> access and change the coordinates?
>
> ----
>> sessionInfo()
> R version 2.8.1 (2008-12-22)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=Danish_Denmark.1252;LC_CTYPE=Danish_Denmark.1252;LC_MONETARY=
> Danish_Denmark.1252;LC_NUMERIC=C;LC_TIME=Danish_Denmark.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
> other attached packages:
> [1] RColorBrewer_1.0-2 maptools_0.7-18    sp_0.9-29
> foreign_0.8-30
> [5] chron_2.3-28       reshape_0.8.2      plyr_0.1.4         epiR_0.9-14
>
>
> loaded via a namespace (and not attached):
> [1] grid_2.8.1      lattice_0.17-20
> ----
> Thank you in advance for any help!
>
> Kind regards,
> Peter Jepsen, MD.
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Thu Feb 12 11:28:53 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 12 Feb 2009 11:28:53 +0100 (CET)
Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
In-Reply-To: <4993F86F.8010100@amnh.org>
References: <499272FA.30902@amnh.org>
	<AD51AB79BC327C40AB2C7EB75D57A3C40512E7@TOLAR.valuta.nhh.no>
	<dc22b2570902110412v3130519aiff3deaf23e29ce32@mail.gmail.com>
	<4992EBB0.20400@amnh.org>
	<dc22b2570902110728te2cb8b6x1912aeadf1558952@mail.gmail.com>
	<4993114A.7030602@amnh.org>
	<dc22b2570902111429y4be75d83sb111931fd67b4a6d@mail.gmail.com>
	<4993C21B.6050304@amnh.org>
	<dc22b2570902112240u42157f07u154e0f1bcb1fc187@mail.gmail.com>
	<alpine.LRH.2.00.0902120809260.2930@reclus.nhh.no>
	<4993E762.8000801@amnh.org>
	<alpine.LRH.2.00.0902121035040.3944@reclus.nhh.no>
	<4993F86F.8010100@amnh.org>
Message-ID: <alpine.LRH.2.00.0902121127550.3944@reclus.nhh.no>

On Thu, 12 Feb 2009, Ned Horning wrote:

> Roger,
>
> Thanks - It looks like this will do the trick. I had to change 
> [X$covertype="forest",] to [X$covertype=="forest",] but it appears to work 
> just fine.

Yes, of course, my mistake. Nice to know it worked after correction.

Roger

>
> Ned
>
> Roger Bivand wrote:
>> On Thu, 12 Feb 2009, Ned Horning wrote:
>> 
>>> Roger and Robert,
>>> 
>>> Thanks for the help. Once again I am close but I can't figure out how to 
>>> use the attribute data to control the sampling. I'd like to stratify the 
>>> sampling by attribute value. In the Shapefile I have an integer attribute 
>>> "covertype". There can be several polygons with the same covertype ID. 
>>> What I want to do is get 100 sample points from polygons of covertype=1, 
>>> 100 points from polygons of covertype=2... Is that possible? I looked at 
>>> readShapePoly, readORG, and the suite of tools in spsample and but didn't 
>>> see what I was looking for.
>>> 
>>> It looks like overlay() is a good way to assign the value of covertype to 
>>> coordinate pairs.
>>> 
>>> One solution to fix all of this is to have a separate Shapefile for each 
>>> covertype but I'd like to avoid that if possible.
>> 
>> If you subset the SpatialPolygonsDataFrame object by covertype, and then 
>> spsample() for the subset, you might get a bit nearer. Subset using the [ 
>> operator as for data.frames:
>> 
>> X_forest <- X[X$covertype="forest",]
>> forest_pts <- spsample(X_forest, n=100)
>> 
>> (untried)
>> 
>> Using lapply, you could probably step along the factor (categorical) levels 
>> of covertype if there are many and (say) n is fixed.
>> 
>> Roger
>> 
>> 
>>> 
>>> Ned
>>> 
>>> Roger Bivand wrote:
>>>> On Thu, 12 Feb 2009, Robert Hijmans wrote:
>>>> 
>>>>> Hi Ned,
>>>>> 
>>>>> Good to hear that. For your other question, have a look at:
>>>>> 
>>>>> require(maptools)
>>>>> ?readShapePoly
>>>> 
>>>> Or more generally readOGR() in rgdal for another use of the underlying 
>>>> shapelib code.
>>>> 
>>>>> 
>>>>> require(sp)
>>>>> ?sample.Polygons
>>>>> 
>>>> 
>>>> Most likely the spsample() method will be enough, without having to pick 
>>>> a specific method - but if necessary the Polygons objects can be 
>>>> dissolved using unionSpatialPolygons() in maptools.
>>>> 
>>>> Roger
>>>> 
>>>>> Robert
>>>>> 
>>>>> 
>>>>> On Thu, Feb 12, 2009 at 2:30 PM, Ned Horning <horning at amnh.org> wrote:
>>>>>> Robert,
>>>>>> 
>>>>>> This worked - thanks. It's always uplifting to see an actual image 
>>>>>> after
>>>>>> working on something for a while. Now I can start playing with 
>>>>>> parameters
>>>>>> and playing with different approaches. I'm just (re)starting my R 
>>>>>> education
>>>>>> and I'm pretty slow getting the hang of it but your examples help a 
>>>>>> lot.
>>>>>> They also give me more avenues to discover other functionality and 
>>>>>> different
>>>>>> ways of doing things. I hope I can keep working with R and GRASS until 
>>>>>> I
>>>>>> know it this time. My goal is to get to the point where I can be 
>>>>>> productive
>>>>>> with these packages and start training other folks.
>>>>>> 
>>>>>> The raster package looks very nice and I'll keep an eye on its 
>>>>>> development.
>>>>>> One step that I am currently doing in GRASS is to read a Shapefile with
>>>>>> training data (polygons with an integer attribute representing a land 
>>>>>> cover
>>>>>> type) and then randomly create 100 points within each set of polygons
>>>>>> representing a specific land cover type. I do this for each land cover 
>>>>>> type
>>>>>> and then concatenate the results into a text file. This file has the
>>>>>> coordinates that I use in xyValues to get the pixels values from the 
>>>>>> SPOT
>>>>>> image. Is there a way to do this sampling using the raster package or
>>>>>> another R package that you are familiar with? In GRASS I convert the
>>>>>> Shapefile to a raster image before doing the random sampling and it 
>>>>>> would be
>>>>>> nice if I could skip this step.
>>>>>> 
>>>>>> All the best,
>>>>>> 
>>>>>> Ned
>>>>>> 
>>>>>> Robert Hijmans wrote:
>>>>>>> 
>>>>>>> I see, in my example, I had a single quantitative variable but you
>>>>>>> probably have land cover classes or something like that. If the
>>>>>>> classes are in fact numbers stored as text then use
>>>>>>> 
>>>>>>> pred <- as.numeric(pred)
>>>>>>> 
>>>>>>> but if you have words such as 'forest', 'crops', 'water' you could do
>>>>>>> something like
>>>>>>> 
>>>>>>> ...
>>>>>>>   pred <- predict(randfor, rowvals)
>>>>>>>   pred[pred=='forest'] <- 1
>>>>>>>   pred[pred=='crops'] <- 2
>>>>>>>   pred[pred=='water'] <- 3
>>>>>>>   pred <- as.numeric(pred)
>>>>>>>   predrast <- setValues(predrast, pred, r)
>>>>>>> ...
>>>>>>> 
>>>>>>> not pretty, you could also fit RF with classes that can be interpreted
>>>>>>> as numbers..
>>>>>>> Make sure you do not get:
>>>>>>> 
>>>>>>> Warning message:
>>>>>>> NAs introduced by coercion
>>>>>>> 
>>>>>>> 
>>>>>>> which would suggest that some character values could not be
>>>>>>> transformed to numbers.
>>>>>>> 
>>>>>>> On Thu, Feb 12, 2009 at 1:56 AM, Ned Horning <horning at amnh.org> wrote:
>>>>>>> 
>>>>>>>> 
>>>>>>>> Robert,
>>>>>>>> 
>>>>>>>> Using predrast <- setValues(predrast, as.vector(pred), r) I got 
>>>>>>>> another
>>>>>>>> error: values must be numeric, integer or logical.
>>>>>>>> 
>>>>>>>> class(pred) = "factor"
>>>>>>>> dim(pred) = NULL
>>>>>>>> class(v) = "character"
>>>>>>>> length(v) == ncol(spot) = TRUE
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Ned
>>>>>>>> 
>>>>>>>> Robert Hijmans wrote:
>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> Strange. You could try
>>>>>>>>>     predrast <- setValues(predrast, as.vector(pred), r)
>>>>>>>>> 
>>>>>>>>> But it would be good to know what pred is.
>>>>>>>>> 
>>>>>>>>> Can you do this:
>>>>>>>>> 
>>>>>>>>> class(pred)
>>>>>>>>> dim(pred)
>>>>>>>>> v <- as.vector(pred)
>>>>>>>>> class(v)
>>>>>>>>> length(v) == ncol(spot)
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> Robert
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> On Wed, Feb 11, 2009 at 11:16 PM, Ned Horning <horning at amnh.org> 
>>>>>>>>> wrote:
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Robert and Roger,
>>>>>>>>>> 
>>>>>>>>>> Thanks for the information and pointers. The raster package looks 
>>>>>>>>>> quite
>>>>>>>>>> interesting and I'll try to get up to speed on some of its
>>>>>>>>>> capabilities.
>>>>>>>>>> Are
>>>>>>>>>> the man pages the best way to do that or is that a single document
>>>>>>>>>> available?
>>>>>>>>>> 
>>>>>>>>>> I made some progress but still have some questions. I followed the
>>>>>>>>>> steps
>>>>>>>>>> laid out by Robert and everything went fine except I ran into an 
>>>>>>>>>> error
>>>>>>>>>> with
>>>>>>>>>> "predrast <- setValues(predrast, pred, r)" in the for loop when I 
>>>>>>>>>> tried
>>>>>>>>>> processing one line at a time and "r <- setValues(r, pred)" when I 
>>>>>>>>>> ran
>>>>>>>>>> the
>>>>>>>>>> full image in one go. The error was: "values must be a vector." Any
>>>>>>>>>> idea
>>>>>>>>>> what I'm doing wrong?
>>>>>>>>>> 
>>>>>>>>>> I tried to read the GRASS files directly but got a message saying 
>>>>>>>>>> it is
>>>>>>>>>> not
>>>>>>>>>> a supported file format. Can you confirm that is the case or am I 
>>>>>>>>>> doing
>>>>>>>>>> something wrong? I was able to read a tiff version of the image. I 
>>>>>>>>>> am
>>>>>>>>>> able
>>>>>>>>>> to run gdalinfo on GRASS files just fine from a terminal window.
>>>>>>>>>> 
>>>>>>>>>> Thanks again for the help.
>>>>>>>>>> 
>>>>>>>>>> Ned
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Robert Hijmans wrote:
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> Ned,
>>>>>>>>>>> 
>>>>>>>>>>> This is an example of running a RandomForest prediction with the
>>>>>>>>>>> raster package (for the simple case that there are no NA values in 
>>>>>>>>>>> the
>>>>>>>>>>> raster data; if there are, you have to into account that "predict'
>>>>>>>>>>> does not return any values (not even NA) for those cells).
>>>>>>>>>>> 
>>>>>>>>>>> Robert
>>>>>>>>>>> 
>>>>>>>>>>> #install.packages("raster", repos="http://R-Forge.R-project.org")
>>>>>>>>>>> require(raster)
>>>>>>>>>>> require(randomForest)
>>>>>>>>>>> 
>>>>>>>>>>> # for single band files
>>>>>>>>>>> spot <- stack('b1.tif', 'b2.tif', 'b3.tif')
>>>>>>>>>>> # for multiple band files
>>>>>>>>>>> # spot <- stackFromFiles(c('bands.tif', 'bands.tif', 'bands.tif'),
>>>>>>>>>>> c(1,2,3) )
>>>>>>>>>>> 
>>>>>>>>>>> # simulate random points and values to model with
>>>>>>>>>>> xy <- xyFromCell(spot, round(runif(100) * ncell(spot)))
>>>>>>>>>>> response <- runif(100) * 100
>>>>>>>>>>> # read values of raster layers at points, and bind to respinse
>>>>>>>>>>> trainvals <- cbind(response, xyValues(spot, xy))
>>>>>>>>>>> 
>>>>>>>>>>> # run RandomForest
>>>>>>>>>>> randfor <- randomForest(response ~ b1 + b2 + b3, data=trainvals)
>>>>>>>>>>> 
>>>>>>>>>>> # apply the prediction, row by row
>>>>>>>>>>> predrast <- setRaster(spot)
>>>>>>>>>>> filename(predrast) <- 'RF_pred.grd'
>>>>>>>>>>> for (r in 1:nrow(spot)) {
>>>>>>>>>>>      spot <- readRow(spot, r)
>>>>>>>>>>>      rowvals <- values(spot, names=TRUE)
>>>>>>>>>>> # this next line should not be necessary, but it is
>>>>>>>>>>> # I'll fix that
>>>>>>>>>>>      colnames(rowvals) <- c('b1', 'b2', 'b3')
>>>>>>>>>>>      pred <- predict(randfor, rowvals)
>>>>>>>>>>>      predrast <- setValues(predrast, pred, r)
>>>>>>>>>>>      predrast <- writeRaster(predrast, overwrite=TRUE)
>>>>>>>>>>> }
>>>>>>>>>>> 
>>>>>>>>>>> plot(predrast)
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> On Wed, Feb 11, 2009 at 5:09 PM, Roger Bivand 
>>>>>>>>>>> <Roger.Bivand at nhh.no>
>>>>>>>>>>> wrote:
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> Ned:
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> The three bands are most likely treated as 4-byte integers, so 
>>>>>>>>>>>> the
>>>>>>>>>>>> object
>>>>>>>>>>>> will be 2732 by 3058 by 3 by 4 plus a little bit. That's 100MB. 
>>>>>>>>>>>> They
>>>>>>>>>>>> may
>>>>>>>>>>>> get copied too. There are no single byte user-level containers 
>>>>>>>>>>>> for
>>>>>>>>>>>> you
>>>>>>>>>>>> (there is a raw data type, but you can't calculate with it). 
>>>>>>>>>>>> Possibly
>>>>>>>>>>>> saying spot_frame <- slot(spot, "data") will save one copying
>>>>>>>>>>>> operation,
>>>>>>>>>>>> but its hard to tell - your choice of method first adds inn all 
>>>>>>>>>>>> the
>>>>>>>>>>>> coordinates, which are 8-byte numbers, so more than doubles its 
>>>>>>>>>>>> size
>>>>>>>>>>>> and
>>>>>>>>>>>> makes more copies (to 233MB for each copy). Running gc() several
>>>>>>>>>>>> times
>>>>>>>>>>>> manually between steps often helps by making the garbage 
>>>>>>>>>>>> collector
>>>>>>>>>>>> more
>>>>>>>>>>>> aggressive.
>>>>>>>>>>>> 
>>>>>>>>>>>> I would watch the developments in the R-Forge package "raster", 
>>>>>>>>>>>> which
>>>>>>>>>>>> builds on some of these things, and try to see how that works. If 
>>>>>>>>>>>> you
>>>>>>>>>>>> have
>>>>>>>>>>>> the GDAL-GRASS plugin for rasters, you can use readGDAL to read 
>>>>>>>>>>>> from
>>>>>>>>>>>> GRASS
>>>>>>>>>>>> - which would work with raster package functions now. Look at the
>>>>>>>>>>>> code
>>>>>>>>>>>> of
>>>>>>>>>>>> recent readRAST6 to see which incantations are needed. If you are
>>>>>>>>>>>> going
>>>>>>>>>>>> to
>>>>>>>>>>>> use randomForest for prediction, you can use smaller tiles until 
>>>>>>>>>>>> you
>>>>>>>>>>>> find
>>>>>>>>>>>> an alternative solution. Note that feeding a data frame of 
>>>>>>>>>>>> integers
>>>>>>>>>>>> to
>>>>>>>>>>>> a
>>>>>>>>>>>> model fitting or prediction function will result in coercion to a
>>>>>>>>>>>> matrix of doubles, so your subsequent workflow should take that 
>>>>>>>>>>>> into
>>>>>>>>>>>> account.
>>>>>>>>>>>>  Getting more memory is another option, and may be very cost and
>>>>>>>>>>>> especially
>>>>>>>>>>>> time effective - at the moment your machine is swapping. Buying
>>>>>>>>>>>> memory
>>>>>>>>>>>> may
>>>>>>>>>>>> save you time programming around too little memory.
>>>>>>>>>>>> 
>>>>>>>>>>>> Hope this helps,
>>>>>>>>>>>> 
>>>>>>>>>>>> Roger
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> ---
>>>>>>>>>>>> Roger Bivand, NHH, Helleveien 30, N-5045 Bergen,
>>>>>>>>>>>> Roger.Bivand at nhh.no
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> -----Original Message-----
>>>>>>>>>>>> From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Ned 
>>>>>>>>>>>> Horning
>>>>>>>>>>>> Sent: Wed 11.02.2009 07:40
>>>>>>>>>>>> To: r-sig-geo at stat.math.ethz.ch
>>>>>>>>>>>> Subject: [R-sig-Geo] SpatialGridDataFrame to data.frame
>>>>>>>>>>>> 
>>>>>>>>>>>> Greetings,
>>>>>>>>>>>> 
>>>>>>>>>>>> I am trying to read an image from GRASS using the spgrass6 
>>>>>>>>>>>> command
>>>>>>>>>>>> readRAST6 and then convert it into a data.frame object so I can 
>>>>>>>>>>>> use
>>>>>>>>>>>> it
>>>>>>>>>>>> with randomForest. The byte image I'm reading is 2732 rows x 3058
>>>>>>>>>>>> columns x 3 bands. It's a small subset of a larger image I would 
>>>>>>>>>>>> like
>>>>>>>>>>>> to
>>>>>>>>>>>> use eventually. I have no problem reading the image using 
>>>>>>>>>>>> readRAST6
>>>>>>>>>>>> but
>>>>>>>>>>>> when I try to convert it to a data.frame object my linux system
>>>>>>>>>>>> resources (1BG RAM, 3GB swap) nearly get maxed out and it runs 
>>>>>>>>>>>> for a
>>>>>>>>>>>> couple hours before I kill the process. The image is less than 
>>>>>>>>>>>> 25MB
>>>>>>>>>>>> so
>>>>>>>>>>>> I'm surprised it requires this level of memory. Can someone let 
>>>>>>>>>>>> me
>>>>>>>>>>>> know
>>>>>>>>>>>> why this is. Should I use something other than the GRASS 
>>>>>>>>>>>> interface
>>>>>>>>>>>> for
>>>>>>>>>>>> this? These are the commands I'm using:
>>>>>>>>>>>> 
>>>>>>>>>>>> spot <- readRAST6(c("subset.red", "subset.green", "subset.blue"))
>>>>>>>>>>>> spot_frame <- as(spot, "data.frame")
>>>>>>>>>>>> 
>>>>>>>>>>>> Any help would be appreciated.
>>>>>>>>>>>> 
>>>>>>>>>>>> All the best,
>>>>>>>>>>>> 
>>>>>>>>>>>> Ned
>>>>>>>>>>>> 
>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>> R-sig-Geo mailing list
>>>>>>>>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>>
>>>>>>>>>>>>     [[alternative HTML version deleted]]
>>>>>>>>>>>> 
>>>>>>>>>>>> _______________________________________________
>>>>>>>>>>>> R-sig-Geo mailing list
>>>>>>>>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>> 
>>>>>> 
>>>>> 
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>> 
>>>> 
>>> 
>>> 
>> 
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From macq at llnl.gov  Thu Feb 12 17:01:03 2009
From: macq at llnl.gov (Don MacQueen)
Date: Thu, 12 Feb 2009 08:01:03 -0800
Subject: [R-sig-Geo] Assistance converting  SPDF polygons to holes
Message-ID: <p06240820c5b9f41b8596@[128.115.67.9]>

I feel a bit lazy asking for help, as I know I can do this -- but 
since I don't work with spatial polygons frequently, I find 
assembling objects consisting of nested polygons to be a bit 
challenging.

I have a Spatial Polygons Data Frame object named "s2poly" (read in 
from a polygons shapefile). The first portion of the output from 
str(s2poly) is shown here:

Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
   ..@ data       :'data.frame':	1173 obs. of  11 variables:
   .. ..$ OBJECTID  : num [1:1173] 3 12 13 77 78 79 80 81 82 83 ...
   .. ..$ ENTITY    : Factor w/ 0 levels: NA NA NA NA NA NA NA NA NA NA ...
   .. ..$ HANDLE    : Factor w/ 1173 levels "10002","10008",..: 348 
349 350 351 352 353 354 355 356 357 ...
   .. ..$ LAYER     : Factor w/ 15 levels 
"ADMIN_MAP","B-BLDG-LINE",..: 14 8 8 8 8 11 11 11 11 9 ...
   .. ..$ COLOR     : num [1:1173] 252 4 4 4 4 200 200 200 200 7 ...
   .. ..$ LINETYPE  : Factor w/ 3 levels "Continuous","DASHED",..: 1 1 
1 1 1 1 1 1 1 1 ...
   .. ..$ ELEVATION : num [1:1173] 0 0 0 0 0 0 0 0 0 0 ...
   .. ..$ THICKNESS : num [1:1173] 0 0 0 0 0 0 0 0 0 0 ...
   .. ..$ TEXT      : Factor w/ 0 levels: NA NA NA NA NA NA NA NA NA NA ...
   .. ..$ SHAPE_AREA: num [1:1173] 10.8 32549.7 16571.2 37.7 59.2 ...
   .. ..$ SHAPE_LEN : num [1:1173] 19 932.6 608 77.4 120.3 ...
   .. ..- attr(*, "data_types")= chr [1:11] "N" "C" "C" "C" ...
   ..@ polygons   :List of 1173
   .. ..$ :Formal class 'Polygons' [package "sp"] with 5 slots
   .. .. .. ..@ Polygons :List of 1
   .. .. .. .. ..$ :Formal class 'Polygon' [package "sp"] with 5 slots
   .. .. .. .. .. .. ..@ labpt  : num [1:2] 1653186 431813
   .. .. .. .. .. .. ..@ area   : num 10.8
   .. .. .. .. .. .. ..@ hole   : logi FALSE
   .. .. .. .. .. .. ..@ ringDir: int 1
   .. .. .. .. .. .. ..@ coords : num [1:8, 1:2] 1653190 1653190 
1653187 1653188 1653183 ...
   .. .. .. ..@ plotOrder: int 1
   .. .. .. ..@ labpt    : num [1:2] 1653186 431813
   .. .. .. ..@ ID       : chr "0"
   .. .. .. ..@ area     : num 10.8


I suspect, but have not confirmed, that some of the instances of 
Polygons objects have length > 1.

I have also created a simple polygon named "s2bound" that surrounds 
all of the polygons in s2poly.

I need a single object that I can give to spsample() in which all of 
the polygons in s2poly are holes within s2bound.
I don't need to keep any of the attributed data in @data, so I 
believe I can simplify to a SpatialPolygons object.

My basic request for assistance is this:

   -    can it be done with a modest number of high levels functions? 
(and if so, I think I need to be shown how)

   -    or will I need to write nested loops of @Polygons within 
@polygons to change @hole to TRUE in every polygon, in order 
construct my final polygon?

Thanks
-Don
-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
925-423-1062


From sisoliveira at gmail.com  Thu Feb 12 17:19:37 2009
From: sisoliveira at gmail.com (Sandra Oliveira)
Date: Thu, 12 Feb 2009 17:19:37 +0100
Subject: [R-sig-Geo] In R: adaptive kernel density estimation
Message-ID: <c1bb11eb0902120819pa5f2c51oeb8d5fb9d90e6976@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090212/925aee6c/attachment.pl>

From Greg.Snow at imail.org  Thu Feb 12 17:39:10 2009
From: Greg.Snow at imail.org (Greg Snow)
Date: Thu, 12 Feb 2009 09:39:10 -0700
Subject: [R-sig-Geo] How to move an island?!
In-Reply-To: <BF9B6C436B8F26458D7F5FC295C7770101CCC24D@gere.svf.au.dk>
References: <BF9B6C436B8F26458D7F5FC295C7770101CCC24D@gere.svf.au.dk>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61CA29FFF7@LP-EXMBVS10.CO.IHC.COM>

Well to move an island you are going to need a really big ship with a really big crane ...

Ok, on a more serious note.  Here is one approach that may work for you (a different idea from what you suggest below):

library(maptools)
library(TeachingDemos)

dnk <- readShapePoly('g:/downloads/DNK_adm/DNK1')
plot(dnk, xlim=c(7.81, 12.85), ylim=c(54.52, 58.22))
subplot( {plot(dnk, xlim=c(14.33,15.42), ylim=c(54.81,55.70) );box()},
                x=c(11.874, 13.0094), y=c(56.861, 57.964) )

Of course you can play with the coordinates to get it looking better and modify the plotting commands to match what you want to show (colors, other annotations, etc.).

Hope this helps,

--
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-
> bounces at stat.math.ethz.ch] On Behalf Of Peter Jepsen
> Sent: Thursday, February 12, 2009 1:30 AM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] How to move an island?!
>
> Dear all,
>
> I have only just begun plotting on maps, so please bear with me. I am
> plotting a map of Denmark in which each county is colorcoded by its
> incidence of a particular disease. I am using the map data found at
> http://biogeo.berkeley.edu/bgm/gdatares.php. The map is perfect, but
> the
> island of Bornholm, which is located far east of the rest of Denmark,
> is
> in its rightful place. To make the map look better, I want to move it
> northwest and put a box around it - this is common practice for maps of
> Denmark, in case you wonder.
>
> I thought that I could simply find the coordinates for Bornholm and
> change them by subtraction/addition, but I can't make it work.
>
> For simplicity, I first create a separate dataset for Bornholm:
>
> born <- dmk[dmk[[3]]=="Bornholm",]
> > class(born)
> [1] "SpatialPolygonsDataFrame"
> attr(,"package")
> [1] "sp"
>
> The output from the command -slot(born, "polygons")- is long and pasted
> at the bottom of this mail. Bornholm is made up of 5 polygons. How do I
> access and change the coordinates?
>
> ----
> > sessionInfo()
> R version 2.8.1 (2008-12-22)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=Danish_Denmark.1252;LC_CTYPE=Danish_Denmark.1252;LC_MONETARY
> =
> Danish_Denmark.1252;LC_NUMERIC=C;LC_TIME=Danish_Denmark.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
> other attached packages:
> [1] RColorBrewer_1.0-2 maptools_0.7-18    sp_0.9-29
> foreign_0.8-30
> [5] chron_2.3-28       reshape_0.8.2      plyr_0.1.4         epiR_0.9-
> 14
>
>
> loaded via a namespace (and not attached):
> [1] grid_2.8.1      lattice_0.17-20
> ----
> Thank you in advance for any help!
>
> Kind regards,
> Peter Jepsen, MD.
>
>
>
>
> > slot(born,"polygons")
> [[1]]
> An object of class "Polygons"
> Slot "Polygons":
> [[1]]
> An object of class "Polygon"
> Slot "labpt":
> [1] 14.93360 55.18284
>
> Slot "area":
> [1] 0.02132633
>
> Slot "hole":
> [1] FALSE
>
> Slot "ringDir":
> [1] 1
>
> Slot "coords":
>            [,1]     [,2]
>   [1,] 14.74450 55.25941
>   [2,] 14.74954 55.26576
>   [3,] 14.75460 55.27808
>   [4,] 14.75489 55.27881
>   [5,] 14.75441 55.28239
>   [6,] 14.75381 55.28687
>   [7,] 14.75334 55.29034
>   [8,] 14.77223 55.30014
>   [9,] 14.77590 55.29659
>  [10,] 14.77639 55.29427
>  [11,] 14.77480 55.29263
>  [12,] 14.77608 55.29094
>  [13,] 14.78393 55.28999
>  [14,] 14.78513 55.28917
>  [15,] 14.78525 55.28828
>  [16,] 14.78637 55.28833
>  [17,] 14.79954 55.27936
>  [18,] 14.80229 55.27904
>  [19,] 14.80276 55.27554
>  [20,] 14.80441 55.27561
>  [21,] 14.80461 55.27444
>  [22,] 14.81148 55.26933
>  [23,] 14.81180 55.26692
>  [24,] 14.81396 55.26702
>  [25,] 14.81659 55.25968
>  [26,] 14.82223 55.25358
>  [27,] 14.82505 55.25293
>  [28,] 14.82914 55.25199
>  [29,] 14.83412 55.24869
>  [30,] 14.84561 55.24796
>  [31,] 14.85450 55.24211
>  [32,] 14.87069 55.23971
>  [33,] 14.87092 55.23798
>  [34,] 14.87394 55.23811
>  [35,] 14.87913 55.23555
>  [36,] 14.87980 55.23404
>  [37,] 14.88147 55.23028
>  [38,] 14.88653 55.22743
>  [39,] 14.90632 55.22203
>  [40,] 14.91248 55.22152
>  [41,] 14.91856 55.22101
>  [42,] 14.93965 55.21001
>  [43,] 14.94801 55.20969
>  [44,] 14.95554 55.21334
>  [45,] 14.96859 55.21518
>  [46,] 14.97698 55.21123
>  [47,] 14.97758 55.20655
>  [48,] 14.98081 55.20669
>  [49,] 14.98628 55.20021
>  [50,] 14.98658 55.19793
>  [51,] 14.98815 55.19799
>  [52,] 14.99110 55.19450
>  [53,] 14.99268 55.19233
>  [54,] 15.00000 55.18967
>  [55,] 15.00427 55.18813
>  [56,] 15.01794 55.17828
>  [57,] 15.02075 55.17723
>  [58,] 15.03137 55.17327
>  [59,] 15.03702 55.17277
>  [60,] 15.04160 55.17237
>  [61,] 15.04540 55.16927
>  [62,] 15.04712 55.16787
>  [63,] 15.05378 55.16531
>  [64,] 15.05790 55.16372
>  [65,] 15.06153 55.15981
>  [66,] 15.07202 55.15820
>  [67,] 15.07648 55.15446
>  [68,] 15.09657 55.14877
>  [69,] 15.10328 55.14748
>  [70,] 15.10368 55.14431
>  [71,] 15.09584 55.14398
>  [72,] 15.09640 55.13950
>  [73,] 15.09696 55.13501
>  [74,] 15.08913 55.13469
>  [75,] 15.08969 55.13020
>  [76,] 15.09025 55.12572
>  [77,] 15.08242 55.12539
>  [78,] 15.08299 55.12091
>  [79,] 15.08355 55.11643
>  [80,] 15.07572 55.11610
>  [81,] 15.07628 55.11161
>  [82,] 15.07684 55.10713
>  [83,] 15.06902 55.10680
>  [84,] 15.06958 55.10232
>  [85,] 15.06176 55.10199
>  [86,] 15.05393 55.10166
>  [87,] 15.04611 55.10133
>  [88,] 15.03828 55.10099
>  [89,] 15.03046 55.10066
>  [90,] 15.02263 55.10033
>  [91,] 15.01481 55.09999
>  [92,] 15.00699 55.09966
>  [93,] 14.99916 55.09932
>  [94,] 14.99859 55.10381
>  [95,] 14.99077 55.10347
>  [96,] 14.98294 55.10313
>  [97,] 14.98237 55.10761
>  [98,] 14.97455 55.10728
>  [99,] 14.97397 55.11176
> [100,] 14.97340 55.11624
> [101,] 14.97282 55.12072
> [102,] 14.97225 55.12521
> [103,] 14.97168 55.12969
> [104,] 14.96385 55.12935
> [105,] 14.96327 55.13383
> [106,] 14.95544 55.13349
> [107,] 14.94761 55.13316
> [108,] 14.94703 55.13764
> [109,] 14.93920 55.13730
> [110,] 14.93137 55.13696
> [111,] 14.93079 55.14144
> [112,] 14.92296 55.14110
> [113,] 14.91513 55.14076
> [114,] 14.91455 55.14524
> [115,] 14.90672 55.14490
> [116,] 14.89889 55.14456
> [117,] 14.89830 55.14904
> [118,] 14.89772 55.15352
> [119,] 14.89714 55.15800
> [120,] 14.89655 55.16248
> [121,] 14.90439 55.16282
> [122,] 14.90381 55.16731
> [123,] 14.90322 55.17179
> [124,] 14.89539 55.17144
> [125,] 14.88755 55.17110
> [126,] 14.87971 55.17076
> [127,] 14.87913 55.17524
> [128,] 14.87129 55.17490
> [129,] 14.87070 55.17938
> [130,] 14.87012 55.18386
> [131,] 14.86953 55.18834
> [132,] 14.86894 55.19282
> [133,] 14.86836 55.19730
> [134,] 14.86051 55.19696
> [135,] 14.85993 55.20144
> [136,] 14.86777 55.20178
> [137,] 14.86718 55.20626
> [138,] 14.86659 55.21075
> [139,] 14.85875 55.21040
> [140,] 14.85816 55.21488
> [141,] 14.85032 55.21454
> [142,] 14.84247 55.21419
> [143,] 14.83462 55.21384
> [144,] 14.83522 55.20937
> [145,] 14.82737 55.20902
> [146,] 14.82678 55.21350
> [147,] 14.81893 55.21315
> [148,] 14.81834 55.21763
> [149,] 14.81050 55.21729
> [150,] 14.80990 55.22177
> [151,] 14.80206 55.22142
> [152,] 14.80146 55.22590
> [153,] 14.79361 55.22555
> [154,] 14.78577 55.22520
> [155,] 14.78636 55.22072
> [156,] 14.77852 55.22037
> [157,] 14.77792 55.22485
> [158,] 14.77007 55.22450
> [159,] 14.76947 55.22898
> [160,] 14.76887 55.23346
> [161,] 14.76827 55.23794
> [162,] 14.76767 55.24242
> [163,] 14.76707 55.24690
> [164,] 14.76647 55.25138
> [165,] 14.76587 55.25586
> [166,] 14.76527 55.26034
> [167,] 14.75742 55.25999
> [168,] 14.74957 55.25964
> [169,] 14.74450 55.25941
>
>
> [[2]]
> An object of class "Polygon"
> Slot "labpt":
> [1] 14.74174 55.25531
>
> Slot "area":
> [1] 1.212006e-06
>
> Slot "hole":
> [1] FALSE
>
> Slot "ringDir":
> [1] 1
>
> Slot "coords":
>          [,1]     [,2]
> [1,] 14.74079 55.25474
> [2,] 14.74210 55.25639
> [3,] 14.74232 55.25481
> [4,] 14.74079 55.25474
>
>
>
> Slot "plotOrder":
> [1] 1 2
>
> Slot "labpt":
> [1] 14.93360 55.18284
>
> Slot "ID":
> [1] "9"
>
> Slot "area":
> [1] 0.02132754
>
>
> [[2]]
> An object of class "Polygons"
> Slot "Polygons":
> [[1]]
> An object of class "Polygon"
> Slot "labpt":
> [1] 14.78569 55.18178
>
> Slot "area":
> [1] 0.01632464
>
> Slot "hole":
> [1] FALSE
>
> Slot "ringDir":
> [1] 1
>
> Slot "coords":
>            [,1]     [,2]
>   [1,] 14.74450 55.25941
>   [2,] 14.74957 55.25964
>   [3,] 14.75742 55.25999
>   [4,] 14.76527 55.26034
>   [5,] 14.76587 55.25586
>   [6,] 14.76647 55.25138
>   [7,] 14.76707 55.24690
>   [8,] 14.76767 55.24242
>   [9,] 14.76827 55.23794
>  [10,] 14.76887 55.23346
>  [11,] 14.76947 55.22898
>  [12,] 14.77007 55.22450
>  [13,] 14.77792 55.22485
>  [14,] 14.77852 55.22037
>  [15,] 14.78636 55.22072
>  [16,] 14.78577 55.22520
>  [17,] 14.79361 55.22555
>  [18,] 14.80146 55.22590
>  [19,] 14.80206 55.22142
>  [20,] 14.80990 55.22177
>  [21,] 14.81050 55.21729
>  [22,] 14.81834 55.21763
>  [23,] 14.81893 55.21315
>  [24,] 14.82678 55.21350
>  [25,] 14.82737 55.20902
>  [26,] 14.83522 55.20937
>  [27,] 14.83462 55.21384
>  [28,] 14.84247 55.21419
>  [29,] 14.85032 55.21454
>  [30,] 14.85816 55.21488
>  [31,] 14.85875 55.21040
>  [32,] 14.86659 55.21075
>  [33,] 14.86718 55.20626
>  [34,] 14.86777 55.20178
>  [35,] 14.85993 55.20144
>  [36,] 14.86051 55.19696
>  [37,] 14.86836 55.19730
>  [38,] 14.86894 55.19282
>  [39,] 14.86953 55.18834
>  [40,] 14.87012 55.18386
>  [41,] 14.87070 55.17938
>  [42,] 14.87129 55.17490
>  [43,] 14.87913 55.17524
>  [44,] 14.87971 55.17076
>  [45,] 14.88755 55.17110
>  [46,] 14.89539 55.17144
>  [47,] 14.90322 55.17179
>  [48,] 14.90381 55.16731
>  [49,] 14.90439 55.16282
>  [50,] 14.89655 55.16248
>  [51,] 14.89714 55.15800
>  [52,] 14.89772 55.15352
>  [53,] 14.89830 55.14904
>  [54,] 14.89889 55.14456
>  [55,] 14.89947 55.14008
>  [56,] 14.90005 55.13559
>  [57,] 14.89222 55.13525
>  [58,] 14.89281 55.13077
>  [59,] 14.88498 55.13043
>  [60,] 14.88439 55.13491
>  [61,] 14.88381 55.13939
>  [62,] 14.88322 55.14387
>  [63,] 14.87539 55.14353
>  [64,] 14.86756 55.14318
>  [65,] 14.85973 55.14284
>  [66,] 14.85190 55.14249
>  [67,] 14.84407 55.14215
>  [68,] 14.83624 55.14180
>  [69,] 14.83565 55.14628
>  [70,] 14.82782 55.14594
>  [71,] 14.82841 55.14146
>  [72,] 14.82057 55.14111
>  [73,] 14.81275 55.14076
>  [74,] 14.81334 55.13628
>  [75,] 14.80551 55.13593
>  [76,] 14.80610 55.13145
>  [77,] 14.79827 55.13110
>  [78,] 14.79044 55.13075
>  [79,] 14.78262 55.13041
>  [80,] 14.77479 55.13005
>  [81,] 14.77538 55.12557
>  [82,] 14.76756 55.12522
>  [83,] 14.76696 55.12970
>  [84,] 14.75913 55.12935
>  [85,] 14.75130 55.12900
>  [86,] 14.74348 55.12865
>  [87,] 14.73565 55.12830
>  [88,] 14.73505 55.13277
>  [89,] 14.72722 55.13242
>  [90,] 14.72662 55.13690
>  [91,] 14.72602 55.14138
>  [92,] 14.71819 55.14103
>  [93,] 14.71758 55.14551
>  [94,] 14.70975 55.14516
>  [95,] 14.70351 55.14487
>  [96,] 14.70161 55.14808
>  [97,] 14.70150 55.14925
>  [98,] 14.70396 55.16602
>  [99,] 14.70121 55.17632
> [100,] 14.70552 55.17652
> [101,] 14.70491 55.18100
> [102,] 14.70003 55.18077
> [103,] 14.69929 55.18353
> [104,] 14.70236 55.18701
> [105,] 14.69951 55.19428
> [106,] 14.70310 55.19444
> [107,] 14.70249 55.19892
> [108,] 14.70225 55.20072
> [109,] 14.70455 55.20477
> [110,] 14.70318 55.21014
> [111,] 14.70527 55.21257
> [112,] 14.70851 55.21272
> [113,] 14.70809 55.21585
> [114,] 14.70936 55.21733
> [115,] 14.70820 55.22176
> [116,] 14.71488 55.22731
> [117,] 14.71952 55.23575
> [118,] 14.72118 55.23582
> [119,] 14.72101 55.23705
> [120,] 14.73076 55.24552
> [121,] 14.73948 55.25308
> [122,] 14.74079 55.25474
> [123,] 14.74232 55.25481
> [124,] 14.74210 55.25639
> [125,] 14.74450 55.25941
>
>
>
> Slot "plotOrder":
> [1] 1
>
> Slot "labpt":
> [1] 14.78569 55.18178
>
> Slot "ID":
> [1] "78"
>
> Slot "area":
> [1] 0.01632464
>
>
> [[3]]
> An object of class "Polygons"
> Slot "Polygons":
> [[1]]
> An object of class "Polygon"
> Slot "labpt":
> [1] 15.07812 55.06290
>
> Slot "area":
> [1] 0.01516297
>
> Slot "hole":
> [1] FALSE
>
> Slot "ringDir":
> [1] 1
>
> Slot "coords":
>            [,1]     [,2]
>   [1,] 15.10328 55.14748
>   [2,] 15.11661 55.14492
>   [3,] 15.12046 55.14214
>   [4,] 15.14019 55.14267
>   [5,] 15.14262 55.13884
>   [6,] 15.14372 55.13885
>   [7,] 15.14395 55.13698
>   [8,] 15.14862 55.13717
>   [9,] 15.14859 55.13269
>  [10,] 15.15228 55.13227
>  [11,] 15.15289 55.12834
>  [12,] 15.15345 55.12386
>  [13,] 15.14562 55.12353
>  [14,] 15.14617 55.11905
>  [15,] 15.14673 55.11456
>  [16,] 15.14531 55.11247
>  [17,] 15.14700 55.10990
>  [18,] 15.14783 55.10560
>  [19,] 15.14816 55.10296
>  [20,] 15.14824 55.10228
>  [21,] 15.14860 55.10119
>  [22,] 15.14878 55.09883
>  [23,] 15.14894 55.09663
>  [24,] 15.15135 55.09673
>  [25,] 15.15702 55.09211
>  [26,] 15.15731 55.09067
>  [27,] 15.15512 55.08769
>  [28,] 15.15869 55.08134
>  [29,] 15.15641 55.07892
>  [30,] 15.15115 55.07870
>  [31,] 15.15160 55.07509
>  [32,] 15.15010 55.07415
>  [33,] 15.14389 55.07389
>  [34,] 15.14430 55.07052
>  [35,] 15.14239 55.06932
>  [36,] 15.13662 55.06908
>  [37,] 15.13720 55.06625
>  [38,] 15.13755 55.06459
>  [39,] 15.12936 55.06428
>  [40,] 15.12991 55.05979
>  [41,] 15.13042 55.05565
>  [42,] 15.12265 55.05499
>  [43,] 15.12321 55.05050
>  [44,] 15.11539 55.05017
>  [45,] 15.11595 55.04569
>  [46,] 15.11650 55.04121
>  [47,] 15.10869 55.04088
>  [48,] 15.10957 55.03604
>  [49,] 15.11614 55.02894
>  [50,] 15.11816 55.02788
>  [51,] 15.11873 55.02328
>  [52,] 15.11893 55.02163
>  [53,] 15.11708 55.01969
>  [54,] 15.11950 55.01705
>  [55,] 15.11992 55.01417
>  [56,] 15.11203 55.01398
>  [57,] 15.11257 55.00961
>  [58,] 15.10478 55.00917
>  [59,] 15.10528 55.00509
>  [60,] 15.09753 55.00436
>  [61,] 15.09805 55.00013
>  [62,] 15.09028 54.99955
>  [63,] 15.09084 54.99507
>  [64,] 15.08304 54.99474
>  [65,] 15.08360 54.99025
>  [66,] 15.07579 54.98993
>  [67,] 15.06799 54.98959
>  [68,] 15.06019 54.98926
>  [69,] 15.05239 54.98893
>  [70,] 15.05182 54.99342
>  [71,] 15.04402 54.99308
>  [72,] 15.03622 54.99275
>  [73,] 15.03565 54.99723
>  [74,] 15.02785 54.99690
>  [75,] 15.02005 54.99657
>  [76,] 15.01948 55.00105
>  [77,] 15.01167 55.00071
>  [78,] 15.00387 55.00038
>  [79,] 14.99607 55.00004
>  [80,] 14.99550 55.00452
>  [81,] 14.99493 55.00901
>  [82,] 14.99436 55.01349
>  [83,] 14.99379 55.01797
>  [84,] 14.99322 55.02245
>  [85,] 15.00103 55.02279
>  [86,] 15.00046 55.02727
>  [87,] 15.00827 55.02761
>  [88,] 15.00770 55.03209
>  [89,] 15.01551 55.03243
>  [90,] 15.01495 55.03691
>  [91,] 15.01438 55.04139
>  [92,] 15.01381 55.04587
>  [93,] 15.00600 55.04554
>  [94,] 15.00543 55.05002
>  [95,] 15.01324 55.05035
>  [96,] 15.01267 55.05484
>  [97,] 15.01211 55.05932
>  [98,] 15.01154 55.06380
>  [99,] 15.01935 55.06413
> [100,] 15.01879 55.06862
> [101,] 15.01822 55.07310
> [102,] 15.01765 55.07758
> [103,] 15.02547 55.07792
> [104,] 15.02490 55.08240
> [105,] 15.02434 55.08688
> [106,] 15.02377 55.09136
> [107,] 15.01595 55.09103
> [108,] 15.01538 55.09551
> [109,] 15.01481 55.09999
> [110,] 15.02263 55.10033
> [111,] 15.03046 55.10066
> [112,] 15.03828 55.10099
> [113,] 15.04611 55.10133
> [114,] 15.05393 55.10166
> [115,] 15.06176 55.10199
> [116,] 15.06958 55.10232
> [117,] 15.06902 55.10680
> [118,] 15.07684 55.10713
> [119,] 15.07628 55.11161
> [120,] 15.07572 55.11610
> [121,] 15.08355 55.11643
> [122,] 15.08299 55.12091
> [123,] 15.08242 55.12539
> [124,] 15.09025 55.12572
> [125,] 15.08969 55.13020
> [126,] 15.08913 55.13469
> [127,] 15.09696 55.13501
> [128,] 15.09640 55.13950
> [129,] 15.09584 55.14398
> [130,] 15.10368 55.14431
> [131,] 15.10328 55.14748
>
>
>
> Slot "plotOrder":
> [1] 1
>
> Slot "labpt":
> [1] 15.07812 55.06290
>
> Slot "ID":
> [1] "139"
>
> Slot "area":
> [1] 0.01516297
>
>
> [[4]]
> An object of class "Polygons"
> Slot "Polygons":
> [[1]]
> An object of class "Polygon"
> Slot "labpt":
> [1] 14.73583 55.10616
>
> Slot "area":
> [1] 0.004280022
>
> Slot "hole":
> [1] FALSE
>
> Slot "ringDir":
> [1] 1
>
> Slot "coords":
>           [,1]     [,2]
>  [1,] 14.73563 55.06969
>  [2,] 14.73503 55.07418
>  [3,] 14.72813 55.07386
>  [4,] 14.72706 55.07502
>  [5,] 14.72662 55.07830
>  [6,] 14.72602 55.08278
>  [7,] 14.71820 55.08243
>  [8,] 14.71038 55.08207
>  [9,] 14.70978 55.08656
> [10,] 14.70196 55.08620
> [11,] 14.70135 55.09068
> [12,] 14.69338 55.09008
> [13,] 14.69308 55.09368
> [14,] 14.69630 55.09442
> [15,] 14.69563 55.09721
> [16,] 14.69024 55.09824
> [17,] 14.68483 55.09653
> [18,] 14.68445 55.09930
> [19,] 14.68746 55.10255
> [20,] 14.69439 55.10326
> [21,] 14.69785 55.10672
> [22,] 14.70006 55.11415
> [23,] 14.69727 55.12097
> [24,] 14.70293 55.12499
> [25,] 14.70315 55.12683
> [26,] 14.70434 55.12688
> [27,] 14.70372 55.13150
> [28,] 14.70503 55.14230
> [29,] 14.70351 55.14487
> [30,] 14.70975 55.14516
> [31,] 14.71758 55.14551
> [32,] 14.71819 55.14103
> [33,] 14.72602 55.14138
> [34,] 14.72662 55.13690
> [35,] 14.72722 55.13242
> [36,] 14.73505 55.13277
> [37,] 14.73565 55.12830
> [38,] 14.74348 55.12865
> [39,] 14.75130 55.12900
> [40,] 14.75913 55.12935
> [41,] 14.76696 55.12970
> [42,] 14.76756 55.12522
> [43,] 14.76816 55.12074
> [44,] 14.77598 55.12109
> [45,] 14.77658 55.11661
> [46,] 14.77717 55.11213
> [47,] 14.77777 55.10765
> [48,] 14.78559 55.10800
> [49,] 14.78619 55.10352
> [50,] 14.78678 55.09904
> [51,] 14.78738 55.09456
> [52,] 14.77956 55.09421
> [53,] 14.78015 55.08973
> [54,] 14.77233 55.08937
> [55,] 14.76451 55.08902
> [56,] 14.75669 55.08867
> [57,] 14.75729 55.08419
> [58,] 14.75789 55.07971
> [59,] 14.75848 55.07523
> [60,] 14.75067 55.07488
> [61,] 14.75127 55.07040
> [62,] 14.74345 55.07005
> [63,] 14.73563 55.06969
>
>
>
> Slot "plotOrder":
> [1] 1
>
> Slot "labpt":
> [1] 14.73583 55.10616
>
> Slot "ID":
> [1] "173"
>
> Slot "area":
> [1] 0.004280022
>
>
> [[5]]
> An object of class "Polygons"
> Slot "Polygons":
> [[1]]
> An object of class "Polygon"
> Slot "labpt":
> [1] 14.89665 55.08017
>
> Slot "area":
> [1] 0.02517117
>
> Slot "hole":
> [1] FALSE
>
> Slot "ringDir":
> [1] 1
>
> Slot "coords":
>            [,1]     [,2]
>   [1,] 14.99550 55.00452
>   [2,] 14.98769 55.00419
>   [3,] 14.97989 55.00385
>   [4,] 14.97208 55.00352
>   [5,] 14.97151 55.00800
>   [6,] 14.96371 55.00766
>   [7,] 14.95590 55.00732
>   [8,] 14.95068 55.00710
>   [9,] 14.94791 55.00845
>  [10,] 14.94752 55.01147
>  [11,] 14.94222 55.01124
>  [12,] 14.93953 55.01255
>  [13,] 14.93914 55.01561
>  [14,] 14.93133 55.01527
>  [15,] 14.92353 55.01493
>  [16,] 14.92295 55.01941
>  [17,] 14.91555 55.01909
>  [18,] 14.91435 55.01989
>  [19,] 14.90696 55.02165
>  [20,] 14.90676 55.02321
>  [21,] 14.90142 55.02298
>  [22,] 14.89988 55.02291
>  [23,] 14.89881 55.02392
>  [24,] 14.89837 55.02735
>  [25,] 14.89292 55.02711
>  [26,] 14.89037 55.02849
>  [27,] 14.88998 55.03149
>  [28,] 14.88216 55.03126
>  [29,] 14.88159 55.03563
>  [30,] 14.87378 55.03529
>  [31,] 14.87319 55.03977
>  [32,] 14.86538 55.03943
>  [33,] 14.85757 55.03908
>  [34,] 14.85699 55.04356
>  [35,] 14.84917 55.04322
>  [36,] 14.84136 55.04287
>  [37,] 14.83355 55.04252
>  [38,] 14.82574 55.04218
>  [39,] 14.82515 55.04666
>  [40,] 14.81734 55.04631
>  [41,] 14.81675 55.05079
>  [42,] 14.80894 55.05045
>  [43,] 14.80408 55.05023
>  [44,] 14.80223 55.05097
>  [45,] 14.80098 55.05120
>  [46,] 14.80053 55.05458
>  [47,] 14.79272 55.05423
>  [48,] 14.78491 55.05388
>  [49,] 14.77709 55.05353
>  [50,] 14.77650 55.05801
>  [51,] 14.76869 55.05766
>  [52,] 14.76080 55.05784
>  [53,] 14.76028 55.06179
>  [54,] 14.75246 55.06144
>  [55,] 14.75186 55.06592
>  [56,] 14.74405 55.06557
>  [57,] 14.73813 55.06530
>  [58,] 14.73604 55.06666
>  [59,] 14.73563 55.06969
>  [60,] 14.74345 55.07005
>  [61,] 14.75127 55.07040
>  [62,] 14.75067 55.07488
>  [63,] 14.75848 55.07523
>  [64,] 14.75789 55.07971
>  [65,] 14.75729 55.08419
>  [66,] 14.75669 55.08867
>  [67,] 14.76451 55.08902
>  [68,] 14.77233 55.08937
>  [69,] 14.78015 55.08973
>  [70,] 14.77956 55.09421
>  [71,] 14.78738 55.09456
>  [72,] 14.78678 55.09904
>  [73,] 14.78619 55.10352
>  [74,] 14.78559 55.10800
>  [75,] 14.77777 55.10765
>  [76,] 14.77717 55.11213
>  [77,] 14.77658 55.11661
>  [78,] 14.77598 55.12109
>  [79,] 14.76816 55.12074
>  [80,] 14.76756 55.12522
>  [81,] 14.77538 55.12557
>  [82,] 14.77479 55.13005
>  [83,] 14.78262 55.13041
>  [84,] 14.79044 55.13075
>  [85,] 14.79827 55.13110
>  [86,] 14.80610 55.13145
>  [87,] 14.80551 55.13593
>  [88,] 14.81334 55.13628
>  [89,] 14.81275 55.14076
>  [90,] 14.82057 55.14111
>  [91,] 14.82841 55.14146
>  [92,] 14.82782 55.14594
>  [93,] 14.83565 55.14628
>  [94,] 14.83624 55.14180
>  [95,] 14.84407 55.14215
>  [96,] 14.85190 55.14249
>  [97,] 14.85973 55.14284
>  [98,] 14.86756 55.14318
>  [99,] 14.87539 55.14353
> [100,] 14.88322 55.14387
> [101,] 14.88381 55.13939
> [102,] 14.88439 55.13491
> [103,] 14.88498 55.13043
> [104,] 14.89281 55.13077
> [105,] 14.89222 55.13525
> [106,] 14.90005 55.13559
> [107,] 14.89947 55.14008
> [108,] 14.89889 55.14456
> [109,] 14.90672 55.14490
> [110,] 14.91455 55.14524
> [111,] 14.91513 55.14076
> [112,] 14.92296 55.14110
> [113,] 14.93079 55.14144
> [114,] 14.93137 55.13696
> [115,] 14.93920 55.13730
> [116,] 14.94703 55.13764
> [117,] 14.94761 55.13316
> [118,] 14.95544 55.13349
> [119,] 14.96327 55.13383
> [120,] 14.96385 55.12935
> [121,] 14.97168 55.12969
> [122,] 14.97225 55.12521
> [123,] 14.97282 55.12072
> [124,] 14.97340 55.11624
> [125,] 14.97397 55.11176
> [126,] 14.97455 55.10728
> [127,] 14.98237 55.10761
> [128,] 14.98294 55.10313
> [129,] 14.99077 55.10347
> [130,] 14.99859 55.10381
> [131,] 14.99916 55.09932
> [132,] 15.00699 55.09966
> [133,] 15.01481 55.09999
> [134,] 15.01538 55.09551
> [135,] 15.01595 55.09103
> [136,] 15.02377 55.09136
> [137,] 15.02434 55.08688
> [138,] 15.02490 55.08240
> [139,] 15.02547 55.07792
> [140,] 15.01765 55.07758
> [141,] 15.01822 55.07310
> [142,] 15.01879 55.06862
> [143,] 15.01935 55.06413
> [144,] 15.01154 55.06380
> [145,] 15.01211 55.05932
> [146,] 15.01267 55.05484
> [147,] 15.01324 55.05035
> [148,] 15.00543 55.05002
> [149,] 15.00600 55.04554
> [150,] 15.01381 55.04587
> [151,] 15.01438 55.04139
> [152,] 15.01495 55.03691
> [153,] 15.01551 55.03243
> [154,] 15.00770 55.03209
> [155,] 15.00827 55.02761
> [156,] 15.00046 55.02727
> [157,] 15.00103 55.02279
> [158,] 14.99322 55.02245
> [159,] 14.99379 55.01797
> [160,] 14.99436 55.01349
> [161,] 14.99493 55.00901
> [162,] 14.99550 55.00452
>
>
>
> Slot "plotOrder":
> [1] 1
>
> Slot "labpt":
> [1] 14.89665 55.08017
>
> Slot "ID":
> [1] "2"
>
> Slot "area":
> [1] 0.02517117
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Pierre.Racine at sbf.ulaval.ca  Thu Feb 12 18:00:27 2009
From: Pierre.Racine at sbf.ulaval.ca (Pierre Racine)
Date: Thu, 12 Feb 2009 12:00:27 -0500
Subject: [R-sig-Geo] Generating Random Transects of Same Length
Message-ID: <D58FF82475EA0A4A9347D3CE16B46E5F757ABE@exch-be03.ulaval.ca>

Hi,

Anybody knows a tool or algorythm (R, GRASS or ArcGIS Script, anything!)
to generate a number of random same length transects (e.g. 1000) within
the extent of a given polygon or raster?

I can't just create random point in the extent and joint hem two by two.
This would result in different length transects.

A simple algorythm would be:

-create a transect of a certain length from a random point and a random
angle
-reject any transect having an end falling outside the given extent

But there is chances that this takes years to run...

Thanks,

Pierre
Pierre.racine at sbf.ulaval.ca


From Roger.Bivand at nhh.no  Thu Feb 12 19:09:16 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 12 Feb 2009 19:09:16 +0100 (CET)
Subject: [R-sig-Geo] Assistance converting  SPDF polygons to holes
In-Reply-To: <p06240820c5b9f41b8596@[128.115.67.9]>
References: <p06240820c5b9f41b8596@[128.115.67.9]>
Message-ID: <alpine.LRH.2.00.0902121855010.6263@reclus.nhh.no>

On Thu, 12 Feb 2009, Don MacQueen wrote:

> I feel a bit lazy asking for help, as I know I can do this -- but since I 
> don't work with spatial polygons frequently, I find assembling objects 
> consisting of nested polygons to be a bit challenging.

It can be done, so this approach from the other side may not cater for the 
specifics. Using the NC counties, construct outbox:

library(maptools)
xx <- readShapeSpatial(system.file("shapes/sids.shp", package="maptools")[1],
  IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
library(splancs)
crds <- sbox(bboxx(bbox(xx)))
crds <- rbind(crds, crds[1,])
outbox <- Polygon(crds, hole=FALSE)

# sample a (much) larger number in outbox

zz <- sample.Polygon(outbox, n=2000, type="random")
plot(SpatialPolygons(list(Polygons(list(outbox), ID="box"))))
points(zz, pch=3, cex=0.5)
plot(xx, add=TRUE, border="red")

# overlay the points and the interior polygons and drop those inside

o <- overlay(as(xx, "SpatialPolygons"), zz)
zzz <- zz[is.na(o)]

zzzz <- zzz[sample(nrow(coordinates(zzz)), 500)]
points(zzzz, pch=3, cex=0.5, col="green")

which does something like your description. It ought to work if there are 
holes in your input polygons too.

It is possible to flatten the input Polygons objects into a single 
Polygons object, add the enclosing Polygon object to the list, and pass to 
checkPolygonsHoles(), but maybe the above is simpler.

Hope this helps,

Roger

>
> I have a Spatial Polygons Data Frame object named "s2poly" (read in from a 
> polygons shapefile). The first portion of the output from str(s2poly) is 
> shown here:
>
> Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
>  ..@ data       :'data.frame':	1173 obs. of  11 variables:
>  .. ..$ OBJECTID  : num [1:1173] 3 12 13 77 78 79 80 81 82 83 ...
>  .. ..$ ENTITY    : Factor w/ 0 levels: NA NA NA NA NA NA NA NA NA NA ...
>  .. ..$ HANDLE    : Factor w/ 1173 levels "10002","10008",..: 348 349 350 
> 351 352 353 354 355 356 357 ...
>  .. ..$ LAYER     : Factor w/ 15 levels "ADMIN_MAP","B-BLDG-LINE",..: 14 8 8 
> 8 8 11 11 11 11 9 ...
>  .. ..$ COLOR     : num [1:1173] 252 4 4 4 4 200 200 200 200 7 ...
>  .. ..$ LINETYPE  : Factor w/ 3 levels "Continuous","DASHED",..: 1 1 1 1 1 1 
> 1 1 1 1 ...
>  .. ..$ ELEVATION : num [1:1173] 0 0 0 0 0 0 0 0 0 0 ...
>  .. ..$ THICKNESS : num [1:1173] 0 0 0 0 0 0 0 0 0 0 ...
>  .. ..$ TEXT      : Factor w/ 0 levels: NA NA NA NA NA NA NA NA NA NA ...
>  .. ..$ SHAPE_AREA: num [1:1173] 10.8 32549.7 16571.2 37.7 59.2 ...
>  .. ..$ SHAPE_LEN : num [1:1173] 19 932.6 608 77.4 120.3 ...
>  .. ..- attr(*, "data_types")= chr [1:11] "N" "C" "C" "C" ...
>  ..@ polygons   :List of 1173
>  .. ..$ :Formal class 'Polygons' [package "sp"] with 5 slots
>  .. .. .. ..@ Polygons :List of 1
>  .. .. .. .. ..$ :Formal class 'Polygon' [package "sp"] with 5 slots
>  .. .. .. .. .. .. ..@ labpt  : num [1:2] 1653186 431813
>  .. .. .. .. .. .. ..@ area   : num 10.8
>  .. .. .. .. .. .. ..@ hole   : logi FALSE
>  .. .. .. .. .. .. ..@ ringDir: int 1
>  .. .. .. .. .. .. ..@ coords : num [1:8, 1:2] 1653190 1653190 1653187 
> 1653188 1653183 ...
>  .. .. .. ..@ plotOrder: int 1
>  .. .. .. ..@ labpt    : num [1:2] 1653186 431813
>  .. .. .. ..@ ID       : chr "0"
>  .. .. .. ..@ area     : num 10.8
>
>
> I suspect, but have not confirmed, that some of the instances of Polygons 
> objects have length > 1.
>
> I have also created a simple polygon named "s2bound" that surrounds all of 
> the polygons in s2poly.
>
> I need a single object that I can give to spsample() in which all of the 
> polygons in s2poly are holes within s2bound.
> I don't need to keep any of the attributed data in @data, so I believe I can 
> simplify to a SpatialPolygons object.
>
> My basic request for assistance is this:
>
>  -    can it be done with a modest number of high levels functions? (and if 
> so, I think I need to be shown how)
>
>  -    or will I need to write nested loops of @Polygons within @polygons to 
> change @hole to TRUE in every polygon, in order construct my final polygon?
>
> Thanks
> -Don
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From b.rowlingson at lancaster.ac.uk  Thu Feb 12 19:33:25 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 12 Feb 2009 18:33:25 +0000
Subject: [R-sig-Geo] Generating Random Transects of Same Length
In-Reply-To: <D58FF82475EA0A4A9347D3CE16B46E5F757ABE@exch-be03.ulaval.ca>
References: <D58FF82475EA0A4A9347D3CE16B46E5F757ABE@exch-be03.ulaval.ca>
Message-ID: <d8ad40b50902121033s5f643babwfd9b0ac8f30e6b82@mail.gmail.com>

2009/2/12 Pierre Racine <Pierre.Racine at sbf.ulaval.ca>:
> Hi,
>
> Anybody knows a tool or algorythm (R, GRASS or ArcGIS Script, anything!)
> to generate a number of random same length transects (e.g. 1000) within
> the extent of a given polygon or raster?
>
> I can't just create random point in the extent and joint hem two by two.
> This would result in different length transects.
>
> A simple algorythm would be:
>
> -create a transect of a certain length from a random point and a random
> angle
> -reject any transect having an end falling outside the given extent
>
> But there is chances that this takes years to run...

 What do you mean by 'random' transects?

 You could define a buffer line of distance d around the inside your
polygon. This divides space into three regions - the outside area, the
buffer zone area, and the inside area. The buffer zone area and the
inside area make up your original polygon.

 Then choose your first point from a spatial uniform distribution on
the inside area. Then pick another point at a random U(0,2*pi) angle
and distance d. This is guaranteed to be in the original polygon, so
there's no rejection step. However, you'll never get transects with
start and end both within the buffer zone. But they would still, in
some sense of the word, be 'random'.

 If this isn't clear then I think a picture would make it so! I think
you can do buffer operations in R... Grass certainly can!

Barry


From marcelino.delacruz at upm.es  Thu Feb 12 20:16:09 2009
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Thu, 12 Feb 2009 20:16:09 +0100
Subject: [R-sig-Geo] Generating Random Transects of Same Length
In-Reply-To: <d8ad40b50902121033s5f643babwfd9b0ac8f30e6b82@mail.gmail.co
 m>
References: <D58FF82475EA0A4A9347D3CE16B46E5F757ABE@exch-be03.ulaval.ca>
	<d8ad40b50902121033s5f643babwfd9b0ac8f30e6b82@mail.gmail.com>
Message-ID: <200902121917.n1CJHVWk027216@edison.ccupm.upm.es>


As an spatstat aficionado, I would use the following code:

Enjoy!

Marcelino


library(spatstat)

# Define polygon, length of transect and number of (points)transects
data(letterR)
mywindow <- letterR
ltransect <- 0.3
npoints <- 100
s<- 1:npoints

# Generate random origin points
cosa <- runifpoint(npoints, w=mywindow)
plot(cosa)


cosaxy <- data.frame(cosa$x,cosa$y)

#compute a circle around each point
cosadisc<- apply(cosaxy,1, function(x) disc(r=ltransect, x))

# Test if every circle point is inside polygonal boundary
cosadisc.df <- lapply(cosadisc, function(W){
                          inside.owin(W$bdry[[1]]$x,W$bdry[[1]]$y 
,w=mywindow)})

#function to sample circle points within the window
samplea2 <- function(cosaxy, l1=cosadisc, l2=cosadisc.df){
result<-c(0,0)
for (i in 1:length(l1)){
                  truinside<-sum(l2[[i]])
                  inside 
<-cbind(l1[[i]]$bdry[[1]]$x,l1[[i]]$bdry[[1]]$y)[l2[[i]],]
                  result<-rbind(result,  inside[sample(1:truinside, size=1),])
}
result<-result[-1,]
result<-cbind(cosaxy,result)
return(result)
}

#the result is a matrix with x0,y0, x1, y1 for each transect
#Plot the random transects:

segmentos<-samplea2(cosaxy)
segments(segmentos[,1][s], segmentos[,2][s],segmentos[,3][s], segmentos[,4][s])




At 19:33 12/02/2009, Barry Rowlingson wrote:
>2009/2/12 Pierre Racine <Pierre.Racine at sbf.ulaval.ca>:
> > Hi,
> >
> > Anybody knows a tool or algorythm (R, GRASS or ArcGIS Script, anything!)
> > to generate a number of random same length transects (e.g. 1000) within
> > the extent of a given polygon or raster?
> >
> > I can't just create random point in the extent and joint hem two by two.
> > This would result in different length transects.
> >
> > A simple algorythm would be:
> >
> > -create a transect of a certain length from a random point and a random
> > angle
> > -reject any transect having an end falling outside the given extent
> >
> > But there is chances that this takes years to run...
>
>  What do you mean by 'random' transects?
>
>  You could define a buffer line of distance d around the inside your
>polygon. This divides space into three regions - the outside area, the
>buffer zone area, and the inside area. The buffer zone area and the
>inside area make up your original polygon.
>
>  Then choose your first point from a spatial uniform distribution on
>the inside area. Then pick another point at a random U(0,2*pi) angle
>and distance d. This is guaranteed to be in the original polygon, so
>there's no rejection step. However, you'll never get transects with
>start and end both within the buffer zone. But they would still, in
>some sense of the word, be 'random'.
>
>  If this isn't clear then I think a picture would make it so! I think
>you can do buffer operations in R... Grass certainly can!
>
>Barry
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at stat.math.ethz.ch
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>---------------------------------------------------------------------------------------------------
>Texto a?adido por Panda IS 2008:
>
>  Este mensaje NO ha sido clasificado como SPAM. 
> Si se trata de un mensaje de correo no 
> solicitado (SPAM), haz clic en el siguiente 
> v?nculo para reclasificarlo: 
> http://localhost:6083/Panda?ID=pav_4376&SPAM=true&path=C:\Documents%20and%20Settings\mcr\Configuraci?n%20local\Datos%20de%20programa\Panda%20Software\AntiSpam
>---------------------------------------------------------------------------------------------------

________________________________

Marcelino de la Cruz Rot

Departamento de  Biolog?a Vegetal
E.U.T.I. Agr?cola
Universidad Polit?cnica de Madrid
28040-Madrid
Tel.: 91 336 54 35
Fax: 91 336 56 56
marcelino.delacruz at upm.es


From b.rowlingson at lancaster.ac.uk  Thu Feb 12 20:42:40 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 12 Feb 2009 19:42:40 +0000
Subject: [R-sig-Geo] Generating Random Transects of Same Length
In-Reply-To: <200902121917.n1CJHVWk027216@edison.ccupm.upm.es>
References: <D58FF82475EA0A4A9347D3CE16B46E5F757ABE@exch-be03.ulaval.ca>
	<d8ad40b50902121033s5f643babwfd9b0ac8f30e6b82@mail.gmail.com>
	<200902121917.n1CJHVWk027216@edison.ccupm.upm.es>
Message-ID: <d8ad40b50902121142m7275baccof4ea47b0d43e330c@mail.gmail.com>

2009/2/12 Marcelino de la Cruz <marcelino.delacruz at upm.es>:
>
> As an spatstat aficionado, I would use the following code:

 Very very nice, but:

> #compute a circle around each point
> cosadisc<- apply(cosaxy,1, function(x) disc(r=ltransect, x))

 generates 128 points on a circle around each point. There's a teeny
tiny chance that none of those points will be in your polygon :)  What
you've done is a rejection method where you generate 128 and throw 127
away!

 I can see the following ways of doing this:

 A:  1. generate first point from CSR on the polygon
      2. generate second point at distance D from first point
      3. goto *2* until second point is in polygon.

 B: 1. generate first point from CSR on the polygon
     2. generate second point at distance D from the first point
     3. goto *1* until second point is in polygon

 C: buffer zone method

your code essentially does A, where the first points are CSR but the
second points arent (I think), and B will have neither first points
nor second points as CSR since it avoids the edges.

the buffer zone method produces CSR in the inner zone for the first
points and non-CSR for the second points.

all depends on what the original questioner wanted - if just a bunch
of segments of length D roughly scattered around inside the polygon
then wham! your lovely spatstat code is exactly that!

Barry


From tephilippi at gmail.com  Fri Feb 13 00:33:06 2009
From: tephilippi at gmail.com (Tom Philippi)
Date: Thu, 12 Feb 2009 16:33:06 -0700
Subject: [R-sig-Geo] Generating Random Transects of Same Length
In-Reply-To: <d8ad40b50902121142m7275baccof4ea47b0d43e330c@mail.gmail.com>
References: <D58FF82475EA0A4A9347D3CE16B46E5F757ABE@exch-be03.ulaval.ca>
	<d8ad40b50902121033s5f643babwfd9b0ac8f30e6b82@mail.gmail.com>
	<200902121917.n1CJHVWk027216@edison.ccupm.upm.es>
	<d8ad40b50902121142m7275baccof4ea47b0d43e330c@mail.gmail.com>
Message-ID: <71ce895d0902121533l52627b84x67b4dec139975222@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090212/5517af28/attachment.pl>

From p.hiemstra at geo.uu.nl  Fri Feb 13 15:39:11 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Fri, 13 Feb 2009 15:39:11 +0100
Subject: [R-sig-Geo] How to move an island?!
In-Reply-To: <BF9B6C436B8F26458D7F5FC295C7770101CCC24D@gere.svf.au.dk>
References: <BF9B6C436B8F26458D7F5FC295C7770101CCC24D@gere.svf.au.dk>
Message-ID: <4995860F.7050708@geo.uu.nl>

Hi Peter,

In addition to the other people who replied (you can do stuff in 
multiple ways in R :)):

Make two seperate spatial objects, one with the island and one with the 
rest and plot them seperately:

island = dmk[dmk[[3]]=="Bornholm"]
rest = dmk[dmk[[3]]!="Bornholm"]

plot_island = spplot(island, colorkey = FALSE) # get rid of the colorkey
plot_rest = spplot(rest)

print(plot_rest, more = TRUE)
print(plot_island, position = c(c(0.1,0.65,0.30,0.9)))

The position argument specifies the area which plot_island is allowed to 
use. The first two numbers are the lower left corner and the two final 
numbers the upper right corner. The coordinates system is as follows, 
the lower left corner of the plot is (0,0), the upper left is (1,1). You 
have to do some trial and error to find the correct numbers for the 
position argument.

You can also use the coordinate system of your plot (e.g. UTM) to 
specify where the plot needs to be:

require(grid)
print(plot_rest, more = TRUE)
trellis.focus()  # This is to focus on your plot, important later on...
# The bbox for your subplot in the coor system of your data
coor_in_your_system = unit(c(a,b,c,d), "native")
# Convert it to the (0,0) to (1,1) system
position_vector = convertX(coor_in_your_system, "npc")
trellis.unfocus()
print(plot_island, position = position_vector)

See ?grid.convert and ?unit for more details. I hope this last section 
is clear, if not, do not hesitate to send an e-mail.

cheers,
Paul

Peter Jepsen wrote:
> Dear all,
>
> I have only just begun plotting on maps, so please bear with me. I am
> plotting a map of Denmark in which each county is colorcoded by its
> incidence of a particular disease. I am using the map data found at
> http://biogeo.berkeley.edu/bgm/gdatares.php. The map is perfect, but the
> island of Bornholm, which is located far east of the rest of Denmark, is
> in its rightful place. To make the map look better, I want to move it
> northwest and put a box around it - this is common practice for maps of
> Denmark, in case you wonder.
>
> I thought that I could simply find the coordinates for Bornholm and
> change them by subtraction/addition, but I can't make it work. 
>
> For simplicity, I first create a separate dataset for Bornholm:
>
> born <- dmk[dmk[[3]]=="Bornholm",]
>   
>> class(born)
>>     
> [1] "SpatialPolygonsDataFrame"
> attr(,"package")
> [1] "sp"
>
> The output from the command -slot(born, "polygons")- is long and pasted
> at the bottom of this mail. Bornholm is made up of 5 polygons. How do I
> access and change the coordinates?  
>
> ----
>   
>> sessionInfo()
>>     
> R version 2.8.1 (2008-12-22) 
> i386-pc-mingw32 
>
> locale:
> LC_COLLATE=Danish_Denmark.1252;LC_CTYPE=Danish_Denmark.1252;LC_MONETARY=
> Danish_Denmark.1252;LC_NUMERIC=C;LC_TIME=Danish_Denmark.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
> other attached packages:
> [1] RColorBrewer_1.0-2 maptools_0.7-18    sp_0.9-29
> foreign_0.8-30    
> [5] chron_2.3-28       reshape_0.8.2      plyr_0.1.4         epiR_0.9-14
>
>
> loaded via a namespace (and not attached):
> [1] grid_2.8.1      lattice_0.17-20
> ----
> Thank you in advance for any help!
>
> Kind regards,
> Peter Jepsen, MD.
>
>
>
>
>   
>> slot(born,"polygons")
>>     
> [[1]]
> An object of class "Polygons"
> Slot "Polygons":
> [[1]]
> An object of class "Polygon"
> Slot "labpt":
> [1] 14.93360 55.18284
>
> Slot "area":
> [1] 0.02132633
>
> Slot "hole":
> [1] FALSE
>
> Slot "ringDir":
> [1] 1
>
> Slot "coords":
>            [,1]     [,2]
>   [1,] 14.74450 55.25941
>   [2,] 14.74954 55.26576
>   [3,] 14.75460 55.27808
>   [4,] 14.75489 55.27881
>   [5,] 14.75441 55.28239
>   [6,] 14.75381 55.28687
>   [7,] 14.75334 55.29034
>   [8,] 14.77223 55.30014
>   [9,] 14.77590 55.29659
>  [10,] 14.77639 55.29427
>  [11,] 14.77480 55.29263
>  [12,] 14.77608 55.29094
>  [13,] 14.78393 55.28999
>  [14,] 14.78513 55.28917
>  [15,] 14.78525 55.28828
>  [16,] 14.78637 55.28833
>  [17,] 14.79954 55.27936
>  [18,] 14.80229 55.27904
>  [19,] 14.80276 55.27554
>  [20,] 14.80441 55.27561
>  [21,] 14.80461 55.27444
>  [22,] 14.81148 55.26933
>  [23,] 14.81180 55.26692
>  [24,] 14.81396 55.26702
>  [25,] 14.81659 55.25968
>  [26,] 14.82223 55.25358
>  [27,] 14.82505 55.25293
>  [28,] 14.82914 55.25199
>  [29,] 14.83412 55.24869
>  [30,] 14.84561 55.24796
>  [31,] 14.85450 55.24211
>  [32,] 14.87069 55.23971
>  [33,] 14.87092 55.23798
>  [34,] 14.87394 55.23811
>  [35,] 14.87913 55.23555
>  [36,] 14.87980 55.23404
>  [37,] 14.88147 55.23028
>  [38,] 14.88653 55.22743
>  [39,] 14.90632 55.22203
>  [40,] 14.91248 55.22152
>  [41,] 14.91856 55.22101
>  [42,] 14.93965 55.21001
>  [43,] 14.94801 55.20969
>  [44,] 14.95554 55.21334
>  [45,] 14.96859 55.21518
>  [46,] 14.97698 55.21123
>  [47,] 14.97758 55.20655
>  [48,] 14.98081 55.20669
>  [49,] 14.98628 55.20021
>  [50,] 14.98658 55.19793
>  [51,] 14.98815 55.19799
>  [52,] 14.99110 55.19450
>  [53,] 14.99268 55.19233
>  [54,] 15.00000 55.18967
>  [55,] 15.00427 55.18813
>  [56,] 15.01794 55.17828
>  [57,] 15.02075 55.17723
>  [58,] 15.03137 55.17327
>  [59,] 15.03702 55.17277
>  [60,] 15.04160 55.17237
>  [61,] 15.04540 55.16927
>  [62,] 15.04712 55.16787
>  [63,] 15.05378 55.16531
>  [64,] 15.05790 55.16372
>  [65,] 15.06153 55.15981
>  [66,] 15.07202 55.15820
>  [67,] 15.07648 55.15446
>  [68,] 15.09657 55.14877
>  [69,] 15.10328 55.14748
>  [70,] 15.10368 55.14431
>  [71,] 15.09584 55.14398
>  [72,] 15.09640 55.13950
>  [73,] 15.09696 55.13501
>  [74,] 15.08913 55.13469
>  [75,] 15.08969 55.13020
>  [76,] 15.09025 55.12572
>  [77,] 15.08242 55.12539
>  [78,] 15.08299 55.12091
>  [79,] 15.08355 55.11643
>  [80,] 15.07572 55.11610
>  [81,] 15.07628 55.11161
>  [82,] 15.07684 55.10713
>  [83,] 15.06902 55.10680
>  [84,] 15.06958 55.10232
>  [85,] 15.06176 55.10199
>  [86,] 15.05393 55.10166
>  [87,] 15.04611 55.10133
>  [88,] 15.03828 55.10099
>  [89,] 15.03046 55.10066
>  [90,] 15.02263 55.10033
>  [91,] 15.01481 55.09999
>  [92,] 15.00699 55.09966
>  [93,] 14.99916 55.09932
>  [94,] 14.99859 55.10381
>  [95,] 14.99077 55.10347
>  [96,] 14.98294 55.10313
>  [97,] 14.98237 55.10761
>  [98,] 14.97455 55.10728
>  [99,] 14.97397 55.11176
> [100,] 14.97340 55.11624
> [101,] 14.97282 55.12072
> [102,] 14.97225 55.12521
> [103,] 14.97168 55.12969
> [104,] 14.96385 55.12935
> [105,] 14.96327 55.13383
> [106,] 14.95544 55.13349
> [107,] 14.94761 55.13316
> [108,] 14.94703 55.13764
> [109,] 14.93920 55.13730
> [110,] 14.93137 55.13696
> [111,] 14.93079 55.14144
> [112,] 14.92296 55.14110
> [113,] 14.91513 55.14076
> [114,] 14.91455 55.14524
> [115,] 14.90672 55.14490
> [116,] 14.89889 55.14456
> [117,] 14.89830 55.14904
> [118,] 14.89772 55.15352
> [119,] 14.89714 55.15800
> [120,] 14.89655 55.16248
> [121,] 14.90439 55.16282
> [122,] 14.90381 55.16731
> [123,] 14.90322 55.17179
> [124,] 14.89539 55.17144
> [125,] 14.88755 55.17110
> [126,] 14.87971 55.17076
> [127,] 14.87913 55.17524
> [128,] 14.87129 55.17490
> [129,] 14.87070 55.17938
> [130,] 14.87012 55.18386
> [131,] 14.86953 55.18834
> [132,] 14.86894 55.19282
> [133,] 14.86836 55.19730
> [134,] 14.86051 55.19696
> [135,] 14.85993 55.20144
> [136,] 14.86777 55.20178
> [137,] 14.86718 55.20626
> [138,] 14.86659 55.21075
> [139,] 14.85875 55.21040
> [140,] 14.85816 55.21488
> [141,] 14.85032 55.21454
> [142,] 14.84247 55.21419
> [143,] 14.83462 55.21384
> [144,] 14.83522 55.20937
> [145,] 14.82737 55.20902
> [146,] 14.82678 55.21350
> [147,] 14.81893 55.21315
> [148,] 14.81834 55.21763
> [149,] 14.81050 55.21729
> [150,] 14.80990 55.22177
> [151,] 14.80206 55.22142
> [152,] 14.80146 55.22590
> [153,] 14.79361 55.22555
> [154,] 14.78577 55.22520
> [155,] 14.78636 55.22072
> [156,] 14.77852 55.22037
> [157,] 14.77792 55.22485
> [158,] 14.77007 55.22450
> [159,] 14.76947 55.22898
> [160,] 14.76887 55.23346
> [161,] 14.76827 55.23794
> [162,] 14.76767 55.24242
> [163,] 14.76707 55.24690
> [164,] 14.76647 55.25138
> [165,] 14.76587 55.25586
> [166,] 14.76527 55.26034
> [167,] 14.75742 55.25999
> [168,] 14.74957 55.25964
> [169,] 14.74450 55.25941
>
>
> [[2]]
> An object of class "Polygon"
> Slot "labpt":
> [1] 14.74174 55.25531
>
> Slot "area":
> [1] 1.212006e-06
>
> Slot "hole":
> [1] FALSE
>
> Slot "ringDir":
> [1] 1
>
> Slot "coords":
>          [,1]     [,2]
> [1,] 14.74079 55.25474
> [2,] 14.74210 55.25639
> [3,] 14.74232 55.25481
> [4,] 14.74079 55.25474
>
>
>
> Slot "plotOrder":
> [1] 1 2
>
> Slot "labpt":
> [1] 14.93360 55.18284
>
> Slot "ID":
> [1] "9"
>
> Slot "area":
> [1] 0.02132754
>
>
> [[2]]
> An object of class "Polygons"
> Slot "Polygons":
> [[1]]
> An object of class "Polygon"
> Slot "labpt":
> [1] 14.78569 55.18178
>
> Slot "area":
> [1] 0.01632464
>
> Slot "hole":
> [1] FALSE
>
> Slot "ringDir":
> [1] 1
>
> Slot "coords":
>            [,1]     [,2]
>   [1,] 14.74450 55.25941
>   [2,] 14.74957 55.25964
>   [3,] 14.75742 55.25999
>   [4,] 14.76527 55.26034
>   [5,] 14.76587 55.25586
>   [6,] 14.76647 55.25138
>   [7,] 14.76707 55.24690
>   [8,] 14.76767 55.24242
>   [9,] 14.76827 55.23794
>  [10,] 14.76887 55.23346
>  [11,] 14.76947 55.22898
>  [12,] 14.77007 55.22450
>  [13,] 14.77792 55.22485
>  [14,] 14.77852 55.22037
>  [15,] 14.78636 55.22072
>  [16,] 14.78577 55.22520
>  [17,] 14.79361 55.22555
>  [18,] 14.80146 55.22590
>  [19,] 14.80206 55.22142
>  [20,] 14.80990 55.22177
>  [21,] 14.81050 55.21729
>  [22,] 14.81834 55.21763
>  [23,] 14.81893 55.21315
>  [24,] 14.82678 55.21350
>  [25,] 14.82737 55.20902
>  [26,] 14.83522 55.20937
>  [27,] 14.83462 55.21384
>  [28,] 14.84247 55.21419
>  [29,] 14.85032 55.21454
>  [30,] 14.85816 55.21488
>  [31,] 14.85875 55.21040
>  [32,] 14.86659 55.21075
>  [33,] 14.86718 55.20626
>  [34,] 14.86777 55.20178
>  [35,] 14.85993 55.20144
>  [36,] 14.86051 55.19696
>  [37,] 14.86836 55.19730
>  [38,] 14.86894 55.19282
>  [39,] 14.86953 55.18834
>  [40,] 14.87012 55.18386
>  [41,] 14.87070 55.17938
>  [42,] 14.87129 55.17490
>  [43,] 14.87913 55.17524
>  [44,] 14.87971 55.17076
>  [45,] 14.88755 55.17110
>  [46,] 14.89539 55.17144
>  [47,] 14.90322 55.17179
>  [48,] 14.90381 55.16731
>  [49,] 14.90439 55.16282
>  [50,] 14.89655 55.16248
>  [51,] 14.89714 55.15800
>  [52,] 14.89772 55.15352
>  [53,] 14.89830 55.14904
>  [54,] 14.89889 55.14456
>  [55,] 14.89947 55.14008
>  [56,] 14.90005 55.13559
>  [57,] 14.89222 55.13525
>  [58,] 14.89281 55.13077
>  [59,] 14.88498 55.13043
>  [60,] 14.88439 55.13491
>  [61,] 14.88381 55.13939
>  [62,] 14.88322 55.14387
>  [63,] 14.87539 55.14353
>  [64,] 14.86756 55.14318
>  [65,] 14.85973 55.14284
>  [66,] 14.85190 55.14249
>  [67,] 14.84407 55.14215
>  [68,] 14.83624 55.14180
>  [69,] 14.83565 55.14628
>  [70,] 14.82782 55.14594
>  [71,] 14.82841 55.14146
>  [72,] 14.82057 55.14111
>  [73,] 14.81275 55.14076
>  [74,] 14.81334 55.13628
>  [75,] 14.80551 55.13593
>  [76,] 14.80610 55.13145
>  [77,] 14.79827 55.13110
>  [78,] 14.79044 55.13075
>  [79,] 14.78262 55.13041
>  [80,] 14.77479 55.13005
>  [81,] 14.77538 55.12557
>  [82,] 14.76756 55.12522
>  [83,] 14.76696 55.12970
>  [84,] 14.75913 55.12935
>  [85,] 14.75130 55.12900
>  [86,] 14.74348 55.12865
>  [87,] 14.73565 55.12830
>  [88,] 14.73505 55.13277
>  [89,] 14.72722 55.13242
>  [90,] 14.72662 55.13690
>  [91,] 14.72602 55.14138
>  [92,] 14.71819 55.14103
>  [93,] 14.71758 55.14551
>  [94,] 14.70975 55.14516
>  [95,] 14.70351 55.14487
>  [96,] 14.70161 55.14808
>  [97,] 14.70150 55.14925
>  [98,] 14.70396 55.16602
>  [99,] 14.70121 55.17632
> [100,] 14.70552 55.17652
> [101,] 14.70491 55.18100
> [102,] 14.70003 55.18077
> [103,] 14.69929 55.18353
> [104,] 14.70236 55.18701
> [105,] 14.69951 55.19428
> [106,] 14.70310 55.19444
> [107,] 14.70249 55.19892
> [108,] 14.70225 55.20072
> [109,] 14.70455 55.20477
> [110,] 14.70318 55.21014
> [111,] 14.70527 55.21257
> [112,] 14.70851 55.21272
> [113,] 14.70809 55.21585
> [114,] 14.70936 55.21733
> [115,] 14.70820 55.22176
> [116,] 14.71488 55.22731
> [117,] 14.71952 55.23575
> [118,] 14.72118 55.23582
> [119,] 14.72101 55.23705
> [120,] 14.73076 55.24552
> [121,] 14.73948 55.25308
> [122,] 14.74079 55.25474
> [123,] 14.74232 55.25481
> [124,] 14.74210 55.25639
> [125,] 14.74450 55.25941
>
>
>
> Slot "plotOrder":
> [1] 1
>
> Slot "labpt":
> [1] 14.78569 55.18178
>
> Slot "ID":
> [1] "78"
>
> Slot "area":
> [1] 0.01632464
>
>
> [[3]]
> An object of class "Polygons"
> Slot "Polygons":
> [[1]]
> An object of class "Polygon"
> Slot "labpt":
> [1] 15.07812 55.06290
>
> Slot "area":
> [1] 0.01516297
>
> Slot "hole":
> [1] FALSE
>
> Slot "ringDir":
> [1] 1
>
> Slot "coords":
>            [,1]     [,2]
>   [1,] 15.10328 55.14748
>   [2,] 15.11661 55.14492
>   [3,] 15.12046 55.14214
>   [4,] 15.14019 55.14267
>   [5,] 15.14262 55.13884
>   [6,] 15.14372 55.13885
>   [7,] 15.14395 55.13698
>   [8,] 15.14862 55.13717
>   [9,] 15.14859 55.13269
>  [10,] 15.15228 55.13227
>  [11,] 15.15289 55.12834
>  [12,] 15.15345 55.12386
>  [13,] 15.14562 55.12353
>  [14,] 15.14617 55.11905
>  [15,] 15.14673 55.11456
>  [16,] 15.14531 55.11247
>  [17,] 15.14700 55.10990
>  [18,] 15.14783 55.10560
>  [19,] 15.14816 55.10296
>  [20,] 15.14824 55.10228
>  [21,] 15.14860 55.10119
>  [22,] 15.14878 55.09883
>  [23,] 15.14894 55.09663
>  [24,] 15.15135 55.09673
>  [25,] 15.15702 55.09211
>  [26,] 15.15731 55.09067
>  [27,] 15.15512 55.08769
>  [28,] 15.15869 55.08134
>  [29,] 15.15641 55.07892
>  [30,] 15.15115 55.07870
>  [31,] 15.15160 55.07509
>  [32,] 15.15010 55.07415
>  [33,] 15.14389 55.07389
>  [34,] 15.14430 55.07052
>  [35,] 15.14239 55.06932
>  [36,] 15.13662 55.06908
>  [37,] 15.13720 55.06625
>  [38,] 15.13755 55.06459
>  [39,] 15.12936 55.06428
>  [40,] 15.12991 55.05979
>  [41,] 15.13042 55.05565
>  [42,] 15.12265 55.05499
>  [43,] 15.12321 55.05050
>  [44,] 15.11539 55.05017
>  [45,] 15.11595 55.04569
>  [46,] 15.11650 55.04121
>  [47,] 15.10869 55.04088
>  [48,] 15.10957 55.03604
>  [49,] 15.11614 55.02894
>  [50,] 15.11816 55.02788
>  [51,] 15.11873 55.02328
>  [52,] 15.11893 55.02163
>  [53,] 15.11708 55.01969
>  [54,] 15.11950 55.01705
>  [55,] 15.11992 55.01417
>  [56,] 15.11203 55.01398
>  [57,] 15.11257 55.00961
>  [58,] 15.10478 55.00917
>  [59,] 15.10528 55.00509
>  [60,] 15.09753 55.00436
>  [61,] 15.09805 55.00013
>  [62,] 15.09028 54.99955
>  [63,] 15.09084 54.99507
>  [64,] 15.08304 54.99474
>  [65,] 15.08360 54.99025
>  [66,] 15.07579 54.98993
>  [67,] 15.06799 54.98959
>  [68,] 15.06019 54.98926
>  [69,] 15.05239 54.98893
>  [70,] 15.05182 54.99342
>  [71,] 15.04402 54.99308
>  [72,] 15.03622 54.99275
>  [73,] 15.03565 54.99723
>  [74,] 15.02785 54.99690
>  [75,] 15.02005 54.99657
>  [76,] 15.01948 55.00105
>  [77,] 15.01167 55.00071
>  [78,] 15.00387 55.00038
>  [79,] 14.99607 55.00004
>  [80,] 14.99550 55.00452
>  [81,] 14.99493 55.00901
>  [82,] 14.99436 55.01349
>  [83,] 14.99379 55.01797
>  [84,] 14.99322 55.02245
>  [85,] 15.00103 55.02279
>  [86,] 15.00046 55.02727
>  [87,] 15.00827 55.02761
>  [88,] 15.00770 55.03209
>  [89,] 15.01551 55.03243
>  [90,] 15.01495 55.03691
>  [91,] 15.01438 55.04139
>  [92,] 15.01381 55.04587
>  [93,] 15.00600 55.04554
>  [94,] 15.00543 55.05002
>  [95,] 15.01324 55.05035
>  [96,] 15.01267 55.05484
>  [97,] 15.01211 55.05932
>  [98,] 15.01154 55.06380
>  [99,] 15.01935 55.06413
> [100,] 15.01879 55.06862
> [101,] 15.01822 55.07310
> [102,] 15.01765 55.07758
> [103,] 15.02547 55.07792
> [104,] 15.02490 55.08240
> [105,] 15.02434 55.08688
> [106,] 15.02377 55.09136
> [107,] 15.01595 55.09103
> [108,] 15.01538 55.09551
> [109,] 15.01481 55.09999
> [110,] 15.02263 55.10033
> [111,] 15.03046 55.10066
> [112,] 15.03828 55.10099
> [113,] 15.04611 55.10133
> [114,] 15.05393 55.10166
> [115,] 15.06176 55.10199
> [116,] 15.06958 55.10232
> [117,] 15.06902 55.10680
> [118,] 15.07684 55.10713
> [119,] 15.07628 55.11161
> [120,] 15.07572 55.11610
> [121,] 15.08355 55.11643
> [122,] 15.08299 55.12091
> [123,] 15.08242 55.12539
> [124,] 15.09025 55.12572
> [125,] 15.08969 55.13020
> [126,] 15.08913 55.13469
> [127,] 15.09696 55.13501
> [128,] 15.09640 55.13950
> [129,] 15.09584 55.14398
> [130,] 15.10368 55.14431
> [131,] 15.10328 55.14748
>
>
>
> Slot "plotOrder":
> [1] 1
>
> Slot "labpt":
> [1] 15.07812 55.06290
>
> Slot "ID":
> [1] "139"
>
> Slot "area":
> [1] 0.01516297
>
>
> [[4]]
> An object of class "Polygons"
> Slot "Polygons":
> [[1]]
> An object of class "Polygon"
> Slot "labpt":
> [1] 14.73583 55.10616
>
> Slot "area":
> [1] 0.004280022
>
> Slot "hole":
> [1] FALSE
>
> Slot "ringDir":
> [1] 1
>
> Slot "coords":
>           [,1]     [,2]
>  [1,] 14.73563 55.06969
>  [2,] 14.73503 55.07418
>  [3,] 14.72813 55.07386
>  [4,] 14.72706 55.07502
>  [5,] 14.72662 55.07830
>  [6,] 14.72602 55.08278
>  [7,] 14.71820 55.08243
>  [8,] 14.71038 55.08207
>  [9,] 14.70978 55.08656
> [10,] 14.70196 55.08620
> [11,] 14.70135 55.09068
> [12,] 14.69338 55.09008
> [13,] 14.69308 55.09368
> [14,] 14.69630 55.09442
> [15,] 14.69563 55.09721
> [16,] 14.69024 55.09824
> [17,] 14.68483 55.09653
> [18,] 14.68445 55.09930
> [19,] 14.68746 55.10255
> [20,] 14.69439 55.10326
> [21,] 14.69785 55.10672
> [22,] 14.70006 55.11415
> [23,] 14.69727 55.12097
> [24,] 14.70293 55.12499
> [25,] 14.70315 55.12683
> [26,] 14.70434 55.12688
> [27,] 14.70372 55.13150
> [28,] 14.70503 55.14230
> [29,] 14.70351 55.14487
> [30,] 14.70975 55.14516
> [31,] 14.71758 55.14551
> [32,] 14.71819 55.14103
> [33,] 14.72602 55.14138
> [34,] 14.72662 55.13690
> [35,] 14.72722 55.13242
> [36,] 14.73505 55.13277
> [37,] 14.73565 55.12830
> [38,] 14.74348 55.12865
> [39,] 14.75130 55.12900
> [40,] 14.75913 55.12935
> [41,] 14.76696 55.12970
> [42,] 14.76756 55.12522
> [43,] 14.76816 55.12074
> [44,] 14.77598 55.12109
> [45,] 14.77658 55.11661
> [46,] 14.77717 55.11213
> [47,] 14.77777 55.10765
> [48,] 14.78559 55.10800
> [49,] 14.78619 55.10352
> [50,] 14.78678 55.09904
> [51,] 14.78738 55.09456
> [52,] 14.77956 55.09421
> [53,] 14.78015 55.08973
> [54,] 14.77233 55.08937
> [55,] 14.76451 55.08902
> [56,] 14.75669 55.08867
> [57,] 14.75729 55.08419
> [58,] 14.75789 55.07971
> [59,] 14.75848 55.07523
> [60,] 14.75067 55.07488
> [61,] 14.75127 55.07040
> [62,] 14.74345 55.07005
> [63,] 14.73563 55.06969
>
>
>
> Slot "plotOrder":
> [1] 1
>
> Slot "labpt":
> [1] 14.73583 55.10616
>
> Slot "ID":
> [1] "173"
>
> Slot "area":
> [1] 0.004280022
>
>
> [[5]]
> An object of class "Polygons"
> Slot "Polygons":
> [[1]]
> An object of class "Polygon"
> Slot "labpt":
> [1] 14.89665 55.08017
>
> Slot "area":
> [1] 0.02517117
>
> Slot "hole":
> [1] FALSE
>
> Slot "ringDir":
> [1] 1
>
> Slot "coords":
>            [,1]     [,2]
>   [1,] 14.99550 55.00452
>   [2,] 14.98769 55.00419
>   [3,] 14.97989 55.00385
>   [4,] 14.97208 55.00352
>   [5,] 14.97151 55.00800
>   [6,] 14.96371 55.00766
>   [7,] 14.95590 55.00732
>   [8,] 14.95068 55.00710
>   [9,] 14.94791 55.00845
>  [10,] 14.94752 55.01147
>  [11,] 14.94222 55.01124
>  [12,] 14.93953 55.01255
>  [13,] 14.93914 55.01561
>  [14,] 14.93133 55.01527
>  [15,] 14.92353 55.01493
>  [16,] 14.92295 55.01941
>  [17,] 14.91555 55.01909
>  [18,] 14.91435 55.01989
>  [19,] 14.90696 55.02165
>  [20,] 14.90676 55.02321
>  [21,] 14.90142 55.02298
>  [22,] 14.89988 55.02291
>  [23,] 14.89881 55.02392
>  [24,] 14.89837 55.02735
>  [25,] 14.89292 55.02711
>  [26,] 14.89037 55.02849
>  [27,] 14.88998 55.03149
>  [28,] 14.88216 55.03126
>  [29,] 14.88159 55.03563
>  [30,] 14.87378 55.03529
>  [31,] 14.87319 55.03977
>  [32,] 14.86538 55.03943
>  [33,] 14.85757 55.03908
>  [34,] 14.85699 55.04356
>  [35,] 14.84917 55.04322
>  [36,] 14.84136 55.04287
>  [37,] 14.83355 55.04252
>  [38,] 14.82574 55.04218
>  [39,] 14.82515 55.04666
>  [40,] 14.81734 55.04631
>  [41,] 14.81675 55.05079
>  [42,] 14.80894 55.05045
>  [43,] 14.80408 55.05023
>  [44,] 14.80223 55.05097
>  [45,] 14.80098 55.05120
>  [46,] 14.80053 55.05458
>  [47,] 14.79272 55.05423
>  [48,] 14.78491 55.05388
>  [49,] 14.77709 55.05353
>  [50,] 14.77650 55.05801
>  [51,] 14.76869 55.05766
>  [52,] 14.76080 55.05784
>  [53,] 14.76028 55.06179
>  [54,] 14.75246 55.06144
>  [55,] 14.75186 55.06592
>  [56,] 14.74405 55.06557
>  [57,] 14.73813 55.06530
>  [58,] 14.73604 55.06666
>  [59,] 14.73563 55.06969
>  [60,] 14.74345 55.07005
>  [61,] 14.75127 55.07040
>  [62,] 14.75067 55.07488
>  [63,] 14.75848 55.07523
>  [64,] 14.75789 55.07971
>  [65,] 14.75729 55.08419
>  [66,] 14.75669 55.08867
>  [67,] 14.76451 55.08902
>  [68,] 14.77233 55.08937
>  [69,] 14.78015 55.08973
>  [70,] 14.77956 55.09421
>  [71,] 14.78738 55.09456
>  [72,] 14.78678 55.09904
>  [73,] 14.78619 55.10352
>  [74,] 14.78559 55.10800
>  [75,] 14.77777 55.10765
>  [76,] 14.77717 55.11213
>  [77,] 14.77658 55.11661
>  [78,] 14.77598 55.12109
>  [79,] 14.76816 55.12074
>  [80,] 14.76756 55.12522
>  [81,] 14.77538 55.12557
>  [82,] 14.77479 55.13005
>  [83,] 14.78262 55.13041
>  [84,] 14.79044 55.13075
>  [85,] 14.79827 55.13110
>  [86,] 14.80610 55.13145
>  [87,] 14.80551 55.13593
>  [88,] 14.81334 55.13628
>  [89,] 14.81275 55.14076
>  [90,] 14.82057 55.14111
>  [91,] 14.82841 55.14146
>  [92,] 14.82782 55.14594
>  [93,] 14.83565 55.14628
>  [94,] 14.83624 55.14180
>  [95,] 14.84407 55.14215
>  [96,] 14.85190 55.14249
>  [97,] 14.85973 55.14284
>  [98,] 14.86756 55.14318
>  [99,] 14.87539 55.14353
> [100,] 14.88322 55.14387
> [101,] 14.88381 55.13939
> [102,] 14.88439 55.13491
> [103,] 14.88498 55.13043
> [104,] 14.89281 55.13077
> [105,] 14.89222 55.13525
> [106,] 14.90005 55.13559
> [107,] 14.89947 55.14008
> [108,] 14.89889 55.14456
> [109,] 14.90672 55.14490
> [110,] 14.91455 55.14524
> [111,] 14.91513 55.14076
> [112,] 14.92296 55.14110
> [113,] 14.93079 55.14144
> [114,] 14.93137 55.13696
> [115,] 14.93920 55.13730
> [116,] 14.94703 55.13764
> [117,] 14.94761 55.13316
> [118,] 14.95544 55.13349
> [119,] 14.96327 55.13383
> [120,] 14.96385 55.12935
> [121,] 14.97168 55.12969
> [122,] 14.97225 55.12521
> [123,] 14.97282 55.12072
> [124,] 14.97340 55.11624
> [125,] 14.97397 55.11176
> [126,] 14.97455 55.10728
> [127,] 14.98237 55.10761
> [128,] 14.98294 55.10313
> [129,] 14.99077 55.10347
> [130,] 14.99859 55.10381
> [131,] 14.99916 55.09932
> [132,] 15.00699 55.09966
> [133,] 15.01481 55.09999
> [134,] 15.01538 55.09551
> [135,] 15.01595 55.09103
> [136,] 15.02377 55.09136
> [137,] 15.02434 55.08688
> [138,] 15.02490 55.08240
> [139,] 15.02547 55.07792
> [140,] 15.01765 55.07758
> [141,] 15.01822 55.07310
> [142,] 15.01879 55.06862
> [143,] 15.01935 55.06413
> [144,] 15.01154 55.06380
> [145,] 15.01211 55.05932
> [146,] 15.01267 55.05484
> [147,] 15.01324 55.05035
> [148,] 15.00543 55.05002
> [149,] 15.00600 55.04554
> [150,] 15.01381 55.04587
> [151,] 15.01438 55.04139
> [152,] 15.01495 55.03691
> [153,] 15.01551 55.03243
> [154,] 15.00770 55.03209
> [155,] 15.00827 55.02761
> [156,] 15.00046 55.02727
> [157,] 15.00103 55.02279
> [158,] 14.99322 55.02245
> [159,] 14.99379 55.01797
> [160,] 14.99436 55.01349
> [161,] 14.99493 55.00901
> [162,] 14.99550 55.00452
>
>
>
> Slot "plotOrder":
> [1] 1
>
> Slot "labpt":
> [1] 14.89665 55.08017
>
> Slot "ID":
> [1] "2"
>
> Slot "area":
> [1] 0.02517117
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul


From pshayes at maine.rr.com  Sat Feb 14 04:09:38 2009
From: pshayes at maine.rr.com (Peter S. Hayes)
Date: Fri, 13 Feb 2009 22:09:38 -0500
Subject: [R-sig-Geo] SpatialPolygons decomposition...
Message-ID: <499635F2.5020905@maine.rr.com>

Hi All,

I'm trying to teach a spatial analysis class using R as a means of 
learning some details... I'm not an expert in R myself, but am learning 
it while using it as a 'tool' for lessons in the class...

In getting the students familiar with some of the SP classes, we began 
looking at the class components and manipulating some of the components 
(such as translating by modifying coordinates..).

Is there a means of decomposing SpatialPolygons to access the list of 
Polygons and contained classes? The help files (for example, polygons()) 
appear to hint so, but not function so... the SpatialPolygons isn't 
quite a traditional R dataframe and won't flatten with a call to 
as.data.frame() to allow access to the individual slots... but there 
must be a means of doing that...

Also, I have "Applied Spatial Data Analysis with R" as one of the 
texts... any thoughts for more references... especially for 
non-programmers: I've some software experience (C/C++...) but most of 
the students are environmental study, environmental science, or biology 
students and this is one of their first experiences with anything having 
a command line. We've been taking things slow, but R is still a bit 
cryptic... any thoughts on that would be appreciated!

Thank you for all!


Pete


From j.burke at earthlink.net  Sat Feb 14 04:22:52 2009
From: j.burke at earthlink.net (Jim Burke)
Date: Fri, 13 Feb 2009 21:22:52 -0600
Subject: [R-sig-Geo] SpatialPolygons decomposition...
In-Reply-To: <499635F2.5020905@maine.rr.com>
References: <499635F2.5020905@maine.rr.com>
Message-ID: <4996390C.3030401@earthlink.net>

Hi Peter,

I think I am three days ahead of you on the learning curve. So come join 
me! Below is a cumulation of suggestions from Rodger Bivand.

Perhaps the code below may help. Start out with your own SpatialPolygon. 
Change it to a dataframe. Then do something data like to the dataframe. 
Then coerce back to a SpatialPolygon dataframe. Then dump the 
SpatialPolygon in various ways. Or you could simply dump the 
SpatialPolygon. 

# the following code takes an sp to a df to add the two columns
# then the df is coerced back into an sp. This solves a merge
# issue when merging an sp and df together. R thinks the result
# should be a data.frame so good bye SpatialPolygons   

    tx2_df <- as(tx2_sp, "data.frame")   #make a sp into a df

    tx2_df1      <- merge(tx2_df, votes2_df, sort=FALSE, by.x="PCT",
    by.y="PCT", all.x=TRUE, all.y=TRUE)
    remove(tx2_df)
    remove(votes2_df) 

    # notice that the data frame row IDs we print are sequential
    # 1,2,3,4... and not proper precinct names like 1234....
    rownames(as(tx2_df1, "data.frame"))  #show us the row IDs

    # key here is match.ID = FALSE so that it does not try to take
    # the 1,2,3 data frame sequence numbers and think they are IDs. 
    # both sp and df must have rows aligned the same.
    tx3_sp <- SpatialPolygonsDataFrame(as(tx2_sp,"SpatialPolygons"),
              data=tx2_df1, match.ID = FALSE)
    remove(tx2_sp)
    remove(tx2_df1)

    # debug tx3_sp a little, lets make sure its a SpatialPologonsDataFrame!
    sapply(slot(tx3_sp, "polygons"), function(x) slot(x, "ID")) #what 
are row "ID"s?
    str(as(tx3_sp, "data.frame"))         #show representation of variables
    (str(tx3_sp))                         #shows representation of 
geometries too.
    names(tx3_sp)                         #nice but lengthy  

Let us know if this helps you any.

Good luck,
Jim Burke



Peter S. Hayes wrote:
> Hi All,
>
> I'm trying to teach a spatial analysis class using R as a means of 
> learning some details... I'm not an expert in R myself, but am 
> learning it while using it as a 'tool' for lessons in the class...
>
> In getting the students familiar with some of the SP classes, we began 
> looking at the class components and manipulating some of the 
> components (such as translating by modifying coordinates..).
>
> Is there a means of decomposing SpatialPolygons to access the list of 
> Polygons and contained classes? The help files (for example, 
> polygons()) appear to hint so, but not function so... the 
> SpatialPolygons isn't quite a traditional R dataframe and won't 
> flatten with a call to as.data.frame() to allow access to the 
> individual slots... but there must be a means of doing that...
>
> Also, I have "Applied Spatial Data Analysis with R" as one of the 
> texts... any thoughts for more references... especially for 
> non-programmers: I've some software experience (C/C++...) but most of 
> the students are environmental study, environmental science, or 
> biology students and this is one of their first experiences with 
> anything having a command line. We've been taking things slow, but R 
> is still a bit cryptic... any thoughts on that would be appreciated!
>
> Thank you for all!
>
>
> Pete
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From Roger.Bivand at nhh.no  Sat Feb 14 10:58:37 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 14 Feb 2009 10:58:37 +0100 (CET)
Subject: [R-sig-Geo] SpatialPolygons decomposition...
In-Reply-To: <499635F2.5020905@maine.rr.com>
References: <499635F2.5020905@maine.rr.com>
Message-ID: <alpine.LRH.2.00.0902141050500.14436@reclus.nhh.no>

On Fri, 13 Feb 2009, Peter S. Hayes wrote:

> Hi All,
>
> I'm trying to teach a spatial analysis class using R as a means of learning 
> some details... I'm not an expert in R myself, but am learning it while using 
> it as a 'tool' for lessons in the class...
>
> In getting the students familiar with some of the SP classes, we began 
> looking at the class components and manipulating some of the components (such 
> as translating by modifying coordinates..).
>
> Is there a means of decomposing SpatialPolygons to access the list of 
> Polygons and contained classes? The help files (for example, polygons()) 
> appear to hint so, but not function so... the SpatialPolygons isn't quite a 
> traditional R dataframe and won't flatten with a call to as.data.frame() to 
> allow access to the individual slots... but there must be a means of doing 
> that...

Perhaps look at the code in the elide methods in maptools - they all 
access and manipulate the coordinate values in Spatial* objects. Usually 
it is a matter of using lapply() on slots containing lists (the stacked-up 
objects in Fig. 2.4, p. 40 in our book). lapply() lets you apply a 
function to each member of a list - so one just steps inwards until one 
gets to the slot with the coordinates in - updating the bbox slot on the 
way out. spTransform methods in rgdal do this too. If you flatten the 
representation, you'd get even worse spaghetti that the present 
representation, which isn't ideal anyway.

>
> Also, I have "Applied Spatial Data Analysis with R" as one of the texts... 
> any thoughts for more references... especially for non-programmers: I've some 
> software experience (C/C++...) but most of the students are environmental 
> study, environmental science, or biology students and this is one of their 
> first experiences with anything having a command line. We've been taking 
> things slow, but R is still a bit cryptic... any thoughts on that would be 
> appreciated!

You could try Braun & Murdoch: A First Course in Statistical Programming 
with R. Cambridge University Press, Cambridge, 2007, or others on:

http://www.r-project.org/doc/bib/R-books.html

Hope this helps,

Roger

>
> Thank you for all!
>
>
> Pete
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Sat Feb 14 11:06:02 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 14 Feb 2009 11:06:02 +0100 (CET)
Subject: [R-sig-Geo] SpatialPolygons decomposition...
In-Reply-To: <4996390C.3030401@earthlink.net>
References: <499635F2.5020905@maine.rr.com> <4996390C.3030401@earthlink.net>
Message-ID: <alpine.LRH.2.00.0902141058540.14436@reclus.nhh.no>

On Fri, 13 Feb 2009, Jim Burke wrote:

> Hi Peter,
>
> I think I am three days ahead of you on the learning curve. So come join me! 
> Below is a cumulation of suggestions from Rodger Bivand.
>
> Perhaps the code below may help. Start out with your own SpatialPolygon. 
> Change it to a dataframe. Then do something data like to the dataframe. Then 
> coerce back to a SpatialPolygon dataframe. Then dump the SpatialPolygon in 
> various ways. Or you could simply dump the SpatialPolygon. 
> # the following code takes an sp to a df to add the two columns
> # then the df is coerced back into an sp. This solves a merge
> # issue when merging an sp and df together. R thinks the result
> # should be a data.frame so good bye SpatialPolygons
>   tx2_df <- as(tx2_sp, "data.frame")   #make a sp into a df
>
>   tx2_df1      <- merge(tx2_df, votes2_df, sort=FALSE, by.x="PCT",
>   by.y="PCT", all.x=TRUE, all.y=TRUE)
>   remove(tx2_df)
>   remove(votes2_df)
>   # notice that the data frame row IDs we print are sequential
>   # 1,2,3,4... and not proper precinct names like 1234....
>   rownames(as(tx2_df1, "data.frame"))  #show us the row IDs

Have you looked at spRbind and spChFIDs methods in maptools? I would be 
worried about ignoring the IDs unless you are very confident that the 
order of the geometric objects and the rows in the data frame are 
identical. Since Peter mentioned our book, there is an extensive example 
on pp. 120-126; the code and data are available in the Chapter 5 set on 
www.asdar-book.org, but without the explanations of the steps involved.

Roger

>
>   # key here is match.ID = FALSE so that it does not try to take
>   # the 1,2,3 data frame sequence numbers and think they are IDs.    # both 
> sp and df must have rows aligned the same.
>   tx3_sp <- SpatialPolygonsDataFrame(as(tx2_sp,"SpatialPolygons"),
>             data=tx2_df1, match.ID = FALSE)
>   remove(tx2_sp)
>   remove(tx2_df1)
>
>   # debug tx3_sp a little, lets make sure its a SpatialPologonsDataFrame!
>   sapply(slot(tx3_sp, "polygons"), function(x) slot(x, "ID")) #what are row 
> "ID"s?
>   str(as(tx3_sp, "data.frame"))         #show representation of variables
>   (str(tx3_sp))                         #shows representation of geometries 
> too.
>   names(tx3_sp)                         #nice but lengthy 
> Let us know if this helps you any.
>
> Good luck,
> Jim Burke
>
>
>
> Peter S. Hayes wrote:
>> Hi All,
>> 
>> I'm trying to teach a spatial analysis class using R as a means of learning 
>> some details... I'm not an expert in R myself, but am learning it while 
>> using it as a 'tool' for lessons in the class...
>> 
>> In getting the students familiar with some of the SP classes, we began 
>> looking at the class components and manipulating some of the components 
>> (such as translating by modifying coordinates..).
>> 
>> Is there a means of decomposing SpatialPolygons to access the list of 
>> Polygons and contained classes? The help files (for example, polygons()) 
>> appear to hint so, but not function so... the SpatialPolygons isn't quite a 
>> traditional R dataframe and won't flatten with a call to as.data.frame() to 
>> allow access to the individual slots... but there must be a means of doing 
>> that...
>> 
>> Also, I have "Applied Spatial Data Analysis with R" as one of the texts... 
>> any thoughts for more references... especially for non-programmers: I've 
>> some software experience (C/C++...) but most of the students are 
>> environmental study, environmental science, or biology students and this is 
>> one of their first experiences with anything having a command line. We've 
>> been taking things slow, but R is still a bit cryptic... any thoughts on 
>> that would be appreciated!
>> 
>> Thank you for all!
>> 
>> 
>> Pete
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>> 
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From pshayes at maine.rr.com  Sat Feb 14 14:39:50 2009
From: pshayes at maine.rr.com (Peter S. Hayes)
Date: Sat, 14 Feb 2009 08:39:50 -0500
Subject: [R-sig-Geo] SpatialPolygons decomposition...
In-Reply-To: <alpine.LRH.2.00.0902141058540.14436@reclus.nhh.no>
References: <499635F2.5020905@maine.rr.com> <4996390C.3030401@earthlink.net>
	<alpine.LRH.2.00.0902141058540.14436@reclus.nhh.no>
Message-ID: <4996C9A6.60303@maine.rr.com>

Thank you, everyone!

Let me go walk through some of this, look at the help for some functions 
that I haven't yet looked at, and see what I can make of it all! :-)

I let myself become trapped in a lab class with this issue... found that 
the as.data.frame() worked fine on SpatialPoints, but ran into a problem 
when someone asked to decompose a polygon similarly (I should have 
looked before class, but ran out of time - too many commitments, not 
enough time!).

Thank you again!


Pete

Roger Bivand wrote:
> On Fri, 13 Feb 2009, Jim Burke wrote:
>
>> Hi Peter,
>>
>> I think I am three days ahead of you on the learning curve. So come 
>> join me! Below is a cumulation of suggestions from Rodger Bivand.
>>
>> Perhaps the code below may help. Start out with your own 
>> SpatialPolygon. Change it to a dataframe. Then do something data like 
>> to the dataframe. Then coerce back to a SpatialPolygon dataframe. 
>> Then dump the SpatialPolygon in various ways. Or you could simply 
>> dump the SpatialPolygon. # the following code takes an sp to a df to 
>> add the two columns
>> # then the df is coerced back into an sp. This solves a merge
>> # issue when merging an sp and df together. R thinks the result
>> # should be a data.frame so good bye SpatialPolygons
>>   tx2_df <- as(tx2_sp, "data.frame")   #make a sp into a df
>>
>>   tx2_df1      <- merge(tx2_df, votes2_df, sort=FALSE, by.x="PCT",
>>   by.y="PCT", all.x=TRUE, all.y=TRUE)
>>   remove(tx2_df)
>>   remove(votes2_df)
>>   # notice that the data frame row IDs we print are sequential
>>   # 1,2,3,4... and not proper precinct names like 1234....
>>   rownames(as(tx2_df1, "data.frame"))  #show us the row IDs
>
> Have you looked at spRbind and spChFIDs methods in maptools? I would 
> be worried about ignoring the IDs unless you are very confident that 
> the order of the geometric objects and the rows in the data frame are 
> identical. Since Peter mentioned our book, there is an extensive 
> example on pp. 120-126; the code and data are available in the Chapter 
> 5 set on www.asdar-book.org, but without the explanations of the steps 
> involved.
>
> Roger
>
>>
>>   # key here is match.ID = FALSE so that it does not try to take
>>   # the 1,2,3 data frame sequence numbers and think they are IDs.    
>> # both sp and df must have rows aligned the same.
>>   tx3_sp <- SpatialPolygonsDataFrame(as(tx2_sp,"SpatialPolygons"),
>>             data=tx2_df1, match.ID = FALSE)
>>   remove(tx2_sp)
>>   remove(tx2_df1)
>>
>>   # debug tx3_sp a little, lets make sure its a 
>> SpatialPologonsDataFrame!
>>   sapply(slot(tx3_sp, "polygons"), function(x) slot(x, "ID")) #what 
>> are row "ID"s?
>>   str(as(tx3_sp, "data.frame"))         #show representation of 
>> variables
>>   (str(tx3_sp))                         #shows representation of 
>> geometries too.
>>   names(tx3_sp)                         #nice but lengthy Let us know 
>> if this helps you any.
>>
>> Good luck,
>> Jim Burke
>>
>>
>>
>> Peter S. Hayes wrote:
>>> Hi All,
>>>
>>> I'm trying to teach a spatial analysis class using R as a means of 
>>> learning some details... I'm not an expert in R myself, but am 
>>> learning it while using it as a 'tool' for lessons in the class...
>>>
>>> In getting the students familiar with some of the SP classes, we 
>>> began looking at the class components and manipulating some of the 
>>> components (such as translating by modifying coordinates..).
>>>
>>> Is there a means of decomposing SpatialPolygons to access the list 
>>> of Polygons and contained classes? The help files (for example, 
>>> polygons()) appear to hint so, but not function so... the 
>>> SpatialPolygons isn't quite a traditional R dataframe and won't 
>>> flatten with a call to as.data.frame() to allow access to the 
>>> individual slots... but there must be a means of doing that...
>>>
>>> Also, I have "Applied Spatial Data Analysis with R" as one of the 
>>> texts... any thoughts for more references... especially for 
>>> non-programmers: I've some software experience (C/C++...) but most 
>>> of the students are environmental study, environmental science, or 
>>> biology students and this is one of their first experiences with 
>>> anything having a command line. We've been taking things slow, but R 
>>> is still a bit cryptic... any thoughts on that would be appreciated!
>>>
>>> Thank you for all!
>>>
>>>
>>> Pete
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From Mitze at gefra-muenster.de  Sat Feb 14 21:17:54 2009
From: Mitze at gefra-muenster.de (Timo Mitze)
Date: Sat, 14 Feb 2009 21:17:54 +0100
Subject: [R-sig-Geo] SpatialFiltering in spdep: How to create an 'nb' object
	from an imported spatial weights matrix
Message-ID: <1ADF70DB48DC0A44869DCBE27D4627F1176D20@TATOOINE.gefra-muenster.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090214/341b0bd0/attachment.pl>

From greenberg at ucdavis.edu  Sat Feb 14 21:29:42 2009
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Sat, 14 Feb 2009 12:29:42 -0800
Subject: [R-sig-Geo] Vector to raster?
Message-ID: <499729B6.8060302@ucdavis.edu>

How do I take a polygon in some OGR supported vector layer (say, a 
shapefile), and rasterize it given a pixel size and projection/datum?

--j

-- 

Jonathan A. Greenberg, PhD
Postdoctoral Scholar
Center for Spatial Technologies and Remote Sensing (CSTARS)
University of California, Davis
One Shields Avenue
The Barn, Room 250N
Davis, CA 95616
Cell: 415-794-5043
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307


From p.hiemstra at geo.uu.nl  Sat Feb 14 22:07:10 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Sat, 14 Feb 2009 22:07:10 +0100
Subject: [R-sig-Geo] Vector to raster?
In-Reply-To: <499729B6.8060302@ucdavis.edu>
References: <499729B6.8060302@ucdavis.edu>
Message-ID: <4997327E.1040401@geo.uu.nl>

Jonathan Greenberg schreef:
> How do I take a polygon in some OGR supported vector layer (say, a 
> shapefile), and rasterize it given a pixel size and projection/datum?
>
> --j
>
Take a look at the spsample() function.

Paul

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:     +31302535773
Fax:    +31302531145
http://intamap.geo.uu.nl/~paul


From T.Hengl at uva.nl  Sat Feb 14 23:11:24 2009
From: T.Hengl at uva.nl (Hengl, T.)
Date: Sat, 14 Feb 2009 23:11:24 +0100
Subject: [R-sig-Geo] Vector to raster?
References: <499729B6.8060302@ucdavis.edu> <4997327E.1040401@geo.uu.nl>
Message-ID: <37382E8DCB905042969BA78541F6570624D6B9@kwek.ic.uva.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090214/e4cb44f8/attachment.pl>

From greenberg at ucdavis.edu  Sun Feb 15 00:50:52 2009
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Sat, 14 Feb 2009 15:50:52 -0800
Subject: [R-sig-Geo] Vector to raster?
In-Reply-To: <37382E8DCB905042969BA78541F6570624D6B9@kwek.ic.uva.nl>
References: <499729B6.8060302@ucdavis.edu> <4997327E.1040401@geo.uu.nl>
	<37382E8DCB905042969BA78541F6570624D6B9@kwek.ic.uva.nl>
Message-ID: <499758DC.30509@ucdavis.edu>

Thanks -- another few questions along these lines:

1) Is there any way to determine the type of vector file in advance of 
defining a layer name?  How can I list layer names affiliated with a 
given vector (it seems to be part of ogrinfo from the main gdal release, 
but when i do a ogrinfo(filename) I get yelled at to feed it a layer 
name first).
2) Is there a way to tell the feature type (point, polygon, line, 
etc...) of a readOGR object?
3) How do I get a polygon/line's node coordinates?  Using 
coordinate(readOGR(...)) I only get a single coordinates associated with 
each polygon/line in the vector.

Thanks!

--j 

Hengl, T. wrote:
>
> If you work with large shapes/grids, try also SAGA:
>
> > rsaga.get.usage(lib="grid_gridding", 3)
> SAGA CMD 2.0.3
> library path:   C:/Progra~1/saga_vc/modules
> library name:   grid_gridding
> module name :   Shapes to Grid
> ...
>
> But before SAGA, you need to reproject the polygons first (if necessary).
>
> see also some examples from:
> http://spatial-analyst.net/wiki/index.php?title=Export_maps_to_GE#Polygon_maps
>
> HTH
>
> Tom Hengl
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Paul Hiemstra
> Sent: Sat 2/14/2009 10:07 PM
> To: Jonathan Greenberg
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] Vector to raster?
>
> Jonathan Greenberg schreef:
> > How do I take a polygon in some OGR supported vector layer (say, a
> > shapefile), and rasterize it given a pixel size and projection/datum?
> >
> > --j
> >
> Take a look at the spsample() function.
>
> Paul
>
> --
> Drs. Paul Hiemstra
> Department of Physical Geography
> Faculty of Geosciences
> University of Utrecht
> Heidelberglaan 2
> P.O. Box 80.115
> 3508 TC Utrecht
> Phone:     +31302535773
> Fax:    +31302531145
> http://intamap.geo.uu.nl/~paul <http://intamap.geo.uu.nl/%7Epaul>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 

Jonathan A. Greenberg, PhD
Postdoctoral Scholar
Center for Spatial Technologies and Remote Sensing (CSTARS)
University of California, Davis
One Shields Avenue
The Barn, Room 250N
Davis, CA 95616
Cell: 415-794-5043
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307


From valerio.bartolino at uniroma1.it  Sun Feb 15 10:51:56 2009
From: valerio.bartolino at uniroma1.it (Valerio Bartolino)
Date: Sun, 15 Feb 2009 01:51:56 -0800
Subject: [R-sig-Geo] localmoran p-values with/without permutation
Message-ID: <1234691516.6004.69.camel@valerio>

Dear list,
I've the objective to identify hotspot areas from a model prediction
over a high resolution grid. After calculating a spatial weight object I
easily applied the localmoran function from the spdep library. It's not
really clear to me the meaning of the p-values associated to the
localmoran function and how much I can rely on them in terms of
statistical significance. For instance can I use these p-values instead
using a randomization approach? I would be glad for any clarification.

Moreover, I want to calculate a statistical significance also through a
randomization approach (commonly used with Moran's I statistic). The
idea behind the randomization is rather simple, and also coding doesn't
seem too difficult, but the identified hotspots appear larger and
disaggregated respect those identified looking at the p-values provided
by the localmoran function at a similar significant level.

Did I do some mistake in the following code I wrote for the permutation?
Thanks for any advice, explanation or comment you will have

Valerio Bartolino

###########################################
require(spdep)

locMoranI.perm <- function(x, R, listw, ...){

# x is a vector of the values on which to calculate the MoranI statistic
# R, listw, ... are all the arguments passed to the localmoran function

	mat <- matrix(data=NA, nrow=R, ncol=length(x))
		for(i in 1:R){
		perm <- sample(x, replace=F)
		I.locmor <- localmoran(perm, listw, ...)
		mat[i,] <- I.locmor[,1]
		rm(I.locmor)
		rm(perm)
		}

	return(mat)
}

# I used this new function as follow:
nsim <- 1000
I.perm <- locMoranI.perm(z, R=nsim, listw=nbw)

MorI <- localmoran(z, listw=nbw)

# select for instance a 0.01 pseudo-significance level
p.perm <- apply(I.perm, 2, quantile, probs=0.99)

## because I-Moran identify spatial clustering
## high and low hotspots have no distinct I values
## make a vector to distinguish significant and high hotspots
hot <- ifelse(p.perm-MorI[,1]<0 & z>mean(z),1,0)


From Roger.Bivand at nhh.no  Sun Feb 15 12:59:51 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 15 Feb 2009 12:59:51 +0100 (CET)
Subject: [R-sig-Geo] SpatialFiltering in spdep: How to create an 'nb'
 object from an imported spatial weights matrix
In-Reply-To: <1ADF70DB48DC0A44869DCBE27D4627F1176D20@TATOOINE.gefra-muenster.de>
References: <1ADF70DB48DC0A44869DCBE27D4627F1176D20@TATOOINE.gefra-muenster.de>
Message-ID: <alpine.LRH.2.00.0902151248160.26830@reclus.nhh.no>

On Sat, 14 Feb 2009, Timo Mitze wrote:

> Dear List,
>
> I have a complete (distance/border based binary) spatial weights matrix
> from Stata (e.g. as a txt-file).

Try using read.dta() in foreign of the exported Stata matrix. This reads a 
data.frame, which you coerce to an R matrix with as.matrix().

> I want to apply spatial filtering in
> spdep, however the routine needs an "nb" object. Is there any way to
> extract the information from my matrix automatically (something like
> mat2nb ???) or do I have to edit the "nb" object by hand? (e.g. in terms
> of creating a GAL file by any text editor and then use "read.gal" option
> - this strategy would mean a lot of work since I have a 240 x 240
> matrix). I'd be happy about any help.

Next use mat2listw() in spdep to convert to a listw object, finally using:

x <- mat2listw(mat)
lw <- nb2listw(x$neighbours, glist=x$weights, style="?")

where ? is your choice of style. mat2listw() just does the convsersion, 
assigning a style of "M", which may not be recognised by model fitting 
functions. Drop the glist= argument if the weights are without importance 
- as I understand they are from your description of them as binary.

Hope this helps,

Roger

>
> Best wishes,
>
> Timo
>
> P.S.: I have tried it with a spatial weights matrix in spdep
> (mat2listw), but it does not work - see my code below:
>
> ****************************************************
>
> #### Code for Griffith Eigenvector Filtering ###
>
>
>
> library(spdep)
>
>
>
> migration_spatial <-
> read.table("C:/migration_laptop/spdep_migration.txt", header=TRUE,
> sep="\t", na.strings="NA", dec=".", strip.white=TRUE)
>
>
>
> summary(migration_spatial)
>
>
>
> mat = matrix(0, 240, 240)
>
>
>
> mat[row(mat) >= col(mat)] <-
> scan("C:/migration_laptop/spdep_Wmat_Chun_border.txt")
>
>
>
> # not sure if the following is needed :
>
>
>
> mat <- mat + t(mat)
>
>
>
> list(mat)
>
>
>
> migmat.listw <- mat2listw(mat)
>
>
>
> migmat.listw
>
>
>
> migfilt <- SpatialFiltering(lnmr_i ~ lnmr_i_lag1 + ldwager_ij_lag1 +
> ldur_ij_lag1 + ldyrl_ij_fd_lag1 + ldq_ij_lag1 + ldpland_ij_lag1 +
> ldhc6_ij_lag1, data=migration_spatial, nb=migmat.listw, style="W",
> ExactEV=TRUE, zero.policy=TRUE)
>
>
>
> ****************************************************
>
>
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Sun Feb 15 13:50:50 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 15 Feb 2009 13:50:50 +0100 (CET)
Subject: [R-sig-Geo] Vector to raster?
In-Reply-To: <499758DC.30509@ucdavis.edu>
References: <499729B6.8060302@ucdavis.edu> <4997327E.1040401@geo.uu.nl>
	<37382E8DCB905042969BA78541F6570624D6B9@kwek.ic.uva.nl>
	<499758DC.30509@ucdavis.edu>
Message-ID: <alpine.LRH.2.00.0902151302290.26830@reclus.nhh.no>

On Sat, 14 Feb 2009, Jonathan Greenberg wrote:

> Thanks -- another few questions along these lines:

Perhaps you could simplify by providing code examples with a built-in data 
set and so on? Verbatim copies do let others see what is going on. So I'll 
start by trying to reconstruct what you seem to be asking about:

library(rgdal)
dsn <- system.file("vectors", package = "rgdal")[1]
layer <- "scot_BNG"
scot_BNG <- readOGR(dsn, layer)

library(maptools)
SG <- Sobj_SpatialGrid(scot_BNG)$SG
o <- overlay(scot_BNG, SG)
SGDF <- SpatialGridDataFrame(slot(SG, "grid"),
  proj4string=CRS(proj4string(SG)), data=o)
spplot(SGDF, "SMR", col.regions=bpy.colors(20))

The Sobj_SpatialGrid() function in maptools takes a maxDim= argument, 
which indirectly controls the (square) cell resolution. It is used in 
creating PNG devices for displaying arbitrary objects in geographical 
coordinates on Google Earth, so is related to vector to raster. An 
alternative is to create a GridTopology object from scratch, here with 
10km by 10km cells:

bb <- bbox(scot_BNG)
grd <- GridTopology(cellcentre.offset=floor(bb[,1]), cellsize=c(10000,
  10000), cells.dim=ceiling(diff(t(bb))/10000))
o <- overlay(scot_BNG, SpatialGrid(grd))
SGDF <- SpatialGridDataFrame(grd,  proj4string=CRS(proj4string(scot_BNG)),
  data=o)
spplot(SGDF, "SMR", col.regions=bpy.colors(20))

>
> 1) Is there any way to determine the type of vector file in advance of 
> defining a layer name?  How can I list layer names affiliated with a given 
> vector (it seems to be part of ogrinfo from the main gdal release, but when i 
> do a ogrinfo(filename) I get yelled at to feed it a layer name first).

ogrInfo(dsn, layer)
system(paste("ogrinfo", dsn))
# only works if ogrinfo is in your PATH
list.files(dsn)

suggests that your description isn't adequate - that is my external 
ogrinfo program appears only to choose one driver, based on the fact that 
it has been passed a directory. If the dsn was suited to other drivers, it 
would have found them, but so would, for example:

list.files(dsn, pattern="shp$")

> 2) Is there a way to tell the feature type (point, polygon, line, etc...) of 
> a readOGR object?

l <- list.files(dsn, pattern="shp$")
sapply(l, function(fn) getinfo.shape(paste(dsn, fn, sep="/")))

for shapefiles and using a function in maptools, type is as in the ESRI 
documentation. I'll try to add a similar facility to rgdal for available 
drivers - in fact, the type is declared for each feature, but is assumed 
uniform on return after accessing all features.

> 3) How do I get a polygon/line's node coordinates?  Using 
> coordinate(readOGR(...)) I only get a single coordinates associated with each 
> polygon/line in the vector.

What do you mean by "node coordinates" - no topology is being done here, 
so no arc/node analysis is available. If you mean the coordinates from 
single Polygon or Line objects, see the thread at:

https://stat.ethz.ch/pipermail/r-sig-geo/2009-February/005037.html

and my reply yesterday on stepping through Polygons and Polygon lists 
using lapply, and where to look for sample code. Basically:

all_the_coords <- lapply(slot(scot_BNG, "polygons"), function(Plns)
   lapply(slot(Plns, "Polygons"), function(Pln) slot(Pln, "coords")))

is a list of lists of coordinate matrices.

Hope this helps,

Roger

>
> Thanks!
>
> --j 
> Hengl, T. wrote:
>> 
>> If you work with large shapes/grids, try also SAGA:
>> 
>> > rsaga.get.usage(lib="grid_gridding", 3)
>> SAGA CMD 2.0.3
>> library path:   C:/Progra~1/saga_vc/modules
>> library name:   grid_gridding
>> module name :   Shapes to Grid
>> ...
>> 
>> But before SAGA, you need to reproject the polygons first (if necessary).
>> 
>> see also some examples from:
>> http://spatial-analyst.net/wiki/index.php?title=Export_maps_to_GE#Polygon_maps
>> 
>> HTH
>> 
>> Tom Hengl
>> 
>> -----Original Message-----
>> From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Paul Hiemstra
>> Sent: Sat 2/14/2009 10:07 PM
>> To: Jonathan Greenberg
>> Cc: r-sig-geo at stat.math.ethz.ch
>> Subject: Re: [R-sig-Geo] Vector to raster?
>> 
>> Jonathan Greenberg schreef:
>> > How do I take a polygon in some OGR supported vector layer (say, a
>> > shapefile), and rasterize it given a pixel size and projection/datum?
>> >
>> > --j
>> >
>> Take a look at the spsample() function.
>> 
>> Paul
>> 
>> --
>> Drs. Paul Hiemstra
>> Department of Physical Geography
>> Faculty of Geosciences
>> University of Utrecht
>> Heidelberglaan 2
>> P.O. Box 80.115
>> 3508 TC Utrecht
>> Phone:     +31302535773
>> Fax:    +31302531145
>> http://intamap.geo.uu.nl/~paul <http://intamap.geo.uu.nl/%7Epaul>
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From cicaboo at gmail.com  Sun Feb 15 15:30:57 2009
From: cicaboo at gmail.com (Michel Barbosa)
Date: Sun, 15 Feb 2009 15:30:57 +0100
Subject: [R-sig-Geo] Point pattern analysis
Message-ID: <f7f7b86f0902150630x52136937v174fd9736b5a15c0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090215/4b3539b4/attachment.pl>

From cicaboo at gmail.com  Sun Feb 15 15:36:01 2009
From: cicaboo at gmail.com (Michel Barbosa)
Date: Sun, 15 Feb 2009 15:36:01 +0100
Subject: [R-sig-Geo] Point pattern analysis
Message-ID: <f7f7b86f0902150636v6aac9cddn19816c337902c37f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090215/73ccba4a/attachment.pl>

From yud at mail.montclair.edu  Sun Feb 15 15:57:57 2009
From: yud at mail.montclair.edu (Danlin Yu)
Date: Sun, 15 Feb 2009 09:57:57 -0500
Subject: [R-sig-Geo] localmoran p-values with/without permutation
In-Reply-To: <1234691516.6004.69.camel@valerio>
References: <1234691516.6004.69.camel@valerio>
Message-ID: <49982D75.6020405@mail.montclair.edu>

Valerio:

For a local Moran's I, a randomization approximation is probably not a 
good idea since for each permutation, the mean and variance (which are 
used to calculated the p-values) of a specific location will change, 
which causes the randomized p-values not poolable (in global Moran's 
case, however, randomization will not change the global mean and variance).

The p-values will be somewhat inflated (pseudo-significant), a not 
significant local autocorrelation might become significant because of 
the reuse of the local samples, hence there is a p.adjust() function 
with various adjustment options. I would be very reluctant to use a 
non-adjusted p-value to judge for local significance. Depending on your 
data and research, you could choose one that suits your purpose the best 
(or try a few and see which ones make more sense as in an exploratory way).

Hope this helps.

Danlin Yu

Valerio Bartolino ??:
> Dear list,
> I've the objective to identify hotspot areas from a model prediction
> over a high resolution grid. After calculating a spatial weight object I
> easily applied the localmoran function from the spdep library. It's not
> really clear to me the meaning of the p-values associated to the
> localmoran function and how much I can rely on them in terms of
> statistical significance. For instance can I use these p-values instead
> using a randomization approach? I would be glad for any clarification.
>
> Moreover, I want to calculate a statistical significance also through a
> randomization approach (commonly used with Moran's I statistic). The
> idea behind the randomization is rather simple, and also coding doesn't
> seem too difficult, but the identified hotspots appear larger and
> disaggregated respect those identified looking at the p-values provided
> by the localmoran function at a similar significant level.
>
> Did I do some mistake in the following code I wrote for the permutation?
> Thanks for any advice, explanation or comment you will have
>
> Valerio Bartolino
>
> ###########################################
> require(spdep)
>
> locMoranI.perm <- function(x, R, listw, ...){
>
> # x is a vector of the values on which to calculate the MoranI statistic
> # R, listw, ... are all the arguments passed to the localmoran function
>
> 	mat <- matrix(data=NA, nrow=R, ncol=length(x))
> 		for(i in 1:R){
> 		perm <- sample(x, replace=F)
> 		I.locmor <- localmoran(perm, listw, ...)
> 		mat[i,] <- I.locmor[,1]
> 		rm(I.locmor)
> 		rm(perm)
> 		}
>
> 	return(mat)
> }
>
> # I used this new function as follow:
> nsim <- 1000
> I.perm <- locMoranI.perm(z, R=nsim, listw=nbw)
>
> MorI <- localmoran(z, listw=nbw)
>
> # select for instance a 0.01 pseudo-significance level
> p.perm <- apply(I.perm, 2, quantile, probs=0.99)
>
> ## because I-Moran identify spatial clustering
> ## high and low hotspots have no distinct I values
> ## make a vector to distinguish significant and high hotspots
> hot <- ifelse(p.perm-MorI[,1]<0 & z>mean(z),1,0)
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
___________________________________________
Danlin Yu, Ph.D.
Assistant Professor
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
email: yud at mail.montclair.edu
webpage: csam.montclair.edu/~yu


From Roger.Bivand at nhh.no  Sun Feb 15 16:10:32 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 15 Feb 2009 16:10:32 +0100 (CET)
Subject: [R-sig-Geo] localmoran p-values with/without permutation
In-Reply-To: <1234691516.6004.69.camel@valerio>
References: <1234691516.6004.69.camel@valerio>
Message-ID: <alpine.LRH.2.00.0902151549430.27632@reclus.nhh.no>

On Sun, 15 Feb 2009, Valerio Bartolino wrote:

> Dear list,
> I've the objective to identify hotspot areas from a model prediction
> over a high resolution grid. After calculating a spatial weight object I
> easily applied the localmoran function from the spdep library. It's not
> really clear to me the meaning of the p-values associated to the
> localmoran function and how much I can rely on them in terms of
> statistical significance. For instance can I use these p-values instead
> using a randomization approach? I would be glad for any clarification.

Yes, you can use the p-values - they are based on the same analytical 
randomisation approach as that for global Moran's I - see the references. 
This approach adjusts for the possible divergence of the observed data 
from normality with respect to kurtosis, but the p-values are tainted by 
multiple comparisons.

By randomisation, also below, you seem to mean permutation bootstraping 
(or Monte Carlo, or Hope-type test). Note that if you permute over all the 
data, you are not actually doing what you think that you are doing, 
because only the (small) set of neighbour values should be used for 
permutation, not all observations. The approaches may be equivalent if you 
know definitely that your model of the data (mean model and covariance 
model) is fully specified: there are no missing variables, all the 
variables have the correct functional forms, and there are no omitted 
global spatial processes. This is a very strong assumption, especially 
given the typical model of y ~ 1 (just the mean) used in Moran and local 
Moran tests.

Instead, it may be safer to do parametric bootstrapping, drawing from the 
actual distribution of observations for the small neighbour set - this 
also permits other approaches to be examined. See Waller & Gotway (2004) 
p. 239 for a discussion. In fact, you can actually use localmoran.sad() 
for a Saddlepoint approximation, or localmoran.exact() for the exact test, 
which are typically similar to the analytical randomisation approach for 
much of the range of the statistic, but perform much better where 
discrimination is needed, and are pretty fast, so speed is not an issue.

This expands Danlin Yu's helpful comments, I share his concerns about 
using unadjusted p-values.

If you want to look at the hotspot literature more closely, see Chapter 7 
in Waller & Gotway, and perhaps review implementations of relevant methods 
in the DCluster package.

Hope this helps,

Roger

>
> Moreover, I want to calculate a statistical significance also through a
> randomization approach (commonly used with Moran's I statistic). The
> idea behind the randomization is rather simple, and also coding doesn't
> seem too difficult, but the identified hotspots appear larger and
> disaggregated respect those identified looking at the p-values provided
> by the localmoran function at a similar significant level.
>
> Did I do some mistake in the following code I wrote for the permutation?
> Thanks for any advice, explanation or comment you will have
>
> Valerio Bartolino
>
> ###########################################
> require(spdep)
>
> locMoranI.perm <- function(x, R, listw, ...){
>
> # x is a vector of the values on which to calculate the MoranI statistic
> # R, listw, ... are all the arguments passed to the localmoran function
>
> 	mat <- matrix(data=NA, nrow=R, ncol=length(x))
> 		for(i in 1:R){
> 		perm <- sample(x, replace=F)
> 		I.locmor <- localmoran(perm, listw, ...)
> 		mat[i,] <- I.locmor[,1]
> 		rm(I.locmor)
> 		rm(perm)
> 		}
>
> 	return(mat)
> }
>
> # I used this new function as follow:
> nsim <- 1000
> I.perm <- locMoranI.perm(z, R=nsim, listw=nbw)
>
> MorI <- localmoran(z, listw=nbw)
>
> # select for instance a 0.01 pseudo-significance level
> p.perm <- apply(I.perm, 2, quantile, probs=0.99)
>
> ## because I-Moran identify spatial clustering
> ## high and low hotspots have no distinct I values
> ## make a vector to distinguish significant and high hotspots
> hot <- ifelse(p.perm-MorI[,1]<0 & z>mean(z),1,0)
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Mitze at gefra-muenster.de  Sun Feb 15 21:44:58 2009
From: Mitze at gefra-muenster.de (Timo Mitze)
Date: Sun, 15 Feb 2009 21:44:58 +0100
Subject: [R-sig-Geo] SpatialFiltering in spdep: How to create an 'nb'
	object from an imported spatial weights matrix
Message-ID: <1ADF70DB48DC0A44869DCBE27D4627F1176D21@TATOOINE.gefra-muenster.de>

Dear Roger and List,

thanks for your advice. I tried it with the code as (as well as some related with different style parameter etc.):

********************************
x <- mat2listw(mat)
lw <- nb2listw(x$neighbours, style="B", zero.policy=TRUE)
migfilt <- SpatialFiltering(lnmr_i ~ 1, data=migration_spatial, nb=lw, style="B", ExactEV=TRUE, zero.policy=TRUE)
********************************

... but unfortunately (always) got the following error message:

********************************
Fehler in card(neighbours) : 
  INTEGER() can only be applied to a 'integer', not a 'character' 
********************************

Can it be the problem the the nb object is still missing, since I try to directly create a listw object?

According to Yongwan Chun (one of the author of Spatial Filtering), the routines needs an nb and NOT(!!!) a listw object. Can I generate such an nb object from my binary 240x240 matrix?

Greetings,

Timo


-----Urspr?ngliche Nachricht-----
Von: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Gesendet: Sonntag, 15. Februar 2009 13:31
An: Timo Mitze
Cc: r-sig-geo at stat.math.ethz.ch
Betreff: Re: [R-sig-Geo] SpatialFiltering in spdep: How to create an 'nb' object from an imported spatial weights matrix

On Sat, 14 Feb 2009, Timo Mitze wrote:

> Dear List,
>
> I have a complete (distance/border based binary) spatial weights 
> matrix from Stata (e.g. as a txt-file).

Try using read.dta() in foreign of the exported Stata matrix. This reads a data.frame, which you coerce to an R matrix with as.matrix().

> I want to apply spatial filtering in
> spdep, however the routine needs an "nb" object. Is there any way to 
> extract the information from my matrix automatically (something like 
> mat2nb ???) or do I have to edit the "nb" object by hand? (e.g. in 
> terms of creating a GAL file by any text editor and then use 
> "read.gal" option
> - this strategy would mean a lot of work since I have a 240 x 240 
> matrix). I'd be happy about any help.

Next use mat2listw() in spdep to convert to a listw object, finally using:

x <- mat2listw(mat)
lw <- nb2listw(x$neighbours, glist=x$weights, style="?")

where ? is your choice of style. mat2listw() just does the convsersion, assigning a style of "M", which may not be recognised by model fitting functions. Drop the glist= argument if the weights are without importance
- as I understand they are from your description of them as binary.

Hope this helps,

Roger

>
> Best wishes,
>
> Timo
>
> P.S.: I have tried it with a spatial weights matrix in spdep 
> (mat2listw), but it does not work - see my code below:
>
> ****************************************************
>
> #### Code for Griffith Eigenvector Filtering ###
>
>
>
> library(spdep)
>
>
>
> migration_spatial <-
> read.table("C:/migration_laptop/spdep_migration.txt", header=TRUE, 
> sep="\t", na.strings="NA", dec=".", strip.white=TRUE)
>
>
>
> summary(migration_spatial)
>
>
>
> mat = matrix(0, 240, 240)
>
>
>
> mat[row(mat) >= col(mat)] <-
> scan("C:/migration_laptop/spdep_Wmat_Chun_border.txt")
>
>
>
> # not sure if the following is needed :
>
>
>
> mat <- mat + t(mat)
>
>
>
> list(mat)
>
>
>
> migmat.listw <- mat2listw(mat)
>
>
>
> migmat.listw
>
>
>
> migfilt <- SpatialFiltering(lnmr_i ~ lnmr_i_lag1 + ldwager_ij_lag1 +
> ldur_ij_lag1 + ldyrl_ij_fd_lag1 + ldq_ij_lag1 + ldpland_ij_lag1 + 
> ldhc6_ij_lag1, data=migration_spatial, nb=migmat.listw, style="W", 
> ExactEV=TRUE, zero.policy=TRUE)
>
>
>
> ****************************************************
>
>
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

--
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of Economics and Business Administration, Helleveien 30, N-5045 Bergen, Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Sun Feb 15 21:51:44 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 15 Feb 2009 21:51:44 +0100 (CET)
Subject: [R-sig-Geo] SpatialFiltering in spdep: How to create an 'nb'
 object from an imported spatial weights matrix
In-Reply-To: <1ADF70DB48DC0A44869DCBE27D4627F1176D21@TATOOINE.gefra-muenster.de>
References: <1ADF70DB48DC0A44869DCBE27D4627F1176D21@TATOOINE.gefra-muenster.de>
Message-ID: <alpine.LRH.2.00.0902152150490.2954@reclus.nhh.no>

On Sun, 15 Feb 2009, Timo Mitze wrote:

> Dear Roger and List,
>
> thanks for your advice. I tried it with the code as (as well as some related with different style parameter etc.):
>
> ********************************
> x <- mat2listw(mat)
> lw <- nb2listw(x$neighbours, style="B", zero.policy=TRUE)
> migfilt <- SpatialFiltering(lnmr_i ~ 1, data=migration_spatial, nb=lw, style="B", ExactEV=TRUE, zero.policy=TRUE)
> ********************************
>
> ... but unfortunately (always) got the following error message:
>
> ********************************
> Fehler in card(neighbours) :
>  INTEGER() can only be applied to a 'integer', not a 'character'
> ********************************
>
> Can it be the problem the the nb object is still missing, since I try to 
> directly create a listw object?

x$neighbours is the nb object, just use that.

Roger

>
> According to Yongwan Chun (one of the author of Spatial Filtering), the 
> routines needs an nb and NOT(!!!) a listw object. Can I generate such an 
> nb object from my binary 240x240 matrix?
>
> Greetings,
>
> Timo
>
>
> -----Urspr?ngliche Nachricht-----
> Von: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Gesendet: Sonntag, 15. Februar 2009 13:31
> An: Timo Mitze
> Cc: r-sig-geo at stat.math.ethz.ch
> Betreff: Re: [R-sig-Geo] SpatialFiltering in spdep: How to create an 'nb' object from an imported spatial weights matrix
>
> On Sat, 14 Feb 2009, Timo Mitze wrote:
>
>> Dear List,
>>
>> I have a complete (distance/border based binary) spatial weights
>> matrix from Stata (e.g. as a txt-file).
>
> Try using read.dta() in foreign of the exported Stata matrix. This reads a data.frame, which you coerce to an R matrix with as.matrix().
>
>> I want to apply spatial filtering in
>> spdep, however the routine needs an "nb" object. Is there any way to
>> extract the information from my matrix automatically (something like
>> mat2nb ???) or do I have to edit the "nb" object by hand? (e.g. in
>> terms of creating a GAL file by any text editor and then use
>> "read.gal" option
>> - this strategy would mean a lot of work since I have a 240 x 240
>> matrix). I'd be happy about any help.
>
> Next use mat2listw() in spdep to convert to a listw object, finally using:
>
> x <- mat2listw(mat)
> lw <- nb2listw(x$neighbours, glist=x$weights, style="?")
>
> where ? is your choice of style. mat2listw() just does the convsersion, assigning a style of "M", which may not be recognised by model fitting functions. Drop the glist= argument if the weights are without importance
> - as I understand they are from your description of them as binary.
>
> Hope this helps,
>
> Roger
>
>>
>> Best wishes,
>>
>> Timo
>>
>> P.S.: I have tried it with a spatial weights matrix in spdep
>> (mat2listw), but it does not work - see my code below:
>>
>> ****************************************************
>>
>> #### Code for Griffith Eigenvector Filtering ###
>>
>>
>>
>> library(spdep)
>>
>>
>>
>> migration_spatial <-
>> read.table("C:/migration_laptop/spdep_migration.txt", header=TRUE,
>> sep="\t", na.strings="NA", dec=".", strip.white=TRUE)
>>
>>
>>
>> summary(migration_spatial)
>>
>>
>>
>> mat = matrix(0, 240, 240)
>>
>>
>>
>> mat[row(mat) >= col(mat)] <-
>> scan("C:/migration_laptop/spdep_Wmat_Chun_border.txt")
>>
>>
>>
>> # not sure if the following is needed :
>>
>>
>>
>> mat <- mat + t(mat)
>>
>>
>>
>> list(mat)
>>
>>
>>
>> migmat.listw <- mat2listw(mat)
>>
>>
>>
>> migmat.listw
>>
>>
>>
>> migfilt <- SpatialFiltering(lnmr_i ~ lnmr_i_lag1 + ldwager_ij_lag1 +
>> ldur_ij_lag1 + ldyrl_ij_fd_lag1 + ldq_ij_lag1 + ldpland_ij_lag1 +
>> ldhc6_ij_lag1, data=migration_spatial, nb=migmat.listw, style="W",
>> ExactEV=TRUE, zero.policy=TRUE)
>>
>>
>>
>> ****************************************************
>>
>>
>>
>>
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of Economics and Business Administration, Helleveien 30, N-5045 Bergen, Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From greenberg at ucdavis.edu  Sun Feb 15 22:14:50 2009
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Sun, 15 Feb 2009 13:14:50 -0800
Subject: [R-sig-Geo] Vector to raster?
In-Reply-To: <alpine.LRH.2.00.0902151302290.26830@reclus.nhh.no>
References: <499729B6.8060302@ucdavis.edu> <4997327E.1040401@geo.uu.nl>
	<37382E8DCB905042969BA78541F6570624D6B9@kwek.ic.uva.nl>
	<499758DC.30509@ucdavis.edu>
	<alpine.LRH.2.00.0902151302290.26830@reclus.nhh.no>
Message-ID: <499885CA.9010708@ucdavis.edu>

Roger:

    Thanks, I'll try to incorporate some of your suggestions and post 
the code + some sample imagery next time I ask a question.  I'm trying 
to build up some R-based code that replicates some of what my "starspan" 
program does (starspan.casil.ucdavis.edu) -- essentially taking vector 
data, querying out the raster data at those locations (point, poly or 
line), and fusing the vector DB with the extracted raster data.  We'll 
probably eventually work on the C version of the code again, and write 
an R wrapper, but for now I wanted an R-only script.

    The larger idea is to be able to generate training/test data for use 
in remote sensing classification and analysis.  We're focusing on using 
rgdal for a course at UC Davis on open source geospatial analysis.  I 
just got your book, so I'll be reading it this weekend!

--j

Roger Bivand wrote:
> On Sat, 14 Feb 2009, Jonathan Greenberg wrote:
>
>> Thanks -- another few questions along these lines:
>
> Perhaps you could simplify by providing code examples with a built-in 
> data set and so on? Verbatim copies do let others see what is going 
> on. So I'll start by trying to reconstruct what you seem to be asking 
> about:
>
> library(rgdal)
> dsn <- system.file("vectors", package = "rgdal")[1]
> layer <- "scot_BNG"
> scot_BNG <- readOGR(dsn, layer)
>
> library(maptools)
> SG <- Sobj_SpatialGrid(scot_BNG)$SG
> o <- overlay(scot_BNG, SG)
> SGDF <- SpatialGridDataFrame(slot(SG, "grid"),
>  proj4string=CRS(proj4string(SG)), data=o)
> spplot(SGDF, "SMR", col.regions=bpy.colors(20))
>
> The Sobj_SpatialGrid() function in maptools takes a maxDim= argument, 
> which indirectly controls the (square) cell resolution. It is used in 
> creating PNG devices for displaying arbitrary objects in geographical 
> coordinates on Google Earth, so is related to vector to raster. An 
> alternative is to create a GridTopology object from scratch, here with 
> 10km by 10km cells:
>
> bb <- bbox(scot_BNG)
> grd <- GridTopology(cellcentre.offset=floor(bb[,1]), cellsize=c(10000,
>  10000), cells.dim=ceiling(diff(t(bb))/10000))
> o <- overlay(scot_BNG, SpatialGrid(grd))
> SGDF <- SpatialGridDataFrame(grd,  
> proj4string=CRS(proj4string(scot_BNG)),
>  data=o)
> spplot(SGDF, "SMR", col.regions=bpy.colors(20))
>
>>
>> 1) Is there any way to determine the type of vector file in advance 
>> of defining a layer name?  How can I list layer names affiliated with 
>> a given vector (it seems to be part of ogrinfo from the main gdal 
>> release, but when i do a ogrinfo(filename) I get yelled at to feed it 
>> a layer name first).
>
> ogrInfo(dsn, layer)
> system(paste("ogrinfo", dsn))
> # only works if ogrinfo is in your PATH
> list.files(dsn)
>
> suggests that your description isn't adequate - that is my external 
> ogrinfo program appears only to choose one driver, based on the fact 
> that it has been passed a directory. If the dsn was suited to other 
> drivers, it would have found them, but so would, for example:
>
> list.files(dsn, pattern="shp$")
>
>> 2) Is there a way to tell the feature type (point, polygon, line, 
>> etc...) of a readOGR object?
>
> l <- list.files(dsn, pattern="shp$")
> sapply(l, function(fn) getinfo.shape(paste(dsn, fn, sep="/")))
>
> for shapefiles and using a function in maptools, type is as in the 
> ESRI documentation. I'll try to add a similar facility to rgdal for 
> available drivers - in fact, the type is declared for each feature, 
> but is assumed uniform on return after accessing all features.
>
>> 3) How do I get a polygon/line's node coordinates?  Using 
>> coordinate(readOGR(...)) I only get a single coordinates associated 
>> with each polygon/line in the vector.
>
> What do you mean by "node coordinates" - no topology is being done 
> here, so no arc/node analysis is available. If you mean the 
> coordinates from single Polygon or Line objects, see the thread at:
>
> https://stat.ethz.ch/pipermail/r-sig-geo/2009-February/005037.html
>
> and my reply yesterday on stepping through Polygons and Polygon lists 
> using lapply, and where to look for sample code. Basically:
>
> all_the_coords <- lapply(slot(scot_BNG, "polygons"), function(Plns)
>   lapply(slot(Plns, "Polygons"), function(Pln) slot(Pln, "coords")))
>
> is a list of lists of coordinate matrices.
>
> Hope this helps,
>
> Roger
>
>>
>> Thanks!
>>
>> --j Hengl, T. wrote:
>>>
>>> If you work with large shapes/grids, try also SAGA:
>>>
>>> > rsaga.get.usage(lib="grid_gridding", 3)
>>> SAGA CMD 2.0.3
>>> library path:   C:/Progra~1/saga_vc/modules
>>> library name:   grid_gridding
>>> module name :   Shapes to Grid
>>> ...
>>>
>>> But before SAGA, you need to reproject the polygons first (if 
>>> necessary).
>>>
>>> see also some examples from:
>>> http://spatial-analyst.net/wiki/index.php?title=Export_maps_to_GE#Polygon_maps 
>>>
>>>
>>> HTH
>>>
>>> Tom Hengl
>>>
>>> -----Original Message-----
>>> From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Paul Hiemstra
>>> Sent: Sat 2/14/2009 10:07 PM
>>> To: Jonathan Greenberg
>>> Cc: r-sig-geo at stat.math.ethz.ch
>>> Subject: Re: [R-sig-Geo] Vector to raster?
>>>
>>> Jonathan Greenberg schreef:
>>> > How do I take a polygon in some OGR supported vector layer (say, a
>>> > shapefile), and rasterize it given a pixel size and projection/datum?
>>> >
>>> > --j
>>> >
>>> Take a look at the spsample() function.
>>>
>>> Paul
>>>
>>> -- 
>>> Drs. Paul Hiemstra
>>> Department of Physical Geography
>>> Faculty of Geosciences
>>> University of Utrecht
>>> Heidelberglaan 2
>>> P.O. Box 80.115
>>> 3508 TC Utrecht
>>> Phone:     +31302535773
>>> Fax:    +31302531145
>>> http://intamap.geo.uu.nl/~paul <http://intamap.geo.uu.nl/%7Epaul>
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>
>

-- 

Jonathan A. Greenberg, PhD
Postdoctoral Scholar
Center for Spatial Technologies and Remote Sensing (CSTARS)
University of California, Davis
One Shields Avenue
The Barn, Room 250N
Davis, CA 95616
Cell: 415-794-5043
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307


From Virgilio.Gomez at uclm.es  Sun Feb 15 22:17:29 2009
From: Virgilio.Gomez at uclm.es (Virgilio Gomez Rubio)
Date: Sun, 15 Feb 2009 22:17:29 +0100
Subject: [R-sig-Geo] Point pattern analysis
In-Reply-To: <f7f7b86f0902150636v6aac9cddn19816c337902c37f@mail.gmail.com>
References: <f7f7b86f0902150636v6aac9cddn19816c337902c37f@mail.gmail.com>
Message-ID: <1234732649.8833.84.camel@Virgilio-Gomez>

Dear Michel,

> I'm new to Spatial Data Analysis and have just begun working through
> "Applied Spatial Data Analysis wit R" by Bivand et al. For my research I
> would like to use SDA to be able to tell more about my restaurant data set
> than just pinpointing them on a google map. So far, from reading the
> literature on SDA I've been able to construct the following questions.

Interesting problem. Let me know if you need help collecting data. ;)

> 
> 1. How far / close are restaurants from each other? (answered by using
> kernel density estimation)
> 2. Which type of restaurants stand next to each other?
> 3. How are the restaurants positioned relatlivey from each other?
> 4. What's the difference between restaurant A and restaurant B?


Questions 2 and 3 are much alike, and I believe that question 4 is too
general and not necessarily about the spatial distribution of the
restaurants.

Depending on the number of different types of restaurants, you may want
to estimate a different surface for each type. Basically, you may
consider a multivariate point pattern, so that you estimate a different
surface for each type and  you compare then to see if they are similar
or not. This will address the question of whether the spatial
distribution of different types of restaurants is the same or not. This
is discussed in Diggle et al. (2005, JRSS Series A). Some of the methods
described in the paper are implemented in package spatialkernel. 

You may also want to compute bivariate K-functions (see 'k12hat' in
splancs; 'Kmulti' in spatstat) to detect differences between the spatial
distributions of types of restaurants. This will give you a partial
answer to Question 2.

If you have a set of covariates for each restaurant and you want to
estimate their effect and how they explain the spatial distribution of
the data you can check Diggle et al. (2006, Biometrics). There is also
an example of this in Bivand et al. (2008).

I am not sure about the best way of tackling Question 3 (and why this is
important). Have you considered to test for whether a certain type of
restaurant tends to appear around a particular area of the city? For
example, are Chinese restaurants clustered around Chinatown?

Finally, another option is to aggregate your data (counts per
neighbourhood, for example) and do a similar analysis as in disease
mapping.

> I've exported a subset of my dataset to CSV in order to import it in R.
> Currently, my CSV file is of the form
> 
> *restaurant name; latitude; longitude; type*
> Amigo;52.996058;6.564229;Italian
> Bella Italia;52.99281;6.560353;Italian
> Isola Bella;52.993764;6.560245;Italian

I would not use long/lat but UTM to do your analysis. You can do this
very easily with R.

> 
> I've tried to import the CSV in R by doing:
> 
> library(spatstat)
> info <- read.csv(file = "sample.csv", sep = ";", strip.white = TRUE)
> win <- owin(c(0,100),c(0,100))
> pattern <- ppp(info$lat, info$lng, window = win, marks=info$name)
> 
> However, if I plot the pattern, the points are all cluttered. What advice
> could you give me on setting the window size?

If you try to plot more than 10,000 points, then I am not surprised that
they are all cluttered. :) I would plot the estimated intensity of the
point patterns. Or you may aggregate your data and produce a map based
on the neighbourhoods in your area.

Hope this helps.

Virgilio


From wroberts at csir.co.za  Mon Feb 16 07:49:51 2009
From: wroberts at csir.co.za (Wesley Roberts)
Date: Mon, 16 Feb 2009 08:49:51 +0200
Subject: [R-sig-Geo] Masking interpolations
Message-ID: <499928AF0200007300018830@pta-emo.csir.co.za>

Dear R-sig-geo'ers

I am currently running some interpolations using automap written by Paul Hiemstra. So far my interpolations have been producing suitable results except for one problem. From the code you will see that the boundaries of the spatial grid are determined using the range of the X and Y coordinates creating a square grid. My point data do not cover the entire grid and I would only like to interpolate in areas where data exists otherwise I get a significant edge effect. Is it possible to limit / mask my interpolation to only predict where data exists? 

The point data are lidar canopy returns for an irregular shaped timber compartment and number around 10 000 irregular spaced points. 

Any help on this matter would be greatly appreciated.

Kind regards,
Wesley


library(automap)
library(gstat)

a <- read.csv("AreaOne_4pts.csv", header=TRUE)

coordinates(a) <-~ x+y

x.range <- as.integer(range(a at coords[,1]))
y.range <- as.integer(range(a at coords[,2]))


grd <- expand.grid(x=seq(from=x.range[1], to=x.range[2], by=0.1), y=seq(from=y.range[1], to=y.range[2], by=0.1))
coordinates(grd) <-~ x+y
gridded(grd) <- TRUE

height = autoKrige(H~1, a, grd, nmax=100)
writeGDAL(height$krige_output, fname="test.tiff", drivername ="GTiff", type = "Float32")

intensity = autoKrige(I~1, a, grd, nmax=100)
writeGDAL(intensity$krige_output, fname="test.tiff", drivername ="GTiff", type = "Float32")

Wesley Roberts MSc.
Researcher: Earth Observation (Ecosystems)
Natural Resources and the Environment
CSIR
Tel: +27 (21) 888-2490
Fax: +27 (21) 888-2693

"To know the road ahead, ask those coming back."
- Chinese proverb


-- 
This message is subject to the CSIR's copyright terms and conditions, e-mail legal notice, and implemented Open Document Format (ODF) standard. 
The full disclaimer details can be found at http://www.csir.co.za/disclaimer.html.

This message has been scanned for viruses and dangerous content by MailScanner, 
and is believed to be clean.  MailScanner thanks Transtec Computers for their support.


From p.hiemstra at geo.uu.nl  Mon Feb 16 09:27:09 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 16 Feb 2009 09:27:09 +0100
Subject: [R-sig-Geo] Masking interpolations
In-Reply-To: <499928AF0200007300018830@pta-emo.csir.co.za>
References: <499928AF0200007300018830@pta-emo.csir.co.za>
Message-ID: <4999235D.6050600@geo.uu.nl>

Hi Wesley,

You could take a look at using a convex hull. I'm not sure if this will 
fix your problem as we cannot see how exactly your points are irregular. 
The latest version on my website (0.5-2) uses a convex hull off the data 
if you don't pass a new_data object. You could try this. The function 
making the convex hull is:

create_new_data = function(obj) {
# Function that creates a new_data object if one is missing
        convex_hull = chull(coordinates(obj)[,1],coordinates(obj)[,2])
        convex_hull = c(convex_hull, convex_hull[1]) # Close the polygon
        d = Polygon(obj[convex_hull,])
        new_data = spsample(d, 5000, type = "regular")
        gridded(new_data) = TRUE
        return(new_data)
}

If you want to call it directly from the package use 
automap:::create_new_data.

cheers,
Paul

Wesley Roberts wrote:
> Dear R-sig-geo'ers
>
> I am currently running some interpolations using automap written by Paul Hiemstra. So far my interpolations have been producing suitable results except for one problem. From the code you will see that the boundaries of the spatial grid are determined using the range of the X and Y coordinates creating a square grid. My point data do not cover the entire grid and I would only like to interpolate in areas where data exists otherwise I get a significant edge effect. Is it possible to limit / mask my interpolation to only predict where data exists? 
>
> The point data are lidar canopy returns for an irregular shaped timber compartment and number around 10 000 irregular spaced points. 
>
> Any help on this matter would be greatly appreciated.
>
> Kind regards,
> Wesley
>
>
> library(automap)
> library(gstat)
>
> a <- read.csv("AreaOne_4pts.csv", header=TRUE)
>
> coordinates(a) <-~ x+y
>
> x.range <- as.integer(range(a at coords[,1]))
> y.range <- as.integer(range(a at coords[,2]))
>
>
> grd <- expand.grid(x=seq(from=x.range[1], to=x.range[2], by=0.1), y=seq(from=y.range[1], to=y.range[2], by=0.1))
> coordinates(grd) <-~ x+y
> gridded(grd) <- TRUE
>
> height = autoKrige(H~1, a, grd, nmax=100)
> writeGDAL(height$krige_output, fname="test.tiff", drivername ="GTiff", type = "Float32")
>
> intensity = autoKrige(I~1, a, grd, nmax=100)
> writeGDAL(intensity$krige_output, fname="test.tiff", drivername ="GTiff", type = "Float32")
>
> Wesley Roberts MSc.
> Researcher: Earth Observation (Ecosystems)
> Natural Resources and the Environment
> CSIR
> Tel: +27 (21) 888-2490
> Fax: +27 (21) 888-2693
>
> "To know the road ahead, ask those coming back."
> - Chinese proverb
>
>
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul


From p.hiemstra at geo.uu.nl  Mon Feb 16 09:38:48 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 16 Feb 2009 09:38:48 +0100
Subject: [R-sig-Geo] Masking interpolations
In-Reply-To: <499928AF0200007300018830@pta-emo.csir.co.za>
References: <499928AF0200007300018830@pta-emo.csir.co.za>
Message-ID: <49992618.5040606@geo.uu.nl>

...in addition:

You could also use AcrGIS, QGis or another GIS package to make a polygon 
that delineates the areas in which you want to interpolate. You can then 
use spsample() like I showed you in the previous mail. Making this 
polygon can also be done in R using spplot and grid.locator, if you are 
interested I can send you some example code.

Another option is to calculate the square grid you make using 
expand.grid, perform the interpolation and throw away any points that 
are above a certain kriging variance (that you have to choose). This 
would be a good solution if you need to automatically interpolate a lot 
of lidar sets that differ a lot in configuration of the points. it is 
not the most elegant and efficient solution though :).

cheers,
Paul

Wesley Roberts wrote:
> Dear R-sig-geo'ers
>
> I am currently running some interpolations using automap written by Paul Hiemstra. So far my interpolations have been producing suitable results except for one problem. From the code you will see that the boundaries of the spatial grid are determined using the range of the X and Y coordinates creating a square grid. My point data do not cover the entire grid and I would only like to interpolate in areas where data exists otherwise I get a significant edge effect. Is it possible to limit / mask my interpolation to only predict where data exists? 
>
> The point data are lidar canopy returns for an irregular shaped timber compartment and number around 10 000 irregular spaced points. 
>
> Any help on this matter would be greatly appreciated.
>
> Kind regards,
> Wesley
>
>
> library(automap)
> library(gstat)
>
> a <- read.csv("AreaOne_4pts.csv", header=TRUE)
>
> coordinates(a) <-~ x+y
>
> x.range <- as.integer(range(a at coords[,1]))
> y.range <- as.integer(range(a at coords[,2]))
>
>
> grd <- expand.grid(x=seq(from=x.range[1], to=x.range[2], by=0.1), y=seq(from=y.range[1], to=y.range[2], by=0.1))
> coordinates(grd) <-~ x+y
> gridded(grd) <- TRUE
>
> height = autoKrige(H~1, a, grd, nmax=100)
> writeGDAL(height$krige_output, fname="test.tiff", drivername ="GTiff", type = "Float32")
>
> intensity = autoKrige(I~1, a, grd, nmax=100)
> writeGDAL(intensity$krige_output, fname="test.tiff", drivername ="GTiff", type = "Float32")
>
> Wesley Roberts MSc.
> Researcher: Earth Observation (Ecosystems)
> Natural Resources and the Environment
> CSIR
> Tel: +27 (21) 888-2490
> Fax: +27 (21) 888-2693
>
> "To know the road ahead, ask those coming back."
> - Chinese proverb
>
>
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul


From wroberts at csir.co.za  Mon Feb 16 10:58:09 2009
From: wroberts at csir.co.za (Wesley Roberts)
Date: Mon, 16 Feb 2009 11:58:09 +0200
Subject: [R-sig-Geo] Masking interpolations
Message-ID: <499954D502000073000188A7@pta-emo.csir.co.za>

Hi Paul,

Many thanks for the reply. I am not sure about the convex hull approach as I am not sure how to implement it as part of my program. Is the code you wrote below replacing the following statements? Would I then pass grd to the autoKrige statement as shown in the original code below?

************************************************************************************************************************************************************************************************************
> x.range <- as.integer(range(a at coords[,1]))
> y.range <- as.integer(range(a at coords[,2]))
> grd <- expand.grid(x=seq(from=x.range[1], to=x.range[2], by=0.1), y=seq(from=y.range[1], to=y.range[2], by=0.1))
> coordinates(grd) <-~ x+y
> gridded(grd) <- TRUE
************************************************************************************************************************************************************************************************************

I have uploaded some pics of my points and interpolations to flickr. 

Link 1 shows the timber compartment with the lidar points overlayed and the bounding polygon used to subset the point data set. You cant really see the irregularity of the points but trust me, they are all over the place. Average distance between points is about 17cm so a 10cm interpolation resolution should be okay. 
Link 1
http://www.flickr.com/photos/35273872 at N07/3283623165/

Link 2, is the height interpolation using the parameters you suggested on Friday. As you can see the lack of points outside the polygon results in a type of edge effect at the boundaries. I can mask the rest out but would prefer to limit the interpolation to minimize errors at the boundaries.
Link 2
http://www.flickr.com/photos/35273872 at N07/3283623941/

Finally link 3 shows what I think is the kriging variance although I cant be sure. When I import the tiff written by writeGDAL there are three bands (using GRASS). The first is the interpolated variable, the next two are a mystery to me. If this is indeed the krig variance then limiting the interpolation based on kriging variance seems like a good idea? What do you think?
Link 3
http://www.flickr.com/photos/35273872 at N07/3284446466/

Many thanks,
Wesley

Wesley Roberts MSc.
Researcher: Earth Observation (Ecosystems)
Natural Resources and the Environment
CSIR
Tel: +27 (21) 888-2490
Fax: +27 (21) 888-2693

"To know the road ahead, ask those coming back."
- Chinese proverb

>>> Paul Hiemstra <p.hiemstra at geo.uu.nl> 02/16/09 10:29 AM >>>
Hi Wesley,

You could take a look at using a convex hull. I'm not sure if this will 
fix your problem as we cannot see how exactly your points are irregular. 
The latest version on my website (0.5-2) uses a convex hull off the data 
if you don't pass a new_data object. You could try this. The function 
making the convex hull is:

create_new_data = function(obj) {
# Function that creates a new_data object if one is missing
        convex_hull = chull(coordinates(obj)[,1],coordinates(obj)[,2])
        convex_hull = c(convex_hull, convex_hull[1]) # Close the polygon
        d = Polygon(obj[convex_hull,])
        new_data = spsample(d, 5000, type = "regular")
        gridded(new_data) = TRUE
        return(new_data)
}

If you want to call it directly from the package use 
automap:::create_new_data.

cheers,
Paul

Wesley Roberts wrote:
> Dear R-sig-geo'ers
>
> I am currently running some interpolations using automap written by Paul Hiemstra. So far my interpolations have been producing suitable results except for one problem. From the code you will see that the boundaries of the spatial grid are determined using the range of the X and Y coordinates creating a square grid. My point data do not cover the entire grid and I would only like to interpolate in areas where data exists otherwise I get a significant edge effect. Is it possible to limit / mask my interpolation to only predict where data exists? 
>
> The point data are lidar canopy returns for an irregular shaped timber compartment and number around 10 000 irregular spaced points. 
>
> Any help on this matter would be greatly appreciated.
>
> Kind regards,
> Wesley
>
>
> library(automap)
> library(gstat)
>
> a <- read.csv("AreaOne_4pts.csv", header=TRUE)
>
> coordinates(a) <-~ x+y
>
> x.range <- as.integer(range(a at coords[,1]))
> y.range <- as.integer(range(a at coords[,2]))
>
>
> grd <- expand.grid(x=seq(from=x.range[1], to=x.range[2], by=0.1), y=seq(from=y.range[1], to=y.range[2], by=0.1))
> coordinates(grd) <-~ x+y
> gridded(grd) <- TRUE
>
> height = autoKrige(H~1, a, grd, nmax=100)
> writeGDAL(height$krige_output, fname="test.tiff", drivername ="GTiff", type = "Float32")
>
> intensity = autoKrige(I~1, a, grd, nmax=100)
> writeGDAL(intensity$krige_output, fname="test.tiff", drivername ="GTiff", type = "Float32")
>
> Wesley Roberts MSc.
> Researcher: Earth Observation (Ecosystems)
> Natural Resources and the Environment
> CSIR
> Tel: +27 (21) 888-2490
> Fax: +27 (21) 888-2693
>
> "To know the road ahead, ask those coming back."
> - Chinese proverb
>
>
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul



-- 
This message is subject to the CSIR's copyright terms and conditions, e-mail legal notice, and implemented Open Document Format (ODF) standard. 
The full disclaimer details can be found at http://www.csir.co.za/disclaimer.html.


and is believed to be clean.  MailScanner thanks Transtec Computers for their support.


From p.hiemstra at geo.uu.nl  Mon Feb 16 11:06:09 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 16 Feb 2009 11:06:09 +0100
Subject: [R-sig-Geo] Masking interpolations
In-Reply-To: <499954D502000073000188A7@pta-emo.csir.co.za>
References: <499954D502000073000188A7@pta-emo.csir.co.za>
Message-ID: <49993A91.8040904@geo.uu.nl>

Hi,

A convex hull should do the trick, if you have the latest automap 
version (>0.5-2) you don't have do to anything to get a convex hull. 
Just omit grd (new_data argument) and automap will automatically use a 
convex hull.

cheers,
Paul

Wesley Roberts wrote:
> Hi Paul,
>
> Many thanks for the reply. I am not sure about the convex hull approach as I am not sure how to implement it as part of my program. Is the code you wrote below replacing the following statements? Would I then pass grd to the autoKrige statement as shown in the original code below?
>
> ************************************************************************************************************************************************************************************************************
>   
>> x.range <- as.integer(range(a at coords[,1]))
>> y.range <- as.integer(range(a at coords[,2]))
>> grd <- expand.grid(x=seq(from=x.range[1], to=x.range[2], by=0.1), y=seq(from=y.range[1], to=y.range[2], by=0.1))
>> coordinates(grd) <-~ x+y
>> gridded(grd) <- TRUE
>>     
> ************************************************************************************************************************************************************************************************************
>
> I have uploaded some pics of my points and interpolations to flickr. 
>
> Link 1 shows the timber compartment with the lidar points overlayed and the bounding polygon used to subset the point data set. You cant really see the irregularity of the points but trust me, they are all over the place. Average distance between points is about 17cm so a 10cm interpolation resolution should be okay. 
> Link 1
> http://www.flickr.com/photos/35273872 at N07/3283623165/
>
> Link 2, is the height interpolation using the parameters you suggested on Friday. As you can see the lack of points outside the polygon results in a type of edge effect at the boundaries. I can mask the rest out but would prefer to limit the interpolation to minimize errors at the boundaries.
> Link 2
> http://www.flickr.com/photos/35273872 at N07/3283623941/
>
> Finally link 3 shows what I think is the kriging variance although I cant be sure. When I import the tiff written by writeGDAL there are three bands (using GRASS). The first is the interpolated variable, the next two are a mystery to me. If this is indeed the krig variance then limiting the interpolation based on kriging variance seems like a good idea? What do you think?
> Link 3
> http://www.flickr.com/photos/35273872 at N07/3284446466/
>   
This is indeed the kriging variance.
> Many thanks,
> Wesley
>
> Wesley Roberts MSc.
> Researcher: Earth Observation (Ecosystems)
> Natural Resources and the Environment
> CSIR
> Tel: +27 (21) 888-2490
> Fax: +27 (21) 888-2693
>
> "To know the road ahead, ask those coming back."
> - Chinese proverb
>
>   
>>>> Paul Hiemstra <p.hiemstra at geo.uu.nl> 02/16/09 10:29 AM >>>
>>>>         
> Hi Wesley,
>
> You could take a look at using a convex hull. I'm not sure if this will 
> fix your problem as we cannot see how exactly your points are irregular. 
> The latest version on my website (0.5-2) uses a convex hull off the data 
> if you don't pass a new_data object. You could try this. The function 
> making the convex hull is:
>
> create_new_data = function(obj) {
> # Function that creates a new_data object if one is missing
>         convex_hull = chull(coordinates(obj)[,1],coordinates(obj)[,2])
>         convex_hull = c(convex_hull, convex_hull[1]) # Close the polygon
>         d = Polygon(obj[convex_hull,])
>         new_data = spsample(d, 5000, type = "regular")
>         gridded(new_data) = TRUE
>         return(new_data)
> }
>
> If you want to call it directly from the package use 
> automap:::create_new_data.
>
> cheers,
> Paul
>
> Wesley Roberts wrote:
>   
>> Dear R-sig-geo'ers
>>
>> I am currently running some interpolations using automap written by Paul Hiemstra. So far my interpolations have been producing suitable results except for one problem. From the code you will see that the boundaries of the spatial grid are determined using the range of the X and Y coordinates creating a square grid. My point data do not cover the entire grid and I would only like to interpolate in areas where data exists otherwise I get a significant edge effect. Is it possible to limit / mask my interpolation to only predict where data exists? 
>>
>> The point data are lidar canopy returns for an irregular shaped timber compartment and number around 10 000 irregular spaced points. 
>>
>> Any help on this matter would be greatly appreciated.
>>
>> Kind regards,
>> Wesley
>>
>>
>> library(automap)
>> library(gstat)
>>
>> a <- read.csv("AreaOne_4pts.csv", header=TRUE)
>>
>> coordinates(a) <-~ x+y
>>
>> x.range <- as.integer(range(a at coords[,1]))
>> y.range <- as.integer(range(a at coords[,2]))
>>
>>
>> grd <- expand.grid(x=seq(from=x.range[1], to=x.range[2], by=0.1), y=seq(from=y.range[1], to=y.range[2], by=0.1))
>> coordinates(grd) <-~ x+y
>> gridded(grd) <- TRUE
>>
>> height = autoKrige(H~1, a, grd, nmax=100)
>> writeGDAL(height$krige_output, fname="test.tiff", drivername ="GTiff", type = "Float32")
>>
>> intensity = autoKrige(I~1, a, grd, nmax=100)
>> writeGDAL(intensity$krige_output, fname="test.tiff", drivername ="GTiff", type = "Float32")
>>
>> Wesley Roberts MSc.
>> Researcher: Earth Observation (Ecosystems)
>> Natural Resources and the Environment
>> CSIR
>> Tel: +27 (21) 888-2490
>> Fax: +27 (21) 888-2693
>>
>> "To know the road ahead, ask those coming back."
>> - Chinese proverb
>>
>>
>>   
>>     
>
>
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul


From wroberts at csir.co.za  Mon Feb 16 11:34:11 2009
From: wroberts at csir.co.za (Wesley Roberts)
Date: Mon, 16 Feb 2009 12:34:11 +0200
Subject: [R-sig-Geo] Masking interpolations
Message-ID: <49995D4402000073000188BD@pta-emo.csir.co.za>

Excellent, that will help alot. I have the newest version of automap and am running an experiment now. 

Just to confirm I need to omit the statement 'grd(new_data argument)' which in my case is 'gridded(grd) <- TRUE'. That way the resolution is defined in x.range <- ..... and y.range <- ..... statements but the entire grid (square) is not defined and thus interpolation only occurs where data exists?

Wesley


Wesley Roberts MSc.
Researcher: Earth Observation (Ecosystems)
Natural Resources and the Environment
CSIR
Tel: +27 (21) 888-2490
Fax: +27 (21) 888-2693

"To know the road ahead, ask those coming back."
- Chinese proverb

>>> Paul Hiemstra <p.hiemstra at geo.uu.nl> 02/16/09 12:08 PM >>>
Hi,

A convex hull should do the trick, if you have the latest automap 
version (>0.5-2) you don't have do to anything to get a convex hull. 
Just omit grd (new_data argument) and automap will automatically use a 
convex hull.

cheers,
Paul

Wesley Roberts wrote:
> Hi Paul,
>
> Many thanks for the reply. I am not sure about the convex hull approach as I am not sure how to implement it as part of my program. Is the code you wrote below replacing the following statements? Would I then pass grd to the autoKrige statement as shown in the original code below?
>
> ************************************************************************************************************************************************************************************************************
>   
>> x.range <- as.integer(range(a at coords[,1]))
>> y.range <- as.integer(range(a at coords[,2]))
>> grd <- expand.grid(x=seq(from=x.range[1], to=x.range[2], by=0.1), y=seq(from=y.range[1], to=y.range[2], by=0.1))
>> coordinates(grd) <-~ x+y
>> gridded(grd) <- TRUE
>>     
> ************************************************************************************************************************************************************************************************************
>
> I have uploaded some pics of my points and interpolations to flickr. 
>
> Link 1 shows the timber compartment with the lidar points overlayed and the bounding polygon used to subset the point data set. You cant really see the irregularity of the points but trust me, they are all over the place. Average distance between points is about 17cm so a 10cm interpolation resolution should be okay. 
> Link 1
> http://www.flickr.com/photos/35273872 at N07/3283623165/
>
> Link 2, is the height interpolation using the parameters you suggested on Friday. As you can see the lack of points outside the polygon results in a type of edge effect at the boundaries. I can mask the rest out but would prefer to limit the interpolation to minimize errors at the boundaries.
> Link 2
> http://www.flickr.com/photos/35273872 at N07/3283623941/
>
> Finally link 3 shows what I think is the kriging variance although I cant be sure. When I import the tiff written by writeGDAL there are three bands (using GRASS). The first is the interpolated variable, the next two are a mystery to me. If this is indeed the krig variance then limiting the interpolation based on kriging variance seems like a good idea? What do you think?
> Link 3
> http://www.flickr.com/photos/35273872 at N07/3284446466/
>   
This is indeed the kriging variance.
> Many thanks,
> Wesley
>
> Wesley Roberts MSc.
> Researcher: Earth Observation (Ecosystems)
> Natural Resources and the Environment
> CSIR
> Tel: +27 (21) 888-2490
> Fax: +27 (21) 888-2693
>
> "To know the road ahead, ask those coming back."
> - Chinese proverb
>
>   
>>>> Paul Hiemstra <p.hiemstra at geo.uu.nl> 02/16/09 10:29 AM >>>
>>>>         
> Hi Wesley,
>
> You could take a look at using a convex hull. I'm not sure if this will
> fix your problem as we cannot see how exactly your points are irregular.
> The latest version on my website (0.5-2) uses a convex hull off the data
> if you don't pass a new_data object. You could try this. The function 
> making the convex hull is:
>
> create_new_data = function(obj) {
> # Function that creates a new_data object if one is missing
>         convex_hull = chull(coordinates(obj)[,1],coordinates(obj)[,2])
>         convex_hull = c(convex_hull, convex_hull[1]) # Close the polygon
>         d = Polygon(obj[convex_hull,])
>         new_data = spsample(d, 5000, type = "regular")
>         gridded(new_data) = TRUE
>         return(new_data)
> }
>
> If you want to call it directly from the package use 
> automap:::create_new_data.
>
> cheers,
> Paul
>
> Wesley Roberts wrote:
>   
>> Dear R-sig-geo'ers
>>
>> I am currently running some interpolations using automap written by Paul Hiemstra. So far my interpolations have been producing suitable results except for one problem. From the code you will see that the boundaries of the spatial grid are determined using the range of the X and Y coordinates creating a square grid. My point data do not cover the entire grid and I would only like to interpolate in areas where data exists otherwise I get a significant edge effect. Is it possible to limit / mask my interpolation to only predict where data exists? 
>>
>> The point data are lidar canopy returns for an irregular shaped timber compartment and number around 10 000 irregular spaced points. 
>>
>> Any help on this matter would be greatly appreciated.
>>
>> Kind regards,
>> Wesley
>>
>>
>> library(automap)
>> library(gstat)
>>
>> a <- read.csv("AreaOne_4pts.csv", header=TRUE)
>>
>> coordinates(a) <-~ x+y
>>
>> x.range <- as.integer(range(a at coords[,1]))
>> y.range <- as.integer(range(a at coords[,2]))
>>
>>
>> grd <- expand.grid(x=seq(from=x.range[1], to=x.range[2], by=0.1), y=seq(from=y.range[1], to=y.range[2], by=0.1))
>> coordinates(grd) <-~ x+y
>> gridded(grd) <- TRUE
>>
>> height = autoKrige(H~1, a, grd, nmax=100)
>> writeGDAL(height$krige_output, fname="test.tiff", drivername ="GTiff", type = "Float32")
>>
>> intensity = autoKrige(I~1, a, grd, nmax=100)
>> writeGDAL(intensity$krige_output, fname="test.tiff", drivername ="GTiff", type = "Float32")
>>
>> Wesley Roberts MSc.
>> Researcher: Earth Observation (Ecosystems)
>> Natural Resources and the Environment
>> CSIR
>> Tel: +27 (21) 888-2490
>> Fax: +27 (21) 888-2693
>>
>> "To know the road ahead, ask those coming back."
>> - Chinese proverb
>>
>>
>>   
>>     
>
>
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul



-- 
This message is subject to the CSIR's copyright terms and conditions, e-mail legal notice, and implemented Open Document Format (ODF) standard. 
The full disclaimer details can be found at http://www.csir.co.za/disclaimer.html.


and is believed to be clean.  MailScanner thanks Transtec Computers for their support.


From srinivasraghav at gmail.com  Mon Feb 16 11:46:30 2009
From: srinivasraghav at gmail.com (srinivasa raghavan)
Date: Mon, 16 Feb 2009 05:46:30 -0500
Subject: [R-sig-Geo] Personal invitation from srinivasa raghavan
Message-ID: <20090216054630.-759877211@unyk.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090216/4369dcac/attachment.pl>

From p.hiemstra at geo.uu.nl  Mon Feb 16 11:47:16 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 16 Feb 2009 11:47:16 +0100
Subject: [R-sig-Geo] Masking interpolations
In-Reply-To: <49995D4402000073000188BD@pta-emo.csir.co.za>
References: <49995D4402000073000188BD@pta-emo.csir.co.za>
Message-ID: <49994434.8000605@geo.uu.nl>

Hi,

If you want to use the standard convex hull of automap, just omit the 
new_data argument. That will stuff 5000 points into the convexhull on a 
regular grid. If you want to specify the pixelsize you need to adapt the 
create_new_data function like this:

create_new_data = function(obj) {
# Function that creates a new_data object if one is missing
        convex_hull = chull(coordinates(obj)[,1],coordinates(obj)[,2])
        convex_hull = c(convex_hull, convex_hull[1]) # Close the polygon
        d = Polygon(obj[convex_hull,])
	# This line is different, in addition I assume that your coordinates are in meters
        new_data = spsample(d, type = "regular", cellsize = 10e-2)
        gridded(new_data) = TRUE
        return(new_data)
}

# perform the interpolation
kr = autoKrige(I~1, a, create_new_data(a), nmax=100)

cheers,
Paul

Wesley Roberts wrote:
> Excellent, that will help alot. I have the newest version of automap and am running an experiment now. 
>
> Just to confirm I need to omit the statement 'grd(new_data argument)' which in my case is 'gridded(grd) <- TRUE'. That way the resolution is defined in x.range <- ..... and y.range <- ..... statements but the entire grid (square) is not defined and thus interpolation only occurs where data exists?
>   
You need to either omit the grd part from the call to autoKrige or use 
the new function I showed above.
> Wesley
>
>
> Wesley Roberts MSc.
> Researcher: Earth Observation (Ecosystems)
> Natural Resources and the Environment
> CSIR
> Tel: +27 (21) 888-2490
> Fax: +27 (21) 888-2693
>
> "To know the road ahead, ask those coming back."
> - Chinese proverb
>
>   
>>>> Paul Hiemstra <p.hiemstra at geo.uu.nl> 02/16/09 12:08 PM >>>
>>>>         
> Hi,
>
> A convex hull should do the trick, if you have the latest automap 
> version (>0.5-2) you don't have do to anything to get a convex hull. 
> Just omit grd (new_data argument) and automap will automatically use a 
> convex hull.
>
> cheers,
> Paul
>
> Wesley Roberts wrote:
>   
>> Hi Paul,
>>
>> Many thanks for the reply. I am not sure about the convex hull approach as I am not sure how to implement it as part of my program. Is the code you wrote below replacing the following statements? Would I then pass grd to the autoKrige statement as shown in the original code below?
>>
>> ************************************************************************************************************************************************************************************************************
>>   
>>     
>>> x.range <- as.integer(range(a at coords[,1]))
>>> y.range <- as.integer(range(a at coords[,2]))
>>> grd <- expand.grid(x=seq(from=x.range[1], to=x.range[2], by=0.1), y=seq(from=y.range[1], to=y.range[2], by=0.1))
>>> coordinates(grd) <-~ x+y
>>> gridded(grd) <- TRUE
>>>     
>>>       
>> ************************************************************************************************************************************************************************************************************
>>
>> I have uploaded some pics of my points and interpolations to flickr. 
>>
>> Link 1 shows the timber compartment with the lidar points overlayed and the bounding polygon used to subset the point data set. You cant really see the irregularity of the points but trust me, they are all over the place. Average distance between points is about 17cm so a 10cm interpolation resolution should be okay. 
>> Link 1
>> http://www.flickr.com/photos/35273872 at N07/3283623165/
>>
>> Link 2, is the height interpolation using the parameters you suggested on Friday. As you can see the lack of points outside the polygon results in a type of edge effect at the boundaries. I can mask the rest out but would prefer to limit the interpolation to minimize errors at the boundaries.
>> Link 2
>> http://www.flickr.com/photos/35273872 at N07/3283623941/
>>
>> Finally link 3 shows what I think is the kriging variance although I cant be sure. When I import the tiff written by writeGDAL there are three bands (using GRASS). The first is the interpolated variable, the next two are a mystery to me. If this is indeed the krig variance then limiting the interpolation based on kriging variance seems like a good idea? What do you think?
>> Link 3
>> http://www.flickr.com/photos/35273872 at N07/3284446466/
>>   
>>     
> This is indeed the kriging variance.
>   
>> Many thanks,
>> Wesley
>>
>> Wesley Roberts MSc.
>> Researcher: Earth Observation (Ecosystems)
>> Natural Resources and the Environment
>> CSIR
>> Tel: +27 (21) 888-2490
>> Fax: +27 (21) 888-2693
>>
>> "To know the road ahead, ask those coming back."
>> - Chinese proverb
>>
>>   
>>     
>>>>> Paul Hiemstra <p.hiemstra at geo.uu.nl> 02/16/09 10:29 AM >>>
>>>>>         
>>>>>           
>> Hi Wesley,
>>
>> You could take a look at using a convex hull. I'm not sure if this will 
>> fix your problem as we cannot see how exactly your points are irregular. 
>> The latest version on my website (0.5-2) uses a convex hull off the data 
>> if you don't pass a new_data object. You could try this. The function 
>> making the convex hull is:
>>
>> create_new_data = function(obj) {
>> # Function that creates a new_data object if one is missing
>>         convex_hull = chull(coordinates(obj)[,1],coordinates(obj)[,2])
>>         convex_hull = c(convex_hull, convex_hull[1]) # Close the polygon
>>         d = Polygon(obj[convex_hull,])
>>         new_data = spsample(d, 5000, type = "regular")
>>         gridded(new_data) = TRUE
>>         return(new_data)
>> }
>>
>> If you want to call it directly from the package use 
>> automap:::create_new_data.
>>
>> cheers,
>> Paul
>>
>> Wesley Roberts wrote:
>>   
>>     
>>> Dear R-sig-geo'ers
>>>
>>> I am currently running some interpolations using automap written by Paul Hiemstra. So far my interpolations have been producing suitable results except for one problem. From the code you will see that the boundaries of the spatial grid are determined using the range of the X and Y coordinates creating a square grid. My point data do not cover the entire grid and I would only like to interpolate in areas where data exists otherwise I get a significant edge effect. Is it possible to limit / mask my interpolation to only predict where data exists? 
>>>
>>> The point data are lidar canopy returns for an irregular shaped timber compartment and number around 10 000 irregular spaced points. 
>>>
>>> Any help on this matter would be greatly appreciated.
>>>
>>> Kind regards,
>>> Wesley
>>>
>>>
>>> library(automap)
>>> library(gstat)
>>>
>>> a <- read.csv("AreaOne_4pts.csv", header=TRUE)
>>>
>>> coordinates(a) <-~ x+y
>>>
>>> x.range <- as.integer(range(a at coords[,1]))
>>> y.range <- as.integer(range(a at coords[,2]))
>>>
>>>
>>> grd <- expand.grid(x=seq(from=x.range[1], to=x.range[2], by=0.1), y=seq(from=y.range[1], to=y.range[2], by=0.1))
>>> coordinates(grd) <-~ x+y
>>> gridded(grd) <- TRUE
>>>
>>> height = autoKrige(H~1, a, grd, nmax=100)
>>> writeGDAL(height$krige_output, fname="test.tiff", drivername ="GTiff", type = "Float32")
>>>
>>> intensity = autoKrige(I~1, a, grd, nmax=100)
>>> writeGDAL(intensity$krige_output, fname="test.tiff", drivername ="GTiff", type = "Float32")
>>>
>>> Wesley Roberts MSc.
>>> Researcher: Earth Observation (Ecosystems)
>>> Natural Resources and the Environment
>>> CSIR
>>> Tel: +27 (21) 888-2490
>>> Fax: +27 (21) 888-2693
>>>
>>> "To know the road ahead, ask those coming back."
>>> - Chinese proverb
>>>
>>>
>>>   
>>>     
>>>       
>>   
>>     
>
>
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul


From wroberts at csir.co.za  Mon Feb 16 13:34:56 2009
From: wroberts at csir.co.za (Wesley Roberts)
Date: Mon, 16 Feb 2009 14:34:56 +0200
Subject: [R-sig-Geo] Masking interpolations
Message-ID: <499979900200007300018910@pta-emo.csir.co.za>

Hi Paul,

I have managed to get the code to run and have figured out what the function does. Many thanks, it should do exactly what I need. Unfortunately I have now run into another problem. The code appears to run properly until the error below appears.

.
.
.
.
60963 (-76170.4, -3300950) 20.0659 113
60984 (-76184.3, -3301000) 21.3390 126
61052 (-76198.2, -3301000) 19.0052 158
Error in while (is.null(res) && its < iter && n_is > 0 && ifelse(type ==  : 
  missing value where TRUE/FALSE needed
>

Had a look at "google" and got no luck. The problem seems to be an internal coding, not sure if you have seen this before?

Wesley

Wesley Roberts MSc.
Researcher: Earth Observation (Ecosystems)
Natural Resources and the Environment
CSIR
Tel: +27 (21) 888-2490
Fax: +27 (21) 888-2693

"To know the road ahead, ask those coming back."
- Chinese proverb


-- 
This message is subject to the CSIR's copyright terms and conditions, e-mail legal notice, and implemented Open Document Format (ODF) standard. 
The full disclaimer details can be found at http://www.csir.co.za/disclaimer.html.

This message has been scanned for viruses and dangerous content by MailScanner, 
and is believed to be clean.  MailScanner thanks Transtec Computers for their support.


From p.hiemstra at geo.uu.nl  Mon Feb 16 13:55:38 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 16 Feb 2009 13:55:38 +0100
Subject: [R-sig-Geo] Masking interpolations
In-Reply-To: <499979900200007300018910@pta-emo.csir.co.za>
References: <499979900200007300018910@pta-emo.csir.co.za>
Message-ID: <4999624A.8010208@geo.uu.nl>

Hi,

Could you provide us with some reproducible code? In addition, look at 
the output of traceback() to get more info on what exactly went wrong.

cheers
Paul,

Wesley Roberts wrote:
> Hi Paul,
>
> I have managed to get the code to run and have figured out what the function does. Many thanks, it should do exactly what I need. Unfortunately I have now run into another problem. The code appears to run properly until the error below appears.
>
> .
> .
> .
> .
> 60963 (-76170.4, -3300950) 20.0659 113
> 60984 (-76184.3, -3301000) 21.3390 126
> 61052 (-76198.2, -3301000) 19.0052 158
> Error in while (is.null(res) && its < iter && n_is > 0 && ifelse(type ==  : 
>   missing value where TRUE/FALSE needed
>   
>
> Had a look at "google" and got no luck. The problem seems to be an internal coding, not sure if you have seen this before?
>
> Wesley
>
> Wesley Roberts MSc.
> Researcher: Earth Observation (Ecosystems)
> Natural Resources and the Environment
> CSIR
> Tel: +27 (21) 888-2490
> Fax: +27 (21) 888-2693
>
> "To know the road ahead, ask those coming back."
> - Chinese proverb
>
>
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul


From nikko at hailmail.net  Mon Feb 16 17:26:50 2009
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Mon, 16 Feb 2009 08:26:50 -0800
Subject: [R-sig-Geo] Point pattern analysis
In-Reply-To: <mailman.9.1234782003.11182.r-sig-geo@stat.math.ethz.ch>
References: <mailman.9.1234782003.11182.r-sig-geo@stat.math.ethz.ch>
Message-ID: <1234801610.31587.1300665155@webmail.messagingengine.com>

Hi,
Yes, if you need help rating restaurants, put me in your grant too :-)
Seriously, there are many ways to skin a cat. I don't think cartograms
will help you much
in this particular case. If you have data besides your point pattern, eg
postal codes, census data,
zoning, ... You could look for the obvious patterns, eg Italian
restaurants clustered in little Italy,
and Chinese in china town, and then look for the more interesting not so
obvious patterns. 

But from your description, it seems like there might be other questions
that should guide your analysis.
Context should drive your exploration of the data.

As Virgilo pointed out you won't get much milage plotting 10000 points.
You need some way of aggregating.
Glyphs might be one way if you have some polygonal unit that makes
sense, such as census blocks. I am not a big
fan of pie charts, but if you have only a few categories they my show a
pattern. Kernel density estimation is limited,
it will show you the spatial distribution of one particular type. 

Another route that might be interesting is if you have street maps, look
at clustering of restaurants on different
streets. It may show interesting patterns, ie fast food clustered near
freeways and walmarts.

The sky is the limit. Once you have done a lot of this more basic EDA,
than think about what kind of analytical
methods you want to use to address specific questions. You are more
likely to get what you want. You might
want to look at flowingdata.com there are some nice map visualizations
there.

Nicholas







> ------------------------------
> 
> Message: 10
> Date: Sun, 15 Feb 2009 22:17:29 +0100
> From: Virgilio Gomez Rubio <Virgilio.Gomez at uclm.es>
> Subject: Re: [R-sig-Geo] Point pattern analysis
> To: Michel Barbosa <cicaboo at gmail.com>
> Cc: r-sig-geo at stat.math.ethz.ch
> Message-ID: <1234732649.8833.84.camel at Virgilio-Gomez>
> Content-Type: text/plain
> 
> Dear Michel,
> 
> > I'm new to Spatial Data Analysis and have just begun working through
> > "Applied Spatial Data Analysis wit R" by Bivand et al. For my research I
> > would like to use SDA to be able to tell more about my restaurant data set
> > than just pinpointing them on a google map. So far, from reading the
> > literature on SDA I've been able to construct the following questions.
> 
> Interesting problem. Let me know if you need help collecting data. ;)
> 
> > 
> > 1. How far / close are restaurants from each other? (answered by using
> > kernel density estimation)
> > 2. Which type of restaurants stand next to each other?
> > 3. How are the restaurants positioned relatlivey from each other?
> > 4. What's the difference between restaurant A and restaurant B?
> 
> 
> Questions 2 and 3 are much alike, and I believe that question 4 is too
> general and not necessarily about the spatial distribution of the
> restaurants.
> 
> Depending on the number of different types of restaurants, you may want
> to estimate a different surface for each type. Basically, you may
> consider a multivariate point pattern, so that you estimate a different
> surface for each type and  you compare then to see if they are similar
> or not. This will address the question of whether the spatial
> distribution of different types of restaurants is the same or not. This
> is discussed in Diggle et al. (2005, JRSS Series A). Some of the methods
> described in the paper are implemented in package spatialkernel. 
> 
> You may also want to compute bivariate K-functions (see 'k12hat' in
> splancs; 'Kmulti' in spatstat) to detect differences between the spatial
> distributions of types of restaurants. This will give you a partial
> answer to Question 2.
> 
> If you have a set of covariates for each restaurant and you want to
> estimate their effect and how they explain the spatial distribution of
> the data you can check Diggle et al. (2006, Biometrics). There is also
> an example of this in Bivand et al. (2008).
> 
> I am not sure about the best way of tackling Question 3 (and why this is
> important). Have you considered to test for whether a certain type of
> restaurant tends to appear around a particular area of the city? For
> example, are Chinese restaurants clustered around Chinatown?
> 
> Finally, another option is to aggregate your data (counts per
> neighbourhood, for example) and do a similar analysis as in disease
> mapping.
> 
> > I've exported a subset of my dataset to CSV in order to import it in R.
> > Currently, my CSV file is of the form
> > 
> > *restaurant name; latitude; longitude; type*
> > Amigo;52.996058;6.564229;Italian
> > Bella Italia;52.99281;6.560353;Italian
> > Isola Bella;52.993764;6.560245;Italian
> 
> I would not use long/lat but UTM to do your analysis. You can do this
> very easily with R.
> 
> > 
> > I've tried to import the CSV in R by doing:
> > 
> > library(spatstat)
> > info <- read.csv(file = "sample.csv", sep = ";", strip.white = TRUE)
> > win <- owin(c(0,100),c(0,100))
> > pattern <- ppp(info$lat, info$lng, window = win, marks=info$name)
> > 
> > However, if I plot the pattern, the points are all cluttered. What advice
> > could you give me on setting the window size?
> 
> If you try to plot more than 10,000 points, then I am not surprised that
> they are all cluttered. :) I would plot the estimated intensity of the
> point patterns. Or you may aggregate your data and produce a map based
> on the neighbourhoods in your area.
> 
> Hope this helps.
> 
> Virgilio
> 
>


From T.Hengl at uva.nl  Mon Feb 16 20:41:35 2009
From: T.Hengl at uva.nl (Hengl, T.)
Date: Mon, 16 Feb 2009 20:41:35 +0100
Subject: [R-sig-Geo] GEOSTAT 2009 Summer School, 3-10 May 2009 MEDILS, Split,
	Croatia
References: <49995D4402000073000188BD@pta-emo.csir.co.za>
Message-ID: <37382E8DCB905042969BA78541F6570624D6BC@kwek.ic.uva.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090216/703afa72/attachment.pl>

From Mitze at gefra-muenster.de  Mon Feb 16 21:39:36 2009
From: Mitze at gefra-muenster.de (Timo Mitze)
Date: Mon, 16 Feb 2009 21:39:36 +0100
Subject: [R-sig-Geo] SpatialFiltering in spdep: How to create an 'nb'
	object from an imported spatial weights matrix
Message-ID: <1ADF70DB48DC0A44869DCBE27D4627F1176D34@TATOOINE.gefra-muenster.de>

Dear Roger,

it works now, many Thanks!

Timo 

-----Urspr?ngliche Nachricht-----
Von: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Gesendet: Sonntag, 15. Februar 2009 23:00
An: Timo Mitze
Cc: r-sig-geo at stat.math.ethz.ch
Betreff: Re: AW: [R-sig-Geo] SpatialFiltering in spdep: How to create an 'nb' object from an imported spatial weights matrix

On Sun, 15 Feb 2009, Timo Mitze wrote:

> Dear Roger and List,
>
> thanks for your advice. I tried it with the code as (as well as some related with different style parameter etc.):
>
> ********************************
> x <- mat2listw(mat)
> lw <- nb2listw(x$neighbours, style="B", zero.policy=TRUE) migfilt <- 
> SpatialFiltering(lnmr_i ~ 1, data=migration_spatial, nb=lw, style="B", 
> ExactEV=TRUE, zero.policy=TRUE)
> ********************************
>
> ... but unfortunately (always) got the following error message:
>
> ********************************
> Fehler in card(neighbours) :
>  INTEGER() can only be applied to a 'integer', not a 'character'
> ********************************
>
> Can it be the problem the the nb object is still missing, since I try 
> to directly create a listw object?

x$neighbours is the nb object, just use that.

Roger

>
> According to Yongwan Chun (one of the author of Spatial Filtering), 
> the routines needs an nb and NOT(!!!) a listw object. Can I generate 
> such an nb object from my binary 240x240 matrix?
>
> Greetings,
>
> Timo
>
>
> -----Urspr?ngliche Nachricht-----
> Von: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Gesendet: Sonntag, 15. Februar 2009 13:31
> An: Timo Mitze
> Cc: r-sig-geo at stat.math.ethz.ch
> Betreff: Re: [R-sig-Geo] SpatialFiltering in spdep: How to create an 
> 'nb' object from an imported spatial weights matrix
>
> On Sat, 14 Feb 2009, Timo Mitze wrote:
>
>> Dear List,
>>
>> I have a complete (distance/border based binary) spatial weights 
>> matrix from Stata (e.g. as a txt-file).
>
> Try using read.dta() in foreign of the exported Stata matrix. This reads a data.frame, which you coerce to an R matrix with as.matrix().
>
>> I want to apply spatial filtering in
>> spdep, however the routine needs an "nb" object. Is there any way to 
>> extract the information from my matrix automatically (something like 
>> mat2nb ???) or do I have to edit the "nb" object by hand? (e.g. in 
>> terms of creating a GAL file by any text editor and then use 
>> "read.gal" option
>> - this strategy would mean a lot of work since I have a 240 x 240 
>> matrix). I'd be happy about any help.
>
> Next use mat2listw() in spdep to convert to a listw object, finally using:
>
> x <- mat2listw(mat)
> lw <- nb2listw(x$neighbours, glist=x$weights, style="?")
>
> where ? is your choice of style. mat2listw() just does the 
> convsersion, assigning a style of "M", which may not be recognised by 
> model fitting functions. Drop the glist= argument if the weights are 
> without importance
> - as I understand they are from your description of them as binary.
>
> Hope this helps,
>
> Roger
>
>>
>> Best wishes,
>>
>> Timo
>>
>> P.S.: I have tried it with a spatial weights matrix in spdep 
>> (mat2listw), but it does not work - see my code below:
>>
>> ****************************************************
>>
>> #### Code for Griffith Eigenvector Filtering ###
>>
>>
>>
>> library(spdep)
>>
>>
>>
>> migration_spatial <-
>> read.table("C:/migration_laptop/spdep_migration.txt", header=TRUE, 
>> sep="\t", na.strings="NA", dec=".", strip.white=TRUE)
>>
>>
>>
>> summary(migration_spatial)
>>
>>
>>
>> mat = matrix(0, 240, 240)
>>
>>
>>
>> mat[row(mat) >= col(mat)] <-
>> scan("C:/migration_laptop/spdep_Wmat_Chun_border.txt")
>>
>>
>>
>> # not sure if the following is needed :
>>
>>
>>
>> mat <- mat + t(mat)
>>
>>
>>
>> list(mat)
>>
>>
>>
>> migmat.listw <- mat2listw(mat)
>>
>>
>>
>> migmat.listw
>>
>>
>>
>> migfilt <- SpatialFiltering(lnmr_i ~ lnmr_i_lag1 + ldwager_ij_lag1 +
>> ldur_ij_lag1 + ldyrl_ij_fd_lag1 + ldq_ij_lag1 + ldpland_ij_lag1 + 
>> ldhc6_ij_lag1, data=migration_spatial, nb=migmat.listw, style="W", 
>> ExactEV=TRUE, zero.policy=TRUE)
>>
>>
>>
>> ****************************************************
>>
>>
>>
>>
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School 
> of Economics and Business Administration, Helleveien 30, N-5045 
> Bergen, Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>
>
>
>

--
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of Economics and Business Administration, Helleveien 30, N-5045 Bergen, Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From tomp at infra.kth.se  Tue Feb 17 00:41:05 2009
From: tomp at infra.kth.se (Tom Petersen)
Date: Tue, 17 Feb 2009 00:41:05 +0100
Subject: [R-sig-Geo] Point pattern analysis
In-Reply-To: <1234732649.8833.84.camel@Virgilio-Gomez>
References: <f7f7b86f0902150636v6aac9cddn19816c337902c37f@mail.gmail.com>
	<1234732649.8833.84.camel@Virgilio-Gomez>
Message-ID: <1234827665.4999f9914ab5d@mail.infra.kth.se>

Michael,

Although your points might seem cluttered (are there reasons to believe that
they shouldn't be?), you should still check what your spatial resolution is,
and if there are several restaurants occupying the same coordinates - in that
case, only the first one will be considered on import. I experienced that in
spatstat with my dataset with a resolution of 250 m.

If this is the case, one solution is to "wiggle" the data by adding uniform
random disturbances to both coordinates, with amplitude = half the resolution
(e.g. in my case a uniform distribution over [-125,125]).

/Tom
============================
Tom Petersen
Transport- och lokaliseringsanalys
Skolan f?r arkitektur och samh?llsbyggnad
Teknikringen 78 B
KTH, 100 44 Stockholm
Tfn 08-790 68 33, 070-424 00 75



Citerar Virgilio Gomez Rubio <Virgilio.Gomez at uclm.es>:

> Dear Michel,
> 
> > I'm new to Spatial Data Analysis and have just begun working through
> > "Applied Spatial Data Analysis wit R" by Bivand et al. For my research I
> > would like to use SDA to be able to tell more about my restaurant data set
> > than just pinpointing them on a google map. So far, from reading the
> > literature on SDA I've been able to construct the following questions.
> 
> Interesting problem. Let me know if you need help collecting data. ;)
> 
> > 
> > 1. How far / close are restaurants from each other? (answered by using
> > kernel density estimation)
> > 2. Which type of restaurants stand next to each other?
> > 3. How are the restaurants positioned relatlivey from each other?
> > 4. What's the difference between restaurant A and restaurant B?
> 
> 
> Questions 2 and 3 are much alike, and I believe that question 4 is too
> general and not necessarily about the spatial distribution of the
> restaurants.
> 
> Depending on the number of different types of restaurants, you may want
> to estimate a different surface for each type. Basically, you may
> consider a multivariate point pattern, so that you estimate a different
> surface for each type and  you compare then to see if they are similar
> or not. This will address the question of whether the spatial
> distribution of different types of restaurants is the same or not. This
> is discussed in Diggle et al. (2005, JRSS Series A). Some of the methods
> described in the paper are implemented in package spatialkernel. 
> 
> You may also want to compute bivariate K-functions (see 'k12hat' in
> splancs; 'Kmulti' in spatstat) to detect differences between the spatial
> distributions of types of restaurants. This will give you a partial
> answer to Question 2.
> 
> If you have a set of covariates for each restaurant and you want to
> estimate their effect and how they explain the spatial distribution of
> the data you can check Diggle et al. (2006, Biometrics). There is also
> an example of this in Bivand et al. (2008).
> 
> I am not sure about the best way of tackling Question 3 (and why this is
> important). Have you considered to test for whether a certain type of
> restaurant tends to appear around a particular area of the city? For
> example, are Chinese restaurants clustered around Chinatown?
> 
> Finally, another option is to aggregate your data (counts per
> neighbourhood, for example) and do a similar analysis as in disease
> mapping.
> 
> > I've exported a subset of my dataset to CSV in order to import it in R.
> > Currently, my CSV file is of the form
> > 
> > *restaurant name; latitude; longitude; type*
> > Amigo;52.996058;6.564229;Italian
> > Bella Italia;52.99281;6.560353;Italian
> > Isola Bella;52.993764;6.560245;Italian
> 
> I would not use long/lat but UTM to do your analysis. You can do this
> very easily with R.
> 
> > 
> > I've tried to import the CSV in R by doing:
> > 
> > library(spatstat)
> > info <- read.csv(file = "sample.csv", sep = ";", strip.white = TRUE)
> > win <- owin(c(0,100),c(0,100))
> > pattern <- ppp(info$lat, info$lng, window = win, marks=info$name)
> > 
> > However, if I plot the pattern, the points are all cluttered. What advice
> > could you give me on setting the window size?
> 
> If you try to plot more than 10,000 points, then I am not surprised that
> they are all cluttered. :) I would plot the estimated intensity of the
> point patterns. Or you may aggregate your data and produce a map based
> on the neighbourhoods in your area.
> 
> Hope this helps.
> 
> Virgilio
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From cicaboo at gmail.com  Tue Feb 17 02:26:43 2009
From: cicaboo at gmail.com (Michel Barbosa)
Date: Tue, 17 Feb 2009 02:26:43 +0100
Subject: [R-sig-Geo] Point pattern analysis
In-Reply-To: <1234732649.8833.84.camel@Virgilio-Gomez>
References: <f7f7b86f0902150636v6aac9cddn19816c337902c37f@mail.gmail.com>
	<1234732649.8833.84.camel@Virgilio-Gomez>
Message-ID: <f7f7b86f0902161726w2481eddfx8acfc3ce737335a6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090217/ece59099/attachment.pl>

From cicaboo at gmail.com  Tue Feb 17 02:40:38 2009
From: cicaboo at gmail.com (Michel Barbosa)
Date: Tue, 17 Feb 2009 02:40:38 +0100
Subject: [R-sig-Geo] Point pattern analysis
In-Reply-To: <1234801610.31587.1300665155@webmail.messagingengine.com>
References: <mailman.9.1234782003.11182.r-sig-geo@stat.math.ethz.ch>
	<1234801610.31587.1300665155@webmail.messagingengine.com>
Message-ID: <f7f7b86f0902161740h71926df7oce26400aadfa4d30@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090217/f9155487/attachment.pl>

From cicaboo at gmail.com  Tue Feb 17 02:47:16 2009
From: cicaboo at gmail.com (Michel Barbosa)
Date: Tue, 17 Feb 2009 02:47:16 +0100
Subject: [R-sig-Geo] Point pattern analysis
In-Reply-To: <1234827665.4999f9914ab5d@mail.infra.kth.se>
References: <f7f7b86f0902150636v6aac9cddn19816c337902c37f@mail.gmail.com>
	<1234732649.8833.84.camel@Virgilio-Gomez>
	<1234827665.4999f9914ab5d@mail.infra.kth.se>
Message-ID: <f7f7b86f0902161747k690bc34dhefbecce6dfa2e6fd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090217/0f350154/attachment.pl>

From j.burke at earthlink.net  Tue Feb 17 06:13:18 2009
From: j.burke at earthlink.net (Jim Burke)
Date: Mon, 16 Feb 2009 23:13:18 -0600
Subject: [R-sig-Geo] Intersect & Plot a Polygon and wkbLineString
Message-ID: <499A476E.5050304@earthlink.net>

I have a nice solid SpatialPologonsDataFrame and a new line file 
(wkbLineString) called "major roads.shp".

MY QUESTIONS.

*I would appreciate examples of*

*a)How to merge the intersection of a **SpatialPologonsDataFrame and a 
wkbLineString **

b)How to plot the result 

c)How to display the street name on the plot (that's FNAME from the 
major roads.dbf file).
*


ADDITIONAL INFORMATION.

The SpatialPologonsDataFrame is a garden variety collection of 
geographical polygons. 

 > tx1_sp <- readShapePoly("precinct08.shp", IDvar="PCT", 
proj4string=CRS("+proj=aea +ellps=GRS80 +datum=WGS84"))



The new file to intersect merge is major roads line map that should 
overlay part of my SpatialPolygons. It does not behave like a Shapfile.

 >main_roads <-readOGR("main roads.shp", layer = "main roads")
OGR data source with driver: ESRI Shapefile
Source: "main roads.shp", layer: "main roads"
with  29161  rows and  33  columns
Feature type: wkbLineString with 2 dimensions


Thanks,
Jim Burke


From j.burke at earthlink.net  Tue Feb 17 06:25:43 2009
From: j.burke at earthlink.net (Jim Burke)
Date: Mon, 16 Feb 2009 23:25:43 -0600
Subject: [R-sig-Geo] Intersect & Plot a Polygon and wkbLineString
In-Reply-To: <499A476E.5050304@earthlink.net>
References: <499A476E.5050304@earthlink.net>
Message-ID: <499A4A57.4030908@earthlink.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090216/82e5b9d7/attachment.pl>

From Virgilio.Gomez at uclm.es  Tue Feb 17 09:22:29 2009
From: Virgilio.Gomez at uclm.es (Virgilio Gomez Rubio)
Date: Tue, 17 Feb 2009 09:22:29 +0100
Subject: [R-sig-Geo] Point pattern analysis
In-Reply-To: <f7f7b86f0902161724j5f67bbaeo7400856fd899079@mail.gmail.com>
References: <f7f7b86f0902150636v6aac9cddn19816c337902c37f@mail.gmail.com>
	<1234732649.8833.84.camel@Virgilio-Gomez>
	<f7f7b86f0902161724j5f67bbaeo7400856fd899079@mail.gmail.com>
Message-ID: <1234858949.7265.13.camel@Virgilio-Gomez>

Hi,


> Thanks :) Actually, I'm busy with developing a Location-Based Service
> (a restaurant finder to be precise) utilising SDA. The goal of my
> research is to integrate SDA in an LBS. For this purpose, I've
> gathered about 13,000 unique restaurants in the Netherlands and would
> like to use 3 SDA techniques that enhance the restaurant finder either
> visually and/or analytically. The motivation behind my research is t
> start a discussion on how SDA can be used inside LBSs to enhance the
> services. In this case, to enable users to make better decisions about
> nearby restaurants. One thing that popped in my mind was to use kernel
> density estimation and overlay it on the google/microsoft map to allow
> users to easily grasp the proximity of restaurants.

Perhaps it would be better if you aggregated your data and considered
municipalities in The Netherlands. I guess that area level maps are
easier to understand. What I mean is that your users will find more
meaningful that there are, say, 20 Indian restaurants in Nijmegen than
saying that the intensity for the Indian restaurants have a peak in the
centre of Nijmegen. Regional maps will be helpful if you have a whole
map of the country, but if you allow them to zoom in then you probably
want to show the individual locations of the restaurants.

> 
>         Depending on the number of different types of restaurants, you
>         may want
>         to estimate a different surface for each type. Basically, you
>         may
>         consider a multivariate point pattern, so that you estimate a
>         different
>         surface for each type and  you compare then to see if they are
>         similar
>         or not. This will address the question of whether the spatial
>         distribution of different types of restaurants is the same or
>         not
> 
> This is quite interesting. Would this allow me to estimate a surface
> for let's say Italian restaurants vs Greek restaurants? I have ratings

Yes, you can compare the spatial distributions of different types of
restaurants.

>  for each restaurant. So a user might want to ask "Where can I find
> good Italian restaurants in the South?" Where good is any rating above
> a 7.0 for example.

This can be more complex because then you may want to produce a map
based on the rating, and then the rating becomes the response variable
in your model...

> 
>         You may also want to compute bivariate K-functions (see
>         'k12hat' in
>         splancs; 'Kmulti' in spatstat) to detect differences between
>         the spatial
>         distributions of types of restaurants. This will give you a
>         partial
>         answer to Question 2.
> 
> Would this mean that a kmulti analysis should be applied for each
> restaurant type and thus each subset I wish to test?

You will need to consider each pair of restaurants at a time.

> 
>         Have you considered to test for whether a certain type of
>         restaurant tends to appear around a particular area of the
>         city? For
>         example, are Chinese restaurants clustered around Chinatown?
> 
> This is something I'm looking for as well. Considering the fact that
> I'm in the process of developing such an LBS, it would be something
> along the line of: A user takes out his mobile phone. He starts the
> application and the applications looks acquires a position fix. When
> this is done, a user might want to know: "What type of restaurant is
> typical for my current location or current neighbourhood. So,
> analysing whether a certain type of restaurant tends to appear around
> the CURRENT area of the city. Is this possible?

Yes, I guess that you can make a buffer of, say, 300 m around the user's
location and then display your results based on the restaurants included
in that buffer.

> Overall, thanks very much for your reply. I'm really excited about
> using these SDA techniques and am very grateful for your quick reply.
> I'll look up a copy of the papers you mentioned and will read through
> them as soon as I can. When I've successfully analysed the dataset
> with some SDA techniques I can begin the process of constructing the
> appropriate architecture for the LBS. I'll definitely keep you guys
> posted if you're interested.

That would be good. And if you get free vouchers let us now as well!! :)

Best,

Virgilio


From Roger.Bivand at nhh.no  Tue Feb 17 10:45:42 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 17 Feb 2009 10:45:42 +0100 (CET)
Subject: [R-sig-Geo] Intersect & Plot a Polygon and wkbLineString
In-Reply-To: <499A476E.5050304@earthlink.net>
References: <499A476E.5050304@earthlink.net>
Message-ID: <alpine.LRH.2.00.0902171030240.26437@reclus.nhh.no>

On Mon, 16 Feb 2009, Jim Burke wrote:

(Just stick to plain text, but don't use fonts or bold or stuff - keep it 
simple).

> I have a nice solid SpatialPologonsDataFrame and a new line file 
> (wkbLineString) called "major roads.shp".
>
> MY QUESTIONS.
>
> *I would appreciate examples of*
>
> *a)How to merge the intersection of a **SpatialPologonsDataFrame and a 
> wkbLineString **
>

Why, and what do you mean? You have some 30000 road lines, what do you 
want to know? How much of which road is in which polygon? Again, you need 
to think through your workflow. My inclination would be to rasterise the 
lines in a GIS, and overlay the raster cell centre points on the polygons, 
but maybe you want line length, or to retain the line IDs (all 30000 of 
them).


> b)How to plot the result

You can of course overplot lines on polygons, with add=TRUE in plot() 
methods and sp.layout= in spplot() methods. But plotting the result of the 
"intersection" means what?

> c)How to display the street name on the plot (that's FNAME from the major 
> roads.dbf file).

30000 names? Do you have a very large screen? Lines objects have IDs, but 
no label point, so there is no easy way of doing it, even label alignment 
is hard.

I can't actually see the statistical question here, could you please make 
it clearer?

Do you simply want to plot a subset of the road lines on your solid 
polygons, adding names? Then you need to find out how to subset them, 
perhaps by cookie-cutting using the union of your polygons, add label 
points and rotation angles (probably by hand), and off you go, but these 
are essentially GIS operations.

Roger

> *
>
>
> ADDITIONAL INFORMATION.
>
> The SpatialPologonsDataFrame is a garden variety collection of geographical 
> polygons. 
>> tx1_sp <- readShapePoly("precinct08.shp", IDvar="PCT", 
> proj4string=CRS("+proj=aea +ellps=GRS80 +datum=WGS84"))
>
>
>
> The new file to intersect merge is major roads line map that should overlay 
> part of my SpatialPolygons. It does not behave like a Shapfile.
>
>> main_roads <-readOGR("main roads.shp", layer = "main roads")
> OGR data source with driver: ESRI Shapefile
> Source: "main roads.shp", layer: "main roads"
> with  29161  rows and  33  columns
> Feature type: wkbLineString with 2 dimensions
>
>
> Thanks,
> Jim Burke
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From j.burke at earthlink.net  Tue Feb 17 14:34:53 2009
From: j.burke at earthlink.net (Jim Burke)
Date: Tue, 17 Feb 2009 07:34:53 -0600
Subject: [R-sig-Geo] Intersect & Plot a Polygon and wkbLineString
In-Reply-To: <alpine.LRH.2.00.0902171030240.26437@reclus.nhh.no>
References: <499A476E.5050304@earthlink.net>
	<alpine.LRH.2.00.0902171030240.26437@reclus.nhh.no>
Message-ID: <499ABCFD.4070003@earthlink.net>

Sorry, we seem to have misunderstood each other.  Basically I have a 
county-wide set of roads called "major roads".  Then originally I had an 
identically sized county-wide set of polygons of which I select (via R) 
a smaller than county-wide subset of adjacent polygons and plot that 
subset.

The "add = TRUE" in plot operations suggestion sounds interesting. 

Your last paragraph is indeed all I am trying to achieve.  I need a GIS 
program to do this? I thought that R might be able to clip the major 
roads file (via an intersect) to conform to the polygon shapes.

I don't know, maybe I am approaching this the wrong way (i.e. trying to 
find the SQL style intersection of these two blobs). Perhaps another 
approach may be better. I think I will do the following.

1. Plot the major roads and try to get the street names on them. No 
polygon here.

2. Overlay what's going to be the large major roads over the smaller 
polygon set. The "add = TRUE" suggestion. Thanks.

3. Figure out how to trim that major roads set.

I have your book "Applied Spatial Data Analysis with R (Use R)" on order 
and it should arrive later today. Then also I am looking forward to a 
good read of "Lattice Multivariate Visualization".

Thanks,
Jim Burke



Roger Bivand wrote:
> On Mon, 16 Feb 2009, Jim Burke wrote:
>
> (Just stick to plain text, but don't use fonts or bold or stuff - keep 
> it simple).
>
>> I have a nice solid SpatialPologonsDataFrame and a new line file 
>> (wkbLineString) called "major roads.shp".
>>
>> MY QUESTIONS.
>>
>> *I would appreciate examples of*
>>
>> *a)How to merge the intersection of a **SpatialPologonsDataFrame and 
>> a wkbLineString **
>>
>
> Why, and what do you mean? You have some 30000 road lines, what do you 
> want to know? How much of which road is in which polygon? Again, you 
> need to think through your workflow. My inclination would be to 
> rasterise the lines in a GIS, and overlay the raster cell centre 
> points on the polygons, but maybe you want line length, or to retain 
> the line IDs (all 30000 of them).
>
>
>> b)How to plot the result
>
> You can of course overplot lines on polygons, with add=TRUE in plot() 
> methods and sp.layout= in spplot() methods. But plotting the result of 
> the "intersection" means what?
>
>> c)How to display the street name on the plot (that's FNAME from the 
>> major roads.dbf file).
>
> 30000 names? Do you have a very large screen? Lines objects have IDs, 
> but no label point, so there is no easy way of doing it, even label 
> alignment is hard.
>
> I can't actually see the statistical question here, could you please 
> make it clearer?
>
> Do you simply want to plot a subset of the road lines on your solid 
> polygons, adding names? Then you need to find out how to subset them, 
> perhaps by cookie-cutting using the union of your polygons, add label 
> points and rotation angles (probably by hand), and off you go, but 
> these are essentially GIS operations.
>
> Roger
>
>> *
>>
>>
>> ADDITIONAL INFORMATION.
>>
>> The SpatialPologonsDataFrame is a garden variety collection of 
>> geographical polygons.
>>> tx1_sp <- readShapePoly("precinct08.shp", IDvar="PCT", 
>> proj4string=CRS("+proj=aea +ellps=GRS80 +datum=WGS84"))
>>
>>
>>
>> The new file to intersect merge is major roads line map that should 
>> overlay part of my SpatialPolygons. It does not behave like a Shapfile.
>>
>>> main_roads <-readOGR("main roads.shp", layer = "main roads")
>> OGR data source with driver: ESRI Shapefile
>> Source: "main roads.shp", layer: "main roads"
>> with  29161  rows and  33  columns
>> Feature type: wkbLineString with 2 dimensions
>>
>>
>> Thanks,
>> Jim Burke
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From Roger.Bivand at nhh.no  Tue Feb 17 16:38:05 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 17 Feb 2009 16:38:05 +0100 (CET)
Subject: [R-sig-Geo] Intersect & Plot a Polygon and wkbLineString
In-Reply-To: <499ABCFD.4070003@earthlink.net>
References: <499A476E.5050304@earthlink.net>
	<alpine.LRH.2.00.0902171030240.26437@reclus.nhh.no>
	<499ABCFD.4070003@earthlink.net>
Message-ID: <alpine.LRH.2.00.0902171552570.27359@reclus.nhh.no>

On Tue, 17 Feb 2009, Jim Burke wrote:

> Sorry, we seem to have misunderstood each other.  Basically I have a 
> county-wide set of roads called "major roads".  Then originally I had an 
> identically sized county-wide set of polygons of which I select (via R) 
> a smaller than county-wide subset of adjacent polygons and plot that 
> subset.
>
> The "add = TRUE" in plot operations suggestion sounds interesting. Your 
> last paragraph is indeed all I am trying to achieve.  I need a GIS 
> program to do this? I thought that R might be able to clip the major 
> roads file (via an intersect) to conform to the polygon shapes.

Thanks, that is clearer. There is some support for polygon clipping in the 
gpclib package, that other packages also use, but not for lines.

>
> I don't know, maybe I am approaching this the wrong way (i.e. trying to 
> find the SQL style intersection of these two blobs). Perhaps another 
> approach may be better. I think I will do the following.
>
> 1. Plot the major roads and try to get the street names on them. No 
> polygon here.

OK, perhaps using xlim= and ylim= to "zoom" in on the view, and locator() 
to choose the label points. Maybe with locator(2) and a bit of 
trigonometry, you could get a label point and an angle. But 30000 is a 
lot for heads-up digitizing.

You might start with some ideas like:

library(maptools)
fylk <- readShapeSpatial(system.file("shapes/fylk-val.shp", package =
   "maptools"))
library(spatstat)
y <- as(fylk, "SpatialLines")
z <- as(y, "psp")
plot(z)
zz <- midpoints.psp(z)
plot(zz, add=TRUE, col="green", pch=3, cex=0.2)
df <- data.frame(x=zz$x, y=zz$y, seg=z$mark)
table(df$seg)

gives a range of segment midpoints - where the discrete values of df$seg 
would indicate which Lines object (FNAME) they correspond to. If there is 
only one, you're OK, if more, maybe choose a central one. They you could 
use text() with the coordinates of the midpoints, one for each FNAME 
object, which would show you where you are roughly. Choosing the midpoints 
ought to keep you away from the junctions. If the roads are gridded, the 
angles will be regular, otherwise that'll need some attention.

>
> 2. Overlay what's going to be the large major roads over the smaller 
> polygon set. The "add = TRUE" suggestion. Thanks.
>

That means working out which of your 30000 constitute the large major 
roads - if you have an attribute, you can perhaps subset to those roads 
first?

> 3. Figure out how to trim that major roads set.
>

You could coerce the polygons to SpatialLines, and go out to psp in 
spatstat as above. Then you have crossing.psp which shows where two psp 
objects cross, but as far as I can see no indication of which segments 
cross, so you'd need to subset those.

zzz <- psp(20000, 6600000, 1060000, 7700000, window=zz$window)
plot(zzz, add=TRUE, col="red")
crossing.psp(zzz, z)
plot(crossing.psp(zzz, z), add=TRUE, col="blue", pch=3)

Use unionSpatialPolygons() in maptools to make a cookie cutter from the 
external boundary of the polygons, then you only need to loop over the 
roads and find out which segment needs the point inserted, cutting it 
there. Another possibility is to fake it by taking the complement of the 
outer edge of the polygons, and over-plot that, painting over the roads.

Hope this helps,

Roger


> I have your book "Applied Spatial Data Analysis with R (Use R)" on order 
> and it should arrive later today. Then also I am looking forward to a 
> good read of "Lattice Multivariate Visualization".
>
> Thanks,
> Jim Burke
>
>
>
> Roger Bivand wrote:
>> On Mon, 16 Feb 2009, Jim Burke wrote:
>> 
>> (Just stick to plain text, but don't use fonts or bold or stuff - keep it 
>> simple).
>> 
>>> I have a nice solid SpatialPologonsDataFrame and a new line file 
>>> (wkbLineString) called "major roads.shp".
>>> 
>>> MY QUESTIONS.
>>> 
>>> *I would appreciate examples of*
>>> 
>>> *a)How to merge the intersection of a **SpatialPologonsDataFrame and a 
>>> wkbLineString **
>>> 
>> 
>> Why, and what do you mean? You have some 30000 road lines, what do you want 
>> to know? How much of which road is in which polygon? Again, you need to 
>> think through your workflow. My inclination would be to rasterise the lines 
>> in a GIS, and overlay the raster cell centre points on the polygons, but 
>> maybe you want line length, or to retain the line IDs (all 30000 of them).
>> 
>> 
>>> b)How to plot the result
>> 
>> You can of course overplot lines on polygons, with add=TRUE in plot() 
>> methods and sp.layout= in spplot() methods. But plotting the result of the 
>> "intersection" means what?
>> 
>>> c)How to display the street name on the plot (that's FNAME from the major 
>>> roads.dbf file).
>> 
>> 30000 names? Do you have a very large screen? Lines objects have IDs, but 
>> no label point, so there is no easy way of doing it, even label alignment 
>> is hard.
>> 
>> I can't actually see the statistical question here, could you please make 
>> it clearer?
>> 
>> Do you simply want to plot a subset of the road lines on your solid 
>> polygons, adding names? Then you need to find out how to subset them, 
>> perhaps by cookie-cutting using the union of your polygons, add label 
>> points and rotation angles (probably by hand), and off you go, but these 
>> are essentially GIS operations.
>> 
>> Roger
>> 
>>> *
>>> 
>>> 
>>> ADDITIONAL INFORMATION.
>>> 
>>> The SpatialPologonsDataFrame is a garden variety collection of 
>>> geographical polygons.
>>>> tx1_sp <- readShapePoly("precinct08.shp", IDvar="PCT", 
>>> proj4string=CRS("+proj=aea +ellps=GRS80 +datum=WGS84"))
>>> 
>>> 
>>> 
>>> The new file to intersect merge is major roads line map that should 
>>> overlay part of my SpatialPolygons. It does not behave like a Shapfile.
>>> 
>>>> main_roads <-readOGR("main roads.shp", layer = "main roads")
>>> OGR data source with driver: ESRI Shapefile
>>> Source: "main roads.shp", layer: "main roads"
>>> with  29161  rows and  33  columns
>>> Feature type: wkbLineString with 2 dimensions
>>> 
>>> 
>>> Thanks,
>>> Jim Burke
>>> 
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> 
>> 
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Adrian.Baddeley at csiro.au  Wed Feb 18 03:56:44 2009
From: Adrian.Baddeley at csiro.au (Adrian Baddeley)
Date: Wed, 18 Feb 2009 11:56:44 +0900
Subject: [R-sig-Geo] Point pattern analysis
Message-ID: <499B78EC.3030909@csiro.au>

Michel Barbosa <cicaboo at gmail.com> asked about analysing a spatial point
pattern of restaurants which are classified by the type of cuisine 
(Italian, etc).

Please have a look at Part V of the e-book 'Analysing Spatial Point
Patterns in R' (version 3) available at
     <http://www.csiro.au/resources/Spatial-Point-Patterns-in-R.html>
which contains a detailed description of how to analyse such data in the
package 'spatstat' using both exploratory tools and formal statistical
models.

Someone else

Adrian Baddeley


From bibiko at eva.mpg.de  Wed Feb 18 11:46:57 2009
From: bibiko at eva.mpg.de (=?ISO-8859-1?Q?Hans-J=F6rg_Bibiko?=)
Date: Wed, 18 Feb 2009 11:46:57 +0100
Subject: [R-sig-Geo] Rgshhs shift=true question
Message-ID: <B49DBFF7-7441-47C3-B1CA-BD3CD0C41F01@eva.mpg.de>


Hi,

I'm using the river database 'wdb_rivers_l.b' downloaded from ftp://ftp.soest.hawaii.edu/pwessel/gshhs/gshhs_1.11.zip 
.

If I do this:

 > rivers_low <- Rgshhs("wdb_rivers_l.b")

I get a list of rivers as SpatialLines with

 > bbox(rivers_low[[1]])
           min       max
r1   0.000278 359.99944
r2 -52.733333  74.41167

Fine.

But I need a xlim range of c(-180, 180). I could do it manually but I  
read in ?Rgshhs that there's an argument 'shift' which, set to TRUE,  
shifts longitudes > 180 degrees to below zero. But if I call:

 > rivers_low <- Rgshhs("wdb_rivers_l.b", shift = TRUE)

I get the same bbox.

What am I doing wrong?

Thanks in advance and kind regards,

--Hans


From marius.fredheim at math.uib.no  Wed Feb 18 12:26:36 2009
From: marius.fredheim at math.uib.no (Marius Fredheim)
Date: Wed, 18 Feb 2009 12:26:36 +0100
Subject: [R-sig-Geo] Shapefiles
Message-ID: <20090218122636.rl0omwan1c0sc4c4@webmail.uib.no>

Dear all,

Do you have any suggestions on where it is best to search for  
Shapefiles for the Nordic countries? Preferably on a postcode level,  
but anything will do.

Thanks in advance.

Regards,
Marius


From Virgilio.Gomez at uclm.es  Wed Feb 18 12:47:19 2009
From: Virgilio.Gomez at uclm.es (Virgilio Gomez Rubio)
Date: Wed, 18 Feb 2009 12:47:19 +0100
Subject: [R-sig-Geo] Shapefiles
In-Reply-To: <20090218122636.rl0omwan1c0sc4c4@webmail.uib.no>
References: <20090218122636.rl0omwan1c0sc4c4@webmail.uib.no>
Message-ID: <1234957639.7156.7.camel@Virgilio-Gomez>

Marius,

I've got a shapefile of Sweden at the municipality level from Statistics
Sweden some years ago. I am not sure about all the other Nordic
countries but you may search in their websites or drop them an e-mail if
you do not find what you are looking for. That is what I did.

Best,

Virgilio


El mi?, 18-02-2009 a las 12:26 +0100, Marius Fredheim escribi?:
> Dear all,
> 
> Do you have any suggestions on where it is best to search for  
> Shapefiles for the Nordic countries? Preferably on a postcode level,  
> but anything will do.
> 
> Thanks in advance.
> 
> Regards,
> Marius
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Wed Feb 18 12:50:08 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 18 Feb 2009 12:50:08 +0100 (CET)
Subject: [R-sig-Geo] Rgshhs shift=true question
In-Reply-To: <B49DBFF7-7441-47C3-B1CA-BD3CD0C41F01@eva.mpg.de>
References: <B49DBFF7-7441-47C3-B1CA-BD3CD0C41F01@eva.mpg.de>
Message-ID: <alpine.LRH.2.00.0902181247580.32440@reclus.nhh.no>

On Wed, 18 Feb 2009, Hans-J?rg Bibiko wrote:

>
> Hi,
>
> I'm using the river database 'wdb_rivers_l.b' downloaded from 
> ftp://ftp.soest.hawaii.edu/pwessel/gshhs/gshhs_1.11.zip.
>
> If I do this:
>
>> rivers_low <- Rgshhs("wdb_rivers_l.b")
>
> I get a list of rivers as SpatialLines with
>
>> bbox(rivers_low[[1]])
>         min       max
> r1   0.000278 359.99944
> r2 -52.733333  74.41167
>
> Fine.
>
> But I need a xlim range of c(-180, 180). I could do it manually but I read in 
> ?Rgshhs that there's an argument 'shift' which, set to TRUE, shifts 
> longitudes > 180 degrees to below zero. But if I call:
>
>> rivers_low <- Rgshhs("wdb_rivers_l.b", shift = TRUE)
>
> I get the same bbox.
>
> What am I doing wrong?

Nothing wrong, it was a bug. Support for the two lines databases was added 
only in draft form, and that argument wasn't respected. From 0.7-20, it is 
respected.

Roger

>
> Thanks in advance and kind regards,
>
> --Hans
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From maechler at stat.math.ethz.ch  Wed Feb 18 19:02:02 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 18 Feb 2009 19:02:02 +0100
Subject: [R-sig-Geo] Timezone boundaries (for adding to world map)?
Message-ID: <18844.19738.165822.672093@stat.math.ethz.ch>

Dear R - Mapping specialists,

for a prospective publication on using date/times etc in R,
we are looking for a way to draw a world map additionally with 
the "timezone stripes".

Thanks to Roger Bivand, it was easy to get to the world map:
I've used this
  http://spatial.nhh.no/R/etc/world_map_intro.html
and later also found
  https://stat.ethz.ch/pipermail/r-sig-geo/2006-March/000848.html

Note that I'm pretty much an ignorant of the diverse shapefile
and other GIS data formats,
[ Furthermore, I'd ideally get a solution (or an *.rda file) 
  that does not need the 'rgdal' package since that is very hard
  for me to get working on our departmental computer, notably the
  64-bit ones (problems in installing libgdal / proj.4 / ...).
  As it *is* working on some versions of R on some ubuntu servers,
  I could use it if needed. ]

Thank you very much in advance!

Martin Maechler, 
ETH Zurich


From Greg.Snow at imail.org  Wed Feb 18 19:14:16 2009
From: Greg.Snow at imail.org (Greg Snow)
Date: Wed, 18 Feb 2009 11:14:16 -0700
Subject: [R-sig-Geo] Timezone boundaries (for adding to world map)?
In-Reply-To: <18844.19738.165822.672093@stat.math.ethz.ch>
References: <18844.19738.165822.672093@stat.math.ethz.ch>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61CA3E23F3@LP-EXMBVS10.CO.IHC.COM>

There is a shapefile (works well with maptools and sp packages) with a world map and time zone information at:
http://openmap.bbn.com/data/shape/timezone/

It has the info needed to color the countries or parts of countries based on time zone, but does not have polygons for time zone stripes over the oceans.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-
> bounces at stat.math.ethz.ch] On Behalf Of Martin Maechler
> Sent: Wednesday, February 18, 2009 11:02 AM
> To: r-sig-geo at stat.math.ethz.ch
> Cc: maechler at stat.math.ethz.ch
> Subject: [R-sig-Geo] Timezone boundaries (for adding to world map)?
> 
> Dear R - Mapping specialists,
> 
> for a prospective publication on using date/times etc in R,
> we are looking for a way to draw a world map additionally with
> the "timezone stripes".
> 
> Thanks to Roger Bivand, it was easy to get to the world map:
> I've used this
>   http://spatial.nhh.no/R/etc/world_map_intro.html
> and later also found
>   https://stat.ethz.ch/pipermail/r-sig-geo/2006-March/000848.html
> 
> Note that I'm pretty much an ignorant of the diverse shapefile
> and other GIS data formats,
> [ Furthermore, I'd ideally get a solution (or an *.rda file)
>   that does not need the 'rgdal' package since that is very hard
>   for me to get working on our departmental computer, notably the
>   64-bit ones (problems in installing libgdal / proj.4 / ...).
>   As it *is* working on some versions of R on some ubuntu servers,
>   I could use it if needed. ]
> 
> Thank you very much in advance!
> 
> Martin Maechler,
> ETH Zurich
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Adrian.Baddeley at csiro.au  Thu Feb 19 04:35:08 2009
From: Adrian.Baddeley at csiro.au (Adrian.Baddeley at csiro.au)
Date: Thu, 19 Feb 2009 12:35:08 +0900
Subject: [R-sig-Geo] R-sig-Geo Digest, Vol 66, Issue 18
In-Reply-To: <mailman.9.1234954804.13982.r-sig-geo@stat.math.ethz.ch>
References: <mailman.9.1234954804.13982.r-sig-geo@stat.math.ethz.ch>
Message-ID: <57DC18C299094D4299F837570C5DF1C50280FCE763@EXWA-MBX01.nexus.csiro.au>


 Jim Burke <j.burke at earthlink.net> asked how to compute the intersection
 between a set of lines (roads) and a set of polygons (regions).

This can be done using the spatstat package.

     1. convert the polygons from the class SpatialPolygons (in the sp package)
        to the class owin (in the spatstat package). See the vignette in the spatstat
       package for details.

    2. convert the lines (roads) to the class psp (in the spatstat package)  similarly.

    3. Use "[.psp" to clip the lines to the polygons. If X is your road network
       and W is a polygon then X[W] is the road network clipped inside W.

 Adrian Baddeley


From rossiter at itc.nl  Thu Feb 19 08:50:37 2009
From: rossiter at itc.nl (David Rossiter)
Date: Thu, 19 Feb 2009 08:50:37 +0100
Subject: [R-sig-Geo] spplot.points not recognizing logical variables
Message-ID: <5AF149DBB6DFE24AA3F4F53201E539AD04E2AD95@itcnt24.itc.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090219/b67509c0/attachment.pl>

From edzer.pebesma at uni-muenster.de  Thu Feb 19 09:48:53 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 19 Feb 2009 09:48:53 +0100
Subject: [R-sig-Geo] spplot.points not recognizing logical variables
In-Reply-To: <5AF149DBB6DFE24AA3F4F53201E539AD04E2AD95@itcnt24.itc.nl>
References: <5AF149DBB6DFE24AA3F4F53201E539AD04E2AD95@itcnt24.itc.nl>
Message-ID: <499D1CF5.2080608@uni-muenster.de>

Thanks for mentioning this; the bug has creeped in when I modified code
to allow for multiple panels with factor variables. I'll update later today.
--
Edzer

David Rossiter wrote:
> As of the last time I compiled code like the following (17-June-2008),
> it displayed an indicator map:
>  
> require(sp)
> data(meuse)
> # indicator: which observations have high Zn content?
> meuse$ind <- (meuse$zinc > 300)
> table(meuse$ind)
> coordinates(meuse) <- ~x +y
> class(meuse) # SpatialPointsDataFrame
> spplot(meuse, zcol="ind")
>  
> But now, with sp 0.9.29, both on Mac OS X 10.5.3 and Win XP (both with R
> 2.8.1 and all the latest updates) I get this message:
>
> # Error in create.z(as(obj, "data.frame"), zcol) : 
> #  no support for variable of this type
>  
> Converting to numeric gives me the map I want:
>
> meuse$ind.n <- as.numeric(meuse$ind)
> spplot(meuse, zcol="ind.n")
>
> Is there any reason why support for T/F variables was removed from
> spplot.points? I try to teach my students to use the correct class, and
> here clearly it's logical. It defeats the purpose to have to convert to
> numeric! These are not 0/1 they are F/T.
>  
> Thanks,
>  
> D G Rossiter
> ITC Enschede (NL)
>
> International Institute for Geo-Information Science and Earth Observation (ITC)
> Chamber of Commerce: 410 27 560
>
> E-mail disclaimer
> The information in this e-mail, including any attachments, is intended for the addressee only. If you are not the intended recipient, you are hereby notified that any disclosure, copying, distribution or action in relation to the content of this information is strictly prohibited. If you have received this e-mail by mistake, please delete the message and any attachment and inform the sender by return e-mail. ITC accepts no liability for any error or omission in the message content or for damage of any kind that may arise as a result of e-mail transmission.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From Bjarke.Christensen at sydbank.dk  Thu Feb 19 13:14:25 2009
From: Bjarke.Christensen at sydbank.dk (Bjarke Christensen)
Date: Thu, 19 Feb 2009 13:14:25 +0100
Subject: [R-sig-Geo] Shapefiles
In-Reply-To: <mailman.15.1235041204.23710.r-sig-geo@stat.math.ethz.ch>
Message-ID: <OFDC53507F.25ED7E63-ONC1257562.00428034-C1257562.00433D24@bdpnet.dk>

Marius Fredheim:
>Do you have any suggestions on where it is best to search for
>Shapefiles for the Nordic countries? Preferably on a postcode level,
>but anything will do.

I don't know about a postcode level file, but http://www.fao.org/geonetwork
has a dataset called GAUL (Global Administrative Unit Layers), containing
the whole world at country level and at two subnational administrative
levels. It's for non-commercial purposes only.


From cicaboo at gmail.com  Fri Feb 20 01:43:11 2009
From: cicaboo at gmail.com (Michel Barbosa)
Date: Fri, 20 Feb 2009 01:43:11 +0100
Subject: [R-sig-Geo] Point pattern analysis
In-Reply-To: <1234858949.7265.13.camel@Virgilio-Gomez>
References: <f7f7b86f0902150636v6aac9cddn19816c337902c37f@mail.gmail.com>
	<1234732649.8833.84.camel@Virgilio-Gomez>
	<f7f7b86f0902161724j5f67bbaeo7400856fd899079@mail.gmail.com>
	<1234858949.7265.13.camel@Virgilio-Gomez>
Message-ID: <f7f7b86f0902191643u2efb19fdjaaf5fa4dcb6ef272@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090220/2e08198f/attachment.pl>

From greenberg at ucdavis.edu  Fri Feb 20 05:38:45 2009
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Thu, 19 Feb 2009 20:38:45 -0800
Subject: [R-sig-Geo] Wiki?
Message-ID: <499E33D5.3060809@ucdavis.edu>

R-sig-geo'ers -- do we have a wiki/script repository?  If not, can we 
start a r-sig-geo wiki subpage on one of the main R wiki sites 
(http://wiki.r-project.org/rwiki/doku.php)?  It would be nice to have a 
centralized location to paste help and/or scripts that we develop.

--j

-- 

Jonathan A. Greenberg, PhD
Postdoctoral Scholar
Center for Spatial Technologies and Remote Sensing (CSTARS)
University of California, Davis
One Shields Avenue
The Barn, Room 250N
Davis, CA 95616
Cell: 415-794-5043
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307


From Friderike.Oehler at fao.org  Fri Feb 20 09:27:03 2009
From: Friderike.Oehler at fao.org (Oehler, Friderike (AGPP))
Date: Fri, 20 Feb 2009 09:27:03 +0100
Subject: [R-sig-Geo] Wiki?
Message-ID: <1A28265B00AA7E4085BB761555D3FCE803EDAA95@hqagex02.fao.org>

Dear Jonathan,

please try this link:
http://wiki.r-project.org/rwiki/doku.php?id=tips:spatial-data

Best,
Friderike


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Jonathan Greenberg
Sent: 20 February 2009 05:39
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] Wiki?


R-sig-geo'ers -- do we have a wiki/script repository?  If not, can we 
start a r-sig-geo wiki subpage on one of the main R wiki sites 
(http://wiki.r-project.org/rwiki/doku.php)?  It would be nice to have a 
centralized location to paste help and/or scripts that we develop.

--j

-- 

Jonathan A. Greenberg, PhD
Postdoctoral Scholar
Center for Spatial Technologies and Remote Sensing (CSTARS) University of
California, Davis One Shields Avenue The Barn, Room 250N Davis, CA 95616
Cell: 415-794-5043
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Fri Feb 20 09:55:52 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 20 Feb 2009 09:55:52 +0100 (CET)
Subject: [R-sig-Geo] Timezone boundaries (for adding to world map)?
In-Reply-To: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61CA3E23F3@LP-EXMBVS10.CO.IHC.COM>
References: <18844.19738.165822.672093@stat.math.ethz.ch>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61CA3E23F3@LP-EXMBVS10.CO.IHC.COM>
Message-ID: <alpine.LRH.2.00.0902200942110.24812@reclus.nhh.no>

On Wed, 18 Feb 2009, Greg Snow wrote:

> There is a shapefile (works well with maptools and sp packages) with a 
> world map and time zone information at: 
> http://openmap.bbn.com/data/shape/timezone/
>
> It has the info needed to color the countries or parts of countries 
> based on time zone, but does not have polygons for time zone stripes 
> over the oceans.

In fact, this shapefile provoked an update in sp, because it is really 
buggy. There are straight-line polygons and many others have multiple 
repeated coordinates (the sp update fixes these to retain finite label 
points), but it doesn't fix the absence of most of the data (several DBF 
columns are empty - checked in oocalc):

> library(rgdal)
> tz <- readOGR(".", "WrldTZA")
OGR data source with driver: ESRI Shapefile
Source: ".", layer: "WrldTZA"
with  1890  rows and  11  columns
Feature type: wkbPolygon with 2 dimensions
Warning messages:
1: In Polygon(cbind(jG[[1]], jG[[2]])) :
   Non-finite label point detected and replaced
2: In Polygon(cbind(jG[[1]], jG[[2]])) :
   Non-finite label point detected and replaced
3: In Polygon(cbind(jG[[1]], jG[[2]])) :
   Non-finite label point detected and replaced
> names(tz)
  [1] "FIPS"     "NAME"     "COMMENTS" "REGION"   "LAT"      "LON"
  [7] "TZ"       "GMTOFF"   "LOCALSUM" "OFFSET"   "CLASSES"
> summary(tz$GMTOFF)
NA's
1890
> summary(tz$TZ)
NA's
1890
> summary(tz$OFFSET)
         0     \xff0        -1    \xff-1    \xff+1       -10       +10
        25        57        13         7       181        24        38
   \xff+10     +10.5       +11     +11.5       +12   \xff+12        +2
        24         1        19         3        12        13         1
    \xff-2    \xff+2        +3    \xff-3    \xff+3      -3.5  \xff+3.5
         4        90        59       146        25         7         3
        -4        +4    \xff-4    \xff+4  \xff+4.5        -5        +5
        56         4       165         8         1       130        13
    \xff-5    \xff+5  \xff+5.5 \xff+5.75        -6        +6    \xff-6
        12         3        16         1        77        10        16
    \xff+6  \xff+6.5        -7        +7    \xff+7        -8        +8
        12        15        63        98        14        61        68
    \xff-8    \xff+8        -9        +9    \xff+9      +9.5      NA's
         3        56        82        97        13        11        33

where my locale is UTF-8.

I wrote to Martin offline that a more recent link is:

http://efele.net/maps/tz/world/

and I've put tz_world.rda on http://spatial.nhh.no/R/etc, but it is not 
line generalised, so it is very large and takes a long time to display - 
they've kept a lot of boundary detail.

Because TZ follow administrative boundaries, they are actually hard to do 
right. Maybe a raster version might help more if vector precision isn't 
needed?

Roger

>
> Hope this helps,
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From T.Hengl at uva.nl  Fri Feb 20 10:13:56 2009
From: T.Hengl at uva.nl (Tomislav Hengl)
Date: Fri, 20 Feb 2009 10:13:56 +0100
Subject: [R-sig-Geo] Wiki?
In-Reply-To: <499E33D5.3060809@ucdavis.edu>
References: <499E33D5.3060809@ucdavis.edu>
Message-ID: <113C4F4FB95B4A5FBDE6C3680B312404@pcibed193>


Jonathan,

I think this is an excellent idea.

Ideally we should have a system that automatically scans e-mails, distinguishes between a question,
answer/suggestion, and R code, and then generates a wiki article (such articles could then be
classified into some hierachical structure using various similarity measures; e.g. based on the
e-mail thread, users, libraries used etc.).

Otherwise, nothing stops you from sorting the R-sig-geo traffic manually, extracting R codes and
putting them into wiki articles.   :)

Tom Hengl
http://spatial-analyst.net 


> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
> Of Jonathan Greenberg
> Sent: Friday, February 20, 2009 5:39 AM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] Wiki?
> 
> R-sig-geo'ers -- do we have a wiki/script repository?  If not, can we
> start a r-sig-geo wiki subpage on one of the main R wiki sites
> (http://wiki.r-project.org/rwiki/doku.php)?  It would be nice to have a
> centralized location to paste help and/or scripts that we develop.
> 
> --j
> 
> --
> 
> Jonathan A. Greenberg, PhD
> Postdoctoral Scholar
> Center for Spatial Technologies and Remote Sensing (CSTARS)
> University of California, Davis
> One Shields Avenue
> The Barn, Room 250N
> Davis, CA 95616
> Cell: 415-794-5043
> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Fri Feb 20 17:11:48 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 20 Feb 2009 17:11:48 +0100 (CET)
Subject: [R-sig-Geo] Wiki?
In-Reply-To: <1A28265B00AA7E4085BB761555D3FCE803EDAA95@hqagex02.fao.org>
References: <1A28265B00AA7E4085BB761555D3FCE803EDAA95@hqagex02.fao.org>
Message-ID: <alpine.LRH.2.00.0902201711020.24812@reclus.nhh.no>

On Fri, 20 Feb 2009, Oehler, Friderike (AGPP) wrote:

> Dear Jonathan,
>
> please try this link:
> http://wiki.r-project.org/rwiki/doku.php?id=tips:spatial-data

Exactly, in fact it is in the "Spatial" task view on your nearest CRAN 
too!

Roger

>
> Best,
> Friderike
>
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Jonathan Greenberg
> Sent: 20 February 2009 05:39
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] Wiki?
>
>
> R-sig-geo'ers -- do we have a wiki/script repository?  If not, can we
> start a r-sig-geo wiki subpage on one of the main R wiki sites
> (http://wiki.r-project.org/rwiki/doku.php)?  It would be nice to have a
> centralized location to paste help and/or scripts that we develop.
>
> --j
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From nikko at hailmail.net  Fri Feb 20 18:26:05 2009
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Fri, 20 Feb 2009 09:26:05 -0800
Subject: [R-sig-Geo] Point pattern analysis
Message-ID: <1235150765.7835.1301507173@webmail.messagingengine.com>

Hi Michael,
A couple of thoughts. Many of the statistical methods are geared toward
describing 
the pattern over a region. So methods like the k-functions, and such
will describe the global 
covariance function over a range of spatial scales. Here you are looking
at very local phenomena,
I am standing in Rotterdam central with my crackberry, and I want to
know what is the best
Italian restaurant within a kilometer. Well one issue is euclidean
distance a good proxy for walking
distance? So nearest neighbor searching might better be done on
Manhattan distance, or even
a quick all shortest path calculation on the street network in the one
kilometer circle. A nice
way to think about these problems might be in terms of graphs (as in
graph theory). Rather than point
process ideas, you could look at some of the social network models. 

Also inherent in this is ranking the restaurants, what order should they
be listed?
If distance, quality, price, ... all play a part in my search criteria,
than 
the ordering should reflect those weightings.  So a neat application
might be that I want
to know (if I were younger) which cheap Italian restaurants are in
walking distance of night
clubs with live music. And get some ranking on those pairs weighted by
distance and price.
So the top ten pairs would be displayed in the view, with lines
connecting them, and the
lines weighted by the pair rankings.

So what you want seems to be more on the lines of heuristics for picking
the best
in a limited query. "statistics" might help a little if you exploit the
local nature of
the queries, ie build your rankings normalized by all Italian
restaurants in Rotterdam,
and highlight the ones that are spatial outliers (really good) LISA's 
(local indicators of spatial association) might be  a good approach for
this. Again,
these are just my musings, but in this context point pattern analysis
may not have that much to
offer.

Nicholas
 
 

-------------------------------------------------------------------------------

Dear Virgilio / Adrian,

I do have data regarding districts, cities and provinces. I could easily
ask
for all the restaurants in Rotterdam or for the province. But for
Location-Based Services, the users tend to be interested in local /
nearby
points of interests. I'm looking for techniques to allow the users to
make
better decisions about the restaurants. By aggregating the data and
doing
area data analysis it might be useful for users that have no real idea
what
place they're looking for. For example tourists that want to know which
city
has the most / best restaurants.

but if you allow them to zoom in then you probably
> want to show the individual locations of the restaurants.
>

Yeah, on a more detailed level, I want to analyse the nearby
restaurants.
Let's say someone's looking for nearby Italian restaurants, for example
within a 1 kilometer radius. The user is presented with 10 restaurants.
To
move beyond pinpoints on a google map, I want to analyse these
restaurants.
I'm interested in showing more information about these 10 restaurants
then
just their location (which becomes obvious from the pinpoints). Let's
say I
have another point pattern dataset which contains the location for ATMs.
I
could use the *nncross* function in spatstat to return the nearest ATM
for
these 10 restaurants that match my criteria. Using arrows to pinpoint
the
ATMs would clearly help users to determine if restaurant 1 is better
than
restaurant 10. Any ideas / tips regarding analysing / comparing two
point
patterns? So far, I've played with the nndist and nncross functions
provided
by spatstat.

This can be more complex because then you may want to produce a map
> based on the rating, and then the rating becomes the response variable
> in your model...


Isn't this what smooth.ppp is trying to accomplish?

Yes, you can compare the spatial distributions of different types of
> restaurants.


Could you give me an example of such a comparison? Do you mean
estimating a
surface for Italian restaurants and for Greek restaurants. And show them
next to each other, as used in split.ppp?
Or different outputs such as tabular comparisons?

Basically, I'm restricted to the screen size of either the iPhone or
Nokia
N95 8GB, since my research involves developing for either one of those
two
phones since they utilise A-GPS.
My dataset has ratings on food / interior / service and a general
rating.
What type of analysis would best suit my dataset in this case? 4 kernel
density estimations and comparing them?

Please have a look at Part V of the e-book 'Analysing Spatial Point
Patterns
> in R' (version 3) available at <
> http://www.csiro.au/resources/Spatial-Point-Patterns-in-R.html> which
> contains a detailed description of how to analyse such data in the package
> 'spatstat' using both exploratory tools and formal statistical models.
>

I've read through Part V and other sections of the e-book. I want to
utilise
Visualisation techniques and Exploratory techniques. Modelling and
thereby
forming statistical models goes beyond the scope of my research. Given
this
limitations, are there any other papers/techniques/r packages I should
consider? My dataset is clearly a point pattern dataset. I might be able
to
get some other point pattern datasets as well. I've looked through the
ones
mentioned under the section *point pattern analysis* at
http://cran.r-project.org/web/views/Spatial.html.

Thanks very much for the great input so far!

Kind regards,

Michel


009/2/17 Virgilio Gomez Rubio <Virgilio.Gomez at uclm.es>

> Hi,
>
>
> > Thanks :) Actually, I'm busy with developing a Location-Based Service
> > (a restaurant finder to be precise) utilising SDA. The goal of my
> > research is to integrate SDA in an LBS. For this purpose, I've
> > gathered about 13,000 unique restaurants in the Netherlands and would
> > like to use 3 SDA techniques that enhance the restaurant finder either
> > visually and/or analytically. The motivation behind my research is t
> > start a discussion on how SDA can be used inside LBSs to enhance the
> > services. In this case, to enable users to make better decisions about
> > nearby restaurants. One thing that popped in my mind was to use kernel
> > density estimation and overlay it on the google/microsoft map to allow
> > users to easily grasp the proximity of restaurants.
>
> Perhaps it would be better if you aggregated your data and considered
> municipalities in The Netherlands. I guess that area level maps are
> easier to understand. What I mean is that your users will find more
> meaningful that there are, say, 20 Indian restaurants in Nijmegen than
> saying that the intensity for the Indian restaurants have a peak in the
> centre of Nijmegen. Regional maps will be helpful if you have a whole
> map of the country, but if you allow them to zoom in then you probably
> want to show the individual locations of the restaurants.
>
> >
> >         Depending on the number of different types of restaurants, you
> >         may want
> >         to estimate a different surface for each type. Basically, you
> >         may
> >         consider a multivariate point pattern, so that you estimate a
> >         different
> >         surface for each type and  you compare then to see if they are
> >         similar
> >         or not. This will address the question of whether the spatial
> >         distribution of different types of restaurants is the same or
> >         not
> >
> > This is quite interesting. Would this allow me to estimate a surface
> > for let's say Italian restaurants vs Greek restaurants? I have ratings
>
> Yes, you can compare the spatial distributions of different types of
> restaurants.
>
> >  for each restaurant. So a user might want to ask "Where can I find
> > good Italian restaurants in the South?" Where good is any rating above
> > a 7.0 for example.
>
> This can be more complex because then you may want to produce a map
> based on the rating, and then the rating becomes the response variable
> in your model...
>
> >
> >         You may also want to compute bivariate K-functions (see
> >         'k12hat' in
> >         splancs; 'Kmulti' in spatstat) to detect differences between
> >         the spatial
> >         distributions of types of restaurants. This will give you a
> >         partial
> >         answer to Question 2.
> >
> > Would this mean that a kmulti analysis should be applied for each
> > restaurant type and thus each subset I wish to test?
>
> You will need to consider each pair of restaurants at a time.
>
> >
> >         Have you considered to test for whether a certain type of
> >         restaurant tends to appear around a particular area of the
> >         city? For
> >         example, are Chinese restaurants clustered around Chinatown?
> >
> > This is something I'm looking for as well. Considering the fact that
> > I'm in the process of developing such an LBS, it would be something
> > along the line of: A user takes out his mobile phone. He starts the
> > application and the applications looks acquires a position fix. When
> > this is done, a user might want to know: "What type of restaurant is
> > typical for my current location or current neighbourhood. So,
> > analysing whether a certain type of restaurant tends to appear around
> > the CURRENT area of the city. Is this possible?
>
> Yes, I guess that you can make a buffer of, say, 300 m around the user's
> location and then display your results based on the restaurants included
> in that buffer.
>
> > Overall, thanks very much for your reply. I'm really excited about
> > using these SDA techniques and am very grateful for your quick reply.
> > I'll look up a copy of the papers you mentioned and will read through
> > them as soon as I can. When I've successfully analysed the dataset
> > with some SDA techniques I can begin the process of constructing the
> > appropriate architecture for the LBS. I'll definitely keep you guys
> > posted if you're interested.
>
> That would be good. And if you get free vouchers let us now as well!! :)
>
> Best,
>
> Virgilio
>
>

        [[alternative HTML version deleted]]


From lhq0837 at yahoo.com  Sat Feb 21 10:46:12 2009
From: lhq0837 at yahoo.com (Christina Qi Li)
Date: Sat, 21 Feb 2009 01:46:12 -0800 (PST)
Subject: [R-sig-Geo] R-squared value for Spatial regressions
Message-ID: <600221.70684.qm@web82705.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090221/9762f5f2/attachment.pl>

From Roger.Bivand at nhh.no  Sat Feb 21 15:21:22 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 21 Feb 2009 15:21:22 +0100 (CET)
Subject: [R-sig-Geo] R-squared value for Spatial regressions
In-Reply-To: <600221.70684.qm@web82705.mail.mud.yahoo.com>
References: <600221.70684.qm@web82705.mail.mud.yahoo.com>
Message-ID: <alpine.LRH.2.00.0902211518160.4736@reclus.nhh.no>

On Sat, 21 Feb 2009, Christina Qi Li wrote:

> Dear List members,
>
> It's a quite basic question, but I cannot figure it out myself: How to 
> get the R-squared value for a spatial lag regression, or a spatial error 
> regression?
>
> The default return for command "lagsarlm" or "errorsarlm" only returns 
> AIC value, not R-squared or Adjusted R-squared value.

Why basic? These are not defined for these kinds of models in the same way 
as for least squares, so use the AIC instead (uses both the log likelihood 
and adjusts for the number of included variables). You can fake R-squared 
via the correlation between the response and the fitted values, but it 
isn't what you expect.

Hope this helps,

Roger

>
> Anyone knows how to get it quickly? Thanks a lot!
>
> Christina
> University of Southern California
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From andersonfaye7 at gmail.com  Sun Feb 22 23:26:05 2009
From: andersonfaye7 at gmail.com (Faye Anderson)
Date: Sun, 22 Feb 2009 16:26:05 -0600
Subject: [R-sig-Geo] multivariable variogram modeling
Message-ID: <e06a91f30902221426l1845625cw9bc85c2deda44b5d@mail.gmail.com>

You might consider posting to r-sig-geo next time, so others may enjoy
the discussion and may even answer.

The most common situation for this is that you have duplicate
observations (use function zerodist to find out), or you have perfectly
correlated variables; use correct.diagonal argument in fit.lmc.

Pls let me know if either of the two worked.
--
Edzer
Hi everyone,
Below is a question I sent to Edzer and he thankfully helped me with.
Any comments?
thanks
Faye
_____
Hi Edzer,

I'd appreciate it if you can comment or provide me with any kind of
guidance on the following:
In your book (Applied Spatial Data Analysis with R), I'm trying to
apply the code of section 8.4.5 to a multivariate data set of similar
structure (groundwater constituents) but I get an error message of
"singular covariance matrix". I think the covariance matrix of my
variables is not positive definite. How can I confirm that? If so,
what is the route for me to get a model for my data set?

Thank you so much.

Faye


From andersonfaye7 at gmail.com  Mon Feb 23 01:07:31 2009
From: andersonfaye7 at gmail.com (Faye Anderson)
Date: Sun, 22 Feb 2009 18:07:31 -0600
Subject: [R-sig-Geo] multivariable variogram modeling
Message-ID: <e06a91f30902221607n1ddc4eblc05ecef575914b39@mail.gmail.com>

Hi All,
I forgot to add that zerodist worked out well.

Thanks.
Faye


From ddepew at sciborg.uwaterloo.ca  Mon Feb 23 19:27:58 2009
From: ddepew at sciborg.uwaterloo.ca (ddepew at sciborg.uwaterloo.ca)
Date: Mon, 23 Feb 2009 13:27:58 -0500
Subject: [R-sig-Geo] cross validation gstat
Message-ID: <20090223132758.10075bhqb45s2v8k@www.nexusmail.uwaterloo.ca>

Hi list,
A quick question regarding n-fold validation...
I've seen several papers suggest the LOOCV is too optimistic. Is  
n-fold closer to a "true" validation?
I am assuming that it uses the variogram that is constructed using ALL  
data, so my assumption is that the variogram is not re-fit for each  
n-fold before estimation...




-- 
David Depew
PhD Candidate
Department of Biology
University of Waterloo
200 University Ave W
Waterloo, Ontario, Canada
N2L 3G1

T:(1)-519-888-4567 x 33895
F:(1)-519-746-0614

ddepew at scimail.uwaterloo.ca
http://www.science.uwaterloo.ca/~ddepew


From Gerard.Heuvelink at wur.nl  Mon Feb 23 19:47:00 2009
From: Gerard.Heuvelink at wur.nl (Heuvelink, Gerard)
Date: Mon, 23 Feb 2009 19:47:00 +0100
Subject: [R-sig-Geo] stratified random sampling
Message-ID: <5DA773FDB5D4484D9A8E36F6C3DC0180BB4BC7@scomp0039.wurnet.nl>

Dear list,
 
I use readShapePoly to import a shape file. The file has multiple polygons (actually, a 'polygon' may consist of multiple polygons that have the same ID). I want to sample one location at random from each of the polygons. I tried to do this with spsample but did not manage (the option "stratified" does not do what I want). I also looked at dotsInPolys but also without success.
 
I think it should be possible with spsample, possibly after first creating a large number of SpatialPolygons objects, one for each polygon, and next sampling one location at random from each of these. Unfortunately I am not very experienced and also failed to achieve what I want in this way.
 
Can you help me?
 
Thanks, Gerard Heuvelink


From debeaudette at ucdavis.edu  Mon Feb 23 19:59:01 2009
From: debeaudette at ucdavis.edu (Dylan Beaudette)
Date: Mon, 23 Feb 2009 10:59:01 -0800
Subject: [R-sig-Geo] stratified random sampling
In-Reply-To: <5DA773FDB5D4484D9A8E36F6C3DC0180BB4BC7@scomp0039.wurnet.nl>
References: <5DA773FDB5D4484D9A8E36F6C3DC0180BB4BC7@scomp0039.wurnet.nl>
Message-ID: <200902231059.01743.dylan.beaudette@gmail.com>

On Monday 23 February 2009, Heuvelink, Gerard wrote:
> Dear list,
>
> I use readShapePoly to import a shape file. The file has multiple polygons
> (actually, a 'polygon' may consist of multiple polygons that have the same
> ID). I want to sample one location at random from each of the polygons. I
> tried to do this with spsample but did not manage (the option "stratified"
> does not do what I want). I also looked at dotsInPolys but also without
> success.
>
> I think it should be possible with spsample, possibly after first creating
> a large number of SpatialPolygons objects, one for each polygon, and next
> sampling one location at random from each of these. Unfortunately I am not
> very experienced and also failed to achieve what I want in this way.
>
> Can you help me?
>
> Thanks, Gerard Heuvelink
>

Does this help:
http://casoilresource.lawr.ucdavis.edu/drupal/node/644

Cheers,

Dylan


-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341


From reeves at nceas.ucsb.edu  Mon Feb 23 20:31:31 2009
From: reeves at nceas.ucsb.edu (rick reeves)
Date: Mon, 23 Feb 2009 11:31:31 -0800
Subject: [R-sig-Geo] stratified random sampling
In-Reply-To: <5DA773FDB5D4484D9A8E36F6C3DC0180BB4BC7@scomp0039.wurnet.nl>
References: <5DA773FDB5D4484D9A8E36F6C3DC0180BB4BC7@scomp0039.wurnet.nl>
Message-ID: <49A2F993.3090000@nceas.ucsb.edu>

Hi Gerald:

I have an example that may help: It demonstrates the sampling of a 
polygon shape file with a regularly-spaced point grid,
and assignment of polygon values to the sampling points:

http://nceas.ucsb.edu/scicomp/GISSeminar/UseCases/SampleVectorPolygonsRasterGrid/SampleVectorPolysRastGrid.html

You could modify this example to randomly select a point inside each 
polygon from the point grid (or a similar modification).

Hope this helps..
Rick Reeves

Heuvelink, Gerard wrote:
> Dear list,
>  
> I use readShapePoly to import a shape file. The file has multiple polygons (actually, a 'polygon' may consist of multiple polygons that have the same ID). I want to sample one location at random from each of the polygons. I tried to do this with spsample but did not manage (the option "stratified" does not do what I want). I also looked at dotsInPolys but also without success.
>  
> I think it should be possible with spsample, possibly after first creating a large number of SpatialPolygons objects, one for each polygon, and next sampling one location at random from each of these. Unfortunately I am not very experienced and also failed to achieve what I want in this way.
>  
> Can you help me?
>  
> Thanks, Gerard Heuvelink
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Rick Reeves
Scientific Programmer/Analyst and Data Manager
National Center for Ecological Analysis and Synthesis
UC Santa Barbara
www.nceas.ucsb.edu
805 892 2533


From edzer.pebesma at uni-muenster.de  Mon Feb 23 20:31:42 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 23 Feb 2009 20:31:42 +0100
Subject: [R-sig-Geo] cross validation gstat
In-Reply-To: <20090223132758.10075bhqb45s2v8k@www.nexusmail.uwaterloo.ca>
References: <20090223132758.10075bhqb45s2v8k@www.nexusmail.uwaterloo.ca>
Message-ID: <49A2F99E.6070404@uni-muenster.de>

ddepew at sciborg.uwaterloo.ca wrote:
> Hi list,
> A quick question regarding n-fold validation...
> I've seen several papers suggest the LOOCV is too optimistic. Is
> n-fold closer to a "true" validation?
I don't think "true" validation exists; could you explain what it is? If
you mean having a completely independent set of observations not
involved in forming the predictions, then there are two issues, (i) how
to form this set from the total set: how to select, how large should it
be? (ii) you're simply forming validation statistics without using all
the information you could use.

In the book by Hastie, Tibshiranie and Friedman (statistical learning)
it is argued (in the context of regression models) that LOOCV often
results in many models that are almost identical, whereas n-fold with
low n results in somewhat more different models. I don't recall they
came with a statistical/theoretical argument why this difference among
models was a good thing.

One of the issues is that with n-fold using random folds (as gstat
does), that the result varies if you repeat the procedure--obviously,
but also a bit of a gamble, then. Which one to pick? Look at
distributions of CV statistics?

I think when you look at CV statistics, you need to question why you do
it; often it is because you want to find out how well the model performs
in a predictive setting. In that case things like predicting locations
very close to measurements is often something that is not possible to CV
at all when data are collected somewhat regular in space.
> I am assuming that it uses the variogram that is constructed using ALL
> data, so my assumption is that the variogram is not re-fit for each
> n-fold before estimation...
>
That is correct. Please submit me code with variogram re-estimation when
you have it. ;-)

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From ddepew at sciborg.uwaterloo.ca  Mon Feb 23 21:06:39 2009
From: ddepew at sciborg.uwaterloo.ca (ddepew at sciborg.uwaterloo.ca)
Date: Mon, 23 Feb 2009 15:06:39 -0500
Subject: [R-sig-Geo] cross validation gstat
In-Reply-To: <49A2F99E.6070404@uni-muenster.de>
References: <20090223132758.10075bhqb45s2v8k@www.nexusmail.uwaterloo.ca>
	<49A2F99E.6070404@uni-muenster.de>
Message-ID: <20090223150639.93516x4s42fmvyg4@www.nexusmail.uwaterloo.ca>

Thanks Edzer,
for some reason I had it in my head that n-fold was a variant of what  
you describe; an independent randomly selected set to "check" the fit  
if the model. I guess that's where I was heading with CV, sore form of  
relative assessment of how "good" the fitted variogram model was/is,  
and if there might be an explanation for some odd zscore values.




-- 
David Depew
PhD Candidate
Department of Biology
University of Waterloo
200 University Ave W
Waterloo, Ontario, Canada
N2L 3G1

T:(1)-519-888-4567 x 33895
F:(1)-519-746-0614

ddepew at scimail.uwaterloo.ca
http://www.science.uwaterloo.ca/~ddepew


Quoting Edzer Pebesma <edzer.pebesma at uni-muenster.de>:

> ddepew at sciborg.uwaterloo.ca wrote:
>> Hi list,
>> A quick question regarding n-fold validation...
>> I've seen several papers suggest the LOOCV is too optimistic. Is
>> n-fold closer to a "true" validation?
> I don't think "true" validation exists; could you explain what it is? If
> you mean having a completely independent set of observations not
> involved in forming the predictions, then there are two issues, (i) how
> to form this set from the total set: how to select, how large should it
> be? (ii) you're simply forming validation statistics without using all
> the information you could use.
>
> In the book by Hastie, Tibshiranie and Friedman (statistical learning)
> it is argued (in the context of regression models) that LOOCV often
> results in many models that are almost identical, whereas n-fold with
> low n results in somewhat more different models. I don't recall they
> came with a statistical/theoretical argument why this difference among
> models was a good thing.
>
> One of the issues is that with n-fold using random folds (as gstat
> does), that the result varies if you repeat the procedure--obviously,
> but also a bit of a gamble, then. Which one to pick? Look at
> distributions of CV statistics?
>
> I think when you look at CV statistics, you need to question why you do
> it; often it is because you want to find out how well the model performs
> in a predictive setting. In that case things like predicting locations
> very close to measurements is often something that is not possible to CV
> at all when data are collected somewhat regular in space.
>> I am assuming that it uses the variogram that is constructed using ALL
>> data, so my assumption is that the variogram is not re-fit for each
>> n-fold before estimation...
>>
> That is correct. Please submit me code with variogram re-estimation when
> you have it. ;-)
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
> http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de
>


From andersonfaye7 at gmail.com  Mon Feb 23 21:09:30 2009
From: andersonfaye7 at gmail.com (Faye Anderson)
Date: Mon, 23 Feb 2009 14:09:30 -0600
Subject: [R-sig-Geo] Iteratively Reweighted Generalized Least Squares IRWGLS
Message-ID: <e06a91f30902231209i2b7c2d2gd95b0e927960ef0f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090223/47242ced/attachment.pl>

From edzer.pebesma at uni-muenster.de  Mon Feb 23 21:30:11 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 23 Feb 2009 21:30:11 +0100
Subject: [R-sig-Geo] stratified random sampling
In-Reply-To: <200902231059.01743.dylan.beaudette@gmail.com>
References: <5DA773FDB5D4484D9A8E36F6C3DC0180BB4BC7@scomp0039.wurnet.nl>
	<200902231059.01743.dylan.beaudette@gmail.com>
Message-ID: <49A30753.6070908@uni-muenster.de>

Hi Gerard,

following Dylan's hint, the following example should be easily reproducable:

library(maptools)
nc1 <- readShapePoly(system.file("shapes/sids.shp",
package="maptools")[1], proj4string=CRS("+proj=longlat +datum=NAD27"))
x100 = do.call(rbind, sapply(slot(nc1, "polygons"), spsample, n=1,
type="random"))
spplot(nc1[1], sp.layout=list(sp.points, x100,col='black'))

the do.call and sapply are of course a bit scary; you could replace it
with with a for loop:

x = slot(nc1, "polygons")
for (i in 1:length(x)) {
        pt = spsample(x[[i]], n = 1, type = "random")
        if (i == 1)
                x100 = pt
        else
                x100 = rbind(x100, pt)
}

to get something perfectly equivalent but less efficient (and more error
prone).

Note that x100 does not have the CRS anymore (design flaw?); you'd need
to do a

proj4string(x100) = proj4string(nc1)
--
Edzer

Dylan Beaudette wrote:
> On Monday 23 February 2009, Heuvelink, Gerard wrote:
>   
>> Dear list,
>>
>> I use readShapePoly to import a shape file. The file has multiple polygons
>> (actually, a 'polygon' may consist of multiple polygons that have the same
>> ID). I want to sample one location at random from each of the polygons. I
>> tried to do this with spsample but did not manage (the option "stratified"
>> does not do what I want). I also looked at dotsInPolys but also without
>> success.
>>
>> I think it should be possible with spsample, possibly after first creating
>> a large number of SpatialPolygons objects, one for each polygon, and next
>> sampling one location at random from each of these. Unfortunately I am not
>> very experienced and also failed to achieve what I want in this way.
>>
>> Can you help me?
>>
>> Thanks, Gerard Heuvelink
>>
>>     
>
> Does this help:
> http://casoilresource.lawr.ucdavis.edu/drupal/node/644
>
> Cheers,
>
> Dylan
>
>
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From alessandro.montaghi at unifi.it  Mon Feb 23 21:44:12 2009
From: alessandro.montaghi at unifi.it (Alessandro)
Date: Mon, 23 Feb 2009 21:44:12 +0100
Subject: [R-sig-Geo] R+SAGA: Table calculator for shapes
Message-ID: <005d01c995f7$7c3f1720$74bd4560$@montaghi@unifi.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090223/78aed80c/attachment.pl>

From brenning at uwaterloo.ca  Mon Feb 23 21:59:17 2009
From: brenning at uwaterloo.ca (Alexander Brenning)
Date: Mon, 23 Feb 2009 15:59:17 -0500
Subject: [R-sig-Geo] R+SAGA: Table calculator for shapes
In-Reply-To: <005d01c995f7$7c3f1720$74bd4560$@montaghi@unifi.it>
References: <005d01c995f7$7c3f1720$74bd4560$@montaghi@unifi.it>
Message-ID: <49A30E25.3090506@uwaterloo.ca>

Dear Alessandro,

it would be easier to give you a constructive answer if you provided at 
least the code that you used.

The SAGA module that you mention does not (yet) have a front-end 
function in the RSAGA package, so I assume that you are using the 
low-level rsaga.geoprocessor function, which is a bit trickier. I hope 
you have carefully read the information provided by rsaga.get.usage on 
the usage of this module.

Cheers
  Alex


Alessandro wrote:
> Hi all and thanks for help,
> 
>  
> 
> I have a shapefile "canopy_height.shp" with two column "a" and "b". I wish
> to do a-b and to obtain a third column ("a-b"). I am using the R+SAGA
> module: "Table calculator for shapes", and all run good, but when I open the
> shape-file after (in ARCMAP)  I don't see the third column. There is a
> option to save a new shape-file? 
> 
>  
> 
> Thanks for Help
> 
>  
> 
> Ale
> 
>  
> 
>  
> 
> SAGA CMD 2.0.3
> 
> library path:   C:\Windows/modules
> 
> library name:   table_calculus
> 
> module name :   Table calculator for shapes
> 
> author      :   
> 
>  
> 
> error: executing module [Table calculator for shapes]
> 
> Usage: -silent -SHAPES <str> [-FORMULA <str>] [-NAME <str>]
> 
>   -SHAPES:<str>         Shapes
> 
>         Shapes (input)
> 
>   -FORMULA:<str>        Formula
> 
>         Text
> 
>   -NAME:<str>           Field Name
> 
>         Text
> 
> The value for the option 'SHAPES' must be specified.
> 
>  
> 
>  
> 
>> rsaga.geoprocessor(lib="table_calculus", module=2,
> param=list(SHAPES="canopy_height.shp", FORMULA="a-b", NAME="a-b"))
> 
>  
> 
> SAGA CMD 2.0.3
> 
> library path:   C:\Windows/modules
> 
> library name:   table_calculus
> 
> module name :   Table calculator for shapes
> 
> author      :   
> 
> Load shapes: canopy_height.shp...
> 
>  
> 
>  
> 
>  
> 
>  
> 
> Parameters
> 
>  
> 
>  
> 
>  
> 
>  
> 
> Shapes: canopy_height.shp
> 
> Formula: a-b
> 
> Field Name: a-b
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 

-- 
Alexander Brenning
brenning at uwaterloo.ca - T +1-519-888-4567 ext 35783
Department of Geography and Environmental Management
University of Waterloo
200 University Ave. W - Waterloo, ON - Canada N2L 3G1
http://www.fes.uwaterloo.ca/geography/faculty/brenning/


From J.vanEtten at cgiar.org  Tue Feb 24 04:22:55 2009
From: J.vanEtten at cgiar.org (van Etten, Jacob (IRRI))
Date: Tue, 24 Feb 2009 11:22:55 +0800
Subject: [R-sig-Geo] cross validation gstat
In-Reply-To: <49A2F99E.6070404@uni-muenster.de>
References: <20090223132758.10075bhqb45s2v8k@www.nexusmail.uwaterloo.ca>
	<49A2F99E.6070404@uni-muenster.de>
Message-ID: <AFBF317E3DEC0B43BF750B4618EBFA0DF7AAA3@HERMES>

Hastie et al. say that k-fold CV with a low k can overestimate the error if there is still significant learning going on when the size of the training set approaches n-n/k. 

Leave-one-out CV, on the other hand, is free of this bias but has a high variance, which is why Hastie et al. dislike it (no further arguments given). Also, it requires more computation effort, obviously.

Jacob van Etten

-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Edzer Pebesma
Sent: Tuesday, February 24, 2009 3:32 AM
To: ddepew at sciborg.uwaterloo.ca
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] cross validation gstat

ddepew at sciborg.uwaterloo.ca wrote:
> Hi list,
> A quick question regarding n-fold validation...
> I've seen several papers suggest the LOOCV is too optimistic. Is
> n-fold closer to a "true" validation?
I don't think "true" validation exists; could you explain what it is? If
you mean having a completely independent set of observations not
involved in forming the predictions, then there are two issues, (i) how
to form this set from the total set: how to select, how large should it
be? (ii) you're simply forming validation statistics without using all
the information you could use.

In the book by Hastie, Tibshiranie and Friedman (statistical learning)
it is argued (in the context of regression models) that LOOCV often
results in many models that are almost identical, whereas n-fold with
low n results in somewhat more different models. I don't recall they
came with a statistical/theoretical argument why this difference among
models was a good thing.

One of the issues is that with n-fold using random folds (as gstat
does), that the result varies if you repeat the procedure--obviously,
but also a bit of a gamble, then. Which one to pick? Look at
distributions of CV statistics?

I think when you look at CV statistics, you need to question why you do
it; often it is because you want to find out how well the model performs
in a predictive setting. In that case things like predicting locations
very close to measurements is often something that is not possible to CV
at all when data are collected somewhat regular in space.
> I am assuming that it uses the variogram that is constructed using ALL
> data, so my assumption is that the variogram is not re-fit for each
> n-fold before estimation...
>
That is correct. Please submit me code with variogram re-estimation when
you have it. ;-)

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Thierry.ONKELINX at inbo.be  Tue Feb 24 10:20:59 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 24 Feb 2009 10:20:59 +0100
Subject: [R-sig-Geo] cross validation gstat
In-Reply-To: <49A2F99E.6070404@uni-muenster.de>
References: <20090223132758.10075bhqb45s2v8k@www.nexusmail.uwaterloo.ca>
	<49A2F99E.6070404@uni-muenster.de>
Message-ID: <2E9C414912813E4EB981326983E0A104061B428E@inboexch.inbo.be>

Dear all,

Im my opinion it makes sense to use repeated k-fold cross validation. The distribution of the statistics yields their confidence intervals.

I will try that during the next few months on a dataset with about 2500 data points. The current plan is to repeat 1000 times a 10-fold cross validation. Or is k = 10 to small? But maybe I will have to downsize this if it requires too much computing time.

The variogram re-estimation is something I had on my mind. I'll send Edzer the code if I manage to get it working.

Cheers,

Thierry


----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics, methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens Edzer Pebesma
Verzonden: maandag 23 februari 2009 20:32
Aan: ddepew at sciborg.uwaterloo.ca
CC: r-sig-geo at stat.math.ethz.ch
Onderwerp: Re: [R-sig-Geo] cross validation gstat

ddepew at sciborg.uwaterloo.ca wrote:
> Hi list,
> A quick question regarding n-fold validation...
> I've seen several papers suggest the LOOCV is too optimistic. Is
> n-fold closer to a "true" validation?
I don't think "true" validation exists; could you explain what it is? If
you mean having a completely independent set of observations not
involved in forming the predictions, then there are two issues, (i) how
to form this set from the total set: how to select, how large should it
be? (ii) you're simply forming validation statistics without using all
the information you could use.

In the book by Hastie, Tibshiranie and Friedman (statistical learning)
it is argued (in the context of regression models) that LOOCV often
results in many models that are almost identical, whereas n-fold with
low n results in somewhat more different models. I don't recall they
came with a statistical/theoretical argument why this difference among
models was a good thing.

One of the issues is that with n-fold using random folds (as gstat
does), that the result varies if you repeat the procedure--obviously,
but also a bit of a gamble, then. Which one to pick? Look at
distributions of CV statistics?

I think when you look at CV statistics, you need to question why you do
it; often it is because you want to find out how well the model performs
in a predictive setting. In that case things like predicting locations
very close to measurements is often something that is not possible to CV
at all when data are collected somewhat regular in space.
> I am assuming that it uses the variogram that is constructed using ALL
> data, so my assumption is that the variogram is not re-fit for each
> n-fold before estimation...
>
That is correct. Please submit me code with variogram re-estimation when
you have it. ;-)

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.


From alessandro.montaghi at unifi.it  Tue Feb 24 10:26:00 2009
From: alessandro.montaghi at unifi.it (Alessandro)
Date: Tue, 24 Feb 2009 10:26:00 +0100
Subject: [R-sig-Geo] substract two columns in a shapefile (but SAGA+R has an
	bug error)
Message-ID: <007101c99661$e8884a90$b998dfb0$@montaghi@unifi.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090224/d0c510a0/attachment.pl>

From Roger.Bivand at nhh.no  Tue Feb 24 10:50:58 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 24 Feb 2009 10:50:58 +0100 (CET)
Subject: [R-sig-Geo] substract two columns in a shapefile (but SAGA+R
 has an bug error)
In-Reply-To: <007101c99661$e8884a90$b998dfb0$@montaghi@unifi.it>
References: <007101c99661$e8884a90$b998dfb0$@montaghi@unifi.it>
Message-ID: <alpine.LRH.2.00.0902241046260.30276@reclus.nhh.no>

On Tue, 24 Feb 2009, Alessandro wrote:

> Dear Researcher,
>
>
>
> I have a shapefile with two columns "a" and "b" and I wish to subtract a-b
> to obtain a new column of difference.  I tried in SAGA + R with the module
> "Table calculator for shapes". This worked without an error, but it didn't
> save the results either. I suspect that this is a bug in the SAGA module.
>
>
>
> Is there an another code or packages (without GRASS+R) to do operation with
> shapefile?


Why not do it the simple way?

Either:

library(maptools)
my_SPDF <- readShapeSpatial("myfile.shp")
my_SPDF$ab <- my_SPDF$a - my_SPDF$b
writeSpatialShape(my_SPDF, "mynewfile")

or:

library(rgdal)
my_SPDF <- readOGR(".", "myfile")
my_SPDF$ab <- my_SPDF$a - my_SPDF$b
writeOGR(my_SPDF, ".", "mynewfile", driver="ESRI Shapefile")

Insert a summary(my_SPDF) to check that a and b are what you think, and 
that ab has been created. It won't work if a and/or b are strings.

Roger

>
>
>
> Thanks
>
>
>
> Ale
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From maechler at stat.math.ethz.ch  Tue Feb 24 11:24:46 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 24 Feb 2009 11:24:46 +0100
Subject: [R-sig-Geo] Timezone boundaries (for adding to world map)?
In-Reply-To: <alpine.LRH.2.00.0902200942110.24812@reclus.nhh.no>
References: <18844.19738.165822.672093@stat.math.ethz.ch>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61CA3E23F3@LP-EXMBVS10.CO.IHC.COM>
	<alpine.LRH.2.00.0902200942110.24812@reclus.nhh.no>
Message-ID: <18851.51950.4084.365570@stat.math.ethz.ch>

>>>>> "RB" == Roger Bivand <Roger.Bivand at nhh.no>
>>>>>     on Fri, 20 Feb 2009 09:55:52 +0100 (CET) writes:

    RB> On Wed, 18 Feb 2009, Greg Snow wrote:
    >> There is a shapefile (works well with maptools and sp packages) with a 
    >> world map and time zone information at: 
    >> http://openmap.bbn.com/data/shape/timezone/
    >> 
    >> It has the info needed to color the countries or parts of countries 
    >> based on time zone, but does not have polygons for time zone stripes 
    >> over the oceans.

    RB> In fact, this shapefile provoked an update in sp, because it is really 
    RB> buggy. 

I'm happy to have provoked progress ;-) :-)

    RB> There are straight-line polygons and many others have multiple 
    RB> repeated coordinates (the sp update fixes these to retain finite label 
    RB> points), but it doesn't fix the absence of most of the data (several DBF 
    RB> columns are empty - checked in oocalc):

    >> library(rgdal)
    >> tz <- readOGR(".", "WrldTZA")
    RB> OGR data source with driver: ESRI Shapefile
    RB> Source: ".", layer: "WrldTZA"
    RB> with  1890  rows and  11  columns
    RB> Feature type: wkbPolygon with 2 dimensions
    RB> Warning messages:
    RB> 1: In Polygon(cbind(jG[[1]], jG[[2]])) :
    RB> Non-finite label point detected and replaced
    RB> 2: In Polygon(cbind(jG[[1]], jG[[2]])) :
    RB> Non-finite label point detected and replaced
    RB> 3: In Polygon(cbind(jG[[1]], jG[[2]])) :
    RB> Non-finite label point detected and replaced
    >> names(tz)
    RB> [1] "FIPS"     "NAME"     "COMMENTS" "REGION"   "LAT"      "LON"
    RB> [7] "TZ"       "GMTOFF"   "LOCALSUM" "OFFSET"   "CLASSES"
    >> summary(tz$GMTOFF)
    RB> NA's
    RB> 1890
    >> summary(tz$TZ)
    RB> NA's
    RB> 1890
    >> summary(tz$OFFSET)
    RB> 0     \xff0        -1    \xff-1    \xff+1       -10       +10
    RB> 25        57        13         7       181        24        38
    RB> \xff+10     +10.5       +11     +11.5       +12   \xff+12        +2
    RB> 24         1        19         3        12        13         1
    RB> \xff-2    \xff+2        +3    \xff-3    \xff+3      -3.5  \xff+3.5
    RB> 4        90        59       146        25         7         3
    RB> -4        +4    \xff-4    \xff+4  \xff+4.5        -5        +5
    RB> 56         4       165         8         1       130        13
    RB> \xff-5    \xff+5  \xff+5.5 \xff+5.75        -6        +6    \xff-6
    RB> 12         3        16         1        77        10        16
    RB> \xff+6  \xff+6.5        -7        +7    \xff+7        -8        +8
    RB> 12        15        63        98        14        61        68
    RB> \xff-8    \xff+8        -9        +9    \xff+9      +9.5      NA's
    RB> 3        56        82        97        13        11        33

    RB> where my locale is UTF-8.

    RB> I wrote to Martin offline that a more recent link is:

    RB> http://efele.net/maps/tz/world/

    RB> and I've put tz_world.rda on http://spatial.nhh.no/R/etc, but it is not 
    RB> line generalised, so it is very large and takes a long time to display - 
    RB> they've kept a lot of boundary detail.

indeed.  But thanks a lot to make it available!!

    RB> Because TZ follow administrative boundaries, they are actually hard to do 
    RB> right. Maybe a raster version might help more if vector precision isn't 
    RB> needed?

as long as we can add a couple of cities (using geographical
coordinates) to it, afterwards, that's fine.

When I load your (above URL) tz file and plot it,
I get the impression that much time is spent on thousands of
very small polygons;
consequently, if I'd want a  ``subset'' of tz that only contains
the polygons that correspond to areas larger than, say, 100 km^2,
how could I do that ?

Looking at the sp-object:

------------------------------------------------------------------------

load("tz_world.rda")

## Look a bit at the 'tz' object:
str(tz, max=2)
## Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
##   ..@ data       :'data.frame':	27704 obs. of  1 variable:
##   .. ..- attr(*, "data_types")= chr "C"
##   ..@ polygons   :List of 27704
##   ..@ plotOrder  : int [1:27704] 24471 111 14349 24641 1598 10291 22351 ...
##   ..@ bbox       : num [1:2, 1:2] -180 -90 180 83.6
##   .. ..- attr(*, "dimnames")=List of 2
##   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots

ltz <- sapply(slotNames(tz), slot, object=tz)
sapply(ltz, object.size)
##        data    polygons   plotOrder        bbox proj4string 
##     1690424   110706296      110856         704         704 

str(tz at data[,1])
##  Factor w/ 382 levels "Africa/Abidjan",..: 307 307 307 307 307 307 ...

str(head(tz at polygons[1:3]), max=1)
## List of 3
##  $ :Formal class 'Polygons' [package "sp"] with 5 slots
##  $ :Formal class 'Polygons' [package "sp"] with 5 slots
##  $ :Formal class 'Polygons' [package "sp"] with 5 slots

------------------------------------------------------------------------

and then ask for 

    showMethods(class = "Polygons")

the result is not so revealing to me; but of course, I'm really
an sp greenhorn.

How could I compute areas?

Regards,
Martin



    RB> Roger

    >> 
    >> Hope this helps,
    >> 
    >> 

    RB> -- 
    RB> Roger Bivand
    RB> Economic Geography Section, Department of Economics, Norwegian School of
    RB> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
    RB> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
    RB> e-mail: Roger.Bivand at nhh.no


From alessandro.montaghi at unifi.it  Tue Feb 24 12:39:27 2009
From: alessandro.montaghi at unifi.it (Alessandro)
Date: Tue, 24 Feb 2009 12:39:27 +0100
Subject: [R-sig-Geo] R: substract two columns in a shapefile (but SAGA+R has
	an bug error)
In-Reply-To: <alpine.LRH.2.00.0902241046260.30276@reclus.nhh.no>
References: <007101c99661$e8884a90$b998dfb0$@montaghi@unifi.it>
	<alpine.LRH.2.00.0902241046260.30276@reclus.nhh.no>
Message-ID: <007901c99674$8d015fa0$a7041ee0$@montaghi@unifi.it>

Dear Prof. Bivand

Tank for help

I tried this cose

library(rgdal)
canopy_height <- readOGR(".", "theme1")
canopy_height$ZDem.sgrd <- canopy_height$Z - canopy_height$Dem.sgrd
writeOGR(canopy_height, ".", "canopy_height", driver="ESRI Shapefile")


because maptool go out of memory, with rgdal the third column appears empty
(value: 0.0000)
I attached a small file of my data set.

Thanks again for your help and time

Ale



-----Messaggio originale-----
Da: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Inviato: marted? 24 febbraio 2009 10.51
A: Alessandro
Cc: r-sig-geo at stat.math.ethz.ch
Oggetto: Re: [R-sig-Geo] substract two columns in a shapefile (but SAGA+R
has an bug error)

On Tue, 24 Feb 2009, Alessandro wrote:

> Dear Researcher,
>
>
>
> I have a shapefile with two columns "a" and "b" and I wish to subtract a-b
> to obtain a new column of difference.  I tried in SAGA + R with the module
> "Table calculator for shapes". This worked without an error, but it didn't
> save the results either. I suspect that this is a bug in the SAGA module.
>
>
>
> Is there an another code or packages (without GRASS+R) to do operation
with
> shapefile?


Why not do it the simple way?

Either:

library(maptools)
my_SPDF <- readShapeSpatial("myfile.shp")
my_SPDF$ab <- my_SPDF$a - my_SPDF$b
writeSpatialShape(my_SPDF, "mynewfile")

or:

library(rgdal)
my_SPDF <- readOGR(".", "myfile")
my_SPDF$ab <- my_SPDF$a - my_SPDF$b
writeOGR(my_SPDF, ".", "mynewfile", driver="ESRI Shapefile")

Insert a summary(my_SPDF) to check that a and b are what you think, and 
that ab has been created. It won't work if a and/or b are strings.

Roger

>
>
>
> Thanks
>
>
>
> Ale
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

-------------- next part --------------
A non-text attachment was scrubbed...
Name: theme1.shp
Type: application/octet-stream
Size: 352 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090224/59bb3e1f/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: theme1.shx
Type: application/octet-stream
Size: 172 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090224/59bb3e1f/attachment-0001.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: theme1.dbf
Type: application/octet-stream
Size: 395 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090224/59bb3e1f/attachment-0002.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: theme1.sbn
Type: application/octet-stream
Size: 220 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090224/59bb3e1f/attachment-0003.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: theme1.sbx
Type: application/octet-stream
Size: 124 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090224/59bb3e1f/attachment-0004.obj>

From alessandro.montaghi at unifi.it  Tue Feb 24 14:41:05 2009
From: alessandro.montaghi at unifi.it (Alessandro)
Date: Tue, 24 Feb 2009 14:41:05 +0100
Subject: [R-sig-Geo] difficult to subtract two column of my shapefile
Message-ID: <008d01c99685$8b14e930$a13ebb90$@montaghi@unifi.it>

Thanks for all help

 

I wish two subtract two column of my shapefile but It look like a impossible
operation with R:

 

1.  In SAGA+R module: "Table calculator for shapes", It runs but doesn't
save the result (there is bug)

2.   I can't use software "GeoDa" because It works only in Windows xp and
not in Windows Vista

3.  Library maptools go down for a memory problems

4.  library(rgdal) give an empty column

 

is there suggestion? please.

 

I attach a small part of my data-set for 

 

Thanks for Help and suggestion

 

 

library(maptools)

my_SPDF <- readShapeSpatial("theme1.shp") 

my_SPDF$ab <- my_SPDF$a - my_SPDF$b 

writeSpatialShape(my_SPDF, "mynewfile")

 

or:

 

library(rgdal)

my_SPDF <- readOGR(".", "theme1")

my_SPDF$ab <- my_SPDF$a - my_SPDF$b

writeOGR(my_SPDF, ".", "mynewfile", driver="ESRI Shapefile")

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090224/f098864f/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: THEME1.zip
Type: application/octet-stream
Size: 1084 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090224/f098864f/attachment.obj>

From andersonfaye7 at gmail.com  Tue Feb 24 15:35:02 2009
From: andersonfaye7 at gmail.com (Faye Anderson)
Date: Tue, 24 Feb 2009 08:35:02 -0600
Subject: [R-sig-Geo] Iteratively Reweighted Generalized Least Squares
	IRWGLS
Message-ID: <e06a91f30902240635w370a6820m995ac794434ce890@mail.gmail.com>

Hi All,
I think sgeostat function fit.variogram does it.
Thanks.
Faye


From brenning at uwaterloo.ca  Tue Feb 24 15:37:23 2009
From: brenning at uwaterloo.ca (Alexander Brenning)
Date: Tue, 24 Feb 2009 09:37:23 -0500
Subject: [R-sig-Geo] difficult to subtract two column of my shapefile
In-Reply-To: <008d01c99685$8b14e930$a13ebb90$@montaghi@unifi.it>
References: <008d01c99685$8b14e930$a13ebb90$@montaghi@unifi.it>
Message-ID: <49A40623.4080401@uwaterloo.ca>

Hi there,

to throw in two more alternatives, there are functions read.dbf and 
write.dbf in packages shapefiles and foreign (see help files for 
examples; the functions differ between the two packages despite having 
the same name).

Remember that operations on the shapefile attributes only affect the dbf 
file of the shape"file" (which is not really a file but a set of files). 
So this will work as long as you don't change the number or order of the 
rows.

This may also be more efficient if the shapes have complex geometry 
(e.g. complex polygons, contour lines...), because the geometry is not 
imported by the functions I mentioned.

Cheers
  Alex


Alessandro wrote:
> Thanks for all help
> 
>  
> 
> I wish two subtract two column of my shapefile but It look like a impossible
> operation with R:
> 
>  
> 
> 1.  In SAGA+R module: "Table calculator for shapes", It runs but doesn't
> save the result (there is bug)
> 
> 2.   I can't use software "GeoDa" because It works only in Windows xp and
> not in Windows Vista
> 
> 3.  Library maptools go down for a memory problems
> 
> 4.  library(rgdal) give an empty column
> 
>  
> 
> is there suggestion? please.
> 
>  
> 
> I attach a small part of my data-set for 
> 
>  
> 
> Thanks for Help and suggestion
> 
>  
> 
>  
> 
> library(maptools)
> 
> my_SPDF <- readShapeSpatial("theme1.shp") 
> 
> my_SPDF$ab <- my_SPDF$a - my_SPDF$b 
> 
> writeSpatialShape(my_SPDF, "mynewfile")
> 
>  
> 
> or:
> 
>  
> 
> library(rgdal)
> 
> my_SPDF <- readOGR(".", "theme1")
> 
> my_SPDF$ab <- my_SPDF$a - my_SPDF$b
> 
> writeOGR(my_SPDF, ".", "mynewfile", driver="ESRI Shapefile")
> 
>  
> 
> 
> 
> 
> ------------------------------------------------------------------------
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Alexander Brenning
brenning at uwaterloo.ca - T +1-519-888-4567 ext 35783
Department of Geography and Environmental Management
University of Waterloo
200 University Ave. W - Waterloo, ON - Canada N2L 3G1
http://www.fes.uwaterloo.ca/geography/faculty/brenning/


From edzer.pebesma at uni-muenster.de  Tue Feb 24 15:58:43 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 24 Feb 2009 15:58:43 +0100
Subject: [R-sig-Geo] Iteratively Reweighted Generalized Least Squares
 IRWGLS
In-Reply-To: <e06a91f30902240635w370a6820m995ac794434ce890@mail.gmail.com>
References: <e06a91f30902240635w370a6820m995ac794434ce890@mail.gmail.com>
Message-ID: <49A40B23.4050800@uni-muenster.de>



Faye Anderson wrote:
> Hi All,
> I think sgeostat function fit.variogram does it.
>   
No, it does not quantify the correlations between variogram estimates,
so you'd better forget about the "Generalized" -- just look at the
output of variogram() that it reads; also the reweighting is only used
when you ask for it; it's a rather problematic feature IMO, as you'd
change the definition of the thing you optimize while you're optimizing
it...

In your original question you forgot to mention that you meant IRWGLS
for variogram model fitting.
--
Edzer
> Thanks.
> Faye
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From jjmaynard at ucdavis.edu  Tue Feb 24 16:49:31 2009
From: jjmaynard at ucdavis.edu (Jonathan Maynard)
Date: Tue, 24 Feb 2009 07:49:31 -0800
Subject: [R-sig-Geo] difficult to subtract two column of my shapefile
In-Reply-To: <49A40623.4080401@uwaterloo.ca>
References: <49A40623.4080401@uwaterloo.ca>
Message-ID: <da51e0870902240749q4daaa2dao2f0f0278ab5ab419@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090224/7189f801/attachment.pl>

From r.hijmans at gmail.com  Tue Feb 24 16:54:54 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Tue, 24 Feb 2009 23:54:54 +0800
Subject: [R-sig-Geo] difficult to subtract two column of my shapefile
In-Reply-To: <49A40623.4080401@uwaterloo.ca>
References: <49A40623.4080401@uwaterloo.ca>
Message-ID: <dc22b2570902240754t1ca66107gba2f6fcddb923692@mail.gmail.com>

indeed, on the example file, this works fine.

library(foreign)
data <- read.dbf('theme1.dbf')
data$AminB <- data$A - data$B
file.remove('theme1.dbf')
write.dbf(data, 'theme1.dbf')

if the dbf is too large you could you use a database to import the
dbf, add the column, export again. Perhaps sqlite (in R).

(((((( in your first post you said you have ArcMap: open attribute
table, options/add field, highlight field, right click/  field
calculator, a - b  ))))))


On Tue, Feb 24, 2009 at 10:37 PM, Alexander Brenning
<brenning at uwaterloo.ca> wrote:
> Hi there,
>
> to throw in two more alternatives, there are functions read.dbf and
> write.dbf in packages shapefiles and foreign (see help files for examples;
> the functions differ between the two packages despite having the same name).
>
> Remember that operations on the shapefile attributes only affect the dbf
> file of the shape"file" (which is not really a file but a set of files). So
> this will work as long as you don't change the number or order of the rows.
>
> This may also be more efficient if the shapes have complex geometry (e.g.
> complex polygons, contour lines...), because the geometry is not imported by
> the functions I mentioned.
>
> Cheers
> ?Alex
>
>
> Alessandro wrote:
>>
>> Thanks for all help
>>
>>
>> I wish two subtract two column of my shapefile but It look like a
>> impossible
>> operation with R:
>>
>>
>> 1. ?In SAGA+R module: "Table calculator for shapes", It runs but doesn't
>> save the result (there is bug)
>>
>> 2. ? I can't use software "GeoDa" because It works only in Windows xp and
>> not in Windows Vista
>>
>> 3. ?Library maptools go down for a memory problems
>>
>> 4. ?library(rgdal) give an empty column
>>
>>
>> is there suggestion? please.
>>
>>
>> I attach a small part of my data-set for
>>
>> Thanks for Help and suggestion
>>
>>
>>
>> library(maptools)
>>
>> my_SPDF <- readShapeSpatial("theme1.shp")
>> my_SPDF$ab <- my_SPDF$a - my_SPDF$b
>> writeSpatialShape(my_SPDF, "mynewfile")
>>
>>
>> or:
>>
>>
>> library(rgdal)
>>
>> my_SPDF <- readOGR(".", "theme1")
>>
>> my_SPDF$ab <- my_SPDF$a - my_SPDF$b
>>
>> writeOGR(my_SPDF, ".", "mynewfile", driver="ESRI Shapefile")
>>
>>
>>
>>
>>
>> ------------------------------------------------------------------------
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> --
> Alexander Brenning
> brenning at uwaterloo.ca - T +1-519-888-4567 ext 35783
> Department of Geography and Environmental Management
> University of Waterloo
> 200 University Ave. W - Waterloo, ON - Canada N2L 3G1
> http://www.fes.uwaterloo.ca/geography/faculty/brenning/
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From Pilar.Tugores at ba.ieo.es  Tue Feb 24 17:42:07 2009
From: Pilar.Tugores at ba.ieo.es (Pilar Tugores Ferra)
Date: Tue, 24 Feb 2009 17:42:07 +0100
Subject: [R-sig-Geo] variance estimation (gstat, geoR, automap)
Message-ID: <0838E01493845742A4D4039EA34EB1C15143C1@ieopalma2.ba.ieo.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090224/914220a1/attachment.pl>

From hacke78 at googlemail.com  Tue Feb 24 18:21:15 2009
From: hacke78 at googlemail.com (Jan Hackenberg)
Date: Tue, 24 Feb 2009 18:21:15 +0100
Subject: [R-sig-Geo] German Grid
Message-ID: <bd496c5e0902240921h2cab337ev9658679f8eeeea5f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090224/8d41b55e/attachment.pl>

From Gerard.Heuvelink at wur.nl  Tue Feb 24 19:43:28 2009
From: Gerard.Heuvelink at wur.nl (Heuvelink, Gerard)
Date: Tue, 24 Feb 2009 19:43:28 +0100
Subject: [R-sig-Geo] stratified random sampling
Message-ID: <5DA773FDB5D4484D9A8E36F6C3DC0180BB4BD1@scomp0039.wurnet.nl>

Dear list,
 
The stratified random sampling problem that I submitted a few days ago has already been solved, with the help of several of you, notably Edzer Pebesma. Edzer came up with the following solution:
 
library(sp)
library(rgdal)
nc1 <- readShapePoly(system.file("shapes/sids.shp",package="maptools")[1], proj4string=CRS("+proj=longlat +datum=NAD27"))
pts = do.call(rbind, sapply(slot(nc1, "polygons"), spsample, n=1, type="random"))
plot(nc1)
points(pts, col='blue', pch=19, cex=1)
 
As it happened, the do.call statement did not work in my case (Edzer and Roger may look into why it does not work with all shapes) and had to be replaced by:
 
for (i in 1:length(slot(nc1, "polygons"))) {
    pt = spsample(nc1[i,], n=1, type="random")
    if (i == 1)
        pts = pt
    else
        pts = rbind(pts, pt)
}

I am so happy!

Gerard


From alessandro.montaghi at unifi.it  Tue Feb 24 20:08:11 2009
From: alessandro.montaghi at unifi.it (Alessandro)
Date: Tue, 24 Feb 2009 20:08:11 +0100
Subject: [R-sig-Geo] Help to improve a code to substract two columns,
	delete and save shape-file
Message-ID: <00b101c996b3$3d11f830$b735e890$@montaghi@unifi.it>

Thanks for All help give me.

 

I spoke with my professor and now I must do some changes. After subtract the
column Z with clomun DEM_SGRD to obtain column H. I wish to create a new
shape with only this H column. I tried and tried but when I write the shape
file there is always an error.

Sorry for all disturb.

 

I don't want to be ill-mannered, to use improperly your time, but before to
save the shape is It possible to save only all records with H value > of 2.
(the statistical analysis need this clean)

 

Thanks

 

Ale

 

 

 

> prova <- readOGR(".", "prova")

 

OGR data source with driver: ESRI Shapefile 

Source: ".", layer: "prova"

with  42  rows and  2  columns

 

> summary(prova)

 

Object of class SpatialPointsDataFrame

Coordinates:

                min       max

coords.x1  267980.1  267998.1

coords.x2 4147799.4 4147818.8

Is projected: NA 

proj4string : [NA]

Number of points: 42

Data attributes:

       Z           DEM_SGRD   

 Min.   :1415   Min.   :1412  

 1st Qu.:1419   1st Qu.:1413  

 Median :1421   Median :1414  

 Mean   :1423   Mean   :1414  

 3rd Qu.:1424   3rd Qu.:1415  

 Max.   :1437   Max.   :1417  

 

> prova$H <- prova$Z - prova$DEM_SGRD 

 

> summary(prova)

 

Object of class SpatialPointsDataFrame

Coordinates:

                min       max

coords.x1  267980.1  267998.1

coords.x2 4147799.4 4147818.8

Is projected: NA 

proj4string : [NA]

Number of points: 42

Data attributes:

       Z           DEM_SGRD          H         

 Min.   :1415   Min.   :1412   Min.   : 3.169  

 1st Qu.:1419   1st Qu.:1413   1st Qu.: 5.612  

 Median :1421   Median :1414   Median : 7.320  

 Mean   :1423   Mean   :1414   Mean   : 9.265  

 3rd Qu.:1424   3rd Qu.:1415   3rd Qu.:10.982  

 Max.   :1437   Max.   :1417   Max.   :21.806  

 

> prova2 <-  prova$H

 

> summary(prova2)

   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 

  3.169   5.612   7.320   9.265  10.980  21.810 

 

> writeOGR(prova2, ".", "prova2", driver="ESRI Shapefile")

Errore in writeOGR(prova2, ".", "prova2", driver = "ESRI Shapefile") : 

  obj of wrong class

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090224/f52ae7bf/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: prova.zip
Type: application/octet-stream
Size: 2204 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090224/f52ae7bf/attachment.obj>

From Virgilio.Gomez at uclm.es  Tue Feb 24 21:57:24 2009
From: Virgilio.Gomez at uclm.es (Virgilio Gomez Rubio)
Date: Tue, 24 Feb 2009 21:57:24 +0100
Subject: [R-sig-Geo] German Grid
In-Reply-To: <bd496c5e0902240921h2cab337ev9658679f8eeeea5f@mail.gmail.com>
References: <bd496c5e0902240921h2cab337ev9658679f8eeeea5f@mail.gmail.com>
Message-ID: <1235509044.7176.1.camel@Virgilio-Gomez>

Jan,


If you have the boundaries of Germany and you want to make your own
grid, you can use the overlay method to 'cut' the grid so that you only
get the points inside Germany. You can use this object in gstat to make
your predictions.

Hope this helps,

Virgilio

El mar, 24-02-2009 a las 18:21 +0100, Jan Hackenberg escribi?:
> Hello
> im doing a project with Interpolating ( Kriging ) Temperature Data from many
> Stations in Germany. To do a Kriging i have to use a Grid. So I have now 2
> options. The better one is too download a prepared grid with the borders of
> Germany. Then the interpolated map will look great, because i have only
> Points inside German borders. So does anyone have got such a grid?
> If no, the other is to make a grid inside a German Bounding Box. Then my map
> will be a quare :). I have looked in the meuse Data set how such a grid
> looks like :
> > meuse.grid
> Object of class SpatialPixelsDataFrame
> Object of class SpatialPixels
> Grid topology:
>   cellcentre.offset cellsize cells.dim
> x            178460       40        78
> y            329620       40       104
> SpatialPoints:
>              x      y
>    [1,] 181180 333740
>    [2,] 181140 333700
>    [3,] 181180 333700
> and so on.
> So is there any Possibility to make such a grid, if i know : Coordinates of
> my Bounding Box (upper left coodinates for example (200000,540000), upper
> right(900000,650000)) and Cellsize for Example 10000?
> I woult prefer too download an existing grid.
> Sorry for my bad english and bad knowledge of R. :)
> Greetings Jan Hackenberg
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From p.hiemstra at geo.uu.nl  Tue Feb 24 22:41:56 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 24 Feb 2009 22:41:56 +0100
Subject: [R-sig-Geo] German Grid
In-Reply-To: <1235509044.7176.1.camel@Virgilio-Gomez>
References: <bd496c5e0902240921h2cab337ev9658679f8eeeea5f@mail.gmail.com>
	<1235509044.7176.1.camel@Virgilio-Gomez>
Message-ID: <49A469A4.9050405@geo.uu.nl>

Hi Jan,

Even simpler, once you have a SpatialPolygons object you can use 
spsample() to make a grid in that polygon. For reading polygons look at 
the rgdal package or readShapePoly() in the maptools package. See 
http://spatial.nhh.no/R/etc/world_map_intro.html for a shapefile for the 
whole world, probably you could get a map of germany from that quite easily.

Be sure to take a look at the automap package, it is a wrapper around 
gstat, automating interpolation. Just see what you get from that as a 
start. automap is not (yet) on cran, but you can download it from my 
website (I wrote the package and now I'm advertising it :)) 
http:/intamap.geo.uu.nl/~paul/Downloads.html.

cheers,
Paul

Virgilio Gomez Rubio schreef:
> Jan,
>
>
> If you have the boundaries of Germany and you want to make your own
> grid, you can use the overlay method to 'cut' the grid so that you only
> get the points inside Germany. You can use this object in gstat to make
> your predictions.
>
> Hope this helps,
>
> Virgilio
>
> El mar, 24-02-2009 a las 18:21 +0100, Jan Hackenberg escribi?:
>   
>> Hello
>> im doing a project with Interpolating ( Kriging ) Temperature Data from many
>> Stations in Germany. To do a Kriging i have to use a Grid. So I have now 2
>> options. The better one is too download a prepared grid with the borders of
>> Germany. Then the interpolated map will look great, because i have only
>> Points inside German borders. So does anyone have got such a grid?
>> If no, the other is to make a grid inside a German Bounding Box. Then my map
>> will be a quare :). I have looked in the meuse Data set how such a grid
>> looks like :
>>     
>>> meuse.grid
>>>       
>> Object of class SpatialPixelsDataFrame
>> Object of class SpatialPixels
>> Grid topology:
>>   cellcentre.offset cellsize cells.dim
>> x            178460       40        78
>> y            329620       40       104
>> SpatialPoints:
>>              x      y
>>    [1,] 181180 333740
>>    [2,] 181140 333700
>>    [3,] 181180 333700
>> and so on.
>> So is there any Possibility to make such a grid, if i know : Coordinates of
>> my Bounding Box (upper left coodinates for example (200000,540000), upper
>> right(900000,650000)) and Cellsize for Example 10000?
>> I woult prefer too download an existing grid.
>> Sorry for my bad english and bad knowledge of R. :)
>> Greetings Jan Hackenberg
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>     
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From p.hiemstra at geo.uu.nl  Tue Feb 24 22:50:02 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 24 Feb 2009 22:50:02 +0100
Subject: [R-sig-Geo] Help to improve a code to substract two columns,
 delete and save shape-file
In-Reply-To: <00b101c996b3$3d11f830$b735e890$@montaghi@unifi.it>
References: <00b101c996b3$3d11f830$b735e890$@montaghi@unifi.it>
Message-ID: <49A46B8A.10606@geo.uu.nl>

Ale,

Some remarks between the lines:

Alessandro schreef:
>
> Thanks for All help give me.
>
> I spoke with my professor and now I must do some changes. After 
> subtract the column Z with clomun DEM_SGRD to obtain column H. I wish 
> to create a new shape with only this H column. I tried and tried but 
> when I write the shape file there is always an error.
>
> Sorry for all disturb.
>
> I don?t want to be ill-mannered, to use improperly your time, but 
> before to save the shape is It possible to save only all records with 
> H value > of 2. (the statistical analysis need this clean)
>
> Thanks
>
> Ale
>
> > prova <- readOGR(".", "prova")
>
> OGR data source with driver: ESRI Shapefile
>
> Source: ".", layer: "prova"
>
> with 42 rows and 2 columns
>
> > summary(prova)
>
> Object of class SpatialPointsDataFrame
>
> Coordinates:
>
> min max
>
> coords.x1 267980.1 267998.1
>
> coords.x2 4147799.4 4147818.8
>
> Is projected: NA
>
> proj4string : [NA]
>
> Number of points: 42
>
> Data attributes:
>
> Z DEM_SGRD
>
> Min. :1415 Min. :1412
>
> 1st Qu.:1419 1st Qu.:1413
>
> Median :1421 Median :1414
>
> Mean :1423 Mean :1414
>
> 3rd Qu.:1424 3rd Qu.:1415
>
> Max. :1437 Max. :1417
>
> > prova$H <- prova$Z - prova$DEM_SGRD
>
> > summary(prova)
>
> Object of class SpatialPointsDataFrame
>
> Coordinates:
>
> min max
>
> coords.x1 267980.1 267998.1
>
> coords.x2 4147799.4 4147818.8
>
> Is projected: NA
>
> proj4string : [NA]
>
> Number of points: 42
>
> Data attributes:
>
> Z DEM_SGRD H
>
> Min. :1415 Min. :1412 Min. : 3.169
>
> 1st Qu.:1419 1st Qu.:1413 1st Qu.: 5.612
>
> Median :1421 Median :1414 Median : 7.320
>
> Mean :1423 Mean :1414 Mean : 9.265
>
> 3rd Qu.:1424 3rd Qu.:1415 3rd Qu.:10.982
>
> Max. :1437 Max. :1417 Max. :21.806
>
> > prova2 <- prova$H
>
Here you extract the data from prova, not including the coordinates. 
Look at class(prova2) to see that it is no longer a 
SpatialPointsDataFrame but a data.frame. Use the following syntax to get 
the data plus the coordinates:

prova2 <- prova["H"]

Now you can export it using write OGR. To get only the values above H == 2:

prova_Hgt2 = prova2[prova2$H > 2,]

Or combining the two actions above into one command:

prova2 = prova[prova$H > 2, "H"]

cheers,
Paul
>
> > summary(prova2)
>
> Min. 1st Qu. Median Mean 3rd Qu. Max.
>
> 3.169 5.612 7.320 9.265 10.980 21.810
>
> > writeOGR(prova2, ".", "prova2", driver="ESRI Shapefile")
>
> Errore in writeOGR(prova2, ".", "prova2", driver = "ESRI Shapefile") :
>
> obj of wrong class
>
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From p.hiemstra at geo.uu.nl  Tue Feb 24 23:03:27 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 24 Feb 2009 23:03:27 +0100
Subject: [R-sig-Geo] variance estimation (gstat, geoR, automap)
In-Reply-To: <0838E01493845742A4D4039EA34EB1C15143C1@ieopalma2.ba.ieo.es>
References: <0838E01493845742A4D4039EA34EB1C15143C1@ieopalma2.ba.ieo.es>
Message-ID: <49A46EAF.1040906@geo.uu.nl>

Hi Pilar,

I think this list appropriate :). What would be a good idea is to get a 
book that describes kriging, some standard books are:

Chil?s, J. & Delfiner, P. Geostatistics: Modeling Spatial Uncertainty 
John Wiley & Sons, New York, 1999
Christensen, R. Plane Answers to Complex Questions: The Theory of Linear 
Models Springer, New York, 1996
Journel, A. & Huijbregts, C. Mining Geostatistics Academic Press., 1978

A more practical book would be the Applied Spatial Data Analysis in R, 
see http://www.asdar-book.org/ for more info.

On the web you could look at:

http://www.kriging.com/, Owned by Isobel Clark
http://spatial-analyst.net/wiki/index.php?title=Main_Page, not sure if 
there is something here on  the theory of kriging.

For a description of kriging (quite mathematical) you can also look at a 
paper I wrote, you can download it from 
http://intamap.geo.uu.nl/~paul/Publications.html, it is the first one 
titled Read-time automatic...etc

This is all I could think of :).

cheers,
Paul

Pilar Tugores Ferra schreef:
> Dear all,
>
> I'm trying to estimate the variance of a global abundance estimation computed by kriging interpolation and I am stuck.
>
> One can easily retrieve the variance at each prediction location (either using the package gstat, geoR or automap) using expressions similar to:
>
>   
>> kriging_object$krige.var
>>     
>
> or >kriging_object$var1.var
>
>  
>
> but, in fact,  I have no idea how these variance values are computed.
>
> Could anybody tell me how is it computed or suggest  some reference material? 
>
> Could this question be inappropriate for this list in which case I would also apprieciate if someone could tell me where to ask it.
>
> Cheers,
>
> Pilar
>
>  
>
> M? Pilar Tugores Ferr?
>
> PhD Student
>
> Instituto Espa?ol de Oceanograf?a
>
> Centro Oceanogr?fico de Baleares
>
> Muelle de Poniente s/n
>
> 07015 Palma de Mallorca
>
> Baleares, Espa?a
>
> Telf.: (34) 971 401561
>
>  
>
>
>
> La informaci?n contenida en este e-mail y sus ficheros adjuntos es totalmente confidencial y no deber?a ser usado si no fuera usted alguno de los destinatarios. Si ha recibido este e-mail por error, por favor avise al remitente y b?rrelo de su buz?n o de cualquier otro medio de almacenamiento.   This email is confidential and should not be used by anyone who is not the original intended  recipient. If you have received this e-mail in  error please inform the sender and delete it from  your mailbox or any other storage mechanism.
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From Virgilio.Gomez at uclm.es  Wed Feb 25 09:43:59 2009
From: Virgilio.Gomez at uclm.es (Virgilio Gomez Rubio)
Date: Wed, 25 Feb 2009 09:43:59 +0100
Subject: [R-sig-Geo] variance estimation (gstat, geoR, automap)
In-Reply-To: <49A46EAF.1040906@geo.uu.nl>
References: <0838E01493845742A4D4039EA34EB1C15143C1@ieopalma2.ba.ieo.es>
	<49A46EAF.1040906@geo.uu.nl>
Message-ID: <1235551439.7599.4.camel@Virgilio-Gomez>

Hi,


In addition to the list provided by Paul, I would like to add

Geostatistics for Environmental Scientists, 2nd Edition
Richard Webster, Margaret A. Oliver 

I have used it in courses for agricultural and environmental engineers
and it worked well. I think that the balance between mathematical
complexity and applications is quite good.

Best,

Virgilio



El mar, 24-02-2009 a las 23:03 +0100, Paul Hiemstra escribi?:
> Hi Pilar,
> 
> I think this list appropriate :). What would be a good idea is to get a 
> book that describes kriging, some standard books are:
> 
> Chil?s, J. & Delfiner, P. Geostatistics: Modeling Spatial Uncertainty 
> John Wiley & Sons, New York, 1999
> Christensen, R. Plane Answers to Complex Questions: The Theory of Linear 
> Models Springer, New York, 1996
> Journel, A. & Huijbregts, C. Mining Geostatistics Academic Press., 1978
> 
> A more practical book would be the Applied Spatial Data Analysis in R, 
> see http://www.asdar-book.org/ for more info.
> 
> On the web you could look at:
> 
> http://www.kriging.com/, Owned by Isobel Clark
> http://spatial-analyst.net/wiki/index.php?title=Main_Page, not sure if 
> there is something here on  the theory of kriging.
> 
> For a description of kriging (quite mathematical) you can also look at a 
> paper I wrote, you can download it from 
> http://intamap.geo.uu.nl/~paul/Publications.html, it is the first one 
> titled Read-time automatic...etc
> 
> This is all I could think of :).
> 
> cheers,
> Paul
> 
> Pilar Tugores Ferra schreef:
> > Dear all,
> >
> > I'm trying to estimate the variance of a global abundance estimation computed by kriging interpolation and I am stuck.
> >
> > One can easily retrieve the variance at each prediction location (either using the package gstat, geoR or automap) using expressions similar to:
> >
> >   
> >> kriging_object$krige.var
> >>     
> >
> > or >kriging_object$var1.var
> >
> >  
> >
> > but, in fact,  I have no idea how these variance values are computed.
> >
> > Could anybody tell me how is it computed or suggest  some reference material? 
> >
> > Could this question be inappropriate for this list in which case I would also apprieciate if someone could tell me where to ask it.
> >
> > Cheers,
> >
> > Pilar
> >
> >  
> >
> > M? Pilar Tugores Ferr?
> >
> > PhD Student
> >
> > Instituto Espa?ol de Oceanograf?a
> >
> > Centro Oceanogr?fico de Baleares
> >
> > Muelle de Poniente s/n
> >
> > 07015 Palma de Mallorca
> >
> > Baleares, Espa?a
> >
> > Telf.: (34) 971 401561
> >
> >  
> >
> >
> >
> > La informaci?n contenida en este e-mail y sus ficheros adjuntos es totalmente confidencial y no deber?a ser usado si no fuera usted alguno de los destinatarios. Si ha recibido este e-mail por error, por favor avise al remitente y b?rrelo de su buz?n o de cualquier otro medio de almacenamiento.   This email is confidential and should not be used by anyone who is not the original intended  recipient. If you have received this e-mail in  error please inform the sender and delete it from  your mailbox or any other storage mechanism.
> > 	[[alternative HTML version deleted]]
> >
> >   
> > ------------------------------------------------------------------------
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >   
> 
> 


From Roger.Bivand at nhh.no  Wed Feb 25 09:53:36 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 25 Feb 2009 09:53:36 +0100 (CET)
Subject: [R-sig-Geo] stratified random sampling
In-Reply-To: <5DA773FDB5D4484D9A8E36F6C3DC0180BB4BD1@scomp0039.wurnet.nl>
References: <5DA773FDB5D4484D9A8E36F6C3DC0180BB4BD1@scomp0039.wurnet.nl>
Message-ID: <alpine.LRH.2.00.0902250930450.1647@reclus.nhh.no>

On Tue, 24 Feb 2009, Heuvelink, Gerard wrote:

> Dear list,
>
> The stratified random sampling problem that I submitted a few days ago 
> has already been solved, with the help of several of you, notably Edzer 
> Pebesma. Edzer came up with the following solution:

WARNING!! This is only conditionally correct. See below for analysis.

>
> library(sp)
> library(rgdal)
> nc1 <- readShapePoly(system.file("shapes/sids.shp",package="maptools")[1],
+ proj4string=CRS("+proj=longlat +datum=NAD27"))
> pts = do.call(rbind, sapply(slot(nc1, "polygons"), spsample, n=1,
+ type="random"))
> plot(nc1)
> points(pts, col='blue', pch=19, cex=1)
>
> As it happened, the do.call statement did not work in my case (Edzer and 
> Roger may look into why it does not work with all shapes)

It was because the shapefile was no good, with both self-intersecting and 
overlapping polygons. This left some values returned by spsample in the 
sapply call as NULL (correctly), and no rbind() method exists for 
SpatialPoints and NULL objects.

> and had to be replaced by:
>
> for (i in 1:length(slot(nc1, "polygons"))) {
>    pt = spsample(nc1[i,], n=1, type="random")
>    if (i == 1)
>        pts = pt
>    else
>        pts = rbind(pts, pt)
> }
>

This gets a result - there are other ways of doing it too, but it is not 
what it seems. Because the polygons are self-intersecting and overlapping, 
the point-in-polygon algorithm is not choosing points correctly (spsample 
for a ring generates more points than needed in the bounding box of the 
polygon, and chooses the number needed from those that fall within the 
polygon).

The input shapefile is a vectorised map of soil types from raster data, 
but unfortunately the software used to generate it is unknown, so we can't 
warn people off it. Assuming that only one soil type occurs in each raster 
cell, we can reproduce the case with meuse.grid:

library(sp)
data(meuse.grid)
coordinates(meuse.grid) <- c("x", "y")
gridded(meuse.grid) <- TRUE
meuse.grid$soil <- factor(meuse.grid$soil)
spplot(meuse.grid, "soil")
meuseSP <- as(meuse.grid, "SpatialPolygons")
ID <- as.character(meuse.grid$soil)
library(maptools)
meuseSP1 <- unionSpatialPolygons(meuseSP, ID)
plot(meuseSP1, col=1:3)
pts = do.call(rbind, sapply(slot(meuseSP1, "polygons"), spsample, n=1,
  type="random"))
points(pts, pch=3, col="white")

Doing the raster to vector conversion in R ought to resolve the underlying 
problem of the soil polygons being generated from the raster values in an 
inappropriate way.

> I am so happy!

Sorry, no comment! I have replied off-list too, but unfortunately bad 
shapefiles really do exist, and they cause lots of problems.

Roger

>
> Gerard
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From jmblanco at ub.edu  Wed Feb 25 12:02:07 2009
From: jmblanco at ub.edu (=?ISO-8859-1?Q?=22Jos=E9_M=2E_Blanco_Moreno=22?=)
Date: Wed, 25 Feb 2009 12:02:07 +0100
Subject: [R-sig-Geo] problem with readOGR
Message-ID: <49A5252F.20004@ub.edu>

Dear list members,
I have been trying to import a shapefile, but I am facing the following 
problem:
 > readOGR('.','SOU-0')
Error en ogrInfo(dsn = dsn, layer = layer, input_field_name_encoding = 
input_field_name_encoding) :
  Multiple # dimensions: 2:1364727026
 > ogrInfo('.','SOU-0')
Error en ogrInfo(".", "SOU-0") : Multiple # dimensions: 2:21374114

The problem seems to be with:
 > ogrFIDs('.','SOU-0')
[1]        0        1        2        3        4        5        
6        7        8        9
[...snipped content...]
[81]       80       81       82 21374112

I don't know why, but an integer seems to be imported as if it were 
double (or something like that!)
If I open the dbf file and save it (with e.g. MS Excel) as a dbase IV 
file, then it works. However, when I have to do this repeatedly it can 
be really annoying. Is there any way to overcome it? It is a documented 
issue (if so, excuse me)?

Thank you very much for any help that you can offer.

Jos? M.

You can find the file here:
http://www.maplibrary.org/stacks/Africa/South%20Africa/KwaZulu-Natal/SOU-0_admin_SHP.zip

This is the information on the system:

 > sessionInfo()
R version 2.8.1 (2008-12-22)
i386-pc-mingw32

locale:
LC_COLLATE=Spanish_Spain.1252;LC_CTYPE=Spanish_Spain.1252;LC_MONETARY=Spanish_Spain.1252;LC_NUMERIC=C;LC_TIME=Spanish_Spain.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base    
 > library(rgdal)
Loading required package: sp
Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 1.6.0, released 2008/12/04
Path to GDAL shared files: C:/ARCHIV~1/R/R-28~1.1/library/rgdal/gdal
Loaded PROJ.4 runtime: Rel. 4.6.1, 21 August 2008
Path to PROJ.4 shared files: C:/ARCHIV~1/R/R-28~1.1/library/rgdal/proj
 > library(maptools)
Loading required package: foreign
 > readOGR('.','SOU-0')
Error en ogrInfo(dsn = dsn, layer = layer, input_field_name_encoding = 
input_field_name_encoding) :
  Multiple # dimensions: 2:1364727026
 > ogrInfo('.','SOU-0')
Error en ogrInfo(".", "SOU-0") : Multiple # dimensions: 2:21374114
 > ogrFIDs('.','SOU-0')
 [1]        0        1        2        3        4        5        
6        7        8        9
[11]       10       11       12       13       14       15       
16       17       18       19
[21]       20       21       22       23       24       25       
26       27       28       29
[31]       30       31       32       33       34       35       
36       37       38       39
[41]       40       41       42       43       44       45       
46       47       48       49
[51]       50       51       52       53       54       55       
56       57       58       59
[61]       60       61       62       63       64       65       
66       67       68       69
[71]       70       71       72       73       74       75       
76       77       78       79
[81]       80       81       82 21374112

-- 
---------------------------------------
Jos? M. Blanco-Moreno

Dept. de Biologia Vegetal (Bot?nica)
Facultat de Biologia
Universitat de Barcelona
Av. Diagonal 645
08028 Barcelona
SPAIN
---------------------------------------

phone: (+34) 934 039 863
fax: (+34) 934 112 842


From Roger.Bivand at nhh.no  Wed Feb 25 14:08:02 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 25 Feb 2009 14:08:02 +0100 (CET)
Subject: [R-sig-Geo] problem with readOGR
In-Reply-To: <49A5252F.20004@ub.edu>
References: <49A5252F.20004@ub.edu>
Message-ID: <alpine.LRH.2.00.0902251359330.1647@reclus.nhh.no>

On Wed, 25 Feb 2009, "Jos? M. Blanco Moreno" wrote:

> Dear list members,
> I have been trying to import a shapefile, but I am facing the following 
> problem:
>> readOGR('.','SOU-0')
> Error en ogrInfo(dsn = dsn, layer = layer, input_field_name_encoding = 
> input_field_name_encoding) :
> Multiple # dimensions: 2:1364727026
>> ogrInfo('.','SOU-0')
> Error en ogrInfo(".", "SOU-0") : Multiple # dimensions: 2:21374114
>
> The problem seems to be with:
>> ogrFIDs('.','SOU-0')
> [1]        0        1        2        3        4        5        6        7 
> 8        9
> [...snipped content...]
> [81]       80       81       82 21374112
>
> I don't know why, but an integer seems to be imported as if it were double 
> (or something like that!)
> If I open the dbf file and save it (with e.g. MS Excel) as a dbase IV file, 
> then it works. However, when I have to do this repeatedly it can be really 
> annoying. Is there any way to overcome it? It is a documented issue (if so, 
> excuse me)?

The issue is that the downloaded shapefile is (seriously) broken. There 
are 84 geometries (polygons), but only 83 rows in the DBF file. This 
might explain why reading it into a spreadsheet and saving helps. 
According to the ESRI specs, they should (of course) agree.

If the data provider can fix the shapefile, you'll be OK. If not, then I 
can modify readShapePoly() in maptools to accommodate this kind of 
breakage - over and above the legion it already handles, but would have to 
assume that the missing row is the final one, setting all values to NA. Of 
course, if the missing row is not the final one, all bets are off.

Roger

PS. two broken shapefiles in one day is enough, really.

>
> Thank you very much for any help that you can offer.
>
> Jos? M.
>
> You can find the file here:
> http://www.maplibrary.org/stacks/Africa/South%20Africa/KwaZulu-Natal/SOU-0_admin_SHP.zip
>
> This is the information on the system:
>
>> sessionInfo()
> R version 2.8.1 (2008-12-22)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=Spanish_Spain.1252;LC_CTYPE=Spanish_Spain.1252;LC_MONETARY=Spanish_Spain.1252;LC_NUMERIC=C;LC_TIME=Spanish_Spain.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base    > 
> library(rgdal)
> Loading required package: sp
> Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 1.6.0, released 2008/12/04
> Path to GDAL shared files: C:/ARCHIV~1/R/R-28~1.1/library/rgdal/gdal
> Loaded PROJ.4 runtime: Rel. 4.6.1, 21 August 2008
> Path to PROJ.4 shared files: C:/ARCHIV~1/R/R-28~1.1/library/rgdal/proj
>> library(maptools)
> Loading required package: foreign
>> readOGR('.','SOU-0')
> Error en ogrInfo(dsn = dsn, layer = layer, input_field_name_encoding = 
> input_field_name_encoding) :
> Multiple # dimensions: 2:1364727026
>> ogrInfo('.','SOU-0')
> Error en ogrInfo(".", "SOU-0") : Multiple # dimensions: 2:21374114
>> ogrFIDs('.','SOU-0')
> [1]        0        1        2        3        4        5        6        7 
> 8        9
> [11]       10       11       12       13       14       15       16       17 
> 18       19
> [21]       20       21       22       23       24       25       26       27 
> 28       29
> [31]       30       31       32       33       34       35       36       37 
> 38       39
> [41]       40       41       42       43       44       45       46       47 
> 48       49
> [51]       50       51       52       53       54       55       56       57 
> 58       59
> [61]       60       61       62       63       64       65       66       67 
> 68       69
> [71]       70       71       72       73       74       75       76       77 
> 78       79
> [81]       80       81       82 21374112
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From jmblanco at ub.edu  Wed Feb 25 15:41:31 2009
From: jmblanco at ub.edu (=?ISO-8859-1?Q?=22Jos=E9_M=2E_Blanco_Moreno=22?=)
Date: Wed, 25 Feb 2009 15:41:31 +0100
Subject: [R-sig-Geo] problem with readOGR
In-Reply-To: <alpine.LRH.2.00.0902251359330.1647@reclus.nhh.no>
References: <49A5252F.20004@ub.edu>
	<alpine.LRH.2.00.0902251359330.1647@reclus.nhh.no>
Message-ID: <49A5589B.3050405@ub.edu>

Thank you for the info. I will try to handle this issue with the data 
provider, since it will be safer for ALL (current and prospective) users.
BTW: My excuses for the second broken shapefile... it was not my intention!

Jos? M.


From fkbarthold46 at hotmail.com  Wed Feb 25 16:01:49 2009
From: fkbarthold46 at hotmail.com (Frauke Barthold)
Date: Wed, 25 Feb 2009 16:01:49 +0100
Subject: [R-sig-Geo] AsciiGridPredict() returns error message
Message-ID: <BLU126-W346733091908629756EBD3CAAC0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090225/47333c5e/attachment.pl>

From bibiko at eva.mpg.de  Wed Feb 25 16:24:48 2009
From: bibiko at eva.mpg.de (=?ISO-8859-1?Q?Hans-J=F6rg_Bibiko?=)
Date: Wed, 25 Feb 2009 16:24:48 +0100
Subject: [R-sig-Geo] topographic maps
Message-ID: <35559474-A5C5-4572-B066-C9FE19E29FAD@eva.mpg.de>

Dear all,

I have a tiny problem, I'd like to draw a map showing topographic  
information (like in a normal atlas) and on top of this map some  
polygons, points, etc. given by long, lat values.

I tried the geomapdata ETOPO5 in conjuction with GEOTOPO which  
actually works fine but the point is I'm dealing with maps displaying  
Eurasia and this takes really time (and memory) to plot [I also set  
GEOTOPTO's npoints to 5 bustill the same].

Then I tried to use geotiff via readOGR which also works but the same  
here, it takes too much time and I have to produce 116 maps.



Is there any elegant way to have a geo-referenced image as background  
and then to draw polygons etc. on top of it? As I said I'm dealing  
with Eurasia thus the resolution is not the big problem.

I'd be happy to get any hint.

Thanks!

--Hans


From Roger.Bivand at nhh.no  Wed Feb 25 16:32:10 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 25 Feb 2009 16:32:10 +0100 (CET)
Subject: [R-sig-Geo] topographic maps
In-Reply-To: <35559474-A5C5-4572-B066-C9FE19E29FAD@eva.mpg.de>
References: <35559474-A5C5-4572-B066-C9FE19E29FAD@eva.mpg.de>
Message-ID: <alpine.LRH.2.00.0902251629520.3285@reclus.nhh.no>

On Wed, 25 Feb 2009, Hans-J?rg Bibiko wrote:

> Dear all,
>
> I have a tiny problem, I'd like to draw a map showing topographic information 
> (like in a normal atlas) and on top of this map some polygons, points, etc. 
> given by long, lat values.
>
> I tried the geomapdata ETOPO5 in conjuction with GEOTOPO which actually works 
> fine but the point is I'm dealing with maps displaying Eurasia and this takes 
> really time (and memory) to plot [I also set GEOTOPTO's npoints to 5 bustill 
> the same].
>
> Then I tried to use geotiff via readOGR which also works but the same here, 
> it takes too much time and I have to produce 116 maps.
>

Well, readGDAL, I hope? If so, use readGDAL(..., output.dim=) to decimate 
the image.

For display, note that the R graphics engines only output vector graphics, 
so each raster cell is drawn as a filled rectangle, which takes time. The 
trick of decimating the image on input ought to reduce the number of 
rectangles to plot.

Roger

>
>
> Is there any elegant way to have a geo-referenced image as background and 
> then to draw polygons etc. on top of it? As I said I'm dealing with Eurasia 
> thus the resolution is not the big problem.
>
> I'd be happy to get any hint.
>
> Thanks!
>
> --Hans
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From dylan.beaudette at gmail.com  Wed Feb 25 17:11:04 2009
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Wed, 25 Feb 2009 08:11:04 -0800
Subject: [R-sig-Geo] stratified random sampling
In-Reply-To: <alpine.LRH.2.00.0902250930450.1647@reclus.nhh.no>
References: <5DA773FDB5D4484D9A8E36F6C3DC0180BB4BD1@scomp0039.wurnet.nl>
	<alpine.LRH.2.00.0902250930450.1647@reclus.nhh.no>
Message-ID: <3c5546140902250811w1e0d5fbevb4413d4e954237ae@mail.gmail.com>

On Wed, Feb 25, 2009 at 12:53 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Tue, 24 Feb 2009, Heuvelink, Gerard wrote:
>
>> Dear list,
>>
>> The stratified random sampling problem that I submitted a few days ago has
>> already been solved, with the help of several of you, notably Edzer Pebesma.
>> Edzer came up with the following solution:
>
> WARNING!! This is only conditionally correct. See below for analysis.
>
>>
>> library(sp)
>> library(rgdal)
>> nc1 <- readShapePoly(system.file("shapes/sids.shp",package="maptools")[1],
>
> + proj4string=CRS("+proj=longlat +datum=NAD27"))
>>
>> pts = do.call(rbind, sapply(slot(nc1, "polygons"), spsample, n=1,
>
> + type="random"))
>>
>> plot(nc1)
>> points(pts, col='blue', pch=19, cex=1)
>>
>> As it happened, the do.call statement did not work in my case (Edzer and
>> Roger may look into why it does not work with all shapes)
>
> It was because the shapefile was no good, with both self-intersecting and
> overlapping polygons. This left some values returned by spsample in the
> sapply call as NULL (correctly), and no rbind() method exists for
> SpatialPoints and NULL objects.
>
>> and had to be replaced by:
>>
>> for (i in 1:length(slot(nc1, "polygons"))) {
>> ? pt = spsample(nc1[i,], n=1, type="random")
>> ? if (i == 1)
>> ? ? ? pts = pt
>> ? else
>> ? ? ? pts = rbind(pts, pt)
>> }
>>
>
> This gets a result - there are other ways of doing it too, but it is not
> what it seems. Because the polygons are self-intersecting and overlapping,
> the point-in-polygon algorithm is not choosing points correctly (spsample
> for a ring generates more points than needed in the bounding box of the
> polygon, and chooses the number needed from those that fall within the
> polygon).
>
> The input shapefile is a vectorised map of soil types from raster data, but
> unfortunately the software used to generate it is unknown, so we can't warn
> people off it. Assuming that only one soil type occurs in each raster cell,
> we can reproduce the case with meuse.grid:
>
> library(sp)
> data(meuse.grid)
> coordinates(meuse.grid) <- c("x", "y")
> gridded(meuse.grid) <- TRUE
> meuse.grid$soil <- factor(meuse.grid$soil)
> spplot(meuse.grid, "soil")
> meuseSP <- as(meuse.grid, "SpatialPolygons")
> ID <- as.character(meuse.grid$soil)
> library(maptools)
> meuseSP1 <- unionSpatialPolygons(meuseSP, ID)
> plot(meuseSP1, col=1:3)
> pts = do.call(rbind, sapply(slot(meuseSP1, "polygons"), spsample, n=1,
> ?type="random"))
> points(pts, pch=3, col="white")
>
> Doing the raster to vector conversion in R ought to resolve the underlying
> problem of the soil polygons being generated from the raster values in an
> inappropriate way.

Thanks for bringing this to our attention Roger. I would add that
GRASS can be used to clean topologically broken shapefiles. Or, it can
be used to vectorize raster data such that the resulting vector is
topologically correct.

Cheers,

Dylan




>
>> I am so happy!
>
> Sorry, no comment! I have replied off-list too, but unfortunately bad
> shapefiles really do exist, and they cause lots of problems.
>
> Roger
>
>>
>> Gerard
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From Roger.Bivand at nhh.no  Wed Feb 25 17:42:11 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 25 Feb 2009 17:42:11 +0100 (CET)
Subject: [R-sig-Geo] Timezone boundaries (for adding to world map)?
In-Reply-To: <18851.51950.4084.365570@stat.math.ethz.ch>
References: <18844.19738.165822.672093@stat.math.ethz.ch>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61CA3E23F3@LP-EXMBVS10.CO.IHC.COM>
	<alpine.LRH.2.00.0902200942110.24812@reclus.nhh.no>
	<18851.51950.4084.365570@stat.math.ethz.ch>
Message-ID: <alpine.LRH.2.00.0902251728300.3285@reclus.nhh.no>

On Tue, 24 Feb 2009, Martin Maechler wrote:

>>>>>> "RB" == Roger Bivand <Roger.Bivand at nhh.no>
>>>>>>     on Fri, 20 Feb 2009 09:55:52 +0100 (CET) writes:
>
>    RB> On Wed, 18 Feb 2009, Greg Snow wrote:
>    >> There is a shapefile (works well with maptools and sp packages) with a
>    >> world map and time zone information at:
>    >> http://openmap.bbn.com/data/shape/timezone/
>    >>
>    >> It has the info needed to color the countries or parts of countries
>    >> based on time zone, but does not have polygons for time zone stripes
>    >> over the oceans.
>
>    RB> In fact, this shapefile provoked an update in sp, because it is really
>    RB> buggy.
>
> I'm happy to have provoked progress ;-) :-)
>
>    RB> There are straight-line polygons and many others have multiple
>    RB> repeated coordinates (the sp update fixes these to retain finite label
>    RB> points), but it doesn't fix the absence of most of the data (several DBF
>    RB> columns are empty - checked in oocalc):
>
>    >> library(rgdal)
>    >> tz <- readOGR(".", "WrldTZA")
>    RB> OGR data source with driver: ESRI Shapefile
>    RB> Source: ".", layer: "WrldTZA"
>    RB> with  1890  rows and  11  columns
>    RB> Feature type: wkbPolygon with 2 dimensions
>    RB> Warning messages:
>    RB> 1: In Polygon(cbind(jG[[1]], jG[[2]])) :
>    RB> Non-finite label point detected and replaced
>    RB> 2: In Polygon(cbind(jG[[1]], jG[[2]])) :
>    RB> Non-finite label point detected and replaced
>    RB> 3: In Polygon(cbind(jG[[1]], jG[[2]])) :
>    RB> Non-finite label point detected and replaced
>    >> names(tz)
>    RB> [1] "FIPS"     "NAME"     "COMMENTS" "REGION"   "LAT"      "LON"
>    RB> [7] "TZ"       "GMTOFF"   "LOCALSUM" "OFFSET"   "CLASSES"
>    >> summary(tz$GMTOFF)
>    RB> NA's
>    RB> 1890
>    >> summary(tz$TZ)
>    RB> NA's
>    RB> 1890
>    >> summary(tz$OFFSET)
>    RB> 0     \xff0        -1    \xff-1    \xff+1       -10       +10
>    RB> 25        57        13         7       181        24        38
>    RB> \xff+10     +10.5       +11     +11.5       +12   \xff+12        +2
>    RB> 24         1        19         3        12        13         1
>    RB> \xff-2    \xff+2        +3    \xff-3    \xff+3      -3.5  \xff+3.5
>    RB> 4        90        59       146        25         7         3
>    RB> -4        +4    \xff-4    \xff+4  \xff+4.5        -5        +5
>    RB> 56         4       165         8         1       130        13
>    RB> \xff-5    \xff+5  \xff+5.5 \xff+5.75        -6        +6    \xff-6
>    RB> 12         3        16         1        77        10        16
>    RB> \xff+6  \xff+6.5        -7        +7    \xff+7        -8        +8
>    RB> 12        15        63        98        14        61        68
>    RB> \xff-8    \xff+8        -9        +9    \xff+9      +9.5      NA's
>    RB> 3        56        82        97        13        11        33
>
>    RB> where my locale is UTF-8.
>
>    RB> I wrote to Martin offline that a more recent link is:
>
>    RB> http://efele.net/maps/tz/world/
>
>    RB> and I've put tz_world.rda on http://spatial.nhh.no/R/etc, but it is not
>    RB> line generalised, so it is very large and takes a long time to display -
>    RB> they've kept a lot of boundary detail.
>
> indeed.  But thanks a lot to make it available!!
>
>    RB> Because TZ follow administrative boundaries, they are actually hard to do
>    RB> right. Maybe a raster version might help more if vector precision isn't
>    RB> needed?
>
> as long as we can add a couple of cities (using geographical
> coordinates) to it, afterwards, that's fine.
>
> When I load your (above URL) tz file and plot it,
> I get the impression that much time is spent on thousands of
> very small polygons;
> consequently, if I'd want a  ``subset'' of tz that only contains
> the polygons that correspond to areas larger than, say, 100 km^2,
> how could I do that ?

I've put simpl_tz.rda on the same site with the smaller non-principal 
islands removed, so it plots faster. However, attempts to do line 
simplification to reduce the detail on coastlines have not yet succeeded.

Anyone like to try to do the line simplification? In GRASS, I'm seeing 
"Attempt to read dead line" after both v.generalize and v.simplify.

Compared to the original object, this one has very many fewer constituent 
Polygons objects, because all the geometries with the same time zone have 
been collected into single Polygons objects, rather than being almost all 
singletons. This has also speeded up plotting.

Hope this helps,

Roger


>
> Looking at the sp-object:
>
> ------------------------------------------------------------------------
>
> load("tz_world.rda")
>
> ## Look a bit at the 'tz' object:
> str(tz, max=2)
> ## Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
> ##   ..@ data       :'data.frame':	27704 obs. of  1 variable:
> ##   .. ..- attr(*, "data_types")= chr "C"
> ##   ..@ polygons   :List of 27704
> ##   ..@ plotOrder  : int [1:27704] 24471 111 14349 24641 1598 10291 22351 ...
> ##   ..@ bbox       : num [1:2, 1:2] -180 -90 180 83.6
> ##   .. ..- attr(*, "dimnames")=List of 2
> ##   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>
> ltz <- sapply(slotNames(tz), slot, object=tz)
> sapply(ltz, object.size)
> ##        data    polygons   plotOrder        bbox proj4string
> ##     1690424   110706296      110856         704         704
>
> str(tz at data[,1])
> ##  Factor w/ 382 levels "Africa/Abidjan",..: 307 307 307 307 307 307 ...
>
> str(head(tz at polygons[1:3]), max=1)
> ## List of 3
> ##  $ :Formal class 'Polygons' [package "sp"] with 5 slots
> ##  $ :Formal class 'Polygons' [package "sp"] with 5 slots
> ##  $ :Formal class 'Polygons' [package "sp"] with 5 slots
>
> ------------------------------------------------------------------------
>
> and then ask for
>
>    showMethods(class = "Polygons")
>
> the result is not so revealing to me; but of course, I'm really
> an sp greenhorn.
>
> How could I compute areas?
>
> Regards,
> Martin
>
>
>
>    RB> Roger
>
>    >>
>    >> Hope this helps,
>    >>
>    >>
>
>    RB> --
>    RB> Roger Bivand
>    RB> Economic Geography Section, Department of Economics, Norwegian School of
>    RB> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>    RB> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>    RB> e-mail: Roger.Bivand at nhh.no
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Pilar.Tugores at ba.ieo.es  Wed Feb 25 18:54:48 2009
From: Pilar.Tugores at ba.ieo.es (Pilar Tugores Ferra)
Date: Wed, 25 Feb 2009 18:54:48 +0100
Subject: [R-sig-Geo] variance estimation (gstat, geoR, automap)
In-Reply-To: <1235551439.7599.4.camel@Virgilio-Gomez>
References: <0838E01493845742A4D4039EA34EB1C15143C1@ieopalma2.ba.ieo.es> 
	<49A46EAF.1040906@geo.uu.nl> <1235551439.7599.4.camel@Virgilio-Gomez>
Message-ID: <0838E01493845742A4D4039EA34EB1C151448E@ieopalma2.ba.ieo.es>


Thanks you all!
I'll have a look and see if I can have access to the reference material you provided me!
Cheers


M? Pilar Tugores Ferr?
PhD Student
Instituto Espa?ol de Oceanograf?a
Centro Oceanogr?fico de Baleares
Muelle de Poniente s/n
07015 Palma de Mallorca
Baleares, Espa?a
Telf.: (34) 971 401561

-----Mensaje original-----
De: Virgilio Gomez Rubio [mailto:Virgilio.Gomez at uclm.es] 
Enviado el: 25 February 2009 09:44
Para: Paul Hiemstra
CC: Pilar Tugores Ferra; r-sig-geo at stat.math.ethz.ch
Asunto: Re: [R-sig-Geo] variance estimation (gstat, geoR, automap)

Hi,


In addition to the list provided by Paul, I would like to add

Geostatistics for Environmental Scientists, 2nd Edition
Richard Webster, Margaret A. Oliver 

I have used it in courses for agricultural and environmental engineers
and it worked well. I think that the balance between mathematical
complexity and applications is quite good.

Best,

Virgilio



El mar, 24-02-2009 a las 23:03 +0100, Paul Hiemstra escribi?:
> Hi Pilar,
> 
> I think this list appropriate :). What would be a good idea is to get a 
> book that describes kriging, some standard books are:
> 
> Chil?s, J. & Delfiner, P. Geostatistics: Modeling Spatial Uncertainty 
> John Wiley & Sons, New York, 1999
> Christensen, R. Plane Answers to Complex Questions: The Theory of Linear 
> Models Springer, New York, 1996
> Journel, A. & Huijbregts, C. Mining Geostatistics Academic Press., 1978
> 
> A more practical book would be the Applied Spatial Data Analysis in R, 
> see http://www.asdar-book.org/ for more info.
> 
> On the web you could look at:
> 
> http://www.kriging.com/, Owned by Isobel Clark
> http://spatial-analyst.net/wiki/index.php?title=Main_Page, not sure if 
> there is something here on  the theory of kriging.
> 
> For a description of kriging (quite mathematical) you can also look at a 
> paper I wrote, you can download it from 
> http://intamap.geo.uu.nl/~paul/Publications.html, it is the first one 
> titled Read-time automatic...etc
> 
> This is all I could think of :).
> 
> cheers,
> Paul
> 
> Pilar Tugores Ferra schreef:
> > Dear all,
> >
> > I'm trying to estimate the variance of a global abundance estimation computed by kriging interpolation and I am stuck.
> >
> > One can easily retrieve the variance at each prediction location (either using the package gstat, geoR or automap) using expressions similar to:
> >
> >   
> >> kriging_object$krige.var
> >>     
> >
> > or >kriging_object$var1.var
> >
> >  
> >
> > but, in fact,  I have no idea how these variance values are computed.
> >
> > Could anybody tell me how is it computed or suggest  some reference material? 
> >
> > Could this question be inappropriate for this list in which case I would also apprieciate if someone could tell me where to ask it.
> >
> > Cheers,
> >
> > Pilar
> >
> >  
> >
> > M? Pilar Tugores Ferr?
> >
> > PhD Student
> >
> > Instituto Espa?ol de Oceanograf?a
> >
> > Centro Oceanogr?fico de Baleares
> >
> > Muelle de Poniente s/n
> >
> > 07015 Palma de Mallorca
> >
> > Baleares, Espa?a
> >
> > Telf.: (34) 971 401561
> >
> >  
> >
> >
> >
> > La informaci?n contenida en este e-mail y sus ficheros adjuntos es totalmente confidencial y no deber?a ser usado si no fuera usted alguno de los destinatarios. Si ha recibido este e-mail por error, por favor avise al remitente y b?rrelo de su buz?n o de cualquier otro medio de almacenamiento.   This email is confidential and should not be used by anyone who is not the original intended  recipient. If you have received this e-mail in  error please inform the sender and delete it from  your mailbox or any other storage mechanism.
> > 	[[alternative HTML version deleted]]
> >
> >   
> > ------------------------------------------------------------------------
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >   
> 
> 

La informaci?n contenida en este e-mail y sus ficheros adjuntos es totalmente confidencial y no deber?a ser usado si no fuera usted alguno de los destinatarios. Si ha recibido este e-mail por error, por favor avise al remitente y b?rrelo de su buz?n o de cualquier otro medio de almacenamiento.   This email is confidential and should not be used by anyone who is not the original intended  recipient. If you have received this e-mail in  error please inform the sender and delete it from  your mailbox or any other storage mechanism.

From Roger.Bivand at nhh.no  Wed Feb 25 19:11:35 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 25 Feb 2009 19:11:35 +0100 (CET)
Subject: [R-sig-Geo] Timezone boundaries (for adding to world map)?
In-Reply-To: <alpine.LRH.2.00.0902251728300.3285@reclus.nhh.no>
References: <18844.19738.165822.672093@stat.math.ethz.ch>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61CA3E23F3@LP-EXMBVS10.CO.IHC.COM>
	<alpine.LRH.2.00.0902200942110.24812@reclus.nhh.no>
	<18851.51950.4084.365570@stat.math.ethz.ch>
	<alpine.LRH.2.00.0902251728300.3285@reclus.nhh.no>
Message-ID: <alpine.LRH.2.00.0902251910220.3285@reclus.nhh.no>

On Wed, 25 Feb 2009, Roger Bivand wrote:

> On Tue, 24 Feb 2009, Martin Maechler wrote:
>
>>>>>>> "RB" == Roger Bivand <Roger.Bivand at nhh.no>
>>>>>>>     on Fri, 20 Feb 2009 09:55:52 +0100 (CET) writes:
>>
>>    RB> On Wed, 18 Feb 2009, Greg Snow wrote:
>>    >> There is a shapefile (works well with maptools and sp packages) with 
>> a
>>    >> world map and time zone information at:
>>    >> http://openmap.bbn.com/data/shape/timezone/
>>    >>
>>    >> It has the info needed to color the countries or parts of countries
>>    >> based on time zone, but does not have polygons for time zone stripes
>>    >> over the oceans.
>>
>>    RB> In fact, this shapefile provoked an update in sp, because it is 
>> really
>>    RB> buggy.
>> 
>> I'm happy to have provoked progress ;-) :-)
>>
>>    RB> There are straight-line polygons and many others have multiple
>>    RB> repeated coordinates (the sp update fixes these to retain finite 
>> label
>>    RB> points), but it doesn't fix the absence of most of the data (several 
>> DBF
>>    RB> columns are empty - checked in oocalc):
>>
>>    >> library(rgdal)
>>    >> tz <- readOGR(".", "WrldTZA")
>>    RB> OGR data source with driver: ESRI Shapefile
>>    RB> Source: ".", layer: "WrldTZA"
>>    RB> with  1890  rows and  11  columns
>>    RB> Feature type: wkbPolygon with 2 dimensions
>>    RB> Warning messages:
>>    RB> 1: In Polygon(cbind(jG[[1]], jG[[2]])) :
>>    RB> Non-finite label point detected and replaced
>>    RB> 2: In Polygon(cbind(jG[[1]], jG[[2]])) :
>>    RB> Non-finite label point detected and replaced
>>    RB> 3: In Polygon(cbind(jG[[1]], jG[[2]])) :
>>    RB> Non-finite label point detected and replaced
>>    >> names(tz)
>>    RB> [1] "FIPS"     "NAME"     "COMMENTS" "REGION"   "LAT"      "LON"
>>    RB> [7] "TZ"       "GMTOFF"   "LOCALSUM" "OFFSET"   "CLASSES"
>>    >> summary(tz$GMTOFF)
>>    RB> NA's
>>    RB> 1890
>>    >> summary(tz$TZ)
>>    RB> NA's
>>    RB> 1890
>>    >> summary(tz$OFFSET)
>>    RB> 0     \xff0        -1    \xff-1    \xff+1       -10       +10
>>    RB> 25        57        13         7       181        24        38
>>    RB> \xff+10     +10.5       +11     +11.5       +12   \xff+12        +2
>>    RB> 24         1        19         3        12        13         1
>>    RB> \xff-2    \xff+2        +3    \xff-3    \xff+3      -3.5  \xff+3.5
>>    RB> 4        90        59       146        25         7         3
>>    RB> -4        +4    \xff-4    \xff+4  \xff+4.5        -5        +5
>>    RB> 56         4       165         8         1       130        13
>>    RB> \xff-5    \xff+5  \xff+5.5 \xff+5.75        -6        +6    \xff-6
>>    RB> 12         3        16         1        77        10        16
>>    RB> \xff+6  \xff+6.5        -7        +7    \xff+7        -8        +8
>>    RB> 12        15        63        98        14        61        68
>>    RB> \xff-8    \xff+8        -9        +9    \xff+9      +9.5      NA's
>>    RB> 3        56        82        97        13        11        33
>>
>>    RB> where my locale is UTF-8.
>>
>>    RB> I wrote to Martin offline that a more recent link is:
>>
>>    RB> http://efele.net/maps/tz/world/
>>
>>    RB> and I've put tz_world.rda on http://spatial.nhh.no/R/etc, but it is 
>> not
>>    RB> line generalised, so it is very large and takes a long time to 
>> display -
>>    RB> they've kept a lot of boundary detail.
>> 
>> indeed.  But thanks a lot to make it available!!
>>
>>    RB> Because TZ follow administrative boundaries, they are actually hard 
>> to do
>>    RB> right. Maybe a raster version might help more if vector precision 
>> isn't
>>    RB> needed?
>> 
>> as long as we can add a couple of cities (using geographical
>> coordinates) to it, afterwards, that's fine.
>> 
>> When I load your (above URL) tz file and plot it,
>> I get the impression that much time is spent on thousands of
>> very small polygons;
>> consequently, if I'd want a  ``subset'' of tz that only contains
>> the polygons that correspond to areas larger than, say, 100 km^2,
>> how could I do that ?
>
> I've put simpl_tz.rda on the same site with the smaller non-principal islands 
> removed, so it plots faster. However, attempts to do line simplification to 
> reduce the detail on coastlines have not yet succeeded.
>
> Anyone like to try to do the line simplification? In GRASS, I'm seeing 
> "Attempt to read dead line" after both v.generalize and v.simplify.
>
> Compared to the original object, this one has very many fewer constituent 
> Polygons objects, because all the geometries with the same time zone have 
> been collected into single Polygons objects, rather than being almost all 
> singletons. This has also speeded up plotting.

And a raster version, same site, SGDF_tz.rda. Then:

image(SGDF, "tzn", col=rainbow(300))

plots a map.

Roger

>
> Hope this helps,
>
> Roger
>
>
>> 
>> Looking at the sp-object:
>> 
>> ------------------------------------------------------------------------
>> 
>> load("tz_world.rda")
>> 
>> ## Look a bit at the 'tz' object:
>> str(tz, max=2)
>> ## Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
>> ##   ..@ data       :'data.frame':	27704 obs. of  1 variable:
>> ##   .. ..- attr(*, "data_types")= chr "C"
>> ##   ..@ polygons   :List of 27704
>> ##   ..@ plotOrder  : int [1:27704] 24471 111 14349 24641 1598 10291 22351 
>> ...
>> ##   ..@ bbox       : num [1:2, 1:2] -180 -90 180 83.6
>> ##   .. ..- attr(*, "dimnames")=List of 2
>> ##   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>> 
>> ltz <- sapply(slotNames(tz), slot, object=tz)
>> sapply(ltz, object.size)
>> ##        data    polygons   plotOrder        bbox proj4string
>> ##     1690424   110706296      110856         704         704
>> 
>> str(tz at data[,1])
>> ##  Factor w/ 382 levels "Africa/Abidjan",..: 307 307 307 307 307 307 ...
>> 
>> str(head(tz at polygons[1:3]), max=1)
>> ## List of 3
>> ##  $ :Formal class 'Polygons' [package "sp"] with 5 slots
>> ##  $ :Formal class 'Polygons' [package "sp"] with 5 slots
>> ##  $ :Formal class 'Polygons' [package "sp"] with 5 slots
>> 
>> ------------------------------------------------------------------------
>> 
>> and then ask for
>>
>>    showMethods(class = "Polygons")
>> 
>> the result is not so revealing to me; but of course, I'm really
>> an sp greenhorn.
>> 
>> How could I compute areas?
>> 
>> Regards,
>> Martin
>> 
>> 
>>
>>    RB> Roger
>>
>>    >>
>>    >> Hope this helps,
>>    >>
>>    >>
>>
>>    RB> --
>>    RB> Roger Bivand
>>    RB> Economic Geography Section, Department of Economics, Norwegian 
>> School of
>>    RB> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>    RB> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>    RB> e-mail: Roger.Bivand at nhh.no
>> 
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From alessandro.montaghi at unifi.it  Wed Feb 25 23:21:13 2009
From: alessandro.montaghi at unifi.it (Alessandro)
Date: Wed, 25 Feb 2009 23:21:13 +0100
Subject: [R-sig-Geo] help to creating a points subset with R: Cut points
	shapefaile with a buffer polygon shapefile
Message-ID: <007001c99797$5eea2970$1cbe7c50$@montaghi@unifi.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090225/b06d0aa4/attachment.pl>

From p.hiemstra at geo.uu.nl  Wed Feb 25 23:24:16 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Wed, 25 Feb 2009 23:24:16 +0100
Subject: [R-sig-Geo] help to creating a points subset with R: Cut points
 shapefaile with a buffer polygon shapefile
In-Reply-To: <007001c99797$5eea2970$1cbe7c50$@montaghi@unifi.it>
References: <007001c99797$5eea2970$1cbe7c50$@montaghi@unifi.it>
Message-ID: <49A5C510.2090205@geo.uu.nl>

Hi,

Have you tried the overlay command in the sp package?

cheers,
Paul

Alessandro schreef:
> Hi All Researcher, 
>
>  
>
> Thanks for help and suggestions. 
>
>  
>
> I have a points shapefile (soil) with one column [H] and a circular buffer
> polygons (plots) with a column [ID identify. Ex: 1,2,3 etc etc]. I wish to
> clip the points shapefile with the buffer and obtain a new points shape file
> (only the points inside the buffer) with two columns [ID of buffer and H).
>
>  
>
> I have with maptools problem with memory because every time my R crash-down.
>
>
>  
>
>  Any suggestions would be appreciated. 
>
>  
>
> Thanks again
>
>  
>
> Ale
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From tsippel at gmail.com  Thu Feb 26 04:55:27 2009
From: tsippel at gmail.com (Tim Sippel)
Date: Thu, 26 Feb 2009 16:55:27 +1300
Subject: [R-sig-Geo] RSAGA .asc morphology loop question
Message-ID: <79a13c220902251955w533f314ap6bd01559759e91f8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090226/ca37ce87/attachment.pl>

From Roger.Bivand at nhh.no  Thu Feb 26 08:13:57 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 26 Feb 2009 08:13:57 +0100 (CET)
Subject: [R-sig-Geo] help to creating a points subset with R: Cut points
 shapefaile with a buffer polygon shapefile
In-Reply-To: <49A5C510.2090205@geo.uu.nl>
References: <007001c99797$5eea2970$1cbe7c50$@montaghi@unifi.it>
	<49A5C510.2090205@geo.uu.nl>
Message-ID: <alpine.LRH.2.00.0902260811220.19670@reclus.nhh.no>

On Wed, 25 Feb 2009, Paul Hiemstra wrote:

> Hi,
>
> Have you tried the overlay command in the sp package?

Exactly. The questioner had asked me offlist (the list is a much better 
choice, it does 24/7, which I don't), and the answer is:

library(rgdal)
buff <- readOGR(".", "buff_canopy_subset")
canopy <- readOGR(".", "canopy_subset")
plot(buff, axes=TRUE)
plot(canopy, add=TRUE, pch=".")
o <- overlay(canopy, buff)
plot(canopy, add=TRUE, pch=".", col=o+1)

The overlay methods are so simple that they really deserve to be among the 
the first things people learn.

Roger

>
> cheers,
> Paul
>
> Alessandro schreef:
>> Hi All Researcher,
>> 
>> Thanks for help and suggestions.
>> 
>> I have a points shapefile (soil) with one column [H] and a circular buffer
>> polygons (plots) with a column [ID identify. Ex: 1,2,3 etc etc]. I wish to
>> clip the points shapefile with the buffer and obtain a new points shape 
>> file
>> (only the points inside the buffer) with two columns [ID of buffer and H).
>>
>> 
>> I have with maptools problem with memory because every time my R 
>> crash-down.
>> 
>>
>>
>>  Any suggestions would be appreciated.
>> 
>> Thanks again
>>
>> 
>> Ale
>> 
>>
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From p.hiemstra at geo.uu.nl  Thu Feb 26 12:00:59 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Thu, 26 Feb 2009 12:00:59 +0100
Subject: [R-sig-Geo] R: help to creating a points subset with R: Cut
 points shapefaile with a buffer polygon shapefile
In-Reply-To: <007801c9979a$061a3b70$124eb250$@montaghi@unifi.it>
References: <007001c99797$5eea2970$1cbe7c50$@montaghi@unifi.it>
	<49A5C510.2090205@geo.uu.nl>
	<007801c9979a$061a3b70$124eb250$@montaghi@unifi.it>
Message-ID: <49A6766B.9010102@geo.uu.nl>

Hi,

Please also send your replies to the mailing list, and not only to me 
personally. Other people might have better ideas than I have.

If your shapefile is too big for your memory, try to cut it up and do 
your analysis on a subset of both your point data and polygon data. And 
please provide us with information on you system, is it 64 bit or 32 
bit, how much memory, which version of R, which operating system. Look 
at the sessionInfo command to get some of this info. To get more hints 
as how to write good posts, please read the posting guide for the main R 
list, R-help.

cheers,
Paul

Alessandro schreef:
> Thanks for your help and Sorry for my ineptitude
>
> Do you tell about "Methods for spatially overlay-ing points (grids) and
> polygons layers" or "spatial overlay for points grids and polygons"? 
> I had see in help(sp) but, sorry, It's not very help clear for not expertise
> like me. I have this two shapefile (point and buffer) but the point is very
> hug dataset and read in maptools is not possible (memory crash down).
>
> Canopy (points)
> Buffer (polygon)
>
> I know that I must get a spatialPointsDataFrame (=canopy) then load the
> Polygon (=buffer), but after "I am in the middle of Ocean with a small ship"
>
> Thanks again if you could help me 
>
> Alessandro
>
>
>
>
> -----Messaggio originale-----
> Da: Paul Hiemstra [mailto:p.hiemstra at geo.uu.nl] 
> Inviato: mercoled? 25 febbraio 2009 23.24
> A: Alessandro
> Cc: r-sig-geo at stat.math.ethz.ch
> Oggetto: Re: [R-sig-Geo] help to creating a points subset with R: Cut points
> shapefaile with a buffer polygon shapefile
>
> Hi,
>
> Have you tried the overlay command in the sp package?
>
> cheers,
> Paul
>
> Alessandro schreef:
>   
>> Hi All Researcher, 
>>
>>  
>>
>> Thanks for help and suggestions. 
>>
>>  
>>
>> I have a points shapefile (soil) with one column [H] and a circular buffer
>> polygons (plots) with a column [ID identify. Ex: 1,2,3 etc etc]. I wish to
>> clip the points shapefile with the buffer and obtain a new points shape
>>     
> file
>   
>> (only the points inside the buffer) with two columns [ID of buffer and H).
>>
>>  
>>
>> I have with maptools problem with memory because every time my R
>>     
> crash-down.
>   
>>  
>>
>>  Any suggestions would be appreciated. 
>>
>>  
>>
>> Thanks again
>>
>>  
>>
>> Ale
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>   
>>     
>
>
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From horning at amnh.org  Thu Feb 26 15:15:29 2009
From: horning at amnh.org (Ned Horning)
Date: Thu, 26 Feb 2009 17:15:29 +0300
Subject: [R-sig-Geo] Writing a byte image
Message-ID: <49A6A401.2070808@amnh.org>

What is the recommended way to output a large byte GeoTiff image one 
line at a time? I am creating large double and integer images using 
writeRaster to create a GeoTiff file. I've been converting these to a 
byte data type outside of R but it would be nice to R to output a byte 
GeoTiff directly. I see there is a "type" flag for writeGDAL but I 
haven't been able to tell if I can use that for line-by-line writing.

This is what I'm using now (thanks to feedback from Robert Hijmans and 
possible unnecessary complications by me):
--
# Set output image properties
predrast <- setRaster(spot)
filename(predrast) <- outImage
nameVec <- colnames(trainvals)
cname <- nameVec[2]
for (n in 2:numbands) {
  cname <- c(cname, nameVec[n+1])
}
# Use the randomForest object to predict land cover type based on the input
# image one line at a time
for (r in 1:nrow(spot)) {
  spot <- readRow(spot, r)
  rowvals <- values(spot, names=TRUE)
  colnames(rowvals) <- cname
  pred <- predict(randfor, rowvals)
  pred <- as.numeric(pred)
  predrast <- setValues(predrast, pred, r)
  predrast <- writeRaster(predrast, format='GTiff', overwrite=TRUE)
}
--

Ned


From Roger.Bivand at nhh.no  Thu Feb 26 17:57:59 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 26 Feb 2009 17:57:59 +0100 (CET)
Subject: [R-sig-Geo] stratified random sampling
In-Reply-To: <alpine.LRH.2.00.0902250930450.1647@reclus.nhh.no>
References: <5DA773FDB5D4484D9A8E36F6C3DC0180BB4BD1@scomp0039.wurnet.nl>
	<alpine.LRH.2.00.0902250930450.1647@reclus.nhh.no>
Message-ID: <alpine.LRH.2.00.0902261742320.19670@reclus.nhh.no>

On Wed, 25 Feb 2009, Roger Bivand wrote:

> On Tue, 24 Feb 2009, Heuvelink, Gerard wrote:
>
>> Dear list,
>> 
>> The stratified random sampling problem that I submitted a few days ago has 
>> already been solved, with the help of several of you, notably Edzer 
>> Pebesma. Edzer came up with the following solution:
>
> WARNING!! This is only conditionally correct. See below for analysis.

Further WARNING!! I have now checked everything as carefully as possible. 
In fact, vectorising the underlying gridded data in R (using sp and 
maptools) led to the same problem.

So it was wrong of me to blame the input shapefile, which although very 
complex, was topologically correct.

The causes of the problem were firstly that when only one point was being 
sampled in each Polygons object, the use of round() to divide n among the 
member Polygon objects by areal proportion was setting n=0 in some cases 
for all Polygon objects. So round() has been replaced by ceiling() in the 
next release of sp - if more than n points are chosen, they are sampled 
back to n.

The second cause was an interaction between the gridded shapes of many 
Polygon objects (they are often single raster cells), their bounding 
boxes, which are of course identical with the polygon ring, and a 
heuristic used to try to detect when a Polygon object is wrongly declared 
as not being a hole. The heuristic was turning raster cells touching at 
one corner vertex into holes, so not sampling them. This has also been 
corrected on CVS and will be in the next sp release.

We'd be grateful for users reporting on spsample() behaving unexpectedly 
with Polygon, Polygons, and/or SpatialPolygons objects, especially with 
test data (as in this case, offline).

Roger


>
>> 
>> library(sp)
>> library(rgdal)
>> nc1 <- readShapePoly(system.file("shapes/sids.shp",package="maptools")[1],
> + proj4string=CRS("+proj=longlat +datum=NAD27"))
>> pts = do.call(rbind, sapply(slot(nc1, "polygons"), spsample, n=1,
> + type="random"))
>> plot(nc1)
>> points(pts, col='blue', pch=19, cex=1)
>> 
>> As it happened, the do.call statement did not work in my case (Edzer and 
>> Roger may look into why it does not work with all shapes)
>
> It was because the shapefile was no good, with both self-intersecting and 
> overlapping polygons. This left some values returned by spsample in the 
> sapply call as NULL (correctly), and no rbind() method exists for 
> SpatialPoints and NULL objects.
>
>> and had to be replaced by:
>> 
>> for (i in 1:length(slot(nc1, "polygons"))) {
>>    pt = spsample(nc1[i,], n=1, type="random")
>>    if (i == 1)
>>        pts = pt
>>    else
>>        pts = rbind(pts, pt)
>> }
>> 
>
> This gets a result - there are other ways of doing it too, but it is not what 
> it seems. Because the polygons are self-intersecting and overlapping, the 
> point-in-polygon algorithm is not choosing points correctly (spsample for a 
> ring generates more points than needed in the bounding box of the polygon, 
> and chooses the number needed from those that fall within the polygon).
>
> The input shapefile is a vectorised map of soil types from raster data, but 
> unfortunately the software used to generate it is unknown, so we can't warn 
> people off it. Assuming that only one soil type occurs in each raster cell, 
> we can reproduce the case with meuse.grid:
>
> library(sp)
> data(meuse.grid)
> coordinates(meuse.grid) <- c("x", "y")
> gridded(meuse.grid) <- TRUE
> meuse.grid$soil <- factor(meuse.grid$soil)
> spplot(meuse.grid, "soil")
> meuseSP <- as(meuse.grid, "SpatialPolygons")
> ID <- as.character(meuse.grid$soil)
> library(maptools)
> meuseSP1 <- unionSpatialPolygons(meuseSP, ID)
> plot(meuseSP1, col=1:3)
> pts = do.call(rbind, sapply(slot(meuseSP1, "polygons"), spsample, n=1,
> type="random"))
> points(pts, pch=3, col="white")
>
> Doing the raster to vector conversion in R ought to resolve the underlying 
> problem of the soil polygons being generated from the raster values in an 
> inappropriate way.
>
>> I am so happy!
>
> Sorry, no comment! I have replied off-list too, but unfortunately bad 
> shapefiles really do exist, and they cause lots of problems.
>
> Roger
>
>> 
>> Gerard
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From r.hijmans at gmail.com  Fri Feb 27 02:07:58 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Fri, 27 Feb 2009 09:07:58 +0800
Subject: [R-sig-Geo] Writing a byte image
In-Reply-To: <49A6A401.2070808@amnh.org>
References: <49A6A401.2070808@amnh.org>
Message-ID: <dc22b2570902261707q120a2819k13dff6d16971a51e@mail.gmail.com>

Hi Ned,

This should work:

# Set output image properties
predrast <- setRaster(spot)

predrast <- setDatatype(predrast, 'INT1U')

filename(predrast) <- outImage

etc.

Robert

On Thu, Feb 26, 2009 at 10:15 PM, Ned Horning <horning at amnh.org> wrote:
> What is the recommended way to output a large byte GeoTiff image one line at
> a time? I am creating large double and integer images using writeRaster to
> create a GeoTiff file. I've been converting these to a byte data type
> outside of R but it would be nice to R to output a byte GeoTiff directly. I
> see there is a "type" flag for writeGDAL but I haven't been able to tell if
> I can use that for line-by-line writing.
>
> This is what I'm using now (thanks to feedback from Robert Hijmans and
> possible unnecessary complications by me):
> --
> # Set output image properties
> predrast <- setRaster(spot)
> filename(predrast) <- outImage
> nameVec <- colnames(trainvals)
> cname <- nameVec[2]
> for (n in 2:numbands) {
> ?cname <- c(cname, nameVec[n+1])
> }
> # Use the randomForest object to predict land cover type based on the input
> # image one line at a time
> for (r in 1:nrow(spot)) {
> ?spot <- readRow(spot, r)
> ?rowvals <- values(spot, names=TRUE)
> ?colnames(rowvals) <- cname
> ?pred <- predict(randfor, rowvals)
> ?pred <- as.numeric(pred)
> ?predrast <- setValues(predrast, pred, r)
> ?predrast <- writeRaster(predrast, format='GTiff', overwrite=TRUE)
> }
> --
>
> Ned
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From bgr at bgs.ac.uk  Fri Feb 27 15:05:43 2009
From: bgr at bgs.ac.uk (Rawlins, Barry G)
Date: Fri, 27 Feb 2009 14:05:43 +0000
Subject: [R-sig-Geo] Feature Extraction - object based image analysis
Message-ID: <28C15D104A882F47954DEE56148152CC1C0AAC41@nerckwmb1.ad.nerc.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090227/bc920eaa/attachment.pl>

From horning at amnh.org  Fri Feb 27 15:35:23 2009
From: horning at amnh.org (Ned Horning)
Date: Fri, 27 Feb 2009 17:35:23 +0300
Subject: [R-sig-Geo] Using a mask
Message-ID: <49A7FA2B.4090807@amnh.org>

Is there an easy way to mask (or flag) data values in R so they do not 
get processed. I am using predict.randomForest on a satellite image and 
there are a lot (~30%) of pixels with a value of "0" that I'd prefer not 
to process with predict.randomForest to save time. I was thinking it 
might be possible to create a data frame with valid data for each line 
read from the input multi-band image and then reconstruct the line 
before writing it out but I think the overhead would be very high. At 
least using the brute force methods like rbind.

All the best,

Ned


From T.Hengl at uva.nl  Fri Feb 27 15:40:03 2009
From: T.Hengl at uva.nl (Tomislav Hengl)
Date: Fri, 27 Feb 2009 15:40:03 +0100
Subject: [R-sig-Geo] Feature Extraction - object based image analysis
In-Reply-To: <28C15D104A882F47954DEE56148152CC1C0AAC41@nerckwmb1.ad.nerc.ac.uk>
References: <28C15D104A882F47954DEE56148152CC1C0AAC41@nerckwmb1.ad.nerc.ac.uk>
Message-ID: <D5662EA9EFC040E29C097562C1C5A759@pcibed193>


Hi Barry,

SAGA has few simple but useful modules for extraction of features from grids. See:

> library(RSAGA)
> rsaga.get.modules("grid_discretisation")
$grid_discretisation
  code                       name interactive
1    0  Supervised Classification       FALSE
2    1 Cluster Analysis for Grids       FALSE
3    2          Grid Segmentation       FALSE
4    3      Grid Segmentation (b)       FALSE
5    4       Grid Skeletonization       FALSE
6   NA                       <NA>       FALSE
7   NA                       <NA>       FALSE


For multiple images, you can use either cluster analysis or supervised classification:

> rsaga.get.usage("grid_discretisation", 0)
SAGA CMD 2.0.3
library path:   C:/Progra~1/saga_vc/modules
library name:   grid_discretisation
module name :   Supervised Classification
Usage: 0 -GRIDS <str> -POLYGONS <str> [-FIELD <num>] -CLASSES <str> -RESULT <str> [-ML_PROB <str>]
[-METHOD <num>] [-NORMALISE] [-ML_THRESHOLD <str>]
  -GRIDS:<str>          Grids
        Grid list (input)
  -POLYGONS:<str>       Training Areas
        Shapes (input)
  -FIELD:<num>          Class Identifier
        Table field
  -CLASSES:<str>        Class Information
        Table (output)
  -RESULT:<str>         Classification
        Grid (output)
  -ML_PROB:<str>        Distance/Probability
        Grid (optional output)
  -METHOD:<num>         Method
        Choice
        Available Choices:
        [0] Minimum Distance
        [1] Maximum Likelihood
  -NORMALISE            Normalise
        Boolean
  -ML_THRESHOLD:<str>   Probability Threshold (Percent)
        Floating point
        Value Range: 0.000000 - 100.000000


You can also consider getting the statistics from grids for polygons:

> rsaga.get.modules("shapes_grid")
$shapes_grid
   code                             name interactive
1     0        Add Grid Values to Points       FALSE
2     1         Get Grid Data for Shapes       FALSE
3     2     Grid Statistics for Polygons       FALSE
4     3            Grid Values to Points       FALSE
5     4 Grid Values to Points (randomly)       FALSE
6     5          Contour Lines from Grid       FALSE
7     6         Vectorising Grid Classes       FALSE
8     7           Clip Grid with Polygon       FALSE
9     8               Gradient from Grid       FALSE
10   NA                             <NA>       FALSE
11   NA                             <NA>       FALSE


You will soon discover that there is not much literature that explains how to run processing and
what does each parameter in SAGA means  :( 
Unfortunately, Olaf does not have time to write up a user's manual for SAGA, but you can always zoom
into the original code. I am sure that all algorithms come from some literature. E.g.:

Kothe, R., Bock, M., 2006. Development and use in practice of SAGA modules for quality analysis of
geodata. In B?hner, J., McCloy, K.R., Strobl, J. [Eds.]: SAGA ? Analysis and Modelling Applications.
G?ttinger Geographische Abhandlungen, Vol.115.
http://surfnet.dl.sourceforge.net/sourceforge/saga-gis/gga115_08.pdf 


HTH

Tom Hengl
http://spatial-analyst.net  



-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
Rawlins, Barry G
Sent: Friday, February 27, 2009 3:06 PM
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] Feature Extraction - object based image analysis

I have a colleague who is not familiar with R and we were discussing feature extraction from
multiple images (air photos, satellite based etc.). He uses a commercial tool for feature
extraction. Can anyone point me to a package in R that does this? I have done a search but not found
such a function. It is not a procedure I am familiar with.

Many thanks, Barry

Dr Barry Rawlins
Sustainable Soils Team Leader
British Geological Survey
Keyworth
Nottingham
NG12 5GG
Direct tel: 0115 9363140
Mobile: 0788 4235473
homepage: http://barryrawlins.googlepages.com<http://barryrawlins.googlepages.com/>




-- 
This message (and any attachments) is for the recipient ...{{dropped:8}}


From Roger.Bivand at nhh.no  Fri Feb 27 16:44:51 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 27 Feb 2009 16:44:51 +0100 (CET)
Subject: [R-sig-Geo] Using a mask
In-Reply-To: <49A7FA2B.4090807@amnh.org>
References: <49A7FA2B.4090807@amnh.org>
Message-ID: <alpine.LRH.2.00.0902271642510.29839@reclus.nhh.no>

On Fri, 27 Feb 2009, Ned Horning wrote:

> Is there an easy way to mask (or flag) data values in R so they do not get 
> processed. I am using predict.randomForest on a satellite image and there are 
> a lot (~30%) of pixels with a value of "0" that I'd prefer not to process 
> with predict.randomForest to save time. I was thinking it might be possible 
> to create a data frame with valid data for each line read from the input 
> multi-band image and then reconstruct the line before writing it out but I 
> think the overhead would be very high. At least using the brute force methods 
> like rbind.

It looks as though setting the values to NA will work. In the 
predict.randomForest example, do:

df <- iris[ind == 2,]
is.na(df[1:10, 1:2]) <- TRUE
predict(iris.rf, df)

So setting the 0 values to NA might get you the results you want, 
maintaining the relative order of the observations.

Roger

>
> All the best,
>
> Ned
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From torleif.lunde at cih.uib.no  Fri Feb 27 17:02:25 2009
From: torleif.lunde at cih.uib.no (Torleif Markussen Lunde)
Date: Fri, 27 Feb 2009 17:02:25 +0100
Subject: [R-sig-Geo] Bug in Rgshhs? - can not only set xlim (requires ylim)
Message-ID: <200902271702.25438.torleif.lunde@cih.uib.no>

Hi

If I am not wrong there is a small bug in Rgshhs in Maptools. When defining 
only xlim (not ylim) an error message is returned:
"Error in polys[[which(chosen_0 == (Antarctica - 1))]] :
  attempt to select less than one element"

Is this a bug or a feature?

In any case. I did some modifications to Rgshhs. It fixes the bug(?) and 
handles shifting slightly different. However the modified Rgshhs does not 
accept upper xlim 180 > xlim > 190. Did not figure out why yet. I am sorry if 
the modification is dirty. The function is slower (x 2) when shifting is 
involved.

The modified version (Rgshhsn) can be found at:
http://open.uib.no/R/Rgshhs3-tmp.r

Best wishes
Torleif


From reeves at nceas.ucsb.edu  Fri Feb 27 19:16:40 2009
From: reeves at nceas.ucsb.edu (rick reeves)
Date: Fri, 27 Feb 2009 10:16:40 -0800
Subject: [R-sig-Geo] Feature Extraction - object based image analysis
In-Reply-To: <28C15D104A882F47954DEE56148152CC1C0AAC41@nerckwmb1.ad.nerc.ac.uk>
References: <28C15D104A882F47954DEE56148152CC1C0AAC41@nerckwmb1.ad.nerc.ac.uk>
Message-ID: <49A82E08.9080804@nceas.ucsb.edu>

If, by 'feature extraction', the colleague refers to classifying the 
raster imagery pixels into discrete categores (e.g., vegetation types),
I would suggest looking at the 'r.' and 'i.' components of  GRASS GIS, 
which of course integrates well with R.

Hope this helps.
Rick R

Rawlins, Barry G wrote:
> I have a colleague who is not familiar with R and we were discussing feature extraction from multiple images (air photos, satellite based etc.). He uses a commercial tool for feature extraction. Can anyone point me to a package in R that does this? I have done a search but not found such a function. It is not a procedure I am familiar with.
>
> Many thanks, Barry
>
> Dr Barry Rawlins
> Sustainable Soils Team Leader
> British Geological Survey
> Keyworth
> Nottingham
> NG12 5GG
> Direct tel: 0115 9363140
> Mobile: 0788 4235473
> homepage: http://barryrawlins.googlepages.com<http://barryrawlins.googlepages.com/>
>
>
>
>
>   


-- 
Rick Reeves
Scientific Programmer/Analyst and Data Manager
National Center for Ecological Analysis and Synthesis
UC Santa Barbara
www.nceas.ucsb.edu
805 892 2533


From cicaboo at gmail.com  Sat Feb 28 16:56:57 2009
From: cicaboo at gmail.com (Michel Barbosa)
Date: Sat, 28 Feb 2009 16:56:57 +0100
Subject: [R-sig-Geo] Point pattern analysis | Kernel estimation and Google
	Maps
Message-ID: <f7f7b86f0902280756v1748fe07sb494d96b012531f5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090228/75ce705e/attachment.pl>

From Torleif.Lunde at cih.uib.no  Sat Feb 28 19:20:47 2009
From: Torleif.Lunde at cih.uib.no (Torleif Markussen Lunde)
Date: Sat, 28 Feb 2009 19:20:47 +0100
Subject: [R-sig-Geo] Point pattern analysis | Kernel estimation and
	GoogleMaps
References: <f7f7b86f0902280756v1748fe07sb494d96b012531f5@mail.gmail.com>
Message-ID: <A3EA804CA6F446429B6AEBB45558456301270E3B@HUGIN.uib.no>

If I understand your question correctly
Something like this? Note that the longleaf data are "wrong" in this case since coordinates were recorded in meters.
 
require(sp)
require(spatstat)
data(longleaf)
 
a <- with(longleaf, data.frame(cbind(x, y, marks)))
coordinates(a) <- ~x+y
#Original projection
my.proj <- CRS("+proj=lonlat +datum=WGS84")
proj4string(a) <- my.proj
bbox(a)
str(a)
 
Later on you can use spTransform. Please correct me if I am wrong.
 
Best wishes, and good luck
Torleif
 
 

________________________________

Fra: r-sig-geo-bounces at stat.math.ethz.ch p? vegne av Michel Barbosa
Sendt: l? 28.02.2009 16:56
Til: R-sig-geo
Emne: [R-sig-Geo] Point pattern analysis | Kernel estimation and GoogleMaps



Dear list,

I'm having troubles with matching the Google Map's bounding box with the
window of plot.ppp (spatstat). My coordinates are in longitude / latitude.
Ultimately, I'd like to have the bounding box of my Google Maps map to be
equal to the rectangle (window) in R. I've seen suggestions that UTM would
be a better way to go. Could you provide me with tips / ideas to tackle this
problem? My intent is to have the Kernel Estimation png overlayed on my
Google Maps map.

Kind regards,

Michel

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From b.rowlingson at lancaster.ac.uk  Sat Feb 28 20:45:22 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sat, 28 Feb 2009 19:45:22 +0000
Subject: [R-sig-Geo] Point pattern analysis | Kernel estimation and
	Google Maps
In-Reply-To: <f7f7b86f0902280756v1748fe07sb494d96b012531f5@mail.gmail.com>
References: <f7f7b86f0902280756v1748fe07sb494d96b012531f5@mail.gmail.com>
Message-ID: <d8ad40b50902281145v546cfaacr907a28c13d048b33@mail.gmail.com>

2009/2/28 Michel Barbosa <cicaboo at gmail.com>:
> Dear list,
>
> I'm having troubles with matching the Google Map's bounding box with the
> window of plot.ppp (spatstat). My coordinates are in longitude / latitude.
> Ultimately, I'd like to have the bounding box of my Google Maps map to be
> equal to the rectangle (window) in R. I've seen suggestions that UTM would
> be a better way to go. Could you provide me with tips / ideas to tackle this
> problem? My intent is to have the Kernel Estimation png overlayed on my
> Google Maps map.

 I've read this about ten times to try and figure out what you want to do!

 Do you want to generate a grid in R and overlay it on Google Maps,
using the Google Maps API? And then is the problem because of the axes
and labels on the png produced from the R graphics device?

 In which case you are probably better off using one of the functions
in the rgdal package to create a georeferenced raster file - that has
no axes or titles etc.

Google Maps uses lat-long with the EPSG:4326 coordinate system, so if
your data is in lat-long with the EPSG:4326 coordinate system then you
don't need any transformation.

Barry


From cicaboo at gmail.com  Sat Feb 28 23:56:54 2009
From: cicaboo at gmail.com (Michel Barbosa)
Date: Sat, 28 Feb 2009 23:56:54 +0100
Subject: [R-sig-Geo] Point pattern analysis | Kernel estimation and
	Google Maps
In-Reply-To: <d8ad40b50902281145v546cfaacr907a28c13d048b33@mail.gmail.com>
References: <f7f7b86f0902280756v1748fe07sb494d96b012531f5@mail.gmail.com>
	<d8ad40b50902281145v546cfaacr907a28c13d048b33@mail.gmail.com>
Message-ID: <f7f7b86f0902281456h514723b2q9748ee1ed090d5c1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090228/ab82e899/attachment.pl>

