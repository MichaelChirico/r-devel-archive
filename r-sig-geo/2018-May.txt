From julian.burgos at hafogvatn.is  Tue May  1 09:22:09 2018
From: julian.burgos at hafogvatn.is (Julian M. Burgos)
Date: Tue, 01 May 2018 07:22:09 +0000
Subject: [R-sig-Geo] Bug in raster::crop?
Message-ID: <xgz8t93ali6.fsf@hafogvatn.is>

Hello everyone,

I am getting this error when using the crop function in the raster
package.  Here is an example, sing the example in the help file:

> r <- raster(nrow=45, ncol=90)
> r[] <- 1:ncell(r)
> e <- extent(-160, 10, 30, 60)
> rc <- crop(r, e)

Error in extent(extent) : insufficient number of elements (should be 4)

I am using R version 3.4.4., and raster 2.6-7.

Many thanks,

Julian

--
Julian Mariano Burgos, PhD
Hafranns?knastofnun, ranns?kna- og r??gjafarstofnun hafs og vatna/
Marine and Freshwater Research Institute
Botnsj?varsvi?s / Demersal Division
Sk?lagata 4, 121 Reykjav?k, Iceland
S?mi/Telephone : +354-5752037
Br?fs?mi/Telefax:  +354-5752001
Netfang/Email: julian.burgos at hafogvatn.is


From b.rowlingson at lancaster.ac.uk  Tue May  1 09:44:16 2018
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 1 May 2018 08:44:16 +0100
Subject: [R-sig-Geo] Bug in raster::crop?
In-Reply-To: <xgz8t93ali6.fsf@hafogvatn.is>
References: <xgz8t93ali6.fsf@hafogvatn.is>
Message-ID: <CANVKczMvgx79td+mkJ1pojoV7LMY26iubWeaOB9cOF0Vi4id2A@mail.gmail.com>

Works perfectly for me, with the same versions of everything:

>     r <- raster(nrow=45, ncol=90)
>      r[] <- 1:ncell(r)
>      e <- extent(-160, 10, 30, 60)
>      rc <- crop(r, e)
>
> packageVersion("raster")
[1] ?2.6.7?
> version
               _
platform       x86_64-pc-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          3
minor          4.4

Can you get crop to work on anything?

Barry




On Tue, May 1, 2018 at 8:22 AM, Julian M. Burgos <julian.burgos at hafogvatn.is
> wrote:

> Hello everyone,
>
> I am getting this error when using the crop function in the raster
> package.  Here is an example, sing the example in the help file:
>
> > r <- raster(nrow=45, ncol=90)
> > r[] <- 1:ncell(r)
> > e <- extent(-160, 10, 30, 60)
> > rc <- crop(r, e)
>
> Error in extent(extent) : insufficient number of elements (should be 4)
>
> I am using R version 3.4.4., and raster 2.6-7.
>
> Many thanks,
>
> Julian
>
> --
> Julian Mariano Burgos, PhD
> Hafranns?knastofnun, ranns?kna- og r??gjafarstofnun hafs og vatna/
> Marine and Freshwater Research Institute
> Botnsj?varsvi?s / Demersal Division
> Sk?lagata 4, 121 Reykjav?k, Iceland
> S?mi/Telephone : +354-5752037
> Br?fs?mi/Telefax:  +354-5752001
> Netfang/Email: julian.burgos at hafogvatn.is
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From vijaylulla at gmail.com  Tue May  1 17:24:01 2018
From: vijaylulla at gmail.com (Vijay Lulla)
Date: Tue, 1 May 2018 11:24:01 -0400
Subject: [R-sig-Geo] Bug in raster::crop?
In-Reply-To: <CANVKczMvgx79td+mkJ1pojoV7LMY26iubWeaOB9cOF0Vi4id2A@mail.gmail.com>
References: <xgz8t93ali6.fsf@hafogvatn.is>
 <CANVKczMvgx79td+mkJ1pojoV7LMY26iubWeaOB9cOF0Vi4id2A@mail.gmail.com>
Message-ID: <CAKkiGbvuXWE6WXX92BA198TcNVYVaBGSxTmj6Y4HC09G1=D2xg@mail.gmail.com>

Works for me too...with same versions of everything.  Maybe you can try e
<- extent(c(-160,10,30,60)) ?  Apparently, ?`extent` states that it needs
either a Raster, Extent, matrix, or vector of four numbers.  I don't
understand why extent(-160,10,30,60) worked for me though!

On Tue, May 1, 2018 at 3:44 AM, Barry Rowlingson <
b.rowlingson at lancaster.ac.uk> wrote:

> Works perfectly for me, with the same versions of everything:
>
> >     r <- raster(nrow=45, ncol=90)
> >      r[] <- 1:ncell(r)
> >      e <- extent(-160, 10, 30, 60)
> >      rc <- crop(r, e)
> >
> > packageVersion("raster")
> [1] ?2.6.7?
> > version
>                _
> platform       x86_64-pc-linux-gnu
> arch           x86_64
> os             linux-gnu
> system         x86_64, linux-gnu
> status
> major          3
> minor          4.4
>
> Can you get crop to work on anything?
>
> Barry
>
>
>
>
> On Tue, May 1, 2018 at 8:22 AM, Julian M. Burgos <
> julian.burgos at hafogvatn.is
> > wrote:
>
> > Hello everyone,
> >
> > I am getting this error when using the crop function in the raster
> > package.  Here is an example, sing the example in the help file:
> >
> > > r <- raster(nrow=45, ncol=90)
> > > r[] <- 1:ncell(r)
> > > e <- extent(-160, 10, 30, 60)
> > > rc <- crop(r, e)
> >
> > Error in extent(extent) : insufficient number of elements (should be 4)
> >
> > I am using R version 3.4.4., and raster 2.6-7.
> >
> > Many thanks,
> >
> > Julian
> >
> > --
> > Julian Mariano Burgos, PhD
> > Hafranns?knastofnun, ranns?kna- og r??gjafarstofnun hafs og vatna/
> > Marine and Freshwater Research Institute
> > Botnsj?varsvi?s / Demersal Division
> > Sk?lagata 4, 121 Reykjav?k, Iceland
> > S?mi/Telephone : +354-5752037
> > Br?fs?mi/Telefax:  +354-5752001
> > Netfang/Email: julian.burgos at hafogvatn.is
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Vijay Lulla, Ph.D.

Assistant Professor,
Dept. of Geography, IUPUI
425 University Blvd, CA-207C.
Indianapolis, IN-46202
vlulla at iupui.edu

<http://vijaylulla.com>
http://vijaylulla.com

	[[alternative HTML version deleted]]


From julian.burgos at hafogvatn.is  Wed May  2 10:58:19 2018
From: julian.burgos at hafogvatn.is (Julian M. Burgos)
Date: Wed, 02 May 2018 08:58:19 +0000
Subject: [R-sig-Geo] Bug in raster::crop?
In-Reply-To: <CAKkiGbvuXWE6WXX92BA198TcNVYVaBGSxTmj6Y4HC09G1=D2xg@mail.gmail.com>
References: <xgz8t93ali6.fsf@hafogvatn.is>
 <CANVKczMvgx79td+mkJ1pojoV7LMY26iubWeaOB9cOF0Vi4id2A@mail.gmail.com>
 <CAKkiGbvuXWE6WXX92BA198TcNVYVaBGSxTmj6Y4HC09G1=D2xg@mail.gmail.com>
Message-ID: <xgzy3h2bfis.fsf@hafogvatn.is>

No, I am still getting the same error, either using
extent(c(-160,10,30,60)) or extent(-160,10,30,60).  I can crop polygons
with no problem.  The strange thing is that it was working fine until a
couple of days ago.  I am not sure what changed...


Vijay Lulla writes:

> Works for me too...with same versions of everything.  Maybe you can try e
> <- extent(c(-160,10,30,60)) ?  Apparently, ?`extent` states that it needs
> either a Raster, Extent, matrix, or vector of four numbers.  I don't
> understand why extent(-160,10,30,60) worked for me though!
>
> On Tue, May 1, 2018 at 3:44 AM, Barry Rowlingson <
> b.rowlingson at lancaster.ac.uk> wrote:
>
>> Works perfectly for me, with the same versions of everything:
>>
>> >     r <- raster(nrow=45, ncol=90)
>> >      r[] <- 1:ncell(r)
>> >      e <- extent(-160, 10, 30, 60)
>> >      rc <- crop(r, e)
>> >
>> > packageVersion("raster")
>> [1] ?2.6.7?
>> > version
>>                _
>> platform       x86_64-pc-linux-gnu
>> arch           x86_64
>> os             linux-gnu
>> system         x86_64, linux-gnu
>> status
>> major          3
>> minor          4.4
>>
>> Can you get crop to work on anything?
>>
>> Barry
>>
>>
>>
>>
>> On Tue, May 1, 2018 at 8:22 AM, Julian M. Burgos <
>> julian.burgos at hafogvatn.is
>> > wrote:
>>
>> > Hello everyone,
>> >
>> > I am getting this error when using the crop function in the raster
>> > package.  Here is an example, sing the example in the help file:
>> >
>> > > r <- raster(nrow=45, ncol=90)
>> > > r[] <- 1:ncell(r)
>> > > e <- extent(-160, 10, 30, 60)
>> > > rc <- crop(r, e)
>> >
>> > Error in extent(extent) : insufficient number of elements (should be 4)
>> >
>> > I am using R version 3.4.4., and raster 2.6-7.
>> >
>> > Many thanks,
>> >
>> > Julian
>> >
>> > --
>> > Julian Mariano Burgos, PhD
>> > Hafranns?knastofnun, ranns?kna- og r??gjafarstofnun hafs og vatna/
>> > Marine and Freshwater Research Institute
>> > Botnsj?varsvi?s / Demersal Division
>> > Sk?lagata 4, 121 Reykjav?k, Iceland
>> > S?mi/Telephone : +354-5752037
>> > Br?fs?mi/Telefax:  +354-5752001
>> > Netfang/Email: julian.burgos at hafogvatn.is
>> >
>> > _______________________________________________
>> > R-sig-Geo mailing list
>> > R-sig-Geo at r-project.org
>> > https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=02%7C01%7C%7C68dbce3f524b40630f7308d5af779672%7C8e105b94435e4303a61063620dbe162b%7C0%7C0%7C636607850526029279&sdata=Zze9meBzzUJSW2sMf2Srzl4EvnNOxvntKG2X1N7WNoU%3D&reserved=0
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=02%7C01%7C%7C68dbce3f524b40630f7308d5af779672%7C8e105b94435e4303a61063620dbe162b%7C0%7C0%7C636607850526029279&sdata=Zze9meBzzUJSW2sMf2Srzl4EvnNOxvntKG2X1N7WNoU%3D&reserved=0
>>


--
Julian Mariano Burgos, PhD
Hafranns?knastofnun, ranns?kna- og r??gjafarstofnun hafs og vatna/
Marine and Freshwater Research Institute
Botnsj?varsvi?s / Demersal Division
Sk?lagata 4, 121 Reykjav?k, Iceland
S?mi/Telephone : +354-5752037
Br?fs?mi/Telefax:  +354-5752001
Netfang/Email: julian.burgos at hafogvatn.is


From julian.burgos at hafogvatn.is  Wed May  2 11:13:57 2018
From: julian.burgos at hafogvatn.is (Julian M. Burgos)
Date: Wed, 02 May 2018 09:13:57 +0000
Subject: [R-sig-Geo] Bug in raster::crop?
In-Reply-To: <CAFk_Y3vY7niMNyLVF3Ht_vNGmDpmC8v6qn7eoyo2BW5oKJ-cOA@mail.gmail.com>
References: <xgz8t93ali6.fsf@hafogvatn.is>
 <CANVKczMvgx79td+mkJ1pojoV7LMY26iubWeaOB9cOF0Vi4id2A@mail.gmail.com>
 <CAKkiGbvuXWE6WXX92BA198TcNVYVaBGSxTmj6Y4HC09G1=D2xg@mail.gmail.com>
 <xgzy3h2bfis.fsf@hafogvatn.is>
 <CAFk_Y3vY7niMNyLVF3Ht_vNGmDpmC8v6qn7eoyo2BW5oKJ-cOA@mail.gmail.com>
Message-ID: <xgzwowmbesq.fsf@hafogvatn.is>

I tried that too, but I am still getting the error.

Alzira Ramos writes:

> Maybe, you need to add raster::extent(c(-160,10,30,60))
>
> r <- raster(nrow=45, ncol=90)
> r[] <- 1:ncell(r)
> e <- raster::extent(-160, 10, 30, 60)
> rc <- crop(r, e)
>
>
> On 2 May 2018 at 10:58, Julian M. Burgos <julian.burgos at hafogvatn.is> wrote:
>
>> No, I am still getting the same error, either using
>> extent(c(-160,10,30,60)) or extent(-160,10,30,60).  I can crop polygons
>> with no problem.  The strange thing is that it was working fine until a
>> couple of days ago.  I am not sure what changed...
>>
>>
>> Vijay Lulla writes:
>>
>> > Works for me too...with same versions of everything.  Maybe you can try e
>> > <- extent(c(-160,10,30,60)) ?  Apparently, ?`extent` states that it needs
>> > either a Raster, Extent, matrix, or vector of four numbers.  I don't
>> > understand why extent(-160,10,30,60) worked for me though!
>> >
>> > On Tue, May 1, 2018 at 3:44 AM, Barry Rowlingson <
>> > b.rowlingson at lancaster.ac.uk> wrote:
>> >
>> >> Works perfectly for me, with the same versions of everything:
>> >>
>> >> >     r <- raster(nrow=45, ncol=90)
>> >> >      r[] <- 1:ncell(r)
>> >> >      e <- extent(-160, 10, 30, 60)
>> >> >      rc <- crop(r, e)
>> >> >
>> >> > packageVersion("raster")
>> >> [1] ?2.6.7?
>> >> > version
>> >>                _
>> >> platform       x86_64-pc-linux-gnu
>> >> arch           x86_64
>> >> os             linux-gnu
>> >> system         x86_64, linux-gnu
>> >> status
>> >> major          3
>> >> minor          4.4
>> >>
>> >> Can you get crop to work on anything?
>> >>
>> >> Barry
>> >>
>> >>
>> >>
>> >>
>> >> On Tue, May 1, 2018 at 8:22 AM, Julian M. Burgos <
>> >> julian.burgos at hafogvatn.is
>> >> > wrote:
>> >>
>> >> > Hello everyone,
>> >> >
>> >> > I am getting this error when using the crop function in the raster
>> >> > package.  Here is an example, sing the example in the help file:
>> >> >
>> >> > > r <- raster(nrow=45, ncol=90)
>> >> > > r[] <- 1:ncell(r)
>> >> > > e <- extent(-160, 10, 30, 60)
>> >> > > rc <- crop(r, e)
>> >> >
>> >> > Error in extent(extent) : insufficient number of elements (should be
>> 4)
>> >> >
>> >> > I am using R version 3.4.4., and raster 2.6-7.
>> >> >
>> >> > Many thanks,
>> >> >
>> >> > Julian
>> >> >
>> >> > --
>> >> > Julian Mariano Burgos, PhD
>> >> > Hafranns?knastofnun, ranns?kna- og r??gjafarstofnun hafs og vatna/
>> >> > Marine and Freshwater Research Institute
>> >> > Botnsj?varsvi?s / Demersal Division
>> >> > Sk?lagata 4, 121 Reykjav?k, Iceland
>> >> > S?mi/Telephone : +354-5752037
>> >> > Br?fs?mi/Telefax:  +354-5752001
>> >> > Netfang/Email: julian.burgos at hafogvatn.is
>> >> >
>> >> > _______________________________________________
>> >> > R-sig-Geo mailing list
>> >> > R-sig-Geo at r-project.org
>> >> > https://emea01.safelinks.protection.outlook.com/?url=
>> https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-
>> geo&data=02%7C01%7C%7C68dbce3f524b40630f7308d5af779672%
>> 7C8e105b94435e4303a61063620dbe162b%7C0%7C0%7C636607850526029279&sdata=
>> Zze9meBzzUJSW2sMf2Srzl4EvnNOxvntKG2X1N7WNoU%3D&reserved=0
>> >> >
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> _______________________________________________
>> >> R-sig-Geo mailing list
>> >> R-sig-Geo at r-project.org
>> >> https://emea01.safelinks.protection.outlook.com/?url=
>> https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-
>> geo&data=02%7C01%7C%7C68dbce3f524b40630f7308d5af779672%
>> 7C8e105b94435e4303a61063620dbe162b%7C0%7C0%7C636607850526029279&sdata=
>> Zze9meBzzUJSW2sMf2Srzl4EvnNOxvntKG2X1N7WNoU%3D&reserved=0
>> >>
>>
>>
>> --
>> Julian Mariano Burgos, PhD
>> Hafranns?knastofnun, ranns?kna- og r??gjafarstofnun hafs og vatna/
>> Marine and Freshwater Research Institute
>> Botnsj?varsvi?s / Demersal Division
>> Sk?lagata 4, 121 Reykjav?k, Iceland
>> S?mi/Telephone : +354-5752037
>> Br?fs?mi/Telefax:  +354-5752001
>> Netfang/Email: julian.burgos at hafogvatn.is
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=02%7C01%7C%7C85bc0da67b5348ac00d508d5b00bbcf1%7C8e105b94435e4303a61063620dbe162b%7C0%7C0%7C636608486825213487&sdata=9csG6vh5u1xmib0FepHuxBofg1wJLB0%2BehANGknX1VU%3D&reserved=0
>>


--
Julian Mariano Burgos, PhD
Hafranns?knastofnun, ranns?kna- og r??gjafarstofnun hafs og vatna/
Marine and Freshwater Research Institute
Botnsj?varsvi?s / Demersal Division
Sk?lagata 4, 121 Reykjav?k, Iceland
S?mi/Telephone : +354-5752037
Br?fs?mi/Telefax:  +354-5752001
Netfang/Email: julian.burgos at hafogvatn.is


From julian.burgos at hafogvatn.is  Wed May  2 11:17:18 2018
From: julian.burgos at hafogvatn.is (Julian M. Burgos)
Date: Wed, 02 May 2018 09:17:18 +0000
Subject: [R-sig-Geo] Bug in raster::crop?
In-Reply-To: <xgz8t93ali6.fsf@hafogvatn.is>
References: <xgz8t93ali6.fsf@hafogvatn.is>
Message-ID: <xgzvac6ben5.fsf@hafogvatn.is>

I should add that I get this also when loading R with the --vanilla
flag.

Julian M. Burgos writes:

> Hello everyone,
>
> I am getting this error when using the crop function in the raster
> package.  Here is an example, sing the example in the help file:
>
>> r <- raster(nrow=45, ncol=90)
>> r[] <- 1:ncell(r)
>> e <- extent(-160, 10, 30, 60)
>> rc <- crop(r, e)
>
> Error in extent(extent) : insufficient number of elements (should be 4)
>
> I am using R version 3.4.4., and raster 2.6-7.
>
> Many thanks,
>
> Julian


--
Julian Mariano Burgos, PhD
Hafranns?knastofnun, ranns?kna- og r??gjafarstofnun hafs og vatna/
Marine and Freshwater Research Institute
Botnsj?varsvi?s / Demersal Division
Sk?lagata 4, 121 Reykjav?k, Iceland
S?mi/Telephone : +354-5752037
Br?fs?mi/Telefax:  +354-5752001
Netfang/Email: julian.burgos at hafogvatn.is


From julian.burgos at hafogvatn.is  Wed May  2 12:05:42 2018
From: julian.burgos at hafogvatn.is (Julian M. Burgos)
Date: Wed, 02 May 2018 10:05:42 +0000
Subject: [R-sig-Geo] Bug in raster::crop? - solved
In-Reply-To: <xgzvac6ben5.fsf@hafogvatn.is>
References: <xgz8t93ali6.fsf@hafogvatn.is> <xgzvac6ben5.fsf@hafogvatn.is>
Message-ID: <xgzsh7abceh.fsf@hafogvatn.is>

Ok, I removed and re-installed the raster package, and now everything
works.

Julian M. Burgos writes:

> I should add that I get this also when loading R with the --vanilla
> flag.
>
> Julian M. Burgos writes:
>
>> Hello everyone,
>>
>> I am getting this error when using the crop function in the raster
>> package.  Here is an example, sing the example in the help file:
>>
>>> r <- raster(nrow=45, ncol=90)
>>> r[] <- 1:ncell(r)
>>> e <- extent(-160, 10, 30, 60)
>>> rc <- crop(r, e)
>>
>> Error in extent(extent) : insufficient number of elements (should be 4)
>>
>> I am using R version 3.4.4., and raster 2.6-7.
>>
>> Many thanks,
>>
>> Julian


--
Julian Mariano Burgos, PhD
Hafranns?knastofnun, ranns?kna- og r??gjafarstofnun hafs og vatna/
Marine and Freshwater Research Institute
Botnsj?varsvi?s / Demersal Division
Sk?lagata 4, 121 Reykjav?k, Iceland
S?mi/Telephone : +354-5752037
Br?fs?mi/Telefax:  +354-5752001
Netfang/Email: julian.burgos at hafogvatn.is


From gestauffer at gmail.com  Wed May  2 19:18:27 2018
From: gestauffer at gmail.com (Glenn Stauffer)
Date: Wed, 2 May 2018 12:18:27 -0500
Subject: [R-sig-Geo] Error using spsample on SpatialLines in Linux OS
In-Reply-To: <3C2BF1B5-0545-47F6-8A6C-65BCE7832A64@llnl.gov>
References: <008e01d3dd7c$18130820$48391860$@gmail.com>
 <11130866-7cf5-b6c1-8d04-953d24d65659@uni-muenster.de>
 <00a001d3dd7f$04376280$0ca62780$@gmail.com>
 <3C2BF1B5-0545-47F6-8A6C-65BCE7832A64@llnl.gov>
Message-ID: <011201d3e239$96aade30$c4009a90$@gmail.com>

Just to follow up. Reinstalling the sp package did not fix the problem. But, uninstalling, and then reinstalling did fix it. I don't get the error anymore.

-----Original Message-----
From: MacQueen, Don [mailto:macqueen1 at llnl.gov] 
Sent: Friday, April 27, 2018 11:14 AM
To: Glenn Stauffer <gestauffer at gmail.com>; r-sig-geo at r-project.org
Cc: 'Edzer Pebesma' <edzer.pebesma at uni-muenster.de>
Subject: Re: [R-sig-Geo] Error using spsample on SpatialLines in Linux OS

The code also works fine on my Mac, and an RHEL (linux) machine to which I have access (though both are still at R 3.4.2 and sp_1.2-5).

You could focus in on the problem a bit by trying the following (I expect you will see the same error)

> sp::LineLength(pts)
[1] 123.0096

Starting with spsample(), and drilling down, eventually LineLength() calls the C function sp_lengths.  LineLength() is pretty simple, and I don't see any evidence that it depends on other packages. I'm not the expert that Edzer is, but it pretty much looks like an installation problem with sp, sorry to say. I can't think of anything else...

Sorry I'm not more helpful,
-Don


> sp::LineLength(pts, sum=FALSE)
[1] 15.81139  7.81025 42.37924 57.00877

> SpatialLinesLengths(L)
[1] 123.0096

> LinesLength(L at lines[[1]])
[1] 123.0096


> sessionInfo()
R version 3.4.2 (2017-09-28)
Platform: x86_64-apple-darwin15.6.0 (64-bit) Running under: OS X El Capitan 10.11.6

Matrix products: default
BLAS: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRblas.0.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] sp_1.2-5

loaded via a namespace (and not attached):
 [1] compiler_3.4.2     colorspace_1.3-2   scales_0.5.0.9000  lazyeval_0.2.1    
 [5] plyr_1.8.4         rgdal_1.2-13       tools_3.4.2        gtable_0.2.0      
 [9] tibble_1.3.4       Rcpp_0.12.14       ggplot2_2.2.1.9000 grid_3.4.2        
[13] rlang_0.1.2        munsell_0.4.3      lattice_0.20-35   

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 4/26/18, 9:52 AM, "R-sig-Geo on behalf of Glenn Stauffer" <r-sig-geo-bounces at r-project.org on behalf of gestauffer at gmail.com> wrote:

    Do you mean the sp package? I should have mentioned that I already tried
    that.
    
    -----Original Message-----
    From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Edzer
    Pebesma
    Sent: Thursday, April 26, 2018 11:35 AM
    To: r-sig-geo at r-project.org
    Subject: Re: [R-sig-Geo] Error using spsample on SpatialLines in Linux OS
    
    I would try reinstalling the package.
    
    On 04/26/2018 06:31 PM, Glenn Stauffer wrote:
    > I ran across a problem when trying to use spsample to sample points 
    > along a line, while in a Linux OS (Mint 18.3). The following code 
    > (which works fine in Win 10):
    > 
    >  
    > 
    > pts <- matrix(c(c(6000,6015,6021,6035,6050),
    > c(6000,5995,6000,6040,6095)),5,2,byrow=FALSE)
    > L = 
    > SpatialLines(list(Lines(list(Line(coordinates(pts))),"X")),proj4string 
    > =
    > CRS("+init=epsg:3071"))
    > plot(L)
    > Lsamp <- spsample(L,10,type="regular",offset=0.5) # this is the line 
    > that generates the error
    > 
    >  
    > 
    > produces the following error:
    > 
    >  
    > 
    > Error in .C("sp_lengths", x, y, n, lengths, lonlat, PACKAGE = "sp") : 
    >   "sp_lengths" not available for .C() for package "sp"
    > 
    > Could this be related to some wrong versions of certain dependencies 
    > (e.g., GDAL)? I don't know much about that, but I did run into that 
    > issue with trying to install other packages (rgeos, sf). In any case, 
    > how can I prevent this error?
    > 
    >  
    > 
    > Thanks,
    > 
    > Glenn
    > 
    >  
    > 
    >  
    > 
    > 
    > 	[[alternative HTML version deleted]]
    > 
    > _______________________________________________
    > R-sig-Geo mailing list
    > R-sig-Geo at r-project.org
    > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
    > 
    
    --
    Edzer Pebesma
    Institute for Geoinformatics
    Heisenbergstrasse 2, 48151 Muenster, Germany
    Phone: +49 251 8333081
    
    _______________________________________________
    R-sig-Geo mailing list
    R-sig-Geo at r-project.org
    https://stat.ethz.ch/mailman/listinfo/r-sig-geo
    
    _______________________________________________
    R-sig-Geo mailing list
    R-sig-Geo at r-project.org
    https://stat.ethz.ch/mailman/listinfo/r-sig-geo
    


From ra454 at exeter.ac.uk  Wed May  2 19:34:41 2018
From: ra454 at exeter.ac.uk (Aguirre Perez, Roman)
Date: Wed, 2 May 2018 17:34:41 +0000
Subject: [R-sig-Geo] Issues with a GDB file in R?
Message-ID: <13F59690-AB9E-40B2-B9F7-2474C9771F52@exeter.ac.uk>

Hi everyone,

I?ve been struggling with a ESRI Geodatabase file (clc12_Version_18_5.gdb) which is a layer of land cover classes available on

https://land.copernicus.eu/pan-european/corine-land-cover/clc-2012?tab=download

whose size is 2.61 GB once unzipped.

My ultimate task is to overlay it with the last NUTS3 administrative boundaries shapefile (2013) available on

http://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units

in order to compute the area covered by each class within each NUTS3 region.

Despite the ease of friendly software for performing this task, haven?t been capable of doing it - GRASS didn?t load the file as the log reports problems with the polygons, QGIS shows a warning regarding a specific object and ArcGIS got frozen. I guess it?s because the PC I used doesn?t have enough capacity. Unfortunately, I don?t have access to a more powerful one.

Anyway, I decided to try with R -after all, I?ll perform my analysis with it. So I started exploring this GDB with rgdal:

ogrInfo(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")

Source: "/Users/Roman/Desktop/clc12gdb/clc12_Version_18_5.gdb",
layer: "clc12_Version_18_5"
Driver: OpenFileGDB;
number of rows: 2370829
Feature type: wkbPolygon with 3 dimensions
Extent: (-2693292 -3086662) - (10037210 5440568)
Null geometry IDs: 2156240
CRS: +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs
Number of fields: 6
name                      type  length  typeName
1 code_12              4       3           String
2 ID                         4       18         String
3 Remark               4       20         String
4 Area_Ha             2       0           Real
5 Shape_Length   2       0           Real
6 Shape_Area       2       0           Real

Then I tried to load it typing

clc<-readOGR(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")

After 3-5 minutes, it appears the following text:

OGR data source with driver: OpenFileGDB
Source: "/Users/Roman/Desktop/clc12shp/clc12_Version_18_5.gdb", layer: "clc12_Version_18_5"
with 2370829 features
It has 6 fields

Unfortunately, after trying 5 times (each one took around 8 hours) I couldn?t get anything but the following messages:

Warning messages:
1: In readOGR(dsn = "clc12_Version_18_5.gdb", layer = "clc12_Version_18_5") :
Dropping null geometries: 2156240
2: In readOGR(dsn = "clc12_Version_18_5.gdb", layer = "clc12_Version_18_5") :
Z-dimension discarded

Could anyone advise me how to tackle it? I also would appreciate suggestions on how to work with geodatabases - it?s my first time I work with these kind of files so I don?t even know their structure.

By the way, these are my computer and software specifications:

MacBook Pro 2012
Processor 2.6 GHz Intel Core i7
Memory 16 GB DDR3
R 3.5.0
RStudio 1.1.447


Best,
Roman.

	[[alternative HTML version deleted]]


From SWalbridge at esri.com  Wed May  2 19:52:56 2018
From: SWalbridge at esri.com (Shaun Walbridge)
Date: Wed, 2 May 2018 17:52:56 +0000
Subject: [R-sig-Geo] Issues with a GDB file in R?
In-Reply-To: <13F59690-AB9E-40B2-B9F7-2474C9771F52@exeter.ac.uk>
References: <13F59690-AB9E-40B2-B9F7-2474C9771F52@exeter.ac.uk>
Message-ID: <AFA371A2-4A57-4038-AD9B-2A6C894E2A86@esri.com>

Hello Roman,

A couple of suggested options: You can try and use the arcgisbinding package [1] to pull the data directly into R via ArcGIS, as you mentioned you have ArcGIS available [presumably on Windows or in a VM]. It will access the data directly, and let you create sp and sf objects out of Geodatabases with little work. A basic workflow looks like this:

d <- arc.open("path/file.gdb/layer_name")
df <- arc.select(d) # here, you can filter columns and attributes, see [2]
# create an sf object
df.sf <- arc.data2sf(df)
# alternatively, create an sp object
df.sp <- arc.data2sp(df)

You can also write the results back to a geodatabase, or any other format that ArcGIS understands. Another option is trying the SpatiaLite version of the data at the URL you posted. You should be able to access this using R directly, provided your rgdal installation is correctly built to read spatialite databases. If it is, try the same process you mentioned using rgdal, but point it at the SpatialLite database instead. You could also use command-line OGR to convert the data, that has a few options like where clause filtering that aren't directly available via readOGR.

If neither of these options work, let me know and I can convert the data for you into a format of your preference.

Cheers,
Shaun

1. https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_R-2DArcGIS_r-2Dbridge-2Dinstall&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=fCPRb7QX-vd5bnO9gIJHCiX852SVUtyYX--xtCKtpfk&m=VcOyJ24SX8iVhqYGKDSOibdcFFiTWW3s5ctLZkiGYyY&s=dDYwxM4KOos8syBwUUUuSWLcyR4ZJlpdzbVvvfd28Oc&e=
2. https://urldefense.proofpoint.com/v2/url?u=https-3A__rdrr.io_github_R-2DArcGIS_r-2Dbridge_man_arc.select.html&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=fCPRb7QX-vd5bnO9gIJHCiX852SVUtyYX--xtCKtpfk&m=VcOyJ24SX8iVhqYGKDSOibdcFFiTWW3s5ctLZkiGYyY&s=oXh8b_5yVefz29INtNDKGdVJ86_GpF3gxuPY2aUOPyY&e=



?On 5/2/18, 1:34 PM, "R-sig-Geo on behalf of Aguirre Perez, Roman" <r-sig-geo-bounces at r-project.org on behalf of ra454 at exeter.ac.uk> wrote:

    Hi everyone,
    
    I?ve been struggling with a ESRI Geodatabase file (clc12_Version_18_5.gdb) which is a layer of land cover classes available on
    
    https://urldefense.proofpoint.com/v2/url?u=https-3A__land.copernicus.eu_pan-2Deuropean_corine-2Dland-2Dcover_clc-2D2012-3Ftab-3Ddownload&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=9LaO4HiB5C5ewiuN_IeSQJSgq2tl5_-oMECPChtZa_U&e=
    
    whose size is 2.61 GB once unzipped.
    
    My ultimate task is to overlay it with the last NUTS3 administrative boundaries shapefile (2013) available on
    
    https://urldefense.proofpoint.com/v2/url?u=http-3A__ec.europa.eu_eurostat_web_gisco_geodata_reference-2Ddata_administrative-2Dunits-2Dstatistical-2Dunits&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=VExYSoR8FY_vhZaPNJpoOx0ZCZNMU9hMTtlGJZj2joU&e=
    
    in order to compute the area covered by each class within each NUTS3 region.
    
    Despite the ease of friendly software for performing this task, haven?t been capable of doing it - GRASS didn?t load the file as the log reports problems with the polygons, QGIS shows a warning regarding a specific object and ArcGIS got frozen. I guess it?s because the PC I used doesn?t have enough capacity. Unfortunately, I don?t have access to a more powerful one.
    
    Anyway, I decided to try with R -after all, I?ll perform my analysis with it. So I started exploring this GDB with rgdal:
    
    ogrInfo(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
    
    Source: "/Users/Roman/Desktop/clc12gdb/clc12_Version_18_5.gdb",
    layer: "clc12_Version_18_5"
    Driver: OpenFileGDB;
    number of rows: 2370829
    Feature type: wkbPolygon with 3 dimensions
    Extent: (-2693292 -3086662) - (10037210 5440568)
    Null geometry IDs: 2156240
    CRS: +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs
    Number of fields: 6
    name                      type  length  typeName
    1 code_12              4       3           String
    2 ID                         4       18         String
    3 Remark               4       20         String
    4 Area_Ha             2       0           Real
    5 Shape_Length   2       0           Real
    6 Shape_Area       2       0           Real
    
    Then I tried to load it typing
    
    clc<-readOGR(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
    
    After 3-5 minutes, it appears the following text:
    
    OGR data source with driver: OpenFileGDB
    Source: "/Users/Roman/Desktop/clc12shp/clc12_Version_18_5.gdb", layer: "clc12_Version_18_5"
    with 2370829 features
    It has 6 fields
    
    Unfortunately, after trying 5 times (each one took around 8 hours) I couldn?t get anything but the following messages:
    
    Warning messages:
    1: In readOGR(dsn = "clc12_Version_18_5.gdb", layer = "clc12_Version_18_5") :
    Dropping null geometries: 2156240
    2: In readOGR(dsn = "clc12_Version_18_5.gdb", layer = "clc12_Version_18_5") :
    Z-dimension discarded
    
    Could anyone advise me how to tackle it? I also would appreciate suggestions on how to work with geodatabases - it?s my first time I work with these kind of files so I don?t even know their structure.
    
    By the way, these are my computer and software specifications:
    
    MacBook Pro 2012
    Processor 2.6 GHz Intel Core i7
    Memory 16 GB DDR3
    R 3.5.0
    RStudio 1.1.447
    
    
    Best,
    Roman.
       



From crockwood at pointblue.org  Wed May  2 20:56:09 2018
From: crockwood at pointblue.org (Cotton Rockwood)
Date: Wed, 2 May 2018 18:56:09 +0000
Subject: [R-sig-Geo] Issues with a GDB file in R?
In-Reply-To: <13F59690-AB9E-40B2-B9F7-2474C9771F52@exeter.ac.uk>
References: <13F59690-AB9E-40B2-B9F7-2474C9771F52@exeter.ac.uk>
Message-ID: <DM2PR04MB701F3C5077A53075B93F55FB9800@DM2PR04MB701.namprd04.prod.outlook.com>

Hi Roman -
As far as I know, 'readOGR' does not read tables in file geodatabases. (see https://gis.stackexchange.com/questions/184013/read-a-table-from-an-esri-file-geodatabase-gdb-using-r). I'm guessing this is the problem you are running into with R. In addition to Sean's suggestions, you might also want to try using the 'sf' package since it can read file geodatabase tables and usually increases read times (and other spatial operations) significantly compared to 'sp' and 'readOGR'. I'm not sure if it will address the issues you seem to be having with the geometries as suggested by the GRASS, QGIS and ArcGIS errors. The specific 'sf' function is:
'st_read' and the syntax is very similar to 'readOGR'.  You will need to make sure you have the newest version: 0.6-1.
-Cotton

-----Original Message-----
From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Aguirre Perez, Roman
Sent: Wednesday, May 02, 2018 10:35 AM
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] Issues with a GDB file in R?

Hi everyone,

I?ve been struggling with a ESRI Geodatabase file (clc12_Version_18_5.gdb) which is a layer of land cover classes available on

https://land.copernicus.eu/pan-european/corine-land-cover/clc-2012?tab=download

whose size is 2.61 GB once unzipped.

My ultimate task is to overlay it with the last NUTS3 administrative boundaries shapefile (2013) available on

http://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units

in order to compute the area covered by each class within each NUTS3 region.

Despite the ease of friendly software for performing this task, haven?t been capable of doing it - GRASS didn?t load the file as the log reports problems with the polygons, QGIS shows a warning regarding a specific object and ArcGIS got frozen. I guess it?s because the PC I used doesn?t have enough capacity. Unfortunately, I don?t have access to a more powerful one.

Anyway, I decided to try with R -after all, I?ll perform my analysis with it. So I started exploring this GDB with rgdal:

ogrInfo(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")

Source: "/Users/Roman/Desktop/clc12gdb/clc12_Version_18_5.gdb",
layer: "clc12_Version_18_5"
Driver: OpenFileGDB;
number of rows: 2370829
Feature type: wkbPolygon with 3 dimensions
Extent: (-2693292 -3086662) - (10037210 5440568) Null geometry IDs: 2156240
CRS: +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs Number of fields: 6
name                      type  length  typeName
1 code_12              4       3           String
2 ID                         4       18         String
3 Remark               4       20         String
4 Area_Ha             2       0           Real
5 Shape_Length   2       0           Real
6 Shape_Area       2       0           Real

Then I tried to load it typing

clc<-readOGR(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")

After 3-5 minutes, it appears the following text:

OGR data source with driver: OpenFileGDB
Source: "/Users/Roman/Desktop/clc12shp/clc12_Version_18_5.gdb", layer: "clc12_Version_18_5"
with 2370829 features
It has 6 fields

Unfortunately, after trying 5 times (each one took around 8 hours) I couldn?t get anything but the following messages:

Warning messages:
1: In readOGR(dsn = "clc12_Version_18_5.gdb", layer = "clc12_Version_18_5") :
Dropping null geometries: 2156240
2: In readOGR(dsn = "clc12_Version_18_5.gdb", layer = "clc12_Version_18_5") :
Z-dimension discarded

Could anyone advise me how to tackle it? I also would appreciate suggestions on how to work with geodatabases - it?s my first time I work with these kind of files so I don?t even know their structure.

By the way, these are my computer and software specifications:

MacBook Pro 2012
Processor 2.6 GHz Intel Core i7
Memory 16 GB DDR3
R 3.5.0
RStudio 1.1.447


Best,
Roman.

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

From mel at mbacou.com  Thu May  3 12:19:08 2018
From: mel at mbacou.com (Bacou, Melanie)
Date: Thu, 3 May 2018 06:19:08 -0400
Subject: [R-sig-Geo] Issues with a GDB file in R?
In-Reply-To: <DM2PR04MB701F3C5077A53075B93F55FB9800@DM2PR04MB701.namprd04.prod.outlook.com>
References: <13F59690-AB9E-40B2-B9F7-2474C9771F52@exeter.ac.uk>
 <DM2PR04MB701F3C5077A53075B93F55FB9800@DM2PR04MB701.namprd04.prod.outlook.com>
Message-ID: <8117c90c-732d-7829-f622-5659aae1e89e@mbacou.com>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20180503/aff23f6b/attachment.html>

From ra454 at exeter.ac.uk  Thu May  3 13:19:32 2018
From: ra454 at exeter.ac.uk (Aguirre Perez, Roman)
Date: Thu, 3 May 2018 11:19:32 +0000
Subject: [R-sig-Geo] Issues with a GDB file in R?
In-Reply-To: <AFA371A2-4A57-4038-AD9B-2A6C894E2A86@esri.com>
References: <13F59690-AB9E-40B2-B9F7-2474C9771F52@exeter.ac.uk>
 <AFA371A2-4A57-4038-AD9B-2A6C894E2A86@esri.com>
Message-ID: <A814689E-6CF5-404D-94FD-841FB832FFAB@exeter.ac.uk>

Hello Shaun,

Thanks a lot for replying and providing me alternative options.


Unfortunately, I can't try both options anymore as I ran out of ArcGIS due to I was using a university PC which is not available now (I installed an ArcGIS trial version there), but I'll try it later. I also failed on installing the sf package - I'll dig a bit more on it. Nevertheless, I already downloaded the SpatialLite version so I'll try the second option and I'll let you know how it goes.


Regards,
Roman.  

?On 02/05/2018, 18:53, "Shaun Walbridge" <SWalbridge at esri.com> wrote:

    Hello Roman,
    
    A couple of suggested options: You can try and use the arcgisbinding package [1] to pull the data directly into R via ArcGIS, as you mentioned you have ArcGIS available [presumably on Windows or in a VM]. It will access the data directly, and let you create sp and sf objects out of Geodatabases with little work. A basic workflow looks like this:
    
    d <- arc.open("path/file.gdb/layer_name")
    df <- arc.select(d) # here, you can filter columns and attributes, see [2]
    # create an sf object
    df.sf <- arc.data2sf(df)
    # alternatively, create an sp object
    df.sp <- arc.data2sp(df)
    
    You can also write the results back to a geodatabase, or any other format that ArcGIS understands. Another option is trying the SpatiaLite version of the data at the URL you posted. You should be able to access this using R directly, provided your rgdal installation is correctly built to read spatialite databases. If it is, try the same process you mentioned using rgdal, but point it at the SpatialLite database instead. You could also use command-line OGR to convert the data, that has a few options like where clause filtering that aren't directly available via readOGR.
    
    If neither of these options work, let me know and I can convert the data for you into a format of your preference.
    
    Cheers,
    Shaun
    
    1. https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_R-2DArcGIS_r-2Dbridge-2Dinstall&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=yckcjR6k3nADiVsNiAhGwcZB--0A8DQgvLSJ27upmyk&m=dkecE8PWOn5sSrtSXqX2R-VwJuFH_In4BvpC5da4LJ0&s=nRO2IG9dlrdKYGMSp3rCf7nwJqRFQoIWnY5zSFrPOQM&e=
    2. https://urldefense.proofpoint.com/v2/url?u=https-3A__rdrr.io_github_R-2DArcGIS_r-2Dbridge_man_arc.select.html&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=yckcjR6k3nADiVsNiAhGwcZB--0A8DQgvLSJ27upmyk&m=dkecE8PWOn5sSrtSXqX2R-VwJuFH_In4BvpC5da4LJ0&s=89N-cLe5N3dhZ6MTsM2OAYwmDImBH88ZrVaA5Hos0n4&e=
    
    
    
    On 5/2/18, 1:34 PM, "R-sig-Geo on behalf of Aguirre Perez, Roman" <r-sig-geo-bounces at r-project.org on behalf of ra454 at exeter.ac.uk> wrote:
    
        Hi everyone,
        
        I?ve been struggling with a ESRI Geodatabase file (clc12_Version_18_5.gdb) which is a layer of land cover classes available on
        
        https://urldefense.proofpoint.com/v2/url?u=https-3A__land.copernicus.eu_pan-2Deuropean_corine-2Dland-2Dcover_clc-2D2012-3Ftab-3Ddownload&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=9LaO4HiB5C5ewiuN_IeSQJSgq2tl5_-oMECPChtZa_U&e=
        
        whose size is 2.61 GB once unzipped.
        
        My ultimate task is to overlay it with the last NUTS3 administrative boundaries shapefile (2013) available on
        
        https://urldefense.proofpoint.com/v2/url?u=http-3A__ec.europa.eu_eurostat_web_gisco_geodata_reference-2Ddata_administrative-2Dunits-2Dstatistical-2Dunits&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=VExYSoR8FY_vhZaPNJpoOx0ZCZNMU9hMTtlGJZj2joU&e=
        
        in order to compute the area covered by each class within each NUTS3 region.
        
        Despite the ease of friendly software for performing this task, haven?t been capable of doing it - GRASS didn?t load the file as the log reports problems with the polygons, QGIS shows a warning regarding a specific object and ArcGIS got frozen. I guess it?s because the PC I used doesn?t have enough capacity. Unfortunately, I don?t have access to a more powerful one.
        
        Anyway, I decided to try with R -after all, I?ll perform my analysis with it. So I started exploring this GDB with rgdal:
        
        ogrInfo(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
        
        Source: "/Users/Roman/Desktop/clc12gdb/clc12_Version_18_5.gdb",
        layer: "clc12_Version_18_5"
        Driver: OpenFileGDB;
        number of rows: 2370829
        Feature type: wkbPolygon with 3 dimensions
        Extent: (-2693292 -3086662) - (10037210 5440568)
        Null geometry IDs: 2156240
        CRS: +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs
        Number of fields: 6
        name                      type  length  typeName
        1 code_12              4       3           String
        2 ID                         4       18         String
        3 Remark               4       20         String
        4 Area_Ha             2       0           Real
        5 Shape_Length   2       0           Real
        6 Shape_Area       2       0           Real
        
        Then I tried to load it typing
        
        clc<-readOGR(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
        
        After 3-5 minutes, it appears the following text:
        
        OGR data source with driver: OpenFileGDB
        Source: "/Users/Roman/Desktop/clc12shp/clc12_Version_18_5.gdb", layer: "clc12_Version_18_5"
        with 2370829 features
        It has 6 fields
        
        Unfortunately, after trying 5 times (each one took around 8 hours) I couldn?t get anything but the following messages:
        
        Warning messages:
        1: In readOGR(dsn = "clc12_Version_18_5.gdb", layer = "clc12_Version_18_5") :
        Dropping null geometries: 2156240
        2: In readOGR(dsn = "clc12_Version_18_5.gdb", layer = "clc12_Version_18_5") :
        Z-dimension discarded
        
        Could anyone advise me how to tackle it? I also would appreciate suggestions on how to work with geodatabases - it?s my first time I work with these kind of files so I don?t even know their structure.
        
        By the way, these are my computer and software specifications:
        
        MacBook Pro 2012
        Processor 2.6 GHz Intel Core i7
        Memory 16 GB DDR3
        R 3.5.0
        RStudio 1.1.447
        
        
        Best,
        Roman.
           
    
    


From Roger.Bivand at nhh.no  Thu May  3 13:26:14 2018
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 3 May 2018 13:26:14 +0200
Subject: [R-sig-Geo] Issues with a GDB file in R?
In-Reply-To: <A814689E-6CF5-404D-94FD-841FB832FFAB@exeter.ac.uk>
References: <13F59690-AB9E-40B2-B9F7-2474C9771F52@exeter.ac.uk>
 <AFA371A2-4A57-4038-AD9B-2A6C894E2A86@esri.com>
 <A814689E-6CF5-404D-94FD-841FB832FFAB@exeter.ac.uk>
Message-ID: <alpine.LFD.2.21.1805031321160.14684@reclus.nhh.no>

On Thu, 3 May 2018, Aguirre Perez, Roman wrote:

> Hello Shaun,
>
> Thanks a lot for replying and providing me alternative options.
>
>
> Unfortunately, I can't try both options anymore as I ran out of ArcGIS 
> due to I was using a university PC which is not available now (I 
> installed an ArcGIS trial version there), but I'll try it later. I also 
> failed on installing the sf package - I'll dig a bit more on it. 
> Nevertheless, I already downloaded the SpatialLite version so I'll try 
> the second option and I'll let you know how it goes.

I think Melanie got it right - the apparent extra detail and precision 
you'd get from vector-vector overlay is illusory, so going with geoTiff 
should get you there (you can check to see whether 100m resolution differs 
from 250m). The only reason to choose vector-vector would be that the 
Corine vector contains categories not represented in the raster version. 
Using raster also steps around the polygon deficiencies in the GDB (and 
probably SQLite) representations.

Roger

>
>
> Regards,
> Roman.
>
> ?On 02/05/2018, 18:53, "Shaun Walbridge" <SWalbridge at esri.com> wrote:
>
>    Hello Roman,
>
>    A couple of suggested options: You can try and use the arcgisbinding package [1] to pull the data directly into R via ArcGIS, as you mentioned you have ArcGIS available [presumably on Windows or in a VM]. It will access the data directly, and let you create sp and sf objects out of Geodatabases with little work. A basic workflow looks like this:
>
>    d <- arc.open("path/file.gdb/layer_name")
>    df <- arc.select(d) # here, you can filter columns and attributes, see [2]
>    # create an sf object
>    df.sf <- arc.data2sf(df)
>    # alternatively, create an sp object
>    df.sp <- arc.data2sp(df)
>
>    You can also write the results back to a geodatabase, or any other format that ArcGIS understands. Another option is trying the SpatiaLite version of the data at the URL you posted. You should be able to access this using R directly, provided your rgdal installation is correctly built to read spatialite databases. If it is, try the same process you mentioned using rgdal, but point it at the SpatialLite database instead. You could also use command-line OGR to convert the data, that has a few options like where clause filtering that aren't directly available via readOGR.
>
>    If neither of these options work, let me know and I can convert the data for you into a format of your preference.
>
>    Cheers,
>    Shaun
>
>    1. https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_R-2DArcGIS_r-2Dbridge-2Dinstall&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=yckcjR6k3nADiVsNiAhGwcZB--0A8DQgvLSJ27upmyk&m=dkecE8PWOn5sSrtSXqX2R-VwJuFH_In4BvpC5da4LJ0&s=nRO2IG9dlrdKYGMSp3rCf7nwJqRFQoIWnY5zSFrPOQM&e=
>    2. https://urldefense.proofpoint.com/v2/url?u=https-3A__rdrr.io_github_R-2DArcGIS_r-2Dbridge_man_arc.select.html&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=yckcjR6k3nADiVsNiAhGwcZB--0A8DQgvLSJ27upmyk&m=dkecE8PWOn5sSrtSXqX2R-VwJuFH_In4BvpC5da4LJ0&s=89N-cLe5N3dhZ6MTsM2OAYwmDImBH88ZrVaA5Hos0n4&e=
>
>
>
>    On 5/2/18, 1:34 PM, "R-sig-Geo on behalf of Aguirre Perez, Roman" <r-sig-geo-bounces at r-project.org on behalf of ra454 at exeter.ac.uk> wrote:
>
>        Hi everyone,
>
>        I?ve been struggling with a ESRI Geodatabase file (clc12_Version_18_5.gdb) which is a layer of land cover classes available on
>
>        https://urldefense.proofpoint.com/v2/url?u=https-3A__land.copernicus.eu_pan-2Deuropean_corine-2Dland-2Dcover_clc-2D2012-3Ftab-3Ddownload&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=9LaO4HiB5C5ewiuN_IeSQJSgq2tl5_-oMECPChtZa_U&e=
>
>        whose size is 2.61 GB once unzipped.
>
>        My ultimate task is to overlay it with the last NUTS3 administrative boundaries shapefile (2013) available on
>
>        https://urldefense.proofpoint.com/v2/url?u=http-3A__ec.europa.eu_eurostat_web_gisco_geodata_reference-2Ddata_administrative-2Dunits-2Dstatistical-2Dunits&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=VExYSoR8FY_vhZaPNJpoOx0ZCZNMU9hMTtlGJZj2joU&e=
>
>        in order to compute the area covered by each class within each NUTS3 region.
>
>        Despite the ease of friendly software for performing this task, haven?t been capable of doing it - GRASS didn?t load the file as the log reports problems with the polygons, QGIS shows a warning regarding a specific object and ArcGIS got frozen. I guess it?s because the PC I used doesn?t have enough capacity. Unfortunately, I don?t have access to a more powerful one.
>
>        Anyway, I decided to try with R -after all, I?ll perform my analysis with it. So I started exploring this GDB with rgdal:
>
>        ogrInfo(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
>
>        Source: "/Users/Roman/Desktop/clc12gdb/clc12_Version_18_5.gdb",
>        layer: "clc12_Version_18_5"
>        Driver: OpenFileGDB;
>        number of rows: 2370829
>        Feature type: wkbPolygon with 3 dimensions
>        Extent: (-2693292 -3086662) - (10037210 5440568)
>        Null geometry IDs: 2156240
>        CRS: +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs
>        Number of fields: 6
>        name                      type  length  typeName
>        1 code_12              4       3           String
>        2 ID                         4       18         String
>        3 Remark               4       20         String
>        4 Area_Ha             2       0           Real
>        5 Shape_Length   2       0           Real
>        6 Shape_Area       2       0           Real
>
>        Then I tried to load it typing
>
>        clc<-readOGR(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
>
>        After 3-5 minutes, it appears the following text:
>
>        OGR data source with driver: OpenFileGDB
>        Source: "/Users/Roman/Desktop/clc12shp/clc12_Version_18_5.gdb", layer: "clc12_Version_18_5"
>        with 2370829 features
>        It has 6 fields
>
>        Unfortunately, after trying 5 times (each one took around 8 hours) I couldn?t get anything but the following messages:
>
>        Warning messages:
>        1: In readOGR(dsn = "clc12_Version_18_5.gdb", layer = "clc12_Version_18_5") :
>        Dropping null geometries: 2156240
>        2: In readOGR(dsn = "clc12_Version_18_5.gdb", layer = "clc12_Version_18_5") :
>        Z-dimension discarded
>
>        Could anyone advise me how to tackle it? I also would appreciate suggestions on how to work with geodatabases - it?s my first time I work with these kind of files so I don?t even know their structure.
>
>        By the way, these are my computer and software specifications:
>
>        MacBook Pro 2012
>        Processor 2.6 GHz Intel Core i7
>        Memory 16 GB DDR3
>        R 3.5.0
>        RStudio 1.1.447
>
>
>        Best,
>        Roman.
>
>
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From russell.barbour at yale.edu  Thu May  3 14:34:02 2018
From: russell.barbour at yale.edu (Barbour, Russell)
Date: Thu, 3 May 2018 12:34:02 +0000
Subject: [R-sig-Geo] Issues with a GDB file in R?
In-Reply-To: <DM2PR04MB701F3C5077A53075B93F55FB9800@DM2PR04MB701.namprd04.prod.outlook.com>
References: <13F59690-AB9E-40B2-B9F7-2474C9771F52@exeter.ac.uk>
 <DM2PR04MB701F3C5077A53075B93F55FB9800@DM2PR04MB701.namprd04.prod.outlook.com>
Message-ID: <SN4PR0801MB374467DD5A4BA793BCDC51D086870@SN4PR0801MB3744.namprd08.prod.outlook.com>

Please unsubscribe me from this list

Russell ?Skip? Barbour Ph.D.
Associate  Director, 
Interdisciplinary Research Methods Core
Center for Interdisciplinary Research on AIDS 
Yale SCHOOL OF PUBLIC HEALTH
135 College Street, Suite 200, New Haven, CT 06510
Tel:203-764-4332 email:russel.lbarbour at yale.edu
http://cira.yale.edu/people/russell-barbour-phd 

?"You just think lovely wonderful thoughts," Peter explained, "and they lift you up in the air.?
Peter Pan teaching Wendy how to fly

-----Original Message-----
From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Cotton Rockwood
Sent: Wednesday, May 2, 2018 2:56 PM
To: Aguirre Perez, Roman <ra454 at exeter.ac.uk>; r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] Issues with a GDB file in R?

Hi Roman -

As far as I know, 'readOGR' does not read tables in file geodatabases. (see https://urldefense.proofpoint.com/v2/url?u=https-3A__gis.stackexchange.com_questions_184013_read-2Da-2Dtable-2Dfrom-2Dan-2Desri-2Dfile-2Dgeodatabase-2Dgdb-2Dusing-2Dr&d=DwIGaQ&c=cjytLXgP8ixuoHflwc-poQ&r=hqlhsfPkcleHC6lIU7H-PK6ab0cWjzsLSsRESstmcuM&m=AyJmViJgTgWrKjYVj6e7XUAt5NWdIU_UynXzlW-ynw8&s=VNhaJinb3W90c6yiWpvXy2FKFi0wRu2659-E_P-IGxo&e=). I'm guessing this is the problem you are running into with R. In addition to Sean's suggestions, you might also want to try using the 'sf' package since it can read file geodatabase tables and usually increases read times (and other spatial operations) significantly compared to 'sp' and 'readOGR'. I'm not sure if it will address the issues you seem to be having with the geometries as suggested by the GRASS, QGIS and ArcGIS errors. The specific 'sf' function is:

'st_read' and the syntax is very similar to 'readOGR'.  You will need to make sure you have the newest version: 0.6-1.

-Cotton



-----Original Message-----

From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Aguirre Perez, Roman

Sent: Wednesday, May 02, 2018 10:35 AM

To: r-sig-geo at r-project.org

Subject: [R-sig-Geo] Issues with a GDB file in R?



Hi everyone,



I?ve been struggling with a ESRI Geodatabase file (clc12_Version_18_5.gdb) which is a layer of land cover classes available on



https://urldefense.proofpoint.com/v2/url?u=https-3A__land.copernicus.eu_pan-2Deuropean_corine-2Dland-2Dcover_clc-2D2012-3Ftab-3Ddownload&d=DwIGaQ&c=cjytLXgP8ixuoHflwc-poQ&r=hqlhsfPkcleHC6lIU7H-PK6ab0cWjzsLSsRESstmcuM&m=AyJmViJgTgWrKjYVj6e7XUAt5NWdIU_UynXzlW-ynw8&s=0H4NNqQ2_ZV2e4VJgk6EsYBt8vnOIuiFqvfiVC1VdaQ&e=



whose size is 2.61 GB once unzipped.



My ultimate task is to overlay it with the last NUTS3 administrative boundaries shapefile (2013) available on



https://urldefense.proofpoint.com/v2/url?u=http-3A__ec.europa.eu_eurostat_web_gisco_geodata_reference-2Ddata_administrative-2Dunits-2Dstatistical-2Dunits&d=DwIGaQ&c=cjytLXgP8ixuoHflwc-poQ&r=hqlhsfPkcleHC6lIU7H-PK6ab0cWjzsLSsRESstmcuM&m=AyJmViJgTgWrKjYVj6e7XUAt5NWdIU_UynXzlW-ynw8&s=On4UScxpDq3FXH_zMMi-4oexQ73Bol0dfV6ELlj18co&e=



in order to compute the area covered by each class within each NUTS3 region.



Despite the ease of friendly software for performing this task, haven?t been capable of doing it - GRASS didn?t load the file as the log reports problems with the polygons, QGIS shows a warning regarding a specific object and ArcGIS got frozen. I guess it?s because the PC I used doesn?t have enough capacity. Unfortunately, I don?t have access to a more powerful one.



Anyway, I decided to try with R -after all, I?ll perform my analysis with it. So I started exploring this GDB with rgdal:



ogrInfo(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")



Source: "/Users/Roman/Desktop/clc12gdb/clc12_Version_18_5.gdb",

layer: "clc12_Version_18_5"

Driver: OpenFileGDB;

number of rows: 2370829

Feature type: wkbPolygon with 3 dimensions

Extent: (-2693292 -3086662) - (10037210 5440568) Null geometry IDs: 2156240

CRS: +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs Number of fields: 6

name                      type  length  typeName

1 code_12              4       3           String

2 ID                         4       18         String

3 Remark               4       20         String

4 Area_Ha             2       0           Real

5 Shape_Length   2       0           Real

6 Shape_Area       2       0           Real



Then I tried to load it typing



clc<-readOGR(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")



After 3-5 minutes, it appears the following text:



OGR data source with driver: OpenFileGDB

Source: "/Users/Roman/Desktop/clc12shp/clc12_Version_18_5.gdb", layer: "clc12_Version_18_5"

with 2370829 features

It has 6 fields



Unfortunately, after trying 5 times (each one took around 8 hours) I couldn?t get anything but the following messages:



Warning messages:

1: In readOGR(dsn = "clc12_Version_18_5.gdb", layer = "clc12_Version_18_5") :

Dropping null geometries: 2156240

2: In readOGR(dsn = "clc12_Version_18_5.gdb", layer = "clc12_Version_18_5") :

Z-dimension discarded



Could anyone advise me how to tackle it? I also would appreciate suggestions on how to work with geodatabases - it?s my first time I work with these kind of files so I don?t even know their structure.



By the way, these are my computer and software specifications:



MacBook Pro 2012

Processor 2.6 GHz Intel Core i7

Memory 16 GB DDR3

R 3.5.0

RStudio 1.1.447





Best,

Roman.



	[[alternative HTML version deleted]]



_______________________________________________

R-sig-Geo mailing list

R-sig-Geo at r-project.org

https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dsig-2Dgeo&d=DwIGaQ&c=cjytLXgP8ixuoHflwc-poQ&r=hqlhsfPkcleHC6lIU7H-PK6ab0cWjzsLSsRESstmcuM&m=AyJmViJgTgWrKjYVj6e7XUAt5NWdIU_UynXzlW-ynw8&s=pYHh6icaGQ-A3K8nOdCWGQyMRAFBs7p1a7SBozBPEfE&e=

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dsig-2Dgeo&d=DwIGaQ&c=cjytLXgP8ixuoHflwc-poQ&r=hqlhsfPkcleHC6lIU7H-PK6ab0cWjzsLSsRESstmcuM&m=AyJmViJgTgWrKjYVj6e7XUAt5NWdIU_UynXzlW-ynw8&s=pYHh6icaGQ-A3K8nOdCWGQyMRAFBs7p1a7SBozBPEfE&e=

From ra454 at exeter.ac.uk  Thu May  3 16:43:15 2018
From: ra454 at exeter.ac.uk (Aguirre Perez, Roman)
Date: Thu, 3 May 2018 14:43:15 +0000
Subject: [R-sig-Geo] Issues with a GDB file in R?
In-Reply-To: <alpine.LFD.2.21.1805031321160.14684@reclus.nhh.no>
References: <13F59690-AB9E-40B2-B9F7-2474C9771F52@exeter.ac.uk>
 <AFA371A2-4A57-4038-AD9B-2A6C894E2A86@esri.com>
 <A814689E-6CF5-404D-94FD-841FB832FFAB@exeter.ac.uk>
 <alpine.LFD.2.21.1805031321160.14684@reclus.nhh.no>
Message-ID: <977196B3-00A0-4D48-8E73-6AAF9988F1B1@exeter.ac.uk>

Hi again,

first of all, thanks a lot for your comments. It's becoming quite interesting how to perform this task with such amount of data. 


Here is an update...

Cotton, I could read the geodatabase by using the commands I shared. However, my R session crashed after overlaying it with a small set of polygons. I guess it was because the size of the sp object (around 14.5 GB). It's also worth mentioning that it was just a "multipolygon" (is that the correct word?) formed by 2370829 polygons. I haven?t succeeded on installing the sf package, but I will keep trying it. 

Melanie, I already downloaded and read the geoTiff version. At first sight, it seems that this object doesn?t have enough features as to perform the overlying. I might have a biased idea of how raster objects work - I'm too stick to the representation of shapefiles which sounds quite related with Roger's idea. So I will start to explore it in order to gain a bit more understanding on it.

Roger, I certainly need to know which category is associated with each CLC polygon in order to compute the area covered by each of these classes within each NUTS3 region. Therefore, I still need to use a vector-vector overlay, right?

I really appreciate any feedback in advance as well as details that I should take into account to understand more about how to work with this kind of data. I will also keep you up to date on how it goes if you like.


Best,
Roman.

?On 03/05/2018, 12:26, "Roger Bivand" <Roger.Bivand at nhh.no> wrote:

    On Thu, 3 May 2018, Aguirre Perez, Roman wrote:
    
    > Hello Shaun,
    >
    > Thanks a lot for replying and providing me alternative options.
    >
    >
    > Unfortunately, I can't try both options anymore as I ran out of ArcGIS 
    > due to I was using a university PC which is not available now (I 
    > installed an ArcGIS trial version there), but I'll try it later. I also 
    > failed on installing the sf package - I'll dig a bit more on it. 
    > Nevertheless, I already downloaded the SpatialLite version so I'll try 
    > the second option and I'll let you know how it goes.
    
    I think Melanie got it right - the apparent extra detail and precision 
    you'd get from vector-vector overlay is illusory, so going with geoTiff 
    should get you there (you can check to see whether 100m resolution differs 
    from 250m). The only reason to choose vector-vector would be that the 
    Corine vector contains categories not represented in the raster version. 
    Using raster also steps around the polygon deficiencies in the GDB (and 
    probably SQLite) representations.
    
    Roger
    
    >
    >
    > Regards,
    > Roman.
    >
    > On 02/05/2018, 18:53, "Shaun Walbridge" <SWalbridge at esri.com> wrote:
    >
    >    Hello Roman,
    >
    >    A couple of suggested options: You can try and use the arcgisbinding package [1] to pull the data directly into R via ArcGIS, as you mentioned you have ArcGIS available [presumably on Windows or in a VM]. It will access the data directly, and let you create sp and sf objects out of Geodatabases with little work. A basic workflow looks like this:
    >
    >    d <- arc.open("path/file.gdb/layer_name")
    >    df <- arc.select(d) # here, you can filter columns and attributes, see [2]
    >    # create an sf object
    >    df.sf <- arc.data2sf(df)
    >    # alternatively, create an sp object
    >    df.sp <- arc.data2sp(df)
    >
    >    You can also write the results back to a geodatabase, or any other format that ArcGIS understands. Another option is trying the SpatiaLite version of the data at the URL you posted. You should be able to access this using R directly, provided your rgdal installation is correctly built to read spatialite databases. If it is, try the same process you mentioned using rgdal, but point it at the SpatialLite database instead. You could also use command-line OGR to convert the data, that has a few options like where clause filtering that aren't directly available via readOGR.
    >
    >    If neither of these options work, let me know and I can convert the data for you into a format of your preference.
    >
    >    Cheers,
    >    Shaun
    >
    >    1. https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_R-2DArcGIS_r-2Dbridge-2Dinstall&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=yckcjR6k3nADiVsNiAhGwcZB--0A8DQgvLSJ27upmyk&m=dkecE8PWOn5sSrtSXqX2R-VwJuFH_In4BvpC5da4LJ0&s=nRO2IG9dlrdKYGMSp3rCf7nwJqRFQoIWnY5zSFrPOQM&e=
    >    2. https://urldefense.proofpoint.com/v2/url?u=https-3A__rdrr.io_github_R-2DArcGIS_r-2Dbridge_man_arc.select.html&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=yckcjR6k3nADiVsNiAhGwcZB--0A8DQgvLSJ27upmyk&m=dkecE8PWOn5sSrtSXqX2R-VwJuFH_In4BvpC5da4LJ0&s=89N-cLe5N3dhZ6MTsM2OAYwmDImBH88ZrVaA5Hos0n4&e=
    >
    >
    >
    >    On 5/2/18, 1:34 PM, "R-sig-Geo on behalf of Aguirre Perez, Roman" <r-sig-geo-bounces at r-project.org on behalf of ra454 at exeter.ac.uk> wrote:
    >
    >        Hi everyone,
    >
    >        I?ve been struggling with a ESRI Geodatabase file (clc12_Version_18_5.gdb) which is a layer of land cover classes available on
    >
    >        https://urldefense.proofpoint.com/v2/url?u=https-3A__land.copernicus.eu_pan-2Deuropean_corine-2Dland-2Dcover_clc-2D2012-3Ftab-3Ddownload&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=9LaO4HiB5C5ewiuN_IeSQJSgq2tl5_-oMECPChtZa_U&e=
    >
    >        whose size is 2.61 GB once unzipped.
    >
    >        My ultimate task is to overlay it with the last NUTS3 administrative boundaries shapefile (2013) available on
    >
    >        https://urldefense.proofpoint.com/v2/url?u=http-3A__ec.europa.eu_eurostat_web_gisco_geodata_reference-2Ddata_administrative-2Dunits-2Dstatistical-2Dunits&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=VExYSoR8FY_vhZaPNJpoOx0ZCZNMU9hMTtlGJZj2joU&e=
    >
    >        in order to compute the area covered by each class within each NUTS3 region.
    >
    >        Despite the ease of friendly software for performing this task, haven?t been capable of doing it - GRASS didn?t load the file as the log reports problems with the polygons, QGIS shows a warning regarding a specific object and ArcGIS got frozen. I guess it?s because the PC I used doesn?t have enough capacity. Unfortunately, I don?t have access to a more powerful one.
    >
    >        Anyway, I decided to try with R -after all, I?ll perform my analysis with it. So I started exploring this GDB with rgdal:
    >
    >        ogrInfo(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
    >
    >        Source: "/Users/Roman/Desktop/clc12gdb/clc12_Version_18_5.gdb",
    >        layer: "clc12_Version_18_5"
    >        Driver: OpenFileGDB;
    >        number of rows: 2370829
    >        Feature type: wkbPolygon with 3 dimensions
    >        Extent: (-2693292 -3086662) - (10037210 5440568)
    >        Null geometry IDs: 2156240
    >        CRS: +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs
    >        Number of fields: 6
    >        name                      type  length  typeName
    >        1 code_12              4       3           String
    >        2 ID                         4       18         String
    >        3 Remark               4       20         String
    >        4 Area_Ha             2       0           Real
    >        5 Shape_Length   2       0           Real
    >        6 Shape_Area       2       0           Real
    >
    >        Then I tried to load it typing
    >
    >        clc<-readOGR(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
    >
    >        After 3-5 minutes, it appears the following text:
    >
    >        OGR data source with driver: OpenFileGDB
    >        Source: "/Users/Roman/Desktop/clc12shp/clc12_Version_18_5.gdb", layer: "clc12_Version_18_5"
    >        with 2370829 features
    >        It has 6 fields
    >
    >        Unfortunately, after trying 5 times (each one took around 8 hours) I couldn?t get anything but the following messages:
    >
    >        Warning messages:
    >        1: In readOGR(dsn = "clc12_Version_18_5.gdb", layer = "clc12_Version_18_5") :
    >        Dropping null geometries: 2156240
    >        2: In readOGR(dsn = "clc12_Version_18_5.gdb", layer = "clc12_Version_18_5") :
    >        Z-dimension discarded
    >
    >        Could anyone advise me how to tackle it? I also would appreciate suggestions on how to work with geodatabases - it?s my first time I work with these kind of files so I don?t even know their structure.
    >
    >        By the way, these are my computer and software specifications:
    >
    >        MacBook Pro 2012
    >        Processor 2.6 GHz Intel Core i7
    >        Memory 16 GB DDR3
    >        R 3.5.0
    >        RStudio 1.1.447
    >
    >
    >        Best,
    >        Roman.
    >
    >
    >
    >
    > _______________________________________________
    > R-sig-Geo mailing list
    > R-sig-Geo at r-project.org
    > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
    
    -- 
    Roger Bivand
    Department of Economics, Norwegian School of Economics,
    Helleveien 30, N-5045 Bergen, Norway.
    voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
    http://orcid.org/0000-0003-2392-6140
    https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From Roger.Bivand at nhh.no  Thu May  3 21:18:57 2018
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 3 May 2018 21:18:57 +0200
Subject: [R-sig-Geo] Issues with a GDB file in R?
In-Reply-To: <977196B3-00A0-4D48-8E73-6AAF9988F1B1@exeter.ac.uk>
References: <13F59690-AB9E-40B2-B9F7-2474C9771F52@exeter.ac.uk>
 <AFA371A2-4A57-4038-AD9B-2A6C894E2A86@esri.com>
 <A814689E-6CF5-404D-94FD-841FB832FFAB@exeter.ac.uk>
 <alpine.LFD.2.21.1805031321160.14684@reclus.nhh.no>
 <977196B3-00A0-4D48-8E73-6AAF9988F1B1@exeter.ac.uk>
Message-ID: <alpine.LFD.2.21.1805032014310.22459@reclus.nhh.no>

On Thu, 3 May 2018, Aguirre Perez, Roman wrote:

> Hi again,
>
> first of all, thanks a lot for your comments. It's becoming quite 
> interesting how to perform this task with such amount of data.
>
>
> Here is an update...
>
> Cotton, I could read the geodatabase by using the commands I shared. 
> However, my R session crashed after overlaying it with a small set of 
> polygons. I guess it was because the size of the sp object (around 14.5 
> GB). It's also worth mentioning that it was just a "multipolygon" (is 
> that the correct word?) formed by 2370829 polygons. I haven?t succeeded 
> on installing the sf package, but I will keep trying it.
>
> Melanie, I already downloaded and read the geoTiff version. At first 
> sight, it seems that this object doesn?t have enough features as to 
> perform the overlying. I might have a biased idea of how raster objects 
> work - I'm too stick to the representation of shapefiles which sounds 
> quite related with Roger's idea. So I will start to explore it in order 
> to gain a bit more understanding on it.
>
> Roger, I certainly need to know which category is associated with each 
> CLC polygon in order to compute the area covered by each of these 
> classes within each NUTS3 region. Therefore, I still need to use a 
> vector-vector overlay, right?

On the contrary. The geoTiffs are coded as described in the documentation. 
Your output is simply the count of raster cells by NUTS3 for each of the 
categories. The geoTiff is in ETRS_1989_LAEA, so is projected; it includes 
a lot of sea and no data because of the French overseas territories.

You could possibly use PostGIS to do the intersections, or use GRASS for 
raster-vector counts (say through rgrass7). In R, you would want to add a 
NUTS3 ID band to the land cover raster, then aggregate by NUTS3 ID.

I would suggest using GRASS as the most obvious route, reading the raster, 
reading the NUTS3 boundaries into a separate location, projecting to LAEA, 
then rasterising the NUTS3 regions (v.to.rast) and running r.cross. You 
get 32K output categories, the 48 corine categories times the count of 
NUTS3 regions minus the nulls (there aren't many glaciers in most 
regions). You'll then need to match back the Corine codes and the NUTS3 
codes - see in the category label file shown by r.category.

I'll try to provide code tomorrow.

Roger

>
> I really appreciate any feedback in advance as well as details that I 
> should take into account to understand more about how to work with this 
> kind of data. I will also keep you up to date on how it goes if you 
> like.
>
>
> Best,
> Roman.
>
> ?On 03/05/2018, 12:26, "Roger Bivand" <Roger.Bivand at nhh.no> wrote:
>
>    On Thu, 3 May 2018, Aguirre Perez, Roman wrote:
>
>    > Hello Shaun,
>    >
>    > Thanks a lot for replying and providing me alternative options.
>    >
>    >
>    > Unfortunately, I can't try both options anymore as I ran out of ArcGIS
>    > due to I was using a university PC which is not available now (I
>    > installed an ArcGIS trial version there), but I'll try it later. I also
>    > failed on installing the sf package - I'll dig a bit more on it.
>    > Nevertheless, I already downloaded the SpatialLite version so I'll try
>    > the second option and I'll let you know how it goes.
>
>    I think Melanie got it right - the apparent extra detail and precision
>    you'd get from vector-vector overlay is illusory, so going with geoTiff
>    should get you there (you can check to see whether 100m resolution differs
>    from 250m). The only reason to choose vector-vector would be that the
>    Corine vector contains categories not represented in the raster version.
>    Using raster also steps around the polygon deficiencies in the GDB (and
>    probably SQLite) representations.
>
>    Roger
>
>    >
>    >
>    > Regards,
>    > Roman.
>    >
>    > On 02/05/2018, 18:53, "Shaun Walbridge" <SWalbridge at esri.com> wrote:
>    >
>    >    Hello Roman,
>    >
>    >    A couple of suggested options: You can try and use the arcgisbinding package [1] to pull the data directly into R via ArcGIS, as you mentioned you have ArcGIS available [presumably on Windows or in a VM]. It will access the data directly, and let you create sp and sf objects out of Geodatabases with little work. A basic workflow looks like this:
>    >
>    >    d <- arc.open("path/file.gdb/layer_name")
>    >    df <- arc.select(d) # here, you can filter columns and attributes, see [2]
>    >    # create an sf object
>    >    df.sf <- arc.data2sf(df)
>    >    # alternatively, create an sp object
>    >    df.sp <- arc.data2sp(df)
>    >
>    >    You can also write the results back to a geodatabase, or any other format that ArcGIS understands. Another option is trying the SpatiaLite version of the data at the URL you posted. You should be able to access this using R directly, provided your rgdal installation is correctly built to read spatialite databases. If it is, try the same process you mentioned using rgdal, but point it at the SpatialLite database instead. You could also use command-line OGR to convert the data, that has a few options like where clause filtering that aren't directly available via readOGR.
>    >
>    >    If neither of these options work, let me know and I can convert the data for you into a format of your preference.
>    >
>    >    Cheers,
>    >    Shaun
>    >
>    >    1. https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_R-2DArcGIS_r-2Dbridge-2Dinstall&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=yckcjR6k3nADiVsNiAhGwcZB--0A8DQgvLSJ27upmyk&m=dkecE8PWOn5sSrtSXqX2R-VwJuFH_In4BvpC5da4LJ0&s=nRO2IG9dlrdKYGMSp3rCf7nwJqRFQoIWnY5zSFrPOQM&e=
>    >    2. https://urldefense.proofpoint.com/v2/url?u=https-3A__rdrr.io_github_R-2DArcGIS_r-2Dbridge_man_arc.select.html&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=yckcjR6k3nADiVsNiAhGwcZB--0A8DQgvLSJ27upmyk&m=dkecE8PWOn5sSrtSXqX2R-VwJuFH_In4BvpC5da4LJ0&s=89N-cLe5N3dhZ6MTsM2OAYwmDImBH88ZrVaA5Hos0n4&e=
>    >
>    >
>    >
>    >    On 5/2/18, 1:34 PM, "R-sig-Geo on behalf of Aguirre Perez, Roman" <r-sig-geo-bounces at r-project.org on behalf of ra454 at exeter.ac.uk> wrote:
>    >
>    >        Hi everyone,
>    >
>    >        I?ve been struggling with a ESRI Geodatabase file (clc12_Version_18_5.gdb) which is a layer of land cover classes available on
>    >
>    >        https://urldefense.proofpoint.com/v2/url?u=https-3A__land.copernicus.eu_pan-2Deuropean_corine-2Dland-2Dcover_clc-2D2012-3Ftab-3Ddownload&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=9LaO4HiB5C5ewiuN_IeSQJSgq2tl5_-oMECPChtZa_U&e=
>    >
>    >        whose size is 2.61 GB once unzipped.
>    >
>    >        My ultimate task is to overlay it with the last NUTS3 administrative boundaries shapefile (2013) available on
>    >
>    >        https://urldefense.proofpoint.com/v2/url?u=http-3A__ec.europa.eu_eurostat_web_gisco_geodata_reference-2Ddata_administrative-2Dunits-2Dstatistical-2Dunits&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=VExYSoR8FY_vhZaPNJpoOx0ZCZNMU9hMTtlGJZj2joU&e=
>    >
>    >        in order to compute the area covered by each class within each NUTS3 region.
>    >
>    >        Despite the ease of friendly software for performing this task, haven?t been capable of doing it - GRASS didn?t load the file as the log reports problems with the polygons, QGIS shows a warning regarding a specific object and ArcGIS got frozen. I guess it?s because the PC I used doesn?t have enough capacity. Unfortunately, I don?t have access to a more powerful one.
>    >
>    >        Anyway, I decided to try with R -after all, I?ll perform my analysis with it. So I started exploring this GDB with rgdal:
>    >
>    >        ogrInfo(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
>    >
>    >        Source: "/Users/Roman/Desktop/clc12gdb/clc12_Version_18_5.gdb",
>    >        layer: "clc12_Version_18_5"
>    >        Driver: OpenFileGDB;
>    >        number of rows: 2370829
>    >        Feature type: wkbPolygon with 3 dimensions
>    >        Extent: (-2693292 -3086662) - (10037210 5440568)
>    >        Null geometry IDs: 2156240
>    >        CRS: +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs
>    >        Number of fields: 6
>    >        name                      type  length  typeName
>    >        1 code_12              4       3           String
>    >        2 ID                         4       18         String
>    >        3 Remark               4       20         String
>    >        4 Area_Ha             2       0           Real
>    >        5 Shape_Length   2       0           Real
>    >        6 Shape_Area       2       0           Real
>    >
>    >        Then I tried to load it typing
>    >
>    >        clc<-readOGR(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
>    >
>    >        After 3-5 minutes, it appears the following text:
>    >
>    >        OGR data source with driver: OpenFileGDB
>    >        Source: "/Users/Roman/Desktop/clc12shp/clc12_Version_18_5.gdb", layer: "clc12_Version_18_5"
>    >        with 2370829 features
>    >        It has 6 fields
>    >
>    >        Unfortunately, after trying 5 times (each one took around 8 hours) I couldn?t get anything but the following messages:
>    >
>    >        Warning messages:
>    >        1: In readOGR(dsn = "clc12_Version_18_5.gdb", layer = "clc12_Version_18_5") :
>    >        Dropping null geometries: 2156240
>    >        2: In readOGR(dsn = "clc12_Version_18_5.gdb", layer = "clc12_Version_18_5") :
>    >        Z-dimension discarded
>    >
>    >        Could anyone advise me how to tackle it? I also would appreciate suggestions on how to work with geodatabases - it?s my first time I work with these kind of files so I don?t even know their structure.
>    >
>    >        By the way, these are my computer and software specifications:
>    >
>    >        MacBook Pro 2012
>    >        Processor 2.6 GHz Intel Core i7
>    >        Memory 16 GB DDR3
>    >        R 3.5.0
>    >        RStudio 1.1.447
>    >
>    >
>    >        Best,
>    >        Roman.
>    >
>    >
>    >
>    >
>    > _______________________________________________
>    > R-sig-Geo mailing list
>    > R-sig-Geo at r-project.org
>    > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>    --
>    Roger Bivand
>    Department of Economics, Norwegian School of Economics,
>    Helleveien 30, N-5045 Bergen, Norway.
>    voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>    http://orcid.org/0000-0003-2392-6140
>    https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From saiku142 at gmail.com  Fri May  4 20:05:46 2018
From: saiku142 at gmail.com (Surya Kr)
Date: Fri, 04 May 2018 18:05:46 +0000
Subject: [R-sig-Geo] Spatial correlation in large data sets
Message-ID: <CAJR1vXWmLE=pxtu9k3bbHTDv8qr=OCofv9OD_20SpfNe37Y0qQ@mail.gmail.com>

Dear Fellow Members,

I have a data set consisting of 1000+ variables, each having
spatio-temporal data. I want to access and filter the variables that show
evidence of spatial patterns so that I can model spatial behavior
accordingly.

For a univariate spatial data, one could plot empirical variograms and
visually assess the presence of spatial pattern in the data. I don't have
that luxury with 1000+ variables. What is your suggestion to do this in an
automated fashion? I'm thinking calculating a spatial correlation measure
like Moran's I for each variable and at each time point and assess by
summarizing appropriately. What are my alternatives?

Appreciate your time.
- Surya


From Roger.Bivand at nhh.no  Fri May  4 21:20:36 2018
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 4 May 2018 21:20:36 +0200
Subject: [R-sig-Geo] Issues with a GDB file in R?
In-Reply-To: <alpine.LFD.2.21.1805032014310.22459@reclus.nhh.no>
References: <13F59690-AB9E-40B2-B9F7-2474C9771F52@exeter.ac.uk>
 <AFA371A2-4A57-4038-AD9B-2A6C894E2A86@esri.com>
 <A814689E-6CF5-404D-94FD-841FB832FFAB@exeter.ac.uk>
 <alpine.LFD.2.21.1805031321160.14684@reclus.nhh.no>
 <977196B3-00A0-4D48-8E73-6AAF9988F1B1@exeter.ac.uk>
 <alpine.LFD.2.21.1805032014310.22459@reclus.nhh.no>
Message-ID: <alpine.LFD.2.21.1805042035570.16297@reclus.nhh.no>

On Thu, 3 May 2018, Roger Bivand wrote:

> On Thu, 3 May 2018, Aguirre Perez, Roman wrote:
>
>>  Hi again,
>>
>>  first of all, thanks a lot for your comments. It's becoming quite
>>  interesting how to perform this task with such amount of data.
>> 
>>
>>  Here is an update...
>>
>>  Cotton, I could read the geodatabase by using the commands I shared.
>>  However, my R session crashed after overlaying it with a small set of
>>  polygons. I guess it was because the size of the sp object (around 14.5
>>  GB). It's also worth mentioning that it was just a "multipolygon" (is that
>>  the correct word?) formed by 2370829 polygons. I haven?t succeeded on
>>  installing the sf package, but I will keep trying it.
>>
>>  Melanie, I already downloaded and read the geoTiff version. At first
>>  sight, it seems that this object doesn?t have enough features as to
>>  perform the overlying. I might have a biased idea of how raster objects
>>  work - I'm too stick to the representation of shapefiles which sounds
>>  quite related with Roger's idea. So I will start to explore it in order to
>>  gain a bit more understanding on it.
>>
>>  Roger, I certainly need to know which category is associated with each CLC
>>  polygon in order to compute the area covered by each of these classes
>>  within each NUTS3 region. Therefore, I still need to use a vector-vector
>>  overlay, right?
>
> On the contrary. The geoTiffs are coded as described in the documentation. 
> Your output is simply the count of raster cells by NUTS3 for each of the 
> categories. The geoTiff is in ETRS_1989_LAEA, so is projected; it includes a 
> lot of sea and no data because of the French overseas territories.
>
> You could possibly use PostGIS to do the intersections, or use GRASS for 
> raster-vector counts (say through rgrass7). In R, you would want to add a 
> NUTS3 ID band to the land cover raster, then aggregate by NUTS3 ID.
>
> I would suggest using GRASS as the most obvious route, reading the raster, 
> reading the NUTS3 boundaries into a separate location, projecting to LAEA, 
> then rasterising the NUTS3 regions (v.to.rast) and running r.cross. You get 
> 32K output categories, the 48 corine categories times the count of NUTS3 
> regions minus the nulls (there aren't many glaciers in most regions). You'll 
> then need to match back the Corine codes and the NUTS3 codes - see in the 
> category label file shown by r.category.
>
> I'll try to provide code tomorrow.

Combining R and GRASS seems to work, but no guarantees.

library(sp)
library(rgdal)
Gi <- GDALinfo("g250_clc12_V18_5.tif")
makeSG <- function(x) {
   stopifnot(class(x) == "GDALobj")
   p4 <- attr(x, "projection")
   gt <- GridTopology(c(x[4]+(x[6]/2), x[5]+(x[7]/2)), c(x[6], x[7]),
     c(x[2], x[1]))
   SpatialGrid(gt, CRS(p4))
}
SG <- makeSG(Gi)
nuts_ll <- readOGR("NUTS_RG_01M_2013_4326_LEVL_3.shp")
nuts_laea <- spTransform(nuts_ll, CRS(attr(Gi, "projection")))
library(rgrass7)
td <- tempdir()
iG <- initGRASS("/home/rsb/topics/grass/g740/grass-7.4.0", td, SG)
# your GRASS will be where you installed it
writeVECT(nuts_laea, "nuts", v.in.ogr_flags="o")
execGRASS("r.in.gdal", input="g250_clc12_V18_5.tif", output="corine",
   flags="o")
execGRASS("v.to.rast", input="nuts", output="nuts3", use="cat",
   label_column="FID")
execGRASS("r.cross", input="nuts3,corine", output="cross_nuts3")
r_stats0 <- execGRASS("r.stats", input="cross_nuts3", flags="a",
   intern=TRUE)
r_stats1 <- gsub("\\*", "NA", r_stats0)
con_stats <- textConnection(r_stats1)
stats <- read.table(con_stats, header=FALSE, col.names=c("cross_cat",
   "area"), colClasses=c("integer", "numeric"))
close(con_stats)
r_cats0 <- execGRASS("r.category", map="cross_nuts3", intern=TRUE)
r_cats1 <- gsub(";", "", r_cats0)
r_cats2 <- gsub("\t", " ", r_cats1)
r_cats3 <- gsub("no data", "no_data", r_cats2)
r_cats4 <- gsub("category ", "", r_cats3)
r_cats4[1] <- paste0(r_cats4[1], "NA NA")
r_cats_split <- strsplit(r_cats4, " ")
cats <- data.frame(cross_cat=as.integer(sapply(r_cats_split, "[", 1)),
   nuts=sapply(r_cats_split, "[", 2),
   corine=as.integer(sapply(r_cats_split, "[", 3)))
catstats <- merge(cats, stats, by="cross_cat", all=TRUE)
agg_areas <- tapply(catstats$area, list(catstats$nuts, catstats$corine),
   sum)
library(foreign)
corine_labels <- read.dbf("g250_clc12_V18_5.tif.vat.dbf", as.is=TRUE)
o <- match(colnames(agg_areas), as.character(corine_labels$Value))
colnames(agg_areas) <- corine_labels$LABEL3[o]
agg_areas_df <- as.data.frame(agg_areas)
agg_areas_df1 <- agg_areas_df[-which(!(row.names(agg_areas_df) %in%
   as.character(nuts_ll$FID))),] # dropping "NA"      "no_data"

This should be ready to merge with the NUTS3 boundaries, if needed.

agg_areas_df1$FID <- row.names(agg_areas_df1)
nuts_corine <- merge(nuts_laea, agg_areas_df1, by="FID")

For the vector parts you could use sf and the provisional rgrass7sf on 
github, but that wouldn't yet let you construct a skeleton SpatialGrid to 
define the GRASS location. Using GRASS for the heavy lifting (the raster 
is 51000 by 35000), and avoiding vector for overlay, this doesn't need 
much memory (GRASS handles rasters by row). The GRASS temporary location 
only takes 130MB of disk space. You could go for the 100m raster 
resolution, but I doubt that the outcome would vary much - anyone like to 
try?

If the sub-polygons by NUTS and corine categories are actually needed, the 
output of r.cross could be passed to r.to.vect:

execGRASS("r.to.vect", input="cross_nuts3", output="cross_nuts3",
   type="area")

but this is more demanding in memory terms.

Interesting case, and it does show that combining GIS and R delivers the 
goods - SAGA would probably work equivalently.

Roger

>
> Roger
>
>>
>>  I really appreciate any feedback in advance as well as details that I
>>  should take into account to understand more about how to work with this
>>  kind of data. I will also keep you up to date on how it goes if you like.
>> 
>>
>>  Best,
>>  Roman.
>>
>>  ?On 03/05/2018, 12:26, "Roger Bivand" <Roger.Bivand at nhh.no> wrote:
>>
>>     On Thu, 3 May 2018, Aguirre Perez, Roman wrote:
>>
>>    >  Hello Shaun,
>>    >
>>    >  Thanks a lot for replying and providing me alternative options.
>>    >
>>    >
>>    >  Unfortunately, I can't try both options anymore as I ran out of
>>    >  ArcGIS
>>    >  due to I was using a university PC which is not available now (I
>>    >  installed an ArcGIS trial version there), but I'll try it later. I
>>    >  also
>>    >  failed on installing the sf package - I'll dig a bit more on it.
>>    >  Nevertheless, I already downloaded the SpatialLite version so I'll
>>    >  try
>>    >  the second option and I'll let you know how it goes.
>>
>>     I think Melanie got it right - the apparent extra detail and precision
>>     you'd get from vector-vector overlay is illusory, so going with geoTiff
>>     should get you there (you can check to see whether 100m resolution
>>     differs
>>     from 250m). The only reason to choose vector-vector would be that the
>>     Corine vector contains categories not represented in the raster
>>     version.
>>     Using raster also steps around the polygon deficiencies in the GDB (and
>>     probably SQLite) representations.
>>
>>     Roger
>>
>>    >
>>    >
>>    >  Regards,
>>    >  Roman.
>>    >
>>    >  On 02/05/2018, 18:53, "Shaun Walbridge" <SWalbridge at esri.com> wrote:
>>    >
>>    >     Hello Roman,
>>    >
>>    >     A couple of suggested options: You can try and use the
>>    >     arcgisbinding package [1] to pull the data directly into R via
>>    >     ArcGIS, as you mentioned you have ArcGIS available [presumably on
>>    >     Windows or in a VM]. It will access the data directly, and let you
>>    >     create sp and sf objects out of Geodatabases with little work. A
>>    >     basic workflow looks like this:
>>    >
>>    >     d <- arc.open("path/file.gdb/layer_name")
>>    >     df <- arc.select(d) # here, you can filter columns and attributes,
>>    >     see [2]
>>    >     # create an sf object
>>    >     df.sf <- arc.data2sf(df)
>>    >     # alternatively, create an sp object
>>    >     df.sp <- arc.data2sp(df)
>>    >
>>    >     You can also write the results back to a geodatabase, or any other
>>    >     format that ArcGIS understands. Another option is trying the
>>    >     SpatiaLite version of the data at the URL you posted. You should
>>    >     be able to access this using R directly, provided your rgdal
>>    >     installation is correctly built to read spatialite databases. If
>>    >     it is, try the same process you mentioned using rgdal, but point
>>    >     it at the SpatialLite database instead. You could also use
>>    >     command-line OGR to convert the data, that has a few options like
>>    >     where clause filtering that aren't directly available via readOGR.
>>    >
>>    >     If neither of these options work, let me know and I can convert
>>    >     the data for you into a format of your preference.
>>    >
>>    >     Cheers,
>>    >     Shaun
>>    >
>>    >     1.
>>    >     https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_R-2DArcGIS_r-2Dbridge-2Dinstall&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=yckcjR6k3nADiVsNiAhGwcZB--0A8DQgvLSJ27upmyk&m=dkecE8PWOn5sSrtSXqX2R-VwJuFH_In4BvpC5da4LJ0&s=nRO2IG9dlrdKYGMSp3rCf7nwJqRFQoIWnY5zSFrPOQM&e=
>>    >     2.
>>    >     https://urldefense.proofpoint.com/v2/url?u=https-3A__rdrr.io_github_R-2DArcGIS_r-2Dbridge_man_arc.select.html&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=yckcjR6k3nADiVsNiAhGwcZB--0A8DQgvLSJ27upmyk&m=dkecE8PWOn5sSrtSXqX2R-VwJuFH_In4BvpC5da4LJ0&s=89N-cLe5N3dhZ6MTsM2OAYwmDImBH88ZrVaA5Hos0n4&e=
>>    >
>>    >
>>    >
>>    >     On 5/2/18, 1:34 PM, "R-sig-Geo on behalf of Aguirre Perez, Roman"
>>    >     <r-sig-geo-bounces at r-project.org on behalf of ra454 at exeter.ac.uk>
>>    >     wrote:
>>    >
>>    >         Hi everyone,
>>    >
>>    >         I?ve been struggling with a ESRI Geodatabase file
>>    >         (clc12_Version_18_5.gdb) which is a layer of land cover
>>    >         classes available on
>>    >
>>    >         https://urldefense.proofpoint.com/v2/url?u=https-3A__land.copernicus.eu_pan-2Deuropean_corine-2Dland-2Dcover_clc-2D2012-3Ftab-3Ddownload&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=9LaO4HiB5C5ewiuN_IeSQJSgq2tl5_-oMECPChtZa_U&e=
>>    >
>>    >         whose size is 2.61 GB once unzipped.
>>    >
>>    >         My ultimate task is to overlay it with the last NUTS3
>>    >         administrative boundaries shapefile (2013) available on
>>    >
>>    >         https://urldefense.proofpoint.com/v2/url?u=http-3A__ec.europa.eu_eurostat_web_gisco_geodata_reference-2Ddata_administrative-2Dunits-2Dstatistical-2Dunits&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=VExYSoR8FY_vhZaPNJpoOx0ZCZNMU9hMTtlGJZj2joU&e=
>>    >
>>    >         in order to compute the area covered by each class within each
>>    >         NUTS3 region.
>>    >
>>    >         Despite the ease of friendly software for performing this
>>    >         task, haven?t been capable of doing it - GRASS didn?t load the
>>    >         file as the log reports problems with the polygons, QGIS shows
>>    >         a warning regarding a specific object and ArcGIS got frozen. I
>>    >         guess it?s because the PC I used doesn?t have enough capacity.
>>    >         Unfortunately, I don?t have access to a more powerful one.
>>    >
>>    >         Anyway, I decided to try with R -after all, I?ll perform my
>>    >         analysis with it. So I started exploring this GDB with rgdal:
>>    >
>>    >         ogrInfo(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
>>    >
>>    >         Source:
>>    >         "/Users/Roman/Desktop/clc12gdb/clc12_Version_18_5.gdb",
>>    >         layer: "clc12_Version_18_5"
>>    >         Driver: OpenFileGDB;
>>    >         number of rows: 2370829
>>    >         Feature type: wkbPolygon with 3 dimensions
>>    >         Extent: (-2693292 -3086662) - (10037210 5440568)
>>    >         Null geometry IDs: 2156240
>>    >         CRS: +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000
>>    >         +ellps=GRS80 +units=m +no_defs
>>    >         Number of fields: 6
>>    >         name                      type  length  typeName
>>    >         1 code_12              4       3           String
>>    >         2 ID                         4       18         String
>>    >         3 Remark               4       20         String
>>    >         4 Area_Ha             2       0           Real
>>    >         5 Shape_Length   2       0           Real
>>    >         6 Shape_Area       2       0           Real
>>    >
>>    >         Then I tried to load it typing
>>    >
>>    >         clc<-readOGR(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
>>    >
>>    >         After 3-5 minutes, it appears the following text:
>>    >
>>    >         OGR data source with driver: OpenFileGDB
>>    >         Source:
>>    >         "/Users/Roman/Desktop/clc12shp/clc12_Version_18_5.gdb", layer:
>>    >         "clc12_Version_18_5"
>>    >         with 2370829 features
>>    >         It has 6 fields
>>    >
>>    >         Unfortunately, after trying 5 times (each one took around 8
>>    >         hours) I couldn?t get anything but the following messages:
>>    >
>>    >         Warning messages:
>>    >         1: In readOGR(dsn = "clc12_Version_18_5.gdb", layer =
>>    >         "clc12_Version_18_5") :
>>    >         Dropping null geometries: 2156240
>>    >         2: In readOGR(dsn = "clc12_Version_18_5.gdb", layer =
>>    >         "clc12_Version_18_5") :
>>    >         Z-dimension discarded
>>    >
>>    >         Could anyone advise me how to tackle it? I also would
>>    >         appreciate suggestions on how to work with geodatabases - it?s
>>    >         my first time I work with these kind of files so I don?t even
>>    >         know their structure.
>>    >
>>    >         By the way, these are my computer and software specifications:
>>    >
>>    >         MacBook Pro 2012
>>    >         Processor 2.6 GHz Intel Core i7
>>    >         Memory 16 GB DDR3
>>    >         R 3.5.0
>>    >         RStudio 1.1.447
>>    >
>>    >
>>    >         Best,
>>    >         Roman.
>>    >
>>    >
>>    >
>>    >
>>    >  _______________________________________________
>>    >  R-sig-Geo mailing list
>>    >  R-sig-Geo at r-project.org
>>    >  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>     --
>>     Roger Bivand
>>     Department of Economics, Norwegian School of Economics,
>>     Helleveien 30, N-5045 Bergen, Norway.
>>     voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>>     http://orcid.org/0000-0003-2392-6140
>>     https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>> 
>> 
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From lcabral at ualberta.ca  Fri May  4 21:33:27 2018
From: lcabral at ualberta.ca (Laura Cabral)
Date: Fri, 4 May 2018 13:33:27 -0600
Subject: [R-sig-Geo] stConstruct returning error message "undefined columns
 selected"
Message-ID: <FBB72C89-3BB6-43DC-8211-1F01B014D325@ualberta.ca>

Hello,

I have been following the R documentation for stConstruct {spacetime} to make my own spacetime object from a long table (Data_Sept5). The space ID is stored in the Location column (char) and the time is stored in Datetime as POSIXct. The data of interest is Prop_Strava, and since only some spacetime values are available, this should generate a STIDF object 

> head(Data_Sept5)
                       Location            Datetime Count_Mio Edge_ID Count_Strava Prop_Strava
1 100 Avenue West of 106 Street 2017-09-05 00:00:00         2   54789           NA          NA
2 100 Avenue West of 106 Street 2017-09-05 01:00:00         2   54789           NA          NA
3 100 Avenue West of 106 Street 2017-09-05 02:00:00         0   54789           NA          NA
4 100 Avenue West of 106 Street 2017-09-05 03:00:00         1   54789           NA          NA
5 100 Avenue West of 106 Street 2017-09-05 04:00:00         0   54789           NA          NA
6 100 Avenue West of 106 Street 2017-09-05 05:00:00         1   54789           NA          NA

The spatial object is a SpatialPointsDataFrame loaded from a shapefile using readOGR, called Counters. Counters contains 13 observations of one variable (Name) which corresponds to the locations names in Data_Sept5 as shown above.

I used this line to generate the spacetime object, however, it generates the error shown below:

ST_Sept5<-stConstruct(Data_Sept5, "Location", "Datetime", Counters, interval = T)

Error in `[.data.frame`(x at data, i, j, ..., drop = FALSE) : 
  undefined columns selected

Any idea what might be the cause? As far as I call tell, all my data is equivalent to the example given in the stConstruct R documentation. I also tried giving the column index instead of the name, but received the same error.

Thank you for your help,

Laura Cabral

 

MSc Candidate in Transportation Engineering

Dept of Civil and Environmental Engineering

University of Alberta

lcabral at ualberta.ca <mailto:lcabral at ualberta.ca>
819 993-1901


The University of Alberta is located in ???????????? (Amiskwac?w?skahikan) on Treaty 6 territory, homeland of the Papaschase and the M?tis Nation


	[[alternative HTML version deleted]]


From alyssonstege at gmail.com  Fri May  4 23:17:33 2018
From: alyssonstege at gmail.com (Alysson Luiz Stege)
Date: Fri, 04 May 2018 21:17:33 +0000
Subject: [R-sig-Geo] Generate the local coefficients in spgwr
Message-ID: <CAMKsCCN0i3BmMXP7JTJ6fJ5oSPx+7ucd3RmM3eWF-eonXH_FRQ@mail.gmail.com>

Hello, my name is Alysson.

I am estimating a model by the geographically weighted regression method
and using the spgwr package. I would like to know how to generate the local
coefficients, the value of the statistic t or the level of significance,
the standard deviation and then export them into a txt file, for example.

Thank's

Alysson

	[[alternative HTML version deleted]]


From yud at mail.montclair.edu  Sat May  5 02:09:13 2018
From: yud at mail.montclair.edu (Danlin Yu)
Date: Fri, 4 May 2018 20:09:13 -0400
Subject: [R-sig-Geo] Generate the local coefficients in spgwr
In-Reply-To: <CAMKsCCN0i3BmMXP7JTJ6fJ5oSPx+7ucd3RmM3eWF-eonXH_FRQ@mail.gmail.com>
References: <CAMKsCCN0i3BmMXP7JTJ6fJ5oSPx+7ucd3RmM3eWF-eonXH_FRQ@mail.gmail.com>
Message-ID: <676be797-7020-be38-dd25-fd81ec9f129f@mail.montclair.edu>

Alysson:

I believe if you calibrate your GWR model using the gwr() routine, the 
resulted gwr object shall have all the elements you need in the SDF 
element, as detailed in the package's manual:

The SDF is a SpatialPointsDataFrame (may be gridded) or 
SpatialPolygonsDataFrame object (see package "sp") with fit.points, 
weights, GWR coefficient estimates, R-squared, and coefficient standard 
errors in its "data" slot.

Once you extract this information, you can output them using generic 
functions like write.table to output to txt files, csv files and the like.

Hope this helps.

Cheers,

Dr. Danlin Yu


On 5/4/2018 5:17 PM, Alysson Luiz Stege wrote:
> Hello, my name is Alysson.
>
> I am estimating a model by the geographically weighted regression method
> and using the spgwr package. I would like to know how to generate the local
> coefficients, the value of the statistic t or the level of significance,
> the standard deviation and then export them into a txt file, for example.
>
> Thank's
>
> Alysson
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
___________________________________________
Danlin Yu, Ph.D.
Professor of GIS and Urban Geography
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
Office: CELS 314
Email: yud at mail.montclair.edu
webpage: csam.montclair.edu/~yu


From ftavares29 at gmail.com  Sat May  5 02:29:09 2018
From: ftavares29 at gmail.com (felipe tavares)
Date: Fri, 4 May 2018 21:29:09 -0300
Subject: [R-sig-Geo] Spatial Panel Models Problem (Splm package)
Message-ID: <CAFAdVoZ2b7Sjee0GGvy22RcXL-we_0NNifp+qsdaZ0kMhRDe4Q@mail.gmail.com>

Good evening.

I am trying to estimate a spatial panel data model through splm package.

I am facing the error: Error in lag.listw(listw, u, zero.policy =
zero.policy) :
  object lengths differ

However, my W matrix is NxN, my y vector is NTx1 and my X matrix is NTxK.

My code is:
poly <- readOGR(dsn ="C:/Users/fstavares/OneDrive/Resource Policy Paper",
layer = "RJ")
RJ <- poly2nb(poly)
W <- nb2listw(RJ, zero.policy = TRUE, style = "W", glist = NULL)
SEM <- spml(gdp ~ oivrev, listw = W, model="within", spatial.error="b",
lag=F, data=panel)


Does anyone have faced this problem?

I can send database and code, if it somebody can help me.



-- 
Att,

Felipe Tavares
Bacharel em Ci?ncias Econ?micas - UFSCar
Mestrando em Economia Aplicada - ESALQ/USP
Analista Pricing - ALLIED Technology

Telefone:
(011) 97468-0833

e-mail:
ftavares29 at gmail.com
f <ftavares29 at usp.br>stavares at alliedbrasil.com.br

	[[alternative HTML version deleted]]


From dexter.locke at gmail.com  Sat May  5 02:33:58 2018
From: dexter.locke at gmail.com (Dexter Locke)
Date: Fri, 4 May 2018 20:33:58 -0400
Subject: [R-sig-Geo] Generate the local coefficients in spgwr
In-Reply-To: <676be797-7020-be38-dd25-fd81ec9f129f@mail.montclair.edu>
References: <CAMKsCCN0i3BmMXP7JTJ6fJ5oSPx+7ucd3RmM3eWF-eonXH_FRQ@mail.gmail.com>
 <676be797-7020-be38-dd25-fd81ec9f129f@mail.montclair.edu>
Message-ID: <C057BEA2-4AFD-48B6-93D5-22AC36B6EDAD@gmail.com>

The R script here might be helpful: DOI: 

https://doi.org/10.5061/dryad.3vh79

-Dexter 

> On May 4, 2018, at 8:09 PM, Danlin Yu <yud at mail.montclair.edu> wrote:
> 
> Alysson:
> 
> I believe if you calibrate your GWR model using the gwr() routine, the resulted gwr object shall have all the elements you need in the SDF element, as detailed in the package's manual:
> 
> The SDF is a SpatialPointsDataFrame (may be gridded) or SpatialPolygonsDataFrame object (see package "sp") with fit.points, weights, GWR coefficient estimates, R-squared, and coefficient standard errors in its "data" slot.
> 
> Once you extract this information, you can output them using generic functions like write.table to output to txt files, csv files and the like.
> 
> Hope this helps.
> 
> Cheers,
> 
> Dr. Danlin Yu
> 
> 
>> On 5/4/2018 5:17 PM, Alysson Luiz Stege wrote:
>> Hello, my name is Alysson.
>> 
>> I am estimating a model by the geographically weighted regression method
>> and using the spgwr package. I would like to know how to generate the local
>> coefficients, the value of the statistic t or the level of significance,
>> the standard deviation and then export them into a txt file, for example.
>> 
>> Thank's
>> 
>> Alysson
>> 
>>    [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> -- 
> ___________________________________________
> Danlin Yu, Ph.D.
> Professor of GIS and Urban Geography
> Department of Earth & Environmental Studies
> Montclair State University
> Montclair, NJ, 07043
> Tel: 973-655-4313
> Fax: 973-655-4072
> Office: CELS 314
> Email: yud at mail.montclair.edu
> webpage: csam.montclair.edu/~yu
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger@Biv@nd @ending from nhh@no  Sat May  5 12:35:42 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Sat, 5 May 2018 12:35:42 +0200
Subject: [R-sig-Geo] Spatial Panel Models Problem (Splm package)
In-Reply-To: <CAFAdVoZ2b7Sjee0GGvy22RcXL-we_0NNifp+qsdaZ0kMhRDe4Q@mail.gmail.com>
References: <CAFAdVoZ2b7Sjee0GGvy22RcXL-we_0NNifp+qsdaZ0kMhRDe4Q@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.1805051227140.18610@reclus.nhh.no>

On Sat, 5 May 2018, felipe tavares wrote:

> Good evening.
>
> I am trying to estimate a spatial panel data model through splm package.
>
> I am facing the error: Error in lag.listw(listw, u, zero.policy =
> zero.policy) :
>  object lengths differ
>
> However, my W matrix is NxN, my y vector is NTx1 and my X matrix is NTxK.
>
> My code is:
> poly <- readOGR(dsn ="C:/Users/fstavares/OneDrive/Resource Policy Paper",
> layer = "RJ")
> RJ <- poly2nb(poly)
> W <- nb2listw(RJ, zero.policy = TRUE, style = "W", glist = NULL)
> SEM <- spml(gdp ~ oivrev, listw = W, model="within", spatial.error="b",
> lag=F, data=panel)
>

Are the first two columns of panel as required (from ?spml):

     data: an object of class ?data.frame? or ?pdata.frame?. A data
           frame containing the variables in the model. When the object
           is a ?data.frame?, the first two columns shall contain the
           indexes, unless otherwise specified. See ?index?

From ?index

      Panel data are stored in a ?"pdata.frame"? which has an ?"index"?
      attribute. Fitted models in ?"plm"? have a ?"model"? element which
      is also a ?"pdata.frame"? and therefore also has an ?"index"?
      attribute. Finally, each series, once extracted from a
      ?"pdata.frame"?, becomes of class ?"pseries"?, which also has this
      ?"index"? attribute.  ?"index"? methods are available for all
      these objects.  The argument ?"which"? indicates which index
      should be extracted. If ?which = NULL?, all indexes are extracted.
      ?"which"? can also be a vector of length 1, 2, or 3 (3 only if the
      pdata frame was constructed with an additional group index)
      containing either characters (the names of the individual variable
      and/or of the time variable and/or the group variable or ?"id"?
      and ?"time"?) and ?"group"? or integers (1 for the individual
      index, 2 for the time index, and 3 for the group index (the latter
      only if the pdata frame was constructed with such).)

and:

> str(Produc)
'data.frame':	816 obs. of  11 variables:
  $ state : Factor w/ 48 levels "ALABAMA","ARIZONA",..: 1 1 1 1 1 1 1 1 1 1 
...
  $ year  : int  1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 ...
  $ region: Factor w/ 9 levels "1","2","3","4",..: 6 6 6 6 6 6 6 6 6 6 ...
  $ pcap  : num  15033 15502 15972 16406 16763 ...
  $ hwy   : num  7326 7526 7765 7908 8026 ...
  $ water : num  1656 1721 1765 1742 1735 ...
  $ util  : num  6051 6255 6442 6756 7002 ...
  $ pc    : num  35794 37300 38670 40084 42057 ...
  $ gsp   : int  28418 29375 31303 33430 33749 33604 35764 37463 39964 
40979 ...
  $ emp   : num  1010 1022 1072 1136 1170 ...
  $ unemp : num  4.7 5.2 4.7 3.9 5.5 7.7 6.8 7.4 6.3 7.1 ...

with the individual column first varying slowly, and the time column 
second varying within the first column values. Since you do not provide a 
reproducible example (not your data and code, an example using built-in 
data), it is hard to know.

Hope this clarifies,

Roger

>
> Does anyone have faced this problem?
>
> I can send database and code, if it somebody can help me.
>
>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From Roger@Biv@nd @ending from nhh@no  Sat May  5 13:02:45 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Sat, 5 May 2018 13:02:45 +0200
Subject: [R-sig-Geo] Issues with a GDB file in R?
In-Reply-To: <alpine.LFD.2.21.1805042035570.16297@reclus.nhh.no>
References: <13F59690-AB9E-40B2-B9F7-2474C9771F52@exeter.ac.uk>
 <AFA371A2-4A57-4038-AD9B-2A6C894E2A86@esri.com>
 <A814689E-6CF5-404D-94FD-841FB832FFAB@exeter.ac.uk>
 <alpine.LFD.2.21.1805031321160.14684@reclus.nhh.no>
 <977196B3-00A0-4D48-8E73-6AAF9988F1B1@exeter.ac.uk>
 <alpine.LFD.2.21.1805032014310.22459@reclus.nhh.no>
 <alpine.LFD.2.21.1805042035570.16297@reclus.nhh.no>
Message-ID: <alpine.LFD.2.21.1805051300370.18610@reclus.nhh.no>

On Fri, 4 May 2018, Roger Bivand wrote:

> On Thu, 3 May 2018, Roger Bivand wrote:
>
>>  On Thu, 3 May 2018, Aguirre Perez, Roman wrote:
>>
>>>   Hi again,
>>>
>>>   first of all, thanks a lot for your comments. It's becoming quite
>>>   interesting how to perform this task with such amount of data.
>>> 
>>>
>>>   Here is an update...
>>>
>>>   Cotton, I could read the geodatabase by using the commands I shared.
>>>   However, my R session crashed after overlaying it with a small set of
>>>   polygons. I guess it was because the size of the sp object (around 14.5
>>>   GB). It's also worth mentioning that it was just a "multipolygon" (is
>>>   that
>>>   the correct word?) formed by 2370829 polygons. I haven?t succeeded on
>>>   installing the sf package, but I will keep trying it.
>>>
>>>   Melanie, I already downloaded and read the geoTiff version. At first
>>>   sight, it seems that this object doesn?t have enough features as to
>>>   perform the overlying. I might have a biased idea of how raster objects
>>>   work - I'm too stick to the representation of shapefiles which sounds
>>>   quite related with Roger's idea. So I will start to explore it in order
>>>   to
>>>   gain a bit more understanding on it.
>>>
>>>   Roger, I certainly need to know which category is associated with each
>>>   CLC
>>>   polygon in order to compute the area covered by each of these classes
>>>   within each NUTS3 region. Therefore, I still need to use a vector-vector
>>>   overlay, right?
>>
>>  On the contrary. The geoTiffs are coded as described in the documentation.
>>  Your output is simply the count of raster cells by NUTS3 for each of the
>>  categories. The geoTiff is in ETRS_1989_LAEA, so is projected; it includes
>>  a lot of sea and no data because of the French overseas territories.
>>
>>  You could possibly use PostGIS to do the intersections, or use GRASS for
>>  raster-vector counts (say through rgrass7). In R, you would want to add a
>>  NUTS3 ID band to the land cover raster, then aggregate by NUTS3 ID.
>>
>>  I would suggest using GRASS as the most obvious route, reading the raster,
>>  reading the NUTS3 boundaries into a separate location, projecting to LAEA,
>>  then rasterising the NUTS3 regions (v.to.rast) and running r.cross. You
>>  get 32K output categories, the 48 corine categories times the count of
>>  NUTS3 regions minus the nulls (there aren't many glaciers in most
>>  regions). You'll then need to match back the Corine codes and the NUTS3
>>  codes - see in the category label file shown by r.category.
>>
>>  I'll try to provide code tomorrow.
>
> Combining R and GRASS seems to work, but no guarantees.
>
> library(sp)
> library(rgdal)
> Gi <- GDALinfo("g250_clc12_V18_5.tif")
> makeSG <- function(x) {
>   stopifnot(class(x) == "GDALobj")
>   p4 <- attr(x, "projection")
>   gt <- GridTopology(c(x[4]+(x[6]/2), x[5]+(x[7]/2)), c(x[6], x[7]),
>     c(x[2], x[1]))
>  SpatialGrid(gt, CRS(p4))
> }
> SG <- makeSG(Gi)
> nuts_ll <- readOGR("NUTS_RG_01M_2013_4326_LEVL_3.shp")
> nuts_laea <- spTransform(nuts_ll, CRS(attr(Gi, "projection")))
> library(rgrass7)
> td <- tempdir()
> iG <- initGRASS("/home/rsb/topics/grass/g740/grass-7.4.0", td, SG)
> # your GRASS will be where you installed it
> writeVECT(nuts_laea, "nuts", v.in.ogr_flags="o")
> execGRASS("r.in.gdal", input="g250_clc12_V18_5.tif", output="corine",
>  flags="o")
> execGRASS("v.to.rast", input="nuts", output="nuts3", use="cat",
>  label_column="FID")
> execGRASS("r.cross", input="nuts3,corine", output="cross_nuts3")
> r_stats0 <- execGRASS("r.stats", input="cross_nuts3", flags="a",
>  intern=TRUE)
> r_stats1 <- gsub("\\*", "NA", r_stats0)
> con_stats <- textConnection(r_stats1)
> stats <- read.table(con_stats, header=FALSE, col.names=c("cross_cat",
>  "area"), colClasses=c("integer", "numeric"))
> close(con_stats)
> r_cats0 <- execGRASS("r.category", map="cross_nuts3", intern=TRUE)
> r_cats1 <- gsub(";", "", r_cats0)
> r_cats2 <- gsub("\t", " ", r_cats1)
> r_cats3 <- gsub("no data", "no_data", r_cats2)
> r_cats4 <- gsub("category ", "", r_cats3)
> r_cats4[1] <- paste0(r_cats4[1], "NA NA")
> r_cats_split <- strsplit(r_cats4, " ")
> cats <- data.frame(cross_cat=as.integer(sapply(r_cats_split, "[", 1)),
>   nuts=sapply(r_cats_split, "[", 2),
>   corine=as.integer(sapply(r_cats_split, "[", 3)))
> catstats <- merge(cats, stats, by="cross_cat", all=TRUE)
> agg_areas <- tapply(catstats$area, list(catstats$nuts, catstats$corine),
>  sum)
> library(foreign)
> corine_labels <- read.dbf("g250_clc12_V18_5.tif.vat.dbf", as.is=TRUE)
> o <- match(colnames(agg_areas), as.character(corine_labels$Value))
> colnames(agg_areas) <- corine_labels$LABEL3[o]
> agg_areas_df <- as.data.frame(agg_areas)
> agg_areas_df1 <- agg_areas_df[-which(!(row.names(agg_areas_df) %in%
>   as.character(nuts_ll$FID))),] # dropping "NA"      "no_data"
>
> This should be ready to merge with the NUTS3 boundaries, if needed.
>
> agg_areas_df1$FID <- row.names(agg_areas_df1)
> nuts_corine <- merge(nuts_laea, agg_areas_df1, by="FID")
>

And to write out as GPKG:

names(nuts_corine)[1] <- "FID_"
writeOGR(nuts_corine, "nuts_corine.gpkg", layer="corine", driver="GPKG")

It seems that at least this driver treats "FID" as a reserved field name.

> For the vector parts you could use sf and the provisional rgrass7sf on 
> github, but that wouldn't yet let you construct a skeleton SpatialGrid to 
> define the GRASS location. Using GRASS for the heavy lifting (the raster is 
> 51000 by 35000), and avoiding vector for overlay, this doesn't need much 
> memory (GRASS handles rasters by row). The GRASS temporary location only 
> takes 130MB of disk space. You could go for the 100m raster resolution, but I 
> doubt that the outcome would vary much - anyone like to try?
>
> If the sub-polygons by NUTS and corine categories are actually needed, the 
> output of r.cross could be passed to r.to.vect:
>
> execGRASS("r.to.vect", input="cross_nuts3", output="cross_nuts3",
>   type="area")
>
> but this is more demanding in memory terms.

Reading into R is not possible, object too large.

Roger

>
> Interesting case, and it does show that combining GIS and R delivers the 
> goods - SAGA would probably work equivalently.
>
> Roger
>
>>
>>  Roger
>> 
>>>
>>>   I really appreciate any feedback in advance as well as details that I
>>>   should take into account to understand more about how to work with this
>>>   kind of data. I will also keep you up to date on how it goes if you
>>>   like.
>>> 
>>>
>>>   Best,
>>>   Roman.
>>>
>>>   ?On 03/05/2018, 12:26, "Roger Bivand" <Roger.Bivand at nhh.no> wrote:
>>>
>>>      On Thu, 3 May 2018, Aguirre Perez, Roman wrote:
>>>
>>>    >   Hello Shaun,
>>>    >
>>>    >   Thanks a lot for replying and providing me alternative options.
>>>    >
>>>    >
>>>    >   Unfortunately, I can't try both options anymore as I ran out of
>>>    >   ArcGIS
>>>    >   due to I was using a university PC which is not available now (I
>>>    >   installed an ArcGIS trial version there), but I'll try it later. I
>>>    >   also
>>>    >   failed on installing the sf package - I'll dig a bit more on it.
>>>    >   Nevertheless, I already downloaded the SpatialLite version so I'll
>>>    >   try
>>>    >   the second option and I'll let you know how it goes.
>>>
>>>      I think Melanie got it right - the apparent extra detail and
>>>      precision
>>>      you'd get from vector-vector overlay is illusory, so going with
>>>      geoTiff
>>>      should get you there (you can check to see whether 100m resolution
>>>      differs
>>>      from 250m). The only reason to choose vector-vector would be that the
>>>      Corine vector contains categories not represented in the raster
>>>      version.
>>>      Using raster also steps around the polygon deficiencies in the GDB
>>>      (and
>>>      probably SQLite) representations.
>>>
>>>      Roger
>>>
>>>    >
>>>    >
>>>    >   Regards,
>>>    >   Roman.
>>>    >
>>>    >   On 02/05/2018, 18:53, "Shaun Walbridge" <SWalbridge at esri.com>
>>>    >   wrote:
>>>    >
>>>    >      Hello Roman,
>>>    >
>>>    >      A couple of suggested options: You can try and use the
>>>    >      arcgisbinding package [1] to pull the data directly into R via
>>>    >      ArcGIS, as you mentioned you have ArcGIS available [presumably
>>>    >      on
>>>    >      Windows or in a VM]. It will access the data directly, and let
>>>    >      you
>>>    >      create sp and sf objects out of Geodatabases with little work. A
>>>    >      basic workflow looks like this:
>>>    >
>>>    >      d <- arc.open("path/file.gdb/layer_name")
>>>    >      df <- arc.select(d) # here, you can filter columns and
>>>    >      attributes,
>>>    >      see [2]
>>>    >      # create an sf object
>>>    >      df.sf <- arc.data2sf(df)
>>>    >      # alternatively, create an sp object
>>>    >      df.sp <- arc.data2sp(df)
>>>    >
>>>    >      You can also write the results back to a geodatabase, or any
>>>    >      other
>>>    >      format that ArcGIS understands. Another option is trying the
>>>    >      SpatiaLite version of the data at the URL you posted. You should
>>>    >      be able to access this using R directly, provided your rgdal
>>>    >      installation is correctly built to read spatialite databases. If
>>>    >      it is, try the same process you mentioned using rgdal, but point
>>>    >      it at the SpatialLite database instead. You could also use
>>>    >      command-line OGR to convert the data, that has a few options
>>>    >      like
>>>    >      where clause filtering that aren't directly available via
>>>    >      readOGR.
>>>    >
>>>    >      If neither of these options work, let me know and I can convert
>>>    >      the data for you into a format of your preference.
>>>    >
>>>    >      Cheers,
>>>    >      Shaun
>>>    >
>>>    >      1.
>>>    >      https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_R-2DArcGIS_r-2Dbridge-2Dinstall&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=yckcjR6k3nADiVsNiAhGwcZB--0A8DQgvLSJ27upmyk&m=dkecE8PWOn5sSrtSXqX2R-VwJuFH_In4BvpC5da4LJ0&s=nRO2IG9dlrdKYGMSp3rCf7nwJqRFQoIWnY5zSFrPOQM&e=
>>>    >      2.
>>>    >      https://urldefense.proofpoint.com/v2/url?u=https-3A__rdrr.io_github_R-2DArcGIS_r-2Dbridge_man_arc.select.html&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=yckcjR6k3nADiVsNiAhGwcZB--0A8DQgvLSJ27upmyk&m=dkecE8PWOn5sSrtSXqX2R-VwJuFH_In4BvpC5da4LJ0&s=89N-cLe5N3dhZ6MTsM2OAYwmDImBH88ZrVaA5Hos0n4&e=
>>>    >
>>>    >
>>>    >
>>>    >      On 5/2/18, 1:34 PM, "R-sig-Geo on behalf of Aguirre Perez,
>>>    >      Roman"
>>>    >      <r-sig-geo-bounces at r-project.org on behalf of
>>>    >      ra454 at exeter.ac.uk>
>>>    >      wrote:
>>>    >
>>>    >          Hi everyone,
>>>    >
>>>    >          I?ve been struggling with a ESRI Geodatabase file
>>>    >          (clc12_Version_18_5.gdb) which is a layer of land cover
>>>    >          classes available on
>>>    >
>>>    >          https://urldefense.proofpoint.com/v2/url?u=https-3A__land.copernicus.eu_pan-2Deuropean_corine-2Dland-2Dcover_clc-2D2012-3Ftab-3Ddownload&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=9LaO4HiB5C5ewiuN_IeSQJSgq2tl5_-oMECPChtZa_U&e=
>>>    >
>>>    >          whose size is 2.61 GB once unzipped.
>>>    >
>>>    >          My ultimate task is to overlay it with the last NUTS3
>>>    >          administrative boundaries shapefile (2013) available on
>>>    >
>>>    >          https://urldefense.proofpoint.com/v2/url?u=http-3A__ec.europa.eu_eurostat_web_gisco_geodata_reference-2Ddata_administrative-2Dunits-2Dstatistical-2Dunits&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=VExYSoR8FY_vhZaPNJpoOx0ZCZNMU9hMTtlGJZj2joU&e=
>>>    >
>>>    >          in order to compute the area covered by each class within
>>>    >          each
>>>    >          NUTS3 region.
>>>    >
>>>    >          Despite the ease of friendly software for performing this
>>>    >          task, haven?t been capable of doing it - GRASS didn?t load
>>>    >          the
>>>    >          file as the log reports problems with the polygons, QGIS
>>>    >          shows
>>>    >          a warning regarding a specific object and ArcGIS got frozen.
>>>    >          I
>>>    >          guess it?s because the PC I used doesn?t have enough
>>>    >          capacity.
>>>    >          Unfortunately, I don?t have access to a more powerful one.
>>>    >
>>>    >          Anyway, I decided to try with R -after all, I?ll perform my
>>>    >          analysis with it. So I started exploring this GDB with
>>>    >          rgdal:
>>>    >
>>>    >          ogrInfo(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
>>>    >
>>>    >          Source:
>>>    >          "/Users/Roman/Desktop/clc12gdb/clc12_Version_18_5.gdb",
>>>    >          layer: "clc12_Version_18_5"
>>>    >          Driver: OpenFileGDB;
>>>    >          number of rows: 2370829
>>>    >          Feature type: wkbPolygon with 3 dimensions
>>>    >          Extent: (-2693292 -3086662) - (10037210 5440568)
>>>    >          Null geometry IDs: 2156240
>>>    >          CRS: +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000
>>>    >          +y_0=3210000
>>>    >          +ellps=GRS80 +units=m +no_defs
>>>    >          Number of fields: 6
>>>    >          name                      type  length  typeName
>>>    >          1 code_12              4       3           String
>>>    >          2 ID                         4       18         String
>>>    >          3 Remark               4       20         String
>>>    >          4 Area_Ha             2       0           Real
>>>    >          5 Shape_Length   2       0           Real
>>>    >          6 Shape_Area       2       0           Real
>>>    >
>>>    >          Then I tried to load it typing
>>>    >
>>>    >          clc<-readOGR(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
>>>    >
>>>    >          After 3-5 minutes, it appears the following text:
>>>    >
>>>    >          OGR data source with driver: OpenFileGDB
>>>    >          Source:
>>>    >          "/Users/Roman/Desktop/clc12shp/clc12_Version_18_5.gdb",
>>>    >          layer:
>>>    >          "clc12_Version_18_5"
>>>    >          with 2370829 features
>>>    >          It has 6 fields
>>>    >
>>>    >          Unfortunately, after trying 5 times (each one took around 8
>>>    >          hours) I couldn?t get anything but the following messages:
>>>    >
>>>    >          Warning messages:
>>>    >          1: In readOGR(dsn = "clc12_Version_18_5.gdb", layer =
>>>    >          "clc12_Version_18_5") :
>>>    >          Dropping null geometries: 2156240
>>>    >          2: In readOGR(dsn = "clc12_Version_18_5.gdb", layer =
>>>    >          "clc12_Version_18_5") :
>>>    >          Z-dimension discarded
>>>    >
>>>    >          Could anyone advise me how to tackle it? I also would
>>>    >          appreciate suggestions on how to work with geodatabases -
>>>    >          it?s
>>>    >          my first time I work with these kind of files so I don?t
>>>    >          even
>>>    >          know their structure.
>>>    >
>>>    >          By the way, these are my computer and software
>>>    >          specifications:
>>>    >
>>>    >          MacBook Pro 2012
>>>    >          Processor 2.6 GHz Intel Core i7
>>>    >          Memory 16 GB DDR3
>>>    >          R 3.5.0
>>>    >          RStudio 1.1.447
>>>    >
>>>    >
>>>    >          Best,
>>>    >          Roman.
>>>    >
>>>    >
>>>    >
>>>    >
>>>    >   _______________________________________________
>>>    >   R-sig-Geo mailing list
>>>    >   R-sig-Geo at r-project.org
>>>    >   https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>      --
>>>      Roger Bivand
>>>      Department of Economics, Norwegian School of Economics,
>>>      Helleveien 30, N-5045 Bergen, Norway.
>>>      voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>>>      http://orcid.org/0000-0003-2392-6140
>>>      https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>>
>>> 
>> 
>> 
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From y@@mine@moh@med @ending from Bue@edu@eg  Sat May  5 16:15:56 2018
From: y@@mine@moh@med @ending from Bue@edu@eg (yasmine mohamed)
Date: Sat, 5 May 2018 14:15:56 +0000
Subject: [R-sig-Geo] Calculating spatiotemporal canonical correlation
In-Reply-To: <DB15DCAD-982F-4B8B-993F-30B2AF729A8E@gmail.com>
References: <DB15DCAD-982F-4B8B-993F-30B2AF729A8E@gmail.com>
Message-ID: <926F7088-9B1E-452B-8B40-2D1B87385317@bue.edu.eg>

Hello, my name is Yasmine.

I am calculating the spatiotemporal canonical correlation for the relationship between precipitation and sea surface temperature.  First, I need to estimate  EOF for my predictors and predictand datasets separately using spacetime package. Then the obtained PC time series will be used in canonical correlation using CCA package. I would like to know if this is the correct way to follow in estimating spatiotemporal canonical correlation like what is included in Noel Cressie and Christopher K. Wikle of ?Statistics for Spatio-Temporal Data? (2011) book.
Thanks,

Yasmine



	[[alternative HTML version deleted]]


From nr@j@ @ending from tn@u@@c@in  Sat May  5 19:31:05 2018
From: nr@j@ @ending from tn@u@@c@in (Raja Natarajan)
Date: Sat, 05 May 2018 17:31:05 +0000
Subject: [R-sig-Geo] Tutorial on reading hyperspectral data
Message-ID: <CA+wLXTJ6byXFMXGUZhVFw7ujC=3HA1x45+4xW8StGE5j3-_KaQ@mail.gmail.com>

Hi

Greetings

Please share any tutorial on read and open hyperspectral astrology images
using R

	[[alternative HTML version deleted]]


From r@turner @ending from @uckl@nd@@c@nz  Sat May  5 23:59:12 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sun, 6 May 2018 09:59:12 +1200
Subject: [R-sig-Geo] [FORGED]  Tutorial on reading hyperspectral data
In-Reply-To: <CA+wLXTJ6byXFMXGUZhVFw7ujC=3HA1x45+4xW8StGE5j3-_KaQ@mail.gmail.com>
References: <CA+wLXTJ6byXFMXGUZhVFw7ujC=3HA1x45+4xW8StGE5j3-_KaQ@mail.gmail.com>
Message-ID: <5926e097-c007-f36c-498c-88e4e8e05ceb@auckland.ac.nz>


On 06/05/18 05:31, Raja Natarajan wrote:

> hyperspectral astrology images

Did you mean *astronomy* ??? !!!

I certainly hope so! :-)

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From md@umner @ending from gm@il@com  Sun May  6 00:48:58 2018
From: md@umner @ending from gm@il@com (Michael Sumner)
Date: Sat, 05 May 2018 22:48:58 +0000
Subject: [R-sig-Geo] Tutorial on reading hyperspectral data
In-Reply-To: <CA+wLXTJ6byXFMXGUZhVFw7ujC=3HA1x45+4xW8StGE5j3-_KaQ@mail.gmail.com>
References: <CA+wLXTJ6byXFMXGUZhVFw7ujC=3HA1x45+4xW8StGE5j3-_KaQ@mail.gmail.com>
Message-ID: <CAAcGz995FtCtRTJAuN0VjgJ3opPePH4NKV4SJPZ+8v61viOC1A@mail.gmail.com>

On Sun, 6 May 2018, 03:31 Raja Natarajan, <nraja at tnau.ac.in> wrote:

> Hi
>
> Greetings
>
> Please share any tutorial on read and open hyperspectral astrology images
> using R
>

Hi Raja, I'd start with running raster::brick on one of your file paths and
let us know the result, also your sessionInfo() because support for the
likely format in use (what is it?) is platform and version dependent,
though things improved greatly recently.

There are tutorials on hyperspectral in R with raster and rhdf5 for remote
sensing data, I don't know of any astro specific ones.You may not need
rhdf5 any more, but geographic assumptions can still bite and make things
harder.

Just a guess that this may be relevant to you
https://www.neonscience.org/create-raster-stack-hsi-hdf5-r


Cheers, Mike

>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From r@454 @ending from exeter@@c@uk  Sun May  6 15:16:24 2018
From: r@454 @ending from exeter@@c@uk (Aguirre Perez, Roman)
Date: Sun, 6 May 2018 13:16:24 +0000
Subject: [R-sig-Geo] Issues with a GDB file in R?
In-Reply-To: <alpine.LFD.2.21.1805051300370.18610@reclus.nhh.no>
References: <13F59690-AB9E-40B2-B9F7-2474C9771F52@exeter.ac.uk>
 <AFA371A2-4A57-4038-AD9B-2A6C894E2A86@esri.com>
 <A814689E-6CF5-404D-94FD-841FB832FFAB@exeter.ac.uk>
 <alpine.LFD.2.21.1805031321160.14684@reclus.nhh.no>
 <977196B3-00A0-4D48-8E73-6AAF9988F1B1@exeter.ac.uk>
 <alpine.LFD.2.21.1805032014310.22459@reclus.nhh.no>
 <alpine.LFD.2.21.1805042035570.16297@reclus.nhh.no>
 <alpine.LFD.2.21.1805051300370.18610@reclus.nhh.no>
Message-ID: <CC45C4FA-F33B-4687-BD82-0F7C41B9A062@exeter.ac.uk>

On 05/05/2018, 12:03, "Roger Bivand" <Roger.Bivand at nhh.no> wrote:

    On Fri, 4 May 2018, Roger Bivand wrote:
    
    > On Thu, 3 May 2018, Roger Bivand wrote:
    >
    >>  On Thu, 3 May 2018, Aguirre Perez, Roman wrote:
    >>
    >>>   Hi again,
    >>>
    >>>   first of all, thanks a lot for your comments. It's becoming quite
    >>>   interesting how to perform this task with such amount of data.
    >>> 
    >>>
    >>>   Here is an update...
    >>>
    >>>   Cotton, I could read the geodatabase by using the commands I shared.
    >>>   However, my R session crashed after overlaying it with a small set of
    >>>   polygons. I guess it was because the size of the sp object (around 14.5
    >>>   GB). It's also worth mentioning that it was just a "multipolygon" (is
    >>>   that
    >>>   the correct word?) formed by 2370829 polygons. I haven?t succeeded on
    >>>   installing the sf package, but I will keep trying it.
    >>>
    >>>   Melanie, I already downloaded and read the geoTiff version. At first
    >>>   sight, it seems that this object doesn?t have enough features as to
    >>>   perform the overlying. I might have a biased idea of how raster objects
    >>>   work - I'm too stick to the representation of shapefiles which sounds
    >>>   quite related with Roger's idea. So I will start to explore it in order
    >>>   to
    >>>   gain a bit more understanding on it.
    >>>
    >>>   Roger, I certainly need to know which category is associated with each
    >>>   CLC
    >>>   polygon in order to compute the area covered by each of these classes
    >>>   within each NUTS3 region. Therefore, I still need to use a vector-vector
    >>>   overlay, right?
    >>
    >>  On the contrary. The geoTiffs are coded as described in the documentation.
    >>  Your output is simply the count of raster cells by NUTS3 for each of the
    >>  categories. The geoTiff is in ETRS_1989_LAEA, so is projected; it includes
    >>  a lot of sea and no data because of the French overseas territories.
    >>
    >>  You could possibly use PostGIS to do the intersections, or use GRASS for
    >>  raster-vector counts (say through rgrass7). In R, you would want to add a
    >>  NUTS3 ID band to the land cover raster, then aggregate by NUTS3 ID.
    >>
    >>  I would suggest using GRASS as the most obvious route, reading the raster,
    >>  reading the NUTS3 boundaries into a separate location, projecting to LAEA,
    >>  then rasterising the NUTS3 regions (v.to.rast) and running r.cross. You
    >>  get 32K output categories, the 48 corine categories times the count of
    >>  NUTS3 regions minus the nulls (there aren't many glaciers in most
    >>  regions). You'll then need to match back the Corine codes and the NUTS3
    >>  codes - see in the category label file shown by r.category.
    >>
    >>  I'll try to provide code tomorrow.
    >
    > Combining R and GRASS seems to work, but no guarantees.
    >
    > library(sp)
    > library(rgdal)
    > Gi <- GDALinfo("g250_clc12_V18_5.tif")
    > makeSG <- function(x) {
    >   stopifnot(class(x) == "GDALobj")
    >   p4 <- attr(x, "projection")
    >   gt <- GridTopology(c(x[4]+(x[6]/2), x[5]+(x[7]/2)), c(x[6], x[7]),
    >     c(x[2], x[1]))
    >  SpatialGrid(gt, CRS(p4))
    > }
    > SG <- makeSG(Gi)
    > nuts_ll <- readOGR("NUTS_RG_01M_2013_4326_LEVL_3.shp")
    > nuts_laea <- spTransform(nuts_ll, CRS(attr(Gi, "projection")))
    > library(rgrass7)
    > td <- tempdir()
    > iG <- initGRASS("/home/rsb/topics/grass/g740/grass-7.4.0", td, SG)
    > # your GRASS will be where you installed it
    > writeVECT(nuts_laea, "nuts", v.in.ogr_flags="o")
    > execGRASS("r.in.gdal", input="g250_clc12_V18_5.tif", output="corine",
    >  flags="o")
    > execGRASS("v.to.rast", input="nuts", output="nuts3", use="cat",
    >  label_column="FID")
    > execGRASS("r.cross", input="nuts3,corine", output="cross_nuts3")
    > r_stats0 <- execGRASS("r.stats", input="cross_nuts3", flags="a",
    >  intern=TRUE)
    > r_stats1 <- gsub("\\*", "NA", r_stats0)
    > con_stats <- textConnection(r_stats1)
    > stats <- read.table(con_stats, header=FALSE, col.names=c("cross_cat",
    >  "area"), colClasses=c("integer", "numeric"))
    > close(con_stats)
    > r_cats0 <- execGRASS("r.category", map="cross_nuts3", intern=TRUE)
    > r_cats1 <- gsub(";", "", r_cats0)
    > r_cats2 <- gsub("\t", " ", r_cats1)
    > r_cats3 <- gsub("no data", "no_data", r_cats2)
    > r_cats4 <- gsub("category ", "", r_cats3)
    > r_cats4[1] <- paste0(r_cats4[1], "NA NA")
    > r_cats_split <- strsplit(r_cats4, " ")
    > cats <- data.frame(cross_cat=as.integer(sapply(r_cats_split, "[", 1)),
    >   nuts=sapply(r_cats_split, "[", 2),
    >   corine=as.integer(sapply(r_cats_split, "[", 3)))
    > catstats <- merge(cats, stats, by="cross_cat", all=TRUE)
    > agg_areas <- tapply(catstats$area, list(catstats$nuts, catstats$corine),
    >  sum)
    > library(foreign)
    > corine_labels <- read.dbf("g250_clc12_V18_5.tif.vat.dbf", as.is=TRUE)
    > o <- match(colnames(agg_areas), as.character(corine_labels$Value))
    > colnames(agg_areas) <- corine_labels$LABEL3[o]
    > agg_areas_df <- as.data.frame(agg_areas)
    > agg_areas_df1 <- agg_areas_df[-which(!(row.names(agg_areas_df) %in%
    >   as.character(nuts_ll$FID))),] # dropping "NA"      "no_data"
    >
    > This should be ready to merge with the NUTS3 boundaries, if needed.
    >
    > agg_areas_df1$FID <- row.names(agg_areas_df1)
    > nuts_corine <- merge(nuts_laea, agg_areas_df1, by="FID")
    >
    
    And to write out as GPKG:
    
    names(nuts_corine)[1] <- "FID_"
    writeOGR(nuts_corine, "nuts_corine.gpkg", layer="corine", driver="GPKG")
    
    It seems that at least this driver treats "FID" as a reserved field name.
    
    > For the vector parts you could use sf and the provisional rgrass7sf on 
    > github, but that wouldn't yet let you construct a skeleton SpatialGrid to 
    > define the GRASS location. Using GRASS for the heavy lifting (the raster is 
    > 51000 by 35000), and avoiding vector for overlay, this doesn't need much 
    > memory (GRASS handles rasters by row). The GRASS temporary location only 
    > takes 130MB of disk space. You could go for the 100m raster resolution, but I 
    > doubt that the outcome would vary much - anyone like to try?
    >
    > If the sub-polygons by NUTS and corine categories are actually needed, the 
    > output of r.cross could be passed to r.to.vect:
    >
    > execGRASS("r.to.vect", input="cross_nuts3", output="cross_nuts3",
    >   type="area")
    >
    > but this is more demanding in memory terms.

Hi Roger,

thanks a lot again for helping me with this issue.


Unfortunately, I haven't managed to call GRASS within R, neither install sf. My guess is that those issues are because I'm using both newest versions OS X High Sierra and R 3.5.0 which are not stable yet.   

    Reading into R is not possible, object too large.

Bearing in mind the previous issues plus this last comment, I decided to use a PC with another OS (Ubuntu) aiming at solving them and working with a bit more space (32 GB).  
    
    Roger

In the meantime, I really would appreciate you guidance for gaining background on this subject. Could you please suggest me resources to better understand the features of objects involved in Spatial Statistics? I should mention that the knowledge I have about it is resumed in your book Applied Spatial Data Analysis with R.


Best,
Roman.    

    >
    > Interesting case, and it does show that combining GIS and R delivers the 
    > goods - SAGA would probably work equivalently.
    >
    > Roger
    >
    >>
    >>  Roger
    >> 
    >>>
    >>>   I really appreciate any feedback in advance as well as details that I
    >>>   should take into account to understand more about how to work with this
    >>>   kind of data. I will also keep you up to date on how it goes if you
    >>>   like.
    >>> 
    >>>
    >>>   Best,
    >>>   Roman.
    >>>
    >>>   On 03/05/2018, 12:26, "Roger Bivand" <Roger.Bivand at nhh.no> wrote:
    >>>
    >>>      On Thu, 3 May 2018, Aguirre Perez, Roman wrote:
    >>>
    >>>    >   Hello Shaun,
    >>>    >
    >>>    >   Thanks a lot for replying and providing me alternative options.
    >>>    >
    >>>    >
    >>>    >   Unfortunately, I can't try both options anymore as I ran out of
    >>>    >   ArcGIS
    >>>    >   due to I was using a university PC which is not available now (I
    >>>    >   installed an ArcGIS trial version there), but I'll try it later. I
    >>>    >   also
    >>>    >   failed on installing the sf package - I'll dig a bit more on it.
    >>>    >   Nevertheless, I already downloaded the SpatialLite version so I'll
    >>>    >   try
    >>>    >   the second option and I'll let you know how it goes.
    >>>
    >>>      I think Melanie got it right - the apparent extra detail and
    >>>      precision
    >>>      you'd get from vector-vector overlay is illusory, so going with
    >>>      geoTiff
    >>>      should get you there (you can check to see whether 100m resolution
    >>>      differs
    >>>      from 250m). The only reason to choose vector-vector would be that the
    >>>      Corine vector contains categories not represented in the raster
    >>>      version.
    >>>      Using raster also steps around the polygon deficiencies in the GDB
    >>>      (and
    >>>      probably SQLite) representations.
    >>>
    >>>      Roger
    >>>
    >>>    >
    >>>    >
    >>>    >   Regards,
    >>>    >   Roman.
    >>>    >
    >>>    >   On 02/05/2018, 18:53, "Shaun Walbridge" <SWalbridge at esri.com>
    >>>    >   wrote:
    >>>    >
    >>>    >      Hello Roman,
    >>>    >
    >>>    >      A couple of suggested options: You can try and use the
    >>>    >      arcgisbinding package [1] to pull the data directly into R via
    >>>    >      ArcGIS, as you mentioned you have ArcGIS available [presumably
    >>>    >      on
    >>>    >      Windows or in a VM]. It will access the data directly, and let
    >>>    >      you
    >>>    >      create sp and sf objects out of Geodatabases with little work. A
    >>>    >      basic workflow looks like this:
    >>>    >
    >>>    >      d <- arc.open("path/file.gdb/layer_name")
    >>>    >      df <- arc.select(d) # here, you can filter columns and
    >>>    >      attributes,
    >>>    >      see [2]
    >>>    >      # create an sf object
    >>>    >      df.sf <- arc.data2sf(df)
    >>>    >      # alternatively, create an sp object
    >>>    >      df.sp <- arc.data2sp(df)
    >>>    >
    >>>    >      You can also write the results back to a geodatabase, or any
    >>>    >      other
    >>>    >      format that ArcGIS understands. Another option is trying the
    >>>    >      SpatiaLite version of the data at the URL you posted. You should
    >>>    >      be able to access this using R directly, provided your rgdal
    >>>    >      installation is correctly built to read spatialite databases. If
    >>>    >      it is, try the same process you mentioned using rgdal, but point
    >>>    >      it at the SpatialLite database instead. You could also use
    >>>    >      command-line OGR to convert the data, that has a few options
    >>>    >      like
    >>>    >      where clause filtering that aren't directly available via
    >>>    >      readOGR.
    >>>    >
    >>>    >      If neither of these options work, let me know and I can convert
    >>>    >      the data for you into a format of your preference.
    >>>    >
    >>>    >      Cheers,
    >>>    >      Shaun
    >>>    >
    >>>    >      1.
    >>>    >      https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_R-2DArcGIS_r-2Dbridge-2Dinstall&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=yckcjR6k3nADiVsNiAhGwcZB--0A8DQgvLSJ27upmyk&m=dkecE8PWOn5sSrtSXqX2R-VwJuFH_In4BvpC5da4LJ0&s=nRO2IG9dlrdKYGMSp3rCf7nwJqRFQoIWnY5zSFrPOQM&e=
    >>>    >      2.
    >>>    >      https://urldefense.proofpoint.com/v2/url?u=https-3A__rdrr.io_github_R-2DArcGIS_r-2Dbridge_man_arc.select.html&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=yckcjR6k3nADiVsNiAhGwcZB--0A8DQgvLSJ27upmyk&m=dkecE8PWOn5sSrtSXqX2R-VwJuFH_In4BvpC5da4LJ0&s=89N-cLe5N3dhZ6MTsM2OAYwmDImBH88ZrVaA5Hos0n4&e=
    >>>    >
    >>>    >
    >>>    >
    >>>    >      On 5/2/18, 1:34 PM, "R-sig-Geo on behalf of Aguirre Perez,
    >>>    >      Roman"
    >>>    >      <r-sig-geo-bounces at r-project.org on behalf of
    >>>    >      ra454 at exeter.ac.uk>
    >>>    >      wrote:
    >>>    >
    >>>    >          Hi everyone,
    >>>    >
    >>>    >          I?ve been struggling with a ESRI Geodatabase file
    >>>    >          (clc12_Version_18_5.gdb) which is a layer of land cover
    >>>    >          classes available on
    >>>    >
    >>>    >          https://urldefense.proofpoint.com/v2/url?u=https-3A__land.copernicus.eu_pan-2Deuropean_corine-2Dland-2Dcover_clc-2D2012-3Ftab-3Ddownload&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=9LaO4HiB5C5ewiuN_IeSQJSgq2tl5_-oMECPChtZa_U&e=
    >>>    >
    >>>    >          whose size is 2.61 GB once unzipped.
    >>>    >
    >>>    >          My ultimate task is to overlay it with the last NUTS3
    >>>    >          administrative boundaries shapefile (2013) available on
    >>>    >
    >>>    >          https://urldefense.proofpoint.com/v2/url?u=http-3A__ec.europa.eu_eurostat_web_gisco_geodata_reference-2Ddata_administrative-2Dunits-2Dstatistical-2Dunits&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=VExYSoR8FY_vhZaPNJpoOx0ZCZNMU9hMTtlGJZj2joU&e=
    >>>    >
    >>>    >          in order to compute the area covered by each class within
    >>>    >          each
    >>>    >          NUTS3 region.
    >>>    >
    >>>    >          Despite the ease of friendly software for performing this
    >>>    >          task, haven?t been capable of doing it - GRASS didn?t load
    >>>    >          the
    >>>    >          file as the log reports problems with the polygons, QGIS
    >>>    >          shows
    >>>    >          a warning regarding a specific object and ArcGIS got frozen.
    >>>    >          I
    >>>    >          guess it?s because the PC I used doesn?t have enough
    >>>    >          capacity.
    >>>    >          Unfortunately, I don?t have access to a more powerful one.
    >>>    >
    >>>    >          Anyway, I decided to try with R -after all, I?ll perform my
    >>>    >          analysis with it. So I started exploring this GDB with
    >>>    >          rgdal:
    >>>    >
    >>>    >          ogrInfo(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
    >>>    >
    >>>    >          Source:
    >>>    >          "/Users/Roman/Desktop/clc12gdb/clc12_Version_18_5.gdb",
    >>>    >          layer: "clc12_Version_18_5"
    >>>    >          Driver: OpenFileGDB;
    >>>    >          number of rows: 2370829
    >>>    >          Feature type: wkbPolygon with 3 dimensions
    >>>    >          Extent: (-2693292 -3086662) - (10037210 5440568)
    >>>    >          Null geometry IDs: 2156240
    >>>    >          CRS: +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000
    >>>    >          +y_0=3210000
    >>>    >          +ellps=GRS80 +units=m +no_defs
    >>>    >          Number of fields: 6
    >>>    >          name                      type  length  typeName
    >>>    >          1 code_12              4       3           String
    >>>    >          2 ID                         4       18         String
    >>>    >          3 Remark               4       20         String
    >>>    >          4 Area_Ha             2       0           Real
    >>>    >          5 Shape_Length   2       0           Real
    >>>    >          6 Shape_Area       2       0           Real
    >>>    >
    >>>    >          Then I tried to load it typing
    >>>    >
    >>>    >          clc<-readOGR(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
    >>>    >
    >>>    >          After 3-5 minutes, it appears the following text:
    >>>    >
    >>>    >          OGR data source with driver: OpenFileGDB
    >>>    >          Source:
    >>>    >          "/Users/Roman/Desktop/clc12shp/clc12_Version_18_5.gdb",
    >>>    >          layer:
    >>>    >          "clc12_Version_18_5"
    >>>    >          with 2370829 features
    >>>    >          It has 6 fields
    >>>    >
    >>>    >          Unfortunately, after trying 5 times (each one took around 8
    >>>    >          hours) I couldn?t get anything but the following messages:
    >>>    >
    >>>    >          Warning messages:
    >>>    >          1: In readOGR(dsn = "clc12_Version_18_5.gdb", layer =
    >>>    >          "clc12_Version_18_5") :
    >>>    >          Dropping null geometries: 2156240
    >>>    >          2: In readOGR(dsn = "clc12_Version_18_5.gdb", layer =
    >>>    >          "clc12_Version_18_5") :
    >>>    >          Z-dimension discarded
    >>>    >
    >>>    >          Could anyone advise me how to tackle it? I also would
    >>>    >          appreciate suggestions on how to work with geodatabases -
    >>>    >          it?s
    >>>    >          my first time I work with these kind of files so I don?t
    >>>    >          even
    >>>    >          know their structure.
    >>>    >
    >>>    >          By the way, these are my computer and software
    >>>    >          specifications:
    >>>    >
    >>>    >          MacBook Pro 2012
    >>>    >          Processor 2.6 GHz Intel Core i7
    >>>    >          Memory 16 GB DDR3
    >>>    >          R 3.5.0
    >>>    >          RStudio 1.1.447
    >>>    >
    >>>    >
    >>>    >          Best,
    >>>    >          Roman.
    >>>    >
    >>>    >
    >>>    >
    >>>    >
    >>>    >   _______________________________________________
    >>>    >   R-sig-Geo mailing list
    >>>    >   R-sig-Geo at r-project.org
    >>>    >   https://stat.ethz.ch/mailman/listinfo/r-sig-geo
    >>>
    >>>      --
    >>>      Roger Bivand
    >>>      Department of Economics, Norwegian School of Economics,
    >>>      Helleveien 30, N-5045 Bergen, Norway.
    >>>      voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
    >>>      http://orcid.org/0000-0003-2392-6140
    >>>      https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
    >>>
    >>> 
    >> 
    >> 
    >
    >
    
    -- 
    Roger Bivand
    Department of Economics, Norwegian School of Economics,
    Helleveien 30, N-5045 Bergen, Norway.
    voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
    http://orcid.org/0000-0003-2392-6140
    https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From nr@j@ @ending from tn@u@@c@in  Mon May  7 06:04:16 2018
From: nr@j@ @ending from tn@u@@c@in (Raja Natarajan)
Date: Mon, 7 May 2018 09:34:16 +0530
Subject: [R-sig-Geo] Tutorial on reading hyperspectral data
In-Reply-To: <CA+wLXTJ6byXFMXGUZhVFw7ujC=3HA1x45+4xW8StGE5j3-_KaQ@mail.gmail.com>
References: <CA+wLXTJ6byXFMXGUZhVFw7ujC=3HA1x45+4xW8StGE5j3-_KaQ@mail.gmail.com>
Message-ID: <CA+wLXTJsfmR1CB2EizPpevokaK-06iCejDm2fwXSOqoKK7pxVw@mail.gmail.com>

Hi

it was misspelled as ..astrology...

it is *"hyperspectral satellite images"*

*Thanks in advance*

With sincere thanks
*UNEP SDG13: Take urgent action to combat climate change and its impacts*
N Raja,
Assistant Professor (Computer Science),
Department of Tree Breeding,
Forest College & Research Institute,
Tamil Nadu Agricultural University,
Mettupalayam  - 641 301.
Tamil Nadu State, INDIA
Phone Office 91-4254-271509,
Hand Phone  91-9488030292,
e-mail ID: nraja at tnau.ac.in
                mail2nraja at gmail.com

On Sat, May 5, 2018 at 11:01 PM, Raja Natarajan <nraja at tnau.ac.in> wrote:

> Hi
>
> Greetings
>
> Please share any tutorial on read and open hyperspectral astrology images
> using R
>

	[[alternative HTML version deleted]]


From edzer@pebe@m@ @ending from uni-muen@ter@de  Mon May  7 07:03:18 2018
From: edzer@pebe@m@ @ending from uni-muen@ter@de (Edzer Pebesma)
Date: Mon, 7 May 2018 07:03:18 +0200
Subject: [R-sig-Geo] Tutorial on reading hyperspectral data
In-Reply-To: <CA+wLXTJ6byXFMXGUZhVFw7ujC=3HA1x45+4xW8StGE5j3-_KaQ@mail.gmail.com>
References: <CA+wLXTJ6byXFMXGUZhVFw7ujC=3HA1x45+4xW8StGE5j3-_KaQ@mail.gmail.com>
Message-ID: <ee6efec6-04ec-39ef-772f-029fe8c2769d@uni-muenster.de>

You may want to look into hsdar,
https://cran.r-project.org/web/packages/hsdar/index.html

On 05/05/2018 07:31 PM, Raja Natarajan wrote:
> Hi
> 
> Greetings
> 
> Please share any tutorial on read and open hyperspectral astrology images
> using R
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48151 Muenster, Germany
Phone: +49 251 8333081


From Roger@Biv@nd @ending from nhh@no  Mon May  7 09:36:09 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Mon, 7 May 2018 09:36:09 +0200
Subject: [R-sig-Geo] Issues with a GDB file in R?
In-Reply-To: <CC45C4FA-F33B-4687-BD82-0F7C41B9A062@exeter.ac.uk>
References: <13F59690-AB9E-40B2-B9F7-2474C9771F52@exeter.ac.uk>
 <AFA371A2-4A57-4038-AD9B-2A6C894E2A86@esri.com>
 <A814689E-6CF5-404D-94FD-841FB832FFAB@exeter.ac.uk>
 <alpine.LFD.2.21.1805031321160.14684@reclus.nhh.no>
 <977196B3-00A0-4D48-8E73-6AAF9988F1B1@exeter.ac.uk>
 <alpine.LFD.2.21.1805032014310.22459@reclus.nhh.no>
 <alpine.LFD.2.21.1805042035570.16297@reclus.nhh.no>
 <alpine.LFD.2.21.1805051300370.18610@reclus.nhh.no>
 <CC45C4FA-F33B-4687-BD82-0F7C41B9A062@exeter.ac.uk>
Message-ID: <alpine.LFD.2.21.1805070912050.3455@reclus.nhh.no>

On Sun, 6 May 2018, Aguirre Perez, Roman wrote:

> On 05/05/2018, 12:03, "Roger Bivand" <Roger.Bivand at nhh.no> wrote:
>
>    On Fri, 4 May 2018, Roger Bivand wrote:
>
>    > On Thu, 3 May 2018, Roger Bivand wrote:
>    >
>    >>  On Thu, 3 May 2018, Aguirre Perez, Roman wrote:
>    >>
>    >>>   Hi again,
>    >>>
>    >>>   first of all, thanks a lot for your comments. It's becoming quite
>    >>>   interesting how to perform this task with such amount of data.
>    >>>
>    >>>
>    >>>   Here is an update...
>    >>>
>    >>>   Cotton, I could read the geodatabase by using the commands I shared.
>    >>>   However, my R session crashed after overlaying it with a small set of
>    >>>   polygons. I guess it was because the size of the sp object (around 14.5
>    >>>   GB). It's also worth mentioning that it was just a "multipolygon" (is
>    >>>   that
>    >>>   the correct word?) formed by 2370829 polygons. I haven?t succeeded on
>    >>>   installing the sf package, but I will keep trying it.
>    >>>
>    >>>   Melanie, I already downloaded and read the geoTiff version. At first
>    >>>   sight, it seems that this object doesn?t have enough features as to
>    >>>   perform the overlying. I might have a biased idea of how raster objects
>    >>>   work - I'm too stick to the representation of shapefiles which sounds
>    >>>   quite related with Roger's idea. So I will start to explore it in order
>    >>>   to
>    >>>   gain a bit more understanding on it.
>    >>>
>    >>>   Roger, I certainly need to know which category is associated with each
>    >>>   CLC
>    >>>   polygon in order to compute the area covered by each of these classes
>    >>>   within each NUTS3 region. Therefore, I still need to use a vector-vector
>    >>>   overlay, right?
>    >>
>    >>  On the contrary. The geoTiffs are coded as described in the documentation.
>    >>  Your output is simply the count of raster cells by NUTS3 for each of the
>    >>  categories. The geoTiff is in ETRS_1989_LAEA, so is projected; it includes
>    >>  a lot of sea and no data because of the French overseas territories.
>    >>
>    >>  You could possibly use PostGIS to do the intersections, or use GRASS for
>    >>  raster-vector counts (say through rgrass7). In R, you would want to add a
>    >>  NUTS3 ID band to the land cover raster, then aggregate by NUTS3 ID.
>    >>
>    >>  I would suggest using GRASS as the most obvious route, reading the raster,
>    >>  reading the NUTS3 boundaries into a separate location, projecting to LAEA,
>    >>  then rasterising the NUTS3 regions (v.to.rast) and running r.cross. You
>    >>  get 32K output categories, the 48 corine categories times the count of
>    >>  NUTS3 regions minus the nulls (there aren't many glaciers in most
>    >>  regions). You'll then need to match back the Corine codes and the NUTS3
>    >>  codes - see in the category label file shown by r.category.
>    >>
>    >>  I'll try to provide code tomorrow.
>    >
>    > Combining R and GRASS seems to work, but no guarantees.
>    >
>    > library(sp)
>    > library(rgdal)
>    > Gi <- GDALinfo("g250_clc12_V18_5.tif")
>    > makeSG <- function(x) {
>    >   stopifnot(class(x) == "GDALobj")
>    >   p4 <- attr(x, "projection")
>    >   gt <- GridTopology(c(x[4]+(x[6]/2), x[5]+(x[7]/2)), c(x[6], x[7]),
>    >     c(x[2], x[1]))
>    >  SpatialGrid(gt, CRS(p4))
>    > }
>    > SG <- makeSG(Gi)
>    > nuts_ll <- readOGR("NUTS_RG_01M_2013_4326_LEVL_3.shp")
>    > nuts_laea <- spTransform(nuts_ll, CRS(attr(Gi, "projection")))
>    > library(rgrass7)
>    > td <- tempdir()
>    > iG <- initGRASS("/home/rsb/topics/grass/g740/grass-7.4.0", td, SG)
>    > # your GRASS will be where you installed it
>    > writeVECT(nuts_laea, "nuts", v.in.ogr_flags="o")
>    > execGRASS("r.in.gdal", input="g250_clc12_V18_5.tif", output="corine",
>    >  flags="o")
>    > execGRASS("v.to.rast", input="nuts", output="nuts3", use="cat",
>    >  label_column="FID")
>    > execGRASS("r.cross", input="nuts3,corine", output="cross_nuts3")
>    > r_stats0 <- execGRASS("r.stats", input="cross_nuts3", flags="a",
>    >  intern=TRUE)
>    > r_stats1 <- gsub("\\*", "NA", r_stats0)
>    > con_stats <- textConnection(r_stats1)
>    > stats <- read.table(con_stats, header=FALSE, col.names=c("cross_cat",
>    >  "area"), colClasses=c("integer", "numeric"))
>    > close(con_stats)
>    > r_cats0 <- execGRASS("r.category", map="cross_nuts3", intern=TRUE)
>    > r_cats1 <- gsub(";", "", r_cats0)
>    > r_cats2 <- gsub("\t", " ", r_cats1)
>    > r_cats3 <- gsub("no data", "no_data", r_cats2)
>    > r_cats4 <- gsub("category ", "", r_cats3)
>    > r_cats4[1] <- paste0(r_cats4[1], "NA NA")
>    > r_cats_split <- strsplit(r_cats4, " ")
>    > cats <- data.frame(cross_cat=as.integer(sapply(r_cats_split, "[", 1)),
>    >   nuts=sapply(r_cats_split, "[", 2),
>    >   corine=as.integer(sapply(r_cats_split, "[", 3)))
>    > catstats <- merge(cats, stats, by="cross_cat", all=TRUE)
>    > agg_areas <- tapply(catstats$area, list(catstats$nuts, catstats$corine),
>    >  sum)
>    > library(foreign)
>    > corine_labels <- read.dbf("g250_clc12_V18_5.tif.vat.dbf", as.is=TRUE)
>    > o <- match(colnames(agg_areas), as.character(corine_labels$Value))
>    > colnames(agg_areas) <- corine_labels$LABEL3[o]
>    > agg_areas_df <- as.data.frame(agg_areas)
>    > agg_areas_df1 <- agg_areas_df[-which(!(row.names(agg_areas_df) %in%
>    >   as.character(nuts_ll$FID))),] # dropping "NA"      "no_data"
>    >
>    > This should be ready to merge with the NUTS3 boundaries, if needed.
>    >
>    > agg_areas_df1$FID <- row.names(agg_areas_df1)
>    > nuts_corine <- merge(nuts_laea, agg_areas_df1, by="FID")
>    >
>
>    And to write out as GPKG:
>
>    names(nuts_corine)[1] <- "FID_"
>    writeOGR(nuts_corine, "nuts_corine.gpkg", layer="corine", driver="GPKG")
>
>    It seems that at least this driver treats "FID" as a reserved field name.
>
>    > For the vector parts you could use sf and the provisional rgrass7sf on
>    > github, but that wouldn't yet let you construct a skeleton SpatialGrid to
>    > define the GRASS location. Using GRASS for the heavy lifting (the raster is
>    > 51000 by 35000), and avoiding vector for overlay, this doesn't need much
>    > memory (GRASS handles rasters by row). The GRASS temporary location only
>    > takes 130MB of disk space. You could go for the 100m raster resolution, but I
>    > doubt that the outcome would vary much - anyone like to try?
>    >
>    > If the sub-polygons by NUTS and corine categories are actually needed, the
>    > output of r.cross could be passed to r.to.vect:
>    >
>    > execGRASS("r.to.vect", input="cross_nuts3", output="cross_nuts3",
>    >   type="area")
>    >
>    > but this is more demanding in memory terms.
>
> Hi Roger,
>
> thanks a lot again for helping me with this issue.
>
>
> Unfortunately, I haven't managed to call GRASS within R, neither install 
> sf. My guess is that those issues are because I'm using both newest 
> versions OS X High Sierra and R 3.5.0 which are not stable yet.

You do not need sf. You do need GRASS, and, yes, OSX causes a lot of 
problems because it is no longer attentive to the needs of numerical 
analysts (certification of installs mandated at cost to FOSS communities; 
gaping empty root password; only interested in pay-for software; never 
contributes to FOSS AFAIK). Apple does not contribute to R.

>
>    Reading into R is not possible, object too large.
>
> Bearing in mind the previous issues plus this last comment, I decided to 
> use a PC with another OS (Ubuntu) aiming at solving them and working 
> with a bit more space (32 GB).

Wrong comment. The vector corine object is impossible to handle anywhere, 
and probably should never have been constructed. I really doubt that it is 
more "accurate" than the 100m raster, and doubt that the areas sums by 
NUTS3 region differ much between 250m and 100m.

You need to go back to the way in which Corine was derived, and to your 
actual needs (which you have not described). If what you need are areas of 
Corine classes by NUTS3 region, the code I provided gives you this. If 
what you need is the full intersection of Corine classes and all NUTS3 
regions, then you cannot visualize them (without zooming - rendering is 
raster anyway) nor can you analyze them in any meaningful way, so you'd 
need to revisit you research question. An intersection of a subset of 
NUTS3 regions yielding raster patches or vector entities is possible and 
could be visualized, but you seem to want the full extent of the NUTS3 
regions.

If you need the intersection between one/few NUTS3 region(s) and Corine, 
you can still use the raster approach, but I don't know PostGIS well 
enough to advise (forthcoming R Journal article; 
https://cran.r-project.org/package=rpostgis). You can read the NUTS3 
boundaries into R, but probably neither of the Corine vector files (not 
just memory, you mentioned earlier that they suffered from topological 
issues which would prevent intersection without intensive cleaning.

Using GRASS, you get the best of both worlds, script in R and run the 
analysis at scale in GRASS using memory-conserving implementations.

Roger

>
>    Roger
>
> In the meantime, I really would appreciate you guidance for gaining 
> background on this subject. Could you please suggest me resources to 
> better understand the features of objects involved in Spatial 
> Statistics? I should mention that the knowledge I have about it is 
> resumed in your book Applied Spatial Data Analysis with R.
>
>
> Best,
> Roman.
>
>    >
>    > Interesting case, and it does show that combining GIS and R delivers the
>    > goods - SAGA would probably work equivalently.
>    >
>    > Roger
>    >
>    >>
>    >>  Roger
>    >>
>    >>>
>    >>>   I really appreciate any feedback in advance as well as details that I
>    >>>   should take into account to understand more about how to work with this
>    >>>   kind of data. I will also keep you up to date on how it goes if you
>    >>>   like.
>    >>>
>    >>>
>    >>>   Best,
>    >>>   Roman.
>    >>>
>    >>>   On 03/05/2018, 12:26, "Roger Bivand" <Roger.Bivand at nhh.no> wrote:
>    >>>
>    >>>      On Thu, 3 May 2018, Aguirre Perez, Roman wrote:
>    >>>
>    >>>    >   Hello Shaun,
>    >>>    >
>    >>>    >   Thanks a lot for replying and providing me alternative options.
>    >>>    >
>    >>>    >
>    >>>    >   Unfortunately, I can't try both options anymore as I ran out of
>    >>>    >   ArcGIS
>    >>>    >   due to I was using a university PC which is not available now (I
>    >>>    >   installed an ArcGIS trial version there), but I'll try it later. I
>    >>>    >   also
>    >>>    >   failed on installing the sf package - I'll dig a bit more on it.
>    >>>    >   Nevertheless, I already downloaded the SpatialLite version so I'll
>    >>>    >   try
>    >>>    >   the second option and I'll let you know how it goes.
>    >>>
>    >>>      I think Melanie got it right - the apparent extra detail and
>    >>>      precision
>    >>>      you'd get from vector-vector overlay is illusory, so going with
>    >>>      geoTiff
>    >>>      should get you there (you can check to see whether 100m resolution
>    >>>      differs
>    >>>      from 250m). The only reason to choose vector-vector would be that the
>    >>>      Corine vector contains categories not represented in the raster
>    >>>      version.
>    >>>      Using raster also steps around the polygon deficiencies in the GDB
>    >>>      (and
>    >>>      probably SQLite) representations.
>    >>>
>    >>>      Roger
>    >>>
>    >>>    >
>    >>>    >
>    >>>    >   Regards,
>    >>>    >   Roman.
>    >>>    >
>    >>>    >   On 02/05/2018, 18:53, "Shaun Walbridge" <SWalbridge at esri.com>
>    >>>    >   wrote:
>    >>>    >
>    >>>    >      Hello Roman,
>    >>>    >
>    >>>    >      A couple of suggested options: You can try and use the
>    >>>    >      arcgisbinding package [1] to pull the data directly into R via
>    >>>    >      ArcGIS, as you mentioned you have ArcGIS available [presumably
>    >>>    >      on
>    >>>    >      Windows or in a VM]. It will access the data directly, and let
>    >>>    >      you
>    >>>    >      create sp and sf objects out of Geodatabases with little work. A
>    >>>    >      basic workflow looks like this:
>    >>>    >
>    >>>    >      d <- arc.open("path/file.gdb/layer_name")
>    >>>    >      df <- arc.select(d) # here, you can filter columns and
>    >>>    >      attributes,
>    >>>    >      see [2]
>    >>>    >      # create an sf object
>    >>>    >      df.sf <- arc.data2sf(df)
>    >>>    >      # alternatively, create an sp object
>    >>>    >      df.sp <- arc.data2sp(df)
>    >>>    >
>    >>>    >      You can also write the results back to a geodatabase, or any
>    >>>    >      other
>    >>>    >      format that ArcGIS understands. Another option is trying the
>    >>>    >      SpatiaLite version of the data at the URL you posted. You should
>    >>>    >      be able to access this using R directly, provided your rgdal
>    >>>    >      installation is correctly built to read spatialite databases. If
>    >>>    >      it is, try the same process you mentioned using rgdal, but point
>    >>>    >      it at the SpatialLite database instead. You could also use
>    >>>    >      command-line OGR to convert the data, that has a few options
>    >>>    >      like
>    >>>    >      where clause filtering that aren't directly available via
>    >>>    >      readOGR.
>    >>>    >
>    >>>    >      If neither of these options work, let me know and I can convert
>    >>>    >      the data for you into a format of your preference.
>    >>>    >
>    >>>    >      Cheers,
>    >>>    >      Shaun
>    >>>    >
>    >>>    >      1.
>    >>>    >      https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_R-2DArcGIS_r-2Dbridge-2Dinstall&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=yckcjR6k3nADiVsNiAhGwcZB--0A8DQgvLSJ27upmyk&m=dkecE8PWOn5sSrtSXqX2R-VwJuFH_In4BvpC5da4LJ0&s=nRO2IG9dlrdKYGMSp3rCf7nwJqRFQoIWnY5zSFrPOQM&e=
>    >>>    >      2.
>    >>>    >      https://urldefense.proofpoint.com/v2/url?u=https-3A__rdrr.io_github_R-2DArcGIS_r-2Dbridge_man_arc.select.html&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=yckcjR6k3nADiVsNiAhGwcZB--0A8DQgvLSJ27upmyk&m=dkecE8PWOn5sSrtSXqX2R-VwJuFH_In4BvpC5da4LJ0&s=89N-cLe5N3dhZ6MTsM2OAYwmDImBH88ZrVaA5Hos0n4&e=
>    >>>    >
>    >>>    >
>    >>>    >
>    >>>    >      On 5/2/18, 1:34 PM, "R-sig-Geo on behalf of Aguirre Perez,
>    >>>    >      Roman"
>    >>>    >      <r-sig-geo-bounces at r-project.org on behalf of
>    >>>    >      ra454 at exeter.ac.uk>
>    >>>    >      wrote:
>    >>>    >
>    >>>    >          Hi everyone,
>    >>>    >
>    >>>    >          I?ve been struggling with a ESRI Geodatabase file
>    >>>    >          (clc12_Version_18_5.gdb) which is a layer of land cover
>    >>>    >          classes available on
>    >>>    >
>    >>>    >          https://urldefense.proofpoint.com/v2/url?u=https-3A__land.copernicus.eu_pan-2Deuropean_corine-2Dland-2Dcover_clc-2D2012-3Ftab-3Ddownload&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=9LaO4HiB5C5ewiuN_IeSQJSgq2tl5_-oMECPChtZa_U&e=
>    >>>    >
>    >>>    >          whose size is 2.61 GB once unzipped.
>    >>>    >
>    >>>    >          My ultimate task is to overlay it with the last NUTS3
>    >>>    >          administrative boundaries shapefile (2013) available on
>    >>>    >
>    >>>    >          https://urldefense.proofpoint.com/v2/url?u=http-3A__ec.europa.eu_eurostat_web_gisco_geodata_reference-2Ddata_administrative-2Dunits-2Dstatistical-2Dunits&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=VExYSoR8FY_vhZaPNJpoOx0ZCZNMU9hMTtlGJZj2joU&e=
>    >>>    >
>    >>>    >          in order to compute the area covered by each class within
>    >>>    >          each
>    >>>    >          NUTS3 region.
>    >>>    >
>    >>>    >          Despite the ease of friendly software for performing this
>    >>>    >          task, haven?t been capable of doing it - GRASS didn?t load
>    >>>    >          the
>    >>>    >          file as the log reports problems with the polygons, QGIS
>    >>>    >          shows
>    >>>    >          a warning regarding a specific object and ArcGIS got frozen.
>    >>>    >          I
>    >>>    >          guess it?s because the PC I used doesn?t have enough
>    >>>    >          capacity.
>    >>>    >          Unfortunately, I don?t have access to a more powerful one.
>    >>>    >
>    >>>    >          Anyway, I decided to try with R -after all, I?ll perform my
>    >>>    >          analysis with it. So I started exploring this GDB with
>    >>>    >          rgdal:
>    >>>    >
>    >>>    >          ogrInfo(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
>    >>>    >
>    >>>    >          Source:
>    >>>    >          "/Users/Roman/Desktop/clc12gdb/clc12_Version_18_5.gdb",
>    >>>    >          layer: "clc12_Version_18_5"
>    >>>    >          Driver: OpenFileGDB;
>    >>>    >          number of rows: 2370829
>    >>>    >          Feature type: wkbPolygon with 3 dimensions
>    >>>    >          Extent: (-2693292 -3086662) - (10037210 5440568)
>    >>>    >          Null geometry IDs: 2156240
>    >>>    >          CRS: +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000
>    >>>    >          +y_0=3210000
>    >>>    >          +ellps=GRS80 +units=m +no_defs
>    >>>    >          Number of fields: 6
>    >>>    >          name                      type  length  typeName
>    >>>    >          1 code_12              4       3           String
>    >>>    >          2 ID                         4       18         String
>    >>>    >          3 Remark               4       20         String
>    >>>    >          4 Area_Ha             2       0           Real
>    >>>    >          5 Shape_Length   2       0           Real
>    >>>    >          6 Shape_Area       2       0           Real
>    >>>    >
>    >>>    >          Then I tried to load it typing
>    >>>    >
>    >>>    >          clc<-readOGR(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
>    >>>    >
>    >>>    >          After 3-5 minutes, it appears the following text:
>    >>>    >
>    >>>    >          OGR data source with driver: OpenFileGDB
>    >>>    >          Source:
>    >>>    >          "/Users/Roman/Desktop/clc12shp/clc12_Version_18_5.gdb",
>    >>>    >          layer:
>    >>>    >          "clc12_Version_18_5"
>    >>>    >          with 2370829 features
>    >>>    >          It has 6 fields
>    >>>    >
>    >>>    >          Unfortunately, after trying 5 times (each one took around 8
>    >>>    >          hours) I couldn?t get anything but the following messages:
>    >>>    >
>    >>>    >          Warning messages:
>    >>>    >          1: In readOGR(dsn = "clc12_Version_18_5.gdb", layer =
>    >>>    >          "clc12_Version_18_5") :
>    >>>    >          Dropping null geometries: 2156240
>    >>>    >          2: In readOGR(dsn = "clc12_Version_18_5.gdb", layer =
>    >>>    >          "clc12_Version_18_5") :
>    >>>    >          Z-dimension discarded
>    >>>    >
>    >>>    >          Could anyone advise me how to tackle it? I also would
>    >>>    >          appreciate suggestions on how to work with geodatabases -
>    >>>    >          it?s
>    >>>    >          my first time I work with these kind of files so I don?t
>    >>>    >          even
>    >>>    >          know their structure.
>    >>>    >
>    >>>    >          By the way, these are my computer and software
>    >>>    >          specifications:
>    >>>    >
>    >>>    >          MacBook Pro 2012
>    >>>    >          Processor 2.6 GHz Intel Core i7
>    >>>    >          Memory 16 GB DDR3
>    >>>    >          R 3.5.0
>    >>>    >          RStudio 1.1.447
>    >>>    >
>    >>>    >
>    >>>    >          Best,
>    >>>    >          Roman.
>    >>>    >
>    >>>    >
>    >>>    >
>    >>>    >
>    >>>    >   _______________________________________________
>    >>>    >   R-sig-Geo mailing list
>    >>>    >   R-sig-Geo at r-project.org
>    >>>    >   https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>    >>>
>    >>>      --
>    >>>      Roger Bivand
>    >>>      Department of Economics, Norwegian School of Economics,
>    >>>      Helleveien 30, N-5045 Bergen, Norway.
>    >>>      voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>    >>>      http://orcid.org/0000-0003-2392-6140
>    >>>      https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>    >>>
>    >>>
>    >>
>    >>
>    >
>    >
>
>    --
>    Roger Bivand
>    Department of Economics, Norwegian School of Economics,
>    Helleveien 30, N-5045 Bergen, Norway.
>    voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>    http://orcid.org/0000-0003-2392-6140
>    https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From r@454 @ending from exeter@@c@uk  Mon May  7 13:28:50 2018
From: r@454 @ending from exeter@@c@uk (Aguirre Perez, Roman)
Date: Mon, 7 May 2018 11:28:50 +0000
Subject: [R-sig-Geo] Issues with a GDB file in R?
In-Reply-To: <alpine.LFD.2.21.1805070912050.3455@reclus.nhh.no>
References: <13F59690-AB9E-40B2-B9F7-2474C9771F52@exeter.ac.uk>
 <AFA371A2-4A57-4038-AD9B-2A6C894E2A86@esri.com>
 <A814689E-6CF5-404D-94FD-841FB832FFAB@exeter.ac.uk>
 <alpine.LFD.2.21.1805031321160.14684@reclus.nhh.no>
 <977196B3-00A0-4D48-8E73-6AAF9988F1B1@exeter.ac.uk>
 <alpine.LFD.2.21.1805032014310.22459@reclus.nhh.no>
 <alpine.LFD.2.21.1805042035570.16297@reclus.nhh.no>
 <alpine.LFD.2.21.1805051300370.18610@reclus.nhh.no>
 <CC45C4FA-F33B-4687-BD82-0F7C41B9A062@exeter.ac.uk>
 <alpine.LFD.2.21.1805070912050.3455@reclus.nhh.no>
Message-ID: <7F036E91-6F88-452B-9AAD-AEAE15155F69@exeter.ac.uk>



?On 07/05/2018, 08:36, "Roger Bivand" <Roger.Bivand at nhh.no> wrote:

    On Sun, 6 May 2018, Aguirre Perez, Roman wrote:
    
    > On 05/05/2018, 12:03, "Roger Bivand" <Roger.Bivand at nhh.no> wrote:
    >
    >    On Fri, 4 May 2018, Roger Bivand wrote:
    >
    >    > On Thu, 3 May 2018, Roger Bivand wrote:
    >    >
    >    >>  On Thu, 3 May 2018, Aguirre Perez, Roman wrote:
    >    >>
    >    >>>   Hi again,
    >    >>>
    >    >>>   first of all, thanks a lot for your comments. It's becoming quite
    >    >>>   interesting how to perform this task with such amount of data.
    >    >>>
    >    >>>
    >    >>>   Here is an update...
    >    >>>
    >    >>>   Cotton, I could read the geodatabase by using the commands I shared.
    >    >>>   However, my R session crashed after overlaying it with a small set of
    >    >>>   polygons. I guess it was because the size of the sp object (around 14.5
    >    >>>   GB). It's also worth mentioning that it was just a "multipolygon" (is
    >    >>>   that
    >    >>>   the correct word?) formed by 2370829 polygons. I haven?t succeeded on
    >    >>>   installing the sf package, but I will keep trying it.
    >    >>>
    >    >>>   Melanie, I already downloaded and read the geoTiff version. At first
    >    >>>   sight, it seems that this object doesn?t have enough features as to
    >    >>>   perform the overlying. I might have a biased idea of how raster objects
    >    >>>   work - I'm too stick to the representation of shapefiles which sounds
    >    >>>   quite related with Roger's idea. So I will start to explore it in order
    >    >>>   to
    >    >>>   gain a bit more understanding on it.
    >    >>>
    >    >>>   Roger, I certainly need to know which category is associated with each
    >    >>>   CLC
    >    >>>   polygon in order to compute the area covered by each of these classes
    >    >>>   within each NUTS3 region. Therefore, I still need to use a vector-vector
    >    >>>   overlay, right?
    >    >>
    >    >>  On the contrary. The geoTiffs are coded as described in the documentation.
    >    >>  Your output is simply the count of raster cells by NUTS3 for each of the
    >    >>  categories. The geoTiff is in ETRS_1989_LAEA, so is projected; it includes
    >    >>  a lot of sea and no data because of the French overseas territories.
    >    >>
    >    >>  You could possibly use PostGIS to do the intersections, or use GRASS for
    >    >>  raster-vector counts (say through rgrass7). In R, you would want to add a
    >    >>  NUTS3 ID band to the land cover raster, then aggregate by NUTS3 ID.
    >    >>
    >    >>  I would suggest using GRASS as the most obvious route, reading the raster,
    >    >>  reading the NUTS3 boundaries into a separate location, projecting to LAEA,
    >    >>  then rasterising the NUTS3 regions (v.to.rast) and running r.cross. You
    >    >>  get 32K output categories, the 48 corine categories times the count of
    >    >>  NUTS3 regions minus the nulls (there aren't many glaciers in most
    >    >>  regions). You'll then need to match back the Corine codes and the NUTS3
    >    >>  codes - see in the category label file shown by r.category.
    >    >>
    >    >>  I'll try to provide code tomorrow.
    >    >
    >    > Combining R and GRASS seems to work, but no guarantees.
    >    >
    >    > library(sp)
    >    > library(rgdal)
    >    > Gi <- GDALinfo("g250_clc12_V18_5.tif")
    >    > makeSG <- function(x) {
    >    >   stopifnot(class(x) == "GDALobj")
    >    >   p4 <- attr(x, "projection")
    >    >   gt <- GridTopology(c(x[4]+(x[6]/2), x[5]+(x[7]/2)), c(x[6], x[7]),
    >    >     c(x[2], x[1]))
    >    >  SpatialGrid(gt, CRS(p4))
    >    > }
    >    > SG <- makeSG(Gi)
    >    > nuts_ll <- readOGR("NUTS_RG_01M_2013_4326_LEVL_3.shp")
    >    > nuts_laea <- spTransform(nuts_ll, CRS(attr(Gi, "projection")))
    >    > library(rgrass7)
    >    > td <- tempdir()
    >    > iG <- initGRASS("/home/rsb/topics/grass/g740/grass-7.4.0", td, SG)
    >    > # your GRASS will be where you installed it
    >    > writeVECT(nuts_laea, "nuts", v.in.ogr_flags="o")
    >    > execGRASS("r.in.gdal", input="g250_clc12_V18_5.tif", output="corine",
    >    >  flags="o")
    >    > execGRASS("v.to.rast", input="nuts", output="nuts3", use="cat",
    >    >  label_column="FID")
    >    > execGRASS("r.cross", input="nuts3,corine", output="cross_nuts3")
    >    > r_stats0 <- execGRASS("r.stats", input="cross_nuts3", flags="a",
    >    >  intern=TRUE)
    >    > r_stats1 <- gsub("\\*", "NA", r_stats0)
    >    > con_stats <- textConnection(r_stats1)
    >    > stats <- read.table(con_stats, header=FALSE, col.names=c("cross_cat",
    >    >  "area"), colClasses=c("integer", "numeric"))
    >    > close(con_stats)
    >    > r_cats0 <- execGRASS("r.category", map="cross_nuts3", intern=TRUE)
    >    > r_cats1 <- gsub(";", "", r_cats0)
    >    > r_cats2 <- gsub("\t", " ", r_cats1)
    >    > r_cats3 <- gsub("no data", "no_data", r_cats2)
    >    > r_cats4 <- gsub("category ", "", r_cats3)
    >    > r_cats4[1] <- paste0(r_cats4[1], "NA NA")
    >    > r_cats_split <- strsplit(r_cats4, " ")
    >    > cats <- data.frame(cross_cat=as.integer(sapply(r_cats_split, "[", 1)),
    >    >   nuts=sapply(r_cats_split, "[", 2),
    >    >   corine=as.integer(sapply(r_cats_split, "[", 3)))
    >    > catstats <- merge(cats, stats, by="cross_cat", all=TRUE)
    >    > agg_areas <- tapply(catstats$area, list(catstats$nuts, catstats$corine),
    >    >  sum)
    >    > library(foreign)
    >    > corine_labels <- read.dbf("g250_clc12_V18_5.tif.vat.dbf", as.is=TRUE)
    >    > o <- match(colnames(agg_areas), as.character(corine_labels$Value))
    >    > colnames(agg_areas) <- corine_labels$LABEL3[o]
    >    > agg_areas_df <- as.data.frame(agg_areas)
    >    > agg_areas_df1 <- agg_areas_df[-which(!(row.names(agg_areas_df) %in%
    >    >   as.character(nuts_ll$FID))),] # dropping "NA"      "no_data"
    >    >
    >    > This should be ready to merge with the NUTS3 boundaries, if needed.
    >    >
    >    > agg_areas_df1$FID <- row.names(agg_areas_df1)
    >    > nuts_corine <- merge(nuts_laea, agg_areas_df1, by="FID")
    >    >
    >
    >    And to write out as GPKG:
    >
    >    names(nuts_corine)[1] <- "FID_"
    >    writeOGR(nuts_corine, "nuts_corine.gpkg", layer="corine", driver="GPKG")
    >
    >    It seems that at least this driver treats "FID" as a reserved field name.
    >
    >    > For the vector parts you could use sf and the provisional rgrass7sf on
    >    > github, but that wouldn't yet let you construct a skeleton SpatialGrid to
    >    > define the GRASS location. Using GRASS for the heavy lifting (the raster is
    >    > 51000 by 35000), and avoiding vector for overlay, this doesn't need much
    >    > memory (GRASS handles rasters by row). The GRASS temporary location only
    >    > takes 130MB of disk space. You could go for the 100m raster resolution, but I
    >    > doubt that the outcome would vary much - anyone like to try?
    >    >
    >    > If the sub-polygons by NUTS and corine categories are actually needed, the
    >    > output of r.cross could be passed to r.to.vect:
    >    >
    >    > execGRASS("r.to.vect", input="cross_nuts3", output="cross_nuts3",
    >    >   type="area")
    >    >
    >    > but this is more demanding in memory terms.
    >
    > Hi Roger,
    >
    > thanks a lot again for helping me with this issue.
    >
    >
    > Unfortunately, I haven't managed to call GRASS within R, neither install 
    > sf. My guess is that those issues are because I'm using both newest 
    > versions OS X High Sierra and R 3.5.0 which are not stable yet.
    
    You do not need sf. You do need GRASS, and, yes, OSX causes a lot of 
    problems because it is no longer attentive to the needs of numerical 
    analysts (certification of installs mandated at cost to FOSS communities; 
    gaping empty root password; only interested in pay-for software; never 
    contributes to FOSS AFAIK). Apple does not contribute to R.

Ah, I got it!
    
    >
    >    Reading into R is not possible, object too large.
    >
    > Bearing in mind the previous issues plus this last comment, I decided to 
    > use a PC with another OS (Ubuntu) aiming at solving them and working 
    > with a bit more space (32 GB).
    
    Wrong comment. The vector corine object is impossible to handle anywhere, 
    and probably should never have been constructed. I really doubt that it is 
    more "accurate" than the 100m raster, and doubt that the areas sums by 
    NUTS3 region differ much between 250m and 100m.


    
    You need to go back to the way in which Corine was derived, and to your 
    actual needs (which you have not described). If what you need are areas of 
    Corine classes by NUTS3 region, the code I provided gives you this. If 
    what you need is the full intersection of Corine classes and all NUTS3 
    regions, then you cannot visualize them (without zooming - rendering is 
    raster anyway) nor can you analyze them in any meaningful way, so you'd 
    need to revisit you research question. An intersection of a subset of 
    NUTS3 regions yielding raster patches or vector entities is possible and 
    could be visualized, but you seem to want the full extent of the NUTS3 
    regions.

My ultimate goal is to compute population within a buffer by downscaling the NUTS3 population on the CLC resolution using algorithms like in Gallego (2010): A population density grid of the European Union. One of them is based on a regression model so , yes, I need to compute the areas of CLC classes within each NUTS3 region. Thanks a lot again for the code. Regarding visualization, I'm planning to convey results at NUTS3 level.
    
    If you need the intersection between one/few NUTS3 region(s) and Corine, 
    you can still use the raster approach, but I don't know PostGIS well 
    enough to advise (forthcoming R Journal article; 
    https://cran.r-project.org/package=rpostgis). You can read the NUTS3 
    boundaries into R, but probably neither of the Corine vector files (not 
    just memory, you mentioned earlier that they suffered from topological 
    issues which would prevent intersection without intensive cleaning.

At some point I might need to implement it on a lower level - within a country for instance - so I will keep it on the lookout. I also will have a look on PostGIS.
    
    Using GRASS, you get the best of both worlds, script in R and run the 
    analysis at scale in GRASS using memory-conserving implementations.

Hot tip!

Roman.
    
    Roger
    
    >
    >    Roger
    >
    > In the meantime, I really would appreciate you guidance for gaining 
    > background on this subject. Could you please suggest me resources to 
    > better understand the features of objects involved in Spatial 
    > Statistics? I should mention that the knowledge I have about it is 
    > resumed in your book Applied Spatial Data Analysis with R.
    >
    >
    > Best,
    > Roman.
    >
    >    >
    >    > Interesting case, and it does show that combining GIS and R delivers the
    >    > goods - SAGA would probably work equivalently.
    >    >
    >    > Roger
    >    >
    >    >>
    >    >>  Roger
    >    >>
    >    >>>
    >    >>>   I really appreciate any feedback in advance as well as details that I
    >    >>>   should take into account to understand more about how to work with this
    >    >>>   kind of data. I will also keep you up to date on how it goes if you
    >    >>>   like.
    >    >>>
    >    >>>
    >    >>>   Best,
    >    >>>   Roman.
    >    >>>
    >    >>>   On 03/05/2018, 12:26, "Roger Bivand" <Roger.Bivand at nhh.no> wrote:
    >    >>>
    >    >>>      On Thu, 3 May 2018, Aguirre Perez, Roman wrote:
    >    >>>
    >    >>>    >   Hello Shaun,
    >    >>>    >
    >    >>>    >   Thanks a lot for replying and providing me alternative options.
    >    >>>    >
    >    >>>    >
    >    >>>    >   Unfortunately, I can't try both options anymore as I ran out of
    >    >>>    >   ArcGIS
    >    >>>    >   due to I was using a university PC which is not available now (I
    >    >>>    >   installed an ArcGIS trial version there), but I'll try it later. I
    >    >>>    >   also
    >    >>>    >   failed on installing the sf package - I'll dig a bit more on it.
    >    >>>    >   Nevertheless, I already downloaded the SpatialLite version so I'll
    >    >>>    >   try
    >    >>>    >   the second option and I'll let you know how it goes.
    >    >>>
    >    >>>      I think Melanie got it right - the apparent extra detail and
    >    >>>      precision
    >    >>>      you'd get from vector-vector overlay is illusory, so going with
    >    >>>      geoTiff
    >    >>>      should get you there (you can check to see whether 100m resolution
    >    >>>      differs
    >    >>>      from 250m). The only reason to choose vector-vector would be that the
    >    >>>      Corine vector contains categories not represented in the raster
    >    >>>      version.
    >    >>>      Using raster also steps around the polygon deficiencies in the GDB
    >    >>>      (and
    >    >>>      probably SQLite) representations.
    >    >>>
    >    >>>      Roger
    >    >>>
    >    >>>    >
    >    >>>    >
    >    >>>    >   Regards,
    >    >>>    >   Roman.
    >    >>>    >
    >    >>>    >   On 02/05/2018, 18:53, "Shaun Walbridge" <SWalbridge at esri.com>
    >    >>>    >   wrote:
    >    >>>    >
    >    >>>    >      Hello Roman,
    >    >>>    >
    >    >>>    >      A couple of suggested options: You can try and use the
    >    >>>    >      arcgisbinding package [1] to pull the data directly into R via
    >    >>>    >      ArcGIS, as you mentioned you have ArcGIS available [presumably
    >    >>>    >      on
    >    >>>    >      Windows or in a VM]. It will access the data directly, and let
    >    >>>    >      you
    >    >>>    >      create sp and sf objects out of Geodatabases with little work. A
    >    >>>    >      basic workflow looks like this:
    >    >>>    >
    >    >>>    >      d <- arc.open("path/file.gdb/layer_name")
    >    >>>    >      df <- arc.select(d) # here, you can filter columns and
    >    >>>    >      attributes,
    >    >>>    >      see [2]
    >    >>>    >      # create an sf object
    >    >>>    >      df.sf <- arc.data2sf(df)
    >    >>>    >      # alternatively, create an sp object
    >    >>>    >      df.sp <- arc.data2sp(df)
    >    >>>    >
    >    >>>    >      You can also write the results back to a geodatabase, or any
    >    >>>    >      other
    >    >>>    >      format that ArcGIS understands. Another option is trying the
    >    >>>    >      SpatiaLite version of the data at the URL you posted. You should
    >    >>>    >      be able to access this using R directly, provided your rgdal
    >    >>>    >      installation is correctly built to read spatialite databases. If
    >    >>>    >      it is, try the same process you mentioned using rgdal, but point
    >    >>>    >      it at the SpatialLite database instead. You could also use
    >    >>>    >      command-line OGR to convert the data, that has a few options
    >    >>>    >      like
    >    >>>    >      where clause filtering that aren't directly available via
    >    >>>    >      readOGR.
    >    >>>    >
    >    >>>    >      If neither of these options work, let me know and I can convert
    >    >>>    >      the data for you into a format of your preference.
    >    >>>    >
    >    >>>    >      Cheers,
    >    >>>    >      Shaun
    >    >>>    >
    >    >>>    >      1.
    >    >>>    >      https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_R-2DArcGIS_r-2Dbridge-2Dinstall&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=yckcjR6k3nADiVsNiAhGwcZB--0A8DQgvLSJ27upmyk&m=dkecE8PWOn5sSrtSXqX2R-VwJuFH_In4BvpC5da4LJ0&s=nRO2IG9dlrdKYGMSp3rCf7nwJqRFQoIWnY5zSFrPOQM&e=
    >    >>>    >      2.
    >    >>>    >      https://urldefense.proofpoint.com/v2/url?u=https-3A__rdrr.io_github_R-2DArcGIS_r-2Dbridge_man_arc.select.html&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=yckcjR6k3nADiVsNiAhGwcZB--0A8DQgvLSJ27upmyk&m=dkecE8PWOn5sSrtSXqX2R-VwJuFH_In4BvpC5da4LJ0&s=89N-cLe5N3dhZ6MTsM2OAYwmDImBH88ZrVaA5Hos0n4&e=
    >    >>>    >
    >    >>>    >
    >    >>>    >
    >    >>>    >      On 5/2/18, 1:34 PM, "R-sig-Geo on behalf of Aguirre Perez,
    >    >>>    >      Roman"
    >    >>>    >      <r-sig-geo-bounces at r-project.org on behalf of
    >    >>>    >      ra454 at exeter.ac.uk>
    >    >>>    >      wrote:
    >    >>>    >
    >    >>>    >          Hi everyone,
    >    >>>    >
    >    >>>    >          I?ve been struggling with a ESRI Geodatabase file
    >    >>>    >          (clc12_Version_18_5.gdb) which is a layer of land cover
    >    >>>    >          classes available on
    >    >>>    >
    >    >>>    >          https://urldefense.proofpoint.com/v2/url?u=https-3A__land.copernicus.eu_pan-2Deuropean_corine-2Dland-2Dcover_clc-2D2012-3Ftab-3Ddownload&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=9LaO4HiB5C5ewiuN_IeSQJSgq2tl5_-oMECPChtZa_U&e=
    >    >>>    >
    >    >>>    >          whose size is 2.61 GB once unzipped.
    >    >>>    >
    >    >>>    >          My ultimate task is to overlay it with the last NUTS3
    >    >>>    >          administrative boundaries shapefile (2013) available on
    >    >>>    >
    >    >>>    >          https://urldefense.proofpoint.com/v2/url?u=http-3A__ec.europa.eu_eurostat_web_gisco_geodata_reference-2Ddata_administrative-2Dunits-2Dstatistical-2Dunits&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=VExYSoR8FY_vhZaPNJpoOx0ZCZNMU9hMTtlGJZj2joU&e=
    >    >>>    >
    >    >>>    >          in order to compute the area covered by each class within
    >    >>>    >          each
    >    >>>    >          NUTS3 region.
    >    >>>    >
    >    >>>    >          Despite the ease of friendly software for performing this
    >    >>>    >          task, haven?t been capable of doing it - GRASS didn?t load
    >    >>>    >          the
    >    >>>    >          file as the log reports problems with the polygons, QGIS
    >    >>>    >          shows
    >    >>>    >          a warning regarding a specific object and ArcGIS got frozen.
    >    >>>    >          I
    >    >>>    >          guess it?s because the PC I used doesn?t have enough
    >    >>>    >          capacity.
    >    >>>    >          Unfortunately, I don?t have access to a more powerful one.
    >    >>>    >
    >    >>>    >          Anyway, I decided to try with R -after all, I?ll perform my
    >    >>>    >          analysis with it. So I started exploring this GDB with
    >    >>>    >          rgdal:
    >    >>>    >
    >    >>>    >          ogrInfo(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
    >    >>>    >
    >    >>>    >          Source:
    >    >>>    >          "/Users/Roman/Desktop/clc12gdb/clc12_Version_18_5.gdb",
    >    >>>    >          layer: "clc12_Version_18_5"
    >    >>>    >          Driver: OpenFileGDB;
    >    >>>    >          number of rows: 2370829
    >    >>>    >          Feature type: wkbPolygon with 3 dimensions
    >    >>>    >          Extent: (-2693292 -3086662) - (10037210 5440568)
    >    >>>    >          Null geometry IDs: 2156240
    >    >>>    >          CRS: +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000
    >    >>>    >          +y_0=3210000
    >    >>>    >          +ellps=GRS80 +units=m +no_defs
    >    >>>    >          Number of fields: 6
    >    >>>    >          name                      type  length  typeName
    >    >>>    >          1 code_12              4       3           String
    >    >>>    >          2 ID                         4       18         String
    >    >>>    >          3 Remark               4       20         String
    >    >>>    >          4 Area_Ha             2       0           Real
    >    >>>    >          5 Shape_Length   2       0           Real
    >    >>>    >          6 Shape_Area       2       0           Real
    >    >>>    >
    >    >>>    >          Then I tried to load it typing
    >    >>>    >
    >    >>>    >          clc<-readOGR(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
    >    >>>    >
    >    >>>    >          After 3-5 minutes, it appears the following text:
    >    >>>    >
    >    >>>    >          OGR data source with driver: OpenFileGDB
    >    >>>    >          Source:
    >    >>>    >          "/Users/Roman/Desktop/clc12shp/clc12_Version_18_5.gdb",
    >    >>>    >          layer:
    >    >>>    >          "clc12_Version_18_5"
    >    >>>    >          with 2370829 features
    >    >>>    >          It has 6 fields
    >    >>>    >
    >    >>>    >          Unfortunately, after trying 5 times (each one took around 8
    >    >>>    >          hours) I couldn?t get anything but the following messages:
    >    >>>    >
    >    >>>    >          Warning messages:
    >    >>>    >          1: In readOGR(dsn = "clc12_Version_18_5.gdb", layer =
    >    >>>    >          "clc12_Version_18_5") :
    >    >>>    >          Dropping null geometries: 2156240
    >    >>>    >          2: In readOGR(dsn = "clc12_Version_18_5.gdb", layer =
    >    >>>    >          "clc12_Version_18_5") :
    >    >>>    >          Z-dimension discarded
    >    >>>    >
    >    >>>    >          Could anyone advise me how to tackle it? I also would
    >    >>>    >          appreciate suggestions on how to work with geodatabases -
    >    >>>    >          it?s
    >    >>>    >          my first time I work with these kind of files so I don?t
    >    >>>    >          even
    >    >>>    >          know their structure.
    >    >>>    >
    >    >>>    >          By the way, these are my computer and software
    >    >>>    >          specifications:
    >    >>>    >
    >    >>>    >          MacBook Pro 2012
    >    >>>    >          Processor 2.6 GHz Intel Core i7
    >    >>>    >          Memory 16 GB DDR3
    >    >>>    >          R 3.5.0
    >    >>>    >          RStudio 1.1.447
    >    >>>    >
    >    >>>    >
    >    >>>    >          Best,
    >    >>>    >          Roman.
    >    >>>    >
    >    >>>    >
    >    >>>    >
    >    >>>    >
    >    >>>    >   _______________________________________________
    >    >>>    >   R-sig-Geo mailing list
    >    >>>    >   R-sig-Geo at r-project.org
    >    >>>    >   https://stat.ethz.ch/mailman/listinfo/r-sig-geo
    >    >>>
    >    >>>      --
    >    >>>      Roger Bivand
    >    >>>      Department of Economics, Norwegian School of Economics,
    >    >>>      Helleveien 30, N-5045 Bergen, Norway.
    >    >>>      voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
    >    >>>      http://orcid.org/0000-0003-2392-6140
    >    >>>      https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
    >    >>>
    >    >>>
    >    >>
    >    >>
    >    >
    >    >
    >
    >    --
    >    Roger Bivand
    >    Department of Economics, Norwegian School of Economics,
    >    Helleveien 30, N-5045 Bergen, Norway.
    >    voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
    >    http://orcid.org/0000-0003-2392-6140
    >    https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
    >
    >
    
    -- 
    Roger Bivand
    Department of Economics, Norwegian School of Economics,
    Helleveien 30, N-5045 Bergen, Norway.
    voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
    http://orcid.org/0000-0003-2392-6140
    https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From Roger@Biv@nd @ending from nhh@no  Mon May  7 13:55:59 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Mon, 7 May 2018 13:55:59 +0200
Subject: [R-sig-Geo] Issues with a GDB file in R?
In-Reply-To: <7F036E91-6F88-452B-9AAD-AEAE15155F69@exeter.ac.uk>
References: <13F59690-AB9E-40B2-B9F7-2474C9771F52@exeter.ac.uk>
 <AFA371A2-4A57-4038-AD9B-2A6C894E2A86@esri.com>
 <A814689E-6CF5-404D-94FD-841FB832FFAB@exeter.ac.uk>
 <alpine.LFD.2.21.1805031321160.14684@reclus.nhh.no>
 <977196B3-00A0-4D48-8E73-6AAF9988F1B1@exeter.ac.uk>
 <alpine.LFD.2.21.1805032014310.22459@reclus.nhh.no>
 <alpine.LFD.2.21.1805042035570.16297@reclus.nhh.no>
 <alpine.LFD.2.21.1805051300370.18610@reclus.nhh.no>
 <CC45C4FA-F33B-4687-BD82-0F7C41B9A062@exeter.ac.uk>
 <alpine.LFD.2.21.1805070912050.3455@reclus.nhh.no>
 <7F036E91-6F88-452B-9AAD-AEAE15155F69@exeter.ac.uk>
Message-ID: <alpine.LFD.2.21.1805071341330.3455@reclus.nhh.no>

On Mon, 7 May 2018, Aguirre Perez, Roman wrote:

>
>
> ?On 07/05/2018, 08:36, "Roger Bivand" <Roger.Bivand at nhh.no> wrote:
>
>    On Sun, 6 May 2018, Aguirre Perez, Roman wrote:
>
>    > On 05/05/2018, 12:03, "Roger Bivand" <Roger.Bivand at nhh.no> wrote:
>    >
>    >    On Fri, 4 May 2018, Roger Bivand wrote:
>    >
>    >    > On Thu, 3 May 2018, Roger Bivand wrote:
>    >    >
>    >    >>  On Thu, 3 May 2018, Aguirre Perez, Roman wrote:
>    >    >>
>    >    >>>   Hi again,
>    >    >>>
>    >    >>>   first of all, thanks a lot for your comments. It's becoming quite
>    >    >>>   interesting how to perform this task with such amount of data.
>    >    >>>
>    >    >>>
>    >    >>>   Here is an update...
>    >    >>>
>    >    >>>   Cotton, I could read the geodatabase by using the commands I shared.
>    >    >>>   However, my R session crashed after overlaying it with a small set of
>    >    >>>   polygons. I guess it was because the size of the sp object (around 14.5
>    >    >>>   GB). It's also worth mentioning that it was just a "multipolygon" (is
>    >    >>>   that
>    >    >>>   the correct word?) formed by 2370829 polygons. I haven?t succeeded on
>    >    >>>   installing the sf package, but I will keep trying it.
>    >    >>>
>    >    >>>   Melanie, I already downloaded and read the geoTiff version. At first
>    >    >>>   sight, it seems that this object doesn?t have enough features as to
>    >    >>>   perform the overlying. I might have a biased idea of how raster objects
>    >    >>>   work - I'm too stick to the representation of shapefiles which sounds
>    >    >>>   quite related with Roger's idea. So I will start to explore it in order
>    >    >>>   to
>    >    >>>   gain a bit more understanding on it.
>    >    >>>
>    >    >>>   Roger, I certainly need to know which category is associated with each
>    >    >>>   CLC
>    >    >>>   polygon in order to compute the area covered by each of these classes
>    >    >>>   within each NUTS3 region. Therefore, I still need to use a vector-vector
>    >    >>>   overlay, right?
>    >    >>
>    >    >>  On the contrary. The geoTiffs are coded as described in the documentation.
>    >    >>  Your output is simply the count of raster cells by NUTS3 for each of the
>    >    >>  categories. The geoTiff is in ETRS_1989_LAEA, so is projected; it includes
>    >    >>  a lot of sea and no data because of the French overseas territories.
>    >    >>
>    >    >>  You could possibly use PostGIS to do the intersections, or use GRASS for
>    >    >>  raster-vector counts (say through rgrass7). In R, you would want to add a
>    >    >>  NUTS3 ID band to the land cover raster, then aggregate by NUTS3 ID.
>    >    >>
>    >    >>  I would suggest using GRASS as the most obvious route, reading the raster,
>    >    >>  reading the NUTS3 boundaries into a separate location, projecting to LAEA,
>    >    >>  then rasterising the NUTS3 regions (v.to.rast) and running r.cross. You
>    >    >>  get 32K output categories, the 48 corine categories times the count of
>    >    >>  NUTS3 regions minus the nulls (there aren't many glaciers in most
>    >    >>  regions). You'll then need to match back the Corine codes and the NUTS3
>    >    >>  codes - see in the category label file shown by r.category.
>    >    >>
>    >    >>  I'll try to provide code tomorrow.
>    >    >
>    >    > Combining R and GRASS seems to work, but no guarantees.
>    >    >
>    >    > library(sp)
>    >    > library(rgdal)
>    >    > Gi <- GDALinfo("g250_clc12_V18_5.tif")
>    >    > makeSG <- function(x) {
>    >    >   stopifnot(class(x) == "GDALobj")
>    >    >   p4 <- attr(x, "projection")
>    >    >   gt <- GridTopology(c(x[4]+(x[6]/2), x[5]+(x[7]/2)), c(x[6], x[7]),
>    >    >     c(x[2], x[1]))
>    >    >  SpatialGrid(gt, CRS(p4))
>    >    > }
>    >    > SG <- makeSG(Gi)
>    >    > nuts_ll <- readOGR("NUTS_RG_01M_2013_4326_LEVL_3.shp")
>    >    > nuts_laea <- spTransform(nuts_ll, CRS(attr(Gi, "projection")))
>    >    > library(rgrass7)
>    >    > td <- tempdir()
>    >    > iG <- initGRASS("/home/rsb/topics/grass/g740/grass-7.4.0", td, SG)
>    >    > # your GRASS will be where you installed it
>    >    > writeVECT(nuts_laea, "nuts", v.in.ogr_flags="o")
>    >    > execGRASS("r.in.gdal", input="g250_clc12_V18_5.tif", output="corine",
>    >    >  flags="o")
>    >    > execGRASS("v.to.rast", input="nuts", output="nuts3", use="cat",
>    >    >  label_column="FID")
>    >    > execGRASS("r.cross", input="nuts3,corine", output="cross_nuts3")
>    >    > r_stats0 <- execGRASS("r.stats", input="cross_nuts3", flags="a",
>    >    >  intern=TRUE)
>    >    > r_stats1 <- gsub("\\*", "NA", r_stats0)
>    >    > con_stats <- textConnection(r_stats1)
>    >    > stats <- read.table(con_stats, header=FALSE, col.names=c("cross_cat",
>    >    >  "area"), colClasses=c("integer", "numeric"))
>    >    > close(con_stats)
>    >    > r_cats0 <- execGRASS("r.category", map="cross_nuts3", intern=TRUE)
>    >    > r_cats1 <- gsub(";", "", r_cats0)
>    >    > r_cats2 <- gsub("\t", " ", r_cats1)
>    >    > r_cats3 <- gsub("no data", "no_data", r_cats2)
>    >    > r_cats4 <- gsub("category ", "", r_cats3)
>    >    > r_cats4[1] <- paste0(r_cats4[1], "NA NA")
>    >    > r_cats_split <- strsplit(r_cats4, " ")
>    >    > cats <- data.frame(cross_cat=as.integer(sapply(r_cats_split, "[", 1)),
>    >    >   nuts=sapply(r_cats_split, "[", 2),
>    >    >   corine=as.integer(sapply(r_cats_split, "[", 3)))
>    >    > catstats <- merge(cats, stats, by="cross_cat", all=TRUE)
>    >    > agg_areas <- tapply(catstats$area, list(catstats$nuts, catstats$corine),
>    >    >  sum)
>    >    > library(foreign)
>    >    > corine_labels <- read.dbf("g250_clc12_V18_5.tif.vat.dbf", as.is=TRUE)
>    >    > o <- match(colnames(agg_areas), as.character(corine_labels$Value))
>    >    > colnames(agg_areas) <- corine_labels$LABEL3[o]
>    >    > agg_areas_df <- as.data.frame(agg_areas)
>    >    > agg_areas_df1 <- agg_areas_df[-which(!(row.names(agg_areas_df) %in%
>    >    >   as.character(nuts_ll$FID))),] # dropping "NA"      "no_data"
>    >    >
>    >    > This should be ready to merge with the NUTS3 boundaries, if needed.
>    >    >
>    >    > agg_areas_df1$FID <- row.names(agg_areas_df1)
>    >    > nuts_corine <- merge(nuts_laea, agg_areas_df1, by="FID")
>    >    >
>    >
>    >    And to write out as GPKG:
>    >
>    >    names(nuts_corine)[1] <- "FID_"
>    >    writeOGR(nuts_corine, "nuts_corine.gpkg", layer="corine", driver="GPKG")
>    >
>    >    It seems that at least this driver treats "FID" as a reserved field name.
>    >
>    >    > For the vector parts you could use sf and the provisional rgrass7sf on
>    >    > github, but that wouldn't yet let you construct a skeleton SpatialGrid to
>    >    > define the GRASS location. Using GRASS for the heavy lifting (the raster is
>    >    > 51000 by 35000), and avoiding vector for overlay, this doesn't need much
>    >    > memory (GRASS handles rasters by row). The GRASS temporary location only
>    >    > takes 130MB of disk space. You could go for the 100m raster resolution, but I
>    >    > doubt that the outcome would vary much - anyone like to try?
>    >    >
>    >    > If the sub-polygons by NUTS and corine categories are actually needed, the
>    >    > output of r.cross could be passed to r.to.vect:
>    >    >
>    >    > execGRASS("r.to.vect", input="cross_nuts3", output="cross_nuts3",
>    >    >   type="area")
>    >    >
>    >    > but this is more demanding in memory terms.
>    >
>    > Hi Roger,
>    >
>    > thanks a lot again for helping me with this issue.
>    >
>    >
>    > Unfortunately, I haven't managed to call GRASS within R, neither install
>    > sf. My guess is that those issues are because I'm using both newest
>    > versions OS X High Sierra and R 3.5.0 which are not stable yet.
>
>    You do not need sf. You do need GRASS, and, yes, OSX causes a lot of
>    problems because it is no longer attentive to the needs of numerical
>    analysts (certification of installs mandated at cost to FOSS communities;
>    gaping empty root password; only interested in pay-for software; never
>    contributes to FOSS AFAIK). Apple does not contribute to R.
>
> Ah, I got it!
>
>    >
>    >    Reading into R is not possible, object too large.
>    >
>    > Bearing in mind the previous issues plus this last comment, I decided to
>    > use a PC with another OS (Ubuntu) aiming at solving them and working
>    > with a bit more space (32 GB).
>
>    Wrong comment. The vector corine object is impossible to handle anywhere,
>    and probably should never have been constructed. I really doubt that it is
>    more "accurate" than the 100m raster, and doubt that the areas sums by
>    NUTS3 region differ much between 250m and 100m.
>
>
>
>    You need to go back to the way in which Corine was derived, and to your
>    actual needs (which you have not described). If what you need are areas of
>    Corine classes by NUTS3 region, the code I provided gives you this. If
>    what you need is the full intersection of Corine classes and all NUTS3
>    regions, then you cannot visualize them (without zooming - rendering is
>    raster anyway) nor can you analyze them in any meaningful way, so you'd
>    need to revisit you research question. An intersection of a subset of
>    NUTS3 regions yielding raster patches or vector entities is possible and
>    could be visualized, but you seem to want the full extent of the NUTS3
>    regions.
>
> My ultimate goal is to compute population within a buffer by downscaling 
> the NUTS3 population on the CLC resolution using algorithms like in 
> Gallego (2010): A population density grid of the European Union. One of 
> them is based on a regression model so , yes, I need to compute the 
> areas of CLC classes within each NUTS3 region. Thanks a lot again for 
> the code. Regarding visualization, I'm planning to convey results at 
> NUTS3 level.

Then staying with raster will be sensible, just interpolate the population 
counts to the raster resolution you want (wouldn't the Gallego 1ha be very 
like the Corine 100m resolution?). If you avoid vector for everything 
apart from rasterising the NUTS3 boundaries, you should be OK. See 
https://doi.org/10.1371/journal.pone.0174993 for a US dasymetric example - 
and see http://sil.uc.edu/webapps/socscape_usa/ for the online tool.

Roger

>
>    If you need the intersection between one/few NUTS3 region(s) and Corine,
>    you can still use the raster approach, but I don't know PostGIS well
>    enough to advise (forthcoming R Journal article;
>    https://cran.r-project.org/package=rpostgis). You can read the NUTS3
>    boundaries into R, but probably neither of the Corine vector files (not
>    just memory, you mentioned earlier that they suffered from topological
>    issues which would prevent intersection without intensive cleaning.
>
> At some point I might need to implement it on a lower level - within a 
> country for instance - so I will keep it on the lookout. I also will 
> have a look on PostGIS.
>
>    Using GRASS, you get the best of both worlds, script in R and run the
>    analysis at scale in GRASS using memory-conserving implementations.
>
> Hot tip!
>
> Roman.
>
>    Roger
>
>    >
>    >    Roger
>    >
>    > In the meantime, I really would appreciate you guidance for gaining
>    > background on this subject. Could you please suggest me resources to
>    > better understand the features of objects involved in Spatial
>    > Statistics? I should mention that the knowledge I have about it is
>    > resumed in your book Applied Spatial Data Analysis with R.
>    >
>    >
>    > Best,
>    > Roman.
>    >
>    >    >
>    >    > Interesting case, and it does show that combining GIS and R delivers the
>    >    > goods - SAGA would probably work equivalently.
>    >    >
>    >    > Roger
>    >    >
>    >    >>
>    >    >>  Roger
>    >    >>
>    >    >>>
>    >    >>>   I really appreciate any feedback in advance as well as details that I
>    >    >>>   should take into account to understand more about how to work with this
>    >    >>>   kind of data. I will also keep you up to date on how it goes if you
>    >    >>>   like.
>    >    >>>
>    >    >>>
>    >    >>>   Best,
>    >    >>>   Roman.
>    >    >>>
>    >    >>>   On 03/05/2018, 12:26, "Roger Bivand" <Roger.Bivand at nhh.no> wrote:
>    >    >>>
>    >    >>>      On Thu, 3 May 2018, Aguirre Perez, Roman wrote:
>    >    >>>
>    >    >>>    >   Hello Shaun,
>    >    >>>    >
>    >    >>>    >   Thanks a lot for replying and providing me alternative options.
>    >    >>>    >
>    >    >>>    >
>    >    >>>    >   Unfortunately, I can't try both options anymore as I ran out of
>    >    >>>    >   ArcGIS
>    >    >>>    >   due to I was using a university PC which is not available now (I
>    >    >>>    >   installed an ArcGIS trial version there), but I'll try it later. I
>    >    >>>    >   also
>    >    >>>    >   failed on installing the sf package - I'll dig a bit more on it.
>    >    >>>    >   Nevertheless, I already downloaded the SpatialLite version so I'll
>    >    >>>    >   try
>    >    >>>    >   the second option and I'll let you know how it goes.
>    >    >>>
>    >    >>>      I think Melanie got it right - the apparent extra detail and
>    >    >>>      precision
>    >    >>>      you'd get from vector-vector overlay is illusory, so going with
>    >    >>>      geoTiff
>    >    >>>      should get you there (you can check to see whether 100m resolution
>    >    >>>      differs
>    >    >>>      from 250m). The only reason to choose vector-vector would be that the
>    >    >>>      Corine vector contains categories not represented in the raster
>    >    >>>      version.
>    >    >>>      Using raster also steps around the polygon deficiencies in the GDB
>    >    >>>      (and
>    >    >>>      probably SQLite) representations.
>    >    >>>
>    >    >>>      Roger
>    >    >>>
>    >    >>>    >
>    >    >>>    >
>    >    >>>    >   Regards,
>    >    >>>    >   Roman.
>    >    >>>    >
>    >    >>>    >   On 02/05/2018, 18:53, "Shaun Walbridge" <SWalbridge at esri.com>
>    >    >>>    >   wrote:
>    >    >>>    >
>    >    >>>    >      Hello Roman,
>    >    >>>    >
>    >    >>>    >      A couple of suggested options: You can try and use the
>    >    >>>    >      arcgisbinding package [1] to pull the data directly into R via
>    >    >>>    >      ArcGIS, as you mentioned you have ArcGIS available [presumably
>    >    >>>    >      on
>    >    >>>    >      Windows or in a VM]. It will access the data directly, and let
>    >    >>>    >      you
>    >    >>>    >      create sp and sf objects out of Geodatabases with little work. A
>    >    >>>    >      basic workflow looks like this:
>    >    >>>    >
>    >    >>>    >      d <- arc.open("path/file.gdb/layer_name")
>    >    >>>    >      df <- arc.select(d) # here, you can filter columns and
>    >    >>>    >      attributes,
>    >    >>>    >      see [2]
>    >    >>>    >      # create an sf object
>    >    >>>    >      df.sf <- arc.data2sf(df)
>    >    >>>    >      # alternatively, create an sp object
>    >    >>>    >      df.sp <- arc.data2sp(df)
>    >    >>>    >
>    >    >>>    >      You can also write the results back to a geodatabase, or any
>    >    >>>    >      other
>    >    >>>    >      format that ArcGIS understands. Another option is trying the
>    >    >>>    >      SpatiaLite version of the data at the URL you posted. You should
>    >    >>>    >      be able to access this using R directly, provided your rgdal
>    >    >>>    >      installation is correctly built to read spatialite databases. If
>    >    >>>    >      it is, try the same process you mentioned using rgdal, but point
>    >    >>>    >      it at the SpatialLite database instead. You could also use
>    >    >>>    >      command-line OGR to convert the data, that has a few options
>    >    >>>    >      like
>    >    >>>    >      where clause filtering that aren't directly available via
>    >    >>>    >      readOGR.
>    >    >>>    >
>    >    >>>    >      If neither of these options work, let me know and I can convert
>    >    >>>    >      the data for you into a format of your preference.
>    >    >>>    >
>    >    >>>    >      Cheers,
>    >    >>>    >      Shaun
>    >    >>>    >
>    >    >>>    >      1.
>    >    >>>    >      https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_R-2DArcGIS_r-2Dbridge-2Dinstall&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=yckcjR6k3nADiVsNiAhGwcZB--0A8DQgvLSJ27upmyk&m=dkecE8PWOn5sSrtSXqX2R-VwJuFH_In4BvpC5da4LJ0&s=nRO2IG9dlrdKYGMSp3rCf7nwJqRFQoIWnY5zSFrPOQM&e=
>    >    >>>    >      2.
>    >    >>>    >      https://urldefense.proofpoint.com/v2/url?u=https-3A__rdrr.io_github_R-2DArcGIS_r-2Dbridge_man_arc.select.html&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=yckcjR6k3nADiVsNiAhGwcZB--0A8DQgvLSJ27upmyk&m=dkecE8PWOn5sSrtSXqX2R-VwJuFH_In4BvpC5da4LJ0&s=89N-cLe5N3dhZ6MTsM2OAYwmDImBH88ZrVaA5Hos0n4&e=
>    >    >>>    >
>    >    >>>    >
>    >    >>>    >
>    >    >>>    >      On 5/2/18, 1:34 PM, "R-sig-Geo on behalf of Aguirre Perez,
>    >    >>>    >      Roman"
>    >    >>>    >      <r-sig-geo-bounces at r-project.org on behalf of
>    >    >>>    >      ra454 at exeter.ac.uk>
>    >    >>>    >      wrote:
>    >    >>>    >
>    >    >>>    >          Hi everyone,
>    >    >>>    >
>    >    >>>    >          I?ve been struggling with a ESRI Geodatabase file
>    >    >>>    >          (clc12_Version_18_5.gdb) which is a layer of land cover
>    >    >>>    >          classes available on
>    >    >>>    >
>    >    >>>    >          https://urldefense.proofpoint.com/v2/url?u=https-3A__land.copernicus.eu_pan-2Deuropean_corine-2Dland-2Dcover_clc-2D2012-3Ftab-3Ddownload&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=9LaO4HiB5C5ewiuN_IeSQJSgq2tl5_-oMECPChtZa_U&e=
>    >    >>>    >
>    >    >>>    >          whose size is 2.61 GB once unzipped.
>    >    >>>    >
>    >    >>>    >          My ultimate task is to overlay it with the last NUTS3
>    >    >>>    >          administrative boundaries shapefile (2013) available on
>    >    >>>    >
>    >    >>>    >          https://urldefense.proofpoint.com/v2/url?u=http-3A__ec.europa.eu_eurostat_web_gisco_geodata_reference-2Ddata_administrative-2Dunits-2Dstatistical-2Dunits&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=YFaRLkcUCdDkLrpTbNOUV9J1CwYBCTMwgm5tdQkRSm4&m=qIGI8rXMP_JTDhSFz8NjjQMAyNAnpnUGFRBxqfH4bPU&s=VExYSoR8FY_vhZaPNJpoOx0ZCZNMU9hMTtlGJZj2joU&e=
>    >    >>>    >
>    >    >>>    >          in order to compute the area covered by each class within
>    >    >>>    >          each
>    >    >>>    >          NUTS3 region.
>    >    >>>    >
>    >    >>>    >          Despite the ease of friendly software for performing this
>    >    >>>    >          task, haven?t been capable of doing it - GRASS didn?t load
>    >    >>>    >          the
>    >    >>>    >          file as the log reports problems with the polygons, QGIS
>    >    >>>    >          shows
>    >    >>>    >          a warning regarding a specific object and ArcGIS got frozen.
>    >    >>>    >          I
>    >    >>>    >          guess it?s because the PC I used doesn?t have enough
>    >    >>>    >          capacity.
>    >    >>>    >          Unfortunately, I don?t have access to a more powerful one.
>    >    >>>    >
>    >    >>>    >          Anyway, I decided to try with R -after all, I?ll perform my
>    >    >>>    >          analysis with it. So I started exploring this GDB with
>    >    >>>    >          rgdal:
>    >    >>>    >
>    >    >>>    >          ogrInfo(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
>    >    >>>    >
>    >    >>>    >          Source:
>    >    >>>    >          "/Users/Roman/Desktop/clc12gdb/clc12_Version_18_5.gdb",
>    >    >>>    >          layer: "clc12_Version_18_5"
>    >    >>>    >          Driver: OpenFileGDB;
>    >    >>>    >          number of rows: 2370829
>    >    >>>    >          Feature type: wkbPolygon with 3 dimensions
>    >    >>>    >          Extent: (-2693292 -3086662) - (10037210 5440568)
>    >    >>>    >          Null geometry IDs: 2156240
>    >    >>>    >          CRS: +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000
>    >    >>>    >          +y_0=3210000
>    >    >>>    >          +ellps=GRS80 +units=m +no_defs
>    >    >>>    >          Number of fields: 6
>    >    >>>    >          name                      type  length  typeName
>    >    >>>    >          1 code_12              4       3           String
>    >    >>>    >          2 ID                         4       18         String
>    >    >>>    >          3 Remark               4       20         String
>    >    >>>    >          4 Area_Ha             2       0           Real
>    >    >>>    >          5 Shape_Length   2       0           Real
>    >    >>>    >          6 Shape_Area       2       0           Real
>    >    >>>    >
>    >    >>>    >          Then I tried to load it typing
>    >    >>>    >
>    >    >>>    >          clc<-readOGR(dsn="clc12_Version_18_5.gdb",layer="clc12_Version_18_5")
>    >    >>>    >
>    >    >>>    >          After 3-5 minutes, it appears the following text:
>    >    >>>    >
>    >    >>>    >          OGR data source with driver: OpenFileGDB
>    >    >>>    >          Source:
>    >    >>>    >          "/Users/Roman/Desktop/clc12shp/clc12_Version_18_5.gdb",
>    >    >>>    >          layer:
>    >    >>>    >          "clc12_Version_18_5"
>    >    >>>    >          with 2370829 features
>    >    >>>    >          It has 6 fields
>    >    >>>    >
>    >    >>>    >          Unfortunately, after trying 5 times (each one took around 8
>    >    >>>    >          hours) I couldn?t get anything but the following messages:
>    >    >>>    >
>    >    >>>    >          Warning messages:
>    >    >>>    >          1: In readOGR(dsn = "clc12_Version_18_5.gdb", layer =
>    >    >>>    >          "clc12_Version_18_5") :
>    >    >>>    >          Dropping null geometries: 2156240
>    >    >>>    >          2: In readOGR(dsn = "clc12_Version_18_5.gdb", layer =
>    >    >>>    >          "clc12_Version_18_5") :
>    >    >>>    >          Z-dimension discarded
>    >    >>>    >
>    >    >>>    >          Could anyone advise me how to tackle it? I also would
>    >    >>>    >          appreciate suggestions on how to work with geodatabases -
>    >    >>>    >          it?s
>    >    >>>    >          my first time I work with these kind of files so I don?t
>    >    >>>    >          even
>    >    >>>    >          know their structure.
>    >    >>>    >
>    >    >>>    >          By the way, these are my computer and software
>    >    >>>    >          specifications:
>    >    >>>    >
>    >    >>>    >          MacBook Pro 2012
>    >    >>>    >          Processor 2.6 GHz Intel Core i7
>    >    >>>    >          Memory 16 GB DDR3
>    >    >>>    >          R 3.5.0
>    >    >>>    >          RStudio 1.1.447
>    >    >>>    >
>    >    >>>    >
>    >    >>>    >          Best,
>    >    >>>    >          Roman.
>    >    >>>    >
>    >    >>>    >
>    >    >>>    >
>    >    >>>    >
>    >    >>>    >   _______________________________________________
>    >    >>>    >   R-sig-Geo mailing list
>    >    >>>    >   R-sig-Geo at r-project.org
>    >    >>>    >   https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>    >    >>>
>    >    >>>      --
>    >    >>>      Roger Bivand
>    >    >>>      Department of Economics, Norwegian School of Economics,
>    >    >>>      Helleveien 30, N-5045 Bergen, Norway.
>    >    >>>      voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>    >    >>>      http://orcid.org/0000-0003-2392-6140
>    >    >>>      https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>    >    >>>
>    >    >>>
>    >    >>
>    >    >>
>    >    >
>    >    >
>    >
>    >    --
>    >    Roger Bivand
>    >    Department of Economics, Norwegian School of Economics,
>    >    Helleveien 30, N-5045 Bergen, Norway.
>    >    voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>    >    http://orcid.org/0000-0003-2392-6140
>    >    https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>    >
>    >
>
>    --
>    Roger Bivand
>    Department of Economics, Norwegian School of Economics,
>    Helleveien 30, N-5045 Bergen, Norway.
>    voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>    http://orcid.org/0000-0003-2392-6140
>    https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From ft@v@re@29 @ending from gm@il@com  Mon May  7 17:02:09 2018
From: ft@v@re@29 @ending from gm@il@com (felipe tavares)
Date: Mon, 7 May 2018 12:02:09 -0300
Subject: [R-sig-Geo] Spatial Panel Models Problem (Splm package)
In-Reply-To: <alpine.LFD.2.21.1805051227140.18610@reclus.nhh.no>
References: <CAFAdVoZ2b7Sjee0GGvy22RcXL-we_0NNifp+qsdaZ0kMhRDe4Q@mail.gmail.com>
 <alpine.LFD.2.21.1805051227140.18610@reclus.nhh.no>
Message-ID: <CAFAdVoYxK-EDgXSrhactWMX6xo_7Js9SDonD1KnVXJsBWCoDPQ@mail.gmail.com>

Hi Roger.

First of all, thank for your help.

Yes, my first two colums are year and id (identification for cities).

I really do not understand, because with the same data I run the regression
in Stata.

There is my full code:
""
# Data
data <- read.xlsx("RJ_database.xlsx", 1, header = TRUE)
panel <- pdata.frame(data, index = c("id", "year"))
time <- length(unique(data$year)) #Salving data time length

pdim(panel)
summary(panel)

poly <- readOGR(dsn ="C:/Users/user/OneDrive/Resource Policy Paper", layer
= "RJ") #Desktop
RJ <- poly2nb(poly)

W <- nb2listw(RJ, style = "W", glist = NULL)
summary(W)

### Kronecker Product
kronecker.W <- listw2dgCMatrix(W)
W_queen2 <- kronecker(Diagonal(time), kronecker.W)
W_queen <- mat2listw(W_queen2, style = "W")

SAR <- spml(gdp ~ oivrev, listw = rjq, model="within", spatial.error= NULL,
lag = TRUE, data=panel)
summary(W_queen)
str(panel)

OLS <- plm(gdp ~ oivrev, model = "within", data = panel)
summary(OLS)

""
And, weird the most is when I run OLS model panel works.

Could you try in your own R to check it out?

Thank you.

On Sat, May 5, 2018 at 7:35 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Sat, 5 May 2018, felipe tavares wrote:
>
> Good evening.
>>
>> I am trying to estimate a spatial panel data model through splm package.
>>
>> I am facing the error: Error in lag.listw(listw, u, zero.policy =
>> zero.policy) :
>>  object lengths differ
>>
>> However, my W matrix is NxN, my y vector is NTx1 and my X matrix is NTxK.
>>
>> My code is:
>> poly <- readOGR(dsn ="C:/Users/fstavares/OneDrive/Resource Policy Paper",
>> layer = "RJ")
>> RJ <- poly2nb(poly)
>> W <- nb2listw(RJ, zero.policy = TRUE, style = "W", glist = NULL)
>> SEM <- spml(gdp ~ oivrev, listw = W, model="within", spatial.error="b",
>> lag=F, data=panel)
>>
>>
> Are the first two columns of panel as required (from ?spml):
>
>     data: an object of class ?data.frame? or ?pdata.frame?. A data
>           frame containing the variables in the model. When the object
>           is a ?data.frame?, the first two columns shall contain the
>           indexes, unless otherwise specified. See ?index?
>
> From ?index
>
>      Panel data are stored in a ?"pdata.frame"? which has an ?"index"?
>      attribute. Fitted models in ?"plm"? have a ?"model"? element which
>      is also a ?"pdata.frame"? and therefore also has an ?"index"?
>      attribute. Finally, each series, once extracted from a
>      ?"pdata.frame"?, becomes of class ?"pseries"?, which also has this
>      ?"index"? attribute.  ?"index"? methods are available for all
>      these objects.  The argument ?"which"? indicates which index
>      should be extracted. If ?which = NULL?, all indexes are extracted.
>      ?"which"? can also be a vector of length 1, 2, or 3 (3 only if the
>      pdata frame was constructed with an additional group index)
>      containing either characters (the names of the individual variable
>      and/or of the time variable and/or the group variable or ?"id"?
>      and ?"time"?) and ?"group"? or integers (1 for the individual
>      index, 2 for the time index, and 3 for the group index (the latter
>      only if the pdata frame was constructed with such).)
>
> and:
>
> str(Produc)
>>
> 'data.frame':   816 obs. of  11 variables:
>  $ state : Factor w/ 48 levels "ALABAMA","ARIZONA",..: 1 1 1 1 1 1 1 1 1 1
> ...
>  $ year  : int  1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 ...
>  $ region: Factor w/ 9 levels "1","2","3","4",..: 6 6 6 6 6 6 6 6 6 6 ...
>  $ pcap  : num  15033 15502 15972 16406 16763 ...
>  $ hwy   : num  7326 7526 7765 7908 8026 ...
>  $ water : num  1656 1721 1765 1742 1735 ...
>  $ util  : num  6051 6255 6442 6756 7002 ...
>  $ pc    : num  35794 37300 38670 40084 42057 ...
>  $ gsp   : int  28418 29375 31303 33430 33749 33604 35764 37463 39964
> 40979 ...
>  $ emp   : num  1010 1022 1072 1136 1170 ...
>  $ unemp : num  4.7 5.2 4.7 3.9 5.5 7.7 6.8 7.4 6.3 7.1 ...
>
> with the individual column first varying slowly, and the time column
> second varying within the first column values. Since you do not provide a
> reproducible example (not your data and code, an example using built-in
> data), it is hard to know.
>
> Hope this clarifies,
>
> Roger
>
>
>
>> Does anyone have faced this problem?
>>
>> I can send database and code, if it somebody can help me.
>>
>>
>>
>>
>>
> --
> Roger Bivand
> Department of Economics, Norwegian Sc
> <https://maps.google.com/?q=Norwegian+Sc&entry=gmail&source=g>hool of
> Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en




-- 
Att,

Felipe Tavares
Bacharel em Ci?ncias Econ?micas - UFSCar
Mestrando em Economia Aplicada - ESALQ/USP
Analista Pricing - ALLIED Technology

Telefone:
(011) 97468-0833

e-mail:
ftavares29 at gmail.com
f <ftavares29 at usp.br>stavares at alliedbrasil.com.br

	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Mon May  7 21:13:07 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Mon, 7 May 2018 21:13:07 +0200
Subject: [R-sig-Geo] Spatial Panel Models Problem (Splm package)
In-Reply-To: <CAFAdVoYxK-EDgXSrhactWMX6xo_7Js9SDonD1KnVXJsBWCoDPQ@mail.gmail.com>
References: <CAFAdVoZ2b7Sjee0GGvy22RcXL-we_0NNifp+qsdaZ0kMhRDe4Q@mail.gmail.com>
 <alpine.LFD.2.21.1805051227140.18610@reclus.nhh.no>
 <CAFAdVoYxK-EDgXSrhactWMX6xo_7Js9SDonD1KnVXJsBWCoDPQ@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.1805072104120.2162@reclus.nhh.no>

On Mon, 7 May 2018, felipe tavares wrote:

> Hi Roger.
>
> First of all, thank for your help.
>
> Yes, my first two colums are year and id (identification for cities).
>
> I really do not understand, because with the same data I run the regression
> in Stata.
>
> There is my full code:
> ""
> # Data
> data <- read.xlsx("RJ_database.xlsx", 1, header = TRUE)
> panel <- pdata.frame(data, index = c("id", "year"))
> time <- length(unique(data$year)) #Salving data time length
>
> pdim(panel)
> summary(panel)
>
> poly <- readOGR(dsn ="C:/Users/user/OneDrive/Resource Policy Paper", layer
> = "RJ") #Desktop
> RJ <- poly2nb(poly)
>
> W <- nb2listw(RJ, style = "W", glist = NULL)
> summary(W)
>
> ### Kronecker Product
> kronecker.W <- listw2dgCMatrix(W)
> W_queen2 <- kronecker(Diagonal(time), kronecker.W)
> W_queen <- mat2listw(W_queen2, style = "W")

This is the problem. You do not need to generate the Kronecker problem 
yourself (using the example in ?spml:

library(splm)
data(Produc, package = "plm")
data(usaww)
W <- mat2listw(usaww, style = "W")

# This is what you did:

years <- length(unique(Produc$year))
kronecker.W <- listw2dgCMatrix(W)
W_queen2 <- kronecker(Diagonal(years), kronecker.W)
W_queen <- mat2listw(W_queen2, style = "W")

fm <- log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp
SAR <- spml(fm, listw = W_queen, model="within", spatial.error= NULL,
   lag = TRUE, data=Produc)
# Error in lag.listw(listw, u, zero.policy = zero.policy) :
#   object lengths differ

# It works if you just pass the listw object:
SAR <- spml(fm, listw = W, model="within", spatial.error= NULL,lag = TRUE,
   data=Produc)

When reading documentation, please do not ignore the examples. They are 
tested once a day on more than 12 different platforms, and can be relied 
upon. This is also explained in the JSS article, which I assume you have 
read and will cite.

Roger

>
> SAR <- spml(gdp ~ oivrev, listw = rjq, model="within", spatial.error= NULL,
> lag = TRUE, data=panel)
> summary(W_queen)
> str(panel)
>
> OLS <- plm(gdp ~ oivrev, model = "within", data = panel)
> summary(OLS)
>
> ""
> And, weird the most is when I run OLS model panel works.
>
> Could you try in your own R to check it out?
>
> Thank you.
>
> On Sat, May 5, 2018 at 7:35 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Sat, 5 May 2018, felipe tavares wrote:
>>
>> Good evening.
>>>
>>> I am trying to estimate a spatial panel data model through splm package.
>>>
>>> I am facing the error: Error in lag.listw(listw, u, zero.policy =
>>> zero.policy) :
>>>  object lengths differ
>>>
>>> However, my W matrix is NxN, my y vector is NTx1 and my X matrix is NTxK.
>>>
>>> My code is:
>>> poly <- readOGR(dsn ="C:/Users/fstavares/OneDrive/Resource Policy Paper",
>>> layer = "RJ")
>>> RJ <- poly2nb(poly)
>>> W <- nb2listw(RJ, zero.policy = TRUE, style = "W", glist = NULL)
>>> SEM <- spml(gdp ~ oivrev, listw = W, model="within", spatial.error="b",
>>> lag=F, data=panel)
>>>
>>>
>> Are the first two columns of panel as required (from ?spml):
>>
>>     data: an object of class ?data.frame? or ?pdata.frame?. A data
>>           frame containing the variables in the model. When the object
>>           is a ?data.frame?, the first two columns shall contain the
>>           indexes, unless otherwise specified. See ?index?
>>
>> From ?index
>>
>>      Panel data are stored in a ?"pdata.frame"? which has an ?"index"?
>>      attribute. Fitted models in ?"plm"? have a ?"model"? element which
>>      is also a ?"pdata.frame"? and therefore also has an ?"index"?
>>      attribute. Finally, each series, once extracted from a
>>      ?"pdata.frame"?, becomes of class ?"pseries"?, which also has this
>>      ?"index"? attribute.  ?"index"? methods are available for all
>>      these objects.  The argument ?"which"? indicates which index
>>      should be extracted. If ?which = NULL?, all indexes are extracted.
>>      ?"which"? can also be a vector of length 1, 2, or 3 (3 only if the
>>      pdata frame was constructed with an additional group index)
>>      containing either characters (the names of the individual variable
>>      and/or of the time variable and/or the group variable or ?"id"?
>>      and ?"time"?) and ?"group"? or integers (1 for the individual
>>      index, 2 for the time index, and 3 for the group index (the latter
>>      only if the pdata frame was constructed with such).)
>>
>> and:
>>
>> str(Produc)
>>>
>> 'data.frame':   816 obs. of  11 variables:
>>  $ state : Factor w/ 48 levels "ALABAMA","ARIZONA",..: 1 1 1 1 1 1 1 1 1 1
>> ...
>>  $ year  : int  1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 ...
>>  $ region: Factor w/ 9 levels "1","2","3","4",..: 6 6 6 6 6 6 6 6 6 6 ...
>>  $ pcap  : num  15033 15502 15972 16406 16763 ...
>>  $ hwy   : num  7326 7526 7765 7908 8026 ...
>>  $ water : num  1656 1721 1765 1742 1735 ...
>>  $ util  : num  6051 6255 6442 6756 7002 ...
>>  $ pc    : num  35794 37300 38670 40084 42057 ...
>>  $ gsp   : int  28418 29375 31303 33430 33749 33604 35764 37463 39964
>> 40979 ...
>>  $ emp   : num  1010 1022 1072 1136 1170 ...
>>  $ unemp : num  4.7 5.2 4.7 3.9 5.5 7.7 6.8 7.4 6.3 7.1 ...
>>
>> with the individual column first varying slowly, and the time column
>> second varying within the first column values. Since you do not provide a
>> reproducible example (not your data and code, an example using built-in
>> data), it is hard to know.
>>
>> Hope this clarifies,
>>
>> Roger
>>
>>
>>
>>> Does anyone have faced this problem?
>>>
>>> I can send database and code, if it somebody can help me.
>>>
>>>
>>>
>>>
>>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian Sc
>> <https://maps.google.com/?q=Norwegian+Sc&entry=gmail&source=g>hool of
>> Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>> http://orcid.org/0000-0003-2392-6140
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>
>
>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From @@iku142 @ending from gm@il@com  Tue May  8 01:04:58 2018
From: @@iku142 @ending from gm@il@com (Surya Kr)
Date: Mon, 07 May 2018 23:04:58 +0000
Subject: [R-sig-Geo] Simulating spatial data using gstat
Message-ID: <CAJR1vXXLTd4VGp1ZFoq5BindtCrt=1ZfTM5aTL5tcfuzeKviqA@mail.gmail.com>

Hi All -

I'm experimenting with the gstat package trying to do something basic. I
want to simulate data with an isotropic covariance structure and turn
around and fit a variogram to the simulated data. I get several warnings
while estimating the variogram indicating failed convergence -

Warning messages:
1: In fit.variogram(o, m, fit.kappa = FALSE, fit.method = fit.method,  ... :
   No convergence after 200 iterations: try different initial values?

My trend surface has the following linear term:
longitude+latitude+covariate_x. Note there is no intercept. The error is
from the Matern model. I'm new to spatial data analysis in R. Very much
appreciate your patience and help if you could correct me if I missed out
on anything. Here's my code -

### simulate the data
# Matern with partial sill, range, and nugget.
v.sim <- vgm(200, "Mat", 30, 20, kappa = 0.1)
g.sim <- gstat(NULL, "z", z~longitude+latitude+covariate_x,
locations=~longitude_dgr+latitude_dgr, beta = c(0.10, 0.20, 0.40),
dummy=TRUE, model = v.sim, nmax=50)
yy <- predict(g.sim, newdata = mydata, nsim = 1) # mydata is a data.table
and has the longitude, latitude, and covariate_x
coordinates(yy) <- c("longitude", "latitude")

### Do an empirical variogram and fit a Matern model
## Add covariate_x to the simulated dataset
yy$covariate_x = mydata$covariate_x
variog_gstat <- variogram(sim1 ~ longitude+latitude+covariate_x, data = yy)
fit.g <- fit.variogram(variog_gstat, vgm(200, "Mat", 30, 20),
fit.kappa=TRUE)
> fit.g
   model    psill    range kappa
1   Nug  95.4979  0.00000   0.0
2   Mat 210.2117 46.92647   0.3
#plot(variog_gstat, fit.g)
## confirming that the above is equivalent to analyzing residuals from
ordinary least squares
lmObj <- lm(sim1 ~ longitude + latitude + covariate_x, data=yy)
yy$lmresids <- lmObj$residuals
variog_gstat1 <- variogram(lmresids ~ 1, data = yy)
#plot(variog_gstat1)
fit.g1 <- fit.variogram(variog_gstat1, vgm(200, "Mat", 30, 20),
fit.kappa=TRUE)
> fit.g1
   model    psill    range kappa
1   Nug  95.4979  0.00000   0.0
2   Mat 210.2117 46.92647   0.3
#plot(variog_gstat1, fit.g1)

My questions:
------------------
1. Did I simulate the dataset with the spatial trend and covariance right?
2. How to correctly estimate variogram from empirical variogram without
getting those warnings. Note that my initial values for the parameters are
the same as the true values. How to make the variogram fitting exercise
more reliable/robust?
2.1. How to choose initial values in an automated fashion? I need to fit
variograms for several spatial datasets (possibly in parallel on a cluster)
and I need to automate choosing the initial parameter values.
3. Is there an example showing similar code for variogram fitting and
simulation of spatial data using the "Fields" package?

Thanks much,
Surya

ps: can I attached plots when I message R-sig-geo and have them displayed
on the message?


From brun@e@ti @ending from gm@il@com  Tue May  8 17:57:26 2018
From: brun@e@ti @ending from gm@il@com (Bruno Sesti)
Date: Tue, 8 May 2018 17:57:26 +0200
Subject: [R-sig-Geo] Spatio-Temporal Kriging - fitting of spatio-temporal
 variogram
Message-ID: <CAFnjcD1H6pbkMK_Pn=hOwpzG9HTPPhS1ReZyptmeu3qr8UOw-w@mail.gmail.com>

Hi,
I am trying to do spatio-temporal kriging. At the moment I was focusing on
the creation and fitting of the empirical variogram
SoI would likre to ask the following question about this issue: how can I
know what value I have to set for parameter range, sill, nugget and model
for the vgm models that have to be set in the function fit.stVariogram,
relatively to the space variogram model, the time variogram model and, if
it is required, the joint variogram model?
I tried to set values (for range, sill, nugget and theoretical model for
each vgm (space, time, joint), using reasonable values and in line with the
defined values, for example, for spatial and temporal ranges and for
spatial and temporal lags.

Kind regards.

	[[alternative HTML version deleted]]


From brun@e@ti @ending from gm@il@com  Sat May 12 21:05:19 2018
From: brun@e@ti @ending from gm@il@com (Bruno Sesti)
Date: Sat, 12 May 2018 21:05:19 +0200
Subject: [R-sig-Geo] Help about gstat's functions for spatio temporal data
 interpolation
Message-ID: <CAFnjcD0f=j36PFHH7cKUEEMRKSuPQQqGk62kCDZ-ep5H_QrX5A@mail.gmail.com>

Hi, I am trying to do spatio-temporal kriging and I am interested
especially in the software implementation of the algorithm and of data
analysis. I saw that R have many libraries and routines to perform spatial
and spatii-temporal kriging. I would like to know if it could be possible
to get the source code of some functions that package gstat offers to
perform spatio-temporal kriging, that are:
variogramST(), vgmST(), fit.StVariogram().

Kind regards.

	[[alternative HTML version deleted]]


From edzer@pebe@m@ @ending from uni-muen@ter@de  Sun May 13 11:56:11 2018
From: edzer@pebe@m@ @ending from uni-muen@ter@de (Edzer Pebesma)
Date: Sun, 13 May 2018 11:56:11 +0200
Subject: [R-sig-Geo] 
 Help about gstat's functions for spatio temporal data interpolation
In-Reply-To: <CAFnjcD0f=j36PFHH7cKUEEMRKSuPQQqGk62kCDZ-ep5H_QrX5A@mail.gmail.com>
References: <CAFnjcD0f=j36PFHH7cKUEEMRKSuPQQqGk62kCDZ-ep5H_QrX5A@mail.gmail.com>
Message-ID: <b7ac7f86-3a0b-e723-1c6a-bef63efc414d@uni-muenster.de>

Dear Bruno,

you'll find everything at https://github.com/edzer/gstat

On 05/12/2018 09:05 PM, Bruno Sesti wrote:
> Hi, I am trying to do spatio-temporal kriging and I am interested
> especially in the software implementation of the algorithm and of data
> analysis. I saw that R have many libraries and routines to perform spatial
> and spatii-temporal kriging. I would like to know if it could be possible
> to get the source code of some functions that package gstat offers to
> perform spatio-temporal kriging, that are:
> variogramST(), vgmST(), fit.StVariogram().
> 
> Kind regards.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48151 Muenster, Germany
Phone: +49 251 8333081


From jefune@ @ending from gm@il@com  Mon May 14 08:16:01 2018
From: jefune@ @ending from gm@il@com (Jose Funes)
Date: Mon, 14 May 2018 02:16:01 -0400
Subject: [R-sig-Geo] INLA
Message-ID: <CAG1eJiHksLbh8akNTzG9aQanQM0y1+Zk7xj9nMqHtf1ga+VueQ@mail.gmail.com>

Hi,
I am new on INLA. I was wondering, how di i extract the parameters
estimates from an sdm.inla object? does sdm_inla also work for spatial
durbin probit model? I will highly appreciate your inputs.
Thanks,
Jose
University of Maryland at College Park
Department of Geographical Sciences

	[[alternative HTML version deleted]]


From @@@oufi@nou @ending from y@hoo@fr  Mon May 14 10:17:36 2018
From: @@@oufi@nou @ending from y@hoo@fr (Soufianou Abou)
Date: Mon, 14 May 2018 08:17:36 +0000 (UTC)
Subject: [R-sig-Geo] Help
References: <1399013555.1518924.1526285856933.ref@mail.yahoo.com>
Message-ID: <1399013555.1518924.1526285856933@mail.yahoo.com>

Bonjour , j'aimerais utiliser? maxent pour mod?liser la distribution potentielle du ni?b? sur la base des donn?es de pr?sence seuls. En effet, jai acquis un certains nombre de variables environnementales et bioclimatiques concernant ma zone d'?tude.? Mais pour choisir les variables les plus contributives dans le mod?le; j'aimerai faire une analyse de correlation de celles-ci. Sur ce, pourriez?vous m'expliquer etape par etape les procedures ? suivre sous R ? J'aimerais dire par l? le scripts pour:??-????compiler et appeler toutes les variables environnementales et les donn?es d'occurence;?-????executer le tester de correlation;-????pour faire une analyse discriminante?

Merci par avance














SADDA Abou-Soufianou











	[[alternative HTML version deleted]]


From r@turner @ending from @uckl@nd@@c@nz  Mon May 14 11:37:18 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Mon, 14 May 2018 21:37:18 +1200
Subject: [R-sig-Geo] [FORGED]  Help
In-Reply-To: <1399013555.1518924.1526285856933@mail.yahoo.com>
References: <1399013555.1518924.1526285856933.ref@mail.yahoo.com>
 <1399013555.1518924.1526285856933@mail.yahoo.com>
Message-ID: <974dd812-75cc-8453-ff39-230e6017dedf@auckland.ac.nz>


On 14/05/18 20:17, Soufianou Abou via R-sig-Geo wrote:

> Bonjour , j'aimerais utiliser  maxent pour mod?liser la distribution
> potentielle du ni?b? sur la base des donn?es de pr?sence seuls. En
> effet, jai acquis un certains nombre de variables environnementales
> et bioclimatiques concernant ma zone d'?tude.  Mais pour choisir les
> variables les plus contributives dans le mod?le; j'aimerai faire une
> analyse de correlation de celles-ci. Sur ce, pourriez vous
> m'expliquer etape par etape les procedures ? suivre sous R ?
> J'aimerais dire par l? le scripts pour:  -    compiler et appeler
> toutes les variables environnementales et les donn?es d'occurence; -
> executer le tester de correlation;-    pour faire une analyse
> discriminante?
> 
> Merci par avance.
La langue de cette liste est l'anglais.
S'il vous pla?t exprimer votre question en anglais.

I'm afraid that my French is insufficient to follow your question 
properly, but I gather that you have presence-only data (for some 
phenomenon) and a number of environmental variables from which you hope 
to predict occurrences of this phenomenon.

You also express an interest in undertaking a correlation analysis of 
your predictors and performing "tests of correlation".

Given that I am understanding you correctly, I would advise against 
this.  The proper strategy (IMHO) is to *fit a model* using your 
predictors and then assess their predictive power in this model,in some way.

If the "presence only" data, that you have, can be considered to be 
point locations, and if the values of your predictors are available at 
all points of your study region, then you may be able to effect the 
required model fitting using the facilities of the spatstat package.

Anyway, please re-post your question en anglais, if you can.  You are 
much more likely to get a useful answer if you do.  Bon chance.

Cordialement,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @@@oufi@nou @ending from y@hoo@fr  Mon May 14 12:28:07 2018
From: @@@oufi@nou @ending from y@hoo@fr (Soufianou Abou)
Date: Mon, 14 May 2018 10:28:07 +0000 (UTC)
Subject: [R-sig-Geo] Help
In-Reply-To: <cc538908-6ac6-0848-27de-888d8babd418@auckland.ac.nz>
References: <1399013555.1518924.1526285856933.ref@mail.yahoo.com>
 <1399013555.1518924.1526285856933@mail.yahoo.com>
 <974dd812-75cc-8453-ff39-230e6017dedf@auckland.ac.nz>
 <906029635.1608753.1526291336354@mail.yahoo.com>
 <cc538908-6ac6-0848-27de-888d8babd418@auckland.ac.nz>
Message-ID: <1835382272.1651251.1526293687217@mail.yahoo.com>

Dear Rolf Turner,

 I have points of presence of cowpea in Niger in CSV format; in addition to other variables (soil texture, soil pH, altitude, I downloaded from worldclim archives, the 19 environmental variables, I cut them all at the Niger scale and I converted them under ASCUI format. The idea for me is to choose the best variables to include in the model.
?NB. I'm using Maxent model, but I'm not good in R?software.

Merci














SADDA Abou-Soufianou

--------------------------------------

Doctorant

Universit? Dan Dicko Dankoulodo deMaradi-Niger

BP 465?120, avenue MamanKoraou-?ADS

???????????????????&

Institut?d?Ecologie et des Sciencesde l?Environnement de Paris (iEES-Paris)

Centre IRD France Nord-(iEES Paris)-32,av.Henri Varangnat 93143 BONDY cedex.

|  
Lien:?https://ieesparis.ufr918.upmc.fr/index.php?page=fiche&id=378&droit=1


?abousoufianou at gmail.com

GSM?: Niger?: (+227) 96-26-99-87/91-56-35-19?; France?(+?33)? 07-55-79-39-93

?
  |  
?
  |










    Le lundi 14 mai 2018 ? 12:05:40 UTC+2, Rolf Turner <r.turner at auckland.ac.nz> a ?crit :  



Please keep your posts "on-list".? You are much more likely to get a 
useful answer that way.? There are many others on the list whose 
knowledge and insight are far greater than mine.

I have therefore cc-ed the list in this reply.

On 14/05/18 21:48, Soufianou Abou wrote:

> Thank you for advice, Rolf Turner
> 
> My question is as follows:
> 
> I'd use maxent to model the potential distribution of cowpea on the 
> basis of the only presence data. Indeed, I have acquired a number of 
> environmental variables and bioclimatic regarding my area of study. But 
> to choose the most contributive variables in the model; I would like to 
> make a correlation analysis of these. On this, could you explain to me 
> the step by step procedures to follow in R? I would like to say scripts 
> for:- compile and call all environmental variables;- run the correlation
> test to select the least correlated ones.

As I said before, I don't think this is the right approach, but I can't 
be sure without knowing more about your data.? I find your description
to be vague.

How are your data stored?? What information do you have about the 
"distribution of cowpea".? Do you have *points* where cowpea is present 
or more extensive *regions* where it is present?? (And could these 
regions be "considered to be points" on the scale of interest?) How are 
your predictors stored?? Are the values of these predictors known at 
every point of your study area?? Can you show us a bit of your data (use 
the function dput() to include *a small sample* of your data in the body 
of your email).

If you insist on mucking about with correlation and testing, perhaps the 
function cor.test() will give you what you want.? I reiterate however
that this seems to me to be a wrong approach.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
  
	[[alternative HTML version deleted]]


From bf@levli@t @ending from gm@il@com  Mon May 14 13:42:10 2018
From: bf@levli@t @ending from gm@il@com (=?UTF-8?Q?Bede-Fazekas_=c3=81kos?=)
Date: Mon, 14 May 2018 13:42:10 +0200
Subject: [R-sig-Geo] Help
In-Reply-To: <1835382272.1651251.1526293687217@mail.yahoo.com>
References: <1399013555.1518924.1526285856933.ref@mail.yahoo.com>
 <1399013555.1518924.1526285856933@mail.yahoo.com>
 <974dd812-75cc-8453-ff39-230e6017dedf@auckland.ac.nz>
 <906029635.1608753.1526291336354@mail.yahoo.com>
 <cc538908-6ac6-0848-27de-888d8babd418@auckland.ac.nz>
 <1835382272.1651251.1526293687217@mail.yahoo.com>
Message-ID: <b799a8e6-ec59-9fad-db1b-04411e157083@gmail.com>

Dear Soufianou,
this is just a framework. Let's say that you have a vector ('variables') 
containing the name of the environmental variables.

library(raster)
library(dismo)
library(corrplot)

for (variable in variables) {
 ??? assign(variable, raster(paste0(variable, ".asc"))
}
environment <- brick(variables)
environment_standardized <- data.frame(scale(x = 
as.data.frame(environment), center = TRUE, scale = TRUE))

correlation_matrix <- cor(environment_standardized, use = "na.or.complete")
corrplot(corr = correlation_matrix)
VIF <- vif(environment_standardized)
CN <- kappa(na.omit(environment_standardized), exact = TRUE)
# You can select variables that fulfill your criteria about correlation 
structure
selected_variables <- variables[c()] # subsetting

maxent(x = environment[[selected_variables]] , p = presence_points)

HTH,
?kos Bede-Fazekas
Hungarian Academy of Sciences

2018.05.14. 12:28 keltez?ssel, Soufianou Abou via R-sig-Geo ?rta:
> Dear Rolf Turner,
>
>   I have points of presence of cowpea in Niger in CSV format; in addition to other variables (soil texture, soil pH, altitude, I downloaded from worldclim archives, the 19 environmental variables, I cut them all at the Niger scale and I converted them under ASCUI format. The idea for me is to choose the best variables to include in the model.
>  ?NB. I'm using Maxent model, but I'm not good in R?software.
>
> Merci
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> SADDA Abou-Soufianou
>
> --------------------------------------
>
> Doctorant
>
> Universit? Dan Dicko Dankoulodo deMaradi-Niger
>
> BP 465?120, avenue MamanKoraou-?ADS
>
>  ???????????????????&
>
> Institut?d?Ecologie et des Sciencesde l?Environnement de Paris (iEES-Paris)
>
> Centre IRD France Nord-(iEES Paris)-32,av.Henri Varangnat 93143 BONDY cedex.
>
> |
> Lien:?https://ieesparis.ufr918.upmc.fr/index.php?page=fiche&id=378&droit=1
>
>
>  ?abousoufianou at gmail.com
>
> GSM?: Niger?: (+227) 96-26-99-87/91-56-35-19?; France?(+?33)? 07-55-79-39-93
>
>   
>    |
>   
>    |
>
>
>
>
>
>
>
>
>
>
>      Le lundi 14 mai 2018 ? 12:05:40 UTC+2, Rolf Turner <r.turner at auckland.ac.nz> a ?crit :
>
>
>
> Please keep your posts "on-list".? You are much more likely to get a
> useful answer that way.? There are many others on the list whose
> knowledge and insight are far greater than mine.
>
> I have therefore cc-ed the list in this reply.
>
> On 14/05/18 21:48, Soufianou Abou wrote:
>
>> Thank you for advice, Rolf Turner
>>
>> My question is as follows:
>>
>> I'd use maxent to model the potential distribution of cowpea on the
>> basis of the only presence data. Indeed, I have acquired a number of
>> environmental variables and bioclimatic regarding my area of study. But
>> to choose the most contributive variables in the model; I would like to
>> make a correlation analysis of these. On this, could you explain to me
>> the step by step procedures to follow in R? I would like to say scripts
>> for:- compile and call all environmental variables;- run the correlation
>> test to select the least correlated ones.
> As I said before, I don't think this is the right approach, but I can't
> be sure without knowing more about your data.? I find your description
> to be vague.
>
> How are your data stored?? What information do you have about the
> "distribution of cowpea".? Do you have *points* where cowpea is present
> or more extensive *regions* where it is present?? (And could these
> regions be "considered to be points" on the scale of interest?) How are
> your predictors stored?? Are the values of these predictors known at
> every point of your study area?? Can you show us a bit of your data (use
> the function dput() to include *a small sample* of your data in the body
> of your email).
>
> If you insist on mucking about with correlation and testing, perhaps the
> function cor.test() will give you what you want.? I reiterate however
> that this seems to me to be a wrong approach.
>
> cheers,
>
> Rolf Turner
>


From brun@e@ti @ending from gm@il@com  Mon May 14 15:52:00 2018
From: brun@e@ti @ending from gm@il@com (Bruno Sesti)
Date: Mon, 14 May 2018 15:52:00 +0200
Subject: [R-sig-Geo] Resources and Technical issues about Spatio Temporal
 Kriging
Message-ID: <CAFnjcD1fgdN3KF3+1Ogz8v_r2nHr1pcdb6dpmSbrkXUJhysZfQ@mail.gmail.com>

Hi,
I am trying to do spatio temporal kriging. I have produced some prediction
maps, but during the process, I noticed something of strange:
during the execution of the function krigeST I saw a high usage of RAM
memory and Disk, which sometimes produced the crash of RStudio. It is
normal? I am using a spatio-temporal grid of about 2000 points as 'newdata'
parameter in krigeST function.
Another issues is that the result of the function krigeST seems to be a
multiple map (for example I made a temporal grid of length 2, so I got 2 in
1 prediction  map as the result of krigeST). I am not sure if the "number"
of prediction maps depends on the length of temporal grid. In any way, it
could.be possible to obtain a unique prediction map as the result of
krigeST (as in the pure spatial context, for example)?

Kind regards.

	[[alternative HTML version deleted]]


From edzer@pebe@m@ @ending from uni-muen@ter@de  Tue May 15 19:58:21 2018
From: edzer@pebe@m@ @ending from uni-muen@ter@de (Edzer Pebesma)
Date: Tue, 15 May 2018 19:58:21 +0200
Subject: [R-sig-Geo] Will upcoming ggplot2::calc() clash with raster::calc()?
Message-ID: <8fe6cb59-74e2-d0cc-4d15-f116a524ae3a@uni-muenster.de>

This was asked on twitter:
https://twitter.com/hadleywickham/status/996430251499536385 , by Hadley
Wickham:

"Can any raster user comment on if the new ggplot2::calc() function is
going to cause significant pain because it clashes with raster::calc()?"

I'll report answers back to twitter, or directly to Hadley if it doesn't
fit in 280 chars.
-- 
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48151 Muenster, Germany
Phone: +49 251 8333081


From b@rowling@on @ending from l@nc@@ter@@c@uk  Wed May 16 18:42:14 2018
From: b@rowling@on @ending from l@nc@@ter@@c@uk (Barry Rowlingson)
Date: Wed, 16 May 2018 17:42:14 +0100
Subject: [R-sig-Geo] Will upcoming ggplot2::calc() clash with
 raster::calc()?
In-Reply-To: <8fe6cb59-74e2-d0cc-4d15-f116a524ae3a@uni-muenster.de>
References: <8fe6cb59-74e2-d0cc-4d15-f116a524ae3a@uni-muenster.de>
Message-ID: <CANVKczMA18Agg7Rx9ORaD79TAv7oPaiNNKUhkRjFQoa60_Vu1A@mail.gmail.com>

It seems the options are:

1. ggplot2 and raster use calc - scripts will have to use raster::calc or
ggplot2::calc to be ambiguous.

 This is the painful solution. Scripts will break. Users will have to type
raster::calc or ggplot2::calc depending on the order they do
library(raster);library(ggplot2). Both packages are often used together.

2. `calc` becomes a "generic" and despatches to the right specific function
when called on a raster or whatever ggplot2::calc needs.

 This either requires "ggplot2" to have "raster" as a dependency or for the
generic to be moved to a package that each of these will depend on. An S3
or S4 generic? Will it even work? Nobody wants to manage the dependency.

3. Use a different name in `ggplot2`, for example, `val`, which has the
same sense - compare:

   geom_histogram(aes(y = *calc*(count)))
   geom_histogram(aes(y = *val*(count)))

4. ggplot2 does something else - maybe the aesthetic could be specified as
a formula?

  geom_histogram(aes(y = ~count))

 but that would require a chunk of ggplot2 rewriting

Barry





On Tue, May 15, 2018 at 6:58 PM, Edzer Pebesma <
edzer.pebesma at uni-muenster.de> wrote:

> This was asked on twitter:
> https://twitter.com/hadleywickham/status/996430251499536385 , by Hadley
> Wickham:
>
> "Can any raster user comment on if the new ggplot2::calc() function is
> going to cause significant pain because it clashes with raster::calc()?"
>
> I'll report answers back to twitter, or directly to Hadley if it doesn't
> fit in 280 chars.
> --
> Edzer Pebesma
> Institute for Geoinformatics
> Heisenbergstrasse 2, 48151 Muenster, Germany
> Phone: +49 251 8333081
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From h@wickh@m @ending from gm@il@com  Wed May 16 20:05:15 2018
From: h@wickh@m @ending from gm@il@com (Hadley Wickham)
Date: Wed, 16 May 2018 11:05:15 -0700
Subject: [R-sig-Geo] Will upcoming ggplot2::calc() clash with
 raster::calc()?
In-Reply-To: <CANVKczMA18Agg7Rx9ORaD79TAv7oPaiNNKUhkRjFQoa60_Vu1A@mail.gmail.com>
References: <8fe6cb59-74e2-d0cc-4d15-f116a524ae3a@uni-muenster.de>
 <CANVKczMA18Agg7Rx9ORaD79TAv7oPaiNNKUhkRjFQoa60_Vu1A@mail.gmail.com>
Message-ID: <CABdHhvFJ6jFrsyHBXSm9VgUAEd_6yLNjzXoD1oq1izuxiC64Kw@mail.gmail.com>

We are tracking at https://github.com/tidyverse/ggplot2/issues/2614 ?
and have come up with a name that I prefer to calc(): stat().

Hadley

On Wed, May 16, 2018 at 9:42 AM, Barry Rowlingson
<b.rowlingson at lancaster.ac.uk> wrote:
> It seems the options are:
>
> 1. ggplot2 and raster use calc - scripts will have to use raster::calc or
> ggplot2::calc to be ambiguous.
>
>  This is the painful solution. Scripts will break. Users will have to type
> raster::calc or ggplot2::calc depending on the order they do
> library(raster);library(ggplot2). Both packages are often used together.
>
> 2. `calc` becomes a "generic" and despatches to the right specific function
> when called on a raster or whatever ggplot2::calc needs.
>
>  This either requires "ggplot2" to have "raster" as a dependency or for the
> generic to be moved to a package that each of these will depend on. An S3
> or S4 generic? Will it even work? Nobody wants to manage the dependency.
>
> 3. Use a different name in `ggplot2`, for example, `val`, which has the
> same sense - compare:
>
>    geom_histogram(aes(y = *calc*(count)))
>    geom_histogram(aes(y = *val*(count)))
>
> 4. ggplot2 does something else - maybe the aesthetic could be specified as
> a formula?
>
>   geom_histogram(aes(y = ~count))
>
>  but that would require a chunk of ggplot2 rewriting
>
> Barry
>
>
>
>
>
> On Tue, May 15, 2018 at 6:58 PM, Edzer Pebesma <
> edzer.pebesma at uni-muenster.de> wrote:
>
>> This was asked on twitter:
>> https://twitter.com/hadleywickham/status/996430251499536385 , by Hadley
>> Wickham:
>>
>> "Can any raster user comment on if the new ggplot2::calc() function is
>> going to cause significant pain because it clashes with raster::calc()?"
>>
>> I'll report answers back to twitter, or directly to Hadley if it doesn't
>> fit in 280 chars.
>> --
>> Edzer Pebesma
>> Institute for Geoinformatics
>> Heisenbergstrasse 2, 48151 Muenster, Germany
>> Phone: +49 251 8333081
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
http://hadley.nz


From jmbc@rreir@@ @ending from gm@il@com  Wed May 16 20:27:50 2018
From: jmbc@rreir@@ @ending from gm@il@com (=?UTF-8?Q?Jo=C3=A3o_Carreiras?=)
Date: Wed, 16 May 2018 19:27:50 +0100
Subject: [R-sig-Geo] Raster extract by polygon generating NAs
Message-ID: <CAAbDveuiZJgU89O6jGLxF2qx3-1=1yjkrBj2NMpqbT3Or194eQ@mail.gmail.com>

Greetings!

I'm using the extract command (raster package) with a raster layer (x)
and a spatial polygons dataframe (y). I'm using it to extract the sum
of raster values by each spatial polygon. However, I'm getting NAs as
a result for some polygon IDs, which I know isn't true because that
doesn't happen in ArcGIS.

Does anyone experienced the same issue?

Thanks!
Joao


From btupper @ending from bigelow@org  Wed May 16 20:36:04 2018
From: btupper @ending from bigelow@org (Ben Tupper)
Date: Wed, 16 May 2018 14:36:04 -0400
Subject: [R-sig-Geo] Raster extract by polygon generating NAs
In-Reply-To: <CAAbDveuiZJgU89O6jGLxF2qx3-1=1yjkrBj2NMpqbT3Or194eQ@mail.gmail.com>
References: <CAAbDveuiZJgU89O6jGLxF2qx3-1=1yjkrBj2NMpqbT3Or194eQ@mail.gmail.com>
Message-ID: <C72CB971-6445-45BE-9D19-B691312A6111@bigelow.org>

Hi,

It's hard to know without any reproducible code, but you will want to pay close attention to the value of the na.rm argument to raster::extract(Raster,SpatialPolygons)  

See ?extract for all the details.

Cheers,
Ben

> On May 16, 2018, at 2:27 PM, Jo?o Carreiras <jmbcarreiras at gmail.com> wrote:
> 
> Greetings!
> 
> I'm using the extract command (raster package) with a raster layer (x)
> and a spatial polygons dataframe (y). I'm using it to extract the sum
> of raster values by each spatial polygon. However, I'm getting NAs as
> a result for some polygon IDs, which I know isn't true because that
> doesn't happen in ArcGIS.
> 
> Does anyone experienced the same issue?
> 
> Thanks!
> Joao
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Tick Forecasting: https://eco.bigelow.org/





	[[alternative HTML version deleted]]


From jmbc@rreir@@ @ending from gm@il@com  Thu May 17 11:45:53 2018
From: jmbc@rreir@@ @ending from gm@il@com (=?UTF-8?Q?Jo=C3=A3o_Carreiras?=)
Date: Thu, 17 May 2018 10:45:53 +0100
Subject: [R-sig-Geo] Raster extract by polygon generating NAs
In-Reply-To: <C72CB971-6445-45BE-9D19-B691312A6111@bigelow.org>
References: <CAAbDveuiZJgU89O6jGLxF2qx3-1=1yjkrBj2NMpqbT3Or194eQ@mail.gmail.com>
 <C72CB971-6445-45BE-9D19-B691312A6111@bigelow.org>
Message-ID: <CAAbDveuZw7jcEyfSMq2uc+iVqhUpgp6u6qdLK8MWeCW8-ovv_Q@mail.gmail.com>

Thank you Ben, setting na.rm = T did the job.

Best wishes
Joao

On 16 May 2018 at 19:36, Ben Tupper <btupper at bigelow.org> wrote:
> Hi,
>
> It's hard to know without any reproducible code, but you will want to pay
> close attention to the value of the na.rm argument to
> raster::extract(Raster,SpatialPolygons)
>
> See ?extract for all the details.
>
> Cheers,
> Ben
>
> On May 16, 2018, at 2:27 PM, Jo?o Carreiras <jmbcarreiras at gmail.com> wrote:
>
> Greetings!
>
> I'm using the extract command (raster package) with a raster layer (x)
> and a spatial polygons dataframe (y). I'm using it to extract the sum
> of raster values by each spatial polygon. However, I'm getting NAs as
> a result for some polygon IDs, which I know isn't true because that
> doesn't happen in ArcGIS.
>
> Does anyone experienced the same issue?
>
> Thanks!
> Joao
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> Tick Forecasting: https://eco.bigelow.org/
>
>
>
>


From kent3737 @ending from gm@il@com  Sat May 19 04:20:45 2018
From: kent3737 @ending from gm@il@com (Kent Johnson)
Date: Fri, 18 May 2018 22:20:45 -0400
Subject: [R-sig-Geo] Intersection of polygons with raster
Message-ID: <CAPP0wyhe2KkLUQ50cNn++uZ5neboX2BYzSi7gd=eLNph+vfF6Q@mail.gmail.com>

Hi,

I have a raster object `flood` containing projected flooding levels and a
simple features object `parcels` containing MULTIPOLYGONs representing
property parcels. I would like to find all the parcel polygons for which
there is any flood > 1 foot. What function(s) can do this? Something like
raster::intersect(parcels, flood >= 1)

I'll put together a reprex if that helps. Hoping someone can point me to
the right function to do this, I haven't found anything promising.

Thanks,
Kent

	[[alternative HTML version deleted]]


From md@umner @ending from gm@il@com  Sat May 19 05:41:30 2018
From: md@umner @ending from gm@il@com (Michael Sumner)
Date: Sat, 19 May 2018 13:41:30 +1000
Subject: [R-sig-Geo] Intersection of polygons with raster
In-Reply-To: <CAPP0wyhe2KkLUQ50cNn++uZ5neboX2BYzSi7gd=eLNph+vfF6Q@mail.gmail.com>
References: <CAPP0wyhe2KkLUQ50cNn++uZ5neboX2BYzSi7gd=eLNph+vfF6Q@mail.gmail.com>
Message-ID: <CAAcGz98hsU4ir2KWbErVGmb6370GAeK0k4g=25n3y65pgy=3PQ@mail.gmail.com>

Hi Kent, this is pretty straightforward with raster::extract. If speed is
an issue you can burn the polygon id into the grid and then group values by
that.

library(raster)
r <- raster(volcano)

## very simplistic polygon layer example
r2 <- raster(r)
res(r2) <- res(r2) * 20
p <- sf::st_as_sf(as(r2, "SpatialPolygonsDataFrame"))

## a dummy threshold value
onefoot <- 150
## grab the first column from extract (it gives multiple columns for
multi-layer rasters)
p$onefoot <- extract(r, p, fun = function(x, na.rm = TRUE) any(x >
onefoot))[,1]

plot(sf::st_geometry(p), col = p$onefoot + 1)
contour(r, levels = onefoot, col = "white", add = T)


## if speed is an issue, use fasterize for a more abstract workflow
library(fasterize)
p$rownum <- 1:nrow(p)
idgrid <- fasterize(p, r, field = "rownum")
p$onefoot <- tapply(values(r), values(idgrid), function(x, na.rm = TRUE)
any(x > onefoot))
plot(p)

FWIW it's always useful to provide a reprex, since that does take time and
might miss the mark for your situation. It's also trickier to provide two
objects that are relevant to each other, so any upfront work you can do in
an example helps the answerer.

HTH

On Sat, 19 May 2018 at 12:20 Kent Johnson <kent3737 at gmail.com> wrote:

> Hi,
>
> I have a raster object `flood` containing projected flooding levels and a
> simple features object `parcels` containing MULTIPOLYGONs representing
> property parcels. I would like to find all the parcel polygons for which
> there is any flood > 1 foot. What function(s) can do this? Something like
> raster::intersect(parcels, flood >= 1)
>
> I'll put together a reprex if that helps. Hoping someone can point me to
> the right function to do this, I haven't found anything promising.
>
> Thanks,
> Kent
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From kent3737 @ending from gm@il@com  Sat May 19 19:40:02 2018
From: kent3737 @ending from gm@il@com (Kent Johnson)
Date: Sat, 19 May 2018 13:40:02 -0400
Subject: [R-sig-Geo] Intersection of polygons with raster
In-Reply-To: <CAAcGz98hsU4ir2KWbErVGmb6370GAeK0k4g=25n3y65pgy=3PQ@mail.gmail.com>
References: <CAPP0wyhe2KkLUQ50cNn++uZ5neboX2BYzSi7gd=eLNph+vfF6Q@mail.gmail.com>
 <CAAcGz98hsU4ir2KWbErVGmb6370GAeK0k4g=25n3y65pgy=3PQ@mail.gmail.com>
Message-ID: <CAPP0wyhkwGm=q9S3bXf=MqjjkCfWrJ6=5qb3Y1H46SMO3BwfsQ@mail.gmail.com>

Thank you Michael, that is exactly what I needed. It is fairly slow for my
case but I only need to do it once :-)

And thank you for providing an example, I'm not too familiar with rasters
and would have had some trouble creating it.

Kent

On Fri, May 18, 2018 at 11:41 PM, Michael Sumner <mdsumner at gmail.com> wrote:

> Hi Kent, this is pretty straightforward with raster::extract. If speed is
> an issue you can burn the polygon id into the grid and then group values by
> that.
>
> library(raster)
> r <- raster(volcano)
>
> ## very simplistic polygon layer example
> r2 <- raster(r)
> res(r2) <- res(r2) * 20
> p <- sf::st_as_sf(as(r2, "SpatialPolygonsDataFrame"))
>
> ## a dummy threshold value
> onefoot <- 150
> ## grab the first column from extract (it gives multiple columns for
> multi-layer rasters)
> p$onefoot <- extract(r, p, fun = function(x, na.rm = TRUE) any(x >
> onefoot))[,1]
>
> plot(sf::st_geometry(p), col = p$onefoot + 1)
> contour(r, levels = onefoot, col = "white", add = T)
>
>
> ## if speed is an issue, use fasterize for a more abstract workflow
> library(fasterize)
> p$rownum <- 1:nrow(p)
> idgrid <- fasterize(p, r, field = "rownum")
> p$onefoot <- tapply(values(r), values(idgrid), function(x, na.rm = TRUE)
> any(x > onefoot))
> plot(p)
>
> FWIW it's always useful to provide a reprex, since that does take time and
> might miss the mark for your situation. It's also trickier to provide two
> objects that are relevant to each other, so any upfront work you can do in
> an example helps the answerer.
>
> HTH
>
> On Sat, 19 May 2018 at 12:20 Kent Johnson <kent3737 at gmail.com> wrote:
>
>> Hi,
>>
>> I have a raster object `flood` containing projected flooding levels and a
>> simple features object `parcels` containing MULTIPOLYGONs representing
>> property parcels. I would like to find all the parcel polygons for which
>> there is any flood > 1 foot. What function(s) can do this? Something like
>> raster::intersect(parcels, flood >= 1)
>>
>> I'll put together a reprex if that helps. Hoping someone can point me to
>> the right function to do this, I haven't found anything promising.
>>
>> Thanks,
>> Kent
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> <https://maps.google.com/?q=203+Channel+Highway+Kingston+Tasmania+7050+Australia&entry=gmail&source=g>
> Kingston Tasmania 7050 Australia
> <https://maps.google.com/?q=203+Channel+Highway+Kingston+Tasmania+7050+Australia&entry=gmail&source=g>
>
>

	[[alternative HTML version deleted]]


From brun@e@ti @ending from gm@il@com  Mon May 21 15:16:07 2018
From: brun@e@ti @ending from gm@il@com (Bruno Sesti)
Date: Mon, 21 May 2018 15:16:07 +0200
Subject: [R-sig-Geo] spatio temporal anisotropy: help with stAni argument
Message-ID: <CAFnjcD3feJL=mPvtwJSJw_e4ohQ2+zH5EcT9SfWHAoAsPvtP6A@mail.gmail.com>

Hi,
I have some problems in understanding the usage of argument 'stAni' of
vgmST and krigeST functions, for.the setting of spatio temporal anisotropy.
How have I to interpret this argument, that is the integer value that I saw
I have to assign to it, what does it means?
How can this argument influence the result of prediction?
Are units of spatial and temporal ranges and lags related to this argument?
How can I study the spatio temporal anisotropy of my data?
Kind regards.

	[[alternative HTML version deleted]]


From @hiv@_kh@n@l @ending from hotm@il@com  Tue May 22 01:55:11 2018
From: @hiv@_kh@n@l @ending from hotm@il@com (Shiva Khanal)
Date: Mon, 21 May 2018 23:55:11 +0000
Subject: [R-sig-Geo] Running spacetime eof on large raster stack
Message-ID: <DM5PR0401MB360597716168A2610002181FF4950@DM5PR0401MB3605.namprd04.prod.outlook.com>

Hi,

I am trying to run the spatial empirical orthogonal function on a raster stack using eof function in spacetime 1.2-1 package.

My raster stack is

> stk
class       : RasterStack
dimensions  : 2423, 2470, 5984810, 690  (nrow, ncol, ncell, nlayers)
resolution  : 499.9339, 499.9718  (x, y)
extent      : -85163.44, 1149673, 5656775, 6868207  (xmin, xmax, ymin, ymax)
coord. ref. : NA
names       : X2001.01.01, X2001.01.09, X2001.01.17, X2001.01.25, X2001.02.02, X2001.02.10, X2001.02.18, X2001.02.26, X2001.03.06, X2001.03.14, X2001.03.22, X2001.03.30, X2001.04.07, X2001.04.15, X2001.04.23, ...
min values  :           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0, ...
max values  :         100,         100,         100,         100,         100,         100,         100,         100,         100,         100,         100,         100,         100,         100,         100, ...

>object.size(stk)
8699416 bytes

The size of raster stack is ~8 mb but when I try to convert to STFDF it become several GBs until I receive error
about memory.

My system is
sysname        release        version        machine
"Windows"     ">= 8 x64"    "build 9200"      "x86-64"

>memory.limit()
[1] 32659

My R version is
"R version 3.5.0 (2018-04-23)"

I would appreciate any advise on possible solutions.

Thank you.

Shiva


	[[alternative HTML version deleted]]


From Scott@W@ichler @ending from pnnl@gov  Tue May 22 02:40:07 2018
From: Scott@W@ichler @ending from pnnl@gov (Waichler, Scott R)
Date: Tue, 22 May 2018 00:40:07 +0000
Subject: [R-sig-Geo] stConstruct with multiple SpatialPolygonsDataFrame
 objects
Message-ID: <074C83DAD4825242A20B2D83FDBCB8881BAEE3B2@EX10MBOX03.pnnl.gov>

Hi, Can anyone provide an example of using stConstruct() with multiple SpatialPolygonsDataFrame objects?  I have created the latter by reading in multiple shapefiles, one shapefile per year.  Each shapefile contains polygons at several levels of an attribute.  I want to plot these polygons for levels of say 1, 5, 10  using stplot, where the panels are years.  I am having trouble understanding how to do this type of task where the spatial coordinates vary across time.

Thank you,
Scott Waichler
Pacific Northwest National Laboratory
scott.waichler _at_ pnnl.gov


From b@gr@eler @ending from 52north@org  Tue May 22 09:39:52 2018
From: b@gr@eler @ending from 52north@org (=?UTF-8?Q?Dr._Benedikt_Gr=c3=a4ler?=)
Date: Tue, 22 May 2018 09:39:52 +0200
Subject: [R-sig-Geo] 
 spatio temporal anisotropy: help with stAni argument
In-Reply-To: <CAFnjcD3feJL=mPvtwJSJw_e4ohQ2+zH5EcT9SfWHAoAsPvtP6A@mail.gmail.com>
References: <CAFnjcD3feJL=mPvtwJSJw_e4ohQ2+zH5EcT9SfWHAoAsPvtP6A@mail.gmail.com>
Message-ID: <be4a408f-16f0-dd79-caf1-2b627aed6887@52north.org>

Dear Bruno,

stAni relates spatial and temporal distances to each other in the model 
for the data set under study. A value of 100 km/day reflects that two 
stations 100 km apart have about the same strength of dependence as the 
values one day apart at the same location (This is in general only true 
for at most one pair of spatial and temporal distances and a 'global' 
compromise is sought). The function gstat::estiStAni provides a few 
heuristics to estimate the spatio-temporal anisotropy.

When a spatio-temporal vgm including a metric component is fitted, the 
stAni parameter is optimized under the objective to find the theoretical 
vgm surface that best fits the empirical one.

In krigeST, an additional and approximate stAni parameter can be 
provided to ease the (pre-)selection of the most relevant observations 
in the space-time cube for the prediction when local kriging is carried 
out. Note that the most relevant (i.e. strongest correlated) 
observations need not to form a cube, but depend on the actual vgm-model 
in use (see also the vignette "Spatio-Temporal Interpolation using 
gstat" at [1]).

The unit of stAni depends on the spatial and temporal units of your data 
set. Check the units of the empirical variogram to find out which units 
R/gstat uses for your data set.

Miss-specifying the stAni parameter will put too large or too small 
weights on the observations with a temporal difference resulting in bad 
predictions (this also holds vise-versa for spatial distances).

HTH,

  Ben

[1] 
https://cran.r-project.org/web/packages/gstat/vignettes/spatio-temporal-kriging.pdf


On 21.05.2018 15:16, Bruno Sesti wrote:
> Hi,
> I have some problems in understanding the usage of argument 'stAni' of
> vgmST and krigeST functions, for.the setting of spatio temporal anisotropy.
> How have I to interpret this argument, that is the integer value that I saw
> I have to assign to it, what does it means?
> How can this argument influence the result of prediction?
> Are units of spatial and temporal ranges and lags related to this argument?
> How can I study the spatio temporal anisotropy of my data?
> Kind regards.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Dr. Benedikt Gr?ler
52?North Initiative for Geospatial Open Source Software GmbH
Martin-Luther-King-Weg 24
48155 Muenster, Germany

E-Mail: b.graeler at 52north.org
Fon: +49-(0)-251/396371-39
Fax: +49-(0)-251/396371-11

http://52north.org/
Twitter: @FiveTwoN

General Managers: Dr. Albert Remke, Dr. Andreas Wytzisk
Local Court Muenster HRB 10849


From b@rowling@on @ending from l@nc@@ter@@c@uk  Tue May 22 10:02:44 2018
From: b@rowling@on @ending from l@nc@@ter@@c@uk (Barry Rowlingson)
Date: Tue, 22 May 2018 09:02:44 +0100
Subject: [R-sig-Geo] 
 spatio temporal anisotropy: help with stAni argument
In-Reply-To: <be4a408f-16f0-dd79-caf1-2b627aed6887@52north.org>
References: <CAFnjcD3feJL=mPvtwJSJw_e4ohQ2+zH5EcT9SfWHAoAsPvtP6A@mail.gmail.com>
 <be4a408f-16f0-dd79-caf1-2b627aed6887@52north.org>
Message-ID: <CANVKczMOHO+Uy8dHyNXw2hZCbZrjFGnC+q2sK0BtWiUdxvDbsA@mail.gmail.com>

This question has also been posted to gis.stackexchange.com:

https://gis.stackexchange.com/questions/283607/spatio-temporal-anisotropy-in-r-stani-argument-in-vgmst-and-krigest/

and better answers than mine there are welcome...

Barry


On Tue, May 22, 2018 at 8:39 AM, Dr. Benedikt Gr?ler <b.graeler at 52north.org>
wrote:

> Dear Bruno,
>
> stAni relates spatial and temporal distances to each other in the model
> for the data set under study. A value of 100 km/day reflects that two
> stations 100 km apart have about the same strength of dependence as the
> values one day apart at the same location (This is in general only true for
> at most one pair of spatial and temporal distances and a 'global'
> compromise is sought). The function gstat::estiStAni provides a few
> heuristics to estimate the spatio-temporal anisotropy.
>
> When a spatio-temporal vgm including a metric component is fitted, the
> stAni parameter is optimized under the objective to find the theoretical
> vgm surface that best fits the empirical one.
>
> In krigeST, an additional and approximate stAni parameter can be provided
> to ease the (pre-)selection of the most relevant observations in the
> space-time cube for the prediction when local kriging is carried out. Note
> that the most relevant (i.e. strongest correlated) observations need not to
> form a cube, but depend on the actual vgm-model in use (see also the
> vignette "Spatio-Temporal Interpolation using gstat" at [1]).
>
> The unit of stAni depends on the spatial and temporal units of your data
> set. Check the units of the empirical variogram to find out which units
> R/gstat uses for your data set.
>
> Miss-specifying the stAni parameter will put too large or too small
> weights on the observations with a temporal difference resulting in bad
> predictions (this also holds vise-versa for spatial distances).
>
> HTH,
>
>  Ben
>
> [1] https://cran.r-project.org/web/packages/gstat/vignettes/spat
> io-temporal-kriging.pdf
>
>
> On 21.05.2018 15:16, Bruno Sesti wrote:
>
>> Hi,
>> I have some problems in understanding the usage of argument 'stAni' of
>> vgmST and krigeST functions, for.the setting of spatio temporal
>> anisotropy.
>> How have I to interpret this argument, that is the integer value that I
>> saw
>> I have to assign to it, what does it means?
>> How can this argument influence the result of prediction?
>> Are units of spatial and temporal ranges and lags related to this
>> argument?
>> How can I study the spatio temporal anisotropy of my data?
>> Kind regards.
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
> --
> Dr. Benedikt Gr?ler
> 52?North Initiative for Geospatial Open Source Software GmbH
> Martin-Luther-King-Weg 24
> 48155 Muenster, Germany
>
> E-Mail: b.graeler at 52north.org
> Fon: +49-(0)-251/396371-39
> Fax: +49-(0)-251/396371-11
>
> http://52north.org/
> Twitter: @FiveTwoN
>
> General Managers: Dr. Albert Remke, Dr. Andreas Wytzisk
> Local Court Muenster HRB 10849
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From Scott@W@ichler @ending from pnnl@gov  Wed May 23 20:39:07 2018
From: Scott@W@ichler @ending from pnnl@gov (Waichler, Scott R)
Date: Wed, 23 May 2018 18:39:07 +0000
Subject: [R-sig-Geo] how to plot different rows of a
 SpatialPolygonsDataFrame in trellis panels
Message-ID: <074C83DAD4825242A20B2D83FDBCB8881BAEE690@EX10MBOX03.pnnl.gov>

Hello,

I have a SpatialPolygonsDataFrame.  I would like to do a trellis plot on one of the attributes, so that in the panel for a given attribute value, only those polygons with that value are plotted.  So, each panel has different polygons plotted in it.  I can't figure out how to do this.  In the toy example below, I would like to create a trellis plot with one panel showing the polygons with id = 1, and another panel showing the polygons with id = 2.

My goal beyond this toy problem is to do the same thing with stplot, where panels correspond to times and each time has a different set of polygons plotted.  Will that be possible?  In all the examples I can find of using stplot for a space-time grid with the spatial objects being polygons, the polygons are the same across time.

# based on example in help("SpatialPolygonsDataFrame-class")
Sr1 = Polygon(cbind(c(2,4,4,1,2),c(2,3,5,4,2)))
Sr2 = Polygon(cbind(c(5,4,2,5),c(2,3,2,2)))
Sr3 = Polygon(cbind(c(4,4,5,10,4),c(5,3,2,5,5)))
Sr4 = Polygon(cbind(c(5,6,6,5,5),c(4,4,3,3,4)), hole = TRUE)
Srs1 = Polygons(list(Sr1), "s1")
Srs2 = Polygons(list(Sr2), "s2")
Srs3 = Polygons(list(Sr3, Sr4), "s3/4")
SpP = SpatialPolygons(list(Srs1,Srs2,Srs3), 1:3)
grd <- GridTopology(c(1,1), c(1,1), c(10,10))
polys <- as(grd, "SpatialPolygons")
centroids <- coordinates(polys)
x <- centroids[,1]
y <- centroids[,2]
z <- 1.4 + 0.1*x + 0.2*y + 0.002*x*x
id = factor(sample(c(1,2), size=length(polys), replace=T))
tmp <- SpatialPolygonsDataFrame(polys,
      data=data.frame(x=x, y=y, z=z, id=id, row.names=row.names(polys)))
plot(tmp)  # plots all the square polygons (n = 10*10)
spplot(tmp)  # plots values of x, y, z, id in separate panels, each with 100 polys
spplot(tmp, zcol=z)  # error message about duplication of factor level
spplot(tmp ~ id, zcol=z, data=tmp)  # won't take formula

Thank you,
ScottWaichler
Pacific Northwest National Laboratory
scott.waichler _at_ pnnl.gov


From Roger@Biv@nd @ending from nhh@no  Wed May 23 20:53:11 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Wed, 23 May 2018 20:53:11 +0200
Subject: [R-sig-Geo] how to plot different rows of a
 SpatialPolygonsDataFrame in trellis panels
In-Reply-To: <074C83DAD4825242A20B2D83FDBCB8881BAEE690@EX10MBOX03.pnnl.gov>
References: <074C83DAD4825242A20B2D83FDBCB8881BAEE690@EX10MBOX03.pnnl.gov>
Message-ID: <alpine.LFD.2.21.1805232049470.21566@reclus.nhh.no>

Scott,

Without having tried your code, how similar is this to these packages:

https://cran.r-project.org/package=micromap
https://cran.r-project.org/package=micromapST

and their JSS papers:

https://www.jstatsoft.org/index.php/jss/article/view/v063i02
https://www.jstatsoft.org/index.php/jss/article/view/v063i03

Roger

On Wed, 23 May 2018, Waichler, Scott R wrote:

> Hello,
>
> I have a SpatialPolygonsDataFrame.  I would like to do a trellis plot on one of the attributes, so that in the panel for a given attribute value, only those polygons with that value are plotted.  So, each panel has different polygons plotted in it.  I can't figure out how to do this.  In the toy example below, I would like to create a trellis plot with one panel showing the polygons with id = 1, and another panel showing the polygons with id = 2.
>
> My goal beyond this toy problem is to do the same thing with stplot, where panels correspond to times and each time has a different set of polygons plotted.  Will that be possible?  In all the examples I can find of using stplot for a space-time grid with the spatial objects being polygons, the polygons are the same across time.
>
> # based on example in help("SpatialPolygonsDataFrame-class")
> Sr1 = Polygon(cbind(c(2,4,4,1,2),c(2,3,5,4,2)))
> Sr2 = Polygon(cbind(c(5,4,2,5),c(2,3,2,2)))
> Sr3 = Polygon(cbind(c(4,4,5,10,4),c(5,3,2,5,5)))
> Sr4 = Polygon(cbind(c(5,6,6,5,5),c(4,4,3,3,4)), hole = TRUE)
> Srs1 = Polygons(list(Sr1), "s1")
> Srs2 = Polygons(list(Sr2), "s2")
> Srs3 = Polygons(list(Sr3, Sr4), "s3/4")
> SpP = SpatialPolygons(list(Srs1,Srs2,Srs3), 1:3)
> grd <- GridTopology(c(1,1), c(1,1), c(10,10))
> polys <- as(grd, "SpatialPolygons")
> centroids <- coordinates(polys)
> x <- centroids[,1]
> y <- centroids[,2]
> z <- 1.4 + 0.1*x + 0.2*y + 0.002*x*x
> id = factor(sample(c(1,2), size=length(polys), replace=T))
> tmp <- SpatialPolygonsDataFrame(polys,
>      data=data.frame(x=x, y=y, z=z, id=id, row.names=row.names(polys)))
> plot(tmp)  # plots all the square polygons (n = 10*10)
> spplot(tmp)  # plots values of x, y, z, id in separate panels, each with 100 polys
> spplot(tmp, zcol=z)  # error message about duplication of factor level
> spplot(tmp ~ id, zcol=z, data=tmp)  # won't take formula
>
> Thank you,
> ScottWaichler
> Pacific Northwest National Laboratory
> scott.waichler _at_ pnnl.gov
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From Scott@W@ichler @ending from pnnl@gov  Wed May 23 21:50:20 2018
From: Scott@W@ichler @ending from pnnl@gov (Waichler, Scott R)
Date: Wed, 23 May 2018 19:50:20 +0000
Subject: [R-sig-Geo] how to plot different rows of a
 SpatialPolygonsDataFrame in trellis panels
In-Reply-To: <alpine.LFD.2.21.1805232049470.21566@reclus.nhh.no>
References: <074C83DAD4825242A20B2D83FDBCB8881BAEE690@EX10MBOX03.pnnl.gov>
 <alpine.LFD.2.21.1805232049470.21566@reclus.nhh.no>
Message-ID: <074C83DAD4825242A20B2D83FDBCB8881BAEE6D3@EX10MBOX03.pnnl.gov>

Roger,

> Without having tried your code, how similar is this to these packages:
> 
> https://cran.r-project.org/package=micromap
> https://cran.r-project.org/package=micromapST

Thanks for responding.  I looked at the micromap vignettes but it seems their focus is being able to provide small maps in one column in figures where the main emphasis is on statistics presented in other columns.  In my problem, all I want to show are maps.  I haven't been able to do this with a higher-level function like spplot or stplot.  I can imagine doing it with a custom panel function, where lpolygons() is used with input that depends on the panel.  

In case it helps, I should clarify that the "different polygons" I referred to are polygons with different spatial coordinates; the attribute values are a small number of discrete values.  My polygons are representations of contaminant plumes in groundwater.  For each year, I have read in a shapefile containing polygons of the contaminant concentration at 2 to 4 levels.  I have combined all of these data into a SpatialPolygonsDataFrame, where each row represents a given year and concentration level, and contains one or more polygons.  The coordinates are different in each row, but years and concentration level are common across rows.  This seems to match the nature of a "long table" format in spacetime, but I haven't been able to work it out in that package, hence I'm stepping back and trying to get the basics working with spplot.

Thanks,
Scott

> > Hello,
> >
> > I have a SpatialPolygonsDataFrame.  I would like to do a trellis plot on one
> of the attributes, so that in the panel for a given attribute value, only those
> polygons with that value are plotted.  So, each panel has different polygons
> plotted in it.  I can't figure out how to do this.  In the toy example below, I
> would like to create a trellis plot with one panel showing the polygons with id
> = 1, and another panel showing the polygons with id = 2.
> >
> > My goal beyond this toy problem is to do the same thing with stplot, where
> panels correspond to times and each time has a different set of polygons
> plotted.  Will that be possible?  In all the examples I can find of using stplot
> for a space-time grid with the spatial objects being polygons, the polygons
> are the same across time.
> >
> > # based on example in help("SpatialPolygonsDataFrame-class")
> > Sr1 = Polygon(cbind(c(2,4,4,1,2),c(2,3,5,4,2)))
> > Sr2 = Polygon(cbind(c(5,4,2,5),c(2,3,2,2)))
> > Sr3 = Polygon(cbind(c(4,4,5,10,4),c(5,3,2,5,5)))
> > Sr4 = Polygon(cbind(c(5,6,6,5,5),c(4,4,3,3,4)), hole = TRUE)
> > Srs1 = Polygons(list(Sr1), "s1")
> > Srs2 = Polygons(list(Sr2), "s2")
> > Srs3 = Polygons(list(Sr3, Sr4), "s3/4") SpP =
> > SpatialPolygons(list(Srs1,Srs2,Srs3), 1:3) grd <- GridTopology(c(1,1),
> > c(1,1), c(10,10)) polys <- as(grd, "SpatialPolygons") centroids <-
> > coordinates(polys) x <- centroids[,1] y <- centroids[,2] z <- 1.4 +
> > 0.1*x + 0.2*y + 0.002*x*x id = factor(sample(c(1,2),
> > size=length(polys), replace=T)) tmp <- SpatialPolygonsDataFrame(polys,
> >      data=data.frame(x=x, y=y, z=z, id=id,
> > row.names=row.names(polys)))
> > plot(tmp)  # plots all the square polygons (n = 10*10)
> > spplot(tmp)  # plots values of x, y, z, id in separate panels, each
> > with 100 polys spplot(tmp, zcol=z)  # error message about duplication
> > of factor level spplot(tmp ~ id, zcol=z, data=tmp)  # won't take
> > formula
> >
> > Thank you,
> > ScottWaichler
> > Pacific Northwest National Laboratory
> > scott.waichler _at_ pnnl.gov
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> 
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics, Helleveien 30, N-
> 5045 Bergen, Norway.
> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From bf@levli@t @ending from gm@il@com  Thu May 24 06:28:23 2018
From: bf@levli@t @ending from gm@il@com (=?UTF-8?Q?Bede-Fazekas_=c3=81kos?=)
Date: Thu, 24 May 2018 06:28:23 +0200
Subject: [R-sig-Geo] how to plot different rows of a
 SpatialPolygonsDataFrame in trellis panels
In-Reply-To: <074C83DAD4825242A20B2D83FDBCB8881BAEE6D3@EX10MBOX03.pnnl.gov>
References: <074C83DAD4825242A20B2D83FDBCB8881BAEE690@EX10MBOX03.pnnl.gov>
 <alpine.LFD.2.21.1805232049470.21566@reclus.nhh.no>
 <074C83DAD4825242A20B2D83FDBCB8881BAEE6D3@EX10MBOX03.pnnl.gov>
Message-ID: <1be09898-0509-7058-cb37-bf9c1a0c4451@gmail.com>

Dear Scott,

use
spplot(tmp, zcol="z")
instead of
spplot(tmp, zcol=z)
to display the column "z".

Use
spplot(tmp[tmp$id == 1, ], zcol = "z")
to display only those grids that has id 1.

And to display two panels:
tmp$z1 <- tmp$z2 <- tmp$z
tmp$z1[tmp$id == 1] <-? NA
tmp$z2[tmp$id == 2] <-? NA
spplot(tmp, zcol=c("z1", "z2"))

HTH,
?kos Bede-Fazekas
Hungarian Academy of Sciences


2018.05.23. 21:50 keltez?ssel, Waichler, Scott R ?rta:
> Roger,
>
>> Without having tried your code, how similar is this to these packages:
>>
>> https://cran.r-project.org/package=micromap
>> https://cran.r-project.org/package=micromapST
> Thanks for responding.  I looked at the micromap vignettes but it seems their focus is being able to provide small maps in one column in figures where the main emphasis is on statistics presented in other columns.  In my problem, all I want to show are maps.  I haven't been able to do this with a higher-level function like spplot or stplot.  I can imagine doing it with a custom panel function, where lpolygons() is used with input that depends on the panel.
>
> In case it helps, I should clarify that the "different polygons" I referred to are polygons with different spatial coordinates; the attribute values are a small number of discrete values.  My polygons are representations of contaminant plumes in groundwater.  For each year, I have read in a shapefile containing polygons of the contaminant concentration at 2 to 4 levels.  I have combined all of these data into a SpatialPolygonsDataFrame, where each row represents a given year and concentration level, and contains one or more polygons.  The coordinates are different in each row, but years and concentration level are common across rows.  This seems to match the nature of a "long table" format in spacetime, but I haven't been able to work it out in that package, hence I'm stepping back and trying to get the basics working with spplot.
>
> Thanks,
> Scott
>
>>> Hello,
>>>
>>> I have a SpatialPolygonsDataFrame.  I would like to do a trellis plot on one
>> of the attributes, so that in the panel for a given attribute value, only those
>> polygons with that value are plotted.  So, each panel has different polygons
>> plotted in it.  I can't figure out how to do this.  In the toy example below, I
>> would like to create a trellis plot with one panel showing the polygons with id
>> = 1, and another panel showing the polygons with id = 2.
>>> My goal beyond this toy problem is to do the same thing with stplot, where
>> panels correspond to times and each time has a different set of polygons
>> plotted.  Will that be possible?  In all the examples I can find of using stplot
>> for a space-time grid with the spatial objects being polygons, the polygons
>> are the same across time.
>>> # based on example in help("SpatialPolygonsDataFrame-class")
>>> Sr1 = Polygon(cbind(c(2,4,4,1,2),c(2,3,5,4,2)))
>>> Sr2 = Polygon(cbind(c(5,4,2,5),c(2,3,2,2)))
>>> Sr3 = Polygon(cbind(c(4,4,5,10,4),c(5,3,2,5,5)))
>>> Sr4 = Polygon(cbind(c(5,6,6,5,5),c(4,4,3,3,4)), hole = TRUE)
>>> Srs1 = Polygons(list(Sr1), "s1")
>>> Srs2 = Polygons(list(Sr2), "s2")
>>> Srs3 = Polygons(list(Sr3, Sr4), "s3/4") SpP =
>>> SpatialPolygons(list(Srs1,Srs2,Srs3), 1:3) grd <- GridTopology(c(1,1),
>>> c(1,1), c(10,10)) polys <- as(grd, "SpatialPolygons") centroids <-
>>> coordinates(polys) x <- centroids[,1] y <- centroids[,2] z <- 1.4 +
>>> 0.1*x + 0.2*y + 0.002*x*x id = factor(sample(c(1,2),
>>> size=length(polys), replace=T)) tmp <- SpatialPolygonsDataFrame(polys,
>>>       data=data.frame(x=x, y=y, z=z, id=id,
>>> row.names=row.names(polys)))
>>> plot(tmp)  # plots all the square polygons (n = 10*10)
>>> spplot(tmp)  # plots values of x, y, z, id in separate panels, each
>>> with 100 polys spplot(tmp, zcol=z)  # error message about duplication
>>> of factor level spplot(tmp ~ id, zcol=z, data=tmp)  # won't take
>>> formula
>>>
>>> Thank you,
>>> ScottWaichler
>>> Pacific Northwest National Laboratory
>>> scott.waichler _at_ pnnl.gov
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics, Helleveien 30, N-
>> 5045 Bergen, Norway.
>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>> http://orcid.org/0000-0003-2392-6140
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From b@mb@zegue @ending from gm@il@com  Thu May 24 13:29:30 2018
From: b@mb@zegue @ending from gm@il@com (Yaya Bamba)
Date: Thu, 24 May 2018 11:29:30 +0000
Subject: [R-sig-Geo] BIG DATABASE
Message-ID: <CAH7XioweOCK32w2ESfKx1jX-LZu4MfGe6zbNC9cJz11M_sHhiQ@mail.gmail.com>

Hello,

Is it possible with R to work on a big database without loading it? If yes,
how can I do do it?

Thanks.

-- 
Yaya BAMBA

El?ve Ing?nieur Statisticien Economiste (ISE)

Ecole Nationale Sup?rieure de Statistique et d'Economie Appliqu?e (ENSEA),
Abidjan (C?te d'Ivoire)

T?l: +225 87 89 76 89

	[[alternative HTML version deleted]]


From m@di@zl @ending from gm@il@com  Thu May 24 13:33:37 2018
From: m@di@zl @ending from gm@il@com (Andres Diaz Loaiza)
Date: Thu, 24 May 2018 13:33:37 +0200
Subject: [R-sig-Geo] BIG DATABASE
In-Reply-To: <CAH7XioweOCK32w2ESfKx1jX-LZu4MfGe6zbNC9cJz11M_sHhiQ@mail.gmail.com>
References: <CAH7XioweOCK32w2ESfKx1jX-LZu4MfGe6zbNC9cJz11M_sHhiQ@mail.gmail.com>
Message-ID: <CAMXOh=1Q-4ws+LXxB08heWtrFyTn3YkW635ZSQ3OYb96EvjEXg@mail.gmail.com>

Hello Yaya,

Many years ago I work with a database in MySQL connected to R through the
package RMySQL?. The data was stored in the MySQL and I was connecting and
using the data from R

you should have a look in:

https://cran.r-project.org/web/packages/RMySQL/index.html

Cheers,

Andres

	[[alternative HTML version deleted]]


From b@mb@zegue @ending from gm@il@com  Thu May 24 13:45:50 2018
From: b@mb@zegue @ending from gm@il@com (Yaya Bamba)
Date: Thu, 24 May 2018 11:45:50 +0000
Subject: [R-sig-Geo] BIG DATABASE
In-Reply-To: <CAMXOh=1Q-4ws+LXxB08heWtrFyTn3YkW635ZSQ3OYb96EvjEXg@mail.gmail.com>
References: <CAH7XioweOCK32w2ESfKx1jX-LZu4MfGe6zbNC9cJz11M_sHhiQ@mail.gmail.com>
 <CAMXOh=1Q-4ws+LXxB08heWtrFyTn3YkW635ZSQ3OYb96EvjEXg@mail.gmail.com>
Message-ID: <CAH7Xiowyhmv9ZQinzZN0LLMwF9BXs2WDh33Ja+QaTcDUQ+4gaw@mail.gmail.com>

Thanks to all of you. I will try with the package  RMySQL and see.

2018-05-24 11:33 GMT+00:00 Andres Diaz Loaiza <madiazl at gmail.com>:

> Hello Yaya,
>
> Many years ago I work with a database in MySQL connected to R through the
> package RMySQL?. The data was stored in the MySQL and I was connecting and
> using the data from R
>
> you should have a look in:
>
> https://cran.r-project.org/web/packages/RMySQL/index.html
>
> Cheers,
>
> Andres
>



-- 
Yaya BAMBA

El?ve Ing?nieur Statisticien Economiste (ISE)

Ecole Nationale Sup?rieure de Statistique et d'Economie Appliqu?e (ENSEA),
Abidjan (C?te d'Ivoire)

T?l: +225 87 89 76 89

	[[alternative HTML version deleted]]


From b@mb@zegue @ending from gm@il@com  Thu May 24 13:56:52 2018
From: b@mb@zegue @ending from gm@il@com (Yaya Bamba)
Date: Thu, 24 May 2018 11:56:52 +0000
Subject: [R-sig-Geo] BIG DATABASE
In-Reply-To: <CAH7Xiowyhmv9ZQinzZN0LLMwF9BXs2WDh33Ja+QaTcDUQ+4gaw@mail.gmail.com>
References: <CAH7XioweOCK32w2ESfKx1jX-LZu4MfGe6zbNC9cJz11M_sHhiQ@mail.gmail.com>
 <CAMXOh=1Q-4ws+LXxB08heWtrFyTn3YkW635ZSQ3OYb96EvjEXg@mail.gmail.com>
 <CAH7Xiowyhmv9ZQinzZN0LLMwF9BXs2WDh33Ja+QaTcDUQ+4gaw@mail.gmail.com>
Message-ID: <CAH7XioyMNZ+Un_5vqFMNLPLGODNPbdW4wqb3U9zLiGPKc-RkCw@mail.gmail.com>

 Elisa Rose , I just wan to use some variables from a database that is
huge, without loading it, for my computer doesn't have much memory capacity.

2018-05-24 11:45 GMT+00:00 Yaya Bamba <bambazegue at gmail.com>:

> Thanks to all of you. I will try with the package  RMySQL and see.
>
> 2018-05-24 11:33 GMT+00:00 Andres Diaz Loaiza <madiazl at gmail.com>:
>
>> Hello Yaya,
>>
>> Many years ago I work with a database in MySQL connected to R through the
>> package RMySQL?. The data was stored in the MySQL and I was connecting and
>> using the data from R
>>
>> you should have a look in:
>>
>> https://cran.r-project.org/web/packages/RMySQL/index.html
>>
>> Cheers,
>>
>> Andres
>>
>
>
>
> --
> Yaya BAMBA
>
> El?ve Ing?nieur Statisticien Economiste (ISE)
>
> Ecole Nationale Sup?rieure de Statistique et d'Economie Appliqu?e (ENSEA),
> Abidjan (C?te d'Ivoire)
>
> T?l: +225 87 89 76 89
>



-- 
Yaya BAMBA

El?ve Ing?nieur Statisticien Economiste (ISE)

Ecole Nationale Sup?rieure de Statistique et d'Economie Appliqu?e (ENSEA),
Abidjan (C?te d'Ivoire)

T?l: +225 87 89 76 89

	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Thu May 24 14:04:31 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Thu, 24 May 2018 14:04:31 +0200
Subject: [R-sig-Geo] BIG DATABASE
In-Reply-To: <CAH7Xiowyhmv9ZQinzZN0LLMwF9BXs2WDh33Ja+QaTcDUQ+4gaw@mail.gmail.com>
References: <CAH7XioweOCK32w2ESfKx1jX-LZu4MfGe6zbNC9cJz11M_sHhiQ@mail.gmail.com>
 <CAMXOh=1Q-4ws+LXxB08heWtrFyTn3YkW635ZSQ3OYb96EvjEXg@mail.gmail.com>
 <CAH7Xiowyhmv9ZQinzZN0LLMwF9BXs2WDh33Ja+QaTcDUQ+4gaw@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.1805241355230.8104@reclus.nhh.no>

On Thu, 24 May 2018, Yaya Bamba wrote:

> Thanks to all of you. I will try with the package  RMySQL and see.

Maybe look more generally through the packages depending on and importing 
from DBI (https://cran.r-project.org/package=DBI) to see what is available 
- there are many more than RMySQL.

and use the Official Statistics and HPC Task Views:

https://cran.r-project.org/view=OfficialStatistics

https://cran.r-project.org/view=HighPerformanceComputing

to see how typical workflows (not necessarily DB-based) can be handled. 
The HPC TV has a section on large memory and out-of-memory approaches. If 
your data are spatial in raster format, the raster package provides some 
out-of-memory functionality. In sf, spatial vector data may be read from 
databases too.

Roger

>
> 2018-05-24 11:33 GMT+00:00 Andres Diaz Loaiza <madiazl at gmail.com>:
>
>> Hello Yaya,
>>
>> Many years ago I work with a database in MySQL connected to R through the
>> package RMySQL?. The data was stored in the MySQL and I was connecting and
>> using the data from R
>>
>> you should have a look in:
>>
>> https://cran.r-project.org/web/packages/RMySQL/index.html
>>
>> Cheers,
>>
>> Andres
>>
>
>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From kent3737 @ending from gm@il@com  Thu May 24 15:04:55 2018
From: kent3737 @ending from gm@il@com (Kent Johnson)
Date: Thu, 24 May 2018 09:04:55 -0400
Subject: [R-sig-Geo] how to plot different rows of a
 SpatialPolygonsDataFrame in trellis panels
Message-ID: <CAPP0wyiec7HFNPDP1fyNqGwDv4t8jQ0wU4GXO4=SC5z_qN2FcQ@mail.gmail.com>

On Thu, May 24, 2018 at 6:00 AM, <r-sig-geo-request at r-project.org> wrote:

>
> Message: 1
> Date: Wed, 23 May 2018 18:39:07 +0000
> From: "Waichler, Scott R" <Scott.Waichler at pnnl.gov>
> To: "r-sig-geo at r-project.org" <r-sig-geo at r-project.org>
> Subject: [R-sig-Geo] how to plot different rows of a
>         SpatialPolygonsDataFrame in trellis panels
>
> Hello,
>
> I have a SpatialPolygonsDataFrame.  I would like to do a trellis plot on
> one of the attributes, so that in the panel for a given attribute value,
> only those polygons with that value are plotted.  So, each panel has
> different polygons plotted in it.  I can't figure out how to do this.  In
> the toy example below, I would like to create a trellis plot with one panel
> showing the polygons with id = 1, and another panel showing the polygons
> with id = 2.
>
> My goal beyond this toy problem is to do the same thing with stplot, where
> panels correspond to times and each time has a different set of polygons
> plotted.  Will that be possible?  In all the examples I can find of using
> stplot for a space-time grid with the spatial objects being polygons, the
> polygons are the same across time.
>
> # based on example in help("SpatialPolygonsDataFrame-class")
> Sr1 = Polygon(cbind(c(2,4,4,1,2),c(2,3,5,4,2)))
> Sr2 = Polygon(cbind(c(5,4,2,5),c(2,3,2,2)))
> Sr3 = Polygon(cbind(c(4,4,5,10,4),c(5,3,2,5,5)))
> Sr4 = Polygon(cbind(c(5,6,6,5,5),c(4,4,3,3,4)), hole = TRUE)
> Srs1 = Polygons(list(Sr1), "s1")
> Srs2 = Polygons(list(Sr2), "s2")
> Srs3 = Polygons(list(Sr3, Sr4), "s3/4")
> SpP = SpatialPolygons(list(Srs1,Srs2,Srs3), 1:3)
> grd <- GridTopology(c(1,1), c(1,1), c(10,10))
> polys <- as(grd, "SpatialPolygons")
> centroids <- coordinates(polys)
> x <- centroids[,1]
> y <- centroids[,2]
> z <- 1.4 + 0.1*x + 0.2*y + 0.002*x*x
> id = factor(sample(c(1,2), size=length(polys), replace=T))
> tmp <- SpatialPolygonsDataFrame(polys,
>       data=data.frame(x=x, y=y, z=z, id=id, row.names=row.names(polys)))
> plot(tmp)  # plots all the square polygons (n = 10*10)
> spplot(tmp)  # plots values of x, y, z, id in separate panels, each with
> 100 polys
> spplot(tmp, zcol=z)  # error message about duplication of factor level
> spplot(tmp ~ id, zcol=z, data=tmp)  # won't take formula
>

You can do the facetting with ggplot2::geom_sf (in the dev version of
ggplot2) though I don't think it will use different coordinate ranges for
different facets:

devtools::install_github('tidyverse/ggplot2')
library(sf)
library(ggplot2)
tmp2 = st_as_sf(tmp)

ggplot(tmp2) + geom_sf(aes(fill=z)) + facet_wrap(~id)

A couple of suggestions here, using tmap or ggspatial, that look promising:
https://stackoverflow.com/questions/47678480/mapping-different-states-with-geom-sf-using-facet-wrap-and-scales-free

Kent Johnson


> Thank you,
> ScottWaichler
> Pacific Northwest National Laboratory
> scott.waichler _at_ pnnl.gov
>

	[[alternative HTML version deleted]]


From jwi@m002 @ending from odu@edu  Thu May 24 15:12:47 2018
From: jwi@m002 @ending from odu@edu (Jeri Wisman)
Date: Thu, 24 May 2018 08:12:47 -0500
Subject: [R-sig-Geo] Measuring length of trajectories
Message-ID: <CACPuJ4k_rR9CZiOjOD2pG-J8k9Ri8UJdWffyHEdTWrAcPR_4Sg@mail.gmail.com>

Hi all -

I am trying to measure the length of time of trajectories taken of seabird
movements to be able to relate time of flight to distance of flight. Any
suggestions of a function or package on how to measure the time? Thanks,

*Jeri Wisman* | Masters Candidate
Old Dominion University
Department of Biological Sciences
Mills Godwin Building, Room 312
Norfolk VA 23529 USA

	[[alternative HTML version deleted]]


From engli@hchri@topher@ @ending from gm@il@com  Thu May 24 15:39:17 2018
From: engli@hchri@topher@ @ending from gm@il@com (chris english)
Date: Thu, 24 May 2018 09:39:17 -0400
Subject: [R-sig-Geo] Measuring length of trajectories
In-Reply-To: <CACPuJ4k_rR9CZiOjOD2pG-J8k9Ri8UJdWffyHEdTWrAcPR_4Sg@mail.gmail.com>
References: <CACPuJ4k_rR9CZiOjOD2pG-J8k9Ri8UJdWffyHEdTWrAcPR_4Sg@mail.gmail.com>
Message-ID: <CAASFQpQKp8dR=FUtzgraunK=3zydv0cmm8VARuc1rO2qGQHFoQ@mail.gmail.com>

Jeri,

Is your data some kind of attached to bird(s) gps data?

Chris

On Thu, May 24, 2018 at 9:12 AM, Jeri Wisman <jwism002 at odu.edu> wrote:

> Hi all -
>
> I am trying to measure the length of time of trajectories taken of seabird
> movements to be able to relate time of flight to distance of flight. Any
> suggestions of a function or package on how to measure the time? Thanks,
>
> *Jeri Wisman* | Masters Candidate
> Old Dominion University
> Department of Biological Sciences
> Mills Godwin Building, Room 312
> Norfolk VA 23529 USA
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From m@rt@zore@ @ending from gm@il@com  Thu May 24 15:40:05 2018
From: m@rt@zore@ @ending from gm@il@com (marta azores)
Date: Thu, 24 May 2018 13:40:05 +0000
Subject: [R-sig-Geo] Measuring length of trajectories
In-Reply-To: <CACPuJ4k_rR9CZiOjOD2pG-J8k9Ri8UJdWffyHEdTWrAcPR_4Sg@mail.gmail.com>
References: <CACPuJ4k_rR9CZiOjOD2pG-J8k9Ri8UJdWffyHEdTWrAcPR_4Sg@mail.gmail.com>
Message-ID: <CAE3WKgSubgOvX-V1_nBnkfitZ0EfxBKxGbQvyGn_k+JUJQC6Dg@mail.gmail.com>

Hi Jeri,

there are a lot of packages to measure the tag trajectories length. You can
start reading about library(move) and library(gdistance)


2018-05-24 13:12 GMT+00:00 Jeri Wisman <jwism002 at odu.edu>:

> Hi all -
>
> I am trying to measure the length of time of trajectories taken of seabird
> movements to be able to relate time of flight to distance of flight. Any
> suggestions of a function or package on how to measure the time? Thanks,
>
> *Jeri Wisman* | Masters Candidate
> Old Dominion University
> Department of Biological Sciences
> Mills Godwin Building, Room 312
> Norfolk VA 23529 USA
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From md@umner @ending from gm@il@com  Thu May 24 15:42:55 2018
From: md@umner @ending from gm@il@com (Michael Sumner)
Date: Thu, 24 May 2018 23:42:55 +1000
Subject: [R-sig-Geo] Measuring length of trajectories
In-Reply-To: <CACPuJ4k_rR9CZiOjOD2pG-J8k9Ri8UJdWffyHEdTWrAcPR_4Sg@mail.gmail.com>
References: <CACPuJ4k_rR9CZiOjOD2pG-J8k9Ri8UJdWffyHEdTWrAcPR_4Sg@mail.gmail.com>
Message-ID: <CAAcGz98a9G0tsQFUpToMvz40bxMnrWqPQ0H9eHZerOOOQo3rLA@mail.gmail.com>

On Thu, 24 May 2018 at 23:32 Jeri Wisman <jwism002 at odu.edu> wrote:

> Hi all -
>
> I am trying to measure the length of time of trajectories taken of seabird
> movements to be able to relate time of flight to distance of flight. Any
> suggestions of a function or package on how to measure the time? Thanks,
>

There are very many, including adehabitatLT package and the trackDistance
function in the trip package (I know how that one works so it's easy for me
to help with, but it's not as sophisticated as adehabitat family so
pros/cons).

Both packages requires you to get your data into the right format. There's
more general capability in sp::spDists which has arguments longlat (set to
TRUE for great circle distances from longlat) and segments, which gives
sequential paired distances. Both adehabitatLT and trip will handle the
grouping of locations into separate paths (ordered by time).

I'd say it's worth trying some of the purpose-built packages, because then
some of the metrics can be extracted very easily (once you know your way
around). Explore the "Moving objects, trajectories" section of this Task
View

https://gist.github.com/mdsumner/0a3cb0e58bf9d37b782943ac269e1eff

and this list of recentish additions, pending update to the Task View,
which gives a taste of how much activity there is in this space(!).

https://gist.github.com/mdsumner/0a3cb0e58bf9d37b782943ac269e1eff

Cheers, Mike.

>
> *Jeri Wisman* | Masters Candidate
> Old Dominion University
> Department of Biological Sciences
> Mills Godwin Building, Room 312
> Norfolk VA 23529 USA
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From tephilippi @ending from gm@il@com  Fri May 25 06:35:39 2018
From: tephilippi @ending from gm@il@com (Tom Philippi)
Date: Thu, 24 May 2018 21:35:39 -0700
Subject: [R-sig-Geo] BIG DATABASE
In-Reply-To: <alpine.LFD.2.21.1805241355230.8104@reclus.nhh.no>
References: <CAH7XioweOCK32w2ESfKx1jX-LZu4MfGe6zbNC9cJz11M_sHhiQ@mail.gmail.com>
 <CAMXOh=1Q-4ws+LXxB08heWtrFyTn3YkW635ZSQ3OYb96EvjEXg@mail.gmail.com>
 <CAH7Xiowyhmv9ZQinzZN0LLMwF9BXs2WDh33Ja+QaTcDUQ+4gaw@mail.gmail.com>
 <alpine.LFD.2.21.1805241355230.8104@reclus.nhh.no>
Message-ID: <CALyPt8ze_8ZPrRHmWLWm5KzAksevthHSVvt0irqkkRvQXLPp6A@mail.gmail.com>

What Roger said (as always).

Note that if you use tidyverse and magrittr, dplyr and tidyverse tools work
well with databases via DBI.  sqldf also works with multiple SQL database
backends if you're an ol dog like me and don't use tidyverse much.

Also, since this is r-sig-*GEO*, note that postgreSQL has postGIS for
spatial data, which does far more than the automatic tiling of large
rasters in package raster.  I'm seeing wonderful performance working with a
340M observation >100GB dataset of bird observation data in R via postGIS,
even with "only" 32GB RAM and constrained to running win7, not linux/unix.

One alternative is that if your database is running on massive hardware
(tons of memory, many cores, etc.), it is possible to run R within both
postgreSQL and now MS SQL Server, the first free, the second an additional
cost add-on, and both usually at the cost of painful negotiations with DA
administrators for permissions to run your ad hoc R code on their SQL
server.  If you have the hardware, you can even run R with hadoop, although
I've never done that with spatial data.

Tom 0


On Thu, May 24, 2018 at 5:04 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Thu, 24 May 2018, Yaya Bamba wrote:
>
> Thanks to all of you. I will try with the package  RMySQL and see.
>>
>
> Maybe look more generally through the packages depending on and importing
> from DBI (https://cran.r-project.org/package=DBI) to see what is
> available - there are many more than RMySQL.
>
> and use the Official Statistics and HPC Task Views:
>
> https://cran.r-project.org/view=OfficialStatistics
>
> https://cran.r-project.org/view=HighPerformanceComputing
>
> to see how typical workflows (not necessarily DB-based) can be handled.
> The HPC TV has a section on large memory and out-of-memory approaches. If
> your data are spatial in raster format, the raster package provides some
> out-of-memory functionality. In sf, spatial vector data may be read from
> databases too.
>
> Roger
>
>
>
>> 2018-05-24 11:33 GMT+00:00 Andres Diaz Loaiza <madiazl at gmail.com>:
>>
>> Hello Yaya,
>>>
>>> Many years ago I work with a database in MySQL connected to R through the
>>> package RMySQL?. The data was stored in the MySQL and I was connecting
>>> and
>>> using the data from R
>>>
>>> you should have a look in:
>>>
>>> https://cran.r-project.org/web/packages/RMySQL/index.html
>>>
>>> Cheers,
>>>
>>> Andres
>>>
>>>
>>
>>
>>
>>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

	[[alternative HTML version deleted]]


From jmbc@rreir@@ @ending from gm@il@com  Fri May 25 12:00:41 2018
From: jmbc@rreir@@ @ending from gm@il@com (=?UTF-8?Q?Jo=C3=A3o_Carreiras?=)
Date: Fri, 25 May 2018 11:00:41 +0100
Subject: [R-sig-Geo] raster::clump not working?
Message-ID: <CAAbDvev+=sx1AOfbERjwHosQHOfRYQKp148xhqsrzx7QTmXDWg@mail.gmail.com>

Hi!

I've been trying to run the clump command but the output is consistently a
raster with values == 1. Please find below an example.

I'm sure I'm doing something stupid. However, the command is really
straightforward and I can't seem to identify what the problem might be.

Any help really appreciated.
Thanks
Joao

r <- raster(ncols=36, nrows=18)
x <- init(r, fun='cell')
x
class       : RasterLayer
dimensions  : 18, 36, 648  (nrow, ncol, ncell)
resolution  : 10, 10  (x, y)
extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
data source : in memory
names       : layer
values      : 1, 648  (min, max)
a <- clump(x)
a
class       : RasterLayer
dimensions  : 18, 36, 648  (nrow, ncol, ncell)
resolution  : 10, 10  (x, y)
extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
data source : in memory
names       : clumps
values      : 1, 1  (min, max)


From btupper @ending from bigelow@org  Fri May 25 12:35:44 2018
From: btupper @ending from bigelow@org (Ben Tupper)
Date: Fri, 25 May 2018 06:35:44 -0400
Subject: [R-sig-Geo] raster::clump not working?
In-Reply-To: <CAAbDvev+=sx1AOfbERjwHosQHOfRYQKp148xhqsrzx7QTmXDWg@mail.gmail.com>
References: <CAAbDvev+=sx1AOfbERjwHosQHOfRYQKp148xhqsrzx7QTmXDWg@mail.gmail.com>
Message-ID: <828691EB-B6F7-41BC-80C0-1654C2BAC84B@bigelow.org>

Hi,

I think it is actually correct - there is only one 'clump' of connected cells.  In raster clumps are separated from other clumps by backgound (0 or NA).  In your example there is no background anywhere so there is just one clump. 

You can see the difference if you divide x in to halves with a row of NAs.  Note that limited spatial extent so the clumping doesn't wrap around the globe which it will for [-180, 180].

r <- raster(ncols=36, nrows=18, xmn = 0, xmx = 36, ymn = 0, ymx = 18)
x <- init(r, fun='cell')
 
x[9,1:36] <- NA
y <- clump(x)
y
# class       : RasterLayer 
# dimensions  : 18, 36, 648  (nrow, ncol, ncell)
# resolution  : 1, 1  (x, y)
# extent      : 0, 36, 0, 18  (xmin, xmax, ymin, ymax)
# coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0 
# data source : in memory
# names       : clumps 
# values      : 1, 2  (min, max)

x[1:18, 18] <- NA
y
# class       : RasterLayer 
# dimensions  : 18, 36, 648  (nrow, ncol, ncell)
# resolution  : 1, 1  (x, y)
# extent      : 0, 36, 0, 18  (xmin, xmax, ymin, ymax)
# coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0 
# data source : in memory
# names       : clumps 
# values      : 1, 4  (min, max)


Cheers,
Ben


> On May 25, 2018, at 6:00 AM, Jo?o Carreiras <jmbcarreiras at gmail.com> wrote:
> 
> Hi!
> 
> I've been trying to run the clump command but the output is consistently a
> raster with values == 1. Please find below an example.
> 
> I'm sure I'm doing something stupid. However, the command is really
> straightforward and I can't seem to identify what the problem might be.
> 
> Any help really appreciated.
> Thanks
> Joao
> 
> r <- raster(ncols=36, nrows=18)
> x <- init(r, fun='cell')
> x
> class       : RasterLayer
> dimensions  : 18, 36, 648  (nrow, ncol, ncell)
> resolution  : 10, 10  (x, y)
> extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> data source : in memory
> names       : layer
> values      : 1, 648  (min, max)
> a <- clump(x)
> a
> class       : RasterLayer
> dimensions  : 18, 36, 648  (nrow, ncol, ncell)
> resolution  : 10, 10  (x, y)
> extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> data source : in memory
> names       : clumps
> values      : 1, 1  (min, max)
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]


From bf@levli@t @ending from gm@il@com  Fri May 25 13:00:02 2018
From: bf@levli@t @ending from gm@il@com (=?UTF-8?Q?Bede-Fazekas_=c3=81kos?=)
Date: Fri, 25 May 2018 13:00:02 +0200
Subject: [R-sig-Geo] raster::clump not working?
In-Reply-To: <CAAbDvev+=sx1AOfbERjwHosQHOfRYQKp148xhqsrzx7QTmXDWg@mail.gmail.com>
References: <CAAbDvev+=sx1AOfbERjwHosQHOfRYQKp148xhqsrzx7QTmXDWg@mail.gmail.com>
Message-ID: <ef8b1a24-edd1-046a-540a-5f544555be6c@gmail.com>

Dear Joao,
I think function clump() works as it should be. A toy example:
x <- raster(matrix(sample(x = c(NA, NA, NA, 1), size = 36*18, replace = 
TRUE), ncol=36, nrow=18))
plot(x)
plot(clump(x))

Maybe you are searching for a function that aggregate those cells that 
have the same value?
In this case it would do what you want (I'm sure there is a more 
straightforward way...):
r <- raster(ncols=36, nrows=18)
x <- init(r, fun='cell')
y <- layerize(x)
ids <- calc(x = y, fun = function(layers) 
{return(which(as.logical(layers))[1])})
plot(ids)

HTH,
?kos Bede-Fazekas
Hungarian Academy of Sciences


2018.05.25. 12:00 keltez?ssel, Jo?o Carreiras ?rta:
> Hi!
>
> I've been trying to run the clump command but the output is consistently a
> raster with values == 1. Please find below an example.
>
> I'm sure I'm doing something stupid. However, the command is really
> straightforward and I can't seem to identify what the problem might be.
>
> Any help really appreciated.
> Thanks
> Joao
>
> r <- raster(ncols=36, nrows=18)
> x <- init(r, fun='cell')
> x
> class       : RasterLayer
> dimensions  : 18, 36, 648  (nrow, ncol, ncell)
> resolution  : 10, 10  (x, y)
> extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> data source : in memory
> names       : layer
> values      : 1, 648  (min, max)
> a <- clump(x)
> a
> class       : RasterLayer
> dimensions  : 18, 36, 648  (nrow, ncol, ncell)
> resolution  : 10, 10  (x, y)
> extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> data source : in memory
> names       : clumps
> values      : 1, 1  (min, max)
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From jmbc@rreir@@ @ending from gm@il@com  Fri May 25 13:14:53 2018
From: jmbc@rreir@@ @ending from gm@il@com (=?UTF-8?Q?Jo=C3=A3o_Carreiras?=)
Date: Fri, 25 May 2018 12:14:53 +0100
Subject: [R-sig-Geo] raster::clump not working?
In-Reply-To: <828691EB-B6F7-41BC-80C0-1654C2BAC84B@bigelow.org>
References: <CAAbDvev+=sx1AOfbERjwHosQHOfRYQKp148xhqsrzx7QTmXDWg@mail.gmail.com>
 <828691EB-B6F7-41BC-80C0-1654C2BAC84B@bigelow.org>
Message-ID: <CAAbDveuQfRVa9cXa6CA-UiYGJcVNymNTeiBzuthaHZKgy=yGpA@mail.gmail.com>

Dear Ben,

Thank you for your prompt reply.

Now I see what clump does. I just thought clump would give the same
result as ArcGIS "Region Group". I need some command to assign a
different value to each patch. And by patch I mean contiguous pixels
having the same value, so that in this (absurd) example I would get
648 patches.

Take care
Joao

On 25 May 2018 at 11:35, Ben Tupper <btupper at bigelow.org> wrote:
> Hi,
>
> I think it is actually correct - there is only one 'clump' of connected
> cells.  In raster clumps are separated from other clumps by backgound (0 or
> NA).  In your example there is no background anywhere so there is just one
> clump.
>
> You can see the difference if you divide x in to halves with a row of NAs.
> Note that limited spatial extent so the clumping doesn't wrap around the
> globe which it will for [-180, 180].
>
> r <- raster(ncols=36, nrows=18, xmn = 0, xmx = 36, ymn = 0, ymx = 18)
> x <- init(r, fun='cell')
>
> x[9,1:36] <- NA
> y <- clump(x)
> y
> # class       : RasterLayer
> # dimensions  : 18, 36, 648  (nrow, ncol, ncell)
> # resolution  : 1, 1  (x, y)
> # extent      : 0, 36, 0, 18  (xmin, xmax, ymin, ymax)
> # coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> # data source : in memory
> # names       : clumps
> # values      : 1, 2  (min, max)
>
> x[1:18, 18] <- NA
> y
> # class       : RasterLayer
> # dimensions  : 18, 36, 648  (nrow, ncol, ncell)
> # resolution  : 1, 1  (x, y)
> # extent      : 0, 36, 0, 18  (xmin, xmax, ymin, ymax)
> # coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> # data source : in memory
> # names       : clumps
> # values      : 1, 4  (min, max)
>
>
> Cheers,
> Ben
>
>
> On May 25, 2018, at 6:00 AM, Jo?o Carreiras <jmbcarreiras at gmail.com> wrote:
>
> Hi!
>
> I've been trying to run the clump command but the output is consistently a
> raster with values == 1. Please find below an example.
>
> I'm sure I'm doing something stupid. However, the command is really
> straightforward and I can't seem to identify what the problem might be.
>
> Any help really appreciated.
> Thanks
> Joao
>
> r <- raster(ncols=36, nrows=18)
> x <- init(r, fun='cell')
> x
> class       : RasterLayer
> dimensions  : 18, 36, 648  (nrow, ncol, ncell)
> resolution  : 10, 10  (x, y)
> extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> data source : in memory
> names       : layer
> values      : 1, 648  (min, max)
> a <- clump(x)
> a
> class       : RasterLayer
> dimensions  : 18, 36, 648  (nrow, ncol, ncell)
> resolution  : 10, 10  (x, y)
> extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> data source : in memory
> names       : clumps
> values      : 1, 1  (min, max)
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> Ecological Forecasting: https://eco.bigelow.org/
>
>
>
>
>


From md@umner @ending from gm@il@com  Fri May 25 13:58:05 2018
From: md@umner @ending from gm@il@com (Michael Sumner)
Date: Fri, 25 May 2018 21:58:05 +1000
Subject: [R-sig-Geo] raster::clump not working?
In-Reply-To: <CAAbDveuQfRVa9cXa6CA-UiYGJcVNymNTeiBzuthaHZKgy=yGpA@mail.gmail.com>
References: <CAAbDvev+=sx1AOfbERjwHosQHOfRYQKp148xhqsrzx7QTmXDWg@mail.gmail.com>
 <828691EB-B6F7-41BC-80C0-1654C2BAC84B@bigelow.org>
 <CAAbDveuQfRVa9cXa6CA-UiYGJcVNymNTeiBzuthaHZKgy=yGpA@mail.gmail.com>
Message-ID: <CAAcGz98qjuEuubBQ_+f9Z89osEnRtPyO729bY8aWnQSaGiY6kQ@mail.gmail.com>

Joao, this is what you are after I think.  It's important to use
sf/fasterize otherwise any holes filled by other patches won't be
identified (and it's faster). It won't scale well given rasterToPolygons,
but there might be other options using sf related tricks.

library(raster)
r <- raster(volcano) %/% 20
## p has six distinct values (multipolygons)
p <- rasterToPolygons(r, dissolve = TRUE)
## pp has ten distinct patches
pp <- disaggregate(p)
pp$patch <- seq_len(nrow(pp))

## back to raster
#rr <- rasterize(pp, r, field = pp$patch)
# or faster with sf/fasterize (also this gets the holes filled correctly)
rr <- fasterize::fasterize(sf::st_as_sf(pp), r, field = "patch")
unique(values(rr))

Cheers, Mike.


On Fri, 25 May 2018 at 21:15 Jo?o Carreiras <jmbcarreiras at gmail.com> wrote:

> Dear Ben,
>
> Thank you for your prompt reply.
>
> Now I see what clump does. I just thought clump would give the same
> result as ArcGIS "Region Group". I need some command to assign a
> different value to each patch. And by patch I mean contiguous pixels
> having the same value, so that in this (absurd) example I would get
> 648 patches.
>
> Take care
> Joao
>
> On 25 May 2018 at 11:35, Ben Tupper <btupper at bigelow.org> wrote:
> > Hi,
> >
> > I think it is actually correct - there is only one 'clump' of connected
> > cells.  In raster clumps are separated from other clumps by backgound (0
> or
> > NA).  In your example there is no background anywhere so there is just
> one
> > clump.
> >
> > You can see the difference if you divide x in to halves with a row of
> NAs.
> > Note that limited spatial extent so the clumping doesn't wrap around the
> > globe which it will for [-180, 180].
> >
> > r <- raster(ncols=36, nrows=18, xmn = 0, xmx = 36, ymn = 0, ymx = 18)
> > x <- init(r, fun='cell')
> >
> > x[9,1:36] <- NA
> > y <- clump(x)
> > y
> > # class       : RasterLayer
> > # dimensions  : 18, 36, 648  (nrow, ncol, ncell)
> > # resolution  : 1, 1  (x, y)
> > # extent      : 0, 36, 0, 18  (xmin, xmax, ymin, ymax)
> > # coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> > # data source : in memory
> > # names       : clumps
> > # values      : 1, 2  (min, max)
> >
> > x[1:18, 18] <- NA
> > y
> > # class       : RasterLayer
> > # dimensions  : 18, 36, 648  (nrow, ncol, ncell)
> > # resolution  : 1, 1  (x, y)
> > # extent      : 0, 36, 0, 18  (xmin, xmax, ymin, ymax)
> > # coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> > # data source : in memory
> > # names       : clumps
> > # values      : 1, 4  (min, max)
> >
> >
> > Cheers,
> > Ben
> >
> >
> > On May 25, 2018, at 6:00 AM, Jo?o Carreiras <jmbcarreiras at gmail.com>
> wrote:
> >
> > Hi!
> >
> > I've been trying to run the clump command but the output is consistently
> a
> > raster with values == 1. Please find below an example.
> >
> > I'm sure I'm doing something stupid. However, the command is really
> > straightforward and I can't seem to identify what the problem might be.
> >
> > Any help really appreciated.
> > Thanks
> > Joao
> >
> > r <- raster(ncols=36, nrows=18)
> > x <- init(r, fun='cell')
> > x
> > class       : RasterLayer
> > dimensions  : 18, 36, 648  (nrow, ncol, ncell)
> > resolution  : 10, 10  (x, y)
> > extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
> > coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> > data source : in memory
> > names       : layer
> > values      : 1, 648  (min, max)
> > a <- clump(x)
> > a
> > class       : RasterLayer
> > dimensions  : 18, 36, 648  (nrow, ncol, ncell)
> > resolution  : 10, 10  (x, y)
> > extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
> > coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> > data source : in memory
> > names       : clumps
> > values      : 1, 1  (min, max)
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> >
> > Ben Tupper
> > Bigelow Laboratory for Ocean Sciences
> > 60 Bigelow Drive, P.O. Box 380
> > East Boothbay, Maine 04544
> > http://www.bigelow.org
> >
> > Ecological Forecasting: https://eco.bigelow.org/
> >
> >
> >
> >
> >
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From mtregli@ @ending from gm@il@com  Fri May 25 14:06:59 2018
From: mtregli@ @ending from gm@il@com (Michael Treglia)
Date: Fri, 25 May 2018 08:06:59 -0400
Subject: [R-sig-Geo] raster::clump not working?
In-Reply-To: <CAAbDveuQfRVa9cXa6CA-UiYGJcVNymNTeiBzuthaHZKgy=yGpA@mail.gmail.com>
References: <CAAbDvev+=sx1AOfbERjwHosQHOfRYQKp148xhqsrzx7QTmXDWg@mail.gmail.com>
 <828691EB-B6F7-41BC-80C0-1654C2BAC84B@bigelow.org>
 <CAAbDveuQfRVa9cXa6CA-UiYGJcVNymNTeiBzuthaHZKgy=yGpA@mail.gmail.com>
Message-ID: <CAPKp32v8=ozT+pYu7CNGWBuH_casqymQvH4yLW_Pd0Dvd8F69w@mail.gmail.com>

Check out SDMTools::ConnCompLabel
I think that will get you what you're after.

Hope that helps!
Mike


Please pardon any typos, this message was sent from a mobile device.

On Fri, May 25, 2018, 7:15 AM Jo?o Carreiras <jmbcarreiras at gmail.com> wrote:

> Dear Ben,
>
> Thank you for your prompt reply.
>
> Now I see what clump does. I just thought clump would give the same
> result as ArcGIS "Region Group". I need some command to assign a
> different value to each patch. And by patch I mean contiguous pixels
> having the same value, so that in this (absurd) example I would get
> 648 patches.
>
> Take care
> Joao
>
> On 25 May 2018 at 11:35, Ben Tupper <btupper at bigelow.org> wrote:
> > Hi,
> >
> > I think it is actually correct - there is only one 'clump' of connected
> > cells.  In raster clumps are separated from other clumps by backgound (0
> or
> > NA).  In your example there is no background anywhere so there is just
> one
> > clump.
> >
> > You can see the difference if you divide x in to halves with a row of
> NAs.
> > Note that limited spatial extent so the clumping doesn't wrap around the
> > globe which it will for [-180, 180].
> >
> > r <- raster(ncols=36, nrows=18, xmn = 0, xmx = 36, ymn = 0, ymx = 18)
> > x <- init(r, fun='cell')
> >
> > x[9,1:36] <- NA
> > y <- clump(x)
> > y
> > # class       : RasterLayer
> > # dimensions  : 18, 36, 648  (nrow, ncol, ncell)
> > # resolution  : 1, 1  (x, y)
> > # extent      : 0, 36, 0, 18  (xmin, xmax, ymin, ymax)
> > # coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> > # data source : in memory
> > # names       : clumps
> > # values      : 1, 2  (min, max)
> >
> > x[1:18, 18] <- NA
> > y
> > # class       : RasterLayer
> > # dimensions  : 18, 36, 648  (nrow, ncol, ncell)
> > # resolution  : 1, 1  (x, y)
> > # extent      : 0, 36, 0, 18  (xmin, xmax, ymin, ymax)
> > # coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> > # data source : in memory
> > # names       : clumps
> > # values      : 1, 4  (min, max)
> >
> >
> > Cheers,
> > Ben
> >
> >
> > On May 25, 2018, at 6:00 AM, Jo?o Carreiras <jmbcarreiras at gmail.com>
> wrote:
> >
> > Hi!
> >
> > I've been trying to run the clump command but the output is consistently
> a
> > raster with values == 1. Please find below an example.
> >
> > I'm sure I'm doing something stupid. However, the command is really
> > straightforward and I can't seem to identify what the problem might be.
> >
> > Any help really appreciated.
> > Thanks
> > Joao
> >
> > r <- raster(ncols=36, nrows=18)
> > x <- init(r, fun='cell')
> > x
> > class       : RasterLayer
> > dimensions  : 18, 36, 648  (nrow, ncol, ncell)
> > resolution  : 10, 10  (x, y)
> > extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
> > coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> > data source : in memory
> > names       : layer
> > values      : 1, 648  (min, max)
> > a <- clump(x)
> > a
> > class       : RasterLayer
> > dimensions  : 18, 36, 648  (nrow, ncol, ncell)
> > resolution  : 10, 10  (x, y)
> > extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
> > coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> > data source : in memory
> > names       : clumps
> > values      : 1, 1  (min, max)
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> >
> > Ben Tupper
> > Bigelow Laboratory for Ocean Sciences
> > 60 Bigelow Drive, P.O. Box 380
> > East Boothbay, Maine 04544
> > http://www.bigelow.org
> >
> > Ecological Forecasting: https://eco.bigelow.org/
> >
> >
> >
> >
> >
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From j@viermoreir@ @ending from gm@il@com  Fri May 25 14:43:47 2018
From: j@viermoreir@ @ending from gm@il@com (Javier Moreira)
Date: Fri, 25 May 2018 09:43:47 -0300
Subject: [R-sig-Geo] BIG DATABASE
In-Reply-To: <CALyPt8ze_8ZPrRHmWLWm5KzAksevthHSVvt0irqkkRvQXLPp6A@mail.gmail.com>
References: <CAH7XioweOCK32w2ESfKx1jX-LZu4MfGe6zbNC9cJz11M_sHhiQ@mail.gmail.com>
 <CAMXOh=1Q-4ws+LXxB08heWtrFyTn3YkW635ZSQ3OYb96EvjEXg@mail.gmail.com>
 <CAH7Xiowyhmv9ZQinzZN0LLMwF9BXs2WDh33Ja+QaTcDUQ+4gaw@mail.gmail.com>
 <alpine.LFD.2.21.1805241355230.8104@reclus.nhh.no>
 <CALyPt8ze_8ZPrRHmWLWm5KzAksevthHSVvt0irqkkRvQXLPp6A@mail.gmail.com>
Message-ID: <CAEyHP-1r3wm7HJyZB1wz8ijUH90M=0s1eWT49NiJxNzhdC+N3g@mail.gmail.com>

Can I use this answer to ask exactly for what it's mentioned.
R and Postgis mostly for Easter files.
Can you point books, online courses, tutorials, GitHub pages, anything, to
better understand this?
I had been struggling to find info.

Thanks!

El vie., 25 may. 2018 1:35, Tom Philippi <tephilippi at gmail.com> escribi?:

> What Roger said (as always).
>
> Note that if you use tidyverse and magrittr, dplyr and tidyverse tools work
> well with databases via DBI.  sqldf also works with multiple SQL database
> backends if you're an ol dog like me and don't use tidyverse much.
>
> Also, since this is r-sig-*GEO*, note that postgreSQL has postGIS for
> spatial data, which does far more than the automatic tiling of large
> rasters in package raster.  I'm seeing wonderful performance working with a
> 340M observation >100GB dataset of bird observation data in R via postGIS,
> even with "only" 32GB RAM and constrained to running win7, not linux/unix.
>
> One alternative is that if your database is running on massive hardware
> (tons of memory, many cores, etc.), it is possible to run R within both
> postgreSQL and now MS SQL Server, the first free, the second an additional
> cost add-on, and both usually at the cost of painful negotiations with DA
> administrators for permissions to run your ad hoc R code on their SQL
> server.  If you have the hardware, you can even run R with hadoop, although
> I've never done that with spatial data.
>
> Tom 0
>
>
> On Thu, May 24, 2018 at 5:04 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
> > On Thu, 24 May 2018, Yaya Bamba wrote:
> >
> > Thanks to all of you. I will try with the package  RMySQL and see.
> >>
> >
> > Maybe look more generally through the packages depending on and importing
> > from DBI (https://cran.r-project.org/package=DBI) to see what is
> > available - there are many more than RMySQL.
> >
> > and use the Official Statistics and HPC Task Views:
> >
> > https://cran.r-project.org/view=OfficialStatistics
> >
> > https://cran.r-project.org/view=HighPerformanceComputing
> >
> > to see how typical workflows (not necessarily DB-based) can be handled.
> > The HPC TV has a section on large memory and out-of-memory approaches. If
> > your data are spatial in raster format, the raster package provides some
> > out-of-memory functionality. In sf, spatial vector data may be read from
> > databases too.
> >
> > Roger
> >
> >
> >
> >> 2018-05-24 11:33 GMT+00:00 Andres Diaz Loaiza <madiazl at gmail.com>:
> >>
> >> Hello Yaya,
> >>>
> >>> Many years ago I work with a database in MySQL connected to R through
> the
> >>> package RMySQL?. The data was stored in the MySQL and I was connecting
> >>> and
> >>> using the data from R
> >>>
> >>> you should have a look in:
> >>>
> >>> https://cran.r-project.org/web/packages/RMySQL/index.html
> >>>
> >>> Cheers,
> >>>
> >>> Andres
> >>>
> >>>
> >>
> >>
> >>
> >>
> > --
> > Roger Bivand
> > Department of Economics, Norwegian School of Economics,
> > Helleveien 30, N-5045 Bergen, Norway.
> > voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
> > http://orcid.org/0000-0003-2392-6140
> > https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Fri May 25 14:50:53 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Fri, 25 May 2018 14:50:53 +0200
Subject: [R-sig-Geo] BIG DATABASE
In-Reply-To: <CAEyHP-1r3wm7HJyZB1wz8ijUH90M=0s1eWT49NiJxNzhdC+N3g@mail.gmail.com>
References: <CAH7XioweOCK32w2ESfKx1jX-LZu4MfGe6zbNC9cJz11M_sHhiQ@mail.gmail.com>
 <CAMXOh=1Q-4ws+LXxB08heWtrFyTn3YkW635ZSQ3OYb96EvjEXg@mail.gmail.com>
 <CAH7Xiowyhmv9ZQinzZN0LLMwF9BXs2WDh33Ja+QaTcDUQ+4gaw@mail.gmail.com>
 <alpine.LFD.2.21.1805241355230.8104@reclus.nhh.no>
 <CALyPt8ze_8ZPrRHmWLWm5KzAksevthHSVvt0irqkkRvQXLPp6A@mail.gmail.com>
 <CAEyHP-1r3wm7HJyZB1wz8ijUH90M=0s1eWT49NiJxNzhdC+N3g@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.1805251447500.14213@reclus.nhh.no>

On Fri, 25 May 2018, Javier Moreira wrote:

> Can I use this answer to ask exactly for what it's mentioned.
> R and Postgis mostly for Easter files.
> Can you point books, online courses, tutorials, GitHub pages, anything, to
> better understand this?
> I had been struggling to find info.

For rpostgis, see:

https://journal.r-project.org/archive/2018/RJ-2018-025/index.html

and the supplementary material linked there to replicate the results in 
the online article (should be in the 2018-1 issue).

Roger

>
> Thanks!
>
> El vie., 25 may. 2018 1:35, Tom Philippi <tephilippi at gmail.com> escribi?:
>
>> What Roger said (as always).
>>
>> Note that if you use tidyverse and magrittr, dplyr and tidyverse tools work
>> well with databases via DBI.  sqldf also works with multiple SQL database
>> backends if you're an ol dog like me and don't use tidyverse much.
>>
>> Also, since this is r-sig-*GEO*, note that postgreSQL has postGIS for
>> spatial data, which does far more than the automatic tiling of large
>> rasters in package raster.  I'm seeing wonderful performance working with a
>> 340M observation >100GB dataset of bird observation data in R via postGIS,
>> even with "only" 32GB RAM and constrained to running win7, not linux/unix.
>>
>> One alternative is that if your database is running on massive hardware
>> (tons of memory, many cores, etc.), it is possible to run R within both
>> postgreSQL and now MS SQL Server, the first free, the second an additional
>> cost add-on, and both usually at the cost of painful negotiations with DA
>> administrators for permissions to run your ad hoc R code on their SQL
>> server.  If you have the hardware, you can even run R with hadoop, although
>> I've never done that with spatial data.
>>
>> Tom 0
>>
>>
>> On Thu, May 24, 2018 at 5:04 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>
>>> On Thu, 24 May 2018, Yaya Bamba wrote:
>>>
>>> Thanks to all of you. I will try with the package  RMySQL and see.
>>>>
>>>
>>> Maybe look more generally through the packages depending on and importing
>>> from DBI (https://cran.r-project.org/package=DBI) to see what is
>>> available - there are many more than RMySQL.
>>>
>>> and use the Official Statistics and HPC Task Views:
>>>
>>> https://cran.r-project.org/view=OfficialStatistics
>>>
>>> https://cran.r-project.org/view=HighPerformanceComputing
>>>
>>> to see how typical workflows (not necessarily DB-based) can be handled.
>>> The HPC TV has a section on large memory and out-of-memory approaches. If
>>> your data are spatial in raster format, the raster package provides some
>>> out-of-memory functionality. In sf, spatial vector data may be read from
>>> databases too.
>>>
>>> Roger
>>>
>>>
>>>
>>>> 2018-05-24 11:33 GMT+00:00 Andres Diaz Loaiza <madiazl at gmail.com>:
>>>>
>>>> Hello Yaya,
>>>>>
>>>>> Many years ago I work with a database in MySQL connected to R through
>> the
>>>>> package RMySQL?. The data was stored in the MySQL and I was connecting
>>>>> and
>>>>> using the data from R
>>>>>
>>>>> you should have a look in:
>>>>>
>>>>> https://cran.r-project.org/web/packages/RMySQL/index.html
>>>>>
>>>>> Cheers,
>>>>>
>>>>> Andres
>>>>>
>>>>>
>>>>
>>>>
>>>>
>>>>
>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics,
>>> Helleveien 30, N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>>> http://orcid.org/0000-0003-2392-6140
>>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From jmbc@rreir@@ @ending from gm@il@com  Fri May 25 15:07:12 2018
From: jmbc@rreir@@ @ending from gm@il@com (=?UTF-8?Q?Jo=C3=A3o_Carreiras?=)
Date: Fri, 25 May 2018 14:07:12 +0100
Subject: [R-sig-Geo] raster::clump not working?
In-Reply-To: <CAAcGz98qjuEuubBQ_+f9Z89osEnRtPyO729bY8aWnQSaGiY6kQ@mail.gmail.com>
References: <CAAbDvev+=sx1AOfbERjwHosQHOfRYQKp148xhqsrzx7QTmXDWg@mail.gmail.com>
 <828691EB-B6F7-41BC-80C0-1654C2BAC84B@bigelow.org>
 <CAAbDveuQfRVa9cXa6CA-UiYGJcVNymNTeiBzuthaHZKgy=yGpA@mail.gmail.com>
 <CAAcGz98qjuEuubBQ_+f9Z89osEnRtPyO729bY8aWnQSaGiY6kQ@mail.gmail.com>
Message-ID: <CAAbDveviNVeVOMCH8uVUvGjaOYAXf=kVtJy3oBrd+rkCRY4eaA@mail.gmail.com>

Dear Mike,

great and many thanks as this is exactly what I was after.

Cheers
Joao

On 25 May 2018 at 12:58, Michael Sumner <mdsumner at gmail.com> wrote:
> Joao, this is what you are after I think.  It's important to use
> sf/fasterize otherwise any holes filled by other patches won't be identified
> (and it's faster). It won't scale well given rasterToPolygons, but there
> might be other options using sf related tricks.
>
> library(raster)
> r <- raster(volcano) %/% 20
> ## p has six distinct values (multipolygons)
> p <- rasterToPolygons(r, dissolve = TRUE)
> ## pp has ten distinct patches
> pp <- disaggregate(p)
> pp$patch <- seq_len(nrow(pp))
>
> ## back to raster
> #rr <- rasterize(pp, r, field = pp$patch)
> # or faster with sf/fasterize (also this gets the holes filled correctly)
> rr <- fasterize::fasterize(sf::st_as_sf(pp), r, field = "patch")
> unique(values(rr))
>
> Cheers, Mike.
>
>
> On Fri, 25 May 2018 at 21:15 Jo?o Carreiras <jmbcarreiras at gmail.com> wrote:
>>
>> Dear Ben,
>>
>> Thank you for your prompt reply.
>>
>> Now I see what clump does. I just thought clump would give the same
>> result as ArcGIS "Region Group". I need some command to assign a
>> different value to each patch. And by patch I mean contiguous pixels
>> having the same value, so that in this (absurd) example I would get
>> 648 patches.
>>
>> Take care
>> Joao
>>
>> On 25 May 2018 at 11:35, Ben Tupper <btupper at bigelow.org> wrote:
>> > Hi,
>> >
>> > I think it is actually correct - there is only one 'clump' of connected
>> > cells.  In raster clumps are separated from other clumps by backgound (0
>> > or
>> > NA).  In your example there is no background anywhere so there is just
>> > one
>> > clump.
>> >
>> > You can see the difference if you divide x in to halves with a row of
>> > NAs.
>> > Note that limited spatial extent so the clumping doesn't wrap around the
>> > globe which it will for [-180, 180].
>> >
>> > r <- raster(ncols=36, nrows=18, xmn = 0, xmx = 36, ymn = 0, ymx = 18)
>> > x <- init(r, fun='cell')
>> >
>> > x[9,1:36] <- NA
>> > y <- clump(x)
>> > y
>> > # class       : RasterLayer
>> > # dimensions  : 18, 36, 648  (nrow, ncol, ncell)
>> > # resolution  : 1, 1  (x, y)
>> > # extent      : 0, 36, 0, 18  (xmin, xmax, ymin, ymax)
>> > # coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
>> > # data source : in memory
>> > # names       : clumps
>> > # values      : 1, 2  (min, max)
>> >
>> > x[1:18, 18] <- NA
>> > y
>> > # class       : RasterLayer
>> > # dimensions  : 18, 36, 648  (nrow, ncol, ncell)
>> > # resolution  : 1, 1  (x, y)
>> > # extent      : 0, 36, 0, 18  (xmin, xmax, ymin, ymax)
>> > # coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
>> > # data source : in memory
>> > # names       : clumps
>> > # values      : 1, 4  (min, max)
>> >
>> >
>> > Cheers,
>> > Ben
>> >
>> >
>> > On May 25, 2018, at 6:00 AM, Jo?o Carreiras <jmbcarreiras at gmail.com>
>> > wrote:
>> >
>> > Hi!
>> >
>> > I've been trying to run the clump command but the output is consistently
>> > a
>> > raster with values == 1. Please find below an example.
>> >
>> > I'm sure I'm doing something stupid. However, the command is really
>> > straightforward and I can't seem to identify what the problem might be.
>> >
>> > Any help really appreciated.
>> > Thanks
>> > Joao
>> >
>> > r <- raster(ncols=36, nrows=18)
>> > x <- init(r, fun='cell')
>> > x
>> > class       : RasterLayer
>> > dimensions  : 18, 36, 648  (nrow, ncol, ncell)
>> > resolution  : 10, 10  (x, y)
>> > extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
>> > coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
>> > data source : in memory
>> > names       : layer
>> > values      : 1, 648  (min, max)
>> > a <- clump(x)
>> > a
>> > class       : RasterLayer
>> > dimensions  : 18, 36, 648  (nrow, ncol, ncell)
>> > resolution  : 10, 10  (x, y)
>> > extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
>> > coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
>> > data source : in memory
>> > names       : clumps
>> > values      : 1, 1  (min, max)
>> >
>> > _______________________________________________
>> > R-sig-Geo mailing list
>> > R-sig-Geo at r-project.org
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >
>> >
>> > Ben Tupper
>> > Bigelow Laboratory for Ocean Sciences
>> > 60 Bigelow Drive, P.O. Box 380
>> > East Boothbay, Maine 04544
>> > http://www.bigelow.org
>> >
>> > Ecological Forecasting: https://eco.bigelow.org/
>> >
>> >
>> >
>> >
>> >
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>


From j@viermoreir@ @ending from gm@il@com  Fri May 25 15:00:47 2018
From: j@viermoreir@ @ending from gm@il@com (Javier Moreira)
Date: Fri, 25 May 2018 10:00:47 -0300
Subject: [R-sig-Geo] BIG DATABASE
In-Reply-To: <alpine.LFD.2.21.1805251447500.14213@reclus.nhh.no>
References: <CAH7XioweOCK32w2ESfKx1jX-LZu4MfGe6zbNC9cJz11M_sHhiQ@mail.gmail.com>
 <CAMXOh=1Q-4ws+LXxB08heWtrFyTn3YkW635ZSQ3OYb96EvjEXg@mail.gmail.com>
 <CAH7Xiowyhmv9ZQinzZN0LLMwF9BXs2WDh33Ja+QaTcDUQ+4gaw@mail.gmail.com>
 <alpine.LFD.2.21.1805241355230.8104@reclus.nhh.no>
 <CALyPt8ze_8ZPrRHmWLWm5KzAksevthHSVvt0irqkkRvQXLPp6A@mail.gmail.com>
 <CAEyHP-1r3wm7HJyZB1wz8ijUH90M=0s1eWT49NiJxNzhdC+N3g@mail.gmail.com>
 <alpine.LFD.2.21.1805251447500.14213@reclus.nhh.no>
Message-ID: <CAEyHP-1pzM=3X5a6EMmY=8gJnxP8ZOKo1s+E7GZMUghye=UZ0Q@mail.gmail.com>

Thanks so much!

El vie., 25 may. 2018 9:51, Roger Bivand <Roger.Bivand at nhh.no> escribi?:

> On Fri, 25 May 2018, Javier Moreira wrote:
>
> > Can I use this answer to ask exactly for what it's mentioned.
> > R and Postgis mostly for Easter files.
> > Can you point books, online courses, tutorials, GitHub pages, anything,
> to
> > better understand this?
> > I had been struggling to find info.
>
> For rpostgis, see:
>
> https://journal.r-project.org/archive/2018/RJ-2018-025/index.html
>
> and the supplementary material linked there to replicate the results in
> the online article (should be in the 2018-1 issue).
>
> Roger
>
> >
> > Thanks!
> >
> > El vie., 25 may. 2018 1:35, Tom Philippi <tephilippi at gmail.com>
> escribi?:
> >
> >> What Roger said (as always).
> >>
> >> Note that if you use tidyverse and magrittr, dplyr and tidyverse tools
> work
> >> well with databases via DBI.  sqldf also works with multiple SQL
> database
> >> backends if you're an ol dog like me and don't use tidyverse much.
> >>
> >> Also, since this is r-sig-*GEO*, note that postgreSQL has postGIS for
> >> spatial data, which does far more than the automatic tiling of large
> >> rasters in package raster.  I'm seeing wonderful performance working
> with a
> >> 340M observation >100GB dataset of bird observation data in R via
> postGIS,
> >> even with "only" 32GB RAM and constrained to running win7, not
> linux/unix.
> >>
> >> One alternative is that if your database is running on massive hardware
> >> (tons of memory, many cores, etc.), it is possible to run R within both
> >> postgreSQL and now MS SQL Server, the first free, the second an
> additional
> >> cost add-on, and both usually at the cost of painful negotiations with
> DA
> >> administrators for permissions to run your ad hoc R code on their SQL
> >> server.  If you have the hardware, you can even run R with hadoop,
> although
> >> I've never done that with spatial data.
> >>
> >> Tom 0
> >>
> >>
> >> On Thu, May 24, 2018 at 5:04 AM, Roger Bivand <Roger.Bivand at nhh.no>
> wrote:
> >>
> >>> On Thu, 24 May 2018, Yaya Bamba wrote:
> >>>
> >>> Thanks to all of you. I will try with the package  RMySQL and see.
> >>>>
> >>>
> >>> Maybe look more generally through the packages depending on and
> importing
> >>> from DBI (https://cran.r-project.org/package=DBI) to see what is
> >>> available - there are many more than RMySQL.
> >>>
> >>> and use the Official Statistics and HPC Task Views:
> >>>
> >>> https://cran.r-project.org/view=OfficialStatistics
> >>>
> >>> https://cran.r-project.org/view=HighPerformanceComputing
> >>>
> >>> to see how typical workflows (not necessarily DB-based) can be handled.
> >>> The HPC TV has a section on large memory and out-of-memory approaches.
> If
> >>> your data are spatial in raster format, the raster package provides
> some
> >>> out-of-memory functionality. In sf, spatial vector data may be read
> from
> >>> databases too.
> >>>
> >>> Roger
> >>>
> >>>
> >>>
> >>>> 2018-05-24 11:33 GMT+00:00 Andres Diaz Loaiza <madiazl at gmail.com>:
> >>>>
> >>>> Hello Yaya,
> >>>>>
> >>>>> Many years ago I work with a database in MySQL connected to R through
> >> the
> >>>>> package RMySQL?. The data was stored in the MySQL and I was
> connecting
> >>>>> and
> >>>>> using the data from R
> >>>>>
> >>>>> you should have a look in:
> >>>>>
> >>>>> https://cran.r-project.org/web/packages/RMySQL/index.html
> >>>>>
> >>>>> Cheers,
> >>>>>
> >>>>> Andres
> >>>>>
> >>>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>> --
> >>> Roger Bivand
> >>> Department of Economics, Norwegian School of Economics,
> >>> Helleveien 30, N-5045 Bergen, Norway.
> >>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
> >>> http://orcid.org/0000-0003-2392-6140
> >>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
> >>> _______________________________________________
> >>> R-sig-Geo mailing list
> >>> R-sig-Geo at r-project.org
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>>
> >>>
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at r-project.org
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

	[[alternative HTML version deleted]]


From K@therine@B@nn@r-M@rtin @ending from dfo-mpo@gc@c@  Sun May 27 20:58:24 2018
From: K@therine@B@nn@r-M@rtin @ending from dfo-mpo@gc@c@ (Bannar-Martin, Katherine)
Date: Sun, 27 May 2018 18:58:24 +0000
Subject: [R-sig-Geo] converting hierarchical clusters to polygons
Message-ID: <C58761628CE59340834AA8638074761A2785BE@DFBCV6CWPEXP001.ENT.dfo-mpo.ca>

I have used hierarchical clustering to assign lats and longs (start and end positions of lines) to separate cluster IDs.
I now need to convert each cluster of points to a polygon.
My first attempt was with CHULL, with the aim to then convert each convex polygon to a polygon layer. However, I cannot get the hulls to plot by cluster and then save as an external object.
I think the easiest method would be to take the outside points of each cluster of points and connect them with a polyline and then convert it to a polygon.
I have 100s of clusters per year (13 years) so I do not want to have 1000s of separate polygon files, but instead one layer with all the polygons per year.

Dummy data to show approximate structure:
GISID     x             y             Attribute              Year       CLUSTER_ID
1             -129.24 52.994   Start                     2005      1
2             -131.26 52.73     Start                     2006      33
3             -126.02 49.297   End                       2005      5
...

Any advice, helpfiles, or vignettes would be greatly appreciated. I've read a variety of stackoverflow entries and r-sig-geo entries and have unsuccessfully adapted other solutions.
e.g. https://stackoverflow.com/questions/44928507/draw-polygons-around-clusters-from-hclust
https://www.nceas.ucsb.edu/scicomp/usecases/GenerateConvexHullAndROIForPoints
Thanks!

	[[alternative HTML version deleted]]


From kent3737 @ending from gm@il@com  Mon May 28 15:39:03 2018
From: kent3737 @ending from gm@il@com (Kent Johnson)
Date: Mon, 28 May 2018 09:39:03 -0400
Subject: [R-sig-Geo] converting hierarchical clusters to polygons
Message-ID: <CAPP0wyiR-AQ8rs6_HF0LvB4a4_1-1dnzoy1LLZX-jzcpsNUq6Q@mail.gmail.com>

On Mon, May 28, 2018 at 6:00 AM, <r-sig-geo-request at r-project.org> wrote:

> From: "Bannar-Martin, Katherine"
>         <Katherine.Bannar-Martin at dfo-mpo.gc.ca>
> To: "r-sig-geo at r-project.org" <r-sig-geo at r-project.org>
> Subject: [R-sig-Geo] converting hierarchical clusters to polygons
> Message-ID:
>         <C58761628CE59340834AA8638074761A2785BE at DFBCV6CWPEXP001.ENT.
> dfo-mpo.ca>
>
> Content-Type: text/plain; charset="utf-8"
>
> I have used hierarchical clustering to assign lats and longs (start and
> end positions of lines) to separate cluster IDs.
> I now need to convert each cluster of points to a polygon.
>


> I have 100s of clusters per year (13 years) so I do not want to have 1000s
> of separate polygon files, but instead one layer with all the polygons per
> year.
>
> Dummy data to show approximate structure:
> GISID     x             y             Attribute              Year
>  CLUSTER_ID
> 1             -129.24 52.994   Start                     2005      1
> 2             -131.26 52.73     Start                     2006      33
> 3             -126.02 49.297   End                       2005      5
>

This uses tidyverse and sf to find the convex hull of points in each
cluster and create a simple features object with one row per polygon. It
retains the Year and CLUSTER_ID so you can select by year and show all
clusters or write one file per year.

library(tidyverse)
library(sf)

d = read_table2(col_names=TRUE,
file="GISID     x             y             Attribute              Year
   CLUSTER_ID
1             -129.24 52.994   Start                     2005      1
2             -131.26 52.73     Start                     2006      33
3             -126.02 49.297   End                       2005      5")

groups = d %>%
  select(-GISID, -Attribute) %>%
  nest(x, y) %>%
  mutate(poly = map(data, ~st_convex_hull(st_multipoint(as.matrix(.[,c('x',
'y')]))))) %>%
  select(-data) %>%
  st_sf()

# For example to plot all polygons for one year, colored y CLUSTER_ID:
groups %>% filter(Year==2006) %>% select(-Year) %>% plot()

HTH,
Kent Johnson

	[[alternative HTML version deleted]]


From l@ur@@poggio @ending from gm@il@com  Tue May 29 15:00:37 2018
From: l@ur@@poggio @ending from gm@il@com (Laura Poggio)
Date: Tue, 29 May 2018 14:00:37 +0100
Subject: [R-sig-Geo] error installing rgdal with gdal 2.3.0 on centos7
Message-ID: <CAKmfgFMtr-G7780fcirCcwQQdg5uV3n-ZX8Ztb2-RBJKs9ZGTg@mail.gmail.com>

Dear all,
I am trying to install rgdal on a centos 7 machine.
First I installed from source gdal 2.3.0. No errors and it is working as
expected.

I then tried to install rgdal using R 3.4.4

I get the error:

In file included from /usr/local/include/gdal.h:45:0,
                 from gdal_test.cc:1:
/usr/local/include/cpl_port.h:187:6: error: #error Must have C++11 or newer.
 #    error Must have C++11 or newer.

I can use a previous version of gdal (2.2.1) without problems, but I was
wondering if other people found a more robust solution that could work with
future versions.

Thanks a lot

Laura

	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Tue May 29 18:18:17 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Tue, 29 May 2018 18:18:17 +0200
Subject: [R-sig-Geo] error installing rgdal with gdal 2.3.0 on centos7
In-Reply-To: <CAKmfgFMtr-G7780fcirCcwQQdg5uV3n-ZX8Ztb2-RBJKs9ZGTg@mail.gmail.com>
References: <CAKmfgFMtr-G7780fcirCcwQQdg5uV3n-ZX8Ztb2-RBJKs9ZGTg@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.1805291803030.10086@reclus.nhh.no>

On Tue, 29 May 2018, Laura Poggio wrote:

> Dear all,
> I am trying to install rgdal on a centos 7 machine.

Which version of rgdal - the current CRAN source?

> First I installed from source gdal 2.3.0. No errors and it is working as
> expected.
>
> I then tried to install rgdal using R 3.4.4
>
> I get the error:
>
> In file included from /usr/local/include/gdal.h:45:0,
>                 from gdal_test.cc:1:
> /usr/local/include/cpl_port.h:187:6: error: #error Must have C++11 or newer.
> #    error Must have C++11 or newer.

Is this during configure? Could you try by downloading the tarball and 
running

R CMD INSTALL rgdal_1-2.20.tar.gz

In configure, the value of CXX is taken from "${RBIN}" CMD config CXX 
where "${RBIN}" is RBIN="${R_HOME}/bin/R" and R_HOME=`R RHOME`, so

R CMD config CXX

which in your case may need -std=g++11 or some such added - please inform.

Roger

>
> I can use a previous version of gdal (2.2.1) without problems, but I was
> wondering if other people found a more robust solution that could work with
> future versions.
>
> Thanks a lot
>
> Laura
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From l@ur@@poggio @ending from gm@il@com  Wed May 30 15:42:37 2018
From: l@ur@@poggio @ending from gm@il@com (Laura Poggio)
Date: Wed, 30 May 2018 14:42:37 +0100
Subject: [R-sig-Geo] error installing rgdal with gdal 2.3.0 on centos7
In-Reply-To: <alpine.LFD.2.21.1805291803030.10086@reclus.nhh.no>
References: <CAKmfgFMtr-G7780fcirCcwQQdg5uV3n-ZX8Ztb2-RBJKs9ZGTg@mail.gmail.com>
 <alpine.LFD.2.21.1805291803030.10086@reclus.nhh.no>
Message-ID: <CAKmfgFMwUOZwi7wMmMG5EX2okUbTwr8q1a2gAU4=PG_=XhEGXA@mail.gmail.com>

Dear Roger,
I was trying to install the version from CRAN, sorry I should have
mentioned it.

The C++ compiler on centos7 seemed to be too old. The solution that worked
was:
installing the devtoolset environment
activate the environment
run R  CMD INSTALL rgdal_1-2.20.tar.gz from the activated environment
(normal install.packages("rgdal") worked as well)
exit the environment

The package is now working without problems (hopefully ... initial tests
fine).

Thanks a lot for the help that set us on the right path.

Laura



On 29 May 2018 at 17:18, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Tue, 29 May 2018, Laura Poggio wrote:
>
> Dear all,
>> I am trying to install rgdal on a centos 7 machine.
>>
>
> Which version of rgdal - the current CRAN source?


>
> First I installed from source gdal 2.3.0. No errors and it is working as
>> expected.
>>
>> I then tried to install rgdal using R 3.4.4
>>
>> I get the error:
>>
>> In file included from /usr/local/include/gdal.h:45:0,
>>                 from gdal_test.cc:1:
>> /usr/local/include/cpl_port.h:187:6: error: #error Must have C++11 or
>> newer.
>> #    error Must have C++11 or newer.
>>
>
> Is this during configure? Could you try by downloading the tarball and
> running
>
> R CMD INSTALL rgdal_1-2.20.tar.gz
>
> In configure, the value of CXX is taken from "${RBIN}" CMD config CXX
> where "${RBIN}" is RBIN="${R_HOME}/bin/R" and R_HOME=`R RHOME`, so
>
> R CMD config CXX
>
> which in your case may need -std=g++11 or some such added - please inform.
>
> Roger
>
>
>> I can use a previous version of gdal (2.2.1) without problems, but I was
>> wondering if other people found a more robust solution that could work
>> with
>> future versions.
>>
>> Thanks a lot
>>
>> Laura
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
> --
> Roger Bivand
> Department of
> <https://maps.google.com/?q=Department+of&entry=gmail&source=g>
> Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>

	[[alternative HTML version deleted]]


From l@ur@@poggio @ending from gm@il@com  Wed May 30 16:03:46 2018
From: l@ur@@poggio @ending from gm@il@com (Laura Poggio)
Date: Wed, 30 May 2018 15:03:46 +0100
Subject: [R-sig-Geo] spam message when sending a mail to the list
Message-ID: <CAKmfgFMY7Bz2RZdwW7Ey1Ygfdi5eow4uHEcSe6iaXSzvFg59zg@mail.gmail.com>

Dear list,
not sure if it is just me, but I sent two messages to the list in the past
couple of days. In both cases I immediately received a message from an
unknown sender with some "particular requests". This is not happening when
I send mails to other contacts.

I can provide more information to the maintainers or please just let me
know if/where to report them.

Thanks

laura

	[[alternative HTML version deleted]]


From m@di@zl @ending from gm@il@com  Wed May 30 16:08:55 2018
From: m@di@zl @ending from gm@il@com (Andres Diaz Loaiza)
Date: Wed, 30 May 2018 16:08:55 +0200
Subject: [R-sig-Geo] spam message when sending a mail to the list
In-Reply-To: <CAKmfgFMY7Bz2RZdwW7Ey1Ygfdi5eow4uHEcSe6iaXSzvFg59zg@mail.gmail.com>
References: <CAKmfgFMY7Bz2RZdwW7Ey1Ygfdi5eow4uHEcSe6iaXSzvFg59zg@mail.gmail.com>
Message-ID: <CAMXOh=16sVKYfWe8ciPQYy7CfupMSzrzt3RNsqKr4n5V0t9bYA@mail.gmail.com>

Hi LAura,

To me also happened the same, even worst because they are now sending
photos which I am probably sure contains viruses.

Is true that the maillist maintainer should exclude this mail address

The mail of the sender is:  elisarose811567 at es.fcebo.com

All the best,

Andres

2018-05-30 16:03 GMT+02:00 Laura Poggio <laura.poggio at gmail.com>:

> Dear list,
> not sure if it is just me, but I sent two messages to the list in the past
> couple of days. In both cases I immediately received a message from an
> unknown sender with some "particular requests". This is not happening when
> I send mails to other contacts.
>
> I can provide more information to the maintainers or please just let me
> know if/where to report them.
>
> Thanks
>
> laura
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Andr?s D.

	[[alternative HTML version deleted]]


From engli@hchri@topher@ @ending from gm@il@com  Wed May 30 16:19:12 2018
From: engli@hchri@topher@ @ending from gm@il@com (chris english)
Date: Wed, 30 May 2018 10:19:12 -0400
Subject: [R-sig-Geo] spam message when sending a mail to the list
In-Reply-To: <CAMXOh=16sVKYfWe8ciPQYy7CfupMSzrzt3RNsqKr4n5V0t9bYA@mail.gmail.com>
References: <CAKmfgFMY7Bz2RZdwW7Ey1Ygfdi5eow4uHEcSe6iaXSzvFg59zg@mail.gmail.com>
 <CAMXOh=16sVKYfWe8ciPQYy7CfupMSzrzt3RNsqKr4n5V0t9bYA@mail.gmail.com>
Message-ID: <CAASFQpTs2YQB8fRz+y3d32CYnZ0HoODhSBTRyahxPOS53ZEq8A@mail.gmail.com>

Laura, Andres,

As Roger admonished me, just never respond ( a mistake I made ), as it is
very difficult to both maintain this
valuable communication regards spatial statistics and exclude the clearly
un-statistically minded.

Chris

On Wed, May 30, 2018 at 10:08 AM, Andres Diaz Loaiza <madiazl at gmail.com>
wrote:

> Hi LAura,
>
> To me also happened the same, even worst because they are now sending
> photos which I am probably sure contains viruses.
>
> Is true that the maillist maintainer should exclude this mail address
>
> The mail of the sender is:  elisarose811567 at es.fcebo.com
>
> All the best,
>
> Andres
>
> 2018-05-30 16:03 GMT+02:00 Laura Poggio <laura.poggio at gmail.com>:
>
> > Dear list,
> > not sure if it is just me, but I sent two messages to the list in the
> past
> > couple of days. In both cases I immediately received a message from an
> > unknown sender with some "particular requests". This is not happening
> when
> > I send mails to other contacts.
> >
> > I can provide more information to the maintainers or please just let me
> > know if/where to report them.
> >
> > Thanks
> >
> > laura
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
>
>
> --
> Andr?s D.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From l@ur@@poggio @ending from gm@il@com  Wed May 30 16:34:41 2018
From: l@ur@@poggio @ending from gm@il@com (Laura Poggio)
Date: Wed, 30 May 2018 15:34:41 +0100
Subject: [R-sig-Geo] spam message when sending a mail to the list
In-Reply-To: <CAASFQpTs2YQB8fRz+y3d32CYnZ0HoODhSBTRyahxPOS53ZEq8A@mail.gmail.com>
References: <CAKmfgFMY7Bz2RZdwW7Ey1Ygfdi5eow4uHEcSe6iaXSzvFg59zg@mail.gmail.com>
 <CAMXOh=16sVKYfWe8ciPQYy7CfupMSzrzt3RNsqKr4n5V0t9bYA@mail.gmail.com>
 <CAASFQpTs2YQB8fRz+y3d32CYnZ0HoODhSBTRyahxPOS53ZEq8A@mail.gmail.com>
Message-ID: <CAKmfgFPmZDxC=W4=vXcciMEX6+xhfeL5MpNLKi4iatu7XCUegA@mail.gmail.com>

Hi Chris,
of course the message is immediately deleted and no response. And I do
understand the issues of the maintainers (and really appreciate their
efforts!).
The senders vary, one is what Andres mentioned, but I got a couple of
others. However they are now sending "not safe for work" images. I am just
afraid that the mailing list will be soon blocked by mail filters.


Thanks

Laura

On 30 May 2018 at 15:19, chris english <englishchristophera at gmail.com>
wrote:

> Laura, Andres,
>
> As Roger admonished me, just never respond ( a mistake I made ), as it is
> very difficult to both maintain this
> valuable communication regards spatial statistics and exclude the clearly
> un-statistically minded.
>
> Chris
>
> On Wed, May 30, 2018 at 10:08 AM, Andres Diaz Loaiza <madiazl at gmail.com>
> wrote:
>
>> Hi LAura,
>>
>> To me also happened the same, even worst because they are now sending
>> photos which I am probably sure contains viruses.
>>
>> Is true that the maillist maintainer should exclude this mail address
>>
>> The mail of the sender is:  elisarose811567 at es.fcebo.com
>>
>> All the best,
>>
>> Andres
>>
>> 2018-05-30 16:03 GMT+02:00 Laura Poggio <laura.poggio at gmail.com>:
>>
>> > Dear list,
>> > not sure if it is just me, but I sent two messages to the list in the
>> past
>> > couple of days. In both cases I immediately received a message from an
>> > unknown sender with some "particular requests". This is not happening
>> when
>> > I send mails to other contacts.
>> >
>> > I can provide more information to the maintainers or please just let me
>> > know if/where to report them.
>> >
>> > Thanks
>> >
>> > laura
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-Geo mailing list
>> > R-sig-Geo at r-project.org
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >
>>
>>
>>
>> --
>> Andr?s D.
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>

	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Wed May 30 16:39:38 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Wed, 30 May 2018 14:39:38 +0000
Subject: [R-sig-Geo] spam message when sending a mail to the list
In-Reply-To: <CAASFQpTs2YQB8fRz+y3d32CYnZ0HoODhSBTRyahxPOS53ZEq8A@mail.gmail.com>
References: <CAKmfgFMY7Bz2RZdwW7Ey1Ygfdi5eow4uHEcSe6iaXSzvFg59zg@mail.gmail.com>
 <CAMXOh=16sVKYfWe8ciPQYy7CfupMSzrzt3RNsqKr4n5V0t9bYA@mail.gmail.com>,
 <CAASFQpTs2YQB8fRz+y3d32CYnZ0HoODhSBTRyahxPOS53ZEq8A@mail.gmail.com>
Message-ID: <BDBEEBC63E3A2C25.d604fecd-47b5-4e9b-9812-62a3a4b112d7@mail.outlook.com>

Thanks for your patience. If you receive such messages after posting, please contact the list owner, rather than post on the list. Several higher volume R lists have seen this behaviour over the last month, and steps are being taken to stop it, so far without sufficient success. Diagnoses are discussed off-list for obvious reasons.

Roger Bivand
List admin.

Norwegian School of Economics
Bergen, Norway



Fra: chris english
Sendt: onsdag 30. mai, 16.19
Emne: Re: [R-sig-Geo] spam message when sending a mail to the list
Til: Andres Diaz Loaiza
Kopi: r-sig-geo at r-project.org


Laura, Andres, As Roger admonished me, just never respond ( a mistake I made ), as it is very difficult to both maintain this valuable communication regards spatial statistics and exclude the clearly un-statistically minded. Chris On Wed, May 30, 2018 at 10:08 AM, Andres Diaz Loaiza wrote: > Hi LAura, > > To me also happened the same, even worst because they are now sending > photos which I am probably sure contains viruses. > > Is true that the maillist maintainer should exclude this mail address > > The mail of the sender is: elisarose811567 at es.fcebo.com > > All the best, > > Andres > > 2018-05-30 16:03 GMT+02:00 Laura Poggio : > > > Dear list, > > not sure if it is just me, but I sent two messages to the list in the > past > > couple of days. In both cases I immediately received a message from an > > unknown sender with some "particular requests". This is not happening > when > > I send mails to other contacts. > > > > I can provide more information to the maintainers or please just let me > > know if/where to report them. > > > > Thanks > > > > laura > > > > [[alternative HTML version deleted]] > > > > _______________________________________________ > > R-sig-Geo mailing list > > R-sig-Geo at r-project.org > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo > > > > > > -- > Andr?s D. > > [[alternative HTML version deleted]] > > _______________________________________________ > R-sig-Geo mailing list > R-sig-Geo at r-project.org > https://stat.ethz.ch/mailman/listinfo/r-sig-geo > [[alternative HTML version deleted]] _______________________________________________ R-sig-Geo mailing list R-sig-Geo at r-project.org https://stat.ethz.ch/mailman/listinfo/r-sig-geo


	[[alternative HTML version deleted]]


From m@rt@zore@ @ending from gm@il@com  Wed May 30 17:59:35 2018
From: m@rt@zore@ @ending from gm@il@com (marta azores)
Date: Wed, 30 May 2018 15:59:35 +0000
Subject: [R-sig-Geo] spam message when sending a mail to the list
In-Reply-To: <CAKmfgFMY7Bz2RZdwW7Ey1Ygfdi5eow4uHEcSe6iaXSzvFg59zg@mail.gmail.com>
References: <CAKmfgFMY7Bz2RZdwW7Ey1Ygfdi5eow4uHEcSe6iaXSzvFg59zg@mail.gmail.com>
Message-ID: <CAE3WKgRGjJPSR3V7=YSxZ4V4TSHYVtSTGHEXih7n85Vdcmjc6Q@mail.gmail.com>

Me too, but from two different mails, both included the name elisa.
Photos+viruses

2018-05-30 14:03 GMT+00:00 Laura Poggio <laura.poggio at gmail.com>:

> Dear list,
> not sure if it is just me, but I sent two messages to the list in the past
> couple of days. In both cases I immediately received a message from an
> unknown sender with some "particular requests". This is not happening when
> I send mails to other contacts.
>
> I can provide more information to the maintainers or please just let me
> know if/where to report them.
>
> Thanks
>
> laura
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From m@rt@zore@ @ending from gm@il@com  Wed May 30 18:54:01 2018
From: m@rt@zore@ @ending from gm@il@com (marta azores)
Date: Wed, 30 May 2018 16:54:01 +0000
Subject: [R-sig-Geo] spam message when sending a mail to the list
In-Reply-To: <932719b6ff167296bd633e59c9bec13f@mx.google.com>
References: <CAE3WKgRGjJPSR3V7=YSxZ4V4TSHYVtSTGHEXih7n85Vdcmjc6Q@mail.gmail.com>
 <932719b6ff167296bd633e59c9bec13f@mx.google.com>
Message-ID: <CAE3WKgQWM7R5x3VNBWSixp8XRMiDGL5XJ9ZzH92-FTRZQMxo8A@mail.gmail.com>

I answered 48 minutes ago to the message "[R-sig-Geo] spam message when
sending a mail to the list"
and 30minutes later came another spam. This time is from this mail:
AmandaCruise <icehuggy_001 at naughtyrelation.pw>
They are really quickly to send us spam, after our posting.





2018-05-30 16:39 GMT+00:00 AmandaCruise <icehuggy_001 at naughtyrelation.pw>:

> Hi marta,  thanks for the reply. I am Amanda Cruise . What part of the
> city are you in? Let me clear you something first, i am here for fun only.
> Nothing serious. All I need a partner on my bed who can satisfy me. So tell
> me this about yourself?.whats your favorite position and how many inches is
> it?
>
> On Wed, 30 May 2018 at 10:39 AM, marta azores <martazores at gmail.com>
> wrote:
>
>>
>>
>>
>>

	[[alternative HTML version deleted]]


From @lex@ndre@@nto@br @ending from y@hoo@com@br  Wed May 30 21:11:58 2018
From: @lex@ndre@@nto@br @ending from y@hoo@com@br (ASANTOS)
Date: Wed, 30 May 2018 15:11:58 -0400
Subject: [R-sig-Geo] Extract xy coordinates from raster of interesting
 neighborhood cells
Message-ID: <c0859532-3d25-508d-0f86-9dcca368769a@yahoo.com.br>

Dear R-Sig-Geo Members,

 ??? I've like to extract xy coordinates from raster of 24 neigborhood 
cells that surround the 4 given points (pts_s) pixels and for this I used:

#Packages

require(raster)
require(sp)

## Create a raster
r <- raster(nc=30, nr=30)
r <- setValues(r, round(runif(ncell(r))* 255))
plot(r)

##Given interesting points coordinates
xd???? <- c(-24.99270,45.12069,99.40321,73.64419)
yd? <- c(-45.435267,-88.369745,-7.086949,44.174530)
pts <- data.frame(xd,yd)
pts_s<- SpatialPoints(pts)
points(pts_s, col="red", pch=16)

## Find pixels center of each point (My idea is not to use the original 
point coordinates, but coordinates of the center of interesting pixel).
N_cells <- cellFromXY(r, pts_s)


# Extract xy coordinates from raster of 24 neighborhood cells given 
pixel number N_cells
e<-adjacent(r, N_cells , directions='bishop', id=TRUE)
coordinates(land_mask)[e[,1],] ## Doesn't return 24 neighborhood by 
N_cells object
ng_coords<-coordinates(land_mask)[e[,1],]
#

#Visualization

plot(r)
points(pts_s, col="red", pch=16)
points(ng_coords, col="black", pch=16)
##

 ??? But I don't have success because the ng_coords object is not a 24 
neighborhood cells of each point that I search. There are solution for this?

Thanks in advance,

Alexandre

-- 
======================================================================
Alexandre dos Santos
Prote??o Florestal
IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
Campus C?ceres
Caixa Postal 244
Avenida dos Ramires, s/n
Bairro: Distrito Industrial
C?ceres - MT                      CEP: 78.200-000
Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)

         alexandre.santos at cas.ifmt.edu.br
Lattes: http://lattes.cnpq.br/1360403201088680
OrcID: orcid.org/0000-0001-8232-6722
Researchgate: www.researchgate.net/profile/Alexandre_Santos10
LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/


From btupper @ending from bigelow@org  Wed May 30 22:22:35 2018
From: btupper @ending from bigelow@org (Ben Tupper)
Date: Wed, 30 May 2018 16:22:35 -0400
Subject: [R-sig-Geo] Extract xy coordinates from raster of interesting
 neighborhood cells
In-Reply-To: <c0859532-3d25-508d-0f86-9dcca368769a@yahoo.com.br>
References: <c0859532-3d25-508d-0f86-9dcca368769a@yahoo.com.br>
Message-ID: <B5250464-3107-4AD4-A7FB-A00B7F4AEFAB@bigelow.org>

Hi,

I'm not sure why you expect 24 points - you have 4 locations and for each you want the 4 bishop's directions - so, I think at most you should expect 16 points.  See http://www.lpc.uottawa.ca/publications/moransi/moran.htm <http://www.lpc.uottawa.ca/publications/moransi/moran.htm> for where I expect 4 points for bishop's for each input location; perhaps you have a different idea of bishop's direction?  

Your second point [45.12069, -88.369745] is on to the southern edge of the raster - so it can't find points southward - only the 2 northward.

Finally, it may not make any difference at all, but your pts_s has no coordinate reference.  Below I show where I assign the same projection as your raster.  I also don't have 'land_mask' so I reused 'r' and used xyFromCell to backwards extract the adjacent cell coordinates.

Does that do the trick for you?

Cheers,
Ben

### START
require(raster)
require(sp)

## Create a raster
r <- raster(nc=30, nr=30)
r <- setValues(r, round(runif(ncell(r))* 255))
plot(r)

##Given interesting points coordinates
xd     <- c( -24.99270,   45.12069,  99.40321,  73.64419)
yd     <- c(-45.435267, -88.369745, -7.086949, 44.174530)
pts <- data.frame(xd,yd)
pts_s<- SpatialPoints(pts)
projection(pts_s) <- projection(r)
points(pts_s, col="red", pch=16)

## Find pixels center of each point 
N_cells <- cellFromXY(r, pts_s)

e <- adjacent(r, N_cells , directions='bishop', id=TRUE, sorted = TRUE)
xy <- xyFromCell(r, e[,'to'], spatial = TRUE)


#Visualization

plot(r)
points(pts_s, col="red", pch=16)
points(xy, col="black", pch=16)
### END





> On May 30, 2018, at 3:11 PM, ASANTOS via R-sig-Geo <r-sig-geo at r-project.org> wrote:
> 
> Dear R-Sig-Geo Members,
> 
>     I've like to extract xy coordinates from raster of 24 neigborhood cells that surround the 4 given points (pts_s) pixels and for this I used:
> 
> #Packages
> 
> require(raster)
> require(sp)
> 
> ## Create a raster
> r <- raster(nc=30, nr=30)
> r <- setValues(r, round(runif(ncell(r))* 255))
> plot(r)
> 
> ##Given interesting points coordinates
> xd     <- c(-24.99270,45.12069,99.40321,73.64419)
> yd  <- c(-45.435267,-88.369745,-7.086949,44.174530)
> pts <- data.frame(xd,yd)
> pts_s<- SpatialPoints(pts)
> points(pts_s, col="red", pch=16)
> 
> ## Find pixels center of each point (My idea is not to use the original point coordinates, but coordinates of the center of interesting pixel).
> N_cells <- cellFromXY(r, pts_s)
> 
> 
> # Extract xy coordinates from raster of 24 neighborhood cells given pixel number N_cells
> e<-adjacent(r, N_cells , directions='bishop', id=TRUE)
> coordinates(land_mask)[e[,1],] ## Doesn't return 24 neighborhood by N_cells object
> ng_coords<-coordinates(land_mask)[e[,1],]
> #
> 
> #Visualization
> 
> plot(r)
> points(pts_s, col="red", pch=16)
> points(ng_coords, col="black", pch=16)
> ##
> 
>     But I don't have success because the ng_coords object is not a 24 neighborhood cells of each point that I search. There are solution for this?
> 
> Thanks in advance,
> 
> Alexandre
> 
> -- 
> ======================================================================
> Alexandre dos Santos
> Prote??o Florestal
> IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
> Campus C?ceres
> Caixa Postal 244
> Avenida dos Ramires, s/n
> Bairro: Distrito Industrial
> C?ceres - MT                      CEP: 78.200-000
> Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)
> 
>        alexandre.santos at cas.ifmt.edu.br
> Lattes: http://lattes.cnpq.br/1360403201088680
> OrcID: orcid.org/0000-0001-8232-6722
> Researchgate: www.researchgate.net/profile/Alexandre_Santos10
> LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
> Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]


From vij@ylull@ @ending from gm@il@com  Wed May 30 22:29:23 2018
From: vij@ylull@ @ending from gm@il@com (Vijay Lulla)
Date: Wed, 30 May 2018 16:29:23 -0400
Subject: [R-sig-Geo] Extract xy coordinates from raster of interesting
 neighborhood cells
In-Reply-To: <B5250464-3107-4AD4-A7FB-A00B7F4AEFAB@bigelow.org>
References: <c0859532-3d25-508d-0f86-9dcca368769a@yahoo.com.br>
 <B5250464-3107-4AD4-A7FB-A00B7F4AEFAB@bigelow.org>
Message-ID: <CAKkiGbvTHNTAKJdtXPVOxb=TGS=dHn44ugxoELrjH=BxccH91g@mail.gmail.com>

Or you can try something like this?

### START
require(raster)
require(sp)

r <- raster(nc=30, nr=30)
r <- setValues(r, round(runif(ncell(r))* 255))

xd     <- c(-24.99270,45.12069,99.40321,73.64419)
yd  <- c(-45.435267,-88.369745,-7.086949,44.174530)
pts <- data.frame(xd,yd)
pts_s<- SpatialPoints(pts)

N_cells <- cellFromXY(r, pts_s)
e<-adjacent(r, N_cells , directions='bishop', pairs=FALSE)

ng_coords <- xyFromCell(r, e)
plot(r)
points(pts, col='red', pch=16)
points(ng_coords, col='black', pch=16)


### Alternative to what Ben suggested!
## Set neighborhood matrix.  Focal cell is 0 while neighbors are 1!!
neigh <- matrix(1L, nrow=5, ncol=5); neigh[3,3] <- 0L
e1<-adjacent(r, N_cells , directions=neigh, pairs=FALSE)
ng_coords1 <- xyFromCell(r, e1)
plot(r);
points(pts, col='red', pch=16);
points(ng_coords, col='black', pch=16);
points(ng_coords1, col='blue', pch=16)
### END

HTH,
Vijay.

On Wed, May 30, 2018 at 4:22 PM, Ben Tupper <btupper at bigelow.org> wrote:

> Hi,
>
> I'm not sure why you expect 24 points - you have 4 locations and for each
> you want the 4 bishop's directions - so, I think at most you should expect
> 16 points.  See http://www.lpc.uottawa.ca/publications/moransi/moran.htm <
> http://www.lpc.uottawa.ca/publications/moransi/moran.htm> for where I
> expect 4 points for bishop's for each input location; perhaps you have a
> different idea of bishop's direction?
>
> Your second point [45.12069, -88.369745] is on to the southern edge of the
> raster - so it can't find points southward - only the 2 northward.
>
> Finally, it may not make any difference at all, but your pts_s has no
> coordinate reference.  Below I show where I assign the same projection as
> your raster.  I also don't have 'land_mask' so I reused 'r' and used
> xyFromCell to backwards extract the adjacent cell coordinates.
>
> Does that do the trick for you?
>
> Cheers,
> Ben
>
> ### START
> require(raster)
> require(sp)
>
> ## Create a raster
> r <- raster(nc=30, nr=30)
> r <- setValues(r, round(runif(ncell(r))* 255))
> plot(r)
>
> ##Given interesting points coordinates
> xd     <- c( -24.99270,   45.12069,  99.40321,  73.64419)
> yd     <- c(-45.435267, -88.369745, -7.086949, 44.174530)
> pts <- data.frame(xd,yd)
> pts_s<- SpatialPoints(pts)
> projection(pts_s) <- projection(r)
> points(pts_s, col="red", pch=16)
>
> ## Find pixels center of each point
> N_cells <- cellFromXY(r, pts_s)
>
> e <- adjacent(r, N_cells , directions='bishop', id=TRUE, sorted = TRUE)
> xy <- xyFromCell(r, e[,'to'], spatial = TRUE)
>
>
> #Visualization
>
> plot(r)
> points(pts_s, col="red", pch=16)
> points(xy, col="black", pch=16)
> ### END
>
>
>
>
>
> > On May 30, 2018, at 3:11 PM, ASANTOS via R-sig-Geo <
> r-sig-geo at r-project.org> wrote:
> >
> > Dear R-Sig-Geo Members,
> >
> >     I've like to extract xy coordinates from raster of 24 neigborhood
> cells that surround the 4 given points (pts_s) pixels and for this I used:
> >
> > #Packages
> >
> > require(raster)
> > require(sp)
> >
> > ## Create a raster
> > r <- raster(nc=30, nr=30)
> > r <- setValues(r, round(runif(ncell(r))* 255))
> > plot(r)
> >
> > ##Given interesting points coordinates
> > xd     <- c(-24.99270,45.12069,99.40321,73.64419)
> > yd  <- c(-45.435267,-88.369745,-7.086949,44.174530)
> > pts <- data.frame(xd,yd)
> > pts_s<- SpatialPoints(pts)
> > points(pts_s, col="red", pch=16)
> >
> > ## Find pixels center of each point (My idea is not to use the original
> point coordinates, but coordinates of the center of interesting pixel).
> > N_cells <- cellFromXY(r, pts_s)
> >
> >
> > # Extract xy coordinates from raster of 24 neighborhood cells given
> pixel number N_cells
> > e<-adjacent(r, N_cells , directions='bishop', id=TRUE)
> > coordinates(land_mask)[e[,1],] ## Doesn't return 24 neighborhood by
> N_cells object
> > ng_coords<-coordinates(land_mask)[e[,1],]
> > #
> >
> > #Visualization
> >
> > plot(r)
> > points(pts_s, col="red", pch=16)
> > points(ng_coords, col="black", pch=16)
> > ##
> >
> >     But I don't have success because the ng_coords object is not a 24
> neighborhood cells of each point that I search. There are solution for this?
> >
> > Thanks in advance,
> >
> > Alexandre
> >
> > --
> > ======================================================================
> > Alexandre dos Santos
> > Prote??o Florestal
> > IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
> > Campus C?ceres
> > Caixa Postal 244
> > Avenida dos Ramires, s/n
> > Bairro: Distrito Industrial
> > C?ceres - MT                      CEP: 78.200-000
> > Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)
> >
> >        alexandre.santos at cas.ifmt.edu.br
> > Lattes: http://lattes.cnpq.br/1360403201088680
> > OrcID: orcid.org/0000-0001-8232-6722
> > Researchgate: www.researchgate.net/profile/Alexandre_Santos10
> > LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
> > Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> Ecological Forecasting: https://eco.bigelow.org/
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Vijay Lulla, Ph.D.

Assistant Professor,
Dept. of Geography, IUPUI
425 University Blvd, CA-207C.
Indianapolis, IN-46202
vlulla at iupui.edu

<http://vijaylulla.com>
http://vijaylulla.com

	[[alternative HTML version deleted]]


From @lex@ndre@@nto@br @ending from y@hoo@com@br  Wed May 30 23:04:46 2018
From: @lex@ndre@@nto@br @ending from y@hoo@com@br (ASANTOS)
Date: Wed, 30 May 2018 17:04:46 -0400
Subject: [R-sig-Geo] Extract xy coordinates from raster of interesting
 neighborhood cells
In-Reply-To: <CAKkiGbvTHNTAKJdtXPVOxb=TGS=dHn44ugxoELrjH=BxccH91g@mail.gmail.com>
References: <c0859532-3d25-508d-0f86-9dcca368769a@yahoo.com.br>
 <B5250464-3107-4AD4-A7FB-A00B7F4AEFAB@bigelow.org>
 <CAKkiGbvTHNTAKJdtXPVOxb=TGS=dHn44ugxoELrjH=BxccH91g@mail.gmail.com>
Message-ID: <0295ab20-9759-4127-3649-54db60649ee8@yahoo.com.br>

Thanks so much Vijay and Ben, now it works!!!

 ??????????? Originally, I expect 24 for each 4 point (96 total). 
Apologies, in my example preparation I changed the raster objects 
'land_mask' and 'r' and the idea of my second point [45.12069, 
-88.369745] is to force NA results.

 ??????????? The code below is a solution that I expected:

### Alternative to what Ben suggested!
## Set neighborhood matrix.? Focal cell is 0 while neighbors are 1!!
neigh <- matrix(1L, nrow=5, ncol=5); neigh[3,3] <- 0L
e1<-adjacent(r, N_cells , directions=neigh, pairs=FALSE)
ng_coords1 <- xyFromCell(r, e1)
plot(r);
points(pts, col='red', pch=16);
points(ng_coords, col='black', pch=16);
points(ng_coords1, col='blue', pch=16)
### END

-- 
======================================================================
Alexandre dos Santos
Prote??o Florestal
IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
Campus C?ceres
Caixa Postal 244
Avenida dos Ramires, s/n
Bairro: Distrito Industrial
C?ceres - MT                      CEP: 78.200-000
Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)

         alexandre.santos at cas.ifmt.edu.br
Lattes: http://lattes.cnpq.br/1360403201088680
OrcID: orcid.org/0000-0001-8232-6722
Researchgate: www.researchgate.net/profile/Alexandre_Santos10
LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
======================================================================

Em 30/05/2018 16:29, Vijay Lulla escreveu:
> Or you can try something like this?
>
> ### START
> require(raster)
> require(sp)
>
> r <- raster(nc=30, nr=30)
> r <- setValues(r, round(runif(ncell(r))* 255))
>
> xd???? <- c(-24.99270,45.12069,99.40321,73.64419)
> yd? <- c(-45.435267,-88.369745,-7.086949,44.174530)
> pts <- data.frame(xd,yd)
> pts_s<- SpatialPoints(pts)
>
> N_cells <- cellFromXY(r, pts_s)
> e<-adjacent(r, N_cells , directions='bishop', pairs=FALSE)
>
> ng_coords <- xyFromCell(r, e)
> plot(r)
> points(pts, col='red', pch=16)
> points(ng_coords, col='black', pch=16)
>
>
[[elided Yahoo spam]]
[[elided Yahoo spam]]
> neigh <- matrix(1L, nrow=5, ncol=5); neigh[3,3] <- 0L
> e1<-adjacent(r, N_cells , directions=neigh, pairs=FALSE)
> ng_coords1 <- xyFromCell(r, e1)
> plot(r);
> points(pts, col='red', pch=16);
> points(ng_coords, col='black', pch=16);
> points(ng_coords1, col='blue', pch=16)
> ### END
>
> HTH,
> Vijay.
>
> On Wed, May 30, 2018 at 4:22 PM, Ben Tupper <btupper at bigelow.org 
> <mailto:btupper at bigelow.org>> wrote:
>
>     Hi,
>
>     I'm not sure why you expect 24 points - you have 4 locations and
>     for each you want the 4 bishop's directions - so, I think at most
>     you should expect 16 points.? See
>     http://www.lpc.uottawa.ca/publications/moransi/moran.htm
>     <http://www.lpc.uottawa.ca/publications/moransi/moran.htm>
>     <http://www.lpc.uottawa.ca/publications/moransi/moran.htm
>     <http://www.lpc.uottawa.ca/publications/moransi/moran.htm>> for
>     where I expect 4 points for bishop's for each input location;
>     perhaps you have a different idea of bishop's direction?
>
>     Your second point [45.12069, -88.369745] is on to the southern
>     edge of the raster - so it can't find points southward - only the
>     2 northward.
>
>     Finally, it may not make any difference at all, but your pts_s has
>     no coordinate reference.? Below I show where I assign the same
>     projection as your raster.? I also don't have 'land_mask' so I
>     reused 'r' and used xyFromCell to backwards extract the adjacent
>     cell coordinates.
>
>     Does that do the trick for you?
>
>     Cheers,
>     Ben
>
>     ### START
>     require(raster)
>     require(sp)
>
>     ## Create a raster
>     r <- raster(nc=30, nr=30)
>     r <- setValues(r, round(runif(ncell(r))* 255))
>     plot(r)
>
>     ##Given interesting points coordinates
>     xd? ? ?<- c( -24.99270,? ?45.12069,? 99.40321, 73.64419)
>     yd? ? ?<- c(-45.435267, -88.369745, -7.086949, 44.174530)
>     pts <- data.frame(xd,yd)
>     pts_s<- SpatialPoints(pts)
>     projection(pts_s) <- projection(r)
>     points(pts_s, col="red", pch=16)
>
>     ## Find pixels center of each point
>     N_cells <- cellFromXY(r, pts_s)
>
>     e <- adjacent(r, N_cells , directions='bishop', id=TRUE, sorted =
>     TRUE)
>     xy <- xyFromCell(r, e[,'to'], spatial = TRUE)
>
>
>     #Visualization
>
>     plot(r)
>     points(pts_s, col="red", pch=16)
>     points(xy, col="black", pch=16)
>     ### END
>
>
>
>
>
>     > On May 30, 2018, at 3:11 PM, ASANTOS via R-sig-Geo
>     <r-sig-geo at r-project.org <mailto:r-sig-geo at r-project.org>> wrote:
>     >
>     > Dear R-Sig-Geo Members,
>     >
>     >? ? ?I've like to extract xy coordinates from raster of 24
>     neigborhood cells that surround the 4 given points (pts_s) pixels
>     and for this I used:
>     >
>     > #Packages
>     >
>     > require(raster)
>     > require(sp)
>     >
>     > ## Create a raster
>     > r <- raster(nc=30, nr=30)
>     > r <- setValues(r, round(runif(ncell(r))* 255))
>     > plot(r)
>     >
>     > ##Given interesting points coordinates
>     > xd? ? ?<- c(-24.99270,45.12069,99.40321,73.64419)
>     > yd? <- c(-45.435267,-88.369745,-7.086949,44.174530)
>     > pts <- data.frame(xd,yd)
>     > pts_s<- SpatialPoints(pts)
>     > points(pts_s, col="red", pch=16)
>     >
>     > ## Find pixels center of each point (My idea is not to use the
>     original point coordinates, but coordinates of the center of
>     interesting pixel).
>     > N_cells <- cellFromXY(r, pts_s)
>     >
>     >
>     > # Extract xy coordinates from raster of 24 neighborhood cells
>     given pixel number N_cells
>     > e<-adjacent(r, N_cells , directions='bishop', id=TRUE)
>     > coordinates(land_mask)[e[,1],] ## Doesn't return 24 neighborhood
>     by N_cells object
>     > ng_coords<-coordinates(land_mask)[e[,1],]
>     > #
>     >
>     > #Visualization
>     >
>     > plot(r)
>     > points(pts_s, col="red", pch=16)
>     > points(ng_coords, col="black", pch=16)
>     > ##
>     >
>     >? ? ?But I don't have success because the ng_coords object is not
>     a 24 neighborhood cells of each point that I search. There are
>     solution for this?
>     >
>     > Thanks in advance,
>     >
>     > Alexandre
>     >
>     > --
>     >
>     ======================================================================
>     > Alexandre dos Santos
>     > Prote??o Florestal
>     > IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de
>     Mato Grosso
>     > Campus C?ceres
>     > Caixa Postal 244
>     > Avenida dos Ramires, s/n
>     > Bairro: Distrito Industrial
>     > C?ceres - MT? ? ? ? ? ? ? ? ? ? ? CEP: 78.200-000
>     > Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)
>     >
>     > alexandre.santos at cas.ifmt.edu.br
>     <mailto:alexandre.santos at cas.ifmt.edu.br>
>     > Lattes: http://lattes.cnpq.br/1360403201088680
>     <http://lattes.cnpq.br/1360403201088680>
>     > OrcID: orcid.org/0000-0001-8232-6722
>     <http://orcid.org/0000-0001-8232-6722>
>     > Researchgate: www.researchgate.net/profile/Alexandre_Santos10
>     <http://www.researchgate.net/profile/Alexandre_Santos10>
>     > LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
>     <http://br.linkedin.com/in/alexandre-dos-santos-87961635>
>     > Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
>     <http://www.mendeley.com/profiles/alexandre-dos-santos6/>
>     >
>     > _______________________________________________
>     > R-sig-Geo mailing list
>     > R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>     >
>
>     Ben Tupper
>     Bigelow Laboratory for Ocean Sciences
>     60 Bigelow Drive, P.O. Box 380
>     East Boothbay, Maine 04544
>     http://www.bigelow.org
>
>     Ecological Forecasting: https://eco.bigelow.org/
>
>
>
>
>
>
>     ? ? ? ? [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-Geo mailing list
>     R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>
>
>
>
> -- 
> Vijay Lulla, Ph.D.
>
> Assistant Professor,
> Dept. of Geography, IUPUI
> 425 University Blvd, CA-207C.
> Indianapolis, IN-46202
> vlulla at iupui.edu <mailto:vlulla at iupui.edu>
>
> <http://vijaylulla.com>
> http://vijaylulla.com


	[[alternative HTML version deleted]]


From K@therine@B@nn@r-M@rtin @ending from dfo-mpo@gc@c@  Thu May 31 00:12:03 2018
From: K@therine@B@nn@r-M@rtin @ending from dfo-mpo@gc@c@ (Bannar-Martin, Katherine)
Date: Wed, 30 May 2018 22:12:03 +0000
Subject: [R-sig-Geo] polygon over or intersect with more than 2 files/layers
Message-ID: <C58761628CE59340834AA8638074761A28B21B@DFBCV6CWPEXP001.ENT.dfo-mpo.ca>

Hi,

I've had no success at finding a tool in an R package that can calculate the intersection/overlap of polygons for more than 2 layers.

e.g. plot(st_intersection(st_union(LateYear2008),st_union(LateYear2009),st_union(LateYear2010),st_union(LateYear2011),st_union(LateYear2012),
st_union(LateYear2013),st_union(LateYear2014),st_union(LateYear2015),st_union(LateYear2016),st_union(LateYear2017)),
col = 'red',xlim=c(min(d$x),max(d$x)),ylim=c(min(d$y),max(d$y)),axes = TRUE)
does NOT work.

Does anyone have any suggestions? Is there a way to save a shapefile with multiple layers of polygons and then run an over/intersection tool.

I can run each pair-wise overlap between layers in a loop but the number of combinations is long.

Efficient solutions welcomed.

Thanks!
Katherine

	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Thu May 31 10:47:27 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Thu, 31 May 2018 10:47:27 +0200
Subject: [R-sig-Geo] 
 polygon over or intersect with more than 2 files/layers
In-Reply-To: <C58761628CE59340834AA8638074761A28B21B@DFBCV6CWPEXP001.ENT.dfo-mpo.ca>
References: <C58761628CE59340834AA8638074761A28B21B@DFBCV6CWPEXP001.ENT.dfo-mpo.ca>
Message-ID: <alpine.LFD.2.21.1805311035010.7126@reclus.nhh.no>

On Thu, 31 May 2018, Bannar-Martin, Katherine wrote:

> Hi,
>
> I've had no success at finding a tool in an R package that can calculate 
> the intersection/overlap of polygons for more than 2 layers.
>
> e.g. 
> plot(st_intersection(st_union(LateYear2008),st_union(LateYear2009),st_union(LateYear2010),st_union(LateYear2011),st_union(LateYear2012), 
> st_union(LateYear2013),st_union(LateYear2014),st_union(LateYear2015),st_union(LateYear2016),st_union(LateYear2017)), 
> col = 'red',xlim=c(min(d$x),max(d$x)),ylim=c(min(d$y),max(d$y)),axes = 
> TRUE) does NOT work.

Why would you think it might, given that the help page only shows pairs of 
objects? The underlying code in GEOS is for binary operations. GRASS also 
handles binary overlay, and the same applies to PostGIS.

It might be possible to work out intersection candidates by building trees 
of envelopes and querying multiple layers based on non-zero envelope 
intersection, but

>
> Does anyone have any suggestions? Is there a way to save a shapefile 
> with multiple layers of polygons and then run an over/intersection tool.
>

No, a "shapefile" has one layer only, unless you want a folder with 
multiple shapefiles. GPKG can take multiple layers, but it isn't obvious 
why this would help.

> I can run each pair-wise overlap between layers in a loop but the number 
> of combinations is long.

Obviously. If you have to have vector, you have to do this pairwise. If 
raster is an option, probably there are many more possibilities; GRASS 
r.cross takes multiple raster layers for example.

>
> Efficient solutions welcomed.

  ... and code contributions ??

Roger

>
> Thanks!
> Katherine
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


