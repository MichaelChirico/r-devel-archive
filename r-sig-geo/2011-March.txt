From macqueen1 at llnl.gov  Tue Mar  1 01:12:18 2011
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 28 Feb 2011 16:12:18 -0800
Subject: [R-sig-Geo] cropping in raster package loses color table?
Message-ID: <C99179E2.668C%macqueen1@llnl.gov>

The colortable is apparently not preserved when using crop() from the
raster package. This is something I would find useful.

I'm only just beginning to learn how to use the raster package, so perhaps
there's another way to subset a raster image that preserves the
colortable? Or I'm making some mistake?

(also, is there a better way to set the colortable?)

There is a reproducible example below.

Thanks
-Don


## based on the example in ?crop
r <- raster(nrow=45, ncol=90)
r[] <- sample(1:10,ncell(r),replace=TRUE)
r at legend@colortable <-c("#476BA1","#D1DEFA","#DECACA","#D99482","#EE0000",
      "#AB0000","#B3AEA3","#68AB63","#1C6330","#B5CA8F")

e <- extent(-160, 10, 30, 60)
rc <- crop(r, e)

cat('original colortable\n')
str(r at legend)
cat('\ncropped colortable\n')
str(rc at legend)

With output:

original colortable
Formal class 'RasterLegend' [package "raster"] with 4 slots
  ..@ type      : chr(0)
  ..@ values    : NULL
  ..@ color     : NULL
  ..@ colortable: chr [1:10] "#476BA1" "#D1DEFA" "#DECACA" "#D99482" ...

cropped colortable
Formal class 'RasterLegend' [package "raster"] with 4 slots
  ..@ type      : chr(0)
  ..@ values    : NULL
  ..@ color     : NULL
  ..@ colortable: NULL




> sessionInfo()
R version 2.12.2 (2011-02-25)
Platform: i386-apple-darwin9.8.0/i386 (32-bit)

locale:
[1] C

attached base packages:
[1] graphics  grDevices utils     datasets  stats     methods   base

other attached packages:
[1] raster_1.7-46   rgdal_0.6-33    maptools_0.7-38 lattice_0.19-17
sp_0.9-77       foreign_0.8-42

loaded via a namespace (and not attached):
[1] grid_2.12.2


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


From r.hijmans at gmail.com  Tue Mar  1 01:17:02 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Mon, 28 Feb 2011 16:17:02 -0800
Subject: [R-sig-Geo] cropping in raster package loses color table?
In-Reply-To: <C99179E2.668C%macqueen1@llnl.gov>
References: <C99179E2.668C%macqueen1@llnl.gov>
Message-ID: <1298938622296-6075542.post@n2.nabble.com>

Don,

> The colortable is apparently not preserved when using crop() from the 
> raster package. This is something I would find useful. 

I agree. Color table support is relatively recent and it is ignored by most
functions (and hence lost when using crop). That needs improvement.

> (also, is there a better way to set the colortable?) 

No, there are no functions for that yet. So you'll have to do that by hand.

Thanks for pointing this out.

Robert

-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/cropping-in-raster-package-loses-color-table-tp6075534p6075542.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From arnold_salvacion at yahoo.com  Tue Mar  1 03:45:36 2011
From: arnold_salvacion at yahoo.com (Arnold Salvacion)
Date: Tue, 1 Mar 2011 10:45:36 +0800 (SGT)
Subject: [R-sig-Geo] converting lat long points to UTM
Message-ID: <204283.93992.qm@web78205.mail.sg1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110301/84b0165c/attachment.pl>

From mdsumner at gmail.com  Tue Mar  1 03:54:31 2011
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 1 Mar 2011 13:54:31 +1100
Subject: [R-sig-Geo] converting lat long points to UTM
In-Reply-To: <204283.93992.qm@web78205.mail.sg1.yahoo.com>
References: <204283.93992.qm@web78205.mail.sg1.yahoo.com>
Message-ID: <AANLkTikUQRVZvLHueCVBr=7HgScTLzB0atkNeu+ahodE@mail.gmail.com>

The rgdal package has the project() function for direct conversion
to/from longlat (WGS84) - via the PROJ.4 library, via GDAL - all
embedded in the package.

library(rgdal)
xy <- cbind(c(118, 119), c(10, 50))
project(xy, "+proj=utm +zone=51 ellps=WGS84")
          [,1]    [,2]
[1,] -48636.65 1109577
[2,] 213372.05 5546301

Be aware that that is a very minimal "PROJ.4" string (metres is
assumed), and that "+proj=longlat +ellps=WGS84" is the assumed base
coordinate system.

FYI, in sp, there is spTransform() which can wrap the required
back-projection and perform reprojections for more complicated data
sets.

See ?project and ?spTransform

Cheers, Mike.

On Tue, Mar 1, 2011 at 1:45 PM, Arnold Salvacion
<arnold_salvacion at yahoo.com> wrote:
> Dear?Colleagues,
> Good day!
> I have a data points collected using GPS..It was on latitude and longitude coordinate system ..I wonder if there's any function in R where I could convert those GPS data points to UTM (e.g. UTM Zone 51N)?
> Thanks in advance
> Arnold
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>



-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


From mdsumner at gmail.com  Tue Mar  1 04:28:40 2011
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 1 Mar 2011 14:28:40 +1100
Subject: [R-sig-Geo] converting lat long points to UTM
In-Reply-To: <223218.51502.qm@web78206.mail.sg1.yahoo.com>
References: <AANLkTikUQRVZvLHueCVBr=7HgScTLzB0atkNeu+ahodE@mail.gmail.com>
	<223218.51502.qm@web78206.mail.sg1.yahoo.com>
Message-ID: <AANLkTik05HXTc571MbQZfp+NDdOoao62p4Zh33U_76wK@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110301/583ff99b/attachment.pl>

From edzer.pebesma at uni-muenster.de  Tue Mar  1 08:59:14 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 1 Mar 2011 08:59:14 +0100
Subject: [R-sig-Geo] UseR! submission dealine for abstracts 2011-04-01
Message-ID: <4D6CA752.2020108@uni-muenster.de>

Dear all,

please note that 2011-04-01 is the submission deadline for abstracts for
the UseR! conference in Warwick, Aug 16-18. One of the topics of the
conference is Spatial Statistics.

http://www.warwick.ac.uk/statsdept/useR-2011/

The conference has an interesting tutorial program (Aug 15):

http://www.warwick.ac.uk/statsdept/useR-2011/tutorials/index.html

which includes a tutorial organized by Roger Bivand and me (and given by
Roger) on "Handling and Analyzing Spatio-temporal Data in R".

Best wishes,
-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From hacke78 at googlemail.com  Tue Mar  1 09:34:21 2011
From: hacke78 at googlemail.com (Jan Hackenberg)
Date: Tue, 1 Mar 2011 09:34:21 +0100
Subject: [R-sig-Geo] converting lat long points to UTM
In-Reply-To: <204283.93992.qm@web78205.mail.sg1.yahoo.com>
References: <204283.93992.qm@web78205.mail.sg1.yahoo.com>
Message-ID: <AANLkTinYWdhFg8AhoaYLAQD-DcexebHbQbnKLWGn9uh2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110301/38c79fb9/attachment.pl>

From mathieu.rajerison at gmail.com  Tue Mar  1 11:25:52 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Tue, 1 Mar 2011 11:25:52 +0100
Subject: [R-sig-Geo] overlay raster by polygons: average values
Message-ID: <AANLkTimqykozhc_xs5zFqVHNjebTV+auYz73dE95EjKA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110301/f3aaf36b/attachment.pl>

From rahulosho at gmail.com  Tue Mar  1 13:22:25 2011
From: rahulosho at gmail.com (Rahul Raj)
Date: Tue, 1 Mar 2011 17:52:25 +0530
Subject: [R-sig-Geo] Help on extracting min/max from raster object
Message-ID: <AANLkTikTSrR3+ooSvuHkjTiSr=a2KPBgJ2AWRHhV7ySd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110301/73b24c92/attachment.pl>

From roman.lustrik at gmail.com  Tue Mar  1 14:18:01 2011
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Tue, 1 Mar 2011 14:18:01 +0100
Subject: [R-sig-Geo] Help on extracting min/max from raster object
In-Reply-To: <AANLkTikTSrR3+ooSvuHkjTiSr=a2KPBgJ2AWRHhV7ySd@mail.gmail.com>
References: <AANLkTikTSrR3+ooSvuHkjTiSr=a2KPBgJ2AWRHhV7ySd@mail.gmail.com>
Message-ID: <AANLkTi=R69O5VW9bhV9-NQK0ZZJJAYmCWVuLwPZKsqPn@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110301/50293225/attachment.pl>

From lestes at princeton.edu  Tue Mar  1 15:02:38 2011
From: lestes at princeton.edu (Lyndon Estes)
Date: Tue, 1 Mar 2011 09:02:38 -0500
Subject: [R-sig-Geo] Help on extracting min/max from raster object
In-Reply-To: <AANLkTikTSrR3+ooSvuHkjTiSr=a2KPBgJ2AWRHhV7ySd@mail.gmail.com>
References: <AANLkTikTSrR3+ooSvuHkjTiSr=a2KPBgJ2AWRHhV7ySd@mail.gmail.com>
Message-ID: <AANLkTi=X3+4F4z7FHszb7ZQENLVcbeHOomgW_=8EFGy3@mail.gmail.com>

If there is not some sort of rounding issue going on with cellStats, I
wonder if perhaps your no data areas are 0 for some reason (although
your raster details suggest not).

Perhaps you could try the following:

r2 <- (r > 0) / (r > 0) * r  # Sets areas of 0 values to NA

Then try cellstats again
cellStats(r2, min)

And see if you have the correct min value.

Cheers, Lyndon








On Tue, Mar 1, 2011 at 7:22 AM, Rahul Raj <rahulosho at gmail.com> wrote:
>
> Dear All
>
> I have imported .img file in R using raster package as
>
> ?r <- raster(inputfile)
>
> Summary:
>
> > r
> class ? ? ? : RasterLayer
> dimensions ?: 1131, 1739, 1 ?(nrow, ncol, nlayers)
> resolution ?: 1000, 1000 ?(x, y)
> extent ? ? ?: 535515, 2274515, 2003813, 3134813 ?(xmin, xmax, ymin, ymax)
> projection ?: +proj=aea +lat_1=28 +lat_2=12 +lat_0=20 +lon_0=78 +x_0=2000000
> +y_0=2000000 +ellps=WGS84 +datum=WGS84 +units=m +no_defs +towgs84=0,0,0
> values ? ? ?: H:\filename.img
> min value ? :* 0.001407638 *
> max value ? : 0.7978822
>
> I wanted to extract the min value and max value from the object. How can I
> do this?
> I have used the following function for this purpose
> > cellStats(r,'min')
> [1] 0
>
> But it is returning 0, not "0.001407638"
>
> Kindly help me.
>
> With regards
> Rahul Raj
> Indian Institute of Remote Sensing, India
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



--
Lyndon Estes
Research Associate
Woodrow Wilson School
Princeton University
+1-609-258-2392 (o)
+1-609-258-6082 (f)
+1-202-431-0496 (m)
lestes at princeton.edu


From jacobvanetten at yahoo.com  Tue Mar  1 15:28:20 2011
From: jacobvanetten at yahoo.com (Jacob van Etten)
Date: Tue, 1 Mar 2011 14:28:20 +0000 (GMT)
Subject: [R-sig-Geo] Help on extracting min/max from raster object
In-Reply-To: <AANLkTi=R69O5VW9bhV9-NQK0ZZJJAYmCWVuLwPZKsqPn@mail.gmail.com>
Message-ID: <697657.78535.qm@web29717.mail.ird.yahoo.com>

Ideally, extract values using extractor functions only.

In this case:

minValue(r)

Jacob.

--- On Tue, 1/3/11, Roman Lu?trik <roman.lustrik at gmail.com> wrote:

> From: Roman Lu?trik <roman.lustrik at gmail.com>
> Subject: Re: [R-sig-Geo] Help on extracting min/max from raster object
> To: "Rahul Raj" <rahulosho at gmail.com>
> Cc: r-sig-geo at r-project.org
> Date: Tuesday, 1 March, 2011, 14:18
> Doing it the non-pretty way is
> 
> r at data@min
> r at data@max
> 
> (see str(r))
> 
> Cheers,
> Roman
> 
> 
> 
> On Tue, Mar 1, 2011 at 1:22 PM, Rahul Raj <rahulosho at gmail.com>
> wrote:
> 
> > Dear All
> >
> > I have imported .img file in R using raster package
> as
> >
> >? r <- raster(inputfile)
> >
> > Summary:
> >
> > > r
> > class? ? ???: RasterLayer
> > dimensions? : 1131, 1739, 1? (nrow, ncol,
> nlayers)
> > resolution? : 1000, 1000? (x, y)
> > extent? ? ? : 535515, 2274515, 2003813,
> 3134813? (xmin, xmax, ymin, ymax)
> > projection? : +proj=aea +lat_1=28 +lat_2=12
> +lat_0=20 +lon_0=78
> > +x_0=2000000
> > +y_0=2000000 +ellps=WGS84 +datum=WGS84 +units=m
> +no_defs +towgs84=0,0,0
> > values? ? ? : H:\filename.img
> > min value???:* 0.001407638 *
> > max value???: 0.7978822
> >
> > I wanted to extract the min value and max value from
> the object. How can I
> > do this?
> > I have used the following function for this purpose
> > > cellStats(r,'min')
> > [1] 0
> >
> > But it is returning 0, not "0.001407638"
> >
> > Kindly help me.
> >
> > With regards
> > Rahul Raj
> > Indian Institute of Remote Sensing, India
> >
> >? ? ? ? [[alternative HTML version
> deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> 
> 
> 
> -- 
> In God we trust, all others bring data.
> 
> ??? [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 





From hzambran.newsgroups at gmail.com  Tue Mar  1 15:35:43 2011
From: hzambran.newsgroups at gmail.com (Mauricio Zambrano)
Date: Tue, 1 Mar 2011 15:35:43 +0100
Subject: [R-sig-Geo] converting lat long points to UTM
In-Reply-To: <204283.93992.qm@web78205.mail.sg1.yahoo.com>
References: <204283.93992.qm@web78205.mail.sg1.yahoo.com>
Message-ID: <AANLkTinc3nrruuR6MiMieQHzSYh5QrUGgrZBJ0SR9p9O@mail.gmail.com>

if you want to use Lat/Long data, you may also try the 'project'
function in the 'proj4' package:

     library(proj4)

     ## this is just very simple, because we don't want to depend on
     ## maps package, so we can't show more useful stuff..

     data(state)

     s <- project(state.center, "+proj=merc", degrees=TRUE)

     plot(s, type='n', asp=1)
     text(s,, state.abb)

(taken from '?project')

Kinds,

Mauricio

-- 
================================
Linux user #454569 -- Ubuntu user #17469
================================


2011/3/1 Arnold Salvacion <arnold_salvacion at yahoo.com>:
> Dear?Colleagues,
> Good day!
> I have a data points collected using GPS..It was on latitude and longitude coordinate system ..I wonder if there's any function in R where I could convert those GPS data points to UTM (e.g. UTM Zone 51N)?
> Thanks in advance
> Arnold
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From sadz_a1000 at yahoo.co.uk  Tue Mar  1 15:59:07 2011
From: sadz_a1000 at yahoo.co.uk (Sadz A)
Date: Tue, 1 Mar 2011 14:59:07 +0000 (GMT)
Subject: [R-sig-Geo] predict a map from point data
In-Reply-To: <4D6B6DC5.6010401@wzw.tum.de>
References: <63848.55332.qm@web24603.mail.ird.yahoo.com>
	<4D6B6DC5.6010401@wzw.tum.de>
Message-ID: <398708.97960.qm@web24603.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110301/1f097b37/attachment.pl>

From ldecola at comcast.net  Tue Mar  1 16:00:34 2011
From: ldecola at comcast.net (ldecola at comcast.net)
Date: Tue, 1 Mar 2011 15:00:34 +0000 (UTC)
Subject: [R-sig-Geo] rendering jpg in color
In-Reply-To: <1477913419.1588406.1298991526793.JavaMail.root@sz0030a.westchester.pa.mail.comcast.net>
Message-ID: <1725477171.1588546.1298991634476.JavaMail.root@sz0030a.westchester.pa.mail.comcast.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110301/24ee9afa/attachment.pl>

From tom.gottfried at wzw.tum.de  Tue Mar  1 16:51:13 2011
From: tom.gottfried at wzw.tum.de (Tom Gottfried)
Date: Tue, 01 Mar 2011 16:51:13 +0100
Subject: [R-sig-Geo] predict a map from point data
In-Reply-To: <398708.97960.qm@web24603.mail.ird.yahoo.com>
References: <63848.55332.qm@web24603.mail.ird.yahoo.com>
	<4D6B6DC5.6010401@wzw.tum.de>
	<398708.97960.qm@web24603.mail.ird.yahoo.com>
Message-ID: <4D6D15F1.4060600@wzw.tum.de>

Hi Sadz,

Am 01.03.2011 15:59, schrieb Sadz A:
> Hi Tom, 
> 
> For the krigging I used variogram and modelling through arcGIS. the
> predictions are bad in the sense that If predictions are plotted against
> real data (where you would get a 1:1 line if it was a perfect model) I
> get strait horizontal line. 
> 
> (what is 'a Gau?ian model and doing block kriging', and how does it
> work/differ from the Arcgis approach (which was called ordinary
> krigging)?

You can consult any textbook on geostatistic to learn about it (e.g. Goovaerts, 1997. Geostatistics
for Natural Resources Evaluation). For R-specific things the ASDAR-book (Bivand et al., 2008,
Applied Spatial Data Analysis with R) is appropriate.

> I think the problem with using the krigging is that it
> assumes that things that are closer are more alike, 

... respectively more "similar". Depending on the semivariogram-model, this is often assumed.

> but with the volume
> this does not necessarily seem to hold true...

Thinking of steres of wood standing on a unit area, I would intuitively suggest that it does hold
true. But this is beyond my (and probably the lists) scope.

regards,
Tom

> no idea how to get around this.
> 
> Thank you for your response
> sadz
> 
>   
> 
> ------------------------------------------------------------------------
> *From:* Tom Gottfried <tom.gottfried at wzw.tum.de>
> *To:* r-sig-geo at r-project.org
> *Sent:* Mon, 28 February, 2011 9:41:25
> *Subject:* Re: [R-sig-Geo] predict a map from point data
> 
> Hi Sadz,
> 
> Am 28.02.2011 01:54, schrieb Sadz A:
>> Hi,
>>
>> I'm trying to predict the distribution of timber over an area, I have
> point
>> location data- so it would make sense to use a krigging to interpolate
> the data
>> over the whole map. Unfortunately the krigging predictions are pretty
> bad.
> 
> What does "pretty bad" mean? What did you actually do? There are many
> "flavours" of doing kriging
> including variogram estimation and modelling. E.g. you seem to
> interpolate volume data, so I suppose
> your "point location data" actually represent a volume too. Sounds like
> fitting a Gau?ian model and
> doing block kriging could be appropriate.
> 
>>
>> I have now got environmental data for my study site and have used the
> r package
>> 'quantreg' to make a model that I can predict the volume from
>> R code:
>> fit <- rqss(sum_vol~qss(env.factor1,lambda=1)+
> qss(env.factor2,lambda=1), tau =
>> 0.9)
>> predi<-predict(fit, new, interval = "none", level = 0.9)
> 
> Do you mean you have any covariates? Maybe multivariable geostatistics
> (the gstat package) are your
> friend.
> 
>>
>> unfortunately this is not working either (a problem with the predict
> function).
>> I have also tried linear modelling, Gams and inverse interpolations.
> 
> Any errors, traceback()?
> 
> regards,
> Tom
> 
>>
>> Does anyone have any ideas on how I could get a spatial map of volume
>> distribution from the point data?
>>
>> Any help is appreciated,
>> thank you
>> sadz
>>
>> ps- if anything is unclear I would be happy to clarify
>>
>>
>>
>>     
>>     [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> -- 
> Technische Universit?t M?nchen
> Department f?r Pflanzenwissenschaften
> Lehrstuhl f?r Gr?nlandlehre
> Alte Akademie 12
> 85350 Freising / Germany
> Phone: ++49 (0)8161 715324
> Fax:  ++49 (0)8161 713243
> email: tom.gottfried at wzw.tum.de <mailto:tom.gottfried at wzw.tum.de>
> http://www.wzw.tum.de/gruenland
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Technische Universit?t M?nchen
Department f?r Pflanzenwissenschaften
Lehrstuhl f?r Gr?nlandlehre
Alte Akademie 12
85350 Freising / Germany
Phone: ++49 (0)8161 715324
Fax:   ++49 (0)8161 713243
email: tom.gottfried at wzw.tum.de
http://www.wzw.tum.de/gruenland


From rahulosho at gmail.com  Tue Mar  1 17:05:00 2011
From: rahulosho at gmail.com (Rahul Raj)
Date: Tue, 1 Mar 2011 21:35:00 +0530
Subject: [R-sig-Geo] Help on extracting min/max from raster object
In-Reply-To: <697657.78535.qm@web29717.mail.ird.yahoo.com>
References: <AANLkTi=R69O5VW9bhV9-NQK0ZZJJAYmCWVuLwPZKsqPn@mail.gmail.com>
	<697657.78535.qm@web29717.mail.ird.yahoo.com>
Message-ID: <AANLkTin_XfaCe+ZfazsGYis67HCVgbiznx4Wo1hWH3_p@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110301/36b6f4a6/attachment.pl>

From r.hijmans at gmail.com  Tue Mar  1 17:55:01 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Tue, 1 Mar 2011 08:55:01 -0800
Subject: [R-sig-Geo] Help on extracting min/max from raster object
In-Reply-To: <AANLkTin_XfaCe+ZfazsGYis67HCVgbiznx4Wo1hWH3_p@mail.gmail.com>
References: <AANLkTikTSrR3+ooSvuHkjTiSr=a2KPBgJ2AWRHhV7ySd@mail.gmail.com>
	<AANLkTi=R69O5VW9bhV9-NQK0ZZJJAYmCWVuLwPZKsqPn@mail.gmail.com>
	<697657.78535.qm@web29717.mail.ird.yahoo.com>
	<AANLkTin_XfaCe+ZfazsGYis67HCVgbiznx4Wo1hWH3_p@mail.gmail.com>
Message-ID: <1298998501231-6077904.post@n2.nabble.com>

Rahul,

> > > I wanted to extract the min value and max value from 
> > the object. How can I 
> > > do this? 
> > > I have used the following function for this purpose 
> > > > cellStats(r,'min') 
> > > [1] 0 
> > > 
> > > But it is returning 0, not "0.001407638" 

The combination of 

minValue(r)
[1] 0.001407638
> cellStats(r, min) 
[1] 0 

Suggests to me that the minimum value reported by the file is incorrect. 

You may first want to do:

r <- setMinMax(r)
# this should be TRUE
minValue(r) == cellStats(r, min)

Robert

-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Help-on-extracting-min-max-from-raster-object-tp6077015p6077904.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From er.rutishauser at gmail.com  Tue Mar  1 18:17:07 2011
From: er.rutishauser at gmail.com (Ervan Rutishauser)
Date: Tue, 1 Mar 2011 18:17:07 +0100
Subject: [R-sig-Geo] Changing projection of a shapefile
Message-ID: <AANLkTintCesZtAPBt=ugxKH4Byn83xn7=NOnsUwZz5gA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110301/302cf09d/attachment.pl>

From s.cavazzi at cranfield.ac.uk  Tue Mar  1 22:50:57 2011
From: s.cavazzi at cranfield.ac.uk (Cavazzi, Stefano)
Date: Tue, 1 Mar 2011 21:50:57 +0000
Subject: [R-sig-Geo] -1.#IND00
Message-ID: <6E3C09D338C1BB46AD3778BB99012D600606A3E352@CCEXCHSTORE-2.central.cranfield.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110301/416e5f6b/attachment.pl>

From s.cavazzi at cranfield.ac.uk  Tue Mar  1 22:58:21 2011
From: s.cavazzi at cranfield.ac.uk (Cavazzi, Stefano)
Date: Tue, 1 Mar 2011 21:58:21 +0000
Subject: [R-sig-Geo] -1.#IND00 problem
Message-ID: <6E3C09D338C1BB46AD3778BB99012D600606A3E356@CCEXCHSTORE-2.central.cranfield.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110301/9e7d32f9/attachment.pl>

From a.lechner at uq.edu.au  Wed Mar  2 07:21:23 2011
From: a.lechner at uq.edu.au (Alex Lechner)
Date: Wed, 2 Mar 2011 16:21:23 +1000
Subject: [R-sig-Geo] Co-kriging
Message-ID: <C56C8DBD00D5B04A820E30A21E6A573604909F0927@UQEXMB04.soe.uq.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110302/ac4ed5fc/attachment.pl>

From edzer.pebesma at uni-muenster.de  Wed Mar  2 08:12:31 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 02 Mar 2011 08:12:31 +0100
Subject: [R-sig-Geo] Co-kriging
In-Reply-To: <C56C8DBD00D5B04A820E30A21E6A573604909F0927@UQEXMB04.soe.uq.edu.au>
References: <C56C8DBD00D5B04A820E30A21E6A573604909F0927@UQEXMB04.soe.uq.edu.au>
Message-ID: <4D6DEDDF.1080209@uni-muenster.de>



On 03/02/2011 07:21 AM, Alex Lechner wrote:
> Hi,
> 
> This might be an easy question for many of you.
> 
> In the literature on co-kriging I have noticed that co-kriging is often used when the  co-variable is more abundant than the target variable. Is this an assumption that must be met when conducting co-kriging?

No.

However, if the interest is in the primary variable, one or more
secondary variables that are not sampled more densely than the primary
variable improve the prediction usually very little, when compared to
ordinary kriging.

When one uses cokriging because one is interested in multivariable
prediction, meaning that not only the predictions and prediction errors
of all p variables are of interest, but also their prediction error
covariances, cokriging is needed anyhow, irrespective differences in
abundance.

> Regards,
> Alex Lechner
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From r.hijmans at gmail.com  Wed Mar  2 08:41:20 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Tue, 1 Mar 2011 23:41:20 -0800
Subject: [R-sig-Geo] overlay raster by polygons: average values
In-Reply-To: <AANLkTimqykozhc_xs5zFqVHNjebTV+auYz73dE95EjKA@mail.gmail.com>
References: <AANLkTimqykozhc_xs5zFqVHNjebTV+auYz73dE95EjKA@mail.gmail.com>
Message-ID: <1299051680590-6079949.post@n2.nabble.com>

>I've got a SpatialGridDataFrame SG with density values given by spatstat 
>package 
>I want to get the average values of this grid for each polygon of a dataset 
>named iris 

Mathieu,  

I think you can do this:

library(raster)
#make a RasterLayer
r <- raster(SG)
# extract mean values for polygons in iris.b
v <- extract(r, iris.b, fun=mean)
# assign these to a new variable
iris.b$newvalues <- v

I think you can also accomplish this with %over% (sp package) in stead of
extract

Robert

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/overlay-raster-by-polygons-average-values-tp6076739p6079949.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From b.rowlingson at lancaster.ac.uk  Wed Mar  2 10:21:11 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 2 Mar 2011 09:21:11 +0000
Subject: [R-sig-Geo] Changing projection of a shapefile
In-Reply-To: <AANLkTintCesZtAPBt=ugxKH4Byn83xn7=NOnsUwZz5gA@mail.gmail.com>
References: <AANLkTintCesZtAPBt=ugxKH4Byn83xn7=NOnsUwZz5gA@mail.gmail.com>
Message-ID: <AANLkTi=Fdrju7v1N8mr0AufePeufVmvEuMP4uz8+O213@mail.gmail.com>

On Tue, Mar 1, 2011 at 5:17 PM, Ervan Rutishauser
<er.rutishauser at gmail.com> wrote:
> Dear R-user,
>
> I would like to change the projection of a shapefile using R, but can't get
> it.
> I know that the shapefile is projected in CSG67 (French Guiana) ( see :
> http://spatialreference.org/ref/epsg/4623/ ), but seems not to be defined in
> the shapefile.
> I would like to change this projection in WSG84 N22.
> Here is what I did:
>
>> gap<-readShapePoly("Donnees/Paracou_PT/ArcView_export/Gaps 2000 Topo
> FM.shp")
>> proj4string(gap)
> [1] NA
>> proj4string(gap)<-CRS("+init=epsg:4623")
> Erreur dans `proj4string<-`(`*tmp*`, value = <S4 object of class "CRS">) :
> ?Geographical CRS given to non-conformant data
>> proj4string(gap)<-CRS("+proj=longlat +ellps=intl
> +towgs84=-186,230,110,0,0,0,0 +units=m")
> Erreur dans `proj4string<-`(`*tmp*`, value = <S4 object of class "CRS">) :
> ?Geographical CRS given to non-conformant data
>

 This could be because your data is outside the valid range for the
CRS you are trying to apply. Here is an example where I get the same
error by giving a lat-long value that is outside +-90 and +-180, and
try to apply epsg:4326 (WGS84 lat-long coords):

> d=data.frame(x=200,y=900,z=1)
> coordinates(d)=~x+y
> proj4string(d)=CRS("+init=epsg:4326")
Error in `proj4string<-`(`*tmp*`, value = <S4 object of class "CRS">) :
  Geographical CRS given to non-conformant data

Try with values that are valid lat-long:

 > d=data.frame(x=20,y=9,z=1)
 > coordinates(d)=~x+y
 > proj4string(d)=CRS("+init=epsg:4326")

So whats the 'bbox(gap)' and is it valid for that CRS?


Barry


From hacke78 at googlemail.com  Wed Mar  2 14:14:29 2011
From: hacke78 at googlemail.com (Jan Hackenberg)
Date: Wed, 2 Mar 2011 14:14:29 +0100
Subject: [R-sig-Geo] Missing values with lm
Message-ID: <AANLkTi=J+ES38L00+AB2QJCxtv3JdWbdEQMDWm+yT1hX@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110302/9733c074/attachment.pl>

From hengl at spatial-analyst.net  Wed Mar  2 17:33:56 2011
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Wed, 02 Mar 2011 17:33:56 +0100
Subject: [R-sig-Geo] -1.#IND00 problem
In-Reply-To: <6E3C09D338C1BB46AD3778BB99012D600606A3E356@CCEXCHSTORE-2.central.cranfield.ac.uk>
References: <6E3C09D338C1BB46AD3778BB99012D600606A3E356@CCEXCHSTORE-2.central.cranfield.ac.uk>
Message-ID: <4D6E7174.5030909@spatial-analyst.net>


Op 1-3-2011 22:58, Cavazzi, Stefano schreef:
> All,
>
> I'm having problems extracting some land surface parameters with
> RSAGA. Somehow I get a weird code "-1.#IND00" instead of numbers.
>
> rsaga.geoprocessor("ta_morphometry",14,list(DEM=paste("Area1.sgrd",sep=""),
> HO=paste("Area1_slopeH.sgrd",sep=""),
> HU=paste("Area1_valleyD.sgrd",sep=""), W=0.5, T=10.0, E=2.0))
> rsaga.sgrd.to.esri(in.sgrds=c(paste("Area1_slopeH.sgrd",sep=""),
> paste("Area1_valleyD.sgrd",sep="")),
> out.grids=c(paste("Area1_slopeH.asc",sep=""),
> paste("Area1_valleyD.asc",sep="")), prec=-6, out.path=getwd())}


#1 I think that you are pasting the text unnecessarily,
#2 You can read the SAGA grids directly to R via a GDAL driver 
[http://spatial-analyst.net/book/SAGA_driver]:

 > rsaga.geoprocessor("ta_morphometry",14,list(DEM="Area1.sgrd", 
HO="Area1_slopeH.sgrd", HU="Area1_valleyD.sgrd", W=0.5, T=10.0, E=2.0))
 > Area1_slopeH <- readGDAL("Area1_slopeH.sdat")

The sign "-1.#IND00" probably indicates NA values (NA mask). GDAL should 
be able to recognize those automatically.

T. Hengl
http://www.wewur.wur.nl/popups/vcard.aspx?id=HENGL001

>
> Any idea?
>
> Thanks, Stefano
>
> Stefano Cavazzi PhD Student, National Soil Resources Institute School
> Of Applied Sciences, Cranfield University
>
> [[alternative HTML version deleted]]
>
> _______________________________________________ R-sig-Geo mailing
> list R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Wed Mar  2 21:35:57 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 2 Mar 2011 21:35:57 +0100
Subject: [R-sig-Geo] Missing values with lm
In-Reply-To: <AANLkTi=J+ES38L00+AB2QJCxtv3JdWbdEQMDWm+yT1hX@mail.gmail.com>
References: <AANLkTi=J+ES38L00+AB2QJCxtv3JdWbdEQMDWm+yT1hX@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1103022133230.31295@reclus.nhh.no>

On Wed, 2 Mar 2011, Jan Hackenberg wrote:

> Hello
> I am trying to fit a linear model with lm. I want to decompose
> spatial-temporal pm10 data into pure spatial component and pure temporal
> component with an error term. My data consists of 36 points with 480
> timesteps.
> The code i am using is
> lm.half <- lm(pm10 ~factor(s) +factor(t),data= half)
> so i expect to get 36 s values and 480 t values. Instead for the first cell
> and the first timestep the value is missing, the lm result is only 35 s
> values and 479 t values ( + one intercept coefficient ). Is there a reason
> behind this and some way to fix it?
> Second question is how could i skip the intercept value in my computation.
> is this simple
> lm.half <- lm(pm10 ~factor(s) +factor(t) -1,data= half)
> ??
> I have found it in the internet, but i fear that then a -1 is taken into
> account always...

Don't always trust the internet, but yes, use -1 or equivalently + 0, see:

?formula

or for more detail:

      Chambers, J. M. and Hastie, T. J. (1992) _Statistical models._
      Chapter 2 of _Statistical Models in S_ eds J. M. Chambers and T.
      J. Hastie, Wadsworth & Brooks/Cole.

which is the authoritative source for where formula and data.frame objects 
came from.

Roger

>
> And also one last question, my R sqaured value is not too high, its only
> about 0.51. Does this tell me the model makes no sense? I would very like to
> use this model but i dont know if this number tells me not to use this ;).
> Have also heard that linear models without intercept have a higher r quared
> value, perhaps it will fix a little bit of this.
>
> Regards
> Jan
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From arnald.marcer at uab.cat  Thu Mar  3 10:03:23 2011
From: arnald.marcer at uab.cat (Arnald Marcer)
Date: Thu, 3 Mar 2011 10:03:23 +0100
Subject: [R-sig-Geo] Filtering a set of points by minimum distance between
	them
Message-ID: <4D6F595B.1000002@uab.cat>

Hi,

I have a set of coordinates in utm and need to get a subset of
them in which any coordinate is at a minimum distance from
any other one, that is to say, I need to filter them according
to a minimum distance between them.

Is there a function to do that or should I try to code it myself ?
Is there also a way of introducing randomness in the sense that
any run will give me a different set ?

Any help would be much appreciated

Thanks

Arnald Marcer
CREAF (Centre for Ecological Research and Forestry Applications)


From Roger.Bivand at nhh.no  Thu Mar  3 10:12:04 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 3 Mar 2011 10:12:04 +0100
Subject: [R-sig-Geo] Filtering a set of points by minimum distance
 between them
In-Reply-To: <4D6F595B.1000002@uab.cat>
References: <4D6F595B.1000002@uab.cat>
Message-ID: <alpine.LRH.2.00.1103031006240.1443@reclus.nhh.no>

On Thu, 3 Mar 2011, Arnald Marcer wrote:

> Hi,
>
> I have a set of coordinates in utm and need to get a subset of
> them in which any coordinate is at a minimum distance from
> any other one, that is to say, I need to filter them according
> to a minimum distance between them.
>
> Is there a function to do that or should I try to code it myself ?
> Is there also a way of introducing randomness in the sense that
> any run will give me a different set ?

The knearneigh() function in the spdep package calls functions in the RANN 
package to do this for planar coordinates - set the number of neighbours 
required to 1. You could look at the RANN package for non-deterministic 
solutions.

Roger

>
> Any help would be much appreciated
>
> Thanks
>
> Arnald Marcer
> CREAF (Centre for Ecological Research and Forestry Applications)
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From piero.campa at gmail.com  Thu Mar  3 14:16:18 2011
From: piero.campa at gmail.com (piero campa)
Date: Thu, 3 Mar 2011 05:16:18 -0800 (PST)
Subject: [R-sig-Geo] Missing values with lm
In-Reply-To: <AANLkTi=J+ES38L00+AB2QJCxtv3JdWbdEQMDWm+yT1hX@mail.gmail.com>
References: <AANLkTi=J+ES38L00+AB2QJCxtv3JdWbdEQMDWm+yT1hX@mail.gmail.com>
Message-ID: <1299158178322-6084753.post@n2.nabble.com>

Hi,
Jan also wrote:

"so i expect to get 36 s values and 480 t values. Instead for the first cell
and the first timestep the value is missing, the lm result is only 35 s
values and 479 t values ( + one intercept coefficient ). Is there a reason
behind this and some way to fix it?"

Any clue about this?
I encountered a similar problem and worked it out by filling the (very small
percentage) of NAs with a simple inverse distance interpolation
(?gstat::krige).

Piero

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Missing-values-with-lm-tp6080805p6084753.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From arnald.marcer at uab.cat  Thu Mar  3 14:33:23 2011
From: arnald.marcer at uab.cat (Arnald Marcer)
Date: Thu, 03 Mar 2011 14:33:23 +0100
Subject: [R-sig-Geo] Filtering a set of points by minimum distance
 between them [SUMMARY]
In-Reply-To: <alpine.LRH.2.00.1103031038190.1443@reclus.nhh.no>
References: <4D6F595B.1000002@uab.cat> <4D6F5FAC.4000003@uab.cat>
	<alpine.LRH.2.00.1103031038190.1443@reclus.nhh.no>
Message-ID: <4D6F98A3.3010805@uab.cat>

Hi,

I finally figured out how to select a subset of coordinates so that
any given one is at a minimum distance of any other one. Here
is the function I wrote. Roger, pointed me how to do it with the spdep
package but I have not been able to do it. I figured out another way,
surely less general, but which works for projected coordinates only.

Arnald
CREAF

Here it is my solution:
#*************************************************************************
sampleByMinDistance <- function(min.dist=0, coords){

     # shuffle the coordinates to factor in randomness in the selection 
of points
     coords <- coords[sample(1:length(coords[,1]), length(coords[,1])),]

     # initialize vector of indices at index 1 of coordinates
     v <- c(1)
     is.far <- TRUE
     for(i in 1:length(coords[,1])){
         for(j in 1:length(v)){
                 dist <- distance(coords[i,], coords[v[j],])
                 if(dist < min.dist){
                     is.far <- FALSE
                 }
         }
         if(is.far){
             v <- append(v, i)
         }
         is.far <- TRUE
     }
     return(coords[v,)
}
#**************************************************************************
distance <- function(p1, p2){
      dx <- abs(p1[1,1] - p2[1,1])
      dy <- abs(p1[1,2] - p2[1,2])
      dist <- sqrt(dx^2 + dy^2)
      return(dist)
}
#**************************************************************************

On 03/03/2011 10:42 AM, Roger Bivand wrote:
> On Thu, 3 Mar 2011, Arnald Marcer wrote:
>
>> Roger,
>>
>> Thank you for your very rapid response.
>>
>> I tried
>>
>> knn <- knearneigh(coords, k=1, longlat=NULL)
>>
>> but then do not know how to proceed to extract points
>> separated by minimum distance ...
>
> df <- data.frame(from=1:knn$np, fromX=knn$x[,1], fromY=knn$x[,2],
>   to=knn$nn[,1], toX=knn$x[knn$nn[,1],1], toY=knn$x[knn$nn[,1],2])
>
> makes a 6-column data frame, with from and to point sequence numbers, 
> and from and to coordinates.
>
> plot(coords)
> segments(df$fromX, df$fromY, df$toX, df$toY)
>
> shows the links - some of which have from and to as mutual nearest 
> neighbours. If you need more detail on extra options to use outside 
> knearneigh(), look at the help page for nn() in RANN.
>
> Please summarise to the list when your prolem is resolved.
>
> Roger
>
>>
>> Arnald
>>
>> On 03/03/2011 10:12 AM, Roger Bivand wrote:
>>> On Thu, 3 Mar 2011, Arnald Marcer wrote:
>>>
>>>> Hi,
>>>>
>>>> I have a set of coordinates in utm and need to get a subset of
>>>> them in which any coordinate is at a minimum distance from
>>>> any other one, that is to say, I need to filter them according
>>>> to a minimum distance between them.
>>>>
>>>> Is there a function to do that or should I try to code it myself ?
>>>> Is there also a way of introducing randomness in the sense that
>>>> any run will give me a different set ?
>>>
>>> The knearneigh() function in the spdep package calls functions in 
>>> the RANN package to do this for planar coordinates - set the number 
>>> of neighbours required to 1. You could look at the RANN package for 
>>> non-deterministic solutions.
>>>
>>> Roger
>>>
>>>>
>>>> Any help would be much appreciated
>>>>
>>>> Thanks
>>>>
>>>> Arnald Marcer
>>>> CREAF (Centre for Ecological Research and Forestry Applications)
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>
>>
>>
>>
>


-- 
Arnald Marcer
Investigador

Centre de Recerca Ecol?gica i Aplicacions Forestals (CREAF)
Edifici C
Universitat Aut?noma de Barcelona
08193 Barcelona

Tel: 93 581 46 67
Fax: 93 581 41 51


From risemary48 at yahoo.com  Fri Mar  4 11:39:50 2011
From: risemary48 at yahoo.com (Mary Rise)
Date: Fri, 4 Mar 2011 02:39:50 -0800 (PST)
Subject: [R-sig-Geo] cleaning up  a SpatialGridDataFrame
Message-ID: <669318.1925.qm@web120810.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110304/7d70e725/attachment.pl>

From kmringelman at ucdavis.edu  Fri Mar  4 20:17:53 2011
From: kmringelman at ucdavis.edu (Kevin Ringelman)
Date: Fri, 4 Mar 2011 11:17:53 -0800
Subject: [R-sig-Geo] spdep: show neighbors from "dnearneigh"
Message-ID: <000201cbdaa0$dda6f4c0$98f4de40$@edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110304/d24d5b1d/attachment.pl>

From ireeve at une.edu.au  Sat Mar  5 12:00:34 2011
From: ireeve at une.edu.au (Ian Reeve)
Date: Sat, 5 Mar 2011 22:00:34 +1100
Subject: [R-sig-Geo] Problem with polygon holes and islands
Message-ID: <C1FF1CF0-0BA1-41A7-8373-B012F4084D16@une.edu.au>

Dear all,

I'm importing census tract boundaries into R from a government website where the boundaries are provided as Mapinfo Interchange Format files, using:

mypolygons <- readOGR("websitefile.mif", layer="websitefile")

Some census tracts have holes.  In these cases, the hole slot of the outer polygon is TRUE and the hole slot of the inner polygon is FALSE.  I have to reverse these manually to get these tracts to plot correctly.

Some census tracts comprise a collection of islands.  In these cases, the hole slot of the first polygon in the collection is FALSE, and in the remainder of the polygons in the collection it is TRUE.  

Again I can correct these manually (and tediously), but I'm wondering if there is either a way of preventing this happening when importing the .mif file, or a single method that can be applied to a SpatialPolygons object to fix the problems in one go.

Any leads much appreciated.

Ian Reeve
University of New England
Armidale, NSW


From Roger.Bivand at nhh.no  Sat Mar  5 17:19:03 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 5 Mar 2011 17:19:03 +0100 (CET)
Subject: [R-sig-Geo] Problem with polygon holes and islands
In-Reply-To: <C1FF1CF0-0BA1-41A7-8373-B012F4084D16@une.edu.au>
References: <C1FF1CF0-0BA1-41A7-8373-B012F4084D16@une.edu.au>
Message-ID: <alpine.LRH.2.00.1103051704290.8089@reclus.nhh.no>

On Sat, 5 Mar 2011, Ian Reeve wrote:

> Dear all,
>
> I'm importing census tract boundaries into R from a government website 
> where the boundaries are provided as Mapinfo Interchange Format files, 
> using:
>
> mypolygons <- readOGR("websitefile.mif", layer="websitefile")
>
> Some census tracts have holes.  In these cases, the hole slot of the 
> outer polygon is TRUE and the hole slot of the inner polygon is FALSE. 
> I have to reverse these manually to get these tracts to plot correctly.
>
> Some census tracts comprise a collection of islands.  In these cases, 
> the hole slot of the first polygon in the collection is FALSE, and in 
> the remainder of the polygons in the collection it is TRUE.
>
> Again I can correct these manually (and tediously), but I'm wondering if 
> there is either a way of preventing this happening when importing the 
> .mif file, or a single method that can be applied to a SpatialPolygons 
> object to fix the problems in one go.

If you could make a sample file available, it might be possible to fix. 
The hole slots are being assigned based on the ring direction of the 
polygon boundaries, if the files do not specify the interior or exterior 
status of the ring. This can also be fixed by running checkPolygonsHoles() 
in the maptools package on the list in the polygons slot of the 
SpatialPolygonsDataFrame object, but there may be other possibilities.

Roger

>
> Any leads much appreciated.
>
> Ian Reeve
> University of New England
> Armidale, NSW
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Sat Mar  5 19:02:41 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 5 Mar 2011 19:02:41 +0100 (CET)
Subject: [R-sig-Geo] spdep: show neighbors from "dnearneigh"
In-Reply-To: <000201cbdaa0$dda6f4c0$98f4de40$@edu>
References: <000201cbdaa0$dda6f4c0$98f4de40$@edu>
Message-ID: <alpine.LRH.2.00.1103051720020.8089@reclus.nhh.no>

On Fri, 4 Mar 2011, Kevin Ringelman wrote:

> I am having trouble viewing the list of neighbors ("regions IDs") after
> created a nb object using the "dnearneigh" function in spdep.  I only seem
> to get a summary (with # regions, # non-zero links, etc.).  This nb object
> also doesn't take well to being converted to another type of object, or
> exported from R.  How I view the list of neighbors?
>

In S and R, objects with a class attribute, such as "nb" objects, may have 
display methods specific to the class. If you just say:

> nb

then this is expanded internally to print(nb), and since nb is an object 
of class "nb", the print.nb() method is chosen. If you want the default 
print method, call it as print.default(nb). Conversion of objects of one 
class to another class may be done by coercion where coercion methods are 
provided. No such methods are available for nb objects. There are 
functions to do things like this, but not methods. For example, to make an 
nb object into a row-standardised matrix, you might do:

> Wmat <- nb2mat(nb, style="W")

but you should avoid this if your number of observations is large. To make 
a sparse matrix, several steps are required:

> lw <- nb2listw(nb, style="W")
> spWmat <- as(as_dgRMatrix_listw(lw), "CsparseMatrix")

using the nb2listw() and (ugly name) as_dgRMatrix_listw() functions, and 
coercion from one representation to another using new-style classes 
defined in the Matrix package.

>
>
> Some additional background: I'm identifying all neighboring bird nests
> within 100m of each nest.  For this particular analysis, I ultimately want
> to calculate the average vegetation height of neighboring nests to compare
> with the focal nest.  This will involve generating a list of neighbors, and
> merging that list with my other data.
>

Note that an nb object is a list - to nuke the class, do:

> class(nb) <- NULL

which lets you call print.default(), but to get at the attribute you want, 
just do:

> attr(nb, "region.id")

to call print.default on the character vector it contains.

Hope this clarifies,

Roger

>
>
> Thanks,
>
> Kevin
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From ana-lee at web.de  Sun Mar  6 20:55:39 2011
From: ana-lee at web.de (Anna Gretschel)
Date: Sun, 06 Mar 2011 20:55:39 +0100
Subject: [R-sig-Geo] self-starting non linear model
Message-ID: <4D73E6BB.9050002@web.de>

Hi List!

I want to apply a selfstarting Michaelis-Menten-Model to my data: 
SSmicmen {stats}

I use thist function in the following way: 
model<-nls(distance~SSmicmen(watercontent, Vm, K))

When I want to compute it I get the error message:

                                                Fehler in lm.fit(x, y, 
offset = offset, singular.ok = singular.ok, ...) :
                                                NA/NaN/Inf in externem 
Funktionsaufruf (arg 4)

which would be in English: Error in lm.fit(x, y, offset = offset, 
singular.ok = singular.ok, ...) :
                                               NA/NaN/Inf in external 
function call(arg 4)

Does this mean the function just does not fit my data or is there 
anything I overlooked - any mistake I made defining the model???

Anna


From v8extra at gmail.com  Mon Mar  7 02:25:25 2011
From: v8extra at gmail.com (=?iso-8859-1?Q?S=E9bastien_Durand?=)
Date: Sun, 6 Mar 2011 20:25:25 -0500
Subject: [R-sig-Geo] How to calculate R2 coefficient of determination
	for	variogram ?
Message-ID: <1304EA17-1820-45CB-960A-6400208E88B5@gmail.com>

Hello, 

I found the following trend on the web, and I am facing the same problem.

I am trying to compute the r2 from my fit, but I end up with a negative value ... 

So I have two quick questions for you: 

1- What do you mean by  : "the same weighting scheme should have been used" and how would you code that?

2-I guess the code that was provide by Kili, should work for any variogram fit...

Thanks a lot for you time.

N.B.: I was unsure how to pursue this discussion on the web, so my apologies for contacting you directly!

S?bastien 


> It looks quite OK; I suspect however that instead of using
> mean(s.v$gamma) for SSTot, for this mean the same weighting scheme
> should have been used.
> --
> Edzer
> 
> On 09/02/2010 02:59 PM, 
> kili at grf.rs
>  wrote:
>>  Hi list,
>>  I'm not sure in my calculation of R2 coefficient of determination for
>>  variogram. Could someone check it, or give the better way.
>>  Here is an example:
>>  library(sp)
>>  library(gstat)
>>  data(meuse)
>>  coordinates(meuse) <- ~x+y
>>  s.v<- variogram(log1p(zinc)~sqrt(dist), meuse)
>>  vr.fit <- fit.variogram(variogram(log1p(zinc)~sqrt(dist), meuse), vgm(0,
>>  "Exp", 300, 1))
>>  ## SSErr is it summ of weighted squares of residuals ?
>>  (SSErr<-attr(vr.fit,"SSErr"))
>> 
>>  ## SStot total sum of weighted squares
>>  weig<-s.v$np/s.v$dist^2  #fit.method	 fitting method, used by gstat. The
>>  default method uses weights $N_h/h^2$ with $N_h$ the number of point pairs
>>  and $h$ the distance.
>>  (SStot<- sum(weig*(s.v$gamma-mean(s.v$gamma))^2)  )
>> 
>>  (R2<-1-SSErr/SStot    )    # R2 coefficient of determination
>>  Best regards,
>>  Kili
>> 
> 


From kili at grf.bg.ac.rs  Mon Mar  7 10:15:53 2011
From: kili at grf.bg.ac.rs (kili at grf.bg.ac.rs)
Date: Mon, 7 Mar 2011 10:15:53 +0100
Subject: [R-sig-Geo] How to calculate R2 coefficient of
	determinationforvariogram ?
Message-ID: <6347e35cc75df53853cc4f498cc4692d.squirrel@mail.grf.bg.ac.rs>

>>>1- What do you mean by  : "the same weighting scheme should have been
used" and how would you code that?

See fit.variogram function and argumnet fit.method .

If you do not check the argumrnt fit.method (the default value
fit.method=7)the weight function will be  $N_h/h^2$ with $N_h$ the number
of point pairs
and $h$ the distance.

So for this case you can use the formulas for any variogram.

R2variogram<-function(s.v,vr.fit){
 # s.v  - sample variogram

    SSErr<-attr(vr.fit,"SSErr")

    ## SStot total sum of weighted squares

    weig<-s.v$np/s.v$dist^2

#fit.method  fitting method, used by gstat. The default method uses
 #weights $N_h/h^2$ with $N_h$ the number of point pairs and $h$ the
 #distance.

    (SStot<- sum(weig*(s.v$gamma-mean(s.v$gamma))^2)  )
    R2<-1-SSErr/SStot

    return(R2)
      }

Best regards,
Milan Kilibarda - Kili





-------Original Message-------

From: S?bastien Durand
Date: 7.3.2011 2:28:44
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] How to calculate R2 coefficient of
determinationforvariogram ?

Hello,

I found the following trend on the web, and I am facing the same problem.

I am trying to compute the r2 from my fit, but I end up with a negative
value ...

So I have two quick questions for you:

1- What do you mean by  : "the same weighting scheme should have been
used" and how would you code that?


2-I guess the code that was provide by Kili, should work for any variogram
fit...

Thanks a lot for you time.

N.B.: I was unsure how to pursue this discussion on the web, so my
apologies for contacting you directly!

S?bastien


> It looks quite OK; I suspect however that instead of using
> mean(s.v$gamma) for SSTot, for this mean the same weighting scheme
> should have been used.
> --
> Edzer
>
> On 09/02/2010 02:59 PM,
> kili at grf.rs
>  wrote:
>>  Hi list,
>>  I'm not sure in my calculation of R2 coefficient of determination for
>>  variogram. Could someone check it, or give the better way.
>>  Here is an example:
>>  library(sp)
>>  library(gstat)
>>  data(meuse)
>>  coordinates(meuse) <- ~x+y
>>  s.v<- variogram(log1p(zinc)~sqrt(dist), me


From ireeve at une.edu.au  Mon Mar  7 11:44:21 2011
From: ireeve at une.edu.au (Ian Reeve)
Date: Mon, 7 Mar 2011 21:44:21 +1100
Subject: [R-sig-Geo] Problem with polygon holes and islands
Message-ID: <AE0C1A9F-2F3D-4889-9EA8-857FA10A0FB4@une.edu.au>

Problem with census tracts with holes and census tracts that are collections of islands not plotting, posted to R-sig-Geo on 5 Mar 2011, has been resolved.  checkPolygonsHoles() fixed the problem, both for holes and collections of islands (thanks, Roger).  The MIF files containing this census tract data came from the Australian Bureau of Statistics (ABS) website.  Roger notes that:

"ABS has a history of generating odd files - its shapefiles from some years ago used a very non-standard method of adding null geometries to insert non-localised data into the DBF file. This is why readOGR has a dropNULLGeometries= argument, and readShapePoly() in maptools has delete_null_obj= and retrieve_ABS_null= arguments (the ABS is the same organisation, not the mathematical function!). I guess they find these oddities helpful in some way in-house."

Ian Reeve
University of New England
Armidale, NSW


From tom.gottfried at wzw.tum.de  Mon Mar  7 14:41:59 2011
From: tom.gottfried at wzw.tum.de (Tom Gottfried)
Date: Mon, 07 Mar 2011 14:41:59 +0100
Subject: [R-sig-Geo] self-starting non linear model
In-Reply-To: <4D73E6BB.9050002@web.de>
References: <4D73E6BB.9050002@web.de>
Message-ID: <4D74E0A7.1030101@wzw.tum.de>

Hi Anna,

maybe this more a subject to be discussed on R-help?

Tom

Am 06.03.2011 20:55, schrieb Anna Gretschel:
> Hi List!
> 
> I want to apply a selfstarting Michaelis-Menten-Model to my data:
> SSmicmen {stats}
> 
> I use thist function in the following way:
> model<-nls(distance~SSmicmen(watercontent, Vm, K))
> 
> When I want to compute it I get the error message:
> 
>                                                Fehler in lm.fit(x, y,
> offset = offset, singular.ok = singular.ok, ...) :
>                                                NA/NaN/Inf in externem
> Funktionsaufruf (arg 4)
> 
> which would be in English: Error in lm.fit(x, y, offset = offset,
> singular.ok = singular.ok, ...) :
>                                               NA/NaN/Inf in external
> function call(arg 4)
> 
> Does this mean the function just does not fit my data or is there
> anything I overlooked - any mistake I made defining the model???
> 
> Anna
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Technische Universit?t M?nchen
Department f?r Pflanzenwissenschaften
Lehrstuhl f?r Gr?nlandlehre
Alte Akademie 12
85350 Freising / Germany
Phone: ++49 (0)8161 715324
Fax:   ++49 (0)8161 713243
email: tom.gottfried at wzw.tum.de
http://www.wzw.tum.de/gruenland


From ccvert11 at gmail.com  Mon Mar  7 17:44:40 2011
From: ccvert11 at gmail.com (CC Greene)
Date: Mon, 7 Mar 2011 17:44:40 +0100
Subject: [R-sig-Geo] Simple external drift kriging question
Message-ID: <AANLkTi=eOKR+cz5MfVdiKdo8mRKMaRSDh0s92XeSFw4x@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110307/5e13fea3/attachment.pl>

From tom.gottfried at wzw.tum.de  Mon Mar  7 18:31:37 2011
From: tom.gottfried at wzw.tum.de (Tom Gottfried)
Date: Mon, 07 Mar 2011 18:31:37 +0100
Subject: [R-sig-Geo] Simple external drift kriging question
In-Reply-To: <AANLkTi=eOKR+cz5MfVdiKdo8mRKMaRSDh0s92XeSFw4x@mail.gmail.com>
References: <AANLkTi=eOKR+cz5MfVdiKdo8mRKMaRSDh0s92XeSFw4x@mail.gmail.com>
Message-ID: <4D751679.5040703@wzw.tum.de>

Hi Chris,

Am 07.03.2011 17:44, schrieb CC Greene:
> Hello,
> 
> I am new to geostatistics. I was hoping someone could answer the following
> question:
> 
> When trying to do external drift kriging, I understand that you create the
> variogram from the residuals. Then, my question is when you actually do the
> kriging, do you interpolate the residuals and add them to an ordinary kriged
> field?

The residuals, that are interpolated by kriging, are added to the values obtained from interpolation
via regression. The gstat package does this for you if you specify an independent variable e.g. in
gstat() or krige().

> Or, can one just take the variogram derived from the residuals and apply it
> to the raw data when kriging.

No, as the variogram derived from the residuals does only represent the spatial dependence in the
residuals, not the raw data.

regards,
Tom

> Thank you for your time and a simple response.
> 
> Chris
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Technische Universit?t M?nchen
Department f?r Pflanzenwissenschaften
Lehrstuhl f?r Gr?nlandlehre
Alte Akademie 12
85350 Freising / Germany
Phone: ++49 (0)8161 715324
Fax:   ++49 (0)8161 713243
email: tom.gottfried at wzw.tum.de
http://www.wzw.tum.de/gruenland


From aman.verma at mcgill.ca  Mon Mar  7 20:15:54 2011
From: aman.verma at mcgill.ca (Aman Verma)
Date: Mon, 7 Mar 2011 14:15:54 -0500
Subject: [R-sig-Geo] sample.Polygons fails for shapes with more than four
	Polygons
Message-ID: <FF83BA46F4BA3C49A1EADAEFE9FD1B4A0A1A24DD9F@EXMBXVS1.campus.mcgill.ca>

Hi everybody,

I have discovered some strange behaviour in the function sample.Polygons in the sp package. Consider this code:

library(maptools)
library(sp)
# Download and unpack this shape file to your working directory:
# http://surveillance.mcgill.ca/countries_subdiv_Project_PP_project_region.zip
shapefile<-readShapePoly("countries_subdiv_Project_PP_project_region.shp")
	
# Try and sample some points from different shapes (with multiple polygons):
sample.Polygons(shapefile at polygons[[1930]],n=1,type='regular') # Has 2 polygons
# Works just fine.
sample.Polygons(shapefile at polygons[[1933]],n=1,type='regular') # Has 10 polygons
# Fails: 
# Error: subscript out of bounds

I have done some debugging, and located the source of the error. In sample.Polygons, if there is more than one Polygon in the 'shape', this for loop is run:

for (i in seq(along = pls)) {
	bbi <- .bbox2SPts(bbox(pls[[i]]), proj4string = proj4string) # Convert bbox to set of 4 points
	# Check which other shapes overlap the bbox of this shape.
	# For a two dimensional object, bb_in is a list of vectors with length 4:
	# one for each point in the bbox.
	bb_in <- lapply(pls[-i], function(x, pts) pointsInPolygon(pts, x), pts = bbi)
	# For a two dimensional object, zzz must be a matrix with exactly four columns.
	zzz <- do.call("rbind", bb_in) 
	# For a 2D object, zzz only has four columns, but i can exceed four!
	# But 'i' represents the index of the polygon in the shape, which can exceed four.
	# zzz[, i] will fail when i exceeds four.
	if (holes[i] || (any(unlist(bb_in) == 1) && !(sum(zzz[, i])%%2) == 0)) smple[i] <- FALSE
}

The comments are my own. Basically, for two-dimensional shapes, the last line will fail when the number of Polygons in the shape exceeds four, and at least one of those shapes doesn't have a "hole". (If they do have holes, then zzz[,i] won't be evaluated.)

I'm not sure exactly what this last line is supposed to be doing... which is why I can't make a suggestion for a correction. I suspect that zzz[,i] should be zzz[i,], but that is just a guess, really.

I have tested this on R version 2.12.2 with sp package 0.9-78 on both the Windows and UNIX (Ubuntu) platforms.

Thanks for any help.

aman


From Roger.Bivand at nhh.no  Mon Mar  7 22:08:16 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 7 Mar 2011 22:08:16 +0100 (CET)
Subject: [R-sig-Geo] sample.Polygons fails for shapes with more than
 four Polygons
In-Reply-To: <FF83BA46F4BA3C49A1EADAEFE9FD1B4A0A1A24DD9F@EXMBXVS1.campus.mcgill.ca>
References: <FF83BA46F4BA3C49A1EADAEFE9FD1B4A0A1A24DD9F@EXMBXVS1.campus.mcgill.ca>
Message-ID: <alpine.LRH.2.00.1103072153510.20186@reclus.nhh.no>

On Mon, 7 Mar 2011, Aman Verma wrote:

> Hi everybody,
>
> I have discovered some strange behaviour in the function sample.Polygons 
> in the sp package. Consider this code:
>
> library(maptools)
> library(sp)
> # Download and unpack this shape file to your working directory:
> # http://surveillance.mcgill.ca/countries_subdiv_Project_PP_project_region.zip
> shapefile<-readShapePoly("countries_subdiv_Project_PP_project_region.shp")
>
> # Try and sample some points from different shapes (with multiple polygons):
> sample.Polygons(shapefile at polygons[[1930]],n=1,type='regular') # Has 2 polygons
> # Works just fine.
> sample.Polygons(shapefile at polygons[[1933]],n=1,type='regular') # Has 10 polygons
> # Fails:
> # Error: subscript out of bounds
>
> I have done some debugging, and located the source of the error. In 
> sample.Polygons, if there is more than one Polygon in the 'shape', this 
> for loop is run:
>
> for (i in seq(along = pls)) {
> 	bbi <- .bbox2SPts(bbox(pls[[i]]), proj4string = proj4string) # Convert bbox to set of 4 points
> 	# Check which other shapes overlap the bbox of this shape.
> 	# For a two dimensional object, bb_in is a list of vectors with length 4:
> 	# one for each point in the bbox.
> 	bb_in <- lapply(pls[-i], function(x, pts) pointsInPolygon(pts, x), pts = bbi)
> 	# For a two dimensional object, zzz must be a matrix with exactly four columns.
> 	zzz <- do.call("rbind", bb_in)
> 	# For a 2D object, zzz only has four columns, but i can exceed four!
> 	# But 'i' represents the index of the polygon in the shape, which can exceed four.
> 	# zzz[, i] will fail when i exceeds four.
> 	if (holes[i] || (any(unlist(bb_in) == 1) && !(sum(zzz[, i])%%2) == 0)) smple[i] <- FALSE
> }
>
> The comments are my own. Basically, for two-dimensional shapes, the last 
> line will fail when the number of Polygons in the shape exceeds four, 
> and at least one of those shapes doesn't have a "hole". (If they do have 
> holes, then zzz[,i] won't be evaluated.)

Hi Aman,

Thanks for a clear analysis and sample data! Bug fix committed to R-Forge 
SVN, will be in tomorrow's R-Forge builds (revision 1039). If you need it 
earlier, please make an anonymous checkout.

pts <- spsample(shapefile, n=5000, type="random")

now works.

>
> I'm not sure exactly what this last line is supposed to be doing... 
> which is why I can't make a suggestion for a correction. I suspect that 
> zzz[,i] should be zzz[i,], but that is just a guess, really.
>

The change adding this code on 16 July 2010 was made to try to improve 
hole logic. Quite often, imported multipolygon objects (Polygons objects 
in sp) have wrong hole status assigned to the geometries. If 
checkPolygonsHoles() in the maptools package has not been run to clean 
them up, this may lead to grief. The code is a guess at finding conditions 
that would identify a hole even though it is declared as not a hole. It 
isn't bullet-proof, and did contain a bug, which you identified.

Best wishes,

Roger

> I have tested this on R version 2.12.2 with sp package 0.9-78 on both 
> the Windows and UNIX (Ubuntu) platforms.
>
> Thanks for any help.
>
> aman
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From r.hijmans at gmail.com  Tue Mar  8 03:00:02 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Mon, 7 Mar 2011 18:00:02 -0800 (PST)
Subject: [R-sig-Geo] cleaning up  a SpatialGridDataFrame
In-Reply-To: <669318.1925.qm@web120810.mail.ne1.yahoo.com>
References: <669318.1925.qm@web120810.mail.ne1.yahoo.com>
Message-ID: <1299549602324-6099877.post@n2.nabble.com>

> I have an image which is a SpatialGridDatafFrame. This image has a number
of 
> cells that i need to erase or to delete but i don`t know how to do this in
> R. 

Mary,

It is not clear what you mean with "erase or delete". 

If you refer to setting some cell values to NA you can do, with
SpatialGridDataFrame x, things like
x at data[2:5,] <- NA

or make a RasterLayer

library(raster)
r <- raster(x)
x[2:5] <- NA
x[1:2, 1:2] <- NA

or use raster package functions like 'reclass', 'subs', or 'cut'

If you refer to removing entire rows or columns from your grid, you can use
function 'crop' and perhaps 'trim' 

Robert


--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/cleaning-up-a-SpatialGridDataFrame-tp6087994p6099877.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From elaine.kuo.tw at gmail.com  Tue Mar  8 07:00:49 2011
From: elaine.kuo.tw at gmail.com (elaine kuo)
Date: Tue, 8 Mar 2011 14:00:49 +0800
Subject: [R-sig-Geo] methods to assess point distributions (ex. random, even,
	or clumped distributions)
Message-ID: <AANLkTimmP2h+z-WX3_RdaCfottuxXh=ZAn6_NgPzr4+U@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110308/f6f5f541/attachment.pl>

From roman.lustrik at gmail.com  Tue Mar  8 07:53:10 2011
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Tue, 8 Mar 2011 07:53:10 +0100
Subject: [R-sig-Geo] methods to assess point distributions (ex. random,
 even, or clumped distributions)
In-Reply-To: <AANLkTimmP2h+z-WX3_RdaCfottuxXh=ZAn6_NgPzr4+U@mail.gmail.com>
References: <AANLkTimmP2h+z-WX3_RdaCfottuxXh=ZAn6_NgPzr4+U@mail.gmail.com>
Message-ID: <AANLkTikkEGKbi+B_TD9=bL6+Qn7oNyMNbTdOrpwQgZcM@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110308/765243c7/attachment.pl>

From Roger.Bivand at nhh.no  Tue Mar  8 14:45:57 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 8 Mar 2011 14:45:57 +0100 (CET)
Subject: [R-sig-Geo] sample.Polygons fails for shapes with more than
 four Polygons
In-Reply-To: <alpine.LRH.2.00.1103072153510.20186@reclus.nhh.no>
References: <FF83BA46F4BA3C49A1EADAEFE9FD1B4A0A1A24DD9F@EXMBXVS1.campus.mcgill.ca>
	<alpine.LRH.2.00.1103072153510.20186@reclus.nhh.no>
Message-ID: <alpine.LRH.2.00.1103081443560.24065@reclus.nhh.no>

On Mon, 7 Mar 2011, Roger Bivand wrote:

> On Mon, 7 Mar 2011, Aman Verma wrote:
>
>> Hi everybody,
>> 
>> I have discovered some strange behaviour in the function sample.Polygons in 
>> the sp package. Consider this code:
>> 
>> library(maptools)
>> library(sp)
>> # Download and unpack this shape file to your working directory:
>> # 
>> http://surveillance.mcgill.ca/countries_subdiv_Project_PP_project_region.zip
>> shapefile<-readShapePoly("countries_subdiv_Project_PP_project_region.shp")
>> 
>> # Try and sample some points from different shapes (with multiple 
>> polygons):
>> sample.Polygons(shapefile at polygons[[1930]],n=1,type='regular') # Has 2 
>> polygons
>> # Works just fine.
>> sample.Polygons(shapefile at polygons[[1933]],n=1,type='regular') # Has 10 
>> polygons
>> # Fails:
>> # Error: subscript out of bounds
>> 
>> I have done some debugging, and located the source of the error. In 
>> sample.Polygons, if there is more than one Polygon in the 'shape', this for 
>> loop is run:
>> 
>> for (i in seq(along = pls)) {
>> 	bbi <- .bbox2SPts(bbox(pls[[i]]), proj4string = proj4string) # 
>> Convert bbox to set of 4 points
>> 	# Check which other shapes overlap the bbox of this shape.
>> 	# For a two dimensional object, bb_in is a list of vectors with 
>> length 4:
>> 	# one for each point in the bbox.
>> 	bb_in <- lapply(pls[-i], function(x, pts) pointsInPolygon(pts, x), 
>> pts = bbi)
>> 	# For a two dimensional object, zzz must be a matrix with exactly 
>> four columns.
>> 	zzz <- do.call("rbind", bb_in)
>> 	# For a 2D object, zzz only has four columns, but i can exceed four!
>> 	# But 'i' represents the index of the polygon in the shape, which can 
>> exceed four.
>> 	# zzz[, i] will fail when i exceeds four.
>> 	if (holes[i] || (any(unlist(bb_in) == 1) && !(sum(zzz[, i])%%2) == 
>> 0)) smple[i] <- FALSE
>> }
>> 
>> The comments are my own. Basically, for two-dimensional shapes, the last 
>> line will fail when the number of Polygons in the shape exceeds four, and 
>> at least one of those shapes doesn't have a "hole". (If they do have holes, 
>> then zzz[,i] won't be evaluated.)
>
> Hi Aman,
>
> Thanks for a clear analysis and sample data! Bug fix committed to R-Forge 
> SVN, will be in tomorrow's R-Forge builds (revision 1039). If you need it 
> earlier, please make an anonymous checkout.

In revision 1040, the whole heuristic is removed - it is the user's 
responsibility to set the Polygon objects "hole" slots correctly - if in 
doubt, use checkPolygonsHoles() in the maptools package.

Roger

>
> pts <- spsample(shapefile, n=5000, type="random")
>
> now works.
>
>> 
>> I'm not sure exactly what this last line is supposed to be doing... which 
>> is why I can't make a suggestion for a correction. I suspect that zzz[,i] 
>> should be zzz[i,], but that is just a guess, really.
>> 
>
> The change adding this code on 16 July 2010 was made to try to improve hole 
> logic. Quite often, imported multipolygon objects (Polygons objects in sp) 
> have wrong hole status assigned to the geometries. If checkPolygonsHoles() in 
> the maptools package has not been run to clean them up, this may lead to 
> grief. The code is a guess at finding conditions that would identify a hole 
> even though it is declared as not a hole. It isn't bullet-proof, and did 
> contain a bug, which you identified.
>
> Best wishes,
>
> Roger
>
>> I have tested this on R version 2.12.2 with sp package 0.9-78 on both the 
>> Windows and UNIX (Ubuntu) platforms.
>> 
>> Thanks for any help.
>> 
>> aman
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From mathieu.rajerison at gmail.com  Tue Mar  8 15:21:08 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Tue, 8 Mar 2011 15:21:08 +0100
Subject: [R-sig-Geo] Polygons with islands are not drawn using plot or spplot
Message-ID: <AANLkTimtDWORhw3VcOvCSjj9Xr17gaowfRw0RZ-CY8SE@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110308/8d5aba27/attachment.pl>

From Roger.Bivand at nhh.no  Tue Mar  8 17:46:58 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 8 Mar 2011 17:46:58 +0100 (CET)
Subject: [R-sig-Geo] Polygons with islands are not drawn using plot or
 spplot
In-Reply-To: <AANLkTimtDWORhw3VcOvCSjj9Xr17gaowfRw0RZ-CY8SE@mail.gmail.com>
References: <AANLkTimtDWORhw3VcOvCSjj9Xr17gaowfRw0RZ-CY8SE@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1103081742180.29701@reclus.nhh.no>

On Tue, 8 Mar 2011, Mathieu Rajerison wrote:

> Hi,
>
> I'm beginning with R. Excuse me in case my question has already been asked.
>
> When I plot polygons with a color fill, the fill color is empty for polygons
> who have got islands.
>
> Any issue for this?

Please provide a very short reproducible example, if necessary posting 
data files on a web server; also remember to report the output of 
sessionInfo(). The answer is that for some reason the hole slots of the 
component Polygon objects are not being set correctly, and this will 
depend on how the objects were imported or created. If the hole slot is 
set as TRUE, the background colour will be shown. Does setting 
usePolypath=TRUE in the plot() call make a difference?

Roger

>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From yee at post.harvard.edu  Tue Mar  8 18:03:10 2011
From: yee at post.harvard.edu (Andrew Yee)
Date: Tue, 8 Mar 2011 12:03:10 -0500
Subject: [R-sig-Geo] package to query Google for latitude and longitude for
	a given ZIP code
Message-ID: <AANLkTik_rhVzb4yzxxN7n0uX2W3VzeCVMeKv-nAr+Xvd@mail.gmail.com>

Hi, I was wondering if someone could direct me to a package that would
allow you to query Google (or any other resource) for the latitude and
longitude of a ZIP code.

While I'm aware of the zipcode package, there are certain ZIP codes
that are not in the database (e.g. areas that are serviced by PO
boxes, e.g. 03861).

I was thinking that Google could be helpful for retrieving this kind
of information and was hoping that there's a package that handles
these kinds of queries.

Thanks,
Andrew


From dan.putler at sauder.ubc.ca  Tue Mar  8 18:16:13 2011
From: dan.putler at sauder.ubc.ca (Dan Putler)
Date: Tue, 8 Mar 2011 09:16:13 -0800
Subject: [R-sig-Geo] package to query Google for latitude and longitude
 for	a given ZIP code
In-Reply-To: <10356_1299603948_1299603948_AANLkTik_rhVzb4yzxxN7n0uX2W3VzeCVMeKv-nAr+Xvd@mail.gmail.com>
References: <10356_1299603948_1299603948_AANLkTik_rhVzb4yzxxN7n0uX2W3VzeCVMeKv-nAr+Xvd@mail.gmail.com>
Message-ID: <4D76645D.3070107@sauder.ubc.ca>

Andrew,

What you are proposing (a) violates Google's terms of service and (b) is 
pretty meaningless since a PO Box zip code will be located at a post 
office location, not the household's or firm's location, which I'm 
pretty certain is not the location that will matter conceptually for any 
model you develop based on this information.

Dan

On 03/08/2011 09:03 AM, Andrew Yee wrote:
> Hi, I was wondering if someone could direct me to a package that would
> allow you to query Google (or any other resource) for the latitude and
> longitude of a ZIP code.
>
> While I'm aware of the zipcode package, there are certain ZIP codes
> that are not in the database (e.g. areas that are serviced by PO
> boxes, e.g. 03861).
>
> I was thinking that Google could be helpful for retrieving this kind
> of information and was hoping that there's a package that handles
> these kinds of queries.
>
> Thanks,
> Andrew
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From yee at post.harvard.edu  Tue Mar  8 18:23:21 2011
From: yee at post.harvard.edu (Andrew Yee)
Date: Tue, 8 Mar 2011 12:23:21 -0500
Subject: [R-sig-Geo] package to query Google for latitude and longitude
 for a given ZIP code
In-Reply-To: <4D76645D.3070107@sauder.ubc.ca>
References: <10356_1299603948_1299603948_AANLkTik_rhVzb4yzxxN7n0uX2W3VzeCVMeKv-nAr+Xvd@mail.gmail.com>
	<4D76645D.3070107@sauder.ubc.ca>
Message-ID: <AANLkTi=eoEVyC4kY+unKtKQCExzUFTX8YFFjFR4zKRAt@mail.gmail.com>

Thanks.  That's interesting, with respect to Google's terms of
service, since I thought this kind of information was available
through the Google Geocoding API.

The reason why I'm pushing for the P.O. box ZIP code is that some
geographic information is better than none.

Thanks,
Andrew

On Tue, Mar 8, 2011 at 12:16 PM, Dan Putler <dan.putler at sauder.ubc.ca> wrote:
> Andrew,
>
> What you are proposing (a) violates Google's terms of service and (b) is
> pretty meaningless since a PO Box zip code will be located at a post office
> location, not the household's or firm's location, which I'm pretty certain
> is not the location that will matter conceptually for any model you develop
> based on this information.
>
> Dan
>
> On 03/08/2011 09:03 AM, Andrew Yee wrote:
>>
>> Hi, I was wondering if someone could direct me to a package that would
>> allow you to query Google (or any other resource) for the latitude and
>> longitude of a ZIP code.
>>
>> While I'm aware of the zipcode package, there are certain ZIP codes
>> that are not in the database (e.g. areas that are serviced by PO
>> boxes, e.g. 03861).
>>
>> I was thinking that Google could be helpful for retrieving this kind
>> of information and was hoping that there's a package that handles
>> these kinds of queries.
>>
>> Thanks,
>> Andrew
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From fernandoascensao at gmail.com  Tue Mar  8 18:28:18 2011
From: fernandoascensao at gmail.com (=?ISO-8859-1?Q?Fernando_Ascens=E3o?=)
Date: Tue, 8 Mar 2011 17:28:18 +0000
Subject: [R-sig-Geo] using animal Utilization Distribution as response
	variable in modeling
Message-ID: <AANLkTinHdh-KRB=5+LrWZ98jwYEgmyWOJa+beHMS62qm@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110308/75630902/attachment.pl>

From tomfool at as220.org  Tue Mar  8 18:29:41 2011
From: tomfool at as220.org (Tom Sgouros)
Date: Tue, 8 Mar 2011 12:29:41 -0500
Subject: [R-sig-Geo] package to query Google for latitude and longitude
	for	a given ZIP code
In-Reply-To: <4D76645D.3070107@sauder.ubc.ca>
References: <10356_1299603948_1299603948_AANLkTik_rhVzb4yzxxN7n0uX2W3VzeCVMeKv-nAr+Xvd@mail.gmail.com>
	<4D76645D.3070107@sauder.ubc.ca>
Message-ID: <B5B42A01-CCB5-45E7-81EF-CF2D57C58222@as220.org>

Andrew:

I don't know if it matters to your goal, but there are some zip codes that do not correspond to locations, and some correspond to locations best represented by a line, not an area.  The post office originally set them up to represent delivery routes or groups of routes, and most of them represent a place, but not all do.  I ran across a note about the limitations of zip codes as a representation of areas in the technical docs of some US Census data once.   I know of one zip code near me that contains a couple of buildings that aren't next to each other.  Some geographic information is better than none, but I don't know what you'd do about a situation like that.

 -Tom


On Mar 8, 2011, at 12:16 PM, Dan Putler wrote:

> Andrew,
> 
> What you are proposing (a) violates Google's terms of service and (b) is pretty meaningless since a PO Box zip code will be located at a post office location, not the household's or firm's location, which I'm pretty certain is not the location that will matter conceptually for any model you develop based on this information.
> 
> Dan
> 
> On 03/08/2011 09:03 AM, Andrew Yee wrote:
>> Hi, I was wondering if someone could direct me to a package that would
>> allow you to query Google (or any other resource) for the latitude and
>> longitude of a ZIP code.
>> 
>> While I'm aware of the zipcode package, there are certain ZIP codes
>> that are not in the database (e.g. areas that are serviced by PO
>> boxes, e.g. 03861).
>> 
>> I was thinking that Google could be helpful for retrieving this kind
>> of information and was hoping that there's a package that handles
>> these kinds of queries.
>> 
>> Thanks,
>> Andrew
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Tue Mar  8 18:30:15 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Tue, 8 Mar 2011 09:30:15 -0800 (PST)
Subject: [R-sig-Geo] package to query Google for latitude and longitude
 for a given ZIP code
In-Reply-To: <AANLkTik_rhVzb4yzxxN7n0uX2W3VzeCVMeKv-nAr+Xvd@mail.gmail.com>
References: <AANLkTik_rhVzb4yzxxN7n0uX2W3VzeCVMeKv-nAr+Xvd@mail.gmail.com>
Message-ID: <1299605415770-6131592.post@n2.nabble.com>

>Hi, I was wondering if someone could direct me to a package that would 
>allow you to query Google (or any other resource) for the latitude and 
>longitude of a ZIP code. 

You can try the 'geocode' function in the dismo package. 

> geocode('03861')
     ID      lon      lat   lonmin    lonmax   latmin   latmax
[1,]  1 -71.0169 43.11589 -71.0731 -70.96072 43.08175 43.17245
> 

Robert

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/package-to-query-Google-for-latitude-and-longitude-for-a-given-ZIP-code-tp6130598p6131592.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From fernandoascensao at gmail.com  Tue Mar  8 18:32:11 2011
From: fernandoascensao at gmail.com (=?ISO-8859-1?Q?Fernando_Ascens=E3o?=)
Date: Tue, 8 Mar 2011 17:32:11 +0000
Subject: [R-sig-Geo] using animal Utilization Distribution as response
	variable in modeling
In-Reply-To: <AANLkTinHdh-KRB=5+LrWZ98jwYEgmyWOJa+beHMS62qm@mail.gmail.com>
References: <AANLkTinHdh-KRB=5+LrWZ98jwYEgmyWOJa+beHMS62qm@mail.gmail.com>
Message-ID: <AANLkTikwjFoymcXNp2+iX-Bmv1=bswDKr3vhuYn9s4sB@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110308/970b988e/attachment.pl>

From dan.putler at sauder.ubc.ca  Tue Mar  8 18:33:55 2011
From: dan.putler at sauder.ubc.ca (Dan Putler)
Date: Tue, 8 Mar 2011 09:33:55 -0800
Subject: [R-sig-Geo] package to query Google for latitude and longitude
 for a given ZIP code
In-Reply-To: <AANLkTi=eoEVyC4kY+unKtKQCExzUFTX8YFFjFR4zKRAt@mail.gmail.com>
References: <10356_1299603948_1299603948_AANLkTik_rhVzb4yzxxN7n0uX2W3VzeCVMeKv-nAr+Xvd@mail.gmail.com>
	<4D76645D.3070107@sauder.ubc.ca>
	<AANLkTi=eoEVyC4kY+unKtKQCExzUFTX8YFFjFR4zKRAt@mail.gmail.com>
Message-ID: <4D766883.8030605@sauder.ubc.ca>

Read the terms of service agreement. You can use the service for the 
purposes of displaying information on a Google map, but not store the 
information or use it for non-display purposes. To use it in R, you will 
be using it for non-display purposes and you will likely store it. This 
topic has been discussed on this list before.

You could use the city, and take advantage of the U.S. Board on 
Geographic Names (public domain) data. See http://geonames.usgs.gov

On 03/08/2011 09:23 AM, Andrew Yee wrote:
> Thanks.  That's interesting, with respect to Google's terms of
> service, since I thought this kind of information was available
> through the Google Geocoding API.
>
> The reason why I'm pushing for the P.O. box ZIP code is that some
> geographic information is better than none.
>
> Thanks,
> Andrew
>
> On Tue, Mar 8, 2011 at 12:16 PM, Dan Putler<dan.putler at sauder.ubc.ca>  wrote:
>> Andrew,
>>
>> What you are proposing (a) violates Google's terms of service and (b) is
>> pretty meaningless since a PO Box zip code will be located at a post office
>> location, not the household's or firm's location, which I'm pretty certain
>> is not the location that will matter conceptually for any model you develop
>> based on this information.
>>
>> Dan
>>
>> On 03/08/2011 09:03 AM, Andrew Yee wrote:
>>> Hi, I was wondering if someone could direct me to a package that would
>>> allow you to query Google (or any other resource) for the latitude and
>>> longitude of a ZIP code.
>>>
>>> While I'm aware of the zipcode package, there are certain ZIP codes
>>> that are not in the database (e.g. areas that are serviced by PO
>>> boxes, e.g. 03861).
>>>
>>> I was thinking that Google could be helpful for retrieving this kind
>>> of information and was hoping that there's a package that handles
>>> these kinds of queries.
>>>
>>> Thanks,
>>> Andrew
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>


From yee at post.harvard.edu  Tue Mar  8 19:26:16 2011
From: yee at post.harvard.edu (Andrew Yee)
Date: Tue, 8 Mar 2011 13:26:16 -0500
Subject: [R-sig-Geo] package to query Google for latitude and longitude
 for a given ZIP code
In-Reply-To: <1299605415770-6131592.post@n2.nabble.com>
References: <AANLkTik_rhVzb4yzxxN7n0uX2W3VzeCVMeKv-nAr+Xvd@mail.gmail.com>
	<1299605415770-6131592.post@n2.nabble.com>
Message-ID: <AANLkTind_==bLrQFknpmuMu6+j91ziWTOex7PZGNAWeg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110308/0bf398b9/attachment.pl>

From guy.serbin at gmail.com  Tue Mar  8 19:58:33 2011
From: guy.serbin at gmail.com (Guy Serbin)
Date: Tue, 8 Mar 2011 13:58:33 -0500
Subject: [R-sig-Geo] package to query Google for latitude and longitude
 for a given ZIP code
In-Reply-To: <AANLkTind_==bLrQFknpmuMu6+j91ziWTOex7PZGNAWeg@mail.gmail.com>
References: <AANLkTik_rhVzb4yzxxN7n0uX2W3VzeCVMeKv-nAr+Xvd@mail.gmail.com>
	<1299605415770-6131592.post@n2.nabble.com>
	<AANLkTind_==bLrQFknpmuMu6+j91ziWTOex7PZGNAWeg@mail.gmail.com>
Message-ID: <AANLkTimTkrmdeUC=kQCMpZJ6BgE-X0sGx14JBPJMzt7+@mail.gmail.com>

Hi,

The data you are looking for could likely come from www.geodata.gov

I am guessing this would be the same set that Google uses, but since
it's from the Federal Government you wouldn't be in violation of any
terms of service.

Best regards,
Guy

On Tue, Mar 8, 2011 at 1:26 PM, Andrew Yee <yee at post.harvard.edu> wrote:
> Thanks everyone for your input. ?I'll give geocode() a try.
>
> Andrew
>
> On Tue, Mar 8, 2011 at 12:30 PM, Robert Hijmans <r.hijmans at gmail.com> wrote:
>
>> >Hi, I was wondering if someone could direct me to a package that would
>> >allow you to query Google (or any other resource) for the latitude and
>> >longitude of a ZIP code.
>>
>> You can try the 'geocode' function in the dismo package.
>>
>> > geocode('03861')
>> ? ? ID ? ? ?lon ? ? ?lat ? lonmin ? ?lonmax ? latmin ? latmax
>> [1,] ?1 -71.0169 43.11589 -71.0731 -70.96072 43.08175 43.17245
>> >
>>
>> Robert
>>
>> --
>> View this message in context:
>> http://r-sig-geo.2731867.n2.nabble.com/package-to-query-Google-for-latitude-and-longitude-for-a-given-ZIP-code-tp6130598p6131592.html
>> Sent from the R-sig-geo mailing list archive at Nabble.com.
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From jim at bitwrit.com.au  Wed Mar  9 09:03:13 2011
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 09 Mar 2011 19:03:13 +1100
Subject: [R-sig-Geo] package to query Google for latitude and longitude
 for a given ZIP code
In-Reply-To: <AANLkTi=eoEVyC4kY+unKtKQCExzUFTX8YFFjFR4zKRAt@mail.gmail.com>
References: <10356_1299603948_1299603948_AANLkTik_rhVzb4yzxxN7n0uX2W3VzeCVMeKv-nAr+Xvd@mail.gmail.com>	<4D76645D.3070107@sauder.ubc.ca>
	<AANLkTi=eoEVyC4kY+unKtKQCExzUFTX8YFFjFR4zKRAt@mail.gmail.com>
Message-ID: <4D773441.9090104@bitwrit.com.au>

On 03/09/2011 04:23 AM, Andrew Yee wrote:

Hi Andrew,
You can get an approximate longitude/latitude for any point on:

http://www.getlatlon.com/

and it doesn't look like there are any restrictions on use.

Jim


From mathieu.rajerison at gmail.com  Wed Mar  9 10:40:00 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Wed, 9 Mar 2011 10:40:00 +0100
Subject: [R-sig-Geo] spatial clustering - land usage - skater?
Message-ID: <AANLkTi=J3DqZv8HM1iV1eEwukmXrz82erS99vdo4qe66@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110309/55aa6158/attachment.pl>

From evion12000 at gmail.com  Wed Mar  9 13:26:38 2011
From: evion12000 at gmail.com (=?iso-8859-1?Q?David_M=E9ndez?=)
Date: Wed, 9 Mar 2011 07:56:38 -0430
Subject: [R-sig-Geo] R-sig-Geo Digest, Vol 91, Issue 8
Message-ID: <4d7771f5.1d4de50a.3591.47b7@mx.google.com>



Enviado desde mi HTC

----- Mensaje original -----
De: r-sig-geo-request at r-project.org
Enviado: Martes, 08 de Marzo de 2011 06:30
Para: r-sig-geo at r-project.org
Asunto: R-sig-Geo Digest, Vol 91, Issue 8

Send R-sig-Geo mailing list submissions to
	r-sig-geo at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://stat.ethz.ch/mailman/listinfo/r-sig-geo
or, via email, send a message with subject or body 'help' to
	r-sig-geo-request at r-project.org

You can reach the person managing the list at
	r-sig-geo-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-Geo digest..."


Today's Topics:

   1. Re: self-starting non linear model (Tom Gottfried)
   2. Simple external drift kriging question (CC Greene)
   3. Re: Simple external drift kriging question (Tom Gottfried)
   4. sample.Polygons fails for shapes with more than four	Polygons
      (Aman Verma)
   5. Re: sample.Polygons fails for shapes with more than four
      Polygons (Roger Bivand)
   6. Re: cleaning up  a SpatialGridDataFrame (Robert Hijmans)
   7. methods to assess point distributions (ex. random, even,	or
      clumped distributions) (elaine kuo)
   8. Re: methods to assess point distributions (ex. random, even,
      or clumped distributions) (Roman Lu?trik)


----------------------------------------------------------------------

Message: 1
Date: Mon, 07 Mar 2011 14:41:59 +0100
From: Tom Gottfried <tom.gottfried at wzw.tum.de>
To: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] self-starting non linear model
Message-ID: <4D74E0A7.1030101 at wzw.tum.de>
Content-Type: text/plain; charset=ISO-8859-1

Hi Anna,

maybe this more a subject to be discussed on R-help?

Tom

Am 06.03.2011 20:55, schrieb Anna Gretschel:
> Hi List!
> 
> I want to apply a selfstarting Michaelis-Menten-Model to my data:
> SSmicmen {stats}
> 
> I use thist function in the following way:
> model<-nls(distance~SSmicmen(watercontent, Vm, K))
> 
> When I want to compute it I get the error message:
> 
>                                                Fehler in lm.fit(x, y,
> offset = offset, singular.ok = singular.ok, ...) :
>                     

[No se incluye el mensaje original entero]

From marceivissa at gmail.com  Wed Mar  9 13:22:19 2011
From: marceivissa at gmail.com (=?ISO-8859-1?Q?Marc_Mar=ED_Dell=27Olmo?=)
Date: Wed, 9 Mar 2011 13:22:19 +0100
Subject: [R-sig-Geo] shp to svg
Message-ID: <AANLkTi=sTuKuNggpHLez3SxZwFqYwd5xNxZmtfAusYPt@mail.gmail.com>

Dear all,

I would like to convert a map in shp (shapefile arcview format) format
to a svg format with R. Does anyone know how?

Thank you very much,

Marc


From research at georgruss.de  Wed Mar  9 14:45:04 2011
From: research at georgruss.de (Georg =?iso-8859-15?B?UnXf?=)
Date: Wed, 9 Mar 2011 14:45:04 +0100
Subject: [R-sig-Geo] spatial clustering - land usage - skater?
In-Reply-To: <AANLkTi=J3DqZv8HM1iV1eEwukmXrz82erS99vdo4qe66@mail.gmail.com>
References: <AANLkTi=J3DqZv8HM1iV1eEwukmXrz82erS99vdo4qe66@mail.gmail.com>
Message-ID: <20110309134503.GI3311@greode>

On 09/03/11 10:40:00, Mathieu Rajerison wrote:
> I've got a dataset of points that covers a city

Okay, is that a spatial points data frame?

> Each point takes 4 values corresponding to area of land usage. The first one
> is for ground, the second is built, the third is wood, the fourth water.

Here it looks like each point in the spatialpoints data frame has a vector
with four entries. Are those binary entries? I.e., if it's a point for
'ground', is the vector c(1,0,0,0) since the other entries must be zero?
Or is the vector just having one entry, coding one of the four values for
"ground", "built", "wood", "water"?

> I'd like to seggregate components corresponding to each of land usage:
> ground / built / wood / water.

I guess once we get the problem and the data structure sorted out, it
shouldn't be one hell of a problem.

> There may be several components for each category. For example, 2 for
> ground, 3 for water and this might be ajusted by the user.

Hmm, here you're talking about categories, which you didn't mention
before. Please clarify, maybe give us a hint on the data structure.

> What is the most appropriate function to accomplish that?
> I considered using spdep package with skater? Is it the most appropriate?

I wouldn't comment on that unless we've had the problem clarified. So
please help us. If you have, post reproducible code fragments.

Regards,
Georg.
--
Research Assistant
Otto-von-Guericke-Universit?t Magdeburg
research at georgruss.de
http://research.georgruss.de


From research at georgruss.de  Wed Mar  9 14:52:14 2011
From: research at georgruss.de (Georg =?iso-8859-15?B?UnXf?=)
Date: Wed, 9 Mar 2011 14:52:14 +0100
Subject: [R-sig-Geo] shp to svg
In-Reply-To: <AANLkTi=sTuKuNggpHLez3SxZwFqYwd5xNxZmtfAusYPt@mail.gmail.com>
References: <AANLkTi=sTuKuNggpHLez3SxZwFqYwd5xNxZmtfAusYPt@mail.gmail.com>
Message-ID: <20110309135214.GJ3311@greode>

On 09/03/11 13:22:19, Marc Mar? Dell'Olmo wrote:
> I would like to convert a map in shp (shapefile arcview format) format
> to a svg format with R. Does anyone know how?

You probably have to use readShapeSpatial (sp package) to get the data
into R. Then it's likely to be something like a SpatialPoints or similar
data frame which you can plot (or of which you can plot single layers)
using spplot.

I guess the plotting device would then be CairoSVG (Cairo package).

I'm just guessing since you didn't provide further info. Otherwise, you
may also try a decent GIS with a scripting interface to get reproducible
results.

Regards,
Georg.
--
Research Assistant
Otto-von-Guericke-Universit?t Magdeburg
research at georgruss.de
http://research.georgruss.de


From marceivissa at gmail.com  Wed Mar  9 15:02:54 2011
From: marceivissa at gmail.com (=?ISO-8859-1?Q?Marc_Mar=ED_Dell=27Olmo?=)
Date: Wed, 9 Mar 2011 15:02:54 +0100
Subject: [R-sig-Geo] shp to svg
In-Reply-To: <20110309135214.GJ3311@greode>
References: <AANLkTi=sTuKuNggpHLez3SxZwFqYwd5xNxZmtfAusYPt@mail.gmail.com>
	<20110309135214.GJ3311@greode>
Message-ID: <AANLkTimjWZa2tMTtqPxnifHByOwFxTmuCYer4We9XjvK@mail.gmail.com>

Thank you for your help!

I have used the following sintax:

map <-readShapePoly(...)
CairoSVG(file = "newmap.svg", width = 12, height = 12, onefile = TRUE,
bg = "transparent")
plot(map, lwd=0.1)
dev.off()

and it works perfectly.

Regards,

Marc


2011/3/9 Georg Ru? <research at georgruss.de>:
> On 09/03/11 13:22:19, Marc Mar? Dell'Olmo wrote:
>> I would like to convert a map in shp (shapefile arcview format) format
>> to a svg format with R. Does anyone know how?
>
> You probably have to use readShapeSpatial (sp package) to get the data
> into R. Then it's likely to be something like a SpatialPoints or similar
> data frame which you can plot (or of which you can plot single layers)
> using spplot.
>
> I guess the plotting device would then be CairoSVG (Cairo package).
>
> I'm just guessing since you didn't provide further info. Otherwise, you
> may also try a decent GIS with a scripting interface to get reproducible
> results.
>
> Regards,
> Georg.
> --
> Research Assistant
> Otto-von-Guericke-Universit?t Magdeburg
> research at georgruss.de
> http://research.georgruss.de
>


From gianni.lavaredo at gmail.com  Wed Mar  9 15:42:40 2011
From: gianni.lavaredo at gmail.com (gianni lavaredo)
Date: Wed, 9 Mar 2011 15:42:40 +0100
Subject: [R-sig-Geo] Help to eliminate duplicated from data.frame but
	Special Problem
Message-ID: <AANLkTint50rkiKDhCmVtCJJHSNuiQhND1ATgV8RwoBq=@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110309/b200f6d8/attachment.pl>

From sarah.goslee at gmail.com  Wed Mar  9 15:45:48 2011
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 9 Mar 2011 09:45:48 -0500
Subject: [R-sig-Geo] Help to eliminate duplicated from data.frame but
 Special Problem
In-Reply-To: <AANLkTint50rkiKDhCmVtCJJHSNuiQhND1ATgV8RwoBq=@mail.gmail.com>
References: <AANLkTint50rkiKDhCmVtCJJHSNuiQhND1ATgV8RwoBq=@mail.gmail.com>
Message-ID: <AANLkTin7Rta9GdkxG3eWfcSEybvC6EX0Xz0AjecmWXvM@mail.gmail.com>

So you want to look at all rows, not just the index?
Then specify that:

> my.df[!duplicated(my.df),]
   Id value1 value2
1   1     10    100
2   2     20    200
3   3     30    300
4   4     40    400
5   5     50    500
7   6     60    600
8   7     70    700
9   8     80    800
11  8     81    799
12  9     90    900

R will do exactly what you tell it, and only that.

And thank you for including a workable example!

Sarah

On Wed, Mar 9, 2011 at 9:42 AM, gianni lavaredo
<gianni.lavaredo at gmail.com> wrote:
> Dear Reseacher,
> i need to resolve the following problem. I wish to delete duplicate row from
> a data.frame but not all duplicate row:
>
>
> ex:
>
> my.df <- data.frame(Id=c(1,2,3,4,5,5,6,7,8,8,8,9),
> value1=c(10,20,30,40,50,50,60,70,80,80,81,90),
> value2=c(100,200,300,400,500,500,600,700,800,800,799,900))
>
>
>> my.df
> ? Id value1 value2
> 1 ? 1 ? ? 10 ? ?100
> 2 ? 2 ? ? 20 ? ?200
> 3 ? 3 ? ? 30 ? ?300
> 4 ? 4 ? ? 40 ? ?400
> 5 ? 5 ? ? 50 ? ?500
> 6 ? 5 ? ? 50 ? ?500
> 7 ? 6 ? ? 60 ? ?600
> 8 ? 7 ? ? 70 ? ?700
> 9 ? 8 ? ? 80 ? ?800
> 10 ?8 ? ? 80 ? ?800
> 11 ?8 ? ? 81 ? ?799
> 12 ?9 ? ? 90 ? ?900
>
>
> eliminate
>
>> my.df
> ? Id value1 value2
> 1 ? 1 ? ? 10 ? ?100
> 2 ? 2 ? ? 20 ? ?200
> 3 ? 3 ? ? 30 ? ?300
> 4 ? 4 ? ? 40 ? ?400
> 5 ? 5 ? ? 50 ? ?500
> 7 ? 6 ? ? 60 ? ?600
> 8 ? 7 ? ? 70 ? ?700
> 9 ? 8 ? ? 80 ? ?800
> 11 ?8 ? ? 81 ? ?799
> 12 ?9 ? ? 90 ? ?900
>
> but if I use
>
> xx <- ?my.df[!duplicated( my.df$Id), ]
>
> my result is
>
>> xx
> ? Id value1 value2
> 1 ? 1 ? ? 10 ? ?100
> 2 ? 2 ? ? 20 ? ?200
> 3 ? 3 ? ? 30 ? ?300
> 4 ? 4 ? ? 40 ? ?400
> 5 ? 5 ? ? 50 ? ?500
> 7 ? 6 ? ? 60 ? ?600
> 8 ? 7 ? ? 70 ? ?700
> 9 ? 8 ? ? 80 ? ?800
> 12 ?9 ? ? 90 ? ?900
>
>
> thanks in advance
> Gianni
>



-- 
Sarah Goslee
http://www.functionaldiversity.org


From mathieu.rajerison at gmail.com  Wed Mar  9 15:50:38 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Wed, 9 Mar 2011 15:50:38 +0100
Subject: [R-sig-Geo] spatial clustering - land usage - skater?
In-Reply-To: <AANLkTikiS94q_2LmOe97WTjQ6EQX8-1g2MMH3mYESfWu@mail.gmail.com>
References: <AANLkTi=J3DqZv8HM1iV1eEwukmXrz82erS99vdo4qe66@mail.gmail.com>
	<20110309134503.GI3311@greode>
	<AANLkTikiS94q_2LmOe97WTjQ6EQX8-1g2MMH3mYESfWu@mail.gmail.com>
Message-ID: <AANLkTin9QdYWUNNxWqka_gvYB2rNnmXBzBaaR4RdGP+H@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110309/7cb50009/attachment.pl>

From jon.skoien at jrc.ec.europa.eu  Wed Mar  9 15:52:40 2011
From: jon.skoien at jrc.ec.europa.eu (Jon Olav Skoien)
Date: Wed, 09 Mar 2011 15:52:40 +0100
Subject: [R-sig-Geo] Help to eliminate duplicated from data.frame but
 Special Problem
In-Reply-To: <AANLkTint50rkiKDhCmVtCJJHSNuiQhND1ATgV8RwoBq=@mail.gmail.com>
References: <AANLkTint50rkiKDhCmVtCJJHSNuiQhND1ATgV8RwoBq=@mail.gmail.com>
Message-ID: <4D779438.20905@jrc.ec.europa.eu>

Hi Gianni,

 From the example it seems like you want to check if value1 is 
duplicated, not Id:
 > my.df[!duplicated(my.df$value1),]
You can also remove duplicated rows based on the values of more than one 
column:
 > my.df[!duplicated(my.df[,c("Id","value1")]),]
Does any of these do what you want?

Cheers,
Jon


On 3/9/2011 3:42 PM, gianni lavaredo wrote:
> Dear Reseacher,
> i need to resolve the following problem. I wish to delete duplicate row from
> a data.frame but not all duplicate row:
>
>
> ex:
>
> my.df<- data.frame(Id=c(1,2,3,4,5,5,6,7,8,8,8,9),
> value1=c(10,20,30,40,50,50,60,70,80,80,81,90),
> value2=c(100,200,300,400,500,500,600,700,800,800,799,900))
>
>
>> my.df
>     Id value1 value2
> 1   1     10    100
> 2   2     20    200
> 3   3     30    300
> 4   4     40    400
> 5   5     50    500
> 6   5     50    500
> 7   6     60    600
> 8   7     70    700
> 9   8     80    800
> 10  8     80    800
> 11  8     81    799
> 12  9     90    900
>
>
> eliminate
>
>> my.df
>     Id value1 value2
> 1   1     10    100
> 2   2     20    200
> 3   3     30    300
> 4   4     40    400
> 5   5     50    500
> 7   6     60    600
> 8   7     70    700
> 9   8     80    800
> 11  8     81    799
> 12  9     90    900
>
> but if I use
>
> xx<-  my.df[!duplicated( my.df$Id), ]
>
> my result is
>
>> xx
>     Id value1 value2
> 1   1     10    100
> 2   2     20    200
> 3   3     30    300
> 4   4     40    400
> 5   5     50    500
> 7   6     60    600
> 8   7     70    700
> 9   8     80    800
> 12  9     90    900
>
>
> thanks in advance
> Gianni
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From research at georgruss.de  Wed Mar  9 15:58:32 2011
From: research at georgruss.de (Georg =?iso-8859-15?B?UnXf?=)
Date: Wed, 9 Mar 2011 15:58:32 +0100
Subject: [R-sig-Geo] Help to eliminate duplicated from data.frame but
 Special Problem
Message-ID: <20110309145829.GM3311@greode>

On 09/03/11 15:42:40, gianni lavaredo wrote:
> Dear Reseacher,
> i need to resolve the following problem. I wish to delete duplicate row from
> a data.frame but not all duplicate row:
>
> ex:
>
> my.df <- data.frame(Id=c(1,2,3,4,5,5,6,7,8,8,8,9),
> value1=c(10,20,30,40,50,50,60,70,80,80,81,90),
> value2=c(100,200,300,400,500,500,600,700,800,800,799,900))
>
>
> > my.df
>    Id value1 value2
> 1   1     10    100
> 2   2     20    200
> 3   3     30    300
> 4   4     40    400
> 5   5     50    500
> 6   5     50    500
> 7   6     60    600
> 8   7     70    700
> 9   8     80    800
> 10  8     80    800
> 11  8     81    799
> 12  9     90    900

Does "unique(my.df)" solve your issue?

What's this got to do with R-sig-geo, anyway?

Regards,
Georg.
-- 
Research Assistant
Otto-von-Guericke-Universit?t Magdeburg
research at georgruss.de
http://research.georgruss.de


From mathieu.rajerison at gmail.com  Wed Mar  9 16:53:16 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Wed, 9 Mar 2011 16:53:16 +0100
Subject: [R-sig-Geo] spatial clustering - land usage - skater?
In-Reply-To: <AANLkTin9QdYWUNNxWqka_gvYB2rNnmXBzBaaR4RdGP+H@mail.gmail.com>
References: <AANLkTi=J3DqZv8HM1iV1eEwukmXrz82erS99vdo4qe66@mail.gmail.com>
	<20110309134503.GI3311@greode>
	<AANLkTikiS94q_2LmOe97WTjQ6EQX8-1g2MMH3mYESfWu@mail.gmail.com>
	<AANLkTin9QdYWUNNxWqka_gvYB2rNnmXBzBaaR4RdGP+H@mail.gmail.com>
Message-ID: <AANLkTinmvc5F-JndF8G34L9aqDbscMm57kWDVXQ8GWjR@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110309/5340b14f/attachment.pl>

From hacke78 at googlemail.com  Wed Mar  9 17:49:34 2011
From: hacke78 at googlemail.com (Jan Hackenberg)
Date: Wed, 9 Mar 2011 17:49:34 +0100
Subject: [R-sig-Geo] Is there a function for comparing a modeled timeseries
 to the measured one?
Message-ID: <AANLkTikwfLSvSrJwYJyDFgLtdh+QZvGNMjHGWnkO4FdR@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110309/5d266599/attachment.pl>

From aman.verma at mcgill.ca  Wed Mar  9 17:58:58 2011
From: aman.verma at mcgill.ca (Aman Verma)
Date: Wed, 9 Mar 2011 11:58:58 -0500
Subject: [R-sig-Geo] Is there a function for comparing a modeled
 timeseries to the measured one?
In-Reply-To: <AANLkTikwfLSvSrJwYJyDFgLtdh+QZvGNMjHGWnkO4FdR@mail.gmail.com>
References: <AANLkTikwfLSvSrJwYJyDFgLtdh+QZvGNMjHGWnkO4FdR@mail.gmail.com>
Message-ID: <FF83BA46F4BA3C49A1EADAEFE9FD1B4A0A1A3ED57B@EXMBXVS1.campus.mcgill.ca>

Hi Jan,

In general, R-squared can be calculated as the square of the correlation coefficient.

However, read here to understand what R-squared means in this case:
http://en.wikipedia.org/wiki/R-squared#As_squared_correlation_coefficient

aman

-----Original Message-----
From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Jan Hackenberg
Sent: March 9, 2011 11:50 AM
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] Is there a function for comparing a modeled timeseries to the measured one?

Dear R - Users
I have 2 timeseries, one measured and one is modeled. The only function to
compare them  i know is cor(model,measured). Is there perhaps another
function to produce the r squared, to prove that my model is well fit?
Thanks for your time
Jan

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From etiennebr at gmail.com  Wed Mar  9 21:21:39 2011
From: etiennebr at gmail.com (Etienne Bellemare)
Date: Wed, 9 Mar 2011 15:21:39 -0500
Subject: [R-sig-Geo] Variable window on a raster
Message-ID: <AANLkTi=36gFFL_EKr1XuM29eMMp6GcLBMn3WSHYFHQps@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110309/843fac5d/attachment.pl>

From ana-lee at web.de  Wed Mar  9 21:25:12 2011
From: ana-lee at web.de (Anna Gretschel)
Date: Wed, 09 Mar 2011 21:25:12 +0100
Subject: [R-sig-Geo] predicting values from variofit function
Message-ID: <4D77E228.6020500@web.de>

Dear List,

I have fitted a spherical function to my variogram using "variofit(...)" 
from GeoR. Now I would like to predict some data with the function 
"predict(object,...)" from package stats. Does anyone know wether this 
works and if it does how to do it?

Thanks a lot!
Anna


From gsadoti at syr.edu  Wed Mar  9 21:56:15 2011
From: gsadoti at syr.edu (Giancarlo Sadoti)
Date: Wed, 9 Mar 2011 20:56:15 +0000
Subject: [R-sig-Geo] Standardizing Moran's I
Message-ID: <A14FEF5232911A48A6D69F2E74DF832A018A50@SN2PRD0102MB127.prod.exchangelabs.com>

Greeting list members,

I'm analyzing the global spatial autocorrelation of a continuous vegetation attribute (MSH) among multiple (15-30) plots (secondary sampling units) across 76 sites (primary sampling units).  I've used the Moran's I permutation test (moran.mc) in the spdep package to do this.  I've included my code from one of my 76 sites:

----------
> library(spdep)
> head(data)
    EAST   NORTH MSH
1 274276 4818867  70
2 274300 4818942  70
3 274249 4818900  60
4 274258 4818900  60
5 274299 4818900  66
6 274304 4818900  66

> dist=as.matrix(dist(cbind(data$EAST,data$NORTH)))
> inv.dist=1/dist
> diag(inv.dist)=0
> lw=mat2listw(inv.dist)
> m=moran.mc(data$MSH,lw,nsim=1000)
> m

        Monte-Carlo simulation of Moran's I

data:  data$MSH 
weights: lw  
number of simulations + 1: 1001 
 
statistic = 0.1704, observed rank = 999, p-value = 0.001998
alternative hypothesis: greater 

> str(m)
List of 7
 $ statistic  : Named num 0.17
  ..- attr(*, "names")= chr "statistic"
 $ parameter  : Named num 999
  ..- attr(*, "names")= chr "observed rank"
 $ p.value    : num 0.002
 $ alternative: chr "greater"
 $ method     : chr "Monte-Carlo simulation of Moran's I"
 $ data.name  : chr "data$MSH \nweights: lw  \nnumber of simulations + 1: 1001 \n"
 $ res        : num [1:1001] 0.0193 -0.00302 -0.00983 -0.00605 -0.03424 ...
 - attr(*, "class")= chr [1:2] "htest" "mc.sim"

------------

I'm investigating whether the spatial autocorrelation of the attribute across the 76 sites is a strong predictor of an ecological response at each site.  Because sample sizes (and expected values of I) vary across sites (-1/[N-1]; N varies between 15-30), the observed Moran's I at each site appears to be an inappropriate statistic for comparison across sites.   I originally proposed the standardization of Moran's I to z-values using the observed Moran's I (I) and the mean (MEAN_I) and sd of I (SD_I) of the 1,000 simulations:

z = (I - MEAN_I) / SD_I

However, as suspected by a reviewer (and confirmed by looking at my data), most (if not all) of the 76 site distributions of the 1,000 expected values of I deviate from the assumption of a normal distribution (tested using Shapiro-Wilks and Kolmogorov-Smirnov tests); most are right-skewed.  Likewise, the p-value of the statistic is an inappropriate standardization due to both positive and negative autocorrelation across sites.  I've considered using the rank of the statistic within the distribution of expected values, but this seems problematic in a way I can't quite articulate.

Can anyone offer any suggestions for an alternative way to standardize Moran's I values in a situation such as this?  Your input will be greatly appreciated.  My apologies in advance if this has been discussed previously.

Giancarlo


From tom.gottfried at wzw.tum.de  Wed Mar  9 22:39:47 2011
From: tom.gottfried at wzw.tum.de (Tom Gottfried)
Date: Wed, 09 Mar 2011 22:39:47 +0100
Subject: [R-sig-Geo] predicting values from variofit function
In-Reply-To: <4D77E228.6020500@web.de>
References: <4D77E228.6020500@web.de>
Message-ID: <4D77F3A3.7040000@wzw.tum.de>

Hi Anna,

Am 09.03.2011 21:25, schrieb Anna Gretschel:
> Dear List,
>
> I have fitted a spherical function to my variogram using "variofit(...)"
> from GeoR. Now I would like to predict some data with the function
> "predict(object,...)" from package stats.

Note that predict() is a generic function (see
http://cran.r-project.org/doc/manuals/R-intro.html#Object-orientation). 
I don't think there is a method in geoR that does what you want.

> Does anyone know wether this
> works and if it does how to do it?

The package gstat has a method for objects of class gstat (see ?gstat, 
?predict.gstat and the ASDAR book). You can coerce your variogram fit 
from geoR to the respective class used in package gstat with 
as.vgm.variomodel(). You can do kriging with krige.conv() from geoR too. 
But I think you have more options in gstat.

regards,
Tom

>
> Thanks a lot!
> Anna
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Andy.Bunn at wwu.edu  Thu Mar 10 01:18:17 2011
From: Andy.Bunn at wwu.edu (Andy Bunn)
Date: Wed, 9 Mar 2011 16:18:17 -0800
Subject: [R-sig-Geo] long 0-360, shift to -180 to 180
In-Reply-To: <4D77F3A3.7040000@wzw.tum.de>
References: <4D77E228.6020500@web.de> <4D77F3A3.7040000@wzw.tum.de>
Message-ID: <7E6EA3F4372E474F8F3F850DD262FDA9125D914C82@ExchMailbox3.univ.dir.wwu.edu>

I have a raster with longitude data over 0 to 360.

bar <- raster(t(foo[,,1]),xmn=0,xmx=356.25,ymn=-87.159094555863,ymx=87.159094555863,
              crs="+proj=longlat +datum=WGS84")

I'd like to shift those longitudes to -180 to 180. I tried paying with the +long_wrap argument to crs but to no avail. Can somebody help? I'll need to overlay and extract data from the negative side (e.g., 100W or -100) and it would be nice to have the coordinates the same.

Thanks in advance, 
Andy


> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> project.org] On Behalf Of Tom Gottfried
> Sent: Wednesday, March 09, 2011 1:40 PM
> To: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] predicting values from variofit function
> 
> Hi Anna,
> 
> Am 09.03.2011 21:25, schrieb Anna Gretschel:
> > Dear List,
> >
> > I have fitted a spherical function to my variogram using
> "variofit(...)"
> > from GeoR. Now I would like to predict some data with the function
> > "predict(object,...)" from package stats.
> 
> Note that predict() is a generic function (see
> http://cran.r-project.org/doc/manuals/R-intro.html#Object-orientation).
> I don't think there is a method in geoR that does what you want.
> 
> > Does anyone know wether this
> > works and if it does how to do it?
> 
> The package gstat has a method for objects of class gstat (see ?gstat,
> ?predict.gstat and the ASDAR book). You can coerce your variogram fit
> from geoR to the respective class used in package gstat with
> as.vgm.variomodel(). You can do kriging with krige.conv() from geoR
> too.
> But I think you have more options in gstat.
> 
> regards,
> Tom
> 
> >
> > Thanks a lot!
> > Anna
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From delphine.antoniucci at gmail.com  Thu Mar 10 14:23:46 2011
From: delphine.antoniucci at gmail.com (Delphine Antoniucci)
Date: Thu, 10 Mar 2011 14:23:46 +0100
Subject: [R-sig-Geo] CRS problem with Polyset2SpatialPolygons (maptools,
	PBSmapping)
Message-ID: <AANLkTinAhmC7A_0fpeOZF0cbx4qykvYJT8edtX1pzzg2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110310/d25ff335/attachment.pl>

From Roger.Bivand at nhh.no  Thu Mar 10 14:56:08 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 10 Mar 2011 14:56:08 +0100 (CET)
Subject: [R-sig-Geo] CRS problem with Polyset2SpatialPolygons (maptools,
 PBSmapping)
In-Reply-To: <AANLkTinAhmC7A_0fpeOZF0cbx4qykvYJT8edtX1pzzg2@mail.gmail.com>
References: <AANLkTinAhmC7A_0fpeOZF0cbx4qykvYJT8edtX1pzzg2@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1103101441300.6524@reclus.nhh.no>

On Thu, 10 Mar 2011, Delphine Antoniucci wrote:

> Dear all,
>
> Im very new to using the maptools, PBSmapping and sp libraries in R, so Im
> sorry if this is something obvious for most of you.
>
> I have had trouble with passing from a PolySet object to
> SpatialPolygonsDataFrame object. Basically I got two
> SpatialPolygonsDataFrame (SP) objects. I need information about their
> intersections. So I used the function 'joinPolys' (PBSmapping) with the
> operation "INT" after having transformed my SP into Polysets. The problem is
> that I got an error message when I try to transform again the result into a
> SP, due to the CRS to be used.

No, it isn't obvious. PBSmapping "knows" unprojected (geographical 
coordinates) and UTM (projected coordinates) with a zone number. It does 
not provide facilities to store any other values.

>
> Here is the syntax I have used:
>
>>   aaa <- joinPolys(SpatialPolygons2PolySet(mapproj),
> SpatialPolygons2PolySet(piece), operation="INT")
>

So if you examine the projection of:

attr(SpatialPolygons2PolySet(mapproj), "projection")

you'll see that it is set to "1", to signal that it is not "LL" or "UTM". 
This is copied in joinPolys() to the output object.

PolySet2SpatialPolygons() was written assuming that the limitations of the 
PolySet representation of coordinate reference systems should be 
respected. For the future, I'll have it insert as.character(NA) and issue 
a warning.

For now, I suggest using spTransform() in rgdal on the input objects to 
transform them to CRS("+proj=longlat +ellps=GRS80") and back out on 
return. I hope that no datum shift will take place, you'd need to check 
whether the initial and final coordinates matched.

Hope this helps,

Roger

>>   bbb <- as.PolySet(aaa)
>>   bbb <- PolySet2SpatialPolygons(bbb, close_polys=TRUE)
> Erreur dans PolySet2SpatialPolygons(bbb, close_polys = TRUE) :
>  unknown coordinate reference system
>
> I think this is due to a wrong projection attribute. By default, the r ratio
> is 1 (1 x unit per y unit)
>
>>   str(aaa,max.level=2)
> Classes ?PolySet? and 'data.frame':     14 obs. of  5 variables:
> $ PID: int  4651 4651 4651 4651 4651 4651 4651 4651 4651 4651 ...
> $ SID: int  1 1 1 1 1 1 1 1 1 1 ...
> $ POS: int  1 2 3 4 5 6 7 8 9 10 ...
> $ X  : num  485038 485085 485080 485084 485058 ...
> $ Y  : num  6506613 6506550 6506531 6506529 6506441 ...
> - attr(*, "projection")= chr "1"
>
> But the original CRS of the SPs ('mapproj' and 'piece') is:
>
>> print(proj4string(mapproj))
> [1] " +proj=lcc +lat_1=44 +lat_2=49 +lat_0=46.5 +lon_0=3 +x_0=700000
> +y_0=6600000 +ellps=GRS80 +units=m +no_defs"
>
> Would you have any suggestion to stay in this CRS? Should I spTransform() my
> SP in another CSR that is known by PolySet2SpatialPolygons? Or would you
> recommend an easier way of getting the information Im looking for without
> using the class PolySet? Any help/hint will be very appreciated!
>
> Many thanks,
>
> Delphine
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From mloranty at whrc.org  Thu Mar 10 14:58:37 2011
From: mloranty at whrc.org (Michael Loranty)
Date: Thu, 10 Mar 2011 08:58:37 -0500
Subject: [R-sig-Geo] long 0-360, shift to -180 to 180
In-Reply-To: <mailman.17.1299754805.9597.r-sig-geo@r-project.org>
References: <mailman.17.1299754805.9597.r-sig-geo@r-project.org>
Message-ID: <50D7802C-56BD-442B-8B2A-5AC2D53DD5F5@whrc.org>

Hi Andy,

I think the rotate function in the raster package might be what you're  
looking for.

Hope things are well with you.

-Mike

dat <- matrix(data = 1:100, nrow=360, ncol = 360)
 > bar <-  
raster(dat,xmn=0,xmx=356.25,ymn=-87.159094555863,ymx=87.159094555863,
+              crs="+proj=longlat +datum=WGS84")
 > bar
class       : RasterLayer
filename    :
nrow        : 360
ncol        : 360
ncell       : 129600
min value   : 1
max value   : 100
projection  : +proj=longlat +datum=WGS84
extent      : 0, 356.25, -87.1591, 87.1591  (xmin, xmax, ymin, ymax)
resolution  : 0.9895833, 0.4842172  (x, y)

 > bar2 <- rotate(bar)
 > bar2
class       : RasterLayer
filename    :
nrow        : 360
ncol        : 360
ncell       : 129600
min value   : 1
max value   : 100
projection  : +proj=longlat +datum=WGS84
extent      : -178.125, 178.125, -87.1591, 87.1591  (xmin, xmax, ymin,  
ymax)
resolution  : 0.9895833, 0.4842172  (x, y)


On Mar 10, 2011, at 6:00 AM, r-sig-geo-request at r-project.org wrote:

>
> Message: 18
> Date: Wed, 9 Mar 2011 16:18:17 -0800
> From: Andy Bunn <Andy.Bunn at wwu.edu>
> To: "r-sig-geo at r-project.org" <r-sig-geo at r-project.org>
> Subject: [R-sig-Geo] long 0-360, shift to -180 to 180
> Message-ID:
> 	<7E6EA3F4372E474F8F3F850DD262FDA9125D914C82 at ExchMailbox3.univ.dir.wwu.edu 
> >
> 	
> Content-Type: text/plain; charset="us-ascii"
>
> I have a raster with longitude data over 0 to 360.
>
> bar <- raster(t(foo[,, 
> 1]),xmn=0,xmx=356.25,ymn=-87.159094555863,ymx=87.159094555863,
>              crs="+proj=longlat +datum=WGS84")
>
> I'd like to shift those longitudes to -180 to 180. I tried paying  
> with the +long_wrap argument to crs but to no avail. Can somebody  
> help? I'll need to overlay and extract data from the negative side  
> (e.g., 100W or -100) and it would be nice to have the coordinates  
> the same.
>
> Thanks in advance,
> Andy
>
>
>> -----Original Message-----
>> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
>> project.org] On Behalf Of Tom Gottfried
>> Sent: Wednesday, March 09, 2011 1:40 PM
>> To: r-sig-geo at r-project.org
>> Subject: Re: [R-sig-Geo] predicting values from variofit function
>>
>> Hi Anna,
>>
>> Am 09.03.2011 21:25, schrieb Anna Gretschel:
>>> Dear List,
>>>
>>> I have fitted a spherical function to my variogram using
>> "variofit(...)"
>>> from GeoR. Now I would like to predict some data with the function
>>> "predict(object,...)" from package stats.
>>
>> Note that predict() is a generic function (see
>> http://cran.r-project.org/doc/manuals/R-intro.html#Object-orientation) 
>> .
>> I don't think there is a method in geoR that does what you want.
>>
>>> Does anyone know wether this
>>> works and if it does how to do it?
>>
>> The package gstat has a method for objects of class gstat (see ? 
>> gstat,
>> ?predict.gstat and the ASDAR book). You can coerce your variogram fit
>> from geoR to the respective class used in package gstat with
>> as.vgm.variomodel(). You can do kriging with krige.conv() from geoR
>> too.
>> But I think you have more options in gstat.
>>
>> regards,
>> Tom
>>
>>>
>>> Thanks a lot!
>>> Anna
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> End of R-sig-Geo Digest, Vol 91, Issue 10
> *****************************************
>


From Andy.Bunn at wwu.edu  Thu Mar 10 21:59:42 2011
From: Andy.Bunn at wwu.edu (Andy Bunn)
Date: Thu, 10 Mar 2011 12:59:42 -0800
Subject: [R-sig-Geo] long 0-360, shift to -180 to 180
In-Reply-To: <50D7802C-56BD-442B-8B2A-5AC2D53DD5F5@whrc.org>
References: <mailman.17.1299754805.9597.r-sig-geo@r-project.org>
	<50D7802C-56BD-442B-8B2A-5AC2D53DD5F5@whrc.org>
Message-ID: <7E6EA3F4372E474F8F3F850DD262FDA9125D914D2D@ExchMailbox3.univ.dir.wwu.edu>

Ah. That's perfect. Thanks Mike. Raster is a potent library!

> -----Original Message-----
> From: Michael Loranty [mailto:mloranty at whrc.org]
> Sent: Thursday, March 10, 2011 5:59 AM
> To: r-sig-geo; Andy Bunn
> Subject: Re: [R-sig-Geo] long 0-360, shift to -180 to 180
> 
> Hi Andy,
> 
> I think the rotate function in the raster package might be what you're
> looking for.
> 
> Hope things are well with you.
> 
> -Mike
> 
> dat <- matrix(data = 1:100, nrow=360, ncol = 360)
>  > bar <-
> raster(dat,xmn=0,xmx=356.25,ymn=-87.159094555863,ymx=87.159094555863,
> +              crs="+proj=longlat +datum=WGS84")
>  > bar
> class       : RasterLayer
> filename    :
> nrow        : 360
> ncol        : 360
> ncell       : 129600
> min value   : 1
> max value   : 100
> projection  : +proj=longlat +datum=WGS84
> extent      : 0, 356.25, -87.1591, 87.1591  (xmin, xmax, ymin, ymax)
> resolution  : 0.9895833, 0.4842172  (x, y)
> 
>  > bar2 <- rotate(bar)
>  > bar2
> class       : RasterLayer
> filename    :
> nrow        : 360
> ncol        : 360
> ncell       : 129600
> min value   : 1
> max value   : 100
> projection  : +proj=longlat +datum=WGS84
> extent      : -178.125, 178.125, -87.1591, 87.1591  (xmin, xmax, ymin,
> ymax)
> resolution  : 0.9895833, 0.4842172  (x, y)
> 
> 
> On Mar 10, 2011, at 6:00 AM, r-sig-geo-request at r-project.org wrote:
> 
> >
> > Message: 18
> > Date: Wed, 9 Mar 2011 16:18:17 -0800
> > From: Andy Bunn <Andy.Bunn at wwu.edu>
> > To: "r-sig-geo at r-project.org" <r-sig-geo at r-project.org>
> > Subject: [R-sig-Geo] long 0-360, shift to -180 to 180
> > Message-ID:
> >
> 	<7E6EA3F4372E474F8F3F850DD262FDA9125D914C82 at ExchMailbox3.univ.dir
> .wwu.edu
> > >
> >
> > Content-Type: text/plain; charset="us-ascii"
> >
> > I have a raster with longitude data over 0 to 360.
> >
> > bar <- raster(t(foo[,,
> > 1]),xmn=0,xmx=356.25,ymn=-87.159094555863,ymx=87.159094555863,
> >              crs="+proj=longlat +datum=WGS84")
> >
> > I'd like to shift those longitudes to -180 to 180. I tried paying
> > with the +long_wrap argument to crs but to no avail. Can somebody
> > help? I'll need to overlay and extract data from the negative side
> > (e.g., 100W or -100) and it would be nice to have the coordinates
> > the same.
> >
> > Thanks in advance,
> > Andy
> >
> >
> >> -----Original Message-----
> >> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> >> project.org] On Behalf Of Tom Gottfried
> >> Sent: Wednesday, March 09, 2011 1:40 PM
> >> To: r-sig-geo at r-project.org
> >> Subject: Re: [R-sig-Geo] predicting values from variofit function
> >>
> >> Hi Anna,
> >>
> >> Am 09.03.2011 21:25, schrieb Anna Gretschel:
> >>> Dear List,
> >>>
> >>> I have fitted a spherical function to my variogram using
> >> "variofit(...)"
> >>> from GeoR. Now I would like to predict some data with the function
> >>> "predict(object,...)" from package stats.
> >>
> >> Note that predict() is a generic function (see
> >> http://cran.r-project.org/doc/manuals/R-intro.html#Object-
> orientation)
> >> .
> >> I don't think there is a method in geoR that does what you want.
> >>
> >>> Does anyone know wether this
> >>> works and if it does how to do it?
> >>
> >> The package gstat has a method for objects of class gstat (see ?
> >> gstat,
> >> ?predict.gstat and the ASDAR book). You can coerce your variogram
> fit
> >> from geoR to the respective class used in package gstat with
> >> as.vgm.variomodel(). You can do kriging with krige.conv() from geoR
> >> too.
> >> But I think you have more options in gstat.
> >>
> >> regards,
> >> Tom
> >>
> >>>
> >>> Thanks a lot!
> >>> Anna
> >>>
> >>> _______________________________________________
> >>> R-sig-Geo mailing list
> >>> R-sig-Geo at r-project.org
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at r-project.org
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> >
> >
> > ------------------------------
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> >
> > End of R-sig-Geo Digest, Vol 91, Issue 10
> > *****************************************
> >
> 
> 


From ana-lee at web.de  Fri Mar 11 12:19:02 2011
From: ana-lee at web.de (Anna Gretschel)
Date: Fri, 11 Mar 2011 12:19:02 +0100
Subject: [R-sig-Geo] predicting values from model function
Message-ID: <4D7A0526.1070800@web.de>

Dear List,

I have fitted a spherical function to my variogram using "variofit(...)" 
from GeoR. Now I would like to predict some data with the function 
"predict(object,...)" from package stats. Does anyone know wether this 
works and if it does how to do it?

Thanks a lot!
Anna


From linxin at craes.org.cn  Fri Mar 11 12:48:19 2011
From: linxin at craes.org.cn (Xin LIN)
Date: Fri, 11 Mar 2011 19:48:19 +0800 (CST)
Subject: [R-sig-Geo] "Argument is of length 0" when extract values from a
	raster
Message-ID: <20110311114819.554552E796D@craes.org.cn>

Hi everyone,

I am trying to extract values from a raster with various irregular polygons
(say, boundaries of cities). I used the "extract" function in the "raster"
package with the argument weights=T to account for the percentage of each
cell covered by the polygon. It is interesting to find that this function
does not always work. It seems that when the polygon is small and covers only
one or two cells, it stop working with "m(xy)[2] != 2) { : argument is of
length zero". I cannot figure out why. Could you please give me some advice?
I will appreciate any help from you and thanks so much in advance.

P.S. I use the latest version of "raster" package.

Xin


From m.roth at tue.nl  Fri Mar 11 15:59:30 2011
From: m.roth at tue.nl (Roth, M.)
Date: Fri, 11 Mar 2011 15:59:30 +0100
Subject: [R-sig-Geo] replace values in spacetime (STFDF) object
Message-ID: <537D63A47F403248921220090BF9EF9001D793CE42B2@EXCHANGE11.campus.tue.nl>

Hello,

I want to replace specific values in a STFDF object from the spacetime package. 
As example consider the following stfdf object out of the vignette.

sp = cbind(x = c(0,0,1), y = c(0,1,1))
row.names(sp) = paste("point", 1:nrow(sp), sep="")
sp = SpatialPoints(sp)
time = xts(1:4, as.POSIXct("2010-08-05", tz = "GMT")+3600*(10:13))
m = c(10,20,30) # means for each of the 3 point locations
mydata = rnorm(length(sp)*length(time),mean=rep(m, 4))
IDs = paste("ID",1:length(mydata), sep = "_")
mydata = data.frame(values = signif(mydata,3), ID=IDs)
stfdf = STFDF(sp, time, mydata)

Now I want to do something like this:

stfdf[ , 1]@data$values <- stfdf[ , 1]@data$values + 1

I get the following error:

Error in stfdf[, 1]@data$values <- stfdf[, 1]@data$values + 1 : 
  object of type 'S4' is not subsettable

Does anybody know how to do that in a correct way?
Thanks a lot,
Martin Roth

From aman.verma at mcgill.ca  Fri Mar 11 16:12:13 2011
From: aman.verma at mcgill.ca (Aman Verma)
Date: Fri, 11 Mar 2011 10:12:13 -0500
Subject: [R-sig-Geo] "Argument is of length 0" when extract values from
 a	raster
In-Reply-To: <20110311114819.554552E796D@craes.org.cn>
References: <20110311114819.554552E796D@craes.org.cn>
Message-ID: <FF83BA46F4BA3C49A1EADAEFE9FD1B4A0A1A521FBF@EXMBXVS1.campus.mcgill.ca>

Hi Xin,

Yes, I came across this exact problem. The bug has been fixed in the latest release (1.8-0), but it isn't fixed in the stable release (1.7-46).

You can pick up the "latest", by typing:

install.packages("raster", repos="http://R-Forge.R-project.org")

But be sure to either unload the raster library first, or just restart R.

Anyway, if you are interested, the problem was in the .polygonValues function.

.polygonValues <- function(x, p, fun, na.rm=FALSE, weights=FALSE, cellnumbers=FALSE, ...) {
	....
		
			} else {
				rc <- .polygonsToRaster(pp, rc, silent=TRUE)
				xy <- rasterToPoints(rc)[,-3,drop=FALSE] 
				# Before, this line didn't have the drop parameter set to FALSE, so when a single row was extracted (which happened when the shape was "small", just as you suspected), then the object would no longer be a matrix. Later on, the dim function is called on xy, and it will fail, because vectors don't have a dimension. By adding the drop parameter, the function stays as a matrix no matter what.
			}
	.....
}

aman

-----Original Message-----
From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Xin LIN
Sent: March 11, 2011 6:48 AM
To: r-Sig-Geo at r-project.org
Subject: [R-sig-Geo] "Argument is of length 0" when extract values from a raster

Hi everyone,

I am trying to extract values from a raster with various irregular polygons
(say, boundaries of cities). I used the "extract" function in the "raster"
package with the argument weights=T to account for the percentage of each
cell covered by the polygon. It is interesting to find that this function
does not always work. It seems that when the polygon is small and covers only
one or two cells, it stop working with "m(xy)[2] != 2) { : argument is of
length zero". I cannot figure out why. Could you please give me some advice?
I will appreciate any help from you and thanks so much in advance.

P.S. I use the latest version of "raster" package.

Xin

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From aman.verma at mcgill.ca  Fri Mar 11 19:16:46 2011
From: aman.verma at mcgill.ca (Aman Verma)
Date: Fri, 11 Mar 2011 13:16:46 -0500
Subject: [R-sig-Geo] replace values in spacetime (STFDF) object
In-Reply-To: <537D63A47F403248921220090BF9EF9001D793CE42B2@EXCHANGE11.campus.tue.nl>
References: <537D63A47F403248921220090BF9EF9001D793CE42B2@EXCHANGE11.campus.tue.nl>
Message-ID: <FF83BA46F4BA3C49A1EADAEFE9FD1B4A0A1A522113@EXMBXVS1.campus.mcgill.ca>

Hi Martin,
You put the brackets in the wrong place. You want to subset the dataframe, right, not the stfdf object, so:

stfdf at data$values[1] <- stfdf at data$values[1] + 1

would increase the "value" in the first row of the stfdf at data data frame.

stfdf at data[,1] 

would get you the first column of the data frame. If you wanted to increase the whole column by one:

stfdf at data[,1] = stfdf at data[,1] + 1

aman

-----Original Message-----
From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Roth, M.
Sent: March 11, 2011 10:00 AM
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] replace values in spacetime (STFDF) object

Hello,

I want to replace specific values in a STFDF object from the spacetime package. 
As example consider the following stfdf object out of the vignette.

sp = cbind(x = c(0,0,1), y = c(0,1,1))
row.names(sp) = paste("point", 1:nrow(sp), sep="")
sp = SpatialPoints(sp)
time = xts(1:4, as.POSIXct("2010-08-05", tz = "GMT")+3600*(10:13))
m = c(10,20,30) # means for each of the 3 point locations
mydata = rnorm(length(sp)*length(time),mean=rep(m, 4))
IDs = paste("ID",1:length(mydata), sep = "_")
mydata = data.frame(values = signif(mydata,3), ID=IDs)
stfdf = STFDF(sp, time, mydata)

Now I want to do something like this:

stfdf[ , 1]@data$values <- stfdf[ , 1]@data$values + 1

I get the following error:

Error in stfdf[, 1]@data$values <- stfdf[, 1]@data$values + 1 : 
  object of type 'S4' is not subsettable

Does anybody know how to do that in a correct way?
Thanks a lot,
Martin Roth
_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From m.roth at tue.nl  Fri Mar 11 21:16:52 2011
From: m.roth at tue.nl (Roth, M.)
Date: Fri, 11 Mar 2011 21:16:52 +0100
Subject: [R-sig-Geo] replace values in spacetime (STFDF) object
In-Reply-To: <FF83BA46F4BA3C49A1EADAEFE9FD1B4A0A1A522113@EXMBXVS1.campus.mcgill.ca>
References: <537D63A47F403248921220090BF9EF9001D793CE42B2@EXCHANGE11.campus.tue.nl>,
	<FF83BA46F4BA3C49A1EADAEFE9FD1B4A0A1A522113@EXMBXVS1.campus.mcgill.ca>
Message-ID: <537D63A47F403248921220090BF9EF9001D793CE42B5@EXCHANGE11.campus.tue.nl>

Hi,

thank you very much. But actually that is not exactly what I want to do. I want to select a specific time 
range and spatial points and manipulate the corresponding data. When I subset the dataframe I must do
the selection manually and that is not that nice.

Any idea how I could do this?
Cheers, Martin
________________________________________
From: Aman Verma [aman.verma at mcgill.ca]
Sent: Friday, March 11, 2011 7:16 PM
To: Roth, M.; r-sig-geo at r-project.org
Subject: RE: replace values in spacetime (STFDF) object

Hi Martin,
You put the brackets in the wrong place. You want to subset the dataframe, right, not the stfdf object, so:

stfdf at data$values[1] <- stfdf at data$values[1] + 1

would increase the "value" in the first row of the stfdf at data data frame.

stfdf at data[,1]

would get you the first column of the data frame. If you wanted to increase the whole column by one:

stfdf at data[,1] = stfdf at data[,1] + 1

aman

-----Original Message-----
From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Roth, M.
Sent: March 11, 2011 10:00 AM
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] replace values in spacetime (STFDF) object

Hello,

I want to replace specific values in a STFDF object from the spacetime package.
As example consider the following stfdf object out of the vignette.

sp = cbind(x = c(0,0,1), y = c(0,1,1))
row.names(sp) = paste("point", 1:nrow(sp), sep="")
sp = SpatialPoints(sp)
time = xts(1:4, as.POSIXct("2010-08-05", tz = "GMT")+3600*(10:13))
m = c(10,20,30) # means for each of the 3 point locations
mydata = rnorm(length(sp)*length(time),mean=rep(m, 4))
IDs = paste("ID",1:length(mydata), sep = "_")
mydata = data.frame(values = signif(mydata,3), ID=IDs)
stfdf = STFDF(sp, time, mydata)

Now I want to do something like this:

stfdf[ , 1]@data$values <- stfdf[ , 1]@data$values + 1

I get the following error:

Error in stfdf[, 1]@data$values <- stfdf[, 1]@data$values + 1 :
  object of type 'S4' is not subsettable

Does anybody know how to do that in a correct way?
Thanks a lot,
Martin Roth
_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From aman.verma at mcgill.ca  Fri Mar 11 21:54:37 2011
From: aman.verma at mcgill.ca (Aman Verma)
Date: Fri, 11 Mar 2011 15:54:37 -0500
Subject: [R-sig-Geo] replace values in spacetime (STFDF) object
In-Reply-To: <537D63A47F403248921220090BF9EF9001D793CE42B5@EXCHANGE11.campus.tue.nl>
References: <537D63A47F403248921220090BF9EF9001D793CE42B2@EXCHANGE11.campus.tue.nl>,
	<FF83BA46F4BA3C49A1EADAEFE9FD1B4A0A1A522113@EXMBXVS1.campus.mcgill.ca>
	<537D63A47F403248921220090BF9EF9001D793CE42B5@EXCHANGE11.campus.tue.nl>
Message-ID: <FF83BA46F4BA3C49A1EADAEFE9FD1B4A0A1A522242@EXMBXVS1.campus.mcgill.ca>

Hi Martin,

It would be very helpful if you provided a clear example of exactly what you wanted to extract from the object, but I'll make a guess.

As the vignette (of the class STFDF) mentions, you can select a specific time range and spatial points very easily by the normal index mechanism: the first index is the time, and the second is the space.

Continuing the example below, if you run

stfdf

It will give you three spatial points, four times, and 12 data points, one for each space time combination. Now, if you wanted to subset this object to select the just the first two points, and the first two times, then you could simply say:

stfdf[1:2,1:2]

And you'll see that there are exactly two points, two times, and four data points. Now, you might say, I don't want to select the "first" or the "second" time, but I want to select by a certain time itself, like after 11:30 on 2010-08-05. 

Take a look at the class of the stfdf at time object

class(stfdf at time)

You can see that it is a xts object. Check out the help file for this class:

?xts

At the bottom, it gives you some great examples of how to subset these kind of time objects. So, now, you can try using these indices instead of the "number" of the time in your set.

stfdf[,'2010-08-05 11:00:00::2010-08-05 12:00:00']

So that is how to select everything from 11:00 to 12:00 on that day.

Now, you have to figure out how to subset the space object. You should be able to get the idea from above though: read the help files and google how to subset that specific object. You'll then be able to subset by index. Or, you could find all the points within a certain window (created by a SpatialPolygon) and then use the vector of logical as you index.

aman





-----Original Message-----
From: Roth, M. [mailto:m.roth at tue.nl] 
Sent: March 11, 2011 3:17 PM
To: Aman Verma; r-sig-geo at r-project.org
Subject: RE: replace values in spacetime (STFDF) object

Hi,

thank you very much. But actually that is not exactly what I want to do. I want to select a specific time 
range and spatial points and manipulate the corresponding data. When I subset the dataframe I must do
the selection manually and that is not that nice.

Any idea how I could do this?
Cheers, Martin
________________________________________
From: Aman Verma [aman.verma at mcgill.ca]
Sent: Friday, March 11, 2011 7:16 PM
To: Roth, M.; r-sig-geo at r-project.org
Subject: RE: replace values in spacetime (STFDF) object

Hi Martin,
You put the brackets in the wrong place. You want to subset the dataframe, right, not the stfdf object, so:

stfdf at data$values[1] <- stfdf at data$values[1] + 1

would increase the "value" in the first row of the stfdf at data data frame.

stfdf at data[,1]

would get you the first column of the data frame. If you wanted to increase the whole column by one:

stfdf at data[,1] = stfdf at data[,1] + 1

aman

-----Original Message-----
From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Roth, M.
Sent: March 11, 2011 10:00 AM
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] replace values in spacetime (STFDF) object

Hello,

I want to replace specific values in a STFDF object from the spacetime package.
As example consider the following stfdf object out of the vignette.

sp = cbind(x = c(0,0,1), y = c(0,1,1))
row.names(sp) = paste("point", 1:nrow(sp), sep="")
sp = SpatialPoints(sp)
time = xts(1:4, as.POSIXct("2010-08-05", tz = "GMT")+3600*(10:13))
m = c(10,20,30) # means for each of the 3 point locations
mydata = rnorm(length(sp)*length(time),mean=rep(m, 4))
IDs = paste("ID",1:length(mydata), sep = "_")
mydata = data.frame(values = signif(mydata,3), ID=IDs)
stfdf = STFDF(sp, time, mydata)

Now I want to do something like this:

stfdf[ , 1]@data$values <- stfdf[ , 1]@data$values + 1

I get the following error:

Error in stfdf[, 1]@data$values <- stfdf[, 1]@data$values + 1 :
  object of type 'S4' is not subsettable

Does anybody know how to do that in a correct way?
Thanks a lot,
Martin Roth
_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From aman.verma at mcgill.ca  Fri Mar 11 23:28:57 2011
From: aman.verma at mcgill.ca (Aman Verma)
Date: Fri, 11 Mar 2011 17:28:57 -0500
Subject: [R-sig-Geo] replace values in spacetime (STFDF) object
In-Reply-To: <537D63A47F403248921220090BF9EF9001D793CE42B6@EXCHANGE11.campus.tue.nl>
References: <537D63A47F403248921220090BF9EF9001D793CE42B2@EXCHANGE11.campus.tue.nl>,
	<FF83BA46F4BA3C49A1EADAEFE9FD1B4A0A1A522113@EXMBXVS1.campus.mcgill.ca>
	<537D63A47F403248921220090BF9EF9001D793CE42B5@EXCHANGE11.campus.tue.nl>,
	<FF83BA46F4BA3C49A1EADAEFE9FD1B4A0A1A522242@EXMBXVS1.campus.mcgill.ca>
	<537D63A47F403248921220090BF9EF9001D793CE42B6@EXCHANGE11.campus.tue.nl>
Message-ID: <FF83BA46F4BA3C49A1EADAEFE9FD1B4A0A1A5222E3@EXMBXVS1.campus.mcgill.ca>

Hi Martin,

Yeah, you can't replace values like that... here is a way to think about it. Consider:

stfdf[,1] 

This returns a *completely new* spacetime object. You cannot set anything in this object because it has not been assigned to any variable.

So, if you select

stfdf[ , 1]@data$values

You are saying: create a completely new spacetime object and then select the 'data' data frame, and select the 'values' column. Now, if you try to say:

stfdf[,1]@data$values = stfdf at data[,1] + 1

Then you are saying: create a *completely new* spacetime object, select a column on its 'data' dataframe and then try to *assign* some value to this completely new object. But you haven't assigned this new object to any variable! So how can you assign a value in it? It would be like saying

c(1,2,3) <- c(4,5,6)

You could say:

x=c(1,2,3)
x=c(4,5,6)

In the same way, you can't assign a value to a variable that hasn't already been 'set' somewhere. (It is a little more complicated than that, but it is a good way to think about it). So, if you wanted, you could do 

x=stfdf[,1]@data$values
x=stfdf[,1]@data$values +1

But that isn't what you want. Your problem is that you want to change a subset of the *data frame that exists within stfdf*. The only way to assign to that data frame is to index to it directly.

stfdf at data[*some row*,*some column*]  = whatever.

But the problem is that you don't know which rows and columns correspond to the time and space subset you want, right? So you find those rows with some comparisons. So, first try just taking the subset you want

stfdf[,'2010-08-05 11:00:00::2010-08-05 12:00:00']

Now, you'll notice that it only retained the data for the time that you subsetted. You can use the column ID to set the values in the original! So,

subset.ids = stfdf[,'2010-08-05 11:00:00::2010-08-05 12:00:00']@data$ID
# That will get you a list of the IDS of the rows you want to change.
stfdf at data$ID %in% subset.ids
# That is a list of true and false, TRUE where your data frame row is in the subset, and FALSE when it is not

You can use this vectors of logicals to change the values you want, and not the others. Like say you wanted to increase the value of just the subset by one:

subset= stfdf at data$ID %in% subset.ids
stfdf at data[subset,'value'] = stfdf at data[subset,'value'] + 1

Now, you could argue that doesn't stfdf at data[subset,'value'] return a *completely new* object, that cannot be assigned to? The answer is no. It appears that for simple objects, like data.frames, you can assign things in this way, but for complex objects, like spacetime objects, you can't. I don't know exactly why... my intuition is that it would be very complicated to allow this behaviour. I think this is what the error is trying to tell you: spacetime is an 'S4' object, which is not subsettable like a data frame is.

aman

-----Original Message-----
From: Roth, M. [mailto:m.roth at tue.nl] 
Sent: March 11, 2011 4:14 PM
To: Aman Verma
Subject: RE: replace values in spacetime (STFDF) object

Dear Aman,

sorry, I thought the example in the first mail would explain what I want to do. But yes,  I can subset my stfdf object by this:

stfdf[ , 1]@data$values (thats all points for the first time) 

So I just get three values - but if I try to replace this values by other three values I get the error I mentioned below. 
My problem is also not subsetting the stfdf object in the right manner but replace the data with other data.

Do you know why this is different from selecting values?

Cheers,
Martin
________________________________________
From: Aman Verma [aman.verma at mcgill.ca]
Sent: Friday, March 11, 2011 9:54 PM
To: Roth, M.; r-sig-geo at r-project.org
Subject: RE: replace values in spacetime (STFDF) object

Hi Martin,

It would be very helpful if you provided a clear example of exactly what you wanted to extract from the object, but I'll make a guess.

As the vignette (of the class STFDF) mentions, you can select a specific time range and spatial points very easily by the normal index mechanism: the first index is the time, and the second is the space.

Continuing the example below, if you run

stfdf

It will give you three spatial points, four times, and 12 data points, one for each space time combination. Now, if you wanted to subset this object to select the just the first two points, and the first two times, then you could simply say:

stfdf[1:2,1:2]

And you'll see that there are exactly two points, two times, and four data points. Now, you might say, I don't want to select the "first" or the "second" time, but I want to select by a certain time itself, like after 11:30 on 2010-08-05.

Take a look at the class of the stfdf at time object

class(stfdf at time)

You can see that it is a xts object. Check out the help file for this class:

?xts

At the bottom, it gives you some great examples of how to subset these kind of time objects. So, now, you can try using these indices instead of the "number" of the time in your set.

stfdf[,'2010-08-05 11:00:00::2010-08-05 12:00:00']

So that is how to select everything from 11:00 to 12:00 on that day.

Now, you have to figure out how to subset the space object. You should be able to get the idea from above though: read the help files and google how to subset that specific object. You'll then be able to subset by index. Or, you could find all the points within a certain window (created by a SpatialPolygon) and then use the vector of logical as you index.

aman





-----Original Message-----
From: Roth, M. [mailto:m.roth at tue.nl]
Sent: March 11, 2011 3:17 PM
To: Aman Verma; r-sig-geo at r-project.org
Subject: RE: replace values in spacetime (STFDF) object

Hi,

thank you very much. But actually that is not exactly what I want to do. I want to select a specific time
range and spatial points and manipulate the corresponding data. When I subset the dataframe I must do
the selection manually and that is not that nice.

Any idea how I could do this?
Cheers, Martin
________________________________________
From: Aman Verma [aman.verma at mcgill.ca]
Sent: Friday, March 11, 2011 7:16 PM
To: Roth, M.; r-sig-geo at r-project.org
Subject: RE: replace values in spacetime (STFDF) object

Hi Martin,
You put the brackets in the wrong place. You want to subset the dataframe, right, not the stfdf object, so:

stfdf at data$values[1] <- stfdf at data$values[1] + 1

would increase the "value" in the first row of the stfdf at data data frame.

stfdf at data[,1]

would get you the first column of the data frame. If you wanted to increase the whole column by one:

stfdf at data[,1] = stfdf at data[,1] + 1

aman

-----Original Message-----
From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Roth, M.
Sent: March 11, 2011 10:00 AM
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] replace values in spacetime (STFDF) object

Hello,

I want to replace specific values in a STFDF object from the spacetime package.
As example consider the following stfdf object out of the vignette.

sp = cbind(x = c(0,0,1), y = c(0,1,1))
row.names(sp) = paste("point", 1:nrow(sp), sep="")
sp = SpatialPoints(sp)
time = xts(1:4, as.POSIXct("2010-08-05", tz = "GMT")+3600*(10:13))
m = c(10,20,30) # means for each of the 3 point locations
mydata = rnorm(length(sp)*length(time),mean=rep(m, 4))
IDs = paste("ID",1:length(mydata), sep = "_")
mydata = data.frame(values = signif(mydata,3), ID=IDs)
stfdf = STFDF(sp, time, mydata)

Now I want to do something like this:

stfdf[ , 1]@data$values <- stfdf[ , 1]@data$values + 1

I get the following error:

Error in stfdf[, 1]@data$values <- stfdf[, 1]@data$values + 1 :
  object of type 'S4' is not subsettable

Does anybody know how to do that in a correct way?
Thanks a lot,
Martin Roth
_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From edzer.pebesma at uni-muenster.de  Sat Mar 12 00:19:03 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sat, 12 Mar 2011 00:19:03 +0100
Subject: [R-sig-Geo] replace values in spacetime (STFDF) object
In-Reply-To: <FF83BA46F4BA3C49A1EADAEFE9FD1B4A0A1A522242@EXMBXVS1.campus.mcgill.ca>
References: <537D63A47F403248921220090BF9EF9001D793CE42B2@EXCHANGE11.campus.tue.nl>,
	<FF83BA46F4BA3C49A1EADAEFE9FD1B4A0A1A522113@EXMBXVS1.campus.mcgill.ca>	<537D63A47F403248921220090BF9EF9001D793CE42B5@EXCHANGE11.campus.tue.nl>
	<FF83BA46F4BA3C49A1EADAEFE9FD1B4A0A1A522242@EXMBXVS1.campus.mcgill.ca>
Message-ID: <4D7AADE7.9050704@uni-muenster.de>

What Martin wants, replacing a subset, is not possible for STFDF (or
other ST*) objects, just as with Spatial* objects:

library(sp)
data(meuse)
coordinates(meuse)=~x+y
meuse[1, "zinc"] = 500
Error in meuse[1, "zinc"] = 500 : object of type 'S4' is not subsettable

Indeed, as Aman suggests, this could be done by subsetting the
data.frame slot, and

meuse$zinc[1] = 500

is a nice/short form for

meuse at data$zinc[1] = 500.

the second form,

meuse$zinc[1] = 500

really calls function "[<-.data.frame"

whereas

meuse[1,"zinc"]<-500 tries to call "[<-.SpatialPointsDataFrame", which
is not available.

The same is true for "[<-.STFDF".

It would be helpful to get some more information why you would need to
do such replacement. For the Spatial* classes this request is very rare,
but in space-time everything might be different, and we'd like to hear
the how/why.

Best regards,

On 03/11/2011 09:54 PM, Aman Verma wrote:
> Hi Martin,
> 
> It would be very helpful if you provided a clear example of exactly what you wanted to extract from the object, but I'll make a guess.
> 
> As the vignette (of the class STFDF) mentions, you can select a specific time range and spatial points very easily by the normal index mechanism: the first index is the time, and the second is the space.
> 
> Continuing the example below, if you run
> 
> stfdf
> 
> It will give you three spatial points, four times, and 12 data points, one for each space time combination. Now, if you wanted to subset this object to select the just the first two points, and the first two times, then you could simply say:
> 
> stfdf[1:2,1:2]
> 
> And you'll see that there are exactly two points, two times, and four data points. Now, you might say, I don't want to select the "first" or the "second" time, but I want to select by a certain time itself, like after 11:30 on 2010-08-05. 
> 
> Take a look at the class of the stfdf at time object
> 
> class(stfdf at time)
> 
> You can see that it is a xts object. Check out the help file for this class:
> 
> ?xts
> 
> At the bottom, it gives you some great examples of how to subset these kind of time objects. So, now, you can try using these indices instead of the "number" of the time in your set.
> 
> stfdf[,'2010-08-05 11:00:00::2010-08-05 12:00:00']
> 
> So that is how to select everything from 11:00 to 12:00 on that day.
> 
> Now, you have to figure out how to subset the space object. You should be able to get the idea from above though: read the help files and google how to subset that specific object. You'll then be able to subset by index. Or, you could find all the points within a certain window (created by a SpatialPolygon) and then use the vector of logical as you index.
> 
> aman
> 
> 
> 
> 
> 
> -----Original Message-----
> From: Roth, M. [mailto:m.roth at tue.nl] 
> Sent: March 11, 2011 3:17 PM
> To: Aman Verma; r-sig-geo at r-project.org
> Subject: RE: replace values in spacetime (STFDF) object
> 
> Hi,
> 
> thank you very much. But actually that is not exactly what I want to do. I want to select a specific time 
> range and spatial points and manipulate the corresponding data. When I subset the dataframe I must do
> the selection manually and that is not that nice.
> 
> Any idea how I could do this?
> Cheers, Martin
> ________________________________________
> From: Aman Verma [aman.verma at mcgill.ca]
> Sent: Friday, March 11, 2011 7:16 PM
> To: Roth, M.; r-sig-geo at r-project.org
> Subject: RE: replace values in spacetime (STFDF) object
> 
> Hi Martin,
> You put the brackets in the wrong place. You want to subset the dataframe, right, not the stfdf object, so:
> 
> stfdf at data$values[1] <- stfdf at data$values[1] + 1
> 
> would increase the "value" in the first row of the stfdf at data data frame.
> 
> stfdf at data[,1]
> 
> would get you the first column of the data frame. If you wanted to increase the whole column by one:
> 
> stfdf at data[,1] = stfdf at data[,1] + 1
> 
> aman
> 
> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Roth, M.
> Sent: March 11, 2011 10:00 AM
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] replace values in spacetime (STFDF) object
> 
> Hello,
> 
> I want to replace specific values in a STFDF object from the spacetime package.
> As example consider the following stfdf object out of the vignette.
> 
> sp = cbind(x = c(0,0,1), y = c(0,1,1))
> row.names(sp) = paste("point", 1:nrow(sp), sep="")
> sp = SpatialPoints(sp)
> time = xts(1:4, as.POSIXct("2010-08-05", tz = "GMT")+3600*(10:13))
> m = c(10,20,30) # means for each of the 3 point locations
> mydata = rnorm(length(sp)*length(time),mean=rep(m, 4))
> IDs = paste("ID",1:length(mydata), sep = "_")
> mydata = data.frame(values = signif(mydata,3), ID=IDs)
> stfdf = STFDF(sp, time, mydata)
> 
> Now I want to do something like this:
> 
> stfdf[ , 1]@data$values <- stfdf[ , 1]@data$values + 1
> 
> I get the following error:
> 
> Error in stfdf[, 1]@data$values <- stfdf[, 1]@data$values + 1 :
>   object of type 'S4' is not subsettable
> 
> Does anybody know how to do that in a correct way?
> Thanks a lot,
> Martin Roth
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From m.roth at tue.nl  Sat Mar 12 18:57:04 2011
From: m.roth at tue.nl (Roth, M.)
Date: Sat, 12 Mar 2011 18:57:04 +0100
Subject: [R-sig-Geo] replace values in spacetime (STFDF) object
Message-ID: <537D63A47F403248921220090BF9EF9001D793CE42BA@EXCHANGE11.campus.tue.nl>

Hi,

thanks a lot for the explanation. My motivation is to do some sort of space-time bootstrapping.
Probably this is a big misuse of the spacetime package as I loose the correct time but I want
to use the procedure I am using for the original sample also for the bootstrapped ones. And at
the moment I don't know another way for keeping the spatial dependencies.
But the way with the logical vector is fine - and if you have any other suggestions (for the whole
bootstrapping thing) please let me know.

Cheers,
Martin  

From liuxd8510 at gmail.com  Sat Mar 12 21:00:09 2011
From: liuxd8510 at gmail.com (Xudong)
Date: Sat, 12 Mar 2011 15:00:09 -0500
Subject: [R-sig-Geo] Prediction based on spatial regression models
Message-ID: <AANLkTinjNtSwKhunTMZou2hb0-SXUPwE9Ou+xOYFnEOb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110312/19502957/attachment.pl>

From sharonb_m at yahoo.com  Sun Mar 13 17:22:05 2011
From: sharonb_m at yahoo.com (Sharon Baruch-Mordo)
Date: Sun, 13 Mar 2011 09:22:05 -0700 (PDT)
Subject: [R-sig-Geo] SpatialLines2PolySet with Albers equal area projection?
Message-ID: <815436.45767.qm@web43138.mail.sp1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110313/896b0559/attachment.pl>

From Roger.Bivand at nhh.no  Sun Mar 13 18:11:30 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 13 Mar 2011 18:11:30 +0100 (CET)
Subject: [R-sig-Geo] SpatialLines2PolySet with Albers equal area
 projection?
In-Reply-To: <815436.45767.qm@web43138.mail.sp1.yahoo.com>
References: <815436.45767.qm@web43138.mail.sp1.yahoo.com>
Message-ID: <alpine.LRH.2.00.1103131806430.22948@reclus.nhh.no>

On Sun, 13 Mar 2011, Sharon Baruch-Mordo wrote:

> Hello list,
> ??
> I???m trying to create a SpatialPolygonsDataFrame from an object of class list
> (x), which has coordinates for contour lines in Albers equal area (full
> parameters below). I???m executing the following code:
> ??
> CRSdata <- "+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=37.5 +lon_0=-96 +x_0=0
> +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs +towgs84=0,0,0"
> sldf <- ContourLines2SLDF(x)
> proj4string(sldf) <- CRS(CRSdata)
> ps <- SpatialLines2PolySet(sldf)
> ??
> #so far so good; continue:
> ??
> sp <- PolySet2SpatialPolygons(ps)
> ??
> # I get the following error:
> ??
> Error in PolySet2SpatialPolygons(ps) : unknown coordinate reference system

As was explained in thread starting at:

https://stat.ethz.ch/pipermail/r-sig-geo/2011-March/011152.html

"PBSmapping "knows" unprojected (geographical coordinates) and UTM 
(projected coordinates) with a zone number. It does not provide facilities 
to store any other values."

So unless you project to utm or longlat first and back again afterwards, 
you are stuck. ?PolySet does state the limitation.

Roger

> ??
> #what I was hoping to continue executing (which works great with UTM data sets
> where I defined attr(ps,???projection???) <- ???UTM??? and attr(ps,???zone???) <- ???17N???)
> ??is:
> ??
> dataframe <- as.data.frame(matrix(as.character(1,nrow=1,ncol=1)))
> spdf <- SpatialPolygonsDataFrame(sp,dataframe,match.ID=TRUE)
> ??
> Because Albers isn???t ???UTM??? nor ???LL??? I???m not sure what projection to specify for
> the PolySet object (i.e., attr(ps,???projection???)) in order to properly convert
> PolySet2SpatialPolygons. Any thoughts or suggestions??? I would also welcome any
> comments if I???m using an unnecessary long code to convert the list of contour
> line x/y points into a spatial polygon with the goal of calculating its area in
> R and exporting it into an ESRI shapefile.
> ??
> Thanks!
> Sharon
> ??
> Sharon Baruch-Mordo
> Ph.D. Candidate in Ecology
> Dept. of Fish, Wildlife, and Conservation??Biology
> Colorado State University
> Fort Collins, CO 80523-1474
> Phone: 970-491-7020??
> Fax: 970-491-5091
> E-mail: sharonbm at warnercnr.colostate.edu
> http://www.warnercnr.colostate.edu/research/bear
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From momadou at yahoo.fr  Sun Mar 13 18:33:44 2011
From: momadou at yahoo.fr (Komine)
Date: Sun, 13 Mar 2011 10:33:44 -0700 (PDT)
Subject: [R-sig-Geo] Open raster _ extract pixel value
Message-ID: <1300037624669-6166730.post@n2.nabble.com>

Hi, 
I begin to work with R software to treat raster data. 
Now, I have a NDVI image with a tiff extension. I want to open this image
and to extract NDVI value for some pixel which I have their coordinates. 
1-	Please what is the code to open a tiff image with R ?
2-	How to extract the value of some pixel which I have their coordinate ? 
NB: I hope you understand my questions with my bad English. 
Thank you 


--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Open-raster-extract-pixel-value-tp6166730p6166730.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From roman.lustrik at gmail.com  Sun Mar 13 18:36:37 2011
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Sun, 13 Mar 2011 18:36:37 +0100
Subject: [R-sig-Geo] Open raster _ extract pixel value
In-Reply-To: <1300037624669-6166730.post@n2.nabble.com>
References: <1300037624669-6166730.post@n2.nabble.com>
Message-ID: <AANLkTimWwp2hzkEzLjVfR0yzZg=Hn3=0cY8pJLEzpekh@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110313/857c7de9/attachment.pl>

From Roger.Bivand at nhh.no  Sun Mar 13 18:51:01 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 13 Mar 2011 18:51:01 +0100 (CET)
Subject: [R-sig-Geo] Open raster _ extract pixel value
In-Reply-To: <AANLkTimWwp2hzkEzLjVfR0yzZg=Hn3=0cY8pJLEzpekh@mail.gmail.com>
References: <1300037624669-6166730.post@n2.nabble.com>
	<AANLkTimWwp2hzkEzLjVfR0yzZg=Hn3=0cY8pJLEzpekh@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1103131845330.22948@reclus.nhh.no>

On Sun, 13 Mar 2011, Roman Lu?trik wrote:

> See package raster and its extensive documentation.
>
>
> Cheers,
> Roman
>

An oblique remark - a translation of the Spatial task view page into 
Belorussian by Amanda Lynn is at:

http://webhostingrating.com/libs/analysis-of-spatial-data-be

If other translations became available (volunteers welcome), perhaps the 
ctv Task View mechanism could be internationalised?

Roger

>
>
> On Sun, Mar 13, 2011 at 6:33 PM, Komine <momadou at yahoo.fr> wrote:
>
>> Hi,
>> I begin to work with R software to treat raster data.
>> Now, I have a NDVI image with a tiff extension. I want to open this image
>> and to extract NDVI value for some pixel which I have their coordinates.
>> 1-      Please what is the code to open a tiff image with R ?
>> 2-      How to extract the value of some pixel which I have their
>> coordinate ?
>> NB: I hope you understand my questions with my bad English.
>> Thank you
>>
>>
>> --
>> View this message in context:
>> http://r-sig-geo.2731867.n2.nabble.com/Open-raster-extract-pixel-value-tp6166730p6166730.html
>> Sent from the R-sig-geo mailing list archive at Nabble.com.
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From momadou at yahoo.fr  Sun Mar 13 21:33:20 2011
From: momadou at yahoo.fr (Komine)
Date: Sun, 13 Mar 2011 13:33:20 -0700 (PDT)
Subject: [R-sig-Geo] Open raster _ extract pixel value
In-Reply-To: <1300037624669-6166730.post@n2.nabble.com>
References: <1300037624669-6166730.post@n2.nabble.com>
Message-ID: <1300048400179-6167068.post@n2.nabble.com>

Thank for your answers,
 But I don't arrive to open my raster.After to download raster package, I
tried this code to open my raster but, there is an error:
My code=
r<-read.raster("C:\\Users\\Komine\\Desktop\\MODIS\\MYD09GQ.A2010280.h16v07.005.2010282160347.sur_refl_b01_1.tif",package="raster")

Please, where is the error?
Thanks again.  

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Open-raster-extract-pixel-value-tp6166730p6167068.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From roman.lustrik at gmail.com  Sun Mar 13 21:51:52 2011
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Sun, 13 Mar 2011 21:51:52 +0100
Subject: [R-sig-Geo] Open raster _ extract pixel value
In-Reply-To: <1300048400179-6167068.post@n2.nabble.com>
References: <1300037624669-6166730.post@n2.nabble.com>
	<1300048400179-6167068.post@n2.nabble.com>
Message-ID: <AANLkTik35pK+wnNFnLQ-TAq7RD2DG7FE5dt1415X5mQS@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110313/9571f6b2/attachment.pl>

From gos47 at hotmail.com  Sun Mar 13 22:11:11 2011
From: gos47 at hotmail.com (=?iso-8859-1?Q?Gaspar_Reyes_P=F3ndigo?=)
Date: Sun, 13 Mar 2011 15:11:11 -0600
Subject: [R-sig-Geo] Open raster _ extract pixel value
Message-ID: <BLU0-SMTP795827539AF1571FA8F00AB7CD0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110313/1e4280ac/attachment.pl>

From momadou at yahoo.fr  Sun Mar 13 23:27:08 2011
From: momadou at yahoo.fr (Komine)
Date: Sun, 13 Mar 2011 15:27:08 -0700 (PDT)
Subject: [R-sig-Geo] Open raster _ extract pixel value
In-Reply-To: <AANLkTimWwp2hzkEzLjVfR0yzZg=Hn3=0cY8pJLEzpekh@mail.gmail.com>
References: <1300037624669-6166730.post@n2.nabble.com>
	<AANLkTimWwp2hzkEzLjVfR0yzZg=Hn3=0cY8pJLEzpekh@mail.gmail.com>
Message-ID: <1300055228425-6167299.post@n2.nabble.com>

Dear all,
I tried your suggestion doing this:

library(raster)
myobject <-
raster("C:\\Users\\komine\\Desktop\\MODIS\\MYD09GQ.A2010280.h16v07.005.2010282160347.sur_refl_b01_1.tif")
e <- extent(-90, -32, -60, 15)
r <-
crop("C:\\Users\\komine\\Desktop\\MODIS\\MYD09GQ.A2010280.h16v07.005.2010282160347.sur_refl_b01_1.tif",e)
plot(myobject)

the result is here:
> library(raster)
> myobject <-
> raster("C:\\Users\\komine\\Desktop\\MODIS\\MYD09GQ.A2010280.h16v07.005.2010282160347.sur_refl_b01_1.tif")
Fixing "AREA_OR_POINT=Point" georeference
> e <- extent(-90, -32, -60, 15)
> r <-
> crop("C:\\Users\\komine\\Desktop\\MODIS\\MYD09GQ.A2010280.h16v07.005.2010282160347.sur_refl_b01_1.tif",e)
Erreur dans function (classes, fdef, mtable)  :
  unable to find an inherited method for function "crop", for signature
"character"
> plot(myobject)

However the raster appear in spite of the previous error message.
1- I suppose that I did an error although R read my raster?
2- Could you explain me the meaning of: extent(-90, -32, -60, 15)

Thanks for your help


--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Open-raster-extract-pixel-value-tp6166730p6167299.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From etiennebr at gmail.com  Sun Mar 13 23:41:11 2011
From: etiennebr at gmail.com (Etienne Bellemare)
Date: Sun, 13 Mar 2011 18:41:11 -0400
Subject: [R-sig-Geo] Open raster _ extract pixel value
In-Reply-To: <1300055228425-6167299.post@n2.nabble.com>
References: <1300037624669-6166730.post@n2.nabble.com>
	<AANLkTimWwp2hzkEzLjVfR0yzZg=Hn3=0cY8pJLEzpekh@mail.gmail.com>
	<1300055228425-6167299.post@n2.nabble.com>
Message-ID: <AANLkTikiktwaK9-gsGPepHM4rfcggvUfKc2-_Y8oasjp@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110313/d6d0ba52/attachment.pl>

From r.hijmans at gmail.com  Mon Mar 14 00:48:03 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Sun, 13 Mar 2011 16:48:03 -0700 (PDT)
Subject: [R-sig-Geo] Variable window on a raster
In-Reply-To: <AANLkTi=36gFFL_EKr1XuM29eMMp6GcLBMn3WSHYFHQps@mail.gmail.com>
References: <AANLkTi=36gFFL_EKr1XuM29eMMp6GcLBMn3WSHYFHQps@mail.gmail.com>
Message-ID: <1300060083109-6167442.post@n2.nabble.com>

Etienne, 

What you are doing makes sense to me. To avoid border problems, perhaps you
can first 'expand' the input raster by adding sufficient rows and columns at
each side such that there are no relevant cells within the filter when it
reaches the border. 

By the way, here:

> r2 <- focal(r, nb=2, fun=vf) 
nb should be ngb, and typically ngb would not be an even number.

Robert

> I'd like to vary the size of my window on a moving window filter. The size 
> of the radius is set by a function of the center pixel (the current pixel 
> processed). I picked the raster package, but as focal() is using a fix 
> radius for the analysis, I thought I could use a large radius and apply a 
> function according to the value of the center pixel inside the raster.
> Now, 
> when reaching the borders of the raster, it's hard to tell where's the 
> center pixel or what's the value of the current pixel processed. 
> 
> I did a little code to illustrate the problem of finding the center : 
> 
> library(raster) 
> r <- raster(matrix(1:25, nrow=5)) 
> 
> vf <- function(x, ...){ 
>   x[length(x)/2+.5] # that' how I (wrongly) find the center pixel 
> } 
> 
> r2 <- focal(r, nb=2, fun=vf) 
> # result : 
> as.matrix(r2-r) 
> 
> 
> #     [,1] [,2] [,3] [,4] [,5] 
> #[1,]    1    0    0    0   -4 
> #[2,]    1    0    0    0   -4 
> #[3,]    1    0    0    0   -4 
> #[4,]    1    0    0    0   -4 
> #[5,]    0   -1   -1   -1   -5 
> 
> 
> Do you know any way I could implement my function or if such a
> functionality 
> is already implemented in another package ? 
> 
> Thanks, 
> Etienne 

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Variable-window-on-a-raster-tp6155312p6167442.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From r.hijmans at gmail.com  Mon Mar 14 00:52:49 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Sun, 13 Mar 2011 16:52:49 -0700 (PDT)
Subject: [R-sig-Geo] Open raster _ extract pixel value
In-Reply-To: <1300055228425-6167299.post@n2.nabble.com>
References: <1300037624669-6166730.post@n2.nabble.com>
	<AANLkTimWwp2hzkEzLjVfR0yzZg=Hn3=0cY8pJLEzpekh@mail.gmail.com>
	<1300055228425-6167299.post@n2.nabble.com>
Message-ID: <1300060369233-6167448.post@n2.nabble.com>

> I tried your suggestion doing this: 
> library(raster) 
> myobject
> <-raster("C:\\Users\\komine\\Desktop\\MODIS\\MYD09GQ.A2010280.h16v07.005.2010282160347.sur_refl_b01_1.tif") 
> e <- extent(-90, -32, -60, 15) 
> r <-
> crop("C:\\Users\\komine\\Desktop\\MODIS\\MYD09GQ.A2010280.h16v07.005.2010282160347.sur_refl_b01_1.tif",e) 
> plot(myobject) 

Komine, you can do:

library(raster) 
myobject
<-raster("C:\\Users\\komine\\Desktop\\MODIS\\MYD09GQ.A2010280.h16v07.005.2010282160347.sur_refl_b01_1.tif") 
plot(myobject)
click(myobject)   # and click somewhere on the map to get the value at that
location 
myobject[1]  # value of first cell
myobject[10,10]  # value of cell at row 10, column 10
extract(myobject, cbind(0,0))  # value at coordinates (0,0) (perhaps not on
your map)
?extract # for more info. 

Robert



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Open-raster-extract-pixel-value-tp6166730p6167448.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From v8extra at gmail.com  Mon Mar 14 01:14:01 2011
From: v8extra at gmail.com (=?iso-8859-1?Q?S=E9bastien_Durand?=)
Date: Sun, 13 Mar 2011 20:14:01 -0400
Subject: [R-sig-Geo] R2 values from SSErr fit.variogram attribute
Message-ID: <A4BAB50B-4C91-4022-BEBF-D6F5F433DE8F@gmail.com>

Hello to all, 

My problem is that I am trying to use R as a remplacement for a software not wanted any more.

What I am trying to do is 
1- Compute variogram model
2- Compare the result I get with R and the ones I am having with the other software.
3- See if I get better fit with R then with the other software.

1) So the first step is easy. I can provide you with my data if you wish but I dont know how to send it to the list.
2) In order for me to be able to compare both model (R and Software), I need the following information to be computed from R

?      Residual Sums of Squares (I beleive the software is using ordinary least square, not sure and that is my problem)
?      R2 value 

To find a solution I need your help!
I have been reading the Gstat manual, the vignette("gstat"), the r-geo-list... but I am still confused and 
I wish to know if I am in the rigth path.

So from my understanding, when "fit.variogram" is used, an SSErr value is computed an attributed to the output and that value will change based on the fit.method that is used
The default is 7 for the fit.method (weigthed least squares).

I guess the SSErr means Sum of Squared Errors (residuals I guess)?

I have found one answer on the list to help me compute the R2 from a fit.variogram that has used the fit.method=7...

Here it is for fit.method 7: 

r2findWLS <-function(fit, vario){
	# fit = fit.variogram output
	# vario = variogram output

	SSErr<-attr(fit,"SSErr")
	weig<-vario$np/vario$dist^2  
	# default method uses weights $N_h/h^2$ 
	# with $N_h$ the number of point pairs and $h$ the distance.
	SStot<- sum(weig*(vario$gamma-mean(vario$gamma))^2)
	R2<-1-SSErr/SStot
	return(R2)
}

So from that how do I get the results for R2 and the RSS usings both ordinary least square, the generalized least square and the weigthed least square...

Frankly my head hurts... 

I dont know if I am on the right track but, if I want to find the best fit using ordinary least square I have to use fit.method=6

Therefore : 

r2findOLS <-function(fit, vario){
	# fit = fit.variogram output
	# vario = variogram output

	SSErr<-attr(fit,"SSErr")
	# this method uses no weights
	# with $N_h$ the number of point pairs and $h$ the distance.
	SStot<- sum((vario$gamma-mean(vario$gamma))^2)
	print(SStot)
	R2<-1-SSErr/SStot
	return(R2)
}


Now my problem is that I dont seem to have correct results (and I am very far for it) when I compare both R results and the software results.

So what I am looking for is : 

1- Is my logic correct
2- What about the function
3- Could you provide me with code that you allow me to compute both these values.


A big thanks to all who wish to spend time and help me out!


From rinke.heida at aris.nl  Mon Mar 14 09:10:47 2011
From: rinke.heida at aris.nl (Rinke)
Date: Mon, 14 Mar 2011 01:10:47 -0700 (PDT)
Subject: [R-sig-Geo] Non Square Pixels
In-Reply-To: <AANLkTik5kSNGq+_gktdr7XYJhGgsgKmLRcsrHu+D7-rg@mail.gmail.com>
References: <AANLkTik5kSNGq+_gktdr7XYJhGgsgKmLRcsrHu+D7-rg@mail.gmail.com>
Message-ID: <1300090247848-6168182.post@n2.nabble.com>

We have a direct read solution in ArcGIS for ASCII Grids (
http://www.aris.nl/index.php?option=com_content&view=article&id=208:aris-ascii-grid-reader&catid=64:arcgis-tools&Itemid=162
ASCII Grid Reader ) and may plan to add functionality to read non-square
cells.

We might support XDIM/YDIM and/or XCELLSIZE/YCELLSIZE in the header in
addition to the standard ESRI ASCII Grid specifications in our ArcGIS 10
version.

This way you can see your ASCII Grid with non-square cells directly in
ArcCatalog and ArcMap. 

Please let me know if this might help you. It would encourage us to
implement this. 

Regards, 

Rinke 

rinke.heida at aris.nl


Narayani Barve wrote:
> 
> Hi All,
> 
> I have ASCII grid (ESRI) format file. This file do not have square pixel
> but
> has rectangular pixel. X dimension is 1 and Y dimension is 0.83333. ESRI
> product cannot read a file with rectangular pixel. Is there a way, to
> convert this file so that square pixels are generated and file can be used
> with ESRI products ? Raster package has any functions to help out ?
> 
> Thanks in anticipation
> Narayani
> 
> 

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Non-Square-Pixels-tp6049989p6168182.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From edzer.pebesma at uni-muenster.de  Mon Mar 14 09:41:23 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 14 Mar 2011 09:41:23 +0100
Subject: [R-sig-Geo] R2 values from SSErr fit.variogram attribute
In-Reply-To: <A4BAB50B-4C91-4022-BEBF-D6F5F433DE8F@gmail.com>
References: <A4BAB50B-4C91-4022-BEBF-D6F5F433DE8F@gmail.com>
Message-ID: <4D7DD4B3.8070800@uni-muenster.de>



On 03/14/2011 01:14 AM, S?bastien Durand wrote:
> 	SStot<- sum(weig*(vario$gamma-mean(vario$gamma))2)

Not having tried, my guess is you need to sum the squared weighted
residuals, not the weighted squared residuals, so

SStot <- sum((weig*(vario$gamma-mean(vario$gamma)))^2)
-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From Gema.FAviles at uclm.es  Mon Mar 14 11:41:35 2011
From: Gema.FAviles at uclm.es (GEMA FERNANDEZ-AVILES CALDERON)
Date: Mon, 14 Mar 2011 11:41:35 +0100
Subject: [R-sig-Geo] School in Spatial Econometrics
Message-ID: <BFE1525242E7DA4B9CBBDE2CF4DDBBFB9E1E11@EVSAB01.uclm.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110314/e2987081/attachment.pl>

From vetter at pik-potsdam.de  Mon Mar 14 17:47:47 2011
From: vetter at pik-potsdam.de (vetter)
Date: Mon, 14 Mar 2011 17:47:47 +0100
Subject: [R-sig-Geo] How to get point pairs form variogram cloud in gstat
	package
Message-ID: <4D7E46B3.8060904@pik-potsdam.de>

I computed a variogram cloud using the gstat package.

My results look like this:

 > var1[,1]
            dist     gamma      dir.hor  dir.ver   id     left  right
1 63834.75 0.2057185       0       0         var1    2     1

My question is:
How can I extract the values from column "left" and "right" from this  
object?

Thanks Tobias Vetter


From v8extra at gmail.com  Mon Mar 14 18:07:17 2011
From: v8extra at gmail.com (=?iso-8859-1?Q?S=E9bastien_Durand?=)
Date: Mon, 14 Mar 2011 13:07:17 -0400
Subject: [R-sig-Geo] R2 values from SSErr fit.variogram attribute
Message-ID: <3E673238-4E68-4AE8-BE4D-5AAE133163CE@gmail.com>

Dear Dr. Pebesma,

I appreciate your help very much and I agree with you!

My head is clearer now but I still have some questions.

My first question is if I set fit.variogram to fit.sills=FALSE, fit.ranges=FALSE, to I get computation of SSErr... (I guess so).

That been said lets move forward :

Based on Geostatistic Modeling Spatial uncertainty (Chiles) page 109, in 
the weighted least square method, the weight are also squared : 
 $sum{w^2 * [?(h_j)-?(h_j:b)]^2}$  

So this agrees with what you have suggested me (and which I have applied). THANK GOD
	
Now, based on the gstat user's manual page 42 table 4.2 values for fit.
#	1 = $N_j$
#	2 = $N_j/{?(h_j)}^2$
#	6 = no weights (OLS) Ordinary Least Square
#	7 = $N_j/h_j^2$

I have made this code... that computes the R2 based of the fitted method used. 

I have also include an example of the data... and my code.

If you tell me the code is correct, I will move forward, but I still do not comprehend why I cannot obtain similar values. 
I must be missing something... any clue...???
I how the thing about comparing results with other software is a risky business but it is statistics, so I would at least be happy with simial result but look what I get... and tell me this is not mind puzzling?

Anyway I hope this code is good: 
		
findR2 <- function(vario, fit, fit.method=c(1,2,6,7)){
	# fit = fit.variogram output
	# vario = variogram output

	if(!is(vario, "gstatVariogram")) stop("Fit must be a gstatVariogram!\n")	
	if(!is(fit, "variogramModel")) stop("Fit must be a variogramModel!\n")
	if(length(fit.method)!=1) stop("One fit.method must be selected!\n")
	if(!any(fit.method==c(1,2,6,7))) stop("The selected fit.method is not managed!\n")
	
	SSErr<-attr(fit,"SSErr")
	if(fit.method==1){
		# weights : $N_j$
		# with $N_j$ the number of point pairs.
		weig<-vario$np 
		SSTot<- sum( (weig* (vario$gamma-mean(vario$gamma)))^2 )
	}
	if(fit.method==2){
		# weights : $N_j/{?(h_j)}^2$
		# with $N_j$ the number of point pairs and $?(h_j)$ the variance of the group of point-pairs.
		weig<-vario$np/vario$gamma^2  
		SSTot<- sum( (weig * (vario$gamma-mean(vario$gamma)))^2 )
	}
	if(fit.method==6){	
		# this method uses no weights
		SSTot<- sum((vario$gamma-mean(vario$gamma))^2 )
	}	
	if(fit.method==7){	
		# The default method used by fit.variogram
		# weights : $N_j/h_j^2$ 
		# with $N_j$ the number of point pairs and $h_j$ the distance.
		weig<-vario$np/vario$dist^2  
		SSTot<- sum( (weig * (vario$gamma-mean(vario$gamma)))^2 )
	}
	SSReg <- SSTot-SSErr
	R2 <-	1-SSErr/SSTot
	cat("\nFind2R values -> SSErr: ", SSErr, " SSReg: ", SSReg, " SSTot: ", SSTot, " R2: ", R2, "\n") 
	return(R2)
}

x<-c(728.42462,730.28539,716.32417,709.38916,723.78518,711.48527,710.63429,702.78617,711.34134,727.15081,733.52192,747.83184,762.91814,772.14823,754.44948,756.01782,782.16277,805.00559,791.57293,778.95638,751.28784,747.50682,729.00907,737.52659,752.25245,765.02277,775.26606,758.40180,761.04191,786.26503,801.47612,805.93667,784.75853,811.48931,808.96591,810.76875,833.36320,852.31984,848.53256,862.31869,864.78162,874.39381,860.98220,863.13351,846.52117,839.26401,823.99134,824.17076,808.31054,796.94449,788.72534,783.46914,760.01992,748.42461,704.66752,705.03418,706.80017,735.23510,760.99192,748.97461,743.58937,757.76718,745.37049,735.69955,713.69304,711.76608,696.13015,698.68165,703.38914,697.03829,674.89737,691.64862,686.96580,670.46693,660.36596,652.17736,655.94281,631.23998,625.32977,608.40446,600.01346,585.69355,565.28714,556.27343,536.13812,515.69045,501.85434,468.78282,452.12268,462.46920,477.41710,502.99157,526.49228,533.27104,565.42016,580.46385,593.30132,597.04050,612.55727,616.51646,632.00233,639.82386,618.77567,632.42059,699.40611,698.19514,688.99576,683.27393,664.85813,672.86755,673.97141,660.74718,651.24705,618.13733,630.26338,611.28937,610.41164,599.03826,576.78329,561.36347,556.46450,553.23343,546.01103,554.50072,542.04608,521.94745,510.27728,512.65755,488.60461,405.01785,361.92731,346.21866,340.41320,380.65148,383.12679,370.70358,351.20737,300.50567,247.95438,262.63726,268.59934,270.24494,281.41292,297.47110,320.07809,313.60984,357.62665,350.65600,384.75226,401.94217,408.48164,422.53176,429.00488,425.17268,437.22270,456.20930,461.29643,474.43676,458.18572,439.57278,421.30108,422.40514,405.29465,392.81110,374.30654,351.43988,317.06783,333.12881,309.35842,265.56919,255.88517,245.52172,229.21670,233.48720,243.23252,259.24005,253.14360,239.99223,214.56455,183.59160,168.31185,152.99117,138.34226,137.52623,115.98087,107.06663,99.69656,85.75688,78.31777,70.17954,79.94090);

y<-c(124.7121,155.7824,162.0367,174.9860,182.7883,193.3682,204.0938,209.6457,226.2255,230.6839,216.3763,206.8596,211.5037,220.2471,224.9453,232.8240,237.5390,247.7069,248.0330,252.4336,247.5189,255.2388,260.4527,271.2947,280.9344,296.3364,320.4039,321.0515,335.8206,348.7338,362.3612,373.6949,380.5346,408.6241,418.1795,440.9424,435.0106,458.6167,476.4112,472.4167,481.8280,497.4812,511.2659,524.5774,505.7546,518.3096,505.7870,475.0471,474.8810,474.4909,456.7841,449.8332,427.9383,425.1974,420.6297,402.9187,397.7280,392.1504,403.7409,393.0887,374.5793,362.1227,340.7810,329.5665,332.4625,314.0868,319.9376,303.6359,284.9916,261.5924,254.7595,243.9278,223.1862,209.6194,218.8728,233.3998,248.0205,228.0175,237.4241,238.7267,227.7562,234.9984,230.4800,246.1515,245.6719,259.3798,271.8863,276.0670,281.5663,304.5483,288.5204,297.2949,298.9224,285.7951,273.1466,292.0257,282.3901,276.2681,254.0934,269.8184,271.7436,287.5611,288.3422,296.2242,339.5946,351.0233,387.9683,380.3363,371.8982,363.1685,347.2458,357.5835,366.7113,391.5945,387.2011,369.5583,380.6504,380.5077,367.6701,392.5244,381.4005,375.1102,390.4030,403.0003,417.9508,396.0499,386.9360,416.5784,416.0306,406.7233,395.8752,394.1087,375.7258,383.5885,408.1062,407.8005,402.2309,380.0658,393.0108,383.8640,384.5255,377.9253,359.1873,365.2347,371.8960,354.6252,349.7077,360.4012,349.1288,345.7168,360.3246,356.7448,346.6512,360.1093,356.0386,344.5684,325.8377,324.5357,310.5146,314.3928,306.2765,314.1672,313.2553,310.6806,321.2840,321.6360,321.7791,337.2096,350.8569,340.5812,359.0478,375.2724,371.9662,361.9425,353.8320,323.5796,305.8561,311.9475,297.7328,288.8309,298.5439,289.7562,276.5800,255.2413,242.7040,259.3922,254.0665,236.4128,232.4118,214.5125,222.0566);

z<-c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,1,1,1,0,1,1,1,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1);

# The variogram used in the other soft.
v.m=vgm(0.311, "Sph", 482, 0.049)
dat=data.frame(x,y,z)
coordinates(dat) = ~x+y
vario=variogram(z~1, dat, width=68.28, cutoff=800);

# The problem I face is that the other software result is 
# R2: 0.982 and Residual Sum of Square: 1.65.1E-03

# So for fit.method=7
f.m=7
v.fit=fit.variogram(vario, v.m, fit.sills=FALSE, fit.ranges=FALSE, fit.method=f.m);
r2=findR2(vario, v.fit, f.m)

# So for fit.method=6
f.m=6
v.fit=fit.variogram(vario, v.m, fit.sills=FALSE, fit.ranges=FALSE, fit.method=f.m)
r2=findR2(vario, v.fit, f.m)

f.m=2
v.fit=fit.variogram(vario, v.m, fit.sills=FALSE, fit.ranges=FALSE, fit.method=f.m)
r2=findR2(vario, v.fit, f.m)

f.m=1
v.fit=fit.variogram(vario, v.m, fit.sills=FALSE, fit.ranges=FALSE, fit.method=f.m)
r2=findR2(vario, v.fit, f.m)


From edzer.pebesma at uni-muenster.de  Mon Mar 14 18:18:58 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 14 Mar 2011 18:18:58 +0100
Subject: [R-sig-Geo] How to get point pairs form variogram cloud in
 gstat package
In-Reply-To: <4D7E46B3.8060904@pik-potsdam.de>
References: <4D7E46B3.8060904@pik-potsdam.de>
Message-ID: <4D7E4E02.1070502@uni-muenster.de>



On 03/14/2011 05:47 PM, vetter wrote:
> I computed a variogram cloud using the gstat package.
> 
> My results look like this:
> 
>> var1[,1]

that was probably a

var[1,]

>            dist     gamma      dir.hor  dir.ver   id     left  right
> 1 63834.75 0.2057185       0       0         var1    2     1
> 
> My question is:
> How can I extract the values from column "left" and "right" from this 
> object?
> 

By coercion to a data.frame, and selecting:

as.data.frame(var1)$left
as.data.frame(var1)$right

> Thanks Tobias Vetter
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From vetter at pik-potsdam.de  Mon Mar 14 18:27:18 2011
From: vetter at pik-potsdam.de (vetter)
Date: Mon, 14 Mar 2011 18:27:18 +0100
Subject: [R-sig-Geo] How to get point pairs form variogram cloud in
 gstat package
In-Reply-To: <4D7E4E02.1070502@uni-muenster.de>
References: <4D7E46B3.8060904@pik-potsdam.de>
	<4D7E4E02.1070502@uni-muenster.de>
Message-ID: <4D7E4FF6.5000900@pik-potsdam.de>

It is not working:

 > as.data.frame(var1)[1,]
   np     dist     gamma dir.hor dir.ver   id
1  1 63834.75 0.2057185       0       0 var1

and therefore:

 > as.data.frame(var1)$left
NULL


>
> On 03/14/2011 05:47 PM, vetter wrote:
>> I computed a variogram cloud using the gstat package.
>>
>> My results look like this:
>>
>>> var1[,1]
> that was probably a
>
> var[1,]
>
>>             dist     gamma      dir.hor  dir.ver   id     left  right
>> 1 63834.75 0.2057185       0       0         var1    2     1
>>
>> My question is:
>> How can I extract the values from column "left" and "right" from this
>> object?
>>
> By coercion to a data.frame, and selecting:
>
> as.data.frame(var1)$left
> as.data.frame(var1)$right
>
>> Thanks Tobias Vetter
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From edzer.pebesma at uni-muenster.de  Mon Mar 14 18:34:12 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 14 Mar 2011 18:34:12 +0100
Subject: [R-sig-Geo] How to get point pairs form variogram cloud in
 gstat package
In-Reply-To: <4D7E4FF6.5000900@pik-potsdam.de>
References: <4D7E46B3.8060904@pik-potsdam.de>	<4D7E4E02.1070502@uni-muenster.de>
	<4D7E4FF6.5000900@pik-potsdam.de>
Message-ID: <4D7E5194.3000202@uni-muenster.de>

make sure var1 is a variogramCloud, obtained by

variogram(..., cloud=TRUE)

On 03/14/2011 06:27 PM, vetter wrote:
> It is not working:
> 
>> as.data.frame(var1)[1,]
>   np     dist     gamma dir.hor dir.ver   id
> 1  1 63834.75 0.2057185       0       0 var1
> 
> and therefore:
> 
>> as.data.frame(var1)$left
> NULL
> 
> 
>>
>> On 03/14/2011 05:47 PM, vetter wrote:
>>> I computed a variogram cloud using the gstat package.
>>>
>>> My results look like this:
>>>
>>>> var1[,1]
>> that was probably a
>>
>> var[1,]
>>
>>>             dist     gamma      dir.hor  dir.ver   id     left  right
>>> 1 63834.75 0.2057185       0       0         var1    2     1
>>>
>>> My question is:
>>> How can I extract the values from column "left" and "right" from this
>>> object?
>>>
>> By coercion to a data.frame, and selecting:
>>
>> as.data.frame(var1)$left
>> as.data.frame(var1)$right
>>
>>> Thanks Tobias Vetter
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From vetter at pik-potsdam.de  Mon Mar 14 18:43:26 2011
From: vetter at pik-potsdam.de (vetter)
Date: Mon, 14 Mar 2011 18:43:26 +0100
Subject: [R-sig-Geo] How to get point pairs form variogram cloud in
 gstat package
In-Reply-To: <4D7E5194.3000202@uni-muenster.de>
References: <4D7E46B3.8060904@pik-potsdam.de>	<4D7E4E02.1070502@uni-muenster.de>	<4D7E4FF6.5000900@pik-potsdam.de>
	<4D7E5194.3000202@uni-muenster.de>
Message-ID: <4D7E53BE.1030605@pik-potsdam.de>

I guess var1 is a variogramCloud. More complete code:

 > var1=variogram(val~1,geoObject,cloud=T)
 > var1[1,]
dist gamma dir.hor dir.ver id left right
1 63834.75 0.08506403 0 0 var1 2 1
 > as.data.frame(var1)$left
NULL


str(var1) gives:

Classes ?variogramCloud? and 'data.frame': 9253 obs. of 6 variables:
$ np : num 1 2 65538 3 65539 ...
$ dist : num 63835 97833 158641 251475 312811 ...
$ gamma : num 0.085 2.222 1.438 7.132 5.659 ...
$ dir.hor: num 0 0 0 0 0 0 0 0 0 0 ...
$ dir.ver: num 0 0 0 0 0 0 0 0 0 0 ...
$ id : Factor w/ 1 level "var1": 1 1 1 1 1 1 1 1 1 1 ...
- attr(*, "direct")='data.frame': 1 obs. of 2 variables:
..$ id : Factor w/ 1 level "var1": 1
..$ is.direct: logi TRUE
- attr(*, ".BigInt")= num 65536


> make sure var1 is a variogramCloud, obtained by
>
> variogram(..., cloud=TRUE)
>
> On 03/14/2011 06:27 PM, vetter wrote:
>> It is not working:
>>
>>> as.data.frame(var1)[1,]
>>    np     dist     gamma dir.hor dir.ver   id
>> 1  1 63834.75 0.2057185       0       0 var1
>>
>> and therefore:
>>
>>> as.data.frame(var1)$left
>> NULL
>>
>>
>>> On 03/14/2011 05:47 PM, vetter wrote:
>>>> I computed a variogram cloud using the gstat package.
>>>>
>>>> My results look like this:
>>>>
>>>>> var1[,1]
>>> that was probably a
>>>
>>> var[1,]
>>>
>>>>              dist     gamma      dir.hor  dir.ver   id     left  right
>>>> 1 63834.75 0.2057185       0       0         var1    2     1
>>>>
>>>> My question is:
>>>> How can I extract the values from column "left" and "right" from this
>>>> object?
>>>>
>>> By coercion to a data.frame, and selecting:
>>>
>>> as.data.frame(var1)$left
>>> as.data.frame(var1)$right
>>>
>>>> Thanks Tobias Vetter
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From edzer.pebesma at uni-muenster.de  Mon Mar 14 18:54:55 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 14 Mar 2011 18:54:55 +0100
Subject: [R-sig-Geo] How to get point pairs form variogram cloud in
 gstat package
In-Reply-To: <4D7E53BE.1030605@pik-potsdam.de>
References: <4D7E46B3.8060904@pik-potsdam.de>	<4D7E4E02.1070502@uni-muenster.de>	<4D7E4FF6.5000900@pik-potsdam.de>	<4D7E5194.3000202@uni-muenster.de>
	<4D7E53BE.1030605@pik-potsdam.de>
Message-ID: <4D7E566F.7090102@uni-muenster.de>

Please send me a reproducable example, for instance as a variation on:

> library(gstat)
Loading required package: sp
> data(meuse)
> coordinates(meuse)=~x+y
> v = variogram(zinc~1,meuse,cloud=TRUE)
numeric(0)
> class(v)
[1] "variogramCloud" "data.frame"
> as.data.frame(v)$left[1:10]
 [1] 2 3 3 4 4 4 5 5 5 5


On 03/14/2011 06:43 PM, vetter wrote:
> I guess var1 is a variogramCloud. More complete code:
> 
>> var1=variogram(val~1,geoObject,cloud=T)
>> var1[1,]
> dist gamma dir.hor dir.ver id left right
> 1 63834.75 0.08506403 0 0 var1 2 1
>> as.data.frame(var1)$left
> NULL
> 
> 
> str(var1) gives:
> 
> Classes ?variogramCloud? and 'data.frame': 9253 obs. of 6 variables:
> $ np : num 1 2 65538 3 65539 ...
> $ dist : num 63835 97833 158641 251475 312811 ...
> $ gamma : num 0.085 2.222 1.438 7.132 5.659 ...
> $ dir.hor: num 0 0 0 0 0 0 0 0 0 0 ...
> $ dir.ver: num 0 0 0 0 0 0 0 0 0 0 ...
> $ id : Factor w/ 1 level "var1": 1 1 1 1 1 1 1 1 1 1 ...
> - attr(*, "direct")='data.frame': 1 obs. of 2 variables:
> ..$ id : Factor w/ 1 level "var1": 1
> ..$ is.direct: logi TRUE
> - attr(*, ".BigInt")= num 65536
> 
> 
>> make sure var1 is a variogramCloud, obtained by
>>
>> variogram(..., cloud=TRUE)
>>
>> On 03/14/2011 06:27 PM, vetter wrote:
>>> It is not working:
>>>
>>>> as.data.frame(var1)[1,]
>>>    np     dist     gamma dir.hor dir.ver   id
>>> 1  1 63834.75 0.2057185       0       0 var1
>>>
>>> and therefore:
>>>
>>>> as.data.frame(var1)$left
>>> NULL
>>>
>>>
>>>> On 03/14/2011 05:47 PM, vetter wrote:
>>>>> I computed a variogram cloud using the gstat package.
>>>>>
>>>>> My results look like this:
>>>>>
>>>>>> var1[,1]
>>>> that was probably a
>>>>
>>>> var[1,]
>>>>
>>>>>              dist     gamma      dir.hor  dir.ver   id     left  right
>>>>> 1 63834.75 0.2057185       0       0         var1    2     1
>>>>>
>>>>> My question is:
>>>>> How can I extract the values from column "left" and "right" from this
>>>>> object?
>>>>>
>>>> By coercion to a data.frame, and selecting:
>>>>
>>>> as.data.frame(var1)$left
>>>> as.data.frame(var1)$right
>>>>
>>>>> Thanks Tobias Vetter
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at r-project.org
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From vetter at pik-potsdam.de  Mon Mar 14 19:12:43 2011
From: vetter at pik-potsdam.de (vetter)
Date: Mon, 14 Mar 2011 19:12:43 +0100
Subject: [R-sig-Geo] How to get point pairs form variogram cloud in
 gstat package
In-Reply-To: <4D7E566F.7090102@uni-muenster.de>
References: <4D7E46B3.8060904@pik-potsdam.de>	<4D7E4E02.1070502@uni-muenster.de>	<4D7E4FF6.5000900@pik-potsdam.de>	<4D7E5194.3000202@uni-muenster.de>	<4D7E53BE.1030605@pik-potsdam.de>
	<4D7E566F.7090102@uni-muenster.de>
Message-ID: <4D7E5A9B.3020007@pik-potsdam.de>

strange still NULL:

 > data(meuse)
 > coordinates(meuse)=~x+y
 > v = variogram(zinc~1,meuse,cloud=TRUE)
 > as.data.frame(v)$left[1:10]
NULL

My current Version R version is  2.9.1.


> Please send me a reproducable example, for instance as a variation on:
>
>> library(gstat)
> Loading required package: sp
>> data(meuse)
>> coordinates(meuse)=~x+y
>> v = variogram(zinc~1,meuse,cloud=TRUE)
> numeric(0)
>> class(v)
> [1] "variogramCloud" "data.frame"
>> as.data.frame(v)$left[1:10]
>   [1] 2 3 3 4 4 4 5 5 5 5
>
>
> On 03/14/2011 06:43 PM, vetter wrote:
>> I guess var1 is a variogramCloud. More complete code:
>>
>>> var1=variogram(val~1,geoObject,cloud=T)
>>> var1[1,]
>> dist gamma dir.hor dir.ver id left right
>> 1 63834.75 0.08506403 0 0 var1 2 1
>>> as.data.frame(var1)$left
>> NULL
>>
>>
>> str(var1) gives:
>>
>> Classes ?variogramCloud? and 'data.frame': 9253 obs. of 6 variables:
>> $ np : num 1 2 65538 3 65539 ...
>> $ dist : num 63835 97833 158641 251475 312811 ...
>> $ gamma : num 0.085 2.222 1.438 7.132 5.659 ...
>> $ dir.hor: num 0 0 0 0 0 0 0 0 0 0 ...
>> $ dir.ver: num 0 0 0 0 0 0 0 0 0 0 ...
>> $ id : Factor w/ 1 level "var1": 1 1 1 1 1 1 1 1 1 1 ...
>> - attr(*, "direct")='data.frame': 1 obs. of 2 variables:
>> ..$ id : Factor w/ 1 level "var1": 1
>> ..$ is.direct: logi TRUE
>> - attr(*, ".BigInt")= num 65536
>>
>>
>>> make sure var1 is a variogramCloud, obtained by
>>>
>>> variogram(..., cloud=TRUE)
>>>
>>> On 03/14/2011 06:27 PM, vetter wrote:
>>>> It is not working:
>>>>
>>>>> as.data.frame(var1)[1,]
>>>>     np     dist     gamma dir.hor dir.ver   id
>>>> 1  1 63834.75 0.2057185       0       0 var1
>>>>
>>>> and therefore:
>>>>
>>>>> as.data.frame(var1)$left
>>>> NULL
>>>>
>>>>
>>>>> On 03/14/2011 05:47 PM, vetter wrote:
>>>>>> I computed a variogram cloud using the gstat package.
>>>>>>
>>>>>> My results look like this:
>>>>>>
>>>>>>> var1[,1]
>>>>> that was probably a
>>>>>
>>>>> var[1,]
>>>>>
>>>>>>               dist     gamma      dir.hor  dir.ver   id     left  right
>>>>>> 1 63834.75 0.2057185       0       0         var1    2     1
>>>>>>
>>>>>> My question is:
>>>>>> How can I extract the values from column "left" and "right" from this
>>>>>> object?
>>>>>>
>>>>> By coercion to a data.frame, and selecting:
>>>>>
>>>>> as.data.frame(var1)$left
>>>>> as.data.frame(var1)$right
>>>>>
>>>>>> Thanks Tobias Vetter
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at r-project.org
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From edzer.pebesma at uni-muenster.de  Mon Mar 14 19:48:43 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 14 Mar 2011 19:48:43 +0100
Subject: [R-sig-Geo] How to get point pairs form variogram cloud in
 gstat package
In-Reply-To: <4D7E5A9B.3020007@pik-potsdam.de>
References: <4D7E46B3.8060904@pik-potsdam.de>	<4D7E4E02.1070502@uni-muenster.de>	<4D7E4FF6.5000900@pik-potsdam.de>	<4D7E5194.3000202@uni-muenster.de>	<4D7E53BE.1030605@pik-potsdam.de>	<4D7E566F.7090102@uni-muenster.de>
	<4D7E5A9B.3020007@pik-potsdam.de>
Message-ID: <4D7E630B.3050404@uni-muenster.de>

On 03/14/2011 07:12 PM, vetter wrote:
> 
> My current Version R version is  2.9.1.

Maybe a good moment to update, then.
-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From nathanielrayl at hotmail.com  Mon Mar 14 20:04:50 2011
From: nathanielrayl at hotmail.com (Nathaniel Rayl)
Date: Mon, 14 Mar 2011 15:04:50 -0400
Subject: [R-sig-Geo] Importing multiple shapefiles to run a loop in R
In-Reply-To: <COL117-W186B39997DC5E6A5BFBDB6B5CC0@phx.gbl>
References: <COL117-W186B39997DC5E6A5BFBDB6B5CC0@phx.gbl>
Message-ID: <COL117-W56E3EB52B7532F05C534CFB5CC0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110314/491ab846/attachment.pl>

From edzer.pebesma at uni-muenster.de  Mon Mar 14 20:11:31 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 14 Mar 2011 20:11:31 +0100
Subject: [R-sig-Geo] Importing multiple shapefiles to run a loop in R
In-Reply-To: <COL117-W56E3EB52B7532F05C534CFB5CC0@phx.gbl>
References: <COL117-W186B39997DC5E6A5BFBDB6B5CC0@phx.gbl>
	<COL117-W56E3EB52B7532F05C534CFB5CC0@phx.gbl>
Message-ID: <4D7E6863.5000702@uni-muenster.de>

Nathaniel, unlike a .csv, a shapefile consists of a set of files. The
functions you use to read them take either the base name ("shape1") or
the .shp file ("shape1.shp") as argument, and discover the rest
themselves. They don't like to be called with e.g. "shape1.dbf".

If your understanding of R is rudimentary, try first to read single
shapefiles in R, then try to understand how lapply works.

On 03/14/2011 08:04 PM, Nathaniel Rayl wrote:
> 
> 
> 
> 
> 
> 
> 
> Hi R Users,
> 
> I commonly import multiple .csv files and then write loops to work with those files like this:
> 
>> setwd('C://Nathaniel/R/allfiles')
>> files<-list.files()
>> allfiles<-lapply(t1,read.csv)
>> for (i in 1:47) {
>>     t1<-allfiles[[i]]
> 
> etc. etc.
> 
> I have written a script that I would like to loop to work with a folder of 400+ .shp files.  Is there an equivalent way to read in all the shapefiles so that I can run a loop?
> 
> I tried this:
> 
>> setwd('C://Nathaniel/R/shapefiles')
>> t1<-list.files()
>> t2<-lapply(t1,readShapePoly)
> 
> which returned this error:
> 
> "Error in Fun(c("shape1.dbf", "shape1.prj", "shape1.sbn", "shape1.sbx", :
>    missing layer"
> 
> and I tried this:
> 
>> setwd('C://Nathaniel/R/shapefiles')
> 
>> t1<-list.files()
> 
>> t2<-lapply(t1,readOGR)
> 
> which returned this error:
> 
> "Error in getinfo.shape(filen) : Error opening SHP file"
> 
> 
> I've searched the archives and wasn't able to find anything like this.  My understanding of R code is rudimentary, so any help would be greatly appreciated.  Thanks for considering my problem.
> 
> Best regards,
> 
> Nathaniel
>  		 	   		  
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From edzer.pebesma at uni-muenster.de  Mon Mar 14 20:20:44 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 14 Mar 2011 20:20:44 +0100
Subject: [R-sig-Geo] R2 values from SSErr fit.variogram attribute
In-Reply-To: <3E673238-4E68-4AE8-BE4D-5AAE133163CE@gmail.com>
References: <3E673238-4E68-4AE8-BE4D-5AAE133163CE@gmail.com>
Message-ID: <4D7E6A8C.6070408@uni-muenster.de>

Sebastien, let me first express my happiness that your head is clearer
now; I hope that I can speak for the other 1990 subscribers of this list
too.

With which software do you compare? And how does that software exactly
document how it computes R2 values?

In your message of Mar 7 to this list you quote a reply from me to kili
at grf.rs. In the computations you've showed so far you're still
ignoring the comment I made there.

On 03/14/2011 06:07 PM, S?bastien Durand wrote:
> Dear Dr. Pebesma,
> 
> I appreciate your help very much and I agree with you!
> 
> My head is clearer now but I still have some questions.
> 
> My first question is if I set fit.variogram to fit.sills=FALSE, fit.ranges=FALSE, to I get computation of SSErr... (I guess so).
> 
> That been said lets move forward :
> 
> Based on Geostatistic Modeling Spatial uncertainty (Chiles) page 109, in 
> the weighted least square method, the weight are also squared : 
>  $sum{w^2 * [?(h_j)-?(h_j:b)]^2}$  
> 
> So this agrees with what you have suggested me (and which I have applied). THANK GOD
> 	
> Now, based on the gstat user's manual page 42 table 4.2 values for fit.
> #	1 = $N_j$
> #	2 = $N_j/{?(h_j)}^2$
> #	6 = no weights (OLS) Ordinary Least Square
> #	7 = $N_j/h_j^2$
> 
> I have made this code... that computes the R2 based of the fitted method used. 
> 
> I have also include an example of the data... and my code.
> 
> If you tell me the code is correct, I will move forward, but I still do not comprehend why I cannot obtain similar values. 
> I must be missing something... any clue...???
> I how the thing about comparing results with other software is a risky business but it is statistics, so I would at least be happy with simial result but look what I get... and tell me this is not mind puzzling?
> 
> Anyway I hope this code is good: 
> 		
> findR2 <- function(vario, fit, fit.method=c(1,2,6,7)){
> 	# fit = fit.variogram output
> 	# vario = variogram output
> 
> 	if(!is(vario, "gstatVariogram")) stop("Fit must be a gstatVariogram!\n")	
> 	if(!is(fit, "variogramModel")) stop("Fit must be a variogramModel!\n")
> 	if(length(fit.method)!=1) stop("One fit.method must be selected!\n")
> 	if(!any(fit.method==c(1,2,6,7))) stop("The selected fit.method is not managed!\n")
> 	
> 	SSErr<-attr(fit,"SSErr")
> 	if(fit.method==1){
> 		# weights : $N_j$
> 		# with $N_j$ the number of point pairs.
> 		weig<-vario$np 
> 		SSTot<- sum( (weig* (vario$gamma-mean(vario$gamma)))^2 )
> 	}
> 	if(fit.method==2){
> 		# weights : $N_j/{?(h_j)}^2$
> 		# with $N_j$ the number of point pairs and $?(h_j)$ the variance of the group of point-pairs.
> 		weig<-vario$np/vario$gamma^2  
> 		SSTot<- sum( (weig * (vario$gamma-mean(vario$gamma)))^2 )
> 	}
> 	if(fit.method==6){	
> 		# this method uses no weights
> 		SSTot<- sum((vario$gamma-mean(vario$gamma))^2 )
> 	}	
> 	if(fit.method==7){	
> 		# The default method used by fit.variogram
> 		# weights : $N_j/h_j^2$ 
> 		# with $N_j$ the number of point pairs and $h_j$ the distance.
> 		weig<-vario$np/vario$dist^2  
> 		SSTot<- sum( (weig * (vario$gamma-mean(vario$gamma)))^2 )
> 	}
> 	SSReg <- SSTot-SSErr
> 	R2 <-	1-SSErr/SSTot
> 	cat("\nFind2R values -> SSErr: ", SSErr, " SSReg: ", SSReg, " SSTot: ", SSTot, " R2: ", R2, "\n") 
> 	return(R2)
> }
> 
> x<-c(728.42462,730.28539,716.32417,709.38916,723.78518,711.48527,710.63429,702.78617,711.34134,727.15081,733.52192,747.83184,762.91814,772.14823,754.44948,756.01782,782.16277,805.00559,791.57293,778.95638,751.28784,747.50682,729.00907,737.52659,752.25245,765.02277,775.26606,758.40180,761.04191,786.26503,801.47612,805.93667,784.75853,811.48931,808.96591,810.76875,833.36320,852.31984,848.53256,862.31869,864.78162,874.39381,860.98220,863.13351,846.52117,839.26401,823.99134,824.17076,808.31054,796.94449,788.72534,783.46914,760.01992,748.42461,704.66752,705.03418,706.80017,735.23510,760.99192,748.97461,743.58937,757.76718,745.37049,735.69955,713.69304,711.76608,696.13015,698.68165,703.38914,697.03829,674.89737,691.64862,686.96580,670.46693,660.36596,652.17736,655.94281,631.23998,625.32977,608.40446,600.01346,585.69355,565.28714,556.27343,536.13812,515.69045,501.85434,468.78282,452.12268,462.46920,477.41710,502.99157,526.49228,533.27104,565.42016,580.46385,593.30132,597.04050,612
.55727,616.51646,632.00233,639.82386,618.77567,632.42059,699.40611,698.19514,688.99576,683.27393,664.85813,672.86755,673.97141,660.74718,651.24705,618.13733,630.26338,611.28937,610.41164,599.03826,576.78329,561.36347,556.46450,553.23343,546.01103,554.50072,542.04608,521.94745,510.27728,512.65755,488.60461,405.01785,361.92731,346.21866,340.41320,380.65148,383.12679,370.70358,351.20737,300.50567,247.95438,262.63726,268.59934,270.24494,281.41292,297.47110,320.07809,313.60984,357.62665,350.65600,384.75226,401.94217,408.48164,422.53176,429.00488,425.17268,437.22270,456.20930,461.29643,474.43676,458.18572,439.57278,421.30108,422.40514,405.29465,392.81110,374.30654,351.43988,317.06783,333.12881,309.35842,265.56919,255.88517,245.52172,229.21670,233.48720,243.23252,259.24005,253.14360,239.99223,214.56455,183.59160,168.31185,152.99117,138.34226,137.52623,115.98087,107.06663,99.69656,85.75688,78.31777,70.17954,79.94090);
> 
> y<-c(124.7121,155.7824,162.0367,174.9860,182.7883,193.3682,204.0938,209.6457,226.2255,230.6839,216.3763,206.8596,211.5037,220.2471,224.9453,232.8240,237.5390,247.7069,248.0330,252.4336,247.5189,255.2388,260.4527,271.2947,280.9344,296.3364,320.4039,321.0515,335.8206,348.7338,362.3612,373.6949,380.5346,408.6241,418.1795,440.9424,435.0106,458.6167,476.4112,472.4167,481.8280,497.4812,511.2659,524.5774,505.7546,518.3096,505.7870,475.0471,474.8810,474.4909,456.7841,449.8332,427.9383,425.1974,420.6297,402.9187,397.7280,392.1504,403.7409,393.0887,374.5793,362.1227,340.7810,329.5665,332.4625,314.0868,319.9376,303.6359,284.9916,261.5924,254.7595,243.9278,223.1862,209.6194,218.8728,233.3998,248.0205,228.0175,237.4241,238.7267,227.7562,234.9984,230.4800,246.1515,245.6719,259.3798,271.8863,276.0670,281.5663,304.5483,288.5204,297.2949,298.9224,285.7951,273.1466,292.0257,282.3901,276.2681,254.0934,269.8184,271.7436,287.5611,288.3422,296.2242,339.5946,351.0233,387.9683,380.3363,371.8982,36
3.1685,347.2458,357.5835,366.7113,391.5945,387.2011,369.5583,380.6504,380.5077,367.6701,392.5244,381.4005,375.1102,390.4030,403.0003,417.9508,396.0499,386.9360,416.5784,416.0306,406.7233,395.8752,394.1087,375.7258,383.5885,408.1062,407.8005,402.2309,380.0658,393.0108,383.8640,384.5255,377.9253,359.1873,365.2347,371.8960,354.6252,349.7077,360.4012,349.1288,345.7168,360.3246,356.7448,346.6512,360.1093,356.0386,344.5684,325.8377,324.5357,310.5146,314.3928,306.2765,314.1672,313.2553,310.6806,321.2840,321.6360,321.7791,337.2096,350.8569,340.5812,359.0478,375.2724,371.9662,361.9425,353.8320,323.5796,305.8561,311.9475,297.7328,288.8309,298.5439,289.7562,276.5800,255.2413,242.7040,259.3922,254.0665,236.4128,232.4118,214.5125,222.0566);
> 
> z<-c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,1,1,1,0,1,1,1,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1);
> 
> # The variogram used in the other soft.
> v.m=vgm(0.311, "Sph", 482, 0.049)
> dat=data.frame(x,y,z)
> coordinates(dat) = ~x+y
> vario=variogram(z~1, dat, width=68.28, cutoff=800);
> 
> # The problem I face is that the other software result is 
> # R2: 0.982 and Residual Sum of Square: 1.65.1E-03
> 
> # So for fit.method=7
> f.m=7
> v.fit=fit.variogram(vario, v.m, fit.sills=FALSE, fit.ranges=FALSE, fit.method=f.m);
> r2=findR2(vario, v.fit, f.m)
> 
> # So for fit.method=6
> f.m=6
> v.fit=fit.variogram(vario, v.m, fit.sills=FALSE, fit.ranges=FALSE, fit.method=f.m)
> r2=findR2(vario, v.fit, f.m)
> 
> f.m=2
> v.fit=fit.variogram(vario, v.m, fit.sills=FALSE, fit.ranges=FALSE, fit.method=f.m)
> r2=findR2(vario, v.fit, f.m)
> 
> f.m=1
> v.fit=fit.variogram(vario, v.m, fit.sills=FALSE, fit.ranges=FALSE, fit.method=f.m)
> r2=findR2(vario, v.fit, f.m)
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From alban.thomas.fr at gmail.com  Mon Mar 14 21:28:46 2011
From: alban.thomas.fr at gmail.com (alban thomas)
Date: Mon, 14 Mar 2011 21:28:46 +0100
Subject: [R-sig-Geo] Importing multiple shapefiles to run a loop in R
In-Reply-To: <4D7E6863.5000702@uni-muenster.de>
References: <COL117-W186B39997DC5E6A5BFBDB6B5CC0@phx.gbl>
	<COL117-W56E3EB52B7532F05C534CFB5CC0@phx.gbl>
	<4D7E6863.5000702@uni-muenster.de>
Message-ID: <AANLkTi=UmtFcBOOoBXV4VQB9NEXOqi48LUgEbshg1qSP@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110314/32a22903/attachment.pl>

From vetter at pik-potsdam.de  Mon Mar 14 21:39:05 2011
From: vetter at pik-potsdam.de (vetter)
Date: Mon, 14 Mar 2011 21:39:05 +0100
Subject: [R-sig-Geo] How to get point pairs form variogram cloud in
 gstat package
In-Reply-To: <4D7E5A9B.3020007@pik-potsdam.de>
References: <4D7E46B3.8060904@pik-potsdam.de>	<4D7E4E02.1070502@uni-muenster.de>	<4D7E4FF6.5000900@pik-potsdam.de>	<4D7E5194.3000202@uni-muenster.de>	<4D7E53BE.1030605@pik-potsdam.de>	<4D7E566F.7090102@uni-muenster.de>
	<4D7E5A9B.3020007@pik-potsdam.de>
Message-ID: <4D7E7CE9.1090503@pik-potsdam.de>

Problem solved. In the newest R-version it works fine.
Thanks for helping
Tobias Vetter
> strange still NULL:
>
> > data(meuse)
> > coordinates(meuse)=~x+y
> > v = variogram(zinc~1,meuse,cloud=TRUE)
> > as.data.frame(v)$left[1:10]
> NULL
>
> My current Version R version is  2.9.1.
>
>
>> Please send me a reproducable example, for instance as a variation on:
>>
>>> library(gstat)
>> Loading required package: sp
>>> data(meuse)
>>> coordinates(meuse)=~x+y
>>> v = variogram(zinc~1,meuse,cloud=TRUE)
>> numeric(0)
>>> class(v)
>> [1] "variogramCloud" "data.frame"
>>> as.data.frame(v)$left[1:10]
>>   [1] 2 3 3 4 4 4 5 5 5 5
>>
>>
>> On 03/14/2011 06:43 PM, vetter wrote:
>>> I guess var1 is a variogramCloud. More complete code:
>>>
>>>> var1=variogram(val~1,geoObject,cloud=T)
>>>> var1[1,]
>>> dist gamma dir.hor dir.ver id left right
>>> 1 63834.75 0.08506403 0 0 var1 2 1
>>>> as.data.frame(var1)$left
>>> NULL
>>>
>>>
>>> str(var1) gives:
>>>
>>> Classes ?variogramCloud? and 'data.frame': 9253 obs. of 6 variables:
>>> $ np : num 1 2 65538 3 65539 ...
>>> $ dist : num 63835 97833 158641 251475 312811 ...
>>> $ gamma : num 0.085 2.222 1.438 7.132 5.659 ...
>>> $ dir.hor: num 0 0 0 0 0 0 0 0 0 0 ...
>>> $ dir.ver: num 0 0 0 0 0 0 0 0 0 0 ...
>>> $ id : Factor w/ 1 level "var1": 1 1 1 1 1 1 1 1 1 1 ...
>>> - attr(*, "direct")='data.frame': 1 obs. of 2 variables:
>>> ..$ id : Factor w/ 1 level "var1": 1
>>> ..$ is.direct: logi TRUE
>>> - attr(*, ".BigInt")= num 65536
>>>
>>>
>>>> make sure var1 is a variogramCloud, obtained by
>>>>
>>>> variogram(..., cloud=TRUE)
>>>>
>>>> On 03/14/2011 06:27 PM, vetter wrote:
>>>>> It is not working:
>>>>>
>>>>>> as.data.frame(var1)[1,]
>>>>>     np     dist     gamma dir.hor dir.ver   id
>>>>> 1  1 63834.75 0.2057185       0       0 var1
>>>>>
>>>>> and therefore:
>>>>>
>>>>>> as.data.frame(var1)$left
>>>>> NULL
>>>>>
>>>>>
>>>>>> On 03/14/2011 05:47 PM, vetter wrote:
>>>>>>> I computed a variogram cloud using the gstat package.
>>>>>>>
>>>>>>> My results look like this:
>>>>>>>
>>>>>>>> var1[,1]
>>>>>> that was probably a
>>>>>>
>>>>>> var[1,]
>>>>>>
>>>>>>>               dist     gamma      dir.hor  dir.ver   id     
>>>>>>> left  right
>>>>>>> 1 63834.75 0.2057185       0       0         var1    2     1
>>>>>>>
>>>>>>> My question is:
>>>>>>> How can I extract the values from column "left" and "right" from 
>>>>>>> this
>>>>>>> object?
>>>>>>>
>>>>>> By coercion to a data.frame, and selecting:
>>>>>>
>>>>>> as.data.frame(var1)$left
>>>>>> as.data.frame(var1)$right
>>>>>>
>>>>>>> Thanks Tobias Vetter
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-Geo mailing list
>>>>>>> R-sig-Geo at r-project.org
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at r-project.org
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From momadou at yahoo.fr  Tue Mar 15 00:02:00 2011
From: momadou at yahoo.fr (Komine)
Date: Mon, 14 Mar 2011 16:02:00 -0700 (PDT)
Subject: [R-sig-Geo] Open raster _ extract pixel value
In-Reply-To: <1300037624669-6166730.post@n2.nabble.com>
References: <1300037624669-6166730.post@n2.nabble.com>
Message-ID: <1300143720025-6171051.post@n2.nabble.com>

Thanks to all for your answers, I progress!
Robert, after to try your code, all is ok. Now I try to open a NDVI image
with HRD extension. Also almost all is ok with the next code: 
library(raster) 
myobject <-raster("C:\\Users\\komine\\Desktop\\MODIS2\\NDVI_280") 
plot(myobject) 
click(myobject)   # and click somewhere on the map to get the value at that
location 
myobject[1]  # value of first cell 
myobject[10,10]  # value of cell at row 10, column 10 
extract(myobject, cbind(496439.36,1662612.38)) # value at coordinates
-	However, the image NDVI don?t appear well because I have a color on the
raster map like a mask,
-	Also, I compare to verify a pixel value NDVI extract from R and the ENVI
software (like Erdas) but I have two differences values for the same pixel
(for the past coordinates, pixel value from R= -0.5376111  whereas for ENVI= 
-0.586962)
Could you help on this problem? 
Thanks again 


--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Open-raster-extract-pixel-value-tp6166730p6171051.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From v8extra at gmail.com  Tue Mar 15 04:18:42 2011
From: v8extra at gmail.com (=?iso-8859-1?Q?S=E9bastien_Durand?=)
Date: Mon, 14 Mar 2011 23:18:42 -0400
Subject: [R-sig-Geo] R2 values from SSErr fit.variogram attribute
Message-ID: <36955D2D-DE0C-4FF0-AF93-5BAD4525047A@gmail.com>

Hello Dr. Pebesma and all other 1989 readers...

Believe me, I would have been much happier, if I could comprehend this tiny little detail that you refer to as : 

> It looks quite OK; I suspect however that instead of using
> mean(s.v$gamma) for SSTot, for this mean the same weighting scheme
> should have been used.

I still do not understand what you mean by that.  I am very sorry for that and yes I now feel stupid, sincerely I am doing my best to graps very old notions.

In my function, it is the weighted residual that are squared, that part is ok, but now you are telling me that I am not using to proper "mean" reference, that in fact the "same weighting scheme should be used on that ... ???  Did you meant "mean(vario$gamma)*weig" ??? 

I would like to receive an explanation for this?

Please indulge me and show me the way, how should I correct my code..

Sincerely!


The other software is GS+

S.

From edzer.pebesma at uni-muenster.de  Tue Mar 15 07:45:00 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 15 Mar 2011 07:45:00 +0100
Subject: [R-sig-Geo] R2 values from SSErr fit.variogram attribute
In-Reply-To: <36955D2D-DE0C-4FF0-AF93-5BAD4525047A@gmail.com>
References: <36955D2D-DE0C-4FF0-AF93-5BAD4525047A@gmail.com>
Message-ID: <4D7F0AEC.8040304@uni-muenster.de>



On 03/15/2011 04:18 AM, S?bastien Durand wrote:
> Hello Dr. Pebesma and all other 1989 readers...
> 
> Believe me, I would have been much happier, if I could comprehend this tiny little detail that you refer to as : 
> 
>> It looks quite OK; I suspect however that instead of using
>> mean(s.v$gamma) for SSTot, for this mean the same weighting scheme
>> should have been used.
> 
> I still do not understand what you mean by that.  I am very sorry for that and yes I now feel stupid, sincerely I am doing my best to graps very old notions.
> 
> In my function, it is the weighted residual that are squared, that part is ok, but now you are telling me that I am not using to proper "mean" reference, that in fact the "same weighting scheme should be used on that ... ???  Did you meant "mean(vario$gamma)*weig" ??? 
> 
> I would like to receive an explanation for this?

You're comparing a weighted fit to an unweighted mean. If you want to
evaluate the fit (by R2), the corresponding null-model should use the
same weights, IMO. Given weights w and values sv$gamma, that would be
sum(w * sv$gamma)/sum(w) rather than mean(sv$gamma).

Or, alternatively, weighted.mean(sv$gamma, w)

> Sincerely!
> 
> 
> The other software is GS+
> 
> S.
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From momadou at yahoo.fr  Tue Mar 15 10:05:33 2011
From: momadou at yahoo.fr (Komine)
Date: Tue, 15 Mar 2011 02:05:33 -0700 (PDT)
Subject: [R-sig-Geo] Open raster _ extract pixel value
In-Reply-To: <1300037624669-6166730.post@n2.nabble.com>
References: <1300037624669-6166730.post@n2.nabble.com>
Message-ID: <1300179933375-6172015.post@n2.nabble.com>

Dear, 
Thanks, pixel value is ok, in fact I must put 4 numbers after the gamma. But
the image NDVI don't appear good with a color on all the map although the
pixel values are correct.

Thank you

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Open-raster-extract-pixel-value-tp6166730p6172015.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From alfios17 at hotmail.com  Tue Mar 15 10:14:36 2011
From: alfios17 at hotmail.com (Lorenzo Alfieri)
Date: Tue, 15 Mar 2011 10:14:36 +0100
Subject: [R-sig-Geo] rgdal to gif: HELP!!!
Message-ID: <DUB106-w46419A2F58D488B05A01BCD7CF0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110315/66ff57dd/attachment.pl>

From villers.alexandre at gmail.com  Tue Mar 15 10:42:50 2011
From: villers.alexandre at gmail.com (Alexandre Villers)
Date: Tue, 15 Mar 2011 11:42:50 +0200
Subject: [R-sig-Geo] rgdal to gif: HELP!!!
In-Reply-To: <DUB106-w46419A2F58D488B05A01BCD7CF0@phx.gbl>
References: <DUB106-w46419A2F58D488B05A01BCD7CF0@phx.gbl>
Message-ID: <4D7F349A.90000@gmail.com>

Hi,

What is exactly your goal? Displaying an image in a GIS or just saving 
an image to be used as an illustration ?
If the second option is yours, then have a look at spplot() and then 
save the image with png(), jpeg(), tiff() or bmp()

HTH

Alex


> Dear all,
>
> I'm new to this forum.
>
> I'm desperately looking for help, as I'm stuck with a problem and I can't find any solution.
>
> I'd like to open a raster map (for example with rgdal it is read as a
> SpatialGridDataFrame) and then save it as a gif image with a specific
> color palette.
>
> I can't find the way to specify the color, so I can only create greyscale images.
>
> It sounds simple but nothing seems to work.
>
> I've been trying with:
>
>
>
> Kp1P<- readGDAL(mymap)
>
> writeGDAL(Kp1P,"myGIFmap.gif",drivername="gif",col=colmed)
>
>
>
> but col is not an option in writeGDAL command
>
>
>
> I need to specify this colors:
>
> colmed<-c(rep(rgb(255/255, 204/255, 204/255),10),rep(rgb(255/255,
> 184/255, 176/255),10),rep(rgb(255/255, 164/255,
> 176/255),10),rep(rgb(255/255, 144/255, 125/255),10),
>
>    rep(rgb(250/255, 125/255, 102/255),10),rep(rgb(247/255, 104/255,
> 79/255),10),rep(rgb(242/255, 85/255, 61/255),10),rep(rgb(235/255,
> 65/255, 42/255),10),
>
>    rep(rgb(227/255, 40/255, 23/255),10),rep(rgb(219/255, 0/255, 0/255),10))
>
>
>
> HELP!
>
>
>
> Lorenzo
> 				 		 	   		
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From hengl at spatial-analyst.net  Tue Mar 15 14:47:59 2011
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Tue, 15 Mar 2011 14:47:59 +0100
Subject: [R-sig-Geo] rgdal to gif: HELP!!!
In-Reply-To: <DUB106-w46419A2F58D488B05A01BCD7CF0@phx.gbl>
References: <DUB106-w46419A2F58D488B05A01BCD7CF0@phx.gbl>
Message-ID: <4D7F6E0F.5090901@spatial-analyst.net>


I recommend using the caTools package for this.

Here is a peace of code I used to write some GIFs with color legend. I 
hope it is self-explanatory :)

# make a color palette:
 > col.pal <- c(grey(1), grey(0.6), grey(0), rep(grey(0), 256-3))

# import DEM to R:
 > dem <- readGDAL("dem.sdat")
# convert to 0:255 numbers:
 > dem$mask <- ifelse(!is.na(dem$band1), 2, ifelse(dem$band1 > 0, 1, 0))
 > write.gif(image=t(as.matrix(dem["mask"])), filename=paste(getwd(), 
"/", "dem_mask_1.gif", sep=""), col=col.pal)

# for scripting possibilities with ImageMagick see 
[http://www.imagemagick.org/Usage/anim_basics/];
 > system("C:\\PROGRA~1\\IMAGEM~1\\convert -delay 80 -loop 0 
*_mask_*.gif  mask_ani.gif")
 > system("C:\\PROGRA~1\\IMAGEM~1\\identify mask_ani.gif")

Here is a result:

http://bioislands.org/sites/default/files/images/mask_ani.gif

HTH,

T. Hengl
http://www.wewur.wur.nl/popups/vcard.aspx?id=HENGL001



Op 15-3-2011 10:14, Lorenzo Alfieri schreef:
>
> Dear all,
>
> I'm new to this forum.
>
> I'm desperately looking for help, as I'm stuck with a problem and I can't find any solution.
>
> I'd like to open a raster map (for example with rgdal it is read as a
> SpatialGridDataFrame) and then save it as a gif image with a specific
> color palette.
>
> I can't find the way to specify the color, so I can only create greyscale images.
>
> It sounds simple but nothing seems to work.
>
> I've been trying with:
>
>
>
> Kp1P<- readGDAL(mymap)
>
> writeGDAL(Kp1P,"myGIFmap.gif",drivername="gif",col=colmed)
>
>
>
> but col is not an option in writeGDAL command
>
>
>
> I need to specify this colors:
>
> colmed<-c(rep(rgb(255/255, 204/255, 204/255),10),rep(rgb(255/255,
> 184/255, 176/255),10),rep(rgb(255/255, 164/255,
> 176/255),10),rep(rgb(255/255, 144/255, 125/255),10),
>
>    rep(rgb(250/255, 125/255, 102/255),10),rep(rgb(247/255, 104/255,
> 79/255),10),rep(rgb(242/255, 85/255, 61/255),10),rep(rgb(235/255,
> 65/255, 42/255),10),
>
>    rep(rgb(227/255, 40/255, 23/255),10),rep(rgb(219/255, 0/255, 0/255),10))
>
>
>
> HELP!
>
>
>
> Lorenzo
> 				 		 	   		
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From rainer.stowasser at wissenschaftsrat.ac.at  Tue Mar 15 16:42:15 2011
From: rainer.stowasser at wissenschaftsrat.ac.at (Stowasser Rainer)
Date: Tue, 15 Mar 2011 16:42:15 +0100
Subject: [R-sig-Geo] simple spplot problem (colorkey inside the plotting
	area)
Message-ID: <7D0D9DB31BB68B45876EF2D0F80E51101943C1@constitution.wissenschaftsrat.ac.at>

I'm using spplot to color regions of Austria
Everything works fine
But I like to have the colorkey INSIDE the plotting area (in the Bavaria
window :-)

space just puts it outside (top, bottom, left, right)

as the spplot is a lattice object it should be possible

I've tried the examples from http://r-spatial.sourceforge.net/gallery/
With the key.space=list(x=0.2,y=0.9,corner=c(0,1))
But this is simply ignored

Is there a way to do this (without using a lattice layer and rebuilding
the colorkey ;-)

I'm using R  2.12.2
Package sp version 0.9-78

Every help would be welcome

Rainer


From murray_richardson at carleton.ca  Tue Mar 15 17:37:29 2011
From: murray_richardson at carleton.ca (Murray Richardson)
Date: Tue, 15 Mar 2011 12:37:29 -0400
Subject: [R-sig-Geo] minimum area bounding rectangles
Message-ID: <4D7F95C9.6010207@carleton.ca>

Hi R users,

I would like to compute minimum area bounding rectangles for polygon 
features to extract short and long axes and azimuths of the long axes.  
Is this possible in R? I have not been able to find a way (yet).

Thanks in advance for any help.

Murray


From aman.verma at mcgill.ca  Tue Mar 15 17:53:25 2011
From: aman.verma at mcgill.ca (Aman Verma)
Date: Tue, 15 Mar 2011 12:53:25 -0400
Subject: [R-sig-Geo] minimum area bounding rectangles
In-Reply-To: <4D7F95C9.6010207@carleton.ca>
References: <4D7F95C9.6010207@carleton.ca>
Message-ID: <FF83BA46F4BA3C49A1EADAEFE9FD1B4A0A1A522BF0@EXMBXVS1.campus.mcgill.ca>

bbox in the sp package is what you are looking for.

-----Original Message-----
From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Murray Richardson
Sent: March 15, 2011 12:37 PM
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] minimum area bounding rectangles

Hi R users,

I would like to compute minimum area bounding rectangles for polygon 
features to extract short and long axes and azimuths of the long axes.  
Is this possible in R? I have not been able to find a way (yet).

Thanks in advance for any help.

Murray

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From murray_richardson at carleton.ca  Tue Mar 15 18:21:05 2011
From: murray_richardson at carleton.ca (Murray Richardson)
Date: Tue, 15 Mar 2011 13:21:05 -0400
Subject: [R-sig-Geo] minimum area bounding rectangles - bbox() not the
 solution
In-Reply-To: <FF83BA46F4BA3C49A1EADAEFE9FD1B4A0A1A522BF0@EXMBXVS1.campus.mcgill.ca>
References: <4D7F95C9.6010207@carleton.ca>
	<FF83BA46F4BA3C49A1EADAEFE9FD1B4A0A1A522BF0@EXMBXVS1.campus.mcgill.ca>
Message-ID: <4D7FA001.1000808@carleton.ca>

Thanks for your advice Arman.  Unfortunately bbox is just the minimum 
bounding rectangle (i.e. min and max of x and y), not the minimum area 
bounding rectangle.  I need MABR to get the short and long axes info.

I will wait for addition advice from others.

Murray

On 15/03/2011 12:53 PM, Aman Verma wrote:
> bbox in the sp package is what you are looking for.
>
> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Murray Richardson
> Sent: March 15, 2011 12:37 PM
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] minimum area bounding rectangles
>
> Hi R users,
>
> I would like to compute minimum area bounding rectangles for polygon
> features to extract short and long axes and azimuths of the long axes.
> Is this possible in R? I have not been able to find a way (yet).
>
> Thanks in advance for any help.
>
> Murray
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From research at georgruss.de  Tue Mar 15 20:07:45 2011
From: research at georgruss.de (Georg =?iso-8859-15?B?UnXf?=)
Date: Tue, 15 Mar 2011 20:07:45 +0100
Subject: [R-sig-Geo] simple spplot problem (colorkey inside the plotting
 area)
In-Reply-To: <7D0D9DB31BB68B45876EF2D0F80E51101943C1@constitution.wissenschaftsrat.ac.at>
References: <7D0D9DB31BB68B45876EF2D0F80E51101943C1@constitution.wissenschaftsrat.ac.at>
Message-ID: <20110315190745.GV5866@greode>

On 15/03/11 16:42:15, Stowasser Rainer wrote:
> I'm using spplot to color regions of Austria
> Everything works fine
> But I like to have the colorkey INSIDE the plotting area (in the Bavaria
> window :-)
>
> space just puts it outside (top, bottom, left, right)
>
> as the spplot is a lattice object it should be possible
>
> I've tried the examples from http://r-spatial.sourceforge.net/gallery/
> With the key.space=list(x=0.2,y=0.9,corner=c(0,1))
> But this is simply ignored

Hi Rainer,

I'm not sure whether I can help, but as soon as I include a
"key.space=list(x=0, y=0, corner=c(0,0))" into an spplot call, the color
key wanders into the plotting rectangle. The (minimal) full call here is:

print(spplot(sppdf, zcol = i, key.space=list(x=0,y=0.01,corner=c(0,0))))

(inside the postscript device for producing eps figures)

If you have, maybe post some code that we can try; or the structure of
your data frame and some further lines to experiment with.

Regards,
Georg.
-- 
Research Assistant
Otto-von-Guericke-Universit?t Magdeburg (nicht in Bayern :-)
research at georgruss.de
http://research.georgruss.de


From v8extra at gmail.com  Tue Mar 15 23:59:30 2011
From: v8extra at gmail.com (=?iso-8859-1?Q?S=E9bastien_Durand?=)
Date: Tue, 15 Mar 2011 18:59:30 -0400
Subject: [R-sig-Geo] R2 values from SSErr fit.variogram attribute
Message-ID: <ACC4BC94-B7A0-4BA5-A86E-270DBAFAAAC2@gmail.com>

Thanks a lot, 

I understand what you meant now.

I was like you said the general the fact that the computed means used to produce de SSErr value was obviously weighted and there to get a true R2 the same weighted means had to be used in the computation for the SSTot...

Thanks a lot for your patience.

I wish you all to live long and prosper.

S.

From b.rowlingson at lancaster.ac.uk  Wed Mar 16 00:20:12 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 15 Mar 2011 23:20:12 +0000
Subject: [R-sig-Geo] minimum area bounding rectangles
In-Reply-To: <4D7F95C9.6010207@carleton.ca>
References: <4D7F95C9.6010207@carleton.ca>
Message-ID: <AANLkTinE6paXYN-rQOJrbhO2dnHL6dHcCGDDT+jMQeFB@mail.gmail.com>

On Tue, Mar 15, 2011 at 4:37 PM, Murray Richardson
<murray_richardson at carleton.ca> wrote:
> Hi R users,
>
> I would like to compute minimum area bounding rectangles for polygon
> features to extract short and long axes and azimuths of the long axes. ?Is
> this possible in R? I have not been able to find a way (yet).
>
> Thanks in advance for any help.

 Do you mean you've not found code for it or not found and implemented
an algorithm for it?

 There's a proof that the minimum area bounding rectangle of a convex
polygon will have one side along a side of the polygon, so the
algorithm involves N rotations of the polygon and computation of the
area of the axis-aligned bounding box after rotation. Choose the
rotation that minimises this.

 In R, chull will get you the convex hull, atan2 will get you the
angles, and sines and cosines will get you a rotation matrix. There's
some matlab code here:

http://www.mathworks.com/matlabcentral/fileexchange/13624-minimal-bounding-rectangle

 which might be useful.

Barry


From murray_richardson at carleton.ca  Wed Mar 16 00:40:38 2011
From: murray_richardson at carleton.ca (Murray Richardson)
Date: Tue, 15 Mar 2011 19:40:38 -0400
Subject: [R-sig-Geo] minimum area bounding rectangles
In-Reply-To: <AANLkTinE6paXYN-rQOJrbhO2dnHL6dHcCGDDT+jMQeFB@mail.gmail.com>
References: <4D7F95C9.6010207@carleton.ca>
	<AANLkTinE6paXYN-rQOJrbhO2dnHL6dHcCGDDT+jMQeFB@mail.gmail.com>
Message-ID: <4D7FF8F6.6060709@carleton.ca>

Thanks Barry for the great tips.  The MATLAB code will be a huge help - 
should be relatively straightforward to implement in R.

cheers,

Murray

On 15/03/2011 7:20 PM, Barry Rowlingson wrote:
> On Tue, Mar 15, 2011 at 4:37 PM, Murray Richardson
> <murray_richardson at carleton.ca>  wrote:
>> Hi R users,
>>
>> I would like to compute minimum area bounding rectangles for polygon
>> features to extract short and long axes and azimuths of the long axes.  Is
>> this possible in R? I have not been able to find a way (yet).
>>
>> Thanks in advance for any help.
>   Do you mean you've not found code for it or not found and implemented
> an algorithm for it?
>
>   There's a proof that the minimum area bounding rectangle of a convex
> polygon will have one side along a side of the polygon, so the
> algorithm involves N rotations of the polygon and computation of the
> area of the axis-aligned bounding box after rotation. Choose the
> rotation that minimises this.
>
>   In R, chull will get you the convex hull, atan2 will get you the
> angles, and sines and cosines will get you a rotation matrix. There's
> some matlab code here:
>
> http://www.mathworks.com/matlabcentral/fileexchange/13624-minimal-bounding-rectangle
>
>   which might be useful.
>
> Barry


From b.rowlingson at lancaster.ac.uk  Wed Mar 16 00:47:31 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 15 Mar 2011 23:47:31 +0000
Subject: [R-sig-Geo] minimum area bounding rectangles
In-Reply-To: <4D7FF8F6.6060709@carleton.ca>
References: <4D7F95C9.6010207@carleton.ca>
	<AANLkTinE6paXYN-rQOJrbhO2dnHL6dHcCGDDT+jMQeFB@mail.gmail.com>
	<4D7FF8F6.6060709@carleton.ca>
Message-ID: <AANLkTim1PVJ6Lx1cBwuE1s17K3ma5_qbBuDGtYzBNTyM@mail.gmail.com>

Shazam:

minbb <- function(pts){

  ch = chull(pts)
  pts=pts[ch,]
  np = nrow(pts)
  pts=rbind(pts,pts[1,])
  minbba = Inf ; bbth = NA; rotmin = NA
  for(i in 1:np){
    th = pi-atan2(pts[i+1,2]-pts[i,2],pts[i+1,1]-pts[i,1])
    prot = rotxy(pts,th)
    bba = diff(range(prot[,1])) * diff(range(prot[,2]))
    if(bba < minbba){
      xyb=cbind(
        c(min(prot[,1]),max(prot[,1]),max(prot[,1]),min(prot[,1])),
        c(min(prot[,2]),min(prot[,2]),max(prot[,2]),max(prot[,2]))
        )
      xyb=rbind(xyb,xyb[1,])
      xyb= rotxy(xyb,-th)

      rotmin=prot
      minbba = bba
      bbth = th
    }
  }
  return(list(minbba=minbba,theta=th,pts=rotmin,box=xyb))

}

rotxy = function(pts,angle){
  co = cos(angle)
  si = sin(angle)
  cbind(co * pts[,1] - si * pts[,2], si * pts[,1] + co * pts[,2])
}

And usage:

 > pts=cbind(runif(60),runif(60))
 > bb=minbb(pts)
 > plot(bb$box,type="l")
 > points(pts)
 > pts2=rotxy(pts,pi/1.6)
 > bb2=minbb(pts2)
 > plot(bb2$box,type="l")
 > points(pts2)


> Thanks Barry for the great tips. ?The MATLAB code will be a huge help -
> should be relatively straightforward to implement in R.

 Wrote this myself with a helpful rotate function nabbed from
spatstat. Could be optimised a bit, I reckon.

Barry


From murray_richardson at carleton.ca  Wed Mar 16 01:05:31 2011
From: murray_richardson at carleton.ca (Murray Richardson)
Date: Tue, 15 Mar 2011 20:05:31 -0400
Subject: [R-sig-Geo] minimum area bounding rectangles
In-Reply-To: <AANLkTim1PVJ6Lx1cBwuE1s17K3ma5_qbBuDGtYzBNTyM@mail.gmail.com>
References: <4D7F95C9.6010207@carleton.ca>
	<AANLkTinE6paXYN-rQOJrbhO2dnHL6dHcCGDDT+jMQeFB@mail.gmail.com>
	<4D7FF8F6.6060709@carleton.ca>
	<AANLkTim1PVJ6Lx1cBwuE1s17K3ma5_qbBuDGtYzBNTyM@mail.gmail.com>
Message-ID: <4D7FFECB.6080602@carleton.ca>

Wow, what can I say!? Thanks a million!  I will try it out thoroughly 
tomorrow.

Murray

On 15/03/2011 7:47 PM, Barry Rowlingson wrote:
> Shazam:
>
> minbb<- function(pts){
>
>    ch = chull(pts)
>    pts=pts[ch,]
>    np = nrow(pts)
>    pts=rbind(pts,pts[1,])
>    minbba = Inf ; bbth = NA; rotmin = NA
>    for(i in 1:np){
>      th = pi-atan2(pts[i+1,2]-pts[i,2],pts[i+1,1]-pts[i,1])
>      prot = rotxy(pts,th)
>      bba = diff(range(prot[,1])) * diff(range(prot[,2]))
>      if(bba<  minbba){
>        xyb=cbind(
>          c(min(prot[,1]),max(prot[,1]),max(prot[,1]),min(prot[,1])),
>          c(min(prot[,2]),min(prot[,2]),max(prot[,2]),max(prot[,2]))
>          )
>        xyb=rbind(xyb,xyb[1,])
>        xyb= rotxy(xyb,-th)
>
>        rotmin=prot
>        minbba = bba
>        bbth = th
>      }
>    }
>    return(list(minbba=minbba,theta=th,pts=rotmin,box=xyb))
>
> }
>
> rotxy = function(pts,angle){
>    co = cos(angle)
>    si = sin(angle)
>    cbind(co * pts[,1] - si * pts[,2], si * pts[,1] + co * pts[,2])
> }
>
> And usage:
>
>   >  pts=cbind(runif(60),runif(60))
>   >  bb=minbb(pts)
>   >  plot(bb$box,type="l")
>   >  points(pts)
>   >  pts2=rotxy(pts,pi/1.6)
>   >  bb2=minbb(pts2)
>   >  plot(bb2$box,type="l")
>   >  points(pts2)
>
>
>> Thanks Barry for the great tips.  The MATLAB code will be a huge help -
>> should be relatively straightforward to implement in R.
>   Wrote this myself with a helpful rotate function nabbed from
> spatstat. Could be optimised a bit, I reckon.
>
> Barry


From rainer.stowasser at wissenschaftsrat.ac.at  Wed Mar 16 10:48:39 2011
From: rainer.stowasser at wissenschaftsrat.ac.at (Stowasser Rainer)
Date: Wed, 16 Mar 2011 10:48:39 +0100
Subject: [R-sig-Geo] simple spplot problem (colorkey inside the plotting
	area)
In-Reply-To: <20110315190745.GV5866@greode>
References: <7D0D9DB31BB68B45876EF2D0F80E51101943C1@constitution.wissenschaftsrat.ac.at>
	<20110315190745.GV5866@greode>
Message-ID: <7D0D9DB31BB68B45876EF2D0F80E51101943C5@constitution.wissenschaftsrat.ac.at>

Hy Georg 
For me it does not work

Here s the Code

# Rdata from http://gadm.org/countryies for Austria Bundesl?nder
load("AUT_adm1.RData")
library(sp)
library(RColorBrewer)
#percent per Bundesland in the correct order
proznormal09=c(3.76,6.57,24.52,18.05,6.59,13.94,6.91,3.74,15.91)
#produce factor
 bundeslfakt <- as.factor(as.numeric(cut(proznormal09, c(0,4,7,10,13,16,19,100)))
levels(bundeslfakt) <- c("<4%", "4-7%", "13-16%", "16-19%",">19%")
gadm$bundeslfakt <-bundeslfakt
#the plot
spplot(gadm, "bundeslfakt", col.regions=brewer.pal(5,"Reds"), main="Prozentverteilung nach Herkunftsbundesl\u00E4nder",key.space=list(x=0,y=0,corner=c(0,0)))

produces a plot with the colorkey on the right side
key.space is ignored

I hope you can reproduce the Effect ;-)
or tell me where I went wrong

Rainer

-----Urspr?ngliche Nachricht-----
Von: Georg Ru? [mailto:research at georgruss.de] 
Gesendet: Dienstag, 15. M?rz 2011 20:08
An: Stowasser Rainer
Cc: r-sig-geo at r-project.org
Betreff: Re: [R-sig-Geo] simple spplot problem (colorkey inside the plotting area)

On 15/03/11 16:42:15, Stowasser Rainer wrote:
> I'm using spplot to color regions of Austria
> Everything works fine
> But I like to have the colorkey INSIDE the plotting area (in the Bavaria
> window :-)
>
> space just puts it outside (top, bottom, left, right)
>
> as the spplot is a lattice object it should be possible
>
> I've tried the examples from http://r-spatial.sourceforge.net/gallery/
> With the key.space=list(x=0.2,y=0.9,corner=c(0,1))
> But this is simply ignored

Hi Rainer,

I'm not sure whether I can help, but as soon as I include a
"key.space=list(x=0, y=0, corner=c(0,0))" into an spplot call, the color
key wanders into the plotting rectangle. The (minimal) full call here is:

print(spplot(sppdf, zcol = i, key.space=list(x=0,y=0.01,corner=c(0,0))))

(inside the postscript device for producing eps figures)

If you have, maybe post some code that we can try; or the structure of
your data frame and some further lines to experiment with.

Regards,
Georg.
-- 
Research Assistant
Otto-von-Guericke-Universit?t Magdeburg (nicht in Bayern :-)
research at georgruss.de
http://research.georgruss.de


From hzambran.newsgroups at gmail.com  Wed Mar 16 10:53:20 2011
From: hzambran.newsgroups at gmail.com (Mauricio Zambrano)
Date: Wed, 16 Mar 2011 10:53:20 +0100
Subject: [R-sig-Geo] Is there a function for comparing a modeled
 timeseries to the measured one?
In-Reply-To: <AANLkTikwfLSvSrJwYJyDFgLtdh+QZvGNMjHGWnkO4FdR@mail.gmail.com>
References: <AANLkTikwfLSvSrJwYJyDFgLtdh+QZvGNMjHGWnkO4FdR@mail.gmail.com>
Message-ID: <AANLkTi=n+gdmv=Fjg0S-AXFbfJDLrGjFGd862yiXQLux@mail.gmail.com>

You may have a look to the 'gof' and 'ggof' functions included in the
hydroGOF package:

http://cran.r-project.org/web/packages/hydroGOF/index.html

which implement  several numerical and graphical goodness-of-?t
measures between observed and simulated values.

Kinds,

Mauricio

-- 
================================
Linux user #454569 -- Ubuntu user #17469
================================

2011/3/9 Jan Hackenberg <hacke78 at googlemail.com>:
> Dear R - Users
> I have 2 timeseries, one measured and one is modeled. The only function to
> compare them ?i know is cor(model,measured). Is there perhaps another
> function to produce the r squared, to prove that my model is well fit?
> Thanks for your time
> Jan
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From edzer.pebesma at uni-muenster.de  Wed Mar 16 12:47:03 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 16 Mar 2011 12:47:03 +0100
Subject: [R-sig-Geo] simple spplot problem (colorkey inside the plotting
 area)
In-Reply-To: <7D0D9DB31BB68B45876EF2D0F80E51101943C5@constitution.wissenschaftsrat.ac.at>
References: <7D0D9DB31BB68B45876EF2D0F80E51101943C1@constitution.wissenschaftsrat.ac.at>	<20110315190745.GV5866@greode>
	<7D0D9DB31BB68B45876EF2D0F80E51101943C5@constitution.wissenschaftsrat.ac.at>
Message-ID: <4D80A337.3090303@uni-muenster.de>

Dear Rainer,

spplot is a wrapper function around levelplot (for grids, polygons and
lines) or xyplot (for points), both in package lattice.

As the documentation mentions, the key.space argument is only available
for points, where it is passed (as key argument) to xyplot.

I looked up the documentation of ?levelplot (after loading lattice), and
although it does have x and y componenents for the colorkey, it does
explicitly mention that these are not implemented. The only things you
can modify are the key height/width, and the space argument ('bottom',
'left', 'right', 'top'). I do not see a possibility to move the key to
wherever you want.

I cc:'d this message to Deepayan Sarkar, the lattice author, maybe he
has a suggestion where to look next.

On 03/16/2011 10:48 AM, Stowasser Rainer wrote:
> Hy Georg 
> For me it does not work
> 
> Here s the Code
> 
> # Rdata from http://gadm.org/countryies for Austria Bundesl?nder
> load("AUT_adm1.RData")
> library(sp)
> library(RColorBrewer)
> #percent per Bundesland in the correct order
> proznormal09=c(3.76,6.57,24.52,18.05,6.59,13.94,6.91,3.74,15.91)
> #produce factor
>  bundeslfakt <- as.factor(as.numeric(cut(proznormal09, c(0,4,7,10,13,16,19,100)))
> levels(bundeslfakt) <- c("<4%", "4-7%", "13-16%", "16-19%",">19%")
> gadm$bundeslfakt <-bundeslfakt
> #the plot
> spplot(gadm, "bundeslfakt", col.regions=brewer.pal(5,"Reds"), main="Prozentverteilung nach Herkunftsbundesl\u00E4nder",key.space=list(x=0,y=0,corner=c(0,0)))
> 
> produces a plot with the colorkey on the right side
> key.space is ignored
> 
> I hope you can reproduce the Effect ;-)
> or tell me where I went wrong
> 
> Rainer
> 
> -----Urspr?ngliche Nachricht-----
> Von: Georg Ru? [mailto:research at georgruss.de] 
> Gesendet: Dienstag, 15. M?rz 2011 20:08
> An: Stowasser Rainer
> Cc: r-sig-geo at r-project.org
> Betreff: Re: [R-sig-Geo] simple spplot problem (colorkey inside the plotting area)
> 
> On 15/03/11 16:42:15, Stowasser Rainer wrote:
>> I'm using spplot to color regions of Austria
>> Everything works fine
>> But I like to have the colorkey INSIDE the plotting area (in the Bavaria
>> window :-)
>>
>> space just puts it outside (top, bottom, left, right)
>>
>> as the spplot is a lattice object it should be possible
>>
>> I've tried the examples from http://r-spatial.sourceforge.net/gallery/
>> With the key.space=list(x=0.2,y=0.9,corner=c(0,1))
>> But this is simply ignored
> 
> Hi Rainer,
> 
> I'm not sure whether I can help, but as soon as I include a
> "key.space=list(x=0, y=0, corner=c(0,0))" into an spplot call, the color
> key wanders into the plotting rectangle. The (minimal) full call here is:
> 
> print(spplot(sppdf, zcol = i, key.space=list(x=0,y=0.01,corner=c(0,0))))
> 
> (inside the postscript device for producing eps figures)
> 
> If you have, maybe post some code that we can try; or the structure of
> your data frame and some further lines to experiment with.
> 
> Regards,
> Georg.

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From adiez at uv.es  Wed Mar 16 13:49:37 2011
From: adiez at uv.es (Agustin Diez Castillo)
Date: Wed, 16 Mar 2011 13:49:37 +0100
Subject: [R-sig-Geo] RgoogleMaps
In-Reply-To: <1296763970972-5990287.post@n2.nabble.com>
References: <B451F396CD230E468613575D48F2EF070B36D203C1@scomp0537.wurnet.nl>
	<4D4ADFAE.4050805@spatial-analyst.net>
	<1296763970972-5990287.post@n2.nabble.com>
Message-ID: <90049227-9080-4F28-93A2-47001E25299D@uv.es>

Following on  that I wish to download several single tiles. To do it I declare the tile extension I wish to download and adapting Robert's hint  I do the following
library(dismo)
#I need to load XML as well
library(XML)
library(maptools)
library(rgdal)
#declare the extent
e = extent(36.1195,36.1205,5.8725,5.8735)
#got the map, exp less than 1.0 zooms the result
r <- gmap(e, type="satellite", filename="mypath/mynumbered.gif", exp=1.0)
#check the result
plot(r)

The thing is that now I want to download several tiles getting the extent from a table that looks like that
       xmin     xmax     ymin     ymax num
1  36.09940 36.10340 5.671173 5.675173  10
2  36.19274 36.19674 5.665194 5.669194  15
3  36.17748 36.18148 5.820774 5.824774  19
4  36.19274 36.19674 5.665194 5.669194  43
5  36.09940 36.10340 5.671173 5.675173  44
6  36.17748 36.18148 5.820774 5.824774  46
so I want pass values from the table to 'extent' and get and numbered gif for each.
Any ideas?
Cheers
Agustin
sessionInfo
R version 2.11.1 Patched (2010-08-26 r52824)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] en_US/en_US/en_US/C/en_US/en_US

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] maps_2.1-4      gpclib_1.5-1    maptools_0.7-38 lattice_0.18-8  foreign_0.8-40  XML_3.2-0       dismo_0.5-11    rJava_0.8-8     raster_1.7-29  
[10] rgdal_0.6-28    sp_0.9-76      

loaded via a namespace (and not attached):
[1] grid_2.11.1  tools_2.11.1



On Feb 3, 2011, at 9:12 PM, Robert Hijmans wrote:

> 
>> Dear all, 
>> I'm using the package RgoogleMaps to import google earth maps into R. The
>> object that is retrieved with function GetMap contains a number of slots
>> which I think can be used to translate the google picture into a geoTiff
>> to for example import into ArgGis. 
>> If anyone would have an example of how to accomplish that or what function
>> to use, I'd be very greatful. 
>> Best wishes, 
>> Erik Meesters 
>> 
> 
> Here is how you can get a single tile
> 
> library(dismo)
> library(maptools)
> library(rgdal)
> 
> # get a google map
> g <- gmap("Australia")
> plot(g)
> 
> # overlay boundaries, after projecting to Mercator
> data(wrld_simpl)
> w = wrld_simpl[wrld_simpl at data[,"NAME"] != "Antarctica", ]
> m = spTransform(w, projection(g, asText=F))
> plot(m, add=T)
> 
> # export to png
> filename <- 'oz.png'
> png(filename, width=ncol(g), height=nrow(g))
> par(mar=c(0,0,0,0))
> image(g, col=g at legend@colortable)
> dev.off()
> 
> # create 'world file' for georferencing png
> r <- raster(filename)
> extent(r) <- extent(g)
> hdr(r, 'worldfile', 'pgw')
> 
> # now open the file in ArcMap
> 
> -- 
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/RgoogleMaps-tp5989261p5990287.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 


From edzer.pebesma at uni-muenster.de  Wed Mar 16 14:33:06 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 16 Mar 2011 14:33:06 +0100
Subject: [R-sig-Geo] Fwd: Re: simple spplot problem (colorkey inside the
 plotting area)
Message-ID: <4D80BC12.8000707@uni-muenster.de>

I'm forwarding this to r-sig-geo on Deepayan's request.

Thanks, Deepayan!

-------- Original Message --------
Subject: Re: [R-sig-Geo] simple spplot problem (colorkey inside the
plotting area)
Date: Wed, 16 Mar 2011 18:53:46 +0530
From: Deepayan Sarkar <deepayan.sarkar at gmail.com>
To: Edzer Pebesma <edzer.pebesma at uni-muenster.de>
CC: r-sig-geo at r-project.org

On Wed, Mar 16, 2011 at 5:17 PM, Edzer Pebesma
<edzer.pebesma at uni-muenster.de> wrote:
> Dear Rainer,
>
> spplot is a wrapper function around levelplot (for grids, polygons and
> lines) or xyplot (for points), both in package lattice.
>
> As the documentation mentions, the key.space argument is only available
> for points, where it is passed (as key argument) to xyplot.
>
> I looked up the documentation of ?levelplot (after loading lattice), and
> although it does have x and y componenents for the colorkey, it does
> explicitly mention that these are not implemented. The only things you
> can modify are the key height/width, and the space argument ('bottom',
> 'left', 'right', 'top'). I do not see a possibility to move the key to
> wherever you want.
>
> I cc:'d this message to Deepayan Sarkar, the lattice author, maybe he
> has a suggestion where to look next.

One option is to draw the legend in the panel function:

require(grid)

pleg <- levelplot(volcano)$legend ## cheat to get default legend details

levelplot(volcano, colorkey = FALSE,
          panel = function(...) {
              panel.levelplot(...)
              draw.colorkey(key = c(pleg$right$args$key, height = 0.6),
                            draw = TRUE,
                            vp = viewport(0.8, 0.5, default.units = "npc"))
          })


Adding support for (x, y) in colorkey is not technically that
challenging. You can produce the equivalent as follows:

p <- levelplot(volcano)
names(p$legend) <- "inside"
p$legend$inside$x <- 0.8
p$legend$inside$y <- 0.7
plot(p)

The only thing is that colorkeys are "expanding" (unlike regular keys
as in xyplot), and I have never been able to figure out a reasonable
expansion rule when it's placed in an arbitrary location. Maybe I
should just implement it as is and let users figure out something that
works for them.

-Deepayan



>
> On 03/16/2011 10:48 AM, Stowasser Rainer wrote:
>> Hy Georg
>> For me it does not work
>>
>> Here s the Code
>>
>> # Rdata from http://gadm.org/countryies for Austria Bundesl?nder
>> load("AUT_adm1.RData")
>> library(sp)
>> library(RColorBrewer)
>> #percent per Bundesland in the correct order
>> proznormal09=c(3.76,6.57,24.52,18.05,6.59,13.94,6.91,3.74,15.91)
>> #produce factor
>>  bundeslfakt <- as.factor(as.numeric(cut(proznormal09, c(0,4,7,10,13,16,19,100)))
>> levels(bundeslfakt) <- c("<4%", "4-7%", "13-16%", "16-19%",">19%")
>> gadm$bundeslfakt <-bundeslfakt
>> #the plot
>> spplot(gadm, "bundeslfakt", col.regions=brewer.pal(5,"Reds"), main="Prozentverteilung nach Herkunftsbundesl\u00E4nder",key.space=list(x=0,y=0,corner=c(0,0)))
>>
>> produces a plot with the colorkey on the right side
>> key.space is ignored
>>
>> I hope you can reproduce the Effect ;-)
>> or tell me where I went wrong
>>
>> Rainer
>>
>> -----Urspr?ngliche Nachricht-----
>> Von: Georg Ru? [mailto:research at georgruss.de]
>> Gesendet: Dienstag, 15. M?rz 2011 20:08
>> An: Stowasser Rainer
>> Cc: r-sig-geo at r-project.org
>> Betreff: Re: [R-sig-Geo] simple spplot problem (colorkey inside the plotting area)
>>
>> On 15/03/11 16:42:15, Stowasser Rainer wrote:
>>> I'm using spplot to color regions of Austria
>>> Everything works fine
>>> But I like to have the colorkey INSIDE the plotting area (in the Bavaria
>>> window :-)
>>>
>>> space just puts it outside (top, bottom, left, right)
>>>
>>> as the spplot is a lattice object it should be possible
>>>
>>> I've tried the examples from http://r-spatial.sourceforge.net/gallery/
>>> With the key.space=list(x=0.2,y=0.9,corner=c(0,1))
>>> But this is simply ignored
>>
>> Hi Rainer,
>>
>> I'm not sure whether I can help, but as soon as I include a
>> "key.space=list(x=0, y=0, corner=c(0,0))" into an spplot call, the color
>> key wanders into the plotting rectangle. The (minimal) full call here is:
>>
>> print(spplot(sppdf, zcol = i, key.space=list(x=0,y=0.01,corner=c(0,0))))
>>
>> (inside the postscript device for producing eps figures)
>>
>> If you have, maybe post some code that we can try; or the structure of
>> your data frame and some further lines to experiment with.
>>
>> Regards,
>> Georg.
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> 8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
> http://www.52north.org/geostatistics      e.pebesma at wwu.de
>


From rainer.stowasser at wissenschaftsrat.ac.at  Wed Mar 16 15:06:04 2011
From: rainer.stowasser at wissenschaftsrat.ac.at (Stowasser Rainer)
Date: Wed, 16 Mar 2011 15:06:04 +0100
Subject: [R-sig-Geo] Fwd: Re: simple spplot problem (colorkey inside the
	plotting area)
In-Reply-To: <4D80BC12.8000707@uni-muenster.de>
References: <4D80BC12.8000707@uni-muenster.de>
Message-ID: <7D0D9DB31BB68B45876EF2D0F80E51101943E0@constitution.wissenschaftsrat.ac.at>

p <- spplot(...)
names(p$legend) <- "inside"
p$legend$inside$x <- 0.8
p$legend$inside$y <- 0.7
plot(p)

works perfect

Many thx for the fast solution

Rainer

-----Urspr?ngliche Nachricht-----
Von: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-project.org] Im Auftrag von Edzer Pebesma
Gesendet: Mittwoch, 16. M?rz 2011 14:33
An: sig-geo
Cc: deepayan.sarkar at gmail.com
Betreff: [R-sig-Geo] Fwd: Re: simple spplot problem (colorkey inside the plotting area)

I'm forwarding this to r-sig-geo on Deepayan's request.

Thanks, Deepayan!

-------- Original Message --------
Subject: Re: [R-sig-Geo] simple spplot problem (colorkey inside the
plotting area)
Date: Wed, 16 Mar 2011 18:53:46 +0530
From: Deepayan Sarkar <deepayan.sarkar at gmail.com>
To: Edzer Pebesma <edzer.pebesma at uni-muenster.de>
CC: r-sig-geo at r-project.org

On Wed, Mar 16, 2011 at 5:17 PM, Edzer Pebesma
<edzer.pebesma at uni-muenster.de> wrote:
> Dear Rainer,
>
> spplot is a wrapper function around levelplot (for grids, polygons and
> lines) or xyplot (for points), both in package lattice.
>
> As the documentation mentions, the key.space argument is only available
> for points, where it is passed (as key argument) to xyplot.
>
> I looked up the documentation of ?levelplot (after loading lattice), and
> although it does have x and y componenents for the colorkey, it does
> explicitly mention that these are not implemented. The only things you
> can modify are the key height/width, and the space argument ('bottom',
> 'left', 'right', 'top'). I do not see a possibility to move the key to
> wherever you want.
>
> I cc:'d this message to Deepayan Sarkar, the lattice author, maybe he
> has a suggestion where to look next.

One option is to draw the legend in the panel function:

require(grid)

pleg <- levelplot(volcano)$legend ## cheat to get default legend details

levelplot(volcano, colorkey = FALSE,
          panel = function(...) {
              panel.levelplot(...)
              draw.colorkey(key = c(pleg$right$args$key, height = 0.6),
                            draw = TRUE,
                            vp = viewport(0.8, 0.5, default.units = "npc"))
          })


Adding support for (x, y) in colorkey is not technically that
challenging. You can produce the equivalent as follows:

p <- levelplot(volcano)
names(p$legend) <- "inside"
p$legend$inside$x <- 0.8
p$legend$inside$y <- 0.7
plot(p)

The only thing is that colorkeys are "expanding" (unlike regular keys
as in xyplot), and I have never been able to figure out a reasonable
expansion rule when it's placed in an arbitrary location. Maybe I
should just implement it as is and let users figure out something that
works for them.

-Deepayan



>
> On 03/16/2011 10:48 AM, Stowasser Rainer wrote:
>> Hy Georg
>> For me it does not work
>>
>> Here s the Code
>>
>> # Rdata from http://gadm.org/countryies for Austria Bundesl?nder
>> load("AUT_adm1.RData")
>> library(sp)
>> library(RColorBrewer)
>> #percent per Bundesland in the correct order
>> proznormal09=c(3.76,6.57,24.52,18.05,6.59,13.94,6.91,3.74,15.91)
>> #produce factor
>>  bundeslfakt <- as.factor(as.numeric(cut(proznormal09, c(0,4,7,10,13,16,19,100)))
>> levels(bundeslfakt) <- c("<4%", "4-7%", "13-16%", "16-19%",">19%")
>> gadm$bundeslfakt <-bundeslfakt
>> #the plot
>> spplot(gadm, "bundeslfakt", col.regions=brewer.pal(5,"Reds"), main="Prozentverteilung nach Herkunftsbundesl\u00E4nder",key.space=list(x=0,y=0,corner=c(0,0)))
>>
>> produces a plot with the colorkey on the right side
>> key.space is ignored
>>
>> I hope you can reproduce the Effect ;-)
>> or tell me where I went wrong
>>
>> Rainer
>>
>> -----Urspr?ngliche Nachricht-----
>> Von: Georg Ru? [mailto:research at georgruss.de]
>> Gesendet: Dienstag, 15. M?rz 2011 20:08
>> An: Stowasser Rainer
>> Cc: r-sig-geo at r-project.org
>> Betreff: Re: [R-sig-Geo] simple spplot problem (colorkey inside the plotting area)
>>
>> On 15/03/11 16:42:15, Stowasser Rainer wrote:
>>> I'm using spplot to color regions of Austria
>>> Everything works fine
>>> But I like to have the colorkey INSIDE the plotting area (in the Bavaria
>>> window :-)
>>>
>>> space just puts it outside (top, bottom, left, right)
>>>
>>> as the spplot is a lattice object it should be possible
>>>
>>> I've tried the examples from http://r-spatial.sourceforge.net/gallery/
>>> With the key.space=list(x=0.2,y=0.9,corner=c(0,1))
>>> But this is simply ignored
>>
>> Hi Rainer,
>>
>> I'm not sure whether I can help, but as soon as I include a
>> "key.space=list(x=0, y=0, corner=c(0,0))" into an spplot call, the color
>> key wanders into the plotting rectangle. The (minimal) full call here is:
>>
>> print(spplot(sppdf, zcol = i, key.space=list(x=0,y=0.01,corner=c(0,0))))
>>
>> (inside the postscript device for producing eps figures)
>>
>> If you have, maybe post some code that we can try; or the structure of
>> your data frame and some further lines to experiment with.
>>
>> Regards,
>> Georg.
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> 8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
> http://www.52north.org/geostatistics      e.pebesma at wwu.de
>

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

From aelmore at usgs.gov  Wed Mar 16 15:27:52 2011
From: aelmore at usgs.gov (Annette H Elmore)
Date: Wed, 16 Mar 2011 10:27:52 -0400
Subject: [R-sig-Geo] sample semivariogram use,
	retrieving anisotropic parameters, subsampling
In-Reply-To: <mailman.19.1300186805.4951.r-sig-geo@r-project.org>
References: <mailman.19.1300186805.4951.r-sig-geo@r-project.org>
Message-ID: <OF4027245D.B1C7165D-ON85257854.0044A5AD-85257855.004F7582@usgs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110316/8525844a/attachment.pl>

From mathieu.rajerison at gmail.com  Wed Mar 16 16:33:41 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Wed, 16 Mar 2011 16:33:41 +0100
Subject: [R-sig-Geo] EBlocal: all the residuals are equal (res$est)
Message-ID: <AANLkTin5irKjmuG5VxW7priSSM16s9SrCL03cfc7v3q_@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110316/5ab5a2f1/attachment.pl>

From etiennebr at gmail.com  Wed Mar 16 17:13:00 2011
From: etiennebr at gmail.com (Etienne Bellemare)
Date: Wed, 16 Mar 2011 12:13:00 -0400
Subject: [R-sig-Geo] Variable window on a raster
In-Reply-To: <1300060083109-6167442.post@n2.nabble.com>
References: <AANLkTi=36gFFL_EKr1XuM29eMMp6GcLBMn3WSHYFHQps@mail.gmail.com>
	<1300060083109-6167442.post@n2.nabble.com>
Message-ID: <AANLkTikMjGD+swA486cEnm7y7LRWaTU0YnqvPTTooLme@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110316/2e925df1/attachment.pl>

From david.depew at queensu.ca  Thu Mar 17 00:32:32 2011
From: david.depew at queensu.ca (david depew)
Date: Wed, 16 Mar 2011 19:32:32 -0400
Subject: [R-sig-Geo] loop through polygons for point in polygon function
Message-ID: <AANLkTimaW3f6=qwdKEEHerbp=hRNAJWF8T3NDycVTte-@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110316/756f6d4c/attachment.pl>

From paul.hiemstra at knmi.nl  Thu Mar 17 08:22:27 2011
From: paul.hiemstra at knmi.nl (Paul Hiemstra)
Date: Thu, 17 Mar 2011 08:22:27 +0100
Subject: [R-sig-Geo] sample semivariogram use,
 retrieving anisotropic parameters, subsampling
In-Reply-To: <OF4027245D.B1C7165D-ON85257854.0044A5AD-85257855.004F7582@usgs.gov>
References: <mailman.19.1300186805.4951.r-sig-geo@r-project.org>
	<OF4027245D.B1C7165D-ON85257854.0044A5AD-85257855.004F7582@usgs.gov>
Message-ID: <4D81B6B3.4030506@knmi.nl>

Hi Annette,

If you are interested in automating variogram fitting, take a look at
the autofitVariogram function from the automap package. A small example:

library(automap)
data(meuse)
coordinates(meuse) =~ x+y
variogram = autofitVariogram(zinc~1,meuse)
plot(variogram)

variogram = autofitVariogram(zinc ~ soil + ffreq + dist, meuse)
plot(variogram)

The result of autofitVariogram is both the sample variogram and the
fitted nugget. Extracting elements such as the nugget is quite simple:

nug = variogram$var_model$psill[1]
sill = variogram$var_model$psill[2] + nug
range = variogram$var_model$range[2]

hope this helps,
Paul

On 03/16/2011 03:27 PM, Annette H Elmore wrote:
> Hi,
>
> I'm new to this forum and would like to retrieve anisotropic parameters 
> from a sample semi-variogram.  I don't need to krig, because I'm already 
> working at 1 m resolution and don't have to refine any further.  Instead, 
> I'm just looking for an anisotropic description of the autocorrelation 
> patterns in the area where I'm working.  I have three  questions that I 
> hope you can address, for I've been going in circles with them, a bit:
>
> I think that I don't want to fit a spherical model to the the experimental 
> variogram, because I want to know what's actually coming out of the 
> observations themselves, but I am unclear about how the initial 
> experimental parameters are generated by gstat, prior to using them to 
> fit/converge with a model of choice (for smoothing/kriging).  Perhaps the 
> initial raw "curve" parameters aren't a good representation of the 
> experimental cloud and curve fitting is necessary to best represent my 
> data?  I will be comparing scenes through time, so my most important 
> criteria for generating the nugget, sill, and range, is consistency.  I'm 
> less concerned about smoothing in a way that would permit kriging, 
> particularly if smoothing moves me away from the raw data in a way that 
> might be inconsistent between years.  So if you have any insight into 
> this, I would love to know more.
>
> Is it possible to retrieve a nugget, sill, and range from a sample 
> variogram?  Ideally, I want to take the parameters for each image and add 
> them as the last row in an existing table.  I notice that in the gstat 
> program (non-R version) the user can tweak with an interactive interface, 
> but what I'm really after is a way to automate all of this as much as 
> possible.
>
> Is it possible to include distance tolerances for the point pairs so that 
> you can subsample the data to be evaluated, playing around with using 
> points at varying distance lengths away from one another in the 
> calculations?  For instance, if I have regularly spaced points that are 
> about 1-1.5 m apart, but want to select pairs as if only points 4 - 5 m 
> apart were present, is there a way to do that?  I could do this by 
> fiddling with the input shapefile (deleting intervening points that I 
> didn't want evaluated) before I import it, but it would be much nicer to 
> do it here if it's possible.
>
> If it's of any help, this is the code I have produced, so far:
>  
> library(maptools)
> library(gstat)
> baseCRS<-CRS("+proj=utm+zone=17+datum=NAD83")
> test <- readShapePoints("C:\\89802_test.shp", proj4string = baseCRS, 
> verbose = TRUE)
> summary(test)
> test.v <- variogram(GRID_CODE~coords.x1+coords.x2, data=test,  alpha = 
> c(0,45,90,135), 
>         cutoff =41, width = 2)
>
> Thanks,
> Annie
>  
> * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
> Annette H. Elmore
> Land Cover Dynamics & Environmental Processes
> Eastern Geographic Science Center
> U.S. Geological Survey
> 12201 Sunrise Valley Drive
> Reston, VA  20192
> Email:  aelmore at usgs.gov
> Voice:  703 648 4805
> Fax:  703 648 4603
> * * * * * * * * * * * * * *
>
> If I don't know I don't know
>                                                I think I know
>
> If I don't know I know
>                                       I think I don't know
>
> -- Knots
>     R.D. Laing
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


-- 
Paul Hiemstra, MSc
Global Climate Division
Royal Netherlands Meteorological Institute (KNMI)
Wilhelminalaan 10 | 3732 GK | De Bilt | Kamer B 3.39
P.O. Box 201 | 3730 AE | De Bilt
tel: +31 30 2206 494

http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From er.rutishauser at gmail.com  Thu Mar 17 11:38:19 2011
From: er.rutishauser at gmail.com (Ervan Rutishauser)
Date: Thu, 17 Mar 2011 11:38:19 +0100
Subject: [R-sig-Geo] Lidar data classification
Message-ID: <AANLkTi=cdWJhFshsGCmHaH7z2ihU+fZZ0+-0zexiP5nZ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110317/e8972184/attachment.pl>

From research at georgruss.de  Thu Mar 17 11:54:01 2011
From: research at georgruss.de (Georg =?iso-8859-15?B?UnXf?=)
Date: Thu, 17 Mar 2011 11:54:01 +0100
Subject: [R-sig-Geo] Lidar data classification
In-Reply-To: <AANLkTi=cdWJhFshsGCmHaH7z2ihU+fZZ0+-0zexiP5nZ@mail.gmail.com>
References: <AANLkTi=cdWJhFshsGCmHaH7z2ihU+fZZ0+-0zexiP5nZ@mail.gmail.com>
Message-ID: <20110317105359.GG5866@greode>

On 17/03/11 11:38:19, Ervan Rutishauser wrote:
> Dear all,
>
> I would like to perform a classification of a large lidar data points
> acquired over a tropical forest plot network (500 km2).
> I computed the mean canopy(tree) height by 5m x 5m cell (pixel) and 3 others
> parameters (max height, height variation over 2 years, mean height in a 50m
> x 50 m neighborhood)
> I did most of this using the raster package.
> Now, I have a kind of multispectral image with 4 layers and I would like to
> perform a large-scale classification of the data based on these 4
> parameters. My aim is to find out "homogeneous" canopy regions, for
> instance: high canopy with low change over the 2 years, canopy gaps, areas
> of recruitment, etc.
>
> I tried to perfom a standard cluster analysis (hclust), but I could not
> compute the dissimilarity matrix (dist) on such a big data set (80'000 rows
> and 4 variables), even with a 64-bits PC.
> The k-means (kmeans{}) classification works, but return me strange results
> (4 main clusters north/south/east/west). I have seen that the biOps package
> allowed to do isodata classification. However isodata{} required an image
> and I don't know how to compute a 4-layer image (if possible).

Hi Ervan,

it seems you're up to doing some clustering on spatial data (which is
similar to classification here). In other words, you have a
spatialPointsDataFrame, and each of the points has four variables' values
attached (canopyheight, max height, ...).  The spatial data points are
uniformly (or on a grid) distributed in space, I guess.  

If the above is correct: I've developed something that can perform
exploratory clustering on this type of data sets. Nearly the same type of
data occur in precision agriculture and they want to find management zones
(management zone delineation): homogeneous areas inside a field. I'm
currently working on that task and it's part of my PhD thesis. If you
want, you can have a look at this publication of mine at last year's
precision agriculture conference:
http://fuzzy.cs.uni-magdeburg.de/aigaion/index.php/publications/show/772

I've written all of this in R and maybe we can have a look at the
clustering I've done. I think what you want is probably something that
gives you a first look at the data and helps you in delineating your
forest into zones, if that's what you want.

Regards,
Georg.
-- 
Research Assistant
Otto-von-Guericke-Universit?t Magdeburg
research at georgruss.de
http://research.georgruss.de


From hengl at spatial-analyst.net  Thu Mar 17 12:00:56 2011
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Thu, 17 Mar 2011 12:00:56 +0100
Subject: [R-sig-Geo] Lidar data classification
In-Reply-To: <AANLkTi=cdWJhFshsGCmHaH7z2ihU+fZZ0+-0zexiP5nZ@mail.gmail.com>
References: <AANLkTi=cdWJhFshsGCmHaH7z2ihU+fZZ0+-0zexiP5nZ@mail.gmail.com>
Message-ID: <4D81E9E8.3000607@spatial-analyst.net>



Op 17-3-2011 11:38, Ervan Rutishauser schreef:
> Dear all,
>
> I would like to perform a classification of a large lidar data points
> acquired over a tropical forest plot network (500 km2).
> I computed the mean canopy(tree) height by 5m x 5m cell (pixel) and 3 others
> parameters (max height, height variation over 2 years, mean height in a 50m
> x 50 m neighborhood)
> I did most of this using the raster package.
> Now, I have a kind of multispectral image with 4 layers and I would like to
> perform a large-scale classification of the data based on these 4
> parameters. My aim is to find out "homogeneous" canopy regions, for
> instance: high canopy with low change over the 2 years, canopy gaps, areas
> of recruitment, etc.
>
> I tried to perfom a standard cluster analysis (hclust), but I could not
> compute the dissimilarity matrix (dist) on such a big data set (80'000 rows
> and 4 variables), even with a 64-bits PC.
> The k-means (kmeans{}) classification works, but return me strange results
> (4 main clusters north/south/east/west). I have seen that the biOps package
> allowed to do isodata classification. However isodata{} required an image
> and I don't know how to compute a 4-layer image (if possible).
>
> Does anyone have any suggestion? Shall I turn me to GIS software?
> I am trying to do it with SAGA at the moment, but find it difficult too :)

Are you referring to 
[http://www.saga-gis.org/saga_modules_doc/grid_discretisation/index.html]? 
Which problems did you experience exactly?

I have been processing large grids using SAGA for years now. I am not a 
computer scientists, but if I test the same operation in SAGA and R, I 
usually discover that (a) SAGA is faster, (b) there are usually much 
less problems with memory consumption etc (see e.g. sec 5.5.2 in 
[http://spatial-analyst.net/book/]).

SAGA has a fairly simply module development system 
[http://www.saga-gis.org/saga_modules_doc/lectures_introduction/index.html] 
and there is also an API functionality 
[http://www.saga-gis.org/saga_api_doc/html/] so you can access SAGA 
grids and libraries from python. As far as I know, linking of R and SAGA 
also goes pretty smooth.

The drawback

T. Hengl
http://www.wewur.wur.nl/popups/vcard.aspx?id=HENGL001

>
> Thank you for any help. Best regards,
> Ervan


From mathieu.rajerison at gmail.com  Thu Mar 17 12:12:57 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Thu, 17 Mar 2011 12:12:57 +0100
Subject: [R-sig-Geo] EBlocal - "variable contains non-finite values"
Message-ID: <AANLkTi=NuJc=ZHB=U6=AWgPTEMJ7sXChJ8w=6L45Q1mT@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110317/35cc4779/attachment.pl>

From aelmore at usgs.gov  Thu Mar 17 13:23:33 2011
From: aelmore at usgs.gov (Annette H Elmore)
Date: Thu, 17 Mar 2011 08:23:33 -0400
Subject: [R-sig-Geo] sample semivariogram use,
	retrieving anisotropic parameters, subsampling
In-Reply-To: <4D81B6B3.4030506@knmi.nl>
References: <mailman.19.1300186805.4951.r-sig-geo@r-project.org>
	<OF4027245D.B1C7165D-ON85257854.0044A5AD-85257855.004F7582@usgs.gov>
	<4D81B6B3.4030506@knmi.nl>
Message-ID: <OF2BBE30FA.0CD6C277-ON85257856.0043CC34-85257856.00441360@usgs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110317/e0dc328a/attachment.pl>

From tom.gottfried at wzw.tum.de  Thu Mar 17 13:38:12 2011
From: tom.gottfried at wzw.tum.de (Tom Gottfried)
Date: Thu, 17 Mar 2011 13:38:12 +0100
Subject: [R-sig-Geo] loop through polygons for point in polygon function
In-Reply-To: <AANLkTimaW3f6=qwdKEEHerbp=hRNAJWF8T3NDycVTte-@mail.gmail.com>
References: <AANLkTimaW3f6=qwdKEEHerbp=hRNAJWF8T3NDycVTte-@mail.gmail.com>
Message-ID: <4D8200B4.30005@wzw.tum.de>

Hi David,

Am 17.03.2011 00:32, schrieb david depew:
> Dear list, I'd like to loop through all polygons in a shapefile, and count
> the # of points of interest in each polygon.

in case these "points of interest" are something that can be represented as SpatialPoints, you could 
use over() or maybe aggregate() to produce counts of them corresponding to each polygon in your 
SpatialPolygonsDataFrame. This prevents you from looping through the slots of a complex object.

regards,
Tom

> I see previous postings suggest
> a for loop should work, but I'm not able to extract the individual polygons.
> I post the following portion since I can get to this point in my
> script....but the extraction step fails (most likely due to my inability to
> specify what part of the SpatialPolygonsDataFrame to extract.....
>
> library(sp)
> library(maptools)
> library(splancs)
> library(rgdal)
> library(spdep)
> nc.sids<- readShapePoly(system.file("etc/shapes/sids.shp",
> package="spdep")[1],
>    ID="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
> rn<- sapply(slot(nc.sids, "polygons"), function(x) slot(x, "ID"))
>
> for (i in 1:length(rn)) {
> temp.poly= ---- effectively, rn[i], i.e. a polygon with ID=="i". I can then
> assign data from the result of the pip function, but I'm having difficulty
> extracting each polygon sequentially to do this.
>
> Any help is much appreciated!
>
> Thanks!
>

-- 
Technische Universit?t M?nchen
Department f?r Pflanzenwissenschaften
Lehrstuhl f?r Gr?nlandlehre
Alte Akademie 12
85350 Freising / Germany
Phone: ++49 (0)8161 715324
Fax:   ++49 (0)8161 713243
email: tom.gottfried at wzw.tum.de
http://www.wzw.tum.de/gruenland


From tom.gottfried at wzw.tum.de  Thu Mar 17 14:36:33 2011
From: tom.gottfried at wzw.tum.de (Tom Gottfried)
Date: Thu, 17 Mar 2011 14:36:33 +0100
Subject: [R-sig-Geo] spacetime bugs
Message-ID: <4D820E61.1020709@wzw.tum.de>

Hi Edzer,

I got some errors in subsetting STSDF-objects by giving a scalar index for either time or space. I 
attached a self-contained example script that generates the errors (at least it did for me) and a 
modified version of STSDF-methods.R from the latest spacetime-source from CRAN that fixed the issues 
for me. I tested it by running the same example script and hope I didn't miss to test something 
important. I commented changes in the source file with "# TG" at the end of the comments.

regards,
Tom
-- 
Technische Universit?t M?nchen
Department f?r Pflanzenwissenschaften
Lehrstuhl f?r Gr?nlandlehre
Alte Akademie 12
85350 Freising / Germany
Phone: ++49 (0)8161 715324
Fax:   ++49 (0)8161 713243
email: tom.gottfried at wzw.tum.de
http://www.wzw.tum.de/gruenland
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: STSDF-methods.R
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110317/ee1f6789/attachment.pl>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: testSTSDF.R
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110317/ee1f6789/attachment-0001.pl>

From smurray at worldbank.org  Thu Mar 17 16:21:06 2011
From: smurray at worldbank.org (smurray at worldbank.org)
Date: Thu, 17 Mar 2011 10:21:06 -0500
Subject: [R-sig-Geo] using IDW with anisotropy
Message-ID: <OF8BC890CA.DD7B9CA4-ON85257856.00537D48-05257856.00546289@worldbank.org>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110317/d86a3873/attachment.html>

From aelmore at usgs.gov  Thu Mar 17 19:24:50 2011
From: aelmore at usgs.gov (Annette H Elmore)
Date: Thu, 17 Mar 2011 14:24:50 -0400
Subject: [R-sig-Geo] sample semivariogram use,
	retrieving anisotropic parameters, subsampling
In-Reply-To: <4D81B6B3.4030506@knmi.nl>
References: <mailman.19.1300186805.4951.r-sig-geo@r-project.org>
	<OF4027245D.B1C7165D-ON85257854.0044A5AD-85257855.004F7582@usgs.gov>
	<4D81B6B3.4030506@knmi.nl>
Message-ID: <OF27A0E702.2716738A-ON85257856.0064A9F3-85257856.006526EB@usgs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110317/e00ae6c4/attachment.pl>

From ktw08 at fsu.edu  Thu Mar 17 19:35:58 2011
From: ktw08 at fsu.edu (Kevin Wolff)
Date: Thu, 17 Mar 2011 13:35:58 -0500
Subject: [R-sig-Geo] Error with read.GWT2nb in making KNN weights symmetrical
Message-ID: <f6beca62879a.4d820e3e@fsu.edu>

Hi all, 

I have worked with R before, but admittedly not in some time.  What I am trying to do is take my Geoda?Nearest Neighbors Spatial weights files and make them symmetrical in order to use the Spatial Lag and Spatial Error functions in Geoda. Roger has been kind enough to help with this in the past and I have the code to do it.  The issue I am facing currently is getting R to run the code specified.  I run the first line 
knngwt?<- read.GWT2nb("1503_NN.GWT", region.id=NULL ) and get the following error:
 "Error: could not find function "read.GWT2nb"

I have installed the newest version of R (2.12) as well as installed the maptools and spdep packages which seem to run okay. 
install.packages("maptools",dependencies=TRUE)
install.packages("spdep",dependencies=TRUE)

But when I put the syntax in I get that error message.  This may be due to an error on my part in installing the required packages, but I have tried everything I have come across to no avail. I appreciate any guidance in this matter. The full code, that I am attempting to run is below.  Thank you again.   Kevin

knngwt <- read.GWT2nb("1503_NN.GWT", region.id=NULL )
class(knngwt) # "nb"
summary(knngwt)
print(is.symmetric.nb(knngwt))
knngwtsym <- make.sym.nb(knngwt)
class(knngwtsym) # "nb"
print(is.symmetric.nb(knngwtsym))
listw1 <- nb2listw(knngwtsym, style="B")
class(listw1) # "listw"
knngwtsymsn <- listw2sn(listw1)
class(knngwtsymsn) # "spatial.neighbour"
write.sn2gwt(knngwtsymsn, "1503_NN_SYM.GWT"


From edzer.pebesma at uni-muenster.de  Thu Mar 17 20:02:05 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 17 Mar 2011 20:02:05 +0100
Subject: [R-sig-Geo] using IDW with anisotropy
In-Reply-To: <OF8BC890CA.DD7B9CA4-ON85257856.00537D48-05257856.00546289@worldbank.org>
References: <OF8BC890CA.DD7B9CA4-ON85257856.00537D48-05257856.00546289@worldbank.org>
Message-ID: <4D825AAD.30400@uni-muenster.de>

Are you interpolating in 3D (x,y,t)?

On 03/17/2011 04:21 PM, smurray at worldbank.org wrote:
> hello,
> 
> I have a timseries dataset of monthly precip data from rain guages. The coverage 
> is relatively sparse (approx 30 stations covering the country) and there is 
> strong anisotropy in the data - at the monthly timestep data is strongly 
> correlated in the E-W direction. Is there any way to use modify the IDW 
> interpolation in gstat, to incorporate a directional bias in the distance weight?
> 
> many thanks for any suggestions
> 
> 
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From edzer.pebesma at uni-muenster.de  Thu Mar 17 20:54:32 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 17 Mar 2011 20:54:32 +0100
Subject: [R-sig-Geo] spacetime bugs
In-Reply-To: <4D820E61.1020709@wzw.tum.de>
References: <4D820E61.1020709@wzw.tum.de>
Message-ID: <4D8266F8.2050507@uni-muenster.de>

Thanks a lot for the helpful bug report & fix, Tom.

I submitted the patched spacetime 0.2-3 to CRAN.

Best regards,

On 03/17/2011 02:36 PM, Tom Gottfried wrote:
> Hi Edzer,
> 
> I got some errors in subsetting STSDF-objects by giving a scalar index
> for either time or space. I attached a self-contained example script
> that generates the errors (at least it did for me) and a modified
> version of STSDF-methods.R from the latest spacetime-source from CRAN
> that fixed the issues for me. I tested it by running the same example
> script and hope I didn't miss to test something important. I commented
> changes in the source file with "# TG" at the end of the comments.
> 
> regards,
> Tom

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From jonathan.s.callahan at gmail.com  Thu Mar 17 21:56:23 2011
From: jonathan.s.callahan at gmail.com (Jonathan Callahan)
Date: Thu, 17 Mar 2011 13:56:23 -0700
Subject: [R-sig-Geo] Ingesting e00 files from the UNEP Nuclear Power Station
	dataset
Message-ID: <AANLkTimLhpaRdbcJ0nPid57ZMZv08O_vCoXHPJZKrVKg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110317/0ca7cedf/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Thu Mar 17 22:07:30 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 17 Mar 2011 21:07:30 +0000
Subject: [R-sig-Geo] Ingesting e00 files from the UNEP Nuclear Power
 Station dataset
In-Reply-To: <AANLkTimLhpaRdbcJ0nPid57ZMZv08O_vCoXHPJZKrVKg@mail.gmail.com>
References: <AANLkTimLhpaRdbcJ0nPid57ZMZv08O_vCoXHPJZKrVKg@mail.gmail.com>
Message-ID: <AANLkTinAmXkyzzeuPbBZz+ZO=nV9vib3bNEaMR_tCetY@mail.gmail.com>

On Thu, Mar 17, 2011 at 8:56 PM, Jonathan Callahan
<jonathan.s.callahan at gmail.com> wrote:
> Greetings,
>
> I am having some difficulty ingesting e00 files from the following UNEP
> dataset:
>
> http://www.grid.unep.ch/GRID_search_details.php?dataid=GNV181
>
> Any short example showing how to do this would be greatly appreciated.

package rgdal can do it via readOGR - you just need to know what
sections of the e00 you need - for example in the sittot99.e00 you
probably want the LAB section:

 > lab=readOGR("sittot99.e00","LAB")
OGR data source with driver: AVCBin
Source: "sittot99.e00", layer: "LAB"
with 249 features and 16 fields
Feature type: wkbPoint with 2 dimensions
 > plot(lab)

 - giving the points of all the nuclear reactors.

Fuller docs here:

http://www.gdal.org/ogr/drv_avce00.html


Barry


From smurray at worldbank.org  Fri Mar 18 01:41:35 2011
From: smurray at worldbank.org (smurray at worldbank.org)
Date: Thu, 17 Mar 2011 19:41:35 -0500
Subject: [R-sig-Geo] using IDW with anisotropy
In-Reply-To: <4D825AAD.30400@uni-muenster.de>
Message-ID: <OF9E467B2C.66CBB9BB-ON85257857.00039E87-05257857.0003DDC8@worldbank.org>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110317/dee42776/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: graycol.gif
Type: image/gif
Size: 105 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110317/dee42776/attachment.gif>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: pic08723.gif
Type: image/gif
Size: 1255 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110317/dee42776/attachment-0001.gif>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ecblank.gif
Type: image/gif
Size: 45 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110317/dee42776/attachment-0002.gif>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 2A748798.gif
Type: image/gif
Size: 821 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110317/dee42776/attachment-0003.gif>

From paul.hiemstra at knmi.nl  Fri Mar 18 08:37:21 2011
From: paul.hiemstra at knmi.nl (Paul Hiemstra)
Date: Fri, 18 Mar 2011 08:37:21 +0100
Subject: [R-sig-Geo] using IDW with anisotropy
In-Reply-To: <OF9E467B2C.66CBB9BB-ON85257857.00039E87-05257857.0003DDC8@worldbank.org>
References: <OF9E467B2C.66CBB9BB-ON85257857.00039E87-05257857.0003DDC8@worldbank.org>
Message-ID: <4D830BB1.70303@knmi.nl>

Hi,

You could also opt for kriging, which supports anisotropy. The intamap
package has a function to detect anisotropy, in case you would like to
automate the interpolation.

cheers,
Paul

On 03/18/2011 01:41 AM, smurray at worldbank.org wrote:
>
> Thanks for the reply. I was planning to generate a surface for each
> time slice independently, so just x ,y.
> Siobhan
> Inactive hide details for Re: [R-sig-Geo] using IDW with anisotropyRe:
> [R-sig-Geo] using IDW with anisotropy
>
>
>
> 	
>
> 	
>
> *Re: [R-sig-Geo] using IDW with anisotropy*
>
>
> *Edzer Pebesma* 	
> to: 	
> r-sig-geo 	
> 03/17/2011 02:03 PM
>
>
>
> Sent by: 	
> *r-sig-geo-bounces at r-project.org*
>
> 	
>
>
> ------------------------------------------------------------------------
>
>
> Are you interpolating in 3D (x,y,t)?
>
> On 03/17/2011 04:21 PM, smurray at worldbank.org wrote:
> > hello,
> >
> > I have a timseries dataset of monthly precip data from rain guages.
> The coverage
> > is relatively sparse (approx 30 stations covering the country) and
> there is
> > strong anisotropy in the data - at the monthly timestep data is
> strongly
> > correlated in the E-W direction. Is there any way to use modify the IDW
> > interpolation in gstat, to incorporate a directional bias in the
> distance weight?
> >
> > many thanks for any suggestions
> >
> >
> >
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> -- 
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> 8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
> http://www.52north.org/geostatistics      e.pebesma at wwu.de
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


-- 
Paul Hiemstra, MSc
Global Climate Division
Royal Netherlands Meteorological Institute (KNMI)
Wilhelminalaan 10 | 3732 GK | De Bilt | Kamer B 3.39
P.O. Box 201 | 3730 AE | De Bilt
tel: +31 30 2206 494

http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110318/c4b98c40/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 105 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110318/c4b98c40/attachment.gif>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 45 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110318/c4b98c40/attachment-0001.gif>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 821 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110318/c4b98c40/attachment-0002.gif>

From nkkroy3 at gmail.com  Fri Mar 18 12:20:04 2011
From: nkkroy3 at gmail.com (Nikki roy)
Date: Fri, 18 Mar 2011 12:20:04 +0100
Subject: [R-sig-Geo] LMC manually fitted
Message-ID: <AANLkTi=uA_QFTw6zr=SjM+0+8_nisDSMCYtX+2z_7jL9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110318/45fcfbd9/attachment.pl>

From etiennebr at gmail.com  Fri Mar 18 19:23:07 2011
From: etiennebr at gmail.com (Etienne Bellemare)
Date: Fri, 18 Mar 2011 14:23:07 -0400
Subject: [R-sig-Geo] extract cell numbers from raster along a line
Message-ID: <AANLkTimjNZSmOZCBsEDqRqgtPQPEJKR2L0Uz-Qa-2A--@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110318/c6855357/attachment.pl>

From tsippel at gmail.com  Fri Mar 18 22:44:18 2011
From: tsippel at gmail.com (tsippel)
Date: Fri, 18 Mar 2011 11:44:18 -1000
Subject: [R-sig-Geo] Map digitization and classification
Message-ID: <AANLkTinLC3dHWhffpCMYe7moQL8zu_Cshmug=NSey14p@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110318/84c1d6ed/attachment.pl>

From r.hijmans at gmail.com  Fri Mar 18 23:25:33 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Fri, 18 Mar 2011 15:25:33 -0700 (PDT)
Subject: [R-sig-Geo] extract cell numbers from raster along a line
In-Reply-To: <AANLkTimjNZSmOZCBsEDqRqgtPQPEJKR2L0Uz-Qa-2A--@mail.gmail.com>
References: <AANLkTimjNZSmOZCBsEDqRqgtPQPEJKR2L0Uz-Qa-2A--@mail.gmail.com>
Message-ID: <1300487133871-6186374.post@n2.nabble.com>

> I'd like to extract celle numbers from a raster using a line, but it seems 
> the cellnumbers=TRUE option isn't working with lines in raster::extract. 

Etienne, 

It is not working because "cellnumbers" is currently only an argument for
extracting values from a Raster* for polygons. That's what the docs say. But
I'll also implement if for lines.  

In your example it is easy to extract cell numbers for the line

> r[] = 1:ncell(r)
> extract(r, l) 
[[1]]
[1]  4  5  8  9 12 13 16 17

> I'm also not sure I get the order in which the values are returned, but it
> seems
>  it is not from the begining of the line to the end or reverse. 

The values are first in row order, and then in column order.  Not in the
order of the coordinates of the line(s).

Robert

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/extract-cell-numbers-from-raster-along-a-line-tp6185643p6186374.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From tom.gottfried at wzw.tum.de  Sat Mar 19 00:11:40 2011
From: tom.gottfried at wzw.tum.de (Tom Gottfried)
Date: Sat, 19 Mar 2011 00:11:40 +0100
Subject: [R-sig-Geo] na.omit-method for STFDF
Message-ID: <4D83E6AC.60707@wzw.tum.de>

Hi,

I wrote a na.omit-method for STFDF (attached) with the intention to 
extract the rows and columns of a sparse space-time grid (STSDF) that 
have data on all nodes via

na.omit(as(stsdf, "STFDF"))

It turned out that I had no point in time with data at all locations in 
my data set. Hence, for me realising this was the only use of the method 
so far. Further I'm not sure about sensible use of the drop argument in 
it. Anyway, in case it's considered useful by others too, it could be a 
starting point for incorporation into spacetime.

I'm looking forward for your opinions!
Tom
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: na.omit.STFDF.R
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110319/89680e03/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Sat Mar 19 01:04:54 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sat, 19 Mar 2011 00:04:54 +0000
Subject: [R-sig-Geo] Map digitization and classification
In-Reply-To: <AANLkTinLC3dHWhffpCMYe7moQL8zu_Cshmug=NSey14p@mail.gmail.com>
References: <AANLkTinLC3dHWhffpCMYe7moQL8zu_Cshmug=NSey14p@mail.gmail.com>
Message-ID: <AANLkTindtDL2ZeAy0JcGyGb109-j9s3rnPAOa0SgtWHR@mail.gmail.com>

On Fri, Mar 18, 2011 at 9:44 PM, tsippel <tsippel at gmail.com> wrote:
> I have a series of scanned global maps (from a bound Atlas) of oceanographic
> sampling effort that I would like to classify. On 1 x1 lat/lon grids are
> symbols that represent sampling density. ?I need to read in these scanned
> maps, and classify the symbols (squares are classified as 1, triangles as 2,
> etc.) and hopefully store them in raster grid files (.asc) for analysis.
>
> After some trawling through CRAN looking for packages for this, it is not
> yet apparent to me which is best. ?I've considered using a GIS for this (ie.
> GRASS), but I'm not sure if that is a more complicated solution to a simpler
> problem. ?I need to process a directory of these images, so scripting the
> process to loop over the directory would be ideal.

 So you've got some high resolution page images and want to do
recognition of the shapes in the grid cells?

 Depending on how much noise there is it might be easy or difficult...
Any chance you can get us a sample image, or a section of one? How
many different symbols are there, and how big is the grid? I guess
global means 360x180, but what's the image resolution? Is there also a
map outline background to confuse things? MIght be easier to attack
this with an image processing toolbox like imageJ...

Barry


From tsippel at gmail.com  Sat Mar 19 01:28:27 2011
From: tsippel at gmail.com (tsippel)
Date: Fri, 18 Mar 2011 14:28:27 -1000
Subject: [R-sig-Geo] Map digitization and classification
In-Reply-To: <AANLkTindtDL2ZeAy0JcGyGb109-j9s3rnPAOa0SgtWHR@mail.gmail.com>
References: <AANLkTinLC3dHWhffpCMYe7moQL8zu_Cshmug=NSey14p@mail.gmail.com>
	<AANLkTindtDL2ZeAy0JcGyGb109-j9s3rnPAOa0SgtWHR@mail.gmail.com>
Message-ID: <AANLkTikHO7z70_4O5vjYwrvyw3BFssJC+f19ssWnmbr-@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110318/bc95bac1/attachment.pl>

From mdsumner at gmail.com  Sat Mar 19 01:40:22 2011
From: mdsumner at gmail.com (Michael Sumner)
Date: Sat, 19 Mar 2011 11:40:22 +1100
Subject: [R-sig-Geo] Map digitization and classification
In-Reply-To: <AANLkTikHO7z70_4O5vjYwrvyw3BFssJC+f19ssWnmbr-@mail.gmail.com>
References: <AANLkTinLC3dHWhffpCMYe7moQL8zu_Cshmug=NSey14p@mail.gmail.com>
	<AANLkTindtDL2ZeAy0JcGyGb109-j9s3rnPAOa0SgtWHR@mail.gmail.com>
	<AANLkTikHO7z70_4O5vjYwrvyw3BFssJC+f19ssWnmbr-@mail.gmail.com>
Message-ID: <AANLkTin1Cvo2wsv_zCtYGZirNMeNwR+oQgMvuxXf7vku@mail.gmail.com>

Hi Tim, wow that looks it could be rather difficult to automate. It's
probably easiest just to visualize them in a map plot and then use
locator() to recreate the locations for each symbol. That would not be
too difficult, but there are a few options.

Is the data not also published in the atlas in tabular form?

If I had to do this myself I'd probably use an interactive GIS like
Manifold, but it certainly could be done in R fairly simply with some
manual handling. The major problem is probably the overall accuracy
when you try to georegister the scans.

Cheers, Mike.

On Sat, Mar 19, 2011 at 11:28 AM, tsippel <tsippel at gmail.com> wrote:
> Here is an example of one of these map sets. ?This is the original as it was
> sent to me, but I would crop each map individually.
>
> https://docs.google.com/viewer?a=v&pid=explorer&chrome=true&srcid=0B0d3zfSSPFQsY2MxODEyZWEtZTRkZC00OTk2LTgwY2YtYTZkYzcwZGYxZDll&hl=en&authkey=CLmWvWc
>
> <https://docs.google.com/viewer?a=v&pid=explorer&chrome=true&srcid=0B0d3zfSSPFQsY2MxODEyZWEtZTRkZC00OTk2LTgwY2YtYTZkYzcwZGYxZDll&hl=en&authkey=CLmWvWc>In
> my original post I asked about classifying squares and triangle for the sake
> of simplicity, but as you can see the symbols used for this (published in
> the 1970s) aren't that easy to distinguish. ?Luckily, I don't think there is
> too much background noise, but maybe the 10 x10 grid lines will be
> problematic?
>
> Since this was scanned from the pages of a bound book, a curvature was
> induced in the scanned copy too, so the borders aren't perfectly square. ?We
> might be able to resolve this by scanning things more carefully, but your
> thoughts on this are very welcome too.
>
> Thanks,
>
> Tim
>
> On Fri, Mar 18, 2011 at 2:04 PM, Barry Rowlingson <
> b.rowlingson at lancaster.ac.uk> wrote:
>
>> On Fri, Mar 18, 2011 at 9:44 PM, tsippel <tsippel at gmail.com> wrote:
>> > I have a series of scanned global maps (from a bound Atlas) of
>> oceanographic
>> > sampling effort that I would like to classify. On 1 x1 lat/lon grids are
>> > symbols that represent sampling density. ?I need to read in these scanned
>> > maps, and classify the symbols (squares are classified as 1, triangles as
>> 2,
>> > etc.) and hopefully store them in raster grid files (.asc) for analysis.
>> >
>> > After some trawling through CRAN looking for packages for this, it is not
>> > yet apparent to me which is best. ?I've considered using a GIS for this
>> (ie.
>> > GRASS), but I'm not sure if that is a more complicated solution to a
>> simpler
>> > problem. ?I need to process a directory of these images, so scripting the
>> > process to loop over the directory would be ideal.
>>
>> ?So you've got some high resolution page images and want to do
>> recognition of the shapes in the grid cells?
>>
>> ?Depending on how much noise there is it might be easy or difficult...
>> Any chance you can get us a sample image, or a section of one? How
>> many different symbols are there, and how big is the grid? I guess
>> global means 360x180, but what's the image resolution? Is there also a
>> map outline background to confuse things? MIght be easier to attack
>> this with an image processing toolbox like imageJ...
>>
>> Barry
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


From mdsumner at gmail.com  Sat Mar 19 01:44:29 2011
From: mdsumner at gmail.com (Michael Sumner)
Date: Sat, 19 Mar 2011 11:44:29 +1100
Subject: [R-sig-Geo] Map digitization and classification
In-Reply-To: <AANLkTin1Cvo2wsv_zCtYGZirNMeNwR+oQgMvuxXf7vku@mail.gmail.com>
References: <AANLkTinLC3dHWhffpCMYe7moQL8zu_Cshmug=NSey14p@mail.gmail.com>
	<AANLkTindtDL2ZeAy0JcGyGb109-j9s3rnPAOa0SgtWHR@mail.gmail.com>
	<AANLkTikHO7z70_4O5vjYwrvyw3BFssJC+f19ssWnmbr-@mail.gmail.com>
	<AANLkTin1Cvo2wsv_zCtYGZirNMeNwR+oQgMvuxXf7vku@mail.gmail.com>
Message-ID: <AANLkTikamwHZkK4KKdvMhHtbfVm6uj+OqLM8RMBr=D7m@mail.gmail.com>

I had another look and the georegistration should be pretty accurate
since there are so many grid lines.

I missed that the first time. If the images need significant warping
to get them regular again you could use control points with the GDAL
command line tools, which is probably easier than doing that in R. You
could still use R to generate the control points with locator though.
They might be good enough just with very simple registration though
(corner point and pixel scale).

Cheers, Mike.

On Sat, Mar 19, 2011 at 11:40 AM, Michael Sumner <mdsumner at gmail.com> wrote:
> Hi Tim, wow that looks it could be rather difficult to automate. It's
> probably easiest just to visualize them in a map plot and then use
> locator() to recreate the locations for each symbol. That would not be
> too difficult, but there are a few options.
>
> Is the data not also published in the atlas in tabular form?
>
> If I had to do this myself I'd probably use an interactive GIS like
> Manifold, but it certainly could be done in R fairly simply with some
> manual handling. The major problem is probably the overall accuracy
> when you try to georegister the scans.
>
> Cheers, Mike.
>
> On Sat, Mar 19, 2011 at 11:28 AM, tsippel <tsippel at gmail.com> wrote:
>> Here is an example of one of these map sets. ?This is the original as it was
>> sent to me, but I would crop each map individually.
>>
>> https://docs.google.com/viewer?a=v&pid=explorer&chrome=true&srcid=0B0d3zfSSPFQsY2MxODEyZWEtZTRkZC00OTk2LTgwY2YtYTZkYzcwZGYxZDll&hl=en&authkey=CLmWvWc
>>
>> <https://docs.google.com/viewer?a=v&pid=explorer&chrome=true&srcid=0B0d3zfSSPFQsY2MxODEyZWEtZTRkZC00OTk2LTgwY2YtYTZkYzcwZGYxZDll&hl=en&authkey=CLmWvWc>In
>> my original post I asked about classifying squares and triangle for the sake
>> of simplicity, but as you can see the symbols used for this (published in
>> the 1970s) aren't that easy to distinguish. ?Luckily, I don't think there is
>> too much background noise, but maybe the 10 x10 grid lines will be
>> problematic?
>>
>> Since this was scanned from the pages of a bound book, a curvature was
>> induced in the scanned copy too, so the borders aren't perfectly square. ?We
>> might be able to resolve this by scanning things more carefully, but your
>> thoughts on this are very welcome too.
>>
>> Thanks,
>>
>> Tim
>>
>> On Fri, Mar 18, 2011 at 2:04 PM, Barry Rowlingson <
>> b.rowlingson at lancaster.ac.uk> wrote:
>>
>>> On Fri, Mar 18, 2011 at 9:44 PM, tsippel <tsippel at gmail.com> wrote:
>>> > I have a series of scanned global maps (from a bound Atlas) of
>>> oceanographic
>>> > sampling effort that I would like to classify. On 1 x1 lat/lon grids are
>>> > symbols that represent sampling density. ?I need to read in these scanned
>>> > maps, and classify the symbols (squares are classified as 1, triangles as
>>> 2,
>>> > etc.) and hopefully store them in raster grid files (.asc) for analysis.
>>> >
>>> > After some trawling through CRAN looking for packages for this, it is not
>>> > yet apparent to me which is best. ?I've considered using a GIS for this
>>> (ie.
>>> > GRASS), but I'm not sure if that is a more complicated solution to a
>>> simpler
>>> > problem. ?I need to process a directory of these images, so scripting the
>>> > process to loop over the directory would be ideal.
>>>
>>> ?So you've got some high resolution page images and want to do
>>> recognition of the shapes in the grid cells?
>>>
>>> ?Depending on how much noise there is it might be easy or difficult...
>>> Any chance you can get us a sample image, or a section of one? How
>>> many different symbols are there, and how big is the grid? I guess
>>> global means 360x180, but what's the image resolution? Is there also a
>>> map outline background to confuse things? MIght be easier to attack
>>> this with an image processing toolbox like imageJ...
>>>
>>> Barry
>>>
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
>
> --
> Michael Sumner
> Institute for Marine and Antarctic Studies, University of Tasmania
> Hobart, Australia
> e-mail: mdsumner at gmail.com
>



-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


From etiennebr at gmail.com  Sat Mar 19 04:24:52 2011
From: etiennebr at gmail.com (Etienne Bellemare)
Date: Fri, 18 Mar 2011 23:24:52 -0400
Subject: [R-sig-Geo] extract cell numbers from raster along a line
In-Reply-To: <1300487133871-6186374.post@n2.nabble.com>
References: <AANLkTimjNZSmOZCBsEDqRqgtPQPEJKR2L0Uz-Qa-2A--@mail.gmail.com>
	<1300487133871-6186374.post@n2.nabble.com>
Message-ID: <AANLkTi=7VSd+24VUETkAbPLCevzs24+UR6tCV4DxW1eH@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110318/a8660eda/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Sat Mar 19 14:18:55 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sat, 19 Mar 2011 13:18:55 +0000
Subject: [R-sig-Geo] Map digitization and classification
In-Reply-To: <AANLkTikamwHZkK4KKdvMhHtbfVm6uj+OqLM8RMBr=D7m@mail.gmail.com>
References: <AANLkTinLC3dHWhffpCMYe7moQL8zu_Cshmug=NSey14p@mail.gmail.com>
	<AANLkTindtDL2ZeAy0JcGyGb109-j9s3rnPAOa0SgtWHR@mail.gmail.com>
	<AANLkTikHO7z70_4O5vjYwrvyw3BFssJC+f19ssWnmbr-@mail.gmail.com>
	<AANLkTin1Cvo2wsv_zCtYGZirNMeNwR+oQgMvuxXf7vku@mail.gmail.com>
	<AANLkTikamwHZkK4KKdvMhHtbfVm6uj+OqLM8RMBr=D7m@mail.gmail.com>
Message-ID: <AANLkTingHRJ-87QuemyxTs06msQAuE5nmt4dYb8O_ftv@mail.gmail.com>

On Sat, Mar 19, 2011 at 12:44 AM, Michael Sumner <mdsumner at gmail.com> wrote:
> I had another look and the georegistration should be pretty accurate
> since there are so many grid lines.

 There's at least two problems here to successful classification:

1. Finding the data grid - tricky because the warping of each image is
different. There's a lot of curvature and I think you'd need a lot of
control points. Alternatively you could look for things that looked
like + signs and infer the best grid from them, but that could be
hard.

 Might even be a patent on it: http://www.freepatentsonline.com/7479969.html

2. Detecting the feature. Also tricky. Some bits of the coastline will
look exactly like vertical bars. Where symbols partly clash with the
coastline they'll look different too.

Zooming right in on the image (1400% or so) shows each pen line to be
about four pixels, and either black or white (was it scanned in mono?)
so despeckling and thresholding might help shape detection. Scanning
in grayscale might be better.

I still think ImageJ might be a handy tool to start working on this. I
believe it has feature detection algorithms.

 Another idea would be to chop it up into the 10x10 grids and create a
job on Amazon's Mechanical Turk system, so real live human beings
would get paid for doing the classification.

 How many pages have you got? You might have to ask yourself if the
effort of coding something to do this would be more than the effort of
typing it all in manually.

 I guess we assume you've tried to find the original authors in order
for them to dig out the punch cards that this data was probably stored
on...

Barry


From r.hijmans at gmail.com  Sat Mar 19 19:11:58 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Sat, 19 Mar 2011 11:11:58 -0700 (PDT)
Subject: [R-sig-Geo] extract cell numbers from raster along a line
In-Reply-To: <AANLkTi=7VSd+24VUETkAbPLCevzs24+UR6tCV4DxW1eH@mail.gmail.com>
References: <AANLkTimjNZSmOZCBsEDqRqgtPQPEJKR2L0Uz-Qa-2A--@mail.gmail.com>
	<1300487133871-6186374.post@n2.nabble.com>
	<AANLkTi=7VSd+24VUETkAbPLCevzs24+UR6tCV4DxW1eH@mail.gmail.com>
Message-ID: <1300558318008-6187936.post@n2.nabble.com>

> 
I did notice that, but there was no ==line== section in the doc I have. Is 
my package outdated ? 
> 

No, there were no additional arguments for lines specifically. There is one
now (cellnumbers) in the R-Forge version (1.8-6). 


>> The values are first in row order, and then in column order.  Not in the 
>> order of the coordinates of the line(s). 
>>

>I'm trying to think of a way to order these. Do you see a simple solution ? 
>I'm finally doing a profile from a raster using a line. 

Below I show how -- I think -- you can order the values such that they
follow the line.


library(raster)
r <- raster(matrix(1:20, nrow=4)) 
l <- SpatialLines(list(Lines(list(Line(list(x=c(0, 1), y=c(0, 1)))), ID=1))) 
plot(r, asp=1); lines(l) 

a <- extract(r, l, cellnumbers=T)[[1]] 
rc <- rowColFromCell(r, a[,1])
b <- cbind(rc, value=a[,2])

#order top to bottom
b[order(-b[,1], b[,2]), 3]
#order bottom to top
b[order(b[,1], -b[,2]), 3]
# or
rev( b[order(-b[,1], b[,2]), 3] )


--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/extract-cell-numbers-from-raster-along-a-line-tp6185643p6187936.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Sat Mar 19 20:53:59 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 19 Mar 2011 20:53:59 +0100 (CET)
Subject: [R-sig-Geo] EBlocal - "variable contains non-finite values"
In-Reply-To: <AANLkTi=NuJc=ZHB=U6=AWgPTEMJ7sXChJ8w=6L45Q1mT@mail.gmail.com>
References: <AANLkTi=NuJc=ZHB=U6=AWgPTEMJ7sXChJ8w=6L45Q1mT@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1103192049410.19929@reclus.nhh.no>

On Thu, 17 Mar 2011, Mathieu Rajerison wrote:

> Hi list,
>
>
> I performed the EBlocal function on my dataset, but I got the following
> error:
>
>> res <- EBlocal(agg$NPARBAT, agg$Expected, nb)
> Erreur dans lag.listw(lw, (ni * (xi - m.i)^2), zero.policy = zero.policy) :
>  Variable contains non-finite values
>

Almost certainly at least one of the values in agg$Expected is zero. 
Indeed, this should not be the expected count, but rather the populations 
at risk, as explained in ?EBlocal, which should all be positive numbers. 
So you are most likely not using the function correctly.

Hope this helps,

Roger

>
> I noticed someone else got the same error message as in this message:
> http://www.mail-archive.com/r-sig-geo at stat.math.ethz.ch/msg07922.html
>
>
> Apparently, it was fixed in the latest version of spdep. My version is
> 0.5-29 (the latest, I think) as the sessionInfo() indicates:
>
>> sessionInfo()
> R version 2.11.1 (2010-05-31)
> i386-pc-mingw32
>
> (...)
>
> other attached packages:
> [1] rgdal_0.6-28       spdep_0.5-29       coda_0.14-2
> deldir_0.0-13
> [5] maptools_0.7-38    foreign_0.8-40     nlme_3.1-96
> MASS_7.3-6
> [9] Matrix_0.999375-39 lattice_0.18-8     boot_1.2-42
> sp_0.9-76
>
> loaded via a namespace (and not attached):
> [1] grid_2.11.1  tools_2.11.1
>
>
> Any help would be greatly appreciated!
>
> Mathieu
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Sat Mar 19 21:02:21 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 19 Mar 2011 21:02:21 +0100 (CET)
Subject: [R-sig-Geo] loop through polygons for point in polygon function
In-Reply-To: <AANLkTimaW3f6=qwdKEEHerbp=hRNAJWF8T3NDycVTte-@mail.gmail.com>
References: <AANLkTimaW3f6=qwdKEEHerbp=hRNAJWF8T3NDycVTte-@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1103192057420.19929@reclus.nhh.no>

On Wed, 16 Mar 2011, david depew wrote:

> Dear list, I'd like to loop through all polygons in a shapefile, and count
> the # of points of interest in each polygon. I see previous postings suggest
> a for loop should work, but I'm not able to extract the individual polygons.
> I post the following portion since I can get to this point in my
> script....but the extraction step fails (most likely due to my inability to
> specify what part of the SpatialPolygonsDataFrame to extract.....
>
> library(sp)
> library(maptools)
> library(splancs)
> library(rgdal)
> library(spdep)
> nc.sids <- readShapePoly(system.file("etc/shapes/sids.shp",
> package="spdep")[1],
>  ID="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
> rn <- sapply(slot(nc.sids, "polygons"), function(x) slot(x, "ID"))
>
> for (i in 1:length(rn)) {
> temp.poly= ---- effectively, rn[i], i.e. a polygon with ID=="i". I can then
> assign data from the result of the pip function, but I'm having difficulty
> extracting each polygon sequentially to do this.

Why do you need to extract the polygons?

pts <- spsample(nc.sids, n=5000, type="random")
plot(nc.sids, axes=TRUE)
points(pts, pch=".")
out <- over(xx, pts)

where out is a vector with a count for each Polygons object in nc.sids. 
You will have more work to do if you need to count in each Polygon object 
within each Polygons object, but that would imply that the input data need 
reorganising.

Hope this helps,

Roger

>
> Any help is much appreciated!
>
> Thanks!
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Sat Mar 19 21:04:34 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 19 Mar 2011 21:04:34 +0100 (CET)
Subject: [R-sig-Geo] Error with read.GWT2nb in making KNN weights
 symmetrical
In-Reply-To: <f6beca62879a.4d820e3e@fsu.edu>
References: <f6beca62879a.4d820e3e@fsu.edu>
Message-ID: <alpine.LRH.2.00.1103192103020.19929@reclus.nhh.no>

On Thu, 17 Mar 2011, Kevin Wolff wrote:

> Hi all,
>
> I have worked with R before, but admittedly not in some time.  What I am 
> trying to do is take my Geoda?Nearest Neighbors Spatial weights files 
> and make them symmetrical in order to use the Spatial Lag and Spatial 
> Error functions in Geoda. Roger has been kind enough to help with this 
> in the past and I have the code to do it.  The issue I am facing 
> currently is getting R to run the code specified.  I run the first line 
> knngwt?<- read.GWT2nb("1503_NN.GWT", region.id=NULL ) and get the 
> following error: "Error: could not find function "read.GWT2nb"

Well, R is case sensitive, and the function is named read.gwt2nb(), so the 
error does seem plausible. Try using the right name. Tip - try ?<name> to 
see if a function exists and is user-visible.

Roger

>
> I have installed the newest version of R (2.12) as well as installed the maptools and spdep packages which seem to run okay.
> install.packages("maptools",dependencies=TRUE)
> install.packages("spdep",dependencies=TRUE)
>
> But when I put the syntax in I get that error message.  This may be due to an error on my part in installing the required packages, but I have tried everything I have come across to no avail. I appreciate any guidance in this matter. The full code, that I am attempting to run is below.  Thank you again.   Kevin
>
> knngwt <- read.GWT2nb("1503_NN.GWT", region.id=NULL )
> class(knngwt) # "nb"
> summary(knngwt)
> print(is.symmetric.nb(knngwt))
> knngwtsym <- make.sym.nb(knngwt)
> class(knngwtsym) # "nb"
> print(is.symmetric.nb(knngwtsym))
> listw1 <- nb2listw(knngwtsym, style="B")
> class(listw1) # "listw"
> knngwtsymsn <- listw2sn(listw1)
> class(knngwtsymsn) # "spatial.neighbour"
> write.sn2gwt(knngwtsymsn, "1503_NN_SYM.GWT"
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From jiniyooni at gmail.com  Sun Mar 20 03:30:06 2011
From: jiniyooni at gmail.com (JIN HUR)
Date: Sat, 19 Mar 2011 21:30:06 -0500
Subject: [R-sig-Geo] Formula in UK and distance in km
Message-ID: <AANLkTimdzrxxRPmiYKa-vUwtry3_297GS_uRb3uXXONw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110319/2fe440e4/attachment.pl>

From edzer.pebesma at uni-muenster.de  Sun Mar 20 09:56:02 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 20 Mar 2011 09:56:02 +0100
Subject: [R-sig-Geo] Formula in UK and distance in km
In-Reply-To: <AANLkTimdzrxxRPmiYKa-vUwtry3_297GS_uRb3uXXONw@mail.gmail.com>
References: <AANLkTimdzrxxRPmiYKa-vUwtry3_297GS_uRb3uXXONw@mail.gmail.com>
Message-ID: <4D85C122.8040707@uni-muenster.de>



On 03/20/2011 03:30 AM, JIN HUR wrote:
> Hi All,
> 
> I'm working on prediction analysis using Universal Kriging (UK).
> I have two questions.
> 
> 1) Formula in UK
>    My input data are latitude and longitude and wind speed to predict wind
> speed at unmeasured points.
>    In this case, how do I make the formula in krige function of UK?  For
> example, in meuse case, usually, formula is "log(zinc)~sqrt(dist)".

Wind.speed ~ Longitude+Latitude

> 
> 2) Distance in km
>    In semivariance, how do I calculate the distance (h) in km in
> semivariogram using longitude (degree) and latitude (degree)?

If you set the CRS such that is.projected reports FALSE, great distances
will be computed assuming long/lat values. For instance:

> library(rgdal)
> proj4string(meuse) <- CRS("+init=epsg:28992")
> meuse.ll = spTransform(meuse, CRS("+init=epsg:4326"))
> is.projected(meuse.ll)
[1] FALSE
> variogram(log(zinc)~dist+x+y,meuse)[1:3,]
   np      dist     gamma dir.hor dir.ver   id
1  57  79.29244 0.0945474       0       0 var1
2 299 163.97367 0.1576838       0       0 var1
3 419 267.36483 0.1837920       0       0 var1

Distances reported are in m.

> 
> My data are as follows:
> 
>    Longitude Latitude Wind.Speed
> 1    -87.545   41.757   2.387500
> 2    -87.669   41.979   2.925000
> 3    -87.568   41.708   2.137500
> 4    -87.726   41.739   2.87500
> 5    -87.558   41.616   3.025000
> 6    -87.792   41.984   3.242857
> 7    -87.990   41.668   3.950000
> 8    -87.753   41.855   1.687500
> 9    -87.898   42.039   3.687500
> 10   -87.676  42.062   3.700000
> 
> 
> Thanks,
> 
> Best Regards,
> Jin
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From edzer.pebesma at uni-muenster.de  Sun Mar 20 16:52:22 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 20 Mar 2011 16:52:22 +0100
Subject: [R-sig-Geo] LMC manually fitted
In-Reply-To: <AANLkTi=uA_QFTw6zr=SjM+0+8_nisDSMCYtX+2z_7jL9@mail.gmail.com>
References: <AANLkTi=uA_QFTw6zr=SjM+0+8_nisDSMCYtX+2z_7jL9@mail.gmail.com>
Message-ID: <4D8622B6.80307@uni-muenster.de>

Nikkie,

you made sure that the Cauchy-Schwartz inequality holds, and although it
is a necessary condition, it is not a sufficient condition for the
coefficient matrices to be positive definite.

function fit.lmc in package gstat contains a function that computes the
positive definite approximation (I believe in a least squares sense) to
a non-positive definite matrix by zero-ing the negative eigenvectors:

    posdef = function(X) {
        q = eigen(X)
        d = q$values
        d[d < 0] = 0
        q$vectors %*% diag(d, nrow = length(d)) %*% t(q$vectors)
    }

You could try to use that on the partial sill matrices. I believe it
still has the risk that things are perfectly correlated, in the end,
hence the correct.diagonal option (mess?) in fit.lmc.

Hth,

On 03/18/2011 12:20 PM, Nikki roy wrote:
> Dear friends,
> 
> I am doing cokriging and i could not fit the LMC to my variograms
> automatically, therefore i ftted the LMC manually. i have a total of 15
> variograms (direct variograms and cross variograms). eg:
> 
> clay.g$model$clay[1,2]
> clay.g$model$clay[1,2] = 0.22
> clay.g$model$clay[2,2] = 0.15
> clay.g$model$evi[1,2] = 0.005
> clay.g$model$evi[2,2] = 0.0105
> clay.g$model$clay.evi[1,2] = 0.185
> clay.g$model$clay.evi[2,2] = 0.025
> 
> then i checked my matrices with this condition which they need to
> satisfy:nugget(clay.evi)
> =<sqrt(nugget(clay) * nugget(evi)) and i got something like this for
> example:
> clay.g$model$clay[1,2] = 0.22
> clay.g$model$clay[2,2] = 0.15
> clay.g$model$evi[1,2] = 0.005
> clay.g$model$evi[2,2] = 0.0105
> clay.g$model$clay.evi[1,2] = 0.030
> clay.g$model$clay.evi[2,2] = 0.025
> 
> 
> still after this correction i am getting this error:
>  predict.gstat(clay.g, newdata = dem)
> non-positive definite coefficient matrix in structure 1non-positive definite
> coefficient matrix in structure 2Warning: No Intrinsic Correlation or Linear
> Model of Coregionalization found
> Reason: coefficient matrix not positive definite
> Warning: [add `set nocheck = 1;' to the command file to ignore the following
> error]
> Error in predict.gstat(clay.g, newdata = dem) :
>   gstat: value not allowed for: variograms do not satisfy a legal model
> May you please help, what went wrong and how to solve this.
> Thanks for your usual co-operation,
> 
> Nikkie
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From stepen.condors at gmail.com  Sun Mar 20 17:05:03 2011
From: stepen.condors at gmail.com (stepen.condors at gmail.com)
Date: Mon, 21 Mar 2011 02:05:03 +1000
Subject: [R-sig-Geo] time-weighted kernel density interpolation
Message-ID: <5C74B18A-5131-4979-94CF-1EDBE2C0C869@gmail.com>

Hi all
I am currently looking into developing some sort of time-weighted kernel density interpolation in R. It is my aim to build something which allows me to the the following:

- Import a point pattern p with associated times for each event 
- Plot a time weighted kernel density map of p - such that more recent events have a greater weighting than those that occurred earlier.  
- Ideally it would be useful to specify both the spatial and temporal bandwidths and the decay function types i.e. linear, exponential
- Import new point data and assign an intensity score to each point from its location on time-weighted kernel density surface.

Is this something that is relatively easily doable in R or am I crazy? 
I have developed something similar previously in both C++ and VB.NET (cough) interfacing directly with MapInfo so I am not afraid of code. 
However, as I am still relatively new to R I imagined that there were likely some better and worse ways to do this and/or libraries to look at. I have checked out the sp and spatstat libraries - but neither seem to have much to do with time, next i am considering trip. Where would you start? I would hate to waste time implementing something just because I was unaware of an existing solution. 

Therefore any advice, suggestions, experiences or abuse concerning how I might accomplish this functionality would be greatly appreciated. 

Best
Stepen

From mdsumner at gmail.com  Sun Mar 20 21:46:38 2011
From: mdsumner at gmail.com (Michael Sumner)
Date: Mon, 21 Mar 2011 07:46:38 +1100
Subject: [R-sig-Geo] time-weighted kernel density interpolation
In-Reply-To: <5C74B18A-5131-4979-94CF-1EDBE2C0C869@gmail.com>
References: <5C74B18A-5131-4979-94CF-1EDBE2C0C869@gmail.com>
Message-ID: <AANLkTimDBFpOHuynO0HfGgNVNuE4yVd8ZxpbZNaKVAhN@mail.gmail.com>

Hi Stepen,

The function tripGrid in package trip does something similar to this
for the time interval between points ("time spent in area") - by using
spatstat's density function on the line segments. The KDE approach is
there for exploration though I think the straight grid approach is
usually better (neither method has any systematic handling for
location error).

I've long meant to generalize the tripGrid function so that it's not
so tied to the time interval and the user could specify the
"weighting" - but that always brings up the issue of whether is is the
points or the implicit line segments between them that are of
interest.

The density.ppp function in spatstat could be used to do this, though
I wonder what kind of result you are expecting from this method?

Some of the approaches in adehabitat (and its new family of packages)
could be useful too.

Cheers, Mike.



On Mon, Mar 21, 2011 at 3:05 AM,  <stepen.condors at gmail.com> wrote:
> Hi all
> I am currently looking into developing some sort of time-weighted kernel density interpolation in R. It is my aim to build something which allows me to the the following:
>
> - Import a point pattern p with associated times for each event
> - Plot a time weighted kernel density map of p - such that more recent events have a greater weighting than those that occurred earlier.
> - Ideally it would be useful to specify both the spatial and temporal bandwidths and the decay function types i.e. linear, exponential
> - Import new point data and assign an intensity score to each point from its location on time-weighted kernel density surface.
>
> Is this something that is relatively easily doable in R or am I crazy?
> I have developed something similar previously in both C++ and VB.NET (cough) interfacing directly with MapInfo so I am not afraid of code.
> However, as I am still relatively new to R I imagined that there were likely some better and worse ways to do this and/or libraries to look at. I have checked out the sp and spatstat libraries - but neither seem to have much to do with time, next i am considering trip. Where would you start? I would hate to waste time implementing something just because I was unaware of an existing solution.
>
> Therefore any advice, suggestions, experiences or abuse concerning how I might accomplish this functionality would be greatly appreciated.
>
> Best
> Stepen
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


From yee at post.harvard.edu  Mon Mar 21 03:02:30 2011
From: yee at post.harvard.edu (Andrew Yee)
Date: Sun, 20 Mar 2011 22:02:30 -0400
Subject: [R-sig-Geo] anyone with experience with maptools and Census TIGER
 shapefiles: Massachusetts plots bizarrely
Message-ID: <AANLkTiksk+CAsppxG+XZLqB0zoXCtJb3rf9+qVFter4d@mail.gmail.com>

Two questions:

1. I was wondering if anyone has thoughts about the shapefiles from
the U.S. Census.  Specifically, I'm interested in plotting an outline
of Massachusetts.  I downloaded the "state and equivalent" shapefile
for Massachusetts from
http://www2.census.gov/cgi-bin/shapefiles2009/state-files?state=25.

map <- readShapeSpatial('tl_2009_33_state.shp')
plot(map)

renders a very bizarre looking Massachusetts, with the Cape looking like a blob.

2. On the other hand, if you download a shapefile from here:

http://pubs.usgs.gov/of/2009/1072/GIS/shapefile/OUTLINE25K_POLY.zip

this renders something that looks appropriate.  However, the
coordinates are not in latitude or longitude.  Is there a method for
obtaining these coordinates in latitude and longitude from this
shapefile?

(Note I'm familiar with the maps package, but was looking for a higher
resolution coastline).

Thanks,
Andrew


From eric.boeker at gmail.com  Mon Mar 21 11:10:24 2011
From: eric.boeker at gmail.com (Eric Boeker)
Date: Mon, 21 Mar 2011 11:10:24 +0100
Subject: [R-sig-Geo] simple operation on data.frame or spatialPointsDataFrame
Message-ID: <AANLkTim1ioJepDif_R4BeP8VbqxtVY3WmsRijW=_yn9_@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110321/522eceae/attachment.pl>

From research at georgruss.de  Mon Mar 21 11:29:33 2011
From: research at georgruss.de (Georg =?iso-8859-15?B?UnXf?=)
Date: Mon, 21 Mar 2011 11:29:33 +0100
Subject: [R-sig-Geo] simple operation on data.frame or
 spatialPointsDataFrame
In-Reply-To: <AANLkTim1ioJepDif_R4BeP8VbqxtVY3WmsRijW=_yn9_@mail.gmail.com>
References: <AANLkTim1ioJepDif_R4BeP8VbqxtVY3WmsRijW=_yn9_@mail.gmail.com>
Message-ID: <20110321102931.GA24192@greode>

On 21/03/11 11:10:24, Eric Boeker wrote:
> Hi All,
>
>
> I'm fitting variograms in GSTAT with fit.variogram. The coordinates are in
> UTM  (meters) and I got the Warning message: *singular model in variogram
> fit*.
>
> I found the reason from a previous archive mail of this warning message. (
> http://www.mail-archive.com/r-sig-geo at stat.math.ethz.ch/msg04054.html)
>
> Basically one possible solution is to divide the UTM coordinates (meters) by
> 1000 to convert them in km.
>
> [...]
> 1. Can this division take place directly on the SpatialPontsDataFrame or
> it should first be done on the dataframe?

Hi Eric,

if you just want to change the UTM coordinates from meters to kilometer
(i.e. divide by 1000), that can be done on the spatialPointsDataFrame, in
the @coords part.

If sppdf is your spatial points data frame, then the following should do:

sppdfN <- sppdf
sppdfN at coords <- sppdf at coords/1000

sppdfN is then the new spatialPointsDataFrame with the coords in km.
Don't know if the result is what you intended.

Regards,
Georg.
-- 
Research Assistant
Otto-von-Guericke-Universit?t Magdeburg
research at georgruss.de
http://research.georgruss.de


From mathieu.rajerison at gmail.com  Mon Mar 21 12:09:15 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Mon, 21 Mar 2011 12:09:15 +0100
Subject: [R-sig-Geo] EBlocal - "variable contains non-finite values"
In-Reply-To: <alpine.LRH.2.00.1103192049410.19929@reclus.nhh.no>
References: <AANLkTi=NuJc=ZHB=U6=AWgPTEMJ7sXChJ8w=6L45Q1mT@mail.gmail.com>
	<alpine.LRH.2.00.1103192049410.19929@reclus.nhh.no>
Message-ID: <AANLkTi==5OMq71upXwXOLh-HeM8ra=wQ83UG0O3m+mg3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110321/f2cd533e/attachment.pl>

From Roger.Bivand at nhh.no  Mon Mar 21 15:29:03 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 21 Mar 2011 15:29:03 +0100 (CET)
Subject: [R-sig-Geo] rgeos released on CRAN
Message-ID: <alpine.LRH.2.00.1103211522320.28668@reclus.nhh.no>

With some trepidation, rgeos - an interface to Geometry Engine - Open 
Source (GEOS) for topology operations on sp geometries - is now released 
on CRAN as a source package. A Windows binary package should follow within 
a couple of days. If an OSX binary package is offered on CRAN extras, 
information will be given, otherwise use the Kyngchaos framework and 
install from source. Contributions of bug reports, code patches, and 
extensions are welcome, especially via R-Forge. Congratulations to Colin 
Rundel for a very thorough implementation during GSoC 2010!

Enjoy!

Roger

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Mon Mar 21 16:51:21 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 21 Mar 2011 16:51:21 +0100 (CET)
Subject: [R-sig-Geo] rgeos released on CRAN
In-Reply-To: <alpine.LRH.2.00.1103211522320.28668@reclus.nhh.no>
References: <alpine.LRH.2.00.1103211522320.28668@reclus.nhh.no>
Message-ID: <alpine.LRH.2.00.1103211643510.28668@reclus.nhh.no>

On Mon, 21 Mar 2011, Roger Bivand wrote:

> With some trepidation, rgeos - an interface to Geometry Engine - Open Source 
> (GEOS) for topology operations on sp geometries - is now released on CRAN as 
> a source package. A Windows binary package should follow within a couple of 
> days. If an OSX binary package is offered on CRAN extras, information will be 
> given, otherwise use the Kyngchaos framework and install from source. 
> Contributions of bug reports, code patches, and extensions are welcome, 
> especially via R-Forge. Congratulations to Colin Rundel for a very thorough 
> implementation during GSoC 2010!

The fresh maptools 0.8-* release now on CRAN suggests rgeos. It can use 
rgeos in checkPolygonHoles(), unionSpatialPolygons() and elsewhere, but 
can still use gpclib if the user prefers. The rgeos version of 
checkPolygonHoles() adds a comment to each Polygons object, showing 
whether the member Polygon objects are exterior rings in the OGC "Simple 
Features" sense, and if they are interior rings, which exterior ring 
contains them. This maptools release addresses many of the issues raised 
over recent weeks, but which have been waiting for rgeos to be released.

Roger

>
> Enjoy!
>
> Roger
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From giuseppe.amatulli at gmail.com  Mon Mar 21 17:11:45 2011
From: giuseppe.amatulli at gmail.com (Giuseppe Amatulli)
Date: Mon, 21 Mar 2011 17:11:45 +0100
Subject: [R-sig-Geo] Species Distribution by Random Forest using a multi
	core pc
Message-ID: <AANLkTi=dWG5ZK3Km1BL3p6npR_+GRzzJF8L0CXWo5yhs@mail.gmail.com>

Hi
First of all sorry for this late answer, i was struggling with compile
all the sw in my new pc (16 processor 16 g of memory) and setting up
all the environment for the large computation.

Herein I will try to reply to the input that i receive more than one month ego.
I will insert my questions and replies in order to track back the history.
Moreover,  I will also insert codes/observations and how i solved the problems.

I'm trying to do forest species distribution at European level (1 km
resolution) by means of  randomForest running it in a cluster
computer. I'm using several predictors of different data sources. All
of them are rasters in grass format.  Therefore i was using spgrass6
to import the data in to R and apply randomForest prediction to the
layers. In the same time, reading carefully the help page of the raster
package seems to me that his "row by row" feature allows a better
performance of the memory limitation, compare to spgrass6. It is this
the case?
If raster package is more efficient, how i can use it to import grass
data?  I suppose by reading the raster under the cellhd folder
>  maps  <-  stack ( c ( 'LOCATION/PERMANENT/cellhd/grid1','LOCATION/PERMANENT/cellhd/grid2'))

On 10 January 2011 20:25, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> In principle, the GRASS GDAL plugin should work in this way, but you can
> also use g.region in GRASS to set the region for readRAST6() to read, which
> could be in tiles or rows at your convenience. This might be easier if the
> predicted tiles are to be written back to GRASS as part of the process. It
> would be overkill to think of this kind of iterated region support in
> raster, which uses the region.dim= and offset= features of the GDAL
> interface, I think. It would be fun to see whether SAGA could be used in the same way with
> raster, as there is a SAGA GDAL driver.
>
> Roger

After several test i decide to use the raster package to read and
write back the GRASS data. My decision was taken due to the faster
performance in reading the data and make the prediction. The drawbacks
were
1) the no-capability of raster package in reading the region of GRASS.
Anyway i easily solved by "cutting" all the grass data using the
setted region
2) the geo-output is a tif which i re-import in grass for other analysis.

I implemented the function for the prediction in this way:

f6 <- function(x, rf, filename='') {
         out <- raster(x)
         dataType(out)='FLT4S'
         small <- canProcessInMemory(out, 1)
         filename <- trim(filename)
         if (! small & filename == '') {
                 filename <- rasterTmpFile()
         }
          if (filename != '') {
                 out <- writeStart(out, filename, overwrite=TRUE)
                 todisk <- TRUE
         } else {
                 vv <- matrix(ncol=nrow(out), nrow=ncol(out))
                 todisk <- FALSE
         }
         bs <- blockSize(out)
         for (i in 1:bs\$n) {
                 block_rasters = getValues(x,
row=bs\$row[i],nrows=bs\$nrows[i] )   # deals with no data
                 block_rasters = unknownToNA( block_rasters,NaN)
                   # i will fix it in a more
                 block_rasters = NAToUnknown ( block_rasters , 0,
force=TRUE)    # clever way
                 print (paste("predict random forest for block",i))
                 pred  = predict (rf, newdata=block_rasters)

                 if (todisk) {
                         writeValues(out, pred, bs\$row[i])
                 } else {
                         cols <- bs\$row[i]:(bs\$row[i]+bs\$nrows[i]-1)
                         vv[,cols] <- matrix(pred, nrow=out at ncols)
                 }
         }
         if (todisk) {
                 out <- writeStop(out)
         } else {
                 out <- setValues(out, as.vector(vv))
         }
         return(out)
}

This function use a raster stack of 30 layers (europe 1x1km) and apply
the random forest prediction. It is very fast just 10 minutes.
In order to use the multi-core power and run several predictions of
different species, I was insert the R script in a bash script under
the   EOF syntax and i run it in this way.

for sp  in /forest/sp_* ; do echo  $sp ;  done  | xargs -n 1 -P 4  sh
./randomForest_predciton.sh

xargs allows the use of 4 processor (-P) using 1 argument (-n 1)

of course  the bash variables needs to be export and import in r by
Sys.getenv().

I always try to do all the gis and data preprocessing in bash using
GRASS  and awk , sed and enter in R with the data completely clean and
ready for the real spatial statistic. Saving memory, computational
time and getting the best from each sw.

Now that all the processing chain is working i can start to play
around with the random forest tuning parameters and use the
suggestions of Roberts:

On 11 January 2011 06:51, Robert Hijmans <r.hijmans at gmail.com> wrote:
> You can also have a look at the 'dismo' package for species distribution
> modeling.  The vignette (under development) has a brief example with
> randomForest.
>
> To apply weights in randomForest (I have not tried this and could very well
> be wrong), you can perhaps use regression rather than classification (in my
> experience randomForest regression works much better in this context) and
> adjust your presence/absence data based on certainty (highly certain absence
> = -1, highly certain presence = 1, everything else scaled in between).

Indeed i also prefer use randomForest in a regression mode. The only
problem is the not so high  value of the explained variance, due to
binary value of the response vs the continues value of the prediction.
So my questions to the community are:
How i can calculate the performance of the model in this particular
case?
Can i consider also in this case the maximization of the explained
variance as a driven factor for the tunning?

> A perhaps better alternative would be to use the cforest function (another
> random forest implementation) in 'party', because this function has a
> weights argument.

Yes, i will test and i will let you know the performance.

Thanks again for the suggestions
best regards
Giuseppe Amatulli


From kmringelman at ucdavis.edu  Mon Mar 21 18:45:24 2011
From: kmringelman at ucdavis.edu (Kevin Ringelman)
Date: Mon, 21 Mar 2011 10:45:24 -0700
Subject: [R-sig-Geo] spdep: show neighbors from "dnearneigh"
In-Reply-To: <alpine.LRH.2.00.1103051720020.8089@reclus.nhh.no>
References: <000201cbdaa0$dda6f4c0$98f4de40$@edu>
	<alpine.LRH.2.00.1103051720020.8089@reclus.nhh.no>
Message-ID: <000f01cbe7ef$c34e7510$49eb5f30$@edu>

Thanks for your help Roger.  I have a couple more questions.

print.default(nb) shows me what I'm looking for: for each region, I see the
regions that are within my distance band.  For example:

[[1]]
 [1]   2  10  11  15  17  18  19  32  40 554

[[2]]
 [1]   1  15  17  21  33  34 426 511 554 557

I want to make this information into a table, with the focal regions as
column 1, and the region IDs of it's neighbors as column 2 (similar to
neighbor analysis output in ArcGIS).  Continuing the example from above:
1	2
1	10
1	11
1	15
1	17
(etc.)

Even after I nuke the nb class
U <- unclass(nb)
I still can't access or manipulate the data...it doesn't appear as an
attribute
attribute(U)

Any suggestions?





-----Original Message-----
From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Sent: Saturday, March 05, 2011 10:03 AM
To: Kevin Ringelman
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] spdep: show neighbors from "dnearneigh"

On Fri, 4 Mar 2011, Kevin Ringelman wrote:

> I am having trouble viewing the list of neighbors ("regions IDs") after
> created a nb object using the "dnearneigh" function in spdep.  I only seem
> to get a summary (with # regions, # non-zero links, etc.).  This nb object
> also doesn't take well to being converted to another type of object, or
> exported from R.  How I view the list of neighbors?
>

In S and R, objects with a class attribute, such as "nb" objects, may have 
display methods specific to the class. If you just say:

> nb

then this is expanded internally to print(nb), and since nb is an object 
of class "nb", the print.nb() method is chosen. If you want the default 
print method, call it as print.default(nb). Conversion of objects of one 
class to another class may be done by coercion where coercion methods are 
provided. No such methods are available for nb objects. There are 
functions to do things like this, but not methods. For example, to make an 
nb object into a row-standardised matrix, you might do:

> Wmat <- nb2mat(nb, style="W")

but you should avoid this if your number of observations is large. To make 
a sparse matrix, several steps are required:

> lw <- nb2listw(nb, style="W")
> spWmat <- as(as_dgRMatrix_listw(lw), "CsparseMatrix")

using the nb2listw() and (ugly name) as_dgRMatrix_listw() functions, and 
coercion from one representation to another using new-style classes 
defined in the Matrix package.

>
>
> Some additional background: I'm identifying all neighboring bird nests
> within 100m of each nest.  For this particular analysis, I ultimately want
> to calculate the average vegetation height of neighboring nests to compare
> with the focal nest.  This will involve generating a list of neighbors,
and
> merging that list with my other data.
>

Note that an nb object is a list - to nuke the class, do:

> class(nb) <- NULL

which lets you call print.default(), but to get at the attribute you want, 
just do:

> attr(nb, "region.id")

to call print.default on the character vector it contains.

Hope this clarifies,

Roger

>
>
> Thanks,
>
> Kevin
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From advaitgodbole at gmail.com  Mon Mar 21 19:29:53 2011
From: advaitgodbole at gmail.com (Advait Godbole)
Date: Mon, 21 Mar 2011 14:29:53 -0400
Subject: [R-sig-Geo] adding variable to shapefile
Message-ID: <AANLkTi=fCg=wob0LUWMynns6uGd5QGrdYKwDnW7qRraN@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110321/d66cd643/attachment.pl>

From j.m.signer at gmail.com  Mon Mar 21 19:56:42 2011
From: j.m.signer at gmail.com (Johannes Signer)
Date: Mon, 21 Mar 2011 19:56:42 +0100
Subject: [R-sig-Geo] adding variable to shapefile
In-Reply-To: <AANLkTi=fCg=wob0LUWMynns6uGd5QGrdYKwDnW7qRraN@mail.gmail.com>
References: <AANLkTi=fCg=wob0LUWMynns6uGd5QGrdYKwDnW7qRraN@mail.gmail.com>
Message-ID: <AANLkTi=YBXwyGSRjRVShtnBhd6XZUyCH4UXcB7K0Ruza@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110321/9ad255dd/attachment.pl>

From znmeb at borasky-research.net  Mon Mar 21 20:08:36 2011
From: znmeb at borasky-research.net (M. Edward (Ed) Borasky)
Date: Mon, 21 Mar 2011 12:08:36 -0700
Subject: [R-sig-Geo] rgeos released on CRAN
In-Reply-To: <alpine.LRH.2.00.1103211643510.28668@reclus.nhh.no>
References: <alpine.LRH.2.00.1103211522320.28668@reclus.nhh.no>
	<alpine.LRH.2.00.1103211643510.28668@reclus.nhh.no>
Message-ID: <15479c8eaf054a5732110eb5b8b27a24@borasky-research.net>

 On Mon, 21 Mar 2011 16:51:21 +0100 (CET), Roger Bivand 
 <Roger.Bivand at nhh.no> wrote:
> On Mon, 21 Mar 2011, Roger Bivand wrote:
>
>> With some trepidation, rgeos - an interface to Geometry Engine - 
>> Open Source (GEOS) for topology operations on sp geometries - is now 
>> released on CRAN as a source package. A Windows binary package should 
>> follow within a couple of days. If an OSX binary package is offered on 
>> CRAN extras, information will be given, otherwise use the Kyngchaos 
>> framework and install from source. Contributions of bug reports, code 
>> patches, and extensions are welcome, especially via R-Forge. 
>> Congratulations to Colin Rundel for a very thorough implementation 
>> during GSoC 2010!
>
> The fresh maptools 0.8-* release now on CRAN suggests rgeos. It can
> use rgeos in checkPolygonHoles(), unionSpatialPolygons() and
> elsewhere, but can still use gpclib if the user prefers. The rgeos
> version of checkPolygonHoles() adds a comment to each Polygons 
> object,
> showing whether the member Polygon objects are exterior rings in the
> OGC "Simple Features" sense, and if they are interior rings, which
> exterior ring contains them. This maptools release addresses many of
> the issues raised over recent weeks, but which have been waiting for
> rgeos to be released.
>
> Roger
>
>>
>> Enjoy!
>>
>> Roger
>>
>>

 1. It looks like it's propagating slowly to US mirrors - 
 http://cran.cnr.berkeley.edu seems to have it, though.
 2. The last time I installed the Spatial task view from source, quite a 
 few routines seemed to have the option of using rgeos but I was never 
 able to get that to work. Is there anything I need to do to make that 
 "automatic", or does just installing rgeos from CRAN now make it happen?

-- 
 http://twitter.com/znmeb http://borasky-research.net

 "A mathematician is a device for turning coffee into theorems." -- Paul 
 Erd?s


From tom.gottfried at wzw.tum.de  Mon Mar 21 20:09:54 2011
From: tom.gottfried at wzw.tum.de (Tom Gottfried)
Date: Mon, 21 Mar 2011 20:09:54 +0100
Subject: [R-sig-Geo] adding variable to shapefile
In-Reply-To: <AANLkTi=YBXwyGSRjRVShtnBhd6XZUyCH4UXcB7K0Ruza@mail.gmail.com>
References: <AANLkTi=fCg=wob0LUWMynns6uGd5QGrdYKwDnW7qRraN@mail.gmail.com>
	<AANLkTi=YBXwyGSRjRVShtnBhd6XZUyCH4UXcB7K0Ruza@mail.gmail.com>
Message-ID: <4D87A282.7090908@wzw.tum.de>

you can even operate directly on the object you obtained from reading the shapefile. To add a column 
called test just do

s$test <- test

assuming that test has length(test)==nrow(s). In case you want it back in the shapefile use 
writePolyShape.

Tom

Am 21.03.2011 19:56, schrieb Johannes Signer:
> You can access the data slot of a shapefile s by:
>
> d<- s at data
>
> d is data frame, where you can a column and write it back to the shapefile.
>
> s at data<- d
>
> Hope this helps
> Johannes
>
> On Mon, Mar 21, 2011 at 7:29 PM, Advait Godbole<advaitgodbole at gmail.com>wrote:
>
>> Dear R-users,
>>
>> I am reading a shapefile in to R using readShapePoly, do some spatial
>> modeling on it and obtain a new variable which I want to write to the same
>> polygons as a new attribute (variable) preserving the spatial structure. Is
>> there a straightforward way of doing it via a "write-to-shapefile"
>> function?
>>
>> Thanks in advance,
>>
>> --
>> advait godbole
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Technische Universit?t M?nchen
Department f?r Pflanzenwissenschaften
Lehrstuhl f?r Gr?nlandlehre
Alte Akademie 12
85350 Freising / Germany
Phone: ++49 (0)8161 715324
Fax:   ++49 (0)8161 713243
email: tom.gottfried at wzw.tum.de
http://www.wzw.tum.de/gruenland


From advaitgodbole at gmail.com  Mon Mar 21 20:32:17 2011
From: advaitgodbole at gmail.com (Advait Godbole)
Date: Mon, 21 Mar 2011 15:32:17 -0400
Subject: [R-sig-Geo] adding variable to shapefile
In-Reply-To: <4D87A282.7090908@wzw.tum.de>
References: <AANLkTi=fCg=wob0LUWMynns6uGd5QGrdYKwDnW7qRraN@mail.gmail.com>
	<AANLkTi=YBXwyGSRjRVShtnBhd6XZUyCH4UXcB7K0Ruza@mail.gmail.com>
	<4D87A282.7090908@wzw.tum.de>
Message-ID: <AANLkTi=6cW+EgWopdH=LRvQSGRXZ_ikcRtbBgT_WzR_o@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110321/3652eed8/attachment.pl>

From j.m.signer at gmail.com  Mon Mar 21 20:41:03 2011
From: j.m.signer at gmail.com (Johannes Signer)
Date: Mon, 21 Mar 2011 20:41:03 +0100
Subject: [R-sig-Geo] adding variable to shapefile
In-Reply-To: <AANLkTi=6cW+EgWopdH=LRvQSGRXZ_ikcRtbBgT_WzR_o@mail.gmail.com>
References: <AANLkTi=fCg=wob0LUWMynns6uGd5QGrdYKwDnW7qRraN@mail.gmail.com>
	<AANLkTi=YBXwyGSRjRVShtnBhd6XZUyCH4UXcB7K0Ruza@mail.gmail.com>
	<4D87A282.7090908@wzw.tum.de>
	<AANLkTi=6cW+EgWopdH=LRvQSGRXZ_ikcRtbBgT_WzR_o@mail.gmail.com>
Message-ID: <AANLkTikooGaGOicjOYwkXjHjK1LiCBHzRC7zN6SyO-9a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110321/24525ca5/attachment.pl>

From massimodisasha at gmail.com  Mon Mar 21 20:59:44 2011
From: massimodisasha at gmail.com (Massimo Di Stefano)
Date: Mon, 21 Mar 2011 15:59:44 -0400
Subject: [R-sig-Geo] how to chose the right cell size to grid an irregular
	point dastaset.
Message-ID: <66986240-F90A-4A10-9472-EEFEC3C1E3E7@gmail.com>

Hi All,

i have a dataset based on a oceanographic ship
it is based on a set of point along transect (the points are 2 meters spaced along the track direction and each track are 400 meter spaced)

for each point i have 6 images (the instrument i'm working on is used to collect sea flor images, 6 image/sec ) 
so is mostly like .. i have a "continuum infromation" along the track with a resolution of 2 meters (each image overlap the previouse one with a 50% factor)

the images arte manually analized and for them i've "how many times a single spiecies is recognized in each images"  (each image has also associated other metadata like depth and substrate type)


for each point i have this information :

x (longitude)
y (latiutude)
z (depth)
specie_density (specie_Count / field_of_view)
substrate_type (id identifier for the substrate type)


for now i want try to generate a regular grid from my dataset interpolating the  "specie_density" value

my first question is ... 

how to chose the right cell size for my grid ? beacouse the resolution alog the transect is like 2 meters .. while each transect is distant from the next one about 400 meters ... 

if i want try first simple interpolation methods like IDW, Spline built-in-side grass

then i have to make a more accurate analisys to interpolate my data (specie_density),
i was tinking to include the depth and substrate as "correlated information" to be used in a cokriging interpolation, 
make sense for you ? 
(for bathymatery data i've also a continuos DTM 10 meters cell size that can be used in addition of each point depth, can be helpfull ?)

for now i'm working inside a grass / python environment (easy to try the grass interpolation methods) while to try to krige my data,
using rpy i just generated a spatialPointDataframe in R (including :  x, y, specie_densithy, depth, substrate) 
i'm now tring to learn more on the sp, rgdal amd gstat package in R  to undstand how to use my spatialpointdataframe as input for a cokriging analisys,
any hints on this next step is will give me an huge help!  


From etiennebr at gmail.com  Mon Mar 21 21:02:19 2011
From: etiennebr at gmail.com (Etienne Bellemare)
Date: Mon, 21 Mar 2011 16:02:19 -0400
Subject: [R-sig-Geo] extract cell numbers from raster along a line
In-Reply-To: <1300558318008-6187936.post@n2.nabble.com>
References: <AANLkTimjNZSmOZCBsEDqRqgtPQPEJKR2L0Uz-Qa-2A--@mail.gmail.com>
	<1300487133871-6186374.post@n2.nabble.com>
	<AANLkTi=7VSd+24VUETkAbPLCevzs24+UR6tCV4DxW1eH@mail.gmail.com>
	<1300558318008-6187936.post@n2.nabble.com>
Message-ID: <AANLkTi=QBRvDvdiATqmWy5ruUaA7dOjBtLfc51fxkZgJ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110321/24e13d92/attachment.pl>

From mathieu.rajerison at gmail.com  Tue Mar 22 00:17:27 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Tue, 22 Mar 2011 00:17:27 +0100
Subject: [R-sig-Geo] spdep: show neighbors from "dnearneigh"
In-Reply-To: <000f01cbe7ef$c34e7510$49eb5f30$@edu>
References: <000201cbdaa0$dda6f4c0$98f4de40$@edu>
	<alpine.LRH.2.00.1103051720020.8089@reclus.nhh.no>
	<000f01cbe7ef$c34e7510$49eb5f30$@edu>
Message-ID: <AANLkTinvYBJJaOoMw-4EsvEEDuHhfwrhg0Zh_5m7Mrjt@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110322/a6f5a1a5/attachment.pl>

From david.depew at queensu.ca  Tue Mar 22 01:07:09 2011
From: david.depew at queensu.ca (david depew)
Date: Mon, 21 Mar 2011 20:07:09 -0400
Subject: [R-sig-Geo] loop through polygons for point in polygon function
In-Reply-To: <alpine.LRH.2.00.1103192057420.19929@reclus.nhh.no>
References: <AANLkTimaW3f6=qwdKEEHerbp=hRNAJWF8T3NDycVTte-@mail.gmail.com>
	<alpine.LRH.2.00.1103192057420.19929@reclus.nhh.no>
Message-ID: <AANLkTi=1CEzMa=C9BZEnBQkerWS+ebnUjqKBbaAU559Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110321/4b5cf38a/attachment.pl>

From stepen.condors at gmail.com  Tue Mar 22 06:05:41 2011
From: stepen.condors at gmail.com (stepen.condors at gmail.com)
Date: Tue, 22 Mar 2011 15:05:41 +1000
Subject: [R-sig-Geo] time-weighted kernel density interpolation
In-Reply-To: <AANLkTimDBFpOHuynO0HfGgNVNuE4yVd8ZxpbZNaKVAhN@mail.gmail.com>
References: <5C74B18A-5131-4979-94CF-1EDBE2C0C869@gmail.com>
	<AANLkTimDBFpOHuynO0HfGgNVNuE4yVd8ZxpbZNaKVAhN@mail.gmail.com>
Message-ID: <C592CD29-9817-4F86-840A-1F9DC6542083@gmail.com>

Thanks for this Michael - I am investigating the trip library as we speak. 

Another (potentially stupid) query:

I have a point pattern (as a ppp):

test.ppp = ppp(test.eastings, test.northings, xrange=c(1000000, 2000000), yrange=c(1000000,2000000))

I'd like to generate a grid over this area storing an associated intensity score with each grid cell - so that where points intersect that grid I can add some value to the intensity score of the cell they lie in (and surrounding ones ideally).

What grid method would you recommend?  and then how might you go about calculating the intersection of points and polygons?

Many Thanks
Stepen


On 21/03/2011, at 6:46 AM, Michael Sumner wrote:

> Hi Stepen,
> 
> The function tripGrid in package trip does something similar to this
> for the time interval between points ("time spent in area") - by using
> spatstat's density function on the line segments. The KDE approach is
> there for exploration though I think the straight grid approach is
> usually better (neither method has any systematic handling for
> location error).
> 
> I've long meant to generalize the tripGrid function so that it's not
> so tied to the time interval and the user could specify the
> "weighting" - but that always brings up the issue of whether is is the
> points or the implicit line segments between them that are of
> interest.
> 
> The density.ppp function in spatstat could be used to do this, though
> I wonder what kind of result you are expecting from this method?
> 
> Some of the approaches in adehabitat (and its new family of packages)
> could be useful too.
> 
> Cheers, Mike.
> 
> 
> 
> On Mon, Mar 21, 2011 at 3:05 AM,  <stepen.condors at gmail.com> wrote:
>> Hi all
>> I am currently looking into developing some sort of time-weighted kernel density interpolation in R. It is my aim to build something which allows me to the the following:
>> 
>> - Import a point pattern p with associated times for each event
>> - Plot a time weighted kernel density map of p - such that more recent events have a greater weighting than those that occurred earlier.
>> - Ideally it would be useful to specify both the spatial and temporal bandwidths and the decay function types i.e. linear, exponential
>> - Import new point data and assign an intensity score to each point from its location on time-weighted kernel density surface.
>> 
>> Is this something that is relatively easily doable in R or am I crazy?
>> I have developed something similar previously in both C++ and VB.NET (cough) interfacing directly with MapInfo so I am not afraid of code.
>> However, as I am still relatively new to R I imagined that there were likely some better and worse ways to do this and/or libraries to look at. I have checked out the sp and spatstat libraries - but neither seem to have much to do with time, next i am considering trip. Where would you start? I would hate to waste time implementing something just because I was unaware of an existing solution.
>> 
>> Therefore any advice, suggestions, experiences or abuse concerning how I might accomplish this functionality would be greatly appreciated.
>> 
>> Best
>> Stepen
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
> 
> 
> 
> -- 
> Michael Sumner
> Institute for Marine and Antarctic Studies, University of Tasmania
> Hobart, Australia
> e-mail: mdsumner at gmail.com


From giuseppe.amatulli at gmail.com  Tue Mar 22 09:19:44 2011
From: giuseppe.amatulli at gmail.com (Giuseppe Amatulli)
Date: Tue, 22 Mar 2011 09:19:44 +0100
Subject: [R-sig-Geo] Species Distribution by Random Forest using a multi
	core pc
In-Reply-To: <AANLkTi=dWG5ZK3Km1BL3p6npR_+GRzzJF8L0CXWo5yhs@mail.gmail.com>
References: <AANLkTi=dWG5ZK3Km1BL3p6npR_+GRzzJF8L0CXWo5yhs@mail.gmail.com>
Message-ID: <AANLkTikEGv7vgYsScfeVvuCs8Ssjao6HYCow9GZcKnx=@mail.gmail.com>

Hi
First of all sorry for this late answer, i was struggling with compile
all the sw in my new pc (16 processor 16 g of memory) and setting up
all the environment for a large computation.

Herein, I will try to reply to the inputs that i receive more than one
month ego.
I will insert my questions and replies in order to track back the history.
Moreover, ?I will also insert codes/observations and how i solved the problems.

1) Issues:

I'm trying to do forest species distribution at European level (1 km
resolution) by means of ?randomForest running it in a cluster
computer. I'm using several predictors of different data sources. All
of them are rasters in grass format. ?Therefore i was using spgrass6
to import the data in to R and apply randomForest prediction to the
layers. In the same time, reading carefully the help page of the raster
package seems to me that his "row by row" feature allows a better
performance of the memory limitation, compare to spgrass6. It is this
the case?
If raster package is more efficient, how i can use it to import grass
data? ?I suppose by reading the raster under the cellhd folder
> ?maps ?<- ?stack ( c ( 'LOCATION/PERMANENT/cellhd/grid1','LOCATION/PERMANENT/cellhd/grid2'))

On 10 January 2011 20:25, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> In principle, the GRASS GDAL plugin should work in this way, but you can
> also use g.region in GRASS to set the region for readRAST6() to read, which
> could be in tiles or rows at your convenience. This might be easier if the
> predicted tiles are to be written back to GRASS as part of the process. It
> would be overkill to think of this kind of iterated region support in
> raster, which uses the region.dim= and offset= features of the GDAL
> interface, I think. It would be fun to see whether SAGA could be used in the same way with
> raster, as there is a SAGA GDAL driver.
>
> Roger

After several test i decide to use the raster package to read and
write back the GRASS data. My decision was taken due to the faster
performance in reading the data and make the prediction. The drawbacks
were
1) the no-capability of raster package in reading the region of GRASS.
Anyway i easily solved by "cutting" all the grass data using the
grass region
2) the geo-output is a tif which i re-import in grass for other analysis.

I implemented the function for the prediction in this way:

rastRFpred <- function(x, rf, filename='') {
? ? ? ? out <- raster(x)
? ? ? ? dataType(out)='FLT4S'
? ? ? ? small <- canProcessInMemory(out, 1)
? ? ? ? filename <- trim(filename)
? ? ? ? if (! small & filename == '') {
? ? ? ? ? ? ? ? filename <- rasterTmpFile()
? ? ? ? }
? ? ? ? ?if (filename != '') {
? ? ? ? ? ? ? ? out <- writeStart(out, filename, overwrite=TRUE)
? ? ? ? ? ? ? ? todisk <- TRUE
? ? ? ? } else {
? ? ? ? ? ? ? ? vv <- matrix(ncol=nrow(out), nrow=ncol(out))
? ? ? ? ? ? ? ? todisk <- FALSE
? ? ? ? }
? ? ? ? bs <- blockSize(out)
? ? ? ? for (i in 1:bs\$n) {
? ? ? ? ? ? ? ? block_rasters = getValues(x,
row=bs\$row[i],nrows=bs\$nrows[i] ) ? # deals with no data
? ? ? ? ? ? ? ? block_rasters = unknownToNA( block_rasters,NaN)
? ? ? ? ? ? ? ? ? # i will fix it in a more
? ? ? ? ? ? ? ? block_rasters = NAToUnknown ( block_rasters , 0,
force=TRUE) ? ?# clever way
? ? ? ? ? ? ? ? print (paste("predict random forest for block",i))
? ? ? ? ? ? ? ? pred ?= predict (rf, newdata=block_rasters)

? ? ? ? ? ? ? ? if (todisk) {
? ? ? ? ? ? ? ? ? ? ? ? writeValues(out, pred, bs\$row[i])
? ? ? ? ? ? ? ? } else {
? ? ? ? ? ? ? ? ? ? ? ? cols <- bs\$row[i]:(bs\$row[i]+bs\$nrows[i]-1)
? ? ? ? ? ? ? ? ? ? ? ? vv[,cols] <- matrix(pred, nrow=out at ncols)
? ? ? ? ? ? ? ? }
? ? ? ? }
? ? ? ? if (todisk) {
? ? ? ? ? ? ? ? out <- writeStop(out)
? ? ? ? } else {
? ? ? ? ? ? ? ? out <- setValues(out, as.vector(vv))
? ? ? ? }
? ? ? ? return(out)
}

This function use a raster stack of 30 layers (Europe 1x1km) and apply
the random forest prediction. It is very fast just 10 minutes.
In order to use the multi-core power and run several predictions of
different species, I was insert the R script in a bash script under
the ? EOF syntax and i run it in this way.

for sp ?in /forest/sp_* ; do echo ?$sp ; ?done ?| xargs -n 1 -P 4 ?sh
./randomForest_predciton.sh

xargs allows the use of 4 processor (-P) using 1 argument (-n 1)

of course ?the bash variables needs to be export from bash and import in r by
Sys.getenv().

I always try to do all the gis and data preprocessing in bash using
GRASS ?and awk , sed and enter in R with the data completely clean and
ready for the real spatial statistic. Saving memory, computational
time and getting the best from each sw.

Now that all the processing chain is working i can start to play
around with the random forest tuning parameters and use the
suggestions of Roberts:

On 11 January 2011 06:51, Robert Hijmans <r.hijmans at gmail.com> wrote:
> You can also have a look at the 'dismo' package for species distribution
> modeling. ?The vignette (under development) has a brief example with
> randomForest.
>
> To apply weights in randomForest (I have not tried this and could very well
> be wrong), you can perhaps use regression rather than classification (in my
> experience randomForest regression works much better in this context) and
> adjust your presence/absence data based on certainty (highly certain absence
> = -1, highly certain presence = 1, everything else scaled in between).

Indeed i also prefer use randomForest in a regression mode. The only
problem is the not so high ?value of the explained variance, due to
binary value of the response vs the continues value of the prediction.
So my questions to the community are:
How i can calculate the performance of the model in this particular
case?
Can i consider also in this case the maximization of the explained
variance as a driven factor for the tunning?

> A perhaps better alternative would be to use the cforest function (another
> random forest implementation) in 'party', because this function has a
> weights argument.

Yes, i will test and i will let you know the performance.

Thanks again for the suggestions
best regards
Giuseppe Amatulli


From Roger.Bivand at nhh.no  Tue Mar 22 09:30:23 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 22 Mar 2011 09:30:23 +0100 (CET)
Subject: [R-sig-Geo] spdep: show neighbors from "dnearneigh"
In-Reply-To: <AANLkTinvYBJJaOoMw-4EsvEEDuHhfwrhg0Zh_5m7Mrjt@mail.gmail.com>
References: <000201cbdaa0$dda6f4c0$98f4de40$@edu>
	<alpine.LRH.2.00.1103051720020.8089@reclus.nhh.no>
	<000f01cbe7ef$c34e7510$49eb5f30$@edu>
	<AANLkTinvYBJJaOoMw-4EsvEEDuHhfwrhg0Zh_5m7Mrjt@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1103220919140.994@reclus.nhh.no>

On Tue, 22 Mar 2011, Mathieu Rajerison wrote:

> Hi,
>
> Maybe you should convert your nb object into a matrix using nb2mat then use
> reshape package?
>
> library(reshape)
>
> df<-as.data.frame(nb.mat)
>
> df$id<-row.names(df)
>
> mdata<-melt(df,id="id")
>
> then subset your data for which mdata$value > 0

No, the question was how to convert to a two-column from-to 
representation, and a direct route is:

example(read.gal)
# to get an nb object
us48.q
us48.q[1:2]
res <- listw2sn(nb2listw(us48.q))[,1:2]
res[1:9,]
str(res)

If you need a matrix, do as.matrix(res).

Roger


>
>
> 2011/3/21 Kevin Ringelman <kmringelman at ucdavis.edu>
>
>> Thanks for your help Roger.  I have a couple more questions.
>>
>> print.default(nb) shows me what I'm looking for: for each region, I see the
>> regions that are within my distance band.  For example:
>>
>> [[1]]
>>  [1]   2  10  11  15  17  18  19  32  40 554
>>
>> [[2]]
>>  [1]   1  15  17  21  33  34 426 511 554 557
>>
>> I want to make this information into a table, with the focal regions as
>> column 1, and the region IDs of it's neighbors as column 2 (similar to
>> neighbor analysis output in ArcGIS).  Continuing the example from above:
>> 1       2
>> 1       10
>> 1       11
>> 1       15
>> 1       17
>> (etc.)
>>
>> Even after I nuke the nb class
>> U <- unclass(nb)
>> I still can't access or manipulate the data...it doesn't appear as an
>> attribute
>> attribute(U)
>>
>> Any suggestions?
>>
>>
>>
>>
>>
>> -----Original Message-----
>> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>> Sent: Saturday, March 05, 2011 10:03 AM
>> To: Kevin Ringelman
>> Cc: r-sig-geo at r-project.org
>> Subject: Re: [R-sig-Geo] spdep: show neighbors from "dnearneigh"
>>
>> On Fri, 4 Mar 2011, Kevin Ringelman wrote:
>>
>>> I am having trouble viewing the list of neighbors ("regions IDs") after
>>> created a nb object using the "dnearneigh" function in spdep.  I only
>> seem
>>> to get a summary (with # regions, # non-zero links, etc.).  This nb
>> object
>>> also doesn't take well to being converted to another type of object, or
>>> exported from R.  How I view the list of neighbors?
>>>
>>
>> In S and R, objects with a class attribute, such as "nb" objects, may have
>> display methods specific to the class. If you just say:
>>
>>> nb
>>
>> then this is expanded internally to print(nb), and since nb is an object
>> of class "nb", the print.nb() method is chosen. If you want the default
>> print method, call it as print.default(nb). Conversion of objects of one
>> class to another class may be done by coercion where coercion methods are
>> provided. No such methods are available for nb objects. There are
>> functions to do things like this, but not methods. For example, to make an
>> nb object into a row-standardised matrix, you might do:
>>
>>> Wmat <- nb2mat(nb, style="W")
>>
>> but you should avoid this if your number of observations is large. To make
>> a sparse matrix, several steps are required:
>>
>>> lw <- nb2listw(nb, style="W")
>>> spWmat <- as(as_dgRMatrix_listw(lw), "CsparseMatrix")
>>
>> using the nb2listw() and (ugly name) as_dgRMatrix_listw() functions, and
>> coercion from one representation to another using new-style classes
>> defined in the Matrix package.
>>
>>>
>>>
>>> Some additional background: I'm identifying all neighboring bird nests
>>> within 100m of each nest.  For this particular analysis, I ultimately
>> want
>>> to calculate the average vegetation height of neighboring nests to
>> compare
>>> with the focal nest.  This will involve generating a list of neighbors,
>> and
>>> merging that list with my other data.
>>>
>>
>> Note that an nb object is a list - to nuke the class, do:
>>
>>> class(nb) <- NULL
>>
>> which lets you call print.default(), but to get at the attribute you want,
>> just do:
>>
>>> attr(nb, "region.id")
>>
>> to call print.default on the character vector it contains.
>>
>> Hope this clarifies,
>>
>> Roger
>>
>>>
>>>
>>> Thanks,
>>>
>>> Kevin
>>>
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Tue Mar 22 11:21:10 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 22 Mar 2011 11:21:10 +0100 (CET)
Subject: [R-sig-Geo] rgeos released on CRAN
In-Reply-To: <15479c8eaf054a5732110eb5b8b27a24@borasky-research.net>
References: <alpine.LRH.2.00.1103211522320.28668@reclus.nhh.no>
	<alpine.LRH.2.00.1103211643510.28668@reclus.nhh.no>
	<15479c8eaf054a5732110eb5b8b27a24@borasky-research.net>
Message-ID: <alpine.LRH.2.00.1103221115100.994@reclus.nhh.no>

On Mon, 21 Mar 2011, M. Edward (Ed) Borasky wrote:

>
> On Mon, 21 Mar 2011 16:51:21 +0100 (CET), Roger Bivand <Roger.Bivand at nhh.no> 
> wrote:
>> On Mon, 21 Mar 2011, Roger Bivand wrote:
>> 
>>> With some trepidation, rgeos - an interface to Geometry Engine - Open 
>>> Source (GEOS) for topology operations on sp geometries - is now released 
>>> on CRAN as a source package. A Windows binary package should follow within 
>>> a couple of days. If an OSX binary package is offered on CRAN extras, 
>>> information will be given, otherwise use the Kyngchaos framework and 
>>> install from source. Contributions of bug reports, code patches, and 
>>> extensions are welcome, especially via R-Forge. Congratulations to Colin 
>>> Rundel for a very thorough implementation during GSoC 2010!
>> 
>> The fresh maptools 0.8-* release now on CRAN suggests rgeos. It can
>> use rgeos in checkPolygonHoles(), unionSpatialPolygons() and
>> elsewhere, but can still use gpclib if the user prefers. The rgeos
>> version of checkPolygonHoles() adds a comment to each Polygons object,
>> showing whether the member Polygon objects are exterior rings in the
>> OGC "Simple Features" sense, and if they are interior rings, which
>> exterior ring contains them. This maptools release addresses many of
>> the issues raised over recent weeks, but which have been waiting for
>> rgeos to be released.
>> 
>> Roger
>> 
>>> 
>>> Enjoy!
>>> 
>>> Roger
>>> 
>>> 
>
> 1. It looks like it's propagating slowly to US mirrors - 
> http://cran.cnr.berkeley.edu seems to have it, though.
> 2. The last time I installed the Spatial task view from source, quite a few 
> routines seemed to have the option of using rgeos but I was never able to get 
> that to work. Is there anything I need to do to make that "automatic", or 
> does just installing rgeos from CRAN now make it happen?
>

Thanks for your feedback. Because rgeos is new on CRAN, other packages 
have not been able to depend on it or suggest it, so there is no record of 
reverse dependencies or suggestions - the latest maptools is now a reverse 
suggestion. Could you please report back in a little while on how the 
situation progresses and hopefully normalised?

Roger

>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From vioravis at gmail.com  Tue Mar 22 14:49:02 2011
From: vioravis at gmail.com (vioravis)
Date: Tue, 22 Mar 2011 06:49:02 -0700 (PDT)
Subject: [R-sig-Geo] Kernel density plot on a US map
Message-ID: <1300801742922-6196265.post@n2.nabble.com>

I am trying to plot the kernel density plot superimposed on a US map. The
data consists of the the latitude and the longitude of a few locations in
the US and a number (such  as count) corresponding to each location. I would
like to generate a kernel density plot with the count as the variable
superimposed on US map so that I can visualize how the count varies across
the US. I have looked at packages such as spatstat about generating the
kernel density plots but unable to superimpose the density plot on the US
map???

Can someone help me on how to do this in R? 

Thank you.

Ravi

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Kernel-density-plot-on-a-US-map-tp6196265p6196265.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From ashton at msu.edu  Tue Mar 22 16:05:07 2011
From: ashton at msu.edu (Ashton Shortridge)
Date: Tue, 22 Mar 2011 11:05:07 -0400
Subject: [R-sig-Geo] Kernel density plot on a US map
In-Reply-To: <1300801742922-6196265.post@n2.nabble.com>
References: <1300801742922-6196265.post@n2.nabble.com>
Message-ID: <201103221105.07308.ashton@msu.edu>

Hi Ravi,

> generating the kernel density plots but unable to superimpose the density
> plot on the US map???
Check out the following R code. 

library(spatstat)
library(maps)
library(maptools)

# Make a random set of lat-lon pairs with values
usdat <- data.frame(x=runif(50, -115, -85), y=runif(50, 33, 41), z=runif(50, 
0, 100))

map('usa')
points(usdat$x, usdat$y)  # do they fall in there?

# Create an owin object from the USA outline(s)
usmap <- map('usa', fill=TRUE, col="transparent", plot=FALSE)
uspoly <- map2SpatialPolygons(usmap, IDs=usmap$names, 
proj4string=CRS("+proj=longlat +datum=wgs84"))
spatstat.options(checkpolygons=FALSE)
usowin <- as.owin.SpatialPolygons(uspoly)
spatstat.options(checkpolygons=TRUE)

# Create a spatstat ppp object
pts <- as.ppp(usdat, W=usowin)
plot(pts)

# Plot a a density surface
plot(density(pts))

# Plot a smoothed surface using the weights
plot(smooth.ppp(pts, 3))



On 2011-03-22, vioravis, wrote:
> I am trying to plot the kernel density plot superimposed on a US map. The
> data consists of the the latitude and the longitude of a few locations in
> the US and a number (such  as count) corresponding to each location. I
> would like to generate a kernel density plot with the count as the
> variable superimposed on US map so that I can visualize how the count
> varies across the US. I have looked at packages such as spatstat about
> generating the kernel density plots but unable to superimpose the density
> plot on the US map???
> 
> Can someone help me on how to do this in R?
> 
> Thank you.
> 
> Ravi
> 
> --
> View this message in context:
> http://r-sig-geo.2731867.n2.nabble.com/Kernel-density-plot-on-a-US-map-tp6
> 196265p6196265.html Sent from the R-sig-geo mailing list archive at
> Nabble.com.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


-----
Ashton Shortridge
Associate Professor			ashton at msu.edu
Dept of Geography			http://www.msu.edu/~ashton
235 Geography Building		ph (517) 432-3561
Michigan State University		fx (517) 432-1671


From wdmccoy at geo.umass.edu  Tue Mar 22 17:06:31 2011
From: wdmccoy at geo.umass.edu (William McCoy)
Date: Tue, 22 Mar 2011 12:06:31 -0400
Subject: [R-sig-Geo] install of new maptools package fails
Message-ID: <4D88C907.4000506@geo.umass.edu>

I tried updating my installed packages on R today since the new rgeos 
and maptools packages were out.  The update of the maptools package 
failed with the message:

 > ERROR: installing package indices failed

I then tried removing the old maptools package and reinstalling it with 
depend = TRUE to be sure I had all the needed dependencies.  However it 
still fails with:

 > ** building package indices ...
 > Warning: file 'gpcholes.rda' has magic number ''
 >    Use of save versions prior to 2 is deprecated
 > Error : bad restore file magic number (file may be corrupted) -- no 
data loaded
 > ERROR: installing package indices failed
 > * removing ?/usr/share/R/library/maptools?


I'm not sure what the underlying cause is.  Can someone suggest a solution?

The full text of the install.packages() output is below.


Bill

-- 
William D. McCoy
Geosciences
University of Massachusetts
Amherst, MA  01003




 > install.packages("maptools", depend = TRUE, lib = "/usr/share/R/library")
trying URL 
'http://software.rc.fas.harvard.edu/mirrors/R/src/contrib/maptools_0.8-3.tar.gz'
Content type 'application/x-gzip' length 894578 bytes (873 Kb)
opened URL
==================================================
downloaded 873 Kb

* installing *source* package ?maptools? ...
** libs
gcc -m64 -std=gnu99 -I/usr/include/R  -I/usr/local/include    -fpic  -O2 
-g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
--param=ssp-buffer-size=4 -m64 -mtune=generic -c Rcentroid.c -o Rcentroid.o
gcc -m64 -std=gnu99 -I/usr/include/R  -I/usr/local/include    -fpic  -O2 
-g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
--param=ssp-buffer-size=4 -m64 -mtune=generic -c Rgshhs.c -o Rgshhs.o
gcc -m64 -std=gnu99 -I/usr/include/R  -I/usr/local/include    -fpic  -O2 
-g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
--param=ssp-buffer-size=4 -m64 -mtune=generic -c Rshapeget.c -o Rshapeget.o
Rshapeget.c: In function ?Rshapeget?:
Rshapeget.c:24:32: warning: unused variable ?nImpliedEOF?
gcc -m64 -std=gnu99 -I/usr/include/R  -I/usr/local/include    -fpic  -O2 
-g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
--param=ssp-buffer-size=4 -m64 -mtune=generic -c Rshapeinfo.c -o 
Rshapeinfo.o
gcc -m64 -std=gnu99 -I/usr/include/R  -I/usr/local/include    -fpic  -O2 
-g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
--param=ssp-buffer-size=4 -m64 -mtune=generic -c Rshapewrite.c -o 
Rshapewrite.o
gcc -m64 -std=gnu99 -I/usr/include/R  -I/usr/local/include    -fpic  -O2 
-g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
--param=ssp-buffer-size=4 -m64 -mtune=generic -c Rshapewrite1.c -o 
Rshapewrite1.o
Rshapewrite1.c: In function ?shpwritepolys?:
Rshapewrite1.c:12:9: warning: ?nShapeType? may be used uninitialized in 
this function
Rshapewrite1.c:15:29: warning: ?padfZ? may be used uninitialized in this 
function
gcc -m64 -std=gnu99 -I/usr/include/R  -I/usr/local/include    -fpic  -O2 
-g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
--param=ssp-buffer-size=4 -m64 -mtune=generic -c insiders.c -o insiders.o
gcc -m64 -std=gnu99 -I/usr/include/R  -I/usr/local/include    -fpic  -O2 
-g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
--param=ssp-buffer-size=4 -m64 -mtune=generic -c pip.c -o pip.o
gcc -m64 -std=gnu99 -I/usr/include/R  -I/usr/local/include    -fpic  -O2 
-g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
--param=ssp-buffer-size=4 -m64 -mtune=generic -c shpopen.c -o shpopen.o
shpopen.c:203:94: warning: ?cvsid_aw? defined but not used
shpopen.c: In function ?SHPOpen?:
shpopen.c:507:10: warning: ignoring return value of ?fread?, declared 
with attribute warn_unused_result
gcc -m64 -std=gnu99 -I/usr/include/R  -I/usr/local/include    -fpic  -O2 
-g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
--param=ssp-buffer-size=4 -m64 -mtune=generic -c shptree.c -o shptree.o
shptree.c:82:94: warning: ?cvsid_aw? defined but not used
shptree.c: In function ?SHPWriteTree?:
shptree.c:969:11: warning: ignoring return value of ?fwrite?, declared 
with attribute warn_unused_result
shptree.c:971:11: warning: ignoring return value of ?fwrite?, declared 
with attribute warn_unused_result
shptree.c:975:11: warning: ignoring return value of ?fwrite?, declared 
with attribute warn_unused_result
shptree.c: In function ?SHPWriteTreeNode?:
shptree.c:915:11: warning: ignoring return value of ?fwrite?, declared 
with attribute warn_unused_result
shptree.c: In function ?SHPSearchDiskTree?:
shptree.c:829:10: warning: ignoring return value of ?fread?, declared 
with attribute warn_unused_result
shptree.c: In function ?SHPSearchDiskTreeNode?:
shptree.c:731:10: warning: ignoring return value of ?fread?, declared 
with attribute warn_unused_result
shptree.c:734:10: warning: ignoring return value of ?fread?, declared 
with attribute warn_unused_result
shptree.c:735:10: warning: ignoring return value of ?fread?, declared 
with attribute warn_unused_result
shptree.c:744:10: warning: ignoring return value of ?fread?, declared 
with attribute warn_unused_result
shptree.c:771:14: warning: ignoring return value of ?fread?, declared 
with attribute warn_unused_result
shptree.c:786:10: warning: ignoring return value of ?fread?, declared 
with attribute warn_unused_result
gcc -m64 -std=gnu99 -shared -L/usr/local/lib64 -o maptools.so 
Rcentroid.o Rgshhs.o Rshapeget.o Rshapeinfo.o Rshapewrite.o 
Rshapewrite1.o insiders.o pip.o shpopen.o shptree.o -L/usr/lib64/R/lib -lR
installing to /usr/share/R/library/maptools/libs
** R
** data
** inst
** preparing package for lazy loading
** help
*** installing help indices
   converting help for package ?maptools?
     finding HTML links ... done
     CCmaps                                  html
Rd warning: /tmp/RtmpU9ikc7/R.INSTALL230eb10c/maptools/man/CCmaps.Rd:14: 
missing file link ?SpatialPolygonsDataFrame?
Rd warning: /tmp/RtmpU9ikc7/R.INSTALL230eb10c/maptools/man/CCmaps.Rd:33: 
missing file link ?SpatialPolygonsDataFrame?
     ContourLines2SLDF                       html
     GE_SpatialGrid                          html
     Rgshhs                                  html
Rd warning: /tmp/RtmpU9ikc7/R.INSTALL230eb10c/maptools/man/Rgshhs.Rd:31: 
missing file link ?gContainsProperly?
Rd warning: /tmp/RtmpU9ikc7/R.INSTALL230eb10c/maptools/man/Rgshhs.Rd:31: 
missing file link ?gContains?
     SpatialLines2PolySet                    html
     as.ppp                                  html
     asciigrid                               html
     checkPolygonsHoles                      html
Rd warning: 
/tmp/RtmpU9ikc7/R.INSTALL230eb10c/maptools/man/checkPolygonsHoles.Rd:20: 
missing file link ?gContainsProperly?
Rd warning: 
/tmp/RtmpU9ikc7/R.INSTALL230eb10c/maptools/man/checkPolygonsHoles.Rd:20: 
missing file link ?gContains?
     dotsInPolys                             html
     elide-methods                           html
     gcDestination                           html
     getKMLcoordinates                       html
     getinfo.shape                           html
     gzAzimuth                               html
     holepolys                               html
     kmlLine                                 html
     kmlOverlay                              html
     kmlPolygon                              html
     leglabs                                 html
     map2SpatialPolygons                     html
     nowrapRecenter                          html
     pal2SpatialPolygons                     html
     pointLabel                              html
     ppp                                     html
     readGPS                                 html
     readShapeLines                          html
     readShapePoints                         html
     readShapePoly                           html
     readShapeSpatial                        html
     readSplus                               html
     sp2Mondrian                             html
     sp2WB                                   html
     sp2tmap                                 html
     spCbind-methods                         html
     spRbind-methods                         html
     sun-methods                             html
     symbolsInPolys                          html
     thinnedSpatialPoly                      html
     unionSpatialPolygons                    html
     wrld_simpl                              html
** building package indices ...
Warning: file 'gpcholes.rda' has magic number ''
    Use of save versions prior to 2 is deprecated
Error : bad restore file magic number (file may be corrupted) -- no data 
loaded
ERROR: installing package indices failed
* removing ?/usr/share/R/library/maptools?

The downloaded packages are in
         ?/tmp/Rtmp9LJc7G/downloaded_packages?
Warning message:
In install.packages("maptools", depend = TRUE, lib = 
"/usr/share/R/library") :
   installation of package 'maptools' had non-zero exit status


From mathieu.rajerison at gmail.com  Tue Mar 22 17:15:44 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Tue, 22 Mar 2011 17:15:44 +0100
Subject: [R-sig-Geo] space-time prediction
Message-ID: <AANLkTinEOOUCuitUGfEo4CdbxuDz3TZrcck0C79KyYzU@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110322/17431e27/attachment.pl>

From Roger.Bivand at nhh.no  Tue Mar 22 17:25:48 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 22 Mar 2011 17:25:48 +0100 (CET)
Subject: [R-sig-Geo] install of new maptools package fails
In-Reply-To: <4D88C907.4000506@geo.umass.edu>
References: <4D88C907.4000506@geo.umass.edu>
Message-ID: <alpine.LRH.2.00.1103221715120.994@reclus.nhh.no>

On Tue, 22 Mar 2011, William McCoy wrote:

> I tried updating my installed packages on R today since the new rgeos and 
> maptools packages were out.  The update of the maptools package failed with 
> the message:
>
>> ERROR: installing package indices failed

Which system - output of sessionInfo() and other relevant details, please? 
The release has checked cleanly pre-submission on Redhat 5 x86_64, but I 
don't see the -m64 flag for my regularly configured R on compiled code. It 
checked OK on pre-release R 2.13 on 32-bit Fedora 14, and on the 
development R 2.14, without the errors you list.

We can take this offlist until it is resolved if you like.

Roger

>
> I then tried removing the old maptools package and reinstalling it with 
> depend = TRUE to be sure I had all the needed dependencies.  However it still 
> fails with:
>
>> ** building package indices ...
>> Warning: file 'gpcholes.rda' has magic number ''
>>    Use of save versions prior to 2 is deprecated
>> Error : bad restore file magic number (file may be corrupted) -- no data 
> loaded
>> ERROR: installing package indices failed
>> * removing ?/usr/share/R/library/maptools?
>
>
> I'm not sure what the underlying cause is.  Can someone suggest a solution?
>
> The full text of the install.packages() output is below.
>
>
> Bill
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From clint at ecy.wa.gov  Tue Mar 22 17:50:18 2011
From: clint at ecy.wa.gov (Clint Bowman)
Date: Tue, 22 Mar 2011 09:50:18 -0700 (PDT)
Subject: [R-sig-Geo] install of new maptools package fails
In-Reply-To: <alpine.LRH.2.00.1103221715120.994@reclus.nhh.no>
References: <4D88C907.4000506@geo.umass.edu>
	<alpine.LRH.2.00.1103221715120.994@reclus.nhh.no>
Message-ID: <alpine.LRH.2.02.1103220939250.8578@aeolus.ecy.wa.gov>

I have a failure installing rgeos:

> sessionInfo()
R version 2.12.2 (2011-02-25)
Platform: x86_64-redhat-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods 
base

loaded via a namespace (and not attached):
[1] tcltk_2.12.2 tools_2.12.2

First error during the install (following a series of warnings):

gcc -m64 -std=gnu99 -I/usr/include/R -I/usr/include 
-I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic 
-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions 
-fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic -c 
rgeos_misc.c -o rgeos_misc.o
rgeos_misc.c: In function ?rgeos_area?:
rgeos_misc.c:5: warning: passing argument 4 of ?rgeos_miscfunc? 
from incompatible pointer type
rgeos_misc.c: In function ?rgeos_length?:
rgeos_misc.c:9: warning: passing argument 4 of ?rgeos_miscfunc? 
from incompatible pointer type
rgeos_misc.c: In function ?rgeos_distance?:
rgeos_misc.c:51: warning: passing argument 5 of 
?rgeos_distancefunc? from incompatible pointer type
rgeos_misc.c: In function ?rgeos_hausdorffdistance?:
rgeos_misc.c:55: error: ?GEOSHausdorffDistance_r? undeclared (first 
use in this function)
rgeos_misc.c:55: error: (Each undeclared identifier is reported 
only once
rgeos_misc.c:55: error: for each function it appears in.)
rgeos_misc.c: In function ?rgeos_hausdorffdistancedensify?:
rgeos_misc.c:137: error: ?GEOSHausdorffDistanceDensify_r? 
undeclared (first use in this function)
make: *** [rgeos_misc.o] Error 1
ERROR: compilation failed for package ?rgeos?

Not that it matters but I see "-m64" twice in the gcc command line.

Clint

-- 
Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600


         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274


On Tue, 22 Mar 2011, Roger Bivand wrote:

> On Tue, 22 Mar 2011, William McCoy wrote:
>
>>  I tried updating my installed packages on R today since the new rgeos and
>>  maptools packages were out.  The update of the maptools package failed
>>  with the message:
>> 
>> >  ERROR: installing package indices failed
>
> Which system - output of sessionInfo() and other relevant details, please? 
> The release has checked cleanly pre-submission on Redhat 5 x86_64, but I 
> don't see the -m64 flag for my regularly configured R on compiled code. It 
> checked OK on pre-release R 2.13 on 32-bit Fedora 14, and on the development 
> R 2.14, without the errors you list.
>
> We can take this offlist until it is resolved if you like.
>
> Roger
>
>>
>>  I then tried removing the old maptools package and reinstalling it with
>>  depend = TRUE to be sure I had all the needed dependencies.  However it
>>  still fails with:
>> 
>> >  ** building package indices ...
>> >  Warning: file 'gpcholes.rda' has magic number ''
>> >     Use of save versions prior to 2 is deprecated
>> >  Error : bad restore file magic number (file may be corrupted) -- no data
>>  loaded
>> >  ERROR: installing package indices failed
>> >  * removing ?/usr/share/R/library/maptools?
>> 
>>
>>  I'm not sure what the underlying cause is.  Can someone suggest a
>>  solution?
>>
>>  The full text of the install.packages() output is below.
>> 
>>
>>  Bill
>> 
>> 
>
>

From kmringelman at ucdavis.edu  Tue Mar 22 18:43:54 2011
From: kmringelman at ucdavis.edu (Kevin Ringelman)
Date: Tue, 22 Mar 2011 10:43:54 -0700
Subject: [R-sig-Geo] spdep: show neighbors from "dnearneigh"
In-Reply-To: <alpine.LRH.2.00.1103220919140.994@reclus.nhh.no>
References: <000201cbdaa0$dda6f4c0$98f4de40$@edu>
	<alpine.LRH.2.00.1103051720020.8089@reclus.nhh.no>
	<000f01cbe7ef$c34e7510$49eb5f30$@edu>
	<AANLkTinvYBJJaOoMw-4EsvEEDuHhfwrhg0Zh_5m7Mrjt@mail.gmail.com>
	<alpine.LRH.2.00.1103220919140.994@reclus.nhh.no>
Message-ID: <000c01cbe8b8$b77b03b0$26710b10$@edu>

Thanks Roger and Mathieu.  Instead of:
 [[1]]
  [1]   2  10  11  15  17

I now have:
1	2
1	10
1	11
1	15
1	17

For the last piece of this analysis, I would like to generate a list of
neighbor distances to complete my table.
nbd <- nbdist(nb, SpatialPoints)
nbd
[[1]]
 [1] 84.95881 90.35486 75.92760 22.20360 81.00617

But ideally, I would like to have
1	2	84.95881
1	10	90.35486
1	11	75.92760
1	15	22.20360
1	17	81.00617

I can't use nb2listw (and then merge), because this is an object of class
"nbdist".  I also cannot use the Mathieu's melt method, because I nb2mat
also requires an object of class "nb".

Suggestions?




-----Original Message-----
From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Sent: Tuesday, March 22, 2011 1:30 AM
To: Mathieu Rajerison
Cc: kmringelman at ucdavis.edu; r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] spdep: show neighbors from "dnearneigh"

On Tue, 22 Mar 2011, Mathieu Rajerison wrote:

> Hi,
>
> Maybe you should convert your nb object into a matrix using nb2mat then
use
> reshape package?
>
> library(reshape)
>
> df<-as.data.frame(nb.mat)
>
> df$id<-row.names(df)
>
> mdata<-melt(df,id="id")
>
> then subset your data for which mdata$value > 0

No, the question was how to convert to a two-column from-to 
representation, and a direct route is:

example(read.gal)
# to get an nb object
us48.q
us48.q[1:2]
res <- listw2sn(nb2listw(us48.q))[,1:2]
res[1:9,]
str(res)

If you need a matrix, do as.matrix(res).

Roger


>
>
> 2011/3/21 Kevin Ringelman <kmringelman at ucdavis.edu>
>
>> Thanks for your help Roger.  I have a couple more questions.
>>
>> print.default(nb) shows me what I'm looking for: for each region, I see
the
>> regions that are within my distance band.  For example:
>>
>> [[1]]
>>  [1]   2  10  11  15  17  18  19  32  40 554
>>
>> [[2]]
>>  [1]   1  15  17  21  33  34 426 511 554 557
>>
>> I want to make this information into a table, with the focal regions as
>> column 1, and the region IDs of it's neighbors as column 2 (similar to
>> neighbor analysis output in ArcGIS).  Continuing the example from above:
>> 1       2
>> 1       10
>> 1       11
>> 1       15
>> 1       17
>> (etc.)
>>
>> Even after I nuke the nb class
>> U <- unclass(nb)
>> I still can't access or manipulate the data...it doesn't appear as an
>> attribute
>> attribute(U)
>>
>> Any suggestions?
>>
>>
>>
>>
>>
>> -----Original Message-----
>> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>> Sent: Saturday, March 05, 2011 10:03 AM
>> To: Kevin Ringelman
>> Cc: r-sig-geo at r-project.org
>> Subject: Re: [R-sig-Geo] spdep: show neighbors from "dnearneigh"
>>
>> On Fri, 4 Mar 2011, Kevin Ringelman wrote:
>>
>>> I am having trouble viewing the list of neighbors ("regions IDs") after
>>> created a nb object using the "dnearneigh" function in spdep.  I only
>> seem
>>> to get a summary (with # regions, # non-zero links, etc.).  This nb
>> object
>>> also doesn't take well to being converted to another type of object, or
>>> exported from R.  How I view the list of neighbors?
>>>
>>
>> In S and R, objects with a class attribute, such as "nb" objects, may
have
>> display methods specific to the class. If you just say:
>>
>>> nb
>>
>> then this is expanded internally to print(nb), and since nb is an object
>> of class "nb", the print.nb() method is chosen. If you want the default
>> print method, call it as print.default(nb). Conversion of objects of one
>> class to another class may be done by coercion where coercion methods are
>> provided. No such methods are available for nb objects. There are
>> functions to do things like this, but not methods. For example, to make
an
>> nb object into a row-standardised matrix, you might do:
>>
>>> Wmat <- nb2mat(nb, style="W")
>>
>> but you should avoid this if your number of observations is large. To
make
>> a sparse matrix, several steps are required:
>>
>>> lw <- nb2listw(nb, style="W")
>>> spWmat <- as(as_dgRMatrix_listw(lw), "CsparseMatrix")
>>
>> using the nb2listw() and (ugly name) as_dgRMatrix_listw() functions, and
>> coercion from one representation to another using new-style classes
>> defined in the Matrix package.
>>
>>>
>>>
>>> Some additional background: I'm identifying all neighboring bird nests
>>> within 100m of each nest.  For this particular analysis, I ultimately
>> want
>>> to calculate the average vegetation height of neighboring nests to
>> compare
>>> with the focal nest.  This will involve generating a list of neighbors,
>> and
>>> merging that list with my other data.
>>>
>>
>> Note that an nb object is a list - to nuke the class, do:
>>
>>> class(nb) <- NULL
>>
>> which lets you call print.default(), but to get at the attribute you
want,
>> just do:
>>
>>> attr(nb, "region.id")
>>
>> to call print.default on the character vector it contains.
>>
>> Hope this clarifies,
>>
>> Roger
>>
>>>
>>>
>>> Thanks,
>>>
>>> Kevin
>>>
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From vioravis at gmail.com  Tue Mar 22 18:46:24 2011
From: vioravis at gmail.com (vioravis)
Date: Tue, 22 Mar 2011 10:46:24 -0700 (PDT)
Subject: [R-sig-Geo] Kernel density plot on a US map
In-Reply-To: <201103221105.07308.ashton@msu.edu>
References: <1300801742922-6196265.post@n2.nabble.com>
	<201103221105.07308.ashton@msu.edu>
Message-ID: <1300815984907-6197393.post@n2.nabble.com>

Hi Ashton,

Thank you. This is exactly what I was looking for!!

It works fine with the test data you have created but when I try it with the
actual data it throws the following error:

Error in `marks<-.ppp`(`*tmp*`, value = c(51L, 14L, 26L, 2L, 108L, 40L,  : 
  number of points != number of marks
In addition: Warning message:
In ppp(X[, 1], X[, 2], window = win, check = check) :
  7 points were rejected as lying outside the specified window

Could you please let me know what is causing this error??? 

Also, could you please let me know the interpretation of smooth.ppp plot.

Thank you.

Ravi

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Kernel-density-plot-on-a-US-map-tp6196265p6197393.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Wed Mar 23 07:36:38 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 23 Mar 2011 07:36:38 +0100 (CET)
Subject: [R-sig-Geo] spdep: show neighbors from "dnearneigh"
In-Reply-To: <000c01cbe8b8$b77b03b0$26710b10$@edu>
References: <000201cbdaa0$dda6f4c0$98f4de40$@edu>
	<alpine.LRH.2.00.1103051720020.8089@reclus.nhh.no>
	<000f01cbe7ef$c34e7510$49eb5f30$@edu>
	<AANLkTinvYBJJaOoMw-4EsvEEDuHhfwrhg0Zh_5m7Mrjt@mail.gmail.com>
	<alpine.LRH.2.00.1103220919140.994@reclus.nhh.no>
	<000c01cbe8b8$b77b03b0$26710b10$@edu>
Message-ID: <alpine.LRH.2.00.1103230733040.4667@reclus.nhh.no>

On Tue, 22 Mar 2011, Kevin Ringelman wrote:

> Thanks Roger and Mathieu.  Instead of:
> [[1]]
>  [1]   2  10  11  15  17
>
> I now have:
> 1	2
> 1	10
> 1	11
> 1	15
> 1	17
>
> For the last piece of this analysis, I would like to generate a list of
> neighbor distances to complete my table.
> nbd <- nbdist(nb, SpatialPoints)
> nbd
> [[1]]
> [1] 84.95881 90.35486 75.92760 22.20360 81.00617
>
> But ideally, I would like to have
> 1	2	84.95881
> 1	10	90.35486
> 1	11	75.92760
> 1	15	22.20360
> 1	17	81.00617
>
> I can't use nb2listw (and then merge), because this is an object of class
> "nbdist".  I also cannot use the Mathieu's melt method, because I nb2mat
> also requires an object of class "nb".

But listw2mat doesn't - see ?nb2mat. For the direct route, see ?nb2listw, 
and ?listw2sn:

ds <- nbdists(us48.q, as.matrix(as.data.frame(state.center))[m50.48,],
   longlat=TRUE)
# here using a matrix of state centroids - geographical coordinates
lw <- nb2listw(us48.q, glist=ds, style="B")
res <- listw2sn(lw)
res[1:9,]
# with distances in this case in Great Circle km.

Roger


>
> Suggestions?
>
>
>
>
> -----Original Message-----
> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Sent: Tuesday, March 22, 2011 1:30 AM
> To: Mathieu Rajerison
> Cc: kmringelman at ucdavis.edu; r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] spdep: show neighbors from "dnearneigh"
>
> On Tue, 22 Mar 2011, Mathieu Rajerison wrote:
>
>> Hi,
>>
>> Maybe you should convert your nb object into a matrix using nb2mat then
> use
>> reshape package?
>>
>> library(reshape)
>>
>> df<-as.data.frame(nb.mat)
>>
>> df$id<-row.names(df)
>>
>> mdata<-melt(df,id="id")
>>
>> then subset your data for which mdata$value > 0
>
> No, the question was how to convert to a two-column from-to
> representation, and a direct route is:
>
> example(read.gal)
> # to get an nb object
> us48.q
> us48.q[1:2]
> res <- listw2sn(nb2listw(us48.q))[,1:2]
> res[1:9,]
> str(res)
>
> If you need a matrix, do as.matrix(res).
>
> Roger
>
>
>>
>>
>> 2011/3/21 Kevin Ringelman <kmringelman at ucdavis.edu>
>>
>>> Thanks for your help Roger.  I have a couple more questions.
>>>
>>> print.default(nb) shows me what I'm looking for: for each region, I see
> the
>>> regions that are within my distance band.  For example:
>>>
>>> [[1]]
>>>  [1]   2  10  11  15  17  18  19  32  40 554
>>>
>>> [[2]]
>>>  [1]   1  15  17  21  33  34 426 511 554 557
>>>
>>> I want to make this information into a table, with the focal regions as
>>> column 1, and the region IDs of it's neighbors as column 2 (similar to
>>> neighbor analysis output in ArcGIS).  Continuing the example from above:
>>> 1       2
>>> 1       10
>>> 1       11
>>> 1       15
>>> 1       17
>>> (etc.)
>>>
>>> Even after I nuke the nb class
>>> U <- unclass(nb)
>>> I still can't access or manipulate the data...it doesn't appear as an
>>> attribute
>>> attribute(U)
>>>
>>> Any suggestions?
>>>
>>>
>>>
>>>
>>>
>>> -----Original Message-----
>>> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>> Sent: Saturday, March 05, 2011 10:03 AM
>>> To: Kevin Ringelman
>>> Cc: r-sig-geo at r-project.org
>>> Subject: Re: [R-sig-Geo] spdep: show neighbors from "dnearneigh"
>>>
>>> On Fri, 4 Mar 2011, Kevin Ringelman wrote:
>>>
>>>> I am having trouble viewing the list of neighbors ("regions IDs") after
>>>> created a nb object using the "dnearneigh" function in spdep.  I only
>>> seem
>>>> to get a summary (with # regions, # non-zero links, etc.).  This nb
>>> object
>>>> also doesn't take well to being converted to another type of object, or
>>>> exported from R.  How I view the list of neighbors?
>>>>
>>>
>>> In S and R, objects with a class attribute, such as "nb" objects, may
> have
>>> display methods specific to the class. If you just say:
>>>
>>>> nb
>>>
>>> then this is expanded internally to print(nb), and since nb is an object
>>> of class "nb", the print.nb() method is chosen. If you want the default
>>> print method, call it as print.default(nb). Conversion of objects of one
>>> class to another class may be done by coercion where coercion methods are
>>> provided. No such methods are available for nb objects. There are
>>> functions to do things like this, but not methods. For example, to make
> an
>>> nb object into a row-standardised matrix, you might do:
>>>
>>>> Wmat <- nb2mat(nb, style="W")
>>>
>>> but you should avoid this if your number of observations is large. To
> make
>>> a sparse matrix, several steps are required:
>>>
>>>> lw <- nb2listw(nb, style="W")
>>>> spWmat <- as(as_dgRMatrix_listw(lw), "CsparseMatrix")
>>>
>>> using the nb2listw() and (ugly name) as_dgRMatrix_listw() functions, and
>>> coercion from one representation to another using new-style classes
>>> defined in the Matrix package.
>>>
>>>>
>>>>
>>>> Some additional background: I'm identifying all neighboring bird nests
>>>> within 100m of each nest.  For this particular analysis, I ultimately
>>> want
>>>> to calculate the average vegetation height of neighboring nests to
>>> compare
>>>> with the focal nest.  This will involve generating a list of neighbors,
>>> and
>>>> merging that list with my other data.
>>>>
>>>
>>> Note that an nb object is a list - to nuke the class, do:
>>>
>>>> class(nb) <- NULL
>>>
>>> which lets you call print.default(), but to get at the attribute you
> want,
>>> just do:
>>>
>>>> attr(nb, "region.id")
>>>
>>> to call print.default on the character vector it contains.
>>>
>>> Hope this clarifies,
>>>
>>> Roger
>>>
>>>>
>>>>
>>>> Thanks,
>>>>
>>>> Kevin
>>>>
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>
>>> --
>>> Roger Bivand
>>> Economic Geography Section, Department of Economics, Norwegian School of
>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>> e-mail: Roger.Bivand at nhh.no
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From piero.campa at gmail.com  Wed Mar 23 10:39:38 2011
From: piero.campa at gmail.com (piero campa)
Date: Wed, 23 Mar 2011 02:39:38 -0700 (PDT)
Subject: [R-sig-Geo] Cell Declustering
In-Reply-To: <4693EBCA.2020802@geo.uu.nl>
References: <4693371F.3000300@science.unitn.it> <46934FA1.9010608@geo.uu.nl>
	<4693EBCA.2020802@geo.uu.nl>
Message-ID: <1300873178049-6199548.post@n2.nabble.com>

"A quick and dirty answer would be to work with grids, and e.g. retain a
single value in each grid cell": that's what I would like to do, since my
points pattern is highly clustered.

I thought I could do something like:
> overlay(points, grid, fn=mean)
but looking at methods?sp::overlay it seems that only assignment of values
of a grid over points locations can be achieved, not the inverse.

Moreover:
> over(points, grid, fn=mean)
would be perfect, but it seems to consider only points that lay exactly on
the centre of the grid, while points within a cell (but not in the centre)
are not considered.

Any clue?
Cheers,
Piero

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Cell-Declustering-tp2763587p6199548.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From vioravis at gmail.com  Wed Mar 23 13:20:49 2011
From: vioravis at gmail.com (vioravis)
Date: Wed, 23 Mar 2011 05:20:49 -0700 (PDT)
Subject: [R-sig-Geo] Kernel density plot on a US map
In-Reply-To: <1300815984907-6197393.post@n2.nabble.com>
References: <1300801742922-6196265.post@n2.nabble.com>
	<201103221105.07308.ashton@msu.edu>
	<1300815984907-6197393.post@n2.nabble.com>
Message-ID: <1300882849820-6199778.post@n2.nabble.com>

After a few trials it appears that the cause of the errors is the points
lying outside the specified window.

1. As a quick fix, I could remove the points (only a few) and do the
analysis. How do I check whether a point lies within the window or not???

2. I have a few points in Alaska and Hawaii that do not appear in the map.
How do I add those regions to the US map???

Please let me know. Thank you.

Ravi

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Kernel-density-plot-on-a-US-map-tp6196265p6199778.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Wed Mar 23 14:38:20 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 23 Mar 2011 14:38:20 +0100 (CET)
Subject: [R-sig-Geo] rgeos released on CRAN
In-Reply-To: <alpine.LRH.2.00.1103211522320.28668@reclus.nhh.no>
References: <alpine.LRH.2.00.1103211522320.28668@reclus.nhh.no>
Message-ID: <alpine.LRH.2.00.1103231435390.5685@reclus.nhh.no>

On Mon, 21 Mar 2011, Roger Bivand wrote:

> With some trepidation, rgeos - an interface to Geometry Engine - Open Source 
> (GEOS) for topology operations on sp geometries - is now released on CRAN as 
> a source package. A Windows binary package should follow within a couple of 
> days. If an OSX binary package is offered on CRAN extras, information will be 
> given, otherwise use the Kyngchaos framework and install from source. 
> Contributions of bug reports, code patches, and extensions are welcome, 
> especially via R-Forge. Congratulations to Colin Rundel for a very thorough 
> implementation during GSoC 2010!

The Windows binary package is now available on CRAN, and thanks to Prof. 
Brian Ripley, an OSX binary package is available on CRAN Extras, (the 
second default repository on OSX R installs).

Roger

>
> Enjoy!
>
> Roger
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From kidsmake6 at msn.com  Wed Mar 23 15:10:02 2011
From: kidsmake6 at msn.com (Brad Nesom)
Date: Wed, 23 Mar 2011 09:10:02 -0500
Subject: [R-sig-Geo] Raster calculation
Message-ID: <AANLkTi=MR+4VS7Qa69j6Yxc4n2Z3ra2JYtwRtq9FTsWr@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110323/81286593/attachment.pl>

From edzer.pebesma at uni-muenster.de  Wed Mar 23 17:06:27 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 23 Mar 2011 17:06:27 +0100
Subject: [R-sig-Geo] simple operation on data.frame or
	spatialPointsDataFrame
In-Reply-To: <AANLkTim1ioJepDif_R4BeP8VbqxtVY3WmsRijW=_yn9_@mail.gmail.com>
References: <AANLkTim1ioJepDif_R4BeP8VbqxtVY3WmsRijW=_yn9_@mail.gmail.com>
Message-ID: <4D8A1A83.8070700@uni-muenster.de>

I find it hard to tell without being able to look over your shoulder.
Maybe you should try to pass a better initial model to fit.variogram;
have you tried to plot the initial model with the sample variogram?

On 03/21/2011 11:10 AM, Eric Boeker wrote:
> Hi All,
> 
> 
> I'm fitting variograms in GSTAT with fit.variogram. The coordinates are in
> UTM  (meters) and I got the Warning message: *singular model in variogram
> fit*.
> 
> I found the reason from a previous archive mail of this warning message. (
> http://www.mail-archive.com/r-sig-geo at stat.math.ethz.ch/msg04054.html)
> 
> 
> Basically one possible solution is to divide the UTM coordinates (meters) by
> 1000 to convert them in km.
> 
> But I really do not want to go back to excel to convert the coordinates
> values. I would like to use R for doing this operation on the coordinates.
> 
> 
> My questions are:
> 
> 
> 
>    1. Can this division take place directly on the SpatialPontsDataFrame or
>    it should first be done on the dataframe?
>    2. How do I do this division to the concerned column? Using the
>    fix(dataframe) or edit.row.names  will take me ages and is not a
>    solution.
> 
> 
> Thanks for your Helps
> 
> 
> The structure of the data I'm using:
> 
> 
> Formal class 'SpatialPointsDataFrame' [package "sp"] with 5 slots
> 
>   ..@ data       :'data.frame':   2433 obs. of  10 variables:
> 
>   .. ..$ CODAGIS: num [1:2433] 1201038 1501545 1471560 1101438 1267741 ...
> 
>   .. ..$ COND   : num [1:2433] 10 10 13 14 14 17 17 18 19 19 ...
> 
>   .. ..$ litho2 : Factor w/ 14 levels "Bg","Bp","Bs",..: 10 10 11 3 10 10 10
> 11 11 11 ...
> 
>   .. ..$ targ   : num [1:2433] 194 233 218 252 217 ...
> 
>   .. ..$ tseas  : num [1:2433] 1192 2445 2077 2746 1928 ...
> 
>   .. ..$ amt    : num [1:2433] 285 276 269 292 282 ...
> 
>   .. ..$ amprc  : num [1:2433] 778 965 1083 632 847 ...
> 
>   .. ..$ qscond : Factor w/ 4 levels "[10,300]","(300,450]",..: 1 1 1 1 1 1
> 1 1 1 1 ...
> 
>   ..@ coords.nrs : int [1:2] 4 5
> 
>   ..@ coords     : num [1:2433, 1:2] 300199 466229 270440 251040 343761 ...
> 
>   .. ..- attr(*, "dimnames")=List of 2
> 
>   .. .. ..$ : NULL
> 
>   .. .. ..$ : chr [1:2] "XUTM" "YUTM"
> 
>   ..@ bbox       : num [1:2, 1:2] 155702 1331253 534504 1719735
> 
>   .. ..- attr(*, "dimnames")=List of 2
> 
>   .. .. ..$ : chr [1:2] "XUTM" "YUTM"
> 
>   .. .. ..$ : chr [1:2] "min" "max"
> 
>   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
> 
>   .. .. ..@ projargs: chr "+proj=utm +zone=29 +datum=WGS84"
> 
> 
> 
> 
> 
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From etiennebr at gmail.com  Wed Mar 23 17:53:30 2011
From: etiennebr at gmail.com (Etienne Bellemare)
Date: Wed, 23 Mar 2011 12:53:30 -0400
Subject: [R-sig-Geo] Raster calculation
In-Reply-To: <AANLkTi=MR+4VS7Qa69j6Yxc4n2Z3ra2JYtwRtq9FTsWr@mail.gmail.com>
References: <AANLkTi=MR+4VS7Qa69j6Yxc4n2Z3ra2JYtwRtq9FTsWr@mail.gmail.com>
Message-ID: <AANLkTimm0rFXLFFjBgNg2V3mbNHj=Y3er409yWWMUbNM@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110323/39980973/attachment.pl>

From kidsmake6 at msn.com  Wed Mar 23 20:06:40 2011
From: kidsmake6 at msn.com (Brad Nesom)
Date: Wed, 23 Mar 2011 14:06:40 -0500
Subject: [R-sig-Geo] Raster calculation
In-Reply-To: <AANLkTimm0rFXLFFjBgNg2V3mbNHj=Y3er409yWWMUbNM@mail.gmail.com>
References: <AANLkTi=MR+4VS7Qa69j6Yxc4n2Z3ra2JYtwRtq9FTsWr@mail.gmail.com>
	<AANLkTimm0rFXLFFjBgNg2V3mbNHj=Y3er409yWWMUbNM@mail.gmail.com>
Message-ID: <AANLkTimfVVWd8PjyorrPyjKhtyBA87pq8OcFmk-VKnAw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110323/458c7e0d/attachment.pl>

From mdsumner at gmail.com  Wed Mar 23 21:14:16 2011
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 24 Mar 2011 07:14:16 +1100
Subject: [R-sig-Geo] time-weighted kernel density interpolation
In-Reply-To: <C592CD29-9817-4F86-840A-1F9DC6542083@gmail.com>
References: <5C74B18A-5131-4979-94CF-1EDBE2C0C869@gmail.com>
	<AANLkTimDBFpOHuynO0HfGgNVNuE4yVd8ZxpbZNaKVAhN@mail.gmail.com>
	<C592CD29-9817-4F86-840A-1F9DC6542083@gmail.com>
Message-ID: <AANLkTikKMGh2giN0r1E1rM4UZ-rPVG8B+ohTJaja-Zyi@mail.gmail.com>

I'm not sure if anyone could give advice here without know more about
the data, but perhaps ?density.ppp or ?pixellate.ppp in spatstat would
be useful.

Cheers, Mike.

On Tue, Mar 22, 2011 at 4:05 PM,  <stepen.condors at gmail.com> wrote:
> Thanks for this Michael - I am investigating the trip library as we speak.
>
> Another (potentially stupid) query:
>
> I have a point pattern (as a ppp):
>
> test.ppp = ppp(test.eastings, test.northings, xrange=c(1000000, 2000000), yrange=c(1000000,2000000))
>
> I'd like to generate a grid over this area storing an associated intensity score with each grid cell - so that where points intersect that grid I can add some value to the intensity score of the cell they lie in (and surrounding ones ideally).
>
> What grid method would you recommend? ?and then how might you go about calculating the intersection of points and polygons?
>
> Many Thanks
> Stepen
>
>
> On 21/03/2011, at 6:46 AM, Michael Sumner wrote:
>
>> Hi Stepen,
>>
>> The function tripGrid in package trip does something similar to this
>> for the time interval between points ("time spent in area") - by using
>> spatstat's density function on the line segments. The KDE approach is
>> there for exploration though I think the straight grid approach is
>> usually better (neither method has any systematic handling for
>> location error).
>>
>> I've long meant to generalize the tripGrid function so that it's not
>> so tied to the time interval and the user could specify the
>> "weighting" - but that always brings up the issue of whether is is the
>> points or the implicit line segments between them that are of
>> interest.
>>
>> The density.ppp function in spatstat could be used to do this, though
>> I wonder what kind of result you are expecting from this method?
>>
>> Some of the approaches in adehabitat (and its new family of packages)
>> could be useful too.
>>
>> Cheers, Mike.
>>
>>
>>
>> On Mon, Mar 21, 2011 at 3:05 AM, ?<stepen.condors at gmail.com> wrote:
>>> Hi all
>>> I am currently looking into developing some sort of time-weighted kernel density interpolation in R. It is my aim to build something which allows me to the the following:
>>>
>>> - Import a point pattern p with associated times for each event
>>> - Plot a time weighted kernel density map of p - such that more recent events have a greater weighting than those that occurred earlier.
>>> - Ideally it would be useful to specify both the spatial and temporal bandwidths and the decay function types i.e. linear, exponential
>>> - Import new point data and assign an intensity score to each point from its location on time-weighted kernel density surface.
>>>
>>> Is this something that is relatively easily doable in R or am I crazy?
>>> I have developed something similar previously in both C++ and VB.NET (cough) interfacing directly with MapInfo so I am not afraid of code.
>>> However, as I am still relatively new to R I imagined that there were likely some better and worse ways to do this and/or libraries to look at. I have checked out the sp and spatstat libraries - but neither seem to have much to do with time, next i am considering trip. Where would you start? I would hate to waste time implementing something just because I was unaware of an existing solution.
>>>
>>> Therefore any advice, suggestions, experiences or abuse concerning how I might accomplish this functionality would be greatly appreciated.
>>>
>>> Best
>>> Stepen
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>
>>
>> --
>> Michael Sumner
>> Institute for Marine and Antarctic Studies, University of Tasmania
>> Hobart, Australia
>> e-mail: mdsumner at gmail.com
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


From r.turner at auckland.ac.nz  Wed Mar 23 21:33:27 2011
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 24 Mar 2011 09:33:27 +1300
Subject: [R-sig-Geo] Kernel density plot on a US map
In-Reply-To: <1300882849820-6199778.post@n2.nabble.com>
References: <1300801742922-6196265.post@n2.nabble.com>	<201103221105.07308.ashton@msu.edu>	<1300815984907-6197393.post@n2.nabble.com>
	<1300882849820-6199778.post@n2.nabble.com>
Message-ID: <4D8A5917.6010304@auckland.ac.nz>

On 24/03/11 01:20, vioravis wrote:
> After a few trials it appears that the cause of the errors is the points
> lying outside the specified window.
>
> 1. As a quick fix, I could remove the points (only a few) and do the
> analysis. How do I check whether a point lies within the window or not???
>

?inside.owin

     cheers,

         Rolf Turner


From John.Janmaat at ubc.ca  Thu Mar 24 05:09:59 2011
From: John.Janmaat at ubc.ca (Janmaat, John)
Date: Wed, 23 Mar 2011 21:09:59 -0700
Subject: [R-sig-Geo] Spatial Lag and Error Model
Message-ID: <C91442134EEFE4408AD950F07899435C1C982F@exchange22.mercury.ad.ubc.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110323/c70f78ae/attachment.pl>

From Roger.Bivand at nhh.no  Thu Mar 24 09:27:13 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 24 Mar 2011 09:27:13 +0100 (CET)
Subject: [R-sig-Geo] Spatial Lag and Error Model
In-Reply-To: <C91442134EEFE4408AD950F07899435C1C982F@exchange22.mercury.ad.ubc.ca>
References: <C91442134EEFE4408AD950F07899435C1C982F@exchange22.mercury.ad.ubc.ca>
Message-ID: <alpine.LRH.2.00.1103240913070.8949@reclus.nhh.no>

On Wed, 23 Mar 2011, Janmaat, John wrote:

> Hello,
>
>
>
> I have a city water use dataset with almost 12000 observations.  I am
> using spdep.  I am using K nearest neighbours (4) to build the neighbour
> list.  I am trying to estimate a model to predict household water use,
> controlling for a set of independent variables like lot size, house
> size, etc.  The spatial model diagnostics, lm.LMtests, suggests that
> there is both a spatial error and a spatial lag in the data.  However,
> on the lm estimations (lagsarlm,errorsarlm), report that the system is
> singular.  I can estimate the model using GMerrorsar and lagmess.
> However, gstsls exits with the same error as the lm estimations.
>
> Is there a function I am missing to estimate a model with both spatial
> autocorrelation and a spatial lagged dependent variable that won't have
> the singularity problem?
>

Well, what we are missing are the verbatim error messages and function 
calls. It may well be that your diagnosis of the problem is not precise 
enough, especially as the code used depends on your choice of input 
arguments. Does lm() of the same model report any unfitted coefficients 
(are there near-linear dependencies present in the X variables, or between 
X and WX)?

Roger

>
>
> Thanks,
>
>
>
> John.
>
>
>
> --------------------
>
> Dr. John Janmaat
>
> Department of Economics
>
> I.K. Barber School of Arts and Sciences
>
> University of British Columbia - Okanagan Campus
>
> 3333 University Way, Kelowna, BC
>
> V1V 1V7
>
> Tel: (250)807-8021
>
> WWW: http://people.ok.ubc.ca/jjanmaat/
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From hzambran.newsgroups at gmail.com  Thu Mar 24 11:25:01 2011
From: hzambran.newsgroups at gmail.com (Mauricio Zambrano)
Date: Thu, 24 Mar 2011 11:25:01 +0100
Subject: [R-sig-Geo] passing 'cutoff' to the 'autoKrige' function ('automap'
	package)
Message-ID: <AANLkTimrDC0LFNfoG7_VNohDs-NyEtrcd=R02Kmt5esd@mail.gmail.com>

Dear list,

Is there any way to pass the 'cutoff' argument (or 'width', or other
arguments of the 'variogram' function of the 'gstat' package)  to the
'autoKrige' function of the 'automap' package ?

I tried with:

> x.ok <- autoKrige(zinc~1, meuse, meuse.grid, miscFitOptions=list(maxdist=100, ?cutoff=500, width=50) )

but both arguments are ignored.


I also tried with:

> x.ok <- autoKrige(zinc~1, meuse, meuse.grid, maxdist=100, ?cutoff=500, width=100)

but I got the following error message:

"Error in gstat(formula = formula, data = locations, model = model,
beta = beta, ?:
?unused argument(s) (cutoff = 500, width = 50)"


Some session info:

R version 2.12.2 (2011-02-25)
automap_1.0-9
gstat_0.9-79


Here there is a reproducible example (for the 'autofitVariogram'
function, because I didn't find a way to pass the 'cutoff' and 'with'
arguments to the 'autoKrige' function):

------------ START ---------------

library(automap)

# Data preparation
data(meuse)
coordinates(meuse) =~ x+y
data(meuse.grid)
gridded(meuse.grid) =~ x+y

# Computing the 'boundaries' value for the 'variogram' function,
# in order to properly compare its results with those of the
'autofitVariogram' function

input_data <- meuse

x <- coordinates(input_data)[, 1]
y <- coordinates(input_data)[, 2]
scale_number <- (0.35 * sqrt((max(x) - min(x))^2 + (max(y) - min(y))^2)/100)
boundaries <- c(2, 4, 6, 9, 12, 15, 25, 35, 50, 65, 80, 100) * scale_number

# variogram computation. Case 1, default parameters
vgm.gstat   <- variogram(zinc ~ 1, locations=meuse, boundaries=boundaries)
vgm.automap <- autofitVariogram(zinc ~ 1, input_data=meuse)

# These variograms are the same
print(vgm.gstat)
print(vgm.automap$exp_var)

# variogram computation. Case 2, with 'cutoff' and 'width'
vgm.gstat2   <- variogram(zinc ~ 1, locations=meuse, cutoff=500, width=50)
vgm.automap2 <- autofitVariogram(zinc ~ 1, input_data=meuse,
cutoff=500, width=50)

# These variograms are NOT the same
print(vgm.gstat2)
print(vgm.automap2$exp_var)

# variogram computation. Case 3, with 'cutoff', 'width' and 'boundaries'
vgm.gstat3   <- variogram(zinc ~ 1, locations=meuse, cutoff=500,
width=50, boundaries=boundaries)
vgm.automap3 <- autofitVariogram(zinc ~ 1, input_data=meuse,
cutoff=500, width=50)

# These variograms are the same
print(vgm.gstat3)
print(vgm.automap3$exp_var)


------------ END ---------------


Looking at the examples, I think that the problem arises because the
'boundaries' argument superimpose its values to the 'cutoff' one, both
in the 'variogram' and 'autofitVariogram' functions.

However, whereas in the 'variogram' function the boundaries are
optional, in the 'autofitVariogram' they are computed internally (in a
smart way), but its maximum default value disable any shorter 'cutoff'
passed to the 'autofitVariogram' function.


In any case, I think that even after solving the issue related to
'cutoff' and 'boundaries', it will still be impossible to pass the
'cutoff' argument to the 'autoKrige' function, because the '...'
argument in 'autoKrige' is passed (internally) to the 'krige' function
and not to 'autofitVariogram' one. Am I right ?

I'm not sure if this could be considered a bug, but I thought it could
be useful to report this behaviour, for the next release of 'automap'.


Kind regards,

Mauricio Zambrano B.

--
================================
Linux user #454569 -- Ubuntu user #17469
================================


From alobolistas at gmail.com  Thu Mar 24 19:11:01 2011
From: alobolistas at gmail.com (Agustin Lobo)
Date: Thu, 24 Mar 2011 19:11:01 +0100
Subject: [R-sig-Geo] raster: extract is empty with polygon
Message-ID: <AANLkTikm7vqavOM7YNSRc2gX=t6qqBU9apzUn-52uPy3@mail.gmail.com>

Hi!
I'm trying to calculate the mean values for a set of polygons.
This is what I do:

require(raster)
require(rgdal)
#SGRGBWBPS125F40
#"read" tif file
SGRGBF40 = brick("/media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL/SGRGB/SGRGBWBPS125F40.tif")
> SGRGBF40
class       : RasterBrick
filename    : /media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL/SGRGB/SGRGBWBPS125F40.tif
nlayers     : 3
nrow        : 1760
ncol        : 2640
ncell       : 4646400
projection  : NA
min value   : 0 0 0
max value   : 65535 65535 65535
extent      : 0, 2640, 0, 1760  (xmin, xmax, ymin, ymax)
resolution  : 1, 1  (x, y)
> projection(SGRGBF40)
[1] "NA"

#read the shape file
calibf2 = readOGR(dsn="/media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL",layer="calibf2",stringsAsFactors=F)
> projection(calibf2)
[1] "+proj=utm +zone=31 +ellps=intl +units=m +no_defs"

> projection(SGRGBF40) = projection(calibf2)

But they do not overlap as shown by
> plot(subset(SGRGBF40,1))
> plot(calibf2,add=T)

and the extracted object is empty
#Calculate mean values for each polygon:
> v <- extract(SGRGBF40, calibf2,fun=mean,nl=3)
> summary(v)
      Length Class  Mode
 [1,] 0      -none- NULL
 [2,] 0      -none- NULL
 [3,] 0      -none- NULL
 [4,] 0      -none- NULL
 [5,] 0      -none- NULL
etc

> sessionInfo()
R version 2.12.2 (2011-02-25)
Platform: i486-pc-linux-gnu (32-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] rgdal_0.6-31 raster_1.7-8 sp_0.9-72

loaded via a namespace (and not attached):
[1] grid_2.12.2     lattice_0.19-17 tools_2.12.2


From alobolistas at gmail.com  Thu Mar 24 19:27:06 2011
From: alobolistas at gmail.com (Agustin Lobo)
Date: Thu, 24 Mar 2011 19:27:06 +0100
Subject: [R-sig-Geo] raster: extract is empty with polygon
In-Reply-To: <AANLkTikm7vqavOM7YNSRc2gX=t6qqBU9apzUn-52uPy3@mail.gmail.com>
References: <AANLkTikm7vqavOM7YNSRc2gX=t6qqBU9apzUn-52uPy3@mail.gmail.com>
Message-ID: <AANLkTin5trnbF8w+85RFfcAQZgn+77JvNsbM4xC8zaM+@mail.gmail.com>

I forgot to add that raster and vector do overlap in qgis (the vector
was actually digitized on top of the raster)
Agus

2011/3/24 Agustin Lobo <alobolistas at gmail.com>:
> Hi!
> I'm trying to calculate the mean values for a set of polygons.
> This is what I do:
>
> require(raster)
> require(rgdal)
> #SGRGBWBPS125F40
> #"read" tif file
> SGRGBF40 = brick("/media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL/SGRGB/SGRGBWBPS125F40.tif")
>> SGRGBF40
> class ? ? ? : RasterBrick
> filename ? ?: /media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL/SGRGB/SGRGBWBPS125F40.tif
> nlayers ? ? : 3
> nrow ? ? ? ?: 1760
> ncol ? ? ? ?: 2640
> ncell ? ? ? : 4646400
> projection ?: NA
> min value ? : 0 0 0
> max value ? : 65535 65535 65535
> extent ? ? ?: 0, 2640, 0, 1760 ?(xmin, xmax, ymin, ymax)
> resolution ?: 1, 1 ?(x, y)
>> projection(SGRGBF40)
> [1] "NA"
>
> #read the shape file
> calibf2 = readOGR(dsn="/media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL",layer="calibf2",stringsAsFactors=F)
>> projection(calibf2)
> [1] "+proj=utm +zone=31 +ellps=intl +units=m +no_defs"
>
>> projection(SGRGBF40) = projection(calibf2)
>
> But they do not overlap as shown by
>> plot(subset(SGRGBF40,1))
>> plot(calibf2,add=T)
>
> and the extracted object is empty
> #Calculate mean values for each polygon:
>> v <- extract(SGRGBF40, calibf2,fun=mean,nl=3)
>> summary(v)
> ? ? ?Length Class ?Mode
> ?[1,] 0 ? ? ?-none- NULL
> ?[2,] 0 ? ? ?-none- NULL
> ?[3,] 0 ? ? ?-none- NULL
> ?[4,] 0 ? ? ?-none- NULL
> ?[5,] 0 ? ? ?-none- NULL
> etc
>
>> sessionInfo()
> R version 2.12.2 (2011-02-25)
> Platform: i486-pc-linux-gnu (32-bit)
>
> locale:
> ?[1] LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C
> ?[3] LC_TIME=en_US.UTF-8 ? ? ? ?LC_COLLATE=en_US.UTF-8
> ?[5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_US.UTF-8
> ?[7] LC_PAPER=en_US.UTF-8 ? ? ? LC_NAME=C
> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] rgdal_0.6-31 raster_1.7-8 sp_0.9-72
>
> loaded via a namespace (and not attached):
> [1] grid_2.12.2 ? ? lattice_0.19-17 tools_2.12.2
>


From r.hijmans at gmail.com  Thu Mar 24 20:30:18 2011
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 24 Mar 2011 12:30:18 -0700
Subject: [R-sig-Geo] raster: extract is empty with polygon
In-Reply-To: <AANLkTin5trnbF8w+85RFfcAQZgn+77JvNsbM4xC8zaM+@mail.gmail.com>
References: <AANLkTikm7vqavOM7YNSRc2gX=t6qqBU9apzUn-52uPy3@mail.gmail.com>
	<AANLkTin5trnbF8w+85RFfcAQZgn+77JvNsbM4xC8zaM+@mail.gmail.com>
Message-ID: <AANLkTi=EK-JSyZFa47k4qmFkDmOR8SGpW40v5B_rxnLy@mail.gmail.com>

Hi Agus,

It would be useful to see

extent(calibf2)

Apparently it does not overlap with SGRGBF40  (see
intersectExtent(calibf2, SGRGBF40)  )
because the polys did not plot on top of the raster.

Perhaps QGIS does some on-the-fly projection trick or other such that
the coordinates from your on-screen digitization do match those of the
raster?

This will not fix that! :
> projection(SGRGBF40) = projection(calibf2)

You can perhaps compare with a polygon you draw in R on top of SGRGBF40

plot(SGRGBF40,1)
p <- drawPoly()
extract(SGRGBF40, p)

And save p and load into QGIS?

Best, Robert

( I would also update the raster package (but I do not think that
matters for this problem).


On Thu, Mar 24, 2011 at 11:27 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
> I forgot to add that raster and vector do overlap in qgis (the vector
> was actually digitized on top of the raster)
> Agus
>
> 2011/3/24 Agustin Lobo <alobolistas at gmail.com>:
>> Hi!
>> I'm trying to calculate the mean values for a set of polygons.
>> This is what I do:
>>
>> require(raster)
>> require(rgdal)
>> #SGRGBWBPS125F40
>> #"read" tif file
>> SGRGBF40 = brick("/media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL/SGRGB/SGRGBWBPS125F40.tif")
>>> SGRGBF40
>> class ? ? ? : RasterBrick
>> filename ? ?: /media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL/SGRGB/SGRGBWBPS125F40.tif
>> nlayers ? ? : 3
>> nrow ? ? ? ?: 1760
>> ncol ? ? ? ?: 2640
>> ncell ? ? ? : 4646400
>> projection ?: NA
>> min value ? : 0 0 0
>> max value ? : 65535 65535 65535
>> extent ? ? ?: 0, 2640, 0, 1760 ?(xmin, xmax, ymin, ymax)
>> resolution ?: 1, 1 ?(x, y)
>>> projection(SGRGBF40)
>> [1] "NA"
>>
>> #read the shape file
>> calibf2 = readOGR(dsn="/media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL",layer="calibf2",stringsAsFactors=F)
>>> projection(calibf2)
>> [1] "+proj=utm +zone=31 +ellps=intl +units=m +no_defs"
>>
>>> projection(SGRGBF40) = projection(calibf2)
>>
>> But they do not overlap as shown by
>>> plot(subset(SGRGBF40,1))
>>> plot(calibf2,add=T)
>>
>> and the extracted object is empty
>> #Calculate mean values for each polygon:
>>> v <- extract(SGRGBF40, calibf2,fun=mean,nl=3)
>>> summary(v)
>> ? ? ?Length Class ?Mode
>> ?[1,] 0 ? ? ?-none- NULL
>> ?[2,] 0 ? ? ?-none- NULL
>> ?[3,] 0 ? ? ?-none- NULL
>> ?[4,] 0 ? ? ?-none- NULL
>> ?[5,] 0 ? ? ?-none- NULL
>> etc
>>
>>> sessionInfo()
>> R version 2.12.2 (2011-02-25)
>> Platform: i486-pc-linux-gnu (32-bit)
>>
>> locale:
>> ?[1] LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C
>> ?[3] LC_TIME=en_US.UTF-8 ? ? ? ?LC_COLLATE=en_US.UTF-8
>> ?[5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_US.UTF-8
>> ?[7] LC_PAPER=en_US.UTF-8 ? ? ? LC_NAME=C
>> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> other attached packages:
>> [1] rgdal_0.6-31 raster_1.7-8 sp_0.9-72
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.12.2 ? ? lattice_0.19-17 tools_2.12.2
>>
>


From alobolistas at gmail.com  Thu Mar 24 20:56:36 2011
From: alobolistas at gmail.com (Agustin Lobo)
Date: Thu, 24 Mar 2011 20:56:36 +0100
Subject: [R-sig-Geo] raster: extract is empty with polygon
In-Reply-To: <AANLkTi=EK-JSyZFa47k4qmFkDmOR8SGpW40v5B_rxnLy@mail.gmail.com>
References: <AANLkTikm7vqavOM7YNSRc2gX=t6qqBU9apzUn-52uPy3@mail.gmail.com>
	<AANLkTin5trnbF8w+85RFfcAQZgn+77JvNsbM4xC8zaM+@mail.gmail.com>
	<AANLkTi=EK-JSyZFa47k4qmFkDmOR8SGpW40v5B_rxnLy@mail.gmail.com>
Message-ID: <AANLkTi=jTf7tOJ2=+yEEyBFu0N6C4MEVrM2MDPFh9hMO@mail.gmail.com>

Robert,

I have "reprojection on the fly" not activated. The raster
is an image from an standard camera, hence no projection.
The shapefile takes the projection from the project, but the
coordinates should be within the limits of the image, as it has been
digitized on top of the image. Thus I thought it was just a matter of
setting the CRS for the raster in R.

> intersectExtent(calibf2, SGRGBF40)
Error in intersectExtent(calibf2, SGRGBF40) : Invalid extent

which is in agreement with the rest of results, but still in
contradiction with what we see in QGIS

Agus

2011/3/24 Robert J. Hijmans <r.hijmans at gmail.com>:
> Hi Agus,
>
> It would be useful to see
>
> extent(calibf2)
>
> Apparently it does not overlap with SGRGBF40 ?(see
> intersectExtent(calibf2, SGRGBF40) ?)
> because the polys did not plot on top of the raster.
>
> Perhaps QGIS does some on-the-fly projection trick or other such that
> the coordinates from your on-screen digitization do match those of the
> raster?
>
> This will not fix that! :
>> projection(SGRGBF40) = projection(calibf2)
>
> You can perhaps compare with a polygon you draw in R on top of SGRGBF40
>
> plot(SGRGBF40,1)
> p <- drawPoly()
> extract(SGRGBF40, p)
>
> And save p and load into QGIS?
>
> Best, Robert
>
> ( I would also update the raster package (but I do not think that
> matters for this problem).
>
>
> On Thu, Mar 24, 2011 at 11:27 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
>> I forgot to add that raster and vector do overlap in qgis (the vector
>> was actually digitized on top of the raster)
>> Agus
>>
>> 2011/3/24 Agustin Lobo <alobolistas at gmail.com>:
>>> Hi!
>>> I'm trying to calculate the mean values for a set of polygons.
>>> This is what I do:
>>>
>>> require(raster)
>>> require(rgdal)
>>> #SGRGBWBPS125F40
>>> #"read" tif file
>>> SGRGBF40 = brick("/media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL/SGRGB/SGRGBWBPS125F40.tif")
>>>> SGRGBF40
>>> class ? ? ? : RasterBrick
>>> filename ? ?: /media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL/SGRGB/SGRGBWBPS125F40.tif
>>> nlayers ? ? : 3
>>> nrow ? ? ? ?: 1760
>>> ncol ? ? ? ?: 2640
>>> ncell ? ? ? : 4646400
>>> projection ?: NA
>>> min value ? : 0 0 0
>>> max value ? : 65535 65535 65535
>>> extent ? ? ?: 0, 2640, 0, 1760 ?(xmin, xmax, ymin, ymax)
>>> resolution ?: 1, 1 ?(x, y)
>>>> projection(SGRGBF40)
>>> [1] "NA"
>>>
>>> #read the shape file
>>> calibf2 = readOGR(dsn="/media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL",layer="calibf2",stringsAsFactors=F)
>>>> projection(calibf2)
>>> [1] "+proj=utm +zone=31 +ellps=intl +units=m +no_defs"
>>>
>>>> projection(SGRGBF40) = projection(calibf2)
>>>
>>> But they do not overlap as shown by
>>>> plot(subset(SGRGBF40,1))
>>>> plot(calibf2,add=T)
>>>
>>> and the extracted object is empty
>>> #Calculate mean values for each polygon:
>>>> v <- extract(SGRGBF40, calibf2,fun=mean,nl=3)
>>>> summary(v)
>>> ? ? ?Length Class ?Mode
>>> ?[1,] 0 ? ? ?-none- NULL
>>> ?[2,] 0 ? ? ?-none- NULL
>>> ?[3,] 0 ? ? ?-none- NULL
>>> ?[4,] 0 ? ? ?-none- NULL
>>> ?[5,] 0 ? ? ?-none- NULL
>>> etc
>>>
>>>> sessionInfo()
>>> R version 2.12.2 (2011-02-25)
>>> Platform: i486-pc-linux-gnu (32-bit)
>>>
>>> locale:
>>> ?[1] LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C
>>> ?[3] LC_TIME=en_US.UTF-8 ? ? ? ?LC_COLLATE=en_US.UTF-8
>>> ?[5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_US.UTF-8
>>> ?[7] LC_PAPER=en_US.UTF-8 ? ? ? LC_NAME=C
>>> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>>
>>> other attached packages:
>>> [1] rgdal_0.6-31 raster_1.7-8 sp_0.9-72
>>>
>>> loaded via a namespace (and not attached):
>>> [1] grid_2.12.2 ? ? lattice_0.19-17 tools_2.12.2
>>>
>>
>


From r.hijmans at gmail.com  Thu Mar 24 21:08:31 2011
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 24 Mar 2011 13:08:31 -0700
Subject: [R-sig-Geo] raster: extract is empty with polygon
In-Reply-To: <AANLkTi=jTf7tOJ2=+yEEyBFu0N6C4MEVrM2MDPFh9hMO@mail.gmail.com>
References: <AANLkTikm7vqavOM7YNSRc2gX=t6qqBU9apzUn-52uPy3@mail.gmail.com>
	<AANLkTin5trnbF8w+85RFfcAQZgn+77JvNsbM4xC8zaM+@mail.gmail.com>
	<AANLkTi=EK-JSyZFa47k4qmFkDmOR8SGpW40v5B_rxnLy@mail.gmail.com>
	<AANLkTi=jTf7tOJ2=+yEEyBFu0N6C4MEVrM2MDPFh9hMO@mail.gmail.com>
Message-ID: <AANLkTin8Gv38Jv3kJMfGFe4GQA-esCvZX=mn6k=A80zo@mail.gmail.com>

Agus,

If this is from a standard camera, perhaps the problem is that there
is no associated georeference, and different programs may come up with
a different solution to put them somewhere on the map.
R (via gdal) does this: 0, 2640, 0, 1760 (xmin, xmax, ymin, ymax),
with resolution 1 (cell). What does QGIS do?
Perhaps you need to first save it to a geotiff, or add a (fake
coordinates) "world file" so that the treatment becomes consistent.

What is extent(calibf2) ?

Robert

On Thu, Mar 24, 2011 at 12:56 PM, Agustin Lobo <alobolistas at gmail.com> wrote:
> Robert,
>
> I have "reprojection on the fly" not activated. The raster
> is an image from an standard camera, hence no projection.
> The shapefile takes the projection from the project, but the
> coordinates should be within the limits of the image, as it has been
> digitized on top of the image. Thus I thought it was just a matter of
> setting the CRS for the raster in R.
>
>> intersectExtent(calibf2, SGRGBF40)
> Error in intersectExtent(calibf2, SGRGBF40) : Invalid extent
>
> which is in agreement with the rest of results, but still in
> contradiction with what we see in QGIS
>
> Agus
>
> 2011/3/24 Robert J. Hijmans <r.hijmans at gmail.com>:
>> Hi Agus,
>>
>> It would be useful to see
>>
>> extent(calibf2)
>>
>> Apparently it does not overlap with SGRGBF40 ?(see
>> intersectExtent(calibf2, SGRGBF40) ?)
>> because the polys did not plot on top of the raster.
>>
>> Perhaps QGIS does some on-the-fly projection trick or other such that
>> the coordinates from your on-screen digitization do match those of the
>> raster?
>>
>> This will not fix that! :
>>> projection(SGRGBF40) = projection(calibf2)
>>
>> You can perhaps compare with a polygon you draw in R on top of SGRGBF40
>>
>> plot(SGRGBF40,1)
>> p <- drawPoly()
>> extract(SGRGBF40, p)
>>
>> And save p and load into QGIS?
>>
>> Best, Robert
>>
>> ( I would also update the raster package (but I do not think that
>> matters for this problem).
>>
>>
>> On Thu, Mar 24, 2011 at 11:27 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
>>> I forgot to add that raster and vector do overlap in qgis (the vector
>>> was actually digitized on top of the raster)
>>> Agus
>>>
>>> 2011/3/24 Agustin Lobo <alobolistas at gmail.com>:
>>>> Hi!
>>>> I'm trying to calculate the mean values for a set of polygons.
>>>> This is what I do:
>>>>
>>>> require(raster)
>>>> require(rgdal)
>>>> #SGRGBWBPS125F40
>>>> #"read" tif file
>>>> SGRGBF40 = brick("/media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL/SGRGB/SGRGBWBPS125F40.tif")
>>>>> SGRGBF40
>>>> class ? ? ? : RasterBrick
>>>> filename ? ?: /media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL/SGRGB/SGRGBWBPS125F40.tif
>>>> nlayers ? ? : 3
>>>> nrow ? ? ? ?: 1760
>>>> ncol ? ? ? ?: 2640
>>>> ncell ? ? ? : 4646400
>>>> projection ?: NA
>>>> min value ? : 0 0 0
>>>> max value ? : 65535 65535 65535
>>>> extent ? ? ?: 0, 2640, 0, 1760 ?(xmin, xmax, ymin, ymax)
>>>> resolution ?: 1, 1 ?(x, y)
>>>>> projection(SGRGBF40)
>>>> [1] "NA"
>>>>
>>>> #read the shape file
>>>> calibf2 = readOGR(dsn="/media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL",layer="calibf2",stringsAsFactors=F)
>>>>> projection(calibf2)
>>>> [1] "+proj=utm +zone=31 +ellps=intl +units=m +no_defs"
>>>>
>>>>> projection(SGRGBF40) = projection(calibf2)
>>>>
>>>> But they do not overlap as shown by
>>>>> plot(subset(SGRGBF40,1))
>>>>> plot(calibf2,add=T)
>>>>
>>>> and the extracted object is empty
>>>> #Calculate mean values for each polygon:
>>>>> v <- extract(SGRGBF40, calibf2,fun=mean,nl=3)
>>>>> summary(v)
>>>> ? ? ?Length Class ?Mode
>>>> ?[1,] 0 ? ? ?-none- NULL
>>>> ?[2,] 0 ? ? ?-none- NULL
>>>> ?[3,] 0 ? ? ?-none- NULL
>>>> ?[4,] 0 ? ? ?-none- NULL
>>>> ?[5,] 0 ? ? ?-none- NULL
>>>> etc
>>>>
>>>>> sessionInfo()
>>>> R version 2.12.2 (2011-02-25)
>>>> Platform: i486-pc-linux-gnu (32-bit)
>>>>
>>>> locale:
>>>> ?[1] LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C
>>>> ?[3] LC_TIME=en_US.UTF-8 ? ? ? ?LC_COLLATE=en_US.UTF-8
>>>> ?[5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_US.UTF-8
>>>> ?[7] LC_PAPER=en_US.UTF-8 ? ? ? LC_NAME=C
>>>> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
>>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>>
>>>> attached base packages:
>>>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>>>
>>>> other attached packages:
>>>> [1] rgdal_0.6-31 raster_1.7-8 sp_0.9-72
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] grid_2.12.2 ? ? lattice_0.19-17 tools_2.12.2
>>>>
>>>
>>
>


From John.Janmaat at ubc.ca  Fri Mar 25 02:51:02 2011
From: John.Janmaat at ubc.ca (Janmaat, John)
Date: Thu, 24 Mar 2011 18:51:02 -0700
Subject: [R-sig-Geo] Spatial Lag and Error Model
In-Reply-To: <C91442134EEFE4408AD950F07899435C1C9832@exchange22.mercury.ad.ubc.ca>
References: <C91442134EEFE4408AD950F07899435C1C982F@exchange22.mercury.ad.ubc.ca>
	<alpine.LRH.2.00.1103240913070.8949@reclus.nhh.no>
	<C91442134EEFE4408AD950F07899435C1C9832@exchange22.mercury.ad.ubc.ca>
Message-ID: <C91442134EEFE4408AD950F07899435C1C9834@exchange22.mercury.ad.ubc.ca>



-----Original Message-----
From: Janmaat, John 
Sent: Thursday, March 24, 2011 3:40 PM
To: 'Roger.Bivand at nhh.no'
Subject: RE: [R-sig-Geo] Spatial Lag and Error Model

Hello Roger,

Thanks for your reply.

A code snippet:

nl <- knearneigh(cbind(wd2$Long,wd2$Lat),k=4)
nb <- knn2nb(nl)
weightings <- nb2listw(nb)
wd.GMerrorsarSum <- gstsls(frmWin, data=wd2,weightings)

The error message:

Error in solve.default(QQ, Qye) : 
  system is computationally singular: reciprocal condition number =
4.20784e-28

There are 10,996 observations.

The dataset has been processed to remove any overlapping points (no zero
distances) and to remove points that do not have at least one neighbour
within 100m.  Overlapping points existed as accounts would change when a
resident moved, leading to multiple observations for a single lot.  This
is what I originally thought could be the issue, as there are then zero
distances.  It has also had all observations with NA removed.  The model
represented in frmWin is solved fine by lm(), with no variables dropped.

I'm not sure how to check for near linear dependence in WX though, so I
would appreciate it if you could direct me there.

I am using k nearest neighbours, as opposed to rook or queen as my data
has lat and long for the lot centroid, as opposed to a polygon for each
lot.

There are some natural boundaries within the data, such that it can be
divided into subsets where within each subset the neighbour list for the
observations in the subset is no different from that generated for the
whole dataset.  I have also done an analysis separately for such
subsets, with the same result.

Thanks in advance for any suggestions.

John.

-----Original Message-----
From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Sent: Thursday, March 24, 2011 1:27 AM
To: Janmaat, John
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] Spatial Lag and Error Model

On Wed, 23 Mar 2011, Janmaat, John wrote:

> Hello,
>
>
>
> I have a city water use dataset with almost 12000 observations.  I am
> using spdep.  I am using K nearest neighbours (4) to build the
neighbour
> list.  I am trying to estimate a model to predict household water use,
> controlling for a set of independent variables like lot size, house
> size, etc.  The spatial model diagnostics, lm.LMtests, suggests that
> there is both a spatial error and a spatial lag in the data.  However,
> on the lm estimations (lagsarlm,errorsarlm), report that the system is
> singular.  I can estimate the model using GMerrorsar and lagmess.
> However, gstsls exits with the same error as the lm estimations.
>
> Is there a function I am missing to estimate a model with both spatial
> autocorrelation and a spatial lagged dependent variable that won't
have
> the singularity problem?
>

Well, what we are missing are the verbatim error messages and function 
calls. It may well be that your diagnosis of the problem is not precise 
enough, especially as the code used depends on your choice of input 
arguments. Does lm() of the same model report any unfitted coefficients 
(are there near-linear dependencies present in the X variables, or
between 
X and WX)?

Roger

>
>
> Thanks,
>
>
>
> John.
>
>
>
> --------------------
>
> Dr. John Janmaat
>
> Department of Economics
>
> I.K. Barber School of Arts and Sciences
>
> University of British Columbia - Okanagan Campus
>
> 3333 University Way, Kelowna, BC
>
> V1V 1V7
>
> Tel: (250)807-8021
>
> WWW: http://people.ok.ubc.ca/jjanmaat/
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From stepen.condors at gmail.com  Fri Mar 25 08:05:14 2011
From: stepen.condors at gmail.com (stepen.condors at gmail.com)
Date: Fri, 25 Mar 2011 17:05:14 +1000
Subject: [R-sig-Geo] time-weighted kernel density interpolation
In-Reply-To: <AANLkTikKMGh2giN0r1E1rM4UZ-rPVG8B+ohTJaja-Zyi@mail.gmail.com>
References: <5C74B18A-5131-4979-94CF-1EDBE2C0C869@gmail.com>
	<AANLkTimDBFpOHuynO0HfGgNVNuE4yVd8ZxpbZNaKVAhN@mail.gmail.com>
	<C592CD29-9817-4F86-840A-1F9DC6542083@gmail.com>
	<AANLkTikKMGh2giN0r1E1rM4UZ-rPVG8B+ohTJaja-Zyi@mail.gmail.com>
Message-ID: <4DEF61BB-C294-43C8-A1A7-D27802076423@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110325/c67a65c6/attachment.pl>

From hzambran.newsgroups at gmail.com  Fri Mar 25 08:57:57 2011
From: hzambran.newsgroups at gmail.com (Mauricio Zambrano)
Date: Fri, 25 Mar 2011 08:57:57 +0100
Subject: [R-sig-Geo] passing 'cutoff' to the 'autoKrige' function ('automap'
	package)
Message-ID: <AANLkTimzzQ5EKzQyGe_SKYnkeRx1F8Kez-KBnbiE_kbP@mail.gmail.com>

Dear list,

Is there any way to pass the 'cutoff' argument (or 'width', or other
arguments of the 'variogram' function of the 'gstat' package)  to the
'autoKrige' function of the 'automap' package ?

I tried with:

> x.ok <- autoKrige(zinc~1, meuse, meuse.grid, miscFitOptions=list(maxdist=100,  cutoff=500, width=50) )

but both arguments are ignored.


I also tried with:

> x.ok <- autoKrige(zinc~1, meuse, meuse.grid, maxdist=100,  cutoff=500, width=100)

but I got the following error message:

"Error in gstat(formula = formula, data = locations, model = model,
beta = beta,  :
 unused argument(s) (cutoff = 500, width = 50)"


Some session info:

R version 2.12.2 (2011-02-25)
automap_1.0-9
gstat_0.9-79


Here there is a reproducible example (for the 'autofitVariogram'
function, because I didn't find a way to pass the 'cutoff' and 'with'
arguments to the 'autoKrige' function):

------------ START ---------------

library(automap)

# Data preparation
data(meuse)
coordinates(meuse) =~ x+y
data(meuse.grid)
gridded(meuse.grid) =~ x+y

# Computing the 'boundaries' value for the 'variogram' function,
# in order to properly compare its results with those of the
'autofitVariogram' function

input_data <- meuse

x <- coordinates(input_data)[, 1]
y <- coordinates(input_data)[, 2]
scale_number <- (0.35 * sqrt((max(x) - min(x))^2 + (max(y) - min(y))^2)/100)
boundaries <- c(2, 4, 6, 9, 12, 15, 25, 35, 50, 65, 80, 100) * scale_number

# variogram computation. Case 1, default parameters
vgm.gstat   <- variogram(zinc ~ 1, locations=meuse, boundaries=boundaries)
vgm.automap <- autofitVariogram(zinc ~ 1, input_data=meuse)

# These variograms are the same
print(vgm.gstat)
print(vgm.automap$exp_var)

# variogram computation. Case 2, with 'cutoff' and 'width'
vgm.gstat2   <- variogram(zinc ~ 1, locations=meuse, cutoff=500, width=50)
vgm.automap2 <- autofitVariogram(zinc ~ 1, input_data=meuse,
cutoff=500, width=50)

# These variograms are NOT the same
print(vgm.gstat2)
print(vgm.automap2$exp_var)

# variogram computation. Case 3, with 'cutoff', 'width' and 'boundaries'
vgm.gstat3   <- variogram(zinc ~ 1, locations=meuse, cutoff=500,
width=50, boundaries=boundaries)
vgm.automap3 <- autofitVariogram(zinc ~ 1, input_data=meuse,
cutoff=500, width=50)

# These variograms are the same
print(vgm.gstat3)
print(vgm.automap3$exp_var)


------------ END ---------------


Looking at the examples, I think that the problem arises because the
'boundaries' argument superimpose its values to the 'cutoff' one, both
in the 'variogram' and 'autofitVariogram' functions.

However, whereas in the 'variogram' function the boundaries are
optional, in the 'autofitVariogram' they are computed internally (in a
smart way), but its maximum default value disable any shorter 'cutoff'
passed to the 'autofitVariogram' function.


In any case, I think that even after solving the issue related to
'cutoff' and 'boundaries', it will still be impossible to pass the
'cutoff' argument to the 'autoKrige' function, because the '...'
argument in 'autoKrige' is passed (internally) to the 'krige' function
and not to 'autofitVariogram' one. Am I right ?

I'm not sure if this could be considered a bug, but I thought it could
be useful to report this behaviour, for the next release of 'automap'.


Kind regards,

Mauricio Zambrano B.


-- 
================================
Linux user #454569 -- Ubuntu user #17469


From alobolistas at gmail.com  Fri Mar 25 10:24:34 2011
From: alobolistas at gmail.com (Agustin Lobo)
Date: Fri, 25 Mar 2011 10:24:34 +0100
Subject: [R-sig-Geo] Fwd: raster: extract is empty with polygon
In-Reply-To: <AANLkTineP+QS7TGU2_eG8T4p1N8z8w1t4tf2EmAGrzy2@mail.gmail.com>
References: <AANLkTikm7vqavOM7YNSRc2gX=t6qqBU9apzUn-52uPy3@mail.gmail.com>
	<AANLkTin5trnbF8w+85RFfcAQZgn+77JvNsbM4xC8zaM+@mail.gmail.com>
	<AANLkTi=EK-JSyZFa47k4qmFkDmOR8SGpW40v5B_rxnLy@mail.gmail.com>
	<AANLkTi=jTf7tOJ2=+yEEyBFu0N6C4MEVrM2MDPFh9hMO@mail.gmail.com>
	<AANLkTin8Gv38Jv3kJMfGFe4GQA-esCvZX=mn6k=A80zo@mail.gmail.com>
	<AANLkTineP+QS7TGU2_eG8T4p1N8z8w1t4tf2EmAGrzy2@mail.gmail.com>
Message-ID: <AANLkTimdCBga2KYeMmgv3_QfqD0HZ_duRboAmpLOb2-X@mail.gmail.com>

But then this is not as in gdal. Gdalinfo states that the bottom left is 0,1760
while R states 0,0
Should not raster do as gdal?

Corner Coordinates:
Upper Left ?( ? ?0.0, ? ?0.0)
Lower Left ?( ? ?0.0, 1760.0)
Upper Right ( 2640.0, ? ?0.0)
Lower Right ( 2640.0, 1760.0)
Center ? ? ?( 1320.0, ?880.0)
Band 1 Block=2640x1 Type=UInt16, ColorInterp=Red
Band 2 Block=2640x1 Type=UInt16, ColorInterp=Green
Band 3 Block=2640x1 Type=UInt16, ColorInterp=Blue

Agus

2011/3/24 Robert J. Hijmans <r.hijmans at gmail.com>:
> Agus,
>
> If this is from a standard camera, perhaps the problem is that there
> is no associated georeference, and different programs may come up with
> a different solution to put them somewhere on the map.
> R (via gdal) does this: 0, 2640, 0, 1760 (xmin, xmax, ymin, ymax),
> with resolution 1 (cell). What does QGIS do?
> Perhaps you need to first save it to a geotiff, or add a (fake
> coordinates) "world file" so that the treatment becomes consistent.
>
> What is extent(calibf2) ?
>
> Robert
>
> On Thu, Mar 24, 2011 at 12:56 PM, Agustin Lobo <alobolistas at gmail.com> wrote:
>> Robert,
>>
>> I have "reprojection on the fly" not activated. The raster
>> is an image from an standard camera, hence no projection.
>> The shapefile takes the projection from the project, but the
>> coordinates should be within the limits of the image, as it has been
>> digitized on top of the image. Thus I thought it was just a matter of
>> setting the CRS for the raster in R.
>>
>>> intersectExtent(calibf2, SGRGBF40)
>> Error in intersectExtent(calibf2, SGRGBF40) : Invalid extent
>>
>> which is in agreement with the rest of results, but still in
>> contradiction with what we see in QGIS
>>
>> Agus
>>
>> 2011/3/24 Robert J. Hijmans <r.hijmans at gmail.com>:
>>> Hi Agus,
>>>
>>> It would be useful to see
>>>
>>> extent(calibf2)
>>>
>>> Apparently it does not overlap with SGRGBF40 ?(see
>>> intersectExtent(calibf2, SGRGBF40) ?)
>>> because the polys did not plot on top of the raster.
>>>
>>> Perhaps QGIS does some on-the-fly projection trick or other such that
>>> the coordinates from your on-screen digitization do match those of the
>>> raster?
>>>
>>> This will not fix that! :
>>>> projection(SGRGBF40) = projection(calibf2)
>>>
>>> You can perhaps compare with a polygon you draw in R on top of SGRGBF40
>>>
>>> plot(SGRGBF40,1)
>>> p <- drawPoly()
>>> extract(SGRGBF40, p)
>>>
>>> And save p and load into QGIS?
>>>
>>> Best, Robert
>>>
>>> ( I would also update the raster package (but I do not think that
>>> matters for this problem).
>>>
>>>
>>> On Thu, Mar 24, 2011 at 11:27 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
>>>> I forgot to add that raster and vector do overlap in qgis (the vector
>>>> was actually digitized on top of the raster)
>>>> Agus
>>>>
>>>> 2011/3/24 Agustin Lobo <alobolistas at gmail.com>:
>>>>> Hi!
>>>>> I'm trying to calculate the mean values for a set of polygons.
>>>>> This is what I do:
>>>>>
>>>>> require(raster)
>>>>> require(rgdal)
>>>>> #SGRGBWBPS125F40
>>>>> #"read" tif file
>>>>> SGRGBF40 = brick("/media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL/SGRGB/SGRGBWBPS125F40.tif")
>>>>>> SGRGBF40
>>>>> class ? ? ? : RasterBrick
>>>>> filename ? ?: /media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL/SGRGB/SGRGBWBPS125F40.tif
>>>>> nlayers ? ? : 3
>>>>> nrow ? ? ? ?: 1760
>>>>> ncol ? ? ? ?: 2640
>>>>> ncell ? ? ? : 4646400
>>>>> projection ?: NA
>>>>> min value ? : 0 0 0
>>>>> max value ? : 65535 65535 65535
>>>>> extent ? ? ?: 0, 2640, 0, 1760 ?(xmin, xmax, ymin, ymax)
>>>>> resolution ?: 1, 1 ?(x, y)
>>>>>> projection(SGRGBF40)
>>>>> [1] "NA"
>>>>>
>>>>> #read the shape file
>>>>> calibf2 = readOGR(dsn="/media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL",layer="calibf2",stringsAsFactors=F)
>>>>>> projection(calibf2)
>>>>> [1] "+proj=utm +zone=31 +ellps=intl +units=m +no_defs"
>>>>>
>>>>>> projection(SGRGBF40) = projection(calibf2)
>>>>>
>>>>> But they do not overlap as shown by
>>>>>> plot(subset(SGRGBF40,1))
>>>>>> plot(calibf2,add=T)
>>>>>
>>>>> and the extracted object is empty
>>>>> #Calculate mean values for each polygon:
>>>>>> v <- extract(SGRGBF40, calibf2,fun=mean,nl=3)
>>>>>> summary(v)
>>>>> ? ? ?Length Class ?Mode
>>>>> ?[1,] 0 ? ? ?-none- NULL
>>>>> ?[2,] 0 ? ? ?-none- NULL
>>>>> ?[3,] 0 ? ? ?-none- NULL
>>>>> ?[4,] 0 ? ? ?-none- NULL
>>>>> ?[5,] 0 ? ? ?-none- NULL
>>>>> etc
>>>>>
>>>>>> sessionInfo()
>>>>> R version 2.12.2 (2011-02-25)
>>>>> Platform: i486-pc-linux-gnu (32-bit)
>>>>>
>>>>> locale:
>>>>> ?[1] LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C
>>>>> ?[3] LC_TIME=en_US.UTF-8 ? ? ? ?LC_COLLATE=en_US.UTF-8
>>>>> ?[5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_US.UTF-8
>>>>> ?[7] LC_PAPER=en_US.UTF-8 ? ? ? LC_NAME=C
>>>>> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
>>>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>>>
>>>>> attached base packages:
>>>>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>>>>
>>>>> other attached packages:
>>>>> [1] rgdal_0.6-31 raster_1.7-8 sp_0.9-72
>>>>>
>>>>> loaded via a namespace (and not attached):
>>>>> [1] grid_2.12.2 ? ? lattice_0.19-17 tools_2.12.2
>>>>>
>>>>
>>>
>>
>


From clement.calenge at oncfs.gouv.fr  Fri Mar 25 10:59:06 2011
From: clement.calenge at oncfs.gouv.fr (=?ISO-8859-1?Q?Cl=E9ment_Calenge?=)
Date: Fri, 25 Mar 2011 10:59:06 +0100
Subject: [R-sig-Geo] time-weighted kernel density interpolation
In-Reply-To: <4DEF61BB-C294-43C8-A1A7-D27802076423@gmail.com>
References: <5C74B18A-5131-4979-94CF-1EDBE2C0C869@gmail.com>	<AANLkTimDBFpOHuynO0HfGgNVNuE4yVd8ZxpbZNaKVAhN@mail.gmail.com>	<C592CD29-9817-4F86-840A-1F9DC6542083@gmail.com>	<AANLkTikKMGh2giN0r1E1rM4UZ-rPVG8B+ohTJaja-Zyi@mail.gmail.com>
	<4DEF61BB-C294-43C8-A1A7-D27802076423@gmail.com>
Message-ID: <4D8C676A.7040209@oncfs.gouv.fr>

I am not sure, but wouldn't the function kernelkcbase from the package 
adehabitatHR fit your needs? it implements the product kernel estimator 
over space and time. It estimates, for a given date, the kernel density 
of the points, the point weights depending on their associated dates 
(see examples of this function). This approach is developed in detail 
pages p. 91 and pp. 103 and following in;

@BOOK{Wand1995,
   title = {Kernel smoothing},
   publisher = {Chapman \& Hall/CRC},
   year = {1995},
   author = {Wand, M.P. and Jones, M.C.}
}

Has been introduced in ecology for the smoothing of space utilization by 
animals by:

@ARTICLE{Keating2009,
   author = {Keating, K.A. and Cherry, S.},
   title = {Modeling utilization distributions in space and time},
   journal = {Ecology},
   year = {2009},
   volume = {90},
   pages = {1971-1980}
}

And has been used for the modelling of ring recoveries by:

@ARTICLE{Calenge2010,
   author = {Calenge, C. and Guillemain, M. and Gauthier-Clerc, M. and 
Simon,
     G.},
   title = {{A new exploratory approach to the study of the 
spatio-temporal distribution
     of ring recoveries: the example of Teal (Anas crecca) ringed in 
Camargue,
     Southern France}},
   journal = {Journal of Ornithology},
   year = {2010},
   pages = {1--6}
}

HTH,

Cl?ment Calenge


On 03/25/2011 08:05 AM, stepen.condors at gmail.com wrote:
> OK Michael I will attempt o explain my requirements a little more thoroughly and some the options I have started to explore.
> I begin by outlining what I would like to do at a functional level.
>
> 1. I have a set of observations each with an  associated x&  y co-ordinates and an age in days - i.e. this observation was made at this point 3 days ago etc.
> 2. I want to create a grid over the area in which the points are found. Each cell of this grid has an associated z-score.
> 3. I now step through the point set and for each point find which grid cell it lies in and then add some value to the z-score of that cell and other cells within a finite distance of the origin cell. These intensity scores are based on the age of the observation and the distance of the grid cell from the point  and are looked up from some other data structure such as a matrix. i.e.
> 		Space
> Age-days 	0-100 	100-200	300-400 	400+
> 0-1		0.8		0.7		0.6		0.5
> 2-3		0.6		0.5		0.4		0.3
> 4+		0.4		0.3		0.2		0.1
>
> Thus, an observation that occurred today might add a z-score of 0.8 to the z of grid cell in which it lies - 0.7 to those within 100-200, 0.6 to those with 300-400 and so on. On the other hand an observation that is 5 days old only adds 0.4 to the cell in which it lies, 0.3 to those within 100-200 etc etc.
>
> It is important that this z-score per grid cell is cumulative so that if multiple points are near one another some grid cells might have numerous values added to their z score.
>
> Describing the above in pseudo code:
>
> points = (x,y,age)
> grid = makegrid(nrows,ncolumns)
>
> for point in points
> {
> 	for cell in grid
> 	{
> 		if point iswithin cell
> 		{
> 			z of cell = z of cell + matrix[point.age,1]
> 			
> 			for nearcell within 100-200m of cell
> 			{
> 				z of nearcell = z of nearcell + matrix[point.age,2]
> 			}	
>
> 			for nearcell within 200-300m of cell
> 			{
> 				z of nearcell = z of nearcell + matrix[point.age,3]
> 			}					
> 			
> 			for nearcell within 300-400m of cell
> 			{
> 				z of nearcell = z of nearcell + matrix[point.age,4]
> 			}
> 		}
> 	}
> }		
>
> On paper this doesn't seem overly complicated, but I am struggling to find the right libraries to do it efficiently.
>
>
> I have attempted a few different methods - but unfortunately I seem to be hitting brick walls.
> I will list a few options I have investigated below:
>
> THE POINTS:
> say for example then my data set is made up as follows:
> 	
> 	xs = sample(1:1000, 100, replace = TRUE)
> 	ys = sample(1:1000, 100, replace = TRUE)
> 	age = sample(1:30,100, replace = TRUE)
>
> I can then generate a ppp as follows:
>
> 	test.ppp = ppp(xs, ys, xrange=c(1,1000), yrange=c(1,1000))
>
> However this only associates the x,y co-eds with points and not the age
> - maybe I can use age as the mark variable as follows:
> 	
> 	test.ppp = ppp(xs, ys, marks = age, xrange=c(1,1000), yrange=c(1,1000))
>
> However, this only seems to impact on the visual display of data.
>
> Perhaps I am better creating a simple object as follows
> 	
> 	observations<- cbind(xs,ys,age)
>
> But then this has no spatial data associated with it
>
> THE GRID:
> In making the grid I can do several things:
> Using pixellate I can count the number of observations in a grid I specify the size of as follows (100x100 grid cells)
>
> 	Z<- pixellate(test.ppp, eps=100)
>
> I can then convert the grid to a data.frame and view it:
> 	
> 	>  as.data.frame(Z)
>        	x     y 	     value
> 	1    50  50      0
> 	2    50 150     3
> 	3    50 250     0
> 	4    50 350     2
>
> However, the points are already aggregated as counts and I need to know the age of each in order to calculate a z-score for each grid. I.e. grid cell 2 has three points in it I need the age of each.
>
> An alternative seems to be to create a bunch of polygon objects for each grid cell as follows (10x10 grid cells in this example):
>
>      	for(x in 0:100)
>          	{
>              	for(y in 0:100)
>                  	{
>                      	cellX = (x * 10)
>                      	cellY = (y * 10)
>                      	grid_cell_dim = cbind(x=c(cellX,(cellX+10),(cellX+10),cellX),y=c((cellY+10),(cellY+10),cellY,cellY))
>                      	polygon(grid_cell_dim)
>
>                  	}
>          	}
>
> Once I have created these polygons I am unsure how I can access them or associate a z-score with each. When I messed about twith SpatialPolygonsDataFrame it keeps telling me 'ring not closed'.
>
>
> Apologies for the long-winded message - but as you can see I am struggling to find the best course of action to do what seems a relatively simple task. Therefore, any advice would be greatly appreciated - are any of these options viable? is there a much simpler solution?
>
> Best Regards
> Stepen
>
>
> On 24/03/2011, at 6:14 AM, Michael Sumner wrote:
>
>> I'm not sure if anyone could give advice here without know more about
>> the data, but perhaps ?density.ppp or ?pixellate.ppp in spatstat would
>> be useful.
>>
>> Cheers, Mike.
>>
>> On Tue, Mar 22, 2011 at 4:05 PM,<stepen.condors at gmail.com>  wrote:
>>> Thanks for this Michael - I am investigating the trip library as we speak.
>>>
>>> Another (potentially stupid) query:
>>>
>>> I have a point pattern (as a ppp):
>>>
>>> test.ppp = ppp(test.eastings, test.northings, xrange=c(1000000, 2000000), yrange=c(1000000,2000000))
>>>
>>> I'd like to generate a grid over this area storing an associated intensity score with each grid cell - so that where points intersect that grid I can add some value to the intensity score of the cell they lie in (and surrounding ones ideally).
>>>
>>> What grid method would you recommend?  and then how might you go about calculating the intersection of points and polygons?
>>>
>>> Many Thanks
>>> Stepen
>>>
>>>
>>> On 21/03/2011, at 6:46 AM, Michael Sumner wrote:
>>>
>>>> Hi Stepen,
>>>>
>>>> The function tripGrid in package trip does something similar to this
>>>> for the time interval between points ("time spent in area") - by using
>>>> spatstat's density function on the line segments. The KDE approach is
>>>> there for exploration though I think the straight grid approach is
>>>> usually better (neither method has any systematic handling for
>>>> location error).
>>>>
>>>> I've long meant to generalize the tripGrid function so that it's not
>>>> so tied to the time interval and the user could specify the
>>>> "weighting" - but that always brings up the issue of whether is is the
>>>> points or the implicit line segments between them that are of
>>>> interest.
>>>>
>>>> The density.ppp function in spatstat could be used to do this, though
>>>> I wonder what kind of result you are expecting from this method?
>>>>
>>>> Some of the approaches in adehabitat (and its new family of packages)
>>>> could be useful too.
>>>>
>>>> Cheers, Mike.
>>>>
>>>>
>>>>
>>>> On Mon, Mar 21, 2011 at 3:05 AM,<stepen.condors at gmail.com>  wrote:
>>>>> Hi all
>>>>> I am currently looking into developing some sort of time-weighted kernel density interpolation in R. It is my aim to build something which allows me to the the following:
>>>>>
>>>>> - Import a point pattern p with associated times for each event
>>>>> - Plot a time weighted kernel density map of p - such that more recent events have a greater weighting than those that occurred earlier.
>>>>> - Ideally it would be useful to specify both the spatial and temporal bandwidths and the decay function types i.e. linear, exponential
>>>>> - Import new point data and assign an intensity score to each point from its location on time-weighted kernel density surface.
>>>>>
>>>>> Is this something that is relatively easily doable in R or am I crazy?
>>>>> I have developed something similar previously in both C++ and VB.NET (cough) interfacing directly with MapInfo so I am not afraid of code.
>>>>> However, as I am still relatively new to R I imagined that there were likely some better and worse ways to do this and/or libraries to look at. I have checked out the sp and spatstat libraries - but neither seem to have much to do with time, next i am considering trip. Where would you start? I would hate to waste time implementing something just because I was unaware of an existing solution.
>>>>>
>>>>> Therefore any advice, suggestions, experiences or abuse concerning how I might accomplish this functionality would be greatly appreciated.
>>>>>
>>>>> Best
>>>>> Stepen
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at r-project.org
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>>>
>>>>
>>>> --
>>>> Michael Sumner
>>>> Institute for Marine and Antarctic Studies, University of Tasmania
>>>> Hobart, Australia
>>>> e-mail: mdsumner at gmail.com
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>
>> -- 
>> Michael Sumner
>> Institute for Marine and Antarctic Studies, University of Tasmania
>> Hobart, Australia
>> e-mail: mdsumner at gmail.com
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


-- 
Cl?ment CALENGE
Cellule d'appui ? l'analyse de donn?es
Direction des Etudes et de la Recherche
Office national de la chasse et de la faune sauvage
Saint Benoist - 78610 Auffargis
tel. (33) 01.30.46.54.14


From Roger.Bivand at nhh.no  Fri Mar 25 12:11:48 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 25 Mar 2011 12:11:48 +0100 (CET)
Subject: [R-sig-Geo] Spatial Lag and Error Model
In-Reply-To: <C91442134EEFE4408AD950F07899435C1C9834@exchange22.mercury.ad.ubc.ca>
References: <C91442134EEFE4408AD950F07899435C1C982F@exchange22.mercury.ad.ubc.ca>
	<alpine.LRH.2.00.1103240913070.8949@reclus.nhh.no>
	<C91442134EEFE4408AD950F07899435C1C9832@exchange22.mercury.ad.ubc.ca>
	<C91442134EEFE4408AD950F07899435C1C9834@exchange22.mercury.ad.ubc.ca>
Message-ID: <alpine.LRH.2.00.1103251211220.13042@reclus.nhh.no>

On Thu, 24 Mar 2011, Janmaat, John wrote:

>
>
> -----Original Message-----
> From: Janmaat, John
> Sent: Thursday, March 24, 2011 3:40 PM
> To: 'Roger.Bivand at nhh.no'
> Subject: RE: [R-sig-Geo] Spatial Lag and Error Model
>
> Hello Roger,
>
> Thanks for your reply.
>
> A code snippet:
>
> nl <- knearneigh(cbind(wd2$Long,wd2$Lat),k=4)
> nb <- knn2nb(nl)
> weightings <- nb2listw(nb)
> wd.GMerrorsarSum <- gstsls(frmWin, data=wd2,weightings)
>
> The error message:
>
> Error in solve.default(QQ, Qye) :
>  system is computationally singular: reciprocal condition number =
> 4.20784e-28
>
> There are 10,996 observations.

You did not provide sessionInfo() output. If you update spdep, you'll find 
that this issue (of poorly conditioned crossproduct matrices in the stsls 
step) was addressed in December 2010, and the current release should work.

The code and error messages from errorsarlm() and lagsarlm() will probably 
also show other misunderstandings, but that can be addressed if you post 
them.

Hope this helps,

Roger

>
> The dataset has been processed to remove any overlapping points (no zero
> distances) and to remove points that do not have at least one neighbour
> within 100m.  Overlapping points existed as accounts would change when a
> resident moved, leading to multiple observations for a single lot.  This
> is what I originally thought could be the issue, as there are then zero
> distances.  It has also had all observations with NA removed.  The model
> represented in frmWin is solved fine by lm(), with no variables dropped.
>
> I'm not sure how to check for near linear dependence in WX though, so I
> would appreciate it if you could direct me there.
>
> I am using k nearest neighbours, as opposed to rook or queen as my data
> has lat and long for the lot centroid, as opposed to a polygon for each
> lot.
>
> There are some natural boundaries within the data, such that it can be
> divided into subsets where within each subset the neighbour list for the
> observations in the subset is no different from that generated for the
> whole dataset.  I have also done an analysis separately for such
> subsets, with the same result.
>
> Thanks in advance for any suggestions.
>
> John.
>
> -----Original Message-----
> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Sent: Thursday, March 24, 2011 1:27 AM
> To: Janmaat, John
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] Spatial Lag and Error Model
>
> On Wed, 23 Mar 2011, Janmaat, John wrote:
>
>> Hello,
>>
>>
>>
>> I have a city water use dataset with almost 12000 observations.  I am
>> using spdep.  I am using K nearest neighbours (4) to build the
> neighbour
>> list.  I am trying to estimate a model to predict household water use,
>> controlling for a set of independent variables like lot size, house
>> size, etc.  The spatial model diagnostics, lm.LMtests, suggests that
>> there is both a spatial error and a spatial lag in the data.  However,
>> on the lm estimations (lagsarlm,errorsarlm), report that the system is
>> singular.  I can estimate the model using GMerrorsar and lagmess.
>> However, gstsls exits with the same error as the lm estimations.
>>
>> Is there a function I am missing to estimate a model with both spatial
>> autocorrelation and a spatial lagged dependent variable that won't
> have
>> the singularity problem?
>>
>
> Well, what we are missing are the verbatim error messages and function
> calls. It may well be that your diagnosis of the problem is not precise
> enough, especially as the code used depends on your choice of input
> arguments. Does lm() of the same model report any unfitted coefficients
> (are there near-linear dependencies present in the X variables, or
> between
> X and WX)?
>
> Roger
>
>>
>>
>> Thanks,
>>
>>
>>
>> John.
>>
>>
>>
>> --------------------
>>
>> Dr. John Janmaat
>>
>> Department of Economics
>>
>> I.K. Barber School of Arts and Sciences
>>
>> University of British Columbia - Okanagan Campus
>>
>> 3333 University Way, Kelowna, BC
>>
>> V1V 1V7
>>
>> Tel: (250)807-8021
>>
>> WWW: http://people.ok.ubc.ca/jjanmaat/
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From alobolistas at gmail.com  Fri Mar 25 13:32:52 2011
From: alobolistas at gmail.com (Agustin Lobo)
Date: Fri, 25 Mar 2011 13:32:52 +0100
Subject: [R-sig-Geo] raster: extract is empty with polygon
In-Reply-To: <AANLkTimdCBga2KYeMmgv3_QfqD0HZ_duRboAmpLOb2-X@mail.gmail.com>
References: <AANLkTikm7vqavOM7YNSRc2gX=t6qqBU9apzUn-52uPy3@mail.gmail.com>
	<AANLkTin5trnbF8w+85RFfcAQZgn+77JvNsbM4xC8zaM+@mail.gmail.com>
	<AANLkTi=EK-JSyZFa47k4qmFkDmOR8SGpW40v5B_rxnLy@mail.gmail.com>
	<AANLkTi=jTf7tOJ2=+yEEyBFu0N6C4MEVrM2MDPFh9hMO@mail.gmail.com>
	<AANLkTin8Gv38Jv3kJMfGFe4GQA-esCvZX=mn6k=A80zo@mail.gmail.com>
	<AANLkTineP+QS7TGU2_eG8T4p1N8z8w1t4tf2EmAGrzy2@mail.gmail.com>
	<AANLkTimdCBga2KYeMmgv3_QfqD0HZ_duRboAmpLOb2-X@mail.gmail.com>
Message-ID: <AANLkTimBjZvGOgaLemUtih31xkMvjBJOdpfwdrmjZ_cc@mail.gmail.com>

Anyway, the problem is solved by including the appropriate wld file:
1.0
0
0
-1.0
0.5
0.5

In this case, both QGIS and R (raster) keep the same coordinates and
the vector layer matches the raster layer.

Agus

2011/3/25 Agustin Lobo <alobolistas at gmail.com>:
> But then this is not as in gdal. Gdalinfo states that the bottom left is 0,1760
> while R states 0,0
> Should not raster do as gdal?
>
> Corner Coordinates:
> Upper Left ?( ? ?0.0, ? ?0.0)
> Lower Left ?( ? ?0.0, 1760.0)
> Upper Right ( 2640.0, ? ?0.0)
> Lower Right ( 2640.0, 1760.0)
> Center ? ? ?( 1320.0, ?880.0)
> Band 1 Block=2640x1 Type=UInt16, ColorInterp=Red
> Band 2 Block=2640x1 Type=UInt16, ColorInterp=Green
> Band 3 Block=2640x1 Type=UInt16, ColorInterp=Blue
>
> Agus
>
> 2011/3/24 Robert J. Hijmans <r.hijmans at gmail.com>:
>> Agus,
>>
>> If this is from a standard camera, perhaps the problem is that there
>> is no associated georeference, and different programs may come up with
>> a different solution to put them somewhere on the map.
>> R (via gdal) does this: 0, 2640, 0, 1760 (xmin, xmax, ymin, ymax),
>> with resolution 1 (cell). What does QGIS do?
>> Perhaps you need to first save it to a geotiff, or add a (fake
>> coordinates) "world file" so that the treatment becomes consistent.
>>
>> What is extent(calibf2) ?
>>
>> Robert
>>
>> On Thu, Mar 24, 2011 at 12:56 PM, Agustin Lobo <alobolistas at gmail.com> wrote:
>>> Robert,
>>>
>>> I have "reprojection on the fly" not activated. The raster
>>> is an image from an standard camera, hence no projection.
>>> The shapefile takes the projection from the project, but the
>>> coordinates should be within the limits of the image, as it has been
>>> digitized on top of the image. Thus I thought it was just a matter of
>>> setting the CRS for the raster in R.
>>>
>>>> intersectExtent(calibf2, SGRGBF40)
>>> Error in intersectExtent(calibf2, SGRGBF40) : Invalid extent
>>>
>>> which is in agreement with the rest of results, but still in
>>> contradiction with what we see in QGIS
>>>
>>> Agus
>>>
>>> 2011/3/24 Robert J. Hijmans <r.hijmans at gmail.com>:
>>>> Hi Agus,
>>>>
>>>> It would be useful to see
>>>>
>>>> extent(calibf2)
>>>>
>>>> Apparently it does not overlap with SGRGBF40 ?(see
>>>> intersectExtent(calibf2, SGRGBF40) ?)
>>>> because the polys did not plot on top of the raster.
>>>>
>>>> Perhaps QGIS does some on-the-fly projection trick or other such that
>>>> the coordinates from your on-screen digitization do match those of the
>>>> raster?
>>>>
>>>> This will not fix that! :
>>>>> projection(SGRGBF40) = projection(calibf2)
>>>>
>>>> You can perhaps compare with a polygon you draw in R on top of SGRGBF40
>>>>
>>>> plot(SGRGBF40,1)
>>>> p <- drawPoly()
>>>> extract(SGRGBF40, p)
>>>>
>>>> And save p and load into QGIS?
>>>>
>>>> Best, Robert
>>>>
>>>> ( I would also update the raster package (but I do not think that
>>>> matters for this problem).
>>>>
>>>>
>>>> On Thu, Mar 24, 2011 at 11:27 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
>>>>> I forgot to add that raster and vector do overlap in qgis (the vector
>>>>> was actually digitized on top of the raster)
>>>>> Agus
>>>>>
>>>>> 2011/3/24 Agustin Lobo <alobolistas at gmail.com>:
>>>>>> Hi!
>>>>>> I'm trying to calculate the mean values for a set of polygons.
>>>>>> This is what I do:
>>>>>>
>>>>>> require(raster)
>>>>>> require(rgdal)
>>>>>> #SGRGBWBPS125F40
>>>>>> #"read" tif file
>>>>>> SGRGBF40 = brick("/media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL/SGRGB/SGRGBWBPS125F40.tif")
>>>>>>> SGRGBF40
>>>>>> class ? ? ? : RasterBrick
>>>>>> filename ? ?: /media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL/SGRGB/SGRGBWBPS125F40.tif
>>>>>> nlayers ? ? : 3
>>>>>> nrow ? ? ? ?: 1760
>>>>>> ncol ? ? ? ?: 2640
>>>>>> ncell ? ? ? : 4646400
>>>>>> projection ?: NA
>>>>>> min value ? : 0 0 0
>>>>>> max value ? : 65535 65535 65535
>>>>>> extent ? ? ?: 0, 2640, 0, 1760 ?(xmin, xmax, ymin, ymax)
>>>>>> resolution ?: 1, 1 ?(x, y)
>>>>>>> projection(SGRGBF40)
>>>>>> [1] "NA"
>>>>>>
>>>>>> #read the shape file
>>>>>> calibf2 = readOGR(dsn="/media/TRANSCEND/MONTSENY2008/CALIBRACION2010/DigiPreprocess/TESTCASA/CALSEL",layer="calibf2",stringsAsFactors=F)
>>>>>>> projection(calibf2)
>>>>>> [1] "+proj=utm +zone=31 +ellps=intl +units=m +no_defs"
>>>>>>
>>>>>>> projection(SGRGBF40) = projection(calibf2)
>>>>>>
>>>>>> But they do not overlap as shown by
>>>>>>> plot(subset(SGRGBF40,1))
>>>>>>> plot(calibf2,add=T)
>>>>>>
>>>>>> and the extracted object is empty
>>>>>> #Calculate mean values for each polygon:
>>>>>>> v <- extract(SGRGBF40, calibf2,fun=mean,nl=3)
>>>>>>> summary(v)
>>>>>> ? ? ?Length Class ?Mode
>>>>>> ?[1,] 0 ? ? ?-none- NULL
>>>>>> ?[2,] 0 ? ? ?-none- NULL
>>>>>> ?[3,] 0 ? ? ?-none- NULL
>>>>>> ?[4,] 0 ? ? ?-none- NULL
>>>>>> ?[5,] 0 ? ? ?-none- NULL
>>>>>> etc
>>>>>>
>>>>>>> sessionInfo()
>>>>>> R version 2.12.2 (2011-02-25)
>>>>>> Platform: i486-pc-linux-gnu (32-bit)
>>>>>>
>>>>>> locale:
>>>>>> ?[1] LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C
>>>>>> ?[3] LC_TIME=en_US.UTF-8 ? ? ? ?LC_COLLATE=en_US.UTF-8
>>>>>> ?[5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_US.UTF-8
>>>>>> ?[7] LC_PAPER=en_US.UTF-8 ? ? ? LC_NAME=C
>>>>>> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
>>>>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>>>>
>>>>>> attached base packages:
>>>>>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>>>>>
>>>>>> other attached packages:
>>>>>> [1] rgdal_0.6-31 raster_1.7-8 sp_0.9-72
>>>>>>
>>>>>> loaded via a namespace (and not attached):
>>>>>> [1] grid_2.12.2 ? ? lattice_0.19-17 tools_2.12.2
>>>>>>
>>>>>
>>>>
>>>
>>
>


From tom.gottfried at wzw.tum.de  Fri Mar 25 14:42:32 2011
From: tom.gottfried at wzw.tum.de (Tom Gottfried)
Date: Fri, 25 Mar 2011 14:42:32 +0100
Subject: [R-sig-Geo] residual variograms for simple or universal kriging
Message-ID: <4D8C9BC8.6040608@wzw.tum.de>

Hi list,

it seems I miss something of how to specify trend parameters for computing a residual variogram for 
simple kriging when doing as follows:

library(gstat)
data(meuse)
coordinates(meuse) <- ~x+y

# residual variogram for universal kriging
meuse_universal <- gstat(NULL, "zinc", zinc~dist,
                          subset(meuse, meuse$landuse=="Ah"))
residvar_universal <- variogram(meuse_universal)
lm_universal <- lm(zinc~dist, subset(meuse, meuse$landuse=="Ah"))

# residual variogram for simple kriging
meuse_simple <- gstat(NULL, "zinc", zinc~dist,
                       subset(meuse, meuse$landuse=="Ah"),
                       beta=coefficients(lm(zinc~dist, meuse)))
residvar_simple <- variogram(meuse_simple)
lm_simple <- lm(zinc~dist, meuse)

identical(coefficients(lm_universal), coefficients(lm_simple))
identical(residvar_universal, residvar_simple)

The next to last line shows that the linear models differ for the subset used in meuse_universal and 
the whole dataset given for the calculation of parameters for meuse_simple. Nevertheless, the 
variograms are identical. As variogram() can not know about the whole dataset when computing 
resdivar_universal, I conclude that what I give as beta argument for meuse_simple and thus 
residvar_simple is not taken into account.

Any help?
Thanks,
Tom

-- 
Technische Universit?t M?nchen
Department f?r Pflanzenwissenschaften
Lehrstuhl f?r Gr?nlandlehre
Alte Akademie 12
85350 Freising / Germany
Phone: ++49 (0)8161 715324
Fax:   ++49 (0)8161 713243
email: tom.gottfried at wzw.tum.de
http://www.wzw.tum.de/gruenland


From John.Janmaat at ubc.ca  Fri Mar 25 14:49:00 2011
From: John.Janmaat at ubc.ca (Janmaat, John)
Date: Fri, 25 Mar 2011 06:49:00 -0700
Subject: [R-sig-Geo] Spatial Lag and Error Model
In-Reply-To: <alpine.LRH.2.00.1103251211220.13042@reclus.nhh.no>
References: <C91442134EEFE4408AD950F07899435C1C982F@exchange22.mercury.ad.ubc.ca>
	<alpine.LRH.2.00.1103240913070.8949@reclus.nhh.no>
	<C91442134EEFE4408AD950F07899435C1C9832@exchange22.mercury.ad.ubc.ca>
	<C91442134EEFE4408AD950F07899435C1C9834@exchange22.mercury.ad.ubc.ca>
	<alpine.LRH.2.00.1103251211220.13042@reclus.nhh.no>
Message-ID: <C91442134EEFE4408AD950F07899435C1C9835@exchange22.mercury.ad.ubc.ca>

Hello again,

Thanks for the suggestion of updating the packages.  That dealt with one
issue.  For the rest, here is some of the info you asked for.  For
errorsarlm and lagsarlm I get a memory allocation problem.

> sessionInfo()
R version 2.12.1 (2010-12-16)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252    LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                           LC_TIME=English_United
States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


other attached packages:
 [1] RANN_2.1.2         pgirmess_1.5.1     spdep_0.5-29
coda_0.14-2        deldir_0.0-13      nlme_3.1-98        MASS_7.3-11
Matrix_0.999375-48
 [9] boot_1.2-43        spgwr_0.6-10       maptools_0.8-4
lattice_0.19-17    foreign_0.8-42     sp_0.9-79         

loaded via a namespace (and not attached):
[1] grid_2.12.1  tools_2.12.1

Here are the error messages when commands run for full sample:

> wd.GMerrorsarSum <- GMerrorsar(frmSum,data=wd2,weightings)
> wd.GMerrorsarWin <- GMerrorsar(frmWin,data=wd2,weightings)
> wd.errorsarSum <- errorsarlm(frmSum,data=wd2,weightings)
Error: cannot allocate vector of size 922.5 Mb
> wd.errorsarWin <- errorsarlm(frmWin,data=wd2,weightings)
Error: cannot allocate vector of size 922.5 Mb
> wd.MESSlagsarSum <- lagmess(frmSum,data=wd2,weightings)
> wd.MESSlagsarWin <- lagmess(frmWin,data=wd2,weightings)
> wd.lagsarSum <- lagsarlm(frmSum,data=wd2,weightings)
Error: cannot allocate vector of size 922.5 Mb
> wd.lagsarWin <- lagsarlm(frmWin,data=wd2,weightings)
Error: cannot allocate vector of size 922.5 Mb
> wd.GMerrorsarSum <- gstsls(frmSum, data=wd2,weightings)
> wd.GMerrorsarWin <- gstsls(frmWin, data=wd2,weightings)

If I run the same set of commands on a subset of the data, then the
command output is:

> wd.GMerrorsarSum <- GMerrorsar(frmSum,data=wd2,weightings)
> wd.GMerrorsarWin <- GMerrorsar(frmWin,data=wd2,weightings)
> wd.errorsarSum <- errorsarlm(frmSum,data=wd2,weightings)
Error in solve.default(asyvar, tol = tol.solve) : 
  system is computationally singular: reciprocal condition number =
8.6909e-27
> wd.errorsarWin <- errorsarlm(frmWin,data=wd2,weightings)
Error in solve.default(asyvar, tol = tol.solve) : 
  system is computationally singular: reciprocal condition number =
8.34845e-27
> wd.MESSlagsarSum <- lagmess(frmSum,data=wd2,weightings)
> wd.MESSlagsarWin <- lagmess(frmWin,data=wd2,weightings)
> wd.lagsarSum <- lagsarlm(frmSum,data=wd2,weightings)
Error in solve.default(inf, tol = tol.solve) : 
  system is computationally singular: reciprocal condition number =
7.82721e-27
> wd.lagsarWin <- lagsarlm(frmWin,data=wd2,weightings)
Error in solve.default(inf, tol = tol.solve) : 
  system is computationally singular: reciprocal condition number =
7.81985e-27
> wd.GMerrorsarSum <- gstsls(frmSum, data=wd2,weightings)
> wd.GMerrorsarWin <- gstsls(frmWin, data=wd2,weightings)
>

Suggestions?



-----Original Message-----
From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Sent: Friday, March 25, 2011 4:12 AM
To: Janmaat, John
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] Spatial Lag and Error Model

On Thu, 24 Mar 2011, Janmaat, John wrote:

>
>
> -----Original Message-----
> From: Janmaat, John
> Sent: Thursday, March 24, 2011 3:40 PM
> To: 'Roger.Bivand at nhh.no'
> Subject: RE: [R-sig-Geo] Spatial Lag and Error Model
>
> Hello Roger,
>
> Thanks for your reply.
>
> A code snippet:
>
> nl <- knearneigh(cbind(wd2$Long,wd2$Lat),k=4)
> nb <- knn2nb(nl)
> weightings <- nb2listw(nb)
> wd.GMerrorsarSum <- gstsls(frmWin, data=wd2,weightings)
>
> The error message:
>
> Error in solve.default(QQ, Qye) :
>  system is computationally singular: reciprocal condition number =
> 4.20784e-28
>
> There are 10,996 observations.

You did not provide sessionInfo() output. If you update spdep, you'll
find 
that this issue (of poorly conditioned crossproduct matrices in the
stsls 
step) was addressed in December 2010, and the current release should
work.

The code and error messages from errorsarlm() and lagsarlm() will
probably 
also show other misunderstandings, but that can be addressed if you post

them.

Hope this helps,

Roger

>
> The dataset has been processed to remove any overlapping points (no
zero
> distances) and to remove points that do not have at least one
neighbour
> within 100m.  Overlapping points existed as accounts would change when
a
> resident moved, leading to multiple observations for a single lot.
This
> is what I originally thought could be the issue, as there are then
zero
> distances.  It has also had all observations with NA removed.  The
model
> represented in frmWin is solved fine by lm(), with no variables
dropped.
>
> I'm not sure how to check for near linear dependence in WX though, so
I
> would appreciate it if you could direct me there.
>
> I am using k nearest neighbours, as opposed to rook or queen as my
data
> has lat and long for the lot centroid, as opposed to a polygon for
each
> lot.
>
> There are some natural boundaries within the data, such that it can be
> divided into subsets where within each subset the neighbour list for
the
> observations in the subset is no different from that generated for the
> whole dataset.  I have also done an analysis separately for such
> subsets, with the same result.
>
> Thanks in advance for any suggestions.
>
> John.
>
> -----Original Message-----
> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Sent: Thursday, March 24, 2011 1:27 AM
> To: Janmaat, John
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] Spatial Lag and Error Model
>
> On Wed, 23 Mar 2011, Janmaat, John wrote:
>
>> Hello,
>>
>>
>>
>> I have a city water use dataset with almost 12000 observations.  I am
>> using spdep.  I am using K nearest neighbours (4) to build the
> neighbour
>> list.  I am trying to estimate a model to predict household water
use,
>> controlling for a set of independent variables like lot size, house
>> size, etc.  The spatial model diagnostics, lm.LMtests, suggests that
>> there is both a spatial error and a spatial lag in the data.
However,
>> on the lm estimations (lagsarlm,errorsarlm), report that the system
is
>> singular.  I can estimate the model using GMerrorsar and lagmess.
>> However, gstsls exits with the same error as the lm estimations.
>>
>> Is there a function I am missing to estimate a model with both
spatial
>> autocorrelation and a spatial lagged dependent variable that won't
> have
>> the singularity problem?
>>
>
> Well, what we are missing are the verbatim error messages and function
> calls. It may well be that your diagnosis of the problem is not
precise
> enough, especially as the code used depends on your choice of input
> arguments. Does lm() of the same model report any unfitted
coefficients
> (are there near-linear dependencies present in the X variables, or
> between
> X and WX)?
>
> Roger
>
>>
>>
>> Thanks,
>>
>>
>>
>> John.
>>
>>
>>
>> --------------------
>>
>> Dr. John Janmaat
>>
>> Department of Economics
>>
>> I.K. Barber School of Arts and Sciences
>>
>> University of British Columbia - Okanagan Campus
>>
>> 3333 University Way, Kelowna, BC
>>
>> V1V 1V7
>>
>> Tel: (250)807-8021
>>
>> WWW: http://people.ok.ubc.ca/jjanmaat/
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From alobolistas at gmail.com  Fri Mar 25 14:58:07 2011
From: alobolistas at gmail.com (Agustin Lobo)
Date: Fri, 25 Mar 2011 14:58:07 +0100
Subject: [R-sig-Geo] raster::extract NAs introduced?
Message-ID: <AANLkTinScGDCLcOY5cDYQH2u0eDwz+6P+pE9yjjYpSAP@mail.gmail.com>

Hi

I've found that extract() introduces NAs:
SGRGBF40 = brick("/media/Iomega_HDD/UAVetal/CALIBRACIONRADIOM/TESTCASA/CALSEL/SGRGB/SGRGBWBPS125F40.tif")
calibf2 = readOGR(dsn="/media/Iomega_HDD/UAVetal/CALIBRACIONRADIOM/TESTCASA/CALSEL",layer="calibf2",stringsAsFactors=F)
projection(SGRGBF40) = projection(calibf2)
plot(subset(SGRGBF40,1))
plot(calibf2,add=T)
(overlay is ok now)

> summary(SGRGBF40)
Cells:  4646400
NAs  :  0 0 0

            1     2     3
Min.     2629     3     3
1st Qu. 34100 22200 18290
Median  42470 27480 24680
Mean    40900 28510 25360
3rd Qu. 48360 33100 29010
Max.    65510 65510 64300
summary based on a sample of 5000 cells, which is 0.107610192837466 %
of all cells
To make sure (NAs could outside the sample):
> any(is.na(SGRGBF40))
class       : RasterLayer
dimensions  : 1760, 2640, 1  (nrow, ncol, nlayers)
resolution  : 1, 1  (x, y)
extent      : 0, 2640, -1759, 1  (xmin, xmax, ymin, ymax)
projection  : +proj=utm +zone=31 +ellps=intl +units=m +no_defs
values      : in memory
min value   : 0
max value   : 1
So no NAs
But:
> summary(v)
 SGRGBWBPS125F40_1 SGRGBWBPS125F40_2 SGRGBWBPS125F40_3
 Min.   :18444     Min.   :  119.4   Min.   :    3
 1st Qu.:33227     1st Qu.:25516.4   1st Qu.:15633
 Median :37752     Median :36264.1   Median :22374
 Mean   :40208     Mean   :36275.1   Mean   :29737
 3rd Qu.:46899     3rd Qu.:48052.5   3rd Qu.:48116
 Max.   :64992     Max.   :63667.1   Max.   :63826
 NA's   :    5     NA's   :    1.0


Any explanation to this? Not a big problem (can use na.rm) but I'm
concerned on this problem implying
the means not being correct.

Agus


From r.hijmans at gmail.com  Fri Mar 25 17:42:13 2011
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Fri, 25 Mar 2011 09:42:13 -0700
Subject: [R-sig-Geo] raster::extract NAs introduced?
In-Reply-To: <AANLkTinScGDCLcOY5cDYQH2u0eDwz+6P+pE9yjjYpSAP@mail.gmail.com>
References: <AANLkTinScGDCLcOY5cDYQH2u0eDwz+6P+pE9yjjYpSAP@mail.gmail.com>
Message-ID: <AANLkTinhdgCHU7qUfZcN=5R_T2Nk7bRhuNkpN0c8rC0A@mail.gmail.com>

Agus,

> any(is.na(SGRGBF40))

returns a RasterLayer with

> min value ? : 0
> max value ? : 1

TRUE == 1, so there is at least one NA value

also see:

count(SGRGBF40, NA)

summary(SGRGBF40, maxsamp=ncell(SGRGBF40))


Best, Robert


On Fri, Mar 25, 2011 at 6:58 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
> Hi
>
> I've found that extract() introduces NAs:
> SGRGBF40 = brick("/media/Iomega_HDD/UAVetal/CALIBRACIONRADIOM/TESTCASA/CALSEL/SGRGB/SGRGBWBPS125F40.tif")
> calibf2 = readOGR(dsn="/media/Iomega_HDD/UAVetal/CALIBRACIONRADIOM/TESTCASA/CALSEL",layer="calibf2",stringsAsFactors=F)
> projection(SGRGBF40) = projection(calibf2)
> plot(subset(SGRGBF40,1))
> plot(calibf2,add=T)
> (overlay is ok now)
>
>> summary(SGRGBF40)
> Cells: ?4646400
> NAs ?: ?0 0 0
>
> ? ? ? ? ? ?1 ? ? 2 ? ? 3
> Min. ? ? 2629 ? ? 3 ? ? 3
> 1st Qu. 34100 22200 18290
> Median ?42470 27480 24680
> Mean ? ?40900 28510 25360
> 3rd Qu. 48360 33100 29010
> Max. ? ?65510 65510 64300
> summary based on a sample of 5000 cells, which is 0.107610192837466 %
> of all cells
> To make sure (NAs could outside the sample):
>> any(is.na(SGRGBF40))
> class ? ? ? : RasterLayer
> dimensions ?: 1760, 2640, 1 ?(nrow, ncol, nlayers)
> resolution ?: 1, 1 ?(x, y)
> extent ? ? ?: 0, 2640, -1759, 1 ?(xmin, xmax, ymin, ymax)
> projection ?: +proj=utm +zone=31 +ellps=intl +units=m +no_defs
> values ? ? ?: in memory
> min value ? : 0
> max value ? : 1
> So no NAs
> But:
>> summary(v)
> ?SGRGBWBPS125F40_1 SGRGBWBPS125F40_2 SGRGBWBPS125F40_3
> ?Min. ? :18444 ? ? Min. ? : ?119.4 ? Min. ? : ? ?3
> ?1st Qu.:33227 ? ? 1st Qu.:25516.4 ? 1st Qu.:15633
> ?Median :37752 ? ? Median :36264.1 ? Median :22374
> ?Mean ? :40208 ? ? Mean ? :36275.1 ? Mean ? :29737
> ?3rd Qu.:46899 ? ? 3rd Qu.:48052.5 ? 3rd Qu.:48116
> ?Max. ? :64992 ? ? Max. ? :63667.1 ? Max. ? :63826
> ?NA's ? : ? ?5 ? ? NA's ? : ? ?1.0
>
>
> Any explanation to this? Not a big problem (can use na.rm) but I'm
> concerned on this problem implying
> the means not being correct.
>
> Agus
>


From r.hijmans at gmail.com  Fri Mar 25 18:10:55 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Fri, 25 Mar 2011 10:10:55 -0700 (PDT)
Subject: [R-sig-Geo] Fwd: raster: extract is empty with polygon
In-Reply-To: <AANLkTimdCBga2KYeMmgv3_QfqD0HZ_duRboAmpLOb2-X@mail.gmail.com>
References: <AANLkTikm7vqavOM7YNSRc2gX=t6qqBU9apzUn-52uPy3@mail.gmail.com>
	<AANLkTin5trnbF8w+85RFfcAQZgn+77JvNsbM4xC8zaM+@mail.gmail.com>
	<AANLkTi=EK-JSyZFa47k4qmFkDmOR8SGpW40v5B_rxnLy@mail.gmail.com>
	<AANLkTi=jTf7tOJ2=+yEEyBFu0N6C4MEVrM2MDPFh9hMO@mail.gmail.com>
	<AANLkTin8Gv38Jv3kJMfGFe4GQA-esCvZX=mn6k=A80zo@mail.gmail.com>
	<AANLkTimdCBga2KYeMmgv3_QfqD0HZ_duRboAmpLOb2-X@mail.gmail.com>
Message-ID: <1301073055817-6208413.post@n2.nabble.com>

> But then this is not as in gdal. Gdalinfo states that the bottom left is
0,1760
> while R states 0,0
> Should not raster do as gdal?
>
> Corner Coordinates:
> Upper Left ?( ? ?0.0, ? ?0.0)
> Lower Left ?( ? ?0.0, 1760.0)
> Upper Right ( 2640.0, ? ?0.0)
> Lower Right ( 2640.0, 1760.0)
> Center ? ? ?( 1320.0, ?880.0)
> Band 1 Block=2640x1 Type=UInt16, ColorInterp=Red
> Band 2 Block=2640x1 Type=UInt16, ColorInterp=Green
> Band 3 Block=2640x1 Type=UInt16, ColorInterp=Blue
>


This is problematic:

> Upper Left  (    0.0,    0.0)
> Lower Left  (    0.0, 1760.0)

unless, perhaps, you say that the vertical resolution is negative and hence
Upper is Lower. Nevertheless, what raster (rgdal) does is consistent with
gdal, because it uses the same coordinates, the same extent.

It seems that the difference is that raster / rgdal say that 0 is smaller
than 1760 and hence

Lower Left  (    0.0,    0.0)
Upper Left  (    0.0, 1760.0)

>From what I understood from you, QGIS does

Lower Left  (    0.0, -1760.0)
Upper Left  (    0.0,    0.0)

Which is consistent of the Upper Left of GDAL. But disagrees with how GDAL
interprets the extent (bounding box).

What does GDALINFO give for the vertical resolution?

Robert


--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/raster-extract-is-empty-with-polygon-tp6205163p6208413.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From p.hiemstra at geo.uu.nl  Sat Mar 26 10:40:55 2011
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Sat, 26 Mar 2011 10:40:55 +0100
Subject: [R-sig-Geo] passing 'cutoff' to the 'autoKrige' function
 ('automap' package)
In-Reply-To: <AANLkTimzzQ5EKzQyGe_SKYnkeRx1F8Kez-KBnbiE_kbP@mail.gmail.com>
References: <AANLkTimzzQ5EKzQyGe_SKYnkeRx1F8Kez-KBnbiE_kbP@mail.gmail.com>
Message-ID: <4D8DB4A7.3050801@geo.uu.nl>

Hi,

The miscFitOptions parameter does not include the 'variogram' paramters. 
I will look into adding them, together with the option to set the 
boundaries manually. However, autofitVariogram at this stage defines a 
fixed set of boundaries, so I'm not sure if the parameters you mention 
will resort any effect even when passing them on. An option at this 
stage would be to use the normal krige function combined with 
autofitVariogram. autofitVariogram passes on parameters to variogram() 
using the ... .

Could you create a new issue in the bitbucket.org account which stores 
automap [1]? This way I can keep track of the issues that need to be 
fixed for autofitVariogram.

cheers,
Paul

[1] https://bitbucket.org/paulhiemstra/automap/issues/new

On 03/25/2011 08:57 AM, Mauricio Zambrano wrote:
> Dear list,
>
> Is there any way to pass the 'cutoff' argument (or 'width', or other
> arguments of the 'variogram' function of the 'gstat' package)  to the
> 'autoKrige' function of the 'automap' package ?
>
> I tried with:
>
>    
>> x.ok<- autoKrige(zinc~1, meuse, meuse.grid, miscFitOptions=list(maxdist=100,  cutoff=500, width=50) )
>>      
> but both arguments are ignored.
>
>
> I also tried with:
>
>    
>> x.ok<- autoKrige(zinc~1, meuse, meuse.grid, maxdist=100,  cutoff=500, width=100)
>>      
> but I got the following error message:
>
> "Error in gstat(formula = formula, data = locations, model = model,
> beta = beta,  :
>   unused argument(s) (cutoff = 500, width = 50)"
>
>
> Some session info:
>
> R version 2.12.2 (2011-02-25)
> automap_1.0-9
> gstat_0.9-79
>
>
> Here there is a reproducible example (for the 'autofitVariogram'
> function, because I didn't find a way to pass the 'cutoff' and 'with'
> arguments to the 'autoKrige' function):
>
> ------------ START ---------------
>
> library(automap)
>
> # Data preparation
> data(meuse)
> coordinates(meuse) =~ x+y
> data(meuse.grid)
> gridded(meuse.grid) =~ x+y
>
> # Computing the 'boundaries' value for the 'variogram' function,
> # in order to properly compare its results with those of the
> 'autofitVariogram' function
>
> input_data<- meuse
>
> x<- coordinates(input_data)[, 1]
> y<- coordinates(input_data)[, 2]
> scale_number<- (0.35 * sqrt((max(x) - min(x))^2 + (max(y) - min(y))^2)/100)
> boundaries<- c(2, 4, 6, 9, 12, 15, 25, 35, 50, 65, 80, 100) * scale_number
>
> # variogram computation. Case 1, default parameters
> vgm.gstat<- variogram(zinc ~ 1, locations=meuse, boundaries=boundaries)
> vgm.automap<- autofitVariogram(zinc ~ 1, input_data=meuse)
>
> # These variograms are the same
> print(vgm.gstat)
> print(vgm.automap$exp_var)
>
> # variogram computation. Case 2, with 'cutoff' and 'width'
> vgm.gstat2<- variogram(zinc ~ 1, locations=meuse, cutoff=500, width=50)
> vgm.automap2<- autofitVariogram(zinc ~ 1, input_data=meuse,
> cutoff=500, width=50)
>
> # These variograms are NOT the same
> print(vgm.gstat2)
> print(vgm.automap2$exp_var)
>
> # variogram computation. Case 3, with 'cutoff', 'width' and 'boundaries'
> vgm.gstat3<- variogram(zinc ~ 1, locations=meuse, cutoff=500,
> width=50, boundaries=boundaries)
> vgm.automap3<- autofitVariogram(zinc ~ 1, input_data=meuse,
> cutoff=500, width=50)
>
> # These variograms are the same
> print(vgm.gstat3)
> print(vgm.automap3$exp_var)
>
>
> ------------ END ---------------
>
>
> Looking at the examples, I think that the problem arises because the
> 'boundaries' argument superimpose its values to the 'cutoff' one, both
> in the 'variogram' and 'autofitVariogram' functions.
>
> However, whereas in the 'variogram' function the boundaries are
> optional, in the 'autofitVariogram' they are computed internally (in a
> smart way), but its maximum default value disable any shorter 'cutoff'
> passed to the 'autofitVariogram' function.
>
>
> In any case, I think that even after solving the issue related to
> 'cutoff' and 'boundaries', it will still be impossible to pass the
> 'cutoff' argument to the 'autoKrige' function, because the '...'
> argument in 'autoKrige' is passed (internally) to the 'krige' function
> and not to 'autofitVariogram' one. Am I right ?
>
> I'm not sure if this could be considered a bug, but I thought it could
> be useful to report this behaviour, for the next release of 'automap'.
>
>
> Kind regards,
>
> Mauricio Zambrano B.
>
>
>    


-- 
Paul Hiemstra, MSc
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 253 5773
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770

currently @ KNMI
paul.hiemstra_AT_knmi.nl


From Roger.Bivand at nhh.no  Sat Mar 26 12:03:05 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 26 Mar 2011 12:03:05 +0100 (CET)
Subject: [R-sig-Geo] Spatial Lag and Error Model
In-Reply-To: <C91442134EEFE4408AD950F07899435C1C9835@exchange22.mercury.ad.ubc.ca>
References: <C91442134EEFE4408AD950F07899435C1C982F@exchange22.mercury.ad.ubc.ca>
	<alpine.LRH.2.00.1103240913070.8949@reclus.nhh.no>
	<C91442134EEFE4408AD950F07899435C1C9832@exchange22.mercury.ad.ubc.ca>
	<C91442134EEFE4408AD950F07899435C1C9834@exchange22.mercury.ad.ubc.ca>
	<alpine.LRH.2.00.1103251211220.13042@reclus.nhh.no>
	<C91442134EEFE4408AD950F07899435C1C9835@exchange22.mercury.ad.ubc.ca>
Message-ID: <alpine.LRH.2.00.1103261155500.19154@reclus.nhh.no>

On Fri, 25 Mar 2011, Janmaat, John wrote:

> Hello again,
>
> Thanks for the suggestion of updating the packages.  That dealt with one
> issue.  For the rest, here is some of the info you asked for.  For
> errorsarlm and lagsarlm I get a memory allocation problem.
>
>> sessionInfo()
> R version 2.12.1 (2010-12-16)
> Platform: i386-pc-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252    LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                           LC_TIME=English_United
> States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
> other attached packages:
> [1] RANN_2.1.2         pgirmess_1.5.1     spdep_0.5-29
> coda_0.14-2        deldir_0.0-13      nlme_3.1-98        MASS_7.3-11
> Matrix_0.999375-48
> [9] boot_1.2-43        spgwr_0.6-10       maptools_0.8-4
> lattice_0.19-17    foreign_0.8-42     sp_0.9-79
>
> loaded via a namespace (and not attached):
> [1] grid_2.12.1  tools_2.12.1
>
> Here are the error messages when commands run for full sample:
>
>> wd.GMerrorsarSum <- GMerrorsar(frmSum,data=wd2,weightings)
>> wd.GMerrorsarWin <- GMerrorsar(frmWin,data=wd2,weightings)
>> wd.errorsarSum <- errorsarlm(frmSum,data=wd2,weightings)
> Error: cannot allocate vector of size 922.5 Mb

See ?errorrsarlm, method= argument. You should not expect to be able to 
use dense matrix methods with as many observations. For k nearest 
neighbours, I suggest LU for an exact result, perhaps MC for an 
approximation.

>> wd.errorsarWin <- errorsarlm(frmWin,data=wd2,weightings)
> Error: cannot allocate vector of size 922.5 Mb

Ditto.

>> wd.MESSlagsarSum <- lagmess(frmSum,data=wd2,weightings)
>> wd.MESSlagsarWin <- lagmess(frmWin,data=wd2,weightings)
>> wd.lagsarSum <- lagsarlm(frmSum,data=wd2,weightings)
> Error: cannot allocate vector of size 922.5 Mb

Ditto - ?lagsarlm

>> wd.lagsarWin <- lagsarlm(frmWin,data=wd2,weightings)
> Error: cannot allocate vector of size 922.5 Mb

Ditto.

You may also see singularities because your RHS variables appear to be 
close to colinear.

>> wd.GMerrorsarSum <- gstsls(frmSum, data=wd2,weightings)
>> wd.GMerrorsarWin <- gstsls(frmWin, data=wd2,weightings)
>
> If I run the same set of commands on a subset of the data, then the
> command output is:
>
>> wd.GMerrorsarSum <- GMerrorsar(frmSum,data=wd2,weightings)
>> wd.GMerrorsarWin <- GMerrorsar(frmWin,data=wd2,weightings)
>> wd.errorsarSum <- errorsarlm(frmSum,data=wd2,weightings)
> Error in solve.default(asyvar, tol = tol.solve) :
>  system is computationally singular: reciprocal condition number =
> 8.6909e-27
>> wd.errorsarWin <- errorsarlm(frmWin,data=wd2,weightings)
> Error in solve.default(asyvar, tol = tol.solve) :
>  system is computationally singular: reciprocal condition number =
> 8.34845e-27

Both of these come when inverting the asymmetric covariance matrix of the 
variables, read about why this happens on the function help pages - it is 
described in details, and may also concern the scaling of your variables.

>> wd.MESSlagsarSum <- lagmess(frmSum,data=wd2,weightings)
>> wd.MESSlagsarWin <- lagmess(frmWin,data=wd2,weightings)
>> wd.lagsarSum <- lagsarlm(frmSum,data=wd2,weightings)
> Error in solve.default(inf, tol = tol.solve) :
>  system is computationally singular: reciprocal condition number =
> 7.82721e-27
>> wd.lagsarWin <- lagsarlm(frmWin,data=wd2,weightings)
> Error in solve.default(inf, tol = tol.solve) :
>  system is computationally singular: reciprocal condition number =
> 7.81985e-27

Ditto.

>> wd.GMerrorsarSum <- gstsls(frmSum, data=wd2,weightings)
>> wd.GMerrorsarWin <- gstsls(frmWin, data=wd2,weightings)
>>
>
> Suggestions?
>

Read the function help pages fully before you use the functions?

Roger

>
>
> -----Original Message-----
> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Sent: Friday, March 25, 2011 4:12 AM
> To: Janmaat, John
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] Spatial Lag and Error Model
>
> On Thu, 24 Mar 2011, Janmaat, John wrote:
>
>>
>>
>> -----Original Message-----
>> From: Janmaat, John
>> Sent: Thursday, March 24, 2011 3:40 PM
>> To: 'Roger.Bivand at nhh.no'
>> Subject: RE: [R-sig-Geo] Spatial Lag and Error Model
>>
>> Hello Roger,
>>
>> Thanks for your reply.
>>
>> A code snippet:
>>
>> nl <- knearneigh(cbind(wd2$Long,wd2$Lat),k=4)
>> nb <- knn2nb(nl)
>> weightings <- nb2listw(nb)
>> wd.GMerrorsarSum <- gstsls(frmWin, data=wd2,weightings)
>>
>> The error message:
>>
>> Error in solve.default(QQ, Qye) :
>>  system is computationally singular: reciprocal condition number =
>> 4.20784e-28
>>
>> There are 10,996 observations.
>
> You did not provide sessionInfo() output. If you update spdep, you'll
> find
> that this issue (of poorly conditioned crossproduct matrices in the
> stsls
> step) was addressed in December 2010, and the current release should
> work.
>
> The code and error messages from errorsarlm() and lagsarlm() will
> probably
> also show other misunderstandings, but that can be addressed if you post
>
> them.
>
> Hope this helps,
>
> Roger
>
>>
>> The dataset has been processed to remove any overlapping points (no
> zero
>> distances) and to remove points that do not have at least one
> neighbour
>> within 100m.  Overlapping points existed as accounts would change when
> a
>> resident moved, leading to multiple observations for a single lot.
> This
>> is what I originally thought could be the issue, as there are then
> zero
>> distances.  It has also had all observations with NA removed.  The
> model
>> represented in frmWin is solved fine by lm(), with no variables
> dropped.
>>
>> I'm not sure how to check for near linear dependence in WX though, so
> I
>> would appreciate it if you could direct me there.
>>
>> I am using k nearest neighbours, as opposed to rook or queen as my
> data
>> has lat and long for the lot centroid, as opposed to a polygon for
> each
>> lot.
>>
>> There are some natural boundaries within the data, such that it can be
>> divided into subsets where within each subset the neighbour list for
> the
>> observations in the subset is no different from that generated for the
>> whole dataset.  I have also done an analysis separately for such
>> subsets, with the same result.
>>
>> Thanks in advance for any suggestions.
>>
>> John.
>>
>> -----Original Message-----
>> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>> Sent: Thursday, March 24, 2011 1:27 AM
>> To: Janmaat, John
>> Cc: r-sig-geo at r-project.org
>> Subject: Re: [R-sig-Geo] Spatial Lag and Error Model
>>
>> On Wed, 23 Mar 2011, Janmaat, John wrote:
>>
>>> Hello,
>>>
>>>
>>>
>>> I have a city water use dataset with almost 12000 observations.  I am
>>> using spdep.  I am using K nearest neighbours (4) to build the
>> neighbour
>>> list.  I am trying to estimate a model to predict household water
> use,
>>> controlling for a set of independent variables like lot size, house
>>> size, etc.  The spatial model diagnostics, lm.LMtests, suggests that
>>> there is both a spatial error and a spatial lag in the data.
> However,
>>> on the lm estimations (lagsarlm,errorsarlm), report that the system
> is
>>> singular.  I can estimate the model using GMerrorsar and lagmess.
>>> However, gstsls exits with the same error as the lm estimations.
>>>
>>> Is there a function I am missing to estimate a model with both
> spatial
>>> autocorrelation and a spatial lagged dependent variable that won't
>> have
>>> the singularity problem?
>>>
>>
>> Well, what we are missing are the verbatim error messages and function
>> calls. It may well be that your diagnosis of the problem is not
> precise
>> enough, especially as the code used depends on your choice of input
>> arguments. Does lm() of the same model report any unfitted
> coefficients
>> (are there near-linear dependencies present in the X variables, or
>> between
>> X and WX)?
>>
>> Roger
>>
>>>
>>>
>>> Thanks,
>>>
>>>
>>>
>>> John.
>>>
>>>
>>>
>>> --------------------
>>>
>>> Dr. John Janmaat
>>>
>>> Department of Economics
>>>
>>> I.K. Barber School of Arts and Sciences
>>>
>>> University of British Columbia - Okanagan Campus
>>>
>>> 3333 University Way, Kelowna, BC
>>>
>>> V1V 1V7
>>>
>>> Tel: (250)807-8021
>>>
>>> WWW: http://people.ok.ubc.ca/jjanmaat/
>>>
>>>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From John.Janmaat at ubc.ca  Sun Mar 27 06:27:11 2011
From: John.Janmaat at ubc.ca (Janmaat, John)
Date: Sat, 26 Mar 2011 21:27:11 -0700
Subject: [R-sig-Geo] Spatial Lag and Error Model
In-Reply-To: <alpine.LRH.2.00.1103261155500.19154@reclus.nhh.no>
References: <C91442134EEFE4408AD950F07899435C1C982F@exchange22.mercury.ad.ubc.ca>
	<alpine.LRH.2.00.1103240913070.8949@reclus.nhh.no>
	<C91442134EEFE4408AD950F07899435C1C9832@exchange22.mercury.ad.ubc.ca>
	<C91442134EEFE4408AD950F07899435C1C9834@exchange22.mercury.ad.ubc.ca>
	<alpine.LRH.2.00.1103251211220.13042@reclus.nhh.no>
	<C91442134EEFE4408AD950F07899435C1C9835@exchange22.mercury.ad.ubc.ca>
	<alpine.LRH.2.00.1103261155500.19154@reclus.nhh.no>
Message-ID: <C91442134EEFE4408AD950F07899435C1C983C@exchange22.mercury.ad.ubc.ca>

I have read the documentation, and have tried both the LU and MC
methods.  I continue to get a similar error.  With a subset of the data
and a simplified model, then it will execute the command.  In my case, I
am using both linear and quadratic terms for some independent variables
to capture curvature in the marginal effects.  These quadratic terms do
enter strongly significantly in the linear model, but seem to cause
problems for errorsarlm() and lagsarlm(), particularly when the full
sample is used.  

Thanks again for the comments.  

John.

-----Original Message-----
From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Sent: Saturday, March 26, 2011 4:03 AM
To: Janmaat, John
Cc: r-sig-geo at r-project.org
Subject: RE: [R-sig-Geo] Spatial Lag and Error Model

On Fri, 25 Mar 2011, Janmaat, John wrote:

> Hello again,
>
> Thanks for the suggestion of updating the packages.  That dealt with
one
> issue.  For the rest, here is some of the info you asked for.  For
> errorsarlm and lagsarlm I get a memory allocation problem.
>
>> sessionInfo()
> R version 2.12.1 (2010-12-16)
> Platform: i386-pc-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252    LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                           LC_TIME=English_United
> States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
> other attached packages:
> [1] RANN_2.1.2         pgirmess_1.5.1     spdep_0.5-29
> coda_0.14-2        deldir_0.0-13      nlme_3.1-98        MASS_7.3-11
> Matrix_0.999375-48
> [9] boot_1.2-43        spgwr_0.6-10       maptools_0.8-4
> lattice_0.19-17    foreign_0.8-42     sp_0.9-79
>
> loaded via a namespace (and not attached):
> [1] grid_2.12.1  tools_2.12.1
>
> Here are the error messages when commands run for full sample:
>
>> wd.GMerrorsarSum <- GMerrorsar(frmSum,data=wd2,weightings)
>> wd.GMerrorsarWin <- GMerrorsar(frmWin,data=wd2,weightings)
>> wd.errorsarSum <- errorsarlm(frmSum,data=wd2,weightings)
> Error: cannot allocate vector of size 922.5 Mb

See ?errorrsarlm, method= argument. You should not expect to be able to 
use dense matrix methods with as many observations. For k nearest 
neighbours, I suggest LU for an exact result, perhaps MC for an 
approximation.

>> wd.errorsarWin <- errorsarlm(frmWin,data=wd2,weightings)
> Error: cannot allocate vector of size 922.5 Mb

Ditto.

>> wd.MESSlagsarSum <- lagmess(frmSum,data=wd2,weightings)
>> wd.MESSlagsarWin <- lagmess(frmWin,data=wd2,weightings)
>> wd.lagsarSum <- lagsarlm(frmSum,data=wd2,weightings)
> Error: cannot allocate vector of size 922.5 Mb

Ditto - ?lagsarlm

>> wd.lagsarWin <- lagsarlm(frmWin,data=wd2,weightings)
> Error: cannot allocate vector of size 922.5 Mb

Ditto.

You may also see singularities because your RHS variables appear to be 
close to colinear.

>> wd.GMerrorsarSum <- gstsls(frmSum, data=wd2,weightings)
>> wd.GMerrorsarWin <- gstsls(frmWin, data=wd2,weightings)
>
> If I run the same set of commands on a subset of the data, then the
> command output is:
>
>> wd.GMerrorsarSum <- GMerrorsar(frmSum,data=wd2,weightings)
>> wd.GMerrorsarWin <- GMerrorsar(frmWin,data=wd2,weightings)
>> wd.errorsarSum <- errorsarlm(frmSum,data=wd2,weightings)
> Error in solve.default(asyvar, tol = tol.solve) :
>  system is computationally singular: reciprocal condition number =
> 8.6909e-27
>> wd.errorsarWin <- errorsarlm(frmWin,data=wd2,weightings)
> Error in solve.default(asyvar, tol = tol.solve) :
>  system is computationally singular: reciprocal condition number =
> 8.34845e-27

Both of these come when inverting the asymmetric covariance matrix of
the 
variables, read about why this happens on the function help pages - it
is 
described in details, and may also concern the scaling of your
variables.

>> wd.MESSlagsarSum <- lagmess(frmSum,data=wd2,weightings)
>> wd.MESSlagsarWin <- lagmess(frmWin,data=wd2,weightings)
>> wd.lagsarSum <- lagsarlm(frmSum,data=wd2,weightings)
> Error in solve.default(inf, tol = tol.solve) :
>  system is computationally singular: reciprocal condition number =
> 7.82721e-27
>> wd.lagsarWin <- lagsarlm(frmWin,data=wd2,weightings)
> Error in solve.default(inf, tol = tol.solve) :
>  system is computationally singular: reciprocal condition number =
> 7.81985e-27

Ditto.

>> wd.GMerrorsarSum <- gstsls(frmSum, data=wd2,weightings)
>> wd.GMerrorsarWin <- gstsls(frmWin, data=wd2,weightings)
>>
>
> Suggestions?
>

Read the function help pages fully before you use the functions?

Roger

>
>
> -----Original Message-----
> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Sent: Friday, March 25, 2011 4:12 AM
> To: Janmaat, John
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] Spatial Lag and Error Model
>
> On Thu, 24 Mar 2011, Janmaat, John wrote:
>
>>
>>
>> -----Original Message-----
>> From: Janmaat, John
>> Sent: Thursday, March 24, 2011 3:40 PM
>> To: 'Roger.Bivand at nhh.no'
>> Subject: RE: [R-sig-Geo] Spatial Lag and Error Model
>>
>> Hello Roger,
>>
>> Thanks for your reply.
>>
>> A code snippet:
>>
>> nl <- knearneigh(cbind(wd2$Long,wd2$Lat),k=4)
>> nb <- knn2nb(nl)
>> weightings <- nb2listw(nb)
>> wd.GMerrorsarSum <- gstsls(frmWin, data=wd2,weightings)
>>
>> The error message:
>>
>> Error in solve.default(QQ, Qye) :
>>  system is computationally singular: reciprocal condition number =
>> 4.20784e-28
>>
>> There are 10,996 observations.
>
> You did not provide sessionInfo() output. If you update spdep, you'll
> find
> that this issue (of poorly conditioned crossproduct matrices in the
> stsls
> step) was addressed in December 2010, and the current release should
> work.
>
> The code and error messages from errorsarlm() and lagsarlm() will
> probably
> also show other misunderstandings, but that can be addressed if you
post
>
> them.
>
> Hope this helps,
>
> Roger
>
>>
>> The dataset has been processed to remove any overlapping points (no
> zero
>> distances) and to remove points that do not have at least one
> neighbour
>> within 100m.  Overlapping points existed as accounts would change
when
> a
>> resident moved, leading to multiple observations for a single lot.
> This
>> is what I originally thought could be the issue, as there are then
> zero
>> distances.  It has also had all observations with NA removed.  The
> model
>> represented in frmWin is solved fine by lm(), with no variables
> dropped.
>>
>> I'm not sure how to check for near linear dependence in WX though, so
> I
>> would appreciate it if you could direct me there.
>>
>> I am using k nearest neighbours, as opposed to rook or queen as my
> data
>> has lat and long for the lot centroid, as opposed to a polygon for
> each
>> lot.
>>
>> There are some natural boundaries within the data, such that it can
be
>> divided into subsets where within each subset the neighbour list for
> the
>> observations in the subset is no different from that generated for
the
>> whole dataset.  I have also done an analysis separately for such
>> subsets, with the same result.
>>
>> Thanks in advance for any suggestions.
>>
>> John.
>>
>> -----Original Message-----
>> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>> Sent: Thursday, March 24, 2011 1:27 AM
>> To: Janmaat, John
>> Cc: r-sig-geo at r-project.org
>> Subject: Re: [R-sig-Geo] Spatial Lag and Error Model
>>
>> On Wed, 23 Mar 2011, Janmaat, John wrote:
>>
>>> Hello,
>>>
>>>
>>>
>>> I have a city water use dataset with almost 12000 observations.  I
am
>>> using spdep.  I am using K nearest neighbours (4) to build the
>> neighbour
>>> list.  I am trying to estimate a model to predict household water
> use,
>>> controlling for a set of independent variables like lot size, house
>>> size, etc.  The spatial model diagnostics, lm.LMtests, suggests that
>>> there is both a spatial error and a spatial lag in the data.
> However,
>>> on the lm estimations (lagsarlm,errorsarlm), report that the system
> is
>>> singular.  I can estimate the model using GMerrorsar and lagmess.
>>> However, gstsls exits with the same error as the lm estimations.
>>>
>>> Is there a function I am missing to estimate a model with both
> spatial
>>> autocorrelation and a spatial lagged dependent variable that won't
>> have
>>> the singularity problem?
>>>
>>
>> Well, what we are missing are the verbatim error messages and
function
>> calls. It may well be that your diagnosis of the problem is not
> precise
>> enough, especially as the code used depends on your choice of input
>> arguments. Does lm() of the same model report any unfitted
> coefficients
>> (are there near-linear dependencies present in the X variables, or
>> between
>> X and WX)?
>>
>> Roger
>>
>>>
>>>
>>> Thanks,
>>>
>>>
>>>
>>> John.
>>>
>>>
>>>
>>> --------------------
>>>
>>> Dr. John Janmaat
>>>
>>> Department of Economics
>>>
>>> I.K. Barber School of Arts and Sciences
>>>
>>> University of British Columbia - Okanagan Campus
>>>
>>> 3333 University Way, Kelowna, BC
>>>
>>> V1V 1V7
>>>
>>> Tel: (250)807-8021
>>>
>>> WWW: http://people.ok.ubc.ca/jjanmaat/
>>>
>>>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From v8extra at gmail.com  Sun Mar 27 19:28:37 2011
From: v8extra at gmail.com (=?iso-8859-1?Q?S=E9bastien_Durand?=)
Date: Sun, 27 Mar 2011 13:28:37 -0400
Subject: [R-sig-Geo] Minor tick marks in spplot
Message-ID: <2CBA40BA-2367-437C-BEEF-4DCF0DF780EE@gmail.com>

Hello to all,

I wish to add minor tick mark to the already existing major tick marks on the following plot 

I wish those minor tick marks to be shorter and grey

Here is an example...

data(meuse.grid)
m = SpatialPixelsDataFrame(points = meuse.grid[c("x", "y")], data = meuse.grid)

spplot(m, zcol="dist", contour=TRUE, pretty=TRUE, 
 		scales=  list(draw = TRUE, alternating=c(1,0), tck=c(1,0)))


# I have tried the yscale.components.subticks and xscale.components.subticks but I am not able to make it work when I used the spplot...

Any hints...

Thanks a lot.

From Roger.Bivand at nhh.no  Sun Mar 27 21:13:42 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 27 Mar 2011 21:13:42 +0200 (CEST)
Subject: [R-sig-Geo] Spatial Lag and Error Model
In-Reply-To: <C91442134EEFE4408AD950F07899435C1C983C@exchange22.mercury.ad.ubc.ca>
References: <C91442134EEFE4408AD950F07899435C1C982F@exchange22.mercury.ad.ubc.ca>
	<alpine.LRH.2.00.1103240913070.8949@reclus.nhh.no>
	<C91442134EEFE4408AD950F07899435C1C9832@exchange22.mercury.ad.ubc.ca>
	<C91442134EEFE4408AD950F07899435C1C9834@exchange22.mercury.ad.ubc.ca>
	<alpine.LRH.2.00.1103251211220.13042@reclus.nhh.no>
	<C91442134EEFE4408AD950F07899435C1C9835@exchange22.mercury.ad.ubc.ca>
	<alpine.LRH.2.00.1103261155500.19154@reclus.nhh.no>
	<C91442134EEFE4408AD950F07899435C1C983C@exchange22.mercury.ad.ubc.ca>
Message-ID: <alpine.LRH.2.00.1103272104120.25559@reclus.nhh.no>

On Sat, 26 Mar 2011, Janmaat, John wrote:

> I have read the documentation, and have tried both the LU and MC
> methods.  I continue to get a similar error.  With a subset of the data
> and a simplified model, then it will execute the command.  In my case, I
> am using both linear and quadratic terms for some independent variables
> to capture curvature in the marginal effects.  These quadratic terms do
> enter strongly significantly in the linear model, but seem to cause
> problems for errorsarlm() and lagsarlm(), particularly when the full
> sample is used.

You are still not providing verbatim commands and error messages; adding 
the output of traceback() after the error would also show more. Have you 
read LeSage & Pace (2009) on mixed numerical Hessians, and seen that the 
ML fitting functions have an argument called trs= which may be used to 
provide traces of the power series of W, generated by trW(), see ?trW to 
see how to do this, and choose the "MC" type. This may relieve the 
problem, but without seeing the complete command you are executing, it is 
very difficult to tell.

If the quadratic terms are of very large or very small numbers, you may 
prefer to rescale the linear to something more modest. You need to realise 
that computers carry out numerical operations on the data you have given - 
models that may look OK on paper will fall over when estimated for all 
kinds of numerical reasons. Did you consider using orthogonal polynomials 
from poly() instead of powers - this may be numerically more stable?

Roger

>
> Thanks again for the comments.
>
> John.
>
> -----Original Message-----
> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Sent: Saturday, March 26, 2011 4:03 AM
> To: Janmaat, John
> Cc: r-sig-geo at r-project.org
> Subject: RE: [R-sig-Geo] Spatial Lag and Error Model
>
> On Fri, 25 Mar 2011, Janmaat, John wrote:
>
>> Hello again,
>>
>> Thanks for the suggestion of updating the packages.  That dealt with
> one
>> issue.  For the rest, here is some of the info you asked for.  For
>> errorsarlm and lagsarlm I get a memory allocation problem.
>>
>>> sessionInfo()
>> R version 2.12.1 (2010-12-16)
>> Platform: i386-pc-mingw32/i386 (32-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>> States.1252    LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C                           LC_TIME=English_United
>> States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>
>> other attached packages:
>> [1] RANN_2.1.2         pgirmess_1.5.1     spdep_0.5-29
>> coda_0.14-2        deldir_0.0-13      nlme_3.1-98        MASS_7.3-11
>> Matrix_0.999375-48
>> [9] boot_1.2-43        spgwr_0.6-10       maptools_0.8-4
>> lattice_0.19-17    foreign_0.8-42     sp_0.9-79
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.12.1  tools_2.12.1
>>
>> Here are the error messages when commands run for full sample:
>>
>>> wd.GMerrorsarSum <- GMerrorsar(frmSum,data=wd2,weightings)
>>> wd.GMerrorsarWin <- GMerrorsar(frmWin,data=wd2,weightings)
>>> wd.errorsarSum <- errorsarlm(frmSum,data=wd2,weightings)
>> Error: cannot allocate vector of size 922.5 Mb
>
> See ?errorrsarlm, method= argument. You should not expect to be able to
> use dense matrix methods with as many observations. For k nearest
> neighbours, I suggest LU for an exact result, perhaps MC for an
> approximation.
>
>>> wd.errorsarWin <- errorsarlm(frmWin,data=wd2,weightings)
>> Error: cannot allocate vector of size 922.5 Mb
>
> Ditto.
>
>>> wd.MESSlagsarSum <- lagmess(frmSum,data=wd2,weightings)
>>> wd.MESSlagsarWin <- lagmess(frmWin,data=wd2,weightings)
>>> wd.lagsarSum <- lagsarlm(frmSum,data=wd2,weightings)
>> Error: cannot allocate vector of size 922.5 Mb
>
> Ditto - ?lagsarlm
>
>>> wd.lagsarWin <- lagsarlm(frmWin,data=wd2,weightings)
>> Error: cannot allocate vector of size 922.5 Mb
>
> Ditto.
>
> You may also see singularities because your RHS variables appear to be
> close to colinear.
>
>>> wd.GMerrorsarSum <- gstsls(frmSum, data=wd2,weightings)
>>> wd.GMerrorsarWin <- gstsls(frmWin, data=wd2,weightings)
>>
>> If I run the same set of commands on a subset of the data, then the
>> command output is:
>>
>>> wd.GMerrorsarSum <- GMerrorsar(frmSum,data=wd2,weightings)
>>> wd.GMerrorsarWin <- GMerrorsar(frmWin,data=wd2,weightings)
>>> wd.errorsarSum <- errorsarlm(frmSum,data=wd2,weightings)
>> Error in solve.default(asyvar, tol = tol.solve) :
>>  system is computationally singular: reciprocal condition number =
>> 8.6909e-27
>>> wd.errorsarWin <- errorsarlm(frmWin,data=wd2,weightings)
>> Error in solve.default(asyvar, tol = tol.solve) :
>>  system is computationally singular: reciprocal condition number =
>> 8.34845e-27
>
> Both of these come when inverting the asymmetric covariance matrix of
> the
> variables, read about why this happens on the function help pages - it
> is
> described in details, and may also concern the scaling of your
> variables.
>
>>> wd.MESSlagsarSum <- lagmess(frmSum,data=wd2,weightings)
>>> wd.MESSlagsarWin <- lagmess(frmWin,data=wd2,weightings)
>>> wd.lagsarSum <- lagsarlm(frmSum,data=wd2,weightings)
>> Error in solve.default(inf, tol = tol.solve) :
>>  system is computationally singular: reciprocal condition number =
>> 7.82721e-27
>>> wd.lagsarWin <- lagsarlm(frmWin,data=wd2,weightings)
>> Error in solve.default(inf, tol = tol.solve) :
>>  system is computationally singular: reciprocal condition number =
>> 7.81985e-27
>
> Ditto.
>
>>> wd.GMerrorsarSum <- gstsls(frmSum, data=wd2,weightings)
>>> wd.GMerrorsarWin <- gstsls(frmWin, data=wd2,weightings)
>>>
>>
>> Suggestions?
>>
>
> Read the function help pages fully before you use the functions?
>
> Roger
>
>>
>>
>> -----Original Message-----
>> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>> Sent: Friday, March 25, 2011 4:12 AM
>> To: Janmaat, John
>> Cc: r-sig-geo at r-project.org
>> Subject: Re: [R-sig-Geo] Spatial Lag and Error Model
>>
>> On Thu, 24 Mar 2011, Janmaat, John wrote:
>>
>>>
>>>
>>> -----Original Message-----
>>> From: Janmaat, John
>>> Sent: Thursday, March 24, 2011 3:40 PM
>>> To: 'Roger.Bivand at nhh.no'
>>> Subject: RE: [R-sig-Geo] Spatial Lag and Error Model
>>>
>>> Hello Roger,
>>>
>>> Thanks for your reply.
>>>
>>> A code snippet:
>>>
>>> nl <- knearneigh(cbind(wd2$Long,wd2$Lat),k=4)
>>> nb <- knn2nb(nl)
>>> weightings <- nb2listw(nb)
>>> wd.GMerrorsarSum <- gstsls(frmWin, data=wd2,weightings)
>>>
>>> The error message:
>>>
>>> Error in solve.default(QQ, Qye) :
>>>  system is computationally singular: reciprocal condition number =
>>> 4.20784e-28
>>>
>>> There are 10,996 observations.
>>
>> You did not provide sessionInfo() output. If you update spdep, you'll
>> find
>> that this issue (of poorly conditioned crossproduct matrices in the
>> stsls
>> step) was addressed in December 2010, and the current release should
>> work.
>>
>> The code and error messages from errorsarlm() and lagsarlm() will
>> probably
>> also show other misunderstandings, but that can be addressed if you
> post
>>
>> them.
>>
>> Hope this helps,
>>
>> Roger
>>
>>>
>>> The dataset has been processed to remove any overlapping points (no
>> zero
>>> distances) and to remove points that do not have at least one
>> neighbour
>>> within 100m.  Overlapping points existed as accounts would change
> when
>> a
>>> resident moved, leading to multiple observations for a single lot.
>> This
>>> is what I originally thought could be the issue, as there are then
>> zero
>>> distances.  It has also had all observations with NA removed.  The
>> model
>>> represented in frmWin is solved fine by lm(), with no variables
>> dropped.
>>>
>>> I'm not sure how to check for near linear dependence in WX though, so
>> I
>>> would appreciate it if you could direct me there.
>>>
>>> I am using k nearest neighbours, as opposed to rook or queen as my
>> data
>>> has lat and long for the lot centroid, as opposed to a polygon for
>> each
>>> lot.
>>>
>>> There are some natural boundaries within the data, such that it can
> be
>>> divided into subsets where within each subset the neighbour list for
>> the
>>> observations in the subset is no different from that generated for
> the
>>> whole dataset.  I have also done an analysis separately for such
>>> subsets, with the same result.
>>>
>>> Thanks in advance for any suggestions.
>>>
>>> John.
>>>
>>> -----Original Message-----
>>> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>> Sent: Thursday, March 24, 2011 1:27 AM
>>> To: Janmaat, John
>>> Cc: r-sig-geo at r-project.org
>>> Subject: Re: [R-sig-Geo] Spatial Lag and Error Model
>>>
>>> On Wed, 23 Mar 2011, Janmaat, John wrote:
>>>
>>>> Hello,
>>>>
>>>>
>>>>
>>>> I have a city water use dataset with almost 12000 observations.  I
> am
>>>> using spdep.  I am using K nearest neighbours (4) to build the
>>> neighbour
>>>> list.  I am trying to estimate a model to predict household water
>> use,
>>>> controlling for a set of independent variables like lot size, house
>>>> size, etc.  The spatial model diagnostics, lm.LMtests, suggests that
>>>> there is both a spatial error and a spatial lag in the data.
>> However,
>>>> on the lm estimations (lagsarlm,errorsarlm), report that the system
>> is
>>>> singular.  I can estimate the model using GMerrorsar and lagmess.
>>>> However, gstsls exits with the same error as the lm estimations.
>>>>
>>>> Is there a function I am missing to estimate a model with both
>> spatial
>>>> autocorrelation and a spatial lagged dependent variable that won't
>>> have
>>>> the singularity problem?
>>>>
>>>
>>> Well, what we are missing are the verbatim error messages and
> function
>>> calls. It may well be that your diagnosis of the problem is not
>> precise
>>> enough, especially as the code used depends on your choice of input
>>> arguments. Does lm() of the same model report any unfitted
>> coefficients
>>> (are there near-linear dependencies present in the X variables, or
>>> between
>>> X and WX)?
>>>
>>> Roger
>>>
>>>>
>>>>
>>>> Thanks,
>>>>
>>>>
>>>>
>>>> John.
>>>>
>>>>
>>>>
>>>> --------------------
>>>>
>>>> Dr. John Janmaat
>>>>
>>>> Department of Economics
>>>>
>>>> I.K. Barber School of Arts and Sciences
>>>>
>>>> University of British Columbia - Okanagan Campus
>>>>
>>>> 3333 University Way, Kelowna, BC
>>>>
>>>> V1V 1V7
>>>>
>>>> Tel: (250)807-8021
>>>>
>>>> WWW: http://people.ok.ubc.ca/jjanmaat/
>>>>
>>>>
>>>>
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>
>>>
>>
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From edzer.pebesma at uni-muenster.de  Sun Mar 27 22:13:40 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 27 Mar 2011 22:13:40 +0200
Subject: [R-sig-Geo] Minor tick marks in spplot
In-Reply-To: <2CBA40BA-2367-437C-BEEF-4DCF0DF780EE@gmail.com>
References: <2CBA40BA-2367-437C-BEEF-4DCF0DF780EE@gmail.com>
Message-ID: <4D8F9A74.4030802@uni-muenster.de>



On 03/27/2011 07:28 PM, S?bastien Durand wrote:
> Hello to all,
> 
> I wish to add minor tick mark to the already existing major tick marks on the following plot 
> 
> I wish those minor tick marks to be shorter and grey
> 
> Here is an example...
> 
> data(meuse.grid)
> m = SpatialPixelsDataFrame(points = meuse.grid[c("x", "y")], data = meuse.grid)
> 
> spplot(m, zcol="dist", contour=TRUE, pretty=TRUE, 
>  		scales=  list(draw = TRUE, alternating=c(1,0), tck=c(1,0)))
> 
> 
> # I have tried the yscale.components.subticks and xscale.components.subticks but I am not able to make it work when I used the spplot...
> 
> Any hints...

Try to get it working with levelplot, as in

library(lattice)
levelplot(dist~x+y, meuse.grid, asp = "iso", contour=TRUE, pretty=TRUE,
scales=  list(draw = TRUE, alternating=c(1,0), tck=c(1,0)))

and look in the docs of ?xyplot (which it seems you did).

If you don't get it to work there, it's beyond my control /
capabilities, and you could try the package maintainer,
deepayan.sarkar at gmail.com or r-help.

> 
> Thanks a lot.
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From nkkroy3 at gmail.com  Mon Mar 28 10:01:20 2011
From: nkkroy3 at gmail.com (Nikki roy)
Date: Mon, 28 Mar 2011 10:01:20 +0200
Subject: [R-sig-Geo] lm() with categorical and quantitative predictors
Message-ID: <AANLkTim9SKaVqtq6F9b+-odWRtzKYPZN45iQF-=ORF4Y@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110328/af8a7c8f/attachment.pl>

From hzambran.newsgroups at gmail.com  Mon Mar 28 10:47:36 2011
From: hzambran.newsgroups at gmail.com (Mauricio Zambrano)
Date: Mon, 28 Mar 2011 10:47:36 +0200
Subject: [R-sig-Geo] passing 'cutoff' to the 'autoKrige' function
 ('automap' package)
In-Reply-To: <4D8DB4A7.3050801@geo.uu.nl>
References: <AANLkTimzzQ5EKzQyGe_SKYnkeRx1F8Kez-KBnbiE_kbP@mail.gmail.com>
	<4D8DB4A7.3050801@geo.uu.nl>
Message-ID: <AANLkTikiv_g6e=Tk89vdGmrmZ0RYupb4tYM2ZuEtKdJ4@mail.gmail.com>

2011/3/26 Paul Hiemstra <p.hiemstra at geo.uu.nl>:
> Hi,
>
> The miscFitOptions parameter does not include the 'variogram' paramters. I
> will look into adding them, together with the option to set the boundaries
> manually. However, autofitVariogram at this stage defines a fixed set of
> boundaries, so I'm not sure if the parameters you mention will resort any
> effect even when passing them on. An option at this stage would be to use
> the normal krige function combined with autofitVariogram. autofitVariogram
> passes on parameters to variogram() using the ... .
>
> Could you create a new issue in the bitbucket.org account which stores
> automap [1]? This way I can keep track of the issues that need to be fixed
> for autofitVariogram.

Thanks Paul for your answer.

I created the issue in bitbucket.org, as an 'enhancement', not a bug.

If you manage to include 'cutoff' and other  'variogram' paramters
into the 'autofitVariogram' function, a way to use its value could be
(after the definition of the 'scale_number'):


    scale_number = (0.35 * sqrt((max(x) - min(x))^2 + (max(y) -
        min(y))^2)/100)
    if (!is.na(cutoff))
      scale_number <- min(scale_number, cutoff/100)
    boundaries = c(2, 4, 6, 9, 12, 15, 25, 35, 50, 65, 80, 100) * scale_number


Do you think it may work ?

In the mean time the combination of 'autofitVariogram' with 'krige'
that you mention is a nice way to overcome the issue with cutoff.

Thanks again for such a useful package.

Cheers,

Mauricio

-- 
=======================================================
FLOODS Action
Land Management and Natural Hazards Unit
Institute for Environment and Sustainability
European Commission, Joint Research Centre
work-phone : (+39)-(0332)-789588
work-fax   : (+39)-(0332)-786653
=======================================================
DISCLAIMER:
"The views expressed are purely those of the writer
and may not in any circumstances be regarded as stating
an official position of the European Commission."
=======================================================
Linux user #454569 -- Ubuntu user #17469
=======================================================
"Go as far as you can see; when you get there,
you'll be able to see farther."
(John Pierpont Morgan)

>
> cheers,
> Paul
>
> [1] https://bitbucket.org/paulhiemstra/automap/issues/new
>
> On 03/25/2011 08:57 AM, Mauricio Zambrano wrote:
>>
>> Dear list,
>>
>> Is there any way to pass the 'cutoff' argument (or 'width', or other
>> arguments of the 'variogram' function of the 'gstat' package) ?to the
>> 'autoKrige' function of the 'automap' package ?
>>
>> I tried with:
>>
>>
>>>
>>> x.ok<- autoKrige(zinc~1, meuse, meuse.grid,
>>> miscFitOptions=list(maxdist=100, ?cutoff=500, width=50) )
>>>
>>
>> but both arguments are ignored.
>>
>>
>> I also tried with:
>>
>>
>>>
>>> x.ok<- autoKrige(zinc~1, meuse, meuse.grid, maxdist=100, ?cutoff=500,
>>> width=100)
>>>
>>
>> but I got the following error message:
>>
>> "Error in gstat(formula = formula, data = locations, model = model,
>> beta = beta, ?:
>> ?unused argument(s) (cutoff = 500, width = 50)"
>>
>>
>> Some session info:
>>
>> R version 2.12.2 (2011-02-25)
>> automap_1.0-9
>> gstat_0.9-79
>>
>>
>> Here there is a reproducible example (for the 'autofitVariogram'
>> function, because I didn't find a way to pass the 'cutoff' and 'with'
>> arguments to the 'autoKrige' function):
>>
>> ------------ START ---------------
>>
>> library(automap)
>>
>> # Data preparation
>> data(meuse)
>> coordinates(meuse) =~ x+y
>> data(meuse.grid)
>> gridded(meuse.grid) =~ x+y
>>
>> # Computing the 'boundaries' value for the 'variogram' function,
>> # in order to properly compare its results with those of the
>> 'autofitVariogram' function
>>
>> input_data<- meuse
>>
>> x<- coordinates(input_data)[, 1]
>> y<- coordinates(input_data)[, 2]
>> scale_number<- (0.35 * sqrt((max(x) - min(x))^2 + (max(y) -
>> min(y))^2)/100)
>> boundaries<- c(2, 4, 6, 9, 12, 15, 25, 35, 50, 65, 80, 100) * scale_number
>>
>> # variogram computation. Case 1, default parameters
>> vgm.gstat<- variogram(zinc ~ 1, locations=meuse, boundaries=boundaries)
>> vgm.automap<- autofitVariogram(zinc ~ 1, input_data=meuse)
>>
>> # These variograms are the same
>> print(vgm.gstat)
>> print(vgm.automap$exp_var)
>>
>> # variogram computation. Case 2, with 'cutoff' and 'width'
>> vgm.gstat2<- variogram(zinc ~ 1, locations=meuse, cutoff=500, width=50)
>> vgm.automap2<- autofitVariogram(zinc ~ 1, input_data=meuse,
>> cutoff=500, width=50)
>>
>> # These variograms are NOT the same
>> print(vgm.gstat2)
>> print(vgm.automap2$exp_var)
>>
>> # variogram computation. Case 3, with 'cutoff', 'width' and 'boundaries'
>> vgm.gstat3<- variogram(zinc ~ 1, locations=meuse, cutoff=500,
>> width=50, boundaries=boundaries)
>> vgm.automap3<- autofitVariogram(zinc ~ 1, input_data=meuse,
>> cutoff=500, width=50)
>>
>> # These variograms are the same
>> print(vgm.gstat3)
>> print(vgm.automap3$exp_var)
>>
>>
>> ------------ END ---------------
>>
>>
>> Looking at the examples, I think that the problem arises because the
>> 'boundaries' argument superimpose its values to the 'cutoff' one, both
>> in the 'variogram' and 'autofitVariogram' functions.
>>
>> However, whereas in the 'variogram' function the boundaries are
>> optional, in the 'autofitVariogram' they are computed internally (in a
>> smart way), but its maximum default value disable any shorter 'cutoff'
>> passed to the 'autofitVariogram' function.
>>
>>
>> In any case, I think that even after solving the issue related to
>> 'cutoff' and 'boundaries', it will still be impossible to pass the
>> 'cutoff' argument to the 'autoKrige' function, because the '...'
>> argument in 'autoKrige' is passed (internally) to the 'krige' function
>> and not to 'autofitVariogram' one. Am I right ?
>>
>> I'm not sure if this could be considered a bug, but I thought it could
>> be useful to report this behaviour, for the next release of 'automap'.
>>
>>
>> Kind regards,
>>
>> Mauricio Zambrano B.
>>
>>
>>
>
>
> --
> Paul Hiemstra, MSc
> Department of Physical Geography
> Faculty of Geosciences
> University of Utrecht
> Heidelberglaan 2
> P.O. Box 80.115
> 3508 TC Utrecht
> Phone: ?+3130 253 5773
> http://intamap.geo.uu.nl/~paul
> http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770
>
> currently @ KNMI
> paul.hiemstra_AT_knmi.nl
>
>


From karl at huftis.org  Mon Mar 28 11:41:16 2011
From: karl at huftis.org (Karl Ove Hufthammer)
Date: Mon, 28 Mar 2011 11:41:16 +0200
Subject: [R-sig-Geo] =?utf-8?q?Handling_invalid_geometries_from_the_?=
	=?utf-8?b?4oCYbWFwZGF0YeKAmSBwYWNrYWdl?=
Message-ID: <impl33$98k$1@dough.gmane.org>

I have discovered what looks like a geometry error in data from ?worldHires?
data set. Here?s an illustration:

library(rgeos)
library(rgdal)o 
library(mapdata)
library(maptools)

x.map = map("worldHires", "Norway", fill=TRUE, col="transparent", plot=FALSE, xlim=c(0,40), ylim=c(50,73))
x.sp = map2SpatialPolygons(x.map, x.map$names, proj4string=CRS("+init=epsg:4326"))

plot(x.sp)            # *Looks* OK
gPointOnSurface(x.sp) # Error: TopologyException: side location conflict at 3.97911 0.0769463
gIsValid(x.sp)        # Error: Self-intersection at or near point 27.9364 70.0864
points(27.9364, 70.0864, col="red", pch=19)

I guess this is to be be expected, as the ?worldHires? data isn?t of very
high quality, and is not guaranteed to be consistent. My questions are 
1) is it possible to automatically ?fix? this problem inside R, and 
2) what other problems may I expect from continuing to use the invalid data?

-- 
Regards,
Karl Ove Hufthammer


From masha.pautrel at gmail.com  Mon Mar 28 11:55:10 2011
From: masha.pautrel at gmail.com (Masha Pautrel)
Date: Mon, 28 Mar 2011 11:55:10 +0200
Subject: [R-sig-Geo] general weights in spatial weights matrix
Message-ID: <AANLkTi=FK4=e=f-hMmsDhnyqxGs3u45JuxudPLeDZZsB@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110328/cf51242e/attachment.pl>

From Roger.Bivand at nhh.no  Mon Mar 28 12:06:09 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 28 Mar 2011 12:06:09 +0200
Subject: [R-sig-Geo]
	=?iso-8859-7?q?Handling_invalid_geometries_from_the_?=
	=?iso-8859-7?q?=A1mapdata=A2_package?=
In-Reply-To: <impl33$98k$1@dough.gmane.org>
References: <impl33$98k$1@dough.gmane.org>
Message-ID: <alpine.LRH.2.00.1103281157340.27642@reclus.nhh.no>

On Mon, 28 Mar 2011, Karl Ove Hufthammer wrote:

> I have discovered what looks like a geometry error in data from ?worldHires?
> data set. Here?s an illustration:
>
> library(rgeos)
> library(rgdal)o 
> library(mapdata)
> library(maptools)
>
> x.map = map("worldHires", "Norway", fill=TRUE, col="transparent", plot=FALSE, xlim=c(0,40), ylim=c(50,73))
> x.sp = map2SpatialPolygons(x.map, x.map$names, proj4string=CRS("+init=epsg:4326"))
>
> plot(x.sp)            # *Looks* OK
> gPointOnSurface(x.sp) # Error: TopologyException: side location conflict at 3.97911 0.0769463
> gIsValid(x.sp)        # Error: Self-intersection at or near point 27.9364 70.0864
> points(27.9364, 70.0864, col="red", pch=19)
>
> I guess this is to be be expected, as the ?worldHires? data isn?t of very
> high quality, and is not guaranteed to be consistent. My questions are 
> 1) is it possible to automatically ?fix? this problem inside R, and 
> 2) what other problems may I expect from continuing to use the invalid data?

To start with, it is always advisible to promote the sp SpatialPolygons 
object Polygons components to GEOS compatibility:

pls <- slot(x.sp, "polygons")
pls1 <- lapply(pls, checkPolygonsHoles)
slot(x.sp, "polygons") <- pls1

which adds a comment attribute to each Polygons object assigning hole 
interior rings to their containing exterior rings.

Your problem cannot be solved automatically, but here from zooming in on 
the problem area:

gIsValid(x.sp)
plot(x.sp, xlim=c(27.9, 28), ylim=c(69.9, 70.1))

and eyeballing the bounding boxes of the Polygons objects:

lapply(pls1, bbox)

it looks as though 26 is the problem:

plot(x.sp[26], add=TRUE, border="orange")

x.sp1 <- x.sp[-26]
gIsValid(x.sp1)
gPointOnSurface(x.sp1)

Fresh releases of rgeos and maptools are on their way to CRAN, but source 
may be checked out from R-Forge now (the package builds there are of 
yesterday's version).

Hope this helps,

Roger

>
> -- 
> Regards,
> Karl Ove Hufthammer
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From karl at huftis.org  Mon Mar 28 13:07:29 2011
From: karl at huftis.org (Karl Ove Hufthammer)
Date: Mon, 28 Mar 2011 13:07:29 +0200
Subject: [R-sig-Geo] =?utf-8?q?Handling_invalid_geometries_from_the_?=
	=?utf-8?b?4oCYbWFwZGF0YeKAmSBwYWNrYWdl?=
References: <impl33$98k$1@dough.gmane.org>
	<alpine.LRH.2.00.1103281157340.27642@reclus.nhh.no>
Message-ID: <impq4q$71r$1@dough.gmane.org>

Roger Bivand wrote:

> Your problem cannot be solved automatically, but here from zooming in on
> the problem area:
> 
> gIsValid(x.sp)
> plot(x.sp, xlim=c(27.9, 28), ylim=c(69.9, 70.1))
> 
> and eyeballing the bounding boxes of the Polygons objects:
> 
> lapply(pls1, bbox)
> 
> it looks as though 26 is the problem:
> 
> plot(x.sp[26], add=TRUE, border="orange")
> 
> x.sp1 <- x.sp[-26]
> gIsValid(x.sp1)
> gPointOnSurface(x.sp1)

Thanks! That helped. ?Norway:Tana? is really a very strange polygon ... :)

I also tried running your procedure on the whole ?worldHires?, to see if 
this is a frequent problem. The idea was to run

  status=gIsValid(x.sp, byid=TRUE)
  status[!status]

to get a list of invalid polygons (though perhaps the SpatialPolygons object 
may be invalid even if all the sub-polygons are valid?)

First I had to remove the proj4string, as some of the polygons are outside 
the [-180, 180] range. And it turned out that I got an error message already 
at the

  pls <- slot(x.sp, "polygons")
  pls1 <- lapply(pls, checkPolygonsHoles)
  slot(x.sp, "polygons") <- pls1

step.

So I guess it?s better to stay away from the ?worldHires? data set,
and use GSHHS instead ? :-/

-- 
Karl Ove Hufthammer


From Roger.Bivand at nhh.no  Mon Mar 28 14:12:43 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 28 Mar 2011 14:12:43 +0200
Subject: [R-sig-Geo]
	=?iso-8859-7?q?Handling_invalid_geometries_from_the_?=
	=?iso-8859-7?q?=A1mapdata=A2_package?=
In-Reply-To: <impq4q$71r$1@dough.gmane.org>
References: <impl33$98k$1@dough.gmane.org>
	<alpine.LRH.2.00.1103281157340.27642@reclus.nhh.no>
	<impq4q$71r$1@dough.gmane.org>
Message-ID: <alpine.LRH.2.00.1103281409440.28479@reclus.nhh.no>

On Mon, 28 Mar 2011, Karl Ove Hufthammer wrote:

> Roger Bivand wrote:
>
>> Your problem cannot be solved automatically, but here from zooming in on
>> the problem area:
>> 
>> gIsValid(x.sp)
>> plot(x.sp, xlim=c(27.9, 28), ylim=c(69.9, 70.1))
>> 
>> and eyeballing the bounding boxes of the Polygons objects:
>> 
>> lapply(pls1, bbox)
>> 
>> it looks as though 26 is the problem:
>> 
>> plot(x.sp[26], add=TRUE, border="orange")
>> 
>> x.sp1 <- x.sp[-26]
>> gIsValid(x.sp1)
>> gPointOnSurface(x.sp1)
>
> Thanks! That helped. ?Norway:Tana? is really a very strange polygon ... :)
>
> I also tried running your procedure on the whole ?worldHires?, to see if 
> this is a frequent problem. The idea was to run
>
>  status=gIsValid(x.sp, byid=TRUE)
>  status[!status]
>
> to get a list of invalid polygons (though perhaps the SpatialPolygons object 
> may be invalid even if all the sub-polygons are valid?)
>
> First I had to remove the proj4string, as some of the polygons are outside 
> the [-180, 180] range. And it turned out that I got an error message already 
> at the
>
>  pls <- slot(x.sp, "polygons")
>  pls1 <- lapply(pls, checkPolygonsHoles)
>  slot(x.sp, "polygons") <- pls1

If the error was:

> pls1 <- lapply(pls, checkPolygonsHoles)
Error in RGEOSBinPredFunc(spgeom1, spgeom2, byid, "rgeos_equals") :
   TopologyException: side location conflict at 78.9364 33.4081

then I can reproduce it, and will examine whether it can be handled - the 
checkPolygonsHoles() function also uses GEOS, but probably should warn 
after failing try(gEquals(...)).

Was this your error?

Throwing bad data at maptools/rgeos is a nice way of stress-testing it.

Roger

>
> step.
>
> So I guess it?s better to stay away from the ?worldHires? data set,
> and use GSHHS instead ? :-/
>
> -- 
> Karl Ove Hufthammer
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From karl at huftis.org  Mon Mar 28 15:04:30 2011
From: karl at huftis.org (Karl Ove Hufthammer)
Date: Mon, 28 Mar 2011 15:04:30 +0200
Subject: [R-sig-Geo] =?utf-8?q?Handling_invalid_geometries_from_the_?=
	=?utf-8?b?4oCYbWFwZGF0YeKAmSBwYWNrYWdl?=
References: <impl33$98k$1@dough.gmane.org>
	<alpine.LRH.2.00.1103281157340.27642@reclus.nhh.no>
	<impq4q$71r$1@dough.gmane.org>
	<alpine.LRH.2.00.1103281409440.28479@reclus.nhh.no>
Message-ID: <imq105$gln$1@dough.gmane.org>

Roger Bivand wrote:

>> pls1 <- lapply(pls, checkPolygonsHoles)
> Error in RGEOSBinPredFunc(spgeom1, spgeom2, byid, "rgeos_equals") :
> TopologyException: side location conflict at 78.9364 33.4081
> 
> then I can reproduce it, and will examine whether it can be handled - the
> checkPolygonsHoles() function also uses GEOS, but probably should warn
> after failing try(gEquals(...)).
> 
> Was this your error?

Yes.

I also eventually managed to get a segfault when trying various stuff like 
this, but it may have been unrelated. (At least, I can?t reproduce it.)

-- 
Karl Ove Hufthammer


From Roger.Bivand at nhh.no  Mon Mar 28 15:13:50 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 28 Mar 2011 15:13:50 +0200
Subject: [R-sig-Geo]
	=?iso-8859-7?q?Handling_invalid_geometries_from_the_?=
	=?iso-8859-7?q?=A1mapdata=A2_package?=
In-Reply-To: <imq105$gln$1@dough.gmane.org>
References: <impl33$98k$1@dough.gmane.org>
	<alpine.LRH.2.00.1103281157340.27642@reclus.nhh.no>
	<impq4q$71r$1@dough.gmane.org>
	<alpine.LRH.2.00.1103281409440.28479@reclus.nhh.no>
	<imq105$gln$1@dough.gmane.org>
Message-ID: <alpine.LRH.2.00.1103281511390.28479@reclus.nhh.no>

On Mon, 28 Mar 2011, Karl Ove Hufthammer wrote:

> Roger Bivand wrote:
>
>>> pls1 <- lapply(pls, checkPolygonsHoles)
>> Error in RGEOSBinPredFunc(spgeom1, spgeom2, byid, "rgeos_equals") :
>> TopologyException: side location conflict at 78.9364 33.4081
>> 
>> then I can reproduce it, and will examine whether it can be handled - the
>> checkPolygonsHoles() function also uses GEOS, but probably should warn
>> after failing try(gEquals(...)).
>> 
>> Was this your error?
>
> Yes.
>
> I also eventually managed to get a segfault when trying various stuff like 
> this, but it may have been unrelated. (At least, I can?t reproduce it.)

Thanks. Updating to maptools 0_8-5 and rgeos 0_1-3 (sources on CRAN now) 
should provide better protection against non-conformant data causing a 
seg-fault in GEOS - GEOS really likes its polygons *very* tidy.

Roger

>
> -- 
> Karl Ove Hufthammer
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From Roger.Bivand at nhh.no  Mon Mar 28 16:26:42 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 28 Mar 2011 16:26:42 +0200
Subject: [R-sig-Geo]
	=?iso-8859-7?q?Handling_invalid_geometries_from_the_?=
	=?iso-8859-7?q?=A1mapdata=A2_package?=
In-Reply-To: <alpine.LRH.2.00.1103281511390.28479@reclus.nhh.no>
References: <impl33$98k$1@dough.gmane.org>
	<alpine.LRH.2.00.1103281157340.27642@reclus.nhh.no>
	<impq4q$71r$1@dough.gmane.org>
	<alpine.LRH.2.00.1103281409440.28479@reclus.nhh.no>
	<imq105$gln$1@dough.gmane.org>
	<alpine.LRH.2.00.1103281511390.28479@reclus.nhh.no>
Message-ID: <alpine.LRH.2.00.1103281617470.28479@reclus.nhh.no>

On Mon, 28 Mar 2011, Roger Bivand wrote:

> On Mon, 28 Mar 2011, Karl Ove Hufthammer wrote:
>
>> Roger Bivand wrote:
>> 
>>>> pls1 <- lapply(pls, checkPolygonsHoles)
>>> Error in RGEOSBinPredFunc(spgeom1, spgeom2, byid, "rgeos_equals") :
>>> TopologyException: side location conflict at 78.9364 33.4081
>>> 
>>> then I can reproduce it, and will examine whether it can be handled - the
>>> checkPolygonsHoles() function also uses GEOS, but probably should warn
>>> after failing try(gEquals(...)).
>>> 
>>> Was this your error?
>> 
>> Yes.
>> 
>> I also eventually managed to get a segfault when trying various stuff like 
>> this, but it may have been unrelated. (At least, I can?t reproduce it.)
>
> Thanks. Updating to maptools 0_8-5 and rgeos 0_1-3 (sources on CRAN now) 
> should provide better protection against non-conformant data causing a 
> seg-fault in GEOS - GEOS really likes its polygons *very* tidy.

The attached plot shows this issue, which is in the area between northern 
India, Kashmir, and China, so perhaps reality is more complicated than 
GEOS prefers? I've only plotted the border given in the data set for 
China, which includes the odd reversed straight line. If I include other 
borders, I see a line starting at right angles to the northern end of this 
line and heading WSW, which may be another demarcation line. Apart from 
this case, the rest of worldHires got through OK - the maptools code on 
SVN now reports:

> pls1 <- lapply(pls, checkPolygonsHoles)
Warning message:
In checkPolygonsGEOS(x, properly = properly) :
   Polygons object China, Polygon 1: Error in RGEOSBinPredFunc(spgeom1, 
spgeom2, byid, "rgeos_equals") :
   TopologyException: side location conflict at 78.9364 33.4081

instead of failing.

Roger

>
> Roger
>
>> 
>> -- 
>> Karl Ove Hufthammer
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ch.png
Type: image/png
Size: 6821 bytes
Desc: ch.png
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110328/1afb148a/attachment.png>

From p.hiemstra at geo.uu.nl  Mon Mar 28 20:27:41 2011
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 28 Mar 2011 20:27:41 +0200
Subject: [R-sig-Geo] passing 'cutoff' to the 'autoKrige' function
 ('automap' package)
In-Reply-To: <AANLkTikiv_g6e=Tk89vdGmrmZ0RYupb4tYM2ZuEtKdJ4@mail.gmail.com>
References: <AANLkTimzzQ5EKzQyGe_SKYnkeRx1F8Kez-KBnbiE_kbP@mail.gmail.com>	<4D8DB4A7.3050801@geo.uu.nl>
	<AANLkTikiv_g6e=Tk89vdGmrmZ0RYupb4tYM2ZuEtKdJ4@mail.gmail.com>
Message-ID: <4D90D31D.1020609@geo.uu.nl>

On 03/28/2011 10:47 AM, Mauricio Zambrano wrote:
> 2011/3/26 Paul Hiemstra<p.hiemstra at geo.uu.nl>:
>    
>> Hi,
>>
>> The miscFitOptions parameter does not include the 'variogram' paramters. I
>> will look into adding them, together with the option to set the boundaries
>> manually. However, autofitVariogram at this stage defines a fixed set of
>> boundaries, so I'm not sure if the parameters you mention will resort any
>> effect even when passing them on. An option at this stage would be to use
>> the normal krige function combined with autofitVariogram. autofitVariogram
>> passes on parameters to variogram() using the ... .
>>
>> Could you create a new issue in the bitbucket.org account which stores
>> automap [1]? This way I can keep track of the issues that need to be fixed
>> for autofitVariogram.
>>      
> Thanks Paul for your answer.
>
> I created the issue in bitbucket.org, as an 'enhancement', not a bug.
>
> If you manage to include 'cutoff' and other  'variogram' paramters
> into the 'autofitVariogram' function, a way to use its value could be
> (after the definition of the 'scale_number'):
>
>
>    

Thanks for creating the issue, I'm not sure when I'll come round to 
fixing the issue though ;). I'll probably fix the problem by giving the 
user the freedom to change all inputs to variogram(), including 
boundaries. But I'll figure that out later.

>      scale_number = (0.35 * sqrt((max(x) - min(x))^2 + (max(y) -
>          min(y))^2)/100)
>      if (!is.na(cutoff))
>        scale_number<- min(scale_number, cutoff/100)
>      boundaries = c(2, 4, 6, 9, 12, 15, 25, 35, 50, 65, 80, 100) * scale_number
>
>
> Do you think it may work ?
>    

Could be an option.

cheers,
Paul
> In the mean time the combination of 'autofitVariogram' with 'krige'
> that you mention is a nice way to overcome the issue with cutoff.
>
> Thanks again for such a useful package.
>
> Cheers,
>
> Mauricio
>
>    


-- 
Paul Hiemstra, MSc
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 253 5773
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770

currently @ KNMI
paul.hiemstra_AT_knmi.nl


From advaitgodbole at gmail.com  Mon Mar 28 20:36:01 2011
From: advaitgodbole at gmail.com (Advait Godbole)
Date: Mon, 28 Mar 2011 14:36:01 -0400
Subject: [R-sig-Geo] package raster: issue with "extent" and "stack"
Message-ID: <AANLkTikondcrrnHLncqJ03DO8WLjOTod92g0juN9jn=8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110328/145a1d4c/attachment.pl>

From Virgilio.Gomez at uclm.es  Mon Mar 28 23:57:36 2011
From: Virgilio.Gomez at uclm.es (Virgilio Gomez Rubio)
Date: Mon, 28 Mar 2011 23:57:36 +0200
Subject: [R-sig-Geo] Google Summer of Code proposal on spatial epidemiology
	with R
Message-ID: <1301349456.2446.21.camel@Virgilio-Gomez>

Dear all,

I have submitted a proposal for Google Summer of Code  2011 on spatial
epidemiology. A summary of the proposal is shown below, and full
information (including other proposals for the R Project) can be found
at

http://rwiki.sciviews.org/doku.php?id=developers:projects:gsoc2011

Note that GSoC is only open to students. Those interested in spatial
epidemiology are encouraged to apply. Please, feel free to contact me
off-list if you have any questions. Note that the student application
deadline is on the 8th of April (Friday next week).

Best wishes,

Virgilio


====== DClusterm: Model-based detection of disease clusters

Summary: Model-based detection of disease clusters

Background: The analysis of disease data is important in order to detect
disease outbreaks and links to risk factors. Some of the methods for
cluster detection have been implemented in the DCluster package.
However, a model-based approach would be of interest in order to explore
disease incidence to potential risk factors.

Description: Model-based clustering will be implemented using
Generalized Linear Models (in principle, for Poisson and Binomial
families). Clustering will be modelled as dummy variables (1=area is in
a cluster, 0=area is not is a cluster). Hence, many possible clusters
will be proposed and the most likely cluster will be selected according
to likelihood ratio test, AIC and (possibly) any other reasonable
method.

Skills required: : A good working knowledge of R and Generalized Linear
Models. Some understanding of spatial statistics will be a plus.

Test: Fit a GLM using the North Carolina SIDS data. See
example(?readShapePoly?) in maptools package. In this GLM, SID74 will be
the outcome and BIR74 a covariate; the Poisson family will be used. In
addition, a dummy variable representing a spatial cluster will be
included. This dummy variable will include 5 different contiguous
regions (i.e., the value of this dummy variable will be 1 for these 5
regions and 0 otherwise). Display the residuals of this model in a map.

Mentor: Virgilio G?mez-Rubio, University of Castilla-La Mancha
(Virgilio.Gomez at uclm.es) 


From etiennesky at yahoo.com  Tue Mar 29 03:47:32 2011
From: etiennesky at yahoo.com (Etienne)
Date: Mon, 28 Mar 2011 18:47:32 -0700 (PDT)
Subject: [R-sig-Geo] plotting of large raster dataset fails
Message-ID: <150486.98343.qm@web36905.mail.mud.yahoo.com>

Greetings,

I am trying to plot a large raster dataset (2159x925 = 2M pixels) using spplot() and it fails with the following error after about 30 seconds:

> r2=readGDAL("img/TM.burnpix.pnsc.2000-2006.freq.tif")
> image(r2)
> spplot(r2)
Error: segfault from C stack overflow

I can plot the same data fine with the image() function in less than a second.

The main problem comes from the fact that many pixels are NA's (I do not wish to include some in the analysis).  If I set the NAs to zero, I can plot the data but it takes a very long time (about 30 seconds), using 100% cpu and a lot of memory (1GB) - orders of magnitude higher than using the image() function.

Questions:

1)
Is this volume of data supported by the spplot() function, and if so is there any trick to get this working properly and faster?

2)
Can I work with NAs or must I convert them to another value (0,Nan ?)

Many thanks,
Etienne

The dataset has the following structure,:
=====
> str(r2)
Formal class 'SpatialGridDataFrame' [package "sp"] with 6 slots
  ..@ data       :'data.frame':	1997075 obs. of  1 variable:
  .. ..$ band1: num [1:1997075] NA NA NA NA NA NA NA NA NA NA ...
  ..@ grid       :Formal class 'GridTopology' [package "sp"] with 3 slots
  .. .. ..@ cellcentre.offset: Named num [1:2] 290965 7751395
  .. .. .. ..- attr(*, "names")= chr [1:2] "x" "y"
  .. .. ..@ cellsize         : num [1:2] 30 30
  .. .. ..@ cells.dim        : int [1:2] 2159 925
  ..@ grid.index : int(0) 
  ..@ coords     : num [1:2, 1:2] 290965 355704 7751395 7779115
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : NULL
  .. .. ..$ : chr [1:2] "x" "y"
  ..@ bbox       : num [1:2, 1:2] 290950 7751380 355719 7779130
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr [1:2] "x" "y"
  .. .. ..$ : chr [1:2] "min" "max"
  ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
  .. .. ..@ projargs: chr " +proj=utm +zone=23 +south +ellps=WGS84 +datum=WGS84 +units=m +no_defs +towgs84=0,0,0"
=====


From r.hijmans at gmail.com  Tue Mar 29 06:49:49 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Mon, 28 Mar 2011 21:49:49 -0700 (PDT)
Subject: [R-sig-Geo] package raster: issue with "extent" and "stack"
In-Reply-To: <AANLkTikondcrrnHLncqJ03DO8WLjOTod92g0juN9jn=8@mail.gmail.com>
References: <AANLkTikondcrrnHLncqJ03DO8WLjOTod92g0juN9jn=8@mail.gmail.com>
Message-ID: <1301374189652-6217680.post@n2.nabble.com>

Advait, 

> I encounter two errors; A) when using extent to crop the rasters 

> lims <- extent(rcmraster,180,185,300,305) 
> Error in .local(x, ...) : unused argument(s) (180, 185, 300, 305) 

> I also tried using lat-long values in place of the index to no avail. 

I cannot reproduce the problem.  You are not providing your sessionInfo(),
but I can see that you are not using the last version of raster. Perhaps
this problem goes away if you update raster.  It is also good practice to
provide to make some effort to provide a self contained example of the
problem encountered. Such as below (which suggest to me that this works):

> r <- raster(nrow=356, ncol=507)
> r[] <- 1:ncell(r)
> s <- stack(r,r,r)
> lims <- extent(r,180,185,300,305) 
> lims
class       : Extent 
xmin        : 32.66272 
xmax        : 36.21302 
ymin        : -3.286517 
ymax        : -0.758427 


if you use long/lat you would need to do something like

lims <- extent(-100, -50, 30, 40) 


and B) using stack 

s_crop <- stack(emitraster,rcmraster) 
Error in function (classes, fdef, mtable)  : 
  unable to find an inherited method for function "trim", for signature 
"integer"  

I do not know what you are trying to do here. Did you mean

s_crop <- crop(emitraster,rcmraster)   # ?

Anyway, this works for me, 

> b <- brick(s)
> ss <- stack(b,b)

But this probably goes wrong because you are using ncdf files; so that might
be a bug. I would happily download and look at those files if you could
establish first that the simple examples works for you like they work for
me, but things break if you use the files instead; and that you are using
the latest version. 

Best, 
Robert






--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/package-raster-issue-with-extent-and-stack-tp6216238p6217680.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From hzambran.newsgroups at gmail.com  Tue Mar 29 10:41:14 2011
From: hzambran.newsgroups at gmail.com (Mauricio Zambrano)
Date: Tue, 29 Mar 2011 10:41:14 +0200
Subject: [R-sig-Geo] passing 'cutoff' to the 'autoKrige' function
 ('automap' package)
In-Reply-To: <4D90D31D.1020609@geo.uu.nl>
References: <AANLkTimzzQ5EKzQyGe_SKYnkeRx1F8Kez-KBnbiE_kbP@mail.gmail.com>
	<4D8DB4A7.3050801@geo.uu.nl>
	<AANLkTikiv_g6e=Tk89vdGmrmZ0RYupb4tYM2ZuEtKdJ4@mail.gmail.com>
	<4D90D31D.1020609@geo.uu.nl>
Message-ID: <AANLkTimHGhCVEUsWj90m=O21mwJvQ7HW+O0tLaE5Jk8T@mail.gmail.com>

2011/3/28 Paul Hiemstra <p.hiemstra at geo.uu.nl>:
> On 03/28/2011 10:47 AM, Mauricio Zambrano wrote:
>>
>> 2011/3/26 Paul Hiemstra<p.hiemstra at geo.uu.nl>:
>>
>>>
>>> Hi,
>>>
>>> The miscFitOptions parameter does not include the 'variogram' paramters.
>>> I
>>> will look into adding them, together with the option to set the
>>> boundaries
>>> manually. However, autofitVariogram at this stage defines a fixed set of
>>> boundaries, so I'm not sure if the parameters you mention will resort any
>>> effect even when passing them on. An option at this stage would be to use
>>> the normal krige function combined with autofitVariogram.
>>> autofitVariogram
>>> passes on parameters to variogram() using the ... .
>>>
>>> Could you create a new issue in the bitbucket.org account which stores
>>> automap [1]? This way I can keep track of the issues that need to be
>>> fixed
>>> for autofitVariogram.
>>>
>>
>> Thanks Paul for your answer.
>>
>> I created the issue in bitbucket.org, as an 'enhancement', not a bug.
>>
>> If you manage to include 'cutoff' and other ?'variogram' paramters
>> into the 'autofitVariogram' function, a way to use its value could be
>> (after the definition of the 'scale_number'):
>>
>>
>>
>
> Thanks for creating the issue, I'm not sure when I'll come round to fixing
> the issue though ;). I'll probably fix the problem by giving the user the
> freedom to change all inputs to variogram(), including boundaries. But I'll
> figure that out later.

It would be great if -when you find the time- you can  give the user
the possibility to change all inputs to variogram().

>
>> ? ? scale_number = (0.35 * sqrt((max(x) - min(x))^2 + (max(y) -
>> ? ? ? ? min(y))^2)/100)
>> ? ? if (!is.na(cutoff))
>> ? ? ? scale_number<- min(scale_number, cutoff/100)
>> ? ? boundaries = c(2, 4, 6, 9, 12, 15, 25, 35, 50, 65, 80, 100) *
>> scale_number
>>
>>
>> Do you think it may work ?
>>
>
> Could be an option.
>
> cheers,
> Paul
>>

Cheers,

Mauricio

-- 
================================
Linux user #454569 -- Ubuntu user #17469
================================

>> In the mean time the combination of 'autofitVariogram' with 'krige'
>> that you mention is a nice way to overcome the issue with cutoff.
>>
>> Thanks again for such a useful package.
>>
>> Cheers,
>>
>> Mauricio
>>
>>
>
>
> --
> Paul Hiemstra, MSc
> Department of Physical Geography
> Faculty of Geosciences
> University of Utrecht
> Heidelberglaan 2
> P.O. Box 80.115
> 3508 TC Utrecht
> Phone: ?+3130 253 5773
> http://intamap.geo.uu.nl/~paul
> http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770
>
> currently @ KNMI
> paul.hiemstra_AT_knmi.nl
>
>


From etiennebr at gmail.com  Tue Mar 29 18:11:28 2011
From: etiennebr at gmail.com (Etienne Bellemare)
Date: Tue, 29 Mar 2011 12:11:28 -0400
Subject: [R-sig-Geo] plotting of large raster dataset fails
In-Reply-To: <150486.98343.qm@web36905.mail.mud.yahoo.com>
References: <150486.98343.qm@web36905.mail.mud.yahoo.com>
Message-ID: <AANLkTi=JE+8fq7zo1+53+ni4kz2YK=8gOZErWxEcnhTe@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110329/ba25edb1/attachment.pl>

From v8extra at gmail.com  Wed Mar 30 01:26:40 2011
From: v8extra at gmail.com (=?iso-8859-1?Q?S=E9bastien_Durand?=)
Date: Tue, 29 Mar 2011 19:26:40 -0400
Subject: [R-sig-Geo] variance estimation (gstat, geoR, automap)
Message-ID: <67B3152B-5825-467A-80A4-CD6FDEDDCFA0@gmail.com>

Have you found a way to compute the variance estimation for the surface? 

I would be happy to see how?

I'm trying to estimate the variance of a global abundance estimation 
computed by kriging interpolation and I am stuck.

I have tried to used and test the block options but I don't get the same answer.

x1=c(-1,1,9)
x2=c(-1,0,3)
x3=c(2,0,4)
x0=c(0,0)
d=rbind(x1,x2,x3)
colnames(d)=c("x","y","z")
c0=1
c=10
a=3
dist(rbind(x0,d[,1:2]))
d=data.frame(d)
coordinates(d)=~x+y
vario=variogram(z~1, d)
v=vgm(1,model="Lin",0,nugget=1)

x0=data.frame(x=0,y=0)
coordinates(x0)=~x+y
krige(formula=z~1, locations=d, newdat, model=v)
# The point estimation ?2 = var1.var, match the example value of 2.65


But for an area it is another issue and I cannont get the proper answer.



Any answers.


From v8extra at gmail.com  Wed Mar 30 03:16:17 2011
From: v8extra at gmail.com (=?iso-8859-1?Q?S=E9bastien_Durand?=)
Date: Tue, 29 Mar 2011 21:16:17 -0400
Subject: [R-sig-Geo] Variance estimation of an krigged area
Message-ID: <7918F5F7-4B9E-413F-ABD3-F78ABFE57BC8@gmail.com>

Hello list!

I am trying to find a way or a function that would allow me to get the variance estimation of an krigged area found within an SpatialPolygons

I have defined a rectangular regular SpatialGrid and krige every point in the grid. 

Now I would like know how good is my kriging and to do so I wish to to get the "variance estimation" for the whole area. 

Note I am not sure if the term "variance estimation" is a correct translation.

But any how I have been looking every where and I don't seem to find any solution to my problem 

I looked at : ?krige ?predict.gstat and many more...  

Could anybody show me how I can get to that value. 

Thanks a lot?

S?bastien

From v8extra at gmail.com  Wed Mar 30 13:48:12 2011
From: v8extra at gmail.com (=?iso-8859-1?Q?S=E9bastien_Durand?=)
Date: Wed, 30 Mar 2011 07:48:12 -0400
Subject: [R-sig-Geo] Minor tick marks in spplot
Message-ID: <0F92EE26-3D4D-4E13-BFBD-F9FD41FC4889@gmail.com>

Thanks for your help... 

I am still unable to generate those minor ticks marks but my knowledge in Lattice is greatly improving.

I have hope and if I find a solution I will come and post it here.

Thanks.

From pieter at sevenc.co.za  Wed Mar 30 14:39:46 2011
From: pieter at sevenc.co.za (Pieter Botha)
Date: Wed, 30 Mar 2011 14:39:46 +0200
Subject: [R-sig-Geo] Circles as polygons?
Message-ID: <95DCE398-2242-4646-ADE5-9482C6E6D77A@sevenc.co.za>

Hi

I have a SpatialPointsDataFrame, originating from location readings from an Android device. These readings are received as latitude / longitude as well as an accuracy reading in meters. An csv dump of the SpatialPointsDataFrame can be downloaded here: http://www.ploemp.com/opla/statp.csv

I am interested in finding points of interest that falls within an accuracy reading for a location. The sp class only supports points, lines and polygons so I guess I will have to construct a polygon that estimates the circle formed by the location with accuracy as radius?

Any pointers here?

Thanks,
Pieter



-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.


From villers.alexandre at gmail.com  Wed Mar 30 14:48:43 2011
From: villers.alexandre at gmail.com (Alexandre Villers)
Date: Wed, 30 Mar 2011 15:48:43 +0300
Subject: [R-sig-Geo] Circles as polygons?
In-Reply-To: <95DCE398-2242-4646-ADE5-9482C6E6D77A@sevenc.co.za>
References: <95DCE398-2242-4646-ADE5-9482C6E6D77A@sevenc.co.za>
Message-ID: <4D9326AB.4050004@gmail.com>

Hi,

Have a look at the disc() function in spatstat. I guess you can then 
either do what you aim at directly with spatstat, or after converting 
spatstat objects to sp class with maptools appropriate functions.

HTH

Alex

On 30/03/2011 15:39, Pieter Botha wrote:
> Hi
>
> I have a SpatialPointsDataFrame, originating from location readings from an Android device. These readings are received as latitude / longitude as well as an accuracy reading in meters. An csv dump of the SpatialPointsDataFrame can be downloaded here: http://www.ploemp.com/opla/statp.csv
>
> I am interested in finding points of interest that falls within an accuracy reading for a location. The sp class only supports points, lines and polygons so I guess I will have to construct a polygon that estimates the circle formed by the location with accuracy as radius?
>
> Any pointers here?
>
> Thanks,
> Pieter
>
>
>


From pieter at sevenc.co.za  Wed Mar 30 14:55:38 2011
From: pieter at sevenc.co.za (Pieter Botha)
Date: Wed, 30 Mar 2011 14:55:38 +0200
Subject: [R-sig-Geo] Circles as polygons?
In-Reply-To: <4D9326AB.4050004@gmail.com>
References: <95DCE398-2242-4646-ADE5-9482C6E6D77A@sevenc.co.za>
	<4D9326AB.4050004@gmail.com>
Message-ID: <FBF9C0A4-30A1-41D4-B17A-065C793678BA@sevenc.co.za>

Thanks Alex

I am looking at the spDists function at the moment, if my points of interest lies at a distance smaller than the accuracy of the reading I have a match. Somewhat simpler approach maybe :-)
On 30 Mar 2011, at 2:48 PM, Alexandre Villers wrote:

> Hi,
> 
> Have a look at the disc() function in spatstat. I guess you can then either do what you aim at directly with spatstat, or after converting spatstat objects to sp class with maptools appropriate functions.
> 
> HTH
> 
> Alex
> 
> On 30/03/2011 15:39, Pieter Botha wrote:
>> Hi
>> 
>> I have a SpatialPointsDataFrame, originating from location readings from an Android device. These readings are received as latitude / longitude as well as an accuracy reading in meters. An csv dump of the SpatialPointsDataFrame can be downloaded here: http://www.ploemp.com/opla/statp.csv
>> 
>> I am interested in finding points of interest that falls within an accuracy reading for a location. The sp class only supports points, lines and polygons so I guess I will have to construct a polygon that estimates the circle formed by the location with accuracy as radius?
>> 
>> Any pointers here?
>> 
>> Thanks,
>> Pieter
>> 
>> 
>> 
> 
> 
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.
> 


-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.


From b.rowlingson at lancaster.ac.uk  Wed Mar 30 15:53:50 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 30 Mar 2011 14:53:50 +0100
Subject: [R-sig-Geo] Identifying regions on the boundary
Message-ID: <AANLkTi=70CxR-udCnOYeduXBUDnZrXs05CLGVwQ_U+vr@mail.gmail.com>

 Given a region divided into polygons, how can I find which polygons
have any edges that are not neighbouring other polygons?

 For example, if the region is Africa and the polygons are countries,
I want to find the land-locked and non-landlocked countries.

 My first idea is to create a large rectangle bigger than Africa, and
cutout from it the country polygons, leaving me with a rectangle with
an Africa-shaped hole. Then I test each country again to see if it
shares a border with the hole. If it does, its not land-locked.

 I can probably do all this with rgeos, but if I've missed a simpler
way I'd like to hear it...

 Obviously I fear sliver polygons after my previous geometry
manipulation fun....

Barry


From virgilio.gomez at uclm.es  Wed Mar 30 16:16:03 2011
From: virgilio.gomez at uclm.es (Virgilio =?ISO-8859-1?Q?G=F3mez-Rubio?=)
Date: Wed, 30 Mar 2011 16:16:03 +0200
Subject: [R-sig-Geo] Identifying regions on the boundary
In-Reply-To: <AANLkTi=70CxR-udCnOYeduXBUDnZrXs05CLGVwQ_U+vr@mail.gmail.com>
References: <AANLkTi=70CxR-udCnOYeduXBUDnZrXs05CLGVwQ_U+vr@mail.gmail.com>
Message-ID: <1301494563.1947.25.camel@virgil-HP-Compaq-8000-Elite-USDT-PC>

Barry,

What you propose is what I would do too. Another approach is to display
the adjacency matrix as a graph (i.e., vertices for the "location" of
the country and edges for the connections between them). I would say
that all the countries whose vertex can be surrounded by edges will be
land-locked, so that the remaining countries will be non-landlocked.

In this way you do not have to deal with strange polygons (they might
affect your adjacency matrix though), but I am not sure whether this is
a simpler approach.

Hope this helps,

Virgilio


El mi?, 30-03-2011 a las 14:53 +0100, Barry Rowlingson escribi?:
> Given a region divided into polygons, how can I find which polygons
> have any edges that are not neighbouring other polygons?
> 
>  For example, if the region is Africa and the polygons are countries,
> I want to find the land-locked and non-landlocked countries.
> 
>  My first idea is to create a large rectangle bigger than Africa, and
> cutout from it the country polygons, leaving me with a rectangle with
> an Africa-shaped hole. Then I test each country again to see if it
> shares a border with the hole. If it does, its not land-locked.
> 
>  I can probably do all this with rgeos, but if I've missed a simpler
> way I'd like to hear it...
> 
>  Obviously I fear sliver polygons after my previous geometry
> manipulation fun....
> 
> Barry
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From b.rowlingson at lancaster.ac.uk  Wed Mar 30 18:49:26 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 30 Mar 2011 17:49:26 +0100
Subject: [R-sig-Geo] Identifying regions on the boundary
In-Reply-To: <1301494563.1947.25.camel@virgil-HP-Compaq-8000-Elite-USDT-PC>
References: <AANLkTi=70CxR-udCnOYeduXBUDnZrXs05CLGVwQ_U+vr@mail.gmail.com>
	<1301494563.1947.25.camel@virgil-HP-Compaq-8000-Elite-USDT-PC>
Message-ID: <AANLkTi=RZJP6trBo0FN8Uc1xC_AcxD-NbAaZL8KvYXFB@mail.gmail.com>

2011/3/30 Virgilio G?mez-Rubio <virgilio.gomez at uclm.es>:
> Barry,
>
> What you propose is what I would do too. Another approach is to display
> the adjacency matrix as a graph (i.e., vertices for the "location" of
> the country and edges for the connections between them). I would say
> that all the countries whose vertex can be surrounded by edges will be
> land-locked, so that the remaining countries will be non-landlocked.
>

Here's a two-liner that seems to work but uses gRelate to compute all
the inner/boundary/exterior relations so is surely overkill since I
only care about the boundary. I use gUnionCascaded to get the outer
'coastline', so the coordinates should be exactly those of the
constituent countries, and hence no slivers...

edgeFinder <- function(sp){
  outer = gUnionCascaded(sp)
  substr(gRelate(sp,outer,byid=TRUE)[1,],5,5)!="F"
  }

The horrible substr expression gets the right part of the DE9IM string. I think.

Barry


From Roger.Bivand at nhh.no  Wed Mar 30 20:19:01 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 30 Mar 2011 20:19:01 +0200 (CEST)
Subject: [R-sig-Geo] Identifying regions on the boundary
In-Reply-To: <AANLkTi=RZJP6trBo0FN8Uc1xC_AcxD-NbAaZL8KvYXFB@mail.gmail.com>
References: <AANLkTi=70CxR-udCnOYeduXBUDnZrXs05CLGVwQ_U+vr@mail.gmail.com>
	<1301494563.1947.25.camel@virgil-HP-Compaq-8000-Elite-USDT-PC>
	<AANLkTi=RZJP6trBo0FN8Uc1xC_AcxD-NbAaZL8KvYXFB@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1103302010200.14831@reclus.nhh.no>

On Wed, 30 Mar 2011, Barry Rowlingson wrote:

> 2011/3/30 Virgilio G?mez-Rubio <virgilio.gomez at uclm.es>:
>> Barry,
>>
>> What you propose is what I would do too. Another approach is to display
>> the adjacency matrix as a graph (i.e., vertices for the "location" of
>> the country and edges for the connections between them). I would say
>> that all the countries whose vertex can be surrounded by edges will be
>> land-locked, so that the remaining countries will be non-landlocked.
>>
>
> Here's a two-liner that seems to work but uses gRelate to compute all
> the inner/boundary/exterior relations so is surely overkill since I
> only care about the boundary. I use gUnionCascaded to get the outer
> 'coastline', so the coordinates should be exactly those of the
> constituent countries, and hence no slivers...
>
> edgeFinder <- function(sp){
>  outer = gUnionCascaded(sp)
>  substr(gRelate(sp,outer,byid=TRUE)[1,],5,5)!="F"
>  }
>
> The horrible substr expression gets the right part of the DE9IM string. 
> I think.

library(maptools)
library(spgrass6)
xx <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1],
   IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
SG <- Sobj_SpatialGrid(xx)$SG
initGRASS("/home/rsb/topics/grass/g640/grass-6.4.0", home=tempdir(),
   SG=SG)
writeVECT6(xx, "nc", v.in.ogr_flags="o")
res <- vect2neigh("nc")
library(rgeos)
opar <- par(mfrow=c(2,1))
plot(xx, col=(attr(res, "external") != 0)+1)
plot(xx, col=edgeFinder(xx)+1)
par(opar)

shows only two differences for counties touching the exterior at only one 
coordinate (GRASS is taking boundary length):

as.character(xx$NAME[which(edgeFinder(xx) != (attr(res, "external") != 
0))])

This works for spgrass6 on R-Forge SVN, there was a small issue in 
vect2neigh() that ought to have been fixed before, and now is.

Nice to see rgeos earning its keep!

Roger

>
> Barry
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From znmeb at borasky-research.net  Thu Mar 31 02:54:35 2011
From: znmeb at borasky-research.net (M. Edward (Ed) Borasky)
Date: Wed, 30 Mar 2011 17:54:35 -0700
Subject: [R-sig-Geo] =?utf-8?q?Beta_testing_with_the_Spatial_task_view_on_?=
 =?utf-8?q?R_2=2E13=3F?=
Message-ID: <ab88580a3f5a6b4d2a31bccf6518d7d6@borasky-research.net>

 I'm doing some beta testing with R 2.13. When I tried to install the 
 Spatial task view, it threw an error:

 Error in split.default(X, group) : first argument must be a vector
 In addition: Warning message:
 In .get_pkgs_from_ctv_or_repos(views = views, coreOnly = coreOnly,  :
   CRAN task view Spatial not available

 Is there some other repository I need to search for a task view with 
 the beta test R 2.13?

-- 
 http://twitter.com/znmeb http://borasky-research.net

 "A mathematician is a device for turning coffee into theorems." -- Paul 
 Erd?s


From axel.urbiz at gmail.com  Thu Mar 31 03:29:26 2011
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Wed, 30 Mar 2011 21:29:26 -0400
Subject: [R-sig-Geo] =?utf-8?q?Help=3A_creating_owin=7Bspats=E2=80=8B?=
	=?utf-8?q?=E2=80=8Btat=7D_objects_from_GIS_data?=
Message-ID: <AANLkTikSy6ym9rPeQwaB5sJsamdOYgAFKx9vKGsLN5Gt@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110330/1965afb1/attachment.pl>

From stepen.condors at gmail.com  Thu Mar 31 05:21:04 2011
From: stepen.condors at gmail.com (stepen.condors at gmail.com)
Date: Thu, 31 Mar 2011 13:21:04 +1000
Subject: [R-sig-Geo] Creating a spatial grid from table and x & y break
	vectors?
In-Reply-To: <AANLkTikSy6ym9rPeQwaB5sJsamdOYgAFKx9vKGsLN5Gt@mail.gmail.com>
References: <AANLkTikSy6ym9rPeQwaB5sJsamdOYgAFKx9vKGsLN5Gt@mail.gmail.com>
Message-ID: <2FCD6C8B-6036-467A-9725-CADDC5C05112@gmail.com>

Hi all,
I have the following datasets and am trying to generate a spatial grid which can be plotted (somewhat like the object created by spatstat's quadratcount):

Dataset 1: A table containing a known number of cells, each value relating to the intensity at a given cell.

> str(gridData)
 table [1:250, 1:400] 0 0 0 0 0 0 1.72 0 0 0 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:250] "A" "B" "C" "D" ...
  ..$ : chr [1:400] "A" "B" "C" "D" ...

Datasets 2&3: vectors of xbreaks and ybreaks - specifying the eastings and northings of the grid cells I want to plot.

> str(xbrks)
 num [1:401] 1740000 1740100 1740200 1740300 1740400 ...

> str(ybrks)
 num [1:251] 5420000 5420100 5420200 5420300 5420400 ...


Given these three datatsets, what would be the easiest way to turn this into a plottable (spatially located) grid, that I can then overlay ppp onto? 

I am aware that I can simply plot the table as an image, but obviously this is not spatially referenced in anyway so I wouldn't then be able to overlay a point data set and allow the pts and grid polygons to interact. 

Any assistance is greatly appreciated.
Stepen

From stepen.condors at gmail.com  Thu Mar 31 05:24:54 2011
From: stepen.condors at gmail.com (stepen.condors at gmail.com)
Date: Thu, 31 Mar 2011 13:24:54 +1000
Subject: [R-sig-Geo] Creating a spatial grid from table and x & y break
	vectors?
Message-ID: <F02F61CC-D652-4F2C-AC6C-CFEF078B2706@gmail.com>

Hi all,
I have the following datasets and am trying to generate a spatial grid which can be plotted (somewhat like the object created by spatstat's quadratcount):

Dataset 1: A table containing a known number of cells, each value relating to the intensity at a given cell.

> str(gridData)
 table [1:250, 1:400] 0 0 0 0 0 0 1.72 0 0 0 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:250] "A" "B" "C" "D" ...
  ..$ : chr [1:400] "A" "B" "C" "D" ...

Datasets 2&3: vectors of xbreaks and ybreaks - specifying the eastings and northings of the grid cells I want to plot.

> str(xbrks)
 num [1:401] 1740000 1740100 1740200 1740300 1740400 ...

> str(ybrks)
 num [1:251] 5420000 5420100 5420200 5420300 5420400 ...


Given these three datatsets, what would be the easiest way to turn this into a plottable (spatially located) grid, that I can then overlay ppp onto? 

I am aware that I can simply plot the table as an image, but obviously this is not spatially referenced in anyway so I wouldn't then be able to overlay a point data set and allow the pts and grid polygons to interact. 

Any assistance is greatly appreciated.
Stepen

From mdsumner at gmail.com  Thu Mar 31 05:30:23 2011
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 31 Mar 2011 14:30:23 +1100
Subject: [R-sig-Geo] Creating a spatial grid from table and x & y break
	vectors?
In-Reply-To: <2FCD6C8B-6036-467A-9725-CADDC5C05112@gmail.com>
References: <AANLkTikSy6ym9rPeQwaB5sJsamdOYgAFKx9vKGsLN5Gt@mail.gmail.com>
	<2FCD6C8B-6036-467A-9725-CADDC5C05112@gmail.com>
Message-ID: <AANLkTi=y4nSfU497o3BPOWaxm8kaTWbqsBb5XTQqQGcs@mail.gmail.com>

If image(gridData) works, then image(xbrks, ybrks, gridData) should
work as well, and plot with the correct spatial coordinates - this
assumes that xbrks and ybrks correspond to the dimensions of gridData
- either exactly (the centres) or longer by one element (the corners).

In the sp package you can do x <-  image2Grid(list(x = xbrks, y =
ybrks, z = gridData)) to get a SpatialGridDataFrame, and then with
maptools you can easily convert to spatstat's "im":

library(maptools)
x.im <- as.im(x)

Either of those will help to plot or image() the data in the proper
space and overplot points.

Cheers, Mike.

On Thu, Mar 31, 2011 at 2:21 PM,  <stepen.condors at gmail.com> wrote:
> Hi all,
> I have the following datasets and am trying to generate a spatial grid which can be plotted (somewhat like the object created by spatstat's quadratcount):
>
> Dataset 1: A table containing a known number of cells, each value relating to the intensity at a given cell.
>
>> str(gridData)
> ?table [1:250, 1:400] 0 0 0 0 0 0 1.72 0 0 0 ...
> ?- attr(*, "dimnames")=List of 2
> ?..$ : chr [1:250] "A" "B" "C" "D" ...
> ?..$ : chr [1:400] "A" "B" "C" "D" ...
>
> Datasets 2&3: vectors of xbreaks and ybreaks - specifying the eastings and northings of the grid cells I want to plot.
>
>> str(xbrks)
> ?num [1:401] 1740000 1740100 1740200 1740300 1740400 ...
>
>> str(ybrks)
> ?num [1:251] 5420000 5420100 5420200 5420300 5420400 ...
>
>
> Given these three datatsets, what would be the easiest way to turn this into a plottable (spatially located) grid, that I can then overlay ppp onto?
>
> I am aware that I can simply plot the table as an image, but obviously this is not spatially referenced in anyway so I wouldn't then be able to overlay a point data set and allow the pts and grid polygons to interact.
>
> Any assistance is greatly appreciated.
> Stepen
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


From stepen.condors at gmail.com  Thu Mar 31 05:30:54 2011
From: stepen.condors at gmail.com (stepen.condors at gmail.com)
Date: Thu, 31 Mar 2011 13:30:54 +1000
Subject: [R-sig-Geo] time-weighted kernel density interpolation
In-Reply-To: <4D8C676A.7040209@oncfs.gouv.fr>
References: <5C74B18A-5131-4979-94CF-1EDBE2C0C869@gmail.com>	<AANLkTimDBFpOHuynO0HfGgNVNuE4yVd8ZxpbZNaKVAhN@mail.gmail.com>	<C592CD29-9817-4F86-840A-1F9DC6542083@gmail.com>	<AANLkTikKMGh2giN0r1E1rM4UZ-rPVG8B+ohTJaja-Zyi@mail.gmail.com>
	<4DEF61BB-C294-43C8-A1A7-D27802076423@gmail.com>
	<4D8C676A.7040209@oncfs.gouv.fr>
Message-ID: <8B04827B-3E49-4DB2-BB19-33AEDBD635E2@gmail.com>

Many thanks for these references / library Cl?ment - they are very useful.

Best 
Stepen

On 25/03/2011, at 7:59 PM, Cl?ment Calenge wrote:

> I am not sure, but wouldn't the function kernelkcbase from the package adehabitatHR fit your needs? it implements the product kernel estimator over space and time. It estimates, for a given date, the kernel density of the points, the point weights depending on their associated dates (see examples of this function). This approach is developed in detail pages p. 91 and pp. 103 and following in;
> 
> @BOOK{Wand1995,
>  title = {Kernel smoothing},
>  publisher = {Chapman \& Hall/CRC},
>  year = {1995},
>  author = {Wand, M.P. and Jones, M.C.}
> }
> 
> Has been introduced in ecology for the smoothing of space utilization by animals by:
> 
> @ARTICLE{Keating2009,
>  author = {Keating, K.A. and Cherry, S.},
>  title = {Modeling utilization distributions in space and time},
>  journal = {Ecology},
>  year = {2009},
>  volume = {90},
>  pages = {1971-1980}
> }
> 
> And has been used for the modelling of ring recoveries by:
> 
> @ARTICLE{Calenge2010,
>  author = {Calenge, C. and Guillemain, M. and Gauthier-Clerc, M. and Simon,
>    G.},
>  title = {{A new exploratory approach to the study of the spatio-temporal distribution
>    of ring recoveries: the example of Teal (Anas crecca) ringed in Camargue,
>    Southern France}},
>  journal = {Journal of Ornithology},
>  year = {2010},
>  pages = {1--6}
> }
> 
> HTH,
> 
> Cl?ment Calenge
> 
> 
> On 03/25/2011 08:05 AM, stepen.condors at gmail.com wrote:
>> OK Michael I will attempt o explain my requirements a little more thoroughly and some the options I have started to explore.
>> I begin by outlining what I would like to do at a functional level.
>> 
>> 1. I have a set of observations each with an  associated x&  y co-ordinates and an age in days - i.e. this observation was made at this point 3 days ago etc.
>> 2. I want to create a grid over the area in which the points are found. Each cell of this grid has an associated z-score.
>> 3. I now step through the point set and for each point find which grid cell it lies in and then add some value to the z-score of that cell and other cells within a finite distance of the origin cell. These intensity scores are based on the age of the observation and the distance of the grid cell from the point  and are looked up from some other data structure such as a matrix. i.e.
>> 		Space
>> Age-days 	0-100 	100-200	300-400 	400+
>> 0-1		0.8		0.7		0.6		0.5
>> 2-3		0.6		0.5		0.4		0.3
>> 4+		0.4		0.3		0.2		0.1
>> 
>> Thus, an observation that occurred today might add a z-score of 0.8 to the z of grid cell in which it lies - 0.7 to those within 100-200, 0.6 to those with 300-400 and so on. On the other hand an observation that is 5 days old only adds 0.4 to the cell in which it lies, 0.3 to those within 100-200 etc etc.
>> 
>> It is important that this z-score per grid cell is cumulative so that if multiple points are near one another some grid cells might have numerous values added to their z score.
>> 
>> Describing the above in pseudo code:
>> 
>> points = (x,y,age)
>> grid = makegrid(nrows,ncolumns)
>> 
>> for point in points
>> {
>> 	for cell in grid
>> 	{
>> 		if point iswithin cell
>> 		{
>> 			z of cell = z of cell + matrix[point.age,1]
>> 			
>> 			for nearcell within 100-200m of cell
>> 			{
>> 				z of nearcell = z of nearcell + matrix[point.age,2]
>> 			}	
>> 
>> 			for nearcell within 200-300m of cell
>> 			{
>> 				z of nearcell = z of nearcell + matrix[point.age,3]
>> 			}					
>> 			
>> 			for nearcell within 300-400m of cell
>> 			{
>> 				z of nearcell = z of nearcell + matrix[point.age,4]
>> 			}
>> 		}
>> 	}
>> }		
>> 
>> On paper this doesn't seem overly complicated, but I am struggling to find the right libraries to do it efficiently.
>> 
>> 
>> I have attempted a few different methods - but unfortunately I seem to be hitting brick walls.
>> I will list a few options I have investigated below:
>> 
>> THE POINTS:
>> say for example then my data set is made up as follows:
>> 	
>> 	xs = sample(1:1000, 100, replace = TRUE)
>> 	ys = sample(1:1000, 100, replace = TRUE)
>> 	age = sample(1:30,100, replace = TRUE)
>> 
>> I can then generate a ppp as follows:
>> 
>> 	test.ppp = ppp(xs, ys, xrange=c(1,1000), yrange=c(1,1000))
>> 
>> However this only associates the x,y co-eds with points and not the age
>> - maybe I can use age as the mark variable as follows:
>> 	
>> 	test.ppp = ppp(xs, ys, marks = age, xrange=c(1,1000), yrange=c(1,1000))
>> 
>> However, this only seems to impact on the visual display of data.
>> 
>> Perhaps I am better creating a simple object as follows
>> 	
>> 	observations<- cbind(xs,ys,age)
>> 
>> But then this has no spatial data associated with it
>> 
>> THE GRID:
>> In making the grid I can do several things:
>> Using pixellate I can count the number of observations in a grid I specify the size of as follows (100x100 grid cells)
>> 
>> 	Z<- pixellate(test.ppp, eps=100)
>> 
>> I can then convert the grid to a data.frame and view it:
>> 	
>> 	>  as.data.frame(Z)
>>       	x     y 	     value
>> 	1    50  50      0
>> 	2    50 150     3
>> 	3    50 250     0
>> 	4    50 350     2
>> 
>> However, the points are already aggregated as counts and I need to know the age of each in order to calculate a z-score for each grid. I.e. grid cell 2 has three points in it I need the age of each.
>> 
>> An alternative seems to be to create a bunch of polygon objects for each grid cell as follows (10x10 grid cells in this example):
>> 
>>     	for(x in 0:100)
>>         	{
>>             	for(y in 0:100)
>>                 	{
>>                     	cellX = (x * 10)
>>                     	cellY = (y * 10)
>>                     	grid_cell_dim = cbind(x=c(cellX,(cellX+10),(cellX+10),cellX),y=c((cellY+10),(cellY+10),cellY,cellY))
>>                     	polygon(grid_cell_dim)
>> 
>>                 	}
>>         	}
>> 
>> Once I have created these polygons I am unsure how I can access them or associate a z-score with each. When I messed about twith SpatialPolygonsDataFrame it keeps telling me 'ring not closed'.
>> 
>> 
>> Apologies for the long-winded message - but as you can see I am struggling to find the best course of action to do what seems a relatively simple task. Therefore, any advice would be greatly appreciated - are any of these options viable? is there a much simpler solution?
>> 
>> Best Regards
>> Stepen
>> 
>> 
>> On 24/03/2011, at 6:14 AM, Michael Sumner wrote:
>> 
>>> I'm not sure if anyone could give advice here without know more about
>>> the data, but perhaps ?density.ppp or ?pixellate.ppp in spatstat would
>>> be useful.
>>> 
>>> Cheers, Mike.
>>> 
>>> On Tue, Mar 22, 2011 at 4:05 PM,<stepen.condors at gmail.com>  wrote:
>>>> Thanks for this Michael - I am investigating the trip library as we speak.
>>>> 
>>>> Another (potentially stupid) query:
>>>> 
>>>> I have a point pattern (as a ppp):
>>>> 
>>>> test.ppp = ppp(test.eastings, test.northings, xrange=c(1000000, 2000000), yrange=c(1000000,2000000))
>>>> 
>>>> I'd like to generate a grid over this area storing an associated intensity score with each grid cell - so that where points intersect that grid I can add some value to the intensity score of the cell they lie in (and surrounding ones ideally).
>>>> 
>>>> What grid method would you recommend?  and then how might you go about calculating the intersection of points and polygons?
>>>> 
>>>> Many Thanks
>>>> Stepen
>>>> 
>>>> 
>>>> On 21/03/2011, at 6:46 AM, Michael Sumner wrote:
>>>> 
>>>>> Hi Stepen,
>>>>> 
>>>>> The function tripGrid in package trip does something similar to this
>>>>> for the time interval between points ("time spent in area") - by using
>>>>> spatstat's density function on the line segments. The KDE approach is
>>>>> there for exploration though I think the straight grid approach is
>>>>> usually better (neither method has any systematic handling for
>>>>> location error).
>>>>> 
>>>>> I've long meant to generalize the tripGrid function so that it's not
>>>>> so tied to the time interval and the user could specify the
>>>>> "weighting" - but that always brings up the issue of whether is is the
>>>>> points or the implicit line segments between them that are of
>>>>> interest.
>>>>> 
>>>>> The density.ppp function in spatstat could be used to do this, though
>>>>> I wonder what kind of result you are expecting from this method?
>>>>> 
>>>>> Some of the approaches in adehabitat (and its new family of packages)
>>>>> could be useful too.
>>>>> 
>>>>> Cheers, Mike.
>>>>> 
>>>>> 
>>>>> 
>>>>> On Mon, Mar 21, 2011 at 3:05 AM,<stepen.condors at gmail.com>  wrote:
>>>>>> Hi all
>>>>>> I am currently looking into developing some sort of time-weighted kernel density interpolation in R. It is my aim to build something which allows me to the the following:
>>>>>> 
>>>>>> - Import a point pattern p with associated times for each event
>>>>>> - Plot a time weighted kernel density map of p - such that more recent events have a greater weighting than those that occurred earlier.
>>>>>> - Ideally it would be useful to specify both the spatial and temporal bandwidths and the decay function types i.e. linear, exponential
>>>>>> - Import new point data and assign an intensity score to each point from its location on time-weighted kernel density surface.
>>>>>> 
>>>>>> Is this something that is relatively easily doable in R or am I crazy?
>>>>>> I have developed something similar previously in both C++ and VB.NET (cough) interfacing directly with MapInfo so I am not afraid of code.
>>>>>> However, as I am still relatively new to R I imagined that there were likely some better and worse ways to do this and/or libraries to look at. I have checked out the sp and spatstat libraries - but neither seem to have much to do with time, next i am considering trip. Where would you start? I would hate to waste time implementing something just because I was unaware of an existing solution.
>>>>>> 
>>>>>> Therefore any advice, suggestions, experiences or abuse concerning how I might accomplish this functionality would be greatly appreciated.
>>>>>> 
>>>>>> Best
>>>>>> Stepen
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at r-project.org
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>> 
>>>>> 
>>>>> 
>>>>> --
>>>>> Michael Sumner
>>>>> Institute for Marine and Antarctic Studies, University of Tasmania
>>>>> Hobart, Australia
>>>>> e-mail: mdsumner at gmail.com
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>> 
>>> 
>>> 
>>> -- 
>>> Michael Sumner
>>> Institute for Marine and Antarctic Studies, University of Tasmania
>>> Hobart, Australia
>>> e-mail: mdsumner at gmail.com
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
> 
> 
> -- 
> Cl?ment CALENGE
> Cellule d'appui ? l'analyse de donn?es
> Direction des Etudes et de la Recherche
> Office national de la chasse et de la faune sauvage
> Saint Benoist - 78610 Auffargis
> tel. (33) 01.30.46.54.14
> 


From marcelino.delacruz at upm.es  Thu Mar 31 09:13:43 2011
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Thu, 31 Mar 2011 09:13:43 +0200
Subject: [R-sig-Geo]
 =?iso-8859-1?q?Help=3A_creating_owin=7Bspats=E2=80=8B?=
 =?iso-8859-1?q?_=E2=80=8Btat=7D__objects_from_GIS_data?=
In-Reply-To: <AANLkTikSy6ym9rPeQwaB5sJsamdOYgAFKx9vKGsLN5Gt@mail.gmail.c
 om>
References: <AANLkTikSy6ym9rPeQwaB5sJsamdOYgAFKx9vKGsLN5Gt@mail.gmail.com>
Message-ID: <201103310713.p2V7Dnt7025867@smtp.upm.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110331/2fd03456/attachment.pl>

From andy.a.wilson at gmail.com  Thu Mar 31 10:33:32 2011
From: andy.a.wilson at gmail.com (Andy Wilson)
Date: Thu, 31 Mar 2011 09:33:32 +0100
Subject: [R-sig-Geo] Fuzzy k-means & raster
Message-ID: <4D943C5C.9070709@googlemail.com>

Hi all,
I'm using an example (p213) in Hengl's A Practical Guide to Statistical 
Mapping (an excellent book btw) as the basis to use fuzzy k-means for 
the unsupervised extraction of landforms from land surface parameter 
rasters. I've found that the classes are not reproducible. When I run 
the same code on the same data 5 times I wont get the same clusters 
every time - sometimes the same, but sometimes there will be different 
numbers of cells attributed to each class. Is this to be expected from 
fuzzy k-means or could this be a problem with my approach.

grids50m <- readGDAL("ELEV.asc")
LSP.list <- c("RELELEV.asc", "PROFILE.asc")
rsaga.sgrd.to.esri(in.sgrds=set.file.extension(LSP.list, ".sgrd"), 
out.grids=LSP.list, prec=4, out.path=getwd())

for(i in 1:length(LSP.list)){
  grids50m at data[strsplit(LSP.list[i], ".asc")[[1]]] <- 
readGDAL(LSP.list[i])$band1
}
pc.dem <- prcomp( ~ RELELEV+PROFILE, scale=TRUE, grids50m at data)
demdata <- as.data.frame(pc.dem$x)

kmeans.dem5 <- kmeans(demdata,7)
grids50m$kmeans.dem5 <- kmeans.dem5$cluster
grids50m$landform5 <- as.factor(kmeans.dem5$cluster)

# Initiate a raster to load the cluster data into
r_class7 <- r_elev
# Extract the landform data into a vector
v_class7 <- as.numeric(grids50m$landform5)
# Load the landform data into the raster
r_class7 <- setValues(r_class5, v_class5)

Many thanks for your advice...
Andy Wilson


From stepen.condors at gmail.com  Thu Mar 31 10:52:09 2011
From: stepen.condors at gmail.com (stepen.condors at gmail.com)
Date: Thu, 31 Mar 2011 18:52:09 +1000
Subject: [R-sig-Geo] Creating a spatial grid from table and x & y break
	vectors?
In-Reply-To: <AANLkTi=y4nSfU497o3BPOWaxm8kaTWbqsBb5XTQqQGcs@mail.gmail.com>
References: <AANLkTikSy6ym9rPeQwaB5sJsamdOYgAFKx9vKGsLN5Gt@mail.gmail.com>
	<2FCD6C8B-6036-467A-9725-CADDC5C05112@gmail.com>
	<AANLkTi=y4nSfU497o3BPOWaxm8kaTWbqsBb5XTQqQGcs@mail.gmail.com>
Message-ID: <8CE62D3A-598F-4D35-99A7-907C081E8DC6@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110331/60bf233b/attachment.pl>

From marcelino.delacruz at upm.es  Thu Mar 31 10:56:47 2011
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Thu, 31 Mar 2011 10:56:47 +0200
Subject: [R-sig-Geo] Fuzzy k-means & raster
In-Reply-To: <4D943C5C.9070709@googlemail.com>
References: <4D943C5C.9070709@googlemail.com>
Message-ID: <201103310856.p2V8urQV006582@smtp.upm.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110331/d3157fcd/attachment.pl>

From g.lionel at lycos.com  Thu Mar 31 11:12:55 2011
From: g.lionel at lycos.com (glionel)
Date: Thu, 31 Mar 2011 02:12:55 -0700 (PDT)
Subject: [R-sig-Geo] =?utf-8?q?Help=3A_creating_owin=7Bspats=E2=80=8B?=
 =?utf-8?q?=E2=80=8Btat=7D_objects_from_GIS_data?=
In-Reply-To: <AANLkTikSy6ym9rPeQwaB5sJsamdOYgAFKx9vKGsLN5Gt@mail.gmail.com>
References: <AANLkTikSy6ym9rPeQwaB5sJsamdOYgAFKx9vKGsLN5Gt@mail.gmail.com>
Message-ID: <1301562775051-6226422.post@n2.nabble.com>

Dear Axel,
I am new user of spatsat but I am working with that tool.
If you have the shape in ESRI format .shp, I can suggest you to use the
following commands

library(maptools)
S <- readShapePoly("C:/../.../Documents/.../.../....shp")#the link to your
file on your computer
library(sp)
SP <- as(S, "SpatialPolygons")
W <- as(SP, "owin")#your converted owin object
plot(W)

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Help-creating-owin-spats-tat-objects-from-GIS-data-tp6225601p6226422.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From mathijsdevaan at gmail.com  Thu Mar 31 11:38:52 2011
From: mathijsdevaan at gmail.com (Mathijs de Vaan)
Date: Thu, 31 Mar 2011 11:38:52 +0200
Subject: [R-sig-Geo] Plotting data on a US County Map
Message-ID: <AANLkTikPRX5mhYABHP+mcft+XgywcgTUHaTC4xdQ-LPc@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110331/6598bb5c/attachment.pl>

From g.lionel at lycos.com  Thu Mar 31 12:39:47 2011
From: g.lionel at lycos.com (glionel)
Date: Thu, 31 Mar 2011 03:39:47 -0700 (PDT)
Subject: [R-sig-Geo] =?utf-8?q?Help=3A_creating_owin=7Bspats=E2=80=8B?=
 =?utf-8?q?=E2=80=8Btat=7D_objects_from_GIS_data?=
In-Reply-To: <AANLkTikSy6ym9rPeQwaB5sJsamdOYgAFKx9vKGsLN5Gt@mail.gmail.com>
References: <AANLkTikSy6ym9rPeQwaB5sJsamdOYgAFKx9vKGsLN5Gt@mail.gmail.com>
Message-ID: <1197687225.69275.1301567978798.JavaMail.mail@webmail07>

Dear Axel, I am new user of spatsat but I am working with that tool. If you have the shape in ESRI format .shp, I can suggest you to use the following commands library(maptools) S &lt;- readShapePoly("C:/../.../Documents/.../.../....shp")#the link to your file on your computer library(sp) SP &lt;- as(S, "SpatialPolygons") W &lt;- as(SP, "owin")#your converted owin object plot(W) 
On Mar 31, 2011, Axel Urbiz [via R-sig-geo] &lt;ml-node+6225601-1939504292-328036 at n2.nabble.com&gt; wrote: 

Dear List, I'm trying to create an object of class "owin" (observation window) in the package spatstat from GIS mapping data. Here's an example of my problem. Everything goes well until the last line of code. I get the error message shown at the bottom: library(spatstat) library(sp) library(maptools) con &lt;- url(" http://gadm.org/data/rda/CHE_adm1.RData" ) class(con) print(load(con)) close(con) SP &lt;- as(gadm, "SpatialPolygons") W &lt;- as(SP, "owin") "Error in owin(poly = opls) : &nbsp; Polygon data contain overlaps between polygons" Thanks for any help, Axel. &nbsp; &nbsp; &nbsp; &nbsp; [[alternative HTML version deleted]] _______________________________________________ R-sig-Geo mailing list [hidden email]  https://stat.ethz.ch/mailman/listinfo/r-sig-geo    


If you reply to this email, your message will be added to the discussion below: 
http://r-sig-geo.2731867.n2.nabble.com/Help-creating-owin-spats-tat-objects-from-GIS-data-tp6225601p6225601.html 
To start a new topic under R-sig-geo, email ml-node+2731867-728108618-328036 at n2.nabble.com   To unsubscribe from R-sig-geo, click here . 




--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Help-creating-owin-spats-tat-objects-from-GIS-data-tp6225601p6226614.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From b.rowlingson at lancaster.ac.uk  Thu Mar 31 13:48:33 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 31 Mar 2011 12:48:33 +0100
Subject: [R-sig-Geo] Help: creating owin{spats tat} objects from GIS data
Message-ID: <AANLkTikhAhYzQ8ZyEeO9vv_MFOsrDQznquvbBsZqwbfc@mail.gmail.com>

On Thu, Mar 31, 2011 at 2:29 AM, Axel Urbiz <axel.urbiz at gmail.com> wrote:
> Dear List,
>
> I'm trying to create an object of class "owin" (observation window) in the
> package spatstat from GIS mapping data. Here's an example of my problem.
> Everything goes well until the last line of code. I get the error message
> shown at the bottom:
>
> "Error in owin(poly = opls) :
> ?Polygon data contain overlaps between polygons"
>
> Thanks for any help,

I'm guessing its because the polygon data contains overlaps between polygons...

 When I run it I also get a lot of useful messages:


 > W <- as(SP, "owin")
Checking 43 polygons...1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,
16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,
31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43.
done.
Checking for cross-intersection between 43 polygons...1, Polygons 1
and 6 cross over
Polygons 1 and 10 cross over
Polygons 1 and 23 cross over
Polygons 1 and 32 cross over

 etc.

 Now I think those numbers dont map exactly to the polygons in SP - I
have only 27 in my map of switzerland. So tracking down what these
overlaps are could be a bit tricky.

 If what you want is a window that is the whole of switzerland, then
either start with the adm0 level boundaries:

 > con <- url("http://gadm.org/data/rda/CHE_adm0.RData")
 > load(con)
 > SP0 <- as(gadm, "SpatialPolygons")
 > length(SP0)
[1] 1
 > plot(SP0)
 > as(SP0,"owin")
Checking 1 polygons...1.
[Checking polygon with 2390 edges...]
done.
window: polygonal boundary
enclosing rectangle: [5.957431, 10.49271] x [45.82166, 47.81115] units

Or dissolve the boundaries using package-of-the-month 'rgeos':

> outer = gUnionCascaded(SP)
> plot(outer)
> W = as(outer,"owin")
Checking 1 polygons...1.
[Checking polygon with 2386 edges...]
done.

rgeos is best got from r-forge at the moment.

Barry


From advaitgodbole at gmail.com  Thu Mar 31 17:54:56 2011
From: advaitgodbole at gmail.com (Advait Godbole)
Date: Thu, 31 Mar 2011 11:54:56 -0400
Subject: [R-sig-Geo] package raster: issue with "extent" and "stack"
In-Reply-To: <1301374189652-6217680.post@n2.nabble.com>
References: <AANLkTikondcrrnHLncqJ03DO8WLjOTod92g0juN9jn=8@mail.gmail.com>
	<1301374189652-6217680.post@n2.nabble.com>
Message-ID: <AANLkTi=BLFffxNLf+YB34Kv_WztVfgKxhDdHdZ7V-V4s@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110331/58c2cb97/attachment.pl>

From everton.emanuel at gmail.com  Thu Mar 31 19:57:48 2011
From: everton.emanuel at gmail.com (Everton Emanuel)
Date: Thu, 31 Mar 2011 14:57:48 -0300
Subject: [R-sig-Geo] Question concerning the comand unionSpatialPolygons
Message-ID: <AANLkTi=vqjoG0-qc2R7CWnC0qEpMp=-a8p8MfjupcmyQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110331/37088f59/attachment.pl>

From ashton at msu.edu  Thu Mar 31 20:04:18 2011
From: ashton at msu.edu (Ashton Shortridge)
Date: Thu, 31 Mar 2011 14:04:18 -0400
Subject: [R-sig-Geo] Fuzzy k-means & raster
In-Reply-To: <201103310856.p2V8urQV006582@smtp.upm.es>
References: <4D943C5C.9070709@googlemail.com>
	<201103310856.p2V8urQV006582@smtp.upm.es>
Message-ID: <201103311404.18800.ashton@msu.edu>

Coincidentally enough, this issue has come up in my office this week. In fact, 
k-means solutions using the generic settings in R appear to be quite unstable. 
Different runs on a small and visually 'simple' data set I've been exploring 
may produce very different clusters and fits.

Setting the nstart parameter to a larger value (e.g., 10 or 50; the default is 
1) seems to greatly improve the stability of the results. Of course this will 
extend the time it takes the function to run, at least for large datasets. 

This also does not address the issue that the same set of points may be 
assigned as a cluster in different runs, but with a different cluster code (e.g. 
cluster 3 the first run, and cluster 7 the second run).

I hope this is useful,

Ashton

On 2011-03-31, Marcelino de la Cruz, wrote:
> This is quite usual with kmeans as the algorithm may find different
> minima every time you call it.
> 
> If you want the same clusters every time you should set the same seed
> before runing kmeans, e.g.
> 
> set.seed(222)
> kmeans.dem5 <- kmeans(demdata,7)
> 
> 
> set.seed(222)
> kmeans.dem5 <- kmeans(demdata,7)
> 
> etc
> 
> Cheers,
> 
> Marcelino
> 
> At 10:33 31/03/2011, Andy Wilson wrote:
> >Hi all,
> >I'm using an example (p213) in Hengl's A Practical Guide to
> >Statistical Mapping (an excellent book btw) as the basis to use
> >fuzzy k-means for the unsupervised extraction of landforms from land
> >surface parameter rasters. I've found that the classes are not
> >reproducible. When I run the same code on the same data 5 times I
> >wont get the same clusters every time - sometimes the same, but
> >sometimes there will be different numbers of cells attributed to
> >each class. Is this to be expected from fuzzy k-means or could this
> >be a problem with my approach.
> >
> >grids50m <- readGDAL("ELEV.asc")
> >LSP.list <- c("RELELEV.asc", "PROFILE.asc")
> >rsaga.sgrd.to.esri(in.sgrds=set.file.extension(LSP.list, ".sgrd"),
> >out.grids=LSP.list, prec=4, out.path=getwd())
> >
> >for(i in 1:length(LSP.list)){
> >
> >  grids50m at data[strsplit(LSP.list[i], ".asc")[[1]]] <-
> > 
> > readGDAL(LSP.list[i])$band1
> >
> >}
> >pc.dem <- prcomp( ~ RELELEV+PROFILE, scale=TRUE, grids50m at data)
> >demdata <- as.data.frame(pc.dem$x)
> >
> >kmeans.dem5 <- kmeans(demdata,7)
> >grids50m$kmeans.dem5 <- kmeans.dem5$cluster
> >grids50m$landform5 <- as.factor(kmeans.dem5$cluster)
> >
> ># Initiate a raster to load the cluster data into
> >r_class7 <- r_elev
> ># Extract the landform data into a vector
> >v_class7 <- as.numeric(grids50m$landform5)
> ># Load the landform data into the raster
> >r_class7 <- setValues(r_class5, v_class5)
> >
> >Many thanks for your advice...
> >Andy Wilson
> >
> >_______________________________________________
> >R-sig-Geo mailing list
> >R-sig-Geo at r-project.org
> >https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> ____________________________________
> 
> Marcelino de la Cruz Rot
> Depto. Biologia Vegetal
> EUIT Agricola
> Universidad Politecnica de Madrid
> 
> tel: 34 + 913365435
> ____________________________________
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


-----
Ashton Shortridge
Associate Professor			ashton at msu.edu
Dept of Geography			http://www.msu.edu/~ashton
235 Geography Building		ph (517) 432-3561
Michigan State University		fx (517) 432-1671


From Roger.Bivand at nhh.no  Thu Mar 31 20:21:46 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 31 Mar 2011 20:21:46 +0200 (CEST)
Subject: [R-sig-Geo] Question concerning the comand unionSpatialPolygons
In-Reply-To: <AANLkTi=vqjoG0-qc2R7CWnC0qEpMp=-a8p8MfjupcmyQ@mail.gmail.com>
References: <AANLkTi=vqjoG0-qc2R7CWnC0qEpMp=-a8p8MfjupcmyQ@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1103312002400.22299@reclus.nhh.no>

On Thu, 31 Mar 2011, Everton Emanuel wrote:

> Dear all,
>
> I am trying to manipulate a shape.file using the function
> unionSpatialPolygons. It is weird but the example, given by the R-CRAN, is
> not working, and I do not know how to solve the problem. Any help will be
> appreciated.

What example (from an older version of maptools than you have installed on 
your computer - what does ?unionSpatialPolygons show in its example?)? If 
you look at the example on the help page of the function for the 
unionSpatialPolygons() function, you see that for maptools 0.7-33 through 
0.7-38 it said:

gpclibPermit()
require(gpclib)

and now (0.8-6) says gpclibPermit(), which may cause gpclib to be used if 
the newly released rgeos package is not available. The gpclib package has 
a very bad license, and should be avoided where possible. If you use the 
command gpclibPermit() and do use gpclib (by not installing rgeos), you 
agree to the license terms implicitly.

The error message you report invites you to ask ?gpclibPermitStatus, and 
that help page explains what the problem is. So two solutions - update 
your maptools (it may be up-to-date, but the help page to which you are 
refering is over a year out of date) and implicitly accept the gpclib 
license, or install rgeos instead.

Roger

>
> Example given by the library maptools:
>
> library(sp)              * ## I discovered that you need to load the
> library spdep, otherwise you do not read the shape.file NorthCaroline*
>
> library(gpclib)
>
> nc1 <- readShapePoly(system.file("shapes/sids.shp",
> package="maptools")[1], proj4string=CRS("+proj=longlat +datum=NAD27"))
>
> lps <- coordinates(nc1)
>
> ID <- cut(lps[,1], quantile(lps[,1]), include.lowest=TRUE)
>
> reg4 <- unionSpatialPolygons(nc1, ID)            *## Here I get the
> following error mensage:* *"Error: isTRUE(gpclibPermitStatus()) is not
> TRUE"*
>
> sapply(slot(reg4, "polygons"), function(i) slot(i, "ID"))
>
> Everton.
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From mathieu.rajerison at gmail.com  Thu Mar 31 23:09:07 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Thu, 31 Mar 2011 23:09:07 +0200
Subject: [R-sig-Geo] spatstat - 2 covariates: which one contributes the most
Message-ID: <AANLkTikGXXThn75XXu0MuW62MhRkfRzjCJe6yKco1Gn_@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110331/e138a184/attachment.pl>

