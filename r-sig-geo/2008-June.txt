From jbarnier at ens-lsh.fr  Mon Jun  2 15:50:44 2008
From: jbarnier at ens-lsh.fr (Julien Barnier)
Date: Mon, 02 Jun 2008 15:50:44 +0200
Subject: [R-sig-Geo] spplot and diverging colorbrewer palette
References: <87mym7n9n9.fsf@ens-lsh.fr> <48402383.1050704@uni-muenster.de>
Message-ID: <87zlq4vtcb.fsf@ens-lsh.fr>

Hi Edzer,

> try the colorkey argument in spplot, it should get passed on to
> spplot, which wraps levelplot.

Thanks for your advice.

In fact it seems that I can achieve something not too far from what I
wanted with the following code :


library(sp)
library(maptools)
library(RColorBrewer)

nc <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1], proj4string=CRS("+proj=longlat +datum=NAD27"))
nc at data$AREA2 <- nc at data$AREA - 0.1

at <- pretty(nc at data$AREA2,n=6)
palpos <- brewer.pal(sum(at>0),"Reds")
palneg <- brewer.pal(sum(at<0),"Blues")
palette <- c(rev(palneg),palpos)

spplot(nc, c("AREA2"), col.regions=palette, at=at, scales=list(draw = TRUE))


But I'm really not sure it is the right way to do it...

Thanks again,

Julien

-- 
Julien Barnier
Groupe de recherche sur la socialisation
ENS-LSH - Lyon, France



From jbarnier at ens-lsh.fr  Mon Jun  2 16:45:24 2008
From: jbarnier at ens-lsh.fr (Julien Barnier)
Date: Mon, 02 Jun 2008 16:45:24 +0200
Subject: [R-sig-Geo] Pretty readable labels with spplot
Message-ID: <87mym3x5dn.fsf@ens-lsh.fr>

Hi,

I keep using spplot to draw some simple maps, but I wonder if someone
has got a good method to draw nice and readable labels above a polygon
map ? More precisely, I wonder if there is a way to draw the labels in
black with a small white border around them in order to keep them
readable over a dark color.

I tried by writing two labels layout, one white and one black, either
by putting the first in bold face or by moving it a bit, but I don't
find the result very good. Here is an example :


library(sp)
library(maptools)
library(RColorBrewer)

nc <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1], proj4string=CRS("+proj=longlat +datum=NAD27"))

labels <- as.character(nc$NAME)
locs.labels <- getSpPPolygonsLabptSlots(nc)
nc.labels <- maptools::pointLabel(x=locs.labels[,1],y=locs.labels[,2],labels=labels,doPlot=FALSE)

nc.labels.white.panel <- list("panel.text",nc.labels$x-0.005,nc.labels$y-0.005,labels=labels,col="white",cex=0.5)
nc.labels.panel <- list("panel.text",nc.labels$x,nc.labels$y,labels=labels,col="black",cex=0.5)
spplot(nc, 'AREA', sp.layout=list(nc.labels.white.panel,nc.labels.panel), col.regions=brewer.pal(7, "Reds"), cuts=6)


Thanks in advance for any advice !

Sincerely,

Julien

-- 
Julien Barnier
Groupe de recherche sur la socialisation
ENS-LSH - Lyon, France



From dujuan at stt.msu.edu  Tue Jun  3 06:51:13 2008
From: dujuan at stt.msu.edu (Juan Du)
Date: Tue, 3 Jun 2008 00:51:13 -0400
Subject: [R-sig-Geo] MLE of multivariate normal likelihood with large
	covariance matrix
Message-ID: <B130A91CAE960240AD7FA52EB156C82E1533E2E460@exchange.sttwin.stt.msu.edu>

Dear R helper,

I am trying to calculate the MLE of the Gaussian process with certain covariance structure, say, exponential, by using nlm. It works fine for small sample size like n<300, but when I increase it to 500 or more, the warning comes out and the estimate will always be initial value. Could you please give some hint about what I'm doing wrong  or help me find another way to calculate the MLE of  multivariate normal likelihood with large covariance matrix?

###########################
z<-seq(0,to=1,length=1000)
dis<-rdist(z)
V<-Exponential(dis, alpha =5, phi = 1)
llth <- function(para)
      {
       x<-y
       dis<-dis
       Vn=Exponential(dis, alpha=theta, phi=sigma2)
       n=length(x)
       logd=log(det(Vn))
       xvx=mahalanobis(x, center = 0, cov = Vn)
       (n/2)*log(2*pi)+(1/2)*logd+(1/2)*xvx
        }
np=length(z)
#set.seed(2)
y=mvrnorm(mu=rep(0, np), Sigma=V) # This is the simulated data
length(y)
t1<-proc.time()
est1<-nlm(llth, p=4.5)

Warning messages:
1: In nlm(llth, p = 4.5) : NA/Inf replaced by maximum positive value
2: In nlm(llth, p = 4.5) : NA/Inf replaced by maximum positive value

##########################################
Thanks in advance,

Sincerely yours,

Juan
________________________________________
From: r-sig-geo-bounces at stat.math.ethz.ch [r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of r-sig-geo-request at stat.math.ethz.ch [r-sig-geo-request at stat.math.ethz.ch]
Sent: Thursday, May 29, 2008 6:00 AM
To: r-sig-geo at stat.math.ethz.ch
Subject: R-sig-Geo Digest, Vol 57, Issue 25

Send R-sig-Geo mailing list submissions to
        r-sig-geo at stat.math.ethz.ch

To subscribe or unsubscribe via the World Wide Web, visit
        https://stat.ethz.ch/mailman/listinfo/r-sig-geo
or, via email, send a message with subject or body 'help' to
        r-sig-geo-request at stat.math.ethz.ch

You can reach the person managing the list at
        r-sig-geo-owner at stat.math.ethz.ch

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-Geo digest..."


Today's Topics:

   1. Re: spatial probit (Eelke Folmer)
   2. Problem overlying Kriging grid with measurement points
      (Mauricio Zambrano)
   3. Re: Problem overlying Kriging grid with measurement points
      (Roger Bivand)
   4. Re: Problem overlying Kriging grid with measurement       points
      (Mauricio Zambrano)


----------------------------------------------------------------------

Message: 1
Date: Wed, 28 May 2008 13:53:58 +0200
From: "Eelke Folmer" <E.O.Folmer at rug.nl>
Subject: Re: [R-sig-Geo] spatial probit
To: "'Bjarke Christensen'" <Bjarke.Christensen at sydbank.dk>,
        <r-sig-geo at stat.math.ethz.ch>
Message-ID: <200805281154.m4SBsI7J015242 at hypatia.math.ethz.ch>
Content-Type: text/plain;       charset="us-ascii"

Roger Bivand mentions LeSage's matlab toolbox
(http://www.spatial-econometrics.com/), including very clear manuals with
theory. I am unable to judge the theoretical validity of the routines but I
experienced that I was able to estimate parameters of spatial probit
regression models (with MCMC) that reflected the parameters used in the
data-generating process.
Regards,
Eelke Folmer


-----Original Message-----
From: Bjarke Christensen [mailto:Bjarke.Christensen at sydbank.dk]
Sent: 27 May 2008 12:41
To: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] spatial probit

Agus,

I recently asked a very similar question, and got the following thoughtful
reply from Roger Bivand:
https://stat.ethz.ch/pipermail/r-sig-geo/2008-May/003527.html

For my purpose, which is to estimate probabilities for use in an inverse
probability weighted regression, I've decided to explore alternative
routes, but if you find a way to estimate a probit model with a spatially
lagged limited dependent variable as a predictor, I'd be interested in
hearing about it as well.

Bjarke Christensen



------------------------------

Message: 2
Date: Wed, 28 May 2008 16:21:18 +0200
From: "Mauricio Zambrano" <hzambran.newsgroups at gmail.com>
Subject: [R-sig-Geo] Problem overlying Kriging grid with measurement
        points
To: r-sig-geo at stat.math.ethz.ch
Message-ID:
        <63d616b0805280721s3b026989g5c055d14e3ccb5c3 at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

Dear List,

I carried out a IDW interpolation and I got a plot of the
interpolations values over the grid that I defined.

However, for a better interpretation of the results, I would like to
plot, over the Kriging grid, the points that were used as data for the
interpolation, which are stored in a shapefile.

For doing this, I tried with:
spplot(pp.idw["var1.pred"], main="Daily Mean PP, [mm]", sp.layout =
list("SpatialPointsDataFrame", meteo_pt[,"PP_DAILY_MEAN_MM"] ) )

but I only get the plot of the interpolated value over the grid, and
the plot shows the following error message:

"error using packet 1"
"Missing 'data' argument, no omission value"

Could you give some hint about what I'm doing wrong ?.

Additional information is:

class(pp.idw)
[1] "SpatialPixelsDataFrame"
attr(,"package")
[1] "sp"

 class(meteo_pt)
[1] "SpatialPointsDataFrame"
attr(,"package")
[1] "sp"


And complete tried procedure:

p4s <- CRS("+proj=utm +zone=30 +ellps=intl +units=m +no_defs")

meteo <- read.csv2("Meteorological_by_basin.csv")

# Selecting only those stations that have a NON "NA" value on the
field "PP_DAILY_MEAN_MM":
meteo_nna <- meteo[!is.na(meteo[,"PP_DAILY_MEAN_MM"]),]

# Settting the COORDINATES
coordinates(meteo_nna) <- ~EAST_ED50 + NORTH_ED50

# Projecting the coordinates of the meteorological stations into the
right system
proj4string(meteo_nna) = p4s
#proj4string(meteo_nna) <- CRS("+init=epsg:28992") ; # another way to
set up the coordinates

# Reading the boundary of the catchment
library(maptools)
catchment <- readShapePoly("only_catchment.shp", proj4string=p4s)

# Defining a sampling GRID of 1000mx1000m with regular spacing
# For avoiding a random grid (sampled randomly from the first cell),
and getting a fixed,
# and reproducable grid, it is neccessary to add the argument "offset
= c(0.5, 0.5)"
catchment.grid <- spsample(catchment, type="regular", cellsize=1000,
offset = c(0.5, 0.5))

# Makin possible that the grid can be used in the interpolations:
gridded(catchment.grid) <- TRUE

# Plotting the grid
spplot(catchment, sp.layout = list("sp.points", catchment.grid))

library(gstat)
# Interpolating with the INVERSE DISTANCE WEIGHTED
pp.idw <- krige(PP_DAILY_MEAN_MM~1, meteo_nna, catchment.grid)

# Plotting the interpolated values
spplot(pp.idw["var1.pred"], main="Daily Mean PP, [mm]")

# Reading the Meteorologicla Stations whitin the cachment
meteo_pt <- readShapePoints("meteo_by_basin.shp", proj4string=p4s)

#Attempting to get the overlay:
spplot(pp.idw["var1.pred"], main="Daily Mean PP, [mm]", sp.layout =
list("SpatialPointsDataFrame", meteo_pt[,"PP_DAILY_MEAN_MM"] ) )


Thanks in advance,

Mauricio

--
Linux user #454569 -- Ubuntu user #17469



------------------------------

Message: 3
Date: Wed, 28 May 2008 16:31:49 +0200 (CEST)
From: Roger Bivand <Roger.Bivand at nhh.no>
Subject: Re: [R-sig-Geo] Problem overlying Kriging grid with
        measurement points
To: Mauricio Zambrano <hzambran.newsgroups at gmail.com>
Cc: r-sig-geo at stat.math.ethz.ch
Message-ID: <Pine.LNX.4.64.0805281630020.24036 at reclus.nhh.no>
Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed

On Wed, 28 May 2008, Mauricio Zambrano wrote:

> Dear List,
>
> I carried out a IDW interpolation and I got a plot of the
> interpolations values over the grid that I defined.
>
> However, for a better interpretation of the results, I would like to
> plot, over the Kriging grid, the points that were used as data for the
> interpolation, which are stored in a shapefile.
>
> For doing this, I tried with:
> spplot(pp.idw["var1.pred"], main="Daily Mean PP, [mm]", sp.layout =
> list("SpatialPointsDataFrame", meteo_pt[,"PP_DAILY_MEAN_MM"] ) )
>
> but I only get the plot of the interpolated value over the grid, and
> the plot shows the following error message:
>
> "error using packet 1"
> "Missing 'data' argument, no omission value"
>
> Could you give some hint about what I'm doing wrong ?.

sp.layout=list("sp.points", meteo_pt)

See Note in ?spplot

Roger

>
> Additional information is:
>
> class(pp.idw)
> [1] "SpatialPixelsDataFrame"
> attr(,"package")
> [1] "sp"
>
> class(meteo_pt)
> [1] "SpatialPointsDataFrame"
> attr(,"package")
> [1] "sp"
>
>
> And complete tried procedure:
>
> p4s <- CRS("+proj=utm +zone=30 +ellps=intl +units=m +no_defs")
>
> meteo <- read.csv2("Meteorological_by_basin.csv")
>
> # Selecting only those stations that have a NON "NA" value on the
> field "PP_DAILY_MEAN_MM":
> meteo_nna <- meteo[!is.na(meteo[,"PP_DAILY_MEAN_MM"]),]
>
> # Settting the COORDINATES
> coordinates(meteo_nna) <- ~EAST_ED50 + NORTH_ED50
>
> # Projecting the coordinates of the meteorological stations into the
> right system
> proj4string(meteo_nna) = p4s
> #proj4string(meteo_nna) <- CRS("+init=epsg:28992") ; # another way to
> set up the coordinates
>
> # Reading the boundary of the catchment
> library(maptools)
> catchment <- readShapePoly("only_catchment.shp", proj4string=p4s)
>
> # Defining a sampling GRID of 1000mx1000m with regular spacing
> # For avoiding a random grid (sampled randomly from the first cell),
> and getting a fixed,
> # and reproducable grid, it is neccessary to add the argument "offset
> = c(0.5, 0.5)"
> catchment.grid <- spsample(catchment, type="regular", cellsize=1000,
> offset = c(0.5, 0.5))
>
> # Makin possible that the grid can be used in the interpolations:
> gridded(catchment.grid) <- TRUE
>
> # Plotting the grid
> spplot(catchment, sp.layout = list("sp.points", catchment.grid))
>
> library(gstat)
> # Interpolating with the INVERSE DISTANCE WEIGHTED
> pp.idw <- krige(PP_DAILY_MEAN_MM~1, meteo_nna, catchment.grid)
>
> # Plotting the interpolated values
> spplot(pp.idw["var1.pred"], main="Daily Mean PP, [mm]")
>
> # Reading the Meteorologicla Stations whitin the cachment
> meteo_pt <- readShapePoints("meteo_by_basin.shp", proj4string=p4s)
>
> #Attempting to get the overlay:
> spplot(pp.idw["var1.pred"], main="Daily Mean PP, [mm]", sp.layout =
> list("SpatialPointsDataFrame", meteo_pt[,"PP_DAILY_MEAN_MM"] ) )
>
>
> Thanks in advance,
>
> Mauricio
>
>

--
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



------------------------------

Message: 4
Date: Wed, 28 May 2008 16:53:12 +0200
From: "Mauricio Zambrano" <hzambran.newsgroups at gmail.com>
Subject: Re: [R-sig-Geo] Problem overlying Kriging grid with
        measurement     points
To: Roger.Bivand at nhh.no
Cc: r-sig-geo at stat.math.ethz.ch
Message-ID:
        <63d616b0805280753s4a2ee1c7l44407aaf7a5706c3 at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

Thanks a lot !. it works.

I had read the ?spplot before, but because I'm new in this topic, I
didn't figure out how to do the overlay in the right way.

My humble opinion, and thinking in newbies, I think that it could be a
good idea to add an example about this (just one line) to the next
version of the documentation of the gstat package, and/or  to the
gstat_package-tutorial.pdf file.

Again, thanks a lot.

--
Mauricio

Linux user #454569 -- Ubuntu user #17469



------------------------------

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


End of R-sig-Geo Digest, Vol 57, Issue 25



From jennifer.argent at yahoo.co.uk  Tue Jun  3 12:49:31 2008
From: jennifer.argent at yahoo.co.uk (Jennifer Argent)
Date: Tue, 3 Jun 2008 10:49:31 +0000 (GMT)
Subject: [R-sig-Geo] Spatial Autocorrelation
Message-ID: <764149.65547.qm@web27701.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080603/019e775c/attachment.pl>

From yud at mail.montclair.edu  Tue Jun  3 15:42:03 2008
From: yud at mail.montclair.edu (Danlin Yu)
Date: Tue, 03 Jun 2008 09:42:03 -0400
Subject: [R-sig-Geo] Spatial Autocorrelation
In-Reply-To: <764149.65547.qm@web27701.mail.ukl.yahoo.com>
References: <764149.65547.qm@web27701.mail.ukl.yahoo.com>
Message-ID: <48454A2B.107@mail.montclair.edu>

Jennifer:

To calculate the moran's Index, you need a spatial weight linkage object 
(in SPDEP language, a listw object). The listw object can be obtained 
from the set of coordinates you have. I'll show how I did it from the 
set of information you provide:

I copy&paste your information into a ".csv" file, say "samples.csv". 
Here are the commands in R:

#load SPDEP:

library(spdep)

#change the current folder to where your ".csv" file is, then read it 
using read.csv() function into a list object called test:

test<-read.csv("samples.csv")

#combine the first two columns to be coordinates:

coords<-cbind(test$loc_x,test$loc_y)

#create a neighborhood list object (in SPDEP, an "nb" object)
#since they are points object, you have two choices determining the 
neighbor list, one is dnearneigh(), which uses lower and upper distance 
bound to determine
#neighborhood, another is knearneigh(), which uses the number of nearest 
neighbors to determine the neighborhood. You can use ?dnearneigh or 
?knearneigh to find out more
#for illustration purpose, I am using the knearneigh() function here, 
and assume 4 nearest neighbors as every point's neighborhood:

test.nb<-knn2nb(knearneigh(coords,k=4))

#create the listw object:

test.listw<-nb2listw(test.nb)

#now since you have the listw object (test.listw), you can calculate the 
Moran's Index for the variable you are interested, let's assume it is 
descham_sp:

descham_sp<-test$descham_sp
descham_sp.moran<-moran(descham_sp,test.listw,length(descham_sp),Szero(test.listw))

#you can test whether or not the calcuated Moran's Index is 
statistically significantly using either randomization or saddlepoint 
approximation:

#randomization:

moran.test(descham_sp,test.listw)

#saddlepoint approximation:

lm.morantest.sad(lm(descham_sp~1),test.listw)


The relevant reference can be found by using ? plus relevant function names.

Hope this helps.

Cheers,
Danlin

Jennifer Argent wrote:
> Hi,
> &nbsp;
> I want to test for spatial autocorrelation of vegetation cover in fixed plots across a site. I thought that using Moran's I in spdep would be suitable but as I am fairly new to R I am quite confused by the script and how I should set out my data.
> &nbsp;
> My data is in the following format (an extract only)&nbsp;with location in an x,y&nbsp;columns followed by the variables concerning vegetation&nbsp;in percentage cover
> &nbsp;
>
>
>
>
>
>
> loc_x
> loc_y
> &nbsp;festuca_sp
> lolium_sp
> agrostis_sp
> descham_sp
> calluna_vulg
> perc_cov
>
> 409471
> 397133
> 6
> 0
> 0
> 0
> 100
> 98
>
> 409475
> 397141
> 0
> 0
> 0
> 12
> 65
> 95
>
> 409511
> 397279
> 0
> 0
> 1
> 85
> 30
> 98
>
> 409513
> 397284
> 0
> 0
> 1
> 40
> 0
> 99
>
> 409511
> 397276
> 0
> 0
> 1
> 30
> 0
> 90
>
> 409498
> 397073
> 0
> 0
> 1
> 30
> 60
> 98
>
> 409509
> 397076
> 0
> 0
> 0
> 4
> 60
> 99
>
> 409508
> 397060
> 8
> 0
> 0
> 0
> 60
> 100
>
> 409598
> 397107
> 15
> 0
> 1
> 45
> 0
> 90
>
> 409595
> 397109
> 1
> 0
> 1
> 44
> 0
> 98
>
> 409589
> 397121
> 5
> 0
> 1
> 60
> 0
> 95
> &nbsp;
> I would really appreciate advice on this as I am still finding my feet with R. I am using R in windows xp.
> &nbsp;
> Kind regards
> Jen
>
>
>
>
>
>       __________________________________________________________
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
___________________________________________
Danlin Yu, Ph.D.
Assistant Professor
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
email: yud at mail.montclair.edu
webpage: csam.montclair.edu/~yu



From swpt07 at gmail.com  Tue Jun  3 17:54:37 2008
From: swpt07 at gmail.com (steven wilson)
Date: Tue, 3 Jun 2008 11:54:37 -0400
Subject: [R-sig-Geo] akima interpolation + Delaunay triangulation
Message-ID: <25944ea00806030854x141d3beexb1711adf45ca9511@mail.gmail.com>

Dear all;

I would like to have some input from anybody who have used the
interpolation function (interp) in the akima package and the
triangulation function (tri.mesh) from the tripack pakage. My problem
is that for a given data set these functions return errors in R while
in S-Plus they don't. The versions of these functions in S-Plus
(S+SpatialStats) can be slightly different to those in R but the
output shoould be the same or approx the same because they're based on
the same algorithm and fortran code.

Here is the code in R:

library(akima)
library(fields)
library(tripack)

soil <- read.table("http://www.unc.edu/~zhuz/teaching/Stat890/Data/soil.txt",header=TRUE)
attach(soil)
soil.interp <- interp(u, v, moist) # linear interpolation works and
the results are similar to those in S-Plus
plot.surface(soil.interp)

# spline interpolation
soil.interp2 <- interp(u, v, moist, linear = F) # spline interpolation
returns only NA's in R while using S-Plus it works fine

# triangulation
tri.mesh(soil$u, soil$v)  # error in R, works in S-Plus

Any comments will be appreciated

Thanks



From Andrew.McFadden at maf.govt.nz  Tue Jun  3 22:23:16 2008
From: Andrew.McFadden at maf.govt.nz (Andrew McFadden)
Date: Wed, 4 Jun 2008 08:23:16 +1200
Subject: [R-sig-Geo] Kernel smoothing: the poly part of kernel12d
Message-ID: <819062A97D2DF1468F1E1117A699282701B1D06F@wdcwmsp58.network.maf.govt.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080604/397f9420/attachment.pl>

From FredeA.Togersen at agrsci.dk  Wed Jun  4 11:15:20 2008
From: FredeA.Togersen at agrsci.dk (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Wed, 4 Jun 2008 11:15:20 +0200
Subject: [R-sig-Geo] akima interpolation + Delaunay triangulation
In-Reply-To: <25944ea00806030854x141d3beexb1711adf45ca9511@mail.gmail.com>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC061A06F5@DJFPOST01.djf.agrsci.dk>


In answering Steven I forgot to address this list also, so here is a repost of my answer (see below). At closing the R session in Emacs/ESS I got this: 


> Save workspace image? [y/n/c]: n
 
*** SDTRAN Error 2: The first three data points are collinear.

    Error detected in SDTRAN called by SDSF3P

 
*** SDTRAN Error 2: The first three data points are collinear.

    Error detected in SDTRAN called by SDSF3P

 
*** SDTRAN Error 2: The first three data points are collinear.

    Error detected in SDTRAN called by SDSF3P


Process R finished at Wed Jun 04 11:05:28 2008

For this reason I have included the maintainer in the list. It support my answer.



My answer to Steven:

I think that it is because you data allready is gridded.

See ?interp where it is mentioned in the section on arguments:

          'x', 'y', and 'z' must be the same length and may contain no
          fewer than four points. The points of 'x' and 'y' cannot be
          collinear, i.e, they cannot fall on the same line (two
          vectors 'x' and 'y' such that 'y = ax + b' for some 'a', 'b'
          will not be accepted). 'interp' is meant for cases in which
          you have 'x', 'y' values scattered over a plane and a 'z'
          value for each.  If, instead, you are trying to evaluate a
          mathematical function, or get a graphical interpretation of
          relationships that can be described by a polynomial, try
          'outer()'. 

Try:

par(mfrow=c(2,1))
plot(u,v)
plot(jitter(u),jitter(v))

soil.interp3 <- interp(jitter(u),jitter(v),moist, linear=FALSE)
plot.surface(soil.interp3)


Best regards

Frede Aakmann T?gersen
Scientist


UNIVERSITY OF AARHUS
Faculty of Agricultural Sciences
Dept. of Genetics and Biotechnology
Blichers All? 20, P.O. BOX 50
DK-8830 Tjele

Phone:   +45 8999 1900
Direct:  +45 8999 1878

E-mail:  FredeA.Togersen at agrsci.dk
Web:	   http://www.agrsci.org				

This email may contain information that is confidential.
Any use or publication of this email without written permission from Faculty of Agricultural Sciences is not allowed.
If you are not the intended recipient, please notify Faculty of Agricultural Sciences immediately and delete this email.




> -----Oprindelig meddelelse-----
> Fra: r-sig-geo-bounces at stat.math.ethz.ch 
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] P? vegne af steven wilson
> Sendt: 3. juni 2008 5:55
> Til: r-sig-geo at stat.math.ethz.ch
> Emne: [R-sig-Geo] akima interpolation + Delaunay triangulation
> 
> Dear all;
> 
> I would like to have some input from anybody who have used 
> the interpolation function (interp) in the akima package and 
> the triangulation function (tri.mesh) from the tripack 
> pakage. My problem is that for a given data set these 
> functions return errors in R while in S-Plus they don't. The 
> versions of these functions in S-Plus
> (S+SpatialStats) can be slightly different to those in R but 
> the output shoould be the same or approx the same because 
> they're based on the same algorithm and fortran code.
> 
> Here is the code in R:
> 
> library(akima)
> library(fields)
> library(tripack)
> 
> soil <- 
> read.table("http://www.unc.edu/~zhuz/teaching/Stat890/Data/soi
> l.txt",header=TRUE)
> attach(soil)
> soil.interp <- interp(u, v, moist) # linear interpolation 
> works and the results are similar to those in S-Plus
> plot.surface(soil.interp)
> 
> # spline interpolation
> soil.interp2 <- interp(u, v, moist, linear = F) # spline 
> interpolation returns only NA's in R while using S-Plus it works fine
> 
> # triangulation
> tri.mesh(soil$u, soil$v)  # error in R, works in S-Plus
> 
> Any comments will be appreciated
> 
> Thanks
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 



From hengl at science.uva.nl  Wed Jun  4 14:00:30 2008
From: hengl at science.uva.nl (Tomislav Hengl)
Date: Wed, 4 Jun 2008 14:00:30 +0200
Subject: [R-sig-Geo] Defining a grid for interpolations ?
In-Reply-To: <63d616b0805270626w7aedf098y5879bd1346d93ff1@mail.gmail.com>
Message-ID: <004901c8c63a$962c7d40$3a871291@pcibed193>


FYI

I have just finishing preparing an R script that accompanies my paper in Computers in Geosciences on
finding the grid cell size for various applications.

The script and the data sets can be obtained from:

http://spatial-analyst.net/pixel.php 

This gives a step-by-step guide to estimate suitable grid cell sizes given an input data with its
inherent properties: scale, positional accuracy, inspection density, spatial correlation and
complexity of terrain. The bottom line is that there are objective ways to calculate a suitable cell
size (or at least a range of suitable cell sizes), and that the selection of grid cell size can be
automated. For example, using the akima package we can automate estimation of the grid:

> lbrary(maptools)
> elevations <- readShapePoints("elevations.shp", proj4string=CRS(as.character(NA)))
> library(akima)
> elevations.interp <- interp(x=elevations at coords[,1],y=elevations at coords[,2],z=elevations$VALUE,
extrap=T, linear=F)
> image(elevations.interp, col=bpy.colors(), asp=1)
> library(spatstat)
> dem.interp <- as.SpatialGridDataFrame.im(as.im(elevations.interp))
> dem.interp at grid

But I would rather first fit a variogram and then select the cell size based on the number of point
pairs and given the effective range of spatial autocorrelation.


For more info see also:

Hengl T., 2006. Finding the right pixel size. Computers and Geosciences, 32(9): 1283-1298.
http://dx.doi.org/10.1016/j.cageo.2005.11.008 


Tom Hengl
http://spatial-analyst.net 



-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
Mauricio Zambrano
Sent: dinsdag 27 mei 2008 15:27
To: Edzer Pebesma; Paul Hiemstra
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] Defining a grid for interpolations ?

Dear Paul and Edzer,

Thanks a lot for your answers.

Before reading the solution proposed by Paul, I had tried with:

# reading the boundary of the catchment
library(maptools)
catchment <- readShapePoly("only_catchment.shp")
catchment.grid <- spsample(catchment, cellsize=100, offset = c(0.5,
0.5)) # reading the boundary of the catchment

 and then I did an IDW interpolation with:

pp.idw <- krige(PP_DAILY_MEAN_MM~1, meteo, catchment.grid)

and it works.

However, after reading your solution, I realised that I didn't use the command:

gridded(catchment.grid)

but I got an interpolation anyway.

Where is performed the interpolation when I don't use a gridded grid (
gridded(catchment.grid) ) ?

Best regards

Mauricio

2008/5/26 Edzer Pebesma <edzer.pebesma at uni-muenster.de>:
> Please note that this "regular" grid is still random, as the first point is
> sampled randomly from the first cell. For a fixed, reproducable grid, add
> the argument offset = c(0.5, 0.5)
> --
> Edzer
>
> Paul Hiemstra wrote:
>>
>> Hi Mauricio,
>>
>> To get a grid based on a shapefile you can use the command "spsample".
>>
>> library(sp)
>> library(maptools)
>> source_poly = readShapePoly("/path/to/poly")
>> # cellsize is in map units (e.g. km), also see "?spsample"
>> grd = spsample(source_poly, cellsize = c(10e3,10e3), type = "regular")
>> gridded(grd) = TRUE # Make it a grid
>> summary(grd)
>> # Visualize the grid
>> spplot(source_poly, sp.layout = list("sp.points", grd))
>>
>> "grd" can now be used for interpolations.
>>
>> hth and cheers,
>> Paul
>>
>> Mauricio Zambrano wrote:
>>>
>>> Dear List,
>>>
>>> My question is about how to define the grid to be used for the
>>> interpolations, using R 2.7.0 and gstat 0.9-47
>>>
>>> I'm working in a catchment of ~3000 km2, with daily rainfall data of
>>> several stations (more than 40), and I would like to interpolate daily
>>> values within all the catchment using ordinary Kriging.
>>>
>>> For defining the grid in which the interpolation will be carried out,
>>> at the beginning, I tried with
>>>
>>> #setting a grid each 100m vertical and horizontal
>>> dx <- seq(674400,730700,by=100)
>>> dy <- seq(4615100,4744400,by=100)
>>> catch.grid <- expand.grid(dx,dy)
>>>
>>> #setting the names of the columns of the grid
>>> names(catch.grid) <- c("x","y")
>>>
>>> #setting the coordinates of the grid
>>> coordinates(catch.grid) <- ~x+y
>>>
>>> #interpolating with the inverse distance
>>> pp.idw <- krige(PP_DAILY_MEAN_MM~1, meteo_catch_nNA, catch.grid)
>>>
>>> #plotting the interpolated values
>>> spplot(pp.idw["var1.pred"], main="Daily Mean PP, [mm]")
>>>
>>> but looking at the figure I realized that the interpolations were
>>> carried out considering all the cells within the squared grid, and not
>>> only within the catchment.
>>>
>>> After, I tried reading a raster file (each 100m) and using it as the
>>> grid,
>>>
>>> DEMM100m <- read.asciigrid("Catch_DEM_c100m")
>>>
>>> but the results that I got seems to be wrong, because I got high
>>> values where low values were expected and viceversa. (I really
>>> appreciate any help clarifying me what I'm doing wrong )
>>>
>>> Is there any way to define a grid, starting from a shapefile of the
>>> catchment boundaries ?. For example, I would like to define something
>>> similar to the "meuse.grid" dataset.
>>>
>>> Thanks in advance and best regards
>>>
>>>
>>
>>
>
>



-- 
hzambran

Linux user #454569 -- Ubuntu user #17469

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From mgallay01 at qub.ac.uk  Thu Jun  5 15:44:54 2008
From: mgallay01 at qub.ac.uk (Michal Gallay)
Date: 05 Jun 2008 14:44:54 +0100
Subject: [R-sig-Geo] several 'if' conditions with 'apply'
Message-ID: <Prayer.1.0.12.0806051444540.12650@localhost.localdomain>

Dear R Users,

I am trying to apply a function to each cell of a data frame, which can 
contain NAs, or values between -360 to +360.

The function should test if each value fullfils one of the conditions and 
converts this value accordingly.
 
As can be seen from the outputs it seems that only the last 'if' condition 
in the 'else' block is applied so that only some values were correctly 
transformed.

I cannot really get my head around this, what I am doing wrong. I tried 
several versions. I feel I am missing something very simple but I just 
can't see it.

Would some be able to help please?

Thank you very much for any directions of how to approach it.

Michal

> resid
       a   b  c   d    e    f
7325 270  10  0   4    7  107
7326  NA  NA NA  NA   NA   NA
7327  NA  NA NA  NA   NA   NA
7328 212 330  0 321   -1   -1
7329   3   5  0  22 -292 -215
7330 353 345  0 317  359  126
> 
> my.fun <- function(xx)
+  {
+ 
+   if(is.na(xx)) # if the value at xx is NA, let it be otherwise ...
+    {
+     xx=xx
+    } else 
+    {
+ if(xx < 180 & xx > 0 || xx == 180 || xx == -180 || xx ==0) xx=abs(xx);
+ if(xx > -180 & xx <0) xx=xx;
+ if(xx > 180 & xx < 360) xx=xx-360;
+ if(xx < -180 & xx > -360) xx=xx+360
+    }
+  }
> 
> 
> bb <- apply(resid, c(1,2), my.fun)
> bb
     a    b    c    d    e    f   
7325 NULL NULL NULL NULL NULL NULL
7326 NA   NA   NA   NA   NA   NA  
7327 NA   NA   NA   NA   NA   NA  
7328 NULL NULL NULL NULL NULL NULL
7329 NULL NULL NULL NULL 68   145 
7330 NULL NULL NULL NULL NULL NULL
> 

PS:
> sessionInfo()
R version 2.6.2 (2008-02-08) 
i386-pc-mingw32 

locale: 
LC_COLLATE=Slovak_Slovakia.1250;LC_CTYPE=Slovak_Slovakia.1250;LC_MONETARY=Slovak_Slovakia.1250;LC_NUMERIC=C;LC_TIME=Slovak_Slovakia.1250 
attached base packages: [1] stats graphics grDevices utils datasets methods 
base other attached packages: [1] circular_0.3-8 boot_1.2-31 rgdal_0.5-24 
sp_0.9-23 loaded via a namespace (and not attached): [1] grid_2.6.2 
lattice_0.17-6 rcompgen_0.1-17 tools_2.6.2
> 

-- 
Michal Gallay

Postgraduate Research Student
School of Geography, Archaeology and Palaeoecology
Queen's University
Belfast BT7 1NN
Northern Ireland

Tel: +44(0)2890 273929
Fax: +44(0)2890 973212
email: mgallay01 at qub.ac.uk
www: www.qub.ac.uk/geog



From a.crowe at lancaster.ac.uk  Thu Jun  5 17:12:07 2008
From: a.crowe at lancaster.ac.uk (Crowe, Andrew)
Date: Thu, 5 Jun 2008 16:12:07 +0100
Subject: [R-sig-Geo] several 'if' conditions with 'apply'
References: <Prayer.1.0.12.0806051444540.12650@localhost.localdomain>
Message-ID: <BB501CE635E5144CA5E30956E5E32C5201A6F765@exchange-be5.lancs.local>

Michal
 
All the if statements are evaluated in your code, so the value of xx is assigned by the final if statement.  This should be solved by using 'else if' so that the code drops out of the else block when the value is assigned.
 
Regards
 
Andrew
 
Dr Andrew Crowe
 
Lancaster Environment Centre
Lancaster University
Lancaster    LA1 4YQ
UK
 
Tel: +44 (0)1524 595879

________________________________

From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Michal Gallay
Sent: Thu 05/06/2008 2:44 PM
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] several 'if' conditions with 'apply'



Dear R Users,

I am trying to apply a function to each cell of a data frame, which can
contain NAs, or values between -360 to +360.

The function should test if each value fullfils one of the conditions and
converts this value accordingly.

As can be seen from the outputs it seems that only the last 'if' condition
in the 'else' block is applied so that only some values were correctly
transformed.

I cannot really get my head around this, what I am doing wrong. I tried
several versions. I feel I am missing something very simple but I just
can't see it.

Would some be able to help please?

Thank you very much for any directions of how to approach it.

Michal

> resid
       a   b  c   d    e    f
7325 270  10  0   4    7  107
7326  NA  NA NA  NA   NA   NA
7327  NA  NA NA  NA   NA   NA
7328 212 330  0 321   -1   -1
7329   3   5  0  22 -292 -215
7330 353 345  0 317  359  126
>
> my.fun <- function(xx)
+  {
+
+   if(is.na(xx)) # if the value at xx is NA, let it be otherwise ...
+    {
+     xx=xx
+    } else
+    {
+ if(xx < 180 & xx > 0 || xx == 180 || xx == -180 || xx ==0) xx=abs(xx);
+ if(xx > -180 & xx <0) xx=xx;
+ if(xx > 180 & xx < 360) xx=xx-360;
+ if(xx < -180 & xx > -360) xx=xx+360
+    }
+  }
>
>
> bb <- apply(resid, c(1,2), my.fun)
> bb
     a    b    c    d    e    f  
7325 NULL NULL NULL NULL NULL NULL
7326 NA   NA   NA   NA   NA   NA 
7327 NA   NA   NA   NA   NA   NA 
7328 NULL NULL NULL NULL NULL NULL
7329 NULL NULL NULL NULL 68   145
7330 NULL NULL NULL NULL NULL NULL
>

PS:
> sessionInfo()
R version 2.6.2 (2008-02-08)
i386-pc-mingw32

locale:
LC_COLLATE=Slovak_Slovakia.1250;LC_CTYPE=Slovak_Slovakia.1250;LC_MONETARY=Slovak_Slovakia.1250;LC_NUMERIC=C;LC_TIME=Slovak_Slovakia.1250
attached base packages: [1] stats graphics grDevices utils datasets methods
base other attached packages: [1] circular_0.3-8 boot_1.2-31 rgdal_0.5-24
sp_0.9-23 loaded via a namespace (and not attached): [1] grid_2.6.2
lattice_0.17-6 rcompgen_0.1-17 tools_2.6.2
>

--
Michal Gallay

Postgraduate Research Student
School of Geography, Archaeology and Palaeoecology
Queen's University
Belfast BT7 1NN
Northern Ireland

Tel: +44(0)2890 273929
Fax: +44(0)2890 973212
email: mgallay01 at qub.ac.uk
www: www.qub.ac.uk/geog

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From Giovanna.Jonalasinio at uniroma1.it  Fri Jun  6 16:01:23 2008
From: Giovanna.Jonalasinio at uniroma1.it (Giovanna.Jonalasinio at uniroma1.it)
Date: Fri, 6 Jun 2008 16:01:23 +0200
Subject: [R-sig-Geo] =?iso-8859-1?q?Giovanna_Jonalasinio_=E8_fuori_ufficio?=
	=?iso-8859-1?q?=2C_I=27m_away?=
Message-ID: <OFF9D03377.DB0C832C-ONC1257460.004D0802-C1257460.004D0802@Uniroma1.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080606/d449d602/attachment.pl>

From milton.ruser at gmail.com  Sat Jun  7 21:03:32 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Sat, 7 Jun 2008 16:03:32 -0300
Subject: [R-sig-Geo] handling circles
Message-ID: <3aaf1a030806071203t41b1e707t311554920bc36688@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080607/45368e37/attachment.pl>

From Roger.Bivand at nhh.no  Sat Jun  7 21:28:56 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 7 Jun 2008 21:28:56 +0200 (CEST)
Subject: [R-sig-Geo] handling circles
In-Reply-To: <3aaf1a030806071203t41b1e707t311554920bc36688@mail.gmail.com>
References: <3aaf1a030806071203t41b1e707t311554920bc36688@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0806072123250.1630@reclus.nhh.no>

On Sat, 7 Jun 2008, milton ruser wrote:

> Dear All
>
>
> I need to handly some circular-shaped polygons on R. First I adapted the
> code from Barry Rowlingson to create a function that create the list of X-Y
> points which create a circle with a specified radii. After that I need to
> save each circle as shapefile with writeOGR. My last task is to identify the
> region that are overlaped by three circles.
>
> I tryed to convert my points to Polygon, and after to SpatialPolygons, but
> got error. Can anyone help me on this task?
>
> Kind regards,
>
> miltinho
>
>
> createCircle <- function(x,y,r,start=0,end=2*pi,nsteps=20,...){
> ## adapted from Barry Rowlingson (2004)
>   rs <- seq(start,end,len=nsteps)
>   xc <- x+r*cos(rs)
>   yc <- y+r*sin(rs)
>   polygon(xc,yc,...)
>
>   my.pol<-cbind(xc,yc)
>   return<-my.pol
> }
>
>
> plot(1:10, type="n")
> my.circle1<-createCircle(5,5,2, col="blue")
> my.circle2<-createCircle(7,6,1,col="transparent")
> my.circle3<-createCircle(7,4.5,1.5,col="transparent")
>
>
> my.circle1.Sr <- Polygon(my.circle1)

The error message here was:

Error in validityMethod(object) : ring not closed

so you need a line closing it in your function:

createCircle <- function(x,y,r,start=0,end=2*pi,nsteps=20,...){
    rs <- seq(start,end,len=nsteps)
    xc <- x+r*cos(rs)
    yc <- y+r*sin(rs)
    my.pol<-cbind(xc,yc)
    my.pol <- rbind(my.pol, my.pol[1,])
    my.pol
}


>From there:

my.circle1.Sr <- Polygons(list(Polygon(my.circle1)), ID="1")
...
my.circle1.Sr.SpatPol <- SpatialPolygons(list(my.circle1.Sr))

where the list would contain your collection of circles as a Polygon 
object inside a Polygons object, before assembling them in a 
SpatialPolygons object.

rn <- sapply(slot(my.circle1.Sr.SpatPol, "polygons"), function(x) slot(x,
   "ID"))
df <- data.frame(rn=rn, row.names=rn)
all.circles <- SpatialPolygonsDataFrame(my.circle1.Sr.SpatPol, data=df)

To output it as a shapefile, it needs a data frame too, so you will need 
to make something like all.circles.

Thanks for a well-structured question, it makes answering so much more 
straight-forward.

Roger

> my.circle1.Sr.SpatPol <- SpatialPolygons(my.circle1.Sr)
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From edzer.pebesma at uni-muenster.de  Mon Jun  9 10:32:50 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 09 Jun 2008 10:32:50 +0200
Subject: [R-sig-Geo] geoinformatics innovation price
Message-ID: <484CEAB2.1020202@uni-muenster.de>

52north, a spin-off with strong links to our department, has written out 
a contest for the innovation price in geoinformatics, see

http://52north.org/index.php?option=com_content&task=view&id=213&Itemid=148

Needless to say that I'd be more than happy to see submissions on the 
geoinformatics-R interface!
--
Edzer



From regmi_pujan at hotmail.com  Mon Jun  9 17:23:16 2008
From: regmi_pujan at hotmail.com (PUJAN RAJ REGMI)
Date: Mon, 9 Jun 2008 15:23:16 +0000
Subject: [R-sig-Geo] Semivariogram Plot
In-Reply-To: <1213013957.990714.48512794.37458.242@otrs.cc.kuleuven.be>
References: <1213013957.990714.48512794.37458.242@otrs.cc.kuleuven.be>
Message-ID: <BAY113-W7E349F891CF40DF7D529A84B00@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080609/2734aa74/attachment.pl>

From milton.ruser at gmail.com  Mon Jun  9 22:06:33 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Mon, 9 Jun 2008 17:06:33 -0300
Subject: [R-sig-Geo] intersecting two polygons
Message-ID: <3aaf1a030806091306k5312ecch4eee72d1c20f8cbf@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080609/35214a90/attachment.pl>

From marcelino.delacruz at upm.es  Tue Jun 10 12:31:49 2008
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Tue, 10 Jun 2008 12:31:49 +0200
Subject: [R-sig-Geo] intersecting two polygons
In-Reply-To: <3aaf1a030806091306k5312ecch4eee72d1c20f8cbf@mail.gmail.com
 >
References: <3aaf1a030806091306k5312ecch4eee72d1c20f8cbf@mail.gmail.com>
Message-ID: <200806101031.m5AAVxT7022018@edison.ccupm.upm.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080610/7b3bb045/attachment.pl>

From cdouvis at geol.uoa.gr  Tue Jun 10 17:42:49 2008
From: cdouvis at geol.uoa.gr (Costas Douvis)
Date: Tue, 10 Jun 2008 18:42:49 +0300 (EEST)
Subject: [R-sig-Geo] alter the lon & lat lines and coastline according to
 the grid coordinates
Message-ID: <55398.85.73.32.162.1213112569.squirrel@webmail.uoa.gr>

Hi everyone

My problem might be easy to deal with but I have already spent quite some
time and effort with no result. Any help will be appreciated

My data come from an RCM that I ran, Regcm3. My domain spans over the
wider area of Europe. The model grid is Lambert conformal. This means that
the data values that come from the same line or column of a data matrix do
not correspond to the exact same latitude or longitude. I have the values
of latitude and longitude of each grid point in 2 matrices with the same
dimensions as my data

So what I need to do is to plot those data on a map. I guess that the best
way to do this is to plot them on a rectangle map, preferably using
filled.contour (forgetting for a moment that the grid is actually bended),
and afterwards overlay the latitude and longitude lines and the coastline
as they really are on that map (i.e. the lat and lon lines should not be
straight)

Is that possible?
Or do you have a better suggestion?

-- 
Kostas Douvis
PhD Student
University of Athens - Department of Geography and Climatology
Academy of Athens - Research Centre for Atmospheric Physics and Climatology
email: cdouvis at geol.uoa.gr
tel: +30-210-8832048, +30-210-8847280
fax: +30-210-8842098



From Roger.Bivand at nhh.no  Tue Jun 10 18:25:04 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 10 Jun 2008 18:25:04 +0200 (CEST)
Subject: [R-sig-Geo] alter the lon & lat lines and coastline according
 to the grid coordinates
In-Reply-To: <55398.85.73.32.162.1213112569.squirrel@webmail.uoa.gr>
References: <55398.85.73.32.162.1213112569.squirrel@webmail.uoa.gr>
Message-ID: <Pine.LNX.4.64.0806101810340.3881@reclus.nhh.no>

On Tue, 10 Jun 2008, Costas Douvis wrote:

> Hi everyone
>
> My problem might be easy to deal with but I have already spent quite some
> time and effort with no result. Any help will be appreciated
>
> My data come from an RCM that I ran, Regcm3.

In case anyone was unsure (I was), these are regional climate models. 
There seem to be discussion on their lists. To get control of this data 
format, you need to establish its exact representation, in PROJ.4 format. 
>From there you can - treating the grids as having point support, do what 
you want, but the first step is to find the exact PROJ.4 incantation. See 
the spTransform methods in rgdal for details. There is a copy of coarse 
GSHHS coastline data in maptools, see Rgshhs - note that these are in 
geographical coordinates.

My advice would be to try to construct a SpatialPointsDataFrame in LCC, 
but you'll meed to convert the pseudo-centres of the irregular grid cells 
in long-lat to planar coordinates first - perhaps see project in rgdal 
assuming that datum transformation is not an issue. But you'll need the 
correct lcc parameters (lat_0, lon_0, etc.) to get back to a regularly 
spaced planar grid.

Are they using ETRS_LCC?

library(rgdal)
EPSG <- make_EPSG()
EPSG[grep("ETRS-LCC", EPSG$note),]

Can you find out from the RCM documentation?

See gridlines in sp for the grid lines.

Roger

> My domain spans over the
> wider area of Europe. The model grid is Lambert conformal. This means that
> the data values that come from the same line or column of a data matrix do
> not correspond to the exact same latitude or longitude. I have the values
> of latitude and longitude of each grid point in 2 matrices with the same
> dimensions as my data
>
> So what I need to do is to plot those data on a map. I guess that the best
> way to do this is to plot them on a rectangle map, preferably using
> filled.contour (forgetting for a moment that the grid is actually bended),
> and afterwards overlay the latitude and longitude lines and the coastline
> as they really are on that map (i.e. the lat and lon lines should not be
> straight)
>
> Is that possible?
> Or do you have a better suggestion?
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From hengl at science.uva.nl  Tue Jun 10 18:58:25 2008
From: hengl at science.uva.nl (Tomislav Hengl)
Date: Tue, 10 Jun 2008 18:58:25 +0200
Subject: [R-sig-Geo] alter the lon & lat lines and coastline according
	to the grid coordinates
In-Reply-To: <55398.85.73.32.162.1213112569.squirrel@webmail.uoa.gr>
Message-ID: <007301c8cb1b$32e122f0$3a871291@pcibed193>


For European projects, we commonly use the official European Terrestrial Reference System
(www.euref.eu). You can convert your data from the longlat system to the ETRS using:

> library(maptools)
> proj4string(pointmap) <- CRS("+proj=longlat +datum=WGS84") 
> pointmap.etrs <- spTransform(pointmap, CRS("+init=epsg:3035"))
> spplot(pointmap.etrs[1])

To simply (without any intervention) generate a gridded surface showing the change of values (the
pattern), see: https://stat.ethz.ch/pipermail/r-sig-geo/2008-June/003703.html 

Many European GI data you can obtain from: EEA (http://dataservice.eea.europa.eu); but also take a
look at:
2. Land cover maps (http://www-gem.jrc.it/glc2000/) 3. Landsat images (http://image2000.jrc.it/) 4.
General type maps (http://www.inspire-geoportal.eu/)


Tom Hengl
http://spatial-analyst.net


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
Costas Douvis
Sent: dinsdag 10 juni 2008 17:43
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] alter the lon & lat lines and coastline according to the grid coordinates

Hi everyone

My problem might be easy to deal with but I have already spent quite some
time and effort with no result. Any help will be appreciated

My data come from an RCM that I ran, Regcm3. My domain spans over the
wider area of Europe. The model grid is Lambert conformal. This means that
the data values that come from the same line or column of a data matrix do
not correspond to the exact same latitude or longitude. I have the values
of latitude and longitude of each grid point in 2 matrices with the same
dimensions as my data

So what I need to do is to plot those data on a map. I guess that the best
way to do this is to plot them on a rectangle map, preferably using
filled.contour (forgetting for a moment that the grid is actually bended),
and afterwards overlay the latitude and longitude lines and the coastline
as they really are on that map (i.e. the lat and lon lines should not be
straight)

Is that possible?
Or do you have a better suggestion?

-- 
Kostas Douvis
PhD Student
University of Athens - Department of Geography and Climatology
Academy of Athens - Research Centre for Atmospheric Physics and Climatology
email: cdouvis at geol.uoa.gr
tel: +30-210-8832048, +30-210-8847280
fax: +30-210-8842098

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From milton.ruser at gmail.com  Tue Jun 10 19:07:02 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Tue, 10 Jun 2008 14:07:02 -0300
Subject: [R-sig-Geo] intersecting two polygons
In-Reply-To: <200806101031.m5AAVxT7022018@edison.ccupm.upm.es>
References: <3aaf1a030806091306k5312ecch4eee72d1c20f8cbf@mail.gmail.com>
	<200806101031.m5AAVxT7022018@edison.ccupm.upm.es>
Message-ID: <3aaf1a030806101007v10776ebbg944f926212af0a13@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080610/0b84e0d2/attachment.pl>

From milton.ruser at gmail.com  Wed Jun 11 01:59:07 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Tue, 10 Jun 2008 20:59:07 -0300
Subject: [R-sig-Geo]  intersecting two polygons
In-Reply-To: <3aaf1a030806101007v10776ebbg944f926212af0a13@mail.gmail.com>
References: <3aaf1a030806091306k5312ecch4eee72d1c20f8cbf@mail.gmail.com>
	<200806101031.m5AAVxT7022018@edison.ccupm.upm.es>
	<3aaf1a030806101007v10776ebbg944f926212af0a13@mail.gmail.com>
Message-ID: <3aaf1a030806101659i10304a7x898e7fcfc1512cde@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080610/2f8fe60e/attachment.pl>

From laura.poggio at gmail.com  Wed Jun 11 15:03:32 2008
From: laura.poggio at gmail.com (Laura Poggio)
Date: Wed, 11 Jun 2008 15:03:32 +0200
Subject: [R-sig-Geo] writing tiff/geotiff in R
In-Reply-To: <e027b8750806110555w41892ccepbd880b2a0cb216b9@mail.gmail.com>
References: <e027b8750806110555w41892ccepbd880b2a0cb216b9@mail.gmail.com>
Message-ID: <e027b8750806110603j5ac8b686t8f0845127ba91d9b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080611/a8223999/attachment.pl>

From Roger.Bivand at nhh.no  Wed Jun 11 15:23:51 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 11 Jun 2008 15:23:51 +0200 (CEST)
Subject: [R-sig-Geo] writing tiff/geotiff in R
In-Reply-To: <e027b8750806110603j5ac8b686t8f0845127ba91d9b@mail.gmail.com>
References: <e027b8750806110555w41892ccepbd880b2a0cb216b9@mail.gmail.com>
	<e027b8750806110603j5ac8b686t8f0845127ba91d9b@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0806111518001.8125@reclus.nhh.no>

On Wed, 11 Jun 2008, Laura Poggio wrote:

> Dear list,
> I managed to read an image in R and to make various elaborations on it,
> mainly clustering. Now I would like to save the results I got as tiff or
> geotiff.
> I found a lot of different examples, but none seems to work.
> Any suggestions on tutorials or code examples for saving clustering results
> as tiff?

First you need to make your object into a SpatialGridDataFrame, then 
writeGDAL in rgdal simply works. But you need to say what structure your 
object has - matrix or vector etc. Then define a GridTopology object to 
suit, add a coordinate reference system if appropriate. Maybe the sp 
package function image2Grid() will help?

Roger

>
> Thank you very much in advance
>
> LP
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From cdouvis at geol.uoa.gr  Wed Jun 11 18:29:10 2008
From: cdouvis at geol.uoa.gr (Costas Douvis)
Date: Wed, 11 Jun 2008 19:29:10 +0300 (EEST)
Subject: [R-sig-Geo] alter the lon & lat lines and coastline according
 to the grid coordinates
Message-ID: <64124.85.73.32.162.1213201750.squirrel@webmail.uoa.gr>

Thank you both very much for replying.

The truth is that I'm still confused. I found what is needed from my
model. I believe that this script represents my grid in PROJ.4 format:

"+proj=lcc +lat_1=55 +lat_2=31 +lat_0=44 +lon_0=15 +x_0=60000 +y_0=60000
+ellps=GRS80 +units=m +no_defs"

(In the model's documentation is mentioned only that the map projection is
Lambert Conformal but I guess that ETRS_LCC is right. It's the only match
when I type   EPSG[grep("LCC", EPSG$note),] )

But I still don't understand what I should do with it. Could you please
tell me again in more detail? R seems to be different that anything I ever
worked with. Here's again what I'm trying to do: To draw a map of my data
on the x-y plain (that's easy, filled contour will do fine) and then add
the correct long & lat lines (which should be curves) and the coastline.

Kostas

> On Tue, 10 Jun 2008, Costas Douvis wrote:
>
>> Hi everyone
>>
>> My problem might be easy to deal with but I have already spent quite
>> some
>> time and effort with no result. Any help will be appreciated
>>
>> My data come from an RCM that I ran, Regcm3.
>
> In case anyone was unsure (I was), these are regional climate models.
> There seem to be discussion on their lists. To get control of this data
> format, you need to establish its exact representation, in PROJ.4 format.
> From there you can - treating the grids as having point support, do what
> you want, but the first step is to find the exact PROJ.4 incantation. See
> the spTransform methods in rgdal for details. There is a copy of coarse
> GSHHS coastline data in maptools, see Rgshhs - note that these are in
> geographical coordinates.
>
> My advice would be to try to construct a SpatialPointsDataFrame in LCC,
> but you'll meed to convert the pseudo-centres of the irregular grid cells
> in long-lat to planar coordinates first - perhaps see project in rgdal
> assuming that datum transformation is not an issue. But you'll need the
> correct lcc parameters (lat_0, lon_0, etc.) to get back to a regularly
> spaced planar grid.
>
> Are they using ETRS_LCC?
>
> library(rgdal)
> EPSG <- make_EPSG()
> EPSG[grep("ETRS-LCC", EPSG$note),]
>
> Can you find out from the RCM documentation?
>
> See gridlines in sp for the grid lines.
>
> Roger
>
>> My domain spans over the
>> wider area of Europe. The model grid is Lambert conformal. This means
>> that
>> the data values that come from the same line or column of a data matrix
>> do
>> not correspond to the exact same latitude or longitude. I have the
>> values
>> of latitude and longitude of each grid point in 2 matrices with the same
>> dimensions as my data
>>
>> So what I need to do is to plo



From ddepew at sciborg.uwaterloo.ca  Wed Jun 11 19:35:19 2008
From: ddepew at sciborg.uwaterloo.ca (Dave Depew)
Date: Wed, 11 Jun 2008 13:35:19 -0400
Subject: [R-sig-Geo] anisotropy
Message-ID: <48500CD7.8060700@scimail.uwaterloo.ca>

Hi All,
I suppose this is a rather simple question...however, I'm managing to 
get more confused the more I read.
I'm doing some OK and UK using the R-gstat package...I have some data 
that is moderately anisotropic. Reading the gstat literature, it would 
seem that to specify the appropriate parameters for anisotropic 
variograms I need the set the angle equal to the direction of maximal  
data continuity? or maximal range?. The ratio of the minimum to maximum 
range appears to be straightforward enough, but the first part is 
confusing me.
As an example;
data(meuse)
 e<-variogram(dist~1, loc=~x+y,data=meuse, alpha=c(0,45,90,135))
plot(e)

Looks to me anyways, that the direction of maximum range is 45 deg, and 
the minRange/maxRange is ~ 1000/1500 = 0.67.

Could more experienced gstat users tell me if I'm out to lunch on this one??

Thanks,



From edzer.pebesma at uni-muenster.de  Wed Jun 11 20:01:59 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 11 Jun 2008 20:01:59 +0200
Subject: [R-sig-Geo] anisotropy gstat
In-Reply-To: <48500CD7.8060700@scimail.uwaterloo.ca>
References: <48500CD7.8060700@scimail.uwaterloo.ca>
Message-ID: <48501317.20008@uni-muenster.de>

Dave Depew wrote:
> Hi All,
> I suppose this is a rather simple question...however, I'm managing to 
> get more confused the more I read.
> I'm doing some OK and UK using the R-gstat package...I have some data 
> that is moderately anisotropic. Reading the gstat literature, it would 
> seem that to specify the appropriate parameters for anisotropic 
> variograms I need the set the angle equal to the direction of maximal  
> data continuity? or maximal range?. The ratio of the minimum to 
> maximum range appears to be straightforward enough, but the first part 
> is confusing me.
> As an example;
> data(meuse)
> e<-variogram(dist~1, loc=~x+y,data=meuse, alpha=c(0,45,90,135))
> plot(e)
Dave, try

require(gstat)
data(meuse)
coordinates(meuse) = ~x+y
e<-variogram(dist~1, meuse, alpha=c(0,45,90,135))
plot(e, vgm(.08, "Sph", 5000, anis=c(45, .2)))

I got there with a bit of trial and error. Clearly, for the 45 degrees 
most happens beyond 1500 m.

Of course this is just for the idea; a variogram model that has some 
parabolic behaviour at the origin would be prefered.
>
> Looks to me anyways, that the direction of maximum range is 45 deg, 
> and the minRange/maxRange is ~ 1000/1500 = 0.67.
the max correlation direction is 45, the range is, in my model, 5000, 
the anisotropy ratio 0.2.
>
> Could more experienced gstat users tell me if I'm out to lunch on this 
> one??
You weren't far off.
--
Edzer



From Jeff.Laake at noaa.gov  Wed Jun 11 20:08:08 2008
From: Jeff.Laake at noaa.gov (Jeff Laake)
Date: Wed, 11 Jun 2008 11:08:08 -0700
Subject: [R-sig-Geo] intersecting two polygons
In-Reply-To: <3aaf1a030806101007v10776ebbg944f926212af0a13@mail.gmail.com>
References: <3aaf1a030806101007v10776ebbg944f926212af0a13@mail.gmail.com>
Message-ID: <48501488.4070005@noaa.gov>

I ran into the same problem with spatstat and then discovered the gpclib 
package.  I wrote a simple function below that converts an owin poly to 
a gpc class (see below).  The snippet of code below shows how to use 
intersect and get.pts from gpclib and then to construct a poly for owin 
that uses the intersection points to create a poly dataframe for owin in 
spatstat.  I've only used this with intersection of rectangles with 
other shapes and have not tested it broadly but I don't know of any 
reason it will not work with 2 general polygons. I mentioned this in 
correspondence with Adrian Baddeley but didn't send him this code yet. 
This worked for me but there may be a better solution.  I'm a newcomer 
to this forum. --jeff

      gpc.area=owin.gpc.poly(study.area)
      b=as(data.frame(x=x,y=y),"gpc.poly")
      inside.poly=get.pts(intersect(b,gpc.area))[[1]]
      xdf= data.frame(x=rev(inside.poly$x),y=rev(inside.poly$y))
      poly=xdf[!duplicated(xdf),]

owin.gpc.poly=function(window)
##################################################################################
# Converts an owin class composed of a single polygon to a gpc.poly
#
# Arguments:  window  - an owin class
#
# Value    :  gpc.poly from first polygon in owin
#
# Jeff Laake
# 18 April 2008
##################################################################################
{
if(is.null(window$bdry))
  return(as(cbind(c(window$xrange,rev(window$xrange)),
             c(rep(window$yrange[1],2),rep(window$yrange[2],2))),
             "gpc.poly"))
else
  return(as(cbind(window$bdry[[1]]$x,window$bdry[[1]]$y),"gpc.poly"))
}



From ashton at msu.edu  Thu Jun 12 01:38:59 2008
From: ashton at msu.edu (Ashton Shortridge)
Date: Wed, 11 Jun 2008 19:38:59 -0400
Subject: [R-sig-Geo] rgdal challenges with binary ArcGrid
Message-ID: <200806111938.59405.ashton@msu.edu>

Hello,

A bit of version information: I'm running  rgdal version 0.5-24, GDAL 1.5.1 
installed on Debian. I'd like to read portions of USGS National Elevation 
Dataset (NED) files in ArcGrid format into R for various abusive purposes.

While the examples at the bottom of the readGDAL() manual page work fine for 
me, I get the following error when I try on one of my NED DEMS:
readGDAL(test.filename, offset=c(50,50), region.dim=c(100,100))
Error in .local(.Object, ...) :
        GDAL Error 3: Attempt to read past EOF in /{lengthy path 
removed}/../info/arc.dir.

I get the same error with GDALinfo(), and I get the same error with every Arc 
Grid I have tried. It does not appear that arc.dir has any relevant 
information for my purposes.

From the command line, gdalinfo gives the same error, but goes on to provide 
plenty of information - more of a warning than an error, perhaps. And 
gdal_translate also lists the error (also an error about failing to open the 
VAT table), but goes on to subset the grid and produce output anyway.

So... readGDAL() does not appear to have to read arc.dir to work - at least 
gdal_translate does not require it. Is there a way to "convince" readGDAL() 
to carry on with the input in spite of this error?

Thanks in advance for any suggestions.

Ashton

-- 
Ashton Shortridge
Associate Professor			ashton at msu.edu
Dept of Geography			http://www.msu.edu/~ashton
235 Geography Building		ph (517) 432-3561
Michigan State University		fx (517) 432-1671



From milton.ruser at gmail.com  Thu Jun 12 05:06:33 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Thu, 12 Jun 2008 00:06:33 -0300
Subject: [R-sig-Geo] Adding new "Polygons" to SpatialPolygons object
Message-ID: <3aaf1a030806112006s575063d6uf025763ccfea2f31@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080612/6fd0637c/attachment.pl>

From Roger.Bivand at nhh.no  Thu Jun 12 08:31:46 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 12 Jun 2008 08:31:46 +0200 (CEST)
Subject: [R-sig-Geo] Adding new "Polygons" to SpatialPolygons object
In-Reply-To: <3aaf1a030806112006s575063d6uf025763ccfea2f31@mail.gmail.com>
References: <3aaf1a030806112006s575063d6uf025763ccfea2f31@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0806120830350.25820@reclus.nhh.no>

On Thu, 12 Jun 2008, milton ruser wrote:

> Dear all,
>
> I have a sequence of polygons as the example below. As the number of
> polygons will change every time, I would like to add a new object of class
> "Polygons" to a SpatialPolygons. Look that on the last time I try to add a
> new "Polygons" and get an error. How can I do dat?

Almost there - just catenate the "polygons" slot with the new "Polygons" 
object(s):

my.pols.SpatPol.complete <- SpatialPolygons(c(slot(my.pols.SpatPol.partial,
   "polygons"), list(my.pol3.Sr)))

Roger

>
> Kind regards,
>
> miltinho
>
> -----
>
> require(maptools)
> my.pol1<-cbind(x=c(3,7,7,3,3),y=c(2,2,6,6,2))
> my.pol2<-cbind(x=c(6,9,9,6,6),y=c(4,4,9,9,4))
> my.pol3<-cbind(x=c(7,10,10,7,7),y=c(2,2,8,8,2))
>
>
> my.pol1.Sr <- Polygons(list(Polygon(my.pol1)), ID="1")
> my.pol2.Sr <- Polygons(list(Polygon(my.pol2)), ID="2")
> my.pol3.Sr <- Polygons(list(Polygon(my.pol3)), ID="3")
>
> my.pols.SpatPol.partial <- SpatialPolygons(list(my.pol1.Sr,my.pol2.Sr))
>
> my.pols.SpatPol.complete <- SpatialPolygons(list(my.pols.SpatPol.partial,
> my.pol3.Sr))
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From laura.poggio at gmail.com  Thu Jun 12 08:56:17 2008
From: laura.poggio at gmail.com (Laura Poggio)
Date: Thu, 12 Jun 2008 08:56:17 +0200
Subject: [R-sig-Geo] clustering multi band images
Message-ID: <e027b8750806112356p1330c178y44afb75372326c0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080612/21b9d382/attachment.pl>

From Roger.Bivand at nhh.no  Thu Jun 12 09:05:49 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 12 Jun 2008 09:05:49 +0200 (CEST)
Subject: [R-sig-Geo] clustering multi band images
In-Reply-To: <e027b8750806112356p1330c178y44afb75372326c0@mail.gmail.com>
References: <e027b8750806112356p1330c178y44afb75372326c0@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0806120902271.25820@reclus.nhh.no>

On Thu, 12 Jun 2008, Laura Poggio wrote:

> Dear list,
> I am trying to do some clustering on images. And I have two main problems:
>
> 1) Clustering multiband images.
> I managed to be successful with a single band image, but when trying to
> apply to a 3 band I get the following warning message:
> In as.matrix.SpatialGridDataFrame(x) :
>  as.matrix.SpatialPixelsDataFrame uses first column;
> pass subset or [] for other columns
>
>
> 2) saving clustering results as grid or image.
> I get a vector of clusters, but without both coordinates. How it is possible
> to transform it in a grid?
>
> Here the code I use to read the image itself and to do the clustering:
>
> library(rgdal)
> fld <- system.file("E:/data/IMG/fr/", package="rgdal")
> img <- readGDAL("123_rawR.tif")
>
> kl <- kmeans(img, 5)

img is a SpatialGridDataFrame. kmeans() wants a matrix or data frame, so 
say:

kl <- kmeans(as(img, "data.frame"), 5)

Then

img$cluster <- kl$cluster

image(img, "cluster")

Does this help?

Roger

>
> I am quite new to image processing, especially within R, and any help is
> greatly appreciated.
>
> Thank you in advance
>
> LP
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From laura.poggio at gmail.com  Thu Jun 12 09:46:23 2008
From: laura.poggio at gmail.com (Laura Poggio)
Date: Thu, 12 Jun 2008 09:46:23 +0200
Subject: [R-sig-Geo] clustering multi band images
In-Reply-To: <Pine.LNX.4.64.0806120902271.25820@reclus.nhh.no>
References: <e027b8750806112356p1330c178y44afb75372326c0@mail.gmail.com>
	<Pine.LNX.4.64.0806120902271.25820@reclus.nhh.no>
Message-ID: <e027b8750806120046x60a35904vf5cfc5cbabe22896@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080612/777f8599/attachment.pl>

From edzer.pebesma at uni-muenster.de  Thu Jun 12 10:07:42 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 12 Jun 2008 10:07:42 +0200
Subject: [R-sig-Geo] clustering multi band images
In-Reply-To: <e027b8750806120046x60a35904vf5cfc5cbabe22896@mail.gmail.com>
References: <e027b8750806112356p1330c178y44afb75372326c0@mail.gmail.com>	<Pine.LNX.4.64.0806120902271.25820@reclus.nhh.no>
	<e027b8750806120046x60a35904vf5cfc5cbabe22896@mail.gmail.com>
Message-ID: <4850D94E.9010000@uni-muenster.de>

Laura Poggio wrote:
> However the results are quite different from what expected.
> Then I am wondering if is it that the correct way to handle clustering of
> remote sensing images.
>
> Thanks
>
> LP
>   
Laura, it's hard for us to look over your shoulder, and say something 
useful, we also don't know your expectations.

Please remember that clustering is done only on the pixel values, and 
ignores the spatial ordering of those pixels. If there's a bit of noise 
in the image, you might find quite a bit of noise in the resulting clusters.
--
Edzer



From Agustin.Lobo at ija.csic.es  Thu Jun 12 10:16:58 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Thu, 12 Jun 2008 10:16:58 +0200
Subject: [R-sig-Geo] clustering multi band images
In-Reply-To: <e027b8750806112356p1330c178y44afb75372326c0@mail.gmail.com>
References: <e027b8750806112356p1330c178y44afb75372326c0@mail.gmail.com>
Message-ID: <4850DB7A.4010808@ija.csic.es>

If your images are large (and images typically are large because pixel size
has to be small compared to the extent of the image for the image to
be of acceptable quality for our vision system), I do not advice you
to get them into R for processing as R has severe memory limits
and many classification techniques are not precisely memory-efficient
(but see clara() in package cluster, actually read 
http://cran.r-project.org/web/views/Cluster.html).

I think that you should sample your image in a RS/GIS environment making 
sure you cover all
the radiometric space and import only a table pixels x bands into R, the 
actual nb. of pixels depending on your HW/SW configuration (but 10000 
would be a good start). Then use the numerous R classification tools to 
define the centroids and once you have them use again your RS/GIS 
program to actually assign each pixel in the image to a centroid 
according to a given rule (i.e. maximum likelihood). There might be
ways of writing an efficient assignation step within R itself also, I 
think that mclust package does it.

Another way of reducing the number of individuals to classify is 
performing a segmentation of the image first and then classify segments
instead of pixels (i.e.
# Lobo, A. 1997.  Image segmentation and discriminant analysis for the 
identification of land cover units in Ecology. IEEE Transactions on 
Geoscience and Remote Sensing, 35(5): 1- 11.
http://wija.ija.csic.es/gt/obster/ABSTRACTS/alobo_ieee97.pdf
perhaps other articles in 
http://wija.ija.csic.es/gt/obster/alobo_publis.html
might be of help)

In any case, note that img in your code should be converted into
a multivariate table pixels x bands for most classification
functions in R to work. Note that this fact makes obvious
that classification approaches to image processing do not make
use of the spatial information of the image, which is actually
a fundamental part of the information of any image.

Agus

Laura Poggio escribi?:
> Dear list,
> I am trying to do some clustering on images. And I have two main problems:
> 
> 1) Clustering multiband images.
> I managed to be successful with a single band image, but when trying to
> apply to a 3 band I get the following warning message:
> In as.matrix.SpatialGridDataFrame(x) :
>   as.matrix.SpatialPixelsDataFrame uses first column;
>  pass subset or [] for other columns
> 
> 
> 2) saving clustering results as grid or image.
> I get a vector of clusters, but without both coordinates. How it is possible
> to transform it in a grid?
> 
> Here the code I use to read the image itself and to do the clustering:
> 
> library(rgdal)
> fld <- system.file("E:/data/IMG/fr/", package="rgdal")
> img <- readGDAL("123_rawR.tif")
> 
> kl <- kmeans(img, 5)
> 
> I am quite new to image processing, especially within R, and any help is
> greatly appreciated.
> 
> Thank you in advance
> 
> LP
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From laura.poggio at gmail.com  Thu Jun 12 10:50:29 2008
From: laura.poggio at gmail.com (Laura Poggio)
Date: Thu, 12 Jun 2008 10:50:29 +0200
Subject: [R-sig-Geo] clustering multi band images
In-Reply-To: <4850DB7A.4010808@ija.csic.es>
References: <e027b8750806112356p1330c178y44afb75372326c0@mail.gmail.com>
	<4850DB7A.4010808@ija.csic.es>
Message-ID: <e027b8750806120150i519826e7y6b3bcf62a50254a1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080612/76cf56f2/attachment.pl>

From Agustin.Lobo at ija.csic.es  Thu Jun 12 10:55:40 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Thu, 12 Jun 2008 10:55:40 +0200
Subject: [R-sig-Geo] clustering multi band images
In-Reply-To: <e027b8750806120150i519826e7y6b3bcf62a50254a1@mail.gmail.com>
References: <e027b8750806112356p1330c178y44afb75372326c0@mail.gmail.com>	
	<4850DB7A.4010808@ija.csic.es>
	<e027b8750806120150i519826e7y6b3bcf62a50254a1@mail.gmail.com>
Message-ID: <4850E48C.9040501@ija.csic.es>

Laura,

Laura Poggio escribi?:
> Thank you very much for your detailed answer that made me understand a 
> lot, and also it pointed out what I was thinking: R does not use the 
> spatial information for classification.

Hep! this is not a problem of R, don't blame it for that. R is wonderful
for multi-variate classification. This is a problem of the whole 
approach of applying multi-variate classification to multi-spectral 
imagery. And this does not mean that the approach is wrong or useless,
it's just a warning, a fact that the analyst must keep in mind.

Agus


> The image (for the moment) is rather small, as it is a sample of 512x512 
> pixels. I have to compare the effect of a segmentation method over raw 
> data for various unsupervised techniques.
> My idea was to do the classification in R, because it handles many more 
> methods then GIS/RS software I have available.
> 
> I will investigate some of the points raised and in case I will come 
> back with more clear ideas and questions.
> 
> Thank you very much to everybody for the support.
> 
> Laura
> 
> 
> 
> 2008/6/12 Agustin Lobo <Agustin.Lobo at ija.csic.es 
> <mailto:Agustin.Lobo at ija.csic.es>>:
> 
>     If your images are large (and images typically are large because
>     pixel size
>     has to be small compared to the extent of the image for the image to
>     be of acceptable quality for our vision system), I do not advice you
>     to get them into R for processing as R has severe memory limits
>     and many classification techniques are not precisely memory-efficient
>     (but see clara() in package cluster, actually read
>     http://cran.r-project.org/web/views/Cluster.html).
> 
>     I think that you should sample your image in a RS/GIS environment
>     making sure you cover all
>     the radiometric space and import only a table pixels x bands into R,
>     the actual nb. of pixels depending on your HW/SW configuration (but
>     10000 would be a good start). Then use the numerous R classification
>     tools to define the centroids and once you have them use again your
>     RS/GIS program to actually assign each pixel in the image to a
>     centroid according to a given rule (i.e. maximum likelihood). There
>     might be
>     ways of writing an efficient assignation step within R itself also,
>     I think that mclust package does it.
> 
>     Another way of reducing the number of individuals to classify is
>     performing a segmentation of the image first and then classify segments
>     instead of pixels (i.e.
>     # Lobo, A. 1997.  Image segmentation and discriminant analysis for
>     the identification of land cover units in Ecology. IEEE Transactions
>     on Geoscience and Remote Sensing, 35(5): 1- 11.
>     http://wija.ija.csic.es/gt/obster/ABSTRACTS/alobo_ieee97.pdf
>     perhaps other articles in
>     http://wija.ija.csic.es/gt/obster/alobo_publis.html
>     might be of help)
> 
>     In any case, note that img in your code should be converted into
>     a multivariate table pixels x bands for most classification
>     functions in R to work. Note that this fact makes obvious
>     that classification approaches to image processing do not make
>     use of the spatial information of the image, which is actually
>     a fundamental part of the information of any image.
> 
>     Agus
> 
>     Laura Poggio escribi?:
> 
>         Dear list,
>         I am trying to do some clustering on images. And I have two main
>         problems:
> 
>         1) Clustering multiband images.
>         I managed to be successful with a single band image, but when
>         trying to
>         apply to a 3 band I get the following warning message:
>         In as.matrix.SpatialGridDataFrame(x) :
>          as.matrix.SpatialPixelsDataFrame uses first column;
>          pass subset or [] for other columns
> 
> 
>         2) saving clustering results as grid or image.
>         I get a vector of clusters, but without both coordinates. How it
>         is possible
>         to transform it in a grid?
> 
>         Here the code I use to read the image itself and to do the
>         clustering:
> 
>         library(rgdal)
>         fld <- system.file("E:/data/IMG/fr/", package="rgdal")
>         img <- readGDAL("123_rawR.tif")
> 
>         kl <- kmeans(img, 5)
> 
>         I am quite new to image processing, especially within R, and any
>         help is
>         greatly appreciated.
> 
>         Thank you in advance
> 
>         LP
> 
>                [[alternative HTML version deleted]]
> 
>         _______________________________________________
>         R-sig-Geo mailing list
>         R-sig-Geo at stat.math.ethz.ch <mailto:R-sig-Geo at stat.math.ethz.ch>
>         https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 
>     -- 
>     Dr. Agustin Lobo
>     Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
>     LLuis Sole Sabaris s/n
>     08028 Barcelona
>     Spain
>     Tel. 34 934095410
>     Fax. 34 934110012
>     email: Agustin.Lobo at ija.csic.es <mailto:Agustin.Lobo at ija.csic.es>
>     http://www.ija.csic.es/gt/obster
> 
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Agustin.Lobo at ija.csic.es  Thu Jun 12 11:12:13 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Thu, 12 Jun 2008 11:12:13 +0200
Subject: [R-sig-Geo] clustering multi band images
In-Reply-To: <e027b8750806120150i519826e7y6b3bcf62a50254a1@mail.gmail.com>
References: <e027b8750806112356p1330c178y44afb75372326c0@mail.gmail.com>	
	<4850DB7A.4010808@ija.csic.es>
	<e027b8750806120150i519826e7y6b3bcf62a50254a1@mail.gmail.com>
Message-ID: <4850E86D.1070804@ija.csic.es>

(sorry I pressed the send button instead of the save as draft button,
I go on with my comments)

Laura,

Laura Poggio escribi?:
> Thank you very much for your detailed answer that made me understand a 
> lot, and also it pointed out what I was thinking: R does not use the 
> spatial information for classification.

Hep! this is not a problem of R, don't blame it for that. R is wonderful
for multi-variate classification. This is a problem of the whole
approach of applying multi-variate classification to multi-spectral
imagery. And this does not mean that the approach is wrong or useless,
it's just a warning, a fact that the analyst must keep in mind.

> The image (for the moment) is rather small, as it is a sample of 512x512 
> pixels.

As you have 3 bands the total dimensionality is 512x512x3, which might 
be ok, it depends on the ram you have. 512x512 is rather small for
imagery these days... (unless you had hyperspectral images!).

You should take advantage of the relatively small size of your image to
compare to results using an increasing nb. of sampled pixels. If you
use model-based clustering, I would say that results using 10000 pixels
(covering the whole radiometric space, this is an important caution)
would yield the same results than using all the 512x512 pixels.

 > I have to compare the effect of a segmentation method over raw
 > data for various unsupervised techniques.

Segmentation is not only meant for reducing the memory problems, this
is just a fortunate side effect. Segmentation has many other advantages 
(and some disadvantages).

> My idea was to do the classification in R, because it handles many more 
> methods then GIS/RS software I have available.

And I agree with you. By using R you get free of all the many 
constraints of classification methods that are implemented in RS 
packages, and you can
experiment with many more different methods. And you do know what yo do.
I was mentioning the use of RS/GIS for sampling and assigning if you had 
large images (yours are exceptionally small nowadays).

Good luck!

Agus


> I will investigate some of the points raised and in case I will come 
> back with more clear ideas and questions.
> 
> Thank you very much to everybody for the support.
> 
> Laura
> 
> 
> 
> 2008/6/12 Agustin Lobo <Agustin.Lobo at ija.csic.es 
> <mailto:Agustin.Lobo at ija.csic.es>>:
> 
>     If your images are large (and images typically are large because
>     pixel size
>     has to be small compared to the extent of the image for the image to
>     be of acceptable quality for our vision system), I do not advice you
>     to get them into R for processing as R has severe memory limits
>     and many classification techniques are not precisely memory-efficient
>     (but see clara() in package cluster, actually read
>     http://cran.r-project.org/web/views/Cluster.html).
> 
>     I think that you should sample your image in a RS/GIS environment
>     making sure you cover all
>     the radiometric space and import only a table pixels x bands into R,
>     the actual nb. of pixels depending on your HW/SW configuration (but
>     10000 would be a good start). Then use the numerous R classification
>     tools to define the centroids and once you have them use again your
>     RS/GIS program to actually assign each pixel in the image to a
>     centroid according to a given rule (i.e. maximum likelihood). There
>     might be
>     ways of writing an efficient assignation step within R itself also,
>     I think that mclust package does it.
> 
>     Another way of reducing the number of individuals to classify is
>     performing a segmentation of the image first and then classify segments
>     instead of pixels (i.e.
>     # Lobo, A. 1997.  Image segmentation and discriminant analysis for
>     the identification of land cover units in Ecology. IEEE Transactions
>     on Geoscience and Remote Sensing, 35(5): 1- 11.
>     http://wija.ija.csic.es/gt/obster/ABSTRACTS/alobo_ieee97.pdf
>     perhaps other articles in
>     http://wija.ija.csic.es/gt/obster/alobo_publis.html
>     might be of help)
> 
>     In any case, note that img in your code should be converted into
>     a multivariate table pixels x bands for most classification
>     functions in R to work. Note that this fact makes obvious
>     that classification approaches to image processing do not make
>     use of the spatial information of the image, which is actually
>     a fundamental part of the information of any image.
> 
>     Agus
> 
>     Laura Poggio escribi?:
> 
>         Dear list,
>         I am trying to do some clustering on images. And I have two main
>         problems:
> 
>         1) Clustering multiband images.
>         I managed to be successful with a single band image, but when
>         trying to
>         apply to a 3 band I get the following warning message:
>         In as.matrix.SpatialGridDataFrame(x) :
>          as.matrix.SpatialPixelsDataFrame uses first column;
>          pass subset or [] for other columns
> 
> 
>         2) saving clustering results as grid or image.
>         I get a vector of clusters, but without both coordinates. How it
>         is possible
>         to transform it in a grid?
> 
>         Here the code I use to read the image itself and to do the
>         clustering:
> 
>         library(rgdal)
>         fld <- system.file("E:/data/IMG/fr/", package="rgdal")
>         img <- readGDAL("123_rawR.tif")
> 
>         kl <- kmeans(img, 5)
> 
>         I am quite new to image processing, especially within R, and any
>         help is
>         greatly appreciated.
> 
>         Thank you in advance
> 
>         LP
> 
>                [[alternative HTML version deleted]]
> 
>         _______________________________________________
>         R-sig-Geo mailing list
>         R-sig-Geo at stat.math.ethz.ch <mailto:R-sig-Geo at stat.math.ethz.ch>
>         https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 
>     -- 
>     Dr. Agustin Lobo
>     Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
>     LLuis Sole Sabaris s/n
>     08028 Barcelona
>     Spain
>     Tel. 34 934095410
>     Fax. 34 934110012
>     email: Agustin.Lobo at ija.csic.es <mailto:Agustin.Lobo at ija.csic.es>
>     http://www.ija.csic.es/gt/obster
> 
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From edzer.pebesma at uni-muenster.de  Thu Jun 12 12:55:07 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 12 Jun 2008 12:55:07 +0200
Subject: [R-sig-Geo] clustering multi band images
In-Reply-To: <Pine.LNX.4.64.0806120902271.25820@reclus.nhh.no>
References: <e027b8750806112356p1330c178y44afb75372326c0@mail.gmail.com>
	<Pine.LNX.4.64.0806120902271.25820@reclus.nhh.no>
Message-ID: <4851008B.8020803@uni-muenster.de>

Roger Bivand wrote:
> On Thu, 12 Jun 2008, Laura Poggio wrote:
>
>> Dear list,
>> I am trying to do some clustering on images. And I have two main 
>> problems:
>>
>> 1) Clustering multiband images.
>> I managed to be successful with a single band image, but when trying to
>> apply to a 3 band I get the following warning message:
>> In as.matrix.SpatialGridDataFrame(x) :
>>  as.matrix.SpatialPixelsDataFrame uses first column;
>> pass subset or [] for other columns
>>
>>
>> 2) saving clustering results as grid or image.
>> I get a vector of clusters, but without both coordinates. How it is 
>> possible
>> to transform it in a grid?
>>
>> Here the code I use to read the image itself and to do the clustering:
>>
>> library(rgdal)
>> fld <- system.file("E:/data/IMG/fr/", package="rgdal")
>> img <- readGDAL("123_rawR.tif")
>>
>> kl <- kmeans(img, 5)
>
> img is a SpatialGridDataFrame. kmeans() wants a matrix or data frame, 
> so say:
>
> kl <- kmeans(as(img, "data.frame"), 5)
this also passes the coordinates to the clustering routine; I'm not sure 
but I think that was not the initial idea.
In case img is a 3-band image, use

kl <- kmeans(as(img, "data.frame")[1:3], 5)
--
Edzer



From laura.poggio at gmail.com  Thu Jun 12 13:19:52 2008
From: laura.poggio at gmail.com (Laura Poggio)
Date: Thu, 12 Jun 2008 13:19:52 +0200
Subject: [R-sig-Geo] clustering multi band images
In-Reply-To: <4851008B.8020803@uni-muenster.de>
References: <e027b8750806112356p1330c178y44afb75372326c0@mail.gmail.com>
	<Pine.LNX.4.64.0806120902271.25820@reclus.nhh.no>
	<4851008B.8020803@uni-muenster.de>
Message-ID: <e027b8750806120419q1bb9d932s9800043813be08a9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080612/39d42f0e/attachment.pl>

From Agustin.Lobo at ija.csic.es  Thu Jun 12 13:49:04 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Thu, 12 Jun 2008 13:49:04 +0200
Subject: [R-sig-Geo] clustering multi band images
In-Reply-To: <e027b8750806120235w736bd8ddl7e414ebc71b04e6b@mail.gmail.com>
References: <e027b8750806112356p1330c178y44afb75372326c0@mail.gmail.com>	
	<4850DB7A.4010808@ija.csic.es>	
	<e027b8750806120150i519826e7y6b3bcf62a50254a1@mail.gmail.com>	
	<4850E86D.1070804@ija.csic.es>
	<e027b8750806120235w736bd8ddl7e414ebc71b04e6b@mail.gmail.com>
Message-ID: <48510D30.50803@ija.csic.es>



Laura Poggio escribi?:
.../...
> 
> 2008/6/12 Agustin Lobo <Agustin.Lobo at ija.csic.es 
> <mailto:Agustin.Lobo at ija.csic.es>>:
>
> May I just ask you if you have easily available an example of code to 
> transform the image in a multivariate table pixels x bands? This would 
> be helpful to avoid many trial and errors (especially the second one). 
> Sorry for that but at my institution I am the only one dealing with R...
> 
> Thank you again
> 
> Laura

You already did it in:
kl <- kmeans(as(img, "data.frame"), 5)

Perhaps you want to do it in 2 steps:

imgtabla <- as(img, "data.frame")
kl <- kmeans(imgtabla, 5)

You can look at the first rows of imgtabla with

imgtabla[1:5,]
or
head(imgtabla)
and then
dim(imgtabla)
summary(imgtabla)

If img were your complete Landsat image, the same steps
would yield an imgtabla with 262144 x 6 (as I assume you are not
using the thermal band). In that case, you probably want
to run PCA and use only the first 3 PCs for classification, as they 
typically
account for >95% of the total variance and you cam always apply
the inverse transform to the centroids to recover the original
metric.

As a matter of fact, I think it's more practical
here to convert imgtabla from data.frame to matrix, as all values are
numerical here.

Agus

> 
> 
> 
>     Agus
> 
> 
>         I will investigate some of the points raised and in case I will
>         come back with more clear ideas and questions.
> 
>         Thank you very much to everybody for the support.
> 
>         Laura
> 
> 
> 
>         2008/6/12 Agustin Lobo <Agustin.Lobo at ija.csic.es
>         <mailto:Agustin.Lobo at ija.csic.es>
>         <mailto:Agustin.Lobo at ija.csic.es
>         <mailto:Agustin.Lobo at ija.csic.es>>>:
> 
> 
>            If your images are large (and images typically are large because
>            pixel size
>            has to be small compared to the extent of the image for the
>         image to
>            be of acceptable quality for our vision system), I do not
>         advice you
>            to get them into R for processing as R has severe memory limits
>            and many classification techniques are not precisely
>         memory-efficient
>            (but see clara() in package cluster, actually read
>            http://cran.r-project.org/web/views/Cluster.html).
> 
>            I think that you should sample your image in a RS/GIS environment
>            making sure you cover all
>            the radiometric space and import only a table pixels x bands
>         into R,
>            the actual nb. of pixels depending on your HW/SW
>         configuration (but
>            10000 would be a good start). Then use the numerous R
>         classification
>            tools to define the centroids and once you have them use
>         again your
>            RS/GIS program to actually assign each pixel in the image to a
>            centroid according to a given rule (i.e. maximum likelihood).
>         There
>            might be
>            ways of writing an efficient assignation step within R itself
>         also,
>            I think that mclust package does it.
> 
>            Another way of reducing the number of individuals to classify is
>            performing a segmentation of the image first and then
>         classify segments
>            instead of pixels (i.e.
>            # Lobo, A. 1997.  Image segmentation and discriminant
>         analysis for
>            the identification of land cover units in Ecology. IEEE
>         Transactions
>            on Geoscience and Remote Sensing, 35(5): 1- 11.
>            http://wija.ija.csic.es/gt/obster/ABSTRACTS/alobo_ieee97.pdf
>            perhaps other articles in
>            http://wija.ija.csic.es/gt/obster/alobo_publis.html
>            might be of help)
> 
>            In any case, note that img in your code should be converted into
>            a multivariate table pixels x bands for most classification
>            functions in R to work. Note that this fact makes obvious
>            that classification approaches to image processing do not make
>            use of the spatial information of the image, which is actually
>            a fundamental part of the information of any image.
> 
>            Agus
> 
>            Laura Poggio escribi?:
> 
>                Dear list,
>                I am trying to do some clustering on images. And I have
>         two main
>                problems:
> 
>                1) Clustering multiband images.
>                I managed to be successful with a single band image, but when
>                trying to
>                apply to a 3 band I get the following warning message:
>                In as.matrix.SpatialGridDataFrame(x) :
>                 as.matrix.SpatialPixelsDataFrame uses first column;
>                 pass subset or [] for other columns
> 
> 
>                2) saving clustering results as grid or image.
>                I get a vector of clusters, but without both coordinates.
>         How it
>                is possible
>                to transform it in a grid?
> 
>                Here the code I use to read the image itself and to do the
>                clustering:
> 
>                library(rgdal)
>                fld <- system.file("E:/data/IMG/fr/", package="rgdal")
>                img <- readGDAL("123_rawR.tif")
> 
>                kl <- kmeans(img, 5)
> 
>                I am quite new to image processing, especially within R,
>         and any
>                help is
>                greatly appreciated.
> 
>                Thank you in advance
> 
>                LP
> 
>                       [[alternative HTML version deleted]]
> 
>                _______________________________________________
>                R-sig-Geo mailing list
>                R-sig-Geo at stat.math.ethz.ch
>         <mailto:R-sig-Geo at stat.math.ethz.ch>
>         <mailto:R-sig-Geo at stat.math.ethz.ch
>         <mailto:R-sig-Geo at stat.math.ethz.ch>>
> 
>                https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 
>            --    Dr. Agustin Lobo
>            Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
>            LLuis Sole Sabaris s/n
>            08028 Barcelona
>            Spain
>            Tel. 34 934095410
>            Fax. 34 934110012
>            email: Agustin.Lobo at ija.csic.es
>         <mailto:Agustin.Lobo at ija.csic.es>
>         <mailto:Agustin.Lobo at ija.csic.es <mailto:Agustin.Lobo at ija.csic.es>>
> 
>            http://www.ija.csic.es/gt/obster
> 
> 
> 
>     -- 
>     Dr. Agustin Lobo
>     Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
>     LLuis Sole Sabaris s/n
>     08028 Barcelona
>     Spain
>     Tel. 34 934095410
>     Fax. 34 934110012
>     email: Agustin.Lobo at ija.csic.es <mailto:Agustin.Lobo at ija.csic.es>
>     http://www.ija.csic.es/gt/obster
> 
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From milton.ruser at gmail.com  Thu Jun 12 13:54:36 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Thu, 12 Jun 2008 08:54:36 -0300
Subject: [R-sig-Geo] Adding new "Polygons" to SpatialPolygons object
In-Reply-To: <Pine.LNX.4.64.0806120830350.25820@reclus.nhh.no>
References: <3aaf1a030806112006s575063d6uf025763ccfea2f31@mail.gmail.com>
	<Pine.LNX.4.64.0806120830350.25820@reclus.nhh.no>
Message-ID: <3aaf1a030806120454l26b89dc9y42c840308a54be65@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080612/96530b15/attachment.pl>

From laura.poggio at gmail.com  Thu Jun 12 13:57:50 2008
From: laura.poggio at gmail.com (Laura Poggio)
Date: Thu, 12 Jun 2008 13:57:50 +0200
Subject: [R-sig-Geo] clustering multi band images
In-Reply-To: <48510D30.50803@ija.csic.es>
References: <e027b8750806112356p1330c178y44afb75372326c0@mail.gmail.com>
	<4850DB7A.4010808@ija.csic.es>
	<e027b8750806120150i519826e7y6b3bcf62a50254a1@mail.gmail.com>
	<4850E86D.1070804@ija.csic.es>
	<e027b8750806120235w736bd8ddl7e414ebc71b04e6b@mail.gmail.com>
	<48510D30.50803@ija.csic.es>
Message-ID: <e027b8750806120457s47703e91o4a12eefab4814dfb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080612/7d12a33d/attachment.pl>

From dylan.beaudette at gmail.com  Thu Jun 12 16:56:22 2008
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Thu, 12 Jun 2008 07:56:22 -0700
Subject: [R-sig-Geo] clustering multi band images
In-Reply-To: <e027b8750806120457s47703e91o4a12eefab4814dfb@mail.gmail.com>
References: <e027b8750806112356p1330c178y44afb75372326c0@mail.gmail.com>
	<4850DB7A.4010808@ija.csic.es>
	<e027b8750806120150i519826e7y6b3bcf62a50254a1@mail.gmail.com>
	<4850E86D.1070804@ija.csic.es>
	<e027b8750806120235w736bd8ddl7e414ebc71b04e6b@mail.gmail.com>
	<48510D30.50803@ija.csic.es>
	<e027b8750806120457s47703e91o4a12eefab4814dfb@mail.gmail.com>
Message-ID: <3c5546140806120756q6781818dw190262b0cf3a7da3@mail.gmail.com>

If you are interested in a (supervised) imagery classification routine
that takes spatial arrangement into consideration, check out the
i.smap command in GRASS GIS.

Cheers,

Dylan

On Thu, Jun 12, 2008 at 4:57 AM, Laura Poggio <laura.poggio at gmail.com> wrote:
> thank you. It seems now solved!
>
> Laura
>
> 2008/6/12 Agustin Lobo <Agustin.Lobo at ija.csic.es>:
>
>>
>>
>> Laura Poggio escribi?:
>> .../...
>>
>>>
>>> 2008/6/12 Agustin Lobo <Agustin.Lobo at ija.csic.es <mailto:
>>> Agustin.Lobo at ija.csic.es>>:
>>>
>>> May I just ask you if you have easily available an example of code to
>>> transform the image in a multivariate table pixels x bands? This would be
>>> helpful to avoid many trial and errors (especially the second one). Sorry
>>> for that but at my institution I am the only one dealing with R...
>>>
>>> Thank you again
>>>
>>> Laura
>>>
>>
>> You already did it in:
>> kl <- kmeans(as(img, "data.frame"), 5)
>>
>> Perhaps you want to do it in 2 steps:
>>
>> imgtabla <- as(img, "data.frame")
>> kl <- kmeans(imgtabla, 5)
>>
>> You can look at the first rows of imgtabla with
>>
>> imgtabla[1:5,]
>> or
>> head(imgtabla)
>> and then
>> dim(imgtabla)
>> summary(imgtabla)
>>
>> If img were your complete Landsat image, the same steps
>> would yield an imgtabla with 262144 x 6 (as I assume you are not
>> using the thermal band). In that case, you probably want
>> to run PCA and use only the first 3 PCs for classification, as they
>> typically
>> account for >95% of the total variance and you cam always apply
>> the inverse transform to the centroids to recover the original
>> metric.
>>
>> As a matter of fact, I think it's more practical
>> here to convert imgtabla from data.frame to matrix, as all values are
>> numerical here.
>>
>> Agus
>>
>>
>>>
>>>
>>>    Agus
>>>
>>>
>>>        I will investigate some of the points raised and in case I will
>>>        come back with more clear ideas and questions.
>>>
>>>        Thank you very much to everybody for the support.
>>>
>>>        Laura
>>>
>>>
>>>
>>>        2008/6/12 Agustin Lobo <Agustin.Lobo at ija.csic.es
>>>        <mailto:Agustin.Lobo at ija.csic.es>
>>>        <mailto:Agustin.Lobo at ija.csic.es
>>>        <mailto:Agustin.Lobo at ija.csic.es>>>:
>>>
>>>
>>>           If your images are large (and images typically are large because
>>>           pixel size
>>>           has to be small compared to the extent of the image for the
>>>        image to
>>>           be of acceptable quality for our vision system), I do not
>>>        advice you
>>>           to get them into R for processing as R has severe memory limits
>>>           and many classification techniques are not precisely
>>>        memory-efficient
>>>           (but see clara() in package cluster, actually read
>>>           http://cran.r-project.org/web/views/Cluster.html).
>>>
>>>           I think that you should sample your image in a RS/GIS
>>> environment
>>>           making sure you cover all
>>>           the radiometric space and import only a table pixels x bands
>>>        into R,
>>>           the actual nb. of pixels depending on your HW/SW
>>>        configuration (but
>>>           10000 would be a good start). Then use the numerous R
>>>        classification
>>>           tools to define the centroids and once you have them use
>>>        again your
>>>           RS/GIS program to actually assign each pixel in the image to a
>>>           centroid according to a given rule (i.e. maximum likelihood).
>>>        There
>>>           might be
>>>           ways of writing an efficient assignation step within R itself
>>>        also,
>>>           I think that mclust package does it.
>>>
>>>           Another way of reducing the number of individuals to classify is
>>>           performing a segmentation of the image first and then
>>>        classify segments
>>>           instead of pixels (i.e.
>>>           # Lobo, A. 1997.  Image segmentation and discriminant
>>>        analysis for
>>>           the identification of land cover units in Ecology. IEEE
>>>        Transactions
>>>           on Geoscience and Remote Sensing, 35(5): 1- 11.
>>>           http://wija.ija.csic.es/gt/obster/ABSTRACTS/alobo_ieee97.pdf
>>>           perhaps other articles in
>>>           http://wija.ija.csic.es/gt/obster/alobo_publis.html
>>>           might be of help)
>>>
>>>           In any case, note that img in your code should be converted into
>>>           a multivariate table pixels x bands for most classification
>>>           functions in R to work. Note that this fact makes obvious
>>>           that classification approaches to image processing do not make
>>>           use of the spatial information of the image, which is actually
>>>           a fundamental part of the information of any image.
>>>
>>>           Agus
>>>
>>>           Laura Poggio escribi?:
>>>
>>>               Dear list,
>>>               I am trying to do some clustering on images. And I have
>>>        two main
>>>               problems:
>>>
>>>               1) Clustering multiband images.
>>>               I managed to be successful with a single band image, but
>>> when
>>>               trying to
>>>               apply to a 3 band I get the following warning message:
>>>               In as.matrix.SpatialGridDataFrame(x) :
>>>                as.matrix.SpatialPixelsDataFrame uses first column;
>>>                pass subset or [] for other columns
>>>
>>>
>>>               2) saving clustering results as grid or image.
>>>               I get a vector of clusters, but without both coordinates.
>>>        How it
>>>               is possible
>>>               to transform it in a grid?
>>>
>>>               Here the code I use to read the image itself and to do the
>>>               clustering:
>>>
>>>               library(rgdal)
>>>               fld <- system.file("E:/data/IMG/fr/", package="rgdal")
>>>               img <- readGDAL("123_rawR.tif")
>>>
>>>               kl <- kmeans(img, 5)
>>>
>>>               I am quite new to image processing, especially within R,
>>>        and any
>>>               help is
>>>               greatly appreciated.
>>>
>>>               Thank you in advance
>>>
>>>               LP
>>>
>>>                      [[alternative HTML version deleted]]
>>>
>>>               _______________________________________________
>>>               R-sig-Geo mailing list
>>>               R-sig-Geo at stat.math.ethz.ch
>>>        <mailto:R-sig-Geo at stat.math.ethz.ch>
>>>        <mailto:R-sig-Geo at stat.math.ethz.ch
>>>        <mailto:R-sig-Geo at stat.math.ethz.ch>>
>>>
>>>               https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>>           --    Dr. Agustin Lobo
>>>           Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
>>>           LLuis Sole Sabaris s/n
>>>           08028 Barcelona
>>>           Spain
>>>           Tel. 34 934095410
>>>           Fax. 34 934110012
>>>           email: Agustin.Lobo at ija.csic.es
>>>        <mailto:Agustin.Lobo at ija.csic.es>
>>>        <mailto:Agustin.Lobo at ija.csic.es <mailto:Agustin.Lobo at ija.csic.es
>>> >>
>>>
>>>           http://www.ija.csic.es/gt/obster
>>>
>>>
>>>
>>>    --    Dr. Agustin Lobo
>>>    Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
>>>    LLuis Sole Sabaris s/n
>>>    08028 Barcelona
>>>    Spain
>>>    Tel. 34 934095410
>>>    Fax. 34 934110012
>>>    email: Agustin.Lobo at ija.csic.es <mailto:Agustin.Lobo at ija.csic.es>
>>>    http://www.ija.csic.es/gt/obster
>>>
>>>
>>>
>> --
>> Dr. Agustin Lobo
>> Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
>> LLuis Sole Sabaris s/n
>> 08028 Barcelona
>> Spain
>> Tel. 34 934095410
>> Fax. 34 934110012
>> email: Agustin.Lobo at ija.csic.es
>> http://www.ija.csic.es/gt/obster
>>
>
>        [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>



From edzer.pebesma at uni-muenster.de  Thu Jun 12 21:06:06 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 12 Jun 2008 21:06:06 +0200
Subject: [R-sig-Geo] [Gstat-info] Normal Score transform
In-Reply-To: <200806121344.07984.ashton@msu.edu>
References: <200806121344.07984.ashton@msu.edu>
Message-ID: <4851739E.1080500@uni-muenster.de>

Ashton, I found it worth dropping at r-sig-geo. And did so.

Thanks, and best wishes,
--
Edzer

Ashton Shortridge wrote:
> Hi all,
>
> Not a question, but hopefully a contribution. I have been messing around with 
> normal scores, which are trivial in R, and back transforms, which are 
> anything but trivial. They are potentially useful when conducting Gaussian 
> simulation using predict() or krige() in gstat.
>
> Attached is a link to some experimental R functions I wrote for performing 
> normal score transforms and back transforms on data, along with example 
> routines demonstrating their use. They are not intended for serious 
> application - they are meant for those of us who might be curious about 
> exploring transform issues and geostatistics with normal scores. The code is 
> fairly heavily documented and somewhat sketchily referenced, and most of it 
> frankly would be trivial for any moderately experienced R programmer to 
> write - the core functions, even with comments, are only about 60 lines long. 
> I hope that nevertheless it will be a useful starting point for the 
> interested.
>
> The URL:
> http://www.msu.edu/~ashton/temp/nscore.R
>
> Documentation, background text, references, and instructions for running the 
> examples are located at the beginning of the script. The rest of the file 
> consists of function definitions. Running the script by itself executes no 
> code, but simply establishes the function definitions.
>
> I have thought about dropping it on ai-geostats but thought this might be a 
> better forum. Let me know what you think.
>
> Yours,
>
> Ashton
>
>



From Roger.Bivand at nhh.no  Fri Jun 13 11:21:26 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 13 Jun 2008 11:21:26 +0200 (CEST)
Subject: [R-sig-Geo] clustering multi band images
In-Reply-To: <4851008B.8020803@uni-muenster.de>
References: <e027b8750806112356p1330c178y44afb75372326c0@mail.gmail.com>
	<Pine.LNX.4.64.0806120902271.25820@reclus.nhh.no>
	<4851008B.8020803@uni-muenster.de>
Message-ID: <Pine.LNX.4.64.0806131120530.29281@reclus.nhh.no>

On Thu, 12 Jun 2008, Edzer Pebesma wrote:

> Roger Bivand wrote:
>>  On Thu, 12 Jun 2008, Laura Poggio wrote:
>> 
>> >  Dear list,
>> >  I am trying to do some clustering on images. And I have two main 
>> >  problems:
>> > 
>> >  1) Clustering multiband images.
>> >  I managed to be successful with a single band image, but when trying to
>> >  apply to a 3 band I get the following warning message:
>> >  In as.matrix.SpatialGridDataFrame(x) :
>> >  as.matrix.SpatialPixelsDataFrame uses first column;
>> >  pass subset or [] for other columns
>> > 
>> > 
>> >  2) saving clustering results as grid or image.
>> >  I get a vector of clusters, but without both coordinates. How it is 
>> >  possible
>> >  to transform it in a grid?
>> > 
>> >  Here the code I use to read the image itself and to do the clustering:
>> > 
>> >  library(rgdal)
>> >  fld <- system.file("E:/data/IMG/fr/", package="rgdal")
>> >  img <- readGDAL("123_rawR.tif")
>> > 
>> >  kl <- kmeans(img, 5)
>>
>>  img is a SpatialGridDataFrame. kmeans() wants a matrix or data frame, so
>>  say:
>>
>>  kl <- kmeans(as(img, "data.frame"), 5)
> this also passes the coordinates to the clustering routine; I'm not sure but 
> I think that was not the initial idea.
> In case img is a 3-band image, use
>
> kl <- kmeans(as(img, "data.frame")[1:3], 5)

Right, I replied too fast without chacking, sorry!

Roger

> --
> Edzer
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ddepew at sciborg.uwaterloo.ca  Fri Jun 13 15:42:20 2008
From: ddepew at sciborg.uwaterloo.ca (Dave Depew)
Date: Fri, 13 Jun 2008 09:42:20 -0400
Subject: [R-sig-Geo] anisotropy gstat
In-Reply-To: <48501317.20008@uni-muenster.de>
References: <48500CD7.8060700@scimail.uwaterloo.ca>
	<48501317.20008@uni-muenster.de>
Message-ID: <4852793C.9080603@scimail.uwaterloo.ca>

Thanks Edzer,

SO to confirm, the 45 deg direction is the maximum range of correlation, 
or simply just the maximum range to determine the angle of anisotropy?


Edzer Pebesma wrote:
> Dave Depew wrote:
>> Hi All,
>> I suppose this is a rather simple question...however, I'm managing to 
>> get more confused the more I read.
>> I'm doing some OK and UK using the R-gstat package...I have some data 
>> that is moderately anisotropic. Reading the gstat literature, it 
>> would seem that to specify the appropriate parameters for anisotropic 
>> variograms I need the set the angle equal to the direction of 
>> maximal  data continuity? or maximal range?. The ratio of the minimum 
>> to maximum range appears to be straightforward enough, but the first 
>> part is confusing me.
>> As an example;
>> data(meuse)
>> e<-variogram(dist~1, loc=~x+y,data=meuse, alpha=c(0,45,90,135))
>> plot(e)
> Dave, try
>
> require(gstat)
> data(meuse)
> coordinates(meuse) = ~x+y
> e<-variogram(dist~1, meuse, alpha=c(0,45,90,135))
> plot(e, vgm(.08, "Sph", 5000, anis=c(45, .2)))
>
> I got there with a bit of trial and error. Clearly, for the 45 degrees 
> most happens beyond 1500 m.
>
> Of course this is just for the idea; a variogram model that has some 
> parabolic behaviour at the origin would be prefered.
>>
>> Looks to me anyways, that the direction of maximum range is 45 deg, 
>> and the minRange/maxRange is ~ 1000/1500 = 0.67.
> the max correlation direction is 45, the range is, in my model, 5000, 
> the anisotropy ratio 0.2.
>>
>> Could more experienced gstat users tell me if I'm out to lunch on 
>> this one??
> You weren't far off.
> -- 
> Edzer
>



From mao.loecher at gmail.com  Fri Jun 13 16:46:11 2008
From: mao.loecher at gmail.com (Markus Loecher)
Date: Fri, 13 Jun 2008 10:46:11 -0400
Subject: [R-sig-Geo] map tiles
Message-ID: <3827b1320806130746s6b29b7bbg450526cccb396d1d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080613/3104ac44/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Fri Jun 13 17:08:29 2008
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 13 Jun 2008 16:08:29 +0100
Subject: [R-sig-Geo] map tiles
In-Reply-To: <3827b1320806130746s6b29b7bbg450526cccb396d1d@mail.gmail.com>
References: <3827b1320806130746s6b29b7bbg450526cccb396d1d@mail.gmail.com>
Message-ID: <48528D6D.9030508@lancaster.ac.uk>

Markus Loecher wrote:
> Dear Rgeo experts,
> what would be the most efficient way of displaying Google map tiles in R and
> overlaying lat/lon points ? It seems that already the first elementary step
> of importing and displaying png pictures is difficult to do in R ?
> 
> Any help would be greatly appreciated,
> 

  It wouldn't be too hard to write some code that grabbed the google map 
tiles for a plot area, converted to some raster format and displayed 
them in an R plot window. However, have you read the google map api:

"""The API may be used only for services that are generally accessible 
to consumers without charge. Accordingly, You may not use the API for 
any service that requires a subscription or other restricted access, or 
for which a fee is charged."""

  I reckon having an R plot on your desktop is pretty much restricted 
access. Google's map data is intended for public web sites. It might 
also fall foul of:

"""You may not copy, reverse engineer, decompile, disassemble, 
translate, modify or make derivative works of the imagery, in whole or 
in part."""

  Now, OpenStreetMap maps are a different story...

www.openstreetmap.org

Barry



From dsb at vt.edu  Sat Jun 14 20:02:30 2008
From: dsb at vt.edu (David S. Bieri)
Date: Sat, 14 Jun 2008 14:02:30 -0400
Subject: [R-sig-Geo] map tiles
In-Reply-To: <48528D6D.9030508@lancaster.ac.uk>
References: <3827b1320806130746s6b29b7bbg450526cccb396d1d@mail.gmail.com>
	<48528D6D.9030508@lancaster.ac.uk>
Message-ID: <000e01c8ce48$d8614680$2b01a8c0@DSB>


This might be of interest too:

GOOGLE CHARTS FROM R: MAPS
http://www.iq.harvard.edu/blog/sss/archives/2008/04/google_charts_f_1.shtml


rgds,
David


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Barry Rowlingson
Sent: Friday, June 13, 2008 11:08 AM
To: Markus Loecher
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] map tiles

Markus Loecher wrote:
> Dear Rgeo experts,
> what would be the most efficient way of displaying Google map tiles in R
and
> overlaying lat/lon points ? It seems that already the first elementary
step
> of importing and displaying png pictures is difficult to do in R ?
> 
> Any help would be greatly appreciated,
> 

  It wouldn't be too hard to write some code that grabbed the google map 
tiles for a plot area, converted to some raster format and displayed 
them in an R plot window. However, have you read the google map api:

"""The API may be used only for services that are generally accessible 
to consumers without charge. Accordingly, You may not use the API for 
any service that requires a subscription or other restricted access, or 
for which a fee is charged."""

  I reckon having an R plot on your desktop is pretty much restricted 
access. Google's map data is intended for public web sites. It might 
also fall foul of:

"""You may not copy, reverse engineer, decompile, disassemble, 
translate, modify or make derivative works of the imagery, in whole or 
in part."""

  Now, OpenStreetMap maps are a different story...

www.openstreetmap.org

Barry

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From b.rowlingson at lancaster.ac.uk  Mon Jun 16 11:27:53 2008
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 16 Jun 2008 10:27:53 +0100
Subject: [R-sig-Geo] Basic raster operations
Message-ID: <48563219.3040807@lancaster.ac.uk>

I'm getting frustrated at what I thought would be simple raster 
manipulations...

  * How can I shift a SpatialGridDataFrame? I can't just change the 
coordinates:

 > coordinates(compare)=coordinates(compare)+10
Error in `coordinates<-`(`*tmp*`, value = c(10.5, 11.5, 12.5, 13.5, 
14.5,  :
   setting coordinates cannot be done on Spatial objects, where they 
have already been set

  Do I have to construct a new GridTopology object, then feed that to 
SpatialGridDataFrame along with the @data slot from the original? It 
seems to work, but I was hoping for something simpler, and I always get 
the jitters when working with slots since I tend to think of them as 
private object data that I shouldn't mess with. Isn't there a 'getData' 
method?

  * How can I construct larger SpatialGridDataFrames by tiling smaller ones?

  If they operated like matrices or data frames I could just cbind or 
rbind them together. I think I'm going to have to do a similar procedure 
as above - work out the new GridTopology and pass a new data frame 
constructed from merging the individual data frames together and making 
sure it's all in the right order. Which is tricky, because the 
SpatialGridDataFrame constructor expects its data argument to start at 
top-left and sweep across and then down. To paste another raster to the 
right of an existing one would mean mingling the data frame rows....

  Or am I just missing something simple with this? Of course it *will* 
be simple, once I've written the tiling functions:

  foo = tile(bar,west=baz)

will construct a new grid 'foo' which is bar with baz pasted on it's 
western edge, equivalent to:

  foo = tile(baz,east=bar)

  it'll check the grids have the same number of rows (or for N-S tiling, 
columns) and that the data frames are similar.

Barry



From mdsumner at utas.edu.au  Mon Jun 16 15:21:03 2008
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Mon, 16 Jun 2008 23:21:03 +1000
Subject: [R-sig-Geo] Basic raster operations
In-Reply-To: <48563219.3040807@lancaster.ac.uk>
References: <48563219.3040807@lancaster.ac.uk>
Message-ID: <485668BF.7020809@utas.edu.au>

I would follow this up in the elide() function of maptools.  I thought 
I'd post this as a partial answer, since I'm sure this is the most 
productive way to go given the goals of sp/maptools.

This is a test done only for simple shift on SGDF:

## WARNING: test method only partially implemented (for shift=)
setMethod("elide", "SpatialGridDataFrame",
    function(obj, ...)
    {
    .local <- function (obj, bb = NULL, shift = c(0, 0), reflect = c(FALSE,
        FALSE), scale = NULL, flip = FALSE, rotate = 0, center = NULL)
    {
        #res <- elide(as(obj, "SpatialPoints"), bb = bb, shift = shift,
         #   reflect = reflect, scale = scale, flip = flip, rotate = 
rotate,
          #  center = center)

    warning("TEST METHOD: elide only defined for shift on SGDF!")
    gt <- getGridTopology(obj)

    cc.offset <- gt at cellcentre.offset + shift
    gt <- GridTopology(cc.offset, gt at cellsize, gt at cells.dim)
    p4 <- proj4string(obj)

        df <- slot(obj, "data")
        res <- SpatialGridDataFrame(gt, data = df, proj4string = 
CRS(as.character(p4)))
        res
    }
    .local(obj, ...)
})

## Examples
library(maptools)
x <- image2Grid(list(x = 1:nrow(volcano), y = 1:ncol(volcano), z = volcano))

image(x)
contour(elide(x, shift = c(-15, 10)), add = T)

y <-  readGDAL(system.file("pictures/Rlogo.jpg", package = "rgdal")[1], 
band=1)
image(y)
image(elide(y, shift = c(10, 10)), add = T)
   
I hope that helps, at least for your first question, certainly I 
appreciate you pushing me in the right direction. 

Cheers, Mike.

Barry Rowlingson wrote:
> I'm getting frustrated at what I thought would be simple raster 
> manipulations...
>
>  * How can I shift a SpatialGridDataFrame? I can't just change the 
> coordinates:
>
> > coordinates(compare)=coordinates(compare)+10
> Error in `coordinates<-`(`*tmp*`, value = c(10.5, 11.5, 12.5, 13.5, 
> 14.5,  :
>   setting coordinates cannot be done on Spatial objects, where they 
> have already been set
>
>  Do I have to construct a new GridTopology object, then feed that to 
> SpatialGridDataFrame along with the @data slot from the original? It 
> seems to work, but I was hoping for something simpler, and I always 
> get the jitters when working with slots since I tend to think of them 
> as private object data that I shouldn't mess with. Isn't there a 
> 'getData' method?
>
>  * How can I construct larger SpatialGridDataFrames by tiling smaller 
> ones?
>
>  If they operated like matrices or data frames I could just cbind or 
> rbind them together. I think I'm going to have to do a similar 
> procedure as above - work out the new GridTopology and pass a new data 
> frame constructed from merging the individual data frames together and 
> making sure it's all in the right order. Which is tricky, because the 
> SpatialGridDataFrame constructor expects its data argument to start at 
> top-left and sweep across and then down. To paste another raster to 
> the right of an existing one would mean mingling the data frame rows....
>
>  Or am I just missing something simple with this? Of course it *will* 
> be simple, once I've written the tiling functions:
>
>  foo = tile(bar,west=baz)
>
> will construct a new grid 'foo' which is bar with baz pasted on it's 
> western edge, equivalent to:
>
>  foo = tile(baz,east=bar)
>
>  it'll check the grids have the same number of rows (or for N-S 
> tiling, columns) and that the data frames are similar.
>
> Barry
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> ------------------------------------------------------------------------
>
>
> No virus found in this incoming message.
> Checked by AVG. 
> Version: 8.0.100 / Virus Database: 270.3.0/1505 - Release Date: 6/16/2008 7:20 AM
>



From ddepew at sciborg.uwaterloo.ca  Mon Jun 16 18:49:22 2008
From: ddepew at sciborg.uwaterloo.ca (Dave Depew)
Date: Mon, 16 Jun 2008 12:49:22 -0400
Subject: [R-sig-Geo] kriging
Message-ID: <48569992.8020006@scimail.uwaterloo.ca>

Hi all,
I have a data set that I would like to krige to interpolate between 
transects. There is a non-linear trend between two of the variables...my 
impression from reading the gstat help file is that there must be a 
linear relationship between the data to use universal kriging?
Second, would a method of non-linear regression followed by modelling of 
the residuals with a semivariogram be an appropriate solution?

Thanks,

Dave



From paulojus at c3sl.ufpr.br  Mon Jun 16 22:21:47 2008
From: paulojus at c3sl.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Mon, 16 Jun 2008 17:21:47 -0300 (BRT)
Subject: [R-sig-Geo] kriging
In-Reply-To: <48569992.8020006@scimail.uwaterloo.ca>
References: <48569992.8020006@scimail.uwaterloo.ca>
Message-ID: <Pine.LNX.4.58.0806161720010.19855@macalan.c3sl.ufpr.br>

Dave,

what is necessary for UK is a relation expressed by a linear model, not
necessaraly a linear relation between the variables.
e.g. you could have a second degree polinomial and still work within the
scope of universal kriging.


On Mon, 16 Jun 2008, Dave Depew wrote:

> Hi all,
> I have a data set that I would like to krige to interpolate between
> transects. There is a non-linear trend between two of the variables...my
> impression from reading the gstat help file is that there must be a
> linear relationship between the data to use universal kriging?
> Second, would a method of non-linear regression followed by modelling of
> the residuals with a semivariogram be an appropriate solution?
>
> Thanks,
>
> Dave
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

Paulo Justiniano Ribeiro Jr
LEG (Laboratorio de Estatistica e Geoinformacao)
Universidade Federal do Parana
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 3361 3573
Fax: (+55) 41 3361 3141
e-mail: paulojus AT  ufpr  br
http://www.leg.ufpr.br/~paulojus



From ddepew at sciborg.uwaterloo.ca  Mon Jun 16 22:54:16 2008
From: ddepew at sciborg.uwaterloo.ca (Dave Depew)
Date: Mon, 16 Jun 2008 16:54:16 -0400
Subject: [R-sig-Geo] kriging
In-Reply-To: <Pine.LNX.4.58.0806161720010.19855@macalan.c3sl.ufpr.br>
References: <48569992.8020006@scimail.uwaterloo.ca>
	<Pine.LNX.4.58.0806161720010.19855@macalan.c3sl.ufpr.br>
Message-ID: <4856D2F8.4060009@scimail.uwaterloo.ca>

Ok,
What about higher order polynomials? I have fitted one using a gam to 
the data which which helps to normalize the residuals, and reduce the 
variance of the residuals.
Is it simply a matter of plugging in the function into the gstat command 
line? Or is it simpler to krig the residuals and then add the trend back 
to the interpolated residual grid?


Paulo Justiniano Ribeiro Jr wrote:
> Dave,
>
> what is necessary for UK is a relation expressed by a linear model, not
> necessaraly a linear relation between the variables.
> e.g. you could have a second degree polinomial and still work within the
> scope of universal kriging.
>
>
> On Mon, 16 Jun 2008, Dave Depew wrote:
>
>   
>> Hi all,
>> I have a data set that I would like to krige to interpolate between
>> transects. There is a non-linear trend between two of the variables...my
>> impression from reading the gstat help file is that there must be a
>> linear relationship between the data to use universal kriging?
>> Second, would a method of non-linear regression followed by modelling of
>> the residuals with a semivariogram be an appropriate solution?
>>
>> Thanks,
>>
>> Dave
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>     
>
> Paulo Justiniano Ribeiro Jr
> LEG (Laboratorio de Estatistica e Geoinformacao)
> Universidade Federal do Parana
> Caixa Postal 19.081
> CEP 81.531-990
> Curitiba, PR  -  Brasil
> Tel: (+55) 41 3361 3573
> Fax: (+55) 41 3361 3141
> e-mail: paulojus AT  ufpr  br
> http://www.leg.ufpr.br/~paulojus
>
>
>
>



From debarchana.ghosh at gmail.com  Tue Jun 17 01:38:33 2008
From: debarchana.ghosh at gmail.com (Debarchana Ghosh)
Date: Mon, 16 Jun 2008 18:38:33 -0500
Subject: [R-sig-Geo] Error in converting SpatialPointsDataFrame object to
	ESRI shape file using writeOGR from rgdal package
Message-ID: <d1b8ff630806161638l50531bc9j43dc1c778ad38152@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080616/3afc4345/attachment.pl>

From yud at mail.montclair.edu  Tue Jun 17 02:26:45 2008
From: yud at mail.montclair.edu (Danlin Yu)
Date: Mon, 16 Jun 2008 20:26:45 -0400
Subject: [R-sig-Geo] Error in converting SpatialPointsDataFrame object
 to	ESRI shape file using writeOGR from rgdal package
In-Reply-To: <d1b8ff630806161638l50531bc9j43dc1c778ad38152@mail.gmail.com>
References: <d1b8ff630806161638l50531bc9j43dc1c778ad38152@mail.gmail.com>
Message-ID: <485704C5.4040700@mail.montclair.edu>

Dear Debarchana Ghosh:

It may be me, but when I put a double quotation on [place] (I assume 
that's the layer's name?], writeOGR generates a folder with shapefiles 
in it. If that doesn't work or my understanding is not correct, you can 
still generate a shapefile by exporting the SDF object as an ASCII file 
(.csv is one of my favorite), since it does contain coordinates, you can 
then create a shapefile using GeoDa [Tools->Shape->Points from ASCII...].

Hope this helps.

Danlin

Debarchana Ghosh wrote:
> Hi,
>
> I am using R 2.7 on windows with 4GB ram.
>
> I am trying to convert the SpatialPointsDataFrame object (SDF) from the
> "gwr" output ( spgwr package) to ESRI shapefile using the writeOGR function
> from the rgdal package. The function is able to write the shape file with
> correct geometry but showing errors when trying to view the attribute table.
> The attribute table is empty. But the data slot of the
> SpatialPointsDataFrame object has values for all the columns. Below I paste
> my codes:
>
> # packages spgwr, maptool, sp, foreign
> # Finding the bandwidth by the AIC method
> test500.bw.aic<-gwr.sel(yimp00~ english + slope30 + mac95d + mdinc_t +
> musa00
>   + popden_t + dissewer + dismcd + diswater + ag04 + c1dishwy + c1dipark +
> tccost1 + soil1 + soil2,
>   data=base500vars, coords = cbind(base500vars$longx, base500vars$laty),
> method = "aic", longlat=TRUE)
>
> # gauss gwr function
> test500.gwr<-gwr(yimp00~ english + slope30 + mac95d + mdinc_t + musa00 +
> popden_t + dissewer + dismcd + diswater
>   + ag04 + c1dishwy + c1dipark + tccost1 + soil1 + soil2, data=base500vars,
>   coords = cbind(base500vars$longx, base500vars$laty), longlat=TRUE,
> bandwidth = test500.bw.aic,
>   hatmatrix=TRUE, se.fit=TRUE)
>
> # output of gwr
> names(test500.gwr)
> [1] "SDF"       "lhat"      "lm"        "results"   "bandwidth" "adapt"
> "hatmatrix" "gweight"   "this.call"
>
> class(test500.gwr$SDF)
> [1] "SpatialPointsDataFrame"
> attr(,"package")
> [1] "sp"
>
>   
>> names(test500.gwr$SDF)
>>     
>  [1] "sum.w"          "(Intercept)"    "english"        "slope30"
> "mac95d"         "mdinc_t"        "musa00"         "popden_t"
>  [9] "dissewer"       "dismcd"         "diswater"       "ag04"
> "c1dishwy"       "c1dipark"       "tccost1"        "soil1"
> [17] "soil2"          "R2"             "gwr.e"          "(Intercept)_se"
> "english_se"     "slope30_se"     "mac95d_se"      "mdinc_t_se"
> [25] "musa00_se"      "popden_t_se"    "dissewer_se"    "dismcd_se"
> "diswater_se"    "ag04_se"        "c1dishwy_se"    "c1dipark_se"
> [33] "tccost1_se"     "soil1_se"       "soil2_se"
>
> # I changed the names of column 2 and 20 to "Intercept" and "Intercept_se"
> because ESRI shapefiles does not like brackets
>   
>> names(test500.gwr$SDF)[2]<-"Intercept"
>> names(test500.gwr$SDF)[20]<-"Intercept_se"
>> names(test500.gwr$SDF)
>>     
>  [1] "sum.w"        "Intercept"    "english"      "slope30"
> "mac95d"       "mdinc_t"      "musa00"       "popden_t"     "dissewer"
> [10] "dismcd"       "diswater"     "ag04"         "c1dishwy"
> "c1dipark"     "tccost1"      "soil1"        "soil2"        "R2"
> [19] "gwr.e"        "Intercept_se" "english_se"   "slope30_se"
> "mac95d_se"    "mdinc_t_se"   "musa00_se"    "popden_t_se"  "dissewer_se"
> [28] "dismcd_se"    "diswater_se"  "ag04_se"      "c1dishwy_se"
> "c1dipark_se"  "tccost1_se"   "soil1_se"     "soil2_se"
>
> # Converting a "SpatialPointsDataFrame" object to ESRI shape file
> # packages rgdal
> writeOGR(test500.gwr$SDF, place, "test500gwr", driver="ESRI Shapefile")
>
> I cannot seem to find the error. Is there any other way to write the
> 'SpatialPointsDataFrame' object to ESRI shapefiles?
>
> Any pointers will be very helpful.
>
>   

-- 
___________________________________________
Danlin Yu, Ph.D.
Assistant Professor
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
email: yud at mail.montclair.edu
webpage: csam.montclair.edu/~yu



From Roger.Bivand at nhh.no  Tue Jun 17 06:02:48 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 17 Jun 2008 06:02:48 +0200 (CEST)
Subject: [R-sig-Geo] Error in converting SpatialPointsDataFrame object
 to ESRI shape file using writeOGR from rgdal package
In-Reply-To: <d1b8ff630806161638l50531bc9j43dc1c778ad38152@mail.gmail.com>
References: <d1b8ff630806161638l50531bc9j43dc1c778ad38152@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0806170552500.10162@reclus.nhh.no>

On Mon, 16 Jun 2008, Debarchana Ghosh wrote:

> Hi,
>
> I am using R 2.7 on windows with 4GB ram.
>
> I am trying to convert the SpatialPointsDataFrame object (SDF) from the
> "gwr" output ( spgwr package) to ESRI shapefile using the writeOGR function
> from the rgdal package. The function is able to write the shape file with
> correct geometry but showing errors when trying to view the attribute table.
> The attribute table is empty. But the data slot of the
> SpatialPointsDataFrame object has values for all the columns. Below I paste
> my codes:

The issue seems to be that the underlying DBF format cannot handle field 
names which are longer than 11 characters. I've looked at:

names(test500.gwr$SDF) <- make.names(names(test500.gwr$SDF))

and tried abbreviate() too, and toupper() without much luck. Maybe:

toupper(gsub("\\.", "_", make.names(substring(names(test500.gwr$SDF), 1,
   7), unique=TRUE)))

or even less than 7 if need be?

What else apart from shapefiles can Arc read that writeOGR can write that 
would let us get round using DBF?

Roger

>
> # packages spgwr, maptool, sp, foreign
> # Finding the bandwidth by the AIC method
> test500.bw.aic<-gwr.sel(yimp00~ english + slope30 + mac95d + mdinc_t +
> musa00
>  + popden_t + dissewer + dismcd + diswater + ag04 + c1dishwy + c1dipark +
> tccost1 + soil1 + soil2,
>  data=base500vars, coords = cbind(base500vars$longx, base500vars$laty),
> method = "aic", longlat=TRUE)
>
> # gauss gwr function
> test500.gwr<-gwr(yimp00~ english + slope30 + mac95d + mdinc_t + musa00 +
> popden_t + dissewer + dismcd + diswater
>  + ag04 + c1dishwy + c1dipark + tccost1 + soil1 + soil2, data=base500vars,
>  coords = cbind(base500vars$longx, base500vars$laty), longlat=TRUE,
> bandwidth = test500.bw.aic,
>  hatmatrix=TRUE, se.fit=TRUE)
>
> # output of gwr
> names(test500.gwr)
> [1] "SDF"       "lhat"      "lm"        "results"   "bandwidth" "adapt"
> "hatmatrix" "gweight"   "this.call"
>
> class(test500.gwr$SDF)
> [1] "SpatialPointsDataFrame"
> attr(,"package")
> [1] "sp"
>
>> names(test500.gwr$SDF)
> [1] "sum.w"          "(Intercept)"    "english"        "slope30"
> "mac95d"         "mdinc_t"        "musa00"         "popden_t"
> [9] "dissewer"       "dismcd"         "diswater"       "ag04"
> "c1dishwy"       "c1dipark"       "tccost1"        "soil1"
> [17] "soil2"          "R2"             "gwr.e"          "(Intercept)_se"
> "english_se"     "slope30_se"     "mac95d_se"      "mdinc_t_se"
> [25] "musa00_se"      "popden_t_se"    "dissewer_se"    "dismcd_se"
> "diswater_se"    "ag04_se"        "c1dishwy_se"    "c1dipark_se"
> [33] "tccost1_se"     "soil1_se"       "soil2_se"
>
> # I changed the names of column 2 and 20 to "Intercept" and "Intercept_se"
> because ESRI shapefiles does not like brackets
>> names(test500.gwr$SDF)[2]<-"Intercept"
>> names(test500.gwr$SDF)[20]<-"Intercept_se"
>> names(test500.gwr$SDF)
> [1] "sum.w"        "Intercept"    "english"      "slope30"
> "mac95d"       "mdinc_t"      "musa00"       "popden_t"     "dissewer"
> [10] "dismcd"       "diswater"     "ag04"         "c1dishwy"
> "c1dipark"     "tccost1"      "soil1"        "soil2"        "R2"
> [19] "gwr.e"        "Intercept_se" "english_se"   "slope30_se"
> "mac95d_se"    "mdinc_t_se"   "musa00_se"    "popden_t_se"  "dissewer_se"
> [28] "dismcd_se"    "diswater_se"  "ag04_se"      "c1dishwy_se"
> "c1dipark_se"  "tccost1_se"   "soil1_se"     "soil2_se"
>
> # Converting a "SpatialPointsDataFrame" object to ESRI shape file
> # packages rgdal
> writeOGR(test500.gwr$SDF, place, "test500gwr", driver="ESRI Shapefile")
>
> I cannot seem to find the error. Is there any other way to write the
> 'SpatialPointsDataFrame' object to ESRI shapefiles?
>
> Any pointers will be very helpful.
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From tech_dev at wildintellect.com  Tue Jun 17 09:40:39 2008
From: tech_dev at wildintellect.com (Alex Mandel)
Date: Tue, 17 Jun 2008 00:40:39 -0700
Subject: [R-sig-Geo] Error in converting SpatialPointsDataFrame object
 to ESRI shape file using writeOGR from rgdal package
In-Reply-To: <Pine.LNX.4.64.0806170552500.10162@reclus.nhh.no>
References: <d1b8ff630806161638l50531bc9j43dc1c778ad38152@mail.gmail.com>
	<Pine.LNX.4.64.0806170552500.10162@reclus.nhh.no>
Message-ID: <48576A77.2090304@wildintellect.com>

Roger Bivand wrote:
> On Mon, 16 Jun 2008, Debarchana Ghosh wrote:
> 
>> Hi,
>>
>> I am using R 2.7 on windows with 4GB ram.
>>
>> I am trying to convert the SpatialPointsDataFrame object (SDF) from the
>> "gwr" output ( spgwr package) to ESRI shapefile using the writeOGR 
>> function
>> from the rgdal package. The function is able to write the shape file with
>> correct geometry but showing errors when trying to view the attribute 
>> table.
>> The attribute table is empty. But the data slot of the
>> SpatialPointsDataFrame object has values for all the columns. Below I 
>> paste
>> my codes:
> 
> The issue seems to be that the underlying DBF format cannot handle field 
> names which are longer than 11 characters. I've looked at:
> 
> names(test500.gwr$SDF) <- make.names(names(test500.gwr$SDF))
> 
> and tried abbreviate() too, and toupper() without much luck. Maybe:
> 
> toupper(gsub("\\.", "_", make.names(substring(names(test500.gwr$SDF), 1,
>   7), unique=TRUE)))
> 
> or even less than 7 if need be?
> 
> What else apart from shapefiles can Arc read that writeOGR can write 
> that would let us get round using DBF?
> 
> Roger
> 
>

It's well known that DBF doesn't support more than 8 characters in field 
names and that Arc doesn't really support much else.

A few options,
1. Create a shp with OGR and put the attributes in something like a csv 
then do a join operation in ArcGIS
2. Create a geodatabase in ArcGIS (mdb format), write the attributes to 
a table via ODBC, import the separately created shp and join.
3. KML, problem again of course is that everything gets converted to shp 
  and hence truncated until you get it into a geodatabase.

Really they are all terrible solutions. In all of them it will have to 
enter shp format at some point which will require the altering of column 
names.

To truly skirt the issue would be to not use Arc at all and use 
something like QGIS,gvSIG or OpenJump which can all read OGR layers - 
GML, KML are a few of the easy ones.

Alex



From T.Hengl at uva.nl  Tue Jun 17 09:42:11 2008
From: T.Hengl at uva.nl (Hengl, T.)
Date: Tue, 17 Jun 2008 09:42:11 +0200
Subject: [R-sig-Geo] kriging
References: <48569992.8020006@scimail.uwaterloo.ca><Pine.LNX.4.58.0806161720010.19855@macalan.c3sl.ufpr.br>
	<4856D2F8.4060009@scimail.uwaterloo.ca>
Message-ID: <37382E8DCB905042969BA78541F6570624D4DE@kwek.ic.uva.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080617/378c288d/attachment.pl>

From ddepew at sciborg.uwaterloo.ca  Tue Jun 17 14:57:07 2008
From: ddepew at sciborg.uwaterloo.ca (Dave Depew)
Date: Tue, 17 Jun 2008 08:57:07 -0400
Subject: [R-sig-Geo] kriging
Message-ID: <4857B4A3.2090602@scimail.uwaterloo.ca>

Thanks Tom,
I've been able to fit a polynomial function to the data quite well. The 
residuals are behaving (i.e normal distribution and no skewness of 
variance). I'm assuming this means that I could krige the residuals 
(Ordinary K?) and then add the trend back to the predicted residual 
grid? I realize that I won't be able to place confidence limits on the 
predictions, but the data is primarily to show that we might be able to 
use GPS hydroacoustic signals to show macrophyte cover and estimate the 
standing crop. I'm still a newbie when it comes to the theory involved 
in kriging, but I think I am familiar with the basics...the variogram of 
the residuals is a nice spherical model (i.e. it reaches a sill about 
50% or so above the nugget, and there is little scatter). I am assuming 
(perhaps wrongly) that the residuals may be modelled with a variogram 
and then kriged...



From debarchana.ghosh at gmail.com  Tue Jun 17 18:18:15 2008
From: debarchana.ghosh at gmail.com (Debarchana Ghosh)
Date: Tue, 17 Jun 2008 11:18:15 -0500
Subject: [R-sig-Geo] Error in converting SpatialPointsDataFrame object
	to ESRI shape file using writeOGR from rgdal package
In-Reply-To: <48576A77.2090304@wildintellect.com>
References: <d1b8ff630806161638l50531bc9j43dc1c778ad38152@mail.gmail.com>
	<Pine.LNX.4.64.0806170552500.10162@reclus.nhh.no>
	<48576A77.2090304@wildintellect.com>
Message-ID: <d1b8ff630806170918i30b3ec10v29816704fbf26efd@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080617/a1d74db4/attachment.pl>

From debarchana.ghosh at gmail.com  Tue Jun 17 19:14:58 2008
From: debarchana.ghosh at gmail.com (Debarchana Ghosh)
Date: Tue, 17 Jun 2008 12:14:58 -0500
Subject: [R-sig-Geo] Interpretation of gwr output ~ where is the
	fitted/predicted y?
Message-ID: <d1b8ff630806171014m29961db1s31361354140079f8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080617/9fede8c1/attachment.pl>

From Roger.Bivand at nhh.no  Wed Jun 18 06:49:00 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 18 Jun 2008 06:49:00 +0200 (CEST)
Subject: [R-sig-Geo] Interpretation of gwr output ~ where is the
 fitted/predicted y?
In-Reply-To: <d1b8ff630806171014m29961db1s31361354140079f8@mail.gmail.com>
References: <d1b8ff630806171014m29961db1s31361354140079f8@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0806180640070.17695@reclus.nhh.no>

On Tue, 17 Jun 2008, Debarchana Ghosh wrote:

> Hi,
>
> OS: 2.70 R version on Windows with 4 GB Ram
>
> I have created an object of class gwr from the function 'gwr' (package
> spgwr). But cannot find the fitted/predicted y values in the output.
>
> test500.gwr <- gwr(formula = yimp00 ~ english + slope30 + mac95d + mdinc_t +
>
>                      musa00 + popden_t + dissewer + dismcd + diswater +
> ag04 +
>                      c1dishwy + c1dipark + tccost1 + soil1 + soil2, data =
> base500vars,
>                      coords = cbind(base500vars$longx, base500vars$laty),
> bandwidth = test500.bw.aic,
>                      hatmatrix = TRUE, longlat = TRUE, se.fit = TRUE)
>
>> names(test500.gwr)
> [1] "SDF"       "lhat"      "lm"        "results"   "bandwidth" "adapt"
> "hatmatrix" "gweight"   "this.call"**
>
>> names(test500.gwr$SDF)
> [1] "sumw"       "Intercept"  "english"    "slope30"    "mac95d"
> "mdinct"     "musa00"     "popdent"    "dissewer"   "dismcd"     "diswater"
>
> [12] "ag04"       "c1dishwy"   "c1dipark"   "tccost1"    "soil1"
> "soil2"      "R2"         "gwre"       "Interse"    "englishse"  "slope30se"
>
> [23] "mac95dse"   "mdinctse"   "musa00se"   "popdentse"  "dissewerse"
> "dismcdse"   "diswaterse" "ag04se"     "c1dishwyse" "c1diparkse" "tccost1se"
>
> [34] "soil1se"    "soil2se"
>
> I want to clarify whether gwre ( previously it was gwr.e) is the estimated Y
> values?
>

No, gwr.e is (currently) the i'th element of the vector of residuals in 
each GWR (that is for each fit point). On examination, neither it nor the 
R2 has any meaning when the fit points are not identical with the data 
points - I will investigate and patch if need be. If data points are fit 
points, you can, perhaps, use it to get fitted values with the y values 
- as in CV bandwidth selection. What do you need them for?

Hope this helps,

Roger

> Thanks,
> Debs.
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From T.Hengl at uva.nl  Wed Jun 18 09:39:16 2008
From: T.Hengl at uva.nl (Tomislav Hengl)
Date: Wed, 18 Jun 2008 09:39:16 +0200
Subject: [R-sig-Geo] kriging
In-Reply-To: <4857B4A3.2090602@scimail.uwaterloo.ca>
Message-ID: <009901c8d116$691b4660$3a871291@pcibed193>


Dear Dave,

I separate fitting of the deterministic (trend) and residual part of the universal kriging model all
the time. Adding OK of residuals to the trend is fine, as long as the regression model is estimated
using GLS (but many do it even if they use only OLS; the difference is often minor). Both KED and RK
give the same results, but in order to run KED, you need to have the residuals, so you always have
to model the trend-part anyway.

See some code at: https://stat.ethz.ch/pipermail/r-sig-geo/2008-April/003433.html 

In future, please keep the whole history of correspondence.

Tom Hengl
http://spatial-analyst.net 



-----Original Message-----
From: Dave Depew [mailto:ddepew at sciborg.uwaterloo.ca] 
Sent: dinsdag 17 juni 2008 14:57
To: T.Hengl at uva.nl
Cc: r-sig-geo at stat.math.ethz.ch
Subject: re:kriging

Thanks Tom,
I've been able to fit a polynomial function to the data quite well. The 
residuals are behaving (i.e normal distribution and no skewness of 
variance). I'm assuming this means that I could krige the residuals 
(Ordinary K?) and then add the trend back to the predicted residual 
grid? I realize that I won't be able to place confidence limits on the 
predictions, but the data is primarily to show that we might be able to 
use GPS hydroacoustic signals to show macrophyte cover and estimate the 
standing crop. I'm still a newbie when it comes to the theory involved 
in kriging, but I think I am familiar with the basics...the variogram of 
the residuals is a nice spherical model (i.e. it reaches a sill about 
50% or so above the nugget, and there is little scatter). I am assuming 
(perhaps wrongly) that the residuals may be modelled with a variogram 
and then kriged...



From ddepew at sciborg.uwaterloo.ca  Wed Jun 18 15:10:20 2008
From: ddepew at sciborg.uwaterloo.ca (Dave Depew)
Date: Wed, 18 Jun 2008 09:10:20 -0400
Subject: [R-sig-Geo] kriging
In-Reply-To: <009901c8d116$691b4660$3a871291@pcibed193>
References: <009901c8d116$691b4660$3a871291@pcibed193>
Message-ID: <4859093C.8040706@scimail.uwaterloo.ca>

hi Tom,
That was my impression from reading some introductory texts... I'll have 
to see how the mgcv package fits the polynomial function to the 
data...it isn't clear to me at first glance how it is accomplished.
Many thanks for your advice.

Dave

Tomislav Hengl wrote:
> Dear Dave,
>
> I separate fitting of the deterministic (trend) and residual part of the universal kriging model all
> the time. Adding OK of residuals to the trend is fine, as long as the regression model is estimated
> using GLS (but many do it even if they use only OLS; the difference is often minor). Both KED and RK
> give the same results, but in order to run KED, you need to have the residuals, so you always have
> to model the trend-part anyway.
>
> See some code at: https://stat.ethz.ch/pipermail/r-sig-geo/2008-April/003433.html 
>
> In future, please keep the whole history of correspondence.
>
> Tom Hengl
> http://spatial-analyst.net 
>
>
>
> -----Original Message-----
> From: Dave Depew [mailto:ddepew at sciborg.uwaterloo.ca] 
> Sent: dinsdag 17 juni 2008 14:57
> To: T.Hengl at uva.nl
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: re:kriging
>
> Thanks Tom,
> I've been able to fit a polynomial function to the data quite well. The 
> residuals are behaving (i.e normal distribution and no skewness of 
> variance). I'm assuming this means that I could krige the residuals 
> (Ordinary K?) and then add the trend back to the predicted residual 
> grid? I realize that I won't be able to place confidence limits on the 
> predictions, but the data is primarily to show that we might be able to 
> use GPS hydroacoustic signals to show macrophyte cover and estimate the 
> standing crop. I'm still a newbie when it comes to the theory involved 
> in kriging, but I think I am familiar with the basics...the variogram of 
> the residuals is a nice spherical model (i.e. it reaches a sill about 
> 50% or so above the nugget, and there is little scatter). I am assuming 
> (perhaps wrongly) that the residuals may be modelled with a variogram 
> and then kriged...
>
>
>



From jbarnier at ens-lsh.fr  Wed Jun 18 15:58:21 2008
From: jbarnier at ens-lsh.fr (Julien Barnier)
Date: Wed, 18 Jun 2008 15:58:21 +0200
Subject: [R-sig-Geo] [OT] Coordinates and pojection problems
Message-ID: <87hcbqc0aq.fsf@z.nozav.org>

Hi,

I'm sorry to post a rather off-topic question here, but as a new sp
user and total novice in coordinates and projections questions, I'm
facing a problem you may help me to solve. Please ignore this post if
it is too much noise.

I've got two map files (a MapInfo file and an ESRI shapefile) from two
different sources but which represent objects from the same french
region (one represent the cities, the other rivers and water
surfaces). 

The problem is that when imported into R and plotted together, they
doesn't appear in the same place.  They seem to have the same
?longitude?, but the ?latitude? is different. If I plot them, the
first map ranges in the Y axis from 70,000 to 100,000 and the second
one from 2,060,000 to 2,140,000. The ranges along the x axis seem to
be the same, though.

Here is the output of ogrinfo on the two files :

,----
| $ ogrinfo -so 69_iris.mid 69_iris
| Had to open data source read-only.
| INFO: Open of `69_iris.mid'
|       using driver `MapInfo File' successful.
| 
| Layer name: 69_iris
| Geometry: Unknown (any)
| Feature Count: 774
| Extent: (747910.000000, 2053380.000000) - (819740.000000,
| 2147622.300000)
| Layer SRS WKT:
| PROJCS[?unnamed?,
|     GEOGCS[?unnamed?,
|         DATUM[?MIF 9999,6,-168,-60,320,0,0,0,0,0?,
|             SPHEROID[?Clarke 1880?,6378249.145,293.465],
|             TOWGS84[-168,-60,320,-0,-0,-0,0]],
|         PRIMEM[?non-Greenwich?,0],
|         UNIT[?degree?,0.0174532925199433]],
|     PROJECTION[?Lambert_Conformal_Conic_2SP?],
|     PARAMETER[?standard_parallel_1?,45.90287723937],
|     PARAMETER[?standard_parallel_2?,47.69712276063],
|     PARAMETER[?latitude_of_origin?,46.8],
|     PARAMETER[?central_meridian?,2.337229104484],
|     PARAMETER[?false_easting?,600000],
|     PARAMETER[?false_northing?,2200000],
|     UNIT[?Meter?,1]]
| DepCom: String (5.0)
| Nom_Com: String (40.0)
| Iris: String (4.0)
| DComIris: String (9.0)
| Nom_Iris: String (43.0)
| Typ_Iris: String (1.0)
| Indic: String (1.0)
| Origine: String (1.0)
`----

,----
| $ ogrinfo -so Decoupage_Administratif/SURFDEAU.shp SURFDEAU
| INFO: Open of `Decoupage_Administratif/SURFDEAU.shp'
|       using driver `ESRI Shapefile' successful.
| 
| Layer name: SURFDEAU
| Geometry: Polygon
| Feature Count: 168
| Extent: (785619.190000, 68133.620000) - (818193.410000, 107443.340000)
| Layer SRS WKT:
| (unknown)
| NUMOBJ: String (11.0)
`----

I've tried to play with some parameters in readShapePoly and
spTransform, but without success.

Any help would be greatly appreciated.

Thanks in advance,
-- 
Julien Barnier
Groupe de recherche sur la socialisation
ENS-LSH - Lyon, France



From debarchana.ghosh at gmail.com  Wed Jun 18 17:10:50 2008
From: debarchana.ghosh at gmail.com (Debarchana Ghosh)
Date: Wed, 18 Jun 2008 10:10:50 -0500
Subject: [R-sig-Geo] Interpretation of gwr output ~ where is the
	fitted/predicted y?
In-Reply-To: <Pine.LNX.4.64.0806180640070.17695@reclus.nhh.no>
References: <d1b8ff630806171014m29961db1s31361354140079f8@mail.gmail.com>
	<Pine.LNX.4.64.0806180640070.17695@reclus.nhh.no>
Message-ID: <d1b8ff630806180810q69ec1b10r2ee0f9103db26466@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080618/ba9e2f95/attachment.pl>

From yud at mail.montclair.edu  Wed Jun 18 18:37:20 2008
From: yud at mail.montclair.edu (Danlin Yu)
Date: Wed, 18 Jun 2008 12:37:20 -0400
Subject: [R-sig-Geo] Interpretation of gwr output ~ where is
 the	fitted/predicted y?
In-Reply-To: <d1b8ff630806180810q69ec1b10r2ee0f9103db26466@mail.gmail.com>
References: <d1b8ff630806171014m29961db1s31361354140079f8@mail.gmail.com>
	<Pine.LNX.4.64.0806180640070.17695@reclus.nhh.no>
	<d1b8ff630806180810q69ec1b10r2ee0f9103db26466@mail.gmail.com>
Message-ID: <485939C0.4020403@mail.montclair.edu>

Debarchana:

As Roger has pointed out, since gwr.e is the gwr residuals, it is easy 
to calculate the estimated Y from the observed Y since residual = 
(observed Y) - (estimated Y).

To extract the gwr.e, just do this:

residuals.gwr<-test500.gwr$SDF$gwr.e

and the estimated Y would be:

est.gwr<-yimp00-residuals.gwr

And then you can compare all Ys.

Hope this helps.

Cheers,
Danlin

Debarchana Ghosh wrote:
>>> I want to clarify whether gwre ( previously it was gwr.e) is the estimated
>>> Y
>>> values?
>>>
>>>
>>>       
>> No, gwr.e is (currently) the i'th element of the vector of residuals in
>> each GWR (that is for each fit point). On examination, neither it nor the R2
>> has any meaning when the fit points are not identical with the data points -
>> I will investigate and patch if need be. If data points are fit points, you
>> can, perhaps, use it to get fitted values with the y values - as in CV
>> bandwidth selection. What do you need them for?
>>     
>
>
>
> In the following gwr run, the fit.points are same as the given data points,
> i.e. the gwr regression is fitted on the points "coords =
> cbind(base500vars$longx, base500vars$laty)" , which was passed as an
> argument in the main gwr function and the fit.points argument was not
> specified.
>
> # gwr function
> test500.gwr<-gwr(yimp00~ english + slope30 + mac95d + mdinc_t + musa00 +
> popden_t + dissewer + dismcd
>   + diswater + ag04 + c1dishwy + c1dipark + tccost1 + soil1 + soil2,
> data=base500vars,
>   coords = cbind(base500vars$longx, base500vars$laty), longlat=TRUE,
> bandwidth = test500.bw.aic,
>   hatmatrix=TRUE, se.fit=TRUE, gweight=bisquare)
>
> I did not understand how I can get the estimated y values as in CV bandwidth
> selection.
>
> Since my data points are same as the fitted points, I want to compare the 1)
> observed Y, 2) estimated Y from the OLS regression (lm object) and 3)
> estimated Y from the GWR regression (from the gwr object)
>
> Thanks,
> Debs.
>
>
>   

-- 
___________________________________________
Danlin Yu, Ph.D.
Assistant Professor
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
email: yud at mail.montclair.edu
webpage: csam.montclair.edu/~yu



From debarchana.ghosh at gmail.com  Wed Jun 18 22:34:55 2008
From: debarchana.ghosh at gmail.com (Debarchana Ghosh)
Date: Wed, 18 Jun 2008 15:34:55 -0500
Subject: [R-sig-Geo] Interpretation of gwr output ~ where is the
	fitted/predicted y?
In-Reply-To: <485939C0.4020403@mail.montclair.edu>
References: <d1b8ff630806171014m29961db1s31361354140079f8@mail.gmail.com>
	<Pine.LNX.4.64.0806180640070.17695@reclus.nhh.no>
	<d1b8ff630806180810q69ec1b10r2ee0f9103db26466@mail.gmail.com>
	<485939C0.4020403@mail.montclair.edu>
Message-ID: <d1b8ff630806181334i6420fee0j2910b1ec4f624b52@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080618/5cac5d0b/attachment.pl>

From tkobayas at indiana.edu  Thu Jun 19 04:43:50 2008
From: tkobayas at indiana.edu (tkobayas at indiana.edu)
Date: Wed, 18 Jun 2008 22:43:50 -0400
Subject: [R-sig-Geo] PBSmapping segfault?
In-Reply-To: <87hcbqc0aq.fsf@z.nozav.org>
References: <87hcbqc0aq.fsf@z.nozav.org>
Message-ID: <20080618224350.vcf20dmi7ko0okw8@webmail.iu.edu>

Hi,

I am having a problem with segmentation fault when I run my code using 
PBSmapping. I have thought 'segfault' indicates either that my code is 
wrong or that something is missing in this package.

When I run my code, a terminal on Ubuntu shows me:

Program received signal SIGSEGV, Segmentation fault.
gpc_polygon_clip (op=GPC_INT, subj=<value optimized out>,
    clip=<value optimized out>, result=0x18c76d0) at gpc.c:1721
1721    gpc.c: No such file or directory.
        in gpc.c

So I guess I need to install gpc.c from somewhere.

I have been net searching this file, but no luck. I appreciate any help.

Thanks.

Best regards,

Taka



From Roger.Bivand at nhh.no  Thu Jun 19 05:30:47 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 19 Jun 2008 05:30:47 +0200 (CEST)
Subject: [R-sig-Geo] Interpretation of gwr output ~ where is the
 fitted/predicted y?
In-Reply-To: <d1b8ff630806180810q69ec1b10r2ee0f9103db26466@mail.gmail.com>
References: <d1b8ff630806171014m29961db1s31361354140079f8@mail.gmail.com> 
	<Pine.LNX.4.64.0806180640070.17695@reclus.nhh.no>
	<d1b8ff630806180810q69ec1b10r2ee0f9103db26466@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0806190524100.20735@reclus.nhh.no>

On Wed, 18 Jun 2008, Debarchana Ghosh wrote:

>>
>>>
>>> I want to clarify whether gwre ( previously it was gwr.e) is the estimated
>>> Y
>>> values?
>>>
>>>
>> No, gwr.e is (currently) the i'th element of the vector of residuals in
>> each GWR (that is for each fit point). On examination, neither it nor the R2
>> has any meaning when the fit points are not identical with the data points -
>> I will investigate and patch if need be. If data points are fit points, you
>> can, perhaps, use it to get fitted values with the y values - as in CV
>> bandwidth selection. What do you need them for?
>
>
>
> In the following gwr run, the fit.points are same as the given data points,
> i.e. the gwr regression is fitted on the points "coords =
> cbind(base500vars$longx, base500vars$laty)" , which was passed as an
> argument in the main gwr function and the fit.points argument was not
> specified.
>
> # gwr function
> test500.gwr<-gwr(yimp00~ english + slope30 + mac95d + mdinc_t + musa00 +
> popden_t + dissewer + dismcd
>  + diswater + ag04 + c1dishwy + c1dipark + tccost1 + soil1 + soil2,
> data=base500vars,
>  coords = cbind(base500vars$longx, base500vars$laty), longlat=TRUE,
> bandwidth = test500.bw.aic,
>  hatmatrix=TRUE, se.fit=TRUE, gweight=bisquare)
>
> I did not understand how I can get the estimated y values as in CV bandwidth
> selection.

By arithmetic. If yi = yhati + ei, and you have yi (from the input 
data) and ei (from gwr.e), you can get yhati. I don't know what they give 
you, though, since they are dependent on the choice of kernel and 
bandwidth, as well as the relative arrangement of the data points, so they 
are just one of many possible sets of GWR fitted values.

Roger

PS. The erroneous local R2 and gwr.e where fit points are not data 
points will be removed from the results at the next release and replaced 
by NAs.

>
> Since my data points are same as the fitted points, I want to compare the 1)
> observed Y, 2) estimated Y from the OLS regression (lm object) and 3)
> estimated Y from the GWR regression (from the gwr object)
>
> Thanks,
> Debs.
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Thu Jun 19 06:06:38 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 19 Jun 2008 06:06:38 +0200 (CEST)
Subject: [R-sig-Geo] PBSmapping segfault?
In-Reply-To: <20080618224350.vcf20dmi7ko0okw8@webmail.iu.edu>
References: <87hcbqc0aq.fsf@z.nozav.org>
	<20080618224350.vcf20dmi7ko0okw8@webmail.iu.edu>
Message-ID: <Pine.LNX.4.64.0806190602220.20735@reclus.nhh.no>

On Wed, 18 Jun 2008, tkobayas at indiana.edu wrote:

> Hi,
>
> I am having a problem with segmentation fault when I run my code using 
> PBSmapping. I have thought 'segfault' indicates either that my code is wrong 
> or that something is missing in this package.
>
> When I run my code, a terminal on Ubuntu shows me:
>
> Program received signal SIGSEGV, Segmentation fault.
> gpc_polygon_clip (op=GPC_INT, subj=<value optimized out>,
>   clip=<value optimized out>, result=0x18c76d0) at gpc.c:1721
> 1721    gpc.c: No such file or directory.
>        in gpc.c
>
> So I guess I need to install gpc.c from somewhere.

No, it simply suggests that your copy of the package was compiled using 
the -g flag (standard for R in most cases, and inherited by packages with 
source code). Did you install from source, or a binary? Have you tried 
running R -d gdb to determine where the problem occurred? Have you 
contacted the package maintainer, best with a copy of the object (save()) 
and a script to reproduce the error?

Roger

>
> I have been net searching this file, but no luck. I appreciate any help.
>
> Thanks.
>
> Best regards,
>
> Taka
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From cfarmer at uvic.ca  Thu Jun 19 09:30:34 2008
From: cfarmer at uvic.ca (cfarmer)
Date: Thu, 19 Jun 2008 00:30:34 -0700 (PDT)
Subject: [R-sig-Geo] Load R sp vector layers in QGIS
In-Reply-To: <200806182218.26708.Ralf.Suhr@bauing.uni-weimar.de>
References: <20080615160005.C600EE01451@lists.osgeo.org>      
	<4859572A.4030602@gmail.com> <1213817300.7091.17.camel@vertical> 
	<200806182218.26708.Ralf.Suhr@bauing.uni-weimar.de>
Message-ID: <35781.142.104.193.193.1213860634.squirrel@wm3.uvic.ca>

Hello lists,

Apologies for cross posting, but I thought this might be of interest to
all groups...

Thanks to the excellent work of Martin Dobias on the QgsMemoryProvider, I
have created a simple plugin which acts as an additional file type handler
for R sp vector objects in QGIS.

To use:
1) In R ( or manageR ;) ), create an sp vector object
(SpatialPointsDataFrame, SpatialPolygonsDataFrame, SpatialLinesDataFrame).
2) Save the sp object to a .Rdata file
3) Enable the plugin in QGIS (the button should appear in the file toolbar
along with 'add vector layer', 'add raster layer', etc..
4) Click 'loadRlayer' button, and browse to your .Rdata file
5) The plugin should do the rest, and voila! Your R spatial layer should
be displayed on the QGIS map canvas.

To get it:
1) It is available from: 'http://www.geog.uvic.ca/spar/carson/'
or
2) Add 'http://www.geog.uvic.ca/spar/carson/cfarmerQgisRepo.xml' to your
repositories list in QGIS

Notes:
1) When possible, the spatial reference information is taken from the sp
object
2) The name is also taken from the sp object, not the name of the .Rdata file
3) Your .Rdata file should only contain a single sp object
4) I haven't tested this on multipoint or multiline features...?
5) You should be able to do all the normal things that vector layers in
QGIS can do (except for save edits).
6) Note that at this point, changes to the layer in QGIS will not be
reflected in the initial sp object, thus, this plugin is primarily for
visualizing your sp vector objects.

Hope you enjoy!

Carson



From p.hiemstra at geo.uu.nl  Thu Jun 19 11:32:04 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Thu, 19 Jun 2008 11:32:04 +0200
Subject: [R-sig-Geo] [OT] Coordinates and pojection problems
In-Reply-To: <87hcbqc0aq.fsf@z.nozav.org>
References: <87hcbqc0aq.fsf@z.nozav.org>
Message-ID: <485A2794.5090408@geo.uu.nl>

Hi,

You need to find out what the projection of the shapefile is, the 
ogrinfo does not give this information for your file as you probably do 
not have the .prj file. The R function spTransform needs the projection 
info in a so called proj4string. The easiest way to define such a string 
is through the epsg code, this code enables proj (the projection library 
used in R) to find the parameter it needs. For example, the proj4string 
for the Dutch national projection is:

"+proj=sterea +lat_0=52.15616055555555 +lon_0=5.38763888888889 
+k=0.9999079 +x_0=155000 +y_0=463000 +ellps=bessel +units=m 
+towgs84=565.04,49.91,465.84,-0.409394387,0.35970519561,-1.868491,4.0772 
+no_defs"

using epsg codes:

"+init=epsg:28992"

The bottomline is to find the projection of your second shapefile as 
this is the most likely candidate to cause the difference. A good place 
to ask questions regarding projections is the proj4-mailing list 
(http://lists.maptools.org/mailman/listinfo/proj).

hth and cheers,
Paul

Julien Barnier wrote:
> Hi,
>
> I'm sorry to post a rather off-topic question here, but as a new sp
> user and total novice in coordinates and projections questions, I'm
> facing a problem you may help me to solve. Please ignore this post if
> it is too much noise.
>
> I've got two map files (a MapInfo file and an ESRI shapefile) from two
> different sources but which represent objects from the same french
> region (one represent the cities, the other rivers and water
> surfaces). 
>
> The problem is that when imported into R and plotted together, they
> doesn't appear in the same place.  They seem to have the same
> ?longitude?, but the ?latitude? is different. If I plot them, the
> first map ranges in the Y axis from 70,000 to 100,000 and the second
> one from 2,060,000 to 2,140,000. The ranges along the x axis seem to
> be the same, though.
>
> Here is the output of ogrinfo on the two files :
>
> ,----
> | $ ogrinfo -so 69_iris.mid 69_iris
> | Had to open data source read-only.
> | INFO: Open of `69_iris.mid'
> |       using driver `MapInfo File' successful.
> | 
> | Layer name: 69_iris
> | Geometry: Unknown (any)
> | Feature Count: 774
> | Extent: (747910.000000, 2053380.000000) - (819740.000000,
> | 2147622.300000)
> | Layer SRS WKT:
> | PROJCS[?unnamed?,
> |     GEOGCS[?unnamed?,
> |         DATUM[?MIF 9999,6,-168,-60,320,0,0,0,0,0?,
> |             SPHEROID[?Clarke 1880?,6378249.145,293.465],
> |             TOWGS84[-168,-60,320,-0,-0,-0,0]],
> |         PRIMEM[?non-Greenwich?,0],
> |         UNIT[?degree?,0.0174532925199433]],
> |     PROJECTION[?Lambert_Conformal_Conic_2SP?],
> |     PARAMETER[?standard_parallel_1?,45.90287723937],
> |     PARAMETER[?standard_parallel_2?,47.69712276063],
> |     PARAMETER[?latitude_of_origin?,46.8],
> |     PARAMETER[?central_meridian?,2.337229104484],
> |     PARAMETER[?false_easting?,600000],
> |     PARAMETER[?false_northing?,2200000],
> |     UNIT[?Meter?,1]]
> | DepCom: String (5.0)
> | Nom_Com: String (40.0)
> | Iris: String (4.0)
> | DComIris: String (9.0)
> | Nom_Iris: String (43.0)
> | Typ_Iris: String (1.0)
> | Indic: String (1.0)
> | Origine: String (1.0)
> `----
>
> ,----
> | $ ogrinfo -so Decoupage_Administratif/SURFDEAU.shp SURFDEAU
> | INFO: Open of `Decoupage_Administratif/SURFDEAU.shp'
> |       using driver `ESRI Shapefile' successful.
> | 
> | Layer name: SURFDEAU
> | Geometry: Polygon
> | Feature Count: 168
> | Extent: (785619.190000, 68133.620000) - (818193.410000, 107443.340000)
> | Layer SRS WKT:
> | (unknown)
> | NUMOBJ: String (11.0)
> `----
>
> I've tried to play with some parameters in readShapePoly and
> spTransform, but without success.
>
> Any help would be greatly appreciated.
>
> Thanks in advance,
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul



From aloboaleu at gmail.com  Thu Jun 19 13:57:56 2008
From: aloboaleu at gmail.com (Agustin Lobo)
Date: Thu, 19 Jun 2008 13:57:56 +0200
Subject: [R-sig-Geo] Load R sp vector layers in QGIS
In-Reply-To: <35781.142.104.193.193.1213860634.squirrel@wm3.uvic.ca>
References: <20080615160005.C600EE01451@lists.osgeo.org>
	<4859572A.4030602@gmail.com> <1213817300.7091.17.camel@vertical>
	<200806182218.26708.Ralf.Suhr@bauing.uni-weimar.de>
	<35781.142.104.193.193.1213860634.squirrel@wm3.uvic.ca>
Message-ID: <485A49C4.5080000@gmail.com>

Carson,

This is geting close to my dreams, but
when I try to load the plugin, I get:
An error has occured while executing Python code:

Traceback (most recent call last):
  File "", line 1, in
  File "/home/alobo/.qgis//python/plugins/loadRlayer/loadRlayer.py", 
line 58, in initGui
   self.fileBar = self.iface.fileToolBar()
AttributeError: fileToolBar


(using QGIS 0.10 on ubuntu hardy from binaries, trying to build another 
version from svn)

Agus

cfarmer wrote:
> Hello lists,
> 
> Apologies for cross posting, but I thought this might be of interest to
> all groups...
> 
> Thanks to the excellent work of Martin Dobias on the QgsMemoryProvider, I
> have created a simple plugin which acts as an additional file type handler
> for R sp vector objects in QGIS.
> 
> To use:
> 1) In R ( or manageR ;) ), create an sp vector object
> (SpatialPointsDataFrame, SpatialPolygonsDataFrame, SpatialLinesDataFrame).
> 2) Save the sp object to a .Rdata file
> 3) Enable the plugin in QGIS (the button should appear in the file toolbar
> along with 'add vector layer', 'add raster layer', etc..
> 4) Click 'loadRlayer' button, and browse to your .Rdata file
> 5) The plugin should do the rest, and voila! Your R spatial layer should
> be displayed on the QGIS map canvas.
> 
> To get it:
> 1) It is available from: 'http://www.geog.uvic.ca/spar/carson/'
> or
> 2) Add 'http://www.geog.uvic.ca/spar/carson/cfarmerQgisRepo.xml' to your
> repositories list in QGIS
> 
> Notes:
> 1) When possible, the spatial reference information is taken from the sp
> object
> 2) The name is also taken from the sp object, not the name of the .Rdata file
> 3) Your .Rdata file should only contain a single sp object
> 4) I haven't tested this on multipoint or multiline features...?
> 5) You should be able to do all the normal things that vector layers in
> QGIS can do (except for save edits).
> 6) Note that at this point, changes to the layer in QGIS will not be
> reflected in the initial sp object, thus, this plugin is primarily for
> visualizing your sp vector objects.
> 
> Hope you enjoy!
> 
> Carson
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Roger.Bivand at nhh.no  Thu Jun 19 14:20:23 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 19 Jun 2008 14:20:23 +0200 (CEST)
Subject: [R-sig-Geo] [OT] Coordinates and pojection problems
In-Reply-To: <485A2794.5090408@geo.uu.nl>
References: <87hcbqc0aq.fsf@z.nozav.org> <485A2794.5090408@geo.uu.nl>
Message-ID: <Pine.LNX.4.64.0806191412460.25909@reclus.nhh.no>

On Thu, 19 Jun 2008, Paul Hiemstra wrote:

> Hi,
> You need to find out what the projection of the shapefile is, the 
> ogrinfo does not give this information for your file as you probably do 
> not have the .prj file. The R function spTransform needs the projection 
> info in a so called proj4string. The easiest way to define such a string 
> is through the epsg code, this code enables proj (the projection library 
> used in R) to find the parameter it needs. For example, the proj4string 
> for the Dutch national projection is:
>
> "+proj=sterea +lat_0=52.15616055555555 +lon_0=5.38763888888889 
> +k=0.9999079 +x_0=155000 +y_0=463000 +ellps=bessel +units=m 
> +towgs84=565.04,49.91,465.84,-0.409394387,0.35970519561,-1.868491,4.0772 
> +no_defs"
>
> using epsg codes:
>
> "+init=epsg:28992"
>
> The bottomline is to find the projection of your second shapefile as 
> this is the most likely candidate to cause the difference. A good place 
> to ask questions regarding projections is the proj4-mailing list 
> (http://lists.maptools.org/mailman/listinfo/proj).

Right. In addition, do some digging into the history of coordinate 
reference systems for your country of interest, for example:

http://www.asprs.org/resources/grids/

has France on January 2001. I think that you may be in Nouvelle 
Triangulation Fran?aise, which has a Paris meridian:

EPSG <- make_EPSG()
EPSG[grep("NTF", EPSG$note), 1:2]

But that is guesswork. For enthusiasts, once you have a guess, use 
spTransform to geographical coordinates (CRS("+longlat +datum=WGS84")), 
and do writeOGR(obj, "obj.kml", "obj", driver="KML") of (a subset of) your 
object and see where it lands in Google Earth.

Roger

>
> hth and cheers,
> Paul
>
> Julien Barnier wrote:
>> Hi,
>>
>> I'm sorry to post a rather off-topic question here, but as a new sp
>> user and total novice in coordinates and projections questions, I'm
>> facing a problem you may help me to solve. Please ignore this post if
>> it is too much noise.
>>
>> I've got two map files (a MapInfo file and an ESRI shapefile) from two
>> different sources but which represent objects from the same french
>> region (one represent the cities, the other rivers and water
>> surfaces). 
>>
>> The problem is that when imported into R and plotted together, they
>> doesn't appear in the same place.  They seem to have the same
>> ?longitude?, but the ?latitude? is different. If I plot them, the
>> first map ranges in the Y axis from 70,000 to 100,000 and the second
>> one from 2,060,000 to 2,140,000. The ranges along the x axis seem to
>> be the same, though.
>>
>> Here is the output of ogrinfo on the two files :
>>
>> ,----
>> | $ ogrinfo -so 69_iris.mid 69_iris
>> | Had to open data source read-only.
>> | INFO: Open of `69_iris.mid'
>> |       using driver `MapInfo File' successful.
>> | 
>> | Layer name: 69_iris
>> | Geometry: Unknown (any)
>> | Feature Count: 774
>> | Extent: (747910.000000, 2053380.000000) - (819740.000000,
>> | 2147622.300000)
>> | Layer SRS WKT:
>> | PROJCS[?unnamed?,
>> |     GEOGCS[?unnamed?,
>> |         DATUM[?MIF 9999,6,-168,-60,320,0,0,0,0,0?,
>> |             SPHEROID[?Clarke 1880?,6378249.145,293.465],
>> |             TOWGS84[-168,-60,320,-0,-0,-0,0]],
>> |         PRIMEM[?non-Greenwich?,0],
>> |         UNIT[?degree?,0.0174532925199433]],
>> |     PROJECTION[?Lambert_Conformal_Conic_2SP?],
>> |     PARAMETER[?standard_parallel_1?,45.90287723937],
>> |     PARAMETER[?standard_parallel_2?,47.69712276063],
>> |     PARAMETER[?latitude_of_origin?,46.8],
>> |     PARAMETER[?central_meridian?,2.337229104484],
>> |     PARAMETER[?false_easting?,600000],
>> |     PARAMETER[?false_northing?,2200000],
>> |     UNIT[?Meter?,1]]
>> | DepCom: String (5.0)
>> | Nom_Com: String (40.0)
>> | Iris: String (4.0)
>> | DComIris: String (9.0)
>> | Nom_Iris: String (43.0)
>> | Typ_Iris: String (1.0)
>> | Indic: String (1.0)
>> | Origine: String (1.0)
>> `----
>>
>> ,----
>> | $ ogrinfo -so Decoupage_Administratif/SURFDEAU.shp SURFDEAU
>> | INFO: Open of `Decoupage_Administratif/SURFDEAU.shp'
>> |       using driver `ESRI Shapefile' successful.
>> | 
>> | Layer name: SURFDEAU
>> | Geometry: Polygon
>> | Feature Count: 168
>> | Extent: (785619.190000, 68133.620000) - (818193.410000, 107443.340000)
>> | Layer SRS WKT:
>> | (unknown)
>> | NUMOBJ: String (11.0)
>> `----
>>
>> I've tried to play with some parameters in readShapePoly and
>> spTransform, but without success.
>>
>> Any help would be greatly appreciated.
>>
>> Thanks in advance,
>> 
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From p.hiemstra at geo.uu.nl  Thu Jun 19 15:23:51 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Thu, 19 Jun 2008 15:23:51 +0200
Subject: [R-sig-Geo] Load R sp vector layers in QGIS
In-Reply-To: <35781.142.104.193.193.1213860634.squirrel@wm3.uvic.ca>
References: <20080615160005.C600EE01451@lists.osgeo.org>
	<4859572A.4030602@gmail.com> <1213817300.7091.17.camel@vertical>
	<200806182218.26708.Ralf.Suhr@bauing.uni-weimar.de>
	<35781.142.104.193.193.1213860634.squirrel@wm3.uvic.ca>
Message-ID: <485A5DE7.50204@geo.uu.nl>

Hi Carson,

Is exporting the Spatial object to a .shp (or other vector format) and 
then reading the file in to QGIS not an easier way to get R spatial 
layers into QGIS. That also solves the problem of not being able to edit 
the features. If you edit in QGIS and save you can read the file back 
into R.

R is also capable of displaying GIS information quite nicely (spplot). I 
tried several programs under Linux to create map output (QGIS, udig,  
for journal articles and ended up using R. R certainly has a steeper 
learning curve, but the output from the version of QGIS I used (0.9.2) 
was not good enough for me.

So my question is, what is the big advantage of getting R data into QGIS 
in this way.

cheers,
Paul

cfarmer wrote:
> Hello lists,
>
> Apologies for cross posting, but I thought this might be of interest to
> all groups...
>
> Thanks to the excellent work of Martin Dobias on the QgsMemoryProvider, I
> have created a simple plugin which acts as an additional file type handler
> for R sp vector objects in QGIS.
>
> To use:
> 1) In R ( or manageR ;) ), create an sp vector object
> (SpatialPointsDataFrame, SpatialPolygonsDataFrame, SpatialLinesDataFrame).
> 2) Save the sp object to a .Rdata file
> 3) Enable the plugin in QGIS (the button should appear in the file toolbar
> along with 'add vector layer', 'add raster layer', etc..
> 4) Click 'loadRlayer' button, and browse to your .Rdata file
> 5) The plugin should do the rest, and voila! Your R spatial layer should
> be displayed on the QGIS map canvas.
>
> To get it:
> 1) It is available from: 'http://www.geog.uvic.ca/spar/carson/'
> or
> 2) Add 'http://www.geog.uvic.ca/spar/carson/cfarmerQgisRepo.xml' to your
> repositories list in QGIS
>
> Notes:
> 1) When possible, the spatial reference information is taken from the sp
> object
> 2) The name is also taken from the sp object, not the name of the .Rdata file
> 3) Your .Rdata file should only contain a single sp object
> 4) I haven't tested this on multipoint or multiline features...?
> 5) You should be able to do all the normal things that vector layers in
> QGIS can do (except for save edits).
> 6) Note that at this point, changes to the layer in QGIS will not be
> reflected in the initial sp object, thus, this plugin is primarily for
> visualizing your sp vector objects.
>
> Hope you enjoy!
>
> Carson
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul



From aloboaleu at gmail.com  Thu Jun 19 16:40:35 2008
From: aloboaleu at gmail.com (Agustin Lobo)
Date: Thu, 19 Jun 2008 16:40:35 +0200
Subject: [R-sig-Geo] Load R sp vector layers in QGIS
In-Reply-To: <485A5DE7.50204@geo.uu.nl>
References: <20080615160005.C600EE01451@lists.osgeo.org>	<4859572A.4030602@gmail.com>
	<1213817300.7091.17.camel@vertical>	<200806182218.26708.Ralf.Suhr@bauing.uni-weimar.de>	<35781.142.104.193.193.1213860634.squirrel@wm3.uvic.ca>
	<485A5DE7.50204@geo.uu.nl>
Message-ID: <485A6FE3.6090903@gmail.com>

R is capable of some very limited display of geographic
information and there are no interactive tools for
the geographic exploration of displayed geodata. If the current
set of tools is enough for you, congratulations. But,
for example, yesterday I got the data of a bunch of
points arranged as transects which contain data of
animal tracks in Bolivia. Once I imported the shp
as an sp object and displayed it, the first thing I wanted
to do was zooming in certain zones, which
I could not do in R. Also, i could not display these
data on top of other many geospatial data I have for the
area. These type of operations are better done in a GIS.
On the other hand, thanks to its flexibility,
R is very good at highlighting some features (for example,
get all consecutive points where the same sp had been observed
and which had been taken within a time lapse less than 2 min).
You can also do some of these operations in some GIS, but
doing it in R is faster and more powerful.
Thus being able of displaying R spatial objects in a real
GIS would be great, at least for some of us.

The current solution of saving to an rda file is an step forward
to the goal of displaying R spatial objects directly in a GIS
display with no intermediate steps for the user.
As soon as I test it, I'll be able to tell if this is better than
saving to shp, but I guess it is. Note than, at least in my case, I
would do this type of operation very often, so even an slight
improvement made by eliminating an intermediate step can be
of interest. An example: you can get a nice RGB composite
display in R, but it would take you several minutes (provided you
remember how to do it) and a waste of disk space, while it would take 
you few seconds in QGIS. This is not important if you have to do it
occasionally, but it is if you do it often.

Agus


Paul Hiemstra wrote:
> Hi Carson,
> 
> Is exporting the Spatial object to a .shp (or other vector format) and 
> then reading the file in to QGIS not an easier way to get R spatial 
> layers into QGIS. That also solves the problem of not being able to edit 
> the features. If you edit in QGIS and save you can read the file back 
> into R.
> 
> R is also capable of displaying GIS information quite nicely (spplot). I 
> tried several programs under Linux to create map output (QGIS, udig,  
> for journal articles and ended up using R. R certainly has a steeper 
> learning curve, but the output from the version of QGIS I used (0.9.2) 
> was not good enough for me.
> 
> So my question is, what is the big advantage of getting R data into QGIS 
> in this way.
> 
> cheers,
> Paul
> 
> cfarmer wrote:
>> Hello lists,
>>
>> Apologies for cross posting, but I thought this might be of interest to
>> all groups...
>>
>> Thanks to the excellent work of Martin Dobias on the QgsMemoryProvider, I
>> have created a simple plugin which acts as an additional file type 
>> handler
>> for R sp vector objects in QGIS.
>>
>> To use:
>> 1) In R ( or manageR ;) ), create an sp vector object
>> (SpatialPointsDataFrame, SpatialPolygonsDataFrame, 
>> SpatialLinesDataFrame).
>> 2) Save the sp object to a .Rdata file
>> 3) Enable the plugin in QGIS (the button should appear in the file 
>> toolbar
>> along with 'add vector layer', 'add raster layer', etc..
>> 4) Click 'loadRlayer' button, and browse to your .Rdata file
>> 5) The plugin should do the rest, and voila! Your R spatial layer should
>> be displayed on the QGIS map canvas.
>>
>> To get it:
>> 1) It is available from: 'http://www.geog.uvic.ca/spar/carson/'
>> or
>> 2) Add 'http://www.geog.uvic.ca/spar/carson/cfarmerQgisRepo.xml' to your
>> repositories list in QGIS
>>
>> Notes:
>> 1) When possible, the spatial reference information is taken from the sp
>> object
>> 2) The name is also taken from the sp object, not the name of the 
>> .Rdata file
>> 3) Your .Rdata file should only contain a single sp object
>> 4) I haven't tested this on multipoint or multiline features...?
>> 5) You should be able to do all the normal things that vector layers in
>> QGIS can do (except for save edits).
>> 6) Note that at this point, changes to the layer in QGIS will not be
>> reflected in the initial sp object, thus, this plugin is primarily for
>> visualizing your sp vector objects.
>>
>> Hope you enjoy!
>>
>> Carson
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>   
> 
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From cfarmer at uvic.ca  Thu Jun 19 20:28:50 2008
From: cfarmer at uvic.ca (cfarmer)
Date: Thu, 19 Jun 2008 11:28:50 -0700 (PDT)
Subject: [R-sig-Geo] Load R sp vector layers in QGIS
In-Reply-To: <485A49C4.5080000@gmail.com>
References: <20080615160005.C600EE01451@lists.osgeo.org>   
	<4859572A.4030602@gmail.com> <1213817300.7091.17.camel@vertical>   
	<200806182218.26708.Ralf.Suhr@bauing.uni-weimar.de>   
	<35781.142.104.193.193.1213860634.squirrel@wm3.uvic.ca>   
	<485A49C4.5080000@gmail.com>
Message-ID: <40096.142.104.193.193.1213900130.squirrel@wm3.uvic.ca>

> Carson,
>
> This is geting close to my dreams

Well I'm glad I could provide something so useful!

> when I try to load the plugin, I get:
> An error has occured while executing Python code:
> Traceback (most recent call last):
>   File "", line 1, in
>   File "/home/alobo/.qgis//python/plugins/loadRlayer/loadRlayer.py",
> line 58, in initGui
>    self.fileBar = self.iface.fileToolBar()
> AttributeError: fileToolBar
>

What I forgot to mention last night in my email is that this plugin will
only work with r8650. This unfortunately means that to use this plugin you
will have to a) build QGIS using latest svn, or b) wait for QGIS 0.11.0.

>
> (using QGIS 0.10 on ubuntu hardy from binaries, trying to build another
version from svn)
>

Perfect! Once you get this going, you should be able to load the plugin no
problem!

Cheers,

Carson


Carson Farmer
Spatial Pattern Analysis & Research Lab (SPAR)
Department of Geography, University of Victoria
Victoria, BC, V8W 3P5,Canada
www.geog.uvic.ca/spar/carson
cfarmer at uvic.ca



From cfarmer at uvic.ca  Thu Jun 19 20:44:27 2008
From: cfarmer at uvic.ca (cfarmer)
Date: Thu, 19 Jun 2008 11:44:27 -0700 (PDT)
Subject: [R-sig-Geo] Load R sp vector layers in QGIS
In-Reply-To: <485A5DE7.50204@geo.uu.nl>
References: <20080615160005.C600EE01451@lists.osgeo.org>   
	<4859572A.4030602@gmail.com> <1213817300.7091.17.camel@vertical>   
	<200806182218.26708.Ralf.Suhr@bauing.uni-weimar.de>   
	<35781.142.104.193.193.1213860634.squirrel@wm3.uvic.ca>   
	<485A5DE7.50204@geo.uu.nl>
Message-ID: <36269.142.104.193.193.1213901067.squirrel@wm3.uvic.ca>

> Hi Carson,
>
> Is exporting the Spatial object to a .shp (or other vector format) and
then reading the file in to QGIS not an easier way to get R spatial
layers into QGIS.

Hi Paul,

I have done this in an automated way already though manageR, but I felt
that this was not a fast or simple enough way of visualizing R results.

>That also solves the problem of not being able to edit
> the features. If you edit in QGIS and save you can read the file back
into R.

The idea here is that users can load the R layer, explore their results,
and if they like what they see, right click the layer and export to .shp,
if not, keep working in R until they get what they need.

> R is also capable of displaying GIS information quite nicely (spplot).

I agree, and I used R for lots of my output as well. However, it does not
have the exploratory power that a true GIS does.

> So my question is, what is the big advantage of getting R data into QGIS
in this way.

The advantage here I think is as Agustin Lobo has previously mentioned:
interaction with the map, and map layers. A GIS is certainly more than
just a map making tool, and QGIS is beginning to grow in terms of analysis
tools as well. For instance, they is now a fully functioning
'geoprocessing' plugin, several plugins for customized applications, and a
few more for simple analysis functions.

Cheers,

Carson



From jbarnier at ens-lsh.fr  Fri Jun 20 14:56:00 2008
From: jbarnier at ens-lsh.fr (Julien Barnier)
Date: Fri, 20 Jun 2008 14:56:00 +0200
Subject: [R-sig-Geo] [OT] Coordinates and pojection problems
References: <87hcbqc0aq.fsf@z.nozav.org> <485A2794.5090408@geo.uu.nl>
	<Pine.LNX.4.64.0806191412460.25909@reclus.nhh.no>
Message-ID: <871w2sb6zj.fsf@z.nozav.org>

Hi Roger and Paul,

Thanks to your help, I've managed to import the files and to transform
them into the same projection. In fact I had the .prj file associated
to the shapefile, but I didn't even know that it contains the
projection informations...

Thanks to readShape Ply and spTransform I've converted both into
geographical coordinates. And the kml export and GoogleEarth
visualization is a very useful possibility I didn't know.

So thanks a lot for your help !

-- 
Julien Barnier
Groupe de recherche sur la socialisation
ENS-LSH - Lyon, France



From mao.loecher at gmail.com  Fri Jun 20 15:37:33 2008
From: mao.loecher at gmail.com (Markus Loecher)
Date: Fri, 20 Jun 2008 09:37:33 -0400
Subject: [R-sig-Geo] kriging on street grid
Message-ID: <3827b1320806200637r35a35c19k2b1dfe026b4cf8b0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080620/78a7c97d/attachment.pl>

From ddepew at sciborg.uwaterloo.ca  Fri Jun 20 15:43:17 2008
From: ddepew at sciborg.uwaterloo.ca (Dave Depew)
Date: Fri, 20 Jun 2008 09:43:17 -0400
Subject: [R-sig-Geo] another kriging question
Message-ID: <485BB3F5.8070304@scimail.uwaterloo.ca>

Hi again,
I'm getting more confused regarding the "accepted" forms of detrending 
data prior to kriging. I've used a GAM (package mgcv) to detrend my 
target variable. The residuals from this 9th order polynomial are well 
behaved (normal distribution, only mild heteroskedasticity). I realize 
that unlike the nlme package, the GAM from mgcv does not account for the 
locations of the data, so the predicted data may not be statistically 
optimal, but it was unclear whether the nlme package could also fit such 
a trend to the data ( i suspected that it could, I'm obviously not 
entering the code correctly). Oddly enough, adding the trend back to the 
kriged residuals produced a similar map that using universal kriging 
did...I suspect that this is because the majority of the prediction area 
involves a portion of the data trend which could probably be modelled 
reasonably well as a linear trend....

I guess, I'm not sure if there is a "standard" as to measure 
against...As I also struggle with the concept of stationarity at times, 
I find it is easy to get quickly confused. Almost all of the variograms 
I produce from these data sets (either the raw data, or the residuals in 
the presence of a weak trend) are bounded (i.e reach a sill), although a 
few behave oddly at very large distances (well past the range of the 
variogram)...I've interpreted this as simply a major reduction in the 
numbers of point pairs that are available to compute  the semivariance, 
but my overall impression is that the data could be considered as second 
order or intrinsically stationary...

If anyone has any thoughts or advice, I'd appreciate hearing your opinions.

Thanks,

Dave



From regmi_pujan at hotmail.com  Fri Jun 20 18:12:52 2008
From: regmi_pujan at hotmail.com (PUJAN RAJ REGMI)
Date: Fri, 20 Jun 2008 16:12:52 +0000
Subject: [R-sig-Geo] Normality Test for Large sample
Message-ID: <BAY113-W12FCA9B20732F52AFB639884A50@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080620/dc5c75e9/attachment.pl>

From edzer.pebesma at uni-muenster.de  Fri Jun 20 21:02:38 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 20 Jun 2008 21:02:38 +0200
Subject: [R-sig-Geo] Normality Test for Large sample
In-Reply-To: <BAY113-W12FCA9B20732F52AFB639884A50@phx.gbl>
References: <BAY113-W12FCA9B20732F52AFB639884A50@phx.gbl>
Message-ID: <485BFECE.7070208@uni-muenster.de>

Dear Pujan,

I believe this is not really the most appropriate list to send your 
question to, as it has little to do with spatial data.

Briefly, with samples the size you have, the smallest deviation from 
_exact_ normality will show up as significant. The real question is what 
that means. Is it a problem that your data come from a distribution that 
is _almost_ normal?
--
Edzer

PUJAN RAJ REGMI wrote:
> Dear list,
> I am trying to perform normality test for my data set. my data set is quite large N>13000 with 4 valriables under study , so When I tried to do normality test for each variable using lillie.test of nortest package the p values is almost zero "2.16e-16". So for all variable the test reject the null hypothesis (p-value the same("2.16e-16").i.e. it doesn't comes from normal distribution which I believe is not true and even this can be seen in histogram plot that fwe variable's plot shows normal distribution. Now I doubted that my approach to test for normality might not be correct becasue I am dealing with large number of samples. So I request you to provide me insight on the other efficient ways in R.
> Thanking you
> Sincerely,
> Pujan
>
> _________________________________________________________________
> Earn cashback on your purchases with Live Search - the search that pays you back!
>
> arncashback
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From edzer.pebesma at uni-muenster.de  Fri Jun 20 21:12:28 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 20 Jun 2008 21:12:28 +0200
Subject: [R-sig-Geo] kriging on street grid
In-Reply-To: <3827b1320806200637r35a35c19k2b1dfe026b4cf8b0@mail.gmail.com>
References: <3827b1320806200637r35a35c19k2b1dfe026b4cf8b0@mail.gmail.com>
Message-ID: <485C011C.4030903@uni-muenster.de>

I don't know about road networks, but I know of at least four groups 
that have worked on kriging over river networks, and one or two that 
worked on coastal data using water distance instead of Euclidian 
distance. Googling "kriging river network" gave quite a few hits.
--
Edzer

Markus Loecher wrote:
> Dear geo experts,
> has anyone looked into kriging of spatial processes that do not live in a 2D
> continuum but instead are constrained to a network/graph (e.g. a street
> grid) ?
> Clearly, distances need to be redefined but more than that, the covariance
> matrix is a very different animal.
>
> Thanks!
>
> Markus
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From hi_ono2001 at ybb.ne.jp  Mon Jun 23 09:55:10 2008
From: hi_ono2001 at ybb.ne.jp (Hisaji ONO)
Date: Mon, 23 Jun 2008 16:55:10 +0900 (JST)
Subject: [R-sig-Geo] kriging on street grid
In-Reply-To: <3827b1320806200637r35a35c19k2b1dfe026b4cf8b0@mail.gmail.com>
Message-ID: <20080623075510.24933.qmail@web10704.mail.bbt.yahoo.co.jp>

Hello.

 Following papaer may be helpful.

 OKABE, A., SATOH, T. and SUGIHARA, K. "A KERNEL DENSITY
ESTIMATION METHOD FOR NETWORKS,
?ITS COMPUTATIONAL METHOD, AND A GIS-BASED TOOL",
Discussion Paper, No. 80, Center for Spatial Information
Science, Univ. of Tokyo, 
http://www.csis.u-tokyo.ac.jp/dp/89.pdf


 However, this SANET seems to support kriging.

 SANET will be available from
http://ua.t.u-tokyo.ac.jp/okabelab/atsu/sanet/sanet-index.html,
thoughI've nver used it.


Regards.


--- Markus Loecher <mao.loecher at gmail.com> wrote:

> Dear geo experts,
> has anyone looked into kriging of spatial processes
> that do not live in a 2D
> continuum but instead are constrained to a
> network/graph (e.g. a street
> grid) ?
> Clearly, distances need to be redefined but more
> than that, the covariance
> matrix is a very different animal.
> 
> Thanks!
> 
> Markus
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From p.hiemstra at geo.uu.nl  Mon Jun 23 14:58:42 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 23 Jun 2008 14:58:42 +0200
Subject: [R-sig-Geo] Function to smooth grids using n x n window moving
 average (low-pass filter)
Message-ID: <485F9E02.8050403@geo.uu.nl>

Dear list,

I recently implemented a smoothing algorithm that could be interesting 
for other people. It smooths a grid by calculating an average for a n x 
n window. The input is a SpatialGrid/PixelsDataframe. For a 3x3 window 
the algorithm creates 8 shifted matrices in addition to the original 
matrix (derived from the grid-object). Adding up these 9 matrices and 
dividing them by 9 gives the smoothed matrix.  The output is a 
SpatialGridDataFrame. Because the algorithm uses just a few simple 
matrix operations it is very fast and scalable to large grid-objects. 
Maybe the code could be added to the sp-package (Edzer or Roger?)?

This is the code, just three functions. I also provided a small but 
functioning example at the bottom:

shift_matrix = function(m, row, col) {
    nrow = dim(m)[1]
    ncol = dim(m)[2]
    if(row > 0) m = rbind(matrix(rep(NA,abs(row)*ncol), 
abs(row),ncol),m[1:(nrow-row),])
    if(row < 0) m = 
rbind(m[-(row-1):nrow,],matrix(rep(NA,abs(row)*ncol), abs(row),ncol))
    if(col > 0) m = cbind(matrix(rep(NA,abs(col)*nrow), nrow, 
abs(col)),m[,1:(ncol-col)])
    if(col < 0) m = 
cbind(m[,-(col-1):ncol],matrix(rep(NA,abs(col)*nrow), nrow, abs(col)))
    m
}

smooth_matrix = function(m, kernel_size = 3) {
    row_nums = rep(floor(kernel_size/2): -floor(kernel_size/2), each = 
kernel_size)
    col_nums = rep(floor(kernel_size/2): -floor(kernel_size/2), kernel_size)
    out = matrix(rep(0,dim(m)[1]*dim(m)[2]), dim(m))
    for(i in 1:length(row_nums)) {
        out = out + shift_matrix(m, row_nums[i], col_nums[i])
    }
    return(out / (kernel_size * kernel_size))
}

smooth_grid = function(grd, zcol, kernel_size = 3, add_to_name = 
"_smooth") {
    if(!fullgrid(grd)) fullgrid(grd) = TRUE
    grd[[paste(zcol,add_to_name, sep = "")]] = 
as.vector(smooth_matrix(as.matrix(grd[zcol]), kernel_size = kernel_size))
    grd
}

## Example script
library(gstat)
data(meuse)
coordinates(meuse) = ~x+y
data(meuse.grid)
gridded(meuse.grid) = ~x+y
meuse.grid$log.zinc = idw(log(zinc)~1, meuse, meuse.grid)$var1.pred
meuse.grid = smooth_grid(meuse.grid, "log.zinc", kernel_size = 3)
spplot(meuse.grid, c("log.zinc","log.zinc_smooth"))

cheers,
Paul

ps The system i run:
R version 2.7.0 (2008-04-22)
i486-pc-linux-gnu

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] gstat_0.9-45 sp_0.9-25

loaded via a namespace (and not attached):
[1] grid_2.7.0     lattice_0.17-6 tools_2.7.0

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul



From mao.loecher at gmail.com  Mon Jun 23 22:24:51 2008
From: mao.loecher at gmail.com (Markus Loecher)
Date: Mon, 23 Jun 2008 16:24:51 -0400
Subject: [R-sig-Geo] kriging on street grid
In-Reply-To: <20080623075510.24933.qmail@web10704.mail.bbt.yahoo.co.jp>
References: <3827b1320806200637r35a35c19k2b1dfe026b4cf8b0@mail.gmail.com>
	<20080623075510.24933.qmail@web10704.mail.bbt.yahoo.co.jp>
Message-ID: <3827b1320806231324s786895fcsb813aa8999be9bc9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080623/729096c0/attachment.pl>

From girodayh at unbc.ca  Tue Jun 24 02:19:37 2008
From: girodayh at unbc.ca (Honey Giroday)
Date: Tue, 24 Jun 2008 00:19:37 +0000
Subject: [R-sig-Geo] Coercing character to image
Message-ID: <BLU128-W48D5CE1B9D4F46DF0B1A18AA10@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080624/16b912ff/attachment.pl>

From T.Hengl at uva.nl  Tue Jun 24 04:03:17 2008
From: T.Hengl at uva.nl (Hengl, T.)
Date: Tue, 24 Jun 2008 04:03:17 +0200
Subject: [R-sig-Geo] Function to smooth grids using n x n window moving
	average (low-pass filter)
References: <485F9E02.8050403@geo.uu.nl>
Message-ID: <37382E8DCB905042969BA78541F6570624D4FE@kwek.ic.uva.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080624/45b2f16e/attachment.pl>

From Roger.Bivand at nhh.no  Tue Jun 24 11:40:42 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 24 Jun 2008 11:40:42 +0200 (CEST)
Subject: [R-sig-Geo] Coercing character to image
In-Reply-To: <BLU128-W48D5CE1B9D4F46DF0B1A18AA10@phx.gbl>
References: <BLU128-W48D5CE1B9D4F46DF0B1A18AA10@phx.gbl>
Message-ID: <Pine.LNX.4.64.0806241138320.2865@reclus.nhh.no>

On Tue, 24 Jun 2008, Honey Giroday wrote:

>
>
> Hi,
>
> I'm currently trying to use save() on a density plot (i.e. an image) 
> that takes a long time to generate (using density(x)).  I want to be 
> able to use the saved dataset as a covariate in ppm.  However, once my 
> image is saved and loaded back in it is a character object instead of an 
> image.  I tried using as.im to coerce the object to an image; however, I 
> get an error message.
>
> Does anyone have a method for converting a character object to an image 
> object?

No, because you have not provided a code example to show what you did 
(wrong). Please create an example using a data set included in spatstat, 
reproducing your problem. We cannot see over your shoulder. My guess is 
that your question is not the right question, because the problem arose 
earlier in the workflow.

Roger

>
> Sincerely,
>
>
>
>
>
>
> Honey-Marie de la Giroday
>
> _________________________________________________________________
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From louzao at cebc.cnrs.fr  Tue Jun 24 13:34:02 2008
From: louzao at cebc.cnrs.fr (LOUZAO)
Date: Tue, 24 Jun 2008 13:34:02 +0200
Subject: [R-sig-Geo] extracting oceanographic data
Message-ID: <4860DBAA.9070502@cebc.cnrs.fr>

Dear list,

I'm trying to extract different oceanographic data (chlorophyll, sea 
surface temperature, etc.) for doing habitat modelling. The input data 
are locations (lat, lon) of tracking data of marine top predators and I 
would like to extract oceanographic data from a given area around each 
specific location, from which compute  the median, maximum and minimum 
values of the corresponding data (sst, chl, etc.). For doing this,

1. I need to import the oceanographic data into R. Which format (ascii, 
hdf, netcdf,etc.) would you recommend? I have been working with ascii, 
importing files with import.asc().
2. For defining the area around each location, I could define a circle 
(radius of 1? in decimal degree) or a square (a total heigth of 1? in 
decimal degree) centered in each location.
In the grid package, the circleGrob() or the viewport() fucntions 
provide this approach. However, I have applied the circleGrob but I do 
not reach to obtain a circle around each location (when I plot it I only 
obtain the same configuration than when plotting the locations). I think 
that I'm missing something related with the units. In this case, x and y 
are longitud and latitud in decimal degress.

circle<-circleGrob(x=locs$Long, y=locs$Lat, r=2, default.units="native", 
name=NULL,
            gp=gpar(), vp=NULL)

I have found other two functions that I do not know if someone has used 
for doing the same.

- symbolsInPolys() in maptools

- spsample() in sp

3. The last step would be to overlay the oceanographic layer and the 
object of circles (or squares) to extract the median, maximum and 
minimum values of the corresponding data (sst, chl, etc.)

Has anybody worked on this problem? Could you please point to any useful 
documents? 

Thanks in advance,

Maite Louzao

-- 
**************************
Maite Louzao Arsuaga
Postdoctoral Researcher

Centre d'Etudes Biologiques de Chiz? - CNRS UPR1934 
79360 Villiers-en-Bois, France 
Tel: +33 (0)5.49.09.35.57
Fax: +33 (0)5.49.09.65.26 
http://www.cebc.cnrs.fr/
**************************




 ________



From mdsumner at utas.edu.au  Tue Jun 24 15:20:39 2008
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Tue, 24 Jun 2008 23:20:39 +1000
Subject: [R-sig-Geo] extracting oceanographic data
In-Reply-To: <4860DBAA.9070502@cebc.cnrs.fr>
References: <4860DBAA.9070502@cebc.cnrs.fr>
Message-ID: <4860F4A7.6090908@utas.edu.au>

Hello,

I've worked a lot on problems of this type - here's some quick thoughts, 
not really directly addressing your questions.

HDF and netCDF can be difficult - you need to compile rgdal from against 
FWTools, or from source to have those work with readGDAL. I would just 
use gdal_translate to convert data to GeoTIFF (installing FWTools is 
trivial). Those formats can offer further challenges, just in 
interpreting the structure and content, but it depends on the actual 
data you want to use.

A question to ask here is what is the service providing the data in the 
first place? Ideally you can read directly from the server, but more 
likely you have a local cache of files. (If you have these as netCDF/HDF 
it's probably best to extract what you need to GeoTIFF using 
gdal_translate. )  The kftools package provides a direct read for SST, 
but it's a bit complicated. I had success with reading directly from the 
service behind the NASA POET site, but that wasn't useful for many 
datasets. I haven't explored the variety of services for some time, 
apparently there is a NOAA service that covers most needs.

For getting a range of pixel values around each point I would use 
overlay() in sp package, and work on creating circle polygons around 
your locations.

You didn't mention the temporal aspect that you need when overlaying 
track data with time series of oceanographic data, but this can be very 
simple when using rgdal since all your time series layers can be stored 
in one SpatialGridDataFrame dataset as separate attributes (depending on 
the size) and you simply find the interval in which your locations fall 
as well as the pixel for each location. Determining a spatial range 
around these is more complicated but not greatly so. The power of 
general indexing in R, along with the spatial extensions provided in sp 
is very helpful here.

How are you determining an appropriate range to query around your track 
locations? The tripEstimation package is a suite of functions written 
for estimating position from raw archival tags or a remote service, and 
I mention that as the outputs there can be very flexible for 
spatial/temporal overlays when location precision is important (but may 
be overkill here, and it's not user friendly).

The trip package extends the foundation provided by sp for track data, 
so that also may be useful for dealing with sets of tracks.

I hope some of that is helpful - sorry I'm not addressing your questions 
specifically. If you post more detail about the actual datasets you are 
trying to deal with I may be able to help more.

Cheers, Mike.


 LOUZAO wrote:
> Dear list,
>
> I'm trying to extract different oceanographic data (chlorophyll, sea 
> surface temperature, etc.) for doing habitat modelling. The input data 
> are locations (lat, lon) of tracking data of marine top predators and 
> I would like to extract oceanographic data from a given area around 
> each specific location, from which compute  the median, maximum and 
> minimum values of the corresponding data (sst, chl, etc.). For doing 
> this,
>
> 1. I need to import the oceanographic data into R. Which format 
> (ascii, hdf, netcdf,etc.) would you recommend? I have been working 
> with ascii, importing files with import.asc().
> 2. For defining the area around each location, I could define a circle 
> (radius of 1? in decimal degree) or a square (a total heigth of 1? in 
> decimal degree) centered in each location.
> In the grid package, the circleGrob() or the viewport() fucntions 
> provide this approach. However, I have applied the circleGrob but I do 
> not reach to obtain a circle around each location (when I plot it I 
> only obtain the same configuration than when plotting the locations). 
> I think that I'm missing something related with the units. In this 
> case, x and y are longitud and latitud in decimal degress.
>
> circle<-circleGrob(x=locs$Long, y=locs$Lat, r=2, 
> default.units="native", name=NULL,
>            gp=gpar(), vp=NULL)
>
> I have found other two functions that I do not know if someone has 
> used for doing the same.
>
> - symbolsInPolys() in maptools
>
> - spsample() in sp
>
> 3. The last step would be to overlay the oceanographic layer and the 
> object of circles (or squares) to extract the median, maximum and 
> minimum values of the corresponding data (sst, chl, etc.)
>
> Has anybody worked on this problem? Could you please point to any 
> useful documents?
> Thanks in advance,
>
> Maite Louzao
>
> ------------------------------------------------------------------------
>
>
> No virus found in this incoming message.
> Checked by AVG. 
> Version: 8.0.100 / Virus Database: 270.4.1/1515 - Release Date: 6/23/2008 7:16 PM
>



From aloboaleu at gmail.com  Tue Jun 24 20:38:19 2008
From: aloboaleu at gmail.com (Agustin Lobo)
Date: Tue, 24 Jun 2008 20:38:19 +0200
Subject: [R-sig-Geo] Guide to plotting R spatial objects
Message-ID: <48613F1B.8080400@gmail.com>

Hi!

Is there a guide for plotting R spatial objects,
best dealing with all (at least several) of the
different spatial packages (sp, PBSmapping, maptools etc)?

Thanks

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From girodayh at unbc.ca  Tue Jun 24 22:44:25 2008
From: girodayh at unbc.ca (Honey Giroday)
Date: Tue, 24 Jun 2008 20:44:25 +0000
Subject: [R-sig-Geo] Coercing character to image
In-Reply-To: <Pine.LNX.4.64.0806241138320.2865@reclus.nhh.no>
References: <BLU128-W48D5CE1B9D4F46DF0B1A18AA10@phx.gbl>
	<Pine.LNX.4.64.0806241138320.2865@reclus.nhh.no>
Message-ID: <BLU128-W452D7381CD0731D2FA9C2E8AA10@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080624/5e86a414/attachment.pl>

From Roger.Bivand at nhh.no  Tue Jun 24 22:57:26 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 24 Jun 2008 22:57:26 +0200 (CEST)
Subject: [R-sig-Geo] Coercing character to image
In-Reply-To: <BLU128-W452D7381CD0731D2FA9C2E8AA10@phx.gbl>
References: <BLU128-W48D5CE1B9D4F46DF0B1A18AA10@phx.gbl>
	<Pine.LNX.4.64.0806241138320.2865@reclus.nhh.no>
	<BLU128-W452D7381CD0731D2FA9C2E8AA10@phx.gbl>
Message-ID: <Pine.LNX.4.64.0806242254310.2865@reclus.nhh.no>

On Tue, 24 Jun 2008, Honey Giroday wrote:

>
> Thank you for your response and assisting me with clarifying my question.  Here is a portion of the code I am using:
>
> xxx04 <- ppp(x=mpb04$Easting, y=mpb04$Northing, window=tpi1.win)
> dens2004<-density(xxx04)
> save(dens2004, file="dens2003.Rdata"
> dens2004.load<-load("dens2004.Rdata")

This is the problem - dens2004.load contains the *name* of the loaded 
object(s). Try:

save(dens2004, file="dens2004.Rdata")
ls()
rm(dens2004)
print(load("dens2004.Rdata"))
ls()

See ?load.

Roger


> dens2004.im<-as.im(dens2004.load, W=tpi1.win)
>
> fm <- ppm(xxx04, ~x + y + density, Poisson(), covariates=list(dens2004.load) #"Error in model.frame.default(formula=fmla, data=glmdata, subset=(.mpl.SUBSET == : invalid type(closure) for variable 'density')
>
> I hope this elucidates the problem further.  Any help you can provide would be wonderful.  Thank you.
>
> Sincerely,
>
>
>
>
>
> Honey-Marie de la Giroday
>
>> Date: Tue, 24 Jun 2008 11:40:42 +0200
>> From: Roger.Bivand at nhh.no
>> To: girodayh at unbc.ca
>> CC: r-sig-geo at stat.math.ethz.ch
>> Subject: Re: [R-sig-Geo] Coercing character to image
>>
>> On Tue, 24 Jun 2008, Honey Giroday wrote:
>>
>>>
>>>
>>> Hi,
>>>
>>> I'm currently trying to use save() on a density plot (i.e. an image)
>>> that takes a long time to generate (using density(x)).  I want to be
>>> able to use the saved dataset as a covariate in ppm.  However, once my
>>> image is saved and loaded back in it is a character object instead of an
>>> image.  I tried using as.im to coerce the object to an image; however, I
>>> get an error message.
>>>
>>> Does anyone have a method for converting a character object to an image
>>> object?
>>
>> No, because you have not provided a code example to show what you did
>> (wrong). Please create an example using a data set included in spatstat,
>> reproducing your problem. We cannot see over your shoulder. My guess is
>> that your question is not the right question, because the problem arose
>> earlier in the workflow.
>>
>> Roger
>>
>>>
>>> Sincerely,
>>>
>>>
>>>
>>>
>>>
>>>
>>> Honey-Marie de la Giroday
>>>
>>> _________________________________________________________________
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>
> _________________________________________________________________
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ajblist-geo at yahoo.de  Wed Jun 25 15:22:10 2008
From: ajblist-geo at yahoo.de (ajblist-geo at yahoo.de)
Date: Wed, 25 Jun 2008 06:22:10 -0700 (PDT)
Subject: [R-sig-Geo] Function to smooth grids using n x n window moving
	average (low-pass filter)
Message-ID: <807823.35603.qm@web52208.mail.re2.yahoo.com>

Hi,

FYI, the RSAGA package provides a function called 'focal.function', which can apply an R function operating on circular or quadratic moving windows to an entire grid. This function is currently very inefficient - but flexible.

Cheers
  Alex

--
Alexander Brenning
brenning -at- uwaterloo.ca - T +1-519-888-4567 ext 35783
Department of Geography and Environmental Management
University of Waterloo
200 University Ave. W - Waterloo, ON - Canada N2L 3G1
http://www.fes.uwaterloo.ca/geography/faculty/brenning/

----- Urspr?ngliche Mail ----
Von: "Hengl, T." <T.Hengl at uva.nl>
An: Paul Hiemstra <p.hiemstra at geo.uu.nl>; r-sig-geo at stat.math.ethz.ch
Gesendet: Montag, den 23. Juni 2008, 22:03:17 Uhr
Betreff: Re: [R-sig-Geo] Function to smooth grids using n x n window moving average (low-pass filter)


Hi Paul,

Thanks for your info and script.

A year ago, I also felt that much of image processing is really missing in R. At the moment, I am increasingly using now RSAGA, which is efficient, fast and easy (+SAGA is still developing; +it works both on Linux and Windows OS). Here are few examples to run e.g. edge filter (the only extra step is to export the sp grid layers to SAGA GIS format, but we are working on improving that):

> library(RSAGA)
> rsaga.env(path="C:/Program Files/saga_vc")  # Windows OS
> # export the map to SAGA format:
> rsaga.esri.to.sgrd(in.grids="DEM.asc", out.sgrds="DEM.sgrd"), in.path="D:/MAPS")
> rsaga.filter.simple(in.grid="DEM.sgrd", out.grid="edge_filter.sgrd", mode="circle", method="edge"), radius=1000)
> # you can also run the filter using the generic module runner:
> rsaga.get.modules("grid_filter")
$grid_filter
  code                       name interactive
1    0              Simple Filter       FALSE
2    1            Gaussian Filter       FALSE
3    2           Laplacian Filter       FALSE
4    3 Multi Direction Lee Filter       FALSE
5    4  User Defined Filter (3x3)       FALSE
6    5              Filter Clumps       FALSE  
> rsaga.get.usage("grid_filter", 0)
> rsaga.geoprocessor(lib="grid_filter", module=0, param=list(INPUT="DEM.sgrd",RESULT="edge_filter.sgrd",METHOD=2,RADIUS=1000))
> # import the map to R:
> rsaga.sgrd.to.esri(in.sgrds="edge_filter.sgrd", out.grids="edge_filter.asc", out.path="D:/MAPS", prec=3)
> library(rgdal)
> edgef = readGDAL("edge_filter.asc")



see also: https://stat.ethz.ch/pipermail/r-sig-geo/2008-January/003078.html 

Tom Hengl
http://spatial-analyst.net




-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Paul Hiemstra
Sent: Mon 6/23/2008 2:58 PM
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] Function to smooth grids using n x n window moving average (low-pass filter)

Dear list,

I recently implemented a smoothing algorithm that could be interesting 
for other people. It smooths a grid by calculating an average for a n x 
n window. The input is a SpatialGrid/PixelsDataframe. For a 3x3 window 
the algorithm creates 8 shifted matrices in addition to the original 
matrix (derived from the grid-object). Adding up these 9 matrices and 
dividing them by 9 gives the smoothed matrix.  The output is a 
SpatialGridDataFrame. Because the algorithm uses just a few simple 
matrix operations it is very fast and scalable to large grid-objects. 
Maybe the code could be added to the sp-package (Edzer or Roger?)?

This is the code, just three functions. I also provided a small but 
functioning example at the bottom:

shift_matrix = function(m, row, col) {
    nrow = dim(m)[1]
    ncol = dim(m)[2]
    if(row > 0) m = rbind(matrix(rep(NA,abs(row)*ncol), 
abs(row),ncol),m[1:(nrow-row),])
    if(row < 0) m = 
rbind(m[-(row-1):nrow,],matrix(rep(NA,abs(row)*ncol), abs(row),ncol))
    if(col > 0) m = cbind(matrix(rep(NA,abs(col)*nrow), nrow, 
abs(col)),m[,1:(ncol-col)])
    if(col < 0) m = 
cbind(m[,-(col-1):ncol],matrix(rep(NA,abs(col)*nrow), nrow, abs(col)))
    m
}

smooth_matrix = function(m, kernel_size = 3) {
    row_nums = rep(floor(kernel_size/2): -floor(kernel_size/2), each = 
kernel_size)
    col_nums = rep(floor(kernel_size/2): -floor(kernel_size/2), kernel_size)
    out = matrix(rep(0,dim(m)[1]*dim(m)[2]), dim(m))
    for(i in 1:length(row_nums)) {
        out = out + shift_matrix(m, row_nums[i], col_nums[i])
    }
    return(out / (kernel_size * kernel_size))
}

smooth_grid = function(grd, zcol, kernel_size = 3, add_to_name = 
"_smooth") {
    if(!fullgrid(grd)) fullgrid(grd) = TRUE
    grd[[paste(zcol,add_to_name, sep = "")]] = 
as.vector(smooth_matrix(as.matrix(grd[zcol]), kernel_size = kernel_size))
    grd
}

## Example script
library(gstat)
data(meuse)
coordinates(meuse) = ~x+y
data(meuse.grid)
gridded(meuse.grid) = ~x+y
meuse.grid$log.zinc = idw(log(zinc)~1, meuse, meuse.grid)$var1.pred
meuse.grid = smooth_grid(meuse.grid, "log.zinc", kernel_size = 3)
spplot(meuse.grid, c("log.zinc","log.zinc_smooth"))

cheers,
Paul

ps The system i run:
R version 2.7.0 (2008-04-22)
i486-pc-linux-gnu

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] gstat_0.9-45 sp_0.9-25

loaded via a namespace (and not attached):
[1] grid_2.7.0     lattice_0.17-6 tools_2.7.0

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:     +31302535773
Fax:    +31302531145
http://intamap.geo.uu.nl/~paul

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


    [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



      _________________________________________________
://de.overview.mail.yahoo.com



From debarchana.ghosh at gmail.com  Wed Jun 25 18:44:22 2008
From: debarchana.ghosh at gmail.com (Debarchana Ghosh)
Date: Wed, 25 Jun 2008 11:44:22 -0500
Subject: [R-sig-Geo] What is the unit of fixed bandwidth calculated from
	gwr.sel?
Message-ID: <d1b8ff630806250944j6eb6f2fema6e1f560f775d5d5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080625/550abb25/attachment.pl>

From ilonan at interchange.ubc.ca  Wed Jun 25 18:56:34 2008
From: ilonan at interchange.ubc.ca (Ilona Naujokaitis-Lewis)
Date: Wed, 25 Jun 2008 09:56:34 -0700
Subject: [R-sig-Geo] SGDF loop processing time
Message-ID: <000c01c8d6e4$6d752360$4001a8c0@forestry.ubc.ca>

   
Dear List-serve, 

I have written a loop that creates a Spatial Grid Dataframe from 2 other
SGDFs. I am interested in finding out if there is a way to decrease the
processing time of the entire loop. I am aware that loops in R are not the
most efficient way to go, but based on my knowledge, I am not sure how to
get around this. To avoid problems with memory allocation I have added gc()
command throughout the loop. 

The system.time() results for the loop (see code below) with a small (16x12)
grid is:
user  system elapsed 
17.08    0.02   17.22

The problem is when I work with larger grids (i.e. greater than dimensions:
900x1200). The processing time is in the order of 24 hours. 

I have checked threads for help on both decreasing the memory size, and
writing efficient code. Any suggestions on how I might decrease the
processing time, as this is the biggest concern right now (both using and
not using R, but the former preferred), would be greatly appreciated.

Here is the code with a brief description of the objects.


Objects: 
prePatchmap: SGDF, binary (0,1)
mean_HS: mean habitat suitability value of original habitat suitability map
sd_HS: standard deviation of original habitat suitability map
new_HSthreshold: new habitat suitability threshold
HSthreshold: original habitat suitability threshold
HSmap: SGDF of original habitat suitability values
  
for (i in 1:length(prePatchmap$patch))
    {
    if (prePatchmap$patch[i]==1)
       {  
       prePatchmap$NPHS[i]<-round(rnorm(1, mean_HS, sd_HS),digits=3)
       gc()
          {
          if (prePatchmap$NPHS[i]<new_HSthreshold)
            {
            prePatchmap$NPHS[i]<-new_HSthreshold
            gc()
            }
          } 
       } else
       {
       if (HSmap$HSvalue[i]<HSthreshold)
            { 
            prePatchmap$NPHS[i]<-HSmap$HSvalue[i]
            }
       gc()
       }
     }


Cheers, 

Ilona Naujokaitis-Lewis


Ilona Naujokaitis-Lewis
Centre for Applied Conservation Research
Forest Sciences Department
University of British Columbia
3041-2424 Main Mall
Vancouver, BC V6T 1Z4
 
phone: 604 822.4382
email: ilonan at interchange.ubc.ca



From Roger.Bivand at nhh.no  Wed Jun 25 19:01:28 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 25 Jun 2008 19:01:28 +0200 (CEST)
Subject: [R-sig-Geo] What is the unit of fixed bandwidth calculated from
 gwr.sel?
In-Reply-To: <d1b8ff630806250944j6eb6f2fema6e1f560f775d5d5@mail.gmail.com>
References: <d1b8ff630806250944j6eb6f2fema6e1f560f775d5d5@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0806251900330.6017@reclus.nhh.no>

On Wed, 25 Jun 2008, Debarchana Ghosh wrote:

> Hi,
>
> OS: Windows with 4 GB Ram. R-2.70
>
> I calculated bandwidth using the gwr.sel function from the spgwr package
>
> dat.bw.cv<-gwr.sel(yimp00~ english + slope30 + mac95d + mdinc_t + musa00 +
> popden_t + dissewer + dismcd
>                    + diswater + ag04 + c1dishwy + c1dipark + tccost1 +
> soil1 + soil2, data=dat,
>                    coords = cbind(dat$longx, dat$laty), longlat=TRUE,
> verbose = FALSE)
>
> My x,y matrix is in latlong coordinates and hence the option is longlat =
> TRUE.  As per the manual, if longlat is TRUE, the distances are used on an
> ellipse with WGS84 parameters. The output is:
> dat.bw.cv
> 69.79589
>
> My question is what is the unit of the fixed bandwidth here?

Kilometers - see ?spDistsN1.

>
> Thanks,
> Debs.
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Wed Jun 25 19:17:51 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 25 Jun 2008 19:17:51 +0200 (CEST)
Subject: [R-sig-Geo] SGDF loop processing time
In-Reply-To: <000c01c8d6e4$6d752360$4001a8c0@forestry.ubc.ca>
References: <000c01c8d6e4$6d752360$4001a8c0@forestry.ubc.ca>
Message-ID: <Pine.LNX.4.64.0806251912510.6017@reclus.nhh.no>

On Wed, 25 Jun 2008, Ilona Naujokaitis-Lewis wrote:

>
>
> Dear List-serve,
>
> I have written a loop that creates a Spatial Grid Dataframe from 2 other
> SGDFs. I am interested in finding out if there is a way to decrease the
> processing time of the entire loop. I am aware that loops in R are not the
> most efficient way to go, but based on my knowledge, I am not sure how to
> get around this. To avoid problems with memory allocation I have added gc()
> command throughout the loop.
>
> The system.time() results for the loop (see code below) with a small (16x12)
> grid is:
> user  system elapsed
> 17.08    0.02   17.22
>
> The problem is when I work with larger grids (i.e. greater than dimensions:
> 900x1200). The processing time is in the order of 24 hours.
>
> I have checked threads for help on both decreasing the memory size, and
> writing efficient code. Any suggestions on how I might decrease the
> processing time, as this is the biggest concern right now (both using and
> not using R, but the former preferred), would be greatly appreciated.
>
> Here is the code with a brief description of the objects.
>
>
> Objects:
> prePatchmap: SGDF, binary (0,1)
> mean_HS: mean habitat suitability value of original habitat suitability map
> sd_HS: standard deviation of original habitat suitability map
> new_HSthreshold: new habitat suitability threshold
> HSthreshold: original habitat suitability threshold
> HSmap: SGDF of original habitat suitability values

Could you provide an online example - save() the objects you need here and 
post the RData file? This does look vectorisable, at least in two chunks.

Roger

>
> for (i in 1:length(prePatchmap$patch))
>    {
>    if (prePatchmap$patch[i]==1)
>       {
>       prePatchmap$NPHS[i]<-round(rnorm(1, mean_HS, sd_HS),digits=3)
>       gc()
>          {
>          if (prePatchmap$NPHS[i]<new_HSthreshold)
>            {
>            prePatchmap$NPHS[i]<-new_HSthreshold
>            gc()
>            }
>          }
>       } else
>       {
>       if (HSmap$HSvalue[i]<HSthreshold)
>            {
>            prePatchmap$NPHS[i]<-HSmap$HSvalue[i]
>            }
>       gc()
>       }
>     }
>
>
> Cheers,
>
> Ilona Naujokaitis-Lewis
>
>
> Ilona Naujokaitis-Lewis
> Centre for Applied Conservation Research
> Forest Sciences Department
> University of British Columbia
> 3041-2424 Main Mall
> Vancouver, BC V6T 1Z4
>
> phone: 604 822.4382
> email: ilonan at interchange.ubc.ca
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ilonan at interchange.ubc.ca  Wed Jun 25 21:59:06 2008
From: ilonan at interchange.ubc.ca (Ilona Naujokaitis-Lewis)
Date: Wed, 25 Jun 2008 12:59:06 -0700
Subject: [R-sig-Geo] SGDF loop processing time
In-Reply-To: <Pine.LNX.4.64.0806251912510.6017@reclus.nhh.no>
References: <000c01c8d6e4$6d752360$4001a8c0@forestry.ubc.ca>
	<Pine.LNX.4.64.0806251912510.6017@reclus.nhh.no>
Message-ID: <001b01c8d6fd$edaa73a0$4001a8c0@forestry.ubc.ca>

Dear Roger, and List-Serve, 

I am posting here a .RData file(IlonaQuesRgeo.RData) to help with my
previous query (see original email below) as per Roger's request. Please let
me know if the attachment does not work. 

Cheers, 
Ilona



Ilona Naujokaitis-Lewis
Centre for Applied Conservation Research
Forest Sciences Department
University of British Columbia
3041-2424 Main Mall
Vancouver, BC V6T 1Z4
 
phone: 604 822.4382
email: ilonan at interchange.ubc.ca

-----Original Message-----
From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Sent: Wednesday, June 25, 2008 10:18 AM
To: Ilona Naujokaitis-Lewis
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] SGDF loop processing time

On Wed, 25 Jun 2008, Ilona Naujokaitis-Lewis wrote:

>
>
> Dear List-serve,
>
> I have written a loop that creates a Spatial Grid Dataframe from 2 other
> SGDFs. I am interested in finding out if there is a way to decrease the
> processing time of the entire loop. I am aware that loops in R are not the
> most efficient way to go, but based on my knowledge, I am not sure how to
> get around this. To avoid problems with memory allocation I have added
gc()
> command throughout the loop.
>
> The system.time() results for the loop (see code below) with a small
(16x12)
> grid is:
> user  system elapsed
> 17.08    0.02   17.22
>
> The problem is when I work with larger grids (i.e. greater than
dimensions:
> 900x1200). The processing time is in the order of 24 hours.
>
> I have checked threads for help on both decreasing the memory size, and
> writing efficient code. Any suggestions on how I might decrease the
> processing time, as this is the biggest concern right now (both using and
> not using R, but the former preferred), would be greatly appreciated.
>
> Here is the code with a brief description of the objects.
>
>
> Objects:
> prePatchmap: SGDF, binary (0,1)
> mean_HS: mean habitat suitability value of original habitat suitability
map
> sd_HS: standard deviation of original habitat suitability map
> new_HSthreshold: new habitat suitability threshold
> HSthreshold: original habitat suitability threshold
> HSmap: SGDF of original habitat suitability values

Could you provide an online example - save() the objects you need here and 
post the RData file? This does look vectorisable, at least in two chunks.

Roger

>
> for (i in 1:length(prePatchmap$patch))
>    {
>    if (prePatchmap$patch[i]==1)
>       {
>       prePatchmap$NPHS[i]<-round(rnorm(1, mean_HS, sd_HS),digits=3)
>       gc()
>          {
>          if (prePatchmap$NPHS[i]<new_HSthreshold)
>            {
>            prePatchmap$NPHS[i]<-new_HSthreshold
>            gc()
>            }
>          }
>       } else
>       {
>       if (HSmap$HSvalue[i]<HSthreshold)
>            {
>            prePatchmap$NPHS[i]<-HSmap$HSvalue[i]
>            }
>       gc()
>       }
>     }
>
>
> Cheers,
>
> Ilona Naujokaitis-Lewis
>
>
> Ilona Naujokaitis-Lewis
> Centre for Applied Conservation Research
> Forest Sciences Department
> University of British Columbia
> 3041-2424 Main Mall
> Vancouver, BC V6T 1Z4
>
> phone: 604 822.4382
> email: ilonan at interchange.ubc.ca
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

-------------- next part --------------
A non-text attachment was scrubbed...
Name: IlonaQuesRgeo.RData
Type: application/octet-stream
Size: 4983 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080625/a5d172fb/attachment.obj>

From Roger.Bivand at nhh.no  Wed Jun 25 22:51:56 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 25 Jun 2008 22:51:56 +0200 (CEST)
Subject: [R-sig-Geo] SGDF loop processing time
In-Reply-To: <001b01c8d6fd$edaa73a0$4001a8c0@forestry.ubc.ca>
References: <000c01c8d6e4$6d752360$4001a8c0@forestry.ubc.ca>
	<Pine.LNX.4.64.0806251912510.6017@reclus.nhh.no>
	<001b01c8d6fd$edaa73a0$4001a8c0@forestry.ubc.ca>
Message-ID: <Pine.LNX.4.64.0806252233480.6017@reclus.nhh.no>

On Wed, 25 Jun 2008, Ilona Naujokaitis-Lewis wrote:

> Dear Roger, and List-Serve,
>
> I am posting here a .RData file(IlonaQuesRgeo.RData) to help with my
> previous query (see original email below) as per Roger's request. Please let
> me know if the attachment does not work.

Hi,

It reached me, not sure about the list - the posting guide on R-help sets 
out the attachments policy.

library(sp)
load("IlonaQuesRgeo.RData")

Patchmap$HSvalue <- HSmap$HSvalue
Patchmap_orig <- Patchmap
fullgrid(Patchmap) <- FALSE
gridded(Patchmap) <- FALSE
# drop back to points to split on ID

Patchmap0 <- Patchmap[Patchmap$ID==0,]
Patchmap1 <- Patchmap[Patchmap$ID==1,]
# split subsets

Patchmap0$NPHS <- ifelse(Patchmap0$HSvalue < HSthreshold,
   Patchmap0$HSvalue, NA)
# vectorised ID==0 (is the else value correct?)

Patchmap1$NPHS <- round(rnorm(length(Patchmap1$ID), mean_HS,
   sd_HS),digits=3)
Patchmap1$NPHS <- ifelse(Patchmap1$NPHS < new_HSthreshold,
   Patchmap1$HSvalue, Patchmap1$NPHS)
# vectorised ID==1 (is the else value correct?)

Patchmap_res <- rbind(Patchmap0, Patchmap1)
gridded(Patchmap_res) <- TRUE
fullgrid(Patchmap_res) <- TRUE
# put back together, re-sorting to get back in place

all.equal(Patchmap_res$ID, Patchmap_orig$ID)
# sanity check on IDs

Patchmap_orig$NPHS <- Patchmap_res$NPHS
# assign back if need be and display image
image(Patchmap_orig, "NPHS")

There must be better ways, the workflow is a little contorted, but it may 
be worth trying. Maybe a set.seed() to anchor the rnorm()?

Hope this helps,

Roger

>
> Cheers,
> Ilona
>
>
>
> Ilona Naujokaitis-Lewis
> Centre for Applied Conservation Research
> Forest Sciences Department
> University of British Columbia
> 3041-2424 Main Mall
> Vancouver, BC V6T 1Z4
>
> phone: 604 822.4382
> email: ilonan at interchange.ubc.ca
>
> -----Original Message-----
> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Sent: Wednesday, June 25, 2008 10:18 AM
> To: Ilona Naujokaitis-Lewis
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] SGDF loop processing time
>
> On Wed, 25 Jun 2008, Ilona Naujokaitis-Lewis wrote:
>
>>
>>
>> Dear List-serve,
>>
>> I have written a loop that creates a Spatial Grid Dataframe from 2 other
>> SGDFs. I am interested in finding out if there is a way to decrease the
>> processing time of the entire loop. I am aware that loops in R are not the
>> most efficient way to go, but based on my knowledge, I am not sure how to
>> get around this. To avoid problems with memory allocation I have added
> gc()
>> command throughout the loop.
>>
>> The system.time() results for the loop (see code below) with a small
> (16x12)
>> grid is:
>> user  system elapsed
>> 17.08    0.02   17.22
>>
>> The problem is when I work with larger grids (i.e. greater than
> dimensions:
>> 900x1200). The processing time is in the order of 24 hours.
>>
>> I have checked threads for help on both decreasing the memory size, and
>> writing efficient code. Any suggestions on how I might decrease the
>> processing time, as this is the biggest concern right now (both using and
>> not using R, but the former preferred), would be greatly appreciated.
>>
>> Here is the code with a brief description of the objects.
>>
>>
>> Objects:
>> prePatchmap: SGDF, binary (0,1)
>> mean_HS: mean habitat suitability value of original habitat suitability
> map
>> sd_HS: standard deviation of original habitat suitability map
>> new_HSthreshold: new habitat suitability threshold
>> HSthreshold: original habitat suitability threshold
>> HSmap: SGDF of original habitat suitability values
>
> Could you provide an online example - save() the objects you need here and
> post the RData file? This does look vectorisable, at least in two chunks.
>
> Roger
>
>>
>> for (i in 1:length(prePatchmap$patch))
>>    {
>>    if (prePatchmap$patch[i]==1)
>>       {
>>       prePatchmap$NPHS[i]<-round(rnorm(1, mean_HS, sd_HS),digits=3)
>>       gc()
>>          {
>>          if (prePatchmap$NPHS[i]<new_HSthreshold)
>>            {
>>            prePatchmap$NPHS[i]<-new_HSthreshold
>>            gc()
>>            }
>>          }
>>       } else
>>       {
>>       if (HSmap$HSvalue[i]<HSthreshold)
>>            {
>>            prePatchmap$NPHS[i]<-HSmap$HSvalue[i]
>>            }
>>       gc()
>>       }
>>     }
>>
>>
>> Cheers,
>>
>> Ilona Naujokaitis-Lewis
>>
>>
>> Ilona Naujokaitis-Lewis
>> Centre for Applied Conservation Research
>> Forest Sciences Department
>> University of British Columbia
>> 3041-2424 Main Mall
>> Vancouver, BC V6T 1Z4
>>
>> phone: 604 822.4382
>> email: ilonan at interchange.ubc.ca
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From adrian at maths.uwa.edu.au  Thu Jun 26 04:25:15 2008
From: adrian at maths.uwa.edu.au (adrian at maths.uwa.edu.au)
Date: Thu, 26 Jun 2008 10:25:15 +0800 (WST)
Subject: [R-sig-Geo] Coercing character to image
In-Reply-To: <mailman.11.1214388002.9851.r-sig-geo@stat.math.ethz.ch>
References: <mailman.11.1214388002.9851.r-sig-geo@stat.math.ethz.ch>
Message-ID: <60212.60.230.217.17.1214447115.squirrel@60.230.217.17>


Honey Giroday <girodayh at unbc.ca> writes:

> xxx04 <- ppp(x=mpb04$Easting, y=mpb04$Northing, window=tpi1.win)
> dens2004<-density(xxx04)
> save(dens2004, file="dens2003.Rdata")
> dens2004.load<-load("dens2004.Rdata")
> dens2004.im<-as.im(dens2004.load, W=tpi1.win)
>
> fm <- ppm(xxx04, ~x + y + density, Poisson(),
> covariates=list(dens2004.load)

Two problems here.

First, a problem with the use of R. The 'load' command causes a dataset to
be loaded, but it returns only the NAME of the dataset that was loaded. So

> dens2004.load<-load("dens2004.Rdata")

just assigns dens2004.load to have the value 'dens2004'.
Just replace this line by

    load("dens2004.Rdata")

Second, a problem with using the package 'spatstat'.

> fm <- ppm(xxx04, ~x + y + density, Poisson(),
                covariates=list(dens2004.load))

For the model-fitting function 'ppm', the argument 'covariates' should be
a NAMED list, with names that correspond to variables in the model
formula. Your model formula includes the variable name 'density', so the
appropriate command is

fm <- ppm(xxx04, ~x + y + density, Poisson(),
                covariates=list(density=dens2004))

where 'dens2004' is your pixel image.

See the workshop notes available at www.spatstat.org for further examples.

Adrian Baddeley



From regmi_pujan at hotmail.com  Thu Jun 26 15:40:18 2008
From: regmi_pujan at hotmail.com (PUJAN RAJ REGMI)
Date: Thu, 26 Jun 2008 13:40:18 +0000
Subject: [R-sig-Geo] Correlogram
Message-ID: <BAY113-W127F447DDE891C482D95D84A30@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080626/6a6bc92c/attachment.pl>

From Giovanna.Jonalasinio at uniroma1.it  Thu Jun 26 16:01:59 2008
From: Giovanna.Jonalasinio at uniroma1.it (Giovanna.Jonalasinio at uniroma1.it)
Date: Thu, 26 Jun 2008 16:01:59 +0200
Subject: [R-sig-Geo] =?iso-8859-1?q?Giovanna_Jonalasinio_=E8_fuori_ufficio?=
	=?iso-8859-1?q?=2C_I=27m_away?=
Message-ID: <OF9B679F80.1B9490FA-ONC1257474.004D1624-C1257474.004D1624@Uniroma1.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080626/574bd33a/attachment.pl>

From mdsumner at utas.edu.au  Thu Jun 26 17:13:46 2008
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Fri, 27 Jun 2008 01:13:46 +1000
Subject: [R-sig-Geo] mkLookup
In-Reply-To: <4863A301.1040808@cebc.cnrs.fr>
References: <4863A301.1040808@cebc.cnrs.fr>
Message-ID: <4863B22A.9070600@utas.edu.au>

How about this?

library(tripEstimation)
img <- list(x = 1:nrow(volcano), y = 1:ncol(volcano), z = volcano > 130 
& volcano < 155)
pts <- cbind(rnorm(100, 50, 10), rnorm(100, 30, 8))
image(img)
points(pts, cex = 0.5)

lookup <- mkLookup(img)
ok <- lookup(pts)
text(pts, lab = substr(as.character(ok), 1, 1))

This is a simple, one time-step lookup function - you can pack these 
binary masks (using "bits<-") compactly using integer arrays so you can 
store long time series of masks, and this lookup function will extract 
them as needed with bits() with the by.segment argument.

(None of this is terribly user friendly or easy to explain quickly I'm 
afraid, as it's applied to fairly specific location estimation routines 
that few people use).

I'll try to address some of your other questions, but I'd suggest 
keeping this conversation in R-sig-geo as many others here have more 
experience to offer.

Cheers, Mike.


LOUZAO wrote:
> Hello again Mike,
>
> Could you send me a code example of the following function?
>
> mkLookup {tripEstimation}
>
> Thanks
> matie louzao
>
> ------------------------------------------------------------------------
>
>
> No virus found in this incoming message.
> Checked by AVG. 
> Version: 8.0.101 / Virus Database: 270.4.1/1519 - Release Date: 6/25/2008 4:13 PM
>



From milton.ruser at gmail.com  Thu Jun 26 17:15:20 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Thu, 26 Jun 2008 12:15:20 -0300
Subject: [R-sig-Geo] Correlogram
In-Reply-To: <BAY113-W127F447DDE891C482D95D84A30@phx.gbl>
References: <BAY113-W127F447DDE891C482D95D84A30@phx.gbl>
Message-ID: <3aaf1a030806260815j1a028f8ufc3fedda9d72ce28@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080626/a23c0c55/attachment.pl>

From mdsumner at utas.edu.au  Thu Jun 26 17:21:34 2008
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Fri, 27 Jun 2008 01:21:34 +1000
Subject: [R-sig-Geo] extracting oceanographic data
In-Reply-To: <48639A3A.2090101@cebc.cnrs.fr>
References: <4860DBAA.9070502@cebc.cnrs.fr> <4860F4A7.6090908@utas.edu.au>
	<48639A3A.2090101@cebc.cnrs.fr>
Message-ID: <4863B3FE.2030507@utas.edu.au>

LOUZAO wrote:
> Hello Mike,
>
> Thank you for your answer but I have some questions for you:
>>
>> HDF and netCDF can be difficult - you need to compile rgdal from 
>> against FWTools
> Do you mean installing the FWTools software opening the HDF or netCDF 
> files and using later rgdal from R? Could you give me an example, please?

Yes, sorry I mean using readGDAL to read HDF/netCDF directly can be 
complicated since the default binary build won't have those drivers.  I 
would use gdal_translate to convert them to GeoTIFF first. GeoTIFF is 
easily the best raster format overall, but it depends on your needs.

Try this at the command line once FWTools is installed:

gdal_translate file.hdf out.tif

Then in R:

d <- readGDAL("out.tif")  ## with appropriate working directory

It all depends on exactly which files you mean, as it's likely these 
files have subdatasets - you can interrogate these names using gdalinfo, 
e.g.

gdalinfo file.hdf

It's well worth becoming familiar with FWTools and the GDAL command line 
utilities, and also the classes and methods in the sp package. rgdal 
package uses these classes and methods with the underlying GDAL 
framework for file I/O and projections, amongst other things.

That mkLookup function expects an xyz image list (see ?image ), and you 
can convert the results of a readGDAL call to that with 
as.image.SpatialGridDataFrame in the sp package.

I hope some of that helps, I can't spend time on the rest right now.

Cheers, Mike.


>> , or from source to have those work with readGDAL.
> Do you mean those sources of oceanographic information which work with 
> readGDAL? Do you know which website work with that? I use to download 
> information from http://poet.jpl.nasa.gov/, 
> http://oceancolor.gsfc.nasa.gov/cgi/level3.pl,etc.
>> I would just use gdal_translate to convert data to GeoTIFF 
>> (installing FWTools is trivial). 
> gdal_translate is a function in FWTools? GeoTIFF is a georeferenced 
> file type? Can you load them in R? Which function can I use?
>> Those formats can offer further challenges, just in interpreting the 
>> structure and content, but it depends on the actual data you want to 
>> use.
> I would like to use SST, CHL, bathymetry, dynamic height, wind, etc. 
> Until now, I have been downloading data from the website previously 
> cited as ESRI ASC which are loaded into R without problem using 
> import.asc() function.
>>
>> A question to ask here is what is the service providing the data in 
>> the first place? Ideally you can read directly from the server, but 
>> more likely you have a local cache of files. (If you have these as 
>> netCDF/HDF it's probably best to extract what you need to GeoTIFF 
>> using gdal_translate. )  The kftools package provides a direct read 
>> for SST, but it's a bit complicated. 
> I haven't found the kftools package!Do you know where I can find it? 
> Also could you send me an example of how is possible to download 
> directly from a ftp server SST, chlorophyll, wind data, etc.?
>> I had success with reading directly from the service behind the NASA 
>> POET site, but that wasn't useful for many datasets. I haven't 
>> explored the variety of services for some time, apparently there is a 
>> NOAA service that covers most needs.
> Could you explain me a little bit how can I download directly from 
> POET for example? Which is the command line to connect with the ftp?
>>
>> For getting a range of pixel values around each point I would use 
>> overlay() in sp package, and work on creating circle polygons around 
>> your locations.
> Yes, I have tried two different functions. One is polycirc2() from the 
> pgirmess package. I have tried the following code (locs are the lat 
> and long of the locations) and it works (because there is no error) 
> but I cannot visualize anything and also there is no information on 
> the help about the units it is using.
>
> polygon(polycirc2(radius = 1, center = c(x=locs$Long,y=locs$Lat)))
>
> Also I have used the grid.circle() function from the grid package but 
> the output circles seem of the same size that the original one.
>
> Do you know how could I efficiently create circles around my points 
> and later overlay with oceanographic information?
>> You didn't mention the temporal aspect that you need when overlaying 
>> track data with time series of oceanographic data, but this can be 
>> very simple when using rgdal since all your time series layers can be 
>> stored in one SpatialGridDataFrame dataset as separate attributes 
>> (depending on the size) and you simply find the interval in which 
>> your locations fall as well as the pixel for each location. 
>> Determining a spatial range around these is more complicated but not 
>> greatly so. The power of general indexing in R, along with the 
>> spatial extensions provided in sp is very helpful here.
> Yes, this would be very useful. For example, imaging that I have a 
> track corresponding to two weeks and I would like to extract weekly 
> chlorophyll data. First, I would like to match track data with the 
> corresponding chlorophyll week and later extract the data from a 
> determining spatial range around locations of 10 km for example. Could 
> you send me an example of this?
>>
>> How are you determining an appropriate range to query around your 
>> track locations? The tripEstimation package is a suite of functions 
>> written for estimating position from raw archival tags or a remote 
>> service, and I mention that as the outputs there can be very flexible 
>> for spatial/temporal overlays when location precision is important 
>> (but may be overkill here, and it's not user friendly).
>>
>> The trip package extends the foundation provided by sp for track 
>> data, so that also may be useful for dealing with sets of tracks.
> I have been working with the trip package a little bit and thanks for 
> the tripEstimation information.
>>
>> I hope some of that is helpful - sorry I'm not addressing your 
>> questions specifically. If you post more detail about the actual 
>> datasets you are trying to deal with I may be able to help more.
> Thank you for you answer and hope you could help me a little bit with 
> me doubts. It seems to me that it would be more useful to use Matlab 
> instead of R for oceanographic data.
>
> Thanks,
> Maite
>>
>> Cheers, Mike.
>>
>>
>> LOUZAO wrote:
>>> Dear list,
>>>
>>> I'm trying to extract different oceanographic data (chlorophyll, sea 
>>> surface temperature, etc.) for doing habitat modelling. The input 
>>> data are locations (lat, lon) of tracking data of marine top 
>>> predators and I would like to extract oceanographic data from a 
>>> given area around each specific location, from which compute  the 
>>> median, maximum and minimum values of the corresponding data (sst, 
>>> chl, etc.). For doing this,
>>>
>>> 1. I need to import the oceanographic data into R. Which format 
>>> (ascii, hdf, netcdf,etc.) would you recommend? I have been working 
>>> with ascii, importing files with import.asc().
>>> 2. For defining the area around each location, I could define a 
>>> circle (radius of 1? in decimal degree) or a square (a total heigth 
>>> of 1? in decimal degree) centered in each location.
>>> In the grid package, the circleGrob() or the viewport() fucntions 
>>> provide this approach. However, I have applied the circleGrob but I 
>>> do not reach to obtain a circle around each location (when I plot it 
>>> I only obtain the same configuration than when plotting the 
>>> locations). I think that I'm missing something related with the 
>>> units. In this case, x and y are longitud and latitud in decimal 
>>> degress.
>>>
>>> circle<-circleGrob(x=locs$Long, y=locs$Lat, r=2, 
>>> default.units="native", name=NULL,
>>>            gp=gpar(), vp=NULL)
>>>
>>> I have found other two functions that I do not know if someone has 
>>> used for doing the same.
>>>
>>> - symbolsInPolys() in maptools
>>>
>>> - spsample() in sp
>>>
>>> 3. The last step would be to overlay the oceanographic layer and the 
>>> object of circles (or squares) to extract the median, maximum and 
>>> minimum values of the corresponding data (sst, chl, etc.)
>>>
>>> Has anybody worked on this problem? Could you please point to any 
>>> useful documents?
>>> Thanks in advance,
>>>
>>> Maite Louzao
>>>
>>> ------------------------------------------------------------------------ 
>>>
>>>
>>>
>>> No virus found in this incoming message.
>>> Checked by AVG. Version: 8.0.100 / Virus Database: 270.4.1/1515 - 
>>> Release Date: 6/23/2008 7:16 PM
>>>   
>>
>>
>>
>>
>
>
> ------------------------------------------------------------------------
>
>
> No virus found in this incoming message.
> Checked by AVG. 
> Version: 8.0.101 / Virus Database: 270.4.1/1519 - Release Date: 6/25/2008 4:13 PM
>



From epeterson at cnps.org  Thu Jun 26 18:22:27 2008
From: epeterson at cnps.org (Eric Peterson)
Date: Thu, 26 Jun 2008 09:22:27 -0700
Subject: [R-sig-Geo] Geospatial R Beginner Resources?
Message-ID: <48635FD3.D097.0090.0@cnps.org>

Is there a website/document/other that provides a good, basic, overview of (A) the available libraries, (b) the processes they make available, and (c) some demos of how to implement them?

I am quite familiar and comfortable with regular use of R for 'standard' statistical analyses and graph making.  In the past, I've had access to some expensive remote sensing software as well as ESRI products for my Geospatial work, including landscape analyses and remote sensing of vegetation.  My current job has access only to the ESRI products, leaving me without much for the remote sensing end of my work.  As I understand it, at least some capabilities are now available in R, but will require a bit of work to learn.  Although I am a little bit of a programmer capable of struggling through most of my needs, I think it would take me several days of searching through the package documents on the cran website to figure out just a few basics.

Thanks!
-Eric
---
Eric B. Peterson, Ph.D.
Vegetation Ecologist
California Native Plant Society




From Roger.Bivand at nhh.no  Thu Jun 26 18:44:15 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 26 Jun 2008 18:44:15 +0200 (CEST)
Subject: [R-sig-Geo] Geospatial R Beginner Resources?
In-Reply-To: <48635FD3.D097.0090.0@cnps.org>
References: <48635FD3.D097.0090.0@cnps.org>
Message-ID: <Pine.LNX.4.64.0806261836150.4446@reclus.nhh.no>

On Thu, 26 Jun 2008, Eric Peterson wrote:

> Is there a website/document/other that provides a good, basic, overview 
> of (A) the available libraries, (b) the processes they make available, 
> and (c) some demos of how to implement them?
>
> I am quite familiar and comfortable with regular use of R for 'standard' 
> statistical analyses and graph making.  In the past, I've had access to 
> some expensive remote sensing software as well as ESRI products for my 
> Geospatial work, including landscape analyses and remote sensing of 
> vegetation.  My current job has access only to the ESRI products, 
> leaving me without much for the remote sensing end of my work.  As I 
> understand it, at least some capabilities are now available in R, but 
> will require a bit of work to learn.  Although I am a little bit of a 
> programmer capable of struggling through most of my needs, I think it 
> would take me several days of searching through the package documents on 
> the cran website to figure out just a few basics.

http://CRAN.R-project.org/view=Spatial

is one of now many Task View pages trying to give some guidance in the 
wealth of contributed packages. Please indicate whether it gets you 
started, and how it might be improved. You'll find examples on the help 
pages of the packages - try looking at them, pasting them into a running R 
session (with the required packages loaded), or running example() of a 
command with executable examples.

Roger

>
> Thanks!
> -Eric
> ---
> Eric B. Peterson, Ph.D.
> Vegetation Ecologist
> California Native Plant Society
>
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From juliane_struve at yahoo.co.uk  Fri Jun 27 01:00:31 2008
From: juliane_struve at yahoo.co.uk (Juliane Struve)
Date: Thu, 26 Jun 2008 23:00:31 +0000 (GMT)
Subject: [R-sig-Geo] Updating a column entry in a dataframe from another
	dataframe
Message-ID: <95743.6420.qm@web27206.mail.ukl.yahoo.com>

Dear list,

I am a new R user and wonder if somebody could help with this problem: 

The entries in column "currentcentroid" in data frame "fish" change in relation to the entry in column "angles" (example is given below). "currentcentroid" is a gridpoint. After updating it according to "angles" I would like to also update the corresponding UTM coordinates "currentUTMX" and "currentUTMY" from data frame "WaterCentroids", which stores centroids and their corresponding UTM coordinates. 

I would like to write an if statement that relates "currentcentroid" and "CurrentUTMX" and "CurrentUTMY" in dataframe "fish" to  "centroid" and "UTMX" and "UTMY" in dataframe "WaterCentroids".But I am having a hrad time figuring it out. Is there anybody who could help or give me a hint ?
The purpose is to simulate the path of fish on a grid. 

Many thanks..

Juliane 

This is my dataframe so far:

nfish=10
startpoints=sample(282816,nfish)
anglesfromnorth=c(0,45,90,135,180,225,270,360)
anglenumber=sample(1:8,size=nfish,replace=TRUE)
angles=anglesfromnorth[anglenumber]
fish=data.frame(WaterCentroids[startpoints, 3:5],angles=angles,currentcentroid=0,currentUTMX=0, currentUTMY=0)
if (fish$angles==45){fish$currentcentroid=fish$centroid +1} else
{fish$currentcentroid=fish$centroid}

How do I update "currentUTMX" and "currentUTMY" from df[WaterCentroids] now ?


      __________________________________________________________
Not happy with your email address?.
Get the one you really want - millions of new email addresses available now at Yahoo! http://uk.docs.yahoo.com/ymail/new.html



From giohappy at gmail.com  Fri Jun 27 18:02:26 2008
From: giohappy at gmail.com (G. Allegri)
Date: Fri, 27 Jun 2008 18:02:26 +0200
Subject: [R-sig-Geo] Geospatial R Beginner Resources?
In-Reply-To: <Pine.LNX.4.64.0806261836150.4446@reclus.nhh.no>
References: <48635FD3.D097.0090.0@cnps.org>
	<Pine.LNX.4.64.0806261836150.4446@reclus.nhh.no>
Message-ID: <e12429640806270902i616b1395g76a65ce9a9281424@mail.gmail.com>

Roger didn't say it but a good comprehensive book about spatial data
handling in R is coming out in the next 2-3 months:

"Applied Spatial Data Analysis with R"
http://www.springer.com/public+health/epidemiology/book/978-0-387-78170-9

I've already boked it...

giovanni

2008/6/26 Roger Bivand <Roger.Bivand at nhh.no>:
> On Thu, 26 Jun 2008, Eric Peterson wrote:
>
>> Is there a website/document/other that provides a good, basic, overview of
>> (A) the available libraries, (b) the processes they make available, and (c)
>> some demos of how to implement them?
>>
>> I am quite familiar and comfortable with regular use of R for 'standard'
>> statistical analyses and graph making.  In the past, I've had access to some
>> expensive remote sensing software as well as ESRI products for my Geospatial
>> work, including landscape analyses and remote sensing of vegetation.  My
>> current job has access only to the ESRI products, leaving me without much
>> for the remote sensing end of my work.  As I understand it, at least some
>> capabilities are now available in R, but will require a bit of work to
>> learn.  Although I am a little bit of a programmer capable of struggling
>> through most of my needs, I think it would take me several days of searching
>> through the package documents on the cran website to figure out just a few
>> basics.
>
> http://CRAN.R-project.org/view=Spatial
>
> is one of now many Task View pages trying to give some guidance in the
> wealth of contributed packages. Please indicate whether it gets you started,
> and how it might be improved. You'll find examples on the help pages of the
> packages - try looking at them, pasting them into a running R session (with
> the required packages loaded), or running example() of a command with
> executable examples.
>
> Roger
>
>>
>> Thanks!
>> -Eric
>> ---
>> Eric B. Peterson, Ph.D.
>> Vegetation Ecologist
>> California Native Plant Society
>>
>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From dhughj at essex.ac.uk  Mon Jun 30 16:00:24 2008
From: dhughj at essex.ac.uk (David Hugh-Jones)
Date: Mon, 30 Jun 2008 16:00:24 +0200
Subject: [R-sig-Geo] thinlines equivalent?
Message-ID: <f5d848060806300700g29ee257ev3caf2a8c101e0d22@mail.gmail.com>

Hi all

I have a big dataset of points and am doing stuff on them that takes a
lot of time. To speed it up, I would like to use "thinlines" from
RArcinfo, which basically makes the maps "rougher" by throwing away
points. Is there an equivalent function for SpatialPolygon type
objects? (I assume that there's no way to convert _to_ Arcinfo, though
I know it's possible to read from it).

Cheers

David Hugh-Jones
PhD Candidate
Essex University Department of Government
http://davidhughjones.googlepages.com



From pinaud at cebc.cnrs.fr  Mon Jun 30 16:55:44 2008
From: pinaud at cebc.cnrs.fr (David PINAUD)
Date: Mon, 30 Jun 2008 16:55:44 +0200
Subject: [R-sig-Geo] thinlines equivalent?
In-Reply-To: <f5d848060806300700g29ee257ev3caf2a8c101e0d22@mail.gmail.com>
References: <f5d848060806300700g29ee257ev3caf2a8c101e0d22@mail.gmail.com>
Message-ID: <4868F3F0.6060300@cebc.cnrs.fr>

maybe you can try the function dp() in the package "shapefiles", which 
is an implementation of the Douglas-Peucker polyLine simplification 
algorithm.
Hope it helps
David

David Hugh-Jones a ?crit :
> Hi all
>
> I have a big dataset of points and am doing stuff on them that takes a
> lot of time. To speed it up, I would like to use "thinlines" from
> RArcinfo, which basically makes the maps "rougher" by throwing away
> points. Is there an equivalent function for SpatialPolygon type
> objects? (I assume that there's no way to convert _to_ Arcinfo, though
> I know it's possible to read from it).
>
> Cheers
>
> David Hugh-Jones
> PhD Candidate
> Essex University Department of Government
> http://davidhughjones.googlepages.com
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
>   

-- 
***************************************************
David PINAUD
Ing?nieur de Recherche "Analyses spatiales"

Centre d'Etudes Biologiques de Chiz? - CNRS UPR1934
79360 Villiers-en-Bois, France 
poste 485
Tel: +33 (0)5.49.09.35.58
Fax: +33 (0)5.49.09.65.26
http://www.cebc.cnrs.fr/

***************************************************




 ________
-------------- next part --------------
A non-text attachment was scrubbed...
Name: pinaud.vcf
Type: text/x-vcard
Size: 324 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080630/45102c6e/attachment.vcf>

From dhughj at essex.ac.uk  Mon Jun 30 18:48:21 2008
From: dhughj at essex.ac.uk (David Hugh-Jones)
Date: Mon, 30 Jun 2008 18:48:21 +0200
Subject: [R-sig-Geo] API documentation?
Message-ID: <f5d848060806300948k61b21090v587ee3f33969d1e0@mail.gmail.com>

Thanks David for his comment about dp.

Quick question: is there any reasonably comprehensible API
documentation for the "sp" package? I have just spent about an hour
trying to get a list of points from a SpatialPolygons object. I
eventually just printed everything out and found the data by hand, so
now I am doing:

coords <- myobject at polygons[[1]]@Polygons[[1]]@coords

but I don't assume that is right. Surely there must be some simple way
to get a list of x and y coords out of any object?

in frustration,
David Hugh-Jones
PhD Candidate
Essex University Department of Government
http://davidhughjones.googlepages.com


2008/6/30 David PINAUD <pinaud at cebc.cnrs.fr>:
> maybe you can try the function dp() in the package "shapefiles", which is an
> implementation of the Douglas-Peucker polyLine simplification algorithm.
> Hope it helps
> David
>
> David Hugh-Jones a ?crit :
>>
>> Hi all
>>
>> I have a big dataset of points and am doing stuff on them that takes a
>> lot of time. To speed it up, I would like to use "thinlines" from
>> RArcinfo, which basically makes the maps "rougher" by throwing away
>> points. Is there an equivalent function for SpatialPolygon type
>> objects? (I assume that there's no way to convert _to_ Arcinfo, though
>> I know it's possible to read from it).
>>
>> Cheers
>>
>> David Hugh-Jones
>> PhD Candidate
>> Essex University Department of Government
>> http://davidhughjones.googlepages.com
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>>
>>
>
> --
> ***************************************************
> David PINAUD
> Ing?nieur de Recherche "Analyses spatiales"
>
> Centre d'Etudes Biologiques de Chiz? - CNRS UPR1934
> 79360 Villiers-en-Bois, France poste 485
> Tel: +33 (0)5.49.09.35.58
> Fax: +33 (0)5.49.09.65.26
> http://www.cebc.cnrs.fr/
>
> ***************************************************
>
>
>
>
> ________ Information from NOD32 ________
> This message was checked by NOD32 Antivirus System for Linux Mail Servers.
> http://www.eset.com



From v.gomezrubio at imperial.ac.uk  Mon Jun 30 19:24:34 2008
From: v.gomezrubio at imperial.ac.uk (Virgilio Gomez-Rubio)
Date: Mon, 30 Jun 2008 18:24:34 +0100
Subject: [R-sig-Geo] API documentation?
In-Reply-To: <f5d848060806300948k61b21090v587ee3f33969d1e0@mail.gmail.com>
References: <f5d848060806300948k61b21090v587ee3f33969d1e0@mail.gmail.com>
Message-ID: <1214846674.6005.11.camel@fh-vrubio>

Dear David,

Probably the best way to start is by checking the HTML documentation. It
should be installed locally but it is also accesible, for example, here:

http://finzi.psych.upenn.edu/R/library/sp/html/00Index.html

Hope this helps.

Virgilio

On Mon, 2008-06-30 at 18:48 +0200, David Hugh-Jones wrote:
> Thanks David for his comment about dp.
> 
> Quick question: is there any reasonably comprehensible API
> documentation for the "sp" package? I have just spent about an hour
> trying to get a list of points from a SpatialPolygons object. I
> eventually just printed everything out and found the data by hand, so
> now I am doing:
> 
> coords <- myobject at polygons[[1]]@Polygons[[1]]@coords
> 
> but I don't assume that is right. Surely there must be some simple way
> to get a list of x and y coords out of any object?
> 
> in frustration,
> David Hugh-Jones
> PhD Candidate
> Essex University Department of Government
> http://davidhughjones.googlepages.com
> 
> 
> 2008/6/30 David PINAUD <pinaud at cebc.cnrs.fr>:
> > maybe you can try the function dp() in the package "shapefiles", which is an
> > implementation of the Douglas-Peucker polyLine simplification algorithm.
> > Hope it helps
> > David
> >
> > David Hugh-Jones a ?crit :
> >>
> >> Hi all
> >>
> >> I have a big dataset of points and am doing stuff on them that takes a
> >> lot of time. To speed it up, I would like to use "thinlines" from
> >> RArcinfo, which basically makes the maps "rougher" by throwing away
> >> points. Is there an equivalent function for SpatialPolygon type
> >> objects? (I assume that there's no way to convert _to_ Arcinfo, though
> >> I know it's possible to read from it).
> >>
> >> Cheers
> >>
> >> David Hugh-Jones
> >> PhD Candidate
> >> Essex University Department of Government
> >> http://davidhughjones.googlepages.com
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at stat.math.ethz.ch
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >>
> >>
> >>
> >
> > --
> > ***************************************************
> > David PINAUD
> > Ing?nieur de Recherche "Analyses spatiales"
> >
> > Centre d'Etudes Biologiques de Chiz? - CNRS UPR1934
> > 79360 Villiers-en-Bois, France poste 485
> > Tel: +33 (0)5.49.09.35.58
> > Fax: +33 (0)5.49.09.65.26
> > http://www.cebc.cnrs.fr/
> >
> > ***************************************************
> >
> >
> >
> >
> > ________ Information from NOD32 ________
> > This message was checked by NOD32 Antivirus System for Linux Mail Servers.
> > http://www.eset.com
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From dhughj at essex.ac.uk  Mon Jun 30 19:39:42 2008
From: dhughj at essex.ac.uk (David Hugh-Jones)
Date: Mon, 30 Jun 2008 19:39:42 +0200
Subject: [R-sig-Geo] API documentation?
In-Reply-To: <1214846674.6005.11.camel@fh-vrubio>
References: <f5d848060806300948k61b21090v587ee3f33969d1e0@mail.gmail.com>
	<1214846674.6005.11.camel@fh-vrubio>
Message-ID: <f5d848060806301039j5609156bj730d78e391e42d57@mail.gmail.com>

Guys

I don't mean to rant, but believe me, I've spent plenty of time with
the documentation and it's really not helping.

Partly this is a problem of R's doc format which treats package
documentation as an alphabetical list of functions - which gives me no
idea where to start.

This then interacts badly with the OO structure. For example, look at
the 20+ pages on "coerce". Hmm, what does "coerce" actually do? In
fact that's in a whole different library. But I didn't know that, so I
click on a page at random, say

coerce,SpatialGrid,data.frame-method

and this takes me to SpatialGrid class - which doesn't mention coerce
at all. (Nor does it tell me what SpatialGrid is, or what it is used
for.)

On the other hand, maybe I might guess that to get a list of
coordinates, I'd use "coordinates". So I click on that method, and it
tells me yes, this "retrieves spatial coordinates". But unfortunately
it retrieves them hidden inside another object ("an object of class
SpatialPointsDataFrame"). OK, but how do I get the _actual_data_?
Maybe the SpatialPointsDataFrame class page will tell me. Nope. Et
cetera.

Rick: yes, I agree that using the internal data structures is how to
do things, but this is broken isn't it? The whole point of having OO
is to be able to use it _without_ understanding the internal data
structures. The ideal, in other words, would be to have a "thin.lines"
method that I could just run on any polygon or set of polygons.
Failing that, then I should be able to get at the internal data
without hours of head scratching.

Right now, it's like, everything is hidden behind a layer of classes
and slots and methods, but I still need to go behind that layer to get
at the actual raw data, and this is so complicated and confusing that
it would be easier just to work with the raw data.

OK, I'll stop venting. If there's anything I could do to improve this
situation, I would gladly try.

David Hugh-Jones
PhD Candidate
Essex University Department of Government
http://davidhughjones.googlepages.com


2008/6/30 Virgilio Gomez-Rubio <v.gomezrubio at imperial.ac.uk>:
> Dear David,
>
> Probably the best way to start is by checking the HTML documentation. It
> should be installed locally but it is also accesible, for example, here:
>
> http://finzi.psych.upenn.edu/R/library/sp/html/00Index.html
>
> Hope this helps.
>
> Virgilio
>
> On Mon, 2008-06-30 at 18:48 +0200, David Hugh-Jones wrote:
>> Thanks David for his comment about dp.
>>
>> Quick question: is there any reasonably comprehensible API
>> documentation for the "sp" package? I have just spent about an hour
>> trying to get a list of points from a SpatialPolygons object. I
>> eventually just printed everything out and found the data by hand, so
>> now I am doing:
>>
>> coords <- myobject at polygons[[1]]@Polygons[[1]]@coords
>>
>> but I don't assume that is right. Surely there must be some simple way
>> to get a list of x and y coords out of any object?
>>
>> in frustration,
>> David Hugh-Jones
>> PhD Candidate
>> Essex University Department of Government
>> http://davidhughjones.googlepages.com
>>
>>
>> 2008/6/30 David PINAUD <pinaud at cebc.cnrs.fr>:
>> > maybe you can try the function dp() in the package "shapefiles", which is an
>> > implementation of the Douglas-Peucker polyLine simplification algorithm.
>> > Hope it helps
>> > David
>> >
>> > David Hugh-Jones a ?crit :
>> >>
>> >> Hi all
>> >>
>> >> I have a big dataset of points and am doing stuff on them that takes a
>> >> lot of time. To speed it up, I would like to use "thinlines" from
>> >> RArcinfo, which basically makes the maps "rougher" by throwing away
>> >> points. Is there an equivalent function for SpatialPolygon type
>> >> objects? (I assume that there's no way to convert _to_ Arcinfo, though
>> >> I know it's possible to read from it).
>> >>
>> >> Cheers
>> >>
>> >> David Hugh-Jones
>> >> PhD Candidate
>> >> Essex University Department of Government
>> >> http://davidhughjones.googlepages.com
>> >>
>> >> _______________________________________________
>> >> R-sig-Geo mailing list
>> >> R-sig-Geo at stat.math.ethz.ch
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >>
>> >>
>> >>
>> >>
>> >
>> > --
>> > ***************************************************
>> > David PINAUD
>> > Ing?nieur de Recherche "Analyses spatiales"
>> >
>> > Centre d'Etudes Biologiques de Chiz? - CNRS UPR1934
>> > 79360 Villiers-en-Bois, France poste 485
>> > Tel: +33 (0)5.49.09.35.58
>> > Fax: +33 (0)5.49.09.65.26
>> > http://www.cebc.cnrs.fr/
>> >
>> > ***************************************************
>> >
>> >
>> >
>> >
>> > ________ Information from NOD32 ________
>> > This message was checked by NOD32 Antivirus System for Linux Mail Servers.
>> > http://www.eset.com
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>



