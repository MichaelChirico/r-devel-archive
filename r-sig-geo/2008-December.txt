From Paul.Satterthwaite at oregonstate.edu  Mon Dec  1 02:41:25 2008
From: Paul.Satterthwaite at oregonstate.edu (Satterthwaite, Paul)
Date: Sun, 30 Nov 2008 17:41:25 -0800
Subject: [R-sig-Geo] spatial moving average
In-Reply-To: <Pine.LNX.4.64.0810101946540.7433@reclus.nhh.no>
References: <mailman.9.1223632808.5013.r-sig-geo@stat.math.ethz.ch><OF480BB96A.770222E2-ONC12574DE.00456D22-C12574DE.00489D96@bdpnet.dk><d8ad40b50810100740i33ac3e6eqc8b3bfa1be1e9153@mail.gmail.com>
	<Pine.LNX.4.64.0810101946540.7433@reclus.nhh.no>
Message-ID: <D7B94F0B40246740A3EFF9DBBD921B7BB89812@SAGE.forestry.oregonstate.edu>

Hello, 

I am a beginner with R, and have 2 questions concerning
spatial/geostatistics. 

I have an artificial landscape composed of a binary grid of patches
(patch=1) or gaps (patch=0), which leads to very periodic empirical
semivariograms. 

1)Is there an already-existing model semivariogram that contains a "hole
effect", i.e., includes some periodicity in the model semivariogram fit
to the empirical data? 


2) Is there a way I can smooth this periodicity using a local/moving
average of values in a local neighborhood around each point in the grid?

Any ideas would be GREATLY appreciated!
Cheers!

Sincerely, 

Paul M. Satterthwaite
MS Student, Forest Science
Richardson 201A
Oregon State University
Corvallis, OR 97331
paul.satterthwaite at oregonstate.edu



From Paul.Satterthwaite at oregonstate.edu  Mon Dec  1 04:12:32 2008
From: Paul.Satterthwaite at oregonstate.edu (Satterthwaite, Paul)
Date: Sun, 30 Nov 2008 19:12:32 -0800
Subject: [R-sig-Geo] moving averages and hole effect models
Message-ID: <D7B94F0B40246740A3EFF9DBBD921B7BB89817@SAGE.forestry.oregonstate.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081130/eb11b0e3/attachment.pl>

From saldanha.plangeo at gmail.com  Tue Dec  2 01:45:45 2008
From: saldanha.plangeo at gmail.com (Raphael Saldanha)
Date: Mon, 1 Dec 2008 22:45:45 -0200
Subject: [R-sig-Geo] Variables inside a for
Message-ID: <c85849370812011645k7b9e31d0m7d2cc344749076b0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081201/2a65e3f6/attachment.pl>

From miguez at illinois.edu  Tue Dec  2 03:11:01 2008
From: miguez at illinois.edu (Fernando Miguez)
Date: Mon, 01 Dec 2008 20:11:01 -0600
Subject: [R-sig-Geo] Variables inside a for
In-Reply-To: <c85849370812011645k7b9e31d0m7d2cc344749076b0@mail.gmail.com>
References: <c85849370812011645k7b9e31d0m7d2cc344749076b0@mail.gmail.com>
Message-ID: <49349935.5020103@illinois.edu>

Hi Raphael,

If you truly only need to run 4 regressions you might be less confused 
if you just do

test1 <- lm(TX01 ~ INCOME, data = database)
test2 <- lm(TX02 ~ INCOME, data = database)
test3 <- lm(TX03 ~ INCOME, data = database)
test4 <- lm(TX04 ~ INCOME, data = database)

If you need to do this 100 times it is not very practical. Here I'm 
going to assume that your data are in a data frame with the first 100 
columns being dependent variables and column 101 being the independent 
variable. Your first option is to select the component from the lm 
object you are interested in, let's assume the coefficients. Then

n <- 100
mat <- matrix(nrow=n,ncol=2)
for(i in 1:n){
mat[i,] <- lm(data[,i] ~ data[,101])$coef
}

The resulting matrix mat will hold the coefficients of the 100 
regressions. Again, if you really need the whole lm object then you 
could do the following

n <- 100
arr <- array(list(),c(1,n))
for(i in 1:n){
arr[[i]] <- lm(data[,i] ~ data[,101])
}

The resulting array will have the 100 lm objects, which you can then 
examine.

Hope this helps,

Fernando

Raphael Saldanha wrote:
> Hi!
> 
> I had a database with some variables in sequence. Let me say: TX01, TX02,
> TX03 and TX04.
> 
> But I need to run some regressions changing the variables... so:
> 
> variable <- paste("TX0", 1:4, sep="")
> 
> for(i in 1:4){
> test[i] <- lm(variable[i] ~ INCOME, data=database)
> }
> 
> But doesn't work... lm tries to find a variable inside database named
> variable[i] ...
> 
> Suggestions?
> 
> 
> King regards!
> 
> Raphael Saldanha
> Brasil
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Fernando E. Miguez
Energy Biosciences Institute
http://netfiles.uiuc.edu/miguez/www/



From ggrothendieck at gmail.com  Tue Dec  2 03:35:13 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 1 Dec 2008 21:35:13 -0500
Subject: [R-sig-Geo] Variables inside a for
In-Reply-To: <c85849370812011645k7b9e31d0m7d2cc344749076b0@mail.gmail.com>
References: <c85849370812011645k7b9e31d0m7d2cc344749076b0@mail.gmail.com>
Message-ID: <971536df0812011835k7ac7d6b8y193b51cec281afc7@mail.gmail.com>

Use this:

lm(database[c(variable[i], "INCOME")])

On Mon, Dec 1, 2008 at 7:45 PM, Raphael Saldanha
<saldanha.plangeo at gmail.com> wrote:
> Hi!
>
> I had a database with some variables in sequence. Let me say: TX01, TX02,
> TX03 and TX04.
>
> But I need to run some regressions changing the variables... so:
>
> variable <- paste("TX0", 1:4, sep="")
>
> for(i in 1:4){
> test[i] <- lm(variable[i] ~ INCOME, data=database)
> }
>
> But doesn't work... lm tries to find a variable inside database named
> variable[i] ...
>
> Suggestions?
>
>
> King regards!
>
> Raphael Saldanha
> Brasil
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From FredeA.Togersen at agrsci.dk  Tue Dec  2 08:37:07 2008
From: FredeA.Togersen at agrsci.dk (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 2 Dec 2008 08:37:07 +0100
Subject: [R-sig-Geo] Variables inside a for
References: <c85849370812011645k7b9e31d0m7d2cc344749076b0@mail.gmail.com>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC04E87ED1@DJFPOST01.djf.agrsci.dk>

How about doing something like:
 
x <- 1:100
y1 <- 1 + 2*x + rnorm(x)
y2 <- 2 + 3*x + rnorm(x)
 
lm(cbind(y1,y2) ~ x)

This is much faster.

Yours sincerely / Venlig hilsen

Frede Aakmann T?gersen
Statistician, M.Sc., Ph.D.
Modeling, Statistics and Risk Analysis

Wind and Site Competence Centre


Technology R&D
T: +45 9730 5135
M: +45 2547 6050
frtog at vestas.com

Company reg. name: Vestas Wind Systems A/S.. 
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice <http://www.vestas.com/legal/notice/owww.vestas.com/legal/notice> 
If you have received this e-mail in error please contact the sender.



________________________________

From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Raphael Saldanha
Sent: Tue 02-12-2008 01:45
To: r-sig-geo at stat.math.ethz.ch; r-help at r-project.org
Cc: Ana Paula Sobral
Subject: [R-sig-Geo] Variables inside a for



Hi!

I had a database with some variables in sequence. Let me say: TX01, TX02,
TX03 and TX04.

But I need to run some regressions changing the variables... so:

variable <- paste("TX0", 1:4, sep="")

for(i in 1:4){
test[i] <- lm(variable[i] ~ INCOME, data=database)
}

But doesn't work... lm tries to find a variable inside database named
variable[i] ...

Suggestions?


King regards!

Raphael Saldanha
Brasil

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From Roger.Bivand at nhh.no  Tue Dec  2 08:46:25 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 2 Dec 2008 08:46:25 +0100 (CET)
Subject: [R-sig-Geo] Variables inside a for
In-Reply-To: <971536df0812011835k7ac7d6b8y193b51cec281afc7@mail.gmail.com>
References: <c85849370812011645k7b9e31d0m7d2cc344749076b0@mail.gmail.com>
	<971536df0812011835k7ac7d6b8y193b51cec281afc7@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0812020841310.32550@reclus.nhh.no>

On Mon, 1 Dec 2008, Gabor Grothendieck wrote:

> Use this:
>
> lm(database[c(variable[i], "INCOME")])
>
> On Mon, Dec 1, 2008 at 7:45 PM, Raphael Saldanha
> <saldanha.plangeo at gmail.com> wrote:
>> Hi!
>>
>> I had a database with some variables in sequence. Let me say: TX01, TX02,
>> TX03 and TX04.
>>
>> But I need to run some regressions changing the variables... so:
>>
>> variable <- paste("TX0", 1:4, sep="")

Or:

lm(as.formula(paste(variable[i], "~ INCOME")), data=database)

as in:

lm(as.formula("dist ~ speed"), data=cars)

Please never cross-post. This should either go to r-help or r-sig-geo, not 
both!! Most r-help subscribers are not subscribed to r-sig-geo, so get a 
post rejection if they reply. In addition, the topic is really an r-help 
question.

Roger

>>
>> for(i in 1:4){
>> test[i] <- lm(variable[i] ~ INCOME, data=database)
>> }
>>
>> But doesn't work... lm tries to find a variable inside database named
>> variable[i] ...
>>
>> Suggestions?
>>
>>
>> King regards!
>>
>> Raphael Saldanha
>> Brasil
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From zev at zevross.com  Tue Dec  2 19:59:47 2008
From: zev at zevross.com (Zev Ross)
Date: Tue, 02 Dec 2008 13:59:47 -0500
Subject: [R-sig-Geo] GSTAT: Optimize power value for IDW
Message-ID: <493585A3.2040909@zevross.com>

Hi All,

ArcGIS has a nice little button that calculates the optimal power value 
to use for inverse distance weighting based on cross-validation and 
RMSPE. Just wondering if anyone had written something similar in R -- 
I'm using GSTAT and I'd like to avoid back and forth with ArcGIS (and 
obviously I'd like to avoid writing it myself as well!).

Zev

-- 
Zev Ross
ZevRoss Spatial Analysis
120 N Aurora, Suite 3A
Ithaca, NY 14850
607-277-0004 (phone)
866-877-3690 (fax, toll-free)
zev at zevross.com



From p.hiemstra at geo.uu.nl  Tue Dec  2 21:06:38 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 02 Dec 2008 21:06:38 +0100
Subject: [R-sig-Geo] GSTAT: Optimize power value for IDW
In-Reply-To: <493585A3.2040909@zevross.com>
References: <493585A3.2040909@zevross.com>
Message-ID: <4935954E.7070705@geo.uu.nl>

Zev Ross schreef:
> Hi All,
>
> ArcGIS has a nice little button that calculates the optimal power 
> value to use for inverse distance weighting based on cross-validation 
> and RMSPE. Just wondering if anyone had written something similar in R 
> -- I'm using GSTAT and I'd like to avoid back and forth with ArcGIS 
> (and obviously I'd like to avoid writing it myself as well!).
>
> Zev
>
Hi,

I don't have any code lying around, but a brute force optimization 
approach should be quite easy. Also because the range of idw-powers is 
relatively small. The speed would ofcourse depend on the size of the 
dataset. In code it would look something like (actually works :)):

library(gstat)
data(meuse)
coordinates(meuse) = ~x+y

# make function to do the cv
do_cv = function(idp) {
  meuse_idw = gstat(id = "zn", formula = zinc~1, data = meuse, set = 
list(idp = idp))
  out = gstat.cv(meuse_idw)
  return(sqrt(mean(out$residual^2))) # RMSE as optimization criterium
}

idw_pow = seq(0.1,5, by = 0.2) # the idwpower values that will be checked
cv_vals = sapply(idw_pow, do_cv) # calculate the rmse
# List of outcomes
print(data.frame(idp = idw_pow, cv_rmse = cv_vals))

After this you select the idw value with the smallest RMSE.

cheers and hth,
Paul

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:     +31302535773
Fax:    +31302531145
http://intamap.geo.uu.nl/~paul



From alessandro.montaghi at unifi.it  Tue Dec  2 21:44:08 2008
From: alessandro.montaghi at unifi.it (Alessandro)
Date: Tue, 2 Dec 2008 12:44:08 -0800
Subject: [R-sig-Geo] R: GSTAT: Optimize power value for IDW (Paul Hiemstra
	approach)
In-Reply-To: <4935954E.7070705@geo.uu.nl>
References: <493585A3.2040909@zevross.com> <4935954E.7070705@geo.uu.nl>
Message-ID: <010401c954be$baacdc60$30069520$@montaghi@unifi.it>

Hi 

Normally I use the R+SAGA to calculate the IDW and create a raster, with
this follow code. I change the radius input with a loop formula to create
several raster and after check the best result (I am studying a oak forest
with low density) 

radii.list <- as.list(c(5, 10, 15, 20, 25, 30)) 
for(i in 1:length(radii.list)){ 
	rsaga.geoprocessor(lib="grid_gridding", module=0,
param=list(GRID=set.file.extension(paste("DEM_iw",radii.list[[i]],sep=""),".
sgrd"),
	SHAPES="ground.shp", FIELD=0, TARGET= 0, POWER=1.0,
RADIUS=radii.list[[i]], NPOINTS=20, 	USER_CELL_SIZE=dem.pixelsize,
USER_X_EXTENT_MIN=ground at bbox[1,1], USER_X_EXTENT_MAX=ground at bbox[1,2],
USER_Y_EXTENT_MIN=ground at bbox[2,1], USER_Y_EXTENT_MAX=ground at bbox[2,2])) 
} 


After I have 6 raster (DEM_idw_5.sgrd, DEM_idw_10.sgrd, DEM_idw_15.sgrd,
DEM_idw_20.sgrd, etc. etc.). I check hand-made the best IDW. I don't know is
It possible to improve this formula with RMSE in gstat and calculate the
best power.

Ale



-----Messaggio originale-----
Da: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] Per conto di Paul Hiemstra
Inviato: marted? 2 dicembre 2008 12.07
A: Zev Ross
Cc: r-sig-geo at stat.math.ethz.ch
Oggetto: Re: [R-sig-Geo] GSTAT: Optimize power value for IDW

Zev Ross schreef:
> Hi All,
>
> ArcGIS has a nice little button that calculates the optimal power 
> value to use for inverse distance weighting based on cross-validation 
> and RMSPE. Just wondering if anyone had written something similar in R 
> -- I'm using GSTAT and I'd like to avoid back and forth with ArcGIS 
> (and obviously I'd like to avoid writing it myself as well!).
>
> Zev
>
Hi,

I don't have any code lying around, but a brute force optimization 
approach should be quite easy. Also because the range of idw-powers is 
relatively small. The speed would ofcourse depend on the size of the 
dataset. In code it would look something like (actually works :)):

library(gstat)
data(meuse)
coordinates(meuse) = ~x+y

# make function to do the cv
do_cv = function(idp) {
  meuse_idw = gstat(id = "zn", formula = zinc~1, data = meuse, set = 
list(idp = idp))
  out = gstat.cv(meuse_idw)
  return(sqrt(mean(out$residual^2))) # RMSE as optimization criterium
}

idw_pow = seq(0.1,5, by = 0.2) # the idwpower values that will be checked
cv_vals = sapply(idw_pow, do_cv) # calculate the rmse
# List of outcomes
print(data.frame(idp = idw_pow, cv_rmse = cv_vals))

After this you select the idw value with the smallest RMSE.

cheers and hth,
Paul

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:     +31302535773
Fax:    +31302531145
http://intamap.geo.uu.nl/~paul

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From zev at zevross.com  Tue Dec  2 21:54:35 2008
From: zev at zevross.com (Zev Ross)
Date: Tue, 02 Dec 2008 15:54:35 -0500
Subject: [R-sig-Geo] R: GSTAT: Optimize power value for IDW (Paul
 Hiemstra approach)
In-Reply-To: <010401c954be$baacdc60$30069520$@montaghi@unifi.it>
References: <493585A3.2040909@zevross.com> <4935954E.7070705@geo.uu.nl>
	<010401c954be$baacdc60$30069520$@montaghi@unifi.it>
Message-ID: <4935A08B.6090101@zevross.com>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081202/1fcf93f3/attachment.html>

From edzer.pebesma at uni-muenster.de  Tue Dec  2 22:29:31 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 02 Dec 2008 22:29:31 +0100
Subject: [R-sig-Geo] R: GSTAT: Optimize power value for IDW (Paul
 Hiemstra approach)
In-Reply-To: <4935A08B.6090101@zevross.com>
References: <493585A3.2040909@zevross.com>
	<4935954E.7070705@geo.uu.nl>	<010401c954be$baacdc60$30069520$@montaghi@unifi.it>
	<4935A08B.6090101@zevross.com>
Message-ID: <4935A8BB.3010900@uni-muenster.de>

Hi Zev,

There's no need to brute force, as optimize is there to help you -- my 
guess is that the function is convex. The following takes a while:

 > f = function(idp, formula, data,...) 
sum(krige.cv(formula,data,set=list(debug=0,idp=idp),...)$residual**2)
 > optimize(f, interval=c(0.01,4), formula=log(zinc)~1, data=meuse)
$minimum
[1] 3.532051

$objective
[1] 32.09126

but that is probably due to the (my?) hopelessly inefficient (though 
flexible) setup of krige.cv. Speeding up can be done by allowing a 
larger tolerance, or passing e.g. nfold=5 to optimize(). This nfold will 
also result in somewhat random output, as it randomly folds the data in 
5 partitions.
--
Edzer


Zev Ross wrote:
> Hi All,
>
> Thanks to Paul and Alessandro for their suggestions. Paul's code 
> (brute force) worked well for me and the results match up well with 
> ArcGIS. I'm not using a large dataset so the speed isn't an issue but 
> with a larger dataset it would be. In ArcGIS the optimization is 
> instantaneous so clearly the software is doing something different 
> than testing out all possible values.
>
> I used Paul's code with no substantive changes then it's 
> straightforward to use:
>
> plot(idw_pow, cv_vals)
> idw_pow[which.min(cv_vals)]
>
> And pull out the min.
>
> Thanks for the advice! Zev
>
>
>
>
> Alessandro wrote:
>> Hi 
>>
>> Normally I use the R+SAGA to calculate the IDW and create a raster, with
>> this follow code. I change the radius input with a loop formula to create
>> several raster and after check the best result (I am studying a oak forest
>> with low density) 
>>
>> radii.list <- as.list(c(5, 10, 15, 20, 25, 30)) 
>> for(i in 1:length(radii.list)){ 
>> 	rsaga.geoprocessor(lib="grid_gridding", module=0,
>> param=list(GRID=set.file.extension(paste("DEM_iw",radii.list[[i]],sep=""),".
>> sgrd"),
>> 	SHAPES="ground.shp", FIELD=0, TARGET= 0, POWER=1.0,
>> RADIUS=radii.list[[i]], NPOINTS=20, 	USER_CELL_SIZE=dem.pixelsize,
>> USER_X_EXTENT_MIN=ground at bbox[1,1], USER_X_EXTENT_MAX=ground at bbox[1,2],
>> USER_Y_EXTENT_MIN=ground at bbox[2,1], USER_Y_EXTENT_MAX=ground at bbox[2,2])) 
>> } 
>>
>>
>> After I have 6 raster (DEM_idw_5.sgrd, DEM_idw_10.sgrd, DEM_idw_15.sgrd,
>> DEM_idw_20.sgrd, etc. etc.). I check hand-made the best IDW. I don't know is
>> It possible to improve this formula with RMSE in gstat and calculate the
>> best power.
>>
>> Ale
>>
>>
>>
>> -----Messaggio originale-----
>> Da: r-sig-geo-bounces at stat.math.ethz.ch
>> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] Per conto di Paul Hiemstra
>> Inviato: marted? 2 dicembre 2008 12.07
>> A: Zev Ross
>> Cc: r-sig-geo at stat.math.ethz.ch
>> Oggetto: Re: [R-sig-Geo] GSTAT: Optimize power value for IDW
>>
>> Zev Ross schreef:
>>   
>>> Hi All,
>>>
>>> ArcGIS has a nice little button that calculates the optimal power 
>>> value to use for inverse distance weighting based on cross-validation 
>>> and RMSPE. Just wondering if anyone had written something similar in R 
>>> -- I'm using GSTAT and I'd like to avoid back and forth with ArcGIS 
>>> (and obviously I'd like to avoid writing it myself as well!).
>>>
>>> Zev
>>>
>>>     
>> Hi,
>>
>> I don't have any code lying around, but a brute force optimization 
>> approach should be quite easy. Also because the range of idw-powers is 
>> relatively small. The speed would ofcourse depend on the size of the 
>> dataset. In code it would look something like (actually works :)):
>>
>> library(gstat)
>> data(meuse)
>> coordinates(meuse) = ~x+y
>>
>> # make function to do the cv
>> do_cv = function(idp) {
>>   meuse_idw = gstat(id = "zn", formula = zinc~1, data = meuse, set = 
>> list(idp = idp))
>>   out = gstat.cv(meuse_idw)
>>   return(sqrt(mean(out$residual^2))) # RMSE as optimization criterium
>> }
>>
>> idw_pow = seq(0.1,5, by = 0.2) # the idwpower values that will be checked
>> cv_vals = sapply(idw_pow, do_cv) # calculate the rmse
>> # List of outcomes
>> print(data.frame(idp = idw_pow, cv_rmse = cv_vals))
>>
>> After this you select the idw value with the smallest RMSE.
>>
>> cheers and hth,
>> Paul
>>
>>   
>
> -- 
> Zev Ross
> ZevRoss Spatial Analysis
> 120 N Aurora, Suite 3A
> Ithaca, NY 14850
> 607-277-0004 (phone)
> 866-877-3690 (fax, toll-free)
> zev at zevross.com
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de



From ct529 at york.ac.uk  Wed Dec  3 10:29:29 2008
From: ct529 at york.ac.uk (Corrado)
Date: Wed, 3 Dec 2008 09:29:29 +0000
Subject: [R-sig-Geo] Raster file from ascii file and flattening Africa ....
	:)
Message-ID: <200812030929.29575.ct529@york.ac.uk>

Dear friends,

I am a kind of advanced newbie, if that makes sense.

I have a text file of the form

coordinate x,coordinate y,cat={real number between 250 and 450}

where coordinate are expressed in latitude and longitude. The files represents 
measurements of the size of a skulls on sites all over Africa.

From it, I would like to build a raster file, 100 km by 100km.  There are 2 
problems:

1) Unfortunately,  in some 100km x 100km squares, there is one of the points 
whilst in others there are maybe 20. How do I average, so that in each square 
I only have 1 value representing the average?
 
2) How do we "flatten" Africa so that we may use 100km x 100km squares instead 
of 1 degree x 1 degree, without committing a geographical crime? What we need 
is to respect the areas ....

Best regards and apologies for the silliness of the questions.
-- 
Corrado Topi

Global Climate Change & Biodiversity Indicators
Area 18,Department of Biology
University of York, York, YO10 5YW, UK
Phone: + 44 (0) 1904 328645, E-mail: ct529 at york.ac.uk



From Kamran.Safi at ioz.ac.uk  Wed Dec  3 11:26:14 2008
From: Kamran.Safi at ioz.ac.uk (Kamran Safi)
Date: Wed, 3 Dec 2008 10:26:14 -0000
Subject: [R-sig-Geo] Raster file from ascii file and flattening Africa
	....:)
In-Reply-To: <200812030929.29575.ct529@york.ac.uk>
References: <200812030929.29575.ct529@york.ac.uk>
Message-ID: <41E1ED29E5E8E34BBDD8B82CFA1A9D04062E6357@zsl26>

Hi Corrado,

Being a advanced newbie myself, I first of all understand what you mean
by that and secondly ask you to qualify my answer.

I would, tackling your problem, create a raster polygon in a metric
equal area projection, such as Mollweide. Then you use overlay() and get
for each polygon the set of points that are within each raster polygon.
You need to import the xyz file in R and convert it into a Spatialpoints
data frame. 

Here's the first bit
This reads a coast line shapefile and extracts africa from it. Then uses
the boundings boxes to produce a grid at the extent of africa. Then it
projects that raster back to longlat for the overlay() procedure. 

map <- readShapePoly("E:/Science/continent.shp", ID="CONTINENT",
proj4string = CRS("+proj=longlat"))
africa <- as.SpatialPolygons.PolygonsList(map at polygons[1])
africa.proj <- spTransform(africa, CRS("+proj=moll"))
grd <- GridTopology(c(bbox(africa.proj)[1,1]+5000,
bbox(africa.proj)[2,1]+50000), c(100000,100000),
c(ceiling((bbox(africa.proj)[1,2] - bbox(africa.proj)[1,1]) /
100000),ceiling((bbox(africa.proj)[1,2] - bbox(africa.proj)[1,1]) /
100000)))

# if you should not have a coastline of africa:
# these are the values you'll need to produce the raster you need to
proceed
# bbox(africa.proj)
#         min     max
# r1 -2472164 6131319
# r2 -4202811 4490010


polys.proj <- as.SpatialPolygons.GridTopology(grd)
proj4string(polys.proj) <- CRS("+proj=moll")
polys <- spTransform(polys.proj, CRS("+proj=longlat"))
# now you have a spatialpolygon in longlat proj that has equal area and
a 
# cell size of 100km2
#prepare a list for you results
results <- rep(NA, length(polys at polygons))
# use something like this to calculate the values per raster grid
# this here is not working probably, as I didn't think about it all too
much
# I have though somewhere a code lying around doing exactly this step,
so if 
# you don't succeed, let me know and I dig that out
for(i in 1:length(polys at polygons))
{
results[i] <- mean(<your spatial
points>$values[which(overlay(as.SpatialPolygons.PolygonsList(map.Proj at po
lygons[i]), <your Spatialpoints>) != NA, ])
}

Apart from the final bits, I tested the start and it worked. The last
bit should not be too difficult to solve. The whole thing could be more
elegant by excluding those polygons that are in the sea. But I think
that is something others can try to get their heads around it. Shouldn't
be too difficult: get the centroid coordinates, overlay it with the
costlines of Africa and convert it back into a grid...

Hope this helped.

Kamran 


------------------------
Kamran Safi

Postdoctoral Research Fellow
Institute of Zoology
Zoological Society of London
Regent's Park
London NW1 4RY

http://www.zoo.cam.ac.uk/ioz/people/safi.htm

http://spatialr.googlepages.com
http://asapi.wetpaint.com

-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Corrado
Sent: 03 December 2008 09:29
To: r-sig-ecology at r-project.org; r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] Raster file from ascii file and flattening Africa
....:)

Dear friends,

I am a kind of advanced newbie, if that makes sense.

I have a text file of the form

coordinate x,coordinate y,cat={real number between 250 and 450}

where coordinate are expressed in latitude and longitude. The files
represents 
measurements of the size of a skulls on sites all over Africa.

>From it, I would like to build a raster file, 100 km by 100km.  There
are 2 
problems:

1) Unfortunately,  in some 100km x 100km squares, there is one of the
points 
whilst in others there are maybe 20. How do I average, so that in each
square 
I only have 1 value representing the average?
 
2) How do we "flatten" Africa so that we may use 100km x 100km squares
instead 
of 1 degree x 1 degree, without committing a geographical crime? What we
need 
is to respect the areas ....

Best regards and apologies for the silliness of the questions.
-- 
Corrado Topi

Global Climate Change & Biodiversity Indicators
Area 18,Department of Biology
University of York, York, YO10 5YW, UK
Phone: + 44 (0) 1904 328645, E-mail: ct529 at york.ac.uk

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo




Click
https://www.mailcontrol.com/sr/wQw0zmjPoHdJTZGyOCrrhg==
rtsaKomrEVtGO6LLtLGhCXg+F32PftV4uyzpFBU8KFm0g==  to report this email as
spam.


The Zoological Society of London is incorporated by Royal Charter
Principal Office England. Company Number RC000749
Registered address: 
Regent's Park, London, England NW1 4RY
Registered Charity in England and Wales no. 208728 

_________________________________________________________________________
This e-mail has been sent in confidence to the named add...{{dropped:17}}



From yong.li at unimelb.edu.au  Wed Dec  3 13:13:34 2008
From: yong.li at unimelb.edu.au (Yong Li)
Date: Wed, 03 Dec 2008 23:13:34 +1100
Subject: [R-sig-Geo] How to pick up cell values of grids using points?
In-Reply-To: <mailman.11.1228302003.24649.r-sig-geo@stat.math.ethz.ch>
Message-ID: <86DBA0678E017341B449A62F258E2956154980@IS-EX-BEV3.unimelb.edu.au>

Hi ALL,

I want to pick up cells values of a grid (say a RS image) using points' positions. For example, I have an image and a point shape file with the same coordinate system, then I try to overlay points on the image, and want to get the cell values of the on-point cell and 8 surrounding cells. Could any expert give some tips to solve my problem?

Regards

Yong



-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of r-sig-geo-request at stat.math.ethz.ch
Sent: 2008?12?3? 22:00
To: r-sig-geo at stat.math.ethz.ch
Subject: R-sig-Geo Digest, Vol 64, Issue 3

Send R-sig-Geo mailing list submissions to
	r-sig-geo at stat.math.ethz.ch

To subscribe or unsubscribe via the World Wide Web, visit
	https://stat.ethz.ch/mailman/listinfo/r-sig-geo
or, via email, send a message with subject or body 'help' to
	r-sig-geo-request at stat.math.ethz.ch

You can reach the person managing the list at
	r-sig-geo-owner at stat.math.ethz.ch

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-Geo digest..."


Today's Topics:

   1. GSTAT: Optimize power value for IDW (Zev Ross)
   2. Re: GSTAT: Optimize power value for IDW (Paul Hiemstra)
   3. R: GSTAT: Optimize power value for IDW (Paul Hiemstra
      approach) (Alessandro)
   4. Re: R: GSTAT: Optimize power value for IDW (Paul Hiemstra
      approach) (Zev Ross)
   5. Re: R: GSTAT: Optimize power value for IDW (Paul Hiemstra
      approach) (Edzer Pebesma)
   6. Raster file from ascii file and flattening Africa ....	:)
      (Corrado)
   7. Re: Raster file from ascii file and flattening Africa	....:)
      (Kamran Safi)


----------------------------------------------------------------------

Message: 1
Date: Tue, 02 Dec 2008 13:59:47 -0500
From: Zev Ross <zev at zevross.com>
Subject: [R-sig-Geo] GSTAT: Optimize power value for IDW
To: r-sig-geo at stat.math.ethz.ch
Message-ID: <493585A3.2040909 at zevross.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

Hi All,

ArcGIS has a nice little button that calculates the optimal power value 
to use for inverse distance weighting based on cross-validation and 
RMSPE. Just wondering if anyone had written something similar in R -- 
I'm using GSTAT and I'd like to avoid back and forth with ArcGIS (and 
obviously I'd like to avoid writing it myself as well!).

Zev

-- 
Zev Ross
ZevRoss Spatial Analysis
120 N Aurora, Suite 3A
Ithaca, NY 14850
607-277-0004 (phone)
866-877-3690 (fax, toll-free)
zev at zevross.com



------------------------------

Message: 2
Date: Tue, 02 Dec 2008 21:06:38 +0100
From: Paul Hiemstra <p.hiemstra at geo.uu.nl>
Subject: Re: [R-sig-Geo] GSTAT: Optimize power value for IDW
To: Zev Ross <zev at zevross.com>
Cc: r-sig-geo at stat.math.ethz.ch
Message-ID: <4935954E.7070705 at geo.uu.nl>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

Zev Ross schreef:
> Hi All,
>
> ArcGIS has a nice little button that calculates the optimal power 
> value to use for inverse distance weighting based on cross-validation 
> and RMSPE. Just wondering if anyone had written something similar in R 
> -- I'm using GSTAT and I'd like to avoid back and forth with ArcGIS 
> (and obviously I'd like to avoid writing it myself as well!).
>
> Zev
>
Hi,

I don't have any code lying around, but a brute force optimization 
approach should be quite easy. Also because the range of idw-powers is 
relatively small. The speed would ofcourse depend on the size of the 
dataset. In code it would look something like (actually works :)):

library(gstat)
data(meuse)
coordinates(meuse) = ?x+y

# make function to do the cv
do_cv = function(idp) {
  meuse_idw = gstat(id = "zn", formula = zinc?1, data = meuse, set = 
list(idp = idp))
  out = gstat.cv(meuse_idw)
  return(sqrt(mean(out$residual^2))) # RMSE as optimization criterium
}

idw_pow = seq(0.1,5, by = 0.2) # the idwpower values that will be checked
cv_vals = sapply(idw_pow, do_cv) # calculate the rmse
# List of outcomes
print(data.frame(idp = idw_pow, cv_rmse = cv_vals))

After this you select the idw value with the smallest RMSE.

cheers and hth,
Paul

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:     +31302535773
Fax:    +31302531145
http://intamap.geo.uu.nl/?paul



------------------------------

Message: 3
Date: Tue, 2 Dec 2008 12:44:08 -0800
From: "Alessandro" <alessandro.montaghi at unifi.it>
Subject: [R-sig-Geo] R: GSTAT: Optimize power value for IDW (Paul
	Hiemstra	approach)
To: "'Paul Hiemstra'" <p.hiemstra at geo.uu.nl>, "'Zev Ross'"
	<zev at zevross.com>
Cc: r-sig-geo at stat.math.ethz.ch
Message-ID: <010401c954be$baacdc60$30069520$@montaghi at unifi.it>
Content-Type: text/plain;	charset="iso-8859-1"

Hi 

Normally I use the R+SAGA to calculate the IDW and create a raster, with
this follow code. I change the radius input with a loop formula to create
several raster and after check the best result (I am studying a oak forest
with low density) 

radii.list <- as.list(c(5, 10, 15, 20, 25, 30)) 
for(i in 1:length(radii.list)){ 
	rsaga.geoprocessor(lib="grid_gridding", module=0,
param=list(GRID=set.file.extension(paste("DEM_iw",radii.list[[i]],sep=""),".
sgrd"),
	SHAPES="ground.shp", FIELD=0, TARGET= 0, POWER=1.0,
RADIUS=radii.list[[i]], NPOINTS=20, 	USER_CELL_SIZE=dem.pixelsize,
USER_X_EXTENT_MIN=ground at bbox[1,1], USER_X_EXTENT_MAX=ground at bbox[1,2],
USER_Y_EXTENT_MIN=ground at bbox[2,1], USER_Y_EXTENT_MAX=ground at bbox[2,2])) 
} 


After I have 6 raster (DEM_idw_5.sgrd, DEM_idw_10.sgrd, DEM_idw_15.sgrd,
DEM_idw_20.sgrd, etc. etc.). I check hand-made the best IDW. I don't know is
It possible to improve this formula with RMSE in gstat and calculate the
best power.

Ale



-----Messaggio originale-----
Da: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] Per conto di Paul Hiemstra
Inviato: marted? 2 dicembre 2008 12.07
A: Zev Ross
Cc: r-sig-geo at stat.math.ethz.ch
Oggetto: Re: [R-sig-Geo] GSTAT: Optimize power value for IDW

Zev Ross schreef:
> Hi All,
>
> ArcGIS has a nice little button that calculates the optimal power 
> value to use for inverse distance weighting based on cross-validation 
> and RMSPE. Just wondering if anyone had written something similar in R 
> -- I'm using GSTAT and I'd like to avoid back and forth with ArcGIS 
> (and obviously I'd like to avoid writing it myself as well!).
>
> Zev
>
Hi,

I don't have any code lying around, but a brute force optimization 
approach should be quite easy. Also because the range of idw-powers is 
relatively small. The speed would ofcourse depend on the size of the 
dataset. In code it would look something like (actually works :)):

library(gstat)
data(meuse)
coordinates(meuse) = ?x+y

# make function to do the cv
do_cv = function(idp) {
  meuse_idw = gstat(id = "zn", formula = zinc?1, data = meuse, set = 
list(idp = idp))
  out = gstat.cv(meuse_idw)
  return(sqrt(mean(out$residual^2))) # RMSE as optimization criterium
}

idw_pow = seq(0.1,5, by = 0.2) # the idwpower values that will be checked
cv_vals = sapply(idw_pow, do_cv) # calculate the rmse
# List of outcomes
print(data.frame(idp = idw_pow, cv_rmse = cv_vals))

After this you select the idw value with the smallest RMSE.

cheers and hth,
Paul

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:     +31302535773
Fax:    +31302531145
http://intamap.geo.uu.nl/?paul

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



------------------------------

Message: 4
Date: Tue, 02 Dec 2008 15:54:35 -0500
From: Zev Ross <zev at zevross.com>
Subject: Re: [R-sig-Geo] R: GSTAT: Optimize power value for IDW (Paul
	Hiemstra approach)
To: Alessandro <alessandro.montaghi at unifi.it>
Cc: r-sig-geo at stat.math.ethz.ch
Message-ID: <4935A08B.6090101 at zevross.com>
Content-Type: text/plain; charset="us-ascii"

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081202/1fcf93f3/attachment-0001.html>

------------------------------

Message: 5
Date: Tue, 02 Dec 2008 22:29:31 +0100
From: Edzer Pebesma <edzer.pebesma at uni-muenster.de>
Subject: Re: [R-sig-Geo] R: GSTAT: Optimize power value for IDW (Paul
	Hiemstra approach)
To: Zev Ross <zev at zevross.com>
Cc: r-sig-geo at stat.math.ethz.ch
Message-ID: <4935A8BB.3010900 at uni-muenster.de>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

Hi Zev,

There's no need to brute force, as optimize is there to help you -- my 
guess is that the function is convex. The following takes a while:

 > f = function(idp, formula, data,...) 
sum(krige.cv(formula,data,set=list(debug=0,idp=idp),...)$residual**2)
 > optimize(f, interval=c(0.01,4), formula=log(zinc)?1, data=meuse)
$minimum
[1] 3.532051

$objective
[1] 32.09126

but that is probably due to the (my?) hopelessly inefficient (though 
flexible) setup of krige.cv. Speeding up can be done by allowing a 
larger tolerance, or passing e.g. nfold=5 to optimize(). This nfold will 
also result in somewhat random output, as it randomly folds the data in 
5 partitions.
--
Edzer


Zev Ross wrote:
> Hi All,
>
> Thanks to Paul and Alessandro for their suggestions. Paul's code 
> (brute force) worked well for me and the results match up well with 
> ArcGIS. I'm not using a large dataset so the speed isn't an issue but 
> with a larger dataset it would be. In ArcGIS the optimization is 
> instantaneous so clearly the software is doing something different 
> than testing out all possible values.
>
> I used Paul's code with no substantive changes then it's 
> straightforward to use:
>
> plot(idw_pow, cv_vals)
> idw_pow[which.min(cv_vals)]
>
> And pull out the min.
>
> Thanks for the advice! Zev
>
>
>
>
> Alessandro wrote:
>> Hi 
>>
>> Normally I use the R+SAGA to calculate the IDW and create a raster, with
>> this follow code. I change the radius input with a loop formula to create
>> several raster and after check the best result (I am studying a oak forest
>> with low density) 
>>
>> radii.list <- as.list(c(5, 10, 15, 20, 25, 30)) 
>> for(i in 1:length(radii.list)){ 
>> 	rsaga.geoprocessor(lib="grid_gridding", module=0,
>> param=list(GRID=set.file.extension(paste("DEM_iw",radii.list[[i]],sep=""),".
>> sgrd"),
>> 	SHAPES="ground.shp", FIELD=0, TARGET= 0, POWER=1.0,
>> RADIUS=radii.list[[i]], NPOINTS=20, 	USER_CELL_SIZE=dem.pixelsize,
>> USER_X_EXTENT_MIN=ground at bbox[1,1], USER_X_EXTENT_MAX=ground at bbox[1,2],
>> USER_Y_EXTENT_MIN=ground at bbox[2,1], USER_Y_EXTENT_MAX=ground at bbox[2,2])) 
>> } 
>>
>>
>> After I have 6 raster (DEM_idw_5.sgrd, DEM_idw_10.sgrd, DEM_idw_15.sgrd,
>> DEM_idw_20.sgrd, etc. etc.). I check hand-made the best IDW. I don't know is
>> It possible to improve this formula with RMSE in gstat and calculate the
>> best power.
>>
>> Ale
>>
>>
>>
>> -----Messaggio originale-----
>> Da: r-sig-geo-bounces at stat.math.ethz.ch
>> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] Per conto di Paul Hiemstra
>> Inviato: marted? 2 dicembre 2008 12.07
>> A: Zev Ross
>> Cc: r-sig-geo at stat.math.ethz.ch
>> Oggetto: Re: [R-sig-Geo] GSTAT: Optimize power value for IDW
>>
>> Zev Ross schreef:
>>   
>>> Hi All,
>>>
>>> ArcGIS has a nice little button that calculates the optimal power 
>>> value to use for inverse distance weighting based on cross-validation 
>>> and RMSPE. Just wondering if anyone had written something similar in R 
>>> -- I'm using GSTAT and I'd like to avoid back and forth with ArcGIS 
>>> (and obviously I'd like to avoid writing it myself as well!).
>>>
>>> Zev
>>>
>>>     
>> Hi,
>>
>> I don't have any code lying around, but a brute force optimization 
>> approach should be quite easy. Also because the range of idw-powers is 
>> relatively small. The speed would ofcourse depend on the size of the 
>> dataset. In code it would look something like (actually works :)):
>>
>> library(gstat)
>> data(meuse)
>> coordinates(meuse) = ?x+y
>>
>> # make function to do the cv
>> do_cv = function(idp) {
>>   meuse_idw = gstat(id = "zn", formula = zinc?1, data = meuse, set = 
>> list(idp = idp))
>>   out = gstat.cv(meuse_idw)
>>   return(sqrt(mean(out$residual^2))) # RMSE as optimization criterium
>> }
>>
>> idw_pow = seq(0.1,5, by = 0.2) # the idwpower values that will be checked
>> cv_vals = sapply(idw_pow, do_cv) # calculate the rmse
>> # List of outcomes
>> print(data.frame(idp = idw_pow, cv_rmse = cv_vals))
>>
>> After this you select the idw value with the smallest RMSE.
>>
>> cheers and hth,
>> Paul
>>
>>   
>
> -- 
> Zev Ross
> ZevRoss Spatial Analysis
> 120 N Aurora, Suite 3A
> Ithaca, NY 14850
> 607-277-0004 (phone)
> 866-877-3690 (fax, toll-free)
> zev at zevross.com
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de



------------------------------

Message: 6
Date: Wed, 3 Dec 2008 09:29:29 +0000
From: Corrado <ct529 at york.ac.uk>
Subject: [R-sig-Geo] Raster file from ascii file and flattening Africa
	....	:)
To: r-sig-ecology at r-project.org, r-sig-geo at stat.math.ethz.ch
Message-ID: <200812030929.29575.ct529 at york.ac.uk>
Content-Type: text/plain;  charset="utf-8"

Dear friends,

I am a kind of advanced newbie, if that makes sense.

I have a text file of the form

coordinate x,coordinate y,cat={real number between 250 and 450}

where coordinate are expressed in latitude and longitude. The files represents 
measurements of the size of a skulls on sites all over Africa.

>From it, I would like to build a raster file, 100 km by 100km.  There are 2 
problems:

1) Unfortunately,  in some 100km x 100km squares, there is one of the points 
whilst in others there are maybe 20. How do I average, so that in each square 
I only have 1 value representing the average?
 
2) How do we "flatten" Africa so that we may use 100km x 100km squares instead 
of 1 degree x 1 degree, without committing a geographical crime? What we need 
is to respect the areas ....

Best regards and apologies for the silliness of the questions.
-- 
Corrado Topi

Global Climate Change & Biodiversity Indicators
Area 18,Department of Biology
University of York, York, YO10 5YW, UK
Phone: + 44 (0) 1904 328645, E-mail: ct529 at york.ac.uk



------------------------------

Message: 7
Date: Wed, 3 Dec 2008 10:26:14 -0000
From: "Kamran Safi" <Kamran.Safi at ioz.ac.uk>
Subject: Re: [R-sig-Geo] Raster file from ascii file and flattening
	Africa	....:)
To: "Corrado" <ct529 at york.ac.uk>, <r-sig-ecology at r-project.org>,
	<r-sig-geo at stat.math.ethz.ch>
Message-ID: <41E1ED29E5E8E34BBDD8B82CFA1A9D04062E6357 at zsl26>
Content-Type: text/plain;	charset="us-ascii"

Hi Corrado,

Being a advanced newbie myself, I first of all understand what you mean
by that and secondly ask you to qualify my answer.

I would, tackling your problem, create a raster polygon in a metric
equal area projection, such as Mollweide. Then you use overlay() and get
for each polygon the set of points that are within each raster polygon.
You need to import the xyz file in R and convert it into a Spatialpoints
data frame. 

Here's the first bit
This reads a coast line shapefile and extracts africa from it. Then uses
the boundings boxes to produce a grid at the extent of africa. Then it
projects that raster back to longlat for the overlay() procedure. 

map <- readShapePoly("E:/Science/continent.shp", ID="CONTINENT",
proj4string = CRS("+proj=longlat"))
africa <- as.SpatialPolygons.PolygonsList(map at polygons[1])
africa.proj <- spTransform(africa, CRS("+proj=moll"))
grd <- GridTopology(c(bbox(africa.proj)[1,1]+5000,
bbox(africa.proj)[2,1]+50000), c(100000,100000),
c(ceiling((bbox(africa.proj)[1,2] - bbox(africa.proj)[1,1]) /
100000),ceiling((bbox(africa.proj)[1,2] - bbox(africa.proj)[1,1]) /
100000)))

# if you should not have a coastline of africa:
# these are the values you'll need to produce the raster you need to
proceed
# bbox(africa.proj)
#         min     max
# r1 -2472164 6131319
# r2 -4202811 4490010


polys.proj <- as.SpatialPolygons.GridTopology(grd)
proj4string(polys.proj) <- CRS("+proj=moll")
polys <- spTransform(polys.proj, CRS("+proj=longlat"))
# now you have a spatialpolygon in longlat proj that has equal area and
a 
# cell size of 100km2
#prepare a list for you results
results <- rep(NA, length(polys at polygons))
# use something like this to calculate the values per raster grid
# this here is not working probably, as I didn't think about it all too
much
# I have though somewhere a code lying around doing exactly this step,
so if 
# you don't succeed, let me know and I dig that out
for(i in 1:length(polys at polygons))
{
results[i] <- mean(<your spatial
points>$values[which(overlay(as.SpatialPolygons.PolygonsList(map.Proj at po
lygons[i]), <your Spatialpoints>) != NA, ])
}

Apart from the final bits, I tested the start and it worked. The last
bit should not be too difficult to solve. The whole thing could be more
elegant by excluding those polygons that are in the sea. But I think
that is something others can try to get their heads around it. Shouldn't
be too difficult: get the centroid coordinates, overlay it with the
costlines of Africa and convert it back into a grid...

Hope this helped.

Kamran 


------------------------
Kamran Safi

Postdoctoral Research Fellow
Institute of Zoology
Zoological Society of London
Regent's Park
London NW1 4RY

http://www.zoo.cam.ac.uk/ioz/people/safi.htm

http://spatialr.googlepages.com
http://asapi.wetpaint.com

-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Corrado
Sent: 03 December 2008 09:29
To: r-sig-ecology at r-project.org; r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] Raster file from ascii file and flattening Africa
....:)

Dear friends,

I am a kind of advanced newbie, if that makes sense.

I have a text file of the form

coordinate x,coordinate y,cat={real number between 250 and 450}

where coordinate are expressed in latitude and longitude. The files
represents 
measurements of the size of a skulls on sites all over Africa.

>From it, I would like to build a raster file, 100 km by 100km.  There
are 2 
problems:

1) Unfortunately,  in some 100km x 100km squares, there is one of the
points 
whilst in others there are maybe 20. How do I average, so that in each
square 
I only have 1 value representing the average?
 
2) How do we "flatten" Africa so that we may use 100km x 100km squares
instead 
of 1 degree x 1 degree, without committing a geographical crime? What we
need 
is to respect the areas ....

Best regards and apologies for the silliness of the questions.
-- 
Corrado Topi

Global Climate Change & Biodiversity Indicators
Area 18,Department of Biology
University of York, York, YO10 5YW, UK
Phone: + 44 (0) 1904 328645, E-mail: ct529 at york.ac.uk

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo




Click
https://www.mailcontrol.com/sr/wQw0zmjPoHdJTZGyOCrrhg==
rtsaKomrEVtGO6LLtLGhCXg+F32PftV4uyzpFBU8KFm0g==  to report this email as
spam.


The Zoological Society of London is incorporated by Royal Charter
Principal Office England. Company Number RC000749
Registered address: 
Regent's Park, London, England NW1 4RY
Registered Charity in England and Wales no. 208728 

_________________________________________________________________________
This e-mail has been sent in confidence to the named add...{{dropped:15}}



From p.hiemstra at geo.uu.nl  Wed Dec  3 13:16:37 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Wed, 03 Dec 2008 13:16:37 +0100
Subject: [R-sig-Geo] How to pick up cell values of grids using points?
In-Reply-To: <86DBA0678E017341B449A62F258E2956154980@IS-EX-BEV3.unimelb.edu.au>
References: <86DBA0678E017341B449A62F258E2956154980@IS-EX-BEV3.unimelb.edu.au>
Message-ID: <493678A5.3010309@geo.uu.nl>

Hi,

Have a look at the overlay() function in the sp-package.

cheers,
Paul

Yong Li wrote:
> Hi ALL,
>
> I want to pick up cells values of a grid (say a RS image) using points' positions. For example, I have an image and a point shape file with the same coordinate system, then I try to overlay points on the image, and want to get the cell values of the on-point cell and 8 surrounding cells. Could any expert give some tips to solve my problem?
>
> Regards
>
> Yong
>
>
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of r-sig-geo-request at stat.math.ethz.ch
> Sent: 2008?12?3? 22:00
> To: r-sig-geo at stat.math.ethz.ch
> Subject: R-sig-Geo Digest, Vol 64, Issue 3
>
> Send R-sig-Geo mailing list submissions to
> 	r-sig-geo at stat.math.ethz.ch
>
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> or, via email, send a message with subject or body 'help' to
> 	r-sig-geo-request at stat.math.ethz.ch
>
> You can reach the person managing the list at
> 	r-sig-geo-owner at stat.math.ethz.ch
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-Geo digest..."
>
>
> Today's Topics:
>
>    1. GSTAT: Optimize power value for IDW (Zev Ross)
>    2. Re: GSTAT: Optimize power value for IDW (Paul Hiemstra)
>    3. R: GSTAT: Optimize power value for IDW (Paul Hiemstra
>       approach) (Alessandro)
>    4. Re: R: GSTAT: Optimize power value for IDW (Paul Hiemstra
>       approach) (Zev Ross)
>    5. Re: R: GSTAT: Optimize power value for IDW (Paul Hiemstra
>       approach) (Edzer Pebesma)
>    6. Raster file from ascii file and flattening Africa ....	:)
>       (Corrado)
>    7. Re: Raster file from ascii file and flattening Africa	....:)
>       (Kamran Safi)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Tue, 02 Dec 2008 13:59:47 -0500
> From: Zev Ross <zev at zevross.com>
> Subject: [R-sig-Geo] GSTAT: Optimize power value for IDW
> To: r-sig-geo at stat.math.ethz.ch
> Message-ID: <493585A3.2040909 at zevross.com>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> Hi All,
>
> ArcGIS has a nice little button that calculates the optimal power value 
> to use for inverse distance weighting based on cross-validation and 
> RMSPE. Just wondering if anyone had written something similar in R -- 
> I'm using GSTAT and I'd like to avoid back and forth with ArcGIS (and 
> obviously I'd like to avoid writing it myself as well!).
>
> Zev
>
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul



From p.hiemstra at geo.uu.nl  Wed Dec  3 13:31:38 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Wed, 03 Dec 2008 13:31:38 +0100
Subject: [R-sig-Geo] GSTAT: Optimize power value for IDW
In-Reply-To: <493585A3.2040909@zevross.com>
References: <493585A3.2040909@zevross.com>
Message-ID: <49367C2A.8060605@geo.uu.nl>

Zev Ross wrote:
> Hi All,
>
> ArcGIS has a nice little button that calculates the optimal power 
> value to use for inverse distance weighting based on cross-validation 
> and RMSPE. Just wondering if anyone had written something similar in R 
> -- I'm using GSTAT and I'd like to avoid back and forth with ArcGIS 
> (and obviously I'd like to avoid writing it myself as well!).
>
> Zev
>
Hi Zev,

It seems to me that you want to perform some kind of optimal automatic 
interpolation. As an alternative to the methods presented by Alessandro, 
Edzer and myself you could try the automap package I wrote for my PhD. 
It provides a means of automatically performing kriging (in my view 
superior to IDW, for example it takes clustering of observations into 
account; it provides an estimate of prediction uncertainty). The package 
is not yet available from CRAN, but the latest version can be downloaded 
from my website:

http://intamap.geo.uu.nl/~paul/Downloads.html

There is a .zip binary file for Windows and a .tar.gz file for Linux. 
After loading the package, the command demo(automap) will give you a 
good impression of the package. Any feedback on the documentation and 
structure of the package is most welcome.

cheers,
Paul

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul



From aloboaleu at gmail.com  Wed Dec  3 14:22:34 2008
From: aloboaleu at gmail.com (Agustin Lobo)
Date: Wed, 03 Dec 2008 14:22:34 +0100
Subject: [R-sig-Geo] readOGR and non-ascii characters
Message-ID: <4936881A.7030803@gmail.com>

Hi!

I have problems at reading a shp file with readOGR(), names with
non-ascii characters (accents ',`) in the dbf table are imported as i.e.
Barber\x85 del Vall\x8as

while I can read them fine with OpenOffice Calc

Is there any way I can state the character set of the dbf file in readOGR()?

Thanks

Agus

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From friendly at yorku.ca  Wed Dec  3 15:33:38 2008
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 03 Dec 2008 09:33:38 -0500
Subject: [R-sig-Geo] overlay 1D graph on a map or map image: van Langren data
Message-ID: <493698C2.3010903@yorku.ca>

Hi
I'm working with some historical data on determinations of longitude 
used by Michael F van Langren
in 1644 to draw what is believed to be the first graph of statistical 
data. The values are estimates
of the distance in longitude between Toledo and Rome.

G. Iansonius      17.736  1501  Jan Jansson              Flanders    
[1588-1664] sb:~ 1615
G. Mercator       19.872  1567  Gerardus Mercator        Flanders
I. Schonerus      20.638  1536  Johann Sch?ner           Germany
P. Lantsbergius   21.106  1530  Phillip van Lansberge    Belgium
T. Brahe          21.447  1578  Tycho Brahe              Denmark
I. Regiomontanus  25.617  1471  Johann Muller            Germany      
[1436-1476] sb: 1463
Orontius          26.000  1542  Oronce Fin?              France       
[1494-1555] 
C. Clavius        26.340  1567  Christoph Clavius        Germany  
C. Ptolomeus      27.787   150  Claudius Ptolemaeus      Alexandria
A. Argelius       28.170  1610  Andrea Argoli            Italy        
sb: 1610
A. Maginus        29.787  1582  Giovanni Antonio Magini  Italy
D. Origanus       30.128  1601  David Origanus           Germany

I want to show these overlaid on a map, something like the following:

http://euclid.psych.yorku.ca/SCS/Gallery/images/Private/Langren/langren-google-overlay.jpg

using *either* a jpeg image,
http://euclid.psych.yorku.ca/SCS/Gallery/images/Private/Langren/google-toledo-rome3.jpg
or a comparable portion of the world map, something like

# approximate coordinates of the BBox of this map
bbox <- c( 38.186, -9.184,
           43.692, 28.674 )
bbox <- matrix(bbox, 2, 2, byrow=TRUE)
map("world", xlim=bbox[,2], ylim=bbox[,1], fill=TRUE, col=colors())
map.axes()

I created the overlay by manually rescaling and calibrating his graph 
with a portion of a Google map.
But I'd like to be able to do this more exactly in R, possibly using 
other data.

I can read in  the data as follows:

langren <- 
read.csv("http://euclid.psych.yorku.ca/SCS/Gallery/Private/langrens.csv", 
header=TRUE)

# Lat/Long of Toledo & Rome, from Google map

toledo <- c(39.86, -4.03)
rome   <- c(41.89, 12.5)

# locations of the estimates, converted to lat, long
locations <- cbind( rep(rome[1], 12), toledo[2] + langren$long)
rownames(locations) <- langren$name
locations <- rbind( toledo, locations)
colnames(locations) <- c("lat", "long")

The above steps give:

locations <-
structure(c(39.86, 41.89, 41.89, 41.89, 41.89, 41.89, 41.89,
41.89, 41.89, 41.89, 41.89, 41.89, 41.89, -4.03, 13.706, 15.842,
16.608, 17.076, 17.417, 21.587, 21.97, 22.31, 23.757, 24.14,
25.757, 26.098), .Dim = c(13L, 2L), .Dimnames = list(c("toledo",
"G. Iansonius", "G. Mercator", "I. Schonerus", "P. Lantsbergius",
"T. Brahe", "I. Regiomontanus", "Orontius", "C. Clavius", "C. Ptolomeus",
"A. Argelius", "A. Maginus", "D. Origanus"), c("lat", "long")))

I can also read the .jpg Google map image, at least from a local file:

# read the google image
library(rimage)
gimage <- 
read.jpeg("C:/Documents/milestone/images/vanLangren/google-toledo-rome3.jpg")

#gimageloc <- 
"http://euclid.psych.yorku.ca/SCS/Gallery/images/Private/Langren/google-toledo-rome3.jpg"
#dest <- paste(tempfile(),'.jpg', sep='')
#download.file(gimageloc, dest)
#  why doesn't this work?
#gimage <- read.jpeg(dest)

plot(gimage)
# approx  pixel coordinates of Toledo and Rome in the image, measured 
from the *top left* corner as (0,0)
toledo.map <- c(130, 119)
rome.map <-(505, 59)

Here's where I'm stumped.  How can I recreate a version of van Langren's 
graph shown on top of
either the gimage or on top of the portion of the R world map?

thanks
-Michael

-- 
Michael Friendly     Email: friendly AT yorku DOT ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



From h.wickham at gmail.com  Wed Dec  3 16:02:34 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 3 Dec 2008 09:02:34 -0600
Subject: [R-sig-Geo] overlay 1D graph on a map or map image: van Langren
	data
In-Reply-To: <493698C2.3010903@yorku.ca>
References: <493698C2.3010903@yorku.ca>
Message-ID: <f8e6ff050812030702q797c8026r50dc01da14253099@mail.gmail.com>

On Wed, Dec 3, 2008 at 8:33 AM, Michael Friendly <friendly at yorku.ca> wrote:
> Hi
> I'm working with some historical data on determinations of longitude used by
> Michael F van Langren
> in 1644 to draw what is believed to be the first graph of statistical data.
> The values are estimates
> of the distance in longitude between Toledo and Rome.
>
> G. Iansonius      17.736  1501  Jan Jansson              Flanders
>  [1588-1664] sb:~ 1615
> G. Mercator       19.872  1567  Gerardus Mercator        Flanders
> I. Schonerus      20.638  1536  Johann Sch?ner           Germany
> P. Lantsbergius   21.106  1530  Phillip van Lansberge    Belgium
> T. Brahe          21.447  1578  Tycho Brahe              Denmark
> I. Regiomontanus  25.617  1471  Johann Muller            Germany
>  [1436-1476] sb: 1463
> Orontius          26.000  1542  Oronce Fin?              France
> [1494-1555] C. Clavius        26.340  1567  Christoph Clavius        Germany
>  C. Ptolomeus      27.787   150  Claudius Ptolemaeus      Alexandria
> A. Argelius       28.170  1610  Andrea Argoli            Italy        sb:
> 1610
> A. Maginus        29.787  1582  Giovanni Antonio Magini  Italy
> D. Origanus       30.128  1601  David Origanus           Germany
>
> I want to show these overlaid on a map, something like the following:
>
> http://euclid.psych.yorku.ca/SCS/Gallery/images/Private/Langren/langren-google-overlay.jpg
>
> using *either* a jpeg image,
> http://euclid.psych.yorku.ca/SCS/Gallery/images/Private/Langren/google-toledo-rome3.jpg
> or a comparable portion of the world map, something like
>
> # approximate coordinates of the BBox of this map
> bbox <- c( 38.186, -9.184,
>          43.692, 28.674 )
> bbox <- matrix(bbox, 2, 2, byrow=TRUE)
> map("world", xlim=bbox[,2], ylim=bbox[,1], fill=TRUE, col=colors())
> map.axes()
>
> I created the overlay by manually rescaling and calibrating his graph with a
> portion of a Google map.
> But I'd like to be able to do this more exactly in R, possibly using other
> data.
>
> I can read in  the data as follows:
>
> langren <-
> read.csv("http://euclid.psych.yorku.ca/SCS/Gallery/Private/langrens.csv",
> header=TRUE)
>
> # Lat/Long of Toledo & Rome, from Google map
>
> toledo <- c(39.86, -4.03)
> rome   <- c(41.89, 12.5)
>
> # locations of the estimates, converted to lat, long
> locations <- cbind( rep(rome[1], 12), toledo[2] + langren$long)
> rownames(locations) <- langren$name
> locations <- rbind( toledo, locations)
> colnames(locations) <- c("lat", "long")
>
> The above steps give:
>
> locations <-
> structure(c(39.86, 41.89, 41.89, 41.89, 41.89, 41.89, 41.89,
> 41.89, 41.89, 41.89, 41.89, 41.89, 41.89, -4.03, 13.706, 15.842,
> 16.608, 17.076, 17.417, 21.587, 21.97, 22.31, 23.757, 24.14,
> 25.757, 26.098), .Dim = c(13L, 2L), .Dimnames = list(c("toledo",
> "G. Iansonius", "G. Mercator", "I. Schonerus", "P. Lantsbergius",
> "T. Brahe", "I. Regiomontanus", "Orontius", "C. Clavius", "C. Ptolomeus",
> "A. Argelius", "A. Maginus", "D. Origanus"), c("lat", "long")))
>
> I can also read the .jpg Google map image, at least from a local file:
>
> # read the google image
> library(rimage)
> gimage <-
> read.jpeg("C:/Documents/milestone/images/vanLangren/google-toledo-rome3.jpg")
>
> #gimageloc <-
> "http://euclid.psych.yorku.ca/SCS/Gallery/images/Private/Langren/google-toledo-rome3.jpg"
> #dest <- paste(tempfile(),'.jpg', sep='')
> #download.file(gimageloc, dest)
> #  why doesn't this work?
> #gimage <- read.jpeg(dest)
>
> plot(gimage)
> # approx  pixel coordinates of Toledo and Rome in the image, measured from
> the *top left* corner as (0,0)
> toledo.map <- c(130, 119)
> rome.map <-(505, 59)
>
> Here's where I'm stumped.  How can I recreate a version of van Langren's
> graph shown on top of
> either the gimage or on top of the portion of the R world map?

Here's a quick start using ggplot2 - one trick to make the map look
nicer is to use a bigger range when calling map, and then adjust the
limits of the plot to zoom in on the region of interest.

library(maps)
library(ggplot2)

langren <- read.csv("http://euclid.psych.yorku.ca/SCS/Gallery/Private/langrens.csv",
header=TRUE)

bbox <- c( 38.186, -9.184,
         43.692, 28.674 )
bbox <- matrix(bbox, 2, 2, byrow=TRUE)

borders <- as.data.frame(map("world", plot = F,
  xlim = expand_range(bbox[,2], 0.2),
  ylim = expand_range(bbox[,1], 0.2))[c("x", "y")])

data(world.cities)
cities <- subset(world.cities,
  name %in% c("Rome", "Toledo") & country.etc %in% c("Spain", "Italy"))

ggplot(langren, aes(long, lat)) +
  geom_path(aes(x, y), borders, colour = "grey60") +
  geom_point(y = 40) +
  geom_text(aes(label = name), y = 40.1, angle = 90, hjust = 0, size = 3) +
  geom_point(data = cities, colour = "red", size = 2) +
  coord_cartesian(xlim=bbox[,2], ylim=bbox[,1])

Regards,

Hadley

-- 
http://had.co.nz/



From friendly at yorku.ca  Wed Dec  3 16:44:00 2008
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 03 Dec 2008 10:44:00 -0500
Subject: [R-sig-Geo] overlay 1D graph on a map or map image: van Langren
 data
In-Reply-To: <f8e6ff050812030702q797c8026r50dc01da14253099@mail.gmail.com>
References: <493698C2.3010903@yorku.ca>
	<f8e6ff050812030702q797c8026r50dc01da14253099@mail.gmail.com>
Message-ID: <4936A940.5030408@yorku.ca>

hadley wickham wrote:
>
> Here's a quick start using ggplot2 - one trick to make the map look
> nicer is to use a bigger range when calling map, and then adjust the
> limits of the plot to zoom in on the region of interest.
>
> library(maps)
> library(ggplot2)
>
> langren <- read.csv("http://euclid.psych.yorku.ca/SCS/Gallery/Private/langrens.csv",
> header=TRUE)
>
> bbox <- c( 38.186, -9.184,
>          43.692, 28.674 )
> bbox <- matrix(bbox, 2, 2, byrow=TRUE)
>
> borders <- as.data.frame(map("world", plot = F,
>   xlim = expand_range(bbox[,2], 0.2),
>   ylim = expand_range(bbox[,1], 0.2))[c("x", "y")])
>
> data(world.cities)
> cities <- subset(world.cities,
>   name %in% c("Rome", "Toledo") & country.etc %in% c("Spain", "Italy"))
>
> ggplot(langren, aes(long, lat)) +
>   geom_path(aes(x, y), borders, colour = "grey60") +
>   geom_point(y = 40) +
>   geom_text(aes(label = name), y = 40.1, angle = 90, hjust = 0, size = 3) +
>   geom_point(data = cities, colour = "red", size = 2) +
>   coord_cartesian(xlim=bbox[,2], ylim=bbox[,1])
>
>   
Thanks very much, Hadley.  However, it doesn't work for me, using 
ggplot2_0.7, even when adding

langren$lat <- 39.68


 > ggplot(langren, aes(long, lat)) +
+   geom_path(aes(x, y), borders, colour = "grey60") +
+   geom_point(y = 40) +
+   geom_text(aes(label = name), y = 40.1, angle = 90, hjust = 0, size = 
3) +
+   geom_point(data = cities, colour = "red", size = 2) +
+   coord_cartesian(xlim=bbox[,2], ylim=bbox[,1])
Error in get("new", env = CoordCartesian, inherits = 
TRUE)(CoordCartesian,  :
  unused argument(s) (xlim = c(-9.184, 28.674), ylim = c(38.186, 43.692))

Eliminating the last line (coord_caertesian) gives a different error,  
and just the first gives

 > ggplot(langren, aes(long, lat))
Error: No layers in plot


 > sessionInfo()
R version 2.8.0 (2008-10-20)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=English_United 
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] splines   grid      stats     graphics  grDevices utils     
datasets  methods 
[9] base    

other attached packages:
[1] ggplot2_0.7        MASS_7.2-44        RColorBrewer_1.0-2 
proto_0.3-8      
[5] reshape_0.8.2      plyr_0.1.3         rimage_0.5-7       
foreign_0.8-29   
[9] maps_2.0-40      
 ...



-- 
Michael Friendly     Email: friendly AT yorku DOT ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA




From h.wickham at gmail.com  Wed Dec  3 17:00:03 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 3 Dec 2008 10:00:03 -0600
Subject: [R-sig-Geo] overlay 1D graph on a map or map image: van Langren
	data
In-Reply-To: <4936A940.5030408@yorku.ca>
References: <493698C2.3010903@yorku.ca>
	<f8e6ff050812030702q797c8026r50dc01da14253099@mail.gmail.com>
	<4936A940.5030408@yorku.ca>
Message-ID: <f8e6ff050812030800w16a85bem8636a5d538c08ed8@mail.gmail.com>

> Thanks very much, Hadley.  However, it doesn't work for me, using
> ggplot2_0.7, even when adding

I'm not surprised - you'll need version 0.8

Hadley

-- 
http://had.co.nz/



From Greg.Snow at imail.org  Wed Dec  3 17:41:53 2008
From: Greg.Snow at imail.org (Greg Snow)
Date: Wed, 3 Dec 2008 09:41:53 -0700
Subject: [R-sig-Geo] overlay 1D graph on a map or map image: van Langren
 data
In-Reply-To: <493698C2.3010903@yorku.ca>
References: <493698C2.3010903@yorku.ca>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61C2F3DE19@LP-EXMBVS10.CO.IHC.COM>

Michael,

Using base graphics, the rimage package has a function for reading jpg files and plotting them and the subplot function from the TeachingDemos package could be used to place the plot on top of the image (the updateusr function in TeachingDemos may also help if you want to change the coordinate system for the map after plotting).

Hope this helps,

--
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-
> bounces at stat.math.ethz.ch] On Behalf Of Michael Friendly
> Sent: Wednesday, December 03, 2008 7:34 AM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] overlay 1D graph on a map or map image: van
> Langren data
>
> Hi
> I'm working with some historical data on determinations of longitude
> used by Michael F van Langren
> in 1644 to draw what is believed to be the first graph of statistical
> data. The values are estimates
> of the distance in longitude between Toledo and Rome.
>
> G. Iansonius      17.736  1501  Jan Jansson              Flanders
> [1588-1664] sb:~ 1615
> G. Mercator       19.872  1567  Gerardus Mercator        Flanders
> I. Schonerus      20.638  1536  Johann Sch?ner           Germany
> P. Lantsbergius   21.106  1530  Phillip van Lansberge    Belgium
> T. Brahe          21.447  1578  Tycho Brahe              Denmark
> I. Regiomontanus  25.617  1471  Johann Muller            Germany
> [1436-1476] sb: 1463
> Orontius          26.000  1542  Oronce Fin?              France
> [1494-1555]
> C. Clavius        26.340  1567  Christoph Clavius        Germany
> C. Ptolomeus      27.787   150  Claudius Ptolemaeus      Alexandria
> A. Argelius       28.170  1610  Andrea Argoli            Italy
> sb: 1610
> A. Maginus        29.787  1582  Giovanni Antonio Magini  Italy
> D. Origanus       30.128  1601  David Origanus           Germany
>
> I want to show these overlaid on a map, something like the following:
>
> http://euclid.psych.yorku.ca/SCS/Gallery/images/Private/Langren/langren
> -google-overlay.jpg
>
> using *either* a jpeg image,
> http://euclid.psych.yorku.ca/SCS/Gallery/images/Private/Langren/google-
> toledo-rome3.jpg
> or a comparable portion of the world map, something like
>
> # approximate coordinates of the BBox of this map
> bbox <- c( 38.186, -9.184,
>            43.692, 28.674 )
> bbox <- matrix(bbox, 2, 2, byrow=TRUE)
> map("world", xlim=bbox[,2], ylim=bbox[,1], fill=TRUE, col=colors())
> map.axes()
>
> I created the overlay by manually rescaling and calibrating his graph
> with a portion of a Google map.
> But I'd like to be able to do this more exactly in R, possibly using
> other data.
>
> I can read in  the data as follows:
>
> langren <-
> read.csv("http://euclid.psych.yorku.ca/SCS/Gallery/Private/langrens.csv
> ",
> header=TRUE)
>
> # Lat/Long of Toledo & Rome, from Google map
>
> toledo <- c(39.86, -4.03)
> rome   <- c(41.89, 12.5)
>
> # locations of the estimates, converted to lat, long
> locations <- cbind( rep(rome[1], 12), toledo[2] + langren$long)
> rownames(locations) <- langren$name
> locations <- rbind( toledo, locations)
> colnames(locations) <- c("lat", "long")
>
> The above steps give:
>
> locations <-
> structure(c(39.86, 41.89, 41.89, 41.89, 41.89, 41.89, 41.89,
> 41.89, 41.89, 41.89, 41.89, 41.89, 41.89, -4.03, 13.706, 15.842,
> 16.608, 17.076, 17.417, 21.587, 21.97, 22.31, 23.757, 24.14,
> 25.757, 26.098), .Dim = c(13L, 2L), .Dimnames = list(c("toledo",
> "G. Iansonius", "G. Mercator", "I. Schonerus", "P. Lantsbergius",
> "T. Brahe", "I. Regiomontanus", "Orontius", "C. Clavius", "C.
> Ptolomeus",
> "A. Argelius", "A. Maginus", "D. Origanus"), c("lat", "long")))
>
> I can also read the .jpg Google map image, at least from a local file:
>
> # read the google image
> library(rimage)
> gimage <-
> read.jpeg("C:/Documents/milestone/images/vanLangren/google-toledo-
> rome3.jpg")
>
> #gimageloc <-
> "http://euclid.psych.yorku.ca/SCS/Gallery/images/Private/Langren/google
> -toledo-rome3.jpg"
> #dest <- paste(tempfile(),'.jpg', sep='')
> #download.file(gimageloc, dest)
> #  why doesn't this work?
> #gimage <- read.jpeg(dest)
>
> plot(gimage)
> # approx  pixel coordinates of Toledo and Rome in the image, measured
> from the *top left* corner as (0,0)
> toledo.map <- c(130, 119)
> rome.map <-(505, 59)
>
> Here's where I'm stumped.  How can I recreate a version of van
> Langren's
> graph shown on top of
> either the gimage or on top of the portion of the R world map?
>
> thanks
> -Michael
>
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept.
> York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
> 4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
> Toronto, ONT  M3J 1P3 CANADA
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From izareis at dpi.inpe.br  Wed Dec  3 20:03:16 2008
From: izareis at dpi.inpe.br (izareis at dpi.inpe.br)
Date: Wed, 03 Dec 2008 17:03:16 -0200
Subject: [R-sig-Geo] Multi-level analysis
Message-ID: <20081203170316.ip54pct38kcgs8s0@agenda.dpi.inpe.br>


Hi

How I do a multi-level analysis in R?

Thanks

Izabel Reis



----------------------------------------------------------------
This message was sent using IMP, the Internet Messaging Program.



From Virgilio.Gomez at uclm.es  Wed Dec  3 20:54:43 2008
From: Virgilio.Gomez at uclm.es (Virgilio Gomez Rubio)
Date: Wed, 03 Dec 2008 19:54:43 +0000
Subject: [R-sig-Geo] Multi-level analysis
In-Reply-To: <20081203170316.ip54pct38kcgs8s0@agenda.dpi.inpe.br>
References: <20081203170316.ip54pct38kcgs8s0@agenda.dpi.inpe.br>
Message-ID: <1228334083.7524.9.camel@Virgilio-Gomez>

Hi,


> How I do a multi-level analysis in R?

This is a non-spatial question but you can use package nlme and lme4 for
that. If you want to try a Bayesian approach, you can use WinBUGS
through R2WinBUGS. You can also find some packages related to multilevel
analysis in the list of packages at CRAN (just look for 'multilevel').

Best,

Virgilio



From pisicandru at hotmail.com  Wed Dec  3 22:50:07 2008
From: pisicandru at hotmail.com (Monica Pisica)
Date: Wed, 3 Dec 2008 21:50:07 +0000
Subject: [R-sig-Geo] merging multiscale data
Message-ID: <BAY104-W4018DFBB6DE86352485E93C3030@phx.gbl>


Hi everybody,
 
I am very much interested in hearing what is your experience with merging different scale data to obtain a uniform surface at the finest scale possible, and if not at the most optimum scale. Now I know that "optimum" is in the eye of the beholder, but maybe we can agree on a definition of optimum scale.
 
Anyway, suppose I have an area (any area) for which I have several sets of data, raster and vector, at different scales and different spatial extents. Some overlap, some not, but the whole area is rather covered by data. Also suppose that all datasets are in the same datum / projection, so we are not concerned about it. How do I get about to merge all of that??? 
 
One idea might be to transform everything in xyz coordinates and interpolate the area and get different surfaces for different resolutions and compare the RMSE and choose the one with the smallest RMSE. Is that an option??? What about if I know the accuracy of each dataset ?. How error will propagate then? What if the area is so big that the computer I work on will not be able to do the interpolation, so I will be forced to work on tiles, how do I elliminate the border differences? 
 
If you have any opinion or any good reference to work with I will really appreciate.
 
Thanks,
 
Monica
_________________________________________________________________
Send e-mail anywhere. No map, no compass.
http://windowslive.com/Explore/hotmail?ocid=TXT_TAGLM_WL_hotmail_acq_anywhere_122008
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081203/4968c5ca/attachment.html>

From alessandro.montaghi at unifi.it  Thu Dec  4 00:35:00 2008
From: alessandro.montaghi at unifi.it (Alessandro)
Date: Wed, 3 Dec 2008 15:35:00 -0800
Subject: [R-sig-Geo] how create grid raster with 0.5 size of resolution
Message-ID: <002501c9559f$c4963870$4dc2a950$@montaghi@unifi.it>

Hi R- Reserchers

 

To improve my analysis i need a raster with 0.5 x 0.5 of resolution.

 

I use this code but I tried several solution to find the right command to
obtain 0.5x0.5 resolution

 

Thanks 

Ale 

 

 

> dem.area <-
(ground at bbox[1,2]-ground at bbox[1,1])*(ground at bbox[2,2]-ground at bbox[2,1]) #A#
makes the dem area

> dem.pixelsize <- round(sqrt(dem.area/length(ground$Z)),0) #A# makes the
cell size

> dem.pixelsize

[1] 1

> dem.grid <-
GridTopology(cellcentre.offset=c(ground at bbox[1,1],ground at bbox[2,1]),
cellsize=c(dem.pixelsize,dem.pixelsize),
cells.dim=c(round((ground at bbox[1,2]-ground at bbox[1,1])/dem.pixelsize,0),round
((ground at bbox[2,2]-ground at bbox[2,1])/dem.pixelsize,0)))

> dem.grid

                        X1      X2

cellcentre.offset 267586.6 4147061

cellsize               1.0       1

cells.dim           1405.0     829

> dem <- as(SpatialGrid(dem.grid, proj4string = CRS(as.character(NA))),
"SpatialGridDataFrame")

> ID <- as.factor(1:(dem.grid at cells.dim[1]*dem.grid at cells.dim[2]))

> dem at data <- as.data.frame(ID)

> proj4string(dem) <- CRS("+init=epsg:26911")

> str(dem["ID"])

Formal class 'SpatialGridDataFrame' [package "sp"] with 6 slots

  ..@ data       :'data.frame': 1164745 obs. of  1 variable:

  .. ..$ ID: Factor w/ 1164745 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8 9
10 ...

  ..@ grid       :Formal class 'GridTopology' [package "sp"] with 3 slots

  .. .. ..@ cellcentre.offset: num [1:2]  267587 4147061

  .. .. ..@ cellsize         : num [1:2] 1 1

  .. .. ..@ cells.dim        : int [1:2] 1405 829

  ..@ grid.index : int(0) 

  ..@ coords     : num [1:2, 1:2]  267587  268991 4147061 4147889

  .. ..- attr(*, "dimnames")=List of 2

  .. .. ..$ : NULL

  .. .. ..$ : chr [1:2] "coords.x1" "coords.x2"

  ..@ bbox       : num [1:2, 1:2]  267586 4147060  268991 4147889

  .. ..- attr(*, "dimnames")=List of 2

  .. .. ..$ : chr [1:2] "coords.x1" "coords.x2"

  .. .. ..$ : chr [1:2] "min" "max"

  ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots

  .. .. ..@ projargs: chr " +init=epsg:26911 +proj=utm +zone=11 +ellps=GRS80
+datum=NAD83 +units=m +no_defs +towgs84=0,0,0"

> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081203/30fe3cbd/attachment.html>

From opheliawang at mail.utexas.edu  Thu Dec  4 07:17:50 2008
From: opheliawang at mail.utexas.edu (Ophelia Wang)
Date: Thu, 04 Dec 2008 00:17:50 -0600
Subject: [R-sig-Geo] How to obtain individual values of transformed Ripley's
	function	local L(r) at a fixed distance r?
Message-ID: <20081204001750.bexelfi39c0wg0so@new.webmail.utexas.edu>

Hi all,

I am using the spatstat package in R to compute local L function, the  
transformed Ripley's k. I am interested in getting the estimated local  
L(r) value for each data point at a fixed distance r. I know I can run  
localL and then generate a plot to show an overall pattern of all the  
data points combined, but is there a way to get these local L(r)  
estimate values so they can be copied or exported into a table? Thanks  
a lot!

Ophelia
-- 
Yung-Ho (Ophelia) Wang
Doctoral Candidate
Department of Geography and the Environment
University of Texas
+1-512-232-1597
opheliawang at mail.utexas.edu



From opheliawang at mail.utexas.edu  Thu Dec  4 07:51:12 2008
From: opheliawang at mail.utexas.edu (Ophelia Wang)
Date: Thu, 04 Dec 2008 00:51:12 -0600
Subject: [R-sig-Geo] How to obtain individual values of transformed
	Ripley's	function local L(r) at a fixed distance r?
In-Reply-To: <20081204001750.bexelfi39c0wg0so@new.webmail.utexas.edu>
References: <20081204001750.bexelfi39c0wg0so@new.webmail.utexas.edu>
Message-ID: <20081204005112.ffclupsqtwcwo0ck@new.webmail.utexas.edu>

Hi again,

To be more specific, my question is: I get an output as a list of  
values labeled from 1 to 600 (let's say I
have 600 data points), but I am not sure how these labeled numbers are  
generated. Is
there a way to know how these labels correspond to my data points, or  
do they just
correspond to the order of my data points when they are read by R?--

Ophelia

Quoting Ophelia Wang <opheliawang at mail.utexas.edu>:

> Hi all,
>
> I am using the spatstat package in R to compute local L function, the
> transformed Ripley's k. I am interested in getting the estimated local
> L(r) value for each data point at a fixed distance r. I know I can run
> localL and then generate a plot to show an overall pattern of all the
> data points combined, but is there a way to get these local L(r)
> estimate values so they can be copied or exported into a table? Thanks
> a lot!
>
> Ophelia
> -- 
>



From Roger.Bivand at nhh.no  Thu Dec  4 08:18:15 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 4 Dec 2008 08:18:15 +0100 (CET)
Subject: [R-sig-Geo] How to obtain individual values of transformed
 Ripley's	function local L(r) at a fixed distance r?
In-Reply-To: <20081204005112.ffclupsqtwcwo0ck@new.webmail.utexas.edu>
References: <20081204001750.bexelfi39c0wg0so@new.webmail.utexas.edu>
	<20081204005112.ffclupsqtwcwo0ck@new.webmail.utexas.edu>
Message-ID: <alpine.LRH.2.00.0812040812110.11827@reclus.nhh.no>

On Thu, 4 Dec 2008, Ophelia Wang wrote:

> Hi again,
>
> To be more specific, my question is: I get an output as a list of values 
> labeled from 1 to 600 (let's say I
> have 600 data points), but I am not sure how these labeled numbers are 
> generated. Is
> there a way to know how these labels correspond to my data points, or do they 
> just
> correspond to the order of my data points when they are read by R?--

Try the examples:

library(spatstat)
data(ponderosa)
X <- ponderosa
L <- localL(X)
r206 <- L$r[206]
L12a <- sapply(L, function(x) x[206])[1:108]
names(L12a) <- NULL
L12 <- localL(X, rvalue=r206)
all.equal(L12, L12a)

The values of L12 are in the same order as the points in X. I can't see 
that any re-ordering is occurring.

Hope this helps,

Roger


>
> Ophelia
>
> Quoting Ophelia Wang <opheliawang at mail.utexas.edu>:
>
>> Hi all,
>> 
>> I am using the spatstat package in R to compute local L function, the
>> transformed Ripley's k. I am interested in getting the estimated local
>> L(r) value for each data point at a fixed distance r. I know I can run
>> localL and then generate a plot to show an overall pattern of all the
>> data points combined, but is there a way to get these local L(r)
>> estimate values so they can be copied or exported into a table? Thanks
>> a lot!
>> 
>> Ophelia
>> -- 
>> 
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ct529 at york.ac.uk  Thu Dec  4 12:36:35 2008
From: ct529 at york.ac.uk (Corrado)
Date: Thu, 4 Dec 2008 11:36:35 +0000
Subject: [R-sig-Geo] Raster file from ascii file and flattening Africa
	....:)
In-Reply-To: <41E1ED29E5E8E34BBDD8B82CFA1A9D04062E6357@zsl26>
References: <200812030929.29575.ct529@york.ac.uk>
	<41E1ED29E5E8E34BBDD8B82CFA1A9D04062E6357@zsl26>
Message-ID: <200812041136.35956.ct529@york.ac.uk>

Thanks a lot Kamran!

I will test your approach and let you know ....

On Wednesday 03 December 2008 10:26:14 Kamran Safi wrote:
> Hi Corrado,
>
> Being a advanced newbie myself, I first of all understand what you mean
> by that and secondly ask you to qualify my answer.
>
> I would, tackling your problem, create a raster polygon in a metric
> equal area projection, such as Mollweide. Then you use overlay() and get
> for each polygon the set of points that are within each raster polygon.
> You need to import the xyz file in R and convert it into a Spatialpoints
> data frame.
>
> Here's the first bit
> This reads a coast line shapefile and extracts africa from it. Then uses
> the boundings boxes to produce a grid at the extent of africa. Then it
> projects that raster back to longlat for the overlay() procedure.
>
> map <- readShapePoly("E:/Science/continent.shp", ID="CONTINENT",
> proj4string = CRS("+proj=longlat"))
> africa <- as.SpatialPolygons.PolygonsList(map at polygons[1])
> africa.proj <- spTransform(africa, CRS("+proj=moll"))
> grd <- GridTopology(c(bbox(africa.proj)[1,1]+5000,
> bbox(africa.proj)[2,1]+50000), c(100000,100000),
> c(ceiling((bbox(africa.proj)[1,2] - bbox(africa.proj)[1,1]) /
> 100000),ceiling((bbox(africa.proj)[1,2] - bbox(africa.proj)[1,1]) /
> 100000)))
>
> # if you should not have a coastline of africa:
> # these are the values you'll need to produce the raster you need to
> proceed
> # bbox(africa.proj)
> #         min     max
> # r1 -2472164 6131319
> # r2 -4202811 4490010
>
>
> polys.proj <- as.SpatialPolygons.GridTopology(grd)
> proj4string(polys.proj) <- CRS("+proj=moll")
> polys <- spTransform(polys.proj, CRS("+proj=longlat"))
> # now you have a spatialpolygon in longlat proj that has equal area and
> a
> # cell size of 100km2
> #prepare a list for you results
> results <- rep(NA, length(polys at polygons))
> # use something like this to calculate the values per raster grid
> # this here is not working probably, as I didn't think about it all too
> much
> # I have though somewhere a code lying around doing exactly this step,
> so if
> # you don't succeed, let me know and I dig that out
> for(i in 1:length(polys at polygons))
> {
> results[i] <- mean(<your spatial
> points>$values[which(overlay(as.SpatialPolygons.PolygonsList(map.Proj at po
> lygons[i]), <your Spatialpoints>) != NA, ])
> }
>
> Apart from the final bits, I tested the start and it worked. The last
> bit should not be too difficult to solve. The whole thing could be more
> elegant by excluding those polygons that are in the sea. But I think
> that is something others can try to get their heads around it. Shouldn't
> be too difficult: get the centroid coordinates, overlay it with the
> costlines of Africa and convert it back into a grid...
>
> Hope this helped.
>
> Kamran
>
>
> ------------------------
> Kamran Safi
>
> Postdoctoral Research Fellow
> Institute of Zoology
> Zoological Society of London
> Regent's Park
> London NW1 4RY
>
> http://www.zoo.cam.ac.uk/ioz/people/safi.htm
>
> http://spatialr.googlepages.com
> http://asapi.wetpaint.com
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Corrado
> Sent: 03 December 2008 09:29
> To: r-sig-ecology at r-project.org; r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] Raster file from ascii file and flattening Africa
> ....:)
>
> Dear friends,
>
> I am a kind of advanced newbie, if that makes sense.
>
> I have a text file of the form
>
> coordinate x,coordinate y,cat={real number between 250 and 450}
>
> where coordinate are expressed in latitude and longitude. The files
> represents
> measurements of the size of a skulls on sites all over Africa.
>
> >From it, I would like to build a raster file, 100 km by 100km.  There
>
> are 2
> problems:
>
> 1) Unfortunately,  in some 100km x 100km squares, there is one of the
> points
> whilst in others there are maybe 20. How do I average, so that in each
> square
> I only have 1 value representing the average?
>
> 2) How do we "flatten" Africa so that we may use 100km x 100km squares
> instead
> of 1 degree x 1 degree, without committing a geographical crime? What we
> need
> is to respect the areas ....
>
> Best regards and apologies for the silliness of the questions.



-- 
Corrado Topi

Global Climate Change & Biodiversity Indicators
Area 18,Department of Biology
University of York, York, YO10 5YW, UK
Phone: + 44 (0) 1904 328645, E-mail: ct529 at york.ac.uk



From roland.kaiser at sbg.ac.at  Thu Dec  4 14:03:24 2008
From: roland.kaiser at sbg.ac.at (Roland Kaiser)
Date: Thu, 4 Dec 2008 14:03:24 +0100
Subject: [R-sig-Geo] readOGR and non-ascii characters
In-Reply-To: <4936881A.7030803@gmail.com>
References: <4936881A.7030803@gmail.com>
Message-ID: <281FA43D-420C-4903-96A8-D5B8A2D5C5DC@sbg.ac.at>

Hi!

The following works well for German umlaut.

Encoding(obj$COLUMN) <- "latin1"

Possibly you need to convert to mode character first.

obj$COLUMN <- as.character(obj$COLUMN)

Cheers,

Roland

Am 03.12.2008 um 14:22 schrieb Agustin Lobo:

> Hi!
>
> I have problems at reading a shp file with readOGR(), names with
> non-ascii characters (accents ',`) in the dbf table are imported as  
> i.e.
> Barber\x85 del Vall\x8as
>
> while I can read them fine with OpenOffice Calc
>
> Is there any way I can state the character set of the dbf file in  
> readOGR()?

I did not find a way of doing so?

>
> Thanks
>
> Agus
>
> -- 
> Dr. Agustin Lobo
> Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
> LLuis Sole Sabaris s/n
> 08028 Barcelona
> Spain
> Tel. 34 934095410
> Fax. 34 934110012
> email: Agustin.Lobo at ija.csic.es
> http://www.ija.csic.es/gt/obster
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From pisicandru at hotmail.com  Thu Dec  4 18:38:10 2008
From: pisicandru at hotmail.com (Monica Pisica)
Date: Thu, 4 Dec 2008 17:38:10 +0000
Subject: [R-sig-Geo] merging multiscale data
In-Reply-To: <EB729232EBC4E443A0670A708C4999B004D4EBD6@501exco02.virginiadot.org>
References: <BAY104-W4018DFBB6DE86352485E93C3030@phx.gbl>
	<EB729232EBC4E443A0670A708C4999B004D4EBD6@501exco02.virginiadot.org>
Message-ID: <BAY104-W3955CA19DE679804D9288FC3020@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081204/44d239f3/attachment.pl>

From Jeremy.Raw at VDOT.Virginia.gov  Thu Dec  4 19:09:58 2008
From: Jeremy.Raw at VDOT.Virginia.gov (Raw, Jeremy, P.E.)
Date: Thu, 4 Dec 2008 13:09:58 -0500
Subject: [R-sig-Geo] merging multiscale data
In-Reply-To: <BAY104-W4018DFBB6DE86352485E93C3030@phx.gbl>
References: <BAY104-W4018DFBB6DE86352485E93C3030@phx.gbl>
Message-ID: <EB729232EBC4E443A0670A708C4999B004D4EBDA@501exco02.virginiadot.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081204/2d8eb2f0/attachment.pl>

From Alexander.Herr at csiro.au  Thu Dec  4 22:56:41 2008
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Fri, 5 Dec 2008 08:56:41 +1100
Subject: [R-sig-Geo] reading ascii grid memory issues
In-Reply-To: <mailman.15.1228388402.9984.r-sig-geo@stat.math.ethz.ch>
References: <mailman.15.1228388402.9984.r-sig-geo@stat.math.ethz.ch>
Message-ID: <D6D8CB3DE7413A44BD15BF7D78C960C3FEDBE73E@EXNSW-MBX04.nexus.csiro.au>

 
Hi List,

I am unable to read in a 7.8Gb ascii grid using readAsciiGrid {maptools}/ read.asciigrid {sp}; R runs out of memory. I have 4Gb ram and 4Gb swap, so things are getting tight.

I am wondering if anyone has alternative options (preferably with example) that enable to read in large grids, do some calculations and save a new grid?

I am running linux 64bit on opensuse11 and R 2.8.0

Thanx
Herry



Dr Alexander Herr - Herry
CSIRO, Sustainable Ecosystems
Gungahlin Homestead
Bellenden Street
GPO Box 284
Crace, ACT 2601
 
Phone/www 
(02) 6242 1542; 6242 1705(fax)
0408679811 (mob)

home: www.csiro.au/people/Alexander.Herr
Webadmin ABS: http://ausbats.org.au
Sustainable Ecosystems: www.cse.csiro.au



From b.rowlingson at lancaster.ac.uk  Thu Dec  4 23:39:02 2008
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 4 Dec 2008 22:39:02 +0000
Subject: [R-sig-Geo] reading ascii grid memory issues
In-Reply-To: <D6D8CB3DE7413A44BD15BF7D78C960C3FEDBE73E@EXNSW-MBX04.nexus.csiro.au>
References: <mailman.15.1228388402.9984.r-sig-geo@stat.math.ethz.ch>
	<D6D8CB3DE7413A44BD15BF7D78C960C3FEDBE73E@EXNSW-MBX04.nexus.csiro.au>
Message-ID: <d8ad40b50812041439k4fcddd3dm530f41cdce284f4@mail.gmail.com>

2008/12/4  <Alexander.Herr at csiro.au>:
>
> Hi List,
>
> I am unable to read in a 7.8Gb ascii grid using readAsciiGrid {maptools}/ read.asciigrid {sp}; R runs out of memory. I have 4Gb ram and 4Gb swap, so things are getting tight.
>
> I am wondering if anyone has alternative options (preferably with example) that enable to read in large grids, do some calculations and save a new grid?

 Depends on what you want to do with it. What's the dimension of the
grid in rows x columns?

 Firstly, can you convert it to a more efficient format? Ascii Grid
files are generally long lines of numbers, looking like 2.333535
4.457574 2.332336 5.445775 and so on. Maybe 10 characters per grid
square. You might be able to squeeze it to 4 characters per grid
square by storing as raw floating point numbers.

 Next, can you just process it serially, one line or grid square at a
time? Do you need to store it all in memory at the same time?

 Finally, how much would you lose if you resampled the grid to a
smaller size? Take every tenth or hundredth cell. I'd certainly not
want to develop any analysis with a grid that size. Maybe you've
already worked out what you want to do with a small grid and the
problem is just processing this monster.

 R is probably not the right thing for this job, you might be better
off writing it as 4-byte floating point numbers, and writing some C
code and using the C seek() functions to read numbers from the grid.

Hope that helps...

Barry



From Alexander.Herr at csiro.au  Thu Dec  4 23:48:59 2008
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Fri, 5 Dec 2008 09:48:59 +1100
Subject: [R-sig-Geo] reading ascii grid memory issues
In-Reply-To: <d8ad40b50812041439k4fcddd3dm530f41cdce284f4@mail.gmail.com>
References: <mailman.15.1228388402.9984.r-sig-geo@stat.math.ethz.ch>
	<D6D8CB3DE7413A44BD15BF7D78C960C3FEDBE73E@EXNSW-MBX04.nexus.csiro.au>
	<d8ad40b50812041439k4fcddd3dm530f41cdce284f4@mail.gmail.com>
Message-ID: <D6D8CB3DE7413A44BD15BF7D78C960C3FEDBE73F@EXNSW-MBX04.nexus.csiro.au>

Thanks Barry 
>
> Hi List,
>
> I am unable to read in a 7.8Gb ascii grid using readAsciiGrid {maptools}/ read.asciigrid {sp}; R runs out of memory. I have 4Gb ram and 4Gb swap, so things are getting tight.
>
> I am wondering if anyone has alternative options (preferably with example) that enable to read in large grids, do some calculations and save a new grid?

 Depends on what you want to do with it. What's the dimension of the grid in rows x columns?

-->dimensions 80264x73772 for the largest grid and 28848x47030 for current grid

Firstly, can you convert it to a more efficient format? Ascii Grid files are generally long lines of numbers, looking like 2.333535
4.457574 2.332336 5.445775 and so on. Maybe 10 characters per grid square. You might be able to squeeze it to 4 characters per grid square by storing as raw floating point numbers.

-->yes, depends on what formats R is able to read in

 Next, can you just process it serially, one line or grid square at a time? Do you need to store it all in memory at the same time?

--> I can process serially, I don't need to store it in memory for the simple math calculations, only for subsequent analysis. But once calculations are done I can resample/aggregate to higher resolution.



From Roger.Bivand at nhh.no  Fri Dec  5 08:47:59 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 5 Dec 2008 08:47:59 +0100 (CET)
Subject: [R-sig-Geo] reading ascii grid memory issues
In-Reply-To: <D6D8CB3DE7413A44BD15BF7D78C960C3FEDBE73F@EXNSW-MBX04.nexus.csiro.au>
References: <mailman.15.1228388402.9984.r-sig-geo@stat.math.ethz.ch>
	<D6D8CB3DE7413A44BD15BF7D78C960C3FEDBE73E@EXNSW-MBX04.nexus.csiro.au>
	<d8ad40b50812041439k4fcddd3dm530f41cdce284f4@mail.gmail.com>
	<D6D8CB3DE7413A44BD15BF7D78C960C3FEDBE73F@EXNSW-MBX04.nexus.csiro.au>
Message-ID: <alpine.LRH.2.00.0812050844080.16287@reclus.nhh.no>

On Fri, 5 Dec 2008, Alexander.Herr at csiro.au wrote:

> Thanks Barry
>>
>> Hi List,
>>
>> I am unable to read in a 7.8Gb ascii grid using readAsciiGrid 
>> {maptools}/ read.asciigrid {sp}; R runs out of memory. I have 4Gb ram 
>> and 4Gb swap, so things are getting tight.
>>
>> I am wondering if anyone has alternative options (preferably with 
>> example) that enable to read in large grids, do some calculations and 
>> save a new grid?

This is another case of posting on r-help and R-sig-geo, leading to the 
thread getting confused. I replied on r-help:

https://stat.ethz.ch/pipermail/r-help/2008-December/181686.html

saying that using tiling with rgdal functions - which have a driver for 
this data - is the obvious way to go, and that the raster package under 
development on R-forge looks very promising for letting users automate the 
process of reading rasters in tiles.

See also the relevant thread here:

https://stat.ethz.ch/pipermail/r-sig-geo/2008-November/004486.html

Roger

>
> Depends on what you want to do with it. What's the dimension of the grid in rows x columns?
>
> -->dimensions 80264x73772 for the largest grid and 28848x47030 for current grid
>
> Firstly, can you convert it to a more efficient format? Ascii Grid files 
> are generally long lines of numbers, looking like 2.333535 4.457574 
> 2.332336 5.445775 and so on. Maybe 10 characters per grid square. You 
> might be able to squeeze it to 4 characters per grid square by storing 
> as raw floating point numbers.
>
> -->yes, depends on what formats R is able to read in
>
> Next, can you just process it serially, one line or grid square at a 
> time? Do you need to store it all in memory at the same time?
>
> --> I can process serially, I don't need to store it in memory for the 
> simple math calculations, only for subsequent analysis. But once 
> calculations are done I can resample/aggregate to higher resolution.
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ashton at msu.edu  Fri Dec  5 15:22:31 2008
From: ashton at msu.edu (Ashton Shortridge)
Date: Fri, 5 Dec 2008 09:22:31 -0500
Subject: [R-sig-Geo] reading ascii grid memory issues
In-Reply-To: <D6D8CB3DE7413A44BD15BF7D78C960C3FEDBE73F@EXNSW-MBX04.nexus.csiro.au>
References: <mailman.15.1228388402.9984.r-sig-geo@stat.math.ethz.ch>
	<d8ad40b50812041439k4fcddd3dm530f41cdce284f4@mail.gmail.com>
	<D6D8CB3DE7413A44BD15BF7D78C960C3FEDBE73F@EXNSW-MBX04.nexus.csiro.au>
Message-ID: <200812050922.31907.ashton@msu.edu>

Alex,

On Thursday 04 December 2008 05:48:59 pm Alexander.Herr at csiro.au wrote:
> > I am wondering if anyone has alternative options (preferably with
> > example) that enable to read in large grids, do some calculations and
> > save a new grid?

You may need a hammer, and R is the screwdriver. But it's a useful 
screwdriver, so maybe you can make it work here. AsciiGrid files are very 
simple. They are text obviously, with a 5 or 6 line header and then rows of 
grid cell values. This means that fairly generic R I/O commands can work with 
them. scan() is where I'd start if I were you. 

Actually I'd start with another thing Barry brought up - make yourself a 
really small asciigrid file, like 4x3, and practice on that while you figure 
out your processing. 

Here's one I have used: modify the values as you see fit.

nrows 4
ncols 5
xllcorner 0.000000
yllcorner 0.000000
cellsize 10.000000
NODATA_value -9999
0 0 0 0 0
0 0 0 0 0
0 0 0 0 0
0 0 0 0 0


yours,

Ashton
-- 
Ashton Shortridge
Associate Professor			ashton at msu.edu
Dept of Geography			http://www.msu.edu/~ashton
235 Geography Building		ph (517) 432-3561
Michigan State University		fx (517) 432-1671



From annachiara.saguatti at gmail.com  Fri Dec  5 15:55:38 2008
From: annachiara.saguatti at gmail.com (Annachiara Saguatti)
Date: Fri, 5 Dec 2008 15:55:38 +0100
Subject: [R-sig-Geo] read.gal3.R
In-Reply-To: <516dbff70812050641i4cc84165pd56c9f4c73ff746a@mail.gmail.com>
References: <516dbff70812050641i4cc84165pd56c9f4c73ff746a@mail.gmail.com>
Message-ID: <516dbff70812050655g3e17979frd21da0fa71f69158@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081205/e6322345/attachment.pl>

From Roger.Bivand at nhh.no  Fri Dec  5 17:01:20 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 5 Dec 2008 17:01:20 +0100 (CET)
Subject: [R-sig-Geo] read.gal3.R
In-Reply-To: <516dbff70812050655g3e17979frd21da0fa71f69158@mail.gmail.com>
References: <516dbff70812050641i4cc84165pd56c9f4c73ff746a@mail.gmail.com>
	<516dbff70812050655g3e17979frd21da0fa71f69158@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0812051655270.16395@reclus.nhh.no>

On Fri, 5 Dec 2008, Annachiara Saguatti wrote:

> Hello everybody,
>
> I'm trying to perform a ESDA on some data about per capita GDP among
> European regions and I'm trying to learn how to make R and GeoDa interact.
> I'm reading that in order to import a GAL file from GeoDa to R it's best to
> source into R the read.gal3.R file. But where can I get it from?

library(rgdal)
?read.gal

The note you are reading is five years old, and does say that 
functionality in spdep's read.gal() will be enhanced shortly. I believe 
this happened in July 2003, after the notes were written.

Hope this helps,

Roger

>
> Thank you,
> Annachiara Saguatti
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From aloboaleu at gmail.com  Fri Dec  5 17:29:02 2008
From: aloboaleu at gmail.com (Agustin Lobo)
Date: Fri, 05 Dec 2008 17:29:02 +0100
Subject: [R-sig-Geo] numeric fields imported as factors by readOGR()
Message-ID: <493956CE.7080504@gmail.com>

I often get some numeric fields (i.e, AREA in this case) imported
as factors by readOGR() from shp files. WHy could it be?
I've reviewed the field in the dbf file and do not
see any non-numeric value.

Thanks
Agus
-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From jnylen+rgeo at gmail.com  Fri Dec  5 17:51:18 2008
From: jnylen+rgeo at gmail.com (James Nylen)
Date: Fri, 5 Dec 2008 10:51:18 -0600
Subject: [R-sig-Geo] numeric fields imported as factors by readOGR()
In-Reply-To: <493956CE.7080504@gmail.com>
References: <493956CE.7080504@gmail.com>
Message-ID: <205a4c310812050851v725a0fedo93001d5e0c43c33a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081205/ab611ae8/attachment.pl>

From Roger.Bivand at nhh.no  Fri Dec  5 18:36:14 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 5 Dec 2008 18:36:14 +0100 (CET)
Subject: [R-sig-Geo] numeric fields imported as factors by readOGR()
In-Reply-To: <205a4c310812050851v725a0fedo93001d5e0c43c33a@mail.gmail.com>
References: <493956CE.7080504@gmail.com>
	<205a4c310812050851v725a0fedo93001d5e0c43c33a@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0812051832580.18293@reclus.nhh.no>

On Fri, 5 Dec 2008, James Nylen wrote:

> This happens to me as well.  I just create a new column in the shapefile
> object's data, like:
>
> shp$AreaNum = as.numeric(as.vector(shp$AREA))
>
> If all you want to know is "why is it coded this way" then I have no idea,
> sorry.

You could look at ogrInfo() for the same dsn= and layer= before you 
import. In principle, if the driver reports "Integer", "Real", or 
"String", this should be respected, so I'd be interested in seeing a case.

Roger

>
> -James
>
> On Fri, Dec 5, 2008 at 10:29 AM, Agustin Lobo <aloboaleu at gmail.com> wrote:
>
>> I often get some numeric fields (i.e, AREA in this case) imported
>> as factors by readOGR() from shp files. WHy could it be?
>> I've reviewed the field in the dbf file and do not
>> see any non-numeric value.
>>
>> Thanks
>> Agus
>> --
>> Dr. Agustin Lobo
>> Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
>> LLuis Sole Sabaris s/n
>> 08028 Barcelona
>> Spain
>> Tel. 34 934095410
>> Fax. 34 934110012
>> email: Agustin.Lobo at ija.csic.es
>> http://www.ija.csic.es/gt/obster
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Agustin.Lobo at ija.csic.es  Sat Dec  6 11:41:50 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Sat, 06 Dec 2008 11:41:50 +0100
Subject: [R-sig-Geo] numeric fields imported as factors by readOGR()
In-Reply-To: <alpine.LRH.2.00.0812051832580.18293@reclus.nhh.no>
References: <493956CE.7080504@gmail.com>
	<205a4c310812050851v725a0fedo93001d5e0c43c33a@mail.gmail.com>
	<alpine.LRH.2.00.0812051832580.18293@reclus.nhh.no>
Message-ID: <493A56EE.6000609@ija.csic.es>

Roland, James, Roger and Carson

ogrInfo() provides info consistent with the behaviour of readOGR()
and editing the dbf with OO as suggested by Roland reveals
that the field is labeled as "C,80" (which I do not understand
as values are areas written by fTools in QGIS, Carson, could this be
a bug?)
Substitution of "C,80" by "N,15,3" in the dbf file for that field with OO
does not work (all values imported as 0). I think that this is because
all values for that field in the dbf have a "'" which is what makes
the field to be character and which I had overlooked. I've tried 
replacing all "'" for that field in OO but, oddly, OO claims that
that no "'" are present.

Anyway, the problem is clearly in the dbf file and not in rgdal.

Also, the quick fix suggested by James works fine.

Thank you all.

Agus

Roger Bivand wrote:
> On Fri, 5 Dec 2008, James Nylen wrote:
> 
>> This happens to me as well.  I just create a new column in the shapefile
>> object's data, like:
>>
>> shp$AreaNum = as.numeric(as.vector(shp$AREA))
>>
>> If all you want to know is "why is it coded this way" then I have no 
>> idea,
>> sorry.
> 
> You could look at ogrInfo() for the same dsn= and layer= before you 
> import. In principle, if the driver reports "Integer", "Real", or 
> "String", this should be respected, so I'd be interested in seeing a case.
> 
> Roger
> 
>>
>> -James
>>
>> On Fri, Dec 5, 2008 at 10:29 AM, Agustin Lobo <aloboaleu at gmail.com> 
>> wrote:
>>
>>> I often get some numeric fields (i.e, AREA in this case) imported
>>> as factors by readOGR() from shp files. WHy could it be?
>>> I've reviewed the field in the dbf file and do not
>>> see any non-numeric value.
>>>
>>> Thanks
>>> Agus
>>> -- 
>>> Dr. Agustin Lobo
>>> Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
>>> LLuis Sole Sabaris s/n
>>> 08028 Barcelona
>>> Spain
>>> Tel. 34 934095410
>>> Fax. 34 934110012
>>> email: Agustin.Lobo at ija.csic.es
>>> http://www.ija.csic.es/gt/obster
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>     [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From zack_holden at hotmail.com  Sat Dec  6 20:07:34 2008
From: zack_holden at hotmail.com (zack holden)
Date: Sat, 6 Dec 2008 19:07:34 +0000
Subject: [R-sig-Geo] create ascii grid from grid.list object (fields)?
Message-ID: <BAY125-W33872D6062E74BB1AD927C87FF0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081206/c926cb5e/attachment.pl>

From Roger.Bivand at nhh.no  Sat Dec  6 21:41:48 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 6 Dec 2008 21:41:48 +0100 (CET)
Subject: [R-sig-Geo] create ascii grid from grid.list object (fields)?
In-Reply-To: <BAY125-W33872D6062E74BB1AD927C87FF0@phx.gbl>
References: <BAY125-W33872D6062E74BB1AD927C87FF0@phx.gbl>
Message-ID: <alpine.LRH.2.00.0812062109010.1100@reclus.nhh.no>

On Sat, 6 Dec 2008, zack holden wrote:

>
>
> Dear list, I've used R for simple statistics in the past, but this is my 
> first attempt at manipulating spatial data. The transition is 
> frustrating and I'd appreciate any advice you can give me on the problem 
> below.
>
> I'm creating interpolated surfaces of PCA loadings extracted from some 
> precipitation data in Oregon/WA USA. I'm using the package fields. I can 
> create the interpolated surface, but I need to use the data from the 
> interpolated surface, either extracting values from the surface for 
> specific x,y locations, or exporting the surface to an ascii grid file, 
> or some format that I can either access via another R package (rgdal??) 
> or ArcGIS, which I've used in the past.
>
> I'd be very grateful for suggestions and/or a snippet of example code 
> telling me how to make the interpolated surface created below, into a 
> spatial object that I can analyze further.
>
> Thanks in advance,
>
> Zack
>

Another time, please use a cluefull text-only email client - the code was 
completely mixed up.


> #######################################################
> require(fields)
> require(maptools)
> require(sp)
>

setwd("C:/climate_data/pnw_data")
data <- readShapePoints("climate_PNW_PCLOAD.shp")

If possible use the rgdal package, it gives many more drivers for vector 
and raster data - see readOGR().

# read in shapefile with X,Y and PC loadings for climate 
stationsproj4string=CRS(as.character(NA)), verbose=FALSE)

No idea what this was supposed to be

# data <- as.data.frame(data)
# long <- x[,1]
# longitude column
# lat <- x[,2]
# latitude column
# minlat <- min(lat)
# maxlat <- max(lat)
# minlong <- min(long)
# maxlong <- max(long)
# grid.l<- list( X1= seq(minlong, maxlong,,100), 
# X3=seq(minlat,maxlat,,100))

PredGrid <- Sobj_SpatialGrid(data)$SG
grd <- slot(PredGrid, "grid")
o <- rep(NA, prod(slot(grd, "cells.dim")))
PredGridDF <- SpatialGridDataFrame(slot(PredGrid, "grid"),
  data=data.frame(o=o))

This makes an empty SpatialGridDataFrame, use the maxDim= argument to 
Sobj_SpatialGrid() to control resolution.

# create grid.list object using ranges of Long. and Lat.
# make.surface.grid(grid.l)
# y <- data$pc1
# Princ. Comp. loading I want to interpolate
# LL <- cbind(long,lat)
# combine Lat and Long
# fit = Krig(LL,y, theta = 10)

fit <- Krig(coordinates(data), data$pc1, theta=10)

Use the data object directly

# fit Princ. comp. 1 to Lat long.
# surface( fit, grid.list=grid.l)

PredGridDF$pc1 <- predict(fit, coordinates(PredGridDF))
spplot(PredGridDF, "pc1", col.regions=tim.colors())

Use the predict() method on the prediction grid coordinates, assigning to 
a variable in the object (treat it as you would treat a data frame).

writeGDAL(PredGridDF["pc1"], "pc1.tif", drivername="GTiff")

to write a geotiff - see other drivers with gdalDrivers().

Hope this helps,

Roger

#  create interpolated surface based on Krig object

> ####################################################
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From harryk at cal.berkeley.edu  Mon Dec  8 09:06:35 2008
From: harryk at cal.berkeley.edu (Harry Kim)
Date: Mon, 8 Dec 2008 00:06:35 -0800
Subject: [R-sig-Geo] projection string when using asSGDF_GROD()
Message-ID: <91b8161f0812080006w3d020a5bjc1c25067cb255b70@mail.gmail.com>

Dear r-sig-geoers,

      I need some help reading in a raster data and at the same time
project it so I can use the overlay() function. The data I am reading
in is quite big, so I managed to source in the subset of the data by
running:

      wetland= asSGDF_GROD(x, offset=c(3600,20400), region.dim=c(8140,18000))

      Running summary(wetland) gives:

      Object of class SpatialGridDataFrame
Coordinates:
        min      max
x -9.999992 140.0000
y -7.833337  60.0000
Is projected: NA
proj4string : [NA]
Number of points: 2
Grid attributes:
  cellcentre.offset    cellsize cells.dim
x         -9.995825 0.008333334     18000
y         -7.829171 0.008333334      8140
Data attributes:
        Min.      1st Qu.       Median         Mean      3rd Qu.         Max.
1.000000e+00 3.000000e+00 4.000000e+00 5.594000e+00 9.000000e+00 1.200000e+01
        NA's
1.396304e+08
----------------------------------------------------------------------------------------------------------------------------------

The original data is geocoded in latitude and longitude spanning from
-180 to 180 for longitude and from -90 to 90 for latitude. As you
probably noticed, the read-in raster image does not inherit the
projection.
I tried to project the data by running:

asSGDF_GROD(x, offset=c(3600,20400),
region.dim=c(8140,18000),CRS("+proj=longlat" ))

and I get a message that says

Error: object is not subsettable

If anybody could help me out, I would greatly appreciate it.

Thank you
Harry



From ddepew at sciborg.uwaterloo.ca  Mon Dec  8 15:58:06 2008
From: ddepew at sciborg.uwaterloo.ca (Dave Depew)
Date: Mon, 08 Dec 2008 09:58:06 -0500
Subject: [R-sig-Geo] gstat memory size
Message-ID: <493D35FE.2090205@scimail.uwaterloo.ca>

Just a quick question re: memory sizes.
Is it possible to quickly estimate the amount of RAM needed to do 
ordinary kriging given a dataset of 14000 records for 2 variables?

-- 
David Depew
PhD Candidate
Department of Biology
University of Waterloo
200 University Ave W.
Waterloo, ON. Canada
N2L 3G1

(T) 1-519-888-4567 x33895
(F) 1-519-746-0614

http://www.science.uwaterloo.ca/~ddepew



From h.greatrex at reading.ac.uk  Mon Dec  8 18:07:25 2008
From: h.greatrex at reading.ac.uk (Helen Greatrex)
Date: Mon, 08 Dec 2008 17:07:25 +0000
Subject: [R-sig-Geo] GStat kriging using spherical geometry
Message-ID: <493D544D.9080002@reading.ac.uk>

Dear all,

Does anyone know if the Gstat package in r offers kriging using 
spherical geometry rather than euclidean distances?

I couldn't find anything in ?krige or online,  but I've heard that the 
general gstat package includes this option.  From comparisons with a 
different kriging code outside r, the inclusion of spherical geometry 
does make a difference to my results, but I'd really like to use gstat!

For some context, I'm block kriging rainfall data using lat long 
coordinates.  An example of my code is below.  To make things simple, in 
this example I'm aiming to krige over a 1 degree block centred at (39.5, 
7.5)
(So the corners of the block would be [39,7],[40,7],[40,8],[39,8])
Note, In general I wouldn't be kriging over a block this size - it's 
just to make the code simple!

Best wishes and thank you for your time
Helen

---------------------------------------------------------------------------

 ># Read in the input files
 >##############################
 >  dayinput <- file("zsourcep.txt","r")
 >  mydata <- read.table(dayinput,header=TRUE)
 >  unlink("zsourcep.txt")
 >
 >
 ># Read in the output files
 >##############################
 >  dayoutput <- file("ztarget.txt","r")
 >  mydataout <- read.table(dayoutput,header=TRUE)
 >  unlink("ztarget.txt")
 >
 >
 ># Turn these into the correct format for krige
 >##############################
 >  cinput <- data.frame (Long = mydataout$Long, Lat= mydataout$Lat     
                              )
 >  input  <- data.frame  (Long = mydata$Long ,     Lat=mydata$Lat,      
Value=mydata$Value)
 >  coordinates(input)  <- ~ Long + Lat
 >  coordinates(cinput)<- ~ Long + Lat
 >
 >
 ># Now make the variogram model
 >##############################
 >  m <- vgm(.675, "Exp", 9.51, 0.237)
 > >
 ># And krige
 >##############################
 >  x <- krige(Value ~ 1, input,cinput , model = m, block=c(1,1))
  [using ordinary kriging]
 >  x
     coordinates var1.pred  var1.var

-- 
-----------------------------
Helen Greatrex (PhD Student)
Room 1U09
Department of Meteorology
University of Reading
Earley Gate
PO Box 243
READING
RG6 6BB



From edzer.pebesma at uni-muenster.de  Mon Dec  8 21:12:53 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 08 Dec 2008 21:12:53 +0100
Subject: [R-sig-Geo] GStat kriging using spherical geometry
In-Reply-To: <493D544D.9080002@reading.ac.uk>
References: <493D544D.9080002@reading.ac.uk>
Message-ID: <493D7FC5.3050404@uni-muenster.de>

I find it hard to believe that you did a thorough online search. 
Googling on "kriging spherical distance" gave me the following as first hit:

https://stat.ethz.ch/pipermail/r-sig-geo/2008-October/004457.html

and then there the search facility for the archives of this list, 
referenced at the end of every message.

In your example, don't forget to set the proj4string of youe objects. 
Further, the exponential model does, afaik, not give positive definite 
covariance matrices on the sphere. I have received no reactions to the 
question in the email mentioned above.

Attempts for block kriging should result in an error message, as I can't 
see what is meant by a constant block size on the sphere--something like 
one degree by one degree?
--
Edzer

Helen Greatrex wrote:
> Dear all,
>
> Does anyone know if the Gstat package in r offers kriging using 
> spherical geometry rather than euclidean distances?
>
> I couldn't find anything in ?krige or online,  but I've heard that the 
> general gstat package includes this option.  From comparisons with a 
> different kriging code outside r, the inclusion of spherical geometry 
> does make a difference to my results, but I'd really like to use gstat!
>
> For some context, I'm block kriging rainfall data using lat long 
> coordinates.  An example of my code is below.  To make things simple, 
> in this example I'm aiming to krige over a 1 degree block centred at 
> (39.5, 7.5)
> (So the corners of the block would be [39,7],[40,7],[40,8],[39,8])
> Note, In general I wouldn't be kriging over a block this size - it's 
> just to make the code simple!
>
> Best wishes and thank you for your time
> Helen
>
> --------------------------------------------------------------------------- 
>
>
> ># Read in the input files
> >##############################
> >  dayinput <- file("zsourcep.txt","r")
> >  mydata <- read.table(dayinput,header=TRUE)
> >  unlink("zsourcep.txt")
> >
> >
> ># Read in the output files
> >##############################
> >  dayoutput <- file("ztarget.txt","r")
> >  mydataout <- read.table(dayoutput,header=TRUE)
> >  unlink("ztarget.txt")
> >
> >
> ># Turn these into the correct format for krige
> >##############################
> >  cinput <- data.frame (Long = mydataout$Long, Lat= mydataout$Lat     
>                              )
> >  input  <- data.frame  (Long = mydata$Long ,     
> Lat=mydata$Lat,      Value=mydata$Value)
> >  coordinates(input)  <- ~ Long + Lat
> >  coordinates(cinput)<- ~ Long + Lat
> >
> >
> ># Now make the variogram model
> >##############################
> >  m <- vgm(.675, "Exp", 9.51, 0.237)
> > >
> ># And krige
> >##############################
> >  x <- krige(Value ~ 1, input,cinput , model = m, block=c(1,1))
>  [using ordinary kriging]
> >  x
>     coordinates var1.pred  var1.var
>

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de



From p.hiemstra at geo.uu.nl  Mon Dec  8 22:26:24 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 08 Dec 2008 22:26:24 +0100
Subject: [R-sig-Geo] projection string when using asSGDF_GROD()
In-Reply-To: <91b8161f0812080006w3d020a5bjc1c25067cb255b70@mail.gmail.com>
References: <91b8161f0812080006w3d020a5bjc1c25067cb255b70@mail.gmail.com>
Message-ID: <493D9100.2090907@geo.uu.nl>

Hi Harry,

Without the output of traceback() to show what exactly went wrong in 
what function it is hard to say what is wrong. A small piece of sample 
code reproducing the error would also make this diagnosis much easier.

good luck and cheers,
Paul

Harry Kim wrote:
> Dear r-sig-geoers,
>
>       I need some help reading in a raster data and at the same time
> project it so I can use the overlay() function. The data I am reading
> in is quite big, so I managed to source in the subset of the data by
> running:
>
>       wetland= asSGDF_GROD(x, offset=c(3600,20400), region.dim=c(8140,18000))
>
>       Running summary(wetland) gives:
>
>       Object of class SpatialGridDataFrame
> Coordinates:
>         min      max
> x -9.999992 140.0000
> y -7.833337  60.0000
> Is projected: NA
> proj4string : [NA]
> Number of points: 2
> Grid attributes:
>   cellcentre.offset    cellsize cells.dim
> x         -9.995825 0.008333334     18000
> y         -7.829171 0.008333334      8140
> Data attributes:
>         Min.      1st Qu.       Median         Mean      3rd Qu.         Max.
> 1.000000e+00 3.000000e+00 4.000000e+00 5.594000e+00 9.000000e+00 1.200000e+01
>         NA's
> 1.396304e+08
> ----------------------------------------------------------------------------------------------------------------------------------
>
> The original data is geocoded in latitude and longitude spanning from
> -180 to 180 for longitude and from -90 to 90 for latitude. As you
> probably noticed, the read-in raster image does not inherit the
> projection.
> I tried to project the data by running:
>
> asSGDF_GROD(x, offset=c(3600,20400),
> region.dim=c(8140,18000),CRS("+proj=longlat" ))
>
> and I get a message that says
>
> Error: object is not subsettable
>
> If anybody could help me out, I would greatly appreciate it.
>
> Thank you
> Harry
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From harryk at cal.berkeley.edu  Tue Dec  9 06:42:49 2008
From: harryk at cal.berkeley.edu (Harry Kim)
Date: Mon, 8 Dec 2008 21:42:49 -0800
Subject: [R-sig-Geo] projection string when using asSGDF_GROD()
In-Reply-To: <493D9100.2090907@geo.uu.nl>
References: <91b8161f0812080006w3d020a5bjc1c25067cb255b70@mail.gmail.com>
	<493D9100.2090907@geo.uu.nl>
Message-ID: <91b8161f0812082142h6d9fb42dpc0828eec5ebbd95@mail.gmail.com>

Hi Paul,

     Thank you so much for the prompt response. Here is the actual code I ran:

library(rgdal)
dpath<-"./glwd_3/hdr.adf"
x <- new("GDALReadOnlyDataset", dpath)
getDriver(x)
getDriverLongName(getDriver(x))

wetland<-asSGDF_GROD(x, offset=c(3600,20400), region.dim=c(8140,
18000),CRS("+proj=longlat" ))

save(wetland,file="wetland.Rdata" )

If I run this code without the CRS() argument for p4s, I can read in
the data without any errors--but it doesn't project correctly. It's
very strange that it doesn't inherit the projection (lat and long)
from the original raster image.

traceback() produces the following:

 > traceback()
5: getRasterData(x, offset = offset, region.dim = region.dim,
output.dim = output.dim,
       ...)
4: asSGDF_GROD(x, offset = c(3600, 20400), region.dim = c(8140,
       18000), CRS("+proj=longlat"))
3: eval.with.vis(expr, envir, enclos)
2: eval.with.vis(ei, envir)
1: source("wetland.R")

Thank you so much in advance!
Harry




On Mon, Dec 8, 2008 at 1:26 PM, Paul Hiemstra <p.hiemstra at geo.uu.nl> wrote:
> Hi Harry,
>
> Without the output of traceback() to show what exactly went wrong in what
> function it is hard to say what is wrong. A small piece of sample code
> reproducing the error would also make this diagnosis much easier.
>
> good luck and cheers,
> Paul
>
> Harry Kim wrote:
>>
>> Dear r-sig-geoers,
>>
>>      I need some help reading in a raster data and at the same time
>> project it so I can use the overlay() function. The data I am reading
>> in is quite big, so I managed to source in the subset of the data by
>> running:
>>
>>      wetland= asSGDF_GROD(x, offset=c(3600,20400),
>> region.dim=c(8140,18000))
>>
>>      Running summary(wetland) gives:
>>
>>      Object of class SpatialGridDataFrame
>> Coordinates:
>>        min      max
>> x -9.999992 140.0000
>> y -7.833337  60.0000
>> Is projected: NA
>> proj4string : [NA]
>> Number of points: 2
>> Grid attributes:
>>  cellcentre.offset    cellsize cells.dim
>> x         -9.995825 0.008333334     18000
>> y         -7.829171 0.008333334      8140
>> Data attributes:
>>        Min.      1st Qu.       Median         Mean      3rd Qu.
>> Max.
>> 1.000000e+00 3.000000e+00 4.000000e+00 5.594000e+00 9.000000e+00
>> 1.200000e+01
>>        NA's
>> 1.396304e+08
>>
>> ----------------------------------------------------------------------------------------------------------------------------------
>>
>> The original data is geocoded in latitude and longitude spanning from
>> -180 to 180 for longitude and from -90 to 90 for latitude. As you
>> probably noticed, the read-in raster image does not inherit the
>> projection.
>> I tried to project the data by running:
>>
>> asSGDF_GROD(x, offset=c(3600,20400),
>> region.dim=c(8140,18000),CRS("+proj=longlat" ))
>>
>> and I get a message that says
>>
>> Error: object is not subsettable
>>
>> If anybody could help me out, I would greatly appreciate it.
>>
>> Thank you
>> Harry
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>



From r.hijmans at gmail.com  Tue Dec  9 07:10:37 2008
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Tue, 9 Dec 2008 14:10:37 +0800
Subject: [R-sig-Geo] projection string when using asSGDF_GROD()
In-Reply-To: <91b8161f0812082142h6d9fb42dpc0828eec5ebbd95@mail.gmail.com>
References: <91b8161f0812080006w3d020a5bjc1c25067cb255b70@mail.gmail.com>
	<493D9100.2090907@geo.uu.nl>
	<91b8161f0812082142h6d9fb42dpc0828eec5ebbd95@mail.gmail.com>
Message-ID: <dc22b2570812082210v5c4eae52mbb4326a537d8de01@mail.gmail.com>

Hi Harry,


I do not really see any evidence for your statement that "it doesn't
inherit the projection (lat and long)"
Are you sure that "dpath" has a defined projection? (the fact that the
data are in lat and long does not imply this.)

If it does, you should get something like this (like I get):

attr(x, "projection")
[1] "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs "

> wetland at proj4string
CRS arguments:
 +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0


If the projection of the arcinfo data has not been defined (which I
assume is the problem), you can fix this with e.g. ArcInfo (command
line) projectdefine (or via ArcMap)

Somethings like this may also work for you:

dpath<-"./glwd_3/hdr.adf"
x <- new("GDALReadOnlyDataset", dpath)
attr(x, "projection") <- "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"
etc.


Robert


On Tue, Dec 9, 2008 at 1:42 PM, Harry Kim <harryk at cal.berkeley.edu> wrote:
> Hi Paul,
>
>     Thank you so much for the prompt response. Here is the actual code I ran:
>
> library(rgdal)
> dpath<-"./glwd_3/hdr.adf"
> x <- new("GDALReadOnlyDataset", dpath)
> getDriver(x)
> getDriverLongName(getDriver(x))
>
> wetland<-asSGDF_GROD(x, offset=c(3600,20400), region.dim=c(8140,
> 18000),CRS("+proj=longlat" ))
>
> save(wetland,file="wetland.Rdata" )
>
> If I run this code without the CRS() argument for p4s, I can read in
> the data without any errors--but it doesn't project correctly. It's
> very strange that it doesn't inherit the projection (lat and long)
> from the original raster image.
>
> traceback() produces the following:
>
>  > traceback()
> 5: getRasterData(x, offset = offset, region.dim = region.dim,
> output.dim = output.dim,
>       ...)
> 4: asSGDF_GROD(x, offset = c(3600, 20400), region.dim = c(8140,
>       18000), CRS("+proj=longlat"))
> 3: eval.with.vis(expr, envir, enclos)
> 2: eval.with.vis(ei, envir)
> 1: source("wetland.R")
>
> Thank you so much in advance!
> Harry
>
>
>
>
> On Mon, Dec 8, 2008 at 1:26 PM, Paul Hiemstra <p.hiemstra at geo.uu.nl> wrote:
>> Hi Harry,
>>
>> Without the output of traceback() to show what exactly went wrong in what
>> function it is hard to say what is wrong. A small piece of sample code
>> reproducing the error would also make this diagnosis much easier.
>>
>> good luck and cheers,
>> Paul
>>
>> Harry Kim wrote:
>>>
>>> Dear r-sig-geoers,
>>>
>>>      I need some help reading in a raster data and at the same time
>>> project it so I can use the overlay() function. The data I am reading
>>> in is quite big, so I managed to source in the subset of the data by
>>> running:
>>>
>>>      wetland= asSGDF_GROD(x, offset=c(3600,20400),
>>> region.dim=c(8140,18000))
>>>
>>>      Running summary(wetland) gives:
>>>
>>>      Object of class SpatialGridDataFrame
>>> Coordinates:
>>>        min      max
>>> x -9.999992 140.0000
>>> y -7.833337  60.0000
>>> Is projected: NA
>>> proj4string : [NA]
>>> Number of points: 2
>>> Grid attributes:
>>>  cellcentre.offset    cellsize cells.dim
>>> x         -9.995825 0.008333334     18000
>>> y         -7.829171 0.008333334      8140
>>> Data attributes:
>>>        Min.      1st Qu.       Median         Mean      3rd Qu.
>>> Max.
>>> 1.000000e+00 3.000000e+00 4.000000e+00 5.594000e+00 9.000000e+00
>>> 1.200000e+01
>>>        NA's
>>> 1.396304e+08
>>>
>>> ----------------------------------------------------------------------------------------------------------------------------------
>>>
>>> The original data is geocoded in latitude and longitude spanning from
>>> -180 to 180 for longitude and from -90 to 90 for latitude. As you
>>> probably noticed, the read-in raster image does not inherit the
>>> projection.
>>> I tried to project the data by running:
>>>
>>> asSGDF_GROD(x, offset=c(3600,20400),
>>> region.dim=c(8140,18000),CRS("+proj=longlat" ))
>>>
>>> and I get a message that says
>>>
>>> Error: object is not subsettable
>>>
>>> If anybody could help me out, I would greatly appreciate it.
>>>
>>> Thank you
>>> Harry
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From zev at zevross.com  Tue Dec  9 20:06:41 2008
From: zev at zevross.com (Zev Ross)
Date: Tue, 09 Dec 2008 14:06:41 -0500
Subject: [R-sig-Geo] GSTAT - singular in meters not km
Message-ID: <493EC1C1.7050902@zevross.com>

Hi All,

I'm fitting variograms in GSTAT with fit.variogram and I was surprised 
to find that all my fits were singular. I experimented with converting 
the data to unprojected data (decimal degrees) and with dividing my X 
and Y coordinates, which are in meters, by 1000 (to get KM). In both 
cases the fitting procedure worked with no singularity. Based on the 
numbers of pairs the bins appeared to be about the same so it appears to 
be a matter of the coordinates themselves.

I'd prefer not to have to convert the coordinates back and forth between 
meters and KM, any suggestions?

Zev



From dmwarner at usgs.gov  Wed Dec 10 03:12:46 2008
From: dmwarner at usgs.gov (David M Warner)
Date: Tue, 9 Dec 2008 21:12:46 -0500
Subject: [R-sig-Geo] subset point data set by distance ranges
Message-ID: <OFF70D9A0C.10DFF46E-ON8525751B.000C27A8-8525751B.000C27C6@usgs.gov>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081209/3369bfd3/attachment.html>

From zack_holden at hotmail.com  Wed Dec 10 06:55:10 2008
From: zack_holden at hotmail.com (zack holden)
Date: Wed, 10 Dec 2008 05:55:10 +0000
Subject: [R-sig-Geo] overlay point extraction of pixel radius (3x3 window)
Message-ID: <BAY125-W56461B3D25C3DC88FE20F587FB0@phx.gbl>


Dear list,
 
I would like to use points to extract values from underlying grids, modifying my query to return the mean, standard deviation, or other function of the cells adjacent to the center grid cell. I assume this is possible, but I can find no examples of this in previous posts or in the Bivand et al. Applied spatial data analysis book. 
 
Would anyone be willing to suggest how to do this or better yet, provide some example code? 
 
Thanks in advance for any help,
 
Zack


From edzer.pebesma at uni-muenster.de  Wed Dec 10 08:06:12 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 10 Dec 2008 08:06:12 +0100
Subject: [R-sig-Geo] GSTAT - singular in meters not km
In-Reply-To: <493EC1C1.7050902@zevross.com>
References: <493EC1C1.7050902@zevross.com>
Message-ID: <493F6A64.6040101@uni-muenster.de>

Hi Zev, it is hard to see what happens without seeing your data or R 
commands.

Is it possible that you passed an unrealistic value for the range 
parameter, as starting value for the variogram model argument of 
fit.variogram?
--
Edzer

Zev Ross wrote:
> Hi All,
>
> I'm fitting variograms in GSTAT with fit.variogram and I was surprised 
> to find that all my fits were singular. I experimented with converting 
> the data to unprojected data (decimal degrees) and with dividing my X 
> and Y coordinates, which are in meters, by 1000 (to get KM). In both 
> cases the fitting procedure worked with no singularity. Based on the 
> numbers of pairs the bins appeared to be about the same so it appears 
> to be a matter of the coordinates themselves.
>
> I'd prefer not to have to convert the coordinates back and forth 
> between meters and KM, any suggestions?
>
> Zev
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de



From Roger.Bivand at nhh.no  Wed Dec 10 08:45:30 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 10 Dec 2008 08:45:30 +0100 (CET)
Subject: [R-sig-Geo] subset point data set by distance ranges
In-Reply-To: <OFF70D9A0C.10DFF46E-ON8525751B.000C27A8-8525751B.000C27C6@usgs.gov>
References: <OFF70D9A0C.10DFF46E-ON8525751B.000C27A8-8525751B.000C27C6@usgs.gov>
Message-ID: <alpine.LRH.2.00.0812100842450.14432@reclus.nhh.no>

On Tue, 9 Dec 2008, David M Warner wrote:

> Greetings
> I'm using R 2.8 with recent (last month) versions of the packages I need to
> use at present.
> ?
> I'm interested in examining hierarchical spatio-temporal patterns in a data
> set.??The data consist of 94 points (X, Y, UTM coordinates) at which catch
> rates for a fish were recorded and there are also estimates of prey
> available for these fish at the same locations.? I have reason to believe
> that the relationships between predators and prey varies with spatial scale
> (nested processes).
> ?
> To test this hypothesis, I'd like?to generate subsets of the points that are
> separated by distance ranges (1-50 km, 51-100 km, etc) so I can run Sncf
> (package ncf) on the subsets.
> ?
> I cannot find a way to do this with R code.? Getting a distance matrix is
> easy.??Using that to help generate?a series of distance-based subsets is
> something I cannot figure out (without manually entering a list of all the
> point pairs).

Perhaps see dnearneigh() in spdep? It will return a list of vectors 
of point indices within the distance thresholds given, which you could 
post-process for your purposes.

Roger

> ?
> Any suggestions would be appreciated.
> Dave Warner?
> David?Warner
> Research?Fishery?Biologist
> USGS?Great?Lakes?Science?Center
> 1451?Green?Road
> Ann?Arbor?MI?48105
> 734.214.9392
> 
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From Roger.Bivand at nhh.no  Wed Dec 10 08:59:28 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 10 Dec 2008 08:59:28 +0100 (CET)
Subject: [R-sig-Geo] overlay point extraction of pixel radius (3x3
 window)
In-Reply-To: <BAY125-W56461B3D25C3DC88FE20F587FB0@phx.gbl>
References: <BAY125-W56461B3D25C3DC88FE20F587FB0@phx.gbl>
Message-ID: <alpine.LRH.2.00.0812100845550.14432@reclus.nhh.no>

On Wed, 10 Dec 2008, zack holden wrote:

>
> Dear list,
>
> I would like to use points to extract values from underlying grids, 
> modifying my query to return the mean, standard deviation, or other 
> function of the cells adjacent to the center grid cell. I assume this is 
> possible, but I can find no examples of this in previous posts or in the 
> Bivand et al. Applied spatial data analysis book.
>
> Would anyone be willing to suggest how to do this or better yet, provide 
> some example code?

library(sp)
data(meuse.grid)
coordinates(meuse.grid) <- c("x", "y")
gridded(meuse.grid) <- TRUE
library(spdep)

# find rook distance (like chess), queen will be
# sqrt(2*(rook^2))
rook <- max(slot(slot(meuse.grid, "grid"), "cellsize"))
library(spdep)

# create a list of neighbours for these distance criteria
nb_rook <- dnearneigh(coordinates(meuse.grid), 0, rook)
nb_rook

# only dist is continuous here, and not very interesting
names(meuse.grid)
meuse.grid$m_dist <- sapply(nb_rook, function(i) mean(meuse.grid$dist[i]))
spplot(meuse.grid, c("dist", "m_dist"))

Roger


>
> Thanks in advance for any help,
>
> Zack
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ddepew at sciborg.uwaterloo.ca  Wed Dec 10 17:23:33 2008
From: ddepew at sciborg.uwaterloo.ca (Dave Depew)
Date: Wed, 10 Dec 2008 11:23:33 -0500
Subject: [R-sig-Geo] resampling grids
Message-ID: <493FED05.4000507@scimail.uwaterloo.ca>

Hi all,
I apologize in advance, I haven't the time today to comb the help list 
for tips and hints, but does anyone know how to resample a 20 by 20m 
grid so the operational spacing is down to a 10 by 10m grid?
Any assistance is MUCH appreciated!

-- 
David Depew
PhD Candidate
Department of Biology
University of Waterloo
200 University Ave W.
Waterloo, ON. Canada
N2L 3G1

(T) 1-519-888-4567 x33895
(F) 1-519-746-0614

http://www.science.uwaterloo.ca/~ddepew



From rob.robinson at bto.org  Wed Dec 10 18:01:16 2008
From: rob.robinson at bto.org (Rob Robinson)
Date: Wed, 10 Dec 2008 17:01:16 -0000
Subject: [R-sig-Geo] Subsetting a spatial grid
In-Reply-To: <493FED05.4000507@scimail.uwaterloo.ca>
References: <493FED05.4000507@scimail.uwaterloo.ca>
Message-ID: <200592B6411E4891A2A6AE8ABDCB01FB@btodomain.bto.org>

Help - please! :-)
 I have what I thought was a really simple problem. I have a raster image of
satellite data from which I would like to extract an arbitrary (but simple
rectangular) portion for subsequent analysis (which I'll need to do for many
images). I have the data as a (projected) SpatialGridDataFrame and have
tried two approaches: create a SpatialPolygon and overlay it (but I don't
think overlay does what I would like it to do), or access the coords slot of
the data set and pick those within the range. I haven't been able to get
either to work - presumably because my R is not good enough! It seems a
fairly common task, but I haven't yet stumbled across an FAQ or page in
ASDAR which seems to help. Any pointers anyone?
Many thanks for any help
Cheers
rob

*** Want to know about Britain's birds? Try  www.bto.org/birdfacts ***

Dr Rob Robinson, Senior Population Biologist
British Trust for Ornithology, The Nunnery, Thetford, Norfolk, IP24 2PU
Ph: +44 (0)1842 750050        E: rob.robinson at bto.org
Fx: +44 (0)1842 750030        W: www.bto.org/cv/rob_robinson.htm

==== "How can anyone be enlightened, when truth is so poorly lit" =====



From Jason.Gasper at noaa.gov  Wed Dec 10 19:22:41 2008
From: Jason.Gasper at noaa.gov (Jason Gasper)
Date: Wed, 10 Dec 2008 09:22:41 -0900
Subject: [R-sig-Geo] resampling grids
In-Reply-To: <493FED05.4000507@scimail.uwaterloo.ca>
References: <493FED05.4000507@scimail.uwaterloo.ca>
Message-ID: <494008F1.9050803@noaa.gov>

Hello David,

I am not sure I completly understand what you want to do, but Hawths 
tools (a free add in for arcMAP) has a  resampling function that may be 
of use:  http://www.spatialecology.com/htools/rndselss.php.  Spatial 
analyst also has some resampling functions.  If you have access to ESRI 
you could read the data into R using the maptools. package.






Dave Depew wrote:
> Hi all,
> I apologize in advance, I haven't the time today to comb the help list 
> for tips and hints, but does anyone know how to resample a 20 by 20m 
> grid so the operational spacing is down to a 10 by 10m grid?
> Any assistance is MUCH appreciated!
>



From debeaudette at ucdavis.edu  Wed Dec 10 19:25:49 2008
From: debeaudette at ucdavis.edu (Dylan Beaudette)
Date: Wed, 10 Dec 2008 10:25:49 -0800
Subject: [R-sig-Geo] Subsetting a spatial grid
In-Reply-To: <200592B6411E4891A2A6AE8ABDCB01FB@btodomain.bto.org>
References: <493FED05.4000507@scimail.uwaterloo.ca>
	<200592B6411E4891A2A6AE8ABDCB01FB@btodomain.bto.org>
Message-ID: <200812101025.49108.dylan.beaudette@gmail.com>

On Wednesday 10 December 2008, Rob Robinson wrote:
> Help - please! :-)
>  I have what I thought was a really simple problem. I have a raster image
> of satellite data from which I would like to extract an arbitrary (but
> simple rectangular) portion for subsequent analysis (which I'll need to do
> for many images). I have the data as a (projected) SpatialGridDataFrame and
> have tried two approaches: create a SpatialPolygon and overlay it (but I
> don't think overlay does what I would like it to do), or access the coords
> slot of the data set and pick those within the range. I haven't been able
> to get either to work - presumably because my R is not good enough! It
> seems a fairly common task, but I haven't yet stumbled across an FAQ or
> page in ASDAR which seems to help. Any pointers anyone?
> Many thanks for any help
> Cheers
> rob

Not sure how to do this in R, but gdal_translate can do this for you on the 
command line. you will need a working GDAL install.

Cheers,

Dylan

>
> *** Want to know about Britain's birds? Try  www.bto.org/birdfacts ***
>
> Dr Rob Robinson, Senior Population Biologist
> British Trust for Ornithology, The Nunnery, Thetford, Norfolk, IP24 2PU
> Ph: +44 (0)1842 750050        E: rob.robinson at bto.org
> Fx: +44 (0)1842 750030        W: www.bto.org/cv/rob_robinson.htm
>
> ==== "How can anyone be enlightened, when truth is so poorly lit" =====
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341



From reeves at nceas.ucsb.edu  Wed Dec 10 19:35:25 2008
From: reeves at nceas.ucsb.edu (rick reeves)
Date: Wed, 10 Dec 2008 10:35:25 -0800
Subject: [R-sig-Geo] Subsetting a spatial grid
In-Reply-To: <200812101025.49108.dylan.beaudette@gmail.com>
References: <493FED05.4000507@scimail.uwaterloo.ca>	<200592B6411E4891A2A6AE8ABDCB01FB@btodomain.bto.org>
	<200812101025.49108.dylan.beaudette@gmail.com>
Message-ID: <49400BED.4020906@nceas.ucsb.edu>

The following R example might be a bit off-topic, but it does show how 
to create a point grid
and then use it to extract samples from an underlying set of vector 
polygons. The vector polygon
data could probably be replaced by a raster grid. Though not a very big 
one, given R's memory
limitations.

http://www.nceas.ucsb.edu/scicomp/GISSeminar/UseCases/SampleVectorPolygonsRasterGrid/SampleVectorPolysRastGrid.html

I might suggest the use of GRASS for this task.

Rick Reeves

Dylan Beaudette wrote:
> On Wednesday 10 December 2008, Rob Robinson wrote:
>   
>> Help - please! :-)
>>  I have what I thought was a really simple problem. I have a raster image
>> of satellite data from which I would like to extract an arbitrary (but
>> simple rectangular) portion for subsequent analysis (which I'll need to do
>> for many images). I have the data as a (projected) SpatialGridDataFrame and
>> have tried two approaches: create a SpatialPolygon and overlay it (but I
>> don't think overlay does what I would like it to do), or access the coords
>> slot of the data set and pick those within the range. I haven't been able
>> to get either to work - presumably because my R is not good enough! It
>> seems a fairly common task, but I haven't yet stumbled across an FAQ or
>> page in ASDAR which seems to help. Any pointers anyone?
>> Many thanks for any help
>> Cheers
>> rob
>>     
>
> Not sure how to do this in R, but gdal_translate can do this for you on the 
> command line. you will need a working GDAL install.
>
> Cheers,
>
> Dylan
>
>   
>> *** Want to know about Britain's birds? Try  www.bto.org/birdfacts ***
>>
>> Dr Rob Robinson, Senior Population Biologist
>> British Trust for Ornithology, The Nunnery, Thetford, Norfolk, IP24 2PU
>> Ph: +44 (0)1842 750050        E: rob.robinson at bto.org
>> Fx: +44 (0)1842 750030        W: www.bto.org/cv/rob_robinson.htm
>>
>> ==== "How can anyone be enlightened, when truth is so poorly lit" =====
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>     
>
>
>
>   


-- 
Rick Reeves
Scientific Programmer/Analyst and Data Manager
National Center for Ecological Analysis and Synthesis
UC Santa Barbara
www.nceas.ucsb.edu
805 892 2533



From zev at zevross.com  Wed Dec 10 20:03:57 2008
From: zev at zevross.com (Zev Ross)
Date: Wed, 10 Dec 2008 14:03:57 -0500
Subject: [R-sig-Geo] GSTAT - singular in meters not km
In-Reply-To: <493F6A64.6040101@uni-muenster.de>
References: <493EC1C1.7050902@zevross.com> <493F6A64.6040101@uni-muenster.de>
Message-ID: <4940129D.9050401@zevross.com>

Edzer (and all),

I don't think that it's related to an unrealistic range. I've tried a 
lot of different realistic and non-realistic values and get singular 
results each time. If I divide the X and Y coordinates by 10, 100, 1000 
or 10000 I don't get singularity. Using Lat and Long works fine. Code is 
below and I included a link to a workspace with the "pol" data set at 
the bottom.

Zev

polA<-pol
coordinates(polA)<-~x+y
v<-variogram(pollutant~1, data=polA)
v.fit<-fit.variogram(v, vgm(0.0005, "Sph", 40000, 0.00001))
attributes(v.fit)$singular # TRUE

polB<-pol
polB$x<-polB$x/1000
polB$y<-polB$y/1000
coordinates(polB)<-~x+y
v<-variogram(pollutant~1, data=polB)
v.fit<-fit.variogram(v, vgm(0.0005, "Sph", 40, 0.00001))
attributes(v.fit)$singular #FALSE

polC<-pol
coordinates(polC)<-~longitude+latitude
v<-variogram(pollutant~1, data=polC)
v.fit<-fit.variogram(v, vgm(0.0005, "Sph", .4, 0.00001))
attributes(v.fit)$singular # FALSE

http://www.zevross.com/temp2/singular_or_not.RData

Edzer Pebesma wrote:
> Hi Zev, it is hard to see what happens without seeing your data or R 
> commands.
>
> Is it possible that you passed an unrealistic value for the range 
> parameter, as starting value for the variogram model argument of 
> fit.variogram?
> -- 
> Edzer
>
> Zev Ross wrote:
>> Hi All,
>>
>> I'm fitting variograms in GSTAT with fit.variogram and I was 
>> surprised to find that all my fits were singular. I experimented with 
>> converting the data to unprojected data (decimal degrees) and with 
>> dividing my X and Y coordinates, which are in meters, by 1000 (to get 
>> KM). In both cases the fitting procedure worked with no singularity. 
>> Based on the numbers of pairs the bins appeared to be about the same 
>> so it appears to be a matter of the coordinates themselves.
>>
>> I'd prefer not to have to convert the coordinates back and forth 
>> between meters and KM, any suggestions?
>>
>> Zev
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From T.Hengl at uva.nl  Thu Dec 11 10:00:23 2008
From: T.Hengl at uva.nl (Tomislav Hengl)
Date: Thu, 11 Dec 2008 10:00:23 +0100
Subject: [R-sig-Geo] resampling grids
In-Reply-To: <494008F1.9050803@noaa.gov>
References: <493FED05.4000507@scimail.uwaterloo.ca> <494008F1.9050803@noaa.gov>
Message-ID: <DDD8EA1646744F869F35D2D3B7E9E746@pcibed193>


A quick way to rescale a set of maps is to use the grid tools of SAGA GIS (see
rsaga.get.usage("grid_tools", 0)). First, download all ASCII file maps to a working directory, then
obtain the list of maps in the folder, and then automate:

> ascmaps <- list.files(getwd(), pattern="\\.asc$", full=F)
> levels(ascmaps) <- list.files(getwd(), pattern="\\.asc$", full=F)
> ascmaps500 <- ascmaps
> levels(ascmaps500) <- paste("500m",levels(ascmaps),sep="")
> library(RSAGA)
> rsaga.esri.to.sgrd(in.grids=levels(ascmaps),
out.sgrds=set.file.extension(levels(ascmaps),".sgrd"), in.path=getwd())
> rsaga.get.usage("grid_tools", 0)
> for (i in 1:length(ascmaps)) {
     rsaga.geoprocessor(lib="grid_tools", module=0,
param=list(INPUT=set.file.extension(levels(ascmaps)[i],".sgrd"),
     GRID=set.file.extension(levels(ascmaps500)[i],".sgrd"), METHOD=0, DIMENSIONS_CELLSIZE=500,
SCALE_UP_METHOD=1))
}
> rsaga.sgrd.to.esri(in.sgrds=set.file.extension(levels(ascmaps500),".sgrd"), 
    out.grids=set.file.extension(levels(ascmaps500),".asc"), out.path=getwd(), prec=1)
> unlink("*.hgrd") # delete the temporary files (SAGA)
> unlink("*.sgrd")
> unlink("*.sdat")

Note that you only need to set the resolution of the output maps and/or the rescaling method:

-SCALE_UP_METHOD:<num>        Interpolation Method
        Choice
        Available Choices:
        [0] Nearest Neighbor
        [1] Bilinear Interpolation
        [2] Inverse Distance Interpolation
        [3] Bicubic Spline Interpolation
        [4] B-Spline Interpolation
        [5] Mean Value
  -SCALE_DOWN_METHOD:<num>      Interpolation Method
        Choice
        Available Choices:
        [0] Nearest Neighbor
        [1] Bilinear Interpolation
        [2] Inverse Distance Interpolation
        [3] Bicubic Spline Interpolation
        [4] B-Spline Interpolation


Mechanical down-scaling from 20 to 10 m is certainly doable but you will be 'cheating' right?

More stuff on this topic (downscaling) in e.g.:

Marc F. P. Bierkens, Peter A. Finke, P. de Willigen, 2000. Upscaling and Downscaling Methods for
Environmental Research. Springer, ISBN 0792363396, 9780792363392, 190 pages.
http://www.amazon.com/gp/reader/0792363396/ 


Tom Hengl
http://spatial-analyst.net/wiki/index.php?title=Software 




-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
Jason Gasper
Sent: Wednesday, December 10, 2008 7:23 PM
To: Dave Depew
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] resampling grids

Hello David,

I am not sure I completly understand what you want to do, but Hawths 
tools (a free add in for arcMAP) has a  resampling function that may be 
of use:  http://www.spatialecology.com/htools/rndselss.php.  Spatial 
analyst also has some resampling functions.  If you have access to ESRI 
you could read the data into R using the maptools. package.






Dave Depew wrote:
> Hi all,
> I apologize in advance, I haven't the time today to comb the help list 
> for tips and hints, but does anyone know how to resample a 20 by 20m 
> grid so the operational spacing is down to a 10 by 10m grid?
> Any assistance is MUCH appreciated!
>

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From ct529 at york.ac.uk  Thu Dec 11 12:46:37 2008
From: ct529 at york.ac.uk (Corrado)
Date: Thu, 11 Dec 2008 11:46:37 +0000
Subject: [R-sig-Geo] Principal Component Analysis - Selecting components? +
	right choice?
Message-ID: <200812111146.38088.ct529@york.ac.uk>

Dear R gurus,

I have some climatic data for a region of the world. They are monthly averages 
1950 -2000 of precipitation (12 months), minimum temperature (12 months), 
maximum temperature (12 months). I have scaled them to 2 km x 2km cells, and 
I have around 75,000 cells.

I need to feed them into a statistical model as co-variates, to use them to 
predict a response variable.

The climatic data are obviously correlated: precipitation for January is 
correlated to precipitation for February and so on .... even precipitation 
and temperature are heavily correlated. I did some correlation analysis and 
they are all strongly correlated.

I though of running PCA on them, in order to reduce the number of co-variates 
I feed into the model.

I run the PCA using prcomp, quite successfully. Now I need to use a criteria 
to select the right number of PC. (that is: is it 1,2,3,4?)

What criteria would you suggest?

At the moment, I am using a criteria based on threshold, but that is highly 
subjective, even if there are some rules of thumb (Jolliffe,Principal 
Component Analysis, II Edition, Springer Verlag,2002). 

Could you suggest something more rigorous?

By the way, do you think I would have been better off by using something 
different from PCA?

Best,
-- 
Corrado Topi

Global Climate Change & Biodiversity Indicators
Area 18,Department of Biology
University of York, York, YO10 5YW, UK
Phone: + 44 (0) 1904 328645, E-mail: ct529 at york.ac.uk



From edzer.pebesma at uni-muenster.de  Thu Dec 11 13:17:01 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 11 Dec 2008 13:17:01 +0100
Subject: [R-sig-Geo] GSTAT - singular in meters not km
In-Reply-To: <4940129D.9050401@zevross.com>
References: <493EC1C1.7050902@zevross.com> <493F6A64.6040101@uni-muenster.de>
	<4940129D.9050401@zevross.com>
Message-ID: <494104BD.8050301@uni-muenster.de>

Thanks for the reproducalbe example, Zev;

the whole thing looks very strange to me; it seems to be the combination 
of very large distance values and very small semivariance values that 
triggers this -- when I multiply v$gamma with 1000, many different 
initial variogram values are fit without problems again. Something 
someone (that's usually me) will have to look into more closely, I'm afraid!

Best regards,
--
Edzer

Zev Ross wrote:
> Edzer (and all),
>
> I don't think that it's related to an unrealistic range. I've tried a 
> lot of different realistic and non-realistic values and get singular 
> results each time. If I divide the X and Y coordinates by 10, 100, 
> 1000 or 10000 I don't get singularity. Using Lat and Long works fine. 
> Code is below and I included a link to a workspace with the "pol" data 
> set at the bottom.
>
> Zev
>
> polA<-pol
> coordinates(polA)<-~x+y
> v<-variogram(pollutant~1, data=polA)
> v.fit<-fit.variogram(v, vgm(0.0005, "Sph", 40000, 0.00001))
> attributes(v.fit)$singular # TRUE
>
> polB<-pol
> polB$x<-polB$x/1000
> polB$y<-polB$y/1000
> coordinates(polB)<-~x+y
> v<-variogram(pollutant~1, data=polB)
> v.fit<-fit.variogram(v, vgm(0.0005, "Sph", 40, 0.00001))
> attributes(v.fit)$singular #FALSE
>
> polC<-pol
> coordinates(polC)<-~longitude+latitude
> v<-variogram(pollutant~1, data=polC)
> v.fit<-fit.variogram(v, vgm(0.0005, "Sph", .4, 0.00001))
> attributes(v.fit)$singular # FALSE
>
> http://www.zevross.com/temp2/singular_or_not.RData
>
> Edzer Pebesma wrote:
>> Hi Zev, it is hard to see what happens without seeing your data or R 
>> commands.
>>
>> Is it possible that you passed an unrealistic value for the range 
>> parameter, as starting value for the variogram model argument of 
>> fit.variogram?
>> -- 
>> Edzer
>>
>> Zev Ross wrote:
>>> Hi All,
>>>
>>> I'm fitting variograms in GSTAT with fit.variogram and I was 
>>> surprised to find that all my fits were singular. I experimented 
>>> with converting the data to unprojected data (decimal degrees) and 
>>> with dividing my X and Y coordinates, which are in meters, by 1000 
>>> (to get KM). In both cases the fitting procedure worked with no 
>>> singularity. Based on the numbers of pairs the bins appeared to be 
>>> about the same so it appears to be a matter of the coordinates 
>>> themselves.
>>>
>>> I'd prefer not to have to convert the coordinates back and forth 
>>> between meters and KM, any suggestions?
>>>
>>> Zev
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de



From ashton at msu.edu  Thu Dec 11 15:10:38 2008
From: ashton at msu.edu (Ashton Shortridge)
Date: Thu, 11 Dec 2008 09:10:38 -0500
Subject: [R-sig-Geo] Principal Component Analysis - Selecting
	components? + right choice?
In-Reply-To: <200812111146.38088.ct529@york.ac.uk>
References: <200812111146.38088.ct529@york.ac.uk>
Message-ID: <200812110910.38588.ashton@msu.edu>

Hi Corrado,

> I run the PCA using prcomp, quite successfully. Now I need to use a
> criteria to select the right number of PC. (that is: is it 1,2,3,4?)
>
> What criteria would you suggest?

that's an interesting and probably controversy-generating question. It's 
probably not an R-sig-geo question, either. I am not a PCA person, but the 
rule of thumb I am aware of is to plot the variability each 
component 'explains' and look for a clear breakpoint. I would think about any 
multivariate analysis text would have a better explanation than I can give, 
though.

As for something more rigorous, I think a lot of people are reluctant to use 
PCA as a modeling approach not so much because it's hard to choose a 
threshold for selecting components, but because the interpretation of the 
meaning of each component is pretty subjective. If you want an explanatory 
model, be careful about using PCA. You would be better served by deciding, 
based perhaps on expert knowledge about the variables, which ones to use in 
the model and which ones not to.

To try to make this a bit more spatial, and therefore more relevant to the 
list, I will also warn you that your various climate variables are almost 
certainly spatially autocorrelated - that is, neighboring and nearby 
observations in the grid are not independent. That has serious implications 
for standard multivariate analysis techniques and diagnostics.

Yours,

Ashton

On Thursday 11 December 2008 06:46:37 am Corrado wrote:
> Dear R gurus,
>
> I have some climatic data for a region of the world. They are monthly
> averages 1950 -2000 of precipitation (12 months), minimum temperature (12
> months), maximum temperature (12 months). I have scaled them to 2 km x 2km
> cells, and I have around 75,000 cells.
>
> I need to feed them into a statistical model as co-variates, to use them to
> predict a response variable.
>
> The climatic data are obviously correlated: precipitation for January is
> correlated to precipitation for February and so on .... even precipitation
> and temperature are heavily correlated. I did some correlation analysis and
> they are all strongly correlated.
>
> I though of running PCA on them, in order to reduce the number of
> co-variates I feed into the model.
>
> I run the PCA using prcomp, quite successfully. Now I need to use a
> criteria to select the right number of PC. (that is: is it 1,2,3,4?)
>
> What criteria would you suggest?
>
> At the moment, I am using a criteria based on threshold, but that is highly
> subjective, even if there are some rules of thumb (Jolliffe,Principal
> Component Analysis, II Edition, Springer Verlag,2002).
>
> Could you suggest something more rigorous?
>
> By the way, do you think I would have been better off by using something
> different from PCA?
>
> Best,



-- 
Ashton Shortridge
Associate Professor			ashton at msu.edu
Dept of Geography			http://www.msu.edu/~ashton
235 Geography Building		ph (517) 432-3561
Michigan State University		fx (517) 432-1671



From edzer.pebesma at uni-muenster.de  Thu Dec 11 15:24:07 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 11 Dec 2008 15:24:07 +0100
Subject: [R-sig-Geo] GSTAT - singular in meters not km
In-Reply-To: <4940129D.9050401@zevross.com>
References: <493EC1C1.7050902@zevross.com> <493F6A64.6040101@uni-muenster.de>
	<4940129D.9050401@zevross.com>
Message-ID: <49412287.7020600@uni-muenster.de>

Zev, if you do a

v.fit<-fit.variogram(v, vgm(0.0005, "Sph", 40000, 0.00001),debug.level=32)

you'll see that the X matrix of the Gauss-Newton iteration with the 
derivatives of the parameters to the error sum of squares is nearly 
singular. The condition number of this matrix is so large that it makes 
the problem ill-conditioned. If you add argument fit.ranges=FALSE it 
will not be singular anymore.

In the end, this problem is similar to e.g. regression of polynomials on 
coordinates without standardizing the coordinates.

I'll add a warning message to fit.variogram to suggest the two 
solutions, for this case.
--
Edzer

Zev Ross wrote:
> Edzer (and all),
>
> I don't think that it's related to an unrealistic range. I've tried a 
> lot of different realistic and non-realistic values and get singular 
> results each time. If I divide the X and Y coordinates by 10, 100, 
> 1000 or 10000 I don't get singularity. Using Lat and Long works fine. 
> Code is below and I included a link to a workspace with the "pol" data 
> set at the bottom.
>
> Zev
>
> polA<-pol
> coordinates(polA)<-~x+y
> v<-variogram(pollutant~1, data=polA)
> v.fit<-fit.variogram(v, vgm(0.0005, "Sph", 40000, 0.00001))
> attributes(v.fit)$singular # TRUE
>
> polB<-pol
> polB$x<-polB$x/1000
> polB$y<-polB$y/1000
> coordinates(polB)<-~x+y
> v<-variogram(pollutant~1, data=polB)
> v.fit<-fit.variogram(v, vgm(0.0005, "Sph", 40, 0.00001))
> attributes(v.fit)$singular #FALSE
>
> polC<-pol
> coordinates(polC)<-~longitude+latitude
> v<-variogram(pollutant~1, data=polC)
> v.fit<-fit.variogram(v, vgm(0.0005, "Sph", .4, 0.00001))
> attributes(v.fit)$singular # FALSE
>
> http://www.zevross.com/temp2/singular_or_not.RData
>
> Edzer Pebesma wrote:
>> Hi Zev, it is hard to see what happens without seeing your data or R 
>> commands.
>>
>> Is it possible that you passed an unrealistic value for the range 
>> parameter, as starting value for the variogram model argument of 
>> fit.variogram?
>> -- 
>> Edzer
>>
>> Zev Ross wrote:
>>> Hi All,
>>>
>>> I'm fitting variograms in GSTAT with fit.variogram and I was 
>>> surprised to find that all my fits were singular. I experimented 
>>> with converting the data to unprojected data (decimal degrees) and 
>>> with dividing my X and Y coordinates, which are in meters, by 1000 
>>> (to get KM). In both cases the fitting procedure worked with no 
>>> singularity. Based on the numbers of pairs the bins appeared to be 
>>> about the same so it appears to be a matter of the coordinates 
>>> themselves.
>>>
>>> I'd prefer not to have to convert the coordinates back and forth 
>>> between meters and KM, any suggestions?
>>>
>>> Zev
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de



From Kamran.Safi at ioz.ac.uk  Thu Dec 11 15:29:27 2008
From: Kamran.Safi at ioz.ac.uk (Kamran Safi)
Date: Thu, 11 Dec 2008 14:29:27 -0000
Subject: [R-sig-Geo] Principal Component Analysis - Selectingcomponents?
	+ right choice?
In-Reply-To: <200812110910.38588.ashton@msu.edu>
References: <200812111146.38088.ct529@york.ac.uk>
	<200812110910.38588.ashton@msu.edu>
Message-ID: <41E1ED29E5E8E34BBDD8B82CFA1A9D040638098F@zsl26>

Hi all,

I agree with Ashton. The issue is very complex and far from resolved.
But sometimes we have to go down the PCA path. Among the many possible
solutions is the broken stick approach, for which you find an R solution
(bstick()) in the package vegan. Technically the broken stick randomly
divides 100% variance into your N principal components and generates a
null expectation for the distributions of randomly partioning the
original variance. You then take all those PCAs that are above the
broken stick distribution. This is by no means an agreed upon approach,
but it is at least reproducible and has some theory behind it, but is
and will remain a rule of thumb.
In terms of spatial analysis you could derive the PCAs and then go into
classic spatial analysis. Although the interpretation of PCA is
sometimes complicated or even impossible, you can calculate the values
for every grid cell and then go into multivariate analysis whereby you
have to take spatial autocorrelation into account. At least your PCA
components are orthogonal, which simplifies your analysis in contrast to
using the original variables. It also allows you to produce predictive
models. 
What you could think of doing could be using PCA to derive
"environmental" variables which are uncorrelated and the use the
distance matrix and spatial filtering to "remove" spatial
autocorrelation. 

Hope this helps,

Kami



------------------------
Kamran Safi

Postdoctoral Research Fellow
Institute of Zoology
Zoological Society of London
Regent's Park
London NW1 4RY

http://www.zoo.cam.ac.uk/ioz/people/safi.htm

http://spatialr.googlepages.com
http://asapi.wetpaint.com

-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Ashton
Shortridge
Sent: 11 December 2008 14:11
To: r-sig-geo at stat.math.ethz.ch
Cc: Corrado
Subject: Re: [R-sig-Geo] Principal Component Analysis -
Selectingcomponents? + right choice?

Hi Corrado,

> I run the PCA using prcomp, quite successfully. Now I need to use a
> criteria to select the right number of PC. (that is: is it 1,2,3,4?)
>
> What criteria would you suggest?

that's an interesting and probably controversy-generating question. It's

probably not an R-sig-geo question, either. I am not a PCA person, but
the 
rule of thumb I am aware of is to plot the variability each 
component 'explains' and look for a clear breakpoint. I would think
about any 
multivariate analysis text would have a better explanation than I can
give, 
though.

As for something more rigorous, I think a lot of people are reluctant to
use 
PCA as a modeling approach not so much because it's hard to choose a 
threshold for selecting components, but because the interpretation of
the 
meaning of each component is pretty subjective. If you want an
explanatory 
model, be careful about using PCA. You would be better served by
deciding, 
based perhaps on expert knowledge about the variables, which ones to use
in 
the model and which ones not to.

To try to make this a bit more spatial, and therefore more relevant to
the 
list, I will also warn you that your various climate variables are
almost 
certainly spatially autocorrelated - that is, neighboring and nearby 
observations in the grid are not independent. That has serious
implications 
for standard multivariate analysis techniques and diagnostics.

Yours,

Ashton

On Thursday 11 December 2008 06:46:37 am Corrado wrote:
> Dear R gurus,
>
> I have some climatic data for a region of the world. They are monthly
> averages 1950 -2000 of precipitation (12 months), minimum temperature
(12
> months), maximum temperature (12 months). I have scaled them to 2 km x
2km
> cells, and I have around 75,000 cells.
>
> I need to feed them into a statistical model as co-variates, to use
them to
> predict a response variable.
>
> The climatic data are obviously correlated: precipitation for January
is
> correlated to precipitation for February and so on .... even
precipitation
> and temperature are heavily correlated. I did some correlation
analysis and
> they are all strongly correlated.
>
> I though of running PCA on them, in order to reduce the number of
> co-variates I feed into the model.
>
> I run the PCA using prcomp, quite successfully. Now I need to use a
> criteria to select the right number of PC. (that is: is it 1,2,3,4?)
>
> What criteria would you suggest?
>
> At the moment, I am using a criteria based on threshold, but that is
highly
> subjective, even if there are some rules of thumb (Jolliffe,Principal
> Component Analysis, II Edition, Springer Verlag,2002).
>
> Could you suggest something more rigorous?
>
> By the way, do you think I would have been better off by using
something
> different from PCA?
>
> Best,



-- 
Ashton Shortridge
Associate Professor			ashton at msu.edu
Dept of Geography			http://www.msu.edu/~ashton
235 Geography Building		ph (517) 432-3561
Michigan State University		fx (517) 432-1671

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo




Click
https://www.mailcontrol.com/sr/wQw0zmjPoHdJTZGyOCrrhg==
dsq0SUeqeT9ZUvqzszeURfMOCDRy5!TUZWDEGNPdlyNkQ==  to report this email as
spam.


The Zoological Society of London is incorporated by Royal Charter
Principal Office England. Company Number RC000749
Registered address: 
Regent's Park, London, England NW1 4RY
Registered Charity in England and Wales no. 208728 

_________________________________________________________________________
This e-mail has been sent in confidence to the named add...{{dropped:17}}



From edzer.pebesma at uni-muenster.de  Thu Dec 11 15:45:28 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 11 Dec 2008 15:45:28 +0100
Subject: [R-sig-Geo] Principal Component Analysis -
 Selecting	components? + right choice?
In-Reply-To: <200812110910.38588.ashton@msu.edu>
References: <200812111146.38088.ct529@york.ac.uk>
	<200812110910.38588.ashton@msu.edu>
Message-ID: <49412788.9020803@uni-muenster.de>

Principle components don't search for directions that best explain your 
dependent variable, but rather try to capture variability and/or 
correlation in the predictors. Methods that look for subspaces that best 
predict the dependent are for instance are partial least squares and 
ridge regression. Using them, you could with the same amount of degrees 
of freedom look at completely different directions.

In addition to Ashton's remark: a variety of principle components that 
tries to pick up spatial correlated patterns in addition to maximum 
variability/correlation between variables is MNF (minimum nois fraction) 
factors, also called min/max autocorrelation factors; see the papers by 
Green, Switzer and others. I'm not aware of implementations of them in 
R, but would be interested to hear.

Best regards,
--
Edzer

Ashton Shortridge wrote:
> Hi Corrado,
>
>   
>> I run the PCA using prcomp, quite successfully. Now I need to use a
>> criteria to select the right number of PC. (that is: is it 1,2,3,4?)
>>
>> What criteria would you suggest?
>>     
>
> that's an interesting and probably controversy-generating question. It's 
> probably not an R-sig-geo question, either. I am not a PCA person, but the 
> rule of thumb I am aware of is to plot the variability each 
> component 'explains' and look for a clear breakpoint. I would think about any 
> multivariate analysis text would have a better explanation than I can give, 
> though.
>
> As for something more rigorous, I think a lot of people are reluctant to use 
> PCA as a modeling approach not so much because it's hard to choose a 
> threshold for selecting components, but because the interpretation of the 
> meaning of each component is pretty subjective. If you want an explanatory 
> model, be careful about using PCA. You would be better served by deciding, 
> based perhaps on expert knowledge about the variables, which ones to use in 
> the model and which ones not to.
>
> To try to make this a bit more spatial, and therefore more relevant to the 
> list, I will also warn you that your various climate variables are almost 
> certainly spatially autocorrelated - that is, neighboring and nearby 
> observations in the grid are not independent. That has serious implications 
> for standard multivariate analysis techniques and diagnostics.
>
> Yours,
>
> Ashton
>
> On Thursday 11 December 2008 06:46:37 am Corrado wrote:
>   
>> Dear R gurus,
>>
>> I have some climatic data for a region of the world. They are monthly
>> averages 1950 -2000 of precipitation (12 months), minimum temperature (12
>> months), maximum temperature (12 months). I have scaled them to 2 km x 2km
>> cells, and I have around 75,000 cells.
>>
>> I need to feed them into a statistical model as co-variates, to use them to
>> predict a response variable.
>>
>> The climatic data are obviously correlated: precipitation for January is
>> correlated to precipitation for February and so on .... even precipitation
>> and temperature are heavily correlated. I did some correlation analysis and
>> they are all strongly correlated.
>>
>> I though of running PCA on them, in order to reduce the number of
>> co-variates I feed into the model.
>>
>> I run the PCA using prcomp, quite successfully. Now I need to use a
>> criteria to select the right number of PC. (that is: is it 1,2,3,4?)
>>
>> What criteria would you suggest?
>>
>> At the moment, I am using a criteria based on threshold, but that is highly
>> subjective, even if there are some rules of thumb (Jolliffe,Principal
>> Component Analysis, II Edition, Springer Verlag,2002).
>>
>> Could you suggest something more rigorous?
>>
>> By the way, do you think I would have been better off by using something
>> different from PCA?
>>
>> Best,
>>     
>
>
>
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de



From ct529 at york.ac.uk  Thu Dec 11 15:44:13 2008
From: ct529 at york.ac.uk (Corrado)
Date: Thu, 11 Dec 2008 14:44:13 +0000
Subject: [R-sig-Geo] Principal Component Analysis - Selectingcomponents?
	+ right choice?
In-Reply-To: <41E1ED29E5E8E34BBDD8B82CFA1A9D040638098F@zsl26>
References: <200812111146.38088.ct529@york.ac.uk>
	<200812110910.38588.ashton@msu.edu>
	<41E1ED29E5E8E34BBDD8B82CFA1A9D040638098F@zsl26>
Message-ID: <200812111444.13540.ct529@york.ac.uk>

Hi all,

I used a rule of thumb as reported by the book quoted, but I am not completely 
happy with it, because it is not really a statistical justification.

I will try the broken stick approach, thanks!

Concerning the interpretation, luckily enough PC1 has a clear interpretation. 
PC2 a bit less so, though .... and the complexity of interpretation increases 
with explained variance decreasing.

I am using the approach suggested by Kamran: I have brewed down the original 
climatic variables to uncorrelated "environmental variables", and I have 
chosen the signification ones using a threshold. I do realise spatial 
auto-correlation is going to be important (even if my sites are fairly 
distant from one another, reducing the impact), but  do not know anything 
about spatial filtering. Whilst I have used distance matrices, I have never 
used them to remove spatial auto-correlation!

Could you please point me out to some resources please?

Best,




On Thursday 11 December 2008 14:29:27 Kamran Safi wrote:
> Hi all,
>
> I agree with Ashton. The issue is very complex and far from resolved.
> But sometimes we have to go down the PCA path. Among the many possible
> solutions is the broken stick approach, for which you find an R solution
> (bstick()) in the package vegan. Technically the broken stick randomly
> divides 100% variance into your N principal components and generates a
> null expectation for the distributions of randomly partioning the
> original variance. You then take all those PCAs that are above the
> broken stick distribution. This is by no means an agreed upon approach,
> but it is at least reproducible and has some theory behind it, but is
> and will remain a rule of thumb.
> In terms of spatial analysis you could derive the PCAs and then go into
> classic spatial analysis. Although the interpretation of PCA is
> sometimes complicated or even impossible, you can calculate the values
> for every grid cell and then go into multivariate analysis whereby you
> have to take spatial autocorrelation into account. At least your PCA
> components are orthogonal, which simplifies your analysis in contrast to
> using the original variables. It also allows you to produce predictive
> models.
> What you could think of doing could be using PCA to derive
> "environmental" variables which are uncorrelated and the use the
> distance matrix and spatial filtering to "remove" spatial
> autocorrelation.
>
> Hope this helps,
>
> Kami
>
>
>
> ------------------------
> Kamran Safi
>
> Postdoctoral Research Fellow
> Institute of Zoology
> Zoological Society of London
> Regent's Park
> London NW1 4RY
>
> http://www.zoo.cam.ac.uk/ioz/people/safi.htm
>
> http://spatialr.googlepages.com
> http://asapi.wetpaint.com
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Ashton
> Shortridge
> Sent: 11 December 2008 14:11
> To: r-sig-geo at stat.math.ethz.ch
> Cc: Corrado
> Subject: Re: [R-sig-Geo] Principal Component Analysis -
> Selectingcomponents? + right choice?
>
> Hi Corrado,
>
> > I run the PCA using prcomp, quite successfully. Now I need to use a
> > criteria to select the right number of PC. (that is: is it 1,2,3,4?)
> >
> > What criteria would you suggest?
>
> that's an interesting and probably controversy-generating question. It's
>
> probably not an R-sig-geo question, either. I am not a PCA person, but
> the
> rule of thumb I am aware of is to plot the variability each
> component 'explains' and look for a clear breakpoint. I would think
> about any
> multivariate analysis text would have a better explanation than I can
> give,
> though.
>
> As for something more rigorous, I think a lot of people are reluctant to
> use
> PCA as a modeling approach not so much because it's hard to choose a
> threshold for selecting components, but because the interpretation of
> the
> meaning of each component is pretty subjective. If you want an
> explanatory
> model, be careful about using PCA. You would be better served by
> deciding,
> based perhaps on expert knowledge about the variables, which ones to use
> in
> the model and which ones not to.
>
> To try to make this a bit more spatial, and therefore more relevant to
> the
> list, I will also warn you that your various climate variables are
> almost
> certainly spatially autocorrelated - that is, neighboring and nearby
> observations in the grid are not independent. That has serious
> implications
> for standard multivariate analysis techniques and diagnostics.
>
> Yours,
>
> Ashton
>
> On Thursday 11 December 2008 06:46:37 am Corrado wrote:
> > Dear R gurus,
> >
> > I have some climatic data for a region of the world. They are monthly
> > averages 1950 -2000 of precipitation (12 months), minimum temperature
>
> (12
>
> > months), maximum temperature (12 months). I have scaled them to 2 km x
>
> 2km
>
> > cells, and I have around 75,000 cells.
> >
> > I need to feed them into a statistical model as co-variates, to use
>
> them to
>
> > predict a response variable.
> >
> > The climatic data are obviously correlated: precipitation for January
>
> is
>
> > correlated to precipitation for February and so on .... even
>
> precipitation
>
> > and temperature are heavily correlated. I did some correlation
>
> analysis and
>
> > they are all strongly correlated.
> >
> > I though of running PCA on them, in order to reduce the number of
> > co-variates I feed into the model.
> >
> > I run the PCA using prcomp, quite successfully. Now I need to use a
> > criteria to select the right number of PC. (that is: is it 1,2,3,4?)
> >
> > What criteria would you suggest?
> >
> > At the moment, I am using a criteria based on threshold, but that is
>
> highly
>
> > subjective, even if there are some rules of thumb (Jolliffe,Principal
> > Component Analysis, II Edition, Springer Verlag,2002).
> >
> > Could you suggest something more rigorous?
> >
> > By the way, do you think I would have been better off by using
>
> something
>
> > different from PCA?
> >
> > Best,



-- 
Corrado Topi

Global Climate Change & Biodiversity Indicators
Area 18,Department of Biology
University of York, York, YO10 5YW, UK
Phone: + 44 (0) 1904 328645, E-mail: ct529 at york.ac.uk



From Kamran.Safi at ioz.ac.uk  Thu Dec 11 17:09:37 2008
From: Kamran.Safi at ioz.ac.uk (Kamran Safi)
Date: Thu, 11 Dec 2008 16:09:37 -0000
Subject: [R-sig-Geo] Principal Component Analysis - Selectingcomponents?
	+ right choice?
In-Reply-To: <200812111444.13540.ct529@york.ac.uk>
References: <200812111146.38088.ct529@york.ac.uk>
	<200812110910.38588.ashton@msu.edu>
	<41E1ED29E5E8E34BBDD8B82CFA1A9D040638098F@zsl26>
	<200812111444.13540.ct529@york.ac.uk>
Message-ID: <41E1ED29E5E8E34BBDD8B82CFA1A9D0406380A30@zsl26>

Hi Corrado,

A useful reference is: Diniz-Filho J.A.F. & Bini L.M. (2005). Modelling
geographical patterns in species richness using eigenvector-based
spatial filters. Global Ecology and Biogeography, 14, 177-185.

So what they do basically is using multidimensional scaling to derive
from the pairwise distance matrix a set of principal coordinates (not be
confused with principal components). MDS is a method (old!) that
converts a pairwise distance matrix into n-1 dimensional vertical
matrix. It is implemented in R base. Have a look at cmdscale() and
isoMDS(). There I would use all those PCo which significantly predict
your dependent variable(s) (But see below).

Another very useful and classic resource is this paper:
http://www.ufz.de/data/Dormann-et-al_Methods-Autocorrelation6834.pdf
Specifically its appendix. Spatial filtering is described there too.

Hope this helps. Good luck.

Kamran




------------------------
Kamran Safi

Postdoctoral Research Fellow
Institute of Zoology
Zoological Society of London
Regent's Park
London NW1 4RY

http://www.zoo.cam.ac.uk/ioz/people/safi.htm

http://spatialr.googlepages.com
http://asapi.wetpaint.com


-----Original Message-----
From: Corrado [mailto:ct529 at york.ac.uk] 
Sent: 11 December 2008 14:44
To: Kamran Safi
Cc: Ashton Shortridge; r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] Principal Component Analysis -
Selectingcomponents? + right choice?

Hi all,

I used a rule of thumb as reported by the book quoted, but I am not
completely 
happy with it, because it is not really a statistical justification.

I will try the broken stick approach, thanks!

Concerning the interpretation, luckily enough PC1 has a clear
interpretation. 
PC2 a bit less so, though .... and the complexity of interpretation
increases 
with explained variance decreasing.

I am using the approach suggested by Kamran: I have brewed down the
original 
climatic variables to uncorrelated "environmental variables", and I have

chosen the signification ones using a threshold. I do realise spatial 
auto-correlation is going to be important (even if my sites are fairly 
distant from one another, reducing the impact), but  do not know
anything 
about spatial filtering. Whilst I have used distance matrices, I have
never 
used them to remove spatial auto-correlation!

Could you please point me out to some resources please?

Best,




On Thursday 11 December 2008 14:29:27 Kamran Safi wrote:
> Hi all,
>
> I agree with Ashton. The issue is very complex and far from resolved.
> But sometimes we have to go down the PCA path. Among the many possible
> solutions is the broken stick approach, for which you find an R
solution
> (bstick()) in the package vegan. Technically the broken stick randomly
> divides 100% variance into your N principal components and generates a
> null expectation for the distributions of randomly partioning the
> original variance. You then take all those PCAs that are above the
> broken stick distribution. This is by no means an agreed upon
approach,
> but it is at least reproducible and has some theory behind it, but is
> and will remain a rule of thumb.
> In terms of spatial analysis you could derive the PCAs and then go
into
> classic spatial analysis. Although the interpretation of PCA is
> sometimes complicated or even impossible, you can calculate the values
> for every grid cell and then go into multivariate analysis whereby you
> have to take spatial autocorrelation into account. At least your PCA
> components are orthogonal, which simplifies your analysis in contrast
to
> using the original variables. It also allows you to produce predictive
> models.
> What you could think of doing could be using PCA to derive
> "environmental" variables which are uncorrelated and the use the
> distance matrix and spatial filtering to "remove" spatial
> autocorrelation.
>
> Hope this helps,
>
> Kami
>
>
>
> ------------------------
> Kamran Safi
>
> Postdoctoral Research Fellow
> Institute of Zoology
> Zoological Society of London
> Regent's Park
> London NW1 4RY
>
> http://www.zoo.cam.ac.uk/ioz/people/safi.htm
>
> http://spatialr.googlepages.com
> http://asapi.wetpaint.com
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Ashton
> Shortridge
> Sent: 11 December 2008 14:11
> To: r-sig-geo at stat.math.ethz.ch
> Cc: Corrado
> Subject: Re: [R-sig-Geo] Principal Component Analysis -
> Selectingcomponents? + right choice?
>
> Hi Corrado,
>
> > I run the PCA using prcomp, quite successfully. Now I need to use a
> > criteria to select the right number of PC. (that is: is it 1,2,3,4?)
> >
> > What criteria would you suggest?
>
> that's an interesting and probably controversy-generating question.
It's
>
> probably not an R-sig-geo question, either. I am not a PCA person, but
> the
> rule of thumb I am aware of is to plot the variability each
> component 'explains' and look for a clear breakpoint. I would think
> about any
> multivariate analysis text would have a better explanation than I can
> give,
> though.
>
> As for something more rigorous, I think a lot of people are reluctant
to
> use
> PCA as a modeling approach not so much because it's hard to choose a
> threshold for selecting components, but because the interpretation of
> the
> meaning of each component is pretty subjective. If you want an
> explanatory
> model, be careful about using PCA. You would be better served by
> deciding,
> based perhaps on expert knowledge about the variables, which ones to
use
> in
> the model and which ones not to.
>
> To try to make this a bit more spatial, and therefore more relevant to
> the
> list, I will also warn you that your various climate variables are
> almost
> certainly spatially autocorrelated - that is, neighboring and nearby
> observations in the grid are not independent. That has serious
> implications
> for standard multivariate analysis techniques and diagnostics.
>
> Yours,
>
> Ashton
>
> On Thursday 11 December 2008 06:46:37 am Corrado wrote:
> > Dear R gurus,
> >
> > I have some climatic data for a region of the world. They are
monthly
> > averages 1950 -2000 of precipitation (12 months), minimum
temperature
>
> (12
>
> > months), maximum temperature (12 months). I have scaled them to 2 km
x
>
> 2km
>
> > cells, and I have around 75,000 cells.
> >
> > I need to feed them into a statistical model as co-variates, to use
>
> them to
>
> > predict a response variable.
> >
> > The climatic data are obviously correlated: precipitation for
January
>
> is
>
> > correlated to precipitation for February and so on .... even
>
> precipitation
>
> > and temperature are heavily correlated. I did some correlation
>
> analysis and
>
> > they are all strongly correlated.
> >
> > I though of running PCA on them, in order to reduce the number of
> > co-variates I feed into the model.
> >
> > I run the PCA using prcomp, quite successfully. Now I need to use a
> > criteria to select the right number of PC. (that is: is it 1,2,3,4?)
> >
> > What criteria would you suggest?
> >
> > At the moment, I am using a criteria based on threshold, but that is
>
> highly
>
> > subjective, even if there are some rules of thumb
(Jolliffe,Principal
> > Component Analysis, II Edition, Springer Verlag,2002).
> >
> > Could you suggest something more rigorous?
> >
> > By the way, do you think I would have been better off by using
>
> something
>
> > different from PCA?
> >
> > Best,



-- 
Corrado Topi

Global Climate Change & Biodiversity Indicators
Area 18,Department of Biology
University of York, York, YO10 5YW, UK
Phone: + 44 (0) 1904 328645, E-mail: ct529 at york.ac.uk


This message has been scanned for viruses by MailControl -
www.mailcontrol.com

Click
https://www.mailcontrol.com/sr/wQw0zmjPoHdJTZGyOCrrhg==
vm6C4VtfQHmif9hp5cCl61pOCDRy5!TUZWDEGNPdlyNkQ==  to report this email as
spam.


The Zoological Society of London is incorporated by Royal Charter
Principal Office England. Company Number RC000749
Registered address: 
Regent's Park, London, England NW1 4RY
Registered Charity in England and Wales no. 208728 

_________________________________________________________________________
This e-mail has been sent in confidence to the named addressee(s).
If you are not the intended recipient, you must not disclose or distribute
it in any form, and you are asked to contact the sender immediately.
Views or opinions expressed in this communication may not be those
of The Zoological Society of London and, therefore, The Zoological
Society of London does not accept legal responsibility for the contents
of this message. The recipient(s) must be aware that e-mail is not a
secure communication medium and that the contents of this mail may
have been altered by a third party in transit.
If you have any issues regarding this mail please contact:
administrator at zsl.org.



From zev at zevross.com  Thu Dec 11 17:16:13 2008
From: zev at zevross.com (Zev Ross)
Date: Thu, 11 Dec 2008 11:16:13 -0500
Subject: [R-sig-Geo] GSTAT - singular in meters not km
In-Reply-To: <49412287.7020600@uni-muenster.de>
References: <493EC1C1.7050902@zevross.com> <493F6A64.6040101@uni-muenster.de>
	<4940129D.9050401@zevross.com> <49412287.7020600@uni-muenster.de>
Message-ID: <49413CCD.5050103@zevross.com>

Edzer,

Glad to hear that I wasn't crazy -- thanks so much for looking into this 
(and so quickly). For now I'll divide by 1000 and use KM which is an 
easy and reasonable solution. Zev

Edzer Pebesma wrote:
> Zev, if you do a
>
> v.fit<-fit.variogram(v, vgm(0.0005, "Sph", 40000, 
> 0.00001),debug.level=32)
>
> you'll see that the X matrix of the Gauss-Newton iteration with the 
> derivatives of the parameters to the error sum of squares is nearly 
> singular. The condition number of this matrix is so large that it 
> makes the problem ill-conditioned. If you add argument 
> fit.ranges=FALSE it will not be singular anymore.
>
> In the end, this problem is similar to e.g. regression of polynomials 
> on coordinates without standardizing the coordinates.
>
> I'll add a warning message to fit.variogram to suggest the two 
> solutions, for this case.
> -- 
> Edzer
>
> Zev Ross wrote:
>> Edzer (and all),
>>
>> I don't think that it's related to an unrealistic range. I've tried a 
>> lot of different realistic and non-realistic values and get singular 
>> results each time. If I divide the X and Y coordinates by 10, 100, 
>> 1000 or 10000 I don't get singularity. Using Lat and Long works fine. 
>> Code is below and I included a link to a workspace with the "pol" 
>> data set at the bottom.
>>
>> Zev
>>
>> polA<-pol
>> coordinates(polA)<-~x+y
>> v<-variogram(pollutant~1, data=polA)
>> v.fit<-fit.variogram(v, vgm(0.0005, "Sph", 40000, 0.00001))
>> attributes(v.fit)$singular # TRUE
>>
>> polB<-pol
>> polB$x<-polB$x/1000
>> polB$y<-polB$y/1000
>> coordinates(polB)<-~x+y
>> v<-variogram(pollutant~1, data=polB)
>> v.fit<-fit.variogram(v, vgm(0.0005, "Sph", 40, 0.00001))
>> attributes(v.fit)$singular #FALSE
>>
>> polC<-pol
>> coordinates(polC)<-~longitude+latitude
>> v<-variogram(pollutant~1, data=polC)
>> v.fit<-fit.variogram(v, vgm(0.0005, "Sph", .4, 0.00001))
>> attributes(v.fit)$singular # FALSE
>>
>> http://www.zevross.com/temp2/singular_or_not.RData
>>
>> Edzer Pebesma wrote:
>>> Hi Zev, it is hard to see what happens without seeing your data or R 
>>> commands.
>>>
>>> Is it possible that you passed an unrealistic value for the range 
>>> parameter, as starting value for the variogram model argument of 
>>> fit.variogram?
>>> -- 
>>> Edzer
>>>
>>> Zev Ross wrote:
>>>> Hi All,
>>>>
>>>> I'm fitting variograms in GSTAT with fit.variogram and I was 
>>>> surprised to find that all my fits were singular. I experimented 
>>>> with converting the data to unprojected data (decimal degrees) and 
>>>> with dividing my X and Y coordinates, which are in meters, by 1000 
>>>> (to get KM). In both cases the fitting procedure worked with no 
>>>> singularity. Based on the numbers of pairs the bins appeared to be 
>>>> about the same so it appears to be a matter of the coordinates 
>>>> themselves.
>>>>
>>>> I'd prefer not to have to convert the coordinates back and forth 
>>>> between meters and KM, any suggestions?
>>>>
>>>> Zev
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>



From edzer.pebesma at uni-muenster.de  Thu Dec 11 18:23:23 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 11 Dec 2008 18:23:23 +0100
Subject: [R-sig-Geo] Subsetting a spatial grid
In-Reply-To: <200592B6411E4891A2A6AE8ABDCB01FB@btodomain.bto.org>
References: <493FED05.4000507@scimail.uwaterloo.ca>
	<200592B6411E4891A2A6AE8ABDCB01FB@btodomain.bto.org>
Message-ID: <49414C8B.4050406@uni-muenster.de>

For SpatialGridDataFrames, row and col selection can be done by

object[firstrow:lastrow, firstcol:lastcol,]

after the last , you can optionally select attributes.
--
Edzer

Rob Robinson wrote:
> Help - please! :-)
>  I have what I thought was a really simple problem. I have a raster image of
> satellite data from which I would like to extract an arbitrary (but simple
> rectangular) portion for subsequent analysis (which I'll need to do for many
> images). I have the data as a (projected) SpatialGridDataFrame and have
> tried two approaches: create a SpatialPolygon and overlay it (but I don't
> think overlay does what I would like it to do), or access the coords slot of
> the data set and pick those within the range. I haven't been able to get
> either to work - presumably because my R is not good enough! It seems a
> fairly common task, but I haven't yet stumbled across an FAQ or page in
> ASDAR which seems to help. Any pointers anyone?
> Many thanks for any help
> Cheers
> rob
>
> *** Want to know about Britain's birds? Try  www.bto.org/birdfacts ***
>
> Dr Rob Robinson, Senior Population Biologist
> British Trust for Ornithology, The Nunnery, Thetford, Norfolk, IP24 2PU
> Ph: +44 (0)1842 750050        E: rob.robinson at bto.org
> Fx: +44 (0)1842 750030        W: www.bto.org/cv/rob_robinson.htm
>
> ==== "How can anyone be enlightened, when truth is so poorly lit" =====
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de



From Paul.Satterthwaite at oregonstate.edu  Thu Dec 11 22:10:54 2008
From: Paul.Satterthwaite at oregonstate.edu (Satterthwaite, Paul)
Date: Thu, 11 Dec 2008 13:10:54 -0800
Subject: [R-sig-Geo] periodic variograms
Message-ID: <D7B94F0B40246740A3EFF9DBBD921B7BB89880@SAGE.forestry.oregonstate.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081211/b3f73ffd/attachment.pl>

From paulojus at c3sl.ufpr.br  Fri Dec 12 00:16:41 2008
From: paulojus at c3sl.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Thu, 11 Dec 2008 21:16:41 -0200 (BRST)
Subject: [R-sig-Geo] periodic variograms
In-Reply-To: <D7B94F0B40246740A3EFF9DBBD921B7BB89880@SAGE.forestry.oregonstate.edu>
References: <D7B94F0B40246740A3EFF9DBBD921B7BB89880@SAGE.forestry.oregonstate.edu>
Message-ID: <Pine.LNX.4.58.0812112115470.9169@talisker.c3sl.ufpr.br>

You could try with the wave model:
> require(geoR)
> plot(c(0,100), c(0,1.5), type="n")
> lines.variomodel(1:100,"wave", cov.pars=c(1, 5), nug=0.2)

which is algo implemented by other packages




Paulo Justiniano Ribeiro Jr
LEG (Laboratorio de Estatistica e Geoinformacao)
Universidade Federal do Parana
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 3361 3573
Fax: (+55) 41 3361 3141
e-mail: paulojus AT  ufpr  br
http://www.leg.ufpr.br/~paulojus



On Thu, 11 Dec 2008, Satterthwaite, Paul wrote:

> Hello,
>
>
>
> I am a beginner with R, and have 2 questions concerning
> spatial/geostatistics. I doing a little exercise investigating
> periodicity in artificial patch landscapes and resulting periodicity of
> semivariograms.
>
>
>
> Does anyone know if there is an already-existing model semivariogram
> that contains a "hole effect" that can dampen with increasing lag, i.e.,
> includes some periodicity in the model semivariogram fit to the
> empirical data?
>
>
>
> Any ideas would be GREATLY appreciated!
>
> Cheers!
>
>
>
> Sincerely,
>
>
>
> Paul M. Satterthwaite
>
>
>
>
>
> Paul M. Satterthwaite
>
> MS Student, Forest Science
>
> Richardson 201A
>
> Oregon State University
>
> Corvallis, OR 97331
>
> paul.satterthwaite at oregonstate.edu
> <mailto:paul.satterthwaite at oregonstate.edu>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From giohappy at gmail.com  Fri Dec 12 01:13:15 2008
From: giohappy at gmail.com (G. Allegri)
Date: Fri, 12 Dec 2008 01:13:15 +0100
Subject: [R-sig-Geo] Principal Component Analysis - Selectingcomponents?
	+ right choice?
In-Reply-To: <41E1ED29E5E8E34BBDD8B82CFA1A9D0406380A30@zsl26>
References: <200812111146.38088.ct529@york.ac.uk>
	<200812110910.38588.ashton@msu.edu>
	<41E1ED29E5E8E34BBDD8B82CFA1A9D040638098F@zsl26>
	<200812111444.13540.ct529@york.ac.uk>
	<41E1ED29E5E8E34BBDD8B82CFA1A9D0406380A30@zsl26>
Message-ID: <e12429640812111613x1f89db7nc282758ae487db51@mail.gmail.com>

I just share a link to a paper I've recently read, about the thread
object: http://dx.doi.org/10.1016/j.csda.2004.06.015

giovanni

2008/12/11 Kamran Safi <Kamran.Safi at ioz.ac.uk>:
> Hi Corrado,
>
> A useful reference is: Diniz-Filho J.A.F. & Bini L.M. (2005). Modelling
> geographical patterns in species richness using eigenvector-based
> spatial filters. Global Ecology and Biogeography, 14, 177-185.
>
> So what they do basically is using multidimensional scaling to derive
> from the pairwise distance matrix a set of principal coordinates (not be
> confused with principal components). MDS is a method (old!) that
> converts a pairwise distance matrix into n-1 dimensional vertical
> matrix. It is implemented in R base. Have a look at cmdscale() and
> isoMDS(). There I would use all those PCo which significantly predict
> your dependent variable(s) (But see below).
>
> Another very useful and classic resource is this paper:
> http://www.ufz.de/data/Dormann-et-al_Methods-Autocorrelation6834.pdf
> Specifically its appendix. Spatial filtering is described there too.
>
> Hope this helps. Good luck.
>
> Kamran
>
>
>
>
> ------------------------
> Kamran Safi
>
> Postdoctoral Research Fellow
> Institute of Zoology
> Zoological Society of London
> Regent's Park
> London NW1 4RY
>
> http://www.zoo.cam.ac.uk/ioz/people/safi.htm
>
> http://spatialr.googlepages.com
> http://asapi.wetpaint.com
>
>
> -----Original Message-----
> From: Corrado [mailto:ct529 at york.ac.uk]
> Sent: 11 December 2008 14:44
> To: Kamran Safi
> Cc: Ashton Shortridge; r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] Principal Component Analysis -
> Selectingcomponents? + right choice?
>
> Hi all,
>
> I used a rule of thumb as reported by the book quoted, but I am not
> completely
> happy with it, because it is not really a statistical justification.
>
> I will try the broken stick approach, thanks!
>
> Concerning the interpretation, luckily enough PC1 has a clear
> interpretation.
> PC2 a bit less so, though .... and the complexity of interpretation
> increases
> with explained variance decreasing.
>
> I am using the approach suggested by Kamran: I have brewed down the
> original
> climatic variables to uncorrelated "environmental variables", and I have
>
> chosen the signification ones using a threshold. I do realise spatial
> auto-correlation is going to be important (even if my sites are fairly
> distant from one another, reducing the impact), but  do not know
> anything
> about spatial filtering. Whilst I have used distance matrices, I have
> never
> used them to remove spatial auto-correlation!
>
> Could you please point me out to some resources please?
>
> Best,
>
>
>
>
> On Thursday 11 December 2008 14:29:27 Kamran Safi wrote:
>> Hi all,
>>
>> I agree with Ashton. The issue is very complex and far from resolved.
>> But sometimes we have to go down the PCA path. Among the many possible
>> solutions is the broken stick approach, for which you find an R
> solution
>> (bstick()) in the package vegan. Technically the broken stick randomly
>> divides 100% variance into your N principal components and generates a
>> null expectation for the distributions of randomly partioning the
>> original variance. You then take all those PCAs that are above the
>> broken stick distribution. This is by no means an agreed upon
> approach,
>> but it is at least reproducible and has some theory behind it, but is
>> and will remain a rule of thumb.
>> In terms of spatial analysis you could derive the PCAs and then go
> into
>> classic spatial analysis. Although the interpretation of PCA is
>> sometimes complicated or even impossible, you can calculate the values
>> for every grid cell and then go into multivariate analysis whereby you
>> have to take spatial autocorrelation into account. At least your PCA
>> components are orthogonal, which simplifies your analysis in contrast
> to
>> using the original variables. It also allows you to produce predictive
>> models.
>> What you could think of doing could be using PCA to derive
>> "environmental" variables which are uncorrelated and the use the
>> distance matrix and spatial filtering to "remove" spatial
>> autocorrelation.
>>
>> Hope this helps,
>>
>> Kami
>>
>>
>>
>> ------------------------
>> Kamran Safi
>>
>> Postdoctoral Research Fellow
>> Institute of Zoology
>> Zoological Society of London
>> Regent's Park
>> London NW1 4RY
>>
>> http://www.zoo.cam.ac.uk/ioz/people/safi.htm
>>
>> http://spatialr.googlepages.com
>> http://asapi.wetpaint.com
>>
>> -----Original Message-----
>> From: r-sig-geo-bounces at stat.math.ethz.ch
>> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Ashton
>> Shortridge
>> Sent: 11 December 2008 14:11
>> To: r-sig-geo at stat.math.ethz.ch
>> Cc: Corrado
>> Subject: Re: [R-sig-Geo] Principal Component Analysis -
>> Selectingcomponents? + right choice?
>>
>> Hi Corrado,
>>
>> > I run the PCA using prcomp, quite successfully. Now I need to use a
>> > criteria to select the right number of PC. (that is: is it 1,2,3,4?)
>> >
>> > What criteria would you suggest?
>>
>> that's an interesting and probably controversy-generating question.
> It's
>>
>> probably not an R-sig-geo question, either. I am not a PCA person, but
>> the
>> rule of thumb I am aware of is to plot the variability each
>> component 'explains' and look for a clear breakpoint. I would think
>> about any
>> multivariate analysis text would have a better explanation than I can
>> give,
>> though.
>>
>> As for something more rigorous, I think a lot of people are reluctant
> to
>> use
>> PCA as a modeling approach not so much because it's hard to choose a
>> threshold for selecting components, but because the interpretation of
>> the
>> meaning of each component is pretty subjective. If you want an
>> explanatory
>> model, be careful about using PCA. You would be better served by
>> deciding,
>> based perhaps on expert knowledge about the variables, which ones to
> use
>> in
>> the model and which ones not to.
>>
>> To try to make this a bit more spatial, and therefore more relevant to
>> the
>> list, I will also warn you that your various climate variables are
>> almost
>> certainly spatially autocorrelated - that is, neighboring and nearby
>> observations in the grid are not independent. That has serious
>> implications
>> for standard multivariate analysis techniques and diagnostics.
>>
>> Yours,
>>
>> Ashton
>>
>> On Thursday 11 December 2008 06:46:37 am Corrado wrote:
>> > Dear R gurus,
>> >
>> > I have some climatic data for a region of the world. They are
> monthly
>> > averages 1950 -2000 of precipitation (12 months), minimum
> temperature
>>
>> (12
>>
>> > months), maximum temperature (12 months). I have scaled them to 2 km
> x
>>
>> 2km
>>
>> > cells, and I have around 75,000 cells.
>> >
>> > I need to feed them into a statistical model as co-variates, to use
>>
>> them to
>>
>> > predict a response variable.
>> >
>> > The climatic data are obviously correlated: precipitation for
> January
>>
>> is
>>
>> > correlated to precipitation for February and so on .... even
>>
>> precipitation
>>
>> > and temperature are heavily correlated. I did some correlation
>>
>> analysis and
>>
>> > they are all strongly correlated.
>> >
>> > I though of running PCA on them, in order to reduce the number of
>> > co-variates I feed into the model.
>> >
>> > I run the PCA using prcomp, quite successfully. Now I need to use a
>> > criteria to select the right number of PC. (that is: is it 1,2,3,4?)
>> >
>> > What criteria would you suggest?
>> >
>> > At the moment, I am using a criteria based on threshold, but that is
>>
>> highly
>>
>> > subjective, even if there are some rules of thumb
> (Jolliffe,Principal
>> > Component Analysis, II Edition, Springer Verlag,2002).
>> >
>> > Could you suggest something more rigorous?
>> >
>> > By the way, do you think I would have been better off by using
>>
>> something
>>
>> > different from PCA?
>> >
>> > Best,
>
>
>
> --
> Corrado Topi
>
> Global Climate Change & Biodiversity Indicators
> Area 18,Department of Biology
> University of York, York, YO10 5YW, UK
> Phone: + 44 (0) 1904 328645, E-mail: ct529 at york.ac.uk
>
>
> This message has been scanned for viruses by MailControl -
> www.mailcontrol.com
>
> Click
> https://www.mailcontrol.com/sr/wQw0zmjPoHdJTZGyOCrrhg==
> vm6C4VtfQHmif9hp5cCl61pOCDRy5!TUZWDEGNPdlyNkQ==  to report this email as
> spam.
>
>
> The Zoological Society of London is incorporated by Royal Charter
> Principal Office England. Company Number RC000749
> Registered address:
> Regent's Park, London, England NW1 4RY
> Registered Charity in England and Wales no. 208728
>
> _________________________________________________________________________
> This e-mail has been sent in confidence to the named addressee(s).
> If you are not the intended recipient, you must not disclose or distribute
> it in any form, and you are asked to contact the sender immediately.
> Views or opinions expressed in this communication may not be those
> of The Zoological Society of London and, therefore, The Zoological
> Society of London does not accept legal responsibility for the contents
> of this message. The recipient(s) must be aware that e-mail is not a
> secure communication medium and that the contents of this mail may
> have been altered by a third party in transit.
> If you have any issues regarding this mail please contact:
> administrator at zsl.org.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From dray at biomserv.univ-lyon1.fr  Fri Dec 12 09:19:21 2008
From: dray at biomserv.univ-lyon1.fr (=?ISO-8859-1?Q?St=E9phane_Dray?=)
Date: Fri, 12 Dec 2008 09:19:21 +0100
Subject: [R-sig-Geo] Principal Component Analysis -
 Selecting	components? + right choice?
In-Reply-To: <49412788.9020803@uni-muenster.de>
References: <200812111146.38088.ct529@york.ac.uk>	<200812110910.38588.ashton@msu.edu>
	<49412788.9020803@uni-muenster.de>
Message-ID: <49421E89.6080300@biomserv.univ-lyon1.fr>

multispati function in ade4 implements a method wich is very similar to 
SFA of Switzer et al. It find linear combination of the variables that 
maximize the product variance by autocorrelation when PCA maximize only 
the first part and SFA only the second one. Relations between SFA and 
multispati are described in the paper:

*S. Dray*, S. Sa?d, and F. D?bias. Spatial ordination of vegetation data 
using a generalization of Wartenberg's multivariate spatial correlation. 
/Journal of Vegetation Science/, 19:45-56, 2008.

Edzer Pebesma wrote:
> Principle components don't search for directions that best explain 
> your dependent variable, but rather try to capture variability and/or 
> correlation in the predictors. Methods that look for subspaces that 
> best predict the dependent are for instance are partial least squares 
> and ridge regression. Using them, you could with the same amount of 
> degrees of freedom look at completely different directions.
>
> In addition to Ashton's remark: a variety of principle components that 
> tries to pick up spatial correlated patterns in addition to maximum 
> variability/correlation between variables is MNF (minimum nois 
> fraction) factors, also called min/max autocorrelation factors; see 
> the papers by Green, Switzer and others. I'm not aware of 
> implementations of them in R, but would be interested to hear.
>
> Best regards,
> -- 
> Edzer
>
> Ashton Shortridge wrote:
>> Hi Corrado,
>>
>>  
>>> I run the PCA using prcomp, quite successfully. Now I need to use a
>>> criteria to select the right number of PC. (that is: is it 1,2,3,4?)
>>>
>>> What criteria would you suggest?
>>>     
>>
>> that's an interesting and probably controversy-generating question. 
>> It's probably not an R-sig-geo question, either. I am not a PCA 
>> person, but the rule of thumb I am aware of is to plot the 
>> variability each component 'explains' and look for a clear 
>> breakpoint. I would think about any multivariate analysis text would 
>> have a better explanation than I can give, though.
>>
>> As for something more rigorous, I think a lot of people are reluctant 
>> to use PCA as a modeling approach not so much because it's hard to 
>> choose a threshold for selecting components, but because the 
>> interpretation of the meaning of each component is pretty subjective. 
>> If you want an explanatory model, be careful about using PCA. You 
>> would be better served by deciding, based perhaps on expert knowledge 
>> about the variables, which ones to use in the model and which ones 
>> not to.
>>
>> To try to make this a bit more spatial, and therefore more relevant 
>> to the list, I will also warn you that your various climate variables 
>> are almost certainly spatially autocorrelated - that is, neighboring 
>> and nearby observations in the grid are not independent. That has 
>> serious implications for standard multivariate analysis techniques 
>> and diagnostics.
>>
>> Yours,
>>
>> Ashton
>>
>> On Thursday 11 December 2008 06:46:37 am Corrado wrote:
>>  
>>> Dear R gurus,
>>>
>>> I have some climatic data for a region of the world. They are monthly
>>> averages 1950 -2000 of precipitation (12 months), minimum 
>>> temperature (12
>>> months), maximum temperature (12 months). I have scaled them to 2 km 
>>> x 2km
>>> cells, and I have around 75,000 cells.
>>>
>>> I need to feed them into a statistical model as co-variates, to use 
>>> them to
>>> predict a response variable.
>>>
>>> The climatic data are obviously correlated: precipitation for 
>>> January is
>>> correlated to precipitation for February and so on .... even 
>>> precipitation
>>> and temperature are heavily correlated. I did some correlation 
>>> analysis and
>>> they are all strongly correlated.
>>>
>>> I though of running PCA on them, in order to reduce the number of
>>> co-variates I feed into the model.
>>>
>>> I run the PCA using prcomp, quite successfully. Now I need to use a
>>> criteria to select the right number of PC. (that is: is it 1,2,3,4?)
>>>
>>> What criteria would you suggest?
>>>
>>> At the moment, I am using a criteria based on threshold, but that is 
>>> highly
>>> subjective, even if there are some rules of thumb (Jolliffe,Principal
>>> Component Analysis, II Edition, Springer Verlag,2002).
>>>
>>> Could you suggest something more rigorous?
>>>
>>> By the way, do you think I would have been better off by using 
>>> something
>>> different from PCA?
>>>
>>> Best,
>>>     
>>
>>
>>
>>   
>

-- 
St?phane DRAY (dray at biomserv.univ-lyon1.fr )
Laboratoire BBE-CNRS-UMR-5558, Univ. C. Bernard - Lyon I
43, Bd du 11 Novembre 1918, 69622 Villeurbanne Cedex, France
Tel: 33 4 72 43 27 57       Fax: 33 4 72 43 13 88
http://biomserv.univ-lyon1.fr/~dray/



From martin.tomko at geo.uzh.ch  Fri Dec 12 12:38:13 2008
From: martin.tomko at geo.uzh.ch (Martin Tomko)
Date: Fri, 12 Dec 2008 12:38:13 +0100
Subject: [R-sig-Geo] viewshed analysis in R
Message-ID: <49424D25.3060501@geo.uzh.ch>

Dear all,
is there a package that would be able to perform a viewshed analysis on 
a DME (raster or TIN)?
Thanks
Martin



From b.rowlingson at lancaster.ac.uk  Fri Dec 12 12:58:04 2008
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 12 Dec 2008 11:58:04 +0000
Subject: [R-sig-Geo] viewshed analysis in R
In-Reply-To: <49424D25.3060501@geo.uzh.ch>
References: <49424D25.3060501@geo.uzh.ch>
Message-ID: <d8ad40b50812120358v5f6664faye1d3b12eb03e4bd8@mail.gmail.com>

2008/12/12 Martin Tomko <martin.tomko at geo.uzh.ch>:
> Dear all,
> is there a package that would be able to perform a viewshed analysis on a
> DME (raster or TIN)?

I'd use GRASS's line-of-sight routines:

http://grass.itc.it/grass5/manuals/html53_user/html/r.los.html

There is an R-Grass interface:

http://grass.itc.it/statsgrass/grass_r_interface.html#Using_GRASS_R

Barry



From zack_holden at hotmail.com  Fri Dec 12 16:36:13 2008
From: zack_holden at hotmail.com (zack holden)
Date: Fri, 12 Dec 2008 15:36:13 +0000
Subject: [R-sig-Geo] Principal Component Analysis - Selecting
 components? +right choice?
In-Reply-To: <mailman.15.1229079604.7199.r-sig-geo@stat.math.ethz.ch>
References: <mailman.15.1229079604.7199.r-sig-geo@stat.math.ethz.ch>
Message-ID: <BAY125-W351BD0DABAD219107B5F5587F90@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081212/2fab8dd3/attachment.pl>

From hzambran.newsgroups at gmail.com  Fri Dec 12 16:37:06 2008
From: hzambran.newsgroups at gmail.com (Mauricio Zambrano)
Date: Fri, 12 Dec 2008 16:37:06 +0100
Subject: [R-sig-Geo] 'krige' messages in loops
Message-ID: <63d616b0812120737i12cb3fb3i7f7bbf7b2c4e4994@mail.gmail.com>

Dear list,

I'm using the 'krige' function of the 'gstat' package for computing
inverse distance interpolated values within a loop.

So far everything works well, but I would like to know if there is any
way of suppressing the message "[inverse distance weighted
interpolation]" (very useful for single analysis) that appears at the
begining of every analysis ?. I'm asking this because this message
makes difficult to read in which part of the loop is being executed.

Thanks in advance,

Mauricio
-- 
Linux user  #454569 -- Ubuntu user #17469



From edzer.pebesma at uni-muenster.de  Fri Dec 12 17:54:36 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 12 Dec 2008 17:54:36 +0100
Subject: [R-sig-Geo] 'krige' messages in loops
In-Reply-To: <63d616b0812120737i12cb3fb3i7f7bbf7b2c4e4994@mail.gmail.com>
References: <63d616b0812120737i12cb3fb3i7f7bbf7b2c4e4994@mail.gmail.com>
Message-ID: <4942974C.3070301@uni-muenster.de>

Mauricio, please try something along the lines of

x = krige(log(zinc)~1, meuse, meuse.grid, set = list(debug = 0))

Mauricio Zambrano wrote:
> Dear list,
>
> I'm using the 'krige' function of the 'gstat' package for computing
> inverse distance interpolated values within a loop.
>
> So far everything works well, but I would like to know if there is any
> way of suppressing the message "[inverse distance weighted
> interpolation]" (very useful for single analysis) that appears at the
> begining of every analysis ?. I'm asking this because this message
> makes difficult to read in which part of the loop is being executed.
>
> Thanks in advance,
>
> Mauricio
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de



From jnylen+rgeo at gmail.com  Fri Dec 12 18:08:21 2008
From: jnylen+rgeo at gmail.com (James Nylen)
Date: Fri, 12 Dec 2008 11:08:21 -0600
Subject: [R-sig-Geo] 'krige' messages in loops
In-Reply-To: <4942974C.3070301@uni-muenster.de>
References: <63d616b0812120737i12cb3fb3i7f7bbf7b2c4e4994@mail.gmail.com>
	<4942974C.3070301@uni-muenster.de>
Message-ID: <205a4c310812120908j251138a3l5ef57da6851a7dcc@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081212/4dd15db7/attachment.pl>

From hzambran.newsgroups at gmail.com  Fri Dec 12 18:19:37 2008
From: hzambran.newsgroups at gmail.com (Mauricio Zambrano)
Date: Fri, 12 Dec 2008 18:19:37 +0100
Subject: [R-sig-Geo] 'krige' messages in loops
In-Reply-To: <205a4c310812120908j251138a3l5ef57da6851a7dcc@mail.gmail.com>
References: <63d616b0812120737i12cb3fb3i7f7bbf7b2c4e4994@mail.gmail.com>
	<4942974C.3070301@uni-muenster.de>
	<205a4c310812120908j251138a3l5ef57da6851a7dcc@mail.gmail.com>
Message-ID: <63d616b0812120919i6fcaac63kcf1e857421279a0e@mail.gmail.com>

Thanks a lot Edzer and James,

Adding 'set = list(debug = 0)' works perfectly. In my case:

'pp.idw <- krige(value~1, locations= loc, newdata= pp.gis.catch, set =
list(debug = 0) )'


Also thanks for the indication about the 'debug.level' parameter of
'krige' function, because I didn't associate the explanation:

'debug.level: debug level, passed to predict.gstat; use -1  to see
progress in percentage'

with presenting the method that is being used for interpolating the values.

Best regards,

Mauricio

2008/12/12 James Nylen <jnylen+rgeo at gmail.com>:
> Adding either of these two arguments to the function call works for me:
>
> set=list(debug=0)
> debug.level=0
>
> The second one was mentioned in ?krige and is probably a little easier to
> remember.
>
> -James
>
>
>
> On Fri, Dec 12, 2008 at 10:54 AM, Edzer Pebesma
> <edzer.pebesma at uni-muenster.de> wrote:
>>
>> Mauricio, please try something along the lines of
>>
>> x = krige(log(zinc)~1, meuse, meuse.grid, set = list(debug = 0))
>>
>> Mauricio Zambrano wrote:
>>>
>>> Dear list,
>>>
>>> I'm using the 'krige' function of the 'gstat' package for computing
>>> inverse distance interpolated values within a loop.
>>>
>>> So far everything works well, but I would like to know if there is any
>>> way of suppressing the message "[inverse distance weighted
>>> interpolation]" (very useful for single analysis) that appears at the
>>> begining of every analysis ?. I'm asking this because this message
>>> makes difficult to read in which part of the loop is being executed.
>>>
>>> Thanks in advance,
>>>
>>> Mauricio
>>>
>>
>> --
>> Edzer Pebesma
>> Institute for Geoinformatics (ifgi), University of M?nster
>> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
>> 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
>> http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>



-- 
hzambran

Linux user  #454569 -- Ubuntu user #17469



From Scott.Waichler at pnl.gov  Fri Dec 12 19:00:49 2008
From: Scott.Waichler at pnl.gov (Waichler, Scott R)
Date: Fri, 12 Dec 2008 10:00:49 -0800
Subject: [R-sig-Geo] 3D grids of discrete values and corresponding polygons
Message-ID: <12A8FC4D0563D1468AD23AAAED861A3E0BB68C@EMAIL02.pnl.gov>

Hello,

I am working with a 3D grid of a small number of discrete values, where
the grid is Cartesian (cell borders are orthogonal) but has irregular
cell width/length/height.  I would like to make plots of 2D cross
sections through the grid.  I want to show the exact outlines of
contiguous groups of like-valued cells.  A couple of years ago Roger
Bivand pointed out how to do this in 2D, using Polygon(),
unionSpatialPolygons(), and other functions.  Is there a way to do this
with a cross section taken through the 3D grid in one of the principal
directions?  I don't see mention or examples of 3D polygons.  Or do I
need to derive the polygons and union them separately for each cross
section?

Also, is there an easy way to search the R-sig-geo archives?

Thanks,
Scott Waichler
Pacific Northwest National Laboratory
scott.waichler at pnl.gov



From Virgilio.Gomez at uclm.es  Sat Dec 13 16:36:25 2008
From: Virgilio.Gomez at uclm.es (Virgilio Gomez Rubio)
Date: Sat, 13 Dec 2008 15:36:25 +0000
Subject: [R-sig-Geo] [Fwd: ANNOUNCE: 2009 John M. Chambers Statistical
	Software Award]
Message-ID: <1229182585.8960.1.camel@Virgilio-Gomez>

Dear all,

I think that this contest may be of interest to some of you.

Best wishes,

Virgilio

--------- Mensaje reenviado --------
De: J.R. Lockwood <lockwood at RAND.ORG>
Reply-to: "J.R. Lockwood" <lockwood at RAND.ORG>
Para: allstat at JISCMAIL.AC.UK
Asunto: ANNOUNCE: 2009 John M. Chambers Statistical Software Award
Fecha: Fri, 12 Dec 2008 15:44:09 -0500

John M. Chambers Statistical Software Award - 2009
Statistical Computing Section
American Statistical Association

The Statistical Computing Section of the American Statistical
Association announces the competition for the John M.  Chambers
Statistical Software Award. In 1998 the Association for Computing
Machinery presented its Software System Award to John Chambers for the
design and development of S. Dr. Chambers generously donated his award
to the Statistical Computing Section to endow an annual prize for
statistical software written by an undergraduate or graduate student.
The prize carries with it a cash award of $1000, plus a substantial
allowance for travel to the annual Joint Statistical Meetings where
the award will be presented.

Teams of up to 3 people can participate in the competition, with the
cash award being split among team members. The travel allowance will
be given to just one individual in the team, who will be presented the
award at JSM.  To be eligible, the team must have designed and
implemented a piece of statistical software.  The individual within
the team indicated to receive the travel allowance must have begun the
development while a student, and must either currently be a student,
or have completed all requirements for her/his last degree after
January 1, 2007.  To apply for the award, teams must provide the
following materials:

   Current CV's of all team members.

   A letter from a faculty mentor at the academic institution of the
   individual indicated to receive the travel award.  The letter
   should confirm that the individual had substantial participation in
   the development of the software, certify her/his student status
   when the software began to be developed (and either the current
   student status or the date of degree completion), and briefly
   discuss the importance of the software to statistical practice.

   A brief, one to two page description of the software, summarizing
   what it does, how it does it, and why it is an important
   contribution.  If the team member competing for the travel
   allowance has continued developing the software after finishing
   her/his studies, the description should indicate what was developed
   when the individual was a student and what has been added since.

   Access to the software by the award committee for their use on
   inputs of their choosing.  Access to the software can consist of an
   executable file, Web-based access, macro code, or other appropriate
   form.  Access should be accompanied by enough information to allow
   the judges to effectively use and evaluate the software (including
   its design considerations.)  This information can be provided in a
   variety of ways, including but not limited to a user manual (paper
   or electronic), a paper, a URL, online help to the system, and
   source code.  In particular, the entrant must be prepared to
   provide complete source code for inspection by the committee if
   requested.

All materials must be in English.  We prefer that electronic text be
submitted in Postscript or PDF.  The entries will be judged on a
variety of dimensions, including the importance and relevance for
statistical practice of the tasks performed by the software, ease of
use, clarity of description, elegance and availability for use by the
statistical community. Preference will be given to those entries that
are grounded in software design rather than calculation.  The decision
of the award committee is final.

All application materials must be received by 5:00pm EST, Monday,
February 23, 2009 at the address below.  The winner will be announced
in May and the award will be given at the 2009 Joint Statistical
Meetings.

Information on the competition can also be accessed on the website of
the Statistical Computing Section (www.statcomputing.org or see the
ASA website, www.amstat.org for a pointer), including the names and
contributions of previous winners.  Inquiries and application
materials should be emailed or mailed to:

Chambers Software Award
c/o J.R. Lockwood
The RAND Corporation
4570 Fifth Avenue, Suite 600
Pittsburgh, PA 15213
lockwood at rand.org

__________________________________________________________________________

This email message is for the sole use of the intended r...{{dropped:6}}



From nmeuriss at ulb.ac.be  Sun Dec 14 10:24:37 2008
From: nmeuriss at ulb.ac.be (Nicolas Meurisse)
Date: Sun, 14 Dec 2008 10:24:37 +0100
Subject: [R-sig-Geo] kriging: export to grid
Message-ID: <4944D0D5.9020701@ulb.ac.be>

Hello,

After kriging with the use of the  krige.conv function, I would like to 
export my result under the grid format. In order to view it into a GIS.

It was suggested to me to use the writeGDAL function into the rgdal 
package. However It looks like I have a problem of supported formats
(dataset object of SpatialGridDataFrame-class or 
SpatialPixelsDataFrame-class ) that is not the same as the one resulting 
from my krige.conv function (kriging -class apparently)

I tried several function to achieve this conversion (getRasterData, 
SpatialGridDataFrame, SpatialPixelsDataFrame, create2GDAL, 
points2grid...). But without any success.

#my actual kriging script:
pred.grid = expand.grid(seq(170000, 130000, l = 50), seq(190000, 160000, 
l = 50))
myPred = krige.conv(myGData, loc = pred.grid, krige = 
krige.control(obj.m = myOLSMod))
image(myPred, loc = pred.grid, col = gray(seq(1, 0.1, l = 30)))

#my conversion attempts
tf <- tempfile()
writeGDAL(myPred, tf, drivername="GTiff", type="Byte", options=NULL)
[Erreur dans function (classes, fdef, mtable) : unable to find an 
inherited method for function "gridded", for signature "kriging"]

Thanks a lot,

Nicolas



From Roger.Bivand at nhh.no  Sun Dec 14 13:54:58 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 14 Dec 2008 13:54:58 +0100 (CET)
Subject: [R-sig-Geo] kriging: export to grid
In-Reply-To: <4944D0D5.9020701@ulb.ac.be>
References: <4944D0D5.9020701@ulb.ac.be>
Message-ID: <alpine.LRH.2.00.0812141342020.5311@reclus.nhh.no>

On Sun, 14 Dec 2008, Nicolas Meurisse wrote:

> Hello,
>
> After kriging with the use of the  krige.conv function, I would like to 
> export my result under the grid format. In order to view it into a GIS.
>
> It was suggested to me to use the writeGDAL function into the rgdal package. 
> However It looks like I have a problem of supported formats
> (dataset object of SpatialGridDataFrame-class or SpatialPixelsDataFrame-class 
> ) that is not the same as the one resulting from my krige.conv function 
> (kriging -class apparently)
>
> I tried several function to achieve this conversion (getRasterData, 
> SpatialGridDataFrame, SpatialPixelsDataFrame, create2GDAL, points2grid...). 
> But without any success.
>
> #my actual kriging script:
> pred.grid = expand.grid(seq(170000, 130000, l = 50), seq(190000, 160000, l = 
> 50))

library(sp)
pred.grid$var3 <- 1
coordinates(pred.grid) <- c("Var1", "Var2")
gridded(pred.grid) <- TRUE

# Create a SpatialPixelsDataFrame or SpatialGridDataFrame object first
# - forced here by including a non-coordnate column to the data frame

> myPred = krige.conv(myGData, loc = pred.grid, krige = krige.control(obj.m = 
> myOLSMod))

myPred = krige.conv(myGData, loc = coordinates(pred.grid),
  krige = krige.control(obj.m = myOLSMod))

# Krige with the coordinates of the object

pred.grid$predict <- myPred$predict

# add the predictions (and standard errors if you like) to the
# object, they are in the correct order;
# then write out, choosing the output column as desired

tf <- tempfile()
writeGDAL(pred.grid["predict"], tf, drivername="GTiff") # not type="Byte"!
GDALinfo(tf)

# I suppose you are using the temporary file here to test your approach
# as you ought to put the output file in a permanent place if you will
# need it later

Hope this helps,

Roger

> image(myPred, loc = pred.grid, col = gray(seq(1, 0.1, l = 30)))
>
> #my conversion attempts
> tf <- tempfile()
> writeGDAL(myPred, tf, drivername="GTiff", type="Byte", options=NULL)
> [Erreur dans function (classes, fdef, mtable) : unable to find an inherited 
> method for function "gridded", for signature "kriging"]
>
> Thanks a lot,
>
> Nicolas
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From adjemian at primal.ucdavis.edu  Sun Dec 14 19:23:01 2008
From: adjemian at primal.ucdavis.edu (adjemian)
Date: Sun, 14 Dec 2008 10:23:01 -0800
Subject: [R-sig-Geo] Trouble with Durbin Model
Message-ID: <49454f05.345.2da2.1574585962@primal.ucdavis.edu>

Hey everyone, 

I'm puzzled about a recent result, and I'm wondering if
anyone can help explain it.  Essentially, I have a set of
data that is positively spatially autocorrelated (Moran's I
is highly significant).  According to LM tests on the OLS
residuals, I find that the spatial lag model is preferred. 
After estimating the lag specification with a group of
covariates, the spatial parameter is positive and
significant at the 1% level.  This indicates that the
spatial clustering in the dependent variable is robust to
the potential confounding influence of the covariates.

However, when I estimate the spatial Durbin specification by
including a set of distanced covariates, the spatial
parameter is still significant, but with the *opposite*
sign.  Something that may be of interest: the errors of the
lag model are not spatially autocorrelated; while the errors
of the Durbin model are.

I wonder why the sign of spatial influence flips.  Has
anybody faced a similar situation?  How should I select the
proper model?

Software used: Geoda, R.

Thanks! 
Mike



From edzer.pebesma at uni-muenster.de  Sun Dec 14 20:50:32 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 14 Dec 2008 20:50:32 +0100
Subject: [R-sig-Geo] periodic variograms
In-Reply-To: <Pine.LNX.4.58.0812112115470.9169@talisker.c3sl.ufpr.br>
References: <D7B94F0B40246740A3EFF9DBBD921B7BB89880@SAGE.forestry.oregonstate.edu>
	<Pine.LNX.4.58.0812112115470.9169@talisker.c3sl.ufpr.br>
Message-ID: <49456388.2050203@uni-muenster.de>

Paulo Justiniano Ribeiro Jr wrote:
> You could try with the wave model:
>   
>> require(geoR)
>> plot(c(0,100), c(0,1.5), type="n")
>> lines.variomodel(1:100,"wave", cov.pars=c(1, 5), nug=0.2)
>>     
>
> which is also implemented by other packages
>   
yes, as in:

library(gstat)
data(meuse)
coordinates(meuse)= c("x", "y")
v = variogram(log(zinc)~1,meuse)
plot(v, fit.variogram(v, vgm(1, "Hol", 200, 1)))

(you may need to update your gstat package to get sane results for it)
--
Edzer

>
>
>
> Paulo Justiniano Ribeiro Jr
> LEG (Laboratorio de Estatistica e Geoinformacao)
> Universidade Federal do Parana
> Caixa Postal 19.081
> CEP 81.531-990
> Curitiba, PR  -  Brasil
> Tel: (+55) 41 3361 3573
> Fax: (+55) 41 3361 3141
> e-mail: paulojus AT  ufpr  br
> http://www.leg.ufpr.br/~paulojus
>
>
>
> On Thu, 11 Dec 2008, Satterthwaite, Paul wrote:
>
>   
>> Hello,
>>
>>
>>
>> I am a beginner with R, and have 2 questions concerning
>> spatial/geostatistics. I doing a little exercise investigating
>> periodicity in artificial patch landscapes and resulting periodicity of
>> semivariograms.
>>
>>
>>
>> Does anyone know if there is an already-existing model semivariogram
>> that contains a "hole effect" that can dampen with increasing lag, i.e.,
>> includes some periodicity in the model semivariogram fit to the
>> empirical data?
>>
>>
>>
>> Any ideas would be GREATLY appreciated!
>>
>> Cheers!
>>
>>
>>
>> Sincerely,
>>
>>
>>
>> Paul M. Satterthwaite
>>
>>
>>
>>
>>
>> Paul M. Satterthwaite
>>
>> MS Student, Forest Science
>>
>> Richardson 201A
>>
>> Oregon State University
>>
>> Corvallis, OR 97331
>>
>> paul.satterthwaite at oregonstate.edu
>> <mailto:paul.satterthwaite at oregonstate.edu>
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>     
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de



From ya-cine at hotmail.com  Sun Dec 14 21:51:11 2008
From: ya-cine at hotmail.com (yacine kouba)
Date: Sun, 14 Dec 2008 20:51:11 +0000
Subject: [R-sig-Geo] Hello
Message-ID: <BAY114-W2736EF0299D0EA57136EC6FBF70@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081214/2a328cb0/attachment.pl>

From marcelino.delacruz at upm.es  Mon Dec 15 09:59:16 2008
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Mon, 15 Dec 2008 09:59:16 +0100
Subject: [R-sig-Geo] Hello
In-Reply-To: <BAY114-W2736EF0299D0EA57136EC6FBF70@phx.gbl>
References: <BAY114-W2736EF0299D0EA57136EC6FBF70@phx.gbl>
Message-ID: <200812150859.mBF8xARS003884@edison.ccupm.upm.es>

I can tell:

First use plot to draw your favourite correlogram.

Then use points, lines or both functions to subsequently add the others.

Last but not least,  read one of the nice 
official or contributed manuals: http://cran.r-project.org/other-docs.html


And next time, please use a more informative subject !


Cheers,

Marcelino




At 21:51 14/12/2008, yacine kouba wrote:
>Content-Type: text/plain
>Content-Disposition: inline
>Content-length: 353
>
>
>Dear all,
>
>somme ome can tell me how I can plot the 
>correlograms of GAM, GLM, AND SVM, in the same graph.
>
>Yacine KOUBA
>PHD Student (ecological modelization)
>Pyrenean Institut of Ecology
>Avda Monta?ana, Apdo 202, 50080, ZARAGOZA, SPAIN
>_________________________________________________________________
>
>
>         [[alternative HTML version deleted]]
>
>
>---------------------------------------------------------------------------------------------------
>Texto a?adido por Panda IS 2008:
>
>  Este mensaje NO ha sido clasificado como SPAM. 
> Si se trata de un mensaje de correo no 
> solicitado (SPAM), haz clic en el siguiente 
> v?nculo para reclasificarlo: 
> http://localhost:6083/Panda?ID=pav_3176&SPAM=true&path=C:\Documents%20and%20Settings\mcr\Configuraci?n%20local\Datos%20de%20programa\Panda%20Software\AntiSpam
>---------------------------------------------------------------------------------------------------
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at stat.math.ethz.ch
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo

________________________________

Marcelino de la Cruz Rot

Departamento de  Biolog?a Vegetal
E.U.T.I. Agr?cola
Universidad Polit?cnica de Madrid
28040-Madrid
Tel.: 91 336 54 35
Fax: 91 336 56 56
marcelino.delacruz at upm.es



From annachiara.saguatti at gmail.com  Mon Dec 15 11:50:06 2008
From: annachiara.saguatti at gmail.com (Annachiara Saguatti)
Date: Mon, 15 Dec 2008 11:50:06 +0100
Subject: [R-sig-Geo] LM test in a spatial lag model
Message-ID: <516dbff70812150250n7a6a5617uc6c5c804605294a1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081215/bd09b525/attachment.pl>

From Roger.Bivand at nhh.no  Mon Dec 15 14:07:31 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 15 Dec 2008 14:07:31 +0100 (CET)
Subject: [R-sig-Geo] LM test in a spatial lag model
In-Reply-To: <516dbff70812150250n7a6a5617uc6c5c804605294a1@mail.gmail.com>
References: <516dbff70812150250n7a6a5617uc6c5c804605294a1@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0812151354570.19706@reclus.nhh.no>

On Mon, 15 Dec 2008, Annachiara Saguatti wrote:

> Hello,
>
> I have question about the interpretation of the results of my regression.
> I'm estimating the convergence between European regions with spatial
> regimes. I have first run an OLS regression for the whole set of regions and
> I have found evidence of residual autocorrelation through the LMerr and
> LMlag tests.
> This was the result:
>
> LMerr = 5.4816, df = 1, p-value = 0.01922
>
> RLMerr = 0.2422, df = 1, p-value = 0.6226
>
> LMlag = 6.3184, df = 1, p-value = 0.01195
>
>
> RLMlag = 1.079, df = 1, p-value = 0.2989
>
> SARMA = 6.5606, df = 2, p-value = 0.03762
>
> I'm modelling spatial heterogeneity through the estimation of two separate
> models for Objective 1 regions and the rest of the regions. According to the
> results of the LM tests I have decided to use a spatial lag model (is this
> correct in your opinion?). I did so because I find that the LMlag test is a
> little more significant than the LMerr... which is the decision rule in this
> case (both LM test significant and both RLM test non significant)?
>

Please note that neither of the robust LM tests are significant. It may 
very well be the case that there is no spatial "story" in your residuals 
for the chosen spatial weights.

> After running the first ML regression I see that there is another LM test
> computed at the end of the results of the regression:
>
> Log likelihood: 176.7501 for lag model
> ML residual variance (sigma squared): 4.7437e-05, (sigma: 0.0068875)
> Number of observations: 50
> Number of parameters estimated: 7
> AIC: -339.5, (AIC for lm: -334.18)
> *LM test for residual autocorrelation
> test value: 3.4731 p-value: 0.062373 *
>
> Which is the interpretation to give to it? Is this relative to a spatial
> error or to a spatial lag?

This is a test for residual error autocorrelation for the same spatial 
weights. It does appear from the AIC values that the spatial lag model 
fits the data better than the aspatial model, but it isn't clear why.

Have you tried fitting a spatial Durbin model (lagsarlm(..., 
type="mixed")), and maybe considered testing the Common Factor hypothesis 
(Mur & Angulo, Spatial Economic Analysis, 2006)? There is a growing 
literature on this.

Another possibility is to look at the Kosfeld & Lauridsen approach to look 
at the non-stationarity question (Papers in Regional Science, 2006).

However, the tests are borderline, so only spend time on this if you have 
to, it may be what in macroecology is known as a "red herring".

Hope this helps,

Roger

>
> Thank you very much for your help!
> Annachiara Saguatti
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From bgr at bgs.ac.uk  Mon Dec 15 15:48:00 2008
From: bgr at bgs.ac.uk (Rawlins, Barry G)
Date: Mon, 15 Dec 2008 14:48:00 +0000
Subject: [R-sig-Geo] Moving variance calculation from an irregular grid
Message-ID: <28C15D104A882F47954DEE56148152CC1B6B0856@nerckwmb1.ad.nerc.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081215/60931d17/attachment.pl>

From Roger.Bivand at nhh.no  Mon Dec 15 16:10:08 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 15 Dec 2008 16:10:08 +0100 (CET)
Subject: [R-sig-Geo] Moving variance calculation from an irregular grid
In-Reply-To: <28C15D104A882F47954DEE56148152CC1B6B0856@nerckwmb1.ad.nerc.ac.uk>
References: <28C15D104A882F47954DEE56148152CC1B6B0856@nerckwmb1.ad.nerc.ac.uk>
Message-ID: <alpine.LRH.2.00.0812151559030.19706@reclus.nhh.no>

On Mon, 15 Dec 2008, Rawlins, Barry G wrote:

> I would like to calculate a moving window variance across a large, 
> irregular spatial dataset (1.1 million points) - I have looked for 
> various functions but have not been able to find one that will do this.

How irregular? Is the moving window adaptive (k nearest neighbours) or 
fixed in distance for a given bandwidth - hence widely varying counts of 
points within the window? Do you need the moving window variances for the 
same support (points) as the data, or for different points (maybe a grid)? 
Could the task be divided up into (overlapping) tiles if memory is a major 
constraint? If k nearest neighbours, ANN (approximate nearest neighbours) 
has been ported several times to R, but not generalised - I can make one 
off-CRAN version available if need be. This thread may be relevant:

https://stat.ethz.ch/pipermail/r-sig-geo/2008-December/004644.html

Roger

>
> Any suggestions  much appreciated.
> Barry R
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From bgr at bgs.ac.uk  Tue Dec 16 15:07:31 2008
From: bgr at bgs.ac.uk (Rawlins, Barry G)
Date: Tue, 16 Dec 2008 14:07:31 +0000
Subject: [R-sig-Geo] Moving variance calculation from an irregular grid
In-Reply-To: <alpine.LRH.2.00.0812151559030.19706@reclus.nhh.no>
References: <28C15D104A882F47954DEE56148152CC1B6B0856@nerckwmb1.ad.nerc.ac.uk>
	<alpine.LRH.2.00.0812151559030.19706@reclus.nhh.no>
Message-ID: <28C15D104A882F47954DEE56148152CC1B6B086A@nerckwmb1.ad.nerc.ac.uk>

To summarise the outcome from my original posting:

I used the ann package (http://spatial.nhh.no/R/etc/) - see instructions on installation from previous thread.

I used this to calculate 12 nearest neighbours in my dataset:

all.tellus <- ann(cbind(data$X, data$Y), k=12) # X and Y are the coordinates
out<-as.matrix(all.tellus) # this converts the output to a matrix- probably not the right way to approach this

## then I loop through my dataset to calculate the local variances
## I was not concerned about selecting a max distance on the neighbourhood - but one could do this
require(ann)
require(stats)
for (j in 1:1075121)
vars<-seq(from=1,to=1075121,by=1) # set up my vars vector
vars[j]<-var(data$CS137[out[j,1:12]]) # writes the variances (my local variances for all points)

My code is probably very poor and many people could probably have written it much better!

"Off list" Edzer Pebebsma told me that there are functions in package gstat that will search a local neighbourhood based on a quad tree. I did not pursue this further but Edzer may be able to suggest which function/approach it is in a subsequent post.

Barry R


-----Original Message-----
From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
Sent: 15 December 2008 15:10
To: Rawlins, Barry G
Cc: 'r-sig-geo at stat.math.ethz.ch'
Subject: Re: [R-sig-Geo] Moving variance calculation from an irregular grid

On Mon, 15 Dec 2008, Rawlins, Barry G wrote:

> I would like to calculate a moving window variance across a large,
> irregular spatial dataset (1.1 million points) - I have looked for
> various functions but have not been able to find one that will do this.

How irregular? Is the moving window adaptive (k nearest neighbours) or
fixed in distance for a given bandwidth - hence widely varying counts of
points within the window? Do you need the moving window variances for the
same support (points) as the data, or for different points (maybe a grid)?
Could the task be divided up into (overlapping) tiles if memory is a major
constraint? If k nearest neighbours, ANN (approximate nearest neighbours)
has been ported several times to R, but not generalised - I can make one
off-CRAN version available if need be. This thread may be relevant:

https://stat.ethz.ch/pipermail/r-sig-geo/2008-December/004644.html

Roger

>
> Any suggestions  much appreciated.
> Barry R
>
>
>

--
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


-- 
This message (and any attachments) is for the recipient ...{{dropped:6}}



From paulojus at c3sl.ufpr.br  Tue Dec 16 15:14:42 2008
From: paulojus at c3sl.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Tue, 16 Dec 2008 12:14:42 -0200 (BRST)
Subject: [R-sig-Geo] kriging: export to grid
In-Reply-To: <alpine.LRH.2.00.0812141342020.5311@reclus.nhh.no>
References: <4944D0D5.9020701@ulb.ac.be>
	<alpine.LRH.2.00.0812141342020.5311@reclus.nhh.no>
Message-ID: <Pine.LNX.4.58.0812161211100.14936@dalmore.c3sl.ufpr.br>

I've just added to the geoR tutorial page an script with examples
on converting geoR's krige.conv() outputs to
SpatialGridDataFrame and SpatialPixelDataFrame formats defined by the sp
package

The relevant link is:
http://leg.ufpr.br/geoR/tutorials/kc2sp.R

These should be encapsulated on function in a (hopefully) near future
to facilitate conversion of outputs from both, krige.conv() and
krige.bayes()


As usual, comments/suggestions/improvements etc are very welcome!

Best
P.J.


Paulo Justiniano Ribeiro Jr
LEG (Laboratorio de Estatistica e Geoinformacao)
Universidade Federal do Parana
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 3361 3573
Fax: (+55) 41 3361 3141
e-mail: paulojus AT  ufpr  br
http://www.leg.ufpr.br/~paulojus



On Sun, 14 Dec 2008, Roger Bivand wrote:

> On Sun, 14 Dec 2008, Nicolas Meurisse wrote:
>
> > Hello,
> >
> > After kriging with the use of the  krige.conv function, I would like to
> > export my result under the grid format. In order to view it into a GIS.
> >
> > It was suggested to me to use the writeGDAL function into the rgdal package.
> > However It looks like I have a problem of supported formats
> > (dataset object of SpatialGridDataFrame-class or SpatialPixelsDataFrame-class
> > ) that is not the same as the one resulting from my krige.conv function
> > (kriging -class apparently)
> >
> > I tried several function to achieve this conversion (getRasterData,
> > SpatialGridDataFrame, SpatialPixelsDataFrame, create2GDAL, points2grid...).
> > But without any success.
> >
> > #my actual kriging script:
> > pred.grid = expand.grid(seq(170000, 130000, l = 50), seq(190000, 160000, l =
> > 50))
>
> library(sp)
> pred.grid$var3 <- 1
> coordinates(pred.grid) <- c("Var1", "Var2")
> gridded(pred.grid) <- TRUE
>
> # Create a SpatialPixelsDataFrame or SpatialGridDataFrame object first
> # - forced here by including a non-coordnate column to the data frame
>
> > myPred = krige.conv(myGData, loc = pred.grid, krige = krige.control(obj.m =
> > myOLSMod))
>
> myPred = krige.conv(myGData, loc = coordinates(pred.grid),
>   krige = krige.control(obj.m = myOLSMod))
>
> # Krige with the coordinates of the object
>
> pred.grid$predict <- myPred$predict
>
> # add the predictions (and standard errors if you like) to the
> # object, they are in the correct order;
> # then write out, choosing the output column as desired
>
> tf <- tempfile()
> writeGDAL(pred.grid["predict"], tf, drivername="GTiff") # not type="Byte"!
> GDALinfo(tf)
>
> # I suppose you are using the temporary file here to test your approach
> # as you ought to put the output file in a permanent place if you will
> # need it later
>
> Hope this helps,
>
> Roger
>
> > image(myPred, loc = pred.grid, col = gray(seq(1, 0.1, l = 30)))
> >
> > #my conversion attempts
> > tf <- tempfile()
> > writeGDAL(myPred, tf, drivername="GTiff", type="Byte", options=NULL)
> > [Erreur dans function (classes, fdef, mtable) : unable to find an inherited
> > method for function "gridded", for signature "kriging"]
> >
> > Thanks a lot,
> >
> > Nicolas
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From david.lunn at mrc-bsu.cam.ac.uk  Tue Dec 16 19:12:23 2008
From: david.lunn at mrc-bsu.cam.ac.uk (Dave Lunn)
Date: Tue, 16 Dec 2008 18:12:23 +0000
Subject: [R-sig-Geo] world map data
Message-ID: <4947EF87.6040401@mrc-bsu.cam.ac.uk>

Hi all,
Sorry if this is a dumb question.... I'm trying to produce a world map 
showing WinBUGS useage from the data collected at the mrc-bsu web-site. 
I've been trying to use the map + mapdata packages but was surprised to 
find that the geography of the world map seemed a little out-of-date, 
being specified in terms of USSR and Yugoslavia, for instance. I 
wondered if there was a more up-to-date version available somewhere??
Best wishes + many thanks for any help you can give...
Dave Lunn

-- 
Dave Lunn
MRC Biostatistics Unit,
Institute of Public Health,
University Forvie Site,
Robinson Way,
Cambridge CB2 0SR
+44 (0)1223 330394



From reeves at nceas.ucsb.edu  Tue Dec 16 19:24:20 2008
From: reeves at nceas.ucsb.edu (rick reeves)
Date: Tue, 16 Dec 2008 10:24:20 -0800
Subject: [R-sig-Geo] world map data
In-Reply-To: <4947EF87.6040401@mrc-bsu.cam.ac.uk>
References: <4947EF87.6040401@mrc-bsu.cam.ac.uk>
Message-ID: <4947F254.4000207@nceas.ucsb.edu>

Dave:

Here is one place to obtain the Digital Chart of the World, which should 
be more accurate:

http://www.maproom.psu.edu/dcw/   (Penn State University DCW Server)

Get the shape files, use R maptools routines (e.g., ReadShapePoly) to 
read the files.

Hope this helps,
Rick Reeves

Dave Lunn wrote:
> Hi all,
> Sorry if this is a dumb question.... I'm trying to produce a world map 
> showing WinBUGS useage from the data collected at the mrc-bsu 
> web-site. I've been trying to use the map + mapdata packages but was 
> surprised to find that the geography of the world map seemed a little 
> out-of-date, being specified in terms of USSR and Yugoslavia, for 
> instance. I wondered if there was a more up-to-date version available 
> somewhere??
> Best wishes + many thanks for any help you can give...
> Dave Lunn
>


-- 
Rick Reeves
Scientific Programmer/Analyst and Data Manager
National Center for Ecological Analysis and Synthesis
UC Santa Barbara
www.nceas.ucsb.edu
805 892 2533



From b.rowlingson at lancaster.ac.uk  Tue Dec 16 19:22:53 2008
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 16 Dec 2008 18:22:53 +0000
Subject: [R-sig-Geo] world map data
In-Reply-To: <4947EF87.6040401@mrc-bsu.cam.ac.uk>
References: <4947EF87.6040401@mrc-bsu.cam.ac.uk>
Message-ID: <d8ad40b50812161022s7463cab8uca777975ab45555c@mail.gmail.com>

2008/12/16 Dave Lunn <david.lunn at mrc-bsu.cam.ac.uk>:
> Hi all,
> Sorry if this is a dumb question.... I'm trying to produce a world map
> showing WinBUGS useage from the data collected at the mrc-bsu web-site. I've
> been trying to use the map + mapdata packages but was surprised to find that
> the geography of the world map seemed a little out-of-date, being specified
> in terms of USSR and Yugoslavia, for instance. I wondered if there was a
> more up-to-date version available somewhere??
> Best wishes + many thanks for any help you can give...

 Is this for print or web purposes? If for a web page, I'd use
OpenLayers to overlay your points on one of the publicly available
world maps, such as OpenStreetMap. Then you'd have a zoomable slippy
map on your page for people to interact with.

Barry



From edzer.pebesma at uni-muenster.de  Tue Dec 16 22:26:53 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 16 Dec 2008 22:26:53 +0100
Subject: [R-sig-Geo] kriging: export to grid
In-Reply-To: <Pine.LNX.4.58.0812161211100.14936@dalmore.c3sl.ufpr.br>
References: <4944D0D5.9020701@ulb.ac.be>	<alpine.LRH.2.00.0812141342020.5311@reclus.nhh.no>
	<Pine.LNX.4.58.0812161211100.14936@dalmore.c3sl.ufpr.br>
Message-ID: <49481D1D.5060204@uni-muenster.de>

Hi Paulo,

you suggest to add conversion functions to geoR later on, but I (as the 
average lazy user) would ask the following: if in the following geoR call

kc.s <- krige.conv(s100, loc=gr.s, krige=krige.control(obj=ml.s))


gr.s is of class SpatialPixels[DataFrame] or SpatialGrid[DataFrame], 
could, as output, the object kc.s be of that same class? You could argue 
this is incompatible, but a call like that was never supposed to work so 
you could call it progress as well. And it saves me the conversion. Of 
course, gr.s and kc.s could be of class SpatialPoints[DataFrame] as well.

Bests regards,
--
Edzer

Paulo Justiniano Ribeiro Jr wrote:
> I've just added to the geoR tutorial page an script with examples
> on converting geoR's krige.conv() outputs to
> SpatialGridDataFrame and SpatialPixelDataFrame formats defined by the sp
> package
>
> The relevant link is:
> http://leg.ufpr.br/geoR/tutorials/kc2sp.R
>
> These should be encapsulated on function in a (hopefully) near future
> to facilitate conversion of outputs from both, krige.conv() and
> krige.bayes()
>
>
> As usual, comments/suggestions/improvements etc are very welcome!
>
> Best
> P.J.
>
>
> Paulo Justiniano Ribeiro Jr
> LEG (Laboratorio de Estatistica e Geoinformacao)
> Universidade Federal do Parana
> Caixa Postal 19.081
> CEP 81.531-990
> Curitiba, PR  -  Brasil
> Tel: (+55) 41 3361 3573
> Fax: (+55) 41 3361 3141
> e-mail: paulojus AT  ufpr  br
> http://www.leg.ufpr.br/~paulojus
>
>
>
> On Sun, 14 Dec 2008, Roger Bivand wrote:
>
>   
>> On Sun, 14 Dec 2008, Nicolas Meurisse wrote:
>>
>>     
>>> Hello,
>>>
>>> After kriging with the use of the  krige.conv function, I would like to
>>> export my result under the grid format. In order to view it into a GIS.
>>>
>>> It was suggested to me to use the writeGDAL function into the rgdal package.
>>> However It looks like I have a problem of supported formats
>>> (dataset object of SpatialGridDataFrame-class or SpatialPixelsDataFrame-class
>>> ) that is not the same as the one resulting from my krige.conv function
>>> (kriging -class apparently)
>>>
>>> I tried several function to achieve this conversion (getRasterData,
>>> SpatialGridDataFrame, SpatialPixelsDataFrame, create2GDAL, points2grid...).
>>> But without any success.
>>>
>>> #my actual kriging script:
>>> pred.grid = expand.grid(seq(170000, 130000, l = 50), seq(190000, 160000, l =
>>> 50))
>>>       
>> library(sp)
>> pred.grid$var3 <- 1
>> coordinates(pred.grid) <- c("Var1", "Var2")
>> gridded(pred.grid) <- TRUE
>>
>> # Create a SpatialPixelsDataFrame or SpatialGridDataFrame object first
>> # - forced here by including a non-coordnate column to the data frame
>>
>>     
>>> myPred = krige.conv(myGData, loc = pred.grid, krige = krige.control(obj.m =
>>> myOLSMod))
>>>       
>> myPred = krige.conv(myGData, loc = coordinates(pred.grid),
>>   krige = krige.control(obj.m = myOLSMod))
>>
>> # Krige with the coordinates of the object
>>
>> pred.grid$predict <- myPred$predict
>>
>> # add the predictions (and standard errors if you like) to the
>> # object, they are in the correct order;
>> # then write out, choosing the output column as desired
>>
>> tf <- tempfile()
>> writeGDAL(pred.grid["predict"], tf, drivername="GTiff") # not type="Byte"!
>> GDALinfo(tf)
>>
>> # I suppose you are using the temporary file here to test your approach
>> # as you ought to put the output file in a permanent place if you will
>> # need it later
>>
>> Hope this helps,
>>
>> Roger
>>
>>     
>>> image(myPred, loc = pred.grid, col = gray(seq(1, 0.1, l = 30)))
>>>
>>> #my conversion attempts
>>> tf <- tempfile()
>>> writeGDAL(myPred, tf, drivername="GTiff", type="Byte", options=NULL)
>>> [Erreur dans function (classes, fdef, mtable) : unable to find an inherited
>>> method for function "gridded", for signature "kriging"]
>>>
>>> Thanks a lot,
>>>
>>> Nicolas
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>       
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>     
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de



From paulojus at c3sl.ufpr.br  Tue Dec 16 23:17:55 2008
From: paulojus at c3sl.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Tue, 16 Dec 2008 20:17:55 -0200 (BRST)
Subject: [R-sig-Geo] kriging: export to grid
In-Reply-To: <49481D1D.5060204@uni-muenster.de>
References: <4944D0D5.9020701@ulb.ac.be>
	<alpine.LRH.2.00.0812141342020.5311@reclus.nhh.no>
	<Pine.LNX.4.58.0812161211100.14936@dalmore.c3sl.ufpr.br>
	<49481D1D.5060204@uni-muenster.de>
Message-ID: <Pine.LNX.4.58.0812162012250.15657@dalmore.c3sl.ufpr.br>

Hi Edzer

Thanks for the feed back.

And yes I agree this is a nice design - the type of input define the type
of output, and, besides that, output.control() can have an
option do explicitly specify the required output format.
If we have the converters, is just a matter of call it internally.

class "geodata" already converts from and to SpatialPointsDataFrame
by this should be extended to (bayesian)kriging outputs

More generally geoR should accept sp object as inputs not only in the
locations arguments but also as data

... and more generally geoR2 should have a completely new design fully
compatible with sp --- I need a sabatical!!!!!

thanks and best regards!


Paulo Justiniano Ribeiro Jr
LEG (Laboratorio de Estatistica e Geoinformacao)
Universidade Federal do Parana
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 3361 3573
Fax: (+55) 41 3361 3141
e-mail: paulojus AT  ufpr  br
http://www.leg.ufpr.br/~paulojus



On Tue, 16 Dec 2008, Edzer Pebesma wrote:

> Hi Paulo,
>
> you suggest to add conversion functions to geoR later on, but I (as the
> average lazy user) would ask the following: if in the following geoR call
>
> kc.s <- krige.conv(s100, loc=gr.s, krige=krige.control(obj=ml.s))
>
>
> gr.s is of class SpatialPixels[DataFrame] or SpatialGrid[DataFrame],
> could, as output, the object kc.s be of that same class? You could argue
> this is incompatible, but a call like that was never supposed to work so
> you could call it progress as well. And it saves me the conversion. Of
> course, gr.s and kc.s could be of class SpatialPoints[DataFrame] as well.
>
> Bests regards,
> --
> Edzer
>
> Paulo Justiniano Ribeiro Jr wrote:
> > I've just added to the geoR tutorial page an script with examples
> > on converting geoR's krige.conv() outputs to
> > SpatialGridDataFrame and SpatialPixelDataFrame formats defined by the sp
> > package
> >
> > The relevant link is:
> > http://leg.ufpr.br/geoR/tutorials/kc2sp.R
> >
> > These should be encapsulated on function in a (hopefully) near future
> > to facilitate conversion of outputs from both, krige.conv() and
> > krige.bayes()
> >
> >
> > As usual, comments/suggestions/improvements etc are very welcome!
> >
> > Best
> > P.J.
> >
> >
> > Paulo Justiniano Ribeiro Jr
> > LEG (Laboratorio de Estatistica e Geoinformacao)
> > Universidade Federal do Parana
> > Caixa Postal 19.081
> > CEP 81.531-990
> > Curitiba, PR  -  Brasil
> > Tel: (+55) 41 3361 3573
> > Fax: (+55) 41 3361 3141
> > e-mail: paulojus AT  ufpr  br
> > http://www.leg.ufpr.br/~paulojus
> >
> >
> >
> > On Sun, 14 Dec 2008, Roger Bivand wrote:
> >
> >
> >> On Sun, 14 Dec 2008, Nicolas Meurisse wrote:
> >>
> >>
> >>> Hello,
> >>>
> >>> After kriging with the use of the  krige.conv function, I would like to
> >>> export my result under the grid format. In order to view it into a GIS.
> >>>
> >>> It was suggested to me to use the writeGDAL function into the rgdal package.
> >>> However It looks like I have a problem of supported formats
> >>> (dataset object of SpatialGridDataFrame-class or SpatialPixelsDataFrame-class
> >>> ) that is not the same as the one resulting from my krige.conv function
> >>> (kriging -class apparently)
> >>>
> >>> I tried several function to achieve this conversion (getRasterData,
> >>> SpatialGridDataFrame, SpatialPixelsDataFrame, create2GDAL, points2grid...).
> >>> But without any success.
> >>>
> >>> #my actual kriging script:
> >>> pred.grid = expand.grid(seq(170000, 130000, l = 50), seq(190000, 160000, l =
> >>> 50))
> >>>
> >> library(sp)
> >> pred.grid$var3 <- 1
> >> coordinates(pred.grid) <- c("Var1", "Var2")
> >> gridded(pred.grid) <- TRUE
> >>
> >> # Create a SpatialPixelsDataFrame or SpatialGridDataFrame object first
> >> # - forced here by including a non-coordnate column to the data frame
> >>
> >>
> >>> myPred = krige.conv(myGData, loc = pred.grid, krige = krige.control(obj.m =
> >>> myOLSMod))
> >>>
> >> myPred = krige.conv(myGData, loc = coordinates(pred.grid),
> >>   krige = krige.control(obj.m = myOLSMod))
> >>
> >> # Krige with the coordinates of the object
> >>
> >> pred.grid$predict <- myPred$predict
> >>
> >> # add the predictions (and standard errors if you like) to the
> >> # object, they are in the correct order;
> >> # then write out, choosing the output column as desired
> >>
> >> tf <- tempfile()
> >> writeGDAL(pred.grid["predict"], tf, drivername="GTiff") # not type="Byte"!
> >> GDALinfo(tf)
> >>
> >> # I suppose you are using the temporary file here to test your approach
> >> # as you ought to put the output file in a permanent place if you will
> >> # need it later
> >>
> >> Hope this helps,
> >>
> >> Roger
> >>
> >>
> >>> image(myPred, loc = pred.grid, col = gray(seq(1, 0.1, l = 30)))
> >>>
> >>> #my conversion attempts
> >>> tf <- tempfile()
> >>> writeGDAL(myPred, tf, drivername="GTiff", type="Byte", options=NULL)
> >>> [Erreur dans function (classes, fdef, mtable) : unable to find an inherited
> >>> method for function "gridded", for signature "kriging"]
> >>>
> >>> Thanks a lot,
> >>>
> >>> Nicolas
> >>>
> >>> _______________________________________________
> >>> R-sig-Geo mailing list
> >>> R-sig-Geo at stat.math.ethz.ch
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>>
> >>>
> >> --
> >> Roger Bivand
> >> Economic Geography Section, Department of Economics, Norwegian School of
> >> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> >> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> >> e-mail: Roger.Bivand at nhh.no
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at stat.math.ethz.ch
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >>
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
> http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de
>
>



From gianni.lavaredo at gmail.com  Wed Dec 17 01:22:31 2008
From: gianni.lavaredo at gmail.com (gianni lavaredo)
Date: Tue, 16 Dec 2008 16:22:31 -0800
Subject: [R-sig-Geo] georeferenc problem export envi files with gdal
	(R+SAGA)---help
Message-ID: <518dff330812161622p44e83a5ajc23bbab6bee146a6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081216/143273d6/attachment.pl>

From Friderike.Oehler at fao.org  Wed Dec 17 08:51:02 2008
From: Friderike.Oehler at fao.org (Oehler, Friderike (AGPP))
Date: Wed, 17 Dec 2008 08:51:02 +0100
Subject: [R-sig-Geo] world map data
Message-ID: <1A28265B00AA7E4085BB761555D3FCE8016AF9DC@hqagex02.fao.org>

For data of a world map of administrative boundaries, I can also recommend
the "Global Administrative Unit Layers" from the FAO Geonetwork catalog
http://www.fao.org/geonetwork/ Just enter "GAUL" in the search window. The
data exist from 1990 to 2008.

Cheers,
Friderike


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of rick reeves
Sent: 16 December 2008 19:24
To: Dave Lunn; r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] world map data


Dave:

Here is one place to obtain the Digital Chart of the World, which should 
be more accurate:

http://www.maproom.psu.edu/dcw/   (Penn State University DCW Server)

Get the shape files, use R maptools routines (e.g., ReadShapePoly) to 
read the files.

Hope this helps,
Rick Reeves

Dave Lunn wrote:
> Hi all,
> Sorry if this is a dumb question.... I'm trying to produce a world map
> showing WinBUGS useage from the data collected at the mrc-bsu 
> web-site. I've been trying to use the map + mapdata packages but was 
> surprised to find that the geography of the world map seemed a little 
> out-of-date, being specified in terms of USSR and Yugoslavia, for 
> instance. I wondered if there was a more up-to-date version available 
> somewhere??
> Best wishes + many thanks for any help you can give...
> Dave Lunn
>


-- 
Rick Reeves
Scientific Programmer/Analyst and Data Manager
National Center for Ecological Analysis and Synthesis
UC Santa Barbara
www.nceas.ucsb.edu
805 892 2533

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From Roger.Bivand at nhh.no  Wed Dec 17 10:00:10 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 17 Dec 2008 10:00:10 +0100 (CET)
Subject: [R-sig-Geo] world map data
In-Reply-To: <1A28265B00AA7E4085BB761555D3FCE8016AF9DC@hqagex02.fao.org>
References: <1A28265B00AA7E4085BB761555D3FCE8016AF9DC@hqagex02.fao.org>
Message-ID: <alpine.LRH.2.00.0812170950360.8435@reclus.nhh.no>

On Wed, 17 Dec 2008, Oehler, Friderike (AGPP) wrote:

> For data of a world map of administrative boundaries, I can also recommend
> the "Global Administrative Unit Layers" from the FAO Geonetwork catalog
> http://www.fao.org/geonetwork/ Just enter "GAUL" in the search window. The
> data exist from 1990 to 2008.

Thanks. These are very good data sets, and show how much work has been put 
into their construction and delivery.

A simpler alternative is shown on an unfinished webpage on my site:

http://spatial.nhh.no/R/etc/world_map_intro.html

and an older and two newer downloads of worldmaps, the newer ones 
generalised and much smaller in file size:

http://spatial.nhh.no/R/etc/world_countries.rda
http://spatial.nhh.no/R/etc/TM_WORLD_BORDERS_SIMPL-0.2.RData
http://spatial.nhh.no/R/etc/TM_WORLD_BORDERS_SIMPL-0.2_Mollweide.RData

with the latter in the Mollweide projection. They use the classes defined 
in the sp package. The work was "done" in connection with a QUEST workshop 
in Devon UK in early July. They are all RData files to load directly into 
R.

Hope this helps,

Roger

>
> Cheers,
> Friderike
>
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of rick reeves
> Sent: 16 December 2008 19:24
> To: Dave Lunn; r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] world map data
>
>
> Dave:
>
> Here is one place to obtain the Digital Chart of the World, which should
> be more accurate:
>
> http://www.maproom.psu.edu/dcw/   (Penn State University DCW Server)
>
> Get the shape files, use R maptools routines (e.g., ReadShapePoly) to
> read the files.
>
> Hope this helps,
> Rick Reeves
>
> Dave Lunn wrote:
>> Hi all,
>> Sorry if this is a dumb question.... I'm trying to produce a world map
>> showing WinBUGS useage from the data collected at the mrc-bsu
>> web-site. I've been trying to use the map + mapdata packages but was
>> surprised to find that the geography of the world map seemed a little
>> out-of-date, being specified in terms of USSR and Yugoslavia, for
>> instance. I wondered if there was a more up-to-date version available
>> somewhere??
>> Best wishes + many thanks for any help you can give...
>> Dave Lunn
>>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ct529 at york.ac.uk  Wed Dec 17 12:25:33 2008
From: ct529 at york.ac.uk (Corrado)
Date: Wed, 17 Dec 2008 11:25:33 +0000
Subject: [R-sig-Geo]
	=?iso-8859-1?q?Principal_Component_Analysis_-_Selecti?=
	=?iso-8859-1?q?ng=09components=3F_+_right_choice=3F?=
In-Reply-To: <49421E89.6080300@biomserv.univ-lyon1.fr>
References: <200812111146.38088.ct529@york.ac.uk>
	<49412788.9020803@uni-muenster.de>
	<49421E89.6080300@biomserv.univ-lyon1.fr>
Message-ID: <200812171125.33206.ct529@york.ac.uk>

Dear R-sig-geo friends,

I have been testing some of the suggested approaches, and they seem too 
confirm each others conclusion.

I think one of the nice things about PC is that it does actually generate 
variables that are a mixture of the original variables (in this case a 
combination of precipitation and temperature), and, in a sense, it seems to 
account for interaction between variables. Do you think this statement is 
true?

Best,

-- 
Corrado Topi

Global Climate Change & Biodiversity Indicators
Area 18,Department of Biology
University of York, York, YO10 5YW, UK
Phone: + 44 (0) 1904 328645, E-mail: ct529 at york.ac.uk



From annachiara.saguatti at gmail.com  Wed Dec 17 14:58:55 2008
From: annachiara.saguatti at gmail.com (Annachiara Saguatti)
Date: Wed, 17 Dec 2008 14:58:55 +0100
Subject: [R-sig-Geo] calculate distance from coordinates
Message-ID: <516dbff70812170558u74996802p60d86b2880e601cc@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081217/081fdd42/attachment.pl>

From Kamran.Safi at ioz.ac.uk  Wed Dec 17 15:08:53 2008
From: Kamran.Safi at ioz.ac.uk (Kamran Safi)
Date: Wed, 17 Dec 2008 14:08:53 -0000
Subject: [R-sig-Geo] calculate distance from coordinates
In-Reply-To: <516dbff70812170558u74996802p60d86b2880e601cc@mail.gmail.com>
References: <516dbff70812170558u74996802p60d86b2880e601cc@mail.gmail.com>
Message-ID: <41E1ED29E5E8E34BBDD8B82CFA1A9D040642040B@zsl26>

Hi Annachiara,

This is what you are looking for, I think:

http://help.nceas.ucsb.edu/R:_Spatial

Somewhere down at the middle... 


Kamran


------------------------
Kamran Safi

Postdoctoral Research Fellow
Institute of Zoology
Zoological Society of London
Regent's Park
London NW1 4RY

http://www.zoo.cam.ac.uk/ioz/people/safi.htm

http://spatialr.googlepages.com
http://asapi.wetpaint.com


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Annachiara
Saguatti
Sent: 17 December 2008 13:59
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] calculate distance from coordinates

Hello,

I have a question which should be very simple. I have a list of long-lat
coordinates of 196 sites and I need to calculate the great circle
distance
(in miles?) between all of them. I can't find the right function
though... I
need this in order to calculate the quartiles of the distances between
all
the regions and set a cut-off distance to create a neighbor list. I have
tried the "dist" function but the output doesn't seem to be what I
expected,
because I cannot recognize the numbers I get as the distance between the
sites: they're too low (max 44.51000, but the sites are the European
regional capitals...).

Does anyone have a hint on this?

Thank you very much,
Annachiara Saguatti

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo




Click
https://www.mailcontrol.com/sr/wQw0zmjPoHdJTZGyOCrrhg==
QY9pqEtBGg0LlGvnh1B!oYVi7e7dvuP24!X9jTmmkEZ8A==  to report this email as
spam.


The Zoological Society of London is incorporated by Royal Charter
Principal Office England. Company Number RC000749
Registered address: 
Regent's Park, London, England NW1 4RY
Registered Charity in England and Wales no. 208728 

_________________________________________________________________________
This e-mail has been sent in confidence to the named add...{{dropped:17}}



From Kamran.Safi at ioz.ac.uk  Wed Dec 17 17:46:26 2008
From: Kamran.Safi at ioz.ac.uk (Kamran Safi)
Date: Wed, 17 Dec 2008 16:46:26 -0000
Subject: [R-sig-Geo] calculate distance from coordinates
In-Reply-To: <516dbff70812170839o4f075bc1nfef2e9148b49ac70@mail.gmail.com>
References: <516dbff70812170558u74996802p60d86b2880e601cc@mail.gmail.com>
	<41E1ED29E5E8E34BBDD8B82CFA1A9D040642040B@zsl26>
	<516dbff70812170839o4f075bc1nfef2e9148b49ac70@mail.gmail.com>
Message-ID: <41E1ED29E5E8E34BBDD8B82CFA1A9D04064205DB@zsl26>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081217/0629b196/attachment.pl>

From annachiara.saguatti at gmail.com  Wed Dec 17 17:50:08 2008
From: annachiara.saguatti at gmail.com (Annachiara Saguatti)
Date: Wed, 17 Dec 2008 17:50:08 +0100
Subject: [R-sig-Geo] calculate distance from coordinates
In-Reply-To: <41E1ED29E5E8E34BBDD8B82CFA1A9D04064205DB@zsl26>
References: <516dbff70812170558u74996802p60d86b2880e601cc@mail.gmail.com>
	<41E1ED29E5E8E34BBDD8B82CFA1A9D040642040B@zsl26>
	<516dbff70812170839o4f075bc1nfef2e9148b49ac70@mail.gmail.com>
	<41E1ED29E5E8E34BBDD8B82CFA1A9D04064205DB@zsl26>
Message-ID: <516dbff70812170850o18aeaea9xdf5c39cca8348291@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081217/76edc9b0/attachment.pl>

From annachiara.saguatti at gmail.com  Wed Dec 17 17:39:12 2008
From: annachiara.saguatti at gmail.com (Annachiara Saguatti)
Date: Wed, 17 Dec 2008 17:39:12 +0100
Subject: [R-sig-Geo] calculate distance from coordinates
In-Reply-To: <41E1ED29E5E8E34BBDD8B82CFA1A9D040642040B@zsl26>
References: <516dbff70812170558u74996802p60d86b2880e601cc@mail.gmail.com>
	<41E1ED29E5E8E34BBDD8B82CFA1A9D040642040B@zsl26>
Message-ID: <516dbff70812170839o4f075bc1nfef2e9148b49ac70@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081217/bc10f346/attachment.pl>

From robert.ptacnik at niva.no  Wed Dec 17 18:51:09 2008
From: robert.ptacnik at niva.no (robert.ptacnik at niva.no)
Date: Wed, 17 Dec 2008 18:51:09 +0100
Subject: [R-sig-Geo] pcnm - scaling
Message-ID: <OF1F2E7B5E.CF95F96C-ONC1257522.00621147-C1257522.0062114A@niva.no>



Dear listers,

[below message was posted on R-help already, but maybe is p?aced better
here]

I am using the pcnm function (spacemakeR) to obtain eigenvectors for a

spatial grid of sampling sites. These pcnm eigenvectors are then used in

multivariate ordination to test where community composition follows local

environment or rather shows spatial autocorrelation, and get support for

apatial autocorrelation.

In an RDA analysis, I can see which eigenvectors correlate most with my

data, which can be interpreted that the spatial scale is rather 'fine' or

'broad' (broad in case of my data). However, is there a way to read the
spatial scale on which the

data correlates best, i.e. is it possible to extract a spatial scale

describing the spatial autocorrelation (e.g. from the eigenvalues)?

My data


- irregularly spaced sampling sites, total scale ca. 2000 km, most sites

few tens of km apart

- i use the dfunction rdist.earth to obtain a distance-matrix of all sites

prior to using pcnm

Thanks !

Robert


From Kamran.Safi at ioz.ac.uk  Wed Dec 17 19:48:39 2008
From: Kamran.Safi at ioz.ac.uk (Kamran Safi)
Date: Wed, 17 Dec 2008 18:48:39 -0000
Subject: [R-sig-Geo] Principal Component Analysis -
	Selecting	components? + right choice?
References: <200812111146.38088.ct529@york.ac.uk>
	<49412788.9020803@uni-muenster.de>
	<49421E89.6080300@biomserv.univ-lyon1.fr>
	<200812171125.33206.ct529@york.ac.uk>
Message-ID: <41E1ED29E5E8E34BBDD8B82CFA1A9D0405F985F2@zsl26>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081217/8bb50331/attachment.pl>

From hilton at meteo.psu.edu  Thu Dec 18 02:18:13 2008
From: hilton at meteo.psu.edu (Timothy W. Hilton)
Date: Wed, 17 Dec 2008 20:18:13 -0500
Subject: [R-sig-Geo] plot.gstatVariogram - overlay multiple models on a
	single variogram
Message-ID: <20081218011813.GA29777@abl.met.psu.edu>

Hello,

Using gstat, I would like to overlay several different variogram
models onto a single empirical semivariogram.  I am having trouble
mastering the necessary lattice plotting commands.  Using an example
from this list (or maybe the docs for gstat; I'm not sure):

mypanel = function(x,y,...) {                                                 
  vgm.panel.xyplot(x,y,...)
}

require(gstat)
g = gstat(formula = log(zinc)~1, data = meuse)
v = variogram(log(zinc)~1,meuse)
vgm1 = fit.variogram(v,vgm(1, "Sph", 900,1))
vgm2 = fit.variogram(v,vgm(1, "Exp", 300,1))
print(plot(v, model=vgm1 ,panel=mypanel))


This plots the variogram with vgm1.  I would now like to overlay vgm2,
in a different color.  I have tried many variations on making model a
list, or trying to write a panel function that will plot the
variogram, then both models sequentially, but I can't get anything to
work.

Many thanks for any help,
Tim



From edzer.pebesma at uni-muenster.de  Thu Dec 18 08:03:32 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 18 Dec 2008 08:03:32 +0100
Subject: [R-sig-Geo] plot.gstatVariogram - overlay multiple models on
 a	single variogram
In-Reply-To: <20081218011813.GA29777@abl.met.psu.edu>
References: <20081218011813.GA29777@abl.met.psu.edu>
Message-ID: <4949F5C4.8060705@uni-muenster.de>

Try:

mypanel = function(x,y,...) {                                                 
  vgm.panel.xyplot(x,y,...)
  panel.lines(variogramLine(vgm2,1500))
}

require(gstat)
g = gstat(formula = log(zinc)~1, data = meuse)
v = variogram(log(zinc)~1,meuse)
vgm1 = fit.variogram(v,vgm(1, "Sph", 900,1))
vgm2 = fit.variogram(v,vgm(1, "Exp", 300,1))
print(plot(v, model=vgm1 ,panel=mypanel))

--
Edzer

Timothy W. Hilton wrote:
> Hello,
>
> Using gstat, I would like to overlay several different variogram
> models onto a single empirical semivariogram.  I am having trouble
> mastering the necessary lattice plotting commands.  Using an example
> from this list (or maybe the docs for gstat; I'm not sure):
>
> mypanel = function(x,y,...) {                                                 
>   vgm.panel.xyplot(x,y,...)
> }
>
> require(gstat)
> g = gstat(formula = log(zinc)~1, data = meuse)
> v = variogram(log(zinc)~1,meuse)
> vgm1 = fit.variogram(v,vgm(1, "Sph", 900,1))
> vgm2 = fit.variogram(v,vgm(1, "Exp", 300,1))
> print(plot(v, model=vgm1 ,panel=mypanel))
>
>
> This plots the variogram with vgm1.  I would now like to overlay vgm2,
> in a different color.  I have tried many variations on making model a
> list, or trying to write a panel function that will plot the
> variogram, then both models sequentially, but I can't get anything to
> work.
>
> Many thanks for any help,
> Tim
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de



From annachiara.saguatti at gmail.com  Thu Dec 18 10:18:24 2008
From: annachiara.saguatti at gmail.com (Annachiara Saguatti)
Date: Thu, 18 Dec 2008 10:18:24 +0100
Subject: [R-sig-Geo] dummies and multicollinearity in lagsarlm
Message-ID: <516dbff70812180118n5439ccx258d9e9ebc0b4008@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081218/072802bf/attachment.pl>

From Roger.Bivand at nhh.no  Thu Dec 18 13:59:31 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 18 Dec 2008 13:59:31 +0100 (CET)
Subject: [R-sig-Geo] dummies and multicollinearity in lagsarlm
In-Reply-To: <516dbff70812180118n5439ccx258d9e9ebc0b4008@mail.gmail.com>
References: <516dbff70812180118n5439ccx258d9e9ebc0b4008@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0812181353320.13292@reclus.nhh.no>

On Thu, 18 Dec 2008, Annachiara Saguatti wrote:

> Hello,
>
> is there a way to estimate a sar model (> lagsarlm) with a dummy variable in
> order to discriminate into two spatial regimes and obtain two different
> coefficients' estimations for each variable? So far I've been constructing
> two new variables from each original one by multiplicating it by each dummy,
> that is: GPC*D1 and GDP*D2. After that I've been running a regression by
> using the two new variables as explanatory v.
> Since the two dummies are perfecly complementary, I guess there might be a
> problem of multicollinearity in this way of estimating the model. Is there
> an option like the "subset" one in the "lm" function which I can use in a
> SAR model? Or otherwise, how would you estimate a SAR model with two spatial
> regimes in R?

This is one of the strengths of the formula abstraction. Dummies are not 
needed, just a factor. The notation would be something like:

formula=y ~ factor / (x1 + x2 + x3 + ...) - 1, data=...

with / using the factor to fit coefficients of the xi for each level of 
factor, and -1 removing a global intercept, so giving an intercept for 
each level of factor. The Chow test is then anova() of the model without 
factor / ... -1 against the model with it.

Hope this helps,

Roger


>
> Thank you
> Annachiara Saguatti
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From dray at biomserv.univ-lyon1.fr  Thu Dec 18 16:07:16 2008
From: dray at biomserv.univ-lyon1.fr (=?ISO-8859-1?Q?St=E9phane_Dray?=)
Date: Thu, 18 Dec 2008 16:07:16 +0100
Subject: [R-sig-Geo] pcnm - scaling
In-Reply-To: <OF1F2E7B5E.CF95F96C-ONC1257522.00621147-C1257522.0062114A@niva.no>
References: <OF1F2E7B5E.CF95F96C-ONC1257522.00621147-C1257522.0062114A@niva.no>
Message-ID: <494A6724.6070205@biomserv.univ-lyon1.fr>

Hi,
it is not clear for me what you mean by  "is it possible to extract a 
spatial scale describing the spatial autocorrelation (e.g. from the 
eigenvalues)?". The function scores.listw is more general and returns a 
vector $values that are equal to Moran's I (multiplyied by a constant).

Cheers,


 

robert.ptacnik at niva.no wrote:
> Dear listers,
>
> [below message was posted on R-help already, but maybe is p?aced better
> here]
>
> I am using the pcnm function (spacemakeR) to obtain eigenvectors for a
>
> spatial grid of sampling sites. These pcnm eigenvectors are then used in
>
> multivariate ordination to test where community composition follows local
>
> environment or rather shows spatial autocorrelation, and get support for
>
> apatial autocorrelation.
>
> In an RDA analysis, I can see which eigenvectors correlate most with my
>
> data, which can be interpreted that the spatial scale is rather 'fine' or
>
> 'broad' (broad in case of my data). However, is there a way to read the
> spatial scale on which the
>
> data correlates best, i.e. is it possible to extract a spatial scale
>
> describing the spatial autocorrelation (e.g. from the eigenvalues)?
>
> My data
>
>
> - irregularly spaced sampling sites, total scale ca. 2000 km, most sites
>
> few tens of km apart
>
> - i use the dfunction rdist.earth to obtain a distance-matrix of all sites
>
> prior to using pcnm
>
> Thanks !
>
> Robert
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
>   

-- 
St?phane DRAY (dray at biomserv.univ-lyon1.fr )
Laboratoire BBE-CNRS-UMR-5558, Univ. C. Bernard - Lyon I
43, Bd du 11 Novembre 1918, 69622 Villeurbanne Cedex, France
Tel: 33 4 72 43 27 57       Fax: 33 4 72 43 13 88
http://biomserv.univ-lyon1.fr/~dray/



From annachiara.saguatti at gmail.com  Thu Dec 18 16:16:20 2008
From: annachiara.saguatti at gmail.com (Annachiara Saguatti)
Date: Thu, 18 Dec 2008 16:16:20 +0100
Subject: [R-sig-Geo] dummies and multicollinearity in lagsarlm
In-Reply-To: <alpine.LRH.2.00.0812181353320.13292@reclus.nhh.no>
References: <516dbff70812180118n5439ccx258d9e9ebc0b4008@mail.gmail.com>
	<alpine.LRH.2.00.0812181353320.13292@reclus.nhh.no>
Message-ID: <516dbff70812180716o3b964cb5t888c536deb6f1dc8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081218/2c417757/attachment.pl>

From Roger.Bivand at nhh.no  Thu Dec 18 20:02:40 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 18 Dec 2008 20:02:40 +0100 (CET)
Subject: [R-sig-Geo] dummies and multicollinearity in lagsarlm
In-Reply-To: <516dbff70812180716o3b964cb5t888c536deb6f1dc8@mail.gmail.com>
References: <516dbff70812180118n5439ccx258d9e9ebc0b4008@mail.gmail.com>
	<alpine.LRH.2.00.0812181353320.13292@reclus.nhh.no>
	<516dbff70812180716o3b964cb5t888c536deb6f1dc8@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0812181953080.14638@reclus.nhh.no>

On Thu, 18 Dec 2008, Annachiara Saguatti wrote:

> Since I want to obtain a common spatial autoregressive parameter (rho) is it
> correct to estimate
>
>> lagsarlm(formula= y ~ D1 / (x1+x2+x3) + D2 / (x1+x2+x3) - 1, data=...,
> listw=...)
>
> where D1 and D2 are two complementary dummies?
> Estimating a model with just one of the two returns me the coefficient for
> only one of the two groups of regions, right?

Please read up on factors and formula objects - I suggest Ch 4 of John 
Fox' An R and S-Plus Companion to Applied Regression (Sage, 2002). When 
you have grasped what is going on, try:

D1D2 <- factor(D1+(2*D2))
# maybe with labels= to provide something more informative than just 1 and 2

and

y ~ D1D2 / ...

Hope this helps,

Roger

>
> Thanks,
> Annachiara
>
>
> 2008/12/18 Roger Bivand <Roger.Bivand at nhh.no>
>
>> On Thu, 18 Dec 2008, Annachiara Saguatti wrote:
>>
>>  Hello,
>>>
>>> is there a way to estimate a sar model (> lagsarlm) with a dummy variable
>>> in
>>> order to discriminate into two spatial regimes and obtain two different
>>> coefficients' estimations for each variable? So far I've been constructing
>>> two new variables from each original one by multiplicating it by each
>>> dummy,
>>> that is: GPC*D1 and GDP*D2. After that I've been running a regression by
>>> using the two new variables as explanatory v.
>>> Since the two dummies are perfecly complementary, I guess there might be a
>>> problem of multicollinearity in this way of estimating the model. Is there
>>> an option like the "subset" one in the "lm" function which I can use in a
>>> SAR model? Or otherwise, how would you estimate a SAR model with two
>>> spatial
>>> regimes in R?
>>>
>>
>> This is one of the strengths of the formula abstraction. Dummies are not
>> needed, just a factor. The notation would be something like:
>>
>> formula=y ~ factor / (x1 + x2 + x3 + ...) - 1, data=...
>>
>> with / using the factor to fit coefficients of the xi for each level of
>> factor, and -1 removing a global intercept, so giving an intercept for each
>> level of factor. The Chow test is then anova() of the model without factor /
>> ... -1 against the model with it.
>>
>> Hope this helps,
>>
>> Roger
>>
>>
>>
>>> Thank you
>>> Annachiara Saguatti
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From jloehrke at umassd.edu  Thu Dec 18 20:38:36 2008
From: jloehrke at umassd.edu (Jon Loehrke)
Date: Thu, 18 Dec 2008 14:38:36 -0500
Subject: [R-sig-Geo] shortest realistic distance for fish travel
Message-ID: <CB6FB9A0-C735-4797-9F3D-D23F088A49EA@umassd.edu>

Hi,

	I am trying to find an algorithm or thoughts on approach for how to  
compute the shortest realistic distance between two points.  I define  
shortest realistic distance as the shortest distance between two  
points that a fish (which is what I study) could move through.  Hence  
the path must wrap around land, islands, archipelagos, etc.

Point 1

41.15  	N
71.26 	W

Point 2

42.17  	N
70.37 	W

	I'm sure this issue has come up with the geo-statistical community,  
but simply need a starting direction.

Thank much and happy holidays.

Jon Loehrke
Graduate Research Assistant
Department of Fisheries Oceanography
School for Marine Science and Technology
University of Massachusetts
200 Mill Road, Suite 325
Fairhaven, MA 02719
jloehrke at umassd.edu
T 508-910-6393
F 508-910-6396



From sarah.goslee at gmail.com  Thu Dec 18 20:45:16 2008
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 18 Dec 2008 14:45:16 -0500
Subject: [R-sig-Geo] shortest realistic distance for fish travel
In-Reply-To: <CB6FB9A0-C735-4797-9F3D-D23F088A49EA@umassd.edu>
References: <CB6FB9A0-C735-4797-9F3D-D23F088A49EA@umassd.edu>
Message-ID: <efb536d50812181145x5c3e2872o215763313140565b@mail.gmail.com>

Hi,

That sounds like a least-cost path problem.

Sarah

On Thu, Dec 18, 2008 at 2:38 PM, Jon Loehrke <jloehrke at umassd.edu> wrote:
> Hi,
>
>        I am trying to find an algorithm or thoughts on approach for how to
> compute the shortest realistic distance between two points.  I define
> shortest realistic distance as the shortest distance between two points that
> a fish (which is what I study) could move through.  Hence the path must wrap
> around land, islands, archipelagos, etc.
>


-- 
Sarah Goslee
http://www.functionaldiversity.org



From debeaudette at ucdavis.edu  Thu Dec 18 20:52:10 2008
From: debeaudette at ucdavis.edu (Dylan Beaudette)
Date: Thu, 18 Dec 2008 11:52:10 -0800
Subject: [R-sig-Geo] shortest realistic distance for fish travel
In-Reply-To: <CB6FB9A0-C735-4797-9F3D-D23F088A49EA@umassd.edu>
References: <CB6FB9A0-C735-4797-9F3D-D23F088A49EA@umassd.edu>
Message-ID: <200812181152.10875.dylan.beaudette@gmail.com>

On Thursday 18 December 2008, Jon Loehrke wrote:
> Hi,
>
> 	I am trying to find an algorithm or thoughts on approach for how to
> compute the shortest realistic distance between two points.  I define
> shortest realistic distance as the shortest distance between two
> points that a fish (which is what I study) could move through.  Hence
> the path must wrap around land, islands, archipelagos, etc.
>
> Point 1
>
> 41.15  	N
> 71.26 	W
>
> Point 2
>
> 42.17  	N
> 70.37 	W
>
> 	I'm sure this issue has come up with the geo-statistical community,
> but simply need a starting direction.
>
> Thank much and happy holidays.

Hi,

This isn't a geo-statistics approach, but simple cost-surface algorithms 
should be able to do this without too much work.

An example in GRASS:

http://casoilresource.lawr.ucdavis.edu/drupal/node/544

You could make the non-water regions a 'really high' static cost, such that 
finding the least-cost path would be constrained to water.

Cheers,

Dylan




> Jon Loehrke
> Graduate Research Assistant
> Department of Fisheries Oceanography
> School for Marine Science and Technology
> University of Massachusetts
> 200 Mill Road, Suite 325
> Fairhaven, MA 02719
> jloehrke at umassd.edu
> T 508-910-6393
> F 508-910-6396
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341



From nikko at hailmail.net  Thu Dec 18 20:57:41 2008
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Thu, 18 Dec 2008 11:57:41 -0800
Subject: [R-sig-Geo]  shortest realistic distance for fish travel
Message-ID: <1229630261.7606.1290802883@webmail.messagingengine.com>

Hi,
You are talking about network distances. One approach would be to 
label all your source areas as nodes, and then create a series of way
point
nodes. From this you can build a graph that connects all source
populations with each other
and then run the all shortest path algorithm to find the most likely
routes. 

another approach would be to define your landscape as a grid, where each
cell has a cost to pass through,and landmasses are set to infinity.
Again 
connect each cell with its neighbors, and find the shortest path between
any two points.

Hope this helps

Nicholas


--------------------------------
Hi,

	I am trying to find an algorithm or thoughts on approach for how to  
compute the shortest realistic distance between two points.  I define  
shortest realistic distance as the shortest distance between two  
points that a fish (which is what I study) could move through.  Hence  
the path must wrap around land, islands, archipelagos, etc.

Point 1

41.15   N
71.26   W

Point 2

42.17   N
70.37   W

	I'm sure this issue has come up with the geo-statistical community,  
but simply need a starting direction.

Thank much and happy holidays.



From acoffin at ufl.edu  Thu Dec 18 21:16:51 2008
From: acoffin at ufl.edu (Alisa Coffin)
Date: Thu, 18 Dec 2008 15:16:51 -0500
Subject: [R-sig-Geo] shortest realistic distance for fish travel
In-Reply-To: <CB6FB9A0-C735-4797-9F3D-D23F088A49EA@umassd.edu>
References: <CB6FB9A0-C735-4797-9F3D-D23F088A49EA@umassd.edu>
Message-ID: <bb61ce440812181216j790965cbn752c3247b4293538@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081218/e86d4157/attachment.pl>

From J.vanEtten at cgiar.org  Thu Dec 18 21:49:09 2008
From: J.vanEtten at cgiar.org (van Etten, Jacob (IRRI))
Date: Fri, 19 Dec 2008 04:49:09 +0800
Subject: [R-sig-Geo] shortest realistic distance for fish travel
References: <CB6FB9A0-C735-4797-9F3D-D23F088A49EA@umassd.edu>
	<bb61ce440812181216j790965cbn752c3247b4293538@mail.gmail.com>
Message-ID: <AFBF317E3DEC0B43BF750B4618EBFA0D793993@HERMES>

You could also look at "resistance distance" (open-source software available at http://www.circuitscape.org/) if your fish travel as random-walkers.

Jacob van Etten

-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Alisa Coffin
Sent: Fri 19/12/2008 04:16
To: Jon Loehrke
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] shortest realistic distance for fish travel
 
Jon,

You could tackle it using a raster-based least-cost path analysis as was
suggested. For that you will need a data layer at the appropriate resolution
to serve as a cost surface. I would expect it to contain at least
bathymetry, but possibly other variables as well, depending on what the
critter considers a more or less costly way to move (e.g. seagrass density,
currents, etc.).

If you had a network of origins and destinations, you could approach it as a
shortest-path network problem. The only R module I'm familiar with for
network analysis is igraph, which I have used to calculate the shortest
(topological) path from point 1 to point 2 within a network graph.

Alisa.

On Thu, Dec 18, 2008 at 2:38 PM, Jon Loehrke <jloehrke at umassd.edu> wrote:

> Hi,
>
>        I am trying to find an algorithm or thoughts on approach for how to
> compute the shortest realistic distance between two points.  I define
> shortest realistic distance as the shortest distance between two points that
> a fish (which is what I study) could move through.  Hence the path must wrap
> around land, islands, archipelagos, etc.
>
> Point 1
>
> 41.15   N
> 71.26   W
>
> Point 2
>
> 42.17   N
> 70.37   W
>
>        I'm sure this issue has come up with the geo-statistical community,
> but simply need a starting direction.
>
> Thank much and happy holidays.
>
> Jon Loehrke
> Graduate Research Assistant
> Department of Fisheries Oceanography
> School for Marine Science and Technology
> University of Massachusetts
> 200 Mill Road, Suite 325
> Fairhaven, MA 02719
> jloehrke at umassd.edu
> T 508-910-6393
> F 508-910-6396
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


-- 
Alisa Coffin, PhD. Candidate
Department of Geography
University of Florida
Gainesville, FL  32611

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From Roger.Bivand at nhh.no  Thu Dec 18 22:05:16 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 18 Dec 2008 22:05:16 +0100 (CET)
Subject: [R-sig-Geo] Trouble with Durbin Model
In-Reply-To: <49454f05.345.2da2.1574585962@primal.ucdavis.edu>
References: <49454f05.345.2da2.1574585962@primal.ucdavis.edu>
Message-ID: <alpine.LRH.2.00.0812182154530.14638@reclus.nhh.no>

On Sun, 14 Dec 2008, adjemian wrote:

> Hey everyone,
>
> I'm puzzled about a recent result, and I'm wondering if
> anyone can help explain it.  Essentially, I have a set of
> data that is positively spatially autocorrelated (Moran's I
> is highly significant).

You mean that the residuals in a *null* model show spatial 
autocorrelation, but do you know the "real" data generating process?

> According to LM tests on the OLS
> residuals, I find that the spatial lag model is preferred.

That is for the chosen covariates and spatial weights - but could be 
misled by the choice of variables wrt. the "real" data generation process 
(and/or the weights).

> After estimating the lag specification with a group of
> covariates, the spatial parameter is positive and
> significant at the 1% level.  This indicates that the
> spatial clustering in the dependent variable is robust to
> the potential confounding influence of the covariates.
>

This is an overly strong assertion, isn't it? Could there be relevant 
omitted covariates? Could there be omitted case weights and/or 
heteroskedasticity, or other misspecification?

> However, when I estimate the spatial Durbin specification by
> including a set of distanced covariates, the spatial
> parameter is still significant, but with the *opposite*
> sign.  Something that may be of interest: the errors of the
> lag model are not spatially autocorrelated; while the errors
> of the Durbin model are.
>
> I wonder why the sign of spatial influence flips.  Has
> anybody faced a similar situation?  How should I select the
> proper model?

It does look as though the model is misspecified as it stands. The Spatial 
Durbin is more general - does comparing the AIC values say anything? If 
the Spatial Durbin fits "better" for a chosen criterion, then it looks 
like a missing variable or equivalently inappropriate functional form in 
one of the covariates.

Sorry not to be more help,

Roger

>
> Software used: Geoda, R.
>
> Thanks!
> Mike
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Maxime.Pauwels at univ-lille1.fr  Fri Dec 19 12:07:17 2008
From: Maxime.Pauwels at univ-lille1.fr (Maxime Pauwels)
Date: Fri, 19 Dec 2008 12:07:17 +0100
Subject: [R-sig-Geo] cutting in spplot
Message-ID: <494B8065.2080400@univ-lille1.fr>

Dear all,

I have a little problem using sppplot that may be easy to resolve for
some of you.
I work with a data frame called "rthrshldrange.txt" including 3
variables: thrshldrange.lat, thrshldrange.long and an attribute, "gridr"

rrange=read.table("rthrshldrange.txt", header=T)
head(rrange)
# thrshldrange.lat thrshldrange.long gridr
#1 54.66292 22.463592 -0.38001696
#2 44.55056 6.888350 0.38050517
#3 45.22472 15.262136 -0.01351420
#4 54.49438 8.898058 0.06822382
#5 48.76404 17.104369 -0.29690619
#6 54.83146 21.123786 -0.39500770

range(rrange$gridr)
#[1] -0.4009798 0.3823646/

After reading, the data.frame is gridded to be able to draw items
afterwards using sp.layout

coordinates(rrange)=~thrshldrange.long+thrshldrange.lat
gridded(rrange)=TRUE
#Warning messages:
#1: In points2grid(points, tolerance, round, fuzz.tol) :
# grid has empty column/rows in dimension 1
#2: In points2grid(points, tolerance, round, fuzz.tol) :
# grid has empty column/rows in dimension 2

Warning messages are not, I guess, a real problem.
spplot function works pretty well when I use a numerical value for the
argument cuts, e.g. cuts=100

spplot(rrange, scales=list(draw=T), xlim=c(-5, 30), ylim=c(40, 60),
xlab = "longitude (dec.)", ylab="latitude(dec.)",cuts=100,
col.regions=grey(1:200/200))

However, I'd like to impose the range of cutting (e.g. from -1 to 1) to
have the same range in different plots using different data with
different ranges for the gridr variable.
I tried:

spplot(rrange, scales=list(draw=T), xlim=c(-5, 30), ylim=c(40, 60),
xlab = "longitude (dec.)", ylab="latitude(dec.)",cuts=c(-1, -0.5, 0,
0.5, 1), col.regions=grey(1:200/200))/

and had the following error message:

Erreur dans cut.default(x, at, include.lowest = TRUE, labels = FALSE) :
nombre d'intervalles incorrect
De plus : Warning messages:
1: In if (length.out == 0) integer(0) else if (One) 1:length.out else if
(missing(by)) { :
la condition a une longueur > 1 et seul le premier ?l?ment est utilis?
2: In if (length.out > 2) if (from == to) rep.int(from, length.out) else
as.vector(c(from, :
la condition a une longueur > 1 et seul le premier ?l?ment est utilis?
3: In 1:length.out :
l'expression num?rique a 5 ?l?ments : seul le premier est utilis?/

What I understand is that my solution clearly doesn't work... But I have
no alternative yet...

Could anyone help?

Many thanks and Merry Xmas

Best regards,

max


-- 
Maxime Pauwels
Post-Doc
Laboratoire de G?n?tique et Evolution des Populations V?g?tales
UMR CNRS 8016
Batiment SN2			Tel  : +33 3 20 43 40 76
Universite de LILLE 1		Fax  : +33 3 20 43 69 79
59655 Villeneuve d'Ascq Cedex	email: maxime.pauwels at univ-lille1.fr
FRANCE				http://www.univ-lille1.fr/gepv

?Impose ta chance, serre ton bonheur et va vers ton risque. A te 
regarder, ils s?habitueront.?
Ren? Char



From annachiara.saguatti at gmail.com  Mon Dec 22 18:33:46 2008
From: annachiara.saguatti at gmail.com (Annachiara Saguatti)
Date: Mon, 22 Dec 2008 18:33:46 +0100
Subject: [R-sig-Geo] spatial error model and spatial regimes
Message-ID: <516dbff70812220933n24b35e5sd8d2d0ca748cd2b8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081222/01426462/attachment.pl>

From annachiara.saguatti at gmail.com  Mon Dec 22 18:58:09 2008
From: annachiara.saguatti at gmail.com (Annachiara Saguatti)
Date: Mon, 22 Dec 2008 18:58:09 +0100
Subject: [R-sig-Geo] spatial error model and spatial regimes
In-Reply-To: <516dbff70812220933n24b35e5sd8d2d0ca748cd2b8@mail.gmail.com>
References: <516dbff70812220933n24b35e5sd8d2d0ca748cd2b8@mail.gmail.com>
Message-ID: <516dbff70812220958p6753cf8cs3f9c8f5ca1c71dcf@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081222/5042add2/attachment.pl>

From Alexander.Herr at csiro.au  Tue Dec 23 01:40:56 2008
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Tue, 23 Dec 2008 11:40:56 +1100
Subject: [R-sig-Geo] writing tiff file by row {raster}
In-Reply-To: <mailman.7.1229770803.5728.r-sig-geo@stat.math.ethz.ch>
References: <mailman.7.1229770803.5728.r-sig-geo@stat.math.ethz.ch>
Message-ID: <D6D8CB3DE7413A44BD15BF7D78C960C3010090BED7@EXNSW-MBX04.nexus.csiro.au>

Hi List,

I can write out ascii grids by row (see below), but I can't figure out how to do this in say compressed geotiff or another compressed lossless format readable by ESRI.

require(rgdal)
require(raster)
# read and write row by row; write to ascii file
 rs <- raster.from.file(system.file("external/test.ag", package="sp"))
  #rs <- setNA(rs, operator ="<=", value=0)
 ascrow <- set.filename(rs, "ascrow.asc")
 for (r in 1:nrow(rs)) {
        rs <- readRow(rs, r)
          #rs <- setNA(rs, operator ="<", value=10)
         print(paste(nrow(rs)+1 - r, " rows to go"))
           vals<-values(rs)/4
           vals[values(rs)<=500]<-NA
          
        ascrow <- set.values.row(ascrow, vals, r)
        ascrow <- write.ascii(ascrow, overwrite=TRUE) 
 }

Any hints appreciated

Thanx
Herry


From Alexander.Herr at csiro.au  Tue Dec 23 23:00:46 2008
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Wed, 24 Dec 2008 09:00:46 +1100
Subject: [R-sig-Geo] writing tiff file by row {raster}
In-Reply-To: <dc22b2570812230827g4bb2e07cq64de18423954feed@mail.gmail.com>
References: <mailman.7.1229770803.5728.r-sig-geo@stat.math.ethz.ch>
	<D6D8CB3DE7413A44BD15BF7D78C960C3010090BED7@EXNSW-MBX04.nexus.csiro.au>
	<dc22b2570812230827g4bb2e07cq64de18423954feed@mail.gmail.com>
Message-ID: <D6D8CB3DE7413A44BD15BF7D78C960C3010090BEDC@EXNSW-MBX04.nexus.csiro.au>

Thanks Robert

Yes, I do work with real numbers. So easiest format for simple grids I'd guess is geotiff or something more complicated for bands. 

I really only need a compressed format for mapping the grid (and saving disk space) and I would guess that people would not (could not) process large grids (above 32bit windows limitation, around 3-4gig depending on setup) in Arc, so even a compressed read only format that Arc supports would do (see http://webhelp.esri.com/arcgisdesktop/9.3/index.cfm?tocVisable=0&ID=3027&TopicName=Supported%20raster%20dataset%20file%20formats&pid=3026).

Cheers
Herry

-----Original Message-----
From: Robert Hijmans [mailto:r.hijmans at gmail.com] 
Sent: Wednesday, December 24, 2008 3:27 AM
To: Herr, Alexander Herr - Herry (CSE, Gungahlin)
Subject: Re: [R-sig-Geo] writing tiff file by row {raster}

Alexander, 

I added a function "grdToBil" to the raster package. It may take 24 hours or so before it is available in the compiled package on R-forge, after that you can get it via
  install.packages("raster",repos="http://R-Forge.R-project.org")

The below example, adjusted from yours, works for me. That is, the raster package creates a GRD file, row by row, and when it is done it exports it to a BIL file using the new function. In R I can read that file (via rgdal).  Whether ArcMap can read this file is another matter (I do not have access to ArcMap right now). Arc-* used to (and perhaps still does) assume that BIL files have unsigned integer values. Thus, if your data are real numbers and/or include negative numbers you might have trouble with reading the exported BIL file in ArcMap. Perhaps you need to round the numbers. The negative number can sometimes be solved with a calculation in Arc (in command line ArcInfo, with a statement like  newgrid = con(oldgrid >= 32768, oldgrid - 65536, newgrid) I will look into a less error prone binary format that ArcMap can read; perhaps Erdas IMG. Suggestions anyone? 

require(raster)
# read and write row by row; write to binary file rs <- raster.from.file(system.file("external/test.ag", package="sp")) binrow <- set.filename(rs, "binrow.grd") for (r in 1:nrow(rs)) {
    rs <- readRow(rs, r)
#   print(paste(nrow(rs)+1 - r, " rows to go"))
    vals<-values(rs)/4
    vals[values(rs)<=500]<-NA
# perhaps you need to add something like the following two lines for your data
#    vals <- round(vals)
#    binrow <- set.datatype(binrow, "integer")
    binrow <- set.values.row(binrow, vals, r)
    binrow <- write.row(binrow, overwrite=TRUE) } # bilraster has not been documented yet # it exports a binary raster to a bil file bilrs <- grdToBil(binrow, keepGRD = TRUE, overwrite = TRUE)

# to show that it worked
raster.map(rs, col=topo.colors(25))
windows()
raster.map(bilrs, col=topo.colors(25))

 
Cheers, Robert


On Tue, Dec 23, 2008 at 8:40 AM, <Alexander.Herr at csiro.au> wrote:


	Hi List,
	
	I can write out ascii grids by row (see below), but I can't figure out how to do this in say compressed geotiff or another compressed lossless format readable by ESRI.
	
	require(rgdal)
	require(raster)
	# read and write row by row; write to ascii file
	 rs <- raster.from.file(system.file("external/test.ag", package="sp"))
	 #rs <- setNA(rs, operator ="<=", value=0)
	 ascrow <- set.filename(rs, "ascrow.asc")
	 for (r in 1:nrow(rs)) {
	       rs <- readRow(rs, r)
	         #rs <- setNA(rs, operator ="<", value=10)
	        print(paste(nrow(rs)+1 - r, " rows to go"))
	          vals<-values(rs)/4
	          vals[values(rs)<=500]<-NA
	
	       ascrow <- set.values.row(ascrow, vals, r)
	       ascrow <- write.ascii(ascrow, overwrite=TRUE)
	 }
	
	Any hints appreciated
	
	Thanx
	Herry
	_______________________________________________
	R-sig-Geo mailing list
	R-sig-Geo at stat.math.ethz.ch
	https://stat.ethz.ch/mailman/listinfo/r-sig-geo
	



From r.hijmans at gmail.com  Wed Dec 24 15:52:16 2008
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Wed, 24 Dec 2008 22:52:16 +0800
Subject: [R-sig-Geo] writing tiff file by row {raster}
In-Reply-To: <D6D8CB3DE7413A44BD15BF7D78C960C3010090BEDC@EXNSW-MBX04.nexus.csiro.au>
References: <mailman.7.1229770803.5728.r-sig-geo@stat.math.ethz.ch>
	<D6D8CB3DE7413A44BD15BF7D78C960C3010090BED7@EXNSW-MBX04.nexus.csiro.au>
	<dc22b2570812230827g4bb2e07cq64de18423954feed@mail.gmail.com>
	<D6D8CB3DE7413A44BD15BF7D78C960C3010090BEDC@EXNSW-MBX04.nexus.csiro.au>
Message-ID: <dc22b2570812240652t149c30eeg1fd1f6b1845d95a5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081224/bf3fd934/attachment.pl>

From jloehrke at umassd.edu  Wed Dec 24 19:01:55 2008
From: jloehrke at umassd.edu (Jon Loehrke)
Date: Wed, 24 Dec 2008 13:01:55 -0500
Subject: [R-sig-Geo] adding a background shape to ssplot
Message-ID: <9D4F31B6-13C3-432C-9369-EC824F4F1A4C@umassd.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081224/5269177e/attachment.pl>

From axelanne at msu.edu  Wed Dec 24 21:58:36 2008
From: axelanne at msu.edu (Anne Axel)
Date: Wed, 24 Dec 2008 15:58:36 -0500
Subject: [R-sig-Geo] how to export results of predict.randomForest
Message-ID: <200812242058.mBOKwkSD013412@hypatia.math.ethz.ch>

Hi List,

I am requesting help with exporting results from the 
predict.randomForest function.  This is my first attempt at working 
with spatial data in R--I was able to import the data and run the 
randomForest model, but I cannot figure out how to export the data 
for use in ArcGIS or ENVI.

I've pasted below the code I used for randomForest and exporting of 
results.  If anyone has suggestions, I would be eternally 
grateful!  Thanks, and Happy Holidays.

Anne Axel


Department of Fisheries and Wildlife
Michigan State University
20 Natural Resources Building
East Lansing, MI 48824 USA
517-930-2248
axelanne at msu.edu


####Read in *img file with 55 bands
bands=readGDAL("multibands3.img")
imgtabla <- as(bands, "data.frame")

######Read in training data and run randomForest
data=read.csv("bandnumsOutput_cond2.csv", header=TRUE)
data2=data[,1:58]
data.rf=randomForest(COVERTYPE~ ., data=data2, mtry=16, importance = 
TRUE, do.trace=100)
print(data.rf)
output=predict(data.rf, imgtabla)

#### I've tried numerous ways of exporting the data, but I don't seem 
to have the data in a format that's acceptable to the functions. In 
addition, I've tried to coerce data into other formats, but nothing 
has worked.  Any suggestions?


 > writeGDAL(bands, output, drivername = "GTiff", type = "Float32", 
mvFlag = NA, options=NULL)
Error in .local(.Object, ...) :
   STRING_ELT() can only be applied to a 'character vector', not a 'integer'
In addition: Warning messages:
1: In if (nchar(fname) == 0) stop("empty file name") :
   the condition has length > 1 and only the first element will be used
2: In if (nchar(filename) == 0) stop("empty file name") :
   the condition has length > 1 and only the first element will be used

 > writeGDAL(output, bands, drivername = "GTiff", type = "Float32", 
mvFlag = NA, options=NULL)
Error in nchar(fname) : cannot coerce type S4 to character vector

 > write.ENVI(output)
Error in dim(X) = c(nRow, nCol, nBand) : length-0 dimension vector is invalid

 > write.ascii.grid(output, "output", header = NULL, write.header = TRUE)
Error: is.matrix(data) is not TRUE





Anne C. Axel
Department of Fisheries and Wildlife
Michigan State University
20 Natural Resources Building
East Lansing, MI 48824 USA
517-930-2248
axelanne at msu.edu



From axelanne at msu.edu  Thu Dec 25 19:01:43 2008
From: axelanne at msu.edu (Anne Axel)
Date: Thu, 25 Dec 2008 13:01:43 -0500
Subject: [R-sig-Geo] how to export results of predict.randomForest
In-Reply-To: <dc22b2570812241802h686e727bo3d7ad131c014d1d6@mail.gmail.co
 m>
References: <200812242058.mBOKwkSD013412@hypatia.math.ethz.ch>
	<dc22b2570812241802h686e727bo3d7ad131c014d1d6@mail.gmail.com>
Message-ID: <200812251801.mBPI1pH1004878@hypatia.math.ethz.ch>

Hi Robert and list,

Thanks so much for the Christmas message!  I tried your great 
suggestion and I got the following error:

 > spgrid <- SpatialGridDataFrame(bands, output)
Error in rbind(grid at cellcentre.offset, grid at cellcentre.offset + 
(grid at cells.dim -  :
   no slot of name "cellcentre.offset" for this object of class 
"SpatialGridDataFrame"

So, I examined the structure of both files (see below). In addition, 
there are no NAs in "imgtabla" or "bands", but there are NAs in the 
rf.prediction ("output").

I tried to  writeGDAL(bands, "test2.tif") and this worked without any 
errors.  Could it have something to do with the fact that my output 
is of class factor?

Again, thanks Robert,  for setting me on the right path.  Any other 
suggestions out there to clear this last hurdle?

Best,
Anne Axel

 > str(bands)
Formal class 'SpatialGridDataFrame' [package "sp"] with 6 slots
   ..@ data       :'data.frame': 163982 obs. of  55 variables:
   .. ..$ band1 : num [1:163982] 0 0 0 0 0 0 0 0 0 0 ...
   .. ..
   ..@ grid       :Formal class 'GridTopology' [package "sp"] with 3 slots
   .. .. ..@ cellcentre.offset: Named num [1:2] 0.5 0.5
   .. .. .. ..- attr(*, "names")= chr [1:2] "x" "y"
   .. .. ..@ cellsize         : num [1:2] 1 1
   .. .. ..@ cells.dim        : int [1:2] 442 371
   ..@ grid.index : int(0)
   ..@ coords     : num [1:2, 1:2]   0.5 441.5   0.5 370.5
   .. ..- attr(*, "dimnames")=List of 2
   .. .. ..$ : NULL
   .. .. ..$ : chr [1:2] "x" "y"
   ..@ bbox       : num [1:2, 1:2] 0 0 442 371
   .. ..- attr(*, "dimnames")=List of 2
   .. .. ..$ : chr [1:2] "x" "y"
   .. .. ..$ : chr [1:2] "min" "max"
   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
   .. .. ..@ projargs: chr " +proj=utm +zone=38 +south +a=6378137 
+datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0"

 > str(output)
  Factor w/ 4 levels "dry","gallery",..: 3 3 3 3 3 3 3 3 3 3 ...


 > class(bands)
[1] "SpatialGridDataFrame"
attr(,"package")
[1] "sp"


 > class(output)
[1] "factor"

 > summary(output)
       dry   gallery notforest     spiny      NA's
     33009      5878    103772     21315         8









At 12/24/2008 09:02 PM, you wrote:
>Hi Anne,
>
>The first argument of writeGDAL is "an object of class 
>SpatialGridDataFrame-class or SpatialPixelsDataFrame-class"
>So you need to create a new SpatialGridDataFrame with the spatial 
>properties of "multibands3.img" and with the RandomForest 
>predictions ("output"). Note that there are some additional 
>complications when there are NAs in your predictors (i.e. in 
>"imgtabla"), but if there are none, I think that something like this 
>might work:
>
>spgrid <- SpatialGridDataFrame(bands, output)
>writeGDAL(spgrid, "rf_results.tif")
>
>Robert
>
>On Thu, Dec 25, 2008 at 4:58 AM, Anne Axel 
><<mailto:axelanne at msu.edu>axelanne at msu.edu> wrote:
>Hi List,
>
>I am requesting help with exporting results from the 
>predict.randomForest function.  This is my first attempt at working 
>with spatial data in R--I was able to import the data and run the 
>randomForest model, but I cannot figure out how to export the data 
>for use in ArcGIS or ENVI.
>
>I've pasted below the code I used for randomForest and exporting of 
>results.  If anyone has suggestions, I would be eternally 
>grateful!  Thanks, and Happy Holidays.
>
>Anne Axel
>
>
>Department of Fisheries and Wildlife
>Michigan State University
>20 Natural Resources Building
>East Lansing, MI 48824 USA
>517-930-2248
><mailto:axelanne at msu.edu>axelanne at msu.edu
>
>
>####Read in *img file with 55 bands
>bands=readGDAL("multibands3.img")
>imgtabla <- as(bands, "data.frame")
>
>######Read in training data and run randomForest
>data=read.csv("bandnumsOutput_cond2.csv", header=TRUE)
>data2=data[,1:58]
>data.rf=randomForest(COVERTYPE~ ., data=data2, mtry=16, importance = 
>TRUE, do.trace=100)
>print(data.rf)
>output=predict(data.rf, imgtabla)
>
>#### I've tried numerous ways of exporting the data, but I don't 
>seem to have the data in a format that's acceptable to the 
>functions. In addition, I've tried to coerce data into other 
>formats, but nothing has worked.  Any suggestions?
>
>
> > writeGDAL(bands, output, drivername = "GTiff", type = "Float32", 
> mvFlag = NA, options=NULL)
>Error in .local(.Object, ...) :
>  STRING_ELT() can only be applied to a 'character vector', not a 'integer'
>In addition: Warning messages:
>1: In if (nchar(fname) == 0) stop("empty file name") :
>  the condition has length > 1 and only the first element will be used
>2: In if (nchar(filename) == 0) stop("empty file name") :
>  the condition has length > 1 and only the first element will be used
>
> > writeGDAL(output, bands, drivername = "GTiff", type = "Float32", 
> mvFlag = NA, options=NULL)
>Error in nchar(fname) : cannot coerce type S4 to character vector
>
> > write.ENVI(output)
>Error in dim(X) = c(nRow, nCol, nBand) : length-0 dimension vector is invalid
>
> > write.ascii.grid(output, "output", header = NULL, write.header = TRUE)
>Error: is.matrix(data) is not TRUE
>
>
>
>
>
>Anne C. Axel
>Department of Fisheries and Wildlife
>Michigan State University
>20 Natural Resources Building
>East Lansing, MI 48824 USA
>517-930-2248
><mailto:axelanne at msu.edu>axelanne at msu.edu
>
>_______________________________________________
>R-sig-Geo mailing list
><mailto:R-sig-Geo at stat.math.ethz.ch>R-sig-Geo at stat.math.ethz.ch
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

" Know your own bone. Gnaw at it, bury it, unearth it, and gnaw it still."
         -Henry David Thoreau

"Outside of a dog, a book is a man's best friend. Inside of a dog, 
it's too dark to read."
         - Groucho Marx

Anne C. Axel
Department of Fisheries and Wildlife
Michigan State University
20 Natural Resources Building
East Lansing, MI 48824 USA
517-930-2248
axelanne at msu.edu



From edzer.pebesma at uni-muenster.de  Fri Dec 26 12:20:44 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 26 Dec 2008 12:20:44 +0100
Subject: [R-sig-Geo] adding a background shape to ssplot
In-Reply-To: <9D4F31B6-13C3-432C-9369-EC824F4F1A4C@umassd.edu>
References: <9D4F31B6-13C3-432C-9369-EC824F4F1A4C@umassd.edu>
Message-ID: <4954BE0C.2040502@uni-muenster.de>

Jon Loehrke wrote:
> Greetings and Happy Holidays!
>
>
>   
...
> #However I can seem to pass the polygon colors argument through spplot
> spplot(nc1, c("f","g"), col.regions=brewer.pal(10, "Set3"),  
> scales=list(draw = TRUE),
> 	panel=function(...) {
> 		panel.mapper()
> 		sp.polygons(nc1)
> 		}
> 	)	
>
>   
A better panel function would be this:

spplot(nc1, c("f","g"), # col.regions=brewer.pal(10, "Set3"),
scales=list(draw = TRUE),
	panel=function(...) {
		panel.mapper()
		panel.polygonsplot(...)
		}
	)	


see

getMethod("spplot", "SpatialPolygonsDataFrame")

to find out how the appropriate spplot method does it.

I am worried, however, about the absence of the last 5 colors and factor
levels f-j.
--
Edzer



From edzer.pebesma at uni-muenster.de  Fri Dec 26 12:26:29 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 26 Dec 2008 12:26:29 +0100
Subject: [R-sig-Geo] how to export results of predict.randomForest
In-Reply-To: <200812251801.mBPI1pH1004878@hypatia.math.ethz.ch>
References: <200812242058.mBOKwkSD013412@hypatia.math.ethz.ch>	<dc22b2570812241802h686e727bo3d7ad131c014d1d6@mail.gmail.com>
	<200812251801.mBPI1pH1004878@hypatia.math.ethz.ch>
Message-ID: <4954BF65.1060404@uni-muenster.de>

I might have missed something obvious, but did you try something like

bands$randomForest = output
spplot(bands, "randomForest")

?
--
Edzer


Anne Axel schrieb:
> Hi Robert and list,
>
> Thanks so much for the Christmas message!  I tried your great 
> suggestion and I got the following error:
>
> > spgrid <- SpatialGridDataFrame(bands, output)
> Error in rbind(grid at cellcentre.offset, grid at cellcentre.offset + 
> (grid at cells.dim -  :
>   no slot of name "cellcentre.offset" for this object of class 
> "SpatialGridDataFrame"
>
> So, I examined the structure of both files (see below). In addition, 
> there are no NAs in "imgtabla" or "bands", but there are NAs in the 
> rf.prediction ("output").
>
> I tried to  writeGDAL(bands, "test2.tif") and this worked without any 
> errors.  Could it have something to do with the fact that my output is 
> of class factor?
>
> Again, thanks Robert,  for setting me on the right path.  Any other 
> suggestions out there to clear this last hurdle?
>
> Best,
> Anne Axel
>
> > str(bands)
> Formal class 'SpatialGridDataFrame' [package "sp"] with 6 slots
>   ..@ data       :'data.frame': 163982 obs. of  55 variables:
>   .. ..$ band1 : num [1:163982] 0 0 0 0 0 0 0 0 0 0 ...
>   .. ..
>   ..@ grid       :Formal class 'GridTopology' [package "sp"] with 3 slots
>   .. .. ..@ cellcentre.offset: Named num [1:2] 0.5 0.5
>   .. .. .. ..- attr(*, "names")= chr [1:2] "x" "y"
>   .. .. ..@ cellsize         : num [1:2] 1 1
>   .. .. ..@ cells.dim        : int [1:2] 442 371
>   ..@ grid.index : int(0)
>   ..@ coords     : num [1:2, 1:2]   0.5 441.5   0.5 370.5
>   .. ..- attr(*, "dimnames")=List of 2
>   .. .. ..$ : NULL
>   .. .. ..$ : chr [1:2] "x" "y"
>   ..@ bbox       : num [1:2, 1:2] 0 0 442 371
>   .. ..- attr(*, "dimnames")=List of 2
>   .. .. ..$ : chr [1:2] "x" "y"
>   .. .. ..$ : chr [1:2] "min" "max"
>   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>   .. .. ..@ projargs: chr " +proj=utm +zone=38 +south +a=6378137 
> +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0"
>
> > str(output)
>  Factor w/ 4 levels "dry","gallery",..: 3 3 3 3 3 3 3 3 3 3 ...
>
>
> > class(bands)
> [1] "SpatialGridDataFrame"
> attr(,"package")
> [1] "sp"
>
>
> > class(output)
> [1] "factor"
>
> > summary(output)
>       dry   gallery notforest     spiny      NA's
>     33009      5878    103772     21315         8
>
>
>
>
>
>
>
>
>
> At 12/24/2008 09:02 PM, you wrote:
>> Hi Anne,
>>
>> The first argument of writeGDAL is "an object of class 
>> SpatialGridDataFrame-class or SpatialPixelsDataFrame-class"
>> So you need to create a new SpatialGridDataFrame with the spatial 
>> properties of "multibands3.img" and with the RandomForest predictions 
>> ("output"). Note that there are some additional complications when 
>> there are NAs in your predictors (i.e. in "imgtabla"), but if there 
>> are none, I think that something like this might work:
>>
>> spgrid <- SpatialGridDataFrame(bands, output)
>> writeGDAL(spgrid, "rf_results.tif")
>>
>> Robert
>>
>> On Thu, Dec 25, 2008 at 4:58 AM, Anne Axel 
>> <<mailto:axelanne at msu.edu>axelanne at msu.edu> wrote:
>> Hi List,
>>
>> I am requesting help with exporting results from the 
>> predict.randomForest function.  This is my first attempt at working 
>> with spatial data in R--I was able to import the data and run the 
>> randomForest model, but I cannot figure out how to export the data 
>> for use in ArcGIS or ENVI.
>>
>> I've pasted below the code I used for randomForest and exporting of 
>> results.  If anyone has suggestions, I would be eternally grateful!  
>> Thanks, and Happy Holidays.
>>
>> Anne Axel
>>
>>
>> Department of Fisheries and Wildlife
>> Michigan State University
>> 20 Natural Resources Building
>> East Lansing, MI 48824 USA
>> 517-930-2248
>> <mailto:axelanne at msu.edu>axelanne at msu.edu
>>
>>
>> ####Read in *img file with 55 bands
>> bands=readGDAL("multibands3.img")
>> imgtabla <- as(bands, "data.frame")
>>
>> ######Read in training data and run randomForest
>> data=read.csv("bandnumsOutput_cond2.csv", header=TRUE)
>> data2=data[,1:58]
>> data.rf=randomForest(COVERTYPE~ ., data=data2, mtry=16, importance = 
>> TRUE, do.trace=100)
>> print(data.rf)
>> output=predict(data.rf, imgtabla)
>>
>> #### I've tried numerous ways of exporting the data, but I don't seem 
>> to have the data in a format that's acceptable to the functions. In 
>> addition, I've tried to coerce data into other formats, but nothing 
>> has worked.  Any suggestions?
>>
>>
>> > writeGDAL(bands, output, drivername = "GTiff", type = "Float32", 
>> mvFlag = NA, options=NULL)
>> Error in .local(.Object, ...) :
>>  STRING_ELT() can only be applied to a 'character vector', not a 
>> 'integer'
>> In addition: Warning messages:
>> 1: In if (nchar(fname) == 0) stop("empty file name") :
>>  the condition has length > 1 and only the first element will be used
>> 2: In if (nchar(filename) == 0) stop("empty file name") :
>>  the condition has length > 1 and only the first element will be used
>>
>> > writeGDAL(output, bands, drivername = "GTiff", type = "Float32", 
>> mvFlag = NA, options=NULL)
>> Error in nchar(fname) : cannot coerce type S4 to character vector
>>
>> > write.ENVI(output)
>> Error in dim(X) = c(nRow, nCol, nBand) : length-0 dimension vector is 
>> invalid
>>
>> > write.ascii.grid(output, "output", header = NULL, write.header = TRUE)
>> Error: is.matrix(data) is not TRUE
>>
>>
>>
>>
>>
>> Anne C. Axel
>> Department of Fisheries and Wildlife
>> Michigan State University
>> 20 Natural Resources Building
>> East Lansing, MI 48824 USA
>> 517-930-2248
>> <mailto:axelanne at msu.edu>axelanne at msu.edu
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> <mailto:R-sig-Geo at stat.math.ethz.ch>R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> " Know your own bone. Gnaw at it, bury it, unearth it, and gnaw it 
> still."
>         -Henry David Thoreau
>
> "Outside of a dog, a book is a man's best friend. Inside of a dog, 
> it's too dark to read."
>         - Groucho Marx
>
> Anne C. Axel
> Department of Fisheries and Wildlife
> Michigan State University
> 20 Natural Resources Building
> East Lansing, MI 48824 USA
> 517-930-2248
> axelanne at msu.edu
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From T.Hengl at uva.nl  Fri Dec 26 15:01:27 2008
From: T.Hengl at uva.nl (Hengl, T.)
Date: Fri, 26 Dec 2008 15:01:27 +0100
Subject: [R-sig-Geo] adding a background shape to ssplot
References: <9D4F31B6-13C3-432C-9369-EC824F4F1A4C@umassd.edu>
Message-ID: <37382E8DCB905042969BA78541F6570624D66B@kwek.ic.uva.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20081226/0bdd1492/attachment.pl>

From katona at statisztikus.hu  Sat Dec 27 22:13:21 2008
From: katona at statisztikus.hu (Katona Lajos)
Date: Sat, 27 Dec 2008 22:13:21 +0100
Subject: [R-sig-Geo] fixed colors in maps
Message-ID: <b72d47fbf2dbcabf33c2919df2b92043@blup.ultimate.hu>

Hi,

I have a proble, can you help me? :-)
I'd like to make lots of maps with spplot with fixed colors and color range. There is in the data the "colors" field or variable which can have fixed value: 1, 2, 3, 4, 5, 6, 7, 8, 9. But in an actual date I have not all value in regions for example only 1, 2, 3. When I see the map I have 3 colors but the fist is 1 (white) the second is 5 (medium) and the third is 9 (dark red) from brewer.pal(9, "Reds"). It is not good for me. I'd like to have other 3 colors. When my "colors" variable is 1 the colors code is 1, when 2 then color code is 2, when 3 then color code is 3 from brewer.pal(9, "Reds"). And the legend near the map is always 9 colors.
It is very imoprtant for me becouse I'd like to make an swf file from 365 jpg image.

data_regions$date_num=as.numeric(data_regions$DATE)
max_date=max(data_regions$date_num)
date_lst=seq(1,max_date)
for(i in date_lst){
   actual_data=subset(data_regions, data_regions$date_num==i)
   actual_date=actual_data[1,]$DATE
   file_name=paste("map_",actual_date,".jpg")
   mapname_colors.sp <- SpatialPolygonsDataFrame(mapname.sp, actual_data[,c(2,8)])
jpeg(filename=file_name, width=1024, height=768, units="px",
 pointsize=12, quality=300, bg="white", res=NA, restoreConsole=TRUE)
spplot(mapname_colors.sp, "colors", col.regions=brewer.pal(9, "Reds"), 
 main="Epidemic, etc.", sub=paste("Timestamp:", actual_date))
dev.off()
}

Thank you!



From moor0554 at umn.edu  Sat Dec 27 22:45:32 2008
From: moor0554 at umn.edu (Christopher Moore)
Date: 27 Dec 2008 15:45:32 -0600
Subject: [R-sig-Geo] Spatial Lags Excluding Neighbors' Missing Attribute
	Values
Message-ID: <Prayer.1.0.16.0812271545320.3701@vs-w.tc.umn.edu>

Greetings,

I am seeking help with creating spatial lags that exclude neighbors with 
missing attribute values. I searched the spdep help documentation and the R 
Sig Geo Archives but was unable to find relevant information. (Please note 
that I posted an R Sig Geo search engine here: 
<http://mycroft.mozdev.org/search-engines.html?name=r+sig+geo>.)

As shown in the example below, the lag.listw function converts missing 
attribute values to zero before calculating the mean of neighbhors' 
attribute values (i.e., the spatial lag).

Do you have any advice for calculating spatial lags so that neighbors with 
missing attribute values are excluded (rather than treated as zero)? 
Alternatively, how might I remove neighbor links when the neighbor is 
missing an attribute value? I would prefer the former approach (exclusion 
from the calculation) because it wouldn't require creating a new neighbor 
list each time a new attribute is analyzed. However, the latter approach 
(editing the neighbor list) seems easier, if only I could get the list into 
a data frame-like object for editing, which I can not figure out how to do.

I would greatly appreciate your help and have provided a reproducible 
example below (see the very bottom of the of the example in particular). 
Please let me know if you need further clarification.

Regards,
Chris

-- 
Christopher Moore, M.P.P.
Doctoral Student
Quantitative Methods in Education
University of Minnesota
moor0554 at umn.edu
http://www.tc.umn.edu/~moor0554/


> ##########
> 
> library(spdep)
> 
> ##process and summarize nc.sids data nc.sids <- 
> readShapePoly(system.file("etc/shapes/sids.shp", package="spdep")[1], 
> ID="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66")) rn <- 
> sapply(slot(nc.sids, "polygons"), function(x) slot(x, "ID")) ncCR85_nb <- 
> read.gal(system.file("etc/weights/ncCR85.gal", package="spdep")[1], 
> region.id=rn) summary(ncCR85_nb, coordinates(nc.sids))
Neighbour list object:
Number of regions: 100 
Number of nonzero links: 492 
Percentage nonzero weights: 4.92 
Average number of links: 4.92 
Link number distribution:

 1  2  3  4  5  6  7  8  9 
 2  6 15 16 23 18 16  2  2 
2 least connected regions:
37053 37055 with 1 link
2 most connected regions:
37097 37125 with 9 links
Summary of link distances:
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.1197  0.3407  0.4018  0.4170  0.4922  0.7843 

  The decimal point is 1 digit(s) to the left of the |

  1 | 22
  1 | 778888888899
  2 | 4444
  2 | 5555555566666666667777778888888888888899999999
  3 | 00000000000000111111111111111111112222222222223333333344444444
  3 | 
55555555555555555555555555555555666666666666666666666677777777777777+26
  4 | 00000000000000000011111111111111111111112222222222222233333333333344
  4 | 55555555555555555566666666667777777777777777888888889999999999
  5 | 00000000111111111122222222222222222233333333334444
  5 | 5555555555556666666666667788888899
  6 | 00111122334444
  6 | 5555557788999999
  7 | 000044
  7 | 88

> wts <- nb2listw(ncCR85_nb)
> str(wts$neighbours)
List of 100
 $ : int [1:6] 17 19 41 68 76 79
 $ : int [1:4] 14 18 49 97
 $ : int [1:3] 5 86 97
 $ : int [1:4] 62 77 84 90
 $ : int [1:3] 3 95 97
 $ : int [1:5] 12 14 56 61 95
 $ : int [1:6] 25 48 59 69 74 94
 $ : int [1:5] 42 46 59 66 94
 $ : int [1:5] 24 26 71 78 82
 $ : int [1:3] 24 65 71
 $ : int [1:7] 44 45 56 58 81 88 100
 $ : int [1:7] 6 14 18 23 55 56 81
 $ : int [1:5] 49 60 80 84 90
 $ : int [1:6] 2 6 12 18 95 97
 $ : int [1:3] 27 37 70
 $ : int [1:3] 25 52 67
 $ : int [1:5] 1 41 68 73 79
 $ : int [1:6] 2 12 14 23 49 55
 $ : int [1:8] 1 32 43 53 63 68 76 92
 $ : int [1:4] 22 38 57 87
 $ : int [1:2] 37 72
 $ : int [1:2] 20 57
 $ : int [1:5] 12 18 36 55 81
 $ : int [1:4] 9 10 71 78
 $ : int [1:6] 7 16 52 54 69 74
 $ : int [1:6] 9 43 47 63 78 82
 $ : int 15
 $ : int 48
 $ : int [1:7] 30 34 41 62 76 80 84
 $ : int [1:5] 29 34 49 80 99
 $ : int [1:6] 52 54 67 71 82 96
 $ : int [1:5] 19 39 68 73 92
 $ : int [1:5] 42 59 64 74 98
 $ : int [1:7] 29 30 41 79 85 86 99
 $ : int [1:7] 39 42 51 64 91 92 93
 $ : int [1:3] 23 55 60
 $ : int [1:5] 15 21 46 70 72
 $ : int [1:3] 20 57 87
 $ : int [1:5] 32 35 73 91 92
 $ : int [1:4] 54 74 96 98
 $ : int [1:7] 1 17 29 34 76 79 85
 $ : int [1:7] 8 33 35 59 64 66 93
 $ : int [1:7] 19 26 51 53 63 82 92
 $ : int [1:6] 11 45 50 58 87 88
 $ : int [1:5] 11 44 75 81 88
 $ : int [1:3] 8 37 66
 $ : int [1:5] 26 63 77 78 83
 $ : int [1:4] 7 28 89 94
 $ : int [1:9] 2 13 18 30 55 60 80 97 99
 $ : int [1:4] 44 57 87 88
 $ : int [1:7] 35 43 64 82 92 96 98
 $ : int [1:5] 16 25 31 54 67
 $ : int [1:3] 19 43 63
 $ : int [1:6] 25 31 40 52 74 96
 $ : int [1:6] 12 18 23 36 49 60
 $ : int [1:6] 6 11 12 61 81 100
 $ : int [1:5] 20 22 38 50 87
 $ : int [1:3] 11 44 100
 $ : int [1:6] 7 8 33 42 74 94
 $ : int [1:5] 13 36 49 55 90
 $ : int [1:3] 6 56 100
 $ : int [1:7] 4 29 63 76 77 80 84
 $ : int [1:9] 19 26 43 47 53 62 76 77 83
 $ : int [1:7] 33 35 42 51 92 93 98
 $ : int [1:2] 10 71
 $ : int [1:3] 8 42 46
 $ : int [1:4] 16 31 52 71
 $ : int [1:5] 1 17 19 32 73
 $ : int [1:2] 7 25
 $ : int [1:3] 15 37 72
 $ : int [1:7] 9 10 24 31 65 67 82
 $ : int [1:3] 21 37 70
 $ : int [1:4] 17 32 39 68
 $ : int [1:7] 7 25 33 40 54 59 98
 $ : int [1:2] 45 81
 $ : int [1:6] 1 19 29 41 62 63
 $ : int [1:6] 4 47 62 63 83 84
 $ : int [1:5] 9 24 26 47 83
 $ : int [1:5] 1 17 34 41 85
 $ : int [1:6] 13 29 30 49 62 84
 $ : int [1:6] 11 12 23 45 56 75
 $ : int [1:7] 9 26 31 43 51 71 96
 $ : int [1:4] 47 63 77 78
 $ : int [1:7] 4 13 29 62 77 80 90
 $ : int [1:4] 34 41 79 86
 $ : int [1:5] 3 34 85 97 99
 $ : int [1:5] 20 38 44 50 57
 $ : int [1:4] 11 44 45 50
 $ : int [1:2] 48 94
 $ : int [1:4] 4 13 60 84
 $ : int [1:3] 35 39 93
 $ : int [1:7] 19 32 35 39 43 51 64
 $ : int [1:4] 35 42 64 91
 $ : int [1:5] 7 8 48 59 89
 $ : int [1:4] 5 6 14 97
 $ : int [1:6] 31 40 51 54 82 98
 $ : int [1:8] 2 3 5 14 49 86 95 99
 $ : int [1:6] 33 40 51 64 74 96
 $ : int [1:5] 30 34 49 86 97
 $ : int [1:4] 11 56 58 61
 - attr(*, "class")= chr "nb"
 - attr(*, "region.id")= chr [1:100] "37001" "37003" "37005" "37007" ...
 - attr(*, "GeoDa")=List of 2
  ..$ shpfile: chr "sids"
  ..$ ind    : chr "rn"
 - attr(*, "gal")= logi TRUE
 - attr(*, "call")= logi TRUE
 - attr(*, "sym")= logi TRUE
> data.frame(NAME=nc.sids at data$NAME, SID79=nc.sids at data$SID79, 
> SID79.lag=lag(wts, nc.sids at data$SID79))
            NAME SID79 SID79.lag
1       Alamance    11 11.000000
2      Alexander     2 10.500000
3      Alleghany     3  4.333333
4          Anson     4  7.750000
5           Ashe     0  3.666667
6          Avery     0  6.400000
7       Beaufort     4  5.166667
8         Bertie     5  5.200000
9         Bladen     5 21.400000
10     Brunswick     6  9.666667
11      Buncombe    18  5.142857
12         Burke    15 10.142857
13      Cabarrus    20 12.800000
14      Caldwell     9  7.666667
15        Camden     2  2.666667
16      Carteret     4 14.333333
17       Caswell     2 12.800000
18       Catawba    21  9.833333
19       Chatham     3 12.875000
20      Cherokee     1  1.500000
21        Chowan     1  1.000000
22          Clay     0  2.000000
23     Cleveland    21 15.400000
24      Columbus    17 10.000000
25        Craven    18  6.000000
26    Cumberland    57  9.333333
27     Currituck     2  2.000000
28          Dare     1  0.000000
29      Davidson     8 13.428571
30         Davie     3  8.000000
31        Duplin     7 11.500000
32        Durham    22  9.600000
33     Edgecombe     9  9.800000
34       Forsyth    18  9.428571
35      Franklin     0 11.428571
36        Gaston    26 21.000000
37         Gates     2  2.400000
38        Graham     1  2.000000
39     Granville     4 12.600000
40        Greene     4 15.250000
41      Guilford    38  8.714286
42       Halifax    17  3.857143
43       Harnett    10 17.000000
44       Haywood     8  6.500000
45     Henderson     8  7.600000
46      Hertford     5  3.333333
47          Hoke     6 22.200000
48          Hyde     0  1.250000
49       Iredell     5 11.555556
50       Jackson     5  4.250000
51      Johnston    13 12.571429
52         Jones     2 13.200000
53           Lee     6  6.000000
54        Lenoir    14 10.833333
55       Lincoln     7 20.500000
56      McDowell     5  7.333333
57         Macon     3  1.800000
58       Madison     2  9.000000
59        Martin     1  7.666667
60   Mecklenburg    35 13.400000
61      Mitchell     2  2.000000
62    Montgomery     8  7.285714
63         Moore     5 13.888889
64          Nash     7 12.142857
65   New Hanover     9  4.500000
66   Northampton     3  9.000000
67        Onslow    23  4.000000
68        Orange     6  8.400000
69       Pamlico     1 11.000000
70    Pasquotank     4  1.333333
71        Pender     3 10.142857
72    Perquimans     0  2.333333
73        Person     4  8.500000
74          Pitt    11  9.000000
75          Polk     0  8.000000
76      Randolph    12 12.166667
77      Richmond     7  7.666667
78       Robeson    26 20.200000
79    Rockingham     5 14.800000
80         Rowan     8  8.500000
81    Rutherford     8 11.166667
82       Sampson     4 16.857143
83      Scotland    16 11.000000
84        Stanly     7  9.142857
85        Stokes     5 16.750000
86         Surry     6  6.800000
87         Swain     2  3.600000
88  Transylvania     4  9.750000
89       Tyrrell     0  0.000000
90         Union     9 16.500000
91         Vance     6  2.000000
92          Wake    31  8.428571
93        Warren     2  7.500000
94    Washington     0  2.000000
95       Watauga     1  4.000000
96         Wayne    23  9.166667
97        Wilkes     7  3.375000
98        Wilson    13 11.166667
99        Yadkin     1  7.800000
100       Yancey     1  6.750000
> Alleghany.before <- data.frame(NAME=nc.sids at data$NAME, 
> SID79=nc.sids at data$SID79, SID79.lag=lag.listw(wts, 
> nc.sids at data$SID79))[nc.sids at data$NAME=="Alleghany",] Alleghany.before
       NAME SID79 SID79.lag
3 Alleghany     3  4.333333
> 
> ##plot neighbors and county names
> plot(nc.sids, border="grey")
> plot(ncCR85_nb, coordinates(nc.sids), add=TRUE, col="blue")
> text(coordinates(nc.sids)+.1, labels=nc.sids at data$NAME, cex=.4)
> title(main="Contiguous neighbors")
> 
> ##recode Wilkes County SID79 from 7 to NA for illustrating behavior of 
> lagging with missing attribute nc.sids at data$SID79[97] <- NA 
> data.frame(NAME=nc.sids at data$NAME, SID79=nc.sids at data$SID79, 
> SID79.lag=lag(wts, nc.sids at data$SID79))[97,]
     NAME SID79 SID79.lag
97 Wilkes    NA     3.375
> Alleghany.after <- data.frame(NAME=nc.sids at data$NAME, 
> SID79=nc.sids at data$SID79, SID79.lag=lag.listw(wts, 
> nc.sids at data$SID79))[nc.sids at data$NAME=="Alleghany",] Alleghany.before
       NAME SID79 SID79.lag
3 Alleghany     3  4.333333
> Alleghany.after
       NAME SID79 SID79.lag
3 Alleghany     3         2
> data.frame(NAME=nc.sids at data$NAME, SID79=nc.sids at data$SID79, 
> SID79.lag=lag(wts, nc.sids at data$SID79))[5,]
  NAME SID79 SID79.lag
5 Ashe     0  1.333333
> data.frame(NAME=nc.sids at data$NAME, SID79=nc.sids at data$SID79, 
> SID79.lag=lag(wts, nc.sids at data$SID79))[86,]
    NAME SID79 SID79.lag
86 Surry     6       5.4
> 
> ##Note that if the spatial weights matrix excluded neighbors with 
> missing attribute values, then the spatial lag would be 3 (i.e., 
> (0+6)/2), which is closer to true value of 4.3.
> 
> ##########



From zack_holden at hotmail.com  Mon Dec 29 00:49:12 2008
From: zack_holden at hotmail.com (zack holden)
Date: Sun, 28 Dec 2008 23:49:12 +0000
Subject: [R-sig-Geo] how to export results of predict.randomForest
	(Edzer Pebesma)
In-Reply-To: <mailman.5.1230375602.19623.r-sig-geo@stat.math.ethz.ch>
References: <mailman.5.1230375602.19623.r-sig-geo@stat.math.ethz.ch>
Message-ID: <BAY125-W48EFC26962D5F1506E108987E90@phx.gbl>



Hi Ann,
I've created prediction surfaces from random forest models and can try to help you. 
 
I don't know Rgdal well enough to guide you through your current approach. What you could do is create ascii grids for each of your raster/image bands, then call to those grids to create your prediction surface. 
 
Check out package = yaImpute and the AsciiGridPredict function within. I can send you some code to make this work if you'd like to try it. Just ask. Feel free to email off list, you can post the solution if it works.
 
Cheers,
 
Zack


> From: r-sig-geo-request at stat.math.ethz.ch
> Subject: R-sig-Geo Digest, Vol 64, Issue 25
> To: r-sig-geo at stat.math.ethz.ch
> Date: Sat, 27 Dec 2008 12:00:02 +0100
>
> Send R-sig-Geo mailing list submissions to
> r-sig-geo at stat.math.ethz.ch
>
> To subscribe or unsubscribe via the World Wide Web, visit
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> or, via email, send a message with subject or body 'help' to
> r-sig-geo-request at stat.math.ethz.ch
>
> You can reach the person managing the list at
> r-sig-geo-owner at stat.math.ethz.ch
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-Geo digest..."
>
>
> Today's Topics:
>
> 1. Re: adding a background shape to ssplot (Edzer Pebesma)
> 2. Re: how to export results of predict.randomForest (Edzer Pebesma)
> 3. Re: adding a background shape to ssplot (Hengl, T.)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Fri, 26 Dec 2008 12:20:44 +0100
> From: Edzer Pebesma
> Subject: Re: [R-sig-Geo] adding a background shape to ssplot
> To: Jon Loehrke
> Cc: r-sig-geo at stat.math.ethz.ch
> Message-ID: 
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> Jon Loehrke wrote:
>> Greetings and Happy Holidays!
>>
>>
>>
> ...
>> #However I can seem to pass the polygon colors argument through spplot
>> spplot(nc1, c("f","g"), col.regions=brewer.pal(10, "Set3"),
>> scales=list(draw = TRUE),
>> panel=function(...) {
>> panel.mapper()
>> sp.polygons(nc1)
>> }
>> )
>>
>>
> A better panel function would be this:
>
> spplot(nc1, c("f","g"), # col.regions=brewer.pal(10, "Set3"),
> scales=list(draw = TRUE),
> panel=function(...) {
> panel.mapper()
> panel.polygonsplot(...)
> }
> )
>
>
> see
>
> getMethod("spplot", "SpatialPolygonsDataFrame")
>
> to find out how the appropriate spplot method does it.
>
> I am worried, however, about the absence of the last 5 colors and factor
> levels f-j.
> --
> Edzer
>
>
>
> ------------------------------
>
> Message: 2
> Date: Fri, 26 Dec 2008 12:26:29 +0100
> From: Edzer Pebesma
> Subject: Re: [R-sig-Geo] how to export results of predict.randomForest
> To: Anne Axel
> Cc: r-sig-geo at stat.math.ethz.ch
> Message-ID: 
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> I might have missed something obvious, but did you try something like
>
> bands$randomForest = output
> spplot(bands, "randomForest")
>
> ?
> --
> Edzer
>
>
> Anne Axel schrieb:
>> Hi Robert and list,
>>
>> Thanks so much for the Christmas message! I tried your great
>> suggestion and I got the following error:
>>
>>> spgrid <- SpatialGridDataFrame(bands, output)
>> Error in rbind(grid at cellcentre.offset, grid at cellcentre.offset +
>> (grid at cells.dim - :
>> no slot of name "cellcentre.offset" for this object of class
>> "SpatialGridDataFrame"
>>
>> So, I examined the structure of both files (see below). In addition,
>> there are no NAs in "imgtabla" or "bands", but there are NAs in the
>> rf.prediction ("output").
>>
>> I tried to writeGDAL(bands, "test2.tif") and this worked without any
>> errors. Could it have something to do with the fact that my output is
>> of class factor?
>>
>> Again, thanks Robert, for setting me on the right path. Any other
>> suggestions out there to clear this last hurdle?
>>
>> Best,
>> Anne Axel
>>
>>> str(bands)
>> Formal class 'SpatialGridDataFrame' [package "sp"] with 6 slots
>> ..@ data :'data.frame': 163982 obs. of 55 variables:
>> .. ..$ band1 : num [1:163982] 0 0 0 0 0 0 0 0 0 0 ...
>> .. ..
>> ..@ grid :Formal class 'GridTopology' [package "sp"] with 3 slots
>> .. .. ..@ cellcentre.offset: Named num [1:2] 0.5 0.5
>> .. .. .. ..- attr(*, "names")= chr [1:2] "x" "y"
>> .. .. ..@ cellsize : num [1:2] 1 1
>> .. .. ..@ cells.dim : int [1:2] 442 371
>> ..@ grid.index : int(0)
>> ..@ coords : num [1:2, 1:2] 0.5 441.5 0.5 370.5
>> .. ..- attr(*, "dimnames")=List of 2
>> .. .. ..$ : NULL
>> .. .. ..$ : chr [1:2] "x" "y"
>> ..@ bbox : num [1:2, 1:2] 0 0 442 371
>> .. ..- attr(*, "dimnames")=List of 2
>> .. .. ..$ : chr [1:2] "x" "y"
>> .. .. ..$ : chr [1:2] "min" "max"
>> ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>> .. .. ..@ projargs: chr " +proj=utm +zone=38 +south +a=6378137
>> +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0"
>>
>>> str(output)
>> Factor w/ 4 levels "dry","gallery",..: 3 3 3 3 3 3 3 3 3 3 ...
>>
>>
>>> class(bands)
>> [1] "SpatialGridDataFrame"
>> attr(,"package")
>> [1] "sp"
>>
>>
>>> class(output)
>> [1] "factor"
>>
>>> summary(output)
>> dry gallery notforest spiny NA's
>> 33009 5878 103772 21315 8
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> At 12/24/2008 09:02 PM, you wrote:
>>> Hi Anne,
>>>
>>> The first argument of writeGDAL is "an object of class
>>> SpatialGridDataFrame-class or SpatialPixelsDataFrame-class"
>>> So you need to create a new SpatialGridDataFrame with the spatial
>>> properties of "multibands3.img" and with the RandomForest predictions
>>> ("output"). Note that there are some additional complications when
>>> there are NAs in your predictors (i.e. in "imgtabla"), but if there
>>> are none, I think that something like this might work:
>>>
>>> spgrid <- SpatialGridDataFrame(bands, output)
>>> writeGDAL(spgrid, "rf_results.tif")
>>>
>>> Robert
>>>
>>> On Thu, Dec 25, 2008 at 4:58 AM, Anne Axel
>>> wrote:
>>> Hi List,
>>>
>>> I am requesting help with exporting results from the
>>> predict.randomForest function. This is my first attempt at working
>>> with spatial data in R--I was able to import the data and run the
>>> randomForest model, but I cannot figure out how to export the data
>>> for use in ArcGIS or ENVI.
>>>
>>> I've pasted below the code I used for randomForest and exporting of
>>> results. If anyone has suggestions, I would be eternally grateful!
>>> Thanks, and Happy Holidays.
>>>
>>> Anne Axel
>>>
>>>
>>> Department of Fisheries and Wildlife
>>> Michigan State University
>>> 20 Natural Resources Building
>>> East Lansing, MI 48824 USA
>>> 517-930-2248
>>> axelanne at msu.edu
>>>
>>>
>>> ####Read in *img file with 55 bands
>>> bands=readGDAL("multibands3.img")
>>> imgtabla <- as(bands, "data.frame")
>>>
>>> ######Read in training data and run randomForest
>>> data=read.csv("bandnumsOutput_cond2.csv", header=TRUE)
>>> data2=data[,1:58]
>>> data.rf=randomForest(COVERTYPE~ ., data=data2, mtry=16, importance =
>>> TRUE, do.trace=100)
>>> print(data.rf)
>>> output=predict(data.rf, imgtabla)
>>>
>>> #### I've tried numerous ways of exporting the data, but I don't seem
>>> to have the data in a format that's acceptable to the functions. In
>>> addition, I've tried to coerce data into other formats, but nothing
>>> has worked. Any suggestions?
>>>
>>>
>>>> writeGDAL(bands, output, drivername = "GTiff", type = "Float32",
>>> mvFlag = NA, options=NULL)
>>> Error in .local(.Object, ...) :
>>> STRING_ELT() can only be applied to a 'character vector', not a
>>> 'integer'
>>> In addition: Warning messages:
>>> 1: In if (nchar(fname) == 0) stop("empty file name") :
>>> the condition has length> 1 and only the first element will be used
>>> 2: In if (nchar(filename) == 0) stop("empty file name") :
>>> the condition has length> 1 and only the first element will be used
>>>
>>>> writeGDAL(output, bands, drivername = "GTiff", type = "Float32",
>>> mvFlag = NA, options=NULL)
>>> Error in nchar(fname) : cannot coerce type S4 to character vector
>>>
>>>> write.ENVI(output)
>>> Error in dim(X) = c(nRow, nCol, nBand) : length-0 dimension vector is
>>> invalid
>>>
>>>> write.ascii.grid(output, "output", header = NULL, write.header = TRUE)
>>> Error: is.matrix(data) is not TRUE
>>>
>>>
>>>
>>>
>>>
>>> Anne C. Axel
>>> Department of Fisheries and Wildlife
>>> Michigan State University
>>> 20 Natural Resources Building
>>> East Lansing, MI 48824 USA
>>> 517-930-2248
>>> axelanne at msu.edu
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> " Know your own bone. Gnaw at it, bury it, unearth it, and gnaw it
>> still."
>> -Henry David Thoreau
>>
>> "Outside of a dog, a book is a man's best friend. Inside of a dog,
>> it's too dark to read."
>> - Groucho Marx
>>
>> Anne C. Axel
>> Department of Fisheries and Wildlife
>> Michigan State University
>> 20 Natural Resources Building
>> East Lansing, MI 48824 USA
>> 517-930-2248
>> axelanne at msu.edu
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
> ------------------------------
>
> Message: 3
> Date: Fri, 26 Dec 2008 15:01:27 +0100
> From: "Hengl, T."
> Subject: Re: [R-sig-Geo] adding a background shape to ssplot
> To: "Jon Loehrke" ,
> Message-ID: 
> Content-Type: text/plain
>
>
> take a look also at some examples from the book by Reimann et al. (2008). They actually load a jpg map (showing coast-line/borders) as a background plot (method "plotbg" in package "StatDA"):
>
> 6.4 Spatial Trends
> http://www.statistik.tuwien.ac.at/StatDA/R-scripts/page138.html
>
> 8.9 Data Subsets in Maps
> http://www.statistik.tuwien.ac.at/StatDA/R-scripts/page157.html
>
>
> HTH
>
> Tom Hengl
> http://spatial-analyst.net
>
> ________________________________
>
> From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Jon Loehrke
> Sent: sri 12/24/2008 7:01
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] adding a background shape to ssplot
>
>
>
> Greetings and Happy Holidays!
>
> I am an ~experienced R user but new to spatially oriented packages. I
> have been trying to add a 'background' shape to a ssplot. My example
> is to add a background state map to the sids data.
>
> My 2 questions, 1) What am I missing with the spplot - lattice
> interaction[this seems like it should be simple]?, and 2) is there a
> better way to add the 'background' map if the object is a
> SpatialPolygonsDataFrame?
>
> #Examples mostly from http://r-spatial.sourceforge.net/gallery/
> #Library's required for example
> library(sp)
> library(grid)
> library(lattice)
> library(maps)
> library(RColorBrewer)
> library(maptools)
>
> #First a Basic plot and an added map
>
> nc1 <- readShapePoly(system.file("shapes/sids.shp", package="maptools")
> [1], proj4string=CRS("+proj=longlat +datum=NAD27"))
>
> names(nc1)
> rrt <- nc1$SID74/nc1$BIR74
> brks <- quantile(rrt, seq(0,1,1/7))
> cols <- grey((length(brks):2)/length(brks))
> dens <- (2:length(brks))*3
> plot(nc1, col=cols[findInterval(rrt, brks, all.inside=TRUE)])
>
> # add US State map
> map('state', add=TRUE, xlim=par('usr')[1:2], ylim=par('usr')[3:4])
>
>
> #This works fine, but I have issues when using spplot.
>
> example
> nc1$f = factor(sample(1:5,100,replace=T),labels=letters[1:5])
> nc1$g = factor(sample(1:5,100,replace=T),labels=letters[6:10])
>
> spplot(nc1, c("f","g"), col.regions=brewer.pal(10, "Set3"),
> scales=list(draw = TRUE))
>
>
> # create a custom panel to add a map polygon to lattice plot
>
> panel.mapper <- function(...){
> library(maps)
> mp<-map('state', fill=TRUE, plot=FALSE)
> lpolygon(mp$x, mp$y, col='gray', ...)
> }
>
> #The panel mapper appears to work
> spplot(nc1, c("f","g"), col.regions=brewer.pal(10, "Set3"),
> scales=list(draw = TRUE), panel=function(...) {
> panel.mapper()
> })
>
> #However I can seem to pass the polygon colors argument through ssplot
> spplot(nc1, c("f","g"), col.regions=brewer.pal(10, "Set3"),
> scales=list(draw = TRUE),
> panel=function(...) {
> panel.mapper()
> sp.polygons(nc1)
> }
> )
>
>
> Thanks for the help and happiest holidays.
>
> Jon Loehrke
> Graduate Research Assistant
> Department of Fisheries Oceanography
> School for Marine Science and Technology
> University of Massachusetts
> 200 Mill Road, Suite 325
> Fairhaven, MA 02719
> jloehrke at umassd.edu
>> sessionInfo()
> R version 2.8.1 (2008-12-22)
> i386-apple-darwin8.11.1
>
> locale:
> en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] grid stats graphics grDevices utils datasets
> methods base
>
> other attached packages:
> [1] lattice_0.17-17 RColorBrewer_1.0-2 maps_2.0-40
> maptools_0.7-15 foreign_0.8-29 sp_0.9-28
>
> loaded via a namespace (and not attached):
> [1] tools_2.8.1
>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
> [[alternative HTML version deleted]]
>
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> End of R-sig-Geo Digest, Vol 64, Issue 25
> *****************************************


From katona at statisztikus.hu  Mon Dec 29 14:57:53 2008
From: katona at statisztikus.hu (Katona Lajos)
Date: Mon, 29 Dec 2008 14:57:53 +0100
Subject: [R-sig-Geo] fixed colors in maps (Katona Lajos)
Message-ID: <59ce81443070646a32d5df368082891e@blup.ultimate.hu>

Hi,
there is an example here:

library(sp)
library(lattice)
library(RColorBrewer)
data(meuse)
coordinates(meuse) <- ~x+y
meuse$color_codes=as.numeric(meuse$ffreq)+as.numeric(meuse$soil)+as.numeric(meuse$lime)
meuse$color_codes[1:3]=1
meuse$color_codes[4:7]=2
meuse$color_codes[16:20]=8
meuse$color_codes[21:26]=9
meuse$color_codes2=meuse$color_codes
meuse$color_codes3=meuse$color_codes
meuse$color_codes2=ifelse(meuse$color_codes2<4,meuse$color_codes2,3)
meuse$color_codes3=ifelse(meuse$color_codes3>6,meuse$color_codes3,6)
meuse$color_codes=as.factor(meuse$color_codes)
meuse$color_codes2=factor(meuse$color_codes2, levels=c(1,2,3,4,5,6,7,8,9))
meuse$color_codes3=factor(meuse$color_codes3, levels=c(1,2,3,4,5,6,7,8,9))
#good
spplot(meuse, "color_codes", col.regions=brewer.pal(9, "Reds"))
#wrong (I'd like to see every code of colors in legend, and only the first 3
colors from the 9 in the map)
spplot(meuse, "color_codes2", col.regions=brewer.pal(9, "Reds"))
#wrong (I'd like to see every code of colors in legend, and only between 6 and
9 colors from the 9 in the map)
spplot(meuse, "color_codes3", col.regions=brewer.pal(9, "Reds"))

Best regards,
Lajos Katona


On Sun, 28 Dec 2008 12:36:35 +0100, Edzer Pebesma
<edzer.pebesma at uni-muenster.de> wrote:
> Could you provide me and/or the list with an example that we can
> reproduce and that illustrates your problem?
> --
> Edzer



From luka.honzak at gmail.com  Mon Dec 29 22:40:08 2008
From: luka.honzak at gmail.com (Luka Honzak)
Date: Mon, 29 Dec 2008 22:40:08 +0100
Subject: [R-sig-Geo] Different variogram fitting results from gstat in R
	than from standalone gstat
In-Reply-To: <4dc1f79d0812291328g731e7c61vfaa300eddd3485db@mail.gmail.com>
References: <4dc1f79d0812291328g731e7c61vfaa300eddd3485db@mail.gmail.com>
Message-ID: <4dc1f79d0812291340x43f9b0a4pab6be9284df40192@mail.gmail.com>

Hi everyone,

I am trying to move my work from standalone gstat to R and I found
that variogram fitting gives different results in R than in standalone
gstat, while variograms are the same.
I want to know if I have done something wrong in R and what.

*gstat:
-set fit = 7; 6.56882 Nug(0) + 584.336 Sph(27110.8)
-set fit = 1; 156.687 Nug(0) + 444.965 Sph(35817.8)
*R:
-fit.method=7
 model      psill    range
1   Nug   3.027124     0.00
2   Sph 593.518692 27282.76
-fit.method=1
 model    psill    range
1   Nug 287.9900     0.00
2   Sph 354.8136 55421.58



*gstat commandline file:
data(RR): 'gstat_2000_5_NV.txt', x=1, y=2, v=4, X=x&y&xy;
variogram(RR): 70 Nug(0) + 600 Sph(30000);
set fit = 7;
set cutoff = 150000;
set width = 6000;


*R code:
library(gstat)
table=read.table("gstat_2000_5_NV.txt")
colnames(table)<-c("x","y","z","RR")
g <- gstat(id = "test", formula = RR~x+y+x*y, locations = ~x+y, data = table)
m <- vgm(600, "Sph", 30000, 70)
v.fit <- fit.variogram(variogram(g), m, fit.method=7)



From edzer.pebesma at uni-muenster.de  Tue Dec 30 12:05:29 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 30 Dec 2008 12:05:29 +0100
Subject: [R-sig-Geo] Different variogram fitting results from gstat in
 R	than from standalone gstat
In-Reply-To: <4dc1f79d0812291340x43f9b0a4pab6be9284df40192@mail.gmail.com>
References: <4dc1f79d0812291328g731e7c61vfaa300eddd3485db@mail.gmail.com>
	<4dc1f79d0812291340x43f9b0a4pab6be9284df40192@mail.gmail.com>
Message-ID: <495A0079.6000002@uni-muenster.de>

Luka, this is hard to tell from here. The first thing I would try to 
find out is whether the sample variograms from both approaches are 
_exactly_ the same or not. For one thing, the X=x&y&xy in gstat 
stand-alone does standardize coordinates, the formula approach in 
R/gstat does not.

Maybe follow-up on the gstat-info list?
--
Edzer

Luka Honzak wrote:
> Hi everyone,
>
> I am trying to move my work from standalone gstat to R and I found
> that variogram fitting gives different results in R than in standalone
> gstat, while variograms are the same.
> I want to know if I have done something wrong in R and what.
>
> *gstat:
> -set fit = 7; 6.56882 Nug(0) + 584.336 Sph(27110.8)
> -set fit = 1; 156.687 Nug(0) + 444.965 Sph(35817.8)
> *R:
> -fit.method=7
>  model      psill    range
> 1   Nug   3.027124     0.00
> 2   Sph 593.518692 27282.76
> -fit.method=1
>  model    psill    range
> 1   Nug 287.9900     0.00
> 2   Sph 354.8136 55421.58
>
>
>
> *gstat commandline file:
> data(RR): 'gstat_2000_5_NV.txt', x=1, y=2, v=4, X=x&y&xy;
> variogram(RR): 70 Nug(0) + 600 Sph(30000);
> set fit = 7;
> set cutoff = 150000;
> set width = 6000;
>
>
> *R code:
> library(gstat)
> table=read.table("gstat_2000_5_NV.txt")
> colnames(table)<-c("x","y","z","RR")
> g <- gstat(id = "test", formula = RR~x+y+x*y, locations = ~x+y, data = table)
> m <- vgm(600, "Sph", 30000, 70)
> v.fit <- fit.variogram(variogram(g), m, fit.method=7)
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de



From francesco.pirotti at unipd.it  Tue Dec 30 12:41:24 2008
From: francesco.pirotti at unipd.it (francesco)
Date: Tue, 30 Dec 2008 12:41:24 +0100
Subject: [R-sig-Geo] turning polygons shapefile into quadrats
Message-ID: UK866.188929MJ@unipd.it

Dear List,

I have been banging my head on a problem for three days now, so I believe the time has come to look for help.

I have a polygon shapefile with an irregular grid and I would like to turn the polygons in the shapefile into tiles to use with "quadratcount" method in spatstat package. 

I have been coercing back and forth with lists, slots, classes and I got a little lost into trying to turn the coordinates of the shapes into tiles.

The final objective is to extract statistics on points falling inside each polygons.  The points are a SpatialPointsDataframe class with attributes which will be analysed in each polygon as if the polygons were containers.

I hope I have explained clearly and that someone can point towards a method to use for this. 

PS  I am relatively new to R, but it's fantastic.

Cheers,
--------------------------------------
Francesco Pirotti
Dept. Te.S.A.F./CIRGEO
University of Padua
Viale dell'Universit? 16
I-35020 Legnaro (PD)
tel.       +39 049 827 2710
fax.      +39 049 827 2686
mob.    +39 349 55 39 261
@mail   francesco.pirotti at unipd.it  
skypeID francesco197576    
http://www.cirgeo.unipd.it/cirgeo/francescopirotti.htm



From hi_ono2001 at ybb.ne.jp  Tue Dec 30 12:54:48 2008
From: hi_ono2001 at ybb.ne.jp (Hisaji ONO)
Date: Tue, 30 Dec 2008 20:54:48 +0900 (JST)
Subject: [R-sig-Geo] Any successful case of Building Rcartogram for Win32
Message-ID: <20081230115448.43394.qmail@web10715.mail.bbt.yahoo.co.jp>

Hello.
 
  On this December, Japanese TV program(created by TV
Tokyo, one of TV broadcast station in Japan) used my
Java-based  area continued cartogram to generate various
cartograms.
 
  However my algorithm is too slow.
 
  Rcartogram(http://www.omegahat.org/Rcartogram/)  seems
to generate cartogram faster and its results very good.
 
  Does anyone succeed to build this program on Win32?


  Regards.



From dylan.beaudette at gmail.com  Tue Dec 30 15:52:18 2008
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Tue, 30 Dec 2008 06:52:18 -0800
Subject: [R-sig-Geo] turning polygons shapefile into quadrats
In-Reply-To: <UK866.188929MJ@unipd.it>
References: <UK866.188929MJ@unipd.it>
Message-ID: <3c5546140812300652i667bb481nc698a5e255a146c4@mail.gmail.com>

On Tue, Dec 30, 2008 at 3:41 AM, francesco <francesco.pirotti at unipd.it> wrote:
> Dear List,
>
> I have been banging my head on a problem for three days now, so I believe the time has come to look for help.
>
> I have a polygon shapefile with an irregular grid and I would like to turn the polygons in the shapefile into tiles to use with "quadratcount" method in spatstat package.
>
> I have been coercing back and forth with lists, slots, classes and I got a little lost into trying to turn the coordinates of the shapes into tiles.
>
> The final objective is to extract statistics on points falling inside each polygons.  The points are a SpatialPointsDataframe class with attributes which will be analysed in each polygon as if the polygons were containers.


Hi. This is not a complete solution, but you may find some tips on
these two sources:

1. http://casoilresource.lawr.ucdavis.edu/drupal/node/644
2. http://casoilresource.lawr.ucdavis.edu/drupal/node/551

The first one deals with iterating over polygons, the second on
conversion between sp and spatstat classes.

Cheers,

Dylan
>
> I hope I have explained clearly and that someone can point towards a method to use for this.
>
> PS  I am relatively new to R, but it's fantastic.
>
> Cheers,
> --------------------------------------
> Francesco Pirotti
> Dept. Te.S.A.F./CIRGEO
> University of Padua
> Viale dell'Universit? 16
> I-35020 Legnaro (PD)
> tel.       +39 049 827 2710
> fax.      +39 049 827 2686
> mob.    +39 349 55 39 261
> @mail   francesco.pirotti at unipd.it
> skypeID francesco197576
> http://www.cirgeo.unipd.it/cirgeo/francescopirotti.htm
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Roger.Bivand at nhh.no  Tue Dec 30 20:20:45 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 30 Dec 2008 20:20:45 +0100 (CET)
Subject: [R-sig-Geo] turning polygons shapefile into quadrats
In-Reply-To: UK866.188929MJ@unipd.it
References: UK866.188929MJ@unipd.it
Message-ID: <alpine.LRH.2.00.0812302008090.27008@reclus.nhh.no>

On Tue, 30 Dec 2008, francesco wrote:

> Dear List,
>
> I have been banging my head on a problem for three days now, so I 
> believe the time has come to look for help.
>
> I have a polygon shapefile with an irregular grid and I would like to 
> turn the polygons in the shapefile into tiles to use with "quadratcount" 
> method in spatstat package.
>
> I have been coercing back and forth with lists, slots, classes and I got 
> a little lost into trying to turn the coordinates of the shapes into 
> tiles.
>
> The final objective is to extract statistics on points falling inside 
> each polygons.  The points are a SpatialPointsDataframe class with 
> attributes which will be analysed in each polygon as if the polygons 
> were containers.
>
> I hope I have explained clearly and that someone can point towards a 
> method to use for this.

Not really clear without a simple code example. If you need to find out 
which points are inside which polygon, use an overlay() method. It isn't 
clear what quadratcount might have to do with this, so you'll need to 
explain that. You can also use overlay() methods to find out which grid 
cells points belong to.

Hope this helps,

Roger


>
> PS  I am relatively new to R, but it's fantastic.
>
> Cheers,
> --------------------------------------
> Francesco Pirotti
> Dept. Te.S.A.F./CIRGEO
> University of Padua
> Viale dell'Universit? 16
> I-35020 Legnaro (PD)
> tel.       +39 049 827 2710
> fax.      +39 049 827 2686
> mob.    +39 349 55 39 261
> @mail   francesco.pirotti at unipd.it
> skypeID francesco197576
> http://www.cirgeo.unipd.it/cirgeo/francescopirotti.htm
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From Roger.Bivand at nhh.no  Tue Dec 30 20:24:18 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 30 Dec 2008 20:24:18 +0100 (CET)
Subject: [R-sig-Geo] Any successful case of Building Rcartogram for Win32
In-Reply-To: <20081230115448.43394.qmail@web10715.mail.bbt.yahoo.co.jp>
References: <20081230115448.43394.qmail@web10715.mail.bbt.yahoo.co.jp>
Message-ID: <alpine.LRH.2.00.0812302021160.27008@reclus.nhh.no>

On Tue, 30 Dec 2008, Hisaji ONO wrote:

> Hello.
>
>  On this December, Japanese TV program(created by TV
> Tokyo, one of TV broadcast station in Japan) used my
> Java-based  area continued cartogram to generate various
> cartograms.
>
>  However my algorithm is too slow.
>
>  Rcartogram(http://www.omegahat.org/Rcartogram/)  seems
> to generate cartogram faster and its results very good.
>
>  Does anyone succeed to build this program on Win32?

You'll need to build by hand with the FFTW3 DLL headers - ./configure will 
most likely not work happily. The FFTW site describes Windows 
installation, but you'll need to modify the source package more to help it 
find the DLL and headers:

http://www.fftw.org/install/windows.html

Best wishes,

Roger

>
>
>  Regards.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From moor0554 at umn.edu  Tue Dec 30 22:27:41 2008
From: moor0554 at umn.edu (Christopher Moore)
Date: 30 Dec 2008 15:27:41 -0600
Subject: [R-sig-Geo] Spatial Lags Excluding Neighbors' Missing Attribute
	Values
In-Reply-To: <mailman.5.1230462002.17612.r-sig-geo@stat.math.ethz.ch>
References: <mailman.5.1230462002.17612.r-sig-geo@stat.math.ethz.ch>
Message-ID: <Prayer.1.0.16.0812301527410.10033@vs-a.tc.umn.edu>

Greetings,

I posted a request for assistance on 12/27/08: 
<https://stat.ethz.ch/pipermail/r-sig-geo/2008-December/004733.html>.

I developed a satisfactory solution, which is posted below for others who 
wish to similarly exclude neighbors' missing attribute values from W style 
spatial lags.

I did not receive any responses to my original message but would still 
appreciate any thoughts or suggestions regarding this approach or the 
general problem of neighbors with missing attribute values. For example, do 
spatial statisticians prefer to impute missing attribute values before 
lagging, or is there a good justification for treating NA as zero when 
calculating spatial lags, thereby pulling lagged values downward?

Thanks,
Chris

-- 
Christopher Moore, M.P.P.
Doctoral Student
Quantitative Methods in Education
University of Minnesota
moor0554 at umn.edu
http://www.tc.umn.edu/~moor0554/


> ##########
> 
> ##Solution developed 12/30/08 attributes <- 
> data.frame(NAME=nc.sids at data$NAME, ID=1:dim(nc.sids at data)[1], 
> SID79=nc.sids at data$SID79) for(i in 1:6) 
> print(merge(data.frame(ID=wts$neighbours[[i]]), attributes, by="ID"))
  ID       NAME SID79
1 17    Caswell     2
2 19    Chatham     3
3 41   Guilford    38
4 68     Orange     6
5 76   Randolph    12
6 79 Rockingham     5
  ID     NAME SID79
1 14 Caldwell     9
2 18  Catawba    21
3 49  Iredell     5
4 97   Wilkes    NA
  ID   NAME SID79
1  5   Ashe     0
2 86  Surry     6
3 97 Wilkes    NA
  ID       NAME SID79
1 62 Montgomery     8
2 77   Richmond     7
3 84     Stanly     7
4 90      Union     9
  ID      NAME SID79
1  3 Alleghany     3
2 95   Watauga     1
3 97    Wilkes    NA
  ID     NAME SID79
1 12    Burke    15
2 14 Caldwell     9
3 56 McDowell     5
4 61 Mitchell     2
5 95  Watauga     1
> attributes$LAG.NEW.W=rep(NA, dim(nc.sids at data)[1]) for(i in 
> 1:dim(nc.sids at data)[1]) attributes[i,"LAG.NEW.W"] <- 
> round(mean(merge(data.frame(ID=wts$neighbours[[i]]), attributes, 
> by="ID")$SID79, na.rm=T), 3) attributes$LAG.ORIG.W <- round(lag(wts, 
> nc.sids at data$SID79), 3) attributes[,c(1,3:5)]
            NAME SID79 LAG.NEW.W LAG.ORIG.W
1       Alamance    11    11.000     11.000
2      Alexander     2    11.667      8.750
3      Alleghany     3     3.000      2.000
4          Anson     4     7.750      7.750
5           Ashe     0     2.000      1.333
6          Avery     0     6.400      6.400
7       Beaufort     4     5.167      5.167
8         Bertie     5     5.200      5.200
9         Bladen     5    21.400     21.400
10     Brunswick     6     9.667      9.667
11      Buncombe    18     5.143      5.143
12         Burke    15    10.143     10.143
13      Cabarrus    20    12.800     12.800
14      Caldwell     9     7.800      6.500
15        Camden     2     2.667      2.667
16      Carteret     4    14.333     14.333
17       Caswell     2    12.800     12.800
18       Catawba    21     9.833      9.833
19       Chatham     3    12.875     12.875
20      Cherokee     1     1.500      1.500
21        Chowan     1     1.000      1.000
22          Clay     0     2.000      2.000
23     Cleveland    21    15.400     15.400
24      Columbus    17    10.000     10.000
25        Craven    18     6.000      6.000
26    Cumberland    57     9.333      9.333
27     Currituck     2     2.000      2.000
28          Dare     1     0.000      0.000
29      Davidson     8    13.429     13.429
30         Davie     3     8.000      8.000
31        Duplin     7    11.500     11.500
32        Durham    22     9.600      9.600
33     Edgecombe     9     9.800      9.800
34       Forsyth    18     9.429      9.429
35      Franklin     0    11.429     11.429
36        Gaston    26    21.000     21.000
37         Gates     2     2.400      2.400
38        Graham     1     2.000      2.000
39     Granville     4    12.600     12.600
40        Greene     4    15.250     15.250
41      Guilford    38     8.714      8.714
42       Halifax    17     3.857      3.857
43       Harnett    10    17.000     17.000
44       Haywood     8     6.500      6.500
45     Henderson     8     7.600      7.600
46      Hertford     5     3.333      3.333
47          Hoke     6    22.200     22.200
48          Hyde     0     1.250      1.250
49       Iredell     5    12.125     10.778
50       Jackson     5     4.250      4.250
51      Johnston    13    12.571     12.571
52         Jones     2    13.200     13.200
53           Lee     6     6.000      6.000
54        Lenoir    14    10.833     10.833
55       Lincoln     7    20.500     20.500
56      McDowell     5     7.333      7.333
57         Macon     3     1.800      1.800
58       Madison     2     9.000      9.000
59        Martin     1     7.667      7.667
60   Mecklenburg    35    13.400     13.400
61      Mitchell     2     2.000      2.000
62    Montgomery     8     7.286      7.286
63         Moore     5    13.889     13.889
64          Nash     7    12.143     12.143
65   New Hanover     9     4.500      4.500
66   Northampton     3     9.000      9.000
67        Onslow    23     4.000      4.000
68        Orange     6     8.400      8.400
69       Pamlico     1    11.000     11.000
70    Pasquotank     4     1.333      1.333
71        Pender     3    10.143     10.143
72    Perquimans     0     2.333      2.333
73        Person     4     8.500      8.500
74          Pitt    11     9.000      9.000
75          Polk     0     8.000      8.000
76      Randolph    12    12.167     12.167
77      Richmond     7     7.667      7.667
78       Robeson    26    20.200     20.200
79    Rockingham     5    14.800     14.800
80         Rowan     8     8.500      8.500
81    Rutherford     8    11.167     11.167
82       Sampson     4    16.857     16.857
83      Scotland    16    11.000     11.000
84        Stanly     7     9.143      9.143
85        Stokes     5    16.750     16.750
86         Surry     6     6.750      5.400
87         Swain     2     3.600      3.600
88  Transylvania     4     9.750      9.750
89       Tyrrell     0     0.000      0.000
90         Union     9    16.500     16.500
91         Vance     6     2.000      2.000
92          Wake    31     8.429      8.429
93        Warren     2     7.500      7.500
94    Washington     0     2.000      2.000
95       Watauga     1     3.000      2.250
96         Wayne    23     9.167      9.167
97        Wilkes    NA     3.375      3.375
98        Wilson    13    11.167     11.167
99        Yadkin     1     8.000      6.400
100       Yancey     1     6.750      6.750
> 
> ##########
>



From hi_ono2001 at ybb.ne.jp  Tue Dec 30 23:01:34 2008
From: hi_ono2001 at ybb.ne.jp (Hisaji ONO)
Date: Wed, 31 Dec 2008 07:01:34 +0900 (JST)
Subject: [R-sig-Geo] Any successful case of Building Rcartogram for Win32
In-Reply-To: <alpine.LRH.2.00.0812302021160.27008@reclus.nhh.no>
Message-ID: <20081230220134.40250.qmail@web10713.mail.bbt.yahoo.co.jp>

Thank you very much for your response.

 I've tried to buid Rcarogram using Rtools, but could not
succeed to configure.


        

--- Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Tue, 30 Dec 2008, Hisaji ONO wrote:
> 
> > Hello.
> >
> >  On this December, Japanese TV program(created by
> TV
> > Tokyo, one of TV broadcast station in Japan) used
> my
> > Java-based  area continued cartogram to generate
> various
> > cartograms.
> >
> >  However my algorithm is too slow.
> >
> >  Rcartogram(http://www.omegahat.org/Rcartogram/) 
> seems
> > to generate cartogram faster and its results very
> good.
> >
> >  Does anyone succeed to build this program on
> Win32?
> 
> You'll need to build by hand with the FFTW3 DLL
> headers - ./configure will 
> most likely not work happily. The FFTW site
> describes Windows 
> installation, but you'll need to modify the source
> package more to help it 
> find the DLL and headers:
> 
> http://www.fftw.org/install/windows.html
> 
> Best wishes,
> 
> Roger
> 
> >
> >
> >  Regards.
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> 
> -- 
> Roger Bivand
> Economic Geography Section, Department of Economics,
> Norwegian School of
> Economics and Business Administration, Helleveien
> 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
> 
>



From Roger.Bivand at nhh.no  Wed Dec 31 12:36:57 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 31 Dec 2008 12:36:57 +0100 (CET)
Subject: [R-sig-Geo] Spatial Lags Excluding Neighbors' Missing Attribute
 Values
In-Reply-To: <Prayer.1.0.16.0812301527410.10033@vs-a.tc.umn.edu>
References: <mailman.5.1230462002.17612.r-sig-geo@stat.math.ethz.ch>
	<Prayer.1.0.16.0812301527410.10033@vs-a.tc.umn.edu>
Message-ID: <alpine.LRH.2.00.0812311223420.5052@reclus.nhh.no>

On Tue, 30 Dec 2008, Christopher Moore wrote:

> Greetings,
>
> I posted a request for assistance on 12/27/08: 
> <https://stat.ethz.ch/pipermail/r-sig-geo/2008-December/004733.html>.
>
> I developed a satisfactory solution, which is posted below for others who 
> wish to similarly exclude neighbors' missing attribute values from W style 
> spatial lags.
>

Well, this is quite a detailed question, and this isn't the best time of 
year to get rapid response. I don't think that your solution is 
satisfactory - and I don't think that there is any viable alternative to 
either imputing to fill all the missing values (I wouldn't do that), or 
subsetting out incomplete cases and using the same subset on the "nb" 
object (there are subset methods). What happens now is that in the 
compiled code in "lagw" the sum is not incremented when the value is not 
finite:

 		sum = 0.0;
 		for (j=0; j<INTEGER_POINTER(card)[i]; j++) {
 		    k = INTEGER_POINTER(VECTOR_ELT(nb, i))[j];
 		    wt = NUMERIC_POINTER(VECTOR_ELT(weights, i))[j];
 		    tmp = NUMERIC_POINTER(x)[k-ROFFSET];
 		    if (R_FINITE(tmp)) sum += tmp * wt;
 		}
 		NUMERIC_POINTER(ans)[i] = sum;

in src/lagw.c. In fact the NAOK argument is not being used, and should be, 
so in the next release you will either get an error, or, for NAOK=TRUE, 
you'll get an NA for the lagged value - that was the intention. If you can 
make a case for a third choice, essentially doing what you describe, I can 
consider it, but being conservative, missing data is missing, really, 
isn't it?

Best wishes,

Roger

> I did not receive any responses to my original message but would still 
> appreciate any thoughts or suggestions regarding this approach or the general 
> problem of neighbors with missing attribute values. For example, do spatial 
> statisticians prefer to impute missing attribute values before lagging, or is 
> there a good justification for treating NA as zero when calculating spatial 
> lags, thereby pulling lagged values downward?
>
> Thanks,
> Chris
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



