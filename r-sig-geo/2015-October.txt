From loredana.mirra at uniroma2.it  Thu Oct  1 12:56:17 2015
From: loredana.mirra at uniroma2.it (Loredana Mirra)
Date: Thu, 1 Oct 2015 12:56:17 +0200
Subject: [R-sig-Geo] Spatial Durbin Model with regimes in a cross section
	framework
Message-ID: <002701d0fc37$cc9286a0$65b793e0$@uniroma2.it>

I am writing to ask you a suggestion about the availability of a R routine
or piece of program for the purposes of my empirical analysis. I should
revise my paper using a Spatial Durbin model. This was recommended in order
to mitigate a problem due to the possible presence of unobserved factors.

Unfortunately data do not permit to perform a panel but a cross section
analysis. I do not have troubles to perform a Spatial Durbin Model on the
entire sample, but I need to study the presence of Spatial Regimes. The
problem is that I cannot find a program, in a cross sections framework. Do
you know if there is a program available in R to perform this analysis?
Thank you very much in advance for your help.

Best regards

Loredana Mirra





-------------------------



Dott.ssa  Loredana Mirra

Universit? di Roma ?Tor Vergata?

Dipartimento di Economia Diritto e Istituzioni

Via Columbia, 2

00133 Roma

Italia

tel. +390672595725

 <mailto:pozzolo at unimol.it> loredana.mirra at uniroma2.it





---
Questa e-mail ? stata controllata per individuare virus con Avast antivirus.
https://www.avast.com/antivirus

	[[alternative HTML version deleted]]


From pius.korner at bluewin.ch  Thu Oct  1 18:11:37 2015
From: pius.korner at bluewin.ch (Pius Korner)
Date: Thu, 1 Oct 2015 18:11:37 +0200
Subject: [R-sig-Geo] gIntersection with drop_lower_td=T drops entire
	intersection
Message-ID: <002601d0fc63$d9a42700$8cec7500$@bluewin.ch>

Dear all

 

I intersect a SpatialPolygons-Object with two polygons 1a and 1b with a
polygon 2. Polygon 1a intersects with polygon 2 in one area but also only
touches polygon 2 at another position.

Here a schematic case for illustration:

 

poly1 <-
SpatialPolygons(list(Polygons(list(Polygon(coords=matrix(c(0,0,2,2,0,1,1,0),
ncol=2,byrow=F))),ID=c("a")),

 
Polygons(list(Polygon(coords=matrix(c(0,0,2,2,2,3,3,2),ncol=2,byrow=F))),ID=
c("b"))))

poly2 <-
SpatialPolygons(list(Polygons(list(Polygon(coords=matrix(c(0,0,2,2,1,1,1,3,3
,0,0,2),ncol=2,byrow=F))),ID=c("c"))))

plot(poly1,border="orange")

plot(poly2,border="blue",add=T,lty=2,density=8,angle=30,col="blue")

 

I'm interested in the area of overlap of polygons 1a and 1b with polygon 2.

gIntersection(poly1,poly2,byid=T)

does not work because of the different subgeometries that result from the
intersection of 1a with 2; they cannot be collected.

gIntersection(poly1,poly2,byid=T,drop_lower_td=T)

drops the entire intersection between 1a with 2, hence I get no value for
1a, even though it does overlap with polygon 2.

 

Is there a way so that only the Point-subgeometries (with area=0) are
dropped, but the Polygon-subgeometry is retained and returned for the
intersection of 1a and 2?

 

my temporary workaround was to very slightly buffer poly1 (width=-0.0001),
to prevent the point-subgeometry.

I could create a loop and intersect each polygon in poly1 separately, but
using byid=T would be nicer (faster..)

 

many thanks

Pius


	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Thu Oct  1 20:44:47 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 1 Oct 2015 20:44:47 +0200
Subject: [R-sig-Geo] Spatial Durbin Model with regimes in a cross
 section framework
In-Reply-To: <002701d0fc37$cc9286a0$65b793e0$@uniroma2.it>
References: <002701d0fc37$cc9286a0$65b793e0$@uniroma2.it>
Message-ID: <alpine.LFD.2.20.1510012027050.9283@reclus.nhh.no>

On Thu, 1 Oct 2015, Loredana Mirra wrote:

> I am writing to ask you a suggestion about the availability of a R routine
> or piece of program for the purposes of my empirical analysis. I should
> revise my paper using a Spatial Durbin model. This was recommended in order
> to mitigate a problem due to the possible presence of unobserved factors.
>
> Unfortunately data do not permit to perform a panel but a cross section
> analysis. I do not have troubles to perform a Spatial Durbin Model on the
> entire sample, but I need to study the presence of Spatial Regimes. The
> problem is that I cannot find a program, in a cross sections framework. Do
> you know if there is a program available in R to perform this analysis?

How do you want to handle the "regimes"? Estimate separate coefficients 
for each regime (regime defined as a factor)? If so, this is a standard 
formula construction, and can be used with formula objects in model 
fitting functions:

lm(mpg ~ 0 + I(factor(am))/(disp + wt), data=mtcars)

or similar - check in detailed discussions of formula objects.

You need to be careful to report impacts, not coefficient values, from the 
Spatial Durbin model.

Hope this helps,

Roger

> Thank you very much in advance for your help.
>
> Best regards
>
> Loredana Mirra
>
>
>
>
>
> -------------------------
>
>
>
> Dott.ssa  Loredana Mirra
>
> Universit??? di Roma ???Tor Vergata???
>
> Dipartimento di Economia Diritto e Istituzioni
>
> Via Columbia, 2
>
> 00133 Roma
>
> Italia
>
> tel. +390672595725
>
> <mailto:pozzolo at unimol.it> loredana.mirra at uniroma2.it
>
>
>
>
>
> ---
> Questa e-mail ??? stata controllata per individuare virus con Avast antivirus.
> https://www.avast.com/antivirus
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From jay.verstreater at gmail.com  Thu Oct  1 21:03:15 2015
From: jay.verstreater at gmail.com (Jay Verstreater)
Date: Thu, 1 Oct 2015 14:03:15 -0500
Subject: [R-sig-Geo] Zip Code Data
Message-ID: <CAJueOzp=z2TrEh1CEtHYT2UpVjkx=Xtg2L-6YTFZxqM6YVoCNQ@mail.gmail.com>

How would I go about figuring out how many clusters of zip codes are in my
data and then analyze from there?

Any suggestions would be greatly appreciated!

Thanks,

Jay Verstreater
217-556-8100

	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Thu Oct  1 21:54:45 2015
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 1 Oct 2015 20:54:45 +0100
Subject: [R-sig-Geo] Zip Code Data
In-Reply-To: <CAJueOzp=z2TrEh1CEtHYT2UpVjkx=Xtg2L-6YTFZxqM6YVoCNQ@mail.gmail.com>
References: <CAJueOzp=z2TrEh1CEtHYT2UpVjkx=Xtg2L-6YTFZxqM6YVoCNQ@mail.gmail.com>
Message-ID: <CANVKczND2Tke+MeZUCxRajnbsNzLUxou2_ZvzejiMooX=0M2bg@mail.gmail.com>

What do you mean by "cluster"? Aren't zip codes clustered more in
urban areas than rural anyway? What's the question you want answered
about the data?

There should be something in the spatial statistics realm that can
help you, but figuring out exactly what is the tricky bit...

Barry


On Thu, Oct 1, 2015 at 8:03 PM, Jay Verstreater
<jay.verstreater at gmail.com> wrote:
> How would I go about figuring out how many clusters of zip codes are in my
> data and then analyze from there?
>
> Any suggestions would be greatly appreciated!
>
> Thanks,
>
> Jay Verstreater
> 217-556-8100
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From jay.verstreater at gmail.com  Fri Oct  2 02:00:18 2015
From: jay.verstreater at gmail.com (Jay Verstreater)
Date: Thu, 1 Oct 2015 19:00:18 -0500
Subject: [R-sig-Geo] Zip Code Data
In-Reply-To: <CANVKczND2Tke+MeZUCxRajnbsNzLUxou2_ZvzejiMooX=0M2bg@mail.gmail.com>
References: <CAJueOzp=z2TrEh1CEtHYT2UpVjkx=Xtg2L-6YTFZxqM6YVoCNQ@mail.gmail.com>
	<CANVKczND2Tke+MeZUCxRajnbsNzLUxou2_ZvzejiMooX=0M2bg@mail.gmail.com>
Message-ID: <0E434523-4680-4E6E-A7D0-0F3867A41ACE@gmail.com>

I'm trying to see if there is more significance in a cluster of zip codes vs single zip codes based on a mileage rate (linehaul charge). Looking to figure out directionality in pricing/rate structures. As of right now I only know how to do a model on zip codes. I want to see if grouping/clustering zip codes in regions across the US would have more of an impact on the rates.

Thanks,

Jay Verstreater
217-556-8100

> On Oct 1, 2015, at 2:54 PM, Barry Rowlingson <b.rowlingson at lancaster.ac.uk> wrote:
> 
> What do you mean by "cluster"? Aren't zip codes clustered more in
> urban areas than rural anyway? What's the question you want answered
> about the data?
> 
> There should be something in the spatial statistics realm that can
> help you, but figuring out exactly what is the tricky bit...
> 
> Barry
> 
> 
> On Thu, Oct 1, 2015 at 8:03 PM, Jay Verstreater
> <jay.verstreater at gmail.com> wrote:
>> How would I go about figuring out how many clusters of zip codes are in my
>> data and then analyze from there?
>> 
>> Any suggestions would be greatly appreciated!
>> 
>> Thanks,
>> 
>> Jay Verstreater
>> 217-556-8100
>> 
>>        [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From jgrn at illinois.edu  Fri Oct  2 04:27:11 2015
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Fri, 02 Oct 2015 02:27:11 +0000
Subject: [R-sig-Geo] Major update to gdalUtils now on R-Forge...
Message-ID: <CABG0rfu2GnDo3TtM3d64QZic9WUdKwsUapyfucSBib5eJH1dbQ@mail.gmail.com>

R GIS'ers:

At long last, I've gotten around to getting gdalUtils updated (mostly) for
GDAL 2.0.  All available functions should now fully support GDAL 2.0.  I
have also added in wrappers for (most) of the new utilities added since
1.11.  I'll try to finish up the last of the wrappers ASAP, and push the
new package to CRAN, but for now, if anyone wants to play around with the
new version, please check out:

https://r-forge.r-project.org/R/?group_id=1695

install.packages("gdalUtils", repos="http://R-Forge.R-project.org")

A few exciting updates:

mosaic_rasters now works better and can support much larger mosaic inputs
(in theory, there should be no limitation on the number of input files you
can use with mosaic_raster).  I've also added a few helpful new parameters
such as "trim_margins" which allows you to pre-trim the margins of your
input tiles before they are mosaicked.  This can help with small NA edges
that are causing headaches with overlapping datasets.

align_rasters: my personal favorite new utility.  This allows for rapid
"syncing" of two rasters -- one raster is warped to match the CMS, extent,
and pixel size of another -- this is great for lining up datasets for map
algebra problems.  This is significantly faster than "spatial_sync_raster"
function in my other package, spatial.tools.  This also supports multi-core
processing, as well as a large number of warping options (anything
available in gdalwarp).  Drop this in a loop, and you can sync a large
number of rasters to a consistent extent.

I'm looking for some beta-testers to put the algorithms through the ringer,
so please let me know if you find any bugs.  I've tried to squash the bugs
that have been reported to me over the last few months.

For those of you who aren't familiar with this package, this provides
wrappers to the gdal raster (http://www.gdal.org/gdal_utilities.html) and
vector (http://www.gdal.org/ogr_utilities.html) command line utilities.
You MUST have gdal installed on your system before using the package.

Enjoy!

--j

	[[alternative HTML version deleted]]


From loredana.mirra at uniroma2.it  Fri Oct  2 10:43:23 2015
From: loredana.mirra at uniroma2.it (Loredana Mirra)
Date: Fri, 2 Oct 2015 10:43:23 +0200
Subject: [R-sig-Geo] Spatial Durbin Model with regimes in a cross
	section framework
Message-ID: <002c01d0fcee$6641f900$32c5eb00$@uniroma2.it>


Thank you very much for your kind help. Yes, I should check also if, after
having estimated separated coefficients,  the difference, if any, is
statistically significant (using a chow test). Implementing such test is the
major issue to me. Can you give me an hint about this? 
Thanks also for the suggestion about the interpretation of output in SDM.
Best Regards
Loredana
-----Messaggio originale-----
Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
Inviato: gioved? 1 ottobre 2015 20:45
A: Loredana Mirra
Cc: r-sig-geo at r-project.org
Oggetto: Re: [R-sig-Geo] Spatial Durbin Model with regimes in a cross
section framework

On Thu, 1 Oct 2015, Loredana Mirra wrote:

> I am writing to ask you a suggestion about the availability of a R 
> routine or piece of program for the purposes of my empirical analysis.
> I should revise my paper using a Spatial Durbin model. This was 
> recommended in order to mitigate a problem due to the possible presence of
unobserved factors.
>
> Unfortunately data do not permit to perform a panel but a cross 
> section analysis. I do not have troubles to perform a Spatial Durbin 
> Model on the entire sample, but I need to study the presence of 
> Spatial Regimes. The problem is that I cannot find a program, in a 
> cross sections framework. Do you know if there is a program available in R
to perform this analysis?

How do you want to handle the "regimes"? Estimate separate coefficients for
each regime (regime defined as a factor)? If so, this is a standard formula
construction, and can be used with formula objects in model fitting
functions:

lm(mpg ~ 0 + I(factor(am))/(disp + wt), data=mtcars)

or similar - check in detailed discussions of formula objects.

You need to be careful to report impacts, not coefficient values, from the
Spatial Durbin model.

Hope this helps,

Roger

> Thank you very much in advance for your help.
>
> Best regards
>
> Loredana Mirra
>
>
>
>
>
> -------------------------
>
>
>
> Dott.ssa  Loredana Mirra
>
> Universit??? di Roma ???Tor Vergata???
>
> Dipartimento di Economia Diritto e Istituzioni
>
> Via Columbia, 2
>
> 00133 Roma
>
> Italia
>
> tel. +390672595725
>
> <mailto:pozzolo at unimol.it> loredana.mirra at uniroma2.it
>
>
>
>
>
> ---
> Questa e-mail ??? stata controllata per individuare virus con Avast
antivirus.
> https://www.avast.com/antivirus
>
> 	[[alternative HTML version deleted]]
>
>

--
Roger Bivand
Department of Economics, Norwegian School of Economics, Helleveien 30,
N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


---
Questa e-mail ? stata controllata per individuare virus con Avast antivirus.
https://www.avast.com/antivirus


From Roger.Bivand at nhh.no  Fri Oct  2 10:59:24 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 2 Oct 2015 10:59:24 +0200
Subject: [R-sig-Geo] Spatial Durbin Model with regimes in a cross
 section framework
In-Reply-To: <002c01d0fcee$6641f900$32c5eb00$@uniroma2.it>
References: <002c01d0fcee$6641f900$32c5eb00$@uniroma2.it>
Message-ID: <alpine.LFD.2.20.1510021049140.28317@reclus.nhh.no>

On Fri, 2 Oct 2015, Loredana Mirra wrote:

>
> Thank you very much for your kind help. Yes, I should check also if, after
> having estimated separated coefficients,  the difference, if any, is
> statistically significant (using a chow test). Implementing such test is the
> major issue to me. Can you give me an hint about this?

Please see ch. 4 in Kleiber and Zeilis (2008) Applied Econometrics with R. 
You may use anova() on the no-regime model and the regime model, which is 
equivalent to a Chow test (personal communication, Achim Zeileis, 2005). 
It will however suffer from misspecification such as outliers, discussed 
in section 4.3 and the use of a Wald test with an HC covariance matrix.

> Thanks also for the suggestion about the interpretation of output in SDM.

A "Chow" test might go through a Likelihood Ratio test, but should 
arguably be presented using the empirical distributions of the impacts for 
each X variable for the no-regime model and for each regime.

Hope this helps,

Roger

> Best Regards
> Loredana
> -----Messaggio originale-----
> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Inviato: gioved? 1 ottobre 2015 20:45
> A: Loredana Mirra
> Cc: r-sig-geo at r-project.org
> Oggetto: Re: [R-sig-Geo] Spatial Durbin Model with regimes in a cross
> section framework
>
> On Thu, 1 Oct 2015, Loredana Mirra wrote:
>
>> I am writing to ask you a suggestion about the availability of a R
>> routine or piece of program for the purposes of my empirical analysis.
>> I should revise my paper using a Spatial Durbin model. This was
>> recommended in order to mitigate a problem due to the possible presence of
> unobserved factors.
>>
>> Unfortunately data do not permit to perform a panel but a cross
>> section analysis. I do not have troubles to perform a Spatial Durbin
>> Model on the entire sample, but I need to study the presence of
>> Spatial Regimes. The problem is that I cannot find a program, in a
>> cross sections framework. Do you know if there is a program available in R
> to perform this analysis?
>
> How do you want to handle the "regimes"? Estimate separate coefficients for
> each regime (regime defined as a factor)? If so, this is a standard formula
> construction, and can be used with formula objects in model fitting
> functions:
>
> lm(mpg ~ 0 + I(factor(am))/(disp + wt), data=mtcars)
>
> or similar - check in detailed discussions of formula objects.
>
> You need to be careful to report impacts, not coefficient values, from the
> Spatial Durbin model.
>
> Hope this helps,
>
> Roger
>
>> Thank you very much in advance for your help.
>>
>> Best regards
>>
>> Loredana Mirra
>>
>>
>>
>>
>>
>> -------------------------
>>
>>
>>
>> Dott.ssa  Loredana Mirra
>>
>> Universit??? di Roma ???Tor Vergata???
>>
>> Dipartimento di Economia Diritto e Istituzioni
>>
>> Via Columbia, 2
>>
>> 00133 Roma
>>
>> Italia
>>
>> tel. +390672595725
>>
>> <mailto:pozzolo at unimol.it> loredana.mirra at uniroma2.it
>>
>>
>>
>>
>>
>> ---
>> Questa e-mail ??? stata controllata per individuare virus con Avast
> antivirus.
>> https://www.avast.com/antivirus
>>
>> 	[[alternative HTML version deleted]]
>>
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics, Helleveien 30,
> N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
>
> ---
> Questa e-mail ? stata controllata per individuare virus con Avast antivirus.
> https://www.avast.com/antivirus
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From Gema.FAviles at uclm.es  Sat Oct  3 09:45:18 2015
From: Gema.FAviles at uclm.es (GEMA FERNANDEZ-AVILES CALDERON)
Date: Sat, 3 Oct 2015 07:45:18 +0000
Subject: [R-sig-Geo] Universal kriging with geoR
References: <VI1PR01MB0973AE0E0EE0BD6DE5C51377974C0@VI1PR01MB0973.eurprd01.prod.exchangelabs.com>
Message-ID: <CBF16964-8A88-4ED6-A648-DA225709315A@uclm.es>

Dear list,

I have a computational error and I can not found the solution...

I would like to perform an Universal Kriging with geoR. I have a geodata object: log(price), long, lat and pollution, but 'krige.conv' and 'ksline' functions give me the same error: system is computationally singular.

Any ideas will be appreciated.

Thanks in advance,
Gema

PS: I can send you the data to run the code


############################################################################

# read the data and create a geodata object
attach(Datos)
bordes.munimadrid=read.table("MuniMadrid.txt")
coord=cbind(long,lat)
uk.vivi<-cbind(coord , log(Datos$precio.house.x), Mal_olor )
obj.uk.vivi<-as.geodata(obj=uk.vivi, coords.col = 1:2, data.col = 3,
              covar.col = 4 ,covar.names = "Pollution" )
summary(obj.uk.vivi)

#Number of data points: 300
#
#Coordinates summary
#      long     lat
#min 433426 4466197
#max 451184 4484681
#
#Distance summary
#     min      max
#   19.18 20836.71
#
#Data summary
#   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
#   6.91    7.94    8.19    8.16    8.43    9.28
#
#Covariates summary
#    Mal_olor
# Min.   :0.080
# 1st Qu.:0.210
# Median :0.260
# Mean   :0.281
# 3rd Qu.:0.330
# Max.   :0.720


## I woulk like to use this spatial trend but UK doesn't run
sp.tren.rp=trend.spatial("1st", obj.uk.vivi, add=~Mal_olor)

# Universal kriging with geoR() first option
loci <- expand.grid(seq(424854, 456141, l = 101), seq(4462788, 4499622, l = 101))
UK.krig.viviendas <- krige.conv(obj.uk.vivi, loc = loci, borders = bordes.munimadrid,
              krige = krige.control(type.krige = "ok", cov.model = "gau",
              cov.pars = c(0.06, 3000), nug = 0.05, trend.l = "1st", trend.d ="1st") )

krige.conv: results will be returned only for prediction locations inside the borders
krige.conv: model with mean given by a 1st order polynomial on the coordinates
Error in solve.default(ttivtt, crossprod(ivtt, as.vector(data))) :
  sistema es computacionalmente singular: n?mero de condici?n rec?proco = 6.8379e-20


# Universal kriging with geoR() second option
uk.2= ksline(obj.uk.vivi, coords = obj.uk.vivi$coords, data = obj.uk.vivi$data,
       loc = loci, borders = bordes.munimadrid,
       cov.model = "gau",  cov.pars=c(0.06, 3000), nug = 0.05,
       lambda = 1, m0 = "kt", nwin = "full",
       trend = 1, d = 2 )

ksline: results will be returned only for prediction locations inside the borders
Error in solve.default(crossprod(xmat, iv) %*% xmat) :
sistema es computacionalmente singular: n?mero de condici?n rec?proco = 6.8379e-20

############################################################################


	[[alternative HTML version deleted]]


From john_gross at nps.gov  Sun Oct  4 21:48:16 2015
From: john_gross at nps.gov (Gross, John)
Date: Sun, 4 Oct 2015 13:48:16 -0600
Subject: [R-sig-Geo] ncdf 4-dim file to raster brick - level error??
Message-ID: <CAM_gmgOLkEKrZA563tm6yPcmF_Z3h=EYjp+W6o2GAe1w458JKw@mail.gmail.com>

I'm trying to read a 4-dimensional ncdf file (dims: lat lon time
projection) into a raster brick and can't get it to read anything
other than the first "level" (i.e. projection, the 4th dimension).

Here's the code, output, and sessionInfo.  This is reminiscent of a
problem a couple years ago with earlier versions of both ncdf4 and
raster that was caused by the ncdf file not closing between calls  But
I'm not sure how to determine it that's happening again.

You can download the data file (10KB - it's only 3x3x59x4) from:
https://www.dropbox.com/s/5jh5n8etpk1y1hu/Extraction_tasmin.nc?dl=0

#===  Code ==========
library(ncdf4)
library(raster)

nc <- nc_open("Extraction_tasmin.nc")    # this is a 3x3 text grid
nc    # dims are lat long time and projection

xy <- data.frame(x = min(nc$dim$lon$vals) + 1/32, y =
max(nc$dim$lat$vals) - 1/32) #get top left point not on grid boundary
coordinates(xy) <- ~x+y

for(i in 1:5){
  b1 <- brick("Extraction_tasmin.nc", lvar=4, level=i)
  pts <- t(extract(b1, xy))
  print(c("pts[1:5} -> ",pts[1:5])); flush.console()
}
#====  Output  =======

File Extraction_tasmin.nc (NC_FORMAT_CLASSIC):

     1 variables (excluding dimension variables):
        float tasmin[longitude,latitude,time,projection]
            typeConversion_op_ncl: double converted to float
            _FillValue: 1.00000002004088e+20

     4 dimensions:
        latitude  Size:3
            valid_max: 52.875
            long_name: Latitude
            valid_min: 25.125
            units: degrees_north
            axis: Y
        longitude  Size:3
            long_name: Longitude
            axis: X
            units: degrees_east
            modulo: 360
            topology: circular
        time  Size:59
            calendar: standard
            units: days since 1950-01-01 00:00:00
            standard_name: time
            long_name: time
            axis: T
        projection  Size:4   *** is unlimited ***

    2 global attributes:
        NCO: 4.0.8
        Projections: access1-0.1.rcp85, bcc-csm1-1.1.rcp85,
canesm2.1.rcp85, ccsm4.1.rcp85,
>

Output:
[1] "pts[1:5} -> "      "-5.08642387390137" "-3.23856282234192"
"-5.46992635726929" "-3.83646535873413" "-3.00846982002258"
[1] "pts[1:5} -> "      "-5.08642387390137" "-3.23856282234192"
"-5.46992635726929" "-3.83646535873413" "-3.00846982002258"
[1] "pts[1:5} -> "      "-5.08642387390137" "-3.23856282234192"
"-5.46992635726929" "-3.83646535873413" "-3.00846982002258"
[1] "pts[1:5} -> "      "-5.08642387390137" "-3.23856282234192"
"-5.46992635726929" "-3.83646535873413" "-3.00846982002258"
[1] "pts[1:5} -> "      "-5.08642387390137" "-3.23856282234192"
"-5.46992635726929" "-3.83646535873413" "-3.00846982002258"
Warning message:
In .rasterObjectFromCDF(x, type = objecttype, band = band, ...) :
  level set to: 4
# ==== sessionInfo =========
R version 3.2.2 (2015-08-14)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.10.5 (Yosemite)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] ncdf4_1.13    raster_2.4-18 sp_1.1-1

loaded via a namespace (and not attached):
[1] rgdal_1.0-4     tools_3.2.2     Rcpp_0.12.1     grid_3.2.2
lattice_0.20-33

-- 
John Gross, PhD
NPS, Ft Collins, CO


From paulojus at c3sl.ufpr.br  Mon Oct  5 01:25:40 2015
From: paulojus at c3sl.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Sun, 4 Oct 2015 20:25:40 -0300 (BRT)
Subject: [R-sig-Geo] Universal kriging with geoR
In-Reply-To: <CBF16964-8A88-4ED6-A648-DA225709315A@uclm.es>
References: <VI1PR01MB0973AE0E0EE0BD6DE5C51377974C0@VI1PR01MB0973.eurprd01.prod.exchangelabs.com>
	<CBF16964-8A88-4ED6-A648-DA225709315A@uclm.es>
Message-ID: <alpine.DEB.2.10.1510042024440.26187@macalan.c3sl.ufpr.br>

try dividind the coordinates by 1000
and let me know

apparently they are given in UTM, therefore meters, this will change to 
kilometers

If this does not run please send me the data



Paulo Justiniano Ribeiro Jr
LEG (Laboratorio de Estatistica e Geoinformacao)
Universidade Federal do Parana
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 3361 3573
VOIP: (+55) (41) (3361 3600) 1053 1066
Fax: (+55) 41 3361 3141
e-mail: paulojus AT  ufpr  br
http://www.leg.ufpr.br/~paulojus

On Sat, 3 Oct 2015, GEMA FERNANDEZ-AVILES CALDERON wrote:

> Dear list,
>
> I have a computational error and I can not found the solution...
>
> I would like to perform an Universal Kriging with geoR. I have a geodata object: log(price), long, lat and pollution, but 'krige.conv' and 'ksline' functions give me the same error: system is computationally singular.
>
> Any ideas will be appreciated.
>
> Thanks in advance,
> Gema
>
> PS: I can send you the data to run the code
>
>
> ############################################################################
>
> # read the data and create a geodata object
> attach(Datos)
> bordes.munimadrid=read.table("MuniMadrid.txt")
> coord=cbind(long,lat)
> uk.vivi<-cbind(coord , log(Datos$precio.house.x), Mal_olor )
> obj.uk.vivi<-as.geodata(obj=uk.vivi, coords.col = 1:2, data.col = 3,
>              covar.col = 4 ,covar.names = "Pollution" )
> summary(obj.uk.vivi)
>
> #Number of data points: 300
> #
> #Coordinates summary
> #      long     lat
> #min 433426 4466197
> #max 451184 4484681
> #
> #Distance summary
> #     min      max
> #   19.18 20836.71
> #
> #Data summary
> #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> #   6.91    7.94    8.19    8.16    8.43    9.28
> #
> #Covariates summary
> #    Mal_olor
> # Min.   :0.080
> # 1st Qu.:0.210
> # Median :0.260
> # Mean   :0.281
> # 3rd Qu.:0.330
> # Max.   :0.720
>
>
> ## I woulk like to use this spatial trend but UK doesn't run
> sp.tren.rp=trend.spatial("1st", obj.uk.vivi, add=~Mal_olor)
>
> # Universal kriging with geoR() first option
> loci <- expand.grid(seq(424854, 456141, l = 101), seq(4462788, 4499622, l = 101))
> UK.krig.viviendas <- krige.conv(obj.uk.vivi, loc = loci, borders = bordes.munimadrid,
>              krige = krige.control(type.krige = "ok", cov.model = "gau",
>              cov.pars = c(0.06, 3000), nug = 0.05, trend.l = "1st", trend.d ="1st") )
>
> krige.conv: results will be returned only for prediction locations inside the borders
> krige.conv: model with mean given by a 1st order polynomial on the coordinates
> Error in solve.default(ttivtt, crossprod(ivtt, as.vector(data))) :
>  sistema es computacionalmente singular: n?mero de condici?n rec?proco = 6.8379e-20
>
>
> # Universal kriging with geoR() second option
> uk.2= ksline(obj.uk.vivi, coords = obj.uk.vivi$coords, data = obj.uk.vivi$data,
>       loc = loci, borders = bordes.munimadrid,
>       cov.model = "gau",  cov.pars=c(0.06, 3000), nug = 0.05,
>       lambda = 1, m0 = "kt", nwin = "full",
>       trend = 1, d = 2 )
>
> ksline: results will be returned only for prediction locations inside the borders
> Error in solve.default(crossprod(xmat, iv) %*% xmat) :
> sistema es computacionalmente singular: n?mero de condici?n rec?proco = 6.8379e-20
>
> ############################################################################
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

From clusk at waikato.ac.nz  Mon Oct  5 03:31:15 2015
From: clusk at waikato.ac.nz (Christopher Lusk)
Date: Mon, 5 Oct 2015 14:31:15 +1300
Subject: [R-sig-Geo] multi-map figure
Message-ID: <CABqyKtsD=Mj1fL5T1FwFMVLPWepX8C+5u=dtB5j1g16x_NsQqw@mail.gmail.com>

Hi - I want to combine 3 maps in one figure, showing geographic patterns of
species richness. Looks OK with the script below, but as the axes are the
same on all 3 maps, I've been trying to remove the space between the 3
panels, and get rid of y-axis ticks and tick labels on panels (b) and (c)
as well. But neither of these is happening, despite several approaches. Can
anyone see what I need to change? Any advice would be appreciated. The data
can be downloaded here:

http://sci.waikato.ac.nz/sites/clusk/DivrepNZ.csv
....................

library(maps)
library(mapdata)

par(mfrow = c(1, 3))
par(mar = c(0, 0, 0, 0), oma = c(1, 1.5, 0.5, 0.5))

map("worldHires","New Zealand", xlim=c(166,179),ylim=c(-48,-34),lty=1,
col="gray", fill=FALSE)
title(xlab = NULL, ylab="Latitude (degrees S)", cex.lab=1.2)
map.axes(cex.axis=0.85, las=1)
DivrepNZ <- read.csv("DivrepNZ.csv")
z <- DivrepNZ$Nativearborescent
zcol <- colorRampPalette(c('greenyellow', 'green4',
'black'))(100)[as.numeric(cut(z, breaks = 100))]
points(DivrepNZ$lon, DivrepNZ$lat, pch = 15, cex = 0.45, col = zcol)
box()
text(178,-35, "(a)", cex=1.2)
xleft <- 167
xright <- 168
ybot <- -39
yint <- (39 - 35) / 100
ytop <- ybot + yint
for(c in colorRampPalette(c('greenyellow', 'green4', 'black'))(100))
{ybot = ybot + yint
  ytop = ytop + yint
  rect(xleft, ybot, xright, ytop, border = NA, col = c)
  print(c(xleft, xright, ybot, ytop, c))
}
labels <- round(seq(min(z), max(z), length.out = 5),2)
text(c(xright + 0.2),
     seq(-39, -35, length.out = 5),
     labels = as.character(labels),
     cex = 0.85,
     pos = 4)
text(178, -35, "(a)")

map("worldHires","New Zealand", xlim=c(166,179),ylim=c(-48,-34),lty=1,
col="gray", fill=FALSE, yaxt=NULL)
title(xlab = "Longitude (degrees E)", ylab=NULL, cex.lab=1.2)
map.axes(cex.axis=0.85, las=1)
DivrepNZ <- read.csv("DivrepNZ.csv")
z <- DivrepNZ$Divaricates
zcol <- colorRampPalette(c('orange', 'orangered4',
'black'))(100)[as.numeric(cut(z, breaks = 100))]
points(DivrepNZ$lon, DivrepNZ$lat, pch = 15, cex = 0.45, col = zcol)
box()
text(178,-35, "(b)", cex=1.2)
xleft <- 167
xright <- 168
ybot <- -39
yint <- (39 - 35) / 100
ytop <- ybot + yint
for(c in colorRampPalette(c('orange', 'orangered4', 'black'))(100))
{ybot = ybot + yint
  ytop = ytop + yint
  rect(xleft, ybot, xright, ytop, border = NA, col = c)
  print(c(xleft, xright, ybot, ytop, c))
}
labels <- round(seq(min(z), max(z), length.out = 5),2)
text(c(xright + 0.2),
     seq(-39, -35, length.out = 5),
     labels = as.character(labels),
     cex = 0.85,
     pos = 4)
text(178, -35, "(b)")

map("worldHires","New Zealand", xlim=c(166,179),ylim=c(-48,-34),lty=1,
col="gray", fill=FALSE, yaxt=NULL)
Show axes with horizontal tick labels
map.axes(cex.axis=0.85, las=1)
title(xlab = NULL, ylab=NULL, cex.lab=1.2)
DivrepNZ <- read.csv("DivrepNZ.csv")
z <- DivrepNZ$divrep
zcol <- colorRampPalette(c('lightskyblue', 'deepskyblue4',
'black'))(100)[as.numeric(cut(z, breaks = 100))]
points(DivrepNZ$lon, DivrepNZ$lat, pch = 15, cex = 0.45, col = zcol)
box()
text(178,-35, "(c)", cex=1.2)
xleft <- 167
xright <- 168
ybot <- -39
yint <- (39 - 35) / 100
ytop <- ybot + yint
for(c in colorRampPalette(c('lightskyblue', 'deepskyblue4', 'black'))(100))
{ybot = ybot + yint
  ytop = ytop + yint
  rect(xleft, ybot, xright, ytop, border = NA, col = c)
  print(c(xleft, xright, ybot, ytop, c))
}
labels <- round(seq(min(z), max(z), length.out = 6),2)
text(c(xright + 0.2),
     seq(-39, -35, length.out = 6),
     labels = as.character(labels),
     cex = 0.85,
     pos = 4)
text(178, -35, "(c)")


--
Dr. Chris Lusk
Environmental Research Institute
The University of Waikato
Private Bag 3105, Hamilton
New Zealand / Aotearoa
http://sci.waikato.ac.nz/sites/clusk/
Ph 64 7 838 4205
~  ~  ~  ~  ~  ~  ~

	[[alternative HTML version deleted]]


From jgrn at illinois.edu  Mon Oct  5 08:20:57 2015
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Mon, 05 Oct 2015 06:20:57 +0000
Subject: [R-sig-Geo] gdalUtils 2.0.1 now on CRAN
Message-ID: <CABG0rfvvVruXOsmUJQsUheriK0zSZzDdzDTy_zy5AS__ETypRw@mail.gmail.com>

Following on my announcement a few days ago, gdalUtils 2.0.1 is now
available on CRAN, updated to support the latest version of GDAL.  As
always, please install GDAL first before using gdalUtils.  Let me know if
you find any bugs!

--j

	[[alternative HTML version deleted]]


From juamecos at gmail.com  Mon Oct  5 13:28:49 2015
From: juamecos at gmail.com (juan jose mena)
Date: Mon, 5 Oct 2015 13:28:49 +0200
Subject: [R-sig-Geo] Euclidean Nearest Neighbour
Message-ID: <CANK1-ktWBjhTgA2a+YvoXHJ64Sx8pFRraGwTN=fvCvVL4eFdyQ@mail.gmail.com>

Hi all,

I am performing a Landscape structure analysis with a raster layer and
using SDMtools package in R. I got some metrics of my interest by means of
ClassStat and PatchStat functions but any of them perform the Euclidean
Nearest Neighbour. So, any of you could tell me a package or a function to
calculate this metric or another connectivity metric to analyze the
isolation?

Thanks in advance

Juan Jos? Mena Costa

	[[alternative HTML version deleted]]


From gbl1 at hi.is  Mon Oct  5 17:39:55 2015
From: gbl1 at hi.is (Gilles Benjamin Leduc)
Date: Mon, 05 Oct 2015 15:39:55 +0000
Subject: [R-sig-Geo] Euclidean Nearest Neighbour
In-Reply-To: <CANK1-kskM76kgZs8vMS0Enjg2Xyu4h29RBBwWajvX+AnHKnzCQ@mail.gmail.com>
Message-ID: <2bca-56129a00-213-49184300@124128235>

I try to  understand... 

So, 

First install this dev package: Linarius. 

library(devtools) 
install_github("giby/Linarius) 
library(Linarius)
 
Then lets load a test dataset: 

data(Leymus)

You may find the distances between all your spot like this 

distGPS(locations[,1], locations[,2],rownames(locations)) #by default use the Lambert approximation 


So lets create a matrix to work on: 

as.matrix(distGPS(locations[,1], locations[,2],rownames(locations)))->distances 

Ugly way to remove 0: 

distances[distances==0]<-100000


then obtain the minimal distance from every place: 
apply(distances,1,min) #look what you obtain 
apply(distances,1,min)->min.dist #keep this object 

 Lets now introduce the type of every place 

type<-c("Artificial", "Pine forest", "Mixed forest", "Oak forest", "Shrublands","Artificial", "Pine forest", "Mixed forest", "Oak forest", "Shrublands","Artificial", "Pine forest", "Mixed forest", "Oak forest") #I just made up this randomly 

Here obtain the mean of minimal distance of Oak forest with any other: 
mean(min.dist[type=="Oak forest"]) 

here obtain the mean minimal distance of every Oak forest to another: 


mean(apply(distances[type=="Oak forest",type=="Oak forest"],1,min)) 

Is one of these that what you tried to do ?

Benjamin 

 
Le Lundi 5 Octobre 2015 14:17 GMT, juan jose mena <juamecos at gmail.com> a ?crit: 
 
> Hi Benjamin,
> 
> I have a Land Cover map with 5 different classes (i.e. Artificial, Pine
> forest, Mixed forest, Oak forest and Shrublands). what I want to compute is
> the mean euclidean nearest neigbour distance between all the patches in all
> the classes as Fragstats does:
> '' ENN = hij, distance (m) from patch ij to nearest neighboring patch of
> the same type (class), based on patch edge-to-edge distance, computed from
> cell center to cell center (FRAGSTATS HELP p. 138)''.
> Thanks in advance,
> 
> Juan
> 
> 2015-10-05 15:52 GMT+02:00 Gilles Benjamin Leduc <gbl1 at hi.is>:
> 
> > Hi,
> >
> > Are you talking about euclidian distances between location (physical
> > distance)  or  between two genotype (genetic distance) or between two
> > populations (also genetic distance, but not the same).
> >
> > I might have an answer for three of them :p
> >
> > Benjamin
> >
> >
> > Le Lundi 5 Octobre 2015 11:28 GMT, juan jose mena <juamecos at gmail.com> a
> > ?crit:
> >
> > > Hi all,
> > >
> > > I am performing a Landscape structure analysis with a raster layer and
> > > using SDMtools package in R. I got some metrics of my interest by means
> > of
> > > ClassStat and PatchStat functions but any of them perform the Euclidean
> > > Nearest Neighbour. So, any of you could tell me a package or a function
> > to
> > > calculate this metric or another connectivity metric to analyze the
> > > isolation?
> > >
> > > Thanks in advance
> > >
> > > Juan Jos? Mena Costa
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-Geo mailing list
> > > R-sig-Geo at r-project.org
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> >
> >
> >
> >


From chrissuthy at gmail.com  Tue Oct  6 19:58:41 2015
From: chrissuthy at gmail.com (Chris SUtherland)
Date: Tue, 6 Oct 2015 13:58:41 -0400
Subject: [R-sig-Geo] rgdal issues
Message-ID: <011401d10060$a2e82bc0$e8b88340$@gmail.com>

Hello group,

 

My abilities:

I use a Linux cluster sometime to parallelize some simulations.  I am not
extremely familiar with linux and there is someone who does the maintenance
of the cluster; I just know how to get R to do the things I need. 

 

My problem:

I recently asked for some packages to be updated, including 'rgda', 'sp' and
'rgeos', and since then, I have trouble executing spatial functions.

Specifically I get the error:

 

R: GeometryComponentFilter.cpp:35: virtual void
geos::geom::GeometryComponentFilter::filter_ro(const geos::geom::Geometry*):
Assertion `0' failed.

Aborted. 

 

Which kicks me out of R. This happens specifically for gDistance(). I saw
that this issue was discussed early in September and a fix was proposed -
but I'm afraid I didn't really follow how to actually implement the fix or
where exactly to put the missing .dat file.

 

Anyway, my question is this: does anybody have a workaround for this issue,
specifically some instruction I can pass on to the folks that centrally
maintain our Linux cluster.

 

Thanks in advance

 

Chris

 

 


	[[alternative HTML version deleted]]


From anacarocuellar at gmail.com  Wed Oct  7 09:48:22 2015
From: anacarocuellar at gmail.com (ana carolina cuellar)
Date: Wed, 7 Oct 2015 09:48:22 +0200
Subject: [R-sig-Geo] problems for reading ASCII file
Message-ID: <CAFrMPsHPctQPQPU4P0amuFpPRX12q+UFipHNvDZ9Fj8bmk8dTw@mail.gmail.com>

Hi All, I am trying to read an ASCII file into R and is the first time i am
trying to work with ASCII files. I saw a previous discussion that this
command can be used:

library(rgdal)
library(maptools)
grid <- readAsciiGrid("<your file and its path>")
table <- data.frame(grid)

in my case:  grid <- readAsciiGrid("I:/modisv5sm0112_2/prueb/amaascii.txt")


but when i used the readAsciiGrid function i get this error:

Error in validObject(.Object) :

  invalid class ?GridTopology? object: cells.dim has incorrect dimension


Can anybody tell me why? i dont get why it doesnt work :(

my ASCII file looks like this:

ncols         260
nrows         193
xllcorner     12,397449031167
yllcorner     55,534017291881
cellsize      0,0012386489974299
NODATA_value  -9999
-9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 25 25....etc


i am trying to process a raster image (the one i transformed to ASCII)
but it is too big to work with it as a raster in R (i am having memory
problems)...thats why i am trying to see if its simplier to process it
in ASCII and then bring it back to raster.

Thanks a lot!!

Ana

	[[alternative HTML version deleted]]


From paulo.flores.mail at gmail.com  Wed Oct  7 11:04:43 2015
From: paulo.flores.mail at gmail.com (Paulo Flores Ribeiro)
Date: Wed, 7 Oct 2015 10:04:43 +0100
Subject: [R-sig-Geo] problems for reading ASCII file
In-Reply-To: <CAFrMPsHPctQPQPU4P0amuFpPRX12q+UFipHNvDZ9Fj8bmk8dTw@mail.gmail.com>
References: <CAFrMPsHPctQPQPU4P0amuFpPRX12q+UFipHNvDZ9Fj8bmk8dTw@mail.gmail.com>
Message-ID: <5614E02B.1040808@gmail.com>

Try change cell size in your ascii text file (eg. instead of ?cellsize 
0,0012386489974299?, try  ?cellsize 10,10?)
Paulo Flores Ribeiro

?s 08:48 de 07-10-2015, ana carolina cuellar escreveu:
> Hi All, I am trying to read an ASCII file into R and is the first time i am
> trying to work with ASCII files. I saw a previous discussion that this
> command can be used:
>
> library(rgdal)
> library(maptools)
> grid <- readAsciiGrid("<your file and its path>")
> table <- data.frame(grid)
>
> in my case:  grid <- readAsciiGrid("I:/modisv5sm0112_2/prueb/amaascii.txt")
>
>
> but when i used the readAsciiGrid function i get this error:
>
> Error in validObject(.Object) :
>
>    invalid class ?GridTopology? object: cells.dim has incorrect dimension
>
>
> Can anybody tell me why? i dont get why it doesnt work :(
>
> my ASCII file looks like this:
>
> ncols         260
> nrows         193
> xllcorner     12,397449031167
> yllcorner     55,534017291881
> cellsize      0,0012386489974299
> NODATA_value  -9999
> -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 25 25....etc
>
>
> i am trying to process a raster image (the one i transformed to ASCII)
> but it is too big to work with it as a raster in R (i am having memory
> problems)...thats why i am trying to see if its simplier to process it
> in ASCII and then bring it back to raster.
>
> Thanks a lot!!
>
> Ana
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From b.rowlingson at lancaster.ac.uk  Wed Oct  7 11:43:17 2015
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 7 Oct 2015 10:43:17 +0100
Subject: [R-sig-Geo] problems for reading ASCII file
In-Reply-To: <5614E02B.1040808@gmail.com>
References: <CAFrMPsHPctQPQPU4P0amuFpPRX12q+UFipHNvDZ9Fj8bmk8dTw@mail.gmail.com>
	<5614E02B.1040808@gmail.com>
Message-ID: <CANVKczPR-94W1SBLBufE4Q2LpFiDgCfavb+JKibKyz2XDAGEWA@mail.gmail.com>

On Wed, Oct 7, 2015 at 10:04 AM, Paulo Flores Ribeiro
<paulo.flores.mail at gmail.com> wrote:
> Try change cell size in your ascii text file (eg. instead of ?cellsize
> 0,0012386489974299?, try  ?cellsize 10,10?)

How is that going to do anything but break the geolocation of the raster?

I'm worried about the comma decimal separators. Are they really commas
in the grid file? They should be full stops "." - otherwise I suspect
readAsciiGrid is throwing a fit. The cellsize parameter is a single
value, Esri Ascii Grid cells are always square.

Its possible there are decimal points okay in the file, and what
you've shown us is a localised printout where your locale is set to
use commas for decimal markers. But if there really are commas in the
file, then it will fail until they are replaced with points.

I can replicate your error with:

ncols 5
nrows 3
xllcorner 1000
yllcorner 1000
cellsize 0,001
NODATA_value -9999
2 3 4 3 2
3 4 5 6 7
1 2 4 3 2

and if I replace the comma with a point it reads in okay.

Barry


> Paulo Flores Ribeiro
>
> ?s 08:48 de 07-10-2015, ana carolina cuellar escreveu:
>>
>> Hi All, I am trying to read an ASCII file into R and is the first time i
>> am
>> trying to work with ASCII files. I saw a previous discussion that this
>> command can be used:
>>
>> library(rgdal)
>> library(maptools)
>> grid <- readAsciiGrid("<your file and its path>")
>> table <- data.frame(grid)
>>
>> in my case:  grid <-
>> readAsciiGrid("I:/modisv5sm0112_2/prueb/amaascii.txt")
>>
>>
>> but when i used the readAsciiGrid function i get this error:
>>
>> Error in validObject(.Object) :
>>
>>    invalid class ?GridTopology? object: cells.dim has incorrect dimension
>>
>>
>> Can anybody tell me why? i dont get why it doesnt work :(
>>
>> my ASCII file looks like this:
>>
>> ncols         260
>> nrows         193
>> xllcorner     12,397449031167
>> yllcorner     55,534017291881
>> cellsize      0,0012386489974299
>> NODATA_value  -9999
>> -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 25
>> 25....etc
>>
>>
>> i am trying to process a raster image (the one i transformed to ASCII)
>> but it is too big to work with it as a raster in R (i am having memory
>> problems)...thats why i am trying to see if its simplier to process it
>> in ASCII and then bring it back to raster.
>>
>> Thanks a lot!!
>>
>> Ana
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From alobolistas at gmail.com  Wed Oct  7 11:44:50 2015
From: alobolistas at gmail.com (Agustin Lobo)
Date: Wed, 7 Oct 2015 11:44:50 +0200
Subject: [R-sig-Geo] raser::boxplot : cannot add grouping layer
Message-ID: <CAG4NReL8EFFQerOFDBocOh3hzRjPugTOf6G1fjycQMy-HcGYaQ@mail.gmail.com>

According to the help page of raster::boxplot
x: Raster* object
y: if x is a RasterLayer object, y can be an additional RasterLayer to
group the values of x by 'zone'

but I get an error when I add a raster layer that represents a classification:
r1 <- r2 <- r3 <- raster(ncol=10, nrow=10)
r1[] <- rnorm(ncell(r1), 100, 40)
r2[] <- rnorm(ncell(r1), 80, 10)
r3[] <- rnorm(ncell(r1), 120, 30)
s <- stack(r1, r2, r3)
names(s) <- c('A', 'B', 'C')

rc <- round(r1[[1]]/100)
hist(rc)
summary(rc)

boxplot(s[[1]],rc)

Error in as.data.frame.default(data) :
  cannot coerce class "structure("RasterLayer", package = "raster")"
to a data.frame

Am I not interpreting what this function is supposed to do? I want to
get the boxplot
of the values of s by class in rc
(i can do it having rc as an sp pol data frame and using extract,  but
thought raster::boxplot
would be a more direct way)

Thanks

Agus


From englishchristophera at gmail.com  Wed Oct  7 15:59:40 2015
From: englishchristophera at gmail.com (englishchristophera at gmail.com)
Date: Wed, 07 Oct 2015 16:59:40 +0300
Subject: [R-sig-Geo] rgdal issues
Message-ID: <q9ht3ch8dvsffjnsgd1h6kkk.1444225834959@email.lge.com>

Hi Chris,I believe the discussion and fix from early September relate to the interactions for calculations of things like distance between rgeos::gDistance, rgdal, and the projections in the (package) proj4 ?'.dat' file. This may have already been fixed and updating proj4 might do it.?Otherwise it remains writing the proj4 .dat file to the recommended location in the fix.As your cluster maintainer has permissions to do things you can't, is more fluent in things linux, then perhaps just providing them with a link to the discussion would do the trick as it is not a cluster issue ?(afaik) but merely writing a file in the right place.HTHChris

LG Mobile dan g?nderildi
------ Original message------From: Chris SUtherlandDate: Tue, Oct 6, 2015 21:02To: r-sig-geo at r-project.org;Cc: Subject:[R-sig-Geo] rgdal issues
Hello group, My abilities:I use a Linux cluster sometime to parallelize some simulations.  I am notextremely familiar with linux and there is someone who does the maintenanceof the cluster; I just know how to get R to do the things I need.  My problem:I recently asked for some packages to be updated, including 'rgda', 'sp' and'rgeos', and since then, I have trouble executing spatial functions.Specifically I get the error: R: GeometryComponentFilter.cpp:35: virtual voidgeos::geom::GeometryComponentFilter::filter_ro(const geos::geom::Geometry*):Assertion `0' failed.Aborted.  Which kicks me out of R. This happens specifically for gDistance(). I sawthat this issue was discussed early in September and a fix was proposed -but I'm afraid I didn't really follow how to actually implement the fix orwhere exactly to put the missing .dat file. Anyway, my question is this: does anybody have a workaround for this issue,specifically some instruction I can pass on to the folks that centrallymaintain our Linux cluster. Thanks in advance Chris  	[[alternative HTML version deleted]]_______________________________________________R-sig-Geo mailing listR-sig-Geo at r-project.orghttps://stat.ethz.ch/mailman/listinfo/r-sig-geo
	[[alternative HTML version deleted]]


From venek at gmx.at  Thu Oct  8 09:14:53 2015
From: venek at gmx.at (Vv)
Date: Thu, 8 Oct 2015 09:14:53 +0200
Subject: [R-sig-Geo] Receiving ID of polygons when intersecting
 SpatialPolygons(DataFrame) and SpatialPoints
Message-ID: <trinity-13fc7080-e26b-4299-9ff2-81f5c5c7e431-1444288493284@3capp-gmx-bs51>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151008/d64fa65f/attachment.html>

From roman.lustrik at gmail.com  Thu Oct  8 09:28:19 2015
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Thu, 8 Oct 2015 09:28:19 +0200
Subject: [R-sig-Geo] Receiving ID of polygons when intersecting
 SpatialPolygons(DataFrame) and SpatialPoints
In-Reply-To: <trinity-13fc7080-e26b-4299-9ff2-81f5c5c7e431-1444288493284@3capp-gmx-bs51>
References: <trinity-13fc7080-e26b-4299-9ff2-81f5c5c7e431-1444288493284@3capp-gmx-bs51>
Message-ID: <CAHT1vphEfrdG38p9u0Xn_Q7x-Efcu1bd8UQvDDusUAWbDsjB6g@mail.gmail.com>

?Hello,

check out the example section of `?sp`.


# return the number of points in each polygon:
sapply(over(sr, geometry(meuse), returnList = TRUE), length)

r1 r2 r3 r4
50 57 48  0


where names in the result should be sufficiently informative.

sapply(slot(sr, "polygons"), slot, name = "ID")

[1] "r1" "r2" "r3" "r4"


?
Cheers,
Roman


On Thu, Oct 8, 2015 at 9:14 AM, Vv <venek at gmx.at> wrote:

> Hi list,
>
> I am currently tackling with the sp function over.
>
> I intersect a SpatialPoints object with a SpatialPolygonsDataFrame.
> I'd like to know how I can receive the ID of the polygons within the
> Polygons slot of the SpatialPolygonsDataFrame which are intersecting the
> SpatialPoints?
>
> Overlap<-sp::over(spPoints, spPolyDataFrame, returnList=TRUE)
>
> Whenever I use over I just receive "1" as result.
>
> Or is there a way to intersect SpatialPoints with objects of class
> polygons that I miss?
>
> Best,
> Ena
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


-- 
In God we trust, all others bring data.

	[[alternative HTML version deleted]]


From galuardi at mit.edu  Thu Oct  8 16:40:16 2015
From: galuardi at mit.edu (Benjamin.Galuardi)
Date: Thu, 08 Oct 2015 10:40:16 -0400
Subject: [R-sig-Geo] multi-map figure
In-Reply-To: <CABqyKtsD=Mj1fL5T1FwFMVLPWepX8C+5u=dtB5j1g16x_NsQqw@mail.gmail.com>
References: <CABqyKtsD=Mj1fL5T1FwFMVLPWepX8C+5u=dtB5j1g16x_NsQqw@mail.gmail.com>
Message-ID: <56168050.30906@mit.edu>

Hi Chris,

I modified your script to get where you want to be. I added a library 
requirement (for better axes) and commeted out a few things. The margin 
issue, for this example, stems from the fact that 'map' function adds a 
margin by default. See how I got around that and modify to your liking. 
You dont want the Y-axis borders touching or the x axis will overlap 
between plots.

Ben

# load libraries
library(maps)
library(mapdata)
library(sp)

# load data
DivrepNZ <- read.csv("C:/Downloads/DivrepNZ.csv")

# set up plot
par(mfrow = c(1, 3))
mymar = c(.5,.5,.5,.5)

# panel 1
map("world","New Zealand", xlim=c(166,179),ylim=c(-48,-34),lty=1,
col="gray", fill=FALSE, mar = mymar)
# title(xlab = NULL, ylab="Latitude (degrees S)", cex.lab=1.2)
# map.axes(cex.axis=0.85, las=1)
z <- DivrepNZ$Nativearborescent
zcol <- colorRampPalette(c('greenyellow', 'green4',
'black'))(100)[as.numeric(cut(z, breaks = 100))]
points(DivrepNZ$lon, DivrepNZ$lat, pch = 15, cex = 0.45, col = zcol)
box()
text(178,-35, "(a)", cex=1.2)
xleft <- 167
xright <- 168
ybot <- -39
yint <- (39 - 35) / 100
ytop <- ybot + yint
for(c in colorRampPalette(c('greenyellow', 'green4', 'black'))(100))
{ybot = ybot + yint
   ytop = ytop + yint
   rect(xleft, ybot, xright, ytop, border = NA, col = c)
   print(c(xleft, xright, ybot, ytop, c))
}
labels <- round(seq(min(z), max(z), length.out = 5),2)
text(c(xright + 0.2),
      seq(-39, -35, length.out = 5),
      labels = as.character(labels),
      cex = 0.85,
      pos = 4)
text(178, -35, "(a)")
degAxis(1)
degAxis(2)

# panel 2
map("world","New Zealand", xlim=c(166,179),ylim=c(-48,-34),lty=1,
col="gray", fill=FALSE, yaxt=NULL, mar = mymar)
# title(xlab = "Longitude (degrees E)", ylab=NULL, cex.lab=1.2)
# map.axes(cex.axis=0.85, las=1)
z <- DivrepNZ$Divaricates
zcol <- colorRampPalette(c('orange', 'orangered4',
'black'))(100)[as.numeric(cut(z, breaks = 100))]
points(DivrepNZ$lon, DivrepNZ$lat, pch = 15, cex = 0.45, col = zcol)
box()
text(178,-35, "(b)", cex=1.2)
xleft <- 167
xright <- 168
ybot <- -39
yint <- (39 - 35) / 100
ytop <- ybot + yint
for(c in colorRampPalette(c('orange', 'orangered4', 'black'))(100))
{ybot = ybot + yint
   ytop = ytop + yint
   rect(xleft, ybot, xright, ytop, border = NA, col = c)
   print(c(xleft, xright, ybot, ytop, c))
}
labels <- round(seq(min(z), max(z), length.out = 5),2)
text(c(xright + 0.2),
      seq(-39, -35, length.out = 5),
      labels = as.character(labels),
      cex = 0.85,
      pos = 4)
text(178, -35, "(b)")
degAxis(1)

# panel 3
map("world","New Zealand", xlim=c(166,179),ylim=c(-48,-34),lty=1,
col="gray", fill=FALSE, yaxt=NULL, mar = mymar)
Show axes with horizontal tick labels
# map.axes(cex.axis=0.85, las=1)
# title(xlab = NULL, ylab=NULL, cex.lab=1.2)
DivrepNZ <- read.csv("DivrepNZ.csv")
z <- DivrepNZ$divrep
zcol <- colorRampPalette(c('lightskyblue', 'deepskyblue4',
'black'))(100)[as.numeric(cut(z, breaks = 100))]
points(DivrepNZ$lon, DivrepNZ$lat, pch = 15, cex = 0.45, col = zcol)
box()
text(178,-35, "(c)", cex=1.2)
xleft <- 167
xright <- 168
ybot <- -39
yint <- (39 - 35) / 100
ytop <- ybot + yint
for(c in colorRampPalette(c('lightskyblue', 'deepskyblue4', 'black'))(100))
{ybot = ybot + yint
   ytop = ytop + yint
   rect(xleft, ybot, xright, ytop, border = NA, col = c)
   print(c(xleft, xright, ybot, ytop, c))
}
labels <- round(seq(min(z), max(z), length.out = 6),2)
text(c(xright + 0.2),
      seq(-39, -35, length.out = 6),
      labels = as.character(labels),
      cex = 0.85,
      pos = 4)
text(178, -35, "(c)")
degAxis(1)
On 10/4/2015 9:31 PM, Christopher Lusk wrote:
> Hi - I want to combine 3 maps in one figure, showing geographic patterns of
> species richness. Looks OK with the script below, but as the axes are the
> same on all 3 maps, I've been trying to remove the space between the 3
> panels, and get rid of y-axis ticks and tick labels on panels (b) and (c)
> as well. But neither of these is happening, despite several approaches. Can
> anyone see what I need to change? Any advice would be appreciated. The data
> can be downloaded here:
>
> http://sci.waikato.ac.nz/sites/clusk/DivrepNZ.csv
> ....................
>
> library(maps)
> library(mapdata)
>
> par(mfrow = c(1, 3))
> par(mar = c(0, 0, 0, 0), oma = c(1, 1.5, 0.5, 0.5))
>
> map("worldHires","New Zealand", xlim=c(166,179),ylim=c(-48,-34),lty=1,
> col="gray", fill=FALSE)
> title(xlab = NULL, ylab="Latitude (degrees S)", cex.lab=1.2)
> map.axes(cex.axis=0.85, las=1)
> DivrepNZ <- read.csv("DivrepNZ.csv")
> z <- DivrepNZ$Nativearborescent
> zcol <- colorRampPalette(c('greenyellow', 'green4',
> 'black'))(100)[as.numeric(cut(z, breaks = 100))]
> points(DivrepNZ$lon, DivrepNZ$lat, pch = 15, cex = 0.45, col = zcol)
> box()
> text(178,-35, "(a)", cex=1.2)
> xleft <- 167
> xright <- 168
> ybot <- -39
> yint <- (39 - 35) / 100
> ytop <- ybot + yint
> for(c in colorRampPalette(c('greenyellow', 'green4', 'black'))(100))
> {ybot = ybot + yint
>    ytop = ytop + yint
>    rect(xleft, ybot, xright, ytop, border = NA, col = c)
>    print(c(xleft, xright, ybot, ytop, c))
> }
> labels <- round(seq(min(z), max(z), length.out = 5),2)
> text(c(xright + 0.2),
>       seq(-39, -35, length.out = 5),
>       labels = as.character(labels),
>       cex = 0.85,
>       pos = 4)
> text(178, -35, "(a)")
>
> map("worldHires","New Zealand", xlim=c(166,179),ylim=c(-48,-34),lty=1,
> col="gray", fill=FALSE, yaxt=NULL)
> title(xlab = "Longitude (degrees E)", ylab=NULL, cex.lab=1.2)
> map.axes(cex.axis=0.85, las=1)
> DivrepNZ <- read.csv("DivrepNZ.csv")
> z <- DivrepNZ$Divaricates
> zcol <- colorRampPalette(c('orange', 'orangered4',
> 'black'))(100)[as.numeric(cut(z, breaks = 100))]
> points(DivrepNZ$lon, DivrepNZ$lat, pch = 15, cex = 0.45, col = zcol)
> box()
> text(178,-35, "(b)", cex=1.2)
> xleft <- 167
> xright <- 168
> ybot <- -39
> yint <- (39 - 35) / 100
> ytop <- ybot + yint
> for(c in colorRampPalette(c('orange', 'orangered4', 'black'))(100))
> {ybot = ybot + yint
>    ytop = ytop + yint
>    rect(xleft, ybot, xright, ytop, border = NA, col = c)
>    print(c(xleft, xright, ybot, ytop, c))
> }
> labels <- round(seq(min(z), max(z), length.out = 5),2)
> text(c(xright + 0.2),
>       seq(-39, -35, length.out = 5),
>       labels = as.character(labels),
>       cex = 0.85,
>       pos = 4)
> text(178, -35, "(b)")
>
> map("worldHires","New Zealand", xlim=c(166,179),ylim=c(-48,-34),lty=1,
> col="gray", fill=FALSE, yaxt=NULL)
> Show axes with horizontal tick labels
> map.axes(cex.axis=0.85, las=1)
> title(xlab = NULL, ylab=NULL, cex.lab=1.2)
> DivrepNZ <- read.csv("DivrepNZ.csv")
> z <- DivrepNZ$divrep
> zcol <- colorRampPalette(c('lightskyblue', 'deepskyblue4',
> 'black'))(100)[as.numeric(cut(z, breaks = 100))]
> points(DivrepNZ$lon, DivrepNZ$lat, pch = 15, cex = 0.45, col = zcol)
> box()
> text(178,-35, "(c)", cex=1.2)
> xleft <- 167
> xright <- 168
> ybot <- -39
> yint <- (39 - 35) / 100
> ytop <- ybot + yint
> for(c in colorRampPalette(c('lightskyblue', 'deepskyblue4', 'black'))(100))
> {ybot = ybot + yint
>    ytop = ytop + yint
>    rect(xleft, ybot, xright, ytop, border = NA, col = c)
>    print(c(xleft, xright, ybot, ytop, c))
> }
> labels <- round(seq(min(z), max(z), length.out = 6),2)
> text(c(xright + 0.2),
>       seq(-39, -35, length.out = 6),
>       labels = as.character(labels),
>       cex = 0.85,
>       pos = 4)
> text(178, -35, "(c)")
>
>
> --
> Dr. Chris Lusk
> Environmental Research Institute
> The University of Waikato
> Private Bag 3105, Hamilton
> New Zealand / Aotearoa
> http://sci.waikato.ac.nz/sites/clusk/
> Ph 64 7 838 4205
> ~  ~  ~  ~  ~  ~  ~
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
==================================================
Benjamin Galuardi
PhD Student
NMFS-Seagrant Population Dynamics Fellow
SMAST, UMass Dartmouth


From r.hijmans at gmail.com  Thu Oct  8 21:57:04 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 8 Oct 2015 12:57:04 -0700
Subject: [R-sig-Geo] raser::boxplot : cannot add grouping layer
In-Reply-To: <CAG4NReL8EFFQerOFDBocOh3hzRjPugTOf6G1fjycQMy-HcGYaQ@mail.gmail.com>
References: <CAG4NReL8EFFQerOFDBocOh3hzRjPugTOf6G1fjycQMy-HcGYaQ@mail.gmail.com>
Message-ID: <CANtt_hx-BKHsaFn_=xy8bJQdMXL0_isdkTNDFTQezMZSB-uSLg@mail.gmail.com>

Hi Agus,
Your example works for me without error.
Can you update.packages() and try this in a clean workspace? (perhaps
another package is interfering?)
Robert

On Wed, Oct 7, 2015 at 2:44 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
> According to the help page of raster::boxplot
> x: Raster* object
> y: if x is a RasterLayer object, y can be an additional RasterLayer to
> group the values of x by 'zone'
>
> but I get an error when I add a raster layer that represents a classification:
> r1 <- r2 <- r3 <- raster(ncol=10, nrow=10)
> r1[] <- rnorm(ncell(r1), 100, 40)
> r2[] <- rnorm(ncell(r1), 80, 10)
> r3[] <- rnorm(ncell(r1), 120, 30)
> s <- stack(r1, r2, r3)
> names(s) <- c('A', 'B', 'C')
>
> rc <- round(r1[[1]]/100)
> hist(rc)
> summary(rc)
>
> boxplot(s[[1]],rc)
>
> Error in as.data.frame.default(data) :
>   cannot coerce class "structure("RasterLayer", package = "raster")"
> to a data.frame
>
> Am I not interpreting what this function is supposed to do? I want to
> get the boxplot
> of the values of s by class in rc
> (i can do it having rc as an sp pol data frame and using extract,  but
> thought raster::boxplot
> would be a more direct way)
>
> Thanks
>
> Agus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From edzer.pebesma at uni-muenster.de  Thu Oct  8 22:14:01 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 8 Oct 2015 16:14:01 -0400
Subject: [R-sig-Geo] Receiving ID of polygons when intersecting
 SpatialPolygons(DataFrame) and SpatialPoints
In-Reply-To: <trinity-13fc7080-e26b-4299-9ff2-81f5c5c7e431-1444288493284@3capp-gmx-bs51>
References: <trinity-13fc7080-e26b-4299-9ff2-81f5c5c7e431-1444288493284@3capp-gmx-bs51>
Message-ID: <5616CE89.1030007@uni-muenster.de>



On 08/10/15 03:14, Vv wrote:
> Hi list,
>  
> I am currently tackling with the sp function over.
>  
> I intersect a SpatialPoints object with a SpatialPolygonsDataFrame.
> I'd like to know how I can receive the ID of the polygons within the
> Polygons slot of the SpatialPolygonsDataFrame which are intersecting the
> SpatialPoints?
>  
> Overlap<-sp::over(spPoints, spPolyDataFrame, returnList=TRUE)
>  
> Whenever I use over I just receive "1" as result.
>  
> Or is there a way to intersect SpatialPoints with objects of class
> polygons that I miss?

rgeos::gIntersects : with arguments byid=TRUE and returnDense=FALSE it
should return a similar list.

>  
> Best,
> Ena
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151008/92389f45/attachment.bin>

From alobolistas at gmail.com  Fri Oct  9 09:30:13 2015
From: alobolistas at gmail.com (Agustin Lobo)
Date: Fri, 9 Oct 2015 09:30:13 +0200
Subject: [R-sig-Geo] raser::boxplot : cannot add grouping layer
In-Reply-To: <CANtt_hx-BKHsaFn_=xy8bJQdMXL0_isdkTNDFTQezMZSB-uSLg@mail.gmail.com>
References: <CAG4NReL8EFFQerOFDBocOh3hzRjPugTOf6G1fjycQMy-HcGYaQ@mail.gmail.com>
	<CANtt_hx-BKHsaFn_=xy8bJQdMXL0_isdkTNDFTQezMZSB-uSLg@mail.gmail.com>
Message-ID: <CAG4NReJgByK8+aMP5K95Gfxu7no8=tev2pc21051Hv8x=On9pQ@mail.gmail.com>

Solved just by upgrading raster.
Thanks
Agus

On Thu, Oct 8, 2015 at 9:57 PM, Robert J. Hijmans <r.hijmans at gmail.com> wrote:
> Hi Agus,
> Your example works for me without error.
> Can you update.packages() and try this in a clean workspace? (perhaps
> another package is interfering?)
> Robert
>
> On Wed, Oct 7, 2015 at 2:44 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
>> According to the help page of raster::boxplot
>> x: Raster* object
>> y: if x is a RasterLayer object, y can be an additional RasterLayer to
>> group the values of x by 'zone'
>>
>> but I get an error when I add a raster layer that represents a classification:
>> r1 <- r2 <- r3 <- raster(ncol=10, nrow=10)
>> r1[] <- rnorm(ncell(r1), 100, 40)
>> r2[] <- rnorm(ncell(r1), 80, 10)
>> r3[] <- rnorm(ncell(r1), 120, 30)
>> s <- stack(r1, r2, r3)
>> names(s) <- c('A', 'B', 'C')
>>
>> rc <- round(r1[[1]]/100)
>> hist(rc)
>> summary(rc)
>>
>> boxplot(s[[1]],rc)
>>
>> Error in as.data.frame.default(data) :
>>   cannot coerce class "structure("RasterLayer", package = "raster")"
>> to a data.frame
>>
>> Am I not interpreting what this function is supposed to do? I want to
>> get the boxplot
>> of the values of s by class in rc
>> (i can do it having rc as an sp pol data frame and using extract,  but
>> thought raster::boxplot
>> would be a more direct way)
>>
>> Thanks
>>
>> Agus
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From ruettenauer at sowi.uni-kl.de  Fri Oct  9 16:54:30 2015
From: ruettenauer at sowi.uni-kl.de (=?iso-8859-1?Q?Tobias_R=FCttenauer?=)
Date: Fri, 9 Oct 2015 16:54:30 +0200
Subject: [R-sig-Geo] Time series in spatial regression model (spautolm)
Message-ID: <005d01d102a2$674f1ad0$35ed5070$@sowi.uni-kl.de>

Dear r-sig-geo team,

I started working with spatial analysis some month ago, so I'm quite new
(and unknowing ) in this field. However, my aim is to connect time series
analysis with spatial analysis, what seems to be quite difficult (to me).

The dataset I am working with a spatial polygons data frame, containing 402
spatial polygons for the years 2007-2011.

In a first step, I want to estimate a SAR model which accounts only for the
spatial autoregressive error term within a year. So what I am basically
trying is to construct a weights list object, containing only weights for
neighbors in the same year (excluding the linkages to the "self" spatial
unit (in different years) and neighboring units in different years). So what
I tried was to expand the original weights matrix by duplicating the
original matrix on the main diagonal while filling all the other linkages
(e.g. linkages between 2007 spatial units and 2008 spatial units) with zero
by the following code:


# Queens links:
> data.nb<-poly2nb(data_subset.spdf)
> 
> # Remove temporal links
> data2.nb<-aggregate(data.nb, data_subset.spdf$id, remove.self = TRUE)
> 
> # Get matrix
> tmp.mat<-nb2mat(data2.nb)
> 
> # Expand matrix
> zero1.mat<-matrix(0, 402, 402)
> zero2.mat<-matrix(0, 402, 402)
> zero3.mat<-matrix(0, 402, 402)
> zero4.mat<-matrix(0, 402, 402)
> zero5.mat<-matrix(0, 402, 402)
> 
> tmp2.mat<-tmp.mat
> tmp3.mat<-tmp.mat
> tmp4.mat<-tmp.mat
> tmp5.mat<-tmp.mat
> 
> row.names(zero1.mat)<-paste("2007", as.numeric(row.names(tmp.mat)), 
> sep="_") row.names(zero2.mat)<-paste("2008", 
> as.numeric(row.names(tmp.mat)), sep="_") 
> row.names(zero3.mat)<-paste("2009", as.numeric(row.names(tmp.mat)), 
> sep="_") row.names(zero4.mat)<-paste("2010", 
> as.numeric(row.names(tmp.mat)), sep="_") 
> row.names(zero5.mat)<-paste("2011", as.numeric(row.names(tmp.mat)), 
> sep="_")
> 
> row.names(tmp.mat)<-paste("2007", as.numeric(row.names(tmp2.mat)), 
> sep="_") row.names(tmp2.mat)<-paste("2008", 
> as.numeric(row.names(tmp2.mat)), sep="_") 
> row.names(tmp3.mat)<-paste("2009", as.numeric(row.names(tmp3.mat)), 
> sep="_") row.names(tmp4.mat)<-paste("2010", 
> as.numeric(row.names(tmp4.mat)), sep="_") 
> row.names(tmp5.mat)<-paste("2011", as.numeric(row.names(tmp5.mat)), 
> sep="_")
> 
> tmp1<-rbind(tmp.mat, zero2.mat, zero3.mat, zero4.mat, zero5.mat) 
> tmp2<-rbind(zero1.mat, tmp2.mat, zero3.mat, zero4.mat, zero5.mat) 
> tmp3<-rbind(zero1.mat, zero2.mat, tmp3.mat, zero4.mat, zero5.mat) 
> tmp4<-rbind(zero1.mat, zero2.mat, zero3.mat, tmp4.mat, zero5.mat) 
> tmp5<-rbind(zero1.mat, zero2.mat, zero3.mat, zero4.mat, tmp5.mat)
> 
> nb.mat<-cbind(tmp1, tmp2, tmp3, tmp4, tmp5)
> 
> data_sub.lw<-mat2listw(data.matrix(nb.mat))
> 
> any(is.na(nb.mat))
[1] FALSE

So I get a weights list object including 2010 observations (5 years with 402
observations, which fits the spatial polygon data frame with 2010
observations), but after running a spautolm model, I get the following error
message:

> spreg.mod<-spautolm(sqrt(fortzuege_gem) ~ v1 + v2,
+                 data=data_subset.spdf, listw=data_sub.lw,
weights=area_sqkm, 
+                 zero.policy=TRUE)
Error in subset.listw(listw, subset, zero.policy = zero.policy) : 
  Not yet able to subset general weights lists

Elsewhere, it is mentioned that this error messages occurs if the weights
matrix contains missing values, but that's not the case here. I assume that
there is some mistake in creating the weights matrix. Do you have any ideas?


Another thing I was trying to estimate is a SAR model with unit fixed
effects, just by including the id dummies into the equation (for the test I
include the total list weights objects, containing all linkages).

> data_total.nb<-poly2nb(data_subset.spdf)
> data_total.lw<-nb2listw(data.nb, style="W")
> 
> spreg_false.mod<-spautolm(sqrt(fortzuege_gem) ~ id  + v1 + v2,
+                     data=data_subset.spdf, listw=data_total.lw,
weights=area_sqkm, 
+                     zero.policy=TRUE)
Error in solve.default(crossprod(X, as.matrix(IlW %*% X)), tol = tol.solve)
: 
  system is computationally singular: reciprocal condition number =
1.01026e-16
>

So I assume there occurs some conflict, between using ID dummies and a
weights matrix in one model? Is there any way to solve this problem? This
may be a stupid question for some who is (totally) aware of the mathematics
behind the model. 

I would be really happy about any help!

Thank you in advance and best wishes,
Tobi


From jajeuck at ncsu.edu  Fri Oct  9 17:18:14 2015
From: jajeuck at ncsu.edu (James Jeuck)
Date: Fri, 9 Oct 2015 11:18:14 -0400
Subject: [R-sig-Geo] rgdal HFA and spheroid issue
Message-ID: <CA+epebe1J7xyr0rJMwJjEqO=ANHJW7088298=bUbguhcJRD6KA@mail.gmail.com>

Greetings:

My apologies if I have not posted correctly or research effectively for a
solution to this question...I am brand new to this list and am still
feeling my way around.....however, I did want to post this to see if there
are any suggestions while I dig through the site....

I am working with a large US SE data set derived from NLCD (.img) imagery.
I pull into a "diced" section (10,000X10,000 pixels) into R via:

 map.rast<-readGDAL(fn)
 map.data<-slot(map.rast,"data")

I processed the data to get it ready for, and then run, a randomForest
prediction of land use.

The predicted values were "slot" back into the original map.raster S4:
new.map<-map.rast
slot(new.map,"data")<-data.frame("band1"=prediction.rf$predict,

"band2"=prediction.rf$prob_0,

"band3"=prediction.rf$prob_1)
 outfn<-paste(c("timl_pred",i,j),collapse="_")
 outfn<-paste(c(outfn,".img"),collapse="")


the structure of that S4 object is:

Formal class 'SpatialGridDataFrame' [package "sp"] with 4 slots
  ..@ data       :'data.frame': 6250000 obs. of  3 variables:
  .. ..$ band1: num [1:6250000] 1 1 1 1 1 1 1 1 1 1 ...
  .. ..$ band2: num [1:6250000] 0.99 0.991 0.991 0.988 0.99 ...
  .. ..$ band3: num [1:6250000] 0.0105 0.0095 0.0095 0.012 0.0105 0.011
0.0105 0.013 0.0125 0.0125 ...
  ..@ grid       :Formal class 'GridTopology' [package "sp"] with 3 slots
  .. .. ..@ cellcentre.offset: Named num [1:2] 872640 1751490
  .. .. .. ..- attr(*, "names")= chr [1:2] "x" "y"
  .. .. ..@ cellsize         : num [1:2] 30 30
  .. .. ..@ cells.dim        : int [1:2] 2500 2500
  ..@ bbox       : num [1:2, 1:2] 872625 1751475 947625 1826475
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr [1:2] "x" "y"
  .. .. ..$ : chr [1:2] "min" "max"
  ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
  .. .. ..@ projargs: chr "+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23
+lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m
+no_defs"

Notice the "@proj4string at projargs" has GRS80 ellipsoid pulled from the
original raster.

Last, I wrote it back out in HFA format:

writeGDAL(new.map,outfn,drivername="HFA",type="Float32",mvFlag=-1000000,
setStatistics=T)

It all works fine but when I try to pull it into ERDAS Imagine 2015 - I get
an error message saying the Spheriod GRS80 table is missing.  I can pull it
into Arc GIS no problem and use the model builder to reproject to WGS84 -
then pull it into Imagine just fine. However, I am puzzled as to what, if
anything, I am doing wrong.  ERDAS Imagine has GRS80 and I have no trouble
pulling in the original data.  Is there a parameter I am missing in the
"new.map" S4 object, should I edit the @ proj4string, or is there a
parameter in writeGDAL that could fix this?  Many thanks in advance -
jaj
-- 
James Jeuck, Extension Associate
NCSU Extension Forestry
Campus Box 8008
Raleigh, NC 27695
919.515.5574 work
828.734.9795 cell
james_jeuck at ncsu.edu

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Sat Oct 10 15:11:17 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 10 Oct 2015 15:11:17 +0200
Subject: [R-sig-Geo] Time series in spatial regression model (spautolm)
In-Reply-To: <005d01d102a2$674f1ad0$35ed5070$@sowi.uni-kl.de>
References: <005d01d102a2$674f1ad0$35ed5070$@sowi.uni-kl.de>
Message-ID: <alpine.LFD.2.20.1510101505530.22748@reclus.nhh.no>

You cross-posted to this list and r-help - never do that - it splinters 
any replies. I have chosen to ignore your r-help posting and hope that 
others will do the same.

On Fri, 9 Oct 2015, Tobias R?ttenauer wrote:

> Dear r-sig-geo team,
>
> I started working with spatial analysis some month ago, so I'm quite new
> (and unknowing ) in this field. However, my aim is to connect time series
> analysis with spatial analysis, what seems to be quite difficult (to me).
>

Why are you not using the splm package, which provides most of the models 
you might ever need to fit? Your manipulation of the weights matrix by 
years is a Kronecker product - used in that package. Study the plm package 
first, run your model aspatially with that, and move on to splm.

Roger

> The dataset I am working with a spatial polygons data frame, containing 402
> spatial polygons for the years 2007-2011.
>
> In a first step, I want to estimate a SAR model which accounts only for the
> spatial autoregressive error term within a year. So what I am basically
> trying is to construct a weights list object, containing only weights for
> neighbors in the same year (excluding the linkages to the "self" spatial
> unit (in different years) and neighboring units in different years). So what
> I tried was to expand the original weights matrix by duplicating the
> original matrix on the main diagonal while filling all the other linkages
> (e.g. linkages between 2007 spatial units and 2008 spatial units) with zero
> by the following code:
>
>
> # Queens links:
>> data.nb<-poly2nb(data_subset.spdf)
>>
>> # Remove temporal links
>> data2.nb<-aggregate(data.nb, data_subset.spdf$id, remove.self = TRUE)
>>
>> # Get matrix
>> tmp.mat<-nb2mat(data2.nb)
>>
>> # Expand matrix
>> zero1.mat<-matrix(0, 402, 402)
>> zero2.mat<-matrix(0, 402, 402)
>> zero3.mat<-matrix(0, 402, 402)
>> zero4.mat<-matrix(0, 402, 402)
>> zero5.mat<-matrix(0, 402, 402)
>>
>> tmp2.mat<-tmp.mat
>> tmp3.mat<-tmp.mat
>> tmp4.mat<-tmp.mat
>> tmp5.mat<-tmp.mat
>>
>> row.names(zero1.mat)<-paste("2007", as.numeric(row.names(tmp.mat)),
>> sep="_") row.names(zero2.mat)<-paste("2008",
>> as.numeric(row.names(tmp.mat)), sep="_")
>> row.names(zero3.mat)<-paste("2009", as.numeric(row.names(tmp.mat)),
>> sep="_") row.names(zero4.mat)<-paste("2010",
>> as.numeric(row.names(tmp.mat)), sep="_")
>> row.names(zero5.mat)<-paste("2011", as.numeric(row.names(tmp.mat)),
>> sep="_")
>>
>> row.names(tmp.mat)<-paste("2007", as.numeric(row.names(tmp2.mat)),
>> sep="_") row.names(tmp2.mat)<-paste("2008",
>> as.numeric(row.names(tmp2.mat)), sep="_")
>> row.names(tmp3.mat)<-paste("2009", as.numeric(row.names(tmp3.mat)),
>> sep="_") row.names(tmp4.mat)<-paste("2010",
>> as.numeric(row.names(tmp4.mat)), sep="_")
>> row.names(tmp5.mat)<-paste("2011", as.numeric(row.names(tmp5.mat)),
>> sep="_")
>>
>> tmp1<-rbind(tmp.mat, zero2.mat, zero3.mat, zero4.mat, zero5.mat)
>> tmp2<-rbind(zero1.mat, tmp2.mat, zero3.mat, zero4.mat, zero5.mat)
>> tmp3<-rbind(zero1.mat, zero2.mat, tmp3.mat, zero4.mat, zero5.mat)
>> tmp4<-rbind(zero1.mat, zero2.mat, zero3.mat, tmp4.mat, zero5.mat)
>> tmp5<-rbind(zero1.mat, zero2.mat, zero3.mat, zero4.mat, tmp5.mat)
>>
>> nb.mat<-cbind(tmp1, tmp2, tmp3, tmp4, tmp5)
>>
>> data_sub.lw<-mat2listw(data.matrix(nb.mat))
>>
>> any(is.na(nb.mat))
> [1] FALSE
>
> So I get a weights list object including 2010 observations (5 years with 402
> observations, which fits the spatial polygon data frame with 2010
> observations), but after running a spautolm model, I get the following error
> message:
>
>> spreg.mod<-spautolm(sqrt(fortzuege_gem) ~ v1 + v2,
> +                 data=data_subset.spdf, listw=data_sub.lw,
> weights=area_sqkm,
> +                 zero.policy=TRUE)
> Error in subset.listw(listw, subset, zero.policy = zero.policy) :
>  Not yet able to subset general weights lists
>
> Elsewhere, it is mentioned that this error messages occurs if the weights
> matrix contains missing values, but that's not the case here. I assume that
> there is some mistake in creating the weights matrix. Do you have any ideas?
>
>
> Another thing I was trying to estimate is a SAR model with unit fixed
> effects, just by including the id dummies into the equation (for the test I
> include the total list weights objects, containing all linkages).
>
>> data_total.nb<-poly2nb(data_subset.spdf)
>> data_total.lw<-nb2listw(data.nb, style="W")
>>
>> spreg_false.mod<-spautolm(sqrt(fortzuege_gem) ~ id  + v1 + v2,
> +                     data=data_subset.spdf, listw=data_total.lw,
> weights=area_sqkm,
> +                     zero.policy=TRUE)
> Error in solve.default(crossprod(X, as.matrix(IlW %*% X)), tol = tol.solve)
> :
>  system is computationally singular: reciprocal condition number =
> 1.01026e-16
>>
>
> So I assume there occurs some conflict, between using ID dummies and a
> weights matrix in one model? Is there any way to solve this problem? This
> may be a stupid question for some who is (totally) aware of the mathematics
> behind the model.
>
> I would be really happy about any help!
>
> Thank you in advance and best wishes,
> Tobi
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From ruettenauer at sowi.uni-kl.de  Sat Oct 10 16:19:53 2015
From: ruettenauer at sowi.uni-kl.de (=?iso-8859-1?Q?Tobias_R=FCttenauer?=)
Date: Sat, 10 Oct 2015 16:19:53 +0200
Subject: [R-sig-Geo] Time series in spatial regression model (spautolm)
Message-ID: <000d01d10366$bbebdf00$33c39d00$@sowi.uni-kl.de>

Dear Roger,

Thank you very much for your reply! 

> Von: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Gesendet: Samstag, 10. Oktober 2015 15:11
> 
> You cross-posted to this list and r-help - never do that - it 
> splinters any replies. I have chosen to ignore your r-help posting and 
> hope that others will do the same.

I am sorry for the crosspost! Won't happen again!

> 
> On Fri, 9 Oct 2015, Tobias R?ttenauer wrote:
> 
> > Dear r-sig-geo team,
> >
> > I started working with spatial analysis some month ago, so I'm quite 
> > new (and unknowing ) in this field. However, my aim is to connect 
> > time series analysis with spatial analysis, what seems to be quite 
> > difficult (to
> me).
> >
> 
> Why are you not using the splm package, which provides most of the 
> models you might ever need to fit? Your manipulation of the weights 
> matrix by years is a Kronecker product - used in that package. Study 
> the plm package first, run your model aspatially with that, and move on to
splm.
> 
> Roger

I didn't recognize that package so far... Thank you very much for the hint,
splm exactly provides what I'm looking for!

Thankful wishes
Tobi

> 
> > The dataset I am working with a spatial polygons data frame, 
> > containing 402 spatial polygons for the years 2007-2011.
> >
> > In a first step, I want to estimate a SAR model which accounts only 
> > for the spatial autoregressive error term within a year. So what I 
> > am basically trying is to construct a weights list object, 
> > containing only weights for neighbors in the same year (excluding 
> > the linkages to the "self" spatial unit (in different years) and 
> > neighboring units in different years). So what I tried was to expand 
> > the original weights matrix by duplicating the original matrix on 
> > the main diagonal while filling all the other linkages (e.g. 
> > linkages between 2007 spatial units and 2008 spatial units) with zero by
the following code:
> >
> >
> > # Queens links:
> >> data.nb<-poly2nb(data_subset.spdf)
> >>
> >> # Remove temporal links
> >> data2.nb<-aggregate(data.nb, data_subset.spdf$id, remove.self = 
> >> TRUE)
> >>
> >> # Get matrix
> >> tmp.mat<-nb2mat(data2.nb)
> >>
> >> # Expand matrix
> >> zero1.mat<-matrix(0, 402, 402)
> >> zero2.mat<-matrix(0, 402, 402)
> >> zero3.mat<-matrix(0, 402, 402)
> >> zero4.mat<-matrix(0, 402, 402)
> >> zero5.mat<-matrix(0, 402, 402)
> >>
> >> tmp2.mat<-tmp.mat
> >> tmp3.mat<-tmp.mat
> >> tmp4.mat<-tmp.mat
> >> tmp5.mat<-tmp.mat
> >>
> >> row.names(zero1.mat)<-paste("2007",
> as.numeric(row.names(tmp.mat)),
> >> sep="_") row.names(zero2.mat)<-paste("2008",
> >> as.numeric(row.names(tmp.mat)), sep="_") 
> >> row.names(zero3.mat)<-paste("2009",
> as.numeric(row.names(tmp.mat)),
> >> sep="_") row.names(zero4.mat)<-paste("2010",
> >> as.numeric(row.names(tmp.mat)), sep="_") 
> >> row.names(zero5.mat)<-paste("2011",
> as.numeric(row.names(tmp.mat)),
> >> sep="_")
> >>
> >> row.names(tmp.mat)<-paste("2007", as.numeric(row.names(tmp2.mat)),
> >> sep="_") row.names(tmp2.mat)<-paste("2008",
> >> as.numeric(row.names(tmp2.mat)), sep="_") 
> >> row.names(tmp3.mat)<-paste("2009",
> as.numeric(row.names(tmp3.mat)),
> >> sep="_") row.names(tmp4.mat)<-paste("2010",
> >> as.numeric(row.names(tmp4.mat)), sep="_") 
> >> row.names(tmp5.mat)<-paste("2011",
> as.numeric(row.names(tmp5.mat)),
> >> sep="_")
> >>
> >> tmp1<-rbind(tmp.mat, zero2.mat, zero3.mat, zero4.mat, zero5.mat) 
> >> tmp2<-rbind(zero1.mat, tmp2.mat, zero3.mat, zero4.mat, zero5.mat) 
> >> tmp3<-rbind(zero1.mat, zero2.mat, tmp3.mat, zero4.mat, zero5.mat) 
> >> tmp4<-rbind(zero1.mat, zero2.mat, zero3.mat, tmp4.mat, zero5.mat) 
> >> tmp5<-rbind(zero1.mat, zero2.mat, zero3.mat, zero4.mat, tmp5.mat)
> >>
> >> nb.mat<-cbind(tmp1, tmp2, tmp3, tmp4, tmp5)
> >>
> >> data_sub.lw<-mat2listw(data.matrix(nb.mat))
> >>
> >> any(is.na(nb.mat))
> > [1] FALSE
> >
> > So I get a weights list object including 2010 observations (5 years 
> > with 402 observations, which fits the spatial polygon data frame 
> > with
> > 2010 observations), but after running a spautolm model, I get the 
> > following error
> > message:
> >
> >> spreg.mod<-spautolm(sqrt(fortzuege_gem) ~ v1 + v2,
> > +                 data=data_subset.spdf, listw=data_sub.lw,
> > weights=area_sqkm,
> > +                 zero.policy=TRUE)
> > Error in subset.listw(listw, subset, zero.policy = zero.policy) :
> >  Not yet able to subset general weights lists
> >
> > Elsewhere, it is mentioned that this error messages occurs if the 
> > weights matrix contains missing values, but that's not the case here.
> > I assume that there is some mistake in creating the weights matrix. 
> > Do you
> have any ideas?
> >
> >
> > Another thing I was trying to estimate is a SAR model with unit 
> > fixed effects, just by including the id dummies into the equation 
> > (for the test I include the total list weights objects, containing all
linkages).
> >
> >> data_total.nb<-poly2nb(data_subset.spdf)
> >> data_total.lw<-nb2listw(data.nb, style="W")
> >>
> >> spreg_false.mod<-spautolm(sqrt(fortzuege_gem) ~ id  + v1 + v2,
> > +                     data=data_subset.spdf, listw=data_total.lw,
> > weights=area_sqkm,
> > +                     zero.policy=TRUE)
> > Error in solve.default(crossprod(X, as.matrix(IlW %*% X)), tol =
> > tol.solve)
> > :
> >  system is computationally singular: reciprocal condition number =
> > 1.01026e-16
> >>
> >
> > So I assume there occurs some conflict, between using ID dummies and 
> > a weights matrix in one model? Is there any way to solve this problem?
> > This may be a stupid question for some who is (totally) aware of the 
> > mathematics behind the model.
> >
> > I would be really happy about any help!
> >
> > Thank you in advance and best wishes, Tobi
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> 
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics, Helleveien 30, 
> N-
> 5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no


Tobias R?ttenauer
Department of Social Science
TU Kaiserslautern
Erwin-Schr?dinger-Stra?e 57
67663 Kaiserslautern
Germany
ruettenauer at sowi.uni-kl.de


From uzzal at gist.ac.kr  Sat Oct 10 18:04:28 2015
From: uzzal at gist.ac.kr (Uzzal)
Date: Sun, 11 Oct 2015 01:04:28 +0900 (KST)
Subject: [R-sig-Geo] How to model anisotropy and get final isotropic
	variogram for kriging using gstat package?
Message-ID: <2021070244.1444493068796.JavaMail.root@eunhasu>

I have dataset contains hourly Particulate matter concentrations (PM10) of 1 march2012,1.00 am for 104 sites. Please download from HERE. My ultimate goal is to do ordinary Kriging (spatial kriging) analyses for this dataset. As far as I know, I need to plot a isotropic variogram for kriging analysis. For this purpose, I have plotted a omnidirectional variogram with following R code using gstat package:  seoul311
#######################################################library(sp)
library(gstat)
library(rgdal) seoul311 #assign a CRS
proj4string(seoul311) =  "+proj=longlat +datum=WGS84"  #Reprojecting data to utm by rgdal
library(rgdal)
seoul311 #plot Omnidirectional Variogram
seoul311.var #Model fit
model.311 After this, I wanted to check the anisotropy. so, I plotted directional variogram for every 10 degree with tolerance=5 degree by following code:
#Directional Variogram
seoul311.var1 Question: What should I do next to get a final isotropic variogram for Ordinary Kring analysis? How can I model anaisotropy using gstat package in R?  [I am kind of struck here. I have read many documents and example for 2 months but couldn't get a clear procedure to do this! Could anyone please explain in details that what code I should write and what aspect I should keep in mind before starting Ordinary Kriging for this data set? Overall. it will be very helpful for me if I got step by step procedure for doing variogram analysis  before starting kriging.]

Orpheus 




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151011/20f3dd88/attachment.html>

From mauriziomarchi85 at gmail.com  Sat Oct 10 18:50:57 2015
From: mauriziomarchi85 at gmail.com (Maurizio Marchi)
Date: Sat, 10 Oct 2015 18:50:57 +0200
Subject: [R-sig-Geo] Optimal Threshold for binary transformation with biomod2
Message-ID: <CANJhsN0YDyC=gkMObrafc0i9Qe0wyKV9uj6WK0i-5unTkAcDTQ@mail.gmail.com>

Hello everybody.
I'm trying to find a method to calculate the optimal threshold to be used
at the end of a modelling procedure with biomod2. More in detail, I would
like to find the threshold which maximise the True Skill Statistic of my
ensemble model. I know that in BIOMOD there was a specific function for
that but I was not able to find it in the new package, biomod2.

Many thanks, Maurizio


-- 
Maurizio Marchi
Calenzano (FI) - Italy
ID Skype: maurizioxyz
Ubuntu 14.04 LTS
linux user 552742

	[[alternative HTML version deleted]]


From sh_didar62 at yahoo.com  Sat Oct 10 22:24:31 2015
From: sh_didar62 at yahoo.com (shohre didari)
Date: Sat, 10 Oct 2015 20:24:31 +0000 (UTC)
Subject: [R-sig-Geo] error in krigeST
References: <976407268.1934925.1444508671777.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <976407268.1934925.1444508671777.JavaMail.yahoo@mail.yahoo.com>

Dear list,I am trying to estimate the value for one of my station withspatio-temporal kriging. ?I fit the summetric variogram. But when I run krigeST , I receive an error as fallow:sum metric variogram:???sill.s??? range.s?? nugget.s????sill.t??? range.t?? nugget.t???sill.st ?4.636903? 42.316172?? 4.268528??1.023742?? 2.399667?? 0.000000??1.517153 ?range.st ?nugget.st?????? anis 413.552515??1.635058? 59.416671 ?predict <- krigeST(ResidualData ~1, mySTFDF.lessone,? mySTFDF.one,??????????????????? modelList= vgmf.sum.metric,stAni=59.41,computeVar=T)
Error in cbind(v0, X) : number ofrows of matrices must match (see arg 2)What does this error mean?And why do I receive it?What should I do to solve it?
I really appreciate any help 

Thanks in advance,Shohreh
	[[alternative HTML version deleted]]


From asafaneh at yahoo.com  Sun Oct 11 20:07:31 2015
From: asafaneh at yahoo.com (Ashraf Afana)
Date: Sun, 11 Oct 2015 18:07:31 +0000 (UTC)
Subject: [R-sig-Geo] How to filter a xyz vector file
References: <724997063.3115071.1444586851666.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <724997063.3115071.1444586851666.JavaMail.yahoo@mail.yahoo.com>

Hi friends, 

I have a xyz vector file from a terrestrial laser scanner that contains a huge amount of points at a high resolution (approximately 15 mm). I need to reduce the amount of point in the file by selecting N number of points each certain distance (i.e. generate equidistant spacing). I was looking at the available libraries in R (sp, rgdal, etc.), but I was unable to find a function to do so.?Any suggestions?

Ashraf,?
	[[alternative HTML version deleted]]


From HodgessE at uhd.edu  Mon Oct 12 21:27:20 2015
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Mon, 12 Oct 2015 19:27:20 +0000
Subject: [R-sig-Geo] testing for timing in different sections of kriging
Message-ID: <FF9DB805FC41CC4E95825A50F6806302B49027D9@challenger.uhd.campus>

Hello!

I'm looking at the gstat package, in particular at the krige function.  I am interested in the amount of time that different steps within the main krige function itself take.

So what I did (which is probably wrong and complete overkill) is to download the source for gstat, untar it, and then copy it to a new directory called egstat.

In the R directory, I copied krige.R to ekr1.R and changed gstat to egstat; predict to pred1.  Also, I copied gstat.R to egstat.R and predict.gstat.R to pred1.R

I changed the cleanup function to read egstat instead of gstat.  Updated the DESCRIPTION file to read egstat with a number of 1.0.0.

When I try to run "build", this is the error that I get:

-o version.o
gcc -m64 -shared -s -static-libgcc -o egstat.dll tmp.def block.o chfactor.o copy
.o data.o direct.o err.o fit.o gcdist.o getest.o gls.o glvars.o hsehldr.o init.o
ivecop.o lex.o lm.o lufactor.o machine.o mapio.o matop.o meminfo.o memory.o msi
m.o norm.o nsearch.o parse.o polygon.o pqueue.o predict.o pxop.o qrfactor.o rand
om.o read.o reml.o s.o select.o sem.o sim.o solve.o sparse.o sprow.o stat.o subm
at.o userio.o utils.o vario.o vario_fn.o vario_io.o vecop.o version.o -Ld:/RComp
ile/r-compiling/local/local320/lib/x64 -Ld:/RCompile/r-compiling/local/local320/
lib -Lc:/Progra~1/R/R-32~1.2/bin/x64 -lR
installing to C:/Users/hodgesse/AppData/Local/Temp/Rtmpkbqf0I/Rinst10a010ca1991/
egstat/libs/x64
** R
** data
** demo
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded
Error in library.dynam(lib, package, package.lib) :
  DLL 'gstat' not found: maybe not installed for this architecture?
Error: loading failed
Execution halted
ERROR: loading failed
* removing 'C:/Users/hodgesse/AppData/Local/Temp/Rtmpkbqf0I/Rinst10a010ca1991/eg
stat'
      -----------------------------------
ERROR: package installation failed

It's looking for gstat instead of egstat, but I don't know how to fix it.

This is on Windows version 7.

Thanks for any help!

Sincerely,
Erin


Erin M. Hodgess, Ph.D.
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: hodgesse at uhd.edu<mailto:hodgesse at uhd.edu>


	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Mon Oct 12 23:50:04 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 12 Oct 2015 17:50:04 -0400
Subject: [R-sig-Geo] testing for timing in different sections of kriging
In-Reply-To: <FF9DB805FC41CC4E95825A50F6806302B49027D9@challenger.uhd.campus>
References: <FF9DB805FC41CC4E95825A50F6806302B49027D9@challenger.uhd.campus>
Message-ID: <561C2B0C.3050804@uni-muenster.de>

Erin, it seems you try to rename the whole package. In that case, in the
first line of the NAMESPACE file, you also need to make the change, as
it now is

useDynLib(gstat,

Please see "Writing R Extensions" for the full infos you'll need.

A simpler approach to learn about timings might be to not rename the
package, but add your modified function to it (and export those).

On 12/10/15 15:27, Hodgess, Erin wrote:
> Hello!
> 
> I'm looking at the gstat package, in particular at the krige function.  I am interested in the amount of time that different steps within the main krige function itself take.
> 
> So what I did (which is probably wrong and complete overkill) is to download the source for gstat, untar it, and then copy it to a new directory called egstat.
> 
> In the R directory, I copied krige.R to ekr1.R and changed gstat to egstat; predict to pred1.  Also, I copied gstat.R to egstat.R and predict.gstat.R to pred1.R
> 
> I changed the cleanup function to read egstat instead of gstat.  Updated the DESCRIPTION file to read egstat with a number of 1.0.0.
> 
> When I try to run "build", this is the error that I get:
> 
> -o version.o
> gcc -m64 -shared -s -static-libgcc -o egstat.dll tmp.def block.o chfactor.o copy
> .o data.o direct.o err.o fit.o gcdist.o getest.o gls.o glvars.o hsehldr.o init.o
> ivecop.o lex.o lm.o lufactor.o machine.o mapio.o matop.o meminfo.o memory.o msi
> m.o norm.o nsearch.o parse.o polygon.o pqueue.o predict.o pxop.o qrfactor.o rand
> om.o read.o reml.o s.o select.o sem.o sim.o solve.o sparse.o sprow.o stat.o subm
> at.o userio.o utils.o vario.o vario_fn.o vario_io.o vecop.o version.o -Ld:/RComp
> ile/r-compiling/local/local320/lib/x64 -Ld:/RCompile/r-compiling/local/local320/
> lib -Lc:/Progra~1/R/R-32~1.2/bin/x64 -lR
> installing to C:/Users/hodgesse/AppData/Local/Temp/Rtmpkbqf0I/Rinst10a010ca1991/
> egstat/libs/x64
> ** R
> ** data
> ** demo
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** installing vignettes
> ** testing if installed package can be loaded
> Error in library.dynam(lib, package, package.lib) :
>   DLL 'gstat' not found: maybe not installed for this architecture?
> Error: loading failed
> Execution halted
> ERROR: loading failed
> * removing 'C:/Users/hodgesse/AppData/Local/Temp/Rtmpkbqf0I/Rinst10a010ca1991/eg
> stat'
>       -----------------------------------
> ERROR: package installation failed
> 
> It's looking for gstat instead of egstat, but I don't know how to fix it.
> 
> This is on Windows version 7.
> 
> Thanks for any help!
> 
> Sincerely,
> Erin
> 
> 
> Erin M. Hodgess, Ph.D.
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgesse at uhd.edu<mailto:hodgesse at uhd.edu>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151012/bc8889eb/attachment.bin>

From HodgessE at uhd.edu  Tue Oct 13 00:11:27 2015
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Mon, 12 Oct 2015 22:11:27 +0000
Subject: [R-sig-Geo] testing for timing in different sections of kriging
In-Reply-To: <561C2B0C.3050804@uni-muenster.de>
References: <FF9DB805FC41CC4E95825A50F6806302B49027D9@challenger.uhd.campus>
	<561C2B0C.3050804@uni-muenster.de>
Message-ID: <FF9DB805FC41CC4E95825A50F6806302B490291A@challenger.uhd.campus>

Arrgh!  That's it!  Thanks so much!

I like that modified function approach much better.

Thanks again,
Sincerely,
E
rin


-----Original Message-----
From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Edzer Pebesma
Sent: Monday, October 12, 2015 4:50 PM
To: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] testing for timing in different sections of kriging

Erin, it seems you try to rename the whole package. In that case, in the first line of the NAMESPACE file, you also need to make the change, as it now is

useDynLib(gstat,

Please see "Writing R Extensions" for the full infos you'll need.

A simpler approach to learn about timings might be to not rename the package, but add your modified function to it (and export those).

On 12/10/15 15:27, Hodgess, Erin wrote:
> Hello!
> 
> I'm looking at the gstat package, in particular at the krige function.  I am interested in the amount of time that different steps within the main krige function itself take.
> 
> So what I did (which is probably wrong and complete overkill) is to download the source for gstat, untar it, and then copy it to a new directory called egstat.
> 
> In the R directory, I copied krige.R to ekr1.R and changed gstat to 
> egstat; predict to pred1.  Also, I copied gstat.R to egstat.R and 
> predict.gstat.R to pred1.R
> 
> I changed the cleanup function to read egstat instead of gstat.  Updated the DESCRIPTION file to read egstat with a number of 1.0.0.
> 
> When I try to run "build", this is the error that I get:
> 
> -o version.o
> gcc -m64 -shared -s -static-libgcc -o egstat.dll tmp.def block.o 
> chfactor.o copy .o data.o direct.o err.o fit.o gcdist.o getest.o gls.o 
> glvars.o hsehldr.o init.o ivecop.o lex.o lm.o lufactor.o machine.o 
> mapio.o matop.o meminfo.o memory.o msi m.o norm.o nsearch.o parse.o 
> polygon.o pqueue.o predict.o pxop.o qrfactor.o rand om.o read.o reml.o 
> s.o select.o sem.o sim.o solve.o sparse.o sprow.o stat.o subm at.o 
> userio.o utils.o vario.o vario_fn.o vario_io.o vecop.o version.o 
> -Ld:/RComp
> ile/r-compiling/local/local320/lib/x64 
> -Ld:/RCompile/r-compiling/local/local320/
> lib -Lc:/Progra~1/R/R-32~1.2/bin/x64 -lR installing to 
> C:/Users/hodgesse/AppData/Local/Temp/Rtmpkbqf0I/Rinst10a010ca1991/
> egstat/libs/x64
> ** R
> ** data
> ** demo
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** installing vignettes
> ** testing if installed package can be loaded Error in 
> library.dynam(lib, package, package.lib) :
>   DLL 'gstat' not found: maybe not installed for this architecture?
> Error: loading failed
> Execution halted
> ERROR: loading failed
> * removing 
> 'C:/Users/hodgesse/AppData/Local/Temp/Rtmpkbqf0I/Rinst10a010ca1991/eg
> stat'
>       -----------------------------------
> ERROR: package installation failed
> 
> It's looking for gstat instead of egstat, but I don't know how to fix it.
> 
> This is on Windows version 7.
> 
> Thanks for any help!
> 
> Sincerely,
> Erin
> 
> 
> Erin M. Hodgess, Ph.D.
> Associate Professor
> Department of Computer and Mathematical Sciences University of Houston 
> - Downtown
> mailto: hodgesse at uhd.edu<mailto:hodgesse at uhd.edu>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

--
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster, Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info


From r.hijmans at gmail.com  Tue Oct 13 00:20:21 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Mon, 12 Oct 2015 15:20:21 -0700
Subject: [R-sig-Geo] problems for reading ASCII file
In-Reply-To: <CAFrMPsHPctQPQPU4P0amuFpPRX12q+UFipHNvDZ9Fj8bmk8dTw@mail.gmail.com>
References: <CAFrMPsHPctQPQPU4P0amuFpPRX12q+UFipHNvDZ9Fj8bmk8dTw@mail.gmail.com>
Message-ID: <CANtt_hy3jCauzPBpBPwpESzX91se1y3deuH+f4CpHbsRNwd5ng@mail.gmail.com>

Ana Carolina,

You say you are using ascii because:

> i am trying to process a raster image (the one i transformed to ASCII)
> but it is too big to work with it as a raster in R (i am having memory
> problems)...thats why i am trying to see if its simplier to process it
> in ASCII and then bring it back to raster.

That does not make much sense.  Either way you have a very small
raster (260 by 193) and I cannot imagine how that could be to big for
the memory of any computer.
So there is probably something else that is going wrong; that should
be fixed (Now it seems that you are trying to solve the problem by
breaking something unrelated that is not broken.)

Robert



On Wed, Oct 7, 2015 at 12:48 AM, ana carolina cuellar
<anacarocuellar at gmail.com> wrote:
> Hi All, I am trying to read an ASCII file into R and is the first time i am
> trying to work with ASCII files. I saw a previous discussion that this
> command can be used:
>
> library(rgdal)
> library(maptools)
> grid <- readAsciiGrid("<your file and its path>")
> table <- data.frame(grid)
>
> in my case:  grid <- readAsciiGrid("I:/modisv5sm0112_2/prueb/amaascii.txt")
>
>
> but when i used the readAsciiGrid function i get this error:
>
> Error in validObject(.Object) :
>
>   invalid class ?GridTopology? object: cells.dim has incorrect dimension
>
>
> Can anybody tell me why? i dont get why it doesnt work :(
>
> my ASCII file looks like this:
>
> ncols         260
> nrows         193
> xllcorner     12,397449031167
> yllcorner     55,534017291881
> cellsize      0,0012386489974299
> NODATA_value  -9999
> -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999 25 25....etc
>
>
> i am trying to process a raster image (the one i transformed to ASCII)
> but it is too big to work with it as a raster in R (i am having memory
> problems)...thats why i am trying to see if its simplier to process it
> in ASCII and then bring it back to raster.
>
> Thanks a lot!!
>
> Ana
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From dave.gregovich at alaska.gov  Tue Oct 13 00:26:15 2015
From: dave.gregovich at alaska.gov (Gregovich, Dave P (DFG))
Date: Mon, 12 Oct 2015 22:26:15 +0000
Subject: [R-sig-Geo] plotKML 'kml' function with raster input
Message-ID: <174524AB15B8E6478D6F927B2131B09BA90F7908@SOAJNUEXMB4.soa.alaska.gov>

Hello,
I am not able to create a .kml raster via the 'kml' function of plotKML (see the error below).
I am  setting the path to gdal in my windows registry as  'C:/Program Files/GDAL' -- the folder that contains 'gdalwarp.exe' and 'gdal_translate.exe' upon gdal installation.
I have also set the parameters in 'plotKML.env' in the two following ways (I don't know which it is supposed to be).
plotKML.env(gdalwarp = 'C:/Program Files/GDAL', gdal_translate = 'C:/Program Files/GDAL')
and
plotKML.env(gdalwarp = 'C:/Program Files/GDAL/gdalwarp.exe', gdal_translate = 'C:/Program Files/GDAL/gdal_translate.exe')


kml.folder <- 'c:/dave/temp';kml.file <- 'test.kml'
rast <- raster(extent(-135.2,-135.1,58.1,58.2),nrows=10,ncol=10,crs=CRS('+init=epsg:4326'))
rast[]<-rnorm(ncell(rast))
kml(rast,kml.fold,kml.file,colour = 'black')

#Results in the following messages...with no kml or kmz file output.
KML file opened for writing...
Writing to KML...
Closing  test.kml
Warning message:
In paths(show.paths = TRUE) :
  Could not locate GDAL! Install program and add it to the Windows registry. See http://www.gdal.org/ for more info.

> sessionInfo()
R version 3.1.3 (2015-03-09)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

other attached packages:
[1] plotKML_0.5-3 rgdal_1.0-7   raster_2.4-20 sp_1.2-0

++++++++++++++++++++++++++++++++
Thanks kindly for your continued support.

__________________________________
Dave Gregovich
Research Analyst
Alaska Department of Fish and Game
Wildlife Conservation Division
Douglas, AK 99821
(907) 465-4291
dave.gregovich at alaska.gov
__________________________________


	[[alternative HTML version deleted]]


From p.woods at qub.ac.uk  Tue Oct 13 00:30:57 2015
From: p.woods at qub.ac.uk (Paul Woods)
Date: Mon, 12 Oct 2015 22:30:57 +0000
Subject: [R-sig-Geo] plotKML 'kml' function with raster input
In-Reply-To: <174524AB15B8E6478D6F927B2131B09BA90F7908@SOAJNUEXMB4.soa.alaska.gov>
References: <174524AB15B8E6478D6F927B2131B09BA90F7908@SOAJNUEXMB4.soa.alaska.gov>
Message-ID: <1BCA831D-ABB6-4D70-AC35-A36BACA77B46@qub.ac.uk>

Try changing your forward slashes (/) to backward slashes (\) as per Windows standard?

Paul

> On 12 Oct 2015, at 23:26, Gregovich, Dave P (DFG) <dave.gregovich at alaska.gov> wrote:
> 
> Hello,
> I am not able to create a .kml raster via the 'kml' function of plotKML (see the error below).
> I am  setting the path to gdal in my windows registry as  'C:/Program Files/GDAL' -- the folder that contains 'gdalwarp.exe' and 'gdal_translate.exe' upon gdal installation.
> I have also set the parameters in 'plotKML.env' in the two following ways (I don't know which it is supposed to be).
> plotKML.env(gdalwarp = 'C:/Program Files/GDAL', gdal_translate = 'C:/Program Files/GDAL')
> and
> plotKML.env(gdalwarp = 'C:/Program Files/GDAL/gdalwarp.exe', gdal_translate = 'C:/Program Files/GDAL/gdal_translate.exe')
> 
> 
> kml.folder <- 'c:/dave/temp';kml.file <- 'test.kml'
> rast <- raster(extent(-135.2,-135.1,58.1,58.2),nrows=10,ncol=10,crs=CRS('+init=epsg:4326'))
> rast[]<-rnorm(ncell(rast))
> kml(rast,kml.fold,kml.file,colour = 'black')
> 
> #Results in the following messages...with no kml or kmz file output.
> KML file opened for writing...
> Writing to KML...
> Closing  test.kml
> Warning message:
> In paths(show.paths = TRUE) :
>  Could not locate GDAL! Install program and add it to the Windows registry. See http://www.gdal.org/ for more info.
> 
>> sessionInfo()
> R version 3.1.3 (2015-03-09)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
> 
> other attached packages:
> [1] plotKML_0.5-3 rgdal_1.0-7   raster_2.4-20 sp_1.2-0
> 
> ++++++++++++++++++++++++++++++++
> Thanks kindly for your continued support.
> 
> __________________________________
> Dave Gregovich
> Research Analyst
> Alaska Department of Fish and Game
> Wildlife Conservation Division
> Douglas, AK 99821
> (907) 465-4291
> dave.gregovich at alaska.gov
> __________________________________
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From mauriziomarchi85 at gmail.com  Tue Oct 13 10:06:41 2015
From: mauriziomarchi85 at gmail.com (Maurizio Marchi)
Date: Tue, 13 Oct 2015 10:06:41 +0200
Subject: [R-sig-Geo] Optimal Threshold for binary transformation with biomod2
Message-ID: <CANJhsN2tBzt0zUcCRNREZa=A_9wXGDk8eC8bXC5d+NVrm=FJXA@mail.gmail.com>

Hello everybody.
I'm trying to find a method to calculate the optimal threshold to be used
at the end of a modelling procedure with biomod2. More in detail, I would
like to find the threshold which maximise the True Skill Statistic of my
ensemble model. I know that in BIOMOD there was a specific function for
that but I was not able to find it in the new package, biomod2.

Many thanks, Maurizio

-- 
Maurizio Marchi
Calenzano (FI) - Italy
ID Skype: maurizioxyz
Ubuntu 14.04 LTS
linux user 552742

	[[alternative HTML version deleted]]


From englishchristophera at gmail.com  Tue Oct 13 11:58:51 2015
From: englishchristophera at gmail.com (chris english)
Date: Tue, 13 Oct 2015 05:58:51 -0400
Subject: [R-sig-Geo] How to filter a xyz vector file
In-Reply-To: <724997063.3115071.1444586851666.JavaMail.yahoo@mail.yahoo.com>
References: <724997063.3115071.1444586851666.JavaMail.yahoo@mail.yahoo.com>
	<724997063.3115071.1444586851666.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAASFQpR0qWU1NsMCcM+TbH2pXiLxoQTRSMW1H+=U7McEM6wzsw@mail.gmail.com>

Ashraf,
You might consider preprocessing with Lastools.  There are a fair number of
hits for google: cran r lidar inclusive of terrestrial.
HTH,
Chris


On Sun, Oct 11, 2015 at 2:07 PM, Ashraf Afana via R-sig-Geo <
r-sig-geo at r-project.org> wrote:

> Hi friends,
>
> I have a xyz vector file from a terrestrial laser scanner that contains a
> huge amount of points at a high resolution (approximately 15 mm). I need to
> reduce the amount of point in the file by selecting N number of points each
> certain distance (i.e. generate equidistant spacing). I was looking at the
> available libraries in R (sp, rgdal, etc.), but I was unable to find a
> function to do so. Any suggestions?
>
> Ashraf,
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From Virgilio.Gomez at uclm.es  Tue Oct 13 16:17:01 2015
From: Virgilio.Gomez at uclm.es (VIRGILIO GOMEZ RUBIO)
Date: Tue, 13 Oct 2015 14:17:01 +0000
Subject: [R-sig-Geo] FW: Short course "Spatial and Spatio-Temporal Bayesian
 Models with R-INLA"
Message-ID: <82650087-D68A-418E-B853-F4E58B365984@uclm.es>

Hi,

I believe that this course may be of interest to some of the people following this list.

Best,

Virgilio

---


Short course "Spatial and Spatio-Temporal Bayesian Models with R-INLA"

12-15 January 2016 

University of Bergamo (Italy)

 
Instructors

Dr. M. Blangiardo - Imperial College London (www.imperial.ac.uk/people/m.blangiardo)

Dr. M. Cameletti - Universit? di Bergamo (www.unibg.it/pers/?michela.cameletti)

Dr. V. G?mez Rubio - Universidad de Castilla-La Mancha (www.uclm.es/profesorado/vgomez)

 
Description

The course aims at providing an introduction to Bayesian analysis for spatial and spatio-temporal modelling using the R software and R-INLA.

The first day of the course will be dedicated to standard spatial analysis with R for different types of data: this includes data import/export, data management and visualisation for geostatistical, area and point pattern data.

In the following days the theoretical aspects of the Bayesian approach will be introduced, with a particular focus on spatial and spatio-temporal models and on the Integrated Nested Laplace Approximation (INLA, www.r-inla.org) approach, which has proven to be a valid alternative to the commonly used Markov Chain Monte Carlo simulations. A particular emphasis will be given on examples of applied analysis using the R-INLA package.

 
The course timetable is a mixture of lectures and computer practicals based on the following two books:

- Applied spatial data analysis with R (www.asdar-book.org)

- Spatial and spatio-temporal Bayesian models with R-INLA (sites.google.com/a/r-inla.org/stbook)

 
Course fee

The course fee is 200 Euro for PhD students, 300 Euro for Academia / Public sector and 500 Euro for Private Sector. The fee includes course material, coffee breaks, lunches and the social dinner.

 
 
For further information and the registration form, please visit the following webpage

www.unibg.it/r-inlacourse

 
Best wishes,

Michela Cameletti



From Virgilio.Gomez at uclm.es  Tue Oct 13 16:45:49 2015
From: Virgilio.Gomez at uclm.es (VIRGILIO GOMEZ RUBIO)
Date: Tue, 13 Oct 2015 14:45:49 +0000
Subject: [R-sig-Geo] Short course "Spatial and Spatio-Temporal Bayesian
 Models with R-INLA"
In-Reply-To: <82650087-D68A-418E-B853-F4E58B365984@uclm.es>
References: <82650087-D68A-418E-B853-F4E58B365984@uclm.es>
Message-ID: <08E57924-9925-4164-83F1-86E0C9AA2054@uclm.es>

Hi,

It seems that the link to the course registration disappeared when I converted the e-mail from HTML to plain text. Apologies for that.  The right one is:

http://www00.unibg.it/struttura/struttura.asp?cerca=dsaemq_r-inla2015

Best,

Virgilio

El 13/10/2015, a las 16:17, VIRGILIO GOMEZ RUBIO <Virgilio.Gomez at uclm.es<mailto:Virgilio.Gomez at uclm.es>> escribi?:

Hi,

I believe that this course may be of interest to some of the people following this list.

Best,

Virgilio

---


Short course "Spatial and Spatio-Temporal Bayesian Models with R-INLA"

12-15 January 2016

University of Bergamo (Italy)


Instructors

Dr. M. Blangiardo - Imperial College London (www.imperial.ac.uk/people/m.blangiardo<http://www.imperial.ac.uk/people/m.blangiardo>)

Dr. M. Cameletti - Universit? di Bergamo (www.unibg.it/pers/?michela.cameletti<http://www.unibg.it/pers/?michela.cameletti>)

Dr. V. G?mez Rubio - Universidad de Castilla-La Mancha (www.uclm.es/profesorado/vgomez<http://www.uclm.es/profesorado/vgomez>)


Description

The course aims at providing an introduction to Bayesian analysis for spatial and spatio-temporal modelling using the R software and R-INLA.

The first day of the course will be dedicated to standard spatial analysis with R for different types of data: this includes data import/export, data management and visualisation for geostatistical, area and point pattern data.

In the following days the theoretical aspects of the Bayesian approach will be introduced, with a particular focus on spatial and spatio-temporal models and on the Integrated Nested Laplace Approximation (INLA, www.r-inla.org<http://www.r-inla.org>) approach, which has proven to be a valid alternative to the commonly used Markov Chain Monte Carlo simulations. A particular emphasis will be given on examples of applied analysis using the R-INLA package.


The course timetable is a mixture of lectures and computer practicals based on the following two books:

- Applied spatial data analysis with R (www.asdar-book.org<http://www.asdar-book.org>)

- Spatial and spatio-temporal Bayesian models with R-INLA (sites.google.com/a/r-inla.org/stbook<http://sites.google.com/a/r-inla.org/stbook>)


Course fee

The course fee is 200 Euro for PhD students, 300 Euro for Academia / Public sector and 500 Euro for Private Sector. The fee includes course material, coffee breaks, lunches and the social dinner.



For further information and the registration form, please visit the following webpage

www.unibg.it/r-inlacourse<http://www.unibg.it/r-inlacourse>


Best wishes,

Michela Cameletti


_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


	[[alternative HTML version deleted]]


From dave.gregovich at alaska.gov  Tue Oct 13 18:25:54 2015
From: dave.gregovich at alaska.gov (Gregovich, Dave P (DFG))
Date: Tue, 13 Oct 2015 16:25:54 +0000
Subject: [R-sig-Geo] plotKML 'kml' function with raster input
In-Reply-To: <1BCA831D-ABB6-4D70-AC35-A36BACA77B46@qub.ac.uk>
References: <174524AB15B8E6478D6F927B2131B09BA90F7908@SOAJNUEXMB4.soa.alaska.gov>
	<1BCA831D-ABB6-4D70-AC35-A36BACA77B46@qub.ac.uk>
Message-ID: <174524AB15B8E6478D6F927B2131B09BA90F9C11@SOAJNUEXMB4.soa.alaska.gov>

Paul,
Thanks kindly for your response. I am not certain of what you mean. My windows search path has all backslashes (\) although I wasn't clear about this in my example. It is not possible to feed the gdalwarp and gdal_translate paths to plotKML.env() as strings with backslashes in them as they are recognized as escape characters.
I forgot to include library loading in the code I shared previously, and for convenience I do so below...Thanks kindly for any further assistance.

#FIRST: Include path to GDAL install that contains 'gdalwarp.exe' and 'gdal_translate.exe' to windows search path, in my case 'C:\Program Files\GDAL'
#__________________________________
library(raster);library(rgdal);library(plotKML)
#Not sure if necessary, but I tried the following to ensure that paths are set up correctly....
#plotKML.env(gdalwarp = 'C:/Program Files/GDAL', gdal_translate = 'C:/Program Files/GDAL')
# or...
#plotKML.env(gdalwarp = 'C:/Program > Files/GDAL/gdalwarp.exe', gdal_translate = 'C:/Program Files/GDAL/gdal_translate.exe')

kml.folder <- 'c:/dave/temp';kml.file <- 'test.kml'
rast <- raster(extent(-135.2,-135.1,58.1,58.2),nrows=10,ncol=10,crs=CRS('+init=epsg:4326'))
rast[]<-rnorm(ncell(rast))
kml(rast,kml.fold,kml.file,colour = 'black')
#__________________________________

Dave.
-----Original Message-----
From: Paul Woods [mailto:p.woods at qub.ac.uk] 
Sent: Monday, October 12, 2015 2:31 PM
To: Gregovich, Dave P (DFG)
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] plotKML 'kml' function with raster input

Try changing your forward slashes (/) to backward slashes (\) as per Windows standard?

Paul

> On 12 Oct 2015, at 23:26, Gregovich, Dave P (DFG) <dave.gregovich at alaska.gov> wrote:
> 
> Hello,
> I am not able to create a .kml raster via the 'kml' function of plotKML (see the error below).
> I am  setting the path to gdal in my windows registry as  'C:/Program Files/GDAL' -- the folder that contains 'gdalwarp.exe' and 'gdal_translate.exe' upon gdal installation.
> I have also set the parameters in 'plotKML.env' in the two following ways (I don't know which it is supposed to be).
> plotKML.env(gdalwarp = 'C:/Program Files/GDAL', gdal_translate = 
> 'C:/Program Files/GDAL') and plotKML.env(gdalwarp = 'C:/Program 
> Files/GDAL/gdalwarp.exe', gdal_translate = 'C:/Program 
> Files/GDAL/gdal_translate.exe')
> 
> 
> kml.folder <- 'c:/dave/temp';kml.file <- 'test.kml'
> rast <- 
> raster(extent(-135.2,-135.1,58.1,58.2),nrows=10,ncol=10,crs=CRS('+init
> =epsg:4326'))
> rast[]<-rnorm(ncell(rast))
> kml(rast,kml.fold,kml.file,colour = 'black')
> 
> #Results in the following messages...with no kml or kmz file output.
> KML file opened for writing...
> Writing to KML...
> Closing  test.kml
> Warning message:
> In paths(show.paths = TRUE) :
>  Could not locate GDAL! Install program and add it to the Windows registry. See http://www.gdal.org/ for more info.
> 
>> sessionInfo()
> R version 3.1.3 (2015-03-09)
> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 x64 
> (build 7601) Service Pack 1
> 
> other attached packages:
> [1] plotKML_0.5-3 rgdal_1.0-7   raster_2.4-20 sp_1.2-0
> 
> ++++++++++++++++++++++++++++++++
> Thanks kindly for your continued support.
> 
> __________________________________
> Dave Gregovich
> Research Analyst
> Alaska Department of Fish and Game
> Wildlife Conservation Division
> Douglas, AK 99821
> (907) 465-4291
> dave.gregovich at alaska.gov
> __________________________________
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Tue Oct 13 20:53:14 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 13 Oct 2015 11:53:14 -0700
Subject: [R-sig-Geo] How to filter a xyz vector file
In-Reply-To: <724997063.3115071.1444586851666.JavaMail.yahoo@mail.yahoo.com>
References: <724997063.3115071.1444586851666.JavaMail.yahoo@mail.yahoo.com>
	<724997063.3115071.1444586851666.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CANtt_hwRcmYUC+HKAW+YVqvv6q3ZGzcjSgcSWjugZB6XyfokwQ@mail.gmail.com>

Ashraf,
Here is an approach:

# some random points
x <- runif(10000)
y <- runif(10000)
xy <- cbind(x, y)

# a raster to specficy the extent and resolution
library(raster)
r <- raster(round(extent(xy)), res=0.1)

# find the distance of each point to the center of the cell it falls in
cell <- cellFromXY(r, xy)
cellxy <- xyFromCell(r, cell)
d <- pointDistance(xy, cellxy, lonlat=FALSE)

# combine and get, for each cell, the point nearest to the center
z <- cbind(cell, xy, d)
z <- z[order(z[, 1], z[, 4]), ]
zz <- z[!duplicated(z[,1]), ]

# have a look:
r[] = 1
plot(r)
points(z[,2:3], cex=.1)
points(zz[,2:3], col='red', pch=20)
# plot(as(r, 'SpatialPolygons'), add=TRUE)

Best, Robert

On Sun, Oct 11, 2015 at 11:07 AM, Ashraf Afana via R-sig-Geo
<r-sig-geo at r-project.org> wrote:
> Hi friends,
>
> I have a xyz vector file from a terrestrial laser scanner that contains a huge amount of points at a high resolution (approximately 15 mm). I need to reduce the amount of point in the file by selecting N number of points each certain distance (i.e. generate equidistant spacing). I was looking at the available libraries in R (sp, rgdal, etc.), but I was unable to find a function to do so. Any suggestions?
>
> Ashraf,
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From vijaylulla at gmail.com  Wed Oct 14 00:52:44 2015
From: vijaylulla at gmail.com (Vijay Lulla)
Date: Tue, 13 Oct 2015 18:52:44 -0400
Subject: [R-sig-Geo] plotKML 'kml' function with raster input
In-Reply-To: <174524AB15B8E6478D6F927B2131B09BA90F9C11@SOAJNUEXMB4.soa.alaska.gov>
References: <174524AB15B8E6478D6F927B2131B09BA90F7908@SOAJNUEXMB4.soa.alaska.gov>
	<1BCA831D-ABB6-4D70-AC35-A36BACA77B46@qub.ac.uk>
	<174524AB15B8E6478D6F927B2131B09BA90F9C11@SOAJNUEXMB4.soa.alaska.gov>
Message-ID: <CAKkiGbtefsq22EYJ_DA5QMqHFsXuV2vfXKO=EdvNpwZ4BnyXLw@mail.gmail.com>

If you want to use backslash in your string then you'll have to double
them to remove the escape mechanism.  So your path should read
"C:\\Program Files\\GDAL\\gdalwarp.exe" etc.  Please see ?Quote in R
help.

However, there is another (simpler IMO) solution.  If you have the
latest QGIS installed then you can use SAGA and gdal utils from it.
That's how I sometimes use plotKML.  If you wish to try this solution
just download the source for plotKML package and apply the attached
patch.  Just make sure that the patch is in the top directory of
plotKML package (i.e. the directory which has DESCRIPTION and
NAMESPACE files in it).

HTH,
Vijay.

On Tue, Oct 13, 2015 at 12:25 PM, Gregovich, Dave P (DFG)
<dave.gregovich at alaska.gov> wrote:
> Paul,
> Thanks kindly for your response. I am not certain of what you mean. My windows search path has all backslashes (\) although I wasn't clear about this in my example. It is not possible to feed the gdalwarp and gdal_translate paths to plotKML.env() as strings with backslashes in them as they are recognized as escape characters.
> I forgot to include library loading in the code I shared previously, and for convenience I do so below...Thanks kindly for any further assistance.
>
> #FIRST: Include path to GDAL install that contains 'gdalwarp.exe' and 'gdal_translate.exe' to windows search path, in my case 'C:\Program Files\GDAL'
> #__________________________________
> library(raster);library(rgdal);library(plotKML)
> #Not sure if necessary, but I tried the following to ensure that paths are set up correctly....
> #plotKML.env(gdalwarp = 'C:/Program Files/GDAL', gdal_translate = 'C:/Program Files/GDAL')
> # or...
> #plotKML.env(gdalwarp = 'C:/Program > Files/GDAL/gdalwarp.exe', gdal_translate = 'C:/Program Files/GDAL/gdal_translate.exe')
>
> kml.folder <- 'c:/dave/temp';kml.file <- 'test.kml'
> rast <- raster(extent(-135.2,-135.1,58.1,58.2),nrows=10,ncol=10,crs=CRS('+init=epsg:4326'))
> rast[]<-rnorm(ncell(rast))
> kml(rast,kml.fold,kml.file,colour = 'black')
> #__________________________________
>
> Dave.
> -----Original Message-----
> From: Paul Woods [mailto:p.woods at qub.ac.uk]
> Sent: Monday, October 12, 2015 2:31 PM
> To: Gregovich, Dave P (DFG)
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] plotKML 'kml' function with raster input
>
> Try changing your forward slashes (/) to backward slashes (\) as per Windows standard?
>
> Paul
>
>> On 12 Oct 2015, at 23:26, Gregovich, Dave P (DFG) <dave.gregovich at alaska.gov> wrote:
>>
>> Hello,
>> I am not able to create a .kml raster via the 'kml' function of plotKML (see the error below).
>> I am  setting the path to gdal in my windows registry as  'C:/Program Files/GDAL' -- the folder that contains 'gdalwarp.exe' and 'gdal_translate.exe' upon gdal installation.
>> I have also set the parameters in 'plotKML.env' in the two following ways (I don't know which it is supposed to be).
>> plotKML.env(gdalwarp = 'C:/Program Files/GDAL', gdal_translate =
>> 'C:/Program Files/GDAL') and plotKML.env(gdalwarp = 'C:/Program
>> Files/GDAL/gdalwarp.exe', gdal_translate = 'C:/Program
>> Files/GDAL/gdal_translate.exe')
>>
>>
>> kml.folder <- 'c:/dave/temp';kml.file <- 'test.kml'
>> rast <-
>> raster(extent(-135.2,-135.1,58.1,58.2),nrows=10,ncol=10,crs=CRS('+init
>> =epsg:4326'))
>> rast[]<-rnorm(ncell(rast))
>> kml(rast,kml.fold,kml.file,colour = 'black')
>>
>> #Results in the following messages...with no kml or kmz file output.
>> KML file opened for writing...
>> Writing to KML...
>> Closing  test.kml
>> Warning message:
>> In paths(show.paths = TRUE) :
>>  Could not locate GDAL! Install program and add it to the Windows registry. See http://www.gdal.org/ for more info.
>>
>>> sessionInfo()
>> R version 3.1.3 (2015-03-09)
>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 x64
>> (build 7601) Service Pack 1
>>
>> other attached packages:
>> [1] plotKML_0.5-3 rgdal_1.0-7   raster_2.4-20 sp_1.2-0
>>
>> ++++++++++++++++++++++++++++++++
>> Thanks kindly for your continued support.
>>
>> __________________________________
>> Dave Gregovich
>> Research Analyst
>> Alaska Department of Fish and Game
>> Wildlife Conservation Division
>> Douglas, AK 99821
>> (907) 465-4291
>> dave.gregovich at alaska.gov
>> __________________________________
>>
>>
>>       [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
-------------- next part --------------
A non-text attachment was scrubbed...
Name: use_qgis_utils.patch
Type: application/octet-stream
Size: 1063 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151013/a1b4ace7/attachment.obj>

From r.hijmans at gmail.com  Wed Oct 14 04:53:13 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 13 Oct 2015 19:53:13 -0700
Subject: [R-sig-Geo] ncdf 4-dim file to raster brick - level error??
In-Reply-To: <CAM_gmgOLkEKrZA563tm6yPcmF_Z3h=EYjp+W6o2GAe1w458JKw@mail.gmail.com>
References: <CAM_gmgOLkEKrZA563tm6yPcmF_Z3h=EYjp+W6o2GAe1w458JKw@mail.gmail.com>
Message-ID: <CANtt_hycKi7CkmK+ZMB2jbQf=Ji+vgS1rPqe7dwa4zLL5b=LzA@mail.gmail.com>

John
Thank you for reporting this. This has now been fixed in raster-devel
install.packages("raster", repos="http://R-Forge.R-project.org")  and
soon on CRAN.
The error (always using the first level on extraction of cell values)
occurred in ncdf files with "levels" as fourth dimension (rather than
time).
Robert

On Sun, Oct 4, 2015 at 12:48 PM, Gross, John <john_gross at nps.gov> wrote:
> I'm trying to read a 4-dimensional ncdf file (dims: lat lon time
> projection) into a raster brick and can't get it to read anything
> other than the first "level" (i.e. projection, the 4th dimension).
>
> Here's the code, output, and sessionInfo.  This is reminiscent of a
> problem a couple years ago with earlier versions of both ncdf4 and
> raster that was caused by the ncdf file not closing between calls  But
> I'm not sure how to determine it that's happening again.
>
> You can download the data file (10KB - it's only 3x3x59x4) from:
> https://www.dropbox.com/s/5jh5n8etpk1y1hu/Extraction_tasmin.nc?dl=0
>
> #===  Code ==========
> library(ncdf4)
> library(raster)
>
> nc <- nc_open("Extraction_tasmin.nc")    # this is a 3x3 text grid
> nc    # dims are lat long time and projection
>
> xy <- data.frame(x = min(nc$dim$lon$vals) + 1/32, y =
> max(nc$dim$lat$vals) - 1/32) #get top left point not on grid boundary
> coordinates(xy) <- ~x+y
>
> for(i in 1:5){
>   b1 <- brick("Extraction_tasmin.nc", lvar=4, level=i)
>   pts <- t(extract(b1, xy))
>   print(c("pts[1:5} -> ",pts[1:5])); flush.console()
> }
> #====  Output  =======
>
> File Extraction_tasmin.nc (NC_FORMAT_CLASSIC):
>
>      1 variables (excluding dimension variables):
>         float tasmin[longitude,latitude,time,projection]
>             typeConversion_op_ncl: double converted to float
>             _FillValue: 1.00000002004088e+20
>
>      4 dimensions:
>         latitude  Size:3
>             valid_max: 52.875
>             long_name: Latitude
>             valid_min: 25.125
>             units: degrees_north
>             axis: Y
>         longitude  Size:3
>             long_name: Longitude
>             axis: X
>             units: degrees_east
>             modulo: 360
>             topology: circular
>         time  Size:59
>             calendar: standard
>             units: days since 1950-01-01 00:00:00
>             standard_name: time
>             long_name: time
>             axis: T
>         projection  Size:4   *** is unlimited ***
>
>     2 global attributes:
>         NCO: 4.0.8
>         Projections: access1-0.1.rcp85, bcc-csm1-1.1.rcp85,
> canesm2.1.rcp85, ccsm4.1.rcp85,
>>
>
> Output:
> [1] "pts[1:5} -> "      "-5.08642387390137" "-3.23856282234192"
> "-5.46992635726929" "-3.83646535873413" "-3.00846982002258"
> [1] "pts[1:5} -> "      "-5.08642387390137" "-3.23856282234192"
> "-5.46992635726929" "-3.83646535873413" "-3.00846982002258"
> [1] "pts[1:5} -> "      "-5.08642387390137" "-3.23856282234192"
> "-5.46992635726929" "-3.83646535873413" "-3.00846982002258"
> [1] "pts[1:5} -> "      "-5.08642387390137" "-3.23856282234192"
> "-5.46992635726929" "-3.83646535873413" "-3.00846982002258"
> [1] "pts[1:5} -> "      "-5.08642387390137" "-3.23856282234192"
> "-5.46992635726929" "-3.83646535873413" "-3.00846982002258"
> Warning message:
> In .rasterObjectFromCDF(x, type = objecttype, band = band, ...) :
>   level set to: 4
> # ==== sessionInfo =========
> R version 3.2.2 (2015-08-14)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.10.5 (Yosemite)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] ncdf4_1.13    raster_2.4-18 sp_1.1-1
>
> loaded via a namespace (and not attached):
> [1] rgdal_1.0-4     tools_3.2.2     Rcpp_0.12.1     grid_3.2.2
> lattice_0.20-33
>
> --
> John Gross, PhD
> NPS, Ft Collins, CO
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From frtog at vestas.com  Wed Oct 14 07:58:50 2015
From: frtog at vestas.com (=?utf-8?B?RnJlZGUgQWFrbWFubiBUw7hnZXJzZW4=?=)
Date: Wed, 14 Oct 2015 05:58:50 +0000
Subject: [R-sig-Geo] plotKML 'kml' function with raster input
In-Reply-To: <CAKkiGbtefsq22EYJ_DA5QMqHFsXuV2vfXKO=EdvNpwZ4BnyXLw@mail.gmail.com>
References: <174524AB15B8E6478D6F927B2131B09BA90F7908@SOAJNUEXMB4.soa.alaska.gov>
	<1BCA831D-ABB6-4D70-AC35-A36BACA77B46@qub.ac.uk>
	<174524AB15B8E6478D6F927B2131B09BA90F9C11@SOAJNUEXMB4.soa.alaska.gov>
	<CAKkiGbtefsq22EYJ_DA5QMqHFsXuV2vfXKO=EdvNpwZ4BnyXLw@mail.gmail.com>
Message-ID: <HE1PR04MB1276169A302D44FF93160B46DB3F0@HE1PR04MB1276.eurprd04.prod.outlook.com>

Hi Dave

Can you please check that you have a working installation of GDAL.

I installed GDAL on my new windows laptop. First I tried unzipping this release,  release-1800-x64-gdal-1-11-1-mapserver-6-4-1.zip

from http://www.gisinternals.com/query.html?content=filelist&file=release-1800-x64-gdal-1-11-1-mapserver-6-4-1.zip

I opened a cmd window and tried calling gdaltransform.exe (of course specifying the full path) but got an error saying that some dll could not be found. I guess that the dlls didn't get registered by Windows OS this way of installation.

Well installing the 
 
gdal-111-1800-x64-core.msi

from same homepage as above it seemed that the dlls are now registered correctly, because in a cmd window I can now call the gdal functions:

Microsoft Windows [Version 6.2.9200]
(c) 2012 Microsoft Corporation. All rights reserved.

C:\Users\frtog>c:\"Program Files"\GDAL\gdaltransform.exe --help
Usage: gdaltransform [--help-general]
    [-i] [-s_srs srs_def] [-t_srs srs_def] [-to "NAME=VALUE"]
    [-order n] [-tps] [-rpc] [-geoloc]
    [-gcp pixel line easting northing [elevation]]*
    [srcfile [dstfile]]

Now in R this works:

library(raster)
library(rgdal)
library(plotKML)

gdalt <- "C:/Program Files/GDAL/gdaltransform.exe"
gdalw <- "C:/Program Files/GDAL/gdalwarp.exe"

plotKML.env(gdalwarp = gdalw, gdal_translate = gdalt)

kml.folder <- "."
kml.file <- 'test.kml'

rast <- raster(extent(-135.2,-135.1,58.1,58.2),nrows=10,ncol=10,crs=CRS('+init=epsg:4326'))
rast[] <- rnorm(ncell(rast))

kml(rast, kml.folder, kml.file, colour = 'black')


Yours sincerely / Med venlig hilsen

Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 



-----Original Message-----
From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Vijay Lulla
Sent: 14. oktober 2015 00:53
To: Gregovich, Dave P (DFG)
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] plotKML 'kml' function with raster input

If you want to use backslash in your string then you'll have to double
them to remove the escape mechanism.  So your path should read
"C:\\Program Files\\GDAL\\gdalwarp.exe" etc.  Please see ?Quote in R
help.

However, there is another (simpler IMO) solution.  If you have the
latest QGIS installed then you can use SAGA and gdal utils from it.
That's how I sometimes use plotKML.  If you wish to try this solution
just download the source for plotKML package and apply the attached
patch.  Just make sure that the patch is in the top directory of
plotKML package (i.e. the directory which has DESCRIPTION and
NAMESPACE files in it).

HTH,
Vijay.

On Tue, Oct 13, 2015 at 12:25 PM, Gregovich, Dave P (DFG)
<dave.gregovich at alaska.gov> wrote:
> Paul,
> Thanks kindly for your response. I am not certain of what you mean. My windows search path has all backslashes (\) although I wasn't clear about this in my example. It is not possible to feed the gdalwarp and gdal_translate paths to plotKML.env() as strings with backslashes in them as they are recognized as escape characters.
> I forgot to include library loading in the code I shared previously, and for convenience I do so below...Thanks kindly for any further assistance.
>
> #FIRST: Include path to GDAL install that contains 'gdalwarp.exe' and 'gdal_translate.exe' to windows search path, in my case 'C:\Program Files\GDAL'
> #__________________________________
> library(raster);library(rgdal);library(plotKML)
> #Not sure if necessary, but I tried the following to ensure that paths are set up correctly....
> #plotKML.env(gdalwarp = 'C:/Program Files/GDAL', gdal_translate = 'C:/Program Files/GDAL')
> # or...
> #plotKML.env(gdalwarp = 'C:/Program > Files/GDAL/gdalwarp.exe', gdal_translate = 'C:/Program Files/GDAL/gdal_translate.exe')
>
> kml.folder <- 'c:/dave/temp';kml.file <- 'test.kml'
> rast <- raster(extent(-135.2,-135.1,58.1,58.2),nrows=10,ncol=10,crs=CRS('+init=epsg:4326'))
> rast[]<-rnorm(ncell(rast))
> kml(rast,kml.fold,kml.file,colour = 'black')
> #__________________________________
>
> Dave.
> -----Original Message-----
> From: Paul Woods [mailto:p.woods at qub.ac.uk]
> Sent: Monday, October 12, 2015 2:31 PM
> To: Gregovich, Dave P (DFG)
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] plotKML 'kml' function with raster input
>
> Try changing your forward slashes (/) to backward slashes (\) as per Windows standard?
>
> Paul
>
>> On 12 Oct 2015, at 23:26, Gregovich, Dave P (DFG) <dave.gregovich at alaska.gov> wrote:
>>
>> Hello,
>> I am not able to create a .kml raster via the 'kml' function of plotKML (see the error below).
>> I am  setting the path to gdal in my windows registry as  'C:/Program Files/GDAL' -- the folder that contains 'gdalwarp.exe' and 'gdal_translate.exe' upon gdal installation.
>> I have also set the parameters in 'plotKML.env' in the two following ways (I don't know which it is supposed to be).
>> plotKML.env(gdalwarp = 'C:/Program Files/GDAL', gdal_translate =
>> 'C:/Program Files/GDAL') and plotKML.env(gdalwarp = 'C:/Program
>> Files/GDAL/gdalwarp.exe', gdal_translate = 'C:/Program
>> Files/GDAL/gdal_translate.exe')
>>
>>
>> kml.folder <- 'c:/dave/temp';kml.file <- 'test.kml'
>> rast <-
>> raster(extent(-135.2,-135.1,58.1,58.2),nrows=10,ncol=10,crs=CRS('+init
>> =epsg:4326'))
>> rast[]<-rnorm(ncell(rast))
>> kml(rast,kml.fold,kml.file,colour = 'black')
>>
>> #Results in the following messages...with no kml or kmz file output.
>> KML file opened for writing...
>> Writing to KML...
>> Closing  test.kml
>> Warning message:
>> In paths(show.paths = TRUE) :
>>  Could not locate GDAL! Install program and add it to the Windows registry. See http://www.gdal.org/ for more info.
>>
>>> sessionInfo()
>> R version 3.1.3 (2015-03-09)
>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 x64
>> (build 7601) Service Pack 1
>>
>> other attached packages:
>> [1] plotKML_0.5-3 rgdal_1.0-7   raster_2.4-20 sp_1.2-0
>>
>> ++++++++++++++++++++++++++++++++
>> Thanks kindly for your continued support.
>>
>> __________________________________
>> Dave Gregovich
>> Research Analyst
>> Alaska Department of Fish and Game
>> Wildlife Conservation Division
>> Douglas, AK 99821
>> (907) 465-4291
>> dave.gregovich at alaska.gov
>> __________________________________
>>
>>
>>       [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

From venek at gmx.at  Wed Oct 14 15:11:14 2015
From: venek at gmx.at (Vv)
Date: Wed, 14 Oct 2015 15:11:14 +0200
Subject: [R-sig-Geo] sp and adehabitatHR: combine UDs
Message-ID: <trinity-ece3c3b1-4db5-40ab-8b9e-ba2c5d55bbb7-1444828274314@3capp-gmx-bs02>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151014/ab0f3b82/attachment.html>

From dave.gregovich at alaska.gov  Wed Oct 14 19:32:08 2015
From: dave.gregovich at alaska.gov (Gregovich, Dave P (DFG))
Date: Wed, 14 Oct 2015 17:32:08 +0000
Subject: [R-sig-Geo] plotKML 'kml' function with raster input
In-Reply-To: <HE1PR04MB1276169A302D44FF93160B46DB3F0@HE1PR04MB1276.eurprd04.prod.outlook.com>
References: <174524AB15B8E6478D6F927B2131B09BA90F7908@SOAJNUEXMB4.soa.alaska.gov>
	<1BCA831D-ABB6-4D70-AC35-A36BACA77B46@qub.ac.uk>
	<174524AB15B8E6478D6F927B2131B09BA90F9C11@SOAJNUEXMB4.soa.alaska.gov>
	<CAKkiGbtefsq22EYJ_DA5QMqHFsXuV2vfXKO=EdvNpwZ4BnyXLw@mail.gmail.com>
	<HE1PR04MB1276169A302D44FF93160B46DB3F0@HE1PR04MB1276.eurprd04.prod.outlook.com>
Message-ID: <174524AB15B8E6478D6F927B2131B09BA90FADAF@SOAJNUEXMB4.soa.alaska.gov>

Frede,
Thanks kindly for taking the time.
I installed gdal via the installer 'gdal-111-1800-x64-core.msi' at http://www.gisinternals.com.
The kml function is now working fine. 
Note one minor change to your code below: gdalt <- "C:/Program Files/GDAL/gdaltransform.exe" should be gdalt <- "C:/Program Files/GDAL/gdal_translate.exe"
Dave.

-----Original Message-----
From: Frede Aakmann T?gersen [mailto:frtog at vestas.com] 
Sent: Tuesday, October 13, 2015 9:59 PM
To: Vijay Lulla; Gregovich, Dave P (DFG)
Cc: r-sig-geo at r-project.org
Subject: RE: [R-sig-Geo] plotKML 'kml' function with raster input

Hi Dave

Can you please check that you have a working installation of GDAL.

I installed GDAL on my new windows laptop. First I tried unzipping this release,  release-1800-x64-gdal-1-11-1-mapserver-6-4-1.zip

from http://www.gisinternals.com/query.html?content=filelist&file=release-1800-x64-gdal-1-11-1-mapserver-6-4-1.zip

I opened a cmd window and tried calling gdaltransform.exe (of course specifying the full path) but got an error saying that some dll could not be found. I guess that the dlls didn't get registered by Windows OS this way of installation.

Well installing the 
 
gdal-111-1800-x64-core.msi

from same homepage as above it seemed that the dlls are now registered correctly, because in a cmd window I can now call the gdal functions:

Microsoft Windows [Version 6.2.9200]
(c) 2012 Microsoft Corporation. All rights reserved.

C:\Users\frtog>c:\"Program Files"\GDAL\gdaltransform.exe --help
Usage: gdaltransform [--help-general]
    [-i] [-s_srs srs_def] [-t_srs srs_def] [-to "NAME=VALUE"]
    [-order n] [-tps] [-rpc] [-geoloc]
    [-gcp pixel line easting northing [elevation]]*
    [srcfile [dstfile]]

Now in R this works:

library(raster)
library(rgdal)
library(plotKML)

gdalt <- "C:/Program Files/GDAL/gdaltransform.exe"
gdalw <- "C:/Program Files/GDAL/gdalwarp.exe"

plotKML.env(gdalwarp = gdalw, gdal_translate = gdalt)

kml.folder <- "."
kml.file <- 'test.kml'

rast <- raster(extent(-135.2,-135.1,58.1,58.2),nrows=10,ncol=10,crs=CRS('+init=epsg:4326'))
rast[] <- rnorm(ncell(rast))

kml(rast, kml.folder, kml.file, colour = 'black')


Yours sincerely / Med venlig hilsen

Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice If you have received this e-mail in error please contact the sender. 



-----Original Message-----
From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Vijay Lulla
Sent: 14. oktober 2015 00:53
To: Gregovich, Dave P (DFG)
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] plotKML 'kml' function with raster input

If you want to use backslash in your string then you'll have to double them to remove the escape mechanism.  So your path should read "C:\\Program Files\\GDAL\\gdalwarp.exe" etc.  Please see ?Quote in R help.

However, there is another (simpler IMO) solution.  If you have the latest QGIS installed then you can use SAGA and gdal utils from it.
That's how I sometimes use plotKML.  If you wish to try this solution just download the source for plotKML package and apply the attached patch.  Just make sure that the patch is in the top directory of plotKML package (i.e. the directory which has DESCRIPTION and NAMESPACE files in it).

HTH,
Vijay.

On Tue, Oct 13, 2015 at 12:25 PM, Gregovich, Dave P (DFG) <dave.gregovich at alaska.gov> wrote:
> Paul,
> Thanks kindly for your response. I am not certain of what you mean. My windows search path has all backslashes (\) although I wasn't clear about this in my example. It is not possible to feed the gdalwarp and gdal_translate paths to plotKML.env() as strings with backslashes in them as they are recognized as escape characters.
> I forgot to include library loading in the code I shared previously, and for convenience I do so below...Thanks kindly for any further assistance.
>
> #FIRST: Include path to GDAL install that contains 'gdalwarp.exe' and 'gdal_translate.exe' to windows search path, in my case 'C:\Program Files\GDAL'
> #__________________________________
> library(raster);library(rgdal);library(plotKML)
> #Not sure if necessary, but I tried the following to ensure that paths are set up correctly....
> #plotKML.env(gdalwarp = 'C:/Program Files/GDAL', gdal_translate = 
> 'C:/Program Files/GDAL') # or...
> #plotKML.env(gdalwarp = 'C:/Program > Files/GDAL/gdalwarp.exe', 
> gdal_translate = 'C:/Program Files/GDAL/gdal_translate.exe')
>
> kml.folder <- 'c:/dave/temp';kml.file <- 'test.kml'
> rast <- 
> raster(extent(-135.2,-135.1,58.1,58.2),nrows=10,ncol=10,crs=CRS('+init
> =epsg:4326'))
> rast[]<-rnorm(ncell(rast))
> kml(rast,kml.fold,kml.file,colour = 'black') 
> #__________________________________
>
> Dave.
> -----Original Message-----
> From: Paul Woods [mailto:p.woods at qub.ac.uk]
> Sent: Monday, October 12, 2015 2:31 PM
> To: Gregovich, Dave P (DFG)
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] plotKML 'kml' function with raster input
>
> Try changing your forward slashes (/) to backward slashes (\) as per Windows standard?
>
> Paul
>
>> On 12 Oct 2015, at 23:26, Gregovich, Dave P (DFG) <dave.gregovich at alaska.gov> wrote:
>>
>> Hello,
>> I am not able to create a .kml raster via the 'kml' function of plotKML (see the error below).
>> I am  setting the path to gdal in my windows registry as  'C:/Program Files/GDAL' -- the folder that contains 'gdalwarp.exe' and 'gdal_translate.exe' upon gdal installation.
>> I have also set the parameters in 'plotKML.env' in the two following ways (I don't know which it is supposed to be).
>> plotKML.env(gdalwarp = 'C:/Program Files/GDAL', gdal_translate = 
>> 'C:/Program Files/GDAL') and plotKML.env(gdalwarp = 'C:/Program 
>> Files/GDAL/gdalwarp.exe', gdal_translate = 'C:/Program
>> Files/GDAL/gdal_translate.exe')
>>
>>
>> kml.folder <- 'c:/dave/temp';kml.file <- 'test.kml'
>> rast <-
>> raster(extent(-135.2,-135.1,58.1,58.2),nrows=10,ncol=10,crs=CRS('+ini
>> t
>> =epsg:4326'))
>> rast[]<-rnorm(ncell(rast))
>> kml(rast,kml.fold,kml.file,colour = 'black')
>>
>> #Results in the following messages...with no kml or kmz file output.
>> KML file opened for writing...
>> Writing to KML...
>> Closing  test.kml
>> Warning message:
>> In paths(show.paths = TRUE) :
>>  Could not locate GDAL! Install program and add it to the Windows registry. See http://www.gdal.org/ for more info.
>>
>>> sessionInfo()
>> R version 3.1.3 (2015-03-09)
>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7 
>> x64 (build 7601) Service Pack 1
>>
>> other attached packages:
>> [1] plotKML_0.5-3 rgdal_1.0-7   raster_2.4-20 sp_1.2-0
>>
>> ++++++++++++++++++++++++++++++++
>> Thanks kindly for your continued support.
>>
>> __________________________________
>> Dave Gregovich
>> Research Analyst
>> Alaska Department of Fish and Game
>> Wildlife Conservation Division
>> Douglas, AK 99821
>> (907) 465-4291
>> dave.gregovich at alaska.gov
>> __________________________________
>>
>>
>>       [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

From basille.web at ase-research.org  Thu Oct 15 00:47:13 2015
From: basille.web at ase-research.org (Mathieu Basille)
Date: Wed, 14 Oct 2015 18:47:13 -0400
Subject: [R-sig-Geo] sp and adehabitatHR: combine UDs
In-Reply-To: <trinity-ece3c3b1-4db5-40ab-8b9e-ba2c5d55bbb7-1444828274314@3capp-gmx-bs02>
References: <trinity-ece3c3b1-4db5-40ab-8b9e-ba2c5d55bbb7-1444828274314@3capp-gmx-bs02>
Message-ID: <561EDB71.6060301@ase-research.org>

Hi Ena,

I'm not sure I completely understand what you want to achieve, but did you
consider using a pre-defined grid (i.e. SpatialPixels) to constrain the
output? See the help from '?kernelbb':

    grid: a number giving the size of the grid on which the UD should
          be estimated.  *Alternatively, this parameter may be an object
          of class 'SpatialPixels'*, or a list of objects of class
          'SpatialPixels', with named elements corresponding to each
          level of the factor id

Hope this helps,
Mathieu.


Le 14/10/2015 09:11, Vv a ?crit :
> Hello list,
> I wonder if there already exists a solution on how to combine UDs.
> My intention is to create a reference UD for Mon, Tue, ...., Sun - thus, 7 
> reference UDs.
> Hence, I compute for each Monday within my data the Brownian bridge home range.
> I do not use the byburst function because I use different grid parameters.
> Then I would like to (maybe) average all the estimated UDs for Mondays and 
> create one single estUD or SpatialPixelsDataFrame.
> (To recreate an estUD would be awesome because then I could use getverticeshr to 
> estimate the home range.)
> I tried to figure out an example:
> library(adehabitatHR)
> library(maptools)
> data(puechcirc)
> 
> dOne<-puechcirc[1]
> dTwo<-puechcirc[2]
> tata1<-kernelbb(dOne, sig1=6.23, sig2=58, grid=50)
> tata2<-kernelbb(dTwo, sig1=3.72, sig2=58, grid=80)
> The goal should be to generate an extended averaged UD out of the two.
> I've already tried spRbind but of course it just returned the positions but not 
> the data within the pixels.
> I also think that the different grid cell size could be challenging but for my 
> data I have not find a better way
> to achieve ~50 meters cell size than to align the grid parameter on the data.
> I would appreciate any help :)
> Best, Ena
> (Of course I will send you the solution if I find one)
> 
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 

Mathieu Basille
basille at ufl.edu | http://ase-research.org/basille
+1 954-577-6314 | University of Florida FLREC

  ? Le tout est de tout dire, et je manque de mots
  Et je manque de temps, et je manque d'audace. ?
  ? Paul ?luard

This message is signed to guarantee its authenticity.
For a true private correspondence, use my public key
to encrypt your messages:
  http://mathieu.basille.net/pub.asc
Learn more: http://mzl.la/1BsOGiZ

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151014/3af0613d/attachment.bin>

From omaralthwaini at yahoo.com  Thu Oct 15 07:43:46 2015
From: omaralthwaini at yahoo.com (Omar Faisel)
Date: Thu, 15 Oct 2015 05:43:46 +0000 (UTC)
Subject: [R-sig-Geo] Spatial prediction map using raster format dataset
In-Reply-To: <1501570335.241931.1444836883237.JavaMail.yahoo@mail.yahoo.com>
References: <1501570335.241931.1444836883237.JavaMail.yahoo@mail.yahoo.com>
	<1501570335.241931.1444836883237.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1867715764.658386.1444887826280.JavaMail.yahoo@mail.yahoo.com>




Dear All,
My data represent landslides locations and conditioning factors (5000 row, 2000 column, tiff format) ?contain the following:1- Training and testing locations (1=exist, 0= not, also -9999 value refer to no-data areas)2- Independent variables like slope, elevation..etc.
Which type of code do i need to use :1- To read the files, (which format?)2- To run linear regression or any prediction model.
Thank you in advance.

Omar.



 
   
	[[alternative HTML version deleted]]


From asafaneh at yahoo.com  Thu Oct 15 10:55:41 2015
From: asafaneh at yahoo.com (Ashraf Afana)
Date: Thu, 15 Oct 2015 08:55:41 +0000 (UTC)
Subject: [R-sig-Geo] How to filter a xyz vector file
In-Reply-To: <CANtt_hwRcmYUC+HKAW+YVqvv6q3ZGzcjSgcSWjugZB6XyfokwQ@mail.gmail.com>
References: <CANtt_hwRcmYUC+HKAW+YVqvv6q3ZGzcjSgcSWjugZB6XyfokwQ@mail.gmail.com>
Message-ID: <16954349.1029603.1444899341261.JavaMail.yahoo@mail.yahoo.com>

Dear Robert,?Thanks a lot. This code really works in a nice and simple way.Ashraf, cheers 


     El Martes 13 de octubre de 2015 19:53, Robert J. Hijmans <r.hijmans at gmail.com> escribi?:
   

 Ashraf,
Here is an approach:

# some random points
x <- runif(10000)
y <- runif(10000)
xy <- cbind(x, y)

# a raster to specficy the extent and resolution
library(raster)
r <- raster(round(extent(xy)), res=0.1)

# find the distance of each point to the center of the cell it falls in
cell <- cellFromXY(r, xy)
cellxy <- xyFromCell(r, cell)
d <- pointDistance(xy, cellxy, lonlat=FALSE)

# combine and get, for each cell, the point nearest to the center
z <- cbind(cell, xy, d)
z <- z[order(z[, 1], z[, 4]), ]
zz <- z[!duplicated(z[,1]), ]

# have a look:
r[] = 1
plot(r)
points(z[,2:3], cex=.1)
points(zz[,2:3], col='red', pch=20)
# plot(as(r, 'SpatialPolygons'), add=TRUE)

Best, Robert

On Sun, Oct 11, 2015 at 11:07 AM, Ashraf Afana via R-sig-Geo
<r-sig-geo at r-project.org> wrote:
> Hi friends,
>
> I have a xyz vector file from a terrestrial laser scanner that contains a huge amount of points at a high resolution (approximately 15 mm). I need to reduce the amount of point in the file by selecting N number of points each certain distance (i.e. generate equidistant spacing). I was looking at the available libraries in R (sp, rgdal, etc.), but I was unable to find a function to do so. Any suggestions?
>
> Ashraf,
>? ? ? ? [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

  
	[[alternative HTML version deleted]]


From e.o.folmer at gmail.com  Thu Oct 15 12:19:16 2015
From: e.o.folmer at gmail.com (Eelke Folmer)
Date: Thu, 15 Oct 2015 12:19:16 +0200
Subject: [R-sig-Geo] Spatial prediction map using raster format dataset
In-Reply-To: <1867715764.658386.1444887826280.JavaMail.yahoo@mail.yahoo.com>
References: <1501570335.241931.1444836883237.JavaMail.yahoo@mail.yahoo.com>	<1501570335.241931.1444836883237.JavaMail.yahoo@mail.yahoo.com>
	<1867715764.658386.1444887826280.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <561F7DA4.9000601@gmail.com>

Omar,
I think that the following document will be of help:
https://cran.r-project.org/web/packages/dismo/vignettes/sdm.pdf
It is a gentle and practical introduction to raster: both data handling 
and regression. It is about species distribution modeling but the 
principles apply to your question too, I think.
Eelke

On 10/15/2015 07:43 AM, Omar Faisel wrote:
>
>
>
> Dear All,
> My data represent landslides locations and conditioning factors (5000 row, 2000 column, tiff format)  contain the following:1- Training and testing locations (1=ist, 0= not, also -9999 value refer to no-data areas)2- Independent variables like slope, elevation..etc.
> Which type of code do i need to use :1- To read the files, (which format?)2- To run linear regression or any prediction model.
> Thank you in advance.
>
> Omar.
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>


From cryan at binghamton.edu  Wed Oct 14 19:35:40 2015
From: cryan at binghamton.edu (Christopher W. Ryan)
Date: Wed, 14 Oct 2015 13:35:40 -0400
Subject: [R-sig-Geo] density from spatstat less than zero
Message-ID: <561E926C.1090207@binghamton.edu>

Hello. I'm a longtime user of R and subscriber to R-help, but new to
R-sig-geo.  I'm running R 3.1.3 and spatstat 1.41-1 on Windows XP.

I have a point pattern consisting of about 26,000 points, in an area as
follows:

Window: polygonal boundary
single connected closed polygon with 133 vertices
enclosing rectangle: [370698.1, 476022.1] x [4649777, 4732634] units
Window area = 6525710000 square units

It is clearly inhomogeneous, with most points clustered in the region's
central city, and very few of them in the vast rural areas.

The density() command from spatstat with all default values gives a
density that is overly-smoothed for my purposes. Using density()
command, with all default values except sigma=bw.diggle or sigma=bw.ppl,
yields densities that are, to the eye, a better match for the point
pattern, but some of the density values are less than zero, although
this is not apparent when I plot() the density.  The same happens if I
use the default sigma and set adjust to much of anything less than 1.

Any ideas why, and how to avoid the negative values?

My apologies for not including a minimal working example. Including the
entire point pattern would be cumbersome. Whittling it down to 100 or so
points still yields the same problem, but I think that changes the game
and would not be a true reflection of my situation.

Thanks.

--Chris
-- 
Christopher W. Ryan, MD, MS
cryanatbinghamtondotedu
https://www.linkedin.com/in/ryancw

Early success is a terrible teacher. You?re essentially being rewarded
for a lack of preparation, so when you find yourself in a situation
where you must prepare, you can?t do it. You don?t know how.
--Chris Hadfield, An Astronaut's Guide to Life on Earth


From mbressan at arpa.veneto.it  Thu Oct 15 17:07:39 2015
From: mbressan at arpa.veneto.it (Massimo Bressan)
Date: Thu, 15 Oct 2015 17:07:39 +0200
Subject: [R-sig-Geo] how to read in R a big raster of about 6 Gb
Message-ID: <1444921659.2123.55.camel@arpa.veneto.it>

hi all


I need to perform a zonal statistics by overlapping a DEM raster (ESRI
grid binary) with some polygons (ESRI polygons);

the problem is that I first of all need to read the raster, which is
quite big: about 6 Gbyte;

I know about the function readGDAL() by the fantastic package "rgdal"
which is usually working very well with smaller size files but this time
I got completely stuck (the pc freezes invariably)

do you have any advice on how to deal with such a problem (big file)?

thank you

regards


From Dominik.Schneider at colorado.edu  Thu Oct 15 17:26:27 2015
From: Dominik.Schneider at colorado.edu (Dominik Schneider)
Date: Thu, 15 Oct 2015 09:26:27 -0600
Subject: [R-sig-Geo] how to read in R a big raster of about 6 Gb
In-Reply-To: <1444921659.2123.55.camel@arpa.veneto.it>
References: <1444921659.2123.55.camel@arpa.veneto.it>
Message-ID: <CAHYDKLbw0x0D1gcrCM4J69btfO7rMQ0sQBzVBER9zHS-2wLbdA@mail.gmail.com>

You can use the raster package,  which will leave the values on disk if
they are too big for memory.
Use the function raster() to read the DEM, then use readOGR() to read the
polygon shape file. You can then use extract() to get statistics on your
DEM. I'm guessing it'll take a while to extract from disk, so if you are
planning to extract multiple times, you should consider copying your DEM
and setting the values equal to the cell numbers with values(DEM) <-
1:ncell(DEM).  Extract this once, keep track of which cell numbers are in
which polygon and then use the cell numbers to index the DEM when you need
values by polygon.
Hope this helps,
Dominik


On Thu, Oct 15, 2015 at 9:07 AM, Massimo Bressan <mbressan at arpa.veneto.it>
wrote:

> hi all
>
>
> I need to perform a zonal statistics by overlapping a DEM raster (ESRI
> grid binary) with some polygons (ESRI polygons);
>
> the problem is that I first of all need to read the raster, which is
> quite big: about 6 Gbyte;
>
> I know about the function readGDAL() by the fantastic package "rgdal"
> which is usually working very well with smaller size files but this time
> I got completely stuck (the pc freezes invariably)
>
> do you have any advice on how to deal with such a problem (big file)?
>
> thank you
>
> regards
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From mbressan at arpa.veneto.it  Thu Oct 15 18:31:20 2015
From: mbressan at arpa.veneto.it (Massimo Bressan)
Date: Thu, 15 Oct 2015 18:31:20 +0200
Subject: [R-sig-Geo] how to read in R a big raster of about 6 Gb
In-Reply-To: <CAHYDKLbw0x0D1gcrCM4J69btfO7rMQ0sQBzVBER9zHS-2wLbdA@mail.gmail.com>
References: <1444921659.2123.55.camel@arpa.veneto.it>
	<CAHYDKLbw0x0D1gcrCM4J69btfO7rMQ0sQBzVBER9zHS-2wLbdA@mail.gmail.com>
Message-ID: <1444926680.2144.10.camel@arpa.veneto.it>

hi, thanks for your prompt reply

in fact by using raster() funciontion "reading" DEM is quite fast and
also reading the polygons by readOGR() went quite smooth...

the problem then come with the extract() function that is taking definitely too
long...

I'm not quite sure I'm completely grasping your hint about
 values(DEM) <- 1:ncell(DEM)
for speeding up the process

please also consider that the SpatialPolygonDataFrame that I readOGR() has 23 fields;
I need finally to associate the DEM values with the levels represented by one of these fields:
do you think is a good idea eliminating the not necessary fields?

max
 


Il giorno Thu, 15/10/2015 alle 09.26 -0600, Dominik Schneider ha
scritto:
> You can use the raster package,  which will leave the values on disk
> if they are too big for memory.
> Use the function raster() to read the DEM, then use readOGR() to read
> the polygon shape file. You can then use extract() to get statistics
> on your DEM. I'm guessing it'll take a while to extract from disk, so
> if you are planning to extract multiple times, you should consider
> copying your DEM and setting the values equal to the cell numbers with
> values(DEM) <- 1:ncell(DEM).  Extract this once, keep track of which
> cell numbers are in which polygon and then use the cell numbers to
> index the DEM when you need values by polygon.
> Hope this helps,
> Dominik
> 
> 
> 
> On Thu, Oct 15, 2015 at 9:07 AM, Massimo Bressan
> <mbressan at arpa.veneto.it> wrote:
>         hi all
>         
>         
>         I need to perform a zonal statistics by overlapping a DEM
>         raster (ESRI
>         grid binary) with some polygons (ESRI polygons);
>         
>         the problem is that I first of all need to read the raster,
>         which is
>         quite big: about 6 Gbyte;
>         
>         I know about the function readGDAL() by the fantastic package
>         "rgdal"
>         which is usually working very well with smaller size files but
>         this time
>         I got completely stuck (the pc freezes invariably)
>         
>         do you have any advice on how to deal with such a problem (big
>         file)?
>         
>         thank you
>         
>         regards
>         
>         _______________________________________________
>         R-sig-Geo mailing list
>         R-sig-Geo at r-project.org
>         https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
>


From basille.web at ase-research.org  Thu Oct 15 19:44:15 2015
From: basille.web at ase-research.org (Mathieu Basille)
Date: Thu, 15 Oct 2015 13:44:15 -0400
Subject: [R-sig-Geo] sp and adehabitatHR: combine UDs
In-Reply-To: <trinity-b14d1482-8c55-4c7e-969c-43f34332eac4-1444886077128@3capp-gmx-bs18>
References: <trinity-ece3c3b1-4db5-40ab-8b9e-ba2c5d55bbb7-1444828274314@3capp-gmx-bs02>,
	<561EDB71.6060301@ase-research.org>
	<trinity-b14d1482-8c55-4c7e-969c-43f34332eac4-1444886077128@3capp-gmx-bs18>
Message-ID: <561FE5EF.60507@ase-research.org>

Well, if you want to combine several maps in one SpatialPixelsDataFrame,
there's really no other way than having the same grid for all individuals.
70 km in one dimension is only an issue if your grid has a cell size of a
few meters! If you keep it reasonable (say >= 100 m), that shouldn't be an
issue for processing time (which is a direct function of the resolution of
the grid, not the geographic size itself).

Mathieu.


Le 15/10/2015 01:14, Vv a ?crit :
> Hi Mathieu,
> thanks for the quick reply.
> I have considered it but my problem is that this pre-defined grid would be way 
> too large (>70km in one dimension).
> However, I have to admit that I haven't tried it yet.
> Do you have experiences with that concerning processing time?
> Thanks,
> Ena
> *Gesendet:* Donnerstag, 15. Oktober 2015 um 00:47 Uhr
> *Von:* "Mathieu Basille" <basille.web at ase-research.org>
> *An:* Vv <venek at gmx.at>, r-sig-geo at r-project.org
> *Betreff:* Re: [R-sig-Geo] sp and adehabitatHR: combine UDs
> Hi Ena,
> 
> I'm not sure I completely understand what you want to achieve, but did you
> consider using a pre-defined grid (i.e. SpatialPixels) to constrain the
> output? See the help from '?kernelbb':
> 
> grid: a number giving the size of the grid on which the UD should
> be estimated. *Alternatively, this parameter may be an object
> of class 'SpatialPixels'*, or a list of objects of class
> 'SpatialPixels', with named elements corresponding to each
> level of the factor id
> 
> Hope this helps,
> Mathieu.
> 
> 
> Le 14/10/2015 09:11, Vv a ?crit :
>  > Hello list,
>  > I wonder if there already exists a solution on how to combine UDs.
>  > My intention is to create a reference UD for Mon, Tue, ...., Sun - thus, 7
>  > reference UDs.
>  > Hence, I compute for each Monday within my data the Brownian bridge home range.
>  > I do not use the byburst function because I use different grid parameters.
>  > Then I would like to (maybe) average all the estimated UDs for Mondays and
>  > create one single estUD or SpatialPixelsDataFrame.
>  > (To recreate an estUD would be awesome because then I could use getverticeshr to
>  > estimate the home range.)
>  > I tried to figure out an example:
>  > library(adehabitatHR)
>  > library(maptools)
>  > data(puechcirc)
>  >
>  > dOne<-puechcirc[1]
>  > dTwo<-puechcirc[2]
>  > tata1<-kernelbb(dOne, sig1=6.23, sig2=58, grid=50)
>  > tata2<-kernelbb(dTwo, sig1=3.72, sig2=58, grid=80)
>  > The goal should be to generate an extended averaged UD out of the two.
>  > I've already tried spRbind but of course it just returned the positions but not
>  > the data within the pixels.
>  > I also think that the different grid cell size could be challenging but for my
>  > data I have not find a better way
>  > to achieve ~50 meters cell size than to align the grid parameter on the data.
>  > I would appreciate any help :)
>  > Best, Ena
>  > (Of course I will send you the solution if I find one)
>  >
>  >
>  >
>  > _______________________________________________
>  > R-sig-Geo mailing list
>  > R-sig-Geo at r-project.org
>  > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>  >
> 
> --
> 
> Mathieu Basille
> basille at ufl.edu | http://ase-research.org/basille
> +1 954-577-6314 | University of Florida FLREC
> 
> ? Le tout est de tout dire, et je manque de mots
> Et je manque de temps, et je manque d'audace. ?
> ? Paul ?luard
> 
> This message is signed to guarantee its authenticity.
> For a true private correspondence, use my public key
> to encrypt your messages:
> http://mathieu.basille.net/pub.asc
> Learn more: http://mzl.la/1BsOGiZ
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 

Mathieu Basille
basille at ufl.edu | http://ase-research.org/basille
+1 954-577-6314 | University of Florida FLREC

  ? Le tout est de tout dire, et je manque de mots
  Et je manque de temps, et je manque d'audace. ?
  ? Paul ?luard

This message is signed to guarantee its authenticity.
For a true private correspondence, use my public key
to encrypt your messages:
  http://mathieu.basille.net/pub.asc
Learn more: http://mzl.la/1BsOGiZ

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151015/454890b8/attachment.bin>

From Dominik.Schneider at colorado.edu  Thu Oct 15 21:23:45 2015
From: Dominik.Schneider at colorado.edu (Dominik Schneider)
Date: Thu, 15 Oct 2015 13:23:45 -0600
Subject: [R-sig-Geo] how to read in R a big raster of about 6 Gb
In-Reply-To: <1444926680.2144.10.camel@arpa.veneto.it>
References: <1444921659.2123.55.camel@arpa.veneto.it>
	<CAHYDKLbw0x0D1gcrCM4J69btfO7rMQ0sQBzVBER9zHS-2wLbdA@mail.gmail.com>
	<1444926680.2144.10.camel@arpa.veneto.it>
Message-ID: <CAHYDKLb0-o8_vmc1fMGwc98dkmEjS3Xho_yPkSrrcRv1i=cB2A@mail.gmail.com>

>
> I need finally to associate the DEM values with the levels represented by
> one of these fields:
> do you think is a good idea eliminating the not necessary fields?

if you mean that you don't need information for all the polygons then yes,
you should subset the spatialpolygonsdF. If you're just concerned about
multiple attribute fields then I don't think it'll make a difference.

I'm not quite sure I'm completely grasping your hint about
>  values(DEM) <- 1:ncell(DEM)
> for speeding up the process

DEMcopy=DEM
values(DEMcopy) <- 1:ncell(DEMcopy)
list_cells=extract(DEMcopy,sppolydF)

list_cells will be a list with the cell numbers associated with each
polygon in a separate list element.  The initial extract() will not take
less time, but it should be useful in the future, e.g. you could do
poly1=list_cells[[1]]
elev1=DEM[poly1]


Another option I've had luck with is rasterizing polygons. Using the GDAL
commandline utility gdal_rasterize you can convert the shape file of
polygons to a classified raster.   In R, you can then use zonal() with some
aggregation function to get stats of DEM using your classified raster.





On Thu, Oct 15, 2015 at 10:31 AM, Massimo Bressan <mbressan at arpa.veneto.it>
wrote:

> hi, thanks for your prompt reply
>
> in fact by using raster() funciontion "reading" DEM is quite fast and
> also reading the polygons by readOGR() went quite smooth...
>
> the problem then come with the extract() function that is taking
> definitely too
> long...
>
> I'm not quite sure I'm completely grasping your hint about
>  values(DEM) <- 1:ncell(DEM)
> for speeding up the process
>
> please also consider that the SpatialPolygonDataFrame that I readOGR() has
> 23 fields;
> I need finally to associate the DEM values with the levels represented by
> one of these fields:
> do you think is a good idea eliminating the not necessary fields?
>
> max
>
>
>
> Il giorno Thu, 15/10/2015 alle 09.26 -0600, Dominik Schneider ha
> scritto:
> > You can use the raster package,  which will leave the values on disk
> > if they are too big for memory.
> > Use the function raster() to read the DEM, then use readOGR() to read
> > the polygon shape file. You can then use extract() to get statistics
> > on your DEM. I'm guessing it'll take a while to extract from disk, so
> > if you are planning to extract multiple times, you should consider
> > copying your DEM and setting the values equal to the cell numbers with
> > values(DEM) <- 1:ncell(DEM).  Extract this once, keep track of which
> > cell numbers are in which polygon and then use the cell numbers to
> > index the DEM when you need values by polygon.
> > Hope this helps,
> > Dominik
> >
> >
> >
> > On Thu, Oct 15, 2015 at 9:07 AM, Massimo Bressan
> > <mbressan at arpa.veneto.it> wrote:
> >         hi all
> >
> >
> >         I need to perform a zonal statistics by overlapping a DEM
> >         raster (ESRI
> >         grid binary) with some polygons (ESRI polygons);
> >
> >         the problem is that I first of all need to read the raster,
> >         which is
> >         quite big: about 6 Gbyte;
> >
> >         I know about the function readGDAL() by the fantastic package
> >         "rgdal"
> >         which is usually working very well with smaller size files but
> >         this time
> >         I got completely stuck (the pc freezes invariably)
> >
> >         do you have any advice on how to deal with such a problem (big
> >         file)?
> >
> >         thank you
> >
> >         regards
> >
> >         _______________________________________________
> >         R-sig-Geo mailing list
> >         R-sig-Geo at r-project.org
> >         https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> >
>
>
>
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Fri Oct 16 00:34:59 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 16 Oct 2015 11:34:59 +1300
Subject: [R-sig-Geo] density from spatstat less than zero
In-Reply-To: <561E926C.1090207@binghamton.edu>
References: <561E926C.1090207@binghamton.edu>
Message-ID: <56202A13.3070605@auckland.ac.nz>


See inline below.

On 15/10/15 06:35, Christopher W. Ryan wrote:
> Hello. I'm a longtime user of R and subscriber to R-help, but new to
> R-sig-geo.  I'm running R 3.1.3 and spatstat 1.41-1 on Windows XP.

If you upgrade to the most recent version of spatstat (in order to do 
which you will need to upgrade to R 3.2.2) you will find that 
density.ppp() now has an argument "positive" which defaults to FALSE.
Setting this argument equal to TRUE should solve your problem.

> I have a point pattern consisting of about 26,000 points, in an area as
> follows:
>
> Window: polygonal boundary
> single connected closed polygon with 133 vertices
> enclosing rectangle: [370698.1, 476022.1] x [4649777, 4732634] units
> Window area = 6525710000 square units
>
> It is clearly inhomogeneous, with most points clustered in the region's
> central city, and very few of them in the vast rural areas.
>
> The density() command from spatstat with all default values gives a
> density that is overly-smoothed for my purposes. Using density()
> command, with all default values except sigma=bw.diggle or sigma=bw.ppl,
> yields densities that are, to the eye, a better match for the point
> pattern, but some of the density values are less than zero, although
> this is not apparent when I plot() the density.

The negative values that you get are very small in magnitude; they are 
really just numerical noise (unless something *really* funny --- and I 
cannot imagine what --- is going on).

Look at

ddd <- density.(X,sigma=bw.diggle)
min(ddd)

to see just how tiny the negative values are.

> The same happens if I
> use the default sigma and set adjust to much of anything less than 1.
>
> Any ideas why, and how to avoid the negative values?

See the start of this message.

> My apologies for not including a minimal working example. Including the
> entire point pattern would be cumbersome. Whittling it down to 100 or so
> points still yields the same problem, but I think that changes the game
> and would not be a true reflection of my situation.

A whittled down example would have been perfectly "valid", but in this 
case an example was not actually needed.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r.turner at auckland.ac.nz  Fri Oct 16 01:02:43 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 16 Oct 2015 12:02:43 +1300
Subject: [R-sig-Geo] [FORGED] Re:  density from spatstat less than zero
In-Reply-To: <56202CE4.7010701@binghamton.edu>
References: <561E926C.1090207@binghamton.edu>
	<56202A13.3070605@auckland.ac.nz> <56202CE4.7010701@binghamton.edu>
Message-ID: <56203093.9030703@auckland.ac.nz>

On 16/10/15 11:47, Christopher W. Ryan wrote:
> Thank you Rolf. The sub-zero density values are indeed extremely tiny in
> absolute value. I will try to upgrade my R and spatstat (institutional
> computer . . . ) and try again.

Just realised:  You can (of course!) work around the problem, without 
upgrading, via:

ddd <- eval.im(pmax(ddd,0))

Note that you need --- for reasons that are a wee bit too complicated to 
go into --- to call eval.im() explicitly in the foregoing.  I.e. you 
*cannot* just do "ddd <- pmax(ddd,0)".

That being said, it would still be a good idea to upgrade --- if you can 
persuade the IT weevils at your institution to cooperate.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From lferreira75.1 at gmail.com  Fri Oct 16 04:29:16 2015
From: lferreira75.1 at gmail.com (Luis Ferreira)
Date: Fri, 16 Oct 2015 03:29:16 +0100
Subject: [R-sig-Geo] Annotating categories according with a
 SpatialPolygonsDataFrame factor
Message-ID: <1444962556.3219.5.camel@leopardo>

Hello all.
I'm starting to use R, so not experienced at all.
I want to create boxplots grouped by zones given by several polygons.
The values are given by a raster DEM (1 band raster), in this case.

I'm lost in what to do when labelling/annotating the zones/categories.

Using rasterize(x,raster,field) and designating the factor/field from
SpatialPolygonsDataFrame doesn't make any difference: the final
zones/groups labels are given by consecutive numbers according to
SpatialPolygonsDataFrame objects order.

##############################################
library(rgdal)
library(maptools)
library(sp)
library(raster)

polyg1 <- readOGR("/data",layer="polygon_shapefile")
raster1 <- brick("/data/dem.tif")

extent(raster1) <- extent(polyg1)

polyg1_rst <- rasterize(polyg1, raster1,
polyg1 at data[["some_character_field"]], fun='last', background=NA,
mask=FALSE, update=FALSE, updateValue='NA')

#create RasterStack
tmp <- stack(raster1, polyg1_rst)
names(tmp) <- c('value', 'cat')

boxplot(tmp$value, tmp$cat, notch = FALSE, outline = TRUE, horizontal =
TRUE)
#############################################



Using extract(x,y), there are no factors from the
SpatialPolygonsDataFrame created on the resulting data frame. The
boxplot categories will be given also by consecutive numbers.

#############################################
library(rgdal)
library(maptools)
library(sp)
library(raster)

polyg1 <- readOGR("/data",layer="polygon_shapefile")
raster1 <- brick("/data/dem.tif")

##create data.frame
tmp <- extract(raster1, polyg1, method='simple', fun=NULL, na.rm=TRUE,
weights=FALSE, normalizeWeights=FALSE, cellnumbers=FALSE, small=FALSE,
df=TRUE, factors=TRUE, sp=FALSE)
names(tmp) <- c('cat', 'value')

boxplot(tmp$value ~ tmp$cat, notch = FALSE, outline = TRUE, horizontal =
TRUE)
############################


Do I need somehow to use is.factor() and as.factor() functions to create
value labels for categorical variables?? 

I'll appreciate any comments
Thank you.

Lu?s



	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Fri Oct 16 09:42:06 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 16 Oct 2015 18:42:06 +1100
Subject: [R-sig-Geo] how to read in R a big raster of about 6 Gb
In-Reply-To: <CAHYDKLb0-o8_vmc1fMGwc98dkmEjS3Xho_yPkSrrcRv1i=cB2A@mail.gmail.com>
References: <1444921659.2123.55.camel@arpa.veneto.it>
	<CAHYDKLbw0x0D1gcrCM4J69btfO7rMQ0sQBzVBER9zHS-2wLbdA@mail.gmail.com>
	<1444926680.2144.10.camel@arpa.veneto.it>
	<CAHYDKLb0-o8_vmc1fMGwc98dkmEjS3Xho_yPkSrrcRv1i=cB2A@mail.gmail.com>
Message-ID: <CAAcGz98QYSkQbTZttBSmCURNnjAy2h5q47=ZcujpXCPxMwtE=Q@mail.gmail.com>

Fwiw, the worst slow downs I see with extract are when the raster is
natively tiled.
(Been meaning to write the fix and/or report to Robert).

Can you check if your file is tiled? Use gdalinfo command line utility.

Extract, at least for points and I assume  also for polygons, scans the
file line by line but this needs to be done tile by tile to avoid
repetitive and wasteful I/O.

Cheers, Mike


On Friday, October 16, 2015, Dominik Schneider <
Dominik.Schneider at colorado.edu> wrote:
>>
>> I need finally to associate the DEM values with the levels represented by
>> one of these fields:
>> do you think is a good idea eliminating the not necessary fields?
>
> if you mean that you don't need information for all the polygons then yes,
> you should subset the spatialpolygonsdF. If you're just concerned about
> multiple attribute fields then I don't think it'll make a difference.
>
> I'm not quite sure I'm completely grasping your hint about
>>  values(DEM) <- 1:ncell(DEM)
>> for speeding up the process
>
> DEMcopy=DEM
> values(DEMcopy) <- 1:ncell(DEMcopy)
> list_cells=extract(DEMcopy,sppolydF)
>
> list_cells will be a list with the cell numbers associated with each
> polygon in a separate list element.  The initial extract() will not take
> less time, but it should be useful in the future, e.g. you could do
> poly1=list_cells[[1]]
> elev1=DEM[poly1]
>
>
> Another option I've had luck with is rasterizing polygons. Using the GDAL
> commandline utility gdal_rasterize you can convert the shape file of
> polygons to a classified raster.   In R, you can then use zonal() with
some
> aggregation function to get stats of DEM using your classified raster.
>
>
>
>
>
> On Thu, Oct 15, 2015 at 10:31 AM, Massimo Bressan <mbressan at arpa.veneto.it
>
> wrote:
>
>> hi, thanks for your prompt reply
>>
>> in fact by using raster() funciontion "reading" DEM is quite fast and
>> also reading the polygons by readOGR() went quite smooth...
>>
>> the problem then come with the extract() function that is taking
>> definitely too
>> long...
>>
>> I'm not quite sure I'm completely grasping your hint about
>>  values(DEM) <- 1:ncell(DEM)
>> for speeding up the process
>>
>> please also consider that the SpatialPolygonDataFrame that I readOGR()
has
>> 23 fields;
>> I need finally to associate the DEM values with the levels represented by
>> one of these fields:
>> do you think is a good idea eliminating the not necessary fields?
>>
>> max
>>
>>
>>
>> Il giorno Thu, 15/10/2015 alle 09.26 -0600, Dominik Schneider ha
>> scritto:
>> > You can use the raster package,  which will leave the values on disk
>> > if they are too big for memory.
>> > Use the function raster() to read the DEM, then use readOGR() to read
>> > the polygon shape file. You can then use extract() to get statistics
>> > on your DEM. I'm guessing it'll take a while to extract from disk, so
>> > if you are planning to extract multiple times, you should consider
>> > copying your DEM and setting the values equal to the cell numbers with
>> > values(DEM) <- 1:ncell(DEM).  Extract this once, keep track of which
>> > cell numbers are in which polygon and then use the cell numbers to
>> > index the DEM when you need values by polygon.
>> > Hope this helps,
>> > Dominik
>> >
>> >
>> >
>> > On Thu, Oct 15, 2015 at 9:07 AM, Massimo Bressan
>> > <mbressan at arpa.veneto.it> wrote:
>> >         hi all
>> >
>> >
>> >         I need to perform a zonal statistics by overlapping a DEM
>> >         raster (ESRI
>> >         grid binary) with some polygons (ESRI polygons);
>> >
>> >         the problem is that I first of all need to read the raster,
>> >         which is
>> >         quite big: about 6 Gbyte;
>> >
>> >         I know about the function readGDAL() by the fantastic package
>> >         "rgdal"
>> >         which is usually working very well with smaller size files but
>> >         this time
>> >         I got completely stuck (the pc freezes invariably)
>> >
>> >         do you have any advice on how to deal with such a problem (big
>> >         file)?
>> >
>> >         thank you
>> >
>> >         regards
>> >
>> >         _______________________________________________
>> >         R-sig-Geo mailing list
>> >         R-sig-Geo at r-project.org
>> >         https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >
>> >
>>
>>
>>
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com

	[[alternative HTML version deleted]]


From mbressan at arpa.veneto.it  Fri Oct 16 13:37:00 2015
From: mbressan at arpa.veneto.it (Massimo Bressan)
Date: Fri, 16 Oct 2015 13:37:00 +0200
Subject: [R-sig-Geo] how to read in R a big raster of about 6 Gb
In-Reply-To: <CAHYDKLb0-o8_vmc1fMGwc98dkmEjS3Xho_yPkSrrcRv1i=cB2A@mail.gmail.com>
References: <1444921659.2123.55.camel@arpa.veneto.it>
	<CAHYDKLbw0x0D1gcrCM4J69btfO7rMQ0sQBzVBER9zHS-2wLbdA@mail.gmail.com>
	<1444926680.2144.10.camel@arpa.veneto.it>
	<CAHYDKLb0-o8_vmc1fMGwc98dkmEjS3Xho_yPkSrrcRv1i=cB2A@mail.gmail.com>
Message-ID: <1444995420.2157.13.camel@arpa.veneto.it>

I do not understand exactly why but I had to pass through a preliminary
step by transforming the binary grid into an ascii grid format then read
it in R by means of readAsciiGrid(), package "maptools", and finally
convert it into a RasterLayer with the function raster() of the package
"rgdal"

after all that the extract() function was returning sensible results,
otherwise not at all (and I do not know why)

thank you all for your support

best regards

max

Il giorno Thu, 15/10/2015 alle 13.23 -0600, Dominik Schneider ha
scritto:
>         I need finally to associate the DEM values with the levels
>         represented by one of these fields:
>         do you think is a good idea eliminating the not necessary
>         fields?
> if you mean that you don't need information for all the polygons then
> yes, you should subset the spatialpolygonsdF. If you're just concerned
> about multiple attribute fields then I don't think it'll make a
> difference.
> 
> 
>         I'm not quite sure I'm completely grasping your hint about
>          values(DEM) <- 1:ncell(DEM)
>         for speeding up the process
> DEMcopy=DEM
> values(DEMcopy) <- 1:ncell(DEMcopy)
> list_cells=extract(DEMcopy,sppolydF)
> 
> 
> list_cells will be a list with the cell numbers associated with each
> polygon in a separate list element.  The initial extract() will not
> take less time, but it should be useful in the future, e.g. you could
> do
> poly1=list_cells[[1]]
> elev1=DEM[poly1]
> 
> 
> 
> 
> Another option I've had luck with is rasterizing polygons. Using the
> GDAL commandline utility gdal_rasterize you can convert the shape file
> of polygons to a classified raster.   In R, you can then use zonal()
> with some aggregation function to get stats of DEM using your
> classified raster.
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> On Thu, Oct 15, 2015 at 10:31 AM, Massimo Bressan
> <mbressan at arpa.veneto.it> wrote:
>         hi, thanks for your prompt reply
>         
>         in fact by using raster() funciontion "reading" DEM is quite
>         fast and
>         also reading the polygons by readOGR() went quite smooth...
>         
>         the problem then come with the extract() function that is
>         taking definitely too
>         long...
>         
>         I'm not quite sure I'm completely grasping your hint about
>          values(DEM) <- 1:ncell(DEM)
>         for speeding up the process
>         
>         please also consider that the SpatialPolygonDataFrame that I
>         readOGR() has 23 fields;
>         I need finally to associate the DEM values with the levels
>         represented by one of these fields:
>         do you think is a good idea eliminating the not necessary
>         fields?
>         
>         max
>         
>         
>         
>         Il giorno Thu, 15/10/2015 alle 09.26 -0600, Dominik Schneider
>         ha
>         scritto:
>         > You can use the raster package,  which will leave the values
>         on disk
>         > if they are too big for memory.
>         > Use the function raster() to read the DEM, then use
>         readOGR() to read
>         > the polygon shape file. You can then use extract() to get
>         statistics
>         > on your DEM. I'm guessing it'll take a while to extract from
>         disk, so
>         > if you are planning to extract multiple times, you should
>         consider
>         > copying your DEM and setting the values equal to the cell
>         numbers with
>         > values(DEM) <- 1:ncell(DEM).  Extract this once, keep track
>         of which
>         > cell numbers are in which polygon and then use the cell
>         numbers to
>         > index the DEM when you need values by polygon.
>         > Hope this helps,
>         > Dominik
>         >
>         >
>         >
>         > On Thu, Oct 15, 2015 at 9:07 AM, Massimo Bressan
>         > <mbressan at arpa.veneto.it> wrote:
>         >         hi all
>         >
>         >
>         >         I need to perform a zonal statistics by overlapping
>         a DEM
>         >         raster (ESRI
>         >         grid binary) with some polygons (ESRI polygons);
>         >
>         >         the problem is that I first of all need to read the
>         raster,
>         >         which is
>         >         quite big: about 6 Gbyte;
>         >
>         >         I know about the function readGDAL() by the
>         fantastic package
>         >         "rgdal"
>         >         which is usually working very well with smaller size
>         files but
>         >         this time
>         >         I got completely stuck (the pc freezes invariably)
>         >
>         >         do you have any advice on how to deal with such a
>         problem (big
>         >         file)?
>         >
>         >         thank you
>         >
>         >         regards
>         >
>         >         _______________________________________________
>         >         R-sig-Geo mailing list
>         >         R-sig-Geo at r-project.org
>         >         https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>         >
>         >
>         
>         
>         
>         
> 
>


From Dominik.Schneider at colorado.edu  Fri Oct 16 16:35:04 2015
From: Dominik.Schneider at colorado.edu (Dominik Schneider)
Date: Fri, 16 Oct 2015 08:35:04 -0600
Subject: [R-sig-Geo] how to read in R a big raster of about 6 Gb
In-Reply-To: <CAAcGz98QYSkQbTZttBSmCURNnjAy2h5q47=ZcujpXCPxMwtE=Q@mail.gmail.com>
References: <1444921659.2123.55.camel@arpa.veneto.it>
	<CAHYDKLbw0x0D1gcrCM4J69btfO7rMQ0sQBzVBER9zHS-2wLbdA@mail.gmail.com>
	<1444926680.2144.10.camel@arpa.veneto.it>
	<CAHYDKLb0-o8_vmc1fMGwc98dkmEjS3Xho_yPkSrrcRv1i=cB2A@mail.gmail.com>
	<CAAcGz98QYSkQbTZttBSmCURNnjAy2h5q47=ZcujpXCPxMwtE=Q@mail.gmail.com>
Message-ID: <CAHYDKLaQaLP76vzyBaiP-YBT0aFuGJRQycutmZ2Ofy8FD8qFTg@mail.gmail.com>

Michael, is the tiling issue also a problem if its tiled by layer? So for a
netcdf it is my understanding that extracting a layer is faster if the
tiles are nrow x ncol x 1 instead of something like nrow/2 x ncol/2 x 1
Domink
On Oct 16, 2015 01:42, "Michael Sumner" <mdsumner at gmail.com> wrote:

>
> Fwiw, the worst slow downs I see with extract are when the raster is
> natively tiled.
> (Been meaning to write the fix and/or report to Robert).
>
> Can you check if your file is tiled? Use gdalinfo command line utility.
>
> Extract, at least for points and I assume  also for polygons, scans the
> file line by line but this needs to be done tile by tile to avoid
> repetitive and wasteful I/O.
>
> Cheers, Mike
>
>
> On Friday, October 16, 2015, Dominik Schneider <
> Dominik.Schneider at colorado.edu> wrote:
> >>
> >> I need finally to associate the DEM values with the levels represented
> by
> >> one of these fields:
> >> do you think is a good idea eliminating the not necessary fields?
> >
> > if you mean that you don't need information for all the polygons then
> yes,
> > you should subset the spatialpolygonsdF. If you're just concerned about
> > multiple attribute fields then I don't think it'll make a difference.
> >
> > I'm not quite sure I'm completely grasping your hint about
> >>  values(DEM) <- 1:ncell(DEM)
> >> for speeding up the process
> >
> > DEMcopy=DEM
> > values(DEMcopy) <- 1:ncell(DEMcopy)
> > list_cells=extract(DEMcopy,sppolydF)
> >
> > list_cells will be a list with the cell numbers associated with each
> > polygon in a separate list element.  The initial extract() will not take
> > less time, but it should be useful in the future, e.g. you could do
> > poly1=list_cells[[1]]
> > elev1=DEM[poly1]
> >
> >
> > Another option I've had luck with is rasterizing polygons. Using the GDAL
> > commandline utility gdal_rasterize you can convert the shape file of
> > polygons to a classified raster.   In R, you can then use zonal() with
> some
> > aggregation function to get stats of DEM using your classified raster.
> >
> >
> >
> >
> >
> > On Thu, Oct 15, 2015 at 10:31 AM, Massimo Bressan <
> mbressan at arpa.veneto.it>
> > wrote:
> >
> >> hi, thanks for your prompt reply
> >>
> >> in fact by using raster() funciontion "reading" DEM is quite fast and
> >> also reading the polygons by readOGR() went quite smooth...
> >>
> >> the problem then come with the extract() function that is taking
> >> definitely too
> >> long...
> >>
> >> I'm not quite sure I'm completely grasping your hint about
> >>  values(DEM) <- 1:ncell(DEM)
> >> for speeding up the process
> >>
> >> please also consider that the SpatialPolygonDataFrame that I readOGR()
> has
> >> 23 fields;
> >> I need finally to associate the DEM values with the levels represented
> by
> >> one of these fields:
> >> do you think is a good idea eliminating the not necessary fields?
> >>
> >> max
> >>
> >>
> >>
> >> Il giorno Thu, 15/10/2015 alle 09.26 -0600, Dominik Schneider ha
> >> scritto:
> >> > You can use the raster package,  which will leave the values on disk
> >> > if they are too big for memory.
> >> > Use the function raster() to read the DEM, then use readOGR() to read
> >> > the polygon shape file. You can then use extract() to get statistics
> >> > on your DEM. I'm guessing it'll take a while to extract from disk, so
> >> > if you are planning to extract multiple times, you should consider
> >> > copying your DEM and setting the values equal to the cell numbers with
> >> > values(DEM) <- 1:ncell(DEM).  Extract this once, keep track of which
> >> > cell numbers are in which polygon and then use the cell numbers to
> >> > index the DEM when you need values by polygon.
> >> > Hope this helps,
> >> > Dominik
> >> >
> >> >
> >> >
> >> > On Thu, Oct 15, 2015 at 9:07 AM, Massimo Bressan
> >> > <mbressan at arpa.veneto.it> wrote:
> >> >         hi all
> >> >
> >> >
> >> >         I need to perform a zonal statistics by overlapping a DEM
> >> >         raster (ESRI
> >> >         grid binary) with some polygons (ESRI polygons);
> >> >
> >> >         the problem is that I first of all need to read the raster,
> >> >         which is
> >> >         quite big: about 6 Gbyte;
> >> >
> >> >         I know about the function readGDAL() by the fantastic package
> >> >         "rgdal"
> >> >         which is usually working very well with smaller size files but
> >> >         this time
> >> >         I got completely stuck (the pc freezes invariably)
> >> >
> >> >         do you have any advice on how to deal with such a problem (big
> >> >         file)?
> >> >
> >> >         thank you
> >> >
> >> >         regards
> >> >
> >> >         _______________________________________________
> >> >         R-sig-Geo mailing list
> >> >         R-sig-Geo at r-project.org
> >> >         https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >> >
> >> >
> >>
> >>
> >>
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> Hobart, Australia
> e-mail: mdsumner at gmail.com
>

	[[alternative HTML version deleted]]


From eduardodiez at gmx.com  Fri Oct 16 19:43:56 2015
From: eduardodiez at gmx.com (Eduardo Diez)
Date: Fri, 16 Oct 2015 14:43:56 -0300
Subject: [R-sig-Geo] Cleaning small spatial polygons
Message-ID: <CANK5cGys6Ay1+WYWQfiCzyqgRHT2vw0cjEHGJRhObVhj0xym_w@mail.gmail.com>

Dear list,
I'm willing to know if any knows a way of performing tha same thing i'm
doing through rgrass7 with GRASS when I execute the function v.clean with
"rmarea" as the tool argument. That is:

"The rmarea tool removes all areas <= thresh. The longest boundary with an
adjacent area is removed or all boundaries if there is no adjacent area.
Area categories are not combined when a small area is merged with a larger
area."

Basically i have raster of zones within a field. I convert it to
SpatialPolygonsDataFrame and in order to leave only the more
important/meaningful ones i remove the small/sliver with this tool. In
general it works fine but having to call an external software with a
specific version makes the script less portable and you have to be careful
with updates and such. Also you have to write rasters and shapefiles back
and forth as GRASS can't work with in-memory objects.

Does someone know a way of doing this in plain R?

Thanks

	[[alternative HTML version deleted]]


From thi_veloso at yahoo.com.br  Fri Oct 16 22:39:51 2015
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Fri, 16 Oct 2015 20:39:51 +0000 (UTC)
Subject: [R-sig-Geo] Convert rasters to data frame with time stamp
References: <359890652.1661473.1445027991362.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <359890652.1661473.1445027991362.JavaMail.yahoo@mail.yahoo.com>

Dear list,

Generally speaking, I love R. However, one of the things I like least in R is the need to interchange between the various data formats required by different packages.

I am trying to apply a bias-correction function on some gridded climate data. The qmap package has functions to perform bias correction on climate data, but the problem I am grasping with is that it requires data to be organized as data.frames:


library(qmap)
data(obsprecip)
data(modprecip)

#Fit a quantile mapping function to observed and modeled data
qm.fit <- fitQmap(obsprecip,modprecip,
              method="QUANT",qstep=0.01)

#Perform bias correction on modeled data 
qm <- doQmap(modprecip, qm.fit, type="tricub")


And that's all. But notice that both observed and modeled data in this example are data frames for different locations (Moss, Geiranger and Barkestad):

> head(obsprecip)
         MOSS GEIRANGER BARKESTAD
1-1-1961  0.1         0         0
2-1-1961  0.2         0         0
3-1-1961  0.9         0         0
4-1-1961 10.6         0         0
5-1-1961  1.5         0         0
6-1-1961  1.2         0         2

> head(modprecip)
           MOSS GEIRANGER BARKESTAD
2-1-1961  2.283    0.0000  3.177000
3-1-1961  2.443   10.8600  1.719000
4-1-1961  3.099   12.7300  6.636000
5-1-1961  0.000    9.7720  9.676000
6-1-1961  0.140    0.6448  7.110000
7-1-1961 13.470    3.3570  0.001107



Now, let's back to my problem. I have monthly precip data to which I want to apply the same function above, but my data is gridded:

library(raster)

#Create a rasterStack similar to my data - same dimensions and layer names
r <- raster(ncol=60, nrow=60)
s <- stack(lapply(1:408, function(x) setValues(r, runif(ncell(r)))))
names(s) <- paste0('X', seq(as.Date("1980/1/1"), by = "month", length.out = 408))
s


Therefore, I need to load data as rasters and iterate through all individual gridcells to create a data frame containing:


date1, cell1, cell2, cell3, ..., cell3600
date2, cell1, cell2, cell3, ..., cell3600
date3, cell1, cell2, cell3, ..., cell3600...
date408, cell1, cell2, cell3, ..., cell3600

then apply the fit function and finally convert the data back to a raster.


Any ideas on how to efficiently convert rasters to data frames containing their time stamp and then back to a raster again??

Any hint is much appreciated.
Greetings,
-- Thiago V. dos Santos

PhD student
Land and Atmospheric Science
University of Minnesota


From Dominik.Schneider at colorado.edu  Fri Oct 16 23:56:17 2015
From: Dominik.Schneider at colorado.edu (Dominik Schneider)
Date: Fri, 16 Oct 2015 15:56:17 -0600
Subject: [R-sig-Geo] Convert rasters to data frame with time stamp
In-Reply-To: <359890652.1661473.1445027991362.JavaMail.yahoo@mail.yahoo.com>
References: <359890652.1661473.1445027991362.JavaMail.yahoo@mail.yahoo.com>
	<359890652.1661473.1445027991362.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAHYDKLbYUNQwnrfyx_SQ3iTG93ymE+YQBRE--kmBk1KWovKDAA@mail.gmail.com>

I don't think I completely understand but can you use tidyr::gather to get
what you want? if you have multiple datasets you could join them all
together at the end.

library(raster)
library(tidyr)

#Create a rasterStack similar to my data - same dimensions and layer names
r <- raster(ncol=60, nrow=60)
s <- stack(lapply(1:408, function(x) setValues(r, runif(ncell(r)))))
names(s) <- paste0('X', seq(as.Date("1980/1/1"), by = "month", length.out =
408))
s
dF=as.data.frame(s)
dF2=gather(dF,date)



On Fri, Oct 16, 2015 at 2:39 PM, Thiago V. dos Santos <
thi_veloso at yahoo.com.br> wrote:

> Dear list,
>
> Generally speaking, I love R. However, one of the things I like least in R
> is the need to interchange between the various data formats required by
> different packages.
>
> I am trying to apply a bias-correction function on some gridded climate
> data. The qmap package has functions to perform bias correction on climate
> data, but the problem I am grasping with is that it requires data to be
> organized as data.frames:
>
>
> library(qmap)
> data(obsprecip)
> data(modprecip)
>
> #Fit a quantile mapping function to observed and modeled data
> qm.fit <- fitQmap(obsprecip,modprecip,
>               method="QUANT",qstep=0.01)
>
> #Perform bias correction on modeled data
> qm <- doQmap(modprecip, qm.fit, type="tricub")
>
>
> And that's all. But notice that both observed and modeled data in this
> example are data frames for different locations (Moss, Geiranger and
> Barkestad):
>
> > head(obsprecip)
>          MOSS GEIRANGER BARKESTAD
> 1-1-1961  0.1         0         0
> 2-1-1961  0.2         0         0
> 3-1-1961  0.9         0         0
> 4-1-1961 10.6         0         0
> 5-1-1961  1.5         0         0
> 6-1-1961  1.2         0         2
>
> > head(modprecip)
>            MOSS GEIRANGER BARKESTAD
> 2-1-1961  2.283    0.0000  3.177000
> 3-1-1961  2.443   10.8600  1.719000
> 4-1-1961  3.099   12.7300  6.636000
> 5-1-1961  0.000    9.7720  9.676000
> 6-1-1961  0.140    0.6448  7.110000
> 7-1-1961 13.470    3.3570  0.001107
>
>
>
> Now, let's back to my problem. I have monthly precip data to which I want
> to apply the same function above, but my data is gridded:
>
> library(raster)
>
> #Create a rasterStack similar to my data - same dimensions and layer names
> r <- raster(ncol=60, nrow=60)
> s <- stack(lapply(1:408, function(x) setValues(r, runif(ncell(r)))))
> names(s) <- paste0('X', seq(as.Date("1980/1/1"), by = "month", length.out
> = 408))
> s
>
>
> Therefore, I need to load data as rasters and iterate through all
> individual gridcells to create a data frame containing:
>
>
> date1, cell1, cell2, cell3, ..., cell3600
> date2, cell1, cell2, cell3, ..., cell3600
> date3, cell1, cell2, cell3, ..., cell3600...
> date408, cell1, cell2, cell3, ..., cell3600
>
> then apply the fit function and finally convert the data back to a raster.
>
>
> Any ideas on how to efficiently convert rasters to data frames containing
> their time stamp and then back to a raster again??
>
> Any hint is much appreciated.
> Greetings,
> -- Thiago V. dos Santos
>
> PhD student
> Land and Atmospheric Science
> University of Minnesota
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From vijaylulla at gmail.com  Sat Oct 17 00:01:25 2015
From: vijaylulla at gmail.com (Vijay Lulla)
Date: Fri, 16 Oct 2015 18:01:25 -0400
Subject: [R-sig-Geo] Convert rasters to data frame with time stamp
In-Reply-To: <359890652.1661473.1445027991362.JavaMail.yahoo@mail.yahoo.com>
References: <359890652.1661473.1445027991362.JavaMail.yahoo@mail.yahoo.com>
	<359890652.1661473.1445027991362.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAKkiGbt0663TZgN75zh0YAg6YGQ8Lq+JQwpCKvvCZ3_pxEuN_A@mail.gmail.com>

>From the help page of `getValues`: "The values returned for a
RasterStack or RasterBrick are always a matrix, with the rows
representing cells, and the columns representing layers"  ....so all
you have to do is transpose the matrix from getValues, cbind the date
column, do your analysis.  To go back to raster again just drop the
names/date column, convert to matrix, transpose, and do setValues.

So for your example (untested...will need checking):
R> s_t <- t(s)
R> df_s_t <- cbind(names(s),as.data.frame(s_t))
R> # do your analysis
R> # To do the reverse
R> m <- as.matrix(df_s_t[,-1])
R> mt <- t(m)
R> setValues(s,mt)

HTH,
Vijay.

On Fri, Oct 16, 2015 at 4:39 PM, Thiago V. dos Santos
<thi_veloso at yahoo.com.br> wrote:
> Dear list,
>
> Generally speaking, I love R. However, one of the things I like least in R is the need to interchange between the various data formats required by different packages.
>
> I am trying to apply a bias-correction function on some gridded climate data. The qmap package has functions to perform bias correction on climate data, but the problem I am grasping with is that it requires data to be organized as data.frames:
>
>
> library(qmap)
> data(obsprecip)
> data(modprecip)
>
> #Fit a quantile mapping function to observed and modeled data
> qm.fit <- fitQmap(obsprecip,modprecip,
>               method="QUANT",qstep=0.01)
>
> #Perform bias correction on modeled data
> qm <- doQmap(modprecip, qm.fit, type="tricub")
>
>
> And that's all. But notice that both observed and modeled data in this example are data frames for different locations (Moss, Geiranger and Barkestad):
>
>> head(obsprecip)
>          MOSS GEIRANGER BARKESTAD
> 1-1-1961  0.1         0         0
> 2-1-1961  0.2         0         0
> 3-1-1961  0.9         0         0
> 4-1-1961 10.6         0         0
> 5-1-1961  1.5         0         0
> 6-1-1961  1.2         0         2
>
>> head(modprecip)
>            MOSS GEIRANGER BARKESTAD
> 2-1-1961  2.283    0.0000  3.177000
> 3-1-1961  2.443   10.8600  1.719000
> 4-1-1961  3.099   12.7300  6.636000
> 5-1-1961  0.000    9.7720  9.676000
> 6-1-1961  0.140    0.6448  7.110000
> 7-1-1961 13.470    3.3570  0.001107
>
>
>
> Now, let's back to my problem. I have monthly precip data to which I want to apply the same function above, but my data is gridded:
>
> library(raster)
>
> #Create a rasterStack similar to my data - same dimensions and layer names
> r <- raster(ncol=60, nrow=60)
> s <- stack(lapply(1:408, function(x) setValues(r, runif(ncell(r)))))
> names(s) <- paste0('X', seq(as.Date("1980/1/1"), by = "month", length.out = 408))
> s
>
>
> Therefore, I need to load data as rasters and iterate through all individual gridcells to create a data frame containing:
>
>
> date1, cell1, cell2, cell3, ..., cell3600
> date2, cell1, cell2, cell3, ..., cell3600
> date3, cell1, cell2, cell3, ..., cell3600...
> date408, cell1, cell2, cell3, ..., cell3600
>
> then apply the fit function and finally convert the data back to a raster.
>
>
> Any ideas on how to efficiently convert rasters to data frames containing their time stamp and then back to a raster again??
>
> Any hint is much appreciated.
> Greetings,
> -- Thiago V. dos Santos
>
> PhD student
> Land and Atmospheric Science
> University of Minnesota
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From wolz1 at illinois.edu  Sat Oct 17 00:52:32 2015
From: wolz1 at illinois.edu (Kevin Wolz)
Date: Fri, 16 Oct 2015 17:52:32 -0500
Subject: [R-sig-Geo] Calculate HIS/HSV values from RGB raster image
Message-ID: <CAL0dvJ-hWEvS=aC_2Fdm8s6q4Uam=f37sH+UR9366ALdQAiH+w@mail.gmail.com>

Does anyone know if there is any pre-existing functionality to easily
calculate hue, saturation, and intensity (HSI or HSV or HIS) from RGB
raster layers?

There is the "rgb2hsv" function in the grDevices packages, but that works
on vectors or matrices of rgb values. The functions for calculating HSI
from RGB are fairly straightforward, so it' would be that bad to directly
calculate new raster layers from the RGB layers, but I'm wondering if there
are any preexisting functions. I can't seem to find any.

Thanks!
Kevin

--
Kevin Wolz
PhD Candidate, DeLucia Lab
University of Illinois at Urbana-Champaign

	[[alternative HTML version deleted]]


From r.hijmans at gmail.com  Sat Oct 17 02:03:46 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Fri, 16 Oct 2015 17:03:46 -0700
Subject: [R-sig-Geo] Calculate HIS/HSV values from RGB raster image
In-Reply-To: <CAL0dvJ-hWEvS=aC_2Fdm8s6q4Uam=f37sH+UR9366ALdQAiH+w@mail.gmail.com>
References: <CAL0dvJ-hWEvS=aC_2Fdm8s6q4Uam=f37sH+UR9366ALdQAiH+w@mail.gmail.com>
Message-ID: <CANtt_hxU+=O5a89GrLyfVmPQZsSg-vqOAyho9RBxGCY4fEKiOA@mail.gmail.com>

Kevin,

I think you can do that like this:

library(raster)
b <- brick(system.file("external/rlogo.grd", package="raster"))

hsv <- overlay(b, fun=rgb2hsv)


Best, Robert

On Fri, Oct 16, 2015 at 3:52 PM, Kevin Wolz <wolz1 at illinois.edu> wrote:
> Does anyone know if there is any pre-existing functionality to easily
> calculate hue, saturation, and intensity (HSI or HSV or HIS) from RGB
> raster layers?
>
> There is the "rgb2hsv" function in the grDevices packages, but that works
> on vectors or matrices of rgb values. The functions for calculating HSI
> from RGB are fairly straightforward, so it' would be that bad to directly
> calculate new raster layers from the RGB layers, but I'm wondering if there
> are any preexisting functions. I can't seem to find any.
>
> Thanks!
> Kevin
>
> --
> Kevin Wolz
> PhD Candidate, DeLucia Lab
> University of Illinois at Urbana-Champaign
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Sat Oct 17 08:59:28 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Fri, 16 Oct 2015 23:59:28 -0700
Subject: [R-sig-Geo] Convert rasters to data frame with time stamp
In-Reply-To: <359890652.1661473.1445027991362.JavaMail.yahoo@mail.yahoo.com>
References: <359890652.1661473.1445027991362.JavaMail.yahoo@mail.yahoo.com>
	<359890652.1661473.1445027991362.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CANtt_hwoysnjEtih2C672ZZ68FqF-rGdD017jK7aG8uz81ZbBQ@mail.gmail.com>

Thiago,

> Therefore, I need to load data as rasters and iterate through all individual gridcells to create a data frame containing:
> date1, cell1, cell2, cell3, ..., cell3600
> date2, cell1, cell2, cell3, ..., cell3600
> date3, cell1, cell2, cell3, ..., cell3600...
> date408, cell1, cell2, cell3, ..., cell3600
> then apply the fit function and finally convert the data back to a raster.

That would be easy enough by using, e.g., as.data.frame, as Dominik
and Vijay suggested, but I do not think that you _need_ to do that.
The manual says that you can use a matrix (no need for data.frame).
The dates are row.names, but I do not think they are used by the
algorithm, so you do not need to supply them (it would be possible).
In most cases like this, you can wrap the functions you need into a
short new function that can be passed to a raster function (calc or
overlay). In this case perhaps something like:

f <- function(obs, mod, ...) {
  obs <- t(obs)
  qm.fit <- fitQmap(obs, t(mod), method="QUANT",qstep=0.01)
  t( doQmap(obs, qm.fit, type="tricub") )
}

try it

x <- f(head(s), head(s * 10))
x[, 1:5]

model <- s * 10
x <- overlay(s, model, fun=f)


Robert

On Fri, Oct 16, 2015 at 1:39 PM, Thiago V. dos Santos
<thi_veloso at yahoo.com.br> wrote:
> Dear list,
>
> Generally speaking, I love R. However, one of the things I like least in R is the need to interchange between the various data formats required by different packages.
>
> I am trying to apply a bias-correction function on some gridded climate data. The qmap package has functions to perform bias correction on climate data, but the problem I am grasping with is that it requires data to be organized as data.frames:
>
>
> library(qmap)
> data(obsprecip)
> data(modprecip)
>
> #Fit a quantile mapping function to observed and modeled data
> qm.fit <- fitQmap(obsprecip,modprecip,
>               method="QUANT",qstep=0.01)
>
> #Perform bias correction on modeled data
> qm <- doQmap(modprecip, qm.fit, type="tricub")
>
>
> And that's all. But notice that both observed and modeled data in this example are data frames for different locations (Moss, Geiranger and Barkestad):
>
>> head(obsprecip)
>          MOSS GEIRANGER BARKESTAD
> 1-1-1961  0.1         0         0
> 2-1-1961  0.2         0         0
> 3-1-1961  0.9         0         0
> 4-1-1961 10.6         0         0
> 5-1-1961  1.5         0         0
> 6-1-1961  1.2         0         2
>
>> head(modprecip)
>            MOSS GEIRANGER BARKESTAD
> 2-1-1961  2.283    0.0000  3.177000
> 3-1-1961  2.443   10.8600  1.719000
> 4-1-1961  3.099   12.7300  6.636000
> 5-1-1961  0.000    9.7720  9.676000
> 6-1-1961  0.140    0.6448  7.110000
> 7-1-1961 13.470    3.3570  0.001107
>
>
>
> Now, let's back to my problem. I have monthly precip data to which I want to apply the same function above, but my data is gridded:
>
> library(raster)
>
> #Create a rasterStack similar to my data - same dimensions and layer names
> r <- raster(ncol=60, nrow=60)
> s <- stack(lapply(1:408, function(x) setValues(r, runif(ncell(r)))))
> names(s) <- paste0('X', seq(as.Date("1980/1/1"), by = "month", length.out = 408))
> s
>
>
> Therefore, I need to load data as rasters and iterate through all individual gridcells to create a data frame containing:
>
>
> date1, cell1, cell2, cell3, ..., cell3600
> date2, cell1, cell2, cell3, ..., cell3600
> date3, cell1, cell2, cell3, ..., cell3600...
> date408, cell1, cell2, cell3, ..., cell3600
>
> then apply the fit function and finally convert the data back to a raster.
>
>
> Any ideas on how to efficiently convert rasters to data frames containing their time stamp and then back to a raster again??
>
> Any hint is much appreciated.
> Greetings,
> -- Thiago V. dos Santos
>
> PhD student
> Land and Atmospheric Science
> University of Minnesota
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From roelofcoster at gmail.com  Sat Oct 17 15:36:37 2015
From: roelofcoster at gmail.com (Roelof Coster)
Date: Sat, 17 Oct 2015 15:36:37 +0200
Subject: [R-sig-Geo] Predicted kriging variances don't match errors in
	cross-validation
Message-ID: <CAPTd6_utg5f=LMbgRsBL5v42qZ0Xb05r-9kfCCiL2DmvE_Zkwg@mail.gmail.com>

Dear list,

I'm working on a local (nmax=100) space-time kriging model. I did a
cross-validation in which I made my model predict the values at 2000
randomly selected data points, based on the rest of the observations.

The results are quite good (the average error is very small, the errors are
symmetrical and the spread is not too large). However, I don't see any
correlation between the squared errors and the predicted variances. The
Kendall's tau correlation coefficient between the two is even slightly
negative. I would expect larger squared errors, on average, for data points
in which the predicted variances are large.

Should I consider this as a sign that my model is incorrect?

Best regards,

Roelof Coster

	[[alternative HTML version deleted]]


From thi_veloso at yahoo.com.br  Sun Oct 18 00:22:31 2015
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Sat, 17 Oct 2015 22:22:31 +0000 (UTC)
Subject: [R-sig-Geo] Convert rasters to data frame with time stamp
In-Reply-To: <CANtt_hwoysnjEtih2C672ZZ68FqF-rGdD017jK7aG8uz81ZbBQ@mail.gmail.com>
References: <359890652.1661473.1445027991362.JavaMail.yahoo@mail.yahoo.com>
	<359890652.1661473.1445027991362.JavaMail.yahoo@mail.yahoo.com>
	<CANtt_hwoysnjEtih2C672ZZ68FqF-rGdD017jK7aG8uz81ZbBQ@mail.gmail.com>
Message-ID: <693648055.2024671.1445120551479.JavaMail.yahoo@mail.yahoo.com>

Thank you Dominik, Vijay and Robers for all the valuable inputs.

Robert, the function you devised is really convenient. However, it fails when the observed and modelled raster objects have different number of layers.

Please notice that the obs and model objects on the example from the qmap packages have different lengths:

library(qmap)
data(obsprecip)
data(modprecip)

dim(obsprecip);dim(modprecip) # notice the difference in the lengths

#Fit a quantile mapping function to observed and modeled data
qm.fit <- fitQmap(obsprecip,modprecip,
method="QUANT",qstep=0.01)

#Perform bias correction on modeled data 
qm <- doQmap(modprecip, qm.fit, type="tricub")



Now, an error is displayed when trying to apply your function on rasters with different "lengths" (number of layers):

library(raster)
library(qmap)

#Create a rasterStack similar to my data - same dimensions and layer names
r <- raster(ncol=60, nrow=60)
obs <- stack(lapply(1:408, function(x) setValues(r, runif(ncell(r)))))
mod <- stack(lapply(1:800, function(x) setValues(r, runif(ncell(r)))))

#Define bias-correction function
f <- function(obs, mod, ...) {
obs <- t(obs)
qm.fit <- fitQmap(obs, t(mod), method="QUANT",qstep=1/15)
t( doQmap(mod, qm.fit, type="tricub") )
}

# Test function on rasters with different # of layers
x <- f(head(obs), head(mod))


Error in t(doQmap(mod, qm.fit, type = "tricub")) : 
error in evaluating the argument 'x' in selecting a method for function 't': Error in doQmapQUANT.matrix(x, fobj, ...) : 
'ncol(x)' and 'nrow(fobj$par$modq)' should be eaqual


Any way to circumvent this?
 
Greetings,
 -- Thiago V. dos Santos

PhD student
Land and Atmospheric Science
University of Minnesota



On Saturday, October 17, 2015 1:59 AM, Robert J. Hijmans <r.hijmans at gmail.com> wrote:
Thiago,

> Therefore, I need to load data as rasters and iterate through all individual gridcells to create a data frame containing:
> date1, cell1, cell2, cell3, ..., cell3600
> date2, cell1, cell2, cell3, ..., cell3600
> date3, cell1, cell2, cell3, ..., cell3600...
> date408, cell1, cell2, cell3, ..., cell3600
> then apply the fit function and finally convert the data back to a raster.

That would be easy enough by using, e.g., as.data.frame, as Dominik
and Vijay suggested, but I do not think that you _need_ to do that.
The manual says that you can use a matrix (no need for data.frame).
The dates are row.names, but I do not think they are used by the
algorithm, so you do not need to supply them (it would be possible).
In most cases like this, you can wrap the functions you need into a
short new function that can be passed to a raster function (calc or
overlay). In this case perhaps something like:

f <- function(obs, mod, ...) {
  obs <- t(obs)
  qm.fit <- fitQmap(obs, t(mod), method="QUANT",qstep=0.01)
  t( doQmap(obs, qm.fit, type="tricub") )
}

try it

x <- f(head(s), head(s * 10))
x[, 1:5]

model <- s * 10
x <- overlay(s, model, fun=f)


Robert


On Fri, Oct 16, 2015 at 1:39 PM, Thiago V. dos Santos
<thi_veloso at yahoo.com.br> wrote:
> Dear list,
>
> Generally speaking, I love R. However, one of the things I like least in R is the need to interchange between the various data formats required by different packages.
>
> I am trying to apply a bias-correction function on some gridded climate data. The qmap package has functions to perform bias correction on climate data, but the problem I am grasping with is that it requires data to be organized as data.frames:
>
>
> library(qmap)
> data(obsprecip)
> data(modprecip)
>
> #Fit a quantile mapping function to observed and modeled data
> qm.fit <- fitQmap(obsprecip,modprecip,
>               method="QUANT",qstep=0.01)
>
> #Perform bias correction on modeled data
> qm <- doQmap(modprecip, qm.fit, type="tricub")
>
>
> And that's all. But notice that both observed and modeled data in this example are data frames for different locations (Moss, Geiranger and Barkestad):
>
>> head(obsprecip)
>          MOSS GEIRANGER BARKESTAD
> 1-1-1961  0.1         0         0
> 2-1-1961  0.2         0         0
> 3-1-1961  0.9         0         0
> 4-1-1961 10.6         0         0
> 5-1-1961  1.5         0         0
> 6-1-1961  1.2         0         2
>
>> head(modprecip)
>            MOSS GEIRANGER BARKESTAD
> 2-1-1961  2.283    0.0000  3.177000
> 3-1-1961  2.443   10.8600  1.719000
> 4-1-1961  3.099   12.7300  6.636000
> 5-1-1961  0.000    9.7720  9.676000
> 6-1-1961  0.140    0.6448  7.110000
> 7-1-1961 13.470    3.3570  0.001107
>
>
>
> Now, let's back to my problem. I have monthly precip data to which I want to apply the same function above, but my data is gridded:
>
> library(raster)
>
> #Create a rasterStack similar to my data - same dimensions and layer names
> r <- raster(ncol=60, nrow=60)
> s <- stack(lapply(1:408, function(x) setValues(r, runif(ncell(r)))))
> names(s) <- paste0('X', seq(as.Date("1980/1/1"), by = "month", length.out = 408))
> s
>
>
> Therefore, I need to load data as rasters and iterate through all individual gridcells to create a data frame containing:
>
>
> date1, cell1, cell2, cell3, ..., cell3600
> date2, cell1, cell2, cell3, ..., cell3600
> date3, cell1, cell2, cell3, ..., cell3600...
> date408, cell1, cell2, cell3, ..., cell3600
>
> then apply the fit function and finally convert the data back to a raster.
>
>
> Any ideas on how to efficiently convert rasters to data frames containing their time stamp and then back to a raster again??
>
> Any hint is much appreciated.
> Greetings,
> -- Thiago V. dos Santos
>
> PhD student
> Land and Atmospheric Science
> University of Minnesota
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From shuitiange at gmail.com  Sun Oct 18 05:10:25 2015
From: shuitiange at gmail.com (Chen Lee)
Date: Sun, 18 Oct 2015 11:10:25 +0800
Subject: [R-sig-Geo] How to use R scripts to estimate two-weight matrix SAR
	models
Message-ID: <CAHYW+7oxqF22Mfj3hv1iALan4vW34fAPprVbu-HGk0fbaXuj7w@mail.gmail.com>

Seek expert help: How to use R scripts to estimate two-weight matrix SAR
models? The two-weight matrix SAR model is specified as: Y=?1W1Y+?2W2Y+X?+?.

	[[alternative HTML version deleted]]


From thomas.vladeck at gmail.com  Sun Oct 18 16:38:49 2015
From: thomas.vladeck at gmail.com (Thomas Vladeck)
Date: Sun, 18 Oct 2015 10:38:49 -0400
Subject: [R-sig-Geo] Dispersion term u in errorsarlm in spdep
Message-ID: <CAO84NJwGB2W-MASooqBr-Fg98Non2F0buwQ-RECwBE6019eG=A@mail.gmail.com>

Hi,

I'm working on a marketing project, and could use a bit of technical help
and advice. I'm trying to model the spatial interdependence of a product's
usage (my dependent variable is the amount of usage in a given zip code
[1]) through a spatial error model, which is of the form:

y = Xb + u // u = ?Wu + e // e ~ N(0, ?^2)

In *Bayesian Statistics and Marketing* [2] the dispersion vector u is
interpreted as the "influence" of one unit over those it's related to via
the weighting matrix. Extracting this would be helpful from a marketer's
perspective as it would be advantageous to promote usage in an influential
area.

I have two questions:

First, is this a reasonable interpretation of the dispersion vector? It's
not clear to me that this is a reasonable interpretation.

Second, I'm using the errorsarlm function in spdep and I'd like to extract
u from the returned object. According to the documentation, it does not
seem that u is returned directly. Can I calculate it as follows?

u = ?Wu + e
u = (I - ?W)^(-1) * e

Which would be the following in code:

W <- mat2listw(
  distance.matrix,
  style = "W"
)

error.sp.model <- errorsarlm(
  formula = fm,
  data = model.data[, -1],
  listw = W
)

lambda    <- error.sp.model$lambda

# (I - ?W)^-1
inv.W      <- ginv((diag(1, nrow(distance.matrix)) - lambda *
distance.matrix))

# the result i'm looking for
u <- inv.W %*% as.vector(error.sp.model$residuals)


Thanks so much! Really appreciate the help.

Tom


[1] Actually, the average across all zip codes that start with the same
first three digits. (I needed to do this to make the problem
computationally tractable
[2] http://www.perossi.org/home/bsm-1

	[[alternative HTML version deleted]]


From r.hijmans at gmail.com  Sun Oct 18 19:28:01 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sun, 18 Oct 2015 10:28:01 -0700
Subject: [R-sig-Geo] Convert rasters to data frame with time stamp
In-Reply-To: <693648055.2024671.1445120551479.JavaMail.yahoo@mail.yahoo.com>
References: <359890652.1661473.1445027991362.JavaMail.yahoo@mail.yahoo.com>
	<CANtt_hwoysnjEtih2C672ZZ68FqF-rGdD017jK7aG8uz81ZbBQ@mail.gmail.com>
	<693648055.2024671.1445120551479.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CANtt_hx9ccsdCpt2wTG2Ot-KXcTBEvoj6Va09xcAosOGid2JCQ@mail.gmail.com>

Thiago,
This is really a qmap question but it would seem that you need to
provide two Raster objects with the same number of layers (matching
time steps). For example do mod <- mod[[1:408]]
Robert

On Sat, Oct 17, 2015 at 3:22 PM, Thiago V. dos Santos
<thi_veloso at yahoo.com.br> wrote:
> Thank you Dominik, Vijay and Robers for all the valuable inputs.
>
> Robert, the function you devised is really convenient. However, it fails when the observed and modelled raster objects have different number of layers.
>
> Please notice that the obs and model objects on the example from the qmap packages have different lengths:
>
> library(qmap)
> data(obsprecip)
> data(modprecip)
>
> dim(obsprecip);dim(modprecip) # notice the difference in the lengths
>
> #Fit a quantile mapping function to observed and modeled data
> qm.fit <- fitQmap(obsprecip,modprecip,
> method="QUANT",qstep=0.01)
>
> #Perform bias correction on modeled data
> qm <- doQmap(modprecip, qm.fit, type="tricub")
>
>
>
> Now, an error is displayed when trying to apply your function on rasters with different "lengths" (number of layers):
>
> library(raster)
> library(qmap)
>
> #Create a rasterStack similar to my data - same dimensions and layer names
> r <- raster(ncol=60, nrow=60)
> obs <- stack(lapply(1:408, function(x) setValues(r, runif(ncell(r)))))
> mod <- stack(lapply(1:800, function(x) setValues(r, runif(ncell(r)))))
>
> #Define bias-correction function
> f <- function(obs, mod, ...) {
> obs <- t(obs)
> qm.fit <- fitQmap(obs, t(mod), method="QUANT",qstep=1/15)
> t( doQmap(mod, qm.fit, type="tricub") )
> }
>
> # Test function on rasters with different # of layers
> x <- f(head(obs), head(mod))
>
>
> Error in t(doQmap(mod, qm.fit, type = "tricub")) :
> error in evaluating the argument 'x' in selecting a method for function 't': Error in doQmapQUANT.matrix(x, fobj, ...) :
> 'ncol(x)' and 'nrow(fobj$par$modq)' should be eaqual
>
>
> Any way to circumvent this?
>
> Greetings,
>  -- Thiago V. dos Santos
>
> PhD student
> Land and Atmospheric Science
> University of Minnesota
>
>
>
> On Saturday, October 17, 2015 1:59 AM, Robert J. Hijmans <r.hijmans at gmail.com> wrote:
> Thiago,
>
>> Therefore, I need to load data as rasters and iterate through all individual gridcells to create a data frame containing:
>> date1, cell1, cell2, cell3, ..., cell3600
>> date2, cell1, cell2, cell3, ..., cell3600
>> date3, cell1, cell2, cell3, ..., cell3600...
>> date408, cell1, cell2, cell3, ..., cell3600
>> then apply the fit function and finally convert the data back to a raster.
>
> That would be easy enough by using, e.g., as.data.frame, as Dominik
> and Vijay suggested, but I do not think that you _need_ to do that.
> The manual says that you can use a matrix (no need for data.frame).
> The dates are row.names, but I do not think they are used by the
> algorithm, so you do not need to supply them (it would be possible).
> In most cases like this, you can wrap the functions you need into a
> short new function that can be passed to a raster function (calc or
> overlay). In this case perhaps something like:
>
> f <- function(obs, mod, ...) {
>   obs <- t(obs)
>   qm.fit <- fitQmap(obs, t(mod), method="QUANT",qstep=0.01)
>   t( doQmap(obs, qm.fit, type="tricub") )
> }
>
> try it
>
> x <- f(head(s), head(s * 10))
> x[, 1:5]
>
> model <- s * 10
> x <- overlay(s, model, fun=f)
>
>
> Robert
>
>
> On Fri, Oct 16, 2015 at 1:39 PM, Thiago V. dos Santos
> <thi_veloso at yahoo.com.br> wrote:
>> Dear list,
>>
>> Generally speaking, I love R. However, one of the things I like least in R is the need to interchange between the various data formats required by different packages.
>>
>> I am trying to apply a bias-correction function on some gridded climate data. The qmap package has functions to perform bias correction on climate data, but the problem I am grasping with is that it requires data to be organized as data.frames:
>>
>>
>> library(qmap)
>> data(obsprecip)
>> data(modprecip)
>>
>> #Fit a quantile mapping function to observed and modeled data
>> qm.fit <- fitQmap(obsprecip,modprecip,
>>               method="QUANT",qstep=0.01)
>>
>> #Perform bias correction on modeled data
>> qm <- doQmap(modprecip, qm.fit, type="tricub")
>>
>>
>> And that's all. But notice that both observed and modeled data in this example are data frames for different locations (Moss, Geiranger and Barkestad):
>>
>>> head(obsprecip)
>>          MOSS GEIRANGER BARKESTAD
>> 1-1-1961  0.1         0         0
>> 2-1-1961  0.2         0         0
>> 3-1-1961  0.9         0         0
>> 4-1-1961 10.6         0         0
>> 5-1-1961  1.5         0         0
>> 6-1-1961  1.2         0         2
>>
>>> head(modprecip)
>>            MOSS GEIRANGER BARKESTAD
>> 2-1-1961  2.283    0.0000  3.177000
>> 3-1-1961  2.443   10.8600  1.719000
>> 4-1-1961  3.099   12.7300  6.636000
>> 5-1-1961  0.000    9.7720  9.676000
>> 6-1-1961  0.140    0.6448  7.110000
>> 7-1-1961 13.470    3.3570  0.001107
>>
>>
>>
>> Now, let's back to my problem. I have monthly precip data to which I want to apply the same function above, but my data is gridded:
>>
>> library(raster)
>>
>> #Create a rasterStack similar to my data - same dimensions and layer names
>> r <- raster(ncol=60, nrow=60)
>> s <- stack(lapply(1:408, function(x) setValues(r, runif(ncell(r)))))
>> names(s) <- paste0('X', seq(as.Date("1980/1/1"), by = "month", length.out = 408))
>> s
>>
>>
>> Therefore, I need to load data as rasters and iterate through all individual gridcells to create a data frame containing:
>>
>>
>> date1, cell1, cell2, cell3, ..., cell3600
>> date2, cell1, cell2, cell3, ..., cell3600
>> date3, cell1, cell2, cell3, ..., cell3600...
>> date408, cell1, cell2, cell3, ..., cell3600
>>
>> then apply the fit function and finally convert the data back to a raster.
>>
>>
>> Any ideas on how to efficiently convert rasters to data frames containing their time stamp and then back to a raster again??
>>
>> Any hint is much appreciated.
>> Greetings,
>> -- Thiago V. dos Santos
>>
>> PhD student
>> Land and Atmospheric Science
>> University of Minnesota
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From javajimburke at gmail.com  Sun Oct 18 22:33:32 2015
From: javajimburke at gmail.com (Jim Burke)
Date: Sun, 18 Oct 2015 15:33:32 -0500
Subject: [R-sig-Geo] Plot one character on a spatial map
Message-ID: <CALkjiFQPL+gaA9D3wOdbqBgJsknMhR7kioxp0z5OUCQMSR7KDw@mail.gmail.com>

I would like to plot a cex(17) darkgreen triangle at a specific lat/long
spatial map on an existing plot. Or a star at that location.

How might I approach this?

I saw an example (below) but so much like the internet not how to
implement. Besides this is probably for non spatial graphs
http://www.statmethods.net/advgraphs/parameters.html

Thanks in advance
Jim Burke

	[[alternative HTML version deleted]]


From jecogeo at gmail.com  Mon Oct 19 00:17:03 2015
From: jecogeo at gmail.com (Jefferson Ferreira-Ferreira)
Date: Sun, 18 Oct 2015 18:17:03 -0400
Subject: [R-sig-Geo] =?utf-8?q?package_or_namespace_load_failed_for_?=
	=?utf-8?b?4oCYZGlzbW/igJk=?=
Message-ID: <CAFFT+Y7tV64sOuRwThxSbXY7meGvfszhVMq0D1O728KtP4cphg@mail.gmail.com>

Hello everyone.

I installed dismo package, but I've been receiving the following loading
error:

*Loading required package: raster*
*Loading required package: sp*
*Error : .onLoad failed in loadNamespace() for 'dismo', details:*
*  call: NULL*
*  error: 'tmpDir' It is not an exported object 'namespace:raster'*
*Error: package or namespace load failed for ?dismo?*

When I type traceback() I get:

*2: stop(gettextf("package or namespace load failed for %s",
sQuote(package)), *
*       call. = FALSE, domain = NA)*
*1: library("dismo")*


Session info:

*> sessionInfo()*
*R version 3.0.3 (2014-03-06)*
*Platform: x86_64-w64-mingw32/x64 (64-bit)*

*locale:*
*[1] LC_COLLATE=Portuguese_Brazil.1252  LC_CTYPE=Portuguese_Brazil.1252   *
*[3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C                      *
*[5] LC_TIME=Portuguese_Brazil.1252    *

*attached base packages:*
*[1] stats     graphics  grDevices utils     datasets  methods   base     *

*other attached packages:*
*[1] raster_2.2-31    sp_1.0-14        Revobase_7.2.0   RevoMods_7.2.0
RevoScaleR_7.2.0*
*[6] lattice_0.20-29  rpart_4.1-5     *

*loaded via a namespace (and not attached):*
*[1] codetools_0.2-8 foreach_1.4.2   grid_3.0.3      iterators_1.0.7
tools_3.0.3 *


Any advice or tip do deal with it will be appreciated?
Thanks in advance.


-- 

*Jefferson Ferreira-Ferreira*

Ge?grafo ? GEOPROCESSAMENTO IDSM | Coordenadoria de TI


Jefferson.ferreira at mamiraua.org.br

*Instituto de Desenvolvimento Sustent?vel Mamirau?*

Minist?rio da Ci?ncia, Tecnologia e Inova??o

Telefone: +55 97 3343-9710

*Google Maps* - Mapas deste e-mail:

Exibir mapa ampliado
<https://maps.google.com.br/maps?q=-3.355557,-64.731151&ll=-3.355471,-64.731145&spn=0.004632,0.006968&num=1&t=h&z=18>


*Contatos particulares:*
*(55) 9615-0100*

	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Mon Oct 19 00:36:01 2015
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sun, 18 Oct 2015 23:36:01 +0100
Subject: [R-sig-Geo] Plot one character on a spatial map
In-Reply-To: <CALkjiFQPL+gaA9D3wOdbqBgJsknMhR7kioxp0z5OUCQMSR7KDw@mail.gmail.com>
References: <CALkjiFQPL+gaA9D3wOdbqBgJsknMhR7kioxp0z5OUCQMSR7KDw@mail.gmail.com>
Message-ID: <CANVKczN-o0Vz+mqu8TTRJGESvv29p8ri1vWi1-H-6ujHtdfvBg@mail.gmail.com>

On Sun, Oct 18, 2015 at 9:33 PM, Jim Burke <javajimburke at gmail.com> wrote:
> I would like to plot a cex(17) darkgreen triangle at a specific lat/long
> spatial map on an existing plot. Or a star at that location.
>
> How might I approach this?
>
> I saw an example (below) but so much like the internet not how to
> implement. Besides this is probably for non spatial graphs
> http://www.statmethods.net/advgraphs/parameters.html

 (you mean pch=17, not cex?)

 uk = raster::shapefile("uk.shp")
 plot(uk)
 points(0, 55, pch=17, col="darkgreen")

works for me. However it depends on what you call a "spatial graph".
You've not given us an example. If you've used `ggplot` instead of
base graphics like I have then `points` won't work...


From Roger.Bivand at nhh.no  Mon Oct 19 11:36:38 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 19 Oct 2015 11:36:38 +0200
Subject: [R-sig-Geo] How to use R scripts to estimate two-weight matrix
 SAR	models
In-Reply-To: <CAHYW+7oxqF22Mfj3hv1iALan4vW34fAPprVbu-HGk0fbaXuj7w@mail.gmail.com>
References: <CAHYW+7oxqF22Mfj3hv1iALan4vW34fAPprVbu-HGk0fbaXuj7w@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1510191131500.32247@reclus.nhh.no>

On Sun, 18 Oct 2015, Chen Lee wrote:

> Seek expert help: How to use R scripts to estimate two-weight matrix SAR
> models? The two-weight matrix SAR model is specified as: Y=?1W1Y+?2W2Y+X?+?.
>
> 	[[alternative HTML version deleted]]

Please do not post HTML.

There are no functions in R for fitting models of this kind. Further, it 
would be important to recall that the fitted coefficients on the X 
variables should not be interpreted directly - rather through their 
impacts, and methods using traces do not (yet) exist for computing such 
impacts. So even if you try to implement a function for model fitting, you 
would also need to implement a suitable impacts method. I am not aware of 
any available implementations in any language, although there may be 
something somewhere. So first the methods would need to be elaborated, the 
inplemented and tested.

Roger

>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From Roger.Bivand at nhh.no  Mon Oct 19 11:44:16 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 19 Oct 2015 11:44:16 +0200
Subject: [R-sig-Geo] Dispersion term u in errorsarlm in spdep
In-Reply-To: <CAO84NJwGB2W-MASooqBr-Fg98Non2F0buwQ-RECwBE6019eG=A@mail.gmail.com>
References: <CAO84NJwGB2W-MASooqBr-Fg98Non2F0buwQ-RECwBE6019eG=A@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1510191137190.32247@reclus.nhh.no>

On Sun, 18 Oct 2015, Thomas Vladeck wrote:

> Hi,
>
> I'm working on a marketing project, and could use a bit of technical help
> and advice. I'm trying to model the spatial interdependence of a product's
> usage (my dependent variable is the amount of usage in a given zip code
> [1]) through a spatial error model, which is of the form:
>
> y = Xb + u // u = ?Wu + e // e ~ N(0, ?^2)
>
> In *Bayesian Statistics and Marketing* [2] the dispersion vector u is
> interpreted as the "influence" of one unit over those it's related to via
> the weighting matrix. Extracting this would be helpful from a marketer's
> perspective as it would be advantageous to promote usage in an influential
> area.
>
> I have two questions:
>
> First, is this a reasonable interpretation of the dispersion vector? It's
> not clear to me that this is a reasonable interpretation.

This would be a spatially structured random effect, as distinct from an 
unstructured random effect in this context. See LeSage & Pace (2009) for 
more details.

>
> Second, I'm using the errorsarlm function in spdep and I'd like to extract
> u from the returned object. According to the documentation, it does not
> seem that u is returned directly. Can I calculate it as follows?
>
> u = ?Wu + e
> u = (I - ?W)^(-1) * e
>

The (legacy) predict method for sarlm objects reports a spatial signal, as 
distinct from the spatial trend (X \beta). Work is ongoing to fold recent 
work, including the GSoC 2015 project, on prediction into spdep.

Roger

PS. Your comment about data size shows that you have not examined the 
method= argument to errorsarlm() - method="Matrix" will work for large 
sparse symmetric spatial neighbour graphs. However, your "distance.matrix" 
object may not be sparse - just full of lots of very small values which 
could without loss be set to zero.

> Which would be the following in code:
>
> W <- mat2listw(
>  distance.matrix,
>  style = "W"
> )
>
> error.sp.model <- errorsarlm(
>  formula = fm,
>  data = model.data[, -1],
>  listw = W
> )
>
> lambda    <- error.sp.model$lambda
>
> # (I - ?W)^-1
> inv.W      <- ginv((diag(1, nrow(distance.matrix)) - lambda *
> distance.matrix))
>
> # the result i'm looking for
> u <- inv.W %*% as.vector(error.sp.model$residuals)
>
>
> Thanks so much! Really appreciate the help.
>
> Tom
>
>
> [1] Actually, the average across all zip codes that start with the same
> first three digits. (I needed to do this to make the problem
> computationally tractable
> [2] http://www.perossi.org/home/bsm-1
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From Roger.Bivand at nhh.no  Mon Oct 19 13:28:24 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 19 Oct 2015 13:28:24 +0200
Subject: [R-sig-Geo] Cleaning small spatial polygons
In-Reply-To: <CANK5cGys6Ay1+WYWQfiCzyqgRHT2vw0cjEHGJRhObVhj0xym_w@mail.gmail.com>
References: <CANK5cGys6Ay1+WYWQfiCzyqgRHT2vw0cjEHGJRhObVhj0xym_w@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1510191324520.32247@reclus.nhh.no>

On Fri, 16 Oct 2015, Eduardo Diez wrote:

> Dear list,
> I'm willing to know if any knows a way of performing tha same thing i'm
> doing through rgrass7 with GRASS when I execute the function v.clean with
> "rmarea" as the tool argument. That is:
>
> "The rmarea tool removes all areas <= thresh. The longest boundary with an
> adjacent area is removed or all boundaries if there is no adjacent area.
> Area categories are not combined when a small area is merged with a larger
> area."
>
> Basically i have raster of zones within a field. I convert it to
> SpatialPolygonsDataFrame and in order to leave only the more
> important/meaningful ones i remove the small/sliver with this tool. In
> general it works fine but having to call an external software with a
> specific version makes the script less portable and you have to be careful
> with updates and such. Also you have to write rasters and shapefiles back
> and forth as GRASS can't work with in-memory objects.

Could you please provide an example of a built-in or contributed data set 
(URL, not attachment) with the slivers you mention, so that we know that 
we are addressing your problem? I don't think that:

https://cran.r-project.org/web/packages/cleangeo/index.html

does this, as it seems to try to repair broken geometries.

Also note that you need to specify that the area threshold is in a square 
planar metric - dropping slivers in unprojected geometries may be more 
complicated.

Roger

>
> Does someone know a way of doing this in plain R?
>
> Thanks
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From eduardodiez at gmx.com  Mon Oct 19 20:03:07 2015
From: eduardodiez at gmx.com (Eduardo Diez)
Date: Mon, 19 Oct 2015 15:03:07 -0300
Subject: [R-sig-Geo] Cleaning small spatial polygons
In-Reply-To: <alpine.LFD.2.20.1510191324520.32247@reclus.nhh.no>
References: <CANK5cGys6Ay1+WYWQfiCzyqgRHT2vw0cjEHGJRhObVhj0xym_w@mail.gmail.com>
	<alpine.LFD.2.20.1510191324520.32247@reclus.nhh.no>
Message-ID: <CANK5cGz+ZuEMJJTRBfPDGx-26N0v5cbu-L8wEVRd_7n4S16QvQ@mail.gmail.com>

Ok. So here's a link to a zip file that contains two shapefiles:
 - pol_to_be_cleaned: the layer from which i'd like to remove small polygons
 - pol_cleaned: the layer cleaned with the function v.clean rmarea

http://1drv.ms/1GmRWS7

The threshold i used for cleaning was 3000 (meaning 3000 squared meters).

Although i do project it before sending it to GRASS, according to the
official help page it should be able to handle it:
"Threshold must always be in square meters, also for latitude-longitude
locations or locations with units other than meters"

Thanks

2015-10-19 8:28 GMT-03:00 Roger Bivand <Roger.Bivand at nhh.no>:

> On Fri, 16 Oct 2015, Eduardo Diez wrote:
>
> Dear list,
>> I'm willing to know if any knows a way of performing tha same thing i'm
>> doing through rgrass7 with GRASS when I execute the function v.clean with
>> "rmarea" as the tool argument. That is:
>>
>> "The rmarea tool removes all areas <= thresh. The longest boundary with an
>> adjacent area is removed or all boundaries if there is no adjacent area.
>> Area categories are not combined when a small area is merged with a larger
>> area."
>>
>> Basically i have raster of zones within a field. I convert it to
>> SpatialPolygonsDataFrame and in order to leave only the more
>> important/meaningful ones i remove the small/sliver with this tool. In
>> general it works fine but having to call an external software with a
>> specific version makes the script less portable and you have to be careful
>> with updates and such. Also you have to write rasters and shapefiles back
>> and forth as GRASS can't work with in-memory objects.
>>
>
> Could you please provide an example of a built-in or contributed data set
> (URL, not attachment) with the slivers you mention, so that we know that we
> are addressing your problem? I don't think that:
>
> https://cran.r-project.org/web/packages/cleangeo/index.html
>
> does this, as it seems to try to repair broken geometries.
>
> Also note that you need to specify that the area threshold is in a square
> planar metric - dropping slivers in unprojected geometries may be more
> complicated.
>
> Roger
>
>
>> Does someone know a way of doing this in plain R?
>>
>> Thanks
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
>

	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Mon Oct 19 20:58:21 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 19 Oct 2015 20:58:21 +0200
Subject: [R-sig-Geo] gstat now uses Lapack
Message-ID: <56253D4D.8080704@uni-muenster.de>

gstat 1.1-0, now on CRAN, no longer comes with its own functions for
matrix factorization and solving systems of equations [1], but now
directly uses Lapack (dpotrf and dtrsm) through R's own lapack interface
and R_ext/Lapack.h header files.

For global kriging at one location from 10,000 observations, as in

library(sp)
library(gstat)
set.seed(1331)
n = 10000
pts = SpatialPoints(cbind(x = runif(n), y = runif(n)))
pts$z = runif(n)
k <- krige(z~1, pts, pts[1,], vgm(1, "Exp", 1))

I see a speed increase from 120 (gstat 1.0-26) to 46 seconds; using
openblas on a 4 core laptop brings this down to 15 seconds - I expect
sth similar with MKL/RevoR.

For local kriging on large data sets with smaller neighborhoods and many
locations, I wouldn't expect large improvements; for global kriging of
large data sets to many prediction locations, krige0 may be faster when
you use openblas or MKL - as long as things fit in memory.

I'd be happy to hear experiences (positive and negative), or otherwise
reactions or questions.

[1] it formerly used meschach,
http://homepage.math.uiowa.edu/~dstewart/meschach/
-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151019/dba5ec90/attachment.bin>

From thomas.vladeck at gmail.com  Mon Oct 19 22:53:08 2015
From: thomas.vladeck at gmail.com (Thomas Vladeck)
Date: Mon, 19 Oct 2015 16:53:08 -0400
Subject: [R-sig-Geo] Dispersion term u in errorsarlm in spdep
In-Reply-To: <alpine.LFD.2.20.1510191137190.32247@reclus.nhh.no>
References: <CAO84NJwGB2W-MASooqBr-Fg98Non2F0buwQ-RECwBE6019eG=A@mail.gmail.com>
	<alpine.LFD.2.20.1510191137190.32247@reclus.nhh.no>
Message-ID: <CAO84NJwLhd5wQXV2Ga-Vpm+_Sb0zcNhQYSB=cF+2N_RGrHgLqA@mail.gmail.com>

Roger,

Thanks so much for your thoughtful reply. (And apologies for my lack of
experience in the field!)

On this:

This would be a spatially structured random effect, as distinct from an
> unstructured random effect in this context. See LeSage & Pace (2009) for
> more details.


Would the Besag-York-Molli? model be a more appropriate option? I have been
through the documentation on CARBayes [1], The LeSage & Pace book you
recommended, and as much other material as I could ingest & understand, and
this seems appropriate - but I'm not sure!

Here:

PS. Your comment about data size shows that you have not examined the
> method= argument to errorsarlm() - method="Matrix" will work for large
> sparse symmetric spatial neighbour graphs. However, your "distance.matrix"
> object may not be sparse - just full of lots of very small values which
> could without loss be set to zero.


It was the latter option that I hadn't realized was possible. Thanks so
much for the recommendation!

Tom

[1]
https://cran.r-project.org/web/packages/CARBayes/vignettes/CARBayesvignette.pdf




On Mon, Oct 19, 2015 at 5:44 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Sun, 18 Oct 2015, Thomas Vladeck wrote:
>
> Hi,
>>
>> I'm working on a marketing project, and could use a bit of technical help
>> and advice. I'm trying to model the spatial interdependence of a product's
>> usage (my dependent variable is the amount of usage in a given zip code
>> [1]) through a spatial error model, which is of the form:
>>
>> y = Xb + u // u = ?Wu + e // e ~ N(0, ?^2)
>>
>> In *Bayesian Statistics and Marketing* [2] the dispersion vector u is
>> interpreted as the "influence" of one unit over those it's related to via
>> the weighting matrix. Extracting this would be helpful from a marketer's
>> perspective as it would be advantageous to promote usage in an influential
>> area.
>>
>> I have two questions:
>>
>> First, is this a reasonable interpretation of the dispersion vector? It's
>> not clear to me that this is a reasonable interpretation.
>>
>
> This would be a spatially structured random effect, as distinct from an
> unstructured random effect in this context. See LeSage & Pace (2009) for
> more details.
>
>
>> Second, I'm using the errorsarlm function in spdep and I'd like to extract
>> u from the returned object. According to the documentation, it does not
>> seem that u is returned directly. Can I calculate it as follows?
>>
>> u = ?Wu + e
>> u = (I - ?W)^(-1) * e
>>
>>
> The (legacy) predict method for sarlm objects reports a spatial signal, as
> distinct from the spatial trend (X \beta). Work is ongoing to fold recent
> work, including the GSoC 2015 project, on prediction into spdep.
>
> Roger
>
> PS. Your comment about data size shows that you have not examined the
> method= argument to errorsarlm() - method="Matrix" will work for large
> sparse symmetric spatial neighbour graphs. However, your "distance.matrix"
> object may not be sparse - just full of lots of very small values which
> could without loss be set to zero.
>
> Which would be the following in code:
>>
>> W <- mat2listw(
>>  distance.matrix,
>>  style = "W"
>> )
>>
>> error.sp.model <- errorsarlm(
>>  formula = fm,
>>  data = model.data[, -1],
>>  listw = W
>> )
>>
>> lambda    <- error.sp.model$lambda
>>
>> # (I - ?W)^-1
>> inv.W      <- ginv((diag(1, nrow(distance.matrix)) - lambda *
>> distance.matrix))
>>
>> # the result i'm looking for
>> u <- inv.W %*% as.vector(error.sp.model$residuals)
>>
>>
>> Thanks so much! Really appreciate the help.
>>
>> Tom
>>
>>
>> [1] Actually, the average across all zip codes that start with the same
>> first three digits. (I needed to do this to make the problem
>> computationally tractable
>> [2] http://www.perossi.org/home/bsm-1
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>



-- 
Thomas P. Vladeck
+1 202 390 0838
tomvladeck.com

	[[alternative HTML version deleted]]


From timjp at unimelb.edu.au  Mon Oct 19 23:56:19 2015
From: timjp at unimelb.edu.au (Tim Peterson)
Date: Tue, 20 Oct 2015 08:56:19 +1100
Subject: [R-sig-Geo] gstat now uses Lapack
In-Reply-To: <56253D4D.8080704@uni-muenster.de>
References: <56253D4D.8080704@uni-muenster.de>
Message-ID: <56256703.20609@unimelb.edu.au>

On 10/20/2015 05:58 AM, Edzer Pebesma wrote:
> gstat 1.1-0, now on CRAN, no longer comes with its own functions for
> matrix factorization and solving systems of equations [1], but now
> directly uses Lapack (dpotrf and dtrsm) through R's own lapack interface
> and R_ext/Lapack.h header files.
>
> For global kriging at one location from 10,000 observations, as in
>
> library(sp)
> library(gstat)
> set.seed(1331)
> n = 10000
> pts = SpatialPoints(cbind(x = runif(n), y = runif(n)))
> pts$z = runif(n)
> k <- krige(z~1, pts, pts[1,], vgm(1, "Exp", 1))
>
> I see a speed increase from 120 (gstat 1.0-26) to 46 seconds; using
> openblas on a 4 core laptop brings this down to 15 seconds - I expect
> sth similar with MKL/RevoR.
>
> For local kriging on large data sets with smaller neighborhoods and many
> locations, I wouldn't expect large improvements; for global kriging of
> large data sets to many prediction locations, krige0 may be faster when
> you use openblas or MKL - as long as things fit in memory.
>
> I'd be happy to hear experiences (positive and negative), or otherwise
> reactions or questions.
>
> [1] it formerly used meschach,
> http://homepage.math.uiowa.edu/~dstewart/meschach/
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
Hi Edzer,

This is good to hear and I look forward to testing it. FYI, I have also 
been extending gls.c to use BLAS & LAPACK. However, when compiled using 
icc it canl optionally offload BLAS & LAPACK tasks (using openMP 
offload) to a co-processor, such as a Xeon Phi card. Once finished and 
tested I will circulate it.

Cheers

Tim
--------------------
Dr. Tim Peterson

The Department of Infrastructure Engineering
The University of Melbourne, 3010 Australia
T: +61 3 8344 9950 <tel:%2B61%203%208344%209950>, M: +61 0438 385 937 
<tel:%2B61%200438%20385%20937>

Dept. profile : 
http://www.ie.unimelb.edu.au/people/staff.php?person_ID=141135
Research Gate : https://www.researchgate.net/profile/Tim_Peterson7
Google Scholar: 
http://scholar.google.com.au/citations?user=kkYJLF4AAAAJ&hl=en&oi=ao

	[[alternative HTML version deleted]]


From frtog at vestas.com  Tue Oct 20 11:16:55 2015
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 20 Oct 2015 09:16:55 +0000
Subject: [R-sig-Geo] is this a clash between wrong version of rgdal and sp?
Message-ID: <HE1PR04MB12769B17EFF10568C13E10A9DB390@HE1PR04MB1276.eurprd04.prod.outlook.com>

Hi

I need to use R-2.14.0 for some INLA calculation. Even though we have more recent versions of R I cannot use those because INLA is not installed for those versions.

When trying to set a CRS I encounter the following error message:

CRS("+proj=utm +zone=34 +datum=WGS84") :   could not find function "checkCRSArgs" 

A similar error was seen in

https://stat.ethz.ch/pipermail/r-sig-geo/2013-February/017582.html 

A solution was found by Olga but it does not work for me.

So can someone please tell me which version of sp and rgdal can I use for R-2.14.0??

I have tried several combinations but nothing has helped me so far.

Any help is appreciated.

Yours sincerely / Med venlig hilsen

Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


From edzer.pebesma at uni-muenster.de  Tue Oct 20 11:23:10 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 20 Oct 2015 11:23:10 +0200
Subject: [R-sig-Geo] is this a clash between wrong version of rgdal and
 sp?
In-Reply-To: <HE1PR04MB12769B17EFF10568C13E10A9DB390@HE1PR04MB1276.eurprd04.prod.outlook.com>
References: <HE1PR04MB12769B17EFF10568C13E10A9DB390@HE1PR04MB1276.eurprd04.prod.outlook.com>
Message-ID: <562607FE.1020909@uni-muenster.de>



On 20/10/15 11:16, Frede Aakmann T?gersen wrote:
> Hi
> 
> I need to use R-2.14.0 for some INLA calculation. Even though we have more recent versions of R I cannot use those because INLA is not installed for those versions.
> 
> When trying to set a CRS I encounter the following error message:
> 
> CRS("+proj=utm +zone=34 +datum=WGS84") :   could not find function "checkCRSArgs" 
> 
> A similar error was seen in
> 
> https://stat.ethz.ch/pipermail/r-sig-geo/2013-February/017582.html 
> 
> A solution was found by Olga but it does not work for me.
> 
> So can someone please tell me which version of sp and rgdal can I use for R-2.14.0??

How about using those that were current at the time of release of
2.14.0, or of the release of the INLA version you are bound to?

> 
> I have tried several combinations but nothing has helped me so far.
> 
> Any help is appreciated.
> 
> Yours sincerely / Med venlig hilsen
> 
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
> 
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
> 
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender. 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151020/98ccc301/attachment.bin>

From frtog at vestas.com  Tue Oct 20 12:43:11 2015
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 20 Oct 2015 10:43:11 +0000
Subject: [R-sig-Geo] is this a clash between wrong version of rgdal and
 sp?
In-Reply-To: <562607FE.1020909@uni-muenster.de>
References: <HE1PR04MB12769B17EFF10568C13E10A9DB390@HE1PR04MB1276.eurprd04.prod.outlook.com>
	<562607FE.1020909@uni-muenster.de>
Message-ID: <HE1PR04MB127644A0E3764E265532A170DB390@HE1PR04MB1276.eurprd04.prod.outlook.com>

Thanks Edzer

So since rgdal depends on sp I first found and installed the most recent versio of sp available for R-2.14.0. Here is a snip from the DESCRIPTION file:

Packaged: 2013-03-29 10:01:36 UTC; rsb
Author: Edzer Pebesma [aut, cre], Roger Bivand [aut], Barry Rowlingson
        [ctb], Virgilio Gomez-Rubio [ctb]
Maintainer: Edzer Pebesma <edzer.pebesma at uni-muenster.de>
NeedsCompilation: yes
Repository: CRAN
Date/Publication: 2013-03-29 13:10:06
Package: sp
Version: 1.0-9
Date: 2013-03-30
Title: classes and methods for spatial data
Authors at R: c(person("Edzer", "Pebesma", role = c("aut", "cre"), email =
        "edzer.pebesma at uni-muenster.de"), person("Roger", "Bivand",
        role = "aut", email = "Roger.Bivand at nhh.no"), person("Barry",
        "Rowlingson", role = "ctb"), person("Virgilio", "Gomez-Rubio",
        role = "ctb"))
Depends: R (>= 2.14.0)
Suggests: lattice, RColorBrewer, rgdal (>= 0.8-7), rgeos (>= 0.1-8)
Imports: methods, graphics, utils, lattice, grid

The sp versio is 1.0-9 and it suggests rgdal (>= 0.8-7).

Installing these versions of sp and rgdal things work for me in R-2.14.0


Yours sincerely / Med venlig hilsen

Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 



-----Original Message-----
From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Edzer Pebesma
Sent: 20. oktober 2015 11:23
To: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] is this a clash between wrong version of rgdal and sp?



On 20/10/15 11:16, Frede Aakmann T?gersen wrote:
> Hi
> 
> I need to use R-2.14.0 for some INLA calculation. Even though we have more recent versions of R I cannot use those because INLA is not installed for those versions.
> 
> When trying to set a CRS I encounter the following error message:
> 
> CRS("+proj=utm +zone=34 +datum=WGS84") :   could not find function "checkCRSArgs" 
> 
> A similar error was seen in
> 
> https://stat.ethz.ch/pipermail/r-sig-geo/2013-February/017582.html 
> 
> A solution was found by Olga but it does not work for me.
> 
> So can someone please tell me which version of sp and rgdal can I use for R-2.14.0??

How about using those that were current at the time of release of
2.14.0, or of the release of the INLA version you are bound to?

> 
> I have tried several combinations but nothing has helped me so far.
> 
> Any help is appreciated.
> 
> Yours sincerely / Med venlig hilsen
> 
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
> 
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
> 
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender. 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info


From thierry.onkelinx at inbo.be  Tue Oct 20 13:50:14 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 20 Oct 2015 13:50:14 +0200
Subject: [R-sig-Geo] is this a clash between wrong version of rgdal and
	sp?
In-Reply-To: <HE1PR04MB127644A0E3764E265532A170DB390@HE1PR04MB1276.eurprd04.prod.outlook.com>
References: <HE1PR04MB12769B17EFF10568C13E10A9DB390@HE1PR04MB1276.eurprd04.prod.outlook.com>
	<562607FE.1020909@uni-muenster.de>
	<HE1PR04MB127644A0E3764E265532A170DB390@HE1PR04MB1276.eurprd04.prod.outlook.com>
Message-ID: <CAJuCY5wkeoLCrzOdx63jsUwj6zYb1=xCk-OtDt+W6D-O4EhNkg@mail.gmail.com>

Dear Frede,

Why not installing INLA on a recent R version? I'm running INLA on R 3.2.2.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-20 12:43 GMT+02:00 Frede Aakmann T?gersen <frtog at vestas.com>:

> Thanks Edzer
>
> So since rgdal depends on sp I first found and installed the most recent
> versio of sp available for R-2.14.0. Here is a snip from the DESCRIPTION
> file:
>
> Packaged: 2013-03-29 10:01:36 UTC; rsb
> Author: Edzer Pebesma [aut, cre], Roger Bivand [aut], Barry Rowlingson
>         [ctb], Virgilio Gomez-Rubio [ctb]
> Maintainer: Edzer Pebesma <edzer.pebesma at uni-muenster.de>
> NeedsCompilation: yes
> Repository: CRAN
> Date/Publication: 2013-03-29 13:10:06
> Package: sp
> Version: 1.0-9
> Date: 2013-03-30
> Title: classes and methods for spatial data
> Authors at R: c(person("Edzer", "Pebesma", role = c("aut", "cre"), email =
>         "edzer.pebesma at uni-muenster.de"), person("Roger", "Bivand",
>         role = "aut", email = "Roger.Bivand at nhh.no"), person("Barry",
>         "Rowlingson", role = "ctb"), person("Virgilio", "Gomez-Rubio",
>         role = "ctb"))
> Depends: R (>= 2.14.0)
> Suggests: lattice, RColorBrewer, rgdal (>= 0.8-7), rgeos (>= 0.1-8)
> Imports: methods, graphics, utils, lattice, grid
>
> The sp versio is 1.0-9 and it suggests rgdal (>= 0.8-7).
>
> Installing these versions of sp and rgdal things work for me in R-2.14.0
>
>
> Yours sincerely / Med venlig hilsen
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>
>
> -----Original Message-----
> From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of
> Edzer Pebesma
> Sent: 20. oktober 2015 11:23
> To: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] is this a clash between wrong version of rgdal
> and sp?
>
>
>
> On 20/10/15 11:16, Frede Aakmann T?gersen wrote:
> > Hi
> >
> > I need to use R-2.14.0 for some INLA calculation. Even though we have
> more recent versions of R I cannot use those because INLA is not installed
> for those versions.
> >
> > When trying to set a CRS I encounter the following error message:
> >
> > CRS("+proj=utm +zone=34 +datum=WGS84") :   could not find function
> "checkCRSArgs"
> >
> > A similar error was seen in
> >
> > https://stat.ethz.ch/pipermail/r-sig-geo/2013-February/017582.html
> >
> > A solution was found by Olga but it does not work for me.
> >
> > So can someone please tell me which version of sp and rgdal can I use
> for R-2.14.0??
>
> How about using those that were current at the time of release of
> 2.14.0, or of the release of the INLA version you are bound to?
>
> >
> > I have tried several combinations but nothing has helped me so far.
> >
> > Any help is appreciated.
> >
> > Yours sincerely / Med venlig hilsen
> >
> > Frede Aakmann T?gersen
> > Specialist, M.Sc., Ph.D.
> > Plant Performance & Modeling
> >
> > Technology & Service Solutions
> > T +45 9730 5135
> > M +45 2547 6050
> > frtog at vestas.com
> > http://www.vestas.com
> >
> > Company reg. name: Vestas Wind Systems A/S
> > This e-mail is subject to our e-mail disclaimer statement.
> > Please refer to www.vestas.com/legal/notice
> > If you have received this e-mail in error please contact the sender.
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi),  University of M?nster,
> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> Journal of Statistical Software:   http://www.jstatsoft.org/
> Computers & Geosciences:   http://elsevier.com/locate/cageo/
> Spatial Statistics Society http://www.spatialstatistics.info
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From frtog at vestas.com  Tue Oct 20 14:27:20 2015
From: frtog at vestas.com (=?utf-8?B?RnJlZGUgQWFrbWFubiBUw7hnZXJzZW4=?=)
Date: Tue, 20 Oct 2015 12:27:20 +0000
Subject: [R-sig-Geo] is this a clash between wrong version of rgdal and
 sp?
In-Reply-To: <CAJuCY5wkeoLCrzOdx63jsUwj6zYb1=xCk-OtDt+W6D-O4EhNkg@mail.gmail.com>
References: <HE1PR04MB12769B17EFF10568C13E10A9DB390@HE1PR04MB1276.eurprd04.prod.outlook.com>
	<562607FE.1020909@uni-muenster.de>
	<HE1PR04MB127644A0E3764E265532A170DB390@HE1PR04MB1276.eurprd04.prod.outlook.com>
	<CAJuCY5wkeoLCrzOdx63jsUwj6zYb1=xCk-OtDt+W6D-O4EhNkg@mail.gmail.com>
Message-ID: <HE1PR04MB12768CC12BCC7451E676AF1ADB390@HE1PR04MB1276.eurprd04.prod.outlook.com>

Hi Thierry

Yes, our sys-admin will do that when we get a new cluster later this year. I don?t want to burden our very busy admin with support on a cluster that is going to be shut down in a few months.

Yours sincerely / Med venlig hilsen

Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com<mailto:frtog at vestas.com>
http://www.vestas.com<http://www.vestas.com/>

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice<http://www.vestas.com/legal/notice>
If you have received this e-mail in error please contact the sender.


From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
Sent: 20. oktober 2015 13:50
To: Frede Aakmann T?gersen
Cc: Edzer Pebesma; r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] is this a clash between wrong version of rgdal and sp?

Dear Frede,

Why not installing INLA on a recent R version? I'm running INLA on R 3.2.2.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2015-10-20 12:43 GMT+02:00 Frede Aakmann T?gersen <frtog at vestas.com<mailto:frtog at vestas.com>>:
Thanks Edzer

So since rgdal depends on sp I first found and installed the most recent versio of sp available for R-2.14.0. Here is a snip from the DESCRIPTION file:

Packaged: 2013-03-29 10:01:36 UTC; rsb
Author: Edzer Pebesma [aut, cre], Roger Bivand [aut], Barry Rowlingson
        [ctb], Virgilio Gomez-Rubio [ctb]
Maintainer: Edzer Pebesma <edzer.pebesma at uni-muenster.de<mailto:edzer.pebesma at uni-muenster.de>>
NeedsCompilation: yes
Repository: CRAN
Date/Publication: 2013-03-29 13:10:06
Package: sp
Version: 1.0-9
Date: 2013-03-30
Title: classes and methods for spatial data
Authors at R: c(person("Edzer", "Pebesma", role = c("aut", "cre"), email =
        "edzer.pebesma at uni-muenster.de<mailto:edzer.pebesma at uni-muenster.de>"), person("Roger", "Bivand",
        role = "aut", email = "Roger.Bivand at nhh.no<mailto:Roger.Bivand at nhh.no>"), person("Barry",
        "Rowlingson", role = "ctb"), person("Virgilio", "Gomez-Rubio",
        role = "ctb"))
Depends: R (>= 2.14.0)
Suggests: lattice, RColorBrewer, rgdal (>= 0.8-7), rgeos (>= 0.1-8)
Imports: methods, graphics, utils, lattice, grid

The sp versio is 1.0-9 and it suggests rgdal (>= 0.8-7).

Installing these versions of sp and rgdal things work for me in R-2.14.0


Yours sincerely / Med venlig hilsen

Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com<mailto:frtog at vestas.com>
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice<http://www.vestas.com/legal/notice>
If you have received this e-mail in error please contact the sender.



-----Original Message-----
From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org<mailto:r-sig-geo-bounces at r-project.org>] On Behalf Of Edzer Pebesma
Sent: 20. oktober 2015 11:23
To: r-sig-geo at r-project.org<mailto:r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] is this a clash between wrong version of rgdal and sp?



On 20/10/15 11:16, Frede Aakmann T?gersen wrote:
> Hi
>
> I need to use R-2.14.0 for some INLA calculation. Even though we have more recent versions of R I cannot use those because INLA is not installed for those versions.
>
> When trying to set a CRS I encounter the following error message:
>
> CRS("+proj=utm +zone=34 +datum=WGS84") :   could not find function "checkCRSArgs"
>
> A similar error was seen in
>
> https://stat.ethz.ch/pipermail/r-sig-geo/2013-February/017582.html
>
> A solution was found by Olga but it does not work for me.
>
> So can someone please tell me which version of sp and rgdal can I use for R-2.14.0??

How about using those that were current at the time of release of
2.14.0, or of the release of the INLA version you are bound to?

>
> I have tried several combinations but nothing has helped me so far.
>
> Any help is appreciated.
>
> Yours sincerely / Med venlig hilsen
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135<tel:%2B45%209730%205135>
> M +45 2547 6050<tel:%2B45%202547%206050>
> frtog at vestas.com<mailto:frtog at vestas.com>
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice<http://www.vestas.com/legal/notice>
> If you have received this e-mail in error please contact the sender.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

--
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081<tel:%2B49%20251%2083%2033081>
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


	[[alternative HTML version deleted]]


From loredana.mirra at uniroma2.it  Wed Oct 21 12:46:18 2015
From: loredana.mirra at uniroma2.it (Loredana Mirra)
Date: Wed, 21 Oct 2015 12:46:18 +0200
Subject: [R-sig-Geo] R: Spatial Durbin Model with regimes in a cross section
	framework
In-Reply-To: <alpine.LFD.2.20.1510021049140.28317@reclus.nhh.no>
References: <002c01d0fcee$6641f900$32c5eb00$@uniroma2.it>
	<alpine.LFD.2.20.1510021049140.28317@reclus.nhh.no>
Message-ID: <008601d10bed$b8058820$28109860$@uniroma2.it>

Hi, and thank you again for your help. Following Anselin (2007) Spatial
regression analysis in R  I managed to test for the presence of spatial
regimes (also performing a Chow test) in R.

Since, I need to apply a Spatial Durbin model, I tried fitting it using the
following (just adding the option "mixed") to the sar command in the cases
of regimes (Centre_North and South in my case): 

durb<-lagsarlm(GR5101m~ 0+ (ONE+
LVAPC51):(C_Nord+NOC_Nord),data=highways,listw, type="mixed")
summary(durb)

I always get this error
error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : 
  0 (non-NA) cases

I checked if there were NA cases and tried with other variables or weight
matrices. I wonder if this is a good approach or what is wrong.

Thank you for your attention 
Loredana Mirra


    

-----Messaggio originale-----
Da: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Inviato: venerd? 2 ottobre 2015 10:59
A: Loredana Mirra
Cc: r-sig-geo at r-project.org
Oggetto: Re:[R-sig-Geo] Spatial Durbin Model with regimes in a cross section
framework

On Fri, 2 Oct 2015, Loredana Mirra wrote:

>
> Thank you very much for your kind help. Yes, I should check also if, 
> after having estimated separated coefficients,  the difference, if 
> any, is statistically significant (using a chow test). Implementing 
> such test is the major issue to me. Can you give me an hint about this?

Please see ch. 4 in Kleiber and Zeilis (2008) Applied Econometrics with R. 
You may use anova() on the no-regime model and the regime model, which is
equivalent to a Chow test (personal communication, Achim Zeileis, 2005). 
It will however suffer from misspecification such as outliers, discussed in
section 4.3 and the use of a Wald test with an HC covariance matrix.

> Thanks also for the suggestion about the interpretation of output in SDM.

A "Chow" test might go through a Likelihood Ratio test, but should arguably
be presented using the empirical distributions of the impacts for each X
variable for the no-regime model and for each regime.

Hope this helps,

Roger

> Best Regards
> Loredana
> -----Messaggio originale-----
> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Inviato: gioved? 1 ottobre 2015 20:45
> A: Loredana Mirra
> Cc: r-sig-geo at r-project.org
> Oggetto: Re: [R-sig-Geo] Spatial Durbin Model with regimes in a cross 
> section framework
>
> On Thu, 1 Oct 2015, Loredana Mirra wrote:
>
>> I am writing to ask you a suggestion about the availability of a R 
>> routine or piece of program for the purposes of my empirical analysis.
>> I should revise my paper using a Spatial Durbin model. This was 
>> recommended in order to mitigate a problem due to the possible 
>> presence of
> unobserved factors.
>>
>> Unfortunately data do not permit to perform a panel but a cross 
>> section analysis. I do not have troubles to perform a Spatial Durbin 
>> Model on the entire sample, but I need to study the presence of 
>> Spatial Regimes. The problem is that I cannot find a program, in a 
>> cross sections framework. Do you know if there is a program available 
>> in R
> to perform this analysis?
>
> How do you want to handle the "regimes"? Estimate separate 
> coefficients for each regime (regime defined as a factor)? If so, this 
> is a standard formula construction, and can be used with formula 
> objects in model fitting
> functions:
>
> lm(mpg ~ 0 + I(factor(am))/(disp + wt), data=mtcars)
>
> or similar - check in detailed discussions of formula objects.
>
> You need to be careful to report impacts, not coefficient values, from 
> the Spatial Durbin model.
>
> Hope this helps,
>
> Roger
>
>> Thank you very much in advance for your help.
>>
>> Best regards
>>
>> Loredana Mirra
>>
>>
>>
>>
>>
>> -------------------------
>>
>>
>>
>> Dott.ssa  Loredana Mirra
>>
>> Universit??? di Roma ???Tor Vergata???
>>
>> Dipartimento di Economia Diritto e Istituzioni
>>
>> Via Columbia, 2
>>
>> 00133 Roma
>>
>> Italia
>>
>> tel. +390672595725
>>
>> <mailto:pozzolo at unimol.it> loredana.mirra at uniroma2.it
>>
>>
>>
>>
>>
>> ---
>> Questa e-mail ??? stata controllata per individuare virus con Avast
> antivirus.
>> https://www.avast.com/antivirus
>>
>> 	[[alternative HTML version deleted]]
>>
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics, Helleveien 30,
> N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
>
> ---
> Questa e-mail ? stata controllata per individuare virus con Avast
antivirus.
> https://www.avast.com/antivirus
>
>

--
Roger Bivand
Department of Economics, Norwegian School of Economics, Helleveien 30,
N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


---
Questa e-mail ? stata controllata per individuare virus con Avast antivirus.
https://www.avast.com/antivirus


From Roger.Bivand at nhh.no  Wed Oct 21 13:26:19 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 21 Oct 2015 13:26:19 +0200
Subject: [R-sig-Geo] R: Spatial Durbin Model with regimes in a cross
 section framework
In-Reply-To: <008601d10bed$b8058820$28109860$@uniroma2.it>
References: <002c01d0fcee$6641f900$32c5eb00$@uniroma2.it>
	<alpine.LFD.2.20.1510021049140.28317@reclus.nhh.no>
	<008601d10bed$b8058820$28109860$@uniroma2.it>
Message-ID: <alpine.LFD.2.20.1510211315480.6127@reclus.nhh.no>

On Wed, 21 Oct 2015, Loredana Mirra wrote:

> Hi, and thank you again for your help. Following Anselin (2007) Spatial
> regression analysis in R  I managed to test for the presence of spatial
> regimes (also performing a Chow test) in R.
>
> Since, I need to apply a Spatial Durbin model, I tried fitting it using the
> following (just adding the option "mixed") to the sar command in the cases
> of regimes (Centre_North and South in my case):
>
> durb<-lagsarlm(GR5101m~ 0+ (ONE+
> LVAPC51):(C_Nord+NOC_Nord),data=highways,listw, type="mixed")
> summary(durb)
>
> I always get this error
> error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
>  0 (non-NA) cases

Please provide the output of traceback() after the error has occurred. I 
think that if the same model can be fitted with type="lag", but not with 
"mixed", then the lagged X variables are possibly to blame.

Maybe also try to use lmSLX() on the same formula, data and listw objects, 
to see whether you also see failures in the lagged X variables. The 
underlying create_WX() function does check for NAs, but may not do it 
correctly - possibly for this formula.

If this sounds hard, do:

save(highways, listw, file="chow_error.RData")

and make the "chow_error.RData" file available on a link (possibly 
off-list if the data are private).

Hope this helps,

Roger

>
> I checked if there were NA cases and tried with other variables or weight
> matrices. I wonder if this is a good approach or what is wrong.
>
> Thank you for your attention
> Loredana Mirra
>
>
>
>
> -----Messaggio originale-----
> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Inviato: venerd? 2 ottobre 2015 10:59
> A: Loredana Mirra
> Cc: r-sig-geo at r-project.org
> Oggetto: Re:[R-sig-Geo] Spatial Durbin Model with regimes in a cross section
> framework
>
> On Fri, 2 Oct 2015, Loredana Mirra wrote:
>
>>
>> Thank you very much for your kind help. Yes, I should check also if,
>> after having estimated separated coefficients,  the difference, if
>> any, is statistically significant (using a chow test). Implementing
>> such test is the major issue to me. Can you give me an hint about this?
>
> Please see ch. 4 in Kleiber and Zeilis (2008) Applied Econometrics with R.
> You may use anova() on the no-regime model and the regime model, which is
> equivalent to a Chow test (personal communication, Achim Zeileis, 2005).
> It will however suffer from misspecification such as outliers, discussed in
> section 4.3 and the use of a Wald test with an HC covariance matrix.
>
>> Thanks also for the suggestion about the interpretation of output in SDM.
>
> A "Chow" test might go through a Likelihood Ratio test, but should arguably
> be presented using the empirical distributions of the impacts for each X
> variable for the no-regime model and for each regime.
>
> Hope this helps,
>
> Roger
>
>> Best Regards
>> Loredana
>> -----Messaggio originale-----
>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>> Inviato: gioved? 1 ottobre 2015 20:45
>> A: Loredana Mirra
>> Cc: r-sig-geo at r-project.org
>> Oggetto: Re: [R-sig-Geo] Spatial Durbin Model with regimes in a cross
>> section framework
>>
>> On Thu, 1 Oct 2015, Loredana Mirra wrote:
>>
>>> I am writing to ask you a suggestion about the availability of a R
>>> routine or piece of program for the purposes of my empirical analysis.
>>> I should revise my paper using a Spatial Durbin model. This was
>>> recommended in order to mitigate a problem due to the possible
>>> presence of
>> unobserved factors.
>>>
>>> Unfortunately data do not permit to perform a panel but a cross
>>> section analysis. I do not have troubles to perform a Spatial Durbin
>>> Model on the entire sample, but I need to study the presence of
>>> Spatial Regimes. The problem is that I cannot find a program, in a
>>> cross sections framework. Do you know if there is a program available
>>> in R
>> to perform this analysis?
>>
>> How do you want to handle the "regimes"? Estimate separate
>> coefficients for each regime (regime defined as a factor)? If so, this
>> is a standard formula construction, and can be used with formula
>> objects in model fitting
>> functions:
>>
>> lm(mpg ~ 0 + I(factor(am))/(disp + wt), data=mtcars)
>>
>> or similar - check in detailed discussions of formula objects.
>>
>> You need to be careful to report impacts, not coefficient values, from
>> the Spatial Durbin model.
>>
>> Hope this helps,
>>
>> Roger
>>
>>> Thank you very much in advance for your help.
>>>
>>> Best regards
>>>
>>> Loredana Mirra
>>>
>>>
>>>
>>>
>>>
>>> -------------------------
>>>
>>>
>>>
>>> Dott.ssa  Loredana Mirra
>>>
>>> Universit??? di Roma ???Tor Vergata???
>>>
>>> Dipartimento di Economia Diritto e Istituzioni
>>>
>>> Via Columbia, 2
>>>
>>> 00133 Roma
>>>
>>> Italia
>>>
>>> tel. +390672595725
>>>
>>> <mailto:pozzolo at unimol.it> loredana.mirra at uniroma2.it
>>>
>>>
>>>
>>>
>>>
>>> ---
>>> Questa e-mail ??? stata controllata per individuare virus con Avast
>> antivirus.
>>> https://www.avast.com/antivirus
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics, Helleveien 30,
>> N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>> ---
>> Questa e-mail ? stata controllata per individuare virus con Avast
> antivirus.
>> https://www.avast.com/antivirus
>>
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics, Helleveien 30,
> N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
>
> ---
> Questa e-mail ? stata controllata per individuare virus con Avast antivirus.
> https://www.avast.com/antivirus
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From loredana.mirra at uniroma2.it  Wed Oct 21 14:05:17 2015
From: loredana.mirra at uniroma2.it (Loredana Mirra)
Date: Wed, 21 Oct 2015 14:05:17 +0200
Subject: [R-sig-Geo] R: R: Spatial Durbin Model with regimes in a cross
	section framework
In-Reply-To: <alpine.LFD.2.20.1510211315480.6127@reclus.nhh.no>
References: <002c01d0fcee$6641f900$32c5eb00$@uniroma2.it>
	<alpine.LFD.2.20.1510021049140.28317@reclus.nhh.no>
	<008601d10bed$b8058820$28109860$@uniroma2.it>
	<alpine.LFD.2.20.1510211315480.6127@reclus.nhh.no>
Message-ID: <009f01d10bf8$c02a7d20$407f7760$@uniroma2.it>

Here the traceback()
4: stop("0 (non-NA) cases")
3: lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...)
2: lm(y ~ x - 1)
1: lagsarlm(GR5101m ~ 0 + (ONE + LVAPC51):(C_Nord + NOC_Nord), data =
highwaysreg, 
       listw, type = "mixed")

No, problem. Data are not private. I tried to use the lmSLX and I got the
same error
This is the link to the file with errors  
https://onedrive.live.com/redir?resid=4484D82DD190F118!2202&authkey=!AEXvKmB
o2FVgrQI&ithint=file%2cRData

Thank you

Loredana



-----Messaggio originale-----
Da: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Inviato: mercoled? 21 ottobre 2015 13:26
A: Loredana Mirra
Cc: r-sig-geo at r-project.org
Oggetto: Re: R: [R-sig-Geo] Spatial Durbin Model with regimes in a cross
section framework

On Wed, 21 Oct 2015, Loredana Mirra wrote:

> Hi, and thank you again for your help. Following Anselin (2007) 
> Spatial regression analysis in R  I managed to test for the presence 
> of spatial regimes (also performing a Chow test) in R.
>
> Since, I need to apply a Spatial Durbin model, I tried fitting it 
> using the following (just adding the option "mixed") to the sar 
> command in the cases of regimes (Centre_North and South in my case):
>
> durb<-lagsarlm(GR5101m~ 0+ (ONE+
> LVAPC51):(C_Nord+NOC_Nord),data=highways,listw, type="mixed")
> summary(durb)
>
> I always get this error
> error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
>  0 (non-NA) cases

Please provide the output of traceback() after the error has occurred. I
think that if the same model can be fitted with type="lag", but not with
"mixed", then the lagged X variables are possibly to blame.

Maybe also try to use lmSLX() on the same formula, data and listw objects,
to see whether you also see failures in the lagged X variables. The
underlying create_WX() function does check for NAs, but may not do it
correctly - possibly for this formula.

If this sounds hard, do:

save(highways, listw, file="chow_error.RData")

and make the "chow_error.RData" file available on a link (possibly off-list
if the data are private).

Hope this helps,

Roger

>
> I checked if there were NA cases and tried with other variables or 
> weight matrices. I wonder if this is a good approach or what is wrong.
>
> Thank you for your attention
> Loredana Mirra
>
>
>
>
> -----Messaggio originale-----
> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Inviato: venerd? 2 ottobre 2015 10:59
> A: Loredana Mirra
> Cc: r-sig-geo at r-project.org
> Oggetto: Re:[R-sig-Geo] Spatial Durbin Model with regimes in a cross 
> section framework
>
> On Fri, 2 Oct 2015, Loredana Mirra wrote:
>
>>
>> Thank you very much for your kind help. Yes, I should check also if, 
>> after having estimated separated coefficients,  the difference, if 
>> any, is statistically significant (using a chow test). Implementing 
>> such test is the major issue to me. Can you give me an hint about this?
>
> Please see ch. 4 in Kleiber and Zeilis (2008) Applied Econometrics with R.
> You may use anova() on the no-regime model and the regime model, which 
> is equivalent to a Chow test (personal communication, Achim Zeileis,
2005).
> It will however suffer from misspecification such as outliers, 
> discussed in section 4.3 and the use of a Wald test with an HC covariance
matrix.
>
>> Thanks also for the suggestion about the interpretation of output in SDM.
>
> A "Chow" test might go through a Likelihood Ratio test, but should 
> arguably be presented using the empirical distributions of the impacts 
> for each X variable for the no-regime model and for each regime.
>
> Hope this helps,
>
> Roger
>
>> Best Regards
>> Loredana
>> -----Messaggio originale-----
>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>> Inviato: gioved? 1 ottobre 2015 20:45
>> A: Loredana Mirra
>> Cc: r-sig-geo at r-project.org
>> Oggetto: Re: [R-sig-Geo] Spatial Durbin Model with regimes in a cross 
>> section framework
>>
>> On Thu, 1 Oct 2015, Loredana Mirra wrote:
>>
>>> I am writing to ask you a suggestion about the availability of a R 
>>> routine or piece of program for the purposes of my empirical analysis.
>>> I should revise my paper using a Spatial Durbin model. This was 
>>> recommended in order to mitigate a problem due to the possible 
>>> presence of
>> unobserved factors.
>>>
>>> Unfortunately data do not permit to perform a panel but a cross 
>>> section analysis. I do not have troubles to perform a Spatial Durbin 
>>> Model on the entire sample, but I need to study the presence of 
>>> Spatial Regimes. The problem is that I cannot find a program, in a 
>>> cross sections framework. Do you know if there is a program 
>>> available in R
>> to perform this analysis?
>>
>> How do you want to handle the "regimes"? Estimate separate 
>> coefficients for each regime (regime defined as a factor)? If so, 
>> this is a standard formula construction, and can be used with formula 
>> objects in model fitting
>> functions:
>>
>> lm(mpg ~ 0 + I(factor(am))/(disp + wt), data=mtcars)
>>
>> or similar - check in detailed discussions of formula objects.
>>
>> You need to be careful to report impacts, not coefficient values, 
>> from the Spatial Durbin model.
>>
>> Hope this helps,
>>
>> Roger
>>
>>> Thank you very much in advance for your help.
>>>
>>> Best regards
>>>
>>> Loredana Mirra
>>>
>>>
>>>
>>>
>>>
>>> -------------------------
>>>
>>>
>>>
>>> Dott.ssa  Loredana Mirra
>>>
>>> Universit??? di Roma ???Tor Vergata???
>>>
>>> Dipartimento di Economia Diritto e Istituzioni
>>>
>>> Via Columbia, 2
>>>
>>> 00133 Roma
>>>
>>> Italia
>>>
>>> tel. +390672595725
>>>
>>> <mailto:pozzolo at unimol.it> loredana.mirra at uniroma2.it
>>>
>>>
>>>
>>>
>>>
>>> ---
>>> Questa e-mail ??? stata controllata per individuare virus con Avast
>> antivirus.
>>> https://www.avast.com/antivirus
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics, Helleveien 
>> 30,
>> N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>> ---
>> Questa e-mail ? stata controllata per individuare virus con Avast
> antivirus.
>> https://www.avast.com/antivirus
>>
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics, Helleveien 30,
> N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
>
> ---
> Questa e-mail ? stata controllata per individuare virus con Avast
antivirus.
> https://www.avast.com/antivirus
>
>

--
Roger Bivand
Department of Economics, Norwegian School of Economics, Helleveien 30,
N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


---
Questa e-mail ? stata controllata per individuare virus con Avast antivirus.
https://www.avast.com/antivirus


From Roger.Bivand at nhh.no  Wed Oct 21 14:19:25 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 21 Oct 2015 14:19:25 +0200
Subject: [R-sig-Geo] R: R: Spatial Durbin Model with regimes in a cross
 section framework
In-Reply-To: <009f01d10bf8$c02a7d20$407f7760$@uniroma2.it>
References: <002c01d0fcee$6641f900$32c5eb00$@uniroma2.it>
	<alpine.LFD.2.20.1510021049140.28317@reclus.nhh.no>
	<008601d10bed$b8058820$28109860$@uniroma2.it>
	<alpine.LFD.2.20.1510211315480.6127@reclus.nhh.no>
	<009f01d10bf8$c02a7d20$407f7760$@uniroma2.it>
Message-ID: <alpine.LFD.2.20.1510211413380.6127@reclus.nhh.no>

On Wed, 21 Oct 2015, Loredana Mirra wrote:

> Here the traceback()
> 4: stop("0 (non-NA) cases")
> 3: lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...)
> 2: lm(y ~ x - 1)
> 1: lagsarlm(GR5101m ~ 0 + (ONE + LVAPC51):(C_Nord + NOC_Nord), data =
> highwaysreg,
>       listw, type = "mixed")
>
> No, problem. Data are not private. I tried to use the lmSLX and I got the
> same error

OK, thanks. I cannot reproduce your error as such - I'm constructing:

ONE <- rep(1, nrow(highways))
NOC_Nord <- as.integer(!highways$C_Nord)

which may not be correct. I'm seeing:

Warning message:
In lagsarlm(GR5101m ~ 0 + I(factor(C_Nord))/(LVAPC51), data = highways,  :
   inversion of asymptotic covariance matrix failed for tol.solve = 1e-10
   reciprocal condition number = 6.6223e-12 - using numerical Hessian.

and an issue in an interaction term between the NOC_Nord term and the 
intercept:

Coefficients: (numerical Hessian approximate standard errors)
     (1 not defined because of singularities)
                        Estimate Std. Error  z value Pr(>|z|)
ONE:C_Nord            0.1385889  0.1310782   1.0573   0.2904
ONE:NOC_Nord          0.1493507  0.1322529   1.1293   0.2588
LVAPC51:C_Nord       -0.0170657  0.0010275 -16.6083   <2e-16
LVAPC51:NOC_Nord     -0.0192602  0.0018370 -10.4845   <2e-16
lag.ONE:C_Nord        0.0195317  0.1159969   0.1684   0.8663
lag.ONE:NOC_Nord             NA         NA       NA       NA
lag.LVAPC51:C_Nord   -0.0034108  0.0086611  -0.3938   0.6937
lag.LVAPC51:NOC_Nord -0.0032861  0.0223143  -0.1473   0.8829

Rho: 0.57171, LR test value: 1.8528, p-value: 0.17346
Approximate (numerical Hessian) standard error: 0.34917
     z-value: 1.6374, p-value: 0.10156
Wald statistic: 2.6809, p-value: 0.10156

Roger


> This is the link to the file with errors
> https://onedrive.live.com/redir?resid=4484D82DD190F118!2202&authkey=!AEXvKmB
> o2FVgrQI&ithint=file%2cRData
>
> Thank you
>
> Loredana
>
>
>
> -----Messaggio originale-----
> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Inviato: mercoled? 21 ottobre 2015 13:26
> A: Loredana Mirra
> Cc: r-sig-geo at r-project.org
> Oggetto: Re: R: [R-sig-Geo] Spatial Durbin Model with regimes in a cross
> section framework
>
> On Wed, 21 Oct 2015, Loredana Mirra wrote:
>
>> Hi, and thank you again for your help. Following Anselin (2007)
>> Spatial regression analysis in R  I managed to test for the presence
>> of spatial regimes (also performing a Chow test) in R.
>>
>> Since, I need to apply a Spatial Durbin model, I tried fitting it
>> using the following (just adding the option "mixed") to the sar
>> command in the cases of regimes (Centre_North and South in my case):
>>
>> durb<-lagsarlm(GR5101m~ 0+ (ONE+
>> LVAPC51):(C_Nord+NOC_Nord),data=highways,listw, type="mixed")
>> summary(durb)
>>
>> I always get this error
>> error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
>>  0 (non-NA) cases
>
> Please provide the output of traceback() after the error has occurred. I
> think that if the same model can be fitted with type="lag", but not with
> "mixed", then the lagged X variables are possibly to blame.
>
> Maybe also try to use lmSLX() on the same formula, data and listw objects,
> to see whether you also see failures in the lagged X variables. The
> underlying create_WX() function does check for NAs, but may not do it
> correctly - possibly for this formula.
>
> If this sounds hard, do:
>
> save(highways, listw, file="chow_error.RData")
>
> and make the "chow_error.RData" file available on a link (possibly off-list
> if the data are private).
>
> Hope this helps,
>
> Roger
>
>>
>> I checked if there were NA cases and tried with other variables or
>> weight matrices. I wonder if this is a good approach or what is wrong.
>>
>> Thank you for your attention
>> Loredana Mirra
>>
>>
>>
>>
>> -----Messaggio originale-----
>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>> Inviato: venerd? 2 ottobre 2015 10:59
>> A: Loredana Mirra
>> Cc: r-sig-geo at r-project.org
>> Oggetto: Re:[R-sig-Geo] Spatial Durbin Model with regimes in a cross
>> section framework
>>
>> On Fri, 2 Oct 2015, Loredana Mirra wrote:
>>
>>>
>>> Thank you very much for your kind help. Yes, I should check also if,
>>> after having estimated separated coefficients,  the difference, if
>>> any, is statistically significant (using a chow test). Implementing
>>> such test is the major issue to me. Can you give me an hint about this?
>>
>> Please see ch. 4 in Kleiber and Zeilis (2008) Applied Econometrics with R.
>> You may use anova() on the no-regime model and the regime model, which
>> is equivalent to a Chow test (personal communication, Achim Zeileis,
> 2005).
>> It will however suffer from misspecification such as outliers,
>> discussed in section 4.3 and the use of a Wald test with an HC covariance
> matrix.
>>
>>> Thanks also for the suggestion about the interpretation of output in SDM.
>>
>> A "Chow" test might go through a Likelihood Ratio test, but should
>> arguably be presented using the empirical distributions of the impacts
>> for each X variable for the no-regime model and for each regime.
>>
>> Hope this helps,
>>
>> Roger
>>
>>> Best Regards
>>> Loredana
>>> -----Messaggio originale-----
>>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>> Inviato: gioved? 1 ottobre 2015 20:45
>>> A: Loredana Mirra
>>> Cc: r-sig-geo at r-project.org
>>> Oggetto: Re: [R-sig-Geo] Spatial Durbin Model with regimes in a cross
>>> section framework
>>>
>>> On Thu, 1 Oct 2015, Loredana Mirra wrote:
>>>
>>>> I am writing to ask you a suggestion about the availability of a R
>>>> routine or piece of program for the purposes of my empirical analysis.
>>>> I should revise my paper using a Spatial Durbin model. This was
>>>> recommended in order to mitigate a problem due to the possible
>>>> presence of
>>> unobserved factors.
>>>>
>>>> Unfortunately data do not permit to perform a panel but a cross
>>>> section analysis. I do not have troubles to perform a Spatial Durbin
>>>> Model on the entire sample, but I need to study the presence of
>>>> Spatial Regimes. The problem is that I cannot find a program, in a
>>>> cross sections framework. Do you know if there is a program
>>>> available in R
>>> to perform this analysis?
>>>
>>> How do you want to handle the "regimes"? Estimate separate
>>> coefficients for each regime (regime defined as a factor)? If so,
>>> this is a standard formula construction, and can be used with formula
>>> objects in model fitting
>>> functions:
>>>
>>> lm(mpg ~ 0 + I(factor(am))/(disp + wt), data=mtcars)
>>>
>>> or similar - check in detailed discussions of formula objects.
>>>
>>> You need to be careful to report impacts, not coefficient values,
>>> from the Spatial Durbin model.
>>>
>>> Hope this helps,
>>>
>>> Roger
>>>
>>>> Thank you very much in advance for your help.
>>>>
>>>> Best regards
>>>>
>>>> Loredana Mirra
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> -------------------------
>>>>
>>>>
>>>>
>>>> Dott.ssa  Loredana Mirra
>>>>
>>>> Universit??? di Roma ???Tor Vergata???
>>>>
>>>> Dipartimento di Economia Diritto e Istituzioni
>>>>
>>>> Via Columbia, 2
>>>>
>>>> 00133 Roma
>>>>
>>>> Italia
>>>>
>>>> tel. +390672595725
>>>>
>>>> <mailto:pozzolo at unimol.it> loredana.mirra at uniroma2.it
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> ---
>>>> Questa e-mail ??? stata controllata per individuare virus con Avast
>>> antivirus.
>>>> https://www.avast.com/antivirus
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>>
>>>
>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics, Helleveien
>>> 30,
>>> N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>> ---
>>> Questa e-mail ? stata controllata per individuare virus con Avast
>> antivirus.
>>> https://www.avast.com/antivirus
>>>
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics, Helleveien 30,
>> N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>> ---
>> Questa e-mail ? stata controllata per individuare virus con Avast
> antivirus.
>> https://www.avast.com/antivirus
>>
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics, Helleveien 30,
> N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
>
> ---
> Questa e-mail ? stata controllata per individuare virus con Avast antivirus.
> https://www.avast.com/antivirus
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From loredana.mirra at uniroma2.it  Wed Oct 21 15:13:51 2015
From: loredana.mirra at uniroma2.it (Loredana Mirra)
Date: Wed, 21 Oct 2015 15:13:51 +0200
Subject: [R-sig-Geo] R: R: R: Spatial Durbin Model with regimes in a cross
	section framework
In-Reply-To: <alpine.LFD.2.20.1510211413380.6127@reclus.nhh.no>
References: <002c01d0fcee$6641f900$32c5eb00$@uniroma2.it>
	<alpine.LFD.2.20.1510021049140.28317@reclus.nhh.no>
	<008601d10bed$b8058820$28109860$@uniroma2.it>
	<alpine.LFD.2.20.1510211315480.6127@reclus.nhh.no>
	<009f01d10bf8$c02a7d20$407f7760$@uniroma2.it>
	<alpine.LFD.2.20.1510211413380.6127@reclus.nhh.no>
Message-ID: <00b501d10c02$54c80e80$fe582b80$@uniroma2.it>

Thanks Roger, 
At least you managed to have an output even if it contains some issues which
I could address changing variables. 
Instead sorry but I am stuck. How can I get that? 
Loredana


-----Messaggio originale-----
Da: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Inviato: mercoled? 21 ottobre 2015 14:19
A: Loredana Mirra
Cc: r-sig-geo at r-project.org
Oggetto: Re: R: R: [R-sig-Geo] Spatial Durbin Model with regimes in a cross
section framework

On Wed, 21 Oct 2015, Loredana Mirra wrote:

> Here the traceback()
> 4: stop("0 (non-NA) cases")
> 3: lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...)
> 2: lm(y ~ x - 1)
> 1: lagsarlm(GR5101m ~ 0 + (ONE + LVAPC51):(C_Nord + NOC_Nord), data = 
> highwaysreg,
>       listw, type = "mixed")
>
> No, problem. Data are not private. I tried to use the lmSLX and I got 
> the same error

OK, thanks. I cannot reproduce your error as such - I'm constructing:

ONE <- rep(1, nrow(highways))
NOC_Nord <- as.integer(!highways$C_Nord)

which may not be correct. I'm seeing:

Warning message:
In lagsarlm(GR5101m ~ 0 + I(factor(C_Nord))/(LVAPC51), data = highways,  :
   inversion of asymptotic covariance matrix failed for tol.solve = 1e-10
   reciprocal condition number = 6.6223e-12 - using numerical Hessian.

and an issue in an interaction term between the NOC_Nord term and the
intercept:

Coefficients: (numerical Hessian approximate standard errors)
     (1 not defined because of singularities)
                        Estimate Std. Error  z value Pr(>|z|)
ONE:C_Nord            0.1385889  0.1310782   1.0573   0.2904
ONE:NOC_Nord          0.1493507  0.1322529   1.1293   0.2588
LVAPC51:C_Nord       -0.0170657  0.0010275 -16.6083   <2e-16
LVAPC51:NOC_Nord     -0.0192602  0.0018370 -10.4845   <2e-16
lag.ONE:C_Nord        0.0195317  0.1159969   0.1684   0.8663
lag.ONE:NOC_Nord             NA         NA       NA       NA
lag.LVAPC51:C_Nord   -0.0034108  0.0086611  -0.3938   0.6937
lag.LVAPC51:NOC_Nord -0.0032861  0.0223143  -0.1473   0.8829

Rho: 0.57171, LR test value: 1.8528, p-value: 0.17346 Approximate (numerical
Hessian) standard error: 0.34917
     z-value: 1.6374, p-value: 0.10156
Wald statistic: 2.6809, p-value: 0.10156

Roger


> This is the link to the file with errors 
> https://onedrive.live.com/redir?resid=4484D82DD190F118!2202&authkey=!A
> EXvKmB
> o2FVgrQI&ithint=file%2cRData
>
> Thank you
>
> Loredana
>
>
>
> -----Messaggio originale-----
> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Inviato: mercoled? 21 ottobre 2015 13:26
> A: Loredana Mirra
> Cc: r-sig-geo at r-project.org
> Oggetto: Re: R: [R-sig-Geo] Spatial Durbin Model with regimes in a 
> cross section framework
>
> On Wed, 21 Oct 2015, Loredana Mirra wrote:
>
>> Hi, and thank you again for your help. Following Anselin (2007) 
>> Spatial regression analysis in R  I managed to test for the presence 
>> of spatial regimes (also performing a Chow test) in R.
>>
>> Since, I need to apply a Spatial Durbin model, I tried fitting it 
>> using the following (just adding the option "mixed") to the sar 
>> command in the cases of regimes (Centre_North and South in my case):
>>
>> durb<-lagsarlm(GR5101m~ 0+ (ONE+
>> LVAPC51):(C_Nord+NOC_Nord),data=highways,listw, type="mixed")
>> summary(durb)
>>
>> I always get this error
>> error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
>>  0 (non-NA) cases
>
> Please provide the output of traceback() after the error has occurred. 
> I think that if the same model can be fitted with type="lag", but not 
> with "mixed", then the lagged X variables are possibly to blame.
>
> Maybe also try to use lmSLX() on the same formula, data and listw 
> objects, to see whether you also see failures in the lagged X 
> variables. The underlying create_WX() function does check for NAs, but 
> may not do it correctly - possibly for this formula.
>
> If this sounds hard, do:
>
> save(highways, listw, file="chow_error.RData")
>
> and make the "chow_error.RData" file available on a link (possibly 
> off-list if the data are private).
>
> Hope this helps,
>
> Roger
>
>>
>> I checked if there were NA cases and tried with other variables or 
>> weight matrices. I wonder if this is a good approach or what is wrong.
>>
>> Thank you for your attention
>> Loredana Mirra
>>
>>
>>
>>
>> -----Messaggio originale-----
>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>> Inviato: venerd? 2 ottobre 2015 10:59
>> A: Loredana Mirra
>> Cc: r-sig-geo at r-project.org
>> Oggetto: Re:[R-sig-Geo] Spatial Durbin Model with regimes in a cross 
>> section framework
>>
>> On Fri, 2 Oct 2015, Loredana Mirra wrote:
>>
>>>
>>> Thank you very much for your kind help. Yes, I should check also if, 
>>> after having estimated separated coefficients,  the difference, if 
>>> any, is statistically significant (using a chow test). Implementing 
>>> such test is the major issue to me. Can you give me an hint about this?
>>
>> Please see ch. 4 in Kleiber and Zeilis (2008) Applied Econometrics with
R.
>> You may use anova() on the no-regime model and the regime model, 
>> which is equivalent to a Chow test (personal communication, Achim 
>> Zeileis,
> 2005).
>> It will however suffer from misspecification such as outliers, 
>> discussed in section 4.3 and the use of a Wald test with an HC 
>> covariance
> matrix.
>>
>>> Thanks also for the suggestion about the interpretation of output in
SDM.
>>
>> A "Chow" test might go through a Likelihood Ratio test, but should 
>> arguably be presented using the empirical distributions of the 
>> impacts for each X variable for the no-regime model and for each regime.
>>
>> Hope this helps,
>>
>> Roger
>>
>>> Best Regards
>>> Loredana
>>> -----Messaggio originale-----
>>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>> Inviato: gioved? 1 ottobre 2015 20:45
>>> A: Loredana Mirra
>>> Cc: r-sig-geo at r-project.org
>>> Oggetto: Re: [R-sig-Geo] Spatial Durbin Model with regimes in a 
>>> cross section framework
>>>
>>> On Thu, 1 Oct 2015, Loredana Mirra wrote:
>>>
>>>> I am writing to ask you a suggestion about the availability of a R 
>>>> routine or piece of program for the purposes of my empirical analysis.
>>>> I should revise my paper using a Spatial Durbin model. This was 
>>>> recommended in order to mitigate a problem due to the possible 
>>>> presence of
>>> unobserved factors.
>>>>
>>>> Unfortunately data do not permit to perform a panel but a cross 
>>>> section analysis. I do not have troubles to perform a Spatial 
>>>> Durbin Model on the entire sample, but I need to study the presence 
>>>> of Spatial Regimes. The problem is that I cannot find a program, in 
>>>> a cross sections framework. Do you know if there is a program 
>>>> available in R
>>> to perform this analysis?
>>>
>>> How do you want to handle the "regimes"? Estimate separate 
>>> coefficients for each regime (regime defined as a factor)? If so, 
>>> this is a standard formula construction, and can be used with 
>>> formula objects in model fitting
>>> functions:
>>>
>>> lm(mpg ~ 0 + I(factor(am))/(disp + wt), data=mtcars)
>>>
>>> or similar - check in detailed discussions of formula objects.
>>>
>>> You need to be careful to report impacts, not coefficient values, 
>>> from the Spatial Durbin model.
>>>
>>> Hope this helps,
>>>
>>> Roger
>>>
>>>> Thank you very much in advance for your help.
>>>>
>>>> Best regards
>>>>
>>>> Loredana Mirra
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> -------------------------
>>>>
>>>>
>>>>
>>>> Dott.ssa  Loredana Mirra
>>>>
>>>> Universit??? di Roma ???Tor Vergata???
>>>>
>>>> Dipartimento di Economia Diritto e Istituzioni
>>>>
>>>> Via Columbia, 2
>>>>
>>>> 00133 Roma
>>>>
>>>> Italia
>>>>
>>>> tel. +390672595725
>>>>
>>>> <mailto:pozzolo at unimol.it> loredana.mirra at uniroma2.it
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> ---
>>>> Questa e-mail ??? stata controllata per individuare virus con Avast
>>> antivirus.
>>>> https://www.avast.com/antivirus
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>>
>>>
>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics, Helleveien 
>>> 30,
>>> N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>> ---
>>> Questa e-mail ? stata controllata per individuare virus con Avast
>> antivirus.
>>> https://www.avast.com/antivirus
>>>
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics, Helleveien 
>> 30,
>> N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>> ---
>> Questa e-mail ? stata controllata per individuare virus con Avast
> antivirus.
>> https://www.avast.com/antivirus
>>
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics, Helleveien 30,
> N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
>
> ---
> Questa e-mail ? stata controllata per individuare virus con Avast
antivirus.
> https://www.avast.com/antivirus
>
>

--
Roger Bivand
Department of Economics, Norwegian School of Economics, Helleveien 30,
N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


---
Questa e-mail ? stata controllata per individuare virus con Avast antivirus.
https://www.avast.com/antivirus


From Roger.Bivand at nhh.no  Wed Oct 21 15:25:33 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 21 Oct 2015 15:25:33 +0200
Subject: [R-sig-Geo] R: R: R: Spatial Durbin Model with regimes in a
 cross section framework
In-Reply-To: <00b501d10c02$54c80e80$fe582b80$@uniroma2.it>
References: <002c01d0fcee$6641f900$32c5eb00$@uniroma2.it>
	<alpine.LFD.2.20.1510021049140.28317@reclus.nhh.no>
	<008601d10bed$b8058820$28109860$@uniroma2.it>
	<alpine.LFD.2.20.1510211315480.6127@reclus.nhh.no>
	<009f01d10bf8$c02a7d20$407f7760$@uniroma2.it>
	<alpine.LFD.2.20.1510211413380.6127@reclus.nhh.no>
	<00b501d10c02$54c80e80$fe582b80$@uniroma2.it>
Message-ID: <alpine.LFD.2.20.1510211514340.6127@reclus.nhh.no>

On Wed, 21 Oct 2015, Loredana Mirra wrote:

> Thanks Roger,
> At least you managed to have an output even if it contains some issues which
> I could address changing variables.
> Instead sorry but I am stuck. How can I get that?

library(spdep)
sessionInfo() # spdep >=0.5-88
load("chow_error.RData")
ONE <- rep(1, nrow(highways))
NOC_Nord <- as.integer(!highways$C_Nord)
durb<-lagsarlm(GR5101m~ 0+ (ONE+LVAPC51):(C_Nord+NOC_Nord),
  data=highways, listw, type="mixed")
summary(durb)

works for me (I'm using the development version of spdep, which seems to 
be the reason for the difference). There was an indexing error in 
create_WX() that is corrected in the development version but not in 0.5-88 
on CRAN. Which OS are you using - there are reasons for not releasing the 
development version yet?

Roger

> Loredana
>
>
> -----Messaggio originale-----
> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Inviato: mercoled? 21 ottobre 2015 14:19
> A: Loredana Mirra
> Cc: r-sig-geo at r-project.org
> Oggetto: Re: R: R: [R-sig-Geo] Spatial Durbin Model with regimes in a cross
> section framework
>
> On Wed, 21 Oct 2015, Loredana Mirra wrote:
>
>> Here the traceback()
>> 4: stop("0 (non-NA) cases")
>> 3: lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...)
>> 2: lm(y ~ x - 1)
>> 1: lagsarlm(GR5101m ~ 0 + (ONE + LVAPC51):(C_Nord + NOC_Nord), data =
>> highwaysreg,
>>       listw, type = "mixed")
>>
>> No, problem. Data are not private. I tried to use the lmSLX and I got
>> the same error
>
> OK, thanks. I cannot reproduce your error as such - I'm constructing:
>
> ONE <- rep(1, nrow(highways))
> NOC_Nord <- as.integer(!highways$C_Nord)
>
> which may not be correct. I'm seeing:
>
> Warning message:
> In lagsarlm(GR5101m ~ 0 + I(factor(C_Nord))/(LVAPC51), data = highways,  :
>   inversion of asymptotic covariance matrix failed for tol.solve = 1e-10
>   reciprocal condition number = 6.6223e-12 - using numerical Hessian.
>
> and an issue in an interaction term between the NOC_Nord term and the
> intercept:
>
> Coefficients: (numerical Hessian approximate standard errors)
>     (1 not defined because of singularities)
>                        Estimate Std. Error  z value Pr(>|z|)
> ONE:C_Nord            0.1385889  0.1310782   1.0573   0.2904
> ONE:NOC_Nord          0.1493507  0.1322529   1.1293   0.2588
> LVAPC51:C_Nord       -0.0170657  0.0010275 -16.6083   <2e-16
> LVAPC51:NOC_Nord     -0.0192602  0.0018370 -10.4845   <2e-16
> lag.ONE:C_Nord        0.0195317  0.1159969   0.1684   0.8663
> lag.ONE:NOC_Nord             NA         NA       NA       NA
> lag.LVAPC51:C_Nord   -0.0034108  0.0086611  -0.3938   0.6937
> lag.LVAPC51:NOC_Nord -0.0032861  0.0223143  -0.1473   0.8829
>
> Rho: 0.57171, LR test value: 1.8528, p-value: 0.17346 Approximate (numerical
> Hessian) standard error: 0.34917
>     z-value: 1.6374, p-value: 0.10156
> Wald statistic: 2.6809, p-value: 0.10156
>
> Roger
>
>
>> This is the link to the file with errors
>> https://onedrive.live.com/redir?resid=4484D82DD190F118!2202&authkey=!A
>> EXvKmB
>> o2FVgrQI&ithint=file%2cRData
>>
>> Thank you
>>
>> Loredana
>>
>>
>>
>> -----Messaggio originale-----
>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>> Inviato: mercoled? 21 ottobre 2015 13:26
>> A: Loredana Mirra
>> Cc: r-sig-geo at r-project.org
>> Oggetto: Re: R: [R-sig-Geo] Spatial Durbin Model with regimes in a
>> cross section framework
>>
>> On Wed, 21 Oct 2015, Loredana Mirra wrote:
>>
>>> Hi, and thank you again for your help. Following Anselin (2007)
>>> Spatial regression analysis in R  I managed to test for the presence
>>> of spatial regimes (also performing a Chow test) in R.
>>>
>>> Since, I need to apply a Spatial Durbin model, I tried fitting it
>>> using the following (just adding the option "mixed") to the sar
>>> command in the cases of regimes (Centre_North and South in my case):
>>>
>>> durb<-lagsarlm(GR5101m~ 0+ (ONE+
>>> LVAPC51):(C_Nord+NOC_Nord),data=highways,listw, type="mixed")
>>> summary(durb)
>>>
>>> I always get this error
>>> error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
>>>  0 (non-NA) cases
>>
>> Please provide the output of traceback() after the error has occurred.
>> I think that if the same model can be fitted with type="lag", but not
>> with "mixed", then the lagged X variables are possibly to blame.
>>
>> Maybe also try to use lmSLX() on the same formula, data and listw
>> objects, to see whether you also see failures in the lagged X
>> variables. The underlying create_WX() function does check for NAs, but
>> may not do it correctly - possibly for this formula.
>>
>> If this sounds hard, do:
>>
>> save(highways, listw, file="chow_error.RData")
>>
>> and make the "chow_error.RData" file available on a link (possibly
>> off-list if the data are private).
>>
>> Hope this helps,
>>
>> Roger
>>
>>>
>>> I checked if there were NA cases and tried with other variables or
>>> weight matrices. I wonder if this is a good approach or what is wrong.
>>>
>>> Thank you for your attention
>>> Loredana Mirra
>>>
>>>
>>>
>>>
>>> -----Messaggio originale-----
>>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>> Inviato: venerd? 2 ottobre 2015 10:59
>>> A: Loredana Mirra
>>> Cc: r-sig-geo at r-project.org
>>> Oggetto: Re:[R-sig-Geo] Spatial Durbin Model with regimes in a cross
>>> section framework
>>>
>>> On Fri, 2 Oct 2015, Loredana Mirra wrote:
>>>
>>>>
>>>> Thank you very much for your kind help. Yes, I should check also if,
>>>> after having estimated separated coefficients,  the difference, if
>>>> any, is statistically significant (using a chow test). Implementing
>>>> such test is the major issue to me. Can you give me an hint about this?
>>>
>>> Please see ch. 4 in Kleiber and Zeilis (2008) Applied Econometrics with
> R.
>>> You may use anova() on the no-regime model and the regime model,
>>> which is equivalent to a Chow test (personal communication, Achim
>>> Zeileis,
>> 2005).
>>> It will however suffer from misspecification such as outliers,
>>> discussed in section 4.3 and the use of a Wald test with an HC
>>> covariance
>> matrix.
>>>
>>>> Thanks also for the suggestion about the interpretation of output in
> SDM.
>>>
>>> A "Chow" test might go through a Likelihood Ratio test, but should
>>> arguably be presented using the empirical distributions of the
>>> impacts for each X variable for the no-regime model and for each regime.
>>>
>>> Hope this helps,
>>>
>>> Roger
>>>
>>>> Best Regards
>>>> Loredana
>>>> -----Messaggio originale-----
>>>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>>> Inviato: gioved? 1 ottobre 2015 20:45
>>>> A: Loredana Mirra
>>>> Cc: r-sig-geo at r-project.org
>>>> Oggetto: Re: [R-sig-Geo] Spatial Durbin Model with regimes in a
>>>> cross section framework
>>>>
>>>> On Thu, 1 Oct 2015, Loredana Mirra wrote:
>>>>
>>>>> I am writing to ask you a suggestion about the availability of a R
>>>>> routine or piece of program for the purposes of my empirical analysis.
>>>>> I should revise my paper using a Spatial Durbin model. This was
>>>>> recommended in order to mitigate a problem due to the possible
>>>>> presence of
>>>> unobserved factors.
>>>>>
>>>>> Unfortunately data do not permit to perform a panel but a cross
>>>>> section analysis. I do not have troubles to perform a Spatial
>>>>> Durbin Model on the entire sample, but I need to study the presence
>>>>> of Spatial Regimes. The problem is that I cannot find a program, in
>>>>> a cross sections framework. Do you know if there is a program
>>>>> available in R
>>>> to perform this analysis?
>>>>
>>>> How do you want to handle the "regimes"? Estimate separate
>>>> coefficients for each regime (regime defined as a factor)? If so,
>>>> this is a standard formula construction, and can be used with
>>>> formula objects in model fitting
>>>> functions:
>>>>
>>>> lm(mpg ~ 0 + I(factor(am))/(disp + wt), data=mtcars)
>>>>
>>>> or similar - check in detailed discussions of formula objects.
>>>>
>>>> You need to be careful to report impacts, not coefficient values,
>>>> from the Spatial Durbin model.
>>>>
>>>> Hope this helps,
>>>>
>>>> Roger
>>>>
>>>>> Thank you very much in advance for your help.
>>>>>
>>>>> Best regards
>>>>>
>>>>> Loredana Mirra
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> -------------------------
>>>>>
>>>>>
>>>>>
>>>>> Dott.ssa  Loredana Mirra
>>>>>
>>>>> Universit??? di Roma ???Tor Vergata???
>>>>>
>>>>> Dipartimento di Economia Diritto e Istituzioni
>>>>>
>>>>> Via Columbia, 2
>>>>>
>>>>> 00133 Roma
>>>>>
>>>>> Italia
>>>>>
>>>>> tel. +390672595725
>>>>>
>>>>> <mailto:pozzolo at unimol.it> loredana.mirra at uniroma2.it
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> ---
>>>>> Questa e-mail ??? stata controllata per individuare virus con Avast
>>>> antivirus.
>>>>> https://www.avast.com/antivirus
>>>>>
>>>>> 	[[alternative HTML version deleted]]
>>>>>
>>>>>
>>>>
>>>> --
>>>> Roger Bivand
>>>> Department of Economics, Norwegian School of Economics, Helleveien
>>>> 30,
>>>> N-5045 Bergen, Norway.
>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>> e-mail: Roger.Bivand at nhh.no
>>>>
>>>>
>>>> ---
>>>> Questa e-mail ? stata controllata per individuare virus con Avast
>>> antivirus.
>>>> https://www.avast.com/antivirus
>>>>
>>>>
>>>
>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics, Helleveien
>>> 30,
>>> N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>> ---
>>> Questa e-mail ? stata controllata per individuare virus con Avast
>> antivirus.
>>> https://www.avast.com/antivirus
>>>
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics, Helleveien 30,
>> N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>> ---
>> Questa e-mail ? stata controllata per individuare virus con Avast
> antivirus.
>> https://www.avast.com/antivirus
>>
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics, Helleveien 30,
> N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
>
> ---
> Questa e-mail ? stata controllata per individuare virus con Avast antivirus.
> https://www.avast.com/antivirus
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From loredana.mirra at uniroma2.it  Wed Oct 21 15:37:10 2015
From: loredana.mirra at uniroma2.it (Loredana Mirra)
Date: Wed, 21 Oct 2015 15:37:10 +0200
Subject: [R-sig-Geo] R: R: R: Spatial Durbin Model with regimes in a
	cross section framework
In-Reply-To: <alpine.LFD.2.20.1510211514340.6127@reclus.nhh.no>
References: <002c01d0fcee$6641f900$32c5eb00$@uniroma2.it>
	<alpine.LFD.2.20.1510021049140.28317@reclus.nhh.no>
	<008601d10bed$b8058820$28109860$@uniroma2.it>
	<alpine.LFD.2.20.1510211315480.6127@reclus.nhh.no>
	<009f01d10bf8$c02a7d20$407f7760$@uniroma2.it>
	<alpine.LFD.2.20.1510211413380.6127@reclus.nhh.no>
	<00b501d10c02$54c80e80$fe582b80$@uniroma2.it>
	<alpine.LFD.2.20.1510211514340.6127@reclus.nhh.no>
Message-ID: <C8DAD9F2-E96F-41F9-8454-CAC623C85E93@uniroma2.it>

I am using window 10. 
Loredana

Inviato da iPhone

> Il giorno 21/ott/2015, alle ore 15:25, Roger Bivand <Roger.Bivand at nhh.no> ha scritto:
> 
>> On Wed, 21 Oct 2015, Loredana Mirra wrote:
>> 
>> Thanks Roger,
>> At least you managed to have an output even if it contains some issues which
>> I could address changing variables.
>> Instead sorry but I am stuck. How can I get that?
> 
> library(spdep)
> sessionInfo() # spdep >=0.5-88
> load("chow_error.RData")
> ONE <- rep(1, nrow(highways))
> NOC_Nord <- as.integer(!highways$C_Nord)
> durb<-lagsarlm(GR5101m~ 0+ (ONE+LVAPC51):(C_Nord+NOC_Nord),
> data=highways, listw, type="mixed")
> summary(durb)
> 
> works for me (I'm using the development version of spdep, which seems to be the reason for the difference). There was an indexing error in create_WX() that is corrected in the development version but not in 0.5-88 on CRAN. Which OS are you using - there are reasons for not releasing the development version yet?
> 
> Roger
> 
>> Loredana
>> 
>> 
>> -----Messaggio originale-----
>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>> Inviato: mercoled? 21 ottobre 2015 14:19
>> A: Loredana Mirra
>> Cc: r-sig-geo at r-project.org
>> Oggetto: Re: R: R: [R-sig-Geo] Spatial Durbin Model with regimes in a cross
>> section framework
>> 
>>> On Wed, 21 Oct 2015, Loredana Mirra wrote:
>>> 
>>> Here the traceback()
>>> 4: stop("0 (non-NA) cases")
>>> 3: lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...)
>>> 2: lm(y ~ x - 1)
>>> 1: lagsarlm(GR5101m ~ 0 + (ONE + LVAPC51):(C_Nord + NOC_Nord), data =
>>> highwaysreg,
>>>      listw, type = "mixed")
>>> 
>>> No, problem. Data are not private. I tried to use the lmSLX and I got
>>> the same error
>> 
>> OK, thanks. I cannot reproduce your error as such - I'm constructing:
>> 
>> ONE <- rep(1, nrow(highways))
>> NOC_Nord <- as.integer(!highways$C_Nord)
>> 
>> which may not be correct. I'm seeing:
>> 
>> Warning message:
>> In lagsarlm(GR5101m ~ 0 + I(factor(C_Nord))/(LVAPC51), data = highways,  :
>>  inversion of asymptotic covariance matrix failed for tol.solve = 1e-10
>>  reciprocal condition number = 6.6223e-12 - using numerical Hessian.
>> 
>> and an issue in an interaction term between the NOC_Nord term and the
>> intercept:
>> 
>> Coefficients: (numerical Hessian approximate standard errors)
>>    (1 not defined because of singularities)
>>                       Estimate Std. Error  z value Pr(>|z|)
>> ONE:C_Nord            0.1385889  0.1310782   1.0573   0.2904
>> ONE:NOC_Nord          0.1493507  0.1322529   1.1293   0.2588
>> LVAPC51:C_Nord       -0.0170657  0.0010275 -16.6083   <2e-16
>> LVAPC51:NOC_Nord     -0.0192602  0.0018370 -10.4845   <2e-16
>> lag.ONE:C_Nord        0.0195317  0.1159969   0.1684   0.8663
>> lag.ONE:NOC_Nord             NA         NA       NA       NA
>> lag.LVAPC51:C_Nord   -0.0034108  0.0086611  -0.3938   0.6937
>> lag.LVAPC51:NOC_Nord -0.0032861  0.0223143  -0.1473   0.8829
>> 
>> Rho: 0.57171, LR test value: 1.8528, p-value: 0.17346 Approximate (numerical
>> Hessian) standard error: 0.34917
>>    z-value: 1.6374, p-value: 0.10156
>> Wald statistic: 2.6809, p-value: 0.10156
>> 
>> Roger
>> 
>> 
>>> This is the link to the file with errors
>>> https://onedrive.live.com/redir?resid=4484D82DD190F118!2202&authkey=!A
>>> EXvKmB
>>> o2FVgrQI&ithint=file%2cRData
>>> 
>>> Thank you
>>> 
>>> Loredana
>>> 
>>> 
>>> 
>>> -----Messaggio originale-----
>>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>> Inviato: mercoled? 21 ottobre 2015 13:26
>>> A: Loredana Mirra
>>> Cc: r-sig-geo at r-project.org
>>> Oggetto: Re: R: [R-sig-Geo] Spatial Durbin Model with regimes in a
>>> cross section framework
>>> 
>>>> On Wed, 21 Oct 2015, Loredana Mirra wrote:
>>>> 
>>>> Hi, and thank you again for your help. Following Anselin (2007)
>>>> Spatial regression analysis in R  I managed to test for the presence
>>>> of spatial regimes (also performing a Chow test) in R.
>>>> 
>>>> Since, I need to apply a Spatial Durbin model, I tried fitting it
>>>> using the following (just adding the option "mixed") to the sar
>>>> command in the cases of regimes (Centre_North and South in my case):
>>>> 
>>>> durb<-lagsarlm(GR5101m~ 0+ (ONE+
>>>> LVAPC51):(C_Nord+NOC_Nord),data=highways,listw, type="mixed")
>>>> summary(durb)
>>>> 
>>>> I always get this error
>>>> error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
>>>> 0 (non-NA) cases
>>> 
>>> Please provide the output of traceback() after the error has occurred.
>>> I think that if the same model can be fitted with type="lag", but not
>>> with "mixed", then the lagged X variables are possibly to blame.
>>> 
>>> Maybe also try to use lmSLX() on the same formula, data and listw
>>> objects, to see whether you also see failures in the lagged X
>>> variables. The underlying create_WX() function does check for NAs, but
>>> may not do it correctly - possibly for this formula.
>>> 
>>> If this sounds hard, do:
>>> 
>>> save(highways, listw, file="chow_error.RData")
>>> 
>>> and make the "chow_error.RData" file available on a link (possibly
>>> off-list if the data are private).
>>> 
>>> Hope this helps,
>>> 
>>> Roger
>>> 
>>>> 
>>>> I checked if there were NA cases and tried with other variables or
>>>> weight matrices. I wonder if this is a good approach or what is wrong.
>>>> 
>>>> Thank you for your attention
>>>> Loredana Mirra
>>>> 
>>>> 
>>>> 
>>>> 
>>>> -----Messaggio originale-----
>>>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>>> Inviato: venerd? 2 ottobre 2015 10:59
>>>> A: Loredana Mirra
>>>> Cc: r-sig-geo at r-project.org
>>>> Oggetto: Re:[R-sig-Geo] Spatial Durbin Model with regimes in a cross
>>>> section framework
>>>> 
>>>>> On Fri, 2 Oct 2015, Loredana Mirra wrote:
>>>>> 
>>>>> 
>>>>> Thank you very much for your kind help. Yes, I should check also if,
>>>>> after having estimated separated coefficients,  the difference, if
>>>>> any, is statistically significant (using a chow test). Implementing
>>>>> such test is the major issue to me. Can you give me an hint about this?
>>>> 
>>>> Please see ch. 4 in Kleiber and Zeilis (2008) Applied Econometrics with
>> R.
>>>> You may use anova() on the no-regime model and the regime model,
>>>> which is equivalent to a Chow test (personal communication, Achim
>>>> Zeileis,
>>> 2005).
>>>> It will however suffer from misspecification such as outliers,
>>>> discussed in section 4.3 and the use of a Wald test with an HC
>>>> covariance
>>> matrix.
>>>> 
>>>>> Thanks also for the suggestion about the interpretation of output in
>> SDM.
>>>> 
>>>> A "Chow" test might go through a Likelihood Ratio test, but should
>>>> arguably be presented using the empirical distributions of the
>>>> impacts for each X variable for the no-regime model and for each regime.
>>>> 
>>>> Hope this helps,
>>>> 
>>>> Roger
>>>> 
>>>>> Best Regards
>>>>> Loredana
>>>>> -----Messaggio originale-----
>>>>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>>>> Inviato: gioved? 1 ottobre 2015 20:45
>>>>> A: Loredana Mirra
>>>>> Cc: r-sig-geo at r-project.org
>>>>> Oggetto: Re: [R-sig-Geo] Spatial Durbin Model with regimes in a
>>>>> cross section framework
>>>>> 
>>>>>> On Thu, 1 Oct 2015, Loredana Mirra wrote:
>>>>>> 
>>>>>> I am writing to ask you a suggestion about the availability of a R
>>>>>> routine or piece of program for the purposes of my empirical analysis.
>>>>>> I should revise my paper using a Spatial Durbin model. This was
>>>>>> recommended in order to mitigate a problem due to the possible
>>>>>> presence of
>>>>> unobserved factors.
>>>>>> 
>>>>>> Unfortunately data do not permit to perform a panel but a cross
>>>>>> section analysis. I do not have troubles to perform a Spatial
>>>>>> Durbin Model on the entire sample, but I need to study the presence
>>>>>> of Spatial Regimes. The problem is that I cannot find a program, in
>>>>>> a cross sections framework. Do you know if there is a program
>>>>>> available in R
>>>>> to perform this analysis?
>>>>> 
>>>>> How do you want to handle the "regimes"? Estimate separate
>>>>> coefficients for each regime (regime defined as a factor)? If so,
>>>>> this is a standard formula construction, and can be used with
>>>>> formula objects in model fitting
>>>>> functions:
>>>>> 
>>>>> lm(mpg ~ 0 + I(factor(am))/(disp + wt), data=mtcars)
>>>>> 
>>>>> or similar - check in detailed discussions of formula objects.
>>>>> 
>>>>> You need to be careful to report impacts, not coefficient values,
>>>>> from the Spatial Durbin model.
>>>>> 
>>>>> Hope this helps,
>>>>> 
>>>>> Roger
>>>>> 
>>>>>> Thank you very much in advance for your help.
>>>>>> 
>>>>>> Best regards
>>>>>> 
>>>>>> Loredana Mirra
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> -------------------------
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> Dott.ssa  Loredana Mirra
>>>>>> 
>>>>>> Universit??? di Roma ???Tor Vergata???
>>>>>> 
>>>>>> Dipartimento di Economia Diritto e Istituzioni
>>>>>> 
>>>>>> Via Columbia, 2
>>>>>> 
>>>>>> 00133 Roma
>>>>>> 
>>>>>> Italia
>>>>>> 
>>>>>> tel. +390672595725
>>>>>> 
>>>>>> <mailto:pozzolo at unimol.it> loredana.mirra at uniroma2.it
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> ---
>>>>>> Questa e-mail ??? stata controllata per individuare virus con Avast
>>>>> antivirus.
>>>>>> https://www.avast.com/antivirus
>>>>>> 
>>>>>>    [[alternative HTML version deleted]]
>>>>> 
>>>>> --
>>>>> Roger Bivand
>>>>> Department of Economics, Norwegian School of Economics, Helleveien
>>>>> 30,
>>>>> N-5045 Bergen, Norway.
>>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>>> e-mail: Roger.Bivand at nhh.no
>>>>> 
>>>>> 
>>>>> ---
>>>>> Questa e-mail ? stata controllata per individuare virus con Avast
>>>> antivirus.
>>>>> https://www.avast.com/antivirus
>>>> 
>>>> --
>>>> Roger Bivand
>>>> Department of Economics, Norwegian School of Economics, Helleveien
>>>> 30,
>>>> N-5045 Bergen, Norway.
>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>> e-mail: Roger.Bivand at nhh.no
>>>> 
>>>> 
>>>> ---
>>>> Questa e-mail ? stata controllata per individuare virus con Avast
>>> antivirus.
>>>> https://www.avast.com/antivirus
>>> 
>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics, Helleveien 30,
>>> N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> e-mail: Roger.Bivand at nhh.no
>>> 
>>> 
>>> ---
>>> Questa e-mail ? stata controllata per individuare virus con Avast
>> antivirus.
>>> https://www.avast.com/antivirus
>> 
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics, Helleveien 30,
>> N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>> 
>> 
>> ---
>> Questa e-mail ? stata controllata per individuare virus con Avast antivirus.
>> https://www.avast.com/antivirus
> 
> -- 
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no


From loredana.mirra at uniroma2.it  Wed Oct 21 16:11:48 2015
From: loredana.mirra at uniroma2.it (Loredana Mirra)
Date: Wed, 21 Oct 2015 16:11:48 +0200
Subject: [R-sig-Geo] R: R: R: R: Spatial Durbin Model with regimes in a
	cross section framework
In-Reply-To: <alpine.LFD.2.20.1510211514340.6127@reclus.nhh.no>
References: <002c01d0fcee$6641f900$32c5eb00$@uniroma2.it>
	<alpine.LFD.2.20.1510021049140.28317@reclus.nhh.no>
	<008601d10bed$b8058820$28109860$@uniroma2.it>
	<alpine.LFD.2.20.1510211315480.6127@reclus.nhh.no>
	<009f01d10bf8$c02a7d20$407f7760$@uniroma2.it>
	<alpine.LFD.2.20.1510211413380.6127@reclus.nhh.no>
	<00b501d10c02$54c80e80$fe582b80$@uniroma2.it>
	<alpine.LFD.2.20.1510211514340.6127@reclus.nhh.no>
Message-ID: <00d601d10c0a$6d0e8750$472b95f0$@uniroma2.it>

I am using Windows 10
Loredana

-----Messaggio originale-----
Da: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Inviato: mercoled? 21 ottobre 2015 15:26
A: Loredana Mirra
Cc: r-sig-geo at r-project.org
Oggetto: Re: R: R: R: [R-sig-Geo] Spatial Durbin Model with regimes in a
cross section framework

On Wed, 21 Oct 2015, Loredana Mirra wrote:

> Thanks Roger,
> At least you managed to have an output even if it contains some issues 
> which I could address changing variables.
> Instead sorry but I am stuck. How can I get that?

library(spdep)
sessionInfo() # spdep >=0.5-88
load("chow_error.RData")
ONE <- rep(1, nrow(highways))
NOC_Nord <- as.integer(!highways$C_Nord) durb<-lagsarlm(GR5101m~ 0+
(ONE+LVAPC51):(C_Nord+NOC_Nord),
  data=highways, listw, type="mixed")
summary(durb)

works for me (I'm using the development version of spdep, which seems to be
the reason for the difference). There was an indexing error in
create_WX() that is corrected in the development version but not in 0.5-88
on CRAN. Which OS are you using - there are reasons for not releasing the
development version yet?

Roger

> Loredana
>
>
> -----Messaggio originale-----
> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Inviato: mercoled? 21 ottobre 2015 14:19
> A: Loredana Mirra
> Cc: r-sig-geo at r-project.org
> Oggetto: Re: R: R: [R-sig-Geo] Spatial Durbin Model with regimes in a 
> cross section framework
>
> On Wed, 21 Oct 2015, Loredana Mirra wrote:
>
>> Here the traceback()
>> 4: stop("0 (non-NA) cases")
>> 3: lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...)
>> 2: lm(y ~ x - 1)
>> 1: lagsarlm(GR5101m ~ 0 + (ONE + LVAPC51):(C_Nord + NOC_Nord), data = 
>> highwaysreg,
>>       listw, type = "mixed")
>>
>> No, problem. Data are not private. I tried to use the lmSLX and I got 
>> the same error
>
> OK, thanks. I cannot reproduce your error as such - I'm constructing:
>
> ONE <- rep(1, nrow(highways))
> NOC_Nord <- as.integer(!highways$C_Nord)
>
> which may not be correct. I'm seeing:
>
> Warning message:
> In lagsarlm(GR5101m ~ 0 + I(factor(C_Nord))/(LVAPC51), data = highways,  :
>   inversion of asymptotic covariance matrix failed for tol.solve = 1e-10
>   reciprocal condition number = 6.6223e-12 - using numerical Hessian.
>
> and an issue in an interaction term between the NOC_Nord term and the
> intercept:
>
> Coefficients: (numerical Hessian approximate standard errors)
>     (1 not defined because of singularities)
>                        Estimate Std. Error  z value Pr(>|z|)
> ONE:C_Nord            0.1385889  0.1310782   1.0573   0.2904
> ONE:NOC_Nord          0.1493507  0.1322529   1.1293   0.2588
> LVAPC51:C_Nord       -0.0170657  0.0010275 -16.6083   <2e-16
> LVAPC51:NOC_Nord     -0.0192602  0.0018370 -10.4845   <2e-16
> lag.ONE:C_Nord        0.0195317  0.1159969   0.1684   0.8663
> lag.ONE:NOC_Nord             NA         NA       NA       NA
> lag.LVAPC51:C_Nord   -0.0034108  0.0086611  -0.3938   0.6937
> lag.LVAPC51:NOC_Nord -0.0032861  0.0223143  -0.1473   0.8829
>
> Rho: 0.57171, LR test value: 1.8528, p-value: 0.17346 Approximate 
> (numerical
> Hessian) standard error: 0.34917
>     z-value: 1.6374, p-value: 0.10156
> Wald statistic: 2.6809, p-value: 0.10156
>
> Roger
>
>
>> This is the link to the file with errors 
>> https://onedrive.live.com/redir?resid=4484D82DD190F118!2202&authkey=!
>> A
>> EXvKmB
>> o2FVgrQI&ithint=file%2cRData
>>
>> Thank you
>>
>> Loredana
>>
>>
>>
>> -----Messaggio originale-----
>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>> Inviato: mercoled? 21 ottobre 2015 13:26
>> A: Loredana Mirra
>> Cc: r-sig-geo at r-project.org
>> Oggetto: Re: R: [R-sig-Geo] Spatial Durbin Model with regimes in a 
>> cross section framework
>>
>> On Wed, 21 Oct 2015, Loredana Mirra wrote:
>>
>>> Hi, and thank you again for your help. Following Anselin (2007) 
>>> Spatial regression analysis in R  I managed to test for the presence 
>>> of spatial regimes (also performing a Chow test) in R.
>>>
>>> Since, I need to apply a Spatial Durbin model, I tried fitting it 
>>> using the following (just adding the option "mixed") to the sar 
>>> command in the cases of regimes (Centre_North and South in my case):
>>>
>>> durb<-lagsarlm(GR5101m~ 0+ (ONE+
>>> LVAPC51):(C_Nord+NOC_Nord),data=highways,listw, type="mixed")
>>> summary(durb)
>>>
>>> I always get this error
>>> error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
>>>  0 (non-NA) cases
>>
>> Please provide the output of traceback() after the error has occurred.
>> I think that if the same model can be fitted with type="lag", but not 
>> with "mixed", then the lagged X variables are possibly to blame.
>>
>> Maybe also try to use lmSLX() on the same formula, data and listw 
>> objects, to see whether you also see failures in the lagged X 
>> variables. The underlying create_WX() function does check for NAs, 
>> but may not do it correctly - possibly for this formula.
>>
>> If this sounds hard, do:
>>
>> save(highways, listw, file="chow_error.RData")
>>
>> and make the "chow_error.RData" file available on a link (possibly 
>> off-list if the data are private).
>>
>> Hope this helps,
>>
>> Roger
>>
>>>
>>> I checked if there were NA cases and tried with other variables or 
>>> weight matrices. I wonder if this is a good approach or what is wrong.
>>>
>>> Thank you for your attention
>>> Loredana Mirra
>>>
>>>
>>>
>>>
>>> -----Messaggio originale-----
>>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>> Inviato: venerd? 2 ottobre 2015 10:59
>>> A: Loredana Mirra
>>> Cc: r-sig-geo at r-project.org
>>> Oggetto: Re:[R-sig-Geo] Spatial Durbin Model with regimes in a cross 
>>> section framework
>>>
>>> On Fri, 2 Oct 2015, Loredana Mirra wrote:
>>>
>>>>
>>>> Thank you very much for your kind help. Yes, I should check also 
>>>> if, after having estimated separated coefficients,  the difference, 
>>>> if any, is statistically significant (using a chow test). 
>>>> Implementing such test is the major issue to me. Can you give me an
hint about this?
>>>
>>> Please see ch. 4 in Kleiber and Zeilis (2008) Applied Econometrics 
>>> with
> R.
>>> You may use anova() on the no-regime model and the regime model, 
>>> which is equivalent to a Chow test (personal communication, Achim 
>>> Zeileis,
>> 2005).
>>> It will however suffer from misspecification such as outliers, 
>>> discussed in section 4.3 and the use of a Wald test with an HC 
>>> covariance
>> matrix.
>>>
>>>> Thanks also for the suggestion about the interpretation of output 
>>>> in
> SDM.
>>>
>>> A "Chow" test might go through a Likelihood Ratio test, but should 
>>> arguably be presented using the empirical distributions of the 
>>> impacts for each X variable for the no-regime model and for each regime.
>>>
>>> Hope this helps,
>>>
>>> Roger
>>>
>>>> Best Regards
>>>> Loredana
>>>> -----Messaggio originale-----
>>>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>>> Inviato: gioved? 1 ottobre 2015 20:45
>>>> A: Loredana Mirra
>>>> Cc: r-sig-geo at r-project.org
>>>> Oggetto: Re: [R-sig-Geo] Spatial Durbin Model with regimes in a 
>>>> cross section framework
>>>>
>>>> On Thu, 1 Oct 2015, Loredana Mirra wrote:
>>>>
>>>>> I am writing to ask you a suggestion about the availability of a R 
>>>>> routine or piece of program for the purposes of my empirical analysis.
>>>>> I should revise my paper using a Spatial Durbin model. This was 
>>>>> recommended in order to mitigate a problem due to the possible 
>>>>> presence of
>>>> unobserved factors.
>>>>>
>>>>> Unfortunately data do not permit to perform a panel but a cross 
>>>>> section analysis. I do not have troubles to perform a Spatial 
>>>>> Durbin Model on the entire sample, but I need to study the 
>>>>> presence of Spatial Regimes. The problem is that I cannot find a 
>>>>> program, in a cross sections framework. Do you know if there is a 
>>>>> program available in R
>>>> to perform this analysis?
>>>>
>>>> How do you want to handle the "regimes"? Estimate separate 
>>>> coefficients for each regime (regime defined as a factor)? If so, 
>>>> this is a standard formula construction, and can be used with 
>>>> formula objects in model fitting
>>>> functions:
>>>>
>>>> lm(mpg ~ 0 + I(factor(am))/(disp + wt), data=mtcars)
>>>>
>>>> or similar - check in detailed discussions of formula objects.
>>>>
>>>> You need to be careful to report impacts, not coefficient values, 
>>>> from the Spatial Durbin model.
>>>>
>>>> Hope this helps,
>>>>
>>>> Roger
>>>>
>>>>> Thank you very much in advance for your help.
>>>>>
>>>>> Best regards
>>>>>
>>>>> Loredana Mirra
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> -------------------------
>>>>>
>>>>>
>>>>>
>>>>> Dott.ssa  Loredana Mirra
>>>>>
>>>>> Universit??? di Roma ???Tor Vergata???
>>>>>
>>>>> Dipartimento di Economia Diritto e Istituzioni
>>>>>
>>>>> Via Columbia, 2
>>>>>
>>>>> 00133 Roma
>>>>>
>>>>> Italia
>>>>>
>>>>> tel. +390672595725
>>>>>
>>>>> <mailto:pozzolo at unimol.it> loredana.mirra at uniroma2.it
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> ---
>>>>> Questa e-mail ??? stata controllata per individuare virus con 
>>>>> Avast
>>>> antivirus.
>>>>> https://www.avast.com/antivirus
>>>>>
>>>>> 	[[alternative HTML version deleted]]
>>>>>
>>>>>
>>>>
>>>> --
>>>> Roger Bivand
>>>> Department of Economics, Norwegian School of Economics, Helleveien 
>>>> 30,
>>>> N-5045 Bergen, Norway.
>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>> e-mail: Roger.Bivand at nhh.no
>>>>
>>>>
>>>> ---
>>>> Questa e-mail ? stata controllata per individuare virus con Avast
>>> antivirus.
>>>> https://www.avast.com/antivirus
>>>>
>>>>
>>>
>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics, Helleveien 
>>> 30,
>>> N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>> ---
>>> Questa e-mail ? stata controllata per individuare virus con Avast
>> antivirus.
>>> https://www.avast.com/antivirus
>>>
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics, Helleveien 
>> 30,
>> N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>> ---
>> Questa e-mail ? stata controllata per individuare virus con Avast
> antivirus.
>> https://www.avast.com/antivirus
>>
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics, Helleveien 30,
> N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
>
> ---
> Questa e-mail ? stata controllata per individuare virus con Avast
antivirus.
> https://www.avast.com/antivirus
>
>

--
Roger Bivand
Department of Economics, Norwegian School of Economics, Helleveien 30,
N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


---
Questa e-mail ? stata controllata per individuare virus con Avast antivirus.
https://www.avast.com/antivirus


From timothee.giraud at ums-riate.fr  Tue Oct 20 16:45:34 2015
From: timothee.giraud at ums-riate.fr (Timothee Giraud)
Date: Tue, 20 Oct 2015 16:45:34 +0200
Subject: [R-sig-Geo] New package for thematic cartography: cartography
Message-ID: <5626538E.8070800@ums-riate.fr>

Dear members of the list,

We just wanted to bring your attention to our new package on CRAN: 
cartography.

This package allows various cartographic representations: proportional 
symbols, chroropleth, typology, flows, discontinuities...
It also proposes some additional useful features: cartographic palettes, 
layout (scale, north arrow, title...), labels, legends, access to 
cartographic API...

Note that the vignette of the package contains commented scripts on how 
to build various types of maps.

The development version is on GitHub: 
https://github.com/Groupe-ElementR/cartography .

And of course feedbacks on the package are more than welcome!

Best regards,
Timoth?e


-- 
Timoth?e Giraud
Databases & Geomatics
http://rgeomatic.hypotheses.org/
http://ums-riate.fr/


From loredana.mirra at uniroma2.it  Wed Oct 21 16:50:58 2015
From: loredana.mirra at uniroma2.it (Loredana Mirra)
Date: Wed, 21 Oct 2015 16:50:58 +0200
Subject: [R-sig-Geo] R: R: R: R: Spatial Durbin Model with regimes in a
	cross section framework
In-Reply-To: <alpine.LFD.2.20.1510211514340.6127@reclus.nhh.no>
References: <002c01d0fcee$6641f900$32c5eb00$@uniroma2.it>
	<alpine.LFD.2.20.1510021049140.28317@reclus.nhh.no>
	<008601d10bed$b8058820$28109860$@uniroma2.it>
	<alpine.LFD.2.20.1510211315480.6127@reclus.nhh.no>
	<009f01d10bf8$c02a7d20$407f7760$@uniroma2.it>
	<alpine.LFD.2.20.1510211413380.6127@reclus.nhh.no>
	<00b501d10c02$54c80e80$fe582b80$@uniroma2.it>
	<alpine.LFD.2.20.1510211514340.6127@reclus.nhh.no>
Message-ID: <00fc01d10c0f$e5af78e0$b10e6aa0$@uniroma2.it>

I will try on another pc with a different OS. 
Thanks a lot
Loredana

-----Messaggio originale-----
Da: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Inviato: mercoled? 21 ottobre 2015 15:26
A: Loredana Mirra
Cc: r-sig-geo at r-project.org
Oggetto: Re: R: R: R: [R-sig-Geo] Spatial Durbin Model with regimes in a
cross section framework

On Wed, 21 Oct 2015, Loredana Mirra wrote:

> Thanks Roger,
> At least you managed to have an output even if it contains some issues 
> which I could address changing variables.
> Instead sorry but I am stuck. How can I get that?

library(spdep)
sessionInfo() # spdep >=0.5-88
load("chow_error.RData")
ONE <- rep(1, nrow(highways))
NOC_Nord <- as.integer(!highways$C_Nord) durb<-lagsarlm(GR5101m~ 0+
(ONE+LVAPC51):(C_Nord+NOC_Nord),
  data=highways, listw, type="mixed")
summary(durb)

works for me (I'm using the development version of spdep, which seems to be
the reason for the difference). There was an indexing error in
create_WX() that is corrected in the development version but not in 0.5-88
on CRAN. Which OS are you using - there are reasons for not releasing the
development version yet?

Roger

> Loredana
>
>
> -----Messaggio originale-----
> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Inviato: mercoled? 21 ottobre 2015 14:19
> A: Loredana Mirra
> Cc: r-sig-geo at r-project.org
> Oggetto: Re: R: R: [R-sig-Geo] Spatial Durbin Model with regimes in a 
> cross section framework
>
> On Wed, 21 Oct 2015, Loredana Mirra wrote:
>
>> Here the traceback()
>> 4: stop("0 (non-NA) cases")
>> 3: lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...)
>> 2: lm(y ~ x - 1)
>> 1: lagsarlm(GR5101m ~ 0 + (ONE + LVAPC51):(C_Nord + NOC_Nord), data = 
>> highwaysreg,
>>       listw, type = "mixed")
>>
>> No, problem. Data are not private. I tried to use the lmSLX and I got 
>> the same error
>
> OK, thanks. I cannot reproduce your error as such - I'm constructing:
>
> ONE <- rep(1, nrow(highways))
> NOC_Nord <- as.integer(!highways$C_Nord)
>
> which may not be correct. I'm seeing:
>
> Warning message:
> In lagsarlm(GR5101m ~ 0 + I(factor(C_Nord))/(LVAPC51), data = highways,  :
>   inversion of asymptotic covariance matrix failed for tol.solve = 1e-10
>   reciprocal condition number = 6.6223e-12 - using numerical Hessian.
>
> and an issue in an interaction term between the NOC_Nord term and the
> intercept:
>
> Coefficients: (numerical Hessian approximate standard errors)
>     (1 not defined because of singularities)
>                        Estimate Std. Error  z value Pr(>|z|)
> ONE:C_Nord            0.1385889  0.1310782   1.0573   0.2904
> ONE:NOC_Nord          0.1493507  0.1322529   1.1293   0.2588
> LVAPC51:C_Nord       -0.0170657  0.0010275 -16.6083   <2e-16
> LVAPC51:NOC_Nord     -0.0192602  0.0018370 -10.4845   <2e-16
> lag.ONE:C_Nord        0.0195317  0.1159969   0.1684   0.8663
> lag.ONE:NOC_Nord             NA         NA       NA       NA
> lag.LVAPC51:C_Nord   -0.0034108  0.0086611  -0.3938   0.6937
> lag.LVAPC51:NOC_Nord -0.0032861  0.0223143  -0.1473   0.8829
>
> Rho: 0.57171, LR test value: 1.8528, p-value: 0.17346 Approximate 
> (numerical
> Hessian) standard error: 0.34917
>     z-value: 1.6374, p-value: 0.10156
> Wald statistic: 2.6809, p-value: 0.10156
>
> Roger
>
>
>> This is the link to the file with errors 
>> https://onedrive.live.com/redir?resid=4484D82DD190F118!2202&authkey=!
>> A
>> EXvKmB
>> o2FVgrQI&ithint=file%2cRData
>>
>> Thank you
>>
>> Loredana
>>
>>
>>
>> -----Messaggio originale-----
>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>> Inviato: mercoled? 21 ottobre 2015 13:26
>> A: Loredana Mirra
>> Cc: r-sig-geo at r-project.org
>> Oggetto: Re: R: [R-sig-Geo] Spatial Durbin Model with regimes in a 
>> cross section framework
>>
>> On Wed, 21 Oct 2015, Loredana Mirra wrote:
>>
>>> Hi, and thank you again for your help. Following Anselin (2007) 
>>> Spatial regression analysis in R  I managed to test for the presence 
>>> of spatial regimes (also performing a Chow test) in R.
>>>
>>> Since, I need to apply a Spatial Durbin model, I tried fitting it 
>>> using the following (just adding the option "mixed") to the sar 
>>> command in the cases of regimes (Centre_North and South in my case):
>>>
>>> durb<-lagsarlm(GR5101m~ 0+ (ONE+
>>> LVAPC51):(C_Nord+NOC_Nord),data=highways,listw, type="mixed")
>>> summary(durb)
>>>
>>> I always get this error
>>> error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
>>>  0 (non-NA) cases
>>
>> Please provide the output of traceback() after the error has occurred.
>> I think that if the same model can be fitted with type="lag", but not 
>> with "mixed", then the lagged X variables are possibly to blame.
>>
>> Maybe also try to use lmSLX() on the same formula, data and listw 
>> objects, to see whether you also see failures in the lagged X 
>> variables. The underlying create_WX() function does check for NAs, 
>> but may not do it correctly - possibly for this formula.
>>
>> If this sounds hard, do:
>>
>> save(highways, listw, file="chow_error.RData")
>>
>> and make the "chow_error.RData" file available on a link (possibly 
>> off-list if the data are private).
>>
>> Hope this helps,
>>
>> Roger
>>
>>>
>>> I checked if there were NA cases and tried with other variables or 
>>> weight matrices. I wonder if this is a good approach or what is wrong.
>>>
>>> Thank you for your attention
>>> Loredana Mirra
>>>
>>>
>>>
>>>
>>> -----Messaggio originale-----
>>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>> Inviato: venerd? 2 ottobre 2015 10:59
>>> A: Loredana Mirra
>>> Cc: r-sig-geo at r-project.org
>>> Oggetto: Re:[R-sig-Geo] Spatial Durbin Model with regimes in a cross 
>>> section framework
>>>
>>> On Fri, 2 Oct 2015, Loredana Mirra wrote:
>>>
>>>>
>>>> Thank you very much for your kind help. Yes, I should check also 
>>>> if, after having estimated separated coefficients,  the difference, 
>>>> if any, is statistically significant (using a chow test). 
>>>> Implementing such test is the major issue to me. Can you give me an
hint about this?
>>>
>>> Please see ch. 4 in Kleiber and Zeilis (2008) Applied Econometrics 
>>> with
> R.
>>> You may use anova() on the no-regime model and the regime model, 
>>> which is equivalent to a Chow test (personal communication, Achim 
>>> Zeileis,
>> 2005).
>>> It will however suffer from misspecification such as outliers, 
>>> discussed in section 4.3 and the use of a Wald test with an HC 
>>> covariance
>> matrix.
>>>
>>>> Thanks also for the suggestion about the interpretation of output 
>>>> in
> SDM.
>>>
>>> A "Chow" test might go through a Likelihood Ratio test, but should 
>>> arguably be presented using the empirical distributions of the 
>>> impacts for each X variable for the no-regime model and for each regime.
>>>
>>> Hope this helps,
>>>
>>> Roger
>>>
>>>> Best Regards
>>>> Loredana
>>>> -----Messaggio originale-----
>>>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>>> Inviato: gioved? 1 ottobre 2015 20:45
>>>> A: Loredana Mirra
>>>> Cc: r-sig-geo at r-project.org
>>>> Oggetto: Re: [R-sig-Geo] Spatial Durbin Model with regimes in a 
>>>> cross section framework
>>>>
>>>> On Thu, 1 Oct 2015, Loredana Mirra wrote:
>>>>
>>>>> I am writing to ask you a suggestion about the availability of a R 
>>>>> routine or piece of program for the purposes of my empirical analysis.
>>>>> I should revise my paper using a Spatial Durbin model. This was 
>>>>> recommended in order to mitigate a problem due to the possible 
>>>>> presence of
>>>> unobserved factors.
>>>>>
>>>>> Unfortunately data do not permit to perform a panel but a cross 
>>>>> section analysis. I do not have troubles to perform a Spatial 
>>>>> Durbin Model on the entire sample, but I need to study the 
>>>>> presence of Spatial Regimes. The problem is that I cannot find a 
>>>>> program, in a cross sections framework. Do you know if there is a 
>>>>> program available in R
>>>> to perform this analysis?
>>>>
>>>> How do you want to handle the "regimes"? Estimate separate 
>>>> coefficients for each regime (regime defined as a factor)? If so, 
>>>> this is a standard formula construction, and can be used with 
>>>> formula objects in model fitting
>>>> functions:
>>>>
>>>> lm(mpg ~ 0 + I(factor(am))/(disp + wt), data=mtcars)
>>>>
>>>> or similar - check in detailed discussions of formula objects.
>>>>
>>>> You need to be careful to report impacts, not coefficient values, 
>>>> from the Spatial Durbin model.
>>>>
>>>> Hope this helps,
>>>>
>>>> Roger
>>>>
>>>>> Thank you very much in advance for your help.
>>>>>
>>>>> Best regards
>>>>>
>>>>> Loredana Mirra
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> -------------------------
>>>>>
>>>>>
>>>>>
>>>>> Dott.ssa  Loredana Mirra
>>>>>
>>>>> Universit??? di Roma ???Tor Vergata???
>>>>>
>>>>> Dipartimento di Economia Diritto e Istituzioni
>>>>>
>>>>> Via Columbia, 2
>>>>>
>>>>> 00133 Roma
>>>>>
>>>>> Italia
>>>>>
>>>>> tel. +390672595725
>>>>>
>>>>> <mailto:pozzolo at unimol.it> loredana.mirra at uniroma2.it
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> ---
>>>>> Questa e-mail ??? stata controllata per individuare virus con 
>>>>> Avast
>>>> antivirus.
>>>>> https://www.avast.com/antivirus
>>>>>
>>>>> 	[[alternative HTML version deleted]]
>>>>>
>>>>>
>>>>
>>>> --
>>>> Roger Bivand
>>>> Department of Economics, Norwegian School of Economics, Helleveien 
>>>> 30,
>>>> N-5045 Bergen, Norway.
>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>> e-mail: Roger.Bivand at nhh.no
>>>>
>>>>
>>>> ---
>>>> Questa e-mail ? stata controllata per individuare virus con Avast
>>> antivirus.
>>>> https://www.avast.com/antivirus
>>>>
>>>>
>>>
>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics, Helleveien 
>>> 30,
>>> N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>> ---
>>> Questa e-mail ? stata controllata per individuare virus con Avast
>> antivirus.
>>> https://www.avast.com/antivirus
>>>
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics, Helleveien 
>> 30,
>> N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>> ---
>> Questa e-mail ? stata controllata per individuare virus con Avast
> antivirus.
>> https://www.avast.com/antivirus
>>
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics, Helleveien 30,
> N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
>
> ---
> Questa e-mail ? stata controllata per individuare virus con Avast
antivirus.
> https://www.avast.com/antivirus
>
>

--
Roger Bivand
Department of Economics, Norwegian School of Economics, Helleveien 30,
N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


---
Questa e-mail ? stata controllata per individuare virus con Avast antivirus.
https://www.avast.com/antivirus


From loredana.mirra at uniroma2.it  Wed Oct 21 17:26:59 2015
From: loredana.mirra at uniroma2.it (Loredana Mirra)
Date: Wed, 21 Oct 2015 17:26:59 +0200
Subject: [R-sig-Geo] R: R: R: R: Spatial Durbin Model with regimes in a
	cross section framework
In-Reply-To: <alpine.LFD.2.20.1510211514340.6127@reclus.nhh.no>
References: <002c01d0fcee$6641f900$32c5eb00$@uniroma2.it>
	<alpine.LFD.2.20.1510021049140.28317@reclus.nhh.no>
	<008601d10bed$b8058820$28109860$@uniroma2.it>
	<alpine.LFD.2.20.1510211315480.6127@reclus.nhh.no>
	<009f01d10bf8$c02a7d20$407f7760$@uniroma2.it>
	<alpine.LFD.2.20.1510211413380.6127@reclus.nhh.no>
	<00b501d10c02$54c80e80$fe582b80$@uniroma2.it>
	<alpine.LFD.2.20.1510211514340.6127@reclus.nhh.no>
Message-ID: <011401d10c14$ed9550c0$c8bff240$@uniroma2.it>

I will try to install and use R and Spdep on another pc with another OS
Loredana

-----Messaggio originale-----
Da: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Inviato: mercoled? 21 ottobre 2015 15:26
A: Loredana Mirra
Cc: r-sig-geo at r-project.org
Oggetto: Re: R: R: R: [R-sig-Geo] Spatial Durbin Model with regimes in a
cross section framework

On Wed, 21 Oct 2015, Loredana Mirra wrote:

> Thanks Roger,
> At least you managed to have an output even if it contains some issues 
> which I could address changing variables.
> Instead sorry but I am stuck. How can I get that?

library(spdep)
sessionInfo() # spdep >=0.5-88
load("chow_error.RData")
ONE <- rep(1, nrow(highways))
NOC_Nord <- as.integer(!highways$C_Nord) durb<-lagsarlm(GR5101m~ 0+
(ONE+LVAPC51):(C_Nord+NOC_Nord),
  data=highways, listw, type="mixed")
summary(durb)

works for me (I'm using the development version of spdep, which seems to be
the reason for the difference). There was an indexing error in
create_WX() that is corrected in the development version but not in 0.5-88
on CRAN. Which OS are you using - there are reasons for not releasing the
development version yet?

Roger

> Loredana
>
>
> -----Messaggio originale-----
> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Inviato: mercoled? 21 ottobre 2015 14:19
> A: Loredana Mirra
> Cc: r-sig-geo at r-project.org
> Oggetto: Re: R: R: [R-sig-Geo] Spatial Durbin Model with regimes in a 
> cross section framework
>
> On Wed, 21 Oct 2015, Loredana Mirra wrote:
>
>> Here the traceback()
>> 4: stop("0 (non-NA) cases")
>> 3: lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...)
>> 2: lm(y ~ x - 1)
>> 1: lagsarlm(GR5101m ~ 0 + (ONE + LVAPC51):(C_Nord + NOC_Nord), data = 
>> highwaysreg,
>>       listw, type = "mixed")
>>
>> No, problem. Data are not private. I tried to use the lmSLX and I got 
>> the same error
>
> OK, thanks. I cannot reproduce your error as such - I'm constructing:
>
> ONE <- rep(1, nrow(highways))
> NOC_Nord <- as.integer(!highways$C_Nord)
>
> which may not be correct. I'm seeing:
>
> Warning message:
> In lagsarlm(GR5101m ~ 0 + I(factor(C_Nord))/(LVAPC51), data = highways,  :
>   inversion of asymptotic covariance matrix failed for tol.solve = 1e-10
>   reciprocal condition number = 6.6223e-12 - using numerical Hessian.
>
> and an issue in an interaction term between the NOC_Nord term and the
> intercept:
>
> Coefficients: (numerical Hessian approximate standard errors)
>     (1 not defined because of singularities)
>                        Estimate Std. Error  z value Pr(>|z|)
> ONE:C_Nord            0.1385889  0.1310782   1.0573   0.2904
> ONE:NOC_Nord          0.1493507  0.1322529   1.1293   0.2588
> LVAPC51:C_Nord       -0.0170657  0.0010275 -16.6083   <2e-16
> LVAPC51:NOC_Nord     -0.0192602  0.0018370 -10.4845   <2e-16
> lag.ONE:C_Nord        0.0195317  0.1159969   0.1684   0.8663
> lag.ONE:NOC_Nord             NA         NA       NA       NA
> lag.LVAPC51:C_Nord   -0.0034108  0.0086611  -0.3938   0.6937
> lag.LVAPC51:NOC_Nord -0.0032861  0.0223143  -0.1473   0.8829
>
> Rho: 0.57171, LR test value: 1.8528, p-value: 0.17346 Approximate 
> (numerical
> Hessian) standard error: 0.34917
>     z-value: 1.6374, p-value: 0.10156
> Wald statistic: 2.6809, p-value: 0.10156
>
> Roger
>
>
>> This is the link to the file with errors 
>> https://onedrive.live.com/redir?resid=4484D82DD190F118!2202&authkey=!
>> A
>> EXvKmB
>> o2FVgrQI&ithint=file%2cRData
>>
>> Thank you
>>
>> Loredana
>>
>>
>>
>> -----Messaggio originale-----
>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>> Inviato: mercoled? 21 ottobre 2015 13:26
>> A: Loredana Mirra
>> Cc: r-sig-geo at r-project.org
>> Oggetto: Re: R: [R-sig-Geo] Spatial Durbin Model with regimes in a 
>> cross section framework
>>
>> On Wed, 21 Oct 2015, Loredana Mirra wrote:
>>
>>> Hi, and thank you again for your help. Following Anselin (2007) 
>>> Spatial regression analysis in R  I managed to test for the presence 
>>> of spatial regimes (also performing a Chow test) in R.
>>>
>>> Since, I need to apply a Spatial Durbin model, I tried fitting it 
>>> using the following (just adding the option "mixed") to the sar 
>>> command in the cases of regimes (Centre_North and South in my case):
>>>
>>> durb<-lagsarlm(GR5101m~ 0+ (ONE+
>>> LVAPC51):(C_Nord+NOC_Nord),data=highways,listw, type="mixed")
>>> summary(durb)
>>>
>>> I always get this error
>>> error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
>>>  0 (non-NA) cases
>>
>> Please provide the output of traceback() after the error has occurred.
>> I think that if the same model can be fitted with type="lag", but not 
>> with "mixed", then the lagged X variables are possibly to blame.
>>
>> Maybe also try to use lmSLX() on the same formula, data and listw 
>> objects, to see whether you also see failures in the lagged X 
>> variables. The underlying create_WX() function does check for NAs, 
>> but may not do it correctly - possibly for this formula.
>>
>> If this sounds hard, do:
>>
>> save(highways, listw, file="chow_error.RData")
>>
>> and make the "chow_error.RData" file available on a link (possibly 
>> off-list if the data are private).
>>
>> Hope this helps,
>>
>> Roger
>>
>>>
>>> I checked if there were NA cases and tried with other variables or 
>>> weight matrices. I wonder if this is a good approach or what is wrong.
>>>
>>> Thank you for your attention
>>> Loredana Mirra
>>>
>>>
>>>
>>>
>>> -----Messaggio originale-----
>>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>> Inviato: venerd? 2 ottobre 2015 10:59
>>> A: Loredana Mirra
>>> Cc: r-sig-geo at r-project.org
>>> Oggetto: Re:[R-sig-Geo] Spatial Durbin Model with regimes in a cross 
>>> section framework
>>>
>>> On Fri, 2 Oct 2015, Loredana Mirra wrote:
>>>
>>>>
>>>> Thank you very much for your kind help. Yes, I should check also 
>>>> if, after having estimated separated coefficients,  the difference, 
>>>> if any, is statistically significant (using a chow test). 
>>>> Implementing such test is the major issue to me. Can you give me an
hint about this?
>>>
>>> Please see ch. 4 in Kleiber and Zeilis (2008) Applied Econometrics 
>>> with
> R.
>>> You may use anova() on the no-regime model and the regime model, 
>>> which is equivalent to a Chow test (personal communication, Achim 
>>> Zeileis,
>> 2005).
>>> It will however suffer from misspecification such as outliers, 
>>> discussed in section 4.3 and the use of a Wald test with an HC 
>>> covariance
>> matrix.
>>>
>>>> Thanks also for the suggestion about the interpretation of output 
>>>> in
> SDM.
>>>
>>> A "Chow" test might go through a Likelihood Ratio test, but should 
>>> arguably be presented using the empirical distributions of the 
>>> impacts for each X variable for the no-regime model and for each regime.
>>>
>>> Hope this helps,
>>>
>>> Roger
>>>
>>>> Best Regards
>>>> Loredana
>>>> -----Messaggio originale-----
>>>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>>> Inviato: gioved? 1 ottobre 2015 20:45
>>>> A: Loredana Mirra
>>>> Cc: r-sig-geo at r-project.org
>>>> Oggetto: Re: [R-sig-Geo] Spatial Durbin Model with regimes in a 
>>>> cross section framework
>>>>
>>>> On Thu, 1 Oct 2015, Loredana Mirra wrote:
>>>>
>>>>> I am writing to ask you a suggestion about the availability of a R 
>>>>> routine or piece of program for the purposes of my empirical analysis.
>>>>> I should revise my paper using a Spatial Durbin model. This was 
>>>>> recommended in order to mitigate a problem due to the possible 
>>>>> presence of
>>>> unobserved factors.
>>>>>
>>>>> Unfortunately data do not permit to perform a panel but a cross 
>>>>> section analysis. I do not have troubles to perform a Spatial 
>>>>> Durbin Model on the entire sample, but I need to study the 
>>>>> presence of Spatial Regimes. The problem is that I cannot find a 
>>>>> program, in a cross sections framework. Do you know if there is a 
>>>>> program available in R
>>>> to perform this analysis?
>>>>
>>>> How do you want to handle the "regimes"? Estimate separate 
>>>> coefficients for each regime (regime defined as a factor)? If so, 
>>>> this is a standard formula construction, and can be used with 
>>>> formula objects in model fitting
>>>> functions:
>>>>
>>>> lm(mpg ~ 0 + I(factor(am))/(disp + wt), data=mtcars)
>>>>
>>>> or similar - check in detailed discussions of formula objects.
>>>>
>>>> You need to be careful to report impacts, not coefficient values, 
>>>> from the Spatial Durbin model.
>>>>
>>>> Hope this helps,
>>>>
>>>> Roger
>>>>
>>>>> Thank you very much in advance for your help.
>>>>>
>>>>> Best regards
>>>>>
>>>>> Loredana Mirra
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> -------------------------
>>>>>
>>>>>
>>>>>
>>>>> Dott.ssa  Loredana Mirra
>>>>>
>>>>> Universit??? di Roma ???Tor Vergata???
>>>>>
>>>>> Dipartimento di Economia Diritto e Istituzioni
>>>>>
>>>>> Via Columbia, 2
>>>>>
>>>>> 00133 Roma
>>>>>
>>>>> Italia
>>>>>
>>>>> tel. +390672595725
>>>>>
>>>>> <mailto:pozzolo at unimol.it> loredana.mirra at uniroma2.it
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> ---
>>>>> Questa e-mail ??? stata controllata per individuare virus con 
>>>>> Avast
>>>> antivirus.
>>>>> https://www.avast.com/antivirus
>>>>>
>>>>> 	[[alternative HTML version deleted]]
>>>>>
>>>>>
>>>>
>>>> --
>>>> Roger Bivand
>>>> Department of Economics, Norwegian School of Economics, Helleveien 
>>>> 30,
>>>> N-5045 Bergen, Norway.
>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>> e-mail: Roger.Bivand at nhh.no
>>>>
>>>>
>>>> ---
>>>> Questa e-mail ? stata controllata per individuare virus con Avast
>>> antivirus.
>>>> https://www.avast.com/antivirus
>>>>
>>>>
>>>
>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics, Helleveien 
>>> 30,
>>> N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>> ---
>>> Questa e-mail ? stata controllata per individuare virus con Avast
>> antivirus.
>>> https://www.avast.com/antivirus
>>>
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics, Helleveien 
>> 30,
>> N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>> ---
>> Questa e-mail ? stata controllata per individuare virus con Avast
> antivirus.
>> https://www.avast.com/antivirus
>>
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics, Helleveien 30,
> N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
>
> ---
> Questa e-mail ? stata controllata per individuare virus con Avast
antivirus.
> https://www.avast.com/antivirus
>
>

--
Roger Bivand
Department of Economics, Norwegian School of Economics, Helleveien 30,
N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


---
Questa e-mail ? stata controllata per individuare virus con Avast antivirus.
https://www.avast.com/antivirus


From Roger.Bivand at nhh.no  Wed Oct 21 18:55:40 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 21 Oct 2015 18:55:40 +0200
Subject: [R-sig-Geo] R: R: R: R: Spatial Durbin Model with regimes in a
 cross section framework
In-Reply-To: <011401d10c14$ed9550c0$c8bff240$@uniroma2.it>
References: <002c01d0fcee$6641f900$32c5eb00$@uniroma2.it>
	<alpine.LFD.2.20.1510021049140.28317@reclus.nhh.no>
	<008601d10bed$b8058820$28109860$@uniroma2.it>
	<alpine.LFD.2.20.1510211315480.6127@reclus.nhh.no>
	<009f01d10bf8$c02a7d20$407f7760$@uniroma2.it>
	<alpine.LFD.2.20.1510211413380.6127@reclus.nhh.no>
	<00b501d10c02$54c80e80$fe582b80$@uniroma2.it>
	<alpine.LFD.2.20.1510211514340.6127@reclus.nhh.no>
	<011401d10c14$ed9550c0$c8bff240$@uniroma2.it>
Message-ID: <alpine.LFD.2.20.1510211854250.14214@reclus.nhh.no>

On Wed, 21 Oct 2015, Loredana Mirra wrote:

> I will try to install and use R and Spdep on another pc with another OS

A Windows binary of the development version is at:

http://win-builder.r-project.org/rIKm3X2H8hCW

which should work (install from local zip file after downloading) on 
Windows 10.

Roger


> Loredana
>
> -----Messaggio originale-----
> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Inviato: mercoled? 21 ottobre 2015 15:26
> A: Loredana Mirra
> Cc: r-sig-geo at r-project.org
> Oggetto: Re: R: R: R: [R-sig-Geo] Spatial Durbin Model with regimes in a
> cross section framework
>
> On Wed, 21 Oct 2015, Loredana Mirra wrote:
>
>> Thanks Roger,
>> At least you managed to have an output even if it contains some issues
>> which I could address changing variables.
>> Instead sorry but I am stuck. How can I get that?
>
> library(spdep)
> sessionInfo() # spdep >=0.5-88
> load("chow_error.RData")
> ONE <- rep(1, nrow(highways))
> NOC_Nord <- as.integer(!highways$C_Nord) durb<-lagsarlm(GR5101m~ 0+
> (ONE+LVAPC51):(C_Nord+NOC_Nord),
>  data=highways, listw, type="mixed")
> summary(durb)
>
> works for me (I'm using the development version of spdep, which seems to be
> the reason for the difference). There was an indexing error in
> create_WX() that is corrected in the development version but not in 0.5-88
> on CRAN. Which OS are you using - there are reasons for not releasing the
> development version yet?
>
> Roger
>
>> Loredana
>>
>>
>> -----Messaggio originale-----
>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>> Inviato: mercoled? 21 ottobre 2015 14:19
>> A: Loredana Mirra
>> Cc: r-sig-geo at r-project.org
>> Oggetto: Re: R: R: [R-sig-Geo] Spatial Durbin Model with regimes in a
>> cross section framework
>>
>> On Wed, 21 Oct 2015, Loredana Mirra wrote:
>>
>>> Here the traceback()
>>> 4: stop("0 (non-NA) cases")
>>> 3: lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...)
>>> 2: lm(y ~ x - 1)
>>> 1: lagsarlm(GR5101m ~ 0 + (ONE + LVAPC51):(C_Nord + NOC_Nord), data =
>>> highwaysreg,
>>>       listw, type = "mixed")
>>>
>>> No, problem. Data are not private. I tried to use the lmSLX and I got
>>> the same error
>>
>> OK, thanks. I cannot reproduce your error as such - I'm constructing:
>>
>> ONE <- rep(1, nrow(highways))
>> NOC_Nord <- as.integer(!highways$C_Nord)
>>
>> which may not be correct. I'm seeing:
>>
>> Warning message:
>> In lagsarlm(GR5101m ~ 0 + I(factor(C_Nord))/(LVAPC51), data = highways,  :
>>   inversion of asymptotic covariance matrix failed for tol.solve = 1e-10
>>   reciprocal condition number = 6.6223e-12 - using numerical Hessian.
>>
>> and an issue in an interaction term between the NOC_Nord term and the
>> intercept:
>>
>> Coefficients: (numerical Hessian approximate standard errors)
>>     (1 not defined because of singularities)
>>                        Estimate Std. Error  z value Pr(>|z|)
>> ONE:C_Nord            0.1385889  0.1310782   1.0573   0.2904
>> ONE:NOC_Nord          0.1493507  0.1322529   1.1293   0.2588
>> LVAPC51:C_Nord       -0.0170657  0.0010275 -16.6083   <2e-16
>> LVAPC51:NOC_Nord     -0.0192602  0.0018370 -10.4845   <2e-16
>> lag.ONE:C_Nord        0.0195317  0.1159969   0.1684   0.8663
>> lag.ONE:NOC_Nord             NA         NA       NA       NA
>> lag.LVAPC51:C_Nord   -0.0034108  0.0086611  -0.3938   0.6937
>> lag.LVAPC51:NOC_Nord -0.0032861  0.0223143  -0.1473   0.8829
>>
>> Rho: 0.57171, LR test value: 1.8528, p-value: 0.17346 Approximate
>> (numerical
>> Hessian) standard error: 0.34917
>>     z-value: 1.6374, p-value: 0.10156
>> Wald statistic: 2.6809, p-value: 0.10156
>>
>> Roger
>>
>>
>>> This is the link to the file with errors
>>> https://onedrive.live.com/redir?resid=4484D82DD190F118!2202&authkey=!
>>> A
>>> EXvKmB
>>> o2FVgrQI&ithint=file%2cRData
>>>
>>> Thank you
>>>
>>> Loredana
>>>
>>>
>>>
>>> -----Messaggio originale-----
>>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>> Inviato: mercoled? 21 ottobre 2015 13:26
>>> A: Loredana Mirra
>>> Cc: r-sig-geo at r-project.org
>>> Oggetto: Re: R: [R-sig-Geo] Spatial Durbin Model with regimes in a
>>> cross section framework
>>>
>>> On Wed, 21 Oct 2015, Loredana Mirra wrote:
>>>
>>>> Hi, and thank you again for your help. Following Anselin (2007)
>>>> Spatial regression analysis in R  I managed to test for the presence
>>>> of spatial regimes (also performing a Chow test) in R.
>>>>
>>>> Since, I need to apply a Spatial Durbin model, I tried fitting it
>>>> using the following (just adding the option "mixed") to the sar
>>>> command in the cases of regimes (Centre_North and South in my case):
>>>>
>>>> durb<-lagsarlm(GR5101m~ 0+ (ONE+
>>>> LVAPC51):(C_Nord+NOC_Nord),data=highways,listw, type="mixed")
>>>> summary(durb)
>>>>
>>>> I always get this error
>>>> error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
>>>>  0 (non-NA) cases
>>>
>>> Please provide the output of traceback() after the error has occurred.
>>> I think that if the same model can be fitted with type="lag", but not
>>> with "mixed", then the lagged X variables are possibly to blame.
>>>
>>> Maybe also try to use lmSLX() on the same formula, data and listw
>>> objects, to see whether you also see failures in the lagged X
>>> variables. The underlying create_WX() function does check for NAs,
>>> but may not do it correctly - possibly for this formula.
>>>
>>> If this sounds hard, do:
>>>
>>> save(highways, listw, file="chow_error.RData")
>>>
>>> and make the "chow_error.RData" file available on a link (possibly
>>> off-list if the data are private).
>>>
>>> Hope this helps,
>>>
>>> Roger
>>>
>>>>
>>>> I checked if there were NA cases and tried with other variables or
>>>> weight matrices. I wonder if this is a good approach or what is wrong.
>>>>
>>>> Thank you for your attention
>>>> Loredana Mirra
>>>>
>>>>
>>>>
>>>>
>>>> -----Messaggio originale-----
>>>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>>> Inviato: venerd? 2 ottobre 2015 10:59
>>>> A: Loredana Mirra
>>>> Cc: r-sig-geo at r-project.org
>>>> Oggetto: Re:[R-sig-Geo] Spatial Durbin Model with regimes in a cross
>>>> section framework
>>>>
>>>> On Fri, 2 Oct 2015, Loredana Mirra wrote:
>>>>
>>>>>
>>>>> Thank you very much for your kind help. Yes, I should check also
>>>>> if, after having estimated separated coefficients,  the difference,
>>>>> if any, is statistically significant (using a chow test).
>>>>> Implementing such test is the major issue to me. Can you give me an
> hint about this?
>>>>
>>>> Please see ch. 4 in Kleiber and Zeilis (2008) Applied Econometrics
>>>> with
>> R.
>>>> You may use anova() on the no-regime model and the regime model,
>>>> which is equivalent to a Chow test (personal communication, Achim
>>>> Zeileis,
>>> 2005).
>>>> It will however suffer from misspecification such as outliers,
>>>> discussed in section 4.3 and the use of a Wald test with an HC
>>>> covariance
>>> matrix.
>>>>
>>>>> Thanks also for the suggestion about the interpretation of output
>>>>> in
>> SDM.
>>>>
>>>> A "Chow" test might go through a Likelihood Ratio test, but should
>>>> arguably be presented using the empirical distributions of the
>>>> impacts for each X variable for the no-regime model and for each regime.
>>>>
>>>> Hope this helps,
>>>>
>>>> Roger
>>>>
>>>>> Best Regards
>>>>> Loredana
>>>>> -----Messaggio originale-----
>>>>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>>>> Inviato: gioved? 1 ottobre 2015 20:45
>>>>> A: Loredana Mirra
>>>>> Cc: r-sig-geo at r-project.org
>>>>> Oggetto: Re: [R-sig-Geo] Spatial Durbin Model with regimes in a
>>>>> cross section framework
>>>>>
>>>>> On Thu, 1 Oct 2015, Loredana Mirra wrote:
>>>>>
>>>>>> I am writing to ask you a suggestion about the availability of a R
>>>>>> routine or piece of program for the purposes of my empirical analysis.
>>>>>> I should revise my paper using a Spatial Durbin model. This was
>>>>>> recommended in order to mitigate a problem due to the possible
>>>>>> presence of
>>>>> unobserved factors.
>>>>>>
>>>>>> Unfortunately data do not permit to perform a panel but a cross
>>>>>> section analysis. I do not have troubles to perform a Spatial
>>>>>> Durbin Model on the entire sample, but I need to study the
>>>>>> presence of Spatial Regimes. The problem is that I cannot find a
>>>>>> program, in a cross sections framework. Do you know if there is a
>>>>>> program available in R
>>>>> to perform this analysis?
>>>>>
>>>>> How do you want to handle the "regimes"? Estimate separate
>>>>> coefficients for each regime (regime defined as a factor)? If so,
>>>>> this is a standard formula construction, and can be used with
>>>>> formula objects in model fitting
>>>>> functions:
>>>>>
>>>>> lm(mpg ~ 0 + I(factor(am))/(disp + wt), data=mtcars)
>>>>>
>>>>> or similar - check in detailed discussions of formula objects.
>>>>>
>>>>> You need to be careful to report impacts, not coefficient values,
>>>>> from the Spatial Durbin model.
>>>>>
>>>>> Hope this helps,
>>>>>
>>>>> Roger
>>>>>
>>>>>> Thank you very much in advance for your help.
>>>>>>
>>>>>> Best regards
>>>>>>
>>>>>> Loredana Mirra
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> -------------------------
>>>>>>
>>>>>>
>>>>>>
>>>>>> Dott.ssa  Loredana Mirra
>>>>>>
>>>>>> Universit??? di Roma ???Tor Vergata???
>>>>>>
>>>>>> Dipartimento di Economia Diritto e Istituzioni
>>>>>>
>>>>>> Via Columbia, 2
>>>>>>
>>>>>> 00133 Roma
>>>>>>
>>>>>> Italia
>>>>>>
>>>>>> tel. +390672595725
>>>>>>
>>>>>> <mailto:pozzolo at unimol.it> loredana.mirra at uniroma2.it
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> ---
>>>>>> Questa e-mail ??? stata controllata per individuare virus con
>>>>>> Avast
>>>>> antivirus.
>>>>>> https://www.avast.com/antivirus
>>>>>>
>>>>>> 	[[alternative HTML version deleted]]
>>>>>>
>>>>>>
>>>>>
>>>>> --
>>>>> Roger Bivand
>>>>> Department of Economics, Norwegian School of Economics, Helleveien
>>>>> 30,
>>>>> N-5045 Bergen, Norway.
>>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>
>>>>>
>>>>> ---
>>>>> Questa e-mail ? stata controllata per individuare virus con Avast
>>>> antivirus.
>>>>> https://www.avast.com/antivirus
>>>>>
>>>>>
>>>>
>>>> --
>>>> Roger Bivand
>>>> Department of Economics, Norwegian School of Economics, Helleveien
>>>> 30,
>>>> N-5045 Bergen, Norway.
>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>> e-mail: Roger.Bivand at nhh.no
>>>>
>>>>
>>>> ---
>>>> Questa e-mail ? stata controllata per individuare virus con Avast
>>> antivirus.
>>>> https://www.avast.com/antivirus
>>>>
>>>>
>>>
>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics, Helleveien
>>> 30,
>>> N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>> ---
>>> Questa e-mail ? stata controllata per individuare virus con Avast
>> antivirus.
>>> https://www.avast.com/antivirus
>>>
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics, Helleveien 30,
>> N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>> ---
>> Questa e-mail ? stata controllata per individuare virus con Avast
> antivirus.
>> https://www.avast.com/antivirus
>>
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics, Helleveien 30,
> N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
>
> ---
> Questa e-mail ? stata controllata per individuare virus con Avast antivirus.
> https://www.avast.com/antivirus
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From loredana.mirra at uniroma2.it  Wed Oct 21 19:35:23 2015
From: loredana.mirra at uniroma2.it (Loredana Mirra)
Date: Wed, 21 Oct 2015 19:35:23 +0200
Subject: [R-sig-Geo] R: R: R: R: R: Spatial Durbin Model with regimes in a
	cross section framework
In-Reply-To: <alpine.LFD.2.20.1510211854250.14214@reclus.nhh.no>
References: <002c01d0fcee$6641f900$32c5eb00$@uniroma2.it>
	<alpine.LFD.2.20.1510021049140.28317@reclus.nhh.no>
	<008601d10bed$b8058820$28109860$@uniroma2.it>
	<alpine.LFD.2.20.1510211315480.6127@reclus.nhh.no>
	<009f01d10bf8$c02a7d20$407f7760$@uniroma2.it>
	<alpine.LFD.2.20.1510211413380.6127@reclus.nhh.no>
	<00b501d10c02$54c80e80$fe582b80$@uniroma2.it>
	<alpine.LFD.2.20.1510211514340.6127@reclus.nhh.no>
	<011401d10c14$ed9550c0$c8bff240$@uniroma2.it>
	<alpine.LFD.2.20.1510211854250.14214@reclus.nhh.no>
Message-ID: <012701d10c26$ddcd39c0$9967ad40$@uniroma2.it>

Thank you so much! Now is working. Now I have to address the issues due to
the choice of variables or matrices. 
I am very grateful to you! You helped a lot.
Thanks again
Loredana

-----Messaggio originale-----
Da: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Inviato: mercoled? 21 ottobre 2015 18:56
A: Loredana Mirra
Cc: r-sig-geo at r-project.org
Oggetto: Re: R: R: R: R: [R-sig-Geo] Spatial Durbin Model with regimes in a
cross section framework

On Wed, 21 Oct 2015, Loredana Mirra wrote:

> I will try to install and use R and Spdep on another pc with another 
> OS

A Windows binary of the development version is at:

http://win-builder.r-project.org/rIKm3X2H8hCW

which should work (install from local zip file after downloading) on Windows
10.

Roger


> Loredana
>
> -----Messaggio originale-----
> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Inviato: mercoled? 21 ottobre 2015 15:26
> A: Loredana Mirra
> Cc: r-sig-geo at r-project.org
> Oggetto: Re: R: R: R: [R-sig-Geo] Spatial Durbin Model with regimes in 
> a cross section framework
>
> On Wed, 21 Oct 2015, Loredana Mirra wrote:
>
>> Thanks Roger,
>> At least you managed to have an output even if it contains some 
>> issues which I could address changing variables.
>> Instead sorry but I am stuck. How can I get that?
>
> library(spdep)
> sessionInfo() # spdep >=0.5-88
> load("chow_error.RData")
> ONE <- rep(1, nrow(highways))
> NOC_Nord <- as.integer(!highways$C_Nord) durb<-lagsarlm(GR5101m~ 0+ 
> (ONE+LVAPC51):(C_Nord+NOC_Nord),  data=highways, listw, type="mixed")
> summary(durb)
>
> works for me (I'm using the development version of spdep, which seems 
> to be the reason for the difference). There was an indexing error in
> create_WX() that is corrected in the development version but not in 
> 0.5-88 on CRAN. Which OS are you using - there are reasons for not 
> releasing the development version yet?
>
> Roger
>
>> Loredana
>>
>>
>> -----Messaggio originale-----
>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>> Inviato: mercoled? 21 ottobre 2015 14:19
>> A: Loredana Mirra
>> Cc: r-sig-geo at r-project.org
>> Oggetto: Re: R: R: [R-sig-Geo] Spatial Durbin Model with regimes in a 
>> cross section framework
>>
>> On Wed, 21 Oct 2015, Loredana Mirra wrote:
>>
>>> Here the traceback()
>>> 4: stop("0 (non-NA) cases")
>>> 3: lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...)
>>> 2: lm(y ~ x - 1)
>>> 1: lagsarlm(GR5101m ~ 0 + (ONE + LVAPC51):(C_Nord + NOC_Nord), data 
>>> = highwaysreg,
>>>       listw, type = "mixed")
>>>
>>> No, problem. Data are not private. I tried to use the lmSLX and I 
>>> got the same error
>>
>> OK, thanks. I cannot reproduce your error as such - I'm constructing:
>>
>> ONE <- rep(1, nrow(highways))
>> NOC_Nord <- as.integer(!highways$C_Nord)
>>
>> which may not be correct. I'm seeing:
>>
>> Warning message:
>> In lagsarlm(GR5101m ~ 0 + I(factor(C_Nord))/(LVAPC51), data = highways,
:
>>   inversion of asymptotic covariance matrix failed for tol.solve = 1e-10
>>   reciprocal condition number = 6.6223e-12 - using numerical Hessian.
>>
>> and an issue in an interaction term between the NOC_Nord term and the
>> intercept:
>>
>> Coefficients: (numerical Hessian approximate standard errors)
>>     (1 not defined because of singularities)
>>                        Estimate Std. Error  z value Pr(>|z|)
>> ONE:C_Nord            0.1385889  0.1310782   1.0573   0.2904
>> ONE:NOC_Nord          0.1493507  0.1322529   1.1293   0.2588
>> LVAPC51:C_Nord       -0.0170657  0.0010275 -16.6083   <2e-16
>> LVAPC51:NOC_Nord     -0.0192602  0.0018370 -10.4845   <2e-16
>> lag.ONE:C_Nord        0.0195317  0.1159969   0.1684   0.8663
>> lag.ONE:NOC_Nord             NA         NA       NA       NA
>> lag.LVAPC51:C_Nord   -0.0034108  0.0086611  -0.3938   0.6937
>> lag.LVAPC51:NOC_Nord -0.0032861  0.0223143  -0.1473   0.8829
>>
>> Rho: 0.57171, LR test value: 1.8528, p-value: 0.17346 Approximate 
>> (numerical
>> Hessian) standard error: 0.34917
>>     z-value: 1.6374, p-value: 0.10156 Wald statistic: 2.6809, 
>> p-value: 0.10156
>>
>> Roger
>>
>>
>>> This is the link to the file with errors 
>>> https://onedrive.live.com/redir?resid=4484D82DD190F118!2202&authkey=!
>>> A
>>> EXvKmB
>>> o2FVgrQI&ithint=file%2cRData
>>>
>>> Thank you
>>>
>>> Loredana
>>>
>>>
>>>
>>> -----Messaggio originale-----
>>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>> Inviato: mercoled? 21 ottobre 2015 13:26
>>> A: Loredana Mirra
>>> Cc: r-sig-geo at r-project.org
>>> Oggetto: Re: R: [R-sig-Geo] Spatial Durbin Model with regimes in a 
>>> cross section framework
>>>
>>> On Wed, 21 Oct 2015, Loredana Mirra wrote:
>>>
>>>> Hi, and thank you again for your help. Following Anselin (2007) 
>>>> Spatial regression analysis in R  I managed to test for the 
>>>> presence of spatial regimes (also performing a Chow test) in R.
>>>>
>>>> Since, I need to apply a Spatial Durbin model, I tried fitting it 
>>>> using the following (just adding the option "mixed") to the sar 
>>>> command in the cases of regimes (Centre_North and South in my case):
>>>>
>>>> durb<-lagsarlm(GR5101m~ 0+ (ONE+
>>>> LVAPC51):(C_Nord+NOC_Nord),data=highways,listw, type="mixed")
>>>> summary(durb)
>>>>
>>>> I always get this error
>>>> error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...)
:
>>>>  0 (non-NA) cases
>>>
>>> Please provide the output of traceback() after the error has occurred.
>>> I think that if the same model can be fitted with type="lag", but 
>>> not with "mixed", then the lagged X variables are possibly to blame.
>>>
>>> Maybe also try to use lmSLX() on the same formula, data and listw 
>>> objects, to see whether you also see failures in the lagged X 
>>> variables. The underlying create_WX() function does check for NAs, 
>>> but may not do it correctly - possibly for this formula.
>>>
>>> If this sounds hard, do:
>>>
>>> save(highways, listw, file="chow_error.RData")
>>>
>>> and make the "chow_error.RData" file available on a link (possibly 
>>> off-list if the data are private).
>>>
>>> Hope this helps,
>>>
>>> Roger
>>>
>>>>
>>>> I checked if there were NA cases and tried with other variables or 
>>>> weight matrices. I wonder if this is a good approach or what is wrong.
>>>>
>>>> Thank you for your attention
>>>> Loredana Mirra
>>>>
>>>>
>>>>
>>>>
>>>> -----Messaggio originale-----
>>>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>>> Inviato: venerd? 2 ottobre 2015 10:59
>>>> A: Loredana Mirra
>>>> Cc: r-sig-geo at r-project.org
>>>> Oggetto: Re:[R-sig-Geo] Spatial Durbin Model with regimes in a 
>>>> cross section framework
>>>>
>>>> On Fri, 2 Oct 2015, Loredana Mirra wrote:
>>>>
>>>>>
>>>>> Thank you very much for your kind help. Yes, I should check also 
>>>>> if, after having estimated separated coefficients,  the 
>>>>> difference, if any, is statistically significant (using a chow test).
>>>>> Implementing such test is the major issue to me. Can you give me 
>>>>> an
> hint about this?
>>>>
>>>> Please see ch. 4 in Kleiber and Zeilis (2008) Applied Econometrics 
>>>> with
>> R.
>>>> You may use anova() on the no-regime model and the regime model, 
>>>> which is equivalent to a Chow test (personal communication, Achim 
>>>> Zeileis,
>>> 2005).
>>>> It will however suffer from misspecification such as outliers, 
>>>> discussed in section 4.3 and the use of a Wald test with an HC 
>>>> covariance
>>> matrix.
>>>>
>>>>> Thanks also for the suggestion about the interpretation of output 
>>>>> in
>> SDM.
>>>>
>>>> A "Chow" test might go through a Likelihood Ratio test, but should 
>>>> arguably be presented using the empirical distributions of the 
>>>> impacts for each X variable for the no-regime model and for each
regime.
>>>>
>>>> Hope this helps,
>>>>
>>>> Roger
>>>>
>>>>> Best Regards
>>>>> Loredana
>>>>> -----Messaggio originale-----
>>>>> Da: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>>>> Inviato: gioved? 1 ottobre 2015 20:45
>>>>> A: Loredana Mirra
>>>>> Cc: r-sig-geo at r-project.org
>>>>> Oggetto: Re: [R-sig-Geo] Spatial Durbin Model with regimes in a 
>>>>> cross section framework
>>>>>
>>>>> On Thu, 1 Oct 2015, Loredana Mirra wrote:
>>>>>
>>>>>> I am writing to ask you a suggestion about the availability of a 
>>>>>> R routine or piece of program for the purposes of my empirical
analysis.
>>>>>> I should revise my paper using a Spatial Durbin model. This was 
>>>>>> recommended in order to mitigate a problem due to the possible 
>>>>>> presence of
>>>>> unobserved factors.
>>>>>>
>>>>>> Unfortunately data do not permit to perform a panel but a cross 
>>>>>> section analysis. I do not have troubles to perform a Spatial 
>>>>>> Durbin Model on the entire sample, but I need to study the 
>>>>>> presence of Spatial Regimes. The problem is that I cannot find a 
>>>>>> program, in a cross sections framework. Do you know if there is a 
>>>>>> program available in R
>>>>> to perform this analysis?
>>>>>
>>>>> How do you want to handle the "regimes"? Estimate separate 
>>>>> coefficients for each regime (regime defined as a factor)? If so, 
>>>>> this is a standard formula construction, and can be used with 
>>>>> formula objects in model fitting
>>>>> functions:
>>>>>
>>>>> lm(mpg ~ 0 + I(factor(am))/(disp + wt), data=mtcars)
>>>>>
>>>>> or similar - check in detailed discussions of formula objects.
>>>>>
>>>>> You need to be careful to report impacts, not coefficient values, 
>>>>> from the Spatial Durbin model.
>>>>>
>>>>> Hope this helps,
>>>>>
>>>>> Roger
>>>>>
>>>>>> Thank you very much in advance for your help.
>>>>>>
>>>>>> Best regards
>>>>>>
>>>>>> Loredana Mirra
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> -------------------------
>>>>>>
>>>>>>
>>>>>>
>>>>>> Dott.ssa  Loredana Mirra
>>>>>>
>>>>>> Universit??? di Roma ???Tor Vergata???
>>>>>>
>>>>>> Dipartimento di Economia Diritto e Istituzioni
>>>>>>
>>>>>> Via Columbia, 2
>>>>>>
>>>>>> 00133 Roma
>>>>>>
>>>>>> Italia
>>>>>>
>>>>>> tel. +390672595725
>>>>>>
>>>>>> <mailto:pozzolo at unimol.it> loredana.mirra at uniroma2.it
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> ---
>>>>>> Questa e-mail ??? stata controllata per individuare virus con 
>>>>>> Avast
>>>>> antivirus.
>>>>>> https://www.avast.com/antivirus
>>>>>>
>>>>>> 	[[alternative HTML version deleted]]
>>>>>>
>>>>>>
>>>>>
>>>>> --
>>>>> Roger Bivand
>>>>> Department of Economics, Norwegian School of Economics, Helleveien 
>>>>> 30,
>>>>> N-5045 Bergen, Norway.
>>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>
>>>>>
>>>>> ---
>>>>> Questa e-mail ? stata controllata per individuare virus con Avast
>>>> antivirus.
>>>>> https://www.avast.com/antivirus
>>>>>
>>>>>
>>>>
>>>> --
>>>> Roger Bivand
>>>> Department of Economics, Norwegian School of Economics, Helleveien 
>>>> 30,
>>>> N-5045 Bergen, Norway.
>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>> e-mail: Roger.Bivand at nhh.no
>>>>
>>>>
>>>> ---
>>>> Questa e-mail ? stata controllata per individuare virus con Avast
>>> antivirus.
>>>> https://www.avast.com/antivirus
>>>>
>>>>
>>>
>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics, Helleveien 
>>> 30,
>>> N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>> ---
>>> Questa e-mail ? stata controllata per individuare virus con Avast
>> antivirus.
>>> https://www.avast.com/antivirus
>>>
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics, Helleveien 
>> 30,
>> N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>> ---
>> Questa e-mail ? stata controllata per individuare virus con Avast
> antivirus.
>> https://www.avast.com/antivirus
>>
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics, Helleveien 30,
> N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
>
> ---
> Questa e-mail ? stata controllata per individuare virus con Avast
antivirus.
> https://www.avast.com/antivirus
>
>

--
Roger Bivand
Department of Economics, Norwegian School of Economics, Helleveien 30,
N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


---
Questa e-mail ? stata controllata per individuare virus con Avast antivirus.
https://www.avast.com/antivirus


From andy.teucher at gmail.com  Thu Oct 22 00:39:39 2015
From: andy.teucher at gmail.com (Andy Teucher)
Date: Wed, 21 Oct 2015 15:39:39 -0700
Subject: [R-sig-Geo] Exporting Multipolygon geojson with rgdal::writeOGR
Message-ID: <CAOdCUxMcO0spZhMbegjU-U2o6VOGfR0QgnCcF6YjfTfMJCoUpg@mail.gmail.com>

I?m finding that writeOGR isn?t exporting multipolygons properly using
the GeoJSON driver. I have a simple test case (borrowed from here:
http://gis.stackexchange.com/questions/137977/writeogr-alters-multipolygon-holes)
with a geojson string with one multipolygon containing two polygons. I
use readOGR to create a SpatialPolygonsDataFrame out of it, then write
it with writeOGR:

library(rgdal)

js <- '{
"type": "MultiPolygon",
"coordinates": [[[[102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0, 3.0],
[102.0, 2.0]]], [[[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0],
[100.0, 0.0]]]]
} '

spdf <- readOGR(js, layer='OGRGeoJSON', verbose=FALSE) # Create a
SpatialPoygonsDataFrame

temp <- tempfile()
writeOGR(spdf, dsn = temp, layer = "", driver="GeoJSON")
cat(readLines(temp))

# Output:
{ "type": "FeatureCollection", "crs": { "type": "name", "properties":
{ "name": "urn:ogc:def:crs:OGC:1.3:CRS84" } }, "features": [ { "type":
"Feature", "id": 0, "properties": { "FID": 0 }, "geometry": { "type":
"MultiPolygon", "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ], [
103.0, 3.0 ], [ 103.0, 2.0 ], [ 102.0, 2.0 ] ], [ [ 100.0, 0.0 ], [
100.0, 1.0 ], [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] } }
] }

If you look closely at the output, you can see that the 'coordinates'
array now contains a single polygon array with two coordinate arrays:
the boundary, and a second one which is now treated as a hole of the
first (orphaned as it is outside the bounds of the polygon). The
original 'coordinates' array consists of two polygon arrays, each
consisting of a single coordinate array which defining a polygon (with
no holes), which is correct according the GeoJSON spec:
http://geojson.org/geojson-spec.html#polygon.

I'm always hesitant to call things a bug, but this doesn't appear to
happen using ogr2ogr on the command line:

writeOGR(spdf, ".", "test", driver = "ESRI Shapefile") # Write a
shapefile to convert using ogr2ogr
system("ogr2ogr -f GeoJSON test_from_shp.geojson test.shp")
cat(readLines("test_from_shp.geojson"))

# Output:
{ "type": "FeatureCollection",  "features": [ { "type": "Feature",
"properties": { "FID": 0 }, "geometry": { "type": "MultiPolygon",
"coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ], [ 103.0, 3.0 ], [
103.0, 2.0 ], [ 102.0, 2.0 ] ] ], [ [ [ 100.0, 0.0 ], [ 100.0, 1.0 ],
[ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] } } ] }

The resulting output is correct.


Thanks in advance for any help on this.

Andy


From Roger.Bivand at nhh.no  Thu Oct 22 09:27:13 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 22 Oct 2015 09:27:13 +0200
Subject: [R-sig-Geo] Exporting Multipolygon geojson with rgdal::writeOGR
In-Reply-To: <CAOdCUxMcO0spZhMbegjU-U2o6VOGfR0QgnCcF6YjfTfMJCoUpg@mail.gmail.com>
References: <CAOdCUxMcO0spZhMbegjU-U2o6VOGfR0QgnCcF6YjfTfMJCoUpg@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1510220915310.21713@reclus.nhh.no>

On Thu, 22 Oct 2015, Andy Teucher wrote:

> I?m finding that writeOGR isn?t exporting multipolygons properly using
> the GeoJSON driver. I have a simple test case (borrowed from here:
> http://gis.stackexchange.com/questions/137977/writeogr-alters-multipolygon-holes)
> with a geojson string with one multipolygon containing two polygons. I
> use readOGR to create a SpatialPolygonsDataFrame out of it, then write
> it with writeOGR:
>
> library(rgdal)
>
> js <- '{
> "type": "MultiPolygon",
> "coordinates": [[[[102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0, 3.0],
> [102.0, 2.0]]], [[[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0],
> [100.0, 0.0]]]]
> } '
>
> spdf <- readOGR(js, layer='OGRGeoJSON', verbose=FALSE) # Create a
> SpatialPoygonsDataFrame
>
> temp <- tempfile()
> writeOGR(spdf, dsn = temp, layer = "", driver="GeoJSON")
> cat(readLines(temp))
>
> # Output:
> { "type": "FeatureCollection", "crs": { "type": "name", "properties":
> { "name": "urn:ogc:def:crs:OGC:1.3:CRS84" } }, "features": [ { "type":
> "Feature", "id": 0, "properties": { "FID": 0 }, "geometry": { "type":
> "MultiPolygon", "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ], [
> 103.0, 3.0 ], [ 103.0, 2.0 ], [ 102.0, 2.0 ] ], [ [ 100.0, 0.0 ], [
> 100.0, 1.0 ], [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] } }
> ] }

I can replicate this with GDAL 2.0.1 and rgdal 1.0-7 - reading temp in 
gives the orphaned hole. I'm surprised that passing the js object to 
readOGR() doesn't fail, but that isn't the source of the problem. spdf 
appears to be structured correctly. Please provide your GDAL and rgdal 
versions, and OS details from sessionInfo().

We are completely relying on the GDAL drivers here - we can't cherry pick 
for particular drivers (historically excepting ESRI Shapefile), so your 
debugging will need to examine writeOGR(), the C code it calls, and the 
interactions between the rgdal C code and called OGR functions. Please 
check which other drivers are affected (I think KML is, is GML?). Can you 
place debugging Rprintf(...); in the rgdal C code to see where this is 
coming from?

I can start looking at this sometime next week, so please make a start 
yourself; contributions from others are very welcome.

Roger

>
> If you look closely at the output, you can see that the 'coordinates'
> array now contains a single polygon array with two coordinate arrays:
> the boundary, and a second one which is now treated as a hole of the
> first (orphaned as it is outside the bounds of the polygon). The
> original 'coordinates' array consists of two polygon arrays, each
> consisting of a single coordinate array which defining a polygon (with
> no holes), which is correct according the GeoJSON spec:
> http://geojson.org/geojson-spec.html#polygon.
>
> I'm always hesitant to call things a bug, but this doesn't appear to
> happen using ogr2ogr on the command line:
>
> writeOGR(spdf, ".", "test", driver = "ESRI Shapefile") # Write a
> shapefile to convert using ogr2ogr
> system("ogr2ogr -f GeoJSON test_from_shp.geojson test.shp")
> cat(readLines("test_from_shp.geojson"))
>
> # Output:
> { "type": "FeatureCollection",  "features": [ { "type": "Feature",
> "properties": { "FID": 0 }, "geometry": { "type": "MultiPolygon",
> "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ], [ 103.0, 3.0 ], [
> 103.0, 2.0 ], [ 102.0, 2.0 ] ] ], [ [ [ 100.0, 0.0 ], [ 100.0, 1.0 ],
> [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] } } ] }
>
> The resulting output is correct.
>
>
> Thanks in advance for any help on this.
>
> Andy
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From dafne.berg at gmail.com  Thu Oct 22 10:19:54 2015
From: dafne.berg at gmail.com (Dafne Berg)
Date: Thu, 22 Oct 2015 09:19:54 +0100
Subject: [R-sig-Geo] indicator kriging with R
Message-ID: <CAGinAQQYtPnDvRa6AprWYGoH+cQ04rr7Z_Bp6puti66kekfO8A@mail.gmail.com>

Dear list,
I am trying to do a indicator kriging of a continuous variable. I am
especially interested in performing the "order relation correction". In the
documentation of "predict" in gstat it is mentioned as debug level 64
(order relation violations (indicator kriging values before and after order
relation correction).

However, when running predict I can only get the values in the range 0 to
1, as expected for indicator kriging.

I am probably missing something very basic here, but I will be grateful for
any pointers in the right direction

Thank you very much in advance

Best wishes

Dafne

	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Thu Oct 22 10:38:26 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 22 Oct 2015 10:38:26 +0200
Subject: [R-sig-Geo] indicator kriging with R
In-Reply-To: <CAGinAQQYtPnDvRa6AprWYGoH+cQ04rr7Z_Bp6puti66kekfO8A@mail.gmail.com>
References: <CAGinAQQYtPnDvRa6AprWYGoH+cQ04rr7Z_Bp6puti66kekfO8A@mail.gmail.com>
Message-ID: <5628A082.1020902@uni-muenster.de>

Yes, this is what indicator kriging does.

What you want is probably going back from the [0..1] estimated
probabilities to the original Z values. Gstat doesn't help here, but it
shouldn't be too hard to write a function for this. You need to make
assumptions about the distribution between different cutoff values, in
particular about both extreme (open) classes. I think the GSLIB and
Goovaerts books would be the first ones to look into.

On 22/10/15 10:19, Dafne Berg wrote:
> Dear list,
> I am trying to do a indicator kriging of a continuous variable. I am
> especially interested in performing the "order relation correction". In the
> documentation of "predict" in gstat it is mentioned as debug level 64
> (order relation violations (indicator kriging values before and after order
> relation correction).
> 
> However, when running predict I can only get the values in the range 0 to
> 1, as expected for indicator kriging.
> 
> I am probably missing something very basic here, but I will be grateful for
> any pointers in the right direction
> 
> Thank you very much in advance
> 
> Best wishes
> 
> Dafne
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151022/bb0c5089/attachment.bin>

From dafne.berg at gmail.com  Thu Oct 22 11:12:24 2015
From: dafne.berg at gmail.com (Dafne Berg)
Date: Thu, 22 Oct 2015 10:12:24 +0100
Subject: [R-sig-Geo] indicator kriging with R
In-Reply-To: <5628A082.1020902@uni-muenster.de>
References: <CAGinAQQYtPnDvRa6AprWYGoH+cQ04rr7Z_Bp6puti66kekfO8A@mail.gmail.com>
	<5628A082.1020902@uni-muenster.de>
Message-ID: <CAGinAQTCHhEO+z6c7P_dhU79d3_pxZBFVtzh0Nedf0mjKF5E8w@mail.gmail.com>

Dear Edzer,
yes it is exactly what I meant. Thanks for the confirmation that it is not
yet implemented in gstat. I will have a look to gslib and the book.

Thanks a lot

Dafne

On 22 October 2015 at 09:38, Edzer Pebesma <edzer.pebesma at uni-muenster.de>
wrote:

> Yes, this is what indicator kriging does.
>
> What you want is probably going back from the [0..1] estimated
> probabilities to the original Z values. Gstat doesn't help here, but it
> shouldn't be too hard to write a function for this. You need to make
> assumptions about the distribution between different cutoff values, in
> particular about both extreme (open) classes. I think the GSLIB and
> Goovaerts books would be the first ones to look into.
>
> On 22/10/15 10:19, Dafne Berg wrote:
> > Dear list,
> > I am trying to do a indicator kriging of a continuous variable. I am
> > especially interested in performing the "order relation correction". In
> the
> > documentation of "predict" in gstat it is mentioned as debug level 64
> > (order relation violations (indicator kriging values before and after
> order
> > relation correction).
> >
> > However, when running predict I can only get the values in the range 0 to
> > 1, as expected for indicator kriging.
> >
> > I am probably missing something very basic here, but I will be grateful
> for
> > any pointers in the right direction
> >
> > Thank you very much in advance
> >
> > Best wishes
> >
> > Dafne
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi),  University of M?nster,
> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> Journal of Statistical Software:   http://www.jstatsoft.org/
> Computers & Geosciences:   http://elsevier.com/locate/cageo/
> Spatial Statistics Society http://www.spatialstatistics.info
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From paul.harris at rothamsted.ac.uk  Thu Oct 22 11:32:45 2015
From: paul.harris at rothamsted.ac.uk (Paul Harris)
Date: Thu, 22 Oct 2015 09:32:45 +0000
Subject: [R-sig-Geo] indicator kriging with R
In-Reply-To: <c861f849-5895-4716-9e53-c5f8e27976d6@ROTHEX2.rothamsted.ac.uk>
References: <CAGinAQQYtPnDvRa6AprWYGoH+cQ04rr7Z_Bp6puti66kekfO8A@mail.gmail.com>
	<5628A082.1020902@uni-muenster.de>
	<c861f849-5895-4716-9e53-c5f8e27976d6@ROTHEX2.rothamsted.ac.uk>
Message-ID: <3995581109E58043A20A2418E7CAB3EE2F9BEEC0@nwex2.rothamsted.ac.uk>

Hi Dafne
If you going to look at GSLIB (with its FORTRAN code), then this is also useful:
Goovaerts P (2009) AUTO-IK: A 2D indicator kriging program for the automated non-parametric modeling of local uncertainty in earth sciences. Comput Geosci 35:1255-1270
Cheers Paul

-----Original Message-----
From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Dafne Berg
Sent: 22 October 2015 10:12
To: Edzer Pebesma
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] indicator kriging with R

Dear Edzer,
yes it is exactly what I meant. Thanks for the confirmation that it is not yet implemented in gstat. I will have a look to gslib and the book.

Thanks a lot

Dafne

On 22 October 2015 at 09:38, Edzer Pebesma <edzer.pebesma at uni-muenster.de>
wrote:

> Yes, this is what indicator kriging does.
>
> What you want is probably going back from the [0..1] estimated
> probabilities to the original Z values. Gstat doesn't help here, but
> it shouldn't be too hard to write a function for this. You need to
> make assumptions about the distribution between different cutoff
> values, in particular about both extreme (open) classes. I think the
> GSLIB and Goovaerts books would be the first ones to look into.
>
> On 22/10/15 10:19, Dafne Berg wrote:
> > Dear list,
> > I am trying to do a indicator kriging of a continuous variable. I am
> > especially interested in performing the "order relation correction".
> > In
> the
> > documentation of "predict" in gstat it is mentioned as debug level
> > 64 (order relation violations (indicator kriging values before and
> > after
> order
> > relation correction).
> >
> > However, when running predict I can only get the values in the range
> > 0 to 1, as expected for indicator kriging.
> >
> > I am probably missing something very basic here, but I will be
> > grateful
> for
> > any pointers in the right direction
> >
> > Thank you very much in advance
> >
> > Best wishes
> >
> > Dafne
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi),  University of M?nster,
> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> Journal of Statistical Software:   http://www.jstatsoft.org/
> Computers & Geosciences:   http://elsevier.com/locate/cageo/
> Spatial Statistics Society http://www.spatialstatistics.info
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


Rothamsted Research is a company limited by guarantee, registered in England at Harpenden, Hertfordshire, AL5 2JQ under the registration number 2393175 and a not for profit charity number 802038.



From tkeitt at utexas.edu  Wed Oct 21 17:21:37 2015
From: tkeitt at utexas.edu (Tim Keitt)
Date: Wed, 21 Oct 2015 10:21:37 -0500
Subject: [R-sig-Geo] New package for thematic cartography: cartography
In-Reply-To: <5626538E.8070800@ums-riate.fr>
References: <5626538E.8070800@ums-riate.fr>
Message-ID: <CANnL8grt4VJ4Jx4OST1X-6c8vD4c5X2ki9M5tTRx1dx8asuA5w@mail.gmail.com>

Looks great. Very useful.

THK

http://www.keittlab.org/

On Tue, Oct 20, 2015 at 9:45 AM, Timothee Giraud <
timothee.giraud at ums-riate.fr> wrote:

> Dear members of the list,
>
> We just wanted to bring your attention to our new package on CRAN:
> cartography.
>
> This package allows various cartographic representations: proportional
> symbols, chroropleth, typology, flows, discontinuities...
> It also proposes some additional useful features: cartographic palettes,
> layout (scale, north arrow, title...), labels, legends, access to
> cartographic API...
>
> Note that the vignette of the package contains commented scripts on how to
> build various types of maps.
>
> The development version is on GitHub:
> https://github.com/Groupe-ElementR/cartography .
>
> And of course feedbacks on the package are more than welcome!
>
> Best regards,
> Timoth?e
>
>
> --
> Timoth?e Giraud
> Databases & Geomatics
> http://rgeomatic.hypotheses.org/
> http://ums-riate.fr/
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From andy.teucher at gmail.com  Thu Oct 22 19:36:51 2015
From: andy.teucher at gmail.com (Andy Teucher)
Date: Thu, 22 Oct 2015 10:36:51 -0700
Subject: [R-sig-Geo] Exporting Multipolygon geojson with rgdal::writeOGR
In-Reply-To: <alpine.LFD.2.20.1510220915310.21713@reclus.nhh.no>
References: <CAOdCUxMcO0spZhMbegjU-U2o6VOGfR0QgnCcF6YjfTfMJCoUpg@mail.gmail.com>
	<alpine.LFD.2.20.1510220915310.21713@reclus.nhh.no>
Message-ID: <CAOdCUxPaFGG4Ld69bsYw9_SVG4++OkJc3VKh-1tr93NP+NZoYA@mail.gmail.com>

Thanks very much Roger.

I've replicated this on my work machine (Windows) and on my Mac at home.

KML and GML are both affected. ESRI shapefile works fine and, though
I'm not very familiar with the format, 'MapInfo File' works too
(loading the file in qgis shows a multipart polygon with no geometry
errors).

sessionInfo() for my Windows machine (using rgdal 1.0-7 with included
gdal drivers):

R version 3.2.2 (2015-08-14)
Platform: i386-w64-mingw32/i386 (32-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
LC_MONETARY=English_Canada.1252
[4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] rgdal_1.0-7 sp_1.2-0

loaded via a namespace (and not attached):
[1] tools_3.2.2     grid_3.2.2      lattice_0.20-33


I'll send the details for my Mac environment this evening.

I'll dig into the source code as soon as I can - C is a completely
foreign language to me, so I can't promise anything fast!

Thanks again,
Andy

On Thu, Oct 22, 2015 at 12:27 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Thu, 22 Oct 2015, Andy Teucher wrote:
>
>> I?m finding that writeOGR isn?t exporting multipolygons properly using
>> the GeoJSON driver. I have a simple test case (borrowed from here:
>>
>> http://gis.stackexchange.com/questions/137977/writeogr-alters-multipolygon-holes)
>> with a geojson string with one multipolygon containing two polygons. I
>> use readOGR to create a SpatialPolygonsDataFrame out of it, then write
>> it with writeOGR:
>>
>> library(rgdal)
>>
>> js <- '{
>> "type": "MultiPolygon",
>> "coordinates": [[[[102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0, 3.0],
>> [102.0, 2.0]]], [[[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0],
>> [100.0, 0.0]]]]
>> } '
>>
>> spdf <- readOGR(js, layer='OGRGeoJSON', verbose=FALSE) # Create a
>> SpatialPoygonsDataFrame
>>
>> temp <- tempfile()
>> writeOGR(spdf, dsn = temp, layer = "", driver="GeoJSON")
>> cat(readLines(temp))
>>
>> # Output:
>> { "type": "FeatureCollection", "crs": { "type": "name", "properties":
>> { "name": "urn:ogc:def:crs:OGC:1.3:CRS84" } }, "features": [ { "type":
>> "Feature", "id": 0, "properties": { "FID": 0 }, "geometry": { "type":
>> "MultiPolygon", "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ], [
>> 103.0, 3.0 ], [ 103.0, 2.0 ], [ 102.0, 2.0 ] ], [ [ 100.0, 0.0 ], [
>> 100.0, 1.0 ], [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] } }
>> ] }
>
>
> I can replicate this with GDAL 2.0.1 and rgdal 1.0-7 - reading temp in gives
> the orphaned hole. I'm surprised that passing the js object to readOGR()
> doesn't fail, but that isn't the source of the problem. spdf appears to be
> structured correctly. Please provide your GDAL and rgdal versions, and OS
> details from sessionInfo().
>
> We are completely relying on the GDAL drivers here - we can't cherry pick
> for particular drivers (historically excepting ESRI Shapefile), so your
> debugging will need to examine writeOGR(), the C code it calls, and the
> interactions between the rgdal C code and called OGR functions. Please check
> which other drivers are affected (I think KML is, is GML?). Can you place
> debugging Rprintf(...); in the rgdal C code to see where this is coming
> from?
>
> I can start looking at this sometime next week, so please make a start
> yourself; contributions from others are very welcome.
>
> Roger
>
>>
>> If you look closely at the output, you can see that the 'coordinates'
>> array now contains a single polygon array with two coordinate arrays:
>> the boundary, and a second one which is now treated as a hole of the
>> first (orphaned as it is outside the bounds of the polygon). The
>> original 'coordinates' array consists of two polygon arrays, each
>> consisting of a single coordinate array which defining a polygon (with
>> no holes), which is correct according the GeoJSON spec:
>> http://geojson.org/geojson-spec.html#polygon.
>>
>> I'm always hesitant to call things a bug, but this doesn't appear to
>> happen using ogr2ogr on the command line:
>>
>> writeOGR(spdf, ".", "test", driver = "ESRI Shapefile") # Write a
>> shapefile to convert using ogr2ogr
>> system("ogr2ogr -f GeoJSON test_from_shp.geojson test.shp")
>> cat(readLines("test_from_shp.geojson"))
>>
>> # Output:
>> { "type": "FeatureCollection",  "features": [ { "type": "Feature",
>> "properties": { "FID": 0 }, "geometry": { "type": "MultiPolygon",
>> "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ], [ 103.0, 3.0 ], [
>> 103.0, 2.0 ], [ 102.0, 2.0 ] ] ], [ [ [ 100.0, 0.0 ], [ 100.0, 1.0 ],
>> [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] } } ] }
>>
>> The resulting output is correct.
>>
>>
>> Thanks in advance for any help on this.
>>
>> Andy
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no


From andy.teucher at gmail.com  Thu Oct 22 20:28:17 2015
From: andy.teucher at gmail.com (Andy Teucher)
Date: Thu, 22 Oct 2015 11:28:17 -0700
Subject: [R-sig-Geo] Exporting Multipolygon geojson with rgdal::writeOGR
In-Reply-To: <CAOdCUxPaFGG4Ld69bsYw9_SVG4++OkJc3VKh-1tr93NP+NZoYA@mail.gmail.com>
References: <CAOdCUxMcO0spZhMbegjU-U2o6VOGfR0QgnCcF6YjfTfMJCoUpg@mail.gmail.com>
	<alpine.LFD.2.20.1510220915310.21713@reclus.nhh.no>
	<CAOdCUxPaFGG4Ld69bsYw9_SVG4++OkJc3VKh-1tr93NP+NZoYA@mail.gmail.com>
Message-ID: <CAOdCUxNf4nLnXoKYqff=XxOLCWT8YgcRBHWxRMU+heEjeAWJSw@mail.gmail.com>

One more test: WKT has the same issue:

library(rgdal)

js <- '{
"type": "MultiPolygon",
"coordinates": [[[[102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0, 3.0],
[102.0, 2.0]]], [[[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0],
[100.0, 0.0]]]]
} '

spdf <- readOGR(js, layer='OGRGeoJSON', verbose=FALSE)

writeOGR(spdf, dsn = "test.csv", layer = "test", driver="CSV",
layer_options = "GEOMETRY=AS_WKT")

cat(readLines("test.csv"), sep = "\n")

WKT,FID,
"MULTIPOLYGON (((102 2,102 3,103 3,103 2,102 2),(100 0,100 1,101 1,101
0,100 0)))",0


It should be:

WKT,FID,
"MULTIPOLYGON (((102 2,102 3,103 3,103 2,102 2)),((100 0,100 1,101
1,101 0,100 0)))",0

Andy

On Thu, Oct 22, 2015 at 10:36 AM, Andy Teucher <andy.teucher at gmail.com> wrote:
> Thanks very much Roger.
>
> I've replicated this on my work machine (Windows) and on my Mac at home.
>
> KML and GML are both affected. ESRI shapefile works fine and, though
> I'm not very familiar with the format, 'MapInfo File' works too
> (loading the file in qgis shows a multipart polygon with no geometry
> errors).
>
> sessionInfo() for my Windows machine (using rgdal 1.0-7 with included
> gdal drivers):
>
> R version 3.2.2 (2015-08-14)
> Platform: i386-w64-mingw32/i386 (32-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
> LC_MONETARY=English_Canada.1252
> [4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] rgdal_1.0-7 sp_1.2-0
>
> loaded via a namespace (and not attached):
> [1] tools_3.2.2     grid_3.2.2      lattice_0.20-33
>
>
> I'll send the details for my Mac environment this evening.
>
> I'll dig into the source code as soon as I can - C is a completely
> foreign language to me, so I can't promise anything fast!
>
> Thanks again,
> Andy
>
> On Thu, Oct 22, 2015 at 12:27 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> On Thu, 22 Oct 2015, Andy Teucher wrote:
>>
>>> I?m finding that writeOGR isn?t exporting multipolygons properly using
>>> the GeoJSON driver. I have a simple test case (borrowed from here:
>>>
>>> http://gis.stackexchange.com/questions/137977/writeogr-alters-multipolygon-holes)
>>> with a geojson string with one multipolygon containing two polygons. I
>>> use readOGR to create a SpatialPolygonsDataFrame out of it, then write
>>> it with writeOGR:
>>>
>>> library(rgdal)
>>>
>>> js <- '{
>>> "type": "MultiPolygon",
>>> "coordinates": [[[[102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0, 3.0],
>>> [102.0, 2.0]]], [[[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0],
>>> [100.0, 0.0]]]]
>>> } '
>>>
>>> spdf <- readOGR(js, layer='OGRGeoJSON', verbose=FALSE) # Create a
>>> SpatialPoygonsDataFrame
>>>
>>> temp <- tempfile()
>>> writeOGR(spdf, dsn = temp, layer = "", driver="GeoJSON")
>>> cat(readLines(temp))
>>>
>>> # Output:
>>> { "type": "FeatureCollection", "crs": { "type": "name", "properties":
>>> { "name": "urn:ogc:def:crs:OGC:1.3:CRS84" } }, "features": [ { "type":
>>> "Feature", "id": 0, "properties": { "FID": 0 }, "geometry": { "type":
>>> "MultiPolygon", "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ], [
>>> 103.0, 3.0 ], [ 103.0, 2.0 ], [ 102.0, 2.0 ] ], [ [ 100.0, 0.0 ], [
>>> 100.0, 1.0 ], [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] } }
>>> ] }
>>
>>
>> I can replicate this with GDAL 2.0.1 and rgdal 1.0-7 - reading temp in gives
>> the orphaned hole. I'm surprised that passing the js object to readOGR()
>> doesn't fail, but that isn't the source of the problem. spdf appears to be
>> structured correctly. Please provide your GDAL and rgdal versions, and OS
>> details from sessionInfo().
>>
>> We are completely relying on the GDAL drivers here - we can't cherry pick
>> for particular drivers (historically excepting ESRI Shapefile), so your
>> debugging will need to examine writeOGR(), the C code it calls, and the
>> interactions between the rgdal C code and called OGR functions. Please check
>> which other drivers are affected (I think KML is, is GML?). Can you place
>> debugging Rprintf(...); in the rgdal C code to see where this is coming
>> from?
>>
>> I can start looking at this sometime next week, so please make a start
>> yourself; contributions from others are very welcome.
>>
>> Roger
>>
>>>
>>> If you look closely at the output, you can see that the 'coordinates'
>>> array now contains a single polygon array with two coordinate arrays:
>>> the boundary, and a second one which is now treated as a hole of the
>>> first (orphaned as it is outside the bounds of the polygon). The
>>> original 'coordinates' array consists of two polygon arrays, each
>>> consisting of a single coordinate array which defining a polygon (with
>>> no holes), which is correct according the GeoJSON spec:
>>> http://geojson.org/geojson-spec.html#polygon.
>>>
>>> I'm always hesitant to call things a bug, but this doesn't appear to
>>> happen using ogr2ogr on the command line:
>>>
>>> writeOGR(spdf, ".", "test", driver = "ESRI Shapefile") # Write a
>>> shapefile to convert using ogr2ogr
>>> system("ogr2ogr -f GeoJSON test_from_shp.geojson test.shp")
>>> cat(readLines("test_from_shp.geojson"))
>>>
>>> # Output:
>>> { "type": "FeatureCollection",  "features": [ { "type": "Feature",
>>> "properties": { "FID": 0 }, "geometry": { "type": "MultiPolygon",
>>> "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ], [ 103.0, 3.0 ], [
>>> 103.0, 2.0 ], [ 102.0, 2.0 ] ] ], [ [ [ 100.0, 0.0 ], [ 100.0, 1.0 ],
>>> [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] } } ] }
>>>
>>> The resulting output is correct.
>>>
>>>
>>> Thanks in advance for any help on this.
>>>
>>> Andy
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no


From timjp at unimelb.edu.au  Fri Oct 23 01:45:13 2015
From: timjp at unimelb.edu.au (Tim Peterson)
Date: Fri, 23 Oct 2015 10:45:13 +1100
Subject: [R-sig-Geo] indicator kriging with R
In-Reply-To: <CAGinAQTCHhEO+z6c7P_dhU79d3_pxZBFVtzh0Nedf0mjKF5E8w@mail.gmail.com>
References: <CAGinAQQYtPnDvRa6AprWYGoH+cQ04rr7Z_Bp6puti66kekfO8A@mail.gmail.com>
	<5628A082.1020902@uni-muenster.de>
	<CAGinAQTCHhEO+z6c7P_dhU79d3_pxZBFVtzh0Nedf0mjKF5E8w@mail.gmail.com>
Message-ID: <56297509.4040301@unimelb.edu.au>

Hi Dafne and Edzer,

I too have been looking into gstat indicator kriging and simulation. My 
interest is because indicator simulations can (at least in GSLib) 
account for systems where extreme values are more/less spatially 
correlated than median values; that is the upper and lower threshold 
variograms can have a very different range to the mean values.

However, following 
http://rstudio-pubs-static.s3.amazonaws.com/10216_57cb0ffbb2e94586b29dfb1849dd49f0.html, 
I've just realised that gstat indicator kriging requires all indicator 
variograms to have an intrinsic correlation or be a linear model of 
coregionalisation, and hence requiring each variogram to have at least 
an equal range (FYI, to test this change line 'meuse.fit = fit.lmc(x, 
meuse.i)' to 'meuse.fit = fit.lmc(x, meuse.i,fit.ranges=TRUE)'). This is 
most likely because, unlike GSLib, gstat uses cokriging but this 
limitation defeats one of the advantages of indicator simulation over 
Gaussian simulation.

Anyway, can anyone propose a work around to this limitation? The only 
solution I can see is to krige each threshold independently but this 
does eliminate the option of accounting for cross-correlations between 
the thresholds or more advanced indicator feature; such as including 
spatially varying constraints eg 
http://www.mssanz.org.au/modsim2011/I9/peterson.pdf

Cheers

Tim


On 22/10/15 20:12, Dafne Berg wrote:
> Dear Edzer,
> yes it is exactly what I meant. Thanks for the confirmation that it is not
> yet implemented in gstat. I will have a look to gslib and the book.
>
> Thanks a lot
>
> Dafne
>
> On 22 October 2015 at 09:38, Edzer Pebesma <edzer.pebesma at uni-muenster.de>
> wrote:
>
>> Yes, this is what indicator kriging does.
>>
>> What you want is probably going back from the [0..1] estimated
>> probabilities to the original Z values. Gstat doesn't help here, but it
>> shouldn't be too hard to write a function for this. You need to make
>> assumptions about the distribution between different cutoff values, in
>> particular about both extreme (open) classes. I think the GSLIB and
>> Goovaerts books would be the first ones to look into.
>>
>> On 22/10/15 10:19, Dafne Berg wrote:
>>> Dear list,
>>> I am trying to do a indicator kriging of a continuous variable. I am
>>> especially interested in performing the "order relation correction". In
>> the
>>> documentation of "predict" in gstat it is mentioned as debug level 64
>>> (order relation violations (indicator kriging values before and after
>> order
>>> relation correction).
>>>
>>> However, when running predict I can only get the values in the range 0 to
>>> 1, as expected for indicator kriging.
>>>
>>> I am probably missing something very basic here, but I will be grateful
>> for
>>> any pointers in the right direction
>>>
>>> Thank you very much in advance
>>>
>>> Best wishes
>>>
>>> Dafne
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>> --
>> Edzer Pebesma
>> Institute for Geoinformatics (ifgi),  University of M?nster,
>> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
>> Journal of Statistical Software:   http://www.jstatsoft.org/
>> Computers & Geosciences:   http://elsevier.com/locate/cageo/
>> Spatial Statistics Society http://www.spatialstatistics.info
>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
----------------------
Dr. Tim Peterson

The Department of Infrastructure Engineering
The University of Melbourne, 3010 Australia
T: +61 3 8344 9950 <tel:%2B61%203%208344%209950>, M: +61 0438 385 937 
<tel:%2B61%200438%20385%20937>

Dept. profile : 
http://www.ie.unimelb.edu.au/people/staff.php?person_ID=141135
Research Gate : https://www.researchgate.net/profile/Tim_Peterson7
Google Scholar: 
http://scholar.google.com.au/citations?user=kkYJLF4AAAAJ&hl=en&oi=ao

	[[alternative HTML version deleted]]


From uzzal at gist.ac.kr  Fri Oct 23 04:43:13 2015
From: uzzal at gist.ac.kr (Uzzal)
Date: Fri, 23 Oct 2015 11:43:13 +0900 (KST)
Subject: [R-sig-Geo] Why correlation coefficient between observed value and
	predicted values very low after cross validation[gstat]?
Message-ID: <914855942.1445568193399.JavaMail.root@eunhasu>

I am trying to perform ordinary Kriging using gstat package on a hourly particulate matter(PM) concentration dataset. my dataset contains PM concentration for 1 hour of 107 sites. You can download dataset from here. After performing ordinary kriging, I did cross validation. but I got the correlation coefficient between observed values and predicted values is ver low (.15~.30). I checked many combination of model (Gau,Exp,Sph), width, cutoff, intial parameter value but still correlation coefficient is low. Am I doing any mistake in my code? Is there anything to do, to get high correlation coefficient? My r code using gstat package: library(sp)
library(gstat)
library(rgdal)seoul030101.cv  #Coordinates
coordinates(seoul030101.cv)  #Variogram modeling
seoul030101.cv_var #Cross Validation                            
cv_pr #Correlation coefficient#correlation observed and predicted, ideally 1
cor(cv_pr$observed, cv_pr$var1.pred) # correlation predicted and residual, ideally 0
cor(cv_pr$var1.pred, cv_pr$residual) #other statistics# mean error, ideally 0:
(mean(cv_pr$residual))#rmse(rmse # Mean square normalized error, ideally close to 1
(mean(cv_pr$zscore^2)) Thanks in advance.Orpheus 




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151023/f33dbd77/attachment.html>

From edzer.pebesma at uni-muenster.de  Fri Oct 23 08:47:27 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 23 Oct 2015 08:47:27 +0200
Subject: [R-sig-Geo] indicator kriging with R
In-Reply-To: <56297509.4040301@unimelb.edu.au>
References: <CAGinAQQYtPnDvRa6AprWYGoH+cQ04rr7Z_Bp6puti66kekfO8A@mail.gmail.com>
	<5628A082.1020902@uni-muenster.de>
	<CAGinAQTCHhEO+z6c7P_dhU79d3_pxZBFVtzh0Nedf0mjKF5E8w@mail.gmail.com>
	<56297509.4040301@unimelb.edu.au>
Message-ID: <5629D7FF.3010509@uni-muenster.de>



On 23/10/15 01:45, Tim Peterson wrote:
> Hi Dafne and Edzer,
> 
> I too have been looking into gstat indicator kriging and simulation. My 
> interest is because indicator simulations can (at least in GSLib) 
> account for systems where extreme values are more/less spatially 
> correlated than median values; that is the upper and lower threshold 
> variograms can have a very different range to the mean values.
> 
> However, following 
> http://rstudio-pubs-static.s3.amazonaws.com/10216_57cb0ffbb2e94586b29dfb1849dd49f0.html, 
> I've just realised that gstat indicator kriging requires all indicator 
> variograms to have an intrinsic correlation or be a linear model of 
> coregionalisation, and hence requiring each variogram to have at least 
> an equal range (FYI, to test this change line 'meuse.fit = fit.lmc(x, 
> meuse.i)' to 'meuse.fit = fit.lmc(x, meuse.i,fit.ranges=TRUE)'). This is 
> most likely because, unlike GSLib, gstat uses cokriging but this 
> limitation defeats one of the advantages of indicator simulation over 
> Gaussian simulation.

please look into the docs of ?fit.lmc, which lets you fit non-LMC
models, with each variogram its own (fitted) range. You can use these
models for direct kriging, and also for cokriging, but in the latter
case there is of course no guarantee that the covariance matrix is PD -
the software will issue warnings, you're at your own risk, and this is
quite likely hard to defend for reviewers who know some basics of random
processes.

> 
> Anyway, can anyone propose a work around to this limitation? The only 
> solution I can see is to krige each threshold independently but this 
> does eliminate the option of accounting for cross-correlations between 
> the thresholds or more advanced indicator feature; such as including 
> spatially varying constraints eg 
> http://www.mssanz.org.au/modsim2011/I9/peterson.pdf

Another, more consistent approach to modeling spatial dependencies where
correlation strength varies across the value range uses copula's, see
e.g. Ben Graeler's PhD work, http://ifgi.uni-muenster.de/~b_grae02/ and
http://spcopula.r-forge.r-project.org/

> 
> Cheers
> 
> Tim
> 
> 
> On 22/10/15 20:12, Dafne Berg wrote:
>> Dear Edzer,
>> yes it is exactly what I meant. Thanks for the confirmation that it is not
>> yet implemented in gstat. I will have a look to gslib and the book.
>>
>> Thanks a lot
>>
>> Dafne
>>
>> On 22 October 2015 at 09:38, Edzer Pebesma <edzer.pebesma at uni-muenster.de>
>> wrote:
>>
>>> Yes, this is what indicator kriging does.
>>>
>>> What you want is probably going back from the [0..1] estimated
>>> probabilities to the original Z values. Gstat doesn't help here, but it
>>> shouldn't be too hard to write a function for this. You need to make
>>> assumptions about the distribution between different cutoff values, in
>>> particular about both extreme (open) classes. I think the GSLIB and
>>> Goovaerts books would be the first ones to look into.
>>>
>>> On 22/10/15 10:19, Dafne Berg wrote:
>>>> Dear list,
>>>> I am trying to do a indicator kriging of a continuous variable. I am
>>>> especially interested in performing the "order relation correction". In
>>> the
>>>> documentation of "predict" in gstat it is mentioned as debug level 64
>>>> (order relation violations (indicator kriging values before and after
>>> order
>>>> relation correction).
>>>>
>>>> However, when running predict I can only get the values in the range 0 to
>>>> 1, as expected for indicator kriging.
>>>>
>>>> I am probably missing something very basic here, but I will be grateful
>>> for
>>>> any pointers in the right direction
>>>>
>>>> Thank you very much in advance
>>>>
>>>> Best wishes
>>>>
>>>> Dafne
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>> --
>>> Edzer Pebesma
>>> Institute for Geoinformatics (ifgi),  University of M?nster,
>>> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
>>> Journal of Statistical Software:   http://www.jstatsoft.org/
>>> Computers & Geosciences:   http://elsevier.com/locate/cageo/
>>> Spatial Statistics Society http://www.spatialstatistics.info
>>>
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151023/4a6f9415/attachment.bin>

From omaralthwaini at yahoo.com  Fri Oct 23 10:44:39 2015
From: omaralthwaini at yahoo.com (Omar Faisel)
Date: Fri, 23 Oct 2015 08:44:39 +0000 (UTC)
Subject: [R-sig-Geo] Spatial prediction map using raster format dataset
In-Reply-To: <561F7DA4.9000601@gmail.com>
References: <561F7DA4.9000601@gmail.com>
Message-ID: <1540720350.2287026.1445589879800.JavaMail.yahoo@mail.yahoo.com>

Actually, I am a new user in R environment. and i faced few dilemmas, if you could help me with some tips regarding: My data represent landslides locations and conditioning factors contain the following: I have spatial data for landslide assessment in .tiff format.
1)Dependent: Training and testing (1=landslide, 0= no landslide, -9999 value refer to nodata) 2)Independent variables, slope, elevation..etc.My question: should i keep using raster format and search for suitable analysis methods like regressions . OR, i need to convert them to ascii, and use the huge amount of tools available. Note: if i convert my data into ascii, it would develop uncertainty, moreover, ascii file size will be huge (60 MB).Worth to mention that my training data represents polygon converted to raster. I am totally overwhelmed. kindly any suggestions.?
Thank you @Eelke . Actually the mentioned case (Vignette) deals with points feature. My question about when we deal with such feature but in raster format. Any suggestions? thank you again

Cordially,
0mar. 


     On Thursday, October 15, 2015 1:19 PM, Eelke Folmer <e.o.folmer at gmail.com> wrote:
   
 

 Omar,
I think that the following document will be of help:
https://cran.r-project.org/web/packages/dismo/vignettes/sdm.pdf
It is a gentle and practical introduction to raster: both data handling 
and regression. It is about species distribution modeling but the 
principles apply to your question too, I think.
Eelke

On 10/15/2015 07:43 AM, Omar Faisel wrote:
>
>
>
> Dear All,
> My data represent landslides locations and conditioning factors (5000 row, 2000 column, tiff format)? contain the following:1- Training and testing locations (1=ist, 0= not, also -9999 value refer to no-data areas)2- Independent variables like slope, elevation..etc.
> Which type of code do i need to use :1- To read the files, (which format?)2- To run linear regression or any prediction model.
> Thank you in advance.
>
> Omar.
>
>
>
>
>
> ??? [[alternative HTML version deleted]]
>
>

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



  
	[[alternative HTML version deleted]]


From alobolistas at gmail.com  Fri Oct 23 13:16:18 2015
From: alobolistas at gmail.com (Agustin Lobo)
Date: Fri, 23 Oct 2015 13:16:18 +0200
Subject: [R-sig-Geo] Apply a different threshold for each layer in a brick
	object
Message-ID: <CAG4NRe+ZgPBfwSNPRvvwYA7_U8N-Rn9ZA2GOW+Pfgh20x6yQJg@mail.gmail.com>

Hi!

Given
r <- raster(ncol=10, nrow=10)
r[]=1:ncell(r)
s <- brick(r,r,r,r,r,r)
s <- s * 1:6
summary(s)

applying a common threshold is simple, i.e.
th <- 50
s[s>th] <- th

but what if th is a vector with a different value for each layer?
Is there a faster (raster!) way (i.e. using calc() or stackApply() )
for the following:

s2 <- brick(r,r,r,r,r,r)
s2 <- s2 * 1:6
th <- c(50*(1:6))
for (i in 1:nlayers(s)){
  a <- s2[[i]]
  a[a>th[i]] <- th[i]
  s2[[i]]  <- a
}

Tried with calc() and stackApply(), but get errors.
Thanks

Agus


From mathieu.rajerison at gmail.com  Fri Oct 23 13:38:35 2015
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Fri, 23 Oct 2015 13:38:35 +0200
Subject: [R-sig-Geo] spgrass6, readVECT and overwriting ?
Message-ID: <CAGfc75kOhMzWuXe_jm+A81-MoiSdRanoXViAycvKGoPLuRzwfw@mail.gmail.com>

Hi,

I'm using spgrass6 and I use readVECT function in a loop.

Using it causes an error because it doesn't overwrite the the temporary
shapefile..

> thin = readVECT(vname="zoneBDTOPOthin")
with_c: argument reversed from version 0.7-11 and in GRASS 6
ERROR :Layer <zoneBDTO> already exists in OGR data source
        'D:/GRASSDB/paca/mapset/.tmp'
OGR data source with driver: ESRI Shapefile
Source: "D:/GRASSDB/paca/mapset/.tmp", layer: "zoneBDTO"
with 770 features
It has 3 fields
Warning message:
running command 'v.out.ogr.exe -e -c input=zoneBDTOPOthin2 type=line
layer=1 dsn=D:/GRASSDB/paca/mapset/.tmp olayer=zoneBDTO
format=ESRI_Shapefile' had status 1


I wonder how to specify to spgrass that I want to overwrite the file in
readVECT, although I know using execGRASS and v.out.ogr with the
appropriate overwrite flags would do the job.

Thanks in advance for the answer..

Mathieu

	[[alternative HTML version deleted]]


From mausv at uni-muenster.de  Fri Oct 23 14:37:21 2015
From: mausv at uni-muenster.de (Victor Maus)
Date: Fri, 23 Oct 2015 14:37:21 +0200
Subject: [R-sig-Geo] Raster multi-band time series analysis
Message-ID: <562A2A01.2080903@uni-muenster.de>

Dear Members,

What kind of raster iterator can I use for multi-band time series 
analysis? I have a time series of multi-band raster files ("RED", "NIR", 
"BLUE", for each time) and I would like to apply some temporal analysis 
to it.


Thank you!

Victor

-- 
Victor Maus, MSc
Assistant Researcher
Institute for Geoinformatics (IFGI), University of M?nster, Germany
PhD candidate in Earth System Science
National Institute for Space Research (INPE), Brazil


From Roger.Bivand at nhh.no  Fri Oct 23 14:49:43 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 23 Oct 2015 14:49:43 +0200
Subject: [R-sig-Geo] gIntersection with drop_lower_td=T drops entire
 intersection
In-Reply-To: <002601d0fc63$d9a42700$8cec7500$@bluewin.ch>
References: <002601d0fc63$d9a42700$8cec7500$@bluewin.ch>
Message-ID: <alpine.LFD.2.20.1510231445570.21155@reclus.nhh.no>

I didn't see this when you posted, sorry. I can replicate the problem 
- thanks for a useful report. I'll try to see where drop_lower_td= is 
being too aggresive.

I'd be very obliged if others (not necessarily the poster!) would try to 
answer questions like this, the code is open, my time is limited, and 
sometimes my day-job has priority ...

Roger

On Thu, 1 Oct 2015, Pius Korner wrote:

> Dear all
>
>
>
> I intersect a SpatialPolygons-Object with two polygons 1a and 1b with a
> polygon 2. Polygon 1a intersects with polygon 2 in one area but also only
> touches polygon 2 at another position.
>
> Here a schematic case for illustration:
>
>
>
> poly1 <-
> SpatialPolygons(list(Polygons(list(Polygon(coords=matrix(c(0,0,2,2,0,1,1,0),
> ncol=2,byrow=F))),ID=c("a")),
>
>
> Polygons(list(Polygon(coords=matrix(c(0,0,2,2,2,3,3,2),ncol=2,byrow=F))),ID=
> c("b"))))
>
> poly2 <-
> SpatialPolygons(list(Polygons(list(Polygon(coords=matrix(c(0,0,2,2,1,1,1,3,3
> ,0,0,2),ncol=2,byrow=F))),ID=c("c"))))
>
> plot(poly1,border="orange")
>
> plot(poly2,border="blue",add=T,lty=2,density=8,angle=30,col="blue")
>
>
>
> I'm interested in the area of overlap of polygons 1a and 1b with polygon 2.
>
> gIntersection(poly1,poly2,byid=T)
>
> does not work because of the different subgeometries that result from the
> intersection of 1a with 2; they cannot be collected.
>
> gIntersection(poly1,poly2,byid=T,drop_lower_td=T)
>
> drops the entire intersection between 1a with 2, hence I get no value for
> 1a, even though it does overlap with polygon 2.
>
>
>
> Is there a way so that only the Point-subgeometries (with area=0) are
> dropped, but the Polygon-subgeometry is retained and returned for the
> intersection of 1a and 2?
>
>
>
> my temporary workaround was to very slightly buffer poly1 (width=-0.0001),
> to prevent the point-subgeometry.
>
> I could create a loop and intersect each polygon in poly1 separately, but
> using byid=T would be nicer (faster..)
>
>
>
> many thanks
>
> Pius
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From loic.dutrieux at wur.nl  Fri Oct 23 14:58:56 2015
From: loic.dutrieux at wur.nl (=?UTF-8?Q?Lo=c3=afc_Dutrieux?=)
Date: Fri, 23 Oct 2015 14:58:56 +0200
Subject: [R-sig-Geo] Raster multi-band time series analysis
In-Reply-To: <562A2A01.2080903@uni-muenster.de>
References: <562A2A01.2080903@uni-muenster.de>
Message-ID: <562A2F10.1050207@wur.nl>

Hi Victor,

As far as I know there isn't anything yet for dealing with raster that 
have more than 3 dimensions in R. The raster package actually has a 4D 
class (raterQuad I think) though, but it does not have any methods yet, 
so it won't help you much, unless you want to develop the methods yourself.

The way I would go about this is by building a temporal rasterBrick for 
each of your spectral band and write a smart function to be passed to 
raster::overlay.

Cheers,
Lo?c

On 10/23/2015 02:37 PM, Victor Maus wrote:
> Dear Members,
>
> What kind of raster iterator can I use for multi-band time series
> analysis? I have a time series of multi-band raster files ("RED", "NIR",
> "BLUE", for each time) and I would like to apply some temporal analysis
> to it.
>
>
> Thank you!
>
> Victor
>


From dafne.berg at gmail.com  Fri Oct 23 14:59:56 2015
From: dafne.berg at gmail.com (Dafne Berg)
Date: Fri, 23 Oct 2015 13:59:56 +0100
Subject: [R-sig-Geo] indicator kriging with R
In-Reply-To: <3995581109E58043A20A2418E7CAB3EE2F9BEEC0@nwex2.rothamsted.ac.uk>
References: <CAGinAQQYtPnDvRa6AprWYGoH+cQ04rr7Z_Bp6puti66kekfO8A@mail.gmail.com>
	<5628A082.1020902@uni-muenster.de>
	<c861f849-5895-4716-9e53-c5f8e27976d6@ROTHEX2.rothamsted.ac.uk>
	<3995581109E58043A20A2418E7CAB3EE2F9BEEC0@nwex2.rothamsted.ac.uk>
Message-ID: <CAGinAQQqDJA-C_R1JZMK8htO+8=3NXQuenc5ajArCXvy_kzXDQ@mail.gmail.com>

Thanks. I am now trying to work with gslib and at the same time understand
how to implement a function in R to back from the estimated probabilities
to the original values.

Thanks a lot

Dafne

On 22 October 2015 at 10:32, Paul Harris <paul.harris at rothamsted.ac.uk>
wrote:

> Hi Dafne
> If you going to look at GSLIB (with its FORTRAN code), then this is also
> useful:
> Goovaerts P (2009) AUTO-IK: A 2D indicator kriging program for the
> automated non-parametric modeling of local uncertainty in earth sciences.
> Comput Geosci 35:1255-1270
> Cheers Paul
>
> -----Original Message-----
> From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of
> Dafne Berg
> Sent: 22 October 2015 10:12
> To: Edzer Pebesma
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] indicator kriging with R
>
> Dear Edzer,
> yes it is exactly what I meant. Thanks for the confirmation that it is not
> yet implemented in gstat. I will have a look to gslib and the book.
>
> Thanks a lot
>
> Dafne
>
> On 22 October 2015 at 09:38, Edzer Pebesma <edzer.pebesma at uni-muenster.de>
> wrote:
>
> > Yes, this is what indicator kriging does.
> >
> > What you want is probably going back from the [0..1] estimated
> > probabilities to the original Z values. Gstat doesn't help here, but
> > it shouldn't be too hard to write a function for this. You need to
> > make assumptions about the distribution between different cutoff
> > values, in particular about both extreme (open) classes. I think the
> > GSLIB and Goovaerts books would be the first ones to look into.
> >
> > On 22/10/15 10:19, Dafne Berg wrote:
> > > Dear list,
> > > I am trying to do a indicator kriging of a continuous variable. I am
> > > especially interested in performing the "order relation correction".
> > > In
> > the
> > > documentation of "predict" in gstat it is mentioned as debug level
> > > 64 (order relation violations (indicator kriging values before and
> > > after
> > order
> > > relation correction).
> > >
> > > However, when running predict I can only get the values in the range
> > > 0 to 1, as expected for indicator kriging.
> > >
> > > I am probably missing something very basic here, but I will be
> > > grateful
> > for
> > > any pointers in the right direction
> > >
> > > Thank you very much in advance
> > >
> > > Best wishes
> > >
> > > Dafne
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-Geo mailing list
> > > R-sig-Geo at r-project.org
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > >
> >
> > --
> > Edzer Pebesma
> > Institute for Geoinformatics (ifgi),  University of M?nster,
> > Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> > Journal of Statistical Software:   http://www.jstatsoft.org/
> > Computers & Geosciences:   http://elsevier.com/locate/cageo/
> > Spatial Statistics Society http://www.spatialstatistics.info
> >
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> Rothamsted Research is a company limited by guarantee, registered in
> England at Harpenden, Hertfordshire, AL5 2JQ under the registration number
> 2393175 and a not for profit charity number 802038.
>
>
>

	[[alternative HTML version deleted]]


From Rainer at krugs.de  Sat Oct 24 13:34:30 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Sat, 24 Oct 2015 13:34:30 +0200
Subject: [R-sig-Geo] spgrass6, readVECT and overwriting ?
In-Reply-To: <CAGfc75kOhMzWuXe_jm+A81-MoiSdRanoXViAycvKGoPLuRzwfw@mail.gmail.com>
	(Mathieu Rajerison's message of "Fri, 23 Oct 2015 13:38:35 +0200")
References: <CAGfc75kOhMzWuXe_jm+A81-MoiSdRanoXViAycvKGoPLuRzwfw@mail.gmail.com>
Message-ID: <m2mvv87b5l.fsf@krugs.de>

Mathieu Rajerison <mathieu.rajerison at gmail.com> writes:

> Hi,
>
> I'm using spgrass6 and I use readVECT function in a loop.
>
> Using it causes an error because it doesn't overwrite the the temporary
> shapefile..
>
>> thin = readVECT(vname="zoneBDTOPOthin")
> with_c: argument reversed from version 0.7-11 and in GRASS 6
> ERROR :Layer <zoneBDTO> already exists in OGR data source
>         'D:/GRASSDB/paca/mapset/.tmp'
> OGR data source with driver: ESRI Shapefile
> Source: "D:/GRASSDB/paca/mapset/.tmp", layer: "zoneBDTO"
> with 770 features
> It has 3 fields
> Warning message:
> running command 'v.out.ogr.exe -e -c input=zoneBDTOPOthin2 type=line
> layer=1 dsn=D:/GRASSDB/paca/mapset/.tmp olayer=zoneBDTO
> format=ESRI_Shapefile' had status 1
>
>
> I wonder how to specify to spgrass that I want to overwrite the file in
> readVECT, although I know using execGRASS and v.out.ogr with the
> appropriate overwrite flags would do the job.
>
> Thanks in advance for the answer..

One reason why probably nobody replied is that

1) no version information about R and GRASS (there are several GRASS 6 versions)
2) no session information i.e. package versions used
3) no information about the OS (I guess it is windows based on the
Source path above)
4) no reproducible example which could be easily done by using the GRASS 
5) as far as I can see, in the newest version of spgrass6 there is no function readVECT()

So I would suggest to provide the info and give a reproducible example
using a GRASS sample dataset
(see https://grass.osgeo.org/download/sample-data/ - the Spearfish
dataset is probably the best)

I will happily look int this if you can provide the necessary info.

Cheers,

Rainer

>
> Mathieu
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151024/3d752df5/attachment.bin>

From Roger.Bivand at nhh.no  Sun Oct 25 11:36:03 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 25 Oct 2015 11:36:03 +0100
Subject: [R-sig-Geo] gIntersection with drop_lower_td=T drops entire
 intersection
In-Reply-To: <alpine.LFD.2.20.1510231445570.21155@reclus.nhh.no>
References: <002601d0fc63$d9a42700$8cec7500$@bluewin.ch>
	<alpine.LFD.2.20.1510231445570.21155@reclus.nhh.no>
Message-ID: <alpine.LFD.2.20.1510251127550.22889@reclus.nhh.no>

Pius,

There was a bug in the C code which caused the deletion of the Polygons 
object rather than the offending point in the geometry collection. The 
current source of rgeos on R-forge should fix the problem - I submitted 
source tarball the source tarball to R Winbuilder, and a Windows binary 
build of the development package is available on (if you use Windows, R 
3.2.2):

http://win-builder.r-project.org/WWjSD9bDw8xx

Thanks for your report of this problem, your example code pinpointed the 
issue, and is now among the examples on the help page.

Best wishes,

Roger

On Fri, 23 Oct 2015, Roger Bivand wrote:

> I didn't see this when you posted, sorry. I can replicate the problem - 
> thanks for a useful report. I'll try to see where drop_lower_td= is being too 
> aggresive.
>
> I'd be very obliged if others (not necessarily the poster!) would try to 
> answer questions like this, the code is open, my time is limited, and 
> sometimes my day-job has priority ...
>
> Roger
>
> On Thu, 1 Oct 2015, Pius Korner wrote:
>
>> Dear all
>> 
>> 
>> 
>> I intersect a SpatialPolygons-Object with two polygons 1a and 1b with a
>> polygon 2. Polygon 1a intersects with polygon 2 in one area but also only
>> touches polygon 2 at another position.
>> 
>> Here a schematic case for illustration:
>> 
>> 
>> 
>> poly1 <-
>> SpatialPolygons(list(Polygons(list(Polygon(coords=matrix(c(0,0,2,2,0,1,1,0),
>> ncol=2,byrow=F))),ID=c("a")),
>> 
>> 
>> Polygons(list(Polygon(coords=matrix(c(0,0,2,2,2,3,3,2),ncol=2,byrow=F))),ID=
>> c("b"))))
>> 
>> poly2 <-
>> SpatialPolygons(list(Polygons(list(Polygon(coords=matrix(c(0,0,2,2,1,1,1,3,3
>> ,0,0,2),ncol=2,byrow=F))),ID=c("c"))))
>> 
>> plot(poly1,border="orange")
>> 
>> plot(poly2,border="blue",add=T,lty=2,density=8,angle=30,col="blue")
>> 
>> 
>> 
>> I'm interested in the area of overlap of polygons 1a and 1b with polygon 2.
>> 
>> gIntersection(poly1,poly2,byid=T)
>> 
>> does not work because of the different subgeometries that result from the
>> intersection of 1a with 2; they cannot be collected.
>> 
>> gIntersection(poly1,poly2,byid=T,drop_lower_td=T)
>> 
>> drops the entire intersection between 1a with 2, hence I get no value for
>> 1a, even though it does overlap with polygon 2.
>> 
>> 
>> 
>> Is there a way so that only the Point-subgeometries (with area=0) are
>> dropped, but the Polygon-subgeometry is retained and returned for the
>> intersection of 1a and 2?
>> 
>> 
>> 
>> my temporary workaround was to very slightly buffer poly1 (width=-0.0001),
>> to prevent the point-subgeometry.
>> 
>> I could create a loop and intersect each polygon in poly1 separately, but
>> using byid=T would be nicer (faster..)
>> 
>> 
>> 
>> many thanks
>> 
>> Pius
>> 
>>
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From mausv at uni-muenster.de  Mon Oct 26 12:23:08 2015
From: mausv at uni-muenster.de (Victor Maus)
Date: Mon, 26 Oct 2015 12:23:08 +0100
Subject: [R-sig-Geo] Raster multi-band time series analysis
Message-ID: <562E0D1C.5030102@uni-muenster.de>

Hi Lo?c,

Thank your very much for your answer. I am working on your suggestion. 
But I still have a question.

The function raster::overlay works for multiple RasterBrick objects. 
However, I noticed that raster::beginCluster works with raster::overlay 
as long as a single RasterStack or RasterBrick is provided as the first 
argument. Do you have any suggestion for parallel processing of multiple 
RasterBrick objects?

Thank you!

Best,
Victor


From loic.dutrieux at wur.nl  Mon Oct 26 14:22:54 2015
From: loic.dutrieux at wur.nl (=?UTF-8?Q?Lo=c3=afc_Dutrieux?=)
Date: Mon, 26 Oct 2015 14:22:54 +0100
Subject: [R-sig-Geo] Raster multi-band time series analysis
In-Reply-To: <562E0D1C.5030102@uni-muenster.de>
References: <562E0D1C.5030102@uni-muenster.de>
Message-ID: <562E292E.6070801@wur.nl>

Hi Victor,

I don't have much experience with beginCluster; however, I have written 
a parallel version of raster::calc a little while ago that uses forking.
https://github.com/dutri001/bfastSpatial/blob/master/R/mc.calc.R

calc and overlay are analogue so that it shouldn't be too hard to extend 
this function to overlay, using an undefined number of rasterStack or 
Bricks as input. You will need a bit more checks and control flow at the 
beginning of the function though.
I'm not sure at all whether this is the most efficient way of 
parallelizing things, but it will for sure speed up your processing 
compared to single core processing.

Hope this helps,
Cheers,
Lo?c

On 10/26/2015 12:23 PM, Victor Maus wrote:
> Hi Lo?c,
>
> Thank your very much for your answer. I am working on your suggestion.
> But I still have a question.
>
> The function raster::overlay works for multiple RasterBrick objects.
> However, I noticed that raster::beginCluster works with raster::overlay
> as long as a single RasterStack or RasterBrick is provided as the first
> argument. Do you have any suggestion for parallel processing of multiple
> RasterBrick objects?
>
> Thank you!
>
> Best,
> Victor


From Dominik.Schneider at colorado.edu  Mon Oct 26 16:18:01 2015
From: Dominik.Schneider at colorado.edu (Dominik Schneider)
Date: Mon, 26 Oct 2015 09:18:01 -0600
Subject: [R-sig-Geo] Raster multi-band time series analysis
In-Reply-To: <562E292E.6070801@wur.nl>
References: <562E0D1C.5030102@uni-muenster.de> <562E292E.6070801@wur.nl>
Message-ID: <CAHYDKLZGOeMLAS-AL3UUvBJfw-pXnkvp_NORrLXUUX2zrhyjFg@mail.gmail.com>

Check out the spatial.tools package for parallel processing with the raster
package.



On Mon, Oct 26, 2015 at 7:22 AM, Lo?c Dutrieux <loic.dutrieux at wur.nl> wrote:

> Hi Victor,
>
> I don't have much experience with beginCluster; however, I have written a
> parallel version of raster::calc a little while ago that uses forking.
> https://github.com/dutri001/bfastSpatial/blob/master/R/mc.calc.R
>
> calc and overlay are analogue so that it shouldn't be too hard to extend
> this function to overlay, using an undefined number of rasterStack or
> Bricks as input. You will need a bit more checks and control flow at the
> beginning of the function though.
> I'm not sure at all whether this is the most efficient way of
> parallelizing things, but it will for sure speed up your processing
> compared to single core processing.
>
> Hope this helps,
> Cheers,
> Lo?c
>
>
> On 10/26/2015 12:23 PM, Victor Maus wrote:
>
>> Hi Lo?c,
>>
>> Thank your very much for your answer. I am working on your suggestion.
>> But I still have a question.
>>
>> The function raster::overlay works for multiple RasterBrick objects.
>> However, I noticed that raster::beginCluster works with raster::overlay
>> as long as a single RasterStack or RasterBrick is provided as the first
>> argument. Do you have any suggestion for parallel processing of multiple
>> RasterBrick objects?
>>
>> Thank you!
>>
>> Best,
>> Victor
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From andy.teucher at gmail.com  Mon Oct 26 23:52:35 2015
From: andy.teucher at gmail.com (Andy Teucher)
Date: Mon, 26 Oct 2015 15:52:35 -0700
Subject: [R-sig-Geo] Exporting Multipolygon geojson with rgdal::writeOGR
In-Reply-To: <alpine.LFD.2.20.1510230802470.21155@reclus.nhh.no>
References: <CAOdCUxNf4nLnXoKYqff=XxOLCWT8YgcRBHWxRMU+heEjeAWJSw@mail.gmail.com>
	<1445569713760.14aec109@Nodemailer>
	<alpine.LFD.2.20.1510230802470.21155@reclus.nhh.no>
Message-ID: <CAOdCUxPUdqtT_wRLDaMvqt2d88JETn4iArU1CJU49Pcd=VmsFw@mail.gmail.com>

Hi Roger,

Sorry I haven't been much help here - it's not for lack of trying,
just lack of skills. I've been poring through OGR_write.cpp and trying
to figure out language and the flow of things... a few thoughts
occurred to me (which are probably obvious to you):

1) Is this bug because holes are standalone polygons in sp objects,
while they are members of polygon objects in geojson, wkt, etc?

2) On a related note, I notice that a single polygon with a hole is
identified as a multipolygon containing a single polygon with a hole,
when using writeOGR and one of the affected drivers.  Practically I
don't think this matters too much, but it's not quite right.

3) In lines 116-160 the polygon/multipolygon and line/multiline
determination is made for the entire layer. Can/should this be made
for each feature in the layer, as you could have a layer with a
mixture of single polygons and multipolygons?

4) I feel like there ought to be one more layer of looping through the
polyons. e.g.:

loop over each feature;
     determine whether each feature is a single polygon (length 1 or
all rings but one are holes), or a multipolygon:
        if a polygon loop over and add ring(s);
        if a multipolygon loop over polygons:
            for each polygon add ring(s) and somehow assign holes to
parent polygons

Again, apologies if I'm being totally obvious (or way off base).
Thanks for all your work on these packages, and on this issue.

Andy


On Thu, Oct 22, 2015 at 11:07 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Fri, 23 Oct 2015, Andy Teucher wrote:
>
>> On my Mac, I am running rgdal 1.0-7 and GDAL 1.11.3
>>
>>
>> sessionInfo()
>>
>
> OK, thanks.
>
> The problem also affects the SQLite driver (the CRAN binaries do not have
> this driver). Could someone please check the PostGIS driver - my guess is
> that all OGC SFS compliant drivers may be affected.
>
> Could somebody also please check whether this is a recently introduced issue
> or not? For example somebody still on rgdal < 1.0? src/OGR_write.cpp was
> changed 2015-08-21, but the last previous change was 2015-06-11, then
> 2015-05-31, 2014-08-17 ... from the ChangeLog visible on the package CRAN
> page.
>
> Roger
>
>
>>
>>
>>
>>
>> R version 3.2.2 (2015-08-14)
>>
>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>
>> Running under: OS X 10.11 (El Capitan)
>>
>>
>>
>>
>> locale:
>>
>> [1] en_CA.UTF-8/en_CA.UTF-8/en_CA.UTF-8/C/en_CA.UTF-8/en_CA.UTF-8
>>
>>
>>
>>
>> attached base packages:
>>
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>
>>
>>
>> other attached packages:
>>
>> [1] rgdal_1.0-7 sp_1.2-1
>>
>>
>>
>>
>> loaded via a namespace (and not attached):
>>
>> [1] tools_3.2.2     grid_3.2.2      lattice_0.20-33
>>
>>
>>
>>
>> Andy
>>
>> On Thu, Oct 22, 2015 at 11:28 AM, Andy Teucher <andy.teucher at gmail.com>
>> wrote:
>>
>>> One more test: WKT has the same issue:
>>> library(rgdal)
>>> js <- '{
>>> "type": "MultiPolygon",
>>> "coordinates": [[[[102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0, 3.0],
>>> [102.0, 2.0]]], [[[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0],
>>> [100.0, 0.0]]]]
>>> } '
>>> spdf <- readOGR(js, layer='OGRGeoJSON', verbose=FALSE)
>>> writeOGR(spdf, dsn = "test.csv", layer = "test", driver="CSV",
>>> layer_options = "GEOMETRY=AS_WKT")
>>> cat(readLines("test.csv"), sep = "\n")
>>> WKT,FID,
>>> "MULTIPOLYGON (((102 2,102 3,103 3,103 2,102 2),(100 0,100 1,101 1,101
>>> 0,100 0)))",0
>>> It should be:
>>> WKT,FID,
>>> "MULTIPOLYGON (((102 2,102 3,103 3,103 2,102 2)),((100 0,100 1,101
>>> 1,101 0,100 0)))",0
>>> Andy
>>> On Thu, Oct 22, 2015 at 10:36 AM, Andy Teucher <andy.teucher at gmail.com>
>>> wrote:
>>>>
>>>> Thanks very much Roger.
>>>>
>>>> I've replicated this on my work machine (Windows) and on my Mac at home.
>>>>
>>>> KML and GML are both affected. ESRI shapefile works fine and, though
>>>> I'm not very familiar with the format, 'MapInfo File' works too
>>>> (loading the file in qgis shows a multipart polygon with no geometry
>>>> errors).
>>>>
>>>> sessionInfo() for my Windows machine (using rgdal 1.0-7 with included
>>>> gdal drivers):
>>>>
>>>> R version 3.2.2 (2015-08-14)
>>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
>>>> LC_MONETARY=English_Canada.1252
>>>> [4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>> other attached packages:
>>>> [1] rgdal_1.0-7 sp_1.2-0
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] tools_3.2.2     grid_3.2.2      lattice_0.20-33
>>>>
>>>>
>>>> I'll send the details for my Mac environment this evening.
>>>>
>>>> I'll dig into the source code as soon as I can - C is a completely
>>>> foreign language to me, so I can't promise anything fast!
>>>>
>>>> Thanks again,
>>>> Andy
>>>>
>>>> On Thu, Oct 22, 2015 at 12:27 AM, Roger Bivand <Roger.Bivand at nhh.no>
>>>> wrote:
>>>>>
>>>>> On Thu, 22 Oct 2015, Andy Teucher wrote:
>>>>>
>>>>>> I?m finding that writeOGR isn?t exporting multipolygons properly using
>>>>>> the GeoJSON driver. I have a simple test case (borrowed from here:
>>>>>>
>>>>>>
>>>>>> http://gis.stackexchange.com/questions/137977/writeogr-alters-multipolygon-holes)
>>>>>> with a geojson string with one multipolygon containing two polygons. I
>>>>>> use readOGR to create a SpatialPolygonsDataFrame out of it, then write
>>>>>> it with writeOGR:
>>>>>>
>>>>>> library(rgdal)
>>>>>>
>>>>>> js <- '{
>>>>>> "type": "MultiPolygon",
>>>>>> "coordinates": [[[[102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0,
>>>>>> 3.0],
>>>>>> [102.0, 2.0]]], [[[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0,
>>>>>> 1.0],
>>>>>> [100.0, 0.0]]]]
>>>>>> } '
>>>>>>
>>>>>> spdf <- readOGR(js, layer='OGRGeoJSON', verbose=FALSE) # Create a
>>>>>> SpatialPoygonsDataFrame
>>>>>>
>>>>>> temp <- tempfile()
>>>>>> writeOGR(spdf, dsn = temp, layer = "", driver="GeoJSON")
>>>>>> cat(readLines(temp))
>>>>>>
>>>>>> # Output:
>>>>>> { "type": "FeatureCollection", "crs": { "type": "name", "properties":
>>>>>> { "name": "urn:ogc:def:crs:OGC:1.3:CRS84" } }, "features": [ { "type":
>>>>>> "Feature", "id": 0, "properties": { "FID": 0 }, "geometry": { "type":
>>>>>> "MultiPolygon", "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ], [
>>>>>> 103.0, 3.0 ], [ 103.0, 2.0 ], [ 102.0, 2.0 ] ], [ [ 100.0, 0.0 ], [
>>>>>> 100.0, 1.0 ], [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] } }
>>>>>> ] }
>>>>>
>>>>>
>>>>>
>>>>> I can replicate this with GDAL 2.0.1 and rgdal 1.0-7 - reading temp in
>>>>> gives
>>>>> the orphaned hole. I'm surprised that passing the js object to
>>>>> readOGR()
>>>>> doesn't fail, but that isn't the source of the problem. spdf appears to
>>>>> be
>>>>> structured correctly. Please provide your GDAL and rgdal versions, and
>>>>> OS
>>>>> details from sessionInfo().
>>>>>
>>>>> We are completely relying on the GDAL drivers here - we can't cherry
>>>>> pick
>>>>> for particular drivers (historically excepting ESRI Shapefile), so your
>>>>> debugging will need to examine writeOGR(), the C code it calls, and the
>>>>> interactions between the rgdal C code and called OGR functions. Please
>>>>> check
>>>>> which other drivers are affected (I think KML is, is GML?). Can you
>>>>> place
>>>>> debugging Rprintf(...); in the rgdal C code to see where this is coming
>>>>> from?
>>>>>
>>>>> I can start looking at this sometime next week, so please make a start
>>>>> yourself; contributions from others are very welcome.
>>>>>
>>>>> Roger
>>>>>
>>>>>>
>>>>>> If you look closely at the output, you can see that the 'coordinates'
>>>>>> array now contains a single polygon array with two coordinate arrays:
>>>>>> the boundary, and a second one which is now treated as a hole of the
>>>>>> first (orphaned as it is outside the bounds of the polygon). The
>>>>>> original 'coordinates' array consists of two polygon arrays, each
>>>>>> consisting of a single coordinate array which defining a polygon (with
>>>>>> no holes), which is correct according the GeoJSON spec:
>>>>>> http://geojson.org/geojson-spec.html#polygon.
>>>>>>
>>>>>> I'm always hesitant to call things a bug, but this doesn't appear to
>>>>>> happen using ogr2ogr on the command line:
>>>>>>
>>>>>> writeOGR(spdf, ".", "test", driver = "ESRI Shapefile") # Write a
>>>>>> shapefile to convert using ogr2ogr
>>>>>> system("ogr2ogr -f GeoJSON test_from_shp.geojson test.shp")
>>>>>> cat(readLines("test_from_shp.geojson"))
>>>>>>
>>>>>> # Output:
>>>>>> { "type": "FeatureCollection",  "features": [ { "type": "Feature",
>>>>>> "properties": { "FID": 0 }, "geometry": { "type": "MultiPolygon",
>>>>>> "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ], [ 103.0, 3.0 ], [
>>>>>> 103.0, 2.0 ], [ 102.0, 2.0 ] ] ], [ [ [ 100.0, 0.0 ], [ 100.0, 1.0 ],
>>>>>> [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] } } ] }
>>>>>>
>>>>>> The resulting output is correct.
>>>>>>
>>>>>>
>>>>>> Thanks in advance for any help on this.
>>>>>>
>>>>>> Andy
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at r-project.org
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> Roger Bivand
>>>>> Department of Economics, Norwegian School of Economics,
>>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>>> e-mail: Roger.Bivand at nhh.no
>>
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Mon Oct 26 23:59:06 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 26 Oct 2015 23:59:06 +0100
Subject: [R-sig-Geo] Exporting Multipolygon geojson with rgdal::writeOGR
In-Reply-To: <CAOdCUxPUdqtT_wRLDaMvqt2d88JETn4iArU1CJU49Pcd=VmsFw@mail.gmail.com>
References: <CAOdCUxNf4nLnXoKYqff=XxOLCWT8YgcRBHWxRMU+heEjeAWJSw@mail.gmail.com>
	<1445569713760.14aec109@Nodemailer>
	<alpine.LFD.2.20.1510230802470.21155@reclus.nhh.no>
	<CAOdCUxPUdqtT_wRLDaMvqt2d88JETn4iArU1CJU49Pcd=VmsFw@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1510262354540.2166@reclus.nhh.no>

On Mon, 26 Oct 2015, Andy Teucher wrote:

> Hi Roger,
>
> Sorry I haven't been much help here - it's not for lack of trying,
> just lack of skills. I've been poring through OGR_write.cpp and trying
> to figure out language and the flow of things... a few thoughts
> occurred to me (which are probably obvious to you):

Thanks, Andy.

We're making some progress but are not yet there. I'm uncertain about 
whether a layer can have Polygon and MultiPolygon features, but we've 
found an OGR function that aims to organise rings for which their 
exterior/interior status is not well known. This passes back the 
appropriate class, bur we then force it to MultiPolygon if any object is a 
MultiPolygon. When we have something to test, we'll get back to you.

Best wishes,

Roger

>
> 1) Is this bug because holes are standalone polygons in sp objects,
> while they are members of polygon objects in geojson, wkt, etc?
>
> 2) On a related note, I notice that a single polygon with a hole is
> identified as a multipolygon containing a single polygon with a hole,
> when using writeOGR and one of the affected drivers.  Practically I
> don't think this matters too much, but it's not quite right.
>
> 3) In lines 116-160 the polygon/multipolygon and line/multiline
> determination is made for the entire layer. Can/should this be made
> for each feature in the layer, as you could have a layer with a
> mixture of single polygons and multipolygons?
>
> 4) I feel like there ought to be one more layer of looping through the
> polyons. e.g.:
>
> loop over each feature;
>     determine whether each feature is a single polygon (length 1 or
> all rings but one are holes), or a multipolygon:
>        if a polygon loop over and add ring(s);
>        if a multipolygon loop over polygons:
>            for each polygon add ring(s) and somehow assign holes to
> parent polygons
>
> Again, apologies if I'm being totally obvious (or way off base).
> Thanks for all your work on these packages, and on this issue.
>
> Andy
>
>
> On Thu, Oct 22, 2015 at 11:07 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> On Fri, 23 Oct 2015, Andy Teucher wrote:
>>
>>> On my Mac, I am running rgdal 1.0-7 and GDAL 1.11.3
>>>
>>>
>>> sessionInfo()
>>>
>>
>> OK, thanks.
>>
>> The problem also affects the SQLite driver (the CRAN binaries do not have
>> this driver). Could someone please check the PostGIS driver - my guess is
>> that all OGC SFS compliant drivers may be affected.
>>
>> Could somebody also please check whether this is a recently introduced issue
>> or not? For example somebody still on rgdal < 1.0? src/OGR_write.cpp was
>> changed 2015-08-21, but the last previous change was 2015-06-11, then
>> 2015-05-31, 2014-08-17 ... from the ChangeLog visible on the package CRAN
>> page.
>>
>> Roger
>>
>>
>>>
>>>
>>>
>>>
>>> R version 3.2.2 (2015-08-14)
>>>
>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>>
>>> Running under: OS X 10.11 (El Capitan)
>>>
>>>
>>>
>>>
>>> locale:
>>>
>>> [1] en_CA.UTF-8/en_CA.UTF-8/en_CA.UTF-8/C/en_CA.UTF-8/en_CA.UTF-8
>>>
>>>
>>>
>>>
>>> attached base packages:
>>>
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>>
>>>
>>>
>>> other attached packages:
>>>
>>> [1] rgdal_1.0-7 sp_1.2-1
>>>
>>>
>>>
>>>
>>> loaded via a namespace (and not attached):
>>>
>>> [1] tools_3.2.2     grid_3.2.2      lattice_0.20-33
>>>
>>>
>>>
>>>
>>> Andy
>>>
>>> On Thu, Oct 22, 2015 at 11:28 AM, Andy Teucher <andy.teucher at gmail.com>
>>> wrote:
>>>
>>>> One more test: WKT has the same issue:
>>>> library(rgdal)
>>>> js <- '{
>>>> "type": "MultiPolygon",
>>>> "coordinates": [[[[102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0, 3.0],
>>>> [102.0, 2.0]]], [[[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0],
>>>> [100.0, 0.0]]]]
>>>> } '
>>>> spdf <- readOGR(js, layer='OGRGeoJSON', verbose=FALSE)
>>>> writeOGR(spdf, dsn = "test.csv", layer = "test", driver="CSV",
>>>> layer_options = "GEOMETRY=AS_WKT")
>>>> cat(readLines("test.csv"), sep = "\n")
>>>> WKT,FID,
>>>> "MULTIPOLYGON (((102 2,102 3,103 3,103 2,102 2),(100 0,100 1,101 1,101
>>>> 0,100 0)))",0
>>>> It should be:
>>>> WKT,FID,
>>>> "MULTIPOLYGON (((102 2,102 3,103 3,103 2,102 2)),((100 0,100 1,101
>>>> 1,101 0,100 0)))",0
>>>> Andy
>>>> On Thu, Oct 22, 2015 at 10:36 AM, Andy Teucher <andy.teucher at gmail.com>
>>>> wrote:
>>>>>
>>>>> Thanks very much Roger.
>>>>>
>>>>> I've replicated this on my work machine (Windows) and on my Mac at home.
>>>>>
>>>>> KML and GML are both affected. ESRI shapefile works fine and, though
>>>>> I'm not very familiar with the format, 'MapInfo File' works too
>>>>> (loading the file in qgis shows a multipart polygon with no geometry
>>>>> errors).
>>>>>
>>>>> sessionInfo() for my Windows machine (using rgdal 1.0-7 with included
>>>>> gdal drivers):
>>>>>
>>>>> R version 3.2.2 (2015-08-14)
>>>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>>>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>>>>
>>>>> locale:
>>>>> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
>>>>> LC_MONETARY=English_Canada.1252
>>>>> [4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252
>>>>>
>>>>> attached base packages:
>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>
>>>>> other attached packages:
>>>>> [1] rgdal_1.0-7 sp_1.2-0
>>>>>
>>>>> loaded via a namespace (and not attached):
>>>>> [1] tools_3.2.2     grid_3.2.2      lattice_0.20-33
>>>>>
>>>>>
>>>>> I'll send the details for my Mac environment this evening.
>>>>>
>>>>> I'll dig into the source code as soon as I can - C is a completely
>>>>> foreign language to me, so I can't promise anything fast!
>>>>>
>>>>> Thanks again,
>>>>> Andy
>>>>>
>>>>> On Thu, Oct 22, 2015 at 12:27 AM, Roger Bivand <Roger.Bivand at nhh.no>
>>>>> wrote:
>>>>>>
>>>>>> On Thu, 22 Oct 2015, Andy Teucher wrote:
>>>>>>
>>>>>>> I?m finding that writeOGR isn?t exporting multipolygons properly using
>>>>>>> the GeoJSON driver. I have a simple test case (borrowed from here:
>>>>>>>
>>>>>>>
>>>>>>> http://gis.stackexchange.com/questions/137977/writeogr-alters-multipolygon-holes)
>>>>>>> with a geojson string with one multipolygon containing two polygons. I
>>>>>>> use readOGR to create a SpatialPolygonsDataFrame out of it, then write
>>>>>>> it with writeOGR:
>>>>>>>
>>>>>>> library(rgdal)
>>>>>>>
>>>>>>> js <- '{
>>>>>>> "type": "MultiPolygon",
>>>>>>> "coordinates": [[[[102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0,
>>>>>>> 3.0],
>>>>>>> [102.0, 2.0]]], [[[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0,
>>>>>>> 1.0],
>>>>>>> [100.0, 0.0]]]]
>>>>>>> } '
>>>>>>>
>>>>>>> spdf <- readOGR(js, layer='OGRGeoJSON', verbose=FALSE) # Create a
>>>>>>> SpatialPoygonsDataFrame
>>>>>>>
>>>>>>> temp <- tempfile()
>>>>>>> writeOGR(spdf, dsn = temp, layer = "", driver="GeoJSON")
>>>>>>> cat(readLines(temp))
>>>>>>>
>>>>>>> # Output:
>>>>>>> { "type": "FeatureCollection", "crs": { "type": "name", "properties":
>>>>>>> { "name": "urn:ogc:def:crs:OGC:1.3:CRS84" } }, "features": [ { "type":
>>>>>>> "Feature", "id": 0, "properties": { "FID": 0 }, "geometry": { "type":
>>>>>>> "MultiPolygon", "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ], [
>>>>>>> 103.0, 3.0 ], [ 103.0, 2.0 ], [ 102.0, 2.0 ] ], [ [ 100.0, 0.0 ], [
>>>>>>> 100.0, 1.0 ], [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] } }
>>>>>>> ] }
>>>>>>
>>>>>>
>>>>>>
>>>>>> I can replicate this with GDAL 2.0.1 and rgdal 1.0-7 - reading temp in
>>>>>> gives
>>>>>> the orphaned hole. I'm surprised that passing the js object to
>>>>>> readOGR()
>>>>>> doesn't fail, but that isn't the source of the problem. spdf appears to
>>>>>> be
>>>>>> structured correctly. Please provide your GDAL and rgdal versions, and
>>>>>> OS
>>>>>> details from sessionInfo().
>>>>>>
>>>>>> We are completely relying on the GDAL drivers here - we can't cherry
>>>>>> pick
>>>>>> for particular drivers (historically excepting ESRI Shapefile), so your
>>>>>> debugging will need to examine writeOGR(), the C code it calls, and the
>>>>>> interactions between the rgdal C code and called OGR functions. Please
>>>>>> check
>>>>>> which other drivers are affected (I think KML is, is GML?). Can you
>>>>>> place
>>>>>> debugging Rprintf(...); in the rgdal C code to see where this is coming
>>>>>> from?
>>>>>>
>>>>>> I can start looking at this sometime next week, so please make a start
>>>>>> yourself; contributions from others are very welcome.
>>>>>>
>>>>>> Roger
>>>>>>
>>>>>>>
>>>>>>> If you look closely at the output, you can see that the 'coordinates'
>>>>>>> array now contains a single polygon array with two coordinate arrays:
>>>>>>> the boundary, and a second one which is now treated as a hole of the
>>>>>>> first (orphaned as it is outside the bounds of the polygon). The
>>>>>>> original 'coordinates' array consists of two polygon arrays, each
>>>>>>> consisting of a single coordinate array which defining a polygon (with
>>>>>>> no holes), which is correct according the GeoJSON spec:
>>>>>>> http://geojson.org/geojson-spec.html#polygon.
>>>>>>>
>>>>>>> I'm always hesitant to call things a bug, but this doesn't appear to
>>>>>>> happen using ogr2ogr on the command line:
>>>>>>>
>>>>>>> writeOGR(spdf, ".", "test", driver = "ESRI Shapefile") # Write a
>>>>>>> shapefile to convert using ogr2ogr
>>>>>>> system("ogr2ogr -f GeoJSON test_from_shp.geojson test.shp")
>>>>>>> cat(readLines("test_from_shp.geojson"))
>>>>>>>
>>>>>>> # Output:
>>>>>>> { "type": "FeatureCollection",  "features": [ { "type": "Feature",
>>>>>>> "properties": { "FID": 0 }, "geometry": { "type": "MultiPolygon",
>>>>>>> "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ], [ 103.0, 3.0 ], [
>>>>>>> 103.0, 2.0 ], [ 102.0, 2.0 ] ] ], [ [ [ 100.0, 0.0 ], [ 100.0, 1.0 ],
>>>>>>> [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] } } ] }
>>>>>>>
>>>>>>> The resulting output is correct.
>>>>>>>
>>>>>>>
>>>>>>> Thanks in advance for any help on this.
>>>>>>>
>>>>>>> Andy
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-Geo mailing list
>>>>>>> R-sig-Geo at r-project.org
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> Roger Bivand
>>>>>> Department of Economics, Norwegian School of Economics,
>>>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From andy.teucher at gmail.com  Tue Oct 27 00:10:25 2015
From: andy.teucher at gmail.com (Andy Teucher)
Date: Mon, 26 Oct 2015 16:10:25 -0700
Subject: [R-sig-Geo] Exporting Multipolygon geojson with rgdal::writeOGR
In-Reply-To: <alpine.LFD.2.20.1510262354540.2166@reclus.nhh.no>
References: <CAOdCUxNf4nLnXoKYqff=XxOLCWT8YgcRBHWxRMU+heEjeAWJSw@mail.gmail.com>
	<1445569713760.14aec109@Nodemailer>
	<alpine.LFD.2.20.1510230802470.21155@reclus.nhh.no>
	<CAOdCUxPUdqtT_wRLDaMvqt2d88JETn4iArU1CJU49Pcd=VmsFw@mail.gmail.com>
	<alpine.LFD.2.20.1510262354540.2166@reclus.nhh.no>
Message-ID: <CAOdCUxM-PSGGXgjo7aDrc5w8s3jErCtxmPeCoOO+ZgabiTqOdw@mail.gmail.com>

Fantastic, thanks Roger. I will follow along in the r-forge repository.

Andy

On Mon, Oct 26, 2015 at 3:59 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Mon, 26 Oct 2015, Andy Teucher wrote:
>
>> Hi Roger,
>>
>> Sorry I haven't been much help here - it's not for lack of trying,
>> just lack of skills. I've been poring through OGR_write.cpp and trying
>> to figure out language and the flow of things... a few thoughts
>> occurred to me (which are probably obvious to you):
>
>
> Thanks, Andy.
>
> We're making some progress but are not yet there. I'm uncertain about
> whether a layer can have Polygon and MultiPolygon features, but we've found
> an OGR function that aims to organise rings for which their
> exterior/interior status is not well known. This passes back the appropriate
> class, bur we then force it to MultiPolygon if any object is a MultiPolygon.
> When we have something to test, we'll get back to you.
>
> Best wishes,
>
> Roger
>
>
>>
>> 1) Is this bug because holes are standalone polygons in sp objects,
>> while they are members of polygon objects in geojson, wkt, etc?
>>
>> 2) On a related note, I notice that a single polygon with a hole is
>> identified as a multipolygon containing a single polygon with a hole,
>> when using writeOGR and one of the affected drivers.  Practically I
>> don't think this matters too much, but it's not quite right.
>>
>> 3) In lines 116-160 the polygon/multipolygon and line/multiline
>> determination is made for the entire layer. Can/should this be made
>> for each feature in the layer, as you could have a layer with a
>> mixture of single polygons and multipolygons?
>>
>> 4) I feel like there ought to be one more layer of looping through the
>> polyons. e.g.:
>>
>> loop over each feature;
>>     determine whether each feature is a single polygon (length 1 or
>> all rings but one are holes), or a multipolygon:
>>        if a polygon loop over and add ring(s);
>>        if a multipolygon loop over polygons:
>>            for each polygon add ring(s) and somehow assign holes to
>> parent polygons
>>
>> Again, apologies if I'm being totally obvious (or way off base).
>> Thanks for all your work on these packages, and on this issue.
>>
>> Andy
>>
>>
>> On Thu, Oct 22, 2015 at 11:07 PM, Roger Bivand <Roger.Bivand at nhh.no>
>> wrote:
>>>
>>> On Fri, 23 Oct 2015, Andy Teucher wrote:
>>>
>>>> On my Mac, I am running rgdal 1.0-7 and GDAL 1.11.3
>>>>
>>>>
>>>> sessionInfo()
>>>>
>>>
>>> OK, thanks.
>>>
>>> The problem also affects the SQLite driver (the CRAN binaries do not have
>>> this driver). Could someone please check the PostGIS driver - my guess is
>>> that all OGC SFS compliant drivers may be affected.
>>>
>>> Could somebody also please check whether this is a recently introduced
>>> issue
>>> or not? For example somebody still on rgdal < 1.0? src/OGR_write.cpp was
>>> changed 2015-08-21, but the last previous change was 2015-06-11, then
>>> 2015-05-31, 2014-08-17 ... from the ChangeLog visible on the package CRAN
>>> page.
>>>
>>> Roger
>>>
>>>
>>>>
>>>>
>>>>
>>>>
>>>> R version 3.2.2 (2015-08-14)
>>>>
>>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>>>
>>>> Running under: OS X 10.11 (El Capitan)
>>>>
>>>>
>>>>
>>>>
>>>> locale:
>>>>
>>>> [1] en_CA.UTF-8/en_CA.UTF-8/en_CA.UTF-8/C/en_CA.UTF-8/en_CA.UTF-8
>>>>
>>>>
>>>>
>>>>
>>>> attached base packages:
>>>>
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>>
>>>>
>>>>
>>>> other attached packages:
>>>>
>>>> [1] rgdal_1.0-7 sp_1.2-1
>>>>
>>>>
>>>>
>>>>
>>>> loaded via a namespace (and not attached):
>>>>
>>>> [1] tools_3.2.2     grid_3.2.2      lattice_0.20-33
>>>>
>>>>
>>>>
>>>>
>>>> Andy
>>>>
>>>> On Thu, Oct 22, 2015 at 11:28 AM, Andy Teucher <andy.teucher at gmail.com>
>>>> wrote:
>>>>
>>>>> One more test: WKT has the same issue:
>>>>> library(rgdal)
>>>>> js <- '{
>>>>> "type": "MultiPolygon",
>>>>> "coordinates": [[[[102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0,
>>>>> 3.0],
>>>>> [102.0, 2.0]]], [[[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0,
>>>>> 1.0],
>>>>> [100.0, 0.0]]]]
>>>>> } '
>>>>> spdf <- readOGR(js, layer='OGRGeoJSON', verbose=FALSE)
>>>>> writeOGR(spdf, dsn = "test.csv", layer = "test", driver="CSV",
>>>>> layer_options = "GEOMETRY=AS_WKT")
>>>>> cat(readLines("test.csv"), sep = "\n")
>>>>> WKT,FID,
>>>>> "MULTIPOLYGON (((102 2,102 3,103 3,103 2,102 2),(100 0,100 1,101 1,101
>>>>> 0,100 0)))",0
>>>>> It should be:
>>>>> WKT,FID,
>>>>> "MULTIPOLYGON (((102 2,102 3,103 3,103 2,102 2)),((100 0,100 1,101
>>>>> 1,101 0,100 0)))",0
>>>>> Andy
>>>>> On Thu, Oct 22, 2015 at 10:36 AM, Andy Teucher <andy.teucher at gmail.com>
>>>>> wrote:
>>>>>>
>>>>>>
>>>>>> Thanks very much Roger.
>>>>>>
>>>>>> I've replicated this on my work machine (Windows) and on my Mac at
>>>>>> home.
>>>>>>
>>>>>> KML and GML are both affected. ESRI shapefile works fine and, though
>>>>>> I'm not very familiar with the format, 'MapInfo File' works too
>>>>>> (loading the file in qgis shows a multipart polygon with no geometry
>>>>>> errors).
>>>>>>
>>>>>> sessionInfo() for my Windows machine (using rgdal 1.0-7 with included
>>>>>> gdal drivers):
>>>>>>
>>>>>> R version 3.2.2 (2015-08-14)
>>>>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>>>>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>>>>>
>>>>>> locale:
>>>>>> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
>>>>>> LC_MONETARY=English_Canada.1252
>>>>>> [4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252
>>>>>>
>>>>>> attached base packages:
>>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>>
>>>>>> other attached packages:
>>>>>> [1] rgdal_1.0-7 sp_1.2-0
>>>>>>
>>>>>> loaded via a namespace (and not attached):
>>>>>> [1] tools_3.2.2     grid_3.2.2      lattice_0.20-33
>>>>>>
>>>>>>
>>>>>> I'll send the details for my Mac environment this evening.
>>>>>>
>>>>>> I'll dig into the source code as soon as I can - C is a completely
>>>>>> foreign language to me, so I can't promise anything fast!
>>>>>>
>>>>>> Thanks again,
>>>>>> Andy
>>>>>>
>>>>>> On Thu, Oct 22, 2015 at 12:27 AM, Roger Bivand <Roger.Bivand at nhh.no>
>>>>>> wrote:
>>>>>>>
>>>>>>>
>>>>>>> On Thu, 22 Oct 2015, Andy Teucher wrote:
>>>>>>>
>>>>>>>> I?m finding that writeOGR isn?t exporting multipolygons properly
>>>>>>>> using
>>>>>>>> the GeoJSON driver. I have a simple test case (borrowed from here:
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> http://gis.stackexchange.com/questions/137977/writeogr-alters-multipolygon-holes)
>>>>>>>> with a geojson string with one multipolygon containing two polygons.
>>>>>>>> I
>>>>>>>> use readOGR to create a SpatialPolygonsDataFrame out of it, then
>>>>>>>> write
>>>>>>>> it with writeOGR:
>>>>>>>>
>>>>>>>> library(rgdal)
>>>>>>>>
>>>>>>>> js <- '{
>>>>>>>> "type": "MultiPolygon",
>>>>>>>> "coordinates": [[[[102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0,
>>>>>>>> 3.0],
>>>>>>>> [102.0, 2.0]]], [[[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0,
>>>>>>>> 1.0],
>>>>>>>> [100.0, 0.0]]]]
>>>>>>>> } '
>>>>>>>>
>>>>>>>> spdf <- readOGR(js, layer='OGRGeoJSON', verbose=FALSE) # Create a
>>>>>>>> SpatialPoygonsDataFrame
>>>>>>>>
>>>>>>>> temp <- tempfile()
>>>>>>>> writeOGR(spdf, dsn = temp, layer = "", driver="GeoJSON")
>>>>>>>> cat(readLines(temp))
>>>>>>>>
>>>>>>>> # Output:
>>>>>>>> { "type": "FeatureCollection", "crs": { "type": "name",
>>>>>>>> "properties":
>>>>>>>> { "name": "urn:ogc:def:crs:OGC:1.3:CRS84" } }, "features": [ {
>>>>>>>> "type":
>>>>>>>> "Feature", "id": 0, "properties": { "FID": 0 }, "geometry": {
>>>>>>>> "type":
>>>>>>>> "MultiPolygon", "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ],
>>>>>>>> [
>>>>>>>> 103.0, 3.0 ], [ 103.0, 2.0 ], [ 102.0, 2.0 ] ], [ [ 100.0, 0.0 ], [
>>>>>>>> 100.0, 1.0 ], [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] }
>>>>>>>> }
>>>>>>>> ] }
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> I can replicate this with GDAL 2.0.1 and rgdal 1.0-7 - reading temp
>>>>>>> in
>>>>>>> gives
>>>>>>> the orphaned hole. I'm surprised that passing the js object to
>>>>>>> readOGR()
>>>>>>> doesn't fail, but that isn't the source of the problem. spdf appears
>>>>>>> to
>>>>>>> be
>>>>>>> structured correctly. Please provide your GDAL and rgdal versions,
>>>>>>> and
>>>>>>> OS
>>>>>>> details from sessionInfo().
>>>>>>>
>>>>>>> We are completely relying on the GDAL drivers here - we can't cherry
>>>>>>> pick
>>>>>>> for particular drivers (historically excepting ESRI Shapefile), so
>>>>>>> your
>>>>>>> debugging will need to examine writeOGR(), the C code it calls, and
>>>>>>> the
>>>>>>> interactions between the rgdal C code and called OGR functions.
>>>>>>> Please
>>>>>>> check
>>>>>>> which other drivers are affected (I think KML is, is GML?). Can you
>>>>>>> place
>>>>>>> debugging Rprintf(...); in the rgdal C code to see where this is
>>>>>>> coming
>>>>>>> from?
>>>>>>>
>>>>>>> I can start looking at this sometime next week, so please make a
>>>>>>> start
>>>>>>> yourself; contributions from others are very welcome.
>>>>>>>
>>>>>>> Roger
>>>>>>>
>>>>>>>>
>>>>>>>> If you look closely at the output, you can see that the
>>>>>>>> 'coordinates'
>>>>>>>> array now contains a single polygon array with two coordinate
>>>>>>>> arrays:
>>>>>>>> the boundary, and a second one which is now treated as a hole of the
>>>>>>>> first (orphaned as it is outside the bounds of the polygon). The
>>>>>>>> original 'coordinates' array consists of two polygon arrays, each
>>>>>>>> consisting of a single coordinate array which defining a polygon
>>>>>>>> (with
>>>>>>>> no holes), which is correct according the GeoJSON spec:
>>>>>>>> http://geojson.org/geojson-spec.html#polygon.
>>>>>>>>
>>>>>>>> I'm always hesitant to call things a bug, but this doesn't appear to
>>>>>>>> happen using ogr2ogr on the command line:
>>>>>>>>
>>>>>>>> writeOGR(spdf, ".", "test", driver = "ESRI Shapefile") # Write a
>>>>>>>> shapefile to convert using ogr2ogr
>>>>>>>> system("ogr2ogr -f GeoJSON test_from_shp.geojson test.shp")
>>>>>>>> cat(readLines("test_from_shp.geojson"))
>>>>>>>>
>>>>>>>> # Output:
>>>>>>>> { "type": "FeatureCollection",  "features": [ { "type": "Feature",
>>>>>>>> "properties": { "FID": 0 }, "geometry": { "type": "MultiPolygon",
>>>>>>>> "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ], [ 103.0, 3.0 ],
>>>>>>>> [
>>>>>>>> 103.0, 2.0 ], [ 102.0, 2.0 ] ] ], [ [ [ 100.0, 0.0 ], [ 100.0, 1.0
>>>>>>>> ],
>>>>>>>> [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] } } ] }
>>>>>>>>
>>>>>>>> The resulting output is correct.
>>>>>>>>
>>>>>>>>
>>>>>>>> Thanks in advance for any help on this.
>>>>>>>>
>>>>>>>> Andy
>>>>>>>>
>>>>>>>> _______________________________________________
>>>>>>>> R-sig-Geo mailing list
>>>>>>>> R-sig-Geo at r-project.org
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>> Roger Bivand
>>>>>>> Department of Economics, Norwegian School of Economics,
>>>>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>
>>>>
>>>>
>>>
>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics,
>>> Helleveien 30, N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> e-mail: Roger.Bivand at nhh.no
>>
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no


From gab.cozzi at gmail.com  Tue Oct 27 09:37:58 2015
From: gab.cozzi at gmail.com (Gabriele Cozzi)
Date: Tue, 27 Oct 2015 09:37:58 +0100
Subject: [R-sig-Geo] spsample: random points within a radius r from observed
	locations
Message-ID: <CADr8yXCrA7YtEqg48VOV=Hue2Vyh0bWa64LyXJSk+LV7acQsYQ@mail.gmail.com>

Dear list,

I have a set of relocation data (call it pnts).

What I want to do is to create, for each relocation of pnts, n alternative
relocations within a radius r.

My intuitive approach was to use of the spsample function in the sp
package.

buffer <- gBuffer(spgeom = pnts, width=r,  byid=T)
randompoints <- spsample(x=buffer, n=10, type="random", iter=10)

The problem here is that spsample creates 10 random points over all
Polygons in the buffer object and not for each Polygon within buffer.

Is there a function that returns random locations by passing a
SpatialPoints-class object to it and a radius r?

Any help is appreciated.

Gabriele



-- 
Gabriele Cozzi
Postdoctoral Research Associate
Population Ecology Research Group
http://www.popecol.org

Zurich University
Institute of Evolutionary Biology and Environmental Studies
Winterthurerstr. 190
8057 Zurich - Switzerland
E-mail: gabriele.cozzi at uzh.ch
Office: 34-J-38
Phone: +41(0)44 635 47 56
Fax: +41(0)16355711
http://www.ieu.uzh.ch

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Oct 27 09:54:22 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 27 Oct 2015 21:54:22 +1300
Subject: [R-sig-Geo] [FORGED] spsample: random points within a radius r
 from observed locations
In-Reply-To: <CADr8yXCrA7YtEqg48VOV=Hue2Vyh0bWa64LyXJSk+LV7acQsYQ@mail.gmail.com>
References: <CADr8yXCrA7YtEqg48VOV=Hue2Vyh0bWa64LyXJSk+LV7acQsYQ@mail.gmail.com>
Message-ID: <562F3BBE.7070608@auckland.ac.nz>

On 27/10/15 21:37, Gabriele Cozzi wrote:
> Dear list,
>
> I have a set of relocation data (call it pnts).
>
> What I want to do is to create, for each relocation of pnts, n alternative
> relocations within a radius r.
>
> My intuitive approach was to use of the spsample function in the sp
> package.
>
> buffer <- gBuffer(spgeom = pnts, width=r,  byid=T)
> randompoints <- spsample(x=buffer, n=10, type="random", iter=10)
>
> The problem here is that spsample creates 10 random points over all
> Polygons in the buffer object and not for each Polygon within buffer.
>
> Is there a function that returns random locations by passing a
> SpatialPoints-class object to it and a radius r?
>
> Any help is appreciated.

I don't know what is meant by "relocation" data, but I am pretty sure 
that you could easily accomplish your goal using the spatstat package. 
You would have to adjust your terminology and thought patterns somewhat, 
however.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From rafael.wueest at gmail.com  Tue Oct 27 10:28:44 2015
From: rafael.wueest at gmail.com (=?UTF-8?Q?Rafael_W=c3=bcest?=)
Date: Tue, 27 Oct 2015 10:28:44 +0100
Subject: [R-sig-Geo] spsample: random points within a radius r from
 observed locations
In-Reply-To: <CADr8yXCrA7YtEqg48VOV=Hue2Vyh0bWa64LyXJSk+LV7acQsYQ@mail.gmail.com>
References: <CADr8yXCrA7YtEqg48VOV=Hue2Vyh0bWa64LyXJSk+LV7acQsYQ@mail.gmail.com>
Message-ID: <562F43CC.8040809@gmail.com>

Hi Gabriele

Don't know of such a function, but the following should return 10 random 
locations per polygon in 'buffer'

randompoints.list <- sapply(buffer at polygons, spsample, n = 10, type = 
'random')
randompoints <- do.call(rbind, randompoints.list)

May be a start...

Cheers,
Rafael


On 27.10.15 09:37, Gabriele Cozzi wrote:
> Dear list,
>
> I have a set of relocation data (call it pnts).
>
> What I want to do is to create, for each relocation of pnts, n alternative
> relocations within a radius r.
>
> My intuitive approach was to use of the spsample function in the sp
> package.
>
> buffer <- gBuffer(spgeom = pnts, width=r,  byid=T)
> randompoints <- spsample(x=buffer, n=10, type="random", iter=10)
>
> The problem here is that spsample creates 10 random points over all
> Polygons in the buffer object and not for each Polygon within buffer.
>
> Is there a function that returns random locations by passing a
> SpatialPoints-class object to it and a radius r?
>
> Any help is appreciated.
>
> Gabriele
>
>
>

-- 
Rafael W?est
rafael.wueest at gmail.com
http://www.rowueest.net


From Rainer at krugs.de  Tue Oct 27 14:11:10 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Tue, 27 Oct 2015 14:11:10 +0100
Subject: [R-sig-Geo] spgrass6, readVECT and overwriting ?
In-Reply-To: <CAGfc75mgjHT94aZm7bEFkLO5628K-8-UR--Z-FQbpndX3tsSsA@mail.gmail.com>
	(Mathieu Rajerison's message of "Tue, 27 Oct 2015 13:06:19 +0100")
References: <CAGfc75kOhMzWuXe_jm+A81-MoiSdRanoXViAycvKGoPLuRzwfw@mail.gmail.com>
	<m2mvv87b5l.fsf@krugs.de>
	<CAGfc75mgjHT94aZm7bEFkLO5628K-8-UR--Z-FQbpndX3tsSsA@mail.gmail.com>
Message-ID: <m2lhaoe9sh.fsf@krugs.de>

Mathieu Rajerison <mathieu.rajerison at gmail.com> writes:

> Dear Mr Krug,
>

I'll Cc the R-sig-geo list in to keep the conversation there for future
reference and for other users who might have the same problem.

> Sorry in advance for my english.

Don't worry abut your English - it is perfectly fine.

>
> My question was not about debugging, but about a potentiel generic
> behaviour of spgrass6.
>
> I should have reformulated my question in a simpler manner : does spgrass6
> allow overwriting an existing dataset when using readVECT function ?

The functions readVect / RAST are using temporary files - you are right,
but they should delete these upon exit. So if they do nbot do this, it
is a bug.

>
> 1) no version information about R and GRASS (there are several GRASS 6
> versions)
> I've just put it at the end of this post.
> 2) no session information i.e. package versions used
> the latest spgrass6
> 3) no information about the OS (I guess it is windows based on the
> Source path above)
> you're right

OK - thanks.

> 4) no reproducible example which could be easily done by using the GRASS

As I said - if you manually have to delete the temporary files, then
there is a bug in the package. Could you please provide a reproducible
example, using one of the example data sets from GRASS, so that I can
look at it?

> 5) as far as I can see, in the newest version of spgrass6 there is no
> function readVECT()
> Yes, there is, as you will see on page 14 of the documentation.

Sorry - overlooked it.

>
> Finally, I solved the problem by using the following hint, "clean" being
> the name of my temporary shapefile dataset :
>   l = list.files("D:/GRASSDB/paca/mapset/.tmp", "^clean.*$"); l =
> file.path("D:/GRASSDB/paca/mapset/.tmp", l)
>   lapply(l,  file.remove)
>   execGRASS("v.out.ogr", parameters=list(input="clean", type="line",
> dsn="D:/GRASSDB/paca/mapset/.tmp", olayer="clean", format="ESRI_Shapefile"))

OK - reformated, the code looks as follow:

--8<---------------cut here---------------start------------->8---
l = list.files("D:/GRASSDB/paca/mapset/.tmp", "^clean.*$")
l = file.path("D:/GRASSDB/paca/mapset/.tmp", l)
lapply(l,  file.remove)
execGRASS( "v.out.ogr",
           parameters=list(input="clean", type="line",dsn="D:/GRASSDB/paca/mapset/.tmp", olayer="clean", format="ESRI_Shapefile"))
--8<---------------cut here---------------end--------------->8---

as a side note, you should be able to do

file.remove( list.files(path = "D:/GRASSDB/paca/mapset/.tmp", Pattern =
"^clean.*$", full.names = TRUE) )

or

unlink("D:/GRASSDB/paca/mapset/.tmp/clean.*")

instead of the first three commands.

Now - in your example, you don't use the readVECT() function?

If you check in the GRASS help for v.out.ogr, you can specify the
overwrite flag and the exported layer will be overwritten.

But I have the feeling you are doing something in a to complicated way.

What is it you want to do, and e=what is the problem you have or the
error message you get?

Cheers,

Rainer

>
>
>> R.Version()
> $platform
> [1] "x86_64-w64-mingw32"
> $arch
> [1] "x86_64"
> $os
> [1] "mingw32"
>
> $system
> [1] "x86_64, mingw32"
> (...)
> $version.string
> [1] "R version 3.1.2 (2014-10-31)"
> $nickname
> [1] "Pumpkin Helmet"
>
> I will happily look int this if you can provide the necessary info.
>
> Cheers,
>
> Mathieu
>
> 2015-10-24 13:34 GMT+02:00 Rainer M Krug <Rainer at krugs.de>:
>
>> Mathieu Rajerison <mathieu.rajerison at gmail.com> writes:
>>
>> > Hi,
>> >
>> > I'm using spgrass6 and I use readVECT function in a loop.
>> >
>> > Using it causes an error because it doesn't overwrite the the temporary
>> > shapefile..
>> >
>> >> thin = readVECT(vname="zoneBDTOPOthin")
>> > with_c: argument reversed from version 0.7-11 and in GRASS 6
>> > ERROR :Layer <zoneBDTO> already exists in OGR data source
>> >         'D:/GRASSDB/paca/mapset/.tmp'
>> > OGR data source with driver: ESRI Shapefile
>> > Source: "D:/GRASSDB/paca/mapset/.tmp", layer: "zoneBDTO"
>> > with 770 features
>> > It has 3 fields
>> > Warning message:
>> > running command 'v.out.ogr.exe -e -c input=zoneBDTOPOthin2 type=line
>> > layer=1 dsn=D:/GRASSDB/paca/mapset/.tmp olayer=zoneBDTO
>> > format=ESRI_Shapefile' had status 1
>> >
>> >
>> > I wonder how to specify to spgrass that I want to overwrite the file in
>> > readVECT, although I know using execGRASS and v.out.ogr with the
>> > appropriate overwrite flags would do the job.
>> >
>> > Thanks in advance for the answer..
>>
>> One reason why probably nobody replied is that
>>
>> 1) no version information about R and GRASS (there are several GRASS 6
>> versions)
>> 2) no session information i.e. package versions used
>> 3) no information about the OS (I guess it is windows based on the
>> Source path above)
>> 4) no reproducible example which could be easily done by using the GRASS
>> 5) as far as I can see, in the newest version of spgrass6 there is no
>> function readVECT()
>>
>> So I would suggest to provide the info and give a reproducible example
>> using a GRASS sample dataset
>> (see https://grass.osgeo.org/download/sample-data/ - the Spearfish
>> dataset is probably the best)
>>
>> I will happily look int this if you can provide the necessary info.
>>
>> Cheers,
>>
>> Rainer
>>
>> >
>> > Mathieu
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-Geo mailing list
>> > R-sig-Geo at r-project.org
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> --
>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
>> Biology, UCT), Dipl. Phys. (Germany)
>>
>> Centre of Excellence for Invasion Biology
>> Stellenbosch University
>> South Africa
>>
>> Tel :       +33 - (0)9 53 10 27 44
>> Cell:       +33 - (0)6 85 62 59 98
>> Fax :       +33 - (0)9 58 10 27 44
>>
>> Fax (D):    +49 - (0)3 21 21 25 22 44
>>
>> email:      Rainer at krugs.de
>>
>> Skype:      RMkrug
>>
>> PGP: 0x0F52F982
>>

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151027/f900b408/attachment.bin>

From mausv at uni-muenster.de  Tue Oct 27 14:47:32 2015
From: mausv at uni-muenster.de (Victor Maus)
Date: Tue, 27 Oct 2015 14:47:32 +0100
Subject: [R-sig-Geo] Raster multi-band time series analysis
In-Reply-To: <CAHYDKLZGOeMLAS-AL3UUvBJfw-pXnkvp_NORrLXUUX2zrhyjFg@mail.gmail.com>
References: <562E0D1C.5030102@uni-muenster.de> <562E292E.6070801@wur.nl>
	<CAHYDKLZGOeMLAS-AL3UUvBJfw-pXnkvp_NORrLXUUX2zrhyjFg@mail.gmail.com>
Message-ID: <562F8074.6010302@uni-muenster.de>

Hi Dominik and Lo?c,

thank you for your suggestions. I solved the problem using 
spatial.tools::rasterEngine. Please see the example below.

Lo?c, I tried to adapt your function "mc.calc" to use raster::overlay, 
however it didn't work out. The raster::overlay iterates over layers, 
therefore, I didn't get the whole time series in my analysis.


### A simple example using spatial.tools
# Computes the average of the time series for each pixel

library(spatial.tools)

ndvi = brick("./MOD13Q1/0___TIFF/250m_16_days_NDVI.tif") # Each layer is 
a sample in the time series
evi = brick("./MOD13Q1/0___TIFF/250m_16_days_EVI.tif")   # Each layer is 
a sample in the time series

fun = function(ndvi, evi, P, ...){
   # Receive rasters as 3D arrays (col, row, band)
   N = nrow(ndvi)
   M = ncol(ndvi)
   avg = array(NA, dim = c(N,M,P) )
   for(i in 1:nrow(ndvi))
     for(j in 1:ncol(ndvi)){
       avg[i,j,1] = mean(ndvi[i,j,])
       avg[i,j,2] = mean(evi[i,j,])
     }
   avg
}

P = 2 # Number of layers in the output
sfQuickInit(cpus=2)
res = rasterEngine(
   fun = fun,
   args = list(P=P),
   ndvi = ndvi,
   evi  = evi,
   outbands = P)
sfQuickStop()


Thank you!


Best,
Victor






On 10/26/2015 04:18 PM, Dominik Schneider wrote:
> Check out the spatial.tools package for parallel processing with the raster
> package.
>
>
>
> On Mon, Oct 26, 2015 at 7:22 AM, Lo?c Dutrieux <loic.dutrieux at wur.nl> wrote:
>
>> Hi Victor,
>>
>> I don't have much experience with beginCluster; however, I have written a
>> parallel version of raster::calc a little while ago that uses forking.
>> https://github.com/dutri001/bfastSpatial/blob/master/R/mc.calc.R
>>
>> calc and overlay are analogue so that it shouldn't be too hard to extend
>> this function to overlay, using an undefined number of rasterStack or
>> Bricks as input. You will need a bit more checks and control flow at the
>> beginning of the function though.
>> I'm not sure at all whether this is the most efficient way of
>> parallelizing things, but it will for sure speed up your processing
>> compared to single core processing.
>>
>> Hope this helps,
>> Cheers,
>> Lo?c
>>
>>
>> On 10/26/2015 12:23 PM, Victor Maus wrote:
>>
>>> Hi Lo?c,
>>>
>>> Thank your very much for your answer. I am working on your suggestion.
>>> But I still have a question.
>>>
>>> The function raster::overlay works for multiple RasterBrick objects.
>>> However, I noticed that raster::beginCluster works with raster::overlay
>>> as long as a single RasterStack or RasterBrick is provided as the first
>>> argument. Do you have any suggestion for parallel processing of multiple
>>> RasterBrick objects?
>>>
>>> Thank you!
>>>
>>> Best,
>>> Victor
>>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Victor Maus, MSc
Assistant Researcher
Institute for Geoinformatics (IFGI), University of M?nster, Germany
PhD candidate in Earth System Science
National Institute for Space Research (INPE), Brazil


From mathieu.rajerison at gmail.com  Wed Oct 28 14:18:20 2015
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Wed, 28 Oct 2015 14:18:20 +0100
Subject: [R-sig-Geo] spgrass6, readVECT and overwriting ?
In-Reply-To: <m2lhaoe9sh.fsf@krugs.de>
References: <CAGfc75kOhMzWuXe_jm+A81-MoiSdRanoXViAycvKGoPLuRzwfw@mail.gmail.com>
	<m2mvv87b5l.fsf@krugs.de>
	<CAGfc75mgjHT94aZm7bEFkLO5628K-8-UR--Z-FQbpndX3tsSsA@mail.gmail.com>
	<m2lhaoe9sh.fsf@krugs.de>
Message-ID: <CAGfc75kGAjR6xWHN+uX_U6xW6jjogVvOsgGGoVwKGeh=8uoa5A@mail.gmail.com>

Mr Krug,


It is difficult to reproduce an example from the spearfish dataset as it
doesn't natively contain data in it close to the one I used.

To give you th context, my goal is to detect all blue features : rivers
from a topographic map, ie 3-band RGB raster.

With RStoolbox, I perform a Spectral Angle Classification of my data using
sample points located on (near)blue pixels

With GRASS, I then thin, vectorize and clean the result.

As the process must be performed on a very large scale, I split it using
grids where sample RGB parts of the topo map are extracted with
gdal_translate. Everything is executed within a loop. At the end of the
loop, I export the resulted cleant shapefile in a folder. At the end, I
have as many shapefiles as processing grids.

That's why I use temporary vector datasets inside GRASS that are
overwritten at each loop instead of storing each individual result. I
noticed that in my process, the vector data read in the grass database was
not correct : always the first one. Because in fact, it didn't manage to
delete the temporary file before writing the new one..

The best I can do, is give you part of the code as as you can see the
context.

Thanks for the code improvements with file.remove and unlink !

Cheers,

Mathieu

for (id in 1:length(grids)) {

(...)

## SMOOTH
  print(">> SMOOTH")
  smoothed = smooth(sieved, 9)
  values(smoothed)[values(smoothed) > 0] = 1
  values(smoothed)[values(smoothed)==0] = NA

  ## THIN
  # WRITE TO GRASS
  writeRAST(as(smoothed, "SpatialGridDataFrame"), "bdtopo", zcol="layer",
flags=c("overwrite"))
  execGRASS("g.region", rast="bdtopo")
  execGRASS("r.thin", parameters=list(input="bdtopo", output="thin"),
flags=c("overwrite"))
  thin = raster(readRAST("thin"))

  ## CLEAN
  execGRASS("r.to.vect", parameters=list(input="thin", output="thin",
feature="line"), flags=c("overwrite"))
  execGRASS("v.clean", parameters=list(input="thin", tool="rmdangle",
output="clean", thresh=20), flags=c("overwrite"))

  # REMOVE FILES
  G = gmeta()
  tmpDir = file.path(G$GISDBASE, G$LOCATION_NAME, G$MAPSET, ".tmp")
  file.remove( list.files(path = tmpDir, Pattern ="^clean.*$", full.names =
TRUE))

  # READ TO SPDF
  execGRASS("v.out.ogr", parameters=list(input="clean", type="line",
dsn=tmpDir, olayer="clean", format="ESRI_Shapefile"))
  cleaned = readOGR(tmpDir, "clean")

  ## EXPORT
  writeOGR(cleaned, "OUT/CLEANED", id, "ESRI Shapefile")
}

2015-10-27 14:11 GMT+01:00 Rainer M Krug <Rainer at krugs.de>:

> Mathieu Rajerison <mathieu.rajerison at gmail.com> writes:
>
> > Dear Mr Krug,
> >
>
> I'll Cc the R-sig-geo list in to keep the conversation there for future
> reference and for other users who might have the same problem.
>
> > Sorry in advance for my english.
>
> Don't worry abut your English - it is perfectly fine.
>
> >
> > My question was not about debugging, but about a potentiel generic
> > behaviour of spgrass6.
> >
> > I should have reformulated my question in a simpler manner : does
> spgrass6
> > allow overwriting an existing dataset when using readVECT function ?
>
> The functions readVect / RAST are using temporary files - you are right,
> but they should delete these upon exit. So if they do nbot do this, it
> is a bug.
>
> >
> > 1) no version information about R and GRASS (there are several GRASS 6
> > versions)
> > I've just put it at the end of this post.
> > 2) no session information i.e. package versions used
> > the latest spgrass6
> > 3) no information about the OS (I guess it is windows based on the
> > Source path above)
> > you're right
>
> OK - thanks.
>
> > 4) no reproducible example which could be easily done by using the GRASS
>
> As I said - if you manually have to delete the temporary files, then
> there is a bug in the package. Could you please provide a reproducible
> example, using one of the example data sets from GRASS, so that I can
> look at it?
>
> > 5) as far as I can see, in the newest version of spgrass6 there is no
> > function readVECT()
> > Yes, there is, as you will see on page 14 of the documentation.
>
> Sorry - overlooked it.
>
> >
> > Finally, I solved the problem by using the following hint, "clean" being
> > the name of my temporary shapefile dataset :
> >   l = list.files("D:/GRASSDB/paca/mapset/.tmp", "^clean.*$"); l =
> > file.path("D:/GRASSDB/paca/mapset/.tmp", l)
> >   lapply(l,  file.remove)
> >   execGRASS("v.out.ogr", parameters=list(input="clean", type="line",
> > dsn="D:/GRASSDB/paca/mapset/.tmp", olayer="clean",
> format="ESRI_Shapefile"))
>
> OK - reformated, the code looks as follow:
>
> --8<---------------cut here---------------start------------->8---
> l = list.files("D:/GRASSDB/paca/mapset/.tmp", "^clean.*$")
> l = file.path("D:/GRASSDB/paca/mapset/.tmp", l)
> lapply(l,  file.remove)
> execGRASS( "v.out.ogr",
>            parameters=list(input="clean",
> type="line",dsn="D:/GRASSDB/paca/mapset/.tmp", olayer="clean",
> format="ESRI_Shapefile"))
> --8<---------------cut here---------------end--------------->8---
>
> as a side note, you should be able to do
>
> file.remove( list.files(path = "D:/GRASSDB/paca/mapset/.tmp", Pattern =
> "^clean.*$", full.names = TRUE) )
>
> or
>
> unlink("D:/GRASSDB/paca/mapset/.tmp/clean.*")
>
> instead of the first three commands.
>
> Now - in your example, you don't use the readVECT() function?
>
> If you check in the GRASS help for v.out.ogr, you can specify the
> overwrite flag and the exported layer will be overwritten.
>
> But I have the feeling you are doing something in a to complicated way.
>
> What is it you want to do, and e=what is the problem you have or the
> error message you get?
>
> Cheers,
>
> Rainer
>
> >
> >
> >> R.Version()
> > $platform
> > [1] "x86_64-w64-mingw32"
> > $arch
> > [1] "x86_64"
> > $os
> > [1] "mingw32"
> >
> > $system
> > [1] "x86_64, mingw32"
> > (...)
> > $version.string
> > [1] "R version 3.1.2 (2014-10-31)"
> > $nickname
> > [1] "Pumpkin Helmet"
> >
> > I will happily look int this if you can provide the necessary info.
> >
> > Cheers,
> >
> > Mathieu
> >
> > 2015-10-24 13:34 GMT+02:00 Rainer M Krug <Rainer at krugs.de>:
> >
> >> Mathieu Rajerison <mathieu.rajerison at gmail.com> writes:
> >>
> >> > Hi,
> >> >
> >> > I'm using spgrass6 and I use readVECT function in a loop.
> >> >
> >> > Using it causes an error because it doesn't overwrite the the
> temporary
> >> > shapefile..
> >> >
> >> >> thin = readVECT(vname="zoneBDTOPOthin")
> >> > with_c: argument reversed from version 0.7-11 and in GRASS 6
> >> > ERROR :Layer <zoneBDTO> already exists in OGR data source
> >> >         'D:/GRASSDB/paca/mapset/.tmp'
> >> > OGR data source with driver: ESRI Shapefile
> >> > Source: "D:/GRASSDB/paca/mapset/.tmp", layer: "zoneBDTO"
> >> > with 770 features
> >> > It has 3 fields
> >> > Warning message:
> >> > running command 'v.out.ogr.exe -e -c input=zoneBDTOPOthin2 type=line
> >> > layer=1 dsn=D:/GRASSDB/paca/mapset/.tmp olayer=zoneBDTO
> >> > format=ESRI_Shapefile' had status 1
> >> >
> >> >
> >> > I wonder how to specify to spgrass that I want to overwrite the file
> in
> >> > readVECT, although I know using execGRASS and v.out.ogr with the
> >> > appropriate overwrite flags would do the job.
> >> >
> >> > Thanks in advance for the answer..
> >>
> >> One reason why probably nobody replied is that
> >>
> >> 1) no version information about R and GRASS (there are several GRASS 6
> >> versions)
> >> 2) no session information i.e. package versions used
> >> 3) no information about the OS (I guess it is windows based on the
> >> Source path above)
> >> 4) no reproducible example which could be easily done by using the GRASS
> >> 5) as far as I can see, in the newest version of spgrass6 there is no
> >> function readVECT()
> >>
> >> So I would suggest to provide the info and give a reproducible example
> >> using a GRASS sample dataset
> >> (see https://grass.osgeo.org/download/sample-data/ - the Spearfish
> >> dataset is probably the best)
> >>
> >> I will happily look int this if you can provide the necessary info.
> >>
> >> Cheers,
> >>
> >> Rainer
> >>
> >> >
> >> > Mathieu
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> > _______________________________________________
> >> > R-sig-Geo mailing list
> >> > R-sig-Geo at r-project.org
> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >> --
> >> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
> >> Biology, UCT), Dipl. Phys. (Germany)
> >>
> >> Centre of Excellence for Invasion Biology
> >> Stellenbosch University
> >> South Africa
> >>
> >> Tel :       +33 - (0)9 53 10 27 44
> >> Cell:       +33 - (0)6 85 62 59 98
> >> Fax :       +33 - (0)9 58 10 27 44
> >>
> >> Fax (D):    +49 - (0)3 21 21 25 22 44
> >>
> >> email:      Rainer at krugs.de
> >>
> >> Skype:      RMkrug
> >>
> >> PGP: 0x0F52F982
> >>
>
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
> Biology, UCT), Dipl. Phys. (Germany)
>
> Centre of Excellence for Invasion Biology
> Stellenbosch University
> South Africa
>
> Tel :       +33 - (0)9 53 10 27 44
> Cell:       +33 - (0)6 85 62 59 98
> Fax :       +33 - (0)9 58 10 27 44
>
> Fax (D):    +49 - (0)3 21 21 25 22 44
>
> email:      Rainer at krugs.de
>
> Skype:      RMkrug
>
> PGP: 0x0F52F982
>

	[[alternative HTML version deleted]]


From mathieu.rajerison at gmail.com  Wed Oct 28 14:20:47 2015
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Wed, 28 Oct 2015 14:20:47 +0100
Subject: [R-sig-Geo] spgrass6, readVECT and overwriting ?
In-Reply-To: <CAGfc75kGAjR6xWHN+uX_U6xW6jjogVvOsgGGoVwKGeh=8uoa5A@mail.gmail.com>
References: <CAGfc75kOhMzWuXe_jm+A81-MoiSdRanoXViAycvKGoPLuRzwfw@mail.gmail.com>
	<m2mvv87b5l.fsf@krugs.de>
	<CAGfc75mgjHT94aZm7bEFkLO5628K-8-UR--Z-FQbpndX3tsSsA@mail.gmail.com>
	<m2lhaoe9sh.fsf@krugs.de>
	<CAGfc75kGAjR6xWHN+uX_U6xW6jjogVvOsgGGoVwKGeh=8uoa5A@mail.gmail.com>
Message-ID: <CAGfc75=30WjKr1+77GCG=vpjnvYymKSddPKUpUZ-MYpTxP=mkg@mail.gmail.com>

Before was the code that works.

Below is the code that generates issues :

(sorry the multiple posts)

for (id in 1:length(grids)) {

(...)

## SMOOTH
  print(">> SMOOTH")
  smoothed = smooth(sieved, 9)
  values(smoothed)[values(smoothed) > 0] = 1
  values(smoothed)[values(smoothed)==0] = NA

  ## THIN
  # WRITE TO GRASS
  writeRAST(as(smoothed, "SpatialGridDataFrame"), "bdtopo", zcol="layer",
flags=c("overwrite"))
  execGRASS("g.region", rast="bdtopo")
  execGRASS("r.thin", parameters=list(input="bdtopo", output="thin"),
flags=c("overwrite"))
  thin = raster(readRAST("thin"))

  ## CLEAN
  execGRASS("r.to.vect", parameters=list(input="thin", output="thin",
feature="line"), flags=c("overwrite"))
  execGRASS("v.clean", parameters=list(input="thin", tool="rmdangle",
output="clean", thresh=20), flags=c("overwrite"))

  cleaned = readVECT("clean")

  ## EXPORT
  writeOGR(cleaned, "OUT/CLEANED", id, "ESRI Shapefile")
}

2015-10-28 14:18 GMT+01:00 Mathieu Rajerison <mathieu.rajerison at gmail.com>:

> Mr Krug,
>
>
> It is difficult to reproduce an example from the spearfish dataset as it
> doesn't natively contain data in it close to the one I used.
>
> To give you th context, my goal is to detect all blue features : rivers
> from a topographic map, ie 3-band RGB raster.
>
> With RStoolbox, I perform a Spectral Angle Classification of my data using
> sample points located on (near)blue pixels
>
> With GRASS, I then thin, vectorize and clean the result.
>
> As the process must be performed on a very large scale, I split it using
> grids where sample RGB parts of the topo map are extracted with
> gdal_translate. Everything is executed within a loop. At the end of the
> loop, I export the resulted cleant shapefile in a folder. At the end, I
> have as many shapefiles as processing grids.
>
> That's why I use temporary vector datasets inside GRASS that are
> overwritten at each loop instead of storing each individual result. I
> noticed that in my process, the vector data read in the grass database was
> not correct : always the first one. Because in fact, it didn't manage to
> delete the temporary file before writing the new one..
>
> The best I can do, is give you part of the code as as you can see the
> context.
>
> Thanks for the code improvements with file.remove and unlink !
>
> Cheers,
>
> Mathieu
>
> for (id in 1:length(grids)) {
>
> (...)
>
> ## SMOOTH
>   print(">> SMOOTH")
>   smoothed = smooth(sieved, 9)
>   values(smoothed)[values(smoothed) > 0] = 1
>   values(smoothed)[values(smoothed)==0] = NA
>
>   ## THIN
>   # WRITE TO GRASS
>   writeRAST(as(smoothed, "SpatialGridDataFrame"), "bdtopo", zcol="layer",
> flags=c("overwrite"))
>   execGRASS("g.region", rast="bdtopo")
>   execGRASS("r.thin", parameters=list(input="bdtopo", output="thin"),
> flags=c("overwrite"))
>   thin = raster(readRAST("thin"))
>
>   ## CLEAN
>   execGRASS("r.to.vect", parameters=list(input="thin", output="thin",
> feature="line"), flags=c("overwrite"))
>   execGRASS("v.clean", parameters=list(input="thin", tool="rmdangle",
> output="clean", thresh=20), flags=c("overwrite"))
>
>   # REMOVE FILES
>   G = gmeta()
>   tmpDir = file.path(G$GISDBASE, G$LOCATION_NAME, G$MAPSET, ".tmp")
>   file.remove( list.files(path = tmpDir, Pattern ="^clean.*$", full.names
> = TRUE))
>
>   # READ TO SPDF
>   execGRASS("v.out.ogr", parameters=list(input="clean", type="line",
> dsn=tmpDir, olayer="clean", format="ESRI_Shapefile"))
>   cleaned = readOGR(tmpDir, "clean")
>
>   ## EXPORT
>   writeOGR(cleaned, "OUT/CLEANED", id, "ESRI Shapefile")
> }
>
> 2015-10-27 14:11 GMT+01:00 Rainer M Krug <Rainer at krugs.de>:
>
>> Mathieu Rajerison <mathieu.rajerison at gmail.com> writes:
>>
>> > Dear Mr Krug,
>> >
>>
>> I'll Cc the R-sig-geo list in to keep the conversation there for future
>> reference and for other users who might have the same problem.
>>
>> > Sorry in advance for my english.
>>
>> Don't worry abut your English - it is perfectly fine.
>>
>> >
>> > My question was not about debugging, but about a potentiel generic
>> > behaviour of spgrass6.
>> >
>> > I should have reformulated my question in a simpler manner : does
>> spgrass6
>> > allow overwriting an existing dataset when using readVECT function ?
>>
>> The functions readVect / RAST are using temporary files - you are right,
>> but they should delete these upon exit. So if they do nbot do this, it
>> is a bug.
>>
>> >
>> > 1) no version information about R and GRASS (there are several GRASS 6
>> > versions)
>> > I've just put it at the end of this post.
>> > 2) no session information i.e. package versions used
>> > the latest spgrass6
>> > 3) no information about the OS (I guess it is windows based on the
>> > Source path above)
>> > you're right
>>
>> OK - thanks.
>>
>> > 4) no reproducible example which could be easily done by using the GRASS
>>
>> As I said - if you manually have to delete the temporary files, then
>> there is a bug in the package. Could you please provide a reproducible
>> example, using one of the example data sets from GRASS, so that I can
>> look at it?
>>
>> > 5) as far as I can see, in the newest version of spgrass6 there is no
>> > function readVECT()
>> > Yes, there is, as you will see on page 14 of the documentation.
>>
>> Sorry - overlooked it.
>>
>> >
>> > Finally, I solved the problem by using the following hint, "clean" being
>> > the name of my temporary shapefile dataset :
>> >   l = list.files("D:/GRASSDB/paca/mapset/.tmp", "^clean.*$"); l =
>> > file.path("D:/GRASSDB/paca/mapset/.tmp", l)
>> >   lapply(l,  file.remove)
>> >   execGRASS("v.out.ogr", parameters=list(input="clean", type="line",
>> > dsn="D:/GRASSDB/paca/mapset/.tmp", olayer="clean",
>> format="ESRI_Shapefile"))
>>
>> OK - reformated, the code looks as follow:
>>
>> --8<---------------cut here---------------start------------->8---
>> l = list.files("D:/GRASSDB/paca/mapset/.tmp", "^clean.*$")
>> l = file.path("D:/GRASSDB/paca/mapset/.tmp", l)
>> lapply(l,  file.remove)
>> execGRASS( "v.out.ogr",
>>            parameters=list(input="clean",
>> type="line",dsn="D:/GRASSDB/paca/mapset/.tmp", olayer="clean",
>> format="ESRI_Shapefile"))
>> --8<---------------cut here---------------end--------------->8---
>>
>> as a side note, you should be able to do
>>
>> file.remove( list.files(path = "D:/GRASSDB/paca/mapset/.tmp", Pattern =
>> "^clean.*$", full.names = TRUE) )
>>
>> or
>>
>> unlink("D:/GRASSDB/paca/mapset/.tmp/clean.*")
>>
>> instead of the first three commands.
>>
>> Now - in your example, you don't use the readVECT() function?
>>
>> If you check in the GRASS help for v.out.ogr, you can specify the
>> overwrite flag and the exported layer will be overwritten.
>>
>> But I have the feeling you are doing something in a to complicated way.
>>
>> What is it you want to do, and e=what is the problem you have or the
>> error message you get?
>>
>> Cheers,
>>
>> Rainer
>>
>> >
>> >
>> >> R.Version()
>> > $platform
>> > [1] "x86_64-w64-mingw32"
>> > $arch
>> > [1] "x86_64"
>> > $os
>> > [1] "mingw32"
>> >
>> > $system
>> > [1] "x86_64, mingw32"
>> > (...)
>> > $version.string
>> > [1] "R version 3.1.2 (2014-10-31)"
>> > $nickname
>> > [1] "Pumpkin Helmet"
>> >
>> > I will happily look int this if you can provide the necessary info.
>> >
>> > Cheers,
>> >
>> > Mathieu
>> >
>> > 2015-10-24 13:34 GMT+02:00 Rainer M Krug <Rainer at krugs.de>:
>> >
>> >> Mathieu Rajerison <mathieu.rajerison at gmail.com> writes:
>> >>
>> >> > Hi,
>> >> >
>> >> > I'm using spgrass6 and I use readVECT function in a loop.
>> >> >
>> >> > Using it causes an error because it doesn't overwrite the the
>> temporary
>> >> > shapefile..
>> >> >
>> >> >> thin = readVECT(vname="zoneBDTOPOthin")
>> >> > with_c: argument reversed from version 0.7-11 and in GRASS 6
>> >> > ERROR :Layer <zoneBDTO> already exists in OGR data source
>> >> >         'D:/GRASSDB/paca/mapset/.tmp'
>> >> > OGR data source with driver: ESRI Shapefile
>> >> > Source: "D:/GRASSDB/paca/mapset/.tmp", layer: "zoneBDTO"
>> >> > with 770 features
>> >> > It has 3 fields
>> >> > Warning message:
>> >> > running command 'v.out.ogr.exe -e -c input=zoneBDTOPOthin2 type=line
>> >> > layer=1 dsn=D:/GRASSDB/paca/mapset/.tmp olayer=zoneBDTO
>> >> > format=ESRI_Shapefile' had status 1
>> >> >
>> >> >
>> >> > I wonder how to specify to spgrass that I want to overwrite the file
>> in
>> >> > readVECT, although I know using execGRASS and v.out.ogr with the
>> >> > appropriate overwrite flags would do the job.
>> >> >
>> >> > Thanks in advance for the answer..
>> >>
>> >> One reason why probably nobody replied is that
>> >>
>> >> 1) no version information about R and GRASS (there are several GRASS 6
>> >> versions)
>> >> 2) no session information i.e. package versions used
>> >> 3) no information about the OS (I guess it is windows based on the
>> >> Source path above)
>> >> 4) no reproducible example which could be easily done by using the
>> GRASS
>> >> 5) as far as I can see, in the newest version of spgrass6 there is no
>> >> function readVECT()
>> >>
>> >> So I would suggest to provide the info and give a reproducible example
>> >> using a GRASS sample dataset
>> >> (see https://grass.osgeo.org/download/sample-data/ - the Spearfish
>> >> dataset is probably the best)
>> >>
>> >> I will happily look int this if you can provide the necessary info.
>> >>
>> >> Cheers,
>> >>
>> >> Rainer
>> >>
>> >> >
>> >> > Mathieu
>> >> >
>> >> >       [[alternative HTML version deleted]]
>> >> >
>> >> > _______________________________________________
>> >> > R-sig-Geo mailing list
>> >> > R-sig-Geo at r-project.org
>> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >>
>> >> --
>> >> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
>> >> Biology, UCT), Dipl. Phys. (Germany)
>> >>
>> >> Centre of Excellence for Invasion Biology
>> >> Stellenbosch University
>> >> South Africa
>> >>
>> >> Tel :       +33 - (0)9 53 10 27 44
>> >> Cell:       +33 - (0)6 85 62 59 98
>> >> Fax :       +33 - (0)9 58 10 27 44
>> >>
>> >> Fax (D):    +49 - (0)3 21 21 25 22 44
>> >>
>> >> email:      Rainer at krugs.de
>> >>
>> >> Skype:      RMkrug
>> >>
>> >> PGP: 0x0F52F982
>> >>
>>
>> --
>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
>> Biology, UCT), Dipl. Phys. (Germany)
>>
>> Centre of Excellence for Invasion Biology
>> Stellenbosch University
>> South Africa
>>
>> Tel :       +33 - (0)9 53 10 27 44
>> Cell:       +33 - (0)6 85 62 59 98
>> Fax :       +33 - (0)9 58 10 27 44
>>
>> Fax (D):    +49 - (0)3 21 21 25 22 44
>>
>> email:      Rainer at krugs.de
>>
>> Skype:      RMkrug
>>
>> PGP: 0x0F52F982
>>
>
>

	[[alternative HTML version deleted]]


From Rainer at krugs.de  Wed Oct 28 16:16:02 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Wed, 28 Oct 2015 16:16:02 +0100
Subject: [R-sig-Geo] spgrass6, readVECT and overwriting ?
In-Reply-To: <CAGfc75=30WjKr1+77GCG=vpjnvYymKSddPKUpUZ-MYpTxP=mkg@mail.gmail.com>
	(Mathieu Rajerison's message of "Wed, 28 Oct 2015 14:20:47 +0100")
References: <CAGfc75kOhMzWuXe_jm+A81-MoiSdRanoXViAycvKGoPLuRzwfw@mail.gmail.com>
	<m2mvv87b5l.fsf@krugs.de>
	<CAGfc75mgjHT94aZm7bEFkLO5628K-8-UR--Z-FQbpndX3tsSsA@mail.gmail.com>
	<m2lhaoe9sh.fsf@krugs.de>
	<CAGfc75kGAjR6xWHN+uX_U6xW6jjogVvOsgGGoVwKGeh=8uoa5A@mail.gmail.com>
	<CAGfc75=30WjKr1+77GCG=vpjnvYymKSddPKUpUZ-MYpTxP=mkg@mail.gmail.com>
Message-ID: <m28u6nc9cd.fsf@krugs.de>

Mathieu Rajerison <mathieu.rajerison at gmail.com> writes:

> Before was the code that works.
>
> Below is the code that generates issues :
>
> (sorry the multiple posts)
>
> for (id in 1:length(grids)) {
>
> (...)
>
> ## SMOOTH
>   print(">> SMOOTH")
>   smoothed = smooth(sieved, 9)
>   values(smoothed)[values(smoothed) > 0] = 1
>   values(smoothed)[values(smoothed)==0] = NA
>
>   ## THIN
>   # WRITE TO GRASS
>   writeRAST(as(smoothed, "SpatialGridDataFrame"), "bdtopo", zcol="layer",
> flags=c("overwrite"))
>   execGRASS("g.region", rast="bdtopo")
>   execGRASS("r.thin", parameters=list(input="bdtopo", output="thin"),
> flags=c("overwrite"))
>   thin = raster(readRAST("thin"))
>
>   ## CLEAN
>   execGRASS("r.to.vect", parameters=list(input="thin", output="thin",
> feature="line"), flags=c("overwrite"))
>   execGRASS("v.clean", parameters=list(input="thin", tool="rmdangle",
> output="clean", thresh=20), flags=c("overwrite"))
>
>   cleaned = readVECT("clean")
>
>   ## EXPORT
>   writeOGR(cleaned, "OUT/CLEANED", id, "ESRI Shapefile")
> }

OK. So what you are doing is in a loop

  write a raster to grass
  calculations in GRASS
  read result vector layer into R

And the error occurs in 

cleaned = readVECT("clean")

as temporary files during the readVECT are not cleaned up and not
overwritten - correct?

Then the rest is irrelevant.

You can reproduce it by doing

for (i in 1:10) {
  x <- readVECT("vectorLayerInSampleDataset")
}

Could you try this and see if it works in a sample dataset?

If it does, the error comes from somewhere else.


Under grass 7 it works:

,----
| 03:37:37 {master} ~/ownCompiled/emacs-mac$ grass70
| Cleaning up temporary files...
| Starting GRASS GIS...
| 
|           __________  ___   __________    _______________
|          / ____/ __ \/   | / ___/ ___/   / ____/  _/ ___/
|         / / __/ /_/ / /| | \__ \\_  \   / / __ / / \__ \
|        / /_/ / _, _/ ___ |___/ /__/ /  / /_/ // / ___/ /
|        \____/_/ |_/_/  |_/____/____/   \____/___//____/
| 
| Welcome to GRASS GIS 7.0.1
| GRASS GIS homepage:                      http://grass.osgeo.org
| This version running through:            Bash Shell (/usr/local/bin/bash)
| Help is available with the command:      g.manual -i
| See the licence terms with:              g.version -c
| If required, restart the GUI with:       g.gui wxpython
| When ready to quit enter:                exit
| 
| Launching <wxpython> GUI in the background, please wait...
| GRASS 7.0.1 (nc_basic_spm_grass7):~/ownCompiled/emacs-mac > R
| 
| R version 3.2.2 (2015-08-14) -- "Fire Safety"
| Copyright (C) 2015 The R Foundation for Statistical Computing
| Platform: x86_64-apple-darwin14.5.0 (64-bit)
| 
| R is free software and comes with ABSOLUTELY NO WARRANTY.
| You are welcome to redistribute it under certain conditions.
| Type 'license()' or 'licence()' for distribution details.
| 
|   Natural language support but running in an English locale
| 
| R is a collaborative project with many contributors.
| Type 'contributors()' for more information and
| 'citation()' on how to cite R or R packages in publications.
| 
| Type 'demo()' for some demos, 'help()' for on-line help, or
| 'help.start()' for an HTML browser interface to help.
| Type 'q()' to quit R.
| 
| > library(rgrass7)
| Loading required package: sp
| Loading required package: XML
| GRASS GIS interface loaded with GRASS version: GRASS 7.0.1 (2015)
| and location: nc_basic_spm_grass7
| > x <- readVECT("streams")
| Exporting 8554 features...
|  100%
| v.out.ogr complete. 8554 features (Line String type) written to <streams>
| (ESRI_Shapefile format).
| OGR data source with driver: ESRI Shapefile
| Source: "/Users/rainerkrug/nc_basic_spm_grass7/PERMANENT/.tmp/Rainers-MacBook-Pro.local", layer: "streams"
| with 8554 features
| It has 14 fields
| > x <- readVECT("streams")
| Exporting 8554 features...
|  100%
| v.out.ogr complete. 8554 features (Line String type) written to <streams>
| (ESRI_Shapefile format).
| OGR data source with driver: ESRI Shapefile
| Source: "/Users/rainerkrug/nc_basic_spm_grass7/PERMANENT/.tmp/Rainers-MacBook-Pro.local", layer: "streams"
| with 8554 features
| It has 14 fields
| >
`----


and also under grass-64:

,----
| > library(spgrass6)
| Loading required package: sp
| Loading required package: XML
| GRASS GIS interface loaded with GRASS version: GRASS 6.4.4 (2014)
| and location: spearfish60
| > x_readVECT("soils")
| Error: could not find function "x_readVECT"
| > x <- readVECT("soils")
| with_c: argument reversed from version 0.7-11 and in GRASS 6
| Exporting 737 areas (may take some time)...
|  100%
| WARNING: 1 features without attributes were written
| v.out.ogr complete. 737 features written to <soils> (ESRI_Shapefile).
| OGR data source with driver: ESRI Shapefile
| Source: "/Users/rainerkrug/spearfish60/user1/.tmp/Rainers-MacBook-Pro.local", layer: "soils"
| with 737 features
| It has 2 fields
| Warning message:
| In execGRASS("v.out.ogr", flags = flags, input = vname, type = type,  :
|   The command:
| v.out.ogr -e -c input=soils type=area layer=1 dsn=/Users/rainerkrug/spearfish60/user1/.tmp/Rainers-MacBook-Pro.local olayer=soils format=ESRI_Shapefile
| produced at least one warning during execution:
| Exporting 737 areas (may take some time)...
|  100%
| WARNING: 1 features without attributes were written
| v.out.ogr complete. 737 features written to <soils> (ESRI_Shapefile).
| > plot(x)
| > plot(x)
| > x <- readVECT("soils")
| with_c: argument reversed from version 0.7-11 and in GRASS 6
| Exporting 737 areas (may take some time)...
|  100%
| WARNING: 1 features without attributes were written
| v.out.ogr complete. 737 features written to <soils> (ESRI_Shapefile).
| OGR data source with driver: ESRI Shapefile
| Source: "/Users/rainerkrug/spearfish60/user1/.tmp/Rainers-MacBook-Pro.local", layer: "soils"
| with 737 features
| It has 2 fields
| Warning message:
| In execGRASS("v.out.ogr", flags = flags, input = vname, type = type,  :
|   The command:
| v.out.ogr -e -c input=soils type=area layer=1 dsn=/Users/rainerkrug/spearfish60/user1/.tmp/Rainers-MacBook-Pro.local olayer=soils format=ESRI_Shapefile
| produced at least one warning during execution:
| Exporting 737 areas (may take some time)...
|  100%
| WARNING: 1 features without attributes were written
| v.out.ogr complete. 737 features written to <soils> (ESRI_Shapefile).
| >
`----


Also: if you want to export it to a shape file, why do you import it
into R and save it afterwards? Why not write it directly from GRASS as a
shape file?

Cheers,

Rainer

>
> 2015-10-28 14:18 GMT+01:00 Mathieu Rajerison <mathieu.rajerison at gmail.com>:
>
>> Mr Krug,
>>
>>
>> It is difficult to reproduce an example from the spearfish dataset as it
>> doesn't natively contain data in it close to the one I used.
>>
>> To give you th context, my goal is to detect all blue features : rivers
>> from a topographic map, ie 3-band RGB raster.
>>
>> With RStoolbox, I perform a Spectral Angle Classification of my data using
>> sample points located on (near)blue pixels
>>
>> With GRASS, I then thin, vectorize and clean the result.
>>
>> As the process must be performed on a very large scale, I split it using
>> grids where sample RGB parts of the topo map are extracted with
>> gdal_translate. Everything is executed within a loop. At the end of the
>> loop, I export the resulted cleant shapefile in a folder. At the end, I
>> have as many shapefiles as processing grids.
>>
>> That's why I use temporary vector datasets inside GRASS that are
>> overwritten at each loop instead of storing each individual result. I
>> noticed that in my process, the vector data read in the grass database was
>> not correct : always the first one. Because in fact, it didn't manage to
>> delete the temporary file before writing the new one..
>>
>> The best I can do, is give you part of the code as as you can see the
>> context.
>>
>> Thanks for the code improvements with file.remove and unlink !
>>
>> Cheers,
>>
>> Mathieu
>>
>> for (id in 1:length(grids)) {
>>
>> (...)
>>
>> ## SMOOTH
>>   print(">> SMOOTH")
>>   smoothed = smooth(sieved, 9)
>>   values(smoothed)[values(smoothed) > 0] = 1
>>   values(smoothed)[values(smoothed)==0] = NA
>>
>>   ## THIN
>>   # WRITE TO GRASS
>>   writeRAST(as(smoothed, "SpatialGridDataFrame"), "bdtopo", zcol="layer",
>> flags=c("overwrite"))
>>   execGRASS("g.region", rast="bdtopo")
>>   execGRASS("r.thin", parameters=list(input="bdtopo", output="thin"),
>> flags=c("overwrite"))
>>   thin = raster(readRAST("thin"))
>>
>>   ## CLEAN
>>   execGRASS("r.to.vect", parameters=list(input="thin", output="thin",
>> feature="line"), flags=c("overwrite"))
>>   execGRASS("v.clean", parameters=list(input="thin", tool="rmdangle",
>> output="clean", thresh=20), flags=c("overwrite"))
>>
>>   # REMOVE FILES
>>   G = gmeta()
>>   tmpDir = file.path(G$GISDBASE, G$LOCATION_NAME, G$MAPSET, ".tmp")
>>   file.remove( list.files(path = tmpDir, Pattern ="^clean.*$", full.names
>> = TRUE))
>>
>>   # READ TO SPDF
>>   execGRASS("v.out.ogr", parameters=list(input="clean", type="line",
>> dsn=tmpDir, olayer="clean", format="ESRI_Shapefile"))
>>   cleaned = readOGR(tmpDir, "clean")
>>
>>   ## EXPORT
>>   writeOGR(cleaned, "OUT/CLEANED", id, "ESRI Shapefile")
>> }
>>
>> 2015-10-27 14:11 GMT+01:00 Rainer M Krug <Rainer at krugs.de>:
>>
>>> Mathieu Rajerison <mathieu.rajerison at gmail.com> writes:
>>>
>>> > Dear Mr Krug,
>>> >
>>>
>>> I'll Cc the R-sig-geo list in to keep the conversation there for future
>>> reference and for other users who might have the same problem.
>>>
>>> > Sorry in advance for my english.
>>>
>>> Don't worry abut your English - it is perfectly fine.
>>>
>>> >
>>> > My question was not about debugging, but about a potentiel generic
>>> > behaviour of spgrass6.
>>> >
>>> > I should have reformulated my question in a simpler manner : does
>>> spgrass6
>>> > allow overwriting an existing dataset when using readVECT function ?
>>>
>>> The functions readVect / RAST are using temporary files - you are right,
>>> but they should delete these upon exit. So if they do nbot do this, it
>>> is a bug.
>>>
>>> >
>>> > 1) no version information about R and GRASS (there are several GRASS 6
>>> > versions)
>>> > I've just put it at the end of this post.
>>> > 2) no session information i.e. package versions used
>>> > the latest spgrass6
>>> > 3) no information about the OS (I guess it is windows based on the
>>> > Source path above)
>>> > you're right
>>>
>>> OK - thanks.
>>>
>>> > 4) no reproducible example which could be easily done by using the GRASS
>>>
>>> As I said - if you manually have to delete the temporary files, then
>>> there is a bug in the package. Could you please provide a reproducible
>>> example, using one of the example data sets from GRASS, so that I can
>>> look at it?
>>>
>>> > 5) as far as I can see, in the newest version of spgrass6 there is no
>>> > function readVECT()
>>> > Yes, there is, as you will see on page 14 of the documentation.
>>>
>>> Sorry - overlooked it.
>>>
>>> >
>>> > Finally, I solved the problem by using the following hint, "clean" being
>>> > the name of my temporary shapefile dataset :
>>> >   l = list.files("D:/GRASSDB/paca/mapset/.tmp", "^clean.*$"); l =
>>> > file.path("D:/GRASSDB/paca/mapset/.tmp", l)
>>> >   lapply(l,  file.remove)
>>> >   execGRASS("v.out.ogr", parameters=list(input="clean", type="line",
>>> > dsn="D:/GRASSDB/paca/mapset/.tmp", olayer="clean",
>>> format="ESRI_Shapefile"))
>>>
>>> OK - reformated, the code looks as follow:
>>>
>>> --8<---------------cut here---------------start------------->8---
>>> l = list.files("D:/GRASSDB/paca/mapset/.tmp", "^clean.*$")
>>> l = file.path("D:/GRASSDB/paca/mapset/.tmp", l)
>>> lapply(l,  file.remove)
>>> execGRASS( "v.out.ogr",
>>>            parameters=list(input="clean",
>>> type="line",dsn="D:/GRASSDB/paca/mapset/.tmp", olayer="clean",
>>> format="ESRI_Shapefile"))
>>> --8<---------------cut here---------------end--------------->8---
>>>
>>> as a side note, you should be able to do
>>>
>>> file.remove( list.files(path = "D:/GRASSDB/paca/mapset/.tmp", Pattern =
>>> "^clean.*$", full.names = TRUE) )
>>>
>>> or
>>>
>>> unlink("D:/GRASSDB/paca/mapset/.tmp/clean.*")
>>>
>>> instead of the first three commands.
>>>
>>> Now - in your example, you don't use the readVECT() function?
>>>
>>> If you check in the GRASS help for v.out.ogr, you can specify the
>>> overwrite flag and the exported layer will be overwritten.
>>>
>>> But I have the feeling you are doing something in a to complicated way.
>>>
>>> What is it you want to do, and e=what is the problem you have or the
>>> error message you get?
>>>
>>> Cheers,
>>>
>>> Rainer
>>>
>>> >
>>> >
>>> >> R.Version()
>>> > $platform
>>> > [1] "x86_64-w64-mingw32"
>>> > $arch
>>> > [1] "x86_64"
>>> > $os
>>> > [1] "mingw32"
>>> >
>>> > $system
>>> > [1] "x86_64, mingw32"
>>> > (...)
>>> > $version.string
>>> > [1] "R version 3.1.2 (2014-10-31)"
>>> > $nickname
>>> > [1] "Pumpkin Helmet"
>>> >
>>> > I will happily look int this if you can provide the necessary info.
>>> >
>>> > Cheers,
>>> >
>>> > Mathieu
>>> >
>>> > 2015-10-24 13:34 GMT+02:00 Rainer M Krug <Rainer at krugs.de>:
>>> >
>>> >> Mathieu Rajerison <mathieu.rajerison at gmail.com> writes:
>>> >>
>>> >> > Hi,
>>> >> >
>>> >> > I'm using spgrass6 and I use readVECT function in a loop.
>>> >> >
>>> >> > Using it causes an error because it doesn't overwrite the the
>>> temporary
>>> >> > shapefile..
>>> >> >
>>> >> >> thin = readVECT(vname="zoneBDTOPOthin")
>>> >> > with_c: argument reversed from version 0.7-11 and in GRASS 6
>>> >> > ERROR :Layer <zoneBDTO> already exists in OGR data source
>>> >> >         'D:/GRASSDB/paca/mapset/.tmp'
>>> >> > OGR data source with driver: ESRI Shapefile
>>> >> > Source: "D:/GRASSDB/paca/mapset/.tmp", layer: "zoneBDTO"
>>> >> > with 770 features
>>> >> > It has 3 fields
>>> >> > Warning message:
>>> >> > running command 'v.out.ogr.exe -e -c input=zoneBDTOPOthin2 type=line
>>> >> > layer=1 dsn=D:/GRASSDB/paca/mapset/.tmp olayer=zoneBDTO
>>> >> > format=ESRI_Shapefile' had status 1
>>> >> >
>>> >> >
>>> >> > I wonder how to specify to spgrass that I want to overwrite the file
>>> in
>>> >> > readVECT, although I know using execGRASS and v.out.ogr with the
>>> >> > appropriate overwrite flags would do the job.
>>> >> >
>>> >> > Thanks in advance for the answer..
>>> >>
>>> >> One reason why probably nobody replied is that
>>> >>
>>> >> 1) no version information about R and GRASS (there are several GRASS 6
>>> >> versions)
>>> >> 2) no session information i.e. package versions used
>>> >> 3) no information about the OS (I guess it is windows based on the
>>> >> Source path above)
>>> >> 4) no reproducible example which could be easily done by using the
>>> GRASS
>>> >> 5) as far as I can see, in the newest version of spgrass6 there is no
>>> >> function readVECT()
>>> >>
>>> >> So I would suggest to provide the info and give a reproducible example
>>> >> using a GRASS sample dataset
>>> >> (see https://grass.osgeo.org/download/sample-data/ - the Spearfish
>>> >> dataset is probably the best)
>>> >>
>>> >> I will happily look int this if you can provide the necessary info.
>>> >>
>>> >> Cheers,
>>> >>
>>> >> Rainer
>>> >>
>>> >> >
>>> >> > Mathieu
>>> >> >
>>> >> >       [[alternative HTML version deleted]]
>>> >> >
>>> >> > _______________________________________________
>>> >> > R-sig-Geo mailing list
>>> >> > R-sig-Geo at r-project.org
>>> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> >>
>>> >> --
>>> >> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
>>> >> Biology, UCT), Dipl. Phys. (Germany)
>>> >>
>>> >> Centre of Excellence for Invasion Biology
>>> >> Stellenbosch University
>>> >> South Africa
>>> >>
>>> >> Tel :       +33 - (0)9 53 10 27 44
>>> >> Cell:       +33 - (0)6 85 62 59 98
>>> >> Fax :       +33 - (0)9 58 10 27 44
>>> >>
>>> >> Fax (D):    +49 - (0)3 21 21 25 22 44
>>> >>
>>> >> email:      Rainer at krugs.de
>>> >>
>>> >> Skype:      RMkrug
>>> >>
>>> >> PGP: 0x0F52F982
>>> >>
>>>
>>> --
>>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
>>> Biology, UCT), Dipl. Phys. (Germany)
>>>
>>> Centre of Excellence for Invasion Biology
>>> Stellenbosch University
>>> South Africa
>>>
>>> Tel :       +33 - (0)9 53 10 27 44
>>> Cell:       +33 - (0)6 85 62 59 98
>>> Fax :       +33 - (0)9 58 10 27 44
>>>
>>> Fax (D):    +49 - (0)3 21 21 25 22 44
>>>
>>> email:      Rainer at krugs.de
>>>
>>> Skype:      RMkrug
>>>
>>> PGP: 0x0F52F982
>>>
>>
>>

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151028/f2602873/attachment.bin>

From mathieu.rajerison at gmail.com  Wed Oct 28 17:11:02 2015
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Wed, 28 Oct 2015 17:11:02 +0100
Subject: [R-sig-Geo] spgrass6, readVECT and overwriting ?
In-Reply-To: <m28u6nc9cd.fsf@krugs.de>
References: <CAGfc75kOhMzWuXe_jm+A81-MoiSdRanoXViAycvKGoPLuRzwfw@mail.gmail.com>
	<m2mvv87b5l.fsf@krugs.de>
	<CAGfc75mgjHT94aZm7bEFkLO5628K-8-UR--Z-FQbpndX3tsSsA@mail.gmail.com>
	<m2lhaoe9sh.fsf@krugs.de>
	<CAGfc75kGAjR6xWHN+uX_U6xW6jjogVvOsgGGoVwKGeh=8uoa5A@mail.gmail.com>
	<CAGfc75=30WjKr1+77GCG=vpjnvYymKSddPKUpUZ-MYpTxP=mkg@mail.gmail.com>
	<m28u6nc9cd.fsf@krugs.de>
Message-ID: <CAGfc75=y901cbM1b90C5jwR_iQ5Zq_EOyFhBquAABbtXKvnJFA@mail.gmail.com>

Yes, you're right. I should export directly from GRASS.

When doing :

for (i in 1:3) {
  f <- readVECT("f")
}

I get :
with_c: argument reversed from version 0.7-11 and in GRASS 6
ERREUR :Layer <f> already exists in OGR data source
        'D:/GRASSDB/paca/mapset/.tmp'
OGR data source with driver: ESRI Shapefile
Source: "D:/GRASSDB/paca/mapset/.tmp", layer: "f"
with 1 features
It has 5 fields
with_c: argument reversed from version 0.7-11 and in GRASS 6
ERREUR :Layer <f> already exists in OGR data source
        'D:/GRASSDB/paca/mapset/.tmp'
OGR data source with driver: ESRI Shapefile
Source: "D:/GRASSDB/paca/mapset/.tmp", layer: "f"
with 1 features
It has 5 fields
with_c: argument reversed from version 0.7-11 and in GRASS 6
ERREUR :Layer <f> already exists in OGR data source
        'D:/GRASSDB/paca/mapset/.tmp'
OGR data source with driver: ESRI Shapefile
Source: "D:/GRASSDB/paca/mapset/.tmp", layer: "f"
with 1 features
It has 5 fields
Warning messages:
1: running command 'v.out.ogr.exe -e -c input=f type=area layer=1
dsn=D:/GRASSDB/paca/mapset/.tmp olayer=f format=ESRI_Shapefile' had status
1
2: running command 'v.out.ogr.exe -e -c input=f type=area layer=1
dsn=D:/GRASSDB/paca/mapset/.tmp olayer=f format=ESRI_Shapefile' had status
1
3: running command 'v.out.ogr.exe -e -c input=f type=area layer=1
dsn=D:/GRASSDB/paca/mapset/.tmp olayer=f format=ESRI_Shapefile' had status
1

-----------------
sessionInfo() :
R version 3.1.2 (2014-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252
 LC_MONETARY=French_France.1252
[4] LC_NUMERIC=C                   LC_TIME=French_France.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
 [1] R.utils_2.1.0     R.oo_1.19.0       R.methodsS3_1.7.0 igraph_1.0.1
 gdalUtils_2.0.1.7
 [6] spdep_0.5-88      Matrix_1.2-2      maptools_0.8-34   spgrass6_0.8-8
 XML_3.98-1.3
[11] rgeos_0.3-8       FNN_1.1           rgdal_0.9-2       raster_2.3-40
  sp_1.0-17
[16] RStoolbox_0.1.1

loaded via a namespace (and not attached):
 [1] boot_1.3-13        car_2.0-25         caret_6.0-57       coda_0.18-1
     codetools_0.2-9
 [6] colorspace_1.2-6   deldir_0.1-9       digest_0.6.8
doParallel_1.0.8   foreach_1.4.2
[11] foreign_0.8-61     geosphere_1.4-3    ggplot2_1.0.1      grid_3.1.2
      gtable_0.1.2
[16] iterators_1.0.7    lattice_0.20-29    LearnBayes_2.15    lme4_1.1-10
     magrittr_1.5
[21] MASS_7.3-35        MatrixModels_0.4-1 mgcv_1.8-3         minqa_1.2.4
     munsell_0.4.2
[26] nlme_3.1-118       nloptr_1.0.4       nnet_7.3-8
parallel_3.1.2     pbkrtest_0.4-2
[31] plyr_1.8.3         proto_0.3-10       quantreg_5.19      Rcpp_0.12.0
     reshape2_1.4.1
[36] scales_0.2.5       SparseM_1.7        splines_3.1.2      stats4_3.1.2
      stringi_0.5-5
[41] stringr_1.0.0      tools_3.1.2

2015-10-28 16:16 GMT+01:00 Rainer M Krug <Rainer at krugs.de>:

> Mathieu Rajerison <mathieu.rajerison at gmail.com> writes:
>
> > Before was the code that works.
> >
> > Below is the code that generates issues :
> >
> > (sorry the multiple posts)
> >
> > for (id in 1:length(grids)) {
> >
> > (...)
> >
> > ## SMOOTH
> >   print(">> SMOOTH")
> >   smoothed = smooth(sieved, 9)
> >   values(smoothed)[values(smoothed) > 0] = 1
> >   values(smoothed)[values(smoothed)==0] = NA
> >
> >   ## THIN
> >   # WRITE TO GRASS
> >   writeRAST(as(smoothed, "SpatialGridDataFrame"), "bdtopo", zcol="layer",
> > flags=c("overwrite"))
> >   execGRASS("g.region", rast="bdtopo")
> >   execGRASS("r.thin", parameters=list(input="bdtopo", output="thin"),
> > flags=c("overwrite"))
> >   thin = raster(readRAST("thin"))
> >
> >   ## CLEAN
> >   execGRASS("r.to.vect", parameters=list(input="thin", output="thin",
> > feature="line"), flags=c("overwrite"))
> >   execGRASS("v.clean", parameters=list(input="thin", tool="rmdangle",
> > output="clean", thresh=20), flags=c("overwrite"))
> >
> >   cleaned = readVECT("clean")
> >
> >   ## EXPORT
> >   writeOGR(cleaned, "OUT/CLEANED", id, "ESRI Shapefile")
> > }
>
> OK. So what you are doing is in a loop
>
>   write a raster to grass
>   calculations in GRASS
>   read result vector layer into R
>
> And the error occurs in
>
> cleaned = readVECT("clean")
>
> as temporary files during the readVECT are not cleaned up and not
> overwritten - correct?
>
> Then the rest is irrelevant.
>
> You can reproduce it by doing
>
> for (i in 1:10) {
>   x <- readVECT("vectorLayerInSampleDataset")
> }
>
> Could you try this and see if it works in a sample dataset?
>
> If it does, the error comes from somewhere else.
>
>
> Under grass 7 it works:
>
> ,----
> | 03:37:37 {master} ~/ownCompiled/emacs-mac$ grass70
> | Cleaning up temporary files...
> | Starting GRASS GIS...
> |
> |           __________  ___   __________    _______________
> |          / ____/ __ \/   | / ___/ ___/   / ____/  _/ ___/
> |         / / __/ /_/ / /| | \__ \\_  \   / / __ / / \__ \
> |        / /_/ / _, _/ ___ |___/ /__/ /  / /_/ // / ___/ /
> |        \____/_/ |_/_/  |_/____/____/   \____/___//____/
> |
> | Welcome to GRASS GIS 7.0.1
> | GRASS GIS homepage:                      http://grass.osgeo.org
> | This version running through:            Bash Shell (/usr/local/bin/bash)
> | Help is available with the command:      g.manual -i
> | See the licence terms with:              g.version -c
> | If required, restart the GUI with:       g.gui wxpython
> | When ready to quit enter:                exit
> |
> | Launching <wxpython> GUI in the background, please wait...
> | GRASS 7.0.1 (nc_basic_spm_grass7):~/ownCompiled/emacs-mac > R
> |
> | R version 3.2.2 (2015-08-14) -- "Fire Safety"
> | Copyright (C) 2015 The R Foundation for Statistical Computing
> | Platform: x86_64-apple-darwin14.5.0 (64-bit)
> |
> | R is free software and comes with ABSOLUTELY NO WARRANTY.
> | You are welcome to redistribute it under certain conditions.
> | Type 'license()' or 'licence()' for distribution details.
> |
> |   Natural language support but running in an English locale
> |
> | R is a collaborative project with many contributors.
> | Type 'contributors()' for more information and
> | 'citation()' on how to cite R or R packages in publications.
> |
> | Type 'demo()' for some demos, 'help()' for on-line help, or
> | 'help.start()' for an HTML browser interface to help.
> | Type 'q()' to quit R.
> |
> | > library(rgrass7)
> | Loading required package: sp
> | Loading required package: XML
> | GRASS GIS interface loaded with GRASS version: GRASS 7.0.1 (2015)
> | and location: nc_basic_spm_grass7
> | > x <- readVECT("streams")
> | Exporting 8554 features...
> |  100%
> | v.out.ogr complete. 8554 features (Line String type) written to <streams>
> | (ESRI_Shapefile format).
> | OGR data source with driver: ESRI Shapefile
> | Source:
> "/Users/rainerkrug/nc_basic_spm_grass7/PERMANENT/.tmp/Rainers-MacBook-Pro.local",
> layer: "streams"
> | with 8554 features
> | It has 14 fields
> | > x <- readVECT("streams")
> | Exporting 8554 features...
> |  100%
> | v.out.ogr complete. 8554 features (Line String type) written to <streams>
> | (ESRI_Shapefile format).
> | OGR data source with driver: ESRI Shapefile
> | Source:
> "/Users/rainerkrug/nc_basic_spm_grass7/PERMANENT/.tmp/Rainers-MacBook-Pro.local",
> layer: "streams"
> | with 8554 features
> | It has 14 fields
> | >
> `----
>
>
> and also under grass-64:
>
> ,----
> | > library(spgrass6)
> | Loading required package: sp
> | Loading required package: XML
> | GRASS GIS interface loaded with GRASS version: GRASS 6.4.4 (2014)
> | and location: spearfish60
> | > x_readVECT("soils")
> | Error: could not find function "x_readVECT"
> | > x <- readVECT("soils")
> | with_c: argument reversed from version 0.7-11 and in GRASS 6
> | Exporting 737 areas (may take some time)...
> |  100%
> | WARNING: 1 features without attributes were written
> | v.out.ogr complete. 737 features written to <soils> (ESRI_Shapefile).
> | OGR data source with driver: ESRI Shapefile
> | Source:
> "/Users/rainerkrug/spearfish60/user1/.tmp/Rainers-MacBook-Pro.local",
> layer: "soils"
> | with 737 features
> | It has 2 fields
> | Warning message:
> | In execGRASS("v.out.ogr", flags = flags, input = vname, type = type,  :
> |   The command:
> | v.out.ogr -e -c input=soils type=area layer=1
> dsn=/Users/rainerkrug/spearfish60/user1/.tmp/Rainers-MacBook-Pro.local
> olayer=soils format=ESRI_Shapefile
> | produced at least one warning during execution:
> | Exporting 737 areas (may take some time)...
> |  100%
> | WARNING: 1 features without attributes were written
> | v.out.ogr complete. 737 features written to <soils> (ESRI_Shapefile).
> | > plot(x)
> | > plot(x)
> | > x <- readVECT("soils")
> | with_c: argument reversed from version 0.7-11 and in GRASS 6
> | Exporting 737 areas (may take some time)...
> |  100%
> | WARNING: 1 features without attributes were written
> | v.out.ogr complete. 737 features written to <soils> (ESRI_Shapefile).
> | OGR data source with driver: ESRI Shapefile
> | Source:
> "/Users/rainerkrug/spearfish60/user1/.tmp/Rainers-MacBook-Pro.local",
> layer: "soils"
> | with 737 features
> | It has 2 fields
> | Warning message:
> | In execGRASS("v.out.ogr", flags = flags, input = vname, type = type,  :
> |   The command:
> | v.out.ogr -e -c input=soils type=area layer=1
> dsn=/Users/rainerkrug/spearfish60/user1/.tmp/Rainers-MacBook-Pro.local
> olayer=soils format=ESRI_Shapefile
> | produced at least one warning during execution:
> | Exporting 737 areas (may take some time)...
> |  100%
> | WARNING: 1 features without attributes were written
> | v.out.ogr complete. 737 features written to <soils> (ESRI_Shapefile).
> | >
> `----
>
>
> Also: if you want to export it to a shape file, why do you import it
> into R and save it afterwards? Why not write it directly from GRASS as a
> shape file?
>
> Cheers,
>
> Rainer
>
> >
> > 2015-10-28 14:18 GMT+01:00 Mathieu Rajerison <
> mathieu.rajerison at gmail.com>:
> >
> >> Mr Krug,
> >>
> >>
> >> It is difficult to reproduce an example from the spearfish dataset as it
> >> doesn't natively contain data in it close to the one I used.
> >>
> >> To give you th context, my goal is to detect all blue features : rivers
> >> from a topographic map, ie 3-band RGB raster.
> >>
> >> With RStoolbox, I perform a Spectral Angle Classification of my data
> using
> >> sample points located on (near)blue pixels
> >>
> >> With GRASS, I then thin, vectorize and clean the result.
> >>
> >> As the process must be performed on a very large scale, I split it using
> >> grids where sample RGB parts of the topo map are extracted with
> >> gdal_translate. Everything is executed within a loop. At the end of the
> >> loop, I export the resulted cleant shapefile in a folder. At the end, I
> >> have as many shapefiles as processing grids.
> >>
> >> That's why I use temporary vector datasets inside GRASS that are
> >> overwritten at each loop instead of storing each individual result. I
> >> noticed that in my process, the vector data read in the grass database
> was
> >> not correct : always the first one. Because in fact, it didn't manage to
> >> delete the temporary file before writing the new one..
> >>
> >> The best I can do, is give you part of the code as as you can see the
> >> context.
> >>
> >> Thanks for the code improvements with file.remove and unlink !
> >>
> >> Cheers,
> >>
> >> Mathieu
> >>
> >> for (id in 1:length(grids)) {
> >>
> >> (...)
> >>
> >> ## SMOOTH
> >>   print(">> SMOOTH")
> >>   smoothed = smooth(sieved, 9)
> >>   values(smoothed)[values(smoothed) > 0] = 1
> >>   values(smoothed)[values(smoothed)==0] = NA
> >>
> >>   ## THIN
> >>   # WRITE TO GRASS
> >>   writeRAST(as(smoothed, "SpatialGridDataFrame"), "bdtopo",
> zcol="layer",
> >> flags=c("overwrite"))
> >>   execGRASS("g.region", rast="bdtopo")
> >>   execGRASS("r.thin", parameters=list(input="bdtopo", output="thin"),
> >> flags=c("overwrite"))
> >>   thin = raster(readRAST("thin"))
> >>
> >>   ## CLEAN
> >>   execGRASS("r.to.vect", parameters=list(input="thin", output="thin",
> >> feature="line"), flags=c("overwrite"))
> >>   execGRASS("v.clean", parameters=list(input="thin", tool="rmdangle",
> >> output="clean", thresh=20), flags=c("overwrite"))
> >>
> >>   # REMOVE FILES
> >>   G = gmeta()
> >>   tmpDir = file.path(G$GISDBASE, G$LOCATION_NAME, G$MAPSET, ".tmp")
> >>   file.remove( list.files(path = tmpDir, Pattern ="^clean.*$",
> full.names
> >> = TRUE))
> >>
> >>   # READ TO SPDF
> >>   execGRASS("v.out.ogr", parameters=list(input="clean", type="line",
> >> dsn=tmpDir, olayer="clean", format="ESRI_Shapefile"))
> >>   cleaned = readOGR(tmpDir, "clean")
> >>
> >>   ## EXPORT
> >>   writeOGR(cleaned, "OUT/CLEANED", id, "ESRI Shapefile")
> >> }
> >>
> >> 2015-10-27 14:11 GMT+01:00 Rainer M Krug <Rainer at krugs.de>:
> >>
> >>> Mathieu Rajerison <mathieu.rajerison at gmail.com> writes:
> >>>
> >>> > Dear Mr Krug,
> >>> >
> >>>
> >>> I'll Cc the R-sig-geo list in to keep the conversation there for future
> >>> reference and for other users who might have the same problem.
> >>>
> >>> > Sorry in advance for my english.
> >>>
> >>> Don't worry abut your English - it is perfectly fine.
> >>>
> >>> >
> >>> > My question was not about debugging, but about a potentiel generic
> >>> > behaviour of spgrass6.
> >>> >
> >>> > I should have reformulated my question in a simpler manner : does
> >>> spgrass6
> >>> > allow overwriting an existing dataset when using readVECT function ?
> >>>
> >>> The functions readVect / RAST are using temporary files - you are
> right,
> >>> but they should delete these upon exit. So if they do nbot do this, it
> >>> is a bug.
> >>>
> >>> >
> >>> > 1) no version information about R and GRASS (there are several GRASS
> 6
> >>> > versions)
> >>> > I've just put it at the end of this post.
> >>> > 2) no session information i.e. package versions used
> >>> > the latest spgrass6
> >>> > 3) no information about the OS (I guess it is windows based on the
> >>> > Source path above)
> >>> > you're right
> >>>
> >>> OK - thanks.
> >>>
> >>> > 4) no reproducible example which could be easily done by using the
> GRASS
> >>>
> >>> As I said - if you manually have to delete the temporary files, then
> >>> there is a bug in the package. Could you please provide a reproducible
> >>> example, using one of the example data sets from GRASS, so that I can
> >>> look at it?
> >>>
> >>> > 5) as far as I can see, in the newest version of spgrass6 there is no
> >>> > function readVECT()
> >>> > Yes, there is, as you will see on page 14 of the documentation.
> >>>
> >>> Sorry - overlooked it.
> >>>
> >>> >
> >>> > Finally, I solved the problem by using the following hint, "clean"
> being
> >>> > the name of my temporary shapefile dataset :
> >>> >   l = list.files("D:/GRASSDB/paca/mapset/.tmp", "^clean.*$"); l =
> >>> > file.path("D:/GRASSDB/paca/mapset/.tmp", l)
> >>> >   lapply(l,  file.remove)
> >>> >   execGRASS("v.out.ogr", parameters=list(input="clean", type="line",
> >>> > dsn="D:/GRASSDB/paca/mapset/.tmp", olayer="clean",
> >>> format="ESRI_Shapefile"))
> >>>
> >>> OK - reformated, the code looks as follow:
> >>>
> >>> --8<---------------cut here---------------start------------->8---
> >>> l = list.files("D:/GRASSDB/paca/mapset/.tmp", "^clean.*$")
> >>> l = file.path("D:/GRASSDB/paca/mapset/.tmp", l)
> >>> lapply(l,  file.remove)
> >>> execGRASS( "v.out.ogr",
> >>>            parameters=list(input="clean",
> >>> type="line",dsn="D:/GRASSDB/paca/mapset/.tmp", olayer="clean",
> >>> format="ESRI_Shapefile"))
> >>> --8<---------------cut here---------------end--------------->8---
> >>>
> >>> as a side note, you should be able to do
> >>>
> >>> file.remove( list.files(path = "D:/GRASSDB/paca/mapset/.tmp", Pattern =
> >>> "^clean.*$", full.names = TRUE) )
> >>>
> >>> or
> >>>
> >>> unlink("D:/GRASSDB/paca/mapset/.tmp/clean.*")
> >>>
> >>> instead of the first three commands.
> >>>
> >>> Now - in your example, you don't use the readVECT() function?
> >>>
> >>> If you check in the GRASS help for v.out.ogr, you can specify the
> >>> overwrite flag and the exported layer will be overwritten.
> >>>
> >>> But I have the feeling you are doing something in a to complicated way.
> >>>
> >>> What is it you want to do, and e=what is the problem you have or the
> >>> error message you get?
> >>>
> >>> Cheers,
> >>>
> >>> Rainer
> >>>
> >>> >
> >>> >
> >>> >> R.Version()
> >>> > $platform
> >>> > [1] "x86_64-w64-mingw32"
> >>> > $arch
> >>> > [1] "x86_64"
> >>> > $os
> >>> > [1] "mingw32"
> >>> >
> >>> > $system
> >>> > [1] "x86_64, mingw32"
> >>> > (...)
> >>> > $version.string
> >>> > [1] "R version 3.1.2 (2014-10-31)"
> >>> > $nickname
> >>> > [1] "Pumpkin Helmet"
> >>> >
> >>> > I will happily look int this if you can provide the necessary info.
> >>> >
> >>> > Cheers,
> >>> >
> >>> > Mathieu
> >>> >
> >>> > 2015-10-24 13:34 GMT+02:00 Rainer M Krug <Rainer at krugs.de>:
> >>> >
> >>> >> Mathieu Rajerison <mathieu.rajerison at gmail.com> writes:
> >>> >>
> >>> >> > Hi,
> >>> >> >
> >>> >> > I'm using spgrass6 and I use readVECT function in a loop.
> >>> >> >
> >>> >> > Using it causes an error because it doesn't overwrite the the
> >>> temporary
> >>> >> > shapefile..
> >>> >> >
> >>> >> >> thin = readVECT(vname="zoneBDTOPOthin")
> >>> >> > with_c: argument reversed from version 0.7-11 and in GRASS 6
> >>> >> > ERROR :Layer <zoneBDTO> already exists in OGR data source
> >>> >> >         'D:/GRASSDB/paca/mapset/.tmp'
> >>> >> > OGR data source with driver: ESRI Shapefile
> >>> >> > Source: "D:/GRASSDB/paca/mapset/.tmp", layer: "zoneBDTO"
> >>> >> > with 770 features
> >>> >> > It has 3 fields
> >>> >> > Warning message:
> >>> >> > running command 'v.out.ogr.exe -e -c input=zoneBDTOPOthin2
> type=line
> >>> >> > layer=1 dsn=D:/GRASSDB/paca/mapset/.tmp olayer=zoneBDTO
> >>> >> > format=ESRI_Shapefile' had status 1
> >>> >> >
> >>> >> >
> >>> >> > I wonder how to specify to spgrass that I want to overwrite the
> file
> >>> in
> >>> >> > readVECT, although I know using execGRASS and v.out.ogr with the
> >>> >> > appropriate overwrite flags would do the job.
> >>> >> >
> >>> >> > Thanks in advance for the answer..
> >>> >>
> >>> >> One reason why probably nobody replied is that
> >>> >>
> >>> >> 1) no version information about R and GRASS (there are several
> GRASS 6
> >>> >> versions)
> >>> >> 2) no session information i.e. package versions used
> >>> >> 3) no information about the OS (I guess it is windows based on the
> >>> >> Source path above)
> >>> >> 4) no reproducible example which could be easily done by using the
> >>> GRASS
> >>> >> 5) as far as I can see, in the newest version of spgrass6 there is
> no
> >>> >> function readVECT()
> >>> >>
> >>> >> So I would suggest to provide the info and give a reproducible
> example
> >>> >> using a GRASS sample dataset
> >>> >> (see https://grass.osgeo.org/download/sample-data/ - the Spearfish
> >>> >> dataset is probably the best)
> >>> >>
> >>> >> I will happily look int this if you can provide the necessary info.
> >>> >>
> >>> >> Cheers,
> >>> >>
> >>> >> Rainer
> >>> >>
> >>> >> >
> >>> >> > Mathieu
> >>> >> >
> >>> >> >       [[alternative HTML version deleted]]
> >>> >> >
> >>> >> > _______________________________________________
> >>> >> > R-sig-Geo mailing list
> >>> >> > R-sig-Geo at r-project.org
> >>> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>> >>
> >>> >> --
> >>> >> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
> >>> >> Biology, UCT), Dipl. Phys. (Germany)
> >>> >>
> >>> >> Centre of Excellence for Invasion Biology
> >>> >> Stellenbosch University
> >>> >> South Africa
> >>> >>
> >>> >> Tel :       +33 - (0)9 53 10 27 44
> >>> >> Cell:       +33 - (0)6 85 62 59 98
> >>> >> Fax :       +33 - (0)9 58 10 27 44
> >>> >>
> >>> >> Fax (D):    +49 - (0)3 21 21 25 22 44
> >>> >>
> >>> >> email:      Rainer at krugs.de
> >>> >>
> >>> >> Skype:      RMkrug
> >>> >>
> >>> >> PGP: 0x0F52F982
> >>> >>
> >>>
> >>> --
> >>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
> >>> Biology, UCT), Dipl. Phys. (Germany)
> >>>
> >>> Centre of Excellence for Invasion Biology
> >>> Stellenbosch University
> >>> South Africa
> >>>
> >>> Tel :       +33 - (0)9 53 10 27 44
> >>> Cell:       +33 - (0)6 85 62 59 98
> >>> Fax :       +33 - (0)9 58 10 27 44
> >>>
> >>> Fax (D):    +49 - (0)3 21 21 25 22 44
> >>>
> >>> email:      Rainer at krugs.de
> >>>
> >>> Skype:      RMkrug
> >>>
> >>> PGP: 0x0F52F982
> >>>
> >>
> >>
>
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
> Biology, UCT), Dipl. Phys. (Germany)
>
> Centre of Excellence for Invasion Biology
> Stellenbosch University
> South Africa
>
> Tel :       +33 - (0)9 53 10 27 44
> Cell:       +33 - (0)6 85 62 59 98
> Fax :       +33 - (0)9 58 10 27 44
>
> Fax (D):    +49 - (0)3 21 21 25 22 44
>
> email:      Rainer at krugs.de
>
> Skype:      RMkrug
>
> PGP: 0x0F52F982
>

	[[alternative HTML version deleted]]


From Rainer at krugs.de  Wed Oct 28 18:54:17 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Wed, 28 Oct 2015 18:54:17 +0100
Subject: [R-sig-Geo] spgrass6, readVECT and overwriting ?
In-Reply-To: <CAGfc75=y901cbM1b90C5jwR_iQ5Zq_EOyFhBquAABbtXKvnJFA@mail.gmail.com>
	(Mathieu Rajerison's message of "Wed, 28 Oct 2015 17:11:02 +0100")
References: <CAGfc75kOhMzWuXe_jm+A81-MoiSdRanoXViAycvKGoPLuRzwfw@mail.gmail.com>
	<m2mvv87b5l.fsf@krugs.de>
	<CAGfc75mgjHT94aZm7bEFkLO5628K-8-UR--Z-FQbpndX3tsSsA@mail.gmail.com>
	<m2lhaoe9sh.fsf@krugs.de>
	<CAGfc75kGAjR6xWHN+uX_U6xW6jjogVvOsgGGoVwKGeh=8uoa5A@mail.gmail.com>
	<CAGfc75=30WjKr1+77GCG=vpjnvYymKSddPKUpUZ-MYpTxP=mkg@mail.gmail.com>
	<m28u6nc9cd.fsf@krugs.de>
	<CAGfc75=y901cbM1b90C5jwR_iQ5Zq_EOyFhBquAABbtXKvnJFA@mail.gmail.com>
Message-ID: <m24mhadgl2.fsf@krugs.de>

Mathieu Rajerison <mathieu.rajerison at gmail.com> writes:

> Yes, you're right. I should export directly from GRASS.
>
> When doing :
>
> for (i in 1:3) {
>   f <- readVECT("f")
> }
>
> I get :
> with_c: argument reversed from version 0.7-11 and in GRASS 6
> ERREUR :Layer <f> already exists in OGR data source
>         'D:/GRASSDB/paca/mapset/.tmp'
> OGR data source with driver: ESRI Shapefile
> Source: "D:/GRASSDB/paca/mapset/.tmp", layer: "f"
> with 1 features
> It has 5 fields
> with_c: argument reversed from version 0.7-11 and in GRASS 6
> ERREUR :Layer <f> already exists in OGR data source
>         'D:/GRASSDB/paca/mapset/.tmp'
> OGR data source with driver: ESRI Shapefile
> Source: "D:/GRASSDB/paca/mapset/.tmp", layer: "f"
> with 1 features
> It has 5 fields
> with_c: argument reversed from version 0.7-11 and in GRASS 6
> ERREUR :Layer <f> already exists in OGR data source
>         'D:/GRASSDB/paca/mapset/.tmp'
> OGR data source with driver: ESRI Shapefile
> Source: "D:/GRASSDB/paca/mapset/.tmp", layer: "f"
> with 1 features
> It has 5 fields
> Warning messages:
> 1: running command 'v.out.ogr.exe -e -c input=f type=area layer=1
> dsn=D:/GRASSDB/paca/mapset/.tmp olayer=f format=ESRI_Shapefile' had status
> 1
> 2: running command 'v.out.ogr.exe -e -c input=f type=area layer=1
> dsn=D:/GRASSDB/paca/mapset/.tmp olayer=f format=ESRI_Shapefile' had status
> 1
> 3: running command 'v.out.ogr.exe -e -c input=f type=area layer=1
> dsn=D:/GRASSDB/paca/mapset/.tmp olayer=f format=ESRI_Shapefile' had status
> 1
>

This looks wrong. Could you please run a reproducible example using one
of the sample datasets, i.e.

1) start grass 6.4 and selsct a sample dataset as kocation
2) in the grass session start R
3) library(spgrass6)
4) for (i in 1:3) {x <- readVECT("soil")}

and send the transcript and the error messages?

Thanks,

Rainer


> -----------------
> sessionInfo() :
> R version 3.1.2 (2014-10-31)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252
>  LC_MONETARY=French_France.1252
> [4] LC_NUMERIC=C                   LC_TIME=French_France.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
>  [1] R.utils_2.1.0     R.oo_1.19.0       R.methodsS3_1.7.0 igraph_1.0.1
>  gdalUtils_2.0.1.7
>  [6] spdep_0.5-88      Matrix_1.2-2      maptools_0.8-34   spgrass6_0.8-8
>  XML_3.98-1.3
> [11] rgeos_0.3-8       FNN_1.1           rgdal_0.9-2       raster_2.3-40
>   sp_1.0-17
> [16] RStoolbox_0.1.1
>
> loaded via a namespace (and not attached):
>  [1] boot_1.3-13        car_2.0-25         caret_6.0-57       coda_0.18-1
>      codetools_0.2-9
>  [6] colorspace_1.2-6   deldir_0.1-9       digest_0.6.8
> doParallel_1.0.8   foreach_1.4.2
> [11] foreign_0.8-61     geosphere_1.4-3    ggplot2_1.0.1      grid_3.1.2
>       gtable_0.1.2
> [16] iterators_1.0.7    lattice_0.20-29    LearnBayes_2.15    lme4_1.1-10
>      magrittr_1.5
> [21] MASS_7.3-35        MatrixModels_0.4-1 mgcv_1.8-3         minqa_1.2.4
>      munsell_0.4.2
> [26] nlme_3.1-118       nloptr_1.0.4       nnet_7.3-8
> parallel_3.1.2     pbkrtest_0.4-2
> [31] plyr_1.8.3         proto_0.3-10       quantreg_5.19      Rcpp_0.12.0
>      reshape2_1.4.1
> [36] scales_0.2.5       SparseM_1.7        splines_3.1.2      stats4_3.1.2
>       stringi_0.5-5
> [41] stringr_1.0.0      tools_3.1.2
>
> 2015-10-28 16:16 GMT+01:00 Rainer M Krug <Rainer at krugs.de>:
>
>> Mathieu Rajerison <mathieu.rajerison at gmail.com> writes:
>>
>> > Before was the code that works.
>> >
>> > Below is the code that generates issues :
>> >
>> > (sorry the multiple posts)
>> >
>> > for (id in 1:length(grids)) {
>> >
>> > (...)
>> >
>> > ## SMOOTH
>> >   print(">> SMOOTH")
>> >   smoothed = smooth(sieved, 9)
>> >   values(smoothed)[values(smoothed) > 0] = 1
>> >   values(smoothed)[values(smoothed)==0] = NA
>> >
>> >   ## THIN
>> >   # WRITE TO GRASS
>> >   writeRAST(as(smoothed, "SpatialGridDataFrame"), "bdtopo", zcol="layer",
>> > flags=c("overwrite"))
>> >   execGRASS("g.region", rast="bdtopo")
>> >   execGRASS("r.thin", parameters=list(input="bdtopo", output="thin"),
>> > flags=c("overwrite"))
>> >   thin = raster(readRAST("thin"))
>> >
>> >   ## CLEAN
>> >   execGRASS("r.to.vect", parameters=list(input="thin", output="thin",
>> > feature="line"), flags=c("overwrite"))
>> >   execGRASS("v.clean", parameters=list(input="thin", tool="rmdangle",
>> > output="clean", thresh=20), flags=c("overwrite"))
>> >
>> >   cleaned = readVECT("clean")
>> >
>> >   ## EXPORT
>> >   writeOGR(cleaned, "OUT/CLEANED", id, "ESRI Shapefile")
>> > }
>>
>> OK. So what you are doing is in a loop
>>
>>   write a raster to grass
>>   calculations in GRASS
>>   read result vector layer into R
>>
>> And the error occurs in
>>
>> cleaned = readVECT("clean")
>>
>> as temporary files during the readVECT are not cleaned up and not
>> overwritten - correct?
>>
>> Then the rest is irrelevant.
>>
>> You can reproduce it by doing
>>
>> for (i in 1:10) {
>>   x <- readVECT("vectorLayerInSampleDataset")
>> }
>>
>> Could you try this and see if it works in a sample dataset?
>>
>> If it does, the error comes from somewhere else.
>>
>>
>> Under grass 7 it works:
>>
>> ,----
>> | 03:37:37 {master} ~/ownCompiled/emacs-mac$ grass70
>> | Cleaning up temporary files...
>> | Starting GRASS GIS...
>> |
>> |           __________  ___   __________    _______________
>> |          / ____/ __ \/   | / ___/ ___/   / ____/  _/ ___/
>> |         / / __/ /_/ / /| | \__ \\_  \   / / __ / / \__ \
>> |        / /_/ / _, _/ ___ |___/ /__/ /  / /_/ // / ___/ /
>> |        \____/_/ |_/_/  |_/____/____/   \____/___//____/
>> |
>> | Welcome to GRASS GIS 7.0.1
>> | GRASS GIS homepage:                      http://grass.osgeo.org
>> | This version running through:            Bash Shell (/usr/local/bin/bash)
>> | Help is available with the command:      g.manual -i
>> | See the licence terms with:              g.version -c
>> | If required, restart the GUI with:       g.gui wxpython
>> | When ready to quit enter:                exit
>> |
>> | Launching <wxpython> GUI in the background, please wait...
>> | GRASS 7.0.1 (nc_basic_spm_grass7):~/ownCompiled/emacs-mac > R
>> |
>> | R version 3.2.2 (2015-08-14) -- "Fire Safety"
>> | Copyright (C) 2015 The R Foundation for Statistical Computing
>> | Platform: x86_64-apple-darwin14.5.0 (64-bit)
>> |
>> | R is free software and comes with ABSOLUTELY NO WARRANTY.
>> | You are welcome to redistribute it under certain conditions.
>> | Type 'license()' or 'licence()' for distribution details.
>> |
>> |   Natural language support but running in an English locale
>> |
>> | R is a collaborative project with many contributors.
>> | Type 'contributors()' for more information and
>> | 'citation()' on how to cite R or R packages in publications.
>> |
>> | Type 'demo()' for some demos, 'help()' for on-line help, or
>> | 'help.start()' for an HTML browser interface to help.
>> | Type 'q()' to quit R.
>> |
>> | > library(rgrass7)
>> | Loading required package: sp
>> | Loading required package: XML
>> | GRASS GIS interface loaded with GRASS version: GRASS 7.0.1 (2015)
>> | and location: nc_basic_spm_grass7
>> | > x <- readVECT("streams")
>> | Exporting 8554 features...
>> |  100%
>> | v.out.ogr complete. 8554 features (Line String type) written to <streams>
>> | (ESRI_Shapefile format).
>> | OGR data source with driver: ESRI Shapefile
>> | Source:
>> "/Users/rainerkrug/nc_basic_spm_grass7/PERMANENT/.tmp/Rainers-MacBook-Pro.local",
>> layer: "streams"
>> | with 8554 features
>> | It has 14 fields
>> | > x <- readVECT("streams")
>> | Exporting 8554 features...
>> |  100%
>> | v.out.ogr complete. 8554 features (Line String type) written to <streams>
>> | (ESRI_Shapefile format).
>> | OGR data source with driver: ESRI Shapefile
>> | Source:
>> "/Users/rainerkrug/nc_basic_spm_grass7/PERMANENT/.tmp/Rainers-MacBook-Pro.local",
>> layer: "streams"
>> | with 8554 features
>> | It has 14 fields
>> | >
>> `----
>>
>>
>> and also under grass-64:
>>
>> ,----
>> | > library(spgrass6)
>> | Loading required package: sp
>> | Loading required package: XML
>> | GRASS GIS interface loaded with GRASS version: GRASS 6.4.4 (2014)
>> | and location: spearfish60
>> | > x_readVECT("soils")
>> | Error: could not find function "x_readVECT"
>> | > x <- readVECT("soils")
>> | with_c: argument reversed from version 0.7-11 and in GRASS 6
>> | Exporting 737 areas (may take some time)...
>> |  100%
>> | WARNING: 1 features without attributes were written
>> | v.out.ogr complete. 737 features written to <soils> (ESRI_Shapefile).
>> | OGR data source with driver: ESRI Shapefile
>> | Source:
>> "/Users/rainerkrug/spearfish60/user1/.tmp/Rainers-MacBook-Pro.local",
>> layer: "soils"
>> | with 737 features
>> | It has 2 fields
>> | Warning message:
>> | In execGRASS("v.out.ogr", flags = flags, input = vname, type = type,  :
>> |   The command:
>> | v.out.ogr -e -c input=soils type=area layer=1
>> dsn=/Users/rainerkrug/spearfish60/user1/.tmp/Rainers-MacBook-Pro.local
>> olayer=soils format=ESRI_Shapefile
>> | produced at least one warning during execution:
>> | Exporting 737 areas (may take some time)...
>> |  100%
>> | WARNING: 1 features without attributes were written
>> | v.out.ogr complete. 737 features written to <soils> (ESRI_Shapefile).
>> | > plot(x)
>> | > plot(x)
>> | > x <- readVECT("soils")
>> | with_c: argument reversed from version 0.7-11 and in GRASS 6
>> | Exporting 737 areas (may take some time)...
>> |  100%
>> | WARNING: 1 features without attributes were written
>> | v.out.ogr complete. 737 features written to <soils> (ESRI_Shapefile).
>> | OGR data source with driver: ESRI Shapefile
>> | Source:
>> "/Users/rainerkrug/spearfish60/user1/.tmp/Rainers-MacBook-Pro.local",
>> layer: "soils"
>> | with 737 features
>> | It has 2 fields
>> | Warning message:
>> | In execGRASS("v.out.ogr", flags = flags, input = vname, type = type,  :
>> |   The command:
>> | v.out.ogr -e -c input=soils type=area layer=1
>> dsn=/Users/rainerkrug/spearfish60/user1/.tmp/Rainers-MacBook-Pro.local
>> olayer=soils format=ESRI_Shapefile
>> | produced at least one warning during execution:
>> | Exporting 737 areas (may take some time)...
>> |  100%
>> | WARNING: 1 features without attributes were written
>> | v.out.ogr complete. 737 features written to <soils> (ESRI_Shapefile).
>> | >
>> `----
>>
>>
>> Also: if you want to export it to a shape file, why do you import it
>> into R and save it afterwards? Why not write it directly from GRASS as a
>> shape file?
>>
>> Cheers,
>>
>> Rainer
>>
>> >
>> > 2015-10-28 14:18 GMT+01:00 Mathieu Rajerison <
>> mathieu.rajerison at gmail.com>:
>> >
>> >> Mr Krug,
>> >>
>> >>
>> >> It is difficult to reproduce an example from the spearfish dataset as it
>> >> doesn't natively contain data in it close to the one I used.
>> >>
>> >> To give you th context, my goal is to detect all blue features : rivers
>> >> from a topographic map, ie 3-band RGB raster.
>> >>
>> >> With RStoolbox, I perform a Spectral Angle Classification of my data
>> using
>> >> sample points located on (near)blue pixels
>> >>
>> >> With GRASS, I then thin, vectorize and clean the result.
>> >>
>> >> As the process must be performed on a very large scale, I split it using
>> >> grids where sample RGB parts of the topo map are extracted with
>> >> gdal_translate. Everything is executed within a loop. At the end of the
>> >> loop, I export the resulted cleant shapefile in a folder. At the end, I
>> >> have as many shapefiles as processing grids.
>> >>
>> >> That's why I use temporary vector datasets inside GRASS that are
>> >> overwritten at each loop instead of storing each individual result. I
>> >> noticed that in my process, the vector data read in the grass database
>> was
>> >> not correct : always the first one. Because in fact, it didn't manage to
>> >> delete the temporary file before writing the new one..
>> >>
>> >> The best I can do, is give you part of the code as as you can see the
>> >> context.
>> >>
>> >> Thanks for the code improvements with file.remove and unlink !
>> >>
>> >> Cheers,
>> >>
>> >> Mathieu
>> >>
>> >> for (id in 1:length(grids)) {
>> >>
>> >> (...)
>> >>
>> >> ## SMOOTH
>> >>   print(">> SMOOTH")
>> >>   smoothed = smooth(sieved, 9)
>> >>   values(smoothed)[values(smoothed) > 0] = 1
>> >>   values(smoothed)[values(smoothed)==0] = NA
>> >>
>> >>   ## THIN
>> >>   # WRITE TO GRASS
>> >>   writeRAST(as(smoothed, "SpatialGridDataFrame"), "bdtopo",
>> zcol="layer",
>> >> flags=c("overwrite"))
>> >>   execGRASS("g.region", rast="bdtopo")
>> >>   execGRASS("r.thin", parameters=list(input="bdtopo", output="thin"),
>> >> flags=c("overwrite"))
>> >>   thin = raster(readRAST("thin"))
>> >>
>> >>   ## CLEAN
>> >>   execGRASS("r.to.vect", parameters=list(input="thin", output="thin",
>> >> feature="line"), flags=c("overwrite"))
>> >>   execGRASS("v.clean", parameters=list(input="thin", tool="rmdangle",
>> >> output="clean", thresh=20), flags=c("overwrite"))
>> >>
>> >>   # REMOVE FILES
>> >>   G = gmeta()
>> >>   tmpDir = file.path(G$GISDBASE, G$LOCATION_NAME, G$MAPSET, ".tmp")
>> >>   file.remove( list.files(path = tmpDir, Pattern ="^clean.*$",
>> full.names
>> >> = TRUE))
>> >>
>> >>   # READ TO SPDF
>> >>   execGRASS("v.out.ogr", parameters=list(input="clean", type="line",
>> >> dsn=tmpDir, olayer="clean", format="ESRI_Shapefile"))
>> >>   cleaned = readOGR(tmpDir, "clean")
>> >>
>> >>   ## EXPORT
>> >>   writeOGR(cleaned, "OUT/CLEANED", id, "ESRI Shapefile")
>> >> }
>> >>
>> >> 2015-10-27 14:11 GMT+01:00 Rainer M Krug <Rainer at krugs.de>:
>> >>
>> >>> Mathieu Rajerison <mathieu.rajerison at gmail.com> writes:
>> >>>
>> >>> > Dear Mr Krug,
>> >>> >
>> >>>
>> >>> I'll Cc the R-sig-geo list in to keep the conversation there for future
>> >>> reference and for other users who might have the same problem.
>> >>>
>> >>> > Sorry in advance for my english.
>> >>>
>> >>> Don't worry abut your English - it is perfectly fine.
>> >>>
>> >>> >
>> >>> > My question was not about debugging, but about a potentiel generic
>> >>> > behaviour of spgrass6.
>> >>> >
>> >>> > I should have reformulated my question in a simpler manner : does
>> >>> spgrass6
>> >>> > allow overwriting an existing dataset when using readVECT function ?
>> >>>
>> >>> The functions readVect / RAST are using temporary files - you are
>> right,
>> >>> but they should delete these upon exit. So if they do nbot do this, it
>> >>> is a bug.
>> >>>
>> >>> >
>> >>> > 1) no version information about R and GRASS (there are several GRASS
>> 6
>> >>> > versions)
>> >>> > I've just put it at the end of this post.
>> >>> > 2) no session information i.e. package versions used
>> >>> > the latest spgrass6
>> >>> > 3) no information about the OS (I guess it is windows based on the
>> >>> > Source path above)
>> >>> > you're right
>> >>>
>> >>> OK - thanks.
>> >>>
>> >>> > 4) no reproducible example which could be easily done by using the
>> GRASS
>> >>>
>> >>> As I said - if you manually have to delete the temporary files, then
>> >>> there is a bug in the package. Could you please provide a reproducible
>> >>> example, using one of the example data sets from GRASS, so that I can
>> >>> look at it?
>> >>>
>> >>> > 5) as far as I can see, in the newest version of spgrass6 there is no
>> >>> > function readVECT()
>> >>> > Yes, there is, as you will see on page 14 of the documentation.
>> >>>
>> >>> Sorry - overlooked it.
>> >>>
>> >>> >
>> >>> > Finally, I solved the problem by using the following hint, "clean"
>> being
>> >>> > the name of my temporary shapefile dataset :
>> >>> >   l = list.files("D:/GRASSDB/paca/mapset/.tmp", "^clean.*$"); l =
>> >>> > file.path("D:/GRASSDB/paca/mapset/.tmp", l)
>> >>> >   lapply(l,  file.remove)
>> >>> >   execGRASS("v.out.ogr", parameters=list(input="clean", type="line",
>> >>> > dsn="D:/GRASSDB/paca/mapset/.tmp", olayer="clean",
>> >>> format="ESRI_Shapefile"))
>> >>>
>> >>> OK - reformated, the code looks as follow:
>> >>>
>> >>> --8<---------------cut here---------------start------------->8---
>> >>> l = list.files("D:/GRASSDB/paca/mapset/.tmp", "^clean.*$")
>> >>> l = file.path("D:/GRASSDB/paca/mapset/.tmp", l)
>> >>> lapply(l,  file.remove)
>> >>> execGRASS( "v.out.ogr",
>> >>>            parameters=list(input="clean",
>> >>> type="line",dsn="D:/GRASSDB/paca/mapset/.tmp", olayer="clean",
>> >>> format="ESRI_Shapefile"))
>> >>> --8<---------------cut here---------------end--------------->8---
>> >>>
>> >>> as a side note, you should be able to do
>> >>>
>> >>> file.remove( list.files(path = "D:/GRASSDB/paca/mapset/.tmp", Pattern =
>> >>> "^clean.*$", full.names = TRUE) )
>> >>>
>> >>> or
>> >>>
>> >>> unlink("D:/GRASSDB/paca/mapset/.tmp/clean.*")
>> >>>
>> >>> instead of the first three commands.
>> >>>
>> >>> Now - in your example, you don't use the readVECT() function?
>> >>>
>> >>> If you check in the GRASS help for v.out.ogr, you can specify the
>> >>> overwrite flag and the exported layer will be overwritten.
>> >>>
>> >>> But I have the feeling you are doing something in a to complicated way.
>> >>>
>> >>> What is it you want to do, and e=what is the problem you have or the
>> >>> error message you get?
>> >>>
>> >>> Cheers,
>> >>>
>> >>> Rainer
>> >>>
>> >>> >
>> >>> >
>> >>> >> R.Version()
>> >>> > $platform
>> >>> > [1] "x86_64-w64-mingw32"
>> >>> > $arch
>> >>> > [1] "x86_64"
>> >>> > $os
>> >>> > [1] "mingw32"
>> >>> >
>> >>> > $system
>> >>> > [1] "x86_64, mingw32"
>> >>> > (...)
>> >>> > $version.string
>> >>> > [1] "R version 3.1.2 (2014-10-31)"
>> >>> > $nickname
>> >>> > [1] "Pumpkin Helmet"
>> >>> >
>> >>> > I will happily look int this if you can provide the necessary info.
>> >>> >
>> >>> > Cheers,
>> >>> >
>> >>> > Mathieu
>> >>> >
>> >>> > 2015-10-24 13:34 GMT+02:00 Rainer M Krug <Rainer at krugs.de>:
>> >>> >
>> >>> >> Mathieu Rajerison <mathieu.rajerison at gmail.com> writes:
>> >>> >>
>> >>> >> > Hi,
>> >>> >> >
>> >>> >> > I'm using spgrass6 and I use readVECT function in a loop.
>> >>> >> >
>> >>> >> > Using it causes an error because it doesn't overwrite the the
>> >>> temporary
>> >>> >> > shapefile..
>> >>> >> >
>> >>> >> >> thin = readVECT(vname="zoneBDTOPOthin")
>> >>> >> > with_c: argument reversed from version 0.7-11 and in GRASS 6
>> >>> >> > ERROR :Layer <zoneBDTO> already exists in OGR data source
>> >>> >> >         'D:/GRASSDB/paca/mapset/.tmp'
>> >>> >> > OGR data source with driver: ESRI Shapefile
>> >>> >> > Source: "D:/GRASSDB/paca/mapset/.tmp", layer: "zoneBDTO"
>> >>> >> > with 770 features
>> >>> >> > It has 3 fields
>> >>> >> > Warning message:
>> >>> >> > running command 'v.out.ogr.exe -e -c input=zoneBDTOPOthin2
>> type=line
>> >>> >> > layer=1 dsn=D:/GRASSDB/paca/mapset/.tmp olayer=zoneBDTO
>> >>> >> > format=ESRI_Shapefile' had status 1
>> >>> >> >
>> >>> >> >
>> >>> >> > I wonder how to specify to spgrass that I want to overwrite the
>> file
>> >>> in
>> >>> >> > readVECT, although I know using execGRASS and v.out.ogr with the
>> >>> >> > appropriate overwrite flags would do the job.
>> >>> >> >
>> >>> >> > Thanks in advance for the answer..
>> >>> >>
>> >>> >> One reason why probably nobody replied is that
>> >>> >>
>> >>> >> 1) no version information about R and GRASS (there are several
>> GRASS 6
>> >>> >> versions)
>> >>> >> 2) no session information i.e. package versions used
>> >>> >> 3) no information about the OS (I guess it is windows based on the
>> >>> >> Source path above)
>> >>> >> 4) no reproducible example which could be easily done by using the
>> >>> GRASS
>> >>> >> 5) as far as I can see, in the newest version of spgrass6 there is
>> no
>> >>> >> function readVECT()
>> >>> >>
>> >>> >> So I would suggest to provide the info and give a reproducible
>> example
>> >>> >> using a GRASS sample dataset
>> >>> >> (see https://grass.osgeo.org/download/sample-data/ - the Spearfish
>> >>> >> dataset is probably the best)
>> >>> >>
>> >>> >> I will happily look int this if you can provide the necessary info.
>> >>> >>
>> >>> >> Cheers,
>> >>> >>
>> >>> >> Rainer
>> >>> >>
>> >>> >> >
>> >>> >> > Mathieu
>> >>> >> >
>> >>> >> >       [[alternative HTML version deleted]]
>> >>> >> >
>> >>> >> > _______________________________________________
>> >>> >> > R-sig-Geo mailing list
>> >>> >> > R-sig-Geo at r-project.org
>> >>> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >>> >>
>> >>> >> --
>> >>> >> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
>> >>> >> Biology, UCT), Dipl. Phys. (Germany)
>> >>> >>
>> >>> >> Centre of Excellence for Invasion Biology
>> >>> >> Stellenbosch University
>> >>> >> South Africa
>> >>> >>
>> >>> >> Tel :       +33 - (0)9 53 10 27 44
>> >>> >> Cell:       +33 - (0)6 85 62 59 98
>> >>> >> Fax :       +33 - (0)9 58 10 27 44
>> >>> >>
>> >>> >> Fax (D):    +49 - (0)3 21 21 25 22 44
>> >>> >>
>> >>> >> email:      Rainer at krugs.de
>> >>> >>
>> >>> >> Skype:      RMkrug
>> >>> >>
>> >>> >> PGP: 0x0F52F982
>> >>> >>
>> >>>
>> >>> --
>> >>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
>> >>> Biology, UCT), Dipl. Phys. (Germany)
>> >>>
>> >>> Centre of Excellence for Invasion Biology
>> >>> Stellenbosch University
>> >>> South Africa
>> >>>
>> >>> Tel :       +33 - (0)9 53 10 27 44
>> >>> Cell:       +33 - (0)6 85 62 59 98
>> >>> Fax :       +33 - (0)9 58 10 27 44
>> >>>
>> >>> Fax (D):    +49 - (0)3 21 21 25 22 44
>> >>>
>> >>> email:      Rainer at krugs.de
>> >>>
>> >>> Skype:      RMkrug
>> >>>
>> >>> PGP: 0x0F52F982
>> >>>
>> >>
>> >>
>>
>> --
>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
>> Biology, UCT), Dipl. Phys. (Germany)
>>
>> Centre of Excellence for Invasion Biology
>> Stellenbosch University
>> South Africa
>>
>> Tel :       +33 - (0)9 53 10 27 44
>> Cell:       +33 - (0)6 85 62 59 98
>> Fax :       +33 - (0)9 58 10 27 44
>>
>> Fax (D):    +49 - (0)3 21 21 25 22 44
>>
>> email:      Rainer at krugs.de
>>
>> Skype:      RMkrug
>>
>> PGP: 0x0F52F982
>>

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151028/1f090b29/attachment.bin>

From thi_veloso at yahoo.com.br  Thu Oct 29 08:46:03 2015
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Thu, 29 Oct 2015 07:46:03 +0000 (UTC)
Subject: [R-sig-Geo] Monthly loop in raster stack with daily data
References: <2116460889.1287250.1446104763361.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <2116460889.1287250.1446104763361.JavaMail.yahoo@mail.yahoo.com>

Hi all,

I am working with very large raster stacks. Each stack is a time-series climate forecast, where the layers are *daily* values of a given meteorological variable (say temperature).

How can I loop through the *months* in the raster and count the number of *days* above a certain threshold?


Please see the code below showing a raster with two years of daily data:

#Create a rasterStack similar to my data - same dimensions and layer names
r <- raster(ncol=360, nrow=180)
s <- stack(lapply(1:730, function(x) setValues(r, runif(ncell(r),min=0,max=30))))
idx <- seq(as.Date("2010/1/1"), by = "day", length.out = 730)
s <- setZ(s, idx)
s

hot.days <- calc(s, function(x,na.rm) sum(x) > 25) # I need to do this for every month in the raster stack, counting the number of days where temperature is greater than 25.

The final raster would have 24 layers (12 months x 2 years) with the count of days.

Is this analysis possible to be done on a raster or should I convert the data to a different format?
Thanks a lot,
 -- Thiago V. dos Santos

PhD student
Land and Atmospheric Science
University of Minnesota


From loic.dutrieux at wur.nl  Thu Oct 29 09:42:13 2015
From: loic.dutrieux at wur.nl (=?UTF-8?Q?Lo=c3=afc_Dutrieux?=)
Date: Thu, 29 Oct 2015 09:42:13 +0100
Subject: [R-sig-Geo] Monthly loop in raster stack with daily data
In-Reply-To: <2116460889.1287250.1446104763361.JavaMail.yahoo@mail.yahoo.com>
References: <2116460889.1287250.1446104763361.JavaMail.yahoo@mail.yahoo.com>
	<2116460889.1287250.1446104763361.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <5631DBE5.6010603@wur.nl>

Hi Thiago,

I think zApply should get you there (for each stack independently).

library(zoo)
library(raster)

#Create a rasterStack similar to my data - same dimensions and layer names
r <- raster(ncol=360, nrow=180)
s <- stack(lapply(1:730, function(x) setValues(r, 
runif(ncell(r),min=0,max=30))))
idx <- seq(as.Date("2010/1/1"), by = "day", length.out = 730)
s <- setZ(s, idx)

fun <- function(x, na.rm) {
   sum(x > 25, na.rm)
}
zApply(s, by=as.yearmon, fun = fun)

Cheers,
Lo?c

On 10/29/2015 08:46 AM, Thiago V. dos Santos wrote:
> Hi all,
>
> I am working with very large raster stacks. Each stack is a time-series climate forecast, where the layers are *daily* values of a given meteorological variable (say temperature).
>
> How can I loop through the *months* in the raster and count the number of *days* above a certain threshold?
>
>
> Please see the code below showing a raster with two years of daily data:
>
> #Create a rasterStack similar to my data - same dimensions and layer names
> r <- raster(ncol=360, nrow=180)
> s <- stack(lapply(1:730, function(x) setValues(r, runif(ncell(r),min=0,max=30))))
> idx <- seq(as.Date("2010/1/1"), by = "day", length.out = 730)
> s <- setZ(s, idx)
> s
>
> hot.days <- calc(s, function(x,na.rm) sum(x) > 25) # I need to do this for every month in the raster stack, counting the number of days where temperature is greater than 25.
>
> The final raster would have 24 layers (12 months x 2 years) with the count of days.
>
> Is this analysis possible to be done on a raster or should I convert the data to a different format?
> Thanks a lot,
>   -- Thiago V. dos Santos
>
> PhD student
> Land and Atmospheric Science
> University of Minnesota
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From thi_veloso at yahoo.com.br  Thu Oct 29 18:00:40 2015
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Thu, 29 Oct 2015 17:00:40 +0000 (UTC)
Subject: [R-sig-Geo] Monthly loop in raster stack with daily data
In-Reply-To: <5631DBE5.6010603@wur.nl>
References: <2116460889.1287250.1446104763361.JavaMail.yahoo@mail.yahoo.com>
	<2116460889.1287250.1446104763361.JavaMail.yahoo@mail.yahoo.com>
	<5631DBE5.6010603@wur.nl>
Message-ID: <543116537.1482511.1446138040682.JavaMail.yahoo@mail.yahoo.com>

Thanks a lot Lo?c. I could not imagine that it would be that easy!
 Greetings,
 -- Thiago V. dos Santos

PhD student
Land and Atmospheric Science
University of Minnesota



On Thursday, October 29, 2015 3:44 AM, Lo?c Dutrieux <loic.dutrieux at wur.nl> wrote:
Hi Thiago,

I think zApply should get you there (for each stack independently).

library(zoo)
library(raster)

#Create a rasterStack similar to my data - same dimensions and layer names
r <- raster(ncol=360, nrow=180)
s <- stack(lapply(1:730, function(x) setValues(r, 
runif(ncell(r),min=0,max=30))))
idx <- seq(as.Date("2010/1/1"), by = "day", length.out = 730)
s <- setZ(s, idx)

fun <- function(x, na.rm) {
   sum(x > 25, na.rm)
}
zApply(s, by=as.yearmon, fun = fun)

Cheers,
Lo?c

On 10/29/2015 08:46 AM, Thiago V. dos Santos wrote:
> Hi all,
>
> I am working with very large raster stacks. Each stack is a time-series climate forecast, where the layers are *daily* values of a given meteorological variable (say temperature).
>
> How can I loop through the *months* in the raster and count the number of *days* above a certain threshold?
>
>
> Please see the code below showing a raster with two years of daily data:
>
> #Create a rasterStack similar to my data - same dimensions and layer names
> r <- raster(ncol=360, nrow=180)
> s <- stack(lapply(1:730, function(x) setValues(r, runif(ncell(r),min=0,max=30))))
> idx <- seq(as.Date("2010/1/1"), by = "day", length.out = 730)
> s <- setZ(s, idx)
> s
>
> hot.days <- calc(s, function(x,na.rm) sum(x) > 25) # I need to do this for every month in the raster stack, counting the number of days where temperature is greater than 25.
>
> The final raster would have 24 layers (12 months x 2 years) with the count of days.
>
> Is this analysis possible to be done on a raster or should I convert the data to a different format?
> Thanks a lot,
>   -- Thiago V. dos Santos
>
> PhD student
> Land and Atmospheric Science
> University of Minnesota
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

>

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From thi_veloso at yahoo.com.br  Thu Oct 29 21:06:24 2015
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Thu, 29 Oct 2015 20:06:24 +0000 (UTC)
Subject: [R-sig-Geo] Programmatically convert raster stack in data frame
 based on polygon extraction
References: <1505079764.1568995.1446149184083.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1505079764.1568995.1446149184083.JavaMail.yahoo@mail.yahoo.com>

Hi all,

I am trying to extract temperature values from a raster stack for about 400 municipalities in Brazil. My final goal is to create a data frame that is going to be used as a database for an interactive map server - probably using shiny and leaflet.

The final data frame would look like this:


> head(df)
Location         Var Cut Year Month Freq
Campinas  temperature  10 2010   1    11
Campinas  temperature  10 2010   2    19
Campinas  temperature  10 2010   3    30
Campinas  temperature  10 2010   4    29
Campinas  temperature  10 2010   5    31
Campinas  temperature  10 2010   6    30


I have global raster stacks with daily data and I am counting, for each month in the raster, the number of days above certain temperature threshold. Please see below:


library(raster)
library(zoo)
library(maptools)

# Create a rasterStack similar to my data - same dimensions and layer namesr <- raster(ncol=360, nrow=180)
s <- stack(lapply(1:730, function(x) setValues(r, runif(ncell(r),min=0,max=30))))
idx <- seq(as.Date("2010/1/1"), by = "day", length.out = 730)
s <- setZ(s, idx)
s

# Define functions for 10, 15, 20 and 25 degrees - Thanks Lo?c in my previous question
fun1 <- function(x, na.rm) {
sum(x > 10, na.rm)
}

fun2 <- function(x, na.rm) {
sum(x > 15, na.rm)
}

fun3 <- function(x, na.rm) {
sum(x > 20, na.rm)
}

fun4 <- function(x, na.rm) {
sum(x > 25, na.rm)
}

# Count number of days above the threshold temperature
days.above.10 <- zApply(s, by=as.yearmon, fun = fun1)
days.above.15 <- zApply(s, by=as.yearmon, fun = fun2)
days.above.20 <- zApply(s, by=as.yearmon, fun = fun3)
days.above.25 <- zApply(s, by=as.yearmon, fun = fun4)


Now, what I would like to do is to programmatically extract values for each location on my study area. The locations are defined as a shapefile with municipal contours of the Sao Paulo state in Brazil.


In this example, however, just for reproducibility's sake, I will be using a world polygon. But keep in mind that in my actual data the polygons will be much smaller.


# Import *sample* polygon data and subset only five "locations"
data(wrld_simpl)
locs <- subset(wrld_simpl, wrld_simpl at data$NAME %in% c("Argentina","Bolivia","Brazil","Paraguay","Uruguay"))

# Plot
plot(days.above.10,1)
plot(locs,add=T)


I feel like half of the work is done, but I am just grasping with the conversion to data frames.

Based on this self-contained example I provided, what would be the best strategy to come out with a data frame per location, like this?

> head(Argentina.df)
Location         Var Cut Year Month Freq
Argentina temperature  10 2010     1  11
Argentina temperature  10 2010     2  19
Argentina temperature  10 2010     3  30
Argentina temperature 10 2010     4  12
Argentina temperature 10 2010     5  17
Argentina temperature 10 2010     6  14


> head(Bolivia.df)
Location         Var Cut Year Month Freq
Bolivia   temperature  10 2010     1  29
Bolivia   temperature  10 2010     2  31
Bolivia   temperature  10 2010     3  30

Bolivia   temperature 10 2010     4  17
Bolivia   temperature 10 2010     5  19
Bolivia   temperature 10 2010     6  12

and so on.

Note that "cut" refers to the temperature thresholds defined in the functions above. Each cut should come from the equivalent raster stack: days.above.10, days.above.15 and so on.

I much appreciate any input. 
Greetings,
 -- Thiago V. dos Santos

PhD student
Land and Atmospheric Science
University of Minnesota


From loic.dutrieux at wur.nl  Thu Oct 29 22:13:46 2015
From: loic.dutrieux at wur.nl (=?UTF-8?Q?Lo=c3=afc_Dutrieux?=)
Date: Thu, 29 Oct 2015 22:13:46 +0100
Subject: [R-sig-Geo] Programmatically convert raster stack in data frame
 based on polygon extraction
In-Reply-To: <1505079764.1568995.1446149184083.JavaMail.yahoo@mail.yahoo.com>
References: <1505079764.1568995.1446149184083.JavaMail.yahoo@mail.yahoo.com>
	<1505079764.1568995.1446149184083.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <56328C0A.1070202@wur.nl>

Hi Thiago,

extract() and some dataframe manipulation should do the trick. See 
comments in line.

Cheers,
Lo?c

On 10/29/2015 09:06 PM, Thiago V. dos Santos wrote:
> Hi all,
>
> I am trying to extract temperature values from a raster stack for about 400 municipalities in Brazil. My final goal is to create a data frame that is going to be used as a database for an interactive map server - probably using shiny and leaflet.
>
Cool project

> The final data frame would look like this:
>
>
>> head(df)
> Location         Var Cut Year Month Freq
> Campinas  temperature  10 2010   1    11
> Campinas  temperature  10 2010   2    19
> Campinas  temperature  10 2010   3    30
> Campinas  temperature  10 2010   4    29
> Campinas  temperature  10 2010   5    31
> Campinas  temperature  10 2010   6    30
>
>
> I have global raster stacks with daily data and I am counting, for each month in the raster, the number of days above certain temperature threshold. Please see below:
>
>
> library(raster)
> library(zoo)
> library(maptools)
# additional packages for dataframes manipulation
library(dplyr)
library(tidyr)
>
> # Create a rasterStack similar to my data - same dimensions and layer namesr <- raster(ncol=360, nrow=180)
> s <- stack(lapply(1:730, function(x) setValues(r, runif(ncell(r),min=0,max=30))))
> idx <- seq(as.Date("2010/1/1"), by = "day", length.out = 730)
> s <- setZ(s, idx)
> s
>
> # Define functions for 10, 15, 20 and 25 degrees - Thanks Lo?c in my previous question
> fun1 <- function(x, na.rm) {
> sum(x > 10, na.rm)
> }
>
> fun2 <- function(x, na.rm) {
> sum(x > 15, na.rm)
> }
>
> fun3 <- function(x, na.rm) {
> sum(x > 20, na.rm)
> }
>
> fun4 <- function(x, na.rm) {
> sum(x > 25, na.rm)
> }
>
> # Count number of days above the threshold temperature
> days.above.10 <- zApply(s, by=as.yearmon, fun = fun1)
> days.above.15 <- zApply(s, by=as.yearmon, fun = fun2)
> days.above.20 <- zApply(s, by=as.yearmon, fun = fun3)
> days.above.25 <- zApply(s, by=as.yearmon, fun = fun4)
>
>
> Now, what I would like to do is to programmatically extract values for each location on my study area. The locations are defined as a shapefile with municipal contours of the Sao Paulo state in Brazil.
>
>
> In this example, however, just for reproducibility's sake, I will be using a world polygon. But keep in mind that in my actual data the polygons will be much smaller.
>
>
> # Import *sample* polygon data and subset only five "locations"
> data(wrld_simpl)
> locs <- subset(wrld_simpl, wrld_simpl at data$NAME %in% c("Argentina","Bolivia","Brazil","Paraguay","Uruguay"))
>
> # Plot
> plot(days.above.10,1)
> plot(locs,add=T)
>

# Extract values for all polygons
spdf <- raster::extract(days.above.10, locs, fun = median, na.rm = TRUE, 
sp = TRUE)

# There is also a df = TRUE option in extract, but it returns only the 
extracted raster values, without binding them with the 
spatialpolygondataframe attributes. I think

# Get dataframe out of spdf
df <- spdf at data

df1 <- select(df, NAME, Jan.2010:Dec.2010)
df2 <- gather(df1, period, freq, -NAME)
df3 <- separate(df2, period, into = c('month', 'year'))
# Can you add these columns "manually" or does it need to be automated?
df3$variable <- 'temperature'
df3$cut <- 10

# If you do the same for cut == 15, etc, you can then rbind() them


>
> I feel like half of the work is done, but I am just grasping with the conversion to data frames.
>
> Based on this self-contained example I provided, what would be the best strategy to come out with a data frame per location, like this?
>
>> head(Argentina.df)
> Location         Var Cut Year Month Freq
> Argentina temperature  10 2010     1  11
> Argentina temperature  10 2010     2  19
> Argentina temperature  10 2010     3  30
> Argentina temperature 10 2010     4  12
> Argentina temperature 10 2010     5  17
> Argentina temperature 10 2010     6  14
>
>
>> head(Bolivia.df)
> Location         Var Cut Year Month Freq
> Bolivia   temperature  10 2010     1  29
> Bolivia   temperature  10 2010     2  31
> Bolivia   temperature  10 2010     3  30
>
> Bolivia   temperature 10 2010     4  17
> Bolivia   temperature 10 2010     5  19
> Bolivia   temperature 10 2010     6  12
>
> and so on.
>
> Note that "cut" refers to the temperature thresholds defined in the functions above. Each cut should come from the equivalent raster stack: days.above.10, days.above.15 and so on.
>
> I much appreciate any input.
> Greetings,
>   -- Thiago V. dos Santos
>
> PhD student
> Land and Atmospheric Science
> University of Minnesota
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From thi_veloso at yahoo.com.br  Fri Oct 30 00:14:01 2015
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Thu, 29 Oct 2015 23:14:01 +0000 (UTC)
Subject: [R-sig-Geo] Programmatically convert raster stack in data frame
 based on polygon extraction
In-Reply-To: <56328C0A.1070202@wur.nl>
References: <1505079764.1568995.1446149184083.JavaMail.yahoo@mail.yahoo.com>
	<1505079764.1568995.1446149184083.JavaMail.yahoo@mail.yahoo.com>
	<56328C0A.1070202@wur.nl>
Message-ID: <1059319645.892616.1446160441648.JavaMail.yahoo@mail.yahoo.com>

Thanks a lot again, Lo?c. It worked exactly as I was planned.
 Greetings,
 -- Thiago V. dos Santos

PhD student
Land and Atmospheric Science
University of Minnesota



On Thursday, October 29, 2015 4:15 PM, Lo?c Dutrieux <loic.dutrieux at wur.nl> wrote:
Hi Thiago,

extract() and some dataframe manipulation should do the trick. See 
comments in line.

Cheers,
Lo?c

On 10/29/2015 09:06 PM, Thiago V. dos Santos wrote:
> Hi all,
>
> I am trying to extract temperature values from a raster stack for about 400 municipalities in Brazil. My final goal is to create a data frame that is going to be used as a database for an interactive map server - probably using shiny and leaflet.
>
Cool project

> The final data frame would look like this:
>
>
>> head(df)
> Location         Var Cut Year Month Freq
> Campinas  temperature  10 2010   1    11
> Campinas  temperature  10 2010   2    19
> Campinas  temperature  10 2010   3    30
> Campinas  temperature  10 2010   4    29
> Campinas  temperature  10 2010   5    31
> Campinas  temperature  10 2010   6    30
>
>
> I have global raster stacks with daily data and I am counting, for each month in the raster, the number of days above certain temperature threshold. Please see below:
>
>
> library(raster)
> library(zoo)
> library(maptools)
# additional packages for dataframes manipulation
library(dplyr)
library(tidyr)
>
> # Create a rasterStack similar to my data - same dimensions and layer namesr <- raster(ncol=360, nrow=180)
> s <- stack(lapply(1:730, function(x) setValues(r, runif(ncell(r),min=0,max=30))))
> idx <- seq(as.Date("2010/1/1"), by = "day", length.out = 730)
> s <- setZ(s, idx)
> s
>
> # Define functions for 10, 15, 20 and 25 degrees - Thanks Lo?c in my previous question
> fun1 <- function(x, na.rm) {
> sum(x > 10, na.rm)
> }
>
> fun2 <- function(x, na.rm) {
> sum(x > 15, na.rm)
> }
>
> fun3 <- function(x, na.rm) {
> sum(x > 20, na.rm)
> }
>
> fun4 <- function(x, na.rm) {
> sum(x > 25, na.rm)
> }
>
> # Count number of days above the threshold temperature
> days.above.10 <- zApply(s, by=as.yearmon, fun = fun1)
> days.above.15 <- zApply(s, by=as.yearmon, fun = fun2)
> days.above.20 <- zApply(s, by=as.yearmon, fun = fun3)
> days.above.25 <- zApply(s, by=as.yearmon, fun = fun4)
>
>
> Now, what I would like to do is to programmatically extract values for each location on my study area. The locations are defined as a shapefile with municipal contours of the Sao Paulo state in Brazil.
>
>
> In this example, however, just for reproducibility's sake, I will be using a world polygon. But keep in mind that in my actual data the polygons will be much smaller.
>
>
> # Import *sample* polygon data and subset only five "locations"
> data(wrld_simpl)
> locs <- subset(wrld_simpl, wrld_simpl at data$NAME %in% c("Argentina","Bolivia","Brazil","Paraguay","Uruguay"))
>
> # Plot
> plot(days.above.10,1)
> plot(locs,add=T)
>

# Extract values for all polygons
spdf <- raster::extract(days.above.10, locs, fun = median, na.rm = TRUE, 
sp = TRUE)

# There is also a df = TRUE option in extract, but it returns only the 
extracted raster values, without binding them with the 
spatialpolygondataframe attributes. I think

# Get dataframe out of spdf
df <- spdf at data

df1 <- select(df, NAME, Jan.2010:Dec.2010)
df2 <- gather(df1, period, freq, -NAME)
df3 <- separate(df2, period, into = c('month', 'year'))
# Can you add these columns "manually" or does it need to be automated?
df3$variable <- 'temperature'
df3$cut <- 10

# If you do the same for cut == 15, etc, you can then rbind() them


>
> I feel like half of the work is done, but I am just grasping with the conversion to data frames.
>
> Based on this self-contained example I provided, what would be the best strategy to come out with a data frame per location, like this?
>
>> head(Argentina.df)
> Location         Var Cut Year Month Freq
> Argentina temperature  10 2010     1  11
> Argentina temperature  10 2010     2  19
> Argentina temperature  10 2010     3  30
> Argentina temperature 10 2010     4  12
> Argentina temperature 10 2010     5  17
> Argentina temperature 10 2010     6  14
>
>
>> head(Bolivia.df)
> Location         Var Cut Year Month Freq
> Bolivia   temperature  10 2010     1  29
> Bolivia   temperature  10 2010     2  31
> Bolivia   temperature  10 2010     3  30
>
> Bolivia   temperature 10 2010     4  17
> Bolivia   temperature 10 2010     5  19
> Bolivia   temperature 10 2010     6  12
>
> and so on.
>
> Note that "cut" refers to the temperature thresholds defined in the functions above. Each cut should come from the equivalent raster stack: days.above.10, days.above.15 and so on.
>
> I much appreciate any input.
> Greetings,
>   -- Thiago V. dos Santos
>
> PhD student
> Land and Atmospheric Science
> University of Minnesota
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

>

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


