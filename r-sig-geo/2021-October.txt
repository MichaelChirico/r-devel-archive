From jhw||@on@nb @end|ng |rom gm@||@com  Thu Oct  7 15:13:31 2021
From: jhw||@on@nb @end|ng |rom gm@||@com (John Wilson)
Date: Thu, 7 Oct 2021 10:13:31 -0300
Subject: [R-sig-Geo] GRTS sampling - 2-level design
Message-ID: <CABdA5Q2U0ddiact2ku+KTDM+C+-dCVm-fVBqaJpOXNcjKJtNVg@mail.gmail.com>

Hi everyone,

I'm working on a sampling design using GRTS, but I'm running into a
logistics problem. The field crew can set 5 nets per day, but only within a
5 km stretch, due to travel time constraints. With 10 sampling days, that's
a total of 50 sites. The overall sampling area is huge, so running a
regular GRTS design for 50 sites results, of course, in much larger
distances between sampling points.

Is there a legitimate way to create a 2-level GRTS design, where in step 1
we choose 10 spatially-balanced sampling points (one "core" point per
sampling day), and then for each of these "core points", we create a grid
of 5 sampling points that are constrained to all be within 5 km from each
other? I can make that happen code-wise, but am not sure what the
implications on spatial balance are, or if there's a built-in way to do
this.

Would appreciate any thoughts...
John

	[[alternative HTML version deleted]]


From Roger@B|v@nd @end|ng |rom nhh@no  Thu Oct  7 15:40:44 2021
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Thu, 7 Oct 2021 15:40:44 +0200 (CEST)
Subject: [R-sig-Geo] GRTS sampling - 2-level design
In-Reply-To: <CABdA5Q2U0ddiact2ku+KTDM+C+-dCVm-fVBqaJpOXNcjKJtNVg@mail.gmail.com>
References: <CABdA5Q2U0ddiact2ku+KTDM+C+-dCVm-fVBqaJpOXNcjKJtNVg@mail.gmail.com>
Message-ID: <6bfb77d3-e6fc-5df8-a3e-5617612ddc98@reclus2.nhh.no>

On Thu, 7 Oct 2021, John Wilson wrote:

> Hi everyone,
>
> I'm working on a sampling design using GRTS, but I'm running into a
> logistics problem. The field crew can set 5 nets per day, but only within a
> 5 km stretch, due to travel time constraints. With 10 sampling days, that's
> a total of 50 sites. The overall sampling area is huge, so running a
> regular GRTS design for 50 sites results, of course, in much larger
> distances between sampling points.
>
> Is there a legitimate way to create a 2-level GRTS design, where in step 1
> we choose 10 spatially-balanced sampling points (one "core" point per
> sampling day), and then for each of these "core points", we create a grid
> of 5 sampling points that are constrained to all be within 5 km from each
> other? I can make that happen code-wise, but am not sure what the
> implications on spatial balance are, or if there's a built-in way to do
> this.

Do you have a code example? Are you using BalancedSampling, SDraw or 
Spbsampling or packages (probably SDraw)? Have you run any simulations to 
try to get a first assessment on the impact of constraining your sample? 
Might approach a package author also help?

Roger


>
> Would appreciate any thoughts...
> John
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Emeritus Professor
Department of Economics, Norwegian School of Economics,
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From jhw||@on@nb @end|ng |rom gm@||@com  Thu Oct  7 15:50:18 2021
From: jhw||@on@nb @end|ng |rom gm@||@com (John Wilson)
Date: Thu, 7 Oct 2021 10:50:18 -0300
Subject: [R-sig-Geo] GRTS sampling - 2-level design
In-Reply-To: <6bfb77d3-e6fc-5df8-a3e-5617612ddc98@reclus2.nhh.no>
References: <CABdA5Q2U0ddiact2ku+KTDM+C+-dCVm-fVBqaJpOXNcjKJtNVg@mail.gmail.com>
 <6bfb77d3-e6fc-5df8-a3e-5617612ddc98@reclus2.nhh.no>
Message-ID: <CABdA5Q35skkDq8VHBOo+jtTQQ3DSVk8N6NjW5Vcc_3KkV-Mtuw@mail.gmail.com>

Oh, sorry - I normally use the grts() function from the spsurvey package.
My hacky approach was to make 10 balanced points with grts(), followed by
imposing a 5 km buffer around each one, and either systematic sampling
within the buffer circle, or running a separate GRTS for the 5 points
within each 5 km buffer circle. Even writing this makes me cringe though,
so hoping for something legitimate... I'll contact the authors if I don't
get any solid leads on here.

On Thu, Oct 7, 2021 at 10:40 AM Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Thu, 7 Oct 2021, John Wilson wrote:
>
> > Hi everyone,
> >
> > I'm working on a sampling design using GRTS, but I'm running into a
> > logistics problem. The field crew can set 5 nets per day, but only
> within a
> > 5 km stretch, due to travel time constraints. With 10 sampling days,
> that's
> > a total of 50 sites. The overall sampling area is huge, so running a
> > regular GRTS design for 50 sites results, of course, in much larger
> > distances between sampling points.
> >
> > Is there a legitimate way to create a 2-level GRTS design, where in step
> 1
> > we choose 10 spatially-balanced sampling points (one "core" point per
> > sampling day), and then for each of these "core points", we create a grid
> > of 5 sampling points that are constrained to all be within 5 km from each
> > other? I can make that happen code-wise, but am not sure what the
> > implications on spatial balance are, or if there's a built-in way to do
> > this.
>
> Do you have a code example? Are you using BalancedSampling, SDraw or
> Spbsampling or packages (probably SDraw)? Have you run any simulations to
> try to get a first assessment on the impact of constraining your sample?
> Might approach a package author also help?
>
> Roger
>
>
> >
> > Would appreciate any thoughts...
> > John
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Roger Bivand
> Emeritus Professor
> Department of Economics, Norwegian School of Economics,
> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
> e-mail: Roger.Bivand at nhh.no
> https://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>

	[[alternative HTML version deleted]]


From Roger@B|v@nd @end|ng |rom nhh@no  Thu Oct  7 16:01:34 2021
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Thu, 7 Oct 2021 16:01:34 +0200 (CEST)
Subject: [R-sig-Geo] GRTS sampling - 2-level design
In-Reply-To: <CABdA5Q35skkDq8VHBOo+jtTQQ3DSVk8N6NjW5Vcc_3KkV-Mtuw@mail.gmail.com>
References: <CABdA5Q2U0ddiact2ku+KTDM+C+-dCVm-fVBqaJpOXNcjKJtNVg@mail.gmail.com>
 <6bfb77d3-e6fc-5df8-a3e-5617612ddc98@reclus2.nhh.no>
 <CABdA5Q35skkDq8VHBOo+jtTQQ3DSVk8N6NjW5Vcc_3KkV-Mtuw@mail.gmail.com>
Message-ID: <599450-aba6-f894-11f4-be4da741d2@reclus2.nhh.no>

On Thu, 7 Oct 2021, John Wilson wrote:

> Oh, sorry - I normally use the grts() function from the spsurvey package.
> My hacky approach was to make 10 balanced points with grts(), followed by
> imposing a 5 km buffer around each one, and either systematic sampling
> within the buffer circle, or running a separate GRTS for the 5 points
> within each 5 km buffer circle. Even writing this makes me cringe though,
> so hoping for something legitimate... I'll contact the authors if I don't
> get any solid leads on here.

That makes sense. Perhaps comparison with the implementation in SDraw 
might be of interest. Please report back on progress (or no progress), 
someone else may well face the same problem. By the way, Task Views are 
being "re-booted", and it seems clear that a section on spatial sampling 
in one or several task views (Spatial, Environmetrics) would be helpful if 
someone could author one. For Spatial, a PR to 
https://github.com/r-spatial/task_views (we will be converting to markdown 
rather than ctv XML markup soon).

Roger

>
> On Thu, Oct 7, 2021 at 10:40 AM Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Thu, 7 Oct 2021, John Wilson wrote:
>>
>>> Hi everyone,
>>>
>>> I'm working on a sampling design using GRTS, but I'm running into a
>>> logistics problem. The field crew can set 5 nets per day, but only
>> within a
>>> 5 km stretch, due to travel time constraints. With 10 sampling days,
>> that's
>>> a total of 50 sites. The overall sampling area is huge, so running a
>>> regular GRTS design for 50 sites results, of course, in much larger
>>> distances between sampling points.
>>>
>>> Is there a legitimate way to create a 2-level GRTS design, where in step
>> 1
>>> we choose 10 spatially-balanced sampling points (one "core" point per
>>> sampling day), and then for each of these "core points", we create a grid
>>> of 5 sampling points that are constrained to all be within 5 km from each
>>> other? I can make that happen code-wise, but am not sure what the
>>> implications on spatial balance are, or if there's a built-in way to do
>>> this.
>>
>> Do you have a code example? Are you using BalancedSampling, SDraw or
>> Spbsampling or packages (probably SDraw)? Have you run any simulations to
>> try to get a first assessment on the impact of constraining your sample?
>> Might approach a package author also help?
>>
>> Roger
>>
>>
>>>
>>> Would appreciate any thoughts...
>>> John
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Emeritus Professor
>> Department of Economics, Norwegian School of Economics,
>> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
>> e-mail: Roger.Bivand at nhh.no
>> https://orcid.org/0000-0003-2392-6140
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>
>

-- 
Roger Bivand
Emeritus Professor
Department of Economics, Norwegian School of Economics,
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From b@@||e@|enorm@nd @end|ng |rom protonm@||@com  Fri Oct  8 12:37:55 2021
From: b@@||e@|enorm@nd @end|ng |rom protonm@||@com (basile.lenormand)
Date: Fri, 08 Oct 2021 10:37:55 +0000
Subject: [R-sig-Geo] markov chain carography on R
Message-ID: <o4Zx2yUjx10OujYZbbWYnjCvnJbbHLoQzkVQUWquE74gm-UxP309x36eFTkCP9NpbHKGxf-dgDCiIJpLM0vdpyNczMRFX9g276RzVu1EWUw=@protonmail.com>

Hello every one!

I am looking for indications about the possibilities to carography on R the results of a Markov chain analysis. I am doing supervised classifications on satellite images and I have to make "predictions".

I found a lot of packages that are dedicated to Markov chains but I did not find any that could convert the results in a map.
Can the cartography package do so?

I am not very skilled neiher in R nor in statistics so I may miss something in my readings. I just need a little direction and I will improve myself on it;

Thank you for your time,
have a great day,
Basile.

PS: I know there is a markov chain module in Idrissi but the software is really not easy couple with other GIS softwares' results and we got better results in our classifications with those.

Sent with [ProtonMail](https://protonmail.com/) Secure Email.
	[[alternative HTML version deleted]]


From @khn@tonon||ne @end|ng |rom hotm@||@com  Fri Oct  8 14:55:26 2021
From: @khn@tonon||ne @end|ng |rom hotm@||@com (Remon Hanna)
Date: Fri, 8 Oct 2021 12:55:26 +0000
Subject: [R-sig-Geo] Combine line segments into one line
In-Reply-To: <VI1P192MB0237672C251DE24F1FA120D4D8B19@VI1P192MB0237.EURP192.PROD.OUTLOOK.COM>
References: <VI1P192MB0237672C251DE24F1FA120D4D8B19@VI1P192MB0237.EURP192.PROD.OUTLOOK.COM>
Message-ID: <VI1P192MB023732384D2E5624C58D3A52D8B29@VI1P192MB0237.EURP192.PROD.OUTLOOK.COM>

Hi

I have line segments that I would like to combine them within each corridor, I.e each corridor will be one line of combined segments of NAME_S2S and combined geometry  as per the screenshot.

I have managed to plot the segments on the map as you can see but when zooming in these segments are not in one, which I would like to group them.

I ran the below line to group them by corridor, but I get error below;

> dataformap1<-gLineMerge(dataformap[dataformap$Corridor==1, ])
Error in gLineMerge(dataformap[dataformap$Corridor == 1, ]) :
  Invalid geometry, may only be applied to lines

Many thanks in advance

Remon Hanna

Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows



	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Fri Oct  8 15:38:48 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Fri, 8 Oct 2021 15:38:48 +0200
Subject: [R-sig-Geo] GRTS sampling - 2-level design
In-Reply-To: <CABdA5Q35skkDq8VHBOo+jtTQQ3DSVk8N6NjW5Vcc_3KkV-Mtuw@mail.gmail.com>
References: <CABdA5Q2U0ddiact2ku+KTDM+C+-dCVm-fVBqaJpOXNcjKJtNVg@mail.gmail.com>
 <6bfb77d3-e6fc-5df8-a3e-5617612ddc98@reclus2.nhh.no>
 <CABdA5Q35skkDq8VHBOo+jtTQQ3DSVk8N6NjW5Vcc_3KkV-Mtuw@mail.gmail.com>
Message-ID: <CAJuCY5xgnZoiyjxXa+s4UUJZO_LK8k7MdoAdAmQYihDn0hdmvA@mail.gmail.com>

Dear John,

Your procedure will create a spatially balanced level 1 sample (10
"regions") and within those regions a spatially balanced level 2 sample.
When you ignore the structure, there is no longer a spatial balance. So
you'll need to incorporate the two level sampling structure in your
analysis. E.g. by using region as random effect.

I presume you are catching fish along rivers and assume that the rivers are
linear features. I'd consider drawing 10 samples using GRTS to define the
regions. Then use that location as the center point of 5 systematic samples
along the river (-2, -1, 0, +1 and +2 km).

You might want to take a look at our grtsdb package. Available at
https://inbo.r-universe.dev/ It generates a full grid of master samples and
stores it in the database. So you can draw multiple samples from the same
master sample. This is useful in case of monitoring with a changing
population. You draw a sample and keep the lowest ranking locations that
are part of the population. If the population changes over time, then the
new sample will keep a proportion of the original sampling location
relative to the proportion of the population that remained stable. This
allows for repeated measures for stable locations while taking into account
the changes in population.

Best regards,

Thierry

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op do 7 okt. 2021 om 15:54 schreef John Wilson <jhwilson.nb at gmail.com>:

> Oh, sorry - I normally use the grts() function from the spsurvey package.
> My hacky approach was to make 10 balanced points with grts(), followed by
> imposing a 5 km buffer around each one, and either systematic sampling
> within the buffer circle, or running a separate GRTS for the 5 points
> within each 5 km buffer circle. Even writing this makes me cringe though,
> so hoping for something legitimate... I'll contact the authors if I don't
> get any solid leads on here.
>
> On Thu, Oct 7, 2021 at 10:40 AM Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
> > On Thu, 7 Oct 2021, John Wilson wrote:
> >
> > > Hi everyone,
> > >
> > > I'm working on a sampling design using GRTS, but I'm running into a
> > > logistics problem. The field crew can set 5 nets per day, but only
> > within a
> > > 5 km stretch, due to travel time constraints. With 10 sampling days,
> > that's
> > > a total of 50 sites. The overall sampling area is huge, so running a
> > > regular GRTS design for 50 sites results, of course, in much larger
> > > distances between sampling points.
> > >
> > > Is there a legitimate way to create a 2-level GRTS design, where in
> step
> > 1
> > > we choose 10 spatially-balanced sampling points (one "core" point per
> > > sampling day), and then for each of these "core points", we create a
> grid
> > > of 5 sampling points that are constrained to all be within 5 km from
> each
> > > other? I can make that happen code-wise, but am not sure what the
> > > implications on spatial balance are, or if there's a built-in way to do
> > > this.
> >
> > Do you have a code example? Are you using BalancedSampling, SDraw or
> > Spbsampling or packages (probably SDraw)? Have you run any simulations to
> > try to get a first assessment on the impact of constraining your sample?
> > Might approach a package author also help?
> >
> > Roger
> >
> >
> > >
> > > Would appreciate any thoughts...
> > > John
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-Geo mailing list
> > > R-sig-Geo at r-project.org
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > >
> >
> > --
> > Roger Bivand
> > Emeritus Professor
> > Department of Economics, Norwegian School of Economics,
> > Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
> > e-mail: Roger.Bivand at nhh.no
> > https://orcid.org/0000-0003-2392-6140
> > https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From jhw||@on@nb @end|ng |rom gm@||@com  Fri Oct  8 16:08:10 2021
From: jhw||@on@nb @end|ng |rom gm@||@com (John Wilson)
Date: Fri, 8 Oct 2021 11:08:10 -0300
Subject: [R-sig-Geo] GRTS sampling - 2-level design
In-Reply-To: <CAJuCY5xgnZoiyjxXa+s4UUJZO_LK8k7MdoAdAmQYihDn0hdmvA@mail.gmail.com>
References: <CABdA5Q2U0ddiact2ku+KTDM+C+-dCVm-fVBqaJpOXNcjKJtNVg@mail.gmail.com>
 <6bfb77d3-e6fc-5df8-a3e-5617612ddc98@reclus2.nhh.no>
 <CABdA5Q35skkDq8VHBOo+jtTQQ3DSVk8N6NjW5Vcc_3KkV-Mtuw@mail.gmail.com>
 <CAJuCY5xgnZoiyjxXa+s4UUJZO_LK8k7MdoAdAmQYihDn0hdmvA@mail.gmail.com>
Message-ID: <CABdA5Q0ZK36JoKR+7d5xfF-w9F0wkZst5OWKLT74Q0+m1z2qkw@mail.gmail.com>

Dear Thierry,

Thank you so much for your reply. Yes, the loss of the spatial balance once
the two-tiered approach is not accounted for was what was worrying me.

The incorporation of region as a random effect has two issues - 1) the
overall sampling area is a lake, and "regions" don't make sense in that
context. 2) The analysis is a mark-recapture for fish (using the MARK
software); I've never seen the incorporation of random effects in the
Jolly-Seber / Cormark-Jolly-Seber models outside of Bayesian framework and
outside of individual random effects... but even if I could do that - the
regions just don't really make sense anyway (that I can see, anyway - maybe
I'm not thinking about it the right way?)

Thank you for the grtsdb suggestion. Do you have any examples of how this
works? I couldn't find any vignettes or worked examples...

Thank you so much,
John

On Fri, Oct 8, 2021 at 10:39 AM Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear John,
>
> Your procedure will create a spatially balanced level 1 sample (10
> "regions") and within those regions a spatially balanced level 2 sample.
> When you ignore the structure, there is no longer a spatial balance. So
> you'll need to incorporate the two level sampling structure in your
> analysis. E.g. by using region as random effect.
>
> I presume you are catching fish along rivers and assume that the rivers
> are linear features. I'd consider drawing 10 samples using GRTS to define
> the regions. Then use that location as the center point of 5 systematic
> samples along the river (-2, -1, 0, +1 and +2 km).
>
> You might want to take a look at our grtsdb package. Available at
> https://inbo.r-universe.dev/ It generates a full grid of master samples
> and stores it in the database. So you can draw multiple samples from the
> same master sample. This is useful in case of monitoring with a changing
> population. You draw a sample and keep the lowest ranking locations that
> are part of the population. If the population changes over time, then the
> new sample will keep a proportion of the original sampling location
> relative to the proportion of the population that remained stable. This
> allows for repeated measures for stable locations while taking into account
> the changes in population.
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op do 7 okt. 2021 om 15:54 schreef John Wilson <jhwilson.nb at gmail.com>:
>
>> Oh, sorry - I normally use the grts() function from the spsurvey package.
>> My hacky approach was to make 10 balanced points with grts(), followed by
>> imposing a 5 km buffer around each one, and either systematic sampling
>> within the buffer circle, or running a separate GRTS for the 5 points
>> within each 5 km buffer circle. Even writing this makes me cringe though,
>> so hoping for something legitimate... I'll contact the authors if I don't
>> get any solid leads on here.
>>
>> On Thu, Oct 7, 2021 at 10:40 AM Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>
>> > On Thu, 7 Oct 2021, John Wilson wrote:
>> >
>> > > Hi everyone,
>> > >
>> > > I'm working on a sampling design using GRTS, but I'm running into a
>> > > logistics problem. The field crew can set 5 nets per day, but only
>> > within a
>> > > 5 km stretch, due to travel time constraints. With 10 sampling days,
>> > that's
>> > > a total of 50 sites. The overall sampling area is huge, so running a
>> > > regular GRTS design for 50 sites results, of course, in much larger
>> > > distances between sampling points.
>> > >
>> > > Is there a legitimate way to create a 2-level GRTS design, where in
>> step
>> > 1
>> > > we choose 10 spatially-balanced sampling points (one "core" point per
>> > > sampling day), and then for each of these "core points", we create a
>> grid
>> > > of 5 sampling points that are constrained to all be within 5 km from
>> each
>> > > other? I can make that happen code-wise, but am not sure what the
>> > > implications on spatial balance are, or if there's a built-in way to
>> do
>> > > this.
>> >
>> > Do you have a code example? Are you using BalancedSampling, SDraw or
>> > Spbsampling or packages (probably SDraw)? Have you run any simulations
>> to
>> > try to get a first assessment on the impact of constraining your sample?
>> > Might approach a package author also help?
>> >
>> > Roger
>> >
>> >
>> > >
>> > > Would appreciate any thoughts...
>> > > John
>> > >
>> > >       [[alternative HTML version deleted]]
>> > >
>> > > _______________________________________________
>> > > R-sig-Geo mailing list
>> > > R-sig-Geo at r-project.org
>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> > >
>> >
>> > --
>> > Roger Bivand
>> > Emeritus Professor
>> > Department of Economics, Norwegian School of Economics,
>> > Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
>> > e-mail: Roger.Bivand at nhh.no
>> > https://orcid.org/0000-0003-2392-6140
>> > https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>

	[[alternative HTML version deleted]]


From mjherrer|@@t @end|ng |rom gm@||@com  Fri Oct  8 16:10:10 2021
From: mjherrer|@@t @end|ng |rom gm@||@com (maria jesus herrerias)
Date: Fri, 8 Oct 2021 16:10:10 +0200
Subject: [R-sig-Geo] problem in moran tes
Message-ID: <CAPvcma3jFp_8gJJ_TPT3kBX8Cdkfj3aC5ZZP+ocGY0-onuEOkQ@mail.gmail.com>

Dear list,

I have a panel data and I would like to test if the spatial dependence is
an issue. However, I am getting this error:
#ERROR
Error in nb2listw(sub.queen.nb$neighbours, style = "W", zero.policy = TRUE)
:
  Not a neighbours list

Below I report my code to see if somebody can help me on this matter:

#Spatial Dependence for Panel 32 regions from 1990-2014

# The Spatial Matrix
# Read the shapefile and set up the working directory.
library(foreign)
library(haven)


setwd("C:/Users/Usuario/Desktop/instituciones/revision energy
economics/docs enviados/spatial test")

x <- read.dta("C:/Users/Usuario/Desktop/instituciones/revision energy
economics/docs enviados/spatial test/high_spatial.dta")

# Matching with stata file and shapefile by ID

dta_cntries <- unique(x$OBJECTID)

library(sf)

wrld <- st_read("C:/Users/Usuario/Desktop/instituciones/revision energy
economics/spatial panel in
stata/Longitude_Graticules_and_World_Countries_Boundaries-shp/countries1.shp")
wrld_a <- aggregate(wrld, list(wrld$OBJECTID), head, n=1)


o <- match(dta_cntries, wrld_a$OBJECTID)

#Check if matching is right

The Stata file has two non-matching names (left ccode stata, right names in
map shapefile):

which(is.na(o))

o <- match(dta_cntries, wrld$OBJECTID)
o

library(spdep)
row.names(wrld_a) <- wrld_a$OBJECTID
nb <- poly2nb(wrld_a)
nb1 <- subset(nb, 1:nrow(wrld_a) %in% o)

#high
Neighbour list object:
Number of regions: 32
Number of nonzero links: 82
Percentage nonzero weights: 8.007812
Average number of links: 2.5625

wrld_s <- wrld_a[1:nrow(wrld_a) %in% o,]
nb2 <- poly2nb(wrld_s)
all.equal(nb1, nb2, check.attributes=FALSE)
[1] TRUE  # subsetting well-done

***********************************
# Queen Matrix
sub.worlddata <-wrld_s
sub.queen.nb <- poly2nb(sub.worlddata, queen=TRUE)
length(sub.queen.nb)  #32
summary(sub.queen.nb)
sub.queen.listw <-nb2listw(sub.queen.nb,zero.policy = TRUE)
summary(sub.queen.listw,zero.policy = TRUE)
head(sub.queen.nb)
*********************************


# Prepare the dataset for panel data analysis in R.

library(plm)

setwd("C:/Users/Usuario/Desktop/instituciones/revision energy
economics/code and data/quantile")

high <- read.dta("C:/Users/Usuario/Desktop/instituciones/revision energy
economics/docs enviados/spatial test/high_spatial.dta")


mydata <- pdata.frame(high, index = c("OBJECTID", "year"))
**************************************
#Variables.

energy <- mydata$leic
gdp <- mydata$lgdppcnewc
gdp2 <- mydata$lgdppcnewc2
fdi <- mydata$fdigc
imports <- mydata$importsgc
industry <- mydata$industrygc
inst.1 <- mydata$kun_legabsc

**********************************
#Define formula

model.1 <- energy ~ gdp + gdp2 + fdi + imports + industry + inst.1

********************
# Testing spatial autocorrelation
library(spatialreg)

ols.eq1 <- lm(model.1, data = mydata)
summary(ols.eq1)
**********************************

lmMoranTest <- lm.morantest(ols.eq1,nb2listw(sub.queen.nb$neighbours,
style="W",zero.policy = TRUE))
lmMoranTest

#ERROR
Error in nb2listw(sub.queen.nb$neighbours, style = "W", zero.policy = TRUE)
:
  Not a neighbours list

library(spdep)

lmLMtests <- lm.LMtests(ols.eq1,nb2listw(sub.queen.nb), test=c("LMerr",
"LMlag", "RLMerr", "RLMlag", "SARMA"))
lmLMtests

#ERROR
Error in nb2listw(sub.queen.nb$neighbours, style = "W", zero.policy = TRUE)
:
  Not a neighbours list

Many thanks

Best wishes,
Maria Jesus

	[[alternative HTML version deleted]]


From r|@@|d@nh@ @end|ng |rom gm@||@com  Fri Oct  8 16:24:06 2021
From: r|@@|d@nh@ @end|ng |rom gm@||@com (Raphael Saldanha)
Date: Fri, 8 Oct 2021 11:24:06 -0300
Subject: [R-sig-Geo] problem in moran tes
In-Reply-To: <CAPvcma3jFp_8gJJ_TPT3kBX8Cdkfj3aC5ZZP+ocGY0-onuEOkQ@mail.gmail.com>
References: <CAPvcma3jFp_8gJJ_TPT3kBX8Cdkfj3aC5ZZP+ocGY0-onuEOkQ@mail.gmail.com>
Message-ID: <5D3F2F86-FCED-4E3B-AF20-F1440676E128@gmail.com>

Hi Maria,

At some point you create an object called ?sub.queen.listw?. You can try to use this one with the test function.


lmLMtests <- lm.LMtests(ols.eq1, sub.queen.listw, test=c("LMerr","LMlag", "RLMerr", "RLMlag", "SARMA?))



Kind regards,

Raphael Saldanha


> Em 8 de out. de 2021, ?(s) 11:10, maria jesus herrerias <mjherreriast at gmail.com> escreveu:
> 
> Dear list,
> 
> I have a panel data and I would like to test if the spatial dependence is
> an issue. However, I am getting this error:
> #ERROR
> Error in nb2listw(sub.queen.nb$neighbours, style = "W", zero.policy = TRUE)
> :
>  Not a neighbours list
> 
> Below I report my code to see if somebody can help me on this matter:
> 
> #Spatial Dependence for Panel 32 regions from 1990-2014
> 
> # The Spatial Matrix
> # Read the shapefile and set up the working directory.
> library(foreign)
> library(haven)
> 
> 
> setwd("C:/Users/Usuario/Desktop/instituciones/revision energy
> economics/docs enviados/spatial test")
> 
> x <- read.dta("C:/Users/Usuario/Desktop/instituciones/revision energy
> economics/docs enviados/spatial test/high_spatial.dta")
> 
> # Matching with stata file and shapefile by ID
> 
> dta_cntries <- unique(x$OBJECTID)
> 
> library(sf)
> 
> wrld <- st_read("C:/Users/Usuario/Desktop/instituciones/revision energy
> economics/spatial panel in
> stata/Longitude_Graticules_and_World_Countries_Boundaries-shp/countries1.shp")
> wrld_a <- aggregate(wrld, list(wrld$OBJECTID), head, n=1)
> 
> 
> o <- match(dta_cntries, wrld_a$OBJECTID)
> 
> #Check if matching is right
> 
> The Stata file has two non-matching names (left ccode stata, right names in
> map shapefile):
> 
> which(is.na(o))
> 
> o <- match(dta_cntries, wrld$OBJECTID)
> o
> 
> library(spdep)
> row.names(wrld_a) <- wrld_a$OBJECTID
> nb <- poly2nb(wrld_a)
> nb1 <- subset(nb, 1:nrow(wrld_a) %in% o)
> 
> #high
> Neighbour list object:
> Number of regions: 32
> Number of nonzero links: 82
> Percentage nonzero weights: 8.007812
> Average number of links: 2.5625
> 
> wrld_s <- wrld_a[1:nrow(wrld_a) %in% o,]
> nb2 <- poly2nb(wrld_s)
> all.equal(nb1, nb2, check.attributes=FALSE)
> [1] TRUE  # subsetting well-done
> 
> ***********************************
> # Queen Matrix
> sub.worlddata <-wrld_s
> sub.queen.nb <- poly2nb(sub.worlddata, queen=TRUE)
> length(sub.queen.nb)  #32
> summary(sub.queen.nb)
> sub.queen.listw <-nb2listw(sub.queen.nb,zero.policy = TRUE)
> summary(sub.queen.listw,zero.policy = TRUE)
> head(sub.queen.nb)
> *********************************
> 
> 
> # Prepare the dataset for panel data analysis in R.
> 
> library(plm)
> 
> setwd("C:/Users/Usuario/Desktop/instituciones/revision energy
> economics/code and data/quantile")
> 
> high <- read.dta("C:/Users/Usuario/Desktop/instituciones/revision energy
> economics/docs enviados/spatial test/high_spatial.dta")
> 
> 
> mydata <- pdata.frame(high, index = c("OBJECTID", "year"))
> **************************************
> #Variables.
> 
> energy <- mydata$leic
> gdp <- mydata$lgdppcnewc
> gdp2 <- mydata$lgdppcnewc2
> fdi <- mydata$fdigc
> imports <- mydata$importsgc
> industry <- mydata$industrygc
> inst.1 <- mydata$kun_legabsc
> 
> **********************************
> #Define formula
> 
> model.1 <- energy ~ gdp + gdp2 + fdi + imports + industry + inst.1
> 
> ********************
> # Testing spatial autocorrelation
> library(spatialreg)
> 
> ols.eq1 <- lm(model.1, data = mydata)
> summary(ols.eq1)
> **********************************
> 
> lmMoranTest <- lm.morantest(ols.eq1,nb2listw(sub.queen.nb$neighbours,
> style="W",zero.policy = TRUE))
> lmMoranTest
> 
> #ERROR
> Error in nb2listw(sub.queen.nb$neighbours, style = "W", zero.policy = TRUE)
> :
>  Not a neighbours list
> 
> library(spdep)
> 
> lmLMtests <- lm.LMtests(ols.eq1,nb2listw(sub.queen.nb), test=c("LMerr",
> "LMlag", "RLMerr", "RLMlag", "SARMA"))
> lmLMtests
> 
> #ERROR
> Error in nb2listw(sub.queen.nb$neighbours, style = "W", zero.policy = TRUE)
> :
>  Not a neighbours list
> 
> Many thanks
> 
> Best wishes,
> Maria Jesus
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4908 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20211008/e2fb86f0/attachment.p7s>

From Roger@B|v@nd @end|ng |rom nhh@no  Fri Oct  8 16:31:24 2021
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Fri, 8 Oct 2021 16:31:24 +0200 (CEST)
Subject: [R-sig-Geo] problem in moran tes
In-Reply-To: <CAPvcma3jFp_8gJJ_TPT3kBX8Cdkfj3aC5ZZP+ocGY0-onuEOkQ@mail.gmail.com>
References: <CAPvcma3jFp_8gJJ_TPT3kBX8Cdkfj3aC5ZZP+ocGY0-onuEOkQ@mail.gmail.com>
Message-ID: <8316688b-89eb-de53-913c-62a78efcd72c@reclus2.nhh.no>

On Fri, 8 Oct 2021, maria jesus herrerias wrote:

> Dear list,
>
> I have a panel data and I would like to test if the spatial dependence is
> an issue. However, I am getting this error:
> #ERROR
> Error in nb2listw(sub.queen.nb$neighbours, style = "W", zero.policy = TRUE)
> :
>  Not a neighbours list

Most likely your data. Either provide a link to your data, or provide the 
example using built-in data (say country boundaries from the rnaturalearth 
package). Without a reproducible example, it isn't possible to guess, 
unless you meant by sub.queen.nb$neighbours, sub.queen.listw$neighbours, 
as "nb" objects do not have "neighbours" components.

Roger

>
> Below I report my code to see if somebody can help me on this matter:
>
> #Spatial Dependence for Panel 32 regions from 1990-2014
>
> # The Spatial Matrix
> # Read the shapefile and set up the working directory.
> library(foreign)
> library(haven)
>
>
> setwd("C:/Users/Usuario/Desktop/instituciones/revision energy
> economics/docs enviados/spatial test")
>
> x <- read.dta("C:/Users/Usuario/Desktop/instituciones/revision energy
> economics/docs enviados/spatial test/high_spatial.dta")
>
> # Matching with stata file and shapefile by ID
>
> dta_cntries <- unique(x$OBJECTID)
>
> library(sf)
>
> wrld <- st_read("C:/Users/Usuario/Desktop/instituciones/revision energy
> economics/spatial panel in
> stata/Longitude_Graticules_and_World_Countries_Boundaries-shp/countries1.shp")
> wrld_a <- aggregate(wrld, list(wrld$OBJECTID), head, n=1)
>
>
> o <- match(dta_cntries, wrld_a$OBJECTID)
>
> #Check if matching is right
>
> The Stata file has two non-matching names (left ccode stata, right names in
> map shapefile):
>
> which(is.na(o))
>
> o <- match(dta_cntries, wrld$OBJECTID)
> o
>
> library(spdep)
> row.names(wrld_a) <- wrld_a$OBJECTID
> nb <- poly2nb(wrld_a)
> nb1 <- subset(nb, 1:nrow(wrld_a) %in% o)
>
> #high
> Neighbour list object:
> Number of regions: 32
> Number of nonzero links: 82
> Percentage nonzero weights: 8.007812
> Average number of links: 2.5625
>
> wrld_s <- wrld_a[1:nrow(wrld_a) %in% o,]
> nb2 <- poly2nb(wrld_s)
> all.equal(nb1, nb2, check.attributes=FALSE)
> [1] TRUE  # subsetting well-done
>
> ***********************************
> # Queen Matrix
> sub.worlddata <-wrld_s
> sub.queen.nb <- poly2nb(sub.worlddata, queen=TRUE)
> length(sub.queen.nb)  #32
> summary(sub.queen.nb)
> sub.queen.listw <-nb2listw(sub.queen.nb,zero.policy = TRUE)
> summary(sub.queen.listw,zero.policy = TRUE)
> head(sub.queen.nb)
> *********************************
>
>
> # Prepare the dataset for panel data analysis in R.
>
> library(plm)
>
> setwd("C:/Users/Usuario/Desktop/instituciones/revision energy
> economics/code and data/quantile")
>
> high <- read.dta("C:/Users/Usuario/Desktop/instituciones/revision energy
> economics/docs enviados/spatial test/high_spatial.dta")
>
>
> mydata <- pdata.frame(high, index = c("OBJECTID", "year"))
> **************************************
> #Variables.
>
> energy <- mydata$leic
> gdp <- mydata$lgdppcnewc
> gdp2 <- mydata$lgdppcnewc2
> fdi <- mydata$fdigc
> imports <- mydata$importsgc
> industry <- mydata$industrygc
> inst.1 <- mydata$kun_legabsc
>
> **********************************
> #Define formula
>
> model.1 <- energy ~ gdp + gdp2 + fdi + imports + industry + inst.1
>
> ********************
> # Testing spatial autocorrelation
> library(spatialreg)
>
> ols.eq1 <- lm(model.1, data = mydata)
> summary(ols.eq1)
> **********************************
>
> lmMoranTest <- lm.morantest(ols.eq1,nb2listw(sub.queen.nb$neighbours,
> style="W",zero.policy = TRUE))
> lmMoranTest
>
> #ERROR
> Error in nb2listw(sub.queen.nb$neighbours, style = "W", zero.policy = TRUE)
> :
>  Not a neighbours list
>
> library(spdep)
>
> lmLMtests <- lm.LMtests(ols.eq1,nb2listw(sub.queen.nb), test=c("LMerr",
> "LMlag", "RLMerr", "RLMlag", "SARMA"))
> lmLMtests
>
> #ERROR
> Error in nb2listw(sub.queen.nb$neighbours, style = "W", zero.policy = TRUE)
> :
>  Not a neighbours list
>
> Many thanks
>
> Best wishes,
> Maria Jesus
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Emeritus Professor
Department of Economics, Norwegian School of Economics,
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From je@n-|uc@dupouey @end|ng |rom |nr@e@|r  Sun Oct 10 20:42:21 2021
From: je@n-|uc@dupouey @end|ng |rom |nr@e@|r (Jean-Luc Dupouey)
Date: Sun, 10 Oct 2021 20:42:21 +0200
Subject: [R-sig-Geo] cannot apply a gridded transformation with sf
Message-ID: <1e7e71eb-53c2-da4e-c276-b4b7d17ea40e@inrae.fr>

Dear forumites,

I try to apply a gridded transformation of coordinates in |sf|, but it 
does not work. Is there something else to do apart from calling 
|sf_proj_network(TRUE)|? Here is the 7 lines of code I used:

|pt_27572 <- data.frame(X=55824.4970,Y=2394454.2120)| # set coordinates 
of one point in EPSG:27572

|pt_2154 <- data.frame(X=107242.8310,Y=6832277.1820)| # known accurate 
coordinates of the same point in EPSG:2154 (from calculations of the 
French National Geographic Institute)

|ptSf_27572 <- st_as_sf(pt_27572, coords = c("X", "Y"), crs = 27572)| # 
build sf object

|ptSf_2154 <- st_as_sf(pt_2154, coords = c("X", "Y"), crs = 2154)| # 
build sf object

|sf_proj_network(TRUE)| # allow search for online datum grids in the 
PROJ CDN

[1] "https://cdn.proj.org"

|sf_proj_pipelines("EPSG:27572", "EPSG:2154")| # grids 
(fr_ign_gr3df97a.tif) seem to be found for accurate transformation from 
EPSG:27572 to EPSG:2154

|Candidate coordinate operations found: 3 Strict containment: FALSE Axis 
order auth compl: FALSE Source: EPSG:27572 Target: EPSG:2154 Best 
instantiable operation has accuracy: 1 m Description: Inverse of Lambert 
zone II + NTF (Paris) to NTF (1) + NTF to RGF93 (1) + Lambert-93 
Definition: +proj=pipeline +step +inv +proj=lcc +lat_1=46.8 +lat_0=46.8 
+lon_0=0 +k_0=0.99987742 +x_0=600000 +y_0=2200000 +ellps=clrk80ign 
+pm=paris +step +proj=push +v_3 +step +proj=cart +ellps=clrk80ign +step 
+proj=xyzgridshift +grids=fr_ign_gr3df97a.tif +grid_ref=output_crs 
+ellps=GRS80 +step +inv +proj=cart +ellps=GRS80 +step +proj=pop +v_3 
+step +proj=lcc +lat_0=46.5 +lon_0=3 +lat_1=49 +lat_2=44 +x_0=700000 
+y_0=6600000 +ellps=GRS80 |

|ptSf_2154_grid <- st_transform(ptSf_27572,crs=2154)| # apply transformation

|st_distance(ptSf_2154_grid,ptSf_2154)| # incorrect (ungridded) 
transformation, the distance should be zero. 3.777 m is the known error 
for the ungridded transformation.

|Units: [m] [,1] [1,] 3.777346 |

I read in (the so useful) "Spatial Data Science" that by default, the 
most accurate pipeline is chosen by |st_transform|. Why isn't it the 
case here?

I am running R version 4.1.1, GEOS 3.9.1, GDAL 3.2.1, PROJ 7.2.1.

Thanks for your help,

Jean-Luc

-- 
Jean-Luc Dupouey
INRAE
Silva Unit
F-54280 Champenoux
France


	[[alternative HTML version deleted]]


From nev||@@mo@ @end|ng |rom gm@||@com  Mon Oct 11 08:28:54 2021
From: nev||@@mo@ @end|ng |rom gm@||@com (nevil amos)
Date: Mon, 11 Oct 2021 17:28:54 +1100
Subject: [R-sig-Geo] Plotting Raster using values from RAT
Message-ID: <CAN9eD7m8SR56c6CsRuAdrRkDu5ZW+x4JTfMUhbGpkF_vYYJ-WA@mail.gmail.com>

Hi

Is there any way  to colour a raster by values in a raster attribute table
that  do not correspond 1:1 with the levels() /ID value in the raster
attribute table.

The example in the rasterVis documentation
https://oscarperpinan.github.io/rastervis/#factor has the categories
aligned with the levels.

Here is what I would like to achieve
r<-raster(matrix(sample(1:9,100,replace=T),10,10))
plot(r)
levels(r)
r<-ratify(r)

df<-data.frame(ID=1:9,
               Grouping1=sample(LETTERS[1:3],9,replace=T),
               NewValue = rnorm(9),
               Grouping2 = sample(LETTERS[4:8],9,replace=T))

rat<-merge(levels(r)[[1]],df)
print(rat)
levels(r)<-rat
plot(r)
rasterVis::levelplot(r,att="Grouping1")
rasterVis::levelplot(r,att="Grouping2")
rasterVis::levelplot(r,att="NewValue")

# in all three cases the colouring of the raster remains the same (
according to the levels() or ID).
# and the legend  only adds a label to each of those levels
#I would like to be able to  colour the raster according to the unique
values in the "groupings"  and the legend to have one row for each unique
value - eg Grouping 1 legend would have 3 colours  corresponding to A B C
or on a colour scale for the numeric "NewValue", without reclassifying the
raster.

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Oct 11 09:17:54 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 11 Oct 2021 09:17:54 +0200
Subject: [R-sig-Geo] GRTS sampling - 2-level design
In-Reply-To: <CABdA5Q0ZK36JoKR+7d5xfF-w9F0wkZst5OWKLT74Q0+m1z2qkw@mail.gmail.com>
References: <CABdA5Q2U0ddiact2ku+KTDM+C+-dCVm-fVBqaJpOXNcjKJtNVg@mail.gmail.com>
 <6bfb77d3-e6fc-5df8-a3e-5617612ddc98@reclus2.nhh.no>
 <CABdA5Q35skkDq8VHBOo+jtTQQ3DSVk8N6NjW5Vcc_3KkV-Mtuw@mail.gmail.com>
 <CAJuCY5xgnZoiyjxXa+s4UUJZO_LK8k7MdoAdAmQYihDn0hdmvA@mail.gmail.com>
 <CABdA5Q0ZK36JoKR+7d5xfF-w9F0wkZst5OWKLT74Q0+m1z2qkw@mail.gmail.com>
Message-ID: <CAJuCY5wGv6xNDeB4KG5MP-JABRcEE-PWbz+Q6JnBFFOjeU5joA@mail.gmail.com>

Dear John,

A real life example is available at https://doi.org/10.5281/zenodo.2784012.
The idea is that the database returns a randomised set of points. You need
to overlay these points with your sampling framework. The final sample is
the set of points with the lowest ranking. The grtsdb package is a
reimplementation of my GRTS package (https://github.com/ThierryO/grts).
That package has a vignette describing GRTS via the Reversed Randomized
Quadrant-Recursive Raster strategy (
https://doi.org/10.1007/s00267-005-0199-x).

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op vr 8 okt. 2021 om 16:08 schreef John Wilson <jhwilson.nb at gmail.com>:

> Dear Thierry,
>
> Thank you so much for your reply. Yes, the loss of the spatial balance
> once the two-tiered approach is not accounted for was what was worrying me.
>
> The incorporation of region as a random effect has two issues - 1) the
> overall sampling area is a lake, and "regions" don't make sense in that
> context. 2) The analysis is a mark-recapture for fish (using the MARK
> software); I've never seen the incorporation of random effects in the
> Jolly-Seber / Cormark-Jolly-Seber models outside of Bayesian framework and
> outside of individual random effects... but even if I could do that - the
> regions just don't really make sense anyway (that I can see, anyway - maybe
> I'm not thinking about it the right way?)
>
> Thank you for the grtsdb suggestion. Do you have any examples of how this
> works? I couldn't find any vignettes or worked examples...
>
> Thank you so much,
> John
>
> On Fri, Oct 8, 2021 at 10:39 AM Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
>> Dear John,
>>
>> Your procedure will create a spatially balanced level 1 sample (10
>> "regions") and within those regions a spatially balanced level 2 sample.
>> When you ignore the structure, there is no longer a spatial balance. So
>> you'll need to incorporate the two level sampling structure in your
>> analysis. E.g. by using region as random effect.
>>
>> I presume you are catching fish along rivers and assume that the rivers
>> are linear features. I'd consider drawing 10 samples using GRTS to define
>> the regions. Then use that location as the center point of 5 systematic
>> samples along the river (-2, -1, 0, +1 and +2 km).
>>
>> You might want to take a look at our grtsdb package. Available at
>> https://inbo.r-universe.dev/ It generates a full grid of master samples
>> and stores it in the database. So you can draw multiple samples from the
>> same master sample. This is useful in case of monitoring with a changing
>> population. You draw a sample and keep the lowest ranking locations that
>> are part of the population. If the population changes over time, then the
>> new sample will keep a proportion of the original sampling location
>> relative to the proportion of the population that remained stable. This
>> allows for repeated measures for stable locations while taking into account
>> the changes in population.
>>
>> Best regards,
>>
>> Thierry
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op do 7 okt. 2021 om 15:54 schreef John Wilson <jhwilson.nb at gmail.com>:
>>
>>> Oh, sorry - I normally use the grts() function from the spsurvey package.
>>> My hacky approach was to make 10 balanced points with grts(), followed by
>>> imposing a 5 km buffer around each one, and either systematic sampling
>>> within the buffer circle, or running a separate GRTS for the 5 points
>>> within each 5 km buffer circle. Even writing this makes me cringe though,
>>> so hoping for something legitimate... I'll contact the authors if I don't
>>> get any solid leads on here.
>>>
>>> On Thu, Oct 7, 2021 at 10:40 AM Roger Bivand <Roger.Bivand at nhh.no>
>>> wrote:
>>>
>>> > On Thu, 7 Oct 2021, John Wilson wrote:
>>> >
>>> > > Hi everyone,
>>> > >
>>> > > I'm working on a sampling design using GRTS, but I'm running into a
>>> > > logistics problem. The field crew can set 5 nets per day, but only
>>> > within a
>>> > > 5 km stretch, due to travel time constraints. With 10 sampling days,
>>> > that's
>>> > > a total of 50 sites. The overall sampling area is huge, so running a
>>> > > regular GRTS design for 50 sites results, of course, in much larger
>>> > > distances between sampling points.
>>> > >
>>> > > Is there a legitimate way to create a 2-level GRTS design, where in
>>> step
>>> > 1
>>> > > we choose 10 spatially-balanced sampling points (one "core" point per
>>> > > sampling day), and then for each of these "core points", we create a
>>> grid
>>> > > of 5 sampling points that are constrained to all be within 5 km from
>>> each
>>> > > other? I can make that happen code-wise, but am not sure what the
>>> > > implications on spatial balance are, or if there's a built-in way to
>>> do
>>> > > this.
>>> >
>>> > Do you have a code example? Are you using BalancedSampling, SDraw or
>>> > Spbsampling or packages (probably SDraw)? Have you run any simulations
>>> to
>>> > try to get a first assessment on the impact of constraining your
>>> sample?
>>> > Might approach a package author also help?
>>> >
>>> > Roger
>>> >
>>> >
>>> > >
>>> > > Would appreciate any thoughts...
>>> > > John
>>> > >
>>> > >       [[alternative HTML version deleted]]
>>> > >
>>> > > _______________________________________________
>>> > > R-sig-Geo mailing list
>>> > > R-sig-Geo at r-project.org
>>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> > >
>>> >
>>> > --
>>> > Roger Bivand
>>> > Emeritus Professor
>>> > Department of Economics, Norwegian School of Economics,
>>> > Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
>>> > e-mail: Roger.Bivand at nhh.no
>>> > https://orcid.org/0000-0003-2392-6140
>>> > https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>

	[[alternative HTML version deleted]]


From Roger@B|v@nd @end|ng |rom nhh@no  Mon Oct 11 13:44:26 2021
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Mon, 11 Oct 2021 13:44:26 +0200 (CEST)
Subject: [R-sig-Geo] cannot apply a gridded transformation with sf
In-Reply-To: <1e7e71eb-53c2-da4e-c276-b4b7d17ea40e@inrae.fr>
References: <1e7e71eb-53c2-da4e-c276-b4b7d17ea40e@inrae.fr>
Message-ID: <bb9b6c94-b4f5-3091-96f5-535bc3974de1@reclus2.nhh.no>

Dear Jean-Luc,

Thanks for a very helpful report. I'll answer fully later, but if you 
could provide in addition your platform (I think Windows or macOS, sf 
installed as a CRAN binary), that would help. On these platforms, access 
to the CDN for grids is not what it should be, and your example is 
helping debug the problem.

Best wishes,

Roger

On Sun, 10 Oct 2021, Jean-Luc Dupouey wrote:

> Dear forumites,
>
> I try to apply a gridded transformation of coordinates in |sf|, but it
> does not work. Is there something else to do apart from calling
> |sf_proj_network(TRUE)|? Here is the 7 lines of code I used:
>
> |pt_27572 <- data.frame(X=55824.4970,Y=2394454.2120)| # set coordinates
> of one point in EPSG:27572
>
> |pt_2154 <- data.frame(X=107242.8310,Y=6832277.1820)| # known accurate
> coordinates of the same point in EPSG:2154 (from calculations of the
> French National Geographic Institute)
>
> |ptSf_27572 <- st_as_sf(pt_27572, coords = c("X", "Y"), crs = 27572)| #
> build sf object
>
> |ptSf_2154 <- st_as_sf(pt_2154, coords = c("X", "Y"), crs = 2154)| #
> build sf object
>
> |sf_proj_network(TRUE)| # allow search for online datum grids in the
> PROJ CDN
>
> [1] "https://cdn.proj.org"
>
> |sf_proj_pipelines("EPSG:27572", "EPSG:2154")| # grids
> (fr_ign_gr3df97a.tif) seem to be found for accurate transformation from
> EPSG:27572 to EPSG:2154
>
> |Candidate coordinate operations found: 3 Strict containment: FALSE Axis
> order auth compl: FALSE Source: EPSG:27572 Target: EPSG:2154 Best
> instantiable operation has accuracy: 1 m Description: Inverse of Lambert
> zone II + NTF (Paris) to NTF (1) + NTF to RGF93 (1) + Lambert-93
> Definition: +proj=pipeline +step +inv +proj=lcc +lat_1=46.8 +lat_0=46.8
> +lon_0=0 +k_0=0.99987742 +x_0=600000 +y_0=2200000 +ellps=clrk80ign
> +pm=paris +step +proj=push +v_3 +step +proj=cart +ellps=clrk80ign +step
> +proj=xyzgridshift +grids=fr_ign_gr3df97a.tif +grid_ref=output_crs
> +ellps=GRS80 +step +inv +proj=cart +ellps=GRS80 +step +proj=pop +v_3
> +step +proj=lcc +lat_0=46.5 +lon_0=3 +lat_1=49 +lat_2=44 +x_0=700000
> +y_0=6600000 +ellps=GRS80 |
>
> |ptSf_2154_grid <- st_transform(ptSf_27572,crs=2154)| # apply transformation
>
> |st_distance(ptSf_2154_grid,ptSf_2154)| # incorrect (ungridded)
> transformation, the distance should be zero. 3.777 m is the known error
> for the ungridded transformation.
>
> |Units: [m] [,1] [1,] 3.777346 |
>
> I read in (the so useful) "Spatial Data Science" that by default, the
> most accurate pipeline is chosen by |st_transform|. Why isn't it the
> case here?
>
> I am running R version 4.1.1, GEOS 3.9.1, GDAL 3.2.1, PROJ 7.2.1.
>
> Thanks for your help,
>
> Jean-Luc
>
>

-- 
Roger Bivand
Emeritus Professor
Department of Economics, Norwegian School of Economics,
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From mjherrer|@@t @end|ng |rom gm@||@com  Mon Oct 11 20:31:34 2021
From: mjherrer|@@t @end|ng |rom gm@||@com (maria jesus herrerias)
Date: Mon, 11 Oct 2021 20:31:34 +0200
Subject: [R-sig-Geo] moran test - Empty neighbour sets found
Message-ID: <CAPvcma18BH3mOwZLYeB-EZGqVaOTOPmRWWZqfvQfETng24aQaw@mail.gmail.com>

Dear Roger,

 I try first with your suggestion for the map:



library(rnaturalearth)

spdf_world <- ne_countries(returnclass="sf")



if (require(sp)) {

  plot(spdf_world)

  }



names(spdf_world)



[1] "scalerank"  "featurecla" "labelrank"  "sovereignt" "sov_a3"

 [6] "adm0_dif"   "level"      "type"       "admin"      "adm0_a3"

[11] "geou_dif"   "geounit"    "gu_a3"      "su_dif"     "subunit"

[16] "su_a3"      "brk_diff"   "name"       "name_long"  "brk_a3"

[21] "brk_name"   "brk_group"  "abbrev"     "postal"     "formal_en"

[26] "formal_fr"  "note_adm0"  "note_brk"   "name_sort"  "name_alt"

[31] "mapcolor7"  "mapcolor8"  "mapcolor9"  "mapcolor13" "pop_est"

[36] "gdp_md_est" "pop_year"   "lastcensus" "gdp_year"   "economy"

[41] "income_grp" "wikipedia"  "fips_10"    "iso_a2"     "iso_a3"

[46] "iso_n3"     "un_a3"      "wb_a2"      "wb_a3"      "woe_id"

[51] "adm0_a3_is" "adm0_a3_us" "adm0_a3_un" "adm0_a3_wb" "continent"

[56] "region_un"  "subregion"  "region_wb"  "name_len"   "long_len"

[61] "abbrev_len" "tiny"       "homepart"   "geometry"





spdf_world$geounit



library(foreign)

library(haven)





setwd("C:/Users/Usuario/Desktop/instituciones/revision energy
economics/docs enviados/spatial test")



x <- read.dta("C:/Users/Usuario/Desktop/instituciones/revision energy
economics/docs enviados/spatial test/high_spatial.dta")



dta_cntries <- unique(x$geounit)



library(sf)



wrld_a <- aggregate(spdf_world, list(spdf_world$geounit), head, n=1)





o <- match(dta_cntries, wrld_a$geounit)



#Check if matching is right



which(is.na(o))

[1] 9

dta_cntries[9] <- "France"

o <- match(dta_cntries, spdf_world$geounit)

o

which(is.na(o))



library(spdep)

row.names(wrld_a) <- wrld_a$geounit

nb <- poly2nb(wrld_a)

nb1 <- subset(nb, 1:nrow(wrld_a) %in% o)



Neighbour list object:

Number of regions: 32

Number of nonzero links: 24

Percentage nonzero weights: 2.34375

Average number of links: 0.75

17 regions with no links:

Angola Dominican Republic East Timor Egypt Falkland Islands Fiji Gambia
Guyana Liberia Malaysia Oman Papua New Guinea Puerto Rico Republic of
Serbia Slovenia Sweden Uruguay

Note for roger: this is wrong as I didn?t include these countries in the
data (17 regions with no links)



wrld_s <- wrld_a[1:nrow(wrld_a) %in% o,]

nb2 <- poly2nb(wrld_s)

all.equal(nb1, nb2, check.attributes=FALSE)

[1] TRUE  # subsetting well-done however.

---------------------------------------------------

I try now with my map:



#Spatial Dependence for Panel 32 regions from 1990-2014



# The Spatial Matrix

# Read the shapefile and set up the working directory.

library(foreign)

library(haven)





setwd("C:/Users/Usuario/Desktop/instituciones/revision energy
economics/docs enviados/spatial test")



x <- read.dta("C:/Users/Usuario/Desktop/instituciones/revision energy
economics/docs enviados/spatial test/high_spatial.dta")



# Matching with stata file and shapefile by ID



dta_cntries <- unique(x$OBJECTID)



library(sf)



wrld <- st_read("C:/Users/Usuario/Desktop/instituciones/revision energy
economics/docs
enviados/Longitude_Graticules_and_World_Countries_Boundaries-shp/mapa1.shp")

wrld_a <- aggregate(wrld, list(wrld$OBJECTID), head, n=1)





o <- match(dta_cntries, wrld_a$OBJECTID)



#Check if matching is right





which(is.na(o))



o <- match(dta_cntries, wrld$OBJECTID)

o



library(spdep)

row.names(wrld_a) <- wrld_a$OBJECTID

nb <- poly2nb(wrld_a, queen=TRUE)

nb1 <- subset(nb, 1:nrow(wrld_a) %in% o)



nb1llistw <- nb2listw(nb1,style = "W", zero.policy = TRUE)



#high

Neighbour list object:

Number of regions: 32

Number of nonzero links: 82

Percentage nonzero weights: 8.007812

Average number of links: 2.5625



wrld_s <- wrld_a[1:nrow(wrld_a) %in% o,]

nb2 <- poly2nb(wrld_s,queen=TRUE)

all.equal(nb1, nb2, check.attributes=FALSE)

[1] TRUE  # subsetting well-done



subworlddata <- wrld_s







# Tranform the nb object into a matrix row standarised.



sub.queen.w.Mat <- listw2mat(sub.queen.listw) # creates a standardized
matrix (rows sum to 1)

sub.queen.B.Mat <- nb2mat(sub.queen.nb, style='B',zero.policy=TRUE) # a
simple binary matrix (rows sum to the number of neighbors)



rownames(sub.queen.w.Mat) <- subworlddata$OBJECTID

colnames(sub.queen.w.Mat) <- subworlddata$OBJECTID





rownames(sub.queen.B.Mat) <- subworlddata$OBJECTID

colnames(sub.queen.B.Mat) <- subworlddata$OBJECTID




----------------------------------------------------------------------------------------------------------





sub.queen.w.Mat1 <-
read.dta("C:/Users/Usuario/Desktop/instituciones/revision energy
economics/docs enviados/subqueenW.dta")

sub.queen.B.Mat1 <-
read.dta("C:/Users/Usuario/Desktop/instituciones/revision energy
economics/docs enviados/subqueenB.dta")





sub.queen.w.Mat11 <- as.matrix(sub.queen.w.Mat1)

rownames(sub.queen.w.Mat11) <- subworlddata$OBJECTID

colnames(sub.queen.w.Mat11) <- subworlddata$OBJECTID

sub.queen.lw.Mat11 <- mat2listw(sub.queen.w.Mat11)



sub.queen.B.Mat11 <- as.matrix(sub.queen.B.Mat1)

rownames(sub.queen.B.Mat11) <- subworlddata$OBJECTID

colnames(sub.queen.B.Mat11) <- subworlddata$OBJECTID

sub.queen.lB.Mat11 <- mat2listw(sub.queen.B.Mat11)





listw1 <- sub.queen.lw.Mat11

listw2 <- sub.queen.lB.Mat11



sub.queen.lw.listw.Mat21 <- nb2listw(sub.queen.lw.Mat11$neighbours,
style="W",zero.policy=TRUE)

sub.queen.lB.listw.Mat21 <- nb2listw(sub.queen.lB.Mat11$neighbours,
style="B",zero.policy=TRUE)



# Summary Matrix nb object to listw

listw21 <- sub.queen.lw.listw.Mat21

listw22 <- sub.queen.lB.listw.Mat21



---------------------------------------------------





library(plm)



setwd("C:/Users/Usuario/Desktop/instituciones/revision energy
economics/code and data/quantile")



x <- read.dta("C:/Users/Usuario/Desktop/instituciones/revision energy
economics/docs enviados/spatial test/high_spatial.dta")





mydata <- pdata.frame(x, index = c("OBJECTID", "year"))

**************************************

#Variables.



energy <- mydata$leic

gdp <- mydata$lgdppcnewc

gdp2 <- mydata$lgdppcnewc2

fdi <- mydata$fdigc

imports <- mydata$importsgc

industry <- mydata$industrygc

inst <- mydata$kun_legabsc

ID <- mydata$OBJECTID

time <- mydata$year



**********************************

#Define formula



model.1 <- energy ~ gdp + gdp2 + fdi + imports + industry + inst



ols.eq1 <- lm(model.1, data = mydata)

summary(ols.eq1)





lmMoranTest <- lm.morantest(ols.eq1,listw = nb2listw(nb1,style = "W",
zero.policy = TRUE))

lmMoranTest



*Error in nb2listw(neighbours = subnb, glist = NULL, style = style,
zero.policy = zero.policy) : *

*  Empty neighbour sets found*



lmLMtests <- lm.LMtests(ols.eq1, listw = nb2listw(nb1,style = "W",
zero.policy = TRUE), test=c("LMerr", "LMlag", "RLMerr", "RLMlag", "SARMA"))

lmLMtests



*Error in nb2listw(neighbours = subnb, glist = NULL, style = style,
zero.policy = zero.policy) : *

*  Empty neighbour sets found*


many thanks
maria jesus

	[[alternative HTML version deleted]]


From Roger@B|v@nd @end|ng |rom nhh@no  Mon Oct 11 21:01:21 2021
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Mon, 11 Oct 2021 21:01:21 +0200 (CEST)
Subject: [R-sig-Geo] cannot apply a gridded transformation with sf
In-Reply-To: <bb9b6c94-b4f5-3091-96f5-535bc3974de1@reclus2.nhh.no>
References: <1e7e71eb-53c2-da4e-c276-b4b7d17ea40e@inrae.fr>
 <bb9b6c94-b4f5-3091-96f5-535bc3974de1@reclus2.nhh.no>
Message-ID: <b140ac6e-1c2f-2fa-d190-8b83289c354e@reclus2.nhh.no>

Assuming the Windows CRAN binary. Binary sf (and rgdal) packages bundle 
PROJ and GDAL metadata files taken as fixed for given releases of PROJ and 
GDAL, but from PROJ 7, a content download network (CDN, 
https://cdn.proj-org) is also available. Binary packages set the PROJ_LIB 
environment variable when loaded to the bundled metadata. From PROJ 7, a 
separate user-writable directory is also needed to cache transformation 
grids downloaded from the CDN.

The current difficulty stems both from problems passing through the string 
defining the user-writable directory, and from st_transform() (and 
rgdal::spTransform()) not choosing the most accurate transformation 
pipeline (possibly because the user-writable directory is not properly 
detected ??). The following code works around the problem by coercing the 
sf object to a Spatial object from sp, using spTransform() instead of 
st_transform, then coercing back to sf. spTransform() does not use PROJ 
through GDAL, but uses PROJ directly; it still needs to be told which 
transformation pipeline to use.

# at the very beginning of the R session, define the user-writable 
# directory
td <- tempfile()
dir.create(td)
Sys.setenv("PROJ_USER_WRITABLE_DIRECTORY"=td)
library(rgdal)
rgdal_extSoftVersion()
# check the PROJ search paths and check that the user-writable directory 
# is empty and that the CDN is not enabled
(pths <- get_proj_search_paths())
list.files(pths[1])
is_proj_CDN_enabled()
# define the objects and check that the search paths are still OK
library(sf)
get_proj_search_paths()
pt_27572 <- data.frame(X=55824.4970,Y=2394454.2120)
pt_2154 <- data.frame(X=107242.8310,Y=6832277.1820)
ptSf_27572 <- st_as_sf(pt_27572, coords = c("X", "Y"), crs=27572)
ptSf_2154 <- st_as_sf(pt_2154, coords = c("X", "Y"), crs=2154)
# enable the CDN and that the user-writable directory is still empty
enable_proj_CDN()
is_proj_CDN_enabled()
list.files(pths[1])
# list candidate coordinate operations
(o <- list_coordOps("EPSG:27572", "EPSG:2154"))
# transform using the first returned coordinate operation pipeline
ptSf_2154_grid <- st_as_sf(spTransform(as(ptSf_27572, "Spatial"),
   CRS("EPSG:2154"), coordOp=o[1, "definition"]))
# print the coordinate operation used
get_last_coordOp()
# check that the user-writable directory is populated
list.files(pths[1])
# check distance to defined point in target crs
st_distance(ptSf_2154_grid, ptSf_2154)

With PROJ 7.2.1 this yields a different sub-millimetre distance from PROJ 
8.1.1, because a different grid is preferred, but both do transform your 
input point to your expected output point if half a millimetre is close 
enough.

I've raised https://github.com/r-spatial/sf/issues/1815 with some more 
details. This may take some time to resolve satisfactorily.

Roger

On Mon, 11 Oct 2021, Roger Bivand wrote:

> Dear Jean-Luc,
>
> Thanks for a very helpful report. I'll answer fully later, but if you could 
> provide in addition your platform (I think Windows or macOS, sf installed as 
> a CRAN binary), that would help. On these platforms, access to the CDN for 
> grids is not what it should be, and your example is helping debug the 
> problem.
>
> Best wishes,
>
> Roger
>
> On Sun, 10 Oct 2021, Jean-Luc Dupouey wrote:
>
>>  Dear forumites,
>>
>>  I try to apply a gridded transformation of coordinates in |sf|, but it
>>  does not work. Is there something else to do apart from calling
>> | sf_proj_network(TRUE)|? Here is the 7 lines of code I used:
>> 
>> | pt_27572 <- data.frame(X=55824.4970,Y=2394454.2120)| # set coordinates
>>  of one point in EPSG:27572
>> 
>> | pt_2154 <- data.frame(X=107242.8310,Y=6832277.1820)| # known accurate
>>  coordinates of the same point in EPSG:2154 (from calculations of the
>>  French National Geographic Institute)
>> 
>> | ptSf_27572 <- st_as_sf(pt_27572, coords = c("X", "Y"), crs = 27572)| #
>>  build sf object
>> 
>> | ptSf_2154 <- st_as_sf(pt_2154, coords = c("X", "Y"), crs = 2154)| #
>>  build sf object
>> 
>> | sf_proj_network(TRUE)| # allow search for online datum grids in the
>>  PROJ CDN
>>
>>  [1] "https://cdn.proj.org"
>> 
>> | sf_proj_pipelines("EPSG:27572", "EPSG:2154")| # grids
>>  (fr_ign_gr3df97a.tif) seem to be found for accurate transformation from
>>  EPSG:27572 to EPSG:2154
>> 
>> | Candidate coordinate operations found: 3 Strict containment: FALSE Axis
>>  order auth compl: FALSE Source: EPSG:27572 Target: EPSG:2154 Best
>>  instantiable operation has accuracy: 1 m Description: Inverse of Lambert
>>  zone II + NTF (Paris) to NTF (1) + NTF to RGF93 (1) + Lambert-93
>>  Definition: +proj=pipeline +step +inv +proj=lcc +lat_1=46.8 +lat_0=46.8
>>  +lon_0=0 +k_0=0.99987742 +x_0=600000 +y_0=2200000 +ellps=clrk80ign
>>  +pm=paris +step +proj=push +v_3 +step +proj=cart +ellps=clrk80ign +step
>>  +proj=xyzgridshift +grids=fr_ign_gr3df97a.tif +grid_ref=output_crs
>>  +ellps=GRS80 +step +inv +proj=cart +ellps=GRS80 +step +proj=pop +v_3
>>  +step +proj=lcc +lat_0=46.5 +lon_0=3 +lat_1=49 +lat_2=44 +x_0=700000
>>  +y_0=6600000 +ellps=GRS80 |
>> 
>> | ptSf_2154_grid <- st_transform(ptSf_27572,crs=2154)| # apply 
>> | transformation
>> 
>> | st_distance(ptSf_2154_grid,ptSf_2154)| # incorrect (ungridded)
>>  transformation, the distance should be zero. 3.777 m is the known error
>>  for the ungridded transformation.
>> 
>> | Units: [m] [,1] [1,] 3.777346 |
>>
>>  I read in (the so useful) "Spatial Data Science" that by default, the
>>  most accurate pipeline is chosen by |st_transform|. Why isn't it the
>>  case here?
>>
>>  I am running R version 4.1.1, GEOS 3.9.1, GDAL 3.2.1, PROJ 7.2.1.
>>
>>  Thanks for your help,
>>
>>  Jean-Luc
>> 
>> 
>
>

-- 
Roger Bivand
Emeritus Professor
Department of Economics, Norwegian School of Economics,
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From Roger@B|v@nd @end|ng |rom nhh@no  Tue Oct 12 15:19:53 2021
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Tue, 12 Oct 2021 15:19:53 +0200 (CEST)
Subject: [R-sig-Geo] moran test - Empty neighbour sets found
In-Reply-To: <CAPvcma18BH3mOwZLYeB-EZGqVaOTOPmRWWZqfvQfETng24aQaw@mail.gmail.com>
References: <CAPvcma18BH3mOwZLYeB-EZGqVaOTOPmRWWZqfvQfETng24aQaw@mail.gmail.com>
Message-ID: <daa7272b-930-b5ec-72b5-ab1580dd9e34@reclus2.nhh.no>

Please use plain text email only, HTML only makes things illegible.

The clear error message is: "Empty neighbour sets found", so you need to 
continue to use the zero.policy=TRUE argument to assert how you want to 
handle this problem.

Roger

On Mon, 11 Oct 2021, maria jesus herrerias wrote:

> Dear Roger,
>
> I try first with your suggestion for the map:
>
>
>
> library(rnaturalearth)
>
> spdf_world <- ne_countries(returnclass="sf")
>
>
>
> if (require(sp)) {
>
>  plot(spdf_world)
>
>  }
>
>
>
> names(spdf_world)
>
>
>
> [1] "scalerank"  "featurecla" "labelrank"  "sovereignt" "sov_a3"
>
> [6] "adm0_dif"   "level"      "type"       "admin"      "adm0_a3"
>
> [11] "geou_dif"   "geounit"    "gu_a3"      "su_dif"     "subunit"
>
> [16] "su_a3"      "brk_diff"   "name"       "name_long"  "brk_a3"
>
> [21] "brk_name"   "brk_group"  "abbrev"     "postal"     "formal_en"
>
> [26] "formal_fr"  "note_adm0"  "note_brk"   "name_sort"  "name_alt"
>
> [31] "mapcolor7"  "mapcolor8"  "mapcolor9"  "mapcolor13" "pop_est"
>
> [36] "gdp_md_est" "pop_year"   "lastcensus" "gdp_year"   "economy"
>
> [41] "income_grp" "wikipedia"  "fips_10"    "iso_a2"     "iso_a3"
>
> [46] "iso_n3"     "un_a3"      "wb_a2"      "wb_a3"      "woe_id"
>
> [51] "adm0_a3_is" "adm0_a3_us" "adm0_a3_un" "adm0_a3_wb" "continent"
>
> [56] "region_un"  "subregion"  "region_wb"  "name_len"   "long_len"
>
> [61] "abbrev_len" "tiny"       "homepart"   "geometry"
>
>
>
>
>
> spdf_world$geounit
>
>
>
> library(foreign)
>
> library(haven)
>
>
>
>
>
> setwd("C:/Users/Usuario/Desktop/instituciones/revision energy
> economics/docs enviados/spatial test")
>
>
>
> x <- read.dta("C:/Users/Usuario/Desktop/instituciones/revision energy
> economics/docs enviados/spatial test/high_spatial.dta")
>
>
>
> dta_cntries <- unique(x$geounit)
>
>
>
> library(sf)
>
>
>
> wrld_a <- aggregate(spdf_world, list(spdf_world$geounit), head, n=1)
>
>
>
>
>
> o <- match(dta_cntries, wrld_a$geounit)
>
>
>
> #Check if matching is right
>
>
>
> which(is.na(o))
>
> [1] 9
>
> dta_cntries[9] <- "France"
>
> o <- match(dta_cntries, spdf_world$geounit)
>
> o
>
> which(is.na(o))
>
>
>
> library(spdep)
>
> row.names(wrld_a) <- wrld_a$geounit
>
> nb <- poly2nb(wrld_a)
>
> nb1 <- subset(nb, 1:nrow(wrld_a) %in% o)
>
>
>
> Neighbour list object:
>
> Number of regions: 32
>
> Number of nonzero links: 24
>
> Percentage nonzero weights: 2.34375
>
> Average number of links: 0.75
>
> 17 regions with no links:
>
> Angola Dominican Republic East Timor Egypt Falkland Islands Fiji Gambia
> Guyana Liberia Malaysia Oman Papua New Guinea Puerto Rico Republic of
> Serbia Slovenia Sweden Uruguay
>
> Note for roger: this is wrong as I didn?t include these countries in the
> data (17 regions with no links)
>
>
>
> wrld_s <- wrld_a[1:nrow(wrld_a) %in% o,]
>
> nb2 <- poly2nb(wrld_s)
>
> all.equal(nb1, nb2, check.attributes=FALSE)
>
> [1] TRUE  # subsetting well-done however.
>
> ---------------------------------------------------
>
> I try now with my map:
>
>
>
> #Spatial Dependence for Panel 32 regions from 1990-2014
>
>
>
> # The Spatial Matrix
>
> # Read the shapefile and set up the working directory.
>
> library(foreign)
>
> library(haven)
>
>
>
>
>
> setwd("C:/Users/Usuario/Desktop/instituciones/revision energy
> economics/docs enviados/spatial test")
>
>
>
> x <- read.dta("C:/Users/Usuario/Desktop/instituciones/revision energy
> economics/docs enviados/spatial test/high_spatial.dta")
>
>
>
> # Matching with stata file and shapefile by ID
>
>
>
> dta_cntries <- unique(x$OBJECTID)
>
>
>
> library(sf)
>
>
>
> wrld <- st_read("C:/Users/Usuario/Desktop/instituciones/revision energy
> economics/docs
> enviados/Longitude_Graticules_and_World_Countries_Boundaries-shp/mapa1.shp")
>
> wrld_a <- aggregate(wrld, list(wrld$OBJECTID), head, n=1)
>
>
>
>
>
> o <- match(dta_cntries, wrld_a$OBJECTID)
>
>
>
> #Check if matching is right
>
>
>
>
>
> which(is.na(o))
>
>
>
> o <- match(dta_cntries, wrld$OBJECTID)
>
> o
>
>
>
> library(spdep)
>
> row.names(wrld_a) <- wrld_a$OBJECTID
>
> nb <- poly2nb(wrld_a, queen=TRUE)
>
> nb1 <- subset(nb, 1:nrow(wrld_a) %in% o)
>
>
>
> nb1llistw <- nb2listw(nb1,style = "W", zero.policy = TRUE)
>
>
>
> #high
>
> Neighbour list object:
>
> Number of regions: 32
>
> Number of nonzero links: 82
>
> Percentage nonzero weights: 8.007812
>
> Average number of links: 2.5625
>
>
>
> wrld_s <- wrld_a[1:nrow(wrld_a) %in% o,]
>
> nb2 <- poly2nb(wrld_s,queen=TRUE)
>
> all.equal(nb1, nb2, check.attributes=FALSE)
>
> [1] TRUE  # subsetting well-done
>
>
>
> subworlddata <- wrld_s
>
>
>
>
>
>
>
> # Tranform the nb object into a matrix row standarised.
>
>
>
> sub.queen.w.Mat <- listw2mat(sub.queen.listw) # creates a standardized
> matrix (rows sum to 1)
>
> sub.queen.B.Mat <- nb2mat(sub.queen.nb, style='B',zero.policy=TRUE) # a
> simple binary matrix (rows sum to the number of neighbors)
>
>
>
> rownames(sub.queen.w.Mat) <- subworlddata$OBJECTID
>
> colnames(sub.queen.w.Mat) <- subworlddata$OBJECTID
>
>
>
>
>
> rownames(sub.queen.B.Mat) <- subworlddata$OBJECTID
>
> colnames(sub.queen.B.Mat) <- subworlddata$OBJECTID
>
>
>
>
> ----------------------------------------------------------------------------------------------------------
>
>
>
>
>
> sub.queen.w.Mat1 <-
> read.dta("C:/Users/Usuario/Desktop/instituciones/revision energy
> economics/docs enviados/subqueenW.dta")
>
> sub.queen.B.Mat1 <-
> read.dta("C:/Users/Usuario/Desktop/instituciones/revision energy
> economics/docs enviados/subqueenB.dta")
>
>
>
>
>
> sub.queen.w.Mat11 <- as.matrix(sub.queen.w.Mat1)
>
> rownames(sub.queen.w.Mat11) <- subworlddata$OBJECTID
>
> colnames(sub.queen.w.Mat11) <- subworlddata$OBJECTID
>
> sub.queen.lw.Mat11 <- mat2listw(sub.queen.w.Mat11)
>
>
>
> sub.queen.B.Mat11 <- as.matrix(sub.queen.B.Mat1)
>
> rownames(sub.queen.B.Mat11) <- subworlddata$OBJECTID
>
> colnames(sub.queen.B.Mat11) <- subworlddata$OBJECTID
>
> sub.queen.lB.Mat11 <- mat2listw(sub.queen.B.Mat11)
>
>
>
>
>
> listw1 <- sub.queen.lw.Mat11
>
> listw2 <- sub.queen.lB.Mat11
>
>
>
> sub.queen.lw.listw.Mat21 <- nb2listw(sub.queen.lw.Mat11$neighbours,
> style="W",zero.policy=TRUE)
>
> sub.queen.lB.listw.Mat21 <- nb2listw(sub.queen.lB.Mat11$neighbours,
> style="B",zero.policy=TRUE)
>
>
>
> # Summary Matrix nb object to listw
>
> listw21 <- sub.queen.lw.listw.Mat21
>
> listw22 <- sub.queen.lB.listw.Mat21
>
>
>
> ---------------------------------------------------
>
>
>
>
>
> library(plm)
>
>
>
> setwd("C:/Users/Usuario/Desktop/instituciones/revision energy
> economics/code and data/quantile")
>
>
>
> x <- read.dta("C:/Users/Usuario/Desktop/instituciones/revision energy
> economics/docs enviados/spatial test/high_spatial.dta")
>
>
>
>
>
> mydata <- pdata.frame(x, index = c("OBJECTID", "year"))
>
> **************************************
>
> #Variables.
>
>
>
> energy <- mydata$leic
>
> gdp <- mydata$lgdppcnewc
>
> gdp2 <- mydata$lgdppcnewc2
>
> fdi <- mydata$fdigc
>
> imports <- mydata$importsgc
>
> industry <- mydata$industrygc
>
> inst <- mydata$kun_legabsc
>
> ID <- mydata$OBJECTID
>
> time <- mydata$year
>
>
>
> **********************************
>
> #Define formula
>
>
>
> model.1 <- energy ~ gdp + gdp2 + fdi + imports + industry + inst
>
>
>
> ols.eq1 <- lm(model.1, data = mydata)
>
> summary(ols.eq1)
>
>
>
>
>
> lmMoranTest <- lm.morantest(ols.eq1,listw = nb2listw(nb1,style = "W",
> zero.policy = TRUE))
>
> lmMoranTest
>
>
>
> *Error in nb2listw(neighbours = subnb, glist = NULL, style = style,
> zero.policy = zero.policy) : *
>
> *  Empty neighbour sets found*
>
>
>
> lmLMtests <- lm.LMtests(ols.eq1, listw = nb2listw(nb1,style = "W",
> zero.policy = TRUE), test=c("LMerr", "LMlag", "RLMerr", "RLMlag", "SARMA"))
>
> lmLMtests
>
>
>
> *Error in nb2listw(neighbours = subnb, glist = NULL, style = style,
> zero.policy = zero.policy) : *
>
> *  Empty neighbour sets found*
>
>
> many thanks
> maria jesus
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Emeritus Professor
Department of Economics, Norwegian School of Economics,
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From rob00x @end|ng |rom gm@||@com  Tue Oct 12 15:43:34 2021
From: rob00x @end|ng |rom gm@||@com (Robin Lovelace)
Date: Tue, 12 Oct 2021 14:43:34 +0100
Subject: [R-sig-Geo] Combine line segments into one line
In-Reply-To: <VI1P192MB023732384D2E5624C58D3A52D8B29@VI1P192MB0237.EURP192.PROD.OUTLOOK.COM>
References: <VI1P192MB0237672C251DE24F1FA120D4D8B19@VI1P192MB0237.EURP192.PROD.OUTLOOK.COM>
 <VI1P192MB023732384D2E5624C58D3A52D8B29@VI1P192MB0237.EURP192.PROD.OUTLOOK.COM>
Message-ID: <CAF16KkX24WJr4w3P4=+q3Qfp5gg3_8c0LoC5xaYdUiqWLj20jg@mail.gmail.com>

Hi Remon,

Please could you provide a fully reproducible example to illustrate the
data you have, what you have tried, and what you hope to achieve?

I cannot see the screenshot mentioned.

All the best,

Robin

On Fri, Oct 8, 2021 at 1:55 PM Remon Hanna <akhnatononline at hotmail.com>
wrote:

> Hi
>
> I have line segments that I would like to combine them within each
> corridor, I.e each corridor will be one line of combined segments of
> NAME_S2S and combined geometry  as per the screenshot.
>
> I have managed to plot the segments on the map as you can see but when
> zooming in these segments are not in one, which I would like to group them.
>
> I ran the below line to group them by corridor, but I get error below;
>
> > dataformap1<-gLineMerge(dataformap[dataformap$Corridor==1, ])
> Error in gLineMerge(dataformap[dataformap$Corridor == 1, ]) :
>   Invalid geometry, may only be applied to lines
>
> Many thanks in advance
>
> Remon Hanna
>
> Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From Roger@B|v@nd @end|ng |rom nhh@no  Tue Oct 12 17:25:37 2021
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Tue, 12 Oct 2021 17:25:37 +0200 (CEST)
Subject: [R-sig-Geo] cannot apply a gridded transformation with sf
In-Reply-To: <b140ac6e-1c2f-2fa-d190-8b83289c354e@reclus2.nhh.no>
References: <1e7e71eb-53c2-da4e-c276-b4b7d17ea40e@inrae.fr>
 <bb9b6c94-b4f5-3091-96f5-535bc3974de1@reclus2.nhh.no>
 <b140ac6e-1c2f-2fa-d190-8b83289c354e@reclus2.nhh.no>
Message-ID: <192c7853-c4a9-79d-6668-f2c8f874d59e@reclus2.nhh.no>

One basic problem is that a regression was introduced in PROJ from 7.2.0, 
resolved last week by https://github.com/OSGeo/PROJ/pull/2884, where grid 
transformations ceased to work if the prime meridian was not Greenwich. So 
for PROJ 7.2.0-8.1.1, the closest you can get is:

ptSf_2154_via_CRS84 <- st_transform(st_transform(ptSf_27572, 
crs="OGC:CRS84"), crs=2154)
st_distance(ptSf_2154_via_CRS84, ptSf_2154)
# Units: [m]
#          [,1]
# [1,] 3.777444

through a CRS84 hub using a Helmert transformation, unless you can force 
the pipeline as shown in the sf issue: 
https://github.com/r-spatial/sf/issues/1815
This forcing so far only works on Linux, as the user-writable directory is 
not properly accessed in sf for Windows or macOS yet. You may also use the 
rgdal work-around setting the user-writable directory as shown earlier in 
this thread.

Roger

On Mon, 11 Oct 2021, Roger Bivand wrote:

> Assuming the Windows CRAN binary. Binary sf (and rgdal) packages bundle PROJ 
> and GDAL metadata files taken as fixed for given releases of PROJ and GDAL, 
> but from PROJ 7, a content download network (CDN, https://cdn.proj-org) is 
> also available. Binary packages set the PROJ_LIB environment variable when 
> loaded to the bundled metadata. From PROJ 7, a separate user-writable 
> directory is also needed to cache transformation grids downloaded from the 
> CDN.
>
> The current difficulty stems both from problems passing through the string 
> defining the user-writable directory, and from st_transform() (and 
> rgdal::spTransform()) not choosing the most accurate transformation pipeline 
> (possibly because the user-writable directory is not properly detected ??). 
> The following code works around the problem by coercing the sf object to a 
> Spatial object from sp, using spTransform() instead of st_transform, then 
> coercing back to sf. spTransform() does not use PROJ through GDAL, but uses 
> PROJ directly; it still needs to be told which transformation pipeline to 
> use.
>
> #  at the very beginning of the R session, define the user-writable directory
> td <- tempfile()
> dir.create(td)
> Sys.setenv("PROJ_USER_WRITABLE_DIRECTORY"=td)
> library(rgdal)
> rgdal_extSoftVersion()
> #  check the PROJ search paths and check that the user-writable directory is 
> #  empty and that the CDN is not enabled
> (pths <- get_proj_search_paths())
> list.files(pths[1])
> is_proj_CDN_enabled()
> # define the objects and check that the search paths are still OK
> library(sf)
> get_proj_search_paths()
> pt_27572 <- data.frame(X=55824.4970,Y=2394454.2120)
> pt_2154 <- data.frame(X=107242.8310,Y=6832277.1820)
> ptSf_27572 <- st_as_sf(pt_27572, coords = c("X", "Y"), crs=27572)
> ptSf_2154 <- st_as_sf(pt_2154, coords = c("X", "Y"), crs=2154)
> # enable the CDN and that the user-writable directory is still empty
> enable_proj_CDN()
> is_proj_CDN_enabled()
> list.files(pths[1])
> # list candidate coordinate operations
> (o <- list_coordOps("EPSG:27572", "EPSG:2154"))
> # transform using the first returned coordinate operation pipeline
> ptSf_2154_grid <- st_as_sf(spTransform(as(ptSf_27572, "Spatial"),
>  CRS("EPSG:2154"), coordOp=o[1, "definition"]))
> # print the coordinate operation used
> get_last_coordOp()
> # check that the user-writable directory is populated
> list.files(pths[1])
> # check distance to defined point in target crs
> st_distance(ptSf_2154_grid, ptSf_2154)
>
> With PROJ 7.2.1 this yields a different sub-millimetre distance from PROJ 
> 8.1.1, because a different grid is preferred, but both do transform your 
> input point to your expected output point if half a millimetre is close 
> enough.
>
> I've raised https://github.com/r-spatial/sf/issues/1815 with some more 
> details. This may take some time to resolve satisfactorily.
>
> Roger
>
> On Mon, 11 Oct 2021, Roger Bivand wrote:
>
>>  Dear Jean-Luc,
>>
>>  Thanks for a very helpful report. I'll answer fully later, but if you
>>  could provide in addition your platform (I think Windows or macOS, sf
>>  installed as a CRAN binary), that would help. On these platforms, access
>>  to the CDN for grids is not what it should be, and your example is helping
>>  debug the problem.
>>
>>  Best wishes,
>>
>>  Roger
>>
>>  On Sun, 10 Oct 2021, Jean-Luc Dupouey wrote:
>>
>>>   Dear forumites,
>>>
>>>   I try to apply a gridded transformation of coordinates in |sf|, but it
>>>   does not work. Is there something else to do apart from calling
>>> |  sf_proj_network(TRUE)|? Here is the 7 lines of code I used:
>>> 
>>> |  pt_27572 <- data.frame(X=55824.4970,Y=2394454.2120)| # set coordinates
>>>   of one point in EPSG:27572
>>> 
>>> |  pt_2154 <- data.frame(X=107242.8310,Y=6832277.1820)| # known accurate
>>>   coordinates of the same point in EPSG:2154 (from calculations of the
>>>   French National Geographic Institute)
>>> 
>>> |  ptSf_27572 <- st_as_sf(pt_27572, coords = c("X", "Y"), crs = 27572)| #
>>>   build sf object
>>> 
>>> |  ptSf_2154 <- st_as_sf(pt_2154, coords = c("X", "Y"), crs = 2154)| #
>>>   build sf object
>>> 
>>> |  sf_proj_network(TRUE)| # allow search for online datum grids in the
>>>   PROJ CDN
>>>
>>>   [1] "https://cdn.proj.org"
>>> 
>>> |  sf_proj_pipelines("EPSG:27572", "EPSG:2154")| # grids
>>>   (fr_ign_gr3df97a.tif) seem to be found for accurate transformation from
>>>   EPSG:27572 to EPSG:2154
>>> 
>>> |  Candidate coordinate operations found: 3 Strict containment: FALSE Axis
>>>   order auth compl: FALSE Source: EPSG:27572 Target: EPSG:2154 Best
>>>   instantiable operation has accuracy: 1 m Description: Inverse of Lambert
>>>   zone II + NTF (Paris) to NTF (1) + NTF to RGF93 (1) + Lambert-93
>>>   Definition: +proj=pipeline +step +inv +proj=lcc +lat_1=46.8 +lat_0=46.8
>>>   +lon_0=0 +k_0=0.99987742 +x_0=600000 +y_0=2200000 +ellps=clrk80ign
>>>   +pm=paris +step +proj=push +v_3 +step +proj=cart +ellps=clrk80ign +step
>>>   +proj=xyzgridshift +grids=fr_ign_gr3df97a.tif +grid_ref=output_crs
>>>   +ellps=GRS80 +step +inv +proj=cart +ellps=GRS80 +step +proj=pop +v_3
>>>   +step +proj=lcc +lat_0=46.5 +lon_0=3 +lat_1=49 +lat_2=44 +x_0=700000
>>>   +y_0=6600000 +ellps=GRS80 |
>>> 
>>> |  ptSf_2154_grid <- st_transform(ptSf_27572,crs=2154)| # apply 
>>> |  transformation
>>> 
>>> |  st_distance(ptSf_2154_grid,ptSf_2154)| # incorrect (ungridded)
>>>   transformation, the distance should be zero. 3.777 m is the known error
>>>   for the ungridded transformation.
>>> 
>>> |  Units: [m] [,1] [1,] 3.777346 |
>>>
>>>   I read in (the so useful) "Spatial Data Science" that by default, the
>>>   most accurate pipeline is chosen by |st_transform|. Why isn't it the
>>>   case here?
>>>
>>>   I am running R version 4.1.1, GEOS 3.9.1, GDAL 3.2.1, PROJ 7.2.1.
>>>
>>>   Thanks for your help,
>>>
>>>   Jean-Luc
>>>
>>> 
>> 
>> 
>
>

-- 
Roger Bivand
Emeritus Professor
Department of Economics, Norwegian School of Economics,
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From @khn@tonon||ne @end|ng |rom hotm@||@com  Tue Oct 12 17:44:41 2021
From: @khn@tonon||ne @end|ng |rom hotm@||@com (Remon Hanna)
Date: Tue, 12 Oct 2021 15:44:41 +0000
Subject: [R-sig-Geo] Combine line segments into one line
In-Reply-To: <CAF16KkX24WJr4w3P4=+q3Qfp5gg3_8c0LoC5xaYdUiqWLj20jg@mail.gmail.com>
References: <VI1P192MB0237672C251DE24F1FA120D4D8B19@VI1P192MB0237.EURP192.PROD.OUTLOOK.COM>
 <VI1P192MB023732384D2E5624C58D3A52D8B29@VI1P192MB0237.EURP192.PROD.OUTLOOK.COM>
 <CAF16KkX24WJr4w3P4=+q3Qfp5gg3_8c0LoC5xaYdUiqWLj20jg@mail.gmail.com>
Message-ID: <VE1P192MB084641A3DE75299E5CC95EEDD8B69@VE1P192MB0846.EURP192.PROD.OUTLOOK.COM>

Hi  Robin

Thanks for coming back to me, my data frame called ?data formap? and each line?s geometry  is in a list as below

Scheme, Corridor, UID,S2S,Geometry

Islington, Canonbury Road, 1447, 14605 to 14609, list(c(-0.100494685106162, -0.100768728775846, -0.100809237473678, -0.100829081233454, -0.101055753520492, -0.101056925872705, -0.101132027068313, -0.101179751049333, -0.101183341723369, -0.101214417461412, -0.101296576180155, -0.101302119916002, -0.101944537808155, 51.5434078452207, 51.5436641294246, 51.5436996947231, 51.5437244960352, 51.544168798304, 51.5441712130049, 51.544334107534, 51.5443894702274, 51.5443939279601, 51.5444353337587, 51.5444892923546, 51.544493149994, 51.5449669589982), c(-0.100337415159165,  -0.100420276584877, -0.100443482598481, -0.100465896635865, -0.100480620959424, -0.100500980394883, -0.100507243380856, -0.100501227668383, -0.100494685106162, 51.5430850037077, 51.5432533165555, 51.5432674582742, 51.5432850407821, 51.5433055391161, 51.5433471893563, 51.5433731318632, 51.5433990971125, 51.5434078452207))


Islington, Canonbury Road, 19934, 14609 TO 29772, list(c(-0.102378850945486, -0.102404766293504, -0.102612043222577, -0.102841140440283, -0.102857165923901, -0.10307303364985, -0.103096514259402, -0.103308545727647, -0.10331512465684, -0.103613310295447, -0.103628721780704, -0.104683501048217, 51.5460024466378, 51.5460044053932, 51.5460430024067, 51.5460719844139, 51.5460746176867, 51.5461185026024, 51.5461247589939, 51.5461957028378, 51.5461980449175, 51.5463107753556, 51.546317496109, 51.5468445401221), c(-0.101944538040546, -0.101987754430814,  -0.101995197988773, -0.102120422782938, -0.102135897924177, -0.102179623597572, -0.102185478839142, -0.102221057492863, -0.102249160660721, -0.102264674655534, -0.102353250310779, -0.10236569955816, -0.10238744921156, -0.102390154716109, -0.102369692569022, -0.102373676493536, -0.102378850945486, 51.5449669591696, 51.5449988326798, 51.5450048166063, 51.5451147525675, 51.5451321348331, 51.5451973544301, 51.5452078768073, 51.545287421255, 51.5453095810419, 51.545324703994, 51.5454336871467, 51.5454557182705,  51.5455198269438, 51.5455452536589, 51.5457128758933, 51.5459370064566, 51.5460024466378))


# converts table to sf format
dataformap <- st_as_sf(dataformap)

# Render leaflet map
map<- leaflet(data=dataformap)%>%
addProviderTiles("CartoDB.Positron",options = providerTileOptions(minZoom=7))%>%
  addPolylines(data=dataformap,color= ~ pal(Scheme), weight = 2,opacity = 0.75,
               smoothFactor = 0,label = ~dataformap$Scheme,
               popup = paste("Scheme:", dataformap$Scheme, "<br>","<br>",
                                    "Corridor:", dataformap$Corridor, "<br>" ))%>%
  addDrawToolbar(targetGroup = "Scheme", editOptions = editToolbarOptions())

map

Thanks

Remon

Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows

From: Robin Lovelace<mailto:rob00x at gmail.com>
Sent: 12 October 2021 14:44
To: r-sig-geo at r-project.org<mailto:r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Combine line segments into one line

Hi Remon,

Please could you provide a fully reproducible example to illustrate the
data you have, what you have tried, and what you hope to achieve?

I cannot see the screenshot mentioned.

All the best,

Robin

On Fri, Oct 8, 2021 at 1:55 PM Remon Hanna <akhnatononline at hotmail.com>
wrote:

> Hi
>
> I have line segments that I would like to combine them within each
> corridor, I.e each corridor will be one line of combined segments of
> NAME_S2S and combined geometry  as per the screenshot.
>
> I have managed to plot the segments on the map as you can see but when
> zooming in these segments are not in one, which I would like to group them.
>
> I ran the below line to group them by corridor, but I get error below;
>
> > dataformap1<-gLineMerge(dataformap[dataformap$Corridor==1, ])
> Error in gLineMerge(dataformap[dataformap$Corridor == 1, ]) :
>   Invalid geometry, may only be applied to lines
>
> Many thanks in advance
>
> Remon Hanna
>
> Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


	[[alternative HTML version deleted]]


From rob00x @end|ng |rom gm@||@com  Tue Oct 12 18:35:41 2021
From: rob00x @end|ng |rom gm@||@com (Robin Lovelace)
Date: Tue, 12 Oct 2021 17:35:41 +0100
Subject: [R-sig-Geo] Combine line segments into one line
In-Reply-To: <VE1P192MB084641A3DE75299E5CC95EEDD8B69@VE1P192MB0846.EURP192.PROD.OUTLOOK.COM>
References: <VI1P192MB0237672C251DE24F1FA120D4D8B19@VI1P192MB0237.EURP192.PROD.OUTLOOK.COM>
 <VI1P192MB023732384D2E5624C58D3A52D8B29@VI1P192MB0237.EURP192.PROD.OUTLOOK.COM>
 <CAF16KkX24WJr4w3P4=+q3Qfp5gg3_8c0LoC5xaYdUiqWLj20jg@mail.gmail.com>
 <VE1P192MB084641A3DE75299E5CC95EEDD8B69@VE1P192MB0846.EURP192.PROD.OUTLOOK.COM>
Message-ID: <CAF16KkWOXP7Wg8XzZ-hRQv8UFj+d+T9L0-MP8wR-romPT+U4Sg@mail.gmail.com>

Great to see the geometry but this still isn't quite a 'reprex'. Can you
provide code that others can reproduce, e.g. starting with:

dataformap = ...

you should be able to get the ... bit from a minimal example of your data
with dput(dataformap). Even better, you could try creating a fully
reproducible example and test it's reproducible using the reprex. You can
do this by copying the code that is reproducible and then entering
reprex::reprex() into the R console. You need to have installed the reprex
package first.

If you'd like to paste code with images you could try pasting the output
into a GitHub issue tracker, e.g.
https://github.com/r-spatial/discuss/issues/

Hope that helps and look forward to seeing a fully reproducible example
that should enable identification of an efficient fix!

Robin

On Tue, Oct 12, 2021 at 4:44 PM Remon Hanna <akhnatononline at hotmail.com>
wrote:

> Hi  Robin
>
>
>
> Thanks for coming back to me, my data frame called ?data formap? and each
> line?s geometry  is in a list as below
>
>
>
> Scheme, Corridor, UID,S2S,Geometry
>
>
>
> Islington, Canonbury Road, 1447, 14605 to 14609,
> list(c(-0.100494685106162, -0.100768728775846, -0.100809237473678,
> -0.100829081233454, -0.101055753520492, -0.101056925872705,
> -0.101132027068313, -0.101179751049333, -0.101183341723369,
> -0.101214417461412, -0.101296576180155, -0.101302119916002,
> -0.101944537808155, 51.5434078452207, 51.5436641294246, 51.5436996947231,
> 51.5437244960352, 51.544168798304, 51.5441712130049, 51.544334107534,
> 51.5443894702274, 51.5443939279601, 51.5444353337587, 51.5444892923546,
> 51.544493149994, 51.5449669589982), c(-0.100337415159165,
> -0.100420276584877, -0.100443482598481, -0.100465896635865,
> -0.100480620959424, -0.100500980394883, -0.100507243380856,
> -0.100501227668383, -0.100494685106162, 51.5430850037077, 51.5432533165555,
> 51.5432674582742, 51.5432850407821, 51.5433055391161, 51.5433471893563,
> 51.5433731318632, 51.5433990971125, 51.5434078452207))
>
>
>
>
>
> Islington, Canonbury Road, 19934, 14609 TO 29772,
> list(c(-0.102378850945486, -0.102404766293504, -0.102612043222577,
> -0.102841140440283, -0.102857165923901, -0.10307303364985,
> -0.103096514259402, -0.103308545727647, -0.10331512465684,
> -0.103613310295447, -0.103628721780704, -0.104683501048217,
> 51.5460024466378, 51.5460044053932, 51.5460430024067, 51.5460719844139,
> 51.5460746176867, 51.5461185026024, 51.5461247589939, 51.5461957028378,
> 51.5461980449175, 51.5463107753556, 51.546317496109, 51.5468445401221),
> c(-0.101944538040546, -0.101987754430814,  -0.101995197988773,
> -0.102120422782938, -0.102135897924177, -0.102179623597572,
> -0.102185478839142, -0.102221057492863, -0.102249160660721,
> -0.102264674655534, -0.102353250310779, -0.10236569955816,
> -0.10238744921156, -0.102390154716109, -0.102369692569022,
> -0.102373676493536, -0.102378850945486, 51.5449669591696, 51.5449988326798,
> 51.5450048166063, 51.5451147525675, 51.5451321348331, 51.5451973544301,
> 51.5452078768073, 51.545287421255, 51.5453095810419, 51.545324703994,
> 51.5454336871467, 51.5454557182705,  51.5455198269438, 51.5455452536589,
> 51.5457128758933, 51.5459370064566, 51.5460024466378))
>
>
>
>
>
> # converts table to sf format
>
> dataformap <- st_as_sf(dataformap)
>
>
>
> # Render leaflet map
>
> map<- leaflet(data=dataformap)%>%
>
> addProviderTiles("CartoDB.Positron",options =
> providerTileOptions(minZoom=7))%>%
>
>   addPolylines(data=dataformap,color= ~ pal(Scheme), weight = 2,opacity =
> 0.75,
>
>                smoothFactor = 0,label = ~dataformap$Scheme,
>
>                popup = paste("Scheme:", dataformap$Scheme, "<br>","<br>",
>
>                                     "Corridor:", dataformap$Corridor,
> "<br>" ))%>%
>
>   addDrawToolbar(targetGroup = "Scheme", editOptions =
> editToolbarOptions())
>
>
>
> map
>
>
>
> Thanks
>
>
>
> Remon
>
>
>
> Sent from Mail <https://go.microsoft.com/fwlink/?LinkId=550986> for
> Windows
>
>
>
> *From: *Robin Lovelace <rob00x at gmail.com>
> *Sent: *12 October 2021 14:44
> *To: *r-sig-geo at r-project.org
> *Subject: *Re: [R-sig-Geo] Combine line segments into one line
>
>
>
> Hi Remon,
>
> Please could you provide a fully reproducible example to illustrate the
> data you have, what you have tried, and what you hope to achieve?
>
> I cannot see the screenshot mentioned.
>
> All the best,
>
> Robin
>
> On Fri, Oct 8, 2021 at 1:55 PM Remon Hanna <akhnatononline at hotmail.com>
> wrote:
>
> > Hi
> >
> > I have line segments that I would like to combine them within each
> > corridor, I.e each corridor will be one line of combined segments of
> > NAME_S2S and combined geometry  as per the screenshot.
> >
> > I have managed to plot the segments on the map as you can see but when
> > zooming in these segments are not in one, which I would like to group
> them.
> >
> > I ran the below line to group them by corridor, but I get error below;
> >
> > > dataformap1<-gLineMerge(dataformap[dataformap$Corridor==1, ])
> > Error in gLineMerge(dataformap[dataformap$Corridor == 1, ]) :
> >   Invalid geometry, may only be applied to lines
> >
> > Many thanks in advance
> >
> > Remon Hanna
> >
> > Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for
> Windows
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>

	[[alternative HTML version deleted]]


From j|n||68 @end|ng |rom gm@||@com  Thu Oct 14 00:44:59 2021
From: j|n||68 @end|ng |rom gm@||@com (Jin Li)
Date: Thu, 14 Oct 2021 09:44:59 +1100
Subject: [R-sig-Geo] spm2: a new package for spatial predictive modelling
Message-ID: <CAGu_3ZK4EXu1ap1As2j2QMeanF83cKWSUU+NrXZ-X3E9sAX_zQ@mail.gmail.com>

Dear all,

A new package, spm2_1.1.0, for spatial predictive modelling has just been
made available on CRAN. It is an updated and extended version of 'spm'
package, by introducing some further novel
               functions for modern statistical methods (i.e., generalised
linear models, glmnet,
               generalised least squares), support vector machine, kriging
methods (i.e., simple
               kriging, universal kriging, block kriging, kriging with an
external drift), and novel
               hybrid methods (228 hybrids plus numerous variants) of
modern statistical methods or
               machine learning methods with mathematical and/or univariate
geostatistical methods for
               spatial predictive modelling. For each method, two functions
are provided, with one
               function for assessing the predictive errors and accuracy of
the method based on
               cross-validation, and the other for generating spatial
predictions. It also contains a
               couple of functions for data preparation and predictive
accuracy assessment.

Any feedback is welcome and appreciated.

Best regards,
-- 
Jin
------------------------------------------
Jin Li, PhD
Founder, Data2action, Australia
https://www.researchgate.net/profile/Jin_Li32
https://scholar.google.com/citations?user=Jeot53EAAAAJ&hl=en

	[[alternative HTML version deleted]]


From @trende @end|ng |rom re@|c|e@rpo||t|c@@com  Thu Oct 14 12:11:01 2021
From: @trende @end|ng |rom re@|c|e@rpo||t|c@@com (Sean Trende)
Date: Thu, 14 Oct 2021 10:11:01 +0000
Subject: [R-sig-Geo] Aggregation and disaggregation in sf
Message-ID: <BLAPR20MB39386D1190AF7B6E67FE49C1BEB89@BLAPR20MB3938.namprd20.prod.outlook.com>

Thank you all for developing this package and taking a huge amount of time to answer questions.  I had a question that I found related answers to, but nothing directly on point.  Perhaps I'm just not being sufficiently creative with my R coding, and I apologize if I missed the "explainer" elsewhere.

A common task is aggregating and disaggregating within a larger polygon set.  I believe that I know how to do the following in the geomander package, but am wondering if there is a "pure" sf solution.

There is a simple version of the task, and a more complex one.

The simple version of task: You have two shapefiles, one of census blocks and one of precinct results. You have a polygon for a precinct that split 100 votes to 100 votes for candidates A and B in the preceding election. The precinct wholly contains three census blocks with respective populations of 100, 200 and 300.  

The task is to identify those blocks that exist within the precinct from the broader block shapefile and then to apportion the votes among these census blocks proportional to population, such that you would have 16.6, 33.3, and 50 votes recorded at the block level for each candidate, respectively.

The more difficult version: Same facts, but now there is a 4th block that is split between precincts. So there has to be some sort of way to acknowledge these blocks and split them, likely in an arbitrary way between the portion within the precinct and without (e.g., 50-50 or by land area within each precinct)

I wouldn't impose upon you to actually write code, but if I could be directed toward the most relevant functions (or told to go play around in ArcGIS) it would be incredibly helpful.

Best regards,

Sean


From edzer@pebe@m@ @end|ng |rom un|-muen@ter@de  Thu Oct 14 12:58:27 2021
From: edzer@pebe@m@ @end|ng |rom un|-muen@ter@de (Edzer Pebesma)
Date: Thu, 14 Oct 2021 12:58:27 +0200
Subject: [R-sig-Geo] Aggregation and disaggregation in sf
In-Reply-To: <BLAPR20MB39386D1190AF7B6E67FE49C1BEB89@BLAPR20MB3938.namprd20.prod.outlook.com>
References: <BLAPR20MB39386D1190AF7B6E67FE49C1BEB89@BLAPR20MB3938.namprd20.prod.outlook.com>
Message-ID: <8e98d55e-abc7-ef17-fb71-14e83a39e571@uni-muenster.de>

I'm not so familiar with the terminology you use, but the function you'd 
most likely want to look into is st_interpolate_aw().

On 14/10/2021 12:11, Sean Trende wrote:
> Thank you all for developing this package and taking a huge amount of time to answer questions.  I had a question that I found related answers to, but nothing directly on point.  Perhaps I'm just not being sufficiently creative with my R coding, and I apologize if I missed the "explainer" elsewhere.
> 
> A common task is aggregating and disaggregating within a larger polygon set.  I believe that I know how to do the following in the geomander package, but am wondering if there is a "pure" sf solution.
> 
> There is a simple version of the task, and a more complex one.
> 
> The simple version of task: You have two shapefiles, one of census blocks and one of precinct results. You have a polygon for a precinct that split 100 votes to 100 votes for candidates A and B in the preceding election. The precinct wholly contains three census blocks with respective populations of 100, 200 and 300.
> 
> The task is to identify those blocks that exist within the precinct from the broader block shapefile and then to apportion the votes among these census blocks proportional to population, such that you would have 16.6, 33.3, and 50 votes recorded at the block level for each candidate, respectively.
> 
> The more difficult version: Same facts, but now there is a 4th block that is split between precincts. So there has to be some sort of way to acknowledge these blocks and split them, likely in an arbitrary way between the portion within the precinct and without (e.g., 50-50 or by land area within each precinct)
> 
> I wouldn't impose upon you to actually write code, but if I could be directed toward the most relevant functions (or told to go play around in ArcGIS) it would be incredibly helpful.
> 
> Best regards,
> 
> Sean
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48151 Muenster, Germany
Phone: +49 251 8333081


From @trende @end|ng |rom re@|c|e@rpo||t|c@@com  Sat Oct 16 12:51:01 2021
From: @trende @end|ng |rom re@|c|e@rpo||t|c@@com (Sean Trende)
Date: Sat, 16 Oct 2021 10:51:01 +0000
Subject: [R-sig-Geo] Aggregation and disaggregation in sf
In-Reply-To: <8e98d55e-abc7-ef17-fb71-14e83a39e571@uni-muenster.de>
References: <BLAPR20MB39386D1190AF7B6E67FE49C1BEB89@BLAPR20MB3938.namprd20.prod.outlook.com>
 <8e98d55e-abc7-ef17-fb71-14e83a39e571@uni-muenster.de>
Message-ID: <BLAPR20MB393828352331EAA59D7B22ACBEBA9@BLAPR20MB3938.namprd20.prod.outlook.com>

Apologies for the Americanisms!  But thank you for this answer and all that you do. It works great.

-----Original Message-----
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> On Behalf Of Edzer Pebesma
Sent: Thursday, October 14, 2021 6:58 AM
To: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] Aggregation and disaggregation in sf

I'm not so familiar with the terminology you use, but the function you'd most likely want to look into is st_interpolate_aw().

On 14/10/2021 12:11, Sean Trende wrote:
> Thank you all for developing this package and taking a huge amount of time to answer questions.  I had a question that I found related answers to, but nothing directly on point.  Perhaps I'm just not being sufficiently creative with my R coding, and I apologize if I missed the "explainer" elsewhere.
> 
> A common task is aggregating and disaggregating within a larger polygon set.  I believe that I know how to do the following in the geomander package, but am wondering if there is a "pure" sf solution.
> 
> There is a simple version of the task, and a more complex one.
> 
> The simple version of task: You have two shapefiles, one of census blocks and one of precinct results. You have a polygon for a precinct that split 100 votes to 100 votes for candidates A and B in the preceding election. The precinct wholly contains three census blocks with respective populations of 100, 200 and 300.
> 
> The task is to identify those blocks that exist within the precinct from the broader block shapefile and then to apportion the votes among these census blocks proportional to population, such that you would have 16.6, 33.3, and 50 votes recorded at the block level for each candidate, respectively.
> 
> The more difficult version: Same facts, but now there is a 4th block 
> that is split between precincts. So there has to be some sort of way 
> to acknowledge these blocks and split them, likely in an arbitrary way 
> between the portion within the precinct and without (e.g., 50-50 or by 
> land area within each precinct)
> 
> I wouldn't impose upon you to actually write code, but if I could be directed toward the most relevant functions (or told to go play around in ArcGIS) it would be incredibly helpful.
> 
> Best regards,
> 
> Sean
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

--
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48151 Muenster, Germany
Phone: +49 251 8333081

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From j|n||68 @end|ng |rom gm@||@com  Mon Oct 18 08:07:04 2021
From: j|n||68 @end|ng |rom gm@||@com (Jin Li)
Date: Mon, 18 Oct 2021 17:07:04 +1100
Subject: [R-sig-Geo] spm2: a new package for spatial predictive modelling
Message-ID: <CAGu_3ZKuCBwbbBF2sAzbo4Mu9MPj_WLNA0tAtq9VEFdUbHH3eA@mail.gmail.com>

Dear all,

A new package, spm2_1.1.0, for spatial predictive modelling has just been
made available on CRAN. It is an updated and extended version of 'spm'
package, by introducing some further novel  functions for modern
statistical methods (i.e., generalised linear models, glmnet,   generalised
least squares), support vector machine, kriging methods (i.e., simple
kriging, universal kriging, block kriging, kriging with an external drift),
and novel  hybrid methods (228 hybrids plus numerous variants) of modern
statistical methods or   machine learning methods with mathematical and/or
univariate geostatistical methods for spatial predictive modelling. For
each method, two functions are provided, with one function for assessing
the predictive errors and accuracy of the method based on
cross-validation, and the other for generating spatial predictions. It also
contains a  couple of functions for data preparation and predictive
accuracy assessment.

Any feedback is welcome and appreciated.

Best regards,
-- 
Jin
------------------------------------------
Jin Li, PhD
Founder, Data2action, Australia
https://www.researchgate.net/profile/Jin_Li32
https://scholar.google.com/citations?user=Jeot53EAAAAJ&hl=en

	[[alternative HTML version deleted]]


From g@b|k|m01 @end|ng |rom gm@||@com  Wed Oct 20 15:20:45 2021
From: g@b|k|m01 @end|ng |rom gm@||@com (Gabriel Cotlier)
Date: Wed, 20 Oct 2021 16:20:45 +0300
Subject: [R-sig-Geo] question on raster Moran's I statistical significance
Message-ID: <CAAKwTDHO1rah2NX+z2p83kdypX+XHt=4fYSXT=SJixM=iGJUaA@mail.gmail.com>

Hello,

I would like to estimate the Moran's *I* coefficient for raster data and
together with the statical significance of the spatial autocorrelation
obtained.

I found that the raster package function Moran() although calculates the
spatial autocorrelation index it apparently does not give directly the
statical significance of the results obtained :
https://search.r-project.org/CRAN/refmans/raster/html/autocor.html

Could it be be possible to obtain the statistical significance of the
results with either raster package or similar one?

Thanks a lot.
Kind regards,
Gabriel

	[[alternative HTML version deleted]]


From Roger@B|v@nd @end|ng |rom nhh@no  Wed Oct 20 19:42:28 2021
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Wed, 20 Oct 2021 19:42:28 +0200 (CEST)
Subject: [R-sig-Geo] 
 question on raster Moran's I statistical significance
In-Reply-To: <CAAKwTDHO1rah2NX+z2p83kdypX+XHt=4fYSXT=SJixM=iGJUaA@mail.gmail.com>
References: <CAAKwTDHO1rah2NX+z2p83kdypX+XHt=4fYSXT=SJixM=iGJUaA@mail.gmail.com>
Message-ID: <91dcba60-909f-ed29-1f4-f39c63a60@reclus2.nhh.no>

On Wed, 20 Oct 2021, Gabriel Cotlier wrote:

> Hello,
>
> I would like to estimate the Moran's *I* coefficient for raster data and
> together with the statical significance of the spatial autocorrelation
> obtained.
>
> I found that the raster package function Moran() although calculates the
> spatial autocorrelation index it apparently does not give directly the
> statical significance of the results obtained :
> https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
>
> Could it be be possible to obtain the statistical significance of the
> results with either raster package or similar one?

fortunes::fortune("This is R")


library(raster)
r <- raster(nrows=10, ncols=10)
values(r) <- 1:ncell(r)
f <- matrix(c(0,1,0,1,0,1,0,1,0), nrow=3)
(rI <- Moran(r, f))
r1 <- r
nsim <- 499
res <- numeric(nsim)
set.seed(1)
for (i in 1:nsim) {
   values(r1) <- values(r)[sample(prod(dim(r)))]
   res[i] <- Moran(r1, f)
}

Hope-type tests date back to Cliff and Ord; they are permutation 
bootstraps.

r_g <- as(r, "SpatialPixelsDataFrame")
library(spdep)
nb <- poly2nb(as(r_g, "SpatialPolygons"), queen=FALSE)
set.seed(1)
o <- moran.mc(r_g$layer, nb2listw(nb, style="B"), nsim=nsim,
   return_boot=TRUE)
x_a <- range(c(o$t, o$t0, res, rI))
plot(density(o$t), xlim=x_a)
abline(v=o$t0)
lines(density(res), lty=2)
abline(v=rI, lty=2)

It is not immediately obvious from the code of raster::Moran() why it is 
different, possibly because of padding the edges of the raster and 
thus increasing the cell count.

For added speed, the bootstrap can be parallelized in both cases; polygon 
boundaries are perhaps not ideal.

Hope this clarifies. Always provide a reproducible example, never post 
HTML mail.

Roger Bivand

>
> Thanks a lot.
> Kind regards,
> Gabriel
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Emeritus Professor
Department of Economics, Norwegian School of Economics,
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From Roger@B|v@nd @end|ng |rom nhh@no  Wed Oct 20 19:45:01 2021
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Wed, 20 Oct 2021 19:45:01 +0200 (CEST)
Subject: [R-sig-Geo] 
 question on raster Moran's I statistical significance
In-Reply-To: <CAAKwTDHO1rah2NX+z2p83kdypX+XHt=4fYSXT=SJixM=iGJUaA@mail.gmail.com>
References: <CAAKwTDHO1rah2NX+z2p83kdypX+XHt=4fYSXT=SJixM=iGJUaA@mail.gmail.com>
Message-ID: <3e639398-e137-5546-1848-5a3afb809240@reclus2.nhh.no>

On Wed, 20 Oct 2021, Gabriel Cotlier wrote:

> Hello,
>
> I would like to estimate the Moran's *I* coefficient for raster data and
> together with the statical significance of the spatial autocorrelation
> obtained.
>
> I found that the raster package function Moran() although calculates the
> spatial autocorrelation index it apparently does not give directly the
> statical significance of the results obtained :
> https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
>
> Could it be be possible to obtain the statistical significance of the
> results with either raster package or similar one?


fortunes::fortune("This is R")


library(raster)
r <- raster(nrows=10, ncols=10)
values(r) <- 1:ncell(r)
f <- matrix(c(0,1,0,1,0,1,0,1,0), nrow=3)
(rI <- Moran(r, f))
r1 <- r
nsim <- 499
res <- numeric(nsim)
set.seed(1)
for (i in 1:nsim) {
   values(r1) <- values(r)[sample(prod(dim(r)))]
   res[i] <- Moran(r1, f)
}

Hope-type tests date back to Cliff and Ord; they are permutation 
bootstraps.

r_g <- as(r, "SpatialPixelsDataFrame")
library(spdep)
nb <- poly2nb(as(r_g, "SpatialPolygons"), queen=FALSE)
set.seed(1)
o <- moran.mc(r_g$layer, nb2listw(nb, style="B"), nsim=nsim,
   return_boot=TRUE)
x_a <- range(c(o$t, o$t0, res, rI))
plot(density(o$t), xlim=x_a)
abline(v=o$t0)
lines(density(res), lty=2)
abline(v=rI, lty=2)

It is not immediately obvious from the code of raster::Moran() why it is
different, possibly because of padding the edges of the raster and thus
increasing the cell count.

For added speed, the bootstrap can be parallelized in both cases; polygon
boundaries are perhaps not ideal.

Hope this clarifies. Always provide a reproducible example, never post 
HTML
mail.

Roger Bivand


>
> Thanks a lot.
> Kind regards,
> Gabriel
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Emeritus Professor
Department of Economics, Norwegian School of Economics,
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From g@b|k|m01 @end|ng |rom gm@||@com  Thu Oct 21 07:36:51 2021
From: g@b|k|m01 @end|ng |rom gm@||@com (Gabriel Cotlier)
Date: Thu, 21 Oct 2021 08:36:51 +0300
Subject: [R-sig-Geo] 
 question on raster Moran's I statistical significance
In-Reply-To: <3e639398-e137-5546-1848-5a3afb809240@reclus2.nhh.no>
References: <CAAKwTDHO1rah2NX+z2p83kdypX+XHt=4fYSXT=SJixM=iGJUaA@mail.gmail.com>
 <3e639398-e137-5546-1848-5a3afb809240@reclus2.nhh.no>
Message-ID: <CAAKwTDHmsathQr3nZLZPwtE++t91oOD_bvdV8DpG-4uO4hjxyA@mail.gmail.com>

Hello

Thank you very much.
I have large raster layers and would like to ask, in order to reduce the
processing time of the simulation, choosing a smaller nsim value could help
? and if so, what could be the minimum nsim value recommended?
Thanks a lot again.
Kind regards,


On Wed, Oct 20, 2021 at 8:45 PM Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Wed, 20 Oct 2021, Gabriel Cotlier wrote:
>
> > Hello,
> >
> > I would like to estimate the Moran's *I* coefficient for raster data and
> > together with the statical significance of the spatial autocorrelation
> > obtained.
> >
> > I found that the raster package function Moran() although calculates the
> > spatial autocorrelation index it apparently does not give directly the
> > statical significance of the results obtained :
> > https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
> >
> > Could it be be possible to obtain the statistical significance of the
> > results with either raster package or similar one?
>
>
> fortunes::fortune("This is R")
>
>
> library(raster)
> r <- raster(nrows=10, ncols=10)
> values(r) <- 1:ncell(r)
> f <- matrix(c(0,1,0,1,0,1,0,1,0), nrow=3)
> (rI <- Moran(r, f))
> r1 <- r
> nsim <- 499
> res <- numeric(nsim)
> set.seed(1)
> for (i in 1:nsim) {
>    values(r1) <- values(r)[sample(prod(dim(r)))]
>    res[i] <- Moran(r1, f)
> }
>
> Hope-type tests date back to Cliff and Ord; they are permutation
> bootstraps.
>
> r_g <- as(r, "SpatialPixelsDataFrame")
> library(spdep)
> nb <- poly2nb(as(r_g, "SpatialPolygons"), queen=FALSE)
> set.seed(1)
> o <- moran.mc(r_g$layer, nb2listw(nb, style="B"), nsim=nsim,
>    return_boot=TRUE)
> x_a <- range(c(o$t, o$t0, res, rI))
> plot(density(o$t), xlim=x_a)
> abline(v=o$t0)
> lines(density(res), lty=2)
> abline(v=rI, lty=2)
>
> It is not immediately obvious from the code of raster::Moran() why it is
> different, possibly because of padding the edges of the raster and thus
> increasing the cell count.
>
> For added speed, the bootstrap can be parallelized in both cases; polygon
> boundaries are perhaps not ideal.
>
> Hope this clarifies. Always provide a reproducible example, never post
> HTML
> mail.
>
> Roger Bivand
>
>
> >
> > Thanks a lot.
> > Kind regards,
> > Gabriel
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Roger Bivand
> Emeritus Professor
> Department of Economics, Norwegian School of Economics,
> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
> e-mail: Roger.Bivand at nhh.no
> https://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>


-- 
Gabriel Cotlier, PhD
Haifa Research Center for Theoretical Physics and Astrophysics (HCTPA)
University of Haifa
Israel

	[[alternative HTML version deleted]]


From Roger@B|v@nd @end|ng |rom nhh@no  Thu Oct 21 10:40:18 2021
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Thu, 21 Oct 2021 10:40:18 +0200 (CEST)
Subject: [R-sig-Geo] 
 question on raster Moran's I statistical significance
In-Reply-To: <CAAKwTDHmsathQr3nZLZPwtE++t91oOD_bvdV8DpG-4uO4hjxyA@mail.gmail.com>
References: <CAAKwTDHO1rah2NX+z2p83kdypX+XHt=4fYSXT=SJixM=iGJUaA@mail.gmail.com>
 <3e639398-e137-5546-1848-5a3afb809240@reclus2.nhh.no>
 <CAAKwTDHmsathQr3nZLZPwtE++t91oOD_bvdV8DpG-4uO4hjxyA@mail.gmail.com>
Message-ID: <895fb754-b644-5543-d213-228764873fc5@reclus2.nhh.no>

On Thu, 21 Oct 2021, Gabriel Cotlier wrote:

> Hello
>
> Thank you very much.
> I have large raster layers and would like to ask, in order to reduce the
> processing time of the simulation, choosing a smaller nsim value could help
> ? and if so, what could be the minimum nsim value recommended?

If you examine the code, you see that raster::Moran() always performs 
multiple raster::focal() calls, effectively constructing the spatial 
weights on each run. The problem is not nsim, it is the way that 
raster::Moran() is constructed.

Indeed, using a Hope-type test gives the same inferential outcome as using 
asymptotic methods for global tests for spatial autocorrelation, and is 
superfluous, but no other approach is feasible for raster::Moran() (which 
by the way only seems to use 4 neighbours although claiming it uses 8).

1. How large is large?

It is possible to generate nb neighbour objects for large data sets, 
making the use of spdep::moran.test() feasible, certainly for tens of 
thousands of observations (all the census tracts in coterminous US, for 
example).

This uses distances between raster cell centres to find neighbours:

> library(spdep)
Loading required package: sp
Loading required package: spData
Loading required package: sf
Linking to GEOS 3.10.0, GDAL 3.3.2, PROJ 8.1.1
> crds <- expand.grid(x=1:800, y=1:1200)
> dim(crds)
[1] 960000      2
> grd <- st_as_sf(crds, coords=c("x", "y"))
> grd$z <- runif(nrow(grd))
> system.time(dnbr <- dnearneigh(grd, 0, 1.01))
    user  system elapsed
  30.065   0.235  30.381
> dnbr
Neighbour list object:
Number of regions: 960000
Number of nonzero links: 3836000
Percentage nonzero weights: 0.0004162326
Average number of links: 3.995833
> system.time(dnbq <- dnearneigh(grd, 0, 1.42))
    user  system elapsed
  54.502   0.080  54.699
> dnbq
Neighbour list object:
Number of regions: 960000
Number of nonzero links: 7668004
Percentage nonzero weights: 0.0008320317
Average number of links: 7.987504

Once the neighbour objects are ready, conversion to spatial weights 
objects takes some time, and computing I with a constant mean model 
depends on the numbers of neighbours:

> system.time(lwr <- nb2listw(dnbr, style="B"))
    user  system elapsed
   6.694   0.000   6.722
> system.time(Ir <- moran.test(grd$z, lwr))
    user  system elapsed
  24.371   0.000  24.470
> Ir

 	Moran I test under randomisation

data:  grd$z
weights: lwr

Moran I statistic standard deviate = -0.06337, p-value = 0.5253
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance
     -4.679899e-05     -1.041668e-06      5.213749e-07

> system.time(lwq <- nb2listw(dnbq, style="B"))
    user  system elapsed
   6.804   0.000   6.828
> system.time(Iq <- moran.test(grd$z, lwq))
    user  system elapsed
  46.703   0.012  46.843
> Iq

 	Moran I test under randomisation

data:  grd$z
weights: lwq

Moran I statistic standard deviate = -0.70373, p-value = 0.7592
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance
     -3.604417e-04     -1.041668e-06      2.608222e-07

2. The larger your N, the less likely that the test means anything at all, 
because the assumption is that the observed entities are not simply 
arbitrary products of, say, resolution.

If you think of global Moran's I as a specification test of a regression 
of the variable of interest on the constant (the mean model is just the 
constant), for raster data the resolution controls the outcome 
(downscaling/upscaling will shift Moran's I). If you include covariates, 
patterning in the residuals of a richer model may well abate.

Hope this clarifies,

Roger

> Thanks a lot again.
> Kind regards,
>
>
> On Wed, Oct 20, 2021 at 8:45 PM Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Wed, 20 Oct 2021, Gabriel Cotlier wrote:
>>
>>> Hello,
>>>
>>> I would like to estimate the Moran's *I* coefficient for raster data and
>>> together with the statical significance of the spatial autocorrelation
>>> obtained.
>>>
>>> I found that the raster package function Moran() although calculates the
>>> spatial autocorrelation index it apparently does not give directly the
>>> statical significance of the results obtained :
>>> https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
>>>
>>> Could it be be possible to obtain the statistical significance of the
>>> results with either raster package or similar one?
>>
>>
>> fortunes::fortune("This is R")
>>
>>
>> library(raster)
>> r <- raster(nrows=10, ncols=10)
>> values(r) <- 1:ncell(r)
>> f <- matrix(c(0,1,0,1,0,1,0,1,0), nrow=3)
>> (rI <- Moran(r, f))
>> r1 <- r
>> nsim <- 499
>> res <- numeric(nsim)
>> set.seed(1)
>> for (i in 1:nsim) {
>>    values(r1) <- values(r)[sample(prod(dim(r)))]
>>    res[i] <- Moran(r1, f)
>> }
>>
>> Hope-type tests date back to Cliff and Ord; they are permutation
>> bootstraps.
>>
>> r_g <- as(r, "SpatialPixelsDataFrame")
>> library(spdep)
>> nb <- poly2nb(as(r_g, "SpatialPolygons"), queen=FALSE)
>> set.seed(1)
>> o <- moran.mc(r_g$layer, nb2listw(nb, style="B"), nsim=nsim,
>>    return_boot=TRUE)
>> x_a <- range(c(o$t, o$t0, res, rI))
>> plot(density(o$t), xlim=x_a)
>> abline(v=o$t0)
>> lines(density(res), lty=2)
>> abline(v=rI, lty=2)
>>
>> It is not immediately obvious from the code of raster::Moran() why it is
>> different, possibly because of padding the edges of the raster and thus
>> increasing the cell count.
>>
>> For added speed, the bootstrap can be parallelized in both cases; polygon
>> boundaries are perhaps not ideal.
>>
>> Hope this clarifies. Always provide a reproducible example, never post
>> HTML
>> mail.
>>
>> Roger Bivand
>>
>>
>>>
>>> Thanks a lot.
>>> Kind regards,
>>> Gabriel
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Emeritus Professor
>> Department of Economics, Norwegian School of Economics,
>> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
>> e-mail: Roger.Bivand at nhh.no
>> https://orcid.org/0000-0003-2392-6140
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>
>
>
>

-- 
Roger Bivand
Emeritus Professor
Department of Economics, Norwegian School of Economics,
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From g@b|k|m01 @end|ng |rom gm@||@com  Thu Oct 21 12:13:36 2021
From: g@b|k|m01 @end|ng |rom gm@||@com (Gabriel Cotlier)
Date: Thu, 21 Oct 2021 13:13:36 +0300
Subject: [R-sig-Geo] 
 question on raster Moran's I statistical significance
In-Reply-To: <895fb754-b644-5543-d213-228764873fc5@reclus2.nhh.no>
References: <CAAKwTDHO1rah2NX+z2p83kdypX+XHt=4fYSXT=SJixM=iGJUaA@mail.gmail.com>
 <3e639398-e137-5546-1848-5a3afb809240@reclus2.nhh.no>
 <CAAKwTDHmsathQr3nZLZPwtE++t91oOD_bvdV8DpG-4uO4hjxyA@mail.gmail.com>
 <895fb754-b644-5543-d213-228764873fc5@reclus2.nhh.no>
Message-ID: <CAAKwTDH-=WDeDUbbMfzUFs5qYXV8S+Xoq3D=tEWT9bX669Z2fg@mail.gmail.com>

Hello
Thanks a lot.
Indeed your explanation makes it much more clear.
Kind regards,


On Thu, Oct 21, 2021 at 11:40 AM Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Thu, 21 Oct 2021, Gabriel Cotlier wrote:
>
> > Hello
> >
> > Thank you very much.
> > I have large raster layers and would like to ask, in order to reduce the
> > processing time of the simulation, choosing a smaller nsim value could
> help
> > ? and if so, what could be the minimum nsim value recommended?
>
> If you examine the code, you see that raster::Moran() always performs
> multiple raster::focal() calls, effectively constructing the spatial
> weights on each run. The problem is not nsim, it is the way that
> raster::Moran() is constructed.
>
> Indeed, using a Hope-type test gives the same inferential outcome as using
> asymptotic methods for global tests for spatial autocorrelation, and is
> superfluous, but no other approach is feasible for raster::Moran() (which
> by the way only seems to use 4 neighbours although claiming it uses 8).
>
> 1. How large is large?
>
> It is possible to generate nb neighbour objects for large data sets,
> making the use of spdep::moran.test() feasible, certainly for tens of
> thousands of observations (all the census tracts in coterminous US, for
> example).
>
> This uses distances between raster cell centres to find neighbours:
>
> > library(spdep)
> Loading required package: sp
> Loading required package: spData
> Loading required package: sf
> Linking to GEOS 3.10.0, GDAL 3.3.2, PROJ 8.1.1
> > crds <- expand.grid(x=1:800, y=1:1200)
> > dim(crds)
> [1] 960000      2
> > grd <- st_as_sf(crds, coords=c("x", "y"))
> > grd$z <- runif(nrow(grd))
> > system.time(dnbr <- dnearneigh(grd, 0, 1.01))
>     user  system elapsed
>   30.065   0.235  30.381
> > dnbr
> Neighbour list object:
> Number of regions: 960000
> Number of nonzero links: 3836000
> Percentage nonzero weights: 0.0004162326
> Average number of links: 3.995833
> > system.time(dnbq <- dnearneigh(grd, 0, 1.42))
>     user  system elapsed
>   54.502   0.080  54.699
> > dnbq
> Neighbour list object:
> Number of regions: 960000
> Number of nonzero links: 7668004
> Percentage nonzero weights: 0.0008320317
> Average number of links: 7.987504
>
> Once the neighbour objects are ready, conversion to spatial weights
> objects takes some time, and computing I with a constant mean model
> depends on the numbers of neighbours:
>
> > system.time(lwr <- nb2listw(dnbr, style="B"))
>     user  system elapsed
>    6.694   0.000   6.722
> > system.time(Ir <- moran.test(grd$z, lwr))
>     user  system elapsed
>   24.371   0.000  24.470
> > Ir
>
>         Moran I test under randomisation
>
> data:  grd$z
> weights: lwr
>
> Moran I statistic standard deviate = -0.06337, p-value = 0.5253
> alternative hypothesis: greater
> sample estimates:
> Moran I statistic       Expectation          Variance
>      -4.679899e-05     -1.041668e-06      5.213749e-07
>
> > system.time(lwq <- nb2listw(dnbq, style="B"))
>     user  system elapsed
>    6.804   0.000   6.828
> > system.time(Iq <- moran.test(grd$z, lwq))
>     user  system elapsed
>   46.703   0.012  46.843
> > Iq
>
>         Moran I test under randomisation
>
> data:  grd$z
> weights: lwq
>
> Moran I statistic standard deviate = -0.70373, p-value = 0.7592
> alternative hypothesis: greater
> sample estimates:
> Moran I statistic       Expectation          Variance
>      -3.604417e-04     -1.041668e-06      2.608222e-07
>
> 2. The larger your N, the less likely that the test means anything at all,
> because the assumption is that the observed entities are not simply
> arbitrary products of, say, resolution.
>
> If you think of global Moran's I as a specification test of a regression
> of the variable of interest on the constant (the mean model is just the
> constant), for raster data the resolution controls the outcome
> (downscaling/upscaling will shift Moran's I). If you include covariates,
> patterning in the residuals of a richer model may well abate.
>
> Hope this clarifies,
>
> Roger
>
> > Thanks a lot again.
> > Kind regards,
> >
> >
> > On Wed, Oct 20, 2021 at 8:45 PM Roger Bivand <Roger.Bivand at nhh.no>
> wrote:
> >
> >> On Wed, 20 Oct 2021, Gabriel Cotlier wrote:
> >>
> >>> Hello,
> >>>
> >>> I would like to estimate the Moran's *I* coefficient for raster data
> and
> >>> together with the statical significance of the spatial autocorrelation
> >>> obtained.
> >>>
> >>> I found that the raster package function Moran() although calculates
> the
> >>> spatial autocorrelation index it apparently does not give directly the
> >>> statical significance of the results obtained :
> >>> https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
> >>>
> >>> Could it be be possible to obtain the statistical significance of the
> >>> results with either raster package or similar one?
> >>
> >>
> >> fortunes::fortune("This is R")
> >>
> >>
> >> library(raster)
> >> r <- raster(nrows=10, ncols=10)
> >> values(r) <- 1:ncell(r)
> >> f <- matrix(c(0,1,0,1,0,1,0,1,0), nrow=3)
> >> (rI <- Moran(r, f))
> >> r1 <- r
> >> nsim <- 499
> >> res <- numeric(nsim)
> >> set.seed(1)
> >> for (i in 1:nsim) {
> >>    values(r1) <- values(r)[sample(prod(dim(r)))]
> >>    res[i] <- Moran(r1, f)
> >> }
> >>
> >> Hope-type tests date back to Cliff and Ord; they are permutation
> >> bootstraps.
> >>
> >> r_g <- as(r, "SpatialPixelsDataFrame")
> >> library(spdep)
> >> nb <- poly2nb(as(r_g, "SpatialPolygons"), queen=FALSE)
> >> set.seed(1)
> >> o <- moran.mc(r_g$layer, nb2listw(nb, style="B"), nsim=nsim,
> >>    return_boot=TRUE)
> >> x_a <- range(c(o$t, o$t0, res, rI))
> >> plot(density(o$t), xlim=x_a)
> >> abline(v=o$t0)
> >> lines(density(res), lty=2)
> >> abline(v=rI, lty=2)
> >>
> >> It is not immediately obvious from the code of raster::Moran() why it is
> >> different, possibly because of padding the edges of the raster and thus
> >> increasing the cell count.
> >>
> >> For added speed, the bootstrap can be parallelized in both cases;
> polygon
> >> boundaries are perhaps not ideal.
> >>
> >> Hope this clarifies. Always provide a reproducible example, never post
> >> HTML
> >> mail.
> >>
> >> Roger Bivand
> >>
> >>
> >>>
> >>> Thanks a lot.
> >>> Kind regards,
> >>> Gabriel
> >>>
> >>>       [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-Geo mailing list
> >>> R-sig-Geo at r-project.org
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>>
> >>
> >> --
> >> Roger Bivand
> >> Emeritus Professor
> >> Department of Economics, Norwegian School of Economics,
> >> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
> >> e-mail: Roger.Bivand at nhh.no
> >> https://orcid.org/0000-0003-2392-6140
> >> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
> >>
> >
> >
> >
>
> --
> Roger Bivand
> Emeritus Professor
> Department of Economics, Norwegian School of Economics,
> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
> e-mail: Roger.Bivand at nhh.no
> https://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>


-- 
Gabriel Cotlier, PhD
Haifa Research Center for Theoretical Physics and Astrophysics (HCTPA)
University of Haifa
Israel

	[[alternative HTML version deleted]]


From g@b|k|m01 @end|ng |rom gm@||@com  Thu Oct 21 13:43:33 2021
From: g@b|k|m01 @end|ng |rom gm@||@com (Gabriel Cotlier)
Date: Thu, 21 Oct 2021 14:43:33 +0300
Subject: [R-sig-Geo] R-sig-Geo Digest, Vol 218, Issue 10
In-Reply-To: <CAGL-CGBiqTBDYGGKfQUGAChbOFvU9zeEycR69aKFm7btMj4+_g@mail.gmail.com>
References: <mailman.28802.3.1634810401.24542.r-sig-geo@r-project.org>
 <CAGL-CGBiqTBDYGGKfQUGAChbOFvU9zeEycR69aKFm7btMj4+_g@mail.gmail.com>
Message-ID: <CAAKwTDFMnNQYnxeNhnTa6M-CAhoQfzVuA2ZvrcVOTQFKB1KK-Q@mail.gmail.com>

Hello Babak,
Thanks. a lot.
Yes, elsa::moran() is indeed faster than raster::Moran() as I saw in your
code; however I have nan values in my raster layer which are rivers of
other geographic features which aren't relevant thus were converted to nan
not to influence the results.
Does there exist a way to make elsa::moran() to work with a raster layer
with nan values?
Thanks a lot again.
Kind regards,
Gabriel

On Thu, Oct 21, 2021 at 1:52 PM Babak Naimi <naimi.b at gmail.com> wrote:

> Hi Gabriel,
>
> You may also use the package elsa to calculate moran (and other spatial
> autocorrelation statistics) for raster data that is quite fast given the
> implementation of the functions in C.
>
> The equivalent function in the new package terra is also faster than the
> one in the raster:
>
>
> > r <- raster(xmn=0, nrows=100, ncols=100)
> > values(r) <- 1:ncell(r)
> > f <- matrix(c(0,1,0,1,0,1,0,1,0), nrow=3)
>
> > system.time(m1 <- raster::Moran(r, f))
>    user  system elapsed
>   0.142   0.001   0.143
> > system.time(m2 <- elsa::moran(r, d1=0,d2=xres(r)))
>    user  system elapsed
>   0.002   0.000   0.002
>
> > rr <- terra::rast(r)
> > system.time(m3 <- terra::autocor(rr, f))
>    user  system elapsed
>   0.022   0.001   0.022
>
> > 0.143 / 0.022
> [1] 6.5.  # terra is 6.5X faster than raster
> > 0.143 / 0.001
> [1] 143 # elsa is 143X faster than raster
> > 0.022 / 0.001
> [1] 22 # elsa is 22X faster than terra
>
> > c(raster=m1, terra=m2, elsa=m3)
>     raster      terra         elsa
>   0.989899   0.989899   0.989899
>
> Hope this helps,
> Cheers,
> Babak
>
>
>
> On Thu, Oct 21, 2021 at 11:01 AM <r-sig-geo-request at r-project.org> wrote:
>
>> Send R-sig-Geo mailing list submissions to
>>         r-sig-geo at r-project.org
>>
>> To subscribe or unsubscribe via the World Wide Web, visit
>>         https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> or, via email, send a message with subject or body 'help' to
>>         r-sig-geo-request at r-project.org
>>
>> You can reach the person managing the list at
>>         r-sig-geo-owner at r-project.org
>>
>> When replying, please edit your Subject line so it is more specific
>> than "Re: Contents of R-sig-Geo digest..."
>>
>>
>> Today's Topics:
>>
>>    1. question on raster Moran's I statistical significance
>>       (Gabriel Cotlier)
>>    2. Re:  question on raster Moran's I statistical significance
>>       (Roger Bivand)
>>    3. Re:  question on raster Moran's I statistical significance
>>       (Roger Bivand)
>>    4. Re:  question on raster Moran's I statistical significance
>>       (Gabriel Cotlier)
>>    5. Re:  question on raster Moran's I statistical significance
>>       (Roger Bivand)
>>
>> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Wed, 20 Oct 2021 16:20:45 +0300
>> From: Gabriel Cotlier <gabiklm01 at gmail.com>
>> To: r-sig-geo <r-sig-geo at r-project.org>
>> Subject: [R-sig-Geo] question on raster Moran's I statistical
>>         significance
>> Message-ID:
>>         <CAAKwTDHO1rah2NX+z2p83kdypX+XHt=4fYSXT=SJixM=
>> iGJUaA at mail.gmail.com>
>> Content-Type: text/plain; charset="utf-8"
>>
>> Hello,
>>
>> I would like to estimate the Moran's *I* coefficient for raster data and
>> together with the statical significance of the spatial autocorrelation
>> obtained.
>>
>> I found that the raster package function Moran() although calculates the
>> spatial autocorrelation index it apparently does not give directly the
>> statical significance of the results obtained :
>> https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
>>
>> Could it be be possible to obtain the statistical significance of the
>> results with either raster package or similar one?
>>
>> Thanks a lot.
>> Kind regards,
>> Gabriel
>>
>>         [[alternative HTML version deleted]]
>>
>>
>>
>>
>> ------------------------------
>>
>> Message: 2
>> Date: Wed, 20 Oct 2021 19:42:28 +0200 (CEST)
>> From: Roger Bivand <Roger.Bivand at nhh.no>
>> To: Gabriel Cotlier <gabiklm01 at gmail.com>
>> Cc: r-sig-geo <r-sig-geo at r-project.org>
>> Subject: Re: [R-sig-Geo]  question on raster Moran's I statistical
>>         significance
>> Message-ID: <91dcba60-909f-ed29-1f4-f39c63a60 at reclus2.nhh.no>
>> Content-Type: text/plain; charset="us-ascii"; Format="flowed"
>>
>> On Wed, 20 Oct 2021, Gabriel Cotlier wrote:
>>
>> > Hello,
>> >
>> > I would like to estimate the Moran's *I* coefficient for raster data and
>> > together with the statical significance of the spatial autocorrelation
>> > obtained.
>> >
>> > I found that the raster package function Moran() although calculates the
>> > spatial autocorrelation index it apparently does not give directly the
>> > statical significance of the results obtained :
>> > https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
>> >
>> > Could it be be possible to obtain the statistical significance of the
>> > results with either raster package or similar one?
>>
>> fortunes::fortune("This is R")
>>
>>
>> library(raster)
>> r <- raster(nrows=10, ncols=10)
>> values(r) <- 1:ncell(r)
>> f <- matrix(c(0,1,0,1,0,1,0,1,0), nrow=3)
>> (rI <- Moran(r, f))
>> r1 <- r
>> nsim <- 499
>> res <- numeric(nsim)
>> set.seed(1)
>> for (i in 1:nsim) {
>>    values(r1) <- values(r)[sample(prod(dim(r)))]
>>    res[i] <- Moran(r1, f)
>> }
>>
>> Hope-type tests date back to Cliff and Ord; they are permutation
>> bootstraps.
>>
>> r_g <- as(r, "SpatialPixelsDataFrame")
>> library(spdep)
>> nb <- poly2nb(as(r_g, "SpatialPolygons"), queen=FALSE)
>> set.seed(1)
>> o <- moran.mc(r_g$layer, nb2listw(nb, style="B"), nsim=nsim,
>>    return_boot=TRUE)
>> x_a <- range(c(o$t, o$t0, res, rI))
>> plot(density(o$t), xlim=x_a)
>> abline(v=o$t0)
>> lines(density(res), lty=2)
>> abline(v=rI, lty=2)
>>
>> It is not immediately obvious from the code of raster::Moran() why it is
>> different, possibly because of padding the edges of the raster and
>> thus increasing the cell count.
>>
>> For added speed, the bootstrap can be parallelized in both cases; polygon
>> boundaries are perhaps not ideal.
>>
>> Hope this clarifies. Always provide a reproducible example, never post
>> HTML mail.
>>
>> Roger Bivand
>>
>> >
>> > Thanks a lot.
>> > Kind regards,
>> > Gabriel
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-Geo mailing list
>> > R-sig-Geo at r-project.org
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >
>>
>> --
>> Roger Bivand
>> Emeritus Professor
>> Department of Economics, Norwegian School of Economics,
>> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
>> e-mail: Roger.Bivand at nhh.no
>> https://orcid.org/0000-0003-2392-6140
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>
>>
>>
>>
>> ------------------------------
>>
>> Message: 3
>> Date: Wed, 20 Oct 2021 19:45:01 +0200 (CEST)
>> From: Roger Bivand <Roger.Bivand at nhh.no>
>> To: Gabriel Cotlier <gabiklm01 at gmail.com>
>> Cc: r-sig-geo <r-sig-geo at r-project.org>
>> Subject: Re: [R-sig-Geo]  question on raster Moran's I statistical
>>         significance
>> Message-ID: <3e639398-e137-5546-1848-5a3afb809240 at reclus2.nhh.no>
>> Content-Type: text/plain; charset="us-ascii"; Format="flowed"
>>
>> On Wed, 20 Oct 2021, Gabriel Cotlier wrote:
>>
>> > Hello,
>> >
>> > I would like to estimate the Moran's *I* coefficient for raster data and
>> > together with the statical significance of the spatial autocorrelation
>> > obtained.
>> >
>> > I found that the raster package function Moran() although calculates the
>> > spatial autocorrelation index it apparently does not give directly the
>> > statical significance of the results obtained :
>> > https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
>> >
>> > Could it be be possible to obtain the statistical significance of the
>> > results with either raster package or similar one?
>>
>>
>> fortunes::fortune("This is R")
>>
>>
>> library(raster)
>> r <- raster(nrows=10, ncols=10)
>> values(r) <- 1:ncell(r)
>> f <- matrix(c(0,1,0,1,0,1,0,1,0), nrow=3)
>> (rI <- Moran(r, f))
>> r1 <- r
>> nsim <- 499
>> res <- numeric(nsim)
>> set.seed(1)
>> for (i in 1:nsim) {
>>    values(r1) <- values(r)[sample(prod(dim(r)))]
>>    res[i] <- Moran(r1, f)
>> }
>>
>> Hope-type tests date back to Cliff and Ord; they are permutation
>> bootstraps.
>>
>> r_g <- as(r, "SpatialPixelsDataFrame")
>> library(spdep)
>> nb <- poly2nb(as(r_g, "SpatialPolygons"), queen=FALSE)
>> set.seed(1)
>> o <- moran.mc(r_g$layer, nb2listw(nb, style="B"), nsim=nsim,
>>    return_boot=TRUE)
>> x_a <- range(c(o$t, o$t0, res, rI))
>> plot(density(o$t), xlim=x_a)
>> abline(v=o$t0)
>> lines(density(res), lty=2)
>> abline(v=rI, lty=2)
>>
>> It is not immediately obvious from the code of raster::Moran() why it is
>> different, possibly because of padding the edges of the raster and thus
>> increasing the cell count.
>>
>> For added speed, the bootstrap can be parallelized in both cases; polygon
>> boundaries are perhaps not ideal.
>>
>> Hope this clarifies. Always provide a reproducible example, never post
>> HTML
>> mail.
>>
>> Roger Bivand
>>
>>
>> >
>> > Thanks a lot.
>> > Kind regards,
>> > Gabriel
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-Geo mailing list
>> > R-sig-Geo at r-project.org
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >
>>
>> --
>> Roger Bivand
>> Emeritus Professor
>> Department of Economics, Norwegian School of Economics,
>> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
>> e-mail: Roger.Bivand at nhh.no
>> https://orcid.org/0000-0003-2392-6140
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>
>>
>>
>>
>> ------------------------------
>>
>> Message: 4
>> Date: Thu, 21 Oct 2021 08:36:51 +0300
>> From: Gabriel Cotlier <gabiklm01 at gmail.com>
>> To: Roger.Bivand at nhh.no
>> Cc: r-sig-geo <r-sig-geo at r-project.org>
>> Subject: Re: [R-sig-Geo]  question on raster Moran's I statistical
>>         significance
>> Message-ID:
>>         <
>> CAAKwTDHmsathQr3nZLZPwtE++t91oOD_bvdV8DpG-4uO4hjxyA at mail.gmail.com>
>> Content-Type: text/plain; charset="utf-8"
>>
>> Hello
>>
>> Thank you very much.
>> I have large raster layers and would like to ask, in order to reduce the
>> processing time of the simulation, choosing a smaller nsim value could
>> help
>> ? and if so, what could be the minimum nsim value recommended?
>> Thanks a lot again.
>> Kind regards,
>>
>>
>> On Wed, Oct 20, 2021 at 8:45 PM Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>
>> > On Wed, 20 Oct 2021, Gabriel Cotlier wrote:
>> >
>> > > Hello,
>> > >
>> > > I would like to estimate the Moran's *I* coefficient for raster data
>> and
>> > > together with the statical significance of the spatial autocorrelation
>> > > obtained.
>> > >
>> > > I found that the raster package function Moran() although calculates
>> the
>> > > spatial autocorrelation index it apparently does not give directly the
>> > > statical significance of the results obtained :
>> > > https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
>> > >
>> > > Could it be be possible to obtain the statistical significance of the
>> > > results with either raster package or similar one?
>> >
>> >
>> > fortunes::fortune("This is R")
>> >
>> >
>> > library(raster)
>> > r <- raster(nrows=10, ncols=10)
>> > values(r) <- 1:ncell(r)
>> > f <- matrix(c(0,1,0,1,0,1,0,1,0), nrow=3)
>> > (rI <- Moran(r, f))
>> > r1 <- r
>> > nsim <- 499
>> > res <- numeric(nsim)
>> > set.seed(1)
>> > for (i in 1:nsim) {
>> >    values(r1) <- values(r)[sample(prod(dim(r)))]
>> >    res[i] <- Moran(r1, f)
>> > }
>> >
>> > Hope-type tests date back to Cliff and Ord; they are permutation
>> > bootstraps.
>> >
>> > r_g <- as(r, "SpatialPixelsDataFrame")
>> > library(spdep)
>> > nb <- poly2nb(as(r_g, "SpatialPolygons"), queen=FALSE)
>> > set.seed(1)
>> > o <- moran.mc(r_g$layer, nb2listw(nb, style="B"), nsim=nsim,
>> >    return_boot=TRUE)
>> > x_a <- range(c(o$t, o$t0, res, rI))
>> > plot(density(o$t), xlim=x_a)
>> > abline(v=o$t0)
>> > lines(density(res), lty=2)
>> > abline(v=rI, lty=2)
>> >
>> > It is not immediately obvious from the code of raster::Moran() why it is
>> > different, possibly because of padding the edges of the raster and thus
>> > increasing the cell count.
>> >
>> > For added speed, the bootstrap can be parallelized in both cases;
>> polygon
>> > boundaries are perhaps not ideal.
>> >
>> > Hope this clarifies. Always provide a reproducible example, never post
>> > HTML
>> > mail.
>> >
>> > Roger Bivand
>> >
>> >
>> > >
>> > > Thanks a lot.
>> > > Kind regards,
>> > > Gabriel
>> > >
>> > >       [[alternative HTML version deleted]]
>> > >
>> > > _______________________________________________
>> > > R-sig-Geo mailing list
>> > > R-sig-Geo at r-project.org
>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> > >
>> >
>> > --
>> > Roger Bivand
>> > Emeritus Professor
>> > Department of Economics, Norwegian School of Economics,
>> > Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
>> > e-mail: Roger.Bivand at nhh.no
>> > https://orcid.org/0000-0003-2392-6140
>> > https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>> >
>>
>>
>> --
>> Gabriel Cotlier, PhD
>> Haifa Research Center for Theoretical Physics and Astrophysics (HCTPA)
>> University of Haifa
>> Israel
>>
>>         [[alternative HTML version deleted]]
>>
>>
>>
>>
>> ------------------------------
>>
>> Message: 5
>> Date: Thu, 21 Oct 2021 10:40:18 +0200 (CEST)
>> From: Roger Bivand <Roger.Bivand at nhh.no>
>> To: Gabriel Cotlier <gabiklm01 at gmail.com>
>> Cc: r-sig-geo <r-sig-geo at r-project.org>
>> Subject: Re: [R-sig-Geo]  question on raster Moran's I statistical
>>         significance
>> Message-ID: <895fb754-b644-5543-d213-228764873fc5 at reclus2.nhh.no>
>> Content-Type: text/plain; charset="us-ascii"; Format="flowed"
>>
>> On Thu, 21 Oct 2021, Gabriel Cotlier wrote:
>>
>> > Hello
>> >
>> > Thank you very much.
>> > I have large raster layers and would like to ask, in order to reduce the
>> > processing time of the simulation, choosing a smaller nsim value could
>> help
>> > ? and if so, what could be the minimum nsim value recommended?
>>
>> If you examine the code, you see that raster::Moran() always performs
>> multiple raster::focal() calls, effectively constructing the spatial
>> weights on each run. The problem is not nsim, it is the way that
>> raster::Moran() is constructed.
>>
>> Indeed, using a Hope-type test gives the same inferential outcome as
>> using
>> asymptotic methods for global tests for spatial autocorrelation, and is
>> superfluous, but no other approach is feasible for raster::Moran() (which
>> by the way only seems to use 4 neighbours although claiming it uses 8).
>>
>> 1. How large is large?
>>
>> It is possible to generate nb neighbour objects for large data sets,
>> making the use of spdep::moran.test() feasible, certainly for tens of
>> thousands of observations (all the census tracts in coterminous US, for
>> example).
>>
>> This uses distances between raster cell centres to find neighbours:
>>
>> > library(spdep)
>> Loading required package: sp
>> Loading required package: spData
>> Loading required package: sf
>> Linking to GEOS 3.10.0, GDAL 3.3.2, PROJ 8.1.1
>> > crds <- expand.grid(x=1:800, y=1:1200)
>> > dim(crds)
>> [1] 960000      2
>> > grd <- st_as_sf(crds, coords=c("x", "y"))
>> > grd$z <- runif(nrow(grd))
>> > system.time(dnbr <- dnearneigh(grd, 0, 1.01))
>>     user  system elapsed
>>   30.065   0.235  30.381
>> > dnbr
>> Neighbour list object:
>> Number of regions: 960000
>> Number of nonzero links: 3836000
>> Percentage nonzero weights: 0.0004162326
>> Average number of links: 3.995833
>> > system.time(dnbq <- dnearneigh(grd, 0, 1.42))
>>     user  system elapsed
>>   54.502   0.080  54.699
>> > dnbq
>> Neighbour list object:
>> Number of regions: 960000
>> Number of nonzero links: 7668004
>> Percentage nonzero weights: 0.0008320317
>> Average number of links: 7.987504
>>
>> Once the neighbour objects are ready, conversion to spatial weights
>> objects takes some time, and computing I with a constant mean model
>> depends on the numbers of neighbours:
>>
>> > system.time(lwr <- nb2listw(dnbr, style="B"))
>>     user  system elapsed
>>    6.694   0.000   6.722
>> > system.time(Ir <- moran.test(grd$z, lwr))
>>     user  system elapsed
>>   24.371   0.000  24.470
>> > Ir
>>
>>         Moran I test under randomisation
>>
>> data:  grd$z
>> weights: lwr
>>
>> Moran I statistic standard deviate = -0.06337, p-value = 0.5253
>> alternative hypothesis: greater
>> sample estimates:
>> Moran I statistic       Expectation          Variance
>>      -4.679899e-05     -1.041668e-06      5.213749e-07
>>
>> > system.time(lwq <- nb2listw(dnbq, style="B"))
>>     user  system elapsed
>>    6.804   0.000   6.828
>> > system.time(Iq <- moran.test(grd$z, lwq))
>>     user  system elapsed
>>   46.703   0.012  46.843
>> > Iq
>>
>>         Moran I test under randomisation
>>
>> data:  grd$z
>> weights: lwq
>>
>> Moran I statistic standard deviate = -0.70373, p-value = 0.7592
>> alternative hypothesis: greater
>> sample estimates:
>> Moran I statistic       Expectation          Variance
>>      -3.604417e-04     -1.041668e-06      2.608222e-07
>>
>> 2. The larger your N, the less likely that the test means anything at
>> all,
>> because the assumption is that the observed entities are not simply
>> arbitrary products of, say, resolution.
>>
>> If you think of global Moran's I as a specification test of a regression
>> of the variable of interest on the constant (the mean model is just the
>> constant), for raster data the resolution controls the outcome
>> (downscaling/upscaling will shift Moran's I). If you include covariates,
>> patterning in the residuals of a richer model may well abate.
>>
>> Hope this clarifies,
>>
>> Roger
>>
>> > Thanks a lot again.
>> > Kind regards,
>> >
>> >
>> > On Wed, Oct 20, 2021 at 8:45 PM Roger Bivand <Roger.Bivand at nhh.no>
>> wrote:
>> >
>> >> On Wed, 20 Oct 2021, Gabriel Cotlier wrote:
>> >>
>> >>> Hello,
>> >>>
>> >>> I would like to estimate the Moran's *I* coefficient for raster data
>> and
>> >>> together with the statical significance of the spatial autocorrelation
>> >>> obtained.
>> >>>
>> >>> I found that the raster package function Moran() although calculates
>> the
>> >>> spatial autocorrelation index it apparently does not give directly the
>> >>> statical significance of the results obtained :
>> >>> https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
>> >>>
>> >>> Could it be be possible to obtain the statistical significance of the
>> >>> results with either raster package or similar one?
>> >>
>> >>
>> >> fortunes::fortune("This is R")
>> >>
>> >>
>> >> library(raster)
>> >> r <- raster(nrows=10, ncols=10)
>> >> values(r) <- 1:ncell(r)
>> >> f <- matrix(c(0,1,0,1,0,1,0,1,0), nrow=3)
>> >> (rI <- Moran(r, f))
>> >> r1 <- r
>> >> nsim <- 499
>> >> res <- numeric(nsim)
>> >> set.seed(1)
>> >> for (i in 1:nsim) {
>> >>    values(r1) <- values(r)[sample(prod(dim(r)))]
>> >>    res[i] <- Moran(r1, f)
>> >> }
>> >>
>> >> Hope-type tests date back to Cliff and Ord; they are permutation
>> >> bootstraps.
>> >>
>> >> r_g <- as(r, "SpatialPixelsDataFrame")
>> >> library(spdep)
>> >> nb <- poly2nb(as(r_g, "SpatialPolygons"), queen=FALSE)
>> >> set.seed(1)
>> >> o <- moran.mc(r_g$layer, nb2listw(nb, style="B"), nsim=nsim,
>> >>    return_boot=TRUE)
>> >> x_a <- range(c(o$t, o$t0, res, rI))
>> >> plot(density(o$t), xlim=x_a)
>> >> abline(v=o$t0)
>> >> lines(density(res), lty=2)
>> >> abline(v=rI, lty=2)
>> >>
>> >> It is not immediately obvious from the code of raster::Moran() why it
>> is
>> >> different, possibly because of padding the edges of the raster and thus
>> >> increasing the cell count.
>> >>
>> >> For added speed, the bootstrap can be parallelized in both cases;
>> polygon
>> >> boundaries are perhaps not ideal.
>> >>
>> >> Hope this clarifies. Always provide a reproducible example, never post
>> >> HTML
>> >> mail.
>> >>
>> >> Roger Bivand
>> >>
>> >>
>> >>>
>> >>> Thanks a lot.
>> >>> Kind regards,
>> >>> Gabriel
>> >>>
>> >>>       [[alternative HTML version deleted]]
>> >>>
>> >>> _______________________________________________
>> >>> R-sig-Geo mailing list
>> >>> R-sig-Geo at r-project.org
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >>>
>> >>
>> >> --
>> >> Roger Bivand
>> >> Emeritus Professor
>> >> Department of Economics, Norwegian School of Economics,
>> >> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
>> >> e-mail: Roger.Bivand at nhh.no
>> >> https://orcid.org/0000-0003-2392-6140
>> >> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>> >>
>> >
>> >
>> >
>>
>> --
>> Roger Bivand
>> Emeritus Professor
>> Department of Economics, Norwegian School of Economics,
>> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
>> e-mail: Roger.Bivand at nhh.no
>> https://orcid.org/0000-0003-2392-6140
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>
>>
>>
>>
>> ------------------------------
>>
>> Subject: Digest Footer
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>> ------------------------------
>>
>> End of R-sig-Geo Digest, Vol 218, Issue 10
>> ******************************************
>>
>

-- 
Gabriel Cotlier, PhD
Haifa Research Center for Theoretical Physics and Astrophysics (HCTPA)
University of Haifa
Israel

	[[alternative HTML version deleted]]


From qi@gsh@@zh@o m@iii@g oii outiook@com  Thu Oct 21 14:27:50 2021
From: qi@gsh@@zh@o m@iii@g oii outiook@com (qi@gsh@@zh@o m@iii@g oii outiook@com)
Date: Thu, 21 Oct 2021 20:27:50 +0800
Subject: [R-sig-Geo] R-sig-Geo Digest, Vol 218, Issue 10
References: <mailman.28802.3.1634810401.24542.r-sig-geo@r-project.org>
Message-ID: <SY4P282MB4097C25999E1B73911539AD8C5BF9@SY4P282MB4097.AUSP282.PROD.OUTLOOK.COM>

Hello,
 
I would like to determines the intersection points between a great circle and a small circle. 

In R, I only found  gcIntersect function in geosphere package for the intersections of two great circles which is ready to use.

Did a lot of search, found gcxsc  function in octave forgepackage mapping. https://octave.sourceforge.io/mapping/function/gcxsc.html 

And use https://github.com/kvasilopoulos/octaver package to call and communication octave in R, but it is slowly.

Is there any ready to use functon in R package for determines the intersection points between a great circle and a small circle I missed?


Thanks a lot.
Kind regards,
Qingshan Zhao
 




qingshanzhao at outlook.com
 
From: r-sig-geo-request
Date: 2021-10-21 18:00
To: r-sig-geo
Subject: R-sig-Geo Digest, Vol 218, Issue 10
Send R-sig-Geo mailing list submissions to
r-sig-geo at r-project.org
 
To subscribe or unsubscribe via the World Wide Web, visit
https://stat.ethz.ch/mailman/listinfo/r-sig-geo
or, via email, send a message with subject or body 'help' to
r-sig-geo-request at r-project.org
 
You can reach the person managing the list at
r-sig-geo-owner at r-project.org
 
When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-Geo digest..."
 
 
Today's Topics:
 
   1. question on raster Moran's I statistical significance
      (Gabriel Cotlier)
   2. Re:  question on raster Moran's I statistical significance
      (Roger Bivand)
   3. Re:  question on raster Moran's I statistical significance
      (Roger Bivand)
   4. Re:  question on raster Moran's I statistical significance
      (Gabriel Cotlier)
   5. Re:  question on raster Moran's I statistical significance
      (Roger Bivand)
 
----------------------------------------------------------------------
 
Message: 1
Date: Wed, 20 Oct 2021 16:20:45 +0300
From: Gabriel Cotlier <gabiklm01 at gmail.com>
To: r-sig-geo <r-sig-geo at r-project.org>
Subject: [R-sig-Geo] question on raster Moran's I statistical
significance
Message-ID:
<CAAKwTDHO1rah2NX+z2p83kdypX+XHt=4fYSXT=SJixM=iGJUaA at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"
 
Hello,
 
I would like to estimate the Moran's *I* coefficient for raster data and
together with the statical significance of the spatial autocorrelation
obtained.
 
I found that the raster package function Moran() although calculates the
spatial autocorrelation index it apparently does not give directly the
statical significance of the results obtained :
https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
 
Could it be be possible to obtain the statistical significance of the
results with either raster package or similar one?
 
Thanks a lot.
Kind regards,
Gabriel
 
[[alternative HTML version deleted]]
 
 
 
 
------------------------------
 
Message: 2
Date: Wed, 20 Oct 2021 19:42:28 +0200 (CEST)
From: Roger Bivand <Roger.Bivand at nhh.no>
To: Gabriel Cotlier <gabiklm01 at gmail.com>
Cc: r-sig-geo <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo]  question on raster Moran's I statistical
significance
Message-ID: <91dcba60-909f-ed29-1f4-f39c63a60 at reclus2.nhh.no>
Content-Type: text/plain; charset="us-ascii"; Format="flowed"
 
On Wed, 20 Oct 2021, Gabriel Cotlier wrote:
 
> Hello,
>
> I would like to estimate the Moran's *I* coefficient for raster data and
> together with the statical significance of the spatial autocorrelation
> obtained.
>
> I found that the raster package function Moran() although calculates the
> spatial autocorrelation index it apparently does not give directly the
> statical significance of the results obtained :
> https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
>
> Could it be be possible to obtain the statistical significance of the
> results with either raster package or similar one?
 
fortunes::fortune("This is R")
 
 
library(raster)
r <- raster(nrows=10, ncols=10)
values(r) <- 1:ncell(r)
f <- matrix(c(0,1,0,1,0,1,0,1,0), nrow=3)
(rI <- Moran(r, f))
r1 <- r
nsim <- 499
res <- numeric(nsim)
set.seed(1)
for (i in 1:nsim) {
   values(r1) <- values(r)[sample(prod(dim(r)))]
   res[i] <- Moran(r1, f)
}
 
Hope-type tests date back to Cliff and Ord; they are permutation 
bootstraps.
 
r_g <- as(r, "SpatialPixelsDataFrame")
library(spdep)
nb <- poly2nb(as(r_g, "SpatialPolygons"), queen=FALSE)
set.seed(1)
o <- moran.mc(r_g$layer, nb2listw(nb, style="B"), nsim=nsim,
   return_boot=TRUE)
x_a <- range(c(o$t, o$t0, res, rI))
plot(density(o$t), xlim=x_a)
abline(v=o$t0)
lines(density(res), lty=2)
abline(v=rI, lty=2)
 
It is not immediately obvious from the code of raster::Moran() why it is 
different, possibly because of padding the edges of the raster and 
thus increasing the cell count.
 
For added speed, the bootstrap can be parallelized in both cases; polygon 
boundaries are perhaps not ideal.
 
Hope this clarifies. Always provide a reproducible example, never post 
HTML mail.
 
Roger Bivand
 
>
> Thanks a lot.
> Kind regards,
> Gabriel
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
 
-- 
Roger Bivand
Emeritus Professor
Department of Economics, Norwegian School of Economics,
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
 
 
 
 
------------------------------
 
Message: 3
Date: Wed, 20 Oct 2021 19:45:01 +0200 (CEST)
From: Roger Bivand <Roger.Bivand at nhh.no>
To: Gabriel Cotlier <gabiklm01 at gmail.com>
Cc: r-sig-geo <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo]  question on raster Moran's I statistical
significance
Message-ID: <3e639398-e137-5546-1848-5a3afb809240 at reclus2.nhh.no>
Content-Type: text/plain; charset="us-ascii"; Format="flowed"
 
On Wed, 20 Oct 2021, Gabriel Cotlier wrote:
 
> Hello,
>
> I would like to estimate the Moran's *I* coefficient for raster data and
> together with the statical significance of the spatial autocorrelation
> obtained.
>
> I found that the raster package function Moran() although calculates the
> spatial autocorrelation index it apparently does not give directly the
> statical significance of the results obtained :
> https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
>
> Could it be be possible to obtain the statistical significance of the
> results with either raster package or similar one?
 
 
fortunes::fortune("This is R")
 
 
library(raster)
r <- raster(nrows=10, ncols=10)
values(r) <- 1:ncell(r)
f <- matrix(c(0,1,0,1,0,1,0,1,0), nrow=3)
(rI <- Moran(r, f))
r1 <- r
nsim <- 499
res <- numeric(nsim)
set.seed(1)
for (i in 1:nsim) {
   values(r1) <- values(r)[sample(prod(dim(r)))]
   res[i] <- Moran(r1, f)
}
 
Hope-type tests date back to Cliff and Ord; they are permutation 
bootstraps.
 
r_g <- as(r, "SpatialPixelsDataFrame")
library(spdep)
nb <- poly2nb(as(r_g, "SpatialPolygons"), queen=FALSE)
set.seed(1)
o <- moran.mc(r_g$layer, nb2listw(nb, style="B"), nsim=nsim,
   return_boot=TRUE)
x_a <- range(c(o$t, o$t0, res, rI))
plot(density(o$t), xlim=x_a)
abline(v=o$t0)
lines(density(res), lty=2)
abline(v=rI, lty=2)
 
It is not immediately obvious from the code of raster::Moran() why it is
different, possibly because of padding the edges of the raster and thus
increasing the cell count.
 
For added speed, the bootstrap can be parallelized in both cases; polygon
boundaries are perhaps not ideal.
 
Hope this clarifies. Always provide a reproducible example, never post 
HTML
mail.
 
Roger Bivand
 
 
>
> Thanks a lot.
> Kind regards,
> Gabriel
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
 
-- 
Roger Bivand
Emeritus Professor
Department of Economics, Norwegian School of Economics,
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
 
 
 
 
------------------------------
 
Message: 4
Date: Thu, 21 Oct 2021 08:36:51 +0300
From: Gabriel Cotlier <gabiklm01 at gmail.com>
To: Roger.Bivand at nhh.no
Cc: r-sig-geo <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo]  question on raster Moran's I statistical
significance
Message-ID:
<CAAKwTDHmsathQr3nZLZPwtE++t91oOD_bvdV8DpG-4uO4hjxyA at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"
 
Hello
 
Thank you very much.
I have large raster layers and would like to ask, in order to reduce the
processing time of the simulation, choosing a smaller nsim value could help
? and if so, what could be the minimum nsim value recommended?
Thanks a lot again.
Kind regards,
 
 
On Wed, Oct 20, 2021 at 8:45 PM Roger Bivand <Roger.Bivand at nhh.no> wrote:
 
> On Wed, 20 Oct 2021, Gabriel Cotlier wrote:
>
> > Hello,
> >
> > I would like to estimate the Moran's *I* coefficient for raster data and
> > together with the statical significance of the spatial autocorrelation
> > obtained.
> >
> > I found that the raster package function Moran() although calculates the
> > spatial autocorrelation index it apparently does not give directly the
> > statical significance of the results obtained :
> > https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
> >
> > Could it be be possible to obtain the statistical significance of the
> > results with either raster package or similar one?
>
>
> fortunes::fortune("This is R")
>
>
> library(raster)
> r <- raster(nrows=10, ncols=10)
> values(r) <- 1:ncell(r)
> f <- matrix(c(0,1,0,1,0,1,0,1,0), nrow=3)
> (rI <- Moran(r, f))
> r1 <- r
> nsim <- 499
> res <- numeric(nsim)
> set.seed(1)
> for (i in 1:nsim) {
>    values(r1) <- values(r)[sample(prod(dim(r)))]
>    res[i] <- Moran(r1, f)
> }
>
> Hope-type tests date back to Cliff and Ord; they are permutation
> bootstraps.
>
> r_g <- as(r, "SpatialPixelsDataFrame")
> library(spdep)
> nb <- poly2nb(as(r_g, "SpatialPolygons"), queen=FALSE)
> set.seed(1)
> o <- moran.mc(r_g$layer, nb2listw(nb, style="B"), nsim=nsim,
>    return_boot=TRUE)
> x_a <- range(c(o$t, o$t0, res, rI))
> plot(density(o$t), xlim=x_a)
> abline(v=o$t0)
> lines(density(res), lty=2)
> abline(v=rI, lty=2)
>
> It is not immediately obvious from the code of raster::Moran() why it is
> different, possibly because of padding the edges of the raster and thus
> increasing the cell count.
>
> For added speed, the bootstrap can be parallelized in both cases; polygon
> boundaries are perhaps not ideal.
>
> Hope this clarifies. Always provide a reproducible example, never post
> HTML
> mail.
>
> Roger Bivand
>
>
> >
> > Thanks a lot.
> > Kind regards,
> > Gabriel
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Roger Bivand
> Emeritus Professor
> Department of Economics, Norwegian School of Economics,
> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
> e-mail: Roger.Bivand at nhh.no
> https://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>
 
 
-- 
Gabriel Cotlier, PhD
Haifa Research Center for Theoretical Physics and Astrophysics (HCTPA)
University of Haifa
Israel
 
[[alternative HTML version deleted]]
 
 
 
 
------------------------------
 
Message: 5
Date: Thu, 21 Oct 2021 10:40:18 +0200 (CEST)
From: Roger Bivand <Roger.Bivand at nhh.no>
To: Gabriel Cotlier <gabiklm01 at gmail.com>
Cc: r-sig-geo <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo]  question on raster Moran's I statistical
significance
Message-ID: <895fb754-b644-5543-d213-228764873fc5 at reclus2.nhh.no>
Content-Type: text/plain; charset="us-ascii"; Format="flowed"
 
On Thu, 21 Oct 2021, Gabriel Cotlier wrote:
 
> Hello
>
> Thank you very much.
> I have large raster layers and would like to ask, in order to reduce the
> processing time of the simulation, choosing a smaller nsim value could help
> ? and if so, what could be the minimum nsim value recommended?
 
If you examine the code, you see that raster::Moran() always performs 
multiple raster::focal() calls, effectively constructing the spatial 
weights on each run. The problem is not nsim, it is the way that 
raster::Moran() is constructed.
 
Indeed, using a Hope-type test gives the same inferential outcome as using 
asymptotic methods for global tests for spatial autocorrelation, and is 
superfluous, but no other approach is feasible for raster::Moran() (which 
by the way only seems to use 4 neighbours although claiming it uses 8).
 
1. How large is large?
 
It is possible to generate nb neighbour objects for large data sets, 
making the use of spdep::moran.test() feasible, certainly for tens of 
thousands of observations (all the census tracts in coterminous US, for 
example).
 
This uses distances between raster cell centres to find neighbours:
 
> library(spdep)
Loading required package: sp
Loading required package: spData
Loading required package: sf
Linking to GEOS 3.10.0, GDAL 3.3.2, PROJ 8.1.1
> crds <- expand.grid(x=1:800, y=1:1200)
> dim(crds)
[1] 960000      2
> grd <- st_as_sf(crds, coords=c("x", "y"))
> grd$z <- runif(nrow(grd))
> system.time(dnbr <- dnearneigh(grd, 0, 1.01))
    user  system elapsed
  30.065   0.235  30.381
> dnbr
Neighbour list object:
Number of regions: 960000
Number of nonzero links: 3836000
Percentage nonzero weights: 0.0004162326
Average number of links: 3.995833
> system.time(dnbq <- dnearneigh(grd, 0, 1.42))
    user  system elapsed
  54.502   0.080  54.699
> dnbq
Neighbour list object:
Number of regions: 960000
Number of nonzero links: 7668004
Percentage nonzero weights: 0.0008320317
Average number of links: 7.987504
 
Once the neighbour objects are ready, conversion to spatial weights 
objects takes some time, and computing I with a constant mean model 
depends on the numbers of neighbours:
 
> system.time(lwr <- nb2listw(dnbr, style="B"))
    user  system elapsed
   6.694   0.000   6.722
> system.time(Ir <- moran.test(grd$z, lwr))
    user  system elapsed
  24.371   0.000  24.470
> Ir
 
Moran I test under randomisation
 
data:  grd$z
weights: lwr
 
Moran I statistic standard deviate = -0.06337, p-value = 0.5253
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance
     -4.679899e-05     -1.041668e-06      5.213749e-07
 
> system.time(lwq <- nb2listw(dnbq, style="B"))
    user  system elapsed
   6.804   0.000   6.828
> system.time(Iq <- moran.test(grd$z, lwq))
    user  system elapsed
  46.703   0.012  46.843
> Iq
 
Moran I test under randomisation
 
data:  grd$z
weights: lwq
 
Moran I statistic standard deviate = -0.70373, p-value = 0.7592
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance
     -3.604417e-04     -1.041668e-06      2.608222e-07
 
2. The larger your N, the less likely that the test means anything at all, 
because the assumption is that the observed entities are not simply 
arbitrary products of, say, resolution.
 
If you think of global Moran's I as a specification test of a regression 
of the variable of interest on the constant (the mean model is just the 
constant), for raster data the resolution controls the outcome 
(downscaling/upscaling will shift Moran's I). If you include covariates, 
patterning in the residuals of a richer model may well abate.
 
Hope this clarifies,
 
Roger
 
> Thanks a lot again.
> Kind regards,
>
>
> On Wed, Oct 20, 2021 at 8:45 PM Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Wed, 20 Oct 2021, Gabriel Cotlier wrote:
>>
>>> Hello,
>>>
>>> I would like to estimate the Moran's *I* coefficient for raster data and
>>> together with the statical significance of the spatial autocorrelation
>>> obtained.
>>>
>>> I found that the raster package function Moran() although calculates the
>>> spatial autocorrelation index it apparently does not give directly the
>>> statical significance of the results obtained :
>>> https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
>>>
>>> Could it be be possible to obtain the statistical significance of the
>>> results with either raster package or similar one?
>>
>>
>> fortunes::fortune("This is R")
>>
>>
>> library(raster)
>> r <- raster(nrows=10, ncols=10)
>> values(r) <- 1:ncell(r)
>> f <- matrix(c(0,1,0,1,0,1,0,1,0), nrow=3)
>> (rI <- Moran(r, f))
>> r1 <- r
>> nsim <- 499
>> res <- numeric(nsim)
>> set.seed(1)
>> for (i in 1:nsim) {
>>    values(r1) <- values(r)[sample(prod(dim(r)))]
>>    res[i] <- Moran(r1, f)
>> }
>>
>> Hope-type tests date back to Cliff and Ord; they are permutation
>> bootstraps.
>>
>> r_g <- as(r, "SpatialPixelsDataFrame")
>> library(spdep)
>> nb <- poly2nb(as(r_g, "SpatialPolygons"), queen=FALSE)
>> set.seed(1)
>> o <- moran.mc(r_g$layer, nb2listw(nb, style="B"), nsim=nsim,
>>    return_boot=TRUE)
>> x_a <- range(c(o$t, o$t0, res, rI))
>> plot(density(o$t), xlim=x_a)
>> abline(v=o$t0)
>> lines(density(res), lty=2)
>> abline(v=rI, lty=2)
>>
>> It is not immediately obvious from the code of raster::Moran() why it is
>> different, possibly because of padding the edges of the raster and thus
>> increasing the cell count.
>>
>> For added speed, the bootstrap can be parallelized in both cases; polygon
>> boundaries are perhaps not ideal.
>>
>> Hope this clarifies. Always provide a reproducible example, never post
>> HTML
>> mail.
>>
>> Roger Bivand
>>
>>
>>>
>>> Thanks a lot.
>>> Kind regards,
>>> Gabriel
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Emeritus Professor
>> Department of Economics, Norwegian School of Economics,
>> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
>> e-mail: Roger.Bivand at nhh.no
>> https://orcid.org/0000-0003-2392-6140
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>
>
>
>
 
-- 
Roger Bivand
Emeritus Professor
Department of Economics, Norwegian School of Economics,
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
 
 
 
 
------------------------------
 
Subject: Digest Footer
 
_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo
 
 
------------------------------
 
End of R-sig-Geo Digest, Vol 218, Issue 10
******************************************

	[[alternative HTML version deleted]]


From n@|m|@b @end|ng |rom gm@||@com  Thu Oct 21 14:56:33 2021
From: n@|m|@b @end|ng |rom gm@||@com (Babak Naimi)
Date: Thu, 21 Oct 2021 13:56:33 +0100
Subject: [R-sig-Geo] R-sig-Geo Digest, Vol 218, Issue 10
In-Reply-To: <CAAKwTDFMnNQYnxeNhnTa6M-CAhoQfzVuA2ZvrcVOTQFKB1KK-Q@mail.gmail.com>
References: <mailman.28802.3.1634810401.24542.r-sig-geo@r-project.org>
 <CAGL-CGBiqTBDYGGKfQUGAChbOFvU9zeEycR69aKFm7btMj4+_g@mail.gmail.com>
 <CAAKwTDFMnNQYnxeNhnTa6M-CAhoQfzVuA2ZvrcVOTQFKB1KK-Q@mail.gmail.com>
Message-ID: <CAGL-CGBTopKM+dHBm1Tvb5zZ-Ek9uqiebGJ2mBsguAdjUk9T2Q@mail.gmail.com>

Hi, If by nan you mean NA pixels, the pixels with NA would not contribute
to the calculation so would not cause any problem for the calculation.



On Thu, Oct 21, 2021 at 12:44 PM Gabriel Cotlier <gabiklm01 at gmail.com>
wrote:

> Hello Babak,
> Thanks. a lot.
> Yes, elsa::moran() is indeed faster than raster::Moran() as I saw in your
> code; however I have nan values in my raster layer which are rivers of
> other geographic features which aren't relevant thus were converted to nan
> not to influence the results.
> Does there exist a way to make elsa::moran() to work with a raster layer
> with nan values?
> Thanks a lot again.
> Kind regards,
> Gabriel
>
> On Thu, Oct 21, 2021 at 1:52 PM Babak Naimi <naimi.b at gmail.com> wrote:
>
>> Hi Gabriel,
>>
>> You may also use the package elsa to calculate moran (and other spatial
>> autocorrelation statistics) for raster data that is quite fast given the
>> implementation of the functions in C.
>>
>> The equivalent function in the new package terra is also faster than the
>> one in the raster:
>>
>>
>> > r <- raster(xmn=0, nrows=100, ncols=100)
>> > values(r) <- 1:ncell(r)
>> > f <- matrix(c(0,1,0,1,0,1,0,1,0), nrow=3)
>>
>> > system.time(m1 <- raster::Moran(r, f))
>>    user  system elapsed
>>   0.142   0.001   0.143
>> > system.time(m2 <- elsa::moran(r, d1=0,d2=xres(r)))
>>    user  system elapsed
>>   0.002   0.000   0.002
>>
>> > rr <- terra::rast(r)
>> > system.time(m3 <- terra::autocor(rr, f))
>>    user  system elapsed
>>   0.022   0.001   0.022
>>
>> > 0.143 / 0.022
>> [1] 6.5.  # terra is 6.5X faster than raster
>> > 0.143 / 0.001
>> [1] 143 # elsa is 143X faster than raster
>> > 0.022 / 0.001
>> [1] 22 # elsa is 22X faster than terra
>>
>> > c(raster=m1, terra=m2, elsa=m3)
>>     raster      terra         elsa
>>   0.989899   0.989899   0.989899
>>
>> Hope this helps,
>> Cheers,
>> Babak
>>
>>
>>
>> On Thu, Oct 21, 2021 at 11:01 AM <r-sig-geo-request at r-project.org> wrote:
>>
>>> Send R-sig-Geo mailing list submissions to
>>>         r-sig-geo at r-project.org
>>>
>>> To subscribe or unsubscribe via the World Wide Web, visit
>>>         https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> or, via email, send a message with subject or body 'help' to
>>>         r-sig-geo-request at r-project.org
>>>
>>> You can reach the person managing the list at
>>>         r-sig-geo-owner at r-project.org
>>>
>>> When replying, please edit your Subject line so it is more specific
>>> than "Re: Contents of R-sig-Geo digest..."
>>>
>>>
>>> Today's Topics:
>>>
>>>    1. question on raster Moran's I statistical significance
>>>       (Gabriel Cotlier)
>>>    2. Re:  question on raster Moran's I statistical significance
>>>       (Roger Bivand)
>>>    3. Re:  question on raster Moran's I statistical significance
>>>       (Roger Bivand)
>>>    4. Re:  question on raster Moran's I statistical significance
>>>       (Gabriel Cotlier)
>>>    5. Re:  question on raster Moran's I statistical significance
>>>       (Roger Bivand)
>>>
>>> ----------------------------------------------------------------------
>>>
>>> Message: 1
>>> Date: Wed, 20 Oct 2021 16:20:45 +0300
>>> From: Gabriel Cotlier <gabiklm01 at gmail.com>
>>> To: r-sig-geo <r-sig-geo at r-project.org>
>>> Subject: [R-sig-Geo] question on raster Moran's I statistical
>>>         significance
>>> Message-ID:
>>>         <CAAKwTDHO1rah2NX+z2p83kdypX+XHt=4fYSXT=SJixM=
>>> iGJUaA at mail.gmail.com>
>>> Content-Type: text/plain; charset="utf-8"
>>>
>>> Hello,
>>>
>>> I would like to estimate the Moran's *I* coefficient for raster data and
>>> together with the statical significance of the spatial autocorrelation
>>> obtained.
>>>
>>> I found that the raster package function Moran() although calculates the
>>> spatial autocorrelation index it apparently does not give directly the
>>> statical significance of the results obtained :
>>> https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
>>>
>>> Could it be be possible to obtain the statistical significance of the
>>> results with either raster package or similar one?
>>>
>>> Thanks a lot.
>>> Kind regards,
>>> Gabriel
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>>
>>>
>>>
>>> ------------------------------
>>>
>>> Message: 2
>>> Date: Wed, 20 Oct 2021 19:42:28 +0200 (CEST)
>>> From: Roger Bivand <Roger.Bivand at nhh.no>
>>> To: Gabriel Cotlier <gabiklm01 at gmail.com>
>>> Cc: r-sig-geo <r-sig-geo at r-project.org>
>>> Subject: Re: [R-sig-Geo]  question on raster Moran's I statistical
>>>         significance
>>> Message-ID: <91dcba60-909f-ed29-1f4-f39c63a60 at reclus2.nhh.no>
>>> Content-Type: text/plain; charset="us-ascii"; Format="flowed"
>>>
>>> On Wed, 20 Oct 2021, Gabriel Cotlier wrote:
>>>
>>> > Hello,
>>> >
>>> > I would like to estimate the Moran's *I* coefficient for raster data
>>> and
>>> > together with the statical significance of the spatial autocorrelation
>>> > obtained.
>>> >
>>> > I found that the raster package function Moran() although calculates
>>> the
>>> > spatial autocorrelation index it apparently does not give directly the
>>> > statical significance of the results obtained :
>>> > https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
>>> >
>>> > Could it be be possible to obtain the statistical significance of the
>>> > results with either raster package or similar one?
>>>
>>> fortunes::fortune("This is R")
>>>
>>>
>>> library(raster)
>>> r <- raster(nrows=10, ncols=10)
>>> values(r) <- 1:ncell(r)
>>> f <- matrix(c(0,1,0,1,0,1,0,1,0), nrow=3)
>>> (rI <- Moran(r, f))
>>> r1 <- r
>>> nsim <- 499
>>> res <- numeric(nsim)
>>> set.seed(1)
>>> for (i in 1:nsim) {
>>>    values(r1) <- values(r)[sample(prod(dim(r)))]
>>>    res[i] <- Moran(r1, f)
>>> }
>>>
>>> Hope-type tests date back to Cliff and Ord; they are permutation
>>> bootstraps.
>>>
>>> r_g <- as(r, "SpatialPixelsDataFrame")
>>> library(spdep)
>>> nb <- poly2nb(as(r_g, "SpatialPolygons"), queen=FALSE)
>>> set.seed(1)
>>> o <- moran.mc(r_g$layer, nb2listw(nb, style="B"), nsim=nsim,
>>>    return_boot=TRUE)
>>> x_a <- range(c(o$t, o$t0, res, rI))
>>> plot(density(o$t), xlim=x_a)
>>> abline(v=o$t0)
>>> lines(density(res), lty=2)
>>> abline(v=rI, lty=2)
>>>
>>> It is not immediately obvious from the code of raster::Moran() why it is
>>> different, possibly because of padding the edges of the raster and
>>> thus increasing the cell count.
>>>
>>> For added speed, the bootstrap can be parallelized in both cases;
>>> polygon
>>> boundaries are perhaps not ideal.
>>>
>>> Hope this clarifies. Always provide a reproducible example, never post
>>> HTML mail.
>>>
>>> Roger Bivand
>>>
>>> >
>>> > Thanks a lot.
>>> > Kind regards,
>>> > Gabriel
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > _______________________________________________
>>> > R-sig-Geo mailing list
>>> > R-sig-Geo at r-project.org
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> >
>>>
>>> --
>>> Roger Bivand
>>> Emeritus Professor
>>> Department of Economics, Norwegian School of Economics,
>>> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
>>> e-mail: Roger.Bivand at nhh.no
>>> https://orcid.org/0000-0003-2392-6140
>>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>>
>>>
>>>
>>>
>>> ------------------------------
>>>
>>> Message: 3
>>> Date: Wed, 20 Oct 2021 19:45:01 +0200 (CEST)
>>> From: Roger Bivand <Roger.Bivand at nhh.no>
>>> To: Gabriel Cotlier <gabiklm01 at gmail.com>
>>> Cc: r-sig-geo <r-sig-geo at r-project.org>
>>> Subject: Re: [R-sig-Geo]  question on raster Moran's I statistical
>>>         significance
>>> Message-ID: <3e639398-e137-5546-1848-5a3afb809240 at reclus2.nhh.no>
>>> Content-Type: text/plain; charset="us-ascii"; Format="flowed"
>>>
>>> On Wed, 20 Oct 2021, Gabriel Cotlier wrote:
>>>
>>> > Hello,
>>> >
>>> > I would like to estimate the Moran's *I* coefficient for raster data
>>> and
>>> > together with the statical significance of the spatial autocorrelation
>>> > obtained.
>>> >
>>> > I found that the raster package function Moran() although calculates
>>> the
>>> > spatial autocorrelation index it apparently does not give directly the
>>> > statical significance of the results obtained :
>>> > https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
>>> >
>>> > Could it be be possible to obtain the statistical significance of the
>>> > results with either raster package or similar one?
>>>
>>>
>>> fortunes::fortune("This is R")
>>>
>>>
>>> library(raster)
>>> r <- raster(nrows=10, ncols=10)
>>> values(r) <- 1:ncell(r)
>>> f <- matrix(c(0,1,0,1,0,1,0,1,0), nrow=3)
>>> (rI <- Moran(r, f))
>>> r1 <- r
>>> nsim <- 499
>>> res <- numeric(nsim)
>>> set.seed(1)
>>> for (i in 1:nsim) {
>>>    values(r1) <- values(r)[sample(prod(dim(r)))]
>>>    res[i] <- Moran(r1, f)
>>> }
>>>
>>> Hope-type tests date back to Cliff and Ord; they are permutation
>>> bootstraps.
>>>
>>> r_g <- as(r, "SpatialPixelsDataFrame")
>>> library(spdep)
>>> nb <- poly2nb(as(r_g, "SpatialPolygons"), queen=FALSE)
>>> set.seed(1)
>>> o <- moran.mc(r_g$layer, nb2listw(nb, style="B"), nsim=nsim,
>>>    return_boot=TRUE)
>>> x_a <- range(c(o$t, o$t0, res, rI))
>>> plot(density(o$t), xlim=x_a)
>>> abline(v=o$t0)
>>> lines(density(res), lty=2)
>>> abline(v=rI, lty=2)
>>>
>>> It is not immediately obvious from the code of raster::Moran() why it is
>>> different, possibly because of padding the edges of the raster and thus
>>> increasing the cell count.
>>>
>>> For added speed, the bootstrap can be parallelized in both cases; polygon
>>> boundaries are perhaps not ideal.
>>>
>>> Hope this clarifies. Always provide a reproducible example, never post
>>> HTML
>>> mail.
>>>
>>> Roger Bivand
>>>
>>>
>>> >
>>> > Thanks a lot.
>>> > Kind regards,
>>> > Gabriel
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > _______________________________________________
>>> > R-sig-Geo mailing list
>>> > R-sig-Geo at r-project.org
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> >
>>>
>>> --
>>> Roger Bivand
>>> Emeritus Professor
>>> Department of Economics, Norwegian School of Economics,
>>> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
>>> e-mail: Roger.Bivand at nhh.no
>>> https://orcid.org/0000-0003-2392-6140
>>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>>
>>>
>>>
>>>
>>> ------------------------------
>>>
>>> Message: 4
>>> Date: Thu, 21 Oct 2021 08:36:51 +0300
>>> From: Gabriel Cotlier <gabiklm01 at gmail.com>
>>> To: Roger.Bivand at nhh.no
>>> Cc: r-sig-geo <r-sig-geo at r-project.org>
>>> Subject: Re: [R-sig-Geo]  question on raster Moran's I statistical
>>>         significance
>>> Message-ID:
>>>         <
>>> CAAKwTDHmsathQr3nZLZPwtE++t91oOD_bvdV8DpG-4uO4hjxyA at mail.gmail.com>
>>> Content-Type: text/plain; charset="utf-8"
>>>
>>> Hello
>>>
>>> Thank you very much.
>>> I have large raster layers and would like to ask, in order to reduce the
>>> processing time of the simulation, choosing a smaller nsim value could
>>> help
>>> ? and if so, what could be the minimum nsim value recommended?
>>> Thanks a lot again.
>>> Kind regards,
>>>
>>>
>>> On Wed, Oct 20, 2021 at 8:45 PM Roger Bivand <Roger.Bivand at nhh.no>
>>> wrote:
>>>
>>> > On Wed, 20 Oct 2021, Gabriel Cotlier wrote:
>>> >
>>> > > Hello,
>>> > >
>>> > > I would like to estimate the Moran's *I* coefficient for raster data
>>> and
>>> > > together with the statical significance of the spatial
>>> autocorrelation
>>> > > obtained.
>>> > >
>>> > > I found that the raster package function Moran() although calculates
>>> the
>>> > > spatial autocorrelation index it apparently does not give directly
>>> the
>>> > > statical significance of the results obtained :
>>> > > https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
>>> > >
>>> > > Could it be be possible to obtain the statistical significance of the
>>> > > results with either raster package or similar one?
>>> >
>>> >
>>> > fortunes::fortune("This is R")
>>> >
>>> >
>>> > library(raster)
>>> > r <- raster(nrows=10, ncols=10)
>>> > values(r) <- 1:ncell(r)
>>> > f <- matrix(c(0,1,0,1,0,1,0,1,0), nrow=3)
>>> > (rI <- Moran(r, f))
>>> > r1 <- r
>>> > nsim <- 499
>>> > res <- numeric(nsim)
>>> > set.seed(1)
>>> > for (i in 1:nsim) {
>>> >    values(r1) <- values(r)[sample(prod(dim(r)))]
>>> >    res[i] <- Moran(r1, f)
>>> > }
>>> >
>>> > Hope-type tests date back to Cliff and Ord; they are permutation
>>> > bootstraps.
>>> >
>>> > r_g <- as(r, "SpatialPixelsDataFrame")
>>> > library(spdep)
>>> > nb <- poly2nb(as(r_g, "SpatialPolygons"), queen=FALSE)
>>> > set.seed(1)
>>> > o <- moran.mc(r_g$layer, nb2listw(nb, style="B"), nsim=nsim,
>>> >    return_boot=TRUE)
>>> > x_a <- range(c(o$t, o$t0, res, rI))
>>> > plot(density(o$t), xlim=x_a)
>>> > abline(v=o$t0)
>>> > lines(density(res), lty=2)
>>> > abline(v=rI, lty=2)
>>> >
>>> > It is not immediately obvious from the code of raster::Moran() why it
>>> is
>>> > different, possibly because of padding the edges of the raster and thus
>>> > increasing the cell count.
>>> >
>>> > For added speed, the bootstrap can be parallelized in both cases;
>>> polygon
>>> > boundaries are perhaps not ideal.
>>> >
>>> > Hope this clarifies. Always provide a reproducible example, never post
>>> > HTML
>>> > mail.
>>> >
>>> > Roger Bivand
>>> >
>>> >
>>> > >
>>> > > Thanks a lot.
>>> > > Kind regards,
>>> > > Gabriel
>>> > >
>>> > >       [[alternative HTML version deleted]]
>>> > >
>>> > > _______________________________________________
>>> > > R-sig-Geo mailing list
>>> > > R-sig-Geo at r-project.org
>>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> > >
>>> >
>>> > --
>>> > Roger Bivand
>>> > Emeritus Professor
>>> > Department of Economics, Norwegian School of Economics,
>>> > Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
>>> > e-mail: Roger.Bivand at nhh.no
>>> > https://orcid.org/0000-0003-2392-6140
>>> > https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>> >
>>>
>>>
>>> --
>>> Gabriel Cotlier, PhD
>>> Haifa Research Center for Theoretical Physics and Astrophysics (HCTPA)
>>> University of Haifa
>>> Israel
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>>
>>>
>>>
>>> ------------------------------
>>>
>>> Message: 5
>>> Date: Thu, 21 Oct 2021 10:40:18 +0200 (CEST)
>>> From: Roger Bivand <Roger.Bivand at nhh.no>
>>> To: Gabriel Cotlier <gabiklm01 at gmail.com>
>>> Cc: r-sig-geo <r-sig-geo at r-project.org>
>>> Subject: Re: [R-sig-Geo]  question on raster Moran's I statistical
>>>         significance
>>> Message-ID: <895fb754-b644-5543-d213-228764873fc5 at reclus2.nhh.no>
>>> Content-Type: text/plain; charset="us-ascii"; Format="flowed"
>>>
>>> On Thu, 21 Oct 2021, Gabriel Cotlier wrote:
>>>
>>> > Hello
>>> >
>>> > Thank you very much.
>>> > I have large raster layers and would like to ask, in order to reduce
>>> the
>>> > processing time of the simulation, choosing a smaller nsim value could
>>> help
>>> > ? and if so, what could be the minimum nsim value recommended?
>>>
>>> If you examine the code, you see that raster::Moran() always performs
>>> multiple raster::focal() calls, effectively constructing the spatial
>>> weights on each run. The problem is not nsim, it is the way that
>>> raster::Moran() is constructed.
>>>
>>> Indeed, using a Hope-type test gives the same inferential outcome as
>>> using
>>> asymptotic methods for global tests for spatial autocorrelation, and is
>>> superfluous, but no other approach is feasible for raster::Moran()
>>> (which
>>> by the way only seems to use 4 neighbours although claiming it uses 8).
>>>
>>> 1. How large is large?
>>>
>>> It is possible to generate nb neighbour objects for large data sets,
>>> making the use of spdep::moran.test() feasible, certainly for tens of
>>> thousands of observations (all the census tracts in coterminous US, for
>>> example).
>>>
>>> This uses distances between raster cell centres to find neighbours:
>>>
>>> > library(spdep)
>>> Loading required package: sp
>>> Loading required package: spData
>>> Loading required package: sf
>>> Linking to GEOS 3.10.0, GDAL 3.3.2, PROJ 8.1.1
>>> > crds <- expand.grid(x=1:800, y=1:1200)
>>> > dim(crds)
>>> [1] 960000      2
>>> > grd <- st_as_sf(crds, coords=c("x", "y"))
>>> > grd$z <- runif(nrow(grd))
>>> > system.time(dnbr <- dnearneigh(grd, 0, 1.01))
>>>     user  system elapsed
>>>   30.065   0.235  30.381
>>> > dnbr
>>> Neighbour list object:
>>> Number of regions: 960000
>>> Number of nonzero links: 3836000
>>> Percentage nonzero weights: 0.0004162326
>>> Average number of links: 3.995833
>>> > system.time(dnbq <- dnearneigh(grd, 0, 1.42))
>>>     user  system elapsed
>>>   54.502   0.080  54.699
>>> > dnbq
>>> Neighbour list object:
>>> Number of regions: 960000
>>> Number of nonzero links: 7668004
>>> Percentage nonzero weights: 0.0008320317
>>> Average number of links: 7.987504
>>>
>>> Once the neighbour objects are ready, conversion to spatial weights
>>> objects takes some time, and computing I with a constant mean model
>>> depends on the numbers of neighbours:
>>>
>>> > system.time(lwr <- nb2listw(dnbr, style="B"))
>>>     user  system elapsed
>>>    6.694   0.000   6.722
>>> > system.time(Ir <- moran.test(grd$z, lwr))
>>>     user  system elapsed
>>>   24.371   0.000  24.470
>>> > Ir
>>>
>>>         Moran I test under randomisation
>>>
>>> data:  grd$z
>>> weights: lwr
>>>
>>> Moran I statistic standard deviate = -0.06337, p-value = 0.5253
>>> alternative hypothesis: greater
>>> sample estimates:
>>> Moran I statistic       Expectation          Variance
>>>      -4.679899e-05     -1.041668e-06      5.213749e-07
>>>
>>> > system.time(lwq <- nb2listw(dnbq, style="B"))
>>>     user  system elapsed
>>>    6.804   0.000   6.828
>>> > system.time(Iq <- moran.test(grd$z, lwq))
>>>     user  system elapsed
>>>   46.703   0.012  46.843
>>> > Iq
>>>
>>>         Moran I test under randomisation
>>>
>>> data:  grd$z
>>> weights: lwq
>>>
>>> Moran I statistic standard deviate = -0.70373, p-value = 0.7592
>>> alternative hypothesis: greater
>>> sample estimates:
>>> Moran I statistic       Expectation          Variance
>>>      -3.604417e-04     -1.041668e-06      2.608222e-07
>>>
>>> 2. The larger your N, the less likely that the test means anything at
>>> all,
>>> because the assumption is that the observed entities are not simply
>>> arbitrary products of, say, resolution.
>>>
>>> If you think of global Moran's I as a specification test of a regression
>>> of the variable of interest on the constant (the mean model is just the
>>> constant), for raster data the resolution controls the outcome
>>> (downscaling/upscaling will shift Moran's I). If you include covariates,
>>> patterning in the residuals of a richer model may well abate.
>>>
>>> Hope this clarifies,
>>>
>>> Roger
>>>
>>> > Thanks a lot again.
>>> > Kind regards,
>>> >
>>> >
>>> > On Wed, Oct 20, 2021 at 8:45 PM Roger Bivand <Roger.Bivand at nhh.no>
>>> wrote:
>>> >
>>> >> On Wed, 20 Oct 2021, Gabriel Cotlier wrote:
>>> >>
>>> >>> Hello,
>>> >>>
>>> >>> I would like to estimate the Moran's *I* coefficient for raster data
>>> and
>>> >>> together with the statical significance of the spatial
>>> autocorrelation
>>> >>> obtained.
>>> >>>
>>> >>> I found that the raster package function Moran() although calculates
>>> the
>>> >>> spatial autocorrelation index it apparently does not give directly
>>> the
>>> >>> statical significance of the results obtained :
>>> >>> https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
>>> >>>
>>> >>> Could it be be possible to obtain the statistical significance of the
>>> >>> results with either raster package or similar one?
>>> >>
>>> >>
>>> >> fortunes::fortune("This is R")
>>> >>
>>> >>
>>> >> library(raster)
>>> >> r <- raster(nrows=10, ncols=10)
>>> >> values(r) <- 1:ncell(r)
>>> >> f <- matrix(c(0,1,0,1,0,1,0,1,0), nrow=3)
>>> >> (rI <- Moran(r, f))
>>> >> r1 <- r
>>> >> nsim <- 499
>>> >> res <- numeric(nsim)
>>> >> set.seed(1)
>>> >> for (i in 1:nsim) {
>>> >>    values(r1) <- values(r)[sample(prod(dim(r)))]
>>> >>    res[i] <- Moran(r1, f)
>>> >> }
>>> >>
>>> >> Hope-type tests date back to Cliff and Ord; they are permutation
>>> >> bootstraps.
>>> >>
>>> >> r_g <- as(r, "SpatialPixelsDataFrame")
>>> >> library(spdep)
>>> >> nb <- poly2nb(as(r_g, "SpatialPolygons"), queen=FALSE)
>>> >> set.seed(1)
>>> >> o <- moran.mc(r_g$layer, nb2listw(nb, style="B"), nsim=nsim,
>>> >>    return_boot=TRUE)
>>> >> x_a <- range(c(o$t, o$t0, res, rI))
>>> >> plot(density(o$t), xlim=x_a)
>>> >> abline(v=o$t0)
>>> >> lines(density(res), lty=2)
>>> >> abline(v=rI, lty=2)
>>> >>
>>> >> It is not immediately obvious from the code of raster::Moran() why it
>>> is
>>> >> different, possibly because of padding the edges of the raster and
>>> thus
>>> >> increasing the cell count.
>>> >>
>>> >> For added speed, the bootstrap can be parallelized in both cases;
>>> polygon
>>> >> boundaries are perhaps not ideal.
>>> >>
>>> >> Hope this clarifies. Always provide a reproducible example, never post
>>> >> HTML
>>> >> mail.
>>> >>
>>> >> Roger Bivand
>>> >>
>>> >>
>>> >>>
>>> >>> Thanks a lot.
>>> >>> Kind regards,
>>> >>> Gabriel
>>> >>>
>>> >>>       [[alternative HTML version deleted]]
>>> >>>
>>> >>> _______________________________________________
>>> >>> R-sig-Geo mailing list
>>> >>> R-sig-Geo at r-project.org
>>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> >>>
>>> >>
>>> >> --
>>> >> Roger Bivand
>>> >> Emeritus Professor
>>> >> Department of Economics, Norwegian School of Economics,
>>> >> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
>>> >> e-mail: Roger.Bivand at nhh.no
>>> >> https://orcid.org/0000-0003-2392-6140
>>> >> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>> >>
>>> >
>>> >
>>> >
>>>
>>> --
>>> Roger Bivand
>>> Emeritus Professor
>>> Department of Economics, Norwegian School of Economics,
>>> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
>>> e-mail: Roger.Bivand at nhh.no
>>> https://orcid.org/0000-0003-2392-6140
>>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>>
>>>
>>>
>>>
>>> ------------------------------
>>>
>>> Subject: Digest Footer
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>> ------------------------------
>>>
>>> End of R-sig-Geo Digest, Vol 218, Issue 10
>>> ******************************************
>>>
>>
>
> --
> Gabriel Cotlier, PhD
> Haifa Research Center for Theoretical Physics and Astrophysics (HCTPA)
> University of Haifa
> Israel
>
>
>

	[[alternative HTML version deleted]]


From ee|koudou@@ @end|ng |rom |ordh@m@edu  Thu Oct 21 15:20:46 2021
From: ee|koudou@@ @end|ng |rom |ordh@m@edu (El Mechry El Koudouss)
Date: Thu, 21 Oct 2021 09:20:46 -0400
Subject: [R-sig-Geo] Dynamic Spatial Panel Data Models in R
Message-ID: <CABvzdCWpajevdO=qd0Vi=-Oxkdhp3sYaKFc+LqMX5aAWxY3kGw@mail.gmail.com>

Dear readers,
Is anyone here aware of an R package that is able to estimate dynamic
spatial panel data models? I am aware of the existence of some MATLAB
routines that are able to do this but I am not that familiar with MATLAB.
Your recommendations would be greatly appreciated.
Thanks

-- 
El Mechry, El Koudouss (Meshry)
Graduate Research Assistant
Center for International Policy Studies
Fordham University
Department of Economics
Website: www.meshry.com

	[[alternative HTML version deleted]]


From e||@@kr@|n@k| @end|ng |rom gm@||@com  Fri Oct 22 11:22:43 2021
From: e||@@kr@|n@k| @end|ng |rom gm@||@com (Elias T. Krainski)
Date: Fri, 22 Oct 2021 12:22:43 +0300
Subject: [R-sig-Geo] Dynamic Spatial Panel Data Models in R
In-Reply-To: <CABvzdCWpajevdO=qd0Vi=-Oxkdhp3sYaKFc+LqMX5aAWxY3kGw@mail.gmail.com>
References: <CABvzdCWpajevdO=qd0Vi=-Oxkdhp3sYaKFc+LqMX5aAWxY3kGw@mail.gmail.com>
Message-ID: <CAA0dk0EKAN=Be+5D7=e9=HdnMY=_vvVr5DqPsp4kuvYZPx3rYA@mail.gmail.com>

Dear Meshry
You can use the INLA package for this model class. You can start with the
paper (in this link
https://www.sciencedirect.com/science/article/pii/S0167947311003999) and
books from the INLA web site at http://www.r-inla.org
Elias

On Thu, 21 Oct 2021 at 16:21, El Mechry El Koudouss <eelkoudouss at fordham.edu>
wrote:

> Dear readers,
> Is anyone here aware of an R package that is able to estimate dynamic
> spatial panel data models? I am aware of the existence of some MATLAB
> routines that are able to do this but I am not that familiar with MATLAB.
> Your recommendations would be greatly appreciated.
> Thanks
>
> --
> El Mechry, El Koudouss (Meshry)
> Graduate Research Assistant
> Center for International Policy Studies
> Fordham University
> Department of Economics
> Website: www.meshry.com
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From g@b|k|m01 @end|ng |rom gm@||@com  Fri Oct 22 20:25:00 2021
From: g@b|k|m01 @end|ng |rom gm@||@com (Gabriel Cotlier)
Date: Fri, 22 Oct 2021 21:25:00 +0300
Subject: [R-sig-Geo] 
 question on raster Moran's I statistical significance
In-Reply-To: <CAAKwTDH-=WDeDUbbMfzUFs5qYXV8S+Xoq3D=tEWT9bX669Z2fg@mail.gmail.com>
References: <CAAKwTDHO1rah2NX+z2p83kdypX+XHt=4fYSXT=SJixM=iGJUaA@mail.gmail.com>
 <3e639398-e137-5546-1848-5a3afb809240@reclus2.nhh.no>
 <CAAKwTDHmsathQr3nZLZPwtE++t91oOD_bvdV8DpG-4uO4hjxyA@mail.gmail.com>
 <895fb754-b644-5543-d213-228764873fc5@reclus2.nhh.no>
 <CAAKwTDH-=WDeDUbbMfzUFs5qYXV8S+Xoq3D=tEWT9bX669Z2fg@mail.gmail.com>
Message-ID: <CAAKwTDEvL5tT_oxa-TN9H4hmmg36nqW8qrOwT9vugRqC4wOhWA@mail.gmail.com>

Hello,

With regards to my intention of solely estimating the pseudo p-value of
Moran's I from raster data layer, by converting it to polygon data in
order to be able to directly use the function  spdep::mc.moran() and
getting in one step not only value of Moran'sI but its statistical
significance without using other simulations but only that in the funcion
spdep::mc.moran() as an alternative I have used the code below. However,
since with the initial version of the code I got  several errors such as :

Error in moran. mc(My_raster, lw.l, 999) : r is not a numeric vector

So I converted "r" to a vector using as.vector() in :

M <- moran.mc(as.vector(r), lw.l, 999)

However then appeared another the error:

Error in na.fail.default(x) : missing values in object

Finally these errors disappeared with the following version of the code--
see below -- the version of the code below runs OK--unless for the input
raster I have used-- with no more errors or problems.

Therefore my question is : if instead of using arguments of the function
spdep::mc.moran() such as na.action = na.omit or other --which I have tried
and could not make work-- is it a valid way to solve the above errors  in
the way as presented in the code below?

Thanks a lot.
Kind regards,

################### Estimate of Moran's I and its p-value from a raster
layer ##################################
library(raster)
library(spdep)
library(easycsv)

rm(list = ls())

r<- raster(file.choose())
l <- rasterToPolygons(r)

nb.l <- poly2nb(l, queen=FALSE)
lw.l <- nb2listw(nb.l, style="W",zero.policy=TRUE)

v<-r[!is.na(r)]
M <- moran.mc((v), lw.l, 999, zero.policy=TRUE)
M

plot(M, main=sprintf("Original, Moran's I (p = %0.3f)", M$p.value),
xlab="Monte-Carlo Simulation of Moran I", sub =NA, cex.lab=1.5,
cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
abline(v=M$statistic, col="red", lw=2)
dev.off()
################################################################################################

On Thu, Oct 21, 2021 at 1:13 PM Gabriel Cotlier <gabiklm01 at gmail.com> wrote:

> Hello
> Thanks a lot.
> Indeed your explanation makes it much more clear.
> Kind regards,
>
>
> On Thu, Oct 21, 2021 at 11:40 AM Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Thu, 21 Oct 2021, Gabriel Cotlier wrote:
>>
>> > Hello
>> >
>> > Thank you very much.
>> > I have large raster layers and would like to ask, in order to reduce the
>> > processing time of the simulation, choosing a smaller nsim value could
>> help
>> > ? and if so, what could be the minimum nsim value recommended?
>>
>> If you examine the code, you see that raster::Moran() always performs
>> multiple raster::focal() calls, effectively constructing the spatial
>> weights on each run. The problem is not nsim, it is the way that
>> raster::Moran() is constructed.
>>
>> Indeed, using a Hope-type test gives the same inferential outcome as
>> using
>> asymptotic methods for global tests for spatial autocorrelation, and is
>> superfluous, but no other approach is feasible for raster::Moran() (which
>> by the way only seems to use 4 neighbours although claiming it uses 8).
>>
>> 1. How large is large?
>>
>> It is possible to generate nb neighbour objects for large data sets,
>> making the use of spdep::moran.test() feasible, certainly for tens of
>> thousands of observations (all the census tracts in coterminous US, for
>> example).
>>
>> This uses distances between raster cell centres to find neighbours:
>>
>> > library(spdep)
>> Loading required package: sp
>> Loading required package: spData
>> Loading required package: sf
>> Linking to GEOS 3.10.0, GDAL 3.3.2, PROJ 8.1.1
>> > crds <- expand.grid(x=1:800, y=1:1200)
>> > dim(crds)
>> [1] 960000      2
>> > grd <- st_as_sf(crds, coords=c("x", "y"))
>> > grd$z <- runif(nrow(grd))
>> > system.time(dnbr <- dnearneigh(grd, 0, 1.01))
>>     user  system elapsed
>>   30.065   0.235  30.381
>> > dnbr
>> Neighbour list object:
>> Number of regions: 960000
>> Number of nonzero links: 3836000
>> Percentage nonzero weights: 0.0004162326
>> Average number of links: 3.995833
>> > system.time(dnbq <- dnearneigh(grd, 0, 1.42))
>>     user  system elapsed
>>   54.502   0.080  54.699
>> > dnbq
>> Neighbour list object:
>> Number of regions: 960000
>> Number of nonzero links: 7668004
>> Percentage nonzero weights: 0.0008320317
>> Average number of links: 7.987504
>>
>> Once the neighbour objects are ready, conversion to spatial weights
>> objects takes some time, and computing I with a constant mean model
>> depends on the numbers of neighbours:
>>
>> > system.time(lwr <- nb2listw(dnbr, style="B"))
>>     user  system elapsed
>>    6.694   0.000   6.722
>> > system.time(Ir <- moran.test(grd$z, lwr))
>>     user  system elapsed
>>   24.371   0.000  24.470
>> > Ir
>>
>>         Moran I test under randomisation
>>
>> data:  grd$z
>> weights: lwr
>>
>> Moran I statistic standard deviate = -0.06337, p-value = 0.5253
>> alternative hypothesis: greater
>> sample estimates:
>> Moran I statistic       Expectation          Variance
>>      -4.679899e-05     -1.041668e-06      5.213749e-07
>>
>> > system.time(lwq <- nb2listw(dnbq, style="B"))
>>     user  system elapsed
>>    6.804   0.000   6.828
>> > system.time(Iq <- moran.test(grd$z, lwq))
>>     user  system elapsed
>>   46.703   0.012  46.843
>> > Iq
>>
>>         Moran I test under randomisation
>>
>> data:  grd$z
>> weights: lwq
>>
>> Moran I statistic standard deviate = -0.70373, p-value = 0.7592
>> alternative hypothesis: greater
>> sample estimates:
>> Moran I statistic       Expectation          Variance
>>      -3.604417e-04     -1.041668e-06      2.608222e-07
>>
>> 2. The larger your N, the less likely that the test means anything at
>> all,
>> because the assumption is that the observed entities are not simply
>> arbitrary products of, say, resolution.
>>
>> If you think of global Moran's I as a specification test of a regression
>> of the variable of interest on the constant (the mean model is just the
>> constant), for raster data the resolution controls the outcome
>> (downscaling/upscaling will shift Moran's I). If you include covariates,
>> patterning in the residuals of a richer model may well abate.
>>
>> Hope this clarifies,
>>
>> Roger
>>
>> > Thanks a lot again.
>> > Kind regards,
>> >
>> >
>> > On Wed, Oct 20, 2021 at 8:45 PM Roger Bivand <Roger.Bivand at nhh.no>
>> wrote:
>> >
>> >> On Wed, 20 Oct 2021, Gabriel Cotlier wrote:
>> >>
>> >>> Hello,
>> >>>
>> >>> I would like to estimate the Moran's *I* coefficient for raster data
>> and
>> >>> together with the statical significance of the spatial autocorrelation
>> >>> obtained.
>> >>>
>> >>> I found that the raster package function Moran() although calculates
>> the
>> >>> spatial autocorrelation index it apparently does not give directly the
>> >>> statical significance of the results obtained :
>> >>> https://search.r-project.org/CRAN/refmans/raster/html/autocor.html
>> >>>
>> >>> Could it be be possible to obtain the statistical significance of the
>> >>> results with either raster package or similar one?
>> >>
>> >>
>> >> fortunes::fortune("This is R")
>> >>
>> >>
>> >> library(raster)
>> >> r <- raster(nrows=10, ncols=10)
>> >> values(r) <- 1:ncell(r)
>> >> f <- matrix(c(0,1,0,1,0,1,0,1,0), nrow=3)
>> >> (rI <- Moran(r, f))
>> >> r1 <- r
>> >> nsim <- 499
>> >> res <- numeric(nsim)
>> >> set.seed(1)
>> >> for (i in 1:nsim) {
>> >>    values(r1) <- values(r)[sample(prod(dim(r)))]
>> >>    res[i] <- Moran(r1, f)
>> >> }
>> >>
>> >> Hope-type tests date back to Cliff and Ord; they are permutation
>> >> bootstraps.
>> >>
>> >> r_g <- as(r, "SpatialPixelsDataFrame")
>> >> library(spdep)
>> >> nb <- poly2nb(as(r_g, "SpatialPolygons"), queen=FALSE)
>> >> set.seed(1)
>> >> o <- moran.mc(r_g$layer, nb2listw(nb, style="B"), nsim=nsim,
>> >>    return_boot=TRUE)
>> >> x_a <- range(c(o$t, o$t0, res, rI))
>> >> plot(density(o$t), xlim=x_a)
>> >> abline(v=o$t0)
>> >> lines(density(res), lty=2)
>> >> abline(v=rI, lty=2)
>> >>
>> >> It is not immediately obvious from the code of raster::Moran() why it
>> is
>> >> different, possibly because of padding the edges of the raster and thus
>> >> increasing the cell count.
>> >>
>> >> For added speed, the bootstrap can be parallelized in both cases;
>> polygon
>> >> boundaries are perhaps not ideal.
>> >>
>> >> Hope this clarifies. Always provide a reproducible example, never post
>> >> HTML
>> >> mail.
>> >>
>> >> Roger Bivand
>> >>
>> >>
>> >>>
>> >>> Thanks a lot.
>> >>> Kind regards,
>> >>> Gabriel
>> >>>
>> >>>       [[alternative HTML version deleted]]
>> >>>
>> >>> _______________________________________________
>> >>> R-sig-Geo mailing list
>> >>> R-sig-Geo at r-project.org
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >>>
>> >>
>> >> --
>> >> Roger Bivand
>> >> Emeritus Professor
>> >> Department of Economics, Norwegian School of Economics,
>> >> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
>> >> e-mail: Roger.Bivand at nhh.no
>> >> https://orcid.org/0000-0003-2392-6140
>> >> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>> >>
>> >
>> >
>> >
>>
>> --
>> Roger Bivand
>> Emeritus Professor
>> Department of Economics, Norwegian School of Economics,
>> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
>> e-mail: Roger.Bivand at nhh.no
>> https://orcid.org/0000-0003-2392-6140
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>
>
>
> --
> Gabriel Cotlier, PhD
> Haifa Research Center for Theoretical Physics and Astrophysics (HCTPA)
> University of Haifa
> Israel
>
>
>

-- 
Gabriel Cotlier, PhD
Haifa Research Center for Theoretical Physics and Astrophysics (HCTPA)
University of Haifa
Israel

	[[alternative HTML version deleted]]


From g@b|k|m01 @end|ng |rom gm@||@com  Sat Oct 23 09:49:53 2021
From: g@b|k|m01 @end|ng |rom gm@||@com (Gabriel Cotlier)
Date: Sat, 23 Oct 2021 10:49:53 +0300
Subject: [R-sig-Geo] question on raster Moran's I statistical significance
Message-ID: <CAAKwTDGq1qzdWC6S+gBL_0+=EViGOxWOx8q3qk=U-5Ui+pX+Og@mail.gmail.com>

Hello,

I would like to estimate the pseudo p-value of Moran's I from raster data
layer, by converting it to polygon data in order to be able to directly use
the function  spdep::mc.moran() and getting in one step not only value of
Moran'sI but its statistical significance without using other simulations
but only that in the funcion spdep::mc.moran() as an alternative I have
used the code below. However, since with the initial version of the code I
got  several errors such as :

Error in moran. mc(My_raster, lw.l, 999) : r is not a numeric vector

So I converted "r" to a vector using as.vector() in :

M <- moran.mc(as.vector(r), lw.l, 999)

However then appeared another the error:

Error in na.fail.default(x) : missing values in object

Finally these errors disappeared with the following version of the code--
see below -- the version of the code below runs OK--unless for the input
raster I have used-- with no more errors or problems.

Therefore my question is : if instead of using arguments of the function
spdep::mc.moran() such as na.action = na.omit or other --which I have tried
and could not make work-- is it a valid way to solve the above errors  in
the way as presented in the code below?

I would appreciate it a lot if there is a possibility of knowing what could
be wrong in the code below?

I suspect it could be possible the problem is related to the way in which
the raster  data layer is converted to polygon data  im the code to be
input to the function spdep::mc.moran() , but will appreciate any guidance
and assistance in the issue to get working in the correct manner.

Thanks a lot.
Kind regards,

################### Estimate of Moran's I and its p-value from a raster
layer ##################################
library(raster)
library(spdep)
library(easycsv)

rm(list = ls())

r<- raster(file.choose())
l <- rasterToPolygons(r)

nb.l <- poly2nb(l, queen=FALSE)
lw.l <- nb2listw(nb.l, style="W",zero.policy=TRUE)

v<-r[!is.na(r)]
M <- moran.mc((v), lw.l, 999, zero.policy=TRUE)
M

plot(M, main=sprintf("Original, Moran's I (p = %0.3f)", M$p.value),
xlab="Monte-Carlo Simulation of Moran I", sub =NA, cex.lab=1.5,
cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
abline(v=M$statistic, col="red", lw=2)
dev.off()
################################################################################################

-- 
Gabriel Cotlier, PhD
Haifa Research Center for Theoretical Physics and Astrophysics (HCTPA)
University of Haifa
Israel

	[[alternative HTML version deleted]]


From c@o@c@rtogr@||@ @end|ng |rom gm@||@com  Sat Oct 23 11:45:47 2021
From: c@o@c@rtogr@||@ @end|ng |rom gm@||@com (Caridad Serrano Ortega)
Date: Sat, 23 Oct 2021 11:45:47 +0200
Subject: [R-sig-Geo] webinar
Message-ID: <CAM98pTx7Zd6svLArWNKFektMNsyZ5==L_D3y+2wi+8PKOMH=5w@mail.gmail.com>

Hello!
There are two webinars for your interest:
Introduction to Google Earth Engine with R language
https://www.youtube.com/watch?v=SHXuIpjU3YE

Deep Learning for Remote Sensing images with R language
https://www.youtube.com/watch?v=N3CHgRlRqOA

	[[alternative HTML version deleted]]


From Roger@B|v@nd @end|ng |rom nhh@no  Mon Oct 25 10:59:54 2021
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Mon, 25 Oct 2021 10:59:54 +0200 (CEST)
Subject: [R-sig-Geo] 
 question on raster Moran's I statistical significance
In-Reply-To: <CAAKwTDGq1qzdWC6S+gBL_0+=EViGOxWOx8q3qk=U-5Ui+pX+Og@mail.gmail.com>
References: <CAAKwTDGq1qzdWC6S+gBL_0+=EViGOxWOx8q3qk=U-5Ui+pX+Og@mail.gmail.com>
Message-ID: <764bf853-2e6-eac0-f412-9189af86850@reclus2.nhh.no>

On Sat, 23 Oct 2021, Gabriel Cotlier wrote:

> Hello,
>
> I would like to estimate the pseudo p-value of Moran's I from raster data
> layer, by converting it to polygon data in order to be able to directly use
> the function  spdep::mc.moran() and getting in one step not only value of
> Moran'sI but its statistical significance without using other simulations
> but only that in the funcion spdep::mc.moran() as an alternative I have
> used the code below. However, since with the initial version of the code I
> got  several errors such as :
>
> Error in moran. mc(My_raster, lw.l, 999) : r is not a numeric vector
>
> So I converted "r" to a vector using as.vector() in :
>
> M <- moran.mc(as.vector(r), lw.l, 999)

First, if you have the spatial weights object lw.l, spdep::moran.test(), 
using analytical rather than bootstrap inference, is almost certainly more 
efficient, and yields almost always the same outcome with 
randomisation=TRUE.

>
> However then appeared another the error:
>
> Error in na.fail.default(x) : missing values in object
>

Please see the na.action= argument to moran.mc() and moran.test(); the 
default is na.fail, but can be na.exclude, which then also subsets the 
listw spatial weights object. You can also subset l before creating the 
neighbour object:

library(raster)
library(spdep)
r <- raster(nrows=10, ncols=10)
values(r) <- c(1:(ncell(r)-1), NA)
l <- rasterToPolygons(r, na.rm=TRUE) # note that this subsets by default
dim(l) # [1] 99  1
nb.l <- poly2nb(l, queen=FALSE)
nb.l # here no no-neighbour observations, no need for zero.policy=
lw.l <- nb2listw(nb.l, style="W")
moran.test(l$layer, lw.l) # default randomisation=TRUE



> Finally these errors disappeared with the following version of the code--
> see below -- the version of the code below runs OK--unless for the input
> raster I have used-- with no more errors or problems.
>

Because rasterToPolygons() removes NA observations by default.

Hope this clarifies,

Roger

> Therefore my question is : if instead of using arguments of the function
> spdep::mc.moran() such as na.action = na.omit or other --which I have tried
> and could not make work-- is it a valid way to solve the above errors  in
> the way as presented in the code below?
>
> I would appreciate it a lot if there is a possibility of knowing what could
> be wrong in the code below?
>
> I suspect it could be possible the problem is related to the way in which
> the raster  data layer is converted to polygon data  im the code to be
> input to the function spdep::mc.moran() , but will appreciate any guidance
> and assistance in the issue to get working in the correct manner.
>
> Thanks a lot.
> Kind regards,
>
> ################### Estimate of Moran's I and its p-value from a raster
> layer ##################################
> library(raster)
> library(spdep)
> library(easycsv)
>
> rm(list = ls())
>
> r<- raster(file.choose())
> l <- rasterToPolygons(r)
>
> nb.l <- poly2nb(l, queen=FALSE)
> lw.l <- nb2listw(nb.l, style="W",zero.policy=TRUE)
>
> v<-r[!is.na(r)]
> M <- moran.mc((v), lw.l, 999, zero.policy=TRUE)
> M
>
> plot(M, main=sprintf("Original, Moran's I (p = %0.3f)", M$p.value),
> xlab="Monte-Carlo Simulation of Moran I", sub =NA, cex.lab=1.5,
> cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
> abline(v=M$statistic, col="red", lw=2)
> dev.off()
> ################################################################################################
>
>

-- 
Roger Bivand
Emeritus Professor
Department of Economics, Norwegian School of Economics,
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From g@b|k|m01 @end|ng |rom gm@||@com  Mon Oct 25 11:21:14 2021
From: g@b|k|m01 @end|ng |rom gm@||@com (Gabriel Cotlier)
Date: Mon, 25 Oct 2021 12:21:14 +0300
Subject: [R-sig-Geo] 
 question on raster Moran's I statistical significance
In-Reply-To: <764bf853-2e6-eac0-f412-9189af86850@reclus2.nhh.no>
References: <CAAKwTDGq1qzdWC6S+gBL_0+=EViGOxWOx8q3qk=U-5Ui+pX+Og@mail.gmail.com>
 <764bf853-2e6-eac0-f412-9189af86850@reclus2.nhh.no>
Message-ID: <CAAKwTDELzUWCkPZB94Lw8nB1FYWp5TuTaZayRNo=YmMx5FyOSA@mail.gmail.com>

Thank you very much for your response.
Yes indeed it clarifies and helps a lot.
Kind regards,
Gabriel Cotlier

On Mon, Oct 25, 2021 at 12:00 PM Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Sat, 23 Oct 2021, Gabriel Cotlier wrote:
>
> > Hello,
> >
> > I would like to estimate the pseudo p-value of Moran's I from raster data
> > layer, by converting it to polygon data in order to be able to directly
> use
> > the function  spdep::mc.moran() and getting in one step not only value of
> > Moran'sI but its statistical significance without using other simulations
> > but only that in the funcion spdep::mc.moran() as an alternative I have
> > used the code below. However, since with the initial version of the code
> I
> > got  several errors such as :
> >
> > Error in moran. mc(My_raster, lw.l, 999) : r is not a numeric vector
> >
> > So I converted "r" to a vector using as.vector() in :
> >
> > M <- moran.mc(as.vector(r), lw.l, 999)
>
> First, if you have the spatial weights object lw.l, spdep::moran.test(),
> using analytical rather than bootstrap inference, is almost certainly more
> efficient, and yields almost always the same outcome with
> randomisation=TRUE.
>
> >
> > However then appeared another the error:
> >
> > Error in na.fail.default(x) : missing values in object
> >
>
> Please see the na.action= argument to moran.mc() and moran.test(); the
> default is na.fail, but can be na.exclude, which then also subsets the
> listw spatial weights object. You can also subset l before creating the
> neighbour object:
>
> library(raster)
> library(spdep)
> r <- raster(nrows=10, ncols=10)
> values(r) <- c(1:(ncell(r)-1), NA)
> l <- rasterToPolygons(r, na.rm=TRUE) # note that this subsets by default
> dim(l) # [1] 99  1
> nb.l <- poly2nb(l, queen=FALSE)
> nb.l # here no no-neighbour observations, no need for zero.policy=
> lw.l <- nb2listw(nb.l, style="W")
> moran.test(l$layer, lw.l) # default randomisation=TRUE
>
>
>
> > Finally these errors disappeared with the following version of the code--
> > see below -- the version of the code below runs OK--unless for the input
> > raster I have used-- with no more errors or problems.
> >
>
> Because rasterToPolygons() removes NA observations by default.
>
> Hope this clarifies,
>
> Roger
>
> > Therefore my question is : if instead of using arguments of the function
> > spdep::mc.moran() such as na.action = na.omit or other --which I have
> tried
> > and could not make work-- is it a valid way to solve the above errors  in
> > the way as presented in the code below?
> >
> > I would appreciate it a lot if there is a possibility of knowing what
> could
> > be wrong in the code below?
> >
> > I suspect it could be possible the problem is related to the way in which
> > the raster  data layer is converted to polygon data  im the code to be
> > input to the function spdep::mc.moran() , but will appreciate any
> guidance
> > and assistance in the issue to get working in the correct manner.
> >
> > Thanks a lot.
> > Kind regards,
> >
> > ################### Estimate of Moran's I and its p-value from a raster
> > layer ##################################
> > library(raster)
> > library(spdep)
> > library(easycsv)
> >
> > rm(list = ls())
> >
> > r<- raster(file.choose())
> > l <- rasterToPolygons(r)
> >
> > nb.l <- poly2nb(l, queen=FALSE)
> > lw.l <- nb2listw(nb.l, style="W",zero.policy=TRUE)
> >
> > v<-r[!is.na(r)]
> > M <- moran.mc((v), lw.l, 999, zero.policy=TRUE)
> > M
> >
> > plot(M, main=sprintf("Original, Moran's I (p = %0.3f)", M$p.value),
> > xlab="Monte-Carlo Simulation of Moran I", sub =NA, cex.lab=1.5,
> > cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
> > abline(v=M$statistic, col="red", lw=2)
> > dev.off()
> >
> ################################################################################################
> >
> >
>
> --
> Roger Bivand
> Emeritus Professor
> Department of Economics, Norwegian School of Economics,
> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
> e-mail: Roger.Bivand at nhh.no
> https://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>


-- 
Gabriel Cotlier, PhD
Haifa Research Center for Theoretical Physics and Astrophysics (HCTPA)
University of Haifa
Israel

	[[alternative HTML version deleted]]


From g@b|k|m01 @end|ng |rom gm@||@com  Mon Oct 25 12:29:56 2021
From: g@b|k|m01 @end|ng |rom gm@||@com (Gabriel Cotlier)
Date: Mon, 25 Oct 2021 13:29:56 +0300
Subject: [R-sig-Geo] 
 question on raster Moran's I statistical significance
In-Reply-To: <CAAKwTDELzUWCkPZB94Lw8nB1FYWp5TuTaZayRNo=YmMx5FyOSA@mail.gmail.com>
References: <CAAKwTDGq1qzdWC6S+gBL_0+=EViGOxWOx8q3qk=U-5Ui+pX+Og@mail.gmail.com>
 <764bf853-2e6-eac0-f412-9189af86850@reclus2.nhh.no>
 <CAAKwTDELzUWCkPZB94Lw8nB1FYWp5TuTaZayRNo=YmMx5FyOSA@mail.gmail.com>
Message-ID: <CAAKwTDHbO9bKdN-ih+vHtR6FWE88HGwjNEogbkMpd6O0w6C6=Q@mail.gmail.com>

Hello,

I have tried the code for most of the dataset but only few make the
same error:
> nb.l
Neighbour list object:
Number of regions: 975434
Number of nonzero links: 3869290
Percentage nonzero weights: 0.0004066638
Average number of links: 3.966737
79 regions with no links:
3206 34632 47267 65155 81013 90934 91361 91427 98318
98765 100054 100472 100884 100896 102508 102514 105207
105937 106630 106965 114449 115479 122329 123614 126880
128631 314459 350405 381283 397379 401275 412489 420698
426384 428632 429752 432058 433230 440631 451195 451196
452270 464327 467009 503242 504459 507625 510412 517865
517916 524413 526766 535269 537320 537712 544576 549519
551629 553413 565169 566421 567703 567791 568587 579209
585464 625809 642179 648122 651096 652581 654065 708908
777500 845322 846238 847153 848065 866391
> lw.l <- nb2listw(nb.l, style="W")
Error in nb2listw(nb.l, style = "W") : Empty neighbour sets found

Could it be something related to the input data layer?
How could it be possible to avoid this error for running the code?

Thanks a lot for your guidance and help.

Kind regards,
Gabriel Cotlier


On Mon, Oct 25, 2021 at 12:21 PM Gabriel Cotlier <gabiklm01 at gmail.com>
wrote:

> Thank you very much for your response.
> Yes indeed it clarifies and helps a lot.
> Kind regards,
> Gabriel Cotlier
>
> On Mon, Oct 25, 2021 at 12:00 PM Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Sat, 23 Oct 2021, Gabriel Cotlier wrote:
>>
>> > Hello,
>> >
>> > I would like to estimate the pseudo p-value of Moran's I from raster
>> data
>> > layer, by converting it to polygon data in order to be able to directly
>> use
>> > the function  spdep::mc.moran() and getting in one step not only value
>> of
>> > Moran'sI but its statistical significance without using other
>> simulations
>> > but only that in the funcion spdep::mc.moran() as an alternative I have
>> > used the code below. However, since with the initial version of the
>> code I
>> > got  several errors such as :
>> >
>> > Error in moran. mc(My_raster, lw.l, 999) : r is not a numeric vector
>> >
>> > So I converted "r" to a vector using as.vector() in :
>> >
>> > M <- moran.mc(as.vector(r), lw.l, 999)
>>
>> First, if you have the spatial weights object lw.l, spdep::moran.test(),
>> using analytical rather than bootstrap inference, is almost certainly
>> more
>> efficient, and yields almost always the same outcome with
>> randomisation=TRUE.
>>
>> >
>> > However then appeared another the error:
>> >
>> > Error in na.fail.default(x) : missing values in object
>> >
>>
>> Please see the na.action= argument to moran.mc() and moran.test(); the
>> default is na.fail, but can be na.exclude, which then also subsets the
>> listw spatial weights object. You can also subset l before creating the
>> neighbour object:
>>
>> library(raster)
>> library(spdep)
>> r <- raster(nrows=10, ncols=10)
>> values(r) <- c(1:(ncell(r)-1), NA)
>> l <- rasterToPolygons(r, na.rm=TRUE) # note that this subsets by default
>> dim(l) # [1] 99  1
>> nb.l <- poly2nb(l, queen=FALSE)
>> nb.l # here no no-neighbour observations, no need for zero.policy=
>> lw.l <- nb2listw(nb.l, style="W")
>> moran.test(l$layer, lw.l) # default randomisation=TRUE
>>
>>
>>
>> > Finally these errors disappeared with the following version of the
>> code--
>> > see below -- the version of the code below runs OK--unless for the input
>> > raster I have used-- with no more errors or problems.
>> >
>>
>> Because rasterToPolygons() removes NA observations by default.
>>
>> Hope this clarifies,
>>
>> Roger
>>
>> > Therefore my question is : if instead of using arguments of the function
>> > spdep::mc.moran() such as na.action = na.omit or other --which I have
>> tried
>> > and could not make work-- is it a valid way to solve the above errors
>> in
>> > the way as presented in the code below?
>> >
>> > I would appreciate it a lot if there is a possibility of knowing what
>> could
>> > be wrong in the code below?
>> >
>> > I suspect it could be possible the problem is related to the way in
>> which
>> > the raster  data layer is converted to polygon data  im the code to be
>> > input to the function spdep::mc.moran() , but will appreciate any
>> guidance
>> > and assistance in the issue to get working in the correct manner.
>> >
>> > Thanks a lot.
>> > Kind regards,
>> >
>> > ################### Estimate of Moran's I and its p-value from a raster
>> > layer ##################################
>> > library(raster)
>> > library(spdep)
>> > library(easycsv)
>> >
>> > rm(list = ls())
>> >
>> > r<- raster(file.choose())
>> > l <- rasterToPolygons(r)
>> >
>> > nb.l <- poly2nb(l, queen=FALSE)
>> > lw.l <- nb2listw(nb.l, style="W",zero.policy=TRUE)
>> >
>> > v<-r[!is.na(r)]
>> > M <- moran.mc((v), lw.l, 999, zero.policy=TRUE)
>> > M
>> >
>> > plot(M, main=sprintf("Original, Moran's I (p = %0.3f)", M$p.value),
>> > xlab="Monte-Carlo Simulation of Moran I", sub =NA, cex.lab=1.5,
>> > cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
>> > abline(v=M$statistic, col="red", lw=2)
>> > dev.off()
>> >
>> ################################################################################################
>> >
>> >
>>
>> --
>> Roger Bivand
>> Emeritus Professor
>> Department of Economics, Norwegian School of Economics,
>> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
>> e-mail: Roger.Bivand at nhh.no
>> https://orcid.org/0000-0003-2392-6140
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>
>
>
> --
> Gabriel Cotlier, PhD
> Haifa Research Center for Theoretical Physics and Astrophysics (HCTPA)
> University of Haifa
> Israel
>
>
>

	[[alternative HTML version deleted]]


From Roger@B|v@nd @end|ng |rom nhh@no  Mon Oct 25 13:11:41 2021
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Mon, 25 Oct 2021 13:11:41 +0200 (CEST)
Subject: [R-sig-Geo] 
 question on raster Moran's I statistical significance
In-Reply-To: <CAAKwTDHbO9bKdN-ih+vHtR6FWE88HGwjNEogbkMpd6O0w6C6=Q@mail.gmail.com>
References: <CAAKwTDGq1qzdWC6S+gBL_0+=EViGOxWOx8q3qk=U-5Ui+pX+Og@mail.gmail.com>
 <764bf853-2e6-eac0-f412-9189af86850@reclus2.nhh.no>
 <CAAKwTDELzUWCkPZB94Lw8nB1FYWp5TuTaZayRNo=YmMx5FyOSA@mail.gmail.com>
 <CAAKwTDHbO9bKdN-ih+vHtR6FWE88HGwjNEogbkMpd6O0w6C6=Q@mail.gmail.com>
Message-ID: <e4fb91c0-5a5e-6b85-a67c-c045f428b1a@reclus2.nhh.no>

On Mon, 25 Oct 2021, Gabriel Cotlier wrote:

> Hello,
>
> I have tried the code for most of the dataset but only few make the
> same error:
>> nb.l
> Neighbour list object:
> Number of regions: 975434
> Number of nonzero links: 3869290
> Percentage nonzero weights: 0.0004066638
> Average number of links: 3.966737
> 79 regions with no links:
> 3206 34632 47267 65155 81013 90934 91361 91427 98318
> 98765 100054 100472 100884 100896 102508 102514 105207
> 105937 106630 106965 114449 115479 122329 123614 126880
> 128631 314459 350405 381283 397379 401275 412489 420698
> 426384 428632 429752 432058 433230 440631 451195 451196
> 452270 464327 467009 503242 504459 507625 510412 517865
> 517916 524413 526766 535269 537320 537712 544576 549519
> 551629 553413 565169 566421 567703 567791 568587 579209
> 585464 625809 642179 648122 651096 652581 654065 708908
> 777500 845322 846238 847153 848065 866391
>> lw.l <- nb2listw(nb.l, style="W")
> Error in nb2listw(nb.l, style = "W") : Empty neighbour sets found
>
> Could it be something related to the input data layer?

Yes. Please also look at the output of spdep::n.comp.nb() if it works for 
a dataset this large, see ?n.comp.nb and examine the nc component (number 
of subgraphs). The singleton graphs have no neighbours, but there may be 
other subgraphs, you find their sizes by table(table(<comp.id 
component>)). This may well have come from the na.rm=TRUE in 
rasterToPolygons(), but is unavoidable. Maybe see also:
https://keen-swartz-3146c4.netlify.app/area.html#
and expand all code (button at top right) and search for n.comp.nc.

Since you have singleton observations, zero.policy=TRUE is your only 
option unless you further subset by omitting all the observations for 
which card(nb.l) == 0L - since they have no neighbours, they do not inform 
the spatial process.

Roger

> How could it be possible to avoid this error for running the code?
>
> Thanks a lot for your guidance and help.
>
> Kind regards,
> Gabriel Cotlier
>
>
> On Mon, Oct 25, 2021 at 12:21 PM Gabriel Cotlier <gabiklm01 at gmail.com>
> wrote:
>
>> Thank you very much for your response.
>> Yes indeed it clarifies and helps a lot.
>> Kind regards,
>> Gabriel Cotlier
>>
>> On Mon, Oct 25, 2021 at 12:00 PM Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>
>>> On Sat, 23 Oct 2021, Gabriel Cotlier wrote:
>>>
>>>> Hello,
>>>>
>>>> I would like to estimate the pseudo p-value of Moran's I from raster
>>> data
>>>> layer, by converting it to polygon data in order to be able to directly
>>> use
>>>> the function  spdep::mc.moran() and getting in one step not only value
>>> of
>>>> Moran'sI but its statistical significance without using other
>>> simulations
>>>> but only that in the funcion spdep::mc.moran() as an alternative I have
>>>> used the code below. However, since with the initial version of the
>>> code I
>>>> got  several errors such as :
>>>>
>>>> Error in moran. mc(My_raster, lw.l, 999) : r is not a numeric vector
>>>>
>>>> So I converted "r" to a vector using as.vector() in :
>>>>
>>>> M <- moran.mc(as.vector(r), lw.l, 999)
>>>
>>> First, if you have the spatial weights object lw.l, spdep::moran.test(),
>>> using analytical rather than bootstrap inference, is almost certainly
>>> more
>>> efficient, and yields almost always the same outcome with
>>> randomisation=TRUE.
>>>
>>>>
>>>> However then appeared another the error:
>>>>
>>>> Error in na.fail.default(x) : missing values in object
>>>>
>>>
>>> Please see the na.action= argument to moran.mc() and moran.test(); the
>>> default is na.fail, but can be na.exclude, which then also subsets the
>>> listw spatial weights object. You can also subset l before creating the
>>> neighbour object:
>>>
>>> library(raster)
>>> library(spdep)
>>> r <- raster(nrows=10, ncols=10)
>>> values(r) <- c(1:(ncell(r)-1), NA)
>>> l <- rasterToPolygons(r, na.rm=TRUE) # note that this subsets by default
>>> dim(l) # [1] 99  1
>>> nb.l <- poly2nb(l, queen=FALSE)
>>> nb.l # here no no-neighbour observations, no need for zero.policy=
>>> lw.l <- nb2listw(nb.l, style="W")
>>> moran.test(l$layer, lw.l) # default randomisation=TRUE
>>>
>>>
>>>
>>>> Finally these errors disappeared with the following version of the
>>> code--
>>>> see below -- the version of the code below runs OK--unless for the input
>>>> raster I have used-- with no more errors or problems.
>>>>
>>>
>>> Because rasterToPolygons() removes NA observations by default.
>>>
>>> Hope this clarifies,
>>>
>>> Roger
>>>
>>>> Therefore my question is : if instead of using arguments of the function
>>>> spdep::mc.moran() such as na.action = na.omit or other --which I have
>>> tried
>>>> and could not make work-- is it a valid way to solve the above errors
>>> in
>>>> the way as presented in the code below?
>>>>
>>>> I would appreciate it a lot if there is a possibility of knowing what
>>> could
>>>> be wrong in the code below?
>>>>
>>>> I suspect it could be possible the problem is related to the way in
>>> which
>>>> the raster  data layer is converted to polygon data  im the code to be
>>>> input to the function spdep::mc.moran() , but will appreciate any
>>> guidance
>>>> and assistance in the issue to get working in the correct manner.
>>>>
>>>> Thanks a lot.
>>>> Kind regards,
>>>>
>>>> ################### Estimate of Moran's I and its p-value from a raster
>>>> layer ##################################
>>>> library(raster)
>>>> library(spdep)
>>>> library(easycsv)
>>>>
>>>> rm(list = ls())
>>>>
>>>> r<- raster(file.choose())
>>>> l <- rasterToPolygons(r)
>>>>
>>>> nb.l <- poly2nb(l, queen=FALSE)
>>>> lw.l <- nb2listw(nb.l, style="W",zero.policy=TRUE)
>>>>
>>>> v<-r[!is.na(r)]
>>>> M <- moran.mc((v), lw.l, 999, zero.policy=TRUE)
>>>> M
>>>>
>>>> plot(M, main=sprintf("Original, Moran's I (p = %0.3f)", M$p.value),
>>>> xlab="Monte-Carlo Simulation of Moran I", sub =NA, cex.lab=1.5,
>>>> cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
>>>> abline(v=M$statistic, col="red", lw=2)
>>>> dev.off()
>>>>
>>> ################################################################################################
>>>>
>>>>
>>>
>>> --
>>> Roger Bivand
>>> Emeritus Professor
>>> Department of Economics, Norwegian School of Economics,
>>> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
>>> e-mail: Roger.Bivand at nhh.no
>>> https://orcid.org/0000-0003-2392-6140
>>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>>
>>
>>
>> --
>> Gabriel Cotlier, PhD
>> Haifa Research Center for Theoretical Physics and Astrophysics (HCTPA)
>> University of Haifa
>> Israel
>>
>>
>>
>

-- 
Roger Bivand
Emeritus Professor
Department of Economics, Norwegian School of Economics,
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From Roger@B|v@nd @end|ng |rom nhh@no  Mon Oct 25 13:43:45 2021
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Mon, 25 Oct 2021 13:43:45 +0200 (CEST)
Subject: [R-sig-Geo] 
 question on raster Moran's I statistical significance
In-Reply-To: <e4fb91c0-5a5e-6b85-a67c-c045f428b1a@reclus2.nhh.no>
References: <CAAKwTDGq1qzdWC6S+gBL_0+=EViGOxWOx8q3qk=U-5Ui+pX+Og@mail.gmail.com>
 <764bf853-2e6-eac0-f412-9189af86850@reclus2.nhh.no>
 <CAAKwTDELzUWCkPZB94Lw8nB1FYWp5TuTaZayRNo=YmMx5FyOSA@mail.gmail.com>
 <CAAKwTDHbO9bKdN-ih+vHtR6FWE88HGwjNEogbkMpd6O0w6C6=Q@mail.gmail.com>
 <e4fb91c0-5a5e-6b85-a67c-c045f428b1a@reclus2.nhh.no>
Message-ID: <e33cdbb5-5018-147-ba43-a312b5941f34@reclus2.nhh.no>

On Mon, 25 Oct 2021, Roger Bivand wrote:

> On Mon, 25 Oct 2021, Gabriel Cotlier wrote:
>
>>  Hello,
>>
>>  I have tried the code for most of the dataset but only few make the
>>  same error:
>>>  nb.l
>>  Neighbour list object:
>>  Number of regions: 975434
>>  Number of nonzero links: 3869290
>>  Percentage nonzero weights: 0.0004066638
>>  Average number of links: 3.966737
>>  79 regions with no links:
>>  3206 34632 47267 65155 81013 90934 91361 91427 98318
>>  98765 100054 100472 100884 100896 102508 102514 105207
>>  105937 106630 106965 114449 115479 122329 123614 126880
>>  128631 314459 350405 381283 397379 401275 412489 420698
>>  426384 428632 429752 432058 433230 440631 451195 451196
>>  452270 464327 467009 503242 504459 507625 510412 517865
>>  517916 524413 526766 535269 537320 537712 544576 549519
>>  551629 553413 565169 566421 567703 567791 568587 579209
>>  585464 625809 642179 648122 651096 652581 654065 708908
>>  777500 845322 846238 847153 848065 866391
>>>  lw.l <- nb2listw(nb.l, style="W")
>>  Error in nb2listw(nb.l, style = "W") : Empty neighbour sets found
>>
>>  Could it be something related to the input data layer?

An afterthought - are there any diagonal linear patterns? You have chosen 
rook not queen, so a diagonal line of cells remaining after dropping 
NAs will generate singleton observations along that line,even though they 
would have been queen neighbours as they touch at one point. What is the 
coordinnate reference system of the input raster (crs(r))?

Roger

>
> Yes. Please also look at the output of spdep::n.comp.nb() if it works for a 
> dataset this large, see ?n.comp.nb and examine the nc component (number of 
> subgraphs). The singleton graphs have no neighbours, but there may be other 
> subgraphs, you find their sizes by table(table(<comp.id 
> component>)) . This may well have come from the na.rm=TRUE in 
> rasterToPolygons(), but is unavoidable. Maybe see also:
> https://keen-swartz-3146c4.netlify.app/area.html#
> and expand all code (button at top right) and search for n.comp.nc.
>
> Since you have singleton observations, zero.policy=TRUE is your only option 
> unless you further subset by omitting all the observations for which 
> card(nb.l) == 0L - since they have no neighbours, they do not inform the 
> spatial process.
>
> Roger
>
>>  How could it be possible to avoid this error for running the code?
>>
>>  Thanks a lot for your guidance and help.
>>
>>  Kind regards,
>>  Gabriel Cotlier
>> 
>>
>>  On Mon, Oct 25, 2021 at 12:21 PM Gabriel Cotlier <gabiklm01 at gmail.com>
>>  wrote:
>>
>>>  Thank you very much for your response.
>>>  Yes indeed it clarifies and helps a lot.
>>>  Kind regards,
>>>  Gabriel Cotlier
>>>
>>>  On Mon, Oct 25, 2021 at 12:00 PM Roger Bivand <Roger.Bivand at nhh.no>
>>>  wrote:
>>>
>>>>  On Sat, 23 Oct 2021, Gabriel Cotlier wrote:
>>>>
>>>>>  Hello,
>>>>>
>>>>>  I would like to estimate the pseudo p-value of Moran's I from raster
>>>>  data
>>>>>  layer, by converting it to polygon data in order to be able to directly
>>>>  use
>>>>>  the function  spdep::mc.moran() and getting in one step not only value
>>>>  of
>>>>>  Moran'sI but its statistical significance without using other
>>>>  simulations
>>>>>  but only that in the funcion spdep::mc.moran() as an alternative I have
>>>>>  used the code below. However, since with the initial version of the
>>>>  code I
>>>>>  got  several errors such as :
>>>>>
>>>>>  Error in moran. mc(My_raster, lw.l, 999) : r is not a numeric vector
>>>>>
>>>>>  So I converted "r" to a vector using as.vector() in :
>>>>>
>>>>>  M <- moran.mc(as.vector(r), lw.l, 999)
>>>>
>>>>  First, if you have the spatial weights object lw.l, spdep::moran.test(),
>>>>  using analytical rather than bootstrap inference, is almost certainly
>>>>  more
>>>>  efficient, and yields almost always the same outcome with
>>>>  randomisation=TRUE.
>>>> 
>>>>>
>>>>>  However then appeared another the error:
>>>>>
>>>>>  Error in na.fail.default(x) : missing values in object
>>>>> 
>>>>
>>>>  Please see the na.action= argument to moran.mc() and moran.test(); the
>>>>  default is na.fail, but can be na.exclude, which then also subsets the
>>>>  listw spatial weights object. You can also subset l before creating the
>>>>  neighbour object:
>>>>
>>>>  library(raster)
>>>>  library(spdep)
>>>>  r <- raster(nrows=10, ncols=10)
>>>>  values(r) <- c(1:(ncell(r)-1), NA)
>>>>  l <- rasterToPolygons(r, na.rm=TRUE) # note that this subsets by default
>>>>  dim(l) # [1] 99  1
>>>>  nb.l <- poly2nb(l, queen=FALSE)
>>>>  nb.l # here no no-neighbour observations, no need for zero.policy=
>>>>  lw.l <- nb2listw(nb.l, style="W")
>>>>  moran.test(l$layer, lw.l) # default randomisation=TRUE
>>>> 
>>>> 
>>>>
>>>>>  Finally these errors disappeared with the following version of the
>>>>  code--
>>>>>  see below -- the version of the code below runs OK--unless for the
>>>>>  input
>>>>>  raster I have used-- with no more errors or problems.
>>>>> 
>>>>
>>>>  Because rasterToPolygons() removes NA observations by default.
>>>>
>>>>  Hope this clarifies,
>>>>
>>>>  Roger
>>>>
>>>>>  Therefore my question is : if instead of using arguments of the
>>>>>  function
>>>>>  spdep::mc.moran() such as na.action = na.omit or other --which I have
>>>>  tried
>>>>>  and could not make work-- is it a valid way to solve the above errors
>>>>  in
>>>>>  the way as presented in the code below?
>>>>>
>>>>>  I would appreciate it a lot if there is a possibility of knowing what
>>>>  could
>>>>>  be wrong in the code below?
>>>>>
>>>>>  I suspect it could be possible the problem is related to the way in
>>>>  which
>>>>>  the raster  data layer is converted to polygon data  im the code to be
>>>>>  input to the function spdep::mc.moran() , but will appreciate any
>>>>  guidance
>>>>>  and assistance in the issue to get working in the correct manner.
>>>>>
>>>>>  Thanks a lot.
>>>>>  Kind regards,
>>>>>
>>>>>  ################### Estimate of Moran's I and its p-value from a raster
>>>>>  layer ##################################
>>>>>  library(raster)
>>>>>  library(spdep)
>>>>>  library(easycsv)
>>>>>
>>>>>  rm(list = ls())
>>>>>
>>>>>  r<- raster(file.choose())
>>>>>  l <- rasterToPolygons(r)
>>>>>
>>>>>  nb.l <- poly2nb(l, queen=FALSE)
>>>>>  lw.l <- nb2listw(nb.l, style="W",zero.policy=TRUE)
>>>>>
>>>>>  v<-r[!is.na(r)]
>>>>>  M <- moran.mc((v), lw.l, 999, zero.policy=TRUE)
>>>>>  M
>>>>>
>>>>>  plot(M, main=sprintf("Original, Moran's I (p = %0.3f)", M$p.value),
>>>>>  xlab="Monte-Carlo Simulation of Moran I", sub =NA, cex.lab=1.5,
>>>>>  cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
>>>>>  abline(v=M$statistic, col="red", lw=2)
>>>>>  dev.off()
>>>>>
>>>>  ################################################################################################
>>>>> 
>>>>> 
>>>>
>>>>  --
>>>>  Roger Bivand
>>>>  Emeritus Professor
>>>>  Department of Economics, Norwegian School of Economics,
>>>>  Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
>>>>  e-mail: Roger.Bivand at nhh.no
>>>>  https://orcid.org/0000-0003-2392-6140
>>>>  https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>>> 
>>> 
>>>
>>>  --
>>>  Gabriel Cotlier, PhD
>>>  Haifa Research Center for Theoretical Physics and Astrophysics (HCTPA)
>>>  University of Haifa
>>>  Israel
>>> 
>>> 
>>> 
>> 
>
>

-- 
Roger Bivand
Emeritus Professor
Department of Economics, Norwegian School of Economics,
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From g@b|k|m01 @end|ng |rom gm@||@com  Mon Oct 25 14:27:01 2021
From: g@b|k|m01 @end|ng |rom gm@||@com (Gabriel Cotlier)
Date: Mon, 25 Oct 2021 15:27:01 +0300
Subject: [R-sig-Geo] 
 question on raster Moran's I statistical significance
In-Reply-To: <e4fb91c0-5a5e-6b85-a67c-c045f428b1a@reclus2.nhh.no>
References: <CAAKwTDGq1qzdWC6S+gBL_0+=EViGOxWOx8q3qk=U-5Ui+pX+Og@mail.gmail.com>
 <764bf853-2e6-eac0-f412-9189af86850@reclus2.nhh.no>
 <CAAKwTDELzUWCkPZB94Lw8nB1FYWp5TuTaZayRNo=YmMx5FyOSA@mail.gmail.com>
 <CAAKwTDHbO9bKdN-ih+vHtR6FWE88HGwjNEogbkMpd6O0w6C6=Q@mail.gmail.com>
 <e4fb91c0-5a5e-6b85-a67c-c045f428b1a@reclus2.nhh.no>
Message-ID: <CAAKwTDEFmhGWQcbnNkeMDoOMqH_A_m=ZywvA56p8FydoUUx+Ug@mail.gmail.com>

Thanks a lot.
I will try spdep::n.comp.nb()  and read the link you suggested to me
on "Proximity and aerial data" which seems very interesting.
Maybe could it be due to the fact that the data layer of the city is
traversed by a river, which I set to na since it was not relevant for the
analysis, thus maybe from there the message "reginos with no links"?
However when I do :
> nb.l
Neighbour list object:
Number of regions: 636410
Number of nonzero links: 5060866
Percentage nonzero weights: 0.001249542
Average number of links: 7.95221
8 regions with no links:
103556 104030 104502 104970 170752 290616 291628 520687

Then, even with regions with no links, I have no error when setting
zero.policy = TRUE in nb2listw()

> lw.l <- nb2listw(nb.l, style="W",zero.policy = TRUE)

and then I can run moran.test() which gives some results :

> moran.test(l$dta, lw.l,zero.policy = TRUE) # default randomisation=TRUE

Moran I test under randomisation

data:  l$dta
weights: lw.l  n reduced by no-neighbour observations


Moran I statistic standard deviate = 1559.1, p-value <
2.2e-16
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance
     9.815120e-01     -1.571336e-06      3.963186e-07

Why could it be running apparently ok in this way ?

Thanks a lot again for your help and guidance.
Kind regards,
Gabriel Cotlier



On Mon, Oct 25, 2021 at 2:12 PM Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Mon, 25 Oct 2021, Gabriel Cotlier wrote:
>
> > Hello,
> >
> > I have tried the code for most of the dataset but only few make the
> > same error:
> >> nb.l
> > Neighbour list object:
> > Number of regions: 975434
> > Number of nonzero links: 3869290
> > Percentage nonzero weights: 0.0004066638
> > Average number of links: 3.966737
> > 79 regions with no links:
> > 3206 34632 47267 65155 81013 90934 91361 91427 98318
> > 98765 100054 100472 100884 100896 102508 102514 105207
> > 105937 106630 106965 114449 115479 122329 123614 126880
> > 128631 314459 350405 381283 397379 401275 412489 420698
> > 426384 428632 429752 432058 433230 440631 451195 451196
> > 452270 464327 467009 503242 504459 507625 510412 517865
> > 517916 524413 526766 535269 537320 537712 544576 549519
> > 551629 553413 565169 566421 567703 567791 568587 579209
> > 585464 625809 642179 648122 651096 652581 654065 708908
> > 777500 845322 846238 847153 848065 866391
> >> lw.l <- nb2listw(nb.l, style="W")
> > Error in nb2listw(nb.l, style = "W") : Empty neighbour sets found
> >
> > Could it be something related to the input data layer?
>
> Yes. Please also look at the output of spdep::n.comp.nb() if it works for
> a dataset this large, see ?n.comp.nb and examine the nc component (number
> of subgraphs). The singleton graphs have no neighbours, but there may be
> other subgraphs, you find their sizes by table(table(<comp.id
> component>)). This may well have come from the na.rm=TRUE in
> rasterToPolygons(), but is unavoidable. Maybe see also:
> https://keen-swartz-3146c4.netlify.app/area.html#
> and expand all code (button at top right) and search for n.comp.nc.
>
> Since you have singleton observations, zero.policy=TRUE is your only
> option unless you further subset by omitting all the observations for
> which card(nb.l) == 0L - since they have no neighbours, they do not inform
> the spatial process.
>
> Roger
>
> > How could it be possible to avoid this error for running the code?
> >
> > Thanks a lot for your guidance and help.
> >
> > Kind regards,
> > Gabriel Cotlier
> >
> >
> > On Mon, Oct 25, 2021 at 12:21 PM Gabriel Cotlier <gabiklm01 at gmail.com>
> > wrote:
> >
> >> Thank you very much for your response.
> >> Yes indeed it clarifies and helps a lot.
> >> Kind regards,
> >> Gabriel Cotlier
> >>
> >> On Mon, Oct 25, 2021 at 12:00 PM Roger Bivand <Roger.Bivand at nhh.no>
> wrote:
> >>
> >>> On Sat, 23 Oct 2021, Gabriel Cotlier wrote:
> >>>
> >>>> Hello,
> >>>>
> >>>> I would like to estimate the pseudo p-value of Moran's I from raster
> >>> data
> >>>> layer, by converting it to polygon data in order to be able to
> directly
> >>> use
> >>>> the function  spdep::mc.moran() and getting in one step not only value
> >>> of
> >>>> Moran'sI but its statistical significance without using other
> >>> simulations
> >>>> but only that in the funcion spdep::mc.moran() as an alternative I
> have
> >>>> used the code below. However, since with the initial version of the
> >>> code I
> >>>> got  several errors such as :
> >>>>
> >>>> Error in moran. mc(My_raster, lw.l, 999) : r is not a numeric vector
> >>>>
> >>>> So I converted "r" to a vector using as.vector() in :
> >>>>
> >>>> M <- moran.mc(as.vector(r), lw.l, 999)
> >>>
> >>> First, if you have the spatial weights object lw.l,
> spdep::moran.test(),
> >>> using analytical rather than bootstrap inference, is almost certainly
> >>> more
> >>> efficient, and yields almost always the same outcome with
> >>> randomisation=TRUE.
> >>>
> >>>>
> >>>> However then appeared another the error:
> >>>>
> >>>> Error in na.fail.default(x) : missing values in object
> >>>>
> >>>
> >>> Please see the na.action= argument to moran.mc() and moran.test(); the
> >>> default is na.fail, but can be na.exclude, which then also subsets the
> >>> listw spatial weights object. You can also subset l before creating the
> >>> neighbour object:
> >>>
> >>> library(raster)
> >>> library(spdep)
> >>> r <- raster(nrows=10, ncols=10)
> >>> values(r) <- c(1:(ncell(r)-1), NA)
> >>> l <- rasterToPolygons(r, na.rm=TRUE) # note that this subsets by
> default
> >>> dim(l) # [1] 99  1
> >>> nb.l <- poly2nb(l, queen=FALSE)
> >>> nb.l # here no no-neighbour observations, no need for zero.policy=
> >>> lw.l <- nb2listw(nb.l, style="W")
> >>> moran.test(l$layer, lw.l) # default randomisation=TRUE
> >>>
> >>>
> >>>
> >>>> Finally these errors disappeared with the following version of the
> >>> code--
> >>>> see below -- the version of the code below runs OK--unless for the
> input
> >>>> raster I have used-- with no more errors or problems.
> >>>>
> >>>
> >>> Because rasterToPolygons() removes NA observations by default.
> >>>
> >>> Hope this clarifies,
> >>>
> >>> Roger
> >>>
> >>>> Therefore my question is : if instead of using arguments of the
> function
> >>>> spdep::mc.moran() such as na.action = na.omit or other --which I have
> >>> tried
> >>>> and could not make work-- is it a valid way to solve the above errors
> >>> in
> >>>> the way as presented in the code below?
> >>>>
> >>>> I would appreciate it a lot if there is a possibility of knowing what
> >>> could
> >>>> be wrong in the code below?
> >>>>
> >>>> I suspect it could be possible the problem is related to the way in
> >>> which
> >>>> the raster  data layer is converted to polygon data  im the code to be
> >>>> input to the function spdep::mc.moran() , but will appreciate any
> >>> guidance
> >>>> and assistance in the issue to get working in the correct manner.
> >>>>
> >>>> Thanks a lot.
> >>>> Kind regards,
> >>>>
> >>>> ################### Estimate of Moran's I and its p-value from a
> raster
> >>>> layer ##################################
> >>>> library(raster)
> >>>> library(spdep)
> >>>> library(easycsv)
> >>>>
> >>>> rm(list = ls())
> >>>>
> >>>> r<- raster(file.choose())
> >>>> l <- rasterToPolygons(r)
> >>>>
> >>>> nb.l <- poly2nb(l, queen=FALSE)
> >>>> lw.l <- nb2listw(nb.l, style="W",zero.policy=TRUE)
> >>>>
> >>>> v<-r[!is.na(r)]
> >>>> M <- moran.mc((v), lw.l, 999, zero.policy=TRUE)
> >>>> M
> >>>>
> >>>> plot(M, main=sprintf("Original, Moran's I (p = %0.3f)", M$p.value),
> >>>> xlab="Monte-Carlo Simulation of Moran I", sub =NA, cex.lab=1.5,
> >>>> cex.axis=1.5, cex.main=1.5, cex.sub=1.5)
> >>>> abline(v=M$statistic, col="red", lw=2)
> >>>> dev.off()
> >>>>
> >>>
> ################################################################################################
> >>>>
> >>>>
> >>>
> >>> --
> >>> Roger Bivand
> >>> Emeritus Professor
> >>> Department of Economics, Norwegian School of Economics,
> >>> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
> >>> e-mail: Roger.Bivand at nhh.no
> >>> https://orcid.org/0000-0003-2392-6140
> >>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
> >>>
> >>
> >>
> >> --
> >> Gabriel Cotlier, PhD
> >> Haifa Research Center for Theoretical Physics and Astrophysics (HCTPA)
> >> University of Haifa
> >> Israel
> >>
> >>
> >>
> >
>
> --
> Roger Bivand
> Emeritus Professor
> Department of Economics, Norwegian School of Economics,
> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
> e-mail: Roger.Bivand at nhh.no
> https://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>

	[[alternative HTML version deleted]]


