From ljlayne at unm.edu  Mon Apr  3 22:46:15 2006
From: ljlayne at unm.edu (Larry Layne)
Date: Mon, 03 Apr 2006 14:46:15 -0600
Subject: [R-sig-Geo] Mean Effects SAR Model
Message-ID: <057DCCEF9A7EED069D8B8BD1@dhcp-129-24-91-249.unm.edu>

Hello!

I would like to estimate the parameters for the SAR model: Y = pWY + XB + 
e, as a pure mean effects model for Y. I want to use the residuals from 
this model in other analyses. I attempted to use lagsarlm from the spdep 
library to do this. I do not know how to specify a mean effects only 
regression model in either lagsarlm or lm, I suppose. For lagsarlm I 
assumed that I could specify 1 regressor as X1 = 0, and the model syntax as 
Y ~ X1. I thought this would leave only the intercept term, B0, and pWY, 
and I could just extract the residuals from the output. Unfortunately I 
only get an error. If I use real data in the variable X1 and specify the 
model as Y ~ X1, the function runs without error, but has parameter 
estimates for B0, B1 and p. Does anyone know if it is possible to compute 
the parameter estimates for a pure mean effects model in lagsarlm, and if 
so, how the syntax should be specified in the function? Should I be using 
something like errorsarlm instead?

Larry Layne
ljlayne at unm.edu



From Roger.Bivand at nhh.no  Mon Apr  3 23:01:05 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 3 Apr 2006 23:01:05 +0200 (CEST)
Subject: [R-sig-Geo] Mean Effects SAR Model
In-Reply-To: <057DCCEF9A7EED069D8B8BD1@dhcp-129-24-91-249.unm.edu>
Message-ID: <Pine.LNX.4.44.0604032252510.5939-100000@reclus.nhh.no>

On Mon, 3 Apr 2006, Larry Layne wrote:

> Hello!
> 
> I would like to estimate the parameters for the SAR model: Y = pWY + XB + 
> e, as a pure mean effects model for Y. 

What is a mean effects model when it is not in your dialect of data 
analysis?

Try:

lm(Y ~ 1)
mean(Y)

If you mean lagsarlm() with just the intercept on the right hand side, 
please see ?formula:

lagsarlm(Y ~ 1, ...) will just fit an intercept (as will the equivalent
call to errorsarlm(), but of course giving a different intercept). There
has to be a right hand side of the formula, though, Y ~ 0 will not work.

Roger

> I want to use the residuals from 
> this model in other analyses. I attempted to use lagsarlm from the spdep 
> library to do this. I do not know how to specify a mean effects only 
> regression model in either lagsarlm or lm, I suppose. For lagsarlm I 
> assumed that I could specify 1 regressor as X1 = 0, and the model syntax as 
> Y ~ X1. I thought this would leave only the intercept term, B0, and pWY, 
> and I could just extract the residuals from the output. Unfortunately I 
> only get an error. If I use real data in the variable X1 and specify the 
> model as Y ~ X1, the function runs without error, but has parameter 
> estimates for B0, B1 and p. Does anyone know if it is possible to compute 
> the parameter estimates for a pure mean effects model in lagsarlm, and if 
> so, how the syntax should be specified in the function? Should I be using 
> something like errorsarlm instead?
> 
> Larry Layne
> ljlayne at unm.edu
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ljlayne at unm.edu  Mon Apr  3 23:23:42 2006
From: ljlayne at unm.edu (Larry Layne)
Date: Mon, 03 Apr 2006 15:23:42 -0600
Subject: [R-sig-Geo] Mean Effects SAR Model
In-Reply-To: <Pine.LNX.4.44.0604032252510.5939-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0604032252510.5939-100000@reclus.nhh.no>
Message-ID: <DA68F60543A4AFAE2F2A5E3F@dhcp-129-24-91-249.unm.edu>

>> I would like to estimate the parameters for the SAR model: Y = pWY + XB
>> +  e, as a pure mean effects model for Y.
>
> What is a mean effects model when it is not in your dialect of data
> analysis?

It means exactly what you say below:

> If you mean lagsarlm() with just the intercept on the right hand side,
> please see ?formula:
>
> lagsarlm(Y ~ 1, ...) will just fit an intercept...

If I specify the model syntax lagsarlm(Y ~ 1, ...) I get:

Spatial lag model
Jacobian calculated using sparse matrix techniques using SparseM
Error: subscript out of bounds

Any idea what subscript the program is talking about?



From Roger.Bivand at nhh.no  Mon Apr  3 23:49:33 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 3 Apr 2006 23:49:33 +0200 (CEST)
Subject: [R-sig-Geo] Mean Effects SAR Model
In-Reply-To: <DA68F60543A4AFAE2F2A5E3F@dhcp-129-24-91-249.unm.edu>
Message-ID: <Pine.LNX.4.44.0604032336310.5939-100000@reclus.nhh.no>

On Mon, 3 Apr 2006, Larry Layne wrote:

> >> I would like to estimate the parameters for the SAR model: Y = pWY + XB
> >> +  e, as a pure mean effects model for Y.
> >
> > What is a mean effects model when it is not in your dialect of data
> > analysis?
> 
> It means exactly what you say below:

(thought so!)

> 
> > If you mean lagsarlm() with just the intercept on the right hand side,
> > please see ?formula:
> >
> > lagsarlm(Y ~ 1, ...) will just fit an intercept...
> 
> If I specify the model syntax lagsarlm(Y ~ 1, ...) I get:
> 
> Spatial lag model
> Jacobian calculated using sparse matrix techniques using SparseM
> Error: subscript out of bounds
> 
> Any idea what subscript the program is talking about?

OK. I can replicate this - there is still a bug in handling intercept-only
models in lagsarlm() with method="SparseM"; it was partly fixed in January
2005. The equivalent model for errorsarlm() works:

library(spdep)
data(columbus)
#lagsarlm(CRIME ~ 1, data=columbus, nb2listw(col.gal.nb), method="SparseM")
try1 <- residuals(errorsarlm(CRIME ~ 1, data=columbus, 
  nb2listw(col.gal.nb), method="SparseM"))
try2 <- residuals(lagsarlm(CRIME ~ 1, data=columbus, 
  nb2listw(col.gal.nb), method="eigen"))
all.equal(try1, try2, tol=1e-07)

and the residuals are the same as for the lag model, as you can see. I'll
try to fix the problem tomorrow.

Thanks for a helpful report.

Roger

> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ljlayne at unm.edu  Tue Apr  4 00:36:48 2006
From: ljlayne at unm.edu (Larry Layne)
Date: Mon, 03 Apr 2006 16:36:48 -0600
Subject: [R-sig-Geo] Mean Effects SAR Model
In-Reply-To: <Pine.LNX.4.44.0604032336310.5939-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0604032336310.5939-100000@reclus.nhh.no>
Message-ID: <64D8DAE868DAFD4568188922@dhcp-129-24-91-249.unm.edu>

--On Monday, April 03, 2006 Roger Bivand wrote:

> OK. I can replicate this - there is still a bug in handling intercept-only
> models in lagsarlm() with method="SparseM"; it was partly fixed in January
> 2005. The equivalent model for errorsarlm() works:
>
> and the residuals are the same as for the lag model, as you can see. I'll
> try to fix the problem tomorrow.
>
> Thanks for a helpful report.

Thanks very much for your help. Using residuals(lagsarlm(Y ~ 
1,method="eigen")) computes what I am looking for. Not sure why I was being 
so dense with respect to specifying an intercept-only model. One of those 
days.

Larry



From Roger.Bivand at nhh.no  Tue Apr  4 09:06:40 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 4 Apr 2006 09:06:40 +0200 (CEST)
Subject: [R-sig-Geo] Mean Effects SAR Model
In-Reply-To: <64D8DAE868DAFD4568188922@dhcp-129-24-91-249.unm.edu>
Message-ID: <Pine.LNX.4.44.0604040905240.6689-100000@reclus.nhh.no>

On Mon, 3 Apr 2006, Larry Layne wrote:

> --On Monday, April 03, 2006 Roger Bivand wrote:
> 
> > OK. I can replicate this - there is still a bug in handling intercept-only
> > models in lagsarlm() with method="SparseM"; it was partly fixed in January
> > 2005. The equivalent model for errorsarlm() works:
> >
> > and the residuals are the same as for the lag model, as you can see. I'll
> > try to fix the problem tomorrow.
> >
> > Thanks for a helpful report.
> 
> Thanks very much for your help. Using residuals(lagsarlm(Y ~ 
> 1,method="eigen")) computes what I am looking for. Not sure why I was being 
> so dense with respect to specifying an intercept-only model. One of those 
> days.

The fix for the bug will be in the next release of spdep (0.3-23 or later)

Roger

> 
> Larry
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From csima.g at met.hu  Tue Apr  4 11:39:40 2006
From: csima.g at met.hu (Csima Gabriella)
Date: Tue, 4 Apr 2006 11:39:40 +0200
Subject: [R-sig-Geo] interpolation in R
Message-ID: <003401c657cb$b2775360$1e0110ac@PC2122>

Dear Everyone!
I am a meteorologist in Hungary and a beginner of using R. I would need a
function in R that can interpolate data from irregular places
(meteorological stations) to regular places (gridpoints). If you know this
kind of function, write me the name of the function and its library.
Thanks very much in advance!
Gabriella Csima
csima.g at met.hu



From e.pebesma at geo.uu.nl  Tue Apr  4 11:51:37 2006
From: e.pebesma at geo.uu.nl (Edzer J. Pebesma)
Date: Tue, 04 Apr 2006 11:51:37 +0200
Subject: [R-sig-Geo] interpolation in R
In-Reply-To: <003401c657cb$b2775360$1e0110ac@PC2122>
References: <003401c657cb$b2775360$1e0110ac@PC2122>
Message-ID: <443241A9.9030802@geo.uu.nl>

Csima Gabriella wrote:
> Dear Everyone!
> I am a meteorologist in Hungary and a beginner of using R. I would need a
> function in R that can interpolate data from irregular places
> (meteorological stations) to regular places (gridpoints). If you know this
> kind of function, write me the name of the function and its library.
>   
function idw in package gstat.

It uses inverse distance weighted interpolation.
--
Edzer



From ernesto at ipimar.pt  Tue Apr  4 11:57:59 2006
From: ernesto at ipimar.pt (ernesto)
Date: Tue, 04 Apr 2006 10:57:59 +0100
Subject: [R-sig-Geo] interpolation in R
In-Reply-To: <003401c657cb$b2775360$1e0110ac@PC2122>
References: <003401c657cb$b2775360$1e0110ac@PC2122>
Message-ID: <44324327.1010403@ipimar.pt>

Csima Gabriella wrote:

>Dear Everyone!
>I am a meteorologist in Hungary and a beginner of using R. I would need a
>function in R that can interpolate data from irregular places
>(meteorological stations) to regular places (gridpoints). If you know this
>kind of function, write me the name of the function and its library.
>Thanks very much in advance!
>Gabriella Csima
>csima.g at met.hu
>  
>

Hi Gabriella,

There's a lot of functions doing it in R (as usual ...).

I guess the simplest one is "interp" from "akima" package but you can
take a look at http://r-spatial.sourceforge.net/ for more info on
spatial stats with R.

One way to look for functions is with the RSiteSearch() function. Try
RSiteSearch("interpolation") within your R section.

Regards

EJ



From hi_ono2001 at ybb.ne.jp  Tue Apr  4 12:27:11 2006
From: hi_ono2001 at ybb.ne.jp (Hisaji ONO)
Date: Tue, 4 Apr 2006 19:27:11 +0900 (JST)
Subject: [R-sig-Geo] interpolation in R
In-Reply-To: <003401c657cb$b2775360$1e0110ac@PC2122>
Message-ID: <20060404102711.50918.qmail@web10703.mail.bbt.yahoo.co.jp>

Hi.

 Fields package has Tps function which can execute Thin
Plate Spline(ESRI ArcGIS's Spatial Analyst extension can
do this method.) and Krig function for krigging.

 In GIS, for interpolation, TIN is popular. R has Tripack,
however no interpolation functions.



                                     Regards.



From danbebber at forestecology.co.uk  Tue Apr  4 12:30:47 2006
From: danbebber at forestecology.co.uk (Dan Bebber)
Date: Tue, 4 Apr 2006 11:30:47 +0100
Subject: [R-sig-Geo] R-sig-Geo Digest, Vol 32, Issue 1
References: <mailman.15.1144144805.19267.r-sig-geo@stat.math.ethz.ch>
Message-ID: <001301c657d2$d655e560$d22401a3@plants.ox.ac.uk>

Hi Gabriella,

there are a bewildering array of functions that do spatial interpolation, 
located in several packages.
If you have a good statistical knowledge you may wish to use geostatistical 
functions (variograms followed by kriging). I wouldn't recommend 
geostatistics without knowledge of its assumptions. Geostatistics are 
available in packages geoR, sgeostat, gstat, RandomFields, fields, and 
spatial.
If you are a beginner, then something like interp() in the library(akima), 
loess in library(stats), surf.ls in library(spatial), splint, image.smooth, 
and interp.surface in library(fields) will give you various types of 
interpolation.
There may be accepted ways of interpolating in meteorology, so I would look 
in the appropriate literature.

Then there is the question of viewing your gridded data. Again, there are 
many, many ways of doing this in R...

Dan Bebber

Department of Plant Sciences
University of Oxford

> ------------------------------
>
> Message: 7
> Date: Tue, 4 Apr 2006 11:39:40 +0200
> From: "Csima Gabriella" <csima.g at met.hu>
> Subject: [R-sig-Geo] interpolation in R
> To: <r-sig-geo at stat.math.ethz.ch>
> Message-ID: <003401c657cb$b2775360$1e0110ac at PC2122>
> Content-Type: text/plain; charset="iso-8859-2"
>
> Dear Everyone!
> I am a meteorologist in Hungary and a beginner of using R. I would need a
> function in R that can interpolate data from irregular places
> (meteorological stations) to regular places (gridpoints). If you know this
> kind of function, write me the name of the function and its library.
> Thanks very much in advance!
> Gabriella Csima
> csima.g at met.hu
>
>
>



From r at swisscarto.ch  Tue Apr  4 12:51:45 2006
From: r at swisscarto.ch (r)
Date: Tue, 04 Apr 2006 12:51:45 +0200
Subject: [R-sig-Geo] Getting polygons from list of lines
Message-ID: <WorldClient-F200604041251.AA51450513@swisscarto.ch>

Hello,

I have got a list of lines given by a line number, the x and y coordinates of the start-point and 
of the end-point, like this:

LineNumber    X1     Y1     X2     Y2
1             64     169    108    162
2             108    162    141    179
3             108    162    119    133
4             141    179    188    179
5             188    179    168    134
6             188    179    233    152
7             233    152    229    117
8             229    117    168    134
9             168    134    119    133
10            119    133    37     132
11            37     132    64     169
12            83     93     37     132
13            83     93     139    96
14            139    96     119    133
15            139    96     197    85
16            197    85     229    117

These lines form a couple of simple polygons. Now I would like to have a list with the polygons 
delimited by these lines (for plotting and export into a external text file). Does anyone know a 
way how to do such a line-to-polygon conversion with R? Is there somewhere a package with 
such a function?

I did some search especially within the spatial packages, but I didn't find something.

Cheers,
Christian



From epistat at gmail.com  Tue Apr  4 16:24:59 2006
From: epistat at gmail.com (zhijie zhang)
Date: Tue, 4 Apr 2006 22:24:59 +0800
Subject: [R-sig-Geo] interpolation in R
Message-ID: <2fc17e30604040724x6141d2dclcb650738bf05467b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060404/e1aeb9df/attachment.pl>

From epistat at gmail.com  Wed Apr  5 07:47:09 2006
From: epistat at gmail.com (zhijie zhang)
Date: Wed, 5 Apr 2006 13:47:09 +0800
Subject: [R-sig-Geo] question on spatial bootstrap /Jackknife ......etc
Message-ID: <2fc17e30604042247s64985474u240d017a332b7092@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060405/d4134422/attachment.pl>

From epistat at gmail.com  Wed Apr  5 08:19:53 2006
From: epistat at gmail.com (zhijie zhang)
Date: Wed, 5 Apr 2006 14:19:53 +0800
Subject: [R-sig-Geo] confused by coordinates
Message-ID: <2fc17e30604042319t1d92c033m93f7bad422e2f361@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060405/76838220/attachment.pl>

From jason at veracis.net  Wed Apr  5 15:01:22 2006
From: jason at veracis.net (Jason Dalton)
Date: Wed, 5 Apr 2006 09:01:22 -0400
Subject: [R-sig-Geo] Viewing GeoTIFFs
In-Reply-To: <mailman.15.1144231205.29109.r-sig-geo@stat.math.ethz.ch>
Message-ID: <000b01c658b1$0a7a4a00$8201a8c0@spadac.com>

I haven't found a package to view GeoTiff imagery in R. Does anyone know of
one that may work?  The GeoTIFF is not compatible with most TIFF viewing
software, the headers are different.  GRASS can view them, but I'd rather
not run GRASS every time I need to check my code output.

Thanks,
Jason Dalton



From Roger.Bivand at nhh.no  Wed Apr  5 15:18:31 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 5 Apr 2006 15:18:31 +0200 (CEST)
Subject: [R-sig-Geo] Viewing GeoTIFFs
In-Reply-To: <000b01c658b1$0a7a4a00$8201a8c0@spadac.com>
Message-ID: <Pine.LNX.4.44.0604051516290.8646-100000@reclus.nhh.no>

On Wed, 5 Apr 2006, Jason Dalton wrote:

> I haven't found a package to view GeoTiff imagery in R. Does anyone know of
> one that may work?  The GeoTIFF is not compatible with most TIFF viewing
> software, the headers are different.  GRASS can view them, but I'd rather
> not run GRASS every time I need to check my code output.
> 

Which platform are you using?

If you can install rgdal, I think you will find that it reads GeoTIFFs 
nicely. You can either read larger images "by hand" using the GDAL 
interface more directly, or use readGDAL() as a wrapper returning a 
SpatialGridDataFrame object directly.

Roger

> Thanks,
> Jason Dalton
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From yud at mail.montclair.edu  Wed Apr  5 17:40:00 2006
From: yud at mail.montclair.edu (Danlin Yu)
Date: Wed, 05 Apr 2006 11:40:00 -0400
Subject: [R-sig-Geo] confused by coordinates
Message-ID: <21fdcb421fd747.21fd74721fdcb4@montclair.edu>

Zhijie:

Coordinates are probably very important in not only analysis in R, but in all environments that deal with spatial data analysis as well.

Difference between the geographical coordinates (Lat. and Long.) and the planar coordinates (the x and y) is basically the difference between spherical coordinates and Descartes' two-dimensional Cartesian coordinates. Distance measurement will be different. In addition, geographical coordinates are always associated with specific Datum (NAD27, NAD83, WGS84, etc.), with different Datum, the same location can have different Lat. and Long. Planar coordinates, on the other hand, in spatial data analysis, are usually not only associated with specific Datum, but specific projection as well (UTM, SPCS, etc.)

Coordinates are important in the field of Geology - I guess, but I would say coordinates are fundamental concepts from Cartography. Hence some good reference book in Cartography might provide further information on the question you ask.

Hope this helps.

Danlin Yu

___________________________________________
Danlin Yu, Ph.D.
Assistant Professor
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
email: yud at mail.montclair.edu

----- Original Message -----
From: zhijie zhang <epistat at gmail.com>
Date: Wednesday, April 5, 2006 2:19 am
Subject: [R-sig-Geo] confused by coordinates

> Dear Friends,
>  Coordinate  is common in geology/spatial science. There are
> latitude/longitude coordinate, x/y coordinate,......... It maybe 
> easy for
> all of you, but difficult for persons without  the background 
> knowledge of
> geology, so they can't do the correct analysis with different 
> coordinate,.In my opinion, it's very important to make clear on it 
> and its application
> with R,  can anybody with excellent knowledge obout it  give some 
> guide on
> using it with R?
> For different coordinate,
> A:
> latitude    longitude   attribute
> 
> B:
> x   y   attribute
> 
> --
> Kind Regards,
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From reeves at nceas.ucsb.edu  Wed Apr  5 19:28:18 2006
From: reeves at nceas.ucsb.edu (Rick Reeves)
Date: Wed, 05 Apr 2006 10:28:18 -0700
Subject: [R-sig-Geo] confused by coordinates
In-Reply-To: <2fc17e30604042319t1d92c033m93f7bad422e2f361@mail.gmail.com>
References: <2fc17e30604042319t1d92c033m93f7bad422e2f361@mail.gmail.com>
Message-ID: <4433FE32.1050608@nceas.ucsb.edu>

Mr. Zhang:

There are many good summaries on the Internet: Google 'spatial 
coordinate systems'

Here is a good example...
http://www.environment.sa.gov.au/mapland/sicom/sicom/tp_scs.html

Best of luck!

Rick Reeves,
UC Santa Barbara
NCEAS
www.nceas.ucsb.edu

zhijie zhang wrote:

>Dear Friends,
>  Coordinate  is common in geology/spatial science. There are
>latitude/longitude coordinate, x/y coordinate,......... It maybe easy for
>all of you, but difficult for persons without  the background knowledge of
>geology, so they can't do the correct analysis with different coordinate,.
>In my opinion, it's very important to make clear on it and its application
>with R,  can anybody with excellent knowledge obout it  give some guide on
>using it with R?
>For different coordinate,
>A:
>latitude    longitude   attribute
>
>B:
>x   y   attribute
>
>--
>Kind Regards,
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at stat.math.ethz.ch
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>  
>

-- 
Rick Reeves	
Scientific ProgrammerAnalyst
National Center for Ecological Analysis and Synthesis (NCEAS)
University of California, Santa Barbara
reeves at nceas.ucsb.edu
805 892 2533



From danbebber at forestecology.co.uk  Wed Apr  5 21:35:01 2006
From: danbebber at forestecology.co.uk (Dan Bebber)
Date: Wed, 5 Apr 2006 20:35:01 +0100
Subject: [R-sig-Geo] R-sig-Geo Digest, Vol 32, Issue 2
In-Reply-To: <mailman.15.1144231205.29109.r-sig-geo@stat.math.ethz.ch>
Message-ID: <000001c658e8$07fcc1e0$24e76958@plants.ox.ac.uk>

Zhi Jie,

1. Yes, they are related. This is nicely explained in "Numerical Ecology 2nd
Edition" by Legendre & Legendre, published by Elsevier (1997). Any other
textbooks on spatial statistics should also be useful.
2. Sorry, not sure what you mean by 'spatial bootstrap'. Do you mean
randomization tests for Moran's I? If so, look in library(spdep).

Dan Bebber
Department of Plant Sciences
University of Oxford

> ------------------------------
>
> Message: 5
> Date: Wed, 5 Apr 2006 13:47:09 +0800
> From: "zhijie zhang" <epistat at gmail.com>
> Subject: [R-sig-Geo] question on spatial bootstrap /Jackknife
> 	......etc
> To: r-sig-geo at stat.math.ethz.ch
> Message-ID:
> 	<2fc17e30604042247s64985474u240d017a332b7092 at mail.gmail.com>
> Content-Type: text/plain
>
>  Dear firends,
>   I have two questions about spatial statistics:
> 1. As we all know ,we can calculate Moran's I to evaluate the spatial
> autocorrelation and we can also visually assess the spatial
> autocorrelation
> through the Variogram in Geostatistics, Now my curiosity is what is the
> difference between the two methods? Is there any relationships
> between them?
> I am confused by them recently?
>
> 2. How to perform spatial bootstrap /Jackknife in R? which package can be
> used?
>
>   Any suggestions are welcome. Thanks in advance!
>
> --
> Kind Regards,Zhi Jie,Zhang ,PHDDepartment of EpidemiologySchool of Public
> HealthFudan UniversityTel:86-21-54237149
>
> 	[[alternative HTML version deleted]]
>
>



From jahernan at umn.edu  Wed Apr  5 21:40:56 2006
From: jahernan at umn.edu (Jose A. Hernandez)
Date: Wed, 05 Apr 2006 14:40:56 -0500
Subject: [R-sig-Geo]  question on spatial bootstrap /Jackknife ......etc
In-Reply-To: <2fc17e30604040724x6141d2dclcb650738bf05467b@mail.gmail.com>
References: <2fc17e30604040724x6141d2dclcb650738bf05467b@mail.gmail.com>
Message-ID: <44341D48.9090802@umn.edu>

Dear zhijie,

zhijie zhang wrote:
> Dear firends,
>   I have two questions about spatial statistics:
> 1. As we all know ,we can calculate Moran's I to evaluate the spatial
> autocorrelation and we can also visually assess the spatial autocorrelation
> through the Variogram in Geostatistics, Now my curiosity is what is the
> difference between the two methods? Is there any relationships between them?
> I am confused by them recently?

In simple terms, Moran's I is used with lattice data and variograms are 
used for geostatistical data. In a nutshell it all depends on what type 
of data you are working with and the assumptions that you ought to comply.

On regards of the relationships and differences of the methods I would 
recommend you to look for some books on "Applied Spatial Statistics" in 
your library.

> 
> 2. How to perform spatial bootstrap /Jackknife in R? which package can be
> used?

I know that the package gstat in R does leave-one-out crossvalidation 
kriging (krige.cv), this may be what you are looking for in terms of the 
jackknife. Edzer may correct me on this one...

Good luck,

Jose

> 
>   Any suggestions are welcome. Thanks in advance!
> 
> --
> Kind Regards,Zhi Jie,Zhang ,PHDDepartment of EpidemiologySchool of Public
> HealthFudan UniversityTel:86-21-54237149
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Jose A. Hernandez
Precision Agriculture Center
Department of Soil, Water, and Climate
University of Minnesota
1991 Upper Buford Circle
St. Paul, MN 55108

Ph. +1 (612) 625-0445, Fax. +1 (612) 625-2208



From sburden at uow.edu.au  Thu Apr  6 02:54:40 2006
From: sburden at uow.edu.au (Sandy Burden)
Date: Thu, 6 Apr 2006 10:54:40 +1000
Subject: [R-sig-Geo] Truncating polygons in R
Message-ID: <200604060055.COK96359@febris.its.uow.edu.au>

Hi,

I am trying to create polygons around a set of points within a 1*1 square to
cover the whole square.  I do not have access to a GIS based package, so I
can really only use R to do this work.

I have been creating polygons around the points using the commands
voronoi.mosaic and voronoi.polygon commands from the tripack package.  I can
then convert the polygons to a spatial polygon data frame so I can use the
polygons for other things, but I am finding that my polygons extend beyond
the boundaries of the 1*1 square.  Is there any command I can use in R to
truncate the polygons so that they don't extend beyond the boundary using
either the voronoi polygons or the spatial polygons?  Or is there a better
way to create the polygons?

Any help would be greatly appreciated.

Regards,

Sandy Burden
School of Mathematics and Applied Statistics,
University of Wollongong
sburden at uow.edu.au



From b.rowlingson at lancaster.ac.uk  Thu Apr  6 09:21:55 2006
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 06 Apr 2006 08:21:55 +0100
Subject: [R-sig-Geo] Truncating polygons in R
In-Reply-To: <200604060055.COK96359@febris.its.uow.edu.au>
References: <200604060055.COK96359@febris.its.uow.edu.au>
Message-ID: <4434C193.5030807@lancaster.ac.uk>

Sandy Burden wrote:

> I have been creating polygons around the points using the commands
> voronoi.mosaic and voronoi.polygon commands from the tripack package.  I can
> then convert the polygons to a spatial polygon data frame so I can use the
> polygons for other things, but I am finding that my polygons extend beyond
> the boundaries of the 1*1 square.  Is there any command I can use in R to
> truncate the polygons so that they don't extend beyond the boundary using
> either the voronoi polygons or the spatial polygons?  Or is there a better
> way to create the polygons?

  Off the top of my head here, but if you generate a number of extra 
points along the edges of your 1x1 square that may constrain the voronoi 
polygons of your data points to stay within the square. The spacing of 
the extra points depends on the distance from the edge to the nearest 
data point. I think!

*thinks a bit more*

Yep, place artificial points on the edges so that from any location on 
the edges, the nearest point is an artificial point rather than a data 
point. Then construct voronoi polygons from the union of the 
artificial+data points, and then only take the data point polygons. 
These will be constrained to be within the square because voronoi 
polygons define nearest neighbour areas, we know the nearest neighbour 
of any location on the edge is one of our constructed points on the 
edge, and hence that the voronoi polys for the data points are within 
the square.

  I'm also sure a diagram would explain this better!

  So the problem is now constructing the extra edge point locations. I 
think if you take all your data points and project them perpendicularly 
onto the north, south, east, and west edges you'll have a solution, but 
not the best one, just one that is simple to construct. You'll just have 
a bigger voronoi triangulation that strictly necessary. Oh lets try a 
diagram (this needs a fixed-width font).

-------------------------------------- north edge
                               3
          1
                        2               some points 1,2,3


  - now project onto north edge, we add 3 new points


---------a-------------b------c------- north edge
                               3
          1
                        2               some points 1,2,3


Now any location on the edge will be nearer to a,b, or c than any of 1,2 
or 3. The voronoi polys for 1,2 and 3 will be within the north edge.

This isn't optimal because imagine 2 is a lot further south, then you 
could get away with only needing a and c on the edge. I cant think of an 
optimal method, it probably involves constructing the voronoi polygons 
and then adding extra points and recomputing, but it is 8am here and 
I've not been awake that long...

Further details on request. And after my morning coffee. And probably 
after someone comes up with a *realy simple* solution!

Barry



From Greg.Snow at intermountainmail.org  Thu Apr  6 16:55:22 2006
From: Greg.Snow at intermountainmail.org (Gregory Snow)
Date: Thu, 6 Apr 2006 08:55:22 -0600
Subject: [R-sig-Geo] Truncating polygons in R
Message-ID: <07E228A5BE53C24CAD490193A7381BBB30E920@LP-EXCHVS07.CO.IHC.COM>

I have one suggested extension to Barry's idea.

With Barry's idea the polygons will all be inside the square, but there
will be some area in the square that is not inside any of the polygons.
If you want the entire square to be included within the polygons then
take Barrys Idea of projecting the points perpendicular to the sides,
but instead of projecting them onto the sides, project them beyond that
side so that they are the same distance from the side of the square.
Then the set of points that are equal distance from the projected point
and the original point will fall along the border of the square.
Consider the following code:

x <- runif(10)
y <- runif(10)

plot(x,y)

plot(voronoi.polygons(voronoi.mosaic(x,y)))
points(x,y)

xx <- c( x,  x,   x, -x, 2-x )
yy <- c( y, -y, 2-y,  y,   y )

plot(voronoi.polygons(voronoi.mosaic(xx,yy)))
points(x,y)


This is a little bit of overkill (you may want to delete some of the
projected points), but you can see that in the center is a set of
polygons that together form the unit square around the data points.  It
is now just a matter of extracting only those polygons.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch 
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of 
> Barry Rowlingson
> Sent: Thursday, April 06, 2006 1:22 AM
> To: sburden at uow.edu.au
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] Truncating polygons in R
> 
> Sandy Burden wrote:
> 
> > I have been creating polygons around the points using the commands 
> > voronoi.mosaic and voronoi.polygon commands from the 
> tripack package.  
> > I can then convert the polygons to a spatial polygon data 
> frame so I 
> > can use the polygons for other things, but I am finding that my 
> > polygons extend beyond the boundaries of the 1*1 square.  
> Is there any 
> > command I can use in R to truncate the polygons so that they don't 
> > extend beyond the boundary using either the voronoi polygons or the 
> > spatial polygons?  Or is there a better way to create the polygons?
> 
>   Off the top of my head here, but if you generate a number 
> of extra points along the edges of your 1x1 square that may 
> constrain the voronoi polygons of your data points to stay 
> within the square. The spacing of the extra points depends on 
> the distance from the edge to the nearest data point. I think!
> 
> *thinks a bit more*
> 
> Yep, place artificial points on the edges so that from any 
> location on the edges, the nearest point is an artificial 
> point rather than a data point. Then construct voronoi 
> polygons from the union of the 
> artificial+data points, and then only take the data point polygons. 
> These will be constrained to be within the square because 
> voronoi polygons define nearest neighbour areas, we know the 
> nearest neighbour of any location on the edge is one of our 
> constructed points on the edge, and hence that the voronoi 
> polys for the data points are within the square.
> 
>   I'm also sure a diagram would explain this better!
> 
>   So the problem is now constructing the extra edge point 
> locations. I think if you take all your data points and 
> project them perpendicularly onto the north, south, east, and 
> west edges you'll have a solution, but not the best one, just 
> one that is simple to construct. You'll just have a bigger 
> voronoi triangulation that strictly necessary. Oh lets try a 
> diagram (this needs a fixed-width font).
> 
> -------------------------------------- north edge
>                                3
>           1
>                         2               some points 1,2,3
> 
> 
>   - now project onto north edge, we add 3 new points
> 
> 
> ---------a-------------b------c------- north edge
>                                3
>           1
>                         2               some points 1,2,3
> 
> 
> Now any location on the edge will be nearer to a,b, or c than 
> any of 1,2 or 3. The voronoi polys for 1,2 and 3 will be 
> within the north edge.
> 
> This isn't optimal because imagine 2 is a lot further south, 
> then you could get away with only needing a and c on the 
> edge. I cant think of an optimal method, it probably involves 
> constructing the voronoi polygons and then adding extra 
> points and recomputing, but it is 8am here and I've not been 
> awake that long...
> 
> Further details on request. And after my morning coffee. And 
> probably after someone comes up with a *realy simple* solution!
> 
> Barry
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From B.Rowlingson at lancaster.ac.uk  Thu Apr  6 17:21:52 2006
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 06 Apr 2006 16:21:52 +0100
Subject: [R-sig-Geo] Truncating polygons in R
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBB30E920@LP-EXCHVS07.CO.IHC.COM>
References: <07E228A5BE53C24CAD490193A7381BBB30E920@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <44353210.2020704@lancaster.ac.uk>

Gregory Snow wrote:
> I have one suggested extension to Barry's idea.
> 
> With Barry's idea the polygons will all be inside the square, but there
> will be some area in the square that is not inside any of the polygons.
> If you want the entire square to be included within the polygons then
> take Barrys Idea of projecting the points perpendicular to the sides,
> but instead of projecting them onto the sides, project them beyond that
> side so that they are the same distance from the side of the square.
> Then the set of points that are equal distance from the projected point
> and the original point will fall along the border of the square.

  Nice.

  I implemented my method this afternoon and one thing I hadn't expected 
was that it can generate disconnected polygons! If you have a point over 
in a corner with not much near it the guard points round the edges can 
cut it off from the rest of the data points. Obviously the tessalation 
as a whole is connected, but when you drop the guard points' polygons 
you get an island. I suspect Greg's technique can't do that since the 
whole square is filled with polygons from your data points.

  Fun.

Barry



From abunn at whrc.org  Thu Apr  6 22:38:09 2006
From: abunn at whrc.org (Andy Bunn)
Date: Thu, 6 Apr 2006 16:38:09 -0400
Subject: [R-sig-Geo] (no subject)
In-Reply-To: <1139432943.10999.21.camel@patagonicus.keittlab.net>
Message-ID: <NEBBIPHDAMMOKDKPOFFICEOBECAA.abunn@whrc.org>

List,

I want to clip (subset) an sp object SpatialGridDataFrame using a polygon.
For instance in this example I want to create a new object of class
SpatialGridDataFrame that is clipped to the area inside the polygon on the
map.

  data(meuse.grid)
  coordinates(meuse.grid) <- ~x+y
  gridded(meuse.grid) <- T
  x = as(meuse.grid, "SpatialGridDataFrame")
  clip <- cbind(x=c(180000,180000,180500,180500,180000),
                y=c(330500,331000,331000,330500,330500))
  image(x, "dist")
  polygon(clip)
  # y = x[...clip?]


How can I go about it?

Thanks in advance, Andy



From tkeitt at mail.utexas.edu  Thu Apr  6 23:19:22 2006
From: tkeitt at mail.utexas.edu (Tim Keitt)
Date: Thu, 06 Apr 2006 16:19:22 -0500
Subject: [R-sig-Geo] (no subject)
In-Reply-To: <NEBBIPHDAMMOKDKPOFFICEOBECAA.abunn@whrc.org>
References: <NEBBIPHDAMMOKDKPOFFICEOBECAA.abunn@whrc.org>
Message-ID: <1144358362.30571.18.camel@patagonicus.keittlab.net>

We need R wrappers for:

http://www.vividsolutions.com/jts/jtshome.htm

or

http://geos.refractions.net/

My preference would be the latter.

THK

On Thu, 2006-04-06 at 16:38 -0400, Andy Bunn wrote:
> List,
> 
> I want to clip (subset) an sp object SpatialGridDataFrame using a polygon.
> For instance in this example I want to create a new object of class
> SpatialGridDataFrame that is clipped to the area inside the polygon on the
> map.
> 
>   data(meuse.grid)
>   coordinates(meuse.grid) <- ~x+y
>   gridded(meuse.grid) <- T
>   x = as(meuse.grid, "SpatialGridDataFrame")
>   clip <- cbind(x=c(180000,180000,180500,180500,180000),
>                 y=c(330500,331000,331000,330500,330500))
>   image(x, "dist")
>   polygon(clip)
>   # y = x[...clip?]
> 
> 
> How can I go about it?
> 
> Thanks in advance, Andy
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
-- 
Timothy H. Keitt
Assistant Professor
http://www.keittlab.org/
http://www.utexas.edu/directory/index.php?q=Keitt



From abunn at whrc.org  Fri Apr  7 02:04:13 2006
From: abunn at whrc.org (Andy Bunn)
Date: Thu, 6 Apr 2006 20:04:13 -0400
Subject: [R-sig-Geo] Clipping/Subsetting Sp objects (was no subject)
In-Reply-To: <1144358362.30571.18.camel@patagonicus.keittlab.net>
Message-ID: <000001c659d6$ce2bfae0$0300a8c0@BasementPC>

Hi Tim, I'm reposting b/c I forgot to include a subject line before (fried).
I'll revisit this tomorrow. 
Thx,
-Andy

-----Original Message-----
From: Tim Keitt [mailto:tkeitt at mail.utexas.edu] 
Sent: Thursday, April 06, 2006 5:19 PM
To: Andy Bunn
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] (no subject)


We need R wrappers for:

http://www.vividsolutions.com/jts/jtshome.htm

or

http://geos.refractions.net/

My preference would be the latter.

THK

On Thu, 2006-04-06 at 16:38 -0400, Andy Bunn wrote:
> List,
> 
> I want to clip (subset) an sp object SpatialGridDataFrame using a 
> polygon. For instance in this example I want to create a new object of 
> class SpatialGridDataFrame that is clipped to the area inside the 
> polygon on the map.
> 
>   data(meuse.grid)
>   coordinates(meuse.grid) <- ~x+y
>   gridded(meuse.grid) <- T
>   x = as(meuse.grid, "SpatialGridDataFrame")
>   clip <- cbind(x=c(180000,180000,180500,180500,180000),
>                 y=c(330500,331000,331000,330500,330500))
>   image(x, "dist")
>   polygon(clip)
>   # y = x[...clip?]
> 
> 
> How can I go about it?
> 
> Thanks in advance, Andy
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch 
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
-- 
Timothy H. Keitt
Assistant Professor
http://www.keittlab.org/ http://www.utexas.edu/directory/index.php?q=Keitt



From e.pebesma at geo.uu.nl  Fri Apr  7 11:30:18 2006
From: e.pebesma at geo.uu.nl (Edzer J. Pebesma)
Date: Fri, 07 Apr 2006 10:30:18 +0100
Subject: [R-sig-Geo] (no subject);
 Clipping/Subsetting Sp objects (was no subject)
In-Reply-To: <1144358362.30571.18.camel@patagonicus.keittlab.net>
References: <NEBBIPHDAMMOKDKPOFFICEOBECAA.abunn@whrc.org>
	<1144358362.30571.18.camel@patagonicus.keittlab.net>
Message-ID: <4436312A.1030200@geo.uu.nl>

Andy, Tim, the magic phrases (following your example) are:

clip.sp = SpatialPolygons(list(Polygons(list(Polygon(clip)), ID="clip")))
fullgrid(x) = FALSE
x.clip = x[!is.na(overlay(x, clip.sp)),]
image(x.clip,col="blue",add=T)

the first command creates a SpatialPolygons object from
the coordinates. Yes, this seems complex, but the class
does allow for real-world polygons, having multiple parts,
holes, islands, etc.

The second converts x from SpatialGridDataFrame into SpatialPixelsDataFrame,
which is basically an object with points and their coordinates that 
happen to lie
on a grid layout (instead of a full 2D matrix with NA's on the cells 
outside the
study region).

The third uses the overlay() method, which basically does a point-in-polygon
and returns NA for points outside any of the polygons.

I'm thinking, right now, how to do this without the fullgrid(x)=F statement,
but selection for a SpatialGridDataFrame needs rows/cols, as
in x[row_sel, col_sel, attribute_sel], so can't be done with a list of
pixel indexes. Maybe it should, but I need to be pushed for this. And
that has it's own use. Perhaps here overlay should return a matrix in this
case, and [ should accept (and understand) a matrix as first argument.

Tim Keitt wrote:

>We need R wrappers for:
>
>http://www.vividsolutions.com/jts/jtshome.htm
>
>or
>
>http://geos.refractions.net/
>
>My preference would be the latter.
>
>THK
>  
>
"We need", as in "I would like to see", yes, I agree, I would also like to
see this. In the sense of "I would put my own resources on this", I doubt
whether I would do this, or work on a (better?) interface to PostGIS.
After all, GEOS was primarily written to provide the spatial 
functionality there.

Currently we have in sp overlay methods (which mainly do point-in-polygons,
and are in development, comments more than welcome!) to combine Spatial
objects of different classes (I'm pretty sure that overlay can, or 
should be able to,
deal with Ulrich's problem posted last week to statsgrass; haven't had the
opportunity to look into it because of computer crashes) -- we also have
polygon/polygon overlay (polygon clipping) using gpclib, interfaced to sp
classes. (Is it still in spgcplib, Roger?)

What exacty do you believe, Tim, would a direct interface to GEOS add to
what we now have?

I believe that a next challenge is to make R work with massive spatial 
data sets;
rgdal does a lot for this, but for polygon and point data (think of laser
altimetry data, yielding e.g. 1e7-1e8 point observations) we may need
an out-of-memory processor (PostGIS?) that can fast retrieve selections
in local search neigbhourhoods fast (GiST?).
--
Edzer

>On Thu, 2006-04-06 at 16:38 -0400, Andy Bunn wrote:
>  
>
>>List,
>>
>>I want to clip (subset) an sp object SpatialGridDataFrame using a polygon.
>>For instance in this example I want to create a new object of class
>>SpatialGridDataFrame that is clipped to the area inside the polygon on the
>>map.
>>
>>  data(meuse.grid)
>>  coordinates(meuse.grid) <- ~x+y
>>  gridded(meuse.grid) <- T
>>  x = as(meuse.grid, "SpatialGridDataFrame")
>>  clip <- cbind(x=c(180000,180000,180500,180500,180000),
>>                y=c(330500,331000,331000,330500,330500))
>>  image(x, "dist")
>>  polygon(clip)
>>  # y = x[...clip?]
>>
>>
>>How can I go about it?
>>
>>Thanks in advance, Andy
>>
>>_______________________________________________
>>R-sig-Geo mailing list
>>R-sig-Geo at stat.math.ethz.ch
>>https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>    
>>



From Roger.Bivand at nhh.no  Fri Apr  7 12:19:04 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 7 Apr 2006 12:19:04 +0200 (CEST)
Subject: [R-sig-Geo] (no subject);
 Clipping/Subsetting Sp objects (was no subject)
In-Reply-To: <4436312A.1030200@geo.uu.nl>
Message-ID: <Pine.LNX.4.44.0604071210000.10698-100000@reclus.nhh.no>

On Fri, 7 Apr 2006, Edzer J. Pebesma wrote:

> Andy, Tim, the magic phrases (following your example) are:
> 
> clip.sp = SpatialPolygons(list(Polygons(list(Polygon(clip)), ID="clip")))
> fullgrid(x) = FALSE
> x.clip = x[!is.na(overlay(x, clip.sp)),]
> image(x.clip,col="blue",add=T)
> 
> the first command creates a SpatialPolygons object from
> the coordinates. Yes, this seems complex, but the class
> does allow for real-world polygons, having multiple parts,
> holes, islands, etc.
> 
> The second converts x from SpatialGridDataFrame into SpatialPixelsDataFrame,
> which is basically an object with points and their coordinates that 
> happen to lie
> on a grid layout (instead of a full 2D matrix with NA's on the cells 
> outside the
> study region).
> 
> The third uses the overlay() method, which basically does a point-in-polygon
> and returns NA for points outside any of the polygons.

Right, and actually also returns which Polygons object the grid centre
belongs to, so that making summary statistics on the pixels by polygons is
a matter of using one of the *apply() functions. The overlay() methods are 
pretty powerful, of course not like GOES for very large data sets, but 
surprisingly fast all the same - certainly faster than implementing robust 
bindings to external software. Another route to this is:

http://starspan.casil.ucdavis.edu/

Roger

> 
> I'm thinking, right now, how to do this without the fullgrid(x)=F statement,
> but selection for a SpatialGridDataFrame needs rows/cols, as
> in x[row_sel, col_sel, attribute_sel], so can't be done with a list of
> pixel indexes. Maybe it should, but I need to be pushed for this. And
> that has it's own use. Perhaps here overlay should return a matrix in this
> case, and [ should accept (and understand) a matrix as first argument.
> 
> Tim Keitt wrote:
> 
> >We need R wrappers for:
> >
> >http://www.vividsolutions.com/jts/jtshome.htm
> >
> >or
> >
> >http://geos.refractions.net/
> >
> >My preference would be the latter.
> >
> >THK
> >  
> >
> "We need", as in "I would like to see", yes, I agree, I would also like to
> see this. In the sense of "I would put my own resources on this", I doubt
> whether I would do this, or work on a (better?) interface to PostGIS.
> After all, GEOS was primarily written to provide the spatial 
> functionality there.
> 
> Currently we have in sp overlay methods (which mainly do point-in-polygons,
> and are in development, comments more than welcome!) to combine Spatial
> objects of different classes (I'm pretty sure that overlay can, or 
> should be able to,
> deal with Ulrich's problem posted last week to statsgrass; haven't had the
> opportunity to look into it because of computer crashes) -- we also have
> polygon/polygon overlay (polygon clipping) using gpclib, interfaced to sp
> classes. (Is it still in spgcplib, Roger?)
> 
> What exacty do you believe, Tim, would a direct interface to GEOS add to
> what we now have?
> 
> I believe that a next challenge is to make R work with massive spatial 
> data sets;
> rgdal does a lot for this, but for polygon and point data (think of laser
> altimetry data, yielding e.g. 1e7-1e8 point observations) we may need
> an out-of-memory processor (PostGIS?) that can fast retrieve selections
> in local search neigbhourhoods fast (GiST?).
> --
> Edzer
> 
> >On Thu, 2006-04-06 at 16:38 -0400, Andy Bunn wrote:
> >  
> >
> >>List,
> >>
> >>I want to clip (subset) an sp object SpatialGridDataFrame using a polygon.
> >>For instance in this example I want to create a new object of class
> >>SpatialGridDataFrame that is clipped to the area inside the polygon on the
> >>map.
> >>
> >>  data(meuse.grid)
> >>  coordinates(meuse.grid) <- ~x+y
> >>  gridded(meuse.grid) <- T
> >>  x = as(meuse.grid, "SpatialGridDataFrame")
> >>  clip <- cbind(x=c(180000,180000,180500,180500,180000),
> >>                y=c(330500,331000,331000,330500,330500))
> >>  image(x, "dist")
> >>  polygon(clip)
> >>  # y = x[...clip?]
> >>
> >>
> >>How can I go about it?
> >>
> >>Thanks in advance, Andy
> >>
> >>_______________________________________________
> >>R-sig-Geo mailing list
> >>R-sig-Geo at stat.math.ethz.ch
> >>https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>    
> >>
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From abunn at whrc.org  Fri Apr  7 15:24:20 2006
From: abunn at whrc.org (Andy Bunn)
Date: Fri, 7 Apr 2006 09:24:20 -0400
Subject: [R-sig-Geo] (no subject);
	Clipping/Subsetting Sp objects (was no subject)
In-Reply-To: <4436312A.1030200@geo.uu.nl>
Message-ID: <NEBBIPHDAMMOKDKPOFFICEOKECAA.abunn@whrc.org>

> -----Original Message-----
> From: Edzer J. Pebesma [mailto:e.pebesma at geo.uu.nl]
> Sent: Friday, April 07, 2006 5:30 AM
> To: Tim Keitt
> Cc: Andy Bunn; r-sig-geo at stat.math.ethz.ch; uleopold at science.uva.nl
> Subject: Re: [R-sig-Geo] (no subject); Clipping/Subsetting Sp objects
> (was no subject)
>
>
> Andy, Tim, the magic phrases (following your example) are:
>
> clip.sp = SpatialPolygons(list(Polygons(list(Polygon(clip)), ID="clip")))
> fullgrid(x) = FALSE
> x.clip = x[!is.na(overlay(x, clip.sp)),]
> image(x.clip,col="blue",add=T)


Edzer, Tim, and Roger: Thanks so much for the magic. That solution does
work. The only sticky bit is setting fullgrid(x) to FALSE. In my application
this takes about 25 seconds as the SpatialGridDataFrame is 1405x621. Keep up
the good work fellers.

Thanks again, Andy




>
> the first command creates a SpatialPolygons object from
> the coordinates. Yes, this seems complex, but the class
> does allow for real-world polygons, having multiple parts,
> holes, islands, etc.
>
> The second converts x from SpatialGridDataFrame into
> SpatialPixelsDataFrame,
> which is basically an object with points and their coordinates that
> happen to lie
> on a grid layout (instead of a full 2D matrix with NA's on the cells
> outside the
> study region).
>
> The third uses the overlay() method, which basically does a
> point-in-polygon
> and returns NA for points outside any of the polygons.
>
> I'm thinking, right now, how to do this without the fullgrid(x)=F
> statement,
> but selection for a SpatialGridDataFrame needs rows/cols, as
> in x[row_sel, col_sel, attribute_sel], so can't be done with a list of
> pixel indexes. Maybe it should, but I need to be pushed for this. And
> that has it's own use. Perhaps here overlay should return a matrix in this
> case, and [ should accept (and understand) a matrix as first argument.
>
> Tim Keitt wrote:
>
> >We need R wrappers for:
> >
> >http://www.vividsolutions.com/jts/jtshome.htm
> >
> >or
> >
> >http://geos.refractions.net/
> >
> >My preference would be the latter.
> >
> >THK
> >
> >
> "We need", as in "I would like to see", yes, I agree, I would also like to
> see this. In the sense of "I would put my own resources on this", I doubt
> whether I would do this, or work on a (better?) interface to PostGIS.
> After all, GEOS was primarily written to provide the spatial
> functionality there.
>
> Currently we have in sp overlay methods (which mainly do
> point-in-polygons,
> and are in development, comments more than welcome!) to combine Spatial
> objects of different classes (I'm pretty sure that overlay can, or
> should be able to,
> deal with Ulrich's problem posted last week to statsgrass; haven't had the
> opportunity to look into it because of computer crashes) -- we also have
> polygon/polygon overlay (polygon clipping) using gpclib, interfaced to sp
> classes. (Is it still in spgcplib, Roger?)
>
> What exacty do you believe, Tim, would a direct interface to GEOS add to
> what we now have?
>
> I believe that a next challenge is to make R work with massive spatial
> data sets;
> rgdal does a lot for this, but for polygon and point data (think of laser
> altimetry data, yielding e.g. 1e7-1e8 point observations) we may need
> an out-of-memory processor (PostGIS?) that can fast retrieve selections
> in local search neigbhourhoods fast (GiST?).
> --
> Edzer
>
> >On Thu, 2006-04-06 at 16:38 -0400, Andy Bunn wrote:
> >
> >
> >>List,
> >>
> >>I want to clip (subset) an sp object SpatialGridDataFrame using
> a polygon.
> >>For instance in this example I want to create a new object of class
> >>SpatialGridDataFrame that is clipped to the area inside the
> polygon on the
> >>map.
> >>
> >>  data(meuse.grid)
> >>  coordinates(meuse.grid) <- ~x+y
> >>  gridded(meuse.grid) <- T
> >>  x = as(meuse.grid, "SpatialGridDataFrame")
> >>  clip <- cbind(x=c(180000,180000,180500,180500,180000),
> >>                y=c(330500,331000,331000,330500,330500))
> >>  image(x, "dist")
> >>  polygon(clip)
> >>  # y = x[...clip?]
> >>
> >>
> >>How can I go about it?
> >>
> >>Thanks in advance, Andy
> >>
> >>_______________________________________________
> >>R-sig-Geo mailing list
> >>R-sig-Geo at stat.math.ethz.ch
> >>https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >>
>
>



From tkeitt at mail.utexas.edu  Fri Apr  7 15:39:09 2006
From: tkeitt at mail.utexas.edu (Tim Keitt)
Date: Fri, 07 Apr 2006 08:39:09 -0500
Subject: [R-sig-Geo] (no subject);
	Clipping/Subsetting Sp objects (was	no subject)
In-Reply-To: <4436312A.1030200@geo.uu.nl>
References: <NEBBIPHDAMMOKDKPOFFICEOBECAA.abunn@whrc.org>
	<1144358362.30571.18.camel@patagonicus.keittlab.net>
	<4436312A.1030200@geo.uu.nl>
Message-ID: <1144417149.21692.13.camel@patagonicus.keittlab.net>

You'll notice that I wasn't volunteering.. :-)

I guess my main comment re massive datasets, etc. is that once I learned
about the power of generic programming (we've been adapting the Boost
Graph Library to work with GIS), I always feel a great sense of waste
when I see nice algorithms chained pitifully to their data structures.
We shouldn't be writing code that depends on R to supply the data. That
will never scale. I agree that PostGIS is probably the way to go. It
would be nice if we could get PostGIS objects to masquerade as R objects
so folks need only learn one interface. Anyway, the sp stuff is a huge
step forward. Wish I had more time to work on some alternative backends.

Cheers,
Tim

On Fri, 2006-04-07 at 10:30 +0100, Edzer J. Pebesma wrote:
> "We need", as in "I would like to see", yes, I agree
-- 
Timothy H. Keitt
Assistant Professor
http://www.keittlab.org/
http://www.utexas.edu/directory/index.php?q=Keitt



From epistat at gmail.com  Sun Apr  9 12:38:22 2006
From: epistat at gmail.com (zhijie zhang)
Date: Sun, 9 Apr 2006 18:38:22 +0800
Subject: [R-sig-Geo] how to get my subset?
Message-ID: <2fc17e30604090338i61ecd9adw5940b07191f48f1a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060409/fb30448c/attachment.pl>

From Roger.Bivand at nhh.no  Sun Apr  9 20:04:16 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 9 Apr 2006 20:04:16 +0200 (CEST)
Subject: [R-sig-Geo] how to get my subset?
In-Reply-To: <2fc17e30604090338i61ecd9adw5940b07191f48f1a@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0604091953180.32033-100000@reclus.nhh.no>

On Sun, 9 Apr 2006, zhijie zhang wrote:

> Dear friends,
>  I want to do some simulations on Moran's I, but met some problems with
> subset my dataset:
> 
> First step: generate my dataset
> *x<-rnorm(20)*  # generate my attribute data
> *y<-cell2nb(4,5)*   # generate my neighbor object
> Then my dataset comprise with x(attribute data) and y(position).
> 
> Second step:subset my datset
>  I don't have any idea on how to get my subset, which is from two different
> sampling on my generated data:
> 1.random sampling:  sample 4 data randomly from my generated data;

x<-rnorm(20)
y<-cell2nb(4,5)
s1 <- sample(1:length(x), 4)
x_s1 <- x[s1]
y_s1 <- subset(y, 1:length(x) %in% s1)

(but with such a small sample, very few neighbour links will remain)


> 2.systematic sampling: Suppose the space is 1, the the subset should be like
> the following:
>  y:1 3rows,1 3 5colums
>  x: the correspding attribute data

look at attr(y, "region.id") to choose the subset, do:

rc <- do.call("rbind", strsplit(attr(y, "region.id"), ":"))

to extract the IDs as a character row, column matrix.

I'm not sure why sampling is useful here, simulations on Moran's I are 
usually done by permutations on the x values, for example by 
permutation bootstrap. There are examples among other places in 
the DCluster and spdep packages, in spdep in the example to function 
moran.mc().

>  I thought it maybe need to use index to get it , or some other better
> methods. I still can't get it through till now, could anybody help me?
>  Any suggestions or help would be greatly appreciated1
> --
> Kind Regards,Zhi Jie,Zhang ,PHD
> Department of EpidemiologySchool of Public HealthFudan
> UniversityTel:86-21-54237149
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Scott.Waichler at pnl.gov  Tue Apr 11 02:22:03 2006
From: Scott.Waichler at pnl.gov (Waichler, Scott R)
Date: Mon, 10 Apr 2006 17:22:03 -0700
Subject: [R-sig-Geo] Best way to plot cross sections of discrete-valued grids
Message-ID: <7E4C06F49D6FEB49BE4B60E5FC92ED7A03F6B049@pnlmse35.pnl.gov>


I have a 3-D grid where the values of the cells are a small number of
discrete values.  (The grid represents subsurface soil and geology
types.)  Contiguous regions of the same value are relatively few in
number and large in size in comparison to the whole domain.  I am
looking for advice on two things:

1)  What is the best way to sample the grid along any transect defined
by a line between (x1, y1) and (x2, y2), and plot the 2-D vertical cross
section?  I would like to sample not only in the orthogonal directions
defined by the grid but along any other compass bearing as well.
Lattice plotting capability is desired.

2)  Is it better to plot the same-valued regions as polygons instead of
discrete cells?  EPS plots using levelplot() tend to show the grid as
faint lines, and have large file sizes because data on each cell is
retained instead of data for single-valued regions that tend to be
relatively large.

Thanks for any help,

Scott Waichler, Senior Research Scientist
Pacific Northwest National Laboratory
scott.waichler _at_ pnl.gov
http://hydrology.pnl.gov



From B.Rowlingson at lancaster.ac.uk  Tue Apr 11 13:25:32 2006
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 11 Apr 2006 12:25:32 +0100
Subject: [R-sig-Geo] Best way to plot cross sections of discrete-valued
 grids
In-Reply-To: <7E4C06F49D6FEB49BE4B60E5FC92ED7A03F6B049@pnlmse35.pnl.gov>
References: <7E4C06F49D6FEB49BE4B60E5FC92ED7A03F6B049@pnlmse35.pnl.gov>
Message-ID: <443B922C.50902@lancaster.ac.uk>

Waichler, Scott R wrote:
> I have a 3-D grid where the values of the cells are a small number of
> discrete values.  (The grid represents subsurface soil and geology
> types.)  Contiguous regions of the same value are relatively few in
> number and large in size in comparison to the whole domain.  I am
> looking for advice on two things:
> 
> 1)  What is the best way to sample the grid along any transect defined
> by a line between (x1, y1) and (x2, y2), and plot the 2-D vertical cross
> section?  I would like to sample not only in the orthogonal directions
> defined by the grid but along any other compass bearing as well.
> Lattice plotting capability is desired.
> 

  At first I thought the best thing to do here would be to use 
contourLines to get the contiguous region boundaries and then work out 
all the intersections of the contour lines with your transect from x1,y1 
to x2,y2. But... You've got categorical data, so the contour function, 
which only works with numerical data, might get messed up...

  So I can only think that you will have to walk along the transect with 
a small step size (1/4 grid size will only miss a few corners), sampling 
from your grid as you go, ending up with a vector of coordinates and 
grid samples.

  Code to do this is fairly straightforward, depending on how complex 
your grids are - evenly spaced, defined by edges or centres, similar in 
X and Y etc etc.

Here's how simple it is using the transectGrid function what I just wrote:

   vo=list(x=1:87,y=1:61,z=volcano)
   image(vo)
   t1=transectGrid(locator(1,type='p'),locator(1,type='p'),vo)
   plot(t1[,1],t1[,3],type='l')

Just click twice. Three short R functions are attached. Hopefully thats 
the sort of thing you are looking for!

Barry


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: rowlings.rIndex.R
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060411/5e8f053f/attachment.pl>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: rowlings.rasterSampleIndices.R
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060411/5e8f053f/attachment-0001.pl>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: rowlings.transectGrid.R
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060411/5e8f053f/attachment-0002.pl>

From e.pebesma at geo.uu.nl  Tue Apr 11 13:35:14 2006
From: e.pebesma at geo.uu.nl (Edzer J. Pebesma)
Date: Tue, 11 Apr 2006 13:35:14 +0200
Subject: [R-sig-Geo] Best way to plot cross sections of discrete-valued
 grids
In-Reply-To: <7E4C06F49D6FEB49BE4B60E5FC92ED7A03F6B049@pnlmse35.pnl.gov>
References: <7E4C06F49D6FEB49BE4B60E5FC92ED7A03F6B049@pnlmse35.pnl.gov>
Message-ID: <443B9472.5080005@geo.uu.nl>

Ah, while typing this email I see Barry's contribution --
Baz, it's time that you take a closer look at what's already
in sp; we're duplicating work.

Here's my reply:

Scott, you can. Consider the following example with
random numbers (1:10) on a 3d 100x100x100 grid.

library(sp)
# create 3D grid
xyz = expand.grid(x = 1:100, y = 1:100, z = 1:100)
d = data.frame(xyz, v = sample(1:10, 1e6, replace = T))
gridded(d) = ~x+y+z
class(d)
summary(d)
# first point on line:
p1 = c(5,5,5)
# second point on line:
p2 = c(95,95,64)
rbind(p1,p2)
pts = sample.Line(rbind(p1,p2), 1000, "regular")
# select grid elements for each of 1000 points:
plot(d$v[overlay(d, pts)], type = 'l')


It "misuses" sample.Line, which was written as a spsample method
for Line objects; too bad that Line objects in sp are limited to exist
in two dimensions. Anyway, this seems to work (although I
obviously didn't just verify that the result was correct!!)

Waichler, Scott R wrote:
> I have a 3-D grid where the values of the cells are a small number of
> discrete values.  (The grid represents subsurface soil and geology
> types.)  Contiguous regions of the same value are relatively few in
> number and large in size in comparison to the whole domain.  I am
> looking for advice on two things:
>
> 1)  What is the best way to sample the grid along any transect defined
> by a line between (x1, y1) and (x2, y2), and plot the 2-D vertical cross
> section?  I would like to sample not only in the orthogonal directions
> defined by the grid but along any other compass bearing as well.
>   
See above.
> Lattice plotting capability is desired.
library(lattice)
xyplot(z~1:1000, data.frame(z = d$v[overlay(d, pts)]), type = 'l')
> 2)  Is it better to plot the same-valued regions as polygons instead of
> discrete cells?  EPS plots using levelplot() tend to show the grid as
> faint lines, and have large file sizes because data on each cell is
> retained instead of data for single-valued regions that tend to be
> relatively large.
>   
Am I correct that the lines you mention are shown in ghostview/ghostscript?
If that is the case, they result from the gs/gv anti-aliasing 
mechanism--they are
not part of the postscript. Printing to paper will not show it.

If file size is a problem, try pdf and wrap the pdf e.g. using pdflatex, 
or directly
print to bitmap formats such as png.

HTH,
--
Edzer
> Thanks for any help,
>
> Scott Waichler, Senior Research Scientist
> Pacific Northwest National Laboratory
> scott.waichler _at_ pnl.gov
> http://hydrology.pnl.gov
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From twgriffi at purdue.edu  Tue Apr 11 15:56:13 2006
From: twgriffi at purdue.edu (Griffin, Terry W)
Date: Tue, 11 Apr 2006 09:56:13 -0400
Subject: [R-sig-Geo] inverse distance weights matrix
Message-ID: <CD7951A61CF9644B8FC63A55CED4194B01A29A3F@EXCH03.purdue.lcl>

Thanks Roger,

I've been working on creating inverse distance matrices; and have been
successful in this first step.  However, as you suggested, the
connectedness of these matrices will cause procedures to be slow, even
prohibitive with my computer (P4 3Gz 1GB RAM) (ran out of RAM).

I've tried a simpler first order queen weights matrix to see if I could
get the errorsarlm model to run; but come to a different problem and an
error message:

source("spat.cot.R")
Error in solve.default(asyvar, tol = tol.solve) : 
        system is computationally singular: reciprocal condition number
= 1.16119e-019
> traceback()
6: solve.default(asyvar, tol = tol.solve)
5: solve(asyvar, tol = tol.solve)
4: errorsarlm(YLD02 ~ CLAY + DIST + PEG + ROT + SUN, data = cotton, 
       q1)
3: eval.with.vis(expr, envir, enclos)
2: eval.with.vis(ei, envir)
1: source("spat.cot.R")

where "spat.cot.R" contains:
spatcot.err<-errorsarlm(YLD02~CLAY+DIST+PEG+ROT+SUN,data=cotton, q1)

Do I need to set my tol to a different value or am I having other
issues?

Thank you,

Terry
  



-----Original Message-----
From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Sent: Saturday, March 18, 2006 3:07 PM
To: Griffin, Terry W
Cc: r-sig-geo at stat.math.ethz.ch
Subject: RE: [R-sig-Geo] inverse distance weights matrix

On Sat, 18 Mar 2006, Griffin, Terry W wrote:

> Thank you Roger,
> 
> I've posted the original shape file for the dataset on the website at:
> http://web.ics.purdue.edu/~twgriffi/R_matrix.htm
> 
> One shape file is projected while the other is not; however both sets
of
> *.dbf are identical and contain both decimal degrees and Northing and
> Easting in meters.  
> 
> I chose a <=75 meter distance threshold and a power=1.  
> 
> The final inverse distance matrix was row standardized so it is not
> symmetric. The weight characteristics you list below are nearly
> identical to those that SpaceStat provides.  

OK - it looks like this at the moment:

library(rgdal)
cotton_proj <- readOGR(".", "cotton_proj") # for shapefiles in the
current
			# working directory, first argument
plot(cotton_proj, cex=0.2, axes=TRUE)
library(spdep)
d75 <- dnearneigh(coordinates(cotton_proj), 0, 75)
dlist <- nbdists(d75, coordinates(cotton_proj))
idlist <- lapply(dlist, function(x) 1/x)
w75 <- nb2listw(d75, glist=idlist, style="W")

Characteristics of d75:

> d75
Neighbour list object:
Number of regions: 2451 
Number of nonzero links: 1182994 
Percentage nonzero weights: 19.69228 
Average number of links: 482.6577 

But:

> inMAT <- matrix(scan("cottonID75wm", sep=","), nrow=2451, ncol=2451, 
+ byrow=TRUE)
> range(rowSums(inMAT))
[1] 0.8159028 1.9115231
> d75MAT <- nb2mat(d75, glist=idlist, style="W")
> range(rowSums(d75MAT))
[1] 1 1
> w75 <- nb2listw(d75, glist=idlist, style="W")
> range(sapply(w75$weights, sum))
[1] 1 1

So something in the construction of your matrix wasn't securing row 
standardisation. The values do differ, this is the upper left corner:

> d75MAT[1:5,1:5]
        [,1]       [,2]       [,3]       [,4]       [,5]
1 0.00000000 0.06735710 0.03227068 0.02182278 0.01660474
2 0.05975093 0.00000000 0.05493976 0.02863058 0.01954588
3 0.02615210 0.05019078 0.00000000 0.05461937 0.02771729
4 0.01639324 0.02424508 0.05062943 0.00000000 0.05216365
5 0.01172946 0.01556467 0.02416008 0.04905229 0.00000000
> inMAT[1:5,1:5]
         [,1]     [,2]     [,3]     [,4]     [,5]
[1,] 0.000000 0.131420 0.061844 0.041726 0.031848
[2,] 0.101440 0.000000 0.090156 0.047180 0.032441
[3,] 0.040305 0.076122 0.000000 0.083545 0.042787
[4,] 0.023708 0.034730 0.072836 0.000000 0.076431
[5,] 0.016296 0.021506 0.033593 0.068830 0.000000
> rowSums(inMAT[1:5,])
[1] 1.911523 1.658689 1.533153 1.440908 1.379051
> rowSums(d75MAT[1:5,])
1 2 3 4 5 
1 1 1 1 1 

They are not the same matrices, although the differences are very small
- 
here I've used the shapefile points, which are stored as binary floating

point, rather than using the DBF values, which are a possibly rounded 
character representation, and that might be enough to cause the 
difference. I think you should be able to generate w75, and that it
should 
do what you need, but I'd be grateful for feedback on how you get on.

Best wishes,

Roger

PS: with numbers of neighbours between 177 and 678 (both in your matrix 
and in d75), even allowing for the dampening effect of inverse distance,

most analyses will be slow. 75m means that many sites are related to
many 
in your case. Doing:

symbols(408725, 3660800, circles=75, inches=FALSE, fg="red", add=TRUE)

on top of the earlier plot shows your chosen neighbourhood for an 
arbitrary point.

> 
> I really appreciate this.  Thank you,
> 
> Terry
> 
> 
> 
> -----Original Message-----
> From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
> Sent: Friday, March 17, 2006 5:50 PM
> To: Griffin, Terry W
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: RE: [R-sig-Geo] inverse distance weights matrix
> 
> Terry:
> 
> http://web.ics.purdue.edu/~twgriffi/mat4rf
> 
> and 
> 
> http://web.ics.purdue.edu/~twgriffi/mat4rs
> 
> throw access errors.
> 
> Do you have the coordinates and your specifications for the inverse 
> weighted neighbours (distance threshold, power if any)? 
> 
> inMAT <- matrix(scan("cottonID75wm", sep=","), nrow=2451, ncol=2451, 
>   byrow=TRUE)
> 
> does read the matrix - the weights aren't symmetric, are they?
> 
> From the weights matrix I get:
> 
> inMATlw <- mat2listw(inMAT)
> 
> print(is.symmetric.nb(inMATlw$neighbours))
> [1] TRUE
> 
> print(inMATlw$neighbours)
> Neighbour list object:
> Number of regions: 2451 
> Number of nonzero links: 1182982 
> Percentage nonzero weights: 19.69208 
> Average number of links: 482.6528 
> 
> If you could post the coordinates and your specifications, I could see
> how 
> to reproduce the weights within R if you like.
> 
> Roger
> 
> 
> On Fri, 17 Mar 2006, Griffin, Terry W wrote:
> 
> > 
> > The MATLAB routines are the Spatial Econometrics Toolbox format.  I
> > tried the read.dat2listw() in R; the code and error message for a
> small
> > matrix example is below; this uses a full matrix from MATLAB
> (realizing
> > that "read.dat2listw" is intended for sparse matrices). 
> > 
> > > mattry<-read.dat2listw("mat4rf")
> > Error in "[.default"(sn, , 1) : incorrect number of dimensions
> > > traceback()
> > 5: NextMethod("[")
> > 4: "[.factor"(sn, , 1)
> > 3: sn[, 1]
> > 2: unique(sn[, 1])
> > 1: read.dat2listw("mat4rf")
> > 
> > 
> > I'm not able to use dlmwrite in MATLAB to export the sparse matrix
so
> I
> > tried to import the full matrix into R (code is above).  The MATLAB
> code
> > I'm using came from this listserve archive.  The MATLAB code and
error
> > message are below.  I'm able to use dlmwrite to create the MATLAB
full
> > matrix (used above in the R code).
> > 
> > load testmat.GWT; A = (spconvert(testmat)); %have to change name in
> two
> > locations on this line
> > n=size(A); nobs=n(1);
> >  % Normalize matrix (adapted form LeSage 1999)
> > wt = sparse(A);
> >  [i1,j1,s1]=find(wt);
> > rsum=sum(wt);
> > for i=1:nobs;
> >             ind=find(i1==i);
> > s1(ind,1)=s1(ind,1)/rsum(1,i);
> > end;
> > [m,n] = size(wt);
> > W = sparse(i1,j1,s1,m,n);
> > S = sparse(W);
> > dlmwrite('mat4rst', S); %give the new sparse weight matrix a
permanent
> > name for R 
> > ??? Error using ==> sprintf
> > Function is not defined for sparse inputs.
> > 
> > Error in ==> dlmwrite at 172
> >         str = sprintf(format,m(i,:));
> > 
> > If anyone wants to give it a try, I've put the small example
matrices
> > and the "real" matrix up on my website at:
> > http://web.ics.purdue.edu/~twgriffi/R_matrix.htm
> > 
> > My objective is to use R for my spatial data analysis using inverse
> > distance weights matrices.  I'm struggling with the inverse distance
> > matrices.  I hope to either create these inverse distance matrices
in
> > SpaceStat then import into R or create the matrices in R.  
> > 
> > Thank you,
> > 
> > Terry
> > 
> > 
> > 
> > 
> > -----Original Message-----
> > From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
> > Sent: Friday, March 17, 2006 2:43 PM
> > To: Griffin, Terry W
> > Cc: r-sig-geo at stat.math.ethz.ch
> > Subject: Re: [R-sig-Geo] inverse distance weights matrix
> > 
> > On Thu, 16 Mar 2006, Griffin, Terry W wrote:
> > 
> > > Greetings,
> > > 
> > >  
> > > 
> > > I'm migrating from MATLAB to R and am having trouble converting
> > inverse
> > > distance weights matrix into a form usable by R.  I've created the
> > > matrix in SpaceStat (in *.FMT format) and converted to *.GWT
format
> > and
> > > also have it in MATLAB *.m format.
> > > 
> > 
> > I wonder whether your Matlab data are in the Spatial Econometrics
> > Toolbox 
> > format - if they are, you could try the read.dat2listw() function 
> > mentioned on the read.gwt2nb function help page.
> > >  
> > > 
> > > I've tried using the read.gwt2nb in R, but without success.  There
> are
> > > nearly 2,451 observations with an average of 482 linkages.  About
20
> %
> > > have nonzero weights.  Any suggestions are appreciated.
> > 
> > Without details of what you mean by "without success", it's hard to
> > offer 
> > any advice. Could you create a small example of the problems you are

> > seeing, and repost with copies of the commands you give and any
error 
> > messages? 
> > 
> > If you are seeing errors ("Error in ..." messages from R), please
also
> > type traceback() at the prompt and report the output. You could also
> put
> > the uncooperative GWT file on a website for others to try to see
what
> is
> > going on.
> > 
> > > 
> > >  
> > > 
> > > Thank you,
> > > 
> > > Terry
> > > 
> > >  
> > > 
> > >  
> > > 
> > > Terry W. Griffin
> > > 
> > > Graduate Research Assistant
> > > 
> > > Agricultural Economics
> > > 
> > > Purdue University
> > > 
> > > 403 W State St
> > > 
> > > West Lafayette, IN 47907
> > > 
> > > 765-494-4257
> > > 
> > > http://web.ics.purdue.edu/~twgriffi/
> > > <http://web.ics.purdue.edu/~twgriffi/> 
> > > 
> > >  
> > > 
> > >  
> > > 
> > > 
> > > 	[[alternative HTML version deleted]]
> > > 
> > > _______________________________________________
> > > R-sig-Geo mailing list
> > > R-sig-Geo at stat.math.ethz.ch
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > > 
> > 
> > 
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From yud at mail.montclair.edu  Tue Apr 11 16:28:18 2006
From: yud at mail.montclair.edu (Danlin Yu)
Date: Tue, 11 Apr 2006 10:28:18 -0400
Subject: [R-sig-Geo] inverse distance weights matrix
Message-ID: <a27a89df1c.9df1ca27a8@montclair.edu>

Terry:

According to my experience, if you set the tol.solve to a smaller value, i.e., smaller than the reported one at e-019, errorsarlm will work through.

Cheers,

___________________________________________
Danlin Yu, Ph.D.
Assistant Professor
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
email: yud at mail.montclair.edu

----- Original Message -----
From: "Griffin, Terry W" <twgriffi at purdue.edu>
Date: Tuesday, April 11, 2006 9:56 am
Subject: Re: [R-sig-Geo] inverse distance weights matrix

> Thanks Roger,
> 
> I've been working on creating inverse distance matrices; and have been
> successful in this first step.  However, as you suggested, the
> connectedness of these matrices will cause procedures to be slow, even
> prohibitive with my computer (P4 3Gz 1GB RAM) (ran out of RAM).
> 
> I've tried a simpler first order queen weights matrix to see if I 
> couldget the errorsarlm model to run; but come to a different 
> problem and an
> error message:
> 
> source("spat.cot.R")
> Error in solve.default(asyvar, tol = tol.solve) : 
>        system is computationally singular: reciprocal condition 
> number= 1.16119e-019
> > traceback()
> 6: solve.default(asyvar, tol = tol.solve)
> 5: solve(asyvar, tol = tol.solve)
> 4: errorsarlm(YLD02 ~ CLAY + DIST + PEG + ROT + SUN, data = 
> cotton, 
>       q1)
> 3: eval.with.vis(expr, envir, enclos)
> 2: eval.with.vis(ei, envir)
> 1: source("spat.cot.R")
> 
> where "spat.cot.R" contains:
> spatcot.err<-errorsarlm(YLD02~CLAY+DIST+PEG+ROT+SUN,data=cotton, q1)
> 
> Do I need to set my tol to a different value or am I having other
> issues?
> 
> Thank you,
> 
> Terry
>  
> 
> 
> 
> -----Original Message-----
> From: Roger Bivand [Roger.Bivand at nhh.no] 
> Sent: Saturday, March 18, 2006 3:07 PM
> To: Griffin, Terry W
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: RE: [R-sig-Geo] inverse distance weights matrix
> 
> On Sat, 18 Mar 2006, Griffin, Terry W wrote:
> 
> > Thank you Roger,
> > 
> > I've posted the original shape file for the dataset on the 
> website at:
> > http://web.ics.purdue.edu/~twgriffi/R_matrix.htm
> > 
> > One shape file is projected while the other is not; however both 
> setsof
> > *.dbf are identical and contain both decimal degrees and 
> Northing and
> > Easting in meters.  
> > 
> > I chose a <=75 meter distance threshold and a power=1.  
> > 
> > The final inverse distance matrix was row standardized so it is not
> > symmetric. The weight characteristics you list below are nearly
> > identical to those that SpaceStat provides.  
> 
> OK - it looks like this at the moment:
> 
> library(rgdal)
> cotton_proj <- readOGR(".", "cotton_proj") # for shapefiles in the
> current
>                	# working directory, first argument
> plot(cotton_proj, cex=0.2, axes=TRUE)
> library(spdep)
> d75 <- dnearneigh(coordinates(cotton_proj), 0, 75)
> dlist <- nbdists(d75, coordinates(cotton_proj))
> idlist <- lapply(dlist, function(x) 1/x)
> w75 <- nb2listw(d75, glist=idlist, style="W")
> 
> Characteristics of d75:
> 
> > d75
> Neighbour list object:
> Number of regions: 2451 
> Number of nonzero links: 1182994 
> Percentage nonzero weights: 19.69228 
> Average number of links: 482.6577 
> 
> But:
> 
> > inMAT <- matrix(scan("cottonID75wm", sep=","), nrow=2451, 
> ncol=2451, 
> + byrow=TRUE)
> > range(rowSums(inMAT))
> [1] 0.8159028 1.9115231
> > d75MAT <- nb2mat(d75, glist=idlist, style="W")
> > range(rowSums(d75MAT))
> [1] 1 1
> > w75 <- nb2listw(d75, glist=idlist, style="W")
> > range(sapply(w75$weights, sum))
> [1] 1 1
> 
> So something in the construction of your matrix wasn't securing 
> row 
> standardisation. The values do differ, this is the upper left corner:
> 
> > d75MAT[1:5,1:5]
>        [,1]       [,2]       [,3]       [,4]       [,5]
> 1 0.00000000 0.06735710 0.03227068 0.02182278 0.01660474
> 2 0.05975093 0.00000000 0.05493976 0.02863058 0.01954588
> 3 0.02615210 0.05019078 0.00000000 0.05461937 0.02771729
> 4 0.01639324 0.02424508 0.05062943 0.00000000 0.05216365
> 5 0.01172946 0.01556467 0.02416008 0.04905229 0.00000000
> > inMAT[1:5,1:5]
>         [,1]     [,2]     [,3]     [,4]     [,5]
> [1,] 0.000000 0.131420 0.061844 0.041726 0.031848
> [2,] 0.101440 0.000000 0.090156 0.047180 0.032441
> [3,] 0.040305 0.076122 0.000000 0.083545 0.042787
> [4,] 0.023708 0.034730 0.072836 0.000000 0.076431
> [5,] 0.016296 0.021506 0.033593 0.068830 0.000000
> > rowSums(inMAT[1:5,])
> [1] 1.911523 1.658689 1.533153 1.440908 1.379051
> > rowSums(d75MAT[1:5,])
> 1 2 3 4 5 
> 1 1 1 1 1 
> 
> They are not the same matrices, although the differences are very 
> small- 
> here I've used the shapefile points, which are stored as binary 
> floating
> point, rather than using the DBF values, which are a possibly 
> rounded 
> character representation, and that might be enough to cause the 
> difference. I think you should be able to generate w75, and that it
> should 
> do what you need, but I'd be grateful for feedback on how you get on.
> 
> Best wishes,
> 
> Roger
> 
> PS: with numbers of neighbours between 177 and 678 (both in your 
> matrix 
> and in d75), even allowing for the dampening effect of inverse 
> distance,
> most analyses will be slow. 75m means that many sites are related to
> many 
> in your case. Doing:
> 
> symbols(408725, 3660800, circles=75, inches=FALSE, fg="red", add=TRUE)
> 
> on top of the earlier plot shows your chosen neighbourhood for an 
> arbitrary point.
> 
> > 
> > I really appreciate this.  Thank you,
> > 
> > Terry
> > 
> > 
> > 
> > -----Original Message-----
> > From: Roger Bivand [Roger.Bivand at nhh.no] 
> > Sent: Friday, March 17, 2006 5:50 PM
> > To: Griffin, Terry W
> > Cc: r-sig-geo at stat.math.ethz.ch
> > Subject: RE: [R-sig-Geo] inverse distance weights matrix
> > 
> > Terry:
> > 
> > http://web.ics.purdue.edu/~twgriffi/mat4rf
> > 
> > and 
> > 
> > http://web.ics.purdue.edu/~twgriffi/mat4rs
> > 
> > throw access errors.
> > 
> > Do you have the coordinates and your specifications for the 
> inverse 
> > weighted neighbours (distance threshold, power if any)? 
> > 
> > inMAT <- matrix(scan("cottonID75wm", sep=","), nrow=2451, 
> ncol=2451, 
> >   byrow=TRUE)
> > 
> > does read the matrix - the weights aren't symmetric, are they?
> > 
> > From the weights matrix I get:
> > 
> > inMATlw <- mat2listw(inMAT)
> > 
> > print(is.symmetric.nb(inMATlw$neighbours))
> > [1] TRUE
> > 
> > print(inMATlw$neighbours)
> > Neighbour list object:
> > Number of regions: 2451 
> > Number of nonzero links: 1182982 
> > Percentage nonzero weights: 19.69208 
> > Average number of links: 482.6528 
> > 
> > If you could post the coordinates and your specifications, I 
> could see
> > how 
> > to reproduce the weights within R if you like.
> > 
> > Roger
> > 
> > 
> > On Fri, 17 Mar 2006, Griffin, Terry W wrote:
> > 
> > > 
> > > The MATLAB routines are the Spatial Econometrics Toolbox 
> format.  I
> > > tried the read.dat2listw() in R; the code and error message 
> for a
> > small
> > > matrix example is below; this uses a full matrix from MATLAB
> > (realizing
> > > that "read.dat2listw" is intended for sparse matrices). 
> > > 
> > > > mattry<-read.dat2listw("mat4rf")
> > > Error in "[.default"(sn, , 1) : incorrect number of dimensions
> > > > traceback()
> > > 5: NextMethod("[")
> > > 4: "[.factor"(sn, , 1)
> > > 3: sn[, 1]
> > > 2: unique(sn[, 1])
> > > 1: read.dat2listw("mat4rf")
> > > 
> > > 
> > > I'm not able to use dlmwrite in MATLAB to export the sparse matrix
> so
> > I
> > > tried to import the full matrix into R (code is above).  The 
> MATLAB> code
> > > I'm using came from this listserve archive.  The MATLAB code and
> error
> > > message are below.  I'm able to use dlmwrite to create the MATLAB
> full
> > > matrix (used above in the R code).
> > > 
> > > load testmat.GWT; A = (spconvert(testmat)); %have to change 
> name in
> > two
> > > locations on this line
> > > n=size(A); nobs=n(1);
> > >  % Normalize matrix (adapted form LeSage 1999)
> > > wt = sparse(A);
> > >  [i1,j1,s1]=find(wt);
> > > rsum=sum(wt);
> > > for i=1:nobs;
> > >             ind=find(i1==i);
> > > s1(ind,1)=s1(ind,1)/rsum(1,i);
> > > end;
> > > [m,n] = size(wt);
> > > W = sparse(i1,j1,s1,m,n);
> > > S = sparse(W);
> > > dlmwrite('mat4rst', S); %give the new sparse weight matrix a
> permanent
> > > name for R 
> > > ??? Error using ==> sprintf
> > > Function is not defined for sparse inputs.
> > > 
> > > Error in ==> dlmwrite at 172
> > >         str = sprintf(format,m(i,:));
> > > 
> > > If anyone wants to give it a try, I've put the small example
> matrices
> > > and the "real" matrix up on my website at:
> > > http://web.ics.purdue.edu/~twgriffi/R_matrix.htm
> > > 
> > > My objective is to use R for my spatial data analysis using 
> inverse> > distance weights matrices.  I'm struggling with the 
> inverse distance
> > > matrices.  I hope to either create these inverse distance matrices
> in
> > > SpaceStat then import into R or create the matrices in R.  
> > > 
> > > Thank you,
> > > 
> > > Terry
> > > 
> > > 
> > > 
> > > 
> > > -----Original Message-----
> > > From: Roger Bivand [Roger.Bivand at nhh.no] 
> > > Sent: Friday, March 17, 2006 2:43 PM
> > > To: Griffin, Terry W
> > > Cc: r-sig-geo at stat.math.ethz.ch
> > > Subject: Re: [R-sig-Geo] inverse distance weights matrix
> > > 
> > > On Thu, 16 Mar 2006, Griffin, Terry W wrote:
> > > 
> > > > Greetings,
> > > > 
> > > >  
> > > > 
> > > > I'm migrating from MATLAB to R and am having trouble converting
> > > inverse
> > > > distance weights matrix into a form usable by R.  I've 
> created the
> > > > matrix in SpaceStat (in *.FMT format) and converted to *.GWT
> format
> > > and
> > > > also have it in MATLAB *.m format.
> > > > 
> > > 
> > > I wonder whether your Matlab data are in the Spatial Econometrics
> > > Toolbox 
> > > format - if they are, you could try the read.dat2listw() 
> function 
> > > mentioned on the read.gwt2nb function help page.
> > > >  
> > > > 
> > > > I've tried using the read.gwt2nb in R, but without success.  
> There> are
> > > > nearly 2,451 observations with an average of 482 linkages.  
> About20
> > %
> > > > have nonzero weights.  Any suggestions are appreciated.
> > > 
> > > Without details of what you mean by "without success", it's 
> hard to
> > > offer 
> > > any advice. Could you create a small example of the problems 
> you are
> 
> > > seeing, and repost with copies of the commands you give and any
> error 
> > > messages? 
> > > 
> > > If you are seeing errors ("Error in ..." messages from R), please
> also
> > > type traceback() at the prompt and report the output. You 
> could also
> > put
> > > the uncooperative GWT file on a website for others to try to see
> what
> > is
> > > going on.
> > > 
> > > > 
> > > >  
> > > > 
> > > > Thank you,
> > > > 
> > > > Terry
> > > > 
> > > >  
> > > > 
> > > >  
> > > > 
> > > > Terry W. Griffin
> > > > 
> > > > Graduate Research Assistant
> > > > 
> > > > Agricultural Economics
> > > > 
> > > > Purdue University
> > > > 
> > > > 403 W State St
> > > > 
> > > > West Lafayette, IN 47907
> > > > 
> > > > 765-494-4257
> > > > 
> > > > http://web.ics.purdue.edu/~twgriffi/
> > > > <http://web.ics.purdue.edu/~twgriffi/> 
> > > > 
> > > >  
> > > > 
> > > >  
> > > > 
> > > > 
> > > > 	[[alternative HTML version deleted]]
> > > > 
> > > > _______________________________________________
> > > > R-sig-Geo mailing list
> > > > R-sig-Geo at stat.math.ethz.ch
> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > > > 
> > > 
> > > 
> > 
> > 
> 
> -- 
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian 
> School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Roger.Bivand at nhh.no  Tue Apr 11 17:21:29 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 11 Apr 2006 17:21:29 +0200 (CEST)
Subject: [R-sig-Geo] inverse distance weights matrix
In-Reply-To: <CD7951A61CF9644B8FC63A55CED4194B01A29A3F@EXCH03.purdue.lcl>
Message-ID: <Pine.LNX.4.44.0604111718080.7162-100000@reclus.nhh.no>

On Tue, 11 Apr 2006, Griffin, Terry W wrote:

> Thanks Roger,
> 
> I've been working on creating inverse distance matrices; and have been
> successful in this first step.  However, as you suggested, the
> connectedness of these matrices will cause procedures to be slow, even
> prohibitive with my computer (P4 3Gz 1GB RAM) (ran out of RAM).
> 

With an almost dense weights matrix and large n, this is difficult to 
avoid.

> I've tried a simpler first order queen weights matrix to see if I could
> get the errorsarlm model to run; but come to a different problem and an
> error message:
> 
> source("spat.cot.R")
> Error in solve.default(asyvar, tol = tol.solve) : 
>         system is computationally singular: reciprocal condition number
> = 1.16119e-019
> > traceback()
> 6: solve.default(asyvar, tol = tol.solve)
> 5: solve(asyvar, tol = tol.solve)
> 4: errorsarlm(YLD02 ~ CLAY + DIST + PEG + ROT + SUN, data = cotton, 
>        q1)
> 3: eval.with.vis(expr, envir, enclos)
> 2: eval.with.vis(ei, envir)
> 1: source("spat.cot.R")
> 
> where "spat.cot.R" contains:
> spatcot.err<-errorsarlm(YLD02~CLAY+DIST+PEG+ROT+SUN,data=cotton, q1)
> 
> Do I need to set my tol to a different value or am I having other
> issues?

Yes, as on the help page, set tol.solve=1e-19, or (at your choice) scale 
the right hand side variables to bring the coefficients nearer to a -1 to 
+1 range (like lambda), usually by multiplying by some power of 10.

Roger

> 
> Thank you,
> 
> Terry
>   
> 
> 
> 
> -----Original Message-----
> From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
> Sent: Saturday, March 18, 2006 3:07 PM
> To: Griffin, Terry W
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: RE: [R-sig-Geo] inverse distance weights matrix
> 
> On Sat, 18 Mar 2006, Griffin, Terry W wrote:
> 
> > Thank you Roger,
> > 
> > I've posted the original shape file for the dataset on the website at:
> > http://web.ics.purdue.edu/~twgriffi/R_matrix.htm
> > 
> > One shape file is projected while the other is not; however both sets
> of
> > *.dbf are identical and contain both decimal degrees and Northing and
> > Easting in meters.  
> > 
> > I chose a <=75 meter distance threshold and a power=1.  
> > 
> > The final inverse distance matrix was row standardized so it is not
> > symmetric. The weight characteristics you list below are nearly
> > identical to those that SpaceStat provides.  
> 
> OK - it looks like this at the moment:
> 
> library(rgdal)
> cotton_proj <- readOGR(".", "cotton_proj") # for shapefiles in the
> current
> 			# working directory, first argument
> plot(cotton_proj, cex=0.2, axes=TRUE)
> library(spdep)
> d75 <- dnearneigh(coordinates(cotton_proj), 0, 75)
> dlist <- nbdists(d75, coordinates(cotton_proj))
> idlist <- lapply(dlist, function(x) 1/x)
> w75 <- nb2listw(d75, glist=idlist, style="W")
> 
> Characteristics of d75:
> 
> > d75
> Neighbour list object:
> Number of regions: 2451 
> Number of nonzero links: 1182994 
> Percentage nonzero weights: 19.69228 
> Average number of links: 482.6577 
> 
> But:
> 
> > inMAT <- matrix(scan("cottonID75wm", sep=","), nrow=2451, ncol=2451, 
> + byrow=TRUE)
> > range(rowSums(inMAT))
> [1] 0.8159028 1.9115231
> > d75MAT <- nb2mat(d75, glist=idlist, style="W")
> > range(rowSums(d75MAT))
> [1] 1 1
> > w75 <- nb2listw(d75, glist=idlist, style="W")
> > range(sapply(w75$weights, sum))
> [1] 1 1
> 
> So something in the construction of your matrix wasn't securing row 
> standardisation. The values do differ, this is the upper left corner:
> 
> > d75MAT[1:5,1:5]
>         [,1]       [,2]       [,3]       [,4]       [,5]
> 1 0.00000000 0.06735710 0.03227068 0.02182278 0.01660474
> 2 0.05975093 0.00000000 0.05493976 0.02863058 0.01954588
> 3 0.02615210 0.05019078 0.00000000 0.05461937 0.02771729
> 4 0.01639324 0.02424508 0.05062943 0.00000000 0.05216365
> 5 0.01172946 0.01556467 0.02416008 0.04905229 0.00000000
> > inMAT[1:5,1:5]
>          [,1]     [,2]     [,3]     [,4]     [,5]
> [1,] 0.000000 0.131420 0.061844 0.041726 0.031848
> [2,] 0.101440 0.000000 0.090156 0.047180 0.032441
> [3,] 0.040305 0.076122 0.000000 0.083545 0.042787
> [4,] 0.023708 0.034730 0.072836 0.000000 0.076431
> [5,] 0.016296 0.021506 0.033593 0.068830 0.000000
> > rowSums(inMAT[1:5,])
> [1] 1.911523 1.658689 1.533153 1.440908 1.379051
> > rowSums(d75MAT[1:5,])
> 1 2 3 4 5 
> 1 1 1 1 1 
> 
> They are not the same matrices, although the differences are very small
> - 
> here I've used the shapefile points, which are stored as binary floating
> 
> point, rather than using the DBF values, which are a possibly rounded 
> character representation, and that might be enough to cause the 
> difference. I think you should be able to generate w75, and that it
> should 
> do what you need, but I'd be grateful for feedback on how you get on.
> 
> Best wishes,
> 
> Roger
> 
> PS: with numbers of neighbours between 177 and 678 (both in your matrix 
> and in d75), even allowing for the dampening effect of inverse distance,
> 
> most analyses will be slow. 75m means that many sites are related to
> many 
> in your case. Doing:
> 
> symbols(408725, 3660800, circles=75, inches=FALSE, fg="red", add=TRUE)
> 
> on top of the earlier plot shows your chosen neighbourhood for an 
> arbitrary point.
> 
> > 
> > I really appreciate this.  Thank you,
> > 
> > Terry
> > 
> > 
> > 
> > -----Original Message-----
> > From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
> > Sent: Friday, March 17, 2006 5:50 PM
> > To: Griffin, Terry W
> > Cc: r-sig-geo at stat.math.ethz.ch
> > Subject: RE: [R-sig-Geo] inverse distance weights matrix
> > 
> > Terry:
> > 
> > http://web.ics.purdue.edu/~twgriffi/mat4rf
> > 
> > and 
> > 
> > http://web.ics.purdue.edu/~twgriffi/mat4rs
> > 
> > throw access errors.
> > 
> > Do you have the coordinates and your specifications for the inverse 
> > weighted neighbours (distance threshold, power if any)? 
> > 
> > inMAT <- matrix(scan("cottonID75wm", sep=","), nrow=2451, ncol=2451, 
> >   byrow=TRUE)
> > 
> > does read the matrix - the weights aren't symmetric, are they?
> > 
> > From the weights matrix I get:
> > 
> > inMATlw <- mat2listw(inMAT)
> > 
> > print(is.symmetric.nb(inMATlw$neighbours))
> > [1] TRUE
> > 
> > print(inMATlw$neighbours)
> > Neighbour list object:
> > Number of regions: 2451 
> > Number of nonzero links: 1182982 
> > Percentage nonzero weights: 19.69208 
> > Average number of links: 482.6528 
> > 
> > If you could post the coordinates and your specifications, I could see
> > how 
> > to reproduce the weights within R if you like.
> > 
> > Roger
> > 
> > 
> > On Fri, 17 Mar 2006, Griffin, Terry W wrote:
> > 
> > > 
> > > The MATLAB routines are the Spatial Econometrics Toolbox format.  I
> > > tried the read.dat2listw() in R; the code and error message for a
> > small
> > > matrix example is below; this uses a full matrix from MATLAB
> > (realizing
> > > that "read.dat2listw" is intended for sparse matrices). 
> > > 
> > > > mattry<-read.dat2listw("mat4rf")
> > > Error in "[.default"(sn, , 1) : incorrect number of dimensions
> > > > traceback()
> > > 5: NextMethod("[")
> > > 4: "[.factor"(sn, , 1)
> > > 3: sn[, 1]
> > > 2: unique(sn[, 1])
> > > 1: read.dat2listw("mat4rf")
> > > 
> > > 
> > > I'm not able to use dlmwrite in MATLAB to export the sparse matrix
> so
> > I
> > > tried to import the full matrix into R (code is above).  The MATLAB
> > code
> > > I'm using came from this listserve archive.  The MATLAB code and
> error
> > > message are below.  I'm able to use dlmwrite to create the MATLAB
> full
> > > matrix (used above in the R code).
> > > 
> > > load testmat.GWT; A = (spconvert(testmat)); %have to change name in
> > two
> > > locations on this line
> > > n=size(A); nobs=n(1);
> > >  % Normalize matrix (adapted form LeSage 1999)
> > > wt = sparse(A);
> > >  [i1,j1,s1]=find(wt);
> > > rsum=sum(wt);
> > > for i=1:nobs;
> > >             ind=find(i1==i);
> > > s1(ind,1)=s1(ind,1)/rsum(1,i);
> > > end;
> > > [m,n] = size(wt);
> > > W = sparse(i1,j1,s1,m,n);
> > > S = sparse(W);
> > > dlmwrite('mat4rst', S); %give the new sparse weight matrix a
> permanent
> > > name for R 
> > > ??? Error using ==> sprintf
> > > Function is not defined for sparse inputs.
> > > 
> > > Error in ==> dlmwrite at 172
> > >         str = sprintf(format,m(i,:));
> > > 
> > > If anyone wants to give it a try, I've put the small example
> matrices
> > > and the "real" matrix up on my website at:
> > > http://web.ics.purdue.edu/~twgriffi/R_matrix.htm
> > > 
> > > My objective is to use R for my spatial data analysis using inverse
> > > distance weights matrices.  I'm struggling with the inverse distance
> > > matrices.  I hope to either create these inverse distance matrices
> in
> > > SpaceStat then import into R or create the matrices in R.  
> > > 
> > > Thank you,
> > > 
> > > Terry
> > > 
> > > 
> > > 
> > > 
> > > -----Original Message-----
> > > From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
> > > Sent: Friday, March 17, 2006 2:43 PM
> > > To: Griffin, Terry W
> > > Cc: r-sig-geo at stat.math.ethz.ch
> > > Subject: Re: [R-sig-Geo] inverse distance weights matrix
> > > 
> > > On Thu, 16 Mar 2006, Griffin, Terry W wrote:
> > > 
> > > > Greetings,
> > > > 
> > > >  
> > > > 
> > > > I'm migrating from MATLAB to R and am having trouble converting
> > > inverse
> > > > distance weights matrix into a form usable by R.  I've created the
> > > > matrix in SpaceStat (in *.FMT format) and converted to *.GWT
> format
> > > and
> > > > also have it in MATLAB *.m format.
> > > > 
> > > 
> > > I wonder whether your Matlab data are in the Spatial Econometrics
> > > Toolbox 
> > > format - if they are, you could try the read.dat2listw() function 
> > > mentioned on the read.gwt2nb function help page.
> > > >  
> > > > 
> > > > I've tried using the read.gwt2nb in R, but without success.  There
> > are
> > > > nearly 2,451 observations with an average of 482 linkages.  About
> 20
> > %
> > > > have nonzero weights.  Any suggestions are appreciated.
> > > 
> > > Without details of what you mean by "without success", it's hard to
> > > offer 
> > > any advice. Could you create a small example of the problems you are
> 
> > > seeing, and repost with copies of the commands you give and any
> error 
> > > messages? 
> > > 
> > > If you are seeing errors ("Error in ..." messages from R), please
> also
> > > type traceback() at the prompt and report the output. You could also
> > put
> > > the uncooperative GWT file on a website for others to try to see
> what
> > is
> > > going on.
> > > 
> > > > 
> > > >  
> > > > 
> > > > Thank you,
> > > > 
> > > > Terry
> > > > 
> > > >  
> > > > 
> > > >  
> > > > 
> > > > Terry W. Griffin
> > > > 
> > > > Graduate Research Assistant
> > > > 
> > > > Agricultural Economics
> > > > 
> > > > Purdue University
> > > > 
> > > > 403 W State St
> > > > 
> > > > West Lafayette, IN 47907
> > > > 
> > > > 765-494-4257
> > > > 
> > > > http://web.ics.purdue.edu/~twgriffi/
> > > > <http://web.ics.purdue.edu/~twgriffi/> 
> > > > 
> > > >  
> > > > 
> > > >  
> > > > 
> > > > 
> > > > 	[[alternative HTML version deleted]]
> > > > 
> > > > _______________________________________________
> > > > R-sig-Geo mailing list
> > > > R-sig-Geo at stat.math.ethz.ch
> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > > > 
> > > 
> > > 
> > 
> > 
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From wes_bak2003 at yahoo.com  Tue Apr 11 19:24:27 2006
From: wes_bak2003 at yahoo.com (wesam bakri)
Date: Tue, 11 Apr 2006 10:24:27 -0700 (PDT)
Subject: [R-sig-Geo] Social network analysis indices
Message-ID: <20060411172428.18631.qmail@web33702.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060411/d71f6dfd/attachment.pl>

From elw at stderr.org  Wed Apr 12 00:28:33 2006
From: elw at stderr.org (elw at stderr.org)
Date: Tue, 11 Apr 2006 17:28:33 -0500 (CDT)
Subject: [R-sig-Geo] Social network analysis indices
In-Reply-To: <20060411172428.18631.qmail@web33702.mail.mud.yahoo.com>
References: <20060411172428.18631.qmail@web33702.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.64.0604111727550.16569@illuminati.stderr.org>



it would probably do you a whole lot of good to ask about these things on 
the SOCNET listserv rather than here.

i can't imagine that there are too many other people who are on both 
lists.... though i could be wrong.

--elijah


On Tue, 11 Apr 2006, wesam bakri wrote:

> Date: Tue, 11 Apr 2006 10:24:27 -0700 (PDT)
> From: wesam bakri <wes_bak2003 at yahoo.com>
> To: R-sig-Geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] Social network analysis indices
> 
> Dear Mr.
>  I already search for indices of Socila network anlaysis, and how to measure it , and what its operational definition , and  i didnt find exactly what i want,
>  would you pls help me in this.
>  Thanx alot , and have a nice day.
>
>
> ---------------------------------
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From icos.atropa at gmail.com  Wed Apr 12 05:35:10 2006
From: icos.atropa at gmail.com (icosa atropa)
Date: Tue, 11 Apr 2006 21:35:10 -0600
Subject: [R-sig-Geo] R spatial newbie seeks advice r.e. esri data-compatible
	packages
Message-ID: <681d07c20604112035k1b840b4cn4e05657a313e7b94@mail.gmail.com>

I'm new to R's spatial facilities.  I've been reading the r-sig-geo
mailing list for a week or two now, and I could use some advice.

I've decided to use R for a ArcGIS class project.  I spent today
reading R spatial package docs, and I'm a little confused as to what
work has been merged or duplicated, and what the most active tools are
for certain tasks.

To start with, I would like to read and write from ESRI formats such
as shapefiles and coverages. For shapefiles i find the
"shapefiles" and "maptools" packages; for coverages, I find "RArcInfo".

For datum and projection conversions, I found that both "rgdal" and
"sp" provide some functionality.

Any advice on where to start?
Thanks,
christian



From e.pebesma at geo.uu.nl  Wed Apr 12 08:56:23 2006
From: e.pebesma at geo.uu.nl (Edzer J. Pebesma)
Date: Wed, 12 Apr 2006 08:56:23 +0200
Subject: [R-sig-Geo] Best way to plot cross sections of discrete-valued
 grids
In-Reply-To: <7E4C06F49D6FEB49BE4B60E5FC92ED7A03F6B4ED@pnlmse35.pnl.gov>
References: <7E4C06F49D6FEB49BE4B60E5FC92ED7A03F6B4ED@pnlmse35.pnl.gov>
Message-ID: <443CA497.8040204@geo.uu.nl>

Waichler, Scott R wrote:
> Edzer,
>
>   
>> library(sp)
>> # create 3D grid
>> xyz = expand.grid(x = 1:100, y = 1:100, z = 1:100) 
>> d = data.frame(xyz, v = sample(1:10, 1e6, replace = T))
>> gridded(d) = ~x+y+z
>> class(d)
>> summary(d)
>> # first point on line:
>> p1 = c(5,5,5)
>> # second point on line:
>> p2 = c(95,95,64)
>> rbind(p1,p2)
>> pts = sample.Line(rbind(p1,p2), 1000, "regular") # select 
>> grid elements for each of 1000 points:
>> plot(d$v[overlay(d, pts)], type = 'l')
>>
>>
>> It "misuses" sample.Line, which was written as a spsample 
>> method for Line objects; too bad that Line objects in sp are 
>> limited to exist in two dimensions. 
>>     
>
> Thank you, this example really helps me understand how to go about it.
> Here pts is along a line.  Can you suggest a way to get a set of pts
> that lie along a plane?  In my application, I want to sample and plot
> 2-D vertical cross sections ("slices") of the 3-D grid, so assuming p1
> and p2 have the same z, I need to repeat pts with different values of z.
> The only way I know how is to extract pts as a matrix and repeat using
> incremented values of z, then convert it back to a SpatialPoints object.
> There must be a more elegant way.
>
> Scott Waichler
>   
O.K., and you want to plot the different cross sections in a conditioning
levelplot? I would go like this: convert the whole thing to points (well, it
was points in my example), apply a coordinate transformation such that z
is the variable you want to cross sect, and apply

levelplot(v~x+y|z, as.data.frame(pts))

If the cross sections you want already line up with x and y, you can leave
out the coordinate transformation; the transformation makes just any
2D cross section possible. It could however be that some cross sections
don't result in nicely gridded patterns, and might need rotation before
levelplot deals with them the way you want.
--
Edzer



From epistat at gmail.com  Wed Apr 12 16:07:56 2006
From: epistat at gmail.com (zhijie zhang)
Date: Wed, 12 Apr 2006 22:07:56 +0800
Subject: [R-sig-Geo] two questions about spdep package
Message-ID: <2fc17e30604120707n36612fdl5955020a5a91863d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060412/49306d31/attachment.pl>

From Roger.Bivand at nhh.no  Wed Apr 12 16:14:54 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 12 Apr 2006 16:14:54 +0200 (CEST)
Subject: [R-sig-Geo] R spatial newbie seeks advice r.e. esri
 data-compatible packages
In-Reply-To: <681d07c20604112035k1b840b4cn4e05657a313e7b94@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0604121601370.7841-100000@reclus.nhh.no>

On Tue, 11 Apr 2006, icosa atropa wrote:

> I'm new to R's spatial facilities.  I've been reading the r-sig-geo
> mailing list for a week or two now, and I could use some advice.
> 
> I've decided to use R for a ArcGIS class project.  I spent today
> reading R spatial package docs, and I'm a little confused as to what
> work has been merged or duplicated, and what the most active tools are
> for certain tasks.
> 
> To start with, I would like to read and write from ESRI formats such
> as shapefiles and coverages. For shapefiles i find the
> "shapefiles" and "maptools" packages; for coverages, I find "RArcInfo".
> 
> For datum and projection conversions, I found that both "rgdal" and
> "sp" provide some functionality.

If you choose to treat the classes defined in the sp package as containers 
for your data, then things are a bit simpler.

You can then read shapefiles into a SpatialPolygonsDataFrame object (or 
...Points... or ...Lines... if appropriate) with readOGR() in rgdal, and 
(some) raster data written by ArcGIS with readGDAL() in rgdal [some 
because handling "." or "," in Arc ASCII grids seems to have changed 
between ArcGIS 8 and 9]. 

You write shapefiles using writePolyShape() (or ...Points... or
...Lines...) in the maptools package, and write the *.prj using showWKT()  
in rgdal. You can write Arc ASCII grids using writeAsciiGrid() in
maptools, but watch the dec= argument - different mixes of platforms and
locals can require patience. ArcView 3.2 is not so picky about the decimal
mark. writeGDAL() in rgdal writes very nice GeoTiffs (multiple floating
point bands, etc), but the ArcGIS 9.1 I have access to does not read them
correctly (however ENVI does).

You are correct that this is all work in progress. The targets also change
- things that worked with ArcGIS 8 now do not work, or work differently. I
think you will find the sp classes useful, because it is so easy to add
new data to the geometries.

What are you looking to do within R, and which discipline are you in?

Roger

> 
> Any advice on where to start?
> Thanks,
> christian
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Wed Apr 12 18:52:06 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 12 Apr 2006 18:52:06 +0200 (CEST)
Subject: [R-sig-Geo] two questions about spdep package
In-Reply-To: <2fc17e30604120707n36612fdl5955020a5a91863d@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0604121651500.7841-100000@reclus.nhh.no>

On Wed, 12 Apr 2006, zhijie zhang wrote:

> Dear friends,
>  I met two problems in spdep package and hope to get help.
> 
> 1. "*coords* :matrix of point coordinates " appeared in spdep package for
> several times,but i can't find how to generate it, could anybody tell me how
> to generate the argument "* coords*",
>  e.g. tri2nb(*coords*, row.names = NULL)

It is a two-column matrix of the coordinate points. 

> 
> 2.  In "write.nb.gal:Write a neighbours list as a GAL *lattice* file, may
> also use newer GeoDa header format" , it refered the definition of lattice
> data. Frankly speaking, i'm not very clear about the difference of grid data
> and lattice data. Anybody who have a clear understanding about them give me
> a brief
> 

The terminology is pretty mixed up, even in GIS. As Danlin suggested, a 
GIS book may help, and the description in Waller & Gotway (2004) Applied 
Spatial Statistics for Public Health Data, Chapter 3, is good too. You are 
probably right that the word "lattice" on the write.nb.gal help page is 
not well chosen, when in fact lattice should refer to a tesselation, 
regular or irregular. GeoDa documentation calls GAL format files spatial 
weights files, while they could also be called spatial neighbour files. I 
will try to find a better fording for the help page.

Roger

> 
> --
> Kind Regards
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From rss10 at duke.edu  Wed Apr 12 23:05:53 2006
From: rss10 at duke.edu (Rob Schick)
Date: Wed, 12 Apr 2006 17:05:53 -0400
Subject: [R-sig-Geo] Interpolating along an XY path
Message-ID: <4ae03def0604121405l62bdfabg94bb27758cc8206c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060412/a6b6691b/attachment.pl>

From ljlayne at unm.edu  Wed Apr 12 23:09:55 2006
From: ljlayne at unm.edu (Larry Layne)
Date: Wed, 12 Apr 2006 15:09:55 -0600
Subject: [R-sig-Geo] Moran's I vs. spatial rho
Message-ID: <95B7D89C41F2DFFD53402503@dhcp-129-24-91-249.unm.edu>

I am using spdep_0.3-12 to compute Moran's I and spatial rho. To compute 
Moran's I, I am using the function 'moran.test' and the row stochastic 
definition of the connectivity matrix (the W matrix). Here is the full line 
of code for Moran's I:

a <- moran.test(NMmap$att.data$y,y,NMlistw,randomisation=FALSE, 
zero.policy=TRUE,alternative="two.sided",rank=FALSE)

I am using the function lagsarlm to compute spatial rho using an 
intercept-only model: Y = pWY + XB + e, and using the row stochastic 
definition of the connectivity matrix (the W matrix). Here is the full line 
of code for this:

x <- lagsarlm(y ~ 1,data=NMpop,NMlistw,type="lag",method="eigen", 
quiet=FALSE,zero.policy=TRUE)

I am having difficulty figuring out why the Moran's I estimates are very 
different from the spatial rho estimates. Specifically (n is number of 
areal units):

Var  n        Moran's I             spatial rho
A  3109    0.365187132203878    0.573153392466612
B  3109    0.360858943229591    0.562977003813789
C  3109    0.140015456674040    0.291046543475327
D  3109    0.613850771465824    0.797930036214143

A   49     0.261942390553635    0.411076873069647
B   49     0.328416006893752    0.526902446982636
C   49     0.341110258614797    0.535113540423957
D   49     0.239118528840316    0.371896460431941

A    4    -0.412023041115369   -1.08397184420832
B    4    -0.577311366437566   -1.21286625541679
C    4    -0.623070319848968   -1.27502649289533
D    4    -0.63499460958309     0.371896460431941

Any ideas why there would be such a discrepancy between Moran's I values 
and spatial rho values (especially when n=4) when both are using the same 
row stochastic connectivity matrix?

Larry Layne
ljlayne at unm.edu



From ljlayne at unm.edu  Wed Apr 12 23:23:41 2006
From: ljlayne at unm.edu (Larry Layne)
Date: Wed, 12 Apr 2006 15:23:41 -0600
Subject: [R-sig-Geo] Moran's I vs. spatial rho
Message-ID: <CB59EEE608BCE4E0B6BF911C@dhcp-129-24-91-249.unm.edu>

There is a typo in the code for moran.test. It should read:

a <- 
moran.test(NMmap$att.data$y,NMlistw,randomisation=FALSE,zero.policy=TRUE, 
alternative="two.sided",rank=FALSE)



From b.rowlingson at lancaster.ac.uk  Wed Apr 12 23:50:07 2006
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 12 Apr 2006 22:50:07 +0100
Subject: [R-sig-Geo] Interpolating along an XY path
In-Reply-To: <4ae03def0604121405l62bdfabg94bb27758cc8206c@mail.gmail.com>
References: <4ae03def0604121405l62bdfabg94bb27758cc8206c@mail.gmail.com>
Message-ID: <443D760F.4050607@lancaster.ac.uk>

Rob Schick wrote:
> I have a series of x,y coordinates that represent a movement path of a
> tagged animal. I want to regularize the track, but approx interpolates over
> the range of x's as opposed to treating the track as an ordered sequence.
> I've tried coercing it into a time series, but this only seems to work when
> the X's constantly increase.

What exactly do you mean by 'regularize'?

  Have you got (x,y,t) data for spotting an animal at point (x,y) at 
time t where t is irregular, and you want to 'regularize' in t? Or do 
you want to regularize in space, so you end up with points all the same 
distance apart? That might not be possible depending on the spacing of 
your points...

  I think you're going to end up interpolating between pairs of points. 
Its quite easy to interpolate points between (x0,y0) and (x1,y1), the 
coords are just (x0+(1:N)*dx, y0+(1:N)*dy) where dx is (x1-x0)/N and 
similarly for y. Or I might be one off there...

Barry



From mdsumner at utas.edu.au  Wed Apr 12 23:53:20 2006
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Thu, 13 Apr 2006 07:53:20 +1000
Subject: [R-sig-Geo] Interpolating along an XY path
In-Reply-To: <4ae03def0604121405l62bdfabg94bb27758cc8206c@mail.gmail.com>
References: <4ae03def0604121405l62bdfabg94bb27758cc8206c@mail.gmail.com>
Message-ID: <443D76D0.2030708@utas.edu.au>

Rob Schick wrote:
> I have a series of x,y coordinates that represent a movement path of a
> tagged animal. I want to regularize the track, but approx interpolates over
> the range of x's as opposed to treating the track as an ordered sequence.
> I've tried coercing it into a time series, but this only seems to work when
> the X's constantly increase. The following dummy track provides a glimpse of
> the problem with approx:
>   

If you treat the x's and y's separately with approx you can get what you 
want (although I'm sure some careful thought would produce a better use 
of approx):

x <- c(1,3,5,5,5,4,2,1.5)
y <- c(1,1,1,2,3,3,3,3)
xypair <- cbind(x,y)
xypair
rownames(xypair) <- 1:length(x)
plot(x,y,type='l')
points(xypair)
text(x,y,rownames(xypair),offset=.5,pos=2)
points(approx(xypair[,1],n=30)$y, approx(xypair[,2],n=30)$y,col=3,pch="*")

BTW, I have a package for animal track data that contains a function 
called equalTime - it interpolates points in space (euclidean) based on 
an (approximation to an) equal time interval to create regular spaced 
points in time, assuming straight motion between fixes. You might find 
it useful. It's never really been finished, but I use it especially for 
the S4 validation of trajectory with "trip", and for quick speed 
filtering and time spent gridding.

http://staff.acecrc.org.au/~mdsumner/Rutas/

HTH, Mike.



From mdsumner at utas.edu.au  Thu Apr 13 00:57:13 2006
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Thu, 13 Apr 2006 08:57:13 +1000
Subject: [R-sig-Geo] Interpolating along an XY path]
Message-ID: <443D85C9.5050204@utas.edu.au>


Rob Schick wrote:
> I have a series of x,y coordinates that represent a movement path of a
> tagged animal. I want to regularize the track, but approx interpolates over
> the range of x's as opposed to treating the track as an ordered sequence.
> I've tried coercing it into a time series, but this only seems to work when
> the X's constantly increase. The following dummy track provides a glimpse of
> the problem with approx:
>   

If you treat the x's and y's separately with approx you can get what you 
want (although I'm sure some careful thought would produce a better use 
of approx):

x <- c(1,3,5,5,5,4,2,1.5)
y <- c(1,1,1,2,3,3,3,3)
xypair <- cbind(x,y)
xypair
rownames(xypair) <- 1:length(x)
plot(x,y,type='l')
points(xypair)
text(x,y,rownames(xypair),offset=.5,pos=2)
points(approx(xypair[,1],n=30)$y, approx(xypair[,2],n=30)$y,col=3,pch="*")

BTW, I have a package for animal track data that contains a function 
called equalTime - it interpolates points in space (euclidean) based on 
an (approximation to an) equal time interval to create regular spaced 
points in time, assuming straight motion between fixes. You might find 
it useful. It's never really been finished, but I use it especially for 
the S4 validation of trajectory with "trip", and for quick speed 
filtering and time spent gridding.

http://staff.acecrc.org.au/~mdsumner/Rutas/

HTH, Mike.



From epistat at gmail.com  Thu Apr 13 09:08:02 2006
From: epistat at gmail.com (zhijie zhang)
Date: Thu, 13 Apr 2006 15:08:02 +0800
Subject: [R-sig-Geo] fail to use class of "SpatialPointsDataFrame"
Message-ID: <2fc17e30604130008re24e9f6yf47cc306f2098095@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060413/ba6d772c/attachment.pl>

From mdsumner at utas.edu.au  Thu Apr 13 09:19:29 2006
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Thu, 13 Apr 2006 17:19:29 +1000
Subject: [R-sig-Geo] projection metadata
In-Reply-To: <CB59EEE608BCE4E0B6BF911C@dhcp-129-24-91-249.unm.edu>
References: <CB59EEE608BCE4E0B6BF911C@dhcp-129-24-91-249.unm.edu>
Message-ID: <443DFB81.6080000@utas.edu.au>

Hello, I'm looking for advice on parsing XML metadata and mapping 
projection tags to PROJ.4 strings.

Manifold GIS provides auxiliary .xml files with every export of 
drawings, images, surfaces or labels and
this is as robust as GeoTIFF headers and can be used to override the 
limitations of shapefiles, png images
etc. that don't store projection metadata completely if at all.

I have a function that writes the xml for a Manifold surface when I 
export an R xyz image to raw binary, it's totally ad hoc
and just explicitly writes out the text lines - but it works well for 
transferring my (usually latlon) data
back and forth.

I'd like to generalize this by mapping the XML tags to PROJ.4 arguments. 

I've made some limited explorations using the XML package to parse the 
xml and modify tags, but
I'm trying to capture two data models (the xml and PROJ.4) at once and 
it's beyond me.

A shorter version of my query might be: is there a DTD or schema for 
PROJ.4 arguments, and can anyone point
me to examples of mapping other schemes to PROJ.4?  ( I imagine that the 
GDAL code for GeoTIFF headers is
likely good place.Any pointers would be appreciated. )  It will be 
simple enough to create or obtain a
DTD for the Manifold XML.

Cheers, Mike.

Here's an example of an XML file:

<?xml version="1.0" encoding="UTF-8"?>
<preset>
    <name>Lambert Azimuthal Equal Area</name>
    <datum>World Geodetic 1984 (WGS84)</datum>
    <system>Lambert Azimuthal Equal Area</system>
    <unit>Meter</unit>
    <majorAxis>6.378137000000000000000000e+006</majorAxis>
    <eccentricity>8.181919084262148600000000e-002</eccentricity>
    <centerX>0.000000000000000000000000e+000</centerX>
    <centerY>0.000000000000000000000000e+000</centerY>
    <centerZ>0.000000000000000000000000e+000</centerZ>
    <rotationX>0.000000000000000000000000e+000</rotationX>
    <rotationY>0.000000000000000000000000e+000</rotationY>
    <rotationZ>0.000000000000000000000000e+000</rotationZ>
    <scaleX>1.000000000000000000000000e+000</scaleX>
    <localScaleX>1.000000000000000000000000e+000</localScaleX>
    <scaleY>1.000000000000000000000000e+000</scaleY>
    <localScaleY>1.000000000000000000000000e+000</localScaleY>
    <falseEasting>0.000000000000000000000000e+000</falseEasting>
    <localOffsetX>0.000000000000000000000000e+000</localOffsetX>
    <falseNorthing>0.000000000000000000000000e+000</falseNorthing>
    <localOffsetY>0.000000000000000000000000e+000</localOffsetY>
    <centerLat>-4.200000000000000000000000e+001</centerLat>
    <centerLon>1.500000000000000000000000e+002</centerLon>
</preset>



From e.pebesma at geo.uu.nl  Thu Apr 13 09:43:49 2006
From: e.pebesma at geo.uu.nl (Edzer J. Pebesma)
Date: Thu, 13 Apr 2006 09:43:49 +0200
Subject: [R-sig-Geo] fail to use class of "SpatialPointsDataFrame"
In-Reply-To: <2fc17e30604130008re24e9f6yf47cc306f2098095@mail.gmail.com>
References: <2fc17e30604130008re24e9f6yf47cc306f2098095@mail.gmail.com>
Message-ID: <443E0135.50002@geo.uu.nl>

zhijie zhang wrote:
> Dear friends,
>  I fail to understand and use the class of "SpatialPointsDataFrame", hope
> someone to givems some hints on it.
> For example:
>  z<-rnorm(16)  # this is attribute data
> coords<-cbind(x=c(1,1,1,2,2,2,3,3,3),y=c(1,2,3,1,2,3,1,2,3))   # this is
> coordinate data
>  How should i use SpatialPointsDataFrame to combine them and generate my
> dataset, Thanks a lot!
>
>
>
> --
> Kind Regards,Zhi Jie,Zhang ,PHDDepartment of EpidemiologySchool of Public
> HealthFudan UniversityTel:86-21-54237149
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   
Try:

SpatialPointsDataFrame(coords, data.frame(z=z[1:9]))

Note that SpatialPointsDataFrame joins the spatial points (coords) and a
data.frame with attributes. The number of rows in the attribute table should
equal the number of spatial points, hence 1:9.
--
Edzer



From e.pebesma at geo.uu.nl  Thu Apr 13 12:08:06 2006
From: e.pebesma at geo.uu.nl (Edzer J. Pebesma)
Date: Thu, 13 Apr 2006 12:08:06 +0200
Subject: [R-sig-Geo] projection metadata
In-Reply-To: <443DFB81.6080000@utas.edu.au>
References: <CB59EEE608BCE4E0B6BF911C@dhcp-129-24-91-249.unm.edu>
	<443DFB81.6080000@utas.edu.au>
Message-ID: <443E2306.8060601@geo.uu.nl>

Michael, I'm pretty new to the xml world, but I guess you need an 
application
that can write out proj.4 strings from the xml's manifold outputs. I thought
something like that was called an xslt rather than a schema/dtd, which 
define
rather the structure (dtd) and content (schema) of the xml.

Briefly browsing the web (google PROJ.4 xml) you may find something
useful in the context of the OGR work done by Frank Warmerdam. BTW
ogr is part of gdal, so if something's in there, you could get to it through
package rgdal.

Keep us updated on this interesting topic,
--
Edzer

Michael Sumner wrote:
> Hello, I'm looking for advice on parsing XML metadata and mapping 
> projection tags to PROJ.4 strings.
>
> Manifold GIS provides auxiliary .xml files with every export of 
> drawings, images, surfaces or labels and
> this is as robust as GeoTIFF headers and can be used to override the 
> limitations of shapefiles, png images
> etc. that don't store projection metadata completely if at all.
>
> I have a function that writes the xml for a Manifold surface when I 
> export an R xyz image to raw binary, it's totally ad hoc
> and just explicitly writes out the text lines - but it works well for 
> transferring my (usually latlon) data
> back and forth.
>
> I'd like to generalize this by mapping the XML tags to PROJ.4 arguments. 
>
> I've made some limited explorations using the XML package to parse the 
> xml and modify tags, but
> I'm trying to capture two data models (the xml and PROJ.4) at once and 
> it's beyond me.
>
> A shorter version of my query might be: is there a DTD or schema for 
> PROJ.4 arguments, and can anyone point
> me to examples of mapping other schemes to PROJ.4?  ( I imagine that the 
> GDAL code for GeoTIFF headers is
> likely good place.Any pointers would be appreciated. )  It will be 
> simple enough to create or obtain a
> DTD for the Manifold XML.
>
> Cheers, Mike.
>
> Here's an example of an XML file:
>
> <?xml version="1.0" encoding="UTF-8"?>
> <preset>
>     <name>Lambert Azimuthal Equal Area</name>
>     <datum>World Geodetic 1984 (WGS84)</datum>
>     <system>Lambert Azimuthal Equal Area</system>
>     <unit>Meter</unit>
>     <majorAxis>6.378137000000000000000000e+006</majorAxis>
>     <eccentricity>8.181919084262148600000000e-002</eccentricity>
>     <centerX>0.000000000000000000000000e+000</centerX>
>     <centerY>0.000000000000000000000000e+000</centerY>
>     <centerZ>0.000000000000000000000000e+000</centerZ>
>     <rotationX>0.000000000000000000000000e+000</rotationX>
>     <rotationY>0.000000000000000000000000e+000</rotationY>
>     <rotationZ>0.000000000000000000000000e+000</rotationZ>
>     <scaleX>1.000000000000000000000000e+000</scaleX>
>     <localScaleX>1.000000000000000000000000e+000</localScaleX>
>     <scaleY>1.000000000000000000000000e+000</scaleY>
>     <localScaleY>1.000000000000000000000000e+000</localScaleY>
>     <falseEasting>0.000000000000000000000000e+000</falseEasting>
>     <localOffsetX>0.000000000000000000000000e+000</localOffsetX>
>     <falseNorthing>0.000000000000000000000000e+000</falseNorthing>
>     <localOffsetY>0.000000000000000000000000e+000</localOffsetY>
>     <centerLat>-4.200000000000000000000000e+001</centerLat>
>     <centerLon>1.500000000000000000000000e+002</centerLon>
> </preset>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From rbt501 at york.ac.uk  Thu Apr 13 12:31:08 2006
From: rbt501 at york.ac.uk (Taylor, RB)
Date: Thu, 13 Apr 2006 11:31:08 +0100
Subject: [R-sig-Geo] WGS84 conversion to UTM
Message-ID: <443E286C.C90EE4D@york.ac.uk>

Dear all,

I'm a rather new user to R, so please excuse my ignorance. I understand
in R there are different spatial packages that allow one to do a variety
of spatial analyses. I have collected GPS in WGS84 in South Africa. I
have the data in a tab-deliniated txt file (along with attribute data)
and in .shp files. I want to be able to read the text file (or ascii)
into R and then batch convert long lat to UTM (34 S), and then do some
analyses in R. I can across the website
http://r-spatial.sourceforge.net/xtra/xtra.RHnw.html#spproj, which seems
quite good. But I don't seem to be able to replicate the same procedure
with my files. Being fairly new to R, I am not all that familiar with
the syntax so perhaps this is why I can't do it.

Any help is appreciated,
thanks

PS I work in a windows environment

--
Rob Taylor

University of York
Biology Department
PO Box 373
York
YO10 5YW
United Kingdom

Mob +00 44 079 01531259



From ernesto at ipimar.pt  Thu Apr 13 12:38:56 2006
From: ernesto at ipimar.pt (ernesto)
Date: Thu, 13 Apr 2006 11:38:56 +0100
Subject: [R-sig-Geo] WGS84 conversion to UTM
In-Reply-To: <443E286C.C90EE4D@york.ac.uk>
References: <443E286C.C90EE4D@york.ac.uk>
Message-ID: <443E2A40.4060907@ipimar.pt>

Taylor, RB wrote:

>Dear all,
>
>I'm a rather new user to R, so please excuse my ignorance. I understand
>in R there are different spatial packages that allow one to do a variety
>of spatial analyses. I have collected GPS in WGS84 in South Africa. I
>have the data in a tab-deliniated txt file (along with attribute data)
>and in .shp files. I want to be able to read the text file (or ascii)
>into R and then batch convert long lat to UTM (34 S), and then do some
>analyses in R. I can across the website
>http://r-spatial.sourceforge.net/xtra/xtra.RHnw.html#spproj, which seems
>quite good. But I don't seem to be able to replicate the same procedure
>with my files. Being fairly new to R, I am not all that familiar with
>the syntax so perhaps this is why I can't do it.
>
>Any help is appreciated,
>thanks
>
>PS I work in a windows environment
>
>--
>Rob Taylor
>

Hi Rob,

Take a look at the package "PBSmapping".

You'll need to create a data.frame with the names X and Y and add an
attribute "projection", then just convUL :-)

See my example:

mydf <- read.table(blah, blah, blah)
names(mydf) <- c("X","Y")
attr(mydf, "projection") <- c("LL")
mydf.utm <- convUL(mydf)

Regards

EJ



From Roger.Bivand at nhh.no  Thu Apr 13 13:56:51 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 13 Apr 2006 13:56:51 +0200 (CEST)
Subject: [R-sig-Geo] Moran's I vs. spatial rho
In-Reply-To: <95B7D89C41F2DFFD53402503@dhcp-129-24-91-249.unm.edu>
Message-ID: <Pine.LNX.4.44.0604131330210.8518-100000@reclus.nhh.no>

On Wed, 12 Apr 2006, Larry Layne wrote:

> I am using spdep_0.3-12 to compute Moran's I and spatial rho. To compute 
> Moran's I, I am using the function 'moran.test' and the row stochastic 
> definition of the connectivity matrix (the W matrix). Here is the full line 
> of code for Moran's I:
> 
> a <- moran.test(NMmap$att.data$y,y,NMlistw,randomisation=FALSE, 
> zero.policy=TRUE,alternative="two.sided",rank=FALSE)
> 
> I am using the function lagsarlm to compute spatial rho using an 
> intercept-only model: Y = pWY + XB + e, and using the row stochastic 
> definition of the connectivity matrix (the W matrix). Here is the full line 
> of code for this:
> 
> x <- lagsarlm(y ~ 1,data=NMpop,NMlistw,type="lag",method="eigen", 
> quiet=FALSE,zero.policy=TRUE)
> 
> I am having difficulty figuring out why the Moran's I estimates are very 
> different from the spatial rho estimates. Specifically (n is number of 
> areal units):
> 
> Var  n        Moran's I             spatial rho
> A  3109    0.365187132203878    0.573153392466612
> B  3109    0.360858943229591    0.562977003813789
> C  3109    0.140015456674040    0.291046543475327
> D  3109    0.613850771465824    0.797930036214143
> 
> A   49     0.261942390553635    0.411076873069647
> B   49     0.328416006893752    0.526902446982636
> C   49     0.341110258614797    0.535113540423957
> D   49     0.239118528840316    0.371896460431941
> 
> A    4    -0.412023041115369   -1.08397184420832
> B    4    -0.577311366437566   -1.21286625541679
> C    4    -0.623070319848968   -1.27502649289533
> D    4    -0.63499460958309     0.371896460431941
> 
> Any ideas why there would be such a discrepancy between Moran's I values 
> and spatial rho values (especially when n=4) when both are using the same 
> row stochastic connectivity matrix?

The relevant question would be why you expect them to be the same, when
they are esimated using different techniques? A spatial autocorrelation
coefficient can be defined as (e'We) / ((e'e) * (e'W'We))^(1/2) - Cliff &
Ord (1981). Note that the OLS estimator would be (e'We) / (e'W'We), and
Moran's I is (e'We) / (e'e), while the ML is adjusted by the Jacobian in
addition:

> library(spdep)
> data(columbus)
> W <- nb2mat(col.gal.nb)
> e <- scale(columbus$CRIME, scale=FALSE)
> ee <- crossprod(e, e)
> We <- crossprod(W, e)
> eWe <- crossprod(e, We)
> eWWe <- crossprod(We, We)
> eWe/ee
          [,1]
[1,] 0.4857709
> moran.test(columbus$CRIME, nb2listw(col.gal.nb))$estimate[1]
Moran I statistic 
        0.4857709 
> eWe/eWWe
          [,1]
[1,] 0.8867512
> lagsarlm(CRIME ~ 1, columbus, nb2listw(col.gal.nb))$rho
      rho 
0.6503681 
> eWe/sqrt(ee*eWWe)
          [,1]
[1,] 0.6563215

If e'W'We is much smaller than e'e (which it will be in the presence of 
positive spatial autocorrelation), the different calculations lead to 
quite different values for the same data, because the calculations are 
different.

Hope this helps,

Roger


> 
> Larry Layne
> ljlayne at unm.edu
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Thu Apr 13 14:43:50 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 13 Apr 2006 14:43:50 +0200 (CEST)
Subject: [R-sig-Geo] projection metadata
In-Reply-To: <443E2306.8060601@geo.uu.nl>
Message-ID: <Pine.LNX.4.44.0604131420270.8518-100000@reclus.nhh.no>

On Thu, 13 Apr 2006, Edzer J. Pebesma wrote:

> Michael, I'm pretty new to the xml world, but I guess you need an 
> application
> that can write out proj.4 strings from the xml's manifold outputs. I thought
> something like that was called an xslt rather than a schema/dtd, which 
> define
> rather the structure (dtd) and content (schema) of the xml.
> 
> Briefly browsing the web (google PROJ.4 xml) you may find something
> useful in the context of the OGR work done by Frank Warmerdam. BTW
> ogr is part of gdal, so if something's in there, you could get to it through
> package rgdal.
> 
> Keep us updated on this interesting topic,
> --
> Edzer
> 
> Michael Sumner wrote:
> > Hello, I'm looking for advice on parsing XML metadata and mapping 
> > projection tags to PROJ.4 strings.
> >
> > Manifold GIS provides auxiliary .xml files with every export of 
> > drawings, images, surfaces or labels and
> > this is as robust as GeoTIFF headers and can be used to override the 
> > limitations of shapefiles, png images
> > etc. that don't store projection metadata completely if at all.
> >
> > I have a function that writes the xml for a Manifold surface when I 
> > export an R xyz image to raw binary, it's totally ad hoc
> > and just explicitly writes out the text lines - but it works well for 
> > transferring my (usually latlon) data
> > back and forth.
> >
> > I'd like to generalize this by mapping the XML tags to PROJ.4 arguments. 

If Manifold can output Well-Known Text WKT forms, in one mutation ESRI 
WKT, then they are already read in rgdal (readOGR() reads them among 
others). The projection code from what was spproj is now included in 
rgdal, by the way - documentation on the websites will follow shortly.

The manual way might be for your example grepping through:

EPSG <- make_EPSG()
EPSG[grep("Lambert", EPSG$note), 1:2]

but the example is actually only:

> showWKT("+proj=laea +ellps=WGS84 +lat_0=-42 +lon_0=150")
[1] "PROJCS[\"Unknown\",
       GEOGCS[\"GCS_WGS_1984\",
         DATUM[\"D_unknown\",
         SPHEROID[\"WGS84\",6378137,298.257223563]],
         PRIMEM[\"Greenwich\",0],
         UNIT[\"Degree\",0.017453292519943295]
       ],
       PROJECTION[\"Lambert_Azimuthal_Equal_Area\"],
       PARAMETER[\"latitude_of_center\",-42],
       PARAMETER[\"longitude_of_center\",150],
       PARAMETER[\"false_easting\",0],
       PARAMETER[\"false_northing\",0]
     ]"

It may well be that there is code in GDAL/OGR/PROJ4 for handling the xml 
directly, or that a converter to ESRI *.prj files (which look like the 
above) already exists.

If showWKT() is given a filename argument, it emits a WKT file, by default 
using the ESRI mutation.

I hope this helps,

Roger

> >
> > I've made some limited explorations using the XML package to parse the 
> > xml and modify tags, but
> > I'm trying to capture two data models (the xml and PROJ.4) at once and 
> > it's beyond me.
> >
> > A shorter version of my query might be: is there a DTD or schema for 
> > PROJ.4 arguments, and can anyone point
> > me to examples of mapping other schemes to PROJ.4?  ( I imagine that the 
> > GDAL code for GeoTIFF headers is
> > likely good place.Any pointers would be appreciated. )  It will be 
> > simple enough to create or obtain a
> > DTD for the Manifold XML.
> >
> > Cheers, Mike.
> >
> > Here's an example of an XML file:
> >
> > <?xml version="1.0" encoding="UTF-8"?>
> > <preset>
> >     <name>Lambert Azimuthal Equal Area</name>
> >     <datum>World Geodetic 1984 (WGS84)</datum>
> >     <system>Lambert Azimuthal Equal Area</system>
> >     <unit>Meter</unit>
> >     <majorAxis>6.378137000000000000000000e+006</majorAxis>
> >     <eccentricity>8.181919084262148600000000e-002</eccentricity>
> >     <centerX>0.000000000000000000000000e+000</centerX>
> >     <centerY>0.000000000000000000000000e+000</centerY>
> >     <centerZ>0.000000000000000000000000e+000</centerZ>
> >     <rotationX>0.000000000000000000000000e+000</rotationX>
> >     <rotationY>0.000000000000000000000000e+000</rotationY>
> >     <rotationZ>0.000000000000000000000000e+000</rotationZ>
> >     <scaleX>1.000000000000000000000000e+000</scaleX>
> >     <localScaleX>1.000000000000000000000000e+000</localScaleX>
> >     <scaleY>1.000000000000000000000000e+000</scaleY>
> >     <localScaleY>1.000000000000000000000000e+000</localScaleY>
> >     <falseEasting>0.000000000000000000000000e+000</falseEasting>
> >     <localOffsetX>0.000000000000000000000000e+000</localOffsetX>
> >     <falseNorthing>0.000000000000000000000000e+000</falseNorthing>
> >     <localOffsetY>0.000000000000000000000000e+000</localOffsetY>
> >     <centerLat>-4.200000000000000000000000e+001</centerLat>
> >     <centerLon>1.500000000000000000000000e+002</centerLon>
> > </preset>
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Thu Apr 13 14:58:47 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 13 Apr 2006 14:58:47 +0200 (CEST)
Subject: [R-sig-Geo] WGS84 conversion to UTM
In-Reply-To: <443E286C.C90EE4D@york.ac.uk>
Message-ID: <Pine.LNX.4.44.0604131445210.8518-100000@reclus.nhh.no>

On Thu, 13 Apr 2006, Taylor, RB wrote:

> Dear all,
> 
> I'm a rather new user to R, so please excuse my ignorance. I understand
> in R there are different spatial packages that allow one to do a variety
> of spatial analyses. I have collected GPS in WGS84 in South Africa. I
> have the data in a tab-deliniated txt file (along with attribute data)
> and in .shp files. I want to be able to read the text file (or ascii)
> into R and then batch convert long lat to UTM (34 S), and then do some
> analyses in R. I can across the website
> http://r-spatial.sourceforge.net/xtra/xtra.RHnw.html#spproj, which seems
> quite good. But I don't seem to be able to replicate the same procedure
> with my files. Being fairly new to R, I am not all that familiar with
> the syntax so perhaps this is why I can't do it.

The functionality in spproj has recently been moved to rgdal, so that for 
a target UTM zone 34 S:

library(rgdal)
EPSG <- make_EPSG()
EPSG[grep("UTM zone 34S", EPSG$note), 1:2]

gives five alternatives with different ellipsoids. Assuming WGS 84:

utm34S <- CRS("+init=epsg:32734")
showWKT(CRSargs(utm34S))

shows that the EPSG projection has been picked up (EPSG is a long list of 
projections originally created by frustrated oil companies in Europe, 
mostly in the North Sea, because nothing lined up right when they began 
from the coastal states' national grids, etc.).

If your shapefiles have a *.prj file already, readOGR() will pick it up. 
If not, and for the textfiles, you'll need to assign the input coordinate 
reference system to the Spatial object(s):

my_ll <- CRS("+proj=lonlat +datum=WGS84")
proj4string(my_ll_object) <- my_ll

from there it is simple,

my_utm34S_object <- transform(my_ll_object,  utm34S)

Some documentation is coming before (too) long.

Roger

> 
> Any help is appreciated,
> thanks
> 
> PS I work in a windows environment
> 
> --
> Rob Taylor
> 
> University of York
> Biology Department
> PO Box 373
> York
> YO10 5YW
> United Kingdom
> 
> Mob +00 44 079 01531259
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From pedro at dpi.inpe.br  Thu Apr 13 17:41:52 2006
From: pedro at dpi.inpe.br (pedro at dpi.inpe.br)
Date: Thu, 13 Apr 2006 12:41:52 -0300
Subject: [R-sig-Geo] AttributeList and data.table
Message-ID: <20060413124152.g3za2cyuztc8ckgw@agenda.dpi.inpe.br>

Hi,

There is a quite new package on CRAN called data.table. It implements 
the class data.table representing a data.frame without rownames, in 
order to improve performance. So, it has the same objective of the sp 
class AttributeList. I confess that I'm very superficial in terms of 
the functionality available in both classes, but I think the projects 
could work together, or even be merged.

Best wishes,

Pedro Andrade

---------- Forwarded message ----------
Date: Wed, 12 Apr 2006 15:19:10 +0100
From: Matthew Dowle <mdowle at concordiafunds.com>
To: "'r-devel at r-project.org'" <r-devel at r-project.org>,
      "'Cran at r-project.org'" <Cran at r-project.org>
Subject: [Rd] New class: data.table


Hi,

Following previous discussion on this list
(http://tolstoy.newcastle.edu.au/R/devel/05/12/3439.html) I have created a
package as suggested, and uploaded it to CRAN incoming : data.table.tar.gz.

** Your comments and feedback will be very much appreciated. **

> From help(data.table) :

This class really does very little. The only reason for its existence is
that the white book specifies that data.frame must have rownames.

Most of the code is copied from base functions with the code manipulating
row.names removed.

A data.table is identical to a data.frame other than:
  	* it doesn't have rownames
  	* [,drop] by default is FALSE, so selecting a single row will always
return a single row data.table not a vector
  	* The comma is optional inside [], so DT[3] returns the 3rd row as a
1 row data.table
  	* [] is like a call to subset()
  	* [,...], is like a call to with().  (not yet implemented)

Motivation:
  	* up to 10 times less memory
  	* up to 10 times faster to create, and copy
  	* simpler R code
  	* the white book defines rownames, so data.frame can't be changed
... => new class

Examples:
nr = 1000000
D = rep(1:5,nr/5)
system.time(DF <<- data.frame(colA=D, colB=D))  # 2.08
system.time(DT <<- data.table(colA=D, colB=D))  # 0.15  (over 10 times
faster to create)
identical(as.data.table(DF), DT)
identical(dim(DT),dim(DF))
object.size(DF)/object.size(DT)                 # 10 times less memory

tt = subset(DF,colA>3)
ss = DT[colA>3]
identical(as.data.table(tt), ss)

mean(subset(DF,colA+colB>5,"colB"))
mean(DT[colA+colB>5]$colB)

tt = with(subset(DF,colA>3),colA+colB)
ss = with(DT[colA>3],colA+colB)                 # but could be:
DT[colA>3,colA+colB]  (not yet implemented)
identical(tt, ss)

tt = DF[with(DF,tapply(1:nrow(DF),colB,last)),] # select last row grouping
by colB
ss = DT[tapply(1:nrow(DT),colB,last)]           # but could be:
DT[last,group=colB]  (not yet implemented)
identical(as.data.table(tt), ss)

Lkp=1:3
tt = DF[with(DF,colA %in% Lkp),]
ss = DT[colA %in% Lkp]                        # expressions inside the []
can see objects in the calling frame
identical(as.data.table(tt), ss)

In each case above there is either a space, time, or code brevity advantage
with the data.table.

The motivation for the new class grew from the realization that performance
of data.frames can be improved by removing the rownames.  See here for the
previous discussion
http://tolstoy.newcastle.edu.au/R/devel/05/12/3439.html.

Regards,
Matthew

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel



From ljlayne at unm.edu  Thu Apr 13 18:33:54 2006
From: ljlayne at unm.edu (Larry Layne)
Date: Thu, 13 Apr 2006 10:33:54 -0600
Subject: [R-sig-Geo] Moran's I vs. spatial rho
In-Reply-To: <Pine.LNX.4.44.0604131330210.8518-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0604131330210.8518-100000@reclus.nhh.no>
Message-ID: <CF672D1688FE470F0AD9C4F3@dhcp-129-24-91-249.unm.edu>

> The relevant question would be why you expect them to be the same, when
> they are esimated using different techniques? ...

Apparently I have had a misconception rattling around in my head regarding 
estimates using the 2 approaches.

Let's see if I have misconceived this next question also. I had assumed 
that if I used the row stochastic connectivity definition for polygons in 
an SAR model (Y = pWY + XB + e) that the rho estimates would be constrained 
between +1 and -1, similar to a Pearson correlation coefficient. Is this 
incorrect?

Larry Layne
ljlayne at unm.edu



From ljlayne at unm.edu  Thu Apr 13 18:45:55 2006
From: ljlayne at unm.edu (Larry Layne)
Date: Thu, 13 Apr 2006 10:45:55 -0600
Subject: [R-sig-Geo] polygon identifiers and nb classes
Message-ID: <F951E7F9830248C399EB7976@dhcp-129-24-91-249.unm.edu>

I use the following code from maptools and spdep to create a neighbors list 
of class nb from a shapefile:

NMmap <- read.shape("CountyLevelData.shp")
NMpolylist <- Map2poly(NMmap,region.id=NULL,quiet=TRUE)
NMnb <- poly2nb(NMpolylist,queen=FALSE)
print(is.symmetric.nb(NMnb))

I can then use write.nb.gal to output the neighbors list to a txt file in 
GAL format:

write.nb.gal(NMnb,file="E://zweightsGAL_county.txt",oldstyle=FALSE,shpfile=NULL,ind=NULL)

I understand how to read the GAL format. What is the origin of the id's 
listed in the txt file (in this case the rweightsGAL_county.txt file). They 
look like they are the values from the FID field + 1 in the original shape 
file.

I want to use the information from the GAL format .txt file to create a 
spatial weights matrix file of the form I can use in ArcGIS on the same 
shapefile the data came from in the first place. (For instance, compute 
Moran's I using spatial statistics extension in ArcGIS using the binary 
weights connectivity matrix.) How do I know which field from the shapefile 
is being used in the construction of the neighbors list for the class nb 
and then being written to the txt file using write.nb.gal?

Larry Layne
ljlayne at unm.edu



From e.pebesma at geo.uu.nl  Thu Apr 13 21:43:17 2006
From: e.pebesma at geo.uu.nl (Edzer J. Pebesma)
Date: Thu, 13 Apr 2006 20:43:17 +0100
Subject: [R-sig-Geo] AttributeList and data.table
In-Reply-To: <20060413124152.g3za2cyuztc8ckgw@agenda.dpi.inpe.br>
References: <20060413124152.g3za2cyuztc8ckgw@agenda.dpi.inpe.br>
Message-ID: <443EA9D5.4060303@geo.uu.nl>

Pedro, you're very alert! I saw it too, and had similar thoughts. 
However, I haven't
had any complaints yet about the way AttributeLists work right now; most 
of it
is hidden behind the scenes anyway. If data.table usage becomes 
widespread we
can certainly provide coercion functions between the two. Let's first 
wait until it
actually hits CRAN. I'm for instance curious what happens if you pass 
one to lm().
--
Edzer

pedro at dpi.inpe.br wrote:

>Hi,
>
>There is a quite new package on CRAN called data.table. It implements 
>the class data.table representing a data.frame without rownames, in 
>order to improve performance. So, it has the same objective of the sp 
>class AttributeList. I confess that I'm very superficial in terms of 
>the functionality available in both classes, but I think the projects 
>could work together, or even be merged.
>
>Best wishes,
>
>Pedro Andrade
>
>---------- Forwarded message ----------
>Date: Wed, 12 Apr 2006 15:19:10 +0100
>From: Matthew Dowle <mdowle at concordiafunds.com>
>To: "'r-devel at r-project.org'" <r-devel at r-project.org>,
>      "'Cran at r-project.org'" <Cran at r-project.org>
>Subject: [Rd] New class: data.table
>
>
>Hi,
>
>Following previous discussion on this list
>(http://tolstoy.newcastle.edu.au/R/devel/05/12/3439.html) I have created a
>package as suggested, and uploaded it to CRAN incoming : data.table.tar.gz.
>
>** Your comments and feedback will be very much appreciated. **
>
>  
>
>>From help(data.table) :
>>    
>>
>
>This class really does very little. The only reason for its existence is
>that the white book specifies that data.frame must have rownames.
>
>Most of the code is copied from base functions with the code manipulating
>row.names removed.
>
>A data.table is identical to a data.frame other than:
>  	* it doesn't have rownames
>  	* [,drop] by default is FALSE, so selecting a single row will always
>return a single row data.table not a vector
>  	* The comma is optional inside [], so DT[3] returns the 3rd row as a
>1 row data.table
>  	* [] is like a call to subset()
>  	* [,...], is like a call to with().  (not yet implemented)
>
>Motivation:
>  	* up to 10 times less memory
>  	* up to 10 times faster to create, and copy
>  	* simpler R code
>  	* the white book defines rownames, so data.frame can't be changed
>... => new class
>
>Examples:
>nr = 1000000
>D = rep(1:5,nr/5)
>system.time(DF <<- data.frame(colA=D, colB=D))  # 2.08
>system.time(DT <<- data.table(colA=D, colB=D))  # 0.15  (over 10 times
>faster to create)
>identical(as.data.table(DF), DT)
>identical(dim(DT),dim(DF))
>object.size(DF)/object.size(DT)                 # 10 times less memory
>
>tt = subset(DF,colA>3)
>ss = DT[colA>3]
>identical(as.data.table(tt), ss)
>
>mean(subset(DF,colA+colB>5,"colB"))
>mean(DT[colA+colB>5]$colB)
>
>tt = with(subset(DF,colA>3),colA+colB)
>ss = with(DT[colA>3],colA+colB)                 # but could be:
>DT[colA>3,colA+colB]  (not yet implemented)
>identical(tt, ss)
>
>tt = DF[with(DF,tapply(1:nrow(DF),colB,last)),] # select last row grouping
>by colB
>ss = DT[tapply(1:nrow(DT),colB,last)]           # but could be:
>DT[last,group=colB]  (not yet implemented)
>identical(as.data.table(tt), ss)
>
>Lkp=1:3
>tt = DF[with(DF,colA %in% Lkp),]
>ss = DT[colA %in% Lkp]                        # expressions inside the []
>can see objects in the calling frame
>identical(as.data.table(tt), ss)
>
>In each case above there is either a space, time, or code brevity advantage
>with the data.table.
>
>The motivation for the new class grew from the realization that performance
>of data.frames can be improved by removing the rownames.  See here for the
>previous discussion
>http://tolstoy.newcastle.edu.au/R/devel/05/12/3439.html.
>
>Regards,
>Matthew
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at stat.math.ethz.ch
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>  
>



From Roger.Bivand at nhh.no  Thu Apr 13 20:58:13 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 13 Apr 2006 20:58:13 +0200 (CEST)
Subject: [R-sig-Geo] Moran's I vs. spatial rho
In-Reply-To: <CF672D1688FE470F0AD9C4F3@dhcp-129-24-91-249.unm.edu>
Message-ID: <Pine.LNX.4.44.0604132052520.8518-100000@reclus.nhh.no>

On Thu, 13 Apr 2006, Larry Layne wrote:

> > The relevant question would be why you expect them to be the same, when
> > they are esimated using different techniques? ...
> 
> Apparently I have had a misconception rattling around in my head regarding 
> estimates using the 2 approaches.
> 
> Let's see if I have misconceived this next question also. I had assumed 
> that if I used the row stochastic connectivity definition for polygons in 
> an SAR model (Y = pWY + XB + e) that the rho estimates would be constrained 
> between +1 and -1, similar to a Pearson correlation coefficient. Is this 
> incorrect?

Sorry, not quite right. The constraints are the inverses of the minimum
and maximum eigenvalues of W:

library(spdep)
data(columbus)
1/range(eigenw(nb2listw(col.gal.nb, style="W")))

is

[1] -1.533849  1.000000

so the upper bound of unity holds for W with row sums of 1. For other 
styles of weights:

> 1/range(eigenw(nb2listw(col.gal.nb, style="B")))
[1] -0.3351569  0.1672385
> 1/range(eigenw(nb2listw(col.gal.nb, style="S")))
[1] -1.7865492  0.8866948

for example. In fact, singularities only happen on the boundaries, but for 
rho outside the bounds, the process would be wild.

Roger


> 
> Larry Layne
> ljlayne at unm.edu
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Thu Apr 13 21:16:39 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 13 Apr 2006 21:16:39 +0200 (CEST)
Subject: [R-sig-Geo] polygon identifiers and nb classes
In-Reply-To: <F951E7F9830248C399EB7976@dhcp-129-24-91-249.unm.edu>
Message-ID: <Pine.LNX.4.44.0604132059440.8518-100000@reclus.nhh.no>

On Thu, 13 Apr 2006, Larry Layne wrote:

> I use the following code from maptools and spdep to create a neighbors list 
> of class nb from a shapefile:
> 
> NMmap <- read.shape("CountyLevelData.shp")
> NMpolylist <- Map2poly(NMmap,region.id=NULL,quiet=TRUE)
> NMnb <- poly2nb(NMpolylist,queen=FALSE)
> print(is.symmetric.nb(NMnb))
> 
> I can then use write.nb.gal to output the neighbors list to a txt file in 
> GAL format:
> 
> write.nb.gal(NMnb,file="E://zweightsGAL_county.txt",oldstyle=FALSE,shpfile=NULL,ind=NULL)
> 
> I understand how to read the GAL format. What is the origin of the id's 
> listed in the txt file (in this case the rweightsGAL_county.txt file). They 
> look like they are the values from the FID field + 1 in the original shape 
> file.

Yes, if no row.names= argument is given to poly2nb(), this is what they 
will default to.

You can choose your own row.names= in poly2nb(), and setting 
oldstyle=FALSE, it should work. You'll need to edit the first line, the 
ArcGIS format is not GAL as far as I understand.

The col.gal.nb object in data(columbus) has region.id attributes set in 
this way:

> summary(col.gal.nb)
Neighbour list object:
Number of regions: 49 
Number of nonzero links: 230 
Percentage nonzero weights: 9.579342 
Average number of links: 4.693878 
Link number distribution:

 2  3  4  5  6  7  8  9 10 
 7  7 13  4  9  6  1  1  1 
7 least connected regions:
1005 1008 1045 1047 1049 1048 1015 with 2 links
1 most connected region:
1017 with 10 links
> tmpfl <- tempfile()
> write.nb.gal(col.gal.nb, tmpfl, oldstyle=FALSE)
> system(paste("cat", tmpfl))
0 49 unknown unknown
1005 2
1001 1006
1001 3
1005 1006 1002
...

so then you'd need to change the header to name the DBF field with the IDs 
correctly. For cross-checking in GeoDa, please set the shapefile= and ind= 
arguments to the appropriate values.

A revision of write.nb.gal() is obviously possible here, I 
would value feedback. Please also crosscheck whether the variance of 
Moran's I agrees with moran.test here in the randomisation=TRUE 
row-standardised weights case - it is known not to agree for fixed range 
and inverse distance weights in ArcGIS, the results here (and in Stata) 
are consistent, but those in ArcGIS are not.

It will be interesting to hear what you find!

Roger

> 
> I want to use the information from the GAL format .txt file to create a 
> spatial weights matrix file of the form I can use in ArcGIS on the same 
> shapefile the data came from in the first place. (For instance, compute 
> Moran's I using spatial statistics extension in ArcGIS using the binary 
> weights connectivity matrix.) How do I know which field from the shapefile 
> is being used in the construction of the neighbors list for the class nb 
> and then being written to the txt file using write.nb.gal?
> 
> Larry Layne
> ljlayne at unm.edu
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Thu Apr 13 21:26:22 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 13 Apr 2006 21:26:22 +0200 (CEST)
Subject: [R-sig-Geo] AttributeList and data.table
In-Reply-To: <443EA9D5.4060303@geo.uu.nl>
Message-ID: <Pine.LNX.4.44.0604132119030.8518-100000@reclus.nhh.no>

On Thu, 13 Apr 2006, Edzer J. Pebesma wrote:

> Pedro, you're very alert! I saw it too, and had similar thoughts. 
> However, I haven't
> had any complaints yet about the way AttributeLists work right now; most 
> of it
> is hidden behind the scenes anyway. If data.table usage becomes 
> widespread we
> can certainly provide coercion functions between the two. Let's first 
> wait until it
> actually hits CRAN. I'm for instance curious what happens if you pass 
> one to lm().

I agree. If it starts gaining momentum, it would save mainenance to pool 
efforts, but data.frame objects are very prevalent in modelling code. But:

> library(sp)
> x <- runif(5000)
> y <- runif(5000)
> z <- rnorm(5000)
> e <- rnorm(5000,0,0.1)
> ze <- 0.3 - 0.1*z + e
> al <- AttributeList(list(z=z, ze=ze))
> spdf <- SpatialPointsDataFrame(cbind(x,y), data=al)
> lm(ze ~ z, spdf)

Call:
lm(formula = ze ~ z, data = spdf)

Coefficients:
(Intercept)            z  
    0.30141     -0.09917  

does very nicely already. Nice work, that AttributeList object!

Roger

> --
> Edzer
> 
> pedro at dpi.inpe.br wrote:
> 
> >Hi,
> >
> >There is a quite new package on CRAN called data.table. It implements 
> >the class data.table representing a data.frame without rownames, in 
> >order to improve performance. So, it has the same objective of the sp 
> >class AttributeList. I confess that I'm very superficial in terms of 
> >the functionality available in both classes, but I think the projects 
> >could work together, or even be merged.
> >
> >Best wishes,
> >
> >Pedro Andrade
> >
> >---------- Forwarded message ----------
> >Date: Wed, 12 Apr 2006 15:19:10 +0100
> >From: Matthew Dowle <mdowle at concordiafunds.com>
> >To: "'r-devel at r-project.org'" <r-devel at r-project.org>,
> >      "'Cran at r-project.org'" <Cran at r-project.org>
> >Subject: [Rd] New class: data.table
> >
> >
> >Hi,
> >
> >Following previous discussion on this list
> >(http://tolstoy.newcastle.edu.au/R/devel/05/12/3439.html) I have created a
> >package as suggested, and uploaded it to CRAN incoming : data.table.tar.gz.
> >
> >** Your comments and feedback will be very much appreciated. **
> >
> >  
> >
> >>From help(data.table) :
> >>    
> >>
> >
> >This class really does very little. The only reason for its existence is
> >that the white book specifies that data.frame must have rownames.
> >
> >Most of the code is copied from base functions with the code manipulating
> >row.names removed.
> >
> >A data.table is identical to a data.frame other than:
> >  	* it doesn't have rownames
> >  	* [,drop] by default is FALSE, so selecting a single row will always
> >return a single row data.table not a vector
> >  	* The comma is optional inside [], so DT[3] returns the 3rd row as a
> >1 row data.table
> >  	* [] is like a call to subset()
> >  	* [,...], is like a call to with().  (not yet implemented)
> >
> >Motivation:
> >  	* up to 10 times less memory
> >  	* up to 10 times faster to create, and copy
> >  	* simpler R code
> >  	* the white book defines rownames, so data.frame can't be changed
> >... => new class
> >
> >Examples:
> >nr = 1000000
> >D = rep(1:5,nr/5)
> >system.time(DF <<- data.frame(colA=D, colB=D))  # 2.08
> >system.time(DT <<- data.table(colA=D, colB=D))  # 0.15  (over 10 times
> >faster to create)
> >identical(as.data.table(DF), DT)
> >identical(dim(DT),dim(DF))
> >object.size(DF)/object.size(DT)                 # 10 times less memory
> >
> >tt = subset(DF,colA>3)
> >ss = DT[colA>3]
> >identical(as.data.table(tt), ss)
> >
> >mean(subset(DF,colA+colB>5,"colB"))
> >mean(DT[colA+colB>5]$colB)
> >
> >tt = with(subset(DF,colA>3),colA+colB)
> >ss = with(DT[colA>3],colA+colB)                 # but could be:
> >DT[colA>3,colA+colB]  (not yet implemented)
> >identical(tt, ss)
> >
> >tt = DF[with(DF,tapply(1:nrow(DF),colB,last)),] # select last row grouping
> >by colB
> >ss = DT[tapply(1:nrow(DT),colB,last)]           # but could be:
> >DT[last,group=colB]  (not yet implemented)
> >identical(as.data.table(tt), ss)
> >
> >Lkp=1:3
> >tt = DF[with(DF,colA %in% Lkp),]
> >ss = DT[colA %in% Lkp]                        # expressions inside the []
> >can see objects in the calling frame
> >identical(as.data.table(tt), ss)
> >
> >In each case above there is either a space, time, or code brevity advantage
> >with the data.table.
> >
> >The motivation for the new class grew from the realization that performance
> >of data.frames can be improved by removing the rownames.  See here for the
> >previous discussion
> >http://tolstoy.newcastle.edu.au/R/devel/05/12/3439.html.
> >
> >Regards,
> >Matthew
> >
> >______________________________________________
> >R-devel at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >_______________________________________________
> >R-sig-Geo mailing list
> >R-sig-Geo at stat.math.ethz.ch
> >https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >  
> >
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ljlayne at unm.edu  Thu Apr 13 22:08:06 2006
From: ljlayne at unm.edu (Larry Layne)
Date: Thu, 13 Apr 2006 14:08:06 -0600
Subject: [R-sig-Geo] Moran's I vs. spatial rho
In-Reply-To: <Pine.LNX.4.44.0604132052520.8518-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0604132052520.8518-100000@reclus.nhh.no>
Message-ID: <71DAB5CB06F00B7671F3F992@dhcp-129-24-91-249.unm.edu>

> Sorry, not quite right. The constraints are the inverses of the minimum
> and maximum eigenvalues of W:

Seems that if a person doesn't work with this stuff virtually every day 
then the knowledge is easily forgotten. Well, at least for me. Thanks very 
much for your patience with me, Roger.

Larry



From ljlayne at unm.edu  Thu Apr 13 22:52:18 2006
From: ljlayne at unm.edu (Larry Layne)
Date: Thu, 13 Apr 2006 14:52:18 -0600
Subject: [R-sig-Geo] polygon identifiers and nb classes
In-Reply-To: <Pine.LNX.4.44.0604132059440.8518-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0604132059440.8518-100000@reclus.nhh.no>
Message-ID: <FDFEF31EA369F14A09AFAA43@dhcp-129-24-91-249.unm.edu>

> Yes, if no row.names= argument is given to poly2nb(), this is what they
> will default to.

FID + 1 is what I assume you to mean.

> You can choose your own row.names= in poly2nb(),

Which I did here:

NMnb <- poly2nb(NMpolylist,row.names="OBJECTID",queen=FALSE)

Now I know for sure which values are being used as polygon ids to define 
the neighborhood list. (FYI, the shapefiles originally came from ArcGIS 
geodatabase polygon feature classes and is the reason the field OBJECTID 
exists in the shapefile DBF.)

> and setting oldstyle=FALSE, it should work.

...oldstyle=FALSE in write.nb.gal. Actually this doesn't matter. oldstyle 
can be either TRUE or FALSE - see below.

> You'll need to edit the first line, the ArcGIS format is not GAL as far as
> I understand.

More than just the first line. As I understand the spatial weights matrix 
file structure for ArcGIS there needs to be a complete rearrangement of the 
GAL file. For instance, given the first 5 lines of a GAL file:

0 49 unknown unknown
1 4
8 9 23 41
2 4
4 27 30 43

the information needs to be rearranged for an ArcGIS spatial weights file 
as follows for a binary weights connectivity matrix (the first line of the 
GAL file is discarded):

OBJECTID
1 8  1
1 9  1
1 23 1
1 41 1
2 4  1
2 27 1
2 30 1
2 43 1

The first line in the file is the name of the field in the DBF file used as 
the polygon label ids. (I am using the work "line" to imply record, row, or 
observation - take your pick.) This was specified above in poly2nb(). 
Following the field name in the first line, each line in the text file 
defines a weight for pairwise connections between polygons. Because polygon 
#1 shares a boundary with 4 other polygons, the weights defining each of 
these connections requires 4 lines in the ArcGIS spatial weights matrix 
file. The same is true for polygon #2, etc. This is what I understand the 
structure of the file to be for an ArcGIS spatial weights matrix file. I 
convert the GAL structure to the ArcGIS spatial weights matrix file using a 
SAS program. Any number of programming languages could be used to do the 
same thing.

> For cross-checking in GeoDa, please set the shapefile= and ind=
> arguments to the appropriate values.

I haven't used GeoDa to date. Maybe I should in the future? Maybe.

> A revision of write.nb.gal() is obviously possible here, I
> would value feedback.

Once I figured out how to read the GAL structure I could convert it to any 
other structure I wanted using SAS program code. For convenience, it might 
be nice to have a function like write.nb.gal() but more general, like 
write.nb() and allow the user to specify a parameter defining the structure 
of the output. For instance, certainly one of the parameter settings would 
be to write a GAL structure to a text file. Another might be to write one 
for ArcGIS like that shown above. (This would also require defining the 
weights in the output file, such as style = W, B, C, U, S.) I have a bunch 
of SAS programs that use a neighbors structure like the following (using 
the same poly ids for the GAL example from above):

1 8 9 23 41
2 4 27 30 43

Structures for other popular spatial stats software? Might be useful to 
different users.

> Please also crosscheck whether the variance of
> Moran's I agrees with moran.test here in the randomisation=TRUE
> row-standardised weights case - it is known not to agree for fixed range
> and inverse distance weights in ArcGIS, the results here (and in Stata)
> are consistent, but those in ArcGIS are not.
> It will be interesting to hear what you find!

I plan to compare all of my results from ArcGIS spatial statistics 
extension to those from spdep as it would be convenient to do a few more 
things in ArcGIS than in spdep, and I would like to have some confidence in 
the ArcGIS results. Generally, my experience with statistics anything in 
ArcGIS is that its output always needs to be verified using some other 
established software because ArcGIS is notorious for giving different 
results. The one good thing about most of the spatial statistics extension 
tools is that I can look at the algorithms they are implementing as most of 
these tools are included as Python scripts. Anyway, I would be glad to send 
you those comparisons right now but cannot because these particular tools 
in the spatial statistics extension have suddenly decided to not work on 
the computer I have the data on! What else could a person expect out of 
such a high-quality software product? I'll send the ArcGIS comparison 
results when I can.

Again, thanks for all your help.

Larry



From Roger.Bivand at nhh.no  Thu Apr 13 22:59:21 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 13 Apr 2006 22:59:21 +0200 (CEST)
Subject: [R-sig-Geo] polygon identifiers and nb classes
In-Reply-To: <FDFEF31EA369F14A09AFAA43@dhcp-129-24-91-249.unm.edu>
Message-ID: <Pine.LNX.4.44.0604132251590.8518-100000@reclus.nhh.no>

On Thu, 13 Apr 2006, Larry Layne wrote:

> > Yes, if no row.names= argument is given to poly2nb(), this is what they
> > will default to.
> 
> FID + 1 is what I assume you to mean.
> 
> > You can choose your own row.names= in poly2nb(),
> 
> Which I did here:
> 
> NMnb <- poly2nb(NMpolylist,row.names="OBJECTID",queen=FALSE)
> 
> Now I know for sure which values are being used as polygon ids to define 
> the neighborhood list. (FYI, the shapefiles originally came from ArcGIS 
> geodatabase polygon feature classes and is the reason the field OBJECTID 
> exists in the shapefile DBF.)
> 
> > and setting oldstyle=FALSE, it should work.
> 
> ...oldstyle=FALSE in write.nb.gal. Actually this doesn't matter. oldstyle 
> can be either TRUE or FALSE - see below.
> 
> > You'll need to edit the first line, the ArcGIS format is not GAL as far as
> > I understand.
> 
> More than just the first line. As I understand the spatial weights matrix 
> file structure for ArcGIS there needs to be a complete rearrangement of the 
> GAL file. For instance, given the first 5 lines of a GAL file:
> 
> 0 49 unknown unknown
> 1 4
> 8 9 23 41
> 2 4
> 4 27 30 43
> 
> the information needs to be rearranged for an ArcGIS spatial weights file 
> as follows for a binary weights connectivity matrix (the first line of the 
> GAL file is discarded):

Right. Please look at write.sn2gwt() instead - it will need modification
to handle the IDs. I'll start looking at it - listw2sn() does carry 
through a region.id attribute, so changing the output function to 
substitute the IDs for the indices shouldn't be hard.

Roger


> 
> OBJECTID
> 1 8  1
> 1 9  1
> 1 23 1
> 1 41 1
> 2 4  1
> 2 27 1
> 2 30 1
> 2 43 1
> 
> The first line in the file is the name of the field in the DBF file used as 
> the polygon label ids. (I am using the work "line" to imply record, row, or 
> observation - take your pick.) This was specified above in poly2nb(). 
> Following the field name in the first line, each line in the text file 
> defines a weight for pairwise connections between polygons. Because polygon 
> #1 shares a boundary with 4 other polygons, the weights defining each of 
> these connections requires 4 lines in the ArcGIS spatial weights matrix 
> file. The same is true for polygon #2, etc. This is what I understand the 
> structure of the file to be for an ArcGIS spatial weights matrix file. I 
> convert the GAL structure to the ArcGIS spatial weights matrix file using a 
> SAS program. Any number of programming languages could be used to do the 
> same thing.
> 
> > For cross-checking in GeoDa, please set the shapefile= and ind=
> > arguments to the appropriate values.
> 
> I haven't used GeoDa to date. Maybe I should in the future? Maybe.
> 
> > A revision of write.nb.gal() is obviously possible here, I
> > would value feedback.
> 
> Once I figured out how to read the GAL structure I could convert it to any 
> other structure I wanted using SAS program code. For convenience, it might 
> be nice to have a function like write.nb.gal() but more general, like 
> write.nb() and allow the user to specify a parameter defining the structure 
> of the output. For instance, certainly one of the parameter settings would 
> be to write a GAL structure to a text file. Another might be to write one 
> for ArcGIS like that shown above. (This would also require defining the 
> weights in the output file, such as style = W, B, C, U, S.) I have a bunch 
> of SAS programs that use a neighbors structure like the following (using 
> the same poly ids for the GAL example from above):
> 
> 1 8 9 23 41
> 2 4 27 30 43
> 
> Structures for other popular spatial stats software? Might be useful to 
> different users.
> 
> > Please also crosscheck whether the variance of
> > Moran's I agrees with moran.test here in the randomisation=TRUE
> > row-standardised weights case - it is known not to agree for fixed range
> > and inverse distance weights in ArcGIS, the results here (and in Stata)
> > are consistent, but those in ArcGIS are not.
> > It will be interesting to hear what you find!
> 
> I plan to compare all of my results from ArcGIS spatial statistics 
> extension to those from spdep as it would be convenient to do a few more 
> things in ArcGIS than in spdep, and I would like to have some confidence in 
> the ArcGIS results. Generally, my experience with statistics anything in 
> ArcGIS is that its output always needs to be verified using some other 
> established software because ArcGIS is notorious for giving different 
> results. The one good thing about most of the spatial statistics extension 
> tools is that I can look at the algorithms they are implementing as most of 
> these tools are included as Python scripts. Anyway, I would be glad to send 
> you those comparisons right now but cannot because these particular tools 
> in the spatial statistics extension have suddenly decided to not work on 
> the computer I have the data on! What else could a person expect out of 
> such a high-quality software product? I'll send the ArcGIS comparison 
> results when I can.
> 
> Again, thanks for all your help.
> 
> Larry
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ljlayne at unm.edu  Thu Apr 13 23:17:34 2006
From: ljlayne at unm.edu (Larry Layne)
Date: Thu, 13 Apr 2006 15:17:34 -0600
Subject: [R-sig-Geo] polygon identifiers and nb classes
In-Reply-To: <Pine.LNX.4.44.0604132251590.8518-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0604132251590.8518-100000@reclus.nhh.no>
Message-ID: <98C429AD6E8127795DCC3D3C@dhcp-129-24-91-249.unm.edu>

> Right. Please look at write.sn2gwt()...

It is also probably a good idea to start using spdep 0.3-22 to take 
advantage of some of the new functions, which I have done.

Larry



From didier.leibovici at teledetection.fr  Fri Apr 14 09:59:28 2006
From: didier.leibovici at teledetection.fr (didier leibovici)
Date: Fri, 14 Apr 2006 09:59:28 +0200
Subject: [R-sig-Geo] plotting shapefile facilities
Message-ID: <443F5660.90808@teledetection.fr>

Dear all,
I read a shapefile using shapefiles package.
Now I would I would like to go around the facilities to plot the shapefile.
Is there any summary of all functionnalities related to "play" with a 
shapefile object?
thanks

-- 
Didier Leibovici         Skype: didier_us166
     didier.leibovici at free.fr  http://didier.leibovici.free.fr
IRD US 166 D?sertification     http://www.us166.ird.fr/
Maison de la T?l?d?tection     http://www.teledetection.fr
 500 rue JF Breton
34093 Montpellier cedex 05     http://www.roselt-oss.org
Tel : 00 33 (0)4 67 54 87 02      Fax : 00 33 (0)4 67 54 87 00



From Roger.Bivand at nhh.no  Fri Apr 14 18:02:55 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 14 Apr 2006 18:02:55 +0200 (CEST)
Subject: [R-sig-Geo] plotting shapefile facilities
In-Reply-To: <443F5660.90808@teledetection.fr>
Message-ID: <Pine.LNX.4.44.0604141759260.14359-100000@reclus.nhh.no>

On Fri, 14 Apr 2006, didier leibovici wrote:

> Dear all,
> I read a shapefile using shapefiles package.
> Now I would I would like to go around the facilities to plot the shapefile.
> Is there any summary of all functionnalities related to "play" with a 
> shapefile object?

You'll find helper functions in the maptools package to convert the object 
read by read.shapefile() into a polylist object, or lines or points, see 
?shape2poly. A plot method is defined for the polylist class.

You may find the classes in the sp package more convenient to use, and 
they have a wider selection of methods. Then readShapePoly() in the 
maptools package, or readOGR() in the rgdal package would be a more direct 
route.

Roger

> thanks
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Fri Apr 14 20:50:46 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 14 Apr 2006 20:50:46 +0200 (CEST)
Subject: [R-sig-Geo] polygon identifiers and nb classes
In-Reply-To: <98C429AD6E8127795DCC3D3C@dhcp-129-24-91-249.unm.edu>
Message-ID: <Pine.LNX.4.44.0604142045430.14359-100000@reclus.nhh.no>

On Thu, 13 Apr 2006, Larry Layne wrote:

> > Right. Please look at write.sn2gwt()...
> 

Here is a first cut, which seems to emit a suitable file. If you can try 
it and/or send back an Arc command line say for COLUMBUS.SHP CRIME and 
NEIGNO as index in GeoDa, I would be grateful:

write.sn2Arc <- function(sn, file, field=NULL) {
	if(!inherits(sn, "spatial.neighbour")) 
	    stop("not a spatial.neighbour object")
	if (is.null(field)) stop("field must be given")
	n <- attr(sn, "n")
	if (n < 1) stop("non-positive number of entities")
	nms <- as.character(attr(sn, "region.id"))
	sn[,1] <- nms[sn[,1]]
	sn[,2] <- nms[sn[,2]]
	con <- file(file, open="w")
	writeLines(field, con)
	write.table(as.data.frame(sn), file=con, append=TRUE,
		row.names=FALSE, col.names=FALSE, quote=FALSE)
	close(con)
}

I think it may fall over if the region.id values include white space or 
are non-unique.

sn is a spatial neighbours object as returned by listw2sn(), so in your 
case it would be:

write.sn2Arc(listw2sn(nb2listw(my_nb, style="B")), filename, fieldname)

Roger

> It is also probably a good idea to start using spdep 0.3-22 to take 
> advantage of some of the new functions, which I have done.
> 
> Larry
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From mdsumner at utas.edu.au  Tue Apr 18 01:33:44 2006
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Tue, 18 Apr 2006 09:33:44 +1000
Subject: [R-sig-Geo] projection metadata
In-Reply-To: <Pine.LNX.4.44.0604131420270.8518-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0604131420270.8518-100000@reclus.nhh.no>
Message-ID: <444425D8.9080507@utas.edu.au>


>>> I'd like to generalize this by mapping the XML tags to PROJ.4 arguments. 
>>>       
>
> If Manifold can output Well-Known Text WKT forms, in one mutation ESRI 
> WKT, then they are already read in rgdal (readOGR() reads them among 
> others). The projection code from what was spproj is now included in 
> rgdal, by the way - documentation on the websites will follow shortly.
>   

Thanks Roger - it turns out that this WKT ESRI text works for Manifold 
when it accompanies a shapefile as a .prj file. At least for one 
instance of lcc that I've tested. ;)
That makes the R to Manifold traverse very simple, for shapefiles.  I've 
yet to test .MIF, GeoTIFF etc.

Manifold will export this ESRI WKT manually in 6.50 SP1, but this is not 
yet possible programmatically. 

I've made a little bit of progress with the XML way - I can read it and 
convert it to a proj string - but it's pretty kludgy.  I'll try to clean 
up what I've done and report.
There's no clear heirarchy of how to specify datums versus coordinate 
system parameters and trying to cover the options is just very 
complicated. I can probably make a working
version that assumes WGS84 without too much trouble, with a lookup file 
for PROJ.4 names to Manifold names.

I will also request Manifold to incorporate the WKT  and PROJ.4 strings 
in the XML, at least as an option - certainly the EPSG codes as 
initials.  This seems to be about as far as the OGR xml forms go - it 
would make for a fairly simple R import and metadata assigment from 
these files.

Cheers, Mike.



From reeves at nceas.ucsb.edu  Tue Apr 18 01:51:38 2006
From: reeves at nceas.ucsb.edu (Rick Reeves)
Date: Mon, 17 Apr 2006 16:51:38 -0700
Subject: [R-sig-Geo] TLA
Message-ID: <44442A0A.5030805@nceas.ucsb.edu>


Hi all:

I'm going to post this question to a couple of lists as it does not 
strictly relate to spatial processing:

We are evaluating the SparseM and Matrix packages as we port MATLAB R14 
scripts into R.
The MATLAB code basically evaluates the AX=B system on sparse matrices 
that result in output
matrices of 100 to 1,000,000 rows/columns.

Our R prototype script uses Matrix() methods qr() and qr.coeff() and 
produces the same answer as the
MATLAB code for small (60x60) problems. But, execution times are much 
longer (40 minutes, compared
to 2 minutes for the MATLAB code)

Also, the R version cannot accommodate a solutioj matrix greater than 
aprox 10,000 x 10,000 elements,
while the MATLAB script has generated solutions for 10**6 x 10**6 
solution matrices.

Question is: Has anyone experiences in improving the performance of the 
R Matrix and SparseM packages?
Also, has anyone explored (and returned alive from) the upper limits of 
R Matrix and SparseM problem sizes?

Thanks in advance for any insights!

Rick Reeves


-- 
Rick Reeves	
Scientific Programmer Analyst
National Center for Ecological Analysis and Synthesis (NCEAS)
University of California, Santa Barbara
reeves at nceas.ucsb.edu
805 892 2533



From mdowle at concordiafunds.com  Tue Apr 18 11:26:17 2006
From: mdowle at concordiafunds.com (Matthew Dowle)
Date: Tue, 18 Apr 2006 10:26:17 +0100
Subject: [R-sig-Geo] AttributeList and data.table
Message-ID: <78166BFC5165D811AA0400065BF0324BF07FE6@wisconsin.concordia>


data.table now appears to be on CRAN.  However, given Prof Ripley's mail to
r-devel on Friday: "row.names in data.frame", it would seem data.frame
itself can be changed after all, so data.table could be removed.

> -----Original Message-----
> From: Edzer J. Pebesma [mailto:e.pebesma at geo.uu.nl] 
> Sent: 13 April 2006 20:43
> To: pedro at dpi.inpe.br
> Cc: r-sig-geo at stat.math.ethz.ch; Matthew Dowle
> Subject: Re: [R-sig-Geo] AttributeList and data.table
> 
> 
> Pedro, you're very alert! I saw it too, and had similar thoughts. 
> However, I haven't
> had any complaints yet about the way AttributeLists work 
> right now; most 
> of it
> is hidden behind the scenes anyway. If data.table usage becomes 
> widespread we
> can certainly provide coercion functions between the two. Let's first 
> wait until it
> actually hits CRAN. I'm for instance curious what happens if you pass 
> one to lm().
> --
> Edzer
> 
> pedro at dpi.inpe.br wrote:
> 
> >Hi,
> >
> >There is a quite new package on CRAN called data.table. It implements
> >the class data.table representing a data.frame without rownames, in 
> >order to improve performance. So, it has the same objective 
> of the sp 
> >class AttributeList. I confess that I'm very superficial in terms of 
> >the functionality available in both classes, but I think the 
> projects 
> >could work together, or even be merged.
> >
> >Best wishes,
> >
> >Pedro Andrade
> >
> >---------- Forwarded message ----------
> >Date: Wed, 12 Apr 2006 15:19:10 +0100
> >From: Matthew Dowle <mdowle at concordiafunds.com>
> >To: "'r-devel at r-project.org'" <r-devel at r-project.org>,
> >      "'Cran at r-project.org'" <Cran at r-project.org>
> >Subject: [Rd] New class: data.table
> >
> >
> >Hi,
> >
> >Following previous discussion on this list
> >(http://tolstoy.newcastle.edu.au/R/devel/05/12/3439.html) I have 
> >created a package as suggested, and uploaded it to CRAN incoming : 
> >data.table.tar.gz.
> >
> >** Your comments and feedback will be very much appreciated. **
> >
> >  
> >
> >>From help(data.table) :
> >>    
> >>
> >
> >This class really does very little. The only reason for its 
> existence 
> >is that the white book specifies that data.frame must have rownames.
> >
> >Most of the code is copied from base functions with the code 
> >manipulating row.names removed.
> >
> >A data.table is identical to a data.frame other than:
> >  	* it doesn't have rownames
> >  	* [,drop] by default is FALSE, so selecting a single 
> row will always 
> >return a single row data.table not a vector
> >  	* The comma is optional inside [], so DT[3] returns the 
> 3rd row as a 
> >1 row data.table
> >  	* [] is like a call to subset()
> >  	* [,...], is like a call to with().  (not yet implemented)
> >
> >Motivation:
> >  	* up to 10 times less memory
> >  	* up to 10 times faster to create, and copy
> >  	* simpler R code
> >  	* the white book defines rownames, so data.frame can't 
> be changed 
> >... => new class
> >
> >Examples:
> >nr = 1000000
> >D = rep(1:5,nr/5)
> >system.time(DF <<- data.frame(colA=D, colB=D))  # 2.08 
> system.time(DT 
> ><<- data.table(colA=D, colB=D))  # 0.15  (over 10 times faster to 
> >create) identical(as.data.table(DF), DT)
> >identical(dim(DT),dim(DF))
> >object.size(DF)/object.size(DT)                 # 10 times 
> less memory
> >
> >tt = subset(DF,colA>3)
> >ss = DT[colA>3]
> >identical(as.data.table(tt), ss)
> >
> >mean(subset(DF,colA+colB>5,"colB"))
> >mean(DT[colA+colB>5]$colB)
> >
> >tt = with(subset(DF,colA>3),colA+colB)
> >ss = with(DT[colA>3],colA+colB)                 # but could be:
> >DT[colA>3,colA+colB]  (not yet implemented)
> >identical(tt, ss)
> >
> >tt = DF[with(DF,tapply(1:nrow(DF),colB,last)),] # select last row 
> >grouping by colB
> >ss = DT[tapply(1:nrow(DT),colB,last)]           # but could be:
> >DT[last,group=colB]  (not yet implemented) 
> identical(as.data.table(tt), 
> >ss)
> >
> >Lkp=1:3
> >tt = DF[with(DF,colA %in% Lkp),]
> >ss = DT[colA %in% Lkp]                        # expressions 
> inside the []
> >can see objects in the calling frame identical(as.data.table(tt), ss)
> >
> >In each case above there is either a space, time, or code brevity 
> >advantage with the data.table.
> >
> >The motivation for the new class grew from the realization that 
> >performance of data.frames can be improved by removing the 
> rownames.  
> >See here for the previous discussion 
> >http://tolstoy.newcastle.edu.au/R/devel/05/12/3439.html.
> >
> >Regards,
> >Matthew
> >
> >______________________________________________
> >R-devel at r-project.org mailing list 
> >https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >_______________________________________________
> >R-sig-Geo mailing list
> >R-sig-Geo at stat.math.ethz.ch 
> >https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >  
> >
> 
>



From mdsumner at utas.edu.au  Tue Apr 18 18:39:59 2006
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Wed, 19 Apr 2006 02:39:59 +1000
Subject: [R-sig-Geo] times and ID records for sp
In-Reply-To: <78166BFC5165D811AA0400065BF0324BF07FE6@wisconsin.concordia>
References: <78166BFC5165D811AA0400065BF0324BF07FE6@wisconsin.concordia>
Message-ID: <4445165F.207@utas.edu.au>

Hello, I'm trying to figure out the best way to represent time-ordered 
records
in a SpatialPointsDataFrame.

In other contexts . . . I use a class "trip" which is simply a list of 
slots "x", "y", "time", "id"
and until now I've simply handled it as a list internally and defined 
methods
for as.list and as.data.frame - I'd like to write it as a SPDF.

What I'd mostly like to do is a single vector of class POSIXct/lt with 
names.
The names would act as a grouping factor for individual record sets 
within the
time-ordered records, and so validity functions would ensure that the 
times were
increasing within factors. Then I would have an extension to SPDF where one
column was "timeID" and handle all the trip information that way. I've 
toyed
with creating another slot (like coordinates) to hold a dataframe of 
timedates and
IDs, but it's mostly too complicated for me since POSIXt is S3 - I just 
don't understand how to setOldClass -,
and row names are (quite rightly) dropped in sp's AttributeList and so 
I'm kind of on the wrong track.

Nothing like asking a question: as I write this I think perhaps it 
should be a new slot that is a matrix (just like coords), and I just store
the times and IDs as integers with conversion methods when they are 
accessed . . . Then
the new class is an extension of SPDF (or perhaps of SpatialPoints - the 
time/IDs don't need to be considered
as "data" if the methods are all there).  I'd always assumed I would use 
POSIXt, but that can be wrapped in the accessor methods
I think. 

I'll try that out - thanks for listening, and I welcome any advice. I've 
toyed with some of the
irregular time series in its and zoo, but they seem like overkill for my 
purposes.


Cheers, Mike.



From bbrehmer at refractions.net  Tue Apr 18 20:23:29 2006
From: bbrehmer at refractions.net (Ben Brehmer)
Date: Tue, 18 Apr 2006 11:23:29 -0700
Subject: [R-sig-Geo] Natural Breaks - Jenks
Message-ID: <44452EA1.3000404@refractions.net>

I have implemented Jenks' algorithm (for finding the natural breaks) in 
php thanks to some sample code I found at: 
http://www.mail-archive.com/r-sig-geo at stat.math.ethz.ch/msg00290.html . 
This algorithm is also implemented in ArcView to determine natural 
breaks in the legends.
Currently I am running the algorithm on a data set which has 65 000 
elements in it, which takes over 3 hours (due to a nested for loop). 
ArcViews' implementation on the other hand returns within seconds. Would 
anyone possibly know why ArcViews implementation is so much more efficient.

Any help would be greatly appreciated.

Ben Brehmer



From Roger.Bivand at nhh.no  Tue Apr 18 20:53:43 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 18 Apr 2006 20:53:43 +0200 (CEST)
Subject: [R-sig-Geo] times and ID records for sp
In-Reply-To: <4445165F.207@utas.edu.au>
Message-ID: <Pine.LNX.4.44.0604182045050.3550-100000@reclus.nhh.no>

On Wed, 19 Apr 2006, Michael Sumner wrote:

> Hello, I'm trying to figure out the best way to represent time-ordered 
> records
> in a SpatialPointsDataFrame.

Interesting question. I might have chosen rather to create a 
time_ordered_records object, use the standard SpatialPoints object, and go 
to a SpatialPointsTOR object, for which the standard SpatialPoints methods 
should still work. Then the extra logic for validation can be put in place 
without needing to fit the AttributeList object framework. Another 
possibility is to stack the IDs on the outside, in a new class of a set of 
SpatialPointsTOR objects, one object per unique trip, which would make it 
easier to retrieve by ID - SPDF are by design best at retrieving per 
location.

Please tell us how you got on!

Roger

> 
> In other contexts . . . I use a class "trip" which is simply a list of 
> slots "x", "y", "time", "id"
> and until now I've simply handled it as a list internally and defined 
> methods
> for as.list and as.data.frame - I'd like to write it as a SPDF.
> 
> What I'd mostly like to do is a single vector of class POSIXct/lt with 
> names.
> The names would act as a grouping factor for individual record sets 
> within the
> time-ordered records, and so validity functions would ensure that the 
> times were
> increasing within factors. Then I would have an extension to SPDF where one
> column was "timeID" and handle all the trip information that way. I've 
> toyed
> with creating another slot (like coordinates) to hold a dataframe of 
> timedates and
> IDs, but it's mostly too complicated for me since POSIXt is S3 - I just 
> don't understand how to setOldClass -,
> and row names are (quite rightly) dropped in sp's AttributeList and so 
> I'm kind of on the wrong track.
> 
> Nothing like asking a question: as I write this I think perhaps it 
> should be a new slot that is a matrix (just like coords), and I just store
> the times and IDs as integers with conversion methods when they are 
> accessed . . . Then
> the new class is an extension of SPDF (or perhaps of SpatialPoints - the 
> time/IDs don't need to be considered
> as "data" if the methods are all there).  I'd always assumed I would use 
> POSIXt, but that can be wrapped in the accessor methods
> I think. 
> 
> I'll try that out - thanks for listening, and I welcome any advice. I've 
> toyed with some of the
> irregular time series in its and zoo, but they seem like overkill for my 
> purposes.
> 
> 
> Cheers, Mike.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Tue Apr 18 21:04:46 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 18 Apr 2006 21:04:46 +0200 (CEST)
Subject: [R-sig-Geo] Natural Breaks - Jenks
In-Reply-To: <44452EA1.3000404@refractions.net>
Message-ID: <Pine.LNX.4.44.0604182053580.3550-100000@reclus.nhh.no>

On Tue, 18 Apr 2006, Ben Brehmer wrote:

> I have implemented Jenks' algorithm (for finding the natural breaks) in 
> php thanks to some sample code I found at: 
> http://www.mail-archive.com/r-sig-geo at stat.math.ethz.ch/msg00290.html . 
> This algorithm is also implemented in ArcView to determine natural 
> breaks in the legends.
> Currently I am running the algorithm on a data set which has 65 000 
> elements in it, which takes over 3 hours (due to a nested for loop). 
> ArcViews' implementation on the other hand returns within seconds. Would 
> anyone possibly know why ArcViews implementation is so much more efficient.

library(classInt)
?classIntervals
y <- runif(65000)
yClass <- classIntervals(y, n=5, style="fisher")

runs on a 1.5GHz machine in 225 seconds. This is using the Fortran code 
you refer to directly. My guess is that Arc looks at the number of unique 
values, and, if there are many, uses a heuristic. If it sampled and set 
the seed the same each time, the result would be the same, and the code 
runs acceptably fast for say 2000 values. Maybe Arc also precomputes 
values?

Roger

> 
> Any help would be greatly appreciated.
> 
> Ben Brehmer
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From munroe.9 at osu.edu  Tue Apr 18 21:21:15 2006
From: munroe.9 at osu.edu (Darla Munroe)
Date: Tue, 18 Apr 2006 15:21:15 -0400
Subject: [R-sig-Geo] Natural Breaks - Jenks
In-Reply-To: <Pine.LNX.4.44.0604182053580.3550-100000@reclus.nhh.no>
Message-ID: <007001c6631d$431a8250$7cc29280@MUNROE>

yes, by default I think ArcGIS takes a 10% sample to create its breaks, and
you have to go in manually to change that option, and yes, Roger - I think
you're right - it samples the data as you load it into the map (you can see
this if you have a very large discrete grid - it won't display all the cells
if there are more than 5,000 or some such cut-off number).

-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Roger Bivand
Sent: Tuesday, April 18, 2006 2:05 PM
To: Ben Brehmer
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] Natural Breaks - Jenks

On Tue, 18 Apr 2006, Ben Brehmer wrote:

> I have implemented Jenks' algorithm (for finding the natural breaks) in 
> php thanks to some sample code I found at: 
> http://www.mail-archive.com/r-sig-geo at stat.math.ethz.ch/msg00290.html . 
> This algorithm is also implemented in ArcView to determine natural 
> breaks in the legends.
> Currently I am running the algorithm on a data set which has 65 000 
> elements in it, which takes over 3 hours (due to a nested for loop). 
> ArcViews' implementation on the other hand returns within seconds. Would 
> anyone possibly know why ArcViews implementation is so much more
efficient.

library(classInt)
?classIntervals
y <- runif(65000)
yClass <- classIntervals(y, n=5, style="fisher")

runs on a 1.5GHz machine in 225 seconds. This is using the Fortran code 
you refer to directly. My guess is that Arc looks at the number of unique 
values, and, if there are many, uses a heuristic. If it sampled and set 
the seed the same each time, the result would be the same, and the code 
runs acceptably fast for say 2000 values. Maybe Arc also precomputes 
values?

Roger

> 
> Any help would be greatly appreciated.
> 
> Ben Brehmer
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From mdsumner at utas.edu.au  Wed Apr 19 02:45:29 2006
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Wed, 19 Apr 2006 10:45:29 +1000
Subject: [R-sig-Geo] times and ID records for sp
In-Reply-To: <4445165F.207@utas.edu.au>
References: <78166BFC5165D811AA0400065BF0324BF07FE6@wisconsin.concordia>
	<4445165F.207@utas.edu.au>
Message-ID: <44458829.9060502@utas.edu.au>

Hello, so far it's going well.  I have a class "SpatialPointsTOR" that 
extends SpatialPoints by adding two slots:

library(sp)
setClass("SpatialPointsTOR", representation("SpatialPoints", timeID = 
"matrix", TORlevels = "character"))

I suspect it would be better to create a completely separate class and 
so hide the expanding list of slots inside that ?
But so far I have print, plot, show, summary, "[" methods for the class 
that do what I want by indexing the id column
of timeID to TORlevels, and simply assuming the epoch = 
ISOdatetime(1970, 1, 1, 0, 0, 0, tz = "GMT") and adding that
to the time column.  (I'll have to think about cases for POSIXlt, and 
for Dates).

Thanks so much for sp!  This is already useful to me, and it will be 
nice to replace my clunky other classes with the
real power of sp. Once I've done a little more I'll package it up and 
provide some examples.

########################################################################################
########################################################################################

My new question involves a potential problem if proj4strings are passed 
in as "NA" rather than as.character(NA):

pts <- SpatialPoints(matrix(c(159, 143, -43, -42), ncol =2), 
CRS("+proj=longlat"))
is.projected(pts)
library(rgdal)
pts <- transform(pts, CRS("+proj=lcc +lon_0=160"))

So far so good, but is.projected seems to just grep for "longlat" and 
otherwise return TRUE.  Shouldn't this have some
validation of the CRS to avoid the following?
pts <- SpatialPoints(matrix(c(159, 143, -43, -42), ncol =2), "NA")   
is.projected(pts)  #TRUE

(I'm not sure how common this would be but I certainly made the error with
a constructor like this:
...
p4string <- "NA"
new("SpatialPointsTOR", SpatialPoints(crds, proj4string = 
CRS(p4string)), ...


Cheers, Mike.



From mdsumner at utas.edu.au  Wed Apr 19 02:57:11 2006
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Wed, 19 Apr 2006 10:57:11 +1000
Subject: [R-sig-Geo] earth distance between points
Message-ID: <44458AE7.4000902@utas.edu.au>

Further to my SpatialPoints TimeOrderedRecords interest:  sp has a 
function spDistsN1 to calculate distances
between 1 and many other locations - I would like to calculate distances 
between succesive locations.

Currently I use this with a clunky dispatch method of my own for great 
circle (sphere) versus Euclidean, where a and b are
subset matrices with the first and last row removed respectively, i.e.

x <- matrix(c(159, 143, 168, -43, -42, -54), ncol =2)
dist.gc(x[-1,], x[-nrow(x),])

## great circle (sphere)
dist.gc <- function(a, b) {
        r <- cos(pi/180 * a[, 2]) * cos(pi/180 * b[, 2]) * cos(pi/180 *
            (b[, 1] - a[, 1])) + sin(pi/180 * a[, 2]) * sin(pi/180 *
            b[, 2])
        6378.137 * acos(pmin(r, 1))
    }

## Euclidean
 dist <- function(a, b) {
            sqrt(rowSums((a - b)^2))
    }

Is there plans for a more general distance function in sp, or should I 
work towards incorporating these functions - they usually suffice
for my purposes but the sphere is not always going to be enough.

  spDistsN1 seems quite specific to a particular need.

Cheers, Mike.



From Roger.Bivand at nhh.no  Wed Apr 19 08:23:46 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 19 Apr 2006 08:23:46 +0200 (CEST)
Subject: [R-sig-Geo] times and ID records for sp
In-Reply-To: <44458829.9060502@utas.edu.au>
Message-ID: <Pine.LNX.4.44.0604190810150.4135-100000@reclus.nhh.no>

On Wed, 19 Apr 2006, Michael Sumner wrote:

> Hello, so far it's going well.  I have a class "SpatialPointsTOR" that 
> extends SpatialPoints by adding two slots:
> 
> library(sp)
> setClass("SpatialPointsTOR", representation("SpatialPoints", timeID = 
> "matrix", TORlevels = "character"))
> 
> I suspect it would be better to create a completely separate class and 
> so hide the expanding list of slots inside that ?
> But so far I have print, plot, show, summary, "[" methods for the class 
> that do what I want by indexing the id column
> of timeID to TORlevels, and simply assuming the epoch = 
> ISOdatetime(1970, 1, 1, 0, 0, 0, tz = "GMT") and adding that
> to the time column.  (I'll have to think about cases for POSIXlt, and 
> for Dates).
> 
> Thanks so much for sp!  This is already useful to me, and it will be 
> nice to replace my clunky other classes with the
> real power of sp. Once I've done a little more I'll package it up and 
> provide some examples.
> 
> ########################################################################################
> ########################################################################################
> 
> My new question involves a potential problem if proj4strings are passed 
> in as "NA" rather than as.character(NA):
> 
> pts <- SpatialPoints(matrix(c(159, 143, -43, -42), ncol =2), 
> CRS("+proj=longlat"))
> is.projected(pts)
> library(rgdal)
> pts <- transform(pts, CRS("+proj=lcc +lon_0=160"))
> 
> So far so good, but is.projected seems to just grep for "longlat" and 
> otherwise return TRUE.  Shouldn't this have some
> validation of the CRS to avoid the following?
> pts <- SpatialPoints(matrix(c(159, 143, -43, -42), ncol =2), "NA")   
> is.projected(pts)  #TRUE

I get:

> pts <- SpatialPoints(matrix(c(159, 143, -43, -42), ncol =2), "NA")   
Error in validObject(.Object) : invalid class "SpatialPoints" object: 
invalid object for slot "proj4string" in class "SpatialPoints": got class 
"character", should be or extend class "CRS"

for:

> sessionInfo()
R version 2.2.1, 2005-12-20, i686-pc-linux-gnu 

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[7] "base"     

other attached packages:
      sp 
"0.8-14" 

but:

> pts <- SpatialPoints(matrix(c(159, 143, -43, -42), ncol =2), CRS("NA"))   
> is.projected(pts)
[1] TRUE

The checking code requires access to the libraries etc, which are in 
rgdal. As of now, these are not aligned, so even when rgdal is attached, 
no checking is done automatically. So:

> library(rgdal)
> .valid.CRSobj(CRS("NA"))
[1] "no arguments in initialization list"
> .valid.CRSobj(CRS("+proj=longlat +ellps=WGS84"))
[1] TRUE

There is about 1.5M to carry around just for PROJ.4. So I guess we'll have 
to work around things by examining the search path, and validate the CRS 
object if rgdal is attached. I think there are issues with pckage 
namespaces too (rgdal doesn't have one, sp does).

Roger

> 
> (I'm not sure how common this would be but I certainly made the error with
> a constructor like this:
> ...
> p4string <- "NA"
> new("SpatialPointsTOR", SpatialPoints(crds, proj4string = 
> CRS(p4string)), ...
> 
> 
> Cheers, Mike.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Wed Apr 19 08:34:04 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 19 Apr 2006 08:34:04 +0200 (CEST)
Subject: [R-sig-Geo] earth distance between points
In-Reply-To: <44458AE7.4000902@utas.edu.au>
Message-ID: <Pine.LNX.4.44.0604190825580.4135-100000@reclus.nhh.no>

On Wed, 19 Apr 2006, Michael Sumner wrote:

> Further to my SpatialPoints TimeOrderedRecords interest:  sp has a 
> function spDistsN1 to calculate distances
> between 1 and many other locations - I would like to calculate distances 
> between succesive locations.

Have a look inside the existing function and *apply or loop over the marix 
rows for .C("sp_dists", ...). There is a similar approach to azimuths in 
the latest maptools (trackAzimuth()). Yes, the current solution is 
specific, and was an attempt to centralise GreatCircle compiled code. 
However, so far R packages cannot be compiled against each others' shared 
libraries, so inter-package calls need to be at the R level, or force code 
copying (which isn't a big problem, but is not good practice for 
maintenance).

Roger

> 
> Currently I use this with a clunky dispatch method of my own for great 
> circle (sphere) versus Euclidean, where a and b are
> subset matrices with the first and last row removed respectively, i.e.
> 
> x <- matrix(c(159, 143, 168, -43, -42, -54), ncol =2)
> dist.gc(x[-1,], x[-nrow(x),])
> 
> ## great circle (sphere)
> dist.gc <- function(a, b) {
>         r <- cos(pi/180 * a[, 2]) * cos(pi/180 * b[, 2]) * cos(pi/180 *
>             (b[, 1] - a[, 1])) + sin(pi/180 * a[, 2]) * sin(pi/180 *
>             b[, 2])
>         6378.137 * acos(pmin(r, 1))
>     }
> 
> ## Euclidean
>  dist <- function(a, b) {
>             sqrt(rowSums((a - b)^2))
>     }
> 
> Is there plans for a more general distance function in sp, or should I 
> work towards incorporating these functions - they usually suffice
> for my purposes but the sphere is not always going to be enough.
> 
>   spDistsN1 seems quite specific to a particular need.
> 
> Cheers, Mike.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From mdsumner at utas.edu.au  Wed Apr 19 09:00:26 2006
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Wed, 19 Apr 2006 17:00:26 +1000
Subject: [R-sig-Geo] earth distance between points
In-Reply-To: <Pine.LNX.4.44.0604190825580.4135-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0604190825580.4135-100000@reclus.nhh.no>
Message-ID: <4445E00A.80905@utas.edu.au>

Thanks Roger.

trackDistance <-
function (track, longlat = FALSE)
{
    if (!is.matrix(track))
        stop("track must be two-column matrix")
    if (ncol(track) != 2)
        stop("track must be two-column matrix")
    n1 <- nrow(track) - 1
    if (n1 < 2)
        stop("less than two points")
    res <- numeric(n1)
    for (i in seq(along = res))
      res[i] <- spDistsN1(track[i,,drop = FALSE],
                          track[(i + 1),,drop = FALSE ], longlat = longlat)
    res
}


ll <- matrix(c(5, 6, 60, 60), ncol=2)
      km <- spDistsN1(ll, ll[1,], longlat=TRUE)
      zapsmall(km)

ll.trk <- matrix(c(5, 6, 8, 8,  60, 60, 60,  60), ncol=2)
km.trk <- trackDistance(ll.trk, longlat = TRUE)
zapsmall(km.trk)


On Wed, 19 Apr 2006, Michael Sumner wrote:


> > Further to my SpatialPoints TimeOrderedRecords interest:  sp has a 
> > function spDistsN1 to calculate distances
> > between 1 and many other locations - I would like to calculate distances 
> > between succesive locations.
>   

Have a look inside the existing function and *apply or loop over the marix 
rows for .C("sp_dists", ...). There is a similar approach to azimuths in 
the latest maptools (trackAzimuth()). Yes, the current solution is 
specific, and was an attempt to centralise GreatCircle compiled code. 
However, so far R packages cannot be compiled against each others' shared 
libraries, so inter-package calls need to be at the R level, or force code 
copying (which isn't a big problem, but is not good practice for 
maintenance).

Roge



From e.pebesma at geo.uu.nl  Wed Apr 19 10:25:44 2006
From: e.pebesma at geo.uu.nl (Edzer J. Pebesma)
Date: Wed, 19 Apr 2006 10:25:44 +0200
Subject: [R-sig-Geo] times and ID records for sp
In-Reply-To: <Pine.LNX.4.44.0604182045050.3550-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0604182045050.3550-100000@reclus.nhh.no>
Message-ID: <4445F408.8030106@geo.uu.nl>

Roger Bivand wrote:
> On Wed, 19 Apr 2006, Michael Sumner wrote:
>
>   
>> Hello, I'm trying to figure out the best way to represent time-ordered 
>> records
>> in a SpatialPointsDataFrame.
>>     
>
> Interesting question. I might have chosen rather to create a 
> time_ordered_records object, use the standard SpatialPoints object, and go 
> to a SpatialPointsTOR object, for which the standard SpatialPoints methods 
> should still work. Then the extra logic for validation can be put in place 
> without needing to fit the AttributeList object framework. Another 
> possibility is to stack the IDs on the outside, in a new class of a set of 
> SpatialPointsTOR objects, one object per unique trip, which would make it 
> easier to retrieve by ID - SPDF are by design best at retrieving per 
> location.
>   
... or per attribute characteristics; if say sea elephant SE0031 is the 
id of a
given trip , and the id is called SE in the AttributeList of the SPDF,
you could select its tracked locations from spdf with

spdf[, spdf$SE == "SE0031"]

or using subset().

Bests,
--
Edzer



From toady2k at hotmail.com  Wed Apr 19 15:11:02 2006
From: toady2k at hotmail.com (Toad 2000)
Date: Wed, 19 Apr 2006 14:11:02 +0100
Subject: [R-sig-Geo] Raster data and MySQL
Message-ID: <BAY24-F177AD9C5D8D2AFBC3CB972F1C50@phx.gbl>

Hi Folks,

Hope this isn't too far off topic + apologies for cross posting if you're on 
both lists...

I'm in the lucky(?) position of setting up an archive of geophysical 
(meteorological) data from scratch. R has been my working 
language/environment for the last few years. I've had plenty of need for the 
maptools + rgdal packages.  Ditto the RMySQL package but never inconjuction 
with spatial analyses.  My worlds are about to collide.

The data come in two types: Station data (irregular grid, irregular times, 
lots of missing values) and Model output (regular grid, regular times, no 
missing data).  The data come in hour after hour, day after day.

Typical queries can be spatial (e.g. what did the rainfall over a given post 
code area look like yesterday?), temporal (what were the houlry wind speeds 
at a specific point for last month?), or both (what was the mean temperature 
across the UK last year).

So how best to store the data to facilitate such queries?  This is where I 
hope you can help! :)

My initial thoughts are to invoke the spatial capabilites of MySQL.  The 
station data seem easy enough to store as POINT or MULTIPOINT and set up a 
spatial index and another on the time stamp.  Spatial queries can be 
performed using a WKB (Well Known Binary - new to me;) representation of the 
region of interest.

I'm stuck on the model data.  I could break it down into points and proceed 
as above but this seems grossly inefficient.  I was hoping to find a RASTER 
data type and store the grids in that.  Trouble is, I could be missing 
something, that I can't seem to find anything like one in MySQL.  Don't know 
about Postgre or SQL sever.  I'm open to suggestions.

Your hopefully, T

_________________________________________________________________

7.5 today! http://join.msn.com/messenger/overview



From ljlayne at unm.edu  Wed Apr 19 16:02:50 2006
From: ljlayne at unm.edu (Larry Layne)
Date: Wed, 19 Apr 2006 08:02:50 -0600
Subject: [R-sig-Geo] polygon identifiers and nb classes
In-Reply-To: <Pine.LNX.4.44.0604142045430.14359-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0604142045430.14359-100000@reclus.nhh.no>
Message-ID: <8455A8291555CD71258BB23A@dhcp-129-24-91-249.unm.edu>

Hello Roger,

> Here is a first cut, which seems to emit a suitable file. If you can try
> it and/or send back an Arc command line say for COLUMBUS.SHP CRIME and
> NEIGNO as index in GeoDa, I would be grateful:

I'm not exactly sure what "as index in GeoDa" means but I have successfully 
tested your code on 2 different data sets: my own and the columbus.shp 
shapefile. Here is the full code to create the text file of spatial weights 
in the form that ArcGIS wants them. The columbus shapefile is used as the 
example file here:

library(maptools)
library(maps)
library(spdep)

setwd("E:\\ShapeFiles")
getwd()

COLUMBUSmap <- read.shape("columbus.shp")
COLUMBUSpolylist <- Map2poly(COLUMBUSmap,region.id=NULL,quiet=TRUE)
COLUMBUSnb <- poly2nb(COLUMBUSpolylist,row.names="POLYID",queen=FALSE)
print(is.symmetric.nb(COLUMBUSnb))

write.sn2Arc(listw2sn(nb2listw(COLUMBUSnb,style="B")),file="E://Shapefiles//zweights_test.txt",field="POLYID")

The tests were successful using style="B" or style="W".
Following are 2 Arc command lines, one for CRIME and the other for NEIGNO:

SpatialAutocorrelation columbus CRIME false "Get Spatial Weights From File" 
"Euclidean Distance" None 0 E:\Shapefiles\zweights_test.txt 0 0

SpatialAutocorrelation columbus NEIGNO false "Get Spatial Weights From 
File" "Euclidean Distance" None 0 E:\Shapefiles\zweights_test.txt 0 0

Thanks for the effort you put into this.

Larry



From Roger.Bivand at nhh.no  Wed Apr 19 16:03:01 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 19 Apr 2006 16:03:01 +0200 (CEST)
Subject: [R-sig-Geo] Raster data and MySQL
In-Reply-To: <BAY24-F177AD9C5D8D2AFBC3CB972F1C50@phx.gbl>
Message-ID: <Pine.LNX.4.44.0604191557260.4198-100000@reclus.nhh.no>

On Wed, 19 Apr 2006, Toad 2000 wrote:

> Hi Folks,
> 
> Hope this isn't too far off topic + apologies for cross posting if you're on 
> both lists...
> 
> I'm in the lucky(?) position of setting up an archive of geophysical 
> (meteorological) data from scratch. R has been my working 
> language/environment for the last few years. I've had plenty of need for the 
> maptools + rgdal packages.  Ditto the RMySQL package but never inconjuction 
> with spatial analyses.  My worlds are about to collide.
> 
> The data come in two types: Station data (irregular grid, irregular times, 
> lots of missing values) and Model output (regular grid, regular times, no 
> missing data).  The data come in hour after hour, day after day.
> 
> Typical queries can be spatial (e.g. what did the rainfall over a given post 
> code area look like yesterday?), temporal (what were the houlry wind speeds 
> at a specific point for last month?), or both (what was the mean temperature 
> across the UK last year).
> 
> So how best to store the data to facilitate such queries?  This is where I 
> hope you can help! :)

Could you have a look at aRT? It has an R component, a database (typically 
MySQL) component, and uses Terralib as glue:

http://www.est.ufpr.br/art/

I think you can use RMySQL directly for non-spatial tasks too. Terralib 
has well-developed spatial data types.

> 
> My initial thoughts are to invoke the spatial capabilites of MySQL.  The 
> station data seem easy enough to store as POINT or MULTIPOINT and set up a 
> spatial index and another on the time stamp.  Spatial queries can be 
> performed using a WKB (Well Known Binary - new to me;) representation of the 
> region of interest.
> 
> I'm stuck on the model data.  I could break it down into points and proceed 
> as above but this seems grossly inefficient.  I was hoping to find a RASTER 
> data type and store the grids in that.  Trouble is, I could be missing 
> something, that I can't seem to find anything like one in MySQL.  Don't know 
> about Postgre or SQL sever.  I'm open to suggestions.
> 
> Your hopefully, T
> 
> _________________________________________________________________
> 
> 7.5 today! http://join.msn.com/messenger/overview
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Wed Apr 19 16:06:11 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 19 Apr 2006 16:06:11 +0200 (CEST)
Subject: [R-sig-Geo] polygon identifiers and nb classes
In-Reply-To: <8455A8291555CD71258BB23A@dhcp-129-24-91-249.unm.edu>
Message-ID: <Pine.LNX.4.44.0604191604580.4198-100000@reclus.nhh.no>

On Wed, 19 Apr 2006, Larry Layne wrote:

> Hello Roger,
> 
> > Here is a first cut, which seems to emit a suitable file. If you can try
> > it and/or send back an Arc command line say for COLUMBUS.SHP CRIME and
> > NEIGNO as index in GeoDa, I would be grateful:
> 
> I'm not exactly sure what "as index in GeoDa" means but I have successfully 
> tested your code on 2 different data sets: my own and the columbus.shp 
> shapefile. Here is the full code to create the text file of spatial weights 
> in the form that ArcGIS wants them. The columbus shapefile is used as the 
> example file here:
> 
> library(maptools)
> library(maps)
> library(spdep)
> 
> setwd("E:\\ShapeFiles")
> getwd()
> 
> COLUMBUSmap <- read.shape("columbus.shp")
> COLUMBUSpolylist <- Map2poly(COLUMBUSmap,region.id=NULL,quiet=TRUE)
> COLUMBUSnb <- poly2nb(COLUMBUSpolylist,row.names="POLYID",queen=FALSE)
> print(is.symmetric.nb(COLUMBUSnb))
> 
> write.sn2Arc(listw2sn(nb2listw(COLUMBUSnb,style="B")),file="E://Shapefiles//zweights_test.txt",field="POLYID")
> 
> The tests were successful using style="B" or style="W".
> Following are 2 Arc command lines, one for CRIME and the other for NEIGNO:
> 
> SpatialAutocorrelation columbus CRIME false "Get Spatial Weights From File" 
> "Euclidean Distance" None 0 E:\Shapefiles\zweights_test.txt 0 0
> 
> SpatialAutocorrelation columbus NEIGNO false "Get Spatial Weights From 
> File" "Euclidean Distance" None 0 E:\Shapefiles\zweights_test.txt 0 0

Thanks, useful! The function will be in the next spdep release.

Roger

> 
> Thanks for the effort you put into this.
> 
> Larry
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From jeff.horner at vanderbilt.edu  Wed Apr 19 16:27:15 2006
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Wed, 19 Apr 2006 09:27:15 -0500
Subject: [R-sig-Geo] [R-sig-DB] Raster data and MySQL
In-Reply-To: <BAY24-F177AD9C5D8D2AFBC3CB972F1C50@phx.gbl>
References: <BAY24-F177AD9C5D8D2AFBC3CB972F1C50@phx.gbl>
Message-ID: <444648C3.3000906@vanderbilt.edu>

Toad 2000 wrote:
> Hi Folks,
> 
> Hope this isn't too far off topic + apologies for cross posting if you're on 
> both lists...
> 
> I'm in the lucky(?) position of setting up an archive of geophysical 
> (meteorological) data from scratch. R has been my working 
> language/environment for the last few years. I've had plenty of need for the 
> maptools + rgdal packages.  Ditto the RMySQL package but never inconjuction 
> with spatial analyses.  My worlds are about to collide.
> 
> The data come in two types: Station data (irregular grid, irregular times, 
> lots of missing values) and Model output (regular grid, regular times, no 
> missing data).  The data come in hour after hour, day after day.
> 
> Typical queries can be spatial (e.g. what did the rainfall over a given post 
> code area look like yesterday?), temporal (what were the houlry wind speeds 
> at a specific point for last month?), or both (what was the mean temperature 
> across the UK last year).
> 
> So how best to store the data to facilitate such queries?  This is where I 
> hope you can help! :)
> 
> My initial thoughts are to invoke the spatial capabilites of MySQL.  The 
> station data seem easy enough to store as POINT or MULTIPOINT and set up a 
> spatial index and another on the time stamp.  Spatial queries can be 
> performed using a WKB (Well Known Binary - new to me;) representation of the 
> region of interest.

Neither RMySQL nor RODBC support BLOB types or any of the Spatial types. 
BLOB (binary large object) types are useful for storing any binary data, 
including raster images. Also, some of the comments here:

http://dev.mysql.com/doc/refman/5.0/en/populating-spatial-columns.html

suggest that actually getting data into MySQL may be difficult.

What's really needed is an update to the R DBI spec to support prepared 
statements, placeholders, and of course BLOB types. I'm actually 
planning an R module which will use BLOB types, but not the way a DBI 
spec would, so I'd be happy to consider helping write some of this after 
I get my hands dirty with the MySQL client apis.

> 
> I'm stuck on the model data.  I could break it down into points and proceed 
> as above but this seems grossly inefficient.  I was hoping to find a RASTER 
> data type and store the grids in that.  Trouble is, I could be missing 
> something, that I can't seem to find anything like one in MySQL.  Don't know 
> about Postgre or SQL sever.  I'm open to suggestions.
> 
> Your hopefully, T
> 
> _________________________________________________________________
> 
> 7.5 today! http://join.msn.com/messenger/overview
> 
> _______________________________________________
> R-sig-DB mailing list -- R Special Interest Group
> R-sig-DB at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-db


-- 
Jeffrey Horner       Computer Systems Analyst         School of Medicine
615-322-8606         Department of Biostatistics   Vanderbilt University



From mdsumner at utas.edu.au  Thu Apr 20 00:01:22 2006
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Thu, 20 Apr 2006 08:01:22 +1000
Subject: [R-sig-Geo] Inf allowed in sp SpatialPoints
In-Reply-To: <444648C3.3000906@vanderbilt.edu>
References: <BAY24-F177AD9C5D8D2AFBC3CB972F1C50@phx.gbl>
	<444648C3.3000906@vanderbilt.edu>
Message-ID: <4446B332.6050503@utas.edu.au>

Hello, thanks for all the help, BTW.

It seems that bbox coordinates in sp are tested for is.na, but not 
is.finite.  (The only finiteness test I see
in sp is in spDistsN1.)

Is there a good reason for this?  I can see that Inf/-Inf has meaning 
under some scenarios, but perhaps they
should not be allowed by default?

Cheers, Mike.
>
> library(sp)
>
>
> pts <- cbind(c(147, 148, 149), c(-42, -42, -44))
>
> pts.na <- pts
> pts.na[2,1] <- NA  # or NaN
>
> pts.inf <- pts
> pts.inf[2,] <- Inf
>
> SpatialPoints(pts, CRS("+proj=longlat"))
> SpatialPoints(pts.na)  #doesn't work,
> SpatialPoints(pts.inf) # does work is.na(Inf) is FALSE, but plot 
> doesn't like it
> sessionInfo()
R version 2.2.1, 2005-12-20, i386-pc-mingw32

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
[7] "base"    

other attached packages:
      sp
"0.8-14"



From Roger.Bivand at nhh.no  Thu Apr 20 08:56:50 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 20 Apr 2006 08:56:50 +0200 (CEST)
Subject: [R-sig-Geo] Inf allowed in sp SpatialPoints
In-Reply-To: <4446B332.6050503@utas.edu.au>
Message-ID: <Pine.LNX.4.44.0604200852420.4886-100000@reclus.nhh.no>

On Thu, 20 Apr 2006, Michael Sumner wrote:

> Hello, thanks for all the help, BTW.
> 
> It seems that bbox coordinates in sp are tested for is.na, but not 
> is.finite.  (The only finiteness test I see
> in sp is in spDistsN1.)
> 
> Is there a good reason for this?  I can see that Inf/-Inf has meaning 
> under some scenarios, but perhaps they
> should not be allowed by default?

I agree that Inf/-Inf should not be allowed as coordinate values, in fact 
under any circumstances - any Inf or other markers ought to be in the 
attributes. We'll see if any transform/project problems arise, but these 
ought to be handled by other means. I've committed a modification to CVS 
to check bounding box values, and to prevent the Spatial object from being 
created if Inf/-Inf are present, this will be in the next release.

Thanks,

Roger

> 
> Cheers, Mike.
> >
> > library(sp)
> >
> >
> > pts <- cbind(c(147, 148, 149), c(-42, -42, -44))
> >
> > pts.na <- pts
> > pts.na[2,1] <- NA  # or NaN
> >
> > pts.inf <- pts
> > pts.inf[2,] <- Inf
> >
> > SpatialPoints(pts, CRS("+proj=longlat"))
> > SpatialPoints(pts.na)  #doesn't work,
> > SpatialPoints(pts.inf) # does work is.na(Inf) is FALSE, but plot 
> > doesn't like it
> > sessionInfo()
> R version 2.2.1, 2005-12-20, i386-pc-mingw32
> 
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
> [7] "base"    
> 
> other attached packages:
>       sp
> "0.8-14"
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From slist at oomvanlieshout.net  Sun Apr 23 16:20:04 2006
From: slist at oomvanlieshout.net (Sander Oom)
Date: Sun, 23 Apr 2006 16:20:04 +0200
Subject: [R-sig-Geo] Problem installing spproj
Message-ID: <444B8D14.5080600@oomvanlieshout.net>

Dear R-geo subscribers,

Using the following commands, I am trying in vain to install spproj:

rSpatial <- "http://r-spatial.sourceforge.net/R"
install.packages("spproj", repos=rSpatial)

I get the following response:

> rSpatial <- "http://r-spatial.sourceforge.net/R"
> install.packages("spproj", repos=rSpatial)
trying URL
'http://r-spatial.sourceforge.net/R/src/contrib/spproj_0.3-4.tar.gz'
Content type 'application/x-tar' length 2466730 bytes
opened URL
==================================================
downloaded 2408Kb

* Installing *source* package 'spproj' ...
creating cache ./config.cache
checking for pj_init_plus in -lproj... no
checking how to run the C preprocessor... cc -E
checking for proj_api.h... no
libproj.a and proj_api.h not found in standard search locations,
edit src/Makevars manually, adding -I<directory with proj_api.h>
to PKG_CPPFLAGS = , and -L<directory with libproj.a> to PKG_LIBS =
ERROR: configuration failed for package 'spproj'
** Removing '/usr/lib/R/library/spproj'

The downloaded packages are in
        /tmp/Rtmpsq7239/downloaded_packages
Warning message:
installation of package 'spproj' had non-zero exit status in:
install.packages("spproj", repos = rSpatial)
>

I am using R:
> version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    2
minor    2.1
year     2005
month    12
day      20
svn rev  36812
language R
>

Any suggestions?

Thanks in advance for your help,

Sander



PS:  The SP packages loaded with no problems:

> options(repos = "http://cran.r-project.org/")
> install.packages("sp")
trying URL 'http://cran.r-project.org/src/contrib/sp_0.8-14.tar.gz'
Content type 'application/x-tar' length 312138 bytes
opened URL
==================================================
downloaded 304Kb

* Installing *source* package 'sp' ...
** libs
gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC   -c gcdist.c -o
gcdist.o
gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC   -c init.c -o init.o
gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC   -c pip.c -o pip.o
gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC   -c Rcentroid.c
-o Rcentroid.o
gcc -shared -L/usr/local/lib -o sp.so gcdist.o init.o pip.o Rcentroid.o
  -L/usr/lib/R/lib -lR
** R
** data
** demo
** inst
** save image

** help
 >>> Building/Updating help pages for package 'sp'
     Formats: text html latex example
  00sp                              text    html    latex
  AttributeList-class               text    html    latex   example
  CRS-class                         text    html    latex   example
  DMS-class                         text    html    latex   example
  GridTopology-class                text    html    latex   example
  Line-class                        text    html    latex   example
  Line                              text    html    latex
  Lines-class                       text    html    latex   example
  Polygon-class                     text    html    latex   example
  Polygons-class                    text    html    latex   example
  Rlogo                             text    html    latex   example
  Spatial-class                     text    html    latex   example
  SpatialGrid-class                 text    html    latex   example
  SpatialGrid                       text    html    latex   example
  SpatialGridDataFrame-class        text    html    latex   example
  SpatialGridDataFrame              text    html    latex   example
  SpatialLines-class                text    html    latex   example
  SpatialLines                      text    html    latex
  SpatialLinesDataFrame-class       text    html    latex   example
  SpatialPixels-class               text    html    latex   example
  SpatialPixelsDataFrame-class      text    html    latex   example
  SpatialPoints-class               text    html    latex   example
  SpatialPoints                     text    html    latex
  SpatialPointsDataFrame-class      text    html    latex   example
  SpatialPolygons-class             text    html    latex   example
  SpatialPolygons                   text    html    latex
  SpatialPolygonsDataFrame-class    text    html    latex   example
  as.SpatialPolygons.GridTopology   text    html    latex   example
  as.SpatialPolygons.PolygonsList   text    html    latex   example
  asciigrid                         text    html    latex   example
  bbox                              text    html    latex   example
  bpy.colors                        text    html    latex   example
  bubble                            text    html    latex   example
  char2dms                          text    html    latex   example
  contourLines2SLDF                 text    html    latex   example
  coordinates-methods               text    html    latex
  coordinates                       text    html    latex   example
  coordnames-methods                text    html    latex
  degaxis                           text    html    latex   example
  dimensions                        text    html    latex   example
  gridded-methods                   text    html    latex   example
  gridlines                         text    html    latex   example
  image                             text    html    latex   example
  is.projected                      text    html    latex   example
  mapasp                            text    html    latex
  meuse                             text    html    latex   example
  meuse.grid                        text    html    latex   example
  meuse.riv                         text    html    latex   example
  nowrapSpatialLines                text    html    latex   example
  overlay-methods                   text    html    latex
  overlay                           text    html    latex   example
  panel                             text    html    latex   example
  point.in.polygon                  text    html    latex   example
  polygons-methods                  text    html    latex
  polygons                          text    html    latex   example
  recenter-methods                  text    html    latex   example
  select.spatial                    text    html    latex   example
  spDistsN1                         text    html    latex   example
  spplot                            text    html    latex   example
  spsample                          text    html    latex   example
  stack                             text    html    latex   example
  transform-methods                 text    html    latex
  zerodist                          text    html    latex   example
** building package indices ...
* DONE (sp)

The downloaded packages are in
        /tmp/Rtmpsq7239/downloaded_packages
>



From Roger.Bivand at nhh.no  Sun Apr 23 16:57:04 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 23 Apr 2006 16:57:04 +0200 (CEST)
Subject: [R-sig-Geo] Problem installing spproj
In-Reply-To: <444B8D14.5080600@oomvanlieshout.net>
Message-ID: <Pine.LNX.4.44.0604231655150.19193-100000@reclus.nhh.no>

On Sun, 23 Apr 2006, Sander Oom wrote:

> Dear R-geo subscribers,
> 
> Using the following commands, I am trying in vain to install spproj:
> 
> rSpatial <- "http://r-spatial.sourceforge.net/R"
> install.packages("spproj", repos=rSpatial)
> 
> I get the following response:
> 
> > rSpatial <- "http://r-spatial.sourceforge.net/R"
> > install.packages("spproj", repos=rSpatial)
> trying URL
> 'http://r-spatial.sourceforge.net/R/src/contrib/spproj_0.3-4.tar.gz'
> Content type 'application/x-tar' length 2466730 bytes
> opened URL
> ==================================================
> downloaded 2408Kb
> 
> * Installing *source* package 'spproj' ...
> creating cache ./config.cache
> checking for pj_init_plus in -lproj... no
> checking how to run the C preprocessor... cc -E
> checking for proj_api.h... no
> libproj.a and proj_api.h not found in standard search locations,
> edit src/Makevars manually, adding -I<directory with proj_api.h>
> to PKG_CPPFLAGS = , and -L<directory with libproj.a> to PKG_LIBS =
> ERROR: configuration failed for package 'spproj'
> ** Removing '/usr/lib/R/library/spproj'
> 
> The downloaded packages are in
>         /tmp/Rtmpsq7239/downloaded_packages
> Warning message:
> installation of package 'spproj' had non-zero exit status in:
> install.packages("spproj", repos = rSpatial)
> >

spproj depends on the external library PROJ.4 from:

http://www.remotesensing.org/proj

which you need to install first.

Roger

> 
> I am using R:
> > version
>          _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    2
> minor    2.1
> year     2005
> month    12
> day      20
> svn rev  36812
> language R
> >
> 
> Any suggestions?
> 
> Thanks in advance for your help,
> 
> Sander
> 
> 
> 
> PS:  The SP packages loaded with no problems:
> 
> > options(repos = "http://cran.r-project.org/")
> > install.packages("sp")
> trying URL 'http://cran.r-project.org/src/contrib/sp_0.8-14.tar.gz'
> Content type 'application/x-tar' length 312138 bytes
> opened URL
> ==================================================
> downloaded 304Kb
> 
> * Installing *source* package 'sp' ...
> ** libs
> gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC   -c gcdist.c -o
> gcdist.o
> gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC   -c init.c -o init.o
> gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC   -c pip.c -o pip.o
> gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC   -c Rcentroid.c
> -o Rcentroid.o
> gcc -shared -L/usr/local/lib -o sp.so gcdist.o init.o pip.o Rcentroid.o
>   -L/usr/lib/R/lib -lR
> ** R
> ** data
> ** demo
> ** inst
> ** save image
> 
> ** help
>  >>> Building/Updating help pages for package 'sp'
>      Formats: text html latex example
>   00sp                              text    html    latex
>   AttributeList-class               text    html    latex   example
>   CRS-class                         text    html    latex   example
>   DMS-class                         text    html    latex   example
>   GridTopology-class                text    html    latex   example
>   Line-class                        text    html    latex   example
>   Line                              text    html    latex
>   Lines-class                       text    html    latex   example
>   Polygon-class                     text    html    latex   example
>   Polygons-class                    text    html    latex   example
>   Rlogo                             text    html    latex   example
>   Spatial-class                     text    html    latex   example
>   SpatialGrid-class                 text    html    latex   example
>   SpatialGrid                       text    html    latex   example
>   SpatialGridDataFrame-class        text    html    latex   example
>   SpatialGridDataFrame              text    html    latex   example
>   SpatialLines-class                text    html    latex   example
>   SpatialLines                      text    html    latex
>   SpatialLinesDataFrame-class       text    html    latex   example
>   SpatialPixels-class               text    html    latex   example
>   SpatialPixelsDataFrame-class      text    html    latex   example
>   SpatialPoints-class               text    html    latex   example
>   SpatialPoints                     text    html    latex
>   SpatialPointsDataFrame-class      text    html    latex   example
>   SpatialPolygons-class             text    html    latex   example
>   SpatialPolygons                   text    html    latex
>   SpatialPolygonsDataFrame-class    text    html    latex   example
>   as.SpatialPolygons.GridTopology   text    html    latex   example
>   as.SpatialPolygons.PolygonsList   text    html    latex   example
>   asciigrid                         text    html    latex   example
>   bbox                              text    html    latex   example
>   bpy.colors                        text    html    latex   example
>   bubble                            text    html    latex   example
>   char2dms                          text    html    latex   example
>   contourLines2SLDF                 text    html    latex   example
>   coordinates-methods               text    html    latex
>   coordinates                       text    html    latex   example
>   coordnames-methods                text    html    latex
>   degaxis                           text    html    latex   example
>   dimensions                        text    html    latex   example
>   gridded-methods                   text    html    latex   example
>   gridlines                         text    html    latex   example
>   image                             text    html    latex   example
>   is.projected                      text    html    latex   example
>   mapasp                            text    html    latex
>   meuse                             text    html    latex   example
>   meuse.grid                        text    html    latex   example
>   meuse.riv                         text    html    latex   example
>   nowrapSpatialLines                text    html    latex   example
>   overlay-methods                   text    html    latex
>   overlay                           text    html    latex   example
>   panel                             text    html    latex   example
>   point.in.polygon                  text    html    latex   example
>   polygons-methods                  text    html    latex
>   polygons                          text    html    latex   example
>   recenter-methods                  text    html    latex   example
>   select.spatial                    text    html    latex   example
>   spDistsN1                         text    html    latex   example
>   spplot                            text    html    latex   example
>   spsample                          text    html    latex   example
>   stack                             text    html    latex   example
>   transform-methods                 text    html    latex
>   zerodist                          text    html    latex   example
> ** building package indices ...
> * DONE (sp)
> 
> The downloaded packages are in
>         /tmp/Rtmpsq7239/downloaded_packages
> >
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From sander at oomvanlieshout.net  Sun Apr 23 18:02:58 2006
From: sander at oomvanlieshout.net (Sander Oom)
Date: Sun, 23 Apr 2006 18:02:58 +0200
Subject: [R-sig-Geo] Problem installing spproj
In-Reply-To: <Pine.LNX.4.44.0604231655150.19193-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0604231655150.19193-100000@reclus.nhh.no>
Message-ID: <444BA532.5010407@oomvanlieshout.net>

Roger Bivand wrote:
> On Sun, 23 Apr 2006, Sander Oom wrote:
> 
>> Dear R-geo subscribers,
>>
>> Using the following commands, I am trying in vain to install spproj:
>>
>> rSpatial <- "http://r-spatial.sourceforge.net/R"
>> install.packages("spproj", repos=rSpatial)
>>
>> I get the following response:
>>
>>> rSpatial <- "http://r-spatial.sourceforge.net/R"
>>> install.packages("spproj", repos=rSpatial)
>> trying URL
>> 'http://r-spatial.sourceforge.net/R/src/contrib/spproj_0.3-4.tar.gz'
>> Content type 'application/x-tar' length 2466730 bytes
>> opened URL
>> ==================================================
>> downloaded 2408Kb
>>
>> * Installing *source* package 'spproj' ...
>> creating cache ./config.cache
>> checking for pj_init_plus in -lproj... no
>> checking how to run the C preprocessor... cc -E
>> checking for proj_api.h... no
>> libproj.a and proj_api.h not found in standard search locations,
>> edit src/Makevars manually, adding -I<directory with proj_api.h>
>> to PKG_CPPFLAGS = , and -L<directory with libproj.a> to PKG_LIBS =
>> ERROR: configuration failed for package 'spproj'
>> ** Removing '/usr/lib/R/library/spproj'
>>
>> The downloaded packages are in
>>         /tmp/Rtmpsq7239/downloaded_packages
>> Warning message:
>> installation of package 'spproj' had non-zero exit status in:
>> install.packages("spproj", repos = rSpatial)
> 
> spproj depends on the external library PROJ.4 from:
> 
> http://www.remotesensing.org/proj
> 
> which you need to install first.
> 
> Roger
> 

Dear Roger,

Thanks for your quick reply. The installation of Proj is actually not
mentioned on the r-spatial pages. Maybe a point of attention. I already
checked and now double checked the installation of Proj:

I have proj-4.4.9-1suse10.0.i586 installed (using the rpm from GDF).

There is a directory: usr/share/proj
While there is an executable: usr/bin/proj

Is spproj expecting it somewhere else?

Sander.



From Roger.Bivand at nhh.no  Sun Apr 23 21:18:08 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 23 Apr 2006 21:18:08 +0200 (CEST)
Subject: [R-sig-Geo] Problem installing spproj
In-Reply-To: <444BA532.5010407@oomvanlieshout.net>
Message-ID: <Pine.LNX.4.44.0604232117040.19193-100000@reclus.nhh.no>

On Sun, 23 Apr 2006, Sander Oom wrote:

> Roger Bivand wrote:
> > On Sun, 23 Apr 2006, Sander Oom wrote:
> > 
> >> Dear R-geo subscribers,
> >>
> >> Using the following commands, I am trying in vain to install spproj:
> >>
> >> rSpatial <- "http://r-spatial.sourceforge.net/R"
> >> install.packages("spproj", repos=rSpatial)
> >>
> >> I get the following response:
> >>
> >>> rSpatial <- "http://r-spatial.sourceforge.net/R"
> >>> install.packages("spproj", repos=rSpatial)
> >> trying URL
> >> 'http://r-spatial.sourceforge.net/R/src/contrib/spproj_0.3-4.tar.gz'
> >> Content type 'application/x-tar' length 2466730 bytes
> >> opened URL
> >> ==================================================
> >> downloaded 2408Kb
> >>
> >> * Installing *source* package 'spproj' ...
> >> creating cache ./config.cache
> >> checking for pj_init_plus in -lproj... no
> >> checking how to run the C preprocessor... cc -E
> >> checking for proj_api.h... no
> >> libproj.a and proj_api.h not found in standard search locations,
> >> edit src/Makevars manually, adding -I<directory with proj_api.h>
> >> to PKG_CPPFLAGS = , and -L<directory with libproj.a> to PKG_LIBS =
> >> ERROR: configuration failed for package 'spproj'
> >> ** Removing '/usr/lib/R/library/spproj'
> >>
> >> The downloaded packages are in
> >>         /tmp/Rtmpsq7239/downloaded_packages
> >> Warning message:
> >> installation of package 'spproj' had non-zero exit status in:
> >> install.packages("spproj", repos = rSpatial)
> > 
> > spproj depends on the external library PROJ.4 from:
> > 
> > http://www.remotesensing.org/proj
> > 
> > which you need to install first.
> > 
> > Roger
> > 
> 
> Dear Roger,
> 
> Thanks for your quick reply. The installation of Proj is actually not
> mentioned on the r-spatial pages. Maybe a point of attention. I already
> checked and now double checked the installation of Proj:
> 
> I have proj-4.4.9-1suse10.0.i586 installed (using the rpm from GDF).
> 
> There is a directory: usr/share/proj
> While there is an executable: usr/bin/proj

You need proj-devel-4.4.9-1suse10.0.i586.rpm too to get the headers and 
static libraries, then it should be OK.

Roger

> 
> Is spproj expecting it somewhere else?
> 
> Sander.
> 
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Anja.Matatko at alta4.com  Tue Apr 25 17:37:04 2006
From: Anja.Matatko at alta4.com (Anja Matatko)
Date: Tue, 25 Apr 2006 17:37:04 +0200
Subject: [R-sig-Geo] regression and cluster analysis with shapefiles: data
	import problems
Message-ID: <8EDE8442902FB941AB8BE96FC8CE168A39878A@srvdc.alta4.local>


Dear list,

I have a shapefile with several numerical attributes and want to do cluster and regression analysis with this data (sociodemographic data). I use the read.shapefile-command to import my data (it is well imported, it appears as an object), and then my first problem occurs: 

I want to do the analysis as in Anselin's "An Introduction to Spatial Regression Analysis in R" or the FAO publication by Petrucci / Salvati / Seghieri "The application of a spatial regression model to the analysis and mapping of poverty", but they all use other raw data than shapefiles and I couldn't find a hint how to convert my shapefile to a format that supports the lm() or similar functions. 

I think there are two problems to solve:

- I need to have access to the headers of my shapefile attribute data, in order to execute commands as mydata$variable1 (actually, I can't call mydata$variable1, I just get the answer NULL)

- I need something to get the spatial information contained in the shapefile (my attribute table has no x y coordinates included). Or is it really necessary to insert x and y columns in the attribute table with the help of ArcGIS? 

Thanks for help,

Anja (student of applied geography writing masters thesis about the use of geographical information systems and several "spatial statistics software" - including R - in planning support, in domains not much affiliated to spatial analysis but working with spatial data)



-------------------------------------------- 
Anja Matatko
alta4 Geoinformatik AG 
Frauenstra?e 8-9 
54290 Trier/Germany 
voice: +49.651.96626-0
fax: +49.651.96626-26 
email: anja.matatko at alta4.com 
internet: http://www.alta4.com 

Die n?chsten GIS-Schulungen:
- ArcGIS 9 Umsteiger: 15. - 17.05.06 in M?nchen
- ArcGIS 9 Geoprocessing & Model Builder: 18. - 19.05.06 in M?nchen
- What's New in ArcGIS 9.1?: 22.-23.05.06 in Trier
- ArcGIS Digitalisieren: 02.06.06 in Trier
Weitere Infos: http://www.alta4.com/de/schulung/index.php

Treffen Sie uns auf folgenden Veranstaltungen:
- IT-Messe: 04.-05.05.06 in Trier
- ESRI Anwenderkonferenz: 09.-11.05.06 in Salzburg
Weitere Infos: http://www.alta4.com/de/alta4/events.php



From yud at mail.montclair.edu  Tue Apr 25 23:18:40 2006
From: yud at mail.montclair.edu (Danlin Yu)
Date: Tue, 25 Apr 2006 17:18:40 -0400
Subject: [R-sig-Geo] regression and cluster analysis with shapefiles:
 data import problems
Message-ID: <7e1a877e4e28.7e4e287e1a87@montclair.edu>

Anja:

If you have a shapefile imported using read.shape, you can view the header (the attribute names) of your shapefile object using "colnames(shapeobject$att.data)"

Similarly, you can assign individual attributes as R objects using command like:

attribute1 <- shapeobject$att.data$attribute1

For polygons, you can get the X, Y, coordinates by using get.Pcent (shapeobject) in the package maptools (which will be loaded when you load the package spdep). I am quite sure you can do similar work with point file as well (Roger mentioned that to me once, but since I have access to ArcGIS, and as a habit I always creat the X, Y fields for my data, I forgot the procedure).

Hope this helps.

Cheers,

___________________________________________
Danlin Yu, Ph.D.
Assistant Professor
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
email: yud at mail.montclair.edu

----- Original Message -----
From: Anja Matatko <Anja.Matatko at alta4.com>
Date: Tuesday, April 25, 2006 11:37 am
Subject: [R-sig-Geo] regression and cluster analysis with shapefiles: data import problems

> 
> Dear list,
> 
> I have a shapefile with several numerical attributes and want to 
> do cluster and regression analysis with this data 
> (sociodemographic data). I use the read.shapefile-command to 
> import my data (it is well imported, it appears as an object), and 
> then my first problem occurs: 
> 
> I want to do the analysis as in Anselin's "An Introduction to 
> Spatial Regression Analysis in R" or the FAO publication by 
> Petrucci / Salvati / Seghieri "The application of a spatial 
> regression model to the analysis and mapping of poverty", but they 
> all use other raw data than shapefiles and I couldn't find a hint 
> how to convert my shapefile to a format that supports the lm() or 
> similar functions. 
> 
> I think there are two problems to solve:
> 
> - I need to have access to the headers of my shapefile attribute 
> data, in order to execute commands as mydata$variable1 (actually, 
> I can't call mydata$variable1, I just get the answer NULL)
> 
> - I need something to get the spatial information contained in the 
> shapefile (my attribute table has no x y coordinates included). Or 
> is it really necessary to insert x and y columns in the attribute 
> table with the help of ArcGIS? 
> 
> Thanks for help,
> 
> Anja (student of applied geography writing masters thesis about 
> the use of geographical information systems and several "spatial 
> statistics software" - including R - in planning support, in 
> domains not much affiliated to spatial analysis but working with 
> spatial data)
> 
> 
> 
> -------------------------------------------- 
> Anja Matatko
> alta4 Geoinformatik AG 
> Frauenstra?e 8-9 
> 54290 Trier/Germany 
> voice: +49.651.96626-0
> fax: +49.651.96626-26 
> email: anja.matatko at alta4.com 
> internet: http://www.alta4.com 
> 
> Die n?chsten GIS-Schulungen:
> - ArcGIS 9 Umsteiger: 15. - 17.05.06 in M?nchen
> - ArcGIS 9 Geoprocessing & Model Builder: 18. - 19.05.06 in M?nchen
> - What's New in ArcGIS 9.1?: 22.-23.05.06 in Trier
> - ArcGIS Digitalisieren: 02.06.06 in Trier
> Weitere Infos: http://www.alta4.com/de/schulung/index.php
> 
> Treffen Sie uns auf folgenden Veranstaltungen:
> - IT-Messe: 04.-05.05.06 in Trier
> - ESRI Anwenderkonferenz: 09.-11.05.06 in Salzburg
> Weitere Infos: http://www.alta4.com/de/alta4/events.php
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Roger.Bivand at nhh.no  Wed Apr 26 00:05:41 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 26 Apr 2006 00:05:41 +0200 (CEST)
Subject: [R-sig-Geo] regression and cluster analysis with shapefiles:
 data import problems
In-Reply-To: <7e1a877e4e28.7e4e287e1a87@montclair.edu>
Message-ID: <Pine.LNX.4.44.0604252327350.22899-100000@reclus.nhh.no>

On Tue, 25 Apr 2006, Danlin Yu wrote:

> Anja:
> 
> If you have a shapefile imported using read.shape, you can view the
> header (the attribute names) of your shapefile object using
> "colnames(shapeobject$att.data)"
> 
> Similarly, you can assign individual attributes as R objects using
> command like:
> 
> attribute1 <- shapeobject$att.data$attribute1
> 
> For polygons, you can get the X, Y, coordinates by using get.Pcent
> (shapeobject) in the package maptools (which will be loaded when you
> load the package spdep). I am quite sure you can do similar work with
> point file as well (Roger mentioned that to me once, but since I have
> access to ArcGIS, and as a habit I always creat the X, Y fields for my
> data, I forgot the procedure).

It always helps to paste copies of the commands you are giving, usually 
together with sessionInfo() to give the package versions.

If you are using the maptools package, you can use read.shape() to return 
an object of class "Map", as the help page for the function explains.

> library(maptools)
Loading required package: foreign
Loading required package: sp
> sessionInfo()
Version 2.3.0 (2006-04-24) 
i686-pc-linux-gnu 

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[7] "base"     

other attached packages:
maptools       sp  foreign 
"0.5-11" "0.8-15" "0.8-12" 
> list.files(pattern="shp")
[1] "baltim.shp"   "columbus.shp" "fylk-val.shp" "sids.shp"    

These are the shapefiles distributed with the maptools package, by the 
way.

> col1 <- read.shape("columbus.shp")
Shapefile type: Polygon, (5), # of Shapes: 49
> class(col1)
[1] "Map"
> names(col1$att.data)
 [1] "AREA"       "PERIMETER"  "COLUMBUS_"  "COLUMBUS_I" "POLYID"    
 [6] "NEIG"       "HOVAL"      "INC"        "CRIME"      "OPEN"      
[11] "PLUMB"      "DISCBD"     "X"          "Y"          "NSA"       
[16] "NSB"        "EW"         "CP"         "THOUS"      "NEIGNO"    
> col1data <- col1$att.data 
> lm(CRIME ~ HOVAL + INC, data=col1data)

Call:
lm(formula = CRIME ~ HOVAL + INC, data = col1data)

Coefficients:
(Intercept)        HOVAL          INC  
    68.6190      -0.2739      -1.5973  


If you use the more user-friendly sp classes with functions from the 
maptools package, you do:

> getinfo.shape("columbus.shp")
Shapefile type: Polygon, (5), # of Shapes: 49

to find out what kind it is, and use one of readShapePoints(), 
readShapeLines() or readShapePoly():

> col2 <- readShapePoly("columbus.shp")
> class(col2)
[1] "SpatialPolygonsDataFrame"
attr(,"package")
[1] "sp"

for which lm() just works:

> lm(CRIME ~ HOVAL + INC, data=col2)

Call:
lm(formula = CRIME ~ HOVAL + INC, data = col2)

Coefficients:
(Intercept)        HOVAL          INC  
    68.6190      -0.2739      -1.5973  

and should you need the centroids of polygons (or point locations), the 
coordinate method returns them:

> coords <- coordinates(col2)
> str(coords)
 num [1:49, 1:2] 8.83 8.33 9.01 8.46 9.01 ...

where str() is a helper function showing the structure of an object. There 
are other ways, but this is the simplest, because sp class SpatialPolygons 
component Polygons objects store their centroids. By the way, the plot 
methods for these classes of objects are also pretty good, and new 
variables can just be added:

> mylm <- lm(CRIME ~ HOVAL + INC, data=col2)
> col2$mylm_res <- residuals(mylm)
> spplot(col2, "mylm_res")

(with lots of options for modification if needed, but now nobody can say 
that they couldn't map the residuals!)

In fact currently the easiest shapefile reader (readOGR()) is in the rgdal
package, because it also reads the *.prj file, and so creates the sp class
object with the appropriate metadata, and finds out automatically if the 
spatial entities are points, lines, or polygons. If your planners, Anja, 
need to keep the coordinate reference system tidy, this may be worth 
looking at, combined with the still slightly messy writing of shapefiles:

writePolyShape(), writeLinesShape(), or writePointsShape() in the maptools 
package and showWKT() in the rgdal package to write the appropriate *.prj.

If you are using read.shapefile() in the shapefiles package, you'll need 
to get at an internal element to find the data.frame:

> library(shapefiles)
> col3 <- read.shapefile("columbus")
> names(col3$dbf$dbf)
 [1] "AREA"       "PERIMETER"  "COLUMBUS_"  "COLUMBUS_I" "POLYID"    
 [6] "NEIG"       "HOVAL"      "INC"        "CRIME"      "OPEN"      
[11] "PLUMB"      "DISCBD"     "X"          "Y"          "NSA"       
[16] "NSB"        "EW"         "CP"         "THOUS"      "NEIGNO"    
> col3data <- col3$dbf$dbf
> lm(CRIME ~ HOVAL + INC, data=col3data)

Call:
lm(formula = CRIME ~ HOVAL + INC, data = col3data)

Coefficients:
(Intercept)        HOVAL          INC  
    68.6190      -0.2739      -1.5973  


will do it.

Roger

> 
> Hope this helps.
> 
> Cheers,
> 
> ___________________________________________
> Danlin Yu, Ph.D.
> Assistant Professor
> Department of Earth & Environmental Studies
> Montclair State University
> Montclair, NJ, 07043
> Tel: 973-655-4313
> Fax: 973-655-4072
> email: yud at mail.montclair.edu
> 
> ----- Original Message -----
> From: Anja Matatko <Anja.Matatko at alta4.com>
> Date: Tuesday, April 25, 2006 11:37 am
> Subject: [R-sig-Geo] regression and cluster analysis with shapefiles: data import problems
> 
> > 
> > Dear list,
> > 
> > I have a shapefile with several numerical attributes and want to 
> > do cluster and regression analysis with this data 
> > (sociodemographic data). I use the read.shapefile-command to 
> > import my data (it is well imported, it appears as an object), and 
> > then my first problem occurs: 
> > 
> > I want to do the analysis as in Anselin's "An Introduction to 
> > Spatial Regression Analysis in R" or the FAO publication by 
> > Petrucci / Salvati / Seghieri "The application of a spatial 
> > regression model to the analysis and mapping of poverty", but they 
> > all use other raw data than shapefiles and I couldn't find a hint 
> > how to convert my shapefile to a format that supports the lm() or 
> > similar functions. 
> > 
> > I think there are two problems to solve:
> > 
> > - I need to have access to the headers of my shapefile attribute 
> > data, in order to execute commands as mydata$variable1 (actually, 
> > I can't call mydata$variable1, I just get the answer NULL)
> > 
> > - I need something to get the spatial information contained in the 
> > shapefile (my attribute table has no x y coordinates included). Or 
> > is it really necessary to insert x and y columns in the attribute 
> > table with the help of ArcGIS? 
> > 
> > Thanks for help,
> > 
> > Anja (student of applied geography writing masters thesis about 
> > the use of geographical information systems and several "spatial 
> > statistics software" - including R - in planning support, in 
> > domains not much affiliated to spatial analysis but working with 
> > spatial data)
> > 
> > 
> > 
> > -------------------------------------------- 
> > Anja Matatko
> > alta4 Geoinformatik AG 
> > Frauenstra?e 8-9 
> > 54290 Trier/Germany 
> > voice: +49.651.96626-0
> > fax: +49.651.96626-26 
> > email: anja.matatko at alta4.com 
> > internet: http://www.alta4.com 
> > 
> > Die n?chsten GIS-Schulungen:
> > - ArcGIS 9 Umsteiger: 15. - 17.05.06 in M?nchen
> > - ArcGIS 9 Geoprocessing & Model Builder: 18. - 19.05.06 in M?nchen
> > - What's New in ArcGIS 9.1?: 22.-23.05.06 in Trier
> > - ArcGIS Digitalisieren: 02.06.06 in Trier
> > Weitere Infos: http://www.alta4.com/de/schulung/index.php
> > 
> > Treffen Sie uns auf folgenden Veranstaltungen:
> > - IT-Messe: 04.-05.05.06 in Trier
> > - ESRI Anwenderkonferenz: 09.-11.05.06 in Salzburg
> > Weitere Infos: http://www.alta4.com/de/alta4/events.php
> > 
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Thomas.Adams at noaa.gov  Thu Apr 27 21:49:50 2006
From: Thomas.Adams at noaa.gov (Thomas Adams)
Date: Thu, 27 Apr 2006 15:49:50 -0400
Subject: [R-sig-Geo] Example of universal kriging with R/gstat in GRASS
	needed
In-Reply-To: <Pine.LNX.4.44.0604252327350.22899-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0604252327350.22899-100000@reclus.nhh.no>
Message-ID: <4451205E.8050805@noaa.gov>

List:

I can not seem to work out the syntax for using R/gstat within a GRASS 
6.1 session to do universal kriging. I have a DEM (elevation data on a 
grid) and point data for temperature; theoretically, the temperatures 
should relate to elevation. So, I am trying to spatially interpolate the 
temperature data based on the elevations at the grid points. How do I 
setup the gstat command in R/gstat (and using spgrass6, of course)? I 
have no trouble reading in my elevation data (DEM) from GRASS and I have 
no problem doing ordinary kriging of my temperature data using 
GRASS/R/gstat.

Regards,
Tom

-- 
Thomas E Adams
National Weather Service
Ohio River Forecast Center
1901 South State Route 134
Wilmington, OH 45177

EMAIL:	thomas.adams at noaa.gov

VOICE:	937-383-0528
FAX:	937-383-0033



From Roger.Bivand at nhh.no  Thu Apr 27 22:21:55 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 27 Apr 2006 22:21:55 +0200 (CEST)
Subject: [R-sig-Geo] Example of universal kriging with R/gstat in GRASS
	needed
In-Reply-To: <4451205E.8050805@noaa.gov>
Message-ID: <Pine.LNX.4.44.0604272206250.22114-100000@reclus.nhh.no>

On Thu, 27 Apr 2006, Thomas Adams wrote:

> List:
> 
> I can not seem to work out the syntax for using R/gstat within a GRASS 
> 6.1 session to do universal kriging. I have a DEM (elevation data on a 
> grid) and point data for temperature; theoretically, the temperatures 
> should relate to elevation. So, I am trying to spatially interpolate the 
> temperature data based on the elevations at the grid points. How do I 
> setup the gstat command in R/gstat (and using spgrass6, of course)? I 
> have no trouble reading in my elevation data (DEM) from GRASS and I have 
> no problem doing ordinary kriging of my temperature data using 
> GRASS/R/gstat.

What do the data look like? Do you have temperature and elevation at the
observation points and elevation over the grid? If temperature is the 
variable for which you want to interpolate, then the formula argument in 
the gstat() function would be temp ~ elev, data=pointsdata (if a 
SpatialPointsDataFrame no need for location= ~ x + y). Then the predict() 
step would need a SpatialGridDataFrame object as newdata, with elev as 
(one of) the columns in the data slot.

An example for the Meuse bank data in Burrough and McDonnell:

cvgm <- variogram(Zn ~ Fldf, data=BMcD, width=100, cutoff=1000)
uefitted <- fit.variogram(cvgm, vgm(psill=1, model="Exp", range=100, 
  nugget=1))
UK_fit <- gstat(id="UK_fit", formula = Zn ~ Fldf, data = BMcD, 
  model=uefitted)
z <- predict(UK_fit, newdata=BMcD_SPx)

where BMcD_SPx is a SpatialPixelsDataFrame (the grid has ragged edges) 
with flood frequencies in Fldf (actually a factor, but works neatly).

Hope this helps,

Roger

> 
> Regards,
> Tom
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Thomas.Adams at noaa.gov  Fri Apr 28 03:03:58 2006
From: Thomas.Adams at noaa.gov (Thomas.Adams at noaa.gov)
Date: Thu, 27 Apr 2006 21:03:58 -0400
Subject: [R-sig-Geo] Example of universal kriging with R/gstat in GRASS
 needed
Message-ID: <c94f2c7ed6.c7ed6c94f2@noaa.gov>

Roger,

Thanks for the help! I can try this tomorrow.

What do the data look like? Do you have temperature and elevation at the observation points 
and elevation over 
the grid? <==== This is exactly what I have; but I have a question: the elevation values I 
have associated with 
the point locations and temperatures are different from those for the grid elevations. The 
point elevation values 
are 'exact' whereas the grid elevations are spatial averages. Does this matter in the 
interpolation process -- it 
seems there would be numerical problems?

If temperature is the variable for which you want to interpolate (**YES**), then the formula 
argument in the 
gstat() function would be temp ~ elev, data=pointsdata... <==== this looks like what I need 
to do...

I'll let you know tomorrow morning when I get to work.

Thanks so much!

Tom



----- Original Message -----
From: Roger Bivand <Roger.Bivand at nhh.no>
Date: Thursday, April 27, 2006 4:21 pm
Subject: Re: [R-sig-Geo] Example of universal kriging with R/gstat in GRASS needed

> On Thu, 27 Apr 2006, Thomas Adams wrote:
> 
> > List:
> > 
> > I can not seem to work out the syntax for using R/gstat within a 
> GRASS 
> > 6.1 session to do universal kriging. I have a DEM (elevation data 
> on a 
> > grid) and point data for temperature; theoretically, the 
> temperatures 
> > should relate to elevation. So, I am trying to spatially 
> interpolate the 
> > temperature data based on the elevations at the grid points. How 
> do I 
> > setup the gstat command in R/gstat (and using spgrass6, of 
> course)? I 
> > have no trouble reading in my elevation data (DEM) from GRASS and 
> I have 
> > no problem doing ordinary kriging of my temperature data using 
> > GRASS/R/gstat.
> 
> What do the data look like? Do you have temperature and elevation 
> at the
> observation points and elevation over the grid? If temperature is 
> the 
> variable for which you want to interpolate, then the formula 
> argument in 
> the gstat() function would be temp ~ elev, data=pointsdata (if a 
> SpatialPointsDataFrame no need for location= ~ x + y). Then the 
> predict() 
> step would need a SpatialGridDataFrame object as newdata, with elev 
> as 
> (one of) the columns in the data slot.
> 
> An example for the Meuse bank data in Burrough and McDonnell:
> 
> cvgm <- variogram(Zn ~ Fldf, data=BMcD, width=100, cutoff=1000)
> uefitted <- fit.variogram(cvgm, vgm(psill=1, model="Exp", 
> range=100, 
>  nugget=1))
> UK_fit <- gstat(id="UK_fit", formula = Zn ~ Fldf, data = BMcD, 
>  model=uefitted)
> z <- predict(UK_fit, newdata=BMcD_SPx)
> 
> where BMcD_SPx is a SpatialPixelsDataFrame (the grid has ragged 
> edges) 
> with flood frequencies in Fldf (actually a factor, but works neatly).
> 
> Hope this helps,
> 
> Roger
> 
> > 
> > Regards,
> > Tom
> > 
> > 
> 
> -- 
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian 
> School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Thomas.Adams at noaa.gov  Fri Apr 28 19:39:33 2006
From: Thomas.Adams at noaa.gov (Thomas Adams)
Date: Fri, 28 Apr 2006 13:39:33 -0400
Subject: [R-sig-Geo] Example of universal kriging with R/gstat in GRASS
	needed
In-Reply-To: <Pine.LNX.4.44.0604272206250.22114-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0604272206250.22114-100000@reclus.nhh.no>
Message-ID: <44525355.4020803@noaa.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060428/ae1ccd6f/attachment.pl>

From Roger.Bivand at nhh.no  Fri Apr 28 19:52:03 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 28 Apr 2006 19:52:03 +0200 (CEST)
Subject: [R-sig-Geo] Example of universal kriging with R/gstat in GRASS
	needed
In-Reply-To: <44525355.4020803@noaa.gov>
Message-ID: <Pine.LNX.4.44.0604281946480.23449-100000@reclus.nhh.no>

On Fri, 28 Apr 2006, Thomas Adams wrote:

> Roger,
> 
> This got me further along, but I am encountering a problem with:
> 
> z <- predict(UK_fit, newdata=BMcD_SPx)
> 
> The gstat step works for me, where I have:
> 
> UK_fit<-gstat(formula=temps$temp~dem,data=temps,model=efitted)
> 
> temps has class SpatialPointsDataFrame:
> 
>               coordinates cat      x     y    z temp name
> 1     (-341460, -2154.42)   1 -90.05 38.90  166   63  ALN
> 2       (-198769, 301388)   2 -88.47 41.77  215   67  ARR
> 3       (-334899, -40321)   3 -89.95 38.55  140   66  BLV
> 4       (-240028, 163910)   4 -88.92 40.48  268   69  BMI
> 5       (-187957, 114806)   5 -88.27 40.04  229   64  CMI
> 6     (-351730, -37305.9)   6 -90.15 38.57  126   65  CPS
> 7      (-242424, 98244.7)   7 -88.92 39.87  204   66  DEC
> 8       (-179844, 315889)   8 -88.24 41.91  232   69  DPA
> 9     (-136093, -24538.2)   9 -87.61 38.76  131   68  LWV
> 10     (-278964, -126152)  10 -89.25 37.78  125   66  MDH
> 11      (-140792, 302011)  11 -87.75 41.79  187   73  MDW
> 12      (-364737, 274189)  12 -90.51 41.45  180   73  MLI
> 13     (-190503, 54493.9)  13 -88.28 39.48  219   64  MTO
> 
> and dem has class SpatialGridDataFrame and just consists of grid values.

I think 

fullgrid(dem) <- FALSE

should make a SpatialPixelsDataFrame, but you'll have to make sure the 
name of the dem variable is the same as in the formula.

Roger

> 
> I tried to create a SpatialPixelsDataFrame for predict(), but with (for 
> example):
> 
> m = SpatialPixelsDataFrame(points=meuse.grid[c("x","y")],data=meuse.grid)
> 
> I have nothing like meuse.grid, so this does not work. I can use 
> image(dem), which produces a plot of elevation values. My point is that 
> meuse.grid and my dem files have very different structures.
> 
> I'm not sure where to go to from here.
> 
> Regards,
> Tom
> 
> 
> Roger Bivand wrote:
> > On Thu, 27 Apr 2006, Thomas Adams wrote:
> >
> >   
> >> List:
> >>
> >> I can not seem to work out the syntax for using R/gstat within a GRASS 
> >> 6.1 session to do universal kriging. I have a DEM (elevation data on a 
> >> grid) and point data for temperature; theoretically, the temperatures 
> >> should relate to elevation. So, I am trying to spatially interpolate the 
> >> temperature data based on the elevations at the grid points. How do I 
> >> setup the gstat command in R/gstat (and using spgrass6, of course)? I 
> >> have no trouble reading in my elevation data (DEM) from GRASS and I have 
> >> no problem doing ordinary kriging of my temperature data using 
> >> GRASS/R/gstat.
> >>     
> >
> > What do the data look like? Do you have temperature and elevation at the
> > observation points and elevation over the grid? If temperature is the 
> > variable for which you want to interpolate, then the formula argument in 
> > the gstat() function would be temp ~ elev, data=pointsdata (if a 
> > SpatialPointsDataFrame no need for location= ~ x + y). Then the predict() 
> > step would need a SpatialGridDataFrame object as newdata, with elev as 
> > (one of) the columns in the data slot.
> >
> > An example for the Meuse bank data in Burrough and McDonnell:
> >
> > cvgm <- variogram(Zn ~ Fldf, data=BMcD, width=100, cutoff=1000)
> > uefitted <- fit.variogram(cvgm, vgm(psill=1, model="Exp", range=100, 
> >   nugget=1))
> > UK_fit <- gstat(id="UK_fit", formula = Zn ~ Fldf, data = BMcD, 
> >   model=uefitted)
> > z <- predict(UK_fit, newdata=BMcD_SPx)
> >
> > where BMcD_SPx is a SpatialPixelsDataFrame (the grid has ragged edges) 
> > with flood frequencies in Fldf (actually a factor, but works neatly).
> >
> > Hope this helps,
> >
> > Roger
> >
> >   
> >> Regards,
> >> Tom
> >>
> >>
> >>     
> >
> >   
> 
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Thomas.Adams at noaa.gov  Fri Apr 28 21:13:12 2006
From: Thomas.Adams at noaa.gov (Thomas Adams)
Date: Fri, 28 Apr 2006 15:13:12 -0400
Subject: [R-sig-Geo] Example of universal kriging with R/gstat in GRASS
	needed
In-Reply-To: <Pine.LNX.4.44.0604281946480.23449-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0604281946480.23449-100000@reclus.nhh.no>
Message-ID: <44526948.7040408@noaa.gov>

Roger,

Your suggestion:

fullgrid(dem) <- FALSE

did turn dem into class type SpatialGridDataFrame, but when I tried:

z <- predict(UK_fit,newdata=dem)

I got an error:

Error in model.frame(... :
invalid variable type.

I think I should restate the problem:

I have a file 'temps' which has class SpatialPointsDataFrame read from 
GRASS 6.1, that looks like:

coordinates cat x y z temp name
1 (-341460, -2154.42) 1 -90.05 38.90 166 63 ALN
2 (-198769, 301388) 2 -88.47 41.77 215 67 ARR
3 (-334899, -40321) 3 -89.95 38.55 140 66 BLV
4 (-240028, 163910) 4 -88.92 40.48 268 69 BMI
5 (-187957, 114806) 5 -88.27 40.04 229 64 CMI
6 (-351730, -37305.9) 6 -90.15 38.57 126 65 CPS
7 (-242424, 98244.7) 7 -88.92 39.87 204 66 DEC
8 (-179844, 315889) 8 -88.24 41.91 232 69 DPA
9 (-136093, -24538.2) 9 -87.61 38.76 131 68 LWV
10 (-278964, -126152) 10 -89.25 37.78 125 66 MDH
11 (-140792, 302011) 11 -87.75 41.79 187 73 MDW
12 (-364737, 274189) 12 -90.51 41.45 180 73 MLI
13 (-190503, 54493.9) 13 -88.28 39.48 219 64 MTO

and I have a a file 'dem' which has class SpatialGridDataFrame which 
just consists of grid of elevation values read from GRASS 6.1 using 
dem<-readFLOAT6sp(). (Sorry, I know I'm repeating myself).

What I want to do is to use the grid of elevation values ('dem') as a 
proxy in the spatial interpolation of the 'temp' values in my 'temps' 
file that are located at the coordinates in parentheses(). Notice that 
the temps file also has 'z' values of elevations. So, is this what you 
already understood? Converting 'dem' to a SpatialPixelsDataFrame seemed 
to only leave me with the grid locations and not the elevation values ? 
is this right.

Thanks again for your help!

Regards,
Tom


Roger Bivand wrote:
> On Fri, 28 Apr 2006, Thomas Adams wrote:
>
>   
>> Roger,
>>
>> This got me further along, but I am encountering a problem with:
>>
>> z <- predict(UK_fit, newdata=BMcD_SPx)
>>
>> The gstat step works for me, where I have:
>>
>> UK_fit<-gstat(formula=temps$temp~dem,data=temps,model=efitted)
>>
>> temps has class SpatialPointsDataFrame:
>>
>>               coordinates cat      x     y    z temp name
>> 1     (-341460, -2154.42)   1 -90.05 38.90  166   63  ALN
>> 2       (-198769, 301388)   2 -88.47 41.77  215   67  ARR
>> 3       (-334899, -40321)   3 -89.95 38.55  140   66  BLV
>> 4       (-240028, 163910)   4 -88.92 40.48  268   69  BMI
>> 5       (-187957, 114806)   5 -88.27 40.04  229   64  CMI
>> 6     (-351730, -37305.9)   6 -90.15 38.57  126   65  CPS
>> 7      (-242424, 98244.7)   7 -88.92 39.87  204   66  DEC
>> 8       (-179844, 315889)   8 -88.24 41.91  232   69  DPA
>> 9     (-136093, -24538.2)   9 -87.61 38.76  131   68  LWV
>> 10     (-278964, -126152)  10 -89.25 37.78  125   66  MDH
>> 11      (-140792, 302011)  11 -87.75 41.79  187   73  MDW
>> 12      (-364737, 274189)  12 -90.51 41.45  180   73  MLI
>> 13     (-190503, 54493.9)  13 -88.28 39.48  219   64  MTO
>>
>> and dem has class SpatialGridDataFrame and just consists of grid values.
>>     
>
> I think 
>
> fullgrid(dem) <- FALSE
>
> should make a SpatialPixelsDataFrame, but you'll have to make sure the 
> name of the dem variable is the same as in the formula.
>
> Roger
>
>   
>> I tried to create a SpatialPixelsDataFrame for predict(), but with (for 
>> example):
>>
>> m = SpatialPixelsDataFrame(points=meuse.grid[c("x","y")],data=meuse.grid)
>>
>> I have nothing like meuse.grid, so this does not work. I can use 
>> image(dem), which produces a plot of elevation values. My point is that 
>> meuse.grid and my dem files have very different structures.
>>
>> I'm not sure where to go to from here.
>>
>> Regards,
>> Tom
>>
>>
>> Roger Bivand wrote:
>>     
>>> On Thu, 27 Apr 2006, Thomas Adams wrote:
>>>
>>>   
>>>       
>>>> List:
>>>>
>>>> I can not seem to work out the syntax for using R/gstat within a GRASS 
>>>> 6.1 session to do universal kriging. I have a DEM (elevation data on a 
>>>> grid) and point data for temperature; theoretically, the temperatures 
>>>> should relate to elevation. So, I am trying to spatially interpolate the 
>>>> temperature data based on the elevations at the grid points. How do I 
>>>> setup the gstat command in R/gstat (and using spgrass6, of course)? I 
>>>> have no trouble reading in my elevation data (DEM) from GRASS and I have 
>>>> no problem doing ordinary kriging of my temperature data using 
>>>> GRASS/R/gstat.
>>>>     
>>>>         
>>> What do the data look like? Do you have temperature and elevation at the
>>> observation points and elevation over the grid? If temperature is the 
>>> variable for which you want to interpolate, then the formula argument in 
>>> the gstat() function would be temp ~ elev, data=pointsdata (if a 
>>> SpatialPointsDataFrame no need for location= ~ x + y). Then the predict() 
>>> step would need a SpatialGridDataFrame object as newdata, with elev as 
>>> (one of) the columns in the data slot.
>>>
>>> An example for the Meuse bank data in Burrough and McDonnell:
>>>
>>> cvgm <- variogram(Zn ~ Fldf, data=BMcD, width=100, cutoff=1000)
>>> uefitted <- fit.variogram(cvgm, vgm(psill=1, model="Exp", range=100, 
>>>   nugget=1))
>>> UK_fit <- gstat(id="UK_fit", formula = Zn ~ Fldf, data = BMcD, 
>>>   model=uefitted)
>>> z <- predict(UK_fit, newdata=BMcD_SPx)
>>>
>>> where BMcD_SPx is a SpatialPixelsDataFrame (the grid has ragged edges) 
>>> with flood frequencies in Fldf (actually a factor, but works neatly).
>>>
>>> Hope this helps,
>>>
>>> Roger
>>>
>>>   
>>>       
>>>> Regards,
>>>> Tom
>>>>
>>>>
>>>>     
>>>>         
>>>   
>>>       
>>
>>     
>
>   


-- 
Thomas E Adams
National Weather Service
Ohio River Forecast Center
1901 South State Route 134
Wilmington, OH 45177

EMAIL:	thomas.adams at noaa.gov

VOICE:	937-383-0528
FAX:	937-383-0033



From Roger.Bivand at nhh.no  Fri Apr 28 21:27:50 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 28 Apr 2006 21:27:50 +0200 (CEST)
Subject: [R-sig-Geo] Example of universal kriging with R/gstat in GRASS
	needed
In-Reply-To: <44526948.7040408@noaa.gov>
Message-ID: <Pine.LNX.4.44.0604282119500.23449-100000@reclus.nhh.no>

On Fri, 28 Apr 2006, Thomas Adams wrote:

> Roger,
> 
> Your suggestion:
> 
> fullgrid(dem) <- FALSE
> 
> did turn dem into class type SpatialGridDataFrame, but when I tried:
> 
> z <- predict(UK_fit,newdata=dem)
> 
> I got an error:
> 
> Error in model.frame(... :
> invalid variable type.
> 
> I think I should restate the problem:
> 
> I have a file 'temps' which has class SpatialPointsDataFrame read from 
> GRASS 6.1, that looks like:
> 
> coordinates cat x y z temp name
> 1 (-341460, -2154.42) 1 -90.05 38.90 166 63 ALN
> 2 (-198769, 301388) 2 -88.47 41.77 215 67 ARR
> 3 (-334899, -40321) 3 -89.95 38.55 140 66 BLV
> 4 (-240028, 163910) 4 -88.92 40.48 268 69 BMI
> 5 (-187957, 114806) 5 -88.27 40.04 229 64 CMI
> 6 (-351730, -37305.9) 6 -90.15 38.57 126 65 CPS
> 7 (-242424, 98244.7) 7 -88.92 39.87 204 66 DEC
> 8 (-179844, 315889) 8 -88.24 41.91 232 69 DPA
> 9 (-136093, -24538.2) 9 -87.61 38.76 131 68 LWV
> 10 (-278964, -126152) 10 -89.25 37.78 125 66 MDH
> 11 (-140792, 302011) 11 -87.75 41.79 187 73 MDW
> 12 (-364737, 274189) 12 -90.51 41.45 180 73 MLI
> 13 (-190503, 54493.9) 13 -88.28 39.48 219 64 MTO
> 
> and I have a a file 'dem' which has class SpatialGridDataFrame which 
> just consists of grid of elevation values read from GRASS 6.1 using 
> dem<-readFLOAT6sp(). (Sorry, I know I'm repeating myself).
> 
> What I want to do is to use the grid of elevation values ('dem') as a 
> proxy in the spatial interpolation of the 'temp' values in my 'temps' 
> file that are located at the coordinates in parentheses(). Notice that 
> the temps file also has 'z' values of elevations. So, is this what you 
> already understood? Converting 'dem' to a SpatialPixelsDataFrame seemed 
> to only leave me with the grid locations and not the elevation values ? 
> is this right.

What does:

summary(dem) 

say before and after doing

fullgrid(dem) <- FALSE?

Afterwards it should be a SpatialPixelsDataFrame with 

names(dem)

being "z". Saying summary(dem) will give you an idea of what is inside, 
str() should too.

Roger

PS. This is usually a one-off thing, once it works, you note down how, and 
then it just does from then on.


> 
> Thanks again for your help!
> 
> Regards,
> Tom
> 
> 
> Roger Bivand wrote:
> > On Fri, 28 Apr 2006, Thomas Adams wrote:
> >
> >   
> >> Roger,
> >>
> >> This got me further along, but I am encountering a problem with:
> >>
> >> z <- predict(UK_fit, newdata=BMcD_SPx)
> >>
> >> The gstat step works for me, where I have:
> >>
> >> UK_fit<-gstat(formula=temps$temp~dem,data=temps,model=efitted)
> >>
> >> temps has class SpatialPointsDataFrame:
> >>
> >>               coordinates cat      x     y    z temp name
> >> 1     (-341460, -2154.42)   1 -90.05 38.90  166   63  ALN
> >> 2       (-198769, 301388)   2 -88.47 41.77  215   67  ARR
> >> 3       (-334899, -40321)   3 -89.95 38.55  140   66  BLV
> >> 4       (-240028, 163910)   4 -88.92 40.48  268   69  BMI
> >> 5       (-187957, 114806)   5 -88.27 40.04  229   64  CMI
> >> 6     (-351730, -37305.9)   6 -90.15 38.57  126   65  CPS
> >> 7      (-242424, 98244.7)   7 -88.92 39.87  204   66  DEC
> >> 8       (-179844, 315889)   8 -88.24 41.91  232   69  DPA
> >> 9     (-136093, -24538.2)   9 -87.61 38.76  131   68  LWV
> >> 10     (-278964, -126152)  10 -89.25 37.78  125   66  MDH
> >> 11      (-140792, 302011)  11 -87.75 41.79  187   73  MDW
> >> 12      (-364737, 274189)  12 -90.51 41.45  180   73  MLI
> >> 13     (-190503, 54493.9)  13 -88.28 39.48  219   64  MTO
> >>
> >> and dem has class SpatialGridDataFrame and just consists of grid values.
> >>     
> >
> > I think 
> >
> > fullgrid(dem) <- FALSE
> >
> > should make a SpatialPixelsDataFrame, but you'll have to make sure the 
> > name of the dem variable is the same as in the formula.
> >
> > Roger
> >
> >   
> >> I tried to create a SpatialPixelsDataFrame for predict(), but with (for 
> >> example):
> >>
> >> m = SpatialPixelsDataFrame(points=meuse.grid[c("x","y")],data=meuse.grid)
> >>
> >> I have nothing like meuse.grid, so this does not work. I can use 
> >> image(dem), which produces a plot of elevation values. My point is that 
> >> meuse.grid and my dem files have very different structures.
> >>
> >> I'm not sure where to go to from here.
> >>
> >> Regards,
> >> Tom
> >>
> >>
> >> Roger Bivand wrote:
> >>     
> >>> On Thu, 27 Apr 2006, Thomas Adams wrote:
> >>>
> >>>   
> >>>       
> >>>> List:
> >>>>
> >>>> I can not seem to work out the syntax for using R/gstat within a GRASS 
> >>>> 6.1 session to do universal kriging. I have a DEM (elevation data on a 
> >>>> grid) and point data for temperature; theoretically, the temperatures 
> >>>> should relate to elevation. So, I am trying to spatially interpolate the 
> >>>> temperature data based on the elevations at the grid points. How do I 
> >>>> setup the gstat command in R/gstat (and using spgrass6, of course)? I 
> >>>> have no trouble reading in my elevation data (DEM) from GRASS and I have 
> >>>> no problem doing ordinary kriging of my temperature data using 
> >>>> GRASS/R/gstat.
> >>>>     
> >>>>         
> >>> What do the data look like? Do you have temperature and elevation at the
> >>> observation points and elevation over the grid? If temperature is the 
> >>> variable for which you want to interpolate, then the formula argument in 
> >>> the gstat() function would be temp ~ elev, data=pointsdata (if a 
> >>> SpatialPointsDataFrame no need for location= ~ x + y). Then the predict() 
> >>> step would need a SpatialGridDataFrame object as newdata, with elev as 
> >>> (one of) the columns in the data slot.
> >>>
> >>> An example for the Meuse bank data in Burrough and McDonnell:
> >>>
> >>> cvgm <- variogram(Zn ~ Fldf, data=BMcD, width=100, cutoff=1000)
> >>> uefitted <- fit.variogram(cvgm, vgm(psill=1, model="Exp", range=100, 
> >>>   nugget=1))
> >>> UK_fit <- gstat(id="UK_fit", formula = Zn ~ Fldf, data = BMcD, 
> >>>   model=uefitted)
> >>> z <- predict(UK_fit, newdata=BMcD_SPx)
> >>>
> >>> where BMcD_SPx is a SpatialPixelsDataFrame (the grid has ragged edges) 
> >>> with flood frequencies in Fldf (actually a factor, but works neatly).
> >>>
> >>> Hope this helps,
> >>>
> >>> Roger
> >>>
> >>>   
> >>>       
> >>>> Regards,
> >>>> Tom
> >>>>
> >>>>
> >>>>     
> >>>>         
> >>>   
> >>>       
> >>
> >>     
> >
> >   
> 
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



