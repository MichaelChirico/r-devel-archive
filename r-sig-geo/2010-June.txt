From jmbarriosg at gmail.com  Tue Jun  1 05:19:44 2010
From: jmbarriosg at gmail.com (=?ISO-8859-1?Q?Jos=E9_Miguel_Barrios?=)
Date: Tue, 1 Jun 2010 05:19:44 +0200
Subject: [R-sig-Geo] problems installing rgdal
Message-ID: <AANLkTin2ihGMeB9hou6OWqn5A1GXMroQVx7s-9mo9fq5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100601/ef1dedfe/attachment.pl>

From sp8ial at gmail.com  Tue Jun  1 07:03:55 2010
From: sp8ial at gmail.com (glee)
Date: Tue, 1 Jun 2010 15:03:55 +1000
Subject: [R-sig-Geo] problems installing rgdal
In-Reply-To: <AANLkTin2ihGMeB9hou6OWqn5A1GXMroQVx7s-9mo9fq5@mail.gmail.com>
References: <AANLkTin2ihGMeB9hou6OWqn5A1GXMroQVx7s-9mo9fq5@mail.gmail.com>
Message-ID: <AANLkTil9RjMDfQ9O0FexsHAyRN7jXJ5S3Xlxp1OVsidk@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100601/8c8b1f83/attachment.pl>

From alobolistas at gmail.com  Tue Jun  1 07:23:23 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 1 Jun 2010 07:23:23 +0200
Subject: [R-sig-Geo] problems installing rgdal
In-Reply-To: <AANLkTin2ihGMeB9hou6OWqn5A1GXMroQVx7s-9mo9fq5@mail.gmail.com>
References: <AANLkTin2ihGMeB9hou6OWqn5A1GXMroQVx7s-9mo9fq5@mail.gmail.com>
Message-ID: <AANLkTin3IskLKsj_lqgx-G4IS8DDcpHZSW-TsJqJ7oOa@mail.gmail.com>

I might be wrong, but it looks like a permissions problem?
Personally, I install all packages as su: I open a terminal,
type su, enter the password, start R, install.packages("rgdal"),
select repository,
go through the installation and q() without saving the workspace. Then
exit su and exit the terminal. Use the software as a normal user.
Agus

El d?a 1 de junio de 2010 05:19, Jos? Miguel Barrios
<jmbarriosg at gmail.com> escribi?:
> Hello list,
>
> I'm trying to install rgdal in kubuntu without success so far. ?I guess this
> is the reason why the installation of other packages I am interested in
> (spgrass6, spdep, ...) does not work either (?). Could it be a problem
> between my R version and rgdal version?
>
> I would appreciate any hint. ?Thanks,
>
> Miguel
>
> R version 2.10.1 (2009-12-14)
> i486-pc-linux-gnu
>
> locale:
> ?[1] LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C
> ?[3] LC_TIME=en_US.UTF-8 ? ? ? ?LC_COLLATE=en_US.UTF-8
> ?[5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_US.UTF-8
> ?[7] LC_PAPER=en_US.UTF-8 ? ? ? LC_NAME=C
> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
>
> * installing *source* package ?rgdal? ...
> gdal-config: gdal-config
> checking for gcc... gcc -std=gnu99
> checking for C compiler default output file name... a.out
> checking whether the C compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc -std=gnu99 accepts -g... yes
> checking for gcc -std=gnu99 option to accept ANSI C... none needed
> checking how to run the C preprocessor... gcc -std=gnu99 -E
> checking for egrep... grep -E
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
>
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking proj_api.h usability... yes
> checking proj_api.h presence... yes
> checking for proj_api.h... yes
> checking for pj_init_plus in -lproj... yes
> Package CPP flags: -I/usr/include/gdal
> Package LIBS: -L/usr/lib -lgdal1.6.0
> configure: creating ./config.status
> config.status: creating src/Makevars
> ** libs
> g++ -I/usr/share/R/include -I/usr/include/gdal
> -I"/usr/local/lib/R/site-library/sp/include" ? -fpic ?-g -O2 -c
> OGR_write.cpp -o OGR_write.o
> /bin/bash: g++: command not found
> make: *** [OGR_write.o] Error 127
> ERROR: compilation failed for package ?rgdal?
> * removing ?/usr/local/lib/R/site-library/rgdal?
>
> The downloaded packages are in
> ? ? ? ??/tmp/RtmpQ3P3w6/downloaded_packages?
> Warning message:
> In install.packages("rgdal") :
> ?installation of package 'rgdal' had non-zero exit status
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From edzer.pebesma at uni-muenster.de  Tue Jun  1 07:47:44 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 01 Jun 2010 07:47:44 +0200
Subject: [R-sig-Geo] problems installing rgdal
In-Reply-To: <AANLkTin2ihGMeB9hou6OWqn5A1GXMroQVx7s-9mo9fq5@mail.gmail.com>
References: <AANLkTin2ihGMeB9hou6OWqn5A1GXMroQVx7s-9mo9fq5@mail.gmail.com>
Message-ID: <4C049F00.2000007@uni-muenster.de>

It seems your computer does not have a c++ compiler installed. Please
install package g++, and retry.

On 06/01/2010 05:19 AM, Jos? Miguel Barrios wrote:
> Hello list,
> 
> I'm trying to install rgdal in kubuntu without success so far.  I guess this
> is the reason why the installation of other packages I am interested in
> (spgrass6, spdep, ...) does not work either (?). Could it be a problem
> between my R version and rgdal version?
> 
> I would appreciate any hint.  Thanks,
> 
> Miguel
> 
> R version 2.10.1 (2009-12-14)
> i486-pc-linux-gnu
> 
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> 
> * installing *source* package ?rgdal? ...
> gdal-config: gdal-config
> checking for gcc... gcc -std=gnu99
> checking for C compiler default output file name... a.out
> checking whether the C compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc -std=gnu99 accepts -g... yes
> checking for gcc -std=gnu99 option to accept ANSI C... none needed
> checking how to run the C preprocessor... gcc -std=gnu99 -E
> checking for egrep... grep -E
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> 
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking proj_api.h usability... yes
> checking proj_api.h presence... yes
> checking for proj_api.h... yes
> checking for pj_init_plus in -lproj... yes
> Package CPP flags: -I/usr/include/gdal
> Package LIBS: -L/usr/lib -lgdal1.6.0
> configure: creating ./config.status
> config.status: creating src/Makevars
> ** libs
> g++ -I/usr/share/R/include -I/usr/include/gdal
> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 -c
> OGR_write.cpp -o OGR_write.o
> /bin/bash: g++: command not found
> make: *** [OGR_write.o] Error 127
> ERROR: compilation failed for package ?rgdal?
> * removing ?/usr/local/lib/R/site-library/rgdal?
> 
> The downloaded packages are in
>         ?/tmp/RtmpQ3P3w6/downloaded_packages?
> Warning message:
> In install.packages("rgdal") :
>   installation of package 'rgdal' had non-zero exit status
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From johan.vandewauw at gmail.com  Tue Jun  1 13:00:59 2010
From: johan.vandewauw at gmail.com (Johan Van de Wauw)
Date: Tue, 1 Jun 2010 13:00:59 +0200
Subject: [R-sig-Geo] problems installing rgdal
In-Reply-To: <AANLkTin2ihGMeB9hou6OWqn5A1GXMroQVx7s-9mo9fq5@mail.gmail.com>
References: <AANLkTin2ihGMeB9hou6OWqn5A1GXMroQVx7s-9mo9fq5@mail.gmail.com>
Message-ID: <AANLkTil9ULFl4M10SU5rUWbIwSr2v3fkXsKWeCWCbN-U@mail.gmail.com>

Install the package:
r-base-dev
if you want to build packages using R.
Apart from that you will need libgdal1-dev to build rgdal.

2010/6/1 Jos? Miguel Barrios <jmbarriosg at gmail.com>:
> Hello list,
>
> I'm trying to install rgdal in kubuntu without success so far. ?I guess this
> is the reason why the installation of other packages I am interested in
> (spgrass6, spdep, ...) does not work either (?). Could it be a problem
> between my R version and rgdal version?
>
> I would appreciate any hint. ?Thanks,
>
> Miguel
>
> R version 2.10.1 (2009-12-14)
> i486-pc-linux-gnu
>
> locale:
> ?[1] LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C
> ?[3] LC_TIME=en_US.UTF-8 ? ? ? ?LC_COLLATE=en_US.UTF-8
> ?[5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_US.UTF-8
> ?[7] LC_PAPER=en_US.UTF-8 ? ? ? LC_NAME=C
> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
>
> * installing *source* package ?rgdal? ...
> gdal-config: gdal-config
> checking for gcc... gcc -std=gnu99
> checking for C compiler default output file name... a.out
> checking whether the C compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc -std=gnu99 accepts -g... yes
> checking for gcc -std=gnu99 option to accept ANSI C... none needed
> checking how to run the C preprocessor... gcc -std=gnu99 -E
> checking for egrep... grep -E
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
>
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking proj_api.h usability... yes
> checking proj_api.h presence... yes
> checking for proj_api.h... yes
> checking for pj_init_plus in -lproj... yes
> Package CPP flags: -I/usr/include/gdal
> Package LIBS: -L/usr/lib -lgdal1.6.0
> configure: creating ./config.status
> config.status: creating src/Makevars
> ** libs
> g++ -I/usr/share/R/include -I/usr/include/gdal
> -I"/usr/local/lib/R/site-library/sp/include" ? -fpic ?-g -O2 -c
> OGR_write.cpp -o OGR_write.o
> /bin/bash: g++: command not found
> make: *** [OGR_write.o] Error 127
> ERROR: compilation failed for package ?rgdal?
> * removing ?/usr/local/lib/R/site-library/rgdal?
>
> The downloaded packages are in
> ? ? ? ??/tmp/RtmpQ3P3w6/downloaded_packages?
> Warning message:
> In install.packages("rgdal") :
> ?installation of package 'rgdal' had non-zero exit status
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From Conde at demogr.mpg.de  Tue Jun  1 15:15:20 2010
From: Conde at demogr.mpg.de (Conde Ovando, Dalia Amor)
Date: Tue, 1 Jun 2010 15:15:20 +0200
Subject: [R-sig-Geo] Layer stack with R
References: <AANLkTin2ihGMeB9hou6OWqn5A1GXMroQVx7s-9mo9fq5@mail.gmail.com> 
	<AANLkTil9ULFl4M10SU5rUWbIwSr2v3fkXsKWeCWCbN-U@mail.gmail.com>
Message-ID: <5B2F2CD24AD2764D898AF5A7B9A2ABBF01DF2488@hermes.demogr.mpg.de>

 
Hi all, 

I am working with satellite images LANDSAT, and I am wondering if there is any way to do a layer stack of the bands. 

THANKS 

Dalia

----------
This mail has been sent through the MPI for Demographic Research.  Should you receive a mail that is apparently from a MPI user without this text displayed, then the address has most likely been faked. If you are uncertain about the validity of this message, please check the mail header or ask your system administrator for assistance.




From roman.lustrik at gmail.com  Tue Jun  1 15:43:22 2010
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Tue, 1 Jun 2010 15:43:22 +0200
Subject: [R-sig-Geo] Layer stack with R
In-Reply-To: <5B2F2CD24AD2764D898AF5A7B9A2ABBF01DF2488@hermes.demogr.mpg.de>
References: <AANLkTin2ihGMeB9hou6OWqn5A1GXMroQVx7s-9mo9fq5@mail.gmail.com> 
	<AANLkTil9ULFl4M10SU5rUWbIwSr2v3fkXsKWeCWCbN-U@mail.gmail.com> 
	<5B2F2CD24AD2764D898AF5A7B9A2ABBF01DF2488@hermes.demogr.mpg.de>
Message-ID: <AANLkTimRG4wX7UrFunPoaJkR1u_ITFrlApVy72uJEjU9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100601/54d24a52/attachment.pl>

From cjpauw at gmail.com  Wed Jun  2 17:01:58 2010
From: cjpauw at gmail.com (christiaan pauw)
Date: Wed, 2 Jun 2010 17:01:58 +0200
Subject: [R-sig-Geo] Subsetted SpatialPolygonsDataFrame cannot writeOGR to
	ESRI shapefiles
Message-ID: <AANLkTin_cxJ9XmD4-LznwZPb3lBC3ra0_NeLT3j8TaFj@mail.gmail.com>

Hallo Everybody

I have been using R for a while but I am new to using R on spatial
data. What I want to do seems fairly straightforward to me but for
some reason it doesn't seem to work even after reading a lot of help
files and mail threads. I want to read shapefile containing a town map
and subset it to contain only the polygons that correspond to a
certain field in the data frame. (i.e. selelct those houses in the
town for which I have some other data). I have a unique stand number
in both the dataframe and shapefile.  Then in want to merge some
additional data from the dataframe and export back to a ESRI
shapefile.

I read the shapefiles with readOGR. The resultant object (called
SPbluegum) is a SpatialPolygonsDataFrame

>class(SPbluegum)
[1] "SpatialPolygonsDataFrame"
attr(,"package")
[1] "sp"

I think where things go wrong is where I try to create a new object
that is a subset of the full town SPDF. My code is:

>SPbluegumImP=SPbluegum[which(is.na(match(SPbluegum$PROPDESC,DF$Stand.Number_0))==FALSE),c(3,4,6)]

This works and can be plotted. class() reveals that this too is a
SpatialPolygonsDataFrame but it cannot be written with writeOGR. This
puzzles me since the error message reads:"unknown data type"

> writeOGR(SPbluegumImp, dsn=paste(outdir,sep=""), layer="BluegumImpMap", driver="ESRI Shapefile")
Error in writeOGR(SPbluegumImp, dsn = paste(outdir, sep = ""), layer =
"BluegumImpMap",  :
  unknown data type

Please show me where I go wrong

best regards
Christiaan


From Roger.Bivand at nhh.no  Wed Jun  2 17:12:14 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 2 Jun 2010 17:12:14 +0200 (CEST)
Subject: [R-sig-Geo] Subsetted SpatialPolygonsDataFrame cannot writeOGR
 to ESRI shapefiles
In-Reply-To: <AANLkTin_cxJ9XmD4-LznwZPb3lBC3ra0_NeLT3j8TaFj@mail.gmail.com>
References: <AANLkTin_cxJ9XmD4-LznwZPb3lBC3ra0_NeLT3j8TaFj@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1006021708400.29865@reclus.nhh.no>

On Wed, 2 Jun 2010, christiaan pauw wrote:

> Hallo Everybody
>
> I have been using R for a while but I am new to using R on spatial
> data. What I want to do seems fairly straightforward to me but for
> some reason it doesn't seem to work even after reading a lot of help
> files and mail threads. I want to read shapefile containing a town map
> and subset it to contain only the polygons that correspond to a
> certain field in the data frame. (i.e. selelct those houses in the
> town for which I have some other data). I have a unique stand number
> in both the dataframe and shapefile.  Then in want to merge some
> additional data from the dataframe and export back to a ESRI
> shapefile.
>
> I read the shapefiles with readOGR. The resultant object (called
> SPbluegum) is a SpatialPolygonsDataFrame
>
>> class(SPbluegum)
> [1] "SpatialPolygonsDataFrame"
> attr(,"package")
> [1] "sp"
>
> I think where things go wrong is where I try to create a new object
> that is a subset of the full town SPDF. My code is:
>
>> SPbluegumImP=SPbluegum[which(is.na(match(SPbluegum$PROPDESC,DF$Stand.Number_0))==FALSE),c(3,4,6)]
>
> This works and can be plotted. class() reveals that this too is a
> SpatialPolygonsDataFrame but it cannot be written with writeOGR. This
> puzzles me since the error message reads:"unknown data type"
>
>> writeOGR(SPbluegumImp, dsn=paste(outdir,sep=""), layer="BluegumImpMap", driver="ESRI Shapefile")
> Error in writeOGR(SPbluegumImp, dsn = paste(outdir, sep = ""), layer =
> "BluegumImpMap",  :
>  unknown data type
>
> Please show me where I go wrong

Please always report the version number of the package involved (usually 
with sessionInfo() output). In this case, the error message formatting was 
improved last year, so your rgdal is seriously out-of-date. Update first, 
then if the error re-occurs, you'll know which variable in the data slot 
of the object cannot be exported. More likely, it will be cast to another 
representation in the updated rgdal.

Roger

>
> best regards
> Christiaan
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From thi_veloso at yahoo.com.br  Wed Jun  2 19:20:16 2010
From: thi_veloso at yahoo.com.br (Thiago Veloso)
Date: Wed, 2 Jun 2010 10:20:16 -0700 (PDT)
Subject: [R-sig-Geo] Spatial data interpolation on R
Message-ID: <6744.30335.qm@web54304.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100602/949eebc1/attachment.pl>

From jgarcia at ija.csic.es  Wed Jun  2 20:09:27 2010
From: jgarcia at ija.csic.es (jgarcia at ija.csic.es)
Date: Wed, 2 Jun 2010 20:09:27 +0200 (CEST)
Subject: [R-sig-Geo] Spatial data interpolation on R
In-Reply-To: <6744.30335.qm@web54304.mail.re2.yahoo.com>
References: <6744.30335.qm@web54304.mail.re2.yahoo.com>
Message-ID: <48070.134.219.57.46.1275502167.squirrel@paleo.ija.csic.es>

You should conduct a block kriging from the point sparse data to the
regular grid (the domain of the satellite images). Try, e.g., gstat

Javier
///
> Dear R colleagues!
> ?I?d like to start my participation in this list by describing my current
> problem: inside my area of study I need to compare precipitation data from
> two different sources: both station (total of 86) and a grid (at 8km) of
> satellite estimates.
> ??My specific objective is to interpolate the station data into a regular
> grid in the same resolution of the satellite estimates, preferentially
> having control of the spatial domain (lat/lon coordinates). As far as I
> know this is the correct way of making such comparison.
> ??Could anybody please point directions to perform this task using R? I?m
> such a beginner that I don?t even know if
>  there?s a package designed to create regular grids from "random" data
> (interpolating by kriging or other technique). Usage examples would be
> welcomed as well!
> Thanks in advance,
> ?Thiago.
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From greenberg at ucdavis.edu  Thu Jun  3 02:27:50 2010
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Wed, 2 Jun 2010 17:27:50 -0700
Subject: [R-sig-Geo] Best way to get values of a raster that are not masked?
Message-ID: <AANLkTilfc3UiIOsKU5prESo4t4vtWkT6jUJDEXwZzGEW@mail.gmail.com>

I've got a file and a mask (1s for "good data", NAs for "bad"), and I
want to extract the cell values AND geographic coordinates of these
cells into a data frame or vector that correspond to the locations
where the mask is 1 -- what is the best practice for doing this?  I
can loop through each row/block and do the query, but is there a
"cleaner" way of approaching this in raster()?

--j


From r.hijmans at gmail.com  Thu Jun  3 02:45:47 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 2 Jun 2010 17:45:47 -0700
Subject: [R-sig-Geo] Best way to get values of a raster that are not
	masked?
In-Reply-To: <AANLkTilfc3UiIOsKU5prESo4t4vtWkT6jUJDEXwZzGEW@mail.gmail.com>
References: <AANLkTilfc3UiIOsKU5prESo4t4vtWkT6jUJDEXwZzGEW@mail.gmail.com>
Message-ID: <AANLkTinGeLYlsCYrK3C2TO26tgDlDWJTQT5lV98okljL@mail.gmail.com>

Hi Jonathan,

The function rasterToPoints does that. Its default behavior is to
returns a matrix with coordinates and values for all cells that are
not NA.
You can also ask for cells with a specific range of values, and for a
SptialPointDataFrame.

Robert


On Wed, Jun 2, 2010 at 5:27 PM, Jonathan Greenberg
<greenberg at ucdavis.edu> wrote:
> I've got a file and a mask (1s for "good data", NAs for "bad"), and I
> want to extract the cell values AND geographic coordinates of these
> cells into a data frame or vector that correspond to the locations
> where the mask is 1 -- what is the best practice for doing this? ?I
> can loop through each row/block and do the query, but is there a
> "cleaner" way of approaching this in raster()?
>
> --j
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From cjpauw at gmail.com  Thu Jun  3 08:43:08 2010
From: cjpauw at gmail.com (christiaan pauw)
Date: Thu, 3 Jun 2010 08:43:08 +0200
Subject: [R-sig-Geo] Subsetted SpatialPolygonsDataFrame cannot writeOGR
	to ESRI shapefiles
In-Reply-To: <4C068C62.4090509@nceas.ucsb.edu>
References: <AANLkTin_cxJ9XmD4-LznwZPb3lBC3ra0_NeLT3j8TaFj@mail.gmail.com>
	<4C068C62.4090509@nceas.ucsb.edu>
Message-ID: <AANLkTimammcveuNu59oF9111-SzW9wFNbHAJM9eVOxgg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100603/503925e5/attachment.pl>

From Roger.Bivand at nhh.no  Thu Jun  3 09:03:40 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 3 Jun 2010 09:03:40 +0200 (CEST)
Subject: [R-sig-Geo] Subsetted SpatialPolygonsDataFrame cannot writeOGR
 to ESRI shapefiles
In-Reply-To: <AANLkTimammcveuNu59oF9111-SzW9wFNbHAJM9eVOxgg@mail.gmail.com>
References: <AANLkTin_cxJ9XmD4-LznwZPb3lBC3ra0_NeLT3j8TaFj@mail.gmail.com>
	<4C068C62.4090509@nceas.ucsb.edu>
	<AANLkTimammcveuNu59oF9111-SzW9wFNbHAJM9eVOxgg@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1006030900540.464@reclus.nhh.no>

On Thu, 3 Jun 2010, christiaan pauw wrote:

> Thanks to Rick and Roger for their respective replies. Both helped.
>
> I updated R, GDAL and rgdal (I now have: R version 2.11.1
> (2010-05-31) x86_64-apple-darwin9.8.0 with rgdal_0.6-26).
> I then Ricks proposed writeOGR statement below. This works.
>
> After adding some data (a dataframe called Bluegum) to the data already
> contained in the SPDF with spCbind like this:
>> SPbluegumADD=spCbind(SPbluegumImP,Bluegum)
> I get a SpatialPolygonsDataFrame (according to class()) that can be plotted
> and looks OK on the plot. I can even use the newly added variables to define
> colours in the plot so I am sure the spCbind was successful.
>
> But when I try to write it to a shapefile I get an error again:
>
>> writeOGR(SPbluegumADD,".","SPbluegumImPX",driver="ESRI Shapefile")
> Error in writeOGR(SPbluegumADD, ".", "SPbluegumImPX", driver = "ESRI
> Shapefile") :
>
> GDAL Error 1: Invalid index : -1

Please make the input data objects to spCbind available on a website, with 
a copy of the spCbind command. Use save() to save as a portable RData 
file. Please also report your exact GDAL version and source, as this may 
also be platform dependent.

Roger

>
> I tried to compare the structure of the objects as Rick adviced by using
> list.tree (is there a better way?) and get:
>
>> list.tree(SPbluegumImP, depth=2)
> SPbluegumImP = S4 1 (717288 bytes)( SpatialPolygonsDataFrame )
> A  bbox = double 4= named array 2 X 2= 28.395 -26.388 28.405 ...
> A  proj4string = S4 1( CRS )
> A  polygons = list 144
> A .  ...   and 132 more
> A  plotOrder = integer 144= 4 26 33 6 22 92 ...
> A  data = list 3( data.frame )
>
>> list.tree(SPbluegumADD, depth=2)
> SPbluegumADD = S4 1 (17552624 bytes)( SpatialPolygonsDataFrame )
> A  bbox = double 4= named array 2 X 2= 28.395 -26.388 28.405 ...
> A  proj4string = S4 1( CRS )
> A  polygons = list 144
> A .  ...   and 132 more
> A  plotOrder = integer 144= 4 26 33 6 22 92 ...
> A  data = list 24( data.frame )
> A .  ...   and 12 more
>
> The difference seems to be that the SPDF object created by the spCbind
> contains something extra. The "A .  ...   and 12 more" at the end. When I
> set the depth in list.tree() to -1 to get everything and look right at the
> end I get:
>
> for the original object(SPbluegumImP:
>
> A  data = list 3( data.frame )
> A .  TOWNSHIP = integer 144= category (7 levels)( factor )= BLUEGUM VIEW
> BLUEGUM VIEW ...
> A .  SUBURB = integer 144= category (1 levels)( factor )= BLUEGUM VIEW
> BLUEGUM VIEW ...
> A .  PROPDESC = integer 144= category (5198 levels)( factor )= 116 82 138 11
> 127 ...
> A A  row.names = integer 144= 3 85 94 127 166 ...
>
> for the Object created by spCbind (SPbluegumADD)
>
> A  data = list 24( data.frame )
> A .  TOWNSHIP = integer 144= category (7 levels)( factor )= BLUEGUM VIEW
> BLUEGUM VIEW ...
> A .  SUBURB = integer 144= category (1 levels)( factor )= BLUEGUM VIEW
> BLUEGUM VIEW ...
> A .  PROPDESC = integer 144= category (5198 levels)( factor )= 116 82 138 11
> 127 ...
> A .  Response.ID = integer 144= category (44327 levels)( factor )=
> 53cbc1d8-c12a-4aaf-a74f-0037b8e4c577 ...
> A .  Fieldworker = character 144= Sfiso Jiyane  ...
> A .  Received = integer 144= category (43009 levels)( factor )= 2010/05/01
> 12:44:16 PM ...
> A .  Start = integer 144= category (42997 levels)( factor )= 2010/04/13
> 09:26:10 AM ...
> A .  End = integer 144= category (43124 levels)( factor )= 2010/04/13
> 09:26:57 AM ...
> A .  Duration = integer 144= category (2908 levels)( factor )= 00:00:47
> 00:01:02 ...
> A .  Location = integer 144= category (1 levels)( factor )= N/A N/A N/A N/A
> ...
> A .  Language = integer 144= category (1 levels)( factor )= English English
> ...
> A .  PROPDESC.1 = integer 144= 5 5 5 5 5 5 5 5 ...
> A .  ...   and 12 more
> A A  row.names = integer 144= 3 85 94 127 166 ...
>
> I cannot see a real difference except that the second object now contains
> the additional columns added by spCbind.
>
> Can anyone offer some insight?
>
> regards and thank for the help so far
> Christiaan
>
> On 2 June 2010 18:52, rick reeves <reeves at nceas.ucsb.edu> wrote:
>
>> Christian:
>>
>> Compare the object fields carefully to those in the 'parent' object.
>> Assuming that SPbluegumImP is a valid SpatialPolygonsDataFrame,
>> you might try simplifying the writeOGR statement to:
>>
>>  writeOGR(SPbluegumImP,".","SPbluegumImP",driver="ESRI Shapefile")
>>
>> ..which will write the file SPbluegumImP.shp to the current working folder
>> (which you can establish with setwd("path"))
>>
>> You can also send me your file, and I will be glad to have a look.
>>
>> hope this helps,
>> Rick R
>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From cheluna at gmail.com  Thu Jun  3 11:16:35 2010
From: cheluna at gmail.com (Consuelo Hermosilla)
Date: Thu, 3 Jun 2010 11:16:35 +0200
Subject: [R-sig-Geo] enfa-gnesfa details (adehabitat)
Message-ID: <AANLkTinCV8LACM53ZUBxXroLsW9UgDrMDH3xFxozkr0L@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100603/d85a2489/attachment.pl>

From cheluna at gmail.com  Thu Jun  3 11:58:05 2010
From: cheluna at gmail.com (Consuelo Hermosilla)
Date: Thu, 3 Jun 2010 11:58:05 +0200
Subject: [R-sig-Geo] randtest.enfa {adehabitat}
Message-ID: <AANLkTil0kDMR7-fU1q6W_2LmfxXZF0Pfa4kYjy2nguxm@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100603/ba13cf3e/attachment.pl>

From mdsumner at gmail.com  Fri Jun  4 04:54:40 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 4 Jun 2010 12:54:40 +1000
Subject: [R-sig-Geo] read function for LAS data
Message-ID: <AANLkTilysK_oh0qeGhpaBOrbFCAvhcA_HuTEeTdldain@mail.gmail.com>

Hello,

I'm looking for interest in this functionality and eventually working
it into a package.

I don't actually use LAS data much, and only have one example file so
I'm hoping others who do or know others who would be interested can
help. I have previously posted this to r-spatial-devel.

R's support for the "raw" type provides a very neat way of reading
data from binary files, such as LAS files. These files have a header
containing metadata that is used to specify reading from the bulk data
in the file. Essentially, you can read large sets of records at once
into a raw matrix with readBin and then use the indexing tools to
extract the relevant bytes for each element of the record. This means
that the bulk read is fast, and processing is also vectorized as the
raw matrix can then be read in index pieces by readBin.

I've done this in a simplistic way in the attached functions

  o "publicHeaderDescription"  - function returns a list generated to hold
      information about the header

  o "readLAS" - read file function


It works for a LAS 1.0 file that I have (see lasinfo summary below)
and returns a matrix of record values.  Certainly it works fast and
efficiently enough for smallish files. I really don't have experience
with the likely range of sizes of these files.

The remaining work I see involves:

 - write as a "chunked" read so large files can be processed in parts,
    not as one big slurp
 - return only desired record values, and / or subset of records
 - extract all components of the records, and generalize for LAS 1.1, 1.2
 - re-organize the header read and arrangement (what I've done was
    easy enough for me to understand, but it's a bit of a mess)
 (- no doubt many more general improvements I haven't thought of)

To use:

source("http://staff.acecrc.org.au/~mdsumner/las/readLAS.R")

## I cannot provide LAS data, this is just an illustration

f <- "lfile.las"
## [1] 53.83393 Mb

file.info(f)$size/1e6

system.time({
  d <- readLAS(f)
})
# user  system elapsed
#   1.01    0.21    1.21

dim(d)
# [1] 1922632       5

colnames(d)
#[1] "x"         "y"         "z"         "gpstime"   "intensity"

Optionally the list of header components (some extracted as actual
data, some left in their "raw" form) can be returned instead of data
using "returnHeaderOnly=TRUE".

###
## example: simple plot with rgl
library(rgl)
scl <- function(x) (x - min(x))/diff(range(x))
plot3d(d[,1:3], col = topo.colors(256)[scl(d[,5]) * 256])

I hope this is of interest.

Cheers, Mike.




lasinfo output on "lfile.las"
---------------------------------------------------------
 Header Summary
---------------------------------------------------------
 File Name: lfile.las
 Version:                    1.0
 Source ID:                  0
 Reserved:                   0
 Project ID/GUID:           '00000000-0000-0000-0000-000000000000'
 System Identifier:         ''
 Generating Software:       'TerraScan'
 File Creation Day/Year:    0/0
 Header Size                227
 Offset to Point Data       229
 Number Var. Length Records 0
 Point Data Format          1
 Point Data Record Length   28
 Number of Point Records    1922632
 Number of Points by Return 1572923 324305 24659 740 5
 Scale Factor X Y Z         0.01 0.01 0.01
##  etc...


From cjpauw at gmail.com  Fri Jun  4 05:44:37 2010
From: cjpauw at gmail.com (christiaan pauw)
Date: Fri, 4 Jun 2010 05:44:37 +0200
Subject: [R-sig-Geo] Subsetted SpatialPolygonsDataFrame cannot writeOGR
	to ESRI shapefiles
In-Reply-To: <alpine.LRH.2.00.1006030900540.464@reclus.nhh.no>
References: <AANLkTin_cxJ9XmD4-LznwZPb3lBC3ra0_NeLT3j8TaFj@mail.gmail.com>
	<4C068C62.4090509@nceas.ucsb.edu>
	<AANLkTimammcveuNu59oF9111-SzW9wFNbHAJM9eVOxgg@mail.gmail.com>
	<alpine.LRH.2.00.1006030900540.464@reclus.nhh.no>
Message-ID: <AANLkTilYIugSCT30SXp6bbpJ1Hbrs6KYV_dgNa1rYhqW@mail.gmail.com>

Thanks Roger.

I get the following from my gdal_version.h

GDAL_RELEASE_DATE ? ? 20100423
GDAL_RELEASE_NAME ? ? "1.7.2"

Downloaded rgdal yesterday from
http://www(dot)kyngchaos(dot)com/files/software/unixport/rgdal-0.6.26-1.zip

I am on Mac OS X 10.5.8

I place the data files together with a sample program here:
https://sites(dot)google(dot)com/site/christiaanpauw/file-cabinet

There is one thing that I noticed while uploading the files that
strikes me as strange. The total size of the SPDF is 28k (containing
144 polygons with an associated dataframe with 3 variables) while the
dataframe(containing 144 rows of 19 variables) in 1.4M. Is it possible
that there is something corrupt in the dataframe that only comes to
the fore in the writeOGR operation?

Thanks for your help
best regards
Christiaan

On 3 June 2010 09:03, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
> On Thu, 3 Jun 2010, christiaan pauw wrote:
> Please make the input data objects to spCbind available on a website, with a copy of the spCbind command. Use save() to save as a portable RData file. Please also report your exact GDAL version and source, as this may also be platform dependent.
>
> Roger
>
>> Thanks to Rick and Roger for their respective replies. Both helped.
>>
>> I updated R, GDAL and rgdal (I now have: R version 2.11.1
>> (2010-05-31) x86_64-apple-darwin9.8.0 with rgdal_0.6-26).
>> I then Ricks proposed writeOGR statement below. This works.
>>
>> After adding some data (a dataframe called Bluegum) to the data already
>> contained in the SPDF with spCbind like this:
>>>
>>> SPbluegumADD=spCbind(SPbluegumImP,Bluegum)
>>
>> I get a SpatialPolygonsDataFrame (according to class()) that can be plotted
>> and looks OK on the plot. I can even use the newly added variables to define
>> colours in the plot so I am sure the spCbind was successful.
>>
>> But when I try to write it to a shapefile I get an error again:
>>
>>> writeOGR(SPbluegumADD,".","SPbluegumImPX",driver="ESRI Shapefile")
>>
>> Error in writeOGR(SPbluegumADD, ".", "SPbluegumImPX", driver = "ESRI
>> Shapefile") :
>>
>> GDAL Error 1: Invalid index : -1
>
>


From clement.calenge at gmail.com  Fri Jun  4 09:14:03 2010
From: clement.calenge at gmail.com (=?ISO-8859-1?Q?Cl=E9ment_Calenge?=)
Date: Fri, 04 Jun 2010 09:14:03 +0200
Subject: [R-sig-Geo] enfa-gnesfa details (adehabitat)
In-Reply-To: <AANLkTinCV8LACM53ZUBxXroLsW9UgDrMDH3xFxozkr0L@mail.gmail.com>
References: <AANLkTinCV8LACM53ZUBxXroLsW9UgDrMDH3xFxozkr0L@mail.gmail.com>
Message-ID: <4C08A7BB.5070709@gmail.com>


> In the Gnesfa paper, when you explain the examples and compare the
> eigenvalues of the 3 analysis, you mentioned a significance test for the
> eigenvalues. For example, at the end of page 680: "Indeed, the tests of the
> first (??1 = 1.61, P<0.002) and of the last eigenvalue (??6 = 0.53, P<0.002)
> were both significant." I don't know if I miss it (I'm sorry if I did!!),
> but I don't know where did you get those tests from? Are they implemented in
> adehabitat too?
>    

No, they are not implemented, but they are easy to implement. Imagine 
that pc is the object containing the PCA of the table of the values of 
environmental variables (columns) in each pixel (rows), and that wei is 
the vector describing the utilization weight of each pixel. Then you can 
perform the test (e.g. for the FANTER) in this way:

## observed first eigenvalue:
obs <- gnesfa(pc, Focus=wei, scan=FALSE)$eig[1]
## randomized datasets:
sim <- sapply(1:500, function(i) {
     weir <- sample(wei)
     gnesfa(pc, Focus=weir, scan=FALSE)$eig[1]
})
## The randomization test
ran <- as.randtest(sim, obs)
ran
plot(ran)

Note that this tests relies on the hypothesis of independence between 
the pixels (e.g. no "contagion" of the utilization weights between 
neighbour pixels, so no social attraction, etc.)


> Another thing, in the MADIFA paper -Calenge et al (2008)-, you tested the
> habitat selection value (??1 = 3.7, P<  0.002, pag 561) with a Monte Carlo
> test. Is it like the renfa function? Again, can I find it in adehabitat?
>    

No, it is not available, but it is similar to the renfa function. To 
perform it, use the same code as above, but replace "Focus=weir" by 
"Reference=weir"


> Regarding the goodness of fit you used, is it implemented in adehabitat? The
> Fig.4 of that paper reminds me AUC plots, are they equivalent?
>    


No they are not equivalent. Have a look at Knick and Dyer for a more 
detailed description (1997, Distribution of black-tailed jackrabbit 
habitat use areas in changing landscapes using the Mahalanobis distance 
statistic, Journal of Wildlife Management, 61: 75-85). They are not 
implemented in adehabitat. They are easy to obtain. If "ma" is your 
object containing the results of the MADIFA, you can draw such a graph by:

## for the approximate Mahalanobis distances
x <- seq(0,1,length=100)
plot(quantile(sort(ma$mahasu), x), x, ty="l", xlab="Mahalanobis 
distances", ylab="Quantiles")

And similarly for other approaches.


> Just two last details... In Calenge et al (2008) you mentioned the inertia
> ratio, but I'm not sure where I can find it in the output of madifa/fanter?
>    

The inertia ratio for each factorial axis is simply the corresponding 
eigenvalue. The inertia ratio for the first axis is the first 
eigenvalue, etc.


> And about enfa, the output gives the global marginality, but, where can I
> find the global specialization or global tolerance?
>    

The "global specialization" does not exist. The specialization 
corresponds to the ratio
variance of available weights/variance of utilization weights
measured on a variable (or a direction of the ecological space). 
Therefore, it is an
unidimensional measure, and cannot be measured globally over the 
ecological space.
The tolerance is just the sum of the variances of utilization weights 
over all the variables.
If "tab" is the dataframe containing the values of environmental 
variables (columns) in each pixel (rows), and that wei is as above the 
vector describing the utilization weight of each pixel, you can 
calculate the tolerance with:

sum(dudi.pca(tab, row.w=wei, scan=FALSE)$eig)

HTH,

Cl?ment Calenge

-- 
Cl?ment CALENGE
Cellule d'appui ? l'analyse de donn?es
Office national de la chasse et de la faune sauvage
Saint Benoist - 78610 Auffargis
tel. (33) 01.30.46.54.14


From clement.calenge at gmail.com  Fri Jun  4 09:18:25 2010
From: clement.calenge at gmail.com (=?ISO-8859-1?Q?Cl=E9ment_Calenge?=)
Date: Fri, 04 Jun 2010 09:18:25 +0200
Subject: [R-sig-Geo] randtest.enfa {adehabitat}
In-Reply-To: <AANLkTil0kDMR7-fU1q6W_2LmfxXZF0Pfa4kYjy2nguxm@mail.gmail.com>
References: <AANLkTil0kDMR7-fU1q6W_2LmfxXZF0Pfa4kYjy2nguxm@mail.gmail.com>
Message-ID: <4C08A8C1.6020206@gmail.com>


> I have another question (oops)!!
> When you do the randomisation test for ENFA and plot the result (with
> scatter() function), what's the meaning of the arrow value?
>    

It is not possible to use the function scatter to plot the result of a 
randomization test.
I do not understand your question here...
Best regards,

Cl?ment Calenge

-- 
Cl?ment CALENGE
Cellule d'appui ? l'analyse de donn?es
Office national de la chasse et de la faune sauvage
Saint Benoist - 78610 Auffargis
tel. (33) 01.30.46.54.14


From Roger.Bivand at nhh.no  Fri Jun  4 10:50:24 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 4 Jun 2010 10:50:24 +0200 (CEST)
Subject: [R-sig-Geo] Subsetted SpatialPolygonsDataFrame cannot writeOGR
 to ESRI shapefiles
In-Reply-To: <AANLkTilYIugSCT30SXp6bbpJ1Hbrs6KYV_dgNa1rYhqW@mail.gmail.com>
References: <AANLkTin_cxJ9XmD4-LznwZPb3lBC3ra0_NeLT3j8TaFj@mail.gmail.com>
	<4C068C62.4090509@nceas.ucsb.edu>
	<AANLkTimammcveuNu59oF9111-SzW9wFNbHAJM9eVOxgg@mail.gmail.com>
	<alpine.LRH.2.00.1006030900540.464@reclus.nhh.no>
	<AANLkTilYIugSCT30SXp6bbpJ1Hbrs6KYV_dgNa1rYhqW@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1006041042210.10022@reclus.nhh.no>

On Fri, 4 Jun 2010, christiaan pauw wrote:

> Thanks Roger.
>
> I get the following from my gdal_version.h
>
> GDAL_RELEASE_DATE ? ? 20100423
> GDAL_RELEASE_NAME ? ? "1.7.2"
>
> Downloaded rgdal yesterday from
> http://www(dot)kyngchaos(dot)com/files/software/unixport/rgdal-0.6.26-1.zip
>
> I am on Mac OS X 10.5.8
>
> I place the data files together with a sample program here:
> https://sites(dot)google(dot)com/site/christiaanpauw/file-cabinet
>
> There is one thing that I noticed while uploading the files that
> strikes me as strange. The total size of the SPDF is 28k (containing
> 144 polygons with an associated dataframe with 3 variables) while the
> dataframe(containing 144 rows of 19 variables) in 1.4M. Is it possible
> that there is something corrupt in the dataframe that only comes to
> the fore in the writeOGR operation?

Christiaan:

The underlying cause is the difference between more forgiving R and the 
less tolerant OGR/Shapefile driver with reference to variable/field names. 
Even though the OGR driver tries to launder the field names, it doesn't 
succeed for fields c(4, 5, 13:16, 20). Please replace the field names 
before using writeOGR(). Other OGR drivers may be less restrictive here, 
so this is up to the user, not to writeOGR:

load("Bluegum.Rda")
load("SPbluegumImp.Rda")
library(maptools)
SPbluegumADD=spCbind(SPbluegumImp,Bluegum)
library(rgdal)
writeOGR(SPbluegumImp,".","SPbluegumImp",driver="ESRI Shapefile")
writeOGR(SPbluegumADD,".","SPbluegumADD",driver="ESRI Shapefile")
summary(SPbluegumADD)
names(SPbluegumADD) <- paste("V", 1:22, sep="")
summary(SPbluegumADD)
writeOGR(SPbluegumADD,".","SPbluegumADD",driver="ESRI Shapefile")
summary(readOGR(".","SPbluegumADD"))

Hope this helps,

Roger

PS. The saved data frame is large because all the roughly 40K original 
factor levels are still retained for each factor variable on subsetting. 
If you don't need factors anyway, you can control this with the 
stringsAsFactors= arguments to data import functions (the default is TRUE, 
but if FALSE, you get a character vector instead).

>
> Thanks for your help
> best regards
> Christiaan
>
> On 3 June 2010 09:03, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>
>> On Thu, 3 Jun 2010, christiaan pauw wrote:
>> Please make the input data objects to spCbind available on a website, with a copy of the spCbind command. Use save() to save as a portable RData file. Please also report your exact GDAL version and source, as this may also be platform dependent.
>>
>> Roger
>>
>>> Thanks to Rick and Roger for their respective replies. Both helped.
>>>
>>> I updated R, GDAL and rgdal (I now have: R version 2.11.1
>>> (2010-05-31) x86_64-apple-darwin9.8.0 with rgdal_0.6-26).
>>> I then Ricks proposed writeOGR statement below. This works.
>>>
>>> After adding some data (a dataframe called Bluegum) to the data already
>>> contained in the SPDF with spCbind like this:
>>>>
>>>> SPbluegumADD=spCbind(SPbluegumImP,Bluegum)
>>>
>>> I get a SpatialPolygonsDataFrame (according to class()) that can be plotted
>>> and looks OK on the plot. I can even use the newly added variables to define
>>> colours in the plot so I am sure the spCbind was successful.
>>>
>>> But when I try to write it to a shapefile I get an error again:
>>>
>>>> writeOGR(SPbluegumADD,".","SPbluegumImPX",driver="ESRI Shapefile")
>>>
>>> Error in writeOGR(SPbluegumADD, ".", "SPbluegumImPX", driver = "ESRI
>>> Shapefile") :
>>>
>>> GDAL Error 1: Invalid index : -1
>>
>>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From alexandre.villers at cebc.cnrs.fr  Fri Jun  4 14:40:16 2010
From: alexandre.villers at cebc.cnrs.fr (Alexandre VILLERS)
Date: Fri, 04 Jun 2010 14:40:16 +0200
Subject: [R-sig-Geo] help unzipping tiff files compressed with gzip
Message-ID: <4C08F430.5060306@cebc.cnrs.fr>

Good afternoon,

I know this not the most appropriate place to post this message but I 
hope that some of you have already been confronted to the same problem.
I have a lot of NDVI tiff files that have been compressed with gzip 
(filename such as 81jul15a.n07-VIg_data.tif.gz ) and that I need to 
geoprocess with R. I would like to unzip the tif from within R but was 
not able to properly understand how to connect to the gz file and unzip 
it with this with function gzfile.
Anybody with some lines of codes hanging that would save my afternoon 
(and help me understand how the connection works) ?

Best regards and thanks for any help.

Alex

-- 
Alexandre Villers
PhD.
AgriPop
Centre d'Etudes Biologiques de Chiz?-CNRS UPR1934
79360 Beauvoir sur Niort

Phone +33 (0)5 49 09 96 13
Fax   +33 (0)5 49 09 65 26




__________ Information from ESET Mail Security, version of virus signature database 5171 (20100604) __________

The message was checked by ESET Mail Security.
http://www.eset.com


From mdsumner at gmail.com  Fri Jun  4 15:59:39 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 4 Jun 2010 23:59:39 +1000
Subject: [R-sig-Geo] help unzipping tiff files compressed with gzip
In-Reply-To: <4C08F430.5060306@cebc.cnrs.fr>
References: <4C08F430.5060306@cebc.cnrs.fr>
Message-ID: <AANLkTimeX93exEmfWbW-gQ8TMvBzxrESinGduc7M_pUx@mail.gmail.com>

gzfile gives a connection, which readGDAL does not support - you need
an actual dataset name that GDAL can understand (not necessarily just
a file path btw).

I think you will have to extract the tif with shell/system calls to
gzip or similar - what OS are you using? Rtools provides a handy gzip
that could be used if your system doesn't already have it (e.g.
Windows).

There are virtual drivers in GDAL for reading from compressed files
(similar to the R gzfile connection mechanism), but it will depend on
the installation of GDAL that you have with rgdal:

http://trac.osgeo.org/gdal/wiki/UserDocs/ReadInZip

http://osgeo-org.1803224.n2.nabble.com/Support-for-reading-GDAL-datasets-in-compressed-archives-gz-and-zip-td2035285.html

It's not available on my system as far as I know ( or I'm not using it
correctly) - if it were avaible in the GDAL used to build rgdal it
should allow readGDAL to read from the "/vsigzip/path....gz" string.

Cheers, Mike.



On Fri, Jun 4, 2010 at 10:40 PM, Alexandre VILLERS
<alexandre.villers at cebc.cnrs.fr> wrote:
> Good afternoon,
>
> I know this not the most appropriate place to post this message but I hope
> that some of you have already been confronted to the same problem.
> I have a lot of NDVI tiff files that have been compressed with gzip
> (filename such as 81jul15a.n07-VIg_data.tif.gz ) and that I need to
> geoprocess with R. I would like to unzip the tif from within R but was not
> able to properly understand how to connect to the gz file and unzip it with
> this with function gzfile.
> Anybody with some lines of codes hanging that would save my afternoon (and
> help me understand how the connection works) ?
>
> Best regards and thanks for any help.
>
> Alex
>
> --
> Alexandre Villers
> PhD.
> AgriPop
> Centre d'Etudes Biologiques de Chiz?-CNRS UPR1934
> 79360 Beauvoir sur Niort
>
> Phone +33 (0)5 49 09 96 13
> Fax ? +33 (0)5 49 09 65 26
>
>
>
>
> __________ Information from ESET Mail Security, version of virus signature
> database 5171 (20100604) __________
>
> The message was checked by ESET Mail Security.
> http://www.eset.com
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From alexandre.villers at cebc.cnrs.fr  Fri Jun  4 17:13:18 2010
From: alexandre.villers at cebc.cnrs.fr (Alexandre VILLERS)
Date: Fri, 04 Jun 2010 17:13:18 +0200
Subject: [R-sig-Geo] help unzipping tiff files compressed with gzip
In-Reply-To: <AANLkTimeX93exEmfWbW-gQ8TMvBzxrESinGduc7M_pUx@mail.gmail.com>
References: <4C08F430.5060306@cebc.cnrs.fr>
	<AANLkTimeX93exEmfWbW-gQ8TMvBzxrESinGduc7M_pUx@mail.gmail.com>
Message-ID: <4C09180E.1050903@cebc.cnrs.fr>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100604/88f85c24/attachment.html>

From brenning at uwaterloo.ca  Fri Jun  4 17:22:20 2010
From: brenning at uwaterloo.ca (Alexander Brenning)
Date: Fri, 04 Jun 2010 11:22:20 -0400
Subject: [R-sig-Geo] RSAGA multi.focal.function
In-Reply-To: <4BFE9F010200005C0005722B@WVUGW01.wvu.edu>
References: <4BFE9F010200005C0005722B@WVUGW01.wvu.edu>
Message-ID: <4C091A2C.4010803@uwaterloo.ca>

Hi,

the problem Nathan described has been solved, and a new release of RSAGA 
(0.9-7) is now available on CRAN.

The problem concerned the situation where radius >= 1 grid cells AND 
more than one input grid was used, i.e. most practical situations were 
not affected by this bug (e.g. applying a 'predict' method to a stack of 
input grids on a pixel-by-pixel basis was not affected because in this 
situation, radius = 0).

Thanks again Nathan for your input.

Best,
   Alex



On 27/05/2010 4:34 PM, Nathan Odgers wrote:
> Hi,
>
> I have been trying to get the RSAGA multi.focal.function function to
> work in R. This is how I have been calling it:
>
> multi.focal.function(in.grids=filestack,out.grid.prefix="test_multi",path="z:/saga/stack",
>
>
fun=returnfirstline,in.varnames=c("elev_v","fix_v"),radius=3,search.mode="square",mw.to.vector=FALSE,mw.na.rm=FALSE)
>
> where filestack is a vector containing the names of two grids: a DEM
> and another grid with integer values. The returnfirstline function
> prints (to the console) the arrays that multi.focal.function sends to
> returnfirstline. This is all very basic because for now I?m just
> trying to get a feel for how multi.focal.function works with multiple
> grids before I try and write a more complex function to use with it.
>
> In any case, this is the problem that I am having with it: everything
> seems to work in that returnfirstline prints the rectangular windows
> to the console output, but the problem is that multi.focal.function
> seems to set the first row of the input grids to NA values. This is
> what the header and first portion of the first four rows of the ascii
> DEM look like:
>
> ncols         202 nrows         202 xllcorner     -50010.3411746
> yllcorner     426994.8486065 cellsize      24.7883519 NODATA_value
> -9999 455 455 456 456 457 457 456 455 456 (?) 454 455 456 456 458 458
> 458 457 457 (?) 454 455 456 457 458 458 459 458 457 (?) 454 454 456
> 457 458 458 459 458 457 (?)
>
> And this is the first matrix window, derived from the DEM, that
> multi.focal.function passes to returnfirstline:
>
> [,1] [,2] [,3] [,4] [,5] [,6] [,7] [1,]   NA   NA   NA   NA   NA   NA
> NA [2,]   NA   NA   NA   NA   NA   NA   NA [3,]   NA   NA   NA   NA
> NA   NA   NA [4,]   NA   NA   NA   NA   NA   NA   NA [5,]   NA   NA
> NA  454  455  456  456 [6,]   NA   NA   NA  454  455  456  457 [7,]
> NA   NA   NA  454  454  456  457
>
> As you can see, the centre value of the matrix window is NA, which
> really should be the elevation 455 from the first row of the DEM.
>
> Any idea why this is happening, or am I just not understanding how to
> use multi.focal.function?
>
> Thanks,
>
> Nathan
>
> Nathan Odgers Postdoctoral Fellow?globalsoilmap.net West Virginia
> University Division of Plant and Soil Sciences National Soil Survey
> Center Geospatial Research Unit ph: +1 304 293 9839
>
> [[alternative HTML version deleted]]
>

-- 
Alexander Brenning
brenning at uwaterloo.ca - T +1-519-888-4567 ext 35783
Department of Geography and Environmental Management
University of Waterloo
200 University Ave. W - Waterloo, ON - Canada N2L 3G1
http://www.fes.uwaterloo.ca/geography/faculty/brenning/


From thi_veloso at yahoo.com.br  Fri Jun  4 20:43:51 2010
From: thi_veloso at yahoo.com.br (Thiago Veloso)
Date: Fri, 4 Jun 2010 11:43:51 -0700 (PDT)
Subject: [R-sig-Geo] Spatial data interpolation on R
Message-ID: <814685.11105.qm@web54301.mail.re2.yahoo.com>

??Dear all,
??Thank you very much for those who read and tried to help. However, I'm really a begginer on R and especially geostatistics.?I'm trying to follow "gstat" package's guide, but I'm facing some trouble when trying to reproduce the commands created for the meuse dataset with my own dataset.
??I wonder if anybody could just help me in this task. In order to better illustrate my problem, I am attaching a figure which shows my spatial domain. The greater contour is Rio Grande do Sul, Brazilian southernmost state. The highlighted region in its interior represents the largest soybean producer area (my area of study). The finer grid are satellite precipitation values and the red dots are the
 station.
?I'm also attaching the two files that contains the gauge and cmorph (satellite) data I mentioned (both files in ascii format). As you can note, I've already organized them in the following structure:
LON ? ? ? ? ? ? ? ? ? ? ? ? ? ? LAT ? ? ? ? ? ? ? ? ? ? ? ? ? ? precipitation record
??Satellite data spatial ranges from longitude -55.6951 to -50.0929 and latitude -29.6907 to -27.1437, with increments ("grid size") of 8km (0.072?, as you can note in the file). Station data varies from longitude -55.2670 to -50.0660 and latitude -29.2680 to -27.1920, disposed randomly.
??Thus, all I need is to interpolate the station values into the same grid of cmorph (satellite) in order to perform a proper comparison between these two sources. Quite challenging problem, huh?
??Could you help me to do this using gstat on R?? Please let me know if I have skipped any
 detail...
??Best wishes,
??Thiago
--- On Wed, 2/6/10, jgarcia at ija.csic.es <jgarcia at ija.csic.es> wrote:

From: jgarcia at ija.csic.es <jgarcia at ija.csic.es>
Subject: Re: [R-sig-Geo] Spatial data interpolation on R
To: "Thiago Veloso" <thi_veloso at yahoo.com.br>
Cc: r-sig-geo at stat.math.ethz.ch
Date: Wednesday, 2 June, 2010, 15:09

You should conduct a block kriging from the point sparse data to the
regular grid (the domain of the satellite images). Try, e.g., gstat

Javier
///
> Dear R colleagues!
> ?I?d like to start my participation in this list by describing my current
> problem: inside my area of study I need to compare precipitation data from
> two different
 sources: both station (total of 86) and a grid (at 8km) of
> satellite estimates.
> ??My specific objective is to interpolate the station data into a regular
> grid in the same resolution of the satellite estimates, preferentially
> having control of the spatial domain (lat/lon coordinates). As far as I
> know this is the correct way of making such comparison.
> ??Could anybody please point directions to perform this task using R? I?m
> such a beginner that I don?t even know if
>? there?s a package designed to create regular grids from "random" data
> (interpolating by kriging or other technique). Usage examples would be
> welcomed as well!
> Thanks in advance,
> ?Thiago.
>
>
>
>
> ??? [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo
 mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>




      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100604/34e23d0b/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: example.png
Type: image/png
Size: 29202 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100604/34e23d0b/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: gauge_09.csv
Type: text/csv
Size: 2858 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100604/34e23d0b/attachment.bin>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: cmorph_09.csv
Type: text/csv
Size: 41088 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100604/34e23d0b/attachment-0001.bin>

From tech_dev at wildintellect.com  Fri Jun  4 22:07:01 2010
From: tech_dev at wildintellect.com (Alex Mandel)
Date: Fri, 04 Jun 2010 13:07:01 -0700
Subject: [R-sig-Geo] read function for LAS data
In-Reply-To: <AANLkTilysK_oh0qeGhpaBOrbFCAvhcA_HuTEeTdldain@mail.gmail.com>
References: <AANLkTilysK_oh0qeGhpaBOrbFCAvhcA_HuTEeTdldain@mail.gmail.com>
Message-ID: <4C095CE5.50409@wildintellect.com>

On 06/03/2010 07:54 PM, Michael Sumner wrote:
> Hello,
> 
> I'm looking for interest in this functionality and eventually working
> it into a package.
> 
> I don't actually use LAS data much, and only have one example file so
> I'm hoping others who do or know others who would be interested can
> help. I have previously posted this to r-spatial-devel.
> 
I think there are people who would use it. You might want to have a look
at http://liblas.org/ (some of the same people that do gdal/org work)
Wrapping this library might be a good approach. There are example files
available too.

Thanks,
Alex


From cheluna at gmail.com  Fri Jun  4 09:40:20 2010
From: cheluna at gmail.com (Consuelo Hermosilla)
Date: Fri, 4 Jun 2010 09:40:20 +0200
Subject: [R-sig-Geo] randtest.enfa {adehabitat}
In-Reply-To: <4C08A8C1.6020206@gmail.com>
References: <AANLkTil0kDMR7-fU1q6W_2LmfxXZF0Pfa4kYjy2nguxm@mail.gmail.com> 
	<4C08A8C1.6020206@gmail.com>
Message-ID: <AANLkTimRDvD7_pRN7XpgEPitMa4Uw_qvJbxeukp9ytqn@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100604/9bf991da/attachment.pl>

From mdsumner at gmail.com  Sat Jun  5 04:36:07 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Sat, 5 Jun 2010 12:36:07 +1000
Subject: [R-sig-Geo] read function for LAS data
In-Reply-To: <4C095CE5.50409@wildintellect.com>
References: <AANLkTilysK_oh0qeGhpaBOrbFCAvhcA_HuTEeTdldain@mail.gmail.com>
	<4C095CE5.50409@wildintellect.com>
Message-ID: <AANLkTilBFwiDCrWDLmxkgY2bEH8pJJJuqPwMRZtDDEGI@mail.gmail.com>

Thanks Alex, I will eventually post this to a broader audience.

I've used liblas and lastools, but the aim here is for a pure R
implementation that is built directly from the LAS specification
without 3rd party tools.

The R code already works quite well to extract x/y/z/time/intensity,
it just needs some extra work to tidy up and generalize things and
ensure that very big datasets can be read.

Cheers, Mike.


On Sat, Jun 5, 2010 at 6:07 AM, Alex Mandel <tech_dev at wildintellect.com> wrote:
> On 06/03/2010 07:54 PM, Michael Sumner wrote:
>> Hello,
>>
>> I'm looking for interest in this functionality and eventually working
>> it into a package.
>>
>> I don't actually use LAS data much, and only have one example file so
>> I'm hoping others who do or know others who would be interested can
>> help. I have previously posted this to r-spatial-devel.
>>
> I think there are people who would use it. You might want to have a look
> at http://liblas.org/ (some of the same people that do gdal/org work)
> Wrapping this library might be a good approach. There are example files
> available too.
>
> Thanks,
> Alex
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From katakagi at bu.edu  Sun Jun  6 01:45:00 2010
From: katakagi at bu.edu (Kenneth Takagi)
Date: Sat, 05 Jun 2010 19:45:00 -0400
Subject: [R-sig-Geo] Issues with unionSpatialPolygons on Ubuntu
Message-ID: <20100605194500.mxuehyukg0kowoog@www.bu.edu>


Hi,

I've cross posted with r-sig-debian since they may be an issue for 
linux (never had this
problem on my windows machine...)
I recently made the switch to Ubuntu 10.04 (lucid), and found that 
unionSpatialPolygons()
gives me the following error when trying to combine polygons within a 
shapefile:

# Read in shapefile and merge polygons
foo <- readShapePoly("foo.shp", proj4string = CRS("+init=epsg:2272"))
IDs <- as.character(foo$ID)
SP_out <- unionSpatialPolygons(foo, IDs)
Error: isTRUE(gpclibPermitStatus()) is not TRUE

I've seen some posts about a package "rgeos" which may have something 
to do with this
error, and I downloaded the source from:
http://r-forge.r-project.org/R/?group_id=602

But when I've tried to install by source using R CMD INSTALL (or using
install.packages()) I get the following error message:

...lines of output not shown...
rgeos_misc.c: In function ?rgeos_hausdorffdistance?:
rgeos_misc.c:62: error: ?GEOSHausdorffDistance_r? undeclared (first use 
in this function)
rgeos_misc.c:62: error: (Each undeclared identifier is reported only once
rgeos_misc.c:62: error: for each function it appears in.)
make: *** [rgeos_misc.o] Error 1
ERROR: compilation failed for package ?rgeos?

I'm using R version 2.11.1 (2010-05-31), in ubuntu 10.04 LTS

Thanks for any help you can offer on getting unionSpatialPolygon up and 
running!

Ken


From etiennebr at gmail.com  Sun Jun  6 12:09:08 2010
From: etiennebr at gmail.com (Etienne Bellemare Racine)
Date: Sun, 06 Jun 2010 06:09:08 -0400
Subject: [R-sig-Geo] read function for LAS data
In-Reply-To: <AANLkTilBFwiDCrWDLmxkgY2bEH8pJJJuqPwMRZtDDEGI@mail.gmail.com>
References: <AANLkTilysK_oh0qeGhpaBOrbFCAvhcA_HuTEeTdldain@mail.gmail.com>	<4C095CE5.50409@wildintellect.com>
	<AANLkTilBFwiDCrWDLmxkgY2bEH8pJJJuqPwMRZtDDEGI@mail.gmail.com>
Message-ID: <4C0B73C4.4070902@gmail.com>

This is interesting, I'll try your code on my lidar files in the next 
few days.

  2010-06-04 22:36, Michael Sumner wrote :
> Thanks Alex, I will eventually post this to a broader audience.
>
> I've used liblas and lastools, but the aim here is for a pure R
> implementation that is built directly from the LAS specification
> without 3rd party tools.
>    

What might be of interest in using liblas is that it provides support 
for many las versions and they plan to provide support for some versions 
to come (conditional to funding) so having an R binding might be of 
interest here. They are also working on the integration of a spatial 
index which would allow easier handling of large files. I must say I 
don't know how hard writing a wrapper for R might be for that particular 
tool.

To other issue I see here is that R is loading the whole file in memory, 
so if you can manage small files, that might not be that easy with 
(standard) larger ones. Don't you think ? Did you give a try to the R 
SAGA package. There is a module for loading las files but again, I don't 
know how it manages memory. I guess that it could be possible to use 
some sort of ff package to handle bigger files, but that's just on the 
top of my head.

Etienne

> The R code already works quite well to extract x/y/z/time/intensity,
> it just needs some extra work to tidy up and generalize things and
> ensure that very big datasets can be read.
>
> Cheers, Mike.
>
>
> On Sat, Jun 5, 2010 at 6:07 AM, Alex Mandel<tech_dev at wildintellect.com>  wrote:
>    
>> On 06/03/2010 07:54 PM, Michael Sumner wrote:
>>      
>>> Hello,
>>>
>>> I'm looking for interest in this functionality and eventually working
>>> it into a package.
>>>
>>> I don't actually use LAS data much, and only have one example file so
>>> I'm hoping others who do or know others who would be interested can
>>> help. I have previously posted this to r-spatial-devel.
>>>
>>>        
>> I think there are people who would use it. You might want to have a look
>> at http://liblas.org/ (some of the same people that do gdal/org work)
>> Wrapping this library might be a good approach. There are example files
>> available too.
>>
>> Thanks,
>> Alex
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>      
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From mdsumner at gmail.com  Sun Jun  6 16:18:49 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Mon, 7 Jun 2010 00:18:49 +1000
Subject: [R-sig-Geo] read function for LAS data
In-Reply-To: <4C0B73C4.4070902@gmail.com>
References: <AANLkTilysK_oh0qeGhpaBOrbFCAvhcA_HuTEeTdldain@mail.gmail.com>
	<4C095CE5.50409@wildintellect.com>
	<AANLkTilBFwiDCrWDLmxkgY2bEH8pJJJuqPwMRZtDDEGI@mail.gmail.com>
	<4C0B73C4.4070902@gmail.com>
Message-ID: <AANLkTimX-SGULQb_2z9GjRVENdcTiPXIf4NRqYPvCYti@mail.gmail.com>

Hello,

> To other issue I see here is that R is loading the whole file in memory, so
> if you can manage small files, that might not be that easy with (standard)
> larger ones. Don't you think ?

That was certainly true of the version of code I posted, but writing a
more flexible version is not difficult, and actually less difficult
than I expected. I've implemented arguments to "skip" and read "nrows"
at a time, so there is the beginnings of a wrapper around the core
read for building more flexibility.

(I was thinking of including subsetting of various kinds which really
makes it more complicated, and the appropriate level to handle that is
in a wrapper to this function).

I've updated the R source on my site, and here's a new example. This
should be considered as a rough working draft, the details can be
hidden in the final suite of functions. My chunk/rows handling is
pretty awkward, and may have bugs for particular record numbers.

Any testing you can provide would be greatly appreciated.


# new version with "skip" and "nrows" arguments
source("http://staff.acecrc.org.au/~mdsumner/las/readLAS.R")

f <- "lfile.las"

## get just the header
hd <- readLAS(f, returnHeaderOnly = TRUE)

numrows <- hd$`Number of point records`
## [1] 1922632

## read in chunks, and pass to DB or ff, or subset by sampling, etc..
rowskip <- 0
chunk <- 1e5
rowsleft <- numrows

system.time({

## keep track of how many rows we skip, and how many are left
for (i in 1:ceiling(numrows / chunk)) {
	if (rowsleft < chunk) chunk <- rowsleft
	if (chunk < 1) break;
	d <- readLAS(f, skip = rowskip, nrows = chunk)
	rowskip <- rowskip + nn
	rowsleft <- numrows - nn
}

})

#   user  system elapsed
#   1.10    0.55    1.64







On Sun, Jun 6, 2010 at 8:09 PM, Etienne Bellemare Racine
<etiennebr at gmail.com> wrote:
> This is interesting, I'll try your code on my lidar files in the next few
> days.
>
> ?2010-06-04 22:36, Michael Sumner wrote :
>>
>> Thanks Alex, I will eventually post this to a broader audience.
>>
>> I've used liblas and lastools, but the aim here is for a pure R
>> implementation that is built directly from the LAS specification
>> without 3rd party tools.
>>
>
> What might be of interest in using liblas is that it provides support for
> many las versions and they plan to provide support for some versions to come
> (conditional to funding) so having an R binding might be of interest here.
> They are also working on the integration of a spatial index which would
> allow easier handling of large files. I must say I don't know how hard
> writing a wrapper for R might be for that particular tool.
>
> To other issue I see here is that R is loading the whole file in memory, so
> if you can manage small files, that might not be that easy with (standard)
> larger ones. Don't you think ? Did you give a try to the R SAGA package.
> There is a module for loading las files but again, I don't know how it
> manages memory. I guess that it could be possible to use some sort of ff
> package to handle bigger files, but that's just on the top of my head.
>
> Etienne
>
>> The R code already works quite well to extract x/y/z/time/intensity,
>> it just needs some extra work to tidy up and generalize things and
>> ensure that very big datasets can be read.
>>
>> Cheers, Mike.
>>
>>
>> On Sat, Jun 5, 2010 at 6:07 AM, Alex Mandel<tech_dev at wildintellect.com>
>> ?wrote:
>>
>>>
>>> On 06/03/2010 07:54 PM, Michael Sumner wrote:
>>>
>>>>
>>>> Hello,
>>>>
>>>> I'm looking for interest in this functionality and eventually working
>>>> it into a package.
>>>>
>>>> I don't actually use LAS data much, and only have one example file so
>>>> I'm hoping others who do or know others who would be interested can
>>>> help. I have previously posted this to r-spatial-devel.
>>>>
>>>>
>>>
>>> I think there are people who would use it. You might want to have a look
>>> at http://liblas.org/ (some of the same people that do gdal/org work)
>>> Wrapping this library might be a good approach. There are example files
>>> available too.
>>>
>>> Thanks,
>>> Alex
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From Roger.Bivand at nhh.no  Sun Jun  6 21:00:14 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 6 Jun 2010 21:00:14 +0200 (CEST)
Subject: [R-sig-Geo] Issues with unionSpatialPolygons on Ubuntu
In-Reply-To: <20100605194500.mxuehyukg0kowoog@www.bu.edu>
References: <20100605194500.mxuehyukg0kowoog@www.bu.edu>
Message-ID: <alpine.LRH.2.00.1006062051050.22658@reclus.nhh.no>

On Sat, 5 Jun 2010, Kenneth Takagi wrote:

>
> Hi,
>
> I've cross posted with r-sig-debian since they may be an issue for linux 
> (never had this problem on my windows machine...) I recently made the 
> switch to Ubuntu 10.04 (lucid), and found that unionSpatialPolygons() 
> gives me the following error when trying to combine polygons within a 
> shapefile:

Did you check that the package versions on Linux and Windows were the same 
(they were not, hence the difference)?

>
> # Read in shapefile and merge polygons
> foo <- readShapePoly("foo.shp", proj4string = CRS("+init=epsg:2272"))
> IDs <- as.character(foo$ID)
> SP_out <- unionSpatialPolygons(foo, IDs)
> Error: isTRUE(gpclibPermitStatus()) is not TRUE
>

Googling on "R gpclibPermit" takes you to the explanation (second hit), 
with the posting on this list's archives at:

https://stat.ethz.ch/pipermail/r-sig-geo/2010-May/008206.html

So set gpclibPermit() to TRUE to use gpclib, or try again to install 
rgeos (which has an external dependency), which is work in progress, so 
may not install cleanly when lots of changes are in progress (which is 
the case at the moment).

Hope this helps,

Roger

> I've seen some posts about a package "rgeos" which may have something to do 
> with this
> error, and I downloaded the source from:
> http://r-forge.r-project.org/R/?group_id=602
>
> But when I've tried to install by source using R CMD INSTALL (or using
> install.packages()) I get the following error message:
>
> ...lines of output not shown...
> rgeos_misc.c: In function ?rgeos_hausdorffdistance?:
> rgeos_misc.c:62: error: ?GEOSHausdorffDistance_r? undeclared (first use in 
> this function)
> rgeos_misc.c:62: error: (Each undeclared identifier is reported only once
> rgeos_misc.c:62: error: for each function it appears in.)
> make: *** [rgeos_misc.o] Error 1
> ERROR: compilation failed for package ?rgeos?
>
> I'm using R version 2.11.1 (2010-05-31), in ubuntu 10.04 LTS
>
> Thanks for any help you can offer on getting unionSpatialPolygon up and 
> running!
>
> Ken
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From katakagi at bu.edu  Sun Jun  6 22:56:03 2010
From: katakagi at bu.edu (Kenneth Takagi)
Date: Sun, 06 Jun 2010 16:56:03 -0400
Subject: [R-sig-Geo] Issues with unionSpatialPolygons on Ubuntu
In-Reply-To: <alpine.LRH.2.00.1006062051050.22658@reclus.nhh.no>
References: <20100605194500.mxuehyukg0kowoog@www.bu.edu>
	<alpine.LRH.2.00.1006062051050.22658@reclus.nhh.no>
Message-ID: <20100606165603.di1izmbs0g84cw88@www.bu.edu>

Thanks for the info,

Turns out that that I didn't have package "gpclib" installed.  Once 
installed, I could run the gpclibPermit() function, which set 
gpclibPermitStatus() = T:

> library(maptools)
Loading required package: foreign
Loading required package: sp
Loading required package: lattice

	Note: polygon geometry computations in maptools
  	depend on the package gpclib, which has a
  	restricted licence. It is disabled by default;
  	to enable gpclib, type gpclibPermit()

Checking rgeos availability as gpclib substitute:
FALSE

> gpclibPermit()
General Polygon Clipper Library for R (version 1.5-1)
	Type 'class ? gpc.poly' for help

[1] TRUE

> # Read in shapefile and merge polygons
> foo <- readShapePoly("foo.shp", proj4string = CRS("+init=epsg:2272"))
> IDs <- as.character(foo$ID)
> SP_out <- unionSpatialPolygons(foo, IDs)

And everything worked fine.  Not sure if there is another way, but this 
worked for me!

Ken

Quoting Roger Bivand <Roger.Bivand at nhh.no>:

> On Sat, 5 Jun 2010, Kenneth Takagi wrote:
>
>>
>> Hi,
>>
>> I've cross posted with r-sig-debian since they may be an issue for 
>> linux (never had this problem on my windows machine...) I recently 
>> made the switch to Ubuntu 10.04 (lucid), and found that 
>> unionSpatialPolygons() gives me the following error when trying to 
>> combine polygons within a shapefile:
>
> Did you check that the package versions on Linux and Windows were the same
> (they were not, hence the difference)?
>
>>
>> # Read in shapefile and merge polygons
>> foo <- readShapePoly("foo.shp", proj4string = CRS("+init=epsg:2272"))
>> IDs <- as.character(foo$ID)
>> SP_out <- unionSpatialPolygons(foo, IDs)
>> Error: isTRUE(gpclibPermitStatus()) is not TRUE
>>
>
> Googling on "R gpclibPermit" takes you to the explanation (second hit),
> with the posting on this list's archives at:
>
> https://stat.ethz.ch/pipermail/r-sig-geo/2010-May/008206.html
>
> So set gpclibPermit() to TRUE to use gpclib, or try again to install
> rgeos (which has an external dependency), which is work in progress, so
> may not install cleanly when lots of changes are in progress (which is
> the case at the moment).
>
> Hope this helps,
>
> Roger
>
>> I've seen some posts about a package "rgeos" which may have 
>> something to do with this
>> error, and I downloaded the source from:
>> http://r-forge.r-project.org/R/?group_id=602
>>
>> But when I've tried to install by source using R CMD INSTALL (or using
>> install.packages()) I get the following error message:
>>
>> ...lines of output not shown...
>> rgeos_misc.c: In function ?rgeos_hausdorffdistance?:
>> rgeos_misc.c:62: error: ?GEOSHausdorffDistance_r? undeclared (first 
>> use in this function)
>> rgeos_misc.c:62: error: (Each undeclared identifier is reported only once
>> rgeos_misc.c:62: error: for each function it appears in.)
>> make: *** [rgeos_misc.o] Error 1
>> ERROR: compilation failed for package ?rgeos?
>>
>> I'm using R version 2.11.1 (2010-05-31), in ubuntu 10.04 LTS
>>
>> Thanks for any help you can offer on getting unionSpatialPolygon up 
>> and running!
>>
>> Ken
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> -- 
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>
>


From roman.lustrik at gmail.com  Mon Jun  7 08:56:24 2010
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Mon, 7 Jun 2010 08:56:24 +0200
Subject: [R-sig-Geo] specific colors for specific cell values
Message-ID: <AANLkTimypCfoksnh0KGZsfL3EuDi8eiJsTRcecHrm83n@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100607/77f200dc/attachment.pl>

From clement.calenge at gmail.com  Mon Jun  7 10:34:05 2010
From: clement.calenge at gmail.com (=?ISO-8859-1?Q?Cl=E9ment_Calenge?=)
Date: Mon, 07 Jun 2010 10:34:05 +0200
Subject: [R-sig-Geo] randtest.enfa {adehabitat}
In-Reply-To: <AANLkTimRDvD7_pRN7XpgEPitMa4Uw_qvJbxeukp9ytqn@mail.gmail.com>
References: <AANLkTil0kDMR7-fU1q6W_2LmfxXZF0Pfa4kYjy2nguxm@mail.gmail.com>
	<4C08A8C1.6020206@gmail.com>
	<AANLkTimRDvD7_pRN7XpgEPitMa4Uw_qvJbxeukp9ytqn@mail.gmail.com>
Message-ID: <4C0CAEFD.6090403@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100607/4ba22c83/attachment.pl>

From Gerard.Heuvelink at wur.nl  Mon Jun  7 13:36:16 2010
From: Gerard.Heuvelink at wur.nl (Heuvelink, Gerard)
Date: Mon, 7 Jun 2010 13:36:16 +0200
Subject: [R-sig-Geo] reading kmz file in R
Message-ID: <B24011B58D81A54AA0D43674E0FE148707DEFFAA2E@scomp0537.wurnet.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100607/8c5e6e6c/attachment.pl>

From bibiko at eva.mpg.de  Mon Jun  7 14:23:41 2010
From: bibiko at eva.mpg.de (=?iso-8859-1?Q?Hans-J=F6rg_Bibiko?=)
Date: Mon, 7 Jun 2010 14:23:41 +0200
Subject: [R-sig-Geo] reading kmz file in R
In-Reply-To: <B24011B58D81A54AA0D43674E0FE148707DEFFAA2E@scomp0537.wurnet.nl>
References: <B24011B58D81A54AA0D43674E0FE148707DEFFAA2E@scomp0537.wurnet.nl>
Message-ID: <ADD2F311-E41A-4FD3-A51A-E20D8D2A3F8B@eva.mpg.de>


On Jun 7, 2010, at 1:36 PM, Heuvelink, Gerard wrote:

> I used 'Add polygon' in Google Earth to create a (single)  closed polygon. It was saved with extension kmz.
> 
> How can I open such a file in R, such that I can for instance do an overlay with raster maps (SpatialGridDataFrame)?


Here only my first thoughts:
kmz files are nothing else then zipped kml files. You can save your polygon in Google Earth by choosing "kml" as format, or unzip your kmz file and rename it to *.kml, or read the kmz as zip connection in R and process the data coming from that connection.

I hope it helps a bit.

Cheers and het beste,
--Hans


From bibiko at eva.mpg.de  Mon Jun  7 14:56:21 2010
From: bibiko at eva.mpg.de (=?iso-8859-1?Q?Hans-J=F6rg_Bibiko?=)
Date: Mon, 7 Jun 2010 14:56:21 +0200
Subject: [R-sig-Geo] reading kmz file in R
In-Reply-To: <ADD2F311-E41A-4FD3-A51A-E20D8D2A3F8B@eva.mpg.de>
References: <B24011B58D81A54AA0D43674E0FE148707DEFFAA2E@scomp0537.wurnet.nl>
	<ADD2F311-E41A-4FD3-A51A-E20D8D2A3F8B@eva.mpg.de>
Message-ID: <C34B857C-D026-4B12-B8E6-3651D183E99A@eva.mpg.de>


On Jun 7, 2010, at 2:23 PM, Hans-J?rg Bibiko wrote:
> On Jun 7, 2010, at 1:36 PM, Heuvelink, Gerard wrote:
> I used 'Add polygon' in Google Earth to create a (single)  closed polygon. It was saved with extension kmz.
>> 
>> How can I open such a file in R, such that I can for instance do an overlay with raster maps (SpatialGridDataFrame)?
> 
> Here only my first thoughts:
> kmz files are nothing else then zipped kml files. You can save your polygon in Google Earth by choosing "kml" as format, or unzip your kmz file and rename it to *.kml, or read the kmz as zip connection in R and process the data coming from that connection.

Here a tiny R example:

library(maptools)
getKMLcoordinates(textConnection(system("unzip -p /Users/foo/test.kmz", intern = TRUE)))

--Hans

From folopez at ivic.gob.ve  Mon Jun  7 16:12:28 2010
From: folopez at ivic.gob.ve (=?UTF-8?Q?Freddy_L=C3=B3pez?=)
Date: Mon, 7 Jun 2010 09:12:28 -0500
Subject: [R-sig-Geo] About extcoeff function.-
Message-ID: <AANLkTilu8wH28iSbvu7cR4F0YoVj6Ok7lSnc2H3zgVOn@mail.gmail.com>

Dear All,

First of all, I present my apologise for this question. I'm sure this
has an easy solution; but I've no found one yet.

When I run the example of extcoeff function (in SpatialExtremes
library) I get a plot which axis are latitude and longitude, I
understand.

In that example the locations are created using:

locations <- matrix(runif(2*n.site, 0, 10), ncol = 2)

and I asume that for this reason the 'center' of the plot is about (0,0).

But (and around here emerge my doubts) if I replace the later locations by:

locations <- matrix(runif(2*n.site, 100, 200), ncol = 2)

I could imagine the 'center' of the plot is not (0,0) (perhaps about
(100,100)?) but this is not the case.

Why this question? Because I have a set of real locations with real
pluviometrical measures and the plot (extcoeff plot) is refering to
different coordinates (always around (0,0)).

I don't know if I have misunderstood the help page or something else.

Does anyone know what the problem is?


--
?But Gwindor answered: 'The doom lies in yourself, not in your name.'?

JRR Tolkien


From etiennebr at gmail.com  Mon Jun  7 16:31:59 2010
From: etiennebr at gmail.com (Etienne Bellemare Racine)
Date: Mon, 07 Jun 2010 10:31:59 -0400
Subject: [R-sig-Geo] read function for LAS data
In-Reply-To: <AANLkTimX-SGULQb_2z9GjRVENdcTiPXIf4NRqYPvCYti@mail.gmail.com>
References: <AANLkTilysK_oh0qeGhpaBOrbFCAvhcA_HuTEeTdldain@mail.gmail.com>	<4C095CE5.50409@wildintellect.com>	<AANLkTilBFwiDCrWDLmxkgY2bEH8pJJJuqPwMRZtDDEGI@mail.gmail.com>	<4C0B73C4.4070902@gmail.com>
	<AANLkTimX-SGULQb_2z9GjRVENdcTiPXIf4NRqYPvCYti@mail.gmail.com>
Message-ID: <4C0D02DF.9040405@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100607/7127dac6/attachment.pl>

From mdsumner at gmail.com  Mon Jun  7 16:32:09 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 8 Jun 2010 00:32:09 +1000
Subject: [R-sig-Geo] About extcoeff function.-
In-Reply-To: <AANLkTilu8wH28iSbvu7cR4F0YoVj6Ok7lSnc2H3zgVOn@mail.gmail.com>
References: <AANLkTilu8wH28iSbvu7cR4F0YoVj6Ok7lSnc2H3zgVOn@mail.gmail.com>
Message-ID: <AANLkTinftLgNLHSc6itBcyIk3qPPhe-3BpugNqP-tBGQ@mail.gmail.com>

The runif function has arguments min/max:

args(runif)
#function (n, min = 0, max = 1)
#NULL

So, in the first example the sampling is done in [0, 10] and the
second in [100, 200] - so the approximate centre is (5,5) and (150,
150) respectively.

In terms of the extcoeff function, the resulting plot centre is to do
with the modelling process - some transformation that is not simply
related to the actual coordinates of the data.

Someone here may be familiar with this package, but in general terms
the package author is perhaps a more appropriate target for your
questions than this list. There is a vignette in the package, if you
have not already read it:

vignette("SpatialExtremesGuide")

Cheers, Mike.



On Tue, Jun 8, 2010 at 12:12 AM, Freddy L?pez <folopez at ivic.gob.ve> wrote:
> Dear All,
>
> First of all, I present my apologise for this question. I'm sure this
> has an easy solution; but I've no found one yet.
>
> When I run the example of extcoeff function (in SpatialExtremes
> library) I get a plot which axis are latitude and longitude, I
> understand.
>
> In that example the locations are created using:
>
> locations <- matrix(runif(2*n.site, 0, 10), ncol = 2)
>
> and I asume that for this reason the 'center' of the plot is about (0,0).
>
> But (and around here emerge my doubts) if I replace the later locations by:
>
> locations <- matrix(runif(2*n.site, 100, 200), ncol = 2)
>
> I could imagine the 'center' of the plot is not (0,0) (perhaps about
> (100,100)?) but this is not the case.
>
> Why this question? Because I have a set of real locations with real
> pluviometrical measures and the plot (extcoeff plot) is refering to
> different coordinates (always around (0,0)).
>
> I don't know if I have misunderstood the help page or something else.
>
> Does anyone know what the problem is?
>
>
> --
> ?But Gwindor answered: 'The doom lies in yourself, not in your name.'?
>
> JRR Tolkien
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From folopez at ivic.gob.ve  Mon Jun  7 16:42:12 2010
From: folopez at ivic.gob.ve (=?UTF-8?Q?Freddy_L=C3=B3pez?=)
Date: Mon, 7 Jun 2010 09:42:12 -0500
Subject: [R-sig-Geo] About extcoeff function.-
In-Reply-To: <AANLkTinftLgNLHSc6itBcyIk3qPPhe-3BpugNqP-tBGQ@mail.gmail.com>
References: <AANLkTilu8wH28iSbvu7cR4F0YoVj6Ok7lSnc2H3zgVOn@mail.gmail.com> 
	<AANLkTinftLgNLHSc6itBcyIk3qPPhe-3BpugNqP-tBGQ@mail.gmail.com>
Message-ID: <AANLkTinQuK74Pj2AwUcB6KxzfILuI38t0au7JElr3cRo@mail.gmail.com>

Thanks Michael,

I have understood that the centre is located by considering the
distance in this sense: in the case [0,10], the axis varies from -10
to 10 and in the  [100, 200] case goes from -200 to 200. Some ideas of
symmetry...

Thanks for your attention. I will wait some hours to write to package author.

Cheers.

On Mon, Jun 7, 2010 at 09:32, Michael Sumner <mdsumner at gmail.com> wrote:
> The runif function has arguments min/max:
>
> args(runif)
> #function (n, min = 0, max = 1)
> #NULL
>
> So, in the first example the sampling is done in [0, 10] and the
> second in [100, 200] - so the approximate centre is (5,5) and (150,
> 150) respectively.
>
> In terms of the extcoeff function, the resulting plot centre is to do
> with the modelling process - some transformation that is not simply
> related to the actual coordinates of the data.
>
> Someone here may be familiar with this package, but in general terms
> the package author is perhaps a more appropriate target for your
> questions than this list. There is a vignette in the package, if you
> have not already read it:
>
> vignette("SpatialExtremesGuide")
>
> Cheers, Mike.
>
>
>
> On Tue, Jun 8, 2010 at 12:12 AM, Freddy L?pez <folopez at ivic.gob.ve> wrote:
>> Dear All,
>>
>> First of all, I present my apologise for this question. I'm sure this
>> has an easy solution; but I've no found one yet.
>>
>> When I run the example of extcoeff function (in SpatialExtremes
>> library) I get a plot which axis are latitude and longitude, I
>> understand.
>>
>> In that example the locations are created using:
>>
>> locations <- matrix(runif(2*n.site, 0, 10), ncol = 2)
>>
>> and I asume that for this reason the 'center' of the plot is about (0,0).
>>
>> But (and around here emerge my doubts) if I replace the later locations by:
>>
>> locations <- matrix(runif(2*n.site, 100, 200), ncol = 2)
>>
>> I could imagine the 'center' of the plot is not (0,0) (perhaps about
>> (100,100)?) but this is not the case.
>>
>> Why this question? Because I have a set of real locations with real
>> pluviometrical measures and the plot (extcoeff plot) is refering to
>> different coordinates (always around (0,0)).
>>
>> I don't know if I have misunderstood the help page or something else.
>>
>> Does anyone know what the problem is?
>>
>>
>> --
>> ?But Gwindor answered: 'The doom lies in yourself, not in your name.'?
>>
>> JRR Tolkien
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
?But Gwindor answered: 'The doom lies in yourself, not in your name.'?

JRR Tolkien


From Jan.Quets at ua.ac.be  Mon Jun  7 17:55:07 2010
From: Jan.Quets at ua.ac.be (Quets Jan)
Date: Mon, 7 Jun 2010 17:55:07 +0200
Subject: [R-sig-Geo] existance of a specific non-overlapping marked
	spatial model in spatstat or other R package?
References: <57DC18C299094D4299F837570C5DF1C52B1433680E@EXWA-MBX01.nexus.csiro.au>
Message-ID: <7D403BF1018E6D4882ADD0F77E35BC5C159579@xmail06.ad.ua.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100607/6f907079/attachment.pl>

From corey.sparks at utsa.edu  Mon Jun  7 20:45:58 2010
From: corey.sparks at utsa.edu (Corey Sparks)
Date: Mon, 7 Jun 2010 13:45:58 -0500
Subject: [R-sig-Geo] Help with glmmPQL using Scottish Lip Cancer data
Message-ID: <C832A896.2D16%corey.sparks@utsa.edu>

Dear List,
I'm trying to replicate results from several sources that analyze the
Clayton and Kaldor (1987) Scottish Lip Cancer data using a Poisson GLMM with
spatial correlation structure using a simple exponential variogram model.
The only way (I think) that my data are different from the published data
are that i'm using the Lat/Long instead of the OSGB projection.

Here is what I've tried:
scot<-read.csv("scotland.csv")
names(scot)
scot$aff<-scot$AFF/10
scot$x<-scot$Longitude
scot$y<-scot$Latitude
scot$smr<-scot$Observed/scot$Expected
scot$logsmr<-log(scot$smr+1)
coordinates(scot)=~x+y

library(MASS)
library(nlme)

#This is the first try, using the corEXP() directly in glmmPQL

fit<-glmmPQL(Observed~offset(log(Expected))+aff,family=poisson, data=scot,
random=~1|District, correlation=corExp(form=~x+y), niter=200)

#it fails with:
iteration 1
Error in corFactor.corSpatial(object) :
  NA/NaN/Inf in foreign function call (arg 1)
In addition: Warning messages:
1: In min(unlist(attr(object, "covariate"))) :
  no non-missing arguments to min; returning Inf
2: In min(unlist(attr(object, "covariate"))) :
  no non-missing arguments to min; returning Inf


#Then I try to initialize the spatial correlation as in ASDAR
sp2<-corSpatial( form=~x+y, type="exponential")
spcor<-Initialize(sp2, as(scot, "data.frame")[,c("x","y")])

glmmPQL(Observed~offset(log(Expected))+aff,family=poisson, data=scot,
random=~1|District, correlation=spcor, niter=200, na.action="na.omit")

#This fails with:
iteration 1
iteration 2
iteration 3
iteration 4
iteration 5
Error in lme.formula(fixed = zz ~ offset(log(Expected)) + aff, random = ~1 |
: 
  nlminb problem, convergence error code = 1
  message = function evaluation limit reached without convergence (9)

Basically, i'm wondering if  anyone can get this to work, because i'm at my
wits end.  


My system info is:
sessionInfo()
R version 2.11.1 (2010-05-31)
x86_64-apple-darwin9.8.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] nlme_3.1-96  MASS_7.3-6   gstat_0.9-69 sp_0.9-64

loaded via a namespace (and not attached):
[1] grid_2.11.1    lattice_0.18-8 tools_2.11.1


Best, 
Corey

I'm pasting in the data, in case anyone wants to have a look:

District,Observed,Expected,AFF,Latitude,Longitude
1,9,1.4,16,57.29,5.5
2,39,8.7,16,57.56,2.36
3,11,3,10,58.44,3.9
4,9,2.5,24,55.76,2.4
5,15,4.3,10,57.71,5.09
6,8,2.4,24,59.13,3.25
7,26,8.1,10,57.47,3.3
8,7,2.3,7,60.24,1.43
9,6,2,7,56.9,5.42
10,20,6.6,16,57.24,2.6
11,13,4.4,7,58.12,6.8
12,5,1.8,16,58.06,4.64
13,3,1.1,10,57.47,3.98
14,8,3.3,24,54.94,5
15,17,7.8,7,56.3,3.1
16,9,4.6,16,57,3
17,2,1.1,10,57.06,4.09
18,7,4.2,7,55.65,2.88
19,9,5.5,7,57.24,4.73
20,7,4.4,10,55.35,2.9
21,16,10.5,7,56.75,2.98
22,31,22.7,16,57.12,2.2
23,11,8.8,10,56.4,5.27
24,7,5.6,7,55.63,3.96
25,19,15.5,1,56.2,3.3
26,15,12.5,1,56.1,3.6
27,7,6,7,55.24,4.09
28,10,9,7,55.95,2.8
29,16,14.4,10,56.6,4.09
30,11,10.2,10,55.9,3.8
31,5,4.8,7,55.47,4.55
32,3,2.9,24,55,4.36
33,7,7,10,55.83,3.2
34,8,8.5,7,56.3,4.73
35,11,12.3,7,55.29,4.98
36,9,10.1,0,55.94,4.95
37,11,12.7,10,55.76,5.02
38,8,9.4,1,55.91,4.18
39,6,7.2,16,56.15,4.99
40,4,5.3,0,56.05,4.91
41,10,18.8,1,55.88,4.82
42,8,15.8,16,56.03,4
43,2,4.3,16,56.15,3.96
44,6,14.6,0,55.82,4.09
45,19,50.7,1,55.93,3.4
46,3,8.2,7,55.65,4.75
47,2,5.6,1,55.71,4.45
48,3,9.3,1,55.79,4.27
49,28,88.7,0,55.9,4.55
50,6,19.6,1,56.45,3.2
51,1,3.4,1,56,4.27
52,1,3.6,0,56.15,4.64
53,1,5.7,1,55.79,4.7
54,1,7,1,55.99,4.45
55,0,4.2,16,55.68,3.38
56,0,1.8,10,55.18,3.4


-- 
Corey Sparks
Assistant Professor
Department of Demography and Organization Studies
University of Texas at San Antonio
501 West Durango Blvd
Monterey Building 2.270C
San Antonio, TX 78207
210-458-3166
corey.sparks 'at' utsa.edu
https://rowdyspace.utsa.edu/users/ozd504/www/index.htm


From greenberg at ucdavis.edu  Mon Jun  7 21:41:16 2010
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Mon, 7 Jun 2010 12:41:16 -0700
Subject: [R-sig-Geo] netCDF, raster(), and being memory-safe
Message-ID: <AANLkTikk5WWdrY3WkavmOzXK0yvpnEqjyr4dvGICnFLY@mail.gmail.com>

r-sig-geo'ers:

Next in my barrage of questions -- what would be a memory-safe way of
dealing with netCDF files via raster()?  I understand that raster
loads the entire netCDF band/file into memory when using raster():

u_wind_rasters=stack(u_wind_file,zvar='uwnd')

or

v_wind_raster=raster(v_wind_file,zvar='vwnd',time=1)

where u_wind_file and v_wind_file are .nc files.

Would it make sense to pre-convert these to something "safer"?  Is
there a memory-safe way of converting these to some multi-band image
within R?

--j


From hobu.inc at gmail.com  Mon Jun  7 22:17:14 2010
From: hobu.inc at gmail.com (Howard Butler)
Date: Mon, 7 Jun 2010 15:17:14 -0500
Subject: [R-sig-Geo] read function for LAS data
In-Reply-To: <4C0B73C4.4070902@gmail.com>
References: <AANLkTilysK_oh0qeGhpaBOrbFCAvhcA_HuTEeTdldain@mail.gmail.com>	<4C095CE5.50409@wildintellect.com>
	<AANLkTilBFwiDCrWDLmxkgY2bEH8pJJJuqPwMRZtDDEGI@mail.gmail.com>
	<4C0B73C4.4070902@gmail.com>
Message-ID: <D44CA39B-5DBE-4EC7-838B-C9AA39725239@gmail.com>


On Jun 6, 2010, at 5:09 AM, Etienne Bellemare Racine wrote:

> This is interesting, I'll try your code on my lidar files in the next few days.
> 
> 2010-06-04 22:36, Michael Sumner wrote :
>> Thanks Alex, I will eventually post this to a broader audience.
>> 
>> I've used liblas and lastools, but the aim here is for a pure R
>> implementation that is built directly from the LAS specification
>> without 3rd party tools.
>>   
> 
> What might be of interest in using liblas is that it provides support for many las versions and they plan to provide support for some versions to come (conditional to funding) so having an R binding might be of interest here. They are also working on the integration of a spatial index which would allow easier handling of large files. I must say I don't know how hard writing a wrapper for R might be for that particular tool.

and controllable point caching, reprojection on the fly (when linked w/ GDAL), coordinate system description, and LAS 1.0-1.3 (no waveform for 1.3 though) support.  I would note that contrary to what the LAS specification says, there are many softwares out in the wild that don't write LAS files properly.  This causes big hassles, but it's libLAS' job to ensure that it can read everything, so we bend over backwards to ensure things work while doing our best to write valid files.

I maintain an LAS sample library at http://liblas.org/samples .  They vary based on format types and the softwares that wrote them as this is what is most interesting to libLAS.  They are free for non-commercial usages.

I understand the desire to not have external dependencies, which is the impetus for efforts like this.  It is unfortunate that distribution and platform issues make duplication of efforts like these economical in the short term.

Howard

From r.hijmans at gmail.com  Mon Jun  7 23:12:23 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Mon, 7 Jun 2010 14:12:23 -0700
Subject: [R-sig-Geo] netCDF, raster(), and being memory-safe
In-Reply-To: <AANLkTikk5WWdrY3WkavmOzXK0yvpnEqjyr4dvGICnFLY@mail.gmail.com>
References: <AANLkTikk5WWdrY3WkavmOzXK0yvpnEqjyr4dvGICnFLY@mail.gmail.com>
Message-ID: <AANLkTim1rQrWysAApL25nDVWx8X6z0ADM7lysMwl8Vee@mail.gmail.com>

Hi Jonathan,

Currently the safest way would be to loop over time with something like this
v_wind_raster=raster(v_wind_file,zvar='vwnd',time=i)
and write these to another format, and then make a RasterStack.

But that's awful. I'll write memory-safer functions for netCDF
sometime this week (i.e. same functions and handling as for other
formats). This has been on the to-do list for a while, but you are the
first to (rightfully) complain.

Robert

On Mon, Jun 7, 2010 at 12:41 PM, Jonathan Greenberg
<greenberg at ucdavis.edu> wrote:
> r-sig-geo'ers:
>
> Next in my barrage of questions -- what would be a memory-safe way of
> dealing with netCDF files via raster()? ?I understand that raster
> loads the entire netCDF band/file into memory when using raster():
>
> u_wind_rasters=stack(u_wind_file,zvar='uwnd')
>
> or
>
> v_wind_raster=raster(v_wind_file,zvar='vwnd',time=1)
>
> where u_wind_file and v_wind_file are .nc files.
>
> Would it make sense to pre-convert these to something "safer"? ?Is
> there a memory-safe way of converting these to some multi-band image
> within R?
>
> --j
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From cheluna at gmail.com  Tue Jun  8 00:38:29 2010
From: cheluna at gmail.com (Consuelo Hermosilla)
Date: Tue, 8 Jun 2010 00:38:29 +0200
Subject: [R-sig-Geo] randtest.enfa {adehabitat}
In-Reply-To: <4C0CAEFD.6090403@gmail.com>
References: <AANLkTil0kDMR7-fU1q6W_2LmfxXZF0Pfa4kYjy2nguxm@mail.gmail.com> 
	<4C08A8C1.6020206@gmail.com>
	<AANLkTimRDvD7_pRN7XpgEPitMa4Uw_qvJbxeukp9ytqn@mail.gmail.com> 
	<4C0CAEFD.6090403@gmail.com>
Message-ID: <AANLkTilQVEvXngVkyXYUWejPrqm_yZO5CKjVxA-Kp0I2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100608/e5ea9dd9/attachment.pl>

From mdsumner at gmail.com  Tue Jun  8 02:31:53 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 8 Jun 2010 10:31:53 +1000
Subject: [R-sig-Geo] read function for LAS data
In-Reply-To: <4C0D02DF.9040405@gmail.com>
References: <AANLkTilysK_oh0qeGhpaBOrbFCAvhcA_HuTEeTdldain@mail.gmail.com>
	<4C095CE5.50409@wildintellect.com>
	<AANLkTilBFwiDCrWDLmxkgY2bEH8pJJJuqPwMRZtDDEGI@mail.gmail.com>
	<4C0B73C4.4070902@gmail.com>
	<AANLkTimX-SGULQb_2z9GjRVENdcTiPXIf4NRqYPvCYti@mail.gmail.com>
	<4C0D02DF.9040405@gmail.com>
Message-ID: <AANLkTimRhzAAuj_duXj2wMV1eGzMd4oO0xibpUhBM9jS@mail.gmail.com>

Thanks Etienne.

On Tue, Jun 8, 2010 at 12:31 AM, Etienne Bellemare Racine
<etiennebr at gmail.com> wrote:
> Michael,
>
> I have not gone through extensive testing, but it seems pretty fast and
> usefull for my 1.0 las. I've loaded a 235 Mb file on a USB drive, and it ran
> in ~20 seconds. SAGA, in comparison did it in 3 min 22 seconds.
>
> Cheers,
> Etienne
>
> Le 2010-06-06 10:18, Michael Sumner a ?crit?:
>
> Hello,
>
>
> To other issue I see here is that R is loading the whole file in memory, so
> if you can manage small files, that might not be that easy with (standard)
> larger ones. Don't you think ?
>
>
> That was certainly true of the version of code I posted, but writing a
> more flexible version is not difficult, and actually less difficult
> than I expected. I've implemented arguments to "skip" and read "nrows"
> at a time, so there is the beginnings of a wrapper around the core
> read for building more flexibility.
> (I was thinking of including subsetting of various kinds which really
> makes it more complicated, and the appropriate level to handle that is
> in a wrapper to this function).
> I've updated the R source on my site, and here's a new example. This
> should be considered as a rough working draft, the details can be
> hidden in the final suite of functions. My chunk/rows handling is
> pretty awkward, and may have bugs for particular record numbers.
> Any testing you can provide would be greatly appreciated.
> # new version with "skip" and "nrows" arguments
> source("http://staff.acecrc.org.au/~mdsumner/las/readLAS.R")
> f <- "lfile.las"
> ## get just the header
> hd <- readLAS(f, returnHeaderOnly = TRUE)
> numrows <- hd$`Number of point records`
> ## [1] 1922632
> ## read in chunks, and pass to DB or ff, or subset by sampling, etc..
> rowskip <- 0
> chunk <- 1e5
> rowsleft <- numrows
> system.time({
> ## keep track of how many rows we skip, and how many are left
> for (i in 1:ceiling(numrows / chunk)) {
> 	if (rowsleft < chunk) chunk <- rowsleft
> 	if (chunk < 1) break;
> 	d <- readLAS(f, skip = rowskip, nrows = chunk)
> 	rowskip <- rowskip + nn
> 	rowsleft <- numrows - nn
> }
> })
> #   user  system elapsed
> #   1.10    0.55    1.64
> On Sun, Jun 6, 2010 at 8:09 PM, Etienne Bellemare Racine
> <etiennebr at gmail.com> wrote:
>
>
> This is interesting, I'll try your code on my lidar files in the next few
> days.
> ?2010-06-04 22:36, Michael Sumner wrote :
>
>
> Thanks Alex, I will eventually post this to a broader audience.
> I've used liblas and lastools, but the aim here is for a pure R
> implementation that is built directly from the LAS specification
> without 3rd party tools.
>
>
> What might be of interest in using liblas is that it provides support for
> many las versions and they plan to provide support for some versions to come
> (conditional to funding) so having an R binding might be of interest here.
> They are also working on the integration of a spatial index which would
> allow easier handling of large files. I must say I don't know how hard
> writing a wrapper for R might be for that particular tool.
> To other issue I see here is that R is loading the whole file in memory, so
> if you can manage small files, that might not be that easy with (standard)
> larger ones. Don't you think ? Did you give a try to the R SAGA package.
> There is a module for loading las files but again, I don't know how it
> manages memory. I guess that it could be possible to use some sort of ff
> package to handle bigger files, but that's just on the top of my head.
> Etienne
>
>
> The R code already works quite well to extract x/y/z/time/intensity,
> it just needs some extra work to tidy up and generalize things and
> ensure that very big datasets can be read.
> Cheers, Mike.
> On Sat, Jun 5, 2010 at 6:07 AM, Alex Mandel<tech_dev at wildintellect.com>
> ?wrote:
>
>
> On 06/03/2010 07:54 PM, Michael Sumner wrote:
>
>
> Hello,
> I'm looking for interest in this functionality and eventually working
> it into a package.
> I don't actually use LAS data much, and only have one example file so
> I'm hoping others who do or know others who would be interested can
> help. I have previously posted this to r-spatial-devel.
>
>
> I think there are people who would use it. You might want to have a look
> at http://liblas.org/ (some of the same people that do gdal/org work)
> Wrapping this library might be a good approach. There are example files
> available too.
> Thanks,
> Alex
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From mdsumner at gmail.com  Tue Jun  8 02:41:31 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 8 Jun 2010 10:41:31 +1000
Subject: [R-sig-Geo] read function for LAS data
In-Reply-To: <D44CA39B-5DBE-4EC7-838B-C9AA39725239@gmail.com>
References: <AANLkTilysK_oh0qeGhpaBOrbFCAvhcA_HuTEeTdldain@mail.gmail.com>
	<4C095CE5.50409@wildintellect.com>
	<AANLkTilBFwiDCrWDLmxkgY2bEH8pJJJuqPwMRZtDDEGI@mail.gmail.com>
	<4C0B73C4.4070902@gmail.com>
	<D44CA39B-5DBE-4EC7-838B-C9AA39725239@gmail.com>
Message-ID: <AANLkTimYTXs8poe52aEVzfTjIaezQq-uy9bV7W3ajiG3@mail.gmail.com>

Thanks Howard, do you know of people working with LAS data in R, or
any efforts to link to liblas? I'd be keen to get involved eventually,
but it's not an area I have particular strengths. I've noticed the "R"
data format driver in GDAL (for reading/writing simple arrays in R's
save() format), so there must be some in that community using R in a
fairly intimate way.

BTW, I don't want this example to be seen as some kind of snub to the
efforts of projects like liblas, I'm really interested in the fact
that it *can* be done - not necessarily pushing that it should be
done. The impetus here was really my interest in alternative methods,
not just avoiding dependencies.

Tools like this can be helpful for basic data rescue when a full
solution is not at hand. There are endless varieties of raw binary
formats out there and very few have a commited team like liblas or
GDAL working to help.

Cheers, Mike.

On Tue, Jun 8, 2010 at 6:17 AM, Howard Butler <hobu.inc at gmail.com> wrote:
>
> On Jun 6, 2010, at 5:09 AM, Etienne Bellemare Racine wrote:
>
>> This is interesting, I'll try your code on my lidar files in the next few days.
>>
>> 2010-06-04 22:36, Michael Sumner wrote :
>>> Thanks Alex, I will eventually post this to a broader audience.
>>>
>>> I've used liblas and lastools, but the aim here is for a pure R
>>> implementation that is built directly from the LAS specification
>>> without 3rd party tools.
>>>
>>
>> What might be of interest in using liblas is that it provides support for many las versions and they plan to provide support for some versions to come (conditional to funding) so having an R binding might be of interest here. They are also working on the integration of a spatial index which would allow easier handling of large files. I must say I don't know how hard writing a wrapper for R might be for that particular tool.
>
> and controllable point caching, reprojection on the fly (when linked w/ GDAL), coordinate system description, and LAS 1.0-1.3 (no waveform for 1.3 though) support. ?I would note that contrary to what the LAS specification says, there are many softwares out in the wild that don't write LAS files properly. ?This causes big hassles, but it's libLAS' job to ensure that it can read everything, so we bend over backwards to ensure things work while doing our best to write valid files.
>
> I maintain an LAS sample library at http://liblas.org/samples . ?They vary based on format types and the softwares that wrote them as this is what is most interesting to libLAS. ?They are free for non-commercial usages.
>
> I understand the desire to not have external dependencies, which is the impetus for efforts like this. ?It is unfortunate that distribution and platform issues make duplication of efforts like these economical in the short term.
>
> Howard
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From tsippel at gmail.com  Tue Jun  8 03:09:52 2010
From: tsippel at gmail.com (tsippel)
Date: Mon, 7 Jun 2010 15:09:52 -1000
Subject: [R-sig-Geo] install rgdal error on Ubuntu 10.04 (lucid)
Message-ID: <AANLkTikdGct3vNRwN1oKJsMsLoW0jVIBgnQpR_IBfJFV@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100607/4cc4cbb8/attachment.pl>

From mdsumner at gmail.com  Tue Jun  8 03:21:21 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 8 Jun 2010 11:21:21 +1000
Subject: [R-sig-Geo] install rgdal error on Ubuntu 10.04 (lucid)
In-Reply-To: <AANLkTikdGct3vNRwN1oKJsMsLoW0jVIBgnQpR_IBfJFV@mail.gmail.com>
References: <AANLkTikdGct3vNRwN1oKJsMsLoW0jVIBgnQpR_IBfJFV@mail.gmail.com>
Message-ID: <AANLkTimLho6l-qkgGBVgRcK3Sf22xDKVXGdpUEnqnZPg@mail.gmail.com>

Hi Tim,

Presumably you don't have GDAL installed - which you need for rgdal to
build from source on Linux.

(On Windows the binary rgdal comes packaged with all the required
dependencies, because of substantial efforts by the rgdal and R
maintainers. )

There is a readme in the source package for rgdal in rgdal\inst\README

Cheers, Mike.



On Tue, Jun 8, 2010 at 11:09 AM, tsippel <tsippel at gmail.com> wrote:
> Hi-
> I've just switched from Windows to Linux, and am encountering a problem with
> installing rgdal in R.
>
>> install.packages('rgdal')
> Warning in install.packages("rgdal") :
> ?argument 'lib' is missing: using
> '/home/au/R/x86_64-pc-linux-gnu-library/2.10'
> --- Please select a CRAN mirror for use in this session ---
> Loading Tcl/Tk interface ... done
> trying URL 'http://cran.stat.ucla.edu/src/contrib/rgdal_0.6-27.tar.gz'
> Content type 'application/x-tar' length 1417523 bytes (1.4 Mb)
> opened URL
> ==================================================
> downloaded 1.4 Mb
>
> * installing *source* package ?rgdal? ...
> gdal-config: gdal-config
> ./configure: line 1311: gdal-config: command not found
> Error: gdal-config not found
> The gdal-config script distributed with GDAL could not be found.
> If you have not installed the GDAL libraries, you can
> download the source from ?http://www.gdal.org/
> If you have installed the GDAL libraries, then make sure that
> gdal-config is in your path. Try typing gdal-config at a
> shell prompt and see if it runs. If not, use:
> ?--configure-args='--with-gdal-config=/usr/local/bin/gdal-config' echo with
> appropriate values for your installation.
>
> ERROR: configuration failed for package ?rgdal?
> * removing ?/home/au/R/x86_64-pc-linux-gnu-library/2.10/rgdal?
>
> The downloaded packages are in
> ?/tmp/RtmprMw6kD/downloaded_packages?
> Warning message:
> In install.packages("rgdal") :
> ?installation of package 'rgdal' had non-zero exit status
>
> My sessionInfo is:
>
>> sessionInfo()
> R version 2.10.1 (2009-12-14)
> x86_64-pc-linux-gnu
>
> locale:
> ?[1] LC_CTYPE=en_US.utf8 ? ? ? LC_NUMERIC=C
> ?[3] LC_TIME=en_US.utf8 ? ? ? ?LC_COLLATE=en_US.utf8
> ?[5] LC_MONETARY=C ? ? ? ? ? ? LC_MESSAGES=en_US.utf8
> ?[7] LC_PAPER=en_US.utf8 ? ? ? LC_NAME=C
> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ?LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> loaded via a namespace (and not attached):
> [1] tcltk_2.10.1 tools_2.10.1
>
> Any advice on this would be appreciated.
>
> Thanks,
>
> Tim
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From hobu.inc at gmail.com  Tue Jun  8 03:51:08 2010
From: hobu.inc at gmail.com (Howard Butler)
Date: Mon, 7 Jun 2010 20:51:08 -0500
Subject: [R-sig-Geo] read function for LAS data
In-Reply-To: <AANLkTimYTXs8poe52aEVzfTjIaezQq-uy9bV7W3ajiG3@mail.gmail.com>
References: <AANLkTilysK_oh0qeGhpaBOrbFCAvhcA_HuTEeTdldain@mail.gmail.com>
	<4C095CE5.50409@wildintellect.com>
	<AANLkTilBFwiDCrWDLmxkgY2bEH8pJJJuqPwMRZtDDEGI@mail.gmail.com>
	<4C0B73C4.4070902@gmail.com>
	<D44CA39B-5DBE-4EC7-838B-C9AA39725239@gmail.com>
	<AANLkTimYTXs8poe52aEVzfTjIaezQq-uy9bV7W3ajiG3@mail.gmail.com>
Message-ID: <427855EC-9CE3-422F-A0D8-A356360212C5@gmail.com>


On Jun 7, 2010, at 7:41 PM, Michael Sumner wrote:
> 
> BTW, I don't want this example to be seen as some kind of snub to the
> efforts of projects like liblas, I'm really interested in the fact
> that it *can* be done - not necessarily pushing that it should be
> done. The impetus here was really my interest in alternative methods,
> not just avoiding dependencies.

I didn't take it as a snub, but rather I was firing back with a warning at how deep this LAS rabbit hole actually goes :)  After first reading the spec, I thought, "oh a nice simple binary format, I can write code for that."    It seems everyone else thought the same as well, and we all came back with different answers.  Over time, I hope the bigger vendors pick up libLAS internally (one or two large commercial vendors and a number of mid-level ones now use libLAS), so the variations in data start to go away.  I've given them every possible reason to take it up too -- BSD license, loads of features, multiple APIs, multiple platforms, not slow.  


From mdsumner at gmail.com  Tue Jun  8 03:57:50 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 8 Jun 2010 11:57:50 +1000
Subject: [R-sig-Geo] read function for LAS data
In-Reply-To: <427855EC-9CE3-422F-A0D8-A356360212C5@gmail.com>
References: <AANLkTilysK_oh0qeGhpaBOrbFCAvhcA_HuTEeTdldain@mail.gmail.com>
	<4C095CE5.50409@wildintellect.com>
	<AANLkTilBFwiDCrWDLmxkgY2bEH8pJJJuqPwMRZtDDEGI@mail.gmail.com>
	<4C0B73C4.4070902@gmail.com>
	<D44CA39B-5DBE-4EC7-838B-C9AA39725239@gmail.com>
	<AANLkTimYTXs8poe52aEVzfTjIaezQq-uy9bV7W3ajiG3@mail.gmail.com>
	<427855EC-9CE3-422F-A0D8-A356360212C5@gmail.com>
Message-ID: <AANLkTikb-tZekGz8CrUIZoXlKLVqUruYmWYfUPXO7d9t@mail.gmail.com>

Thanks Howard, I appreciate the perspective.

> "oh a nice simple binary format, I can write code for that."

Heh - yes indeed this is an attractive pit.

Cheers, Mike.

On Tue, Jun 8, 2010 at 11:51 AM, Howard Butler <hobu.inc at gmail.com> wrote:
>
> On Jun 7, 2010, at 7:41 PM, Michael Sumner wrote:
>>
>> BTW, I don't want this example to be seen as some kind of snub to the
>> efforts of projects like liblas, I'm really interested in the fact
>> that it *can* be done - not necessarily pushing that it should be
>> done. The impetus here was really my interest in alternative methods,
>> not just avoiding dependencies.
>
> I didn't take it as a snub, but rather I was firing back with a warning at how deep this LAS rabbit hole actually goes :) ?After first reading the spec, I thought, "oh a nice simple binary format, I can write code for that." ? ?It seems everyone else thought the same as well, and we all came back with different answers. ?Over time, I hope the bigger vendors pick up libLAS internally (one or two large commercial vendors and a number of mid-level ones now use libLAS), so the variations in data start to go away. ?I've given them every possible reason to take it up too -- BSD license, loads of features, multiple APIs, multiple platforms, not slow.
>
>


From tsippel at gmail.com  Tue Jun  8 04:57:10 2010
From: tsippel at gmail.com (tsippel)
Date: Mon, 7 Jun 2010 16:57:10 -1000
Subject: [R-sig-Geo] install rgdal error on Ubuntu 10.04 (lucid)
In-Reply-To: <AANLkTimLho6l-qkgGBVgRcK3Sf22xDKVXGdpUEnqnZPg@mail.gmail.com>
References: <AANLkTikdGct3vNRwN1oKJsMsLoW0jVIBgnQpR_IBfJFV@mail.gmail.com>
	<AANLkTimLho6l-qkgGBVgRcK3Sf22xDKVXGdpUEnqnZPg@mail.gmail.com>
Message-ID: <AANLkTinUQusYkjkJqtBn-s9P_jFKkexL4Jr933Yrlz86@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100607/6565b07f/attachment.pl>

From tsippel at gmail.com  Tue Jun  8 08:11:42 2010
From: tsippel at gmail.com (tsippel)
Date: Mon, 7 Jun 2010 20:11:42 -1000
Subject: [R-sig-Geo] install rgdal error on Ubuntu 10.04 (lucid)
In-Reply-To: <AANLkTinUQusYkjkJqtBn-s9P_jFKkexL4Jr933Yrlz86@mail.gmail.com>
References: <AANLkTikdGct3vNRwN1oKJsMsLoW0jVIBgnQpR_IBfJFV@mail.gmail.com>
	<AANLkTimLho6l-qkgGBVgRcK3Sf22xDKVXGdpUEnqnZPg@mail.gmail.com>
	<AANLkTinUQusYkjkJqtBn-s9P_jFKkexL4Jr933Yrlz86@mail.gmail.com>
Message-ID: <AANLkTinD-llKzzSS1fZ0VKqzFeTaMSRrcj-uWZA4Etv6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100607/6f1e5cd4/attachment.pl>

From johan.vandewauw at gmail.com  Tue Jun  8 09:01:35 2010
From: johan.vandewauw at gmail.com (Johan Van de Wauw)
Date: Tue, 8 Jun 2010 09:01:35 +0200
Subject: [R-sig-Geo] install rgdal error on Ubuntu 10.04 (lucid)
In-Reply-To: <AANLkTinD-llKzzSS1fZ0VKqzFeTaMSRrcj-uWZA4Etv6@mail.gmail.com>
References: <AANLkTikdGct3vNRwN1oKJsMsLoW0jVIBgnQpR_IBfJFV@mail.gmail.com> 
	<AANLkTimLho6l-qkgGBVgRcK3Sf22xDKVXGdpUEnqnZPg@mail.gmail.com> 
	<AANLkTinUQusYkjkJqtBn-s9P_jFKkexL4Jr933Yrlz86@mail.gmail.com> 
	<AANLkTinD-llKzzSS1fZ0VKqzFeTaMSRrcj-uWZA4Etv6@mail.gmail.com>
Message-ID: <AANLkTilCccCiCe5COMJth-gphA1UMO_vXG6cARRXDXIQ@mail.gmail.com>

For reference:
Instead of compiling gdal yourself you can also install this package
in debian/ubuntu:
libgdal1-dev

Johan

On Tue, Jun 8, 2010 at 8:11 AM, tsippel <tsippel at gmail.com> wrote:
> Sorry, looks like I failed to include the link. ?Here it is:
>
> http://www.xastir.org/wiki/HowTo:Ubuntu_10.04
>
> <http://www.xastir.org/wiki/HowTo:Ubuntu_10.04>
>
> On Mon, Jun 7, 2010 at 4:57 PM, tsippel <tsippel at gmail.com> wrote:
>
>> Thanks Mike-
>> Installing gdal seems to have done the trick as you say. ?Thins link was
>> helpful in building gdal (and proj4) for my Ubuntu 10.04 (Lucid) system.
>> Best regards,
>> Tim
>>
>>
>> On Mon, Jun 7, 2010 at 3:21 PM, Michael Sumner <mdsumner at gmail.com> wrote:
>>
>>> Hi Tim,
>>>
>>> Presumably you don't have GDAL installed - which you need for rgdal to
>>> build from source on Linux.
>>>
>>> (On Windows the binary rgdal comes packaged with all the required
>>> dependencies, because of substantial efforts by the rgdal and R
>>> maintainers. )
>>>
>>> There is a readme in the source package for rgdal in rgdal\inst\README
>>>
>>> Cheers, Mike.
>>>
>>>
>>>
>>> On Tue, Jun 8, 2010 at 11:09 AM, tsippel <tsippel at gmail.com> wrote:
>>> > Hi-
>>> > I've just switched from Windows to Linux, and am encountering a problem
>>> with
>>> > installing rgdal in R.
>>> >
>>> >> install.packages('rgdal')
>>> > Warning in install.packages("rgdal") :
>>> > ?argument 'lib' is missing: using
>>> > '/home/au/R/x86_64-pc-linux-gnu-library/2.10'
>>> > --- Please select a CRAN mirror for use in this session ---
>>> > Loading Tcl/Tk interface ... done
>>> > trying URL 'http://cran.stat.ucla.edu/src/contrib/rgdal_0.6-27.tar.gz'
>>> > Content type 'application/x-tar' length 1417523 bytes (1.4 Mb)
>>> > opened URL
>>> > ==================================================
>>> > downloaded 1.4 Mb
>>> >
>>> > * installing *source* package ?rgdal? ...
>>> > gdal-config: gdal-config
>>> > ./configure: line 1311: gdal-config: command not found
>>> > Error: gdal-config not found
>>> > The gdal-config script distributed with GDAL could not be found.
>>> > If you have not installed the GDAL libraries, you can
>>> > download the source from ?http://www.gdal.org/
>>> > If you have installed the GDAL libraries, then make sure that
>>> > gdal-config is in your path. Try typing gdal-config at a
>>> > shell prompt and see if it runs. If not, use:
>>> > ?--configure-args='--with-gdal-config=/usr/local/bin/gdal-config' echo
>>> with
>>> > appropriate values for your installation.
>>> >
>>> > ERROR: configuration failed for package ?rgdal?
>>> > * removing ?/home/au/R/x86_64-pc-linux-gnu-library/2.10/rgdal?
>>> >
>>> > The downloaded packages are in
>>> > ?/tmp/RtmprMw6kD/downloaded_packages?
>>> > Warning message:
>>> > In install.packages("rgdal") :
>>> > ?installation of package 'rgdal' had non-zero exit status
>>> >
>>> > My sessionInfo is:
>>> >
>>> >> sessionInfo()
>>> > R version 2.10.1 (2009-12-14)
>>> > x86_64-pc-linux-gnu
>>> >
>>> > locale:
>>> > ?[1] LC_CTYPE=en_US.utf8 ? ? ? LC_NUMERIC=C
>>> > ?[3] LC_TIME=en_US.utf8 ? ? ? ?LC_COLLATE=en_US.utf8
>>> > ?[5] LC_MONETARY=C ? ? ? ? ? ? LC_MESSAGES=en_US.utf8
>>> > ?[7] LC_PAPER=en_US.utf8 ? ? ? LC_NAME=C
>>> > ?[9] LC_ADDRESS=C ? ? ? ? ? ? ?LC_TELEPHONE=C
>>> > [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>>> >
>>> > attached base packages:
>>> > [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>> >
>>> > loaded via a namespace (and not attached):
>>> > [1] tcltk_2.10.1 tools_2.10.1
>>> >
>>> > Any advice on this would be appreciated.
>>> >
>>> > Thanks,
>>> >
>>> > Tim
>>> >
>>> > ? ? ? ?[[alternative HTML version deleted]]
>>> >
>>> >
>>> > _______________________________________________
>>> > R-sig-Geo mailing list
>>> > R-sig-Geo at stat.math.ethz.ch
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> >
>>> >
>>>
>>
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From hamid200356 at yahoo.com  Tue Jun  8 10:18:37 2010
From: hamid200356 at yahoo.com (Hamid)
Date: Tue, 8 Jun 2010 01:18:37 -0700 (PDT)
Subject: [R-sig-Geo] test for CSR
Message-ID: <193257.23838.qm@web63803.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100608/e99f72af/attachment.pl>

From Adrian.Baddeley at csiro.au  Tue Jun  8 12:37:00 2010
From: Adrian.Baddeley at csiro.au (Adrian.Baddeley at csiro.au)
Date: Tue, 8 Jun 2010 18:37:00 +0800
Subject: [R-sig-Geo]  test for CSR
Message-ID: <57DC18C299094D4299F837570C5DF1C52B19D4CC83@EXWA-MBX01.nexus.csiro.au>

Hamid <hamid200356 at yahoo.com> writes:

> I use the following function to simulate CSR point pattern nsim times.

This is a question about the package 'spatstat'.

> Is there a way to reduce running time (maybe by avoiding the loop)?

> bakhti<-function(nsim) {
>     n<-c(10,20,25,30,40,50,100,200,300)
> #n is the number of points in unit square

Actually n gives the *expected* number of points in the unit *cube*

> #nsim is the number of simulation
> for ( j in 1:length(n))
> Xsim<- vector("list",nsim)
> for(i in 1: nsim)
> {   Xsim[[i]] <- rpoispp3(n[j]) }
> ksim  <- sapply(Xsim, function(x) K3est(x, rmax=1,nrval=101)$iso)
> }
> return(ksim)
> }

Since you are only using the 'iso' estimate from K3est, you can halve the computation time in this step by calling
      K3est(x, correction="isotropic", rmax=1,nrval=101)$iso
to avoid calculating the translation correction as well. 

The loop will use a lot of memory, which will slow things down. It saves all the simulated point patterns Xsim[[i]] and these are not subsequently used except to calculate the K function. Also there is a lot of 'internal state' that is saved in the double loop. So it would be better to write as follows.

runone <- function(lambda, nsim) {
    kmat <- NULL
    for(i in 1: nsim) {
        progressreport(i, nsim)
        Xsim <- rpoispp3(lambda)
        ksim <- K3est(Xsim, correction="isotropic", rmax=1,nrval=101)$iso
        kmat <- cbind(kmat, ksim)
    }
    return(kmat)
}

Then 

lambdas <- c(10,20,25,30,40,50,100,200,300)
kout <- lapply(lambdas, runone, nsim=20000)

The result is a list of matrices, where each matrix represents the simulated K values for a particular intensity, and each matrix has one column for each simulated outcome. This might be useful to compute means and variances etc.

> I need huge number of simulation, let say, nsim=20000, which
> yields very long running time (in hours scale!!). 

Hours or days? If it is hours, I don't think it is so unreasonable, since you are trying to compute 9 * 20000 = 180000 simulated 3D point patterns and compute their K-functions. At one realisation every 0.1 second, that would take 0.1 * 180000/3600 = 5 hours. 

To reduce the computation time further, you could use the translation-corrected estimate (correction='translation') instead of the isotropic correction.

The call to 'progressreport' will show you whether the computations are getting slower as the loop index i increases. If this happens, it usually indicates a memory leak in the loop. 

----

Prof Adrian Baddeley (UWA/CSIRO)
CSIRO Mathematics, Informatics & Statistics
Leeuwin Centre, 65 Brockway Road, Floreat WA 6014, Australia
Tel: 08 9333 6177 | Fax: 08 9333 6121 | Mob: 0410 447 821


From Jan.Quets at ua.ac.be  Tue Jun  8 15:55:40 2010
From: Jan.Quets at ua.ac.be (Quets Jan)
Date: Tue, 8 Jun 2010 15:55:40 +0200
Subject: [R-sig-Geo] alltypes & envelopes
Message-ID: <7D403BF1018E6D4882ADD0F77E35BC5C15957A@xmail06.ad.ua.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100608/89ab9dea/attachment.pl>

From basille at ase-research.org  Tue Jun  8 20:09:53 2010
From: basille at ase-research.org (Mathieu Basille)
Date: Tue, 08 Jun 2010 14:09:53 -0400
Subject: [R-sig-Geo] randtest.enfa {adehabitat}
In-Reply-To: <AANLkTilQVEvXngVkyXYUWejPrqm_yZO5CKjVxA-Kp0I2@mail.gmail.com>
References: <AANLkTil0kDMR7-fU1q6W_2LmfxXZF0Pfa4kYjy2nguxm@mail.gmail.com>
	<4C08A8C1.6020206@gmail.com>	<AANLkTimRDvD7_pRN7XpgEPitMa4Uw_qvJbxeukp9ytqn@mail.gmail.com>
	<4C0CAEFD.6090403@gmail.com>
	<AANLkTilQVEvXngVkyXYUWejPrqm_yZO5CKjVxA-Kp0I2@mail.gmail.com>
Message-ID: <4C0E8771.6040809@ase-research.org>

Consuelo,

Here are some elements that you might find useful.

> I had already read the paper. I understood the idea of the scatter plot,
> that the arrows were a projection of the marginality and specialization but
> I didn't understand where the length of arrows came from. I was somehow lost
> thinking how their length represent the marginality and specialization. Now
> you tell me that they "correspond to the scores of the environmental
> variables on the axes of the ENFA". Hmmm.... Are these scores given
> somewhere in the output of enfa?

Yes they are. Look at the $co element of the enfa object. Following the 
example in ?enfa:

 > enfa1$co
               Mar        Spe1
forets  0.7178829  0.29304902
hydro   0.0977121 -0.94018385
routes -0.5394778  0.15001749
artif   0.4290224 -0.08758622

It gives you the coordinates of the arrow. The starting point of the 
vector is the average availability which is centred on zero.

> You see, the main issue for me is that if I put that graph in a manuscript,
> I'd like to be able to tell, the arrow length represent XX times the
> marginality and XX times the specialization of each variable or something
> like that. In order to give an idea of the real value of marginality and
> specialization. Does it make any sense? Maybe it doesn't make any sense and
> it's not necessary, what do you think? I hope you understand me this time...
> otherwise, I'll give up!!!

You should interpret the scatter plot qualitatively. E.g. in the example 
of ?enfa, the marginality is very strong on "forets" (forest) with a 
shift towards high values, on "routes" (roads) with a shift on low 
values, and to a lesser extent on "artif" (artificial areas) with a 
shift on high values. On the other hand, the specialization is very 
pronounced on "hydro" only, with a restriction around the mean (you have 
to look at the specific distributions on this particular variable to say 
more about it).

> Regarding the global specialization issue. Not sure about something again.
> You told me that there's not global specialization, but Hirzel et al (2002),
> described it. Why you say "it cannot be measured globally over the
> ecological space"? Is it wrong if I use the global specialization formula of
> Hirzel et al (square root of the sum of the eigeinvalues divided by the
> number of variables) to estimate this global specialization (sensu Hirzel et
> al)? Can I do that?

You can indeed compute such an index. But now, how would you interpret 
it? The only case it could be useful is the comparison of two niches in 
the same environment, i.e. same availability. Two study sites cannot be 
compared on such basis. So that it would give you an idea of a global 
specialization that is totally context dependent. This is why it is not, 
from my point of view, very useful.

> And regarding the tolerance, just to be sure we're talking about the same,
> is it the inverse of the specialization, right? if I calculate it, could I
> use it to estimate the specialization? Actually, I have tried to calculate
> the tolerance, but I think I have used the wrong "wei". Can you please
> confirm I'm using the correct terms?

It is conceptually the inverse of the specialization: the specialization 
is a ratio of variances (available over used) while the tolerance is the 
sum of used variances over all variables (which is similar to divide it 
by an available variance of 1). You might have a look at ?niche.test for 
a global measure of tolerance.

> You told me to use this formula: sum(dudi.pca(tab, row.w=wei,
> scan=FALSE)$eig); in which "tab" is the dataframe containing the values of
> environmental variables and "wei" is vector describing the utilization
> weight of each pixel. Using the manual example for enfa:
> 
> data(lynxjura)
> map <- lynxjura$map
> tmp <- lynxjura$locs[,4]!="D"
> locs <- lynxjura$locs[tmp, c("X","Y")]
> dataenfa1 <- data2enfa(map, locs)
> enfa1 <- enfa(pc, dataenfa1$pr,+ scannf = FALSE)
> 
> For me, in this case, "tab" would be kasc2df(map)  and "wei" would be
> dataenfa1$pr
> so, the tolerance would be: sum(dudi.pca(kasc2df(map), row.w=dataenfa1$pr,
> scan=FALSE)$eig)
> Is this correct? I got this huge value (2355). It's kind of high, isn't it?

Maybe try:

sum(dudi.pca(kasc2df(map), row.w = dataenfa1$pr/sum(dataenfa1$pr), 
scan=FALSE)$eig)

which gives you 5 only. The weights should sum to 1 (i.e. they are 
proportions). But then, how would you interpret this? This is the same 
as for the "global specialization".

> And about the specialization axis you keep in enfa (or madifa or gnesfa or
> any other one of these analysis), is there a way to get the % variation
> explained by each eigenvalue? I mean, a referee can ask that, right? I have
> tried to figure it out, but without any luck... I have chosen only one
> eigenvalue of specialization, but I wasn't able to calculate how much
> variation it accounted for.

There is no way to give a percentage of variation for a specialization 
axis, by nature: the eigenvalue of each axis gives you a ratio of 
variance. E.g. an eigenvalue of 12 tells you that the available variance 
on this axis is 12 times higher than the used variance. It is up to you 
to interpret this (is it a strong specialization or not).

> I hope you don't mind all these question... I need to be sure of what I'm
> doing if I want to publish these results...

No problem about it. The ENFA, however, should be seen as a very elegant 
way of exploring the data, at the manner of a PCA (and the 
interpretation is in many ways similar, when you take into account the 
specificity of the analysis).

Hope this helps a bit,
Mathieu.


> Thanks!!!
> 
> Consuelo
> 
> -------------
> Consuelo Hermosilla
> PhD student
> Departamento de Ecolog?a y Biolog?a Animal
> Departamento de Bioqu?mica, Gen?tica e Inmunolog?a, ?rea de Gen?tica
> Facultad de Ciencias del Mar
> Campus de As Lagoas-Marcosende
> Universidad de Vigo
> 36310 Vigo
> SPAIN
> Mobile: +34 692 633 298
> 
> oooO
> (     ) Oooo
>    (   (     )
>   _)    )  /
>         (_/
> 
> Stop Gaza Massacre
> 
> 
> 2010/6/7 Cl?ment Calenge <clement.calenge at gmail.com>
> 
>>  On 06/04/2010 09:40 AM, Consuelo Hermosilla wrote:
>>
>> Hummm, true, I got confused! Sorry!! I meant scatter.enfa.
>> What I don't understand is the length of the arrows. The grid is d=2,
>> different from the grid set with the biplot of marginality and
>> specialization (d=0.5). In that case, the length make senses to me, but I
>> don't understand it in the scatter.enfa. They don't have the same lenght
>> /value as they have in the biplot. Do you understand me?
>>
>>
>> I do not understand you... The function scatter.enfa draws the biplot
>> associated with the results of the ENFA. The following paper explains this
>> graph in detail:
>>
>> Basille, M., Calenge, C., Marboutin, E., Andersen, R. and Gaillard, J.M.
>> 2008. Assessing habitat selection using multivariate statistics: some
>> refinements of the ecological niche factor analysis. Ecol. model. 211:
>> 233--240.
>>
>>
>>
> 
>> I am not sure what you mean by "biplot of marginality and specialization".
>> There is only one way to draw a biplot with the ENFA: it is provided by
>> scatter.enfa (see the paper cited above). So I do not understand how the
>> result of scatter.enfa could be inconsistent with the biplot, since the
>> result of scatter.enfa *is* the biplot.
>> Best,
>>
>>
>> Cl?ment Calenge
>>
>> --
>> Cl?ment CALENGE
>> Cellule d'appui ? l'analyse de donn?es
>> Office national de la chasse et de la faune sauvage
>> Saint Benoist - 78610 Auffargis
>> tel. (33) 01.30.46.54.14
>>
>>
>>
>>
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 

~$ whoami
Mathieu Basille, Post-Doc

~$ locate
Laboratoire d'?cologie Comportementale et de Conservation de la Faune
+ Centre d'?tude de la For?t
D?partement de Biologie
Universit? Laval, Qu?bec

~$ info
http://ase-research.org/basille

~$ fortune
``If you can't win by reason, go for volume.''
Calvin, by Bill Watterson.


From spluque at gmail.com  Wed Jun  9 01:26:23 2010
From: spluque at gmail.com (Sebastian P. Luque)
Date: Tue, 08 Jun 2010 18:26:23 -0500
Subject: [R-sig-Geo] plotting Polygon (sp)
Message-ID: <87hbld2jj4.fsf@kolob.sebmags.homelinux.org>

Hi,

Using the example from the vignette "sp" (section 7.1):

---<--------------------cut here---------------start------------------->---
R> sr1
An object of class "Polygon"
Slot "labpt":
[1] 2.697 3.545

Slot "area":
[1] 5.5

Slot "hole":
[1] TRUE

Slot "ringDir":
[1] -1

Slot "coords":
     [,1] [,2]
[1,]    2    2
[2,]    4    3
[3,]    4    5
[4,]    1    4
[5,]    2    2

R> plot(sr1)
Error in as.double(y) : 
  cannot coerce type 'S4' to vector of type 'double'
R> showMethods("plot")
Function: plot (package graphics)
x="ANY", y="ANY"
x="Polygon", y="missing"
    (inherited from: x="ANY", y="ANY")
x="SpatialLines", y="missing"
x="Spatial", y="missing"
x="SpatialPoints", y="missing"
x="SpatialPolygons", y="missing"

R> sessionInfo()
R version 2.11.1 (2010-05-31) 
x86_64-pc-linux-gnu 

locale:
 [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C               LC_TIME=en_CA.UTF-8       
 [4] LC_COLLATE=en_CA.UTF-8     LC_MONETARY=C              LC_MESSAGES=en_CA.UTF-8   
 [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C                  LC_ADDRESS=C              
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] rgdal_0.6-27    maptools_0.7-34 foreign_0.8-40  mapdata_2.1-2   maps_2.1-3     
[6] sp_0.9-64       slmisc_0.7.6    lattice_0.18-8 

loaded via a namespace (and not attached):
[1] grid_2.11.1  tools_2.11.1
---<--------------------cut here---------------end--------------------->---

Why is plot() failing with that error?


Cheers,

-- 
Seb


From clement.calenge at gmail.com  Wed Jun  9 09:05:54 2010
From: clement.calenge at gmail.com (=?ISO-8859-1?Q?Cl=E9ment_Calenge?=)
Date: Wed, 09 Jun 2010 09:05:54 +0200
Subject: [R-sig-Geo] randtest.enfa {adehabitat}
In-Reply-To: <4C0E8771.6040809@ase-research.org>
References: <AANLkTil0kDMR7-fU1q6W_2LmfxXZF0Pfa4kYjy2nguxm@mail.gmail.com>
	<4C08A8C1.6020206@gmail.com>	<AANLkTimRDvD7_pRN7XpgEPitMa4Uw_qvJbxeukp9ytqn@mail.gmail.com>
	<4C0CAEFD.6090403@gmail.com>
	<AANLkTilQVEvXngVkyXYUWejPrqm_yZO5CKjVxA-Kp0I2@mail.gmail.com>
	<4C0E8771.6040809@ase-research.org>
Message-ID: <4C0F3D52.9010002@gmail.com>


>
> sum(dudi.pca(kasc2df(map), row.w = dataenfa1$pr/sum(dataenfa1$pr),
> scan=FALSE)$eig)
>
> which gives you 5 only. The weights should sum to 1 (i.e. they are
> proportions). But then, how would you interpret this? This is the same
> as for the "global specialization".

Yes, but be careful: kasc2df returns a list with one component "tab" 
(the component of interest) and one component "index" (the component 
allowing to rebuild the original kasc), so that the correct code is:

sum(dudi.pca(kasc2df(map)$tab, row.w = dataenfa1$pr/sum(dataenfa1$pr), 
scan=FALSE)$eig)


Best,

Cl?ment Calenge


From clement.calenge at gmail.com  Wed Jun  9 11:16:09 2010
From: clement.calenge at gmail.com (=?ISO-8859-1?Q?Cl=E9ment_Calenge?=)
Date: Wed, 09 Jun 2010 11:16:09 +0200
Subject: [R-sig-Geo] randtest.enfa {adehabitat} -- erratum in
 calculating the tolerance
In-Reply-To: <4C0F3D52.9010002@gmail.com>
References: <AANLkTil0kDMR7-fU1q6W_2LmfxXZF0Pfa4kYjy2nguxm@mail.gmail.com>	<4C08A8C1.6020206@gmail.com>	<AANLkTimRDvD7_pRN7XpgEPitMa4Uw_qvJbxeukp9ytqn@mail.gmail.com>	<4C0CAEFD.6090403@gmail.com>	<AANLkTilQVEvXngVkyXYUWejPrqm_yZO5CKjVxA-Kp0I2@mail.gmail.com>	<4C0E8771.6040809@ase-research.org>
	<4C0F3D52.9010002@gmail.com>
Message-ID: <4C0F5BD9.1090407@gmail.com>

On 06/09/2010 09:05 AM, Cl?ment Calenge wrote:
>
>>
>> sum(dudi.pca(kasc2df(map), row.w = dataenfa1$pr/sum(dataenfa1$pr),
>> scan=FALSE)$eig)
>>
>> which gives you 5 only. The weights should sum to 1 (i.e. they are
>> proportions). But then, how would you interpret this? This is the same
>> as for the "global specialization".
>
> Yes, but be careful: kasc2df returns a list with one component "tab" 
> (the component of interest) and one component "index" (the component 
> allowing to rebuild the original kasc), so that the correct code is:
>
> sum(dudi.pca(kasc2df(map)$tab, row.w = dataenfa1$pr/sum(dataenfa1$pr), 
> scan=FALSE)$eig)

I was a bit too hasty for this reply. Actually the code is incorrect. 
Consider the following code:

pc <- dudi.pca(kasc2df(map)$tab, row.w = dataenfa1$pr/sum(dataenfa1$pr))

This code performs a *centered and scaled* PCA of the environmental 
variables: this analysis first centers and scales the table containing 
the value of the environmental variables. Therefore, for each variable 
of pc$tab, the mean *weighted by the utilization weights* is equal to 
zero and the variance *weighted by the utilization weights* is equal to 
1. Therefore, the sum of the eigenvalues of the PCA on this transformed 
table is equal to the number of environmental variables. This code is 
incorrect (thanks Mathieu for noting the inconsistency). First, to 
calculate the global tolerance, you would need to calculate:

pc <- dudi.pca(kasc2df(map)$tab, scan=FALSE)

This preliminary analysis is performed just to center/scale the 
variables with uniform weighting. This allows to compare the different 
variables in pc$tab (they all have the same average and the same scale). 
*Then*, calculate the weighted and *unscaled* PCA of the table pc$tab:

sum(dudi.pca(pc$tab, scale=FALSE, row.w = 
dataenfa1$pr/sum(dataenfa1$pr), scan=FALSE)$eig)

This gives the tolerance of the species on the area,
Sorry for the confusion,
HTH,

Cl?ment Calenge

-- 
Cl?ment CALENGE
Cellule d'appui ? l'analyse de donn?es
Office national de la chasse et de la faune sauvage
Saint Benoist - 78610 Auffargis
tel. (33) 01.30.46.54.14


From Adrian.Baddeley at csiro.au  Wed Jun  9 12:22:11 2010
From: Adrian.Baddeley at csiro.au (Adrian.Baddeley at csiro.au)
Date: Wed, 9 Jun 2010 18:22:11 +0800
Subject: [R-sig-Geo] alltypes & envelopes
In-Reply-To: <mailman.13.1276077604.32447.r-sig-geo@stat.math.ethz.ch>
References: <mailman.13.1276077604.32447.r-sig-geo@stat.math.ethz.ch>
Message-ID: <57DC18C299094D4299F837570C5DF1C52B19D4CC87@EXWA-MBX01.nexus.csiro.au>

Thus spake Jan Quets <Jan.Quets at ua.ac.be>:

> with "envelope" it is possible to generate a summary statistic (e.g. G-function) 
> of a given unitype point pattern, together with a monte-carlo-envelope of a 
> null-model.

Again this is a question about the package 'spatstat'.

> with "envelope" it is also possible to save the monte-carlo-generated patterns 
> of a null-model by setting the argument "savepatterns=TRUE"

> with "alltypes" it is possible to generate a summary statistic (e.g. n x n G-functions) > of a given n-multitype point pattern, together with monte-carlo-envelopes 
> of a CSR-model.

> But is it also possible with "alltypes" to generate monte-carlo-envelopes of 
> a non-CSR-null-model, for instance by setting simulate as an argument in "alltypes" 
> equal to an expression which generates a n-multitype null model pattern, 
> "nsim" times, like is the case with "envelope"?

Yes. 
According to help(alltypes), any additional arguments ("...") are passed to envelope(). 
 e.g.

    data(amacrine)
    z <- alltypes(amacrine, Gcross, envelope=TRUE, simulate=expression(rlabel(amacrine)))
    plot(z)

Since 'simulate' is not the name of any formal argument of 'alltypes', the argument 'simulate' is passed through to envelope(). That means each call to envelope() is executed with the argument simulate=expression(rlabel(amacrine)). 

Note that 'simulate' is an expression that is evaluated if we want to generate ONE simulated realisation. It will be evaluated nsim times to get nsim random patterns.

> Is it possible (as it is with "envelope") in "alltypes" to set the argument 
> "savepatterns=TRUE", and hereby saving the generated "nsim" n-multitype
>  point patterns of the null-model, which can be used to generating another
>  envelope in an other summary statistic (e.g. J-function)?

Yes.
See above.

   data(amacrine)
   z <- alltypes(amacrine, Gcross, envelope=TRUE, 
              simulate=expression(rlabel(amacrine)),
              savepatterns=TRUE)

To extract the simulated patterns for the plot panel in (say) the top left position,

    z11 <- z[1,1]
    s11 <- attr(z11, "simpatterns")

====
Prof Adrian Baddeley (UWA/CSIRO)
CSIRO Mathematics, Informatics & Statistics
Leeuwin Centre, 65 Brockway Road, Floreat WA 6014, Australia
Tel: 08 9333 6177 | Fax: 08 9333 6121 | Mob: 0410 447 821


From Adrian.Baddeley at csiro.au  Wed Jun  9 12:33:51 2010
From: Adrian.Baddeley at csiro.au (Adrian.Baddeley at csiro.au)
Date: Wed, 9 Jun 2010 18:33:51 +0800
Subject: [R-sig-Geo] existance of a specific non-overlapping marked
 spatial model in spatstat or other R package?
In-Reply-To: <7D403BF1018E6D4882ADD0F77E35BC5C159579@xmail06.ad.ua.ac.be>
References: <57DC18C299094D4299F837570C5DF1C52B1433680E@EXWA-MBX01.nexus.csiro.au>
	<7D403BF1018E6D4882ADD0F77E35BC5C159579@xmail06.ad.ua.ac.be>
Message-ID: <57DC18C299094D4299F837570C5DF1C52B19D4CC88@EXWA-MBX01.nexus.csiro.au>

Jan Quets <Jan.Quets at ua.ac.be> heeft geschreven:
 
>  Hello all, thx for the input this far.
> after having implemented the interesting code 
> professor Baddeley suggested, it seems that 'sort(X$marks)' and 'sort(rvals)'
> are however not the same vectors, which they should be 
> according to the proposed null model. 
 
You didn't say that you want each disc radius to be used only once 
(aka 'sampling without replacement'). 
 
To do that, change the line 
     con <- rmhcontrol(p=1)
to 
   con <- rmhcontrol(p=1, fixall=TRUE)
 
so that the algorithm will not resample the marks; and change the line
 
   sta <- rmhstart(n.start=k) 
to 
  sta <- rmhstart(x.start=XX)
 
where 'XX' is a point pattern that uses each mark exactly once (and satisfies the model constraints). 

> Also I don't understand the piece of code:
> marks(X) <- rvals[marks(X)]

Before this line is executed, X is a multitype point pattern; marks(X) is a factor ('categorical variable') with values that are effectively the numbers 1 to m. You want the mark 1 to be replaced by the actual radius value rvals[1]. So after this line is executed, marks(X) is a numeric vector containing the actual mark values. If you plot the resulting pattern X as plot(X, markscale=1) then you'll see the discs.

===
Prof Adrian Baddeley (UWA/CSIRO)
CSIRO Mathematics, Informatics & Statistics
Leeuwin Centre, 65 Brockway Road, Floreat WA 6014, Australia
Tel: 08 9333 6177 | Fax: 08 9333 6121 | Mob: 0410 447 821


From thi_veloso at yahoo.com.br  Wed Jun  9 20:45:05 2010
From: thi_veloso at yahoo.com.br (Thiago Veloso)
Date: Wed, 9 Jun 2010 11:45:05 -0700 (PDT)
Subject: [R-sig-Geo] How to extract coordinates values from a shapefile?
Message-ID: <140741.42372.qm@web54307.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100609/9404fd76/attachment.pl>

From wwwhsd at gmail.com  Wed Jun  9 20:53:14 2010
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Wed, 9 Jun 2010 15:53:14 -0300
Subject: [R-sig-Geo] How to extract coordinates values from a shapefile?
In-Reply-To: <140741.42372.qm@web54307.mail.re2.yahoo.com>
References: <140741.42372.qm@web54307.mail.re2.yahoo.com>
Message-ID: <AANLkTik5PqEYO-LaZgaknya-mRILa2eqeia0EgtzqREJ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100609/f0149314/attachment.pl>

From nikhil.list at gmail.com  Wed Jun  9 21:00:56 2010
From: nikhil.list at gmail.com (Nikhil Kaza)
Date: Wed, 9 Jun 2010 15:00:56 -0400
Subject: [R-sig-Geo] How to extract coordinates values from a shapefile?
In-Reply-To: <140741.42372.qm@web54307.mail.re2.yahoo.com>
References: <140741.42372.qm@web54307.mail.re2.yahoo.com>
Message-ID: <89BDA5F2-155C-4F20-BC96-1FB2A9B4F239@gmail.com>

Look at this. Not sure if this is indeed what you want or if you  
actually have to unproject them.

http://www.mail-archive.com/r-sig-geo at stat.math.ethz.ch/msg04715.html

require(ggplot2)
fortify(br)


Nikhil Kaza
Asst. Professor,
City and Regional Planning
University of North Carolina

nikhil.list at gmail.com

On Jun 9, 2010, at 2:45 PM, Thiago Veloso wrote:

>   Dear R colleagues,
>   Does anyone know if it's possible to create a vector with  
> coordinate values extracted from a shape loaded with readShapePoly  
> command of "maptools" package?
>   For example, the following code loads the shapefile containing  
> Brazilian states division:
> library(maptools)br<-readShapePoly("BR-map/3.shp")
>   What I need to do is create a vector which contains all lat and  
> lon values inside this shapefile...
>   Thanks in advance,
>   Thiago Veloso.
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From thi_veloso at yahoo.com.br  Wed Jun  9 21:04:20 2010
From: thi_veloso at yahoo.com.br (Thiago Veloso)
Date: Wed, 9 Jun 2010 12:04:20 -0700 (PDT)
Subject: [R-sig-Geo] How to extract coordinates values from a shapefile?
In-Reply-To: <AANLkTik5PqEYO-LaZgaknya-mRILa2eqeia0EgtzqREJ@mail.gmail.com>
Message-ID: <775537.90040.qm@web54305.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100609/4dbc8eb9/attachment.pl>

From jmbarriosg at gmail.com  Wed Jun  9 21:32:09 2010
From: jmbarriosg at gmail.com (=?ISO-8859-1?Q?Jos=E9_Miguel_Barrios?=)
Date: Wed, 9 Jun 2010 21:32:09 +0200
Subject: [R-sig-Geo] installing spdep
Message-ID: <AANLkTik_wJlSqv_EB53MXNLT95mv8zKt3gohQPHtRbpA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100609/8bfa5775/attachment.pl>

From thi_veloso at yahoo.com.br  Wed Jun  9 21:34:14 2010
From: thi_veloso at yahoo.com.br (Thiago Veloso)
Date: Wed, 9 Jun 2010 12:34:14 -0700 (PDT)
Subject: [R-sig-Geo] How to extract coordinates values from a shapefile?
In-Reply-To: <89BDA5F2-155C-4F20-BC96-1FB2A9B4F239@gmail.com>
Message-ID: <858168.96212.qm@web54306.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100609/d6ecd153/attachment.pl>

From edzer.pebesma at uni-muenster.de  Wed Jun  9 21:36:02 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 09 Jun 2010 21:36:02 +0200
Subject: [R-sig-Geo] installing spdep
In-Reply-To: <AANLkTik_wJlSqv_EB53MXNLT95mv8zKt3gohQPHtRbpA@mail.gmail.com>
References: <AANLkTik_wJlSqv_EB53MXNLT95mv8zKt3gohQPHtRbpA@mail.gmail.com>
Message-ID: <4C0FED22.9060603@uni-muenster.de>

package liblapack-dev might need to be installed.

On 06/09/2010 09:32 PM, Jos? Miguel Barrios wrote:
> Hello,
> 
> I'm using Kubuntu and R 2.10; I want to install spdep but I get the
> following problem.  Perhaps some of you have faced and solved this problem
> before; could you give any suggestion?  Thank you in advance.
> Miguel.
> 
> installing *source* package ?spdep? ...
> ** libs
> gcc -std=gnu99 -I/usr/share/R/include      -fpic  -g -O2 -c card.c -o card.o
> gcc -std=gnu99 -I/usr/share/R/include      -fpic  -g -O2 -c dfs_ncomp.c -o
> dfs_ncomp.o
> gcc -std=gnu99 -I/usr/share/R/include      -fpic  -g -O2 -c dnn.c -o dnn.o
> gcc -std=gnu99 -I/usr/share/R/include      -fpic  -g -O2 -c gabriel.c -o
> gabriel.o
> gcc -std=gnu99 -I/usr/share/R/include      -fpic  -g -O2 -c gearyw.c -o
> gearyw.o
> gcc -std=gnu99 -I/usr/share/R/include      -fpic  -g -O2 -c gsymtest.c -o
> gsymtest.o
> gcc -std=gnu99 -I/usr/share/R/include      -fpic  -g -O2 -c init.c -o init.o
> gcc -std=gnu99 -I/usr/share/R/include      -fpic  -g -O2 -c insiders.c -o
> insiders.o
> gcc -std=gnu99 -I/usr/share/R/include      -fpic  -g -O2 -c jc.c -o jc.o
> gcc -std=gnu99 -I/usr/share/R/include      -fpic  -g -O2 -c knn.c -o knn.o
> gcc -std=gnu99 -I/usr/share/R/include      -fpic  -g -O2 -c lagw.c -o lagw.o
> gcc -std=gnu99 -I/usr/share/R/include      -fpic  -g -O2 -c listw2Matrix.c
> -o listw2Matrix.o
> gcc -std=gnu99 -I/usr/share/R/include      -fpic  -g -O2 -c listw2sn.c -o
> listw2sn.o
> gcc -std=gnu99 -I/usr/share/R/include      -fpic  -g -O2 -c ml_sse.c -o
> ml_sse.o
> gcc -std=gnu99 -I/usr/share/R/include      -fpic  -g -O2 -c nbdists.c -o
> nbdists.o
> gcc -std=gnu99 -I/usr/share/R/include      -fpic  -g -O2 -c polypoly.c -o
> polypoly.o
> gcc -std=gnu99 -I/usr/share/R/include      -fpic  -g -O2 -c relative.c -o
> relative.o
> gcc -std=gnu99 -I/usr/share/R/include      -fpic  -g -O2 -c skater.c -o
> skater.o
> gcc -std=gnu99 -I/usr/share/R/include      -fpic  -g -O2 -c soigraph.c -o
> soigraph.o
> gcc -std=gnu99 -I/usr/share/R/include      -fpic  -g -O2 -c symtest.c -o
> symtest.o
> gcc -std=gnu99 -shared -o spdep.so card.o dfs_ncomp.o dnn.o gabriel.o
> gearyw.o gsymtest.o init.o insiders.o jc.o knn.o lagw.o listw2Matrix.o
> listw2sn.o ml_sse.o nbdists.o polypoly.o relative.o skater.o soigraph.o
> symtest.o -llapack -lblas -lgfortran -lm -L/usr/lib/R/lib -lR
> /usr/bin/ld: cannot find -llapack
> collect2: ld returned 1 exit status
> make: *** [spdep.so] Error 1
> ERROR: compilation failed for package ?spdep?
> * removing ?/home/jm/R/i486-pc-linux-gnu-library/2.10/spdep?
> 
> The downloaded packages are in
>         ?/tmp/RtmpD2fTpS/downloaded_packages?
> Warning message:
> In install.packages("spdep") :
>   installation of package 'spdep' had non-zero exit status
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From nikhil.list at gmail.com  Wed Jun  9 21:37:41 2010
From: nikhil.list at gmail.com (Nikhil Kaza)
Date: Wed, 9 Jun 2010 15:37:41 -0400
Subject: [R-sig-Geo] How to extract coordinates values from a shapefile?
In-Reply-To: <858168.96212.qm@web54306.mail.re2.yahoo.com>
References: <858168.96212.qm@web54306.mail.re2.yahoo.com>
Message-ID: <EEBF95B6-EE20-40CE-BEF7-3690DA4AC9D8@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100609/92104c29/attachment.pl>

From thi_veloso at yahoo.com.br  Wed Jun  9 21:46:21 2010
From: thi_veloso at yahoo.com.br (Thiago Veloso)
Date: Wed, 9 Jun 2010 12:46:21 -0700 (PDT)
Subject: [R-sig-Geo] How to extract coordinates values from a shapefile?
In-Reply-To: <EEBF95B6-EE20-40CE-BEF7-3690DA4AC9D8@gmail.com>
Message-ID: <556658.84166.qm@web54307.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100609/f3059a15/attachment.pl>

From biozealot21 at gmail.com  Wed Jun  9 21:58:04 2010
From: biozealot21 at gmail.com (Matt Beard)
Date: Wed, 9 Jun 2010 15:58:04 -0400
Subject: [R-sig-Geo] How to extract coordinates values from a shapefile?
In-Reply-To: <556658.84166.qm@web54307.mail.re2.yahoo.com>
References: <EEBF95B6-EE20-40CE-BEF7-3690DA4AC9D8@gmail.com>
	<556658.84166.qm@web54307.mail.re2.yahoo.com>
Message-ID: <AANLkTikhyv5Xq0Pi13ibosOy1zR21ncMNeB6sw5a7T5L@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100609/dcb54116/attachment.pl>

From edzer.pebesma at uni-muenster.de  Wed Jun  9 22:24:09 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 09 Jun 2010 22:24:09 +0200
Subject: [R-sig-Geo] How to extract coordinates values from a shapefile?
In-Reply-To: <AANLkTikhyv5Xq0Pi13ibosOy1zR21ncMNeB6sw5a7T5L@mail.gmail.com>
References: <EEBF95B6-EE20-40CE-BEF7-3690DA4AC9D8@gmail.com>	<556658.84166.qm@web54307.mail.re2.yahoo.com>
	<AANLkTikhyv5Xq0Pi13ibosOy1zR21ncMNeB6sw5a7T5L@mail.gmail.com>
Message-ID: <4C0FF869.4010804@uni-muenster.de>

The example provided by Matt assumes that each polygon consists of a
single ring, and doesn't have islands, lakes etc. The function below
pasts all coordinates to a single 2-column matrix. For clarity's sake, I
avoided nested sapply's.

library(maptools)
xx <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1],
  IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
allcoordinates = function(x) {
    ret = NULL
    polys = x at polygons
    for(i in 1:length(polys)) {
        pp = polys[[i]]@Polygons
        for (j in 1:length(pp))
            ret = rbind(ret, coordinates(pp[[j]]))
    }
    ret
}
q = allcoordinates(xx)

# check:
plot(xx)
lines(q, col='blue')


On 06/09/2010 09:58 PM, Matt Beard wrote:
>>
>> library(maptools)
>>
>> # A simple way to print out a list of coordinates for each polygon in your
>> shapefile:
>>
>> # Path and filename of polygon shapefile
>> testfile <- '/media/PKBACK# 001/FNR210/QGISLab/habitats/habitats.shp'
>>
>> # Read in polygon shapefile using handy maptools function
>> test <- readShapePoly(testfile)
>>
>> # Extract the list of Polygons objects
>> polys <- slot(test,"polygons")
>>
>> # Within each Polygons object
>> #    Extract the Polygon list (assuming just one per Polygons)
>> #    And Extract the coordinates from each Polygon
>> for (i in 1:length(polys)) {
>>    print(paste("Polygon #",i))
>>    print(slot(slot(polys[[i]],"Polygons")[[1]],"coords"  ))
>> }
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From hadley at rice.edu  Wed Jun  9 22:50:48 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 9 Jun 2010 15:50:48 -0500
Subject: [R-sig-Geo] How to extract coordinates values from a shapefile?
In-Reply-To: <4C0FF869.4010804@uni-muenster.de>
References: <EEBF95B6-EE20-40CE-BEF7-3690DA4AC9D8@gmail.com> 
	<556658.84166.qm@web54307.mail.re2.yahoo.com>
	<AANLkTikhyv5Xq0Pi13ibosOy1zR21ncMNeB6sw5a7T5L@mail.gmail.com> 
	<4C0FF869.4010804@uni-muenster.de>
Message-ID: <AANLkTinkp4xo5ZRX0iy_fFZ3E14167DEYFYtOBPre2uO@mail.gmail.com>

On Wed, Jun 9, 2010 at 3:24 PM, Edzer Pebesma
<edzer.pebesma at uni-muenster.de> wrote:
> The example provided by Matt assumes that each polygon consists of a
> single ring, and doesn't have islands, lakes etc. The function below
> pasts all coordinates to a single 2-column matrix. For clarity's sake, I
> avoided nested sapply's.
>
> library(maptools)
> xx <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1],
> ?IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
> allcoordinates = function(x) {
> ? ?ret = NULL
> ? ?polys = x at polygons
> ? ?for(i in 1:length(polys)) {
> ? ? ? ?pp = polys[[i]]@Polygons
> ? ? ? ?for (j in 1:length(pp))
> ? ? ? ? ? ?ret = rbind(ret, coordinates(pp[[j]]))
> ? ?}
> ? ?ret
> }
> q = allcoordinates(xx)
>
> # check:
> plot(xx)
> lines(q, col='blue')

And that's basically what fortify does, except it covers a few more cases.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From Roger.Bivand at nhh.no  Wed Jun  9 22:55:06 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 9 Jun 2010 22:55:06 +0200 (CEST)
Subject: [R-sig-Geo] plotting Polygon (sp)
In-Reply-To: <87hbld2jj4.fsf@kolob.sebmags.homelinux.org>
References: <87hbld2jj4.fsf@kolob.sebmags.homelinux.org>
Message-ID: <alpine.LRH.2.00.1006092251140.13732@reclus.nhh.no>

On Tue, 8 Jun 2010, Sebastian P. Luque wrote:

> Hi,
>
> Using the example from the vignette "sp" (section 7.1):

Well, not really, because the example on p. 19 builds a SpatialPolygons 
object, for which there is a plot() method. There is no plot() method for 
Polygon or Polygons objects exposed at the user level, mostly because of 
plot order and hole handling issues.

Roger

>
> ---<--------------------cut here---------------start------------------->---
> R> sr1
> An object of class "Polygon"
> Slot "labpt":
> [1] 2.697 3.545
>
> Slot "area":
> [1] 5.5
>
> Slot "hole":
> [1] TRUE
>
> Slot "ringDir":
> [1] -1
>
> Slot "coords":
>     [,1] [,2]
> [1,]    2    2
> [2,]    4    3
> [3,]    4    5
> [4,]    1    4
> [5,]    2    2
>
> R> plot(sr1)
> Error in as.double(y) :
>  cannot coerce type 'S4' to vector of type 'double'
> R> showMethods("plot")
> Function: plot (package graphics)
> x="ANY", y="ANY"
> x="Polygon", y="missing"
>    (inherited from: x="ANY", y="ANY")
> x="SpatialLines", y="missing"
> x="Spatial", y="missing"
> x="SpatialPoints", y="missing"
> x="SpatialPolygons", y="missing"
>
> R> sessionInfo()
> R version 2.11.1 (2010-05-31)
> x86_64-pc-linux-gnu
>
> locale:
> [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C               LC_TIME=en_CA.UTF-8
> [4] LC_COLLATE=en_CA.UTF-8     LC_MONETARY=C              LC_MESSAGES=en_CA.UTF-8
> [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C                  LC_ADDRESS=C
> [10] LC_TELEPHONE=C             LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] rgdal_0.6-27    maptools_0.7-34 foreign_0.8-40  mapdata_2.1-2   maps_2.1-3
> [6] sp_0.9-64       slmisc_0.7.6    lattice_0.18-8
>
> loaded via a namespace (and not attached):
> [1] grid_2.11.1  tools_2.11.1
> ---<--------------------cut here---------------end--------------------->---
>
> Why is plot() failing with that error?
>
>
> Cheers,
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From debeaudette at ucdavis.edu  Wed Jun  9 23:01:50 2010
From: debeaudette at ucdavis.edu (Dylan Beaudette)
Date: Wed, 9 Jun 2010 14:01:50 -0700
Subject: [R-sig-Geo] How to extract coordinates values from a shapefile?
In-Reply-To: <AANLkTinkp4xo5ZRX0iy_fFZ3E14167DEYFYtOBPre2uO@mail.gmail.com>
References: <EEBF95B6-EE20-40CE-BEF7-3690DA4AC9D8@gmail.com>
	<4C0FF869.4010804@uni-muenster.de>
	<AANLkTinkp4xo5ZRX0iy_fFZ3E14167DEYFYtOBPre2uO@mail.gmail.com>
Message-ID: <201006091401.50501.dylan.beaudette@gmail.com>

On Wednesday 09 June 2010, Hadley Wickham wrote:
> On Wed, Jun 9, 2010 at 3:24 PM, Edzer Pebesma
>
> <edzer.pebesma at uni-muenster.de> wrote:
> > The example provided by Matt assumes that each polygon consists of a
> > single ring, and doesn't have islands, lakes etc. The function below
> > pasts all coordinates to a single 2-column matrix. For clarity's sake, I
> > avoided nested sapply's.
> >
> > library(maptools)
> > xx <- readShapePoly(system.file("shapes/sids.shp",
> > package="maptools")[1], IDvar="FIPSNO", proj4string=CRS("+proj=longlat
> > +ellps=clrk66")) allcoordinates = function(x) {
> > ? ?ret = NULL
> > ? ?polys = x at polygons
> > ? ?for(i in 1:length(polys)) {
> > ? ? ? ?pp = polys[[i]]@Polygons
> > ? ? ? ?for (j in 1:length(pp))
> > ? ? ? ? ? ?ret = rbind(ret, coordinates(pp[[j]]))
> > ? ?}
> > ? ?ret
> > }
> > q = allcoordinates(xx)
> >
> > # check:
> > plot(xx)
> > lines(q, col='blue')
>
> And that's basically what fortify does, except it covers a few more cases.
>
> Hadley

Not to be nit-picky, but wouldn't it be safer to pre-allocated "ret" instead 
of dynamically appending? This would allow the suggested function to scale to 
very large geometries.


Cheers,
Dylan



-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341


From johan.vandewauw at gmail.com  Thu Jun 10 11:35:46 2010
From: johan.vandewauw at gmail.com (Johan Van de Wauw)
Date: Thu, 10 Jun 2010 11:35:46 +0200
Subject: [R-sig-Geo] installing spdep
In-Reply-To: <4C0FED22.9060603@uni-muenster.de>
References: <AANLkTik_wJlSqv_EB53MXNLT95mv8zKt3gohQPHtRbpA@mail.gmail.com> 
	<4C0FED22.9060603@uni-muenster.de>
Message-ID: <AANLkTinB1U7Axq7YM-4BT6hogR0eP5zgLAJfoKgytG3O@mail.gmail.com>

I recommend installing the r-base-dev package. That will install
liblapack-dev and a number of other development packages which are
needed to compile the the most common R- packages.

On Wed, Jun 9, 2010 at 9:36 PM, Edzer Pebesma
<edzer.pebesma at uni-muenster.de> wrote:
> package liblapack-dev might need to be installed.
>

>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> 8333081, Fax: +49 251 8339763 ?http://ifgi.uni-muenster.de
> http://www.52north.org/geostatistics ? ? ?e.pebesma at wwu.de
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From cjpauw at gmail.com  Thu Jun 10 11:47:33 2010
From: cjpauw at gmail.com (christiaan pauw)
Date: Thu, 10 Jun 2010 11:47:33 +0200
Subject: [R-sig-Geo] Plot categorical data from SpatialPolygonsDataFrame in
	color with label: plot() vs spplot()
Message-ID: <AANLkTinMNWLG2jJZjr0tQKE3dQIw7HyaJuW7V1tgTx9u@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100610/99bc5ba0/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Thu Jun 10 12:00:50 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 10 Jun 2010 11:00:50 +0100
Subject: [R-sig-Geo] Plot categorical data from SpatialPolygonsDataFrame
	in color with label: plot() vs spplot()
In-Reply-To: <AANLkTinMNWLG2jJZjr0tQKE3dQIw7HyaJuW7V1tgTx9u@mail.gmail.com>
References: <AANLkTinMNWLG2jJZjr0tQKE3dQIw7HyaJuW7V1tgTx9u@mail.gmail.com>
Message-ID: <AANLkTilVi59sEhxvVCZeEexWAUYMcxZYQwQ8E91JJSct@mail.gmail.com>

On Thu, Jun 10, 2010 at 10:47 AM, christiaan pauw <cjpauw at gmail.com> wrote:
> Hi everybody
>
> I have a town map with a polygon for every individual stand. I have
> interview data in a SpatialPolygonsDataFrame (SPDF) for some of them. Now I
> want to print a map in pdf (as large as A0 !) ?that displays:
>
> 1. All stands in the town
> 2. The ones we have done interviews with in one of four colours depending in
> the value of a categorical variable (factor) with four levels.
> 3. The stand number (which is also a variable in the data frame)
>
> I have tried using plot() and spplot. With plot I can get 1 and 2 (very
> nicely with thin lines for 1.) With spplot I can get 1. and 3. (labels
> scaled correctly but lines very thick). I include a reproducible example of
> how far I got.
>
> x <- readShapePoly(system.file("shapes/sids.shp", package="maptools"))
> x at data$cat=sample(1:4,length(xx at data[,1]),replace=TRUE)

 what's 'xx'? I'll assume you meant 'x' and carry on...

> x at data$select=sample(0:1,length(xx at data[,1]),replace=TRUE)
> my.select=x[x$select==1,]plot(x,lwd=0.025,main="Whatever")
> plot(my.select[which(my.select$cat==1),],lwd=0.05,col="green",add=TRUE)
> plot(my.select[which(my.select$cat==2),],lwd=0.05,col="grey",add=TRUE)
> plot(my.select[which(my.select$cat==3),],lwd=0.05,col="brown",add=TRUE)
> plot(my.select[which(my.select$cat==4),],lwd=0.05,col="red",add=TRUE)
> text(coordinates(x),x at data$NAME,cex=0.025)
>
> # Everything worked except the last line. Why?
> # I have the colours but not the lables

 You've not given the text() function a character argument!
x at data$NAME is a factor, so I think text() thinks this is your Y
coordinate. Try:

 > plot(x)
 > text(coordinates(x),x at data$NAME,cex=0.25)
 > text(coordinates(x),as.character(x at data$NAME),cex=0.25)

 the first fails horribly (draws numbers at odd places) but the second works.

 I'm not sure if cex=0.025 works since I don't have an electron
microscope handy in order to read it!  There may be limitations on
very small text sizes with some graphics devices. There certainly is
on my eyes...

 Also, you can probably plot the coloured ones in one go. Something like:

 > mypal = c("green","grey","brown","red")
 > plot(my.select,col=mypal[my.select$cat])

there are other ways of mapping values to colours, such as my
colourschemes package [shameless plug!], but this is the simplest.

hope that helps

Barry


From p.hiemstra at geo.uu.nl  Thu Jun 10 14:25:44 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Thu, 10 Jun 2010 14:25:44 +0200
Subject: [R-sig-Geo] How to extract coordinates values from a shapefile?
In-Reply-To: <201006091401.50501.dylan.beaudette@gmail.com>
References: <EEBF95B6-EE20-40CE-BEF7-3690DA4AC9D8@gmail.com>	<4C0FF869.4010804@uni-muenster.de>	<AANLkTinkp4xo5ZRX0iy_fFZ3E14167DEYFYtOBPre2uO@mail.gmail.com>
	<201006091401.50501.dylan.beaudette@gmail.com>
Message-ID: <4C10D9C8.1020404@geo.uu.nl>

On 06/09/2010 11:01 PM, Dylan Beaudette wrote:
> On Wednesday 09 June 2010, Hadley Wickham wrote:
>    
>> On Wed, Jun 9, 2010 at 3:24 PM, Edzer Pebesma
>>
>> <edzer.pebesma at uni-muenster.de>  wrote:
>>      
>>> The example provided by Matt assumes that each polygon consists of a
>>> single ring, and doesn't have islands, lakes etc. The function below
>>> pasts all coordinates to a single 2-column matrix. For clarity's sake, I
>>> avoided nested sapply's.
>>>
>>> library(maptools)
>>> xx<- readShapePoly(system.file("shapes/sids.shp",
>>> package="maptools")[1], IDvar="FIPSNO", proj4string=CRS("+proj=longlat
>>> +ellps=clrk66")) allcoordinates = function(x) {
>>>     ret = NULL
>>>     polys = x at polygons
>>>     for(i in 1:length(polys)) {
>>>         pp = polys[[i]]@Polygons
>>>         for (j in 1:length(pp))
>>>             ret = rbind(ret, coordinates(pp[[j]]))
>>>     }
>>>     ret
>>> }
>>> q = allcoordinates(xx)
>>>
>>> # check:
>>> plot(xx)
>>> lines(q, col='blue')
>>>        
>> And that's basically what fortify does, except it covers a few more cases.
>>
>> Hadley
>>      
> Not to be nit-picky, but wouldn't it be safer to pre-allocated "ret" instead
> of dynamically appending? This would allow the suggested function to scale to
> very large geometries.
>    
A combination of lapply and do.call("rbind" also works well in terms of 
performance.

cheers,
Paul
>
> Cheers,
> Dylan
>
>
>
>    


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From everton.emanuel at gmail.com  Thu Jun 10 15:29:24 2010
From: everton.emanuel at gmail.com (Everton Emanuel)
Date: Thu, 10 Jun 2010 10:29:24 -0300
Subject: [R-sig-Geo] Doubt about the local moran - spdep
Message-ID: <AANLkTikY6mmNmjMDSzkHAUf4kDAnTp4FhZ5hzlsIb1Fu@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100610/ffe09792/attachment.pl>

From cjpauw at gmail.com  Thu Jun 10 19:35:00 2010
From: cjpauw at gmail.com (christiaan pauw)
Date: Thu, 10 Jun 2010 19:35:00 +0200
Subject: [R-sig-Geo] rotate label in plot based on polygon shape
Message-ID: <AANLkTik7e4sDqiztkQYku2AfSJfc4YrOKv4_CUqvjXis@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100610/d65ee2aa/attachment.pl>

From erich.neuwirth at univie.ac.at  Thu Jun 10 23:01:54 2010
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Thu, 10 Jun 2010 23:01:54 +0200
Subject: [R-sig-Geo] Rcartogram from omegahat
Message-ID: <4C1152C2.9030709@univie.ac.at>

The package Rcartogram available from omegahat
cannot be installed with the standard
R CMD INSTALL Rcartogram
on Windows.
It needs libfftw3.
There is a binary version of the package on the site,
but only for R 2.9.
Does anybody have a version of this package for R 2.11 on Windows,
or does anybody have instructions how to build it?

-- 
Erich Neuwirth, University of Vienna
Faculty of Computer Science
Center for Computer Science Didactics and Learning Research
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-39902 Fax: +43-1-4277-39459


From dvrbts at ecology.msu.montana.edu  Thu Jun 10 23:45:50 2010
From: dvrbts at ecology.msu.montana.edu (Dave Roberts)
Date: Thu, 10 Jun 2010 15:45:50 -0600
Subject: [R-sig-Geo] libproj errors
Message-ID: <4C115D0E.9060402@ecology.msu.montana.edu>

Friends,

    I recently became a GRASS convert. I have been an R user for a long 
time, so naturally I have tried spgrass6.  Unfortunately I have yet to 
get it to work.  The beginning goes well

 > library(spgrass6)
Loading required package: sp
Loading required package: rgdal
Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 1.5.3, released 2008/09/09
Path to GDAL shared files: /usr/share/gdal
Loaded PROJ.4 runtime: Rel. 4.6.1, 21 August 2008
Path to PROJ.4 shared files: (autodetected)
Loading required package: XML
GRASS GIS interface loaded with GRASS version: 6.3.0
and location: grte

but then (despite the reference to PROJ.4 above) when I try and get a 
raster into R I get an error

 > test <- readRAST6('elev_30')
Error in .local(.Object, ...) :

	GDAL Error 1: libproj.so: cannot open shared object file: No such file 
or directory

but it appears to be there (twice actually)

 > system('find /usr -name libproj.so')
/usr/local/lib/libproj.so
/usr/lib/libproj.so

I copied it from usr/local/lib to usr/lib thinking maybe it wasn't 
looking at the right path, but it doesn't seem to find it in either 
location.  This appears to be a GDAL error, rather than an R or spgrass6 
error, but GRASS runs fine.

FWIW I'm running Fedora 10 x86_64, GRASS 6.3, GDAL 1.5.3, PROJ.4 4.6.1

Thanks in advance for any help, Dave
-- 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
David W. Roberts                                     office 406-994-4548
Department of Ecology                         email droberts at montana.edu
Montana State University
Bozeman, MT 59717-3460


From Roger.Bivand at nhh.no  Fri Jun 11 01:39:44 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 11 Jun 2010 01:39:44 +0200 (CEST)
Subject: [R-sig-Geo] libproj errors
In-Reply-To: <4C115D0E.9060402@ecology.msu.montana.edu>
References: <4C115D0E.9060402@ecology.msu.montana.edu>
Message-ID: <alpine.LRH.2.00.1006110134001.18093@reclus.nhh.no>

On Thu, 10 Jun 2010, Dave Roberts wrote:

> Friends,
>
>   I recently became a GRASS convert. I have been an R user for a long time, 
> so naturally I have tried spgrass6.  Unfortunately I have yet to get it to 
> work.  The beginning goes well

>From the versions, it looks at though everything is rather aged. Upgrading 
may help - did you install binary packages, I guess you must have, because 
current source releases are GRASS 6.4.0 RC6, GDAL 1.7.2, and PROJ 4.7.0. 
Workaround below.

>
>> library(spgrass6)
> Loading required package: sp
> Loading required package: rgdal
> Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 1.5.3, released 2008/09/09
> Path to GDAL shared files: /usr/share/gdal
> Loaded PROJ.4 runtime: Rel. 4.6.1, 21 August 2008
> Path to PROJ.4 shared files: (autodetected)
> Loading required package: XML
> GRASS GIS interface loaded with GRASS version: 6.3.0
> and location: grte
>
> but then (despite the reference to PROJ.4 above) when I try and get a raster 
> into R I get an error
>
>> test <- readRAST6('elev_30')
> Error in .local(.Object, ...) :
>
> 	GDAL Error 1: libproj.so: cannot open shared object file: No such 
> file or directory

Look at the arguments to readRAST6. If you set useGDAL=FALSE, the data 
will be copied to a simple binary file, and the GRASS r.out.gdal command 
will not be used.

Do the examples in readGDAL in rgdal work correctly? Do those in 
spTransform work correctly? If so, the GDAL/PROJ problem is most likely 
affecting the GDAL and/or PROJ versions used to build the r.out.gdal 
binary.

Hope this helps,

Roger

>
> but it appears to be there (twice actually)
>
>> system('find /usr -name libproj.so')
> /usr/local/lib/libproj.so
> /usr/lib/libproj.so
>
> I copied it from usr/local/lib to usr/lib thinking maybe it wasn't looking at 
> the right path, but it doesn't seem to find it in either location.  This 
> appears to be a GDAL error, rather than an R or spgrass6 error, but GRASS 
> runs fine.
>
> FWIW I'm running Fedora 10 x86_64, GRASS 6.3, GDAL 1.5.3, PROJ.4 4.6.1
>
> Thanks in advance for any help, Dave
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Fri Jun 11 01:51:05 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 11 Jun 2010 01:51:05 +0200 (CEST)
Subject: [R-sig-Geo] rotate label in plot based on polygon shape
In-Reply-To: <AANLkTik7e4sDqiztkQYku2AfSJfc4YrOKv4_CUqvjXis@mail.gmail.com>
References: <AANLkTik7e4sDqiztkQYku2AfSJfc4YrOKv4_CUqvjXis@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1006110141530.18093@reclus.nhh.no>

On Thu, 10 Jun 2010, christiaan pauw wrote:

> Hi everybody
>
> Is it possible, when plotting a SPDF to rotate the label in a polygon based
> on the shape of the polygon. I want the greatest possible length in which to
> print the label and don't mind  reading upside down as long as the label is
> readable. I am printing a map consisting of tens of thousands of labeled
> polygons ( of various shape s but mainly rectangles). If the rectangle is
> orientated with its long side horizontally (like so | LABEL |), the labels
> are readable but if the short side is on the horisontal level then the label
> runs into and over the rectangle and all the lables end up in an unreadable
> tangle. In that case I would prefer to have something like this
> _
> |L|
> |A|
> |B|
> |E|
> |L|

The par(srt=) argument can be set to rotate all labels in a text() command 
- it only takes a single value in each call to text(), but not the letters 
in a label. Label placement is a hard problem to solve automatically. See 
?pointLabel in maptools for some unrotated ways of avoiding point labels 
overlapping, but I don't think that it will help much. Can you abbreviate 
the labels - see ?abbreviate?

Roger

>
> Does anyone know if it is possible to specify the rotation of labels in some
> way?
>
> Thanks is advance
>
> Christiaan
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From vivacity at hotmail.sg  Fri Jun 11 07:24:54 2010
From: vivacity at hotmail.sg (v v)
Date: Fri, 11 Jun 2010 13:24:54 +0800
Subject: [R-sig-Geo] How to locate local minima points on a Krige-fitted
	surface?
Message-ID: <SNT113-W385A1202C4694FB0D1E340B5D90@phx.gbl>



Hi,

I am using the 'fields' package to conduct Kriging interpolation on my dataset. I have managed to generate the 3-dimensional surface plot of the Krige-fitted surface. There are several local minima points on the surface. My main interest is to pinpoint the exact x-y coordinates of the lowest response (elevation) point of each of the local minima points.

Although an approximation is possible by generating predicted values using a regularly-spaced grids, such approximations are not good enough for my purposes. I have intentions to use the optim() and/or constrOptim() functions to locate the minima but I do not know what is the objective function to be optimized. Therefore, so far, I am still unable to do that.

So, know how can I locate the local minima on a Krige-fitted surface?

regards,
Jeff Yeo 		 	   		  
_________________________________________________________________
Hotmail: Trusted email with powerful SPAM protection.
https://signup.live.com/signup.aspx?id=60969


From aslantas at metu.edu.tr  Fri Jun 11 10:29:12 2010
From: aslantas at metu.edu.tr (Pinar Aslantas Bostan)
Date: Fri, 11 Jun 2010 11:29:12 +0300
Subject: [R-sig-Geo] GWR Analysis
Message-ID: <20100611112912.7046178p2b4mg53s@horde.metu.edu.tr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100611/1907d049/attachment.pl>

From p.hiemstra at geo.uu.nl  Fri Jun 11 11:43:34 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Fri, 11 Jun 2010 11:43:34 +0200
Subject: [R-sig-Geo] How to extract coordinates values from a shapefile?
In-Reply-To: <201006091401.50501.dylan.beaudette@gmail.com>
References: <EEBF95B6-EE20-40CE-BEF7-3690DA4AC9D8@gmail.com>	<4C0FF869.4010804@uni-muenster.de>	<AANLkTinkp4xo5ZRX0iy_fFZ3E14167DEYFYtOBPre2uO@mail.gmail.com>
	<201006091401.50501.dylan.beaudette@gmail.com>
Message-ID: <4C120546.4030309@geo.uu.nl>

On 06/09/2010 11:01 PM, Dylan Beaudette wrote:
> On Wednesday 09 June 2010, Hadley Wickham wrote:
>    
>> On Wed, Jun 9, 2010 at 3:24 PM, Edzer Pebesma
>>
>> <edzer.pebesma at uni-muenster.de>  wrote:
>>      
>>> The example provided by Matt assumes that each polygon consists of a
>>> single ring, and doesn't have islands, lakes etc. The function below
>>> pasts all coordinates to a single 2-column matrix. For clarity's sake, I
>>> avoided nested sapply's.
>>>
>>> library(maptools)
>>> xx<- readShapePoly(system.file("shapes/sids.shp",
>>> package="maptools")[1], IDvar="FIPSNO", proj4string=CRS("+proj=longlat
>>> +ellps=clrk66")) allcoordinates = function(x) {
>>>     ret = NULL
>>>     polys = x at polygons
>>>     for(i in 1:length(polys)) {
>>>         pp = polys[[i]]@Polygons
>>>         for (j in 1:length(pp))
>>>             ret = rbind(ret, coordinates(pp[[j]]))
>>>     }
>>>     ret
>>> }
>>> q = allcoordinates(xx)
>>>
>>> # check:
>>> plot(xx)
>>> lines(q, col='blue')
>>>        
>> And that's basically what fortify does, except it covers a few more cases.
>>
>> Hadley
>>      
> Not to be nit-picky, but wouldn't it be safer to pre-allocated "ret" instead
> of dynamically appending? This would allow the suggested function to scale to
> very large geometries.
>    
In addition to my previous suggestion, I tried using lapply + do.call 
instead of the for loop based implementation of edzer:

library(maptools)
xx<- readShapePoly(system.file("shapes/sids.shp", 
package="maptools")[1], IDvar="FIPSNO", proj4string=CRS("+proj=longlat 
+ellps=clrk66"))

allcoordinates = function(x) {
     ret = NULL
     polys = x at polygons
     for(i in 1:length(polys)) {
         pp = polys[[i]]@Polygons
         for (j in 1:length(pp))
             ret = rbind(ret, coordinates(pp[[j]]))
     }
     ret
}

allcoordinates_lapply = function(x) {
     polys = x at polygons
     return(do.call("rbind", lapply(polys, function(pp) {
     do.call("rbind", lapply(pp at Polygons, coordinates))
     })))
}

q = allcoordinates(xx)
z = allcoordinates_lapply(xx)
all.equal(q,z)

So far it produces the same output. And now comes the nice part, doing a 
test with a large polygon set and timing the performance of both functions:

 > system.time(x <- allcoordinates(nuts))
    user  system elapsed
  22.781   8.572  31.422
 > system.time(y <- allcoordinates_lapply(nuts))
    user  system elapsed
   0.248   0.004   0.250
 > all.equal(x,y)
[1] TRUE

So apart from the imo nicer looking function in terms of syntax, it is 
also several orders of magnitude faster. This effect will only become 
stronger if the polygon set becomes larger. So, lapply + do.call is your 
friend :).

cheers,
Paul

 > sessionInfo()
R version 2.11.0 (2010-04-22)
i486-pc-linux-gnu

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] maptools_0.7-34 lattice_0.18-5  sp_0.9-62       foreign_0.8-40

loaded via a namespace (and not attached):
[1] grid_2.11.0

>
> Cheers,
> Dylan
>
>
>
>    


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From Roger.Bivand at nhh.no  Fri Jun 11 14:00:48 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 11 Jun 2010 14:00:48 +0200 (CEST)
Subject: [R-sig-Geo] GWR Analysis
In-Reply-To: <20100611112912.7046178p2b4mg53s@horde.metu.edu.tr>
References: <20100611112912.7046178p2b4mg53s@horde.metu.edu.tr>
Message-ID: <alpine.LRH.2.00.1006111347160.20024@reclus.nhh.no>

On Fri, 11 Jun 2010, Pinar Aslantas Bostan wrote:

>
>
> Dear all,
>
> I want to make GWR analysis to predict precipitation distribution 
> measured from 225 meteorological stations. I have three independent 
> variables (Z, V1, V2). I want to obtain predictions on the grid dataset 
> which has 31203 number of pixels. I gave some details about my datasets 
> below. While performing GWR, I get error message: "new data matrix rows 
> mismatch"
>
> How can I solve that problem?

You need to provide the detailed output of traceback(), and probably also 
run gwr() under debug() to see whether this is a data problem or a code 
problem. Does gwr() work when predict=FALSE, and/or predict=TRUE, 
se.fit=FALSE? The error message is generated when the number of columns in 
the matrix of X variables is not the same in data and and fit.points. Are 
the variables in both cases stored in the same way? What do 
str(station.grid) and str(station) look like before conversion to SPDF and 
after? Is one variable a factor in one and numeric in the other? Running 
under debug() will let you check what x and predx look like.

If this sounds hard, consider putting your data on a website and posting 
the link.

Hope this helps,

Roger

>
> Thanks, Pinar.
>
> station.grid<-read.table("D:\\R\\dem.txt", header=TRUE)
> station<-read.table("D:\\R\\station.txt", header=TRUE)
>
> grid = SpatialPointsDataFrame(data=station.grid, 
> coords=cbind(station.grid$X, station.grid$Y))

> station = SpatialPointsDataFrame(data=station, coords=cbind(station$X,station$Y))
>
>> names(grid)
> [1] "Z" "X" "Y" "V1" "V2"
>> names(station)
> [1] "PREC" "Z" "X" "Y" "V1" "V2"
>
> bw=gwr.sel(PREC~station$Z+station$V1+station$V2,data=station,adapt=T)

> gwr <-gwr(PREC ~ station$Z + 
station$V1 + station$V2, data=station, adapt=bw, 
fit.points = grid, predict=TRUE, se.fit=T)
>
> Error in gwr(PREC ~ station$Z + station$V1 + station$V2, data = station, :
> NEW DATA MATRiX ROWS MiSMATCH
>
> ----------------------------------------------------------------
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From p.hiemstra at geo.uu.nl  Fri Jun 11 15:04:32 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Fri, 11 Jun 2010 15:04:32 +0200
Subject: [R-sig-Geo] How to locate local minima points on a Krige-fitted
 surface?
In-Reply-To: <SNT113-W385A1202C4694FB0D1E340B5D90@phx.gbl>
References: <SNT113-W385A1202C4694FB0D1E340B5D90@phx.gbl>
Message-ID: <4C123460.6070705@geo.uu.nl>

Dear Jeff,

I think you cannot escape discretizing your kriging surface as there is 
no mathematical expression that captures the kriging surface. To use 
optim you could make an objective function that was two inputs, x and y 
location. The functions calls the fields package to estimate the kriging 
prediction at this point and returns it. This ofcourse assumes that the 
variogram model is known. You have to play with the settings of optim to 
get it working and prevent a local minimum. You could take a look at 
SANN (simulated anealing) which is part of optim.

cheers,
Paul

On 06/11/2010 07:24 AM, v v wrote:
>
> Hi,
>
> I am using the 'fields' package to conduct Kriging interpolation on my dataset. I have managed to generate the 3-dimensional surface plot of the Krige-fitted surface. There are several local minima points on the surface. My main interest is to pinpoint the exact x-y coordinates of the lowest response (elevation) point of each of the local minima points.
>
> Although an approximation is possible by generating predicted values using a regularly-spaced grids, such approximations are not good enough for my purposes. I have intentions to use the optim() and/or constrOptim() functions to locate the minima but I do not know what is the objective function to be optimized. Therefore, so far, I am still unable to do that.
>
> So, know how can I locate the local minima on a Krige-fitted surface?
>
> regards,
> Jeff Yeo 		 	   		
> _________________________________________________________________
> Hotmail: Trusted email with powerful SPAM protection.
> https://signup.live.com/signup.aspx?id=60969
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>    


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From p.hiemstra at geo.uu.nl  Fri Jun 11 15:08:57 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Fri, 11 Jun 2010 15:08:57 +0200
Subject: [R-sig-Geo] test for CSR
In-Reply-To: <57DC18C299094D4299F837570C5DF1C52B19D4CC83@EXWA-MBX01.nexus.csiro.au>
References: <57DC18C299094D4299F837570C5DF1C52B19D4CC83@EXWA-MBX01.nexus.csiro.au>
Message-ID: <4C123569.1080509@geo.uu.nl>

On 06/08/2010 12:37 PM, Adrian.Baddeley at csiro.au wrote:
> Hamid<hamid200356 at yahoo.com>  writes:
>
>    
>> I use the following function to simulate CSR point pattern nsim times.
>>      
> This is a question about the package 'spatstat'.
>
>    
>> Is there a way to reduce running time (maybe by avoiding the loop)?
>>      
>    
>> bakhti<-function(nsim) {
>>      n<-c(10,20,25,30,40,50,100,200,300)
>> #n is the number of points in unit square
>>      
> Actually n gives the *expected* number of points in the unit *cube*
>
>    
>> #nsim is the number of simulation
>> for ( j in 1:length(n))
>> Xsim<- vector("list",nsim)
>> for(i in 1: nsim)
>> {   Xsim[[i]]<- rpoispp3(n[j]) }
>> ksim<- sapply(Xsim, function(x) K3est(x, rmax=1,nrval=101)$iso)
>> }
>> return(ksim)
>> }
>>      
> Since you are only using the 'iso' estimate from K3est, you can halve the computation time in this step by calling
>        K3est(x, correction="isotropic", rmax=1,nrval=101)$iso
> to avoid calculating the translation correction as well.
>
> The loop will use a lot of memory, which will slow things down. It saves all the simulated point patterns Xsim[[i]] and these are not subsequently used except to calculate the K function. Also there is a lot of 'internal state' that is saved in the double loop. So it would be better to write as follows.
>
> runone<- function(lambda, nsim) {
>      kmat<- NULL
>      for(i in 1: nsim) {
>          progressreport(i, nsim)
>          Xsim<- rpoispp3(lambda)
>          ksim<- K3est(Xsim, correction="isotropic", rmax=1,nrval=101)$iso
>          kmat<- cbind(kmat, ksim)
>    
My 2ct :), use a combination of lapply and do.call. This has much better 
performance if kmat grows large. Something along these lines should do 
the job:

runone_lapply = function(lambda, nsim) {
     kmat = do.call("c", lapply(1:nsim, function(i) {
                progressreport(i, nsim)
         Xsim <- rpoispp3(lambda)
         ksim <- K3est(Xsim, correction="isotropic", rmax=1,nrval=101)$iso
         ksim
     }
     kmat
}

cheers,
Paul
>      }
>      return(kmat)
> }
>
> Then
>
> lambdas<- c(10,20,25,30,40,50,100,200,300)
> kout<- lapply(lambdas, runone, nsim=20000)
>
> The result is a list of matrices, where each matrix represents the simulated K values for a particular intensity, and each matrix has one column for each simulated outcome. This might be useful to compute means and variances etc.
>
>    
>> I need huge number of simulation, let say, nsim=20000, which
>> yields very long running time (in hours scale!!).
>>      
> Hours or days? If it is hours, I don't think it is so unreasonable, since you are trying to compute 9 * 20000 = 180000 simulated 3D point patterns and compute their K-functions. At one realisation every 0.1 second, that would take 0.1 * 180000/3600 = 5 hours.
>
> To reduce the computation time further, you could use the translation-corrected estimate (correction='translation') instead of the isotropic correction.
>
> The call to 'progressreport' will show you whether the computations are getting slower as the loop index i increases. If this happens, it usually indicates a memory leak in the loop.
>
> ----
>
> Prof Adrian Baddeley (UWA/CSIRO)
> CSIRO Mathematics, Informatics&  Statistics
> Leeuwin Centre, 65 Brockway Road, Floreat WA 6014, Australia
> Tel: 08 9333 6177 | Fax: 08 9333 6121 | Mob: 0410 447 821
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>    


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From aslantas at metu.edu.tr  Fri Jun 11 15:25:42 2010
From: aslantas at metu.edu.tr (Pinar Aslantas Bostan)
Date: Fri, 11 Jun 2010 16:25:42 +0300
Subject: [R-sig-Geo] GWR Analysis
In-Reply-To: <alpine.LRH.2.00.1006111347160.20024@reclus.nhh.no>
References: <20100611112912.7046178p2b4mg53s@horde.metu.edu.tr>
	<alpine.LRH.2.00.1006111347160.20024@reclus.nhh.no>
Message-ID: <20100611162542.46972up109crqi52@horde.metu.edu.tr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100611/68ed39ec/attachment.pl>

From julien.beguin.1 at ulaval.ca  Fri Jun 11 20:15:35 2010
From: julien.beguin.1 at ulaval.ca (Julien Beguin)
Date: Fri, 11 Jun 2010 14:15:35 -0400
Subject: [R-sig-Geo] variogram with nominal data
Message-ID: <B56D7C27B4408243B93FBC46ABECB5A0011A8CFBC7A2@EXCH-MBX-F.ulaval.ca>

Dear list,

I would like to evaluate spatial dependence for about 10000 spatial data points. However, the variable associated with those points is not continuous as in the data "meuse" but is a land cover type (e.g. WATER). What should I consider as variable Z in the variogram() function with gstat? is it right to take the ID of each point as in the code below?    
-----------------------------------------------------------------------------
Z <- data.frame[ which(data.frame$landcover=='WATER'),]$ID
X <- frame$X
Y <- frame$Y
mydata1 <- data.frame(Z, X, Y);
coordinates(mydata1) <- c("X", "Y");
vario01 <- variogram(Z~1, mydata1, cutoff=50000, alpha=c(0,45,90,135))
------------------------------------------------------------------------------

Any advice would be very appreciated. Thank you for your time,

Julien Beguin
------------------
Ph.D. student
Laval University
Qu?bec, Canada
  

From ashton at msu.edu  Sat Jun 12 05:16:18 2010
From: ashton at msu.edu (ashton at msu.edu)
Date: Fri, 11 Jun 2010 23:16:18 -0400
Subject: [R-sig-Geo] variogram with nominal data
In-Reply-To: <B56D7C27B4408243B93FBC46ABECB5A0011A8CFBC7A2@EXCH-MBX-F.ulaval.ca>
References: <B56D7C27B4408243B93FBC46ABECB5A0011A8CFBC7A2@EXCH-MBX-F.ulaval.ca>
Message-ID: <20100611231618.11014b3icjomqjnm@mail.msu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100611/fcaea2f6/attachment.pl>

From Roger.Bivand at nhh.no  Sat Jun 12 07:02:31 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 12 Jun 2010 07:02:31 +0200 (CEST)
Subject: [R-sig-Geo] GWR Analysis
In-Reply-To: <20100611162542.46972up109crqi52@horde.metu.edu.tr>
References: <20100611112912.7046178p2b4mg53s@horde.metu.edu.tr>
	<alpine.LRH.2.00.1006111347160.20024@reclus.nhh.no>
	<20100611162542.46972up109crqi52@horde.metu.edu.tr>
Message-ID: <alpine.LRH.2.00.1006120656100.22837@reclus.nhh.no>

On Fri, 11 Jun 2010, Pinar Aslantas Bostan wrote:

>
>
> Dear Roger,
>
> I tried with data frames instead of SPDF. I gave some details of names 
> and class types of datasets. Grid data has 31204 rows (first row is 
> column names) and 5 columns (Z,X,Y,V1,V2). Station data has 226 rows 
> (first row is column names) and 6 columns (PREC,Z,X,Y,V1,V2). I gave an 
> example about datasets below.

Please do try to read up on what is going on. Find out how variables may 
be treated as string not numeric on input, and converted into factors. Do 
report str() of the imported objects as I said last time. This will show 
if some numeric are really factors - this may happen for example if the 
locale thinks that ",", not "." is the decimal sign, or if there is any 
non-numeric character in a column. If need be put your data (or a subset 
with the same problem on a website and post the link. Please do try to use 
lm() and predict() on the lm output object to see whether the problem is 
reproduced there too.

Please also be aware that using GWR for prediction has no good basis 
anywhere for anything - and the standard errors should not be given any 
credibility. This is not what GWR is for at all.

Roger

>
> Grid data
> Z   X   Y   V1  V2
> 495 259725.32564500000 5010656.22353999000 44.15584946 53525.25605680000
> 621 264725.32564499800 5010656.22353999000 50.67575455 50139.84515760000
> 432 274725.32564499800 5010656.22353999000 58.62472534 44295.66734330000
> 418 279725.32564499800 5010656.22353999000 45.05175400 41966.14328090000
> 361 254725.32564500000 5005656.22353999000 37.61386871 60596.18505359990
>
> Station data
> PREC  Z X   Y   V1  V2
> 514.3522848 1039 410428.05168500000 4478786.07400999000 100.69618225 81321.18533050000
> 650.6115948 29 942127.25593400000 4409537.10120000000 7.64556551 34796.24442280000
> 690.1826088 614 1201166.68404000000 4496907.09750000000 39.14785004 212666.95252600000
> 427.7718516 1213 1080214.69930000000 4550293.99677000000 53.82775879 164788.61213900000
> 402.9552240 1197 525196.23761299900 4619486.48904000000 69.23021698 206901.35695100000
>
> And from the list Binbin lu send me a message, according to his advice I 
> don't write "station$" term while performing gwr.sel and gwr functions. 
> In this way gwr function has worked but gave a warning message. And when 
> I plot the predicted precipitation values of the grid there are some 
> negative values which should't be occur! It didn't calculate predicted 
> errors also.
>
> What do you mean with 'factor' and I don't know how to run the function 
> under debug.
>
> Thanks for your help.
> Pinar
>
> ###########################################################################
>> grid<-read.table("D:\\R\\dem.txt", header=TRUE)
>> station<-read.table("D:\\R\\station.txt", header=TRUE)
>
>> class(grid)
> [1] "data.frame"
>
>> class(station)
> [1] "data.frame"
>
>> names(grid)
> [1] "Z"  "X"  "Y"  "V1" "V2"
>
>> names(station)
> [1] "PREC" "Z"    "X"    "Y"    "V1"   "V2"
>
>> coordinates(station) <- c("X", "Y")
>> coordinates(grid) <- c("X", "Y")
>
>> bw=gwr.sel(PREC~Z+V1+V2,data=station,adapt=T)
>> gwr <-gwr(PREC~Z+V1+V2,data=station,adapt=bw, fit.points = grid, predict=T, se.fit=T, hatmatrix=T)
>
> Warning message:
> In gwr(PREC ~ Z + V1 + V2, data = station, adapt = bw, fit.points = grid,  :
>  standard errors set to NA, normalised RSS not available
>
> Alinti Roger Bivand <Roger.Bivand at nhh.no>
>
>> On Fri, 11 Jun 2010, Pinar Aslantas Bostan wrote:
>>
>>>
>>>
>>> Dear all,
>>>
>>> I want to make GWR analysis to predict precipitation distribution
>>> measured from 225 meteorological stations. I have three independent
>>> variables (Z, V1, V2). I want to obtain predictions on the grid
>>> dataset which has 31203 number of pixels. I gave some details about
>>> my datasets below. While performing GWR, I get error message: "new
>>> data matrix rows mismatch"
>>>
>>> How can I solve that problem?
>>
>> You need to provide the detailed output of traceback(), and probably
>> also run gwr() under debug() to see whether this is a data problem or
>> a code problem. Does gwr() work when predict=FALSE, and/or
>> predict=TRUE, se.fit=FALSE? The error message is generated when the
>> number of columns in the matrix of X variables is not the same in
>> data and and fit.points. Are the variables in both cases stored in
>> the same way? What do str(station.grid) and str(station) look like
>> before conversion to SPDF and after? Is one variable a factor in one
>> and numeric in the other? Running under debug() will let you check
>> what x and predx look like.
>>
>> If this sounds hard, consider putting your data on a website and
>> posting the link.
>>
>> Hope this helps,
>>
>> Roger
>>
>>>
>>> Thanks, Pinar.
>>>
>>> station.grid<-read.table("D:\\R\\dem.txt", header=TRUE)
>>> station<-read.table("D:\\R\\station.txt", header=TRUE)
>>>
>>> grid = SpatialPointsDataFrame(data=station.grid,
>>> coords=cbind(station.grid$X, station.grid$Y))
>>
>>> station = SpatialPointsDataFrame(data=station,
>>> coords=cbind(station$X,station$Y))
>>>
>>>> names(grid)
>>> [1] "Z" "X" "Y" "V1" "V2"
>>>> names(station)
>>> [1] "PREC" "Z" "X" "Y" "V1" "V2"
>>>
>>> bw=gwr.sel(PREC~station$Z+station$V1+station$V2,data=station,adapt=T)
>>
>>> gwr <-gwr(PREC ~ station$Z +
>> station$V1 + station$V2, data=station, adapt=bw, fit.points = grid,
>> predict=TRUE, se.fit=T)
>>>
>>> Error in gwr(PREC ~ station$Z + station$V1 + station$V2, data = station, :
>>> NEW DATA MATRiX ROWS MiSMATCH
>>>
>>> ----------------------------------------------------------------
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>
>
>
> ----------------------------------------------------------------
> This message was sent using IMP, the Internet Messaging Program.
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From vivacity at hotmail.sg  Sat Jun 12 09:11:05 2010
From: vivacity at hotmail.sg (v v)
Date: Sat, 12 Jun 2010 15:11:05 +0800
Subject: [R-sig-Geo] How to locate local minima points on a Krige-fitted
 surface?
In-Reply-To: <4C123460.6070705@geo.uu.nl>
References: <SNT113-W385A1202C4694FB0D1E340B5D90@phx.gbl>,
	<4C123460.6070705@geo.uu.nl>
Message-ID: <SNT113-W635993634FB979C8CE6233B5DA0@phx.gbl>


Hi, Paul,
 
Thank you for the reply. 
 
I have attempted to write some code to test out what you've suggested but ran into some errors.
 
library(fields)
k <- Krig(ozone$x, ozone$y, theta=20)
 
# define objective function 
kfunc <- function(para,k) {
  xcoord=para[1]
  ycoord=para[2]
 
  minimum <- NULL
  testpoint <- c(xcoord, ycoord)
  minimum <- predict(k, testpoint)
  return(minimum)
}
 
initialpar <- c(max(ozone$x), max(ozone$y))
initialpar 
 
# optimization
best <- optim(initialpar, kfunc, NULL, method = "BFGS", hessian=TRUE)
 
# Error in predict(k, testpoint) : argument "k" is missing, with no default
 
 
regards,
Jeff 

----------------------------------------
> Date: Fri, 11 Jun 2010 15:04:32 +0200
> From: p.hiemstra at geo.uu.nl
> To: vivacity at hotmail.sg
> CC: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] How to locate local minima points on a Krige-fitted surface?
>
> Dear Jeff,
>
> I think you cannot escape discretizing your kriging surface as there is
> no mathematical expression that captures the kriging surface. To use
> optim you could make an objective function that was two inputs, x and y
> location. The functions calls the fields package to estimate the kriging
> prediction at this point and returns it. This ofcourse assumes that the
> variogram model is known. You have to play with the settings of optim to
> get it working and prevent a local minimum. You could take a look at
> SANN (simulated anealing) which is part of optim.
>
> cheers,
> Paul
> 		 	   		  
_________________________________________________________________
Hotmail: Powerful Free email with security by Microsoft.
https://signup.live.com/signup.aspx?id=60969


From p.hiemstra at geo.uu.nl  Sat Jun 12 11:41:39 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Sat, 12 Jun 2010 11:41:39 +0200
Subject: [R-sig-Geo] How to locate local minima points on a Krige-fitted
 surface?
In-Reply-To: <SNT113-W635993634FB979C8CE6233B5DA0@phx.gbl>
References: <SNT113-W385A1202C4694FB0D1E340B5D90@phx.gbl>,
	<4C123460.6070705@geo.uu.nl>
	<SNT113-W635993634FB979C8CE6233B5DA0@phx.gbl>
Message-ID: <4C135653.50902@geo.uu.nl>

On 06/12/2010 09:11 AM, v v wrote:
> Hi, Paul,
>  
> Thank you for the reply. 
>  
> I have attempted to write some code to test out what you've suggested but ran into some errors.
>  
> library(fields)
> k <- Krig(ozone$x, ozone$y, theta=20)
>  
> # define objective function 
> kfunc <- function(para,k) {
>   xcoord=para[1]
>   ycoord=para[2]
>  
>   minimum <- NULL
>   
The command above is not needed.
>   testpoint <- c(xcoord, ycoord)
>   minimum <- predict(k, testpoint)
>   
btw, this predict command fails. I have no experience with Fields and no
time right now to find out why.
>   return(minimum)
> }
>  
> initialpar <- c(max(ozone$x), max(ozone$y))
> initialpar 
>  
> # optimization
> best <- optim(initialpar, kfunc, NULL, method = "BFGS", hessian=TRUE)
>   
The costfunction for optim needs k as an input, which you didn't pass
on. This passes on k:

best <- optim(initialpar, kfunc, NULL, k = k, method = "BFGS", hessian=TRUE)

But as I mentioned above, the predict for Fields still does not work.

cheers,
Paul
>  
> # Error in predict(k, testpoint) : argument "k" is missing, with no default
>  
>  
> regards,
> Jeff 
>
> ----------------------------------------
>   
>> Date: Fri, 11 Jun 2010 15:04:32 +0200
>> From: p.hiemstra at geo.uu.nl
>> To: vivacity at hotmail.sg
>> CC: r-sig-geo at stat.math.ethz.ch
>> Subject: Re: [R-sig-Geo] How to locate local minima points on a Krige-fitted surface?
>>
>> Dear Jeff,
>>
>> I think you cannot escape discretizing your kriging surface as there is
>> no mathematical expression that captures the kriging surface. To use
>> optim you could make an objective function that was two inputs, x and y
>> location. The functions calls the fields package to estimate the kriging
>> prediction at this point and returns it. This ofcourse assumes that the
>> variogram model is known. You have to play with the settings of optim to
>> get it working and prevent a local minimum. You could take a look at
>> SANN (simulated anealing) which is part of optim.
>>
>> cheers,
>> Paul
>> 		 	   		  
>>     
> _________________________________________________________________
> Hotmail: Powerful Free email with security by Microsoft.
> https://signup.live.com/signup.aspx?id=60969
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From p.hiemstra at geo.uu.nl  Sat Jun 12 20:29:23 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Sat, 12 Jun 2010 20:29:23 +0200
Subject: [R-sig-Geo] How to extract coordinates values from a shapefile?
In-Reply-To: <4C120546.4030309@geo.uu.nl>
References: <EEBF95B6-EE20-40CE-BEF7-3690DA4AC9D8@gmail.com>	<4C0FF869.4010804@uni-muenster.de>	<AANLkTinkp4xo5ZRX0iy_fFZ3E14167DEYFYtOBPre2uO@mail.gmail.com>	<201006091401.50501.dylan.beaudette@gmail.com>
	<4C120546.4030309@geo.uu.nl>
Message-ID: <4C13D203.5040308@geo.uu.nl>

On 06/11/2010 11:43 AM, Paul Hiemstra wrote:
> On 06/09/2010 11:01 PM, Dylan Beaudette wrote:
>> On Wednesday 09 June 2010, Hadley Wickham wrote:
>>> On Wed, Jun 9, 2010 at 3:24 PM, Edzer Pebesma
>>>
>>> <edzer.pebesma at uni-muenster.de>  wrote:
>>>> The example provided by Matt assumes that each polygon consists of a
>>>> single ring, and doesn't have islands, lakes etc. The function below
>>>> pasts all coordinates to a single 2-column matrix. For clarity's 
>>>> sake, I
>>>> avoided nested sapply's.
>>>>
>>>> library(maptools)
>>>> xx<- readShapePoly(system.file("shapes/sids.shp",
>>>> package="maptools")[1], IDvar="FIPSNO", proj4string=CRS("+proj=longlat
>>>> +ellps=clrk66")) allcoordinates = function(x) {
>>>>     ret = NULL
>>>>     polys = x at polygons
>>>>     for(i in 1:length(polys)) {
>>>>         pp = polys[[i]]@Polygons
>>>>         for (j in 1:length(pp))
>>>>             ret = rbind(ret, coordinates(pp[[j]]))
>>>>     }
>>>>     ret
>>>> }
>>>> q = allcoordinates(xx)
>>>>
>>>> # check:
>>>> plot(xx)
>>>> lines(q, col='blue')
>>> And that's basically what fortify does, except it covers a few more 
>>> cases.
>>>
>>> Hadley
>> Not to be nit-picky, but wouldn't it be safer to pre-allocated "ret" 
>> instead
>> of dynamically appending? This would allow the suggested function to 
>> scale to
>> very large geometries.
> In addition to my previous suggestion, I tried using lapply + do.call 
> instead of the for loop based implementation of edzer:
>
> library(maptools)
> xx<- readShapePoly(system.file("shapes/sids.shp", 
> package="maptools")[1], IDvar="FIPSNO", proj4string=CRS("+proj=longlat 
> +ellps=clrk66"))
>
> allcoordinates = function(x) {
>     ret = NULL
>     polys = x at polygons
>     for(i in 1:length(polys)) {
>         pp = polys[[i]]@Polygons
>         for (j in 1:length(pp))
>             ret = rbind(ret, coordinates(pp[[j]]))
>     }
>     ret
> }
>
> allcoordinates_lapply = function(x) {
>     polys = x at polygons
>     return(do.call("rbind", lapply(polys, function(pp) {
>     do.call("rbind", lapply(pp at Polygons, coordinates))
>     })))
> }
More information on why this is so much faster can be found in the R 
Inferno Chapter 2, this gives a good description of what goes wrong in 
the background when growing an R object.

http://www.burns-stat.com/pages/Tutor/R_inferno.pdf

The following basic R code also provides some info:

# Just letting the object grow
# without preallocation
meth1 = function(n) {
   vec <- numeric(0);
   for(i in 1:n) vec <- c(vec, i)
}

# preallocation
meth2 = function(n) {
   vec <- numeric(n)
   for(i in 1:n) vec[i] <- i
}

# Direct creation
# Not relevant for the
# above case
meth3 = function(n) {
   vec <- 1:n
}

# The suggestion I did
# with do.call and lapply
meth4 = function(n) {
   do.call("c", lapply(1:n, function(x) x))
}

n = 100000
# Speed test
system.time(meth1(n)) # Slooooow
system.time(meth2(n))
system.time(meth3(n))
system.time(meth4(n))

cheers,
Paul

>
> q = allcoordinates(xx)
> z = allcoordinates_lapply(xx)
> all.equal(q,z)
>
> So far it produces the same output. And now comes the nice part, doing 
> a test with a large polygon set and timing the performance of both 
> functions:
>
> > system.time(x <- allcoordinates(nuts))
>    user  system elapsed
>  22.781   8.572  31.422
> > system.time(y <- allcoordinates_lapply(nuts))
>    user  system elapsed
>   0.248   0.004   0.250
> > all.equal(x,y)
> [1] TRUE
>
> So apart from the imo nicer looking function in terms of syntax, it is 
> also several orders of magnitude faster. This effect will only become 
> stronger if the polygon set becomes larger. So, lapply + do.call is 
> your friend :).
>
> cheers,
> Paul
>
> > sessionInfo()
> R version 2.11.0 (2010-04-22)
> i486-pc-linux-gnu
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] maptools_0.7-34 lattice_0.18-5  sp_0.9-62       foreign_0.8-40
>
> loaded via a namespace (and not attached):
> [1] grid_2.11.0
>
>>
>> Cheers,
>> Dylan
>>
>>
>>
>
>


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From macq at llnl.gov  Sun Jun 13 02:05:01 2010
From: macq at llnl.gov (Don MacQueen)
Date: Sat, 12 Jun 2010 17:05:01 -0700
Subject: [R-sig-Geo] Combining multiple polylines into a single polyline
Message-ID: <p06240800c839c78b9d96@[128.115.67.9]>

I have an input shapefile representing roads in a city, read into R 
where it becomes a SpatialLInesDataFrame.

Looking at just one road at a time, it looks fine when plotted. But 
in the underlying structure, the single real-world road has been 
broken up into many shorter polylines, and they are not included in 
the "correct" order, i.e., end to end.

When I sample along the road using spsample() with type='regular', 
the points aren't equally spaced. I assumed this was because it is 
broken up into separate lines. So I thought to combine the many short 
polylines into a single long polyline, i.e., matching endpoints of 
one polyline with the beginning of the next, dropping redundant 
nodes, and creating a new SLDF object.

I'm wondering if there's already an algorithm for this somewhere (in 
R or GRASS, preferably!).
(That's my main question)


However, in my toy example below, consisting of just three polylines 
making up a single road, spsample() does appear to equally space the 
points along the entire length. So perhaps my real roads have some 
other structural problem. Perhaps some endpoints don't match.

Thanks
-Don

Here's a toy example:

l1 <- matrix(c(1,1, 6,6, 4,8), byrow=TRUE, ncol=2)
l2 <- matrix(c(4,8, 7,9), byrow=TRUE, ncol=2)
l3 <- matrix(c(7,9, 11,10, 13,13), byrow=TRUE, ncol=2)

LL1 <- Lines( list( Line(l1)) , ID='32')
LL2 <- Lines( list( Line(l2)) , ID='147')
LL3 <- Lines( list( Line(l3)) , ID='21')

## deliberately constructed out of order
SL <- SpatialLines( list( LL2, LL3, LL1) )
df <- data.frame( name=rep('Road',3))
row.names(df) <- c('147','21','32')
SLDF <- SpatialLinesDataFrame( SL, df)

## I would like to reduce to a structure like this:
lc <- rbind(l1 , l2[-1,] , l3[-1,])
df1 <- data.frame( name='Road')
row.names(df1) <- 'a'
SLDFfix <- SpatialLinesDataFrame( SpatialLines( list( Lines( list( 
Line(lc)) , ID='a'))) , df1)

-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
925-423-1062


From edzer.pebesma at uni-muenster.de  Sun Jun 13 10:40:15 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 13 Jun 2010 10:40:15 +0200
Subject: [R-sig-Geo] variogram with nominal data
In-Reply-To: <20100611231618.11014b3icjomqjnm@mail.msu.edu>
References: <B56D7C27B4408243B93FBC46ABECB5A0011A8CFBC7A2@EXCH-MBX-F.ulaval.ca>
	<20100611231618.11014b3icjomqjnm@mail.msu.edu>
Message-ID: <4C14996F.3030806@uni-muenster.de>

Indeed, the usual approach is to use multiple indicators. You'll find an
example for different thresholds of a continuous variable in the end of
the following demo script.

library(gstat)
demo(cokriging)
--
Edzer

On 06/12/2010 05:16 AM, ashton at msu.edu wrote:
> Hi Julian, and list,
> 
> the variogram calculates the average squared difference between z-values separated by particular lags. Calculating differences with nominal data, and certainly IDs, is wrong. You will get results, but garbage in, garbage out applies here.
> 
> That said, you can calculate indicator variograms on nominal data. See a recent paper by Ola Ahqvist and myself, or other papers, mostly in soil science. (What fun to self-cite!): 
> Spatial and semantic dimensions of landscape heterogeneity, Landscape Ecology (2010).
> 
> I don't think the gstat variogram functionality for nominal data extends to more than two binary classes, but is not hard to implement more than that. I have R script on my machine at work if you would be interested.
> 
> Hope this helps,
> 
> Ashton Shortridge
> 
> Quoting Julien Beguin <julien.beguin.1 at ulaval.ca>:
> 
>> Dear list,
>>
>> I would like to evaluate spatial dependence for about 10000 spatial 
>> data points. However, the variable associated with those points is 
>> not continuous as in the data "meuse" but is a land cover type (e.g. 
>> WATER). What should I consider as variable Z in the variogram() 
>> function with gstat? is it right to take the ID of each point as in 
>> the code below?
>> -----------------------------------------------------------------------------
>> Z <- data.frame[ which(data.frame$landcover=='WATER'),]$ID
>> X <- frame$X
>> Y <- frame$Y
>> mydata1 <- data.frame(Z, X, Y);
>> coordinates(mydata1) <- c("X", "Y");
>> vario01 <- variogram(Z~1, mydata1, cutoff=50000, alpha=c(0,45,90,135))
>> ------------------------------------------------------------------------------
>>
>> Any advice would be very appreciated. Thank you for your time,
>>
>> Julien Beguin
>> ------------------
>> Ph.D. student
>> Laval University
>> Qu?bec, Canada
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
> 	[[alternative HTML version deleted]]
> 
> 
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From cheluna at gmail.com  Sun Jun 13 17:50:04 2010
From: cheluna at gmail.com (Consuelo Hermosilla)
Date: Sun, 13 Jun 2010 11:50:04 -0400
Subject: [R-sig-Geo] randtest.enfa {adehabitat} -- erratum in
	calculating the tolerance
In-Reply-To: <4C0F5BD9.1090407@gmail.com>
References: <AANLkTil0kDMR7-fU1q6W_2LmfxXZF0Pfa4kYjy2nguxm@mail.gmail.com> 
	<4C08A8C1.6020206@gmail.com>
	<AANLkTimRDvD7_pRN7XpgEPitMa4Uw_qvJbxeukp9ytqn@mail.gmail.com> 
	<4C0CAEFD.6090403@gmail.com>
	<AANLkTilQVEvXngVkyXYUWejPrqm_yZO5CKjVxA-Kp0I2@mail.gmail.com> 
	<4C0E8771.6040809@ase-research.org> <4C0F3D52.9010002@gmail.com> 
	<4C0F5BD9.1090407@gmail.com>
Message-ID: <AANLkTimb3H7ouRircJVr4BcDFb-7xCdjSz3yhscxqlsO@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100613/a225fbf3/attachment.pl>

From rundel at gmail.com  Mon Jun 14 03:25:43 2010
From: rundel at gmail.com (Colin Rundel)
Date: Sun, 13 Jun 2010 18:25:43 -0700
Subject: [R-sig-Geo] rgeos and Google Summer of Code
Message-ID: <F82A6905-9397-46BF-A544-FBA262A71453@gmail.com>

The rgeos package has been accepted as part of the Google Summer of Code and is currently under active development. Between myself and Roger Bivand we have made a good deal of progress and are very close to a point where the package will be usable (for the more adventurous). It is our goal to have a complete implementation of all GEOS functionality as well as replacement functions for gpclib (along with complete documentation and a vignette) by late august when the GSoC program ends.

There is currently a post introducing the package on the R GSoC blog at http://gsoc2010r.wordpress.com/ (which also has updates for other R GSoC projects). If you are interested in using this package in the near term additional updates and examples will be posted to the blog as development continues.

We are very much interested in suggestions, comments, bug reports, etc. and we would appreciate feedback of any kind.

-Colin


From thi_veloso at yahoo.com.br  Mon Jun 14 05:05:28 2010
From: thi_veloso at yahoo.com.br (Thiago Veloso)
Date: Sun, 13 Jun 2010 20:05:28 -0700 (PDT)
Subject: [R-sig-Geo] How to extract coordinates values from a shapefile?
In-Reply-To: <4C0FF869.4010804@uni-muenster.de>
Message-ID: <263550.98378.qm@web54306.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100613/1e2f59c3/attachment.pl>

From Rosi.Siber at eawag.ch  Mon Jun 14 13:54:00 2010
From: Rosi.Siber at eawag.ch (Siber Rosi)
Date: Mon, 14 Jun 2010 13:54:00 +0200
Subject: [R-sig-Geo] Import .gz-File
Message-ID: <B422D84F52D1C049B0D1B522E618C17702250C6EE6CA@EAW-EXC-MAIL.eawag.wroot.emp-eaw.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100614/b38ef855/attachment.pl>

From Roger.Bivand at nhh.no  Mon Jun 14 17:27:49 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 14 Jun 2010 17:27:49 +0200 (CEST)
Subject: [R-sig-Geo] Import .gz-File
In-Reply-To: <B422D84F52D1C049B0D1B522E618C17702250C6EE6CA@EAW-EXC-MAIL.eawag.wroot.emp-eaw.ch>
References: <B422D84F52D1C049B0D1B522E618C17702250C6EE6CA@EAW-EXC-MAIL.eawag.wroot.emp-eaw.ch>
Message-ID: <alpine.LRH.2.00.1006141724520.531@reclus.nhh.no>

On Mon, 14 Jun 2010, Siber Rosi wrote:

> Dear all, Is it possible to import Esri ascii files which are compressed 
> in a .gz file direct to R?  My example : 111212.asc in an .gz File I 
> thought there might be a similar command as the "zip.file.extract"- 
> command.  I tried the "gzfile" command, but it did not work. Do you have 
> any suggestions?

The readGDAL command in rgdal needs a file, I believe, as also does 
readAsciiGrid() in maptools. The header is part of the same file, so it 
needs to be read in different ways, first to get the metadata, then to 
read the data.

Roger

> Thank you very much in advance.
> Best wishes, Rosi
>
>
> ???
> Rosi Siber
> Swiss Federal Institute of Aquatic Science and Technology (Eawag)
> Siam
> Ueberlandstrasse 133
> 8600 Duebendorf
> Switzerland
> Phone: +41 (0)44 823 5566
> Fax:   +41 (0)44 823 5375
> rosi.siber at eawag.ch
> http://www.eawag.ch/~siberros
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From hamid200356 at yahoo.com  Mon Jun 14 17:42:02 2010
From: hamid200356 at yahoo.com (Hamid)
Date: Mon, 14 Jun 2010 08:42:02 -0700 (PDT)
Subject: [R-sig-Geo] Test fro CSR
Message-ID: <63450.99594.qm@web63802.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100614/87b2f131/attachment.pl>

From lestes at princeton.edu  Mon Jun 14 18:14:36 2010
From: lestes at princeton.edu (Lyndon Estes)
Date: Mon, 14 Jun 2010 12:14:36 -0400
Subject: [R-sig-Geo] Advice on GLS on residual variogram?
Message-ID: <AANLkTintjBG78yXTcW-EeAu3g08VuUOk5uniLne6rpY4@mail.gmail.com>

Hello,

I am attempting to implement regression kriging, following methods
recommended by Hengl et al. (2007; and others), for % soil organic
carbon over South Africa. I was hoping to ask for advice as to whether
the results I am getting from GLS make sense.

For background, I have 3300+ soil profiles providing A horizon OC %,
and I have derived 8 spatial predictors including slope, solar
radiation, a topographic moisture index, etc. These have been
transformed using principal components analysis (in ArcGIS).

My question concerns variograms resulting from the first component of
the methodology, which is to find the coefficients and residuals of a
GLS model as follows:

1. Use OLS to fit my model:

oc<-read.dbf('~/oc/ocdat.dbf')
oc_2<-as.data.frame(oc[,c(2,5:6,21:27,207:225)])

gls.all<-gls(log(CTOP)~PCB1+PCB2+PCB3+PCB4+PCB5+PCB6+PCB8,data=oc_2)
# Note: GLS is OLS if correlation structure is not specified

2. Find the GLS coefficients (and residuals) using an appropriate
autocorrelation structure. In this case, fitting a variogram to the
OLS residuals suggested a spherical autocorrelation structure:

gls.all.update<-update(gls.all,correlation=corSpher(form=~X+Y,nugget=TRUE))

Step 2 took a long time to complete, given my dataset--an overnight
run (not sure how many hours though) using 64-bit R2.10.1 on a MacBook
Pro with a 2.4 GHZ processor and 4 GB of RAM. I am not sure that the
results make sense, however, as the GLS shows greater autocorrelation
in the residuals then the original OLS residuals. The following
produced the illustration of the plotted residual variograms posted
here (http://sites.google.com/site/ldemisc/variogram):

# Fit variograms to residuals of OLS and GLS
oc.var<-variogram(residuals(gls.all)~1,oc_2)
oc.var.update<-variogram(residuals(gls.all.update)~1,oc_2)

# Create variograms plots
oc.var.update.pl<-plot(oc.var.update,main="GLS residuals")
oc.var.pl<-plot(oc.var,main="OLS residuals")

# Display variograms side-by-side
oc.var.pl$x.limits<-oc.var.update.pl$x.limits
oc.var.pl$y.limits<-oc.var.update.pl$y.limits
print(oc.var.pl,split=c(1,1,2,1),more=TRUE)
print(oc.var.update.pl,split=c(2,1,2,1),more=FALSE)

Does it seem sensible that GLS residuals show a stronger degree of
spatial autocorrelation (with no sign of a sill) than OLS? For
comparison with another spatially autocorrelated dataset, I used the
meuse dataset (following an example from Hengl 2009) with the models:

data(meuse)
coordinates(meuse)=~x+y
meu.ols<-gls(log(zinc)~dist.m+ffreq,meuse)
meu.gls<-update(meu.ols,correlation=corExp(form=~x+y))

Plotting the variograms:

zinc.vgmOLS<-variogram(residuals(meu.ols)~1,meuse)
ols.vgm.pl<-plot(zinc.vgmOLS,main="OLS plot")

zinc.vgm.GLS<-variogram(residuals(meu.gls)~1,meuse)
gls.vgm.pl<-plot(zinc.vgm.GLS,main="GLS plot")

# Display variograms side-by-side
ols.vgm.pl$x.limits<-gls.vgm.pl$x.limits
ols.vgm.pl$y.limits<-gls.vgm.pl$y.limits
print(ols.vgm.pl,split=c(1,1,2,1),more=TRUE)
print(gls.vgm.pl,split=c(2,1,2,1),more=FALSE)

In contrast, this shows nearly identical spatial autocorrelation
patterns for OLS and GLS.

I would greatly appreciate any advice regarding the (seemingly)
unusual variogram results, and/or clearing up of any misunderstandings
I might have.

Thanks in advance.

Regards, Lyndon


Hengl, T., G.B.M. Heuvelink, and D.G. Rossiter. 2007. About
regression-kriging: From equations to case studies. Computers &
Geosciences 33, no. 10 (October): 1301-1315.

Hengl, T. 2009. A Practical Guide to Geostatistical Mapping.
Luxembourg: Office for Official Publications of the European
Communities.


From edzer.pebesma at uni-muenster.de  Mon Jun 14 18:24:04 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 14 Jun 2010 18:24:04 +0200
Subject: [R-sig-Geo] How to extract coordinates values from a shapefile?
In-Reply-To: <263550.98378.qm@web54306.mail.re2.yahoo.com>
References: <263550.98378.qm@web54306.mail.re2.yahoo.com>
Message-ID: <4C1657A4.5050204@uni-muenster.de>

long = q[,1]
lat  = q[,2]

On 06/14/2010 05:05 AM, Thiago Veloso wrote:
>   This function worked like a charm, but I can't individually invoke the columns which contain the coordinates of variable "q".
>> names(q)NULL
>   For example, I need to plot the coordinates using polygon function, whose help tells us that "?polygon? draws the polygons whose vertices are given in ?x? and ?y?".
>   So, I'd like to be able to refer to lon and lat columns of variable "q" as "q$lon" and "q$lat".
>   Is it possible??
>   Best wishes,
>   Thiago.
> 
> --- On Wed, 9/6/10, Edzer Pebesma <edzer.pebesma at uni-muenster.de> wrote:
> 
> From: Edzer Pebesma <edzer.pebesma at uni-muenster.de>
> Subject: Re: [R-sig-Geo] How to extract coordinates values from a shapefile?
> To: r-sig-geo at stat.math.ethz.ch
> Date: Wednesday, 9 June, 2010, 17:24
> 
> The example provided by Matt assumes that each polygon consists of a
> single ring, and doesn't have islands, lakes etc. The function below
> pasts all coordinates to a single 2-column matrix. For clarity's sake, I
> avoided nested sapply's.
> 
> library(maptools)
> xx <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1],
>   IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
> allcoordinates = function(x) {
>     ret = NULL
>     polys = x at polygons
>     for(i in 1:length(polys)) {
>         pp = polys[[i]]@Polygons
>         for (j in 1:length(pp))
>             ret = rbind(ret, coordinates(pp[[j]]))
>     }
>     ret
> }
> q = allcoordinates(xx)
> 
> # check:
> plot(xx)
> lines(q, col='blue')
> 
> 
> On 06/09/2010 09:58 PM, Matt Beard wrote:
>>>
>>> library(maptools)
>>>
>>> # A simple way to print out a list of coordinates for each polygon in your
>>> shapefile:
>>>
>>> # Path and filename of polygon shapefile
>>> testfile <- '/media/PKBACK# 001/FNR210/QGISLab/habitats/habitats.shp'
>>>
>>> # Read in polygon shapefile using handy maptools function
>>> test <- readShapePoly(testfile)
>>>
>>> # Extract the list of Polygons objects
>>> polys <- slot(test,"polygons")
>>>
>>> # Within each Polygons object
>>> #    Extract the Polygon list (assuming just one per Polygons)
>>> #    And Extract the coordinates from each Polygon
>>> for (i in 1:length(polys)) {
>>>     print(paste("Polygon #",i))
>>>     print(slot(slot(polys[[i]],"Polygons")[[1]],"coords"  ))
>>> }
>>>
>>>
>>
>>     [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From katakagi at bu.edu  Mon Jun 14 18:30:51 2010
From: katakagi at bu.edu (Kenneth Takagi)
Date: Mon, 14 Jun 2010 12:30:51 -0400
Subject: [R-sig-Geo] Import .gz-File
In-Reply-To: <alpine.LRH.2.00.1006141724520.531@reclus.nhh.no>
References: <B422D84F52D1C049B0D1B522E618C17702250C6EE6CA@EAW-EXC-MAIL.eawag.wroot.emp-eaw.ch>
	<alpine.LRH.2.00.1006141724520.531@reclus.nhh.no>
Message-ID: <4C16593B.3080307@bu.edu>

Rosi,

Try this:
#unzip "temp.gz" files and save file as "temp.txt":
   gunzip(filename = "temp.gz", remove = T, overwrite = T, destname = 
"temp.txt")
#now read in "temp.txt" as SpatialGridDataFrame
   SGDF = read.asciigrid("temp1.txt", proj4string = CRS("+init=epsg:4322"))

This assumes that "temp.txt" is a ascii grid file.
HTH,
Ken
On 6/14/2010 11:27 AM, Roger Bivand wrote:
> On Mon, 14 Jun 2010, Siber Rosi wrote:
>
>> Dear all, Is it possible to import Esri ascii files which are
>> compressed in a .gz file direct to R? My example : 111212.asc in an
>> .gz File I thought there might be a similar command as the
>> "zip.file.extract"- command. I tried the "gzfile" command, but it did
>> not work. Do you have any suggestions?
>
> The readGDAL command in rgdal needs a file, I believe, as also does
> readAsciiGrid() in maptools. The header is part of the same file, so it
> needs to be read in different ways, first to get the metadata, then to
> read the data.
>
> Roger
>
>> Thank you very much in advance.
>> Best wishes, Rosi
>>
>>
>> ???
>> Rosi Siber
>> Swiss Federal Institute of Aquatic Science and Technology (Eawag)
>> Siam
>> Ueberlandstrasse 133
>> 8600 Duebendorf
>> Switzerland
>> Phone: +41 (0)44 823 5566
>> Fax: +41 (0)44 823 5375
>> rosi.siber at eawag.ch
>> http://www.eawag.ch/~siberros
>>
>>
>>
>>
>>
>>
>> [[alternative HTML version deleted]]
>>
>>
>


From katakagi at bu.edu  Mon Jun 14 19:04:07 2010
From: katakagi at bu.edu (Kenneth Takagi)
Date: Mon, 14 Jun 2010 13:04:07 -0400
Subject: [R-sig-Geo] Import .gz-File
In-Reply-To: <4C16593B.3080307@bu.edu>
References: <B422D84F52D1C049B0D1B522E618C17702250C6EE6CA@EAW-EXC-MAIL.eawag.wroot.emp-eaw.ch>	<alpine.LRH.2.00.1006141724520.531@reclus.nhh.no>
	<4C16593B.3080307@bu.edu>
Message-ID: <4C166107.4030607@bu.edu>

Rosi,
I forgot to add that you need to install package "GEOquery" first to 
access gunzip function.

-Ken

On 6/14/2010 12:30 PM, Kenneth Takagi wrote:
> Rosi,
>
> Try this:
> #unzip "temp.gz" files and save file as "temp.txt":
> gunzip(filename = "temp.gz", remove = T, overwrite = T, destname =
> "temp.txt")
> #now read in "temp.txt" as SpatialGridDataFrame
> SGDF = read.asciigrid("temp1.txt", proj4string = CRS("+init=epsg:4322"))
>
> This assumes that "temp.txt" is a ascii grid file.
> HTH,
> Ken
> On 6/14/2010 11:27 AM, Roger Bivand wrote:
>> On Mon, 14 Jun 2010, Siber Rosi wrote:
>>
>>> Dear all, Is it possible to import Esri ascii files which are
>>> compressed in a .gz file direct to R? My example : 111212.asc in an
>>> .gz File I thought there might be a similar command as the
>>> "zip.file.extract"- command. I tried the "gzfile" command, but it did
>>> not work. Do you have any suggestions?
>>
>> The readGDAL command in rgdal needs a file, I believe, as also does
>> readAsciiGrid() in maptools. The header is part of the same file, so it
>> needs to be read in different ways, first to get the metadata, then to
>> read the data.
>>
>> Roger
>>
>>> Thank you very much in advance.
>>> Best wishes, Rosi
>>>
>>>
>>> ???
>>> Rosi Siber
>>> Swiss Federal Institute of Aquatic Science and Technology (Eawag)
>>> Siam
>>> Ueberlandstrasse 133
>>> 8600 Duebendorf
>>> Switzerland
>>> Phone: +41 (0)44 823 5566
>>> Fax: +41 (0)44 823 5375
>>> rosi.siber at eawag.ch
>>> http://www.eawag.ch/~siberros
>>>
>>>
>>>
>>>
>>>
>>>
>>> [[alternative HTML version deleted]]
>>>
>>>
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From kjetil1001 at gmail.com  Mon Jun 14 19:50:17 2010
From: kjetil1001 at gmail.com (Kjetil brinchmann Halvorsen)
Date: Mon, 14 Jun 2010 13:50:17 -0400
Subject: [R-sig-Geo] cokriging
Message-ID: <AANLkTil0YtDxa9h3dNFP0lf_oiv_z7dwBVywRf19YeLF@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100614/9c6f9401/attachment.pl>

From titli at vt.edu  Mon Jun 14 20:04:45 2010
From: titli at vt.edu (tannistha maiti)
Date: Mon, 14 Jun 2010 14:04:45 -0400
Subject: [R-sig-Geo] dataset extraction
Message-ID: <AANLkTinT6PfSTPICufU7E8X1ClKZkpK7bjOgucDTMw41@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100614/4c37775a/attachment.pl>

From Roger.Bivand at nhh.no  Mon Jun 14 21:15:26 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 14 Jun 2010 21:15:26 +0200 (CEST)
Subject: [R-sig-Geo] Import .gz-File
In-Reply-To: <4C166107.4030607@bu.edu>
References: <B422D84F52D1C049B0D1B522E618C17702250C6EE6CA@EAW-EXC-MAIL.eawag.wroot.emp-eaw.ch>
	<alpine.LRH.2.00.1006141724520.531@reclus.nhh.no>
	<4C16593B.3080307@bu.edu> <4C166107.4030607@bu.edu>
Message-ID: <alpine.LRH.2.00.1006142110570.1053@reclus.nhh.no>

On Mon, 14 Jun 2010, Kenneth Takagi wrote:

> Rosi,
> I forgot to add that you need to install package "GEOquery" first to access 
> gunzip function.

And a little but important detail - this is not a CRAN package but a 
BioConductor one:

http://bioconductor.org/packages/2.6/bioc/html/GEOquery.html

so will further require Biobase and RCurl. The GEO here means "Gene 
Expression Omnibus", rather than what one might expect.

Depending on your platform, you may also be able to use system() to call a 
freestanding archive program of your choice to decompress the *.gz file. 
This may be as easy as installing BioConductor packages, if you haven't 
done that before.

Roger

>
> -Ken
>
> On 6/14/2010 12:30 PM, Kenneth Takagi wrote:
>> Rosi,
>> 
>> Try this:
>> #unzip "temp.gz" files and save file as "temp.txt":
>> gunzip(filename = "temp.gz", remove = T, overwrite = T, destname =
>> "temp.txt")
>> #now read in "temp.txt" as SpatialGridDataFrame
>> SGDF = read.asciigrid("temp1.txt", proj4string = CRS("+init=epsg:4322"))
>> 
>> This assumes that "temp.txt" is a ascii grid file.
>> HTH,
>> Ken
>> On 6/14/2010 11:27 AM, Roger Bivand wrote:
>>> On Mon, 14 Jun 2010, Siber Rosi wrote:
>>> 
>>>> Dear all, Is it possible to import Esri ascii files which are
>>>> compressed in a .gz file direct to R? My example : 111212.asc in an
>>>> .gz File I thought there might be a similar command as the
>>>> "zip.file.extract"- command. I tried the "gzfile" command, but it did
>>>> not work. Do you have any suggestions?
>>> 
>>> The readGDAL command in rgdal needs a file, I believe, as also does
>>> readAsciiGrid() in maptools. The header is part of the same file, so it
>>> needs to be read in different ways, first to get the metadata, then to
>>> read the data.
>>> 
>>> Roger
>>> 
>>>> Thank you very much in advance.
>>>> Best wishes, Rosi
>>>> 
>>>> 
>>>> ???
>>>> Rosi Siber
>>>> Swiss Federal Institute of Aquatic Science and Technology (Eawag)
>>>> Siam
>>>> Ueberlandstrasse 133
>>>> 8600 Duebendorf
>>>> Switzerland
>>>> Phone: +41 (0)44 823 5566
>>>> Fax: +41 (0)44 823 5375
>>>> rosi.siber at eawag.ch
>>>> http://www.eawag.ch/~siberros
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> [[alternative HTML version deleted]]
>>>> 
>>>> 
>>> 
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From basille at ase-research.org  Mon Jun 14 21:44:52 2010
From: basille at ase-research.org (Mathieu Basille)
Date: Mon, 14 Jun 2010 15:44:52 -0400
Subject: [R-sig-Geo] randtest.enfa {adehabitat} -- erratum in
 calculating the tolerance
In-Reply-To: <AANLkTimb3H7ouRircJVr4BcDFb-7xCdjSz3yhscxqlsO@mail.gmail.com>
References: <AANLkTil0kDMR7-fU1q6W_2LmfxXZF0Pfa4kYjy2nguxm@mail.gmail.com>
	<4C08A8C1.6020206@gmail.com>
	<AANLkTimRDvD7_pRN7XpgEPitMa4Uw_qvJbxeukp9ytqn@mail.gmail.com>
	<4C0CAEFD.6090403@gmail.com>
	<AANLkTilQVEvXngVkyXYUWejPrqm_yZO5CKjVxA-Kp0I2@mail.gmail.com>
	<4C0E8771.6040809@ase-research.org>
	<4C0F3D52.9010002@gmail.com> <4C0F5BD9.1090407@gmail.com>
	<AANLkTimb3H7ouRircJVr4BcDFb-7xCdjSz3yhscxqlsO@mail.gmail.com>
Message-ID: <4C1686B4.2080801@ase-research.org>

Consuelo,

> Again, about the tolerance, using the code you told me:
> 
> pc3 <- dudi.pca(kasc2df(map)$tab, scan=FALSE)
> sum(dudi.pca(pc3$tab, scale=FALSE, row.w = 
> dataenfa1$pr/sum(dataenfa1$pr), scan=FALSE)$eig)
> 
> I got* 3.129783*, is this correct?

Yes it is. You can double check it with niche.test:

bla <- niche.test(map, lynxjura$locs[tmp, c("X", "Y")])
bla$obs
0.1450481 3.1297832

The first value is the marginality (same as in enfa1), the second one is 
the tolerance.

> But I don't understand, shouldn't tolerance have a value ranging from 0 
> to 1? I thougth that was the idea, since specialization varies from 1 to 
> infinite, right? [i.e. Reutter et al 2003***]

Not necessarily. But I guess you will find different definitions of 
(global) tolerance and (global) specialization according to different 
sources.

In any cases, I would not recommend the use of a *global* 
tolerance/specialization index, unless it is used to compare:

- two species in the same study area
- the same species in two periods, given that the environment does not 
change.

> In the other hand, I have estimated the global specializations using 
> Hirzel et al (2002) formula,  like this:
> 
> S <- (sqrt(sum(enfa1$s)))/1.96
>  
> Does it seem correct?

According to Hirzel et al. (2002)'s definition, it should be divided by 
the number of specialization axes. It is just the mean eigenvalue of 
specialization, which can be seen as a way to define a global 
specialization. Now, as I said before, it is difficult to use it as is.

> I got this value S = 0.996322 (<1 though), and then, my tolerance (1/S) 
> was 1.003692 (>1).
> 
> It bothers me that we don't have the same values! grrr

My guess: the S = 1/T relation only hold on one dimension, but not in 
the N-dimensions ecological space. Could be wrong, though. Anyway, 
Hirzel et al. (2002)'s definition of specialization cannot not be used 
in this context.

> What do you think?
> 
> About my other question about the scatter plot of enfa, the scores and 
> so on... I think I haven't been able to explain myself... I have 
> uploaded a picture http://img808.imageshack.us/i/scatter.jpg/. I hope 
> you can see what I mean there.

Now I see. The d=1 that you have in the upper-right corner just holds 
for the projection of pixels (simplified with the use of MCPs). Try the 
following:

 > scatter(enfa1, pts = TRUE)
 > summary(enfa1$li)

which should help. The arrows are just proportional to their real 
values, in order to adequately fit in the graph.

Regards,
Mathieu.


> Thanks again guys!!!
> 
> Consuelo
> 
> 
> *** Reutter, B.A,  V. Helfer, A.H. Hirzel1 & P. Vogel. 2003. Modelling 
> habitat-suitability using museum collections: an example with three 
> sympatric Apodemus species from the Alps. Journal of Biogeography, 30, 
> 581?590
> 
> -------------
> Consuelo Hermosilla
> PhD student
> Departamento de Ecolog?a y Biolog?a Animal
> Departamento de Bioqu?mica, Gen?tica e Inmunolog?a, ?rea de Gen?tica
> Facultad de Ciencias del Mar
> Campus de As Lagoas-Marcosende
> Universidad de Vigo
> 36310 Vigo
> SPAIN
> Mobile: +34 692 633 298
> 
> oooO
> (     ) Oooo
>    (   (     )
>   _)    )  /
>         (_/
> 
> Stop Gaza Massacre
> 
> 
> 2010/6/9 Cl?ment Calenge <clement.calenge at gmail.com 
> <mailto:clement.calenge at gmail.com>>
> 
>     On 06/09/2010 09:05 AM, Cl?ment Calenge wrote:
> 
> 
> 
>             sum(dudi.pca(kasc2df(map), row.w =
>             dataenfa1$pr/sum(dataenfa1$pr),
>             scan=FALSE)$eig)
> 
>             which gives you 5 only. The weights should sum to 1 (i.e.
>             they are
>             proportions). But then, how would you interpret this? This
>             is the same
>             as for the "global specialization".
> 
> 
>         Yes, but be careful: kasc2df returns a list with one component
>         "tab" (the component of interest) and one component "index" (the
>         component allowing to rebuild the original kasc), so that the
>         correct code is:
> 
>         sum(dudi.pca(kasc2df(map)$tab, row.w =
>         dataenfa1$pr/sum(dataenfa1$pr), scan=FALSE)$eig)
> 
> 
>     I was a bit too hasty for this reply. Actually the code is
>     incorrect. Consider the following code:
> 
>     pc <- dudi.pca(kasc2df(map)$tab, row.w = dataenfa1$pr/sum(dataenfa1$pr))
> 
>     This code performs a *centered and scaled* PCA of the environmental
>     variables: this analysis first centers and scales the table
>     containing the value of the environmental variables. Therefore, for
>     each variable of pc$tab, the mean *weighted by the utilization
>     weights* is equal to zero and the variance *weighted by the
>     utilization weights* is equal to 1. Therefore, the sum of the
>     eigenvalues of the PCA on this transformed table is equal to the
>     number of environmental variables. This code is incorrect (thanks
>     Mathieu for noting the inconsistency). First, to calculate the
>     global tolerance, you would need to calculate:
> 
>     pc <- dudi.pca(kasc2df(map)$tab, scan=FALSE)
> 
>     This preliminary analysis is performed just to center/scale the
>     variables with uniform weighting. This allows to compare the
>     different variables in pc$tab (they all have the same average and
>     the same scale). *Then*, calculate the weighted and *unscaled* PCA
>     of the table pc$tab:
> 
>     sum(dudi.pca(pc$tab, scale=FALSE, row.w =
>     dataenfa1$pr/sum(dataenfa1$pr), scan=FALSE)$eig)
> 
>     This gives the tolerance of the species on the area,
>     Sorry for the confusion,
>     HTH,
> 
>     Cl?ment Calenge
> 
>     -- 
>     Cl?ment CALENGE
>     Cellule d'appui ? l'analyse de donn?es
>     Office national de la chasse et de la faune sauvage
>     Saint Benoist - 78610 Auffargis
>     tel. (33) 01.30.46.54.14
> 
> 

-- 

~$ whoami
Mathieu Basille, Post-Doc

~$ locate
Laboratoire d'?cologie Comportementale et de Conservation de la Faune
+ Centre d'?tude de la For?t
D?partement de Biologie
Universit? Laval, Qu?bec

~$ info
http://ase-research.org/basille

~$ fortune
``If you can't win by reason, go for volume.''
Calvin, by Bill Watterson.


From alobolistas at gmail.com  Tue Jun 15 08:11:53 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Mon, 14 Jun 2010 23:11:53 -0700 (PDT)
Subject: [R-sig-Geo] rgeos and Google Summer of Code
In-Reply-To: <F82A6905-9397-46BF-A544-FBA262A71453@gmail.com>
References: <F82A6905-9397-46BF-A544-FBA262A71453@gmail.com>
Message-ID: <1276582313702-5180627.post@n2.nabble.com>


Excellent!

Many thanks for your contribution, I'm often missing
this type of functionality in current tools  in R.
The examples you provide in your web page
are very interesting. Whenever you have time, I'd appreciate an indicative
list of the high-level functionality to be expected once
your work is completed.

Have a nice a GSC!

Agus
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/rgeos-and-Google-Summer-of-Code-tp5175783p5180627.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From edzer.pebesma at uni-muenster.de  Tue Jun 15 08:27:38 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 15 Jun 2010 08:27:38 +0200
Subject: [R-sig-Geo] rgeos and Google Summer of Code
In-Reply-To: <F82A6905-9397-46BF-A544-FBA262A71453@gmail.com>
References: <F82A6905-9397-46BF-A544-FBA262A71453@gmail.com>
Message-ID: <4C171D5A.9080403@uni-muenster.de>

Colin, this looks very promising!

For some reason the r-forge pages don't show anymore how r-forge
packages can be installed. As they always did, I didn't bother to
remember. Could you tell us, so we can alpha test, and perhaps add this
to the rgeos page on r-forge? (Better would be someone repaired r-forge,
which seems to have broken layouts ever since the Vienna power crash)
--
Edzer


On 06/14/2010 03:25 AM, Colin Rundel wrote:
> The rgeos package has been accepted as part of the Google Summer of Code and is currently under active development. Between myself and Roger Bivand we have made a good deal of progress and are very close to a point where the package will be usable (for the more adventurous). It is our goal to have a complete implementation of all GEOS functionality as well as replacement functions for gpclib (along with complete documentation and a vignette) by late august when the GSoC program ends.
> 
> There is currently a post introducing the package on the R GSoC blog at http://gsoc2010r.wordpress.com/ (which also has updates for other R GSoC projects). If you are interested in using this package in the near term additional updates and examples will be posted to the blog as development continues.
> 
> We are very much interested in suggestions, comments, bug reports, etc. and we would appreciate feedback of any kind.
> 
> -Colin
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From b.rowlingson at lancaster.ac.uk  Tue Jun 15 09:14:54 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 15 Jun 2010 08:14:54 +0100
Subject: [R-sig-Geo] rgeos and Google Summer of Code
In-Reply-To: <4C171D5A.9080403@uni-muenster.de>
References: <F82A6905-9397-46BF-A544-FBA262A71453@gmail.com>
	<4C171D5A.9080403@uni-muenster.de>
Message-ID: <AANLkTikl-njdpozGyiIba_M7pgd3FNtV3XDWKaiofaOf@mail.gmail.com>

On Tue, Jun 15, 2010 at 7:27 AM, Edzer Pebesma
<edzer.pebesma at uni-muenster.de> wrote:

> For some reason the r-forge pages don't show anymore how r-forge
> packages can be installed. As they always did, I didn't bother to
> remember. Could you tell us, so we can alpha test, and perhaps add this
> to the rgeos page on r-forge? (Better would be someone repaired r-forge,
> which seems to have broken layouts ever since the Vienna power crash)

 If you go to the 'Packages' section of an R-forge project, you can see:

"""
To install this package directly within R type:
install.packages("rgeos", repos="http://R-Forge.R-project.org")
"""

 but yes, I'm fairly sure it used to say it on each main project page...

Barry


From Thierry.ONKELINX at inbo.be  Tue Jun 15 10:47:04 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 15 Jun 2010 10:47:04 +0200
Subject: [R-sig-Geo] Advice on GLS on residual variogram?
In-Reply-To: <AANLkTintjBG78yXTcW-EeAu3g08VuUOk5uniLne6rpY4@mail.gmail.com>
References: <AANLkTintjBG78yXTcW-EeAu3g08VuUOk5uniLne6rpY4@mail.gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A1040735BFE3@inboexch.inbo.be>

Dear Lyndon,

Have a look at the normalised residuals when creating a variogram. Those
take the correlation structure into account. And have a look at the
parameters of the correlation structure. Are they from a similar
magnitude as you would expect from the OLS variogram? If not, rerun the
GLS with starting values for range and sill based on the OLS variogram.
I had some strange results in the past with range parameters being
smaller than the smallest distance between two points. Supplying
reasonable starting values yielded better results.

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: r-sig-geo-bounces at stat.math.ethz.ch 
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens Lyndon Estes
> Verzonden: maandag 14 juni 2010 18:15
> Aan: r-sig-geo
> Onderwerp: [R-sig-Geo] Advice on GLS on residual variogram?
> 
> Hello,
> 
> I am attempting to implement regression kriging, following 
> methods recommended by Hengl et al. (2007; and others), for % 
> soil organic carbon over South Africa. I was hoping to ask 
> for advice as to whether the results I am getting from GLS make sense.
> 
> For background, I have 3300+ soil profiles providing A 
> horizon OC %, and I have derived 8 spatial predictors 
> including slope, solar radiation, a topographic moisture
> index, etc. These have been transformed using principal
> components analysis (in ArcGIS).
> 
> My question concerns variograms resulting from the first 
> component of the methodology, which is to find the 
> coefficients and residuals of a GLS model as follows:
> 
> 1. Use OLS to fit my model:
> 
> oc<-read.dbf('~/oc/ocdat.dbf')
> oc_2<-as.data.frame(oc[,c(2,5:6,21:27,207:225)])
> 
> gls.all<-gls(log(CTOP)~PCB1+PCB2+PCB3+PCB4+PCB5+PCB6+PCB8,data=oc_2)
> # Note: GLS is OLS if correlation structure is not specified
> 
> 2. Find the GLS coefficients (and residuals) using an
> appropriate autocorrelation structure. In this case, fitting 
> a variogram to the OLS residuals suggested a spherical 
> autocorrelation structure:
> 
> gls.all.update<-update(gls.all,correlation=corSpher(form=~X+Y,
> nugget=TRUE))
> 
> Step 2 took a long time to complete, given my dataset--an 
> overnight run (not sure how many hours though) using 64-bit 
> R2.10.1 on a MacBook Pro with a 2.4 GHZ processor and 4 GB of 
> RAM. I am not sure that the results make sense, however, as 
> the GLS shows greater autocorrelation in the residuals then 
> the original OLS residuals. The following produced the
> illustration of the plotted residual variograms posted here 
> (http://sites.google.com/site/ldemisc/variogram):
> 
> # Fit variograms to residuals of OLS and GLS
> oc.var<-variogram(residuals(gls.all)~1,oc_2)
> oc.var.update<-variogram(residuals(gls.all.update)~1,oc_2)
> 
> # Create variograms plots
> oc.var.update.pl<-plot(oc.var.update,main="GLS residuals") 
> oc.var.pl<-plot(oc.var,main="OLS residuals")
> 
> # Display variograms side-by-side
> oc.var.pl$x.limits<-oc.var.update.pl$x.limits
> oc.var.pl$y.limits<-oc.var.update.pl$y.limits
> print(oc.var.pl,split=c(1,1,2,1),more=TRUE)
> print(oc.var.update.pl,split=c(2,1,2,1),more=FALSE)
> 
> Does it seem sensible that GLS residuals show a stronger 
> degree of spatial autocorrelation (with no sign of a sill) 
> than OLS? For comparison with another spatially 
> autocorrelated dataset, I used the meuse dataset (following 
> an example from Hengl 2009) with the models:
> 
> data(meuse)
> coordinates(meuse)=~x+y
> meu.ols<-gls(log(zinc)~dist.m+ffreq,meuse)
> meu.gls<-update(meu.ols,correlation=corExp(form=~x+y))
> 
> Plotting the variograms:
> 
> zinc.vgmOLS<-variogram(residuals(meu.ols)~1,meuse)
> ols.vgm.pl<-plot(zinc.vgmOLS,main="OLS plot")
> 
> zinc.vgm.GLS<-variogram(residuals(meu.gls)~1,meuse)
> gls.vgm.pl<-plot(zinc.vgm.GLS,main="GLS plot")
> 
> # Display variograms side-by-side
> ols.vgm.pl$x.limits<-gls.vgm.pl$x.limits
> ols.vgm.pl$y.limits<-gls.vgm.pl$y.limits
> print(ols.vgm.pl,split=c(1,1,2,1),more=TRUE)
> print(gls.vgm.pl,split=c(2,1,2,1),more=FALSE)
> 
> In contrast, this shows nearly identical spatial 
> autocorrelation patterns for OLS and GLS.
> 
> I would greatly appreciate any advice regarding the 
> (seemingly) unusual variogram results, and/or clearing up of 
> any misunderstandings I might have.
> 
> Thanks in advance.
> 
> Regards, Lyndon
> 
> 
> Hengl, T., G.B.M. Heuvelink, and D.G. Rossiter. 2007. About
> regression-kriging: From equations to case studies. Computers 
> & Geosciences 33, no. 10 (October): 1301-1315.
> 
> Hengl, T. 2009. A Practical Guide to Geostatistical Mapping.
> Luxembourg: Office for Official Publications of the European 
> Communities.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.


From aslantas at metu.edu.tr  Tue Jun 15 11:16:03 2010
From: aslantas at metu.edu.tr (Pinar Aslantas Bostan)
Date: Tue, 15 Jun 2010 12:16:03 +0300
Subject: [R-sig-Geo] GWR Analysis
In-Reply-To: <alpine.LRH.2.00.1006120656100.22837@reclus.nhh.no>
References: <20100611112912.7046178p2b4mg53s@horde.metu.edu.tr>
	<alpine.LRH.2.00.1006111347160.20024@reclus.nhh.no>
	<20100611162542.46972up109crqi52@horde.metu.edu.tr>
	<alpine.LRH.2.00.1006120656100.22837@reclus.nhh.no>
Message-ID: <20100615121603.18427nwqdwldtccz@horde.metu.edu.tr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100615/0575eadf/attachment.pl>

From Tim.Haering at lwf.bayern.de  Tue Jun 15 11:50:28 2010
From: Tim.Haering at lwf.bayern.de (=?iso-8859-1?Q?H=E4ring=2C_Tim_=28LWF=29?=)
Date: Tue, 15 Jun 2010 11:50:28 +0200
Subject: [R-sig-Geo] georeferencing point shape
Message-ID: <70FC67C4A585D1489E66225A4E0238BA9371D9@RZS-EXC-CL06.rz-sued.bayern.de>

Hello !

I have a point shape containing field measurements in a small scale studyarea. Unfortunately these points didn`t have geographic or projected coordinates. The spatial reference for these points are theodolite measurements. For four corner points gps measurements of projected coordinates are available. I want to georeference my point shape in these projected coordinate system and have no idea how.
Here is a subset of my data:

x <- c(5.786, -3.766, -12.613, -21.836, -26.340, 3.958, -11.120, -17.266, -18.938,
  16.751, -21.507, 26.420, -19.916, 23.184, 9.660, -5.711, -18.256, 27.888, 12.634, -33.510)
y <- c(4.470, 0.797, -3.130, -7.656, -9.313, 8.700, 6.923, 8.545, 12.468, 4.748,
  -20.920, -5.396, -24.830, -11.636, 22.462, 19.210, -28.851, -9.510, 27.421, 8.035)
z <- c(1100.493, 1100.867, 1101.798, 1102.559, 1103.703, 1102.366, 1107.249, 1110.781,
 1113.920, 1096.967, 1095.284, 1088.956, 1092.869, 1086.786, 1101.300, 1110.197, NA, NA, NA, NA)
gps_x <- c(NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA, 4560136, 4560184, 4560172, 4560121)
gps_y <- c(NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA, 5289465, 5289482, 5289521, 5289502)

d <- data.frame(x,y,z,gps_x,gps_y)
d
coordinates(d) = ~x+y
plot(d, axes=T)

gps_points <- d[17:20,]
points(gps_points, pch=19, col="red")

Because both measurements - the theodolite values and the gps values - are measured in meters, my first idea was to calculate the coordinates for all points by sum the difference between a gps point and every single theodolite point in x- and y-direction. Unfortunately there are little differences depending which gps point is used as basis.
Is there a better way to transform the point pattern into the projected coordinate system?
The proj4string for my coordinate system is:
+proj=tmerc +lat_0=0 +lon_0=12 +k=1 +x_0=4500000 +y_0=0 +ellps=bessel +units=m +no_defs

Thank you very much.

TIM



----------------------------------------------------------------------------------- 
Tim H?ring
Bavarian State Institute of Forestry 
Department of Forest Ecology
Hans-Carl-von-Carlowitz-Platz 1
D-85354 Freising

E-Mail: tim.haering at lwf.bayern.de
http://www.lwf.bayern.de


From tom.gottfried at wzw.tum.de  Tue Jun 15 12:17:05 2010
From: tom.gottfried at wzw.tum.de (Tom Gottfried)
Date: Tue, 15 Jun 2010 12:17:05 +0200
Subject: [R-sig-Geo] georeferencing point shape
In-Reply-To: <70FC67C4A585D1489E66225A4E0238BA9371D9@RZS-EXC-CL06.rz-sued.bayern.de>
References: <70FC67C4A585D1489E66225A4E0238BA9371D9@RZS-EXC-CL06.rz-sued.bayern.de>
Message-ID: <4C175321.5000405@wzw.tum.de>

Hi Tim,

> I have a point shape containing field measurements in a small scale studyarea. Unfortunately these
points didn`t have geographic or projected coordinates. The spatial reference for these points are
theodolite measurements. For four corner points gps measurements of projected coordinates are
available. I want to georeference my point shape in these projected coordinate system and have no
idea how.
> Here is a subset of my data:
>
> x <- c(5.786, -3.766, -12.613, -21.836, -26.340, 3.958, -11.120, -17.266, -18.938,
>   16.751, -21.507, 26.420, -19.916, 23.184, 9.660, -5.711, -18.256, 27.888, 12.634, -33.510)
> y <- c(4.470, 0.797, -3.130, -7.656, -9.313, 8.700, 6.923, 8.545, 12.468, 4.748,
>   -20.920, -5.396, -24.830, -11.636, 22.462, 19.210, -28.851, -9.510, 27.421, 8.035)
> z <- c(1100.493, 1100.867, 1101.798, 1102.559, 1103.703, 1102.366, 1107.249, 1110.781,
>  1113.920, 1096.967, 1095.284, 1088.956, 1092.869, 1086.786, 1101.300, 1110.197, NA, NA, NA, NA)
> gps_x <- c(NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA, 4560136, 4560184, 4560172, 4560121)
> gps_y <- c(NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA, 5289465, 5289482, 5289521, 5289502)
>
> d <- data.frame(x,y,z,gps_x,gps_y)
> d
> coordinates(d) = ~x+y
> plot(d, axes=T)
>
> gps_points <- d[17:20,]
> points(gps_points, pch=19, col="red")
>
> Because both measurements - the theodolite values and the gps values - are measured in meters, my
> first idea was to calculate the coordinates for all points by sum the difference between a gps
> point and every single theodolite point in x- and y-direction. Unfortunately there are little
> differences depending which gps point is used as basis.

If you can assume the little differences being due to the error in gps-measurements, you could
calculate your coordinates with all your gps points as a basis and then take the mean as final value.

Tom

> Is there a better way to transform the point pattern into the projected coordinate system?
> The proj4string for my coordinate system is:
> +proj=tmerc +lat_0=0 +lon_0=12 +k=1 +x_0=4500000 +y_0=0 +ellps=bessel +units=m +no_defs
>
> Thank you very much.
>
> TIM
>
>

-- 
Technische Universit?t M?nchen
Department f?r Pflanzenwissenschaften
Lehrstuhl f?r Gr?nlandlehre
Am Hochanger 1
85350 Freising / Germany
Phone: ++49 (0)8161 715324
Fax:   ++49 (0)8161 713243
email: tom.gottfried at wzw.tum.de
http://www.wzw.tum.de/gruenland


From Roger.Bivand at nhh.no  Tue Jun 15 12:37:39 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 15 Jun 2010 12:37:39 +0200 (CEST)
Subject: [R-sig-Geo] GWR Analysis
In-Reply-To: <20100615121603.18427nwqdwldtccz@horde.metu.edu.tr>
References: <20100611112912.7046178p2b4mg53s@horde.metu.edu.tr>
	<alpine.LRH.2.00.1006111347160.20024@reclus.nhh.no>
	<20100611162542.46972up109crqi52@horde.metu.edu.tr>
	<alpine.LRH.2.00.1006120656100.22837@reclus.nhh.no>
	<20100615121603.18427nwqdwldtccz@horde.metu.edu.tr>
Message-ID: <alpine.LRH.2.00.1006151235320.3716@reclus.nhh.no>

On Tue, 15 Jun 2010, Pinar Aslantas Bostan wrote:

>
>
> Dear Roger,
>
> Thank you for your advice. I performed lm() and predict(),the same problem is not produced that time. I created an attribute (voronoi) and set as factor for station and grid datasets. (I created voronoi polygons for station data. Each station has a voronoi code such a primary key variable. Then I made join operation between voronoi and grid, so each point at the grid data takes the attributes of the voronoi polygon if it falls inside. So that station and grid has the same voronoi codes) After setting voronoi attribute as factor, GWR analysis has worked and gave results. But this time it gives a warning message:
> In points2grid(points, tolerance, round, fuzz.tol) :
>  grid has empty column/rows in dimension 1'.
>
> Is this an important warning, do I have to consider it carefully?

No, this occurs when the representation is changed to grid, and where some 
complete columns or rows are absent. This can occur for good reason, say 
in an archipelago, but the warning is given in case the analyst made a 
mistake, and that absent grid rows or columns were not expected.

Roger

>
> ###########################################################################
>> station$VORONOI<-factor(station$VORONOI)
>> grid$VORONOI<-factor(grid$VORONOI)
>> gridded(grid) <- TRUE
> Warning message:
> In points2grid(points, tolerance, round, fuzz.tol) :
>  grid has empty column/rows in dimension 1
>
>> bw=gwr.sel(PREC~Z+V1+V2,data=station,adapt=T)
>> xx<-gwr(PREC~Z+V1+V2,station,adapt=bw,hatmatrix=TRUE)
>> x <-gwr(PREC~Z+V1+V2,data=station,adapt=bw, fit.points = grid, predict=T, se.fit=T, fittedGWRobject=xx)
> Warning message:
> In points2grid(points, tolerance, round, fuzz.tol) :
>  grid has empty column/rows in dimension 1
>
>> gwrres<-x$SDF
>> names(gwrres)
> [1] "sum.w"              "(Intercept)"        "Z"                  "V1"
> [5] "V2"                 "(Intercept)_se"     "Z_se"               "V1_se"
> [9] "V2_se"              "pred"               "pred.se"            "localR2"
> [13] "(Intercept)_se_EDF" "Z_se_EDF"           "V1_se_EDF"          "V2_se_EDF"
> [17] "pred.se_EDF"
>
> Alinti Roger Bivand <Roger.Bivand at nhh.no>
>
>> On Fri, 11 Jun 2010, Pinar Aslantas Bostan wrote:
>>
>>>
>>>
>>> Dear Roger,
>>>
>>> I tried with data frames instead of SPDF. I gave some details of
>>> names and class types of datasets. Grid data has 31204 rows (first
>>> row is column names) and 5 columns (Z,X,Y,V1,V2). Station data has
>>> 226 rows (first row is column names) and 6 columns
>>> (PREC,Z,X,Y,V1,V2). I gave an example about datasets below.
>>
>> Please do try to read up on what is going on. Find out how variables
>> may be treated as string not numeric on input, and converted into
>> factors. Do report str() of the imported objects as I said last time.
>> This will show if some numeric are really factors - this may happen
>> for example if the locale thinks that ",", not "." is the decimal
>> sign, or if there is any non-numeric character in a column. If need
>> be put your data (or a subset with the same problem on a website and
>> post the link. Please do try to use lm() and predict() on the lm
>> output object to see whether the problem is reproduced there too.
>>
>> Please also be aware that using GWR for prediction has no good basis
>> anywhere for anything - and the standard errors should not be given
>> any credibility. This is not what GWR is for at all.
>>
>> Roger
>>
>>>
>>> Grid data
>>> Z   X   Y   V1  V2
>>> 495 259725.32564500000 5010656.22353999000 44.15584946 53525.25605680000
>>> 621 264725.32564499800 5010656.22353999000 50.67575455 50139.84515760000
>>> 432 274725.32564499800 5010656.22353999000 58.62472534 44295.66734330000
>>> 418 279725.32564499800 5010656.22353999000 45.05175400 41966.14328090000
>>> 361 254725.32564500000 5005656.22353999000 37.61386871 60596.18505359990
>>>
>>> Station data
>>> PREC  Z X   Y   V1  V2
>>> 514.3522848 1039 410428.05168500000 4478786.07400999000 100.69618225
>>> 81321.18533050000
>>> 650.6115948 29 942127.25593400000 4409537.10120000000 7.64556551
>>> 34796.24442280000
>>> 690.1826088 614 1201166.68404000000 4496907.09750000000 39.14785004
>>> 212666.95252600000
>>> 427.7718516 1213 1080214.69930000000 4550293.99677000000 53.82775879
>>> 164788.61213900000
>>> 402.9552240 1197 525196.23761299900 4619486.48904000000 69.23021698
>>> 206901.35695100000
>>>
>>> And from the list Binbin lu send me a message, according to his
>>> advice I don't write "station$" term while performing gwr.sel and
>>> gwr functions. In this way gwr function has worked but gave a
>>> warning message. And when I plot the predicted precipitation values
>>> of the grid there are some negative values which should't be occur!
>>> It didn't calculate predicted errors also.
>>>
>>> What do you mean with 'factor' and I don't know how to run the
>>> function under debug.
>>>
>>> Thanks for your help.
>>> Pinar
>>>
>>> ###########################################################################
>>>> grid<-read.table("D:\\R\\dem.txt", header=TRUE)
>>>> station<-read.table("D:\\R\\station.txt", header=TRUE)
>>>
>>>> class(grid)
>>> [1] "data.frame"
>>>
>>>> class(station)
>>> [1] "data.frame"
>>>
>>>> names(grid)
>>> [1] "Z"  "X"  "Y"  "V1" "V2"
>>>
>>>> names(station)
>>> [1] "PREC" "Z"    "X"    "Y"    "V1"   "V2"
>>>
>>>> coordinates(station) <- c("X", "Y")
>>>> coordinates(grid) <- c("X", "Y")
>>>
>>>> bw=gwr.sel(PREC~Z+V1+V2,data=station,adapt=T)
>>>> gwr <-gwr(PREC~Z+V1+V2,data=station,adapt=bw, fit.points = grid,
>>>> predict=T, se.fit=T, hatmatrix=T)
>>>
>>> Warning message:
>>> In gwr(PREC ~ Z + V1 + V2, data = station, adapt = bw, fit.points = grid,  :
>>> standard errors set to NA, normalised RSS not available
>>>
>>> Alinti Roger Bivand <Roger.Bivand at nhh.no>
>>>
>>>> On Fri, 11 Jun 2010, Pinar Aslantas Bostan wrote:
>>>>
>>>>>
>>>>>
>>>>> Dear all,
>>>>>
>>>>> I want to make GWR analysis to predict precipitation distribution
>>>>> measured from 225 meteorological stations. I have three independent
>>>>> variables (Z, V1, V2). I want to obtain predictions on the grid
>>>>> dataset which has 31203 number of pixels. I gave some details about
>>>>> my datasets below. While performing GWR, I get error message: "new
>>>>> data matrix rows mismatch"
>>>>>
>>>>> How can I solve that problem?
>>>>
>>>> You need to provide the detailed output of traceback(), and probably
>>>> also run gwr() under debug() to see whether this is a data problem or
>>>> a code problem. Does gwr() work when predict=FALSE, and/or
>>>> predict=TRUE, se.fit=FALSE? The error message is generated when the
>>>> number of columns in the matrix of X variables is not the same in
>>>> data and and fit.points. Are the variables in both cases stored in
>>>> the same way? What do str(station.grid) and str(station) look like
>>>> before conversion to SPDF and after? Is one variable a factor in one
>>>> and numeric in the other? Running under debug() will let you check
>>>> what x and predx look like.
>>>>
>>>> If this sounds hard, consider putting your data on a website and
>>>> posting the link.
>>>>
>>>> Hope this helps,
>>>>
>>>> Roger
>>>>
>>>>>
>>>>> Thanks, Pinar.
>>>>>
>>>>> station.grid<-read.table("D:\\R\\dem.txt", header=TRUE)
>>>>> station<-read.table("D:\\R\\station.txt", header=TRUE)
>>>>>
>>>>> grid = SpatialPointsDataFrame(data=station.grid,
>>>>> coords=cbind(station.grid$X, station.grid$Y))
>>>>
>>>>> station = SpatialPointsDataFrame(data=station,
>>>>> coords=cbind(station$X,station$Y))
>>>>>
>>>>>> names(grid)
>>>>> [1] "Z" "X" "Y" "V1" "V2"
>>>>>> names(station)
>>>>> [1] "PREC" "Z" "X" "Y" "V1" "V2"
>>>>>
>>>>> bw=gwr.sel(PREC~station$Z+station$V1+station$V2,data=station,adapt=T)
>>>>
>>>>> gwr <-gwr(PREC ~ station$Z +
>>>> station$V1 + station$V2, data=station, adapt=bw, fit.points = grid,
>>>> predict=TRUE, se.fit=T)
>>>>>
>>>>> Error in gwr(PREC ~ station$Z + station$V1 + station$V2, data = station, :
>>>>> NEW DATA MATRiX ROWS MiSMATCH
>>>>>
>>>>> ----------------------------------------------------------------
>>>>>
>>>>>
>>>>>        [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>>>
>>>> --
>>>> Roger Bivand
>>>> Economic Geography Section, Department of Economics, Norwegian School of
>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>> e-mail: Roger.Bivand at nhh.no
>>>>
>>>>
>>>
>>>
>>>
>>> ----------------------------------------------------------------
>>> This message was sent using IMP, the Internet Messaging Program.
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>
>
>
> ----------------------------------------------------------------
> This message was sent using IMP, the Internet Messaging Program.
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From marco.helbich at geog.uni-heidelberg.de  Tue Jun 15 13:48:54 2010
From: marco.helbich at geog.uni-heidelberg.de (Marco Helbich)
Date: Tue, 15 Jun 2010 13:48:54 +0200
Subject: [R-sig-Geo] spplot contour font size and color adjustment
Message-ID: <4C1768A6.4030900@geog.uni-heidelberg.de>

Dear list,

I am struggling with the spplot function, in detail, a) labeling some
contours superimposed on a grid. How can I control the contour's font
size? b) How can I set values above 0.6 transparent?

I played around using panel utility functions for spplot but got no
appropriate solution.

# example
library(sp)
data(meuse.grid)
gridded(meuse.grid) = ~x+y
densplot <- spplot(meuse.grid, c("dist"),
   col.regions=rev(gray.colors(20)), contour=T, labels=T, pretty=T,
   panel = function(...) {
     panel.gridplot(...)
     #sp.lines(...)
     })
print(densplot)

I appreciate every hint!

Best regards
Marco
-- 
Marco Helbich
Chair of GIScience
Department of Geography, University of Heidelberg
marco.helbich at geog.uni-heidelberg.de
Berliner Stra?e 48, D-69120 Heidelberg, Germany


From hadley at rice.edu  Tue Jun 15 14:40:55 2010
From: hadley at rice.edu (Hadley Wickham)
Date: Tue, 15 Jun 2010 07:40:55 -0500
Subject: [R-sig-Geo] rgeos and Google Summer of Code
In-Reply-To: <AANLkTikl-njdpozGyiIba_M7pgd3FNtV3XDWKaiofaOf@mail.gmail.com>
References: <F82A6905-9397-46BF-A544-FBA262A71453@gmail.com> 
	<4C171D5A.9080403@uni-muenster.de>
	<AANLkTikl-njdpozGyiIba_M7pgd3FNtV3XDWKaiofaOf@mail.gmail.com>
Message-ID: <AANLkTimsROS9np3V1I4_PgruLWY-LT2OFHCSXgnD2Qix@mail.gmail.com>

>> For some reason the r-forge pages don't show anymore how r-forge
>> packages can be installed. As they always did, I didn't bother to
>> remember. Could you tell us, so we can alpha test, and perhaps add this
>> to the rgeos page on r-forge? (Better would be someone repaired r-forge,
>> which seems to have broken layouts ever since the Vienna power crash)
>
> ?If you go to the 'Packages' section of an R-forge project, you can see:
>
> """
> To install this package directly within R type:
> install.packages("rgeos", repos="http://R-Forge.R-project.org")
> """
>
> ?but yes, I'm fairly sure it used to say it on each main project page...

But as per the blog post:

The package is available at r-forge
(http://rgeos.r-forge.r-project.org/) where it can be downloaded from
svn. Binary packages will not be available for the foreseeable future
due to the dependency on GEOS. With GEOS version 3.2 or later
installed it should be straight forward to install the package from
source if you would like to play with prerelease versions.

Hadley


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From Roger.Bivand at nhh.no  Tue Jun 15 15:48:46 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 15 Jun 2010 15:48:46 +0200 (CEST)
Subject: [R-sig-Geo] georeferencing point shape
In-Reply-To: <4C175321.5000405@wzw.tum.de>
References: <70FC67C4A585D1489E66225A4E0238BA9371D9@RZS-EXC-CL06.rz-sued.bayern.de>
	<4C175321.5000405@wzw.tum.de>
Message-ID: <alpine.LRH.2.00.1006151529460.3716@reclus.nhh.no>

On Tue, 15 Jun 2010, Tom Gottfried wrote:

> Hi Tim,
>
>> I have a point shape containing field measurements in a small scale studyarea. Unfortunately these
> points didn`t have geographic or projected coordinates. The spatial reference for these points are
> theodolite measurements. For four corner points gps measurements of projected coordinates are
> available. I want to georeference my point shape in these projected coordinate system and have no
> idea how.
>> Here is a subset of my data:
>>
>> x <- c(5.786, -3.766, -12.613, -21.836, -26.340, 3.958, -11.120, -17.266, -18.938,
>>   16.751, -21.507, 26.420, -19.916, 23.184, 9.660, -5.711, -18.256, 27.888, 12.634, -33.510)
>> y <- c(4.470, 0.797, -3.130, -7.656, -9.313, 8.700, 6.923, 8.545, 12.468, 4.748,
>>   -20.920, -5.396, -24.830, -11.636, 22.462, 19.210, -28.851, -9.510, 27.421, 8.035)
>> z <- c(1100.493, 1100.867, 1101.798, 1102.559, 1103.703, 1102.366, 1107.249, 1110.781,
>>  1113.920, 1096.967, 1095.284, 1088.956, 1092.869, 1086.786, 1101.300, 1110.197, NA, NA, NA, NA)
>> gps_x <- c(NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA, 4560136, 4560184, 4560172, 4560121)
>> gps_y <- c(NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA, 5289465, 5289482, 5289521, 5289502)
>>
>> d <- data.frame(x,y,z,gps_x,gps_y)
>> d
>> coordinates(d) = ~x+y
>> plot(d, axes=T)
>>
>> gps_points <- d[17:20,]
>> points(gps_points, pch=19, col="red")
>>
>> Because both measurements - the theodolite values and the gps values - are measured in meters, my
>> first idea was to calculate the coordinates for all points by sum the difference between a gps
>> point and every single theodolite point in x- and y-direction. Unfortunately there are little
>> differences depending which gps point is used as basis.
>
> If you can assume the little differences being due to the error in gps-measurements, you could
> calculate your coordinates with all your gps points as a basis and then take the mean as final value.
>
> Tom

There is a problem with the known points too, in that their surveyed and 
GPS interpoint distances differ somewhat:

dist(cbind(gps_x, gps_y)[17:20,])
dist(cbind(x, y)[17:20,])
dist(cbind(gps_x, gps_y)[17:20,]) - dist(cbind(x, y)[17:20,])

This means that with only 4 GPS points, it is hard to model the 
transformation with more terms:

df <- data.frame(gps_x, gps_y, x, y)
lmx <- lm(gps_x ~ x + y, data=df[17:20,])
lmy <- lm(gps_y ~ x + y, data=df[17:20,])
nx <- predict(lmx, data.frame(x, y))
ny <- predict(lmy, data.frame(x, y))
dist(cbind(nx, ny)[17:20,])
dxy <- dist(cbind(x, y))
dnxny <- dist(cbind(nx, ny))
all.equal(dxy, dnxny, check.attributes=FALSE)

More GPS measurements would have helped, but at this scale, GPS are always 
going to be approximate. You cannot measure the centres of the GPS and 
surveyed points accurately either, I'm afraid. To fix things, you would 
need GPS measurements in the precision of the data set, so in most cases 
like this DGPS rather than GPS. If one of the surveyed points is clearly 
visible on a registered high resolution image, you could use that instead 
of the GPS - something like the corner of a building (measured to about 
1cm and known in the projection of interest). However, planning this 
before doing the fieldwork was the only effective remedy.

Roger

PS. Do you know that the GPS was using the ellipse you specify? Which 
datum are you assuming (WGS84)?


>
>> Is there a better way to transform the point pattern into the projected 
>> coordinate system? The proj4string for my coordinate system is: 
>> +proj=tmerc +lat_0=0 +lon_0=12 +k=1 +x_0=4500000 +y_0=0 +ellps=bessel 
>> +units=m +no_defs
>>
>> Thank you very much.
>>
>> TIM
>>
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From lestes at princeton.edu  Wed Jun 16 02:55:03 2010
From: lestes at princeton.edu (Lyndon Estes)
Date: Tue, 15 Jun 2010 20:55:03 -0400
Subject: [R-sig-Geo] Advice on GLS on residual variogram?
In-Reply-To: <2E9C414912813E4EB981326983E0A1040735BFE3@inboexch.inbo.be>
References: <AANLkTintjBG78yXTcW-EeAu3g08VuUOk5uniLne6rpY4@mail.gmail.com>
	<2E9C414912813E4EB981326983E0A1040735BFE3@inboexch.inbo.be>
Message-ID: <AANLkTilC3IxeV8Qlr-iZcpQbsc7aqabsiPih1oVopSJk@mail.gmail.com>

Dear Thierry,

Many thanks for your help.

> Have a look at the normalised residuals when creating a variogram. Those
> take the correlation structure into account.

Using the normalized residuals for the variogram produces more
sensible looking results (see bottom image here:
http://sites.google.com/site/ldemisc/variogram):

# OLS and GLS
gls.2<-gls(log(CTOP)~PCB1+PCB2+PCB3+PCB4+PCB5+PCB6+PCB8,data=oc_2)
gls.2.sph<-update(gls.2,correlation=corSpher(form=~X+Y,nugget=TRUE))

# OLS variogram
v.gls<-variogram(residuals(gls.2)~1,data=oc_2)
v.gls.pl<-plot(v.gls)

# GLS variogram
v.gls.sph<-variogram(residuals(gls.2.sph,type="normalized")~1,data=oc_2)
v.gls.sph.pl<-plot(v.gls.sph)

# Side by side variogram plot
v.gls.pl$x.limits<-v.gls.sph.pl$x.limits
v.gls.pl$y.limits<-v.gls.sph.pl$y.limits
print(v.gls.pl,split=c(1,1,2,1),more=TRUE)
print(v.gls.sph.pl,split=c(2,1,2,1),more=FALSE)    			

This looks like much more plausible GLS output, no?

> And have a look at the
> parameters of the correlation structure. Are they from a similar
> magnitude as you would expect from the OLS variogram? If not, rerun the
> GLS with starting values for range and sill based on the OLS variogram.
> I had some strange results in the past with range parameters being
> smaller than the smallest distance between two points. Supplying
> reasonable starting values yielded better results.


Looking at the variogram parameter found from the OLS residuals, I see
a fair bit of difference between those found by GLS for the
correlation structure:

vgm.ols.norm<-variogram(residuals(gls.2,type="normalized")~1,data=oc_2)
ols.vgm.parms1<-vgm(nugget=0.27,model="Sph",psill=0.6,range=200000)
ols.fit.sph.var<-fit.variogram(vgm.ols2,model=ols.vgm.parms1)

> ols.fit.sph.var
  model      psill    range
1   Nug 0.26197480      0.0
2   Sph 0.09186248 220528.5

#Partial output from summary of GLS fit

>summary(gls.2.sph)

Correlation Structure: Spherical spatial correlation
 Formula: ~X + Y
 Parameter estimate(s):
       range       nugget
1509259    0.1357911

So, I will retry the GLS using the fitted variogram values overnight
(the GLS with spherical correlation model takes ~ 6 hours to run).

I had one more issue that came up related to this process, which is
rather alarming--using R on two different installations, with the same
code and same data, I am getting different results for the GLS!  I was
hoping someone could help me figure out what's wrong.

Installation 1: MacBook Pro with OS X 10.5.8, with the following R :

R version 2.11.1 (2010-05-31)
[R.app GUI 1.34 (5589) x86_64-apple-darwin9.8.0]

Installation 2: 8 node Linux cluster, with custom version of RHEL5. I
built R 2.11.1 from source here and installed locally.

As I said, with my dataset, I am getting different results.

Everything is the same with the initial portions of the code:

Mac R >

oc<-read.dbf('~/Desktop/ARC_profs_OC+PCA+PREDs.dbf')		
oc_2<-as.data.frame(oc[,c(2,5:6,21:27,207:225)])
gls.2<-gls(log(CTOP)~PCB1+PCB2+PCB3+PCB4+PCB5+PCB6+PCB8,data=oc_2)
summary(gls.2)

Generalized least squares fit by REML
  Model: log(CTOP) ~ PCB1 + PCB2 + PCB3 + PCB4 + PCB5 + PCB6 + PCB8
  Data: oc_2
       AIC      BIC    logLik
  6320.516 6375.617 -3151.258

Coefficients:
                 Value Std.Error   t-value p-value
(Intercept)  1.6608899 0.4280775   3.87988   1e-04
PCB1        -0.0002037 0.0000156 -13.03177   0e+00
PCB2         0.0004070 0.0000230  17.68030   0e+00
PCB3         0.0026349 0.0000460  57.28741   0e+00
PCB4         0.0133557 0.0011803  11.31585   0e+00
PCB5        -0.0085951 0.0012186  -7.05294   0e+00
PCB6         0.0315716 0.0012912  24.45119   0e+00
PCB8        -0.0990330 0.0064676 -15.31206   0e+00

[snipped for space]

Residual standard error: 0.6061033
Degrees of freedom: 3377 total; 3369 residual

Linux R >

Generalized least squares fit by REML
  Model: log(CTOP) ~ PCB1 + PCB2 + PCB3 + PCB4 + PCB5 + PCB6 + PCB8
  Data: oc_2
       AIC      BIC    logLik
  6320.516 6375.617 -3151.258

Coefficients:
                 Value Std.Error   t-value p-value
(Intercept)  1.6608899 0.4280775   3.87988   1e-04
PCB1        -0.0002037 0.0000156 -13.03177   0e+00
PCB2         0.0004070 0.0000230  17.68030   0e+00
PCB3         0.0026349 0.0000460  57.28741   0e+00
PCB4         0.0133557 0.0011803  11.31585   0e+00
PCB5        -0.0085951 0.0012186  -7.05294   0e+00
PCB6         0.0315716 0.0012912  24.45119   0e+00
PCB8        -0.0990330 0.0064676 -15.31206   0e+00

[snipped for space]

Residual standard error: 0.6061033
Degrees of freedom: 3377 total; 3369 residual

So, this suggests that the input datasets are not somehow different
from one another. The problem comes here:

Mac R >

gls.2.sph<-update(gls.2,correlation=corSpher(form=~X+Y,nugget=TRUE))
summary(gls.2.sph)

Generalized least squares fit by REML
  Model: log(CTOP) ~ PCB1 + PCB2 + PCB3 + PCB4 + PCB5 + PCB6 + PCB8
  Data: oc_2
       AIC      BIC    logLik
  5742.647 5809.993 -2860.323

Correlation Structure: Spherical spatial correlation
 Formula: ~X + Y
 Parameter estimate(s):
       range       nugget
1.509259e+06 1.357911e-01

Coefficients:
                 Value Std.Error   t-value p-value
(Intercept) -1.6911740 0.9610770 -1.759665  0.0786
PCB1        -0.0001095 0.0000166 -6.612440  0.0000
PCB2         0.0012919 0.0000677 19.081299  0.0000
PCB3         0.0014827 0.0001903  7.791159  0.0000
PCB4         0.0026119 0.0014134  1.847974  0.0647
PCB5        -0.0119822 0.0012409 -9.655755  0.0000
PCB6         0.0196123 0.0017884 10.966588  0.0000
PCB8         0.0290101 0.0193420  1.499847  0.1337

 Correlation:
     (Intr) PCB1   PCB2   PCB3   PCB4   PCB5   PCB6
PCB1 -0.496
PCB2 -0.202  0.229
PCB3  0.260 -0.427 -0.161
PCB4  0.254 -0.439 -0.403  0.280
PCB5 -0.007 -0.256 -0.123  0.023  0.455
PCB6  0.326 -0.405 -0.246  0.428  0.487  0.161
PCB8 -0.618  0.473  0.339 -0.583 -0.535 -0.091 -0.622

Standardized residuals:
       Min         Q1        Med         Q3        Max
-2.8618482 -1.1854998 -0.7948018 -0.3657106  1.3957297

Residual standard error: 1.368062
Degrees of freedom: 3377 total; 3369 residual

Linux R >

gls.2.sph<-update(gls.2,correlation=corSpher(form=~X+Y,nugget=TRUE))
summary(gls.2.sph)

Generalized least squares fit by REML
  Model: log(CTOP) ~ PCB1 + PCB2 + PCB3 + PCB4 + PCB5 + PCB6 + PCB8
  Data: oc_2
       AIC      BIC    logLik
  5742.867 5810.213 -2860.433

Correlation Structure: Spherical spatial correlation
 Formula: ~X + Y
 Parameter estimate(s):
       range       nugget
1.625556e+06 1.272891e-01

Coefficients:
                 Value Std.Error   t-value p-value
(Intercept) -1.5625757 0.9952075 -1.570100  0.1165
PCB1        -0.0001095 0.0000166 -6.609627  0.0000
PCB2         0.0012916 0.0000677 19.078453  0.0000
PCB3         0.0014815 0.0001904  7.779445  0.0000
PCB4         0.0026110 0.0014141  1.846390  0.0649
PCB5        -0.0119806 0.0012410 -9.654330  0.0000
PCB6         0.0196109 0.0017893 10.959835  0.0000
PCB8         0.0291060 0.0193667  1.502889  0.1330

 Correlation:
     (Intr) PCB1   PCB2   PCB3   PCB4   PCB5   PCB6
PCB1 -0.477
PCB2 -0.189  0.229
PCB3  0.247 -0.428 -0.162
PCB4  0.242 -0.439 -0.404  0.281
PCB5 -0.008 -0.256 -0.123  0.023  0.455
PCB6  0.312 -0.405 -0.246  0.429  0.487  0.161
PCB8 -0.592  0.474  0.340 -0.583 -0.535 -0.091 -0.623

Standardized residuals:
       Min         Q1        Med         Q3        Max
-2.8627169 -1.2401476 -0.8617219 -0.4464233  1.2590098

Residual standard error: 1.413038
Degrees of freedom: 3377 total; 3369 residual


Just about everything is different in this, even if just slightly, and
I am not sure why. To check to see if there was a problem with another
dataset, I used meuse:

data(meuse)
meu.ols<-gls(log(zinc)~dist.m+ffreq,meuse)
meu.gls<-update(meu.ols,correlation=corExp(form=~x+y,nugget=TRUE))
summary(meu.gls)

But the results are the same from both, e.g.

Mac >

Parameter estimate(s):
       range       nugget
236.94597158   0.02719958

Coefficients:
                Value  Std.Error  t-value p-value
(Intercept)  6.759524 0.12988675 52.04168       0
dist.m      -0.001910 0.00028717 -6.64969       0
ffreq2      -0.562034 0.06642560 -8.46110       0
ffreq3      -0.557639 0.10166715 -5.48495       0

Linux >

 Parameter estimate(s):
       range       nugget
236.94597172   0.02719958

Coefficients:
                Value  Std.Error  t-value p-value
(Intercept)  6.759524 0.12988675 52.04168       0
dist.m      -0.001910 0.00028717 -6.64969       0
ffreq2      -0.562034 0.06642560 -8.46110       0
ffreq3      -0.557639 0.10166715 -5.48495       0


So, I am really not sure what is going on here. As I said, my datasets
seem fine, and to further confirm this I exported the values from oc_2
from linux, imported into my Mac R installation, and did a few tests:


Linux R >

write.csv(oc_2[,c(1:3,9,14:21)],oc2out.txt)

Mac R >

oc_2_ad<-read.csv("oc2out.txt")
str(oc_2_ad)
str(oc_2)

#Compare coordinates

xdiffs<-round(oc_2$X-oc_2_ad$X,5)
ydiffs<-round(oc_2$Y-oc_2_ad$Y,5)
ctopdiffs<-oc_2$CTOP-oc_2_ad$CTOP
pc1diffs<-oc_2$PCB1-oc_2_ad$PCB1
pc2diffs<-oc_2$PCB2-oc_2_ad$PCB2
pc3diffs<-oc_2$PCB3-oc_2_ad$PCB3
pc4diffs<-oc_2$PCB4-oc_2_ad$PCB4
pc5diffs<-oc_2$PCB5-oc_2_ad$PCB5
pc6diffs<-oc_2$PCB6-oc_2_ad$PCB6
pc8diffs<-oc_2$PCB8-oc_2_ad$PCB8


min(xdiffs);max(xdiffs);mean(xdiffs)							
min(ydiffs);max(ydiffs);mean(ydiffs)							
min(ctopdiffs);max(ctopdiffs);mean(ctopdiffs)
min(pc1diffs);max(pc1diffs);mean(pc1diffs)
min(pc2diffs);max(pc2diffs);mean(pc2diffs)
min(pc3diffs);max(pc3diffs);mean(pc3diffs)
min(pc4diffs);max(pc4diffs);mean(pc4diffs)
min(pc5diffs);max(pc5diffs);mean(pc5diffs)
min(pc6diffs);max(pc6diffs);mean(pc6diffs)
min(pc8diffs);max(pc8diffs);mean(pc8diffs)			

The results were all zeros, so the problem doesn't seem to be
different values in the dataset, or misaligned rows.  So, I am at a
loss here.

Could this have something to do with a faulty build on the linux cluster?

Thanks in advance for any help and advice!

Cheers, Lyndon


From Thierry.ONKELINX at inbo.be  Wed Jun 16 11:06:49 2010
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 16 Jun 2010 11:06:49 +0200
Subject: [R-sig-Geo] Advice on GLS on residual variogram?
In-Reply-To: <AANLkTilC3IxeV8Qlr-iZcpQbsc7aqabsiPih1oVopSJk@mail.gmail.com>
References: <AANLkTintjBG78yXTcW-EeAu3g08VuUOk5uniLne6rpY4@mail.gmail.com><2E9C414912813E4EB981326983E0A1040735BFE3@inboexch.inbo.be>
	<AANLkTilC3IxeV8Qlr-iZcpQbsc7aqabsiPih1oVopSJk@mail.gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A1040735C206@inboexch.inbo.be>

Hi Lyndon,

The results seems sensible to me. The difference in range and nugget
between the OLS variogram and the GLS correlation structure is IMHO not
a problem. They both are some the same magnitude. The GLS takes the
spatial structure directly into account. Hence the model fit
(parameters) will change and so will the residuals.

As far as a know, GLS uses an iterative algorithm to estimate the
correlation structure. That might explain the differences you observe
between the two machines. Rerunning the same model on the same dataset
and the same machine will also yield somewhat different results.

Best regards,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey
  


Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.


From haenlein at escpeurope.eu  Wed Jun 16 14:40:41 2010
From: haenlein at escpeurope.eu (Michael Haenlein)
Date: Wed, 16 Jun 2010 14:40:41 +0200
Subject: [R-sig-Geo] Problem with moran.test function
Message-ID: <AANLkTikUtVCwo7FI5X84UiJpUQzMu3YwllGJjky-sjY3@mail.gmail.com>

Dear all,

I'm trying to estimate Moran's I using the moran.test function Below
please find the summary statistics for my network and key variable. In
doing so, I'm facing the issue that my estimation results in the
following error message:

Warning message: In moran.test(x, Network_): Out-of-range p-value:
reconsider test arguments

The results are as follows:

        Moran's I test under randomisation

data:  x
weights: Network

Moran I statistic standard deviate = NA, p-value = NA
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance
             -Inf     -0.0002926544                NA

Could anyone please tell me what this error message means?

Is there a problem with my network and/ or with my key variable?

Thanks very much for letting me know,

Michael






Characteristics of weights list object:
Neighbour list object:
Number of regions: 3418
Number of nonzero links: 6442
Percentage nonzero weights: 0.05514125
Average number of links: 1.884728
Non-symmetric neighbours list
Weights style: NA
Weights constants summary:
      n       nn S0 S1 S2
NA 3418 11682724  0 NA NA

summary(x)
Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
1082    1543    2119    2250    2886    3965


From Roger.Bivand at nhh.no  Wed Jun 16 15:08:17 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 16 Jun 2010 15:08:17 +0200 (CEST)
Subject: [R-sig-Geo] Problem with moran.test function
In-Reply-To: <AANLkTikUtVCwo7FI5X84UiJpUQzMu3YwllGJjky-sjY3@mail.gmail.com>
References: <AANLkTikUtVCwo7FI5X84UiJpUQzMu3YwllGJjky-sjY3@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1006161450180.8640@reclus.nhh.no>

On Wed, 16 Jun 2010, Michael Haenlein wrote:

> Dear all,
>
> I'm trying to estimate Moran's I using the moran.test function Below
> please find the summary statistics for my network and key variable. In
> doing so, I'm facing the issue that my estimation results in the
> following error message:
>
> Warning message: In moran.test(x, Network_): Out-of-range p-value:
> reconsider test arguments
>
> The results are as follows:
>
>        Moran's I test under randomisation
>
> data:  x
> weights: Network
>
> Moran I statistic standard deviate = NA, p-value = NA
> alternative hypothesis: greater
> sample estimates:
> Moran I statistic       Expectation          Variance
>             -Inf     -0.0002926544                NA
>
> Could anyone please tell me what this error message means?

Well, Moran's I is -Inf, and the analytical variance is NA, so something 
is not right. The problem could lie in x, Network, or the lag of x (when 
x and Network are OK but their combination is unhappy). Can you run 
moran.test() under debug() and check which values lead the value of I to 
go to -Inf? Is this what is going on:

data(columbus)
set.seed(1)
x <- log(rpois(n=49, 2))
x
moran.test(x, nb2listw(col.gal.nb))

where the current spdep release fails reporting:

Error in lag.listw(listw, z, zero.policy = zero.policy, NAOK = NAOK) :
   Variable contains non-finite values

which was a fix introduced four weeks ago, changed to a test on |Inf| from 
a test on NA:

https://r-forge.r-project.org/scm/viewvc.php/pkg/src/lagw.c?root=spdep&r1=244&r2=282

If you update spdep, you'll pick up the improvement (made thanks to a bug 
report by Matias Mayor Fernandez), and if this is the case, the problem is 
in the x.

Hope this helps,

Roger

>
> Is there a problem with my network and/ or with my key variable?
>
> Thanks very much for letting me know,
>
> Michael
>
>
>
>
>
>
> Characteristics of weights list object:
> Neighbour list object:
> Number of regions: 3418
> Number of nonzero links: 6442
> Percentage nonzero weights: 0.05514125
> Average number of links: 1.884728
> Non-symmetric neighbours list
> Weights style: NA
> Weights constants summary:
>      n       nn S0 S1 S2
> NA 3418 11682724  0 NA NA
>
> summary(x)
> Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> 1082    1543    2119    2250    2886    3965
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From tom.gottfried at wzw.tum.de  Wed Jun 16 16:35:24 2010
From: tom.gottfried at wzw.tum.de (Tom Gottfried)
Date: Wed, 16 Jun 2010 16:35:24 +0200
Subject: [R-sig-Geo] georeferencing point shape
In-Reply-To: <alpine.LRH.2.00.1006151529460.3716@reclus.nhh.no>
References: <70FC67C4A585D1489E66225A4E0238BA9371D9@RZS-EXC-CL06.rz-sued.bayern.de>
	<4C175321.5000405@wzw.tum.de>
	<alpine.LRH.2.00.1006151529460.3716@reclus.nhh.no>
Message-ID: <4C18E12C.4060006@wzw.tum.de>

Am 15.06.2010 15:48, schrieb Roger Bivand:
> On Tue, 15 Jun 2010, Tom Gottfried wrote:
> 
>> Hi Tim,
>>
>>> I have a point shape containing field measurements in a small scale
>>> studyarea. Unfortunately these
>> points didn`t have geographic or projected coordinates. The spatial
>> reference for these points are
>> theodolite measurements. For four corner points gps measurements of
>> projected coordinates are
>> available. I want to georeference my point shape in these projected
>> coordinate system and have no
>> idea how.
>>> Here is a subset of my data:
>>>
>>> x <- c(5.786, -3.766, -12.613, -21.836, -26.340, 3.958, -11.120,
>>> -17.266, -18.938,
>>>   16.751, -21.507, 26.420, -19.916, 23.184, 9.660, -5.711, -18.256,
>>> 27.888, 12.634, -33.510)
>>> y <- c(4.470, 0.797, -3.130, -7.656, -9.313, 8.700, 6.923, 8.545,
>>> 12.468, 4.748,
>>>   -20.920, -5.396, -24.830, -11.636, 22.462, 19.210, -28.851, -9.510,
>>> 27.421, 8.035)
>>> z <- c(1100.493, 1100.867, 1101.798, 1102.559, 1103.703, 1102.366,
>>> 1107.249, 1110.781,
>>>  1113.920, 1096.967, 1095.284, 1088.956, 1092.869, 1086.786,
>>> 1101.300, 1110.197, NA, NA, NA, NA)
>>> gps_x <- c(NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA, 4560136,
>>> 4560184, 4560172, 4560121)
>>> gps_y <- c(NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA, 5289465,
>>> 5289482, 5289521, 5289502)
>>>
>>> d <- data.frame(x,y,z,gps_x,gps_y)
>>> d
>>> coordinates(d) = ~x+y
>>> plot(d, axes=T)
>>>
>>> gps_points <- d[17:20,]
>>> points(gps_points, pch=19, col="red")
>>>
>>> Because both measurements - the theodolite values and the gps values
>>> - are measured in meters, my
>>> first idea was to calculate the coordinates for all points by sum the
>>> difference between a gps
>>> point and every single theodolite point in x- and y-direction.
>>> Unfortunately there are little
>>> differences depending which gps point is used as basis.
>>
>> If you can assume the little differences being due to the error in
>> gps-measurements, you could
>> calculate your coordinates with all your gps points as a basis and
>> then take the mean as final value.
>>
>> Tom
> 
> There is a problem with the known points too, in that their surveyed and
> GPS interpoint distances differ somewhat:
> 
> dist(cbind(gps_x, gps_y)[17:20,])
> dist(cbind(x, y)[17:20,])
> dist(cbind(gps_x, gps_y)[17:20,]) - dist(cbind(x, y)[17:20,])

Yes! And the surveyed interpoint distances should be more accurate. Thus, I think it's better to
rely on the surveyed (relative) coordinates, rather than transforming them to obtain the best fit
with the erroneous GPS-measurements.
But "snapping" the relative coordinates to the projected coordinate system by something like

x_new <- rep(0, times=length(x))
y_new <- x_new
for (i in 17:20){x_new <- x_new + gps_x[i]+x-x[i]; y_new <- y_new + gps_y[i]+y-y[i]}
x_new <- x_new/4; y_new <- y_new/4

(as I suggested last time), assumes that the error of GPS is random in both dimensions and has an
expected value of 0. Might this assumption be unrealistic?

> This means that with only 4 GPS points, it is hard to model the
> transformation with more terms:
> 
> df <- data.frame(gps_x, gps_y, x, y)
> lmx <- lm(gps_x ~ x + y, data=df[17:20,])
> lmy <- lm(gps_y ~ x + y, data=df[17:20,])
> nx <- predict(lmx, data.frame(x, y))
> ny <- predict(lmy, data.frame(x, y))
> dist(cbind(nx, ny)[17:20,])
> dxy <- dist(cbind(x, y))
> dnxny <- dist(cbind(nx, ny))
> all.equal(dxy, dnxny, check.attributes=FALSE)
> 
> More GPS measurements would have helped, but at this scale, GPS are
> always going to be approximate. You cannot measure the centres of the
> GPS and surveyed points accurately either, I'm afraid. To fix things,
> you would need GPS measurements in the precision of the data set, so in
> most cases like this DGPS rather than GPS. If one of the surveyed points
> is clearly visible on a registered high resolution image, you could use
> that instead of the GPS - something like the corner of a building
> (measured to about 1cm and known in the projection of interest).

Orthophotos (I think with a resolution of 40 cm) are available. This should be already much better
than the mean of the GPS measurements.

Tom

> However, planning this before doing the fieldwork was the only effective
> remedy.
> 
> Roger
> 
> PS. Do you know that the GPS was using the ellipse you specify? Which
> datum are you assuming (WGS84)?
> 
> 
>>
>>> Is there a better way to transform the point pattern into the
>>> projected coordinate system? The proj4string for my coordinate system
>>> is: +proj=tmerc +lat_0=0 +lon_0=12 +k=1 +x_0=4500000 +y_0=0
>>> +ellps=bessel +units=m +no_defs
>>>
>>> Thank you very much.
>>>
>>> TIM
>>>
>>>
>>
>>
> 

-- 
Technische Universit?t M?nchen
Department f?r Pflanzenwissenschaften
Lehrstuhl f?r Gr?nlandlehre
Am Hochanger 1
85350 Freising / Germany
Phone: ++49 (0)8161 715324
Fax:   ++49 (0)8161 713243
email: tom.gottfried at wzw.tum.de
http://www.wzw.tum.de/gruenland


From lestes at princeton.edu  Wed Jun 16 19:40:15 2010
From: lestes at princeton.edu (Lyndon Estes)
Date: Wed, 16 Jun 2010 13:40:15 -0400
Subject: [R-sig-Geo] Advice on GLS on residual variogram?
In-Reply-To: <2E9C414912813E4EB981326983E0A1040735C206@inboexch.inbo.be>
References: <AANLkTintjBG78yXTcW-EeAu3g08VuUOk5uniLne6rpY4@mail.gmail.com>
	<2E9C414912813E4EB981326983E0A1040735BFE3@inboexch.inbo.be>
	<AANLkTilC3IxeV8Qlr-iZcpQbsc7aqabsiPih1oVopSJk@mail.gmail.com>
	<2E9C414912813E4EB981326983E0A1040735C206@inboexch.inbo.be>
Message-ID: <AANLkTil_ugskbMqGVjLxoA9WICMsRSntBgEBrj9FeyR_@mail.gmail.com>

Dear Thierry,

Many thanks again for your help and clarifications.

I ran the GLS again last night, this time using the following code (I
post here in case it is of use to anyone else), run on the Mac, Linux,
and a Windows machine for good measure:

library(gstat)
library(foreign)
library(nlme)
library(sp)
library(MASS)

oc<-read.dbf('~/ocdata.dbf')	                                      # Import file
oc2new<-as.data.frame(oc[,c(2,5:6,21:27,207:225)])   # Subset relevant columns
coordinates(oc2new)=~X+Y                                          #
Define coordinates

#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++#
#GLS procedure

########################
# 1. Start with OLS using GLS
########################

gls.new<-gls(log(CTOP)~PCB1+PCB2+PCB3+PCB4+PCB5+PCB6+PCB8,
data=oc2new)

#######################################################
# 2. Find autocorrelation structure of the residuals, using a variogram
#######################################################

v.gls.new<-variogram(residuals(gls.new)~1,oc2new)
plot(v.gls.new)

#____________________________
# Starting values for fitting variogram

# Nugget
v.gls.nug1<-min(v.gls.new$gamma)

# Gives major range, but then divided by two because had singularity problems.
v.gls.range1<-(sqrt(diff(oc2new at bbox["X",])^2 + diff(oc2new at bbox["Y",])^2)/4)/2	

# Partial sill estimate
v.gls.psill<-var(residuals(gls.new))-v.gls.nug1					

v.gls.new.vgm<-vgm(nugget=v.gls.nug1,model="Sph",psill=v.gls.psill,range=v.gls.range1)

# Fit variogram			
v.gls.new.fit<-fit.variogram(v.gls.new,model=v.gls.new.vgm)

# Check variogram fit
# pl.vgm.gls.new.fit<-plot(v.gls.new,v.gls.new.fit,col="black",main="Log
OC residuals")
																
# Capture output to feed to GLS corStruct
gls.fitted.nug<-v.gls.new.fit$psill[1]							# Capture nugget value
gls.fitted.range<-v.gls.new.fit$range[2]						# Capture range value

################################################
# 3. Update the OLS model with defined correlation structure
################################################
ding<-Sys.time()
gls.new.up<-update(gls.new,correlation=corSpher(c(gls.fitted.range,gls.fitted.nug),form=~X+Y,nugget=TRUE))
dong<-Sys.time()

summary(gls.new.up)

print("Spherical GLS completed")
print(dong-ding)

The results this time around were pretty much identical for all three
machines, with Windows and Linux returning the same results, and Mac
just a shade different, e.g. two of the coefficients showed
differences in the 6th decimal.

I guess the earlier problem with the larger between-platform
differences was caused by GLS not having any initial values for
correlation structure specified.  So, that approach helps. Also, and
perhaps of greatest interest, providing starting values for GLS
dramatically improved the processing time (by reducing the number of
iterations needed).

Time to run this on Mac:

gls.2.sph<-update(gls.2,correlation=corSpher(form=~X+Y,nugget=TRUE))

4.7 hours

Versus 1.8 hours for the newer version:

gls.new.up<-update(gls.new,correlation=corSpher(c(gls.fitted.range,gls.fitted.nug),form=~X+Y,nugget=TRUE))

Thanks again for your assistance!

Cheers, Lyndon









On Wed, Jun 16, 2010 at 5:06 AM, ONKELINX, Thierry
<Thierry.ONKELINX at inbo.be> wrote:
>
> Hi Lyndon,
>
> The results seems sensible to me. The difference in range and nugget
> between the OLS variogram and the GLS correlation structure is IMHO not
> a problem. They both are some the same magnitude. The GLS takes the
> spatial structure directly into account. Hence the model fit
> (parameters) will change and so will the residuals.
>
> As far as a know, GLS uses an iterative algorithm to estimate the
> correlation structure. That might explain the differences you observe
> between the two machines. Rerunning the same model on the same dataset
> and the same machine will also yield somewhat different results.
>
> Best regards,
>
> Thierry
>
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek
> team Biometrie & Kwaliteitszorg
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
>
> Research Institute for Nature and Forest
> team Biometrics & Quality Assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
>
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>
>
>
> Druk dit bericht a.u.b. niet onnodig af.
> Please do not print this message unnecessarily.
>
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer
> en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
> door een geldig ondertekend document. The views expressed in ?this message
> and any annex are purely those of the writer and may not be regarded as stating
> an official position of INBO, as long as the message is not confirmed by a duly
> signed document.


From haenlein at escpeurope.eu  Thu Jun 17 07:05:54 2010
From: haenlein at escpeurope.eu (Michael Haenlein)
Date: Thu, 17 Jun 2010 07:05:54 +0200
Subject: [R-sig-Geo] Problem with moran.test function
Message-ID: <AANLkTilO5Gbe0PDjCrGCsEMbi05AayXwkAFCT1Okta2K@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100617/d33d9221/attachment.pl>

From Roger.Bivand at nhh.no  Thu Jun 17 08:50:28 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 17 Jun 2010 08:50:28 +0200 (CEST)
Subject: [R-sig-Geo] Problem with moran.test function
In-Reply-To: <AANLkTilO5Gbe0PDjCrGCsEMbi05AayXwkAFCT1Okta2K@mail.gmail.com>
References: <AANLkTilO5Gbe0PDjCrGCsEMbi05AayXwkAFCT1Okta2K@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1006170824140.11582@reclus.nhh.no>

On Thu, 17 Jun 2010, Michael Haenlein wrote:

> Roger,
>
> thanks very much for your reply!
>
> I tried to update spdep and downloaded the new version. Installation worked
> fine and I'm now working with spdep, version 0.5-11, 2010-05-31.
>
> The problem is, however, that I now can no longer use the read.dat2listw
> function, which I use to obtain network information from an external file.
> When I run
> Network <- read.dat2listw("C:/Network.txt")
> I get the error message:
> Error in `[.data.frame`(sn, , 3) : undefined columns selected
>
> I therefore had to move back to spdep, version 0.4-56, 2009-12-14.

No, it is definitely better to find out what is wrong with Network.txt, as 
the change made in April to sn2listw() - called by read.dat2listw() was to 
trap defective input objects. Please look at traceback() after the error. 
Do debug() on read.dat2listw, and summary() on wmat and sn. Are there 
locale issues in reading the text file, perhaps (decimal symbol?)?

This would feed downstream into the obviously wrong lagged values seen 
below. I'd be interested in access to the input file to strengthen 
defences against unusual weights, or weights seen by the system as 
unusual. I think that an errant final column is becoming a factor, then 
converted to numeric (with large n and many unique weights, their integer 
indices will become large). read.dat2listw() needs to check that there are 
3 columns, and that the first two are integer, and the third is numeric, I 
think. But we need to see why reading the file is failing.

Roger

>
> I also used moran.test under debug() as you suggested but if I understood
> the output correctly, the error message only comes up at the end.
> I have attached the full debug report below.
>
> lag.listw(Network,x) seems to work fine although the values are very, very
> small:
>
> y<-lag.listw(Network,x)
> summary(y)
>      Min.    1st Qu.     Median       Mean    3rd Qu.       Max.
> 1.497e-310 1.200e-300 1.698e-300 1.094e-226 2.414e-300 1.994e-223
>
> This is a bit surprising to me as the values of x are several orders of
> magnitude larger:
>
> summary(x)
>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>   1082    1543    2119    2250    2886    3965
>
> Thanks,
>
> Michael
>
>
>
>
>
>
>> debug(moran.test)
>> moran.test(x,Network)
> debugging in: moran.test(x, Network)
> debug: {
>    alternative <- match.arg(alternative, c("greater", "less",
>        "two.sided"))
>    if (!inherits(listw, "listw"))
>        stop(paste(deparse(substitute(listw)), "is not a listw object"))
>    if (!is.numeric(x))
>        stop(paste(deparse(substitute(x)), "is not a numeric vector"))
>    if (is.null(spChk))
>        spChk <- get.spChkOption()
>    if (spChk && !chkIDs(x, listw))
>        stop("Check of data and weights ID integrity failed")
>    xname <- deparse(substitute(x))
>    wname <- deparse(substitute(listw))
>    NAOK <- deparse(substitute(na.action)) == "na.pass"
>    x <- na.action(x)
>    na.act <- attr(x, "na.action")
>    if (!is.null(na.act)) {
>        subset <- !(1:length(listw$neighbours) %in% na.act)
>        listw <- subset(listw, subset, zero.policy = zero.policy)
>    }
>    n <- length(listw$neighbours)
>    if (n != length(x))
>        stop("objects of different length")
>    wc <- spweights.constants(listw, zero.policy = zero.policy,
>        adjust.n = adjust.n)
>    S02 <- wc$S0 * wc$S0
>    res <- moran(x, listw, wc$n, wc$S0, zero.policy = zero.policy,
>        NAOK = NAOK)
>    I <- res$I
>    K <- res$K
>    if (rank)
>        K <- (3 * (3 * wc$n^2 - 7))/(5 * (wc$n^2 - 1))
>    EI <- (-1)/wc$n1
>    if (randomisation) {
>        VI <- wc$n * (wc$S1 * (wc$nn - 3 * wc$n + 3) - wc$n *
>            wc$S2 + 3 * S02)
>        tmp <- K * (wc$S1 * (wc$nn - wc$n) - 2 * wc$n * wc$S2 +
>            6 * S02)
>        VI <- (VI - tmp)/(wc$n1 * wc$n2 * wc$n3 * S02)
>        VI <- VI - EI^2
>    }
>    else {
>        VI <- (wc$nn * wc$S1 - wc$n * wc$S2 + 3 * S02)/(S02 *
>            (wc$nn - 1))
>        VI <- VI - EI^2
>    }
>    ZI <- (I - EI)/sqrt(VI)
>    statistic <- ZI
>    names(statistic) <- "Moran I statistic standard deviate"
>    if (alternative == "two.sided")
>        PrI <- 2 * pnorm(abs(ZI), lower.tail = FALSE)
>    else if (alternative == "greater")
>        PrI <- pnorm(ZI, lower.tail = FALSE)
>    else PrI <- pnorm(ZI)
>    if (!is.finite(PrI) || PrI < 0 || PrI > 1)
>        warning("Out-of-range p-value: reconsider test arguments")
>    vec <- c(I, EI, VI)
>    names(vec) <- c("Moran I statistic", "Expectation", "Variance")
>    method <- paste("Moran's I test under", ifelse(randomisation,
>        "randomisation", "normality"))
>    data.name <- paste(xname, ifelse(rank, "using rank correction",
>        ""), "\nweights:", wname, ifelse(is.null(na.act), "",
>        paste("\nomitted:", paste(na.act, collapse = ", "))),
>        "\n")
>    res <- list(statistic = statistic, p.value = PrI, estimate = vec,
>        alternative = alternative, method = method, data.name = data.name)
>    if (!is.null(na.act))
>        attr(res, "na.action") <- na.act
>    class(res) <- "htest"
>    res
> }
> Browse[1]>
> debug: alternative <- match.arg(alternative, c("greater", "less",
> "two.sided"))
> Browse[1]>
> debug: if (!inherits(listw, "listw"))
> stop(paste(deparse(substitute(listw)), "is not a listw object"))
> Browse[1]>
> debug: if (!is.numeric(x)) stop(paste(deparse(substitute(x)), "is not a
> numeric vector"))
> Browse[1]>
> debug: if (is.null(spChk)) spChk <- get.spChkOption()
> Browse[1]>
> debug: if (spChk && !chkIDs(x, listw)) stop("Check of data and weights ID
> integrity failed")
> Browse[1]>
> debug: xname <- deparse(substitute(x))
> Browse[1]>
> debug: wname <- deparse(substitute(listw))
> Browse[1]>
> debug: NAOK <- deparse(substitute(na.action)) == "na.pass"
> Browse[1]>
> debug: x <- na.action(x)
> Browse[1]>
> debug: na.act <- attr(x, "na.action")
> Browse[1]>
> debug: if (!is.null(na.act)) {
>    subset <- !(1:length(listw$neighbours) %in% na.act)
>    listw <- subset(listw, subset, zero.policy = zero.policy)
> }
> Browse[1]>
> debug: n <- length(listw$neighbours)
> Browse[1]>
> debug: if (n != length(x)) stop("objects of different length")
> Browse[1]>
> debug: wc <- spweights.constants(listw, zero.policy = zero.policy, adjust.n
> = adjust.n)
> Browse[1]>
> debug: S02 <- wc$S0 * wc$S0
> Browse[1]>
> debug: res <- moran(x, listw, wc$n, wc$S0, zero.policy = zero.policy, NAOK =
> NAOK)
> Browse[1]>
> debug: I <- res$I
> Browse[1]>
> debug: K <- res$K
> Browse[1]>
> debug: if (rank) K <- (3 * (3 * wc$n^2 - 7))/(5 * (wc$n^2 - 1))
> Browse[1]>
> debug: EI <- (-1)/wc$n1
> Browse[1]>
> debug: if (randomisation) {
>    VI <- wc$n * (wc$S1 * (wc$nn - 3 * wc$n + 3) - wc$n * wc$S2 +
>        3 * S02)
>    tmp <- K * (wc$S1 * (wc$nn - wc$n) - 2 * wc$n * wc$S2 + 6 *
>        S02)
>    VI <- (VI - tmp)/(wc$n1 * wc$n2 * wc$n3 * S02)
>    VI <- VI - EI^2
> } else {
>    VI <- (wc$nn * wc$S1 - wc$n * wc$S2 + 3 * S02)/(S02 * (wc$nn -
>        1))
>    VI <- VI - EI^2
> }
> Browse[1]>
> debug: VI <- wc$n * (wc$S1 * (wc$nn - 3 * wc$n + 3) - wc$n * wc$S2 + 3 *
> S02)
> Browse[1]>
> debug: tmp <- K * (wc$S1 * (wc$nn - wc$n) - 2 * wc$n * wc$S2 + 6 * S02)
> Browse[1]>
> debug: VI <- (VI - tmp)/(wc$n1 * wc$n2 * wc$n3 * S02)
> Browse[1]>
> debug: VI <- VI - EI^2
> Browse[1]>
> debug: ZI <- (I - EI)/sqrt(VI)
> Browse[1]>
> debug: statistic <- ZI
> Browse[1]>
> debug: names(statistic) <- "Moran I statistic standard deviate"
> Browse[1]>
> debug: if (alternative == "two.sided") PrI <- 2 * pnorm(abs(ZI), lower.tail
> = FALSE) else if (alternative ==
>    "greater") PrI <- pnorm(ZI, lower.tail = FALSE) else PrI <- pnorm(ZI)
> Browse[1]>
> debug: if (!is.finite(PrI) || PrI < 0 || PrI > 1) warning("Out-of-range
> p-value: reconsider test arguments")
> Browse[1]>
> debug: vec <- c(I, EI, VI)
> Browse[1]>
> debug: names(vec) <- c("Moran I statistic", "Expectation", "Variance")
> Browse[1]>
> debug: method <- paste("Moran's I test under",
> ifelse(randomisation, "randomisation", "normality"))
> Browse[1]>
> debug: data.name <- paste(xname, ifelse(rank, "using rank correction",
>    ""), "\nweights:", wname, ifelse(is.null(na.act), "",
> paste("\nomitted:",
>    paste(na.act, collapse = ", "))), "\n")
> Browse[1]>
> debug: res <- list(statistic = statistic, p.value = PrI, estimate = vec,
>    alternative = alternative, method = method, data.name = data.name)
> Browse[1]>
> debug: if (!is.null(na.act)) attr(res, "na.action") <- na.act
> Browse[1]>
> debug: class(res) <- "htest"
> Browse[1]>
> debug: res
> Browse[1]>
> exiting from: moran.test(x, Network)
>
>        Moran's I test under randomisation
>
> data:  x
> weights: Network
>
> Moran I statistic standard deviate = NA, p-value = NA
> alternative hypothesis: greater
> sample estimates:
> Moran I statistic       Expectation          Variance
>             -Inf     -0.0002926544                NA
>
> Warning message:
> In moran.test(x, Network) : Out-of-range p-value: reconsider test arguments
>>
>
>
>
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:
> r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Roger Bivand
> Sent: Wednesday, June 16, 2010 15:08
> To: Michael Haenlein
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] Problem with moran.test function
>
> Well, Moran's I is -Inf, and the analytical variance is NA, so something is
> not right. The problem could lie in x, Network, or the lag of x (when x and
> Network are OK but their combination is unhappy). Can you run moran.test()
> under debug() and check which values lead the value of I to go to -Inf? Is
> this what is going on:
>
> data(columbus)
> set.seed(1)
> x <- log(rpois(n=49, 2))
> x
> moran.test(x, nb2listw(col.gal.nb))
>
> where the current spdep release fails reporting:
>
> Error in lag.listw(listw, z, zero.policy = zero.policy, NAOK =
> NAOK): Variable contains non-finite values
>
> which was a fix introduced four weeks ago, changed to a test on |Inf| from a
> test on NA:
>
> https://r-forge.r-project.org/scm/viewvc.php/pkg/src/lagw.c?root=spdep&r1=244&r2=282
>
> If you update spdep, you'll pick up the improvement (made thanks to a bug
> report by Matias Mayor Fernandez), and if this is the case, the problem is
> in the x.
>
> Hope this helps,
>
> Roger
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From haenlein at escpeurope.eu  Thu Jun 17 11:32:16 2010
From: haenlein at escpeurope.eu (Michael Haenlein)
Date: Thu, 17 Jun 2010 11:32:16 +0200
Subject: [R-sig-Geo] Problem with moran.test function
Message-ID: <AANLkTimMlQe8ZVNgLvmNOKyInMHScRCik-kA6VK4i8Lg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100617/f4a1cd5b/attachment.pl>

From Roger.Bivand at nhh.no  Thu Jun 17 11:50:32 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 17 Jun 2010 11:50:32 +0200 (CEST)
Subject: [R-sig-Geo] Combining multiple polylines into a single polyline
In-Reply-To: <p06240800c839c78b9d96@[128.115.67.9]>
References: <p06240800c839c78b9d96@[128.115.67.9]>
Message-ID: <alpine.LRH.2.00.1006171135060.12369@reclus.nhh.no>

On Sat, 12 Jun 2010, Don MacQueen wrote:

> I have an input shapefile representing roads in a city, read into R where it 
> becomes a SpatialLInesDataFrame.
>
> Looking at just one road at a time, it looks fine when plotted. But in the 
> underlying structure, the single real-world road has been broken up into many 
> shorter polylines, and they are not included in the "correct" order, i.e., 
> end to end.

Is this an rgeos question - you seem to need a topology operation on 
geometries? Since rgeos is work in progress, there isn't support yet, and 
I don't know if there will be, but the use case seems convincing.

Roger

>
> When I sample along the road using spsample() with type='regular', the points 
> aren't equally spaced. I assumed this was because it is broken up into 
> separate lines. So I thought to combine the many short polylines into a 
> single long polyline, i.e., matching endpoints of one polyline with the 
> beginning of the next, dropping redundant nodes, and creating a new SLDF 
> object.
>
> I'm wondering if there's already an algorithm for this somewhere (in R or 
> GRASS, preferably!).
> (That's my main question)
>
>
> However, in my toy example below, consisting of just three polylines making 
> up a single road, spsample() does appear to equally space the points along 
> the entire length. So perhaps my real roads have some other structural 
> problem. Perhaps some endpoints don't match.
>
> Thanks
> -Don
>
> Here's a toy example:
>
> l1 <- matrix(c(1,1, 6,6, 4,8), byrow=TRUE, ncol=2)
> l2 <- matrix(c(4,8, 7,9), byrow=TRUE, ncol=2)
> l3 <- matrix(c(7,9, 11,10, 13,13), byrow=TRUE, ncol=2)
>
> LL1 <- Lines( list( Line(l1)) , ID='32')
> LL2 <- Lines( list( Line(l2)) , ID='147')
> LL3 <- Lines( list( Line(l3)) , ID='21')
>
> ## deliberately constructed out of order
> SL <- SpatialLines( list( LL2, LL3, LL1) )
> df <- data.frame( name=rep('Road',3))
> row.names(df) <- c('147','21','32')
> SLDF <- SpatialLinesDataFrame( SL, df)
>
> ## I would like to reduce to a structure like this:
> lc <- rbind(l1 , l2[-1,] , l3[-1,])
> df1 <- data.frame( name='Road')
> row.names(df1) <- 'a'
> SLDFfix <- SpatialLinesDataFrame( SpatialLines( list( Lines( list( Line(lc)) 
> , ID='a'))) , df1)
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Thu Jun 17 11:52:35 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 17 Jun 2010 11:52:35 +0200 (CEST)
Subject: [R-sig-Geo] Problem with moran.test function
In-Reply-To: <AANLkTimMlQe8ZVNgLvmNOKyInMHScRCik-kA6VK4i8Lg@mail.gmail.com>
References: <AANLkTimMlQe8ZVNgLvmNOKyInMHScRCik-kA6VK4i8Lg@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1006171151180.12369@reclus.nhh.no>

On Thu, 17 Jun 2010, Michael Haenlein wrote:

> Dear Roger,
>
> As per your suggestion, I moved back to spdep, version 0.5-11, 2010-05-31.
>
> Based on your message I think the problem might have been that the input
> file only had two columns and not three. As you might remember from some
> previous conversations we had, I'm using spdep in the context of social
> network analysis. So my initial input file only included information on who
> is connected to whom (e.g., "2 3" or "5 7") but not on how strong/ weak that
> connection is. I now included a third column that has the value 1 for all
> pairs (e.g., "2 3 1" or "5 7 1") and reading now works fine. Probably
> another indication that the read.dat2listw() function had some problems in
> the previous version.
>
> Within the new version of spdep also my estimation of Moran's I now works
> perfectly fine:
>
> Moran I statistic       Expectation          Variance
>     0.0191115263     -0.0002926544      0.0003092456
>
> So I think the issue is solved. If you still would like to look at the input
> files, please let me know and I'm happy to send them to you off-list.

I think the missing column is the key here, so I'll add a check to 
read.dat2listw().

Thanks,

Roger

>
> Thanks again for your help -- I appreciate a lot!
>
> Michael
>
>
>
>
>
> -----Original Message-----
> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Sent: Thursday, June 17, 2010 08:50
> To: Michael Haenlein
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] Problem with moran.test function
>
> On Thu, 17 Jun 2010, Michael Haenlein wrote:
>
> No, it is definitely better to find out what is wrong with Network.txt, as
> the change made in April to sn2listw() - called by read.dat2listw() was to
> trap defective input objects. Please look at traceback() after the error.
> Do debug() on read.dat2listw, and summary() on wmat and sn. Are there
> locale issues in reading the text file, perhaps (decimal symbol?)?
>
> This would feed downstream into the obviously wrong lagged values seen
> below. I'd be interested in access to the input file to strengthen defences
> against unusual weights, or weights seen by the system as unusual. I think
> that an errant final column is becoming a factor, then converted to numeric
> (with large n and many unique weights, their integer indices will become
> large). read.dat2listw() needs to check that there are 3 columns, and that
> the first two are integer, and the third is numeric, I think. But we need to
> see why reading the file is failing.
>
> Roger
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From nikhil.list at gmail.com  Thu Jun 17 14:28:11 2010
From: nikhil.list at gmail.com (Nikhil Kaza)
Date: Thu, 17 Jun 2010 08:28:11 -0400
Subject: [R-sig-Geo] Combining multiple polylines into a single polyline
In-Reply-To: <p06240800c839c78b9d96@[128.115.67.9]>
References: <p06240800c839c78b9d96@[128.115.67.9]>
Message-ID: <BE81B013-C5DF-4B65-ADBF-DB5E81B5C137@gmail.com>


Not a R solution. But does v.generalize in grass help?

http://grass.osgeo.org/wiki/V.generalize_tutorial



Nikhil Kaza
Asst. Professor,
City and Regional Planning
University of North Carolina

nikhil.list at gmail.com

On Jun 12, 2010, at 8:05 PM, Don MacQueen wrote:

> I have an input shapefile representing roads in a city, read into R  
> where it becomes a SpatialLInesDataFrame.
>
> Looking at just one road at a time, it looks fine when plotted. But  
> in the underlying structure, the single real-world road has been  
> broken up into many shorter polylines, and they are not included in  
> the "correct" order, i.e., end to end.
>
> When I sample along the road using spsample() with type='regular',  
> the points aren't equally spaced. I assumed this was because it is  
> broken up into separate lines. So I thought to combine the many  
> short polylines into a single long polyline, i.e., matching  
> endpoints of one polyline with the beginning of the next, dropping  
> redundant nodes, and creating a new SLDF object.
>
> I'm wondering if there's already an algorithm for this somewhere (in  
> R or GRASS, preferably!).
> (That's my main question)
>
>
> However, in my toy example below, consisting of just three polylines  
> making up a single road, spsample() does appear to equally space the  
> points along the entire length. So perhaps my real roads have some  
> other structural problem. Perhaps some endpoints don't match.
>
> Thanks
> -Don
>
> Here's a toy example:
>
> l1 <- matrix(c(1,1, 6,6, 4,8), byrow=TRUE, ncol=2)
> l2 <- matrix(c(4,8, 7,9), byrow=TRUE, ncol=2)
> l3 <- matrix(c(7,9, 11,10, 13,13), byrow=TRUE, ncol=2)
>
> LL1 <- Lines( list( Line(l1)) , ID='32')
> LL2 <- Lines( list( Line(l2)) , ID='147')
> LL3 <- Lines( list( Line(l3)) , ID='21')
>
> ## deliberately constructed out of order
> SL <- SpatialLines( list( LL2, LL3, LL1) )
> df <- data.frame( name=rep('Road',3))
> row.names(df) <- c('147','21','32')
> SLDF <- SpatialLinesDataFrame( SL, df)
>
> ## I would like to reduce to a structure like this:
> lc <- rbind(l1 , l2[-1,] , l3[-1,])
> df1 <- data.frame( name='Road')
> row.names(df1) <- 'a'
> SLDFfix <-  
> SpatialLinesDataFrame( SpatialLines( list( Lines( list( Line(lc)) ,  
> ID='a'))) , df1)
>
> -- 
> --------------------------------------
> Don MacQueen
> Environmental Protection Department
> Lawrence Livermore National Laboratory
> Livermore, CA, USA
> 925-423-1062
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From elaine.kuo.tw at gmail.com  Thu Jun 17 15:38:21 2010
From: elaine.kuo.tw at gmail.com (elaine kuo)
Date: Thu, 17 Jun 2010 21:38:21 +0800
Subject: [R-sig-Geo] Moran I for generalized linear model
Message-ID: <AANLkTimyApgjo3Jdf8AdtDyF1e6Bc63HBReJa3x3mFEw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100617/a2ae1cec/attachment.pl>

From elaine.kuo.tw at gmail.com  Thu Jun 17 15:47:34 2010
From: elaine.kuo.tw at gmail.com (elaine kuo)
Date: Thu, 17 Jun 2010 21:47:34 +0800
Subject: [R-sig-Geo] Moran I for generalized linear model
In-Reply-To: <AANLkTimyApgjo3Jdf8AdtDyF1e6Bc63HBReJa3x3mFEw@mail.gmail.com>
References: <AANLkTimyApgjo3Jdf8AdtDyF1e6Bc63HBReJa3x3mFEw@mail.gmail.com>
Message-ID: <AANLkTim77OZfGB9lziw410_3xRARv8h2Q1ed7DefpXMC@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100617/50f2f4e6/attachment.pl>

From Roger.Bivand at nhh.no  Thu Jun 17 16:48:56 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 17 Jun 2010 16:48:56 +0200 (CEST)
Subject: [R-sig-Geo] Moran I for generalized linear model
In-Reply-To: <AANLkTim77OZfGB9lziw410_3xRARv8h2Q1ed7DefpXMC@mail.gmail.com>
References: <AANLkTimyApgjo3Jdf8AdtDyF1e6Bc63HBReJa3x3mFEw@mail.gmail.com>
	<AANLkTim77OZfGB9lziw410_3xRARv8h2Q1ed7DefpXMC@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1006171647330.14823@reclus.nhh.no>

On Thu, 17 Jun 2010, elaine kuo wrote:

> This is Elaine.
>>
>> I am try the R package spdep to calculate Moran I for each of the 7
>> generalized linear
>> models generated by 3 predictors respectively.
>>

There is no accepted authority for any test for the residuals of a glm() 
fit for spatial autocorrelation (a paper in Geographical Analysis is not 
adequate authority - one in Biometrika or Statistics in Medicine might 
be). Because a glm object is also an lm object, you may - at your own risk 
- use lm.morantest() as if the fitted model was an lm object. Since it is 
very hard to simulate correlated multivariate counts, we have no idea 
whether this test behaves as it should.

Hope this helps,

Roger

>
>    The models were generated by bird richness and the habitual conditions,
> based on a grid system with the number corresponding to the variables of the
> models.
>
>
>> I read the pdf manual but still confounded which function should be used to
>> achieved the goal.
>>
>
> Thanks
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From grant.j.gillis at gmail.com  Thu Jun 17 20:27:09 2010
From: grant.j.gillis at gmail.com (Grant Gillis)
Date: Thu, 17 Jun 2010 14:27:09 -0400
Subject: [R-sig-Geo] creating a mean of ascii grids
Message-ID: <AANLkTilLqFqfOoC1PFSSjI9hJ8jdAwxIfiYiCwWvAd9w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100617/6aeced53/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Thu Jun 17 20:39:56 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 17 Jun 2010 19:39:56 +0100
Subject: [R-sig-Geo] creating a mean of ascii grids
In-Reply-To: <AANLkTilLqFqfOoC1PFSSjI9hJ8jdAwxIfiYiCwWvAd9w@mail.gmail.com>
References: <AANLkTilLqFqfOoC1PFSSjI9hJ8jdAwxIfiYiCwWvAd9w@mail.gmail.com>
Message-ID: <AANLkTilTu4QSTLWCWiwTqJJacszHYnDmKDQ7Hm5obXNB@mail.gmail.com>

On Thu, Jun 17, 2010 at 7:27 PM, Grant Gillis <grant.j.gillis at gmail.com> wrote:

> grid1 <- readAsciiGrid("C:\\junk\\grid1.asc")
> grid2 <- readAsciiGrid("C:\\junk\\grid2.asc")
>
> After this no luck with the "mean" command

 These things are SpatialGridDataFrames and can be 'cbind'ed together:

 > gAll = cbind(grid1,grid2)

 > spplot(gAll)

now compute the row means and add them to the data frame:

 > gAll$mean = apply(gAll at data[,1:2],1,mean)
 > spplot(gAll)

 Just to make sure it was doing the right thing I made some test data:

 > gAll at data[,1]=1:100
 > gAll at data[,2]=100:1
 > gAll$mean = apply(gAll at data[,1:2],1,mean)
 > spplot(gAll)

  - which shows me two ramps in opposite directions and a very flat
mean, with value:

 > gAll at data[,3]
  [1] 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5
 [16] 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5

 How's that? It probably only works if the grids have the same spatial
basis. If you've really got many of these, then write a loop.

Barry


From rundel at gmail.com  Thu Jun 17 20:50:36 2010
From: rundel at gmail.com (Colin Rundel)
Date: Thu, 17 Jun 2010 11:50:36 -0700
Subject: [R-sig-Geo] Combining multiple polylines into a single polyline
In-Reply-To: <alpine.LRH.2.00.1006171135060.12369@reclus.nhh.no>
References: <p06240800c839c78b9d96@[128.115.67.9]>
	<alpine.LRH.2.00.1006171135060.12369@reclus.nhh.no>
Message-ID: <5FACA1BB-7838-42F4-A42C-467053245192@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100617/f75956db/attachment.pl>

From r.hijmans at gmail.com  Thu Jun 17 20:51:25 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 17 Jun 2010 11:51:25 -0700
Subject: [R-sig-Geo] creating a mean of ascii grids
In-Reply-To: <AANLkTilTu4QSTLWCWiwTqJJacszHYnDmKDQ7Hm5obXNB@mail.gmail.com>
References: <AANLkTilLqFqfOoC1PFSSjI9hJ8jdAwxIfiYiCwWvAd9w@mail.gmail.com>
	<AANLkTilTu4QSTLWCWiwTqJJacszHYnDmKDQ7Hm5obXNB@mail.gmail.com>
Message-ID: <AANLkTilv6JkzQnY35iEJD8xyu5YIzZIaMQg_NQQdyB1C@mail.gmail.com>

Or like this:

library(raster)
files = list.files(path="C:\\junk\\", pattern='.asc')
s = stack(files)
r = mean(s)

plot(r)
r = writeRaster(r, filename='mean.asc')



On Thu, Jun 17, 2010 at 11:39 AM, Barry Rowlingson
<b.rowlingson at lancaster.ac.uk> wrote:
> On Thu, Jun 17, 2010 at 7:27 PM, Grant Gillis <grant.j.gillis at gmail.com> wrote:
>
>> grid1 <- readAsciiGrid("C:\\junk\\grid1.asc")
>> grid2 <- readAsciiGrid("C:\\junk\\grid2.asc")
>>
>> After this no luck with the "mean" command
>
> ?These things are SpatialGridDataFrames and can be 'cbind'ed together:
>
> ?> gAll = cbind(grid1,grid2)
>
> ?> spplot(gAll)
>
> now compute the row means and add them to the data frame:
>
> ?> gAll$mean = apply(gAll at data[,1:2],1,mean)
> ?> spplot(gAll)
>
> ?Just to make sure it was doing the right thing I made some test data:
>
> ?> gAll at data[,1]=1:100
> ?> gAll at data[,2]=100:1
> ?> gAll$mean = apply(gAll at data[,1:2],1,mean)
> ?> spplot(gAll)
>
> ?- which shows me two ramps in opposite directions and a very flat
> mean, with value:
>
> ?> gAll at data[,3]
> ?[1] 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5
> ?[16] 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5 50.5
>
> ?How's that? It probably only works if the grids have the same spatial
> basis. If you've really got many of these, then write a loop.
>
> Barry
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From tomfool at as220.org  Fri Jun 18 02:40:27 2010
From: tomfool at as220.org (tom sgouros)
Date: Thu, 17 Jun 2010 20:40:27 -0400
Subject: [R-sig-Geo] rgdal
Message-ID: <28367.1276821627@as220.org>


Hello all:

I read this in the rgdal documentation:

> The GDAL and PROJ.4 libraries are external to the package, and, when
> installing the package from source, must be correctly installed first. 

Does "correctly" mean something different from the default?  I installed
PROJ.4 on my Mac OS X (10.6) machine, using 'make all' and 'make
install'.  I saw no errors, and I see libproj.a sitting happily in
/usr/local/lib which seems pretty standard to me, but when I try to
install rgdal, I get this:

  ...
  checking proj_api.h usability... yes
  checking proj_api.h presence... yes
  checking for proj_api.h... yes
  checking for pj_init_plus in -lproj... no
  Error: libproj.a not found.
  If the PROJ.4 library is installed in a non-standard location,
  use --configure-args='--with-proj-lib=/opt/local/lib' for example,
  replacing /opt/local/* with appropriate values for your installation.
  If PROJ.4 is not installed, install it.

Before it was installed, the configure choked on the line about
proj_api.h.  

It was already installed, but per those directions, I tried this:

> install.packages(c("rgdal"),lib="/Library/Frameworks/R.framework/Resources/library",contriburl=contrib.url(getOption("repos"),'source'),type='source',dependencies=TRUE,configure.args=c(PROJ='--with-proj-lib=/usr/local/lib'))

But it didn't seem to change the result, and I get the same message
about not being able to find libproj.a, even after it does find
proj_api.h 

(Incidentally, this came to me via an attempted install of a package
that depends on rgdal, so I didn't have a chance to read the rgdal
documentation until after the original install failed.  I wish there
were some way to flag those kinds of dependencies in a way that
install.packages could deal with.)

Can anyone suggest why this configure isn't working and how I can fix
it?

Many thanks in advance,

 -tom

-- 
 --------------------------------------------------------
 Check out "Ten Things You Don't Know About Rhode Island"
     http://whatcheer.net      http://sgouros.com


From tech_dev at wildintellect.com  Fri Jun 18 03:18:47 2010
From: tech_dev at wildintellect.com (Alex Mandel)
Date: Thu, 17 Jun 2010 18:18:47 -0700
Subject: [R-sig-Geo] rgdal
In-Reply-To: <28367.1276821627@as220.org>
References: <28367.1276821627@as220.org>
Message-ID: <4C1AC977.6070200@wildintellect.com>

On 06/17/2010 05:40 PM, tom sgouros wrote:
> 
> Hello all:
> 
> I read this in the rgdal documentation:
> 
>> The GDAL and PROJ.4 libraries are external to the package, and, when
>> installing the package from source, must be correctly installed first. 
> 
> Does "correctly" mean something different from the default?  I installed
> PROJ.4 on my Mac OS X (10.6) machine, using 'make all' and 'make
> install'.  I saw no errors, and I see libproj.a sitting happily in
> /usr/local/lib which seems pretty standard to me, but when I try to
> install rgdal, I get this:
> 
>   ...
>   checking proj_api.h usability... yes
>   checking proj_api.h presence... yes
>   checking for proj_api.h... yes
>   checking for pj_init_plus in -lproj... no
>   Error: libproj.a not found.
>   If the PROJ.4 library is installed in a non-standard location,
>   use --configure-args='--with-proj-lib=/opt/local/lib' for example,
>   replacing /opt/local/* with appropriate values for your installation.
>   If PROJ.4 is not installed, install it.
> 
> Before it was installed, the configure choked on the line about
> proj_api.h.  
> 
> It was already installed, but per those directions, I tried this:
> 
>> install.packages(c("rgdal"),lib="/Library/Frameworks/R.framework/Resources/library",contriburl=contrib.url(getOption("repos"),'source'),type='source',dependencies=TRUE,configure.args=c(PROJ='--with-proj-lib=/usr/local/lib'))
> 
Those instructions seem to indicate that it should be:
configure.args='--with-proj-lib=/usr/local/lib'
while the R code you put in may seem similar and theoretically provide
the same, try doing it exactly like the example.

The other option to consider is install Proj and GDAL from the Frameworks:
http://www.kyngchaos.com/software/frameworks

I know people have gotten the frameworks to work.

Enjoy,
Alex


From massimodisasha at gmail.com  Fri Jun 18 03:29:09 2010
From: massimodisasha at gmail.com (Massimo Di Stefano)
Date: Fri, 18 Jun 2010 03:29:09 +0200
Subject: [R-sig-Geo] rgdal
In-Reply-To: <4C1AC977.6070200@wildintellect.com>
References: <28367.1276821627@as220.org> <4C1AC977.6070200@wildintellect.com>
Message-ID: <F9053C2D-B7E8-4358-BDAC-C6412AFF1D2C@gmail.com>

Hi,

to install rgdal usually i do :

R64 CMD install rgdal_0.6-27.tar.gz --configure-args='--with-proj-include=/Library/Frameworks/PROJ.framework/unix/include --with-proj-lib=/Library/Frameworks/PROJ.framework/unix/lib'

to download rgdal, from your local repository (mine is in italy)

http://dssm.unipa.it/CRAN/src/contrib/

download the latest rgdal source (now it is : rgdal_0.6-27.tar.gz)
you need the .tar.gz package so usually i do from the shell :

wget http://dssm.unipa.it/CRAN/src/contrib/rgdal_0.6-27.tar.gz
R64 CMD install rgdal_0.6-27.tar.gz --configure-args='--with-proj-include=/Library/Frameworks/PROJ.framework/unix/include --with-proj-lib=/Library/Frameworks/PROJ.framework/unix/lib'

hope this helps.

Ciao,

Massimo.

Il giorno 18/giu/2010, alle ore 03.18, Alex Mandel ha scritto:

> On 06/17/2010 05:40 PM, tom sgouros wrote:
>> 
>> Hello all:
>> 
>> I read this in the rgdal documentation:
>> 
>>> The GDAL and PROJ.4 libraries are external to the package, and, when
>>> installing the package from source, must be correctly installed first. 
>> 
>> Does "correctly" mean something different from the default?  I installed
>> PROJ.4 on my Mac OS X (10.6) machine, using 'make all' and 'make
>> install'.  I saw no errors, and I see libproj.a sitting happily in
>> /usr/local/lib which seems pretty standard to me, but when I try to
>> install rgdal, I get this:
>> 
>>  ...
>>  checking proj_api.h usability... yes
>>  checking proj_api.h presence... yes
>>  checking for proj_api.h... yes
>>  checking for pj_init_plus in -lproj... no
>>  Error: libproj.a not found.
>>  If the PROJ.4 library is installed in a non-standard location,
>>  use --configure-args='--with-proj-lib=/opt/local/lib' for example,
>>  replacing /opt/local/* with appropriate values for your installation.
>>  If PROJ.4 is not installed, install it.
>> 
>> Before it was installed, the configure choked on the line about
>> proj_api.h.  
>> 
>> It was already installed, but per those directions, I tried this:
>> 
>>> install.packages(c("rgdal"),lib="/Library/Frameworks/R.framework/Resources/library",contriburl=contrib.url(getOption("repos"),'source'),type='source',dependencies=TRUE,configure.args=c(PROJ='--with-proj-lib=/usr/local/lib'))
>> 
> Those instructions seem to indicate that it should be:
> configure.args='--with-proj-lib=/usr/local/lib'
> while the R code you put in may seem similar and theoretically provide
> the same, try doing it exactly like the example.
> 
> The other option to consider is install Proj and GDAL from the Frameworks:
> http://www.kyngchaos.com/software/frameworks
> 
> I know people have gotten the frameworks to work.
> 
> Enjoy,
> Alex
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From tomfool at as220.org  Fri Jun 18 03:35:03 2010
From: tomfool at as220.org (tom sgouros)
Date: Thu, 17 Jun 2010 21:35:03 -0400
Subject: [R-sig-Geo] rgdal
In-Reply-To: <4C1AC977.6070200@wildintellect.com> 
References: <28367.1276821627@as220.org> <4C1AC977.6070200@wildintellect.com>
Message-ID: <456.1276824903@as220.org>


Alex Mandel <tech_dev at wildintellect.com> wrote:

> On 06/17/2010 05:40 PM, tom sgouros wrote:
> > 
> > Hello all:
> > 
> > I read this in the rgdal documentation:
> > 
> >> The GDAL and PROJ.4 libraries are external to the package, and, when
> >> installing the package from source, must be correctly installed first. 
> > 
> > Does "correctly" mean something different from the default?  I installed
> > PROJ.4 on my Mac OS X (10.6) machine, using 'make all' and 'make
> > install'.  I saw no errors, and I see libproj.a sitting happily in
> > /usr/local/lib which seems pretty standard to me, but when I try to
> > install rgdal, I get this:
> > 
> >   ...
> >   checking proj_api.h usability... yes
> >   checking proj_api.h presence... yes
> >   checking for proj_api.h... yes
> >   checking for pj_init_plus in -lproj... no
> >   Error: libproj.a not found.
> >   If the PROJ.4 library is installed in a non-standard location,
> >   use --configure-args='--with-proj-lib=/opt/local/lib' for example,
> >   replacing /opt/local/* with appropriate values for your installation.
> >   If PROJ.4 is not installed, install it.
> > 
> > Before it was installed, the configure choked on the line about
> > proj_api.h.  
> > 
> > It was already installed, but per those directions, I tried this:
> > 
> >> install.packages(c("rgdal"),lib="/Library/Frameworks/R.framework/Resources/library",contriburl=contrib.url(getOption("repos"),'source'),type='source',dependencies=TRUE,configure.args=c(PROJ='--with-proj-lib=/usr/local/lib'))
> > 
> Those instructions seem to indicate that it should be:
> configure.args='--with-proj-lib=/usr/local/lib'
> while the R code you put in may seem similar and theoretically provide
> the same, try doing it exactly like the example.

The example is from a command line invocation of ./configure.  How that
relates to an install.packages() option wasn't obvious to me.  I was
just copying the example in the install.packages() documentation.  But I
tried it your way just now and it still doesn't work.  Same error.
Besides, what's so non-standard about /usr/local/lib?

> 
> The other option to consider is install Proj and GDAL from the Frameworks:
> http://www.kyngchaos.com/software/frameworks
> 
> I know people have gotten the frameworks to work.

I'll try that, but I'm still mystified.

Thank you,

 -tom


> 
> Enjoy,
> Alex
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 


-- 
 --------------------------------------------------------
 Check out "Ten Things You Don't Know About Rhode Island"
     http://whatcheer.net      http://sgouros.com


From Roger.Bivand at nhh.no  Fri Jun 18 10:04:22 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 18 Jun 2010 10:04:22 +0200 (CEST)
Subject: [R-sig-Geo] rgdal
In-Reply-To: <456.1276824903@as220.org>
References: <28367.1276821627@as220.org> <4C1AC977.6070200@wildintellect.com>
	<456.1276824903@as220.org>
Message-ID: <alpine.LRH.2.00.1006180944020.18137@reclus.nhh.no>

On Thu, 17 Jun 2010, tom sgouros wrote:

Your syntax for the configure.args= argument was wrong, and most likely it 
would fail on GDAL next. If you want to install from source, install 
PROJ.4 first, test it (you need the headers and the *shared* library), 
then install and test GDAL. When they are in place, determine the correct 
locations and use configure.args= without any PROJ=.

If this sounds hard, use the Kyngchaos route, which is well tried, both 
for getting the external dependencies and installing rgdal from source, or 
indeed for installing binary rgdal (William Kyngesburye is kind enough to 
keep things pretty updated).

The easiest route is to do:

setRepositories(ind=1:2)
install.packages("rgdal")

which looking at the list archives would have shown, for example google 
on:

R-sig-geo rgdal MAC

or similar. The second repository in the list is in this case on OSX at 
Oxford on CRAN extras, and the rgdal binary with bundled PROJ.4 and GDAL 
dependencies is built by Brian Ripley:

http://www.stats.ox.ac.uk/pub/RWin/bin/macosx/leopard/contrib/2.11/rgdal_0.6-27.tgz

or similar for the R 2.10 and development 2.12 releases.

Unless you need extra drivers, installing from CRAN extras version is 
probably the easiest.

Roger

>
> Alex Mandel <tech_dev at wildintellect.com> wrote:
>
>> On 06/17/2010 05:40 PM, tom sgouros wrote:
>>>
>>> Hello all:
>>>
>>> I read this in the rgdal documentation:
>>>
>>>> The GDAL and PROJ.4 libraries are external to the package, and, when
>>>> installing the package from source, must be correctly installed first.
>>>
>>> Does "correctly" mean something different from the default?  I installed
>>> PROJ.4 on my Mac OS X (10.6) machine, using 'make all' and 'make
>>> install'.  I saw no errors, and I see libproj.a sitting happily in
>>> /usr/local/lib which seems pretty standard to me, but when I try to
>>> install rgdal, I get this:
>>>
>>>   ...
>>>   checking proj_api.h usability... yes
>>>   checking proj_api.h presence... yes
>>>   checking for proj_api.h... yes
>>>   checking for pj_init_plus in -lproj... no
>>>   Error: libproj.a not found.
>>>   If the PROJ.4 library is installed in a non-standard location,
>>>   use --configure-args='--with-proj-lib=/opt/local/lib' for example,
>>>   replacing /opt/local/* with appropriate values for your installation.
>>>   If PROJ.4 is not installed, install it.
>>>
>>> Before it was installed, the configure choked on the line about
>>> proj_api.h.
>>>
>>> It was already installed, but per those directions, I tried this:
>>>
>>>> install.packages(c("rgdal"),lib="/Library/Frameworks/R.framework/Resources/library",contriburl=contrib.url(getOption("repos"),'source'),type='source',dependencies=TRUE,configure.args=c(PROJ='--with-proj-lib=/usr/local/lib'))
>>>
>> Those instructions seem to indicate that it should be:
>> configure.args='--with-proj-lib=/usr/local/lib'
>> while the R code you put in may seem similar and theoretically provide
>> the same, try doing it exactly like the example.
>
> The example is from a command line invocation of ./configure.  How that
> relates to an install.packages() option wasn't obvious to me.  I was
> just copying the example in the install.packages() documentation.  But I
> tried it your way just now and it still doesn't work.  Same error.
> Besides, what's so non-standard about /usr/local/lib?
>
>>
>> The other option to consider is install Proj and GDAL from the Frameworks:
>> http://www.kyngchaos.com/software/frameworks
>>
>> I know people have gotten the frameworks to work.
>
> I'll try that, but I'm still mystified.
>
> Thank you,
>
> -tom
>
>
>>
>> Enjoy,
>> Alex
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From mayeul.kauffmann at jrc.ec.europa.eu  Fri Jun 18 10:08:55 2010
From: mayeul.kauffmann at jrc.ec.europa.eu (Mayeul KAUFFMANN)
Date: Fri, 18 Jun 2010 10:08:55 +0200
Subject: [R-sig-Geo] Combining multiple polylines into a single polyline
In-Reply-To: <alpine.LRH.2.00.1006171135060.12369@reclus.nhh.no>
References: <p06240800c839c78b9d96@[128.115.67.9]>
	<alpine.LRH.2.00.1006171135060.12369@reclus.nhh.no>
Message-ID: <000001cb0ebd$7f95c280$7ec14780$@kauffmann@jrc.ec.europa.eu>

Hi,
Just a question to try and understand where the problem comes from: Are the
lines correctly represented in the shape files (and the problems comes when
importing/processing it), or is it already buggy in the shape files?

Also, you might want to look at the solution I use since I have the same
application as you and it works perfectly with a Qgis-R tandem.
I have lines as a shp layer in a QuantumGIS project, with distinct attributes
for each lines.
I use the "manageR" plugin to transfer data (line and DEM) to R:
http://www.ftools.ca/plugins.html

Then I created a "manageR" plugin (using library spatstat among others) to
sample along a line to get the profile according to DEM. It works nicely.
For the moment, it's only available at the link below, but you can copy-paste to
the tools.xml file:

http://code.google.com/p/ftools-qgis/source/detail?r=150
http://code.google.com/p/ftools-qgis/source/detail?r=151
(because of xml, the "<-" sign is represented as "&lt;-")

Hope it helps,
Mayeul
_____________________________________________________
Dr. Mayeul KAUFFMANN, Conflict Specialist
European Commission, Joint Research Centre (JRC)
Institute for the Protection and Security of the Citizen (IPSC)
Global Security and Crisis Management - ISFEREA
Via E. Fermi 2749 - I-21027 Ispra (VA), ITALY
Phone: (+39) 033278 5071
http://isferea.jrc.ec.europa.eu/Staff/Pages/Kauffmann-Mayeul.aspx

(Office: building 48c, 1st floor, room 123. TP: 483)

-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Roger Bivand
Sent: Thursday, June 17, 2010 11:51 AM
To: Don MacQueen
Cc: r-sig-geo at stat.math.ethz.ch; Colin Rundel
Subject: Re: [R-sig-Geo] Combining multiple polylines into a single polyline

On Sat, 12 Jun 2010, Don MacQueen wrote:

> I have an input shapefile representing roads in a city, read into R where it 
> becomes a SpatialLInesDataFrame.
>
> Looking at just one road at a time, it looks fine when plotted. But in the 
> underlying structure, the single real-world road has been broken up into many 
> shorter polylines, and they are not included in the "correct" order, i.e., 
> end to end.

Is this an rgeos question - you seem to need a topology operation on 
geometries? Since rgeos is work in progress, there isn't support yet, and 
I don't know if there will be, but the use case seems convincing.

Roger

>
> When I sample along the road using spsample() with type='regular', the points 
> aren't equally spaced. I assumed this was because it is broken up into 
> separate lines. So I thought to combine the many short polylines into a 
> single long polyline, i.e., matching endpoints of one polyline with the 
> beginning of the next, dropping redundant nodes, and creating a new SLDF 
> object.
>
> I'm wondering if there's already an algorithm for this somewhere (in R or 
> GRASS, preferably!).
> (That's my main question)
>
>
> However, in my toy example below, consisting of just three polylines making 
> up a single road, spsample() does appear to equally space the points along 
> the entire length. So perhaps my real roads have some other structural 
> problem. Perhaps some endpoints don't match.
>
> Thanks
> -Don
>
> Here's a toy example:
>
> l1 <- matrix(c(1,1, 6,6, 4,8), byrow=TRUE, ncol=2)
> l2 <- matrix(c(4,8, 7,9), byrow=TRUE, ncol=2)
> l3 <- matrix(c(7,9, 11,10, 13,13), byrow=TRUE, ncol=2)
>
> LL1 <- Lines( list( Line(l1)) , ID='32')
> LL2 <- Lines( list( Line(l2)) , ID='147')
> LL3 <- Lines( list( Line(l3)) , ID='21')
>
> ## deliberately constructed out of order
> SL <- SpatialLines( list( LL2, LL3, LL1) )
> df <- data.frame( name=rep('Road',3))
> row.names(df) <- c('147','21','32')
> SLDF <- SpatialLinesDataFrame( SL, df)
>
> ## I would like to reduce to a structure like this:
> lc <- rbind(l1 , l2[-1,] , l3[-1,])
> df1 <- data.frame( name='Road')
> row.names(df1) <- 'a'
> SLDFfix <- SpatialLinesDataFrame( SpatialLines( list( Lines( list( Line(lc)) 
> , ID='a'))) , df1)
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From hengl at spatial-analyst.net  Fri Jun 18 10:19:50 2010
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Fri, 18 Jun 2010 10:19:50 +0200
Subject: [R-sig-Geo] creating a mean of ascii grids
In-Reply-To: <AANLkTilLqFqfOoC1PFSSjI9hJ8jdAwxIfiYiCwWvAd9w@mail.gmail.com>
References: <AANLkTilLqFqfOoC1PFSSjI9hJ8jdAwxIfiYiCwWvAd9w@mail.gmail.com>
Message-ID: <000c01cb0ebf$058bedf0$10a3c9d0$@net>


Looks like your grids are relatively small, so you could just sum them per row:

> ?rowSums
> grids <- readGDAL("grid1.asc"); names(grids) <- "g1"
> grids$g2 <- readGDAL(grids2.asc")$band1
> grids$avg <- rowSums(grids at data, na.rm=FALSE, dims=1)/length(names(grids))

Otherwise SAGA can be very efficient in getting grid statistics for large grids e.g.:

> rsaga.get.usage(lib="geostatistics_grid", module=5)

[http://spatial-analyst.net/scripts/getMOD12C1.R]

T. Hengl
http://home.medewerker.uva.nl/t.hengl/ 


> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-
> bounces at stat.math.ethz.ch] On Behalf Of Grant Gillis
> Sent: Thursday, June 17, 2010 8:27 PM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] creating a mean of ascii grids
> 
> Hello All,
> 
> Thanks in advance.
> 
> I have many ascii raster files with values representing resistance to animal
> movement.  I would like to merge these files into one with the cells
> representing the mean cell value from all of the files but I have not found
> an easy way to do this.  Hopefully I haven't missed something easy.
> 
> Example:
> 
> grid1
> 
> ncols         10
> nrows         10
> xllcorner     1.0
> yllcorner     1.0
> cellsize      1.0
> NODATA_value  -9999
> 0.000357 0.001027 0.000805 0.000000 0.081807 0.187900 0.104016 0.022658
> 0.009466 0.001935
> 0.003548 0.127713 0.209348 0.000000 0.223908 0.038593 0.130113 0.153949
> 0.077215 0.006899
> 0.011093 1.000000 0.431280 0.408257 0.000000 0.000000 0.110307 0.025862
> 0.137367 0.062129
> 0.034994 0.216908 0.353100 0.272441 0.377437 0.302346 0.000000 0.096949
> 0.103691 0.109096
> 0.082386 0.106230 0.143232 0.082990 0.000000 0.108077 0.303234 0.000000
> 0.028730 0.177887
> 0.038909 0.214878 0.070393 0.065658 0.069213 0.062199 0.320038 0.033622
> 0.000000 0.194666
> 0.019571 0.207906 0.072075 0.063715 0.048383 0.289683 1.000000 0.016230
> 0.203176 0.000000
> 0.024110 0.181760 0.038990 0.140245 0.184284 0.213371 0.181881 0.208175
> 0.040404 0.010333
> 0.000000 0.087435 0.181934 0.139346 0.140992 0.081971 0.005192 0.003207
> 0.001927 0.000927
> 0.000000 0.000000 0.016308 0.016914 0.012778 0.006049 0.002248 0.000651
> 0.000341 0.000197
> 
> grid2
> 
> ncols         10
> nrows         10
> xllcorner     1.0
> yllcorner     1.0
> cellsize      1.0
> NODATA_value  -9999
> 0.000468 0.001199 0.000920 0.000000 0.121743 0.280769 0.161228 0.041467
> 0.018927 0.003883
> 0.003525 0.135052 0.228564 0.000000 0.332760 0.054795 0.181881 0.314980
> 0.159828 0.014272
> 0.008427 1.000000 0.437725 0.501494 0.000000 0.000000 0.234149 0.052453
> 0.384025 0.142958
> 0.024514 0.176738 0.346569 0.267034 0.399569 0.344980 0.000000 0.371773
> 1.000000 0.178494
> 0.056282 0.071736 0.096446 0.059201 0.000000 0.061408 0.233373 0.000000
> 0.036457 0.209228
> 0.026387 0.143127 0.045834 0.043704 0.041783 0.023811 0.053071 0.016786
> 0.000000 0.221727
> 0.013008 0.137858 0.047432 0.041280 0.029609 0.111149 0.105711 0.008439
> 0.222293 0.000000
> 0.015954 0.119895 0.025838 0.091063 0.117556 0.127833 0.130537 0.212232
> 0.044132 0.012076
> 0.000000 0.057663 0.119803 0.090802 0.091032 0.054078 0.005361 0.004239
> 0.003214 0.001584
> 0.000000 0.000000 0.010709 0.011090 0.008433 0.004449 0.002848 0.002021
> 0.001321 0.000456
> 
> 
> grid1 <- readAsciiGrid("C:\\junk\\grid1.asc")
> grid2 <- readAsciiGrid("C:\\junk\\grid2.asc")
> 
> After this no luck with the "mean" command
> 
> Thank you and sorry for a potentially easy newbie question.
> 
> G.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From manguefleur at yahoo.fr  Fri Jun 18 11:30:39 2010
From: manguefleur at yahoo.fr (Lho Lho)
Date: Fri, 18 Jun 2010 09:30:39 +0000 (GMT)
Subject: [R-sig-Geo] image() with levels
Message-ID: <531868.63159.qm@web29217.mail.ird.yahoo.com>

Dear all 

I am beginner in R and I am involved in geostatistics analysis

I failed to map my "values" with contour.filled() or image() [and add levels afterward with contour()] because I do not know how I should shape my data in order to use image() or contour.filled()

I attached my data file for someone who can help me by providing me the code 

Best regards,

lho


      
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Myfile
Type: application/octet-stream
Size: 61350 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100618/2c933e8b/attachment.obj>

From manguefleur at yahoo.fr  Fri Jun 18 12:02:11 2010
From: manguefleur at yahoo.fr (Lho Lho)
Date: Fri, 18 Jun 2010 10:02:11 +0000 (GMT)
Subject: [R-sig-Geo] Fw : image() with levels
Message-ID: <61398.11475.qm@web29214.mail.ird.yahoo.com>



--- En date de?: Ven 18.6.10, Lho Lho <manguefleur at yahoo.fr> a ?crit?:

> De: Lho Lho <manguefleur at yahoo.fr>
> Objet: image() with levels
> ?: "helpgeoR helpgeoR" <r-sig-geo at stat.math.ethz.ch>
> Date: Vendredi 18 juin 2010, 9h30
> Dear all 
> 
> I am beginner in R and I am involved in geostatistics
> analysis
> 
> I failed to map my "values" with contour.filled() or
> image() [and add levels afterward with contour()] because I
> do not know how I should shape my data in order to use
> image() or contour.filled()
> 
> I attached my data file for someone who can help me by
> providing me the code 
> 
> Best regards,
> 
> lho
> 
> 
> ? ? ? 


      
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Myfile
Type: application/octet-stream
Size: 61350 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100618/a0686ec2/attachment.obj>

From Roger.Bivand at nhh.no  Fri Jun 18 12:28:27 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 18 Jun 2010 12:28:27 +0200 (CEST)
Subject: [R-sig-Geo] Fw : image() with levels
In-Reply-To: <61398.11475.qm@web29214.mail.ird.yahoo.com>
References: <61398.11475.qm@web29214.mail.ird.yahoo.com>
Message-ID: <alpine.LRH.2.00.1006181217180.18137@reclus.nhh.no>

On Fri, 18 Jun 2010, Lho Lho wrote:

You are very impatient, and have forwarded your message (with a large and 
unnecessary attachment) to the list as a repeat thread. This smells like 
homework. Please read the posting guide:

http://www.r-project.org/posting-guide.html

and respect other users' time (and server capacity and net bandwidth)

Questions should be well-framed, but yours are incomprehensible - it is 
impossible to know what your problem is (the subject is also very 
unclear). Please examine carefully a sample of other threads and the 
posting guide to see how to ask questions that may attract answers.

In general, attachments are not welcome. If an attachment seems 
essential, please only provide a link to the files considered for 
attachment, and do not attach the files themselves. Sending attachments to 
over 1600 list members uses energy on multiple servers without any need, 
and wastes server capacity. Only members prepared to reply are likely to 
need to access the attachment, so a link is much more practical, even if 
it takes a little longer to set up.

Your list admin,

Roger

>
>
> --- En date de?: Ven 18.6.10, Lho Lho <manguefleur at yahoo.fr> a ?crit?:
>
>> De: Lho Lho <manguefleur at yahoo.fr>
>> Objet: image() with levels
>> ?: "helpgeoR helpgeoR" <r-sig-geo at stat.math.ethz.ch>
>> Date: Vendredi 18 juin 2010, 9h30
>> Dear all 
>> 
>> I am beginner in R and I am involved in geostatistics
>> analysis
>> 
>> I failed to map my "values" with contour.filled() or
>> image() [and add levels afterward with contour()] because I
>> do not know how I should shape my data in order to use
>> image() or contour.filled()
>> 
>> I attached my data file for someone who can help me by
>> providing me the code 
>> 
>> Best regards,
>> 
>> lho
>> 
>> 
>> ? ? ?

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From tomfool at as220.org  Fri Jun 18 15:20:02 2010
From: tomfool at as220.org (tom sgouros)
Date: Fri, 18 Jun 2010 09:20:02 -0400
Subject: [R-sig-Geo] rgdal
In-Reply-To: <alpine.LRH.2.00.1006180944020.18137@reclus.nhh.no> 
References: <28367.1276821627@as220.org> <4C1AC977.6070200@wildintellect.com>
	<456.1276824903@as220.org>
	<alpine.LRH.2.00.1006180944020.18137@reclus.nhh.no>
Message-ID: <28149.1276867202@as220.org>


Roger:

Thank you for the answers.  But I still don't understand why the default
installation wouldn't work before I tried to specify the location
explicitly?  /usr/local/lib doesn't seem non-standard to me, and it was
the default from the PROJ 'make install'.  Why wouldn't the default
rgdal installation work with the default PROJ installation?

Also, how would you suggest testing the PROJ installation?  Or GDAL, for
that matter.  Neither makefile seems to have a test target, and I'm
coming to them as dependencies of a different package that I want to
use, so they are not libraries with which I am familiar.  Where can I
find a test program?

Thank you,

 -tom


Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Thu, 17 Jun 2010, tom sgouros wrote:
> 
> Your syntax for the configure.args= argument was wrong, and most
> likely it would fail on GDAL next. If you want to install from source,
> install PROJ.4 first, test it (you need the headers and the *shared*
> library), then install and test GDAL. When they are in place,
> determine the correct locations and use configure.args= without any
> PROJ=.
> 
> If this sounds hard, use the Kyngchaos route, which is well tried,
> both for getting the external dependencies and installing rgdal from
> source, or indeed for installing binary rgdal (William Kyngesburye is
> kind enough to keep things pretty updated).
> 
> The easiest route is to do:
> 
> setRepositories(ind=1:2)
> install.packages("rgdal")
> 
> which looking at the list archives would have shown, for example
> google on:
> 
> R-sig-geo rgdal MAC
> 
> or similar. The second repository in the list is in this case on OSX
> at Oxford on CRAN extras, and the rgdal binary with bundled PROJ.4 and
> GDAL dependencies is built by Brian Ripley:
> 
> http://www.stats.ox.ac.uk/pub/RWin/bin/macosx/leopard/contrib/2.11/rgdal_0.6-27.tgz
> 
> or similar for the R 2.10 and development 2.12 releases.
> 
> Unless you need extra drivers, installing from CRAN extras version is
> probably the easiest.
> 
> Roger
> 
> >
> > Alex Mandel <tech_dev at wildintellect.com> wrote:
> >
> >> On 06/17/2010 05:40 PM, tom sgouros wrote:
> >>>
> >>> Hello all:
> >>>
> >>> I read this in the rgdal documentation:
> >>>
> >>>> The GDAL and PROJ.4 libraries are external to the package, and, when
> >>>> installing the package from source, must be correctly installed first.
> >>>
> >>> Does "correctly" mean something different from the default?  I installed
> >>> PROJ.4 on my Mac OS X (10.6) machine, using 'make all' and 'make
> >>> install'.  I saw no errors, and I see libproj.a sitting happily in
> >>> /usr/local/lib which seems pretty standard to me, but when I try to
> >>> install rgdal, I get this:
> >>>
> >>>   ...
> >>>   checking proj_api.h usability... yes
> >>>   checking proj_api.h presence... yes
> >>>   checking for proj_api.h... yes
> >>>   checking for pj_init_plus in -lproj... no
> >>>   Error: libproj.a not found.
> >>>   If the PROJ.4 library is installed in a non-standard location,
> >>>   use --configure-args='--with-proj-lib=/opt/local/lib' for example,
> >>>   replacing /opt/local/* with appropriate values for your installation.
> >>>   If PROJ.4 is not installed, install it.
> >>>
> >>> Before it was installed, the configure choked on the line about
> >>> proj_api.h.
> >>>
> >>> It was already installed, but per those directions, I tried this:
> >>>
> >>>> install.packages(c("rgdal"),lib="/Library/Frameworks/R.framework/Resources/library",contriburl=contrib.url(getOption("repos"),'source'),type='source',dependencies=TRUE,configure.args=c(PROJ='--with-proj-lib=/usr/local/lib'))
> >>>
> >> Those instructions seem to indicate that it should be:
> >> configure.args='--with-proj-lib=/usr/local/lib'
> >> while the R code you put in may seem similar and theoretically provide
> >> the same, try doing it exactly like the example.
> >
> > The example is from a command line invocation of ./configure.  How that
> > relates to an install.packages() option wasn't obvious to me.  I was
> > just copying the example in the install.packages() documentation.  But I
> > tried it your way just now and it still doesn't work.  Same error.
> > Besides, what's so non-standard about /usr/local/lib?
> >
> >>
> >> The other option to consider is install Proj and GDAL from the Frameworks:
> >> http://www.kyngchaos.com/software/frameworks
> >>
> >> I know people have gotten the frameworks to work.
> >
> > I'll try that, but I'm still mystified.
> >
> > Thank you,
> >
> > -tom
> >
> >
> >>
> >> Enjoy,
> >> Alex
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at stat.math.ethz.ch
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >
> >
> >
> 
> -- 
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
> 







-- 
 --------------------------------------------------------
 Check out "Ten Things You Don't Know About Rhode Island"
     http://whatcheer.net      http://sgouros.com


From Roger.Bivand at nhh.no  Fri Jun 18 16:38:19 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 18 Jun 2010 16:38:19 +0200 (CEST)
Subject: [R-sig-Geo] rgdal
In-Reply-To: <28149.1276867202@as220.org>
References: <28367.1276821627@as220.org> <4C1AC977.6070200@wildintellect.com>
	<456.1276824903@as220.org>
	<alpine.LRH.2.00.1006180944020.18137@reclus.nhh.no>
	<28149.1276867202@as220.org>
Message-ID: <alpine.LRH.2.00.1006181534170.18137@reclus.nhh.no>

On Fri, 18 Jun 2010, tom sgouros wrote:

>
> Roger:
>
> Thank you for the answers.  But I still don't understand why the default
> installation wouldn't work before I tried to specify the location
> explicitly?  /usr/local/lib doesn't seem non-standard to me, and it was
> the default from the PROJ 'make install'.  Why wouldn't the default
> rgdal installation work with the default PROJ installation?

I believe that your syntax in the install.packages() command was wrong, 
you had:

configure.args=c(PROJ='--with-proj-lib=/usr/local/lib')

which I don't think is what is needed, I think that the name PROJ= is 
redundant, but c(rgdal='--with-proj-lib=/usr/local/lib') would seem to 
correspond to the documentation, because this is a configure argument to 
rgdal. In the example, two R packages are being installed, each with a 
configure argument.

>
> Also, how would you suggest testing the PROJ installation?

make check in proj-4.7.0 for that release.

> Or GDAL, for that matter.

It is a separate download - look for gdalautotest for the major release 
family.

> Neither makefile seems to have a test target, and I'm coming to them as 
> dependencies of a different package that I want to use, so they are not 
> libraries with which I am familiar.  Where can I find a test program?

Usually it is sufficient to run ogrinfo on any vector file, and gdalinfo 
on any raster file (both for simple drivers). This shows that the 
dynamically loaded dependencies are satisfied. Running the gdalautotest is 
more for developers.

Hope this helps,

Roger

>
> Thank you,
>
> -tom
>
>
> Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Thu, 17 Jun 2010, tom sgouros wrote:
>>
>> Your syntax for the configure.args= argument was wrong, and most
>> likely it would fail on GDAL next. If you want to install from source,
>> install PROJ.4 first, test it (you need the headers and the *shared*
>> library), then install and test GDAL. When they are in place,
>> determine the correct locations and use configure.args= without any
>> PROJ=.
>>
>> If this sounds hard, use the Kyngchaos route, which is well tried,
>> both for getting the external dependencies and installing rgdal from
>> source, or indeed for installing binary rgdal (William Kyngesburye is
>> kind enough to keep things pretty updated).
>>
>> The easiest route is to do:
>>
>> setRepositories(ind=1:2)
>> install.packages("rgdal")
>>
>> which looking at the list archives would have shown, for example
>> google on:
>>
>> R-sig-geo rgdal MAC
>>
>> or similar. The second repository in the list is in this case on OSX
>> at Oxford on CRAN extras, and the rgdal binary with bundled PROJ.4 and
>> GDAL dependencies is built by Brian Ripley:
>>
>> http://www.stats.ox.ac.uk/pub/RWin/bin/macosx/leopard/contrib/2.11/rgdal_0.6-27.tgz
>>
>> or similar for the R 2.10 and development 2.12 releases.
>>
>> Unless you need extra drivers, installing from CRAN extras version is
>> probably the easiest.
>>
>> Roger
>>
>>>
>>> Alex Mandel <tech_dev at wildintellect.com> wrote:
>>>
>>>> On 06/17/2010 05:40 PM, tom sgouros wrote:
>>>>>
>>>>> Hello all:
>>>>>
>>>>> I read this in the rgdal documentation:
>>>>>
>>>>>> The GDAL and PROJ.4 libraries are external to the package, and, when
>>>>>> installing the package from source, must be correctly installed first.
>>>>>
>>>>> Does "correctly" mean something different from the default?  I installed
>>>>> PROJ.4 on my Mac OS X (10.6) machine, using 'make all' and 'make
>>>>> install'.  I saw no errors, and I see libproj.a sitting happily in
>>>>> /usr/local/lib which seems pretty standard to me, but when I try to
>>>>> install rgdal, I get this:
>>>>>
>>>>>   ...
>>>>>   checking proj_api.h usability... yes
>>>>>   checking proj_api.h presence... yes
>>>>>   checking for proj_api.h... yes
>>>>>   checking for pj_init_plus in -lproj... no
>>>>>   Error: libproj.a not found.
>>>>>   If the PROJ.4 library is installed in a non-standard location,
>>>>>   use --configure-args='--with-proj-lib=/opt/local/lib' for example,
>>>>>   replacing /opt/local/* with appropriate values for your installation.
>>>>>   If PROJ.4 is not installed, install it.
>>>>>
>>>>> Before it was installed, the configure choked on the line about
>>>>> proj_api.h.
>>>>>
>>>>> It was already installed, but per those directions, I tried this:
>>>>>
>>>>>> install.packages(c("rgdal"), 
lib="/Library/Frameworks/R.framework/Resources/library", 
contriburl=contrib.url(getOption("repos"),'source'), 
type='source', 
dependencies=TRUE, 
configure.args=c(PROJ='--with-proj-lib=/usr/local/lib'))

>>>>>
>>>> Those instructions seem to indicate that it should be:
>>>> configure.args='--with-proj-lib=/usr/local/lib'
>>>> while the R code you put in may seem similar and theoretically provide
>>>> the same, try doing it exactly like the example.
>>>
>>> The example is from a command line invocation of ./configure.  How that
>>> relates to an install.packages() option wasn't obvious to me.  I was
>>> just copying the example in the install.packages() documentation.  But I
>>> tried it your way just now and it still doesn't work.  Same error.
>>> Besides, what's so non-standard about /usr/local/lib?
>>>
>>>>
>>>> The other option to consider is install Proj and GDAL from the Frameworks:
>>>> http://www.kyngchaos.com/software/frameworks
>>>>
>>>> I know people have gotten the frameworks to work.
>>>
>>> I'll try that, but I'm still mystified.
>>>
>>> Thank you,
>>>
>>> -tom
>>>
>>>
>>>>
>>>> Enjoy,
>>>> Alex
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>
>>>
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>
>
>
>
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Giovanna.Jonalasinio at uniroma1.it  Sat Jun 19 16:01:38 2010
From: Giovanna.Jonalasinio at uniroma1.it (Giovanna.Jonalasinio at uniroma1.it)
Date: Sat, 19 Jun 2010 16:01:38 +0200
Subject: [R-sig-Geo] =?iso-8859-1?q?Giovanna_Jonalasinio_=E8_fuori_ufficio?=
	=?iso-8859-1?q?=2C_Out_of_Office?=
Message-ID: <OFFDBCDAB4.16335D15-ONC1257747.004D0E01-C1257747.004D0E01@Uniroma1.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100619/35919896/attachment.pl>

From hualianglin at gmail.com  Sun Jun 20 14:28:49 2010
From: hualianglin at gmail.com (Hualiang Lin)
Date: Sun, 20 Jun 2010 20:28:49 +0800
Subject: [R-sig-Geo] r-sig-geo
Message-ID: <AANLkTimi8AuH1I1Q1L8IWQ5LC3zJtByZ5whk-6kcfMve@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100620/1e131baa/attachment.pl>

From elaine.kuo.tw at gmail.com  Sun Jun 20 14:36:43 2010
From: elaine.kuo.tw at gmail.com (elaine kuo)
Date: Sun, 20 Jun 2010 20:36:43 +0800
Subject: [R-sig-Geo] comparing non-spatial and spatial generalized linear
	models
In-Reply-To: <AANLkTilvh3NAStRgkPKhaeTO32V1Hd8LFK3XRnktKsE9@mail.gmail.com>
References: <AANLkTilvh3NAStRgkPKhaeTO32V1Hd8LFK3XRnktKsE9@mail.gmail.com>
Message-ID: <AANLkTimsksVEbSPakfUGlxKIiRbqPFQUP8ymdOPMR2xp@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100620/57218430/attachment.pl>

From diaomi at gmail.com  Mon Jun 21 05:26:11 2010
From: diaomi at gmail.com (Mi Diao)
Date: Sun, 20 Jun 2010 23:26:11 -0400
Subject: [R-sig-Geo] spatial durbin model with large dataset
Message-ID: <AANLkTikvzu8z2nwNNn_RfXPYm2pp3Gp2Y0ZJGMBinsy3@mail.gmail.com>

Dear all,

I am trying to calibrate a Spatial Durbin Model for a dataset with
52000 observations. Geoda can handle a dataset of this size, but it
can only estimate spatial lag and spatial error model. Can the spdep
package of R handle my dataset?

Thanks a lot for your kind help!

Mi


From Beth.Crase at nt.gov.au  Mon Jun 21 07:51:39 2010
From: Beth.Crase at nt.gov.au (Beth Crase)
Date: Mon, 21 Jun 2010 15:21:39 +0930
Subject: [R-sig-Geo] help with writing focal operations to new raster file
Message-ID: <DFD69EDC6B175E4D93E0D013C92962661A3C7768D8@EMPGB-ES1.prod.main.ntgov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100621/831f983c/attachment.pl>

From r.hijmans at gmail.com  Mon Jun 21 08:28:46 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sun, 20 Jun 2010 23:28:46 -0700
Subject: [R-sig-Geo] help with writing focal operations to new raster
	file
In-Reply-To: <DFD69EDC6B175E4D93E0D013C92962661A3C7768D8@EMPGB-ES1.prod.main.ntgov>
References: <DFD69EDC6B175E4D93E0D013C92962661A3C7768D8@EMPGB-ES1.prod.main.ntgov>
Message-ID: <AANLkTilIjPJkYlV9mf3_V0b92BY7v4wOnB4C2GEqCHAL@mail.gmail.com>

Dear Beth,

This one is puzzling:

> Error in .Internal(which(x)) : no internal function "which"

My guess is that something has gone wrong with the installation or
raster or a mismatch with the R version. Could you re-install raster
(from CRAN)? Are you using an older version or R? I recently heard
from two people with similar error messages; they resolved the problem
by in one case by properly installing raster, and by updating R in the
other case. I am guessing here as I cannot reproduce this error. Could
you please send me your sessionInfo()

Apart from that, you could restate your script to something like this:

trial <- raster("data.asc")
focal.trial <-  focal(trial, ngb=3, fun=mean, na.rm=TRUE)

If you also want to save the results to file, you can add a filename argument:

focal.trial <-  focal(trial, ngb=3, fun=mean, na.rm=TRUE, filename="focal.tif")

In your example you provide the filename "raster.focal" of which
'focal" was interpreted as the filename extension. The extension is
used to guess the file format you want (unless you also provide a
"format= " argument). The function expects a known extension such as
tif, asc, img, rst, ....  In this case, it simply warned you that
"focal" could not be associated with a file format.

Robert


On Sun, Jun 20, 2010 at 10:51 PM, Beth Crase <Beth.Crase at nt.gov.au> wrote:
> Dear List,
> I am new to the raster package, but very excited that it can do focal calculations.
>
> I read an Ascii file as a Spatial Grid (using spdep package) and then to a RasterLayer (using raster package) as follows:
> #read ascii file in as a SpatialGrid
> trial<-readAsciiGrid("data.asc")
> #convert SpatialGrid to RasterLayer
> raster.trial <- raster(trial)
> Then I tried to clone RasterLayer so I have somewhere to put the focal values, but I am not sure whether this is correct:
> raster.focal <- raster.trial
> Then I tried to calculate focal values from "raster.trial" and write them to "raster.focal"
> focal(raster.trial, ngb=3, fun=mean, na.rm=TRUE, filename="raster.focal")
>
> Unfortunately I get the following errors:
> Error in .Internal(which(x)) : no internal function "which"
> In addition: Warning message:
> In .getFormat(filename) : extension .focalis unknown. Using default format.
> I am not sure how to interpret the error messages.
> And I am not sure I have the correct approach with cloning the first raster file.
>
> Can someone help?
> Cheers
> Beth.
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From elaine.kuo.tw at gmail.com  Mon Jun 21 09:32:19 2010
From: elaine.kuo.tw at gmail.com (elaine kuo)
Date: Mon, 21 Jun 2010 15:32:19 +0800
Subject: [R-sig-Geo] how to find observed Moran's I value using
	moran.test(spdep)
In-Reply-To: <AANLkTimGg8nLrXOy6oWfOxv_VNMU5i75F7KXALGvIGPP@mail.gmail.com>
References: <AANLkTimGg8nLrXOy6oWfOxv_VNMU5i75F7KXALGvIGPP@mail.gmail.com>
Message-ID: <AANLkTikUxRPOS_bC29r5iWWK8jRy8JmFob4xF9uMxH2S@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100621/1696ff1f/attachment.pl>

From Roger.Bivand at nhh.no  Mon Jun 21 09:46:08 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 21 Jun 2010 09:46:08 +0200 (CEST)
Subject: [R-sig-Geo] how to find observed Moran's I value using
 moran.test(spdep)
In-Reply-To: <AANLkTikUxRPOS_bC29r5iWWK8jRy8JmFob4xF9uMxH2S@mail.gmail.com>
References: <AANLkTimGg8nLrXOy6oWfOxv_VNMU5i75F7KXALGvIGPP@mail.gmail.com>
	<AANLkTikUxRPOS_bC29r5iWWK8jRy8JmFob4xF9uMxH2S@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1006210939090.1009@reclus.nhh.no>

On Mon, 21 Jun 2010, elaine kuo wrote:

> Dear ,
>
> This is Elaine.
>
> I am computing moran's I using moran.test for
> a generalized linear model (multiregression).

Don't do this, the expected value and the calculated variance under 
normality and randomisation are wrong. Use lm.morantest(), but be aware 
that it is for an lm() fit, not a glm() fit. There are no tests with 
statistical authority for glm residuals (as far as I know).

One would usually assign the output of a test to an object, then examine 
the object with str() to find the required value, here the list component 
called estimate, first vector element.

So lm.morantest(modg1, modg1.listw)$estimate[1] is the calculated value of 
Moran's I for your glm model, for what it is worth.

Roger

>
> The following contents are the results, and I cannot find the observed
> Moran's I mentioned as estimate in the manual.
> Please kindly help indicate if there is observed Moran's I did not notice or
> other method for calculation.
> Thanks
>
> Elaine
>
> data:  residuals(modg1)
> weights: modg1.listw
>
> Moran I statistic standard deviate = 786.6486, p-value < 2.2e-16
> alternative hypothesis: greater
> sample estimates:
> Moran I statistic       Expectation          Variance
>     6.351413e-01     -2.052545e-04      6.523188e-07
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Mon Jun 21 11:13:49 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 21 Jun 2010 11:13:49 +0200 (CEST)
Subject: [R-sig-Geo] spatial durbin model with large dataset
In-Reply-To: <AANLkTikvzu8z2nwNNn_RfXPYm2pp3Gp2Y0ZJGMBinsy3@mail.gmail.com>
References: <AANLkTikvzu8z2nwNNn_RfXPYm2pp3Gp2Y0ZJGMBinsy3@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1006211056050.1009@reclus.nhh.no>

On Sun, 20 Jun 2010, Mi Diao wrote:

> Dear all,
>
> I am trying to calibrate a Spatial Durbin Model for a dataset with
> 52000 observations. Geoda can handle a dataset of this size, but it
> can only estimate spatial lag and spatial error model. Can the spdep
> package of R handle my dataset?

Yes. At a recent demo, I ran the 25k ?house example on a small memory 
older laptop without trouble (http://spatial.nhh.no/R/sea10.zip). With 50k 
and many RHS variables, you may find a busy Windows 1Gb machine gasps a 
bit - if so, shut down other programs (IE etc.) before starting R. Look at 
?lagsarlm, then ?impacts. Typically, you'll need something like:

# lw is your weights object, probably from nb2listw()
# df is the data.frame with your data

# first generate sparse matrix product traces
W <- as(as_dgRMatrix_lw(lw), "CsparseMatrix")
trMat <- trW(W, type="MC")

SD_fit <- lagsarlm(y ~ x, data=df, listw=lw, type="mixed",
   method="Matrix", tr=trMat, control=list(compiled_sse=TRUE))
# type="mixed" fits a Spatial Durbin model;
# method could also be "Chebyshev" or "MC" for approximations,
# "Matrix" uses updating sparse Cholesky Jacobians, see ?do_ldet
# for details. "Matrix" needs symmetric neighbours, some other methods
# may not. Beware of k-nearest neighbour schemes, for the same reasons
# as in GeoDa

summary(SD_fit)

# now generate samples from the fitted model to assess the
# significance of the impacts
imp_SD_fit <- impacts(SD_fit, tr=trMat, R=2000)
summary(imp_SD_fit)
plot(imp_SD_fit)
summary(imp_SD_fit, zstats=TRUE, short=TRUE)

Hope this helps,

Roger

>
> Thanks a lot for your kind help!
>
> Mi
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Maxime.Pauwels at univ-lille1.fr  Mon Jun 21 14:35:13 2010
From: Maxime.Pauwels at univ-lille1.fr (Maxime Pauwels)
Date: Mon, 21 Jun 2010 14:35:13 +0200
Subject: [R-sig-Geo] scale bar on spplot
Message-ID: <4C1F5C81.2030203@univ-lille1.fr>

Dear all,

I have a single little question that may be straighforward for much of you.
I'm performing spplot and don't know how to eliminate the scale bar from 
the graph, which is in default settings.
Could you help.

Thank you

max


-- 
Maxime Pauwels
Researcher ID: http://www.researcherid.com/rid/A-1745-2009

Laboratoire de G?n?tique et Evolution des Populations V?g?tales
UMR CNRS 8016
Universit? de Lille, USTL-Lille1
http://gepv.univ-lille1.fr 
Tel  : +33 3 20 33 62 38
Fax  : +33 3 20 43 69 79
			
?Impose ta chance, serre ton bonheur et va vers ton risque. A te regarder, ils s?habitueront.?
Ren? Char


From edzer.pebesma at uni-muenster.de  Mon Jun 21 14:53:10 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 21 Jun 2010 14:53:10 +0200
Subject: [R-sig-Geo] scale bar on spplot
In-Reply-To: <4C1F5C81.2030203@univ-lille1.fr>
References: <4C1F5C81.2030203@univ-lille1.fr>
Message-ID: <4C1F60B6.4010407@uni-muenster.de>

library(sp)
data(meuse.grid)
gridded(meuse.grid)=~x+y
spplot(meuse.grid[1], colorkey=NULL)

I learned this from

library(lattice)
?levelplot

spplot is not much more than a wrapper around levelplot (for regions)
and xyplot (for points).

On 06/21/2010 02:35 PM, Maxime Pauwels wrote:
> Dear all,
> 
> I have a single little question that may be straighforward for much of you.
> I'm performing spplot and don't know how to eliminate the scale bar from
> the graph, which is in default settings.
> Could you help.
> 
> Thank you
> 
> max
> 
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From aslantas at metu.edu.tr  Mon Jun 21 15:23:22 2010
From: aslantas at metu.edu.tr (Pinar Aslantas Bostan)
Date: Mon, 21 Jun 2010 16:23:22 +0300
Subject: [R-sig-Geo] GWR Analysis
Message-ID: <20100621162322.93173clp8ybphhhm@horde.metu.edu.tr>

Dear Roger,

Maybe you can remember, last week I asked some questions about gwr  
analysis and you helped me. In order to make refresh, I want to  
summarize my problem. I am trying to make gwr analysis to predict  
precipitation distribution on a DEM. I have two datasets; first one is  
'station' consists of 225 prec. measurements and 3 independent  
variables (Z, V1, V2). The second one is 'DEM' dataset which has 31203  
# of pixels. Firstly I tried with using SPDF (SpatialPointsDataFrame)  
and obtained predicted precipitations on DEM. But when I plot the  
predicted precipitation values, I saw a lot of negative values which  
is impossible to get such a values. I thought that this was caused  
because I used point data sets (SPDF) for grid. Then I tried with  
using SGDF (SpatialGridDataFrame). At this time, gwr() resulted with  
an error message "new data matrix rows mismatch". You told me that  
'The error message is generated when the number of columns in the  
matrix of X variables is not the same in data and and fit.points.' I  
gave some information about datasets below.

> class(station)
[1] "SpatialPointsDataFrame"
attr(,"package")
[1] "sp"
> names(station)
[1] "PREC" "Z"    "V1"   "V2"
> class(dem)
[1] "SpatialGridDataFrame"
attr(,"package")
[1] "sp"
> names(dem)
[1] "Z"  "V1" "V2"

'PREC' is the observations and I want to get predictions of them on 'dem'.

I checked the str() and variables are stored in the same way.

> bw=gwr.sel(PREC~Z+V1+V2,data=station,adapt=T)
> xx1<-gwr(PREC~Z+V1+V2,station,adapt=bw,hatmatrix=TRUE)
> x1 <-gwr(PREC~Z+V1+V2,data=station,adapt=bw, fit.points = dem,  
> predict=T, se.fit=T, fittedGWRobject=xx1)
Error in gwr(PREC ~ Z + V1 + V2, data = station, adapt = bw,  
fit.points = dem,  :
   new data matrix rows mismatch


If I wrote 'predict=F' then gwr() works but gives only sum.w,  
coefficients and localR2.

I tried to run gwr() under debug but I didn't understand the output.

I really don't understand the problem and need help.

Best regards,
Pinar


From Roger.Bivand at nhh.no  Mon Jun 21 18:14:11 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 21 Jun 2010 18:14:11 +0200 (CEST)
Subject: [R-sig-Geo] GWR Analysis
In-Reply-To: <20100621162322.93173clp8ybphhhm@horde.metu.edu.tr>
References: <20100621162322.93173clp8ybphhhm@horde.metu.edu.tr>
Message-ID: <alpine.LRH.2.00.1006211808140.2164@reclus.nhh.no>

On Mon, 21 Jun 2010, Pinar Aslantas Bostan wrote:

> Dear Roger,
>
> Maybe you can remember, last week I asked some questions about gwr analysis 
> and you helped me. In order to make refresh, I want to summarize my problem. 
> I am trying to make gwr analysis to predict precipitation distribution on a 
> DEM. I have two datasets; first one is 'station' consists of 225 prec. 
> measurements and 3 independent variables (Z, V1, V2). The second one is 'DEM' 
> dataset which has 31203 # of pixels. Firstly I tried with using SPDF 
> (SpatialPointsDataFrame) and obtained predicted precipitations on DEM. But 
> when I plot the predicted precipitation values, I saw a lot of negative 
> values which is impossible to get such a values.

No, this is just a weighted linear model. Unless you limit it by design, 
all such linear models will happily predict out of domain. Consider how 
you might by design limit the response to non-negative values.

> I thought that this was 
> caused because I used point data sets (SPDF) for grid.

Why would you think that? All you need to provoke this is a slightly 
unfortunate placing of the met stations (all in west and falling trend 
eastwards beyond the observed stations). Did the regular lm() fit also 
predict negative values (very likely yes).

This isn't a GWR problem, it's more general. Fix it for lm() first.

Roger

> Then I tried with 
> using SGDF (SpatialGridDataFrame). At this time, gwr() resulted with an error 
> message "new data matrix rows mismatch". You told me that 'The error message 
> is generated when the number of columns in the matrix of X variables is not 
> the same in data and and fit.points.' I gave some information about datasets 
> below.
>
>> class(station)
> [1] "SpatialPointsDataFrame"
> attr(,"package")
> [1] "sp"
>> names(station)
> [1] "PREC" "Z"    "V1"   "V2"
>> class(dem)
> [1] "SpatialGridDataFrame"
> attr(,"package")
> [1] "sp"
>> names(dem)
> [1] "Z"  "V1" "V2"
>
> 'PREC' is the observations and I want to get predictions of them on 'dem'.
>
> I checked the str() and variables are stored in the same way.
>
>> bw=gwr.sel(PREC~Z+V1+V2,data=station,adapt=T)
>> xx1<-gwr(PREC~Z+V1+V2,station,adapt=bw,hatmatrix=TRUE)
>> x1 <-gwr(PREC~Z+V1+V2,data=station,adapt=bw, fit.points = dem, predict=T, 
>> se.fit=T, fittedGWRobject=xx1)
> Error in gwr(PREC ~ Z + V1 + V2, data = station, adapt = bw, fit.points = 
> dem,  :
> new data matrix rows mismatch
>
>
> If I wrote 'predict=F' then gwr() works but gives only sum.w, coefficients 
> and localR2.
>
> I tried to run gwr() under debug but I didn't understand the output.
>
> I really don't understand the problem and need help.
>
> Best regards,
> Pinar
>
>
> ----------------------------------------------------------------
> This message was sent using IMP, the Internet Messaging Program.
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From mark_connolly at acm.org  Mon Jun 21 19:58:21 2010
From: mark_connolly at acm.org (Mark Connolly)
Date: Mon, 21 Jun 2010 13:58:21 -0400
Subject: [R-sig-Geo] sequence of interpolation of spatial attributes
Message-ID: <4C1FA83D.6030104@acm.org>

Say I have two related observations that can be combined to derive a third:

c = a + b

and I want interpolations of all three.

I could do something equivalent to

(form 1) c = krige(a) + krige(b)

or

(form 2) c = krige(a + b)

The issue become important when a is a subset of a very large set.  In 
my case, a is a set of observations at one of five depths on one of 385 
dates.  b is static throughout.

For each date, I want a and c, so I have to perform krige(a) in any 
case.  I want krige(b) so that has to be performed once.

After the static krige(b) is complete and a krige(a) has been performed, 
the compute time of form 1 is less than a second.  If I used form 2, the 
compute time of each depth and date doubles.  If I want other derived 
attributes, I add another computationally expensive step.  In real 
terms, I have four derived attributes.  Form 2 will take 240 hours 
versus 60 cpu hours for form 1.

So my question is, are there reasons one form might be better than 
another?  Intuitively, form 2 is better, but if the original 
interpolations are good, I can't think of any reason the second form 
would be invalid.  I can overlay (randomly selected) observations onto 
interpolations and qualitatively compare the two.  Sometimes 1 seems 
better and sometimes 2 seems better.  I am willing to randomly compare 
the two methods if that makes sense and if there is a quantitative 
comparison I could make.

Anyone have any suggestions?

Thanks!


From nikhil.list at gmail.com  Mon Jun 21 21:28:29 2010
From: nikhil.list at gmail.com (Nikhil Kaza)
Date: Mon, 21 Jun 2010 15:28:29 -0400
Subject: [R-sig-Geo] cell2nb
Message-ID: <8AF43E41-9CEA-4AF8-B12D-40A2E8067259@gmail.com>

While answering a question on R-help, I was monkeying with the code in  
cell2nb  in spdep (5.11) to see if it can be made faster.

Getting rid of the for loop and replacing with lapply and apply only  
marginally improves the performance

   n <- nrow*ncol
     for (i in 1:n) {
         res[[i]] <- sort(mrc2vi(xcell(vi2mrc(i, nrow, ncol),
             nrow, ncol, torus), nrow, ncol))
         rownames[i] <- paste(vi2mrc(i, nrow, ncol), collapse = ":")
     }

However, I do not understand why the loop has to run through 1:n. If  
the adjacency matrix is symmertic, should we not just make ceil[n/2]  
comparisons and take advantage of its symmetry? Am I missing  
something? Not sure if it makes it any faster though.




Nikhil Kaza
Asst. Professor,
City and Regional Planning
University of North Carolina

nikhil.list at gmail.com


From Roger.Bivand at nhh.no  Mon Jun 21 21:56:30 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 21 Jun 2010 21:56:30 +0200 (CEST)
Subject: [R-sig-Geo] cell2nb
In-Reply-To: <8AF43E41-9CEA-4AF8-B12D-40A2E8067259@gmail.com>
References: <8AF43E41-9CEA-4AF8-B12D-40A2E8067259@gmail.com>
Message-ID: <alpine.LRH.2.00.1006212138280.2164@reclus.nhh.no>

On Mon, 21 Jun 2010, Nikhil Kaza wrote:

> While answering a question on R-help, I was monkeying with the code in 
> cell2nb  in spdep (5.11) to see if it can be made faster.
>
> Getting rid of the for loop and replacing with lapply and apply only 
> marginally improves the performance
>
> n <- nrow*ncol
>   for (i in 1:n) {
>       res[[i]] <- sort(mrc2vi(xcell(vi2mrc(i, nrow, ncol),
>           nrow, ncol, torus), nrow, ncol))
>       rownames[i] <- paste(vi2mrc(i, nrow, ncol), collapse = ":")
>   }
>
> However, I do not understand why the loop has to run through 1:n. If the 
> adjacency matrix is symmertic, should we not just make ceil[n/2] comparisons 
> and take advantage of its symmetry? Am I missing something? Not sure if it 
> makes it any faster though.
>

The reason why cell2nb() was written was originally to provide a way of 
generating neighbours for grids on a torus, which is hard to do for 
coordinates of a planar grid. These are typically needed to simulate 
processes without edge effects, for modest grid sizes. Agreed, neighbours 
in grids are symmetric, but an "nb" object contains both symmetric links 
for generality (the "neig" class in ade4 does not), so these would have to 
be added in afterwards. Typically, dnearneigh() with the step distance as 
its threshold generates rook neighbours in acceptable time, with the 
diagonal distance it yields queen neighbours:

> library(spdep)
> system.time(res <- cell2nb(10, 10))
    user  system elapsed
   0.099   0.000   0.099
> system.time({grd <- GridTopology(c(0,0), c(1,1), c(10,10));
+ resd <- dnearneigh(coordinates(grd), 0, 1)})
    user  system elapsed
   0.003   0.000   0.002
> all.equal(res, resd, check.attributes=FALSE)
[1] TRUE
> system.time(res <- cell2nb(50, 50))   user  system elapsed
   2.404   0.001   2.407
> system.time({grd <- GridTopology(c(0,0), c(1,1), c(50,50));
+ resd <- dnearneigh(coordinates(grd), 0, 1)})
    user  system elapsed
   0.267   0.000   0.267
> all.equal(res, resd, check.attributes=FALSE)[1] TRUE
> system.time(res <- cell2nb(100, 100))   user  system elapsed
   9.817   0.003   9.872
> system.time({grd <- GridTopology(c(0,0), c(1,1), c(100,100));
+ resd <- dnearneigh(coordinates(grd), 0, 1)})
    user  system elapsed
   4.125   0.001   4.127
> all.equal(res, resd, check.attributes=FALSE)[1] TRUE

It degrades but not as fast, and may be speeded up using rgeos soon (using 
a spatial index on the points to cherry-pick, rather than brute-force as 
now).

Roger


>
>
>
> Nikhil Kaza
> Asst. Professor,
> City and Regional Planning
> University of North Carolina
>
> nikhil.list at gmail.com
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Gema.FAviles at uclm.es  Mon Jun 21 22:31:16 2010
From: Gema.FAviles at uclm.es (GEMA FERNANDEZ-AVILES CALDERON)
Date: Mon, 21 Jun 2010 22:31:16 +0200
Subject: [R-sig-Geo] variogram parameters
Message-ID: <BFE1525242E7DA4B9CBBDE2CF4DDBBFB9E15BC@EVSAB01.uclm.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100621/cda7e1c6/attachment.pl>

From carmichael.h at gmail.com  Mon Jun 21 22:44:43 2010
From: carmichael.h at gmail.com (Heather Carmichael)
Date: Mon, 21 Jun 2010 16:44:43 -0400
Subject: [R-sig-Geo] removing key from spplot with a factor variable
Message-ID: <AANLkTil6EqGyLCn6RLdqvbVx0ApXtyDy1sKFxfMZupIx@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100621/5bf8292f/attachment.pl>

From ashton at msu.edu  Tue Jun 22 00:11:57 2010
From: ashton at msu.edu (Ashton Shortridge)
Date: Mon, 21 Jun 2010 18:11:57 -0400
Subject: [R-sig-Geo] variogram parameters
In-Reply-To: <BFE1525242E7DA4B9CBBDE2CF4DDBBFB9E15BC@EVSAB01.uclm.es>
References: <BFE1525242E7DA4B9CBBDE2CF4DDBBFB9E15BC@EVSAB01.uclm.es>
Message-ID: <201006211811.57471.ashton@msu.edu>

Well,

all are very important for a good fit to your empirical semivariogram. Screw up 
one, and the curve won't be very close.

Maybe what you are looking for is, how to start developing a good model.

If so, I would say (based largely on experience teaching this):

1. anisotropy first. No point developing a crummy omnidirectional model
2. model form is next (spherical, exponential, etc)
3. nugget
4. sill and range

And iterate 2-4 until it seems ok. 

Others surely have their own preferences....

Yours,

Ashton

On Monday 21 June 2010 16:31:16 GEMA FERNANDEZ-AVILES CALDERON wrote:
> Dear list,
> 
> I have a trivial but not easy quiestion for me. In a semivariogram you use
>  this parameters:
> 
> a) partial sill
> b) nugget
> c) range
> d) anisotropy parameters
> 
> Please, could you ranking them beeing 1 the most important parameter?
> 
> Thank you very much,
> Gema
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Ashton Shortridge
Associate Professor			ashton at msu.edu
Dept of Geography			http://www.msu.edu/~ashton
235 Geography Building		ph (517) 432-3561
Michigan State University		fx (517) 432-1671


From jsbarret at sfu.ca  Tue Jun 22 01:48:22 2010
From: jsbarret at sfu.ca (Jenn Barrett)
Date: Mon, 21 Jun 2010 16:48:22 -0700 (PDT)
Subject: [R-sig-Geo] Best approach to account for sp. auto in models with
	count data?
In-Reply-To: <1598630020.11092571277164092102.JavaMail.root@jaguar9.sfu.ca>
Message-ID: <4575705.11092591277164102472.JavaMail.root@jaguar9.sfu.ca>

Hi everyone,

I've been searching all over the Internet, and through the literature, and can't seem to find the answer to this question - hopefully someone here can help.

I have a dataset that consists of counts of birds (6 different species) within circular plots. The goal of our study is to examine the relationship between:

1) species richness and habitat features;
2) the abundance (zero-truncated) of each species and habitat features; and
3) the presence/absence of each species and habitat features.

The count data has a negative binomial distribution. Moran?s I correlograms of bird presence by plot indicated spatial autocorrelation in all species groups, and spatial autocorrelation (positive) was also present in the residuals of the nb.glm. We therefore wish to account for spatial autocorrelation in our models; however, I'm a little stuck on how to do this for raw counts. For 3) above, I'm using an autologistic model (i.e., I'm including a distance-weighted autocovariate in the regression equation); however, I've read that an auto-poisson (or, I'm assuming an auto-negbin) model can only account for negative spatial autocorrelation (not positive). Also, while I have used spatial error models in the past on continuous, normally distributed data, my impression from the literature is that they are not meant for count data - so this doesn't seem like a good option either.

Many articles that I've read which modeled richness or counts while accounting for spatial autocorrelation seem to simply transform the response variable (either log or sqrt), and then apply auto-Gaussian methods (e.g., AR, SAR or CAR). Is this the norm? Or is there some way to model the raw (i.e., non-transformed) counts?

Thanks!

Cheers,
Jenn


From Beth.Crase at nt.gov.au  Mon Jun 21 08:53:06 2010
From: Beth.Crase at nt.gov.au (Beth Crase)
Date: Mon, 21 Jun 2010 06:53:06 +0000 (UTC)
Subject: [R-sig-Geo] comparing non-spatial and spatial generalized
	linear models
References: <AANLkTilvh3NAStRgkPKhaeTO32V1Hd8LFK3XRnktKsE9@mail.gmail.com>
	<AANLkTimsksVEbSPakfUGlxKIiRbqPFQUP8ymdOPMR2xp@mail.gmail.com>
Message-ID: <loom.20100621T075628-84@post.gmane.org>

Hello Elaine,

It depends on the focus of your study. 
(1)If you want to work out which of your three explanatory variables is the 
most important for bird richness, then you will probably compare parameter 
estimates from non-spatial and spatial (autoregressive) models. See Dormann et 
al (2007) Ecography 30:609-628 for excellent examples and code. They use 
simulated data, and you use actual data so you will not know the true value of 
your parameters. If there is a lot of autocorrelation in your data then your 
parameter estimates will be poor. The effect of autocorrelation in your data 
is to inflate the importance of variables - but you may not know which ones or 
by how much. 

(2)If you want to make good predictions, then compare the predicted values 
from your spatial and non-spatial models to your actual observed values. For 
this you could calculate AUC (or ROC) and percent of deviance explained by 
partitioning your data and using some for training, and some for testing. 
Cross validation would be better. And an independent data set, better yet. See 
Betts et al (2006) Ecological Modelling 191, 197-224.

(3)If you just want to show that there IS autocorrelation in your data, then 
you could calculate or plot Moran's I, and show any differences in parameter 
estimates from the non-spatial and spatial models.  
Cheers
Beth.


From angus at internode.on.net  Tue Jun 22 04:42:31 2010
From: angus at internode.on.net (Angus Johnson)
Date: Tue, 22 Jun 2010 12:42:31 +1000
Subject: [R-sig-Geo] Offering an alternative to GPC.
Message-ID: <4C202317.2010300@internode.on.net>

  While I'm not an R user, I noticed a couple of months ago some posters 
in this mailing list were looking at ways to address the commercial 
licensing restrictions associated with General Polygon Clipper (GPC).

I'd like to offer to the RGEOS community my own recently developed 
polygon clipping library - 'Clipper'. I believe Clipper - 
http://sourceforge.net/projects/polyclipping/ - has a couple of 
significant advantages over GPC:
1. the licensing (MPL 1.1 or LGPL2.1) is much less restrictive and 
doesn't require payment for commercial uses.
2. my testing indicates that Clipper is both significantly faster and 
also more robust that GPC (see 
http://angusj.com/delphi/clipper.php#features ).

Clipper was initially written in Delphi, but I've also translated the 
library into C++.
There's also a DLL (for Window's users) that exports functions to 
perform the boolean clipping algorithms (intersection, union, difference 
& xor).
I'm afraid documentation is still very thin, but there is a demo in the 
download package which shows that basics. Nevertheless, the public 
methods of Clipper C++ class (or TClipper Delphi class) are relatively 
few and fairly well documented with in the code (though much more 
extensive in the Delphi code).

Hope that helps ...
Angus


From roman.lustrik at gmail.com  Tue Jun 22 09:36:10 2010
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Tue, 22 Jun 2010 09:36:10 +0200
Subject: [R-sig-Geo] distances values from a point exhibit a hexagon-like
	distribution
Message-ID: <AANLkTilcxmzZtE7M9lM_gZhTFhCZvMRv84JJ65r79HXg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100622/a2eebce8/attachment.pl>

From mdsumner at gmail.com  Tue Jun 22 09:55:57 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 22 Jun 2010 17:55:57 +1000
Subject: [R-sig-Geo] distances values from a point exhibit a
	hexagon-like distribution
In-Reply-To: <AANLkTilcxmzZtE7M9lM_gZhTFhCZvMRv84JJ65r79HXg@mail.gmail.com>
References: <AANLkTilcxmzZtE7M9lM_gZhTFhCZvMRv84JJ65r79HXg@mail.gmail.com>
Message-ID: <AANLkTikBjF8asROK9ONksEjSN0A2PiQeHNkl1UWCwRW6@mail.gmail.com>

Could you please provide a reproducible example with useable code?

Cheers, Mike.

On Tue, Jun 22, 2010 at 5:36 PM, Roman Lu?trik <roman.lustrik at gmail.com> wrote:
> Can someone explain to me why values of distances from a point are not in a
> uniform, circle-like fashion, but rather form a hexagon shape (see
> image<http://imagepaste.nullnetwork.net/viewimage.php?id=1075>)?
> Here is the code I'm using to produce this plot (kudos to
> Robert<http://r-sig-geo.2731867.n2.nabble.com/assigning-raster-cell-values-based-on-predefined-criteria-td4929775.html#a4929775>).
> Raster projection is "+projs = NA".
>
> rst.poly <- polygonsToRaster(circle.polygon, rst) #circle.polygon is the
> polygon I'm overlaying, rst is the raster
> rst.lines <- linesToRaster(circle.polygon, rst)
> rst.lines[rst.lines > 0] <- 0
> rst.point <- pointsToRaster(rst, xy[[i]][j,]) #xy is the point from where
> the distances are calculated
> rst.cover <- cover(rst.point, rst.lines)
> rst.grid <- gridDistance(rst.cover)
> rst.grid[!is.na(rst.lines)] <- NA
> plot(rst.grid)
>
>
> Cheers,
> Roman
>
>
> --
> In God we trust, all others bring data.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From roman.lustrik at gmail.com  Tue Jun 22 10:28:47 2010
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Tue, 22 Jun 2010 10:28:47 +0200
Subject: [R-sig-Geo] distances values from a point exhibit a
	hexagon-like distribution
In-Reply-To: <AANLkTinYI8l1klIskNODKfPgPy-WlT520FAxubzBM04x@mail.gmail.com>
References: <AANLkTilcxmzZtE7M9lM_gZhTFhCZvMRv84JJ65r79HXg@mail.gmail.com> 
	<AANLkTikBjF8asROK9ONksEjSN0A2PiQeHNkl1UWCwRW6@mail.gmail.com> 
	<AANLkTinYI8l1klIskNODKfPgPy-WlT520FAxubzBM04x@mail.gmail.com>
Message-ID: <AANLkTik1O2mpE9r-uXOEJT7rzaLZC9ysUuDEY3aIUA8M@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100622/939c61a7/attachment.pl>

From mdsumner at gmail.com  Tue Jun 22 10:37:16 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 22 Jun 2010 18:37:16 +1000
Subject: [R-sig-Geo] distances values from a point exhibit a
	hexagon-like distribution
In-Reply-To: <AANLkTik1O2mpE9r-uXOEJT7rzaLZC9ysUuDEY3aIUA8M@mail.gmail.com>
References: <AANLkTilcxmzZtE7M9lM_gZhTFhCZvMRv84JJ65r79HXg@mail.gmail.com>
	<AANLkTikBjF8asROK9ONksEjSN0A2PiQeHNkl1UWCwRW6@mail.gmail.com>
	<AANLkTinYI8l1klIskNODKfPgPy-WlT520FAxubzBM04x@mail.gmail.com>
	<AANLkTik1O2mpE9r-uXOEJT7rzaLZC9ysUuDEY3aIUA8M@mail.gmail.com>
Message-ID: <AANLkTimr89ogVSLnmggXesgh5-fnG9FmKrZ6ZWrLJ5Zx@mail.gmail.com>

Sorry, but it still doesn't work for me. I'm surprised you could get
passed the first line, since "projs" is not an argument to raster -
it's not necessary for your example to have that set though, so I
ignore it.

I had to install igraph package as well, but still this fails at the
gridDistance line. Can you let us know your OS, R and package versions
for raster, sp, and igraph?  Use sessionInfo()  please.

library(raster)
library(sp)
library(igraph)

rst <- raster(nrow = 200, ncol = 200, xmn = -100, xmx = 100, ymn =
-100, ymx = 100)
sample.matrix <- t(matrix(c(50,-50, 50,50, -50,50, -50,-50), 2, 4))
sample.matrix <- rbind(sample.matrix, sample.matrix[1,])
sq.polygon <- SpatialPolygons(list(Polygons(list(Polygon(sample.matrix)),
ID = "effect_dist")))
rst[] <- runif(ncell(rst))
xy <- matrix(c(0,0), 1, 2)

rst.poly <- polygonsToRaster(sq.polygon, rst)
rst.lines <- linesToRaster(sq.polygon, rst)

rst.lines[rst.lines > 0] <- 0

rst.point <- pointsToRaster(rst, xy)

rst.cover <- cover(rst.point, rst.lines)

## fails at this line
rst.grid <- gridDistance(rst.cover)
rst.grid[!is.na(rst.lines)] <- NA
plot(rst.grid)

sessionInfo()

R version 2.11.1 (2010-05-31)
x86_64-pc-mingw32

locale:
[1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252
   LC_MONETARY=English_Australia.1252
[4] LC_NUMERIC=C                       LC_TIME=English_Australia.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] igraph_0.5.3 raster_1.1.7 sp_0.9-64

loaded via a namespace (and not attached):
[1] grid_2.11.1    lattice_0.18-8 tools_2.11.1


On Tue, Jun 22, 2010 at 6:28 PM, Roman Lu?trik <roman.lustrik at gmail.com> wrote:
> Thank you Michael for taking interest in my problem. Here is the code that
> should work. The only difference is that here, for a polygon, I use a square
> instead of a circle (no biggie). I suspect gridDistance may have something
> to do with the "hexagon".
>
> library(raster)
> library(sp)
> rst <- raster(nrow = 200, ncol = 200, xmn = -100, xmx = 100, ymn = -100, ymx
> = 100, projs = "+proj=NA")
> sample.matrix <- t(matrix(c(50,-50, 50,50, -50,50, -50,-50), 2, 4))
> sample.matrix <- rbind(sample.matrix, sample.matrix[1,])
> sq.polygon <- SpatialPolygons(list(Polygons(list(Polygon(sample.matrix)), ID
> = "effect_dist")))
> rst[] <- runif(ncell(rst))
> xy <- matrix(c(0,0), 1, 2)
>
> rst.poly <- polygonsToRaster(sq.polygon, rst)
> rst.lines <- linesToRaster(sq.polygon, rst)
>
> rst.lines[rst.lines > 0] <- 0
> rst.point <- pointsToRaster(rst, xy)
>
> rst.cover <- cover(rst.point, rst.lines)
> rst.grid <- gridDistance(rst.cover)
> rst.grid[!is.na(rst.lines)] <- NA
> plot(rst.grid)
>
>
> Cheers,
> Roman
>
>
>
>
> On Tue, Jun 22, 2010 at 9:55 AM, Michael Sumner <mdsumner at gmail.com> wrote:
>
>> Could you please provide a reproducible example with useable code?
>>
>> Cheers, Mike.
>>
>> On Tue, Jun 22, 2010 at 5:36 PM, Roman Lu?trik <roman.lustrik at gmail.com>
>> wrote:
>> > Can someone explain to me why values of distances from a point are not in
>> a
>> > uniform, circle-like fashion, but rather form a hexagon shape (see
>> > image<http://imagepaste.nullnetwork.net/viewimage.php?id=1075>)?
>> > Here is the code I'm using to produce this plot (kudos to
>> > Robert<
>> http://r-sig-geo.2731867.n2.nabble.com/assigning-raster-cell-values-based-on-predefined-criteria-td4929775.html#a4929775
>> >).
>> > Raster projection is "+projs = NA".
>> >
>> > rst.poly <- polygonsToRaster(circle.polygon, rst) #circle.polygon is the
>> > polygon I'm overlaying, rst is the raster
>> > rst.lines <- linesToRaster(circle.polygon, rst)
>> > rst.lines[rst.lines > 0] <- 0
>> > rst.point <- pointsToRaster(rst, xy[[i]][j,]) #xy is the point from where
>> > the distances are calculated
>> > rst.cover <- cover(rst.point, rst.lines)
>> > rst.grid <- gridDistance(rst.cover)
>> > rst.grid[!is.na(rst.lines)] <- NA
>> > plot(rst.grid)
>> >
>> >
>> > Cheers,
>> > Roman
>> >
>> >
>> > --
>> > In God we trust, all others bring data.
>> >
>> > ? ? ? ?[[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-Geo mailing list
>> > R-sig-Geo at stat.math.ethz.ch
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >
>>
>
>
>
> --
> In God we trust, all others bring data.
>
>
>
> --
> In God we trust, all others bring data.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From roman.lustrik at gmail.com  Tue Jun 22 10:49:06 2010
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Tue, 22 Jun 2010 10:49:06 +0200
Subject: [R-sig-Geo] distances values from a point exhibit a
	hexagon-like distribution
In-Reply-To: <AANLkTimr89ogVSLnmggXesgh5-fnG9FmKrZ6ZWrLJ5Zx@mail.gmail.com>
References: <AANLkTilcxmzZtE7M9lM_gZhTFhCZvMRv84JJ65r79HXg@mail.gmail.com> 
	<AANLkTikBjF8asROK9ONksEjSN0A2PiQeHNkl1UWCwRW6@mail.gmail.com> 
	<AANLkTinYI8l1klIskNODKfPgPy-WlT520FAxubzBM04x@mail.gmail.com> 
	<AANLkTik1O2mpE9r-uXOEJT7rzaLZC9ysUuDEY3aIUA8M@mail.gmail.com> 
	<AANLkTimr89ogVSLnmggXesgh5-fnG9FmKrZ6ZWrLJ5Zx@mail.gmail.com>
Message-ID: <AANLkTil1e3dukqdccUwZoEl7wNs8n4i1AKkNuCvG-5sR@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100622/a5f95c0a/attachment.pl>

From aslantas at metu.edu.tr  Tue Jun 22 11:40:31 2010
From: aslantas at metu.edu.tr (Pinar Aslantas Bostan)
Date: Tue, 22 Jun 2010 12:40:31 +0300
Subject: [R-sig-Geo] GWR Analysis
In-Reply-To: <alpine.LRH.2.00.1006211808140.2164@reclus.nhh.no>
References: <20100621162322.93173clp8ybphhhm@horde.metu.edu.tr>
	<alpine.LRH.2.00.1006211808140.2164@reclus.nhh.no>
Message-ID: <20100622124031.203062cps95fcwzz@horde.metu.edu.tr>

Dear Roger,

Thank you for your mail. I tried lm() and it doesn't resulted with  
negative values. Also gwr() doesn't give negative values if I don't  
use fit.points.

> bw1=gwr.sel(PREC~Z+V1+V2,station,adapt=T)
> xx1<-gwr(PREC~Z+V1+V2,station,adapt=bw1,se.fit=T,hatmatrix=TRUE)
> gwrx<-xx1$SDF
> min(gwrx$pred)
[1] 311.189
> max(gwrx$pred)
[1] 1700.559

But if I use fit.points to predict precipitation on a grid, then it  
gave negative values.

> x1 <-gwr(PREC~Z+V1+V2,station,adapt=bw1, fit.points = dem,  
> predict=T, se.fit=T, fittedGWRobject=xx1)
> gwrres<-x1$SDF
> min(gwrres$pred)
[1] -1126.052
> max(gwrres$pred)
[1] 2104.136

You mentioned about limiting the design of the model, so that it  
doesn't give negative values. Do you have any idea about that, how can  
I perform this?

Best regards,
Pinar




Alinti Roger Bivand <Roger.Bivand at nhh.no>

> On Mon, 21 Jun 2010, Pinar Aslantas Bostan wrote:
>
>> Dear Roger,
>>
>> Maybe you can remember, last week I asked some questions about gwr  
>> analysis and you helped me. In order to make refresh, I want to  
>> summarize my problem. I am trying to make gwr analysis to predict  
>> precipitation distribution on a DEM. I have two datasets; first one  
>> is 'station' consists of 225 prec. measurements and 3 independent  
>> variables (Z, V1, V2). The second one is 'DEM' dataset which has  
>> 31203 # of pixels. Firstly I tried with using SPDF  
>> (SpatialPointsDataFrame) and obtained predicted precipitations on  
>> DEM. But when I plot the predicted precipitation values, I saw a  
>> lot of negative values which is impossible to get such a values.
>
> No, this is just a weighted linear model. Unless you limit it by  
> design, all such linear models will happily predict out of domain.  
> Consider how you might by design limit the response to non-negative  
> values.
>
>> I thought that this was caused because I used point data sets  
>> (SPDF) for grid.
>
> Why would you think that? All you need to provoke this is a slightly  
> unfortunate placing of the met stations (all in west and falling  
> trend eastwards beyond the observed stations). Did the regular lm()  
> fit also predict negative values (very likely yes).
>
> This isn't a GWR problem, it's more general. Fix it for lm() first.
>
> Roger
>
>> Then I tried with using SGDF (SpatialGridDataFrame). At this time,  
>> gwr() resulted with an error message "new data matrix rows  
>> mismatch". You told me that 'The error message is generated when  
>> the number of columns in the matrix of X variables is not the same  
>> in data and and fit.points.' I gave some information about datasets  
>> below.
>>
>>> class(station)
>> [1] "SpatialPointsDataFrame"
>> attr(,"package")
>> [1] "sp"
>>> names(station)
>> [1] "PREC" "Z"    "V1"   "V2"
>>> class(dem)
>> [1] "SpatialGridDataFrame"
>> attr(,"package")
>> [1] "sp"
>>> names(dem)
>> [1] "Z"  "V1" "V2"
>>
>> 'PREC' is the observations and I want to get predictions of them on 'dem'.
>>
>> I checked the str() and variables are stored in the same way.
>>
>>> bw=gwr.sel(PREC~Z+V1+V2,data=station,adapt=T)
>>> xx1<-gwr(PREC~Z+V1+V2,station,adapt=bw,hatmatrix=TRUE)
>>> x1 <-gwr(PREC~Z+V1+V2,data=station,adapt=bw, fit.points = dem,  
>>> predict=T, se.fit=T, fittedGWRobject=xx1)
>> Error in gwr(PREC ~ Z + V1 + V2, data = station, adapt = bw,  
>> fit.points = dem,  :
>> new data matrix rows mismatch
>>
>>
>> If I wrote 'predict=F' then gwr() works but gives only sum.w,  
>> coefficients and localR2.
>>
>> I tried to run gwr() under debug but I didn't understand the output.
>>
>> I really don't understand the problem and need help.
>>
>> Best regards,
>> Pinar
>>
>>
>> ----------------------------------------------------------------
>> This message was sent using IMP, the Internet Messaging Program.
>>
>>
>
> -- 
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>


From jacobvanetten at yahoo.com  Tue Jun 22 11:45:27 2010
From: jacobvanetten at yahoo.com (Jacob van Etten)
Date: Tue, 22 Jun 2010 02:45:27 -0700 (PDT)
Subject: [R-sig-Geo] distances values from a point exhibit a
	hexagon-like distribution
In-Reply-To: <AANLkTilcxmzZtE7M9lM_gZhTFhCZvMRv84JJ65r79HXg@mail.gmail.com>
Message-ID: <840088.10500.qm@web32904.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100622/ba47903a/attachment.pl>

From Roger.Bivand at nhh.no  Tue Jun 22 11:58:25 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 22 Jun 2010 11:58:25 +0200 (CEST)
Subject: [R-sig-Geo] GWR Analysis
In-Reply-To: <20100622124031.203062cps95fcwzz@horde.metu.edu.tr>
References: <20100621162322.93173clp8ybphhhm@horde.metu.edu.tr>
	<alpine.LRH.2.00.1006211808140.2164@reclus.nhh.no>
	<20100622124031.203062cps95fcwzz@horde.metu.edu.tr>
Message-ID: <alpine.LRH.2.00.1006221146070.5799@reclus.nhh.no>

On Tue, 22 Jun 2010, Pinar Aslantas Bostan wrote:

> Dear Roger,
>
> Thank you for your mail. I tried lm() and it doesn't resulted with negative 
> values. Also gwr() doesn't give negative values if I don't use fit.points.

OK. What this means then is that for fit.points some local coefficients 
with your chosen adaptive proportion and chosen kernel, and with the 
values of Z, V1, and V2 (are V1 and V2 coordinates - is a GW trend model a 
good idea?) are driving the predictions negative. Could you try this with 
different adaptive proportion values to see whether the predictions stay 
non-negative? Are the relationships between PREC and Z, V1, and V2 really 
linear? Can you fit a gam() and look at the linearity of the fits? Would 
taking log(PREC) help with the linearity (as well as with bounding the 
model)? Do you have any resource persons at your university? Do you have 
access to Chris Lloyd's nice 2006 book on local models:

http://www.crcpress.com/product/isbn/0415316812

Hope this helps,

Roger

>
>> bw1=gwr.sel(PREC~Z+V1+V2,station,adapt=T)
>> xx1<-gwr(PREC~Z+V1+V2,station,adapt=bw1,se.fit=T,hatmatrix=TRUE)
>> gwrx<-xx1$SDF
>> min(gwrx$pred)
> [1] 311.189
>> max(gwrx$pred)
> [1] 1700.559
>
> But if I use fit.points to predict precipitation on a grid, then it gave 
> negative values.
>
>> x1 <-gwr(PREC~Z+V1+V2,station,adapt=bw1, fit.points = dem, predict=T, 
>> se.fit=T, fittedGWRobject=xx1)
>> gwrres<-x1$SDF
>> min(gwrres$pred)
> [1] -1126.052
>> max(gwrres$pred)
> [1] 2104.136
>
> You mentioned about limiting the design of the model, so that it doesn't give 
> negative values. Do you have any idea about that, how can I perform this?
>
> Best regards,
> Pinar
>
>
>
>
> Alinti Roger Bivand <Roger.Bivand at nhh.no>
>
>> On Mon, 21 Jun 2010, Pinar Aslantas Bostan wrote:
>> 
>>> Dear Roger,
>>> 
>>> Maybe you can remember, last week I asked some questions about gwr 
>>> analysis and you helped me. In order to make refresh, I want to summarize 
>>> my problem. I am trying to make gwr analysis to predict precipitation 
>>> distribution on a DEM. I have two datasets; first one is 'station' 
>>> consists of 225 prec. measurements and 3 independent variables (Z, V1, 
>>> V2). The second one is 'DEM' dataset which has 31203 # of pixels. Firstly 
>>> I tried with using SPDF (SpatialPointsDataFrame) and obtained predicted 
>>> precipitations on DEM. But when I plot the predicted precipitation values, 
>>> I saw a lot of negative values which is impossible to get such a values.
>> 
>> No, this is just a weighted linear model. Unless you limit it by design, 
>> all such linear models will happily predict out of domain. Consider how you 
>> might by design limit the response to non-negative values.
>> 
>>> I thought that this was caused because I used point data sets (SPDF) for 
>>> grid.
>> 
>> Why would you think that? All you need to provoke this is a slightly 
>> unfortunate placing of the met stations (all in west and falling trend 
>> eastwards beyond the observed stations). Did the regular lm() fit also 
>> predict negative values (very likely yes).
>> 
>> This isn't a GWR problem, it's more general. Fix it for lm() first.
>> 
>> Roger
>> 
>>> Then I tried with using SGDF (SpatialGridDataFrame). At this time, gwr() 
>>> resulted with an error message "new data matrix rows mismatch". You told 
>>> me that 'The error message is generated when the number of columns in the 
>>> matrix of X variables is not the same in data and and fit.points.' I gave 
>>> some information about datasets below.
>>> 
>>>> class(station)
>>> [1] "SpatialPointsDataFrame"
>>> attr(,"package")
>>> [1] "sp"
>>>> names(station)
>>> [1] "PREC" "Z"    "V1"   "V2"
>>>> class(dem)
>>> [1] "SpatialGridDataFrame"
>>> attr(,"package")
>>> [1] "sp"
>>>> names(dem)
>>> [1] "Z"  "V1" "V2"
>>> 
>>> 'PREC' is the observations and I want to get predictions of them on 'dem'.
>>> 
>>> I checked the str() and variables are stored in the same way.
>>> 
>>>> bw=gwr.sel(PREC~Z+V1+V2,data=station,adapt=T)
>>>> xx1<-gwr(PREC~Z+V1+V2,station,adapt=bw,hatmatrix=TRUE)
>>>> x1 <-gwr(PREC~Z+V1+V2,data=station,adapt=bw, fit.points = dem, predict=T, 
>>>> se.fit=T, fittedGWRobject=xx1)
>>> Error in gwr(PREC ~ Z + V1 + V2, data = station, adapt = bw, fit.points = 
>>> dem,  :
>>> new data matrix rows mismatch
>>> 
>>> 
>>> If I wrote 'predict=F' then gwr() works but gives only sum.w, coefficients 
>>> and localR2.
>>> 
>>> I tried to run gwr() under debug but I didn't understand the output.
>>> 
>>> I really don't understand the problem and need help.
>>> 
>>> Best regards,
>>> Pinar
>>> 
>>> 
>>> ----------------------------------------------------------------
>>> This message was sent using IMP, the Internet Messaging Program.
>>> 
>>> 
>> 
>> -- 
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>> 
>> 
>
>
>
> ----------------------------------------------------------------
> This message was sent using IMP, the Internet Messaging Program.
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From roman.lustrik at gmail.com  Tue Jun 22 12:05:05 2010
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Tue, 22 Jun 2010 12:05:05 +0200
Subject: [R-sig-Geo] distances values from a point exhibit a
	hexagon-like distribution
In-Reply-To: <840088.10500.qm@web32904.mail.mud.yahoo.com>
References: <AANLkTilcxmzZtE7M9lM_gZhTFhCZvMRv84JJ65r79HXg@mail.gmail.com> 
	<840088.10500.qm@web32904.mail.mud.yahoo.com>
Message-ID: <AANLkTimIEaV4Ep631ioJssY6AoHq-EirAVm36gl2hfWH@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100622/c9f2c097/attachment.pl>

From Gema.FAviles at uclm.es  Tue Jun 22 15:40:45 2010
From: Gema.FAviles at uclm.es (GEMA FERNANDEZ-AVILES CALDERON)
Date: Tue, 22 Jun 2010 15:40:45 +0200
Subject: [R-sig-Geo] variogram parameters
References: <BFE1525242E7DA4B9CBBDE2CF4DDBBFB9E15BC@EVSAB01.uclm.es>
	<201006211811.57471.ashton@msu.edu>
Message-ID: <BFE1525242E7DA4B9CBBDE2CF4DDBBFB9E15C1@EVSAB01.uclm.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100622/d6ec300d/attachment.pl>

From r.aluizio at gmail.com  Tue Jun 22 15:57:05 2010
From: r.aluizio at gmail.com (Rodrigo Aluizio)
Date: Tue, 22 Jun 2010 10:57:05 -0300
Subject: [R-sig-Geo] Plot (image( )) Real RGB Colors of an Imported GeoTIFF
	(readGDAL( ))
Message-ID: <!&!AAAAAAAAAAAYAAAAAAAAAIAEEiZZmSdOqwxDqjxFJxXigAAAEAAAAHHTRb5l8ypFn7KtY8bfI6oBAAAAAA==@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100622/5dfd0394/attachment.pl>

From eick at vistracks.com  Tue Jun 22 16:24:11 2010
From: eick at vistracks.com (Stephen G. Eick)
Date: Tue, 22 Jun 2010 09:24:11 -0500
Subject: [R-sig-Geo] distance from point to line and line to line
Message-ID: <002501cb1216$97e32f60$c7a98e20$@uic.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100622/9e7c8d8d/attachment.pl>

From wmconnol at ncsu.edu  Tue Jun 22 16:25:50 2010
From: wmconnol at ncsu.edu (Mark Connolly)
Date: Tue, 22 Jun 2010 10:25:50 -0400
Subject: [R-sig-Geo] Best way to get values of a raster that are not
 masked?
In-Reply-To: <AANLkTilfc3UiIOsKU5prESo4t4vtWkT6jUJDEXwZzGEW@mail.gmail.com>
Message-ID: <1277216750.27102.18.camel@localhost>

Not sure exactly what you are starting with but something like 

# ?read.csv and look for information on as.is and na.strings
# depending on how clean the data are, you may want to bring them in
# as is and use as.numeric etc on the specific attributes
mixed = read.csv("filename.csv")

good = subset(mixed, testattrib == 1)[,c("x","y","dataattrib")]



If you already have some coordinates and want to join data frames
together ?base::merge (there is also a raster::merge)

Mark


From r.hijmans at gmail.com  Tue Jun 22 18:16:37 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 22 Jun 2010 09:16:37 -0700
Subject: [R-sig-Geo] Plot (image( )) Real RGB Colors of an Imported
	GeoTIFF (readGDAL( ))
In-Reply-To: <!&!AAAAAAAAAAAYAAAAAAAAAIAEEiZZmSdOqwxDqjxFJxXigAAAEAAAAHHTRb5l8ypFn7KtY8bfI6oBAAAAAA==@gmail.com>
References: <!&!AAAAAAAAAAAYAAAAAAAAAIAEEiZZmSdOqwxDqjxFJxXigAAAEAAAAHHTRb5l8ypFn7KtY8bfI6oBAAAAAA==@gmail.com>
Message-ID: <AANLkTimpGMsY5HCNOCjPdJGew6iHRaM3i2zjvvKHdrf9@mail.gmail.com>

Rodrigo, you can try plotRGB in raster. Robert

On Tue, Jun 22, 2010 at 6:57 AM, Rodrigo Aluizio <r.aluizio at gmail.com> wrote:
> Hi List members.
>
> I?m actually able to import a Georeferenced image (.tiff) using readGDAL
> {rgdal} and plot it using image {Graphics}.
>
> But the colors options available in the image function (topo.colors,
> heat.colors, terrain.colors, etc) aren?t able to adequately reproduce the
> original image. The tiff file represent land and ocean, so I need brow and
> green tones to land and blue tones to ocean. I was able to create the blue
> tones with colorRampPalette () but these blue tones are also applied to the
> land.
>
> Once imported the object containing the raster georeferenced file brings
> three data columns with bands (RGB maybe) values of each cell (I guess).
> Isn?t there a way to reproduce the real colors using these columns
> information or any other way to do so?
>
>
>
> Thank you on advance for the patience and help.
>
>
>
> Below, some useful information on the object:
>
>
>
>>
> BC<-readGDAL('C:/Users/Rodrigo/Documents/Shapefiles/Campos/BaciaCampos-GE-SA
> D69-LongLat.tiff')
>
> C:/Users/Rodrigo/Documents/Shapefiles/Campos/BaciaCampos-GE-SAD69-LongLat.ti
> ff has GDAL driver GTiff
>
> and has 3350 rows and 3015 columns
>
>
>
>> summary(BC)
>
> Object of class SpatialGridDataFrame
>
> Coordinates:
>
> ? ? ? ?min ? ? ? max
>
> x -42.15808 -39.58503
>
> y -23.74079 -21.08709
>
> Is projected: FALSE
>
> proj4string : [+proj=longlat +ellps=aust_SA +no_defs]
>
> Number of points: 2
>
> Grid attributes:
>
> ?cellcentre.offset ? ? cellsize cells.dim
>
> x ? ? ? ? -42.15765 0.0008534147 ? ? ?3015
>
> y ? ? ? ? -23.74040 0.0007921499 ? ? ?3350
>
> Data attributes:
>
> ? ? band1 ? ? ? ? ? ?band2 ? ? ? ? ? ?band3
>
> ?Min. ? : ?0.00 ? Min. ? : ?0.00 ? Min. ? : ?0.0
>
> ?1st Qu.: 48.00 ? 1st Qu.: 67.00 ? 1st Qu.: 95.0
>
> ?Median : 70.00 ? Median : 89.00 ? Median :117.0
>
> ?Mean ? : 65.17 ? Mean ? : 83.37 ? Mean ? :117.7
>
> ?3rd Qu.: 76.00 ? 3rd Qu.: 97.00 ? 3rd Qu.:150.0
>
> ?Max. ? :255.00 ? Max. ? :255.00 ? Max. ? :255.0
>
>
>
> Regards
>
>
>
> -------------------------------------------------------------
>
> MSc. ?<mailto:r.aluizio at gmail.com> Rodrigo Aluizio
>
> Centro de Estudos do Mar/UFPR
> Laborat?rio de Micropaleontologia
> Avenida Beira Mar s/n - CEP 83255-000
> Pontal do Paran? - PR - Brasil
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From edzer.pebesma at uni-muenster.de  Tue Jun 22 18:27:33 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 22 Jun 2010 18:27:33 +0200
Subject: [R-sig-Geo] Plot (image( )) Real RGB Colors of an Imported
 GeoTIFF (readGDAL( ))
In-Reply-To: <!&!AAAAAAAAAAAYAAAAAAAAAIAEEiZZmSdOqwxDqjxFJxXigAAAEAAAAHHTRb5l8ypFn7KtY8bfI6oBAAAAAA==@gmail.com>
References: <!&!AAAAAAAAAAAYAAAAAAAAAIAEEiZZmSdOqwxDqjxFJxXigAAAEAAAAHHTRb5l8ypFn7KtY8bfI6oBAAAAAA==@gmail.com>
Message-ID: <4C20E475.8090306@uni-muenster.de>

Asssuming r g and b are on a 0 - 255 scale and form the first, second
and third band in obj, which was read through readGDAL, you could use

image(obj, red = 1, green = 2, blue = 3)

which is image { sp } and not image { graphics }. See also

library(sp)
?image.SpatialGridDataFrame

On 06/22/2010 03:57 PM, Rodrigo Aluizio wrote:
> Hi List members.
> 
> I?m actually able to import a Georeferenced image (.tiff) using readGDAL
> {rgdal} and plot it using image {Graphics}.
> 
> But the colors options available in the image function (topo.colors,
> heat.colors, terrain.colors, etc) aren?t able to adequately reproduce the
> original image. The tiff file represent land and ocean, so I need brow and
> green tones to land and blue tones to ocean. I was able to create the blue
> tones with colorRampPalette () but these blue tones are also applied to the
> land.
> 
> Once imported the object containing the raster georeferenced file brings
> three data columns with bands (RGB maybe) values of each cell (I guess).
> Isn?t there a way to reproduce the real colors using these columns
> information or any other way to do so?
> 
>  
> 
> Thank you on advance for the patience and help.
> 
>  
> 
> Below, some useful information on the object:
> 
>  
> 
>>
> BC<-readGDAL('C:/Users/Rodrigo/Documents/Shapefiles/Campos/BaciaCampos-GE-SA
> D69-LongLat.tiff')
> 
> C:/Users/Rodrigo/Documents/Shapefiles/Campos/BaciaCampos-GE-SAD69-LongLat.ti
> ff has GDAL driver GTiff 
> 
> and has 3350 rows and 3015 columns
> 
>  
> 
>> summary(BC)
> 
> Object of class SpatialGridDataFrame
> 
> Coordinates:
> 
>         min       max
> 
> x -42.15808 -39.58503
> 
> y -23.74079 -21.08709
> 
> Is projected: FALSE 
> 
> proj4string : [+proj=longlat +ellps=aust_SA +no_defs]
> 
> Number of points: 2
> 
> Grid attributes:
> 
>   cellcentre.offset     cellsize cells.dim
> 
> x         -42.15765 0.0008534147      3015
> 
> y         -23.74040 0.0007921499      3350
> 
> Data attributes:
> 
>      band1            band2            band3      
> 
>  Min.   :  0.00   Min.   :  0.00   Min.   :  0.0  
> 
>  1st Qu.: 48.00   1st Qu.: 67.00   1st Qu.: 95.0  
> 
>  Median : 70.00   Median : 89.00   Median :117.0  
> 
>  Mean   : 65.17   Mean   : 83.37   Mean   :117.7  
> 
>  3rd Qu.: 76.00   3rd Qu.: 97.00   3rd Qu.:150.0  
> 
>  Max.   :255.00   Max.   :255.00   Max.   :255.0
> 
>  
> 
> Regards
> 
>  
> 
> -------------------------------------------------------------
> 
> MSc.  <mailto:r.aluizio at gmail.com> Rodrigo Aluizio
> 
> Centro de Estudos do Mar/UFPR
> Laborat?rio de Micropaleontologia
> Avenida Beira Mar s/n - CEP 83255-000
> Pontal do Paran? - PR - Brasil
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From r.hijmans at gmail.com  Tue Jun 22 19:12:31 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 22 Jun 2010 10:12:31 -0700
Subject: [R-sig-Geo] distances values from a point exhibit a
	hexagon-like distribution
In-Reply-To: <AANLkTimr89ogVSLnmggXesgh5-fnG9FmKrZ6ZWrLJ5Zx@mail.gmail.com>
References: <AANLkTilcxmzZtE7M9lM_gZhTFhCZvMRv84JJ65r79HXg@mail.gmail.com>
	<AANLkTikBjF8asROK9ONksEjSN0A2PiQeHNkl1UWCwRW6@mail.gmail.com>
	<AANLkTinYI8l1klIskNODKfPgPy-WlT520FAxubzBM04x@mail.gmail.com>
	<AANLkTik1O2mpE9r-uXOEJT7rzaLZC9ysUuDEY3aIUA8M@mail.gmail.com>
	<AANLkTimr89ogVSLnmggXesgh5-fnG9FmKrZ6ZWrLJ5Zx@mail.gmail.com>
Message-ID: <AANLkTikw3VSHFe9GbdgRlL892-CMFXKTpIBtEmJgfS6S@mail.gmail.com>

Mike,

You are using a more recent version of raster. The "projs" argument in
raster() was, for consistency, replaced by "crs", and gridDistance()
now requires two more arguments, originValue and omitValue.
In Roman's example, this:

rst.grid <- gridDistance(rst.cover)

should be replaced by:

rst.grid <- gridDistance(rst.cover, 1, 0)

Best, Robert

On Tue, Jun 22, 2010 at 1:37 AM, Michael Sumner <mdsumner at gmail.com> wrote:
> Sorry, but it still doesn't work for me. I'm surprised you could get
> passed the first line, since "projs" is not an argument to raster -
> it's not necessary for your example to have that set though, so I
> ignore it.
>
> I had to install igraph package as well, but still this fails at the
> gridDistance line. Can you let us know your OS, R and package versions
> for raster, sp, and igraph? ?Use sessionInfo() ?please.
>
> library(raster)
> library(sp)
> library(igraph)
>
> rst <- raster(nrow = 200, ncol = 200, xmn = -100, xmx = 100, ymn =
> -100, ymx = 100)
> sample.matrix <- t(matrix(c(50,-50, 50,50, -50,50, -50,-50), 2, 4))
> sample.matrix <- rbind(sample.matrix, sample.matrix[1,])
> sq.polygon <- SpatialPolygons(list(Polygons(list(Polygon(sample.matrix)),
> ID = "effect_dist")))
> rst[] <- runif(ncell(rst))
> xy <- matrix(c(0,0), 1, 2)
>
> rst.poly <- polygonsToRaster(sq.polygon, rst)
> rst.lines <- linesToRaster(sq.polygon, rst)
>
> rst.lines[rst.lines > 0] <- 0
>
> rst.point <- pointsToRaster(rst, xy)
>
> rst.cover <- cover(rst.point, rst.lines)
>
> ## fails at this line
> rst.grid <- gridDistance(rst.cover)
> rst.grid[!is.na(rst.lines)] <- NA
> plot(rst.grid)
>
> sessionInfo()
>
> R version 2.11.1 (2010-05-31)
> x86_64-pc-mingw32
>
> locale:
> [1] LC_COLLATE=English_Australia.1252 ?LC_CTYPE=English_Australia.1252
> ? LC_MONETARY=English_Australia.1252
> [4] LC_NUMERIC=C ? ? ? ? ? ? ? ? ? ? ? LC_TIME=English_Australia.1252
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] igraph_0.5.3 raster_1.1.7 sp_0.9-64
>
> loaded via a namespace (and not attached):
> [1] grid_2.11.1 ? ?lattice_0.18-8 tools_2.11.1
>
>
> On Tue, Jun 22, 2010 at 6:28 PM, Roman Lu?trik <roman.lustrik at gmail.com> wrote:
>> Thank you Michael for taking interest in my problem. Here is the code that
>> should work. The only difference is that here, for a polygon, I use a square
>> instead of a circle (no biggie). I suspect gridDistance may have something
>> to do with the "hexagon".
>>
>> library(raster)
>> library(sp)
>> rst <- raster(nrow = 200, ncol = 200, xmn = -100, xmx = 100, ymn = -100, ymx
>> = 100, projs = "+proj=NA")
>> sample.matrix <- t(matrix(c(50,-50, 50,50, -50,50, -50,-50), 2, 4))
>> sample.matrix <- rbind(sample.matrix, sample.matrix[1,])
>> sq.polygon <- SpatialPolygons(list(Polygons(list(Polygon(sample.matrix)), ID
>> = "effect_dist")))
>> rst[] <- runif(ncell(rst))
>> xy <- matrix(c(0,0), 1, 2)
>>
>> rst.poly <- polygonsToRaster(sq.polygon, rst)
>> rst.lines <- linesToRaster(sq.polygon, rst)
>>
>> rst.lines[rst.lines > 0] <- 0
>> rst.point <- pointsToRaster(rst, xy)
>>
>> rst.cover <- cover(rst.point, rst.lines)
>> rst.grid <- gridDistance(rst.cover)
>> rst.grid[!is.na(rst.lines)] <- NA
>> plot(rst.grid)
>>
>>
>> Cheers,
>> Roman
>>
>>
>>
>>
>> On Tue, Jun 22, 2010 at 9:55 AM, Michael Sumner <mdsumner at gmail.com> wrote:
>>
>>> Could you please provide a reproducible example with useable code?
>>>
>>> Cheers, Mike.
>>>
>>> On Tue, Jun 22, 2010 at 5:36 PM, Roman Lu?trik <roman.lustrik at gmail.com>
>>> wrote:
>>> > Can someone explain to me why values of distances from a point are not in
>>> a
>>> > uniform, circle-like fashion, but rather form a hexagon shape (see
>>> > image<http://imagepaste.nullnetwork.net/viewimage.php?id=1075>)?
>>> > Here is the code I'm using to produce this plot (kudos to
>>> > Robert<
>>> http://r-sig-geo.2731867.n2.nabble.com/assigning-raster-cell-values-based-on-predefined-criteria-td4929775.html#a4929775
>>> >).
>>> > Raster projection is "+projs = NA".
>>> >
>>> > rst.poly <- polygonsToRaster(circle.polygon, rst) #circle.polygon is the
>>> > polygon I'm overlaying, rst is the raster
>>> > rst.lines <- linesToRaster(circle.polygon, rst)
>>> > rst.lines[rst.lines > 0] <- 0
>>> > rst.point <- pointsToRaster(rst, xy[[i]][j,]) #xy is the point from where
>>> > the distances are calculated
>>> > rst.cover <- cover(rst.point, rst.lines)
>>> > rst.grid <- gridDistance(rst.cover)
>>> > rst.grid[!is.na(rst.lines)] <- NA
>>> > plot(rst.grid)
>>> >
>>> >
>>> > Cheers,
>>> > Roman
>>> >
>>> >
>>> > --
>>> > In God we trust, all others bring data.
>>> >
>>> > ? ? ? ?[[alternative HTML version deleted]]
>>> >
>>> > _______________________________________________
>>> > R-sig-Geo mailing list
>>> > R-sig-Geo at stat.math.ethz.ch
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> >
>>>
>>
>>
>>
>> --
>> In God we trust, all others bring data.
>>
>>
>>
>> --
>> In God we trust, all others bring data.
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From r.aluizio at gmail.com  Tue Jun 22 19:23:04 2010
From: r.aluizio at gmail.com (Rodrigo Aluizio)
Date: Tue, 22 Jun 2010 14:23:04 -0300
Subject: [R-sig-Geo] RES: Plot (image( )) Real RGB Colors of an Imported
	GeoTIFF (readGDAL( ))
In-Reply-To: <4C20E475.8090306@uni-muenster.de>
References: <!&!AAAAAAAAAAAYAAAAAAAAAIAEEiZZmSdOqwxDqjxFJxXigAAAEAAAAHHTRb5l8ypFn7KtY8bfI6oBAAAAAA==@gmail.com>
	<4C20E475.8090306@uni-muenster.de>
Message-ID: <!&!AAAAAAAAAAAYAAAAAAAAAIAEEiZZmSdOqwxDqjxFJxXigAAAEAAAAP+TUNi6wA9GkelHr+VaSTQBAAAAAA==@gmail.com>

Excelent!
Sorry for asking such a simple question. But, I was blind for such obvious
thing.

Rodrigo.

-----Mensagem original-----
De: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] Em nome de Edzer Pebesma
Enviada em: ter?a-feira, 22 de junho de 2010 13:28
Para: r-sig-geo at stat.math.ethz.ch
Assunto: Re: [R-sig-Geo] Plot (image( )) Real RGB Colors of an Imported
GeoTIFF (readGDAL( ))

Asssuming r g and b are on a 0 - 255 scale and form the first, second
and third band in obj, which was read through readGDAL, you could use

image(obj, red = 1, green = 2, blue = 3)

which is image { sp } and not image { graphics }. See also

library(sp)
?image.SpatialGridDataFrame

On 06/22/2010 03:57 PM, Rodrigo Aluizio wrote:
> Hi List members.
> 
> I?m actually able to import a Georeferenced image (.tiff) using readGDAL
> {rgdal} and plot it using image {Graphics}.
> 
> But the colors options available in the image function (topo.colors,
> heat.colors, terrain.colors, etc) aren?t able to adequately reproduce the
> original image. The tiff file represent land and ocean, so I need brow and
> green tones to land and blue tones to ocean. I was able to create the blue
> tones with colorRampPalette () but these blue tones are also applied to
the
> land.
> 
> Once imported the object containing the raster georeferenced file brings
> three data columns with bands (RGB maybe) values of each cell (I guess).
> Isn?t there a way to reproduce the real colors using these columns
> information or any other way to do so?
> 
>  
> 
> Thank you on advance for the patience and help.
> 
>  
> 
> Below, some useful information on the object:
> 
>  
> 
>>
>
BC<-readGDAL('C:/Users/Rodrigo/Documents/Shapefiles/Campos/BaciaCampos-GE-SA
> D69-LongLat.tiff')
> 
>
C:/Users/Rodrigo/Documents/Shapefiles/Campos/BaciaCampos-GE-SAD69-LongLat.ti
> ff has GDAL driver GTiff 
> 
> and has 3350 rows and 3015 columns
> 
>  
> 
>> summary(BC)
> 
> Object of class SpatialGridDataFrame
> 
> Coordinates:
> 
>         min       max
> 
> x -42.15808 -39.58503
> 
> y -23.74079 -21.08709
> 
> Is projected: FALSE 
> 
> proj4string : [+proj=longlat +ellps=aust_SA +no_defs]
> 
> Number of points: 2
> 
> Grid attributes:
> 
>   cellcentre.offset     cellsize cells.dim
> 
> x         -42.15765 0.0008534147      3015
> 
> y         -23.74040 0.0007921499      3350
> 
> Data attributes:
> 
>      band1            band2            band3      
> 
>  Min.   :  0.00   Min.   :  0.00   Min.   :  0.0  
> 
>  1st Qu.: 48.00   1st Qu.: 67.00   1st Qu.: 95.0  
> 
>  Median : 70.00   Median : 89.00   Median :117.0  
> 
>  Mean   : 65.17   Mean   : 83.37   Mean   :117.7  
> 
>  3rd Qu.: 76.00   3rd Qu.: 97.00   3rd Qu.:150.0  
> 
>  Max.   :255.00   Max.   :255.00   Max.   :255.0
> 
>  
> 
> Regards
> 
>  
> 
> -------------------------------------------------------------
> 
> MSc.  <mailto:r.aluizio at gmail.com> Rodrigo Aluizio
> 
> Centro de Estudos do Mar/UFPR
> Laborat?rio de Micropaleontologia
> Avenida Beira Mar s/n - CEP 83255-000
> Pontal do Paran? - PR - Brasil
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From wgu at uab.edu  Tue Jun 22 22:29:39 2010
From: wgu at uab.edu (Weidong Gu)
Date: Tue, 22 Jun 2010 15:29:39 -0500
Subject: [R-sig-Geo] how to transform Polygons to SpatialPolygons
Message-ID: <540FAB030B18B14B8E672DB4B500635B27AA2FA7C5@UABEXMBS6.ad.uab.edu>

Hi,

I ran into a problem in subsetting the Mainland from a usa map

Library(maps)
usa=map('usa',plot=F,fill=T)
IDs=sapply(strsplit(state$names,':'), function(x) x[1])
crs=CRS('+proj=longlat +ellps=WGS84')
sp.usa=map2SpatialPolygons(usa,IDs=usa$names,proj4string=crs)

since sp.usa consists of a group of lands and I only need the mainland, then

mainland=slot(sp.usa,'polygons')[[3]]
class(mainland)
[1] "Polygons"
attr(,"package")
[1] "sp"

The question is how to transform 'mainland' back into SpatialPolygons format. 

Any advice would be appreciated.

Weidong Gu, 

University of Alabama, Birmingham


From bibiko at eva.mpg.de  Tue Jun 22 22:59:29 2010
From: bibiko at eva.mpg.de (=?iso-8859-1?Q?Hans-J=F6rg_Bibiko?=)
Date: Tue, 22 Jun 2010 22:59:29 +0200
Subject: [R-sig-Geo] how to transform Polygons to SpatialPolygons
In-Reply-To: <540FAB030B18B14B8E672DB4B500635B27AA2FA7C5@UABEXMBS6.ad.uab.edu>
References: <540FAB030B18B14B8E672DB4B500635B27AA2FA7C5@UABEXMBS6.ad.uab.edu>
Message-ID: <282AA3F8-5283-4588-9C74-9B3A9C849641@eva.mpg.de>


On Jun 22, 2010, at 10:29 PM, Weidong Gu wrote:

> 
> The question is how to transform 'mainland' back into SpatialPolygons format. 


Hi,

maybe try the following:

library(maps)
library(maptools)
usa=map('usa',plot=F,fill=T)
IDs=sapply(strsplit(usa$names,':'), function(x) x[1])
crs=CRS('+proj=longlat +ellps=WGS84')
sp.usa=map2SpatialPolygons(usa,IDs=usa$names,proj4string=crs)

mainland <- list(slot(sp.usa,'polygons')[[3]])
sp_mainland <- SpatialPolygons(mainland, proj4string=crs)
str(sp_mainland)
plot(sp_mainland)

Cheers,
--Hans


**********************************************************
Hans-Joerg Bibiko
Max Planck Institute for Evolutionary Anthropology
Department of Linguistics
Deutscher Platz 6     phone:   +49 (0) 341 3550 341
D-04103 Leipzig       fax:     +49 (0) 341 3550 333
Germany               e-mail:  bibiko[-at-]eva.mpg.de


From sjmyers at syr.edu  Tue Jun 22 23:20:31 2010
From: sjmyers at syr.edu (Seth J Myers)
Date: Tue, 22 Jun 2010 21:20:31 +0000
Subject: [R-sig-Geo] edge/boundary delineation in R?
In-Reply-To: <266CBFBFD14254478D52158AE6BF90171032C26B@BL2PRD0103MB043.prod.exchangelabs.com>
References: <266CBFBFD14254478D52158AE6BF90171032C26B@BL2PRD0103MB043.prod.exchangelabs.com>
Message-ID: <266CBFBFD14254478D52158AE6BF901710333480@BL2PRD0103MB038.prod.exchangelabs.com>



________________________________________
From: Seth J Myers
Sent: Saturday, June 19, 2010 3:01 PM
To: r-sig-geo at stat.math.ethz.ch
Subject: edge/boundary delineation in R?

Hi,

Sorry if you see this twice.  I submitted this a few days ago but have not seen it on the listserv.

I need to delineate edges in a multivariate data set with each variable measured at a systematic grid of points separated by a distance (not a contiguous lattice, i.e. raster).  Triangulation wombling appears to be the method most mentioned for this.  I cannot find an open source with this function.  SAM used to have it but now it appears it was removed.  R has wombsoft, which is designed specifically for allele frequency and so I'm afraid it won't work for several continuous variables.  Any suggestions for edge delineation with multiple variables in R (doesn't have to be wombling)?

Thanks
Seth

________________________________________
From: r-sig-geo-bounces at stat.math.ethz.ch [r-sig-geo-bounces at stat.math.ethz.ch] on behalf of r-sig-geo-request at stat.math.ethz.ch [r-sig-geo-request at stat.math.ethz.ch]
Sent: Saturday, June 19, 2010 6:00 AM
To: r-sig-geo at stat.math.ethz.ch
Subject: R-sig-Geo Digest, Vol 82, Issue 19

Send R-sig-Geo mailing list submissions to
        r-sig-geo at stat.math.ethz.ch

To subscribe or unsubscribe via the World Wide Web, visit
        https://stat.ethz.ch/mailman/listinfo/r-sig-geo
or, via email, send a message with subject or body 'help' to
        r-sig-geo-request at stat.math.ethz.ch

You can reach the person managing the list at
        r-sig-geo-owner at stat.math.ethz.ch

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-Geo digest..."


Today's Topics:

   1. Fw : image() with levels (Lho Lho)
   2. Re: Fw : image() with levels (Roger Bivand)
   3. Re: rgdal (tom sgouros)
   4. Re: rgdal (Roger Bivand)


----------------------------------------------------------------------

Message: 1
Date: Fri, 18 Jun 2010 10:02:11 +0000 (GMT)
From: Lho Lho <manguefleur at yahoo.fr>
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] Fw : image() with levels
Message-ID: <61398.11475.qm at web29214.mail.ird.yahoo.com>
Content-Type: text/plain; charset="iso-8859-1"






> Objet: image() with levels
> ?: "helpgeoR helpgeoR" <r-sig-geo at stat.math.ethz.ch>
> Date: Vendredi 18 juin 2010, 9h30
> Dear all
>
> I am beginner in R and I am involved in geostatistics
> analysis
>
> I failed to map my "values" with contour.filled() or
> image() [and add levels afterward with contour()] because I
> do not know how I should shape my data in order to use
> image() or contour.filled()
>
> I attached my data file for someone who can help me by
> providing me the code
>
> Best regards,
>
> lho
>
>
> ? ? ?



-------------- next part --------------
A non-text attachment was scrubbed...
Name: Myfile
Type: application/octet-stream
Size: 61350 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100618/a0686ec2/attachment-0001.obj>

------------------------------

Message: 2
Date: Fri, 18 Jun 2010 12:28:27 +0200 (CEST)
From: Roger Bivand <Roger.Bivand at nhh.no>

Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] Fw : image() with levels
Message-ID: <alpine.LRH.2.00.1006181217180.18137 at reclus.nhh.no>
Content-Type: text/plain; charset="iso-8859-15"; Format="flowed"

On Fri, 18 Jun 2010, Lho Lho wrote:

You are very impatient, and have forwarded your message (with a large and
unnecessary attachment) to the list as a repeat thread. This smells like
homework. Please read the posting guide:

http://www.r-project.org/posting-guide.html

and respect other users' time (and server capacity and net bandwidth)

Questions should be well-framed, but yours are incomprehensible - it is
impossible to know what your problem is (the subject is also very
unclear). Please examine carefully a sample of other threads and the
posting guide to see how to ask questions that may attract answers.

In general, attachments are not welcome. If an attachment seems
essential, please only provide a link to the files considered for
attachment, and do not attach the files themselves. Sending attachments to
over 1600 list members uses energy on multiple servers without any need,
and wastes server capacity. Only members prepared to reply are likely to
need to access the attachment, so a link is much more practical, even if
it takes a little longer to set up.

Your list admin,

Roger

>
>

>

>> Objet: image() with levels
>> ?: "helpgeoR helpgeoR" <r-sig-geo at stat.math.ethz.ch>
>> Date: Vendredi 18 juin 2010, 9h30
>> Dear all
>>
>> I am beginner in R and I am involved in geostatistics
>> analysis
>>
>> I failed to map my "values" with contour.filled() or
>> image() [and add levels afterward with contour()] because I
>> do not know how I should shape my data in order to use
>> image() or contour.filled()
>>
>> I attached my data file for someone who can help me by
>> providing me the code
>>
>> Best regards,
>>
>> lho
>>
>>
>> ? ? ?

--
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

------------------------------

Message: 3
Date: Fri, 18 Jun 2010 09:20:02 -0400
From: tom sgouros <tomfool at as220.org>
To: Roger.Bivand at nhh.no
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] rgdal
Message-ID: <28149.1276867202 at as220.org>


Roger:

Thank you for the answers.  But I still don't understand why the default
installation wouldn't work before I tried to specify the location
explicitly?  /usr/local/lib doesn't seem non-standard to me, and it was
the default from the PROJ 'make install'.  Why wouldn't the default
rgdal installation work with the default PROJ installation?

Also, how would you suggest testing the PROJ installation?  Or GDAL, for
that matter.  Neither makefile seems to have a test target, and I'm
coming to them as dependencies of a different package that I want to
use, so they are not libraries with which I am familiar.  Where can I
find a test program?

Thank you,

 -tom


Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Thu, 17 Jun 2010, tom sgouros wrote:
>
> Your syntax for the configure.args= argument was wrong, and most
> likely it would fail on GDAL next. If you want to install from source,
> install PROJ.4 first, test it (you need the headers and the *shared*
> library), then install and test GDAL. When they are in place,
> determine the correct locations and use configure.args= without any
> PROJ=.
>
> If this sounds hard, use the Kyngchaos route, which is well tried,
> both for getting the external dependencies and installing rgdal from
> source, or indeed for installing binary rgdal (William Kyngesburye is
> kind enough to keep things pretty updated).
>
> The easiest route is to do:
>
> setRepositories(ind=1:2)
> install.packages("rgdal")
>
> which looking at the list archives would have shown, for example
> google on:
>
> R-sig-geo rgdal MAC
>
> or similar. The second repository in the list is in this case on OSX
> at Oxford on CRAN extras, and the rgdal binary with bundled PROJ.4 and
> GDAL dependencies is built by Brian Ripley:
>
> http://www.stats.ox.ac.uk/pub/RWin/bin/macosx/leopard/contrib/2.11/rgdal_0.6-27.tgz
>
> or similar for the R 2.10 and development 2.12 releases.
>
> Unless you need extra drivers, installing from CRAN extras version is
> probably the easiest.
>
> Roger
>
> >
> > Alex Mandel <tech_dev at wildintellect.com> wrote:
> >
> >> On 06/17/2010 05:40 PM, tom sgouros wrote:
> >>>
> >>> Hello all:
> >>>
> >>> I read this in the rgdal documentation:
> >>>
> >>>> The GDAL and PROJ.4 libraries are external to the package, and, when
> >>>> installing the package from source, must be correctly installed first.
> >>>
> >>> Does "correctly" mean something different from the default?  I installed
> >>> PROJ.4 on my Mac OS X (10.6) machine, using 'make all' and 'make
> >>> install'.  I saw no errors, and I see libproj.a sitting happily in
> >>> /usr/local/lib which seems pretty standard to me, but when I try to
> >>> install rgdal, I get this:
> >>>
> >>>   ...
> >>>   checking proj_api.h usability... yes
> >>>   checking proj_api.h presence... yes
> >>>   checking for proj_api.h... yes
> >>>   checking for pj_init_plus in -lproj... no
> >>>   Error: libproj.a not found.
> >>>   If the PROJ.4 library is installed in a non-standard location,
> >>>   use --configure-args='--with-proj-lib=/opt/local/lib' for example,
> >>>   replacing /opt/local/* with appropriate values for your installation.
> >>>   If PROJ.4 is not installed, install it.
> >>>
> >>> Before it was installed, the configure choked on the line about
> >>> proj_api.h.
> >>>
> >>> It was already installed, but per those directions, I tried this:
> >>>
> >>>> install.packages(c("rgdal"),lib="/Library/Frameworks/R.framework/Resources/library",contriburl=contrib.url(getOption("repos"),'source'),type='source',dependencies=TRUE,configure.args=c(PROJ='--with-proj-lib=/usr/local/lib'))
> >>>
> >> Those instructions seem to indicate that it should be:
> >> configure.args='--with-proj-lib=/usr/local/lib'
> >> while the R code you put in may seem similar and theoretically provide
> >> the same, try doing it exactly like the example.
> >
> > The example is from a command line invocation of ./configure.  How that
> > relates to an install.packages() option wasn't obvious to me.  I was
> > just copying the example in the install.packages() documentation.  But I
> > tried it your way just now and it still doesn't work.  Same error.
> > Besides, what's so non-standard about /usr/local/lib?
> >
> >>
> >> The other option to consider is install Proj and GDAL from the Frameworks:
> >> http://www.kyngchaos.com/software/frameworks
> >>
> >> I know people have gotten the frameworks to work.
> >
> > I'll try that, but I'm still mystified.
> >
> > Thank you,
> >
> > -tom
> >
> >
> >>
> >> Enjoy,
> >> Alex
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at stat.math.ethz.ch
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >
> >
> >
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>







--
 --------------------------------------------------------
 Check out "Ten Things You Don't Know About Rhode Island"
     http://whatcheer.net      http://sgouros.com



------------------------------

Message: 4
Date: Fri, 18 Jun 2010 16:38:19 +0200 (CEST)
From: Roger Bivand <Roger.Bivand at nhh.no>
To: tom sgouros <tomfool at as220.org>
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] rgdal
Message-ID: <alpine.LRH.2.00.1006181534170.18137 at reclus.nhh.no>
Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed

On Fri, 18 Jun 2010, tom sgouros wrote:

>
> Roger:
>
> Thank you for the answers.  But I still don't understand why the default
> installation wouldn't work before I tried to specify the location
> explicitly?  /usr/local/lib doesn't seem non-standard to me, and it was
> the default from the PROJ 'make install'.  Why wouldn't the default
> rgdal installation work with the default PROJ installation?

I believe that your syntax in the install.packages() command was wrong,
you had:

configure.args=c(PROJ='--with-proj-lib=/usr/local/lib')

which I don't think is what is needed, I think that the name PROJ= is
redundant, but c(rgdal='--with-proj-lib=/usr/local/lib') would seem to
correspond to the documentation, because this is a configure argument to
rgdal. In the example, two R packages are being installed, each with a
configure argument.

>
> Also, how would you suggest testing the PROJ installation?

make check in proj-4.7.0 for that release.

> Or GDAL, for that matter.

It is a separate download - look for gdalautotest for the major release
family.

> Neither makefile seems to have a test target, and I'm coming to them as
> dependencies of a different package that I want to use, so they are not
> libraries with which I am familiar.  Where can I find a test program?

Usually it is sufficient to run ogrinfo on any vector file, and gdalinfo
on any raster file (both for simple drivers). This shows that the
dynamically loaded dependencies are satisfied. Running the gdalautotest is
more for developers.

Hope this helps,

Roger

>
> Thank you,
>
> -tom
>
>
> Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Thu, 17 Jun 2010, tom sgouros wrote:
>>
>> Your syntax for the configure.args= argument was wrong, and most
>> likely it would fail on GDAL next. If you want to install from source,
>> install PROJ.4 first, test it (you need the headers and the *shared*
>> library), then install and test GDAL. When they are in place,
>> determine the correct locations and use configure.args= without any
>> PROJ=.
>>
>> If this sounds hard, use the Kyngchaos route, which is well tried,
>> both for getting the external dependencies and installing rgdal from
>> source, or indeed for installing binary rgdal (William Kyngesburye is
>> kind enough to keep things pretty updated).
>>
>> The easiest route is to do:
>>
>> setRepositories(ind=1:2)
>> install.packages("rgdal")
>>
>> which looking at the list archives would have shown, for example
>> google on:
>>
>> R-sig-geo rgdal MAC
>>
>> or similar. The second repository in the list is in this case on OSX
>> at Oxford on CRAN extras, and the rgdal binary with bundled PROJ.4 and
>> GDAL dependencies is built by Brian Ripley:
>>
>> http://www.stats.ox.ac.uk/pub/RWin/bin/macosx/leopard/contrib/2.11/rgdal_0.6-27.tgz
>>
>> or similar for the R 2.10 and development 2.12 releases.
>>
>> Unless you need extra drivers, installing from CRAN extras version is
>> probably the easiest.
>>
>> Roger
>>
>>>
>>> Alex Mandel <tech_dev at wildintellect.com> wrote:
>>>
>>>> On 06/17/2010 05:40 PM, tom sgouros wrote:
>>>>>
>>>>> Hello all:
>>>>>
>>>>> I read this in the rgdal documentation:
>>>>>
>>>>>> The GDAL and PROJ.4 libraries are external to the package, and, when
>>>>>> installing the package from source, must be correctly installed first.
>>>>>
>>>>> Does "correctly" mean something different from the default?  I installed
>>>>> PROJ.4 on my Mac OS X (10.6) machine, using 'make all' and 'make
>>>>> install'.  I saw no errors, and I see libproj.a sitting happily in
>>>>> /usr/local/lib which seems pretty standard to me, but when I try to
>>>>> install rgdal, I get this:
>>>>>
>>>>>   ...
>>>>>   checking proj_api.h usability... yes
>>>>>   checking proj_api.h presence... yes
>>>>>   checking for proj_api.h... yes
>>>>>   checking for pj_init_plus in -lproj... no
>>>>>   Error: libproj.a not found.
>>>>>   If the PROJ.4 library is installed in a non-standard location,
>>>>>   use --configure-args='--with-proj-lib=/opt/local/lib' for example,
>>>>>   replacing /opt/local/* with appropriate values for your installation.
>>>>>   If PROJ.4 is not installed, install it.
>>>>>
>>>>> Before it was installed, the configure choked on the line about
>>>>> proj_api.h.
>>>>>
>>>>> It was already installed, but per those directions, I tried this:
>>>>>
>>>>>> install.packages(c("rgdal"),
lib="/Library/Frameworks/R.framework/Resources/library",
contriburl=contrib.url(getOption("repos"),'source'),
type='source',
dependencies=TRUE,
configure.args=c(PROJ='--with-proj-lib=/usr/local/lib'))

>>>>>
>>>> Those instructions seem to indicate that it should be:
>>>> configure.args='--with-proj-lib=/usr/local/lib'
>>>> while the R code you put in may seem similar and theoretically provide
>>>> the same, try doing it exactly like the example.
>>>
>>> The example is from a command line invocation of ./configure.  How that
>>> relates to an install.packages() option wasn't obvious to me.  I was
>>> just copying the example in the install.packages() documentation.  But I
>>> tried it your way just now and it still doesn't work.  Same error.
>>> Besides, what's so non-standard about /usr/local/lib?
>>>
>>>>
>>>> The other option to consider is install Proj and GDAL from the Frameworks:
>>>> http://www.kyngchaos.com/software/frameworks
>>>>
>>>> I know people have gotten the frameworks to work.
>>>
>>> I'll try that, but I'm still mystified.
>>>
>>> Thank you,
>>>
>>> -tom
>>>
>>>
>>>>
>>>> Enjoy,
>>>> Alex
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>
>>>
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>
>
>
>
>
>
>
>

--
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



------------------------------

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


End of R-sig-Geo Digest, Vol 82, Issue 19


From thangalin at gmail.com  Tue Jun 22 23:37:59 2010
From: thangalin at gmail.com (David Jarvis)
Date: Tue, 22 Jun 2010 14:37:59 -0700
Subject: [R-sig-Geo] Long/Lat coordinates inside a complex spherical polygon
Message-ID: <AANLkTin336ZY6-PjEnsuAstkmj96_OBSt7ro64H_NBHJ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100622/d0589aa4/attachment.pl>

From r.hijmans at gmail.com  Wed Jun 23 00:27:26 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 22 Jun 2010 15:27:26 -0700
Subject: [R-sig-Geo] Long/Lat coordinates inside a complex spherical
	polygon
In-Reply-To: <AANLkTin336ZY6-PjEnsuAstkmj96_OBSt7ro64H_NBHJ@mail.gmail.com>
References: <AANLkTin336ZY6-PjEnsuAstkmj96_OBSt7ro64H_NBHJ@mail.gmail.com>
Message-ID: <AANLkTikg-8mr3tQ8JW3hTf2iPk6OEKihD5_JJTYm6Sog@mail.gmail.com>

David, You can use overlay in sp, but that does not consider the
inter-vertex curvature of the polygons. If this is a concern (i.e.
your have polygons with vertices that are far apart), you could first
uses geosphere::makePoly  to at least avoid the worst mistakes (as in
the example below). For relatively small polygons with a reasonable
number of vertices it would probably not make much of a difference.
Robert

library(sp)
library(geosphere)

pol <- rbind(c(-180,-20), c(-160,5), c(-60, 0), c(-160,-60), c(-180,-20))
sp1 <- SpatialPolygons(list(Polygons(list(Polygon(pol)), 1)))
sp2 <- makePoly(pol, interval=100000, sp=T)

pt = data.frame(cbind(x=-111, y=-41))
coordinates(pt) = ~ x + y

# pt is (incorrectly) outside sp1
overlay(pt, sp1)
# but (correctly) inside (polygon #1)
overlay(pt, sp2)

plot(sp1)
plot(sp2, add=T, border='red')
points(pt, col='blue', cex='x', pch=2)

On Tue, Jun 22, 2010 at 2:37 PM, David Jarvis <thangalin at gmail.com> wrote:
> Hi,
>
> What R package provides a way to determine if a longitude/latitude
> coordinate is situated inside a closed, complex spherical polygon (i.e., a
> point inside a polygon on Earth's surface)?
>
> For example:
>
> p <- rbind( c(-123.4447,48.5146), c(-123.3171,48.5128),
> c(-123.2607,48.4108), c(-123.4018,48.4099), c(-123.4447,48.5146) )
>
> ll <- c(-123.3501,48.4902)
>
> print( isInside( ll, p ) )
>
> I have looked at the following packages:
>
> ? - geosphere
> ? - GEOmap
>
> I could not find anything else at CRAN that looked suitable.
>
> A good article on the subject is at:
>
> trs-new.jpl.nasa.gov/dspace/bitstream/2014/40409/1/07-03.pdf
>
> Thank you!
> Dave
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From edzer.pebesma at uni-muenster.de  Wed Jun 23 09:08:20 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 23 Jun 2010 09:08:20 +0200
Subject: [R-sig-Geo] how to transform Polygons to SpatialPolygons
In-Reply-To: <282AA3F8-5283-4588-9C74-9B3A9C849641@eva.mpg.de>
References: <540FAB030B18B14B8E672DB4B500635B27AA2FA7C5@UABEXMBS6.ad.uab.edu>
	<282AA3F8-5283-4588-9C74-9B3A9C849641@eva.mpg.de>
Message-ID: <4C21B2E4.5070001@uni-muenster.de>

Or maybe just:

plot(sp.usa[3])
class(sp.usa[3])
[1] "SpatialPolygons"
attr(,"package")
[1] "sp"



On 06/22/2010 10:59 PM, Hans-J?rg Bibiko wrote:
> 
> On Jun 22, 2010, at 10:29 PM, Weidong Gu wrote:
> 
>>
>> The question is how to transform 'mainland' back into SpatialPolygons format. 
> 
> 
> Hi,
> 
> maybe try the following:
> 
> library(maps)
> library(maptools)
> usa=map('usa',plot=F,fill=T)
> IDs=sapply(strsplit(usa$names,':'), function(x) x[1])
> crs=CRS('+proj=longlat +ellps=WGS84')
> sp.usa=map2SpatialPolygons(usa,IDs=usa$names,proj4string=crs)
> 
> mainland <- list(slot(sp.usa,'polygons')[[3]])
> sp_mainland <- SpatialPolygons(mainland, proj4string=crs)
> str(sp_mainland)
> plot(sp_mainland)
> 
> Cheers,
> --Hans
> 
> 
> **********************************************************
> Hans-Joerg Bibiko
> Max Planck Institute for Evolutionary Anthropology
> Department of Linguistics
> Deutscher Platz 6     phone:   +49 (0) 341 3550 341
> D-04103 Leipzig       fax:     +49 (0) 341 3550 333
> Germany               e-mail:  bibiko[-at-]eva.mpg.de
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From vieadmm4 at uib.es  Wed Jun 23 09:41:25 2010
From: vieadmm4 at uib.es (vieadmm4 at uib.es)
Date: Wed, 23 Jun 2010 09:41:25 +0200
Subject: [R-sig-Geo] semivariogram of residuals from logistic model
Message-ID: <20100623094125.hfgzft0ask8wcg48@wm.uib.es>

Dear all,

I wish to make a semivariogram using the residuals of a GLM  
(family=binomial(link=logit)). Well, my problem is that I have  
realized that residuals.glm() can return different types of residuals.  
I'm using the "response" type as it returns the values on the -1 to +1  
scale. However, I'm not quite familiar with this issue. Semivariograms  
of the different types look similar, but the values of semivariance  
are different.
I will appreciate any help regarding this issue and additional  
considerations that I should need to take into account for the  
variography of this kind of model.

Best regards,

David March Morla
Doctorando / PhD student
Instituto Mediterraneo de Estudios Avanzados (UIB-CSIC)
C/Miquel Marques,21
07190 Esporles
Islas Baleares - Spain
Tel: +34 971 611 722
Fax: +34 971 611 761
Email: david.march at uib.es


From k.lamb at sphsu.mrc.ac.uk  Wed Jun 23 13:17:18 2010
From: k.lamb at sphsu.mrc.ac.uk (Karen Lamb)
Date: Wed, 23 Jun 2010 12:17:18 +0100
Subject: [R-sig-Geo] Assessing residual spatial autocorrelation in a
	Poisson or Negative Binomial model
References: <4B0E5C88.8030002@sphsu.mrc.ac.uk>
	<684e31d40911260311x5d2f36b0m6b32794fafbf020f@mail.gmail.com>
	<alpine.LRH.2.00.0911261225240.13556@reclus.nhh.no>
Message-ID: <E52EDFC1C68C4DADACDBCAD1C3D0184F@ibmroompc>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100623/f37ce229/attachment.pl>

From edzer.pebesma at uni-muenster.de  Wed Jun 23 13:48:49 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 23 Jun 2010 13:48:49 +0200
Subject: [R-sig-Geo] removing key from spplot with a factor variable
In-Reply-To: <AANLkTil6EqGyLCn6RLdqvbVx0ApXtyDy1sKFxfMZupIx@mail.gmail.com>
References: <AANLkTil6EqGyLCn6RLdqvbVx0ApXtyDy1sKFxfMZupIx@mail.gmail.com>
Message-ID: <4C21F4A1.5060103@uni-muenster.de>

Heather kindly provided me a reproducable example of this bug off-list,
it is found below.

I corrected it, in cvs, it will be in the next sp version (to be
released soon).

Thanks!
--
Edzer


library(sp)
library(maptools)

nc <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1],
proj4string=CRS("+proj=longlat +datum=NAD27"))
names(nc)
# create two dummy factor variables, with equal labels:
set.seed(31)
nc$f = factor(sample(1:5,100,replace=T),labels=letters[3:7])
nc$f = factor(nc$f, levels = letters[1:7])

library(RColorBrewer)
## Two (dummy) factor variables shown with qualitative colour ramp;

key <- spplot(nc, c("f"), col.regions=brewer.pal(7, "Set3"),
scales=list(draw = TRUE))
nokey <- spplot(nc, c("f"), col.regions=brewer.pal(7, "Set3"),
scales=list(draw = TRUE), colorkey=F)

print(key, split= c(1,1,1,2), more=TRUE)
print(nokey, split = c(1,2,1,2))

On 06/21/2010 10:44 PM, Heather Carmichael wrote:
> I have been trying to plot using spplot().  My variable is a factor, but
> some levels are unused.  When I plot the map with a key (using the default
> colorkey=T) everything plots fine.  But when I remove the key (colorkey=F)
> all of the colors map to the wrong factors (I am assuming this is because
> some of the factor levels are unused).
> 
> This maps as I would expect it, with the key:
> spplot(worldmap, "mu.level", lwd=0.01, col="white", scales = list(draw = F),
> colorkey = T,  par.settings=list(fontsize=list(text=10, points=10)),
> cuts=24, col.regions=colvec)
> 
> 
> Is there any way to hide/get rid of the key without changing the plot (i.e.
> without using colorkey=F)?
> 
> Thanks!
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From corey.sparks at utsa.edu  Wed Jun 23 14:04:19 2010
From: corey.sparks at utsa.edu (Corey Sparks)
Date: Wed, 23 Jun 2010 07:04:19 -0500
Subject: [R-sig-Geo] Help converting neighbor list to vector
Message-ID: <DAC82C09-5CB4-4B4A-AE96-3054B68C1DA5@utsa.edu>

Hello all,
I have a neighbor list, formed from poly2nb in spdep, and a spatial  
weight matrix formed by nbmat(). I then extract all of the elements of  
the matrix that are nonzero (the neighbors for each observation),  
here's what i've done

sa<-readShapePoly("~/Documents/data/SA_bg_ses_wtabc_crime.shp")
sa.nb<-poly2nb(sa2)
sa.wt<-nb2mat(sa.nb, style="B")
x<-apply(sa.wt, 1,function(x){which(x==1)})

so, here is a preview of the x object from above:

x[1:3]
$`0`
[1]  4 11

$`1`
[1]  3 10 12

$`2`
[1]  2  7 10 12 13

If we look at the entire dataset (there are ~900 observations) the  
maximum number of neighbors is 10.  I would like to turn this 'x'  
object into a vector of form:

row1  obs#  obs#offirstneighbor  obs#ofsecondeighbor  
obs#ofthirdneighbor ... total#ofneighbors

like this example

      V1 V2  V3  V4 V5 V6
1     1 11   2   0  0  2
2     2 12   1   3  0  3
3     3 13   2   4  0  3


Here's what I've tried, but alas it fails

nbs<-matrix(0, nrow=dim(slot(sa,"data.frame"))[1], ncol=10)

for(i in 1:dim(slot(sa,"data.frame"))[1]) { for (j in length(x[[j]])) 
{nbs[i,j]<-x[[i]][j]}}

I've also tried unlist(x), but that doesn't give the result i'm  
looking for.  If anyone might have an idea on this one I'd really be  
appreciative, and i'd be happy to make the data available if anyone  
would like.
Best,
Corey

Corey Sparks
Assistant Professor
Department of Demography and Organization Studies
College of Public Policy
501 West Durango Blvd
Monterrey Building 2.270C
San Antonio, TX 78207
corey.sparks 'at' utsa.edu
210 458 3166


From thi_veloso at yahoo.com.br  Wed Jun 23 15:29:43 2010
From: thi_veloso at yahoo.com.br (Thiago Veloso)
Date: Wed, 23 Jun 2010 06:29:43 -0700 (PDT)
Subject: [R-sig-Geo] How to clip a map using shapefiles?
Message-ID: <217367.98145.qm@web54305.mail.re2.yahoo.com>

??Dear r-siggers,
??Does anybody know how to clip, or cut a map using a previous loaded shapefile? To produce the attached map, I'm using the following code:?image(lon,lat,testedec1[111:133,15:43],col=rainbow(10))par(new=T)plot(brazil)
??Where "brazil" is a shapefile loaded with maptools library. Is it possible to use this shape as a mask to filter the map values? The result would be only the values which are inside the contour...
??Thanks in advance,
??Thiago Veloso.


      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100623/d0ed8104/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: sample_map.png
Type: image/png
Size: 42592 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100623/d0ed8104/attachment.png>

From roman.lustrik at gmail.com  Wed Jun 23 16:02:48 2010
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Wed, 23 Jun 2010 16:02:48 +0200
Subject: [R-sig-Geo] how to find cells in a raster
Message-ID: <AANLkTik0vYQelrx2jkGIWqIuZmMuRl-Cu1YWcUiwprpo@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100623/6137cc61/attachment.pl>

From r.hijmans at gmail.com  Wed Jun 23 19:12:08 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 23 Jun 2010 10:12:08 -0700
Subject: [R-sig-Geo] how to find cells in a raster
In-Reply-To: <AANLkTik0vYQelrx2jkGIWqIuZmMuRl-Cu1YWcUiwprpo@mail.gmail.com>
References: <AANLkTik0vYQelrx2jkGIWqIuZmMuRl-Cu1YWcUiwprpo@mail.gmail.com>
Message-ID: <AANLkTilZkcQvA-OSV_NYj0y0QIirtp2ZrWXOxxJjuCCO@mail.gmail.com>

Roman,

Perhaps you can make a RasterLayer with the cell numbers and then use
xyValues with a buffer

r <- raster(original.raser)
r[] <- 1:ncell(r)
xyValues(r, points, buffer=?)

Robert

On Wed, Jun 23, 2010 at 7:02 AM, Roman Lu?trik <roman.lustrik at gmail.com> wrote:
> Dear list,
>
> I'm trying to find cells in a RasterLayer object. Specifically, I'm trying
> to find all cells within a radius from a pre-defined point. When I have cell
> numbers or coordinates, I can calculate their distance from the
> aforementioned pre-defined point.
> So far, I've been overlaying a polygon and extracting cell numbers with
> polygonValues(), however, this method seems to be somewhat slow (especially
> on larger rasters). I've benchmarked it and it is approximately as fast as
> if I used distanceFromPoints(), which calculates distances for all cells in
> a raster. Is there a faster way of finding these cells?
>
> Cheers,
> Roman
>
>
> --
> In God we trust, all others bring data.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From r.hijmans at gmail.com  Wed Jun 23 19:16:12 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 23 Jun 2010 10:16:12 -0700
Subject: [R-sig-Geo] How to clip a map using shapefiles?
In-Reply-To: <217367.98145.qm@web54305.mail.re2.yahoo.com>
References: <217367.98145.qm@web54305.mail.re2.yahoo.com>
Message-ID: <AANLkTik423y2cvH2OpMV70jOyIShsVsSKoGPcquufi4A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100623/3dc8416d/attachment.pl>

From diaomi at gmail.com  Wed Jun 23 21:28:36 2010
From: diaomi at gmail.com (Mi Diao)
Date: Wed, 23 Jun 2010 15:28:36 -0400
Subject: [R-sig-Geo] spatial durbin model with large dataset
In-Reply-To: <alpine.LRH.2.00.1006211056050.1009@reclus.nhh.no>
References: <AANLkTikvzu8z2nwNNn_RfXPYm2pp3Gp2Y0ZJGMBinsy3@mail.gmail.com>
	<alpine.LRH.2.00.1006211056050.1009@reclus.nhh.no>
Message-ID: <AANLkTinoaJvjM37Y3quFoU8Y94XVTjfe1owH27AyXw4-@mail.gmail.com>

Thanks a lot for your help, Roger!

I ran into another problem when I try to calibrate spatial lag and
spatial durbin model with this dataset using spdep. The error messages
that I got are:

Error in solve.default(-(mat), tol.solve = tol.solve) :
 Lapack routine dgesv: system is exactly singular

In addition: There were 38 warnings (use warnings() to see them)
> warnings()
Warning messages:
1: In determinant(x, TRUE) : This version of the Matrix package returns
|determinant(L)| instead of determinant(A), i.e., a
*DIFFERENT* value.
 If still necessary, do change your code, following
http://matrix.r-forge.r-project.org

2: In optimize(sar.lag.mixed.f, interval = interval, maximum = TRUE,  ... :
 NA/Inf replaced by maximum positive value
......

I have been able to calibrate the spatial lag model with the same
dataset using Geoda. Could anyone help me figure this out?

Thanks a lot!

Mi

On Mon, Jun 21, 2010 at 5:13 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Sun, 20 Jun 2010, Mi Diao wrote:
>
>> Dear all,
>>
>> I am trying to calibrate a Spatial Durbin Model for a dataset with
>> 52000 observations. Geoda can handle a dataset of this size, but it
>> can only estimate spatial lag and spatial error model. Can the spdep
>> package of R handle my dataset?
>
> Yes. At a recent demo, I ran the 25k ?house example on a small memory older
> laptop without trouble (http://spatial.nhh.no/R/sea10.zip). With 50k and
> many RHS variables, you may find a busy Windows 1Gb machine gasps a bit - if
> so, shut down other programs (IE etc.) before starting R. Look at ?lagsarlm,
> then ?impacts. Typically, you'll need something like:
>
> # lw is your weights object, probably from nb2listw()
> # df is the data.frame with your data
>
> # first generate sparse matrix product traces
> W <- as(as_dgRMatrix_lw(lw), "CsparseMatrix")
> trMat <- trW(W, type="MC")
>
> SD_fit <- lagsarlm(y ~ x, data=df, listw=lw, type="mixed",
> ?method="Matrix", tr=trMat, control=list(compiled_sse=TRUE))
> # type="mixed" fits a Spatial Durbin model;
> # method could also be "Chebyshev" or "MC" for approximations,
> # "Matrix" uses updating sparse Cholesky Jacobians, see ?do_ldet
> # for details. "Matrix" needs symmetric neighbours, some other methods
> # may not. Beware of k-nearest neighbour schemes, for the same reasons
> # as in GeoDa
>
> summary(SD_fit)
>
> # now generate samples from the fitted model to assess the
> # significance of the impacts
> imp_SD_fit <- impacts(SD_fit, tr=trMat, R=2000)
> summary(imp_SD_fit)
> plot(imp_SD_fit)
> summary(imp_SD_fit, zstats=TRUE, short=TRUE)
>
> Hope this helps,
>
> Roger
>
>>
>> Thanks a lot for your kind help!
>>
>> Mi
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>



-- 
--------------------------------------------------------------
Mi Diao
Ph. D. Candidate
Department of Urban Studies and Planning
Massachusetts Institute of Technology
Cambridge, MA 02139


From Roger.Bivand at nhh.no  Thu Jun 24 10:01:05 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 24 Jun 2010 10:01:05 +0200 (CEST)
Subject: [R-sig-Geo] spatial durbin model with large dataset
In-Reply-To: <AANLkTinNjAiefbZ2asIHfeCWwrF35qnD0ttN3SPVsR-i@mail.gmail.com>
References: <AANLkTikvzu8z2nwNNn_RfXPYm2pp3Gp2Y0ZJGMBinsy3@mail.gmail.com>
	<alpine.LRH.2.00.1006211056050.1009@reclus.nhh.no>
	<AANLkTinNjAiefbZ2asIHfeCWwrF35qnD0ttN3SPVsR-i@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1006240945430.15824@reclus.nhh.no>

On Wed, 23 Jun 2010, Mi Diao wrote:

> Thanks a lot for your help, Roger!
>
> I ran into another problem when I try to calibrate spatial lag and
> spatial durbin model with this dataset using spdep. The error messages
> that I got are:
>
> Error in solve.default(-(mat), tol.solve = tol.solve) :
>  Lapack routine dgesv: system is exactly singular

After an error, always report the output of traceback(), and always show 
the command in full that led to the error. In addition, always show the 
output of sessionInfo(). On examining the entrails, it looks (guesswork) 
as though the matrix output of the adjusted finite difference Hessian 
of the coefficients seems to be singular, which suggests that perhaps the 
X variables and the WX are strongly correlated. Try:

SD_fit <- lagsarlm(y ~ x, data=df, listw=lw, type="mixed",
  ?method="Matrix", tr=trMat, control=list(compiled_sse=FALSE))
SD_fit <- lagsarlm(y ~ x, data=df, listw=lw, type="mixed",
  ?method="Matrix", control=list(compiled_sse=FALSE))
SD_fit <- lagsarlm(y ~ x, data=df, listw=lw, type="mixed",
  ?method="Matrix", control=list(compiled_sse=TRUE))
SD_fit <- lagsarlm(y ~ x, data=df, listw=lw, type="mixed",
  ?method="Matrix", control=list(fdHess=FALSE))

and if any of them succeed, do

summary(SD_fit)

and see if any of the coefficients are aliased. The other warnings about 
the line optimisation reseting on NA suggests that there are issues with 
your spatial weights too - the fact that you can fit the model in GeoDa 
doesn't mean that the fit is OK - with odd weights, you can get odd 
results. Does the lagsarlm() fit with type="lag" give you the same results 
as GeoDa? Are your weights in spdep the same as in GeoDa? Are you maybe 
using inverse distance or similar odd weights?

If this doesn't make sense, please put your code, a copy of the GeoDa lag 
model fit, and save()-ed input data objects into a zip archive and post a 
link to them.

Hope this helps,

Roger

>
> In addition: There were 38 warnings (use warnings() to see them)
>> warnings()
> Warning messages:
> 1: In determinant(x, TRUE) : This version of the Matrix package returns
> |determinant(L)| instead of determinant(A), i.e., a
> *DIFFERENT* value.
> If still necessary, do change your code, following
> http://matrix.r-forge.r-project.org
>
> 2: In optimize(sar.lag.mixed.f, interval = interval, maximum = TRUE,  ... :
>  NA/Inf replaced by maximum positive value
> ......
>
> I have been able to calibrate the spatial lag model with the same
> dataset using Geoda. Could anyone help me figure this out?
>
> Thanks a lot!
>
> Mi
>
>
> On Mon, Jun 21, 2010 at 5:13 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> On Sun, 20 Jun 2010, Mi Diao wrote:
>>
>>> Dear all,
>>>
>>> I am trying to calibrate a Spatial Durbin Model for a dataset with
>>> 52000 observations. Geoda can handle a dataset of this size, but it
>>> can only estimate spatial lag and spatial error model. Can the spdep
>>> package of R handle my dataset?
>>
>> Yes. At a recent demo, I ran the 25k ?house example on a small memory older
>> laptop without trouble (http://spatial.nhh.no/R/sea10.zip). With 50k and
>> many RHS variables, you may find a busy Windows 1Gb machine gasps a bit - if
>> so, shut down other programs (IE etc.) before starting R. Look at ?lagsarlm,
>> then ?impacts. Typically, you'll need something like:
>>
>> # lw is your weights object, probably from nb2listw()
>> # df is the data.frame with your data
>>
>> # first generate sparse matrix product traces
>> W <- as(as_dgRMatrix_lw(lw), "CsparseMatrix")
>> trMat <- trW(W, type="MC")
>>
>> SD_fit <- lagsarlm(y ~ x, data=df, listw=lw, type="mixed",
>> ?method="Matrix", tr=trMat, control=list(compiled_sse=TRUE))
>> # type="mixed" fits a Spatial Durbin model;
>> # method could also be "Chebyshev" or "MC" for approximations,
>> # "Matrix" uses updating sparse Cholesky Jacobians, see ?do_ldet
>> # for details. "Matrix" needs symmetric neighbours, some other methods
>> # may not. Beware of k-nearest neighbour schemes, for the same reasons
>> # as in GeoDa
>>
>> summary(SD_fit)
>>
>> # now generate samples from the fitted model to assess the
>> # significance of the impacts
>> imp_SD_fit <- impacts(SD_fit, tr=trMat, R=2000)
>> summary(imp_SD_fit)
>> plot(imp_SD_fit)
>> summary(imp_SD_fit, zstats=TRUE, short=TRUE)
>>
>> Hope this helps,
>>
>> Roger
>>
>>>
>>> Thanks a lot for your kind help!
>>>
>>> Mi
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From hengl at spatial-analyst.net  Thu Jun 24 12:45:49 2010
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Thu, 24 Jun 2010 12:45:49 +0200
Subject: [R-sig-Geo] GEOSTAT 2010 summer school Live broadcast
Message-ID: <001001cb138a$68f45a10$3add0e30$@net>


Dear R-sig-geo,

Next week, we (Roger Bivand, Edzer Pebesma, Gerard Heuvelink, Olaf Conrad, Markus Metz, Victor Olaya and I) will run the GEOSTAT 2010 summer school in Plasencia, Spain. We have decided to open a live broadcast channel (sound and screencasting + separate web-cams), and open this summer school to public. For more info see:

[http://geostat2010.info/Live]

The summer school will start on Monday 28-06 at 9:00 European time. The complete programme of the summer school (including the slides etc) is available at: [http://geostat2010.info/programme]. We hope to record all sessions and then publish the videos after the end of the summer school, so you do not necessarily have to follow the lectures live.
PS: I have never run a webcasting with an open channel, so there might be some technical difficulties for which we apologize in advance (we did pay a subscription for the InstantPresenter, so it would not only be our fault).

On Friday 2-07 we will run a GEOSTAT workshop where anybody will be able to present a problem and get some live feedback (sort of Live R-sig-geo). If some of you would like to present some new package or functionality through webcasting, please submit a proposal via the course website [http://geostat2011.info/Instructions] and we might add you to the programme. You will need to register at the website before you can submit content of course.


GEOSTAT2011 - CALL FOR PROPOSALS:
Would some of you like to host the http://geostat2011.info event? If you think that you have energy and enthusiasm (end a lot of support from your bosses), then please submit a proposal via [http://geostat2010.info/proposal_geostat2011], by 1st of October 2010 the latest. Of course, before you can submit a proposal, you will need to do some home work and collect information, get permissions etc, hence the deadline in 3 months. 

yours,

Tom Hengl
http://home.medewerker.uva.nl/t.hengl/


From pazurrobert at gmail.com  Thu Jun 24 13:57:56 2010
From: pazurrobert at gmail.com (Robert Pazur)
Date: Thu, 24 Jun 2010 12:57:56 +0100
Subject: [R-sig-Geo] sp.correlogram
In-Reply-To: <AANLkTikKZg6Ta7PZf_HtiCPKC5r-P6WgSh73kZESoe5M@mail.gmail.com>
References: <AANLkTikKZg6Ta7PZf_HtiCPKC5r-P6WgSh73kZESoe5M@mail.gmail.com>
Message-ID: <AANLkTinkqXnYOc3IXpMk_Ng5AY4_topc6I_4y8W3nYsv@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100624/e9271ea7/attachment.pl>

From Roger.Bivand at nhh.no  Thu Jun 24 14:40:26 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 24 Jun 2010 14:40:26 +0200 (CEST)
Subject: [R-sig-Geo] sp.correlogram
In-Reply-To: <AANLkTinkqXnYOc3IXpMk_Ng5AY4_topc6I_4y8W3nYsv@mail.gmail.com>
References: <AANLkTikKZg6Ta7PZf_HtiCPKC5r-P6WgSh73kZESoe5M@mail.gmail.com>
	<AANLkTinkqXnYOc3IXpMk_Ng5AY4_topc6I_4y8W3nYsv@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1006241414400.15824@reclus.nhh.no>

On Thu, 24 Jun 2010, Robert Pazur wrote:

> Dear all,
>
> I would like to perform Moran'I correlogram (sp.correlogram method in spdep
> package) based on euclidian fixed distances  but I have following problem:
> I created an artificial table, containing long and lati of regular points
>> points <-read.table("http://www.scandinavia.sk/data/moran5.csv", sep=",",
> header=T)
> following the manual I also identified neighbours of region
>> dnb <- dnearneigh(as.matrix(points$long, points$lati), 0, 20, longlat=T)

No, from your helpful link to the data, you have projected coordinates, 
not geographical. In addition, your use of as.matrix() instead of cbind() 
has bad consequences:

str(as.matrix(points$long, points$lati))
str(cbind(points$long, points$lati))

dnearneigh() will be revised to trap this.

Had you said:

coordinates(points) <- c("long", "lati")

then:

proj4string(points) <- CRS("+proj=longlat")

you would have seen the problem, because the sp classes check for the 
bounds on objects.

So after doing:

points <-read.table("http://www.scandinavia.sk/data/moran5.csv", sep=",",
  header=T)
coordinates(points) <- c("long", "lati")
dnb <- dnearneigh(points, 0, 20)

you are good to go. Next step - how to replicate the ArcGIS Moran's I - is 
easy with the correct dnb:

moran.test(points$GRID_CODE, listw=nb2listw(dnb, style="B"))

You might use correlog() in pgirmess for distance bins, but you'll have 
more control over the bin boundaries by makin new sets of neighbours for 
your chosen bin thresholds.

Hope this helps (and thank you for reverting to the list after writing to 
me directly 70 minutes earlier. List is always best).

Roger


> neighbours list
>> ME200.listw <- nb2listw(dnb, style="W", zero.policy=T)
> but if I perform sp.correlogram function:
>> correl<-sp.correlogram(dnb, points$GRID_CODE, order = 2, method = "I",
> style = "W", randomisation = TRUE, zero.policy = TRUE, spChk=NULL)
> my results are :
> Spatial correlogram for points$GRID_CODE
> method: Moran's I
>    estimate expectation   variance standard deviate Pr(I) two sided
> 1 -0.0029855  -0.0344828  0.0019674           0.7101          0.4776
> 2 -0.0044436  -0.0344828  0.0022585           0.6321          0.5273
>
> and if i perform this part of this task in Arcgis for the same point
> shapefile Moran Calculation for Fixed distance band, Euclidian distance a
> and 20m threshold, result of Moran coefficient is
> (SpatialAutocorrelation moran GRID_CODE false "Fixed Distance Band"
> "Euclidean Distance" None 20 # 0 0 0) results are:
> Global Moran's I Summary
> Moran's Index:   0.746511
> Expected Index:  -0.003521
> Variance:        0.001827
> Z Score:         17.545122
> p-value:         0.000000
>
> I would like to perform the same task like in Arcgis but for multiple
> distances. However Arcgis cannot deal with large data with multiple points,
> thatswhy I
> would like to use R. Its seems to me much better software, but
> unfortunatelly I never use it (but I really want)
> If you could give me some advice i will be very happy.
>
> Robert.
>
>
> -------------------------------------------------------
> Robert Pazur
> PhD student
> Institute of Geography
> Slovak Academy Of Sciences
>
> Mobile : +421 948 001 705
> Skype  : ruegdeg
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From pazurrobert at gmail.com  Thu Jun 24 15:18:53 2010
From: pazurrobert at gmail.com (Robert Pazur)
Date: Thu, 24 Jun 2010 14:18:53 +0100
Subject: [R-sig-Geo] sp.correlogram
In-Reply-To: <alpine.LRH.2.00.1006241414400.15824@reclus.nhh.no>
References: <AANLkTikKZg6Ta7PZf_HtiCPKC5r-P6WgSh73kZESoe5M@mail.gmail.com> 
	<AANLkTinkqXnYOc3IXpMk_Ng5AY4_topc6I_4y8W3nYsv@mail.gmail.com> 
	<alpine.LRH.2.00.1006241414400.15824@reclus.nhh.no>
Message-ID: <AANLkTik6XXescBfUQtRkevCJD8M74B8pVkhKqiS0mswW@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100624/d285680d/attachment.pl>

From mazatlanmexico at yahoo.com  Thu Jun 24 16:38:10 2010
From: mazatlanmexico at yahoo.com (Felipe Carrillo)
Date: Thu, 24 Jun 2010 07:38:10 -0700 (PDT)
Subject: [R-sig-Geo] Predict and plot spatial data with ggplot
Message-ID: <227281.42040.qm@web56602.mail.re3.yahoo.com>

Thanks Roger for letting me know about this list.

The shapefile data can be downloaded from the link below:
download all the six files and save them on your working directory
and make sure the dsn path is set to where the files are saved.
My shapefiles are saved on C:/Data.


https://secure.filesanywhere.com/fs/v.aspx?v=897263875a6472a99baa

Hi:
I am practicing with the attached shapefile and was wondering if I can?
get some help. Haven't used 'rgdal' and 'maptools' much but it appears to be 
a great way to bring map data into R.
Please take a look at the comments and let me know if I need to
explain better what I am trying to accomplish.

library(rgdal)
library(maptools)
library(ggplot2)
dsn="C:/Data"
wolves.map <- readOGR(dsn=dsn, layer="PNW_wolf_habitat_grid")
class(wolves.map)
dim(wolves.map)
head(wolves.map,1)
names(wolves.map)
gpclibPermit()
wolves.ds <- fortify(wolves.map)
head(wolves.ds);tail(wolves.ds)
# Shapefile of 5 states
wolves.plot <- ggplot(wolves.ds,aes(long,lat,group=group)) +
geom_polygon(colour='white',fill='lightblue')
wolves.plot
# How to show the state borders of Washington, Oregon, Idaho, Montana and Wyoming on map?

# Subset from wolves to create a logistic regression model based on WOLVES_99 and then apply to all the 5 states
# Remove the WOLVES_99 2(two value) and use "one" for presence and "zero" for absence to end up with 153 records.

wolfsub <- wolves.map[!wolves.map$WOLVES_99 %in% 2,];wolfsub
dim(wolfsub)
# 42 = Forest, 51 = Shrub, > 81 = Agriculture
wolfsub$Forest<-ifelse(wolfsub$MAJOR_LC==42,1,0)
wolfsub$Shrub<-ifelse(wolfsub$MAJOR_LC==51,1,0)
wolfsub$Agriculture<-ifelse(wolfsub$MAJOR_LC>81,1,0)
names(wolfsub);dim(wolfsub)

# Create the model
mod1<-glm(WOLVES_99~RD_DENSITY+Forest+Shrub+Agriculture,family=binomial,data=wolfsub)
summary(mod1)
wolfsub$pred99<-fitted(mod1)
names(wolfsub)
#fitted(mod1)
wolfsub$pred99

# Add the wolfsub data to the map
wolfsub <- fortify(wolfsub);names(wolfsub) 
area_mod <- wolves.plot + geom_polygon(data=wolfsub,aes(fill=????)) #Want to fill by WOLVES_99 but is gone #after fortify
area_mod
# Based on data from WOLVES_99 want to predict data for WOLVES_01.
#Not sure how to proceed from here to fit the 'mod1' model to all the 5 states and show the prediction on map.
#?I?am checking if predict()? would do it but so far no success.
# I wanted to use ggplot2 but spplot would be fine. Thanks

?
Felipe D. Carrillo
Supervisory Fishery Biologist
Department of the Interior
US Fish & Wildlife Service
California, USA





From eduardomarinho at gmail.com  Thu Jun 24 17:16:46 2010
From: eduardomarinho at gmail.com (Eduardo Marinho)
Date: Thu, 24 Jun 2010 17:16:46 +0200
Subject: [R-sig-Geo] Measurement errors and kriging
Message-ID: <AANLkTikeMWxTZayQcdNdCGqe4dIAtE4o2uH2Tp_ZsUK2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100624/42341b1b/attachment.pl>

From Roger.Bivand at nhh.no  Thu Jun 24 18:43:22 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 24 Jun 2010 18:43:22 +0200 (CEST)
Subject: [R-sig-Geo] Predict and plot spatial data with ggplot
In-Reply-To: <227281.42040.qm@web56602.mail.re3.yahoo.com>
References: <227281.42040.qm@web56602.mail.re3.yahoo.com>
Message-ID: <alpine.LRH.2.00.1006241838520.15824@reclus.nhh.no>

On Thu, 24 Jun 2010, Felipe Carrillo wrote:

> Thanks Roger for letting me know about this list.

Please re-formulate your question using data that ships with packages on 
CRAN. Trying things on data other than your own very often solves the 
problem - you get to look at the problem from a different perspective.

Please do not use ggplot until you have sorted out data handling. I for 
example have never used ggplot, so cannot answer questions involving its 
use (my bad of course, but life is tooo short...). Use sp plot and image 
methods until you are sure that you know that the data handling issues are 
resolved, simplifying as much as necessary does no harm.

Roger

>
> The shapefile data can be downloaded from the link below:
> download all the six files and save them on your working directory
> and make sure the dsn path is set to where the files are saved.
> My shapefiles are saved on C:/Data.
>
>
> https://secure.filesanywhere.com/fs/v.aspx?v=897263875a6472a99baa
>
> Hi:
> I am practicing with the attached shapefile and was wondering if I can?
> get some help. Haven't used 'rgdal' and 'maptools' much but it appears to be
> a great way to bring map data into R.
> Please take a look at the comments and let me know if I need to
> explain better what I am trying to accomplish.
>
> library(rgdal)
> library(maptools)
> library(ggplot2)
> dsn="C:/Data"
> wolves.map <- readOGR(dsn=dsn, layer="PNW_wolf_habitat_grid")
> class(wolves.map)
> dim(wolves.map)
> head(wolves.map,1)
> names(wolves.map)
> gpclibPermit()
> wolves.ds <- fortify(wolves.map)
> head(wolves.ds);tail(wolves.ds)
> # Shapefile of 5 states
> wolves.plot <- ggplot(wolves.ds,aes(long,lat,group=group)) +
> geom_polygon(colour='white',fill='lightblue')
> wolves.plot
> # How to show the state borders of Washington, Oregon, Idaho, Montana and Wyoming on map?
>
> # Subset from wolves to create a logistic regression model based on WOLVES_99 and then apply to all the 5 states
> # Remove the WOLVES_99 2(two value) and use "one" for presence and "zero" for absence to end up with 153 records.
>
> wolfsub <- wolves.map[!wolves.map$WOLVES_99 %in% 2,];wolfsub
> dim(wolfsub)
> # 42 = Forest, 51 = Shrub, > 81 = Agriculture
> wolfsub$Forest<-ifelse(wolfsub$MAJOR_LC==42,1,0)
> wolfsub$Shrub<-ifelse(wolfsub$MAJOR_LC==51,1,0)
> wolfsub$Agriculture<-ifelse(wolfsub$MAJOR_LC>81,1,0)
> names(wolfsub);dim(wolfsub)
>
> # Create the model
> mod1<-glm(WOLVES_99~RD_DENSITY+Forest+Shrub+Agriculture,family=binomial,data=wolfsub)
> summary(mod1)
> wolfsub$pred99<-fitted(mod1)
> names(wolfsub)
> #fitted(mod1)
> wolfsub$pred99
>
> # Add the wolfsub data to the map
> wolfsub <- fortify(wolfsub);names(wolfsub)
> area_mod <- wolves.plot + geom_polygon(data=wolfsub,aes(fill=????)) #Want to fill by WOLVES_99 but is gone #after fortify
> area_mod
> # Based on data from WOLVES_99 want to predict data for WOLVES_01.
> #Not sure how to proceed from here to fit the 'mod1' model to all the 5 states and show the prediction on map.
> #?I?am checking if predict()? would do it but so far no success.
> # I wanted to use ggplot2 but spplot would be fine. Thanks
>
> ?
> Felipe D. Carrillo
> Supervisory Fishery Biologist
> Department of the Interior
> US Fish & Wildlife Service
> California, USA
>
>
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From katakagi at bu.edu  Thu Jun 24 20:15:45 2010
From: katakagi at bu.edu (Kenneth Takagi)
Date: Thu, 24 Jun 2010 14:15:45 -0400
Subject: [R-sig-Geo] Question on ssplot key
In-Reply-To: <AANLkTikeMWxTZayQcdNdCGqe4dIAtE4o2uH2Tp_ZsUK2@mail.gmail.com>
References: <AANLkTikeMWxTZayQcdNdCGqe4dIAtE4o2uH2Tp_ZsUK2@mail.gmail.com>
Message-ID: <4C23A0D1.1070400@bu.edu>

Hi All,

I have a question about producing keys in ssplot().  I've included 
reproducible code below. Here goes:

I'd like to produce a key in ssplot that has both rectangles, points and 
lines.  Unfortunately, when you include all of these symbols in one key, 
the produce a "staggered" look with rectangles on the far left and lines 
closest to the labels (run script below to see what I am talking about).

Questions:
1. How can you have them all line up in a single column?
I tried using negative values for "size" of rectangles, but that begins 
to change the size of the grey background box.

2.  key.space does not seem to change anything when used inside the 
update function. Any suggestions on how to move the key?

Thanks!
-Ken

# Reproducible Script:
library(sp)
library(lattice) # required for trellis.par.set():
trellis.par.set(sp.theme()) # sets color ramp to bpy.colors()

data(meuse)
coordinates(meuse)=~x+y
data(meuse.riv)
meuse.sr = 
SpatialPolygons(list(Polygons(list(Polygon(meuse.riv)),"meuse.riv")))

# Create spplot
plot1 = spplot(meuse, "zinc", auto.key=F, panel = function(x, y, ...) {
		sp.polygons(meuse.sr, fill = "lightblue")
		panel.pointsplot(x, y, auto.key = F, ...)
	},
	main = "Top soil zinc concentration (ppm)"
	)
#Update spplot
plot.update <- update(plot1,
key = list(rep = F,  between.row = 0.75, between = 0.8, background="grey90",
key.space = list(x = 0.1, y = 0.93, corner = c(1,0)),
rectangle = list(col = c(rep(NA, 3), rep("magenta", 4)),
                  border = c(rep(NA, 3),rep("black", 4)),
                  size = 1.8, lwd = 7),
points = list(pch = c(NA, seq(1, 2,1), rep(NA, 4)),
               col = c(NA, rep("black", 2), rep(NA, 4))),
lines = list(type = "l", size = 2, lwd = 2, lty = 1),
text = list(rep("Some Variable", 7))
))
#Print spplot
print(plot.update)


From elaine.kuo.tw at gmail.com  Fri Jun 25 00:33:51 2010
From: elaine.kuo.tw at gmail.com (elaine kuo)
Date: Fri, 25 Jun 2010 06:33:51 +0800
Subject: [R-sig-Geo] errorsarlm out of memory
Message-ID: <AANLkTinBnOM9IUpuJ4kuPtZ4YMbuRGXjzTlw-vRq22dL@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100625/9126ddda/attachment.pl>

From felix at nfrac.org  Fri Jun 25 01:47:36 2010
From: felix at nfrac.org (Felix Andrews)
Date: Fri, 25 Jun 2010 09:47:36 +1000
Subject: [R-sig-Geo] Question on ssplot key
In-Reply-To: <4C23A0D1.1070400@bu.edu>
References: <AANLkTikeMWxTZayQcdNdCGqe4dIAtE4o2uH2Tp_ZsUK2@mail.gmail.com> 
	<4C23A0D1.1070400@bu.edu>
Message-ID: <AANLkTinTElRO1T1AydwbEpICNJz9aXNgZDnU4T4ujG2z@mail.gmail.com>

On 25 June 2010 04:15, Kenneth Takagi <katakagi at bu.edu> wrote:
> Hi All,
>
> I have a question about producing keys in ssplot(). ?I've included
> reproducible code below. Here goes:
>
> I'd like to produce a key in ssplot that has both rectangles, points and
> lines. ?Unfortunately, when you include all of these symbols in one key, the
> produce a "staggered" look with rectangles on the far left and lines closest
> to the labels (run script below to see what I am talking about).
>
> Questions:
> 1. How can you have them all line up in a single column?
> I tried using negative values for "size" of rectangles, but that begins to
> change the size of the grey background box.
>
> 2. ?key.space does not seem to change anything when used inside the update
> function. Any suggestions on how to move the key?



update(plot1, key = list(
  background = "grey90",
  lines = list(type = c("l", rep("p", 6)),
      pch = c(NA, 1:2, rep(22, 4)),   ## 22 is filled square
      fill = c(rep(NA, 3), rep("magenta", 4)),
      border = "black"),
  text = list(rep("Some Variable", 7)),
  x = 0.1, y = 0.93, corner = c(1,0)
))


>
> Thanks!
> -Ken
>
> # Reproducible Script:
> library(sp)
> library(lattice) # required for trellis.par.set():
> trellis.par.set(sp.theme()) # sets color ramp to bpy.colors()
>
> data(meuse)
> coordinates(meuse)=~x+y
> data(meuse.riv)
> meuse.sr =
> SpatialPolygons(list(Polygons(list(Polygon(meuse.riv)),"meuse.riv")))
>
> # Create spplot
> plot1 = spplot(meuse, "zinc", auto.key=F, panel = function(x, y, ...) {
> ? ? ? ? ? ? ? ?sp.polygons(meuse.sr, fill = "lightblue")
> ? ? ? ? ? ? ? ?panel.pointsplot(x, y, auto.key = F, ...)
> ? ? ? ?},
> ? ? ? ?main = "Top soil zinc concentration (ppm)"
> ? ? ? ?)
> #Update spplot
> plot.update <- update(plot1,
> key = list(rep = F, ?between.row = 0.75, between = 0.8, background="grey90",
> key.space = list(x = 0.1, y = 0.93, corner = c(1,0)),
> rectangle = list(col = c(rep(NA, 3), rep("magenta", 4)),
> ? ? ? ? ? ? ? ? border = c(rep(NA, 3),rep("black", 4)),
> ? ? ? ? ? ? ? ? size = 1.8, lwd = 7),
> points = list(pch = c(NA, seq(1, 2,1), rep(NA, 4)),
> ? ? ? ? ? ? ?col = c(NA, rep("black", 2), rep(NA, 4))),
> lines = list(type = "l", size = 2, lwd = 2, lty = 1),
> text = list(rep("Some Variable", 7))
> ))
> #Print spplot
> print(plot.update)
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Felix Andrews / ???
Integrated Catchment Assessment and Management (iCAM) Centre
Fenner School of Environment and Society [Bldg 48a]
The Australian National University
Canberra ACT 0200 Australia
M: +61 410 400 963
T: + 61 2 6125 4670
E: felix.andrews at anu.edu.au
CRICOS Provider No. 00120C
-- 
http://www.neurofractal.org/felix/


From Roger.Bivand at nhh.no  Fri Jun 25 12:10:07 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 25 Jun 2010 12:10:07 +0200 (CEST)
Subject: [R-sig-Geo] errorsarlm out of memory
In-Reply-To: <AANLkTinBnOM9IUpuJ4kuPtZ4YMbuRGXjzTlw-vRq22dL@mail.gmail.com>
References: <AANLkTinBnOM9IUpuJ4kuPtZ4YMbuRGXjzTlw-vRq22dL@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1006251156510.20268@reclus.nhh.no>

On Fri, 25 Jun 2010, elaine kuo wrote:

> Dear List,
>
> I am using errorsarlm (spdep) to measure SAR autocorrelation but failed as
> detailed below.
>
> system: windows XP and Vista
> RAM : 2G (XP) and 4G(Vista)
>
> sample size : 4500
> variable: 4
> nb10<-dnearneigh(coords,0,9)
>
> the error issue: out of memory of 180 Mb
>
> The similar messages in the archive were checked and tried but failed to
> solve the issues.
> 1. enlarging the R space to 2047 Mb
> 2. updating the neighboring unit from 0.5 to 9
>
> Please kindly help how to solve the problem, for I found SAR and CAR seem to
> be more reliable for autocorrelation than autocovariate.


No, you have not included the verbatim code leading to the memory problem, 
nor the output of traceback() after the error, nor the output of 
sessionInfo() to tell us which versions of packages you are using. This is 
almost certainly nothing to do with dnearneigh(), unless the (0, 9) 
thresholds include all n observations as neighbours for each neighbour, 
and even then the neighbour object would not be very large.

Did you read the help page for errorsarlm() or spautolm()? No? Then do so 
and look carefully at the method= argument. You are almost certainly using 
the default method, which uses dense matrices. Use your choice of sparse 
or approximation alternatives, for example "Matrix" for updating sparse 
Cholesky Jacobians, or "Chebyshev" for a fast approximate Jacobians.

Using sparse matrix methods to overcome memory constraints has been 
mentioned on this and other lists many times. With n=25000 ther is no 
problem on a 1GB machine, so your problem doesn't even count as large.

The list isn't really an alternative for reading help pages, and crucially 
accessing the references given on the help pages. I'll add a link to 
?do_ldet on the function fitting pages, and add LeSage J and RK Pace 
(2009) Introduction to Spatial Econometrics. CRC Press, Boca Raton too, as 
this is the key reference that is required reading in this area.

Hope this helps,

Roger


>
> Thanks
>
> Elaine
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From k.lamb at sphsu.mrc.ac.uk  Fri Jun 25 18:09:39 2010
From: k.lamb at sphsu.mrc.ac.uk (Karen Lamb)
Date: Fri, 25 Jun 2010 17:09:39 +0100
Subject: [R-sig-Geo] Spatial models or multilevel models
Message-ID: <54E52DC0A0824441A6BD49FF7F804EBD@ibmroompc>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100625/dd27c45d/attachment.pl>

From mark_connolly at acm.org  Fri Jun 25 18:40:19 2010
From: mark_connolly at acm.org (Mark Connolly)
Date: Fri, 25 Jun 2010 12:40:19 -0400
Subject: [R-sig-Geo] HDF-EOS Level 2B point model and rgdal/gdal
Message-ID: <4C24DBF3.1070505@acm.org>

I am trying to load point data into R, but am having no luck.  Does 
rgdal support these data sets?

Thanks,

Mark Connolly
Master of Science Program
Department of Soil Science
North Carolina State University
PO Box 7619
Raleigh, North Carolina 27695-7619


From mark_connolly at acm.org  Fri Jun 25 19:20:29 2010
From: mark_connolly at acm.org (Mark Connolly)
Date: Fri, 25 Jun 2010 13:20:29 -0400
Subject: [R-sig-Geo] HDF-EOS Level 2B point model and rgdal/gdal
In-Reply-To: <4C24DCAF.2070601@nceas.ucsb.edu>
References: <4C24DBF3.1070505@acm.org> <4C24DCAF.2070601@nceas.ucsb.edu>
Message-ID: <4C24E55D.20703@acm.org>

I may not have asked that question very well.  The HDF-EOS Level 2b is 
an hdf4 file that contains point data and has a structure that is quite 
different from the Level 3 (which I have been able to bring in as a 
raster after using HEG to pull a specific object from the file).

If anyone else has the same need, the contents can be pulled out of the 
point file using the hdp hdf dumper from the HDF Group 
(http://www.hdfgroup.org/hdp.html).

In my case, I wanted a subset of the fields from a specific vdata node 
in the hdf structure.  The command line I ended up with was

hdp dumpvd -o AMSR_E_L2_Land_V09_200206190754_A.txt -d -i 1 -f 
Latitude,Longitude,Soil_Moisture AMSR_E_L2_Land_V09_200206190754_A.hdf

-o ... = output file name
-d = no headers
-i 1 = the index of the vdata
-f ... = the field names

The produced a file that can be read as a table in R.

http://hdfeos.org/software/tool.php#HEG
is appropriate for Level 3 HDF to GeoTIFF

http://www.hdfgroup.org/hdf-java-html/hdfview/
is good for exploring the file structure of many hdf forms


Maybe this will be useful for someone.

Mark



On 06/25/2010 12:43 PM, rick reeves wrote:
> Mark, have a look at:
>
> http://www.nceas.ucsb.edu/scicomp/usecases/ReadWriteESRIShapeFiles
>
> hope this helps,
> Rick Reeves
>
> On 6/25/2010 9:40 AM, Mark Connolly wrote:
>> I am trying to load point data into R, but am having no luck.  Does 
>> rgdal support these data sets?
>>
>> Thanks,
>>
>> Mark Connolly
>> Master of Science Program
>> Department of Soil Science
>> North Carolina State University
>> PO Box 7619
>> Raleigh, North Carolina 27695-7619
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From Steve_Friedman at nps.gov  Fri Jun 25 19:54:16 2010
From: Steve_Friedman at nps.gov (Steve_Friedman at nps.gov)
Date: Fri, 25 Jun 2010 13:54:16 -0400
Subject: [R-sig-Geo] variograms and kriging
Message-ID: <OFD03B1CD9.05F1A412-ON8525774D.00623884-8525774D.00625A30@nps.gov>


Hello

Trying to develop variograms and kriged surfaces from a point file. Here is
what I've done so far.


library(gstat)  # also loads library(sp)
library(lattice)

 soilpts$x <- soilpts$UTM_X
 soilpts$y <- soilpts$UTM_Y
 soil.dat <- subset(soilpts, select=c(x, y, Area, BulkDensity, LOI, TP, TN,
TC, Total_Mg))

dim(soil.dat)
[1] 1292    7

 coordinates(soil.dat) <- ~ x+y

 gridded(soil.dat) <- TRUE

Warning messages:
1: In points2grid(points, tolerance, round, fuzz.tol) :
  grid has empty column/rows in dimension 1
2: In points2grid(points, tolerance, round, fuzz.tol) :
  grid has empty column/rows in dimension 2

 class(soil.dat)
[1] "SpatialPixelsDataFrame"
attr(,"package")
[1] "sp"
> bbox(soil.dat)
      min     max
x  476819  575981
y 2785749 2948128

> soil.dat[1:3,]

suggested tolerance minimum: 0.165318957771788
Error in points2grid(points, tolerance, round, fuzz.tol) :
  dimension 1 : coordinate intervals are not constant


The last error message and the warning returned above,  leads me to think
that the spatial sampling locations must be regular equally spaced.  My
data thou is not

I have spent the morning trying to figure this out - going back and forth
among many spatial packages that can do variograms and krigging.  Without a
good road map to follow however, I've had to a number of about faces.  Not
sure which way to turn now.

Can anyone provide guidance?

Using Windows WP and R 2.11.1 packages updated today.

Thanks
Steve


Steve Friedman Ph. D.
Spatial Statistical Analyst
Everglades and Dry Tortugas National Park
950 N Krome Ave (3rd Floor)
Homestead, Florida 33034

Steve_Friedman at nps.gov
Office (305) 224 - 4282
Fax     (305) 224 - 4147


From johan.vandewauw at gmail.com  Fri Jun 25 20:33:28 2010
From: johan.vandewauw at gmail.com (Johan Van de Wauw)
Date: Fri, 25 Jun 2010 20:33:28 +0200
Subject: [R-sig-Geo] variograms and kriging
In-Reply-To: <OFD03B1CD9.05F1A412-ON8525774D.00623884-8525774D.00625A30@nps.gov>
References: <OFD03B1CD9.05F1A412-ON8525774D.00623884-8525774D.00625A30@nps.gov>
Message-ID: <AANLkTinJG0ZI05WjEFXu3Ijil6NgF0dDU_bhMu8oi4e2@mail.gmail.com>

On Fri, Jun 25, 2010 at 7:54 PM,  <Steve_Friedman at nps.gov> wrote:

> ?gridded(soil.dat) <- TRUE

No need (and no use) to run this line if your data is not on a rectangular grid

>
> The last error message and the warning returned above, ?leads me to think
> that the spatial sampling locations must be regular equally spaced. ?My
> data thou is not


From julien.beguin.1 at ulaval.ca  Fri Jun 25 20:52:33 2010
From: julien.beguin.1 at ulaval.ca (Julien Beguin)
Date: Fri, 25 Jun 2010 14:52:33 -0400
Subject: [R-sig-Geo] question about autocov_dist function in "spdep" package
Message-ID: <B56D7C27B4408243B93FBC46ABECB5A0011A8CFBC7C7@EXCH-MBX-F.ulaval.ca>

Dear list member,

I am using the autocov_dist function in spdep on binary point data set to estimate the autocovariate to be used in autologistic regression (session info at the end):

coords<-as.matrix(cbind(datafile$X_COORD, datafile$Y_COORD))
ac1 <- autocov_dist(datafile$binary_variable, coords, nbs=400, type = "inverse", zero.policy=TRUE) 

It works fine with large value of nbs. When nbs value is below the neibhorhood distance of some pairs of point I get warnings because of empty neighbors:

>Warning messages:
>1: In autocov_dist(datafile$binary_variable, coords, nbs = 400, type = "inverse",  :
> With value 400 some points have no neighbours
>2: In nb2listw(nb, glist = gl, style = style, zero.policy = zero.policy) :
> zero sum general weights

It seems, but I might be wrong, that points with no neighbour have an autocov_dist value of zero. Since it is what I want, it is ok for me. But if I decrease nbs value below the smallest neighbourhood distance among pairs of points in my data set, I get an error message: 

>Error in nb2listw(nb, glist = gl, style = style, zero.policy = zero.policy) : 
>  No valid observations
>In addition: Warning messages:
>1: In autocov_dist(datafile$binary_variable, coords, nbs = 100, type = "inverse",  :
> With value 100 some points have no neighbours
>2: In nb2listw(nb, glist = gl, style = style, zero.policy = zero.policy) :
>  zero sum general weights
  
My question is as follows: why do autocov_dist function require that at least one neighbor pair exists? and why not returning zero value for all points when no any point has a neighbor? 

This might appear to be a strange question but in my case I estimating autocov_dist for different spatial block in which the minimum distance between points vary from block to block, but still I would like a commun nbs value for all block.

Thank you for your help,

Julien Beguin
--------------------
Ph.D. student
Laval University
Qu?bec, Canada

SESSION INFO:  

R version 2.10.1 (2009-12-14) 
i386-pc-mingw32 
locale:
[1] LC_COLLATE=French_Canada.1252  LC_CTYPE=French_Canada.1252   
[3] LC_MONETARY=French_Canada.1252 LC_NUMERIC=C                  
[5] LC_TIME=French_Canada.1252    
attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     
other attached packages:
 [1] spdep_0.5-4         spam_0.20-3         coda_0.13-4        
 [4] deldir_0.0-12       maptools_0.7-29     foreign_0.8-40     
 [7] nlme_3.1-96         MASS_7.3-4          Matrix_0.999375-33 
[10] lattice_0.17-26     boot_1.2-41         sp_0.9-60          
[13] compositions_1.01-1 robustbase_0.5-0-1  tensorA_0.31       
[16] rgl_0.91           
loaded via a namespace (and not attached):
[1] grid_2.10.1  tools_2.10.1

From Roger.Bivand at nhh.no  Fri Jun 25 21:55:14 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 25 Jun 2010 21:55:14 +0200 (CEST)
Subject: [R-sig-Geo] question about autocov_dist function in "spdep"
 package
In-Reply-To: <B56D7C27B4408243B93FBC46ABECB5A0011A8CFBC7C7@EXCH-MBX-F.ulaval.ca>
References: <B56D7C27B4408243B93FBC46ABECB5A0011A8CFBC7C7@EXCH-MBX-F.ulaval.ca>
Message-ID: <alpine.LRH.2.00.1006252148310.21394@reclus.nhh.no>

On Fri, 25 Jun 2010, Julien Beguin wrote:

> Dear list member,
>
> I am using the autocov_dist function in spdep on binary point data set 
> to estimate the autocovariate to be used in autologistic regression 
> (session info at the end):
>
> coords<-as.matrix(cbind(datafile$X_COORD, datafile$Y_COORD))
> ac1 <- autocov_dist(datafile$binary_variable, coords, nbs=400, type = "inverse", zero.policy=TRUE)
>
> It works fine with large value of nbs. When nbs value is below the neibhorhood distance of some pairs of point I get warnings because of empty neighbors:
>
>> Warning messages: 1: In autocov_dist(datafile$binary_variable, coords, 
>> nbs = 400, type = "inverse", :

>> With value 400 some points have no neighbours
>> 2: In nb2listw(nb, glist = gl, style = style, zero.policy = zero.policy) :
>> zero sum general weights
>
> It seems, but I might be wrong, that points with no neighbour have an 
> autocov_dist value of zero. Since it is what I want, it is ok for me.

No, the general weights sum to zero, as it says, you are using inverse.

> But if I decrease nbs value below the smallest neighbourhood distance 
> among pairs of points in my data set, I get an error message:
>
>> Error in nb2listw(nb, glist = gl, style = style, zero.policy = zero.policy) :
>>  No valid observations
>> In addition: Warning messages:
>> 1: In autocov_dist(datafile$binary_variable, coords, nbs = 100, type = "inverse",  :
>> With value 100 some points have no neighbours
>> 2: In nb2listw(nb, glist = gl, style = style, zero.policy = zero.policy) :
>>  zero sum general weights
>
> My question is as follows: why do autocov_dist function require that at 
> least one neighbor pair exists? and why not returning zero value for all 
> points when no any point has a neighbor?
>
> This might appear to be a strange question but in my case I estimating 
> autocov_dist for different spatial block in which the minimum distance 
> between points vary from block to block, but still I would like a commun 
> nbs value for all block.

It does indeed seem very strange, as you are asking to include a constant 
vector of zeros, which will alias the constant. The function itself is a 
really bad idea, and is included only to show (see Dormann et al 2007) 
that using it is inferior to all other methods examined there. Trying to 
include a second zero constant doesn't seem well-founded, to put it 
mildly.

Hope this helps,

Roger

>
> Thank you for your help,
>
> Julien Beguin
> --------------------
> Ph.D. student
> Laval University
> Qu?bec, Canada
>
> SESSION INFO:
>
> R version 2.10.1 (2009-12-14)
> i386-pc-mingw32
> locale:
> [1] LC_COLLATE=French_Canada.1252  LC_CTYPE=French_Canada.1252
> [3] LC_MONETARY=French_Canada.1252 LC_NUMERIC=C
> [5] LC_TIME=French_Canada.1252
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> other attached packages:
> [1] spdep_0.5-4         spam_0.20-3         coda_0.13-4
> [4] deldir_0.0-12       maptools_0.7-29     foreign_0.8-40
> [7] nlme_3.1-96         MASS_7.3-4          Matrix_0.999375-33
> [10] lattice_0.17-26     boot_1.2-41         sp_0.9-60
> [13] compositions_1.01-1 robustbase_0.5-0-1  tensorA_0.31
> [16] rgl_0.91
> loaded via a namespace (and not attached):
> [1] grid_2.10.1  tools_2.10.1
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From yuwm at hotmail.com  Sat Jun 26 00:02:31 2010
From: yuwm at hotmail.com (andrew.yu)
Date: Fri, 25 Jun 2010 15:02:31 -0700 (PDT)
Subject: [R-sig-Geo] maptools and rgeos
In-Reply-To: <4BE2AD23.7020409@uni-muenster.de>
References: <A1F9CA77-4AAB-4886-8379-4CB57A0D68A1@remoteinformation.com.au>
	<alpine.LRH.2.00.1005060950300.21837@reclus.nhh.no>
	<E827D730-53DD-4D2D-815F-044C9B64ED3C@remoteinformation.com.au>
	<4BE2AD23.7020409@uni-muenster.de>
Message-ID: <1277503351945-5223899.post@n2.nabble.com>


I try to install the Rgeos. However, it gives me the following:

> utils:::menuInstallLocal()
Error in gzfile(file, "r") : cannot open the connection
In addition: Warning messages:
1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
2: In gzfile(file, "r") :
  cannot open compressed file 'rgeos_0.0-10.tar.gz/DESCRIPTION', probable
reason 'No such file or directory'


Could anybody help me?
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/maptools-and-rgeos-tp5013007p5223899.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From elaine.kuo.tw at gmail.com  Sat Jun 26 02:20:04 2010
From: elaine.kuo.tw at gmail.com (elaine kuo)
Date: Sat, 26 Jun 2010 08:20:04 +0800
Subject: [R-sig-Geo] errorsarlm out of memory
In-Reply-To: <alpine.LRH.2.00.1006251156510.20268@reclus.nhh.no>
References: <AANLkTinBnOM9IUpuJ4kuPtZ4YMbuRGXjzTlw-vRq22dL@mail.gmail.com>
	<alpine.LRH.2.00.1006251156510.20268@reclus.nhh.no>
Message-ID: <AANLkTilHTEIqjn1mJ693jBs6YnHsLZHKZcvAdsh2u6Zp@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100626/776b6733/attachment.pl>

From elaine.kuo.tw at gmail.com  Sat Jun 26 02:22:59 2010
From: elaine.kuo.tw at gmail.com (elaine kuo)
Date: Sat, 26 Jun 2010 08:22:59 +0800
Subject: [R-sig-Geo] errorsarlm out of memory (method Chebyshev undetected
	in help)
Message-ID: <AANLkTimW69kh5QWF0I-28p0tlKPEJ6y-IKTwtYZg5d_1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100626/81689f9e/attachment.pl>

From mazatlanmexico at yahoo.com  Mon Jun 28 03:33:03 2010
From: mazatlanmexico at yahoo.com (Felipe Carrillo)
Date: Sun, 27 Jun 2010 18:33:03 -0700 (PDT)
Subject: [R-sig-Geo] How to add borders to a shapefile
Message-ID: <392460.67593.qm@web56607.mail.re3.yahoo.com>

Hi:
Could someone show me how to add state borders to a shapefile.
Please follow the bellow link to download it.Thanks

https://secure.filesanywhere.com/fs/v.aspx?v=897263875a6472a99baa

library(rgdal)
library(maptools)
dsn="C:/pathtoshapefile"
wolves.map <- readOGR(dsn=dsn, layer="PNW_wolf_habitat_grid")
cols<-heat.colors(16);cols
spplot(wolves.map, "PRED_SUIT", names.attr = "PRED_SUIT", col.regions=rev(cols),
??? colorkey=list(space="bottom"), main = "Wolf Presence", as.table = TRUE)

?
Felipe D. Carrillo
Supervisory Fishery Biologist
Department of the Interior
US Fish & Wildlife Service
California, USA





From lists at remoteinformation.com.au  Mon Jun 28 03:43:15 2010
From: lists at remoteinformation.com.au (Ben Madin)
Date: Mon, 28 Jun 2010 09:43:15 +0800
Subject: [R-sig-Geo] maptools and rgeos
In-Reply-To: <19355950.6843.1277492418200.JavaMail.root@jim.nabble.com>
References: <19355950.6843.1277492418200.JavaMail.root@jim.nabble.com>
Message-ID: <FDF35DC2-BC70-4CAD-B3B5-2575939EC1F1@remoteinformation.com.au>

I confess I'm not even familiar with the command you have shown below?

This package is still in early development, and you would need to provide a little more information about the environment you are trying to install in (sessionInfo() would be a good start). Your name might also help.

Also, I'm not one of the developers, so you are going to be better posting to the list. I don't currently have it installed on my current version of R (now 2.11).

Good luck

Ben


On 26/06/2010, at 3:00 , yuwm at hotmail.com wrote:

> I am trying to install the package Rgeos after?????????????????????????????r-forge. However, it gives me the following information. Could you help me?
> 
>> utils:::menuInstallLocal()
> Error in gzfile(file, "r") : cannot open the connection
> In addition: Warning messages:
> 1: In unzip(zipname, exdir = dest) : error 1 in extracting from zip file
> 2: In gzfile(file, "r") :
>  cannot open compressed file 'rgeos_0.0-10.tar.gz/DESCRIPTION', probable reason 'No such file or directory'
> 
> 
> 
> 
> 
> <quote author='Ben Madin'>
> G'day all,
> 
> Please excuse my not finding this, but having just upgraded maptools, there
> appears to be some issue over gpclib - not looking for trouble, I installed
> rgeos from r-forge, and it seems to be loadable, but loading maptools I
> still get the following message.
> 
>> library(rgeos)
> Loading required package: sp
> GEOS runtime version: 3.2.0-CAPI-1.6.0 
>> library(maptools)
> Loading required package: foreign
> Loading required package: lattice
> 
> 	Note: polygon geometry computations in maptools
> 	depend on the package gpclib, which has a
> 	restricted licence. It is disabled by default;
> 	to enable gpclib, type gpclibPermit()
> 
> Checking rgeos availability as gpclib substitute:
> FALSE 
>> 
> 
> Have I missed something on installation?(I'm using William Kyngesbury's GEOS
> Frameworks)
> 
> cheers
> 
> Ben
> 
> 
> 
> sessionInfo()
> R version 2.10.1 Patched (2010-02-01 r51089) 
> x86_64-apple-darwin9.8.0 
> 
> locale:
> [1] en_AU.UTF-8/en_AU.UTF-8/C/C/en_AU.UTF-8/en_AU.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     
> 
> other attached packages:
> [1] maptools_0.7-34 lattice_0.18-3  foreign_0.8-40  rgeos_0.0-9    
> sp_0.9-62      
> 
> loaded via a namespace (and not attached):
> [1] grid_2.10.1  tools_2.10.1
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> </quote>
> Quoted from: 
> http://r-sig-geo.2731867.n2.nabble.com/maptools-and-rgeos-tp5013007p5013007.html


From mazatlanmexico at yahoo.com  Mon Jun 28 03:53:38 2010
From: mazatlanmexico at yahoo.com (Felipe Carrillo)
Date: Sun, 27 Jun 2010 18:53:38 -0700 (PDT)
Subject: [R-sig-Geo] states borders
Message-ID: <263206.36430.qm@web56608.mail.re3.yahoo.com>

Hi:
Could someone show me how to add state borders to a shapefile.
Please follow the bellow link to download it.Thanks

https://secure.filesanywhere.com/fs/v.aspx?v=897263875a6472a99baa

library(rgdal)
library(maptools)
dsn="C:/pathtoshapefile"
wolves.map <- readOGR(dsn=dsn, layer="PNW_wolf_habitat_grid")
cols<-heat.colors(16);cols
spplot(wolves.map, "PRED_SUIT", names.attr = "PRED_SUIT", col.regions=rev(cols),
??? colorkey=list(space="bottom"), main = "Wolf Presence", as.table = TRUE)

?
Felipe D. Carrillo
Supervisory Fishery Biologist
Department of the Interior
US Fish & Wildlife Service
California, USA





From mazatlanmexico at yahoo.com  Mon Jun 28 03:58:30 2010
From: mazatlanmexico at yahoo.com (Felipe Carrillo)
Date: Sun, 27 Jun 2010 18:58:30 -0700 (PDT)
Subject: [R-sig-Geo] borders
Message-ID: <80019.10351.qm@web56601.mail.re3.yahoo.com>

Hi:
Could someone show me how to add state borders to a shapefile.
Please follow the bellow link to download it.Thanks

https://secure.filesanywhere.com/fs/v.aspx?v=897263875a6472a99baa

library(rgdal)
library(maptools)
dsn="C:/pathtoshapefile"
wolves.map <- readOGR(dsn=dsn, layer="PNW_wolf_habitat_grid")
cols<-heat.colors(16);cols
spplot(wolves.map, "PRED_SUIT", names.attr = "PRED_SUIT", col.regions=rev(cols),
??? colorkey=list(space="bottom"), main = "Wolf Presence", as.table = TRUE)


?
Felipe D. Carrillo
Supervisory Fishery Biologist
Department of the Interior
US Fish & Wildlife Service
California, USA





From mazatlanmexico at yahoo.com  Mon Jun 28 04:01:17 2010
From: mazatlanmexico at yahoo.com (Felipe Carrillo)
Date: Sun, 27 Jun 2010 19:01:17 -0700 (PDT)
Subject: [R-sig-Geo] ??
Message-ID: <900938.8438.qm@web56601.mail.re3.yahoo.com>

Sorry, it keeps going to my spam folder so I'll skip the subject

Hi:
Could someone show me how to add state borders to a shapefile.
Please follow the bellow link to download it.Thanks

https://secure.filesanywhere.com/fs/v.aspx?v=897263875a6472a99baa

library(rgdal)
library(maptools)
dsn="C:/pathtoshapefile"
wolves.map <- readOGR(dsn=dsn, layer="PNW_wolf_habitat_grid")
cols<-heat.colors(16);cols
spplot(wolves.map, "PRED_SUIT", names.attr = "PRED_SUIT", col.regions=rev(cols),
??? colorkey=list(space="bottom"), main = "Wolf Presence", as.table = TRUE)

?
Felipe D. Carrillo
Supervisory Fishery Biologist
Department of the Interior
US Fish & Wildlife Service
California, USA





From mazatlanmexico at yahoo.com  Mon Jun 28 04:03:29 2010
From: mazatlanmexico at yahoo.com (Felipe Carrillo)
Date: Sun, 27 Jun 2010 19:03:29 -0700 (PDT)
Subject: [R-sig-Geo] (no subject)
Message-ID: <137405.68801.qm@web56602.mail.re3.yahoo.com>

Sorry, it keeps going to my spam folder so I skipped the subject

Hi:
Could someone show me how to add state borders to a shapefile.
Please follow the bellow link to download it.Thanks

https://secure.filesanywhere.com/fs/v.aspx?v=897263875a6472a99baa

library(rgdal)
library(maptools)
dsn="C:/pathtoshapefile"
wolves.map <- readOGR(dsn=dsn, layer="PNW_wolf_habitat_grid")
cols<-heat.colors(16);cols
spplot(wolves.map, "PRED_SUIT", names.attr = "PRED_SUIT", col.regions=rev(cols),
??? colorkey=list(space="bottom"), main = "Wolf Presence", as.table = TRUE)

?
Felipe D. Carrillo
Supervisory Fishery Biologist
Department of the Interior
US Fish & Wildlife Service
California, USA





From mazatlanmexico at yahoo.com  Mon Jun 28 04:22:46 2010
From: mazatlanmexico at yahoo.com (Felipe Carrillo)
Date: Sun, 27 Jun 2010 19:22:46 -0700 (PDT)
Subject: [R-sig-Geo] how to draw borders
Message-ID: <651886.53110.qm@web56608.mail.re3.yahoo.com>


Hi:
Could someone show me how to add state borders to a shapefile.
Please follow the bellow link to download it.Thanks

http://docs.google.com/leaf?id=0B9LuhHLxsabgNmUxM2VhZmQtNzNlNC00ZDhiLTg0MTQtODJhN2U5MWI3ZTdi&hl=en&authkey=CMeh644K
http://docs.google.com/leaf?id=0B9LuhHLxsabgZTJkNmY3NmYtZjI3NS00ZmZlLTljMWEtZTkzOWY5NWJiNzZm&hl=en&authkey=CNHh6vkL
http://docs.google.com/leaf?id=0B9LuhHLxsabgYjIxZTAxZGYtYTc1Zi00M2Y0LWI2NDMtNTQwMzc2ODZjZTlm&hl=en&authkey=CPGYi9gL
http://docs.google.com/leaf?id=0B9LuhHLxsabgMDgyMTBjMjMtOGZjZS00OGM1LTgzNDQtMGM3M2JlYWNhMzky&hl=en&authkey=COWjorMD
http://docs.google.com/leaf?id=0B9LuhHLxsabgN2E4YTllOTEtMjhmMC00ZjY5LWFmYWQtMmQ0YmRmMzJjYWM5&hl=en&authkey=COWkixM
http://docs.google.com/leaf?id=0B9LuhHLxsabgODVkMmJlNjctYTQxZi00MDA5LWIzMDEtZDc0YTY4YjExMjc2&hl=en&authkey=CIzq0_EH
?
library(rgdal)
library(maptools)
dsn="C:/pathtoshapefile"
wolves.map <- readOGR(dsn=dsn, layer="PNW_wolf_habitat_grid")
cols<-heat.colors(16);cols
spplot(wolves.map, "PRED_SUIT", names.attr = "PRED_SUIT", col.regions=rev(cols),
??? colorkey=list(space="bottom"), main = "Wolf Presence", as.table = TRUE)



Felipe D. Carrillo
Supervisory Fishery Biologist
Department of the Interior
US Fish & Wildlife Service
California, USA





From mazatlanmexico at yahoo.com  Mon Jun 28 04:26:14 2010
From: mazatlanmexico at yahoo.com (Felipe Carrillo)
Date: Sun, 27 Jun 2010 19:26:14 -0700 (PDT)
Subject: [R-sig-Geo] shapefile
Message-ID: <989730.78064.qm@web56605.mail.re3.yahoo.com>

Sorry, the subject is not very informative but after a few tries my email keeps going to the spam folder

Hi:
Could someone show me how to add state borders to a shapefile.
Please follow the bellow link to download it.Thanks

http://docs.google.com/leaf?id=0B9LuhHLxsabgNmUxM2VhZmQtNzNlNC00ZDhiLTg0MTQtODJhN2U5MWI3ZTdi&hl=en&authkey=CMeh644K
http://docs.google.com/leaf?id=0B9LuhHLxsabgZTJkNmY3NmYtZjI3NS00ZmZlLTljMWEtZTkzOWY5NWJiNzZm&hl=en&authkey=CNHh6vkL
http://docs.google.com/leaf?id=0B9LuhHLxsabgYjIxZTAxZGYtYTc1Zi00M2Y0LWI2NDMtNTQwMzc2ODZjZTlm&hl=en&authkey=CPGYi9gL
http://docs.google.com/leaf?id=0B9LuhHLxsabgMDgyMTBjMjMtOGZjZS00OGM1LTgzNDQtMGM3M2JlYWNhMzky&hl=en&authkey=COWjorMD
http://docs.google.com/leaf?id=0B9LuhHLxsabgN2E4YTllOTEtMjhmMC00ZjY5LWFmYWQtMmQ0YmRmMzJjYWM5&hl=en&authkey=COWkixM
http://docs.google.com/leaf?id=0B9LuhHLxsabgODVkMmJlNjctYTQxZi00MDA5LWIzMDEtZDc0YTY4YjExMjc2&hl=en&authkey=CIzq0_EH
?
library(rgdal)
library(maptools)
dsn="C:/pathtoshapefile"
wolves.map <- readOGR(dsn=dsn, layer="PNW_wolf_habitat_grid")
cols<-heat.colors(16);cols
spplot(wolves.map, "PRED_SUIT", names.attr = "PRED_SUIT", col.regions=rev(cols),
??? colorkey=list(space="bottom"), main = "Wolf Presence", as.table = TRUE)

?
Felipe D. Carrillo
Supervisory Fishery Biologist
Department of the Interior
US Fish & Wildlife Service
California, USA





From mazatlanmexico at yahoo.com  Mon Jun 28 04:28:12 2010
From: mazatlanmexico at yahoo.com (Felipe Carrillo)
Date: Sun, 27 Jun 2010 19:28:12 -0700 (PDT)
Subject: [R-sig-Geo] spatial data
Message-ID: <962477.2880.qm@web56603.mail.re3.yahoo.com>

Sorry, the subject is not very informative but after a few tries my email keeps going to the spam folder

Hi:
Could someone show me how to add state borders to a shapefile.
Please follow the bellow link to download it.Thanks

http://docs.google.com/leaf?id=0B9LuhHLxsabgNmUxM2VhZmQtNzNlNC00ZDhiLTg0MTQtODJhN2U5MWI3ZTdi&hl=en&authkey=CMeh644K
http://docs.google.com/leaf?id=0B9LuhHLxsabgZTJkNmY3NmYtZjI3NS00ZmZlLTljMWEtZTkzOWY5NWJiNzZm&hl=en&authkey=CNHh6vkL
http://docs.google.com/leaf?id=0B9LuhHLxsabgYjIxZTAxZGYtYTc1Zi00M2Y0LWI2NDMtNTQwMzc2ODZjZTlm&hl=en&authkey=CPGYi9gL
http://docs.google.com/leaf?id=0B9LuhHLxsabgMDgyMTBjMjMtOGZjZS00OGM1LTgzNDQtMGM3M2JlYWNhMzky&hl=en&authkey=COWjorMD
http://docs.google.com/leaf?id=0B9LuhHLxsabgN2E4YTllOTEtMjhmMC00ZjY5LWFmYWQtMmQ0YmRmMzJjYWM5&hl=en&authkey=COWkixM
http://docs.google.com/leaf?id=0B9LuhHLxsabgODVkMmJlNjctYTQxZi00MDA5LWIzMDEtZDc0YTY4YjExMjc2&hl=en&authkey=CIzq0_EH
?
library(rgdal)
library(maptools)
dsn="C:/pathtoshapefile"
wolves.map <- readOGR(dsn=dsn, layer="PNW_wolf_habitat_grid")
cols<-heat.colors(16);cols
spplot(wolves.map, "PRED_SUIT", names.attr = "PRED_SUIT", col.regions=rev(cols),
??? colorkey=list(space="bottom"), main = "Wolf Presence", as.table = TRUE)


?
Felipe D. Carrillo
Supervisory Fishery Biologist
Department of the Interior
US Fish & Wildlife Service
California, USA





From mdsumner at gmail.com  Mon Jun 28 04:34:26 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Mon, 28 Jun 2010 12:34:26 +1000
Subject: [R-sig-Geo] spatial data
In-Reply-To: <962477.2880.qm@web56603.mail.re3.yahoo.com>
References: <962477.2880.qm@web56603.mail.re3.yahoo.com>
Message-ID: <AANLkTikryv8J-mxb0FR1p09qpmO5AVb19PvxM29K9HL_@mail.gmail.com>

It is not (yet) going into my spam folder - that problem may only be
at your end. Check the archives to see if your message is getting
through to the list (it is).

https://stat.ethz.ch/pipermail/r-sig-geo/2010-June/thread.html

Cheers, Mike.

On Mon, Jun 28, 2010 at 12:28 PM, Felipe Carrillo
<mazatlanmexico at yahoo.com> wrote:
> Sorry, the subject is not very informative but after a few tries my email keeps going to the spam folder
>
> Hi:
> Could someone show me how to add state borders to a shapefile.
> Please follow the bellow link to download it.Thanks
>
> http://docs.google.com/leaf?id=0B9LuhHLxsabgNmUxM2VhZmQtNzNlNC00ZDhiLTg0MTQtODJhN2U5MWI3ZTdi&hl=en&authkey=CMeh644K
> http://docs.google.com/leaf?id=0B9LuhHLxsabgZTJkNmY3NmYtZjI3NS00ZmZlLTljMWEtZTkzOWY5NWJiNzZm&hl=en&authkey=CNHh6vkL
> http://docs.google.com/leaf?id=0B9LuhHLxsabgYjIxZTAxZGYtYTc1Zi00M2Y0LWI2NDMtNTQwMzc2ODZjZTlm&hl=en&authkey=CPGYi9gL
> http://docs.google.com/leaf?id=0B9LuhHLxsabgMDgyMTBjMjMtOGZjZS00OGM1LTgzNDQtMGM3M2JlYWNhMzky&hl=en&authkey=COWjorMD
> http://docs.google.com/leaf?id=0B9LuhHLxsabgN2E4YTllOTEtMjhmMC00ZjY5LWFmYWQtMmQ0YmRmMzJjYWM5&hl=en&authkey=COWkixM
> http://docs.google.com/leaf?id=0B9LuhHLxsabgODVkMmJlNjctYTQxZi00MDA5LWIzMDEtZDc0YTY4YjExMjc2&hl=en&authkey=CIzq0_EH
>
> library(rgdal)
> library(maptools)
> dsn="C:/pathtoshapefile"
> wolves.map <- readOGR(dsn=dsn, layer="PNW_wolf_habitat_grid")
> cols<-heat.colors(16);cols
> spplot(wolves.map, "PRED_SUIT", names.attr = "PRED_SUIT", col.regions=rev(cols),
> ??? colorkey=list(space="bottom"), main = "Wolf Presence", as.table = TRUE)
>
>
>
> Felipe D. Carrillo
> Supervisory Fishery Biologist
> Department of the Interior
> US Fish & Wildlife Service
> California, USA
>
>
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From p.hiemstra at geo.uu.nl  Mon Jun 28 09:51:54 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 28 Jun 2010 09:51:54 +0200
Subject: [R-sig-Geo] spatial data
In-Reply-To: <962477.2880.qm@web56603.mail.re3.yahoo.com>
References: <962477.2880.qm@web56603.mail.re3.yahoo.com>
Message-ID: <4C28549A.10402@geo.uu.nl>

Hi,

See:

http://rwiki.sciviews.org/doku.php?id=tips:spatial-data:spatial_data_visualization

For some tips.

cheers,
Paul

On 06/28/2010 04:28 AM, Felipe Carrillo wrote:
> Sorry, the subject is not very informative but after a few tries my email keeps going to the spam folder
>
> Hi:
> Could someone show me how to add state borders to a shapefile.
> Please follow the bellow link to download it.Thanks
>
> http://docs.google.com/leaf?id=0B9LuhHLxsabgNmUxM2VhZmQtNzNlNC00ZDhiLTg0MTQtODJhN2U5MWI3ZTdi&hl=en&authkey=CMeh644K
> http://docs.google.com/leaf?id=0B9LuhHLxsabgZTJkNmY3NmYtZjI3NS00ZmZlLTljMWEtZTkzOWY5NWJiNzZm&hl=en&authkey=CNHh6vkL
> http://docs.google.com/leaf?id=0B9LuhHLxsabgYjIxZTAxZGYtYTc1Zi00M2Y0LWI2NDMtNTQwMzc2ODZjZTlm&hl=en&authkey=CPGYi9gL
> http://docs.google.com/leaf?id=0B9LuhHLxsabgMDgyMTBjMjMtOGZjZS00OGM1LTgzNDQtMGM3M2JlYWNhMzky&hl=en&authkey=COWjorMD
> http://docs.google.com/leaf?id=0B9LuhHLxsabgN2E4YTllOTEtMjhmMC00ZjY5LWFmYWQtMmQ0YmRmMzJjYWM5&hl=en&authkey=COWkixM
> http://docs.google.com/leaf?id=0B9LuhHLxsabgODVkMmJlNjctYTQxZi00MDA5LWIzMDEtZDc0YTY4YjExMjc2&hl=en&authkey=CIzq0_EH
>   
> library(rgdal)
> library(maptools)
> dsn="C:/pathtoshapefile"
> wolves.map<- readOGR(dsn=dsn, layer="PNW_wolf_habitat_grid")
> cols<-heat.colors(16);cols
> spplot(wolves.map, "PRED_SUIT", names.attr = "PRED_SUIT", col.regions=rev(cols),
>      colorkey=list(space="bottom"), main = "Wolf Presence", as.table = TRUE)
>
>
>   
> Felipe D. Carrillo
> Supervisory Fishery Biologist
> Department of the Interior
> US Fish&  Wildlife Service
> California, USA
>
>
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>    


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 253 5773
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From pazurrobert at gmail.com  Mon Jun 28 12:25:09 2010
From: pazurrobert at gmail.com (Robert Pazur)
Date: Mon, 28 Jun 2010 11:25:09 +0100
Subject: [R-sig-Geo] sp.correlogram
In-Reply-To: <AANLkTik6XXescBfUQtRkevCJD8M74B8pVkhKqiS0mswW@mail.gmail.com>
References: <AANLkTikKZg6Ta7PZf_HtiCPKC5r-P6WgSh73kZESoe5M@mail.gmail.com> 
	<AANLkTinkqXnYOc3IXpMk_Ng5AY4_topc6I_4y8W3nYsv@mail.gmail.com> 
	<alpine.LRH.2.00.1006241414400.15824@reclus.nhh.no>
	<AANLkTik6XXescBfUQtRkevCJD8M74B8pVkhKqiS0mswW@mail.gmail.com>
Message-ID: <AANLkTinP7WIjBprfBBmwKup1jqnEH5A2xZdBcP3oRtlO@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100628/fa5295e4/attachment.pl>

From manguefleur at yahoo.fr  Mon Jun 28 13:00:42 2010
From: manguefleur at yahoo.fr (Lho Lho)
Date: Mon, 28 Jun 2010 11:00:42 +0000 (GMT)
Subject: [R-sig-Geo] Fw : glsm.krige in geoRglm
Message-ID: <781571.77390.qm@web29213.mail.ird.yahoo.com>

Dear Paulo Ribeiro,

Sorry to send you again my previous e-mail. I am keen to understand why I am not able to use krige.glsm() with my rectangular grid. 

I hope that I am not disturbing you
Best regards,

Hocine
PhD Student UCC
Cork, Ireland

--- En date de?: Mer 16.6.10, Lho Lho <manguefleur at yahoo.fr> a ?crit?:

> De: Lho Lho <manguefleur at yahoo.fr>
> Objet: glsm.krige in geoRglm
> ?: "Paulo J Ribeiro Jr" <paulojus at c3sl.ufpr.br>
> Date: Mercredi 16 juin 2010, 11h22
> Dear Paulo Ribeiro 
> 
> Concerning the function krige.glsm(), I copied and past the
> example code you have in geoRglm package for binomial data
> (b50). 
> 
> The following code (from the package) is:
> 
> test2 <- glsm.krige(outmcmc.5,
> locations=matrix(c(0.15,0.15,0.005,0.05),2,2)) 
> 
> My question is:
> 
> Why when I try to put a rectangular grid in the locations
> argument above (instead of your matrix) 
> 
> rectangleb50.grid<-pred_grid(b50$coords[,1:2], by=0.3)
> 
> test2 <- glsm.krige(outmcmc.5,
> locations=rectangleb50.grid)
> 
> I have these 50 warnings() from R:
> 
> "In asympvar(kpl.result$predict, messages = FALSE) :
> ? value of argument lag.max is not suffiently long"
> 
> Actually, I am working with counts data and I can perform
> glsm.krige only with locations=geodata$coords[,1:2].
> 
> If I try to put my rectangular.grid (which I built
> according to my data) in the locations argument I have the
> same warning messages.
> 
> My purpose is to display a image() using the glsm.krige
> output
> 
> Please, would you like to provide me an explanation?
> 
> Best regards
> 
> lho
> 
> 
> 
> 
> 
> 
> ? 
> 
> --- En date de?: Lun 24.5.10, Lho Lho <manguefleur at yahoo.fr>
> a ?crit?:
> 
> > De: Lho Lho <manguefleur at yahoo.fr>
> > Objet: Re: Help with proflik() 2
> > ?: "Paulo J Ribeiro Jr" <paulojus at c3sl.ufpr.br>
> > Date: Lundi 24 mai 2010, 17h18
> > Hi Paulo!
> > 
> > Thank you for your help? and sorry for the delay of
> my
> > answer I was away from my office.
> > 
> > It is still not working neither (*100) nor (*1000).
> > 
> > However, I tried in the likfit() function to choose
> > trend="1st" instead of trend= "2nd" and then, the
> proflik()
> > function worked.
> > 
> > I hope that the problem raised here is only due to
> me.
> > 
> > Actually, the quadratic trend surface (trend="2nd")
> makes
> > the data "bell" shaped according to the
> plot.geodata()
> > display.
> > Then, the geostatistical results I could draw from it
> could
> > be of interest if? compared with geoRglm results
> > (provided I assume that my burrows counts is poisson
> > distributed with units.m="m2").
> > 
> > I am going to try again with an other set of data (and
> I
> > cross my finger!!)
> > 
> > Please, let me know if you find out a solution!!!
> > 
> > Hocine
> > 
> > 
> > ? ? 
> > 
> > 
> > 
> > 
> > --- En date de?: Dim 23.5.10, Paulo J Ribeiro Jr
> <paulojus at c3sl.ufpr.br>
> > a ?crit?:
> > 
> > > De: Paulo J Ribeiro Jr <paulojus at c3sl.ufpr.br>
> > > Objet: Re: Help with proflik()
> > > ?: "Lho Lho" <manguefleur at yahoo.fr>
> > > Date: Dimanche 23 mai 2010, 21h04
> > > Hi 
> > > 
> > > Yhanks for reporting and sending detailed
> > information.
> > > I have not yet inspected/run the files and
> commands
> > > but I suspect that the probelem may be due to
> > numerical
> > > instability
> > > due to the different orders of magnitude between
> your
> > phi
> > > (range)
> > > parameters and the others.
> > > 
> > > As a quick try you could multiply all the
> coordinates
> > by a
> > > constant (100
> > > or 1000), changind range parameters (phi) values
> > > accordingly and see if
> > > the problem persists
> > > 
> > > Please let me know
> > > 
> > > best
> > > P.J.
> > > 
> > > 
> > > Em Dom, 2010-05-23 ?s 17:37 +0000, Lho Lho
> escreveu:
> > > > Dear Paulo Justiniano Ribeiro 
> > > > 
> > > > After performing the proflik() function I
> had
> > this
> > > message from R:
> > > > 
> > > > ##proflik:computing profile likelihood for
> the
> > sill
> > > > Error in solve.default(xix, xiy) :
> > > >???system is computationally singular:
> > > reciprocal condition number=5.05981e-19##
> > > > 
> > > > I guess it is related to "matrice" with the
> term
> > > solve.default(??)
> > > > 
> > > > Unfortunately, I was not able to overcome
> this
> > > problem.
> > > > 
> > > > Would you like to help me?
> > > > 
> > > > 
> > > > Please find attached my data in text format
> > (Apple).
> > > > 
> > > > My? R code was :
> > > > 
> > > >
> > >
> >
> ini.values=expand.grid(x=seq(500,1300,by=25),y=seq(0,0.40,by=0.01))
> > > > inivalues<-as.matrix(ini.values)
> > > > 
> > > >
> > >
> >
> Burrows.likfit<-likfit(Burrows.geo,trend="2nd",fix.lambda=TRUE,lambda=1,ini.cov.pars=ini.values,fix.nugget=FALSE,nugget=0,lik.method="ML",cov.model="mat")
> > > > 
> > > >
> > >
> >
> profile<-proflik(Burrows.likfit,geodata=Burrows.geo,sill.values=seq(1210,1213,l=4),range.values=seq(0.026,0.029,l=4),nugget.values=seq(31,34,l=4),
> > > uni.only=T))
> > > > 
> > > > 
> > > > Hocine BENCHIKH
> > > > PhD student UCC
> > > > Ireland
> > > > 
> > > > 
> > > > 
> > > > 
> > > >? ? ???
> > > 
> > > 
> > > 
> > 
> > 
> > 
> > 
> 
> 
> ? ? 
>






From mark_connolly at acm.org  Mon Jun 28 13:36:37 2010
From: mark_connolly at acm.org (Mark Connolly)
Date: Mon, 28 Jun 2010 07:36:37 -0400
Subject: [R-sig-Geo] Spatial data interpolation on R
Message-ID: <4C288945.2030108@acm.org>

You should consider acquiring

Applied Spatial Data Analysis with R
Roger S. Bivand, Edzer J. Pebesma and V. G?mez-Rubio
http://www.asdar-book.org/

It is an excellent resource.


From jsbarret at sfu.ca  Mon Jun 28 20:54:03 2010
From: jsbarret at sfu.ca (Jenn Barrett)
Date: Mon, 28 Jun 2010 11:54:03 -0700 (PDT)
Subject: [R-sig-Geo] Question (and answer) about spdep 'autocov_dist' for
 use in autopoisson
Message-ID: <925737853.13568441277751243136.JavaMail.root@jaguar9.sfu.ca>

Hi everyone,

I recently wrote to Roger Bivand regarding the 'autocov_dist' function in spdep for use in an autopoisson, and as per his suggestion, I'm posting our conversation (below) to the list, as others may find it useful. Likewise, any thoughts/input on this matter would be more than welcome!

Cheers,
Jenn


----- Original Message -----
From: "Roger Bivand" <Roger.Bivand at nhh.no>
To: "Jenn Barrett" <jsbarret at sfu.ca>
Sent: Thursday, 24 June, 2010 00:44:51 GMT -08:00 US/Canada Pacific
Subject: Re: Question about spdep 'autocov_dist' for use in autopoisson

On Wed, 23 Jun 2010, Jenn Barrett wrote:

> Hi Dr. Bivand,
>
> My apologies for writing you directly, but I have been all over the
> internet and literature trying to find an answer to this question, and
> have had no luck.

Dear Jenn,

Please *do* write to the R-sig-geo list rather than to me directly -
others can answer your question as well, perhaps better, and in a more
timely way than I can. In addition, threads in the list can be searched in
the archives, so others can avoid the same problem later.

>
> Your R-package 'spdep' provides a function 'autocov_dist' for
> calculating a distance-weighted autocovariate for use in an
> autologistic, autopoisson or autonormal model; however, I've come across
> several papers now that suggest that autopoisson models can only account
> for negative autocorrelation. I'm confused as to why this is, as the
> approach (i.e., of including an autocovariate) is independent of the
> error distribution (as Dormann et al. 2007 point out in their Ecography
> appendix). Is it appropriate to use an autocovariate, as calculated in
> the function described above, to account for positive spatial
> autocorrelation in a poisson (or negbin) model? If not, why?

The autocov_dist function was included in connection with Dormann et al.
(2007) paper based on a workshop in 2005, where Carsten wrote the
function. It was a proof of concept idea, which I felt was rather stupid,
as shown in the examples. The main problem is that some ecology journals
never ask statisticians to referee papers, so things get done differently
in different disciplines. The underlying problem is that there is no known
way of simulating spatial autocorrelation in discrete variables to that
tests and model fitting techniques can be assessed properly.

The idea of using the spatial lag of the dependent variable in a
regression is prevalent in "spatial econometrics", but is arguably no less
wrong-headed - in the Gaussian case, it is fit with ML anyway (and with
IV methods - horror!).

A GLMM will fit with the spatial process in the error term, but its
applicability also depends on the model being well-specified. Bayesian
methods give some flexibility, but are also dependent on a "good" prior.
Spatial filtering offers some possibilities, but again, without a good way
of simulating the level of spatial autocorrelation in discrete variables
so that any tests or model fitting methods can be checked, one is
wandering around in darkness. There is no good answer to this, I'm afraid
- unless someone can show that there is a robust and workable way though,
this is a show-stopper.

Hope this helps,

Roger

>
> Many thanks in advance.
>
> Cheers,
> Jenn
>
_____________________________
Jennifer Barrett
Centre for Wildlife Ecology
Dept. of Biological Sciences
Simon Fraser University
Burnaby, B.C.


Hi Dr. Bivand,

Thanks for your timely reply. What you've written makes sense to me, and it would thus appear that I'm at a bit of a dead end in terms of how to handle the spatial autocorrelation in our count data. I suppose I could transform the counts to densities (e.g., birds/km-squared), or log or sqrt transform them, and apply Gaussian methods, as I've seen others do (e.g., Lichstein et al. 2002, Keitt et al. 2002, Tognelli and Kelt 2004) or as described in your book chapter (Chap 10: Modelling Areal Data -  Applied Spatial Data Analysis in R). That said, there are arguments against transforming count data as well (see O'Hara and Kotze 2010), so this may not be a valid approach either.

A GLMM may be an option; however, we wish to use an information theoretic approach and glmmPQL (the function suggested by Dormann et al. 2007) does not allow for calculation of AIC values. Perhaps glmmML is an option - I'll have to look into this.

I will post our conversation to R-sig-geo for the benefit of others facing the same issue.

Thanks again for your quick and informative reply.

Cheers,
Jenn


From julien.beguin.1 at ulaval.ca  Tue Jun 29 17:15:43 2010
From: julien.beguin.1 at ulaval.ca (Julien Beguin)
Date: Tue, 29 Jun 2010 11:15:43 -0400
Subject: [R-sig-Geo] RE : question about autocov_dist function in "spdep"
 package
In-Reply-To: <alpine.LRH.2.00.1006252148310.21394@reclus.nhh.no>
References: <B56D7C27B4408243B93FBC46ABECB5A0011A8CFBC7C7@EXCH-MBX-F.ulaval.ca>,
	<alpine.LRH.2.00.1006252148310.21394@reclus.nhh.no>
Message-ID: <B56D7C27B4408243B93FBC46ABECB5A0011A8CFBC7CA@EXCH-MBX-F.ulaval.ca>

Thank you Roger for your fast response and Jenn for cc:ing your message about autocov_dist in spdep. I am far to be a specialist in spatial statistic and I know that autologistic models have been criticised in inferential context (e.g. Dorman et al. ). Several authors (in ecology, at least) also found it useful in prediction context (Betts et al.). I guess that the debate might not be over...
 
My objective is not to trust results of autologistic model without criticism but rather to compare them with other approaches (e.g. Moran eigenvector, spatial regression, etc...). 
 
Sorry for my ignorance but what means:

"general weights sum to zero". Is autocovariate term (not) calculated as follows ? A = sum(wij*yj)/ sum(wij) where wij=1/euclidian distance between i and j (for inverse distance). It is maybe a stupid question but how could weights sum to zero?

Also, it is not false to say that I am asking to include a constant vector of zeros, but only for points that have no neighbour in a single region. Imagine a study area composed of 5 regions containing each N presence/absence points with associated covariates. If I calculate the autocovariate term for each region separately (with constant nbs) and that for one region (not the others) the minimum distance between pair of points < nbs value, it will crash for that region. It might be that spatial autocorrelation vary from region to region, and that in a specific region, A value based on a constant nbs among regions would be zero (because of no neighbour) for that region.   

A GLMM with fixed factors: Y~ covariates + Autocovariate; and random factors = 1|Region/Autocovariate could account for that, no?

Thank you again for your time,

Julien 
_______________________________________
De : Roger Bivand [Roger.Bivand at nhh.no]
Date d'envoi : 25 juin 2010 15:55
? : Julien Beguin
Cc : r-sig-geo at stat.math.ethz.ch
Objet : Re: [R-sig-Geo] question about autocov_dist function in "spdep" package

On Fri, 25 Jun 2010, Julien Beguin wrote:

> Dear list member,
>
> I am using the autocov_dist function in spdep on binary point data set
> to estimate the autocovariate to be used in autologistic regression
> (session info at the end):
>
> coords<-as.matrix(cbind(datafile$X_COORD, datafile$Y_COORD))
> ac1 <- autocov_dist(datafile$binary_variable, coords, nbs=400, type = "inverse", zero.policy=TRUE)
>
> It works fine with large value of nbs. When nbs value is below the neibhorhood distance of some pairs of point I get warnings because of empty neighbors:
>
>> Warning messages: 1: In autocov_dist(datafile$binary_variable, coords,
>> nbs = 400, type = "inverse", :

>> With value 400 some points have no neighbours
>> 2: In nb2listw(nb, glist = gl, style = style, zero.policy = zero.policy) :
>> zero sum general weights
>
> It seems, but I might be wrong, that points with no neighbour have an
> autocov_dist value of zero. Since it is what I want, it is ok for me.

No, the general weights sum to zero, as it says, you are using inverse.

> But if I decrease nbs value below the smallest neighbourhood distance
> among pairs of points in my data set, I get an error message:
>
>> Error in nb2listw(nb, glist = gl, style = style, zero.policy = zero.policy) :
>>  No valid observations
>> In addition: Warning messages:
>> 1: In autocov_dist(datafile$binary_variable, coords, nbs = 100, type = "inverse",  :
>> With value 100 some points have no neighbours
>> 2: In nb2listw(nb, glist = gl, style = style, zero.policy = zero.policy) :
>>  zero sum general weights
>
> My question is as follows: why do autocov_dist function require that at
> least one neighbor pair exists? and why not returning zero value for all
> points when no any point has a neighbor?
>
> This might appear to be a strange question but in my case I estimating
> autocov_dist for different spatial block in which the minimum distance
> between points vary from block to block, but still I would like a commun
> nbs value for all block.

It does indeed seem very strange, as you are asking to include a constant
vector of zeros, which will alias the constant. The function itself is a
really bad idea, and is included only to show (see Dormann et al 2007)
that using it is inferior to all other methods examined there. Trying to
include a second zero constant doesn't seem well-founded, to put it
mildly.

Hope this helps,

Roger

>
> Thank you for your help,
>
> Julien Beguin
> --------------------
> Ph.D. student
> Laval University
> Qu?bec, Canada
>
> SESSION INFO:
>
> R version 2.10.1 (2009-12-14)
> i386-pc-mingw32
> locale:
> [1] LC_COLLATE=French_Canada.1252  LC_CTYPE=French_Canada.1252
> [3] LC_MONETARY=French_Canada.1252 LC_NUMERIC=C
> [5] LC_TIME=French_Canada.1252
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> other attached packages:
> [1] spdep_0.5-4         spam_0.20-3         coda_0.13-4
> [4] deldir_0.0-12       maptools_0.7-29     foreign_0.8-40
> [7] nlme_3.1-96         MASS_7.3-4          Matrix_0.999375-33
> [10] lattice_0.17-26     boot_1.2-41         sp_0.9-60
> [13] compositions_1.01-1 robustbase_0.5-0-1  tensorA_0.31
> [16] rgl_0.91
> loaded via a namespace (and not attached):
> [1] grid_2.10.1  tools_2.10.1
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

--
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From Pierre.Racine at sbf.ulaval.ca  Tue Jun 29 17:31:55 2010
From: Pierre.Racine at sbf.ulaval.ca (Pierre Racine)
Date: Tue, 29 Jun 2010 11:31:55 -0400
Subject: [R-sig-Geo] Raster/vector intersections in PostGIS WKT Raster
Message-ID: <87A96661E65C5541AB4D20721C2DD7F880A316869D@EXCH-MBX-A.ulaval.ca>

Hi everybody,

I'm pleased to announce that you can now do intersections between rasters and geometries very much like you used to do geometry/geometry intersections in PostGIS. For this, PostGIS WKT Raster introduces two new functions to PostGIS: ST_Intersects(geometry, raster, band) and ST_Intersection(geometry, raster, band).

As its geometry/geometry sister, ST_Intersects(geometry, raster, band) returns TRUE if the withvalue area of a raster or a raster tile (nodata value are ignored) intersects a geometry and ST_Intersection(geometry, raster, band) returns the geometry/value set of geometries representing the intersection between the geometry and each polygonized group of pixel sharing a same value from the raster and its associated value. Example:

SELECT polyid,
       (ST_Intersection(the_geom, rast)).geom,
       (ST_Intersection(the_geom, rast)).val
FROM my_polygons, srtm_tiled
WHERE ST_Intersects(rast, the_geom)

or, a bit more complex, but much faster and returning the same result:

SELECT polyid, (gv).geom, (gv).val
FROM (SELECT polyid, ST_Intersection(the_geom, rast, 1) AS gv
     FROM my_polygons, srtm_tiled
     WHERE ST_Intersects(rast, the_geom)) foo

These functions works with any kind of geometry so you can intersect any road, river, polygons or point layer with your favorite elevation or land cover raster of any resolution and any size. You can also load any number of raster in the database with one command line to constitute a unique table raster coverage of any shape (no matter if your group of raster do not form a rectangular coverage).

You will find a complete tutorial on how to use those two new functions here: http://trac.osgeo.org/postgis/wiki/WKTRasterTutorial01. A reference is available here: http://postgis.refractions.net/documentation/manual-svn/RT_reference.html and chapter 13 of "PostGIS in Action" is also a very good introduction to WKT Raster.

Compilation and installation info are available in the project home page: http://trac.osgeo.org/postgis/wiki/WKTRaster

These features are the result of two years of collaboration between many people and companies interested in bringing raster into PostGIS. I would like to thanks particularly Steve Cumming who initially made all this possible, Sandro Santilli who wrote the base code, Mateusz Loskot who wrote the Python loader, Jorge Arevalo who wrote the GDAL driver and ST_DumpAsPolygons(), Regina and Leo Obe who are doing so many things and believed in the project from the beginning by adding a chapter about WKT Raster in "PostGIS in Action" and also David Zwarg who wrote most of the setter functions.

This is the first step toward a first complete raster/vector analysis and manipulation SQL API. We hope to make of PostGIS with WKT Raster the most powerful and complete GIS analysis and manipulation high level language ever (!!!). WKT Raster should normally be totally integrated into PostGIS in PostGIS release 2.0. Upcoming functions should include ST_Reclass, ST_Clip, ST_AsRaster, ST_Resample.

Let us know your need and your experience with WKT Raster.

Thanks,

Pierre Racine


From macq at llnl.gov  Tue Jun 29 17:59:38 2010
From: macq at llnl.gov (Don MacQueen)
Date: Tue, 29 Jun 2010 08:59:38 -0700
Subject: [R-sig-Geo] Spatial data interpolation on R
In-Reply-To: <6744.30335.qm@web54304.mail.re2.yahoo.com>
References: <6744.30335.qm@web54304.mail.re2.yahoo.com>
Message-ID: <p06240801c84fc3b7bff8@[128.115.67.9]>

If you are willing to do simple interpolation, 
i.e., ignoring any spatial correlation, you could 
look at the interp() function, which is in the 
akima package.  Even if you need to incorporate 
spatial correlation, starting with the interp() 
function would probably serve as a good way to 
get started learning R. The help page for 
interp() has some examples.

Here's an excerpt from the help page for the interp() function:

interp                  package:akima                  R Documentation

Gridded Bivariate Interpolation for Irregular Data

Description:

      These functions implement bivariate interpolation onto a grid for
      irregularly spaced input data.  Bilinear or bicubic spline
      interpolation is applied using different versions of algorithms
      from Akima.


Install the akima package using the R console GUI 
(Mac or Windows) or the install.packages() 
function (linux).

Then there's the question of coordinate systems. 
interp() assumes cartesian coordinates, but 
lat/long is not cartesian. If your site is too 
large, you shouldn't ignore this, so you will 
have to learn how to project from lat/long to UTM 
or other appropriate local coordinate  system. 
For this, I use the spTransform() function in the 
rgdal package. Looking on the CRAN website, it 
appears there is a Windows binary for rgdal; for 
the other platforms (I use Mac), it can be more 
challenging. Converting your data into a 
"spatial" class object, so that it can be 
projected, will be a challenge at first.

Gettng the book that Mark Connolly mentioned would help a lot.

-Don


At 10:20 AM -0700 6/2/10, Thiago Veloso wrote:
>Content-Type: text/plain
>Content-Disposition: inline
>Content-length: 937
>
>Dear R colleagues!
>  I?d like to start my participation in this list 
>by describing my current problem: inside my area 
>of study I need to compare precipitation data 
>from two different sources: both station (total 
>of 86) and a grid (at 8km) of satellite 
>estimates.
>   My specific objective is to interpolate the 
>station data into a regular grid in the same 
>resolution of the satellite estimates, 
>preferentially having control of the spatial 
>domain (lat/lon coordinates). As far as I know 
>this is the correct way of making such 
>comparison.
>   Could anybody please point directions to 
>perform this task using R? I?m such a beginner 
>that I don?t even know if
>  there?s a package designed to create regular 
>grids from "random" data (interpolating by 
>kriging or other technique). Usage examples 
>would be welcomed as well!
>Thanks in advance,
>  Thiago.
>
>
>
>      
>	[[alternative HTML version deleted]]
>
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at stat.math.ethz.ch
>https://*stat.ethz.ch/mailman/listinfo/r-sig-geo


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
925-423-1062


From r.hijmans at gmail.com  Tue Jun 29 20:15:49 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 29 Jun 2010 11:15:49 -0700
Subject: [R-sig-Geo] Spatial data interpolation on R
In-Reply-To: <p06240801c84fc3b7bff8@128.115.67.9>
References: <6744.30335.qm@web54304.mail.re2.yahoo.com>
	<p06240801c84fc3b7bff8@128.115.67.9>
Message-ID: <AANLkTikb7y1VNWgD8TTLTvKkgEp_s2ySFjILMfvKiHZi@mail.gmail.com>

Thiago,

I think a better approach would be to estimate the value for the sat
images at the stations' locations; and not the other way around, as
your are proposing.

A simple way to do that is bilinear interpolation of the sat image
values for the weather station locations.

If 'xyv' is your lon/lat/prec matrix and 'f' is a filename for one of
your sat images.

library(raster)
r <- raster(f)
res <- xyValues(r, xyv[,1:2], method='bilinear')
plot(res, xyv[,3])


..... and now analyze the difference between res and xyv[,3]  data
taking spatial autocorrelation into account



Nevertheless, if you insist on interpolating the weather station data,
you could do that with a spline

library(fields)
tps <- Tps(xyv[,1:2], xyv[,3])
p <- raster(r)
p <- interpolate(p, tps)
plot(p, r)


In the end, the best approach to obtaining a raster of the rainfall
data, if that is what you are after, would probably be a hybrid where
the sat image is use as an independent variable (covariate) in the
spline (or other interpolation method).

Robert


On Tue, Jun 29, 2010 at 8:59 AM, Don MacQueen <macq at llnl.gov> wrote:
> If you are willing to do simple interpolation, i.e., ignoring any spatial
> correlation, you could look at the interp() function, which is in the akima
> package. ?Even if you need to incorporate spatial correlation, starting with
> the interp() function would probably serve as a good way to get started
> learning R. The help page for interp() has some examples.
>
> Here's an excerpt from the help page for the interp() function:
>
> interp ? ? ? ? ? ? ? ? ?package:akima ? ? ? ? ? ? ? ? ?R Documentation
>
> Gridded Bivariate Interpolation for Irregular Data
>
> Description:
>
> ? ? These functions implement bivariate interpolation onto a grid for
> ? ? irregularly spaced input data. ?Bilinear or bicubic spline
> ? ? interpolation is applied using different versions of algorithms
> ? ? from Akima.
>
>
> Install the akima package using the R console GUI (Mac or Windows) or the
> install.packages() function (linux).
>
> Then there's the question of coordinate systems. interp() assumes cartesian
> coordinates, but lat/long is not cartesian. If your site is too large, you
> shouldn't ignore this, so you will have to learn how to project from
> lat/long to UTM or other appropriate local coordinate ?system. For this, I
> use the spTransform() function in the rgdal package. Looking on the CRAN
> website, it appears there is a Windows binary for rgdal; for the other
> platforms (I use Mac), it can be more challenging. Converting your data into
> a "spatial" class object, so that it can be projected, will be a challenge
> at first.
>
> Gettng the book that Mark Connolly mentioned would help a lot.
>
> -Don
>
>
> At 10:20 AM -0700 6/2/10, Thiago Veloso wrote:
>>
>> Content-Type: text/plain
>> Content-Disposition: inline
>> Content-length: 937
>>
>> Dear R colleagues!
>> ?I?d like to start my participation in this list by describing my current
>> problem: inside my area of study I need to compare precipitation data from
>> two different sources: both station (total of 86) and a grid (at 8km) of
>> satellite estimates.
>> ?My specific objective is to interpolate the station data into a regular
>> grid in the same resolution of the satellite estimates, preferentially
>> having control of the spatial domain (lat/lon coordinates). As far as I know
>> this is the correct way of making such comparison.
>> ?Could anybody please point directions to perform this task using R? I?m
>> such a beginner that I don?t even know if
>> ?there?s a package designed to create regular grids from "random" data
>> (interpolating by kriging or other technique). Usage examples would be
>> welcomed as well!
>> Thanks in advance,
>> ?Thiago.
>>
>>
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://*stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> --
> --------------------------------------
> Don MacQueen
> Environmental Protection Department
> Lawrence Livermore National Laboratory
> Livermore, CA, USA
> 925-423-1062
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From sjmyers at syr.edu  Tue Jun 29 21:34:04 2010
From: sjmyers at syr.edu (Seth-3)
Date: Tue, 29 Jun 2010 12:34:04 -0700 (PDT)
Subject: [R-sig-Geo] logistic GWR
In-Reply-To: <a4655df90912041536v7fbc5522hae70c092221bf417@mail.gmail.com>
References: <a4655df90912041536v7fbc5522hae70c092221bf417@mail.gmail.com>
Message-ID: <1277840044118-5236339.post@n2.nabble.com>


Yes, it is very possible.  

memory.limit(size=2800)
library(sp)
library(spgwr)
spatdata<-read.table(file="C:\\ctlogreg_rfordata\\data\\650GRD_AOIM1KNONDEV85DRYLNDCNSH2OMSK_85to06chcommameancent.txt",header=TRUE,sep=",")


ggwr5k<-ggwr(devchng~
  agricden          +
grassden          +
agric             +
barren            +
grass             +
wtlnd             +
allcitydis.w      +
devden            +
dis.citge100k.wab +
dis.prim.wab      +
dis.secloc.wab    +
dist.rampm.wab    +
elev.wab          +
fema100yr.w01     +
medinc.wab        +
munifeddep.w01    +
popinvdis.wab     +
sewer01.w         +
slope.deg.wab     
,
data=spatdata,coords=cbind(spatdata$eastdis.mab,spatdata$northdist.mab),
bandwidth=5000,gweight=gwr.Gauss,family=binomial(link="logit"),longlat=FALSE,type=c("response"))
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/logistic-GWR-tp4115587p5236339.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From mario.gellrich at gmx.ch  Wed Jun 30 11:44:26 2010
From: mario.gellrich at gmx.ch (Mario Gellrich)
Date: Wed, 30 Jun 2010 11:44:26 +0200
Subject: [R-sig-Geo] Reading Multi Polygon Shapefiles
Message-ID: <20100630094426.312890@gmx.net>

Dear list members

I have a question concerning the import of multipolygon-shapefiles (ESRI notation: PolygonM, type 25). I tried readShapePoly() from the maptools package, the PBSmapping package (which seems to use the same function) and read.shapefile() from the shapefile package. With maptools/PBSmapping I've got the message that this polygon-type cannot (yet) be handled. Is there another way to read such shapefile-types? We also have PostGIS in our office, but I did'nt tried out, whether it works or not. I work with R version 2.10.1 (64 bit) on Mac.

Best regards

Mario
-- 
GMX DSL: Internet-, Telefon- und Handy-Flat ab 19,99 EUR/mtl.  
Bis zu 150 EUR Startguthaben inklusive! http://portal.gmx.net/de/go/dsl


From nikhil.list at gmail.com  Wed Jun 30 12:45:00 2010
From: nikhil.list at gmail.com (Nikhil Kaza)
Date: Wed, 30 Jun 2010 06:45:00 -0400
Subject: [R-sig-Geo] Reading Multi Polygon Shapefiles
In-Reply-To: <20100630094426.312890@gmx.net>
References: <20100630094426.312890@gmx.net>
Message-ID: <CAB203A6-34A0-4E1C-B39F-5C1D3D192A3C@gmail.com>

try readOGR in rgdal package.

If you are using a mac, installing rgdal is slightly more complicated.
http://www.kyngchaos.com/software:frameworks


Nikhil Kaza
Asst. Professor,
City and Regional Planning
University of North Carolina

nikhil.list at gmail.com

On Jun 30, 2010, at 5:44 AM, Mario Gellrich wrote:

> Dear list members
>
> I have a question concerning the import of multipolygon-shapefiles  
> (ESRI notation: PolygonM, type 25). I tried readShapePoly() from the  
> maptools package, the PBSmapping package (which seems to use the  
> same function) and read.shapefile() from the shapefile package. With  
> maptools/PBSmapping I've got the message that this polygon-type  
> cannot (yet) be handled. Is there another way to read such shapefile- 
> types? We also have PostGIS in our office, but I did'nt tried out,  
> whether it works or not. I work with R version 2.10.1 (64 bit) on Mac.
>
> Best regards
>
> Mario
> -- 
> GMX DSL: Internet-, Telefon- und Handy-Flat ab 19,99 EUR/mtl.
> Bis zu 150 EUR Startguthaben inklusive! http://portal.gmx.net/de/go/ 
> dsl
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From alobolistas at gmail.com  Wed Jun 30 13:58:15 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Wed, 30 Jun 2010 13:58:15 +0200
Subject: [R-sig-Geo] Raster:memory or disk?
Message-ID: <AANLkTikGzK7e3vMBqEfe4nZjoew9hg1cW-WyB1Mv12za@mail.gmail.com>

Hi!

Is there any way to check if the values of a raster object
are in memory or in disk?

For example
r10 <- raster("2000_TSDP_IP-INVDIST-SP10_43023435.tif")
b <- r10

I understand that values of r10 are not loaded in memory
but b is completely in memory (am I wrong?)
How could I actually verify this?

Thanks

Agus


From carson.farmer at gmail.com  Wed Jun 30 14:50:25 2010
From: carson.farmer at gmail.com (Carson Farmer)
Date: Wed, 30 Jun 2010 13:50:25 +0100
Subject: [R-sig-Geo] Raster:memory or disk?
In-Reply-To: <AANLkTikGzK7e3vMBqEfe4nZjoew9hg1cW-WyB1Mv12za@mail.gmail.com>
References: <AANLkTikGzK7e3vMBqEfe4nZjoew9hg1cW-WyB1Mv12za@mail.gmail.com>
Message-ID: <AANLkTimIFpZhOpbKNf3D0Y7eYXfJxBW5PO6Rmy0vUykr@mail.gmail.com>

Agus,

What about using:

> object.size(b)

which (according to ?object.size) provides an estimate of the memory
that is being used to store an R object.

Carson

On 30 June 2010 12:58, Agustin Lobo <alobolistas at gmail.com> wrote:
> Hi!
>
> Is there any way to check if the values of a raster object
> are in memory or in disk?
>
> For example
> r10 <- raster("2000_TSDP_IP-INVDIST-SP10_43023435.tif")
> b <- r10
>
> I understand that values of r10 are not loaded in memory
> but b is completely in memory (am I wrong?)
> How could I actually verify this?
>
> Thanks
>
> Agus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Carson J. Q. Farmer
ISSP Doctoral Fellow
National Centre for Geocomputation
National University of Ireland, Maynooth,
http://www.carsonfarmer.com/


From alobolistas at gmail.com  Wed Jun 30 14:51:14 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Wed, 30 Jun 2010 14:51:14 +0200
Subject: [R-sig-Geo] mapproject
Message-ID: <AANLkTinKL_lozMQ2mxaxOnpq2Marh_pSOaNJnMh0riYc@mail.gmail.com>

I have a SpPolDF in geographic coordinates (eugrd025DF) and must reproject it
to the projection of a raster object (Br):
> projection(eugrd025DF)
[1] "+proj=longlat +ellps=WGS84"

> projection(Br)
[1] "+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000
+ellps=GRS80 +units=m +no_defs"

Can I do this with mapproject (package mapproj) os is it better to
export to shape file, reproject
with a GIS and import back? If it's possible/convenient, how to write
the parameters argument
in mapproject()?

Thanks


From b.rowlingson at lancaster.ac.uk  Wed Jun 30 15:25:42 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 30 Jun 2010 14:25:42 +0100
Subject: [R-sig-Geo] mapproject
In-Reply-To: <AANLkTinKL_lozMQ2mxaxOnpq2Marh_pSOaNJnMh0riYc@mail.gmail.com>
References: <AANLkTinKL_lozMQ2mxaxOnpq2Marh_pSOaNJnMh0riYc@mail.gmail.com>
Message-ID: <AANLkTimmp24RzE7dJwSvTf4gUw2lKt4L13oWH2DpZK37@mail.gmail.com>

On Wed, Jun 30, 2010 at 1:51 PM, Agustin Lobo <alobolistas at gmail.com> wrote:
> I have a SpPolDF in geographic coordinates (eugrd025DF) and must reproject it
> to the projection of a raster object (Br):
>> projection(eugrd025DF)
> [1] "+proj=longlat +ellps=WGS84"
>
>> projection(Br)
> [1] "+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000
> +ellps=GRS80 +units=m +no_defs"
>
> Can I do this with mapproject (package mapproj) os is it better to
> export to shape file, reproject
> with a GIS and import back? If it's possible/convenient, how to write
> the parameters argument
> in mapproject()?


Use spTransform from package:rgdal? That's what I use.

examples in ?spTransform include:

state.ll83 <- spTransform(states, CRS("+proj=longlat +ellps=GRS80"))

so things should just plug in.

Barry


From mdsumner at gmail.com  Wed Jun 30 15:31:16 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 30 Jun 2010 23:31:16 +1000
Subject: [R-sig-Geo] mapproject
In-Reply-To: <AANLkTinKL_lozMQ2mxaxOnpq2Marh_pSOaNJnMh0riYc@mail.gmail.com>
References: <AANLkTinKL_lozMQ2mxaxOnpq2Marh_pSOaNJnMh0riYc@mail.gmail.com>
Message-ID: <AANLkTinGKwqyHWbi3fmJ-iROnY_RbmDpEREmQBLP3Jll@mail.gmail.com>

I think rgdal package would be the preferable way. There are some old
and outdated map projection packages (I admittedly do not not the
details, and use rgdal exclusively).

library(rgdal)
eugrd025DF.laea <- spTransform(eugrd025DF, CRS(projection(Br)))

spTransform() handles all the details of back and forward transforming
(see inv argument in project) so that valid CRS() projection strings
can be used directly to specify reprojections.

I'm not intimate yet with the raster package so I might have missed
something that's possible in the way the CRS string is derived by
projection, but if proj4string(eugrd025DF) gives the same value as
projection(eugrd025DF) then the spTransform approach should be fine.

Cheers, Mike.

On Wed, Jun 30, 2010 at 10:51 PM, Agustin Lobo <alobolistas at gmail.com> wrote:
> I have a SpPolDF in geographic coordinates (eugrd025DF) and must reproject it
> to the projection of a raster object (Br):
>> projection(eugrd025DF)
> [1] "+proj=longlat +ellps=WGS84"
>
>> projection(Br)
> [1] "+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000
> +ellps=GRS80 +units=m +no_defs"
>
> Can I do this with mapproject (package mapproj) os is it better to
> export to shape file, reproject
> with a GIS and import back? If it's possible/convenient, how to write
> the parameters argument
> in mapproject()?
>
> Thanks
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From jacobvanetten at yahoo.com  Wed Jun 30 16:07:07 2010
From: jacobvanetten at yahoo.com (Jacob van Etten)
Date: Wed, 30 Jun 2010 14:07:07 +0000 (GMT)
Subject: [R-sig-Geo] Raster:memory or disk?
In-Reply-To: <AANLkTikGzK7e3vMBqEfe4nZjoew9hg1cW-WyB1Mv12za@mail.gmail.com>
Message-ID: <792840.94188.qm@web23704.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100630/37b78a79/attachment.pl>

From alobolistas at gmail.com  Wed Jun 30 16:12:41 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Wed, 30 Jun 2010 16:12:41 +0200
Subject: [R-sig-Geo] polygonValues (raster): Very slow
Message-ID: <AANLkTikPNOMFUdF87TsWUcJCoqXX-Am7G5eeMXHDinPf@mail.gmail.com>

Hi!
I'm trying:

> eugrd025EFDC <- readOGR(dsn="eugrd025EFDC",layer="eugrd025EFDC")
v <- polygonValues(p=eugrd025EFDC, Br, weights=TRUE)

where

> str(eugrd025EFDC,max.level=2)
Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
  ..@ data       :'data.frame':	18000 obs. of  5 variables:
  ..@ polygons   :List of 18000
  .. .. [list output truncated]
  ..@ plotOrder  : int [1:18000] 17901 17900 17902 17903 17899 17898
17904 17897 17905 17906 ...
  ..@ bbox       : num [1:2, 1:2] 2484331 1314148 6575852 4328780
  .. ..- attr(*, "dimnames")=List of 2
  ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots

> summary(Br)
Cells:  13967442
NAs  :  0


Min.       0.00
1st Qu.    0.00
Median     0.00
Mean      48.82
3rd Qu.    0.00
Max.    4999.00

so quite large objects.

The problem is that  polygonValues() has been running (and not
completed the task) for
more than 2 h on a intel core i7 machine with 16 Gb RAM (Dell
Precision M6500), so a pretty powerful machine.
Is there any way I could speed up this process?
Also, is there anything I could do in order to take better advantage
of the 8 processing threads?
Currently, I see only 1 cpu working for R processes and the rest
remain pretty inactive

Thanks

Agus


From nikhil.list at gmail.com  Wed Jun 30 16:27:11 2010
From: nikhil.list at gmail.com (Nikhil Kaza)
Date: Wed, 30 Jun 2010 10:27:11 -0400
Subject: [R-sig-Geo] polygonValues (raster): Very slow
In-Reply-To: <AANLkTikPNOMFUdF87TsWUcJCoqXX-Am7G5eeMXHDinPf@mail.gmail.com>
References: <AANLkTikPNOMFUdF87TsWUcJCoqXX-Am7G5eeMXHDinPf@mail.gmail.com>
Message-ID: <34A485B9-0ECA-4E1F-8692-BAAB01BD2131@gmail.com>


This is not an R solution and I am not even sure if this speeds up  
your process. But in the past I have used starspan for this kind of  
work. It worked fairly well for me for large datasets. But it was a  
one off process that I didn't mind spending couple of hours. I also  
did a naive parallelization by breaking up the polygon files multiple  
parts and then assembling them back,  but if you really need the  
accurate proportion of cell area of a cell that falls across two  
polygons, this strategy wont work.

http://starspan.projects.atlas.ca.gov/doku/doku.php



Nikhil Kaza
Asst. Professor,
City and Regional Planning
University of North Carolina

nikhil.list at gmail.com

On Jun 30, 2010, at 10:12 AM, Agustin Lobo wrote:

> Hi!
> I'm trying:
>
>> eugrd025EFDC <- readOGR(dsn="eugrd025EFDC",layer="eugrd025EFDC")
> v <- polygonValues(p=eugrd025EFDC, Br, weights=TRUE)
>
> where
>
>> str(eugrd025EFDC,max.level=2)
> Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
>  ..@ data       :'data.frame':	18000 obs. of  5 variables:
>  ..@ polygons   :List of 18000
>  .. .. [list output truncated]
>  ..@ plotOrder  : int [1:18000] 17901 17900 17902 17903 17899 17898
> 17904 17897 17905 17906 ...
>  ..@ bbox       : num [1:2, 1:2] 2484331 1314148 6575852 4328780
>  .. ..- attr(*, "dimnames")=List of 2
>  ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>
>> summary(Br)
> Cells:  13967442
> NAs  :  0
>
>
> Min.       0.00
> 1st Qu.    0.00
> Median     0.00
> Mean      48.82
> 3rd Qu.    0.00
> Max.    4999.00
>
> so quite large objects.
>
> The problem is that  polygonValues() has been running (and not
> completed the task) for
> more than 2 h on a intel core i7 machine with 16 Gb RAM (Dell
> Precision M6500), so a pretty powerful machine.
> Is there any way I could speed up this process?
> Also, is there anything I could do in order to take better advantage
> of the 8 processing threads?
> Currently, I see only 1 cpu working for R processes and the rest
> remain pretty inactive
>
> Thanks
>
> Agus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Wed Jun 30 18:30:42 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 30 Jun 2010 18:30:42 +0200 (CEST)
Subject: [R-sig-Geo] sp.correlogram
In-Reply-To: <AANLkTinP7WIjBprfBBmwKup1jqnEH5A2xZdBcP3oRtlO@mail.gmail.com>
References: <AANLkTikKZg6Ta7PZf_HtiCPKC5r-P6WgSh73kZESoe5M@mail.gmail.com>
	<AANLkTinkqXnYOc3IXpMk_Ng5AY4_topc6I_4y8W3nYsv@mail.gmail.com>
	<alpine.LRH.2.00.1006241414400.15824@reclus.nhh.no>
	<AANLkTik6XXescBfUQtRkevCJD8M74B8pVkhKqiS0mswW@mail.gmail.com>
	<AANLkTinP7WIjBprfBBmwKup1jqnEH5A2xZdBcP3oRtlO@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1006301827410.7515@reclus.nhh.no>

On Mon, 28 Jun 2010, Robert Pazur wrote:

> Dear all,
>
> according to perfect recommendations I perform moran.test  from "spdep"
> package. My datasets - csv X,Y tables has 90 000 rows representing 90 000
> regular points. In order to obtain morans correlogram I did a batch run and
> my plan is to obtain autocorrelation values up to 3000 meters
> distance.  However according to my hardware limitations I  just came to to
> 170 meters value of the dnearneigh -neighbours of region points by Euclidean
> distance function (dnr_170 <- dnearneigh(pointd_r, 0, 170). After this I
> receive well know memory allocation error problem. R in my machine runs on
> 32-bit Windows xp version, with just 2 GB of RAM. Is there some way to
> overcome this issue?

Are you perhaps not deleting the previous large objects that you have 
created? Look at ls(), and use rm() and gc() to get rid of unneeded 
objects. If you are careful, you may do save() before rm(), to have a copy 
of the nb or listw object for each step. If I recall, your points are in a 
grid 20m apart, so you might also consider using other approaches to this.

Roger

> Thanks in advance.
>
> Robert Pazur
>
>
> -------------------------------------------------------
> Robert Pazur
> PhD student
> Institute of Geography
> Slovak Academy Of Sciences
>
> Mobile : +421 948 001 705
> Skype  : ruegdeg
>
>
> 2010/6/24 Robert Pazur <pazurrobert at gmail.com>
>
>> Thank you very much for wonderful reply! Its exactly what i was looking for
>> last couple of hours.
>> Its incredible smart tool!
>> Kind regards,
>> Robert.
>>
>>
>>
>>
>>
>>
>> 2010/6/24 Roger Bivand <Roger.Bivand at nhh.no>
>>
>> On Thu, 24 Jun 2010, Robert Pazur wrote:
>>>
>>>  Dear all,
>>>>
>>>> I would like to perform Moran'I correlogram (sp.correlogram method in
>>>> spdep
>>>> package) based on euclidian fixed distances  but I have following
>>>> problem:
>>>> I created an artificial table, containing long and lati of regular points
>>>>
>>>>> points <-read.table("http://www.scandinavia.sk/data/moran5.csv",
>>>>> sep=",",
>>>>>
>>>> header=T)
>>>> following the manual I also identified neighbours of region
>>>>
>>>>> dnb <- dnearneigh(as.matrix(points$long, points$lati), 0, 20, longlat=T)
>>>>>
>>>>
>>> No, from your helpful link to the data, you have projected coordinates,
>>> not geographical. In addition, your use of as.matrix() instead of cbind()
>>> has bad consequences:
>>>
>>> str(as.matrix(points$long, points$lati))
>>> str(cbind(points$long, points$lati))
>>>
>>> dnearneigh() will be revised to trap this.
>>>
>>> Had you said:
>>>
>>> coordinates(points) <- c("long", "lati")
>>>
>>> then:
>>>
>>> proj4string(points) <- CRS("+proj=longlat")
>>>
>>> you would have seen the problem, because the sp classes check for the
>>> bounds on objects.
>>>
>>> So after doing:
>>>
>>>
>>> points <-read.table("http://www.scandinavia.sk/data/moran5.csv", sep=",",
>>>  header=T)
>>> coordinates(points) <- c("long", "lati")
>>> dnb <- dnearneigh(points, 0, 20)
>>>
>>> you are good to go. Next step - how to replicate the ArcGIS Moran's I - is
>>> easy with the correct dnb:
>>>
>>> moran.test(points$GRID_CODE, listw=nb2listw(dnb, style="B"))
>>>
>>> You might use correlog() in pgirmess for distance bins, but you'll have
>>> more control over the bin boundaries by makin new sets of neighbours for
>>> your chosen bin thresholds.
>>>
>>> Hope this helps (and thank you for reverting to the list after writing to
>>> me directly 70 minutes earlier. List is always best).
>>>
>>> Roger
>>>
>>>
>>>  neighbours list
>>>>
>>>>> ME200.listw <- nb2listw(dnb, style="W", zero.policy=T)
>>>>>
>>>> but if I perform sp.correlogram function:
>>>>
>>>>> correl<-sp.correlogram(dnb, points$GRID_CODE, order = 2, method = "I",
>>>>>
>>>> style = "W", randomisation = TRUE, zero.policy = TRUE, spChk=NULL)
>>>> my results are :
>>>> Spatial correlogram for points$GRID_CODE
>>>> method: Moran's I
>>>>   estimate expectation   variance standard deviate Pr(I) two sided
>>>> 1 -0.0029855  -0.0344828  0.0019674           0.7101          0.4776
>>>> 2 -0.0044436  -0.0344828  0.0022585           0.6321          0.5273
>>>>
>>>> and if i perform this part of this task in Arcgis for the same point
>>>> shapefile Moran Calculation for Fixed distance band, Euclidian distance a
>>>> and 20m threshold, result of Moran coefficient is
>>>> (SpatialAutocorrelation moran GRID_CODE false "Fixed Distance Band"
>>>> "Euclidean Distance" None 20 # 0 0 0) results are:
>>>> Global Moran's I Summary
>>>> Moran's Index:   0.746511
>>>> Expected Index:  -0.003521
>>>> Variance:        0.001827
>>>> Z Score:         17.545122
>>>> p-value:         0.000000
>>>>
>>>> I would like to perform the same task like in Arcgis but for multiple
>>>> distances. However Arcgis cannot deal with large data with multiple
>>>> points,
>>>> thatswhy I
>>>> would like to use R. Its seems to me much better software, but
>>>> unfortunatelly I never use it (but I really want)
>>>> If you could give me some advice i will be very happy.
>>>>
>>>> Robert.
>>>>
>>>>
>>>> -------------------------------------------------------
>>>> Robert Pazur
>>>> PhD student
>>>> Institute of Geography
>>>> Slovak Academy Of Sciences
>>>>
>>>> Mobile : +421 948 001 705
>>>> Skype  : ruegdeg
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>
>>> --
>>> Roger Bivand
>>> Economic Geography Section, Department of Economics, Norwegian School of
>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Wed Jun 30 18:43:30 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 30 Jun 2010 18:43:30 +0200 (CEST)
Subject: [R-sig-Geo] errorsarlm out of memory (method Chebyshev
 undetected in help)
In-Reply-To: <AANLkTimW69kh5QWF0I-28p0tlKPEJ6y-IKTwtYZg5d_1@mail.gmail.com>
References: <AANLkTimW69kh5QWF0I-28p0tlKPEJ6y-IKTwtYZg5d_1@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1006301836230.7515@reclus.nhh.no>

On Sat, 26 Jun 2010, elaine kuo wrote:

> Thanks for reminding.
>
> method "Sparse" and "Chebyshev"" unavailable here

There is no method="Sparse", "Chebyshev" is in recent releases of spdep, 
yours is old.

>
> memry.size ()  TRUE=1535.12  / FALSE=1147.03
> memory.limit() size=NA  1535
>
> 1. spdep  ver 2.10.1
>
> 2. the code is as below.
>
> rm(list=ls())
> datam <-read.csv("c:/migration/M_R_20100618_t2.csv",header=T, row.names=1)
> dim(datam)
> datam[1,]
>
> #SAR err
> library(ncf)
> require (spdep)
>
> # Define coordinates, neighbours, and spatial weights
> coords<-cbind(datam$lat,datam$lon)
> coords<-as.matrix(coords)
>
> #Define neighbourhood (here distance 9)
> nb10<-dnearneigh(coords,0,9)    # 9
>
> #######################
> #Spatial weights, illustrated with coding style "W" (row standardized)
> nb10.w<-nb2listw(nb10, glist=NULL, style="W", zero.policy=FALSE)
>
> #style="C"(sums over all links to n), or"B"(binary) for method "Matrix"or
> "spam" in errorsarlm
> #"C" and "B" = symmetric but "W"(sums over all links to n), "S" = similar to
> symmertic
> #"U"(sums over all links to unity)  , "S"( variance-stabilizing coding )
>
>
> glm1<- glm (datam$bird_w~datam$topo_var)
> summary(glm1)
> res.glm1 <- residuals(glm1)
>
>
> #######################
> #1. Spatial SAR error model
> sem.nb10.w <- errorsarlm(glm1,

*NO* - the first argument to models is a formula, I'm afraid that you need 
to consult local help (from someone who can talk to you where you work) to 
sort out how to use R. This may be trying to extract the formula from 
glm1, but do not rely on this.

Once you start doing things properly (start with a small and simple 
example), you can scale up to harder things.

Roger


> listw=nb10.w,na.action=na.fail,tol.solve=1.0e-12)
> summary(sem.nb1.5.w) #Gives a summary of the SAR error model
> res.sem.nb1.5.w <- residuals(sem.nb1.5.w)
> #######################
>
>
>
>
> 3. error message
> method=default
> warnings
> cannot allocate vector of size 181.2 Mb
>> warnings()
> Warning messages:
> 1: In errorsarlm(glm1, listw = nb10.w, na.action = na.fail,  ... :
>  Reached total allocation of 1535Mb: see help(memory.size)
> 2: In errorsarlm(glm1, listw = nb10.w, na.action = na.fail,  ... :
>  Reached total allocation of 1535Mb: see help(memory.size)
> 3: In crossprod(WA) : Reached total allocation of 1535Mb: see
> help(memory.size)
> 4: In crossprod(WA) : Reached total allocation of 1535Mb: see
> help(memory.size)
> 5: In array(0, c(n, p)) :
>  Reached total allocation of 1535Mb: see help(memory.size)
> 6: In array(0, c(n, p)) :
>  Reached total allocation of 1535Mb: see help(memory.size)
> 7: In t.default(W) : Reached total allocation of 1535Mb: see
> help(memory.size)
> 8: In t.default(W) : Reached total allocation of 1535Mb: see
> help(memory.size)
> 9: Reached total allocation of 1535Mb: see help(memory.size)
> 10: Reached total allocation of 1535Mb: see help(memory.size)
> 11: In array(0, c(n, p)) :
>  Reached total allocation of 1535Mb: see help(memory.size)
> 12: In array(0, c(n, p)) :
>  Reached total allocation of 1535Mb: see help(memory.size)
> 13: In y[1L + 0L:(m - 1L) * (n + 1L)] <- x :
>  Reached total allocation of 1535Mb: see help(memory.size)
> 14: In y[1L + 0L:(m - 1L) * (n + 1L)] <- x :
>  Reached total allocation of 1535Mb: see help(memory.size)
> 15: In colnames(b) <- rownames(a) :
>  Reached total allocation of 1535Mb: see help(memory.size)
> 16: In colnames(b) <- rownames(a) :
>  Reached total allocation of 1535Mb: see help(memory.size)
> 17: In storage.mode(a) <- "double" :
>  Reached total allocation of 1535Mb: see help(memory.size)
> 18: In storage.mode(a) <- "double" :
>  Reached total allocation of 1535Mb: see help(memory.size)
> 19: In rownames(b) <- colnames(a) :
>  Reached total allocation of 1535Mb: see help(memory.size)
> 20: In rownames(b) <- colnames(a) :
>  Reached total allocation of 1535Mb: see help(memory.size)
> 21: In rownames(b) <- colnames(a) :
>  Reached total allocation of 1535Mb: see help(memory.size)
> 22: In rownames(b) <- colnames(a) :
>  Reached total allocation of 1535Mb: see help(memory.size)
>>
>
> method ="Matrix" (style ="B", the remaining part of code is identical as
> above)
>
> ?????????if (mean(as(last, "matrix")) < tol) { :
>  something lacking in TRUE/FALSE value
> ??????: ?????? 40 ????????? (??? warnings() ?????????)
> Warning messages:
> 1: In determinant(x, TRUE) : This version of the Matrix package returns
> |determinant(L)| instead of determinant(A), i.e., a
> *DIFFERENT* value.
> If still necessary, do change your code, following
> http://matrix.r-forge.r-project.org
>
> 2: In optimize(sar.error.f, interval = interval, maximum = TRUE,  ... :
>  NA/Inf is converted to the maximum positive value
> .........
> 23: In .local(object, ...) :
>  Reached total allocation of 1535Mb: see help(memory.size)
> 24: In .local(object, ...) :
>  Reached total allocation of 1535Mb: see help(memory.size)
>
> 25: In optimize(sar.error.f, interval = interval, maximum = TRUE,  ... :
>  NA/Inf is converted to the maximum positive value
> 40: the same
>
>
> method"spam"
> Loading required package: spam
> Package 'spam' is loaded. Spam version 0.22-0 (2010-06-08).
> Type demo( spam) for some demos, help( Spam) for an overview
> of this package.
> Help for individual functions is optained by adding the
> suffix '.spam' to the function name, e.g. 'help(chol.spam)'.
>
> Attaching package: 'spam'
>
>
>        The following object(s) are masked from package:Matrix :
>
>         norm
>
>
>        The following object(s) are masked from package:base :
>
>         backsolve,
>         forwardsolve
>
>> warnings()
> Warning messages:
> 1: package 'spam' was built under R version 2.10.1
> 2: In optimize(sar.error.f, interval = interval, maximum = TRUE,  ... :
>  NA/Inf is converted to the maximum positive value
> .....
> 16: the same
> 17: In t.spam(x) : Reached total allocation of 1535Mb: see help(memory.size)
> 18: In t.spam(x) : Reached total allocation of 1535Mb: see help(memory.size)
> 19: In optimize(sar.error.f, interval = interval, maximum = TRUE,  ... :
>  NA/Inf is converted to the maximum positive value
> ...
> 40:  the same
>
>
>
>
>
> On Fri, Jun 25, 2010 at 6:10 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Fri, 25 Jun 2010, elaine kuo wrote:
>>
>>  Dear List,
>>>
>>> I am using errorsarlm (spdep) to measure SAR autocorrelation but failed as
>>> detailed below.
>>>
>>> system: windows XP and Vista
>>> RAM : 2G (XP) and 4G(Vista)
>>>
>>> sample size : 4500
>>> variable: 4
>>> nb10<-dnearneigh(coords,0,9)
>>>
>>> the error issue: out of memory of 180 Mb
>>>
>>> The similar messages in the archive were checked and tried but failed to
>>> solve the issues.
>>> 1. enlarging the R space to 2047 Mb
>>> 2. updating the neighboring unit from 0.5 to 9
>>>
>>> Please kindly help how to solve the problem, for I found SAR and CAR seem
>>> to
>>> be more reliable for autocorrelation than autocovariate.
>>>
>>
>>
>> No, you have not included the verbatim code leading to the memory problem,
>> nor the output of traceback() after the error, nor the output of
>> sessionInfo() to tell us which versions of packages you are using. This is
>> almost certainly nothing to do with dnearneigh(), unless the (0, 9)
>> thresholds include all n observations as neighbours for each neighbour, and
>> even then the neighbour object would not be very large.
>>
>> Did you read the help page for errorsarlm() or spautolm()? No? Then do so
>> and look carefully at the method= argument. You are almost certainly using
>> the default method, which uses dense matrices. Use your choice of sparse or
>> approximation alternatives, for example "Matrix" for updating sparse
>> Cholesky Jacobians, or "Chebyshev" for a fast approximate Jacobians.
>>
>> Using sparse matrix methods to overcome memory constraints has been
>> mentioned on this and other lists many times. With n=25000 ther is no
>> problem on a 1GB machine, so your problem doesn't even count as large.
>>
>> The list isn't really an alternative for reading help pages, and crucially
>> accessing the references given on the help pages. I'll add a link to
>> ?do_ldet on the function fitting pages, and add LeSage J and RK Pace (2009)
>> Introduction to Spatial Econometrics. CRC Press, Boca Raton too, as this is
>> the key reference that is required reading in this area.
>>
>> Hope this helps,
>>
>> Roger
>>
>>
>>
>>> Thanks
>>>
>>> Elaine
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Wed Jun 30 18:52:08 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 30 Jun 2010 18:52:08 +0200 (CEST)
Subject: [R-sig-Geo] RE : question about autocov_dist function in
 "spdep" package
In-Reply-To: <B56D7C27B4408243B93FBC46ABECB5A0011A8CFBC7CA@EXCH-MBX-F.ulaval.ca>
References: <B56D7C27B4408243B93FBC46ABECB5A0011A8CFBC7C7@EXCH-MBX-F.ulaval.ca>,
	<alpine.LRH.2.00.1006252148310.21394@reclus.nhh.no>
	<B56D7C27B4408243B93FBC46ABECB5A0011A8CFBC7CA@EXCH-MBX-F.ulaval.ca>
Message-ID: <alpine.LRH.2.00.1006301844231.7515@reclus.nhh.no>

On Tue, 29 Jun 2010, Julien Beguin wrote:

> Thank you Roger for your fast response and Jenn for cc:ing your message 
> about autocov_dist in spdep. I am far to be a specialist in spatial 
> statistic and I know that autologistic models have been criticised in 
> inferential context (e.g. Dorman et al. ). Several authors (in ecology, 
> at least) also found it useful in prediction context (Betts et al.). I 
> guess that the debate might not be over...
>
> My objective is not to trust results of autologistic model without
> criticism but rather to compare them with other approaches (e.g. Moran 
> eigenvector, spatial regression, etc...).
>
> Sorry for my ignorance but what means:
>
> "general weights sum to zero". Is autocovariate term (not) calculated as 
> follows ? A = sum(wij*yj)/ sum(wij) where wij=1/euclidian distance 
> between i and j (for inverse distance). It is maybe a stupid question 
> but how could weights sum to zero?

No, it is A_i = sum_j(wij*yj)/ sum_j(wij)

So for some i, sum_j(wij) is zero, and A_1 = 0/0. If you are going to use 
general weigts, they should not sum to zero, but for some i, it is 
permitted. However, if you look at the code:

 		if (any(sapply(glist, function(x)
 			isTRUE(all.equal(sum(x), 0)))))
 			warning("zero sum general weights")

you will see that this is a warning, given properly when the condition is 
met. The code is the documentation here.

>
> Also, it is not false to say that I am asking to include a constant 
> vector of zeros, but only for points that have no neighbour in a single 
> region. Imagine a study area composed of 5 regions containing each N 
> presence/absence points with associated covariates. If I calculate the 
> autocovariate term for each region separately (with constant nbs) and 
> that for one region (not the others) the minimum distance between pair 
> of points < nbs value, it will crash for that region. It might be that 
> spatial autocorrelation vary from region to region, and that in a 
> specific region, A value based on a constant nbs among regions would be 
> zero (because of no neighbour) for that region.
>

What you said earlier was that you would encounter distance thresholds in 
data subsets for which no observations would have any neighbours. I have 
already explained that this is your problem.

Roger

> A GLMM with fixed factors: Y~ covariates + Autocovariate; and random 
> factors = 1|Region/Autocovariate could account for that, no?
>
> Thank you again for your time,
>
> Julien
> _______________________________________
> De : Roger Bivand [Roger.Bivand at nhh.no]
> Date d'envoi : 25 juin 2010 15:55
> ? : Julien Beguin
> Cc : r-sig-geo at stat.math.ethz.ch
> Objet : Re: [R-sig-Geo] question about autocov_dist function in "spdep" package
>
> On Fri, 25 Jun 2010, Julien Beguin wrote:
>
>> Dear list member,
>>
>> I am using the autocov_dist function in spdep on binary point data set
>> to estimate the autocovariate to be used in autologistic regression
>> (session info at the end):
>>
>> coords<-as.matrix(cbind(datafile$X_COORD, datafile$Y_COORD))
>> ac1 <- autocov_dist(datafile$binary_variable, coords, nbs=400, type = "inverse", zero.policy=TRUE)
>>
>> It works fine with large value of nbs. When nbs value is below the neibhorhood distance of some pairs of point I get warnings because of empty neighbors:
>>
>>> Warning messages: 1: In autocov_dist(datafile$binary_variable, coords,
>>> nbs = 400, type = "inverse", :
>
>>> With value 400 some points have no neighbours
>>> 2: In nb2listw(nb, glist = gl, style = style, zero.policy = zero.policy) :
>>> zero sum general weights
>>
>> It seems, but I might be wrong, that points with no neighbour have an
>> autocov_dist value of zero. Since it is what I want, it is ok for me.
>
> No, the general weights sum to zero, as it says, you are using inverse.
>
>> But if I decrease nbs value below the smallest neighbourhood distance
>> among pairs of points in my data set, I get an error message:
>>
>>> Error in nb2listw(nb, glist = gl, style = style, zero.policy = zero.policy) :
>>>  No valid observations
>>> In addition: Warning messages:
>>> 1: In autocov_dist(datafile$binary_variable, coords, nbs = 100, type = "inverse",  :
>>> With value 100 some points have no neighbours
>>> 2: In nb2listw(nb, glist = gl, style = style, zero.policy = zero.policy) :
>>>  zero sum general weights
>>
>> My question is as follows: why do autocov_dist function require that at
>> least one neighbor pair exists? and why not returning zero value for all
>> points when no any point has a neighbor?
>>
>> This might appear to be a strange question but in my case I estimating
>> autocov_dist for different spatial block in which the minimum distance
>> between points vary from block to block, but still I would like a commun
>> nbs value for all block.
>
> It does indeed seem very strange, as you are asking to include a constant
> vector of zeros, which will alias the constant. The function itself is a
> really bad idea, and is included only to show (see Dormann et al 2007)
> that using it is inferior to all other methods examined there. Trying to
> include a second zero constant doesn't seem well-founded, to put it
> mildly.
>
> Hope this helps,
>
> Roger
>
>>
>> Thank you for your help,
>>
>> Julien Beguin
>> --------------------
>> Ph.D. student
>> Laval University
>> Qu?bec, Canada
>>
>> SESSION INFO:
>>
>> R version 2.10.1 (2009-12-14)
>> i386-pc-mingw32
>> locale:
>> [1] LC_COLLATE=French_Canada.1252  LC_CTYPE=French_Canada.1252
>> [3] LC_MONETARY=French_Canada.1252 LC_NUMERIC=C
>> [5] LC_TIME=French_Canada.1252
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> other attached packages:
>> [1] spdep_0.5-4         spam_0.20-3         coda_0.13-4
>> [4] deldir_0.0-12       maptools_0.7-29     foreign_0.8-40
>> [7] nlme_3.1-96         MASS_7.3-4          Matrix_0.999375-33
>> [10] lattice_0.17-26     boot_1.2-41         sp_0.9-60
>> [13] compositions_1.01-1 robustbase_0.5-0-1  tensorA_0.31
>> [16] rgl_0.91
>> loaded via a namespace (and not attached):
>> [1] grid_2.10.1  tools_2.10.1
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From alobolistas at gmail.com  Wed Jun 30 19:08:20 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Wed, 30 Jun 2010 19:08:20 +0200
Subject: [R-sig-Geo] polygonValues (raster): Very slow
In-Reply-To: <34A485B9-0ECA-4E1F-8692-BAAB01BD2131@gmail.com>
References: <AANLkTikPNOMFUdF87TsWUcJCoqXX-Am7G5eeMXHDinPf@mail.gmail.com>
	<34A485B9-0ECA-4E1F-8692-BAAB01BD2131@gmail.com>
Message-ID: <AANLkTiniqpTkcXdOl7ZiC8fwKQVemVezq9VwYcKjER8o@mail.gmail.com>

The info looks interesting, as it claims to be a fast algorithm with
support for large files.
Unfortunately, it seems that the package cannot be downloaded any
more. At least the provided
link brings you to an empty space, files seem not to be in the casil.ucdavis.edu
any more and you end up in projects.atlas.ca.gov, where I've not been able
to find the files.

Agus

2010/6/30 Nikhil Kaza <nikhil.list at gmail.com>:
>
> This is not an R solution and I am not even sure if this speeds up your
> process. But in the past I have used starspan for this kind of work. It
> worked fairly well for me for large datasets. But it was a one off process
> that I didn't mind spending couple of hours. I also did a naive
> parallelization by breaking up the polygon files multiple parts and then
> assembling them back, ?but if you really need the accurate proportion of
> cell area of a cell that falls across two polygons, this strategy wont work.
>
> http://starspan.projects.atlas.ca.gov/doku/doku.php
>
>
>
> Nikhil Kaza
> Asst. Professor,
> City and Regional Planning
> University of North Carolina
>
> nikhil.list at gmail.com
>
> On Jun 30, 2010, at 10:12 AM, Agustin Lobo wrote:
>
>> Hi!
>> I'm trying:
>>
>>> eugrd025EFDC <- readOGR(dsn="eugrd025EFDC",layer="eugrd025EFDC")
>>
>> v <- polygonValues(p=eugrd025EFDC, Br, weights=TRUE)
>>
>> where
>>
>>> str(eugrd025EFDC,max.level=2)
>>
>> Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
>> ?..@ data ? ? ? :'data.frame': ?18000 obs. of ?5 variables:
>> ?..@ polygons ? :List of 18000
>> ?.. .. [list output truncated]
>> ?..@ plotOrder ?: int [1:18000] 17901 17900 17902 17903 17899 17898
>> 17904 17897 17905 17906 ...
>> ?..@ bbox ? ? ? : num [1:2, 1:2] 2484331 1314148 6575852 4328780
>> ?.. ..- attr(*, "dimnames")=List of 2
>> ?..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>>
>>> summary(Br)
>>
>> Cells: ?13967442
>> NAs ?: ?0
>>
>>
>> Min. ? ? ? 0.00
>> 1st Qu. ? ?0.00
>> Median ? ? 0.00
>> Mean ? ? ?48.82
>> 3rd Qu. ? ?0.00
>> Max. ? ?4999.00
>>
>> so quite large objects.
>>
>> The problem is that ?polygonValues() has been running (and not
>> completed the task) for
>> more than 2 h on a intel core i7 machine with 16 Gb RAM (Dell
>> Precision M6500), so a pretty powerful machine.
>> Is there any way I could speed up this process?
>> Also, is there anything I could do in order to take better advantage
>> of the 8 processing threads?
>> Currently, I see only 1 cpu working for R processes and the rest
>> remain pretty inactive
>>
>> Thanks
>>
>> Agus
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From r.hijmans at gmail.com  Wed Jun 30 19:15:31 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 30 Jun 2010 10:15:31 -0700
Subject: [R-sig-Geo] polygonValues (raster): Very slow
In-Reply-To: <AANLkTikPNOMFUdF87TsWUcJCoqXX-Am7G5eeMXHDinPf@mail.gmail.com>
References: <AANLkTikPNOMFUdF87TsWUcJCoqXX-Am7G5eeMXHDinPf@mail.gmail.com>
Message-ID: <AANLkTikbj5P2H-PF9K7b3gZC3aFCCcI1gjQIc3CJVQhu@mail.gmail.com>

Dear Agus,

You are extracting values for 18000 polygons for a high res raster.
That is going to take a while. And using "weights=TRUE" is also bad
(in terms of processing speed!); do you really need it?. You can do
some testing by subsetting the polygons object.

If the polygons are not overlapping, you could consider to do
polygonsToRaster and then zonal. That would likely be much faster (but
you would not have the weights).

I have not attempted to optimize polygonValues much and 'raster' does
not do multi-processor computations. I hope to have that implemented,
at least for some slower functions like this one, by the end of this
year.

Robert

On Wed, Jun 30, 2010 at 7:12 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
> Hi!
> I'm trying:
>
>> eugrd025EFDC <- readOGR(dsn="eugrd025EFDC",layer="eugrd025EFDC")
> v <- polygonValues(p=eugrd025EFDC, Br, weights=TRUE)
>
> where
>
>> str(eugrd025EFDC,max.level=2)
> Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
> ?..@ data ? ? ? :'data.frame': 18000 obs. of ?5 variables:
> ?..@ polygons ? :List of 18000
> ?.. .. [list output truncated]
> ?..@ plotOrder ?: int [1:18000] 17901 17900 17902 17903 17899 17898
> 17904 17897 17905 17906 ...
> ?..@ bbox ? ? ? : num [1:2, 1:2] 2484331 1314148 6575852 4328780
> ?.. ..- attr(*, "dimnames")=List of 2
> ?..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>
>> summary(Br)
> Cells: ?13967442
> NAs ?: ?0
>
>
> Min. ? ? ? 0.00
> 1st Qu. ? ?0.00
> Median ? ? 0.00
> Mean ? ? ?48.82
> 3rd Qu. ? ?0.00
> Max. ? ?4999.00
>
> so quite large objects.
>
> The problem is that ?polygonValues() has been running (and not
> completed the task) for
> more than 2 h on a intel core i7 machine with 16 Gb RAM (Dell
> Precision M6500), so a pretty powerful machine.
> Is there any way I could speed up this process?
> Also, is there anything I could do in order to take better advantage
> of the 8 processing threads?
> Currently, I see only 1 cpu working for R processes and the rest
> remain pretty inactive
>
> Thanks
>
> Agus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From nikhil.list at gmail.com  Wed Jun 30 19:23:09 2010
From: nikhil.list at gmail.com (Nikhil Kaza)
Date: Wed, 30 Jun 2010 13:23:09 -0400
Subject: [R-sig-Geo] polygonValues (raster): Very slow
In-Reply-To: <AANLkTikbj5P2H-PF9K7b3gZC3aFCCcI1gjQIc3CJVQhu@mail.gmail.com>
References: <AANLkTikPNOMFUdF87TsWUcJCoqXX-Am7G5eeMXHDinPf@mail.gmail.com>
	<AANLkTikbj5P2H-PF9K7b3gZC3aFCCcI1gjQIc3CJVQhu@mail.gmail.com>
Message-ID: <1BB5DE54-C7D1-4692-8752-D6153B2044E0@gmail.com>

I second that you should reconsider weights argument and zonal  
statistics are much faster.


In case you wanted starspan download here it is

http://projects.atlas.ca.gov/frs/?group_id=48


Nikhil Kaza
Asst. Professor,
City and Regional Planning
University of North Carolina

nikhil.list at gmail.com

On Jun 30, 2010, at 1:15 PM, Robert J. Hijmans wrote:

> Dear Agus,
>
> You are extracting values for 18000 polygons for a high res raster.
> That is going to take a while. And using "weights=TRUE" is also bad
> (in terms of processing speed!); do you really need it?. You can do
> some testing by subsetting the polygons object.
>
> If the polygons are not overlapping, you could consider to do
> polygonsToRaster and then zonal. That would likely be much faster (but
> you would not have the weights).
>
> I have not attempted to optimize polygonValues much and 'raster' does
> not do multi-processor computations. I hope to have that implemented,
> at least for some slower functions like this one, by the end of this
> year.
>
> Robert
>
> On Wed, Jun 30, 2010 at 7:12 AM, Agustin Lobo  
> <alobolistas at gmail.com> wrote:
>> Hi!
>> I'm trying:
>>
>>> eugrd025EFDC <- readOGR(dsn="eugrd025EFDC",layer="eugrd025EFDC")
>> v <- polygonValues(p=eugrd025EFDC, Br, weights=TRUE)
>>
>> where
>>
>>> str(eugrd025EFDC,max.level=2)
>> Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
>>  ..@ data       :'data.frame': 18000 obs. of  5 variables:
>>  ..@ polygons   :List of 18000
>>  .. .. [list output truncated]
>>  ..@ plotOrder  : int [1:18000] 17901 17900 17902 17903 17899 17898
>> 17904 17897 17905 17906 ...
>>  ..@ bbox       : num [1:2, 1:2] 2484331 1314148 6575852 4328780
>>  .. ..- attr(*, "dimnames")=List of 2
>>  ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>>
>>> summary(Br)
>> Cells:  13967442
>> NAs  :  0
>>
>>
>> Min.       0.00
>> 1st Qu.    0.00
>> Median     0.00
>> Mean      48.82
>> 3rd Qu.    0.00
>> Max.    4999.00
>>
>> so quite large objects.
>>
>> The problem is that  polygonValues() has been running (and not
>> completed the task) for
>> more than 2 h on a intel core i7 machine with 16 Gb RAM (Dell
>> Precision M6500), so a pretty powerful machine.
>> Is there any way I could speed up this process?
>> Also, is there anything I could do in order to take better advantage
>> of the 8 processing threads?
>> Currently, I see only 1 cpu working for R processes and the rest
>> remain pretty inactive
>>
>> Thanks
>>
>> Agus
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Wed Jun 30 19:32:27 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 30 Jun 2010 10:32:27 -0700
Subject: [R-sig-Geo] Raster:memory or disk?
In-Reply-To: <792840.94188.qm@web23704.mail.ird.yahoo.com>
References: <AANLkTikGzK7e3vMBqEfe4nZjoew9hg1cW-WyB1Mv12za@mail.gmail.com>
	<792840.94188.qm@web23704.mail.ird.yahoo.com>
Message-ID: <AANLkTikUd5bmmCF5q887sjx22TBOWouT8rWmFwAySGIQ@mail.gmail.com>

> Is there any way to check if the values of a raster object
> are in memory or in disk?

Also have a look at "dataContent"

> library(raster)
> r  <- raster(system.file("external/test.grd", package="raster"))
> dataSource(r)
[1] "disk"
> dataContent(r)
[1] "nodata"
>
> r <- readAll(r)
> dataSource(r)
[1] "disk"
> dataContent(r)
[1] "all"
>
> r <- r + 1
> dataSource(r)
[1] "ram"
> dataContent(r)
[1] "all"
>
> r <- raster(r)
> dataSource(r)
[1] "ram"
> dataContent(r)
[1] "nodata"


((note: This is subject to changes in the near future. In past
versions, you could have several values for dataContent (row, rows,
block) that are no longer allowed. With only two values left for both
functions, in the future this will become valuesFromDisk (TRUE or
FALSE), and valuesInMemory (TRUE or FALSE) ))


>
> --- On Wed, 30/6/10, Agustin Lobo <alobolistas at gmail.com> wrote:
>
> From: Agustin Lobo <alobolistas at gmail.com>
> Subject: [R-sig-Geo] Raster:memory or disk?
> To: "r-sig-geo" <r-sig-geo at stat.math.ethz.ch>
> Cc: agustin.lobo at ija.csic.es
> Date: Wednesday, 30 June, 2010, 13:58
>
> Hi!
>
> Is there any way to check if the values of a raster object
> are in memory or in disk?
>
> For example
> r10 <- raster("2000_TSDP_IP-INVDIST-SP10_43023435.tif")
> b <- r10
>
> I understand that values of r10 are not loaded in memory
> but b is completely in memory (am I wrong?)
> How could I actually verify this?
>
> Thanks
>
> Agus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From alobolistas at gmail.com  Wed Jun 30 20:10:59 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Wed, 30 Jun 2010 20:10:59 +0200
Subject: [R-sig-Geo] polygonValues (raster): Very slow
In-Reply-To: <1BB5DE54-C7D1-4692-8752-D6153B2044E0@gmail.com>
References: <AANLkTikPNOMFUdF87TsWUcJCoqXX-Am7G5eeMXHDinPf@mail.gmail.com>
	<AANLkTikbj5P2H-PF9K7b3gZC3aFCCcI1gjQIc3CJVQhu@mail.gmail.com>
	<1BB5DE54-C7D1-4692-8752-D6153B2044E0@gmail.com>
Message-ID: <AANLkTinyxhszOPBGTgBiqyNOMA3r13EiZ9qccoC2jQr9@mail.gmail.com>

Yes, you are both right. Actually, shame to me: the better the
machine, the more careless the user!

1. Weights are not really needed, as the polygons are much larger than
the pixels. Ignoring those pixels not
having their center in the polygon is good enough.
2. A lot (~40%) of the polygons actually lie over the ocean or over
continents for which the raster
has no data. Therefore I must discard the unnecessary polygons first.
I think I can do this with maptools,
but can do it outside R as well. The only problem is that I would
prefer not having broken polygons, so
polygons should be either kept or eliminated.

The polygons actually come from a grid. The raster is a map of %cover
of Betula in Europe that we
have to coarsen to an specified grid for a model of atmospheric
transport that we expect will predict
pollen abundance, which we'll check against data from pollen sampling stations.

The grid is not aligned to the raster, this is why I'm using a polygon
and a raster instead of 2 raster layers.
But I can reconsider this if using 2 raster layer is faster.

Thanks!

Agus

2010/6/30 Nikhil Kaza <nikhil.list at gmail.com>:
> I second that you should reconsider weights argument and zonal statistics
> are much faster.
>
>
> In case you wanted starspan download here it is
>
> http://projects.atlas.ca.gov/frs/?group_id=48
>
>
> Nikhil Kaza
> Asst. Professor,
> City and Regional Planning
> University of North Carolina
>
> nikhil.list at gmail.com
>
> On Jun 30, 2010, at 1:15 PM, Robert J. Hijmans wrote:
>
>> Dear Agus,
>>
>> You are extracting values for 18000 polygons for a high res raster.
>> That is going to take a while. And using "weights=TRUE" is also bad
>> (in terms of processing speed!); do you really need it?. You can do
>> some testing by subsetting the polygons object.
>>
>> If the polygons are not overlapping, you could consider to do
>> polygonsToRaster and then zonal. That would likely be much faster (but
>> you would not have the weights).
>>
>> I have not attempted to optimize polygonValues much and 'raster' does
>> not do multi-processor computations. I hope to have that implemented,
>> at least for some slower functions like this one, by the end of this
>> year.
>>
>> Robert
>>
>> On Wed, Jun 30, 2010 at 7:12 AM, Agustin Lobo <alobolistas at gmail.com>
>> wrote:
>>>
>>> Hi!
>>> I'm trying:
>>>
>>>> eugrd025EFDC <- readOGR(dsn="eugrd025EFDC",layer="eugrd025EFDC")
>>>
>>> v <- polygonValues(p=eugrd025EFDC, Br, weights=TRUE)
>>>
>>> where
>>>
>>>> str(eugrd025EFDC,max.level=2)
>>>
>>> Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
>>> ?..@ data ? ? ? :'data.frame': 18000 obs. of ?5 variables:
>>> ?..@ polygons ? :List of 18000
>>> ?.. .. [list output truncated]
>>> ?..@ plotOrder ?: int [1:18000] 17901 17900 17902 17903 17899 17898
>>> 17904 17897 17905 17906 ...
>>> ?..@ bbox ? ? ? : num [1:2, 1:2] 2484331 1314148 6575852 4328780
>>> ?.. ..- attr(*, "dimnames")=List of 2
>>> ?..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>>>
>>>> summary(Br)
>>>
>>> Cells: ?13967442
>>> NAs ?: ?0
>>>
>>>
>>> Min. ? ? ? 0.00
>>> 1st Qu. ? ?0.00
>>> Median ? ? 0.00
>>> Mean ? ? ?48.82
>>> 3rd Qu. ? ?0.00
>>> Max. ? ?4999.00
>>>
>>> so quite large objects.
>>>
>>> The problem is that ?polygonValues() has been running (and not
>>> completed the task) for
>>> more than 2 h on a intel core i7 machine with 16 Gb RAM (Dell
>>> Precision M6500), so a pretty powerful machine.
>>> Is there any way I could speed up this process?
>>> Also, is there anything I could do in order to take better advantage
>>> of the 8 processing threads?
>>> Currently, I see only 1 cpu working for R processes and the rest
>>> remain pretty inactive
>>>
>>> Thanks
>>>
>>> Agus
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From r.hijmans at gmail.com  Wed Jun 30 20:20:32 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 30 Jun 2010 11:20:32 -0700
Subject: [R-sig-Geo] polygonValues (raster): Very slow
In-Reply-To: <AANLkTinyxhszOPBGTgBiqyNOMA3r13EiZ9qccoC2jQr9@mail.gmail.com>
References: <AANLkTikPNOMFUdF87TsWUcJCoqXX-Am7G5eeMXHDinPf@mail.gmail.com>
	<AANLkTikbj5P2H-PF9K7b3gZC3aFCCcI1gjQIc3CJVQhu@mail.gmail.com>
	<1BB5DE54-C7D1-4692-8752-D6153B2044E0@gmail.com>
	<AANLkTinyxhszOPBGTgBiqyNOMA3r13EiZ9qccoC2jQr9@mail.gmail.com>
Message-ID: <AANLkTikdL4hRzmE8Z8yPDtpRrpH5B4KtQbY2hd8qD24r@mail.gmail.com>

Agus, You should be able to use raster::resample to align the grids;
particularly if you are coarsening the data anyway. Treating a raster
as polygons is asking for trouble; even with big machines. Robert



On Wed, Jun 30, 2010 at 11:10 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
> Yes, you are both right. Actually, shame to me: the better the
> machine, the more careless the user!
>
> 1. Weights are not really needed, as the polygons are much larger than
> the pixels. Ignoring those pixels not
> having their center in the polygon is good enough.
> 2. A lot (~40%) of the polygons actually lie over the ocean or over
> continents for which the raster
> has no data. Therefore I must discard the unnecessary polygons first.
> I think I can do this with maptools,
> but can do it outside R as well. The only problem is that I would
> prefer not having broken polygons, so
> polygons should be either kept or eliminated.
>
> The polygons actually come from a grid. The raster is a map of %cover
> of Betula in Europe that we
> have to coarsen to an specified grid for a model of atmospheric
> transport that we expect will predict
> pollen abundance, which we'll check against data from pollen sampling stations.
>
> The grid is not aligned to the raster, this is why I'm using a polygon
> and a raster instead of 2 raster layers.
> But I can reconsider this if using 2 raster layer is faster.
>
> Thanks!
>
> Agus
>
> 2010/6/30 Nikhil Kaza <nikhil.list at gmail.com>:
>> I second that you should reconsider weights argument and zonal statistics
>> are much faster.
>>
>>
>> In case you wanted starspan download here it is
>>
>> http://projects.atlas.ca.gov/frs/?group_id=48
>>
>>
>> Nikhil Kaza
>> Asst. Professor,
>> City and Regional Planning
>> University of North Carolina
>>
>> nikhil.list at gmail.com
>>
>> On Jun 30, 2010, at 1:15 PM, Robert J. Hijmans wrote:
>>
>>> Dear Agus,
>>>
>>> You are extracting values for 18000 polygons for a high res raster.
>>> That is going to take a while. And using "weights=TRUE" is also bad
>>> (in terms of processing speed!); do you really need it?. You can do
>>> some testing by subsetting the polygons object.
>>>
>>> If the polygons are not overlapping, you could consider to do
>>> polygonsToRaster and then zonal. That would likely be much faster (but
>>> you would not have the weights).
>>>
>>> I have not attempted to optimize polygonValues much and 'raster' does
>>> not do multi-processor computations. I hope to have that implemented,
>>> at least for some slower functions like this one, by the end of this
>>> year.
>>>
>>> Robert
>>>
>>> On Wed, Jun 30, 2010 at 7:12 AM, Agustin Lobo <alobolistas at gmail.com>
>>> wrote:
>>>>
>>>> Hi!
>>>> I'm trying:
>>>>
>>>>> eugrd025EFDC <- readOGR(dsn="eugrd025EFDC",layer="eugrd025EFDC")
>>>>
>>>> v <- polygonValues(p=eugrd025EFDC, Br, weights=TRUE)
>>>>
>>>> where
>>>>
>>>>> str(eugrd025EFDC,max.level=2)
>>>>
>>>> Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
>>>> ?..@ data ? ? ? :'data.frame': 18000 obs. of ?5 variables:
>>>> ?..@ polygons ? :List of 18000
>>>> ?.. .. [list output truncated]
>>>> ?..@ plotOrder ?: int [1:18000] 17901 17900 17902 17903 17899 17898
>>>> 17904 17897 17905 17906 ...
>>>> ?..@ bbox ? ? ? : num [1:2, 1:2] 2484331 1314148 6575852 4328780
>>>> ?.. ..- attr(*, "dimnames")=List of 2
>>>> ?..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>>>>
>>>>> summary(Br)
>>>>
>>>> Cells: ?13967442
>>>> NAs ?: ?0
>>>>
>>>>
>>>> Min. ? ? ? 0.00
>>>> 1st Qu. ? ?0.00
>>>> Median ? ? 0.00
>>>> Mean ? ? ?48.82
>>>> 3rd Qu. ? ?0.00
>>>> Max. ? ?4999.00
>>>>
>>>> so quite large objects.
>>>>
>>>> The problem is that ?polygonValues() has been running (and not
>>>> completed the task) for
>>>> more than 2 h on a intel core i7 machine with 16 Gb RAM (Dell
>>>> Precision M6500), so a pretty powerful machine.
>>>> Is there any way I could speed up this process?
>>>> Also, is there anything I could do in order to take better advantage
>>>> of the 8 processing threads?
>>>> Currently, I see only 1 cpu working for R processes and the rest
>>>> remain pretty inactive
>>>>
>>>> Thanks
>>>>
>>>> Agus
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>


From alobolistas at gmail.com  Wed Jun 30 20:25:21 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Wed, 30 Jun 2010 20:25:21 +0200
Subject: [R-sig-Geo] mapproject
In-Reply-To: <AANLkTinGKwqyHWbi3fmJ-iROnY_RbmDpEREmQBLP3Jll@mail.gmail.com>
References: <AANLkTinKL_lozMQ2mxaxOnpq2Marh_pSOaNJnMh0riYc@mail.gmail.com>
	<AANLkTinGKwqyHWbi3fmJ-iROnY_RbmDpEREmQBLP3Jll@mail.gmail.com>
Message-ID: <AANLkTilu9GssvrCz4WB3Zv9H1reD-FZGW40U-gK5wP5_@mail.gmail.com>

True, thanks. I actually think that I have used spTransform in the past.

The problem was that I searched the help system for "reprojection"
and "projection", and spTransform did not come up.
Maybe both keywords can be included in the documentation of spTransform ?

Agus

2010/6/30 Michael Sumner <mdsumner at gmail.com>:
> I think rgdal package would be the preferable way. There are some old
> and outdated map projection packages (I admittedly do not not the
> details, and use rgdal exclusively).
>
> library(rgdal)
> eugrd025DF.laea <- spTransform(eugrd025DF, CRS(projection(Br)))
>
> spTransform() handles all the details of back and forward transforming
> (see inv argument in project) so that valid CRS() projection strings
> can be used directly to specify reprojections.
>
> I'm not intimate yet with the raster package so I might have missed
> something that's possible in the way the CRS string is derived by
> projection, but if proj4string(eugrd025DF) gives the same value as
> projection(eugrd025DF) then the spTransform approach should be fine.
>
> Cheers, Mike.
>
> On Wed, Jun 30, 2010 at 10:51 PM, Agustin Lobo <alobolistas at gmail.com> wrote:
>> I have a SpPolDF in geographic coordinates (eugrd025DF) and must reproject it
>> to the projection of a raster object (Br):
>>> projection(eugrd025DF)
>> [1] "+proj=longlat +ellps=WGS84"
>>
>>> projection(Br)
>> [1] "+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000
>> +ellps=GRS80 +units=m +no_defs"
>>
>> Can I do this with mapproject (package mapproj) os is it better to
>> export to shape file, reproject
>> with a GIS and import back? If it's possible/convenient, how to write
>> the parameters argument
>> in mapproject()?
>>
>> Thanks
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From alobolistas at gmail.com  Wed Jun 30 20:35:24 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Wed, 30 Jun 2010 20:35:24 +0200
Subject: [R-sig-Geo] polygonValues (raster): Very slow
In-Reply-To: <AANLkTikdL4hRzmE8Z8yPDtpRrpH5B4KtQbY2hd8qD24r@mail.gmail.com>
References: <AANLkTikPNOMFUdF87TsWUcJCoqXX-Am7G5eeMXHDinPf@mail.gmail.com>
	<AANLkTikbj5P2H-PF9K7b3gZC3aFCCcI1gjQIc3CJVQhu@mail.gmail.com>
	<1BB5DE54-C7D1-4692-8752-D6153B2044E0@gmail.com>
	<AANLkTinyxhszOPBGTgBiqyNOMA3r13EiZ9qccoC2jQr9@mail.gmail.com>
	<AANLkTikdL4hRzmE8Z8yPDtpRrpH5B4KtQbY2hd8qD24r@mail.gmail.com>
Message-ID: <AANLkTikYeK70t9PBvOoIH-9gsUaiaDgCWcPJsmyeZkHg@mail.gmail.com>

Yes, right. Once not using weights, keep using the vector is not that
much advantage.
Except that with the vector I can discard the cells for which the
original raster has no data.
But this is not going to compensate. I'll try both and let you know.

Thanks a lot for your help.

Agus

2010/6/30 Robert J. Hijmans <r.hijmans at gmail.com>:
> Agus, You should be able to use raster::resample to align the grids;
> particularly if you are coarsening the data anyway. Treating a raster
> as polygons is asking for trouble; even with big machines. Robert
>
>
>
> On Wed, Jun 30, 2010 at 11:10 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
>> Yes, you are both right. Actually, shame to me: the better the
>> machine, the more careless the user!
>>
>> 1. Weights are not really needed, as the polygons are much larger than
>> the pixels. Ignoring those pixels not
>> having their center in the polygon is good enough.
>> 2. A lot (~40%) of the polygons actually lie over the ocean or over
>> continents for which the raster
>> has no data. Therefore I must discard the unnecessary polygons first.
>> I think I can do this with maptools,
>> but can do it outside R as well. The only problem is that I would
>> prefer not having broken polygons, so
>> polygons should be either kept or eliminated.
>>
>> The polygons actually come from a grid. The raster is a map of %cover
>> of Betula in Europe that we
>> have to coarsen to an specified grid for a model of atmospheric
>> transport that we expect will predict
>> pollen abundance, which we'll check against data from pollen sampling stations.
>>
>> The grid is not aligned to the raster, this is why I'm using a polygon
>> and a raster instead of 2 raster layers.
>> But I can reconsider this if using 2 raster layer is faster.
>>
>> Thanks!
>>
>> Agus
>>
>> 2010/6/30 Nikhil Kaza <nikhil.list at gmail.com>:
>>> I second that you should reconsider weights argument and zonal statistics
>>> are much faster.
>>>
>>>
>>> In case you wanted starspan download here it is
>>>
>>> http://projects.atlas.ca.gov/frs/?group_id=48
>>>
>>>
>>> Nikhil Kaza
>>> Asst. Professor,
>>> City and Regional Planning
>>> University of North Carolina
>>>
>>> nikhil.list at gmail.com
>>>
>>> On Jun 30, 2010, at 1:15 PM, Robert J. Hijmans wrote:
>>>
>>>> Dear Agus,
>>>>
>>>> You are extracting values for 18000 polygons for a high res raster.
>>>> That is going to take a while. And using "weights=TRUE" is also bad
>>>> (in terms of processing speed!); do you really need it?. You can do
>>>> some testing by subsetting the polygons object.
>>>>
>>>> If the polygons are not overlapping, you could consider to do
>>>> polygonsToRaster and then zonal. That would likely be much faster (but
>>>> you would not have the weights).
>>>>
>>>> I have not attempted to optimize polygonValues much and 'raster' does
>>>> not do multi-processor computations. I hope to have that implemented,
>>>> at least for some slower functions like this one, by the end of this
>>>> year.
>>>>
>>>> Robert
>>>>
>>>> On Wed, Jun 30, 2010 at 7:12 AM, Agustin Lobo <alobolistas at gmail.com>
>>>> wrote:
>>>>>
>>>>> Hi!
>>>>> I'm trying:
>>>>>
>>>>>> eugrd025EFDC <- readOGR(dsn="eugrd025EFDC",layer="eugrd025EFDC")
>>>>>
>>>>> v <- polygonValues(p=eugrd025EFDC, Br, weights=TRUE)
>>>>>
>>>>> where
>>>>>
>>>>>> str(eugrd025EFDC,max.level=2)
>>>>>
>>>>> Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
>>>>> ?..@ data ? ? ? :'data.frame': 18000 obs. of ?5 variables:
>>>>> ?..@ polygons ? :List of 18000
>>>>> ?.. .. [list output truncated]
>>>>> ?..@ plotOrder ?: int [1:18000] 17901 17900 17902 17903 17899 17898
>>>>> 17904 17897 17905 17906 ...
>>>>> ?..@ bbox ? ? ? : num [1:2, 1:2] 2484331 1314148 6575852 4328780
>>>>> ?.. ..- attr(*, "dimnames")=List of 2
>>>>> ?..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>>>>>
>>>>>> summary(Br)
>>>>>
>>>>> Cells: ?13967442
>>>>> NAs ?: ?0
>>>>>
>>>>>
>>>>> Min. ? ? ? 0.00
>>>>> 1st Qu. ? ?0.00
>>>>> Median ? ? 0.00
>>>>> Mean ? ? ?48.82
>>>>> 3rd Qu. ? ?0.00
>>>>> Max. ? ?4999.00
>>>>>
>>>>> so quite large objects.
>>>>>
>>>>> The problem is that ?polygonValues() has been running (and not
>>>>> completed the task) for
>>>>> more than 2 h on a intel core i7 machine with 16 Gb RAM (Dell
>>>>> Precision M6500), so a pretty powerful machine.
>>>>> Is there any way I could speed up this process?
>>>>> Also, is there anything I could do in order to take better advantage
>>>>> of the 8 processing threads?
>>>>> Currently, I see only 1 cpu working for R processes and the rest
>>>>> remain pretty inactive
>>>>>
>>>>> Thanks
>>>>>
>>>>> Agus
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>
>


From r.hijmans at gmail.com  Wed Jun 30 20:48:23 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 30 Jun 2010 11:48:23 -0700
Subject: [R-sig-Geo] polygonValues (raster): Very slow
In-Reply-To: <AANLkTikYeK70t9PBvOoIH-9gsUaiaDgCWcPJsmyeZkHg@mail.gmail.com>
References: <AANLkTikPNOMFUdF87TsWUcJCoqXX-Am7G5eeMXHDinPf@mail.gmail.com>
	<AANLkTikbj5P2H-PF9K7b3gZC3aFCCcI1gjQIc3CJVQhu@mail.gmail.com>
	<1BB5DE54-C7D1-4692-8752-D6153B2044E0@gmail.com>
	<AANLkTinyxhszOPBGTgBiqyNOMA3r13EiZ9qccoC2jQr9@mail.gmail.com>
	<AANLkTikdL4hRzmE8Z8yPDtpRrpH5B4KtQbY2hd8qD24r@mail.gmail.com>
	<AANLkTikYeK70t9PBvOoIH-9gsUaiaDgCWcPJsmyeZkHg@mail.gmail.com>
Message-ID: <AANLkTinVN3Fphb9sh1tXIOEBObIl4ZtdqbRg-jkEu0JX@mail.gmail.com>

> Except that with the vector I can discard the cells for which the
> original raster has no data.

To speed up your original set-up you could perhaps also first do
"trim(x)"  to remove the outer rows and columns of the raster that
only have NA values. Perhaps after doing crop first.
r <- crop(r, polygons)
r <- trim(r)

Robert


On Wed, Jun 30, 2010 at 11:35 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
> Yes, right. Once not using weights, keep using the vector is not that
> much advantage.
> Except that with the vector I can discard the cells for which the
> original raster has no data.
> But this is not going to compensate. I'll try both and let you know.
>
> Thanks a lot for your help.
>
> Agus
>
> 2010/6/30 Robert J. Hijmans <r.hijmans at gmail.com>:
>> Agus, You should be able to use raster::resample to align the grids;
>> particularly if you are coarsening the data anyway. Treating a raster
>> as polygons is asking for trouble; even with big machines. Robert
>>
>>
>>
>> On Wed, Jun 30, 2010 at 11:10 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
>>> Yes, you are both right. Actually, shame to me: the better the
>>> machine, the more careless the user!
>>>
>>> 1. Weights are not really needed, as the polygons are much larger than
>>> the pixels. Ignoring those pixels not
>>> having their center in the polygon is good enough.
>>> 2. A lot (~40%) of the polygons actually lie over the ocean or over
>>> continents for which the raster
>>> has no data. Therefore I must discard the unnecessary polygons first.
>>> I think I can do this with maptools,
>>> but can do it outside R as well. The only problem is that I would
>>> prefer not having broken polygons, so
>>> polygons should be either kept or eliminated.
>>>
>>> The polygons actually come from a grid. The raster is a map of %cover
>>> of Betula in Europe that we
>>> have to coarsen to an specified grid for a model of atmospheric
>>> transport that we expect will predict
>>> pollen abundance, which we'll check against data from pollen sampling stations.
>>>
>>> The grid is not aligned to the raster, this is why I'm using a polygon
>>> and a raster instead of 2 raster layers.
>>> But I can reconsider this if using 2 raster layer is faster.
>>>
>>> Thanks!
>>>
>>> Agus
>>>
>>> 2010/6/30 Nikhil Kaza <nikhil.list at gmail.com>:
>>>> I second that you should reconsider weights argument and zonal statistics
>>>> are much faster.
>>>>
>>>>
>>>> In case you wanted starspan download here it is
>>>>
>>>> http://projects.atlas.ca.gov/frs/?group_id=48
>>>>
>>>>
>>>> Nikhil Kaza
>>>> Asst. Professor,
>>>> City and Regional Planning
>>>> University of North Carolina
>>>>
>>>> nikhil.list at gmail.com
>>>>
>>>> On Jun 30, 2010, at 1:15 PM, Robert J. Hijmans wrote:
>>>>
>>>>> Dear Agus,
>>>>>
>>>>> You are extracting values for 18000 polygons for a high res raster.
>>>>> That is going to take a while. And using "weights=TRUE" is also bad
>>>>> (in terms of processing speed!); do you really need it?. You can do
>>>>> some testing by subsetting the polygons object.
>>>>>
>>>>> If the polygons are not overlapping, you could consider to do
>>>>> polygonsToRaster and then zonal. That would likely be much faster (but
>>>>> you would not have the weights).
>>>>>
>>>>> I have not attempted to optimize polygonValues much and 'raster' does
>>>>> not do multi-processor computations. I hope to have that implemented,
>>>>> at least for some slower functions like this one, by the end of this
>>>>> year.
>>>>>
>>>>> Robert
>>>>>
>>>>> On Wed, Jun 30, 2010 at 7:12 AM, Agustin Lobo <alobolistas at gmail.com>
>>>>> wrote:
>>>>>>
>>>>>> Hi!
>>>>>> I'm trying:
>>>>>>
>>>>>>> eugrd025EFDC <- readOGR(dsn="eugrd025EFDC",layer="eugrd025EFDC")
>>>>>>
>>>>>> v <- polygonValues(p=eugrd025EFDC, Br, weights=TRUE)
>>>>>>
>>>>>> where
>>>>>>
>>>>>>> str(eugrd025EFDC,max.level=2)
>>>>>>
>>>>>> Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
>>>>>> ?..@ data ? ? ? :'data.frame': 18000 obs. of ?5 variables:
>>>>>> ?..@ polygons ? :List of 18000
>>>>>> ?.. .. [list output truncated]
>>>>>> ?..@ plotOrder ?: int [1:18000] 17901 17900 17902 17903 17899 17898
>>>>>> 17904 17897 17905 17906 ...
>>>>>> ?..@ bbox ? ? ? : num [1:2, 1:2] 2484331 1314148 6575852 4328780
>>>>>> ?.. ..- attr(*, "dimnames")=List of 2
>>>>>> ?..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>>>>>>
>>>>>>> summary(Br)
>>>>>>
>>>>>> Cells: ?13967442
>>>>>> NAs ?: ?0
>>>>>>
>>>>>>
>>>>>> Min. ? ? ? 0.00
>>>>>> 1st Qu. ? ?0.00
>>>>>> Median ? ? 0.00
>>>>>> Mean ? ? ?48.82
>>>>>> 3rd Qu. ? ?0.00
>>>>>> Max. ? ?4999.00
>>>>>>
>>>>>> so quite large objects.
>>>>>>
>>>>>> The problem is that ?polygonValues() has been running (and not
>>>>>> completed the task) for
>>>>>> more than 2 h on a intel core i7 machine with 16 Gb RAM (Dell
>>>>>> Precision M6500), so a pretty powerful machine.
>>>>>> Is there any way I could speed up this process?
>>>>>> Also, is there anything I could do in order to take better advantage
>>>>>> of the 8 processing threads?
>>>>>> Currently, I see only 1 cpu working for R processes and the rest
>>>>>> remain pretty inactive
>>>>>>
>>>>>> Thanks
>>>>>>
>>>>>> Agus
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>
>>>
>>
>


From Pierre.Racine at sbf.ulaval.ca  Wed Jun 30 22:14:22 2010
From: Pierre.Racine at sbf.ulaval.ca (Pierre Racine)
Date: Wed, 30 Jun 2010 16:14:22 -0400
Subject: [R-sig-Geo] polygonValues (raster): Very slow
In-Reply-To: <AANLkTikPNOMFUdF87TsWUcJCoqXX-Am7G5eeMXHDinPf@mail.gmail.com>
References: <AANLkTikPNOMFUdF87TsWUcJCoqXX-Am7G5eeMXHDinPf@mail.gmail.com>
Message-ID: <87A96661E65C5541AB4D20721C2DD7F880A316873F@EXCH-MBX-A.ulaval.ca>

Agustin,

PostGIS WKT Raster was made to do exactly this kind of operation on large datasets. Give it a try!

http://trac.osgeo.org/postgis/wiki/WKTRasterTutorial01

Pierre

>-----Original Message-----
>From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
>Agustin Lobo
>Sent: 30 juin 2010 10:13
>To: r-sig-geo
>Cc: agustin.lobo at ija.csic.es
>Subject: [R-sig-Geo] polygonValues (raster): Very slow
>
>Hi!
>I'm trying:
>
>> eugrd025EFDC <- readOGR(dsn="eugrd025EFDC",layer="eugrd025EFDC")
>v <- polygonValues(p=eugrd025EFDC, Br, weights=TRUE)
>
>where
>
>> str(eugrd025EFDC,max.level=2)
>Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
>  ..@ data       :'data.frame':        18000 obs. of  5 variables:
>  ..@ polygons   :List of 18000
>  .. .. [list output truncated]
>  ..@ plotOrder  : int [1:18000] 17901 17900 17902 17903 17899 17898
>17904 17897 17905 17906 ...
>  ..@ bbox       : num [1:2, 1:2] 2484331 1314148 6575852 4328780
>  .. ..- attr(*, "dimnames")=List of 2
>  ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>
>> summary(Br)
>Cells:  13967442
>NAs  :  0
>
>
>Min.       0.00
>1st Qu.    0.00
>Median     0.00
>Mean      48.82
>3rd Qu.    0.00
>Max.    4999.00
>
>so quite large objects.
>
>The problem is that  polygonValues() has been running (and not
>completed the task) for
>more than 2 h on a intel core i7 machine with 16 Gb RAM (Dell
>Precision M6500), so a pretty powerful machine.
>Is there any way I could speed up this process?
>Also, is there anything I could do in order to take better advantage
>of the 8 processing threads?
>Currently, I see only 1 cpu working for R processes and the rest
>remain pretty inactive
>
>Thanks
>
>Agus
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at stat.math.ethz.ch
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo


