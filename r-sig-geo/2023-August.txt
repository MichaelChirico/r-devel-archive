From j@@onede|k|nd @end|ng |rom @o|@com  Sun Aug  6 22:23:08 2023
From: j@@onede|k|nd @end|ng |rom @o|@com (Jason Edelkind)
Date: Sun, 6 Aug 2023 15:23:08 -0500
Subject: [R-sig-Geo] Did I correctly convert my data from UTM zone 12 to 11?
References: <00383000-0C7B-47B4-AB3B-9A2DFAFA92E9.ref@aol.com>
Message-ID: <00383000-0C7B-47B4-AB3B-9A2DFAFA92E9@aol.com>

?hello, first time user here and aspiring grad student. I have a set of location data that I?ve been trying to import into google earth engine from R as a CSV file. The problem is that about half of my data is from utm zone 12, and the other half is from utm zone 11. When I import my original data into google earth engine, the zone 11 data is shifted over to the right because I use utm zone 12 as the crs in R. After some reading into the definition of a utm zone, I tried to just subtract 6 from the zone 11 latitude values after first converting them to a lon/lat format. This appears to have worked as on first glance all of the zone 11 points are where they should be, however it feels like too easy a fix for me after struggling with this for several days. So my question is, is this an acceptable way to convert my data, or am I doing something wrong that could result in inaccurate location data? Thanks!

From md@umner @end|ng |rom gm@||@com  Mon Aug  7 01:26:32 2023
From: md@umner @end|ng |rom gm@||@com (Michael Sumner)
Date: Mon, 7 Aug 2023 09:26:32 +1000
Subject: [R-sig-Geo] 
 Did I correctly convert my data from UTM zone 12 to 11?
In-Reply-To: <00383000-0C7B-47B4-AB3B-9A2DFAFA92E9@aol.com>
References: <00383000-0C7B-47B4-AB3B-9A2DFAFA92E9.ref@aol.com>
 <00383000-0C7B-47B4-AB3B-9A2DFAFA92E9@aol.com>
Message-ID: <CAAcGz99UCV1AwYMhg3Km+sa0nL-Ccjg5Bogaizr2YCuuWHjeyw@mail.gmail.com>

You should treat the different sets of coordinates (from Zone 11 and Zone
12) completely separately. You cannot have mixed crs (of projected
coordinates) in a dataset. When you plot in R (generally, even with popular
spatial formats) there is no account taken of crs, the graphics doesn't
know that you plot Zone 11 and then (say) add coordinates from Zone 12,
they will be "shifted" as you say.  (There are exceptions to this plotting
rule but apart from ggplot2::coord_sf they are in dusty corners not front
and centre of plotting code in R).

Some level of coordinate hackery (arithmetic shifting) *can work*  in
limited circumstances, but I would highly recommend against that. Separate
your coordinates into two objects, set the source crs appropriately of the
zone for each, transform each to a common crs.

 (UTM is generally a bad idea but comes with a very popular usage culture
which is a shame, there's no single right choice but you always need to put
thought into the overall region of your data, the properties of the
coordinate space that make sense for your work, and whether you will need
smaller or larger regions in the future for related work ... I would advise
a common crs that is *not UTM* but advice there really depends on the
details of your situation).

It's hard to be more specific without details of your flow, e.g. code
examples.

HTH, Mike





On Mon, Aug 7, 2023 at 6:23?AM Jason Edelkind via R-sig-Geo <
r-sig-geo at r-project.org> wrote:

> hello, first time user here and aspiring grad student. I have a set of
> location data that I?ve been trying to import into google earth engine from
> R as a CSV file. The problem is that about half of my data is from utm zone
> 12, and the other half is from utm zone 11. When I import my original data
> into google earth engine, the zone 11 data is shifted over to the right
> because I use utm zone 12 as the crs in R. After some reading into the
> definition of a utm zone, I tried to just subtract 6 from the zone 11
> latitude values after first converting them to a lon/lat format. This
> appears to have worked as on first glance all of the zone 11 points are
> where they should be, however it feels like too easy a fix for me after
> struggling with this for several days. So my question is, is this an
> acceptable way to convert my data, or am I doing something wrong that could
> result in inaccurate location data? Thanks!
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


-- 
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com

	[[alternative HTML version deleted]]


From m@ur|z|o@m@rch| @end|ng |rom cnr@|t  Mon Aug  7 12:21:04 2023
From: m@ur|z|o@m@rch| @end|ng |rom cnr@|t (MAURIZIO MARCHI)
Date: Mon, 7 Aug 2023 10:21:04 +0000
Subject: [R-sig-Geo] 
 Did I correctly convert my data from UTM zone 12 to 11?
Message-ID: <E7FF0584-CDB5-4F82-9231-9A8F737EE507@cnr.it>

? I strongly agree with Michael Sumner. Mathematical adjustments may work but are heavily discouraged. The right way to work is to create two different spatial objects (I recommend to use the vect function of terra package) and then to reproject one of them in the other reference system or both in a common projection as for example EPSG:4326 or something like that. After that you can merge the two spatial objects in a single one or extract the new spatial coordinates to rewrite a new .csv file to be used outside R

--
Maurizio Marchi,
PhD Forest Science - Ecological Modelling
Researcher
CNR - Institute of Biosciences and BioResources (IBBR), Florence Research Area, Sesto Fiorentino (Italy)
SkypeID: maurizioxyz

https://scholar.google.com/citations?user=_2X6fu8AAAAJ&hl=en

#####------#####
EUFGIS National Focal Point for Italy (www.eufgis.org<http://www.eufgis.org/>)
Scopus Author ID: 57188626512
ResearcherID: T-3813-2019
https://ibbr.cnr.it/climate-dt/

Il giorno 7 ago 2023, alle ore 12:02, r-sig-geo-request at r-project.org ha scritto:

?Send R-sig-Geo mailing list submissions to
   r-sig-geo at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
   https://stat.ethz.ch/mailman/listinfo/r-sig-geo
or, via email, send a message with subject or body 'help' to
   r-sig-geo-request at r-project.org

You can reach the person managing the list at
   r-sig-geo-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-Geo digest..."


Today's Topics:

  1. Did I correctly convert my data from UTM zone 12 to 11?
     (Jason Edelkind)
  2. Re:  Did I correctly convert my data from UTM zone 12 to 11?
     (Michael Sumner)

----------------------------------------------------------------------

Message: 1
Date: Sun, 6 Aug 2023 15:23:08 -0500
From: Jason Edelkind <jasonedelkind at aol.com>
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] Did I correctly convert my data from UTM zone 12
   to 11?
Message-ID: <00383000-0C7B-47B4-AB3B-9A2DFAFA92E9 at aol.com>
Content-Type: text/plain; charset="utf-8"

?hello, first time user here and aspiring grad student. I have a set of location data that I?ve been trying to import into google earth engine from R as a CSV file. The problem is that about half of my data is from utm zone 12, and the other half is from utm zone 11. When I import my original data into google earth engine, the zone 11 data is shifted over to the right because I use utm zone 12 as the crs in R. After some reading into the definition of a utm zone, I tried to just subtract 6 from the zone 11 latitude values after first converting them to a lon/lat format. This appears to have worked as on first glance all of the zone 11 points are where they should be, however it feels like too easy a fix for me after struggling with this for several days. So my question is, is this an acceptable way to convert my data, or am I doing something wrong that could result in inaccurate location data? Thanks!



------------------------------

Message: 2
Date: Mon, 7 Aug 2023 09:26:32 +1000
From: Michael Sumner <mdsumner at gmail.com>
To: Jason Edelkind <jasonedelkind at aol.com>
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo]  Did I correctly convert my data from UTM
   zone 12 to 11?
Message-ID:
   <CAAcGz99UCV1AwYMhg3Km+sa0nL-Ccjg5Bogaizr2YCuuWHjeyw at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

You should treat the different sets of coordinates (from Zone 11 and Zone
12) completely separately. You cannot have mixed crs (of projected
coordinates) in a dataset. When you plot in R (generally, even with popular
spatial formats) there is no account taken of crs, the graphics doesn't
know that you plot Zone 11 and then (say) add coordinates from Zone 12,
they will be "shifted" as you say.  (There are exceptions to this plotting
rule but apart from ggplot2::coord_sf they are in dusty corners not front
and centre of plotting code in R).

Some level of coordinate hackery (arithmetic shifting) *can work*  in
limited circumstances, but I would highly recommend against that. Separate
your coordinates into two objects, set the source crs appropriately of the
zone for each, transform each to a common crs.

(UTM is generally a bad idea but comes with a very popular usage culture
which is a shame, there's no single right choice but you always need to put
thought into the overall region of your data, the properties of the
coordinate space that make sense for your work, and whether you will need
smaller or larger regions in the future for related work ... I would advise
a common crs that is *not UTM* but advice there really depends on the
details of your situation).

It's hard to be more specific without details of your flow, e.g. code
examples.

HTH, Mike





On Mon, Aug 7, 2023 at 6:23?AM Jason Edelkind via R-sig-Geo <
r-sig-geo at r-project.org> wrote:

hello, first time user here and aspiring grad student. I have a set of
location data that I?ve been trying to import into google earth engine from
R as a CSV file. The problem is that about half of my data is from utm zone
12, and the other half is from utm zone 11. When I import my original data
into google earth engine, the zone 11 data is shifted over to the right
because I use utm zone 12 as the crs in R. After some reading into the
definition of a utm zone, I tried to just subtract 6 from the zone 11
latitude values after first converting them to a lon/lat format. This
appears to have worked as on first glance all of the zone 11 points are
where they should be, however it feels like too easy a fix for me after
struggling with this for several days. So my question is, is this an
acceptable way to convert my data, or am I doing something wrong that could
result in inaccurate location data? Thanks!
_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



--
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com

   [[alternative HTML version deleted]]




------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


------------------------------

End of R-sig-Geo Digest, Vol 240, Issue 1
*****************************************

	[[alternative HTML version deleted]]


From kev|n @end|ng |rom zembower@org  Mon Aug  7 20:33:41 2023
From: kev|n @end|ng |rom zembower@org (Kevin Zembower)
Date: Mon, 7 Aug 2023 18:33:41 +0000
Subject: [R-sig-Geo] Calculating median age for a group of US census blocks?
References: <c83c0fa5-e069-6436-0ba6-8ecd518264fd@zembower.org>
Message-ID: <01000189d146bd0d-ecb41aac-0501-46f4-b313-a1faebeff2a9-000000@email.amazonses.com>

Hello, all,

I'd like to obtain the median age for a population in a specific group 
of US Decennial census blocks. Here's an example of the problem:

## Example of calculating median age of population in census blocks.
library(tidyverse)
library(tidycensus)

counts <- get_decennial(
     geography = "block",
     state = "MD",
     county = "Baltimore city",
     table = "P1",
     year = 2020,
     sumfile = "dhc") %>%
     mutate(NAME = NULL) %>%
     filter(substr(GEOID, 6, 11) == "271101" &
            substr(GEOID, 12, 15) %in% c(3000, 3001, 3002)
            )

ages <- get_decennial(
     geography = "block",
     state = "MD",
     county = "Baltimore city",
     table = "P13",
     year = 2020,
     sumfile = "dhc") %>%
     mutate(NAME = NULL) %>%
     filter(substr(GEOID, 6, 11) == "271101" &
            substr(GEOID, 12, 15) %in% c(3000, 3001, 3002)
            )

I have two questions:

1. Is it mathematically valid to multiply the population of a block by 
the median age of that block (in other words, assign the median age to 
each member of a block), then calculate the median of those numbers for 
a group of blocks?

2. Is raw data on the ages of individuals available anywhere else in the 
census data? I can find tables such as P12, that breaks down the 
population by age ranges or bins, but can't find specific data of counts 
per age in years.

Thanks for your advice and help.

-Kevin


From jo@|@h@p@rry @end|ng |rom gm@||@com  Mon Aug  7 20:38:16 2023
From: jo@|@h@p@rry @end|ng |rom gm@||@com (Josiah Parry)
Date: Mon, 7 Aug 2023 14:38:16 -0400
Subject: [R-sig-Geo] 
 Calculating median age for a group of US census blocks?
In-Reply-To: <01000189d146bd0d-ecb41aac-0501-46f4-b313-a1faebeff2a9-000000@email.amazonses.com>
References: <c83c0fa5-e069-6436-0ba6-8ecd518264fd@zembower.org>
 <01000189d146bd0d-ecb41aac-0501-46f4-b313-a1faebeff2a9-000000@email.amazonses.com>
Message-ID: <CAL3ufUJVvcZvdtYM2V0tmo9U-RMZ1zOGL8NZDhjK7V8GFc77HA@mail.gmail.com>

Hey Kevin, I don't think you're going to be able to get individual level
data from the US Census Bureau. The closest you may be able to get is the
current population survey (CPS) which I believe is also available via
tidycensus. Regarding your first question, I'm not sure I follow what your
objective is with it. I would use a geography of census block groups as the
measure of median for census block groups. Otherwise it is unclear how you
are defining what a "group of blocks" is.

On Mon, Aug 7, 2023 at 2:34?PM Kevin Zembower via R-sig-Geo <
r-sig-geo at r-project.org> wrote:

> Hello, all,
>
> I'd like to obtain the median age for a population in a specific group
> of US Decennial census blocks. Here's an example of the problem:
>
> ## Example of calculating median age of population in census blocks.
> library(tidyverse)
> library(tidycensus)
>
> counts <- get_decennial(
>      geography = "block",
>      state = "MD",
>      county = "Baltimore city",
>      table = "P1",
>      year = 2020,
>      sumfile = "dhc") %>%
>      mutate(NAME = NULL) %>%
>      filter(substr(GEOID, 6, 11) == "271101" &
>             substr(GEOID, 12, 15) %in% c(3000, 3001, 3002)
>             )
>
> ages <- get_decennial(
>      geography = "block",
>      state = "MD",
>      county = "Baltimore city",
>      table = "P13",
>      year = 2020,
>      sumfile = "dhc") %>%
>      mutate(NAME = NULL) %>%
>      filter(substr(GEOID, 6, 11) == "271101" &
>             substr(GEOID, 12, 15) %in% c(3000, 3001, 3002)
>             )
>
> I have two questions:
>
> 1. Is it mathematically valid to multiply the population of a block by
> the median age of that block (in other words, assign the median age to
> each member of a block), then calculate the median of those numbers for
> a group of blocks?
>
> 2. Is raw data on the ages of individuals available anywhere else in the
> census data? I can find tables such as P12, that breaks down the
> population by age ranges or bins, but can't find specific data of counts
> per age in years.
>
> Thanks for your advice and help.
>
> -Kevin
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From @trende @end|ng |rom re@|c|e@rpo||t|c@@com  Mon Aug  7 20:45:48 2023
From: @trende @end|ng |rom re@|c|e@rpo||t|c@@com (Sean Trende)
Date: Mon, 7 Aug 2023 18:45:48 +0000
Subject: [R-sig-Geo] 
 Calculating median age for a group of US census blocks?
In-Reply-To: <CAL3ufUJVvcZvdtYM2V0tmo9U-RMZ1zOGL8NZDhjK7V8GFc77HA@mail.gmail.com>
References: <c83c0fa5-e069-6436-0ba6-8ecd518264fd@zembower.org>
 <01000189d146bd0d-ecb41aac-0501-46f4-b313-a1faebeff2a9-000000@email.amazonses.com>
 <CAL3ufUJVvcZvdtYM2V0tmo9U-RMZ1zOGL8NZDhjK7V8GFc77HA@mail.gmail.com>
Message-ID: <BLAPR20MB39382F6CD501D6B1ED8F2C11BE0CA@BLAPR20MB3938.namprd20.prod.outlook.com>

This is correct on the second question, at least for more recent censuses.  On the first question, imagine a block where the ages of three individuals are 60, 50, and 40, and another one where the ages are 20, 20, and 20.  Using your approach you would have 50 * 3 = 150 for the first block, and 20*3 = 60 for the second block.  The median of 60 and 150 is 105.  Even dividing that by three you get 35, which is not the correct median age (30).

-----Original Message-----
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> On Behalf Of Josiah Parry
Sent: Monday, August 7, 2023 2:38 PM
To: Kevin Zembower <kevin at zembower.org>
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] Calculating median age for a group of US census blocks?

Hey Kevin, I don't think you're going to be able to get individual level data from the US Census Bureau. The closest you may be able to get is the current population survey (CPS) which I believe is also available via tidycensus. Regarding your first question, I'm not sure I follow what your objective is with it. I would use a geography of census block groups as the measure of median for census block groups. Otherwise it is unclear how you are defining what a "group of blocks" is.

On Mon, Aug 7, 2023 at 2:34?PM Kevin Zembower via R-sig-Geo < r-sig-geo at r-project.org> wrote:

> Hello, all,
>
> I'd like to obtain the median age for a population in a specific group 
> of US Decennial census blocks. Here's an example of the problem:
>
> ## Example of calculating median age of population in census blocks.
> library(tidyverse)
> library(tidycensus)
>
> counts <- get_decennial(
>      geography = "block",
>      state = "MD",
>      county = "Baltimore city",
>      table = "P1",
>      year = 2020,
>      sumfile = "dhc") %>%
>      mutate(NAME = NULL) %>%
>      filter(substr(GEOID, 6, 11) == "271101" &
>             substr(GEOID, 12, 15) %in% c(3000, 3001, 3002)
>             )
>
> ages <- get_decennial(
>      geography = "block",
>      state = "MD",
>      county = "Baltimore city",
>      table = "P13",
>      year = 2020,
>      sumfile = "dhc") %>%
>      mutate(NAME = NULL) %>%
>      filter(substr(GEOID, 6, 11) == "271101" &
>             substr(GEOID, 12, 15) %in% c(3000, 3001, 3002)
>             )
>
> I have two questions:
>
> 1. Is it mathematically valid to multiply the population of a block by 
> the median age of that block (in other words, assign the median age to 
> each member of a block), then calculate the median of those numbers 
> for a group of blocks?
>
> 2. Is raw data on the ages of individuals available anywhere else in 
> the census data? I can find tables such as P12, that breaks down the 
> population by age ranges or bins, but can't find specific data of 
> counts per age in years.
>
> Thanks for your advice and help.
>
> -Kevin
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

From kev|n @end|ng |rom zembower@org  Mon Aug  7 20:52:33 2023
From: kev|n @end|ng |rom zembower@org (Kevin Zembower)
Date: Mon, 7 Aug 2023 18:52:33 +0000
Subject: [R-sig-Geo] 
 Calculating median age for a group of US census blocks?
In-Reply-To: <BLAPR20MB39382F6CD501D6B1ED8F2C11BE0CA@BLAPR20MB3938.namprd20.prod.outlook.com>
References: <c83c0fa5-e069-6436-0ba6-8ecd518264fd@zembower.org> 
 <01000189d146bd0d-ecb41aac-0501-46f4-b313-a1faebeff2a9-000000@email.amazonses.com>
 <CAL3ufUJVvcZvdtYM2V0tmo9U-RMZ1zOGL8NZDhjK7V8GFc77HA@mail.gmail.com> 
 <BLAPR20MB39382F6CD501D6B1ED8F2C11BE0CA@BLAPR20MB3938.namprd20.prod.outlook.com>
 <4c7bbebf-3851-0835-b684-29a8e9d753e5@zembower.org>
Message-ID: <01000189d1580211-8b8fa766-f820-4ae9-862b-e98e1a4881bf-000000@email.amazonses.com>

Yes, I see what you mean:

 > median(c(60, 50, 40, 20, 20, 20))
[1] 30
 > median(c(50, 50, 50, 20, 20, 20))
[1] 35
 >

Thanks so much for that clear example.

-Kevin

On 8/7/23 14:45, Sean Trende wrote:
> This is correct on the second question, at least for more recent censuses.  On the first question, imagine a block where the ages of three individuals are 60, 50, and 40, and another one where the ages are 20, 20, and 20.  Using your approach you would have 50 * 3 = 150 for the first block, and 20*3 = 60 for the second block.  The median of 60 and 150 is 105.  Even dividing that by three you get 35, which is not the correct median age (30).
> 
> -----Original Message-----
> From: R-sig-Geo <r-sig-geo-bounces at r-project.org> On Behalf Of Josiah Parry
> Sent: Monday, August 7, 2023 2:38 PM
> To: Kevin Zembower <kevin at zembower.org>
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] Calculating median age for a group of US census blocks?
> 
> Hey Kevin, I don't think you're going to be able to get individual level data from the US Census Bureau. The closest you may be able to get is the current population survey (CPS) which I believe is also available via tidycensus. Regarding your first question, I'm not sure I follow what your objective is with it. I would use a geography of census block groups as the measure of median for census block groups. Otherwise it is unclear how you are defining what a "group of blocks" is.
> 
> On Mon, Aug 7, 2023 at 2:34?PM Kevin Zembower via R-sig-Geo < r-sig-geo at r-project.org> wrote:
> 
>> Hello, all,
>>
>> I'd like to obtain the median age for a population in a specific group
>> of US Decennial census blocks. Here's an example of the problem:
>>
>> ## Example of calculating median age of population in census blocks.
>> library(tidyverse)
>> library(tidycensus)
>>
>> counts <- get_decennial(
>>       geography = "block",
>>       state = "MD",
>>       county = "Baltimore city",
>>       table = "P1",
>>       year = 2020,
>>       sumfile = "dhc") %>%
>>       mutate(NAME = NULL) %>%
>>       filter(substr(GEOID, 6, 11) == "271101" &
>>              substr(GEOID, 12, 15) %in% c(3000, 3001, 3002)
>>              )
>>
>> ages <- get_decennial(
>>       geography = "block",
>>       state = "MD",
>>       county = "Baltimore city",
>>       table = "P13",
>>       year = 2020,
>>       sumfile = "dhc") %>%
>>       mutate(NAME = NULL) %>%
>>       filter(substr(GEOID, 6, 11) == "271101" &
>>              substr(GEOID, 12, 15) %in% c(3000, 3001, 3002)
>>              )
>>
>> I have two questions:
>>
>> 1. Is it mathematically valid to multiply the population of a block by
>> the median age of that block (in other words, assign the median age to
>> each member of a block), then calculate the median of those numbers
>> for a group of blocks?
>>
>> 2. Is raw data on the ages of individuals available anywhere else in
>> the census data? I can find tables such as P12, that breaks down the
>> population by age ranges or bins, but can't find specific data of
>> counts per age in years.
>>
>> Thanks for your advice and help.
>>
>> -Kevin
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From jbogg@ @end|ng |rom brocku@c@  Mon Aug  7 20:53:05 2023
From: jbogg@ @end|ng |rom brocku@c@ (Jeff Boggs)
Date: Mon, 7 Aug 2023 18:53:05 +0000
Subject: [R-sig-Geo] 
 Calculating median age for a group of US census blocks?
In-Reply-To: <01000189d146bd0d-ecb41aac-0501-46f4-b313-a1faebeff2a9-000000@email.amazonses.com>
References: <c83c0fa5-e069-6436-0ba6-8ecd518264fd@zembower.org>
 <01000189d146bd0d-ecb41aac-0501-46f4-b313-a1faebeff2a9-000000@email.amazonses.com>
Message-ID: <YT3PR01MB91703A158414A8F28FB4052FC00CA@YT3PR01MB9170.CANPRD01.PROD.OUTLOOK.COM>

Responses to your questions:
Q1: No. It is not mathematically valid, sadly.

Q2: I do not know, but your intuition that this is a possible solution is correct.

I don't use US Census data anymore, but suspect that the data exists. Whether they are publicly-available is a different question. I suspect, though, that block level age-sex cohort in five-year intervals is available, given this is the usual ingredient for a population pyramid. That data could be used to calculate a less exact median, if you make some simplifying assumptions.

Best regards,
Jeff


________________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of Kevin Zembower via R-sig-Geo <r-sig-geo at r-project.org>
Sent: Monday, August 7, 2023 14:33
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] Calculating median age for a group of US census blocks?

Hello, all,

I'd like to obtain the median age for a population in a specific group
of US Decennial census blocks. Here's an example of the problem:

## Example of calculating median age of population in census blocks.
library(tidyverse)
library(tidycensus)

counts <- get_decennial(
     geography = "block",
     state = "MD",
     county = "Baltimore city",
     table = "P1",
     year = 2020,
     sumfile = "dhc") %>%
     mutate(NAME = NULL) %>%
     filter(substr(GEOID, 6, 11) == "271101" &
            substr(GEOID, 12, 15) %in% c(3000, 3001, 3002)
            )

ages <- get_decennial(
     geography = "block",
     state = "MD",
     county = "Baltimore city",
     table = "P13",
     year = 2020,
     sumfile = "dhc") %>%
     mutate(NAME = NULL) %>%
     filter(substr(GEOID, 6, 11) == "271101" &
            substr(GEOID, 12, 15) %in% c(3000, 3001, 3002)
            )

I have two questions:

1. Is it mathematically valid to multiply the population of a block by
the median age of that block (in other words, assign the median age to
each member of a block), then calculate the median of those numbers for
a group of blocks?

2. Is raw data on the ages of individuals available anywhere else in the
census data? I can find tables such as P12, that breaks down the
population by age ranges or bins, but can't find specific data of counts
per age in years.

Thanks for your advice and help.

-Kevin

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From kev|n @end|ng |rom zembower@org  Mon Aug  7 21:00:38 2023
From: kev|n @end|ng |rom zembower@org (Kevin Zembower)
Date: Mon, 7 Aug 2023 19:00:38 +0000
Subject: [R-sig-Geo] 
 Calculating median age for a group of US census blocks?
In-Reply-To: <CAL3ufUJVvcZvdtYM2V0tmo9U-RMZ1zOGL8NZDhjK7V8GFc77HA@mail.gmail.com>
References: <c83c0fa5-e069-6436-0ba6-8ecd518264fd@zembower.org> 
 <01000189d146bd0d-ecb41aac-0501-46f4-b313-a1faebeff2a9-000000@email.amazonses.com>
 <CAL3ufUJVvcZvdtYM2V0tmo9U-RMZ1zOGL8NZDhjK7V8GFc77HA@mail.gmail.com> 
 <65caf2f5-4ca2-fe64-de52-a48120f75051@zembower.org>
Message-ID: <01000189d15f6aa3-d32ffe39-a210-436f-9f8f-cc551370f034-000000@email.amazonses.com>

Josiah, thanks for your reply.

Regarding my objective, I'm trying to compile census statistics for the 
blocks that make up the neighborhood where I live. It consists of ten 
census blocks, of which I selected three for simplicity in my example. 
The census block-group which contains these ten blocks also contains 
some blocks which are outside of my neighborhood and shouldn't be 
counted or included.

Since I won't be able to calculate the median age from the age and count 
data, and since the individual data doesn't seem to be available, is it 
your thought that I can't produce a valid median age for a group of 
census blocks?

Thanks so much for your advice.

-Kevin

On 8/7/23 14:38, Josiah Parry wrote:
> Hey Kevin, I don't think you're going to be able to get individual level 
> data from the US Census Bureau. The closest you may be able to get is 
> the current population survey (CPS) which I believe is also available 
> via tidycensus. Regarding your first question, I'm not sure I follow 
> what your objective is with it. I would use a geography of census block 
> groups as the measure of median for census block groups. Otherwise it is 
> unclear how you are defining what a "group of blocks" is.
> 
> On Mon, Aug 7, 2023 at 2:34?PM Kevin Zembower via R-sig-Geo 
> <r-sig-geo at r-project.org <mailto:r-sig-geo at r-project.org>> wrote:
> 
>     Hello, all,
> 
>     I'd like to obtain the median age for a population in a specific group
>     of US Decennial census blocks. Here's an example of the problem:
> 
>     ## Example of calculating median age of population in census blocks.
>     library(tidyverse)
>     library(tidycensus)
> 
>     counts <- get_decennial(
>      ? ? ?geography = "block",
>      ? ? ?state = "MD",
>      ? ? ?county = "Baltimore city",
>      ? ? ?table = "P1",
>      ? ? ?year = 2020,
>      ? ? ?sumfile = "dhc") %>%
>      ? ? ?mutate(NAME = NULL) %>%
>      ? ? ?filter(substr(GEOID, 6, 11) == "271101" &
>      ? ? ? ? ? ? substr(GEOID, 12, 15) %in% c(3000, 3001, 3002)
>      ? ? ? ? ? ? )
> 
>     ages <- get_decennial(
>      ? ? ?geography = "block",
>      ? ? ?state = "MD",
>      ? ? ?county = "Baltimore city",
>      ? ? ?table = "P13",
>      ? ? ?year = 2020,
>      ? ? ?sumfile = "dhc") %>%
>      ? ? ?mutate(NAME = NULL) %>%
>      ? ? ?filter(substr(GEOID, 6, 11) == "271101" &
>      ? ? ? ? ? ? substr(GEOID, 12, 15) %in% c(3000, 3001, 3002)
>      ? ? ? ? ? ? )
> 
>     I have two questions:
> 
>     1. Is it mathematically valid to multiply the population of a block by
>     the median age of that block (in other words, assign the median age to
>     each member of a block), then calculate the median of those numbers for
>     a group of blocks?
> 
>     2. Is raw data on the ages of individuals available anywhere else in
>     the
>     census data? I can find tables such as P12, that breaks down the
>     population by age ranges or bins, but can't find specific data of
>     counts
>     per age in years.
> 
>     Thanks for your advice and help.
> 
>     -Kevin
> 
>     _______________________________________________
>     R-sig-Geo mailing list
>     R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
> 



From dexter@|ocke @end|ng |rom gm@||@com  Mon Aug  7 21:43:50 2023
From: dexter@|ocke @end|ng |rom gm@||@com (Dexter Locke)
Date: Mon, 7 Aug 2023 15:43:50 -0400
Subject: [R-sig-Geo] 
 Calculating median age for a group of US census blocks?
In-Reply-To: <01000189d15f6aa3-d32ffe39-a210-436f-9f8f-cc551370f034-000000@email.amazonses.com>
References: <c83c0fa5-e069-6436-0ba6-8ecd518264fd@zembower.org>
 <01000189d146bd0d-ecb41aac-0501-46f4-b313-a1faebeff2a9-000000@email.amazonses.com>
 <65caf2f5-4ca2-fe64-de52-a48120f75051@zembower.org>
 <CAL3ufUJVvcZvdtYM2V0tmo9U-RMZ1zOGL8NZDhjK7V8GFc77HA@mail.gmail.com>
 <01000189d15f6aa3-d32ffe39-a210-436f-9f8f-cc551370f034-000000@email.amazonses.com>
Message-ID: <CAA=SVwHn=92B-k1tBZm2ioEW79gJx_QX0VD-x2UUEQOBQ+TEvg@mail.gmail.com>

Hi Kevin and all,

Given the binned data, you could count the number of people per age class
for those 10 blocks. You can then express that in a number of
different ways, like percent under 25 years old, or by calculating the
dependency
ratio
<https://www.who.int/data/gho/indicator-metadata-registry/imr-details/1119#:~:text=Definition%3A,a%20specific%20point%20in%20time.>
.

I do think it is feasible to calculate an estimated mean from the counts
within groups representing ranges. See, for example, here:
https://stackoverflow.com/questions/18887382/how-to-calculate-the-median-on-grouped-dataset

Since you are working in Baltimore, you may consider looking at The
Baltimore Neighborhood Indicators Alliance https://bniajfi.org/vital_signs/.
They provide useful data on a range of issues (transportation, crime,
education, environment etc.) including summaries from Census-derived
demographics. What you are seeking may already exist. BNIA creates
neighborhoods or "community statistical areas" (n=55) based on aggregates
of Census data.

Although not pertaining to age, Baltimore City Planning has paid Census in
the past to aggregate from individual-level Census data to the more
colloquially-used definitions of Baltimore shown here (n = 273):
https://data.baltimorecity.gov/datasets/neighborhood-1/explore?location=39.284832%2C-76.620516%2C12.91

Best, Dexter
https://dexterlocke.com/





On Mon, Aug 7, 2023 at 3:02?PM Kevin Zembower via R-sig-Geo <
r-sig-geo at r-project.org> wrote:

> Josiah, thanks for your reply.
>
> Regarding my objective, I'm trying to compile census statistics for the
> blocks that make up the neighborhood where I live. It consists of ten
> census blocks, of which I selected three for simplicity in my example.
> The census block-group which contains these ten blocks also contains
> some blocks which are outside of my neighborhood and shouldn't be
> counted or included.
>
> Since I won't be able to calculate the median age from the age and count
> data, and since the individual data doesn't seem to be available, is it
> your thought that I can't produce a valid median age for a group of
> census blocks?
>
> Thanks so much for your advice.
>
> -Kevin
>
> On 8/7/23 14:38, Josiah Parry wrote:
> > Hey Kevin, I don't think you're going to be able to get individual level
> > data from the US Census Bureau. The closest you may be able to get is
> > the current population survey (CPS) which I believe is also available
> > via tidycensus. Regarding your first question, I'm not sure I follow
> > what your objective is with it. I would use a geography of census block
> > groups as the measure of median for census block groups. Otherwise it is
> > unclear how you are defining what a "group of blocks" is.
> >
> > On Mon, Aug 7, 2023 at 2:34?PM Kevin Zembower via R-sig-Geo
> > <r-sig-geo at r-project.org <mailto:r-sig-geo at r-project.org>> wrote:
> >
> >     Hello, all,
> >
> >     I'd like to obtain the median age for a population in a specific
> group
> >     of US Decennial census blocks. Here's an example of the problem:
> >
> >     ## Example of calculating median age of population in census blocks.
> >     library(tidyverse)
> >     library(tidycensus)
> >
> >     counts <- get_decennial(
> >           geography = "block",
> >           state = "MD",
> >           county = "Baltimore city",
> >           table = "P1",
> >           year = 2020,
> >           sumfile = "dhc") %>%
> >           mutate(NAME = NULL) %>%
> >           filter(substr(GEOID, 6, 11) == "271101" &
> >                  substr(GEOID, 12, 15) %in% c(3000, 3001, 3002)
> >                  )
> >
> >     ages <- get_decennial(
> >           geography = "block",
> >           state = "MD",
> >           county = "Baltimore city",
> >           table = "P13",
> >           year = 2020,
> >           sumfile = "dhc") %>%
> >           mutate(NAME = NULL) %>%
> >           filter(substr(GEOID, 6, 11) == "271101" &
> >                  substr(GEOID, 12, 15) %in% c(3000, 3001, 3002)
> >                  )
> >
> >     I have two questions:
> >
> >     1. Is it mathematically valid to multiply the population of a block
> by
> >     the median age of that block (in other words, assign the median age
> to
> >     each member of a block), then calculate the median of those numbers
> for
> >     a group of blocks?
> >
> >     2. Is raw data on the ages of individuals available anywhere else in
> >     the
> >     census data? I can find tables such as P12, that breaks down the
> >     population by age ranges or bins, but can't find specific data of
> >     counts
> >     per age in years.
> >
> >     Thanks for your advice and help.
> >
> >     -Kevin
> >
> >     _______________________________________________
> >     R-sig-Geo mailing list
> >     R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
> >
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From @|||ch @end|ng |rom u@|@edu  Tue Aug  8 20:46:59 2023
From: @|||ch @end|ng |rom u@|@edu (Alexander Ilich)
Date: Tue, 8 Aug 2023 18:46:59 +0000
Subject: [R-sig-Geo] 
 Did I correctly convert my data from UTM zone 12 to 11?
In-Reply-To: <00383000-0C7B-47B4-AB3B-9A2DFAFA92E9@aol.com>
References: <00383000-0C7B-47B4-AB3B-9A2DFAFA92E9.ref@aol.com>
 <00383000-0C7B-47B4-AB3B-9A2DFAFA92E9@aol.com>
Message-ID: <BN0PR08MB73415A5F614F5330CE97DE3BC60CA@BN0PR08MB7341.namprd08.prod.outlook.com>

If the vast majority of your data was within one UTM zone and only a small amount bled over into the adjacent UTM zone then it'd probably just be ok to choose the one that contains the majority of your data and accept that there will be some distortion. Since it's roughly 50/50 though, you should either split the data into two data sets and perform calculations separately for each one, or transform them to a common projection (e.g. EPSG:4326 aka WGS84 aka lat/lon) and then perform the analysis. Most of this has been stated already, but I figured I'd point you to some tools as well that may help you. Rather than doing some work arounds that seem to get it to look right it'd be better to use tools specifically to transform between different projections. Based on what you wrote it seems like you're working with vector data. For vector data, the sf package in R is very comprehensive (though terra also has vector capabilities). The st_crs will let you check or manually set a projection for a data set, and the st_transform function will let you transform from one projection to another. Note the difference here is that st_crs will not change the coordinates, it will just assign the name of the coordinate system whereas st_transform will convert from one to the other. UTM is convenient in certain cases because it can make calculations simpler since you can assume the area is essentially flat over the space considered. That being said, the sf package many calculations can now be done using spherical geometry<https://r-spatial.org/book/04-Spherical.html> which will be more accurate (I'm not sure about google earth engine though as I haven't used it). Below is some R code to take a dataframe of coordinates (like from your CSV), define the projection as UTM 11 or UTM 12 in separate objects, and how to transform them to lat/lon and combine them into a single object.

``` r
library(sf)
#> Linking to GEOS 3.11.1, GDAL 3.6.2, PROJ 9.1.1; sf_use_s2() is TRUE

# Create Data frames of points (Here you would use read.csv)
UTM11<- data.frame(X = c(358334, 571173, 446818, 576082, 331892),
                   Y = c(5128282, 5105900, 4730385, 4667181, 4811548))

UTM12<- data.frame(X = c(405776, 614821, 428211, 602751, 366593),
                   Y = c(5132654, 5117139, 4841550, 4704516, 4625745))

#Have 2 separate objects with different crs
UTM11<- st_as_sf(UTM11, coords = c("X", "Y"))
st_crs(UTM11)<- "EPSG:32611" #Set crs (https://epsg.io/32611)

UTM12<- st_as_sf(UTM12, coords = c("X", "Y"))
st_crs(UTM12)<- "EPSG:32612" #Set crs (https://epsg.io/32612)

#Transform to common crs and merge
WGS84<- rbind(st_transform(UTM11, crs = "EPSG:4326"),
              st_transform(UTM12, crs = "EPSG:4326"))
```

<sup>Created on 2023-08-08 with [reprex v2.0.2](https://reprex.tidyverse.org)</sup>


________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of Jason Edelkind via R-sig-Geo <r-sig-geo at r-project.org>
Sent: Sunday, August 6, 2023 4:23 PM
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: [R-sig-Geo] Did I correctly convert my data from UTM zone 12 to 11?

hello, first time user here and aspiring grad student. I have a set of location data that I?ve been trying to import into google earth engine from R as a CSV file. The problem is that about half of my data is from utm zone 12, and the other half is from utm zone 11. When I import my original data into google earth engine, the zone 11 data is shifted over to the right because I use utm zone 12 as the crs in R. After some reading into the definition of a utm zone, I tried to just subtract 6 from the zone 11 latitude values after first converting them to a lon/lat format. This appears to have worked as on first glance all of the zone 11 points are where they should be, however it feels like too easy a fix for me after struggling with this for several days. So my question is, is this an acceptable way to convert my data, or am I doing something wrong that could result in inaccurate location data? Thanks!
_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=05%7C01%7Cailich%40usf.edu%7Cf73b5985c9d543c03e7508db96bb0824%7C741bf7dee2e546df8d6782607df9deaa%7C0%7C0%7C638269502289723854%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=T2BxWF1rCQPJmqKsVkbFR4%2F8xXrEh5iXM0XjhO634gc%3D&reserved=0<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.

	[[alternative HTML version deleted]]


From kev|n @end|ng |rom zembower@org  Tue Aug  8 21:31:50 2023
From: kev|n @end|ng |rom zembower@org (Kevin Zembower)
Date: Tue, 8 Aug 2023 19:31:50 +0000
Subject: [R-sig-Geo] 
 Calculating median age for a group of US census blocks?
In-Reply-To: <CAA=SVwHn=92B-k1tBZm2ioEW79gJx_QX0VD-x2UUEQOBQ+TEvg@mail.gmail.com>
References: <c83c0fa5-e069-6436-0ba6-8ecd518264fd@zembower.org> 
 <01000189d146bd0d-ecb41aac-0501-46f4-b313-a1faebeff2a9-000000@email.amazonses.com>
 <65caf2f5-4ca2-fe64-de52-a48120f75051@zembower.org> 
 <CAL3ufUJVvcZvdtYM2V0tmo9U-RMZ1zOGL8NZDhjK7V8GFc77HA@mail.gmail.com> 
 <01000189d15f6aa3-d32ffe39-a210-436f-9f8f-cc551370f034-000000@email.amazonses.com>
 <CAA=SVwHn=92B-k1tBZm2ioEW79gJx_QX0VD-x2UUEQOBQ+TEvg@mail.gmail.com> 
 <bf0744f6-5f16-0de8-7306-d874fabbd74e@zembower.org>
Message-ID: <01000189d6a25641-f946f382-89e2-4ffa-a59e-b0edff9bae58-000000@email.amazonses.com>


Dexter, Thanks so much for your reply. I wasn't aware of the two sources 
you cite, and I'll be sure to include them in my work.

The open Baltimore website, at 
https://data.baltimorecity.gov/datasets/neighborhood-1/explore, has 
statistics for my neighborhood, Radnor-Winston 
(https://radnorwinston.org).The Baltimore Neighborhood Indicators 
Alliance at https://bniajfi.org/vital_signs/ lumps us into North 
Baltimore/Guilford/Homeland, which, as I'm sure you're aware, contains 
many homes (mansions!) with very different characteristics than the 
people of Radnor-Winston.

Thanks, again, for your help and expertise. I learned a lot from your note.

-Kevin

On 8/7/23 15:43, Dexter Locke wrote:
> Hi Kevin and all,
> 
> Given the binned?data, you could count the number of people per age 
> class for those 10 blocks. You can then express that in a number of 
> different?ways, like percent under 25 years old, or by calculating the 
> dependency ratio 
> <https://www.who.int/data/gho/indicator-metadata-registry/imr-details/1119#:~:text=Definition%3A,a%20specific%20point%20in%20time.>.
> 
> I do think it is feasible to calculate?an estimated mean from the counts 
> within groups representing ranges. See, for example, here: 
> https://stackoverflow.com/questions/18887382/how-to-calculate-the-median-on-grouped-dataset <https://stackoverflow.com/questions/18887382/how-to-calculate-the-median-on-grouped-dataset>
> 
> Since you are working in Baltimore, you may consider looking at The 
> Baltimore Neighborhood?Indicators Alliance 
> https://bniajfi.org/vital_signs/ <https://bniajfi.org/vital_signs/>. 
> They provide useful?data on a range of issues (transportation, crime, 
> education, environment etc.) including summaries from Census-derived 
> demographics. What?you are seeking may already exist. BNIA creates 
> neighborhoods or "community statistical areas" (n=55) based on 
> aggregates of Census data.
> 
> Although not pertaining to age, Baltimore City Planning has paid Census 
> in the past to aggregate from individual-level Census data to the more 
> colloquially-used definitions of Baltimore shown here (n = 273): 
> https://data.baltimorecity.gov/datasets/neighborhood-1/explore?location=39.284832%2C-76.620516%2C12.91 <https://data.baltimorecity.gov/datasets/neighborhood-1/explore?location=39.284832%2C-76.620516%2C12.91>
> 
> Best, Dexter
> https://dexterlocke.com/ <https://dexterlocke.com/>
> 
> 
> 
> 
> 
> On Mon, Aug 7, 2023 at 3:02?PM Kevin Zembower via R-sig-Geo 
> <r-sig-geo at r-project.org <mailto:r-sig-geo at r-project.org>> wrote:
> 
>     Josiah, thanks for your reply.
> 
>     Regarding my objective, I'm trying to compile census statistics for the
>     blocks that make up the neighborhood where I live. It consists of ten
>     census blocks, of which I selected three for simplicity in my example.
>     The census block-group which contains these ten blocks also contains
>     some blocks which are outside of my neighborhood and shouldn't be
>     counted or included.
> 
>     Since I won't be able to calculate the median age from the age and
>     count
>     data, and since the individual data doesn't seem to be available, is it
>     your thought that I can't produce a valid median age for a group of
>     census blocks?
> 
>     Thanks so much for your advice.
> 
>     -Kevin
> 
>     On 8/7/23 14:38, Josiah Parry wrote:
>      > Hey Kevin, I don't think you're going to be able to get
>     individual level
>      > data from the US Census Bureau. The closest you may be able to
>     get is
>      > the current population survey (CPS) which I believe is also
>     available
>      > via tidycensus. Regarding your first question, I'm not sure I follow
>      > what your objective is with it. I would use a geography of census
>     block
>      > groups as the measure of median for census block groups.
>     Otherwise it is
>      > unclear how you are defining what a "group of blocks" is.
>      >
>      > On Mon, Aug 7, 2023 at 2:34?PM Kevin Zembower via R-sig-Geo
>      > <r-sig-geo at r-project.org <mailto:r-sig-geo at r-project.org>
>     <mailto:r-sig-geo at r-project.org <mailto:r-sig-geo at r-project.org>>>
>     wrote:
>      >
>      >? ? ?Hello, all,
>      >
>      >? ? ?I'd like to obtain the median age for a population in a
>     specific group
>      >? ? ?of US Decennial census blocks. Here's an example of the problem:
>      >
>      >? ? ?## Example of calculating median age of population in census
>     blocks.
>      >? ? ?library(tidyverse)
>      >? ? ?library(tidycensus)
>      >
>      >? ? ?counts <- get_decennial(
>      >? ? ? ? ? ?geography = "block",
>      >? ? ? ? ? ?state = "MD",
>      >? ? ? ? ? ?county = "Baltimore city",
>      >? ? ? ? ? ?table = "P1",
>      >? ? ? ? ? ?year = 2020,
>      >? ? ? ? ? ?sumfile = "dhc") %>%
>      >? ? ? ? ? ?mutate(NAME = NULL) %>%
>      >? ? ? ? ? ?filter(substr(GEOID, 6, 11) == "271101" &
>      >? ? ? ? ? ? ? ? ? substr(GEOID, 12, 15) %in% c(3000, 3001, 3002)
>      >? ? ? ? ? ? ? ? ? )
>      >
>      >? ? ?ages <- get_decennial(
>      >? ? ? ? ? ?geography = "block",
>      >? ? ? ? ? ?state = "MD",
>      >? ? ? ? ? ?county = "Baltimore city",
>      >? ? ? ? ? ?table = "P13",
>      >? ? ? ? ? ?year = 2020,
>      >? ? ? ? ? ?sumfile = "dhc") %>%
>      >? ? ? ? ? ?mutate(NAME = NULL) %>%
>      >? ? ? ? ? ?filter(substr(GEOID, 6, 11) == "271101" &
>      >? ? ? ? ? ? ? ? ? substr(GEOID, 12, 15) %in% c(3000, 3001, 3002)
>      >? ? ? ? ? ? ? ? ? )
>      >
>      >? ? ?I have two questions:
>      >
>      >? ? ?1. Is it mathematically valid to multiply the population of a
>     block by
>      >? ? ?the median age of that block (in other words, assign the
>     median age to
>      >? ? ?each member of a block), then calculate the median of those
>     numbers for
>      >? ? ?a group of blocks?
>      >
>      >? ? ?2. Is raw data on the ages of individuals available anywhere
>     else in
>      >? ? ?the
>      >? ? ?census data? I can find tables such as P12, that breaks down the
>      >? ? ?population by age ranges or bins, but can't find specific data of
>      >? ? ?counts
>      >? ? ?per age in years.
>      >
>      >? ? ?Thanks for your advice and help.
>      >
>      >? ? ?-Kevin
>      >
>      >? ? ?_______________________________________________
>      >? ? ?R-sig-Geo mailing list
>      > R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>     <mailto:R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>>
>      > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>      >? ? ?<https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>>
>      >
> 
> 
>     _______________________________________________
>     R-sig-Geo mailing list
>     R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
> 



From i@io m@iii@g oii phys@ii@-courses@org  Fri Aug 11 18:26:15 2023
From: i@io m@iii@g oii phys@ii@-courses@org (i@io m@iii@g oii phys@ii@-courses@org)
Date: Fri, 11 Aug 2023 18:26:15 +0200 (CEST)
Subject: [R-sig-Geo] Spatial Analysis and Mapping in R - October 23-27, 2023
Message-ID: <1691771175.48891266@webmail.jimdo.com>


Dear all,
We are delighted to introduce our upcoming course on Mapping and Spatial Operations in R, scheduled to take place from October 23rd to 27th, 2023. This immersive online course offers a unique opportunity to harness the power of R as a Geographic Information System (GIS) for mapping and analyzing spatial data.
 
 
**Course Overview:**
Geographic Information Systems (GIS) play a pivotal role in collecting, representing, and analyzing spatial data. In this course, we explore how to seamlessly integrate GIS operations into R, facilitating the creation of automated, reproducible, and visually appealing maps. Through a combination of theoretical insights and practical hands-on sessions, you'll gain the skills to script complex spatial analyses and create impactful maps using R.
 
 
**Target Audience and Assumed Background:**
Whether you're a researcher, practitioner, or enthusiast, this course is designed for individuals at all career stages who wish to enhance their spatial analysis capabilities. If you have an interest in mapping and spatial analysis of biodiversity or environmental data, and seek to script your procedures for reproducibility and automation, this course is tailor-made for you. A basic understanding of R is recommended, and participants should be comfortable working with computers, equipped with a good internet connection and webcam for interactive online sessions.
 
 
**Learning Outcomes:**
Upon completing this course, you will:
1. Acquire a foundational understanding of GIS, cartographic projections, and mapping principles.
2. Effectively import and manage spatial data in R, and script automated map generation.
3. Perform various spatial operations using R, unlocking new insights from your data.
4. Create visually compelling maps and export them for presentation and analysis.
Don't miss this opportunity to master the art of spatial analysis and mapping in R, and elevate your data visualization and analysis capabilities.
 
 
For more details and to secure your spot, please visit [ https://www.physalia-courses.org/courses-workshops/gis-in-r/ ]( https://www.physalia-courses.org/courses-workshops/gis-in-r/ )
 
We look forward to welcoming you to this enriching course and embarking on a journey of spatial exploration together.
 
Best regards,
 
Valentina
 
 
Valentina Sardina
Course coordinator
info at physalia-courses.org
[ http://www.physalia-courses.org/ ]( http://www.physalia-courses.org/ ) 
mobile: +49 17645230846
Follow us on [ Twitter ]( https://twitter.com/Physacourses ) & [ Mastodon ]( https://mas.to/@PhysaliaCourses )
	[[alternative HTML version deleted]]


From i@io m@iii@g oii phys@ii@-courses@org  Fri Aug 11 18:36:13 2023
From: i@io m@iii@g oii phys@ii@-courses@org (i@io m@iii@g oii phys@ii@-courses@org)
Date: Fri, 11 Aug 2023 18:36:13 +0200 (CEST)
Subject: [R-sig-Geo] Course - Introduction to Ecological Remote Sensing in R
Message-ID: <1691771773.057513310@webmail.jimdo.com>


Dear all,We are excited to announce the upcoming online course on "Introduction to Ecological Remote Sensing in R" scheduled for September 11-15, 2023. This course aims to provide scholars with no prior experience in R a comprehensive understanding of ecological remote sensing and its application in analyzing planetary changes.**Course Overview:**The course is tailored to those seeking to delve into the world of ecological remote sensing and harness the power of R for data analysis. We will begin from the basics of R programming and guide attendees through each step of coding remote sensing analysis. By the end of the course, participants will have developed proficiency in constructing analysis workflows and effectively reporting their findings using LaTeX. The final part of the course will cover the essentials of LaTeX scripting for articles and presentations.**Learning Outcomes:**By attending this course, participants will achieve the following objectives:- Learn how to set up and manage a GitHub account for storing code- Develop foundational coding skills in R, progressing to remote sensing data analysis- Gain insight into LaTeX for coding text and generating output reports**Program Overview:**The course will follow a daily schedule from 15:00 to 18:00 (Berlin time), covering a range of topics and practical sessions. 

This course is a unique opportunity to enhance your skills in ecological remote sensing and R programming, regardless of your prior experience level.

For more information and registration, please visit https://www.physalia-courses.org/courses-workshops/remote-sensing-in-r/

We look forward to welcoming you to the "Introduction to Ecological Remote Sensing in R" course in September.

Best regards,
Valentina
 
Valentina Sardina
Course coordinator
info at physalia-courses.org
[ http://www.physalia-courses.org/ ]( http://www.physalia-courses.org/ ) 
mobile: +49 17645230846
Follow us on [ Twitter ]( https://twitter.com/Physacourses ) & [ Mastodon ]( https://mas.to/@PhysaliaCourses )
	[[alternative HTML version deleted]]


From Roger@B|v@nd @end|ng |rom nhh@no  Fri Aug 11 20:11:34 2023
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Fri, 11 Aug 2023 18:11:34 +0000
Subject: [R-sig-Geo] 
 Course - Introduction to Ecological Remote Sensing in R
In-Reply-To: <1691771773.057513310@webmail.jimdo.com>
References: <1691771773.057513310@webmail.jimdo.com>
Message-ID: <SV0P279MB0475372BF0C284632B2559BDEE10A@SV0P279MB0475.NORP279.PROD.OUTLOOK.COM>

Advertising of commercial courses charging more than simple cost-covering is bad practice. The list maintainer should have been asked for permission, something most course providers usually are careful to do. Please desist - any further such postings without permission will lead to administrative unsubscription. You use multiple other channels to market your courses, please do not turn this list into a commercial arena as it will lead to many ceasing to use the list for its main purposes.

--
Roger Bivand
Emeritus Professor
Norwegian School of Economics
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway
Roger.Bivand at nhh.no

________________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of info at physalia-courses.org <info at physalia-courses.org>
Sent: 11 August 2023 18:36
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] Course - Introduction to Ecological Remote Sensing in R


Dear all,We are excited to announce the upcoming online course on "Introduction to Ecological Remote Sensing in R" scheduled for September 11-15, 2023. This course aims to provide scholars with no prior experience in R a comprehensive understanding of ecological remote sensing and its application in analyzing planetary changes.**Course Overview:**The course is tailored to those seeking to delve into the world of ecological remote sensing and harness the power of R for data analysis. We will begin from the basics of R programming and guide attendees through each step of coding remote sensing analysis. By the end of the course, participants will have developed proficiency in constructing analysis workflows and effectively reporting their findings using LaTeX. The final part of the course will cover the essentials of LaTeX scripting for articles and presentations.**Learning Outcomes:**By attending this course, participants will achieve the following objectives:- Learn how to set up and
 manage a GitHub account for storing code- Develop foundational coding skills in R, progressing to remote sensing data analysis- Gain insight into LaTeX for coding text and generating output reports**Program Overview:**The course will follow a daily schedule from 15:00 to 18:00 (Berlin time), covering a range of topics and practical sessions.

This course is a unique opportunity to enhance your skills in ecological remote sensing and R programming, regardless of your prior experience level.

For more information and registration, please visit https://www.physalia-courses.org/courses-workshops/remote-sensing-in-r/

We look forward to welcoming you to the "Introduction to Ecological Remote Sensing in R" course in September.

Best regards,
Valentina

Valentina Sardina
Course coordinator
info at physalia-courses.org
[ http://www.physalia-courses.org/ ]( http://www.physalia-courses.org/ )
mobile: +49 17645230846
Follow us on [ Twitter ]( https://twitter.com/Physacourses ) & [ Mastodon ]( https://mas.to/@PhysaliaCourses )
        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From m@ur|c|o@m@rdone@ @end|ng |rom ||op@c|  Fri Aug 11 20:47:23 2023
From: m@ur|c|o@m@rdone@ @end|ng |rom ||op@c| (MAURICIO MARDONES)
Date: Fri, 11 Aug 2023 20:47:23 +0200
Subject: [R-sig-Geo] 
 Course - Introduction to Ecological Remote Sensing in R
In-Reply-To: <SV0P279MB0475372BF0C284632B2559BDEE10A@SV0P279MB0475.NORP279.PROD.OUTLOOK.COM>
References: <1691771773.057513310@webmail.jimdo.com>
 <SV0P279MB0475372BF0C284632B2559BDEE10A@SV0P279MB0475.NORP279.PROD.OUTLOOK.COM>
Message-ID: <CAG=XH2v-_bKYEU6R3T5V-gP5g2dxCjzgz9r2rzwB2tecfvfOBw@mail.gmail.com>

Totally agree with Roger.

They charge for teaching the use of free software and for packages that are
not even developers or maintainers.

And they are not cheap! There are thousands of free tutorials, books and
courses in this giant R community. No need to pay for it.

Best

On Fri, Aug 11, 2023 at 8:12?PM Roger Bivand <Roger.Bivand at nhh.no> wrote:

> Advertising of commercial courses charging more than simple cost-covering
> is bad practice. The list maintainer should have been asked for permission,
> something most course providers usually are careful to do. Please desist -
> any further such postings without permission will lead to administrative
> unsubscription. You use multiple other channels to market your courses,
> please do not turn this list into a commercial arena as it will lead to
> many ceasing to use the list for its main purposes.
>
> --
> Roger Bivand
> Emeritus Professor
> Norwegian School of Economics
> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway
> Roger.Bivand at nhh.no
>
> ________________________________________
> From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of
> info at physalia-courses.org <info at physalia-courses.org>
> Sent: 11 August 2023 18:36
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] Course - Introduction to Ecological Remote Sensing in
> R
>
>
> Dear all,We are excited to announce the upcoming online course on
> "Introduction to Ecological Remote Sensing in R" scheduled for September
> 11-15, 2023. This course aims to provide scholars with no prior experience
> in R a comprehensive understanding of ecological remote sensing and its
> application in analyzing planetary changes.**Course Overview:**The course
> is tailored to those seeking to delve into the world of ecological remote
> sensing and harness the power of R for data analysis. We will begin from
> the basics of R programming and guide attendees through each step of coding
> remote sensing analysis. By the end of the course, participants will have
> developed proficiency in constructing analysis workflows and effectively
> reporting their findings using LaTeX. The final part of the course will
> cover the essentials of LaTeX scripting for articles and
> presentations.**Learning Outcomes:**By attending this course, participants
> will achieve the following objectives:- Learn how to set up and
>  manage a GitHub account for storing code- Develop foundational coding
> skills in R, progressing to remote sensing data analysis- Gain insight into
> LaTeX for coding text and generating output reports**Program Overview:**The
> course will follow a daily schedule from 15:00 to 18:00 (Berlin time),
> covering a range of topics and practical sessions.
>
> This course is a unique opportunity to enhance your skills in ecological
> remote sensing and R programming, regardless of your prior experience level.
>
> For more information and registration, please visit
> https://www.physalia-courses.org/courses-workshops/remote-sensing-in-r/
>
> We look forward to welcoming you to the "Introduction to Ecological Remote
> Sensing in R" course in September.
>
> Best regards,
> Valentina
>
> Valentina Sardina
> Course coordinator
> info at physalia-courses.org
> [ http://www.physalia-courses.org/ ]( http://www.physalia-courses.org/ )
> mobile: +49 17645230846
> Follow us on [ Twitter ]( https://twitter.com/Physacourses ) & [ Mastodon
> ]( https://mas.to/@PhysaliaCourses )
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


-- 

*Mauricio Mardones Inostroza*

Investigador Departamento Evaluaci?n de Recursos
Instituto de Fomento Pesquero - IFOP
Valpara?so - Chile
+56-32-21514 <callto:+56-32-2151424>42

www.ifop.cl

-- 
C*ertificaci?n ISO 9001/2015*: Sistema de Datos Biol?gico-Pesqueros?(Arica, 
Iquique, Coquimbo, Valpara?so, San Antonio, Talcahuano y Calbuco, 
pesquer?as industriales y artesanales)

	[[alternative HTML version deleted]]


From m@|uc@68 @end|ng |rom gm@||@com  Fri Aug 11 20:54:07 2023
From: m@|uc@68 @end|ng |rom gm@||@com (=?UTF-8?Q?Martha_Luc=C3=ADa_Casta=C3=B1eda_Cediel?=)
Date: Fri, 11 Aug 2023 12:54:07 -0600
Subject: [R-sig-Geo] 
 Course - Introduction to Ecological Remote Sensing in R
In-Reply-To: <CAG=XH2v-_bKYEU6R3T5V-gP5g2dxCjzgz9r2rzwB2tecfvfOBw@mail.gmail.com>
References: <1691771773.057513310@webmail.jimdo.com>
 <SV0P279MB0475372BF0C284632B2559BDEE10A@SV0P279MB0475.NORP279.PROD.OUTLOOK.COM>
 <CAG=XH2v-_bKYEU6R3T5V-gP5g2dxCjzgz9r2rzwB2tecfvfOBw@mail.gmail.com>
Message-ID: <CAMjSbDMCfaq_GC68r-eE2NNCgryjvMUQPC+KKAHuZ99AkUhYSg@mail.gmail.com>

Totally agree with Roger, and Mauricio!!!

nice day!!

Martha Luc?a Casta?eda Cediel
Doctora en Geograf?a
Universidad Nacional Aut?noma de M?xico

Skype: malucasce
https://www.researchgate.net/profile/Martha-Casta?eda-Cediel

"Nadie podr? llevar por encima de su coraz?n a nadie ni hacerle mal en su
persona aunque piense y diga diferente". Interpretaci?n Wayuu, art?culo 11
Constituci?n Pol?tica de Colombia.
Art?culo 11. El derecho a la vida es inviolable. No habr? pena de muerte.

El vie, 11 de ago de 2023, 12:47, MAURICIO MARDONES <
mauricio.mardones at ifop.cl> escribi?:

> Totally agree with Roger.
>
> They charge for teaching the use of free software and for packages that are
> not even developers or maintainers.
>
> And they are not cheap! There are thousands of free tutorials, books and
> courses in this giant R community. No need to pay for it.
>
> Best
>
> On Fri, Aug 11, 2023 at 8:12?PM Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
> > Advertising of commercial courses charging more than simple cost-covering
> > is bad practice. The list maintainer should have been asked for
> permission,
> > something most course providers usually are careful to do. Please desist
> -
> > any further such postings without permission will lead to administrative
> > unsubscription. You use multiple other channels to market your courses,
> > please do not turn this list into a commercial arena as it will lead to
> > many ceasing to use the list for its main purposes.
> >
> > --
> > Roger Bivand
> > Emeritus Professor
> > Norwegian School of Economics
> > Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway
> > Roger.Bivand at nhh.no
> >
> > ________________________________________
> > From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of
> > info at physalia-courses.org <info at physalia-courses.org>
> > Sent: 11 August 2023 18:36
> > To: r-sig-geo at r-project.org
> > Subject: [R-sig-Geo] Course - Introduction to Ecological Remote Sensing
> in
> > R
> >
> >
> > Dear all,We are excited to announce the upcoming online course on
> > "Introduction to Ecological Remote Sensing in R" scheduled for September
> > 11-15, 2023. This course aims to provide scholars with no prior
> experience
> > in R a comprehensive understanding of ecological remote sensing and its
> > application in analyzing planetary changes.**Course Overview:**The course
> > is tailored to those seeking to delve into the world of ecological remote
> > sensing and harness the power of R for data analysis. We will begin from
> > the basics of R programming and guide attendees through each step of
> coding
> > remote sensing analysis. By the end of the course, participants will have
> > developed proficiency in constructing analysis workflows and effectively
> > reporting their findings using LaTeX. The final part of the course will
> > cover the essentials of LaTeX scripting for articles and
> > presentations.**Learning Outcomes:**By attending this course,
> participants
> > will achieve the following objectives:- Learn how to set up and
> >  manage a GitHub account for storing code- Develop foundational coding
> > skills in R, progressing to remote sensing data analysis- Gain insight
> into
> > LaTeX for coding text and generating output reports**Program
> Overview:**The
> > course will follow a daily schedule from 15:00 to 18:00 (Berlin time),
> > covering a range of topics and practical sessions.
> >
> > This course is a unique opportunity to enhance your skills in ecological
> > remote sensing and R programming, regardless of your prior experience
> level.
> >
> > For more information and registration, please visit
> > https://www.physalia-courses.org/courses-workshops/remote-sensing-in-r/
> >
> > We look forward to welcoming you to the "Introduction to Ecological
> Remote
> > Sensing in R" course in September.
> >
> > Best regards,
> > Valentina
> >
> > Valentina Sardina
> > Course coordinator
> > info at physalia-courses.org
> > [ http://www.physalia-courses.org/ ]( http://www.physalia-courses.org/ )
> > mobile: +49 17645230846
> > Follow us on [ Twitter ]( https://twitter.com/Physacourses ) & [
> Mastodon
> > ]( https://mas.to/@PhysaliaCourses )
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
>
> --
>
> *Mauricio Mardones Inostroza*
>
> Investigador Departamento Evaluaci?n de Recursos
> Instituto de Fomento Pesquero - IFOP
> Valpara?so - Chile
> +56-32-21514 <callto:+56-32-2151424>42
>
> www.ifop.cl
>
> --
> C*ertificaci?n ISO 9001/2015*: Sistema de Datos
> Biol?gico-Pesqueros (Arica,
> Iquique, Coquimbo, Valpara?so, San Antonio, Talcahuano y Calbuco,
> pesquer?as industriales y artesanales)
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From roy@mende|@@ohn @end|ng |rom no@@@gov  Fri Aug 11 22:02:27 2023
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Fri, 11 Aug 2023 13:02:27 -0700
Subject: [R-sig-Geo] Free Satellite Oceanography Course
Message-ID: <263A7856-232B-45DB-AA56-7035C6BA0C5A@noaa.gov>

NOAA/Coastwatch, NOAA/Polarwatch and NOAA/NMFS/SWFC/ERD  are offering a free course on satellite oceanography September 18-20, 2023 in Anchorage, Alaska.  While this is the perfect excuse to visit Alaska,  the course will be a hybrid course so that you will be able to attend remotely.  While the emphasize of the course will be the polar regions,  you will learn about satellite oceanography more generally,  the different types of data available,  and how to access the data you desire.  The course emphasizes the use of free, open source software includng R and Python,  and the data services used are also free, requiring no enrollment, password or secret handshake.  Moreover with the knowledge from this course you will be able to access a wide variety of satellite and non-satellite data hosted by NOAA/NMFS,  NOAA/Coastwatch,  NOAA/Polarwatch,  NOAA/IOOS,  NOAA/OAR as well as over 100 other institutions.

For more information see https://events.r20.constantcontact.com/register/event?oeidk=a07ejso5ljfa55ebeb4&llr=ji7pbq7ab 

-Roy



**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From cboett|g @end|ng |rom gm@||@com  Wed Aug 16 01:02:25 2023
From: cboett|g @end|ng |rom gm@||@com (Carl Boettiger)
Date: Tue, 15 Aug 2023 16:02:25 -0700
Subject: [R-sig-Geo] Using duckdb spatial module from R (with sf)?
Message-ID: <CAN_1p9x+fN0LCt=cYhgykJtUuivcJTrQjh8wsmnpeiw7PimP8g@mail.gmail.com>

Hi folks,


I'm curious if anyone has explored the relatively new spatial
extension in duckdb (https://duckdb.org/docs/extensions/spatial.html)
or has any pointers/tutorials regarding its use from R?

Consider the following minimal example that seeks to use the sf
library to speak to duckdb:

  library(duckdb)
  library(sf)
  conn <- DBI::dbConnect(duckdb::duckdb())
  status <- DBI::dbExecute(conn, "INSTALL 'spatial';")
  status <- DBI::dbExecute(conn, "LOAD 'spatial';")

  test <- data.frame(site = letters[1:10], latitude = 1:10, longitude = 1:10)
  DBI::dbWriteTable(conn, "test", test)

# Ok, let's try and make a geometry column
  query <- paste(
    'SELECT *, ST_Point(longitude, latitude) AS geom',
    'FROM "test"'
  )

  ex <- st_read(con, query=query, geometry_column = "geom")
  ## error: reading wkb type 0 is not supported


  ex <- st_read(con, query=query, geometry_column = "geom", EWKB = FALSE)
  ## prints: wkbType: 1572864
  ## Error in CPL_read_wkb(x, EWKB, spatialite) : unsupported wkbType
dim in switch

 We seem to get closer than I might have hoped (sf doesn't just insist
that conn isn't postgresgis), but is getting stuck on the encoding of
the wkb.  Is this something we can work around?  The queries seem to
run successfully, I just seem to be getting some unsupported ecoding
of the WKB geometry column....

---
Carl Boettiger
http://carlboettiger.info/


From jo@|@h@p@rry @end|ng |rom gm@||@com  Wed Aug 16 01:36:05 2023
From: jo@|@h@p@rry @end|ng |rom gm@||@com (Josiah Parry)
Date: Tue, 15 Aug 2023 19:36:05 -0400
Subject: [R-sig-Geo] Using duckdb spatial module from R (with sf)?
In-Reply-To: <CAN_1p9x+fN0LCt=cYhgykJtUuivcJTrQjh8wsmnpeiw7PimP8g@mail.gmail.com>
References: <CAN_1p9x+fN0LCt=cYhgykJtUuivcJTrQjh8wsmnpeiw7PimP8g@mail.gmail.com>
Message-ID: <CAL3ufU+xmWG_yY4n=Vk8Mdj0dKAXpEc7BdsRisR4ejih3NwNgg@mail.gmail.com>

Hey Carl, this is super cool! Is there a way to get the query result as wkb
and read the wkb using {wk}? That?s where I might start?validating the wkb
output :)

On Tue, Aug 15, 2023 at 19:02 Carl Boettiger <cboettig at gmail.com> wrote:

> Hi folks,
>
>
> I'm curious if anyone has explored the relatively new spatial
> extension in duckdb (https://duckdb.org/docs/extensions/spatial.html)
> or has any pointers/tutorials regarding its use from R?
>
> Consider the following minimal example that seeks to use the sf
> library to speak to duckdb:
>
>   library(duckdb)
>   library(sf)
>   conn <- DBI::dbConnect(duckdb::duckdb())
>   status <- DBI::dbExecute(conn, "INSTALL 'spatial';")
>   status <- DBI::dbExecute(conn, "LOAD 'spatial';")
>
>   test <- data.frame(site = letters[1:10], latitude = 1:10, longitude =
> 1:10)
>   DBI::dbWriteTable(conn, "test", test)
>
> # Ok, let's try and make a geometry column
>   query <- paste(
>     'SELECT *, ST_Point(longitude, latitude) AS geom',
>     'FROM "test"'
>   )
>
>   ex <- st_read(con, query=query, geometry_column = "geom")
>   ## error: reading wkb type 0 is not supported
>
>
>   ex <- st_read(con, query=query, geometry_column = "geom", EWKB = FALSE)
>   ## prints: wkbType: 1572864
>   ## Error in CPL_read_wkb(x, EWKB, spatialite) : unsupported wkbType
> dim in switch
>
>  We seem to get closer than I might have hoped (sf doesn't just insist
> that conn isn't postgresgis), but is getting stuck on the encoding of
> the wkb.  Is this something we can work around?  The queries seem to
> run successfully, I just seem to be getting some unsupported ecoding
> of the WKB geometry column....
>
> ---
> Carl Boettiger
> http://carlboettiger.info/
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From cboett|g @end|ng |rom gm@||@com  Wed Aug 16 01:42:37 2023
From: cboett|g @end|ng |rom gm@||@com (Carl Boettiger)
Date: Tue, 15 Aug 2023 16:42:37 -0700
Subject: [R-sig-Geo] Using duckdb spatial module from R (with sf)?
In-Reply-To: <CAN_1p9x+fN0LCt=cYhgykJtUuivcJTrQjh8wsmnpeiw7PimP8g@mail.gmail.com>
References: <CAN_1p9x+fN0LCt=cYhgykJtUuivcJTrQjh8wsmnpeiw7PimP8g@mail.gmail.com>
Message-ID: <CAN_1p9xiS6XZ7wrb5+ZLiMKDQuo1J72GW9JSv-jfF6sAidzq+w@mail.gmail.com>

Ah ha.  if we ask duckdb to coerce it's geometry format to hex, it
appears sf can understand it just fine!

replacing the above query with the following we are good to go.



query <- paste(
  'SELECT *, ST_AsHEXWKB(ST_Point(longitude, latitude)) AS geom',
  'FROM "test"'
)
ex <- st_read(con, query=query, geometry_column = "geom", EWKB=FALSE)
ex


I'll experiment further.  I'm terrible at SQL, and to my eyes it looks
needlessly verbose.  I'm keen to understand how I can better leverage
sf's notation to compose the sql queries to duckdb....  but it seems
to work!   I'm also still trying to determine if duckdb is using EWKB
or vanilla WKB....

---
Carl Boettiger
http://carlboettiger.info/

On Tue, Aug 15, 2023 at 4:02?PM Carl Boettiger <cboettig at gmail.com> wrote:
>
> Hi folks,
>
>
> I'm curious if anyone has explored the relatively new spatial
> extension in duckdb (https://duckdb.org/docs/extensions/spatial.html)
> or has any pointers/tutorials regarding its use from R?
>
> Consider the following minimal example that seeks to use the sf
> library to speak to duckdb:
>
>   library(duckdb)
>   library(sf)
>   conn <- DBI::dbConnect(duckdb::duckdb())
>   status <- DBI::dbExecute(conn, "INSTALL 'spatial';")
>   status <- DBI::dbExecute(conn, "LOAD 'spatial';")
>
>   test <- data.frame(site = letters[1:10], latitude = 1:10, longitude = 1:10)
>   DBI::dbWriteTable(conn, "test", test)
>
> # Ok, let's try and make a geometry column
>   query <- paste(
>     'SELECT *, ST_Point(longitude, latitude) AS geom',
>     'FROM "test"'
>   )
>
>   ex <- st_read(con, query=query, geometry_column = "geom")
>   ## error: reading wkb type 0 is not supported
>
>
>   ex <- st_read(con, query=query, geometry_column = "geom", EWKB = FALSE)
>   ## prints: wkbType: 1572864
>   ## Error in CPL_read_wkb(x, EWKB, spatialite) : unsupported wkbType
> dim in switch
>
>  We seem to get closer than I might have hoped (sf doesn't just insist
> that conn isn't postgresgis), but is getting stuck on the encoding of
> the wkb.  Is this something we can work around?  The queries seem to
> run successfully, I just seem to be getting some unsupported ecoding
> of the WKB geometry column....
>
> ---
> Carl Boettiger
> http://carlboettiger.info/


From cboett|g @end|ng |rom gm@||@com  Wed Aug 16 02:34:21 2023
From: cboett|g @end|ng |rom gm@||@com (Carl Boettiger)
Date: Tue, 15 Aug 2023 17:34:21 -0700
Subject: [R-sig-Geo] Using duckdb spatial module from R (with sf)?
In-Reply-To: <CAN_1p9xiS6XZ7wrb5+ZLiMKDQuo1J72GW9JSv-jfF6sAidzq+w@mail.gmail.com>
References: <CAN_1p9x+fN0LCt=cYhgykJtUuivcJTrQjh8wsmnpeiw7PimP8g@mail.gmail.com>
 <CAN_1p9xiS6XZ7wrb5+ZLiMKDQuo1J72GW9JSv-jfF6sAidzq+w@mail.gmail.com>
Message-ID: <CAN_1p9ycOAOLE9_-XexMF93=FN0rQY1pTJDVvV1OSUToODH9vA@mail.gmail.com>

Hi list,

One more go at this and I'll stop for other ideas.  Below is a
slightly modified example using dbplyr::sql_render() to construct the
query, which works and to me feels a little cleaner, though maybe is
ill-advised.  Then I try to construct a spatial filter (for points in
a polygon) this way with ST_Contains, but my effort comes back empty.
Not sure where I went wrong.  Any ideas?


## boilerplate setup
library(duckdb)
conn <- DBI::dbConnect(duckdb::duckdb())
status <- DBI::dbExecute(conn, "INSTALL 'spatial';")
status <- DBI::dbExecute(conn, "LOAD 'spatial';")
test <- data.frame(site = letters[1:10], latitude = 1:10, longitude = 1:10)
DBI::dbWriteTable(conn, "test", test)

## Here we go, works!
sql <- tbl(con, "test") |>
  mutate(geom = ST_AsHEXWKB(ST_Point(longitude, latitude))) |>
  dbplyr::sql_render()
ex <- st_read(conn, query=sql, geometry_column = "geom", EWKB=FALSE)
ex

## a trivial search polygon to filter:
p2 <- rbind(c(1,1), c(1,2), c(2,2), c(1,1))
pol <-st_polygon(list(p2))
txt <- st_as_text(pol)

## Can we use this to filter duckdb?
sql <- tbl(conn, "test") |>
  mutate(geometry = ST_Point(longitude, latitude),
         geom = ST_AsHEXWKB(geometry)) |>
  filter(ST_Contains(geometry, ST_GeomFromText({txt}))) |>
  dbplyr::sql_render()
sql
ex <- st_read(conn, query=sql, geometry_column = "geom", EWKB=FALSE)
ex
## oh no! our result comes back empty?  did I need CRS on this?  Or do
I missunderstand "ST_Contains()"?

## Here's what the desired result would be from pure sf:
sf <- st_as_sf(test, coords = c(3,2))
filter <- st_as_sf(tibble(sites = "A", geometry = list(pol)))
sf |> st_filter(filter)




---
Carl Boettiger
http://carlboettiger.info/

On Tue, Aug 15, 2023 at 4:42?PM Carl Boettiger <cboettig at gmail.com> wrote:
>
> Ah ha.  if we ask duckdb to coerce it's geometry format to hex, it
> appears sf can understand it just fine!
>
> replacing the above query with the following we are good to go.
>
>
>
> query <- paste(
>   'SELECT *, ST_AsHEXWKB(ST_Point(longitude, latitude)) AS geom',
>   'FROM "test"'
> )
> ex <- st_read(con, query=query, geometry_column = "geom", EWKB=FALSE)
> ex
>
>
> I'll experiment further.  I'm terrible at SQL, and to my eyes it looks
> needlessly verbose.  I'm keen to understand how I can better leverage
> sf's notation to compose the sql queries to duckdb....  but it seems
> to work!   I'm also still trying to determine if duckdb is using EWKB
> or vanilla WKB....
>
> ---
> Carl Boettiger
> http://carlboettiger.info/
>
> On Tue, Aug 15, 2023 at 4:02?PM Carl Boettiger <cboettig at gmail.com> wrote:
> >
> > Hi folks,
> >
> >
> > I'm curious if anyone has explored the relatively new spatial
> > extension in duckdb (https://duckdb.org/docs/extensions/spatial.html)
> > or has any pointers/tutorials regarding its use from R?
> >
> > Consider the following minimal example that seeks to use the sf
> > library to speak to duckdb:
> >
> >   library(duckdb)
> >   library(sf)
> >   conn <- DBI::dbConnect(duckdb::duckdb())
> >   status <- DBI::dbExecute(conn, "INSTALL 'spatial';")
> >   status <- DBI::dbExecute(conn, "LOAD 'spatial';")
> >
> >   test <- data.frame(site = letters[1:10], latitude = 1:10, longitude = 1:10)
> >   DBI::dbWriteTable(conn, "test", test)
> >
> > # Ok, let's try and make a geometry column
> >   query <- paste(
> >     'SELECT *, ST_Point(longitude, latitude) AS geom',
> >     'FROM "test"'
> >   )
> >
> >   ex <- st_read(con, query=query, geometry_column = "geom")
> >   ## error: reading wkb type 0 is not supported
> >
> >
> >   ex <- st_read(con, query=query, geometry_column = "geom", EWKB = FALSE)
> >   ## prints: wkbType: 1572864
> >   ## Error in CPL_read_wkb(x, EWKB, spatialite) : unsupported wkbType
> > dim in switch
> >
> >  We seem to get closer than I might have hoped (sf doesn't just insist
> > that conn isn't postgresgis), but is getting stuck on the encoding of
> > the wkb.  Is this something we can work around?  The queries seem to
> > run successfully, I just seem to be getting some unsupported ecoding
> > of the WKB geometry column....
> >
> > ---
> > Carl Boettiger
> > http://carlboettiger.info/


From jo@|@h@p@rry @end|ng |rom gm@||@com  Wed Aug 16 02:39:15 2023
From: jo@|@h@p@rry @end|ng |rom gm@||@com (Josiah Parry)
Date: Tue, 15 Aug 2023 20:39:15 -0400
Subject: [R-sig-Geo] Using duckdb spatial module from R (with sf)?
In-Reply-To: <CAN_1p9ycOAOLE9_-XexMF93=FN0rQY1pTJDVvV1OSUToODH9vA@mail.gmail.com>
References: <CAN_1p9x+fN0LCt=cYhgykJtUuivcJTrQjh8wsmnpeiw7PimP8g@mail.gmail.com>
 <CAN_1p9xiS6XZ7wrb5+ZLiMKDQuo1J72GW9JSv-jfF6sAidzq+w@mail.gmail.com>
 <CAN_1p9ycOAOLE9_-XexMF93=FN0rQY1pTJDVvV1OSUToODH9vA@mail.gmail.com>
Message-ID: <CAL3ufU+UbmswMVXi796LQAg16w-Wc+za7pL5Rc6OYfWVNBoXNA@mail.gmail.com>

Quick note on the contains: a polygon has 5 points! The first has to be the
same as the last. And they shuold be going in Counter clock wise order if
memory serves ! :)

On Tue, Aug 15, 2023 at 8:34?PM Carl Boettiger <cboettig at gmail.com> wrote:

> Hi list,
>
> One more go at this and I'll stop for other ideas.  Below is a
> slightly modified example using dbplyr::sql_render() to construct the
> query, which works and to me feels a little cleaner, though maybe is
> ill-advised.  Then I try to construct a spatial filter (for points in
> a polygon) this way with ST_Contains, but my effort comes back empty.
> Not sure where I went wrong.  Any ideas?
>
>
> ## boilerplate setup
> library(duckdb)
> conn <- DBI::dbConnect(duckdb::duckdb())
> status <- DBI::dbExecute(conn, "INSTALL 'spatial';")
> status <- DBI::dbExecute(conn, "LOAD 'spatial';")
> test <- data.frame(site = letters[1:10], latitude = 1:10, longitude = 1:10)
> DBI::dbWriteTable(conn, "test", test)
>
> ## Here we go, works!
> sql <- tbl(con, "test") |>
>   mutate(geom = ST_AsHEXWKB(ST_Point(longitude, latitude))) |>
>   dbplyr::sql_render()
> ex <- st_read(conn, query=sql, geometry_column = "geom", EWKB=FALSE)
> ex
>
> ## a trivial search polygon to filter:
> p2 <- rbind(c(1,1), c(1,2), c(2,2), c(1,1))
> pol <-st_polygon(list(p2))
> txt <- st_as_text(pol)
>
> ## Can we use this to filter duckdb?
> sql <- tbl(conn, "test") |>
>   mutate(geometry = ST_Point(longitude, latitude),
>          geom = ST_AsHEXWKB(geometry)) |>
>   filter(ST_Contains(geometry, ST_GeomFromText({txt}))) |>
>   dbplyr::sql_render()
> sql
> ex <- st_read(conn, query=sql, geometry_column = "geom", EWKB=FALSE)
> ex
> ## oh no! our result comes back empty?  did I need CRS on this?  Or do
> I missunderstand "ST_Contains()"?
>
> ## Here's what the desired result would be from pure sf:
> sf <- st_as_sf(test, coords = c(3,2))
> filter <- st_as_sf(tibble(sites = "A", geometry = list(pol)))
> sf |> st_filter(filter)
>
>
>
>
> ---
> Carl Boettiger
> http://carlboettiger.info/
>
> On Tue, Aug 15, 2023 at 4:42?PM Carl Boettiger <cboettig at gmail.com> wrote:
> >
> > Ah ha.  if we ask duckdb to coerce it's geometry format to hex, it
> > appears sf can understand it just fine!
> >
> > replacing the above query with the following we are good to go.
> >
> >
> >
> > query <- paste(
> >   'SELECT *, ST_AsHEXWKB(ST_Point(longitude, latitude)) AS geom',
> >   'FROM "test"'
> > )
> > ex <- st_read(con, query=query, geometry_column = "geom", EWKB=FALSE)
> > ex
> >
> >
> > I'll experiment further.  I'm terrible at SQL, and to my eyes it looks
> > needlessly verbose.  I'm keen to understand how I can better leverage
> > sf's notation to compose the sql queries to duckdb....  but it seems
> > to work!   I'm also still trying to determine if duckdb is using EWKB
> > or vanilla WKB....
> >
> > ---
> > Carl Boettiger
> > http://carlboettiger.info/
> >
> > On Tue, Aug 15, 2023 at 4:02?PM Carl Boettiger <cboettig at gmail.com>
> wrote:
> > >
> > > Hi folks,
> > >
> > >
> > > I'm curious if anyone has explored the relatively new spatial
> > > extension in duckdb (https://duckdb.org/docs/extensions/spatial.html)
> > > or has any pointers/tutorials regarding its use from R?
> > >
> > > Consider the following minimal example that seeks to use the sf
> > > library to speak to duckdb:
> > >
> > >   library(duckdb)
> > >   library(sf)
> > >   conn <- DBI::dbConnect(duckdb::duckdb())
> > >   status <- DBI::dbExecute(conn, "INSTALL 'spatial';")
> > >   status <- DBI::dbExecute(conn, "LOAD 'spatial';")
> > >
> > >   test <- data.frame(site = letters[1:10], latitude = 1:10, longitude
> = 1:10)
> > >   DBI::dbWriteTable(conn, "test", test)
> > >
> > > # Ok, let's try and make a geometry column
> > >   query <- paste(
> > >     'SELECT *, ST_Point(longitude, latitude) AS geom',
> > >     'FROM "test"'
> > >   )
> > >
> > >   ex <- st_read(con, query=query, geometry_column = "geom")
> > >   ## error: reading wkb type 0 is not supported
> > >
> > >
> > >   ex <- st_read(con, query=query, geometry_column = "geom", EWKB =
> FALSE)
> > >   ## prints: wkbType: 1572864
> > >   ## Error in CPL_read_wkb(x, EWKB, spatialite) : unsupported wkbType
> > > dim in switch
> > >
> > >  We seem to get closer than I might have hoped (sf doesn't just insist
> > > that conn isn't postgresgis), but is getting stuck on the encoding of
> > > the wkb.  Is this something we can work around?  The queries seem to
> > > run successfully, I just seem to be getting some unsupported ecoding
> > > of the WKB geometry column....
> > >
> > > ---
> > > Carl Boettiger
> > > http://carlboettiger.info/
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From cboett|g @end|ng |rom gm@||@com  Wed Aug 16 02:56:35 2023
From: cboett|g @end|ng |rom gm@||@com (Carl Boettiger)
Date: Tue, 15 Aug 2023 17:56:35 -0700
Subject: [R-sig-Geo] Using duckdb spatial module from R (with sf)?
In-Reply-To: <CAL3ufU+UbmswMVXi796LQAg16w-Wc+za7pL5Rc6OYfWVNBoXNA@mail.gmail.com>
References: <CAN_1p9x+fN0LCt=cYhgykJtUuivcJTrQjh8wsmnpeiw7PimP8g@mail.gmail.com>
 <CAN_1p9xiS6XZ7wrb5+ZLiMKDQuo1J72GW9JSv-jfF6sAidzq+w@mail.gmail.com>
 <CAN_1p9ycOAOLE9_-XexMF93=FN0rQY1pTJDVvV1OSUToODH9vA@mail.gmail.com>
 <CAL3ufU+UbmswMVXi796LQAg16w-Wc+za7pL5Rc6OYfWVNBoXNA@mail.gmail.com>
Message-ID: <CAN_1p9wZcEU632yEREwQ9Oz3WC3Nz24z+o58hmLqsWL873rerw@mail.gmail.com>

thanks!  of course the polygon can be a triangle, but I think the
difference here is that (a) I wanted st_within() if I'm giving my
points first and then my filter, and I think st_contains / st_within
have slightly different opinions about being on the exact boundary
than st_filter().

Anyway, fixing my filter does indeed work!  Thanks Josiah for the help
here.  This is very appealing to me thanks to the ability of duckdb to
open very large remote csv / parquet files without downloading them,
which often contain lat / long columns in my work.


I'll stop bugging the rest of you :-)




here's the working filter for comparison in case anyone is following along.

## a trivial search polygon to filter:
p2 <- rbind(c(0,0), c(0,3), c(3,3), c(3,0), c(0,0))
pol <-st_polygon(list(p2))
txt <- st_as_text(pol)

## Can we use this to filter duckdb?
sql <- tbl(conn, "test") |>
  mutate(geometry = ST_Point(longitude, latitude),
         geom = ST_AsHEXWKB(geometry)) |>
  filter(ST_Within(geometry, ST_GeomFromText({txt}))) |>
  dbplyr::sql_render()
sql
ex <- st_read(conn, query=sql, geometry_column = "geom", EWKB=FALSE)
ex

(note this still differs with sf::st_filter() regarding the 3,3 point,
which I believe is well documented I just overlooked it).

---
Carl Boettiger
http://carlboettiger.info/

On Tue, Aug 15, 2023 at 5:39?PM Josiah Parry <josiah.parry at gmail.com> wrote:
>
> Quick note on the contains: a polygon has 5 points! The first has to be the same as the last. And they shuold be going in Counter clock wise order if memory serves ! :)
>
> On Tue, Aug 15, 2023 at 8:34?PM Carl Boettiger <cboettig at gmail.com> wrote:
>>
>> Hi list,
>>
>> One more go at this and I'll stop for other ideas.  Below is a
>> slightly modified example using dbplyr::sql_render() to construct the
>> query, which works and to me feels a little cleaner, though maybe is
>> ill-advised.  Then I try to construct a spatial filter (for points in
>> a polygon) this way with ST_Contains, but my effort comes back empty.
>> Not sure where I went wrong.  Any ideas?
>>
>>
>> ## boilerplate setup
>> library(duckdb)
>> conn <- DBI::dbConnect(duckdb::duckdb())
>> status <- DBI::dbExecute(conn, "INSTALL 'spatial';")
>> status <- DBI::dbExecute(conn, "LOAD 'spatial';")
>> test <- data.frame(site = letters[1:10], latitude = 1:10, longitude = 1:10)
>> DBI::dbWriteTable(conn, "test", test)
>>
>> ## Here we go, works!
>> sql <- tbl(con, "test") |>
>>   mutate(geom = ST_AsHEXWKB(ST_Point(longitude, latitude))) |>
>>   dbplyr::sql_render()
>> ex <- st_read(conn, query=sql, geometry_column = "geom", EWKB=FALSE)
>> ex
>>
>> ## a trivial search polygon to filter:
>> p2 <- rbind(c(1,1), c(1,2), c(2,2), c(1,1))
>> pol <-st_polygon(list(p2))
>> txt <- st_as_text(pol)
>>
>> ## Can we use this to filter duckdb?
>> sql <- tbl(conn, "test") |>
>>   mutate(geometry = ST_Point(longitude, latitude),
>>          geom = ST_AsHEXWKB(geometry)) |>
>>   filter(ST_Contains(geometry, ST_GeomFromText({txt}))) |>
>>   dbplyr::sql_render()
>> sql
>> ex <- st_read(conn, query=sql, geometry_column = "geom", EWKB=FALSE)
>> ex
>> ## oh no! our result comes back empty?  did I need CRS on this?  Or do
>> I missunderstand "ST_Contains()"?
>>
>> ## Here's what the desired result would be from pure sf:
>> sf <- st_as_sf(test, coords = c(3,2))
>> filter <- st_as_sf(tibble(sites = "A", geometry = list(pol)))
>> sf |> st_filter(filter)
>>
>>
>>
>>
>> ---
>> Carl Boettiger
>> http://carlboettiger.info/
>>
>> On Tue, Aug 15, 2023 at 4:42?PM Carl Boettiger <cboettig at gmail.com> wrote:
>> >
>> > Ah ha.  if we ask duckdb to coerce it's geometry format to hex, it
>> > appears sf can understand it just fine!
>> >
>> > replacing the above query with the following we are good to go.
>> >
>> >
>> >
>> > query <- paste(
>> >   'SELECT *, ST_AsHEXWKB(ST_Point(longitude, latitude)) AS geom',
>> >   'FROM "test"'
>> > )
>> > ex <- st_read(con, query=query, geometry_column = "geom", EWKB=FALSE)
>> > ex
>> >
>> >
>> > I'll experiment further.  I'm terrible at SQL, and to my eyes it looks
>> > needlessly verbose.  I'm keen to understand how I can better leverage
>> > sf's notation to compose the sql queries to duckdb....  but it seems
>> > to work!   I'm also still trying to determine if duckdb is using EWKB
>> > or vanilla WKB....
>> >
>> > ---
>> > Carl Boettiger
>> > http://carlboettiger.info/
>> >
>> > On Tue, Aug 15, 2023 at 4:02?PM Carl Boettiger <cboettig at gmail.com> wrote:
>> > >
>> > > Hi folks,
>> > >
>> > >
>> > > I'm curious if anyone has explored the relatively new spatial
>> > > extension in duckdb (https://duckdb.org/docs/extensions/spatial.html)
>> > > or has any pointers/tutorials regarding its use from R?
>> > >
>> > > Consider the following minimal example that seeks to use the sf
>> > > library to speak to duckdb:
>> > >
>> > >   library(duckdb)
>> > >   library(sf)
>> > >   conn <- DBI::dbConnect(duckdb::duckdb())
>> > >   status <- DBI::dbExecute(conn, "INSTALL 'spatial';")
>> > >   status <- DBI::dbExecute(conn, "LOAD 'spatial';")
>> > >
>> > >   test <- data.frame(site = letters[1:10], latitude = 1:10, longitude = 1:10)
>> > >   DBI::dbWriteTable(conn, "test", test)
>> > >
>> > > # Ok, let's try and make a geometry column
>> > >   query <- paste(
>> > >     'SELECT *, ST_Point(longitude, latitude) AS geom',
>> > >     'FROM "test"'
>> > >   )
>> > >
>> > >   ex <- st_read(con, query=query, geometry_column = "geom")
>> > >   ## error: reading wkb type 0 is not supported
>> > >
>> > >
>> > >   ex <- st_read(con, query=query, geometry_column = "geom", EWKB = FALSE)
>> > >   ## prints: wkbType: 1572864
>> > >   ## Error in CPL_read_wkb(x, EWKB, spatialite) : unsupported wkbType
>> > > dim in switch
>> > >
>> > >  We seem to get closer than I might have hoped (sf doesn't just insist
>> > > that conn isn't postgresgis), but is getting stuck on the encoding of
>> > > the wkb.  Is this something we can work around?  The queries seem to
>> > > run successfully, I just seem to be getting some unsupported ecoding
>> > > of the WKB geometry column....
>> > >
>> > > ---
>> > > Carl Boettiger
>> > > http://carlboettiger.info/
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From dewey @end|ng |rom dunn|ngton@c@  Wed Aug 16 02:58:16 2023
From: dewey @end|ng |rom dunn|ngton@c@ (Dewey Dunnington)
Date: Tue, 15 Aug 2023 21:58:16 -0300
Subject: [R-sig-Geo] Using duckdb spatial module from R (with sf)?
In-Reply-To: <CAN_1p9x+fN0LCt=cYhgykJtUuivcJTrQjh8wsmnpeiw7PimP8g@mail.gmail.com>
References: <CAN_1p9x+fN0LCt=cYhgykJtUuivcJTrQjh8wsmnpeiw7PimP8g@mail.gmail.com>
Message-ID: <538de7f1dbb391c306fdb8bd34c2c8ca@dunnington.ca>

I think you probably want ST_AsWKB() (almost certainly faster than hex).
The raw result looks like the internal geometry representation which is
probably something more like lwgeom's serialized form than WKB.
As far as I know, they have not yet implemented spatial index or 
prepared
geometry support; however, plug-and-chug computations like length, area,
and distance are likely to be much faster (if you turn on threading).
I haven't played with it much yet but am looking forward to it!

-dewey

library(duckdb)
#> Loading required package: DBI

conn <- DBI::dbConnect(duckdb::duckdb())
# status <- DBI::dbExecute(conn, "INSTALL 'spatial';")
status <- DBI::dbExecute(conn, "LOAD 'spatial';")

test <- data.frame(site = letters[1:10], latitude = 1:10, longitude = 
1:10)
DBI::dbWriteTable(conn, "test", test)

# Ok, let's try and make a geometry column
query <- paste(
   'SELECT *, ST_AsWKB(ST_Point(longitude, latitude)) AS geom',
   'FROM "test"'
)

sf::st_read(conn, query = query, geometry_column = "geom", EWKB = FALSE)
#> Simple feature collection with 10 features and 3 fields
#> Geometry type: POINT
#> Dimension:     XY
#> Bounding box:  xmin: 1 ymin: 1 xmax: 10 ymax: 10
#> CRS:           NA
#>    site latitude longitude          geom
#> 1     a        1         1   POINT (1 1)
#> 2     b        2         2   POINT (2 2)
#> 3     c        3         3   POINT (3 3)
#> 4     d        4         4   POINT (4 4)
#> 5     e        5         5   POINT (5 5)
#> 6     f        6         6   POINT (6 6)
#> 7     g        7         7   POINT (7 7)
#> 8     h        8         8   POINT (8 8)
#> 9     i        9         9   POINT (9 9)
#> 10    j       10        10 POINT (10 10)

On 2023-08-15 20:02, Carl Boettiger wrote:
> Hi folks,
> 
> 
> I'm curious if anyone has explored the relatively new spatial
> extension in duckdb (https://duckdb.org/docs/extensions/spatial.html)
> or has any pointers/tutorials regarding its use from R?
> 
> Consider the following minimal example that seeks to use the sf
> library to speak to duckdb:
> 
>   library(duckdb)
>   library(sf)
>   conn <- DBI::dbConnect(duckdb::duckdb())
>   status <- DBI::dbExecute(conn, "INSTALL 'spatial';")
>   status <- DBI::dbExecute(conn, "LOAD 'spatial';")
> 
>   test <- data.frame(site = letters[1:10], latitude = 1:10, longitude = 
> 1:10)
>   DBI::dbWriteTable(conn, "test", test)
> 
> # Ok, let's try and make a geometry column
>   query <- paste(
>     'SELECT *, ST_Point(longitude, latitude) AS geom',
>     'FROM "test"'
>   )
> 
>   ex <- st_read(con, query=query, geometry_column = "geom")
>   ## error: reading wkb type 0 is not supported
> 
> 
>   ex <- st_read(con, query=query, geometry_column = "geom", EWKB = 
> FALSE)
>   ## prints: wkbType: 1572864
>   ## Error in CPL_read_wkb(x, EWKB, spatialite) : unsupported wkbType
> dim in switch
> 
>  We seem to get closer than I might have hoped (sf doesn't just insist
> that conn isn't postgresgis), but is getting stuck on the encoding of
> the wkb.  Is this something we can work around?  The queries seem to
> run successfully, I just seem to be getting some unsupported ecoding
> of the WKB geometry column....
> 
> ---
> Carl Boettiger
> http://carlboettiger.info/
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From cboett|g @end|ng |rom gm@||@com  Wed Aug 16 07:22:49 2023
From: cboett|g @end|ng |rom gm@||@com (Carl Boettiger)
Date: Tue, 15 Aug 2023 22:22:49 -0700
Subject: [R-sig-Geo] Using duckdb spatial module from R (with sf)?
In-Reply-To: <538de7f1dbb391c306fdb8bd34c2c8ca@dunnington.ca>
References: <CAN_1p9x+fN0LCt=cYhgykJtUuivcJTrQjh8wsmnpeiw7PimP8g@mail.gmail.com>
 <538de7f1dbb391c306fdb8bd34c2c8ca@dunnington.ca>
Message-ID: <CAN_1p9xAsuOuiY9aOJ-bxwXCRpPQMxoZ76mX=suJmD7nX=6nNw@mail.gmail.com>

thanks Dewey, good call on st_aswkb.  yup I was puzzled as to what that
internal format is too! from the docs (
https://github.com/duckdblabs/duckdb_spatial#multi-tiered-geometry-type-system
)

> The internal binary format is very similar to the one used by PostGIS -
basically double aligned WKB, and we may eventually look into enforcing the
format to be properly compatible with PostGIS (which may be useful for the
PostGIS scanner extension)

so maybe one day this coercion won't be necessary.

The docs detail which operations are currently 'native' threaded duckdb and
which aren't
https://github.com/duckdblabs/duckdb_spatial#supported-functions
Looks like their roadmap might be of interest to users on this sig as well
(looks like spatial indexing is still on there
<https://github.com/duckdblabs/duckdb_spatial/issues/7>, but that's way
over my head).

So far this works pretty well for me! Using this trivial example of a
spatial polygon filter, I'm able to run a query against a GBIF parquet
snapshot (~2000+ parquet partitions, about 175 GB compressed) on an S3
bucket from duckdb without downloading in about 17 minutes.  (doing
approximately the same filtering using only the bounding box of the
polygon, ie. in pure duckdb, w/o spatial extension, takes about 8 minutes,
so the additional overhead of casting lat/long columns to geometry and
filtering with the polygon really isn't that bad!). Note that RAM use is
minimal, as expected.

Cheers,

Carl
---
Carl Boettiger
http://carlboettiger.info/

---
Carl Boettiger
http://carlboettiger.info/


On Tue, Aug 15, 2023 at 5:58?PM Dewey Dunnington <dewey at dunnington.ca>
wrote:

> I think you probably want ST_AsWKB() (almost certainly faster than hex).
> The raw result looks like the internal geometry representation which is
> probably something more like lwgeom's serialized form than WKB.
> As far as I know, they have not yet implemented spatial index or
> prepared
> geometry support; however, plug-and-chug computations like length, area,
> and distance are likely to be much faster (if you turn on threading).
> I haven't played with it much yet but am looking forward to it!
>
> -dewey
>
> library(duckdb)
> #> Loading required package: DBI
>
> conn <- DBI::dbConnect(duckdb::duckdb())
> # status <- DBI::dbExecute(conn, "INSTALL 'spatial';")
> status <- DBI::dbExecute(conn, "LOAD 'spatial';")
>
> test <- data.frame(site = letters[1:10], latitude = 1:10, longitude =
> 1:10)
> DBI::dbWriteTable(conn, "test", test)
>
> # Ok, let's try and make a geometry column
> query <- paste(
>    'SELECT *, ST_AsWKB(ST_Point(longitude, latitude)) AS geom',
>    'FROM "test"'
> )
>
> sf::st_read(conn, query = query, geometry_column = "geom", EWKB = FALSE)
> #> Simple feature collection with 10 features and 3 fields
> #> Geometry type: POINT
> #> Dimension:     XY
> #> Bounding box:  xmin: 1 ymin: 1 xmax: 10 ymax: 10
> #> CRS:           NA
> #>    site latitude longitude          geom
> #> 1     a        1         1   POINT (1 1)
> #> 2     b        2         2   POINT (2 2)
> #> 3     c        3         3   POINT (3 3)
> #> 4     d        4         4   POINT (4 4)
> #> 5     e        5         5   POINT (5 5)
> #> 6     f        6         6   POINT (6 6)
> #> 7     g        7         7   POINT (7 7)
> #> 8     h        8         8   POINT (8 8)
> #> 9     i        9         9   POINT (9 9)
> #> 10    j       10        10 POINT (10 10)
>
> On 2023-08-15 20:02, Carl Boettiger wrote:
> > Hi folks,
> >
> >
> > I'm curious if anyone has explored the relatively new spatial
> > extension in duckdb (https://duckdb.org/docs/extensions/spatial.html)
> > or has any pointers/tutorials regarding its use from R?
> >
> > Consider the following minimal example that seeks to use the sf
> > library to speak to duckdb:
> >
> >   library(duckdb)
> >   library(sf)
> >   conn <- DBI::dbConnect(duckdb::duckdb())
> >   status <- DBI::dbExecute(conn, "INSTALL 'spatial';")
> >   status <- DBI::dbExecute(conn, "LOAD 'spatial';")
> >
> >   test <- data.frame(site = letters[1:10], latitude = 1:10, longitude =
> > 1:10)
> >   DBI::dbWriteTable(conn, "test", test)
> >
> > # Ok, let's try and make a geometry column
> >   query <- paste(
> >     'SELECT *, ST_Point(longitude, latitude) AS geom',
> >     'FROM "test"'
> >   )
> >
> >   ex <- st_read(con, query=query, geometry_column = "geom")
> >   ## error: reading wkb type 0 is not supported
> >
> >
> >   ex <- st_read(con, query=query, geometry_column = "geom", EWKB =
> > FALSE)
> >   ## prints: wkbType: 1572864
> >   ## Error in CPL_read_wkb(x, EWKB, spatialite) : unsupported wkbType
> > dim in switch
> >
> >  We seem to get closer than I might have hoped (sf doesn't just insist
> > that conn isn't postgresgis), but is getting stuck on the encoding of
> > the wkb.  Is this something we can work around?  The queries seem to
> > run successfully, I just seem to be getting some unsupported ecoding
> > of the WKB geometry column....
> >
> > ---
> > Carl Boettiger
> > http://carlboettiger.info/
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From kev|n @end|ng |rom zembower@org  Thu Aug 31 21:47:43 2023
From: kev|n @end|ng |rom zembower@org (=?UTF-8?Q?Kevin_Zembower?=)
Date: Thu, 31 Aug 2023 19:47:43 +0000
Subject: [R-sig-Geo] Calculating median age for a group of US census blocks?
In-Reply-To: <mailman.29305.5.1691488802.58786.r-sig-geo@r-project.org>
References: <mailman.29305.5.1691488802.58786.r-sig-geo@r-project.org> 
 <b6e33db913412dc85d14aba08e38a43a0c40fb77.camel@zembower.org>
Message-ID: <0100018a4d2325c3-6d4eca02-124a-45ca-8df4-5955a0d8aeda-000000@email.amazonses.com>

Sorry to resurrect a long-dead thread, but I'm still struggling with my
desire to assign a median age to the population in a group of US census
blocks. I'm using the data from the US Census table P12, which bins the
ages into ranges.

I'm convinced (thank you!) that I can't compute the exact median age.
Can I compute the lower and upper bounds of the median age? Can I
assign all the people in a binned age range (say "20 to 29 years") to
the lower limit of the range, then compute the median of those ages,
and say that the true median age is between this lower limit and the
upper one, computed similarly?

If this is valid, how do I deal with the "85 years and older" bin? I
have 9 people 85 years and older, out of a total population of 537
people in my group of census blocks. For the lower bounds of the
median, I assign all 9 the age of 85. What can I do for the upper
bounds? 

I've done this, and found that the true median age is between 40 and 44
years old, if I drop all the "85 years and older" population as NA. The
true mean is between 39.96 and 43.46, similarly.?

One thought: If there are 9 people in the "85 years and older" group,
should I drop them and also drop the 9 youngest ages?

I look forward to reading your thoughts. Thank you for any advice and
guidance.

-Kevin

On Tue, 2023-08-08 at 12:00 +0200, r-sig-geo-request at r-project.org
wrote:
> 
> Message: 2
> Date: Mon, 7 Aug 2023 18:33:41 +0000
> From: Kevin Zembower <kevin at zembower.org>
> To: "r-sig-geo at r-project.org" <r-sig-geo at r-project.org>
> Subject: [R-sig-Geo] Calculating median age for a group of US census
> ????????blocks?
> Message-ID:
> ????????<01000189d146bd0d-ecb41aac-0501-46f4-b313-a1faebeff2a9-
> 000000 at email.amazonses.com>
> ????????
> Content-Type: text/plain; charset="utf-8"
> 
> Hello, all,
> 
> I'd like to obtain the median age for a population in a specific
> group 
> of US Decennial census blocks. Here's an example of the problem:
> 
> ## Example of calculating median age of population in census blocks.
> library(tidyverse)
> library(tidycensus)
> 
> counts <- get_decennial(
> ???? geography = "block",
> ???? state = "MD",
> ???? county = "Baltimore city",
> ???? table = "P1",
> ???? year = 2020,
> ???? sumfile = "dhc") %>%
> ???? mutate(NAME = NULL) %>%
> ???? filter(substr(GEOID, 6, 11) == "271101" &
> ??????????? substr(GEOID, 12, 15) %in% c(3000, 3001, 3002)
> ??????????? )
> 
> ages <- get_decennial(
> ???? geography = "block",
> ???? state = "MD",
> ???? county = "Baltimore city",
> ???? table = "P13",
> ???? year = 2020,
> ???? sumfile = "dhc") %>%
> ???? mutate(NAME = NULL) %>%
> ???? filter(substr(GEOID, 6, 11) == "271101" &
> ??????????? substr(GEOID, 12, 15) %in% c(3000, 3001, 3002)
> ??????????? )
> 
> I have two questions:
> 
> 1. Is it mathematically valid to multiply the population of a block
> by 
> the median age of that block (in other words, assign the median age
> to 
> each member of a block), then calculate the median of those numbers
> for 
> a group of blocks?
> 
> 2. Is raw data on the ages of individuals available anywhere else in
> the 
> census data? I can find tables such as P12, that breaks down the 
> population by age ranges or bins, but can't find specific data of
> counts 
> per age in years.
> 
> Thanks for your advice and help.
> 
> -Kevin
> 
> 
> 
> 
> ------------------------------
> 
> Message: 3
> Date: Mon, 7 Aug 2023 14:38:16 -0400
> From: Josiah Parry <josiah.parry at gmail.com>
> To: Kevin Zembower <kevin at zembower.org>
> Cc: "r-sig-geo at r-project.org" <r-sig-geo at r-project.org>
> Subject: Re: [R-sig-Geo]? Calculating median age for a group of US
> ????????census blocks?
> Message-ID:
> ????????<
> CAL3ufUJVvcZvdtYM2V0tmo9U-RMZ1zOGL8NZDhjK7V8GFc77HA at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
> 
> Hey Kevin, I don't think you're going to be able to get individual
> level
> data from the US Census Bureau. The closest you may be able to get is
> the
> current population survey (CPS) which I believe is also available via
> tidycensus. Regarding your first question, I'm not sure I follow what
> your
> objective is with it. I would use a geography of census block groups
> as the
> measure of median for census block groups. Otherwise it is unclear
> how you
> are defining what a "group of blocks" is.
> 
> ------------------------------
> 
> Message: 4
> Date: Mon, 7 Aug 2023 19:00:38 +0000
> From: Kevin Zembower <kevin at zembower.org>
> To: Josiah Parry <josiah.parry at gmail.com>
> Cc: "r-sig-geo at r-project.org" <r-sig-geo at r-project.org>
> Subject: Re: [R-sig-Geo]? Calculating median age for a group of US
> ????????census blocks?
> Message-ID:
> ????????<01000189d15f6aa3-d32ffe39-a210-436f-9f8f-cc551370f034-
> 000000 at email.amazonses.com>
> ????????
> Content-Type: text/plain; charset="utf-8"
> 
> Josiah, thanks for your reply.
> 
> Regarding my objective, I'm trying to compile census statistics for
> the 
> blocks that make up the neighborhood where I live. It consists of ten
> census blocks, of which I selected three for simplicity in my
> example. 
> The census block-group which contains these ten blocks also contains 
> some blocks which are outside of my neighborhood and shouldn't be 
> counted or included.
> 
> Since I won't be able to calculate the median age from the age and
> count 
> data, and since the individual data doesn't seem to be available, is
> it 
> your thought that I can't produce a valid median age for a group of 
> census blocks?
> 
> Thanks so much for your advice.
> 
> -Kevin
> 
> ------------------------------
> 
> Message: 5
> Date: Mon, 7 Aug 2023 18:45:48 +0000
> From: Sean Trende <strende at realclearpolitics.com>
> To: Josiah Parry <josiah.parry at gmail.com>, Kevin Zembower
> ????????<kevin at zembower.org>
> Cc: "r-sig-geo at r-project.org" <r-sig-geo at r-project.org>
> Subject: Re: [R-sig-Geo]? Calculating median age for a group of US
> ????????census blocks?
> Message-ID:
> ????????<
> BLAPR20MB39382F6CD501D6B1ED8F2C11BE0CA at BLAPR20MB3938.namprd20.prod.ou
> tlook.com>
> ????????
> Content-Type: text/plain; charset="utf-8"
> 
> This is correct on the second question, at least for more recent
> censuses.? On the first question, imagine a block where the ages of
> three individuals are 60, 50, and 40, and another one where the ages
> are 20, 20, and 20.? Using your approach you would have 50 * 3 = 150
> for the first block, and 20*3 = 60 for the second block.? The median
> of 60 and 150 is 105.? Even dividing that by three you get 35, which
> is not the correct median age (30).
> 
> ------------------------------
> 
> Message: 6
> Date: Mon, 7 Aug 2023 18:52:33 +0000
> From: Kevin Zembower <kevin at zembower.org>
> To: Sean Trende <strende at realclearpolitics.com>,? Josiah Parry
> ????????<josiah.parry at gmail.com>
> Cc: "r-sig-geo at r-project.org" <r-sig-geo at r-project.org>
> Subject: Re: [R-sig-Geo]? Calculating median age for a group of US
> ????????census blocks?
> Message-ID:
> ????????<01000189d1580211-8b8fa766-f820-4ae9-862b-e98e1a4881bf-
> 000000 at email.amazonses.com>
> ????????
> Content-Type: text/plain; charset="utf-8"
> 
> Yes, I see what you mean:
> 
> ?> median(c(60, 50, 40, 20, 20, 20))
> [1] 30
> ?> median(c(50, 50, 50, 20, 20, 20))
> [1] 35
> ?>
> 
> Thanks so much for that clear example.
> 
> -Kevin
> 
> ------------------------------
> 
> Message: 7
> Date: Mon, 7 Aug 2023 18:53:05 +0000
> From: Jeff Boggs <jboggs at brocku.ca>
> To: "r-sig-geo at r-project.org" <r-sig-geo at r-project.org>, Kevin
> ????????Zembower <kevin at zembower.org>
> Subject: Re: [R-sig-Geo]? Calculating median age for a group of US
> ????????census blocks?
> Message-ID:
> ????????<
> YT3PR01MB91703A158414A8F28FB4052FC00CA at YT3PR01MB9170.CANPRD01.PROD.OU
> TLOOK.COM>
> ????????
> Content-Type: text/plain; charset="us-ascii"
> 
> Responses to your questions:
> Q1: No. It is not mathematically valid, sadly.
> 
> Q2: I do not know, but your intuition that this is a possible
> solution is correct.
> 
> I don't use US Census data anymore, but suspect that the data exists.
> Whether they are publicly-available is a different question. I
> suspect, though, that block level age-sex cohort in five-year
> intervals is available, given this is the usual ingredient for a
> population pyramid. That data could be used to calculate a less exact
> median, if you make some simplifying assumptions.
> 
> Best regards,
> Jeff
> 
> ------------------------------
> 
> Message: 8
> Date: Mon, 7 Aug 2023 15:43:50 -0400
> From: Dexter Locke <dexter.locke at gmail.com>
> To: Kevin Zembower <kevin at zembower.org>
> Cc: Josiah Parry <josiah.parry at gmail.com>,? "r-sig-geo at r-project.org"
> ????????<r-sig-geo at r-project.org>
> Subject: Re: [R-sig-Geo]? Calculating median age for a group of US
> ????????census blocks?
> Message-ID:
> ????????<
> CAA=SVwHn=92B-k1tBZm2ioEW79gJx_QX0VD-x2UUEQOBQ+TEvg at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
> 
> Hi Kevin and all,
> 
> Given the binned data, you could count the number of people per age
> class
> for those 10 blocks. You can then express that in a number of
> different ways, like percent under 25 years old, or by calculating
> the
> dependency
> ratio
> <
> https://www.who.int/data/gho/indicator-metadata-registry/imr-details/1
> 119#:~:text=Definition%3A,a%20specific%20point%20in%20time.>
> .
> 
> I do think it is feasible to calculate an estimated mean from the
> counts
> within groups representing ranges. See, for example, here:
> https://stackoverflow.com/questions/18887382/how-to-calculate-the-median-on-grouped-dataset
> 
> Since you are working in Baltimore, you may consider looking at The
> Baltimore Neighborhood Indicators Alliance
> https://bniajfi.org/vital_signs/.
> They provide useful data on a range of issues (transportation, crime,
> education, environment etc.) including summaries from Census-derived
> demographics. What you are seeking may already exist. BNIA creates
> neighborhoods or "community statistical areas" (n=55) based on
> aggregates
> of Census data.
> 
> Although not pertaining to age, Baltimore City Planning has paid
> Census in
> the past to aggregate from individual-level Census data to the more
> colloquially-used definitions of Baltimore shown here (n = 273):
> https://data.baltimorecity.gov/datasets/neighborhood-1/explore?location=39.284832%2C-76.620516%2C12.91
> 
> Best, Dexter
> https://dexterlocke.com/
> 
> 




