From p.hiemstra at geo.uu.nl  Sat May  1 10:34:37 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemsta)
Date: Sat, 01 May 2010 10:34:37 +0200
Subject: [R-sig-Geo] Combining regions in one map
In-Reply-To: <7CD806EFDC19B64E82120E3FC0ADF6A35425E1@mx.ecoplan.local>
References: <7CD806EFDC19B64E82120E3FC0ADF6A35425E1@mx.ecoplan.local>
Message-ID: <4BDBE79D.6000407@geo.uu.nl>

Renger van Nieuwkoop wrote:
> Hi
> I just started using PBSmapping for R and have the following question:
> I have shape files for the quartier level of a big city.Now I want to combine several quartiers to one bigger region.
> I have an attribute which relates the PID from the quartiers to the regions, but I do not manage to get a map of the region.
> It might be simple, but I haven't found out yet.
> Can anybody help me?
> Thanks
> Renger
>
> _________________________________________
> Renger van Nieuwkoop
> Centre for Energy Policy and Economics, ETH
> Z?richbergstrasse 18 (ZUE)
> CH - 8032 Z?rich
> mailto: renger at vannieuwkoop.ch
>
>
>
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   
Take a look at unionSpatialPolygons in, I think, the maptools or gpclib 
package.

cheers,
Paul


From sjmyers at syr.edu  Sun May  2 08:02:46 2010
From: sjmyers at syr.edu (Seth J Myers)
Date: Sun, 2 May 2010 06:02:46 +0000
Subject: [R-sig-Geo] from idirisi to s-plus to r
Message-ID: <266CBFBFD14254478D52158AE6BF90170C324AB7@BL2PRD0103MB038.prod.exchangelabs.com>

Hi,

I use IDRISI as my main raster GIS program and R for stats.  IDRISI has an export to s-plus function that allows you to mask a raster file for sampling and then export into a format that supposedly works with s-plus.  What this ends up being is a .txt file with spaces between adjacent columns but no seeming rhyme or reason as far as column width (it varies seemingly arbitrarily and IDRISI help is no help in this area).  They are of fixed width for each column, but the width is not consistent among columns.  

I know I could import IDRISI .rst files into R, but this is very wasteful of memory as I only need a small % of large files.  My questions are: 1) is there an easier export format to move a sample of an IDRISI .rst file into R?  2) is there a way to import a .txt file into R that will ignore repetitive spacing?  (meaning two columns can be separated by 1 or more spaces but the number of spaces is not specified).  I would just specify column width for each column in each file, but I have many files with 43 columns each, so I prefer to avoid brute force here.  Thanks, Seth

From sjmyers at syr.edu  Sun May  2 08:09:17 2010
From: sjmyers at syr.edu (Seth J Myers)
Date: Sun, 2 May 2010 06:09:17 +0000
Subject: [R-sig-Geo] please ignore IDRISI to R question from 3 min ago
Message-ID: <266CBFBFD14254478D52158AE6BF90170C324AC2@BL2PRD0103MB038.prod.exchangelabs.com>

I disobeyed my firm rule, never right emails without careful thought after several hours of analysis and 3 beers on a saturday night ;)  -Seth


From j.m.signer at gmail.com  Sun May  2 17:29:34 2010
From: j.m.signer at gmail.com (Johannes Signer)
Date: Sun, 2 May 2010 17:29:34 +0200
Subject: [R-sig-Geo] Summary of multiple rasters
Message-ID: <k2iaa7630001005020829zb057b145t7cd8c22303f49b98@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100502/815f2411/attachment.pl>

From muhammad.rahiz at ouce.ox.ac.uk  Sun May  2 20:10:49 2010
From: muhammad.rahiz at ouce.ox.ac.uk (Muhammad Rahiz)
Date: Sun, 02 May 2010 19:10:49 +0100
Subject: [R-sig-Geo] help with color scale
Message-ID: <4BDDC029.9070706@ouce.ox.ac.uk>

Hi all,

I hope someone can help me with this.

Given,

library(fields)
x <- array(rnorm(100),dim=c(50,50))
image.plot(x)

I want to change the range in the color bar so that the range is from -1 
to 1. I did adjust the image.plot() command to

image.plot(x,zlim=c(-1,1))

but the image shows white spaces.

How can I set the the color scale such that values  which are less than 
- 1 are assigned a color e.g. blue and those which are more than  1 are 
assigned red.

In essence, how do I make the color scale to reflect the a certain band 
of values i.e.

color 1 = > 1
color 2 =  0.9 to 1
color 3 = 0.8 to 0.9
...
color 8 = -0.8 to -0.9
color 9 = -0.9 to -1
color 10  = < -1


Muhammad


From gildemir at gmail.com  Mon May  3 04:49:47 2010
From: gildemir at gmail.com (Francisco Silva)
Date: Sun, 2 May 2010 23:49:47 -0300
Subject: [R-sig-Geo] R-sig-Geo Digest, Vol 81, Issue 2
In-Reply-To: <mailman.1.1272794402.2320.r-sig-geo@stat.math.ethz.ch>
References: <mailman.1.1272794402.2320.r-sig-geo@stat.math.ethz.ch>
Message-ID: <p2v48d290dc1005021949sf74cefcau32156edcc41940b8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100502/2417d3e6/attachment.pl>

From hengl at spatial-analyst.net  Mon May  3 10:56:17 2010
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Mon, 3 May 2010 10:56:17 +0200
Subject: [R-sig-Geo] Summary of multiple rasters
In-Reply-To: <k2iaa7630001005020829zb057b145t7cd8c22303f49b98@mail.gmail.com>
References: <k2iaa7630001005020829zb057b145t7cd8c22303f49b98@mail.gmail.com>
Message-ID: <002c01caea9e$7ebf2970$7c3d7c50$@net>


Dear Johannes,

Looks like you are in the field of error propagation [http://spatial-accuracy.org/workshopSUP]. 

Both mean and median are valid statistical parameters to describe the central tendencies. What is often more interesting is the propagated uncertainty in the final estimates. I assume that your output is a binomial variable? In our 
HESS paper [http://www.hydrol-earth-syst-sci-discuss.net/7/767/2010/hessd-7-767-2010.html], we use the Information entropy index to quantify the uncertainty of the model (we deal with a binary/Bernoulli variable). The code and the dataset can be obtained from: [http://geomorphometry.org/content/uncertainty-stream-networks-derived-elevation-data]

A number of (Gaussian) grid statistics parameters can be derived using SAGA GIS:

> library(RSAGA)
> rsaga.get.usage(lib="geostatistics_grid", module=5)
SAGA CMD 2.0.3
library path:   C:/PROGRA~1/R/R-210~1.1/library/RSAGA/saga_vc/modules
library name:   geostatistics_grid
module name :   Statistics for Grids
Usage: 5 -GRIDS <str> [-MEAN <str>] [-MIN <str>] [-MAX <str>] [-VAR <str>] [-STDDEV <str>] [-STDDEVLO <str>] [-STDDEVHI <str>]
  -GRIDS:<str>          Grids
        Grid list (input)
  -MEAN:<str>           Arithmetic Mean
        Grid (optional output)
  -MIN:<str>            Minimum
        Grid (optional output)
  -MAX:<str>            Maximum
        Grid (optional output)
  -VAR:<str>            Variance
        Grid (optional output)
  -STDDEV:<str>         Standard Deviation
        Grid (optional output)
  -STDDEVLO:<str>       Mean less Standard Deviation
        Grid (optional output)
  -STDDEVHI:<str>       Mean plus Standard Deviation



HTH,

T. Hengl



> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-
> bounces at stat.math.ethz.ch] On Behalf Of Johannes Signer
> Sent: Sunday, May 02, 2010 5:30 PM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] Summary of multiple rasters
> 
> Dear List,
> 
> my problem is as follows:
> 
> I have a model that predicts me the distribution  of a species in the
> landscape. I run that model several times and now I am not sure which
> summary statistic to use (mean, median). Is there an index to get an idea of
> how the prediction in each cell are distributed?
> 
> Any are greatly appreciated,
> 
> Thanks
> Johannes
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From jim at bitwrit.com.au  Mon May  3 13:08:17 2010
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 03 May 2010 21:08:17 +1000
Subject: [R-sig-Geo] help with color scale
In-Reply-To: <4BDDC029.9070706@ouce.ox.ac.uk>
References: <4BDDC029.9070706@ouce.ox.ac.uk>
Message-ID: <4BDEAEA1.80600@bitwrit.com.au>

On 05/03/2010 04:10 AM, Muhammad Rahiz wrote:
> Hi all,
>
> I hope someone can help me with this.
>
> Given,
>
> library(fields)
> x <- array(rnorm(100),dim=c(50,50))
> image.plot(x)
>
> I want to change the range in the color bar so that the range is from -1
> to 1. I did adjust the image.plot() command to
>
> image.plot(x,zlim=c(-1,1))
>
> but the image shows white spaces.
>
> How can I set the the color scale such that values which are less than -
> 1 are assigned a color e.g. blue and those which are more than 1 are
> assigned red.
>
> In essence, how do I make the color scale to reflect the a certain band
> of values i.e.
>
> color 1 = > 1
> color 2 = 0.9 to 1
> color 3 = 0.8 to 0.9
> ...
> color 8 = -0.8 to -0.9
> color 9 = -0.9 to -1
> color 10 = < -1
>
Hi Muhammad,
The color.scale function in the plotrix package will translate numeric 
values into colors. for example:

imagecolors<-color.scale(x,c(0,1),0,c(1,0))

gives a very simple color scale going from blue at the minimum value to 
red at the maximum. Look at the examples in the color2d.matplot help 
page to see how you can do fancier color mappings.

Jim


From muhammad.rahiz at ouce.ox.ac.uk  Mon May  3 16:43:18 2010
From: muhammad.rahiz at ouce.ox.ac.uk (Muhammad Rahiz)
Date: Mon, 03 May 2010 15:43:18 +0100
Subject: [R-sig-Geo] help with color scale
In-Reply-To: <4BDEAEA1.80600@bitwrit.com.au>
References: <4BDDC029.9070706@ouce.ox.ac.uk> <4BDEAEA1.80600@bitwrit.com.au>
Message-ID: <4BDEE106.9060102@ouce.ox.ac.uk>

Thanks Arien & Jim for the useful tips.

I've used both methods suggested but am still not getting the desired 
results.

The problem with my actual data is that it contains several extreme 
values/outliers.The lab.breaks argument in image.plot() is able to 
assign a color to a specific range of value e.g. red = 0.9 to 1. But I 
also want to assign a color to any values which are > 1 (e.g. 1.10, 
2.15, 25) and < 1 but I'm not able to do that unless i set the color 
scale to include the whole range of values - which does not look pretty.

My last resort is to do a small manipulation by using the if/ifelse 
function to assign a number to values that beyond a certain threshold 
before I plot them.


Muhammad



Jim Lemon wrote:
> On 05/03/2010 04:10 AM, Muhammad Rahiz wrote:
>   
>> Hi all,
>>
>> I hope someone can help me with this.
>>
>> Given,
>>
>> library(fields)
>> x <- array(rnorm(100),dim=c(50,50))
>> image.plot(x)
>>
>> I want to change the range in the color bar so that the range is from -1
>> to 1. I did adjust the image.plot() command to
>>
>> image.plot(x,zlim=c(-1,1))
>>
>> but the image shows white spaces.
>>
>> How can I set the the color scale such that values which are less than -
>> 1 are assigned a color e.g. blue and those which are more than 1 are
>> assigned red.
>>
>> In essence, how do I make the color scale to reflect the a certain band
>> of values i.e.
>>
>> color 1 = > 1
>> color 2 = 0.9 to 1
>> color 3 = 0.8 to 0.9
>> ...
>> color 8 = -0.8 to -0.9
>> color 9 = -0.9 to -1
>> color 10 = < -1
>>
>>     
> Hi Muhammad,
> The color.scale function in the plotrix package will translate numeric 
> values into colors. for example:
>
> imagecolors<-color.scale(x,c(0,1),0,c(1,0))
>
> gives a very simple color scale going from blue at the minimum value to 
> red at the maximum. Look at the examples in the color2d.matplot help 
> page to see how you can do fancier color mappings.
>
> Jim
>
>


From roberto.patuelli at usi.ch  Mon May  3 19:02:57 2010
From: roberto.patuelli at usi.ch (Roberto Patuelli)
Date: Mon, 3 May 2010 19:02:57 +0200
Subject: [R-sig-Geo] Mapping a factor
Message-ID: <132B95067A7348D29C73E1251D4F4D91@Ciretto>

Dear All,

I'm having trouble mapping the levels of a factor.
This is the code I have as of now. The legend works fine (suggesting that 
item "colours" is correct), but not the map!

gino = factor(data_abs1$Ethnic.Dominance, labels = c(" French", " German", " 
Italian", " Portuguese", " Spanish", " Fmr. Yugoslavian", " Turkish"))
colours = rev(bpy.colors(n = length(levels(gino)), cutoff.tails = 0.2))
submap <- swiss.map[data_abs$FORACTIVE >=5 & data_abs$NAME != "D?moret",] # 
this is only to build a smaller map which excludes some regions
plot(swiss.map, axes = FALSE)
plot(submap, add = TRUE, col = colours[findInterval(gino, levels(gino), 
all.inside = FALSE)])
legend("topleft", xjust = 0, ncol = 1, legend = levels(gino), fill = 
colours, bty ="n", title = "CIAO")


Can anyone clear the problem?

Thanks a lot
Roberto

********************
Roberto Patuelli, Ph.D.
Istituto Ricerche Economiche (IRE) (Institute for Economic Research)
Universit? della Svizzera Italiana (University of Lugano)
via Maderno 24, CP 4361
CH-6904 Lugano
Switzerland
Phone: +41-(0)58-666-4166
Fax: +39-02-700419665
Email: roberto.patuelli at usi.ch
Homepage: http://www.people.lu.unisi.ch/patuellr


From mark_connolly at acm.org  Mon May  3 23:08:53 2010
From: mark_connolly at acm.org (Mark Connolly)
Date: Mon, 03 May 2010 17:08:53 -0400
Subject: [R-sig-Geo] negative range from fit.variogram through
	autofitVariogram
Message-ID: <4BDF3B65.6040006@acm.org>

I am using autofitVariogram during the process of interpolating a large 
set of daily observations through a volume.  Each volume is decomposed 
into 2D layers prior to selecting a model to use for interpolation.  I 
made it through 2010 interpolations and then ran into a failed 
interpolation when the best model selected by autofitVariogram had a 
negative range.  This was rejected by the krige function.  I see mention 
of negative sills but not of negative ranges.

It appears that autofitVariogram is having some issues with the trial 
arguments sent to fit.variogram.  This is repeatable.  Not sure if this 
is a bug for some package or a data issue.  The data values do not look 
overly strange.



# data
sparse =
structure(list(x = c(740381.862, 740456.052, 740503.958, 740551.752,
740559.502, 740502.995, 740446, 740389.229, 740371.693, 740428.25,
740484.918, 740541.356, 740549.277, 740474.724, 740418.118, 740370.187,
740354.321, 740410.53, 740467.451, 740523.772, 740522.433, 740474.797,
740400.293, 740343.175, 740336.067, 740392.917, 740449.622, 740506.162,
740495.664, 740448.693, 740382.062, 740325.464, 740318.174, 740430.337,
740488.37, 740477.578, 740429.695, 740373.133, 740325.408, 740631.842,
740688.362, 740744.857, 740726.149, 740695.778, 740621.663, 740613.553,
740670.205, 740726.566, 740733.965, 740660.272, 740620.315, 740594.82,
740651.714, 740708.217, 740690.056, 740659.603, 740575.902, 740576.796,
740558.179), y = c(181644.086, 181620.772, 181605.577, 181590.417,
181568.637, 181586.847, 181604.615, 181622.136, 181565.531, 181547.708,
181530.169, 181512.439, 181490.328, 181513.956, 181531.875, 181547.048,
181508.946, 181491.148, 181473.394, 181455.233, 181436.726, 181452.342,
181475.522, 181492.661, 181451.96, 181434.265, 181416.566, 181398.729,
181382.764, 181397.808, 181418.748, 181436.677, 181395.477, 181360.409,
181342.547, 181327.09, 181341.971, 181359.55, 181374.453, 181546.959,
181528.576, 181510.58, 181497.501, 181507.159, 181530.759, 181490.008,
181472.209, 181453.968, 181432.87, 181456.085, 181468.588, 181433.854,
181415.758, 181397.497, 181384.359, 181393.795, 181420.579, 181376.982,
181363.899), depth_cm = c(-8, -8, -8, -8, -8, -8, -8, -8, -8,
-8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8,
-8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8,
-8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8,
-8, -8), theta_percent = c(23.63, 19.68, 23.81, 22.01, 23.98,
12.8, 14.92, 20.49, 22.59, 24.32, 20.24, 23.03, 12.97, 19.09,
39.2, 12.09, 24.52, 25.57, 25.5, 19.76, 19.17, 21.98, 7.5, 22.75,
17.85, 17.75, 17.95, 26.93, 18.84, 22.95, 23.71, 25.03, 40.69,
9.7, 24.66, 17.43, 16.3, 24.13, 19.98, 23.35, 12.16, 17.24, 14.29,
34.42, 21.84, 25.63, 20.51, 25.87, 24.44, 22.35, 8.57, 21.43,
25.63, 21.56, 21.49, 17.66, 25.61, 24.11, 28.31)), .Names = c("x",
"y", "depth_cm", "theta_percent"), row.names = c("1", "5", "10",
"15", "20", "25", "30", "35", "40", "45", "50", "55", "60", "65",
"70", "75", "80", "85", "90", "95", "100", "105", "109", "114",
"119", "124", "129", "134", "139", "144", "149", "154", "159",
"164", "169", "174", "179", "184", "188", "193", "198", "203",
"208", "213", "218", "223", "228", "233", "238", "243", "248",
"253", "258", "263", "268", "273", "278", "283", "288"), class = 
"data.frame")


# the broken fit for best search
require("automap")
coordinates(sparse) = c("x", "y", "depth_cm")
proj4string(sparse) = CRS("+init=epsg:32119")
v.fit <- autofitVariogram(theta_percent~1, sparse)


There were 50 or more warnings (use warnings() to see the first 50)
 > warnings()
Warning messages:
1: In getModel(initial_sill - initial_nugget, m, initial_range,  ... :
   An error has occured during variogram fitting. Used:
         nugget: 34.1432533936652
         model:  Exp
         psill:  13.2004974623731
         range:  53.1549477005646
         kappa:  NA
   as initial guess. This particular variogram fit is not taken into 
account.
Gstat error:
Error in if (direct[direct$id == id, "is.direct"] && any(model$psill <  :
   missing value where TRUE/FALSE needed

2: In fit.variogram(object, model, fit.sills = fit.sills,  ... :
   value out of range in 'bessel_k'
3 ...


# a quick visual of the data in the field
rescale = function(x, to=c(1,10)) (x - min(x)) * ((max(to) - 
min(to))/(max(x) - min(x)))
require("rgl")
sparse_df=as.data.frame(sparse)
spheres3d(sparse_df$x, sparse_df$y, sparse_df$depth_cm, 
radius=rescale(sparse_df$theta_percent))


From christoph.hofer at env.ethz.ch  Tue May  4 09:39:59 2010
From: christoph.hofer at env.ethz.ch (Christoph Hofer)
Date: Tue, 4 May 2010 09:39:59 +0200
Subject: [R-sig-Geo] expand the dist covariate of the prediction-grid
	meuse.grid (sp package)
Message-ID: <3DAB392E-081E-4146-AF25-493DB6B7847A@env.ethz.ch>

Dear list


I would like to expand the covariate "dist"  of the meuse.grid dataset, of the sp package,
to the south-east direction. The value of the covariate dist is relative between [0,1].
Now, it is not clear for me how I shall calculate the distance between
a new gird point and the river (is it the perpendicular between the river border and the grid point)?

I appreciate for any tips or hints.



Christoph





ETH Zurich
Christoph Hofer
Soil and Terrestrial Environmental Physics
Institute of Terrestrial Ecosystems
CHN E 50.2
Universit?tstrasse 16
8092 Zurich, Switzerland
phone         (+41) - (0)44 - 633 63 65
fax               (+41) - (0)44 - 633 11 23
e-mail: christoph.hofer at env.ethz.ch


From p.hiemstra at geo.uu.nl  Tue May  4 11:05:12 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 04 May 2010 11:05:12 +0200
Subject: [R-sig-Geo] negative range from fit.variogram
	through	autofitVariogram
In-Reply-To: <4BDF3B65.6040006@acm.org>
References: <4BDF3B65.6040006@acm.org>
Message-ID: <4BDFE348.3080204@geo.uu.nl>

Hi Mark,

Thanks for the reproducible example. The problem is that when I look at 
the sample variogram, the semivariance values start high and end low. 
This is best illustrated by:

plot(variogram(theta_percent~1, sparse))

You see that there are outliers in the data that cause high 
semi-variance at a short distance. I would say that is 'strange' ;). You 
can try and identify which point causes this by:

plot(variogram(theta_percent~1, sparse, cloud = TRUE), identify = TRUE)
# Click on the plot to identify the point pairs

There is not really one value I think that causes this. It might be also 
attributable to the fact that your dataset is somewhat sparse in the 
distance range from 20-40 m.

As a quick fix you can restrict the model selection to "Sph", this 
works. And I would not be enthusiastic about using Ste. This is because 
the main difference between different kappa values if the behavior at 
short distances, but you don't have a lot of data on the short distance 
to fit this value on in a meaningful way.

At this stage I don't see a (relatively quick) fix that could solve this 
problem in an automatic way and on a more fundamental level. Do you have 
any suggestions? From an implementation point of view I can let automap 
discard any model that has negative values in it, this would ensure that 
the user gets at least the Sph model back.

cheers,
Paul

Mark Connolly wrote:
> I am using autofitVariogram during the process of interpolating a 
> large set of daily observations through a volume.  Each volume is 
> decomposed into 2D layers prior to selecting a model to use for 
> interpolation.  I made it through 2010 interpolations and then ran 
> into a failed interpolation when the best model selected by 
> autofitVariogram had a negative range.  This was rejected by the krige 
> function.  I see mention of negative sills but not of negative ranges.
>
> It appears that autofitVariogram is having some issues with the trial 
> arguments sent to fit.variogram.  This is repeatable.  Not sure if 
> this is a bug for some package or a data issue.  The data values do 
> not look overly strange.
>
>
>
> # data
> sparse =
> structure(list(x = c(740381.862, 740456.052, 740503.958, 740551.752,
> 740559.502, 740502.995, 740446, 740389.229, 740371.693, 740428.25,
> 740484.918, 740541.356, 740549.277, 740474.724, 740418.118, 740370.187,
> 740354.321, 740410.53, 740467.451, 740523.772, 740522.433, 740474.797,
> 740400.293, 740343.175, 740336.067, 740392.917, 740449.622, 740506.162,
> 740495.664, 740448.693, 740382.062, 740325.464, 740318.174, 740430.337,
> 740488.37, 740477.578, 740429.695, 740373.133, 740325.408, 740631.842,
> 740688.362, 740744.857, 740726.149, 740695.778, 740621.663, 740613.553,
> 740670.205, 740726.566, 740733.965, 740660.272, 740620.315, 740594.82,
> 740651.714, 740708.217, 740690.056, 740659.603, 740575.902, 740576.796,
> 740558.179), y = c(181644.086, 181620.772, 181605.577, 181590.417,
> 181568.637, 181586.847, 181604.615, 181622.136, 181565.531, 181547.708,
> 181530.169, 181512.439, 181490.328, 181513.956, 181531.875, 181547.048,
> 181508.946, 181491.148, 181473.394, 181455.233, 181436.726, 181452.342,
> 181475.522, 181492.661, 181451.96, 181434.265, 181416.566, 181398.729,
> 181382.764, 181397.808, 181418.748, 181436.677, 181395.477, 181360.409,
> 181342.547, 181327.09, 181341.971, 181359.55, 181374.453, 181546.959,
> 181528.576, 181510.58, 181497.501, 181507.159, 181530.759, 181490.008,
> 181472.209, 181453.968, 181432.87, 181456.085, 181468.588, 181433.854,
> 181415.758, 181397.497, 181384.359, 181393.795, 181420.579, 181376.982,
> 181363.899), depth_cm = c(-8, -8, -8, -8, -8, -8, -8, -8, -8,
> -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8,
> -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8,
> -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8,
> -8, -8), theta_percent = c(23.63, 19.68, 23.81, 22.01, 23.98,
> 12.8, 14.92, 20.49, 22.59, 24.32, 20.24, 23.03, 12.97, 19.09,
> 39.2, 12.09, 24.52, 25.57, 25.5, 19.76, 19.17, 21.98, 7.5, 22.75,
> 17.85, 17.75, 17.95, 26.93, 18.84, 22.95, 23.71, 25.03, 40.69,
> 9.7, 24.66, 17.43, 16.3, 24.13, 19.98, 23.35, 12.16, 17.24, 14.29,
> 34.42, 21.84, 25.63, 20.51, 25.87, 24.44, 22.35, 8.57, 21.43,
> 25.63, 21.56, 21.49, 17.66, 25.61, 24.11, 28.31)), .Names = c("x",
> "y", "depth_cm", "theta_percent"), row.names = c("1", "5", "10",
> "15", "20", "25", "30", "35", "40", "45", "50", "55", "60", "65",
> "70", "75", "80", "85", "90", "95", "100", "105", "109", "114",
> "119", "124", "129", "134", "139", "144", "149", "154", "159",
> "164", "169", "174", "179", "184", "188", "193", "198", "203",
> "208", "213", "218", "223", "228", "233", "238", "243", "248",
> "253", "258", "263", "268", "273", "278", "283", "288"), class = 
> "data.frame")
>
>
> # the broken fit for best search
> require("automap")
> coordinates(sparse) = c("x", "y", "depth_cm")
> proj4string(sparse) = CRS("+init=epsg:32119")
> v.fit <- autofitVariogram(theta_percent~1, sparse)
>
>
> There were 50 or more warnings (use warnings() to see the first 50)
> > warnings()
> Warning messages:
> 1: In getModel(initial_sill - initial_nugget, m, initial_range,  ... :
>   An error has occured during variogram fitting. Used:
>         nugget: 34.1432533936652
>         model:  Exp
>         psill:  13.2004974623731
>         range:  53.1549477005646
>         kappa:  NA
>   as initial guess. This particular variogram fit is not taken into 
> account.
> Gstat error:
> Error in if (direct[direct$id == id, "is.direct"] && any(model$psill <  :
>   missing value where TRUE/FALSE needed
>
> 2: In fit.variogram(object, model, fit.sills = fit.sills,  ... :
>   value out of range in 'bessel_k'
> 3 ...
>
>
> # a quick visual of the data in the field
> rescale = function(x, to=c(1,10)) (x - min(x)) * ((max(to) - 
> min(to))/(max(x) - min(x)))
> require("rgl")
> sparse_df=as.data.frame(sparse)
> spheres3d(sparse_df$x, sparse_df$y, sparse_df$depth_cm, 
> radius=rescale(sparse_df$theta_percent))
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From k.oreilly at imperial.ac.uk  Tue May  4 11:30:54 2010
From: k.oreilly at imperial.ac.uk (kath_o_reilly)
Date: Tue, 4 May 2010 02:30:54 -0700 (PDT)
Subject: [R-sig-Geo] sp2WB in Maptools - order of polygons
Message-ID: <1272965454819-5002508.post@n2.nabble.com>


Dear R users,

I plan on using the command sp2WB to convert a .shp file to a .map file in
order to carry out some analysis in WinBUGS. Thanks for the threads I've
followed on how to do this.

The command itself is working fine and produces the map I would expect.
However to analyse the data for each polygon, I need to know which polygon
is which. How do I determine the ID for each polygon generated? I'm hoping
there is a better solution than figuring it out by hand...

Regards,

Kath O'Reilly 
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/sp2WB-in-Maptools-order-of-polygons-tp5002508p5002508.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From p.hiemstra at geo.uu.nl  Tue May  4 11:49:16 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 04 May 2010 11:49:16 +0200
Subject: [R-sig-Geo] negative range from
	fit.variogram	through	autofitVariogram
In-Reply-To: <4BDFE348.3080204@geo.uu.nl>
References: <4BDF3B65.6040006@acm.org> <4BDFE348.3080204@geo.uu.nl>
Message-ID: <4BDFED9C.3010703@geo.uu.nl>

I just uploaded a new version of automap (1.07) that fixes this problem. 
It deletes fitted variogram models with a negative sill/range/nugget.

cheers,
Paul

Paul Hiemstra wrote:
> Hi Mark,
>
> Thanks for the reproducible example. The problem is that when I look 
> at the sample variogram, the semivariance values start high and end 
> low. This is best illustrated by:
>
> plot(variogram(theta_percent~1, sparse))
>
> You see that there are outliers in the data that cause high 
> semi-variance at a short distance. I would say that is 'strange' ;). 
> You can try and identify which point causes this by:
>
> plot(variogram(theta_percent~1, sparse, cloud = TRUE), identify = TRUE)
> # Click on the plot to identify the point pairs
>
> There is not really one value I think that causes this. It might be 
> also attributable to the fact that your dataset is somewhat sparse in 
> the distance range from 20-40 m.
>
> As a quick fix you can restrict the model selection to "Sph", this 
> works. And I would not be enthusiastic about using Ste. This is 
> because the main difference between different kappa values if the 
> behavior at short distances, but you don't have a lot of data on the 
> short distance to fit this value on in a meaningful way.
>
> At this stage I don't see a (relatively quick) fix that could solve 
> this problem in an automatic way and on a more fundamental level. Do 
> you have any suggestions? From an implementation point of view I can 
> let automap discard any model that has negative values in it, this 
> would ensure that the user gets at least the Sph model back.
>
> cheers,
> Paul
>
> Mark Connolly wrote:
>> I am using autofitVariogram during the process of interpolating a 
>> large set of daily observations through a volume.  Each volume is 
>> decomposed into 2D layers prior to selecting a model to use for 
>> interpolation.  I made it through 2010 interpolations and then ran 
>> into a failed interpolation when the best model selected by 
>> autofitVariogram had a negative range.  This was rejected by the 
>> krige function.  I see mention of negative sills but not of negative 
>> ranges.
>>
>> It appears that autofitVariogram is having some issues with the trial 
>> arguments sent to fit.variogram.  This is repeatable.  Not sure if 
>> this is a bug for some package or a data issue.  The data values do 
>> not look overly strange.
>>
>>
>>
>> # data
>> sparse =
>> structure(list(x = c(740381.862, 740456.052, 740503.958, 740551.752,
>> 740559.502, 740502.995, 740446, 740389.229, 740371.693, 740428.25,
>> 740484.918, 740541.356, 740549.277, 740474.724, 740418.118, 740370.187,
>> 740354.321, 740410.53, 740467.451, 740523.772, 740522.433, 740474.797,
>> 740400.293, 740343.175, 740336.067, 740392.917, 740449.622, 740506.162,
>> 740495.664, 740448.693, 740382.062, 740325.464, 740318.174, 740430.337,
>> 740488.37, 740477.578, 740429.695, 740373.133, 740325.408, 740631.842,
>> 740688.362, 740744.857, 740726.149, 740695.778, 740621.663, 740613.553,
>> 740670.205, 740726.566, 740733.965, 740660.272, 740620.315, 740594.82,
>> 740651.714, 740708.217, 740690.056, 740659.603, 740575.902, 740576.796,
>> 740558.179), y = c(181644.086, 181620.772, 181605.577, 181590.417,
>> 181568.637, 181586.847, 181604.615, 181622.136, 181565.531, 181547.708,
>> 181530.169, 181512.439, 181490.328, 181513.956, 181531.875, 181547.048,
>> 181508.946, 181491.148, 181473.394, 181455.233, 181436.726, 181452.342,
>> 181475.522, 181492.661, 181451.96, 181434.265, 181416.566, 181398.729,
>> 181382.764, 181397.808, 181418.748, 181436.677, 181395.477, 181360.409,
>> 181342.547, 181327.09, 181341.971, 181359.55, 181374.453, 181546.959,
>> 181528.576, 181510.58, 181497.501, 181507.159, 181530.759, 181490.008,
>> 181472.209, 181453.968, 181432.87, 181456.085, 181468.588, 181433.854,
>> 181415.758, 181397.497, 181384.359, 181393.795, 181420.579, 181376.982,
>> 181363.899), depth_cm = c(-8, -8, -8, -8, -8, -8, -8, -8, -8,
>> -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8,
>> -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8,
>> -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8,
>> -8, -8), theta_percent = c(23.63, 19.68, 23.81, 22.01, 23.98,
>> 12.8, 14.92, 20.49, 22.59, 24.32, 20.24, 23.03, 12.97, 19.09,
>> 39.2, 12.09, 24.52, 25.57, 25.5, 19.76, 19.17, 21.98, 7.5, 22.75,
>> 17.85, 17.75, 17.95, 26.93, 18.84, 22.95, 23.71, 25.03, 40.69,
>> 9.7, 24.66, 17.43, 16.3, 24.13, 19.98, 23.35, 12.16, 17.24, 14.29,
>> 34.42, 21.84, 25.63, 20.51, 25.87, 24.44, 22.35, 8.57, 21.43,
>> 25.63, 21.56, 21.49, 17.66, 25.61, 24.11, 28.31)), .Names = c("x",
>> "y", "depth_cm", "theta_percent"), row.names = c("1", "5", "10",
>> "15", "20", "25", "30", "35", "40", "45", "50", "55", "60", "65",
>> "70", "75", "80", "85", "90", "95", "100", "105", "109", "114",
>> "119", "124", "129", "134", "139", "144", "149", "154", "159",
>> "164", "169", "174", "179", "184", "188", "193", "198", "203",
>> "208", "213", "218", "223", "228", "233", "238", "243", "248",
>> "253", "258", "263", "268", "273", "278", "283", "288"), class = 
>> "data.frame")
>>
>>
>> # the broken fit for best search
>> require("automap")
>> coordinates(sparse) = c("x", "y", "depth_cm")
>> proj4string(sparse) = CRS("+init=epsg:32119")
>> v.fit <- autofitVariogram(theta_percent~1, sparse)
>>
>>
>> There were 50 or more warnings (use warnings() to see the first 50)
>> > warnings()
>> Warning messages:
>> 1: In getModel(initial_sill - initial_nugget, m, initial_range,  ... :
>>   An error has occured during variogram fitting. Used:
>>         nugget: 34.1432533936652
>>         model:  Exp
>>         psill:  13.2004974623731
>>         range:  53.1549477005646
>>         kappa:  NA
>>   as initial guess. This particular variogram fit is not taken into 
>> account.
>> Gstat error:
>> Error in if (direct[direct$id == id, "is.direct"] && any(model$psill 
>> <  :
>>   missing value where TRUE/FALSE needed
>>
>> 2: In fit.variogram(object, model, fit.sills = fit.sills,  ... :
>>   value out of range in 'bessel_k'
>> 3 ...
>>
>>
>> # a quick visual of the data in the field
>> rescale = function(x, to=c(1,10)) (x - min(x)) * ((max(to) - 
>> min(to))/(max(x) - min(x)))
>> require("rgl")
>> sparse_df=as.data.frame(sparse)
>> spheres3d(sparse_df$x, sparse_df$y, sparse_df$depth_cm, 
>> radius=rescale(sparse_df$theta_percent))
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From mark_connolly at acm.org  Tue May  4 13:31:10 2010
From: mark_connolly at acm.org (Mark Connolly)
Date: Tue, 04 May 2010 07:31:10 -0400
Subject: [R-sig-Geo] negative range from fit.variogram
	through	autofitVariogram
In-Reply-To: <4BDFE348.3080204@geo.uu.nl>
References: <4BDF3B65.6040006@acm.org> <4BDFE348.3080204@geo.uu.nl>
Message-ID: <4BE0057E.6080807@acm.org>

I took the expedient of detecting the negative range and recording the 
offending time and space slice.  Then I went back and checked each model 
type individually.

This is perfectly acceptable but I did want to alert you to the 
possibility that autofitVariogram and therefore autoKrige could have 
issues with some data.

Since you asked, my preference would be that autofitVariogram returned 
the best usable model and an error if none can be found.  You could keep 
the current behavior as the default with some selector parameter 
(best="sserror" (default), best="usable" (alternative).  Or maybe just 
some mention in the help that an unusable model might be returned.

During the process of iterating through the data, I record the model 
information including the sserror.  My expectation is that I can use 
this information to look for suspicious models after the processing is 
complete.  I might be fooling myself, but I am trying to not have to go 
through thousands of variograms assessing the fits by eye.

Thanks,
Mark



On 05/04/2010 05:05 AM, Paul Hiemstra wrote:
> Hi Mark,
>
> Thanks for the reproducible example. The problem is that when I look 
> at the sample variogram, the semivariance values start high and end 
> low. This is best illustrated by:
>
> plot(variogram(theta_percent~1, sparse))
>
> You see that there are outliers in the data that cause high 
> semi-variance at a short distance. I would say that is 'strange' ;). 
> You can try and identify which point causes this by:
>
> plot(variogram(theta_percent~1, sparse, cloud = TRUE), identify = TRUE)
> # Click on the plot to identify the point pairs
>
> There is not really one value I think that causes this. It might be 
> also attributable to the fact that your dataset is somewhat sparse in 
> the distance range from 20-40 m.
>
> As a quick fix you can restrict the model selection to "Sph", this 
> works. And I would not be enthusiastic about using Ste. This is 
> because the main difference between different kappa values if the 
> behavior at short distances, but you don't have a lot of data on the 
> short distance to fit this value on in a meaningful way.
>
> At this stage I don't see a (relatively quick) fix that could solve 
> this problem in an automatic way and on a more fundamental level. Do 
> you have any suggestions? From an implementation point of view I can 
> let automap discard any model that has negative values in it, this 
> would ensure that the user gets at least the Sph model back.
>
> cheers,
> Paul
>
> Mark Connolly wrote:
>> I am using autofitVariogram during the process of interpolating a 
>> large set of daily observations through a volume.  Each volume is 
>> decomposed into 2D layers prior to selecting a model to use for 
>> interpolation.  I made it through 2010 interpolations and then ran 
>> into a failed interpolation when the best model selected by 
>> autofitVariogram had a negative range.  This was rejected by the 
>> krige function.  I see mention of negative sills but not of negative 
>> ranges.
>>
>> It appears that autofitVariogram is having some issues with the trial 
>> arguments sent to fit.variogram.  This is repeatable.  Not sure if 
>> this is a bug for some package or a data issue.  The data values do 
>> not look overly strange.
>>
>>
>>
>> # data
>> sparse =
>> structure(list(x = c(740381.862, 740456.052, 740503.958, 740551.752,
>> 740559.502, 740502.995, 740446, 740389.229, 740371.693, 740428.25,
>> 740484.918, 740541.356, 740549.277, 740474.724, 740418.118, 740370.187,
>> 740354.321, 740410.53, 740467.451, 740523.772, 740522.433, 740474.797,
>> 740400.293, 740343.175, 740336.067, 740392.917, 740449.622, 740506.162,
>> 740495.664, 740448.693, 740382.062, 740325.464, 740318.174, 740430.337,
>> 740488.37, 740477.578, 740429.695, 740373.133, 740325.408, 740631.842,
>> 740688.362, 740744.857, 740726.149, 740695.778, 740621.663, 740613.553,
>> 740670.205, 740726.566, 740733.965, 740660.272, 740620.315, 740594.82,
>> 740651.714, 740708.217, 740690.056, 740659.603, 740575.902, 740576.796,
>> 740558.179), y = c(181644.086, 181620.772, 181605.577, 181590.417,
>> 181568.637, 181586.847, 181604.615, 181622.136, 181565.531, 181547.708,
>> 181530.169, 181512.439, 181490.328, 181513.956, 181531.875, 181547.048,
>> 181508.946, 181491.148, 181473.394, 181455.233, 181436.726, 181452.342,
>> 181475.522, 181492.661, 181451.96, 181434.265, 181416.566, 181398.729,
>> 181382.764, 181397.808, 181418.748, 181436.677, 181395.477, 181360.409,
>> 181342.547, 181327.09, 181341.971, 181359.55, 181374.453, 181546.959,
>> 181528.576, 181510.58, 181497.501, 181507.159, 181530.759, 181490.008,
>> 181472.209, 181453.968, 181432.87, 181456.085, 181468.588, 181433.854,
>> 181415.758, 181397.497, 181384.359, 181393.795, 181420.579, 181376.982,
>> 181363.899), depth_cm = c(-8, -8, -8, -8, -8, -8, -8, -8, -8,
>> -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8,
>> -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8,
>> -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8,
>> -8, -8), theta_percent = c(23.63, 19.68, 23.81, 22.01, 23.98,
>> 12.8, 14.92, 20.49, 22.59, 24.32, 20.24, 23.03, 12.97, 19.09,
>> 39.2, 12.09, 24.52, 25.57, 25.5, 19.76, 19.17, 21.98, 7.5, 22.75,
>> 17.85, 17.75, 17.95, 26.93, 18.84, 22.95, 23.71, 25.03, 40.69,
>> 9.7, 24.66, 17.43, 16.3, 24.13, 19.98, 23.35, 12.16, 17.24, 14.29,
>> 34.42, 21.84, 25.63, 20.51, 25.87, 24.44, 22.35, 8.57, 21.43,
>> 25.63, 21.56, 21.49, 17.66, 25.61, 24.11, 28.31)), .Names = c("x",
>> "y", "depth_cm", "theta_percent"), row.names = c("1", "5", "10",
>> "15", "20", "25", "30", "35", "40", "45", "50", "55", "60", "65",
>> "70", "75", "80", "85", "90", "95", "100", "105", "109", "114",
>> "119", "124", "129", "134", "139", "144", "149", "154", "159",
>> "164", "169", "174", "179", "184", "188", "193", "198", "203",
>> "208", "213", "218", "223", "228", "233", "238", "243", "248",
>> "253", "258", "263", "268", "273", "278", "283", "288"), class = 
>> "data.frame")
>>
>>
>> # the broken fit for best search
>> require("automap")
>> coordinates(sparse) = c("x", "y", "depth_cm")
>> proj4string(sparse) = CRS("+init=epsg:32119")
>> v.fit <- autofitVariogram(theta_percent~1, sparse)
>>
>>
>> There were 50 or more warnings (use warnings() to see the first 50)
>> > warnings()
>> Warning messages:
>> 1: In getModel(initial_sill - initial_nugget, m, initial_range,  ... :
>>   An error has occured during variogram fitting. Used:
>>         nugget: 34.1432533936652
>>         model:  Exp
>>         psill:  13.2004974623731
>>         range:  53.1549477005646
>>         kappa:  NA
>>   as initial guess. This particular variogram fit is not taken into 
>> account.
>> Gstat error:
>> Error in if (direct[direct$id == id, "is.direct"] && any(model$psill 
>> <  :
>>   missing value where TRUE/FALSE needed
>>
>> 2: In fit.variogram(object, model, fit.sills = fit.sills,  ... :
>>   value out of range in 'bessel_k'
>> 3 ...
>>
>>
>> # a quick visual of the data in the field
>> rescale = function(x, to=c(1,10)) (x - min(x)) * ((max(to) - 
>> min(to))/(max(x) - min(x)))
>> require("rgl")
>> sparse_df=as.data.frame(sparse)
>> spheres3d(sparse_df$x, sparse_df$y, sparse_df$depth_cm, 
>> radius=rescale(sparse_df$theta_percent))
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From cheluna at gmail.com  Tue May  4 13:41:44 2010
From: cheluna at gmail.com (Consuelo Hermosilla)
Date: Tue, 4 May 2010 13:41:44 +0200
Subject: [R-sig-Geo] enfa [adehabitat]
Message-ID: <t2t62a688d1005040441o129ace2bv4895a2355d9cc095@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100504/30755a3d/attachment.pl>

From clement.calenge at gmail.com  Tue May  4 14:20:42 2010
From: clement.calenge at gmail.com (=?ISO-8859-1?Q?Cl=E9ment_Calenge?=)
Date: Tue, 04 May 2010 14:20:42 +0200
Subject: [R-sig-Geo] enfa [adehabitat]
In-Reply-To: <t2t62a688d1005040441o129ace2bv4895a2355d9cc095@mail.gmail.com>
References: <t2t62a688d1005040441o129ace2bv4895a2355d9cc095@mail.gmail.com>
Message-ID: <4BE0111A.4010501@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100504/f50e755c/attachment.pl>

From cheluna at gmail.com  Tue May  4 16:05:36 2010
From: cheluna at gmail.com (Consuelo Hermosilla)
Date: Tue, 4 May 2010 16:05:36 +0200
Subject: [R-sig-Geo] enfa [adehabitat]
In-Reply-To: <4BE0111A.4010501@gmail.com>
References: <t2t62a688d1005040441o129ace2bv4895a2355d9cc095@mail.gmail.com> 
	<4BE0111A.4010501@gmail.com>
Message-ID: <x2o62a688d1005040705vd96bd519z62bdd8688f903755@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100504/bf9ff8d6/attachment.pl>

From mark_connolly at acm.org  Tue May  4 16:15:10 2010
From: mark_connolly at acm.org (Mark Connolly)
Date: Tue, 04 May 2010 10:15:10 -0400
Subject: [R-sig-Geo] negative range from
	fit.variogram	through	autofitVariogram
In-Reply-To: <4BDFED9C.3010703@geo.uu.nl>
References: <4BDF3B65.6040006@acm.org> <4BDFE348.3080204@geo.uu.nl>
	<4BDFED9C.3010703@geo.uu.nl>
Message-ID: <4BE02BEE.3080601@acm.org>

Thanks.  I'll pick it up as it becomes available.

Does the possibility exist that you would delete all models?  In such a 
case, what does the function return?

On 05/04/2010 05:49 AM, Paul Hiemstra wrote:
> I just uploaded a new version of automap (1.07) that fixes this 
> problem. It deletes fitted variogram models with a negative 
> sill/range/nugget.
>
> cheers,
> Paul
>
> Paul Hiemstra wrote:
>> Hi Mark,
>>
>> Thanks for the reproducible example. The problem is that when I look 
>> at the sample variogram, the semivariance values start high and end 
>> low. This is best illustrated by:
>>
>> plot(variogram(theta_percent~1, sparse))
>>
>> You see that there are outliers in the data that cause high 
>> semi-variance at a short distance. I would say that is 'strange' ;). 
>> You can try and identify which point causes this by:
>>
>> plot(variogram(theta_percent~1, sparse, cloud = TRUE), identify = TRUE)
>> # Click on the plot to identify the point pairs
>>
>> There is not really one value I think that causes this. It might be 
>> also attributable to the fact that your dataset is somewhat sparse in 
>> the distance range from 20-40 m.
>>
>> As a quick fix you can restrict the model selection to "Sph", this 
>> works. And I would not be enthusiastic about using Ste. This is 
>> because the main difference between different kappa values if the 
>> behavior at short distances, but you don't have a lot of data on the 
>> short distance to fit this value on in a meaningful way.
>>
>> At this stage I don't see a (relatively quick) fix that could solve 
>> this problem in an automatic way and on a more fundamental level. Do 
>> you have any suggestions? From an implementation point of view I can 
>> let automap discard any model that has negative values in it, this 
>> would ensure that the user gets at least the Sph model back.
>>
>> cheers,
>> Paul
>>
>> Mark Connolly wrote:
>>> I am using autofitVariogram during the process of interpolating a 
>>> large set of daily observations through a volume.  Each volume is 
>>> decomposed into 2D layers prior to selecting a model to use for 
>>> interpolation.  I made it through 2010 interpolations and then ran 
>>> into a failed interpolation when the best model selected by 
>>> autofitVariogram had a negative range.  This was rejected by the 
>>> krige function.  I see mention of negative sills but not of negative 
>>> ranges.
>>>
>>> It appears that autofitVariogram is having some issues with the 
>>> trial arguments sent to fit.variogram.  This is repeatable.  Not 
>>> sure if this is a bug for some package or a data issue.  The data 
>>> values do not look overly strange.
>>>
>>>
>>>
>>> # data
>>> sparse =
>>> structure(list(x = c(740381.862, 740456.052, 740503.958, 740551.752,
>>> 740559.502, 740502.995, 740446, 740389.229, 740371.693, 740428.25,
>>> 740484.918, 740541.356, 740549.277, 740474.724, 740418.118, 740370.187,
>>> 740354.321, 740410.53, 740467.451, 740523.772, 740522.433, 740474.797,
>>> 740400.293, 740343.175, 740336.067, 740392.917, 740449.622, 740506.162,
>>> 740495.664, 740448.693, 740382.062, 740325.464, 740318.174, 740430.337,
>>> 740488.37, 740477.578, 740429.695, 740373.133, 740325.408, 740631.842,
>>> 740688.362, 740744.857, 740726.149, 740695.778, 740621.663, 740613.553,
>>> 740670.205, 740726.566, 740733.965, 740660.272, 740620.315, 740594.82,
>>> 740651.714, 740708.217, 740690.056, 740659.603, 740575.902, 740576.796,
>>> 740558.179), y = c(181644.086, 181620.772, 181605.577, 181590.417,
>>> 181568.637, 181586.847, 181604.615, 181622.136, 181565.531, 181547.708,
>>> 181530.169, 181512.439, 181490.328, 181513.956, 181531.875, 181547.048,
>>> 181508.946, 181491.148, 181473.394, 181455.233, 181436.726, 181452.342,
>>> 181475.522, 181492.661, 181451.96, 181434.265, 181416.566, 181398.729,
>>> 181382.764, 181397.808, 181418.748, 181436.677, 181395.477, 181360.409,
>>> 181342.547, 181327.09, 181341.971, 181359.55, 181374.453, 181546.959,
>>> 181528.576, 181510.58, 181497.501, 181507.159, 181530.759, 181490.008,
>>> 181472.209, 181453.968, 181432.87, 181456.085, 181468.588, 181433.854,
>>> 181415.758, 181397.497, 181384.359, 181393.795, 181420.579, 181376.982,
>>> 181363.899), depth_cm = c(-8, -8, -8, -8, -8, -8, -8, -8, -8,
>>> -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8,
>>> -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8,
>>> -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8,
>>> -8, -8), theta_percent = c(23.63, 19.68, 23.81, 22.01, 23.98,
>>> 12.8, 14.92, 20.49, 22.59, 24.32, 20.24, 23.03, 12.97, 19.09,
>>> 39.2, 12.09, 24.52, 25.57, 25.5, 19.76, 19.17, 21.98, 7.5, 22.75,
>>> 17.85, 17.75, 17.95, 26.93, 18.84, 22.95, 23.71, 25.03, 40.69,
>>> 9.7, 24.66, 17.43, 16.3, 24.13, 19.98, 23.35, 12.16, 17.24, 14.29,
>>> 34.42, 21.84, 25.63, 20.51, 25.87, 24.44, 22.35, 8.57, 21.43,
>>> 25.63, 21.56, 21.49, 17.66, 25.61, 24.11, 28.31)), .Names = c("x",
>>> "y", "depth_cm", "theta_percent"), row.names = c("1", "5", "10",
>>> "15", "20", "25", "30", "35", "40", "45", "50", "55", "60", "65",
>>> "70", "75", "80", "85", "90", "95", "100", "105", "109", "114",
>>> "119", "124", "129", "134", "139", "144", "149", "154", "159",
>>> "164", "169", "174", "179", "184", "188", "193", "198", "203",
>>> "208", "213", "218", "223", "228", "233", "238", "243", "248",
>>> "253", "258", "263", "268", "273", "278", "283", "288"), class = 
>>> "data.frame")
>>>
>>>
>>> # the broken fit for best search
>>> require("automap")
>>> coordinates(sparse) = c("x", "y", "depth_cm")
>>> proj4string(sparse) = CRS("+init=epsg:32119")
>>> v.fit <- autofitVariogram(theta_percent~1, sparse)
>>>
>>>
>>> There were 50 or more warnings (use warnings() to see the first 50)
>>> > warnings()
>>> Warning messages:
>>> 1: In getModel(initial_sill - initial_nugget, m, initial_range,  ... :
>>>   An error has occured during variogram fitting. Used:
>>>         nugget: 34.1432533936652
>>>         model:  Exp
>>>         psill:  13.2004974623731
>>>         range:  53.1549477005646
>>>         kappa:  NA
>>>   as initial guess. This particular variogram fit is not taken into 
>>> account.
>>> Gstat error:
>>> Error in if (direct[direct$id == id, "is.direct"] && any(model$psill 
>>> <  :
>>>   missing value where TRUE/FALSE needed
>>>
>>> 2: In fit.variogram(object, model, fit.sills = fit.sills,  ... :
>>>   value out of range in 'bessel_k'
>>> 3 ...
>>>
>>>
>>> # a quick visual of the data in the field
>>> rescale = function(x, to=c(1,10)) (x - min(x)) * ((max(to) - 
>>> min(to))/(max(x) - min(x)))
>>> require("rgl")
>>> sparse_df=as.data.frame(sparse)
>>> spheres3d(sparse_df$x, sparse_df$y, sparse_df$depth_cm, 
>>> radius=rescale(sparse_df$theta_percent))
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>
>


From Virgilio.Gomez at uclm.es  Tue May  4 16:55:54 2010
From: Virgilio.Gomez at uclm.es (Virgilio Gomez Rubio)
Date: Tue, 04 May 2010 16:55:54 +0200
Subject: [R-sig-Geo] sp2WB in Maptools - order of polygons
In-Reply-To: <1272965454819-5002508.post@n2.nabble.com>
References: <1272965454819-5002508.post@n2.nabble.com>
Message-ID: <1272984954.2657.22.camel@Virgilio-Gomez>

Dear Kath,

> The command itself is working fine and produces the map I would expect.
> However to analyse the data for each polygon, I need to know which polygon
> is which. How do I determine the ID for each polygon generated? I'm hoping
> there is a better solution than figuring it out by hand...

You will need to find a match between your polygons and your data.
Usually, this is done by means of an area ID (postcode, district code,
etc.). Then you can reorder either your polygons or your data to have
both in the same order, and then produce the files (maps and data) for
WinBUGS.

Best wishes,

-- 
Virgilio G?mez Rubio
Departamento de Matem?ticas
Escuela de Ingenieros Industriales de Albacete
Universidad de Castilla-La Mancha
Avda. Espa?a s/n
02071 Albacete - SPAIN
Tel: 967 59 92 00 ext. 2399


From rusers.sh at gmail.com  Tue May  4 18:05:41 2010
From: rusers.sh at gmail.com (rusers.sh)
Date: Tue, 4 May 2010 12:05:41 -0400
Subject: [R-sig-Geo] how to get the values for corresponding neighbors
Message-ID: <y2oa835c81e1005040905vd6ad449ic6b446bea1516940@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100504/23a4df07/attachment.pl>

From edzer.pebesma at uni-muenster.de  Tue May  4 19:33:09 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 04 May 2010 19:33:09 +0200
Subject: [R-sig-Geo] expand the dist covariate of the prediction-grid
 meuse.grid (sp package)
In-Reply-To: <3DAB392E-081E-4146-AF25-493DB6B7847A@env.ethz.ch>
References: <3DAB392E-081E-4146-AF25-493DB6B7847A@env.ethz.ch>
Message-ID: <4BE05A55.4020505@uni-muenster.de>

sp does not do points-to-line distances, but can do point-to-point
distances. In the second section I resampled the river boundary so we
get a closer approximation, because more points. Maybe rgeos can be
expanded do the real point-to-line things (R != GIS?).

library(sp)
data(meuse.riv)
meuse.sr =
SpatialPolygons(list(Polygons(list(Polygon(meuse.riv)),"meuse.riv")))
meuse.sp = as(as(meuse.sr, "SpatialLines"), "SpatialPoints")

# create a grid:
grd = SpatialPixels(SpatialPoints(makegrid(meuse.sr)))
plot(meuse.sr)
grd = spsample(as(meuse.sr, "Spatial"), type='regular', n=10000)
points(coordinates(grd))
d = spDists(grd, meuse.sp)
d0 = apply(d,1,function(x){x[x==min(x)][1]})
g0 = SpatialPixelsDataFrame(as(grd, "SpatialPixels"), data.frame(d0=d0))
spplot(g0, col.regions=bpy.colors())

# for finer discretized
meuse.sp = as(spsample(as(meuse.sr, "SpatialLines"),type="regular",
n=1000),    "SpatialPoints")
d = spDists(grd, meuse.sp)
g0$d1 = apply(d,1,function(x){x[x==min(x)][1]})
pplot(g0, col.regions=rev(bpy.colors()))

Hope this helps,
--
Edzer

On 05/04/2010 09:39 AM, Christoph Hofer wrote:
> Dear list
> 
> 
> I would like to expand the covariate "dist"  of the meuse.grid dataset, of the sp package,
> to the south-east direction. The value of the covariate dist is relative between [0,1].
> Now, it is not clear for me how I shall calculate the distance between
> a new gird point and the river (is it the perpendicular between the river border and the grid point)?
> 
> I appreciate for any tips or hints.
> 
> 
> 
> Christoph
> 
> 
> 
> 
> 
> ETH Zurich
> Christoph Hofer
> Soil and Terrestrial Environmental Physics
> Institute of Terrestrial Ecosystems
> CHN E 50.2
> Universit?tstrasse 16
> 8092 Zurich, Switzerland
> phone         (+41) - (0)44 - 633 63 65
> fax               (+41) - (0)44 - 633 11 23
> e-mail: christoph.hofer at env.ethz.ch
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From Roger.Bivand at nhh.no  Tue May  4 20:38:27 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 4 May 2010 20:38:27 +0200 (CEST)
Subject: [R-sig-Geo] how to get the values for corresponding neighbors
In-Reply-To: <y2oa835c81e1005040905vd6ad449ic6b446bea1516940@mail.gmail.com>
References: <y2oa835c81e1005040905vd6ad449ic6b446bea1516940@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1005042037470.14545@reclus.nhh.no>

On Tue, 4 May 2010, rusers.sh wrote:

> Hi there,
>  Take the data of columbus(spdep) as an example. Say ?i? is one of the
> polygons, and ?j? represents its neighbours. How to get the vlues of
> ?sum(Wij*Xj)??  ?Wij? means the weights, which can be get by
> ?nb2listw$weights?.
> Say ?Xj? to be ?columbus$PLUMB?. The problem is how to get the right values
> of ?columbus$PLUMB? for the corresponding neighbours, so i can calculate the
> "sum(Wij*Xj)"? See the following example.
> example(columbus);coords <- coordinates(columbus)
> nbs <- dnearneigh(coords,0,4)
> nbslistw<-nb2listw(nbs, style="B")
> #nbslistw$neighbours; nbslistw$weights
> I can not figure it out. Anybody can give me some suggestions?

lag(nbslistw, x)

?lag.listw

HTH

Roger

> Thanks.
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From christoph.hofer at env.ethz.ch  Wed May  5 08:00:04 2010
From: christoph.hofer at env.ethz.ch (Christoph Hofer)
Date: Wed, 5 May 2010 08:00:04 +0200
Subject: [R-sig-Geo] expand the dist covariate of the prediction-grid
	meuse.grid (sp package)
In-Reply-To: <4BE05A55.4020505@uni-muenster.de>
References: <3DAB392E-081E-4146-AF25-493DB6B7847A@env.ethz.ch>
	<4BE05A55.4020505@uni-muenster.de>
Message-ID: <6BA7D727-9316-48E5-895C-2D8CAF363BF6@env.ethz.ch>

Edzer,

Many thanks for the fast and qualified reply.


Christoph

Am 04.05.2010 um 19:33 schrieb Edzer Pebesma:

> sp does not do points-to-line distances, but can do point-to-point
> distances. In the second section I resampled the river boundary so we
> get a closer approximation, because more points. Maybe rgeos can be
> expanded do the real point-to-line things (R != GIS?).
> 
> library(sp)
> data(meuse.riv)
> meuse.sr =
> SpatialPolygons(list(Polygons(list(Polygon(meuse.riv)),"meuse.riv")))
> meuse.sp = as(as(meuse.sr, "SpatialLines"), "SpatialPoints")
> 
> # create a grid:
> grd = SpatialPixels(SpatialPoints(makegrid(meuse.sr)))
> plot(meuse.sr)
> grd = spsample(as(meuse.sr, "Spatial"), type='regular', n=10000)
> points(coordinates(grd))
> d = spDists(grd, meuse.sp)
> d0 = apply(d,1,function(x){x[x==min(x)][1]})
> g0 = SpatialPixelsDataFrame(as(grd, "SpatialPixels"), data.frame(d0=d0))
> spplot(g0, col.regions=bpy.colors())
> 
> # for finer discretized
> meuse.sp = as(spsample(as(meuse.sr, "SpatialLines"),type="regular",
> n=1000),    "SpatialPoints")
> d = spDists(grd, meuse.sp)
> g0$d1 = apply(d,1,function(x){x[x==min(x)][1]})
> pplot(g0, col.regions=rev(bpy.colors()))
> 
> Hope this helps,
> --
> Edzer
> 
> On 05/04/2010 09:39 AM, Christoph Hofer wrote:
>> Dear list
>> 
>> 
>> I would like to expand the covariate "dist"  of the meuse.grid dataset, of the sp package,
>> to the south-east direction. The value of the covariate dist is relative between [0,1].
>> Now, it is not clear for me how I shall calculate the distance between
>> a new gird point and the river (is it the perpendicular between the river border and the grid point)?
>> 
>> I appreciate for any tips or hints.
>> 
>> 
>> 
>> Christoph
>> 
>> 
>> 
>> 
>> 
>> ETH Zurich
>> Christoph Hofer
>> Soil and Terrestrial Environmental Physics
>> Institute of Terrestrial Ecosystems
>> CHN E 50.2
>> Universit?tstrasse 16
>> 8092 Zurich, Switzerland
>> phone         (+41) - (0)44 - 633 63 65
>> fax               (+41) - (0)44 - 633 11 23
>> e-mail: christoph.hofer at env.ethz.ch
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> -- 
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> 8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
> http://www.52north.org/geostatistics      e.pebesma at wwu.de


From Bjarke.Christensen at sydbank.dk  Wed May  5 09:11:40 2010
From: Bjarke.Christensen at sydbank.dk (Bjarke Christensen)
Date: Wed, 5 May 2010 09:11:40 +0200
Subject: [R-sig-Geo] Mapping a factor
In-Reply-To: <mailman.13.1272967203.30902.r-sig-geo@stat.math.ethz.ch>
Message-ID: <OF51D66375.433C7C8B-ONC125771A.00272735-C125771A.00278567@bdpnet.dk>

Roberto,

I think the following expression is incorrect:
col = colours[findInterval(gino, levels(gino), all.inside = FALSE)]

It should probably just be colours[gino]. You can test that by typing:
data.frame(gino, colours[findInterval(gino, levels(gino), all.inside =
FALSE)], colours[gino])


----
Dear All,

I'm having trouble mapping the levels of a factor.
This is the code I have as of now. The legend works fine (suggesting that
item "colours" is correct), but not the map!

gino = factor(data_abs1$Ethnic.Dominance, labels = c(" French", " German",
"
Italian", " Portuguese", " Spanish", " Fmr. Yugoslavian", " Turkish"))
colours = rev(bpy.colors(n = length(levels(gino)), cutoff.tails = 0.2))
submap <- swiss.map[data_abs$FORACTIVE >=5 & data_abs$NAME != "D?moret",] #

this is only to build a smaller map which excludes some regions
plot(swiss.map, axes = FALSE)
plot(submap, add = TRUE, col = colours[findInterval(gino, levels(gino),
all.inside = FALSE)])
legend("topleft", xjust = 0, ncol = 1, legend = levels(gino), fill =
colours, bty ="n", title = "CIAO")


Can anyone clear the problem?

Thanks a lot
Roberto

********************
Roberto Patuelli, Ph.D.
Istituto Ricerche Economiche (IRE) (Institute for Economic Research)
Universit? della Svizzera Italiana (University of Lugano)
via Maderno 24, CP 4361
CH-6904 Lugano
Switzerland
Phone: +41-(0)58-666-4166
Fax: +39-02-700419665
Email: roberto.patuelli at usi.ch
Homepage: http://www.people.lu.unisi.ch/patuellr


From sjmyers at syr.edu  Thu May  6 03:52:20 2010
From: sjmyers at syr.edu (Seth J Myers)
Date: Thu, 6 May 2010 01:52:20 +0000
Subject: [R-sig-Geo] writeRaster problems
Message-ID: <266CBFBFD14254478D52158AE6BF90170C6490F7@BL2PRD0103MB038.prod.exchangelabs.com>

Hi,

I'm running R 2.11.0 on a 32 bit Windows Vista machine.  I have new versions of all relevant libraries installed.  I have been reading from IDRISI .rst files and this works fine using raster() and getValues().  I have passed the values from the .rst files through another R object and would like to write them as an .rst file.  In the following code, I am attempting to set the 1st row values of a RasterLayer object and then write these to a .rst file.  All raster files I am working with have 3,700 columns and 4,203 rows and are Connecticut StatePlane coordinate system which is equivalent to lambert's conformal conic proj.

#extract 2nd column of a matrix which are the values of interest for the 1st row
p1a<-p1[c(1:3700),c(2)]   
p1am<-as.matrix(p1a)
#create RasterLayer object from a .rst file that was created in IDRISI beforehand with all 0s (real nums) for cell values
put<-raster("C:\\rforest\\data\\rst85\\write2.rst",values=FALSE)
#set 1st row to equal the values of interest
put<-setValues(put,p1am,1)
#write to a .rst file that I created in IDRISI beforehand with all 0s (real nums)
writeRaster(put, filename="C:\\rforest\\data\\rst85\\write5.rst", format="IDRISI",overwrite=TRUE)


PROBLEM:

Until the writeRaster function call, everything is working.  I can use getValues to look at the 1st row of "put", and this equals p1am values.  I can look at the 2nd row of "put" and they are all zeros.  The writeRaster function does not give an error but, when opened in IDRISI, the legend seems correct but the values are expressed in scientific notation and are MUCH too small.  Also, the 1st row values are copied for all rows, when I expect all but row=1 to be equal to 0.  I tried, prior to opening in IDRISI, to create a RasterLayer object from the output raster from writeRaster above, to see if R gives the result wanted.  This results in the following error message and report on the RasterLayer object created.

> put2<-raster("C:\\rforest\\data\\rst85\\write5.rst",values=TRUE)
> put3<-getValues(put2,1)
Error: 
        GDAL Error 3: Can't read(C:\rforest\data\rst85\write5.rst) block with X offset 0 and Y offset 0.
No error
Error in values(readRows(x, row, nrows)) : 
  error in evaluating the argument 'x' in selecting a method for function 'values'
> put2
class       : RasterLayer 
filename    : C:\rforest\data\rst85\write5.rst 
nrow        : 4203 
ncol        : 3700 
ncell       : 15551100 
min value   : 0 
max value   : 0 
projection  : +proj=lcc +lat_1=41.86666666666667 +lat_2=41.2 +lat_0=40.83333333333334 +lon_0=-72.75 +x_0=304800.6096 +y_0=152400.3048 +ellps=GRS80 +datum=NAD83 +units=m +no_defs +towgs84=0,0,0 
xmin        : 221895.5 
xmax        : 334671.7 
ymin        : 164342.4 
ymax        : 292450.1 
xres        : 30.48006 
yres        : 30.48006 


I have tried this entire process starting NOT with blank 0 rasters to create my SpatialLayer object (a shortcut I thought may be a problem) but instead creating rasters by specifying projections etc on non-used filenames.  The results are the same.

Thanks,
Seth

From r.hijmans at gmail.com  Thu May  6 07:05:30 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 5 May 2010 22:05:30 -0700
Subject: [R-sig-Geo] Fwd:  writeRaster problems
In-Reply-To: <u2xdc22b2571005052203y9cb1af5ej952e9e9d4474c0bc@mail.gmail.com>
References: <266CBFBFD14254478D52158AE6BF90170C6490F7@BL2PRD0103MB038.prod.exchangelabs.com>
	<u2xdc22b2571005052203y9cb1af5ej952e9e9d4474c0bc@mail.gmail.com>
Message-ID: <l2udc22b2571005052205q256fe453m7b5e977da8c99bbe@mail.gmail.com>

Dear Seth,

I think the problem is that you try to overwrite values in an existing
file. That is not directly possible (with raster anyway). You have to
start a new fil. Below are some examples. Also see
vignette('functions', 'raster')

#1 if you can read the whole raster into memory
p1a <- rep(0, ncol(rout))
rin <- raster(system.file("external/test.grd", package="raster"), values=TRUE)
rin[1:ncol(rin)] = p1a
rout <- writeRaster(rin, filename="write1.rst", format="IDRISI",overwrite=TRUE)

#2 row by row (and slow)
rin <- raster(system.file("external/test.grd", package="raster"))
rout <- raster(rin)
p1a <- rep(0, ncol(rout))
rout <- setValues(rout, p1a, 1)
rout <- writeRaster(rout, filename="write2.rst", format="IDRISI",overwrite=TRUE)
for (r in 2:nrow(rout)) {
? ? ? ?rin <- readRow(rin, r)
? ? ? ?rout <-setValues(rout, values(rin), r)
? ? ? ?rout <- writeRaster(rout, filename="write5.rst",
format="IDRISI",overwrite=TRUE)
}


# 3 block by block (much faster); using the rgdal driver
(format='RST') so that you
# first copy all values and then overwrite rows at any location
rin <- raster(system.file("external/test.grd", package="raster"))
rout <- raster(rin)
bs <- blockSize(rout)
rout <- writeStart(rout, filename="write3.rst", format="RST", overwrite=TRUE)
for (i in 1:bs$n) {
? ? ? ?v = getValuesBlock(rin, row=bs$row[i], nrows=bs$size)
? ? ? ?writeValues(rout, v, bs$row[i])
}
p1a <- rep(0, ncol(rout))
writeValues(rout, p1a, 1) # replace a row
rout <- writeStop(rout)


Robert



On Wed, May 5, 2010 at 6:52 PM, Seth J Myers <sjmyers at syr.edu> wrote:
> Hi,
>
> I'm running R 2.11.0 on a 32 bit Windows Vista machine. ?I have new versions of all relevant libraries installed. ?I have been reading from IDRISI .rst files and this works fine using raster() and getValues(). ?I have passed the values from the .rst files through another R object and would like to write them as an .rst file. ?In the following code, I am attempting to set the 1st row values of a RasterLayer object and then write these to a .rst file. ?All raster files I am working with have 3,700 columns and 4,203 rows and are Connecticut StatePlane coordinate system which is equivalent to lambert's conformal conic proj.
>
> #extract 2nd column of a matrix which are the values of interest for the 1st row
> p1a<-p1[c(1:3700),c(2)]
> p1am<-as.matrix(p1a)
> #create RasterLayer object from a .rst file that was created in IDRISI beforehand with all 0s (real nums) for cell values
> put<-raster("C:\\rforest\\data\\rst85\\write2.rst",values=FALSE)
> #set 1st row to equal the values of interest
> put<-setValues(put,p1am,1)
> #write to a .rst file that I created in IDRISI beforehand with all 0s (real nums)
> writeRaster(put, filename="C:\\rforest\\data\\rst85\\write5.rst", format="IDRISI",overwrite=TRUE)
>
>
> PROBLEM:
>
> Until the writeRaster function call, everything is working. ?I can use getValues to look at the 1st row of "put", and this equals p1am values. ?I can look at the 2nd row of "put" and they are all zeros. ?The writeRaster function does not give an error but, when opened in IDRISI, the legend seems correct but the values are expressed in scientific notation and are MUCH too small. ?Also, the 1st row values are copied for all rows, when I expect all but row=1 to be equal to 0. ?I tried, prior to opening in IDRISI, to create a RasterLayer object from the output raster from writeRaster above, to see if R gives the result wanted. ?This results in the following error message and report on the RasterLayer object created.
>
>> put2<-raster("C:\\rforest\\data\\rst85\\write5.rst",values=TRUE)
>> put3<-getValues(put2,1)
> Error:
> ? ? ? ?GDAL Error 3: Can't read(C:\rforest\data\rst85\write5.rst) block with X offset 0 and Y offset 0.
> No error
> Error in values(readRows(x, row, nrows)) :
> ?error in evaluating the argument 'x' in selecting a method for function 'values'
>> put2
> class ? ? ? : RasterLayer
> filename ? ?: C:\rforest\data\rst85\write5.rst
> nrow ? ? ? ?: 4203
> ncol ? ? ? ?: 3700
> ncell ? ? ? : 15551100
> min value ? : 0
> max value ? : 0
> projection ?: +proj=lcc +lat_1=41.86666666666667 +lat_2=41.2 +lat_0=40.83333333333334 +lon_0=-72.75 +x_0=304800.6096 +y_0=152400.3048 +ellps=GRS80 +datum=NAD83 +units=m +no_defs +towgs84=0,0,0
> xmin ? ? ? ?: 221895.5
> xmax ? ? ? ?: 334671.7
> ymin ? ? ? ?: 164342.4
> ymax ? ? ? ?: 292450.1
> xres ? ? ? ?: 30.48006
> yres ? ? ? ?: 30.48006
>
>
> I have tried this entire process starting NOT with blank 0 rasters to create my SpatialLayer object (a shortcut I thought may be a problem) but instead creating rasters by specifying projections etc on non-used filenames. ?The results are the same.
>
> Thanks,
> Seth
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From r.hijmans at gmail.com  Thu May  6 07:26:35 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 5 May 2010 22:26:35 -0700
Subject: [R-sig-Geo] writeRaster problems
In-Reply-To: <l2udc22b2571005052205q256fe453m7b5e977da8c99bbe@mail.gmail.com>
References: <266CBFBFD14254478D52158AE6BF90170C6490F7@BL2PRD0103MB038.prod.exchangelabs.com>
	<u2xdc22b2571005052203y9cb1af5ej952e9e9d4474c0bc@mail.gmail.com>
	<l2udc22b2571005052205q256fe453m7b5e977da8c99bbe@mail.gmail.com>
Message-ID: <t2ndc22b2571005052226yc0bb2827ma540f1485db545e2@mail.gmail.com>

Seth,
I think I overlooked what is perhaps the easiest way to do this, using
a standard replacement approach:

library(raster)
r <- raster(system.file("external/test.grd", package="raster"))
p1a <- rep(100, ncol(r))
r[1:ncol(r)] <- p1a
r <- writeRaster(r, filename='test.rst', overwrite=TRUE)
plot(r)


Robert


On Wed, May 5, 2010 at 10:05 PM, Robert J. Hijmans <r.hijmans at gmail.com> wrote:
> Dear Seth,
>
> I think the problem is that you try to overwrite values in an existing
> file. That is not directly possible (with raster anyway). You have to
> start a new fil. Below are some examples. Also see
> vignette('functions', 'raster')
>
> #1 if you can read the whole raster into memory
> p1a <- rep(0, ncol(rout))
> rin <- raster(system.file("external/test.grd", package="raster"), values=TRUE)
> rin[1:ncol(rin)] = p1a
> rout <- writeRaster(rin, filename="write1.rst", format="IDRISI",overwrite=TRUE)
>
> #2 row by row (and slow)
> rin <- raster(system.file("external/test.grd", package="raster"))
> rout <- raster(rin)
> p1a <- rep(0, ncol(rout))
> rout <- setValues(rout, p1a, 1)
> rout <- writeRaster(rout, filename="write2.rst", format="IDRISI",overwrite=TRUE)
> for (r in 2:nrow(rout)) {
> ? ? ? ?rin <- readRow(rin, r)
> ? ? ? ?rout <-setValues(rout, values(rin), r)
> ? ? ? ?rout <- writeRaster(rout, filename="write5.rst",
> format="IDRISI",overwrite=TRUE)
> }
>
>
> # 3 block by block (much faster); using the rgdal driver
> (format='RST') so that you
> # first copy all values and then overwrite rows at any location
> rin <- raster(system.file("external/test.grd", package="raster"))
> rout <- raster(rin)
> bs <- blockSize(rout)
> rout <- writeStart(rout, filename="write3.rst", format="RST", overwrite=TRUE)
> for (i in 1:bs$n) {
> ? ? ? ?v = getValuesBlock(rin, row=bs$row[i], nrows=bs$size)
> ? ? ? ?writeValues(rout, v, bs$row[i])
> }
> p1a <- rep(0, ncol(rout))
> writeValues(rout, p1a, 1) # replace a row
> rout <- writeStop(rout)
>
>
> Robert
>
>
>
> On Wed, May 5, 2010 at 6:52 PM, Seth J Myers <sjmyers at syr.edu> wrote:
>> Hi,
>>
>> I'm running R 2.11.0 on a 32 bit Windows Vista machine. ?I have new versions of all relevant libraries installed. ?I have been reading from IDRISI .rst files and this works fine using raster() and getValues(). ?I have passed the values from the .rst files through another R object and would like to write them as an .rst file. ?In the following code, I am attempting to set the 1st row values of a RasterLayer object and then write these to a .rst file. ?All raster files I am working with have 3,700 columns and 4,203 rows and are Connecticut StatePlane coordinate system which is equivalent to lambert's conformal conic proj.
>>
>> #extract 2nd column of a matrix which are the values of interest for the 1st row
>> p1a<-p1[c(1:3700),c(2)]
>> p1am<-as.matrix(p1a)
>> #create RasterLayer object from a .rst file that was created in IDRISI beforehand with all 0s (real nums) for cell values
>> put<-raster("C:\\rforest\\data\\rst85\\write2.rst",values=FALSE)
>> #set 1st row to equal the values of interest
>> put<-setValues(put,p1am,1)
>> #write to a .rst file that I created in IDRISI beforehand with all 0s (real nums)
>> writeRaster(put, filename="C:\\rforest\\data\\rst85\\write5.rst", format="IDRISI",overwrite=TRUE)
>>
>>
>> PROBLEM:
>>
>> Until the writeRaster function call, everything is working. ?I can use getValues to look at the 1st row of "put", and this equals p1am values. ?I can look at the 2nd row of "put" and they are all zeros. ?The writeRaster function does not give an error but, when opened in IDRISI, the legend seems correct but the values are expressed in scientific notation and are MUCH too small. ?Also, the 1st row values are copied for all rows, when I expect all but row=1 to be equal to 0. ?I tried, prior to opening in IDRISI, to create a RasterLayer object from the output raster from writeRaster above, to see if R gives the result wanted. ?This results in the following error message and report on the RasterLayer object created.
>>
>>> put2<-raster("C:\\rforest\\data\\rst85\\write5.rst",values=TRUE)
>>> put3<-getValues(put2,1)
>> Error:
>> ? ? ? ?GDAL Error 3: Can't read(C:\rforest\data\rst85\write5.rst) block with X offset 0 and Y offset 0.
>> No error
>> Error in values(readRows(x, row, nrows)) :
>> ?error in evaluating the argument 'x' in selecting a method for function 'values'
>>> put2
>> class ? ? ? : RasterLayer
>> filename ? ?: C:\rforest\data\rst85\write5.rst
>> nrow ? ? ? ?: 4203
>> ncol ? ? ? ?: 3700
>> ncell ? ? ? : 15551100
>> min value ? : 0
>> max value ? : 0
>> projection ?: +proj=lcc +lat_1=41.86666666666667 +lat_2=41.2 +lat_0=40.83333333333334 +lon_0=-72.75 +x_0=304800.6096 +y_0=152400.3048 +ellps=GRS80 +datum=NAD83 +units=m +no_defs +towgs84=0,0,0
>> xmin ? ? ? ?: 221895.5
>> xmax ? ? ? ?: 334671.7
>> ymin ? ? ? ?: 164342.4
>> ymax ? ? ? ?: 292450.1
>> xres ? ? ? ?: 30.48006
>> yres ? ? ? ?: 30.48006
>>
>>
>> I have tried this entire process starting NOT with blank 0 rasters to create my SpatialLayer object (a shortcut I thought may be a problem) but instead creating rasters by specifying projections etc on non-used filenames. ?The results are the same.
>>
>> Thanks,
>> Seth
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From edzer.pebesma at uni-muenster.de  Thu May  6 08:18:29 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 06 May 2010 08:18:29 +0200
Subject: [R-sig-Geo] writeRaster problems
In-Reply-To: <t2ndc22b2571005052226yc0bb2827ma540f1485db545e2@mail.gmail.com>
References: <266CBFBFD14254478D52158AE6BF90170C6490F7@BL2PRD0103MB038.prod.exchangelabs.com>	<u2xdc22b2571005052203y9cb1af5ej952e9e9d4474c0bc@mail.gmail.com>	<l2udc22b2571005052205q256fe453m7b5e977da8c99bbe@mail.gmail.com>
	<t2ndc22b2571005052226yc0bb2827ma540f1485db545e2@mail.gmail.com>
Message-ID: <4BE25F35.10908@uni-muenster.de>

On 05/06/2010 07:26 AM, Robert J. Hijmans wrote:
> Seth,
> I think I overlooked what is perhaps the easiest way to do this, using
> a standard replacement approach:
> 
> library(raster)
> r <- raster(system.file("external/test.grd", package="raster"))
> p1a <- rep(100, ncol(r))
> r[1:ncol(r)] <- p1a
> r <- writeRaster(r, filename='test.rst', overwrite=TRUE)
> plot(r)

Please note that in order to get the usual map view for this data set,
such that 1 km NS equals 1 km EW, you need to add:

plot(r, asp=1)

> Robert
> 
> 
> On Wed, May 5, 2010 at 10:05 PM, Robert J. Hijmans <r.hijmans at gmail.com> wrote:
>> Dear Seth,
>>
>> I think the problem is that you try to overwrite values in an existing
>> file. That is not directly possible (with raster anyway). You have to
>> start a new fil. Below are some examples. Also see
>> vignette('functions', 'raster')
>>
>> #1 if you can read the whole raster into memory
>> p1a <- rep(0, ncol(rout))
>> rin <- raster(system.file("external/test.grd", package="raster"), values=TRUE)
>> rin[1:ncol(rin)] = p1a
>> rout <- writeRaster(rin, filename="write1.rst", format="IDRISI",overwrite=TRUE)
>>
>> #2 row by row (and slow)
>> rin <- raster(system.file("external/test.grd", package="raster"))
>> rout <- raster(rin)
>> p1a <- rep(0, ncol(rout))
>> rout <- setValues(rout, p1a, 1)
>> rout <- writeRaster(rout, filename="write2.rst", format="IDRISI",overwrite=TRUE)
>> for (r in 2:nrow(rout)) {
>>        rin <- readRow(rin, r)
>>        rout <-setValues(rout, values(rin), r)
>>        rout <- writeRaster(rout, filename="write5.rst",
>> format="IDRISI",overwrite=TRUE)
>> }
>>
>>
>> # 3 block by block (much faster); using the rgdal driver
>> (format='RST') so that you
>> # first copy all values and then overwrite rows at any location
>> rin <- raster(system.file("external/test.grd", package="raster"))
>> rout <- raster(rin)
>> bs <- blockSize(rout)
>> rout <- writeStart(rout, filename="write3.rst", format="RST", overwrite=TRUE)
>> for (i in 1:bs$n) {
>>        v = getValuesBlock(rin, row=bs$row[i], nrows=bs$size)
>>        writeValues(rout, v, bs$row[i])
>> }
>> p1a <- rep(0, ncol(rout))
>> writeValues(rout, p1a, 1) # replace a row
>> rout <- writeStop(rout)
>>
>>
>> Robert
>>
>>
>>
>> On Wed, May 5, 2010 at 6:52 PM, Seth J Myers <sjmyers at syr.edu> wrote:
>>> Hi,
>>>
>>> I'm running R 2.11.0 on a 32 bit Windows Vista machine.  I have new versions of all relevant libraries installed.  I have been reading from IDRISI .rst files and this works fine using raster() and getValues().  I have passed the values from the .rst files through another R object and would like to write them as an .rst file.  In the following code, I am attempting to set the 1st row values of a RasterLayer object and then write these to a .rst file.  All raster files I am working with have 3,700 columns and 4,203 rows and are Connecticut StatePlane coordinate system which is equivalent to lambert's conformal conic proj.
>>>
>>> #extract 2nd column of a matrix which are the values of interest for the 1st row
>>> p1a<-p1[c(1:3700),c(2)]
>>> p1am<-as.matrix(p1a)
>>> #create RasterLayer object from a .rst file that was created in IDRISI beforehand with all 0s (real nums) for cell values
>>> put<-raster("C:\\rforest\\data\\rst85\\write2.rst",values=FALSE)
>>> #set 1st row to equal the values of interest
>>> put<-setValues(put,p1am,1)
>>> #write to a .rst file that I created in IDRISI beforehand with all 0s (real nums)
>>> writeRaster(put, filename="C:\\rforest\\data\\rst85\\write5.rst", format="IDRISI",overwrite=TRUE)
>>>
>>>
>>> PROBLEM:
>>>
>>> Until the writeRaster function call, everything is working.  I can use getValues to look at the 1st row of "put", and this equals p1am values.  I can look at the 2nd row of "put" and they are all zeros.  The writeRaster function does not give an error but, when opened in IDRISI, the legend seems correct but the values are expressed in scientific notation and are MUCH too small.  Also, the 1st row values are copied for all rows, when I expect all but row=1 to be equal to 0.  I tried, prior to opening in IDRISI, to create a RasterLayer object from the output raster from writeRaster above, to see if R gives the result wanted.  This results in the following error message and report on the RasterLayer object created.
>>>
>>>> put2<-raster("C:\\rforest\\data\\rst85\\write5.rst",values=TRUE)
>>>> put3<-getValues(put2,1)
>>> Error:
>>>        GDAL Error 3: Can't read(C:\rforest\data\rst85\write5.rst) block with X offset 0 and Y offset 0.
>>> No error
>>> Error in values(readRows(x, row, nrows)) :
>>>  error in evaluating the argument 'x' in selecting a method for function 'values'
>>>> put2
>>> class       : RasterLayer
>>> filename    : C:\rforest\data\rst85\write5.rst
>>> nrow        : 4203
>>> ncol        : 3700
>>> ncell       : 15551100
>>> min value   : 0
>>> max value   : 0
>>> projection  : +proj=lcc +lat_1=41.86666666666667 +lat_2=41.2 +lat_0=40.83333333333334 +lon_0=-72.75 +x_0=304800.6096 +y_0=152400.3048 +ellps=GRS80 +datum=NAD83 +units=m +no_defs +towgs84=0,0,0
>>> xmin        : 221895.5
>>> xmax        : 334671.7
>>> ymin        : 164342.4
>>> ymax        : 292450.1
>>> xres        : 30.48006
>>> yres        : 30.48006
>>>
>>>
>>> I have tried this entire process starting NOT with blank 0 rasters to create my SpatialLayer object (a shortcut I thought may be a problem) but instead creating rasters by specifying projections etc on non-used filenames.  The results are the same.
>>>
>>> Thanks,
>>> Seth
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From roman.lustrik at gmail.com  Thu May  6 08:58:10 2010
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Thu, 6 May 2010 08:58:10 +0200
Subject: [R-sig-Geo] raster::setValues
Message-ID: <u2h63a206011005052358h1ac60701h503e0c8fef1e60e4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100506/bfe1f7d1/attachment.pl>

From lists at remoteinformation.com.au  Thu May  6 09:44:40 2010
From: lists at remoteinformation.com.au (Ben Madin)
Date: Thu, 6 May 2010 15:44:40 +0800
Subject: [R-sig-Geo] maptools and rgeos
Message-ID: <A1F9CA77-4AAB-4886-8379-4CB57A0D68A1@remoteinformation.com.au>

G'day all,

Please excuse my not finding this, but having just upgraded maptools, there appears to be some issue over gpclib - not looking for trouble, I installed rgeos from r-forge, and it seems to be loadable, but loading maptools I still get the following message.

> library(rgeos)
Loading required package: sp
GEOS runtime version: 3.2.0-CAPI-1.6.0 
> library(maptools)
Loading required package: foreign
Loading required package: lattice

	Note: polygon geometry computations in maptools
 	depend on the package gpclib, which has a
 	restricted licence. It is disabled by default;
 	to enable gpclib, type gpclibPermit()

Checking rgeos availability as gpclib substitute:
FALSE 
>

Have I missed something on installation?(I'm using William Kyngesbury's GEOS Frameworks)

cheers

Ben



sessionInfo()
R version 2.10.1 Patched (2010-02-01 r51089) 
x86_64-apple-darwin9.8.0 

locale:
[1] en_AU.UTF-8/en_AU.UTF-8/C/C/en_AU.UTF-8/en_AU.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] maptools_0.7-34 lattice_0.18-3  foreign_0.8-40  rgeos_0.0-9     sp_0.9-62      

loaded via a namespace (and not attached):
[1] grid_2.10.1  tools_2.10.1


From Roger.Bivand at nhh.no  Thu May  6 10:08:58 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 6 May 2010 10:08:58 +0200 (CEST)
Subject: [R-sig-Geo] maptools and rgeos
In-Reply-To: <A1F9CA77-4AAB-4886-8379-4CB57A0D68A1@remoteinformation.com.au>
References: <A1F9CA77-4AAB-4886-8379-4CB57A0D68A1@remoteinformation.com.au>
Message-ID: <alpine.LRH.2.00.1005060950300.21837@reclus.nhh.no>

On Thu, 6 May 2010, Ben Madin wrote:

> G'day all,
>
> Please excuse my not finding this, but having just upgraded maptools, 
> there appears to be some issue over gpclib - not looking for trouble, I 
> installed rgeos from r-forge, and it seems to be loadable, but loading 
> maptools I still get the following message.
>
>> library(rgeos)
> Loading required package: sp
> GEOS runtime version: 3.2.0-CAPI-1.6.0
>> library(maptools)
> Loading required package: foreign
> Loading required package: lattice
>
> 	Note: polygon geometry computations in maptools
> 	depend on the package gpclib, which has a
> 	restricted licence. It is disabled by default;
> 	to enable gpclib, type gpclibPermit()
>
> Checking rgeos availability as gpclib substitute:
> FALSE
>>
>
> Have I missed something on installation?(I'm using William Kyngesbury's 
> GEOS Frameworks)

No, thanks for taking this up, and for attention to detail. Both maptools 
and spatstat now warn explicitly about the license problems with gpclib. 
We had hoped to have rgeos ready by now, but interfacing GEOS has turned 
out to be harder than anticipated.

The maptools development code had been modified to use rgeos if available 
- by a call to require(), and the inclusion of rgeos in the Suggests: 
field in the package metadata. Before rgeos had been advanced to release 
status, a serious problem was spotted (by Brian Ripley) in the maptools C 
code for reading GSHHS files, triggering a premature release. In this 
premature release, as can be seen in the ChangeLog:

http://cran.r-project.org/web/packages/maptools/ChangeLog

rgeos was hidden, and all links were commented out. Until rgeos is ready 
for returning to Suggests: status, use of the "drop in" rgeos functions 
has to be manual, so instead of say unionSpatialPolygons() in maptools, 
use unionSpatialPolygonsGEOS() in rgeos (and look at the examples on the 
help page, trying them out to see that the rounding problem has now been 
resolved).

R has (once again) had deserved success in the Google Summer of Coding, 
and rgeos is one of the projects that has been adopted. Some of the 
original difficulties have now been resolved, and I hope that the package 
will be greatly improved compared with my "muddling through" first cut at 
the GEOS interface.

Hope this clarifies things a little,

Roger

>
> cheers
>
> Ben
>
>
>
> sessionInfo()
> R version 2.10.1 Patched (2010-02-01 r51089)
> x86_64-apple-darwin9.8.0
>
> locale:
> [1] en_AU.UTF-8/en_AU.UTF-8/C/C/en_AU.UTF-8/en_AU.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] maptools_0.7-34 lattice_0.18-3  foreign_0.8-40  rgeos_0.0-9     sp_0.9-62
>
> loaded via a namespace (and not attached):
> [1] grid_2.10.1  tools_2.10.1
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From lists at remoteinformation.com.au  Thu May  6 10:27:46 2010
From: lists at remoteinformation.com.au (Ben Madin)
Date: Thu, 6 May 2010 16:27:46 +0800
Subject: [R-sig-Geo] maptools and rgeos
In-Reply-To: <alpine.LRH.2.00.1005060950300.21837@reclus.nhh.no>
References: <A1F9CA77-4AAB-4886-8379-4CB57A0D68A1@remoteinformation.com.au>
	<alpine.LRH.2.00.1005060950300.21837@reclus.nhh.no>
Message-ID: <E827D730-53DD-4D2D-815F-044C9B64ED3C@remoteinformation.com.au>

Thanks Roger,

Congratulations on the GSOC project - I had read about it, but my antipodean mind-set (Summer is over down here!) meant I thought it might be well underway or nearly over already!

cheers

Ben


On 06/05/2010, at 16:08 , Roger Bivand wrote:

> On Thu, 6 May 2010, Ben Madin wrote:
> 
>> G'day all,
>> 
>> Please excuse my not finding this, but having just upgraded maptools, there appears to be some issue over gpclib - not looking for trouble, I installed rgeos from r-forge, and it seems to be loadable, but loading maptools I still get the following message.
>> 
>>> library(rgeos)
>> Loading required package: sp
>> GEOS runtime version: 3.2.0-CAPI-1.6.0
>>> library(maptools)
>> Loading required package: foreign
>> Loading required package: lattice
>> 
>> 	Note: polygon geometry computations in maptools
>> 	depend on the package gpclib, which has a
>> 	restricted licence. It is disabled by default;
>> 	to enable gpclib, type gpclibPermit()
>> 
>> Checking rgeos availability as gpclib substitute:
>> FALSE
>>> 
>> 
>> Have I missed something on installation?(I'm using William Kyngesbury's GEOS Frameworks)
> 
> No, thanks for taking this up, and for attention to detail. Both maptools and spatstat now warn explicitly about the license problems with gpclib. We had hoped to have rgeos ready by now, but interfacing GEOS has turned out to be harder than anticipated.
> 
> The maptools development code had been modified to use rgeos if available - by a call to require(), and the inclusion of rgeos in the Suggests: field in the package metadata. Before rgeos had been advanced to release status, a serious problem was spotted (by Brian Ripley) in the maptools C code for reading GSHHS files, triggering a premature release. In this premature release, as can be seen in the ChangeLog:
> 
> http://cran.r-project.org/web/packages/maptools/ChangeLog
> 
> rgeos was hidden, and all links were commented out. Until rgeos is ready for returning to Suggests: status, use of the "drop in" rgeos functions has to be manual, so instead of say unionSpatialPolygons() in maptools, use unionSpatialPolygonsGEOS() in rgeos (and look at the examples on the help page, trying them out to see that the rounding problem has now been resolved).
> 
> R has (once again) had deserved success in the Google Summer of Coding, and rgeos is one of the projects that has been adopted. Some of the original difficulties have now been resolved, and I hope that the package will be greatly improved compared with my "muddling through" first cut at the GEOS interface.
> 
> Hope this clarifies things a little,
> 
> Roger
> 
>> 
>> cheers
>> 
>> Ben
>> 
>> 
>> 
>> sessionInfo()
>> R version 2.10.1 Patched (2010-02-01 r51089)
>> x86_64-apple-darwin9.8.0
>> 
>> locale:
>> [1] en_AU.UTF-8/en_AU.UTF-8/C/C/en_AU.UTF-8/en_AU.UTF-8
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> other attached packages:
>> [1] maptools_0.7-34 lattice_0.18-3  foreign_0.8-40  rgeos_0.0-9     sp_0.9-62
>> 
>> loaded via a namespace (and not attached):
>> [1] grid_2.10.1  tools_2.10.1
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
> 
> -- 
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
> 


From edzer.pebesma at uni-muenster.de  Thu May  6 13:50:59 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 06 May 2010 13:50:59 +0200
Subject: [R-sig-Geo] maptools and rgeos
In-Reply-To: <E827D730-53DD-4D2D-815F-044C9B64ED3C@remoteinformation.com.au>
References: <A1F9CA77-4AAB-4886-8379-4CB57A0D68A1@remoteinformation.com.au>	<alpine.LRH.2.00.1005060950300.21837@reclus.nhh.no>
	<E827D730-53DD-4D2D-815F-044C9B64ED3C@remoteinformation.com.au>
Message-ID: <4BE2AD23.7020409@uni-muenster.de>

Great to hear a GSOC project will work on this!

http://socghop.appspot.com/gsoc/student_proposal/show/google/gsoc2010/rundel/t127052456783


On 05/06/2010 10:27 AM, Ben Madin wrote:
> Thanks Roger,
> 
> Congratulations on the GSOC project - I had read about it, but my antipodean mind-set (Summer is over down here!) meant I thought it might be well underway or nearly over already!
> 
> cheers
> 
> Ben
> 
> 
> On 06/05/2010, at 16:08 , Roger Bivand wrote:
> 
>> On Thu, 6 May 2010, Ben Madin wrote:
>>
>>> G'day all,
>>>
>>> Please excuse my not finding this, but having just upgraded maptools, there appears to be some issue over gpclib - not looking for trouble, I installed rgeos from r-forge, and it seems to be loadable, but loading maptools I still get the following message.
>>>
>>>> library(rgeos)
>>> Loading required package: sp
>>> GEOS runtime version: 3.2.0-CAPI-1.6.0
>>>> library(maptools)
>>> Loading required package: foreign
>>> Loading required package: lattice
>>>
>>> 	Note: polygon geometry computations in maptools
>>> 	depend on the package gpclib, which has a
>>> 	restricted licence. It is disabled by default;
>>> 	to enable gpclib, type gpclibPermit()
>>>
>>> Checking rgeos availability as gpclib substitute:
>>> FALSE
>>>>
>>>
>>> Have I missed something on installation?(I'm using William Kyngesbury's GEOS Frameworks)
>>
>> No, thanks for taking this up, and for attention to detail. Both maptools and spatstat now warn explicitly about the license problems with gpclib. We had hoped to have rgeos ready by now, but interfacing GEOS has turned out to be harder than anticipated.
>>
>> The maptools development code had been modified to use rgeos if available - by a call to require(), and the inclusion of rgeos in the Suggests: field in the package metadata. Before rgeos had been advanced to release status, a serious problem was spotted (by Brian Ripley) in the maptools C code for reading GSHHS files, triggering a premature release. In this premature release, as can be seen in the ChangeLog:
>>
>> http://cran.r-project.org/web/packages/maptools/ChangeLog
>>
>> rgeos was hidden, and all links were commented out. Until rgeos is ready for returning to Suggests: status, use of the "drop in" rgeos functions has to be manual, so instead of say unionSpatialPolygons() in maptools, use unionSpatialPolygonsGEOS() in rgeos (and look at the examples on the help page, trying them out to see that the rounding problem has now been resolved).
>>
>> R has (once again) had deserved success in the Google Summer of Coding, and rgeos is one of the projects that has been adopted. Some of the original difficulties have now been resolved, and I hope that the package will be greatly improved compared with my "muddling through" first cut at the GEOS interface.
>>
>> Hope this clarifies things a little,
>>
>> Roger
>>
>>>
>>> cheers
>>>
>>> Ben
>>>
>>>
>>>
>>> sessionInfo()
>>> R version 2.10.1 Patched (2010-02-01 r51089)
>>> x86_64-apple-darwin9.8.0
>>>
>>> locale:
>>> [1] en_AU.UTF-8/en_AU.UTF-8/C/C/en_AU.UTF-8/en_AU.UTF-8
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] maptools_0.7-34 lattice_0.18-3  foreign_0.8-40  rgeos_0.0-9     sp_0.9-62
>>>
>>> loaded via a namespace (and not attached):
>>> [1] grid_2.10.1  tools_2.10.1
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> -- 
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From r.hijmans at gmail.com  Thu May  6 18:10:49 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 6 May 2010 09:10:49 -0700
Subject: [R-sig-Geo] raster::setValues
In-Reply-To: <u2h63a206011005052358h1ac60701h503e0c8fef1e60e4@mail.gmail.com>
References: <u2h63a206011005052358h1ac60701h503e0c8fef1e60e4@mail.gmail.com>
Message-ID: <x2zdc22b2571005060910k7121fc45t19a08e2d6f896d6a@mail.gmail.com>

Dear Roman,

> rs object ends up empty when trying to apply rowvals. I would expect the rs
> object to have line number three populated with as many values as there are
> columns.

This is the case:

> values(rs)
 [1]  1  2  3  4  5  6  7  8  9 10
> dataContent(rs)
[1] "row"
> dataIndices(rs)
[1] 21 30

dataIndices returns the cell numbers of the first and last value.
Generally the only reason to set a row of values is to then write them
to disk. There is not much else you can do because only the values of
this row are stored, not the values for any other cells. If you want
those too:

rs[] = NA
rs[(2*ncol(rs)+1):(3*ncol(rs))] = 1:ncol(rs)

# or

rs[] = NA
start = cellFromRowCol(rs, 3,1)
end =  cellFromRowCol(rs, 3, ncol(rs))
rs[start:end] = 1:ncol(rs)

Robert


On Wed, May 5, 2010 at 11:58 PM, Roman Lu?trik <roman.lustrik at gmail.com> wrote:
> When I run the sample code in ?setValues
>
> rs <- raster(ncol=10, nrow=10)
> vals <- 1:ncell(rs)
> rs <- setValues(rs, vals)
> rs <- clearValues(rs)
> rowvals <- 1:ncol(rs)
> rs <- setValues(rs, rowvals, 3)
>
> rs object ends up empty when trying to apply rowvals. I would expect the rs
> object to have line number three populated with as many values as there are
> columns. Or am I missing something very obvious here? Same behavior on 2.10
> and 2.11.
>
> Cheers,
> Roman
>
>
> --
> In God we trust, all others bring data.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From Steve_Friedman at nps.gov  Thu May  6 19:30:01 2010
From: Steve_Friedman at nps.gov (Steve_Friedman at nps.gov)
Date: Thu, 6 May 2010 13:30:01 -0400
Subject: [R-sig-Geo] How to merge or overlay spatial objects
Message-ID: <OF60FB978A.6136E12B-ON8525771B.005F6FC0-8525771B.006021C8@nps.gov>


Hi,

I'm working with a colleague who is attempting to overlay several
shapefiles and add attribute data to one of the shapefiles from an
independent *.csv file.

He has been successful in bringing in individual shapefiles into R, merging
the attribute data with one of the shapefiles, and plotting these one at a
time.

The ultimate objective is to plot them together and use the merged
attribute data to colorcode a specific subset of polygons associated with
the shapefile.

I apologize, for not having a good set of code snippets to share.  If
anyone can provide clues or guidelines on a method I would certainly
appreciate the assistance.

Thanks in Advance
Steve


Steve Friedman Ph. D.
Spatial Statistical Analyst
Everglades and Dry Tortugas National Park
950 N Krome Ave (3rd Floor)
Homestead, Florida 33034

Steve_Friedman at nps.gov
Office (305) 224 - 4282
Fax     (305) 224 - 4147


From Roger.Bivand at nhh.no  Thu May  6 20:00:38 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 6 May 2010 20:00:38 +0200 (CEST)
Subject: [R-sig-Geo] spgwr and selecting aic for bandwidth configuration
In-Reply-To: <x2zaf66389e1004101347o9c3763b5m392b50ef6c852103@mail.gmail.com>
References: <x2zaf66389e1004101347o9c3763b5m392b50ef6c852103@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1005061948470.21837@reclus.nhh.no>

On Sat, 10 Apr 2010, Christopher Cardinal wrote:

> I am trying to use gwr.sel to apply the AIC method for bandwidth selection
> in SPGWR. R version is 2.10.1 (used for compatibility with Rpy--however, the
> following problem occurs directly from within R). SPGWR version is 0.6-4.
> First I run global regression, then gwr()with default CV method for
> bandwidth selection with no problems. Then I run "aic" bandwidth selection
> method, which outputs bandwidth results. Then I run gwr(), which produces no
> output. Perhaps I'm using the wrong command? I can't find many examples of
> gwr() implemented with "aic". Please share your ideas if you have any.

Sorry not to have replied earlier. There is no summary() method for "gwr" 
objects, only a print() method. The output of gwr.sel() is a single 
number. It is impossible to say what is in data_bw_aic - it should be 
similar to the last number shown in the verbose output - but the 
optimisation in gwr.sel() does not seem to have converged - I don't think 
that you have paid attention to error messages, or at least not shown them 
in your posting. Without a reproducible example, it is impossible to help. 
Try to reproduce your problem with the columbus or georgia data sets 
shipped with the package.

Hope this helps,

Roger


> Thanks.
>
>> library(spgwr)
> Loading required package: sp
> Loading required package: maptools
> Loading required package: foreign
> Loading required package: lattice
> NOTE: default kernel and CV criteria changed
> see help pages for details
>> library(foreign)
>> data <-
> read.dbf("C:/GIS/Hunter/Thesis/GISData/Parcel/Albany/AlbCnty/Polygon2004/test2.dbf")
>> data <- subset(data, GOOGDIST > 0)
>> data <- subset(data, ACRES > .5)
>> data_lm <- lm(SALE_PRICE ~ ACRES + CUR_TOT_A + HHINC + PERGTBACH, data =
> data)
>> data_lm_sum <- summary(data_lm)
>> tmp<-print(data_lm_sum)
>
> Call:
> lm(formula = SALE_PRICE ~ ACRES + CUR_TOT_A + HHINC + PERGTBACH,
>    data = data)
>
> Residuals:
>    Min      1Q  Median      3Q     Max
> -890883  -92357  -66457   76176 1550181
>
> Coefficients:
>              Estimate Std. Error t value Pr(>|t|)
> (Intercept)  8.997e+04  2.566e+04   3.507 0.000483 ***
> ACRES       -1.999e+03  3.915e+02  -5.106 4.26e-07 ***
> CUR_TOT_A    1.993e+00  9.443e-02  21.104  < 2e-16 ***
> HHINC       -7.636e-02  5.363e-01  -0.142 0.886810
> PERGTBACH    9.287e+03  5.020e+04   0.185 0.853272
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Residual standard error: 186700 on 689 degrees of freedom
> Multiple R-squared: 0.4061,     Adjusted R-squared: 0.4027
> F-statistic: 117.8 on 4 and 689 DF,  p-value: < 2.2e-16
>
>> data_bw <- gwr.sel(SALE_PRICE ~ ACRES + CUR_TOT_A + HHINC + PERGTBACH ,
> data = data, coords = cbind(data$X, data$Y))
> Bandwidth: 79378.23 CV score: 2.508302e+13
> Bandwidth: 128308.4 CV score: 2.549703e+13
> Bandwidth: 49137.69 CV score: 2.444211e+13
> Bandwidth: 30448.02 CV score: 2.369592e+13
> Bandwidth: 18897.16 CV score: 2.35517e+13
> Bandwidth: 17792.42 CV score: 2.365362e+13
> Bandwidth: 23918.27 CV score: 2.340727e+13
> Bandwidth: 26412.41 CV score: 2.348778e+13
> Bandwidth: 23178.31 CV score: 2.339931e+13
> Bandwidth: 22740.56 CV score: 2.339894e+13
> Bandwidth: 22908.52 CV score: 2.339868e+13
> Bandwidth: 22910.54 CV score: 2.339868e+13
> Bandwidth: 22909.77 CV score: 2.339868e+13
> Bandwidth: 22909.78 CV score: 2.339868e+13
> Bandwidth: 22909.78 CV score: 2.339868e+13
> Bandwidth: 22909.78 CV score: 2.339868e+13
> Bandwidth: 22909.78 CV score: 2.339868e+13
>> data_gauss <- gwr(SALE_PRICE ~ ACRES + CUR_TOT_A + HHINC + PERGTBACH, data
> = data, coords = cbind(data$X, data$Y), bandwidth = data_bw, hatmatrix =
> TRUE)
>> data_gauss_sum <- summary(data_gauss)
>> print (data_gauss_sum)
>          Length Class                  Mode
> SDF            1 SpatialPointsDataFrame S4
> lhat      481636 -none-                 numeric
> lm            11 -none-                 list
> results       14 -none-                 list
> bandwidth      1 -none-                 numeric
> adapt          0 -none-                 NULL
> hatmatrix      1 -none-                 logical
> gweight        1 -none-                 character
> this.call      6 -none-                 call
>> print (data_gauss)
> Call:
> gwr(formula = SALE_PRICE ~ ACRES + CUR_TOT_A + HHINC + PERGTBACH,
>    data = data, coords = cbind(data$X, data$Y), bandwidth = data_bw,
>    hatmatrix = TRUE)
> Kernel function: gwr.Gauss
> Fixed bandwidth: 22909.78
> Summary of GWR coefficient estimates:
>                   Min.    1st Qu.     Median    3rd Qu.       Max.
> Global
> X.Intercept. -2.883e+05 -4.166e+04  1.135e+05  1.655e+05  2.834e+05
> 89969.4089
> ACRES        -3.259e+03 -2.678e+03 -1.572e+03  9.080e+02  8.611e+03
> -1998.9124
> CUR_TOT_A     2.233e-02  1.261e+00  1.628e+00  2.049e+00  2.380e+00
> 1.9928
> HHINC        -5.563e+00 -1.219e+00  3.129e-01  2.753e+00  8.023e+00
> -0.0764
> PERGTBACH    -3.023e+05 -9.237e+04 -5.303e+04 -7.264e+03  1.014e+05
> 9287.3433
> Number of data points: 694
> Effective number of parameters (residual: 2traceS - traceS'S): 29.87522
> Effective degrees of freedom (residual: 2traceS - traceS'S): 664.1248
> Sigma (residual: 2traceS - traceS'S): 170145.2
> Effective number of parameters (model: traceS): 21.99972
> Effective degrees of freedom (model: traceS): 672.0003
> Sigma (model: traceS): 169145.3
> Sigma (ML): 166442.7
> AICc (GWR p. 61, eq 2.33; p. 96, eq. 4.21): 18704.23
> AIC (GWR p. 96, eq. 4.22): 18678.59
> Residual sum of squares: 1.922601e+13
>
>> data_bw_aic <- gwr.sel(SALE_PRICE ~ ACRES + CUR_TOT_A + HHINC + PERGTBACH
> , data = data, coords = cbind(data$X, data$Y), method="aic")
> Bandwidth: 79378.23 AIC: 18795.23
> Bandwidth: 128308.4 AIC: 18811.03
> Bandwidth: 49137.69 AIC: 18768.93
> Bandwidth: 30448.02 AIC: 18733.32
> Bandwidth: 18897.16 AIC: 18678.52
> Bandwidth: 11758.34 AIC: 18593.90
>> data_bw_aic_sum <- summary(data_bw_aic)
>> data_bw_aic_sum
>> print(data_bw_aic)
>> data_gauss_aic <- gwr(SALE_PRICE ~ ACRES + CUR_TOT_A + HHINC + PERGTBACH,
> data = data, coords = cbind(data$X, data$Y), bandwidth = data_bw_aic,
> hatmatrix = TRUE)
>> print(data_gauss_aic)
>> summary(data_gauss_aic)
>>
>
>
> data looks like this:
>        UID YEAR        X       Y      LAT      LONG       ACRES SLOPE
> CUR_TOT_A     FLOODPER
> 1      6482 2004 698260.3 1446285 42.80053 -73.73233   0.7309970     1
> 40000 0.0000000000
> 5      8554 2004 695351.2 1438002 42.77801 -73.74342   0.8890091     1
> 7400 0.0000000000
> 7     15413 2004 696033.0 1431745 42.76088 -73.74108   0.5565335     1
> 50000 0.0000000000
> 10     8220 2004 680872.2 1435917 42.77268 -73.79744   0.8693349     1
> 27200 0.0000000000
> 11     8221 2004 681023.1 1436053 42.77303 -73.79688   0.8018674     1
> 25900 0.0000000000
> 12     8792 2004 691488.3 1439555 42.78245 -73.75765   0.8236566     1
> 42000 0.0000000000
> 13     8793 2004 691556.9 1439692 42.78277 -73.75746   0.8610513     1
> 42000 0.0000000000
> 14    14411 2004 682812.3 1426310 42.74625 -73.79048   1.9767706     1
> 150000 0.0000000000
> 15    14656 2004 688672.5 1432607 42.76348 -73.76833   3.5036509     1
> 65700 0.0000000000
> 16    15103 2004 686513.4 1428931 42.75343 -73.77653   4.5957896     1
> 352800 0.0000000000
> 19    89916 2004 702825.7 1439163 42.78107 -73.71557   5.4003465     1
> 23200 0.0000000000
> 22    93898 2004 704736.3 1432229 42.76197 -73.70865   0.9085830     1
> 8400 0.0000000000
> 25    10109 2004 657502.9 1427039 42.74891 -73.88458   3.1770620     1
> 53600 0.0000000000
> 26    10296 2004 657568.5 1427583 42.75031 -73.88438   0.9898759     1
> 39200 0.5419490988
>
>                                                         GOOGADDR GOOGDIST
> PROP_CLASS SALE_PRICE HHINC
> 1                       1251 New Loudon Rd, Cohoes, NY 12047, USA
> 21597        311      42500 25964
> 5                             22 Meadow St, Cohoes, NY 12047, USA
> 19195        311      31500 25964
> 7                            44 Graffin Dr, Latham, NY 12110, USA
> 18764        311     396500 25964
> 10                      4119-4195 River Rd, Latham, NY 12110, USA
> 18941        311      71454 16222
> 11                      4119-4195 River Rd, Latham, NY 12110, USA
> 18941        311      71454 16222
> 12                   112 Dunsbach Ferry Rd, Cohoes, NY 12047, USA
> 19164        311      65000 16222
> 13                   114 Dunsbach Ferry Rd, Cohoes, NY 12047, USA
> 19208        311      68000 16222
> 14                             155 Wade Rd, Latham, NY 12110, USA
> 13289        330     100000 16222
> 15                      100 Sparrowbush Rd, Latham, NY 12110, USA
> 16458        311     275000 16222
> 16                           4 Stanley Cir, Latham, NY 12110, USA
> 15605        330     307000 16222
> 19                            28 Edward St, Cohoes, NY 12047, USA
> 21813        311     114685 51214
> 22                            8 Oxford Cir, Cohoes, NY 12047, USA
> 22499        311     342551 51214
> 25                           72 Morris Rd, Colonie, NY 12205, USA
> 14924        330     190000 19865
> 26                       79 Morris Rd, Schenectady, NY 12304, USA
> 14929        330      18000 19865
>
>      PERGTBACH PERLTBACH PERCAPINC
> 1    0.11521926 0.8847807     14998
> 5    0.11521926 0.8847807     14998
> 7    0.11521926 0.8847807     14998
> 10   0.12627425 0.8737257     12147
> 11   0.12627425 0.8737257     12147
> 12   0.12627425 0.8737257     12147
> 13   0.12627425 0.8737257     12147
> 14   0.12627425 0.8737257     12147
> 15   0.12627425 0.8737257     12147
> 16   0.12627425 0.8737257     12147
> 19   0.37195452 0.6280455     25915
> 22   0.37195452 0.6280455     25915
> 25   0.16253444 0.8374656     10992
> 26   0.16253444 0.8374656     10992
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From r.hijmans at gmail.com  Thu May  6 20:11:11 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 6 May 2010 11:11:11 -0700
Subject: [R-sig-Geo] writeRaster problems
In-Reply-To: <4BE25F35.10908@uni-muenster.de>
References: <266CBFBFD14254478D52158AE6BF90170C6490F7@BL2PRD0103MB038.prod.exchangelabs.com>
	<u2xdc22b2571005052203y9cb1af5ej952e9e9d4474c0bc@mail.gmail.com>
	<l2udc22b2571005052205q256fe453m7b5e977da8c99bbe@mail.gmail.com>
	<t2ndc22b2571005052226yc0bb2827ma540f1485db545e2@mail.gmail.com>
	<4BE25F35.10908@uni-muenster.de>
Message-ID: <i2qdc22b2571005061111m798addd1n4974162e5166f270@mail.gmail.com>

> Please note that in order to get the usual map view for this data set,
> such that 1 km NS equals 1 km EW, you need to add:
>
> plot(r, asp=1)


And this is now the default behavior ( raster >= 1.0.8 ). Thanks for
pointing this out (again).



On Wed, May 5, 2010 at 11:18 PM, Edzer Pebesma
<edzer.pebesma at uni-muenster.de> wrote:
> On 05/06/2010 07:26 AM, Robert J. Hijmans wrote:
>> Seth,
>> I think I overlooked what is perhaps the easiest way to do this, using
>> a standard replacement approach:
>>
>> library(raster)
>> r <- raster(system.file("external/test.grd", package="raster"))
>> p1a <- rep(100, ncol(r))
>> r[1:ncol(r)] <- p1a
>> r <- writeRaster(r, filename='test.rst', overwrite=TRUE)
>> plot(r)
>
> Please note that in order to get the usual map view for this data set,
> such that 1 km NS equals 1 km EW, you need to add:
>
> plot(r, asp=1)
>
>> Robert
>>
>>
>> On Wed, May 5, 2010 at 10:05 PM, Robert J. Hijmans <r.hijmans at gmail.com> wrote:
>>> Dear Seth,
>>>
>>> I think the problem is that you try to overwrite values in an existing
>>> file. That is not directly possible (with raster anyway). You have to
>>> start a new fil. Below are some examples. Also see
>>> vignette('functions', 'raster')
>>>
>>> #1 if you can read the whole raster into memory
>>> p1a <- rep(0, ncol(rout))
>>> rin <- raster(system.file("external/test.grd", package="raster"), values=TRUE)
>>> rin[1:ncol(rin)] = p1a
>>> rout <- writeRaster(rin, filename="write1.rst", format="IDRISI",overwrite=TRUE)
>>>
>>> #2 row by row (and slow)
>>> rin <- raster(system.file("external/test.grd", package="raster"))
>>> rout <- raster(rin)
>>> p1a <- rep(0, ncol(rout))
>>> rout <- setValues(rout, p1a, 1)
>>> rout <- writeRaster(rout, filename="write2.rst", format="IDRISI",overwrite=TRUE)
>>> for (r in 2:nrow(rout)) {
>>> ? ? ? ?rin <- readRow(rin, r)
>>> ? ? ? ?rout <-setValues(rout, values(rin), r)
>>> ? ? ? ?rout <- writeRaster(rout, filename="write5.rst",
>>> format="IDRISI",overwrite=TRUE)
>>> }
>>>
>>>
>>> # 3 block by block (much faster); using the rgdal driver
>>> (format='RST') so that you
>>> # first copy all values and then overwrite rows at any location
>>> rin <- raster(system.file("external/test.grd", package="raster"))
>>> rout <- raster(rin)
>>> bs <- blockSize(rout)
>>> rout <- writeStart(rout, filename="write3.rst", format="RST", overwrite=TRUE)
>>> for (i in 1:bs$n) {
>>> ? ? ? ?v = getValuesBlock(rin, row=bs$row[i], nrows=bs$size)
>>> ? ? ? ?writeValues(rout, v, bs$row[i])
>>> }
>>> p1a <- rep(0, ncol(rout))
>>> writeValues(rout, p1a, 1) # replace a row
>>> rout <- writeStop(rout)
>>>
>>>
>>> Robert
>>>
>>>
>>>
>>> On Wed, May 5, 2010 at 6:52 PM, Seth J Myers <sjmyers at syr.edu> wrote:
>>>> Hi,
>>>>
>>>> I'm running R 2.11.0 on a 32 bit Windows Vista machine. ?I have new versions of all relevant libraries installed. ?I have been reading from IDRISI .rst files and this works fine using raster() and getValues(). ?I have passed the values from the .rst files through another R object and would like to write them as an .rst file. ?In the following code, I am attempting to set the 1st row values of a RasterLayer object and then write these to a .rst file. ?All raster files I am working with have 3,700 columns and 4,203 rows and are Connecticut StatePlane coordinate system which is equivalent to lambert's conformal conic proj.
>>>>
>>>> #extract 2nd column of a matrix which are the values of interest for the 1st row
>>>> p1a<-p1[c(1:3700),c(2)]
>>>> p1am<-as.matrix(p1a)
>>>> #create RasterLayer object from a .rst file that was created in IDRISI beforehand with all 0s (real nums) for cell values
>>>> put<-raster("C:\\rforest\\data\\rst85\\write2.rst",values=FALSE)
>>>> #set 1st row to equal the values of interest
>>>> put<-setValues(put,p1am,1)
>>>> #write to a .rst file that I created in IDRISI beforehand with all 0s (real nums)
>>>> writeRaster(put, filename="C:\\rforest\\data\\rst85\\write5.rst", format="IDRISI",overwrite=TRUE)
>>>>
>>>>
>>>> PROBLEM:
>>>>
>>>> Until the writeRaster function call, everything is working. ?I can use getValues to look at the 1st row of "put", and this equals p1am values. ?I can look at the 2nd row of "put" and they are all zeros. ?The writeRaster function does not give an error but, when opened in IDRISI, the legend seems correct but the values are expressed in scientific notation and are MUCH too small. ?Also, the 1st row values are copied for all rows, when I expect all but row=1 to be equal to 0. ?I tried, prior to opening in IDRISI, to create a RasterLayer object from the output raster from writeRaster above, to see if R gives the result wanted. ?This results in the following error message and report on the RasterLayer object created.
>>>>
>>>>> put2<-raster("C:\\rforest\\data\\rst85\\write5.rst",values=TRUE)
>>>>> put3<-getValues(put2,1)
>>>> Error:
>>>> ? ? ? ?GDAL Error 3: Can't read(C:\rforest\data\rst85\write5.rst) block with X offset 0 and Y offset 0.
>>>> No error
>>>> Error in values(readRows(x, row, nrows)) :
>>>> ?error in evaluating the argument 'x' in selecting a method for function 'values'
>>>>> put2
>>>> class ? ? ? : RasterLayer
>>>> filename ? ?: C:\rforest\data\rst85\write5.rst
>>>> nrow ? ? ? ?: 4203
>>>> ncol ? ? ? ?: 3700
>>>> ncell ? ? ? : 15551100
>>>> min value ? : 0
>>>> max value ? : 0
>>>> projection ?: +proj=lcc +lat_1=41.86666666666667 +lat_2=41.2 +lat_0=40.83333333333334 +lon_0=-72.75 +x_0=304800.6096 +y_0=152400.3048 +ellps=GRS80 +datum=NAD83 +units=m +no_defs +towgs84=0,0,0
>>>> xmin ? ? ? ?: 221895.5
>>>> xmax ? ? ? ?: 334671.7
>>>> ymin ? ? ? ?: 164342.4
>>>> ymax ? ? ? ?: 292450.1
>>>> xres ? ? ? ?: 30.48006
>>>> yres ? ? ? ?: 30.48006
>>>>
>>>>
>>>> I have tried this entire process starting NOT with blank 0 rasters to create my SpatialLayer object (a shortcut I thought may be a problem) but instead creating rasters by specifying projections etc on non-used filenames. ?The results are the same.
>>>>
>>>> Thanks,
>>>> Seth
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> 8333081, Fax: +49 251 8339763 ?http://ifgi.uni-muenster.de
> http://www.52north.org/geostatistics ? ? ?e.pebesma at wwu.de
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From ageel_bushara at yahoo.com  Thu May  6 23:20:06 2010
From: ageel_bushara at yahoo.com (Ageel Ibrahim Bushara)
Date: Thu, 6 May 2010 14:20:06 -0700 (PDT)
Subject: [R-sig-Geo] Fw: AGU Book on Rainfall: Request for chapter
	contribution
Message-ID: <156306.42486.qm@web35802.mail.mud.yahoo.com>

Dear All,

This is might be interesting for you.

Cheers,
Ageel I. Bushara,
PhD in Environmental Engineering, University of Trento, Italy



----- Forwarded Message ----
From: "MeKonnen, Gebremichael" <mekonnen at engr.uconn.edu>
To: Ageel Ibrahim Bushara <ageel_bushara at yahoo.com>
Sent: Wed, May 5, 2010 8:57:49 PM
Subject: AGU Book on Rainfall: Request for chapter contribution

 
Dear
Ageel,
Thank
you for your help to send this email out to Geostatistics Professors you know
of who could write the book chapter in a reasonably short period of time, say 4
? 6 weeks. 
Cheers,
Mekonnen
 
Dear Invited Author/s:

We (Dr. Firat Testik and I) proposed to publisher AGU an edited book titled
"Rainfall: Microphysics, Measurement, Estimation, and Statistical
Analyses".  The idea is to provide a comprehensive coverage of
the current state of rainfall physics and estimation.  AGU has accepted
our proposal and agreed to publish the edited book according to the table of
contents attached. In fact, we have received all  the book chapter manuscripts
except one chapter, which is why I am sending this invitation.
We just learnt that the
author of our ?Geostatistics? chapter cannot
deliver as promised due to unexpected health problems. Therefore, we are
looking for author/s who can write this manuscript in a reasonable short period
of time, about 1 month. The nice thing about writing this book chapter is that the
book will be published fairly soon, since we have all the book chapters ready
except this one.
Given your expertise, we
would like to invite you to write this specific chapter. We hope that you will
accept this invitation to disseminate your expertise among the rainfall science
community through this book.

Please advise us of your decision as soon as possible. If you have any
questions, feel free to contact us.


Cordially,
 
Mekonnen
Gebremichael, Ph.D. 
Assistant
Professor
Director,
Distance Learning & M. Eng. Program Development
Department of
Civil and Environmental Engineering
University of
Connecticut (UConn)
261 Glenbrook
Road Unit 2037, Storrs, CT 06269-2037, USA 
Tel:
+1-860-486-2771
Fax:
+1-860-486-2298 
mekonnen at engr.uconn.edu
 
Representative of the University of
Connecticut to CUAHSI (Consortium of Universities Allied for Hydrological Sciences
Inc.)
Advisor,
Engineers Without Border ? University of Connecticut Chapter
 
Editor, Satellite
Rainfall Applications for Surface Hydrology
Editor, A
special issue of Remote Sensing- Land Surface Fluxes
Associate
Editor, Atmospheric Research
Editorial Board
Member,Remote Sensing
Guest Editor,Hydrology and Earth System Sciences


      
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100506/a3cfe14f/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: TOC.docx
Type: application/vnd.openxmlformats-officedocument.wordprocessingml.document
Size: 16124 bytes
Desc: TOC.docx
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100506/a3cfe14f/attachment.bin>

From jgarcia at ija.csic.es  Fri May  7 02:28:31 2010
From: jgarcia at ija.csic.es (jgarcia at ija.csic.es)
Date: Fri, 7 May 2010 02:28:31 +0200 (CEST)
Subject: [R-sig-Geo] Fw: AGU Book on Rainfall: Request for chapter
 contribution
In-Reply-To: <156306.42486.qm@web35802.mail.mud.yahoo.com>
References: <156306.42486.qm@web35802.mail.mud.yahoo.com>
Message-ID: <57353.86.0.54.218.1273192111.squirrel@paleo.ija.csic.es>

Dear Ageel,
Perhaps searching for geostatistics uses for multisensor rainfall
estimation you could find a number of authors that could do this
relatively fast (e.g., Dong J. Seo, Witold Krajewski, Smith...)
Good luck,

Javier Garc?a-Pintado
---

I guess you know geostatistics uses for multisensor rainfall estimation.

> Dear All,
>
> This is might be interesting for you.
>
> Cheers,
> Ageel I. Bushara,
> PhD in Environmental Engineering, University of Trento, Italy
>
>
>
> ----- Forwarded Message ----
> From: "MeKonnen, Gebremichael" <mekonnen at engr.uconn.edu>
> To: Ageel Ibrahim Bushara <ageel_bushara at yahoo.com>
> Sent: Wed, May 5, 2010 8:57:49 PM
> Subject: AGU Book on Rainfall: Request for chapter contribution
>
>
> Dear
> Ageel,
> Thank
> you for your help to send this email out to Geostatistics Professors you
> know
> of who could write the book chapter in a reasonably short period of time,
> say 4
> ??? 6 weeks.
> Cheers,
> Mekonnen
>
> Dear Invited Author/s:
>
> We (Dr. Firat Testik and I) proposed to publisher AGU an edited book
> titled
> "Rainfall: Microphysics, Measurement, Estimation, and Statistical
> Analyses".  The idea is to provide a comprehensive coverage of
> the current state of rainfall physics and estimation.  AGU has accepted
> our proposal and agreed to publish the edited book according to the table
> of
> contents attached. In fact, we have received all  the book chapter
> manuscripts
> except one chapter, which is why I am sending this invitation.
> We just learnt that the
> author of our ???Geostatistics??? chapter cannot
> deliver as promised due to unexpected health problems. Therefore, we are
> looking for author/s who can write this manuscript in a reasonable short
> period
> of time, about 1 month. The nice thing about writing this book chapter is
> that the
> book will be published fairly soon, since we have all the book chapters
> ready
> except this one.
> Given your expertise, we
> would like to invite you to write this specific chapter. We hope that you
> will
> accept this invitation to disseminate your expertise among the rainfall
> science
> community through this book.
>
> Please advise us of your decision as soon as possible. If you have any
> questions, feel free to contact us.
>
>
> Cordially,
>
> Mekonnen
> Gebremichael, Ph.D.
> Assistant
> Professor
> Director,
> Distance Learning & M. Eng. Program Development
> Department of
> Civil and Environmental Engineering
> University of
> Connecticut (UConn)
> 261 Glenbrook
> Road Unit 2037, Storrs, CT 06269-2037, USA
> Tel:
> +1-860-486-2771
> Fax:
> +1-860-486-2298
> mekonnen at engr.uconn.edu
>
> Representative of the University of
> Connecticut to CUAHSI (Consortium of Universities Allied for Hydrological
> Sciences
> Inc.)
> Advisor,
> Engineers Without Border ??? University of Connecticut Chapter
>
> Editor, Satellite
> Rainfall Applications for Surface Hydrology
> Editor, A
> special issue of Remote Sensing- Land Surface Fluxes
> Associate
> Editor, Atmospheric Research
> Editorial Board
> Member,Remote Sensing
> Guest Editor,Hydrology and Earth System Sciences
>
>
>       _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From everton.emanuel at gmail.com  Fri May  7 20:36:40 2010
From: everton.emanuel at gmail.com (Everton Emanuel)
Date: Fri, 7 May 2010 15:36:40 -0300
Subject: [R-sig-Geo] How to delete a single polygon in a shape file
Message-ID: <n2kdf06e3df1005071136z2716aec0mef41e5c49719adbb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100507/a3efb415/attachment.pl>

From mudrak at wisc.edu  Fri May  7 22:06:17 2010
From: mudrak at wisc.edu (Erika Mudrak)
Date: Fri, 07 May 2010 15:06:17 -0500
Subject: [R-sig-Geo] memory allocation problem with envelope function in
	spatstat
Message-ID: <72b0f4e61e81f.4be42c69@wiscmail.wisc.edu>

Hi everyone-  I am trying to fit an inhomogenous K function based to a large(ish) dataset.  I have successfully executed this code on data sets with a smaller n. 



> SPECIES.ppp
 planar point pattern: 1598 points 
window: rectangle = [564320, 564320] x [228490, 228500] units 
> lambda=density(SPECIES.ppp)
> Lin=envelope(SPECIES.ppp,Linhom,nsim=5,simulate=expression(rpoispp(lambda)),
+ correction="border")
Error: cannot allocate vector of size 244.5 Mb

I am working on a Windows Vista OS with 3GB RAM, and I have attempted to increase the memory size using  memory.limit(2000) within R and by adding --max-vsize=2000M  to the end of the Target field in the shortcut tab of the R properties dialog box. 

I have also tried making a list of simulated patterns ahead of time, but I get the same error:

> simpatterns=list()
> for (i in 1:5)simpatterns[[i]]=rpoispp(lambda)
> Lin=envelope(SPECIES.ppp,Linhom,nsim=5,simulate=simpatterns,
+ correction="border")
Error: cannot allocate vector of size 244.5 Mb

The spatstat FAQ suggest that a complete analysis should be feasible on a data set up of to 4000 points. 

Can anyone suggest ways to increase my memory limit or to modify my code to make this possible? I don't know what else to try!! Ideally, I would like to be able to make nsim=200, but I am trying to make it work with small numbers for now.  

Thank you,

Erika Mudrak


-- 
-------------------------------------------
Erika Mudrak
Graduate Student
Department of Botany
University of Wisconsin-Madison
430 Lincoln Dr
Madison WI, 53706
608-265-2191
mudrak at wisc.edu
http://botany.wisc.edu/waller/lab/Mudrak/


From dan.putler at sauder.ubc.ca  Fri May  7 22:22:51 2010
From: dan.putler at sauder.ubc.ca (Dan Putler)
Date: Fri, 7 May 2010 13:22:51 -0700
Subject: [R-sig-Geo] memory allocation problem with envelope function	in
	spatstat
In-Reply-To: <6450_1273262799_1273262799_72b0f4e61e81f.4be42c69@wiscmail.wisc.edu>
References: <6450_1273262799_1273262799_72b0f4e61e81f.4be42c69@wiscmail.wisc.edu>
Message-ID: <1273263771.6860.9.camel@whitebox>

Hi Erika,

Yes, R's classic warning that you don't have enough memory. I've done K
function analysis with much larger (19,000 point) data sets on a machine
with 3.5GB (running 32 bit Linux), so what you are doing should be
possible. One thought is to create a new R workspace with only your
point data set in it. R wants to hold the workspace in memory, so if you
have a lot of stuff lying around your workspace, you could run into
problems.

Dan

On Fri, 2010-05-07 at 13:06 -0700, Erika Mudrak wrote:
> Hi everyone-  I am trying to fit an inhomogenous K function based to a large(ish) dataset.  I have successfully executed this code on data sets with a smaller n. 
> 
> 
> 
> > SPECIES.ppp
>  planar point pattern: 1598 points 
> window: rectangle = [564320, 564320] x [228490, 228500] units 
> > lambda=density(SPECIES.ppp)
> > Lin=envelope(SPECIES.ppp,Linhom,nsim=5,simulate=expression(rpoispp(lambda)),
> + correction="border")
> Error: cannot allocate vector of size 244.5 Mb
> 
> I am working on a Windows Vista OS with 3GB RAM, and I have attempted to increase the memory size using  memory.limit(2000) within R and by adding --max-vsize=2000M  to the end of the Target field in the shortcut tab of the R properties dialog box. 
> 
> I have also tried making a list of simulated patterns ahead of time, but I get the same error:
> 
> > simpatterns=list()
> > for (i in 1:5)simpatterns[[i]]=rpoispp(lambda)
> > Lin=envelope(SPECIES.ppp,Linhom,nsim=5,simulate=simpatterns,
> + correction="border")
> Error: cannot allocate vector of size 244.5 Mb
> 
> The spatstat FAQ suggest that a complete analysis should be feasible on a data set up of to 4000 points. 
> 
> Can anyone suggest ways to increase my memory limit or to modify my code to make this possible? I don't know what else to try!! Ideally, I would like to be able to make nsim=200, but I am trying to make it work with small numbers for now.  
> 
> Thank you,
> 
> Erika Mudrak
> 
> 
-- 
Dan Putler
Sauder School of Business
University of British Columbia


From tim.romel at vistracks.com  Fri May  7 23:35:34 2010
From: tim.romel at vistracks.com (Tim Romel)
Date: Fri, 7 May 2010 16:35:34 -0500
Subject: [R-sig-Geo] Querying Spatial Data Using rgdal
Message-ID: <s2z90a726dc1005071435ifb97b2cdm5e8d580fd4b9f3f1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100507/54db06cb/attachment.pl>

From brookskehler at gmail.com  Sun May  9 00:30:27 2010
From: brookskehler at gmail.com (Brooks Kehler)
Date: Sat, 8 May 2010 18:30:27 -0400
Subject: [R-sig-Geo] Querying Spatial Data Using rgdal
In-Reply-To: <s2z90a726dc1005071435ifb97b2cdm5e8d580fd4b9f3f1@mail.gmail.com>
References: <s2z90a726dc1005071435ifb97b2cdm5e8d580fd4b9f3f1@mail.gmail.com>
Message-ID: <w2o49b12cd41005081530s2d6c45f8oc6a61dec3ffa2426@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100508/ad0d4097/attachment.pl>

From nitmithv at yahoo.com.cn  Mon May 10 06:52:01 2010
From: nitmithv at yahoo.com.cn (Kai Zhang)
Date: Sun, 9 May 2010 23:52:01 -0500
Subject: [R-sig-Geo] Parameters in fitting variogram automatically in gstat
Message-ID: <201005092352007033108@yahoo.com.cn>

Hi folks,

I am working on a problem dealing with fitting variogram automatically due to a large dateset. Gstat R package is used to conduct this work. Part of this work is to compare performance of different kriging methods. The comparison criteria is RMSE. I am using fit.variogram function for ordinary kriging, and fit.lmc for co-kriging. I have to specify a theoretical variogram at first. The problem is that results are sensitive to initial values specified in theoretical variograms, mainly "Range". Gstat manual points out "If fitting the range(s) is part of the job of this function, the results may well depend on the starting values, given in argument model." (for fit.variogram function). My question is how to choose starting values. I did take a few data to check variograms, and found they had different "range" values. I am not sure what starting values I should choose, say a small "range" value or a large "range" value. 

Best regards,
Kai




__________________________________________________
???????????????


From Adrian.Baddeley at csiro.au  Mon May 10 09:09:50 2010
From: Adrian.Baddeley at csiro.au (Adrian.Baddeley at csiro.au)
Date: Mon, 10 May 2010 15:09:50 +0800
Subject: [R-sig-Geo] memory allocation problem with envelope function in
 spatstat
Message-ID: <57DC18C299094D4299F837570C5DF1C52B1201DB63@EXWA-MBX01.nexus.csiro.au>

Erika Mudrak <mudrak at wisc.edu> writes:

! Hi everyone-  I am trying to fit an inhomogenous K function based to 
! a large(ish) dataset.  I have successfully executed this code on data sets 
! with a smaller n. 

! > SPECIES.ppp
! planar point pattern: 1598 points 
! window: rectangle = [564320, 564320] x [228490, 228500] units 
! > lambda=density(SPECIES.ppp)
! > Lin=envelope(SPECIES.ppp,Linhom,nsim=5,simulate=expression(rpoispp(lambda)),
! + correction="border")
! Error: cannot allocate vector of size 244.5 Mb

Memory allocation problems in a point process simulation typically happen when the system is trying to generate a huge number of points.

In this simulation, the expected number of random points in each randomised pattern is equal to the integral of the pixel image 'lambda', which you can evaluate by
     summary(lambda)$integral 
and of course you can also plot(lambda) to see if there is anything strange happening.

Normally the code you have typed above should be OK. If X is a point pattern with 1600 points then the intensity estimate computed by lambda <- density(X) should have an integral approximately equal to 1600 except for edge effects. So the expected number of points in each simulation should be about 1600.

However, there could be a problem here with the shape of the window and/or the configuration of the data points. The printout above says the window is 

! window: rectangle = [564320, 564320] x [228490, 228500] units 

The width of the rectangle appears to be 0; but these coordinates have been rounded to the nearest multiple of 10. Please tell me the window width is not exactly zero!!! 
I would guess that you have a very thin window, with some points that are very close to the boundary. Because of edge effects and various numerical artifacts, this could result in an erroneously large intensity estimate. 

My advice is to make sure that the density estimate 'lambda' is reasonable. Try controlling the smoothing parameter 'sigma' and the pixel size 'eps' until the estimated intensity looks reasonable and the integral summary(lambda)$integral is tolerably close to 1600.

regards 
Adrian Baddeley 
CSIRO Mathematics, Informatics & Statistics
Leeuwin Centre, 65 Brockway Road, Floreat WA 6014, Australia
Tel: 08 9333 6177 | Fax: 08 9333 6121 | Mob: 0410 447 821


From edzer.pebesma at uni-muenster.de  Mon May 10 09:57:50 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 10 May 2010 09:57:50 +0200
Subject: [R-sig-Geo] GSTAT - can a spline be used in the drift?
In-Reply-To: <4B9E9CA1.3000402@zevross.com>
References: <4B9E9CA1.3000402@zevross.com>
Message-ID: <4BE7BC7E.7030505@uni-muenster.de>

Dear Zev, thanks for reminding me about his (off-line).

I looked into this issue, and found that predict.ns (the predict method
that comes with ns usage in predict mode) simply calls ns, and so
re-computes the whole spline with predict data ranges. As the spline
fitted depends on the data that is fed to it, the solution depends on
the data fed to the predict statement, and I believe that's what you noted.

The difference in the solutions seems to be a consequence of the
placement of the knots. The knots are placed along quantiles of the x
values (dist), so if the range differs from one call to the other, the
solution will change.

I'm not sure how bad all this is. The variogram fitted uses a different
x range than the predict step, so the residuals are not identical. Also,
it's a bit muddly, as you're combining two basically different sets of
splines, one based on data, one on prediction values. As long as
quantiles for both sets are identical, results should be identical. Once
their quantiles start being very differently, the differences will increase.

The solution I could find is to fix the knots in calls to ns, e.g. by
the example below.

Hth, with best regards,
--
Edzer

library(splines)
data(meuse)
data(meuse.grid)

coordinates(meuse) = ~x + y
coordinates(meuse.grid) = ~x + y

lznr.vgm = variogram(log(zinc) ~ ns(dist,3), meuse)
lznr.fit = fit.variogram(lznr.vgm, model = vgm(1, "Exp", 300,+ 1))
plot(lznr.vgm, lznr.fit)
Bk = range(meuse.grid$dist)
k = quantile(meuse.grid$dist, 0.5)
preds<-krige(log(zinc) ~ ns(dist,Boundary.knots=Bk,knots=k), meuse,
meuse.grid, lznr.fit)
preds["var1.pred"][1:5,] # these predictions will be different from
those below

data(meuse.grid)
meuse.grid<-meuse.grid[1:5,]
coordinates(meuse.grid) = ~x + y
preds<-krige(log(zinc) ~ ns(dist,Boundary.knots=Bk,knots=k), meuse,
meuse.grid, lznr.fit)
preds["var1.pred"][1:5,] # these predictions are different from those above



On 03/15/2010 09:46 PM, Zev Ross wrote:
> Hi All,
> 
> Sorry for the re-post, I didn't get an answer the first time around and
> thought I'd give it another try. I am noticing in GSTAT that if I
> include a spline as part of the drift in an external drift kriging model
> that the prediction, oddly, depends on how many observations I have in
> the "newdata" argument.
> 
> Using the meuse data as an example, you'll see that the predictions at
> the same first 5 records will be different if I include just those five
> records (second example below) or a larger dataset that includes those
> five records.
> 
> Perhaps using a spline in the drift is not supported and I should use a
> polynomial? Can anyone explain?
> 
> Zev
> 
> 
> library(splines)
> data(meuse)
> data(meuse.grid)
> 
> coordinates(meuse) = ~x + y
> coordinates(meuse.grid) = ~x + y
> 
> lznr.vgm = variogram(log(zinc) ~ ns(dist,3), meuse)
> lznr.fit = fit.variogram(lznr.vgm, model = vgm(1, "Exp", 300,+ 1))
> plot(lznr.vgm, lznr.fit)
> preds<-krige(log(zinc) ~ ns(dist,3), meuse, meuse.grid, lznr.fit)
> preds[["var1.pred"]][1:5] # these predictions will be different from
> those below
> 
> data(meuse.grid)
> meuse.grid<-meuse.grid[1:5,]
> coordinates(meuse.grid) = ~x + y
> preds<-krige(log(zinc) ~ ns(dist,3), meuse, meuse.grid, lznr.fit)
> preds[["var1.pred"]][1:5] # these predictions are different from those
> above
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From edzer.pebesma at uni-muenster.de  Mon May 10 12:21:12 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 10 May 2010 12:21:12 +0200
Subject: [R-sig-Geo] Parameters in fitting variogram automatically in
 gstat
In-Reply-To: <201005092352007033108@yahoo.com.cn>
References: <201005092352007033108@yahoo.com.cn>
Message-ID: <4BE7DE18.6000708@uni-muenster.de>

Dear Kai,

you might want to look at function autofitVariogram in R package
automap, which exactly tries to do this. It uses reasonable default
(starting) values, but as any algorithm, it may not work well with
particular input data that is extreme in some sense.
--
Edzer

On 05/10/2010 06:52 AM, Kai Zhang wrote:
> Hi folks,
> 
> I am working on a problem dealing with fitting variogram automatically due to a large dateset. Gstat R package is used to conduct this work. Part of this work is to compare performance of different kriging methods. The comparison criteria is RMSE. I am using fit.variogram function for ordinary kriging, and fit.lmc for co-kriging. I have to specify a theoretical variogram at first. The problem is that results are sensitive to initial values specified in theoretical variograms, mainly "Range". Gstat manual points out "If fitting the range(s) is part of the job of this function, the results may well depend on the starting values, given in argument model." (for fit.variogram function). My question is how to choose starting values. I did take a few data to check variograms, and found they had different "range" values. I am not sure what starting values I should choose, say a small "range" value or a large "range" value. 
> 
> Best regards,
> Kai
> 
> 
> 
> 
> __________________________________________________
> ???????????????
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From p.hiemstra at geo.uu.nl  Mon May 10 21:26:18 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 10 May 2010 21:26:18 +0200
Subject: [R-sig-Geo] Parameters in fitting variogram automatically in
 gstat
In-Reply-To: <201005092352007033108@yahoo.com.cn>
References: <201005092352007033108@yahoo.com.cn>
Message-ID: <4BE85DDA.1030808@geo.uu.nl>

On 05/10/2010 06:52 AM, Kai Zhang wrote:
> Hi folks,
>
> I am working on a problem dealing with fitting variogram automatically due to a large dateset. Gstat R package is used to conduct this work. Part of this work is to compare performance of different kriging methods. The comparison criteria is RMSE. I am using fit.variogram function for ordinary kriging, and fit.lmc for co-kriging. I have to specify a theoretical variogram at first. The problem is that results are sensitive to initial values specified in theoretical variograms, mainly "Range". Gstat manual points out "If fitting the range(s) is part of the job of this function, the results may well depend on the starting values, given in argument model." (for fit.variogram function). My question is how to choose starting values. I did take a few data to check variograms, and found they had different "range" values. I am not sure what starting values I should choose, say a small "range" value or a large "range" value. 
>
> Best regards,
> Kai
>
>
>
>
> __________________________________________________
> ???????????????
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   
Hi Kai,

In addition to Edzers answer, just install automap and run demo(automap)
to see what the package can do.

cheers,
Paul


From eick at vistracks.com  Tue May 11 00:54:19 2010
From: eick at vistracks.com (Stephen G. Eick)
Date: Mon, 10 May 2010 17:54:19 -0500
Subject: [R-sig-Geo] (no subject)
Message-ID: <00b501caf093$bbde0970$339a1c50$@uic.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100510/e303f70a/attachment.pl>

From alobolistas at gmail.com  Tue May 11 09:15:35 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 11 May 2010 00:15:35 -0700 (PDT)
Subject: [R-sig-Geo] readOGR(): stringsAsFactors
Message-ID: <1273562135300-5034706.post@n2.nabble.com>


Hi!

Could it be possible having the option stringsAsFactors=F
available in readOGR() as it is in read.table() ?

Thanks

Agus
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/readOGR-stringsAsFactors-tp5034706p5034706.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Tue May 11 11:40:36 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 11 May 2010 11:40:36 +0200 (CEST)
Subject: [R-sig-Geo] readOGR(): stringsAsFactors
In-Reply-To: <1273562135300-5034706.post@n2.nabble.com>
References: <1273562135300-5034706.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.00.1005111139480.11770@reclus.nhh.no>

On Tue, 11 May 2010, Agustin Lobo wrote:

>
> Hi!
>
> Could it be possible having the option stringsAsFactors=F
> available in readOGR() as it is in read.table() ?

Change committed to sourceforge rgdal project - could you please check and 
confirm that it does what you want?

Roger

>
> Thanks
>
> Agus
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Tue May 11 11:53:21 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 11 May 2010 11:53:21 +0200 (CEST)
Subject: [R-sig-Geo] (no subject)
In-Reply-To: <00b501caf093$bbde0970$339a1c50$@uic.edu>
References: <00b501caf093$bbde0970$339a1c50$@uic.edu>
Message-ID: <alpine.LRH.2.00.1005111150010.11770@reclus.nhh.no>

On Mon, 10 May 2010, Stephen G. Eick wrote:

> Are there any easy function to parse WKT and convert it into a sp object?
> E.g.  to parse
>

Not yet, not in OGR in rgdal anyway. There is a draft pair of MULTIPOLYGON 
<-> SpatialPolygons functions in rgeos on R-forge - maybe add a wish 
there, or consider contributing? GEOS has WKT input-output functions.

Roger

>
>
> "MULTILINESTRING((-88.06354 41.80337,-88.06415 41.80297,-88.06447
> 41.80288,-88.06566 41.80275,-88.06586 41.80277,-88.06596 41.80284,-88.06598
> 41.8029,-88.06592 41.80433,-88.06592 41.80449,-88.06598 41.8047,-88.06599
> 41.80619,-88.06598 41.80623,-88.06594 41.80628,-88.06588 41.80628,-88.06523
> 41.80602,-88.0646 41.8058))"
>
>
>
> Or
>
>
>
> "POINT(-88.06594 41.80628)"
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From b.rowlingson at lancaster.ac.uk  Tue May 11 12:35:37 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 11 May 2010 11:35:37 +0100
Subject: [R-sig-Geo] (no subject)
In-Reply-To: <alpine.LRH.2.00.1005111150010.11770@reclus.nhh.no>
References: <00b501caf093$bbde0970$339a1c50$@uic.edu>
	<alpine.LRH.2.00.1005111150010.11770@reclus.nhh.no>
Message-ID: <AANLkTimu81PQXRg-cmP_nqZaZs0eahMPas0sQ9-_NLZC@mail.gmail.com>

On Tue, May 11, 2010 at 10:53 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Mon, 10 May 2010, Stephen G. Eick wrote:
>
>> Are there any easy function to parse WKT and convert it into a sp object?
>> E.g. ?to parse
>>
>
> Not yet, not in OGR in rgdal anyway. There is a draft pair of MULTIPOLYGON
> <-> SpatialPolygons functions in rgeos on R-forge - maybe add a wish there,
> or consider contributing? GEOS has WKT input-output functions.

 If you are desperate to parse some WKT then there's a couple of
solutions for python: the ogr and shapely libraries.

 With ogr:

>>> f = ogr.CreateGeometryFromWkt("POINT(-88.06594 41.80628)")

then you can do:

>>> f.ExportToGML()
'<gml:Point><gml:coordinates>-88.065939999999998,41.80628</gml:coordinates></gml:Point>'

 and you could collect up all the GML into a .gml file and read into R....

 With shapely:

>>> from shapely import wkt
>>> s
'MULTILINESTRING ((-72.0000000000000000 45.0000000000000000,
-72.5000000000000000 47.7000000000000028, -73.0000000000000000
48.2000000000000028), (-82.0000000000000000 47.0000000000000000,
-82.5000000000000000 55.1000000000000014))'
>>> f = wkt.loads(s)

 then get the coords thusly:

>>> [[p for p in g.coords] for g in f.geoms]
[[(-72.0, 45.0), (-72.5, 47.700000000000003), (-73.0,
48.200000000000003)], [(-82.0, 47.0), (-82.5, 55.100000000000001)]]

 and do what you want with them.

 The shapely package is looking very nice these days:

http://trac.gispython.org/lab/wiki/Examples

Barry


From Roger.Bivand at nhh.no  Tue May 11 13:16:36 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 11 May 2010 13:16:36 +0200 (CEST)
Subject: [R-sig-Geo] How to delete a single polygon in a shape file
In-Reply-To: <n2kdf06e3df1005071136z2716aec0mef41e5c49719adbb@mail.gmail.com>
References: <n2kdf06e3df1005071136z2716aec0mef41e5c49719adbb@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1005111312340.11770@reclus.nhh.no>

On Fri, 7 May 2010, Everton Emanuel wrote:

> Dear all,
>
> I have a small problem, and hope to get some help from you guys.
>
> I have a shape file of Brazilian micro regions; in order to estimate spatial
> correlation I need to construct a weight scheme of this shape. However, the
> shape contains "islands" that unables its construction. I want to know how
> is it possible to manipulate the original shape and erase these islands?

I'm not sure what you mean. If you want to subset a 
SpatialPolygonsDataFrame, use the "[" method:

sub <- <logical vector of same length as dim(a)[1]>
asub <- a[sub, ]

If you really want to drop the subset in order to generate spatial 
weights, you could do it in this way. However, you could use a graph-based 
method that would retain off-shore islands if they are substantive 
records. I don't think that you are obliged to drop islands in order to 
construct weights.

Hope this helps,

Roger

>
> I appreciate any help,
>
> Everton.
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From alobolistas at gmail.com  Tue May 11 13:19:37 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 11 May 2010 04:19:37 -0700 (PDT)
Subject: [R-sig-Geo] readOGR(): stringsAsFactors
In-Reply-To: <alpine.LRH.2.00.1005111139480.11770@reclus.nhh.no>
References: <1273562135300-5034706.post@n2.nabble.com>
	<alpine.LRH.2.00.1005111139480.11770@reclus.nhh.no>
Message-ID: <1273576777675-5035470.post@n2.nabble.com>


Roger,

I've tried but:
> install.packages("rgdal",repos="http://R-Forge.R-project.org")
Warning in install.packages("rgdal", repos = "http://R-Forge.R-project.org")
:
  argument 'lib' is missing: using '/usr/local/lib/R/site-library'
Warning message:
In getDependencies(pkgs, dependencies, available, lib) :
  package ?rgdal? is not available

am I not using the right repo?

Agus
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/readOGR-stringsAsFactors-tp5034706p5035470.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Tue May 11 13:21:20 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 11 May 2010 13:21:20 +0200 (CEST)
Subject: [R-sig-Geo] Querying Spatial Data Using rgdal
In-Reply-To: <w2o49b12cd41005081530s2d6c45f8oc6a61dec3ffa2426@mail.gmail.com>
References: <s2z90a726dc1005071435ifb97b2cdm5e8d580fd4b9f3f1@mail.gmail.com>
	<w2o49b12cd41005081530s2d6c45f8oc6a61dec3ffa2426@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1005111317120.11770@reclus.nhh.no>

On Sat, 8 May 2010, Brooks Kehler wrote:

> Have a look at:
>
> http://www.joeconway.com/plr/
>
> http://www.bostongis.com/PrinterFriendly.aspx?content_name=postgresql_plr_tut01
>

That only gets you so far. Could Tim please try ogr2ogr with the -sql or 
-where or -spat arguments set to see whether these go in the correct 
direction, that is returning geometries meeting the given selection 
conditions? I have looked briefly at how hard it would be to add this 
functionality to readOGR(), but without a substantial re-write, it will 
not be easy. If there are other users who would value such an addition to 
readOGR, please indicate!

Roger

>
>
> On Fri, May 7, 2010 at 5:35 PM, Tim Romel <tim.romel at vistracks.com> wrote:
>
>> I have the need to bring spatial data into R from a postgres database.  I
>> am
>> trying to do this right now using rgdal with a command similar to the
>> following:
>>
>> results=readOGR("PG:dbname='dbname' host='hostname' port='portnum'
>> user='username' password='pass' <password='P at ssw0rd'>, layer="tablename")
>>
>> This works in bringing back all data from the entire table.  However, this
>> is a very large table and I was wondering if there was a way to run a query
>> against the table instead of bringing back all data using readOGR.  I have
>> found no examples anywhere and have even seen suggestions that it is not
>> possible.  Is this the case?  If there are other libraries that support R's
>> SP library that allow access to postgres that would be great to know too.
>>
>> Any help is much appreaciated.
>>
>> Thanks.
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Tue May 11 14:45:40 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 11 May 2010 14:45:40 +0200 (CEST)
Subject: [R-sig-Geo] readOGR(): stringsAsFactors
In-Reply-To: <1273576777675-5035470.post@n2.nabble.com>
References: <1273562135300-5034706.post@n2.nabble.com>
	<alpine.LRH.2.00.1005111139480.11770@reclus.nhh.no>
	<1273576777675-5035470.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.00.1005111443210.12555@reclus.nhh.no>

On Tue, 11 May 2010, Agustin Lobo wrote:

>
> Roger,
>
> I've tried but:
>> install.packages("rgdal",repos="http://R-Forge.R-project.org")
> Warning in install.packages("rgdal", repos = "http://R-Forge.R-project.org")
> :
>  argument 'lib' is missing: using '/usr/local/lib/R/site-library'

Wrong, I'm afraid. You need to check out or update the source package from 
CVS on *sourceforge*, not a package install from R-Forge. We've considered 
moving to R-Forge, but unless the binary dependencies can be installed 
there, the gains would be minimal.

Roger

> Warning message:
> In getDependencies(pkgs, dependencies, available, lib) :
>  package ?rgdal? is not available
>
> am I not using the right repo?
>
> Agus
> -- 
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/readOGR-stringsAsFactors-tp5034706p5035470.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From manuel.schneider at art.admin.ch  Tue May 11 18:35:18 2010
From: manuel.schneider at art.admin.ch (manuel.schneider at art.admin.ch)
Date: Tue, 11 May 2010 18:35:18 +0200
Subject: [R-sig-Geo] RSAGA Vectorizing Grid Classes creates unclosed rings
Message-ID: <F16DA63221030F44A4E2E81645E9B5170361C434@EVD-C8001.bk.evdad.admin.ch>

Dear list

I am trying to use SAGA function Vectorizing grid classes from R but
this creates an unclosed ring in the resulting shapefile. All steps work
in SAGA GUI. Maybe somebody can reproduce the error and help on it.
Otherwise, is there a direct way (in the sp framework) to convert grid
classes into polygons?

> d <- SpatialGridDataFrame(GridTopology(c(0,0), c(1,1), c(5,6)),
data=data.frame(x=sample(rep(c(NA,1,2),10),30)))
> write.asciigrid(d, "test.asc" , na.value=-9999)
> rsaga.esri.to.sgrd(in.grids="test.asc", out.sgrd="classes.sgrd")

SAGA CMD 2.0.3
library path:   C:/ManuProgs/R/R-2.10.1/library/RSAGA/saga_vc/modules
library name:   io_grid
module name :   Import ESRI Arc/Info Grid
author      :   (c) 2007 by O.Conrad
Parameters
Grid: [not set]
File: test.asc
ready
Save grid: classes.sgrd...
ready

> rsaga.geoprocessor(lib="shapes_grid", module=6,
param=list(GRID="classes.sgrd", SHAPES="classes.shp", CLASS_ALL=1))

SAGA CMD 2.0.3
library path:   C:/ManuProgs/R/R-2.10.1/library/RSAGA/saga_vc/modules
library name:   shapes_grid
module name :   Vectorising Grid Classes
author      :   (c) 2008 by O.Conrad
Load grid: classes.sgrd...
ready
Parameters
Grid system: 1; 5x 6y; 0x 0y
Grid: classes.sgrd
Shapes: Shapes
Class Selection: all classes
Class Identifier: 1.000000
Vectorised class as...: each island as separated polygon

vectorising class 1: 1.000000
vectorising class 2: 2.000000
Save shapes: classes.shp...
Save shapes: classes.shp
ready
Save table: classes.dbf...
ready

> classes <- readOGR("classes.shp","classes")
OGR data source with driver: ESRI Shapefile 
Source: "classes.shp", layer: "classes"
with 8 features and 3 fields
Feature type: wkbPolygon with 2 dimensions
Error in is.vector(X) : ring not closed

Thanks in advance
Manuel


From ted.rosenbaum at yale.edu  Tue May 11 19:05:00 2010
From: ted.rosenbaum at yale.edu (Ted Rosenbaum)
Date: Tue, 11 May 2010 13:05:00 -0400
Subject: [R-sig-Geo] point process panel regression?
In-Reply-To: <57DC18C299094D4299F837570C5DF1C52B1201DB4C@EXWA-MBX01.nexus.csiro.au>
References: <AcroGa7c0RYxND38Rpe/5mOIFxDN6g==>
	<57DC18C299094D4299F837570C5DF1C52B1201DB4C@EXWA-MBX01.nexus.csiro.au>
Message-ID: <AANLkTikz6tlJdPPeCjRqhaCGXSL8vL0GTMmjnih9dtR1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100511/e4fd65da/attachment.pl>

From Roger.Bivand at nhh.no  Tue May 11 19:21:51 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 11 May 2010 19:21:51 +0200 (CEST)
Subject: [R-sig-Geo] RSAGA Vectorizing Grid Classes creates unclosed
 rings
In-Reply-To: <F16DA63221030F44A4E2E81645E9B5170361C434@EVD-C8001.bk.evdad.admin.ch>
References: <F16DA63221030F44A4E2E81645E9B5170361C434@EVD-C8001.bk.evdad.admin.ch>
Message-ID: <alpine.LRH.2.00.1005111919580.12555@reclus.nhh.no>

On Tue, 11 May 2010, manuel.schneider at art.admin.ch wrote:

> Dear list
>
> I am trying to use SAGA function Vectorizing grid classes from R but
> this creates an unclosed ring in the resulting shapefile. All steps work
> in SAGA GUI. Maybe somebody can reproduce the error and help on it.
> Otherwise, is there a direct way (in the sp framework) to convert grid
> classes into polygons?
>
>> d <- SpatialGridDataFrame(GridTopology(c(0,0), c(1,1), c(5,6)),
> data=data.frame(x=sample(rep(c(NA,1,2),10),30)))
>> write.asciigrid(d, "test.asc" , na.value=-9999)
>> rsaga.esri.to.sgrd(in.grids="test.asc", out.sgrd="classes.sgrd")
>
> SAGA CMD 2.0.3
> library path:   C:/ManuProgs/R/R-2.10.1/library/RSAGA/saga_vc/modules
> library name:   io_grid
> module name :   Import ESRI Arc/Info Grid
> author      :   (c) 2007 by O.Conrad
> Parameters
> Grid: [not set]
> File: test.asc
> ready
> Save grid: classes.sgrd...
> ready
>
>> rsaga.geoprocessor(lib="shapes_grid", module=6,
> param=list(GRID="classes.sgrd", SHAPES="classes.shp", CLASS_ALL=1))
>
> SAGA CMD 2.0.3
> library path:   C:/ManuProgs/R/R-2.10.1/library/RSAGA/saga_vc/modules
> library name:   shapes_grid
> module name :   Vectorising Grid Classes
> author      :   (c) 2008 by O.Conrad
> Load grid: classes.sgrd...
> ready
> Parameters
> Grid system: 1; 5x 6y; 0x 0y
> Grid: classes.sgrd
> Shapes: Shapes
> Class Selection: all classes
> Class Identifier: 1.000000
> Vectorised class as...: each island as separated polygon
>
> vectorising class 1: 1.000000
> vectorising class 2: 2.000000
> Save shapes: classes.shp...
> Save shapes: classes.shp
> ready
> Save table: classes.dbf...
> ready
>
>> classes <- readOGR("classes.shp","classes")
> OGR data source with driver: ESRI Shapefile
> Source: "classes.shp", layer: "classes"
> with 8 features and 3 fields
> Feature type: wkbPolygon with 2 dimensions
> Error in is.vector(X) : ring not closed

http://shapelib.maptools.org/dl/shapefile.pdf

does specify that a polygon in a shapefile must be closed. You may be able 
to use readShapePoly(..., force_ring=TRUE) in maptools to work around the 
problem.

Roger

>
> Thanks in advance
> Manuel
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From manuel.schneider at art.admin.ch  Tue May 11 20:02:14 2010
From: manuel.schneider at art.admin.ch (manuel.schneider)
Date: Tue, 11 May 2010 18:02:14 +0000 (UTC)
Subject: [R-sig-Geo] RSAGA Vectorizing Grid Classes creates unclosed
	rings
References: <F16DA63221030F44A4E2E81645E9B5170361C434@EVD-C8001.bk.evdad.admin.ch>
	<alpine.LRH.2.00.1005111919580.12555@reclus.nhh.no>
Message-ID: <loom.20100511T195649-38@post.gmane.org>

Roger Bivand <Roger.Bivand <at> nhh.no> writes:

> 
> On Tue, 11 May 2010, manuel.schneider <at> art.admin.ch wrote:
> 
...
> > Error in is.vector(X) : ring not closed
> 
> http://shapelib.maptools.org/dl/shapefile.pdf
> 
> does specify that a polygon in a shapefile must be closed. You may be able 
> to use readShapePoly(..., force_ring=TRUE) in maptools to work around the 
> problem.
> 
> Roger
> 
> 

As always, your suggestion does the trick. Thanks a lot.
However, still puzzled why it occurs.


From nitmithv at yahoo.com.cn  Tue May 11 20:12:52 2010
From: nitmithv at yahoo.com.cn (Kai Zhang)
Date: Tue, 11 May 2010 14:12:52 -0400
Subject: [R-sig-Geo] Co-Kriging using two variables versus one variable
Message-ID: <201005111412522183770@yahoo.com.cn>

Hi folks,

I am working on an exercise which compares the performance of different Kriging methods including ordinary Kriging, Co-Kriging and Universal Kriging. Regarding Co-Kriging, I am trying to conduct Co-Kriging using two secondary variables separately. RMSEs from these two Co-Kriging are smaller than those from Ordinary Kriging. I am also conducting Co-Kriging using both secondary variables. However, RMSEs are larger than those from Co-Kriging with either secondary variable separately. I am wondering if these results do make sense since I expect that RMSEs from Co-Kriging using both variables are smaller. Any comments are welcome.

Thanks,
Kai 



__________________________________________________
???????????????


From pslarson2 at gmail.com  Tue May 11 22:10:00 2010
From: pslarson2 at gmail.com (Peter Larson)
Date: Tue, 11 May 2010 16:10:00 -0400
Subject: [R-sig-Geo] Neighbor matrix from shp file
In-Reply-To: <201005111412522183770@yahoo.com.cn>
References: <201005111412522183770@yahoo.com.cn>
Message-ID: <4BE9B998.1090809@gmail.com>

Hello,

I have a shp file of polygons of US counties and want to generate an
adjacency matrix (neighbor matrix).

Is there an easy way to do this? It seems like it should be trivial.

Thanks,

Pete


From b.rowlingson at lancaster.ac.uk  Tue May 11 22:24:17 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 11 May 2010 21:24:17 +0100
Subject: [R-sig-Geo] Neighbor matrix from shp file
In-Reply-To: <4BE9B998.1090809@gmail.com>
References: <201005111412522183770@yahoo.com.cn> <4BE9B998.1090809@gmail.com>
Message-ID: <AANLkTinLDuPCgZOSDBfOI3_RudaHrR676OEJqmwn6vGR@mail.gmail.com>

On Tue, May 11, 2010 at 9:10 PM, Peter Larson <pslarson2 at gmail.com> wrote:
> Hello,
>
> I have a shp file of polygons of US counties and want to generate an
> adjacency matrix (neighbor matrix).
>
> Is there an easy way to do this? It seems like it should be trivial.

poly2nb in the spdep package will produce a list of adjacencies, and
from that you can make a full adjacency matrix if you want, but it
will probably be very sparse.

 However... polygons that look adjacent might be very very close and
not found as adjacent by poly2nb. I'm investigating this with some of
my data at the moment...

 Barry


From Roger.Bivand at nhh.no  Tue May 11 22:40:32 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 11 May 2010 22:40:32 +0200 (CEST)
Subject: [R-sig-Geo] Neighbor matrix from shp file
In-Reply-To: <AANLkTinLDuPCgZOSDBfOI3_RudaHrR676OEJqmwn6vGR@mail.gmail.com>
References: <201005111412522183770@yahoo.com.cn> <4BE9B998.1090809@gmail.com>
	<AANLkTinLDuPCgZOSDBfOI3_RudaHrR676OEJqmwn6vGR@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1005112237001.16602@reclus.nhh.no>

On Tue, 11 May 2010, Barry Rowlingson wrote:

> On Tue, May 11, 2010 at 9:10 PM, Peter Larson <pslarson2 at gmail.com> wrote:
>> Hello,
>>
>> I have a shp file of polygons of US counties and want to generate an
>> adjacency matrix (neighbor matrix).
>>
>> Is there an easy way to do this? It seems like it should be trivial.
>
> poly2nb in the spdep package will produce a list of adjacencies, and
> from that you can make a full adjacency matrix if you want, but it
> will probably be very sparse.
>
> However... polygons that look adjacent might be very very close and
> not found as adjacent by poly2nb. I'm investigating this with some of
> my data at the moment...

Use the snap= argument to poly2nb() set to a larger but still small value 
than default in that case, say 10m for projected coordinates.

Barry, if you'd like to try SVN spdep from R-forge (and maybe also SVN 
rgeos from R-forge), you'll find a number of speedups. Any feedback on 
those would be very welcome.

Roger

>
> Barry
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From alobolistas at gmail.com  Wed May 12 08:27:03 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 11 May 2010 23:27:03 -0700 (PDT)
Subject: [R-sig-Geo] readOGR(): stringsAsFactors
In-Reply-To: <alpine.LRH.2.00.1005111443210.12555@reclus.nhh.no>
References: <1273562135300-5034706.post@n2.nabble.com>
	<alpine.LRH.2.00.1005111139480.11770@reclus.nhh.no>
	<1273576777675-5035470.post@n2.nabble.com>
	<alpine.LRH.2.00.1005111443210.12555@reclus.nhh.no>
Message-ID: <1273645623545-5039744.post@n2.nabble.com>


Roger, 
I've done:
root at alobo-laptop:/home/alobo# cvs -z3
-d:pserver:anonymous at r-spatial.cvs.sourceforge.net:/cvsroot/r-spatial co -P
spGDAL
cvs checkout: Updating spGDAL
cvs checkout: Updating spGDAL/R
cvs checkout: Updating spGDAL/man

but then
root at alobo-laptop:/home/alobo# R CMD check rgdal
* checking for working pdflatex ... OK
* using log directory '/home/alobo/rgdal.Rcheck'
* using R version 2.11.0 (2010-04-22)
* using session charset: UTF-8
* checking for file 'rgdal/DESCRIPTION' ... OK
* this is package 'rgdal' version '0.6-20'
* checking package name space information ... OK
* checking package dependencies ... OK
* checking if this is a source package ... WARNING
Subdirectory 'rgdal/src' contains object files.
* checking for executable files ... OK
* checking whether package 'rgdal' can be installed ... ERROR
Installation failed.
See '/home/alobo/rgdal.Rcheck/00install.out' for details.

The end of 00install.out is:
make: Nothing to be done for `all'.
installing to /home/alobo/rgdal.Rcheck/rgdal/libs
** R
** inst
** preparing package for lazy loading
Error in matchSignature(signature, fdef) : 
  more elements in the method signature (2) than in the generic  signature
(1)
Error : unable to load R code in package 'rgdal'
ERROR: lazy loading failed for package ?rgdal?
* removing ?/home/alobo/rgdal.Rcheck/rgdal?

Am I doing something wrong or is the package missing some component?

BTW, is rgdal becoming spGDAL ? 

Agus



-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/readOGR-stringsAsFactors-tp5034706p5039744.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From edzer.pebesma at uni-muenster.de  Wed May 12 08:44:42 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 12 May 2010 08:44:42 +0200
Subject: [R-sig-Geo] readOGR(): stringsAsFactors
In-Reply-To: <1273645623545-5039744.post@n2.nabble.com>
References: <1273562135300-5034706.post@n2.nabble.com>	<alpine.LRH.2.00.1005111139480.11770@reclus.nhh.no>	<1273576777675-5035470.post@n2.nabble.com>	<alpine.LRH.2.00.1005111443210.12555@reclus.nhh.no>
	<1273645623545-5039744.post@n2.nabble.com>
Message-ID: <4BEA4E5A.7090507@uni-muenster.de>

No, rgdal is a different (and I believe older) sourceforge project,
found under:

http://rgdal.cvs.sourceforge.net/

--
Edzer

On 05/12/2010 08:27 AM, Agustin Lobo wrote:
> 
> Roger, 
> I've done:
> root at alobo-laptop:/home/alobo# cvs -z3
> -d:pserver:anonymous at r-spatial.cvs.sourceforge.net:/cvsroot/r-spatial co -P
> spGDAL
> cvs checkout: Updating spGDAL
> cvs checkout: Updating spGDAL/R
> cvs checkout: Updating spGDAL/man
> 
> but then
> root at alobo-laptop:/home/alobo# R CMD check rgdal
> * checking for working pdflatex ... OK
> * using log directory '/home/alobo/rgdal.Rcheck'
> * using R version 2.11.0 (2010-04-22)
> * using session charset: UTF-8
> * checking for file 'rgdal/DESCRIPTION' ... OK
> * this is package 'rgdal' version '0.6-20'
> * checking package name space information ... OK
> * checking package dependencies ... OK
> * checking if this is a source package ... WARNING
> Subdirectory 'rgdal/src' contains object files.
> * checking for executable files ... OK
> * checking whether package 'rgdal' can be installed ... ERROR
> Installation failed.
> See '/home/alobo/rgdal.Rcheck/00install.out' for details.
> 
> The end of 00install.out is:
> make: Nothing to be done for `all'.
> installing to /home/alobo/rgdal.Rcheck/rgdal/libs
> ** R
> ** inst
> ** preparing package for lazy loading
> Error in matchSignature(signature, fdef) : 
>   more elements in the method signature (2) than in the generic  signature
> (1)
> Error : unable to load R code in package 'rgdal'
> ERROR: lazy loading failed for package ?rgdal?
> * removing ?/home/alobo/rgdal.Rcheck/rgdal?
> 
> Am I doing something wrong or is the package missing some component?
> 
> BTW, is rgdal becoming spGDAL ? 
> 
> Agus
> 
> 
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From Roger.Bivand at nhh.no  Wed May 12 09:33:54 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 12 May 2010 09:33:54 +0200 (CEST)
Subject: [R-sig-Geo] readOGR(): stringsAsFactors
In-Reply-To: <1273645623545-5039744.post@n2.nabble.com>
References: <1273562135300-5034706.post@n2.nabble.com>
	<alpine.LRH.2.00.1005111139480.11770@reclus.nhh.no>
	<1273576777675-5035470.post@n2.nabble.com>
	<alpine.LRH.2.00.1005111443210.12555@reclus.nhh.no>
	<1273645623545-5039744.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.00.1005120929250.19319@reclus.nhh.no>

On Tue, 11 May 2010, Agustin Lobo wrote:

>
> Roger, 
> I've done:
> root at alobo-laptop:/home/alobo# cvs -z3
> -d:pserver:anonymous at r-spatial.cvs.sourceforge.net:/cvsroot/r-spatial co -P
> spGDAL

NO!

rgdal is rgdal project, rgdal module, just search for rgdal on opening sf:

-d:pserver:anonymous at rgdal.cvs.sourceforge.net:/cvsroot/rgdal co -P rgdal

Roger

PS. CVS anywhere is great as an archive, but it is very difficult to 
delete things. As you saw, the r-spatial project on sourceforge has very 
many deprecated modules, which are of historical interest only.


> cvs checkout: Updating spGDAL
> cvs checkout: Updating spGDAL/R
> cvs checkout: Updating spGDAL/man
>
> but then
> root at alobo-laptop:/home/alobo# R CMD check rgdal
> * checking for working pdflatex ... OK
> * using log directory '/home/alobo/rgdal.Rcheck'
> * using R version 2.11.0 (2010-04-22)
> * using session charset: UTF-8
> * checking for file 'rgdal/DESCRIPTION' ... OK
> * this is package 'rgdal' version '0.6-20'
> * checking package name space information ... OK
> * checking package dependencies ... OK
> * checking if this is a source package ... WARNING
> Subdirectory 'rgdal/src' contains object files.
> * checking for executable files ... OK
> * checking whether package 'rgdal' can be installed ... ERROR
> Installation failed.
> See '/home/alobo/rgdal.Rcheck/00install.out' for details.
>
> The end of 00install.out is:
> make: Nothing to be done for `all'.
> installing to /home/alobo/rgdal.Rcheck/rgdal/libs
> ** R
> ** inst
> ** preparing package for lazy loading
> Error in matchSignature(signature, fdef) :
>  more elements in the method signature (2) than in the generic  signature
> (1)
> Error : unable to load R code in package 'rgdal'
> ERROR: lazy loading failed for package ?rgdal?
> * removing ?/home/alobo/rgdal.Rcheck/rgdal?
>
> Am I doing something wrong or is the package missing some component?
>
> BTW, is rgdal becoming spGDAL ? 
>
> Agus
>
>
>
> -- 
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/readOGR-stringsAsFactors-tp5034706p5039744.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From alobolistas at gmail.com  Wed May 12 11:52:55 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Wed, 12 May 2010 02:52:55 -0700 (PDT)
Subject: [R-sig-Geo] readOGR(): stringsAsFactors
In-Reply-To: <alpine.LRH.2.00.1005120929250.19319@reclus.nhh.no>
References: <1273562135300-5034706.post@n2.nabble.com>
	<alpine.LRH.2.00.1005111139480.11770@reclus.nhh.no>
	<1273576777675-5035470.post@n2.nabble.com>
	<alpine.LRH.2.00.1005111443210.12555@reclus.nhh.no>
	<1273645623545-5039744.post@n2.nabble.com>
	<alpine.LRH.2.00.1005120929250.19319@reclus.nhh.no>
Message-ID: <1273657975486-5040366.post@n2.nabble.com>


ok,
After the correct installation of the new release with:
cvs -z3 -d:pserver:rgdal.cvs.sourceforge.net:/cvsroot/rgdal co -P rgdal
R CMD INSTALL rgdal 

I can confirm that the new argument works fine:
> require(rgdal)
Loading required package: rgdal
Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 1.6.3, released 2009/11/19
Path to GDAL shared files: /usr/share/gdal16
Loaded PROJ.4 runtime: Rel. 4.7.1, 23 September 2009
Path to PROJ.4 shared files: (autodetected)

> packageDescription("rgdal")
Package: rgdal
Title: Bindings for the Geospatial Data Abstraction Library
Version: 0.6-27
Date: 2010-05-11
.../...

> terNOXLC <-
> readOGR(dsn="/media/TRANSCEND/MASTER_ICTA2007_2008/miniproj_GISInP2009/MARICEL2",
> layer="terNOX0709buf2500values",stringsAsFactors=F)
OGR data source with driver: ESRI Shapefile 
Source:
"/media/TRANSCEND/MASTER_ICTA2007_2008/miniproj_GISInP2009/MARICEL2", layer:
"terNOX0709buf2500values"
with 4100 features and 12 fields
Feature type: wkbPoint with 2 dimensions

> class(terNOXLC at data[,1])
[1] "character"

> terNOXLC <-
> readOGR(dsn="/media/TRANSCEND/MASTER_ICTA2007_2008/miniproj_GISInP2009/MARICEL2",
> layer="terNOX0709buf2500values",stringsAsFactors=T)
OGR data source with driver: ESRI Shapefile 
Source:
"/media/TRANSCEND/MASTER_ICTA2007_2008/miniproj_GISInP2009/MARICEL2", layer:
"terNOX0709buf2500values"
with 4100 features and 12 fields
Feature type: wkbPoint with 2 dimensions

> class(terNOXLC at data[,1])
[1] "factor"

> terNOXLC <-
> readOGR(dsn="/media/TRANSCEND/MASTER_ICTA2007_2008/miniproj_GISInP2009/MARICEL2",
> layer="terNOX0709buf2500values")
OGR data source with driver: ESRI Shapefile 
Source:
"/media/TRANSCEND/MASTER_ICTA2007_2008/miniproj_GISInP2009/MARICEL2", layer:
"terNOX0709buf2500values"
with 4100 features and 12 fields
Feature type: wkbPoint with 2 dimensions

> class(terNOXLC at data[,1])
[1] "factor"


Many thanks! When do you think that this new improvement will make it into
CRAN?
Agus

-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/readOGR-stringsAsFactors-tp5034706p5040366.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From b.rowlingson at lancaster.ac.uk  Wed May 12 13:44:34 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 12 May 2010 12:44:34 +0100
Subject: [R-sig-Geo] Neighbor matrix from shp file
In-Reply-To: <alpine.LRH.2.00.1005112237001.16602@reclus.nhh.no>
References: <201005111412522183770@yahoo.com.cn> <4BE9B998.1090809@gmail.com>
	<AANLkTinLDuPCgZOSDBfOI3_RudaHrR676OEJqmwn6vGR@mail.gmail.com>
	<alpine.LRH.2.00.1005112237001.16602@reclus.nhh.no>
Message-ID: <AANLkTil7RbNnOoot5oqAmeiToFK9NXCBeZq3dvIMQWy1@mail.gmail.com>

On Tue, May 11, 2010 at 9:40 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Tue, 11 May 2010, Barry Rowlingson wrote:

> Use the snap= argument to poly2nb() set to a larger but still small value
> than default in that case, say 10m for projected coordinates.

 Ooh, yes, that's fixed it.

> Barry, if you'd like to try SVN spdep from R-forge (and maybe also SVN rgeos
> from R-forge), you'll find a number of speedups. Any feedback on those would
> be very welcome.

 Computing the adjacency for about 1500 polygons with 127,000
coordinate points takes about 11 seconds - I should only need to do
this once so I don't think I'll investigate speedups at the moment!

thanks!

Barry

-- 
blog: http://geospaced.blogspot.com/
web: http://www.maths.lancs.ac.uk/~rowlings
web: http://www.rowlingson.com/
twitter: http://twitter.com/geospacedman
pics: http://www.flickr.com/photos/spacedman


From tom.gottfried at wzw.tum.de  Wed May 12 14:06:02 2010
From: tom.gottfried at wzw.tum.de (Tom Gottfried)
Date: Wed, 12 May 2010 14:06:02 +0200
Subject: [R-sig-Geo] Querying Spatial Data Using rgdal
In-Reply-To: <alpine.LRH.2.00.1005111317120.11770@reclus.nhh.no>
References: <alpine.LRH.2.00.1005111317120.11770@reclus.nhh.no>
Message-ID: <4BEA99AA.5090200@wzw.tum.de>

Dear list and Roger,

currently I achieve such things via RODBC and then transforming the resulting data.frame to an
sp-object. But the possibility to do this directly via readOGR() would be greatly appreciated.

Tom
-- 
Technische Universit?t M?nchen
Department f?r Pflanzenwissenschaften
Lehrstuhl f?r Gr?nlandlehre
Am Hochanger 1
85350 Freising / Germany
Phone: ++49 (0)8161 715324
Fax:   ++49 (0)8161 713243
email: tom.gottfried at wzw.tum.de
http://www.wzw.tum.de/gruenland


From gentils at emse.fr  Wed May 12 16:23:31 2010
From: gentils at emse.fr (=?ISO-8859-1?Q?Aur=E9lien_Gentils?=)
Date: Wed, 12 May 2010 16:23:31 +0200
Subject: [R-sig-Geo] spsample out of bounding box
Message-ID: <4BEAB9E3.5080008@emse.fr>

Dear list,

I have tried using spsample with option "stratified", and it seems some
sampled points are outside of the bounding box. I got the same problem
with a few tries of "nonaligned" and "hexagonal" options as well.

Does someone reproduce this behaviour or am I doing something wrong?

Thanks

Aur?lien


From huangykiz at 163.com  Wed May 12 17:18:57 2010
From: huangykiz at 163.com (huangykiz)
Date: Wed, 12 May 2010 23:18:57 +0800 (CST)
Subject: [R-sig-Geo] How to get the Coefficient of Determination in the
 results of GWR
In-Reply-To: <alpine.LRH.2.00.1005120914260.19319@reclus.nhh.no>
References: <alpine.LRH.2.00.1005120914260.19319@reclus.nhh.no>
	<alpine.LRH.2.00.1005111834410.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111758330.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111632010.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111226160.11770@reclus.nhh.no>
	<7fbb8685.9c9e.12886ce7d95.Coremail.huangykiz@163.com>
	<35fc8b41.9509.128878f8dc7.Coremail.huangykiz@163.com>
	<5cd1a7.aaf7.12887db30ba.Coremail.huangykiz@163.com>
	<1721ac8.cd5c.1288828d49a.Coremail.huangykiz@163.com>
	<e41e5d3.ff74.1288a727c78.Coremail.huangykiz@163.com>
Message-ID: <e30f5db.13f83.1288d18e217.Coremail.huangykiz@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100512/9c4531cb/attachment.pl>

From Roger.Bivand at nhh.no  Wed May 12 17:29:00 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 12 May 2010 17:29:00 +0200 (CEST)
Subject: [R-sig-Geo] How to get the Coefficient of Determination in the
 results of GWR
In-Reply-To: <e30f5db.13f83.1288d18e217.Coremail.huangykiz@163.com>
References: <alpine.LRH.2.00.1005120914260.19319@reclus.nhh.no>
	<alpine.LRH.2.00.1005111834410.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111758330.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111632010.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111226160.11770@reclus.nhh.no>
	<7fbb8685.9c9e.12886ce7d95.Coremail.huangykiz@163.com>
	<35fc8b41.9509.128878f8dc7.Coremail.huangykiz@163.com>
	<5cd1a7.aaf7.12887db30ba.Coremail.huangykiz@163.com>
	<1721ac8.cd5c.1288828d49a.Coremail.huangykiz@163.com>
	<e41e5d3.ff74.1288a727c78.Coremail.huangykiz@163.com>
	<e30f5db.13f83.1288d18e217.Coremail.huangykiz@163.com>
Message-ID: <alpine.LRH.2.00.1005121726190.5691@reclus.nhh.no>

On Wed, 12 May 2010, huangykiz wrote:

> Hi, Is "adapt=TRUE"(spgwr) not the same as "adaptive Spatial 
> Kernel"(SAM)?The result of "adaptive Spatial Kernel" may be better than 
> fixed bandwidth. If I want to ues "adaptive Spatial Kernel" in spgwr, 
> how to write the code?

READ THE HELP PAGES!

adaptive_proportion <- gwr.sel(...)

result <- gwr(..., adapt=adaptive_proportion; ...)

exactly as on the example om the help page:

data(georgia)
g.adapt.gauss <- gwr.sel(PctBach ~ TotPop90 + PctRural + PctEld + PctFB +
   PctPov + PctBlack, data=gSRDF, adapt=TRUE)
res.adpt <- gwr(PctBach ~ TotPop90 + PctRural + PctEld + PctFB + PctPov +
   PctBlack, data=gSRDF, adapt=g.adapt.gauss)
res.adpt

Clear?

> 
> Thanks a lot.
> 
> Cheers.
> 
> 
>> Hi,
>> I think that I use the same bandwidth and kernel. In SAM, I use "spatial Weighting Function"=gaussian, adaptive Spatial Kernel, and compute Geographical Distances based on longitudinal coordinate(X) and latitudinal coordinate(Y). In spgwr, gweight is gwr.Gauss and adapt is TRUE.
>> 
>> For example, this is my code:
>
>> PET.bw <- gwr.sel(SPECIES_RI ~ PET, data=variables, 
>> coords=cbind(variables$LONGX, variables$LATY),adapt=TRUE)
>
>> PET.gauss <- gwr(SPECIES_RI ~ PET, data=variables, 
>> coords=cbind(variables$LONGX, variables$LATY), bandwidth=PET.bw, 
>> gweight=gwr.Gauss,adapt=TRUE,hatmatrix=TRUE)
>
> So where do you pass PET.bw to the gwr() function? adapt=TRUE will treat 
> the adaptive proportion as 1, so include all data points. If you want to 
> compare, use a fixed bandwidth in both, with no CV selection. Then you 
> compare like with like.
>
> Note that your messages are *not* reaching the list, they must be sent to:
>
> r-sig-geo at stat.math.ethz.ch, not
>
> r-sig-geo-request at stat.math.ethz.ch
>
> You are not thinking carefully and are rushing into things and drawing 
> wrong conclusions.
>
>>
>> Thanks a lot.
>> 
>> Cheers.
>>
>>
>>
>> ?2010-05-12 20:28:47?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>> On Wed, 12 May 2010, huangykiz wrote:
>>>
>>>> Hi,
>>>> One of SAM author ("Jos? Alexandre Felizola Diniz Filho"<diniz at icb.ufg.br>) say that they also base on GWR3 (the Fotherigham book)  and the data used within each kernel 
>>>> may be some slight differences
>>>
>>> Naturally, if you are not using exactly the same kernel and bandwidth, you 
>>> should not be surprised by differences in values. Please make sure that 
>>> the bandwidth and kernel are the same and try again.
>>>
>>> Roger
>>>
>>>> Cheers
>
>
>
>
> ?2010-05-12 20:28:47?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>> On Wed, 12 May 2010, huangykiz wrote:
>>
>>> Hi,
>>> One of SAM author ("Jos? Alexandre Felizola Diniz Filho"<diniz at icb.ufg.br>) say that they also base on GWR3 (the Fotherigham book)  and the data used within each kernel 
>>> may be some slight differences
>>
>> Naturally, if you are not using exactly the same kernel and bandwidth, you 
>> should not be surprised by differences in values. Please make sure that 
>> the bandwidth and kernel are the same and try again.
>>
>> Roger
>>
>>> Cheers.
>>>
>
>
>
>
>
> ?2010-05-12 15:27:58?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>> On Wed, 12 May 2010, huangykiz wrote:
>>
>>> Hi,
>>> 
>>> I am sorry I donot know how to install module spgwr from sourceforge (I can find it on the web http://r-spatial.cvs.sourceforge.net/viewvc/r-spatial/spgwr/R/gwr.R?view=log). So I use the code sketch to calculate quasi-global R2. The results are different between SAM and spgwr(Attached are the results ). The quasi-global R2 in R is 0.4515894, but in SAM is 0.696.
>>> This is my code:
>>> 
>>> library(spgwr)
>>> Environmental_variables<-read.csv("Environmental_variables100.csv",header=TRUE)
>>> attach(Environmental_variables)
>>> region_PET.bw <- gwr.sel(SPECIES_RI ~ PET, data=Environmental_variables, coords=cbind(Environmental_variables$LONGX, Environmental_variables$LATY),adapt=TRUE)
>>> region_PET.gauss <- gwr(SPECIES_RI ~ PET, data=Environmental_variables, coords=cbind(Environmental_variables$LONGX, Environmental_variables$LATY), bandwidth=region_PET.bw, gweight=gwr.Gauss,adapt=TRUE,hatmatrix=TRUE)
>>> names(region_PET.gauss$SDF)
>>> region_PET.gauss$SDF$localR2
>>> 1 - (region_PET.gauss$results$rss/crossprod(scale(Environmental_variables$SPECIES_RI, scale=FALSE)))
>>> 
>>> Thank you very much.
>>
>> SAM is closed source - ask them how they compute it. For spgwr, the code 
>> is provided, so you can read it for yourself. For the record, the current 
>> gwr() code in spgwr gives the same value as GWR3, which is also closed 
>> source, and where the Effective number of parameters (model: traceS), 
>> Sigma, and Residual sum of squares also agree. I suppose SAM has a 
>> different understanding of GWR internals than the authors of the GWR book.
>>
>> Once again:
>>
>> Please *do* write to the R-sig-geo list rather than to me directly -
>> others can answer your question as well, perhaps better, and in a more
>> timely way than I can. In addition, threads in the list can be searched in
>> the archives, so others can avoid the same problem later.
>>
>> Please summarise to the list if this resolves the problem.
>>
>> Roger
>>
>>> 
>>> 
>>>
>>>
>>>
>>> ?2010-05-12 01:16:18?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>> On Wed, 12 May 2010, huangykiz wrote:
>>>>
>>>>> Hi, I just need one for global, not *each* fit point. In this case, how 
>>>>> can I select or do? Why in other software such as SAM(Spatial Analysis 
>>>>> in Macroecology) just gives one R2?
>>>>
>>>> If you believe theirs, good luck! The authors of the GWR book have local 
>>>> R^2 values in GWR3 and formulae that are wrong by their own admission in 
>>>> private emails. The localR2 now agrees with the as-yet unreleased GWR4 
>>>> from the GWR authors. How SAM can be "better", I don't know. What you are 
>>>> suggesting is that the model fitted with fit points at data points (but 
>>>> not at other fit points) might have a "quasi-global" R^2, based on the RSS 
>>>> of the pooled fit. For the columbus case, that might be:
>>>>
>>>> 1 - (col.gauss$results$rss/crossprod(scale(columbus$crime, scale=FALSE)))
>>>>
>>>> but I don't know whether this is in any way correct. I've added it as:
>>>>
>>>> Quasi-global R2:
>>>>
>>>> to the print output of a GWR model fitted with a hatmatrix, and have 
>>>> committed it to sourceforge, project r-spatial, module spgwr. Arguably, it 
>>>> ought to be adjusted by the ratio of degrees of freedom, but I don't trust 
>>>> the DF either. Could you please check out spgwr from sourceforge ,install 
>>>> it from source, and confirm that the "quasi-global R2" does the same as 
>>>> SAM, or use the code sketch above to do the same, and report back?
>>>>
>>>> Roger
>>>>
>>>>> 
>>>>> Thanks a lot.
>>>>> 
>>>>> Cheers,
>>>>>
>>>>> 
>>>>>
>>>>>
>>>>>
>>>>> ?2010-05-11 23:59:44?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>>>>>
>>>>>>> Hi,
>>>>>>> 
>>>>>>> There are 49  localR2 in the results. Which one do I need? The code "look for localR2:" cannot run.
>>>>>>
>>>>>> Well, how many do you want? There is one for each fit point, they are 
>>>>>> *local* R2. Please do try to grasp what GWR does - it fits one moddel for 
>>>>>> *each* fit point.
>>>>>>
>>>>>>> 
>>>>>>> Thans a lot
>>>>>>> 
>>>>>>> Cheers.
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> ?2010-05-11 22:33:59?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>>>>>>>
>>>>>>>>> Hi, OK. But I need it for compariation. In what some contexts to get it? 
>>>>>>>>> May you tell me how to get it?
>>>>>>>>
>>>>>>>> library(spgwr)
>>>>>>>> data(columbus)
>>>>>>>> col.bw <- gwr.sel(crime ~ income + housing, data=columbus,
>>>>>>>>  coords=cbind(columbus$x, columbus$y))
>>>>>>>> col.gauss <- gwr(crime ~ income + housing, data=columbus,
>>>>>>>>  coords=cbind(columbus$x, columbus$y), bandwidth=col.bw, hatmatrix=TRUE)
>>>>>>>> names(col.gauss$SDF)
>>>>>>>>
>>>>>>>> look for localR2:
>>>>>>>>
>>>>>>>> col.gauss$SDF$localR2
>>>>>>>>
>>>>>>>> But do not rely on it or use it for anything at all! Like all GWR, it is 
>>>>>>>> most unreliable!
>>>>>>>>
>>>>>>>> Roger Bivand
>>>>>>>>
>>>>>>>>> 
>>>>>>>>> Thank you very much for your great helps
>>>>>>>>> 
>>>>>>>>> Best regards.
>>>>>>>>> 
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> ?2010-05-11 18:28:44?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>>>>>>>>>
>>>>>>>>>>> Dear professor Bivand,
>>>>>>>>>>> 
>>>>>>>>>>> I am a strudent. I recently use GWR(Geographically 
>>>>>>>>>>> weighted regression) model. May I ask you a question? There is not 
>>>>>>>>>>> Coefficient of Determination in the results of GWR. How can I get it? 
>>>>>>>>>>> What is the programs to get it?
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> Please address questions like this to the R-sig-geo list rather than to me 
>>>>>>>>>> directly in future.
>>>>>>>>>>
>>>>>>>>>> The local R2 values are available in some contexts when running gwr(), but 
>>>>>>>>>> are not well defined (neither in the GWR book nor in implementations). I 
>>>>>>>>>> advise against their use - they are most probably meaningless.
>>>>>>>>>>
>>>>>>>>>> Hope this helps,
>>>>>>>>>>
>>>>>>>>>> Roger Bivand
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>> 
>>>>>>>>>>> Thank you very much for your any helps.
>>>>>>>>>>> 
>>>>>>>>>>> Best regards.
>>>>>>>>>>> 
>>>>>>>>>>> Yong Huang
>>>>>>>>>>
>>>>>>>>>> -- 
>>>>>>>>>> Roger Bivand
>>>>>>>>>> Economic Geography Section, Department of Economics, Norwegian School of
>>>>>>>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>>>>>>
>>>>>>>>
>>>>>>>> -- 
>>>>>>>> Roger Bivand
>>>>>>>> Economic Geography Section, Department of Economics, Norwegian School of
>>>>>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>>
>>>>>> -- 
>>>>>> Roger Bivand
>>>>>> Economic Geography Section, Department of Economics, Norwegian School of
>>>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>
>>>> -- 
>>>> Roger Bivand
>>>> Economic Geography Section, Department of Economics, Norwegian School of
>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>> e-mail: Roger.Bivand at nhh.no
>>
>> -- 
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From Roger.Bivand at nhh.no  Wed May 12 18:07:23 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 12 May 2010 18:07:23 +0200 (CEST)
Subject: [R-sig-Geo] How to get the Coefficient of Determination in the
 results of GWR
In-Reply-To: <alpine.LRH.2.00.1005121726190.5691@reclus.nhh.no>
References: <alpine.LRH.2.00.1005120914260.19319@reclus.nhh.no>
	<alpine.LRH.2.00.1005111834410.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111758330.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111632010.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111226160.11770@reclus.nhh.no>
	<7fbb8685.9c9e.12886ce7d95.Coremail.huangykiz@163.com>
	<35fc8b41.9509.128878f8dc7.Coremail.huangykiz@163.com>
	<5cd1a7.aaf7.12887db30ba.Coremail.huangykiz@163.com>
	<1721ac8.cd5c.1288828d49a.Coremail.huangykiz@163.com>
	<e41e5d3.ff74.1288a727c78.Coremail.huangykiz@163.com>
	<e30f5db.13f83.1288d18e217.Coremail.huangykiz@163.com>
	<alpine.LRH.2.00.1005121726190.5691@reclus.nhh.no>
Message-ID: <alpine.LRH.2.00.1005121803170.5691@reclus.nhh.no>

On Wed, 12 May 2010, Roger Bivand wrote:

> On Wed, 12 May 2010, huangykiz wrote:
>
>> Hi, Is "adapt=TRUE"(spgwr) not the same as "adaptive Spatial 
>> Kernel"(SAM)?The result of "adaptive Spatial Kernel" may be better than 
>> fixed bandwidth. If I want to ues "adaptive Spatial Kernel" in spgwr, how 
>> to write the code?
>
> READ THE HELP PAGES!
>
> adaptive_proportion <- gwr.sel(...)
>
> result <- gwr(..., adapt=adaptive_proportion; ...)
>
> exactly as on the example om the help page:
>
> data(georgia)
> g.adapt.gauss <- gwr.sel(PctBach ~ TotPop90 + PctRural + PctEld + PctFB +
>  PctPov + PctBlack, data=gSRDF, adapt=TRUE)
> res.adpt <- gwr(PctBach ~ TotPop90 + PctRural + PctEld + PctFB + PctPov +
>  PctBlack, data=gSRDF, adapt=g.adapt.gauss)
> res.adpt
>
> Clear?

I have now compared the same data in R/spgwr and SAM for effective number 
of parameters, sigma, and your questionable R^2, and they agree adequately 
when the kernel and the bandwidth are the same. Having the algorithm 
choose the bandwidth does obscure what is going on. You should use SAM if 
you prefer GUI and not needing to know how things work, and remember that 
GWR is a very doubtful approach for anything beyond exploring 
non-stationarity, its original motivation.

>
>> 
>> Thanks a lot.
>> 
>> Cheers.
>> 
>> 
>>> Hi,
>>> I think that I use the same bandwidth and kernel. In SAM, I use "spatial 
>>> Weighting Function"=gaussian, adaptive Spatial Kernel, and compute 
>>> Geographical Distances based on longitudinal coordinate(X) and latitudinal 
>>> coordinate(Y). In spgwr, gweight is gwr.Gauss and adapt is TRUE.
>>> 
>>> For example, this is my code:
>> 
>>> PET.bw <- gwr.sel(SPECIES_RI ~ PET, data=variables, 
>>> coords=cbind(variables$LONGX, variables$LATY),adapt=TRUE)
>> 
>>> PET.gauss <- gwr(SPECIES_RI ~ PET, data=variables, 
>>> coords=cbind(variables$LONGX, variables$LATY), bandwidth=PET.bw, 
>>> gweight=gwr.Gauss,adapt=TRUE,hatmatrix=TRUE)
>> 
>> So where do you pass PET.bw to the gwr() function? adapt=TRUE will treat 
>> the adaptive proportion as 1, so include all data points. If you want to 
>> compare, use a fixed bandwidth in both, with no CV selection. Then you 
>> compare like with like.
>> 
>> Note that your messages are *not* reaching the list, they must be sent to:
>> 
>> r-sig-geo at stat.math.ethz.ch, not
>> 
>> r-sig-geo-request at stat.math.ethz.ch
>> 
>> You are not thinking carefully and are rushing into things and drawing 
>> wrong conclusions.
>> 
>>> 
>>> Thanks a lot.
>>> 
>>> Cheers.
>>> 
>>> 
>>> 
>>> ?2010-05-12 20:28:47?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>> On Wed, 12 May 2010, huangykiz wrote:
>>>> 
>>>>> Hi,
>>>>> One of SAM author ("Jos? Alexandre Felizola Diniz 
>>>>> Filho"<diniz at icb.ufg.br>) say that they also base on GWR3 (the 
>>>>> Fotherigham book)  and the data used within each kernel may be some 
>>>>> slight differences
>>>> 
>>>> Naturally, if you are not using exactly the same kernel and bandwidth, 
>>>> you should not be surprised by differences in values. Please make sure 
>>>> that the bandwidth and kernel are the same and try again.
>>>> 
>>>> Roger
>>>> 
>>>>> Cheers
>> 
>> 
>> 
>> 
>> ?2010-05-12 20:28:47?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>> On Wed, 12 May 2010, huangykiz wrote:
>>> 
>>>> Hi,
>>>> One of SAM author ("Jos? Alexandre Felizola Diniz 
>>>> Filho"<diniz at icb.ufg.br>) say that they also base on GWR3 (the 
>>>> Fotherigham book)  and the data used within each kernel may be some 
>>>> slight differences
>>> 
>>> Naturally, if you are not using exactly the same kernel and bandwidth, you 
>>> should not be surprised by differences in values. Please make sure that 
>>> the bandwidth and kernel are the same and try again.
>>> 
>>> Roger
>>> 
>>>> Cheers.
>>>> 
>> 
>> 
>> 
>> 
>> 
>> ?2010-05-12 15:27:58?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>> On Wed, 12 May 2010, huangykiz wrote:
>>> 
>>>> Hi,
>>>> 
>>>> I am sorry I donot know how to install module spgwr from sourceforge (I 
>>>> can find it on the web 
>>>> http://r-spatial.cvs.sourceforge.net/viewvc/r-spatial/spgwr/R/gwr.R?view=log). 
>>>> So I use the code sketch to calculate quasi-global R2. The results are 
>>>> different between SAM and spgwr(Attached are the results ). The 
>>>> quasi-global R2 in R is 0.4515894, but in SAM is 0.696.
>>>> This is my code:
>>>> 
>>>> library(spgwr)
>>>> Environmental_variables<-read.csv("Environmental_variables100.csv",header=TRUE)
>>>> attach(Environmental_variables)
>>>> region_PET.bw <- gwr.sel(SPECIES_RI ~ PET, data=Environmental_variables, 
>>>> coords=cbind(Environmental_variables$LONGX, 
>>>> Environmental_variables$LATY),adapt=TRUE)
>>>> region_PET.gauss <- gwr(SPECIES_RI ~ PET, data=Environmental_variables, 
>>>> coords=cbind(Environmental_variables$LONGX, 
>>>> Environmental_variables$LATY), bandwidth=region_PET.bw, 
>>>> gweight=gwr.Gauss,adapt=TRUE,hatmatrix=TRUE)
>>>> names(region_PET.gauss$SDF)
>>>> region_PET.gauss$SDF$localR2
>>>> 1 - 
>>>> (region_PET.gauss$results$rss/crossprod(scale(Environmental_variables$SPECIES_RI, 
>>>> scale=FALSE)))
>>>> 
>>>> Thank you very much.
>>> 
>>> SAM is closed source - ask them how they compute it. For spgwr, the code 
>>> is provided, so you can read it for yourself. For the record, the current 
>>> gwr() code in spgwr gives the same value as GWR3, which is also closed 
>>> source, and where the Effective number of parameters (model: traceS), 
>>> Sigma, and Residual sum of squares also agree. I suppose SAM has a 
>>> different understanding of GWR internals than the authors of the GWR book.
>>> 
>>> Once again:
>>> 
>>> Please *do* write to the R-sig-geo list rather than to me directly -
>>> others can answer your question as well, perhaps better, and in a more
>>> timely way than I can. In addition, threads in the list can be searched in
>>> the archives, so others can avoid the same problem later.
>>> 
>>> Please summarise to the list if this resolves the problem.
>>> 
>>> Roger
>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> ?2010-05-12 01:16:18?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>>>> 
>>>>>> Hi, I just need one for global, not *each* fit point. In this case, how 
>>>>>> can I select or do? Why in other software such as SAM(Spatial Analysis 
>>>>>> in Macroecology) just gives one R2?
>>>>> 
>>>>> If you believe theirs, good luck! The authors of the GWR book have local 
>>>>> R^2 values in GWR3 and formulae that are wrong by their own admission in 
>>>>> private emails. The localR2 now agrees with the as-yet unreleased GWR4 
>>>>> from the GWR authors. How SAM can be "better", I don't know. What you 
>>>>> are suggesting is that the model fitted with fit points at data points 
>>>>> (but not at other fit points) might have a "quasi-global" R^2, based on 
>>>>> the RSS of the pooled fit. For the columbus case, that might be:
>>>>> 
>>>>> 1 - (col.gauss$results$rss/crossprod(scale(columbus$crime, 
>>>>> scale=FALSE)))
>>>>> 
>>>>> but I don't know whether this is in any way correct. I've added it as:
>>>>> 
>>>>> Quasi-global R2:
>>>>> 
>>>>> to the print output of a GWR model fitted with a hatmatrix, and have 
>>>>> committed it to sourceforge, project r-spatial, module spgwr. Arguably, 
>>>>> it ought to be adjusted by the ratio of degrees of freedom, but I don't 
>>>>> trust the DF either. Could you please check out spgwr from sourceforge 
>>>>> ,install it from source, and confirm that the "quasi-global R2" does the 
>>>>> same as SAM, or use the code sketch above to do the same, and report 
>>>>> back?
>>>>> 
>>>>> Roger
>>>>> 
>>>>>> 
>>>>>> Thanks a lot.
>>>>>> 
>>>>>> Cheers,
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> ?2010-05-11 23:59:44?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>>>>>> 
>>>>>>>> Hi,
>>>>>>>> 
>>>>>>>> There are 49  localR2 in the results. Which one do I need? The code 
>>>>>>>> "look for localR2:" cannot run.
>>>>>>> 
>>>>>>> Well, how many do you want? There is one for each fit point, they are 
>>>>>>> *local* R2. Please do try to grasp what GWR does - it fits one moddel 
>>>>>>> for *each* fit point.
>>>>>>> 
>>>>>>>> 
>>>>>>>> Thans a lot
>>>>>>>> 
>>>>>>>> Cheers.
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> ?2010-05-11 22:33:59?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>>>>>>>> 
>>>>>>>>>> Hi, OK. But I need it for compariation. In what some contexts to 
>>>>>>>>>> get it? May you tell me how to get it?
>>>>>>>>> 
>>>>>>>>> library(spgwr)
>>>>>>>>> data(columbus)
>>>>>>>>> col.bw <- gwr.sel(crime ~ income + housing, data=columbus,
>>>>>>>>>  coords=cbind(columbus$x, columbus$y))
>>>>>>>>> col.gauss <- gwr(crime ~ income + housing, data=columbus,
>>>>>>>>>  coords=cbind(columbus$x, columbus$y), bandwidth=col.bw, 
>>>>>>>>> hatmatrix=TRUE)
>>>>>>>>> names(col.gauss$SDF)
>>>>>>>>> 
>>>>>>>>> look for localR2:
>>>>>>>>> 
>>>>>>>>> col.gauss$SDF$localR2
>>>>>>>>> 
>>>>>>>>> But do not rely on it or use it for anything at all! Like all GWR, 
>>>>>>>>> it is most unreliable!
>>>>>>>>> 
>>>>>>>>> Roger Bivand
>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Thank you very much for your great helps
>>>>>>>>>> 
>>>>>>>>>> Best regards.
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> ?2010-05-11 18:28:44?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>>>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>>>>>>>>>> 
>>>>>>>>>>>> Dear professor Bivand,
>>>>>>>>>>>> 
>>>>>>>>>>>> I am a strudent. I recently use GWR(Geographically weighted 
>>>>>>>>>>>> regression) model. May I ask you a question? There is not 
>>>>>>>>>>>> Coefficient of Determination in the results of GWR. How can I get 
>>>>>>>>>>>> it? What is the programs to get it?
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> Please address questions like this to the R-sig-geo list rather 
>>>>>>>>>>> than to me directly in future.
>>>>>>>>>>> 
>>>>>>>>>>> The local R2 values are available in some contexts when running 
>>>>>>>>>>> gwr(), but are not well defined (neither in the GWR book nor in 
>>>>>>>>>>> implementations). I advise against their use - they are most 
>>>>>>>>>>> probably meaningless.
>>>>>>>>>>> 
>>>>>>>>>>> Hope this helps,
>>>>>>>>>>> 
>>>>>>>>>>> Roger Bivand
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> Thank you very much for your any helps.
>>>>>>>>>>>> 
>>>>>>>>>>>> Best regards.
>>>>>>>>>>>> 
>>>>>>>>>>>> Yong Huang
>>>>>>>>>>> 
>>>>>>>>>>> -- 
>>>>>>>>>>> Roger Bivand
>>>>>>>>>>> Economic Geography Section, Department of Economics, Norwegian 
>>>>>>>>>>> School of
>>>>>>>>>>> Economics and Business Administration, Helleveien 30, N-5045 
>>>>>>>>>>> Bergen,
>>>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> -- 
>>>>>>>>> Roger Bivand
>>>>>>>>> Economic Geography Section, Department of Economics, Norwegian 
>>>>>>>>> School of
>>>>>>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>>> 
>>>>>>> -- 
>>>>>>> Roger Bivand
>>>>>>> Economic Geography Section, Department of Economics, Norwegian School 
>>>>>>> of
>>>>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>> 
>>>>> -- 
>>>>> Roger Bivand
>>>>> Economic Geography Section, Department of Economics, Norwegian School of
>>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>> e-mail: Roger.Bivand at nhh.no
>>> 
>>> -- 
>>> Roger Bivand
>>> Economic Geography Section, Department of Economics, Norwegian School of
>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>> e-mail: Roger.Bivand at nhh.no
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From Roger.Bivand at nhh.no  Wed May 12 18:32:37 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 12 May 2010 18:32:37 +0200 (CEST)
Subject: [R-sig-Geo] readOGR(): stringsAsFactors
In-Reply-To: <1273657975486-5040366.post@n2.nabble.com>
References: <1273562135300-5034706.post@n2.nabble.com>
	<alpine.LRH.2.00.1005111139480.11770@reclus.nhh.no>
	<1273576777675-5035470.post@n2.nabble.com>
	<alpine.LRH.2.00.1005111443210.12555@reclus.nhh.no>
	<1273645623545-5039744.post@n2.nabble.com>
	<alpine.LRH.2.00.1005120929250.19319@reclus.nhh.no>
	<1273657975486-5040366.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.00.1005121831230.5691@reclus.nhh.no>

On Wed, 12 May 2010, Agustin Lobo wrote:

>
> ok,
> After the correct installation of the new release with:
> cvs -z3 -d:pserver:rgdal.cvs.sourceforge.net:/cvsroot/rgdal co -P rgdal
> R CMD INSTALL rgdal
>
> I can confirm that the new argument works fine:
>> require(rgdal)
> Loading required package: rgdal
> Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 1.6.3, released 2009/11/19
> Path to GDAL shared files: /usr/share/gdal16
> Loaded PROJ.4 runtime: Rel. 4.7.1, 23 September 2009
> Path to PROJ.4 shared files: (autodetected)
>
>> packageDescription("rgdal")
> Package: rgdal
> Title: Bindings for the Geospatial Data Abstraction Library
> Version: 0.6-27
> Date: 2010-05-11
> .../...
>
>> terNOXLC <-
>> readOGR(dsn="/media/TRANSCEND/MASTER_ICTA2007_2008/miniproj_GISInP2009/MARICEL2",
>> layer="terNOX0709buf2500values",stringsAsFactors=F)
> OGR data source with driver: ESRI Shapefile
> Source:
> "/media/TRANSCEND/MASTER_ICTA2007_2008/miniproj_GISInP2009/MARICEL2", layer:
> "terNOX0709buf2500values"
> with 4100 features and 12 fields
> Feature type: wkbPoint with 2 dimensions
>
>> class(terNOXLC at data[,1])
> [1] "character"
>
>> terNOXLC <-
>> readOGR(dsn="/media/TRANSCEND/MASTER_ICTA2007_2008/miniproj_GISInP2009/MARICEL2",
>> layer="terNOX0709buf2500values",stringsAsFactors=T)
> OGR data source with driver: ESRI Shapefile
> Source:
> "/media/TRANSCEND/MASTER_ICTA2007_2008/miniproj_GISInP2009/MARICEL2", layer:
> "terNOX0709buf2500values"
> with 4100 features and 12 fields
> Feature type: wkbPoint with 2 dimensions
>
>> class(terNOXLC at data[,1])
> [1] "factor"
>
>> terNOXLC <-
>> readOGR(dsn="/media/TRANSCEND/MASTER_ICTA2007_2008/miniproj_GISInP2009/MARICEL2",
>> layer="terNOX0709buf2500values")
> OGR data source with driver: ESRI Shapefile
> Source:
> "/media/TRANSCEND/MASTER_ICTA2007_2008/miniproj_GISInP2009/MARICEL2", layer:
> "terNOX0709buf2500values"
> with 4100 features and 12 fields
> Feature type: wkbPoint with 2 dimensions
>
>> class(terNOXLC at data[,1])
> [1] "factor"
>
>
> Many thanks! When do you think that this new improvement will make it into
> CRAN?

Submitted to CRAN, should appear as source fairly soon, as binaries a 
little later.

Roger

> Agus
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From tim.romel at vistracks.com  Thu May 13 01:45:56 2010
From: tim.romel at vistracks.com (Tim Romel)
Date: Wed, 12 May 2010 18:45:56 -0500
Subject: [R-sig-Geo] Querying Spatial Data Using rgdal
In-Reply-To: <alpine.LRH.2.00.1005111317120.11770@reclus.nhh.no>
References: <s2z90a726dc1005071435ifb97b2cdm5e8d580fd4b9f3f1@mail.gmail.com>
	<w2o49b12cd41005081530s2d6c45f8oc6a61dec3ffa2426@mail.gmail.com>
	<alpine.LRH.2.00.1005111317120.11770@reclus.nhh.no>
Message-ID: <AANLkTim8qdab6pB_2i0VP7jvbHY9s2v7qkzLMAd3TlnL@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100512/b81c7cf1/attachment.pl>

From huangykiz at 163.com  Thu May 13 09:10:55 2010
From: huangykiz at 163.com (huangykiz)
Date: Thu, 13 May 2010 15:10:55 +0800 (CST)
Subject: [R-sig-Geo] How to get the Coefficient of Determination in the
 results of GWR
In-Reply-To: <alpine.LRH.2.00.1005121803170.5691@reclus.nhh.no>
References: <alpine.LRH.2.00.1005121803170.5691@reclus.nhh.no>
	<alpine.LRH.2.00.1005120914260.19319@reclus.nhh.no>
	<alpine.LRH.2.00.1005111834410.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111758330.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111632010.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111226160.11770@reclus.nhh.no>
	<7fbb8685.9c9e.12886ce7d95.Coremail.huangykiz@163.com>
	<35fc8b41.9509.128878f8dc7.Coremail.huangykiz@163.com>
	<5cd1a7.aaf7.12887db30ba.Coremail.huangykiz@163.com>
	<1721ac8.cd5c.1288828d49a.Coremail.huangykiz@163.com>
	<e41e5d3.ff74.1288a727c78.Coremail.huangykiz@163.com>
	<e30f5db.13f83.1288d18e217.Coremail.huangykiz@163.com>
	<alpine.LRH.2.00.1005121726190.5691@reclus.nhh.no>
Message-ID: <342188fb.6e7b.12890806f61.Coremail.huangykiz@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100513/4a4b58c3/attachment.pl>

From Roger.Bivand at nhh.no  Thu May 13 11:43:06 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 13 May 2010 11:43:06 +0200 (CEST)
Subject: [R-sig-Geo] How to get the Coefficient of Determination in the
 results of GWR
In-Reply-To: <342188fb.6e7b.12890806f61.Coremail.huangykiz@163.com>
References: <alpine.LRH.2.00.1005121803170.5691@reclus.nhh.no>
	<alpine.LRH.2.00.1005120914260.19319@reclus.nhh.no>
	<alpine.LRH.2.00.1005111834410.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111758330.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111632010.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111226160.11770@reclus.nhh.no>
	<7fbb8685.9c9e.12886ce7d95.Coremail.huangykiz@163.com>
	<35fc8b41.9509.128878f8dc7.Coremail.huangykiz@163.com>
	<5cd1a7.aaf7.12887db30ba.Coremail.huangykiz@163.com>
	<1721ac8.cd5c.1288828d49a.Coremail.huangykiz@163.com>
	<e41e5d3.ff74.1288a727c78.Coremail.huangykiz@163.com>
	<e30f5db.13f83.1288d18e217.Coremail.huangykiz@163.com>
	<alpine.LRH.2.00.1005121726190.5691@reclus.nhh.no>
	<342188fb.6e7b.12890806f61.Coremail.huangykiz@163.com>
Message-ID: <alpine.LRH.2.00.1005131135030.19985@reclus.nhh.no>

On Thu, 13 May 2010, huangykiz wrote:

> Hi,

> I am sorry I say that I cannot get the same R^2 between in R/spgwr and 
> SAM in my data.

Establish that the adaptive proportion is exactly the same.

You haven't done that - copy and paste from SAM to gwr(), not using 
gwr.sel(). Do it first for fixed Gaussian, then if you get a sensible 
figure from SAM for adaptive, do the same there. I see very different 
bandwidths chosen by SAM and by gwr.sel() and GWR3 - gwr.sel() and GWR3 
usually agree fairly well for CV fixed bandwidths, but gwr.sel() typically 
continues its search a little longer than GWR3.

I don't know how SAM chooses its bandwidth or adaptive proportion, it is 
closed source, so only its authors know.

Is SAM using Great Circle distances, if so, you should set longlat=TRUE in 
gwr.sel() and gwr()? Are your coordinates geographical (decimal degrees) 
or projected (metres)?

Roger

> In R/spgwr
> R^2:    0.972989;
> AICc (GWR p. 61, eq 2.33; p. 96, eq. 4.21): 4668.92
> Effective number of parameters (model: traceS): 435.7586; 
> Effective number of parameters (residual: 2traceS - traceS'S): 582.3581;
> Sigma (residual: 2traceS - traceS'S): 2.437066;
> Sigma (model: traceS): 1.927127;
> Sigma (ML): 1.325501;
> 
> In SAM,
> Coefficient of Determination :           0.696 
> Adjusted r-square (r?Adj):                 0.693 
> Sigma:                                             20.058 
> Effective Number of Parameters:          10.002 
> Akaike Information Criterion (AICc):      4838.299 
> Correlation Coefficient (r):                    0.834 
> F:                                                   207.852 
> 
> Here are my code:
> PET.adapt.gauss <- gwr.sel(SPECIES_RI ~ PET, data=Environmental_variables, coords=cbind(Environmental_variables$LONGX, 
> Environmental_variables$LATY),adapt=TRUE)
> 
> PET.gauss<- gwr(SPECIES_RI ~ PET, data=Environmental_variables, coords=cbind(Environmental_variables$LONGX, 
> Environmental_variables$LATY), gweight=gwr.Gauss,adapt=PET.adapt.gauss,hatmatrix=TRUE)
> 
> 1 - (PET.gauss$results$rss/crossprod(scale(Environmental_variables$SPECIES_RI, scale=FALSE)))
> 
> In SAM, I selecte "spatial Weighting Function"=gaussian, adaptive 
> Spatial Kernel, and compute Geographical Distances based on longitudinal 
> coordinate(X) and latitudinal coordinate(Y). I donot select method for 
> AIC optimisation.
> 
> So I donot know where is wrong.
> 
> Thank you very much for your great helps.
> 
> 
> 
> 
> 
>
> ?2010-05-13 00:07:23?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>> On Wed, 12 May 2010, Roger Bivand wrote:
>>
>>> On Wed, 12 May 2010, huangykiz wrote:
>>>
>>>> Hi, Is "adapt=TRUE"(spgwr) not the same as "adaptive Spatial 
>>>> Kernel"(SAM)?The result of "adaptive Spatial Kernel" may be better than 
>>>> fixed bandwidth. If I want to ues "adaptive Spatial Kernel" in spgwr, how 
>>>> to write the code?
>>>
>>> READ THE HELP PAGES!
>>>
>>> adaptive_proportion <- gwr.sel(...)
>>>
>>> result <- gwr(..., adapt=adaptive_proportion; ...)
>>>
>>> exactly as on the example om the help page:
>>>
>>> data(georgia)
>>> g.adapt.gauss <- gwr.sel(PctBach ~ TotPop90 + PctRural + PctEld + PctFB +
>>>  PctPov + PctBlack, data=gSRDF, adapt=TRUE)
>>> res.adpt <- gwr(PctBach ~ TotPop90 + PctRural + PctEld + PctFB + PctPov +
>>>  PctBlack, data=gSRDF, adapt=g.adapt.gauss)
>>> res.adpt
>>>
>>> Clear?
>>
>> I have now compared the same data in R/spgwr and SAM for effective number 
>> of parameters, sigma, and your questionable R^2, and they agree adequately 
>> when the kernel and the bandwidth are the same. Having the algorithm 
>> choose the bandwidth does obscure what is going on. You should use SAM if 
>> you prefer GUI and not needing to know how things work, and remember that 
>> GWR is a very doubtful approach for anything beyond exploring 
>> non-stationarity, its original motivation.
>>
>>>
>>>> 
>>>> Thanks a lot.
>>>> 
>>>> Cheers.
>>>> 
>>>> 
>>>>> Hi,
>>>>> I think that I use the same bandwidth and kernel. In SAM, I use "spatial 
>>>>> Weighting Function"=gaussian, adaptive Spatial Kernel, and compute 
>>>>> Geographical Distances based on longitudinal coordinate(X) and latitudinal 
>>>>> coordinate(Y). In spgwr, gweight is gwr.Gauss and adapt is TRUE.
>>>>> 
>>>>> For example, this is my code:
>>>> 
>>>>> PET.bw <- gwr.sel(SPECIES_RI ~ PET, data=variables, 
>>>>> coords=cbind(variables$LONGX, variables$LATY),adapt=TRUE)
>>>> 
>>>>> PET.gauss <- gwr(SPECIES_RI ~ PET, data=variables, 
>>>>> coords=cbind(variables$LONGX, variables$LATY), bandwidth=PET.bw, 
>>>>> gweight=gwr.Gauss,adapt=TRUE,hatmatrix=TRUE)
>>>> 
>>>> So where do you pass PET.bw to the gwr() function? adapt=TRUE will treat 
>>>> the adaptive proportion as 1, so include all data points. If you want to 
>>>> compare, use a fixed bandwidth in both, with no CV selection. Then you 
>>>> compare like with like.
>>>> 
>>>> Note that your messages are *not* reaching the list, they must be sent to:
>>>> 
>>>> r-sig-geo at stat.math.ethz.ch, not
>>>> 
>>>> r-sig-geo-request at stat.math.ethz.ch
>>>> 
>>>> You are not thinking carefully and are rushing into things and drawing 
>>>> wrong conclusions.
>>>> 
>>>>> 
>>>>> Thanks a lot.
>>>>> 
>>>>> Cheers.
>>>>> 
>>>>> 
>>>>> 
>>>>> ?2010-05-12 20:28:47?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>>>>> 
>>>>>>> Hi,
>>>>>>> One of SAM author ("Jos? Alexandre Felizola Diniz 
>>>>>>> Filho"<diniz at icb.ufg.br>) say that they also base on GWR3 (the 
>>>>>>> Fotherigham book)  and the data used within each kernel may be some 
>>>>>>> slight differences
>>>>>> 
>>>>>> Naturally, if you are not using exactly the same kernel and bandwidth, 
>>>>>> you should not be surprised by differences in values. Please make sure 
>>>>>> that the bandwidth and kernel are the same and try again.
>>>>>> 
>>>>>> Roger
>>>>>> 
>>>>>>> Cheers
>>>> 
>>>> 
>>>> 
>>>> 
>>>> ?2010-05-12 20:28:47?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>>>> 
>>>>>> Hi,
>>>>>> One of SAM author ("Jos? Alexandre Felizola Diniz 
>>>>>> Filho"<diniz at icb.ufg.br>) say that they also base on GWR3 (the 
>>>>>> Fotherigham book)  and the data used within each kernel may be some 
>>>>>> slight differences
>>>>> 
>>>>> Naturally, if you are not using exactly the same kernel and bandwidth, you 
>>>>> should not be surprised by differences in values. Please make sure that 
>>>>> the bandwidth and kernel are the same and try again.
>>>>> 
>>>>> Roger
>>>>> 
>>>>>> Cheers.
>>>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> ?2010-05-12 15:27:58?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>>>> 
>>>>>> Hi,
>>>>>> 
>>>>>> I am sorry I donot know how to install module spgwr from sourceforge (I 
>>>>>> can find it on the web 
>>>>>> http://r-spatial.cvs.sourceforge.net/viewvc/r-spatial/spgwr/R/gwr.R?view=log). 
>>>>>> So I use the code sketch to calculate quasi-global R2. The results are 
>>>>>> different between SAM and spgwr(Attached are the results ). The 
>>>>>> quasi-global R2 in R is 0.4515894, but in SAM is 0.696.
>>>>>> This is my code:
>>>>>> 
>>>>>> library(spgwr)
>>>>>> Environmental_variables<-read.csv("Environmental_variables100.csv",header=TRUE)
>>>>>> attach(Environmental_variables)
>>>>>> region_PET.bw <- gwr.sel(SPECIES_RI ~ PET, data=Environmental_variables, 
>>>>>> coords=cbind(Environmental_variables$LONGX, 
>>>>>> Environmental_variables$LATY),adapt=TRUE)
>>>>>> region_PET.gauss <- gwr(SPECIES_RI ~ PET, data=Environmental_variables, 
>>>>>> coords=cbind(Environmental_variables$LONGX, 
>>>>>> Environmental_variables$LATY), bandwidth=region_PET.bw, 
>>>>>> gweight=gwr.Gauss,adapt=TRUE,hatmatrix=TRUE)
>>>>>> names(region_PET.gauss$SDF)
>>>>>> region_PET.gauss$SDF$localR2
>>>>>> 1 - 
>>>>>> (region_PET.gauss$results$rss/crossprod(scale(Environmental_variables$SPECIES_RI, 
>>>>>> scale=FALSE)))
>>>>>> 
>>>>>> Thank you very much.
>>>>> 
>>>>> SAM is closed source - ask them how they compute it. For spgwr, the code 
>>>>> is provided, so you can read it for yourself. For the record, the current 
>>>>> gwr() code in spgwr gives the same value as GWR3, which is also closed 
>>>>> source, and where the Effective number of parameters (model: traceS), 
>>>>> Sigma, and Residual sum of squares also agree. I suppose SAM has a 
>>>>> different understanding of GWR internals than the authors of the GWR book.
>>>>> 
>>>>> Once again:
>>>>> 
>>>>> Please *do* write to the R-sig-geo list rather than to me directly -
>>>>> others can answer your question as well, perhaps better, and in a more
>>>>> timely way than I can. In addition, threads in the list can be searched in
>>>>> the archives, so others can avoid the same problem later.
>>>>> 
>>>>> Please summarise to the list if this resolves the problem.
>>>>> 
>>>>> Roger
>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> ?2010-05-12 01:16:18?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>>>>>> 
>>>>>>>> Hi, I just need one for global, not *each* fit point. In this case, how 
>>>>>>>> can I select or do? Why in other software such as SAM(Spatial Analysis 
>>>>>>>> in Macroecology) just gives one R2?
>>>>>>> 
>>>>>>> If you believe theirs, good luck! The authors of the GWR book have local 
>>>>>>> R^2 values in GWR3 and formulae that are wrong by their own admission in 
>>>>>>> private emails. The localR2 now agrees with the as-yet unreleased GWR4 
>>>>>>> from the GWR authors. How SAM can be "better", I don't know. What you 
>>>>>>> are suggesting is that the model fitted with fit points at data points 
>>>>>>> (but not at other fit points) might have a "quasi-global" R^2, based on 
>>>>>>> the RSS of the pooled fit. For the columbus case, that might be:
>>>>>>> 
>>>>>>> 1 - (col.gauss$results$rss/crossprod(scale(columbus$crime, 
>>>>>>> scale=FALSE)))
>>>>>>> 
>>>>>>> but I don't know whether this is in any way correct. I've added it as:
>>>>>>> 
>>>>>>> Quasi-global R2:
>>>>>>> 
>>>>>>> to the print output of a GWR model fitted with a hatmatrix, and have 
>>>>>>> committed it to sourceforge, project r-spatial, module spgwr. Arguably, 
>>>>>>> it ought to be adjusted by the ratio of degrees of freedom, but I don't 
>>>>>>> trust the DF either. Could you please check out spgwr from sourceforge 
>>>>>>> ,install it from source, and confirm that the "quasi-global R2" does the 
>>>>>>> same as SAM, or use the code sketch above to do the same, and report 
>>>>>>> back?
>>>>>>> 
>>>>>>> Roger
>>>>>>> 
>>>>>>>> 
>>>>>>>> Thanks a lot.
>>>>>>>> 
>>>>>>>> Cheers,
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> ?2010-05-11 23:59:44?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>>>>>>>> 
>>>>>>>>>> Hi,
>>>>>>>>>> 
>>>>>>>>>> There are 49  localR2 in the results. Which one do I need? The code 
>>>>>>>>>> "look for localR2:" cannot run.
>>>>>>>>> 
>>>>>>>>> Well, how many do you want? There is one for each fit point, they are 
>>>>>>>>> *local* R2. Please do try to grasp what GWR does - it fits one moddel 
>>>>>>>>> for *each* fit point.
>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Thans a lot
>>>>>>>>>> 
>>>>>>>>>> Cheers.
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> ?2010-05-11 22:33:59?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>>>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>>>>>>>>>> 
>>>>>>>>>>>> Hi, OK. But I need it for compariation. In what some contexts to 
>>>>>>>>>>>> get it? May you tell me how to get it?
>>>>>>>>>>> 
>>>>>>>>>>> library(spgwr)
>>>>>>>>>>> data(columbus)
>>>>>>>>>>> col.bw <- gwr.sel(crime ~ income + housing, data=columbus,
>>>>>>>>>>>  coords=cbind(columbus$x, columbus$y))
>>>>>>>>>>> col.gauss <- gwr(crime ~ income + housing, data=columbus,
>>>>>>>>>>>  coords=cbind(columbus$x, columbus$y), bandwidth=col.bw, 
>>>>>>>>>>> hatmatrix=TRUE)
>>>>>>>>>>> names(col.gauss$SDF)
>>>>>>>>>>> 
>>>>>>>>>>> look for localR2:
>>>>>>>>>>> 
>>>>>>>>>>> col.gauss$SDF$localR2
>>>>>>>>>>> 
>>>>>>>>>>> But do not rely on it or use it for anything at all! Like all GWR, 
>>>>>>>>>>> it is most unreliable!
>>>>>>>>>>> 
>>>>>>>>>>> Roger Bivand
>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> Thank you very much for your great helps
>>>>>>>>>>>> 
>>>>>>>>>>>> Best regards.
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> ?2010-05-11 18:28:44?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>>>>>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Dear professor Bivand,
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> I am a strudent. I recently use GWR(Geographically weighted 
>>>>>>>>>>>>>> regression) model. May I ask you a question? There is not 
>>>>>>>>>>>>>> Coefficient of Determination in the results of GWR. How can I get 
>>>>>>>>>>>>>> it? What is the programs to get it?
>>>>>>>>>>>>> 
>>>>>>>>>>>>> 
>>>>>>>>>>>>> Please address questions like this to the R-sig-geo list rather 
>>>>>>>>>>>>> than to me directly in future.
>>>>>>>>>>>>> 
>>>>>>>>>>>>> The local R2 values are available in some contexts when running 
>>>>>>>>>>>>> gwr(), but are not well defined (neither in the GWR book nor in 
>>>>>>>>>>>>> implementations). I advise against their use - they are most 
>>>>>>>>>>>>> probably meaningless.
>>>>>>>>>>>>> 
>>>>>>>>>>>>> Hope this helps,
>>>>>>>>>>>>> 
>>>>>>>>>>>>> Roger Bivand
>>>>>>>>>>>>> 
>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Thank you very much for your any helps.
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Best regards.
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Yong Huang
>>>>>>>>>>>>> 
>>>>>>>>>>>>> -- 
>>>>>>>>>>>>> Roger Bivand
>>>>>>>>>>>>> Economic Geography Section, Department of Economics, Norwegian 
>>>>>>>>>>>>> School of
>>>>>>>>>>>>> Economics and Business Administration, Helleveien 30, N-5045 
>>>>>>>>>>>>> Bergen,
>>>>>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> -- 
>>>>>>>>>>> Roger Bivand
>>>>>>>>>>> Economic Geography Section, Department of Economics, Norwegian 
>>>>>>>>>>> School of
>>>>>>>>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>>>>> 
>>>>>>>>> -- 
>>>>>>>>> Roger Bivand
>>>>>>>>> Economic Geography Section, Department of Economics, Norwegian School 
>>>>>>>>> of
>>>>>>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>>> 
>>>>>>> -- 
>>>>>>> Roger Bivand
>>>>>>> Economic Geography Section, Department of Economics, Norwegian School of
>>>>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>> 
>>>>> -- 
>>>>> Roger Bivand
>>>>> Economic Geography Section, Department of Economics, Norwegian School of
>>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>
>> -- 
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From Roger.Bivand at nhh.no  Thu May 13 11:44:50 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 13 May 2010 11:44:50 +0200 (CEST)
Subject: [R-sig-Geo] Querying Spatial Data Using rgdal
In-Reply-To: <AANLkTim8qdab6pB_2i0VP7jvbHY9s2v7qkzLMAd3TlnL@mail.gmail.com>
References: <s2z90a726dc1005071435ifb97b2cdm5e8d580fd4b9f3f1@mail.gmail.com>
	<w2o49b12cd41005081530s2d6c45f8oc6a61dec3ffa2426@mail.gmail.com>
	<alpine.LRH.2.00.1005111317120.11770@reclus.nhh.no>
	<AANLkTim8qdab6pB_2i0VP7jvbHY9s2v7qkzLMAd3TlnL@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1005131143150.19985@reclus.nhh.no>

On Wed, 12 May 2010, Tim Romel wrote:

> Thanks you both for your quick responses.
>
> Roger, could you please expand on how I would use ogr2ogr with R?  I didn't
> see any direct way to use ogr2ogr within R or to bring the results returned
> by the ogr2ogr command into R spatial objects.

Through system(). Use ogr2ogr to write a temporary file for readOGR() to 
pick up next. Then you can set the -sql or similar selection in the 
ogr2ogr command.

Roger

>
> Thanks again.
>
> On Tue, May 11, 2010 at 6:21 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Sat, 8 May 2010, Brooks Kehler wrote:
>>
>>  Have a look at:
>>>
>>> http://www.joeconway.com/plr/
>>>
>>>
>>> http://www.bostongis.com/PrinterFriendly.aspx?content_name=postgresql_plr_tut01
>>>
>>>
>> That only gets you so far. Could Tim please try ogr2ogr with the -sql or
>> -where or -spat arguments set to see whether these go in the correct
>> direction, that is returning geometries meeting the given selection
>> conditions? I have looked briefly at how hard it would be to add this
>> functionality to readOGR(), but without a substantial re-write, it will not
>> be easy. If there are other users who would value such an addition to
>> readOGR, please indicate!
>>
>> Roger
>>
>>
>>
>>>
>>> On Fri, May 7, 2010 at 5:35 PM, Tim Romel <tim.romel at vistracks.com>
>>> wrote:
>>>
>>>  I have the need to bring spatial data into R from a postgres database.  I
>>>> am
>>>> trying to do this right now using rgdal with a command similar to the
>>>> following:
>>>>
>>>> results=readOGR("PG:dbname='dbname' host='hostname' port='portnum'
>>>> user='username' password='pass' <password='P at ssw0rd'>,
>>>> layer="tablename")
>>>>
>>>> This works in bringing back all data from the entire table.  However,
>>>> this
>>>> is a very large table and I was wondering if there was a way to run a
>>>> query
>>>> against the table instead of bringing back all data using readOGR.  I
>>>> have
>>>> found no examples anywhere and have even seen suggestions that it is not
>>>> possible.  Is this the case?  If there are other libraries that support
>>>> R's
>>>> SP library that allow access to postgres that would be great to know too.
>>>>
>>>> Any help is much appreaciated.
>>>>
>>>> Thanks.
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From sylvain.willart at gmail.com  Thu May 13 13:13:52 2010
From: sylvain.willart at gmail.com (sylvain willart)
Date: Thu, 13 May 2010 13:13:52 +0200
Subject: [R-sig-Geo] Extract part(s) of SpatialPolygonsDataFrame
Message-ID: <AANLkTinVyjb9RCJDoZr9zeiJISXz-ZMd6JlLqC2Caebl@mail.gmail.com>

Hello,

I have an .RData file which is a SpatialPolygonsDataFrame a France,

I only need, for now, to work on two areas: Burgundy and Centre,

I would like to extract those two areas from the France file,

I tried, na?vely,
Centre <- France[France$NAME_1=="Centre", ]

but it didn't work out,
(NAME_1 is the variable where are stored the names of the French Regions)

any idea ?

Sylvain
PS: I found quite a lot of information on points, ploygons, or lines,
but few on spatialpolygonsdataframe besides they are "a set of spatial
polygons", Any reference on their inside structure ?


From huangykiz at 163.com  Thu May 13 13:18:57 2010
From: huangykiz at 163.com (huangykiz)
Date: Thu, 13 May 2010 19:18:57 +0800 (CST)
Subject: [R-sig-Geo] How to get the Coefficient of Determination in the
 results of GWR
In-Reply-To: <alpine.LRH.2.00.1005131135030.19985@reclus.nhh.no>
References: <alpine.LRH.2.00.1005131135030.19985@reclus.nhh.no>
	<alpine.LRH.2.00.1005121803170.5691@reclus.nhh.no>
	<alpine.LRH.2.00.1005120914260.19319@reclus.nhh.no>
	<alpine.LRH.2.00.1005111834410.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111758330.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111632010.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111226160.11770@reclus.nhh.no>
	<7fbb8685.9c9e.12886ce7d95.Coremail.huangykiz@163.com>
	<35fc8b41.9509.128878f8dc7.Coremail.huangykiz@163.com>
	<5cd1a7.aaf7.12887db30ba.Coremail.huangykiz@163.com>
	<1721ac8.cd5c.1288828d49a.Coremail.huangykiz@163.com>
	<e41e5d3.ff74.1288a727c78.Coremail.huangykiz@163.com>
	<e30f5db.13f83.1288d18e217.Coremail.huangykiz@163.com>
	<alpine.LRH.2.00.1005121726190.5691@reclus.nhh.no>
	<342188fb.6e7b.12890806f61.Coremail.huangykiz@163.com>
Message-ID: <4c0f7f.7041.12891638426.Coremail.huangykiz@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100513/df1c19c7/attachment.pl>

From carson.farmer at gmail.com  Thu May 13 13:32:32 2010
From: carson.farmer at gmail.com (Carson Farmer)
Date: Thu, 13 May 2010 12:32:32 +0100
Subject: [R-sig-Geo] Extract part(s) of SpatialPolygonsDataFrame
In-Reply-To: <AANLkTinVyjb9RCJDoZr9zeiJISXz-ZMd6JlLqC2Caebl@mail.gmail.com>
References: <AANLkTinVyjb9RCJDoZr9zeiJISXz-ZMd6JlLqC2Caebl@mail.gmail.com>
Message-ID: <AANLkTimSF9SdspzPu8KHrf6hAPYKIqmjKjd7kvx0iAab@mail.gmail.com>

Hi,

> I only need, for now, to work on two areas: Burgundy and Centre,
> I would like to extract those two areas from the France file,
> I tried, na?vely,
> Centre <- France[France$NAME_1=="Centre", ]

try:
> Centre <- France[France at data$NAME_1=="Centre",]

> PS: I found quite a lot of information on points, ploygons, or lines,
> but few on spatialpolygonsdataframe besides they are "a set of spatial
> polygons", Any reference on their inside structure ?

see:
> ?SpatialPolygonsDataFrame
A SpatialPolygonsDataFrame is made up of a data.frame and an object of
class SpatialPolygons, which is a list of objects of class Polygons,
which is made up of a list with Polygon class objects.
You can use getSlots to list the available slots of the various object types.
> ?getSlots

Regards,

Carson


From sylvain.willart at gmail.com  Thu May 13 13:41:42 2010
From: sylvain.willart at gmail.com (sylvain willart)
Date: Thu, 13 May 2010 13:41:42 +0200
Subject: [R-sig-Geo] Extract part(s) of SpatialPolygonsDataFrame
In-Reply-To: <AANLkTimSF9SdspzPu8KHrf6hAPYKIqmjKjd7kvx0iAab@mail.gmail.com>
References: <AANLkTinVyjb9RCJDoZr9zeiJISXz-ZMd6JlLqC2Caebl@mail.gmail.com>
	<AANLkTimSF9SdspzPu8KHrf6hAPYKIqmjKjd7kvx0iAab@mail.gmail.com>
Message-ID: <AANLkTinagZm9p8lrrkygdZEaHcmhvJZsoA3cshWICEhV@mail.gmail.com>

Great,
I didn't know about the use of '@'
Thank you

Sylvain

2010/5/13 Carson Farmer <carson.farmer at gmail.com>:
> Hi,
>
>> I only need, for now, to work on two areas: Burgundy and Centre,
>> I would like to extract those two areas from the France file,
>> I tried, na?vely,
>> Centre <- France[France$NAME_1=="Centre", ]
>
> try:
>> Centre <- France[France at data$NAME_1=="Centre",]
>
>> PS: I found quite a lot of information on points, ploygons, or lines,
>> but few on spatialpolygonsdataframe besides they are "a set of spatial
>> polygons", Any reference on their inside structure ?
>
> see:
>> ?SpatialPolygonsDataFrame
> A SpatialPolygonsDataFrame is made up of a data.frame and an object of
> class SpatialPolygons, which is a list of objects of class Polygons,
> which is made up of a list with Polygon class objects.
> You can use getSlots to list the available slots of the various object types.
>> ?getSlots
>
> Regards,
>
> Carson
>


From huangykiz at 163.com  Thu May 13 14:03:54 2010
From: huangykiz at 163.com (huangykiz)
Date: Thu, 13 May 2010 20:03:54 +0800 (CST)
Subject: [R-sig-Geo] How to get the Coefficient of Determination in the
 results of GWR
In-Reply-To: <alpine.LRH.2.00.1005131135030.19985@reclus.nhh.no>
References: <alpine.LRH.2.00.1005131135030.19985@reclus.nhh.no>
	<alpine.LRH.2.00.1005121803170.5691@reclus.nhh.no>
	<alpine.LRH.2.00.1005120914260.19319@reclus.nhh.no>
	<alpine.LRH.2.00.1005111834410.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111758330.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111632010.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111226160.11770@reclus.nhh.no>
	<7fbb8685.9c9e.12886ce7d95.Coremail.huangykiz@163.com>
	<35fc8b41.9509.128878f8dc7.Coremail.huangykiz@163.com>
	<5cd1a7.aaf7.12887db30ba.Coremail.huangykiz@163.com>
	<1721ac8.cd5c.1288828d49a.Coremail.huangykiz@163.com>
	<e41e5d3.ff74.1288a727c78.Coremail.huangykiz@163.com>
	<e30f5db.13f83.1288d18e217.Coremail.huangykiz@163.com>
	<alpine.LRH.2.00.1005121726190.5691@reclus.nhh.no>
	<342188fb.6e7b.12890806f61.Coremail.huangykiz@163.com>
Message-ID: <1a77f94.738a.128918cab0d.Coremail.huangykiz@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100513/4ba130dd/attachment.pl>

From yud at mail.montclair.edu  Thu May 13 14:29:14 2010
From: yud at mail.montclair.edu (Danlin Yu)
Date: Thu, 13 May 2010 08:29:14 -0400
Subject: [R-sig-Geo] How to get the Coefficient of Determination in the
	results of GWR
In-Reply-To: <1a77f94.738a.128918cab0d.Coremail.huangykiz@163.com>
References: <alpine.LRH.2.00.1005131135030.19985@reclus.nhh.no>
	<alpine.LRH.2.00.1005121803170.5691@reclus.nhh.no>
	<alpine.LRH.2.00.1005120914260.19319@reclus.nhh.no>
	<alpine.LRH.2.00.1005111834410.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111758330.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111632010.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111226160.11770@reclus.nhh.no>
	<7fbb8685.9c9e.12886ce7d95.Coremail.huangykiz@163.com>
	<35fc8b41.9509.128878f8dc7.Coremail.huangykiz@163.com>
	<5cd1a7.aaf7.12887db30ba.Coremail.huangykiz@163.com>
	<1721ac8.cd5c.1288828d49a.Coremail.huangykiz@163.com>
	<e41e5d3.ff74.1288a727c78.Coremail.huangykiz@163.com>
	<e30f5db.13f83.1288d18e217.Coremail.huangykiz@163.com>
	<alpine.LRH.2.00.1005121726190.5691@reclus.nhh.no>
	<342188fb.6e7b.12890806f61.Coremail.huangykiz@163.com>
	<1a77f94.738a.128918cab0d.Coremail.huangykiz@163.com>
Message-ID: <9FDCDFCD-C921-4CEB-9B21-988578290B48@mail.montclair.edu>

You shall set "adpt" parameter to 0.1.

Sent from my Iphone
Dr. Danlin Yu
Assistant Professor of GIS, Urban Geography
Earth & Environmental Studies
Montclair State University
Montclair, NJ 07043
Tel: 973-655-4313
Fax: 973-655-4072
Email: yud at mail.montclair.edu

? May 13, 2010?8:03 AM?huangykiz <huangykiz at 163.com> ???

> Hi,
> If I want to  chang the adaptive Spatial Kernel = 10% neighbors in  
> gwr()? How to chang it?
>
> Thank you very much.
>
> Cheers.
>
>
>
>
> ?2010-05-13 17:43:06?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>> On Thu, 13 May 2010, huangykiz wrote:
>>
>>> Hi,
>>
>>> I am sorry I say that I cannot get the same R^2 between in R/spgwr  
>>> and
>>> SAM in my data.
>>
>> Establish that the adaptive proportion is exactly the same.
>>
>> You haven't done that - copy and paste from SAM to gwr(), not using
>> gwr.sel(). Do it first for fixed Gaussian, then if you get a sensible
>> figure from SAM for adaptive, do the same there. I see very different
>> bandwidths chosen by SAM and by gwr.sel() and GWR3 - gwr.sel() and  
>> GWR3
>> usually agree fairly well for CV fixed bandwidths, but gwr.sel()  
>> typically
>> continues its search a little longer than GWR3.
>>
>> I don't know how SAM chooses its bandwidth or adaptive proportion,  
>> it is
>> closed source, so only its authors know.
>>
>> Is SAM using Great Circle distances, if so, you should set  
>> longlat=TRUE in
>> gwr.sel() and gwr()? Are your coordinates geographical (decimal  
>> degrees)
>> or projected (metres)?
>>
>> Roger
>>
>>> In R/spgwr
>>> R^2:    0.972989;
>>> AICc (GWR p. 61, eq 2.33; p. 96, eq. 4.21): 4668.92
>>> Effective number of parameters (model: traceS): 435.7586;
>>> Effective number of parameters (residual: 2traceS - traceS'S): 582.3581 
>>> ;
>>> Sigma (residual: 2traceS - traceS'S): 2.437066;
>>> Sigma (model: traceS): 1.927127;
>>> Sigma (ML): 1.325501;
>>>
>>> In SAM,
>>> Coefficient of Determination :           0.696
>>> Adjusted r-square (r?Adj):                 0.693
>>> Sigma:                                             20.058
>>> Effective Number of Parameters:          10.002
>>> Akaike Information Criterion (AICc):      4838.299
>>> Correlation Coefficient (r):                    0.834
>>> F:                                                   207.852
>>>
>>> Here are my code:
>>> PET.adapt.gauss <- gwr.sel(SPECIES_RI ~ PET,  
>>> data=Environmental_variables, coords=cbind(Environmental_variables 
>>> $LONGX,
>>> Environmental_variables$LATY),adapt=TRUE)
>>>
>>> PET.gauss<- gwr(SPECIES_RI ~ PET, data=Environmental_variables,  
>>> coords=cbind(Environmental_variables$LONGX,
>>> Environmental_variables$LATY),  
>>> gweight=gwr.Gauss,adapt=PET.adapt.gauss,hatmatrix=TRUE)
>>>
>>> 1 - (PET.gauss$results$rss/crossprod(scale(Environmental_variables 
>>> $SPECIES_RI, scale=FALSE)))
>>>
>>> In SAM, I selecte "spatial Weighting Function"=gaussian, adaptive
>>> Spatial Kernel, and compute Geographical Distances based on  
>>> longitudinal
>>> coordinate(X) and latitudinal coordinate(Y). I donot select method  
>>> for
>>> AIC optimisation.
>>>
>>> So I donot know where is wrong.
>>>
>>> Thank you very much for your great helps.
>>>
>>>
>>>
>>>
>>>
>>>
>>> ?2010-05-13 00:07:23?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>> On Wed, 12 May 2010, Roger Bivand wrote:
>>>>
>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>>>>
>>>>>> Hi, Is "adapt=TRUE"(spgwr) not the same as "adaptive Spatial
>>>>>> Kernel"(SAM)?The result of "adaptive Spatial Kernel" may be  
>>>>>> better than
>>>>>> fixed bandwidth. If I want to ues "adaptive Spatial Kernel" in  
>>>>>> spgwr, how
>>>>>> to write the code?
>>>>>
>>>>> READ THE HELP PAGES!
>>>>>
>>>>> adaptive_proportion <- gwr.sel(...)
>>>>>
>>>>> result <- gwr(..., adapt=adaptive_proportion; ...)
>>>>>
>>>>> exactly as on the example om the help page:
>>>>>
>>>>> data(georgia)
>>>>> g.adapt.gauss <- gwr.sel(PctBach ~ TotPop90 + PctRural + PctEld  
>>>>> + PctFB +
>>>>> PctPov + PctBlack, data=gSRDF, adapt=TRUE)
>>>>> res.adpt <- gwr(PctBach ~ TotPop90 + PctRural + PctEld + PctFB +  
>>>>> PctPov +
>>>>> PctBlack, data=gSRDF, adapt=g.adapt.gauss)
>>>>> res.adpt
>>>>>
>>>>> Clear?
>>>>
>>>> I have now compared the same data in R/spgwr and SAM for  
>>>> effective number
>>>> of parameters, sigma, and your questionable R^2, and they agree  
>>>> adequately
>>>> when the kernel and the bandwidth are the same. Having the  
>>>> algorithm
>>>> choose the bandwidth does obscure what is going on. You should  
>>>> use SAM if
>>>> you prefer GUI and not needing to know how things work, and  
>>>> remember that
>>>> GWR is a very doubtful approach for anything beyond exploring
>>>> non-stationarity, its original motivation.
>>>>
>>>>>
>>>>>>
>>>>>> Thanks a lot.
>>>>>>
>>>>>> Cheers.
>>>>>>
>>>>>>
>>>>>>> Hi,
>>>>>>> I think that I use the same bandwidth and kernel. In SAM, I  
>>>>>>> use "spatial
>>>>>>> Weighting Function"=gaussian, adaptive Spatial Kernel, and  
>>>>>>> compute
>>>>>>> Geographical Distances based on longitudinal coordinate(X) and  
>>>>>>> latitudinal
>>>>>>> coordinate(Y). In spgwr, gweight is gwr.Gauss and adapt is TRUE.
>>>>>>>
>>>>>>> For example, this is my code:
>>>>>>
>>>>>>> PET.bw <- gwr.sel(SPECIES_RI ~ PET, data=variables,
>>>>>>> coords=cbind(variables$LONGX, variables$LATY),adapt=TRUE)
>>>>>>
>>>>>>> PET.gauss <- gwr(SPECIES_RI ~ PET, data=variables,
>>>>>>> coords=cbind(variables$LONGX, variables$LATY), bandwidth=PET.bw,
>>>>>>> gweight=gwr.Gauss,adapt=TRUE,hatmatrix=TRUE)
>>>>>>
>>>>>> So where do you pass PET.bw to the gwr() function? adapt=TRUE  
>>>>>> will treat
>>>>>> the adaptive proportion as 1, so include all data points. If  
>>>>>> you want to
>>>>>> compare, use a fixed bandwidth in both, with no CV selection.  
>>>>>> Then you
>>>>>> compare like with like.
>>>>>>
>>>>>> Note that your messages are *not* reaching the list, they must  
>>>>>> be sent to:
>>>>>>
>>>>>> r-sig-geo at stat.math.ethz.ch, not
>>>>>>
>>>>>> r-sig-geo-request at stat.math.ethz.ch
>>>>>>
>>>>>> You are not thinking carefully and are rushing into things and  
>>>>>> drawing
>>>>>> wrong conclusions.
>>>>>>
>>>>>>>
>>>>>>> Thanks a lot.
>>>>>>>
>>>>>>> Cheers.
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> ?2010-05-12 20:28:47?"Roger Bivand" <Roger.Bivand at nhh 
>>>>>>> .no> ???
>>>>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>>>>>>>
>>>>>>>>> Hi,
>>>>>>>>> One of SAM author ("Jos? Alexandre Felizola Diniz
>>>>>>>>> Filho"<diniz at icb.ufg.br>) say that they also base on GWR3 (the
>>>>>>>>> Fotherigham book)  and the data used within each kernel may  
>>>>>>>>> be some
>>>>>>>>> slight differences
>>>>>>>>
>>>>>>>> Naturally, if you are not using exactly the same kernel and  
>>>>>>>> bandwidth,
>>>>>>>> you should not be surprised by differences in values. Please  
>>>>>>>> make sure
>>>>>>>> that the bandwidth and kernel are the same and try again.
>>>>>>>>
>>>>>>>> Roger
>>>>>>>>
>>>>>>>>> Cheers
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> ?2010-05-12 20:28:47?"Roger Bivand" <Roger.Bivand at nhh. 
>>>>>> no> ???
>>>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>>>>>>
>>>>>>>> Hi,
>>>>>>>> One of SAM author ("Jos? Alexandre Felizola Diniz
>>>>>>>> Filho"<diniz at icb.ufg.br>) say that they also base on GWR3 (the
>>>>>>>> Fotherigham book)  and the data used within each kernel may  
>>>>>>>> be some
>>>>>>>> slight differences
>>>>>>>
>>>>>>> Naturally, if you are not using exactly the same kernel and  
>>>>>>> bandwidth, you
>>>>>>> should not be surprised by differences in values. Please make  
>>>>>>> sure that
>>>>>>> the bandwidth and kernel are the same and try again.
>>>>>>>
>>>>>>> Roger
>>>>>>>
>>>>>>>> Cheers.
>>>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> ?2010-05-12 15:27:58?"Roger Bivand" <Roger.Bivand at nhh. 
>>>>>> no> ???
>>>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>>>>>>
>>>>>>>> Hi,
>>>>>>>>
>>>>>>>> I am sorry I donot know how to install module spgwr from  
>>>>>>>> sourceforge (I
>>>>>>>> can find it on the web
>>>>>>>> http://r-spatial.cvs.sourceforge.net/viewvc/r-spatial/spgwr/R/gwr.R?view=log 
>>>>>>>> ).
>>>>>>>> So I use the code sketch to calculate quasi-global R2. The  
>>>>>>>> results are
>>>>>>>> different between SAM and spgwr(Attached are the results ). The
>>>>>>>> quasi-global R2 in R is 0.4515894, but in SAM is 0.696.
>>>>>>>> This is my code:
>>>>>>>>
>>>>>>>> library(spgwr)
>>>>>>>> Environmental_variables<-read.csv 
>>>>>>>> ("Environmental_variables100.csv",header=TRUE)
>>>>>>>> attach(Environmental_variables)
>>>>>>>> region_PET.bw <- gwr.sel(SPECIES_RI ~ PET,  
>>>>>>>> data=Environmental_variables,
>>>>>>>> coords=cbind(Environmental_variables$LONGX,
>>>>>>>> Environmental_variables$LATY),adapt=TRUE)
>>>>>>>> region_PET.gauss <- gwr(SPECIES_RI ~ PET,  
>>>>>>>> data=Environmental_variables,
>>>>>>>> coords=cbind(Environmental_variables$LONGX,
>>>>>>>> Environmental_variables$LATY), bandwidth=region_PET.bw,
>>>>>>>> gweight=gwr.Gauss,adapt=TRUE,hatmatrix=TRUE)
>>>>>>>> names(region_PET.gauss$SDF)
>>>>>>>> region_PET.gauss$SDF$localR2
>>>>>>>> 1 -
>>>>>>>> (region_PET.gauss$results$rss/crossprod(scale 
>>>>>>>> (Environmental_variables$SPECIES_RI,
>>>>>>>> scale=FALSE)))
>>>>>>>>
>>>>>>>> Thank you very much.
>>>>>>>
>>>>>>> SAM is closed source - ask them how they compute it. For  
>>>>>>> spgwr, the code
>>>>>>> is provided, so you can read it for yourself. For the record,  
>>>>>>> the current
>>>>>>> gwr() code in spgwr gives the same value as GWR3, which is  
>>>>>>> also closed
>>>>>>> source, and where the Effective number of parameters (model:  
>>>>>>> traceS),
>>>>>>> Sigma, and Residual sum of squares also agree. I suppose SAM  
>>>>>>> has a
>>>>>>> different understanding of GWR internals than the authors of  
>>>>>>> the GWR book.
>>>>>>>
>>>>>>> Once again:
>>>>>>>
>>>>>>> Please *do* write to the R-sig-geo list rather than to me  
>>>>>>> directly -
>>>>>>> others can answer your question as well, perhaps better, and  
>>>>>>> in a more
>>>>>>> timely way than I can. In addition, threads in the list can be  
>>>>>>> searched in
>>>>>>> the archives, so others can avoid the same problem later.
>>>>>>>
>>>>>>> Please summarise to the list if this resolves the problem.
>>>>>>>
>>>>>>> Roger
>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> ?2010-05-12 01:16:18?"Roger Bivand" <Roger.Bivand at nh 
>>>>>>>> h.no> ???
>>>>>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>>>>>>>>
>>>>>>>>>> Hi, I just need one for global, not *each* fit point. In  
>>>>>>>>>> this case, how
>>>>>>>>>> can I select or do? Why in other software such as SAM 
>>>>>>>>>> (Spatial Analysis
>>>>>>>>>> in Macroecology) just gives one R2?
>>>>>>>>>
>>>>>>>>> If you believe theirs, good luck! The authors of the GWR  
>>>>>>>>> book have local
>>>>>>>>> R^2 values in GWR3 and formulae that are wrong by their own  
>>>>>>>>> admission in
>>>>>>>>> private emails. The localR2 now agrees with the as-yet  
>>>>>>>>> unreleased GWR4
>>>>>>>>> from the GWR authors. How SAM can be "better", I don't know.  
>>>>>>>>> What you
>>>>>>>>> are suggesting is that the model fitted with fit points at  
>>>>>>>>> data points
>>>>>>>>> (but not at other fit points) might have a "quasi-global"  
>>>>>>>>> R^2, based on
>>>>>>>>> the RSS of the pooled fit. For the columbus case, that might  
>>>>>>>>> be:
>>>>>>>>>
>>>>>>>>> 1 - (col.gauss$results$rss/crossprod(scale(columbus$crime,
>>>>>>>>> scale=FALSE)))
>>>>>>>>>
>>>>>>>>> but I don't know whether this is in any way correct. I've  
>>>>>>>>> added it as:
>>>>>>>>>
>>>>>>>>> Quasi-global R2:
>>>>>>>>>
>>>>>>>>> to the print output of a GWR model fitted with a hatmatrix,  
>>>>>>>>> and have
>>>>>>>>> committed it to sourceforge, project r-spatial, module  
>>>>>>>>> spgwr. Arguably,
>>>>>>>>> it ought to be adjusted by the ratio of degrees of freedom,  
>>>>>>>>> but I don't
>>>>>>>>> trust the DF either. Could you please check out spgwr from  
>>>>>>>>> sourceforge
>>>>>>>>> ,install it from source, and confirm that the "quasi-global  
>>>>>>>>> R2" does the
>>>>>>>>> same as SAM, or use the code sketch above to do the same,  
>>>>>>>>> and report
>>>>>>>>> back?
>>>>>>>>>
>>>>>>>>> Roger
>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> Thanks a lot.
>>>>>>>>>>
>>>>>>>>>> Cheers,
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> ?2010-05-11 23:59:44?"Roger Bivand" <Roger.Bivand@ 
>>>>>>>>>> nhh.no> ???
>>>>>>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>>>>>>>>>>
>>>>>>>>>>>> Hi,
>>>>>>>>>>>>
>>>>>>>>>>>> There are 49  localR2 in the results. Which one do I  
>>>>>>>>>>>> need? The code
>>>>>>>>>>>> "look for localR2:" cannot run.
>>>>>>>>>>>
>>>>>>>>>>> Well, how many do you want? There is one for each fit  
>>>>>>>>>>> point, they are
>>>>>>>>>>> *local* R2. Please do try to grasp what GWR does - it fits  
>>>>>>>>>>> one moddel
>>>>>>>>>>> for *each* fit point.
>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> Thans a lot
>>>>>>>>>>>>
>>>>>>>>>>>> Cheers.
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> ?2010-05-11 22:33:59?"Roger Bivand" <Roger.Biv 
>>>>>>>>>>>> and at nhh.no> ???
>>>>>>>>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>>>>>>>>>>>>
>>>>>>>>>>>>>> Hi, OK. But I need it for compariation. In what some  
>>>>>>>>>>>>>> contexts to
>>>>>>>>>>>>>> get it? May you tell me how to get it?
>>>>>>>>>>>>>
>>>>>>>>>>>>> library(spgwr)
>>>>>>>>>>>>> data(columbus)
>>>>>>>>>>>>> col.bw <- gwr.sel(crime ~ income + housing, data=columbus,
>>>>>>>>>>>>> coords=cbind(columbus$x, columbus$y))
>>>>>>>>>>>>> col.gauss <- gwr(crime ~ income + housing, data=columbus,
>>>>>>>>>>>>> coords=cbind(columbus$x, columbus$y), bandwidth=col.bw,
>>>>>>>>>>>>> hatmatrix=TRUE)
>>>>>>>>>>>>> names(col.gauss$SDF)
>>>>>>>>>>>>>
>>>>>>>>>>>>> look for localR2:
>>>>>>>>>>>>>
>>>>>>>>>>>>> col.gauss$SDF$localR2
>>>>>>>>>>>>>
>>>>>>>>>>>>> But do not rely on it or use it for anything at all!  
>>>>>>>>>>>>> Like all GWR,
>>>>>>>>>>>>> it is most unreliable!
>>>>>>>>>>>>>
>>>>>>>>>>>>> Roger Bivand
>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Thank you very much for your great helps
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Best regards.
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> ?2010-05-11 18:28:44?"Roger Bivand" <Roger 
>>>>>>>>>>>>>> .Bivand at nhh.no> ???
>>>>>>>>>>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> Dear professor Bivand,
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> I am a strudent. I recently use GWR(Geographically  
>>>>>>>>>>>>>>>> weighted
>>>>>>>>>>>>>>>> regression) model. May I ask you a question? There is  
>>>>>>>>>>>>>>>> not
>>>>>>>>>>>>>>>> Coefficient of Determination in the results of GWR.  
>>>>>>>>>>>>>>>> How can I get
>>>>>>>>>>>>>>>> it? What is the programs to get it?
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Please address questions like this to the R-sig-geo  
>>>>>>>>>>>>>>> list rather
>>>>>>>>>>>>>>> than to me directly in future.
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> The local R2 values are available in some contexts  
>>>>>>>>>>>>>>> when running
>>>>>>>>>>>>>>> gwr(), but are not well defined (neither in the GWR  
>>>>>>>>>>>>>>> book nor in
>>>>>>>>>>>>>>> implementations). I advise against their use - they  
>>>>>>>>>>>>>>> are most
>>>>>>>>>>>>>>> probably meaningless.
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Hope this helps,
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> Roger Bivand
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> Thank you very much for your any helps.
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> Best regards.
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> Yong Huang
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> -- 
>>>>>>>>>>>>>>> Roger Bivand
>>>>>>>>>>>>>>> Economic Geography Section, Department of Economics,  
>>>>>>>>>>>>>>> Norwegian
>>>>>>>>>>>>>>> School of
>>>>>>>>>>>>>>> Economics and Business Administration, Helleveien 30,  
>>>>>>>>>>>>>>> N-5045
>>>>>>>>>>>>>>> Bergen,
>>>>>>>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>>>>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>> -- 
>>>>>>>>>>>>> Roger Bivand
>>>>>>>>>>>>> Economic Geography Section, Department of Economics,  
>>>>>>>>>>>>> Norwegian
>>>>>>>>>>>>> School of
>>>>>>>>>>>>> Economics and Business Administration, Helleveien 30,  
>>>>>>>>>>>>> N-5045 Bergen,
>>>>>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>>>>>>>
>>>>>>>>>>> -- 
>>>>>>>>>>> Roger Bivand
>>>>>>>>>>> Economic Geography Section, Department of Economics,  
>>>>>>>>>>> Norwegian School
>>>>>>>>>>> of
>>>>>>>>>>> Economics and Business Administration, Helleveien 30,  
>>>>>>>>>>> N-5045 Bergen,
>>>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>>>>>
>>>>>>>>> -- 
>>>>>>>>> Roger Bivand
>>>>>>>>> Economic Geography Section, Department of Economics,  
>>>>>>>>> Norwegian School of
>>>>>>>>> Economics and Business Administration, Helleveien 30, N-5045  
>>>>>>>>> Bergen,
>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>>>
>>>>>>> -- 
>>>>>>> Roger Bivand
>>>>>>> Economic Geography Section, Department of Economics, Norwegian  
>>>>>>> School of
>>>>>>> Economics and Business Administration, Helleveien 30, N-5045  
>>>>>>> Bergen,
>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>
>>>>>
>>>>
>>>> -- 
>>>> Roger Bivand
>>>> Economic Geography Section, Department of Economics, Norwegian  
>>>> School of
>>>> Economics and Business Administration, Helleveien 30, N-5045  
>>>> Bergen,
>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>> e-mail: Roger.Bivand at nhh.no
>>
>> -- 
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian  
>> School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>
>    [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From huangykiz at 163.com  Thu May 13 15:04:20 2010
From: huangykiz at 163.com (huangykiz)
Date: Thu, 13 May 2010 21:04:20 +0800 (CST)
Subject: [R-sig-Geo] How to get the Coefficient of Determination in the
 results of GWR
In-Reply-To: <9FDCDFCD-C921-4CEB-9B21-988578290B48@mail.montclair.edu>
References: <9FDCDFCD-C921-4CEB-9B21-988578290B48@mail.montclair.edu>
	<alpine.LRH.2.00.1005131135030.19985@reclus.nhh.no>
	<alpine.LRH.2.00.1005121803170.5691@reclus.nhh.no>
	<alpine.LRH.2.00.1005120914260.19319@reclus.nhh.no>
	<alpine.LRH.2.00.1005111834410.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111758330.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111632010.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111226160.11770@reclus.nhh.no>
	<7fbb8685.9c9e.12886ce7d95.Coremail.huangykiz@163.com>
	<35fc8b41.9509.128878f8dc7.Coremail.huangykiz@163.com>
	<5cd1a7.aaf7.12887db30ba.Coremail.huangykiz@163.com>
	<1721ac8.cd5c.1288828d49a.Coremail.huangykiz@163.com>
	<e41e5d3.ff74.1288a727c78.Coremail.huangykiz@163.com>
	<e30f5db.13f83.1288d18e217.Coremail.huangykiz@163.com>
	<alpine.LRH.2.00.1005121726190.5691@reclus.nhh.no>
	<342188fb.6e7b.12890806f61.Coremail.huangykiz@163.com>
	<1a77f94.738a.128918cab0d.Coremail.huangykiz@163.com>
Message-ID: <16d8a50.6301.12891c3fe03.Coremail.huangykiz@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100513/228c3b9a/attachment.pl>

From yud at mail.montclair.edu  Thu May 13 15:34:48 2010
From: yud at mail.montclair.edu (Danlin Yu)
Date: Thu, 13 May 2010 09:34:48 -0400
Subject: [R-sig-Geo] How to get the Coefficient of Determination in the
 results of GWR
In-Reply-To: <16d8a50.6301.12891c3fe03.Coremail.huangykiz@163.com>
References: <9FDCDFCD-C921-4CEB-9B21-988578290B48@mail.montclair.edu>
	<alpine.LRH.2.00.1005131135030.19985@reclus.nhh.no>
	<alpine.LRH.2.00.1005121803170.5691@reclus.nhh.no>
	<alpine.LRH.2.00.1005120914260.19319@reclus.nhh.no>
	<alpine.LRH.2.00.1005111834410.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111758330.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111632010.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111226160.11770@reclus.nhh.no>
	<7fbb8685.9c9e.12886ce7d95.Coremail.huangykiz@163.com>
	<35fc8b41.9509.128878f8dc7.Coremail.huangykiz@163.com>
	<5cd1a7.aaf7.12887db30ba.Coremail.huangykiz@163.com>
	<1721ac8.cd5c.1288828d49a.Coremail.huangykiz@163.com>
	<e41e5d3.ff74.1288a727c78.Coremail.huangykiz@163.com>
	<e30f5db.13f83.1288d18e217.Coremail.huangykiz@163.com>
	<alpine.LRH.2.00.1005121726190.5691@reclus.nhh.no>
	<342188fb.6e7b.12890806f61.Coremail.huangykiz@163.com>
	<1a77f94.738a.128918cab0d.Coremail.huangykiz@163.com>
	<16d8a50.6301.12891c3fe03.Coremail.huangykiz@163.com>
Message-ID: <4BEBFFF8.9050508@mail.montclair.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100513/2cb15407/attachment.pl>

From huangykiz at 163.com  Thu May 13 16:02:53 2010
From: huangykiz at 163.com (huangykiz)
Date: Thu, 13 May 2010 22:02:53 +0800 (CST)
Subject: [R-sig-Geo] How to get the Coefficient of Determination in the
 results of GWR
In-Reply-To: <4BEBFFF8.9050508@mail.montclair.edu>
References: <4BEBFFF8.9050508@mail.montclair.edu>
	<9FDCDFCD-C921-4CEB-9B21-988578290B48@mail.montclair.edu>
	<alpine.LRH.2.00.1005131135030.19985@reclus.nhh.no>
	<alpine.LRH.2.00.1005121803170.5691@reclus.nhh.no>
	<alpine.LRH.2.00.1005120914260.19319@reclus.nhh.no>
	<alpine.LRH.2.00.1005111834410.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111758330.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111632010.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111226160.11770@reclus.nhh.no>
	<7fbb8685.9c9e.12886ce7d95.Coremail.huangykiz@163.com>
	<35fc8b41.9509.128878f8dc7.Coremail.huangykiz@163.com>
	<5cd1a7.aaf7.12887db30ba.Coremail.huangykiz@163.com>
	<1721ac8.cd5c.1288828d49a.Coremail.huangykiz@163.com>
	<e41e5d3.ff74.1288a727c78.Coremail.huangykiz@163.com>
	<e30f5db.13f83.1288d18e217.Coremail.huangykiz@163.com>
	<alpine.LRH.2.00.1005121726190.5691@reclus.nhh.no>
	<342188fb.6e7b.12890806f61.Coremail.huangykiz@163.com>
	<1a77f94.738a.128918cab0d.Coremail.huangykiz@163.com>
	<16d8a50.6301.12891c3fe03.Coremail.huangykiz@163.com>
Message-ID: <198c2c9.66fd.12891f999c4.Coremail.huangykiz@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100513/0f412b6d/attachment.pl>

From huangykiz at 163.com  Thu May 13 16:03:52 2010
From: huangykiz at 163.com (huangykiz)
Date: Thu, 13 May 2010 22:03:52 +0800 (CST)
Subject: [R-sig-Geo] How to get the Coefficient of Determination in the
 results of GWR
In-Reply-To: <4BEBFFF8.9050508@mail.montclair.edu>
References: <4BEBFFF8.9050508@mail.montclair.edu>
	<9FDCDFCD-C921-4CEB-9B21-988578290B48@mail.montclair.edu>
	<alpine.LRH.2.00.1005131135030.19985@reclus.nhh.no>
	<alpine.LRH.2.00.1005121803170.5691@reclus.nhh.no>
	<alpine.LRH.2.00.1005120914260.19319@reclus.nhh.no>
	<alpine.LRH.2.00.1005111834410.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111758330.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111632010.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111226160.11770@reclus.nhh.no>
	<7fbb8685.9c9e.12886ce7d95.Coremail.huangykiz@163.com>
	<35fc8b41.9509.128878f8dc7.Coremail.huangykiz@163.com>
	<5cd1a7.aaf7.12887db30ba.Coremail.huangykiz@163.com>
	<1721ac8.cd5c.1288828d49a.Coremail.huangykiz@163.com>
	<e41e5d3.ff74.1288a727c78.Coremail.huangykiz@163.com>
	<e30f5db.13f83.1288d18e217.Coremail.huangykiz@163.com>
	<alpine.LRH.2.00.1005121726190.5691@reclus.nhh.no>
	<342188fb.6e7b.12890806f61.Coremail.huangykiz@163.com>
	<1a77f94.738a.128918cab0d.Coremail.huangykiz@163.com>
	<16d8a50.6301.12891c3fe03.Coremail.huangykiz@163.com>
Message-ID: <1b68087.6708.12891fa812c.Coremail.huangykiz@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100513/f3d7c02d/attachment.pl>

From yud at mail.montclair.edu  Thu May 13 17:10:38 2010
From: yud at mail.montclair.edu (Danlin Yu)
Date: Thu, 13 May 2010 11:10:38 -0400
Subject: [R-sig-Geo] How to get the Coefficient of Determination in the
 results of GWR
In-Reply-To: <1b68087.6708.12891fa812c.Coremail.huangykiz@163.com>
References: <4BEBFFF8.9050508@mail.montclair.edu>
	<alpine.LRH.2.00.1005121803170.5691@reclus.nhh.no>
	<alpine.LRH.2.00.1005120914260.19319@reclus.nhh.no>
	<alpine.LRH.2.00.1005111834410.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111758330.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111632010.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111226160.11770@reclus.nhh.no>
	<7fbb8685.9c9e.12886ce7d95.Coremail.huangykiz@163.com>
	<35fc8b41.9509.128878f8dc7.Coremail.huangykiz@163.com>
	<5cd1a7.aaf7.12887db30ba.Coremail.huangykiz@163.com>
	<1721ac8.cd5c.1288828d49a.Coremail.huangykiz@163.com>
	<e41e5d3.ff74.1288a727c78.Coremail.huangykiz@163.com>
	<e30f5db.13f83.1288d18e217.Coremail.huangykiz@163.com>
	<alpine.LRH.2.00.1005121726190.5691@reclus.nhh.no>
	<342188fb.6e7b.12890806f61.Coremail.huangykiz@163.com>
	<1a77f94.738a.128918cab0d.Coremail.huangykiz@163.com>
	<16d8a50.6301.12891c3fe03.Coremail.huangykiz@163.com>
	<1b68087.6708.12891fa812c.Coremail.huangykiz@163.com>
Message-ID: <4BEC166E.5010602@mail.montclair.edu>



huangykiz ????:
> Hi,
> *I know that a proportion of "adapt" between 0 and 1*.For example, 
> values below are calculated using adapt=TRUE, and then in gwr(), it 
> will use the best adapt q=0.0008484767 (the last line) to compute. But 
> I just want to ues adapt q=0.1(the red line) to compute in gwr() next, 
> not adapt q=0.0008484767 (the last line). So I mean how to get the 10% 
> proportion value and how to write it in gwr(), not just 
> adaptive_proportion <- gwr.sel(...); */result <- gwr(..., 
> adapt=adaptive_proportion; ...)./*
So you set the argument "adapt" in gwr() as 0.1.

Really, these two lines "adaptive_proportion <- gwr.sel(...); */result 
<- gwr(..., adapt=adaptive_proportion; ...)/* were written together for 
your to understand that the argument "adapt" is how you set the 
proportion as the adaptive bandwidth in gwr(), if you understand the 
context, you shall know that in the function gwr(), "adapt" can be equal 
to other values (proportions of the total data points) other than the 
one obtained via gwr.sel(). Actually, you said that yourself 
(highlighted above).

Always asking questions is a good learning habit, but asking questions 
without thinking might not be that good.

Is that clear enough?

Danlin
> Adaptive q: 0.381966 CV score: 24370.57
> Adaptive q: 0.618034 CV score: 27368.81
> Adaptive q: 0.236068 CV score: 21363.70
> Adaptive q: 0.1458980 CV score: 18875.33
> Adaptive q: 0.09016994 CV score: 16519.28
> Adaptive q: 0.05572809 CV score: 14424.12
> Adaptive q: 0.03444185 CV score: 12722.21
> Adaptive q: 0.02128624 CV score: 11354.84
> Adaptive q: 0.01315562 CV score: 10373.59
> Adaptive q: 0.008130619 CV score: 8748.126
> Adaptive q: 0.005024999 CV score: 7748.467
> Adaptive q: 0.00310562 CV score: 7251.083
> Adaptive q: 0.001919379 CV score: 6869.442
> Adaptive q: 0.001186241 CV score: 6769.606
> Adaptive q: 0.0008484767 CV score: 6343.859
> Adaptive q: 0.0005243874 CV score: 7706.465
> Adaptive q: 0.0009774913 CV score: 6428.712
> Adaptive q: 0.0007990996 CV score: 6356.182
> Adaptive q: 0.0008891668 CV score: 6354.715
> Adaptive q: 0.0008484767 CV score: 6343.859
> Thank you very much for your any helps.
> Cheers.
>
> ??2010-05-13 21:34:48??"Danlin Yu" <yud at mail.montclair.edu> ??????
>
>     In gwr(), it's actually adapt = 0.1. It was a typo in my previous
>     email. And actually before you ask this question, you shall really
>     follow what Roger said, "READ THE HELP PAGES". Do some homework
>     (Roger has already answered your question in his previous email,
>     highlights by me, see:
>
>     >>>>>> READ THE HELP PAGES!
>     >>>>>>
>     >>>>>> adaptive_proportion <- gwr.sel(...)
>     >>>>>>
>     >>>>>> /*result <- gwr(..., adapt=adaptive_proportion; ...)*/
>     >>>>>>
>     >>>>>> exactly as on the example om the help page:
>     >>>>>>
>     >>>>>> data(georgia)
>     >>>>>> g.adapt.gauss <- gwr.sel(PctBach ~ TotPop90 + PctRural +
>     PctEld
>     >>>>>> + PctFB +
>     >>>>>> PctPov + PctBlack, data=gSRDF, adapt=TRUE)
>     >>>>>> res.adpt <- gwr(PctBach ~ TotPop90 + PctRural + PctEld +
>     PctFB +
>     >>>>>> PctPov +
>     >>>>>> PctBlack, data=gSRDF, adapt=g.adapt.gauss)
>     >>>>>> res.adpt
>
>     )
>
>     In addition, if you are considering using R quite often, I would
>     suggest you try to read the codes that are provided by simply
>     typing the name of the function. This way, you'll learn about the
>     parameters, how they are used, what results are produced and how
>     they are produced, etc. The open-source codes will certainly tell
>     you "more detail" (more than you could imagine, I'd say).
>
>     Hope this helps.
>
>     Cheers,
>     Danlin
>
>     huangykiz ????:
>>     Hi,
>>     Set In gwr.sel() or gwr()?. How to write the code about set
>>     "adpt" parameter to 0.1? May you tell more detail.
>>     Thank you very much.
>>     Cheers,
>>
>>     ??2010-05-13 20:29:14??"Danlin Yu" <yud at mail.montclair.edu> ??????
>>     >You shall set "adpt" parameter to 0.1.
>>     >
>>     >Sent from my Iphone
>>     >Dr. Danlin Yu
>>     >Assistant Professor of GIS, Urban Geography
>>     >Earth & Environmental Studies
>>     >Montclair State University
>>     >Montclair, NJ 07043
>>     >Tel: 973-655-4313
>>     >Fax: 973-655-4072
>>     >Email: yud at mail.montclair.edu
>>     >
>>     >?? May 13, 2010??8:03 AM??huangykiz <huangykiz at 163.com> ??????
>>     >
>>     >> Hi,
>>     >> If I want to chang the adaptive Spatial Kernel = 10% neighbors in
>>     >> gwr()? How to chang it?
>>     >>
>>     >> Thank you very much.
>>     >>
>>     >> Cheers.
>>     >>
>>     >>
>>     >>
>>     >>
>>     >> ??2010-05-13 17:43:06??"Roger Bivand" <Roger.Bivand at nhh.no> ??????
>>     >>> On Thu, 13 May 2010, huangykiz wrote:
>>     >>>
>>     >>>> Hi,
>>     >>>
>>     >>>> I am sorry I say that I cannot get the same R^2 between in
>>     R/spgwr
>>     >>>> and
>>     >>>> SAM in my data.
>>     >>>
>>     >>> Establish that the adaptive proportion is exactly the same.
>>     >>>
>>     >>> You haven't done that - copy and paste from SAM to gwr(), not
>>     using
>>     >>> gwr.sel(). Do it first for fixed Gaussian, then if you get a
>>     sensible
>>     >>> figure from SAM for adaptive, do the same there. I see very
>>     different
>>     >>> bandwidths chosen by SAM and by gwr.sel() and GWR3 -
>>     gwr.sel() and
>>     >>> GWR3
>>     >>> usually agree fairly well for CV fixed bandwidths, but gwr.sel()
>>     >>> typically
>>     >>> continues its search a little longer than GWR3.
>>     >>>
>>     >>> I don't know how SAM chooses its bandwidth or adaptive
>>     proportion,
>>     >>> it is
>>     >>> closed source, so only its authors know.
>>     >>>
>>     >>> Is SAM using Great Circle distances, if so, you should set
>>     >>> longlat=TRUE in
>>     >>> gwr.sel() and gwr()? Are your coordinates geographical (decimal
>>     >>> degrees)
>>     >>> or projected (metres)?
>>     >>>
>>     >>> Roger
>>     >>>
>>     >>>> In R/spgwr
>>     >>>> R^2: 0.972989;
>>     >>>> AICc (GWR p. 61, eq 2.33; p. 96, eq. 4.21): 4668.92
>>     >>>> Effective number of parameters (model: traceS): 435.7586;
>>     >>>> Effective number of parameters (residual: 2traceS -
>>     traceS'S): 582.3581
>>     >>>> ;
>>     >>>> Sigma (residual: 2traceS - traceS'S): 2.437066;
>>     >>>> Sigma (model: traceS): 1.927127;
>>     >>>> Sigma (ML): 1.325501;
>>     >>>>
>>     >>>> In SAM,
>>     >>>> Coefficient of Determination : 0.696
>>     >>>> Adjusted r-square (r?Adj): 0.693
>>     >>>> Sigma: 20.058
>>     >>>> Effective Number of Parameters: 10.002
>>     >>>> Akaike Information Criterion (AICc): 4838.299
>>     >>>> Correlation Coefficient (r): 0.834
>>     >>>> F: 207.852
>>     >>>>
>>     >>>> Here are my code:
>>     >>>> PET.adapt.gauss <- gwr.sel(SPECIES_RI ~ PET,
>>     >>>> data=Environmental_variables,
>>     coords=cbind(Environmental_variables
>>     >>>> $LONGX,
>>     >>>> Environmental_variables$LATY),adapt=TRUE)
>>     >>>>
>>     >>>> PET.gauss<- gwr(SPECIES_RI ~ PET, data=Environmental_variables,
>>     >>>> coords=cbind(Environmental_variables$LONGX,
>>     >>>> Environmental_variables$LATY),
>>     >>>> gweight=gwr.Gauss,adapt=PET.adapt.gauss,hatmatrix=TRUE)
>>     >>>>
>>     >>>> 1 -
>>     (PET.gauss$results$rss/crossprod(scale(Environmental_variables
>>     >>>> $SPECIES_RI, scale=FALSE)))
>>     >>>>
>>     >>>> In SAM, I selecte "spatial Weighting Function"=gaussian,
>>     adaptive
>>     >>>> Spatial Kernel, and compute Geographical Distances based on
>>     >>>> longitudinal
>>     >>>> coordinate(X) and latitudinal coordinate(Y). I donot select
>>     method
>>     >>>> for
>>     >>>> AIC optimisation.
>>     >>>>
>>     >>>> So I donot know where is wrong.
>>     >>>>
>>     >>>> Thank you very much for your great helps.
>>     >>>>
>>     >>>>
>>     >>>>
>>     >>>>
>>     >>>>
>>     >>>>
>>     >>>> ??2010-05-13 00:07:23??"Roger Bivand" < Roger.Bivand at nhh.no>
>>     ??????
>>     >>>>> On Wed, 12 May 2010, Roger Bivand wrote:
>>     >>>>>
>>     >>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>     >>>>>>
>>     >>>>>>> Hi, Is "adapt=TRUE"(spgwr) not the same as "adaptive Spatial
>>     >>>>>>> Kernel"(SAM)?The result of "adaptive Spatial Kernel" may be
>>     >>>>>>> better than
>>     >>>>>>> fixed bandwidth. If I want to ues "adaptive Spatial
>>     Kernel" in
>>     >>>>>>> spgwr, how
>>     >>>>>>> to write the code?
>>     >>>>>>
>>     >>>>>> READ THE HELP PAGES!
>>     >>>>>>
>>     >>>>>> adaptive_proportion <- gwr.sel(...)
>>     >>>>>>
>>     >>>>>> result <- gwr(..., adapt=adaptive_proportion; ...)
>>     >>>>>>
>>     >>>>>> exactly as on the example om the help page:
>>     >>>>>>
>>     >>>>>> data(georgia)
>>     >>>>>> g.adapt.gauss <- gwr.sel(PctBach ~ TotPop90 + PctRural +
>>     PctEld
>>     >>>>>> + PctFB +
>>     >>>>>> PctPov + PctBlack, data=gSRDF, adapt=TRUE)
>>     >>>>>> res.adpt <- gwr(PctBach ~ TotPop90 + PctRural + PctEld +
>>     PctFB +
>>     >>>>>> PctPov +
>>     >>>>>> PctBlack, data=gSRDF, adapt=g.adapt.gauss)
>>     >>>>>> res.adpt
>>     >>>>>>
>>     >>>>>> Clear?
>>     >>>>>
>>     >>>>> I have now compared the same data in R/spgwr and SAM for
>>     >>>>> effective number
>>     >>>>> of parameters, sigma, and your questionable R^2, and they
>>     agree
>>     >>>>> adequately
>>     >>>>> when the kernel and the bandwidth are the same. Having the
>>     >>>>> algorithm
>>     >>>>> choose the bandwidth does obscure what is going on. You should
>>     >>>>> use SAM if
>>     >>>>> you prefer GUI and not needing to know how things work, and
>>     >>>>> remember that
>>     >>>>> GWR is a very doubtful approach for anything beyond exploring
>>     >>>>> non-stationarity, its original motivation.
>>     >>>>>
>>     >>>>>>
>>     >>>>>>>
>>     >>>>>>> Thanks a lot.
>>     >>>>>>>
>>     >>>>>>> Cheers.
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>> Hi,
>>     >>>>>>>> I think that I use the same bandwidth and kernel. In SAM, I
>>     >>>>>>>> use "spatial
>>     >>>>>>>> Weighting Function"=gaussian, adaptive Spatial Kernel, and
>>     >>>>>>>> compute
>>     >>>>>>>> Geographical Distances based on longitudinal
>>     coordinate(X) and
>>     >>>>>>>> latitudinal
>>     >>>>>>>> coordinate(Y). In spgwr, gweight is gwr.Gauss and adapt
>>     is TRUE.
>>     >>>>>>>>
>>     >>>>>>>> For example, this is my code:
>>     >>>>>>>
>>     >>>>>>>> PET.bw <- gwr.sel(SPECIES_RI ~ PET, data=variables,
>>     >>>>>>>> coords=cbind(variables$LONGX, variables$LATY),adapt=TRUE)
>>     >>>>>>>
>>     >>>>>>>> PET.gauss <- gwr(SPECIES_RI ~ PET, data=variables,
>>     >>>>>>>> coords=cbind(variables$LONGX, variables$LATY),
>>     bandwidth=PET.bw,
>>     >>>>>>>> gweight=gwr.Gauss,adapt=TRUE,hatmatrix=TRUE)
>>     >>>>>>>
>>     >>>>>>> So where do you pass PET.bw to the gwr() function?
>>     adapt=TRUE
>>     >>>>>>> will treat
>>     >>>>>>> the adaptive proportion as 1, so include all data points. If
>>     >>>>>>> you want to
>>     >>>>>>> compare, use a fixed bandwidth in both, with no CV
>>     selection.
>>     >>>>>>> Then you
>>     >>>>>>> compare like with like.
>>     >>>>>>>
>>     >>>>>>> Note that your messages are *not* reaching the list, they
>>     must
>>     >>>>>>> be sent to:
>>     >>>>>>>
>>     >>>>>>> r-sig-geo at stat.math.ethz.ch, not
>>     >>>>>>>
>>     >>>>>>> r-sig-geo-request at stat.math.ethz.ch
>>     >>>>>>>
>>     >>>>>>> You are not thinking carefully and are rushing into
>>     things and
>>     >>>>>>> drawing
>>     >>>>>>> wrong conclusions.
>>     >>>>>>>
>>     >>>>>>>>
>>     >>>>>>>> Thanks a lot.
>>     >>>>>>>>
>>     >>>>>>>> Cheers.
>>     >>>>>>>>
>>     >>>>>>>>
>>     >>>>>>>>
>>     >>>>>>>> ??2010-05-12 20:28:47?? "Roger Bivand" <Roger.Bivand at nhh
>>     >>>>>>>> .no> ??????
>>     >>>>>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>     >>>>>>>>>
>>     >>>>>>>>>> Hi,
>>     >>>>>>>>>> One of SAM author ("Jos?? Alexandre Felizola Diniz
>>     >>>>>>>>>> Filho"<diniz at icb.ufg.br>) say that they also base on
>>     GWR3 (the
>>     >>>>>>>>>> Fotherigham book) and the data used within each kernel
>>     may
>>     >>>>>>>>>> be some
>>     >>>>>>>>>> slight differences
>>     >>>>>>>>>
>>     >>>>>>>>> Naturally, if you are not using exactly the same kernel
>>     and
>>     >>>>>>>>> bandwidth,
>>     >>>>>>>>> you should not be surprised by differences in values.
>>     Please
>>     >>>>>>>>> make sure
>>     >>>>>>>>> that the bandwidth and kernel are the same and try again.
>>     >>>>>>>>>
>>     >>>>>>>>> Roger
>>     >>>>>>>>>
>>     >>>>>>>>>> Cheers
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>> ??2010-05-12 20:28:47??"Roger Bivand" < Roger.Bivand at nhh.
>>     >>>>>>> no> ??????
>>     >>>>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>     >>>>>>>>
>>     >>>>>>>>> Hi,
>>     >>>>>>>>> One of SAM author ("Jos?? Alexandre Felizola Diniz
>>     >>>>>>>>> Filho"<diniz at icb.ufg.br>) say that they also base on
>>     GWR3 (the
>>     >>>>>>>>> Fotherigham book) and the data used within each kernel may
>>     >>>>>>>>> be some
>>     >>>>>>>>> slight differences
>>     >>>>>>>>
>>     >>>>>>>> Naturally, if you are not using exactly the same kernel and
>>     >>>>>>>> bandwidth, you
>>     >>>>>>>> should not be surprised by differences in values. Please
>>     make
>>     >>>>>>>> sure that
>>     >>>>>>>> the bandwidth and kernel are the same and try again.
>>     >>>>>>>>
>>     >>>>>>>> Roger
>>     >>>>>>>>
>>     >>>>>>>>> Cheers.
>>     >>>>>>>>>
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>> ??2010-05-12 15:27:58??"Roger Bivand" < Roger.Bivand at nhh.
>>     >>>>>>> no> ??????
>>     >>>>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>     >>>>>>>>
>>     >>>>>>>>> Hi,
>>     >>>>>>>>>
>>     >>>>>>>>> I am sorry I donot know how to install module spgwr from
>>     >>>>>>>>> sourceforge (I
>>     >>>>>>>>> can find it on the web
>>     >>>>>>>>>
>>     http://r-spatial.cvs.sourceforge.net/viewvc/r-spatial/spgwr/R/gwr.R?view=log
>>
>>     >>>>>>>>> ).
>>     >>>>>>>>> So I use the code sketch to calculate quasi-global R2. The
>>     >>>>>>>>> results are
>>     >>>>>>>>> different between SAM and spgwr(Attached are the
>>     results ). The
>>     >>>>>>>>> quasi-global R2 in R is 0.4515894, but in SAM is 0.696.
>>     >>>>>>>>> This is my code:
>>     >>>>>>>>>
>>     >>>>>>>>> library(spgwr)
>>     >>>>>>>>> Environmental_variables<-read.csv
>>     >>>>>>>>> ("Environmental_variables100.csv",header=TRUE)
>>     >>>>>>>>> attach(Environmental_variables)
>>     >>>>>>>>> region_PET.bw <- gwr.sel(SPECIES_RI ~ PET,
>>     >>>>>>>>> data=Environmental_variables,
>>     >>>>>>>>> coords=cbind(Environmental_variables$LONGX,
>>     >>>>>>>>> Environmental_variables$LATY),adapt=TRUE)
>>     >>>>>>>>> region_PET.gauss <- gwr(SPECIES_RI ~ PET,
>>     >>>>>>>>> data=Environmental_variables,
>>     >>>>>>>>> coords=cbind(Environmental_variables$LONGX,
>>     >>>>>>>>> Environmental_variables$LATY), bandwidth=region_PET.bw,
>>     >>>>>>>>> gweight=gwr.Gauss,adapt=TRUE,hatmatrix=TRUE)
>>     >>>>>>>>> names(region_PET.gauss$SDF)
>>     >>>>>>>>> region_PET.gauss$SDF$localR2
>>     >>>>>>>>> 1 -
>>     >>>>>>>>> (region_PET.gauss$results$rss/crossprod(scale
>>     >>>>>>>>> (Environmental_variables$SPECIES_RI,
>>     >>>>>>>>> scale=FALSE)))
>>     >>>>>>>>>
>>     >>>>>>>>> Thank you very much.
>>     >>>>>>>>
>>     >>>>>>>> SAM is closed source - ask them how they compute it. For
>>     >>>>>>>> spgwr, the code
>>     >>>>>>>> is provided, so you can read it for yourself. For the
>>     record,
>>     >>>>>>>> the current
>>     >>>>>>>> gwr() code in spgwr gives the same value as GWR3, which is
>>     >>>>>>>> also closed
>>     >>>>>>>> source, and where the Effective number of parameters
>>     (model:
>>     >>>>>>>> traceS),
>>     >>>>>>>> Sigma, and Residual sum of squares also agree. I suppose
>>     SAM
>>     >>>>>>>> has a
>>     >>>>>>>> different understanding of GWR internals than the
>>     authors of
>>     >>>>>>>> the GWR book.
>>     >>>>>>>>
>>     >>>>>>>> Once again:
>>     >>>>>>>>
>>     >>>>>>>> Please *do* write to the R-sig-geo list rather than to me
>>     >>>>>>>> directly -
>>     >>>>>>>> others can answer your question as well, perhaps better,
>>     and
>>     >>>>>>>> in a more
>>     >>>>>>>> timely way than I can. In addition, threads in the list
>>     can be
>>     >>>>>>>> searched in
>>     >>>>>>>> the archives, so others can avoid the same problem later.
>>     >>>>>>>>
>>     >>>>>>>> Please summarise to the list if this resolves the problem.
>>     >>>>>>>>
>>     >>>>>>>> Roger
>>     >>>>>>>>
>>     >>>>>>>>>
>>     >>>>>>>>>
>>     >>>>>>>>>
>>     >>>>>>>>>
>>     >>>>>>>>>
>>     >>>>>>>>> ??2010-05-12 01:16:18?? "Roger Bivand" <Roger.Bivand at nh
>>     >>>>>>>>> h.no> ??????
>>     >>>>>>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>     >>>>>>>>>>
>>     >>>>>>>>>>> Hi, I just need one for global, not *each* fit point. In
>>     >>>>>>>>>>> this case, how
>>     >>>>>>>>>>> can I select or do? Why in other software such as SAM
>>     >>>>>>>>>>> (Spatial Analysis
>>     >>>>>>>>>>> in Macroecology) just gives one R2?
>>     >>>>>>>>>>
>>     >>>>>>>>>> If you believe theirs, good luck! The authors of the GWR
>>     >>>>>>>>>> book have local
>>     >>>>>>>>>> R^2 values in GWR3 and formulae that are wrong by
>>     their own
>>     >>>>>>>>>> admission in
>>     >>>>>>>>>> private emails. The localR2 now agrees with the as-yet
>>     >>>>>>>>>> unreleased GWR4
>>     >>>>>>>>>> from the GWR authors. How SAM can be "better", I don't
>>     know.
>>     >>>>>>>>>> What you
>>     >>>>>>>>>> are suggesting is that the model fitted with fit
>>     points at
>>     >>>>>>>>>> data points
>>     >>>>>>>>>> (but not at other fit points) might have a "quasi-global"
>>     >>>>>>>>>> R^2, based on
>>     >>>>>>>>>> the RSS of the pooled fit. For the columbus case, that
>>     might
>>     >>>>>>>>>> be:
>>     >>>>>>>>>>
>>     >>>>>>>>>> 1 - (col.gauss$results$rss/crossprod(scale(columbus$crime,
>>     >>>>>>>>>> scale=FALSE)))
>>     >>>>>>>>>>
>>     >>>>>>>>>> but I don't know whether this is in any way correct. I've
>>     >>>>>>>>>> added it as:
>>     >>>>>>>>>>
>>     >>>>>>>>>> Quasi-global R2:
>>     >>>>>>>>>>
>>     >>>>>>>>>> to the print output of a GWR model fitted with a
>>     hatmatrix,
>>     >>>>>>>>>> and have
>>     >>>>>>>>>> committed it to sourceforge, project r-spatial, module
>>     >>>>>>>>>> spgwr. Arguably,
>>     >>>>>>>>>> it ought to be adjusted by the ratio of degrees of
>>     freedom,
>>     >>>>>>>>>> but I don't
>>     >>>>>>>>>> trust the DF either. Could you please check out spgwr
>>     from
>>     >>>>>>>>>> sourceforge
>>     >>>>>>>>>> ,install it from source, and confirm that the
>>     "quasi-global
>>     >>>>>>>>>> R2" does the
>>     >>>>>>>>>> same as SAM, or use the code sketch above to do the same,
>>     >>>>>>>>>> and report
>>     >>>>>>>>>> back?
>>     >>>>>>>>>>
>>     >>>>>>>>>> Roger
>>     >>>>>>>>>>
>>     >>>>>>>>>>>
>>     >>>>>>>>>>> Thanks a lot.
>>     >>>>>>>>>>>
>>     >>>>>>>>>>> Cheers,
>>     >>>>>>>>>>>
>>     >>>>>>>>>>>
>>     >>>>>>>>>>>
>>     >>>>>>>>>>>
>>     >>>>>>>>>>>
>>     >>>>>>>>>>> ??2010-05-11 23:59:44?? "Roger Bivand" <Roger.Bivand@
>>     >>>>>>>>>>> nhh.no> ??????
>>     >>>>>>>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>     >>>>>>>>>>>>
>>     >>>>>>>>>>>>> Hi,
>>     >>>>>>>>>>>>>
>>     >>>>>>>>>>>>> There are 49 localR2 in the results. Which one do I
>>     >>>>>>>>>>>>> need? The code
>>     >>>>>>>>>>>>> "look for localR2:" cannot run.
>>     >>>>>>>>>>>>
>>     >>>>>>>>>>>> Well, how many do you want? There is one for each fit
>>     >>>>>>>>>>>> point, they are
>>     >>>>>>>>>>>> *local* R2. Please do try to grasp what GWR does -
>>     it fits
>>     >>>>>>>>>>>> one moddel
>>     >>>>>>>>>>>> for *each* fit point.
>>     >>>>>>>>>>>>
>>     >>>>>>>>>>>>>
>>     >>>>>>>>>>>>> Thans a lot
>>     >>>>>>>>>>>>>
>>     >>>>>>>>>>>>> Cheers.
>>     >>>>>>>>>>>>>
>>     >>>>>>>>>>>>>
>>     >>>>>>>>>>>>>
>>     >>>>>>>>>>>>>
>>     >>>>>>>>>>>>>
>>     >>>>>>>>>>>>> ??2010-05-11 22:33: 59??"Roger Bivand" <Roger.Biv
>>     >>>>>>>>>>>>> and at nhh.no> ??????
>>     >>>>>>>>>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>     >>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>> Hi, OK. But I need it for compariation. In what some
>>     >>>>>>>>>>>>>>> contexts to
>>     >>>>>>>>>>>>>>> get it? May you tell me how to get it?
>>     >>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>> library(spgwr)
>>     >>>>>>>>>>>>>> data(columbus)
>>     >>>>>>>>>>>>>> col.bw <- gwr.sel(crime ~ income + housing,
>>     data=columbus,
>>     >>>>>>>>>>>>>> coords=cbind(columbus$x, columbus$y))
>>     >>>>>>>>>>>>>> col.gauss <- gwr(crime ~ income + housing,
>>     data=columbus,
>>     >>>>>>>>>>>>>> coords=cbind(columbus$x, columbus$y),
>>     bandwidth=col.bw,
>>     >>>>>>>>>>>>>> hatmatrix=TRUE)
>>     >>>>>>>>>>>>>> names(col.gauss$SDF)
>>     >>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>> look for localR2:
>>     >>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>> col.gauss$SDF$localR2
>>     >>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>> But do not rely on it or use it for anything at all!
>>     >>>>>>>>>>>>>> Like all GWR,
>>     >>>>>>>>>>>>>> it is most unreliable!
>>     >>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>> Roger Bivand
>>     >>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>> Thank you very much for your great helps
>>     >>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>> Best regards.
>>     >>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>> ??2010-05- 11 18:28:44??"Roger Bivand" <Roger
>>     >>>>>>>>>>>>>>> .Bivand at nhh.no <mailto:Bivand at nhh.no>> ??????
>>     >>>>>>>>>>>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>     >>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>>> Dear professor Bivand,
>>     >>>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>>> I am a strudent. I recently use GWR(Geographically
>>     >>>>>>>>>>>>>>>>> weighted
>>     >>>>>>>>>>>>>>>>> regression) model. May I ask you a question?
>>     There is
>>     >>>>>>>>>>>>>>>>> not
>>     >>>>>>>>>>>>>>>>> Coefficient of Determination in the results of
>>     GWR.
>>     >>>>>>>>>>>>>>>>> How can I get
>>     >>>>>>>>>>>>>>>>> it? What is the programs to get it?
>>     >>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>> Please address questions like this to the R-sig-geo
>>     >>>>>>>>>>>>>>>> list rather
>>     >>>>>>>>>>>>>>>> than to me directly in future.
>>     >>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>> The local R2 values are available in some contexts
>>     >>>>>>>>>>>>>>>> when running
>>     >>>>>>>>>>>>>>>> gwr(), but are not well defined (neither in the GWR
>>     >>>>>>>>>>>>>>>> book nor in
>>     >>>>>>>>>>>>>>>> implementations). I advise against their use - they
>>     >>>>>>>>>>>>>>>> are most
>>     >>>>>>>>>>>>>>>> probably meaningless.
>>     >>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>> Hope this helps,
>>     >>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>> Roger Bivand
>>     >>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>>> Thank you very much for your any helps.
>>     >>>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>>> Best regards.
>>     >>>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>>> Yong Huang
>>     >>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>> --
>>     >>>>>>>>>>>>>>>> Roger Bivand
>>     >>>>>>>>>>>>>>>> Economic Geography Section, Department of
>>     Economics,
>>     >>>>>>>>>>>>>>>> Norwegian
>>     >>>>>>>>>>>>>>>> School of
>>     >>>>>>>>>>>>>>>> Economics and Business Administration,
>>     Helleveien 30,
>>     >>>>>>>>>>>>>>>> N-5045
>>     >>>>>>>>>>>>>>>> Bergen,
>>     >>>>>>>>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>     >>>>>>>>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>     >>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>> --
>>     >>>>>>>>>>>>>> Roger Bivand
>>     >>>>>>>>>>>>>> Economic Geography Section, Department of Economics,
>>     >>>>>>>>>>>>>> Norwegian
>>     >>>>>>>>>>>>>> School of
>>     >>>>>>>>>>>>>> Economics and Business Administration, Helleveien 30,
>>     >>>>>>>>>>>>>> N-5045 Bergen,
>>     >>>>>>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>     >>>>>>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>     >>>>>>>>>>>>
>>     >>>>>>>>>>>> --
>>     >>>>>>>>>>>> Roger Bivand
>>     >>>>>>>>>>>> Economic Geography Section, Department of Economics,
>>     >>>>>>>>>>>> Norwegian School
>>     >>>>>>>>>>>> of
>>     >>>>>>>>>>>> Economics and Business Administration, Helleveien 30,
>>     >>>>>>>>>>>> N-5045 Bergen,
>>     >>>>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>     >>>>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>     >>>>>>>>>>
>>     >>>>>>>>>> --
>>     >>>>>>>>>> Roger Bivand
>>     >>>>>>>>>> Economic Geography Section, Department of Economics,
>>     >>>>>>>>>> Norwegian School of
>>     >>>>>>>>>> Economics and Business Administration, Helleveien 30,
>>     N-5045
>>     >>>>>>>>>> Bergen,
>>     >>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>     >>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>     >>>>>>>>
>>     >>>>>>>> --
>>     >>>>>>>> Roger Bivand
>>     >>>>>>>> Economic Geography Section, Department of Economics,
>>     Norwegian
>>     >>>>>>>> School of
>>     >>>>>>>> Economics and Business Administration, Helleveien 30,
>>     N-5045
>>     >>>>>>>> Bergen,
>>     >>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>     >>>>>>>> e-mail: Roger.Bivand at nhh.no
>>     >>>>>>
>>     >>>>>>
>>     >>>>>
>>     >>>>> --
>>     >>>>> Roger Bivand
>>     >>>>> Economic Geography Section, Department of Economics, Norwegian
>>     >>>>> School of
>>     >>>>> Economics and Business Administration, Helleveien 30, N-5045
>>     >>>>> Bergen,
>>     >>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>     >>>>> e-mail: Roger.Bivand at nhh.no
>>     >>>
>>     >>> --
>>     >>> Roger Bivand
>>     >>> Economic Geography Section, Department of Economics, Norwegian
>>     >>> School of
>>     >>> Economics and Business Administration, Helleveien 30, N-5045
>>     Bergen,
>>     >>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>     >>> e-mail: Roger.Bivand at nhh.no
>>     >>
>>     >> [[alternative HTML version deleted]]
>>     >>
>>     >> _______________________________________________
>>     >> R-sig-Geo mailing list
>>     >> R-sig-Geo at stat.math.ethz.ch
>>     >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>>     ------------------------------------------------------------------------
>>     ??????????????????????????????????????????
>>     <http://ym.163.com/?from=od3> 
>
>     -- 
>     ___________________________________________
>     Danlin Yu, Ph.D.
>     Assistant Professor of GIS and Urban Geography
>     Department of Earth & Environmental Studies
>     Montclair State University
>     Montclair, NJ, 07043
>     Tel: 973-655-4313
>     Fax: 973-655-4072
>     email: yud at mail.montclair.edu
>     webpage: csam.montclair.edu/~yu
>
>
>
> ------------------------------------------------------------------------
> ?????????????????????????????????????????? <http://ym.163.com/?from=od3> 

-- 
___________________________________________
Danlin Yu, Ph.D.
Assistant Professor of GIS and Urban Geography
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
email: yud at mail.montclair.edu
webpage: csam.montclair.edu/~yu


From yud at mail.montclair.edu  Thu May 13 17:14:00 2010
From: yud at mail.montclair.edu (Danlin Yu)
Date: Thu, 13 May 2010 11:14:00 -0400
Subject: [R-sig-Geo] How to get the Coefficient of Determination in the
 results of GWR
In-Reply-To: <1b68087.6708.12891fa812c.Coremail.huangykiz@163.com>
References: <4BEBFFF8.9050508@mail.montclair.edu>
	<alpine.LRH.2.00.1005121803170.5691@reclus.nhh.no>
	<alpine.LRH.2.00.1005120914260.19319@reclus.nhh.no>
	<alpine.LRH.2.00.1005111834410.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111758330.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111632010.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111226160.11770@reclus.nhh.no>
	<7fbb8685.9c9e.12886ce7d95.Coremail.huangykiz@163.com>
	<35fc8b41.9509.128878f8dc7.Coremail.huangykiz@163.com>
	<5cd1a7.aaf7.12887db30ba.Coremail.huangykiz@163.com>
	<1721ac8.cd5c.1288828d49a.Coremail.huangykiz@163.com>
	<e41e5d3.ff74.1288a727c78.Coremail.huangykiz@163.com>
	<e30f5db.13f83.1288d18e217.Coremail.huangykiz@163.com>
	<alpine.LRH.2.00.1005121726190.5691@reclus.nhh.no>
	<342188fb.6e7b.12890806f61.Coremail.huangykiz@163.com>
	<1a77f94.738a.128918cab0d.Coremail.huangykiz@163.com>
	<16d8a50.6301.12891c3fe03.Coremail.huangykiz@163.com>
	<1b68087.6708.12891fa812c.Coremail.huangykiz@163.com>
Message-ID: <4BEC1738.8040506@mail.montclair.edu>

In addition (I guess this is where the problem is), the argument "adapt" 
in gwr.sel() is not the same as the argument "adapt" in gwr(). The 
former will take a logical value (T or F), the latter takes numeric 
values (0 - 1).

Danlin

huangykiz ????:
> Hi,
> I know that a proportion of "adapt" between 0 and 1.For example, 
> values below are calculated using adapt=TRUE, and then in gwr(), it 
> will use the best adapt q=0.0008484767 (the last line) to compute. But 
> I just want to ues adapt q=0.1(the red line) to compute in gwr() next, 
> not adapt q=0.0008484767 (the last line). So I mean how to get the 10% 
> proportion value and how to write it in gwr(), not just 
> adaptive_proportion <- gwr.sel(...); */result <- gwr(..., 
> adapt=adaptive_proportion; ...)./*
> Adaptive q: 0.381966 CV score: 24370.57
> Adaptive q: 0.618034 CV score: 27368.81
> Adaptive q: 0.236068 CV score: 21363.70
> Adaptive q: 0.1458980 CV score: 18875.33
> Adaptive q: 0.09016994 CV score: 16519.28
> Adaptive q: 0.05572809 CV score: 14424.12
> Adaptive q: 0.03444185 CV score: 12722.21
> Adaptive q: 0.02128624 CV score: 11354.84
> Adaptive q: 0.01315562 CV score: 10373.59
> Adaptive q: 0.008130619 CV score: 8748.126
> Adaptive q: 0.005024999 CV score: 7748.467
> Adaptive q: 0.00310562 CV score: 7251.083
> Adaptive q: 0.001919379 CV score: 6869.442
> Adaptive q: 0.001186241 CV score: 6769.606
> Adaptive q: 0.0008484767 CV score: 6343.859
> Adaptive q: 0.0005243874 CV score: 7706.465
> Adaptive q: 0.0009774913 CV score: 6428.712
> Adaptive q: 0.0007990996 CV score: 6356.182
> Adaptive q: 0.0008891668 CV score: 6354.715
> Adaptive q: 0.0008484767 CV score: 6343.859
> Thank you very much for your any helps.
> Cheers.
>
> ??2010-05-13 21:34:48??"Danlin Yu" <yud at mail.montclair.edu> ??????
>
>     In gwr(), it's actually adapt = 0.1. It was a typo in my previous
>     email. And actually before you ask this question, you shall really
>     follow what Roger said, "READ THE HELP PAGES". Do some homework
>     (Roger has already answered your question in his previous email,
>     highlights by me, see:
>
>     >>>>>> READ THE HELP PAGES!
>     >>>>>>
>     >>>>>> adaptive_proportion <- gwr.sel(...)
>     >>>>>>
>     >>>>>> /*result <- gwr(..., adapt=adaptive_proportion; ...)*/
>     >>>>>>
>     >>>>>> exactly as on the example om the help page:
>     >>>>>>
>     >>>>>> data(georgia)
>     >>>>>> g.adapt.gauss <- gwr.sel(PctBach ~ TotPop90 + PctRural +
>     PctEld
>     >>>>>> + PctFB +
>     >>>>>> PctPov + PctBlack, data=gSRDF, adapt=TRUE)
>     >>>>>> res.adpt <- gwr(PctBach ~ TotPop90 + PctRural + PctEld +
>     PctFB +
>     >>>>>> PctPov +
>     >>>>>> PctBlack, data=gSRDF, adapt=g.adapt.gauss)
>     >>>>>> res.adpt
>
>     )
>
>     In addition, if you are considering using R quite often, I would
>     suggest you try to read the codes that are provided by simply
>     typing the name of the function. This way, you'll learn about the
>     parameters, how they are used, what results are produced and how
>     they are produced, etc. The open-source codes will certainly tell
>     you "more detail" (more than you could imagine, I'd say).
>
>     Hope this helps.
>
>     Cheers,
>     Danlin
>
>     huangykiz ????:
>>     Hi,
>>     Set In gwr.sel() or gwr()?. How to write the code about set
>>     "adpt" parameter to 0.1? May you tell more detail.
>>     Thank you very much.
>>     Cheers,
>>
>>     ??2010-05-13 20:29:14??"Danlin Yu" <yud at mail.montclair.edu> ??????
>>     >You shall set "adpt" parameter to 0.1.
>>     >
>>     >Sent from my Iphone
>>     >Dr. Danlin Yu
>>     >Assistant Professor of GIS, Urban Geography
>>     >Earth & Environmental Studies
>>     >Montclair State University
>>     >Montclair, NJ 07043
>>     >Tel: 973-655-4313
>>     >Fax: 973-655-4072
>>     >Email: yud at mail.montclair.edu
>>     >
>>     >?? May 13, 2010??8:03 AM??huangykiz <huangykiz at 163.com> ??????
>>     >
>>     >> Hi,
>>     >> If I want to chang the adaptive Spatial Kernel = 10% neighbors in
>>     >> gwr()? How to chang it?
>>     >>
>>     >> Thank you very much.
>>     >>
>>     >> Cheers.
>>     >>
>>     >>
>>     >>
>>     >>
>>     >> ??2010-05-13 17:43:06??"Roger Bivand" <Roger.Bivand at nhh.no> ??????
>>     >>> On Thu, 13 May 2010, huangykiz wrote:
>>     >>>
>>     >>>> Hi,
>>     >>>
>>     >>>> I am sorry I say that I cannot get the same R^2 between in
>>     R/spgwr
>>     >>>> and
>>     >>>> SAM in my data.
>>     >>>
>>     >>> Establish that the adaptive proportion is exactly the same.
>>     >>>
>>     >>> You haven't done that - copy and paste from SAM to gwr(), not
>>     using
>>     >>> gwr.sel(). Do it first for fixed Gaussian, then if you get a
>>     sensible
>>     >>> figure from SAM for adaptive, do the same there. I see very
>>     different
>>     >>> bandwidths chosen by SAM and by gwr.sel() and GWR3 -
>>     gwr.sel() and
>>     >>> GWR3
>>     >>> usually agree fairly well for CV fixed bandwidths, but gwr.sel()
>>     >>> typically
>>     >>> continues its search a little longer than GWR3.
>>     >>>
>>     >>> I don't know how SAM chooses its bandwidth or adaptive
>>     proportion,
>>     >>> it is
>>     >>> closed source, so only its authors know.
>>     >>>
>>     >>> Is SAM using Great Circle distances, if so, you should set
>>     >>> longlat=TRUE in
>>     >>> gwr.sel() and gwr()? Are your coordinates geographical (decimal
>>     >>> degrees)
>>     >>> or projected (metres)?
>>     >>>
>>     >>> Roger
>>     >>>
>>     >>>> In R/spgwr
>>     >>>> R^2: 0.972989;
>>     >>>> AICc (GWR p. 61, eq 2.33; p. 96, eq. 4.21): 4668.92
>>     >>>> Effective number of parameters (model: traceS): 435.7586;
>>     >>>> Effective number of parameters (residual: 2traceS -
>>     traceS'S): 582.3581
>>     >>>> ;
>>     >>>> Sigma (residual: 2traceS - traceS'S): 2.437066;
>>     >>>> Sigma (model: traceS): 1.927127;
>>     >>>> Sigma (ML): 1.325501;
>>     >>>>
>>     >>>> In SAM,
>>     >>>> Coefficient of Determination : 0.696
>>     >>>> Adjusted r-square (r?Adj): 0.693
>>     >>>> Sigma: 20.058
>>     >>>> Effective Number of Parameters: 10.002
>>     >>>> Akaike Information Criterion (AICc): 4838.299
>>     >>>> Correlation Coefficient (r): 0.834
>>     >>>> F: 207.852
>>     >>>>
>>     >>>> Here are my code:
>>     >>>> PET.adapt.gauss <- gwr.sel(SPECIES_RI ~ PET,
>>     >>>> data=Environmental_variables,
>>     coords=cbind(Environmental_variables
>>     >>>> $LONGX,
>>     >>>> Environmental_variables$LATY),adapt=TRUE)
>>     >>>>
>>     >>>> PET.gauss<- gwr(SPECIES_RI ~ PET, data=Environmental_variables,
>>     >>>> coords=cbind(Environmental_variables$LONGX,
>>     >>>> Environmental_variables$LATY),
>>     >>>> gweight=gwr.Gauss,adapt=PET.adapt.gauss,hatmatrix=TRUE)
>>     >>>>
>>     >>>> 1 -
>>     (PET.gauss$results$rss/crossprod(scale(Environmental_variables
>>     >>>> $SPECIES_RI, scale=FALSE)))
>>     >>>>
>>     >>>> In SAM, I selecte "spatial Weighting Function"=gaussian,
>>     adaptive
>>     >>>> Spatial Kernel, and compute Geographical Distances based on
>>     >>>> longitudinal
>>     >>>> coordinate(X) and latitudinal coordinate(Y). I donot select
>>     method
>>     >>>> for
>>     >>>> AIC optimisation.
>>     >>>>
>>     >>>> So I donot know where is wrong.
>>     >>>>
>>     >>>> Thank you very much for your great helps.
>>     >>>>
>>     >>>>
>>     >>>>
>>     >>>>
>>     >>>>
>>     >>>>
>>     >>>> ??2010-05-13 00:07:23??"Roger Bivand" < Roger.Bivand at nhh.no>
>>     ??????
>>     >>>>> On Wed, 12 May 2010, Roger Bivand wrote:
>>     >>>>>
>>     >>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>     >>>>>>
>>     >>>>>>> Hi, Is "adapt=TRUE"(spgwr) not the same as "adaptive Spatial
>>     >>>>>>> Kernel"(SAM)?The result of "adaptive Spatial Kernel" may be
>>     >>>>>>> better than
>>     >>>>>>> fixed bandwidth. If I want to ues "adaptive Spatial
>>     Kernel" in
>>     >>>>>>> spgwr, how
>>     >>>>>>> to write the code?
>>     >>>>>>
>>     >>>>>> READ THE HELP PAGES!
>>     >>>>>>
>>     >>>>>> adaptive_proportion <- gwr.sel(...)
>>     >>>>>>
>>     >>>>>> result <- gwr(..., adapt=adaptive_proportion; ...)
>>     >>>>>>
>>     >>>>>> exactly as on the example om the help page:
>>     >>>>>>
>>     >>>>>> data(georgia)
>>     >>>>>> g.adapt.gauss <- gwr.sel(PctBach ~ TotPop90 + PctRural +
>>     PctEld
>>     >>>>>> + PctFB +
>>     >>>>>> PctPov + PctBlack, data=gSRDF, adapt=TRUE)
>>     >>>>>> res.adpt <- gwr(PctBach ~ TotPop90 + PctRural + PctEld +
>>     PctFB +
>>     >>>>>> PctPov +
>>     >>>>>> PctBlack, data=gSRDF, adapt=g.adapt.gauss)
>>     >>>>>> res.adpt
>>     >>>>>>
>>     >>>>>> Clear?
>>     >>>>>
>>     >>>>> I have now compared the same data in R/spgwr and SAM for
>>     >>>>> effective number
>>     >>>>> of parameters, sigma, and your questionable R^2, and they
>>     agree
>>     >>>>> adequately
>>     >>>>> when the kernel and the bandwidth are the same. Having the
>>     >>>>> algorithm
>>     >>>>> choose the bandwidth does obscure what is going on. You should
>>     >>>>> use SAM if
>>     >>>>> you prefer GUI and not needing to know how things work, and
>>     >>>>> remember that
>>     >>>>> GWR is a very doubtful approach for anything beyond exploring
>>     >>>>> non-stationarity, its original motivation.
>>     >>>>>
>>     >>>>>>
>>     >>>>>>>
>>     >>>>>>> Thanks a lot.
>>     >>>>>>>
>>     >>>>>>> Cheers.
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>> Hi,
>>     >>>>>>>> I think that I use the same bandwidth and kernel. In SAM, I
>>     >>>>>>>> use "spatial
>>     >>>>>>>> Weighting Function"=gaussian, adaptive Spatial Kernel, and
>>     >>>>>>>> compute
>>     >>>>>>>> Geographical Distances based on longitudinal
>>     coordinate(X) and
>>     >>>>>>>> latitudinal
>>     >>>>>>>> coordinate(Y). In spgwr, gweight is gwr.Gauss and adapt
>>     is TRUE.
>>     >>>>>>>>
>>     >>>>>>>> For example, this is my code:
>>     >>>>>>>
>>     >>>>>>>> PET.bw <- gwr.sel(SPECIES_RI ~ PET, data=variables,
>>     >>>>>>>> coords=cbind(variables$LONGX, variables$LATY),adapt=TRUE)
>>     >>>>>>>
>>     >>>>>>>> PET.gauss <- gwr(SPECIES_RI ~ PET, data=variables,
>>     >>>>>>>> coords=cbind(variables$LONGX, variables$LATY),
>>     bandwidth=PET.bw,
>>     >>>>>>>> gweight=gwr.Gauss,adapt=TRUE,hatmatrix=TRUE)
>>     >>>>>>>
>>     >>>>>>> So where do you pass PET.bw to the gwr() function?
>>     adapt=TRUE
>>     >>>>>>> will treat
>>     >>>>>>> the adaptive proportion as 1, so include all data points. If
>>     >>>>>>> you want to
>>     >>>>>>> compare, use a fixed bandwidth in both, with no CV
>>     selection.
>>     >>>>>>> Then you
>>     >>>>>>> compare like with like.
>>     >>>>>>>
>>     >>>>>>> Note that your messages are *not* reaching the list, they
>>     must
>>     >>>>>>> be sent to:
>>     >>>>>>>
>>     >>>>>>> r-sig-geo at stat.math.ethz.ch, not
>>     >>>>>>>
>>     >>>>>>> r-sig-geo-request at stat.math.ethz.ch
>>     >>>>>>>
>>     >>>>>>> You are not thinking carefully and are rushing into
>>     things and
>>     >>>>>>> drawing
>>     >>>>>>> wrong conclusions.
>>     >>>>>>>
>>     >>>>>>>>
>>     >>>>>>>> Thanks a lot.
>>     >>>>>>>>
>>     >>>>>>>> Cheers.
>>     >>>>>>>>
>>     >>>>>>>>
>>     >>>>>>>>
>>     >>>>>>>> ??2010-05-12 20:28:47?? "Roger Bivand" <Roger.Bivand at nhh
>>     >>>>>>>> .no> ??????
>>     >>>>>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>     >>>>>>>>>
>>     >>>>>>>>>> Hi,
>>     >>>>>>>>>> One of SAM author ("Jos?? Alexandre Felizola Diniz
>>     >>>>>>>>>> Filho"<diniz at icb.ufg.br>) say that they also base on
>>     GWR3 (the
>>     >>>>>>>>>> Fotherigham book) and the data used within each kernel
>>     may
>>     >>>>>>>>>> be some
>>     >>>>>>>>>> slight differences
>>     >>>>>>>>>
>>     >>>>>>>>> Naturally, if you are not using exactly the same kernel
>>     and
>>     >>>>>>>>> bandwidth,
>>     >>>>>>>>> you should not be surprised by differences in values.
>>     Please
>>     >>>>>>>>> make sure
>>     >>>>>>>>> that the bandwidth and kernel are the same and try again.
>>     >>>>>>>>>
>>     >>>>>>>>> Roger
>>     >>>>>>>>>
>>     >>>>>>>>>> Cheers
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>> ??2010-05-12 20:28:47??"Roger Bivand" < Roger.Bivand at nhh.
>>     >>>>>>> no> ??????
>>     >>>>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>     >>>>>>>>
>>     >>>>>>>>> Hi,
>>     >>>>>>>>> One of SAM author ("Jos?? Alexandre Felizola Diniz
>>     >>>>>>>>> Filho"<diniz at icb.ufg.br>) say that they also base on
>>     GWR3 (the
>>     >>>>>>>>> Fotherigham book) and the data used within each kernel may
>>     >>>>>>>>> be some
>>     >>>>>>>>> slight differences
>>     >>>>>>>>
>>     >>>>>>>> Naturally, if you are not using exactly the same kernel and
>>     >>>>>>>> bandwidth, you
>>     >>>>>>>> should not be surprised by differences in values. Please
>>     make
>>     >>>>>>>> sure that
>>     >>>>>>>> the bandwidth and kernel are the same and try again.
>>     >>>>>>>>
>>     >>>>>>>> Roger
>>     >>>>>>>>
>>     >>>>>>>>> Cheers.
>>     >>>>>>>>>
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>> ??2010-05-12 15:27:58??"Roger Bivand" < Roger.Bivand at nhh.
>>     >>>>>>> no> ??????
>>     >>>>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>     >>>>>>>>
>>     >>>>>>>>> Hi,
>>     >>>>>>>>>
>>     >>>>>>>>> I am sorry I donot know how to install module spgwr from
>>     >>>>>>>>> sourceforge (I
>>     >>>>>>>>> can find it on the web
>>     >>>>>>>>>
>>     http://r-spatial.cvs.sourceforge.net/viewvc/r-spatial/spgwr/R/gwr.R?view=log
>>
>>     >>>>>>>>> ).
>>     >>>>>>>>> So I use the code sketch to calculate quasi-global R2. The
>>     >>>>>>>>> results are
>>     >>>>>>>>> different between SAM and spgwr(Attached are the
>>     results ). The
>>     >>>>>>>>> quasi-global R2 in R is 0.4515894, but in SAM is 0.696.
>>     >>>>>>>>> This is my code:
>>     >>>>>>>>>
>>     >>>>>>>>> library(spgwr)
>>     >>>>>>>>> Environmental_variables<-read.csv
>>     >>>>>>>>> ("Environmental_variables100.csv",header=TRUE)
>>     >>>>>>>>> attach(Environmental_variables)
>>     >>>>>>>>> region_PET.bw <- gwr.sel(SPECIES_RI ~ PET,
>>     >>>>>>>>> data=Environmental_variables,
>>     >>>>>>>>> coords=cbind(Environmental_variables$LONGX,
>>     >>>>>>>>> Environmental_variables$LATY),adapt=TRUE)
>>     >>>>>>>>> region_PET.gauss <- gwr(SPECIES_RI ~ PET,
>>     >>>>>>>>> data=Environmental_variables,
>>     >>>>>>>>> coords=cbind(Environmental_variables$LONGX,
>>     >>>>>>>>> Environmental_variables$LATY), bandwidth=region_PET.bw,
>>     >>>>>>>>> gweight=gwr.Gauss,adapt=TRUE,hatmatrix=TRUE)
>>     >>>>>>>>> names(region_PET.gauss$SDF)
>>     >>>>>>>>> region_PET.gauss$SDF$localR2
>>     >>>>>>>>> 1 -
>>     >>>>>>>>> (region_PET.gauss$results$rss/crossprod(scale
>>     >>>>>>>>> (Environmental_variables$SPECIES_RI,
>>     >>>>>>>>> scale=FALSE)))
>>     >>>>>>>>>
>>     >>>>>>>>> Thank you very much.
>>     >>>>>>>>
>>     >>>>>>>> SAM is closed source - ask them how they compute it. For
>>     >>>>>>>> spgwr, the code
>>     >>>>>>>> is provided, so you can read it for yourself. For the
>>     record,
>>     >>>>>>>> the current
>>     >>>>>>>> gwr() code in spgwr gives the same value as GWR3, which is
>>     >>>>>>>> also closed
>>     >>>>>>>> source, and where the Effective number of parameters
>>     (model:
>>     >>>>>>>> traceS),
>>     >>>>>>>> Sigma, and Residual sum of squares also agree. I suppose
>>     SAM
>>     >>>>>>>> has a
>>     >>>>>>>> different understanding of GWR internals than the
>>     authors of
>>     >>>>>>>> the GWR book.
>>     >>>>>>>>
>>     >>>>>>>> Once again:
>>     >>>>>>>>
>>     >>>>>>>> Please *do* write to the R-sig-geo list rather than to me
>>     >>>>>>>> directly -
>>     >>>>>>>> others can answer your question as well, perhaps better,
>>     and
>>     >>>>>>>> in a more
>>     >>>>>>>> timely way than I can. In addition, threads in the list
>>     can be
>>     >>>>>>>> searched in
>>     >>>>>>>> the archives, so others can avoid the same problem later.
>>     >>>>>>>>
>>     >>>>>>>> Please summarise to the list if this resolves the problem.
>>     >>>>>>>>
>>     >>>>>>>> Roger
>>     >>>>>>>>
>>     >>>>>>>>>
>>     >>>>>>>>>
>>     >>>>>>>>>
>>     >>>>>>>>>
>>     >>>>>>>>>
>>     >>>>>>>>> ??2010-05-12 01:16:18?? "Roger Bivand" <Roger.Bivand at nh
>>     >>>>>>>>> h.no> ??????
>>     >>>>>>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>     >>>>>>>>>>
>>     >>>>>>>>>>> Hi, I just need one for global, not *each* fit point. In
>>     >>>>>>>>>>> this case, how
>>     >>>>>>>>>>> can I select or do? Why in other software such as SAM
>>     >>>>>>>>>>> (Spatial Analysis
>>     >>>>>>>>>>> in Macroecology) just gives one R2?
>>     >>>>>>>>>>
>>     >>>>>>>>>> If you believe theirs, good luck! The authors of the GWR
>>     >>>>>>>>>> book have local
>>     >>>>>>>>>> R^2 values in GWR3 and formulae that are wrong by
>>     their own
>>     >>>>>>>>>> admission in
>>     >>>>>>>>>> private emails. The localR2 now agrees with the as-yet
>>     >>>>>>>>>> unreleased GWR4
>>     >>>>>>>>>> from the GWR authors. How SAM can be "better", I don't
>>     know.
>>     >>>>>>>>>> What you
>>     >>>>>>>>>> are suggesting is that the model fitted with fit
>>     points at
>>     >>>>>>>>>> data points
>>     >>>>>>>>>> (but not at other fit points) might have a "quasi-global"
>>     >>>>>>>>>> R^2, based on
>>     >>>>>>>>>> the RSS of the pooled fit. For the columbus case, that
>>     might
>>     >>>>>>>>>> be:
>>     >>>>>>>>>>
>>     >>>>>>>>>> 1 - (col.gauss$results$rss/crossprod(scale(columbus$crime,
>>     >>>>>>>>>> scale=FALSE)))
>>     >>>>>>>>>>
>>     >>>>>>>>>> but I don't know whether this is in any way correct. I've
>>     >>>>>>>>>> added it as:
>>     >>>>>>>>>>
>>     >>>>>>>>>> Quasi-global R2:
>>     >>>>>>>>>>
>>     >>>>>>>>>> to the print output of a GWR model fitted with a
>>     hatmatrix,
>>     >>>>>>>>>> and have
>>     >>>>>>>>>> committed it to sourceforge, project r-spatial, module
>>     >>>>>>>>>> spgwr. Arguably,
>>     >>>>>>>>>> it ought to be adjusted by the ratio of degrees of
>>     freedom,
>>     >>>>>>>>>> but I don't
>>     >>>>>>>>>> trust the DF either. Could you please check out spgwr
>>     from
>>     >>>>>>>>>> sourceforge
>>     >>>>>>>>>> ,install it from source, and confirm that the
>>     "quasi-global
>>     >>>>>>>>>> R2" does the
>>     >>>>>>>>>> same as SAM, or use the code sketch above to do the same,
>>     >>>>>>>>>> and report
>>     >>>>>>>>>> back?
>>     >>>>>>>>>>
>>     >>>>>>>>>> Roger
>>     >>>>>>>>>>
>>     >>>>>>>>>>>
>>     >>>>>>>>>>> Thanks a lot.
>>     >>>>>>>>>>>
>>     >>>>>>>>>>> Cheers,
>>     >>>>>>>>>>>
>>     >>>>>>>>>>>
>>     >>>>>>>>>>>
>>     >>>>>>>>>>>
>>     >>>>>>>>>>>
>>     >>>>>>>>>>> ??2010-05-11 23:59:44?? "Roger Bivand" <Roger.Bivand@
>>     >>>>>>>>>>> nhh.no> ??????
>>     >>>>>>>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>     >>>>>>>>>>>>
>>     >>>>>>>>>>>>> Hi,
>>     >>>>>>>>>>>>>
>>     >>>>>>>>>>>>> There are 49 localR2 in the results. Which one do I
>>     >>>>>>>>>>>>> need? The code
>>     >>>>>>>>>>>>> "look for localR2:" cannot run.
>>     >>>>>>>>>>>>
>>     >>>>>>>>>>>> Well, how many do you want? There is one for each fit
>>     >>>>>>>>>>>> point, they are
>>     >>>>>>>>>>>> *local* R2. Please do try to grasp what GWR does -
>>     it fits
>>     >>>>>>>>>>>> one moddel
>>     >>>>>>>>>>>> for *each* fit point.
>>     >>>>>>>>>>>>
>>     >>>>>>>>>>>>>
>>     >>>>>>>>>>>>> Thans a lot
>>     >>>>>>>>>>>>>
>>     >>>>>>>>>>>>> Cheers.
>>     >>>>>>>>>>>>>
>>     >>>>>>>>>>>>>
>>     >>>>>>>>>>>>>
>>     >>>>>>>>>>>>>
>>     >>>>>>>>>>>>>
>>     >>>>>>>>>>>>> ??2010-05-11 22:33: 59??"Roger Bivand" <Roger.Biv
>>     >>>>>>>>>>>>> and at nhh.no> ??????
>>     >>>>>>>>>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>     >>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>> Hi, OK. But I need it for compariation. In what some
>>     >>>>>>>>>>>>>>> contexts to
>>     >>>>>>>>>>>>>>> get it? May you tell me how to get it?
>>     >>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>> library(spgwr)
>>     >>>>>>>>>>>>>> data(columbus)
>>     >>>>>>>>>>>>>> col.bw <- gwr.sel(crime ~ income + housing,
>>     data=columbus,
>>     >>>>>>>>>>>>>> coords=cbind(columbus$x, columbus$y))
>>     >>>>>>>>>>>>>> col.gauss <- gwr(crime ~ income + housing,
>>     data=columbus,
>>     >>>>>>>>>>>>>> coords=cbind(columbus$x, columbus$y),
>>     bandwidth=col.bw,
>>     >>>>>>>>>>>>>> hatmatrix=TRUE)
>>     >>>>>>>>>>>>>> names(col.gauss$SDF)
>>     >>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>> look for localR2:
>>     >>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>> col.gauss$SDF$localR2
>>     >>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>> But do not rely on it or use it for anything at all!
>>     >>>>>>>>>>>>>> Like all GWR,
>>     >>>>>>>>>>>>>> it is most unreliable!
>>     >>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>> Roger Bivand
>>     >>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>> Thank you very much for your great helps
>>     >>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>> Best regards.
>>     >>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>> ??2010-05- 11 18:28:44??"Roger Bivand" <Roger
>>     >>>>>>>>>>>>>>> .Bivand at nhh.no <mailto:Bivand at nhh.no>> ??????
>>     >>>>>>>>>>>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>     >>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>>> Dear professor Bivand,
>>     >>>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>>> I am a strudent. I recently use GWR(Geographically
>>     >>>>>>>>>>>>>>>>> weighted
>>     >>>>>>>>>>>>>>>>> regression) model. May I ask you a question?
>>     There is
>>     >>>>>>>>>>>>>>>>> not
>>     >>>>>>>>>>>>>>>>> Coefficient of Determination in the results of
>>     GWR.
>>     >>>>>>>>>>>>>>>>> How can I get
>>     >>>>>>>>>>>>>>>>> it? What is the programs to get it?
>>     >>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>> Please address questions like this to the R-sig-geo
>>     >>>>>>>>>>>>>>>> list rather
>>     >>>>>>>>>>>>>>>> than to me directly in future.
>>     >>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>> The local R2 values are available in some contexts
>>     >>>>>>>>>>>>>>>> when running
>>     >>>>>>>>>>>>>>>> gwr(), but are not well defined (neither in the GWR
>>     >>>>>>>>>>>>>>>> book nor in
>>     >>>>>>>>>>>>>>>> implementations). I advise against their use - they
>>     >>>>>>>>>>>>>>>> are most
>>     >>>>>>>>>>>>>>>> probably meaningless.
>>     >>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>> Hope this helps,
>>     >>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>> Roger Bivand
>>     >>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>>> Thank you very much for your any helps.
>>     >>>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>>> Best regards.
>>     >>>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>>> Yong Huang
>>     >>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>>> --
>>     >>>>>>>>>>>>>>>> Roger Bivand
>>     >>>>>>>>>>>>>>>> Economic Geography Section, Department of
>>     Economics,
>>     >>>>>>>>>>>>>>>> Norwegian
>>     >>>>>>>>>>>>>>>> School of
>>     >>>>>>>>>>>>>>>> Economics and Business Administration,
>>     Helleveien 30,
>>     >>>>>>>>>>>>>>>> N-5045
>>     >>>>>>>>>>>>>>>> Bergen,
>>     >>>>>>>>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>     >>>>>>>>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>     >>>>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>>
>>     >>>>>>>>>>>>>> --
>>     >>>>>>>>>>>>>> Roger Bivand
>>     >>>>>>>>>>>>>> Economic Geography Section, Department of Economics,
>>     >>>>>>>>>>>>>> Norwegian
>>     >>>>>>>>>>>>>> School of
>>     >>>>>>>>>>>>>> Economics and Business Administration, Helleveien 30,
>>     >>>>>>>>>>>>>> N-5045 Bergen,
>>     >>>>>>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>     >>>>>>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>     >>>>>>>>>>>>
>>     >>>>>>>>>>>> --
>>     >>>>>>>>>>>> Roger Bivand
>>     >>>>>>>>>>>> Economic Geography Section, Department of Economics,
>>     >>>>>>>>>>>> Norwegian School
>>     >>>>>>>>>>>> of
>>     >>>>>>>>>>>> Economics and Business Administration, Helleveien 30,
>>     >>>>>>>>>>>> N-5045 Bergen,
>>     >>>>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>     >>>>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>     >>>>>>>>>>
>>     >>>>>>>>>> --
>>     >>>>>>>>>> Roger Bivand
>>     >>>>>>>>>> Economic Geography Section, Department of Economics,
>>     >>>>>>>>>> Norwegian School of
>>     >>>>>>>>>> Economics and Business Administration, Helleveien 30,
>>     N-5045
>>     >>>>>>>>>> Bergen,
>>     >>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>     >>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>     >>>>>>>>
>>     >>>>>>>> --
>>     >>>>>>>> Roger Bivand
>>     >>>>>>>> Economic Geography Section, Department of Economics,
>>     Norwegian
>>     >>>>>>>> School of
>>     >>>>>>>> Economics and Business Administration, Helleveien 30,
>>     N-5045
>>     >>>>>>>> Bergen,
>>     >>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>     >>>>>>>> e-mail: Roger.Bivand at nhh.no
>>     >>>>>>
>>     >>>>>>
>>     >>>>>
>>     >>>>> --
>>     >>>>> Roger Bivand
>>     >>>>> Economic Geography Section, Department of Economics, Norwegian
>>     >>>>> School of
>>     >>>>> Economics and Business Administration, Helleveien 30, N-5045
>>     >>>>> Bergen,
>>     >>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>     >>>>> e-mail: Roger.Bivand at nhh.no
>>     >>>
>>     >>> --
>>     >>> Roger Bivand
>>     >>> Economic Geography Section, Department of Economics, Norwegian
>>     >>> School of
>>     >>> Economics and Business Administration, Helleveien 30, N-5045
>>     Bergen,
>>     >>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>     >>> e-mail: Roger.Bivand at nhh.no
>>     >>
>>     >> [[alternative HTML version deleted]]
>>     >>
>>     >> _______________________________________________
>>     >> R-sig-Geo mailing list
>>     >> R-sig-Geo at stat.math.ethz.ch
>>     >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>>     ------------------------------------------------------------------------
>>     ??????????????????????????????????????????
>>     <http://ym.163.com/?from=od3> 
>
>     -- 
>     ___________________________________________
>     Danlin Yu, Ph.D.
>     Assistant Professor of GIS and Urban Geography
>     Department of Earth & Environmental Studies
>     Montclair State University
>     Montclair, NJ, 07043
>     Tel: 973-655-4313
>     Fax: 973-655-4072
>     email: yud at mail.montclair.edu
>     webpage: csam.montclair.edu/~yu
>
>
>
> ------------------------------------------------------------------------
> ?????????????????????????????????????????? <http://ym.163.com/?from=od3> 

-- 
___________________________________________
Danlin Yu, Ph.D.
Assistant Professor of GIS and Urban Geography
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
email: yud at mail.montclair.edu
webpage: csam.montclair.edu/~yu


From etiennebr at gmail.com  Thu May 13 19:05:20 2010
From: etiennebr at gmail.com (Etienne Bellemare Racine)
Date: Thu, 13 May 2010 13:05:20 -0400
Subject: [R-sig-Geo] readOGR(): stringsAsFactors
In-Reply-To: <1273657975486-5040366.post@n2.nabble.com>
References: <1273562135300-5034706.post@n2.nabble.com>	<alpine.LRH.2.00.1005111139480.11770@reclus.nhh.no>	<1273576777675-5035470.post@n2.nabble.com>	<alpine.LRH.2.00.1005111443210.12555@reclus.nhh.no>	<1273645623545-5039744.post@n2.nabble.com>	<alpine.LRH.2.00.1005120929250.19319@reclus.nhh.no>
	<1273657975486-5040366.post@n2.nabble.com>
Message-ID: <4BEC3150.1010404@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100513/5513c783/attachment.pl>

From jofrhwld at gmail.com  Fri May 14 02:39:19 2010
From: jofrhwld at gmail.com (Josef Fruehwald)
Date: Thu, 13 May 2010 20:39:19 -0400
Subject: [R-sig-Geo] Help with Voronoi Tesselation
Message-ID: <AANLkTimOX_8PRgrYxGe1agRaKRfvMK33PIk-KHgCAklw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100513/36312c76/attachment.pl>

From Roger.Bivand at nhh.no  Fri May 14 10:40:44 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 14 May 2010 10:40:44 +0200 (CEST)
Subject: [R-sig-Geo] How to get the Coefficient of Determination in the
 results of GWR
In-Reply-To: <4c0f7f.7041.12891638426.Coremail.huangykiz@163.com>
References: <alpine.LRH.2.00.1005131135030.19985@reclus.nhh.no>
	<alpine.LRH.2.00.1005121803170.5691@reclus.nhh.no>
	<alpine.LRH.2.00.1005120914260.19319@reclus.nhh.no>
	<alpine.LRH.2.00.1005111834410.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111758330.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111632010.12555@reclus.nhh.no>
	<alpine.LRH.2.00.1005111226160.11770@reclus.nhh.no>
	<7fbb8685.9c9e.12886ce7d95.Coremail.huangykiz@163.com>
	<35fc8b41.9509.128878f8dc7.Coremail.huangykiz@163.com>
	<5cd1a7.aaf7.12887db30ba.Coremail.huangykiz@163.com>
	<1721ac8.cd5c.1288828d49a.Coremail.huangykiz@163.com>
	<e41e5d3.ff74.1288a727c78.Coremail.huangykiz@163.com>
	<e30f5db.13f83.1288d18e217.Coremail.huangykiz@163.com>
	<alpine.LRH.2.00.1005121726190.5691@reclus.nhh.no>
	<342188fb.6e7b.12890806f61.Coremail.huangykiz@163.com>
	<4c0f7f.7041.12891638426.Coremail.huangykiz@163.com>
Message-ID: <alpine.LRH.2.00.1005141037200.3526@reclus.nhh.no>

On Thu, 13 May 2010, huangykiz wrote:

> Hi,
> 
> My coordinates geographical are decimal degrees. I am soryy I donot know 
> how to and what do copy and paste from SAM to gwr()? I cannot see the 
> code of SAM.

If they are, then you must use longlat=TRUE, otherwise the distances 
computed will be in inappropriate and varying arbitrary units. Please do 
read the help pages for the functions you are trying to use. To compare 
different implementations, here gwr.sel() and gwr() in R with SAM, you 
must make sure that the implementations are receiving the same input.

> 
> Thanks a lot.
>
> Cheers.
>
>
>
> ?2010-05-13 17:43:06?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>> On Thu, 13 May 2010, huangykiz wrote:
>>
>>> Hi,
>>
>>> I am sorry I say that I cannot get the same R^2 between in R/spgwr and 
>>> SAM in my data.
>>
>> Establish that the adaptive proportion is exactly the same.
>>
>> You haven't done that - copy and paste from SAM to gwr(), not using 
>> gwr.sel(). Do it first for fixed Gaussian, then if you get a sensible 
>> figure from SAM for adaptive, do the same there. I see very different 
>> bandwidths chosen by SAM and by gwr.sel() and GWR3 - gwr.sel() and GWR3 
>> usually agree fairly well for CV fixed bandwidths, but gwr.sel() typically 
>> continues its search a little longer than GWR3.
>>
>> I don't know how SAM chooses its bandwidth or adaptive proportion, it is 
>> closed source, so only its authors know.
>>
>> Is SAM using Great Circle distances, if so, you should set longlat=TRUE in 
>> gwr.sel() and gwr()? Are your coordinates geographical (decimal degrees) 
>> or projected (metres)?
>>
>> Roger
>>
>>> In R/spgwr
>>> R^2:    0.972989;
>>> AICc (GWR p. 61, eq 2.33; p. 96, eq. 4.21): 4668.92
>>> Effective number of parameters (model: traceS): 435.7586; 
>>> Effective number of parameters (residual: 2traceS - traceS'S): 582.3581;
>>> Sigma (residual: 2traceS - traceS'S): 2.437066;
>>> Sigma (model: traceS): 1.927127;
>>> Sigma (ML): 1.325501;
>>> 
>>> In SAM,
>>> Coefficient of Determination :           0.696 
>>> Adjusted r-square (r?Adj):                 0.693 
>>> Sigma:                                             20.058 
>>> Effective Number of Parameters:          10.002 
>>> Akaike Information Criterion (AICc):      4838.299 
>>> Correlation Coefficient (r):                    0.834 
>>> F:                                                   207.852 
>>> 
>>> Here are my code:
>>> PET.adapt.gauss <- gwr.sel(SPECIES_RI ~ PET, data=Environmental_variables, coords=cbind(Environmental_variables$LONGX, 
>>> Environmental_variables$LATY),adapt=TRUE)
>>> 
>>> PET.gauss<- gwr(SPECIES_RI ~ PET, data=Environmental_variables, coords=cbind(Environmental_variables$LONGX, 
>>> Environmental_variables$LATY), gweight=gwr.Gauss,adapt=PET.adapt.gauss,hatmatrix=TRUE)
>>> 
>>> 1 - (PET.gauss$results$rss/crossprod(scale(Environmental_variables$SPECIES_RI, scale=FALSE)))
>>> 
>>> In SAM, I selecte "spatial Weighting Function"=gaussian, adaptive 
>>> Spatial Kernel, and compute Geographical Distances based on longitudinal 
>>> coordinate(X) and latitudinal coordinate(Y). I donot select method for 
>>> AIC optimisation.
>>> 
>>> So I donot know where is wrong.
>>> 
>>> Thank you very much for your great helps.
>>> 
>>> 
>>> 
>>> 
>>> 
>>>
>>> ?2010-05-13 00:07:23?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>> On Wed, 12 May 2010, Roger Bivand wrote:
>>>>
>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>>>>
>>>>>> Hi, Is "adapt=TRUE"(spgwr) not the same as "adaptive Spatial 
>>>>>> Kernel"(SAM)?The result of "adaptive Spatial Kernel" may be better than 
>>>>>> fixed bandwidth. If I want to ues "adaptive Spatial Kernel" in spgwr, how 
>>>>>> to write the code?
>>>>>
>>>>> READ THE HELP PAGES!
>>>>>
>>>>> adaptive_proportion <- gwr.sel(...)
>>>>>
>>>>> result <- gwr(..., adapt=adaptive_proportion; ...)
>>>>>
>>>>> exactly as on the example om the help page:
>>>>>
>>>>> data(georgia)
>>>>> g.adapt.gauss <- gwr.sel(PctBach ~ TotPop90 + PctRural + PctEld + PctFB +
>>>>>  PctPov + PctBlack, data=gSRDF, adapt=TRUE)
>>>>> res.adpt <- gwr(PctBach ~ TotPop90 + PctRural + PctEld + PctFB + PctPov +
>>>>>  PctBlack, data=gSRDF, adapt=g.adapt.gauss)
>>>>> res.adpt
>>>>>
>>>>> Clear?
>>>>
>>>> I have now compared the same data in R/spgwr and SAM for effective number 
>>>> of parameters, sigma, and your questionable R^2, and they agree adequately 
>>>> when the kernel and the bandwidth are the same. Having the algorithm 
>>>> choose the bandwidth does obscure what is going on. You should use SAM if 
>>>> you prefer GUI and not needing to know how things work, and remember that 
>>>> GWR is a very doubtful approach for anything beyond exploring 
>>>> non-stationarity, its original motivation.
>>>>
>>>>>
>>>>>> 
>>>>>> Thanks a lot.
>>>>>> 
>>>>>> Cheers.
>>>>>> 
>>>>>> 
>>>>>>> Hi,
>>>>>>> I think that I use the same bandwidth and kernel. In SAM, I use "spatial 
>>>>>>> Weighting Function"=gaussian, adaptive Spatial Kernel, and compute 
>>>>>>> Geographical Distances based on longitudinal coordinate(X) and latitudinal 
>>>>>>> coordinate(Y). In spgwr, gweight is gwr.Gauss and adapt is TRUE.
>>>>>>> 
>>>>>>> For example, this is my code:
>>>>>> 
>>>>>>> PET.bw <- gwr.sel(SPECIES_RI ~ PET, data=variables, 
>>>>>>> coords=cbind(variables$LONGX, variables$LATY),adapt=TRUE)
>>>>>> 
>>>>>>> PET.gauss <- gwr(SPECIES_RI ~ PET, data=variables, 
>>>>>>> coords=cbind(variables$LONGX, variables$LATY), bandwidth=PET.bw, 
>>>>>>> gweight=gwr.Gauss,adapt=TRUE,hatmatrix=TRUE)
>>>>>> 
>>>>>> So where do you pass PET.bw to the gwr() function? adapt=TRUE will treat 
>>>>>> the adaptive proportion as 1, so include all data points. If you want to 
>>>>>> compare, use a fixed bandwidth in both, with no CV selection. Then you 
>>>>>> compare like with like.
>>>>>> 
>>>>>> Note that your messages are *not* reaching the list, they must be sent to:
>>>>>> 
>>>>>> r-sig-geo at stat.math.ethz.ch, not
>>>>>> 
>>>>>> r-sig-geo-request at stat.math.ethz.ch
>>>>>> 
>>>>>> You are not thinking carefully and are rushing into things and drawing 
>>>>>> wrong conclusions.
>>>>>> 
>>>>>>> 
>>>>>>> Thanks a lot.
>>>>>>> 
>>>>>>> Cheers.
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> ?2010-05-12 20:28:47?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>>>>>>> 
>>>>>>>>> Hi,
>>>>>>>>> One of SAM author ("Jos? Alexandre Felizola Diniz 
>>>>>>>>> Filho"<diniz at icb.ufg.br>) say that they also base on GWR3 (the 
>>>>>>>>> Fotherigham book)  and the data used within each kernel may be some 
>>>>>>>>> slight differences
>>>>>>>> 
>>>>>>>> Naturally, if you are not using exactly the same kernel and bandwidth, 
>>>>>>>> you should not be surprised by differences in values. Please make sure 
>>>>>>>> that the bandwidth and kernel are the same and try again.
>>>>>>>> 
>>>>>>>> Roger
>>>>>>>> 
>>>>>>>>> Cheers
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> ?2010-05-12 20:28:47?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>>>>>> 
>>>>>>>> Hi,
>>>>>>>> One of SAM author ("Jos? Alexandre Felizola Diniz 
>>>>>>>> Filho"<diniz at icb.ufg.br>) say that they also base on GWR3 (the 
>>>>>>>> Fotherigham book)  and the data used within each kernel may be some 
>>>>>>>> slight differences
>>>>>>> 
>>>>>>> Naturally, if you are not using exactly the same kernel and bandwidth, you 
>>>>>>> should not be surprised by differences in values. Please make sure that 
>>>>>>> the bandwidth and kernel are the same and try again.
>>>>>>> 
>>>>>>> Roger
>>>>>>> 
>>>>>>>> Cheers.
>>>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> ?2010-05-12 15:27:58?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>>>>>> 
>>>>>>>> Hi,
>>>>>>>> 
>>>>>>>> I am sorry I donot know how to install module spgwr from sourceforge (I 
>>>>>>>> can find it on the web 
>>>>>>>> http://r-spatial.cvs.sourceforge.net/viewvc/r-spatial/spgwr/R/gwr.R?view=log). 
>>>>>>>> So I use the code sketch to calculate quasi-global R2. The results are 
>>>>>>>> different between SAM and spgwr(Attached are the results ). The 
>>>>>>>> quasi-global R2 in R is 0.4515894, but in SAM is 0.696.
>>>>>>>> This is my code:
>>>>>>>> 
>>>>>>>> library(spgwr)
>>>>>>>> Environmental_variables<-read.csv("Environmental_variables100.csv",header=TRUE)
>>>>>>>> attach(Environmental_variables)
>>>>>>>> region_PET.bw <- gwr.sel(SPECIES_RI ~ PET, data=Environmental_variables, 
>>>>>>>> coords=cbind(Environmental_variables$LONGX, 
>>>>>>>> Environmental_variables$LATY),adapt=TRUE)
>>>>>>>> region_PET.gauss <- gwr(SPECIES_RI ~ PET, data=Environmental_variables, 
>>>>>>>> coords=cbind(Environmental_variables$LONGX, 
>>>>>>>> Environmental_variables$LATY), bandwidth=region_PET.bw, 
>>>>>>>> gweight=gwr.Gauss,adapt=TRUE,hatmatrix=TRUE)
>>>>>>>> names(region_PET.gauss$SDF)
>>>>>>>> region_PET.gauss$SDF$localR2
>>>>>>>> 1 - 
>>>>>>>> (region_PET.gauss$results$rss/crossprod(scale(Environmental_variables$SPECIES_RI, 
>>>>>>>> scale=FALSE)))
>>>>>>>> 
>>>>>>>> Thank you very much.
>>>>>>> 
>>>>>>> SAM is closed source - ask them how they compute it. For spgwr, the code 
>>>>>>> is provided, so you can read it for yourself. For the record, the current 
>>>>>>> gwr() code in spgwr gives the same value as GWR3, which is also closed 
>>>>>>> source, and where the Effective number of parameters (model: traceS), 
>>>>>>> Sigma, and Residual sum of squares also agree. I suppose SAM has a 
>>>>>>> different understanding of GWR internals than the authors of the GWR book.
>>>>>>> 
>>>>>>> Once again:
>>>>>>> 
>>>>>>> Please *do* write to the R-sig-geo list rather than to me directly -
>>>>>>> others can answer your question as well, perhaps better, and in a more
>>>>>>> timely way than I can. In addition, threads in the list can be searched in
>>>>>>> the archives, so others can avoid the same problem later.
>>>>>>> 
>>>>>>> Please summarise to the list if this resolves the problem.
>>>>>>> 
>>>>>>> Roger
>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> ?2010-05-12 01:16:18?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>>>>>> On Wed, 12 May 2010, huangykiz wrote:
>>>>>>>>> 
>>>>>>>>>> Hi, I just need one for global, not *each* fit point. In this case, how 
>>>>>>>>>> can I select or do? Why in other software such as SAM(Spatial Analysis 
>>>>>>>>>> in Macroecology) just gives one R2?
>>>>>>>>> 
>>>>>>>>> If you believe theirs, good luck! The authors of the GWR book have local 
>>>>>>>>> R^2 values in GWR3 and formulae that are wrong by their own admission in 
>>>>>>>>> private emails. The localR2 now agrees with the as-yet unreleased GWR4 
>>>>>>>>> from the GWR authors. How SAM can be "better", I don't know. What you 
>>>>>>>>> are suggesting is that the model fitted with fit points at data points 
>>>>>>>>> (but not at other fit points) might have a "quasi-global" R^2, based on 
>>>>>>>>> the RSS of the pooled fit. For the columbus case, that might be:
>>>>>>>>> 
>>>>>>>>> 1 - (col.gauss$results$rss/crossprod(scale(columbus$crime, 
>>>>>>>>> scale=FALSE)))
>>>>>>>>> 
>>>>>>>>> but I don't know whether this is in any way correct. I've added it as:
>>>>>>>>> 
>>>>>>>>> Quasi-global R2:
>>>>>>>>> 
>>>>>>>>> to the print output of a GWR model fitted with a hatmatrix, and have 
>>>>>>>>> committed it to sourceforge, project r-spatial, module spgwr. Arguably, 
>>>>>>>>> it ought to be adjusted by the ratio of degrees of freedom, but I don't 
>>>>>>>>> trust the DF either. Could you please check out spgwr from sourceforge 
>>>>>>>>> ,install it from source, and confirm that the "quasi-global R2" does the 
>>>>>>>>> same as SAM, or use the code sketch above to do the same, and report 
>>>>>>>>> back?
>>>>>>>>> 
>>>>>>>>> Roger
>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Thanks a lot.
>>>>>>>>>> 
>>>>>>>>>> Cheers,
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> ?2010-05-11 23:59:44?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>>>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>>>>>>>>>> 
>>>>>>>>>>>> Hi,
>>>>>>>>>>>> 
>>>>>>>>>>>> There are 49  localR2 in the results. Which one do I need? The code 
>>>>>>>>>>>> "look for localR2:" cannot run.
>>>>>>>>>>> 
>>>>>>>>>>> Well, how many do you want? There is one for each fit point, they are 
>>>>>>>>>>> *local* R2. Please do try to grasp what GWR does - it fits one moddel 
>>>>>>>>>>> for *each* fit point.
>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> Thans a lot
>>>>>>>>>>>> 
>>>>>>>>>>>> Cheers.
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> ?2010-05-11 22:33:59?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>>>>>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Hi, OK. But I need it for compariation. In what some contexts to 
>>>>>>>>>>>>>> get it? May you tell me how to get it?
>>>>>>>>>>>>> 
>>>>>>>>>>>>> library(spgwr)
>>>>>>>>>>>>> data(columbus)
>>>>>>>>>>>>> col.bw <- gwr.sel(crime ~ income + housing, data=columbus,
>>>>>>>>>>>>>  coords=cbind(columbus$x, columbus$y))
>>>>>>>>>>>>> col.gauss <- gwr(crime ~ income + housing, data=columbus,
>>>>>>>>>>>>>  coords=cbind(columbus$x, columbus$y), bandwidth=col.bw, 
>>>>>>>>>>>>> hatmatrix=TRUE)
>>>>>>>>>>>>> names(col.gauss$SDF)
>>>>>>>>>>>>> 
>>>>>>>>>>>>> look for localR2:
>>>>>>>>>>>>> 
>>>>>>>>>>>>> col.gauss$SDF$localR2
>>>>>>>>>>>>> 
>>>>>>>>>>>>> But do not rely on it or use it for anything at all! Like all GWR, 
>>>>>>>>>>>>> it is most unreliable!
>>>>>>>>>>>>> 
>>>>>>>>>>>>> Roger Bivand
>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Thank you very much for your great helps
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> Best regards.
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> 
>>>>>>>>>>>>>> ?2010-05-11 18:28:44?"Roger Bivand" <Roger.Bivand at nhh.no> ???
>>>>>>>>>>>>>>> On Tue, 11 May 2010, huangykiz wrote:
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> Dear professor Bivand,
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> I am a strudent. I recently use GWR(Geographically weighted 
>>>>>>>>>>>>>>>> regression) model. May I ask you a question? There is not 
>>>>>>>>>>>>>>>> Coefficient of Determination in the results of GWR. How can I get 
>>>>>>>>>>>>>>>> it? What is the programs to get it?
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> Please address questions like this to the R-sig-geo list rather 
>>>>>>>>>>>>>>> than to me directly in future.
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> The local R2 values are available in some contexts when running 
>>>>>>>>>>>>>>> gwr(), but are not well defined (neither in the GWR book nor in 
>>>>>>>>>>>>>>> implementations). I advise against their use - they are most 
>>>>>>>>>>>>>>> probably meaningless.
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> Hope this helps,
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> Roger Bivand
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> Thank you very much for your any helps.
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> Best regards.
>>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>>> Yong Huang
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>>>> -- 
>>>>>>>>>>>>>>> Roger Bivand
>>>>>>>>>>>>>>> Economic Geography Section, Department of Economics, Norwegian 
>>>>>>>>>>>>>>> School of
>>>>>>>>>>>>>>> Economics and Business Administration, Helleveien 30, N-5045 
>>>>>>>>>>>>>>> Bergen,
>>>>>>>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>>>>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>>>>>>>>>>> 
>>>>>>>>>>>>> 
>>>>>>>>>>>>> -- 
>>>>>>>>>>>>> Roger Bivand
>>>>>>>>>>>>> Economic Geography Section, Department of Economics, Norwegian 
>>>>>>>>>>>>> School of
>>>>>>>>>>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>>>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>>>>>>> 
>>>>>>>>>>> -- 
>>>>>>>>>>> Roger Bivand
>>>>>>>>>>> Economic Geography Section, Department of Economics, Norwegian School 
>>>>>>>>>>> of
>>>>>>>>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>>>>> 
>>>>>>>>> -- 
>>>>>>>>> Roger Bivand
>>>>>>>>> Economic Geography Section, Department of Economics, Norwegian School of
>>>>>>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>>> 
>>>>>>> -- 
>>>>>>> Roger Bivand
>>>>>>> Economic Geography Section, Department of Economics, Norwegian School of
>>>>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>
>>>>>
>>>>
>>>> -- 
>>>> Roger Bivand
>>>> Economic Geography Section, Department of Economics, Norwegian School of
>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>> e-mail: Roger.Bivand at nhh.no
>>
>> -- 
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From roman.lustrik at gmail.com  Fri May 14 10:45:12 2010
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Fri, 14 May 2010 10:45:12 +0200
Subject: [R-sig-Geo] trying to plot listed RasterLayers
Message-ID: <AANLkTimdK4gOLNm2mGybwL5U5fy-wjbGcUgV9pmkY4TM@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100514/e1c19530/attachment.pl>

From jacobvanetten at yahoo.com  Fri May 14 12:57:36 2010
From: jacobvanetten at yahoo.com (Jacob van Etten)
Date: Fri, 14 May 2010 03:57:36 -0700 (PDT)
Subject: [R-sig-Geo] trying to plot listed RasterLayers
In-Reply-To: <AANLkTimdK4gOLNm2mGybwL5U5fy-wjbGcUgV9pmkY4TM@mail.gmail.com>
Message-ID: <365499.75567.qm@web32903.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100514/1f4127a9/attachment.pl>

From saldanha.plangeo at gmail.com  Fri May 14 14:53:11 2010
From: saldanha.plangeo at gmail.com (Raphael Saldanha)
Date: Fri, 14 May 2010 09:53:11 -0300
Subject: [R-sig-Geo] Region raster
Message-ID: <AANLkTiny8iSa-us0aTLus6PURlnAd4mP25HEjBFmaBg6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100514/9fede794/attachment.pl>

From carson.farmer at gmail.com  Fri May 14 15:44:09 2010
From: carson.farmer at gmail.com (Carson Farmer)
Date: Fri, 14 May 2010 14:44:09 +0100
Subject: [R-sig-Geo] Help with Voronoi Tesselation
In-Reply-To: <AANLkTimOX_8PRgrYxGe1agRaKRfvMK33PIk-KHgCAklw@mail.gmail.com>
References: <AANLkTimOX_8PRgrYxGe1agRaKRfvMK33PIk-KHgCAklw@mail.gmail.com>
Message-ID: <AANLkTil9S2AwS1RmYhOFCXVP0jQDDl3TW2pppOinipDW@mail.gmail.com>

Does this help at all?
http://www.carsonfarmer.com/?p=455

Carson

On Fri, May 14, 2010 at 1:39 AM, Josef Fruehwald <jofrhwld at gmail.com> wrote:
> Hi All,
>
> I'm somewhat of a novice at doing spatial analysis in R, so forgive me if my
> question is obvious, or misposted.
>
> I have a number of points located within the United States. My goal is to
> compute the voronoi tessellation, bounded by the borders of the US. I would
> like to eventually format this as a dataframe of coordinates with a grouping
> ID column so that I can plot the polygons in ggplot2.
>
> Here's what I've got so far.
>
> cities <- structure(list(CitState = c("SiouxFalls SD", "Rockford IL",
> "Kenosha WI",
> "Duluth MN", "SiouxCity IA", "CedarRapids IA", "NewYork NY"),
> ? ?Latitude = c(43.54599, 42.265973, 42.577791, 46.779135, 42.489678,
> ? ?41.976662, 40.756054), Longitude = c(-96.731291, -89.086667,
> ? ?-87.822644, -92.108243, -96.404948, -91.673155, -73.986951
> ? ?)), .Names = c("CitState", "Latitude", "Longitude"), row.names = c(1L,
> 2L, 3L, 4L, 5L, 6L, 267L), class = "data.frame")
>
> library(maps)
> library(spatstat)
> us <- data.frame(map("usa", regions = "main",plot = F)[c("x","y")])
> manhattan <- data.frame(map("usa", regions = "manhattan",plot =
> F)[c("x","y")])
> spatstat.options(checkpolygons = FALSE)
> us.win <- owin(poly = list(list(x = us$x, y = us$y),list(x = manhattan$x,y =
> manhattan$y)))
> us.ppp <- ppp(cities$Longitude, cities$Latitude, window = us.win)
>
> But, if I use dirichlet() on us.ppp, it gives me back a pixel array. If I
> use deldir() on us.ppp, the boundaries of the tesselations don't seem to be
> constrained by the US borders, and I can't figure out how to extract the
> polygons from the object.
>
> plot(dirichlet(us.ppp))
> ##
> map("usa")
> plot(deldir(us.ppp), wlines = "tess",add = T)
>
> If I could extract from some object, a list of polygons, I could probably
> get the rest done myself.
>
> Thanks in advance!
>
> -Joe
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Carson J. Q. Farmer
ISSP Doctoral Fellow
National Centre for Geocomputation
National University of Ireland, Maynooth,
http://www.carsonfarmer.com/


From jacobvanetten at yahoo.com  Fri May 14 15:53:14 2010
From: jacobvanetten at yahoo.com (Jacob van Etten)
Date: Fri, 14 May 2010 06:53:14 -0700 (PDT)
Subject: [R-sig-Geo] Region raster
In-Reply-To: <AANLkTiny8iSa-us0aTLus6PURlnAd4mP25HEjBFmaBg6@mail.gmail.com>
Message-ID: <750106.72869.qm@web32903.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100514/1c78bfc1/attachment.pl>

From bohara at unm.edu  Fri May 14 16:10:29 2010
From: bohara at unm.edu (Alok K Bohara, PhD)
Date: Fri, 14 May 2010 08:10:29 -0600
Subject: [R-sig-Geo] spatial count regression model
In-Reply-To: <AANLkTil9S2AwS1RmYhOFCXVP0jQDDl3TW2pppOinipDW@mail.gmail.com>
References: <AANLkTimOX_8PRgrYxGe1agRaKRfvMK33PIk-KHgCAklw@mail.gmail.com>
	<AANLkTil9S2AwS1RmYhOFCXVP0jQDDl3TW2pppOinipDW@mail.gmail.com>
Message-ID: <4BED59D5.8000509@unm.edu>

Dear all:

Do you know of any R package that can to do spatial regression poisson 
or spatial regression NB model (not using the filtering) by taking into 
account the spatial correlation --neighborhood effect.  I am looking for 
something that can do e.g., CAR type models.  I used spatcounts to do a 
spatial poisson but the spatial correlation (gamma and psi) both turned 
out to be 0, showing that there is no spatial effect (I think).  Yet, I 
know there is a strong spatial effect in  my data.   I just have a one 
set of count data on 800 cells with co-variates (30 % with 0) --that is, 
no repeated counts for each cells.   Thanks.

Best,
Alok Bohara



-- 
Alok K. Bohara, Ph.D.
Professor
Department of Economics
MSC 05 3060
1 University of New Mexico
Albuquerque, NM 87131-0001, USA
Ph: 505-277-5903/5304(w)
Fax:505-277-9445
email: bohara at unm.edu
http://www.unm.edu/~econ/faculty/professors.html
Nepal Study Center: http://nepalstudycenter.unm.edu


From valerio.bartolino at uniroma1.it  Sat May 15 13:05:32 2010
From: valerio.bartolino at uniroma1.it (valerio.bartolino at uniroma1.it)
Date: Sat, 15 May 2010 13:05:32 +0200
Subject: [R-sig-Geo] K-function and bootstrap
Message-ID: <OF23100266.D5FCDAFE-ONC1257724.003CEE6C-C1257724.003CEE74@Uniroma1.it>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100515/b82f0896/attachment.html>

From alobolistas at gmail.com  Sun May 16 23:04:49 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Sun, 16 May 2010 14:04:49 -0700 (PDT)
Subject: [R-sig-Geo] Error at reading shape file (readOGR())
Message-ID: <1274043889831-5062752.post@n2.nabble.com>


Hi!

I'm getting this error at reading a shape file that comes from a third
party:
> AilantMSY09 <-
> readOGR(dsn="/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09/",layer="AilantMSY09")
OGR data source with driver: ESRI Shapefile 
Source:
"/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09/",
layer: "AilantMSY09"
with 62 features and 29 fields
Error in make.names(fldnms, unique = TRUE) : invalid multibyte string 9

(Using R version 2.11.0, rgdal 0.6-26 and GDAL 1.6.3)

Any guide on how to debug this problem? I've looked at the dbf file and
do not see anything weird. I can display the file using QGIS, but cannot 
create a csv file (but QGIS uses OGR also, so this is not really an
alternative).

Thanks for any help
(I can post the file if needed)

Agus
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Error-at-reading-shape-file-readOGR-tp5062752p5062752.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From b.rowlingson at lancaster.ac.uk  Sun May 16 23:13:45 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sun, 16 May 2010 22:13:45 +0100
Subject: [R-sig-Geo] Error at reading shape file (readOGR())
In-Reply-To: <1274043889831-5062752.post@n2.nabble.com>
References: <1274043889831-5062752.post@n2.nabble.com>
Message-ID: <AANLkTilMLs6WDbMg3LGMcPZ_wxDX-jBiGhUeR4Ll1cup@mail.gmail.com>

On Sun, May 16, 2010 at 10:04 PM, Agustin Lobo <alobolistas at gmail.com> wrote:

> OGR data source with driver: ESRI Shapefile
> Source:
> "/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09/",
> layer: "AilantMSY09"
> with 62 features and 29 fields
> Error in make.names(fldnms, unique = TRUE) : invalid multibyte string 9

 The error message seems to come from the part of the code that
converts the DBF column names to valid R column names...

> (Using R version 2.11.0, rgdal 0.6-26 and GDAL 1.6.3)
>
> Any guide on how to debug this problem? I've looked at the dbf file and
> do not see anything weird.

 Ah, but one man's weird is another man's accented character! Do the
column names of the DBF have anything that someone on my side of the
English Channel would think of as 'weird'? :)

 How does read.dbf in the foreign package handle the DBF part of the shapefile?

Barry


From alobolistas at gmail.com  Sun May 16 23:43:02 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Sun, 16 May 2010 14:43:02 -0700 (PDT)
Subject: [R-sig-Geo] Error at reading shape file (readOGR())
In-Reply-To: <AANLkTilMLs6WDbMg3LGMcPZ_wxDX-jBiGhUeR4Ll1cup@mail.gmail.com>
References: <1274043889831-5062752.post@n2.nabble.com>
	<AANLkTilMLs6WDbMg3LGMcPZ_wxDX-jBiGhUeR4Ll1cup@mail.gmail.com>
Message-ID: <1274046182484-5062839.post@n2.nabble.com>


Thanks!
Identical error with read.dbf(). I'll try to change the names of the fields
with OO or QGIS and
will let you know.
Agus
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Error-at-reading-shape-file-readOGR-tp5062752p5062839.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From clelia.bilodeau at gmail.com  Mon May 17 03:20:11 2010
From: clelia.bilodeau at gmail.com (=?ISO-8859-1?Q?Cl=E9lia_Bilodeau?=)
Date: Mon, 17 May 2010 03:20:11 +0200
Subject: [R-sig-Geo] Zonal {raster}: function with very large files
Message-ID: <AANLkTimxQBglrjWRAj35QLIi3458wBT_xU_S6W-H7DUH@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100517/847e8a97/attachment.pl>

From clelia.bilodeau at gmail.com  Mon May 17 03:29:27 2010
From: clelia.bilodeau at gmail.com (=?ISO-8859-1?Q?Cl=E9lia_Bilodeau?=)
Date: Mon, 17 May 2010 03:29:27 +0200
Subject: [R-sig-Geo] Zonal {raster}: function with very large files
Message-ID: <AANLkTikP7PnFCrOGwgrvJGlI2q8QeZDf2QrNYm6CyCc0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100517/217ff5bc/attachment.pl>

From Adrian.Baddeley at csiro.au  Mon May 17 07:36:55 2010
From: Adrian.Baddeley at csiro.au (Adrian.Baddeley at csiro.au)
Date: Mon, 17 May 2010 13:36:55 +0800
Subject: [R-sig-Geo] Help with Voronoi Tesselation
Message-ID: <57DC18C299094D4299F837570C5DF1C52B143367EA@EXWA-MBX01.nexus.csiro.au>

Josef Fruehwald <jofrhwld at gmail.com> writes: 

> I have a number of points located within the United States. My goal is to
> compute the voronoi tessellation, bounded by the borders of the US
  [ ...]
> But, if I use dirichlet() on us.ppp, it gives me back a pixel array.

This is a query about the 'spatstat' package. 

You want the software to clip the Dirichlet polygons to the USA boundary. Polygon computations in spatstat currently depend on the package 'gpclib'. This package has a restrictive licence, so it is turned off by default, and you get a pixel image instead.

To enable polygon computations, type
           spatstat.options(gpclib=TRUE)
Please type licence.polygons() for more information about the licence conditions. 

If the licence conditions do not allow you to use gpclib, then I suggest you replace the USA boundary by a rectangle. Then dirichlet() will give a list of polygons, which you can extract and deal with yourself.

Adrian Baddeley

.............................. Full message ..............................................

> I have a number of points located within the United States. My goal is to
> compute the voronoi tessellation, bounded by the borders of the US. I would
> like to eventually format this as a dataframe of coordinates with a grouping
> ID column so that I can plot the polygons in ggplot2.

> library(maps)
> library(spatstat)
  [...]
> us.win <- owin(poly = list(list(x = us$x, y = us$y),list(x = manhattan$x,y =
> manhattan$y)))
> us.ppp <- ppp(cities$Longitude, cities$Latitude, window = us.win)

> But, if I use dirichlet() on us.ppp, it gives me back a pixel array. If I
> use deldir() on us.ppp, the boundaries of the tesselations don't seem to be
> constrained by the US borders, and I can't figure out how to extract the
> polygons from the object.
> plot(dirichlet(us.ppp))
> map("usa")
> plot(deldir(us.ppp), wlines = "tess",add = T)
> If I could extract from some object, a list of polygons, I could probably
> get the rest done myself.

From alobolistas at gmail.com  Mon May 17 11:08:16 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Mon, 17 May 2010 02:08:16 -0700 (PDT)
Subject: [R-sig-Geo] Error at reading shape file (readOGR())
In-Reply-To: <1274046182484-5062839.post@n2.nabble.com>
References: <1274043889831-5062752.post@n2.nabble.com>
	<AANLkTilMLs6WDbMg3LGMcPZ_wxDX-jBiGhUeR4Ll1cup@mail.gmail.com>
	<1274046182484-5062839.post@n2.nabble.com>
Message-ID: <1274087296924-5064220.post@n2.nabble.com>


Solved: it was an accent, I just edited the name of the field with plugin
Table manager in QGIS.
Nevertheless, if QGIS can manage the file, why not R? should not be a matter
of having
an option for the charset? 
I tend to not to use non-ascii characters in files, but many agencies do.

Thanks!

Agus
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Error-at-reading-shape-file-readOGR-tp5062752p5064220.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From alobolistas at gmail.com  Mon May 17 12:08:43 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Mon, 17 May 2010 03:08:43 -0700 (PDT)
Subject: [R-sig-Geo] writeOGR to GPX file: empty table
Message-ID: <1274090923881-5064393.post@n2.nabble.com>


Hi!,

I'm converting from shape to gpx through rgdal (I get an empty file with
gpsbabel and, according to its web, I'm not convinced that the shape format
is actually fully supported by gpsbabel).

This is what I do:
> AilantMSY09 <-
> readOGR(dsn="/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09/",layer="AilantMSY09")
OGR data source with driver: ESRI Shapefile 

> writeOGR(AilantMSY09,
> dsn="/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09GPX",layer="AilantMSY09GPX",driver="GPX")
Error in writeOGR(AilantMSY09, dsn =
"/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09GPX", 
: 
  
	GDAL Error 6: Field of name 'Comentario' is not supported in GPX schema.
Use GPX_USE_EXTENSIONS creation option to allow use of the <extensions>
element.

After reading the gdal-ogr doc, I include dataset_options:

> writeOGR(AilantMSY09,
> dsn="/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09GPX",layer="AilantMSY09GPX",driver="GPX",dataset_options="GPX_USE_EXTENSIONS=YES")
Error in writeOGR(AilantMSY09, dsn =
"/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09GPX", 
: 
  
	GDAL Error 1: Latitude 4627933.603181 is invalid. Valid range is [-90,90].
This warning will not be issued any more

Which indicates that the user must unproject first (it seems that GPX files
only support lon,lat):

> AilantMSY09WGS84LL <- spTransform(AilantMSY09, CRS("+proj=longlat
> +ellps=WGS84"))
Warning message:
In spTransform(xSP, CRSobj) :
  Only x- and y-coordinates are being transformed

> writeOGR(AilantMSY09WGS84LL,
> dsn="/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09GPX.gpx",layer="AilantMSY09GPX",driver="GPX",dataset_options="GPX_USE_EXTENSIONS=YES")

Once in QGIS, the points are in the right sites but the attribute table is
all NULLs

This is not a concern (by now) for me as I just need the gpx file to upload
the points to the gps unit,
but report it just in case this is a bug and/or to know if I'm doing
something wrong.

Note: I do get the correct table for the gpx file using plugin OGR converter
in QGIS.

Thanks

Agus
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/writeOGR-to-GPX-file-empty-table-tp5064393p5064393.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From b.rowlingson at lancaster.ac.uk  Mon May 17 12:36:55 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 17 May 2010 11:36:55 +0100
Subject: [R-sig-Geo] Error at reading shape file (readOGR())
In-Reply-To: <1274087296924-5064220.post@n2.nabble.com>
References: <1274043889831-5062752.post@n2.nabble.com>
	<AANLkTilMLs6WDbMg3LGMcPZ_wxDX-jBiGhUeR4Ll1cup@mail.gmail.com>
	<1274046182484-5062839.post@n2.nabble.com>
	<1274087296924-5064220.post@n2.nabble.com>
Message-ID: <AANLkTinNW3a6f9qPrcffrroVpIqeOQftGrPuQc9U8XQM@mail.gmail.com>

On Mon, May 17, 2010 at 10:08 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
>
> Solved: it was an accent, I just edited the name of the field with plugin
> Table manager in QGIS.
> Nevertheless, if QGIS can manage the file, why not R? should not be a matter
> of having
> an option for the charset?
> I tend to not to use non-ascii characters in files, but many agencies do.

 It's either your version of R/rgdal or something more specific in the
column names. I've just created a shapefile with accented column names
and it's read into R fine:

> s=readOGR(".","accents")
OGR data source with driver: ESRI Shapefile
Source: ".", layer: "accents"
with 2 features and 2 fields
Feature type: wkbPoint with 2 dimensions
> s
            coordinates  ?? ID
1 (-0.438119, 0.515347) Foo  1
2 (0.0163366, 0.182673) Bar  2

 - that's a column name of e-with-two-dots and a-with-a-circle. it was
created in Qgis by pasting characters from the Latin page in a
character map utility. The Unicodes are  U+00EB and U+00E5.

  Suggest you post a cut-down version of your DBF somewhere with a few
rows and columns (not the whole thing if its more than 10 rows and
cols) and we'll see if it croaks with us too. And your R/rgdal
version!

 Barry


From Roger.Bivand at nhh.no  Mon May 17 13:06:01 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 17 May 2010 13:06:01 +0200 (CEST)
Subject: [R-sig-Geo] Error at reading shape file (readOGR())
In-Reply-To: <1274087296924-5064220.post@n2.nabble.com>
References: <1274043889831-5062752.post@n2.nabble.com>
	<AANLkTilMLs6WDbMg3LGMcPZ_wxDX-jBiGhUeR4Ll1cup@mail.gmail.com>
	<1274046182484-5062839.post@n2.nabble.com>
	<1274087296924-5064220.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.00.1005171256270.15971@reclus.nhh.no>

On Mon, 17 May 2010, Agustin Lobo wrote:

>
> Solved: it was an accent, I just edited the name of the field with plugin
> Table manager in QGIS.
> Nevertheless, if QGIS can manage the file, why not R? should not be a matter
> of having
> an option for the charset?
> I tend to not to use non-ascii characters in files, but many agencies do.

Did you try any variant of the input_field_name_encoding= argument to 
ogrInfo() or readOGR()? Few data sources declare their encodings in a 
portable way, and OGR is not able to double-guess either, so will 
typically assume the locale of the machine on which it is running. If this 
is wrong, it sometimes has no safe fallback. Organisations often wrongly 
assume that files will only ever be used on the same platform in the same 
locale used to create them. Sometimes you can try ogrInfo() with different 
encoding settings until you find one that works. R has robust support for 
encoding, but does need clear knowledge of the encoding of the input.

Roger

>
> Thanks!
>
> Agus
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Mon May 17 13:19:18 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 17 May 2010 13:19:18 +0200 (CEST)
Subject: [R-sig-Geo] writeOGR to GPX file: empty table
In-Reply-To: <1274090923881-5064393.post@n2.nabble.com>
References: <1274090923881-5064393.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.00.1005171311220.15971@reclus.nhh.no>

On Mon, 17 May 2010, Agustin Lobo wrote:

>
> Hi!,
>
> I'm converting from shape to gpx through rgdal (I get an empty file with
> gpsbabel and, according to its web, I'm not convinced that the shape format
> is actually fully supported by gpsbabel).
>
> This is what I do:
>> AilantMSY09 <-
>> readOGR(dsn="/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09/",layer="AilantMSY09")
> OGR data source with driver: ESRI Shapefile
>
>> writeOGR(AilantMSY09,
>> dsn="/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09GPX",layer="AilantMSY09GPX",driver="GPX")
> Error in writeOGR(AilantMSY09, dsn =
> "/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09GPX",
> :
>
> 	GDAL Error 6: Field of name 'Comentario' is not supported in GPX schema.
> Use GPX_USE_EXTENSIONS creation option to allow use of the <extensions>
> element.
>
> After reading the gdal-ogr doc, I include dataset_options:
>
>> writeOGR(AilantMSY09,
>> dsn="/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09GPX",layer="AilantMSY09GPX",driver="GPX",dataset_options="GPX_USE_EXTENSIONS=YES")
> Error in writeOGR(AilantMSY09, dsn =
> "/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09GPX",
> :
>
> 	GDAL Error 1: Latitude 4627933.603181 is invalid. Valid range is [-90,90].
> This warning will not be issued any more
>
> Which indicates that the user must unproject first (it seems that GPX files
> only support lon,lat):
>
>> AilantMSY09WGS84LL <- spTransform(AilantMSY09, CRS("+proj=longlat
>> +ellps=WGS84"))
> Warning message:
> In spTransform(xSP, CRSobj) :
>  Only x- and y-coordinates are being transformed
>
>> writeOGR(AilantMSY09WGS84LL,
>> dsn="/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09GPX.gpx",layer="AilantMSY09GPX",driver="GPX",dataset_options="GPX_USE_EXTENSIONS=YES")
>
> Once in QGIS, the points are in the right sites but the attribute table is
> all NULLs

Please check the output GPX file in a text editor to see what is present 
there. Also please read the GPX file back into R with readOGR(), assuming 
that on your platform the OGR GPX driver has read support.

Roger

>
> This is not a concern (by now) for me as I just need the gpx file to upload
> the points to the gps unit,
> but report it just in case this is a bug and/or to know if I'm doing
> something wrong.
>
> Note: I do get the correct table for the gpx file using plugin OGR converter
> in QGIS.
>
> Thanks
>
> Agus
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From alobolistas at gmail.com  Mon May 17 13:40:45 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Mon, 17 May 2010 04:40:45 -0700 (PDT)
Subject: [R-sig-Geo] writeOGR to GPX file: empty table
In-Reply-To: <alpine.LRH.2.00.1005171311220.15971@reclus.nhh.no>
References: <1274090923881-5064393.post@n2.nabble.com>
	<alpine.LRH.2.00.1005171311220.15971@reclus.nhh.no>
Message-ID: <1274096445201-5064652.post@n2.nabble.com>


Roger,
There is actually information in the file, i.e. the first point is:

<?xml version="1.0"?>
<gpx version="1.1" creator="GDAL 1.6.3"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xmlns:ogr="http://osgeo.org/gdal" xmlns="http://www.topografix.com/GPX/1/1"
xsi:schemaLocation="http://www.topografix.com/GPX/1/1
http://www.topografix.com/GPX/1/1/gpx.xsd">
<wpt lat="41.800745980899059" lon="2.359550956673553">
  <extensions>
    <ogr:Comentario>4</ogr:Comentario>
    <ogr:Rcvr_Type>Juno ST</ogr:Rcvr_Type>
    <ogr:GPS_Date>2009/10/27</ogr:GPS_Date>
    <ogr:GPS_Time>03:09:11pm</ogr:GPS_Time>
    <ogr:Datafile>AILANTO27102009.SSF</ogr:Datafile>
    <ogr:GPS_Height>1089.392</ogr:GPS_Height>
    <ogr:Northing>4627933.603</ogr:Northing>
    <ogr:Easting>446791.833</ogr:Easting>
    <ogr:PDOP_max>0</ogr:PDOP_max>
    <ogr:HDOP_max>0</ogr:HDOP_max>
    <ogr:Fecha_GPS>0000/00/00</ogr:Fecha_GPS>
    <ogr:PosNofilt>0</ogr:PosNofilt>
    <ogr:Pos_filt>0</ogr:Pos_filt>
    <ogr:Semana_GPS>0</ogr:Semana_GPS>
    <ogr:Segundo_GP>0</ogr:Segundo_GP>
    <ogr:Altura_GPS>0</ogr:Altura_GPS>
    <ogr:Prec_vert>0</ogr:Prec_vert>
    <ogr:Prec_horz>0</ogr:Prec_horz>
    <ogr:Dev_Tp>0</ogr:Dev_Tp>
    <ogr:Norte>0</ogr:Norte>
    <ogr:Este>0</ogr:Este>
    <ogr:Abundancia>4</ogr:Abundancia>
  </extensions>
</wpt>

Cannot read it in R. Maybe I'm not using the appropriate settings for dsn
and layer (I've tried
many alternatives):

> writeOGR(AilantMSY09WGS84LL,
> dsn="/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09R.gpx",layer="AilantMSY09R",driver="GPX",dataset_options="GPX_USE_EXTENSIONS=YES")

> test <-
> readOGR(dsn="/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09R.gpx",layer="AilantMSY09R")Error
> in ogrInfo(dsn = dsn, layer = layer, input_field_name_encoding =
> input_field_name_encoding) : 
  Cannot open layer

Agus

-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/writeOGR-to-GPX-file-empty-table-tp5064393p5064652.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Mon May 17 13:57:37 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 17 May 2010 13:57:37 +0200 (CEST)
Subject: [R-sig-Geo] writeOGR to GPX file: empty table
In-Reply-To: <1274096445201-5064652.post@n2.nabble.com>
References: <1274090923881-5064393.post@n2.nabble.com>
	<alpine.LRH.2.00.1005171311220.15971@reclus.nhh.no>
	<1274096445201-5064652.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.00.1005171350520.15971@reclus.nhh.no>

On Mon, 17 May 2010, Agustin Lobo wrote:

>
> Roger,
> There is actually information in the file, i.e. the first point is:
>
> <?xml version="1.0"?>
> <gpx version="1.1" creator="GDAL 1.6.3"
> xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
> xmlns:ogr="http://osgeo.org/gdal" xmlns="http://www.topografix.com/GPX/1/1"
> xsi:schemaLocation="http://www.topografix.com/GPX/1/1
> http://www.topografix.com/GPX/1/1/gpx.xsd">
> <wpt lat="41.800745980899059" lon="2.359550956673553">
>  <extensions>
>    <ogr:Comentario>4</ogr:Comentario>
>    <ogr:Rcvr_Type>Juno ST</ogr:Rcvr_Type>
>    <ogr:GPS_Date>2009/10/27</ogr:GPS_Date>
>    <ogr:GPS_Time>03:09:11pm</ogr:GPS_Time>
>    <ogr:Datafile>AILANTO27102009.SSF</ogr:Datafile>
>    <ogr:GPS_Height>1089.392</ogr:GPS_Height>
>    <ogr:Northing>4627933.603</ogr:Northing>
>    <ogr:Easting>446791.833</ogr:Easting>
>    <ogr:PDOP_max>0</ogr:PDOP_max>
>    <ogr:HDOP_max>0</ogr:HDOP_max>
>    <ogr:Fecha_GPS>0000/00/00</ogr:Fecha_GPS>
>    <ogr:PosNofilt>0</ogr:PosNofilt>
>    <ogr:Pos_filt>0</ogr:Pos_filt>
>    <ogr:Semana_GPS>0</ogr:Semana_GPS>
>    <ogr:Segundo_GP>0</ogr:Segundo_GP>
>    <ogr:Altura_GPS>0</ogr:Altura_GPS>
>    <ogr:Prec_vert>0</ogr:Prec_vert>
>    <ogr:Prec_horz>0</ogr:Prec_horz>
>    <ogr:Dev_Tp>0</ogr:Dev_Tp>
>    <ogr:Norte>0</ogr:Norte>
>    <ogr:Este>0</ogr:Este>
>    <ogr:Abundancia>4</ogr:Abundancia>
>  </extensions>
> </wpt>
>
> Cannot read it in R. Maybe I'm not using the appropriate settings for dsn
> and layer (I've tried
> many alternatives):

The variants are as described in the readOGR help file, that is layer=
"waypoints", "tracks", "routes", "track_points", or "route_points". Maybe 
reading the help page might save time??

Roger

PS. I think that the OGR GPX driver expects a number of fields that are 
most often absent when reading (so generating NULL/NA), and may not handle 
other extra user-defined fields gracefully. If need be, create a short 
string in the NAME or name field to concatenate the data you need, that is 
work around apparent shortcomings in the driver.

>
>> writeOGR(AilantMSY09WGS84LL,
>> dsn="/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09R.gpx",layer="AilantMSY09R",driver="GPX",dataset_options="GPX_USE_EXTENSIONS=YES")
>
>> test <-
>> readOGR(dsn="/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09R.gpx",layer="AilantMSY09R")Error
>> in ogrInfo(dsn = dsn, layer = layer, input_field_name_encoding =
>> input_field_name_encoding) :
>  Cannot open layer
>
> Agus
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From alobolistas at gmail.com  Mon May 17 14:23:35 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Mon, 17 May 2010 05:23:35 -0700 (PDT)
Subject: [R-sig-Geo] writeOGR to GPX file: empty table
In-Reply-To: <alpine.LRH.2.00.1005171350520.15971@reclus.nhh.no>
References: <1274090923881-5064393.post@n2.nabble.com>
	<alpine.LRH.2.00.1005171311220.15971@reclus.nhh.no>
	<1274096445201-5064652.post@n2.nabble.com>
	<alpine.LRH.2.00.1005171350520.15971@reclus.nhh.no>
Message-ID: <1274099015470-5064784.post@n2.nabble.com>


Sorry about not having read the doc, I'm probably too used to import shape
files
with readOGR() and did not realize that GPX files would have different
options.

test <-
readOGR(dsn="/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09R.gpx",layer="waypoints")

works fine and the table is correct. I think that 
dataset_options="GPX_USE_EXTENSIONS=YES"
at writing did the job.

So no problem at all with writing/reading GPX files in R through rgdal
I would add a line to the help page reminding the user that coordinates must
be geographic in GPX
files (thus the user must eventually unproject before writeOGR() ).

Thanks!

Agus
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/writeOGR-to-GPX-file-empty-table-tp5064393p5064784.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Mon May 17 14:57:22 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 17 May 2010 14:57:22 +0200 (CEST)
Subject: [R-sig-Geo] writeOGR to GPX file: empty table
In-Reply-To: <1274099015470-5064784.post@n2.nabble.com>
References: <1274090923881-5064393.post@n2.nabble.com>
	<alpine.LRH.2.00.1005171311220.15971@reclus.nhh.no>
	<1274096445201-5064652.post@n2.nabble.com>
	<alpine.LRH.2.00.1005171350520.15971@reclus.nhh.no>
	<1274099015470-5064784.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.00.1005171457000.15971@reclus.nhh.no>

On Mon, 17 May 2010, Agustin Lobo wrote:

>
> Sorry about not having read the doc, I'm probably too used to import shape
> files
> with readOGR() and did not realize that GPX files would have different
> options.
>
> test <-
> readOGR(dsn="/media/TRANSCEND/MONTSENY2008/MONTSENY_GEODATA/FloraExotica2009/AilantMSY09R.gpx",layer="waypoints")
>
> works fine and the table is correct. I think that
> dataset_options="GPX_USE_EXTENSIONS=YES"
> at writing did the job.
>
> So no problem at all with writing/reading GPX files in R through rgdal
> I would add a line to the help page reminding the user that coordinates must
> be geographic in GPX
> files (thus the user must eventually unproject before writeOGR() ).

OK, will do.

Roger

>
> Thanks!
>
> Agus
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From gblanchet.list at gmail.com  Mon May 17 19:15:01 2010
From: gblanchet.list at gmail.com (Guillaume Blanchet)
Date: Mon, 17 May 2010 11:15:01 -0600
Subject: [R-sig-Geo] properly using function aggregate(raster)
Message-ID: <4BF17995.8030907@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100517/b220e4fe/attachment.pl>

From r.hijmans at gmail.com  Mon May 17 19:50:37 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Mon, 17 May 2010 10:50:37 -0700
Subject: [R-sig-Geo] properly using function aggregate(raster)
In-Reply-To: <4BF17995.8030907@gmail.com>
References: <4BF17995.8030907@gmail.com>
Message-ID: <AANLkTil5mWwz9n2mdW122f-dt50U2tjIfuIxnSO3st-I@mail.gmail.com>

Dear Guillaume,

This probably happened because the aggregate function tests if the
output raster can be stored in memory. This is a mistake as it should
do the test for the input raster (which is, in this case, 16 times
larger). I have just fixed that. For now, you can use this (otherwise
*not* recommended (or necessary), as it slows things down) option, to
force processing the file in chunks :

setOptions(todisk=TRUE)
wam<-aggregate(wam, fact=4, fun=mean, expand=FALSE,
filename="wam_ag4", progress='tcltk')
setOptions(todisk=FALSE)

Robert

On Mon, May 17, 2010 at 10:15 AM, Guillaume Blanchet
<gblanchet.list at gmail.com> wrote:
> Hi !
>
> I recently started to use the raster package to play with a file that I
> consider fairly big. Since file size is subjective, following is the
> summary output R gives of the data I am working with :
>
> ?> wam
> class ? ? ? : RasterLayer
> filename ? ?: w001001.adf
> nrow ? ? ? ?: 14143
> ncol ? ? ? ?: 11733
> ncell ? ? ? : 165939819
> min value ? : 0
> max value ? : 36.3769
> projection ?: +proj=utm +zone=11 +ellps=GRS80 +datum=NAD83 +units=m
> +no_defs +towgs84=0,0,0
> xmin ? ? ? ?: 410133
> xmax ? ? ? ?: 421866
> ymin ? ? ? ?: 6287971
> ymax ? ? ? ?: 6302114
> xres ? ? ? ?: 1
> yres ? ? ? ?: 1
>
> I would like to aggregate the information of that RasterLayer. I tried
> to use the function aggregate() without any real success. Following is
> the code line I use to perform that procedure and the error message I get:
>
> ?> wam<-aggregate(wam, fact=4, fun=mean, expand=FALSE, filename="wam_ag4")
>
> Erreur : impossible d'allouer un vecteur de taille 633.0 Mo (A loose
> translation would be : "Error: allocating a vector of 633.0 Mb in size
> is impossible")
> De plus : Messages d'avis :
> 1: In .local(x, ...) :
> ? Reached total allocation of 3061Mb: see help(memory.size)
> 2: In .local(x, ...) :
> ? Reached total allocation of 3061Mb: see help(memory.size)
> 3: In .local(x, ...) :
> ? Reached total allocation of 3061Mb: see help(memory.size)
> 4: In .local(x, ...) :
> ? Reached total allocation of 3061Mb: see help(memory.size)
>
> I understood while reading help files and various posting that the
> raster package can handle files larger than the RAM memory of the
> computer. The computer I am using has 3Gb of RAM and the file I want to
> read is only 633 Mb. I suppose there something I am not doing right.
>
> Any help would be much appreciated !
>
> Thank you in advance !
>
> Guillaume Blanchet
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From gblanchet.list at gmail.com  Mon May 17 21:22:57 2010
From: gblanchet.list at gmail.com (Guillaume Blanchet)
Date: Mon, 17 May 2010 13:22:57 -0600
Subject: [R-sig-Geo] properly using function aggregate(raster)
In-Reply-To: <AANLkTil5mWwz9n2mdW122f-dt50U2tjIfuIxnSO3st-I@mail.gmail.com>
References: <4BF17995.8030907@gmail.com>
	<AANLkTil5mWwz9n2mdW122f-dt50U2tjIfuIxnSO3st-I@mail.gmail.com>
Message-ID: <4BF19791.8090505@gmail.com>

Dear Robert !

Thank you very much for your quick answer !

I just ran the bits of code you gave me and it worked perfectly !

Have a good day !

Guillaume

Le 10-05-17 11:50, Robert J. Hijmans a ?crit :
> Dear Guillaume,
>
> This probably happened because the aggregate function tests if the
> output raster can be stored in memory. This is a mistake as it should
> do the test for the input raster (which is, in this case, 16 times
> larger). I have just fixed that. For now, you can use this (otherwise
> *not* recommended (or necessary), as it slows things down) option, to
> force processing the file in chunks :
>
> setOptions(todisk=TRUE)
> wam<-aggregate(wam, fact=4, fun=mean, expand=FALSE,
> filename="wam_ag4", progress='tcltk')
> setOptions(todisk=FALSE)
>
> Robert
>
> On Mon, May 17, 2010 at 10:15 AM, Guillaume Blanchet
> <gblanchet.list at gmail.com>  wrote:
>    
>> Hi !
>>
>> I recently started to use the raster package to play with a file that I
>> consider fairly big. Since file size is subjective, following is the
>> summary output R gives of the data I am working with :
>>
>>   >  wam
>> class       : RasterLayer
>> filename    : w001001.adf
>> nrow        : 14143
>> ncol        : 11733
>> ncell       : 165939819
>> min value   : 0
>> max value   : 36.3769
>> projection  : +proj=utm +zone=11 +ellps=GRS80 +datum=NAD83 +units=m
>> +no_defs +towgs84=0,0,0
>> xmin        : 410133
>> xmax        : 421866
>> ymin        : 6287971
>> ymax        : 6302114
>> xres        : 1
>> yres        : 1
>>
>> I would like to aggregate the information of that RasterLayer. I tried
>> to use the function aggregate() without any real success. Following is
>> the code line I use to perform that procedure and the error message I get:
>>
>>   >  wam<-aggregate(wam, fact=4, fun=mean, expand=FALSE, filename="wam_ag4")
>>
>> Erreur : impossible d'allouer un vecteur de taille 633.0 Mo (A loose
>> translation would be : "Error: allocating a vector of 633.0 Mb in size
>> is impossible")
>> De plus : Messages d'avis :
>> 1: In .local(x, ...) :
>>    Reached total allocation of 3061Mb: see help(memory.size)
>> 2: In .local(x, ...) :
>>    Reached total allocation of 3061Mb: see help(memory.size)
>> 3: In .local(x, ...) :
>>    Reached total allocation of 3061Mb: see help(memory.size)
>> 4: In .local(x, ...) :
>>    Reached total allocation of 3061Mb: see help(memory.size)
>>
>> I understood while reading help files and various posting that the
>> raster package can handle files larger than the RAM memory of the
>> computer. The computer I am using has 3Gb of RAM and the file I want to
>> read is only 633 Mb. I suppose there something I am not doing right.
>>
>> Any help would be much appreciated !
>>
>> Thank you in advance !
>>
>> Guillaume Blanchet
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>      
>


From Gerard.Heuvelink at wur.nl  Tue May 18 14:08:56 2010
From: Gerard.Heuvelink at wur.nl (Heuvelink, Gerard)
Date: Tue, 18 May 2010 14:08:56 +0200
Subject: [R-sig-Geo] projection
Message-ID: <5DA773FDB5D4484D9A8E36F6C3DC018001834A91@scomp0039.wurnet.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100518/1a140d86/attachment.pl>

From alobolistas at gmail.com  Tue May 18 16:23:40 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 18 May 2010 16:23:40 +0200
Subject: [R-sig-Geo] rbind of SpPolDFs
Message-ID: <AANLkTin-j86M9qlOtQpWGtO9ptAw1-uTwbpRqxeo6stY@mail.gmail.com>

Hi!

I have a set of shapefiles, each one with one single polygon, and I
want to end up with one single SpPolDF including all polygons.
I read the set of shapefiles with readOGR() and thus get one SpPolDF
for each polygon.
I (unsuccessfully)  try:
> delme <- rbind.SpatialPolygonsDataFrame(BesosBoundary,TerBoundary)
Error in validObject(.Object) :
  invalid class "SpatialPolygons" object: non-unique Polygons ID slot values
Calls: rbind.SpatialPolygons ... SpatialPolygons -> new -> initialize
-> initialize -> validObject

> delme <- rbind.SpatialPolygonsDataFrame(BesosBoundary[1],TerBoundary[1])
Error in validObject(.Object) :
  invalid class "SpatialPolygons" object: non-unique Polygons ID slot values
Calls: rbind.SpatialPolygonsDataFrame ... SpatialPolygons -> new ->
initialize -> initialize -> validObject

> delme <- rbind.SpatialPolygonsDataFrame(BesosBoundary at polygons,TerBoundary at polygons)
Error in as(x, "SpatialPolygons") :
  no method or default for coercing "list" to "SpatialPolygons"
Calls: rbind.SpatialPolygonsDataFrame -> do.call -> lapply -> FUN -> as

and some other variants.

Any help on how to do this? A solution would be using joinPolys from
maptools (the polygons do not overlap), but think that
rbind.SpatialPolygonsDataFrame() is better suited for this operation.

Agus


From Roger.Bivand at nhh.no  Tue May 18 16:38:24 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 18 May 2010 16:38:24 +0200 (CEST)
Subject: [R-sig-Geo] rbind of SpPolDFs
In-Reply-To: <AANLkTin-j86M9qlOtQpWGtO9ptAw1-uTwbpRqxeo6stY@mail.gmail.com>
References: <AANLkTin-j86M9qlOtQpWGtO9ptAw1-uTwbpRqxeo6stY@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1005181633360.20109@reclus.nhh.no>

On Tue, 18 May 2010, Agustin Lobo wrote:

> Hi!
>
> I have a set of shapefiles, each one with one single polygon, and I
> want to end up with one single SpPolDF including all polygons.
> I read the set of shapefiles with readOGR() and thus get one SpPolDF
> for each polygon.
> I (unsuccessfully)  try:
>> delme <- rbind.SpatialPolygonsDataFrame(BesosBoundary,TerBoundary)
> Error in validObject(.Object) :
>  invalid class "SpatialPolygons" object: non-unique Polygons ID slot values

What about using spChFIDs() to assign unique FIDs? For example:

BesosBoundary <- spChFIDs(BesosBoundary, paste("Besos",
   row.names(BesosBoundary), sep="_"))

and so on. As it is, all will have "0", "1", ..., which are then not 
unique when rbind'ed. The user needs to control the FIDs, so needs to 
assign unique values before rbind.

Roger


> Calls: rbind.SpatialPolygons ... SpatialPolygons -> new -> initialize
> -> initialize -> validObject
>
>> delme <- rbind.SpatialPolygonsDataFrame(BesosBoundary[1],TerBoundary[1])
> Error in validObject(.Object) :
>  invalid class "SpatialPolygons" object: non-unique Polygons ID slot values
> Calls: rbind.SpatialPolygonsDataFrame ... SpatialPolygons -> new ->
> initialize -> initialize -> validObject
>
>> delme <- rbind.SpatialPolygonsDataFrame(BesosBoundary at polygons,TerBoundary at polygons)
> Error in as(x, "SpatialPolygons") :
>  no method or default for coercing "list" to "SpatialPolygons"
> Calls: rbind.SpatialPolygonsDataFrame -> do.call -> lapply -> FUN -> as
>
> and some other variants.
>
> Any help on how to do this? A solution would be using joinPolys from
> maptools (the polygons do not overlap), but think that
> rbind.SpatialPolygonsDataFrame() is better suited for this operation.
>
> Agus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Tue May 18 16:57:24 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 18 May 2010 16:57:24 +0200 (CEST)
Subject: [R-sig-Geo] projection
In-Reply-To: <5DA773FDB5D4484D9A8E36F6C3DC018001834A91@scomp0039.wurnet.nl>
References: <5DA773FDB5D4484D9A8E36F6C3DC018001834A91@scomp0039.wurnet.nl>
Message-ID: <alpine.LRH.2.00.1005181640340.20109@reclus.nhh.no>

On Tue, 18 May 2010, Heuvelink, Gerard wrote:

> Dear list,
>
> I hope someone can help me with the following.
>
> I have an SRTM DEM of Turkey in the "ED 1950 Lambert Conformal Conic"
> projection system.

See: http://www.asprs.org/resources/GRIDS/, September 2006. The third page 
gives the ED50 to ETRS89 seven-parameter values for the +towgs84= 
component. What you do not have to set up a +proj=lcc ... is the +lat_0=, 
+lon_0=, and so on. Without those, you have no chance of success. Obtain 
then from your data source. They must be assumed to have known what they 
were doing, as the input SRTM were not projected.

Roger

>
> However, I do not know how this is referred to in R. For example, I
> might load the dem as:
>
> DEM = readGDAL("srtm_5km_ascii.txt")
>
> Next I will want to let know what projection it is by issuing:
>
> proj4string(DEM) = XXXXXXXXXXX
>
> What do I write for XXXXXXXX?
>
> Thanks, Gerard
>
>
> Gerard B.M. Heuvelink
> Environmental Sciences Group
> Wageningen University and Research Centre
> P.O. Box 47
> 6700 AA Wageningen
> The Netherlands
>
> tel +31 317 486538 Mon Tue
> tel +31 317 482716 Wed Thu Fri
>
> email gerard.heuvelink at wur.nl <mailto:gerard.heuvelink at wur.nl>
> http://www.lad.wur.nl/UK/ <http://www.lad.wur.nl/UK/>
> http://www.alterra.wur.nl/NL/onderzoek/Werkveld+Bodem/TBGE/Gerard+Heuvel
> ink/
> <http://www.alterra.wur.nl/NL/onderzoek/Werkveld+Bodem/TBGE/Gerard+Heuve
> link/>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From b.rowlingson at lancaster.ac.uk  Tue May 18 17:04:06 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 18 May 2010 16:04:06 +0100
Subject: [R-sig-Geo] Better print method for Spatial*DataFrames?
Message-ID: <AANLkTikrtxVdCpwymXAws7B_aa82CcsUVh4ENNyLj3Mx@mail.gmail.com>

Currently if I print a spatial polygon data frame I get the list
representation, which almost always scrolls way of the screen as giant
lists of lists of coordinates whizz past. It's nearly always useless
and luckily ESS lets me C-c C-o and zap the output. For
SpatialPointsDF you get:

        coordinates letters LETTERS
1    (1, 0.0486677)       a       A
2     (2, 0.520911)       b       B
3     (3, 0.207873)       c       C
4     (4, 0.466571)       d       D

- for spatial polys and lines would it be better to have such a
compact representation as the default print? I'd rather use the word
'geometry' and have it print as a (truncated) pseudo-WKT, something
like:

     geometry letters LETTERS
1   POINT(1  0.0486677)       a       A
2   POINT(2  0.520911)       b       B

 for points, and:

     geometry letters LETTERS
1   LINESTRING(...)       a       A

 for lines, and:

     geometry letters LETTERS
1  POLYGON(...)       a       A

 for polygons. Or MULTIPOLYGON, whichever is appropriate. I think it
should literally print dot-dot-dot, since for anything other than
points its going to be voluminous.

Today I am a random idea factory...

Barry


From lists at remoteinformation.com.au  Tue May 18 17:15:49 2010
From: lists at remoteinformation.com.au (Ben Madin)
Date: Tue, 18 May 2010 23:15:49 +0800
Subject: [R-sig-Geo] projection
In-Reply-To: <5DA773FDB5D4484D9A8E36F6C3DC018001834A91@scomp0039.wurnet.nl>
References: <5DA773FDB5D4484D9A8E36F6C3DC018001834A91@scomp0039.wurnet.nl>
Message-ID: <266B6374-5A7E-41FF-86A4-ED8406C58F74@remoteinformation.com.au>

Gerard,

Until someone else replies, XXXXXXXX might be something like :

+proj=lcc +lat_1=37.8 +lat_0=37.8 +lon_0=34.9134 +k_0=0.99987742 +x_0=0 +y_0=0 +ellps=intl +units=m +no_defs

but it might also not be... I'm particularly wary of the x_0 and y_0 values. 

You could also try the proj list?

cheers

Ben



On 18/05/2010, at 20:08 , Heuvelink, Gerard wrote:

> Dear list,
> 
> I hope someone can help me with the following.
> 
> I have an SRTM DEM of Turkey in the "ED 1950 Lambert Conformal Conic"
> projection system.
> 
> However, I do not know how this is referred to in R. For example, I
> might load the dem as:
> 
> DEM = readGDAL("srtm_5km_ascii.txt")
> 
> Next I will want to let know what projection it is by issuing:
> 
> proj4string(DEM) = XXXXXXXXXXX
> 
> What do I write for XXXXXXXX?
> 
> Thanks, Gerard
> 
> 
> Gerard B.M. Heuvelink
> Environmental Sciences Group
> Wageningen University and Research Centre
> P.O. Box 47
> 6700 AA Wageningen
> The Netherlands
> 
> tel +31 317 486538 Mon Tue
> tel +31 317 482716 Wed Thu Fri
> 
> email gerard.heuvelink at wur.nl <mailto:gerard.heuvelink at wur.nl> 
> http://www.lad.wur.nl/UK/ <http://www.lad.wur.nl/UK/> 
> http://www.alterra.wur.nl/NL/onderzoek/Werkveld+Bodem/TBGE/Gerard+Heuvel
> ink/
> <http://www.alterra.wur.nl/NL/onderzoek/Werkveld+Bodem/TBGE/Gerard+Heuve
> link/> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From alobolistas at gmail.com  Tue May 18 18:45:26 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 18 May 2010 09:45:26 -0700 (PDT)
Subject: [R-sig-Geo] rbind of SpPolDFs
In-Reply-To: <alpine.LRH.2.00.1005181633360.20109@reclus.nhh.no>
References: <AANLkTin-j86M9qlOtQpWGtO9ptAw1-uTwbpRqxeo6stY@mail.gmail.com>
	<alpine.LRH.2.00.1005181633360.20109@reclus.nhh.no>
Message-ID: <1274201126195-5070943.post@n2.nabble.com>


Thanks. I have to do it this way as the tables are inconsistent:

BesosBoundary at data <- data.frame(Basin="Besos")
TerBoundary at data <- data.frame(Basin="Ter")
BesosBoundary <- spChFIDs(BesosBoundary, "Besos")
TerBoundary <- spChFIDs(TerBoundary, "Ter")
delme <- rbind.SpatialPolygonsDataFrame(BesosBoundary,TerBoundary)

Nevertheless, as I have several of these shape files, I'm trying a loop.
But while the following works:
> i <- 1
> basnom <- unlist(strsplit(bas[i], "Boundary"))
> basnom
[1] "Besos"

> slot(BesosBoundary,"data") <- data.frame(Basin = basnom)

the following (which I need for using the names in an array) does not:
> bas[i]
[1] "BesosBoundary"

> slot(get(bas[i]),"data") <- data.frame(Basin = basnom)
Error in slot(get(bas[i]), "data") <- data.frame(Basin = basnom) :
  could not find function "get<-"

am I doing something wrong or have I hitted an inconsistency?

Agus 
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/rbind-of-SpPolDFs-tp5070215p5070943.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Tue May 18 18:54:02 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 18 May 2010 18:54:02 +0200 (CEST)
Subject: [R-sig-Geo] rbind of SpPolDFs
In-Reply-To: <1274201126195-5070943.post@n2.nabble.com>
References: <AANLkTin-j86M9qlOtQpWGtO9ptAw1-uTwbpRqxeo6stY@mail.gmail.com>
	<alpine.LRH.2.00.1005181633360.20109@reclus.nhh.no>
	<1274201126195-5070943.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.00.1005181852280.20109@reclus.nhh.no>

On Tue, 18 May 2010, Agustin Lobo wrote:

>
> Thanks. I have to do it this way as the tables are inconsistent:
>
> BesosBoundary at data <- data.frame(Basin="Besos")
> TerBoundary at data <- data.frame(Basin="Ter")
> BesosBoundary <- spChFIDs(BesosBoundary, "Besos")
> TerBoundary <- spChFIDs(TerBoundary, "Ter")
> delme <- rbind.SpatialPolygonsDataFrame(BesosBoundary,TerBoundary)
>
> Nevertheless, as I have several of these shape files, I'm trying a loop.
> But while the following works:
>> i <- 1
>> basnom <- unlist(strsplit(bas[i], "Boundary"))
>> basnom
> [1] "Besos"
>
>> slot(BesosBoundary,"data") <- data.frame(Basin = basnom)
>
> the following (which I need for using the names in an array) does not:
>> bas[i]
> [1] "BesosBoundary"
>
>> slot(get(bas[i]),"data") <- data.frame(Basin = basnom)
> Error in slot(get(bas[i]), "data") <- data.frame(Basin = basnom) :
>  could not find function "get<-"
>
> am I doing something wrong or have I hitted an inconsistency?

The error message seems explicit. Use get() first to a temporary local 
object, do slot()<- on that object, and assign() back to bas[i]. Untried.

Roger

>
> Agus
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From carson.farmer at gmail.com  Tue May 18 19:44:38 2010
From: carson.farmer at gmail.com (Carson Farmer)
Date: Tue, 18 May 2010 18:44:38 +0100
Subject: [R-sig-Geo] Querying Spatial Data Using rgdal
In-Reply-To: <alpine.LRH.2.00.1005111317120.11770@reclus.nhh.no>
References: <s2z90a726dc1005071435ifb97b2cdm5e8d580fd4b9f3f1@mail.gmail.com>
	<w2o49b12cd41005081530s2d6c45f8oc6a61dec3ffa2426@mail.gmail.com>
	<alpine.LRH.2.00.1005111317120.11770@reclus.nhh.no>
Message-ID: <AANLkTikpwXLt9sFaKvQaKqOX7xVulkDvrs1_a8wswMxv@mail.gmail.com>

Just to bring this up again...

> That only gets you so far. Could Tim please try ogr2ogr with the -sql or
> -where or -spat arguments set to see whether these go in the correct
> direction, that is returning geometries meeting the given selection
> conditions? I have looked briefly at how hard it would be to add this
> functionality to readOGR(), but without a substantial re-write, it will not
> be easy. If there are other users who would value such an addition to
> readOGR, please indicate!
+1 from me Roger, though I notice no one else has said anything about
this lately!

Carson

-- 
Carson J. Q. Farmer
ISSP Doctoral Fellow
National Centre for Geocomputation
National University of Ireland, Maynooth,
http://www.carsonfarmer.com/


From dmsilv at gmail.com  Wed May 19 00:39:20 2010
From: dmsilv at gmail.com (Daniel)
Date: Tue, 18 May 2010 19:39:20 -0300
Subject: [R-sig-Geo] Shape in Latin-1
Message-ID: <AANLkTinq3gZlYFfMVpvwW8AHPqi8ZYyzZfcAvymTu5Vo@mail.gmail.com>

Hello all,
I have had a incovenient trouble to read a shapefile that I suspect
was encoded as "latin-1". Since I'm mac user and mac uses UTF-8, some
kind of problem could be happen.
I tryed some comand lines without success:

> brasil <- readShapeSpatial(file.choose(),
proj4string=CRS("+proj=longlat"))
Error in getinfo.shape(fn) : Error opening SHP file

> brasil <- readShapePoly("/Users/daniel/bases/maps/Brasil/55mu2500gsr.shp", encoding="latin1")
Error in readShapePoly("/Users/daniel/bases/maps/Brasil/55mu2500gsr.shp", ?:
??unused argument(s) (encoding = "latin1")

Somebody know how can I open it?
Daniel


From Roger.Bivand at nhh.no  Wed May 19 09:12:02 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 19 May 2010 09:12:02 +0200 (CEST)
Subject: [R-sig-Geo] Shape in Latin-1
In-Reply-To: <AANLkTinq3gZlYFfMVpvwW8AHPqi8ZYyzZfcAvymTu5Vo@mail.gmail.com>
References: <AANLkTinq3gZlYFfMVpvwW8AHPqi8ZYyzZfcAvymTu5Vo@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1005190857260.22739@reclus.nhh.no>

On Tue, 18 May 2010, Daniel wrote:

> Hello all,
> I have had a incovenient trouble to read a shapefile that I suspect
> was encoded as "latin-1". Since I'm mac user and mac uses UTF-8, some
> kind of problem could be happen.
> I tryed some comand lines without success:
>
>> brasil <- readShapeSpatial(file.choose(),
> proj4string=CRS("+proj=longlat"))
> Error in getinfo.shape(fn) : Error opening SHP file
>
>> brasil <- readShapePoly("/Users/daniel/bases/maps/Brasil/55mu2500gsr.shp", encoding="latin1")
> Error in readShapePoly("/Users/daniel/bases/maps/Brasil/55mu2500gsr.shp", ?:
> ??unused argument(s) (encoding = "latin1")
>
> Somebody know how can I open it?

Please do read the error messages, and do not jump to conclusions. Always 
examine the output of traceback() after an error. In the first case, you 
do not show the file name, nor have you tried list.files() to show that 
the file is where you think it is (it doesn't seem to be there). In the 
second case, as the error message says, there is no encoding= argument to 
readShape*() - does it say there is on the help page?

Are you refering to the field names in the DBF, or to the contents of the 
fields? Can you read the DBF file itself with read.dbf() in the foreign 
package (used in maptools)? So far, you have not established that your 
beliefs about the encoding are the problem here.

If the issue is in the field names, have you tried readOGR() in rgdal, 
which does have an argument for setting the encoding of field names? If 
you feel that rgdal is not available for OSX, I can with pleasure thank 
Brian Ripley for making both 32-bit and 64-bit Intel versions available on 
CRAN extras - use:

> setRepositories(ind=1:2)
> install.packages('rgdal')

Roger


> Daniel
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From moshersteven at gmail.com  Wed May 19 09:18:07 2010
From: moshersteven at gmail.com (steven mosher)
Date: Wed, 19 May 2010 00:18:07 -0700
Subject: [R-sig-Geo] rgdal on MAC
Message-ID: <AANLkTilzHZFadWvRCz2T0ZziGrtF0duUE5SEe6WQ2v07@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100519/638e1474/attachment.pl>

From Roger.Bivand at nhh.no  Wed May 19 10:16:45 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 19 May 2010 10:16:45 +0200 (CEST)
Subject: [R-sig-Geo] rgdal on MAC
In-Reply-To: <AANLkTilzHZFadWvRCz2T0ZziGrtF0duUE5SEe6WQ2v07@mail.gmail.com>
References: <AANLkTilzHZFadWvRCz2T0ZziGrtF0duUE5SEe6WQ2v07@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1005191010410.22739@reclus.nhh.no>

On Wed, 19 May 2010, steven mosher wrote:

> On Cran it indicates that the package is not available on MAC (OSX 10.5.8)
> Is that the whole story?
> Is it a situation that will change or am I missing something. I've left a
> similar Q on the Mac Sig, but havent  got any feedback

It is always possible to use the instructions on the CRAN page under 
SystemRequirements: - that is install the external dependencies, for 
example using Kyngchaos' frameworks, and install from source, or from an 
OSX binary rgdal package at the same site. This probably gives a larger 
set of drivers.

For those who prefer a Leopard-style binary with the same minimal set of 
drivers that we have on CRAN for Win32 and Win64: I can with pleasure 
thank Brian Ripley for making both 32-bit and 64-bit Intel versions 
available on CRAN extras - on OSX use:

> setRepositories(ind=1:2)
> install.packages('rgdal')

Please report back on whether this advice was helpful.

Roger


>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From moshersteven at gmail.com  Wed May 19 18:02:47 2010
From: moshersteven at gmail.com (steven mosher)
Date: Wed, 19 May 2010 09:02:47 -0700
Subject: [R-sig-Geo] rgdal on MAC
In-Reply-To: <alpine.LRH.2.00.1005191010410.22739@reclus.nhh.no>
References: <AANLkTilzHZFadWvRCz2T0ZziGrtF0duUE5SEe6WQ2v07@mail.gmail.com> 
	<alpine.LRH.2.00.1005191010410.22739@reclus.nhh.no>
Message-ID: <AANLkTimcXxLkbt2cg8gYE0MJ3Jdj1NsPzB5LKy9zmuhF@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100519/5c453663/attachment.pl>

From moshersteven at gmail.com  Wed May 19 18:39:01 2010
From: moshersteven at gmail.com (steven mosher)
Date: Wed, 19 May 2010 09:39:01 -0700
Subject: [R-sig-Geo] rgdal on MAC
In-Reply-To: <alpine.LRH.2.00.1005191010410.22739@reclus.nhh.no>
References: <AANLkTilzHZFadWvRCz2T0ZziGrtF0duUE5SEe6WQ2v07@mail.gmail.com> 
	<alpine.LRH.2.00.1005191010410.22739@reclus.nhh.no>
Message-ID: <AANLkTimDIgaDdt65n9eJH48eRLCbWHlmWqfVpOx_24OU@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100519/900883c4/attachment.pl>

From alobolistas at gmail.com  Thu May 20 13:40:55 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Thu, 20 May 2010 13:40:55 +0200
Subject: [R-sig-Geo] overlay spatialgrid on spatial polygons data frame
Message-ID: <AANLkTinIagay1mKmVZX2XQQ_0s0_DhsZIonFP9sJ6ZKL@mail.gmail.com>

I have an SpPolDF and a coarse SpatialGrid, i.e.,
srdf=SpatialPolygonsDataFrame(sr, data.frame(cbind(1:3,5:3),
row.names=c("r1","r2","r3")))
#the one used in help(overlay);
> srdf at data
   X1 X2
r1  1  5
r2  2  4
r3  3  3

> bbox(srdf)
     min    max
x 178544 181477
y 329665 333676

> test <- SpatialGrid(GridTopology(cellcentre.offset=c(178440,329600), cellsize=c(500,500), cells.dim=c(8,10)))
> plot(srdf)
> plot(test,add=T)

My goal is to "overlay" test over srdf and tranfer the data in
srdf at data to a data frame associated
to test (=> test must become a SpatialGridDF) so that each cell has
the average value of the overlaid srdf at data polygon(s) weighted
by area: in case 25% of a given cell in test would overlay polygon r1
and 75% polygon r2, the value of X1 for that cell would be
0.25*1 + 0.75*2

According to help(overlay),
"Value
 a numerical array of indices of x on locations of y, or a data.frame
with (possibly aggregate) properties of x in units of y"

I've tried this:
> overlay(srdf, test, fn=mean, na.rm)

     X1 X2
NA   NA NA
NA.1 NA NA

Cannot go beyond, perhaps overlay() is not suited for this: the
definition of overlay in its help page
"overlay combines points (or grids) and polygons by performing
point-in-polygon operation on all point-polygons combinations"
is a bit confusing, the first part of the sentence gives me some hope
but the second one seems to exclude what I'm trying to do.

Any help appreciated (or perhaps pointing to more doc?)


Agus


From alobolistas at gmail.com  Thu May 20 14:37:11 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Thu, 20 May 2010 14:37:11 +0200
Subject: [R-sig-Geo] check all IDs of a spatialPolygons object
Message-ID: <AANLkTin5wYf0c99wZiZfnbFnO6PH1x-hjIBdwRF0Cnw0@mail.gmail.com>

Is there a cleaner way to check all IDs of a spatialPolygons object?
I know how to do it with one:
 > slot(spol at polygons[[2]],"ID")
[1] "g2"

and for all of them I use
> sapply(spol at polygons,slot,"ID")

is there something more straightforward, sort of spFIDs() (by analogy
to spChFIDs() )?

Thanks

Agus


From Roger.Bivand at nhh.no  Thu May 20 14:50:20 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 20 May 2010 14:50:20 +0200 (CEST)
Subject: [R-sig-Geo] check all IDs of a spatialPolygons object
In-Reply-To: <AANLkTin5wYf0c99wZiZfnbFnO6PH1x-hjIBdwRF0Cnw0@mail.gmail.com>
References: <AANLkTin5wYf0c99wZiZfnbFnO6PH1x-hjIBdwRF0Cnw0@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1005201450010.28208@reclus.nhh.no>

On Thu, 20 May 2010, Agustin Lobo wrote:

> Is there a cleaner way to check all IDs of a spatialPolygons object?
> I know how to do it with one:
> > slot(spol at polygons[[2]],"ID")
> [1] "g2"
>
> and for all of them I use
>> sapply(spol at polygons,slot,"ID")
>
> is there something more straightforward, sort of spFIDs() (by analogy
> to spChFIDs() )?

row.names(spol), OK?

Roger

>
> Thanks
>
> Agus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From alobolistas at gmail.com  Thu May 20 15:05:29 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Thu, 20 May 2010 15:05:29 +0200
Subject: [R-sig-Geo] check all IDs of a spatialPolygons object
In-Reply-To: <alpine.LRH.2.00.1005201450010.28208@reclus.nhh.no>
References: <AANLkTin5wYf0c99wZiZfnbFnO6PH1x-hjIBdwRF0Cnw0@mail.gmail.com>
	<alpine.LRH.2.00.1005201450010.28208@reclus.nhh.no>
Message-ID: <AANLkTilWe01qWI_sG--YNsp2MXo_rZfDdjhjcF1iYEjx@mail.gmail.com>

Yes!
I would have thought on that if spol where a spatialpolygonsDataFrame,
(as many sp functions for SpPolDF actually mimic functions for
dataframes, which is
great help for the memory), but in this case, spol is just a
spatialpolygons and the user
probably will not think at that.

Thanks!
Agus

2010/5/20 Roger Bivand <Roger.Bivand at nhh.no>:
> On Thu, 20 May 2010, Agustin Lobo wrote:
>
>> Is there a cleaner way to check all IDs of a spatialPolygons object?
>> I know how to do it with one:
>> > slot(spol at polygons[[2]],"ID")
>> [1] "g2"
>>
>> and for all of them I use
>>>
>>> sapply(spol at polygons,slot,"ID")
>>
>> is there something more straightforward, sort of spFIDs() (by analogy
>> to spChFIDs() )?
>
> row.names(spol), OK?
>
> Roger
>
>>
>> Thanks
>>
>> Agus
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>


From dmsilv at gmail.com  Thu May 20 15:07:22 2010
From: dmsilv at gmail.com (Daniel)
Date: Thu, 20 May 2010 10:07:22 -0300
Subject: [R-sig-Geo] rgdal on MAC
In-Reply-To: <alpine.LRH.2.00.1005191010410.22739@reclus.nhh.no>
References: <AANLkTilzHZFadWvRCz2T0ZziGrtF0duUE5SEe6WQ2v07@mail.gmail.com>
	<alpine.LRH.2.00.1005191010410.22739@reclus.nhh.no>
Message-ID: <AANLkTikJ_eSWCVaTTJ5iUyS_yNb1r1_jmbbq0SvHPD6Z@mail.gmail.com>

Yeah, Roger. That was amazing, works like a charm.
I almost believe that I couldn't open my counties shape on R. Thanks
for prompt help.

brasil <- readOGR("/Users/daniel/bases/maps/Brasil/55mu2500gsr.shp",
"55mu2500gsr", input_field_name_encoding="iso-8859-1")
OGR data source with driver: ESRI Shapefile
Source: "/Users/daniel/bases/maps/Brasil/55mu2500gsr.shp", layer: "55mu2500gsr"
with 5566 features and 9 fields
Feature type: wkbPolygon with 2 dimensions

> for(i in 1:length(names(brasil))) {
+   if (class(brasil[[i]]) == "factor") {
+     brasil[[i]] <- factor(iconv(brasil[[i]], from="latin1", to="utf-8"))
+   }
+ }
> plot(brasil)

Daniel

On Wed, May 19, 2010 at 5:16 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Wed, 19 May 2010, steven mosher wrote:
>
>> On Cran it indicates that the package is not available on MAC (OSX 10.5.8)
>> Is that the whole story?
>> Is it a situation that will change or am I missing something. I've left a
>> similar Q on the Mac Sig, but havent ?got any feedback
>
> It is always possible to use the instructions on the CRAN page under
> SystemRequirements: - that is install the external dependencies, for example
> using Kyngchaos' frameworks, and install from source, or from an OSX binary
> rgdal package at the same site. This probably gives a larger set of drivers.
>
> For those who prefer a Leopard-style binary with the same minimal set of
> drivers that we have on CRAN for Win32 and Win64: I can with pleasure thank
> Brian Ripley for making both 32-bit and 64-bit Intel versions available on
> CRAN extras - on OSX use:
>
>> setRepositories(ind=1:2)
>> install.packages('rgdal')
>
> Please report back on whether this advice was helpful.
>
> Roger
>
>
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From ashenkin at ufl.edu  Thu May 20 17:29:26 2010
From: ashenkin at ufl.edu (Alexander Shenkin)
Date: Thu, 20 May 2010 10:29:26 -0500
Subject: [R-sig-Geo] finding euclidean proximate points in two datasets
Message-ID: <4BF55556.5020207@ufl.edu>

Hello All,

I posted this over on R-help, but was then directed here.

I've been pouring through the various spatial packages, but haven't come
across the right thing yet.

Given a set of points in 2-d space X, i'm trying to find the subset of
points in Y proximate to each point in X.  Furthermore, the proximity
threshold of each point in X differs (X$threshold).  I've constructed
this myself already, but it's horrificly slow with a dataset of 40k+
points in one set, and a 700 in the other.

A very inefficient example of what I'm looking for:

    X = data.frame(x=c(1,2,3), y=c(2,3,1), threshold=c(1,2,4))
    Y = data.frame(x=c(5,2,3,4,2,5,2,3), y=c(5,2,2,4,1,2,3,1))
    proximate=list()
    i=1
    for (pt in 1:length(X$x)) {
        proximate[[i]] <- sqrt((X[pt,]$x - Y$x)2 + (X[pt,]$y - Y$y)2)
                          > X[pt,]$threshold
        i=i+1
    }
    proximate

Perhaps crossdist() in spatstat is what I should use, and then code a
comparison with X$threshold after the cross-distances are computed.
However, I was wondering if there was another tool I should be
considering.  David Winsemius suggested I first compare on in each
coordinate to cull points outside the threshold on that axis first,
before computing distances, which will help.  Any and all thoughts are
very welcome.  Thanks in advance.

Thanks,
Allie
-- 
Alexander Shenkin
PhD Candidate
School of Natural Resources and Environment
University of Florida

http://snre.ufl.edu/people/students.asp


From Roger.Bivand at nhh.no  Thu May 20 20:02:30 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 20 May 2010 20:02:30 +0200 (CEST)
Subject: [R-sig-Geo] finding euclidean proximate points in two datasets
In-Reply-To: <4BF55556.5020207@ufl.edu>
References: <4BF55556.5020207@ufl.edu>
Message-ID: <alpine.LRH.2.00.1005202000190.29106@reclus.nhh.no>

On Thu, 20 May 2010, Alexander Shenkin wrote:

> Hello All,
>
> I posted this over on R-help, but was then directed here.
>
> I've been pouring through the various spatial packages, but haven't come
> across the right thing yet.
>
> Given a set of points in 2-d space X, i'm trying to find the subset of
> points in Y proximate to each point in X.  Furthermore, the proximity
> threshold of each point in X differs (X$threshold).  I've constructed
> this myself already, but it's horrificly slow with a dataset of 40k+
> points in one set, and a 700 in the other.

Could you get any further with nn2() in the RANN package? I realise that 
it isn't handling distances directly, but for some k=, it might help.

Roger

>
> A very inefficient example of what I'm looking for:
>
>    X = data.frame(x=c(1,2,3), y=c(2,3,1), threshold=c(1,2,4))
>    Y = data.frame(x=c(5,2,3,4,2,5,2,3), y=c(5,2,2,4,1,2,3,1))
>    proximate=list()
>    i=1
>    for (pt in 1:length(X$x)) {
>        proximate[[i]] <- sqrt((X[pt,]$x - Y$x)2 + (X[pt,]$y - Y$y)2)
>                          > X[pt,]$threshold
>        i=i+1
>    }
>    proximate
>
> Perhaps crossdist() in spatstat is what I should use, and then code a
> comparison with X$threshold after the cross-distances are computed.
> However, I was wondering if there was another tool I should be
> considering.  David Winsemius suggested I first compare on in each
> coordinate to cull points outside the threshold on that axis first,
> before computing distances, which will help.  Any and all thoughts are
> very welcome.  Thanks in advance.
>
> Thanks,
> Allie
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From hengl at spatial-analyst.net  Thu May 20 20:36:55 2010
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Thu, 20 May 2010 20:36:55 +0200
Subject: [R-sig-Geo] projection
In-Reply-To: <5DA773FDB5D4484D9A8E36F6C3DC018001834A91@scomp0039.wurnet.nl>
References: <5DA773FDB5D4484D9A8E36F6C3DC018001834A91@scomp0039.wurnet.nl>
Message-ID: <20100520203655.ezvj9ps1co4gw8ws@spatial-analyst.net>


It is a pity that people that have provided this data did not attach  
any metadata (see for example the simple metadata format I used to  
prepare worldmaps e.g.  
[http://spatial-analyst.net/worldmaps/globedem.rdc]).

My favorite places to look for correct proj4 strings (i.e. projection  
parameters) are [http://spatialreference.org] and  
[http://epsg-registry.org]. In this case I get multiple matches e.g.:

[http://spatialreference.org/ref/?search=ED+1950+Lambert+Conformal+Conic]

which means that you either need to test each one (reproject to latlon  
coordinates and then display in Google Earth). Or you need to contact  
the people that gave you this file and check with them how did they  
generate that map.

Otherwise, why break head? You can also obtain the SRTM blocks  
yourself and rebuild (mosaic) the map for the area of interest:

[http://srtm.csi.cgiar.org/SELECTION/inputCoord.asp]

In fact, this is probably the best recommendation that I can give.

HTH

T. Hengl
http://home.medewerker.uva.nl/t.hengl/


Quoting "Heuvelink, Gerard" <Gerard.Heuvelink at wur.nl>:
> Dear list,
>
> I hope someone can help me with the following.
>
> I have an SRTM DEM of Turkey in the "ED 1950 Lambert Conformal Conic"
> projection system.
>
> However, I do not know how this is referred to in R. For example, I
> might load the dem as:
>
> DEM = readGDAL("srtm_5km_ascii.txt")
>
> Next I will want to let know what projection it is by issuing:
>
> proj4string(DEM) = XXXXXXXXXXX
>
> What do I write for XXXXXXXX?
>
> Thanks, Gerard
>
>
> Gerard B.M. Heuvelink
> Environmental Sciences Group
> Wageningen University and Research Centre
> P.O. Box 47
> 6700 AA Wageningen
> The Netherlands
>
> tel +31 317 486538 Mon Tue
> tel +31 317 482716 Wed Thu Fri
>
> email gerard.heuvelink at wur.nl <mailto:gerard.heuvelink at wur.nl>
> http://www.lad.wur.nl/UK/ <http://www.lad.wur.nl/UK/>
> http://www.alterra.wur.nl/NL/onderzoek/Werkveld+Bodem/TBGE/Gerard+Heuvel
> ink/
> <http://www.alterra.wur.nl/NL/onderzoek/Werkveld+Bodem/TBGE/Gerard+Heuve
> link/>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From Roger.Bivand at nhh.no  Thu May 20 21:17:22 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 20 May 2010 21:17:22 +0200 (CEST)
Subject: [R-sig-Geo] overlay spatialgrid on spatial polygons data frame
In-Reply-To: <AANLkTinIagay1mKmVZX2XQQ_0s0_DhsZIonFP9sJ6ZKL@mail.gmail.com>
References: <AANLkTinIagay1mKmVZX2XQQ_0s0_DhsZIonFP9sJ6ZKL@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1005202112220.29106@reclus.nhh.no>

On Thu, 20 May 2010, Agustin Lobo wrote:

> I have an SpPolDF and a coarse SpatialGrid, i.e.,
> srdf=SpatialPolygonsDataFrame(sr, data.frame(cbind(1:3,5:3),
> row.names=c("r1","r2","r3")))
> #the one used in help(overlay);
>> srdf at data
>   X1 X2
> r1  1  5
> r2  2  4
> r3  3  3
>
>> bbox(srdf)
>     min    max
> x 178544 181477
> y 329665 333676
>
>> test <- SpatialGrid(GridTopology(cellcentre.offset=c(178440,329600), cellsize=c(500,500), cells.dim=c(8,10)))
>> plot(srdf)
>> plot(test,add=T)
>
> My goal is to "overlay" test over srdf and tranfer the data in
> srdf at data to a data frame associated
> to test (=> test must become a SpatialGridDF) so that each cell has
> the average value of the overlaid srdf at data polygon(s) weighted
> by area: in case 25% of a given cell in test would overlay polygon r1
> and 75% polygon r2, the value of X1 for that cell would be
> 0.25*1 + 0.75*2

This involves a topology operation on two sets of polygons, and is not 
supported. You can approximate it by creating a finer raster and using 
that subsequently aggregate, for example using the polygons in ?overlay 
to form srdf, then:

test2 <- SpatialGrid(GridTopology(cellcentre.offset=c(178440,329600),
  cellsize=c(50,50), cells.dim=c(80,100)))
o <- overlay(test2, srdf)
o1 <- SpatialPointsDataFrame(coordinates(test2), data=data.frame(o=o))
o2 <- o1[!is.na(o1$o),]
o2$X1 <- srdf$X1[o2$o]
o2$X2 <- srdf$X2[o2$o]
u <- overlay(test, o2)
uu <- aggregate(slot(o2, "data"), list(u), mean)
X1 <- rep(as.numeric(NA), nrow(coordinates(test)))
X2 <- rep(as.numeric(NA), nrow(coordinates(test)))
X1[uu$Group.1] <- uu$X1
X2[uu$Group.1] <- uu$X2
testdf <- 
SpatialGridDataFrame(GridTopology(cellcentre.offset=c(178440,329600),
cellsize=c(500,500), cells.dim=c(8,10)), data=data.frame(X1, X2))
spl <- list("sp.lines", as(srdf, "SpatialLines"), col="grey30")
spplot(testdf, c("X1", "X2"), col.regions=bpy.colors(20), sp.layout=spl)

The finer resolution should be fine enough to capture the relative areas 
of the polygons adequately.

Roger


>
> According to help(overlay),
> "Value
> a numerical array of indices of x on locations of y, or a data.frame
> with (possibly aggregate) properties of x in units of y"
>
> I've tried this:
>> overlay(srdf, test, fn=mean, na.rm)
>
>     X1 X2
> NA   NA NA
> NA.1 NA NA
>
> Cannot go beyond, perhaps overlay() is not suited for this: the
> definition of overlay in its help page
> "overlay combines points (or grids) and polygons by performing
> point-in-polygon operation on all point-polygons combinations"
> is a bit confusing, the first part of the sentence gives me some hope
> but the second one seems to exclude what I'm trying to do.
>
> Any help appreciated (or perhaps pointing to more doc?)
>
>
> Agus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From r.hijmans at gmail.com  Thu May 20 21:24:46 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 20 May 2010 12:24:46 -0700
Subject: [R-sig-Geo] overlay spatialgrid on spatial polygons data frame
In-Reply-To: <alpine.LRH.2.00.1005202112220.29106@reclus.nhh.no>
References: <AANLkTinIagay1mKmVZX2XQQ_0s0_DhsZIonFP9sJ6ZKL@mail.gmail.com>
	<alpine.LRH.2.00.1005202112220.29106@reclus.nhh.no>
Message-ID: <AANLkTimdSaFmUULIEWqENrk3o5pdhlSodBy44A1KowZe@mail.gmail.com>

Or essentially the same with using the polygonValues function in
raster (with weights=TRUE)

library(raster)
r <- raster(test)
r[] <- 1:ncell(r)
# finding out the fraction covered by each polygon
v <- polygonValues(srdf, r, weights=TRUE)

# below could possibly done more elegantly in an sapply
vv <- matrix(nrow=0, ncol=2)
polyvar <- 2  # second variable of the SpPolDF
for (i in 1:length(v)) {
	a <- v[[i]]
	vv <- rbind(vv, cbind(a[,1], a[,2] * srdf at data[i,polyvar]))
}

# sum over cells
vvv <- tapply(vv[,2], vv[,1], sum)
rr <- r
r[] <- NA
# apply cell values to raster
r[as.integer(rownames(vvv))] <- vvv
plot(r)
plot(srdf, add=T)


Robert

On Thu, May 20, 2010 at 12:17 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Thu, 20 May 2010, Agustin Lobo wrote:
>
>> I have an SpPolDF and a coarse SpatialGrid, i.e.,
>> srdf=SpatialPolygonsDataFrame(sr, data.frame(cbind(1:3,5:3),
>> row.names=c("r1","r2","r3")))
>> #the one used in help(overlay);
>>>
>>> srdf at data
>>
>> ?X1 X2
>> r1 ?1 ?5
>> r2 ?2 ?4
>> r3 ?3 ?3
>>
>>> bbox(srdf)
>>
>> ? ?min ? ?max
>> x 178544 181477
>> y 329665 333676
>>
>>> test <- SpatialGrid(GridTopology(cellcentre.offset=c(178440,329600),
>>> cellsize=c(500,500), cells.dim=c(8,10)))
>>> plot(srdf)
>>> plot(test,add=T)
>>
>> My goal is to "overlay" test over srdf and tranfer the data in
>> srdf at data to a data frame associated
>> to test (=> test must become a SpatialGridDF) so that each cell has
>> the average value of the overlaid srdf at data polygon(s) weighted
>> by area: in case 25% of a given cell in test would overlay polygon r1
>> and 75% polygon r2, the value of X1 for that cell would be
>> 0.25*1 + 0.75*2
>
> This involves a topology operation on two sets of polygons, and is not
> supported. You can approximate it by creating a finer raster and using that
> subsequently aggregate, for example using the polygons in ?overlay to form
> srdf, then:
>
> test2 <- SpatialGrid(GridTopology(cellcentre.offset=c(178440,329600),
> ?cellsize=c(50,50), cells.dim=c(80,100)))
> o <- overlay(test2, srdf)
> o1 <- SpatialPointsDataFrame(coordinates(test2), data=data.frame(o=o))
> o2 <- o1[!is.na(o1$o),]
> o2$X1 <- srdf$X1[o2$o]
> o2$X2 <- srdf$X2[o2$o]
> u <- overlay(test, o2)
> uu <- aggregate(slot(o2, "data"), list(u), mean)
> X1 <- rep(as.numeric(NA), nrow(coordinates(test)))
> X2 <- rep(as.numeric(NA), nrow(coordinates(test)))
> X1[uu$Group.1] <- uu$X1
> X2[uu$Group.1] <- uu$X2
> testdf <-
> SpatialGridDataFrame(GridTopology(cellcentre.offset=c(178440,329600),
> cellsize=c(500,500), cells.dim=c(8,10)), data=data.frame(X1, X2))
> spl <- list("sp.lines", as(srdf, "SpatialLines"), col="grey30")
> spplot(testdf, c("X1", "X2"), col.regions=bpy.colors(20), sp.layout=spl)
>
> The finer resolution should be fine enough to capture the relative areas of
> the polygons adequately.
>
> Roger
>
>
>>
>> According to help(overlay),
>> "Value
>> a numerical array of indices of x on locations of y, or a data.frame
>> with (possibly aggregate) properties of x in units of y"
>>
>> I've tried this:
>>>
>>> overlay(srdf, test, fn=mean, na.rm)
>>
>> ? ?X1 X2
>> NA ? NA NA
>> NA.1 NA NA
>>
>> Cannot go beyond, perhaps overlay() is not suited for this: the
>> definition of overlay in its help page
>> "overlay combines points (or grids) and polygons by performing
>> point-in-polygon operation on all point-polygons combinations"
>> is a bit confusing, the first part of the sentence gives me some hope
>> but the second one seems to exclude what I'm trying to do.
>>
>> Any help appreciated (or perhaps pointing to more doc?)
>>
>>
>> Agus
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From reeves at nceas.ucsb.edu  Fri May 21 02:10:13 2010
From: reeves at nceas.ucsb.edu (rick reeves)
Date: Thu, 20 May 2010 17:10:13 -0700
Subject: [R-sig-Geo] sp package/ spatial points operation works in R <= 2.8,
 fails for R >= 2.9 - resend with file download link
Message-ID: <4BF5CF65.1080205@nceas.ucsb.edu>

Hello List:

The following script creates a point grid at user-supplied spatial 
resolution;
this grid (SpatialPoints) is then used as an input to sp/overlay() to 
extract
points at regular intervals from a SpatialPolygonsDataFrame object.

Downloat the code and data for this example at: 
http://www.nceas.ucsb.edu/files/scicomp/Dloads/CreatePointGridSP.zip

CreatePointGrid <- function()
{
    library(rgdal) # loads sp package

# Read ESRI Shape File into SpatialPolygonsDataFrame

    EcoRegion <- 
readOGR("BaileysEcoRegionUsaGP.shp","BaileysEcoRegionUsaGP")
    theProjection <- proj4string(EcoRegion)

    vals <- EcoRegion at bbox
    deltaLong <- as.integer((vals[1,2] - vals[1,1]) + 1.5)
    deltaLat <- as.integer((vals[2,2] - vals[2,1]) + 1.5)

# grid resolution units: decimal degress.

    gridRes <- 1.0
    gridSizeX <- deltaLong / gridRes
    gridSizeY <- deltaLat / gridRes

# GridTopology object is basis for sampling grid

    GridTopoOneDeg <- GridTopology(vals[,1],
                                   c(gridRes,gridRes),
                                   c(gridSizeX,gridSizeY))

# Create the SpatialGrid object....

    SampGridOneDeg <- SpatialGrid(GridTopoOneDeg,proj4string = 
CRS(theProjection))
    SampPointsOneDeg <- as(SampGridOneDeg,"SpatialPoints")
    message("hit key to see first 20 points of One Degree Grid Points...")
    browser()
    print(SampPointsOneDeg[1:20,])
    message("done")
}
The issue: the line:

   SampPointsOneDeg <- as(SampGridOneDeg,"SpatialPoints")

   ...generates the required list of points when the script is run under 
R version 2.8 and earlier.
   However, if the script is run under R 2.9 or greater, the point list 
contains only 2 coordinate pairs.

   Question: What has changed in R 2.9 and later? Is this technique 
deprecated, and is there a better
                   way of creating such a point list?

Thanks,
Rick R

< Attached zip file contains the script and sample data set>

-- 
Rick Reeves
Scientific Programmer/Analyst and Data Manager
National Center for Ecological Analysis and Synthesis
UC Santa Barbara
www.nceas.ucsb.edu
805 892 2533


From alobolistas at gmail.com  Fri May 21 07:38:30 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Thu, 20 May 2010 22:38:30 -0700 (PDT)
Subject: [R-sig-Geo] writeOGR error: problem with GDAL (libgdal1- 1.7.0)
Message-ID: <1274420310057-5082811.post@n2.nabble.com>


I'm getting this error using a command and an object that
used to work few months ago

> writeOGR(Montseny20090409shtotspols, dsn="Montseny20090409tots2",
> layer="Montseny20090409shtots2",driver="ESRI Shapefile")
Error in writeOGR(Montseny20090409shtotspols, dsn = "Montseny20090409tots2", 
: 
  
	GDAL Error 1: Invalid index : -1
Calls: writeOGR -> .Call
In addition: Warning messages:
1: In writeOGR(Montseny20090409shtotspols, dsn = "Montseny20090409tots2",  :
  
	Non-fatal GDAL Error 6: Normalized/laundered field name: 'coords.x1.1' to
'coords.x1.'
2: In writeOGR(Montseny20090409shtotspols, dsn = "Montseny20090409tots2",  :
  
	Non-fatal GDAL Error 6: Normalized/laundered field name: 'coords.x2.1' to
'coords.x2.'

Both the Error and Warnings are new, and are actually related: if I do:
> names(Montseny20090409shtotspols at data)[31]<-"UTMX"
> names(Montseny20090409shtotspols at data)[32]<-"UTMY"

writeOGR() works fine.

Could a more explicit error message, linking the error to the problem with
the names, be issued by writeOGR() ? Initially I even thought I could have a
disk problem!

I recently upgraded from ubuntu 9.04 to 9.10 and to libgdal1-1.7.0.
R version 2.11.0 (2010-04-22)
 Package: rgdal
Version: 0.6-27
Date: 2010-05-11

Thanks

Agus
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/writeOGR-error-problem-with-GDAL-libgdal1-1-7-0-tp5082811p5082811.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From alobolistas at gmail.com  Fri May 21 07:54:59 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Thu, 20 May 2010 22:54:59 -0700 (PDT)
Subject: [R-sig-Geo] overlay spatialgrid on spatial polygons data frame
In-Reply-To: <AANLkTimdSaFmUULIEWqENrk3o5pdhlSodBy44A1KowZe@mail.gmail.com>
References: <AANLkTinIagay1mKmVZX2XQQ_0s0_DhsZIonFP9sJ6ZKL@mail.gmail.com>
	<alpine.LRH.2.00.1005202112220.29106@reclus.nhh.no>
	<AANLkTimdSaFmUULIEWqENrk3o5pdhlSodBy44A1KowZe@mail.gmail.com>
Message-ID: <1274421299016-5082854.post@n2.nabble.com>


Thanks to both of you.
I was keeping the solution through rasterization as a fallback because the
involved
raster would be very large.
I'll try to solve the problem keeping the vectorial format (at least for the
polygons) using grass through spgrass6 and will report back.
Also, maybe an intersection using joinPolys() could be another solution.
A suboptimal solution would be a stratified random sample of points within
the grid.

Agus
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/overlay-spatialgrid-on-spatial-polygons-data-frame-tp5079242p5082854.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From edzer.pebesma at uni-muenster.de  Fri May 21 08:29:18 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 21 May 2010 08:29:18 +0200
Subject: [R-sig-Geo] sp package/ spatial points operation works in R <=
 2.8, fails for R >= 2.9 - resend with file download link
In-Reply-To: <4BF5CF65.1080205@nceas.ucsb.edu>
References: <4BF5CF65.1080205@nceas.ucsb.edu>
Message-ID: <4BF6283E.8040601@uni-muenster.de>

Hi Rick, thanks for the clean and reproducable example.

instead of

  SampPointsOneDeg <- as(SampGridOneDeg, "SpatialPoints")

you now need to do a

   SampPointsOneDeg <- as(as(SampGridOneDeg,
"SpatialPixels"),"SpatialPoints")

to make your example work.

As these coercion functions were written a long time ago I believe that
the reason it stopped working are changes in the methods package rather
than in sp. I'd agree that the first one should work as well, and I'll
have a look at modifying sp such that it will, again, in the future.
--
Edzer

On 05/21/2010 02:10 AM, rick reeves wrote:
> Hello List:
> 
> The following script creates a point grid at user-supplied spatial
> resolution;
> this grid (SpatialPoints) is then used as an input to sp/overlay() to
> extract
> points at regular intervals from a SpatialPolygonsDataFrame object.
> 
> Downloat the code and data for this example at:
> http://www.nceas.ucsb.edu/files/scicomp/Dloads/CreatePointGridSP.zip
> 
> CreatePointGrid <- function()
> {
>    library(rgdal) # loads sp package
> 
> # Read ESRI Shape File into SpatialPolygonsDataFrame
> 
>    EcoRegion <-
> readOGR("BaileysEcoRegionUsaGP.shp","BaileysEcoRegionUsaGP")
>    theProjection <- proj4string(EcoRegion)
> 
>    vals <- EcoRegion at bbox
>    deltaLong <- as.integer((vals[1,2] - vals[1,1]) + 1.5)
>    deltaLat <- as.integer((vals[2,2] - vals[2,1]) + 1.5)
> 
> # grid resolution units: decimal degress.
> 
>    gridRes <- 1.0
>    gridSizeX <- deltaLong / gridRes
>    gridSizeY <- deltaLat / gridRes
> 
> # GridTopology object is basis for sampling grid
> 
>    GridTopoOneDeg <- GridTopology(vals[,1],
>                                   c(gridRes,gridRes),
>                                   c(gridSizeX,gridSizeY))
> 
> # Create the SpatialGrid object....
> 
>    SampGridOneDeg <- SpatialGrid(GridTopoOneDeg,proj4string =
> CRS(theProjection))
>    SampPointsOneDeg <- as(SampGridOneDeg,"SpatialPoints")
>    message("hit key to see first 20 points of One Degree Grid Points...")
>    browser()
>    print(SampPointsOneDeg[1:20,])
>    message("done")
> }
> The issue: the line:
> 
>   SampPointsOneDeg <- as(SampGridOneDeg,"SpatialPoints")
> 
>   ...generates the required list of points when the script is run under
> R version 2.8 and earlier.
>   However, if the script is run under R 2.9 or greater, the point list
> contains only 2 coordinate pairs.
> 
>   Question: What has changed in R 2.9 and later? Is this technique
> deprecated, and is there a better
>                   way of creating such a point list?
> 
> Thanks,
> Rick R
> 
> < Attached zip file contains the script and sample data set>
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From oldeland at gmx.de  Sun May 23 19:25:46 2010
From: oldeland at gmx.de (Jens Oldeland)
Date: Sun, 23 May 2010 19:25:46 +0200
Subject: [R-sig-Geo] Creating non-overlapping polygons from centroid with
	known size
Message-ID: <4BF9651A.80206@gmx.de>

Dear group,

I am looking for a method that allows me to creating non-overlapping 
polygons from centroids with a known size. I have information on the 
location of farms in Azerbaijan. All farms have a specific size, but I 
don?t know the exact borderlines of those farms. Now, I have to create a 
polygon layer that has polygons with the specific farmsize for each 
polygon, and the polygons of the farms should not overlap. However, I do 
not have a good idea how to do that.


I would be grateful for any hints or suggestions!

regards,
Jens


From b.rowlingson at lancaster.ac.uk  Sun May 23 19:56:17 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sun, 23 May 2010 18:56:17 +0100
Subject: [R-sig-Geo] Creating non-overlapping polygons from centroid
	with known size
In-Reply-To: <4BF9651A.80206@gmx.de>
References: <4BF9651A.80206@gmx.de>
Message-ID: <AANLkTikqnfOjU-XCzMrk6eqat50vzvSdiktZRBcPhRDD@mail.gmail.com>

On Sun, May 23, 2010 at 6:25 PM, Jens Oldeland <oldeland at gmx.de> wrote:
> Dear group,
>
> I am looking for a method that allows me to creating non-overlapping
> polygons from centroids with a known size. I have information on the
> location of farms in Azerbaijan. All farms have a specific size, but I don?t
> know the exact borderlines of those farms. Now, I have to create a polygon
> layer that has polygons with the specific farmsize for each polygon, and the
> polygons of the farms should not overlap. However, I do not have a good idea
> how to do that.
>
>
> I would be grateful for any hints or suggestions!
>

 Hmmmm. seems like an interesting problem. The easiest ideas I can
come up with operate on raster grids. Start with an empty grid on a
finer resolution than the closest pair of farms. Seed one grid square
for each farm centroid. Then loop over farms, allocating an adjacent
grid square in a non-allocated space until all farms have their
allocation. How do you choose the next grid square for a farm? I'd go
for the nearest non-allocated space that is contiguous to current
squares for that farm, which should keep it compact. I think I've seen
a screensaver do something similar with advancing waves of pixels. Any
solution to this in pure R would probably be horrendously slow for
even a small number of farms on a fine grid. Coded in C it should zip
along, with some clever data structures to help.

 There may be code to do this already, in the raster processing
section of a GIS package such as GRASS or gvSIG or geotools.

 Doing it with vectors could be tricky. For a first try, especially if
the farms are quite spaced out, you could generate voronoi polygons
for each farm, and if they are all larger than the required farm area
then all you then need to do is shrink each voronoi polygon about the
centroid by a factor. If any voronoi polys aren't big enough then
maybe you can shrink the big ones, and feed their points into the
voronoi algorithm again to get polys for the remaining centroids. And
repeat. This might not work though!

Barry


From jacobvanetten at yahoo.com  Sun May 23 22:21:58 2010
From: jacobvanetten at yahoo.com (Jacob van Etten)
Date: Sun, 23 May 2010 13:21:58 -0700 (PDT)
Subject: [R-sig-Geo] Creating non-overlapping polygons from centroid
	with known size
In-Reply-To: <4BF9651A.80206@gmx.de>
Message-ID: <548036.28616.qm@web32908.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100523/17732da6/attachment.pl>

From greenberg at ucdavis.edu  Tue May 25 04:35:36 2010
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Mon, 24 May 2010 19:35:36 -0700
Subject: [R-sig-Geo] raster() and mixed-projection/resolution files
Message-ID: <AANLkTim_m49BAxETXSuvJ8bkrrLH27jKDC00I5myyazq@mail.gmail.com>

R-sig-geo'ers:

Given two rasters of differing resolutions, extents, and cell sizes,
what is the most efficient way to do some level of raster algebra on
the files, e.g.:

raster1=raster(file1)
raster2=raster(file2)

I would like to add raster1 + raster2 and have the output be the
extent, cell size and projection of file1.   My understanding is
raster()'s map algebra requires the same size/projection of the
inputs, correct?  Thanks!

--j


From r.hijmans at gmail.com  Tue May 25 05:39:35 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Mon, 24 May 2010 20:39:35 -0700
Subject: [R-sig-Geo] raster() and mixed-projection/resolution files
In-Reply-To: <AANLkTim_m49BAxETXSuvJ8bkrrLH27jKDC00I5myyazq@mail.gmail.com>
References: <AANLkTim_m49BAxETXSuvJ8bkrrLH27jKDC00I5myyazq@mail.gmail.com>
Message-ID: <AANLkTimMIFL1qg4tQV1tW29luBI0NmiF5AOAHsgaoa2a@mail.gmail.com>

Dear Jonathan,

It depends. In the best case you can change the resolution of raster2
with 'aggregate' or 'disaggregate' (or a combination); and change its
extent with 'expand' or 'crop'.

In other cases, for example if the origin of the rasters also differ,
it may be necessary to resort to 'resample' to change the origin (and
perhaps cells size and extent at the same time).

Some raster algebra will actually work for rasters with different
extents, as long as they overlap at least partly, and their origin and
resolution are the same (the extent of the raster returned is the
intersect of the input rasters)

Robert


On Mon, May 24, 2010 at 7:35 PM, Jonathan Greenberg
<greenberg at ucdavis.edu> wrote:
> R-sig-geo'ers:
>
> Given two rasters of differing resolutions, extents, and cell sizes,
> what is the most efficient way to do some level of raster algebra on
> the files, e.g.:
>
> raster1=raster(file1)
> raster2=raster(file2)
>
> I would like to add raster1 + raster2 and have the output be the
> extent, cell size and projection of file1. ? My understanding is
> raster()'s map algebra requires the same size/projection of the
> inputs, correct? ?Thanks!
>
> --j
>


From paulo.mailing.list at gmail.com  Tue May 25 16:16:50 2010
From: paulo.mailing.list at gmail.com (Paulo Eduardo Cardoso)
Date: Tue, 25 May 2010 15:16:50 +0100
Subject: [R-sig-Geo] SpatialPointDataFrame to SpatialLinesDataFrame
Message-ID: <AANLkTikmVs6KHuQF2D0Q1k0bkaolLhD7I1J-JCTgzIDS@mail.gmail.com>

Hi,

How can one coerce spatial point to spatial line?

I'm struggling to find a way of coerce a point SPDF object to Lines
based in a ID [TARGET_ID] field.

Any idea will be very welcome.

Formal class 'SpatialPointsDataFrame' [package "sp"] with 5 slots
  ..@ data       :'data.frame': 28 obs. of  8 variables:
  .. ..$ ID        : int [1:28] 462964 462990 463015 463034 463052 463069
463083 463102 463122 463144 ...
  .. ..$ TIME_STAMP: POSIXlt[1:28], format: "2009-07-26 09:00:07"
"2009-07-26 09:00:13" "2009-07-26 09:00:19" "2009-07-26 09:00:25" ...
  .. ..$ DAY_PERIOD: int [1:28] 1 1 1 1 1 1 1 1 1 1 ...
  .. ..$ SEASON    : int [1:28] 2 2 2 2 2 2 2 2 2 2 ...
  .. ..$ TARGET_ID : int [1:28] 108426 108426 108426 108426 108426 108426
108426 108426 108426 108426 ...
  .. ..$ SPEED     : num [1:28] 0.283 0.6 0.4 0.2 0.2 ...
  .. ..$ HEADING   : int [1:28] 134 1 179 179 179 271 123 179 179 90 ...
  .. ..$ DISTANCE  : num [1:28] 1.41 3 2 1 1 ...
  ..@ coords.nrs : int [1:2] 7 6
  ..@ coords     : num [1:28, 1:2] -8.71 -8.71 -8.71 -8.71 -8.71 ...
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : NULL
  .. .. ..$ : chr [1:2] "LONGITUDE" "LATITUDE"
  ..@ bbox       : num [1:2, 1:2] -8.82 38.73 -8.69 38.8
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr [1:2] "LONGITUDE" "LATITUDE"
  .. .. ..$ : chr [1:2] "min" "max"
  ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
  .. .. ..@ projargs: chr " +init=epsg:4326 +proj=longlat +ellps=WGS84
+datum=WGS84 +no_defs +towgs84=0,0,0"


Paulo Eduardo Cardoso


From edzer.pebesma at uni-muenster.de  Tue May 25 22:04:23 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 25 May 2010 22:04:23 +0200
Subject: [R-sig-Geo] SpatialPointDataFrame to SpatialLinesDataFrame
In-Reply-To: <AANLkTikmVs6KHuQF2D0Q1k0bkaolLhD7I1J-JCTgzIDS@mail.gmail.com>
References: <AANLkTikmVs6KHuQF2D0Q1k0bkaolLhD7I1J-JCTgzIDS@mail.gmail.com>
Message-ID: <4BFC2D47.9050107@uni-muenster.de>

Here's an example how a Lines object is built from several sets of
points (meuse data, split by soil type):

library(sp)
data(meuse)
Lines(sapply(split(meuse[c("x","y")], meuse$soil), Line))

Note that meuse is used as a data.frame in this example; use
as.data.frame on your SPDF to get it.

I hope this helps,

On 05/25/2010 04:16 PM, Paulo Eduardo Cardoso wrote:
> Hi,
> 
> How can one coerce spatial point to spatial line?
> 
> I'm struggling to find a way of coerce a point SPDF object to Lines
> based in a ID [TARGET_ID] field.
> 
> Any idea will be very welcome.
> 
> Formal class 'SpatialPointsDataFrame' [package "sp"] with 5 slots
>   ..@ data       :'data.frame': 28 obs. of  8 variables:
>   .. ..$ ID        : int [1:28] 462964 462990 463015 463034 463052 463069
> 463083 463102 463122 463144 ...
>   .. ..$ TIME_STAMP: POSIXlt[1:28], format: "2009-07-26 09:00:07"
> "2009-07-26 09:00:13" "2009-07-26 09:00:19" "2009-07-26 09:00:25" ...
>   .. ..$ DAY_PERIOD: int [1:28] 1 1 1 1 1 1 1 1 1 1 ...
>   .. ..$ SEASON    : int [1:28] 2 2 2 2 2 2 2 2 2 2 ...
>   .. ..$ TARGET_ID : int [1:28] 108426 108426 108426 108426 108426 108426
> 108426 108426 108426 108426 ...
>   .. ..$ SPEED     : num [1:28] 0.283 0.6 0.4 0.2 0.2 ...
>   .. ..$ HEADING   : int [1:28] 134 1 179 179 179 271 123 179 179 90 ...
>   .. ..$ DISTANCE  : num [1:28] 1.41 3 2 1 1 ...
>   ..@ coords.nrs : int [1:2] 7 6
>   ..@ coords     : num [1:28, 1:2] -8.71 -8.71 -8.71 -8.71 -8.71 ...
>   .. ..- attr(*, "dimnames")=List of 2
>   .. .. ..$ : NULL
>   .. .. ..$ : chr [1:2] "LONGITUDE" "LATITUDE"
>   ..@ bbox       : num [1:2, 1:2] -8.82 38.73 -8.69 38.8
>   .. ..- attr(*, "dimnames")=List of 2
>   .. .. ..$ : chr [1:2] "LONGITUDE" "LATITUDE"
>   .. .. ..$ : chr [1:2] "min" "max"
>   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>   .. .. ..@ projargs: chr " +init=epsg:4326 +proj=longlat +ellps=WGS84
> +datum=WGS84 +no_defs +towgs84=0,0,0"
> 
> 
> Paulo Eduardo Cardoso
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From paulo.mailing.list at gmail.com  Wed May 26 10:43:15 2010
From: paulo.mailing.list at gmail.com (Paulo Eduardo Cardoso)
Date: Wed, 26 May 2010 09:43:15 +0100
Subject: [R-sig-Geo] SpatialPointDataFrame to SpatialLinesDataFrame
In-Reply-To: <4BFC2D47.9050107@uni-muenster.de>
References: <AANLkTikmVs6KHuQF2D0Q1k0bkaolLhD7I1J-JCTgzIDS@mail.gmail.com>
	<4BFC2D47.9050107@uni-muenster.de>
Message-ID: <AANLkTikvueiHbXrqCFdYaoL9AajoYZvd1Xaf1hvcntsC@mail.gmail.com>

Thanks!

But by doing this

ltraj <- Lines(sapply(split(traj_subam[c("LONGITUDE","LATITUDE")],
traj_subam$TARGET_ID), Line))

we get

Slot "ID":
[1] NA


We are not holding the [Target_ID] column as ID ?

2010/5/25 Edzer Pebesma <edzer.pebesma at uni-muenster.de>:
> Here's an example how a Lines object is built from several sets of
> points (meuse data, split by soil type):
>
> library(sp)
> data(meuse)
> Lines(sapply(split(meuse[c("x","y")], meuse$soil), Line))
>
> Note that meuse is used as a data.frame in this example; use
> as.data.frame on your SPDF to get it.
>
> I hope this helps,
>
> On 05/25/2010 04:16 PM, Paulo Eduardo Cardoso wrote:
>> Hi,
>>
>> How can one coerce spatial point to spatial line?
>>
>> I'm struggling to find a way of coerce a point SPDF object to Lines
>> based in a ID [TARGET_ID] field.
>>
>> Any idea will be very welcome.
>>
>> Formal class 'SpatialPointsDataFrame' [package "sp"] with 5 slots
>> ? ..@ data ? ? ? :'data.frame': 28 obs. of ?8 variables:
>> ? .. ..$ ID ? ? ? ?: int [1:28] 462964 462990 463015 463034 463052 463069
>> 463083 463102 463122 463144 ...
>> ? .. ..$ TIME_STAMP: POSIXlt[1:28], format: "2009-07-26 09:00:07"
>> "2009-07-26 09:00:13" "2009-07-26 09:00:19" "2009-07-26 09:00:25" ...
>> ? .. ..$ DAY_PERIOD: int [1:28] 1 1 1 1 1 1 1 1 1 1 ...
>> ? .. ..$ SEASON ? ?: int [1:28] 2 2 2 2 2 2 2 2 2 2 ...
>> ? .. ..$ TARGET_ID : int [1:28] 108426 108426 108426 108426 108426 108426
>> 108426 108426 108426 108426 ...
>> ? .. ..$ SPEED ? ? : num [1:28] 0.283 0.6 0.4 0.2 0.2 ...
>> ? .. ..$ HEADING ? : int [1:28] 134 1 179 179 179 271 123 179 179 90 ...
>> ? .. ..$ DISTANCE ?: num [1:28] 1.41 3 2 1 1 ...
>> ? ..@ coords.nrs : int [1:2] 7 6
>> ? ..@ coords ? ? : num [1:28, 1:2] -8.71 -8.71 -8.71 -8.71 -8.71 ...
>> ? .. ..- attr(*, "dimnames")=List of 2
>> ? .. .. ..$ : NULL
>> ? .. .. ..$ : chr [1:2] "LONGITUDE" "LATITUDE"
>> ? ..@ bbox ? ? ? : num [1:2, 1:2] -8.82 38.73 -8.69 38.8
>> ? .. ..- attr(*, "dimnames")=List of 2
>> ? .. .. ..$ : chr [1:2] "LONGITUDE" "LATITUDE"
>> ? .. .. ..$ : chr [1:2] "min" "max"
>> ? ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>> ? .. .. ..@ projargs: chr " +init=epsg:4326 +proj=longlat +ellps=WGS84
>> +datum=WGS84 +no_defs +towgs84=0,0,0"
>>
>>
>> Paulo Eduardo Cardoso
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> 8333081, Fax: +49 251 8339763 ?http://ifgi.uni-muenster.de
> http://www.52north.org/geostatistics ? ? ?e.pebesma at wwu.de
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From paulo.mailing.list at gmail.com  Wed May 26 10:46:40 2010
From: paulo.mailing.list at gmail.com (Paulo Eduardo Cardoso)
Date: Wed, 26 May 2010 09:46:40 +0100
Subject: [R-sig-Geo] SpatialPointDataFrame to SpatialLinesDataFrame
In-Reply-To: <AANLkTikvueiHbXrqCFdYaoL9AajoYZvd1Xaf1hvcntsC@mail.gmail.com>
References: <AANLkTikmVs6KHuQF2D0Q1k0bkaolLhD7I1J-JCTgzIDS@mail.gmail.com>
	<4BFC2D47.9050107@uni-muenster.de>
	<AANLkTikvueiHbXrqCFdYaoL9AajoYZvd1Xaf1hvcntsC@mail.gmail.com>
Message-ID: <AANLkTilp3_hzKciA-QQKm20Ow0xOxekfOxzjRJFyB_j7@mail.gmail.com>

When I try to coerce Lnes to SLDF with

ltraj <- Lines(sapply(split(traj_subam[c("LONGITUDE","LATITUDE")],
traj_subam$TARGET_ID), Line))
ltraj <- SpatialLinesDataFrame(ltraj, traj_subam, match.ID = TRUE)

I get

Error in slot(sl, "lines") :
  no slot of name "lines" for this object of class "Lines"

Any idea?

2010/5/26 Paulo Eduardo Cardoso <paulo.mailing.list at gmail.com>:
> Thanks!
>
> But by doing this
>
> ltraj <- Lines(sapply(split(traj_subam[c("LONGITUDE","LATITUDE")],
> traj_subam$TARGET_ID), Line))
>
> we get
>
> Slot "ID":
> [1] NA
>
>
> We are not holding the [Target_ID] column as ID ?
>
> 2010/5/25 Edzer Pebesma <edzer.pebesma at uni-muenster.de>:
>> Here's an example how a Lines object is built from several sets of
>> points (meuse data, split by soil type):
>>
>> library(sp)
>> data(meuse)
>> Lines(sapply(split(meuse[c("x","y")], meuse$soil), Line))
>>
>> Note that meuse is used as a data.frame in this example; use
>> as.data.frame on your SPDF to get it.
>>
>> I hope this helps,
>>
>> On 05/25/2010 04:16 PM, Paulo Eduardo Cardoso wrote:
>>> Hi,
>>>
>>> How can one coerce spatial point to spatial line?
>>>
>>> I'm struggling to find a way of coerce a point SPDF object to Lines
>>> based in a ID [TARGET_ID] field.
>>>
>>> Any idea will be very welcome.
>>>
>>> Formal class 'SpatialPointsDataFrame' [package "sp"] with 5 slots
>>> ? ..@ data ? ? ? :'data.frame': 28 obs. of ?8 variables:
>>> ? .. ..$ ID ? ? ? ?: int [1:28] 462964 462990 463015 463034 463052 463069
>>> 463083 463102 463122 463144 ...
>>> ? .. ..$ TIME_STAMP: POSIXlt[1:28], format: "2009-07-26 09:00:07"
>>> "2009-07-26 09:00:13" "2009-07-26 09:00:19" "2009-07-26 09:00:25" ...
>>> ? .. ..$ DAY_PERIOD: int [1:28] 1 1 1 1 1 1 1 1 1 1 ...
>>> ? .. ..$ SEASON ? ?: int [1:28] 2 2 2 2 2 2 2 2 2 2 ...
>>> ? .. ..$ TARGET_ID : int [1:28] 108426 108426 108426 108426 108426 108426
>>> 108426 108426 108426 108426 ...
>>> ? .. ..$ SPEED ? ? : num [1:28] 0.283 0.6 0.4 0.2 0.2 ...
>>> ? .. ..$ HEADING ? : int [1:28] 134 1 179 179 179 271 123 179 179 90 ...
>>> ? .. ..$ DISTANCE ?: num [1:28] 1.41 3 2 1 1 ...
>>> ? ..@ coords.nrs : int [1:2] 7 6
>>> ? ..@ coords ? ? : num [1:28, 1:2] -8.71 -8.71 -8.71 -8.71 -8.71 ...
>>> ? .. ..- attr(*, "dimnames")=List of 2
>>> ? .. .. ..$ : NULL
>>> ? .. .. ..$ : chr [1:2] "LONGITUDE" "LATITUDE"
>>> ? ..@ bbox ? ? ? : num [1:2, 1:2] -8.82 38.73 -8.69 38.8
>>> ? .. ..- attr(*, "dimnames")=List of 2
>>> ? .. .. ..$ : chr [1:2] "LONGITUDE" "LATITUDE"
>>> ? .. .. ..$ : chr [1:2] "min" "max"
>>> ? ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>>> ? .. .. ..@ projargs: chr " +init=epsg:4326 +proj=longlat +ellps=WGS84
>>> +datum=WGS84 +no_defs +towgs84=0,0,0"
>>>
>>>
>>> Paulo Eduardo Cardoso
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> --
>> Edzer Pebesma
>> Institute for Geoinformatics (ifgi), University of M?nster
>> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
>> 8333081, Fax: +49 251 8339763 ?http://ifgi.uni-muenster.de
>> http://www.52north.org/geostatistics ? ? ?e.pebesma at wwu.de
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From clelia.bilodeau at gmail.com  Wed May 26 11:08:01 2010
From: clelia.bilodeau at gmail.com (=?ISO-8859-1?Q?Cl=E9lia_Bilodeau?=)
Date: Wed, 26 May 2010 11:08:01 +0200
Subject: [R-sig-Geo] Elevation histogram for each region
Message-ID: <AANLkTil_cmNeY6WTeNQizAdCzPO4jZWn1wENrWjVAC25@mail.gmail.com>

Dear list,

I have two rasters, one is a Digital Elevation Model, and the other is
a region file.
I am looking for a method that allows me to plot the elevation
histogram or density for each region.

My first try was to do this with a function and to use "Zonal" from
the "raster" package, but I have a very large file, so I have this
error:
"RasterLayers are too large. You can use fun='sum', 'mean', 'min', or
'max', but not a function"

Is there another way to do this?

Thank you.


From paulo.mailing.list at gmail.com  Wed May 26 11:37:54 2010
From: paulo.mailing.list at gmail.com (Paulo Eduardo Cardoso)
Date: Wed, 26 May 2010 10:37:54 +0100
Subject: [R-sig-Geo] SpatialPointDataFrame to SpatialLinesDataFrame
In-Reply-To: <AANLkTilp3_hzKciA-QQKm20Ow0xOxekfOxzjRJFyB_j7@mail.gmail.com>
References: <AANLkTikmVs6KHuQF2D0Q1k0bkaolLhD7I1J-JCTgzIDS@mail.gmail.com>
	<4BFC2D47.9050107@uni-muenster.de>
	<AANLkTikvueiHbXrqCFdYaoL9AajoYZvd1Xaf1hvcntsC@mail.gmail.com>
	<AANLkTilp3_hzKciA-QQKm20Ow0xOxekfOxzjRJFyB_j7@mail.gmail.com>
Message-ID: <AANLkTimuaT9oZltp7l8JoMt4MVXO-nskdPrAVIbb7Jno@mail.gmail.com>

Sory but I'm not getting this correctly.

a data.frame

> print(traj_subam, row.names =F)
      ID          TIME_STAMP DAY_PERIOD SEASON TARGET_ID LATITUDE
LONGITUDE     SPEED HEADING DISTANCE
 7127128 2010-03-12 06:26:45          2      4   1712762 38.79497
-8.756062 0.5656855      46 2.828427
 7127143 2010-03-12 06:26:50          2      4   1712762 38.79539
-8.755520 0.2000000       1 1.000000
 7127156 2010-03-12 06:26:55          2      4   1712762 38.79560
-8.755520 0.7211103      34 3.605551
 7127175 2010-03-12 06:27:00          2      4   1712762 38.79624
-8.754979 0.0000000       0 0.000000
 7422814 2010-03-14 15:04:34          1      4   1782729 38.82139
-8.738729 0.4472136     153 2.236068
 7422841 2010-03-14 15:04:39          1      4   1782729 38.82096
-8.738460 0.4472136     334 2.236068
 7422865 2010-03-14 15:04:45          1      4   1782729 38.82139
-8.738729 0.0000000       0 0.000000
>

Then
#!Lines
ltraj <- Lines(sapply(split(traj_subam[c("LONGITUDE","LATITUDE")],
traj_subam$TARGET_ID), Line), ID =
as.character(unique(traj_subam$TARGET_ID)))

#! SpatialLines
ltraj <- SpatialLines(list(ltraj))

SLDF cannot be created with

ltraj <- SpatialLinesDataFrame(ltraj, data.frame("TARGET_ID" =
unique(traj_subam$TARGET_ID)), match.ID = T)

neither with match.ID = T or F

Paulo

2010/5/26 Paulo Eduardo Cardoso <paulo.mailing.list at gmail.com>:
> When I try to coerce Lnes to SLDF with
>
> ltraj <- Lines(sapply(split(traj_subam[c("LONGITUDE","LATITUDE")],
> traj_subam$TARGET_ID), Line))
> ltraj <- SpatialLinesDataFrame(ltraj, traj_subam, match.ID = TRUE)
>
> I get
>
> Error in slot(sl, "lines") :
> ?no slot of name "lines" for this object of class "Lines"
>
> Any idea?
>
> 2010/5/26 Paulo Eduardo Cardoso <paulo.mailing.list at gmail.com>:
>> Thanks!
>>
>> But by doing this
>>
>> ltraj <- Lines(sapply(split(traj_subam[c("LONGITUDE","LATITUDE")],
>> traj_subam$TARGET_ID), Line))
>>
>> we get
>>
>> Slot "ID":
>> [1] NA
>>
>>
>> We are not holding the [Target_ID] column as ID ?
>>
>> 2010/5/25 Edzer Pebesma <edzer.pebesma at uni-muenster.de>:
>>> Here's an example how a Lines object is built from several sets of
>>> points (meuse data, split by soil type):
>>>
>>> library(sp)
>>> data(meuse)
>>> Lines(sapply(split(meuse[c("x","y")], meuse$soil), Line))
>>>
>>> Note that meuse is used as a data.frame in this example; use
>>> as.data.frame on your SPDF to get it.
>>>
>>> I hope this helps,
>>>
>>> On 05/25/2010 04:16 PM, Paulo Eduardo Cardoso wrote:
>>>> Hi,
>>>>
>>>> How can one coerce spatial point to spatial line?
>>>>
>>>> I'm struggling to find a way of coerce a point SPDF object to Lines
>>>> based in a ID [TARGET_ID] field.
>>>>
>>>> Any idea will be very welcome.
>>>>
>>>> Formal class 'SpatialPointsDataFrame' [package "sp"] with 5 slots
>>>> ? ..@ data ? ? ? :'data.frame': 28 obs. of ?8 variables:
>>>> ? .. ..$ ID ? ? ? ?: int [1:28] 462964 462990 463015 463034 463052 463069
>>>> 463083 463102 463122 463144 ...
>>>> ? .. ..$ TIME_STAMP: POSIXlt[1:28], format: "2009-07-26 09:00:07"
>>>> "2009-07-26 09:00:13" "2009-07-26 09:00:19" "2009-07-26 09:00:25" ...
>>>> ? .. ..$ DAY_PERIOD: int [1:28] 1 1 1 1 1 1 1 1 1 1 ...
>>>> ? .. ..$ SEASON ? ?: int [1:28] 2 2 2 2 2 2 2 2 2 2 ...
>>>> ? .. ..$ TARGET_ID : int [1:28] 108426 108426 108426 108426 108426 108426
>>>> 108426 108426 108426 108426 ...
>>>> ? .. ..$ SPEED ? ? : num [1:28] 0.283 0.6 0.4 0.2 0.2 ...
>>>> ? .. ..$ HEADING ? : int [1:28] 134 1 179 179 179 271 123 179 179 90 ...
>>>> ? .. ..$ DISTANCE ?: num [1:28] 1.41 3 2 1 1 ...
>>>> ? ..@ coords.nrs : int [1:2] 7 6
>>>> ? ..@ coords ? ? : num [1:28, 1:2] -8.71 -8.71 -8.71 -8.71 -8.71 ...
>>>> ? .. ..- attr(*, "dimnames")=List of 2
>>>> ? .. .. ..$ : NULL
>>>> ? .. .. ..$ : chr [1:2] "LONGITUDE" "LATITUDE"
>>>> ? ..@ bbox ? ? ? : num [1:2, 1:2] -8.82 38.73 -8.69 38.8
>>>> ? .. ..- attr(*, "dimnames")=List of 2
>>>> ? .. .. ..$ : chr [1:2] "LONGITUDE" "LATITUDE"
>>>> ? .. .. ..$ : chr [1:2] "min" "max"
>>>> ? ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>>>> ? .. .. ..@ projargs: chr " +init=epsg:4326 +proj=longlat +ellps=WGS84
>>>> +datum=WGS84 +no_defs +towgs84=0,0,0"
>>>>
>>>>
>>>> Paulo Eduardo Cardoso
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>> --
>>> Edzer Pebesma
>>> Institute for Geoinformatics (ifgi), University of M?nster
>>> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
>>> 8333081, Fax: +49 251 8339763 ?http://ifgi.uni-muenster.de
>>> http://www.52north.org/geostatistics ? ? ?e.pebesma at wwu.de
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>


From r.hijmans at gmail.com  Wed May 26 18:44:39 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 26 May 2010 09:44:39 -0700
Subject: [R-sig-Geo] Elevation histogram for each region
In-Reply-To: <AANLkTil_cmNeY6WTeNQizAdCzPO4jZWn1wENrWjVAC25@mail.gmail.com>
References: <AANLkTil_cmNeY6WTeNQizAdCzPO4jZWn1wENrWjVAC25@mail.gmail.com>
Message-ID: <AANLkTinhCwvIKHd9d9xyoJW9EA90pDQEmQR47JwJc57r@mail.gmail.com>

Cl?lia,

The optimal solution would depend a bit on your data. If the regions
are not too large, you could loop over the zones

library(raster)
lst = list()
for (i in 1:nzones) {
  p <- rasterToPoints(r, fun=function(x){x==i})
  lst[[i]] = histogram(p[,3])
}

If you also have the zones as polygons you could alternatively look
over the polygons and use  polygonValues in stead of rasterToPoints

Another, more elaborate, option could be to, in your loop, reclassify
the regions raster (1 / 0 ), multiply that with the elevation data;
trim the output raster, make a histogram (set maxpixels to
ncell(raster)) (this may take a long time to finish)

You could also first aggregate the rasters; unless you care much about
the extreme values.

Hope this helps,
Robert


On Wed, May 26, 2010 at 2:08 AM, Cl?lia Bilodeau
<clelia.bilodeau at gmail.com> wrote:
> Dear list,
>
> I have two rasters, one is a Digital Elevation Model, and the other is
> a region file.
> I am looking for a method that allows me to plot the elevation
> histogram or density for each region.
>
> My first try was to do this with a function and to use "Zonal" from
> the "raster" package, but I have a very large file, so I have this
> error:
> "RasterLayers are too large. You can use fun='sum', 'mean', 'min', or
> 'max', but not a function"
>
> Is there another way to do this?
>
> Thank you.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From Jan.Quets at ua.ac.be  Thu May 27 12:00:48 2010
From: Jan.Quets at ua.ac.be (Quets Jan)
Date: Thu, 27 May 2010 12:00:48 +0200
Subject: [R-sig-Geo] circular holes in rectangular polygon
Message-ID: <7D403BF1018E6D4882ADD0F77E35BC5C159568@xmail06.ad.ua.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100527/5aa4cc46/attachment.pl>

From roman.lustrik at gmail.com  Thu May 27 12:19:35 2010
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Thu, 27 May 2010 12:19:35 +0200
Subject: [R-sig-Geo] circular holes in rectangular polygon
In-Reply-To: <7D403BF1018E6D4882ADD0F77E35BC5C159568@xmail06.ad.ua.ac.be>
References: <7D403BF1018E6D4882ADD0F77E35BC5C159568@xmail06.ad.ua.ac.be>
Message-ID: <AANLkTikbXiUbHaon1oa6DHxc0k0qQkOfAfqmrA3Votox@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100527/1100a284/attachment.pl>

From johan.vandewauw at gmail.com  Thu May 27 12:55:56 2010
From: johan.vandewauw at gmail.com (Johan Van de Wauw)
Date: Thu, 27 May 2010 12:55:56 +0200
Subject: [R-sig-Geo] RSAGA Vectorizing Grid Classes creates unclosed
	rings
In-Reply-To: <loom.20100511T195649-38@post.gmane.org>
References: <F16DA63221030F44A4E2E81645E9B5170361C434@EVD-C8001.bk.evdad.admin.ch>
	<alpine.LRH.2.00.1005111919580.12555@reclus.nhh.no>
	<loom.20100511T195649-38@post.gmane.org>
Message-ID: <AANLkTimpfyfPfFwq7tSeJ8Gg0nQV_XNnudue6jHoix3h@mail.gmail.com>

This is a known error in SAGA.
It will be fixed in the next version
http://saga-gis.cvs.sourceforge.net/viewvc/saga-gis/saga_2/src/modules/shapes/shapes_grid/Grid_Classes_To_Shapes.cpp?view=log

On Tue, May 11, 2010 at 8:02 PM, manuel.schneider
<manuel.schneider at art.admin.ch> wrote:
> Roger Bivand <Roger.Bivand <at> nhh.no> writes:
>
>>
>> On Tue, 11 May 2010, manuel.schneider <at> art.admin.ch wrote:
>>
> ...
>> > Error in is.vector(X) : ring not closed
>>
>> http://shapelib.maptools.org/dl/shapefile.pdf
>>
>> does specify that a polygon in a shapefile must be closed. You may be able
>> to use readShapePoly(..., force_ring=TRUE) in maptools to work around the
>> problem.
>>
>> Roger
>>
>>
>
> As always, your suggestion does the trick. Thanks a lot.
> However, still puzzled why it occurs.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From edzer.pebesma at uni-muenster.de  Thu May 27 13:06:31 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 27 May 2010 13:06:31 +0200
Subject: [R-sig-Geo] SpatialPointDataFrame to SpatialLinesDataFrame
In-Reply-To: <AANLkTimuaT9oZltp7l8JoMt4MVXO-nskdPrAVIbb7Jno@mail.gmail.com>
References: <AANLkTikmVs6KHuQF2D0Q1k0bkaolLhD7I1J-JCTgzIDS@mail.gmail.com>	<4BFC2D47.9050107@uni-muenster.de>	<AANLkTikvueiHbXrqCFdYaoL9AajoYZvd1Xaf1hvcntsC@mail.gmail.com>	<AANLkTilp3_hzKciA-QQKm20Ow0xOxekfOxzjRJFyB_j7@mail.gmail.com>
	<AANLkTimuaT9oZltp7l8JoMt4MVXO-nskdPrAVIbb7Jno@mail.gmail.com>
Message-ID: <4BFE5237.5070806@uni-muenster.de>

Your question is this time different from the initial one. Also, the
example you provide is not reproducable for others. Does the example
below match what you have in mind?

library(sp)
data(meuse)
lst = split(meuse[c("x","y")], meuse$soil)
x = SpatialLines(sapply(1:length(lst),
        function(i) Lines(list(Line(lst[[i]])), as.character(i))
    )
)
x.sl = SpatialLinesDataFrame(x, data.frame(soil=unique(meuse$soil)))
plot(x.sl, col=x.sl$soil)


On 05/26/2010 11:37 AM, Paulo Eduardo Cardoso wrote:
> Sory but I'm not getting this correctly.
> 
> a data.frame
> 
>> print(traj_subam, row.names =F)
>       ID          TIME_STAMP DAY_PERIOD SEASON TARGET_ID LATITUDE
> LONGITUDE     SPEED HEADING DISTANCE
>  7127128 2010-03-12 06:26:45          2      4   1712762 38.79497
> -8.756062 0.5656855      46 2.828427
>  7127143 2010-03-12 06:26:50          2      4   1712762 38.79539
> -8.755520 0.2000000       1 1.000000
>  7127156 2010-03-12 06:26:55          2      4   1712762 38.79560
> -8.755520 0.7211103      34 3.605551
>  7127175 2010-03-12 06:27:00          2      4   1712762 38.79624
> -8.754979 0.0000000       0 0.000000
>  7422814 2010-03-14 15:04:34          1      4   1782729 38.82139
> -8.738729 0.4472136     153 2.236068
>  7422841 2010-03-14 15:04:39          1      4   1782729 38.82096
> -8.738460 0.4472136     334 2.236068
>  7422865 2010-03-14 15:04:45          1      4   1782729 38.82139
> -8.738729 0.0000000       0 0.000000
>>
> 
> Then
> #!Lines
> ltraj <- Lines(sapply(split(traj_subam[c("LONGITUDE","LATITUDE")],
> traj_subam$TARGET_ID), Line), ID =
> as.character(unique(traj_subam$TARGET_ID)))
> 
> #! SpatialLines
> ltraj <- SpatialLines(list(ltraj))
> 
> SLDF cannot be created with
> 
> ltraj <- SpatialLinesDataFrame(ltraj, data.frame("TARGET_ID" =
> unique(traj_subam$TARGET_ID)), match.ID = T)
> 
> neither with match.ID = T or F
> 
> Paulo
> 
> 2010/5/26 Paulo Eduardo Cardoso <paulo.mailing.list at gmail.com>:
>> When I try to coerce Lnes to SLDF with
>>
>> ltraj <- Lines(sapply(split(traj_subam[c("LONGITUDE","LATITUDE")],
>> traj_subam$TARGET_ID), Line))
>> ltraj <- SpatialLinesDataFrame(ltraj, traj_subam, match.ID = TRUE)
>>
>> I get
>>
>> Error in slot(sl, "lines") :
>>  no slot of name "lines" for this object of class "Lines"
>>
>> Any idea?
>>
>> 2010/5/26 Paulo Eduardo Cardoso <paulo.mailing.list at gmail.com>:
>>> Thanks!
>>>
>>> But by doing this
>>>
>>> ltraj <- Lines(sapply(split(traj_subam[c("LONGITUDE","LATITUDE")],
>>> traj_subam$TARGET_ID), Line))
>>>
>>> we get
>>>
>>> Slot "ID":
>>> [1] NA
>>>
>>>
>>> We are not holding the [Target_ID] column as ID ?
>>>
>>> 2010/5/25 Edzer Pebesma <edzer.pebesma at uni-muenster.de>:
>>>> Here's an example how a Lines object is built from several sets of
>>>> points (meuse data, split by soil type):
>>>>
>>>> library(sp)
>>>> data(meuse)
>>>> Lines(sapply(split(meuse[c("x","y")], meuse$soil), Line))
>>>>
>>>> Note that meuse is used as a data.frame in this example; use
>>>> as.data.frame on your SPDF to get it.
>>>>
>>>> I hope this helps,
>>>>
>>>> On 05/25/2010 04:16 PM, Paulo Eduardo Cardoso wrote:
>>>>> Hi,
>>>>>
>>>>> How can one coerce spatial point to spatial line?
>>>>>
>>>>> I'm struggling to find a way of coerce a point SPDF object to Lines
>>>>> based in a ID [TARGET_ID] field.
>>>>>
>>>>> Any idea will be very welcome.
>>>>>
>>>>> Formal class 'SpatialPointsDataFrame' [package "sp"] with 5 slots
>>>>>   ..@ data       :'data.frame': 28 obs. of  8 variables:
>>>>>   .. ..$ ID        : int [1:28] 462964 462990 463015 463034 463052 463069
>>>>> 463083 463102 463122 463144 ...
>>>>>   .. ..$ TIME_STAMP: POSIXlt[1:28], format: "2009-07-26 09:00:07"
>>>>> "2009-07-26 09:00:13" "2009-07-26 09:00:19" "2009-07-26 09:00:25" ...
>>>>>   .. ..$ DAY_PERIOD: int [1:28] 1 1 1 1 1 1 1 1 1 1 ...
>>>>>   .. ..$ SEASON    : int [1:28] 2 2 2 2 2 2 2 2 2 2 ...
>>>>>   .. ..$ TARGET_ID : int [1:28] 108426 108426 108426 108426 108426 108426
>>>>> 108426 108426 108426 108426 ...
>>>>>   .. ..$ SPEED     : num [1:28] 0.283 0.6 0.4 0.2 0.2 ...
>>>>>   .. ..$ HEADING   : int [1:28] 134 1 179 179 179 271 123 179 179 90 ...
>>>>>   .. ..$ DISTANCE  : num [1:28] 1.41 3 2 1 1 ...
>>>>>   ..@ coords.nrs : int [1:2] 7 6
>>>>>   ..@ coords     : num [1:28, 1:2] -8.71 -8.71 -8.71 -8.71 -8.71 ...
>>>>>   .. ..- attr(*, "dimnames")=List of 2
>>>>>   .. .. ..$ : NULL
>>>>>   .. .. ..$ : chr [1:2] "LONGITUDE" "LATITUDE"
>>>>>   ..@ bbox       : num [1:2, 1:2] -8.82 38.73 -8.69 38.8
>>>>>   .. ..- attr(*, "dimnames")=List of 2
>>>>>   .. .. ..$ : chr [1:2] "LONGITUDE" "LATITUDE"
>>>>>   .. .. ..$ : chr [1:2] "min" "max"
>>>>>   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>>>>>   .. .. ..@ projargs: chr " +init=epsg:4326 +proj=longlat +ellps=WGS84
>>>>> +datum=WGS84 +no_defs +towgs84=0,0,0"
>>>>>
>>>>>
>>>>> Paulo Eduardo Cardoso
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>> --
>>>> Edzer Pebesma
>>>> Institute for Geoinformatics (ifgi), University of M?nster
>>>> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
>>>> 8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
>>>> http://www.52north.org/geostatistics      e.pebesma at wwu.de
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>
>>

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From edzer.pebesma at uni-muenster.de  Thu May 27 15:26:07 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 27 May 2010 15:26:07 +0200
Subject: [R-sig-Geo] Better print method for Spatial*DataFrames?
In-Reply-To: <AANLkTikrtxVdCpwymXAws7B_aa82CcsUVh4ENNyLj3Mx@mail.gmail.com>
References: <AANLkTikrtxVdCpwymXAws7B_aa82CcsUVh4ENNyLj3Mx@mail.gmail.com>
Message-ID: <4BFE72EF.9070108@uni-muenster.de>

Nice suggestion! I did this for points (committed to cvs), as option in
print, and get

> options(width=60)
> print(meuse[1:3,], sWKT=T)
              geometry cadmium copper lead zinc  elev
1 POINT(333611 181072)    11.7     85  299 1022 7.909
2 POINT(333558 181025)     8.6     81  277 1141 6.983
3 POINT(333537 181165)     6.5     68  199  640 7.800
        dist   om ffreq soil lime landuse dist.m
1 0.00135803 13.6     1    1    1      Ah     50
2 0.01222430 14.0     1    1    1      Ah     30
3 0.10302900 13.0     1    1    1      Ah    150

For (multi)lines / polygons, would it be useful to print the first
coordinate followed by ..., so that some kind of identification is possible?

On 05/18/2010 05:04 PM, Barry Rowlingson wrote:
> Currently if I print a spatial polygon data frame I get the list
> representation, which almost always scrolls way of the screen as giant
> lists of lists of coordinates whizz past. It's nearly always useless
> and luckily ESS lets me C-c C-o and zap the output. For
> SpatialPointsDF you get:
> 
>         coordinates letters LETTERS
> 1    (1, 0.0486677)       a       A
> 2     (2, 0.520911)       b       B
> 3     (3, 0.207873)       c       C
> 4     (4, 0.466571)       d       D
> 
> - for spatial polys and lines would it be better to have such a
> compact representation as the default print? I'd rather use the word
> 'geometry' and have it print as a (truncated) pseudo-WKT, something
> like:
> 
>      geometry letters LETTERS
> 1   POINT(1  0.0486677)       a       A
> 2   POINT(2  0.520911)       b       B
> 
>  for points, and:
> 
>      geometry letters LETTERS
> 1   LINESTRING(...)       a       A
> 
>  for lines, and:
> 
>      geometry letters LETTERS
> 1  POLYGON(...)       a       A
> 
>  for polygons. Or MULTIPOLYGON, whichever is appropriate. I think it
> should literally print dot-dot-dot, since for anything other than
> points its going to be voluminous.
> 
> Today I am a random idea factory...
> 
> Barry
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From burtonshank at gmail.com  Thu May 27 16:32:53 2010
From: burtonshank at gmail.com (Burton Shank)
Date: Thu, 27 May 2010 10:32:53 -0400
Subject: [R-sig-Geo] reading HDF 4 files into R
Message-ID: <AANLkTimD7yHkL1ZBx7CidPW_ACHwOYznek7DRQ-nO1UR@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100527/3011a60c/attachment.pl>

From Roger.Bivand at nhh.no  Thu May 27 16:49:29 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 27 May 2010 16:49:29 +0200 (CEST)
Subject: [R-sig-Geo] reading HDF 4 files into R
In-Reply-To: <AANLkTimD7yHkL1ZBx7CidPW_ACHwOYznek7DRQ-nO1UR@mail.gmail.com>
References: <AANLkTimD7yHkL1ZBx7CidPW_ACHwOYznek7DRQ-nO1UR@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1005271638390.6596@reclus.nhh.no>

On Thu, 27 May 2010, Burton Shank wrote:

> Hi all,
>
> We're trying to process large amounts of remote-sensing data currently
> stored in hdf v4 formats.  I expect there may be a simple way to read these
> files directly into R (ideally as a spatial pixels data frame) but can't
> find the right function.  It seems that it may be possible to use readGDAL
> or readOGR but I can't find an appropriate syntax in the documentation.
>
> Most people seem to pre-process these files into an hdf_5 or netDCS before
> importing, and this would be acceptable except we're looking to process
> hundreds of files and would rather avoid learning another scripting language
> just for batch pre-processing.  Are there any freeware programs that can
> easily perform such batch-processing?
>
> For a sample file, go to
> http://oceandata.sci.gsfc.nasa.gov/SeaWiFS/Mapped/8Day/chlor/1997/
> download any .bz2 file and unzip.
>
> The unzipped files are in hd_4 format, though they don't have any file
> extension (.hdf or .h4).

On a platform with GDAL built with the HDF4 driver, rgdal would cover 
this, with some requirements with regard to the organisation of the data. 
If the driver is not available, you could batch-convert to one of the 
drivers that are available for rgdal for that platform. Since you do not 
state your platform, I assume it is Windows. There, using for example an 
OSGEO4W build of GDAL will probably include HDF4, but the Windows 32/64 
bit builds of GDAL shipped with binary rgdal do not. So from R you would 
use system() to call gdal_translate to get from HDF4 to say GTiff. On a 
platform where you build your own GDAL, then install rgdal from source, 
you should have the driver there for you:

http://www.gdal.org/frmt_hdf4.html

Hope this helps,

Roger

>
> Any assistance is appreciated.
>
> Burton Shank
> Northeast Fisheries Science Center
> Woods Hole, MA
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From wade.wall at gmail.com  Thu May 27 19:15:48 2010
From: wade.wall at gmail.com (Wade Wall)
Date: Thu, 27 May 2010 13:15:48 -0400
Subject: [R-sig-Geo] reading KML files in R
Message-ID: <AANLkTikCyNsNdJk9lPGYYzOSfiDJCJ_VY1y7ey9kQKsh@mail.gmail.com>

Hi all,

Does anyone have experience reading and writing KML files in R?  I
have seen several threads that seem to suggest that it is difficult if
not impossible, but it is convenient to use KML files when working
with Google Earth and inconvenient to read and write shapefiles and
then convert to KML using other software.

If anyone is able to read and write KML files, if they could provide a
description of how to do it, I am sure a lot of people would
appreciate it.  I have tried to do so under both Windows and Linux to
no avail.  The Windows approach looks more difficult, judging by the
readme file associated with rgdal.

Thanks,

Wade


From reeves at nceas.ucsb.edu  Thu May 27 19:55:42 2010
From: reeves at nceas.ucsb.edu (rick reeves)
Date: Thu, 27 May 2010 10:55:42 -0700
Subject: [R-sig-Geo] reading KML files in R
In-Reply-To: <AANLkTikCyNsNdJk9lPGYYzOSfiDJCJ_VY1y7ey9kQKsh@mail.gmail.com>
References: <AANLkTikCyNsNdJk9lPGYYzOSfiDJCJ_VY1y7ey9kQKsh@mail.gmail.com>
Message-ID: <4BFEB21E.50703@nceas.ucsb.edu>

Hi Wade:

I recently assembled the following example, which might help you:


http://www.nceas.ucsb.edu/scicomp/usecases/shapeFileToKML

Regards,
Rick R

On 5/27/2010 10:15 AM, Wade Wall wrote:
> Hi all,
>
> Does anyone have experience reading and writing KML files in R?  I
> have seen several threads that seem to suggest that it is difficult if
> not impossible, but it is convenient to use KML files when working
> with Google Earth and inconvenient to read and write shapefiles and
> then convert to KML using other software.
>
> If anyone is able to read and write KML files, if they could provide a
> description of how to do it, I am sure a lot of people would
> appreciate it.  I have tried to do so under both Windows and Linux to
> no avail.  The Windows approach looks more difficult, judging by the
> readme file associated with rgdal.
>
> Thanks,
>
> Wade
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>    


-- 
Rick Reeves
Scientific Programmer/Analyst and Data Manager
National Center for Ecological Analysis and Synthesis
UC Santa Barbara
www.nceas.ucsb.edu
805 892 2533


From reeves at nceas.ucsb.edu  Thu May 27 20:01:08 2010
From: reeves at nceas.ucsb.edu (rick reeves)
Date: Thu, 27 May 2010 11:01:08 -0700
Subject: [R-sig-Geo] reading KML files in R
In-Reply-To: <AANLkTikCyNsNdJk9lPGYYzOSfiDJCJ_VY1y7ey9kQKsh@mail.gmail.com>
References: <AANLkTikCyNsNdJk9lPGYYzOSfiDJCJ_VY1y7ey9kQKsh@mail.gmail.com>
Message-ID: <4BFEB364.1080906@nceas.ucsb.edu>

I do note that the example I provided does not demonstrate how to READ a KML
file into R. But, SOON, I plan to modify the example to demonstrate 
reading of KMLs
into some R-compatible format.

RR

On 5/27/2010 10:15 AM, Wade Wall wrote:
> Hi all,
>
> Does anyone have experience reading and writing KML files in R?  I
> have seen several threads that seem to suggest that it is difficult if
> not impossible, but it is convenient to use KML files when working
> with Google Earth and inconvenient to read and write shapefiles and
> then convert to KML using other software.
>
> If anyone is able to read and write KML files, if they could provide a
> description of how to do it, I am sure a lot of people would
> appreciate it.  I have tried to do so under both Windows and Linux to
> no avail.  The Windows approach looks more difficult, judging by the
> readme file associated with rgdal.
>
> Thanks,
>
> Wade
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>    


-- 
Rick Reeves
Scientific Programmer/Analyst and Data Manager
National Center for Ecological Analysis and Synthesis
UC Santa Barbara
www.nceas.ucsb.edu
805 892 2533


From Roger.Bivand at nhh.no  Thu May 27 20:15:33 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 27 May 2010 20:15:33 +0200 (CEST)
Subject: [R-sig-Geo] reading KML files in R
In-Reply-To: <4BFEB364.1080906@nceas.ucsb.edu>
References: <AANLkTikCyNsNdJk9lPGYYzOSfiDJCJ_VY1y7ey9kQKsh@mail.gmail.com>
	<4BFEB364.1080906@nceas.ucsb.edu>
Message-ID: <alpine.LRH.2.00.1005272014000.7056@reclus.nhh.no>

On Thu, 27 May 2010, rick reeves wrote:

> I do note that the example I provided does not demonstrate how to READ a KML
> file into R. But, SOON, I plan to modify the example to demonstrate reading 
> of KMLs
> into some R-compatible format.

readOGR() does read KML files, but you do have to identify the correct 
layer name - see:

http://www.gdal.org/ogr/drv_kml.html

Roger

>
> RR
>
> On 5/27/2010 10:15 AM, Wade Wall wrote:
>> Hi all,
>> 
>> Does anyone have experience reading and writing KML files in R?  I
>> have seen several threads that seem to suggest that it is difficult if
>> not impossible, but it is convenient to use KML files when working
>> with Google Earth and inconvenient to read and write shapefiles and
>> then convert to KML using other software.
>> 
>> If anyone is able to read and write KML files, if they could provide a
>> description of how to do it, I am sure a lot of people would
>> appreciate it.  I have tried to do so under both Windows and Linux to
>> no avail.  The Windows approach looks more difficult, judging by the
>> readme file associated with rgdal.
>> 
>> Thanks,
>> 
>> Wade
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> 
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From wade.wall at gmail.com  Thu May 27 20:52:43 2010
From: wade.wall at gmail.com (Wade Wall)
Date: Thu, 27 May 2010 14:52:43 -0400
Subject: [R-sig-Geo] reading KML files in R
In-Reply-To: <alpine.LRH.2.00.1005272014000.7056@reclus.nhh.no>
References: <AANLkTikCyNsNdJk9lPGYYzOSfiDJCJ_VY1y7ey9kQKsh@mail.gmail.com>
	<4BFEB364.1080906@nceas.ucsb.edu>
	<alpine.LRH.2.00.1005272014000.7056@reclus.nhh.no>
Message-ID: <AANLkTin3jgggXJlgHl7qqdRrZd2zcQINWgRSjJLCB0Ft@mail.gmail.com>

I am not exactly sure what you mean by identify the correct layer
name.  Using R under Linux, this is what happens.

I have a file in the current directory named ASMI_GA.kml

library(rgdal)
tmp<-readOGR(".", layer="ASMI_GA.kml")

However, I get the following message.

Error in ogrInfo(dsn = dsn, layer = layer, input_field_name_encoding =
input_field_name_encoding) :
  Cannot open file

I have expat XML parser installed and gdal.  This probably sounds
rather stupid, but I am not sure what the following means in the link
that Dr. Bivand provided: "KML reading is only available if GDAL/OGR
is built with the Expat XML Parser, otherwise only KML writing will be
supported."  I installed both as debian packages (using get-apt).
Should I install both from source code, Expat XML Parser first and
then GDAL?

Sorry if I seem dense here, but it is not real clear to me.  Also,
even though this may be beyond the scope of R-sig-geo, I think that
other people are also struggling with this.

Thanks for any help.

Wade


On Thu, May 27, 2010 at 2:15 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Thu, 27 May 2010, rick reeves wrote:
>
>> I do note that the example I provided does not demonstrate how to READ a
>> KML
>> file into R. But, SOON, I plan to modify the example to demonstrate
>> reading of KMLs
>> into some R-compatible format.
>
> readOGR() does read KML files, but you do have to identify the correct layer
> name - see:
>
> http://www.gdal.org/ogr/drv_kml.html
>
> Roger
>
>>
>> RR
>>
>> On 5/27/2010 10:15 AM, Wade Wall wrote:
>>>
>>> Hi all,
>>>
>>> Does anyone have experience reading and writing KML files in R? ?I
>>> have seen several threads that seem to suggest that it is difficult if
>>> not impossible, but it is convenient to use KML files when working
>>> with Google Earth and inconvenient to read and write shapefiles and
>>> then convert to KML using other software.
>>>
>>> If anyone is able to read and write KML files, if they could provide a
>>> description of how to do it, I am sure a lot of people would
>>> appreciate it. ?I have tried to do so under both Windows and Linux to
>>> no avail. ?The Windows approach looks more difficult, judging by the
>>> readme file associated with rgdal.
>>>
>>> Thanks,
>>>
>>> Wade
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>
>>
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>


From Nathan.Odgers at mail.wvu.edu  Thu May 27 22:34:09 2010
From: Nathan.Odgers at mail.wvu.edu (Nathan Odgers)
Date: Thu, 27 May 2010 16:34:09 -0400
Subject: [R-sig-Geo] RSAGA multi.focal.function
Message-ID: <4BFE9F010200005C0005722B@WVUGW01.wvu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100527/80d6a9e1/attachment.pl>

From Jan.Quets at ua.ac.be  Thu May 27 22:53:08 2010
From: Jan.Quets at ua.ac.be (Quets Jan)
Date: Thu, 27 May 2010 22:53:08 +0200
Subject: [R-sig-Geo] existance of a specific non-overlapping marked spatial
	model in spatstat or other R package?
Message-ID: <7D403BF1018E6D4882ADD0F77E35BC5C15956A@xmail06.ad.ua.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100527/f0e5bbe0/attachment.pl>

From r.turner at auckland.ac.nz  Fri May 28 00:00:35 2010
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 28 May 2010 10:00:35 +1200
Subject: [R-sig-Geo] existance of a specific non-overlapping marked
	spatial model in spatstat or other R package?
In-Reply-To: <7D403BF1018E6D4882ADD0F77E35BC5C15956A@xmail06.ad.ua.ac.be>
References: <7D403BF1018E6D4882ADD0F77E35BC5C15956A@xmail06.ad.ua.ac.be>
Message-ID: <B9268B92-B6F4-420C-AF04-EEE1DA182F67@auckland.ac.nz>


On 28/05/2010, at 8:53 AM, Quets Jan wrote:

> 
> Hi,
> 
> I am looking for a specific non-overlapping marked spatial model for use as a null model for monte carle simulations with use of the 'envelope' function in spatstat.
> 
> the specific marked spatial model should:
> -----------------
> *generate a spatial random pattern with a predetermined number of points (with conditions set below)
> 
> *each point should be assigned a mark randomly out of a predetermined set of marks
> 
> *these marks represent the radia of circular discs which should be drawn around these points (which act as centres)
> 
> *no discs should overlap
> -----------------
> 
> Does anybody has knowledge of a such a built in model in spatstat or another R package?
> 
> For now, I have built this model by myself, but it turns out to have a very time-consuming running time, especially when used as a null model in a monte carlo simulation. Also I have multiple monte carlo simulations to perform.
> 
> It will be of great help,

The only way I can think of doing this is sequentially.  I.e. select a radius,
then repetitively select a point to add, rejecting the selected point if its
circle (with the chosen radius) intersects any of the existing circles.  If
after ``giveup'' attempts the function has failed to find an acceptable point,
it gives up (and throws an error).

I cobbled together some code to effect this; it took one minute of user time
to do 100 replications of choosing 100 points with non-overlapping circles
in the unit square, with the radii selected uniform-randomly from (1:5)/100
and giveup=1000.

I believe that it would require a lot of work and great cleverness to get
anything substantially faster.  Of course, I could be wrong --- I was once,
back in 1968 when I thought I'd made a mistake and I hadn't. :-)

	cheers,

		Rolf Turner

P. S.  Let me know if you want my code.  I suspect it's not much different
from what you have built yourself.

		R.
######################################################################
Attention: 
This e-mail message is privileged and confidential. If you are not the 
intended recipient please delete the message and notify the sender. 
Any views or opinions presented are solely those of the author.

This e-mail has been scanned and cleared by MailMarshal 
www.marshalsoftware.com
######################################################################


From greenberg at ucdavis.edu  Fri May 28 00:55:35 2010
From: greenberg at ucdavis.edu (Jonathan Greenberg)
Date: Thu, 27 May 2010 15:55:35 -0700
Subject: [R-sig-Geo] Extracting a z-subset from a rasterStack object
Message-ID: <AANLkTik8Gg-AzMpsIlxfgtJk38Y93s9aFldlDyJjUp7e@mail.gmail.com>

I'm thinking I'm missing something obvious -- if I want to make a new
raster stack which is a subset of another raster stack, how do I go
about doing this?  Neither of these worked:

data_sub=stack(data_stack,bands=c(10,20))
data_sub=stack(data_stack,index=c(10,20))

data_stack is a rasterStack of 1500 layers...

Thanks!

--j


From r.hijmans at gmail.com  Fri May 28 03:09:18 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 27 May 2010 18:09:18 -0700
Subject: [R-sig-Geo] Extracting a z-subset from a rasterStack object
In-Reply-To: <AANLkTik8Gg-AzMpsIlxfgtJk38Y93s9aFldlDyJjUp7e@mail.gmail.com>
References: <AANLkTik8Gg-AzMpsIlxfgtJk38Y93s9aFldlDyJjUp7e@mail.gmail.com>
Message-ID: <AANLkTimHOpVVL9UoU0-O4qZnyUfmGxbX_F3Zf4mwGXDv@mail.gmail.com>

Hi Jonathan,

You can do it by accessing the layers slot:

data_sub=stack( data_stack at layers[10:20] )

But I like better what you tried to do, and will implement that.

Robert


On Thu, May 27, 2010 at 3:55 PM, Jonathan Greenberg
<greenberg at ucdavis.edu> wrote:
> I'm thinking I'm missing something obvious -- if I want to make a new
> raster stack which is a subset of another raster stack, how do I go
> about doing this? ?Neither of these worked:
>
> data_sub=stack(data_stack,bands=c(10,20))
> data_sub=stack(data_stack,index=c(10,20))
>
> data_stack is a rasterStack of 1500 layers...
>
> Thanks!
>
> --j
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From Roger.Bivand at nhh.no  Fri May 28 09:29:46 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 28 May 2010 09:29:46 +0200 (CEST)
Subject: [R-sig-Geo] reading KML files in R
In-Reply-To: <AANLkTin3jgggXJlgHl7qqdRrZd2zcQINWgRSjJLCB0Ft@mail.gmail.com>
References: <AANLkTikCyNsNdJk9lPGYYzOSfiDJCJ_VY1y7ey9kQKsh@mail.gmail.com>
	<4BFEB364.1080906@nceas.ucsb.edu>
	<alpine.LRH.2.00.1005272014000.7056@reclus.nhh.no>
	<AANLkTin3jgggXJlgHl7qqdRrZd2zcQINWgRSjJLCB0Ft@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1005280908320.9550@reclus.nhh.no>

On Thu, 27 May 2010, Wade Wall wrote:

> I am not exactly sure what you mean by identify the correct layer
> name.  Using R under Linux, this is what happens.
>
> I have a file in the current directory named ASMI_GA.kml
>
> library(rgdal)
> tmp<-readOGR(".", layer="ASMI_GA.kml")
>
> However, I get the following message.
>
> Error in ogrInfo(dsn = dsn, layer = layer, input_field_name_encoding =
> input_field_name_encoding) :
>  Cannot open file

That is what I said. Each driver has its own understanding of what the 
dsn= and layer= arguments are, and your usage doesn't match what the 
driver is expecting. The dsn= for the KML driver seems to be the file name 
(possibly with its complete path), and the layer= is the string in the:

<Document><Folder><name>cities</name>

line (conditional on the writing software using a similar logic to OGR), 
here in this example:

library(rgdal)
cities <- readOGR(system.file("vectors", package = "rgdal")[1], "cities")
is.na(cities$POPULATION) <- cities$POPULATION == -99
summary(cities$POPULATION)
td <- tempdir()
writeOGR(cities, paste(td, "cities.kml", sep="/"), "cities", driver="KML")
xx <- readOGR(paste(td, "cities.kml", sep="/"), "cities")

How one discovers this name is not obvious, since the KML driver in OGR 
needs it to access the file. One possibility is:

system(paste("ogrinfo", paste(td, "cities.kml", sep="/")), intern=TRUE)

which lists the layer name(s). Perhaps ogrInfo() could be revised to 
access the dsn in the same way when not given a layer= argument to 
discover layer names - anyone with lots of time on their hands like to 
help?

Roger

PS. ogrDrivers() lists the drivers seen by OGR as running in rgdal, but 
for drivers with write but not read capability, it cannot distinguish. In 
that case, you only find out if a read driver is present and has its 
external dependencies properly satisfied by using it, I'm afraid. The 
example above will show whether your rgdal/GDAL/Expat do work or not.

>
> I have expat XML parser installed and gdal.  This probably sounds
> rather stupid, but I am not sure what the following means in the link
> that Dr. Bivand provided: "KML reading is only available if GDAL/OGR
> is built with the Expat XML Parser, otherwise only KML writing will be
> supported."  I installed both as debian packages (using get-apt).
> Should I install both from source code, Expat XML Parser first and
> then GDAL?
>
> Sorry if I seem dense here, but it is not real clear to me.  Also,
> even though this may be beyond the scope of R-sig-geo, I think that
> other people are also struggling with this.
>
> Thanks for any help.
>
> Wade
>
>
> On Thu, May 27, 2010 at 2:15 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> On Thu, 27 May 2010, rick reeves wrote:
>>
>>> I do note that the example I provided does not demonstrate how to READ a
>>> KML
>>> file into R. But, SOON, I plan to modify the example to demonstrate
>>> reading of KMLs
>>> into some R-compatible format.
>>
>> readOGR() does read KML files, but you do have to identify the correct layer
>> name - see:
>>
>> http://www.gdal.org/ogr/drv_kml.html
>>
>> Roger
>>
>>>
>>> RR
>>>
>>> On 5/27/2010 10:15 AM, Wade Wall wrote:
>>>>
>>>> Hi all,
>>>>
>>>> Does anyone have experience reading and writing KML files in R? ?I
>>>> have seen several threads that seem to suggest that it is difficult if
>>>> not impossible, but it is convenient to use KML files when working
>>>> with Google Earth and inconvenient to read and write shapefiles and
>>>> then convert to KML using other software.
>>>>
>>>> If anyone is able to read and write KML files, if they could provide a
>>>> description of how to do it, I am sure a lot of people would
>>>> appreciate it. ?I have tried to do so under both Windows and Linux to
>>>> no avail. ?The Windows approach looks more difficult, judging by the
>>>> readme file associated with rgdal.
>>>>
>>>> Thanks,
>>>>
>>>> Wade
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>
>>>
>>>
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From R.Catarino at MARLAB.AC.UK  Fri May 28 10:58:06 2010
From: R.Catarino at MARLAB.AC.UK (Rui Catarino)
Date: Fri, 28 May 2010 09:58:06 +0100
Subject: [R-sig-Geo] from R to ArcMap
Message-ID: <A0F8DAFB525DED4ABAF6841BB11C5812044E7E73@mail4.marlab.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100528/a23646ad/attachment.pl>

From Adrian.Baddeley at csiro.au  Fri May 28 13:40:37 2010
From: Adrian.Baddeley at csiro.au (Adrian.Baddeley at csiro.au)
Date: Fri, 28 May 2010 19:40:37 +0800
Subject: [R-sig-Geo] circular holes in rectangular polygon
Message-ID: <57DC18C299094D4299F837570C5DF1C52B1433680D@EXWA-MBX01.nexus.csiro.au>

Jan Quets Jan.Quets at ua.ac.be writes:

> I want to make a rectangular window with circular holes within.
> I have tried and searched but not found a solution yet.

library(spatstat)
R <- owin(c(0,4),c(0,5))
O <- disc(radius=1, centre=c(2, 3))
W <- complement.owin(O, frame=R)
plot(W)

From Adrian.Baddeley at csiro.au  Fri May 28 14:04:16 2010
From: Adrian.Baddeley at csiro.au (Adrian.Baddeley at csiro.au)
Date: Fri, 28 May 2010 20:04:16 +0800
Subject: [R-sig-Geo] existance of a specific non-overlapping marked
 spatial model in spatstat or other R package?
Message-ID: <57DC18C299094D4299F837570C5DF1C52B1433680E@EXWA-MBX01.nexus.csiro.au>

Jan Quets <Jan.Quets at ua.ac.be> writes:

> I am looking for a specific non-overlapping marked spatial model for use as a null model 
> for monte carle simulations with use of the 'envelope' function in spatstat.
> the specific marked spatial model should:
> *generate a spatial random pattern with a predetermined number of points (with conditions set below)
> *each point should be assigned a mark randomly out of a predetermined set of marks
> *these marks represent the radia of circular discs which should be drawn around these points 
>   (which act as centres)
>  *no discs should overlap

If the 'predetermined set of marks' is a finite set of radii, then this is a special case of the multitype Strauss process, where you set the interaction distance between mark r1 and mark r2 to be r1+r2, and the interaction parameters gamma are all equal to zero. 

Suppose 'rvals' is a vector containing the desired radii, 'W' is the simulation window and 'b' is the base intensity. Then do
        m <- length(rvals)
        types <- 1:m
        rmat <- outer(rvals, rvals, "+")
        gmat <- matrix(0, m, m)
        mod <- rmhmodel(cif="straussm", par=list(beta=rep(b, m), gamma=gmat, radii=rmat), w=W)
This defines the model. Then if you want simulations of exactly k points, 
        sta <- rmhstart(n.start=k)
        con <- rmhcontrol(p=1)
If you now call
        X <- rmh(mod, sta, con)
you'll get a multitype point pattern with marks 1:m where mark j corresponds to radius rvals[j]. If you need to convert this to a marked point pattern with the radii as the marks, do something like
       marks(X) <- rvals[marks(X)]
To use this in envelope(), set
         mapmarks <- function(X, v=rvals) { marks(X) <- v[marks(X)]; return(X) }
         expr <- expression(mapmarks(rmh(mod, sta, con)))
then call
       envelope(....... simulate=expr)


If the 'predetermined set of marks' is a continuous range of radii, then there does exist some code to do this, but it is not yet released in spatstat.

Adrian Baddeley

From clelia.bilodeau at gmail.com  Fri May 28 15:59:03 2010
From: clelia.bilodeau at gmail.com (=?ISO-8859-1?Q?Cl=E9lia_Bilodeau?=)
Date: Fri, 28 May 2010 15:59:03 +0200
Subject: [R-sig-Geo] Elevation histogram for each region
In-Reply-To: <AANLkTinhCwvIKHd9d9xyoJW9EA90pDQEmQR47JwJc57r@mail.gmail.com>
References: <AANLkTil_cmNeY6WTeNQizAdCzPO4jZWn1wENrWjVAC25@mail.gmail.com>
	<AANLkTinhCwvIKHd9d9xyoJW9EA90pDQEmQR47JwJc57r@mail.gmail.com>
Message-ID: <AANLkTikK9jd0hUvuSTcolXhirVF3Wh8hFh5te-qiBMfz@mail.gmail.com>

Thank you for your help.
I'm still working on it.
I think the use of polygonValues is a good idea, but the script:

library(raster)
lst = list()
for (i in 1:nzones) {
p <- polygonValues(pol,r, fun=function(x){x==i})
lst[[i]] = histogram(p[,3])
}
doesn't work yet.
Do I have to define a function to use in "fun=function(x)(x==1)"?

Thank you.
C.


2010/5/26 Robert J. Hijmans <r.hijmans at gmail.com>:
> Cl?lia,
>
> The optimal solution would depend a bit on your data. If the regions
> are not too large, you could loop over the zones
>
> library(raster)
> lst = list()
> for (i in 1:nzones) {
> ?p <- rasterToPoints(r, fun=function(x){x==i})
> ?lst[[i]] = histogram(p[,3])
> }
>
> If you also have the zones as polygons you could alternatively look
> over the polygons and use ?polygonValues in stead of rasterToPoints
>
> Another, more elaborate, option could be to, in your loop, reclassify
> the regions raster (1 / 0 ), multiply that with the elevation data;
> trim the output raster, make a histogram (set maxpixels to
> ncell(raster)) (this may take a long time to finish)
>
> You could also first aggregate the rasters; unless you care much about
> the extreme values.
>
> Hope this helps,
> Robert
>
>
> On Wed, May 26, 2010 at 2:08 AM, Cl?lia Bilodeau
> <clelia.bilodeau at gmail.com> wrote:
>> Dear list,
>>
>> I have two rasters, one is a Digital Elevation Model, and the other is
>> a region file.
>> I am looking for a method that allows me to plot the elevation
>> histogram or density for each region.
>>
>> My first try was to do this with a function and to use "Zonal" from
>> the "raster" package, but I have a very large file, so I have this
>> error:
>> "RasterLayers are too large. You can use fun='sum', 'mean', 'min', or
>> 'max', but not a function"
>>
>> Is there another way to do this?
>>
>> Thank you.
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From etiennebr at gmail.com  Fri May 28 16:47:05 2010
From: etiennebr at gmail.com (Etienne Bellemare Racine)
Date: Fri, 28 May 2010 10:47:05 -0400
Subject: [R-sig-Geo] Better print method for Spatial*DataFrames?
In-Reply-To: <4BFE72EF.9070108@uni-muenster.de>
References: <AANLkTikrtxVdCpwymXAws7B_aa82CcsUVh4ENNyLj3Mx@mail.gmail.com>
	<4BFE72EF.9070108@uni-muenster.de>
Message-ID: <4BFFD769.1010906@gmail.com>

I taught I could add my two cents.
> Nice suggestion!
I agree !
>> options(width=60)
>> print(meuse[1:3,], sWKT=T)
>>      
I don't know what's sWKT, but the folowing output is the kind of 
printing I would like by default. Sometimes I make the mistake of 
printing a spatial polygon data frame and it can take literally 5 
minutes to output. So if it could just be the default, I'd be happy.
>                geometry cadmium copper lead zinc  elev
> 1 POINT(333611 181072)    11.7     85  299 1022 7.909
> 2 POINT(333558 181025)     8.6     81  277 1141 6.983
> 3 POINT(333537 181165)     6.5     68  199  640 7.800
>          dist   om ffreq soil lime landuse dist.m
> 1 0.00135803 13.6     1    1    1      Ah     50
> 2 0.01222430 14.0     1    1    1      Ah     30
> 3 0.10302900 13.0     1    1    1      Ah    150
>
> For (multi)lines / polygons, would it be useful to print the first
> coordinate followed by ..., so that some kind of identification is possible?
>
>    
I think it's a good idea, but long output are always a pain to read. So 
I suggest someting compact. Maybe there could be kind of an offset 
before the display. So if you had like

POINT(349600.8 5387597)
POINT(349597.0 5387597)
POINT(349590.4 5387595)
POINT(349569.9 5387591)
POINT(349557.1 5387586)
POINT(349548.5 5387581)
POINT(349542.9 5387575)
...
Maybe it could print the coordinates as
349000+  5387500+
POINT(600.8 97)
POINT(597.0 97)
POINT(590.4 95)
POINT(569.9 91)
POINT(557.1 86)
POINT(548.5 81)
POINT(542.9 75)
...
Maybe the coordinate to display should be the "labpt" slot ? I think for 
a matter of identification someting compact is much more useful.
Talking about compactness, as I don't know of any way to put many 
geometry types in one class spatial*dataframe, is it necessary to repeat 
POINT, or (MULTI)LINE, or POLYGON ? Would it be possible to only display 
(random thaught here) P, M, L, Y? or S for surface ? I don't know. I 
like compactness !

Also, is it possible to add the same identifier (coordinate) to View() ?

Etienne


From nikko at hailmail.net  Fri May 28 17:51:16 2010
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Fri, 28 May 2010 08:51:16 -0700
Subject: [R-sig-Geo] existance of a specific non-overlapping marked
 spatial model in spatstat or other R package?
In-Reply-To: <mailman.7.1275040802.4587.r-sig-geo@stat.math.ethz.ch>
References: <mailman.7.1275040802.4587.r-sig-geo@stat.math.ethz.ch>
Message-ID: <1275061876.24727.1377394997@webmail.messagingengine.com>

Hi,
I don't think the code exists, but I think that there are modifications
of the 
algorithm Rolf described that may be much faster. I assume the
predetermined
set of marks is a set of distinct classes with different radii. 
One thing that comes to mind is you may want to generate the marks first
and
then assign locations. So if you allocate the largest radii first, you
may be able to
sequentially eliminate whole regions of the space where the next disk
could be allocated
using a quad tree, and there by do fewer rejections of locations. There
may be some
divide and conquer type strategies that work as well. 

Thinking about this more, it seems like the most time consuming step
would be the 
acceptance/rejection of new locations because of the search for adjacent
intersecting discs.
So as the plane fills up there will be more and more rejections, and the
search time will increase. 
In fact for a finite area, there will be an upper bound on the number of
points depending on
the distribution of marks. Which suggest that one would want to first
generate the marks, and check that the
sum of the disks is less than the total area of your region.

So as I am musing here, and probably getting less and less helpful, I am
thinking that 
using the delaunay triangulation or the nearest neighbor graph might
help speed up the search.
I am also wondering if one could condition on the existing points more
efficiently, may
be using some sort of metropolis hastings type algorithm to ensure that
the next draw
is closer to the restricted space available. I am even guessing there
may be some percolation
model that would approximate this process and be faster to generate.

Ok used up my 2c. Hope this helps

Nicholas
 

   

> Date: Fri, 28 May 2010 10:00:35 +1200
> From: Rolf Turner <r.turner at auckland.ac.nz>
> To: Quets Jan <Jan.Quets at ua.ac.be>
> Cc: "r-sig-geo at stat.math.ethz.ch" <r-sig-geo at stat.math.ethz.ch>
> Subject: Re: [R-sig-Geo] existance of a specific non-overlapping
> 	marked	spatial model in spatstat or other R package?
> Message-ID: <B9268B92-B6F4-420C-AF04-EEE1DA182F67 at auckland.ac.nz>
> Content-Type: text/plain; charset="us-ascii"
> 
> 
> On 28/05/2010, at 8:53 AM, Quets Jan wrote:
> 
> > 
> > Hi,
> > 
> > I am looking for a specific non-overlapping marked spatial model for use as a null model for monte carle simulations with use of the 'envelope' function in spatstat.
> > 
> > the specific marked spatial model should:
> > -----------------
> > *generate a spatial random pattern with a predetermined number of points (with conditions set below)
> > 
> > *each point should be assigned a mark randomly out of a predetermined set of marks
> > 
> > *these marks represent the radia of circular discs which should be drawn around these points (which act as centres)
> > 
> > *no discs should overlap
> > -----------------
> > 
> > Does anybody has knowledge of a such a built in model in spatstat or another R package?
> > 
> > For now, I have built this model by myself, but it turns out to have a very time-consuming running time, especially when used as a null model in a monte carlo simulation. Also I have multiple monte carlo simulations to perform.
> > 
> > It will be of great help,
> 
> The only way I can think of doing this is sequentially.  I.e. select a
> radius,
> then repetitively select a point to add, rejecting the selected point if
> its
> circle (with the chosen radius) intersects any of the existing circles. 
> If
> after ``giveup'' attempts the function has failed to find an acceptable
> point,
> it gives up (and throws an error).
> 
> I cobbled together some code to effect this; it took one minute of user
> time
> to do 100 replications of choosing 100 points with non-overlapping
> circles
> in the unit square, with the radii selected uniform-randomly from
> (1:5)/100
> and giveup=1000.
> 
> I believe that it would require a lot of work and great cleverness to get
> anything substantially faster.  Of course, I could be wrong --- I was
> once,
> back in 1968 when I thought I'd made a mistake and I hadn't. :-)
> 
> 	cheers,
> 
> 		Rolf Turner
> 
> P. S.  Let me know if you want my code.  I suspect it's not much
> different
> from what you have built yourself.
> 
> 		R.
> ######################################################################
> Attention: 
> This e-mail message is privileged and confidential. If you are not the 
> intended recipient please delete the message and notify the sender. 
> Any views or opinions presented are solely those of the author.
> 
> This e-mail has been scanned and cleared by MailMarshal 
> www.marshalsoftware.com
> ######################################################################
> 
>


From Roger.Bivand at nhh.no  Fri May 28 18:18:46 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 28 May 2010 18:18:46 +0200 (CEST)
Subject: [R-sig-Geo] Better print method for Spatial*DataFrames?
In-Reply-To: <4BFFD769.1010906@gmail.com>
References: <AANLkTikrtxVdCpwymXAws7B_aa82CcsUVh4ENNyLj3Mx@mail.gmail.com>
	<4BFE72EF.9070108@uni-muenster.de> <4BFFD769.1010906@gmail.com>
Message-ID: <alpine.LRH.2.00.1005281806580.11964@reclus.nhh.no>

On Fri, 28 May 2010, Etienne Bellemare Racine wrote:

> I taught I could add my two cents.
>> Nice suggestion!
> I agree !

No. Only for SpatialPointDataFrame objects, which is what it does already. 
Please, understand that str() is a *much* better choice in effectively all 
cases where summary() isn't used. For the Spatial* objects, set a 
max.level=2 or similar, and you can *see* what is in it. The proposed 
print() method for a big multiband raster will also run away with you. Do 
str(), not print()!!!

library(maptools)
xx <- readShapeSpatial(system.file("shapes/sids.shp",
  package="maptools")[1], IDvar="FIPSNO",
  proj4string=CRS("+proj=longlat +ellps=clrk66"))
summary(xx)
str(xx, max.level=2)

To avoid having to remember to write max.level=2, could someone contribute 
a generic str() for S4 Spatial*?

Roger

>>> options(width=60)
>>> print(meuse[1:3,], sWKT=T)
>>> 
> I don't know what's sWKT, but the folowing output is the kind of printing I 
> would like by default. Sometimes I make the mistake of printing a spatial 
> polygon data frame and it can take literally 5 minutes to output. So if it 
> could just be the default, I'd be happy.
>>                geometry cadmium copper lead zinc  elev
>> 1 POINT(333611 181072)    11.7     85  299 1022 7.909
>> 2 POINT(333558 181025)     8.6     81  277 1141 6.983
>> 3 POINT(333537 181165)     6.5     68  199  640 7.800
>>          dist   om ffreq soil lime landuse dist.m
>> 1 0.00135803 13.6     1    1    1      Ah     50
>> 2 0.01222430 14.0     1    1    1      Ah     30
>> 3 0.10302900 13.0     1    1    1      Ah    150
>> 
>> For (multi)lines / polygons, would it be useful to print the first
>> coordinate followed by ..., so that some kind of identification is 
>> possible?
>>
>> 
> I think it's a good idea, but long output are always a pain to read. So I 
> suggest someting compact. Maybe there could be kind of an offset before the 
> display. So if you had like
>
> POINT(349600.8 5387597)
> POINT(349597.0 5387597)
> POINT(349590.4 5387595)
> POINT(349569.9 5387591)
> POINT(349557.1 5387586)
> POINT(349548.5 5387581)
> POINT(349542.9 5387575)
> ...
> Maybe it could print the coordinates as
> 349000+  5387500+
> POINT(600.8 97)
> POINT(597.0 97)
> POINT(590.4 95)
> POINT(569.9 91)
> POINT(557.1 86)
> POINT(548.5 81)
> POINT(542.9 75)
> ...
> Maybe the coordinate to display should be the "labpt" slot ? I think for a 
> matter of identification someting compact is much more useful.
> Talking about compactness, as I don't know of any way to put many geometry 
> types in one class spatial*dataframe, is it necessary to repeat POINT, or 
> (MULTI)LINE, or POLYGON ? Would it be possible to only display (random 
> thaught here) P, M, L, Y? or S for surface ? I don't know. I like compactness 
> !
>
> Also, is it possible to add the same identifier (coordinate) to View() ?
>
> Etienne
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From b.rowlingson at lancaster.ac.uk  Fri May 28 18:35:38 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 28 May 2010 17:35:38 +0100
Subject: [R-sig-Geo] Better print method for Spatial*DataFrames?
In-Reply-To: <alpine.LRH.2.00.1005281806580.11964@reclus.nhh.no>
References: <AANLkTikrtxVdCpwymXAws7B_aa82CcsUVh4ENNyLj3Mx@mail.gmail.com>
	<4BFE72EF.9070108@uni-muenster.de> <4BFFD769.1010906@gmail.com>
	<alpine.LRH.2.00.1005281806580.11964@reclus.nhh.no>
Message-ID: <AANLkTik-wte4kJhYhyejdEX-QD3BGD8XxSc1uD51_Ff0@mail.gmail.com>

On Fri, May 28, 2010 at 5:18 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Fri, 28 May 2010, Etienne Bellemare Racine wrote:
>
>> I taught I could add my two cents.
>>>
>>> Nice suggestion!
>>
>> I agree !
>
> No. Only for SpatialPointDataFrame objects, which is what it does already.
> Please, understand that str() is a *much* better choice in effectively all
> cases where summary() isn't used. For the Spatial* objects, set a
> max.level=2 or similar, and you can *see* what is in it. The proposed
> print() method for a big multiband raster will also run away with you. Do
> str(), not print()!!!

 I'm not sure what you're saying 'No' to here, Roger. Neither str(xx)
nor summary(xx) present the object as a data frame. Conceptually its a
data frame where one of the columns is a geometry, and seeing it print
as such is a good thing (imho). I'd like to never have to use xx at data
again!

 I'm not sure trying to truncate the coordinates for nice formatting
is a good idea though, but some indication when printing a
Spatial*DataFrame that its a dataframe with geometries seems a good
idea.

Barry


From nikko at hailmail.net  Fri May 28 19:04:05 2010
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Fri, 28 May 2010 10:04:05 -0700
Subject: [R-sig-Geo] existance of a specific non-overlapping marked
 spatial model in spatstat or other R package?
In-Reply-To: <1275061876.24727.1377394997@webmail.messagingengine.com>
References: <mailman.7.1275040802.4587.r-sig-geo@stat.math.ethz.ch>
	<1275061876.24727.1377394997@webmail.messagingengine.com>
Message-ID: <1275066245.7552.1377411271@webmail.messagingengine.com>

Ok My 2c is going to go up to a quarter. Having discussed this a little
more 
with a colleague, we realized that a sequential approach may not work so
well,
because in a finite region so many configurations would be inadmissible
and and
you would have to reject the whole thing, unless the density of disks 
is sparse. So this really is a yucky problem.

Nicholas 

On Fri, 28 May 2010 08:51 -0700, "Nicholas Lewin-Koh"
<nikko at hailmail.net> wrote:
> Hi,
> I don't think the code exists, but I think that there are modifications
> of the 
> algorithm Rolf described that may be much faster. I assume the
> predetermined
> set of marks is a set of distinct classes with different radii. 
> One thing that comes to mind is you may want to generate the marks first
> and
> then assign locations. So if you allocate the largest radii first, you
> may be able to
> sequentially eliminate whole regions of the space where the next disk
> could be allocated
> using a quad tree, and there by do fewer rejections of locations. There
> may be some
> divide and conquer type strategies that work as well. 
> 
> Thinking about this more, it seems like the most time consuming step
> would be the 
> acceptance/rejection of new locations because of the search for adjacent
> intersecting discs.
> So as the plane fills up there will be more and more rejections, and the
> search time will increase. 
> In fact for a finite area, there will be an upper bound on the number of
> points depending on
> the distribution of marks. Which suggest that one would want to first
> generate the marks, and check that the
> sum of the disks is less than the total area of your region.
> 
> So as I am musing here, and probably getting less and less helpful, I am
> thinking that 
> using the delaunay triangulation or the nearest neighbor graph might
> help speed up the search.
> I am also wondering if one could condition on the existing points more
> efficiently, may
> be using some sort of metropolis hastings type algorithm to ensure that
> the next draw
> is closer to the restricted space available. I am even guessing there
> may be some percolation
> model that would approximate this process and be faster to generate.
> 
> Ok used up my 2c. Hope this helps
> 
> Nicholas
>  
> 
>    
> 
> > Date: Fri, 28 May 2010 10:00:35 +1200
> > From: Rolf Turner <r.turner at auckland.ac.nz>
> > To: Quets Jan <Jan.Quets at ua.ac.be>
> > Cc: "r-sig-geo at stat.math.ethz.ch" <r-sig-geo at stat.math.ethz.ch>
> > Subject: Re: [R-sig-Geo] existance of a specific non-overlapping
> > 	marked	spatial model in spatstat or other R package?
> > Message-ID: <B9268B92-B6F4-420C-AF04-EEE1DA182F67 at auckland.ac.nz>
> > Content-Type: text/plain; charset="us-ascii"
> > 
> > 
> > On 28/05/2010, at 8:53 AM, Quets Jan wrote:
> > 
> > > 
> > > Hi,
> > > 
> > > I am looking for a specific non-overlapping marked spatial model for use as a null model for monte carle simulations with use of the 'envelope' function in spatstat.
> > > 
> > > the specific marked spatial model should:
> > > -----------------
> > > *generate a spatial random pattern with a predetermined number of points (with conditions set below)
> > > 
> > > *each point should be assigned a mark randomly out of a predetermined set of marks
> > > 
> > > *these marks represent the radia of circular discs which should be drawn around these points (which act as centres)
> > > 
> > > *no discs should overlap
> > > -----------------
> > > 
> > > Does anybody has knowledge of a such a built in model in spatstat or another R package?
> > > 
> > > For now, I have built this model by myself, but it turns out to have a very time-consuming running time, especially when used as a null model in a monte carlo simulation. Also I have multiple monte carlo simulations to perform.
> > > 
> > > It will be of great help,
> > 
> > The only way I can think of doing this is sequentially.  I.e. select a
> > radius,
> > then repetitively select a point to add, rejecting the selected point if
> > its
> > circle (with the chosen radius) intersects any of the existing circles. 
> > If
> > after ``giveup'' attempts the function has failed to find an acceptable
> > point,
> > it gives up (and throws an error).
> > 
> > I cobbled together some code to effect this; it took one minute of user
> > time
> > to do 100 replications of choosing 100 points with non-overlapping
> > circles
> > in the unit square, with the radii selected uniform-randomly from
> > (1:5)/100
> > and giveup=1000.
> > 
> > I believe that it would require a lot of work and great cleverness to get
> > anything substantially faster.  Of course, I could be wrong --- I was
> > once,
> > back in 1968 when I thought I'd made a mistake and I hadn't. :-)
> > 
> > 	cheers,
> > 
> > 		Rolf Turner
> > 
> > P. S.  Let me know if you want my code.  I suspect it's not much
> > different
> > from what you have built yourself.
> > 
> > 		R.
> > ######################################################################
> > Attention: 
> > This e-mail message is privileged and confidential. If you are not the 
> > intended recipient please delete the message and notify the sender. 
> > Any views or opinions presented are solely those of the author.
> > 
> > This e-mail has been scanned and cleared by MailMarshal 
> > www.marshalsoftware.com
> > ######################################################################
> > 
> > 
> 
>


From r.hijmans at gmail.com  Fri May 28 19:44:09 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Fri, 28 May 2010 10:44:09 -0700
Subject: [R-sig-Geo] Elevation histogram for each region
In-Reply-To: <AANLkTikK9jd0hUvuSTcolXhirVF3Wh8hFh5te-qiBMfz@mail.gmail.com>
References: <AANLkTil_cmNeY6WTeNQizAdCzPO4jZWn1wENrWjVAC25@mail.gmail.com>
	<AANLkTinhCwvIKHd9d9xyoJW9EA90pDQEmQR47JwJc57r@mail.gmail.com>
	<AANLkTikK9jd0hUvuSTcolXhirVF3Wh8hFh5te-qiBMfz@mail.gmail.com>
Message-ID: <AANLkTimZsSiIlQQ0gH-WBznyDhtoxvllQqGTL0gGMrJw@mail.gmail.com>

Cl?lia,

Here is a example with polygonValues. It works under the assumption
that all the raster cells for a single polygon can be held in memory.


library(raster)
# creating some polygons
p1 <- rbind(c(-180,-20), c(-140,55), c(10, 0), c(-140,-60), c(-180,-20))
p2 <- rbind(c(-10,0), c(140,60), c(160,0), c(140,-55), c(-10,0))
p3 <- rbind(c(-125,0), c(0,60), c(40,5), c(15,-45), c(-125,0))
pols <- SpatialPolygons( list(  Polygons(list(Polygon(p1)), 1),
Polygons(list(Polygon(p2)), 2), Polygons(list(Polygon(p3)), 3)))

# set up a raster
r <- raster(ncol=180, nrow=90)
r[] = runif(ncell(r))

# how many polygons
nzones = length(pols at polygons)

lst = list()
for (i in 1:nzones) {
	pol <- pols[i]
	p <- polygonValues(pol,r)
	lst[[i]] = hist(unlist(p), main='')  # perhaps change to
main=pol at data[1,1]  or equivalent
}

plot(lst[[1]])


Robert


On Fri, May 28, 2010 at 6:59 AM, Cl?lia Bilodeau
<clelia.bilodeau at gmail.com> wrote:
> Thank you for your help.
> I'm still working on it.
> I think the use of polygonValues is a good idea, but the script:
>
> library(raster)
> lst = list()
> for (i in 1:nzones) {
> p <- polygonValues(pol,r, fun=function(x){x==i})
> lst[[i]] = histogram(p[,3])
> }
> doesn't work yet.
> Do I have to define a function to use in "fun=function(x)(x==1)"?
>
> Thank you.
> C.
>
>
> 2010/5/26 Robert J. Hijmans <r.hijmans at gmail.com>:
>> Cl?lia,
>>
>> The optimal solution would depend a bit on your data. If the regions
>> are not too large, you could loop over the zones
>>
>> library(raster)
>> lst = list()
>> for (i in 1:nzones) {
>> ?p <- rasterToPoints(r, fun=function(x){x==i})
>> ?lst[[i]] = histogram(p[,3])
>> }
>>
>> If you also have the zones as polygons you could alternatively look
>> over the polygons and use ?polygonValues in stead of rasterToPoints
>>
>> Another, more elaborate, option could be to, in your loop, reclassify
>> the regions raster (1 / 0 ), multiply that with the elevation data;
>> trim the output raster, make a histogram (set maxpixels to
>> ncell(raster)) (this may take a long time to finish)
>>
>> You could also first aggregate the rasters; unless you care much about
>> the extreme values.
>>
>> Hope this helps,
>> Robert
>>
>>
>> On Wed, May 26, 2010 at 2:08 AM, Cl?lia Bilodeau
>> <clelia.bilodeau at gmail.com> wrote:
>>> Dear list,
>>>
>>> I have two rasters, one is a Digital Elevation Model, and the other is
>>> a region file.
>>> I am looking for a method that allows me to plot the elevation
>>> histogram or density for each region.
>>>
>>> My first try was to do this with a function and to use "Zonal" from
>>> the "raster" package, but I have a very large file, so I have this
>>> error:
>>> "RasterLayers are too large. You can use fun='sum', 'mean', 'min', or
>>> 'max', but not a function"
>>>
>>> Is there another way to do this?
>>>
>>> Thank you.
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>


From r.hijmans at gmail.com  Fri May 28 19:57:55 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Fri, 28 May 2010 10:57:55 -0700
Subject: [R-sig-Geo] from R to ArcMap
In-Reply-To: <A0F8DAFB525DED4ABAF6841BB11C5812044E7E73@mail4.marlab.ac.uk>
References: <A0F8DAFB525DED4ABAF6841BB11C5812044E7E73@mail4.marlab.ac.uk>
Message-ID: <AANLkTin5tAIsVVPBUcvEJWaL2OHkcSuybqPFN_JA0JZY@mail.gmail.com>

Rui,
For writing to raster formats that can be read by ArcGIS you can have
a look at writeGDAL() in 'rgdal' or writeRaster() in 'raster'.
None of these formats support cells of varying sizes (which I believe
is something that levelplot might produce).
Robert

On Fri, May 28, 2010 at 1:58 AM, Rui Catarino <R.Catarino at marlab.ac.uk> wrote:
> Hello to all,
>
>
>
> Is there a way of transforming an output of levelplot function in a
> ArcMap raster?
>
> Basically I have a script from a colleague that uses data from surveys
> and transforms it into smooth levelplot's.
>
> I have look around but all I get is the opposite from ArcMap raster to
> R.
>
>
>
> Thanks in advance
>
> Rui
>
>
>
>
>
>
>
>
>
> Rui Catarino
>
> Scientific Officer
>
> Fishery Systems Group
>
> Marine Scotland - Science
>
>
>
> Scottish Government | 36 |B |Marine Laboratory, PO Box 101| 375,
> Victoria Road | Aberdeen AB11 9DB
>
>
>
> Tel: ?+44 (0)1224 295572
>
> Mob:+44 (0)7530 240666
>
> Fax: +44 (0)1224 295511
>
> e: r.catarino at marlab.ac.uk
>
> w: http://www.scotland.gov.uk/marinescotland
> <http://www.scotland.gov.uk/marinescotland>
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From wade.wall at gmail.com  Fri May 28 20:03:16 2010
From: wade.wall at gmail.com (Wade Wall)
Date: Fri, 28 May 2010 14:03:16 -0400
Subject: [R-sig-Geo] reading KML files in R
In-Reply-To: <alpine.LRH.2.00.1005280908320.9550@reclus.nhh.no>
References: <AANLkTikCyNsNdJk9lPGYYzOSfiDJCJ_VY1y7ey9kQKsh@mail.gmail.com>
	<4BFEB364.1080906@nceas.ucsb.edu>
	<alpine.LRH.2.00.1005272014000.7056@reclus.nhh.no>
	<AANLkTin3jgggXJlgHl7qqdRrZd2zcQINWgRSjJLCB0Ft@mail.gmail.com>
	<alpine.LRH.2.00.1005280908320.9550@reclus.nhh.no>
Message-ID: <AANLkTiltEvT2rOz_X9668CaooGdTg8isumAu-IchNIRR@mail.gmail.com>

Thanks Dr. Bivand,

I was able to import my kml file using your example.  I opened up the
kml file in a text editor to find out the layer name, but
system(paste("ogrinfo", paste(td, "cities.kml", sep="/")),
intern=TRUE) also works to find the name.

As for modifying ogrinfo(), I will take a look and see if it is above
my skill level or not.

Wade

On Fri, May 28, 2010 at 3:29 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Thu, 27 May 2010, Wade Wall wrote:
>
>> I am not exactly sure what you mean by identify the correct layer
>> name. ?Using R under Linux, this is what happens.
>>
>> I have a file in the current directory named ASMI_GA.kml
>>
>> library(rgdal)
>> tmp<-readOGR(".", layer="ASMI_GA.kml")
>>
>> However, I get the following message.
>>
>> Error in ogrInfo(dsn = dsn, layer = layer, input_field_name_encoding =
>> input_field_name_encoding) :
>> ?Cannot open file
>
> That is what I said. Each driver has its own understanding of what the dsn=
> and layer= arguments are, and your usage doesn't match what the driver is
> expecting. The dsn= for the KML driver seems to be the file name (possibly
> with its complete path), and the layer= is the string in the:
>
> <Document><Folder><name>cities</name>
>
> line (conditional on the writing software using a similar logic to OGR),
> here in this example:
>
> library(rgdal)
> cities <- readOGR(system.file("vectors", package = "rgdal")[1], "cities")
> is.na(cities$POPULATION) <- cities$POPULATION == -99
> summary(cities$POPULATION)
> td <- tempdir()
> writeOGR(cities, paste(td, "cities.kml", sep="/"), "cities", driver="KML")
> xx <- readOGR(paste(td, "cities.kml", sep="/"), "cities")
>
> How one discovers this name is not obvious, since the KML driver in OGR
> needs it to access the file. One possibility is:
>
> system(paste("ogrinfo", paste(td, "cities.kml", sep="/")), intern=TRUE)
>
> which lists the layer name(s). Perhaps ogrInfo() could be revised to access
> the dsn in the same way when not given a layer= argument to discover layer
> names - anyone with lots of time on their hands like to help?
>
> Roger
>
> PS. ogrDrivers() lists the drivers seen by OGR as running in rgdal, but for
> drivers with write but not read capability, it cannot distinguish. In that
> case, you only find out if a read driver is present and has its external
> dependencies properly satisfied by using it, I'm afraid. The example above
> will show whether your rgdal/GDAL/Expat do work or not.
>
>>
>> I have expat XML parser installed and gdal. ?This probably sounds
>> rather stupid, but I am not sure what the following means in the link
>> that Dr. Bivand provided: "KML reading is only available if GDAL/OGR
>> is built with the Expat XML Parser, otherwise only KML writing will be
>> supported." ?I installed both as debian packages (using get-apt).
>> Should I install both from source code, Expat XML Parser first and
>> then GDAL?
>>
>> Sorry if I seem dense here, but it is not real clear to me. ?Also,
>> even though this may be beyond the scope of R-sig-geo, I think that
>> other people are also struggling with this.
>>
>> Thanks for any help.
>>
>> Wade
>>
>>
>> On Thu, May 27, 2010 at 2:15 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>>
>>> On Thu, 27 May 2010, rick reeves wrote:
>>>
>>>> I do note that the example I provided does not demonstrate how to READ a
>>>> KML
>>>> file into R. But, SOON, I plan to modify the example to demonstrate
>>>> reading of KMLs
>>>> into some R-compatible format.
>>>
>>> readOGR() does read KML files, but you do have to identify the correct
>>> layer
>>> name - see:
>>>
>>> http://www.gdal.org/ogr/drv_kml.html
>>>
>>> Roger
>>>
>>>>
>>>> RR
>>>>
>>>> On 5/27/2010 10:15 AM, Wade Wall wrote:
>>>>>
>>>>> Hi all,
>>>>>
>>>>> Does anyone have experience reading and writing KML files in R? ?I
>>>>> have seen several threads that seem to suggest that it is difficult if
>>>>> not impossible, but it is convenient to use KML files when working
>>>>> with Google Earth and inconvenient to read and write shapefiles and
>>>>> then convert to KML using other software.
>>>>>
>>>>> If anyone is able to read and write KML files, if they could provide a
>>>>> description of how to do it, I am sure a lot of people would
>>>>> appreciate it. ?I have tried to do so under both Windows and Linux to
>>>>> no avail. ?The Windows approach looks more difficult, judging by the
>>>>> readme file associated with rgdal.
>>>>>
>>>>> Thanks,
>>>>>
>>>>> Wade
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>>>>
>>>>
>>>>
>>>>
>>>
>>> --
>>> Roger Bivand
>>> Economic Geography Section, Department of Economics, Norwegian School of
>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>


From emptican at gmail.com  Fri May 28 21:58:27 2010
From: emptican at gmail.com (Steve Hong)
Date: Fri, 28 May 2010 14:58:27 -0500
Subject: [R-sig-Geo] helps in predicting with spatial data
Message-ID: <AANLkTilbGxHMlYE6F1Rc9ERSU-pPx5kVNfY1OAHHTIH1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100528/611881a8/attachment.pl>

From gildemir at gmail.com  Sat May 29 06:10:20 2010
From: gildemir at gmail.com (Francisco Silva)
Date: Sat, 29 May 2010 01:10:20 -0300
Subject: [R-sig-Geo] Spatial Logit Model
Message-ID: <AANLkTinN86rd3kB4oriRQkAkLRBBgD3ezHxdKtarUZMK@mail.gmail.com>

Hello everybody,

I am trying to do a spatial logit model with the spatially
autoregressive error structure - SAE. Right now, I did an
implementation and i would like to check the results.
Somebody knows with there is a package in R that estimates parameters
to spatial logit model with SAE structure? or Somebody else had made
some implementations of this model and can help me?

Thanks a lot in advances,
Francisco Gildemir Ferreira da Silva


From alobolistas at gmail.com  Sat May 29 09:21:03 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Sat, 29 May 2010 09:21:03 +0200
Subject: [R-sig-Geo] reading KML files in R
In-Reply-To: <AANLkTiltEvT2rOz_X9668CaooGdTg8isumAu-IchNIRR@mail.gmail.com>
References: <AANLkTikCyNsNdJk9lPGYYzOSfiDJCJ_VY1y7ey9kQKsh@mail.gmail.com>
	<4BFEB364.1080906@nceas.ucsb.edu>
	<alpine.LRH.2.00.1005272014000.7056@reclus.nhh.no>
	<AANLkTin3jgggXJlgHl7qqdRrZd2zcQINWgRSjJLCB0Ft@mail.gmail.com>
	<alpine.LRH.2.00.1005280908320.9550@reclus.nhh.no>
	<AANLkTiltEvT2rOz_X9668CaooGdTg8isumAu-IchNIRR@mail.gmail.com>
Message-ID: <AANLkTilm2up1a5oOEAanEFNIYROMKREPyRQF43tLaklI@mail.gmail.com>

Excuses for the quite adjacent question, does anybody know if kml files require
using the google spherical projection?
My understanding is that, in theory, you can use any projection, but,
in fact, you must use
google spherical to get a correct display in google maps

Agus

2010/5/28 Wade Wall <wade.wall at gmail.com>:
> Thanks Dr. Bivand,
>
> I was able to import my kml file using your example. ?I opened up the
> kml file in a text editor to find out the layer name, but
> system(paste("ogrinfo", paste(td, "cities.kml", sep="/")),
> intern=TRUE) also works to find the name.
>
> As for modifying ogrinfo(), I will take a look and see if it is above
> my skill level or not.
>
> Wade
>
> On Fri, May 28, 2010 at 3:29 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> On Thu, 27 May 2010, Wade Wall wrote:
>>
>>> I am not exactly sure what you mean by identify the correct layer
>>> name. ?Using R under Linux, this is what happens.
>>>
>>> I have a file in the current directory named ASMI_GA.kml
>>>
>>> library(rgdal)
>>> tmp<-readOGR(".", layer="ASMI_GA.kml")
>>>
>>> However, I get the following message.
>>>
>>> Error in ogrInfo(dsn = dsn, layer = layer, input_field_name_encoding =
>>> input_field_name_encoding) :
>>> ?Cannot open file
>>
>> That is what I said. Each driver has its own understanding of what the dsn=
>> and layer= arguments are, and your usage doesn't match what the driver is
>> expecting. The dsn= for the KML driver seems to be the file name (possibly
>> with its complete path), and the layer= is the string in the:
>>
>> <Document><Folder><name>cities</name>
>>
>> line (conditional on the writing software using a similar logic to OGR),
>> here in this example:
>>
>> library(rgdal)
>> cities <- readOGR(system.file("vectors", package = "rgdal")[1], "cities")
>> is.na(cities$POPULATION) <- cities$POPULATION == -99
>> summary(cities$POPULATION)
>> td <- tempdir()
>> writeOGR(cities, paste(td, "cities.kml", sep="/"), "cities", driver="KML")
>> xx <- readOGR(paste(td, "cities.kml", sep="/"), "cities")
>>
>> How one discovers this name is not obvious, since the KML driver in OGR
>> needs it to access the file. One possibility is:
>>
>> system(paste("ogrinfo", paste(td, "cities.kml", sep="/")), intern=TRUE)
>>
>> which lists the layer name(s). Perhaps ogrInfo() could be revised to access
>> the dsn in the same way when not given a layer= argument to discover layer
>> names - anyone with lots of time on their hands like to help?
>>
>> Roger
>>
>> PS. ogrDrivers() lists the drivers seen by OGR as running in rgdal, but for
>> drivers with write but not read capability, it cannot distinguish. In that
>> case, you only find out if a read driver is present and has its external
>> dependencies properly satisfied by using it, I'm afraid. The example above
>> will show whether your rgdal/GDAL/Expat do work or not.
>>
>>>
>>> I have expat XML parser installed and gdal. ?This probably sounds
>>> rather stupid, but I am not sure what the following means in the link
>>> that Dr. Bivand provided: "KML reading is only available if GDAL/OGR
>>> is built with the Expat XML Parser, otherwise only KML writing will be
>>> supported." ?I installed both as debian packages (using get-apt).
>>> Should I install both from source code, Expat XML Parser first and
>>> then GDAL?
>>>
>>> Sorry if I seem dense here, but it is not real clear to me. ?Also,
>>> even though this may be beyond the scope of R-sig-geo, I think that
>>> other people are also struggling with this.
>>>
>>> Thanks for any help.
>>>
>>> Wade
>>>
>>>
>>> On Thu, May 27, 2010 at 2:15 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>>>
>>>> On Thu, 27 May 2010, rick reeves wrote:
>>>>
>>>>> I do note that the example I provided does not demonstrate how to READ a
>>>>> KML
>>>>> file into R. But, SOON, I plan to modify the example to demonstrate
>>>>> reading of KMLs
>>>>> into some R-compatible format.
>>>>
>>>> readOGR() does read KML files, but you do have to identify the correct
>>>> layer
>>>> name - see:
>>>>
>>>> http://www.gdal.org/ogr/drv_kml.html
>>>>
>>>> Roger
>>>>
>>>>>
>>>>> RR
>>>>>
>>>>> On 5/27/2010 10:15 AM, Wade Wall wrote:
>>>>>>
>>>>>> Hi all,
>>>>>>
>>>>>> Does anyone have experience reading and writing KML files in R? ?I
>>>>>> have seen several threads that seem to suggest that it is difficult if
>>>>>> not impossible, but it is convenient to use KML files when working
>>>>>> with Google Earth and inconvenient to read and write shapefiles and
>>>>>> then convert to KML using other software.
>>>>>>
>>>>>> If anyone is able to read and write KML files, if they could provide a
>>>>>> description of how to do it, I am sure a lot of people would
>>>>>> appreciate it. ?I have tried to do so under both Windows and Linux to
>>>>>> no avail. ?The Windows approach looks more difficult, judging by the
>>>>>> readme file associated with rgdal.
>>>>>>
>>>>>> Thanks,
>>>>>>
>>>>>> Wade
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>
>>>> --
>>>> Roger Bivand
>>>> Economic Geography Section, Department of Economics, Norwegian School of
>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>> e-mail: Roger.Bivand at nhh.no
>>>>
>>>>
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From alobolistas at gmail.com  Sat May 29 09:29:30 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Sat, 29 May 2010 09:29:30 +0200
Subject: [R-sig-Geo] projection() and proj4string()
Message-ID: <AANLkTincjYWi3MqXI8TO1P_xLl1V-dQygfe4Dyfh8Xue@mail.gmail.com>

Why do I have to use proj4string() instead of projection() in this example?

> class(Montseny20090409sh)
[1] "SpatialPointsDataFrame"
attr(,"package")
[1] "sp"

> projection(Montseny20090409sh)
[1] "+proj=utm +zone=31 +ellps=intl +units=m +no_defs"

> a<- SpatialPoints(coordinates(Montseny20090409sh))
> class(a)
[1] "SpatialPoints"
attr(,"package")
[1] "sp"

> projection(a) <- projection(Montseny20090409sh)
Error in checkSlotAssignment(object, name, value) :
  "crs" is not a slot in class "SpatialPoints"
Calls: projection<- -> @<- -> slot<- -> checkSlotAssignment

> proj4string(a) <- projection(Montseny20090409sh)
> geogWGS84 <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
> aGW <- spTransform(a, geogWGS84)
> Montseny20090409sh2 <- Montseny20090409sh
> Montseny20090409sh2 at data <- cbind(Montseny20090409sh2 at data,coordinates(aGW))

Thanks for any clarification,

Agus


From tech_dev at wildintellect.com  Sat May 29 09:33:06 2010
From: tech_dev at wildintellect.com (Alex Mandel)
Date: Sat, 29 May 2010 00:33:06 -0700
Subject: [R-sig-Geo] reading KML files in R
In-Reply-To: <AANLkTilm2up1a5oOEAanEFNIYROMKREPyRQF43tLaklI@mail.gmail.com>
References: <AANLkTikCyNsNdJk9lPGYYzOSfiDJCJ_VY1y7ey9kQKsh@mail.gmail.com>	<4BFEB364.1080906@nceas.ucsb.edu>	<alpine.LRH.2.00.1005272014000.7056@reclus.nhh.no>	<AANLkTin3jgggXJlgHl7qqdRrZd2zcQINWgRSjJLCB0Ft@mail.gmail.com>	<alpine.LRH.2.00.1005280908320.9550@reclus.nhh.no>	<AANLkTiltEvT2rOz_X9668CaooGdTg8isumAu-IchNIRR@mail.gmail.com>
	<AANLkTilm2up1a5oOEAanEFNIYROMKREPyRQF43tLaklI@mail.gmail.com>
Message-ID: <4C00C332.7010900@wildintellect.com>

Actually I believe for kml you must use geographic coordinates
unprojected. WGS 84 Lat/Lon , EPSG:4326

And yes it's only so Google maps/earth knows what to do with it.
If I could make head or tails of OGC specs I'm sure it says something
about it in there.

Alex

On 05/29/2010 12:21 AM, Agustin Lobo wrote:
> Excuses for the quite adjacent question, does anybody know if kml files require
> using the google spherical projection?
> My understanding is that, in theory, you can use any projection, but,
> in fact, you must use
> google spherical to get a correct display in google maps
> 
> Agus
> 
> 2010/5/28 Wade Wall <wade.wall at gmail.com>:
>> Thanks Dr. Bivand,
>>
>> I was able to import my kml file using your example.  I opened up the
>> kml file in a text editor to find out the layer name, but
>> system(paste("ogrinfo", paste(td, "cities.kml", sep="/")),
>> intern=TRUE) also works to find the name.
>>
>> As for modifying ogrinfo(), I will take a look and see if it is above
>> my skill level or not.
>>
>> Wade
>>
>> On Fri, May 28, 2010 at 3:29 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>> On Thu, 27 May 2010, Wade Wall wrote:
>>>
>>>> I am not exactly sure what you mean by identify the correct layer
>>>> name.  Using R under Linux, this is what happens.
>>>>
>>>> I have a file in the current directory named ASMI_GA.kml
>>>>
>>>> library(rgdal)
>>>> tmp<-readOGR(".", layer="ASMI_GA.kml")
>>>>
>>>> However, I get the following message.
>>>>
>>>> Error in ogrInfo(dsn = dsn, layer = layer, input_field_name_encoding =
>>>> input_field_name_encoding) :
>>>>  Cannot open file
>>>
>>> That is what I said. Each driver has its own understanding of what the dsn=
>>> and layer= arguments are, and your usage doesn't match what the driver is
>>> expecting. The dsn= for the KML driver seems to be the file name (possibly
>>> with its complete path), and the layer= is the string in the:
>>>
>>> <Document><Folder><name>cities</name>
>>>
>>> line (conditional on the writing software using a similar logic to OGR),
>>> here in this example:
>>>
>>> library(rgdal)
>>> cities <- readOGR(system.file("vectors", package = "rgdal")[1], "cities")
>>> is.na(cities$POPULATION) <- cities$POPULATION == -99
>>> summary(cities$POPULATION)
>>> td <- tempdir()
>>> writeOGR(cities, paste(td, "cities.kml", sep="/"), "cities", driver="KML")
>>> xx <- readOGR(paste(td, "cities.kml", sep="/"), "cities")
>>>
>>> How one discovers this name is not obvious, since the KML driver in OGR
>>> needs it to access the file. One possibility is:
>>>
>>> system(paste("ogrinfo", paste(td, "cities.kml", sep="/")), intern=TRUE)
>>>
>>> which lists the layer name(s). Perhaps ogrInfo() could be revised to access
>>> the dsn in the same way when not given a layer= argument to discover layer
>>> names - anyone with lots of time on their hands like to help?
>>>
>>> Roger
>>>
>>> PS. ogrDrivers() lists the drivers seen by OGR as running in rgdal, but for
>>> drivers with write but not read capability, it cannot distinguish. In that
>>> case, you only find out if a read driver is present and has its external
>>> dependencies properly satisfied by using it, I'm afraid. The example above
>>> will show whether your rgdal/GDAL/Expat do work or not.
>>>
>>>>
>>>> I have expat XML parser installed and gdal.  This probably sounds
>>>> rather stupid, but I am not sure what the following means in the link
>>>> that Dr. Bivand provided: "KML reading is only available if GDAL/OGR
>>>> is built with the Expat XML Parser, otherwise only KML writing will be
>>>> supported."  I installed both as debian packages (using get-apt).
>>>> Should I install both from source code, Expat XML Parser first and
>>>> then GDAL?
>>>>
>>>> Sorry if I seem dense here, but it is not real clear to me.  Also,
>>>> even though this may be beyond the scope of R-sig-geo, I think that
>>>> other people are also struggling with this.
>>>>
>>>> Thanks for any help.
>>>>
>>>> Wade
>>>>
>>>>
>>>> On Thu, May 27, 2010 at 2:15 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>>>>
>>>>> On Thu, 27 May 2010, rick reeves wrote:
>>>>>
>>>>>> I do note that the example I provided does not demonstrate how to READ a
>>>>>> KML
>>>>>> file into R. But, SOON, I plan to modify the example to demonstrate
>>>>>> reading of KMLs
>>>>>> into some R-compatible format.
>>>>>
>>>>> readOGR() does read KML files, but you do have to identify the correct
>>>>> layer
>>>>> name - see:
>>>>>
>>>>> http://www.gdal.org/ogr/drv_kml.html
>>>>>
>>>>> Roger
>>>>>
>>>>>>
>>>>>> RR
>>>>>>
>>>>>> On 5/27/2010 10:15 AM, Wade Wall wrote:
>>>>>>>
>>>>>>> Hi all,
>>>>>>>
>>>>>>> Does anyone have experience reading and writing KML files in R?  I
>>>>>>> have seen several threads that seem to suggest that it is difficult if
>>>>>>> not impossible, but it is convenient to use KML files when working
>>>>>>> with Google Earth and inconvenient to read and write shapefiles and
>>>>>>> then convert to KML using other software.
>>>>>>>
>>>>>>> If anyone is able to read and write KML files, if they could provide a
>>>>>>> description of how to do it, I am sure a lot of people would
>>>>>>> appreciate it.  I have tried to do so under both Windows and Linux to
>>>>>>> no avail.  The Windows approach looks more difficult, judging by the
>>>>>>> readme file associated with rgdal.
>>>>>>>
>>>>>>> Thanks,
>>>>>>>
>>>>>>> Wade
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-Geo mailing list
>>>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>
>>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>> --
>>>>> Roger Bivand
>>>>> Economic Geography Section, Department of Economics, Norwegian School of
>>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>
>>>>>
>>>>
>>>
>>> --
>>> Roger Bivand
>>> Economic Geography Section, Department of Economics, Norwegian School of
>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>> e-mail: Roger.Bivand at nhh.no
>>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Sat May 29 11:06:18 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 29 May 2010 11:06:18 +0200 (CEST)
Subject: [R-sig-Geo] Better print method for Spatial*DataFrames?
In-Reply-To: <AANLkTik-wte4kJhYhyejdEX-QD3BGD8XxSc1uD51_Ff0@mail.gmail.com>
References: <AANLkTikrtxVdCpwymXAws7B_aa82CcsUVh4ENNyLj3Mx@mail.gmail.com>
	<4BFE72EF.9070108@uni-muenster.de> <4BFFD769.1010906@gmail.com>
	<alpine.LRH.2.00.1005281806580.11964@reclus.nhh.no>
	<AANLkTik-wte4kJhYhyejdEX-QD3BGD8XxSc1uD51_Ff0@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1005291046050.14661@reclus.nhh.no>

On Fri, 28 May 2010, Barry Rowlingson wrote:

> On Fri, May 28, 2010 at 5:18 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> On Fri, 28 May 2010, Etienne Bellemare Racine wrote:
>>
>>> I taught I could add my two cents.
>>>>
>>>> Nice suggestion!
>>>
>>> I agree !
>>
>> No. Only for SpatialPointDataFrame objects, which is what it does already.
>> Please, understand that str() is a *much* better choice in effectively all
>> cases where summary() isn't used. For the Spatial* objects, set a
>> max.level=2 or similar, and you can *see* what is in it. The proposed
>> print() method for a big multiband raster will also run away with you. Do
>> str(), not print()!!!
>
> I'm not sure what you're saying 'No' to here, Roger. Neither str(xx)
> nor summary(xx) present the object as a data frame. Conceptually its a
> data frame where one of the columns is a geometry, and seeing it print
> as such is a good thing (imho). I'd like to never have to use xx at data
> again!

Just pragmatics, since things which have rushed off the top of my screen 
really are not much help, I find.

I use as(xx, "data.frame") when needed, but most often subset both 
observations and variables by "[". I'm not sure where displaying all the 
data gets you for more than a trivial number of observations and 
variables, though? The output will still swamp the console/terminal 
buffer. I'm thinking of a multi-band raster, but even standard 
show(meuse.grid) as a data.frame only leaves rows 2605-3103 on screen for 
a standard gnome-terminal. The data editor I see doesn't have a scroll 
bar, so to scroll, one would need an external viewer, I think.

In other software systems (octave, Stata, ...), one can turn on and off a 
more/less screen-by-screen displayer (not scrolling upwards, just 
chunking), but I'm not aware of an equivalent in R/S. I'm not sure how 
head() and tail() work in R, and personally use str() by default. If I 
need to access the coordinates of a particular line or polygon, I print() 
just that list element (Line or Polygon object).

I can see what you mean, but feel that users will benefit much more by 
using str(), which is a real gem!

Roger

>
> I'm not sure trying to truncate the coordinates for nice formatting
> is a good idea though, but some indication when printing a
> Spatial*DataFrame that its a dataframe with geometries seems a good
> idea.
>
> Barry
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From b.rowlingson at lancaster.ac.uk  Sat May 29 11:28:12 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sat, 29 May 2010 10:28:12 +0100
Subject: [R-sig-Geo] Better print method for Spatial*DataFrames?
In-Reply-To: <alpine.LRH.2.00.1005291046050.14661@reclus.nhh.no>
References: <AANLkTikrtxVdCpwymXAws7B_aa82CcsUVh4ENNyLj3Mx@mail.gmail.com>
	<4BFE72EF.9070108@uni-muenster.de> <4BFFD769.1010906@gmail.com>
	<alpine.LRH.2.00.1005281806580.11964@reclus.nhh.no>
	<AANLkTik-wte4kJhYhyejdEX-QD3BGD8XxSc1uD51_Ff0@mail.gmail.com>
	<alpine.LRH.2.00.1005291046050.14661@reclus.nhh.no>
Message-ID: <AANLkTinjSbnRg8H2FBNtFt8Phitm5e4YIhygAMTXd9Cx@mail.gmail.com>

On Sat, May 29, 2010 at 10:06 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:


> In other software systems (octave, Stata, ...), one can turn on and off a
> more/less screen-by-screen displayer (not scrolling upwards, just chunking),
> but I'm not aware of an equivalent in R/S. I'm not sure how head() and
> tail() work in R,

 They don't seem to work very well at all for Spatial*DataFrames. If I
add coordinates to meuse to get a SpatialPointsDataFrame and
head(that) I get all the 'rows' but with only the cadmium
measurements. It's slicing it the wrong way. Odd.

> and personally use str() by default. If I need to access
> the coordinates of a particular line or polygon, I print() just that list
> element (Line or Polygon object).
>
> I can see what you mean, but feel that users will benefit much more by using
> str(), which is a real gem!

 str is great if you need to know the str-ucture of an R object. But
it doesn't even align the values so you can see across rows of your
data, which is what I'd like print to do (by analogy with
print.data.frame).

 Currently if I print a SpatialPolygonsDataFrame I get the structure.
Print methods should do better than that - you're almost suggesting
not having, for example, a print method for data frames and that we'd
be better off having what print.default(anyDataFrame) gives us.

 So my proposal is that print of a SpatialPolygonsDataFrame class
should print like a data frame but with some indicator of the geometry
at the start of the row, such as POLYGON(...) - literally with dots,
there's no need to spell it out. Similarly for Lines.

 Another suggestion is for head() and tail methods on
Spatial*DataFrame objects - I think just subscripting [1:n,] from the
object and returning would do it. I think currently head and tail
treat these objects as lists and the results are not pretty.

Barry


From CXT755 at bham.ac.uk  Sat May 29 11:43:03 2010
From: CXT755 at bham.ac.uk (Claire Teeling)
Date: Sat, 29 May 2010 10:43:03 +0100
Subject: [R-sig-Geo] spatially balanced sampling to reduce geo-political bias
Message-ID: <9DF33C99B2BAE94CB9C5B27A154900DA02AA0BE7378E@mbx7.adf.bham.ac.uk>

Dear all,

I am carrying out some species distribution modelling based on a database of
species occurrence records of a single tree species, encompassing the entire European
continent. The records are primarily historical and heavily biased towards
western, northern Europe. A few of the counts of records by country are shown
below to illustrate.

CHE     12
CZE     1
DEN     6
DEU     1742
DNK     12
ESP     237
FIN     1
FRA     6536
GBR     3294
GEO     39
GRC     47
HUN     2

I am very new to R and I'm trying to find a way to subsample in order to obtain
a more spatially balanced sample of 300 records, from a total of 16794. I have
looked at some packages, e.g. sp, spcosa, spsurvey, spdep, have searched the
manuals and searched for similar examples.
I have also tried to stratify the data but can't find a stratum which reduces
the impact of the bias. I also have a field containing inclusion probabilities
for each record, based on country.
I just can't seem to work out how best to perform sampling to reduce the effect
of geopolitical bias.
Any advice, for an R novice, would be very gratefully received.

Thanks,

Claire

From Roger.Bivand at nhh.no  Sat May 29 11:47:45 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 29 May 2010 11:47:45 +0200 (CEST)
Subject: [R-sig-Geo] Better print method for Spatial*DataFrames?
In-Reply-To: <AANLkTinjSbnRg8H2FBNtFt8Phitm5e4YIhygAMTXd9Cx@mail.gmail.com>
References: <AANLkTikrtxVdCpwymXAws7B_aa82CcsUVh4ENNyLj3Mx@mail.gmail.com>
	<4BFE72EF.9070108@uni-muenster.de> <4BFFD769.1010906@gmail.com>
	<alpine.LRH.2.00.1005281806580.11964@reclus.nhh.no>
	<AANLkTik-wte4kJhYhyejdEX-QD3BGD8XxSc1uD51_Ff0@mail.gmail.com>
	<alpine.LRH.2.00.1005291046050.14661@reclus.nhh.no>
	<AANLkTinjSbnRg8H2FBNtFt8Phitm5e4YIhygAMTXd9Cx@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1005291138380.14661@reclus.nhh.no>

On Sat, 29 May 2010, Barry Rowlingson wrote:

> On Sat, May 29, 2010 at 10:06 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>
>> In other software systems (octave, Stata, ...), one can turn on and off a
>> more/less screen-by-screen displayer (not scrolling upwards, just chunking),
>> but I'm not aware of an equivalent in R/S. I'm not sure how head() and
>> tail() work in R,
>
> They don't seem to work very well at all for Spatial*DataFrames. If I
> add coordinates to meuse to get a SpatialPointsDataFrame and
> head(that) I get all the 'rows' but with only the cadmium
> measurements. It's slicing it the wrong way. Odd.
>
>> and personally use str() by default. If I need to access
>> the coordinates of a particular line or polygon, I print() just that list
>> element (Line or Polygon object).
>>
>> I can see what you mean, but feel that users will benefit much more by using
>> str(), which is a real gem!
>
> str is great if you need to know the str-ucture of an R object. But
> it doesn't even align the values so you can see across rows of your
> data, which is what I'd like print to do (by analogy with
> print.data.frame).
>
> Currently if I print a SpatialPolygonsDataFrame I get the structure.
> Print methods should do better than that - you're almost suggesting
> not having, for example, a print method for data frames and that we'd
> be better off having what print.default(anyDataFrame) gives us.
>
> So my proposal is that print of a SpatialPolygonsDataFrame class
> should print like a data frame but with some indicator of the geometry
> at the start of the row, such as POLYGON(...) - literally with dots,
> there's no need to spell it out. Similarly for Lines.
>
> Another suggestion is for head() and tail methods on
> Spatial*DataFrame objects - I think just subscripting [1:n,] from the
> object and returning would do it. I think currently head and tail
> treat these objects as lists and the results are not pretty.

Right, because they see S4 objects as lists with no components, only with 
attributes. str() does have support for S4 objects. They would need to be 
wrapped around an S4 show/print method, with the output captured, as in 
capture.output(). Would it make sense to have the default print/show for 
Spatial* be str() with max.level= set, and for Spatial*DataFrame be the 
print method for the data slot prepended with some text (perhaps POINT, 
MULTILINESTRING, MULTIPOLYGON, PIXEL, CELL, or better an abbreviation)?

One would do this by cbind()ing the text in front of the as(, 
"data.frame"), I think, as a "geometry" variable.

Roger

>
> Barry
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From georgekick at gmail.com  Sat May 29 12:59:09 2010
From: georgekick at gmail.com (George Kikuchi)
Date: Sat, 29 May 2010 19:59:09 +0900
Subject: [R-sig-Geo] testing significance of temporal K function
Message-ID: <AANLkTim85-3P5a14UkYcaQbVnlzvWNT8sWjm-Vh0FwXH@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100529/cbe645d2/attachment.pl>

From georgekick at gmail.com  Sat May 29 13:04:21 2010
From: georgekick at gmail.com (George Kikuchi)
Date: Sat, 29 May 2010 20:04:21 +0900
Subject: [R-sig-Geo] testing significance of temporal K function
Message-ID: <AANLkTinj2kG3sF77p6pmj6T7ptg33Ns7DXk35EWK_5-U@mail.gmail.com>

Hello R-sig-Geo subscribers,

I would like to know if there is an easy way to test the statistical
significance of temporal K function (ideally using the results from
splancs stkhat function).  I assume this is an easy problem.  There
seems to be many textbooks and websites explaining spatial K function,
while not so many about temporal K function.
I really appreciate if anybody can tell me ways to test the
significance of temporal K function (with R codes), as well as guides
to interpret the results..

library(splancs)
data(burkitt)
bur1 <- stkhat(burpts, burkitt$t, burbdy, c(400, 5800), seq(1,40,2),
seq(100, 1500, 100))
oldpar <- par(mfrow=c(2,1))
plot(bur1$s, bur1$ks, type="l", xlab="distance", ylab="Estimated K",
main="spatial K function")
plot(bur1$t, bur1$kt, type="l", xlab="time", ylab="Estimated K",
main="temporal K function")
par(oldpar)

Thanks in advance,

George


From Roger.Bivand at nhh.no  Sat May 29 13:09:36 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 29 May 2010 13:09:36 +0200 (CEST)
Subject: [R-sig-Geo] projection() and proj4string()
In-Reply-To: <AANLkTincjYWi3MqXI8TO1P_xLl1V-dQygfe4Dyfh8Xue@mail.gmail.com>
References: <AANLkTincjYWi3MqXI8TO1P_xLl1V-dQygfe4Dyfh8Xue@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1005291257120.14661@reclus.nhh.no>

On Sat, 29 May 2010, Agustin Lobo wrote:

> Why do I have to use proj4string() instead of projection() in this example?

You are getting mixed up between packages. projection() is a function in 
the raster package, while proj4string() is a function in sp. Use 
projection() for classes defined or extended in raster, proj4string() for 
classes defined in sp. Critically, projection<-() tries to assign to a 
slot called "crs", which is not present in Spatial* objects.

My feeling is that the sp nomenclature is clearer but clunkier, because it 
specifies the representation of the projection as a PROJ.4 string, while 
the name of the function "projection" could admit arbitrary 
representations, but in fact uses the same representation and mechanisms 
as sp (with verification through the PROJ.4 library if rgdal is loaded).

Probably projection<-() needs the same if() statement as that used in 
projection(), to distinguish extensions of "BasicRaster" from those of 
"Spatial", in which case projection<-() and proj4string<-() will both work 
on objects extending "Spatial" too.

Roger


>
>> class(Montseny20090409sh)
> [1] "SpatialPointsDataFrame"
> attr(,"package")
> [1] "sp"
>
>> projection(Montseny20090409sh)
> [1] "+proj=utm +zone=31 +ellps=intl +units=m +no_defs"
>
>> a<- SpatialPoints(coordinates(Montseny20090409sh))
>> class(a)
> [1] "SpatialPoints"
> attr(,"package")
> [1] "sp"
>
>> projection(a) <- projection(Montseny20090409sh)
> Error in checkSlotAssignment(object, name, value) :
>  "crs" is not a slot in class "SpatialPoints"
> Calls: projection<- -> @<- -> slot<- -> checkSlotAssignment
>
>> proj4string(a) <- projection(Montseny20090409sh)
>> geogWGS84 <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
>> aGW <- spTransform(a, geogWGS84)
>> Montseny20090409sh2 <- Montseny20090409sh
>> Montseny20090409sh2 at data <- cbind(Montseny20090409sh2 at data,coordinates(aGW))
>
> Thanks for any clarification,
>
> Agus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From pslarson2 at gmail.com  Sat May 29 16:58:46 2010
From: pslarson2 at gmail.com (Peter Larson)
Date: Sat, 29 May 2010 10:58:46 -0400
Subject: [R-sig-Geo] Better print method for Spatial*DataFrames?
In-Reply-To: <alpine.LRH.2.00.1005291138380.14661@reclus.nhh.no>
References: <AANLkTikrtxVdCpwymXAws7B_aa82CcsUVh4ENNyLj3Mx@mail.gmail.com>	<4BFE72EF.9070108@uni-muenster.de>
	<4BFFD769.1010906@gmail.com>	<alpine.LRH.2.00.1005281806580.11964@reclus.nhh.no>	<AANLkTik-wte4kJhYhyejdEX-QD3BGD8XxSc1uD51_Ff0@mail.gmail.com>	<alpine.LRH.2.00.1005291046050.14661@reclus.nhh.no>	<AANLkTinjSbnRg8H2FBNtFt8Phitm5e4YIhygAMTXd9Cx@mail.gmail.com>
	<alpine.LRH.2.00.1005291138380.14661@reclus.nhh.no>
Message-ID: <4C012BA6.8030606@gmail.com>

Hello,

I am attempting to use the sample code in "Applied Spatial Data Analysis 
with R" but cannot get this to work and get this error:

 > nc = readShapePoly(system.file("shapes/sids.shp", package="maptools")[1],
+ IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
?????? read.dbf(filen) : unable to open DBF file

Any ideas?

Thanks,

Pete


From Roger.Bivand at nhh.no  Sat May 29 18:10:28 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 29 May 2010 18:10:28 +0200 (CEST)
Subject: [R-sig-Geo] Better print method for Spatial*DataFrames?
In-Reply-To: <4C012BA6.8030606@gmail.com>
References: <AANLkTikrtxVdCpwymXAws7B_aa82CcsUVh4ENNyLj3Mx@mail.gmail.com>
	<4BFE72EF.9070108@uni-muenster.de> <4BFFD769.1010906@gmail.com>
	<alpine.LRH.2.00.1005281806580.11964@reclus.nhh.no>
	<AANLkTik-wte4kJhYhyejdEX-QD3BGD8XxSc1uD51_Ff0@mail.gmail.com>
	<alpine.LRH.2.00.1005291046050.14661@reclus.nhh.no>
	<AANLkTinjSbnRg8H2FBNtFt8Phitm5e4YIhygAMTXd9Cx@mail.gmail.com>
	<alpine.LRH.2.00.1005291138380.14661@reclus.nhh.no>
	<4C012BA6.8030606@gmail.com>
Message-ID: <alpine.LRH.2.00.1005291809260.15379@reclus.nhh.no>

On Sat, 29 May 2010, Peter Larson wrote:

> Hello,
>
> I am attempting to use the sample code in "Applied Spatial Data Analysis 
> with R" but cannot get this to work and get this error:
>
> > nc = readShapePoly(system.file("shapes/sids.shp", package="maptools")[1],
> + IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
> ?????? read.dbf(filen) : unable to open DBF file
>
> Any ideas?

Please update your installed packages - this looks like a mismatch between 
foreign and maptools.

Roger

>
> Thanks,
>
> Pete
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From alobolistas at gmail.com  Sat May 29 19:02:49 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Sat, 29 May 2010 10:02:49 -0700 (PDT)
Subject: [R-sig-Geo] projection() and proj4string()
In-Reply-To: <alpine.LRH.2.00.1005291257120.14661@reclus.nhh.no>
References: <AANLkTincjYWi3MqXI8TO1P_xLl1V-dQygfe4Dyfh8Xue@mail.gmail.com>
	<alpine.LRH.2.00.1005291257120.14661@reclus.nhh.no>
Message-ID: <1275152569520-5116707.post@n2.nabble.com>


So, if I correctly understand, projection() can be used to retrieve
information
from an sp object but not to assign that info to a sp object:
> projection(a)
[1] "+proj=utm +zone=31 +ellps=intl +units=m +no_defs"

> projection(a) <- projection(a)
Error in checkSlotAssignment(object, name, value) : 
  "crs" is not a slot in class "SpatialPoints"
Calls: projection<- -> @<- -> slot<- -> checkSlotAssignment


Roger Bivand wrote:
> 
> .../...
> Probably projection<-() needs the same if() statement as that used in 
> projection(), to distinguish extensions of "BasicRaster" from those of 
> "Spatial", in which case projection<-() and proj4string<-() will both work 
> on objects extending "Spatial" too.
> 
> Roger
> 

>From a user point of view, this would be certainly useful.

Thanks!

Agus
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/projection-and-proj4string-tp5115767p5116707.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From b.rowlingson at lancaster.ac.uk  Sat May 29 19:10:07 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sat, 29 May 2010 18:10:07 +0100
Subject: [R-sig-Geo] projection() and proj4string()
In-Reply-To: <1275152569520-5116707.post@n2.nabble.com>
References: <AANLkTincjYWi3MqXI8TO1P_xLl1V-dQygfe4Dyfh8Xue@mail.gmail.com>
	<alpine.LRH.2.00.1005291257120.14661@reclus.nhh.no>
	<1275152569520-5116707.post@n2.nabble.com>
Message-ID: <AANLkTilID0aiptGDDcBYtgCubXcsATxzif7IX2hg6bO5@mail.gmail.com>

On Sat, May 29, 2010 at 6:02 PM, Agustin Lobo <alobolistas at gmail.com> wrote:
>
> So, if I correctly understand, projection() can be used to retrieve
> information
> from an sp object but not to assign that info to a sp object:
>> projection(a)
> [1] "+proj=utm +zone=31 +ellps=intl +units=m +no_defs"
>
>> projection(a) <- projection(a)
> Error in checkSlotAssignment(object, name, value) :
> ?"crs" is not a slot in class "SpatialPoints"
> Calls: projection<- -> @<- -> slot<- -> checkSlotAssignment

 Read the source. "projection" does a bunch of class tests (sure sign
of a broken OO model), returning x at crs for BasicRaster and
x at proj4string for Spatial classes.

 However, "projection<-" doesn't. It tries to assign to x at crs whatever.

Barry


From alobolistas at gmail.com  Sat May 29 19:20:40 2010
From: alobolistas at gmail.com (Agustin Lobo)
Date: Sat, 29 May 2010 10:20:40 -0700 (PDT)
Subject: [R-sig-Geo] reading KML files in R
In-Reply-To: <4C00C332.7010900@wildintellect.com>
References: <AANLkTikCyNsNdJk9lPGYYzOSfiDJCJ_VY1y7ey9kQKsh@mail.gmail.com>
	<4BFEB364.1080906@nceas.ucsb.edu>
	<alpine.LRH.2.00.1005272014000.7056@reclus.nhh.no>
	<AANLkTin3jgggXJlgHl7qqdRrZd2zcQINWgRSjJLCB0Ft@mail.gmail.com>
	<alpine.LRH.2.00.1005280908320.9550@reclus.nhh.no>
	<AANLkTiltEvT2rOz_X9668CaooGdTg8isumAu-IchNIRR@mail.gmail.com>
	<AANLkTilm2up1a5oOEAanEFNIYROMKREPyRQF43tLaklI@mail.gmail.com>
	<4C00C332.7010900@wildintellect.com>
Message-ID: <1275153640469-5116751.post@n2.nabble.com>


Right. I was confused by this thread
http://osgeo-org.1803224.n2.nabble.com/google-layers-plugin-projection-td5098024.html#a5113148

that mentions
EPSG:3857 (Google Mercator)
+proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0
+k=1.0 +units=m +nadgrids=@null +wktext +no_defs

but this is another story, not implying that kml files had to use such
projection.
Sorry for the noise.
Agus
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/reading-KML-files-in-R-tp5109680p5116751.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From r.hijmans at gmail.com  Sat May 29 19:54:28 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sat, 29 May 2010 10:54:28 -0700
Subject: [R-sig-Geo] projection() and proj4string()
In-Reply-To: <1275152569520-5116707.post@n2.nabble.com>
References: <AANLkTincjYWi3MqXI8TO1P_xLl1V-dQygfe4Dyfh8Xue@mail.gmail.com>
	<alpine.LRH.2.00.1005291257120.14661@reclus.nhh.no>
	<1275152569520-5116707.post@n2.nabble.com>
Message-ID: <AANLkTilwXpmDlHMEGEtwQac3zZM3EHL-Z2d63bsRSU31@mail.gmail.com>

I have implemented Roger's suggestion (in 'raster' version 1.1.5). I.e.

projection(x) <-  value

can now assign a new CRS to objects 'x' of class Spatial* as well as
class Raster*
value can be either a character string or an object of class CRS.

Robert

On Sat, May 29, 2010 at 10:02 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
>
> So, if I correctly understand, projection() can be used to retrieve
> information
> from an sp object but not to assign that info to a sp object:
>> projection(a)
> [1] "+proj=utm +zone=31 +ellps=intl +units=m +no_defs"
>
>> projection(a) <- projection(a)
> Error in checkSlotAssignment(object, name, value) :
> ?"crs" is not a slot in class "SpatialPoints"
> Calls: projection<- -> @<- -> slot<- -> checkSlotAssignment
>
>
> Roger Bivand wrote:
>>
>> .../...
>> Probably projection<-() needs the same if() statement as that used in
>> projection(), to distinguish extensions of "BasicRaster" from those of
>> "Spatial", in which case projection<-() and proj4string<-() will both work
>> on objects extending "Spatial" too.
>>
>> Roger
>>
>
> >From a user point of view, this would be certainly useful.
>
> Thanks!
>
> Agus
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/projection-and-proj4string-tp5115767p5116707.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From jacobvanetten at yahoo.com  Sat May 29 21:52:29 2010
From: jacobvanetten at yahoo.com (Jacob van Etten)
Date: Sat, 29 May 2010 12:52:29 -0700 (PDT)
Subject: [R-sig-Geo] projection() and proj4string()
In-Reply-To: <AANLkTilID0aiptGDDcBYtgCubXcsATxzif7IX2hg6bO5@mail.gmail.com>
Message-ID: <292059.14603.qm@web32901.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100529/5a59c921/attachment.pl>

From edzer.pebesma at uni-muenster.de  Sun May 30 01:34:40 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 30 May 2010 01:34:40 +0200
Subject: [R-sig-Geo] Better print method for Spatial*DataFrames?
In-Reply-To: <alpine.LRH.2.00.1005291138380.14661@reclus.nhh.no>
References: <AANLkTikrtxVdCpwymXAws7B_aa82CcsUVh4ENNyLj3Mx@mail.gmail.com>	<4BFE72EF.9070108@uni-muenster.de>
	<4BFFD769.1010906@gmail.com>	<alpine.LRH.2.00.1005281806580.11964@reclus.nhh.no>	<AANLkTik-wte4kJhYhyejdEX-QD3BGD8XxSc1uD51_Ff0@mail.gmail.com>	<alpine.LRH.2.00.1005291046050.14661@reclus.nhh.no>	<AANLkTinjSbnRg8H2FBNtFt8Phitm5e4YIhygAMTXd9Cx@mail.gmail.com>
	<alpine.LRH.2.00.1005291138380.14661@reclus.nhh.no>
Message-ID: <4C01A490.7090903@uni-muenster.de>

On 05/29/2010 11:47 AM, Roger Bivand wrote:

> On Sat, 29 May 2010, Barry Rowlingson wrote:
> 
>> On Sat, May 29, 2010 at 10:06 AM, Roger Bivand <Roger.Bivand at nhh.no>
>> wrote:
>>
>>
>>> In other software systems (octave, Stata, ...), one can turn on and
>>> off a
>>> more/less screen-by-screen displayer (not scrolling upwards, just
>>> chunking),
>>> but I'm not aware of an equivalent in R/S. I'm not sure how head() and
>>> tail() work in R,
>>
>> They don't seem to work very well at all for Spatial*DataFrames. If I
>> add coordinates to meuse to get a SpatialPointsDataFrame and
>> head(that) I get all the 'rows' but with only the cadmium
>> measurements. It's slicing it the wrong way. Odd.
>>
>>> and personally use str() by default. If I need to access
>>> the coordinates of a particular line or polygon, I print() just that
>>> list
>>> element (Line or Polygon object).
>>>
>>> I can see what you mean, but feel that users will benefit much more
>>> by using
>>> str(), which is a real gem!
>>
>> str is great if you need to know the str-ucture of an R object. But
>> it doesn't even align the values so you can see across rows of your
>> data, which is what I'd like print to do (by analogy with
>> print.data.frame).
>>
>> Currently if I print a SpatialPolygonsDataFrame I get the structure.
>> Print methods should do better than that - you're almost suggesting
>> not having, for example, a print method for data frames and that we'd
>> be better off having what print.default(anyDataFrame) gives us.
>>
>> So my proposal is that print of a SpatialPolygonsDataFrame class
>> should print like a data frame but with some indicator of the geometry
>> at the start of the row, such as POLYGON(...) - literally with dots,
>> there's no need to spell it out. Similarly for Lines.
>>
>> Another suggestion is for head() and tail methods on
>> Spatial*DataFrame objects - I think just subscripting [1:n,] from the
>> object and returning would do it. I think currently head and tail
>> treat these objects as lists and the results are not pretty.
> 
> Right, because they see S4 objects as lists with no components, only
> with attributes. str() does have support for S4 objects. They would need
> to be wrapped around an S4 show/print method, with the output captured,
> as in capture.output(). Would it make sense to have the default
> print/show for Spatial* be str() with max.level= set, and for
> Spatial*DataFrame be the print method for the data slot prepended with
> some text (perhaps POINT, MULTILINESTRING, MULTIPOLYGON, PIXEL, CELL, or
> better an abbreviation)?

In the following example:

require(maptools)
nc = readShapePoly(system.file("shapes/sids.shp", package =
"maptools")[1], IDvar="FIPSNO", proj4string=CRS("+proj=longlat
+ellps=clrk66"))
str(as(nc, "SpatialPolygons"))
as(nc, "SpatialPolygons")

I personally find the output of the (current) print method producing
much easier readable than that of str. Partly because I've grown
accustomed to it, but also partly because I have never liked the output
of str. I tend to use the current default show method used for
SpatialLines* and SpatialPolygons* (the generic show for S4 objects) to
figure out what the structure of the data is, not how to use it. So I
guess for those who want to use the data without bothering about the
deeper structure, these print methods (both: current show.S4 and str)
are not so useful. If you disagree with this: please respond!

As for Barry's proposal, I find it a bit repetitive (and space
consuming) to have a POINT(1 1) instead of the current (1,1) (which,
credits where credits go, is from a package Barry wrote that preceded
sp). I can very well understand that many people will not know how to
read WKT [1], as it again is something that programmers tend to find
useful, not users; to be right we need the awfully long words
MULTILINESTRING and MULTIPOLYGON to represent the sp classes, and then
can't write the whole string but need to abbreviate. I agree with Barry
that a representation as much as possible like a data.frame is most useful.

I suggest the folloging: for points:

  geometry attr1 attr2 attr3
PT(234 45)   333   xxy  22.5
PT(455 68)   221   xxx  13.2

for polygons: use PN(3;2335) to express that this MULTIPOLYGON consists
of 3 POLYGONS, and has 2335 coordinates (in total)

  geometry attr1 attr2 attr3
PN(3;2335)   333   xxy  22.5
PN(45;345)   221   xxx  13.2

for lines:

  geometry attr1 attr2 attr3
LI(3;2335)   333   xxy  22.5
LI (5;345)   221   xxx  13.2

for pixels: use points, replace PT with PX

for grids: don't print all the values, but a very short summary.

To really educate users that we "glue" data.frame attribute tables to
geometries, they need to see this, and therefore I want to print a
SpatialPoints object as:

  geometry
PT(234 45)
PT(455 68)

and do the same for SpatialLines and SpatialPolygons:

  geometry
PN(3;2335)
PN(45;345)

  geometry
LI(3;2335)
LI (5;345)

what head and tail should do is then obvious.

Next thing is that developers/programmers need to find out how to print
all the gory details -- they will need to use str(nc) or show(unclass(nc)).

For those from Europe: thank you for all the points in the song contest.
We also like Lena a lot, here at home.

[1] http://en.wikipedia.org/wiki/Well-known_text
-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From b.rowlingson at lancaster.ac.uk  Sun May 30 03:01:04 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sun, 30 May 2010 02:01:04 +0100
Subject: [R-sig-Geo] projection() and proj4string()
In-Reply-To: <292059.14603.qm@web32901.mail.mud.yahoo.com>
References: <AANLkTilID0aiptGDDcBYtgCubXcsATxzif7IX2hg6bO5@mail.gmail.com>
	<292059.14603.qm@web32901.mail.mud.yahoo.com>
Message-ID: <AANLkTin5r1hx_54Eo_Y22N-sgW4tENcZakHuEZc7K_5U@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100530/1158e210/attachment.pl>

From pslarson2 at gmail.com  Mon May 31 01:54:32 2010
From: pslarson2 at gmail.com (Peter Larson)
Date: Sun, 30 May 2010 19:54:32 -0400
Subject: [R-sig-Geo] ReadShapePoly subsetting data
In-Reply-To: <AANLkTin5r1hx_54Eo_Y22N-sgW4tENcZakHuEZc7K_5U@mail.gmail.com>
References: <AANLkTilID0aiptGDDcBYtgCubXcsATxzif7IX2hg6bO5@mail.gmail.com>	<292059.14603.qm@web32901.mail.mud.yahoo.com>
	<AANLkTin5r1hx_54Eo_Y22N-sgW4tENcZakHuEZc7K_5U@mail.gmail.com>
Message-ID: <4C02FAB8.8010500@gmail.com>

Hello all,

I have data for several states and no data for most. I just want to 
subset the states I have data for and ignore the rest.

Is there anyway to do this? I have a shapefile and have read it in with 
ReadShapePoly successfully, but I don't need all 50 American states.

Thanks,

Pete


From biozealot21 at gmail.com  Mon May 31 02:28:12 2010
From: biozealot21 at gmail.com (Matt Beard)
Date: Sun, 30 May 2010 20:28:12 -0400
Subject: [R-sig-Geo] ReadShapePoly subsetting data
In-Reply-To: <4C02FAB8.8010500@gmail.com>
References: <AANLkTilID0aiptGDDcBYtgCubXcsATxzif7IX2hg6bO5@mail.gmail.com>
	<292059.14603.qm@web32901.mail.mud.yahoo.com>
	<AANLkTin5r1hx_54Eo_Y22N-sgW4tENcZakHuEZc7K_5U@mail.gmail.com>
	<4C02FAB8.8010500@gmail.com>
Message-ID: <AANLkTiljI4cVlc_za6K2OJmJpzJQEXDlP-TwfZBNde3I@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100530/0afb1757/attachment.pl>

From cheluna at gmail.com  Mon May 31 02:28:39 2010
From: cheluna at gmail.com (Consuelo Hermosilla)
Date: Mon, 31 May 2010 02:28:39 +0200
Subject: [R-sig-Geo] FANTER? (adehabitat)
Message-ID: <AANLkTima0tKuryqqN3l2dV9xfV2QWtgKP9yf7cxoTpmq@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100531/4d973ce4/attachment.pl>

From pslarson2 at gmail.com  Mon May 31 03:01:21 2010
From: pslarson2 at gmail.com (Peter Larson)
Date: Sun, 30 May 2010 21:01:21 -0400
Subject: [R-sig-Geo] ReadShapePoly subsetting data
In-Reply-To: <AANLkTiljI4cVlc_za6K2OJmJpzJQEXDlP-TwfZBNde3I@mail.gmail.com>
References: <AANLkTilID0aiptGDDcBYtgCubXcsATxzif7IX2hg6bO5@mail.gmail.com>	<292059.14603.qm@web32901.mail.mud.yahoo.com>	<AANLkTin5r1hx_54Eo_Y22N-sgW4tENcZakHuEZc7K_5U@mail.gmail.com>	<4C02FAB8.8010500@gmail.com>
	<AANLkTiljI4cVlc_za6K2OJmJpzJQEXDlP-TwfZBNde3I@mail.gmail.com>
Message-ID: <4C030A61.9030006@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100530/185184be/attachment.pl>

From biozealot21 at gmail.com  Mon May 31 03:14:41 2010
From: biozealot21 at gmail.com (Matt Beard)
Date: Sun, 30 May 2010 21:14:41 -0400
Subject: [R-sig-Geo] ReadShapePoly subsetting data
In-Reply-To: <4C030A61.9030006@gmail.com>
References: <AANLkTilID0aiptGDDcBYtgCubXcsATxzif7IX2hg6bO5@mail.gmail.com>
	<292059.14603.qm@web32901.mail.mud.yahoo.com>
	<AANLkTin5r1hx_54Eo_Y22N-sgW4tENcZakHuEZc7K_5U@mail.gmail.com>
	<4C02FAB8.8010500@gmail.com>
	<AANLkTiljI4cVlc_za6K2OJmJpzJQEXDlP-TwfZBNde3I@mail.gmail.com>
	<4C030A61.9030006@gmail.com>
Message-ID: <AANLkTilzhRSZvMYHHisEdkCW9VtFkWWGuYlTAEky_D0-@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100530/fdf66695/attachment.pl>

From r.hijmans at gmail.com  Mon May 31 03:48:32 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sun, 30 May 2010 18:48:32 -0700
Subject: [R-sig-Geo] spatially balanced sampling to reduce geo-political
	bias
In-Reply-To: <9DF33C99B2BAE94CB9C5B27A154900DA02AA0BE7378E@mbx7.adf.bham.ac.uk>
References: <9DF33C99B2BAE94CB9C5B27A154900DA02AA0BE7378E@mbx7.adf.bham.ac.uk>
Message-ID: <AANLkTil01pr5s0C6lwPcaehr93-s39kgoodjM5IgXTCn@mail.gmail.com>

Dear Claire,

The below function uses a raster to stratify the region.
You can tune it by changing the resolution of the raster (res) and/or
n (the number of samples to take from each cell).


library(raster)

gridsample <- function(xy, res, n=1) {
	r = raster(extent(range(xy[,1]), range(xy[,2])) + res)
	res(r) = res
	cell = cellFromXY(r, xy)
	uc = unique(cell)
	xy = cbind(xy, cell, runif( nrow(xy)))
	xy =  xy[order(xy[,4]), ]
	pts = matrix(nrow=0, ncol=2)
	for (u in uc) {
		ss = subset(xy, xy[,3] == u)
		pts = rbind(pts, ss[1:min(n, nrow(ss)), 1:2])
	}
	return(pts)
}

x = rnorm(1000, 10, 5)
y = rnorm(1000, 50, 5)
xy = cbind(x,y)

# change the value of res (and/or n) untill nrow(s)
# approximates your desired number of samples
samp = gridsample(xy, res=5, n=1)
nrow(samp)

plot(xy, cex=0.1)
points(samp, pch='x', col='red')




On Sat, May 29, 2010 at 2:43 AM, Claire Teeling <CXT755 at bham.ac.uk> wrote:
> Dear all,
>
> I am carrying out some species distribution modelling based on a database of
> species occurrence records of a single tree species, encompassing the entire European
> continent. The records are primarily historical and heavily biased towards
> western, northern Europe. A few of the counts of records by country are shown
> below to illustrate.
>
> CHE ? ? 12
> CZE ? ? 1
> DEN ? ? 6
> DEU ? ? 1742
> DNK ? ? 12
> ESP ? ? 237
> FIN ? ? 1
> FRA ? ? 6536
> GBR ? ? 3294
> GEO ? ? 39
> GRC ? ? 47
> HUN ? ? 2
>
> I am very new to R and I'm trying to find a way to subsample in order to obtain
> a more spatially balanced sample of 300 records, from a total of 16794. I have
> looked at some packages, e.g. sp, spcosa, spsurvey, spdep, have searched the
> manuals and searched for similar examples.
> I have also tried to stratify the data but can't find a stratum which reduces
> the impact of the bias. I also have a field containing inclusion probabilities
> for each record, based on country.
> I just can't seem to work out how best to perform sampling to reduce the effect
> of geopolitical bias.
> Any advice, for an R novice, would be very gratefully received.
>
> Thanks,
>
> Claire
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From pslarson2 at gmail.com  Mon May 31 04:53:30 2010
From: pslarson2 at gmail.com (Peter Larson)
Date: Sun, 30 May 2010 22:53:30 -0400
Subject: [R-sig-Geo] ReadShapePoly subsetting data
In-Reply-To: <AANLkTilzhRSZvMYHHisEdkCW9VtFkWWGuYlTAEky_D0-@mail.gmail.com>
References: <AANLkTilID0aiptGDDcBYtgCubXcsATxzif7IX2hg6bO5@mail.gmail.com>	<292059.14603.qm@web32901.mail.mud.yahoo.com>	<AANLkTin5r1hx_54Eo_Y22N-sgW4tENcZakHuEZc7K_5U@mail.gmail.com>	<4C02FAB8.8010500@gmail.com>	<AANLkTiljI4cVlc_za6K2OJmJpzJQEXDlP-TwfZBNde3I@mail.gmail.com>	<4C030A61.9030006@gmail.com>
	<AANLkTilzhRSZvMYHHisEdkCW9VtFkWWGuYlTAEky_D0-@mail.gmail.com>
Message-ID: <4C0324AA.1050405@gmail.com>

It doesn't seem to work. This what I have though.

I have a STATE_NAME variable in the data that I could potentially use, 
assuming I know the write syntax.

Any ideas?

Thanks!

Pete

nc_file <- system.file("/LynchingHotSpots.shp", package="maptools")[1]
llCRS <- CRS("+proj=longlat +datum=NAD27")
nc <- readShapePoly("LynchingHotSpots.shp",  proj4string=llCRS)

statesWanted <- c("MN","WI")

nc <- nc[nc$STATE_NAME %in% statesWanted,]


print(spplot(nc, c("Lynchings")))


From macq at llnl.gov  Mon May 31 06:18:40 2010
From: macq at llnl.gov (Don MacQueen)
Date: Sun, 30 May 2010 21:18:40 -0700
Subject: [R-sig-Geo] ReadShapePoly subsetting data
In-Reply-To: <4C0324AA.1050405@gmail.com>
References: <AANLkTilID0aiptGDDcBYtgCubXcsATxzif7IX2hg6bO5@mail.gmail.com>
	<292059.14603.qm@web32901.mail.mud.yahoo.com>
	<AANLkTin5r1hx_54Eo_Y22N-sgW4tENcZakHuEZc7K_5U@mail.gmail.com>
	<4C02FAB8.8010500@gmail.com>
	<AANLkTiljI4cVlc_za6K2OJmJpzJQEXDlP-TwfZBNde3I@mail.gmail.com>
	<4C030A61.9030006@gmail.com>
	<AANLkTilzhRSZvMYHHisEdkCW9VtFkWWGuYlTAEky_D0-@mail.gmail.com>
	<4C0324AA.1050405@gmail.com>
Message-ID: <p06240800c828e7516ca4@[192.168.11.8]>


Supposing that your data object is named "mydata", try following this example:

   mydata[ , STATE_NAME %in% c('name1','name2','name17') ]

replacing my fake state names with the ones you want.

If you have another variable that identifies the subset you want, use 
it instead of STATE_NAME.

This example assumes you data is in a SpatialPolygonsDataFrame.

You haven't really provided enough information for more specific suggestions.

-Don

At 10:53 PM -0400 5/30/10, Peter Larson wrote:
>It doesn't seem to work. This what I have though.
>
>I have a STATE_NAME variable in the data that I could potentially 
>use, assuming I know the write syntax.
>
>Any ideas?
>
>Thanks!
>
>Pete
>
>nc_file <- system.file("/LynchingHotSpots.shp", package="maptools")[1]
>llCRS <- CRS("+proj=longlat +datum=NAD27")
>nc <- readShapePoly("LynchingHotSpots.shp",  proj4string=llCRS)
>
>statesWanted <- c("MN","WI")
>
>nc <- nc[nc$STATE_NAME %in% statesWanted,]
>
>
>print(spplot(nc, c("Lynchings")))
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at stat.math.ethz.ch
>https://*stat.ethz.ch/mailman/listinfo/r-sig-geo


-- 
---------------------------------
Don MacQueen
Lawrence Livermore National Laboratory
Livermore, CA, USA
925-423-1062
macq at llnl.gov


From biozealot21 at gmail.com  Mon May 31 06:32:30 2010
From: biozealot21 at gmail.com (Matt Beard)
Date: Mon, 31 May 2010 00:32:30 -0400
Subject: [R-sig-Geo] ReadShapePoly subsetting data
In-Reply-To: <p06240800c828e7516ca4@192.168.11.8>
References: <AANLkTilID0aiptGDDcBYtgCubXcsATxzif7IX2hg6bO5@mail.gmail.com>
	<292059.14603.qm@web32901.mail.mud.yahoo.com>
	<AANLkTin5r1hx_54Eo_Y22N-sgW4tENcZakHuEZc7K_5U@mail.gmail.com>
	<4C02FAB8.8010500@gmail.com>
	<AANLkTiljI4cVlc_za6K2OJmJpzJQEXDlP-TwfZBNde3I@mail.gmail.com>
	<4C030A61.9030006@gmail.com>
	<AANLkTilzhRSZvMYHHisEdkCW9VtFkWWGuYlTAEky_D0-@mail.gmail.com>
	<4C0324AA.1050405@gmail.com> <p06240800c828e7516ca4@192.168.11.8>
Message-ID: <AANLkTimqjSa34xgeNCE_DhI1db621NOkaLoTp_hmj1Wv@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100531/7d2cdd48/attachment.pl>

From clement.calenge at gmail.com  Mon May 31 09:43:43 2010
From: clement.calenge at gmail.com (=?ISO-8859-1?Q?Cl=E9ment_Calenge?=)
Date: Mon, 31 May 2010 09:43:43 +0200
Subject: [R-sig-Geo] FANTER? (adehabitat)
In-Reply-To: <AANLkTima0tKuryqqN3l2dV9xfV2QWtgKP9yf7cxoTpmq@mail.gmail.com>
References: <AANLkTima0tKuryqqN3l2dV9xfV2QWtgKP9yf7cxoTpmq@mail.gmail.com>
Message-ID: <4C0368AF.8010802@gmail.com>

On 05/31/2010 02:28 AM, Consuelo Hermosilla wrote:
> I have a doubt. I'd like to implement the FANTER analysis, described in
> Calenge&  Basille (2008), which should be a type of Gnesfa analysis, right?
> But I don't know how to implement it (in adehabitat)... the gnesfa default
> option is equivalent to FANTER?

No. Actually, depending on the distribution chosen, the GNESFA will 
correspond to the MADIFA or the FANTER.  Consider the examples of the 
help page of this function:

## Loads the data
data(bauges)
kasc <- bauges$kasc
locs <- bauges$locs

## Prepares the data for the GNESFA:
litab <- kasc2df(kasc)
pc <- dudi.pca(litab$tab, scannf = FALSE)
Dp <- count.points(locs, kasc)[litab$index]


In this case, pc stores the environmental information. Conceptually, it 
can be considered as a table storing the value of the environmental 
variables (columns) in each pixel of the map (rows). Dp is a vector 
containing the utilization weights, i.e. the number of animals in each 
pixel of the map. The MADIFA corresponds to a GNESFA with the reference 
distribution corresponding to the utilization weights, that is, to 
perform the MADIFA, type:

gn <- gnesfa(pc, Reference = Dp)

If you want to perform a FANTER, you have to set the utilization weights 
as the Focus distribution, that is:

gn <- gnesfa(pc, Focus = Dp)



>   I understand the modifications leading to
> ENFA and MADIFA (using gnesfa fuction), but I'm kind of lost in how to
> implemet FANTER...
> I know (following the paper) that I should keep the first and last
> eigenvalue, but what about the other options of the function?
>    

You can choose the number of first and last axes that you keep in your 
analysis, not necessarily only the first and last one.
The options nfFirst and nfLast are easier to understand if you do not 
set scannf=FALSE, so that the eigenvalue barplot is displayer. For 
example, if you can identify visually a clear "break" in the decrease of 
the eigenvalues after the second eigenvalue, then, it would be a good 
idea to keep the first two axes. Similarly, if you can identify a strong 
"break" in the increase of 1/eigenvalues just before the eigenvalue P-3 
(where P is the total number of eigenvalues), then it would be a good 
idea to keep the last three axes. Then factorial maps and other tools 
described on the help page and in the paper would help to interpret the 
results.
Hope this helps,


Cl?ment Calenge


From p.hiemstra at geo.uu.nl  Mon May 31 10:03:54 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 31 May 2010 10:03:54 +0200
Subject: [R-sig-Geo] from R to ArcMap
In-Reply-To: <A0F8DAFB525DED4ABAF6841BB11C5812044E7E73@mail4.marlab.ac.uk>
References: <A0F8DAFB525DED4ABAF6841BB11C5812044E7E73@mail4.marlab.ac.uk>
Message-ID: <4C036D6A.9060500@geo.uu.nl>

On 05/28/2010 10:58 AM, Rui Catarino wrote:
> Hello to all,
>
>
>
> Is there a way of transforming an output of levelplot function in a
> ArcMap raster?
>
> Basically I have a script from a colleague that uses data from surveys
> and transforms it into smooth levelplot's.
>
> I have look around but all I get is the opposite from ArcMap raster to
> R.
>    
Hi Rui,

If you have your data in the following format in a data.frame (which you 
do not specify):

x    y    z
1    1    3.42
1    2    4.51

You can transfer this to a SpatialPixelsDataFrame by:

coordinates(bla) = ~x+y

assuming your data.frame is named bla. See the documentation of the 
sp-package for more information. After this conversion you can export 
the data to any GIS raster format that your installation of rgdal supports.

cheers,
Paul
>
>
> Thanks in advance
>
> Rui
>
>
>
>
>
>
>
>
>
> Rui Catarino
>
> Scientific Officer
>
> Fishery Systems Group
>
> Marine Scotland - Science
>
>
>
> Scottish Government | 36 |B |Marine Laboratory, PO Box 101| 375,
> Victoria Road | Aberdeen AB11 9DB
>
>
>
> Tel:  +44 (0)1224 295572
>
> Mob:+44 (0)7530 240666
>
> Fax: +44 (0)1224 295511
>
> e: r.catarino at marlab.ac.uk
>
> w: http://www.scotland.gov.uk/marinescotland
> <http://www.scotland.gov.uk/marinescotland>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>    


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From cheluna at gmail.com  Mon May 31 10:39:18 2010
From: cheluna at gmail.com (Consuelo Hermosilla)
Date: Mon, 31 May 2010 10:39:18 +0200
Subject: [R-sig-Geo] FANTER? (adehabitat)
In-Reply-To: <4C0368AF.8010802@gmail.com>
References: <AANLkTima0tKuryqqN3l2dV9xfV2QWtgKP9yf7cxoTpmq@mail.gmail.com> 
	<4C0368AF.8010802@gmail.com>
Message-ID: <AANLkTimwV0f0r2d55-JcxddlthaGEm7OH0b8JCglZSf5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100531/1daca4d9/attachment.pl>

From pslarson2 at gmail.com  Mon May 31 14:27:26 2010
From: pslarson2 at gmail.com (Peter Larson)
Date: Mon, 31 May 2010 08:27:26 -0400
Subject: [R-sig-Geo] BYM Model Problem
In-Reply-To: <AANLkTimwV0f0r2d55-JcxddlthaGEm7OH0b8JCglZSf5@mail.gmail.com>
References: <AANLkTima0tKuryqqN3l2dV9xfV2QWtgKP9yf7cxoTpmq@mail.gmail.com>
	<4C0368AF.8010802@gmail.com>
	<AANLkTimwV0f0r2d55-JcxddlthaGEm7OH0b8JCglZSf5@mail.gmail.com>
Message-ID: <4C03AB2E.2080507@gmail.com>

Hello again,

I am working through the examples in Applied Spatial Data Analysis with 
R using my own data.

When I attempt to run the Besage-York-Mollie model in Chapter 11, I get 
an index out of range error in WinBugs.

How should I go about finding where the problem is?

Thanks!

Pete


From Virgilio.Gomez at uclm.es  Mon May 31 20:20:33 2010
From: Virgilio.Gomez at uclm.es (Virgilio Gomez Rubio)
Date: Mon, 31 May 2010 20:20:33 +0200
Subject: [R-sig-Geo] BYM Model Problem
In-Reply-To: <4C03AB2E.2080507@gmail.com>
References: <AANLkTima0tKuryqqN3l2dV9xfV2QWtgKP9yf7cxoTpmq@mail.gmail.com>
	<4C0368AF.8010802@gmail.com>
	<AANLkTimwV0f0r2d55-JcxddlthaGEm7OH0b8JCglZSf5@mail.gmail.com>
	<4C03AB2E.2080507@gmail.com>
Message-ID: <1275330033.6978.38.camel@Virgilio-Gomez>

Dear Peter,


> I am working through the examples in Applied Spatial Data Analysis with 
> R using my own data.
> 
> When I attempt to run the Besage-York-Mollie model in Chapter 11, I get 
> an index out of range error in WinBugs.
> 
> How should I go about finding where the problem is?

PLease, could you provide more information? In particular, are you
trying to reproduce the example in the book or adapting it to your own
data set? In that case, could you provide the code and data that you are
using (in a private e-mail, if you prefer)?

The error usually happens when there is some mismatch between the index
in the loop exceeds some vector size(i.e., looping over 20 areas when
there are just 15).

Best,

Virgilio


From pslarson2 at gmail.com  Mon May 31 22:19:46 2010
From: pslarson2 at gmail.com (Peter Larson)
Date: Mon, 31 May 2010 16:19:46 -0400
Subject: [R-sig-Geo] BYM Model Problem
In-Reply-To: <1275330033.6978.38.camel@Virgilio-Gomez>
References: <AANLkTima0tKuryqqN3l2dV9xfV2QWtgKP9yf7cxoTpmq@mail.gmail.com>	
	<4C0368AF.8010802@gmail.com>	
	<AANLkTimwV0f0r2d55-JcxddlthaGEm7OH0b8JCglZSf5@mail.gmail.com>	
	<4C03AB2E.2080507@gmail.com>
	<1275330033.6978.38.camel@Virgilio-Gomez>
Message-ID: <4C0419E2.3000703@gmail.com>

Hello,

I can get the example in the book to work fine, but it will not work 
with my data. I have loaded a shp file in using the code below but don't 
know if I can attach it to the whole list or not.

What could be going wrong?

Thank you very much for your help,

Pete


nc <- readShapePoly("LynchingHotSpots.shp",  proj4string=llCRS)

statesWanted <- c("Alabama","Mississippi","Louisiana","Georgia","Kentucky",
"North Carolina","South Carolina","Florida","Arkansas","Tennessee")

nc <- nc[nc at data$STATE_NAME %in% statesWanted,]

#names(nc)#Variables in the dataset

nc$Observed<-nc$Lynchings
nc$Population<-nc$POP1990   #Population at risk
r<-sum(nc$Observed)/sum(nc$Population)
nc$Expected<-nc$Population*r

#Computed Standardised Mortality Ratio
nc$SMR<-nc$Observed/nc$Expected

#######BESAG

nc.nb <- nb2WB(nc)
nc$nwprop <- nc$Lynchings/nc$POP1990
d<-list(N=N, observed=nc$Observed, expected=nc$Expected,
   nonwhite=nc$nwprop,#log(nwprop/(1-nwprop)),
   adj=nc.nb$adj,  weights=nc.nb$weights, num=nc.nb$num)

dwoutcov<-list(N=N, observed=nc$Observed, expected=nc$Expected,
   adj=nc.nb$adj,  weights=nc.nb$weights, num=nc.nb$num)

inits<-list(u=rep(0,N), v=rep(0,N), alpha=0, beta=0, precu=.001, 
precv=.001)
#inits$v[d$num==0]<-NA


#### Winbugs ####

  bymmodelfile<-paste(getwd(), "/besag.txt", sep="")
  wdir<-paste(getwd(), "/BYM", sep="")
  if(!file.exists(wdir)){dir.create(wdir)}
  BugsDir <- "C:/Users/Pete/Downloads/WinBUGS14"
  MCMCres<- bugs(data=d, inits=list(inits),
  working.directory=wdir,
  parameters.to.save=c("theta", "alpha", "beta", "u", "v", "sigmau", 
"sigmav"),
  n.chains=1, n.iter=30000, n.burnin=20000, n.thin=10,
  model.file=bymmodelfile,
  bugs.directory=BugsDir,
  WINEPATH="/usr/bin/winepath")
      save(file="BYM.RData", list=c("d", "inits", "MCMCres") )
#Load the data obtained by running WinBUGS in Windows
nc$BYMmean<-MCMCres$mean$theta
#nc$BYMmedian<-MCMCres$median$theta
nc$BYMumean<-MCMCres$mean$u
#nc$BYMumedian<-MCMCres$median$u
nc$BYMvmean<-MCMCres$mean$v
#nc$BYMvmedian<-MCMCres$median$v
On 2010/05/31 14:20, Virgilio Gomez Rubio wrote:

On 2010/05/31 14:20, Virgilio Gomez Rubio wrote:
> Dear Peter,
>
>
>    
>> I am working through the examples in Applied Spatial Data Analysis with
>> R using my own data.
>>
>> When I attempt to run the Besage-York-Mollie model in Chapter 11, I get
>> an index out of range error in WinBugs.
>>
>> How should I go about finding where the problem is?
>>      
> PLease, could you provide more information? In particular, are you
> trying to reproduce the example in the book or adapting it to your own
> data set? In that case, could you provide the code and data that you are
> using (in a private e-mail, if you prefer)?
>
> The error usually happens when there is some mismatch between the index
> in the loop exceeds some vector size(i.e., looping over 20 areas when
> there are just 15).
>
> Best,
>
> Virgilio
>


From Virgilio.Gomez at uclm.es  Mon May 31 22:21:53 2010
From: Virgilio.Gomez at uclm.es (Virgilio Gomez Rubio)
Date: Mon, 31 May 2010 22:21:53 +0200
Subject: [R-sig-Geo] BYM Model Problem
In-Reply-To: <4C0419E2.3000703@gmail.com>
References: <AANLkTima0tKuryqqN3l2dV9xfV2QWtgKP9yf7cxoTpmq@mail.gmail.com>
	<4C0368AF.8010802@gmail.com>
	<AANLkTimwV0f0r2d55-JcxddlthaGEm7OH0b8JCglZSf5@mail.gmail.com>
	<4C03AB2E.2080507@gmail.com> <1275330033.6978.38.camel@Virgilio-Gomez>
	<4C0419E2.3000703@gmail.com>
Message-ID: <1275337313.6978.52.camel@Virgilio-Gomez>

Hi Peter,

You will probably need to define 'N' as the number of areas in your
problem. For this, you could use 

N<-nrow(nc at data)

This is the most likely cause for your problem, as I mentioned in my
previous e-mail


Also, please use these two lines to get the neighbour list in WB format:

nc.neig<-poly2nb(nc)
nc.nb <- nb2WB(nc.neig)


I believe that your code will work with these changes.

Best,

Virgilio

El lun, 31-05-2010 a las 16:19 -0400, Peter Larson escribi?: 
> Hello,
> 
> I can get the example in the book to work fine, but it will not work 
> with my data. I have loaded a shp file in using the code below but don't 
> know if I can attach it to the whole list or not.
> 
> What could be going wrong?
> 
> Thank you very much for your help,
> 
> Pete
> 
> 
> nc <- readShapePoly("LynchingHotSpots.shp",  proj4string=llCRS)
> 
> statesWanted <- c("Alabama","Mississippi","Louisiana","Georgia","Kentucky",
> "North Carolina","South Carolina","Florida","Arkansas","Tennessee")
> 
> nc <- nc[nc at data$STATE_NAME %in% statesWanted,]
> 
> #names(nc)#Variables in the dataset
> 
> nc$Observed<-nc$Lynchings
> nc$Population<-nc$POP1990   #Population at risk
> r<-sum(nc$Observed)/sum(nc$Population)
> nc$Expected<-nc$Population*r
> 
> #Computed Standardised Mortality Ratio
> nc$SMR<-nc$Observed/nc$Expected
> 
> #######BESAG
> 
> nc.nb <- nb2WB(nc)
> nc$nwprop <- nc$Lynchings/nc$POP1990
> d<-list(N=N, observed=nc$Observed, expected=nc$Expected,
>    nonwhite=nc$nwprop,#log(nwprop/(1-nwprop)),
>    adj=nc.nb$adj,  weights=nc.nb$weights, num=nc.nb$num)
> 
> dwoutcov<-list(N=N, observed=nc$Observed, expected=nc$Expected,
>    adj=nc.nb$adj,  weights=nc.nb$weights, num=nc.nb$num)
> 
> inits<-list(u=rep(0,N), v=rep(0,N), alpha=0, beta=0, precu=.001, 
> precv=.001)
> #inits$v[d$num==0]<-NA
> 
> 
> #### Winbugs ####
> 
>   bymmodelfile<-paste(getwd(), "/besag.txt", sep="")
>   wdir<-paste(getwd(), "/BYM", sep="")
>   if(!file.exists(wdir)){dir.create(wdir)}
>   BugsDir <- "C:/Users/Pete/Downloads/WinBUGS14"
>   MCMCres<- bugs(data=d, inits=list(inits),
>   working.directory=wdir,
>   parameters.to.save=c("theta", "alpha", "beta", "u", "v", "sigmau", 
> "sigmav"),
>   n.chains=1, n.iter=30000, n.burnin=20000, n.thin=10,
>   model.file=bymmodelfile,
>   bugs.directory=BugsDir,
>   WINEPATH="/usr/bin/winepath")
>       save(file="BYM.RData", list=c("d", "inits", "MCMCres") )
> #Load the data obtained by running WinBUGS in Windows
> nc$BYMmean<-MCMCres$mean$theta
> #nc$BYMmedian<-MCMCres$median$theta
> nc$BYMumean<-MCMCres$mean$u
> #nc$BYMumedian<-MCMCres$median$u
> nc$BYMvmean<-MCMCres$mean$v
> #nc$BYMvmedian<-MCMCres$median$v
> On 2010/05/31 14:20, Virgilio Gomez Rubio wrote:
> 
> On 2010/05/31 14:20, Virgilio Gomez Rubio wrote:
> > Dear Peter,
> >
> >
> >    
> >> I am working through the examples in Applied Spatial Data Analysis with
> >> R using my own data.
> >>
> >> When I attempt to run the Besage-York-Mollie model in Chapter 11, I get
> >> an index out of range error in WinBugs.
> >>
> >> How should I go about finding where the problem is?
> >>      
> > PLease, could you provide more information? In particular, are you
> > trying to reproduce the example in the book or adapting it to your own
> > data set? In that case, could you provide the code and data that you are
> > using (in a private e-mail, if you prefer)?
> >
> > The error usually happens when there is some mismatch between the index
> > in the loop exceeds some vector size(i.e., looping over 20 areas when
> > there are just 15).
> >
> > Best,
> >
> > Virgilio
> >    
> 


From pslarson2 at gmail.com  Mon May 31 22:26:09 2010
From: pslarson2 at gmail.com (Peter Larson)
Date: Mon, 31 May 2010 16:26:09 -0400
Subject: [R-sig-Geo] BYM Model Problem
In-Reply-To: <1275337313.6978.52.camel@Virgilio-Gomez>
References: <AANLkTima0tKuryqqN3l2dV9xfV2QWtgKP9yf7cxoTpmq@mail.gmail.com>	
	<4C0368AF.8010802@gmail.com>	
	<AANLkTimwV0f0r2d55-JcxddlthaGEm7OH0b8JCglZSf5@mail.gmail.com>	
	<4C03AB2E.2080507@gmail.com>
	<1275330033.6978.38.camel@Virgilio-Gomez>	
	<4C0419E2.3000703@gmail.com>
	<1275337313.6978.52.camel@Virgilio-Gomez>
Message-ID: <4C041B61.6020702@gmail.com>

Virgilio,

It appears to be working now. Thank you very much for your help.

Pete



On 2010/05/31 16:21, Virgilio Gomez Rubio wrote:
> Hi Peter,
>
> You will probably need to define 'N' as the number of areas in your
> problem. For this, you could use
>
> N<-nrow(nc at data)
>
> This is the most likely cause for your problem, as I mentioned in my
> previous e-mail
>
>
> Also, please use these two lines to get the neighbour list in WB format:
>
> nc.neig<-poly2nb(nc)
> nc.nb<- nb2WB(nc.neig)
>
>
> I believe that your code will work with these changes.
>
> Best,
>
> Virgilio
>
> El lun, 31-05-2010 a las 16:19 -0400, Peter Larson escribi?:
>    
>> Hello,
>>
>> I can get the example in the book to work fine, but it will not work
>> with my data. I have loaded a shp file in using the code below but don't
>> know if I can attach it to the whole list or not.
>>
>> What could be going wrong?
>>
>> Thank you very much for your help,
>>
>> Pete
>>
>>
>> nc<- readShapePoly("LynchingHotSpots.shp",  proj4string=llCRS)
>>
>> statesWanted<- c("Alabama","Mississippi","Louisiana","Georgia","Kentucky",
>> "North Carolina","South Carolina","Florida","Arkansas","Tennessee")
>>
>> nc<- nc[nc at data$STATE_NAME %in% statesWanted,]
>>
>> #names(nc)#Variables in the dataset
>>
>> nc$Observed<-nc$Lynchings
>> nc$Population<-nc$POP1990   #Population at risk
>> r<-sum(nc$Observed)/sum(nc$Population)
>> nc$Expected<-nc$Population*r
>>
>> #Computed Standardised Mortality Ratio
>> nc$SMR<-nc$Observed/nc$Expected
>>
>> #######BESAG
>>
>> nc.nb<- nb2WB(nc)
>> nc$nwprop<- nc$Lynchings/nc$POP1990
>> d<-list(N=N, observed=nc$Observed, expected=nc$Expected,
>>     nonwhite=nc$nwprop,#log(nwprop/(1-nwprop)),
>>     adj=nc.nb$adj,  weights=nc.nb$weights, num=nc.nb$num)
>>
>> dwoutcov<-list(N=N, observed=nc$Observed, expected=nc$Expected,
>>     adj=nc.nb$adj,  weights=nc.nb$weights, num=nc.nb$num)
>>
>> inits<-list(u=rep(0,N), v=rep(0,N), alpha=0, beta=0, precu=.001,
>> precv=.001)
>> #inits$v[d$num==0]<-NA
>>
>>
>> #### Winbugs ####
>>
>>    bymmodelfile<-paste(getwd(), "/besag.txt", sep="")
>>    wdir<-paste(getwd(), "/BYM", sep="")
>>    if(!file.exists(wdir)){dir.create(wdir)}
>>    BugsDir<- "C:/Users/Pete/Downloads/WinBUGS14"
>>    MCMCres<- bugs(data=d, inits=list(inits),
>>    working.directory=wdir,
>>    parameters.to.save=c("theta", "alpha", "beta", "u", "v", "sigmau",
>> "sigmav"),
>>    n.chains=1, n.iter=30000, n.burnin=20000, n.thin=10,
>>    model.file=bymmodelfile,
>>    bugs.directory=BugsDir,
>>    WINEPATH="/usr/bin/winepath")
>>        save(file="BYM.RData", list=c("d", "inits", "MCMCres") )
>> #Load the data obtained by running WinBUGS in Windows
>> nc$BYMmean<-MCMCres$mean$theta
>> #nc$BYMmedian<-MCMCres$median$theta
>> nc$BYMumean<-MCMCres$mean$u
>> #nc$BYMumedian<-MCMCres$median$u
>> nc$BYMvmean<-MCMCres$mean$v
>> #nc$BYMvmedian<-MCMCres$median$v
>> On 2010/05/31 14:20, Virgilio Gomez Rubio wrote:
>>
>> On 2010/05/31 14:20, Virgilio Gomez Rubio wrote:
>>      
>>> Dear Peter,
>>>
>>>
>>>
>>>        
>>>> I am working through the examples in Applied Spatial Data Analysis with
>>>> R using my own data.
>>>>
>>>> When I attempt to run the Besage-York-Mollie model in Chapter 11, I get
>>>> an index out of range error in WinBugs.
>>>>
>>>> How should I go about finding where the problem is?
>>>>
>>>>          
>>> PLease, could you provide more information? In particular, are you
>>> trying to reproduce the example in the book or adapting it to your own
>>> data set? In that case, could you provide the code and data that you are
>>> using (in a private e-mail, if you prefer)?
>>>
>>> The error usually happens when there is some mismatch between the index
>>> in the loop exceeds some vector size(i.e., looping over 20 areas when
>>> there are just 15).
>>>
>>> Best,
>>>
>>> Virgilio
>>>
>>>        
>>      
>


