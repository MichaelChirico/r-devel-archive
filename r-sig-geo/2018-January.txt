From bernard2120 at outlook.com  Tue Jan  2 18:08:35 2018
From: bernard2120 at outlook.com (bernard julien)
Date: Tue, 2 Jan 2018 17:08:35 +0000
Subject: [R-sig-Geo] how to access source code to the 'variogramLine'
	function in Gstat ?
Message-ID: <CY4PR05MB335104F3206B22159143D215B1190@CY4PR05MB3351.namprd05.prod.outlook.com>

Good day all,


I would like to access the source code used by the 'variogramLine' function  (Gstat package) to compute covariance matrices.

There is the following which I found : https://github.com/edzer/gstat/blob/master/R/variogramLine.R

However, I am looking for the direct code used to define the covariance computations.


cheers

Bernard




	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Tue Jan  2 18:28:21 2018
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 2 Jan 2018 18:28:21 +0100
Subject: [R-sig-Geo] how to access source code to the 'variogramLine'
 function in Gstat ?
In-Reply-To: <CY4PR05MB335104F3206B22159143D215B1190@CY4PR05MB3351.namprd05.prod.outlook.com>
References: <CY4PR05MB335104F3206B22159143D215B1190@CY4PR05MB3351.namprd05.prod.outlook.com>
Message-ID: <06324077-dd4f-d33b-7807-e2fb8725172f@uni-muenster.de>

Bernard,

https://github.com/edzer/gstat/blob/master/src/vario_fn.c

gets you all the unit functions; they get multiplied by their partial
sill value, and added up here:

https://github.com/edzer/gstat/blob/master/src/vario.c#L286-L308

the C function interfacing R is here:

https://github.com/edzer/gstat/blob/master/src/s.c#L709



On 01/02/2018 06:08 PM, bernard julien wrote:
> Good day all,
> 
> 
> I would like to access the source code used by the 'variogramLine' function  (Gstat package) to compute covariance matrices.
> 
> There is the following which I found : https://github.com/edzer/gstat/blob/master/R/variogramLine.R
> 
> However, I am looking for the direct code used to define the covariance computations.
> 
> 
> cheers
> 
> Bernard
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48151 Muenster, Germany
Phone: +49 251 8333081


From bernard2120 at outlook.com  Tue Jan  2 19:12:54 2018
From: bernard2120 at outlook.com (bernard julien)
Date: Tue, 2 Jan 2018 18:12:54 +0000
Subject: [R-sig-Geo] how to access source code to the 'variogramLine'
 function in Gstat ?
In-Reply-To: <06324077-dd4f-d33b-7807-e2fb8725172f@uni-muenster.de>
References: <CY4PR05MB335104F3206B22159143D215B1190@CY4PR05MB3351.namprd05.prod.outlook.com>,
 <06324077-dd4f-d33b-7807-e2fb8725172f@uni-muenster.de>
Message-ID: <CY4PR05MB335181A3076D44B4CDFADF53B1190@CY4PR05MB3351.namprd05.prod.outlook.com>

Edzer,

thank you.

________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of Edzer Pebesma <edzer.pebesma at uni-muenster.de>
Sent: Tuesday, January 2, 2018 9:28:21 AM
To: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] how to access source code to the 'variogramLine' function in Gstat ?

Bernard,

https://github.com/edzer/gstat/blob/master/src/vario_fn.c

gets you all the unit functions; they get multiplied by their partial
sill value, and added up here:

https://github.com/edzer/gstat/blob/master/src/vario.c#L286-L308

the C function interfacing R is here:

https://github.com/edzer/gstat/blob/master/src/s.c#L709



On 01/02/2018 06:08 PM, bernard julien wrote:
> Good day all,
>
>
> I would like to access the source code used by the 'variogramLine' function  (Gstat package) to compute covariance matrices.
>
> There is the following which I found : https://github.com/edzer/gstat/blob/master/R/variogramLine.R
>
> However, I am looking for the direct code used to define the covariance computations.
>
>
> cheers
>
> Bernard
>
>
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

--
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48151 Muenster, Germany
Phone: +49 251 8333081

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From rafa.pereira.br at gmail.com  Wed Jan  3 12:37:04 2018
From: rafa.pereira.br at gmail.com (Rafael Pereira)
Date: Wed, 3 Jan 2018 09:37:04 -0200
Subject: [R-sig-Geo] standard errors of total impacts in a spatial lag
	regression model lagsarlm
Message-ID: <CAA42DGkS345AxhdhsXcsQ4MwQO2kMkKcERU7knBd2Ou2=bmbHg@mail.gmail.com>

Dear all,

I am using a spatial lag regression model in a paper. I know already how to
get the total impacts of the model, but I don't know how to generate the
standard errors of the total impacts.

In this paper by Roger Bivand here*, these SE were "calculated using the
'estimable' function in the R gmodels package." I've checked the function
documentation but I couldn't really get my head around how to use it on
a lagsarlm lag model.

Can someone give me hand? There is a reproducible example below, but if any
of you could share a snippet of code you have already used this would be
very helpful already.

# reproducible example
data(oldcol)
COL.lag.eig <- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD, type="lag",
                        nb2listw(COL.nb, style="W"), method="eigen",
quiet=FALSE)
summary(COL.lag.eig, correlation=TRUE)



* http://openjournals.wu.ac.at/region/paper_107/107.html

best wishes,

Rafael H M Pereira

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Wed Jan  3 13:32:47 2018
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 3 Jan 2018 13:32:47 +0100
Subject: [R-sig-Geo] standard errors of total impacts in a spatial lag
 regression model lagsarlm
In-Reply-To: <CAA42DGkS345AxhdhsXcsQ4MwQO2kMkKcERU7knBd2Ou2=bmbHg@mail.gmail.com>
References: <CAA42DGkS345AxhdhsXcsQ4MwQO2kMkKcERU7knBd2Ou2=bmbHg@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.1801031326300.30685@reclus.nhh.no>

On Wed, 3 Jan 2018, Rafael Pereira wrote:

> Dear all,
>
> I am using a spatial lag regression model in a paper. I know already how to
> get the total impacts of the model, but I don't know how to generate the
> standard errors of the total impacts.
>
> In this paper by Roger Bivand here*, these SE were "calculated using the
> 'estimable' function in the R gmodels package." I've checked the function
> documentation but I couldn't really get my head around how to use it on
> a lagsarlm lag model.

Wrong reference - those are for SLX and SDEM models, but use the 
appropriate impacts() methods. See ?impacts. Remember to create a vector 
of traces, and help your head by (re)-reading LeSage & Pace 2009, and 
https://www.jstatsoft.org/index.php/jss/article/view/v063i18, p. 8 and 
section 5.

Hope this helps,

Roger

>
> Can someone give me hand? There is a reproducible example below, but if any
> of you could share a snippet of code you have already used this would be
> very helpful already.
>
> # reproducible example
> data(oldcol)
> COL.lag.eig <- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD, type="lag",
>                        nb2listw(COL.nb, style="W"), method="eigen",
> quiet=FALSE)
> summary(COL.lag.eig, correlation=TRUE)
>
>
>
> * http://openjournals.wu.ac.at/region/paper_107/107.html
>
> best wishes,
>
> Rafael H M Pereira
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From rafa.pereira.br at gmail.com  Thu Jan  4 13:17:50 2018
From: rafa.pereira.br at gmail.com (Rafael Pereira)
Date: Thu, 4 Jan 2018 10:17:50 -0200
Subject: [R-sig-Geo] standard errors of total impacts in a spatial lag
 regression model lagsarlm
In-Reply-To: <alpine.LFD.2.21.1801031326300.30685@reclus.nhh.no>
References: <CAA42DGkS345AxhdhsXcsQ4MwQO2kMkKcERU7knBd2Ou2=bmbHg@mail.gmail.com>
 <alpine.LFD.2.21.1801031326300.30685@reclus.nhh.no>
Message-ID: <CAA42DG=tjzc32dqs19V4g-t0OLp4vmPcJDrz5wALBJWe9G-w-Q@mail.gmail.com>

Thank you, Roger!

I will look into this .

best wishes,

Rafael H M Pereira

On Wed, Jan 3, 2018 at 10:32 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Wed, 3 Jan 2018, Rafael Pereira wrote:
>
> Dear all,
>>
>> I am using a spatial lag regression model in a paper. I know already how
>> to
>> get the total impacts of the model, but I don't know how to generate the
>> standard errors of the total impacts.
>>
>> In this paper by Roger Bivand here*, these SE were "calculated using the
>> 'estimable' function in the R gmodels package." I've checked the function
>> documentation but I couldn't really get my head around how to use it on
>> a lagsarlm lag model.
>>
>
> Wrong reference - those are for SLX and SDEM models, but use the
> appropriate impacts() methods. See ?impacts. Remember to create a vector of
> traces, and help your head by (re)-reading LeSage & Pace 2009, and
> https://www.jstatsoft.org/index.php/jss/article/view/v063i18, p. 8 and
> section 5.
>
> Hope this helps,
>
> Roger
>
>
>> Can someone give me hand? There is a reproducible example below, but if
>> any
>> of you could share a snippet of code you have already used this would be
>> very helpful already.
>>
>> # reproducible example
>> data(oldcol)
>> COL.lag.eig <- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD, type="lag",
>>                        nb2listw(COL.nb, style="W"), method="eigen",
>> quiet=FALSE)
>> summary(COL.lag.eig, correlation=TRUE)
>>
>>
>>
>> * http://openjournals.wu.ac.at/region/paper_107/107.html
>>
>> best wishes,
>>
>> Rafael H M Pereira
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
> Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>

	[[alternative HTML version deleted]]


From laura.poggio at gmail.com  Thu Jan  4 15:08:03 2018
From: laura.poggio at gmail.com (Laura Poggio)
Date: Thu, 4 Jan 2018 14:08:03 +0000
Subject: [R-sig-Geo] error when using fit.variogram.gls
Message-ID: <CAKmfgFNf6+Tj=-q1idQqD0VVcP-=_1Vrbyi_t3M2bQCqdZ6=_A@mail.gmail.com>

Dear all,
I was trying to use the function fit.variogram.gls from gstat package, and
I got the error below:
"Error in gamfn(h0, theta) : could not find function "gamfn""

Below some lines of code that trigger the error:
library(gstat)
library(sp)
data(meuse)
coordinates(meuse) = ~x+y
fit.variogram.gls(log(zinc)~1, meuse[1:40,], vgm(1, "Sph", 900,1))

My sessionInfo():
R version 3.4.2 (2017-09-28)
Platform: x86_64-redhat-linux-gnu (64-bit)
Running under: CentOS Linux 7 (Core)

Matrix products: default
BLAS/LAPACK: /usr/lib64/R/lib/libRblas.so

locale:
 [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8
 [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_GB.UTF-8
 [7] LC_PAPER=en_GB.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] gstat_1.1-5 sp_1.2-5

loaded via a namespace (and not attached):
[1] zoo_1.8-0        compiler_3.4.2   tools_3.4.2      xts_0.10-0
[5] spacetime_1.2-1  grid_3.4.2       FNN_1.1          intervals_0.15.1
[9] lattice_0.20-35

The same is happening also under Fedora 27 (Workstation Edition).

Thank you in advance and best wishes

Laura

	[[alternative HTML version deleted]]


From rlmanzione at gmail.com  Fri Jan  5 19:15:03 2018
From: rlmanzione at gmail.com (Rodrigo Lilla Manzione)
Date: Fri, 5 Jan 2018 16:15:03 -0200
Subject: [R-sig-Geo] STKriging export
Message-ID: <CABf+oy4-=LCog1w1V8nr3JHHy3skSqRZG21Wf-FXe4_Tr9PsRQ@mail.gmail.com>

Dear list,

I am facing a doubt about what I am producing when performing STKriging.
Probably my mistake is when setting ST prediction frame.

I have groundwater monitoring time series from Sep 2014 to Sep 207 in a
semi-monthly observed frequency at 56 wells. I would like to have a
prediction in the end of the series and a forecast  about 100 days in
advance.

This is my code and data can be found at:
https://www.dropbox.com/sh/tz3lufzaup677aa/AAAC6CgkZ_XrIM2-8jvS1VbFa?dl=0

##############
library(gstat)
library(sp)
library(spacetime)

#data load#
#input data, space and time#
level <- read.table("water_level_up.csv", header=T)
s <- read.table("UTM_up.csv", header=T, row.names=1, sep=",")
d = read.table("dates_up.csv",sep=",", header=T)

#set time#
nr = nrow(d)
dates <- as.Date(d[1,1])
for (i in 2:nr){
dates[i]<- as.Date(d[i,1])
}

#set space#
stations <- SpatialPoints(s, proj4string=CRS(as.character(NA)), bbox = NULL)

#merge time, space and data#
water = STFDF(stations, dates, data.frame(level = as.vector(level)))


#GIS#
#load area mask#
mask = read.asciigrid("g_50.asc", as.image=F, plot.image=T)
image(mask, col="black")

#shows area and sample points#
spplot(mask, scales = list(draw=T), sp.layout=list("sp.points", stations,
pch="+"))


#ST modelling#
#empirical st-variogram#
empVgm <- variogramST(level~1, water, tlags=0:38,cutoff=2400)
plot(empVgm, wireframe=T,
scales=list(arrows=F),zlab=list(rot=90),zlim=c(0,3))

#covariance functions#
#product-sum model#
prodSumModel <- vgmST("productSum",
space = vgm(0.75, "Sph", 1250, 0.05),
time = vgm(1.45, "Sph", 120, 0.0),
k = 2)
psFit <- fit.StVariogram(empVgm, prodSumModel, fit.method = 7,
stAni = 117, method = "L-BFGS-B",
control = list(parscale=c(1,10,1,1,0.1,1,10)),
lower = rep(0.0001,7))

plot(empVgm, psFit)
plot(empVgm, psFit, wireframe=TRUE, all=TRUE)


#ST prediction#
#ST kriging#
#setting ST prediction frame#
t <- water[,"2017-09-04/2017-12-13"]
tt <- as.Date("2017-09-04")
tt[2] <- as.Date("2017-12-13")
pred <- STF(sp=as(mask,"SpatialPoints"), time=tt)

#Product-Sum model prediction#
predPS <- krigeST(level~1, as(t,'STSDF'), pred, psFit)
stplot(predPS)

#Data export#
#'*.csv'#
write.csv(predPS, "STkrigePS.csv")
############

When I plot the maps I have one map for Sep 13 and another on for Dec 13.
Perfect. When I export it, I have in the .cvs file two sequences of data,
one with time starting at Sep 04 and time ending at Dec13 and another one
starting at Dec 13 and ending at March 13.

My question is, whay am I exporting? Is these layers predictions for the
ending date based on the set up period variability? Or it is something
else? Of course I can have predictions for the date I choose setting the
rigth period if that is the case, but I would like to understand better
what I am missing when setting the ST prediction frame

Thanks in advance,

Rodrigo Manzione, PhD
Associate professor
UNESP/FCE-Tup?
Brazil

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Livre
de v?rus. www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>.
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Sat Jan  6 20:11:24 2018
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sat, 6 Jan 2018 20:11:24 +0100
Subject: [R-sig-Geo] =?utf-8?q?EGU_session=3A_R=E2=80=99s_deliberate_role_?=
 =?utf-8?q?in_Earth_sciences=3B_abstract_deadline_Jan_10?=
Message-ID: <9d186927-6b99-8f7b-c2ce-8212786363e4@uni-muenster.de>

Last year this session was held for the first time, and it was a lot of
fun; although it started 8:15 we had around 250 visitors pretty soon,
and a lot of good discussions.

This year the session is again organized:

http://meetingorganizer.copernicus.org/EGU2018/session/27584

Note that you can submit to a PICO session in addition to an oral
preference in another session.

I hope to see you in Vienna!
-- 
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48151 Muenster, Germany
Phone: +49 251 8333081


From ghiaco at gmail.com  Wed Jan 10 17:32:36 2018
From: ghiaco at gmail.com (Sima Usvyatsov)
Date: Wed, 10 Jan 2018 12:32:36 -0400
Subject: [R-sig-Geo] Spatial filtering with glm with grid sampling
Message-ID: <CAFGTTqTvUfdnZEn9LxHL=wwwr8GykffPsf81kF1nOniUP9GLvg@mail.gmail.com>

Hello,

I am running a negative binomial model (MASS) on count data collected on a
grid. The dataset is large - ~4,000 points, with many predictors. Being
counts, there are a lot of zeroes. All data are collected on a grid with 20
points, with high spatial autocorrelation.

I would like to filter out the spatial autocorrelation. My question is:
since I have very limited spatial info (only 20 distinct spatial
locations), is it possible to simplify ME() so that I don't have to run it
on the whole dataset? When I try to run ME() on a 100-point subset of the
data, I get error in glm.fit: NA/NaN/Inf in 'x'. When I run it on a single
instance of the grid, I "get away" with a warning ("algorithm did not
converge").

Here's a fake dataset. It was grinding for a while but not throwing errors
(like my original data would). Regardless, it demonstrates the repeated
sampling at the same points and the large number of zeroes.

Any advice would be most welcome.

library(spdep)
library(MASS)

df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat = rnorm(100, 30,
0.1), Lon = rnorm(1000, -75, 1), x = rnegbin(100, 1, 1))
coordinates(df) <- ~Lon + Lat
proj4string(df) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
nb <- dnearneigh(x=coordinates(df), d1=0, d2=200,longlat = TRUE)
dists <- nbdists(nb, coordinates(df), longlat=TRUE)
glist <- lapply(dists, function(x) 1/x)
lw <- nb2listw(nb, glist, style="W")
me <- ME(x ~ 1, data = df, family = "quasipoisson", listw = lw, alpha = 0.5)

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Thu Jan 11 10:01:13 2018
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 11 Jan 2018 10:01:13 +0100
Subject: [R-sig-Geo] Spatial filtering with glm with grid sampling
In-Reply-To: <CAFGTTqTvUfdnZEn9LxHL=wwwr8GykffPsf81kF1nOniUP9GLvg@mail.gmail.com>
References: <CAFGTTqTvUfdnZEn9LxHL=wwwr8GykffPsf81kF1nOniUP9GLvg@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.1801110944550.22121@reclus.nhh.no>

On Wed, 10 Jan 2018, Sima Usvyatsov wrote:

> Hello,
>
> I am running a negative binomial model (MASS) on count data collected on a
> grid. The dataset is large - ~4,000 points, with many predictors. Being
> counts, there are a lot of zeroes. All data are collected on a grid with 20
> points, with high spatial autocorrelation.
>
> I would like to filter out the spatial autocorrelation. My question is:
> since I have very limited spatial info (only 20 distinct spatial
> locations), is it possible to simplify ME() so that I don't have to run it
> on the whole dataset? When I try to run ME() on a 100-point subset of the
> data, I get error in glm.fit: NA/NaN/Inf in 'x'. When I run it on a single
> instance of the grid, I "get away" with a warning ("algorithm did not
> converge").
>
> Here's a fake dataset. It was grinding for a while but not throwing errors
> (like my original data would). Regardless, it demonstrates the repeated
> sampling at the same points and the large number of zeroes.

The data set has 1000 values in Lon, so is probably bigger than you 
intended, and when 100 is used is not autocorrelated. You seem to have a 
hierarchical model, with repeated measurements at the locations, so a 
multi-level treatment of some kind may be sensible. If you want to stay 
with ME-based spatial filtering, maybe look at the literature on spatial 
panel (repeated measurements are in time) with ME/SF, and on network 
autocorrelation (dyadic relationships with autocorrelation among origins 
and/or destinations). Both these cases use Kronecker products on the 
selected eigenvectors, I think.

Alternatively, use a standard GLMM with a grouped iid random effect and/or 
a spatially structured random effect at the 20 location level. If the 
groups are repeated observations in time, you should model the whole 
(non-)separable space-time process.

Hope this helps,

Roger

>
> Any advice would be most welcome.
>
> library(spdep)
> library(MASS)
>
> df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat = rnorm(100, 30,
> 0.1), Lon = rnorm(1000, -75, 1), x = rnegbin(100, 1, 1))
> coordinates(df) <- ~Lon + Lat
> proj4string(df) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
> nb <- dnearneigh(x=coordinates(df), d1=0, d2=200,longlat = TRUE)
> dists <- nbdists(nb, coordinates(df), longlat=TRUE)
> glist <- lapply(dists, function(x) 1/x)
> lw <- nb2listw(nb, glist, style="W")
> me <- ME(x ~ 1, data = df, family = "quasipoisson", listw = lw, alpha = 0.5)
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From ghiaco at gmail.com  Thu Jan 11 11:57:22 2018
From: ghiaco at gmail.com (Sima Usvyatsov)
Date: Thu, 11 Jan 2018 06:57:22 -0400
Subject: [R-sig-Geo] Spatial filtering with glm with grid sampling
In-Reply-To: <alpine.LFD.2.21.1801110944550.22121@reclus.nhh.no>
References: <CAFGTTqTvUfdnZEn9LxHL=wwwr8GykffPsf81kF1nOniUP9GLvg@mail.gmail.com>
 <alpine.LFD.2.21.1801110944550.22121@reclus.nhh.no>
Message-ID: <CAFGTTqTE_rbUMm4G1N1G4u_Ajoq+wLmUQa4fAxx2eMRswJ+hYw@mail.gmail.com>

Thank you so much for your response.

Yes, I managed to muck up the fake data in 2 (!) ways - the 1,000 lons and
the fact that the lon/lats weren't repeated. Here's the correct structure.

df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat = rep(rnorm(20,
30, 0.1), each = 5), Lon = rep(rnorm(20, -75, 1), each = 5), x =
rnegbin(100, 1, 1),
Stratum = rep(1:5, each = 20))

In the meantime, I (somewhat) resolved the issue with the glmmPQL fixed
effects - my fault, of course.

My current model is set up as follows:

mod1 <- glmmPQL(Count ~ Stratum + SiteInStratum + ...other predictors,
random = ~ 1 |RoundStart,
family = quasipoisson,
correlation = corExp(form=~site.Easting + site.Northing + RoundStart)

where RoundStart is the date/time of starting each count. I'm assuming that
by "using a standard GLMM" you were thinking of MASS's glmmPQL()?
Does this look correct for specifying the full space/time dependence? The
variogram and pacf look very decent, but one can never have too many
checks...

On Thu, Jan 11, 2018 at 5:01 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Wed, 10 Jan 2018, Sima Usvyatsov wrote:
>
> Hello,
>>
>> I am running a negative binomial model (MASS) on count data collected on a
>> grid. The dataset is large - ~4,000 points, with many predictors. Being
>> counts, there are a lot of zeroes. All data are collected on a grid with
>> 20
>> points, with high spatial autocorrelation.
>>
>> I would like to filter out the spatial autocorrelation. My question is:
>> since I have very limited spatial info (only 20 distinct spatial
>> locations), is it possible to simplify ME() so that I don't have to run it
>> on the whole dataset? When I try to run ME() on a 100-point subset of the
>> data, I get error in glm.fit: NA/NaN/Inf in 'x'. When I run it on a single
>> instance of the grid, I "get away" with a warning ("algorithm did not
>> converge").
>>
>> Here's a fake dataset. It was grinding for a while but not throwing errors
>> (like my original data would). Regardless, it demonstrates the repeated
>> sampling at the same points and the large number of zeroes.
>>
>
> The data set has 1000 values in Lon, so is probably bigger than you
> intended, and when 100 is used is not autocorrelated. You seem to have a
> hierarchical model, with repeated measurements at the locations, so a
> multi-level treatment of some kind may be sensible. If you want to stay
> with ME-based spatial filtering, maybe look at the literature on spatial
> panel (repeated measurements are in time) with ME/SF, and on network
> autocorrelation (dyadic relationships with autocorrelation among origins
> and/or destinations). Both these cases use Kronecker products on the
> selected eigenvectors, I think.
>
> Alternatively, use a standard GLMM with a grouped iid random effect and/or
> a spatially structured random effect at the 20 location level. If the
> groups are repeated observations in time, you should model the whole
> (non-)separable space-time process.
>
> Hope this helps,
>
> Roger
>
>
>> Any advice would be most welcome.
>>
>> library(spdep)
>> library(MASS)
>>
>> df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat = rnorm(100,
>> 30,
>> 0.1), Lon = rnorm(1000, -75, 1), x = rnegbin(100, 1, 1))
>> coordinates(df) <- ~Lon + Lat
>> proj4string(df) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
>> nb <- dnearneigh(x=coordinates(df), d1=0, d2=200,longlat = TRUE)
>> dists <- nbdists(nb, coordinates(df), longlat=TRUE)
>> glist <- lapply(dists, function(x) 1/x)
>> lw <- nb2listw(nb, glist, style="W")
>> me <- ME(x ~ 1, data = df, family = "quasipoisson", listw = lw, alpha =
>> 0.5)
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
> Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Thu Jan 11 13:18:48 2018
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 11 Jan 2018 13:18:48 +0100
Subject: [R-sig-Geo] Spatial filtering with glm with grid sampling
In-Reply-To: <CAFGTTqTE_rbUMm4G1N1G4u_Ajoq+wLmUQa4fAxx2eMRswJ+hYw@mail.gmail.com>
References: <CAFGTTqTvUfdnZEn9LxHL=wwwr8GykffPsf81kF1nOniUP9GLvg@mail.gmail.com>
 <alpine.LFD.2.21.1801110944550.22121@reclus.nhh.no>
 <CAFGTTqTE_rbUMm4G1N1G4u_Ajoq+wLmUQa4fAxx2eMRswJ+hYw@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.1801111317310.22716@reclus.nhh.no>

On Thu, 11 Jan 2018, Sima Usvyatsov wrote:

> Thank you so much for your response.
>
> Yes, I managed to muck up the fake data in 2 (!) ways - the 1,000 lons and
> the fact that the lon/lats weren't repeated. Here's the correct structure.
>
> df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat = rep(rnorm(20,
> 30, 0.1), each = 5), Lon = rep(rnorm(20, -75, 1), each = 5), x =
> rnegbin(100, 1, 1),
> Stratum = rep(1:5, each = 20))
>
> In the meantime, I (somewhat) resolved the issue with the glmmPQL fixed
> effects - my fault, of course.
>
> My current model is set up as follows:
>
> mod1 <- glmmPQL(Count ~ Stratum + SiteInStratum + ...other predictors,
> random = ~ 1 |RoundStart,
> family = quasipoisson,
> correlation = corExp(form=~site.Easting + site.Northing + RoundStart)
>
> where RoundStart is the date/time of starting each count. I'm assuming that
> by "using a standard GLMM" you were thinking of MASS's glmmPQL()?
> Does this look correct for specifying the full space/time dependence? The
> variogram and pacf look very decent, but one can never have too many
> checks...

I can't judge whether it really makes sense, but I think this is much more 
robust. I'd explore some other GLMMs too, to see what they contribute.

Roger

>
> On Thu, Jan 11, 2018 at 5:01 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Wed, 10 Jan 2018, Sima Usvyatsov wrote:
>>
>> Hello,
>>>
>>> I am running a negative binomial model (MASS) on count data collected on a
>>> grid. The dataset is large - ~4,000 points, with many predictors. Being
>>> counts, there are a lot of zeroes. All data are collected on a grid with
>>> 20
>>> points, with high spatial autocorrelation.
>>>
>>> I would like to filter out the spatial autocorrelation. My question is:
>>> since I have very limited spatial info (only 20 distinct spatial
>>> locations), is it possible to simplify ME() so that I don't have to run it
>>> on the whole dataset? When I try to run ME() on a 100-point subset of the
>>> data, I get error in glm.fit: NA/NaN/Inf in 'x'. When I run it on a single
>>> instance of the grid, I "get away" with a warning ("algorithm did not
>>> converge").
>>>
>>> Here's a fake dataset. It was grinding for a while but not throwing errors
>>> (like my original data would). Regardless, it demonstrates the repeated
>>> sampling at the same points and the large number of zeroes.
>>>
>>
>> The data set has 1000 values in Lon, so is probably bigger than you
>> intended, and when 100 is used is not autocorrelated. You seem to have a
>> hierarchical model, with repeated measurements at the locations, so a
>> multi-level treatment of some kind may be sensible. If you want to stay
>> with ME-based spatial filtering, maybe look at the literature on spatial
>> panel (repeated measurements are in time) with ME/SF, and on network
>> autocorrelation (dyadic relationships with autocorrelation among origins
>> and/or destinations). Both these cases use Kronecker products on the
>> selected eigenvectors, I think.
>>
>> Alternatively, use a standard GLMM with a grouped iid random effect and/or
>> a spatially structured random effect at the 20 location level. If the
>> groups are repeated observations in time, you should model the whole
>> (non-)separable space-time process.
>>
>> Hope this helps,
>>
>> Roger
>>
>>
>>> Any advice would be most welcome.
>>>
>>> library(spdep)
>>> library(MASS)
>>>
>>> df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat = rnorm(100,
>>> 30,
>>> 0.1), Lon = rnorm(1000, -75, 1), x = rnegbin(100, 1, 1))
>>> coordinates(df) <- ~Lon + Lat
>>> proj4string(df) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
>>> nb <- dnearneigh(x=coordinates(df), d1=0, d2=200,longlat = TRUE)
>>> dists <- nbdists(nb, coordinates(df), longlat=TRUE)
>>> glist <- lapply(dists, function(x) 1/x)
>>> lw <- nb2listw(nb, glist, style="W")
>>> me <- ME(x ~ 1, data = df, family = "quasipoisson", listw = lw, alpha =
>>> 0.5)
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>> Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
>> http://orcid.org/0000-0003-2392-6140
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From ghiaco at gmail.com  Thu Jan 11 13:22:21 2018
From: ghiaco at gmail.com (Sima Usvyatsov)
Date: Thu, 11 Jan 2018 08:22:21 -0400
Subject: [R-sig-Geo] Spatial filtering with glm with grid sampling
In-Reply-To: <alpine.LFD.2.21.1801111317310.22716@reclus.nhh.no>
References: <CAFGTTqTvUfdnZEn9LxHL=wwwr8GykffPsf81kF1nOniUP9GLvg@mail.gmail.com>
 <alpine.LFD.2.21.1801110944550.22121@reclus.nhh.no>
 <CAFGTTqTE_rbUMm4G1N1G4u_Ajoq+wLmUQa4fAxx2eMRswJ+hYw@mail.gmail.com>
 <alpine.LFD.2.21.1801111317310.22716@reclus.nhh.no>
Message-ID: <CAFGTTqQY+ov3Y6SBTqTQhq4xP5dfi_OFzt=UOBSB0eUq+nX4RA@mail.gmail.com>

What other GLMM options do I have, under the restrictions of count data
with lots of zeroes and spatial autocorrelation? I was under the impression
that glmmPQL was my only choice?

On Thu, Jan 11, 2018 at 8:18 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Thu, 11 Jan 2018, Sima Usvyatsov wrote:
>
> Thank you so much for your response.
>>
>> Yes, I managed to muck up the fake data in 2 (!) ways - the 1,000 lons and
>> the fact that the lon/lats weren't repeated. Here's the correct structure.
>>
>> df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat = rep(rnorm(20,
>> 30, 0.1), each = 5), Lon = rep(rnorm(20, -75, 1), each = 5), x =
>> rnegbin(100, 1, 1),
>> Stratum = rep(1:5, each = 20))
>>
>> In the meantime, I (somewhat) resolved the issue with the glmmPQL fixed
>> effects - my fault, of course.
>>
>> My current model is set up as follows:
>>
>> mod1 <- glmmPQL(Count ~ Stratum + SiteInStratum + ...other predictors,
>> random = ~ 1 |RoundStart,
>> family = quasipoisson,
>> correlation = corExp(form=~site.Easting + site.Northing + RoundStart)
>>
>> where RoundStart is the date/time of starting each count. I'm assuming
>> that
>> by "using a standard GLMM" you were thinking of MASS's glmmPQL()?
>> Does this look correct for specifying the full space/time dependence? The
>> variogram and pacf look very decent, but one can never have too many
>> checks...
>>
>
> I can't judge whether it really makes sense, but I think this is much more
> robust. I'd explore some other GLMMs too, to see what they contribute.
>
> Roger
>
>
>
>> On Thu, Jan 11, 2018 at 5:01 AM, Roger Bivand <Roger.Bivand at nhh.no>
>> wrote:
>>
>> On Wed, 10 Jan 2018, Sima Usvyatsov wrote:
>>>
>>> Hello,
>>>
>>>>
>>>> I am running a negative binomial model (MASS) on count data collected
>>>> on a
>>>> grid. The dataset is large - ~4,000 points, with many predictors. Being
>>>> counts, there are a lot of zeroes. All data are collected on a grid with
>>>> 20
>>>> points, with high spatial autocorrelation.
>>>>
>>>> I would like to filter out the spatial autocorrelation. My question is:
>>>> since I have very limited spatial info (only 20 distinct spatial
>>>> locations), is it possible to simplify ME() so that I don't have to run
>>>> it
>>>> on the whole dataset? When I try to run ME() on a 100-point subset of
>>>> the
>>>> data, I get error in glm.fit: NA/NaN/Inf in 'x'. When I run it on a
>>>> single
>>>> instance of the grid, I "get away" with a warning ("algorithm did not
>>>> converge").
>>>>
>>>> Here's a fake dataset. It was grinding for a while but not throwing
>>>> errors
>>>> (like my original data would). Regardless, it demonstrates the repeated
>>>> sampling at the same points and the large number of zeroes.
>>>>
>>>>
>>> The data set has 1000 values in Lon, so is probably bigger than you
>>> intended, and when 100 is used is not autocorrelated. You seem to have a
>>> hierarchical model, with repeated measurements at the locations, so a
>>> multi-level treatment of some kind may be sensible. If you want to stay
>>> with ME-based spatial filtering, maybe look at the literature on spatial
>>> panel (repeated measurements are in time) with ME/SF, and on network
>>> autocorrelation (dyadic relationships with autocorrelation among origins
>>> and/or destinations). Both these cases use Kronecker products on the
>>> selected eigenvectors, I think.
>>>
>>> Alternatively, use a standard GLMM with a grouped iid random effect
>>> and/or
>>> a spatially structured random effect at the 20 location level. If the
>>> groups are repeated observations in time, you should model the whole
>>> (non-)separable space-time process.
>>>
>>> Hope this helps,
>>>
>>> Roger
>>>
>>>
>>> Any advice would be most welcome.
>>>>
>>>> library(spdep)
>>>> library(MASS)
>>>>
>>>> df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat = rnorm(100,
>>>> 30,
>>>> 0.1), Lon = rnorm(1000, -75, 1), x = rnegbin(100, 1, 1))
>>>> coordinates(df) <- ~Lon + Lat
>>>> proj4string(df) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84
>>>> +no_defs")
>>>> nb <- dnearneigh(x=coordinates(df), d1=0, d2=200,longlat = TRUE)
>>>> dists <- nbdists(nb, coordinates(df), longlat=TRUE)
>>>> glist <- lapply(dists, function(x) 1/x)
>>>> lw <- nb2listw(nb, glist, style="W")
>>>> me <- ME(x ~ 1, data = df, family = "quasipoisson", listw = lw, alpha =
>>>> 0.5)
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>
>>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics,
>>> Helleveien 30, N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>>> Editor-in-Chief of The R Journal, https://journal.r-project.org/
>>> index.html
>>> http://orcid.org/0000-0003-2392-6140
>>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>>
>>>
>>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
> Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Thu Jan 11 13:33:38 2018
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 11 Jan 2018 13:33:38 +0100
Subject: [R-sig-Geo] Spatial filtering with glm with grid sampling
In-Reply-To: <CAFGTTqQY+ov3Y6SBTqTQhq4xP5dfi_OFzt=UOBSB0eUq+nX4RA@mail.gmail.com>
References: <CAFGTTqTvUfdnZEn9LxHL=wwwr8GykffPsf81kF1nOniUP9GLvg@mail.gmail.com>
 <alpine.LFD.2.21.1801110944550.22121@reclus.nhh.no>
 <CAFGTTqTE_rbUMm4G1N1G4u_Ajoq+wLmUQa4fAxx2eMRswJ+hYw@mail.gmail.com>
 <alpine.LFD.2.21.1801111317310.22716@reclus.nhh.no>
 <CAFGTTqQY+ov3Y6SBTqTQhq4xP5dfi_OFzt=UOBSB0eUq+nX4RA@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.1801111331170.22716@reclus.nhh.no>

On Thu, 11 Jan 2018, Sima Usvyatsov wrote:

> What other GLMM options do I have, under the restrictions of count data
> with lots of zeroes and spatial autocorrelation? I was under the impression
> that glmmPQL was my only choice?

See for example:

https://www.fromthebottomoftheheap.net/2017/05/04/compare-mgcv-with-glmmTMB/

https://rjournal.github.io/archive/2017/RJ-2017-066/index.html 
(forthcoming)

for surveys and discussions; maybe your current choice is the best bet for 
negbin.

Roger

>
> On Thu, Jan 11, 2018 at 8:18 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Thu, 11 Jan 2018, Sima Usvyatsov wrote:
>>
>> Thank you so much for your response.
>>>
>>> Yes, I managed to muck up the fake data in 2 (!) ways - the 1,000 lons and
>>> the fact that the lon/lats weren't repeated. Here's the correct structure.
>>>
>>> df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat = rep(rnorm(20,
>>> 30, 0.1), each = 5), Lon = rep(rnorm(20, -75, 1), each = 5), x =
>>> rnegbin(100, 1, 1),
>>> Stratum = rep(1:5, each = 20))
>>>
>>> In the meantime, I (somewhat) resolved the issue with the glmmPQL fixed
>>> effects - my fault, of course.
>>>
>>> My current model is set up as follows:
>>>
>>> mod1 <- glmmPQL(Count ~ Stratum + SiteInStratum + ...other predictors,
>>> random = ~ 1 |RoundStart,
>>> family = quasipoisson,
>>> correlation = corExp(form=~site.Easting + site.Northing + RoundStart)
>>>
>>> where RoundStart is the date/time of starting each count. I'm assuming
>>> that
>>> by "using a standard GLMM" you were thinking of MASS's glmmPQL()?
>>> Does this look correct for specifying the full space/time dependence? The
>>> variogram and pacf look very decent, but one can never have too many
>>> checks...
>>>
>>
>> I can't judge whether it really makes sense, but I think this is much more
>> robust. I'd explore some other GLMMs too, to see what they contribute.
>>
>> Roger
>>
>>
>>
>>> On Thu, Jan 11, 2018 at 5:01 AM, Roger Bivand <Roger.Bivand at nhh.no>
>>> wrote:
>>>
>>> On Wed, 10 Jan 2018, Sima Usvyatsov wrote:
>>>>
>>>> Hello,
>>>>
>>>>>
>>>>> I am running a negative binomial model (MASS) on count data collected
>>>>> on a
>>>>> grid. The dataset is large - ~4,000 points, with many predictors. Being
>>>>> counts, there are a lot of zeroes. All data are collected on a grid with
>>>>> 20
>>>>> points, with high spatial autocorrelation.
>>>>>
>>>>> I would like to filter out the spatial autocorrelation. My question is:
>>>>> since I have very limited spatial info (only 20 distinct spatial
>>>>> locations), is it possible to simplify ME() so that I don't have to run
>>>>> it
>>>>> on the whole dataset? When I try to run ME() on a 100-point subset of
>>>>> the
>>>>> data, I get error in glm.fit: NA/NaN/Inf in 'x'. When I run it on a
>>>>> single
>>>>> instance of the grid, I "get away" with a warning ("algorithm did not
>>>>> converge").
>>>>>
>>>>> Here's a fake dataset. It was grinding for a while but not throwing
>>>>> errors
>>>>> (like my original data would). Regardless, it demonstrates the repeated
>>>>> sampling at the same points and the large number of zeroes.
>>>>>
>>>>>
>>>> The data set has 1000 values in Lon, so is probably bigger than you
>>>> intended, and when 100 is used is not autocorrelated. You seem to have a
>>>> hierarchical model, with repeated measurements at the locations, so a
>>>> multi-level treatment of some kind may be sensible. If you want to stay
>>>> with ME-based spatial filtering, maybe look at the literature on spatial
>>>> panel (repeated measurements are in time) with ME/SF, and on network
>>>> autocorrelation (dyadic relationships with autocorrelation among origins
>>>> and/or destinations). Both these cases use Kronecker products on the
>>>> selected eigenvectors, I think.
>>>>
>>>> Alternatively, use a standard GLMM with a grouped iid random effect
>>>> and/or
>>>> a spatially structured random effect at the 20 location level. If the
>>>> groups are repeated observations in time, you should model the whole
>>>> (non-)separable space-time process.
>>>>
>>>> Hope this helps,
>>>>
>>>> Roger
>>>>
>>>>
>>>> Any advice would be most welcome.
>>>>>
>>>>> library(spdep)
>>>>> library(MASS)
>>>>>
>>>>> df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat = rnorm(100,
>>>>> 30,
>>>>> 0.1), Lon = rnorm(1000, -75, 1), x = rnegbin(100, 1, 1))
>>>>> coordinates(df) <- ~Lon + Lat
>>>>> proj4string(df) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84
>>>>> +no_defs")
>>>>> nb <- dnearneigh(x=coordinates(df), d1=0, d2=200,longlat = TRUE)
>>>>> dists <- nbdists(nb, coordinates(df), longlat=TRUE)
>>>>> glist <- lapply(dists, function(x) 1/x)
>>>>> lw <- nb2listw(nb, glist, style="W")
>>>>> me <- ME(x ~ 1, data = df, family = "quasipoisson", listw = lw, alpha =
>>>>> 0.5)
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at r-project.org
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>>>>
>>>>> --
>>>> Roger Bivand
>>>> Department of Economics, Norwegian School of Economics,
>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>>>> Editor-in-Chief of The R Journal, https://journal.r-project.org/
>>>> index.html
>>>> http://orcid.org/0000-0003-2392-6140
>>>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>>>
>>>>
>>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>> Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
>> http://orcid.org/0000-0003-2392-6140
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From ghiaco at gmail.com  Thu Jan 11 17:53:27 2018
From: ghiaco at gmail.com (Sima Usvyatsov)
Date: Thu, 11 Jan 2018 12:53:27 -0400
Subject: [R-sig-Geo] Spatial filtering with glm with grid sampling
In-Reply-To: <alpine.LFD.2.21.1801111331170.22716@reclus.nhh.no>
References: <CAFGTTqTvUfdnZEn9LxHL=wwwr8GykffPsf81kF1nOniUP9GLvg@mail.gmail.com>
 <alpine.LFD.2.21.1801110944550.22121@reclus.nhh.no>
 <CAFGTTqTE_rbUMm4G1N1G4u_Ajoq+wLmUQa4fAxx2eMRswJ+hYw@mail.gmail.com>
 <alpine.LFD.2.21.1801111317310.22716@reclus.nhh.no>
 <CAFGTTqQY+ov3Y6SBTqTQhq4xP5dfi_OFzt=UOBSB0eUq+nX4RA@mail.gmail.com>
 <alpine.LFD.2.21.1801111331170.22716@reclus.nhh.no>
Message-ID: <CAFGTTqScbgFzmAyEAN27mymsHM8o4PfnZC9sAzeOeVrKVCTfiw@mail.gmail.com>

I had no idea this was coming up - can't believe it didn't come up in any
of my searches. Looks super useful, and I'm sure I'll be using it sooner
than later, whether on this analysis or not. The worked example is
ridiculously useful - so glad to have it.

If I'm reading the help page correctly (the autocorrelation bits,
struc(terms|group)) - to replicate the spatial autocorrelation within
Round, would I add this?

exp(site.Easting + site.Northing | RoundStart)

So something like this:

mod1 <- glmmTMB(Count ~ Stratum + SiteInStratum + ...other predictors +
# random variable
(1 | RoundStart) +
# autocorrelation
exp(site.Easting + site.Northing | RoundStart),

family = nbinom2, # or nbinom1 - I guess decide based on residuals?
correlation = corExp(form=~site.Easting + site.Northing + RoundStart)

Does that look like the twin of the glmmPQL specification I had (other than
family)? I can also email sig-ME if it's a better forum for this.

On Thu, Jan 11, 2018 at 8:33 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Thu, 11 Jan 2018, Sima Usvyatsov wrote:
>
> What other GLMM options do I have, under the restrictions of count data
>> with lots of zeroes and spatial autocorrelation? I was under the
>> impression
>> that glmmPQL was my only choice?
>>
>
> See for example:
>
> https://www.fromthebottomoftheheap.net/2017/05/04/compare-
> mgcv-with-glmmTMB/
>
> https://rjournal.github.io/archive/2017/RJ-2017-066/index.html
> (forthcoming)
>
> for surveys and discussions; maybe your current choice is the best bet for
> negbin.
>
>
> Roger
>
>
>> On Thu, Jan 11, 2018 at 8:18 AM, Roger Bivand <Roger.Bivand at nhh.no>
>> wrote:
>>
>> On Thu, 11 Jan 2018, Sima Usvyatsov wrote:
>>>
>>> Thank you so much for your response.
>>>
>>>>
>>>> Yes, I managed to muck up the fake data in 2 (!) ways - the 1,000 lons
>>>> and
>>>> the fact that the lon/lats weren't repeated. Here's the correct
>>>> structure.
>>>>
>>>> df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat =
>>>> rep(rnorm(20,
>>>> 30, 0.1), each = 5), Lon = rep(rnorm(20, -75, 1), each = 5), x =
>>>> rnegbin(100, 1, 1),
>>>> Stratum = rep(1:5, each = 20))
>>>>
>>>> In the meantime, I (somewhat) resolved the issue with the glmmPQL fixed
>>>> effects - my fault, of course.
>>>>
>>>> My current model is set up as follows:
>>>>
>>>> mod1 <- glmmPQL(Count ~ Stratum + SiteInStratum + ...other predictors,
>>>> random = ~ 1 |RoundStart,
>>>> family = quasipoisson,
>>>> correlation = corExp(form=~site.Easting + site.Northing + RoundStart)
>>>>
>>>> where RoundStart is the date/time of starting each count. I'm assuming
>>>> that
>>>> by "using a standard GLMM" you were thinking of MASS's glmmPQL()?
>>>> Does this look correct for specifying the full space/time dependence?
>>>> The
>>>> variogram and pacf look very decent, but one can never have too many
>>>> checks...
>>>>
>>>>
>>> I can't judge whether it really makes sense, but I think this is much
>>> more
>>> robust. I'd explore some other GLMMs too, to see what they contribute.
>>>
>>> Roger
>>>
>>>
>>>
>>> On Thu, Jan 11, 2018 at 5:01 AM, Roger Bivand <Roger.Bivand at nhh.no>
>>>> wrote:
>>>>
>>>> On Wed, 10 Jan 2018, Sima Usvyatsov wrote:
>>>>
>>>>>
>>>>> Hello,
>>>>>
>>>>>
>>>>>> I am running a negative binomial model (MASS) on count data collected
>>>>>> on a
>>>>>> grid. The dataset is large - ~4,000 points, with many predictors.
>>>>>> Being
>>>>>> counts, there are a lot of zeroes. All data are collected on a grid
>>>>>> with
>>>>>> 20
>>>>>> points, with high spatial autocorrelation.
>>>>>>
>>>>>> I would like to filter out the spatial autocorrelation. My question
>>>>>> is:
>>>>>> since I have very limited spatial info (only 20 distinct spatial
>>>>>> locations), is it possible to simplify ME() so that I don't have to
>>>>>> run
>>>>>> it
>>>>>> on the whole dataset? When I try to run ME() on a 100-point subset of
>>>>>> the
>>>>>> data, I get error in glm.fit: NA/NaN/Inf in 'x'. When I run it on a
>>>>>> single
>>>>>> instance of the grid, I "get away" with a warning ("algorithm did not
>>>>>> converge").
>>>>>>
>>>>>> Here's a fake dataset. It was grinding for a while but not throwing
>>>>>> errors
>>>>>> (like my original data would). Regardless, it demonstrates the
>>>>>> repeated
>>>>>> sampling at the same points and the large number of zeroes.
>>>>>>
>>>>>>
>>>>>> The data set has 1000 values in Lon, so is probably bigger than you
>>>>> intended, and when 100 is used is not autocorrelated. You seem to have
>>>>> a
>>>>> hierarchical model, with repeated measurements at the locations, so a
>>>>> multi-level treatment of some kind may be sensible. If you want to stay
>>>>> with ME-based spatial filtering, maybe look at the literature on
>>>>> spatial
>>>>> panel (repeated measurements are in time) with ME/SF, and on network
>>>>> autocorrelation (dyadic relationships with autocorrelation among
>>>>> origins
>>>>> and/or destinations). Both these cases use Kronecker products on the
>>>>> selected eigenvectors, I think.
>>>>>
>>>>> Alternatively, use a standard GLMM with a grouped iid random effect
>>>>> and/or
>>>>> a spatially structured random effect at the 20 location level. If the
>>>>> groups are repeated observations in time, you should model the whole
>>>>> (non-)separable space-time process.
>>>>>
>>>>> Hope this helps,
>>>>>
>>>>> Roger
>>>>>
>>>>>
>>>>> Any advice would be most welcome.
>>>>>
>>>>>>
>>>>>> library(spdep)
>>>>>> library(MASS)
>>>>>>
>>>>>> df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat =
>>>>>> rnorm(100,
>>>>>> 30,
>>>>>> 0.1), Lon = rnorm(1000, -75, 1), x = rnegbin(100, 1, 1))
>>>>>> coordinates(df) <- ~Lon + Lat
>>>>>> proj4string(df) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84
>>>>>> +no_defs")
>>>>>> nb <- dnearneigh(x=coordinates(df), d1=0, d2=200,longlat = TRUE)
>>>>>> dists <- nbdists(nb, coordinates(df), longlat=TRUE)
>>>>>> glist <- lapply(dists, function(x) 1/x)
>>>>>> lw <- nb2listw(nb, glist,
>>>>>> <https://maps.google.com/?q=tw(nb,+glist,&entry=gmail&source=g>
>>>>>> style="W")
>>>>>> me <- ME(x ~ 1, data = df, family = "quasipoisson", listw = lw, alpha
>>>>>> =
>>>>>> 0.5)
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at r-project.org
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>
>>>>>>
>>>>>> --
>>>>>>
>>>>> Roger Bivand
>>>>> Department of Economics, Norwegian School of Economics,
>>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>>>>> Editor-in-Chief of The R Journal, https://journal.r-project.org/
>>>>> index.html
>>>>> http://orcid.org/0000-0003-2392-6140
>>>>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>>>>
>>>>>
>>>>>
>>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics,
>>> Helleveien 30, N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>>> Editor-in-Chief of The R Journal, https://journal.r-project.org/
>>> index.html
>>> http://orcid.org/0000-0003-2392-6140
>>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>>
>>>
>>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
> Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Fri Jan 12 13:45:53 2018
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 12 Jan 2018 13:45:53 +0100
Subject: [R-sig-Geo] Spatial filtering with glm with grid sampling
In-Reply-To: <CAFGTTqScbgFzmAyEAN27mymsHM8o4PfnZC9sAzeOeVrKVCTfiw@mail.gmail.com>
References: <CAFGTTqTvUfdnZEn9LxHL=wwwr8GykffPsf81kF1nOniUP9GLvg@mail.gmail.com>
 <alpine.LFD.2.21.1801110944550.22121@reclus.nhh.no>
 <CAFGTTqTE_rbUMm4G1N1G4u_Ajoq+wLmUQa4fAxx2eMRswJ+hYw@mail.gmail.com>
 <alpine.LFD.2.21.1801111317310.22716@reclus.nhh.no>
 <CAFGTTqQY+ov3Y6SBTqTQhq4xP5dfi_OFzt=UOBSB0eUq+nX4RA@mail.gmail.com>
 <alpine.LFD.2.21.1801111331170.22716@reclus.nhh.no>
 <CAFGTTqScbgFzmAyEAN27mymsHM8o4PfnZC9sAzeOeVrKVCTfiw@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.1801121345000.5376@reclus.nhh.no>

On Thu, 11 Jan 2018, Sima Usvyatsov wrote:

> I had no idea this was coming up - can't believe it didn't come up in any
> of my searches. Looks super useful, and I'm sure I'll be using it sooner
> than later, whether on this analysis or not. The worked example is
> ridiculously useful - so glad to have it.
>
> If I'm reading the help page correctly (the autocorrelation bits,
> struc(terms|group)) - to replicate the spatial autocorrelation within
> Round, would I add this?

Not sure - please report back if you find an equivalent to the glmmPQL 
approach.

Roger

>
> exp(site.Easting + site.Northing | RoundStart)
>
> So something like this:
>
> mod1 <- glmmTMB(Count ~ Stratum + SiteInStratum + ...other predictors +
> # random variable
> (1 | RoundStart) +
> # autocorrelation
> exp(site.Easting + site.Northing | RoundStart),
>
> family = nbinom2, # or nbinom1 - I guess decide based on residuals?
> correlation = corExp(form=~site.Easting + site.Northing + RoundStart)
>
> Does that look like the twin of the glmmPQL specification I had (other than
> family)? I can also email sig-ME if it's a better forum for this.
>
> On Thu, Jan 11, 2018 at 8:33 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Thu, 11 Jan 2018, Sima Usvyatsov wrote:
>>
>> What other GLMM options do I have, under the restrictions of count data
>>> with lots of zeroes and spatial autocorrelation? I was under the
>>> impression
>>> that glmmPQL was my only choice?
>>>
>>
>> See for example:
>>
>> https://www.fromthebottomoftheheap.net/2017/05/04/compare-
>> mgcv-with-glmmTMB/
>>
>> https://rjournal.github.io/archive/2017/RJ-2017-066/index.html
>> (forthcoming)
>>
>> for surveys and discussions; maybe your current choice is the best bet for
>> negbin.
>>
>>
>> Roger
>>
>>
>>> On Thu, Jan 11, 2018 at 8:18 AM, Roger Bivand <Roger.Bivand at nhh.no>
>>> wrote:
>>>
>>> On Thu, 11 Jan 2018, Sima Usvyatsov wrote:
>>>>
>>>> Thank you so much for your response.
>>>>
>>>>>
>>>>> Yes, I managed to muck up the fake data in 2 (!) ways - the 1,000 lons
>>>>> and
>>>>> the fact that the lon/lats weren't repeated. Here's the correct
>>>>> structure.
>>>>>
>>>>> df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat =
>>>>> rep(rnorm(20,
>>>>> 30, 0.1), each = 5), Lon = rep(rnorm(20, -75, 1), each = 5), x =
>>>>> rnegbin(100, 1, 1),
>>>>> Stratum = rep(1:5, each = 20))
>>>>>
>>>>> In the meantime, I (somewhat) resolved the issue with the glmmPQL fixed
>>>>> effects - my fault, of course.
>>>>>
>>>>> My current model is set up as follows:
>>>>>
>>>>> mod1 <- glmmPQL(Count ~ Stratum + SiteInStratum + ...other predictors,
>>>>> random = ~ 1 |RoundStart,
>>>>> family = quasipoisson,
>>>>> correlation = corExp(form=~site.Easting + site.Northing + RoundStart)
>>>>>
>>>>> where RoundStart is the date/time of starting each count. I'm assuming
>>>>> that
>>>>> by "using a standard GLMM" you were thinking of MASS's glmmPQL()?
>>>>> Does this look correct for specifying the full space/time dependence?
>>>>> The
>>>>> variogram and pacf look very decent, but one can never have too many
>>>>> checks...
>>>>>
>>>>>
>>>> I can't judge whether it really makes sense, but I think this is much
>>>> more
>>>> robust. I'd explore some other GLMMs too, to see what they contribute.
>>>>
>>>> Roger
>>>>
>>>>
>>>>
>>>> On Thu, Jan 11, 2018 at 5:01 AM, Roger Bivand <Roger.Bivand at nhh.no>
>>>>> wrote:
>>>>>
>>>>> On Wed, 10 Jan 2018, Sima Usvyatsov wrote:
>>>>>
>>>>>>
>>>>>> Hello,
>>>>>>
>>>>>>
>>>>>>> I am running a negative binomial model (MASS) on count data collected
>>>>>>> on a
>>>>>>> grid. The dataset is large - ~4,000 points, with many predictors.
>>>>>>> Being
>>>>>>> counts, there are a lot of zeroes. All data are collected on a grid
>>>>>>> with
>>>>>>> 20
>>>>>>> points, with high spatial autocorrelation.
>>>>>>>
>>>>>>> I would like to filter out the spatial autocorrelation. My question
>>>>>>> is:
>>>>>>> since I have very limited spatial info (only 20 distinct spatial
>>>>>>> locations), is it possible to simplify ME() so that I don't have to
>>>>>>> run
>>>>>>> it
>>>>>>> on the whole dataset? When I try to run ME() on a 100-point subset of
>>>>>>> the
>>>>>>> data, I get error in glm.fit: NA/NaN/Inf in 'x'. When I run it on a
>>>>>>> single
>>>>>>> instance of the grid, I "get away" with a warning ("algorithm did not
>>>>>>> converge").
>>>>>>>
>>>>>>> Here's a fake dataset. It was grinding for a while but not throwing
>>>>>>> errors
>>>>>>> (like my original data would). Regardless, it demonstrates the
>>>>>>> repeated
>>>>>>> sampling at the same points and the large number of zeroes.
>>>>>>>
>>>>>>>
>>>>>>> The data set has 1000 values in Lon, so is probably bigger than you
>>>>>> intended, and when 100 is used is not autocorrelated. You seem to have
>>>>>> a
>>>>>> hierarchical model, with repeated measurements at the locations, so a
>>>>>> multi-level treatment of some kind may be sensible. If you want to stay
>>>>>> with ME-based spatial filtering, maybe look at the literature on
>>>>>> spatial
>>>>>> panel (repeated measurements are in time) with ME/SF, and on network
>>>>>> autocorrelation (dyadic relationships with autocorrelation among
>>>>>> origins
>>>>>> and/or destinations). Both these cases use Kronecker products on the
>>>>>> selected eigenvectors, I think.
>>>>>>
>>>>>> Alternatively, use a standard GLMM with a grouped iid random effect
>>>>>> and/or
>>>>>> a spatially structured random effect at the 20 location level. If the
>>>>>> groups are repeated observations in time, you should model the whole
>>>>>> (non-)separable space-time process.
>>>>>>
>>>>>> Hope this helps,
>>>>>>
>>>>>> Roger
>>>>>>
>>>>>>
>>>>>> Any advice would be most welcome.
>>>>>>
>>>>>>>
>>>>>>> library(spdep)
>>>>>>> library(MASS)
>>>>>>>
>>>>>>> df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat =
>>>>>>> rnorm(100,
>>>>>>> 30,
>>>>>>> 0.1), Lon = rnorm(1000, -75, 1), x = rnegbin(100, 1, 1))
>>>>>>> coordinates(df) <- ~Lon + Lat
>>>>>>> proj4string(df) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84
>>>>>>> +no_defs")
>>>>>>> nb <- dnearneigh(x=coordinates(df), d1=0, d2=200,longlat = TRUE)
>>>>>>> dists <- nbdists(nb, coordinates(df), longlat=TRUE)
>>>>>>> glist <- lapply(dists, function(x) 1/x)
>>>>>>> lw <- nb2listw(nb, glist,
>>>>>>> <https://maps.google.com/?q=tw(nb,+glist,&entry=gmail&source=g>
>>>>>>> style="W")
>>>>>>> me <- ME(x ~ 1, data = df, family = "quasipoisson", listw = lw, alpha
>>>>>>> =
>>>>>>> 0.5)
>>>>>>>
>>>>>>>         [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-Geo mailing list
>>>>>>> R-sig-Geo at r-project.org
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>>
>>>>>> Roger Bivand
>>>>>> Department of Economics, Norwegian School of Economics,
>>>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>>>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>>>>>> Editor-in-Chief of The R Journal, https://journal.r-project.org/
>>>>>> index.html
>>>>>> http://orcid.org/0000-0003-2392-6140
>>>>>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>>>>>
>>>>>>
>>>>>>
>>>>> --
>>>> Roger Bivand
>>>> Department of Economics, Norwegian School of Economics,
>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>>>> Editor-in-Chief of The R Journal, https://journal.r-project.org/
>>>> index.html
>>>> http://orcid.org/0000-0003-2392-6140
>>>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>>>
>>>>
>>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>> Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
>> http://orcid.org/0000-0003-2392-6140
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From stefano.sofia at regione.marche.it  Thu Jan 18 09:11:44 2018
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Thu, 18 Jan 2018 08:11:44 +0000
Subject: [R-sig-Geo] R code for rainfall isohyet map
Message-ID: <8B435C9568170B469AE31E8891E8CC4F471E8488@ESINO.regionemarche.intra>

Dear R-sig-geo list users,
given n meteorological automatic stations with rain gouge, I need to produce an image with the isohyets of the rainfall values of my region (Italy, Marche region, on the Adriatic Sea in front of Croatia).
For each station the available coordinates are in Gauss Boaga, Long and Lat in degrees, minutes and seconds and Long and Lat in degrees and decimals.
In the code below reported Long and Lat in degrees and decimals have been used.

This is an example of the input file called in the code "pointfile.csv":

Station_code, Rainfall_value, GaussBoaga_EST, GaussBoaga_NORD, Long_degrees, Long_minutes, Long_seconds, Lat_degrees, Lat_minutes, Lat_seconds, Long_Cent, Lat_Cent
1056, 11.8, 2328427, 4851813, 12, 37, 7.45291, 43, 47, 40.09906, 12.618737, 43.794472

The code below reported (with the precious support of Micha Silver) does compile, but the final image reports some numerical values (isohjet_map.png).
Would please somebody be able and help me to see where the code can be improved?

Thank you for your help
Stefano

Code:

library(automap)
library(ggplot2)
library(gstat)
library(rasterVis)
library(rgdal)

## READ INPUT FILE
rain_data <- read.csv(file="pointfile.csv")
str(rain_data)

point_coords <- rain_data[c("Long_Cent","Lat_Cent")]
coordinates(rain_data) <- point_coords
p4str <- CRS("+init=epsg:4326")
proj4string(rain_data) <- p4str

## CONVERTION TO UTM
p4str_UTM <- CRS("+init=epsg:32633")
rain_data_UTM <- spTransform(rain_data, p4str_UTM)

## CHECK THAT THIS IS A SPDF IN THE UTM COORDINATE SYSTEM
str(rain_data_UTM)

## CREATE GRID FOR KRIGING OUTPUT, USING THE EXTENT OF THE RAIN DATA SPDF
minx <-  rain_data_UTM at bbox[1,1]
maxx <- rain_data_UTM at bbox[1,2]
miny <- rain_data_UTM at bbox[2,1]
maxy <- rain_data_UTM at bbox[2,2]
## EACH PIXEL WILL BE 1000 METERS
pixel <- 1000
grd <- expand.grid(x=seq(minx, maxx, by=pixel), y=seq(miny, maxy, by=pixel))
coordinates(grd) <- ~x+y
gridded(grd) <- TRUE
proj4string(grd) <- p4str_UTM

## KRIGING, USING AUTOKRIGE WHICH CREATES A BEST GUESS VARIOGRAM
OK_rain <- autoKrige(Rainfall_value ~ 1, rain_data_UTM, grd)

## TRASFORM TO RASTER
rain_rast <- raster(OK_rain$krige_output)

## READ THE MARCHE BOUNDARY SHAPEFILE
Marche_shape <- readOGR(dsn="Lim_reg_2012_wgs32633.shp", layer="Lim_reg_2012_wgs32633")

##PLOT
png(file="isohyet_map.png")
gplot(rain_rast) + geom_tile(aes(fill=factor(value),alpha=0.8)) + geom_polygon(data=Marche_shape, aes(x=long, y=lat, group=group), fill=NA, color="grey50", size=1) + coord_equal()
dev.off()




         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Area Meteorologica e  Area nivologica - Centro Funzionale
Servizio Protezione Civile - Regione Marche
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 19973 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20180118/2c606d58/attachment.bin>

From petersonsk at ornl.gov  Mon Jan 22 21:22:01 2018
From: petersonsk at ornl.gov (Peterson, Steven K.)
Date: Mon, 22 Jan 2018 20:22:01 +0000
Subject: [R-sig-Geo] Updated Text of Applied Spatial Data Analysis with R?
Message-ID: <5cee39aabe224969ab6d4670b54d7de2@EXCHCS32.ornl.gov>

Hello,

Apologies if I missed the subject in this thread, but I was wondering if there was an updated version of Applied Spatial Data Analysis with R, Bivand et al, that would reference the sf package, or if there are some existing reference works for using the sf package that are recommended by the group.

Thanks,

Steve

OAK RIDGE NATIONAL LABORATORY
MANAGED BY UT-BATTELLE FOR U.S. DOE

Steven Peterson, Ph.D.
Economic and Transportation Geography
Geographic Information Sciences and Technology Group
Computational Sciences and Engineering  Division

(865) 574-4676           office
(865) 399-2464           cell

One Bethel Valley Road
P.O. Box 2008, MS-6017
Oak Ridge, TN 37831
petersonsk at ornl.gov<mailto:petersonsk at ornl.gov>


	[[alternative HTML version deleted]]


From patrick.schratz at gmail.com  Mon Jan 22 23:14:13 2018
From: patrick.schratz at gmail.com (Patrick Schratz)
Date: Mon, 22 Jan 2018 23:14:13 +0100
Subject: [R-sig-Geo] Updated Text of Applied Spatial Data Analysis with
 R?
In-Reply-To: <5cee39aabe224969ab6d4670b54d7de2@EXCHCS32.ornl.gov>
References: <5cee39aabe224969ab6d4670b54d7de2@EXCHCS32.ornl.gov>
Message-ID: <local-34f0276c-0b3b@pjs-PRO2>

Dear Steven,

you might wanna take a look at https://geocompr.robinlovelace.net/index.html
Furthermore, make sure to read the vignettes (articles) of the sf package: https://r-spatial.github.io/sf/
Cheers, Patrick

Patrick Schratz
PhD Student at Department of Geography, GIScience group, University of Jena

W: http://pats-s.github.io

On Jan 22 2018, at 9:22 pm, Peterson, Steven K. <petersonsk at ornl.gov> wrote:
>
> Hello,
> Apologies if I missed the subject in this thread, but I was wondering if there was an updated version of Applied Spatial Data Analysis with R, Bivand et al, that would reference the sf package, or if there are some existing reference works for using the sf package that are recommended by the group.
> Thanks,
> Steve
> OAK RIDGE NATIONAL LABORATORY
> MANAGED BY UT-BATTELLE FOR U.S. DOE
>
> Steven Peterson, Ph.D.
> Economic and Transportation Geography
> Geographic Information Sciences and Technology Group
> Computational Sciences and Engineering Division
>
> (865) 574-4676 office
> (865) 399-2464 cell
>
> One Bethel Valley Road
> P.O. Box 2008, MS-6017
> Oak Ridge, TN 37831
> petersonsk at ornl.gov<mailto:petersonsk at ornl.gov>
>
>
> [[alternative HTML version deleted]]
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


	[[alternative HTML version deleted]]


From e.j.h.polle at gmail.com  Tue Jan 23 21:49:03 2018
From: e.j.h.polle at gmail.com (=?UTF-8?B?RWdnZS1KYW4gUG9sbMOp?=)
Date: Tue, 23 Jan 2018 20:49:03 +0000
Subject: [R-sig-Geo] Issue with st_read sf with Encoding for MapInfo file
 (Frisian municipality name)
In-Reply-To: <CAGVoNq2ZNXNB8btCt_pXwuWVNCY=H4wQD1W+yzW_tmq2k0aK3Q@mail.gmail.com>
References: <CAGVoNq2ZNXNB8btCt_pXwuWVNCY=H4wQD1W+yzW_tmq2k0aK3Q@mail.gmail.com>
Message-ID: <CAGVoNq24Tmz5x=1r7ZvhY7ONx7rSYwvLDiFb_1r37FNqbbUvwQ@mail.gmail.com>

Hello,

Would someone know a solution for this issue:

When I load a MapInfo file with st_read (sf) I have an issue with the
Frisian municipality name 'S?dwest-Frysl?n'; it shows as
'S<fa>dwest-Frysl<e2>n' :-( Some issue with the encoding...

Below you will find a reproducible example, which will also download the
data set used.

If I load the same data with readOGR, everything is fine.

And if I load a comparable data set in ESRI SHP file format with st_read
(sf) there is no issue either.

So it really has something to do with the MapInfo driver. I did not find a
solution yet, so any help would be appreciated.

Cheers,

Egge-Jan Poll?


REPRODUCIBLE EXAMPLE:
# Download and read the data
#
# Make sure you have your Working Directory properly set, e.g.:
# setwd("C:/RMOOC")
#
# Download
URL <- "http://www.twiav.nl/files/NL_Municipalities2017.zip"
datafile <- file.path(basename(URL))
dir.create("./Data", showWarnings = FALSE)
workingdirectory <- getwd()
setwd("./Data")
download.file(URL, destfile = datafile, mode = "wb")
unzip(datafile)
unlink(datafile)
rm(URL, datafile)
setwd(workingdirectory)
rm(workingdirectory)

# Read
# Make sure the package "sf" is properly installed:
# install.packages("sf")
library(sf)
NL_Municipalities2017 <-
st_read("Data/NL_Municipalities2017/NL_Municipalities2017.TAB")
View(NL_Municipalities2017)
plot(st_geometry(NL_Municipalities2017),col = "darkgreen", border =
"lightgray")
View(NL_Municipalities2017) # issue with 'S?dwest-Frysl?n'; it shows as
'S<fa>dwest-Frysl<e2>n'

# Using rgdal everything is fine...
library(rgdal)
nl2 <- readOGR(dsn = "Data/NL_Municipalities2017", layer =
"NL_Municipalities2017")
View(as.data.frame(nl2))
library(mapview)
mapview(nl2)

	[[alternative HTML version deleted]]


From peter.vanhorssen at wxs.nl  Tue Jan 23 22:20:10 2018
From: peter.vanhorssen at wxs.nl (Peter van Horssen)
Date: Tue, 23 Jan 2018 22:20:10 +0100
Subject: [R-sig-Geo] Issue with st_read sf with Encoding for MapInfo
 file (Frisian municipality name)
In-Reply-To: <CAGVoNq24Tmz5x=1r7ZvhY7ONx7rSYwvLDiFb_1r37FNqbbUvwQ@mail.gmail.com>
References: <CAGVoNq2ZNXNB8btCt_pXwuWVNCY=H4wQD1W+yzW_tmq2k0aK3Q@mail.gmail.com>
 <CAGVoNq24Tmz5x=1r7ZvhY7ONx7rSYwvLDiFb_1r37FNqbbUvwQ@mail.gmail.com>
Message-ID: <f3573fe2-a295-6d33-ef31-a48fed379bcd@wxs.nl>

try here:
https://github.com/r-spatial/sf/issues/5
a similar issue with a solution ...

greetings , Peter




Op 23-1-2018 om 21:49 schreef Egge-Jan Poll?:
> Hello,
>
> Would someone know a solution for this issue:
>
> When I load a MapInfo file with st_read (sf) I have an issue with the
> Frisian municipality name 'S?dwest-Frysl?n'; it shows as
> 'S<fa>dwest-Frysl<e2>n' :-( Some issue with the encoding...
>
> Below you will find a reproducible example, which will also download the
> data set used.
>
> If I load the same data with readOGR, everything is fine.
>
> And if I load a comparable data set in ESRI SHP file format with st_read
> (sf) there is no issue either.
>
> So it really has something to do with the MapInfo driver. I did not find a
> solution yet, so any help would be appreciated.
>
> Cheers,
>
> Egge-Jan Poll?
>
>
> REPRODUCIBLE EXAMPLE:
> # Download and read the data
> #
> # Make sure you have your Working Directory properly set, e.g.:
> # setwd("C:/RMOOC")
> #
> # Download
> URL <- "http://www.twiav.nl/files/NL_Municipalities2017.zip"
> datafile <- file.path(basename(URL))
> dir.create("./Data", showWarnings = FALSE)
> workingdirectory <- getwd()
> setwd("./Data")
> download.file(URL, destfile = datafile, mode = "wb")
> unzip(datafile)
> unlink(datafile)
> rm(URL, datafile)
> setwd(workingdirectory)
> rm(workingdirectory)
>
> # Read
> # Make sure the package "sf" is properly installed:
> # install.packages("sf")
> library(sf)
> NL_Municipalities2017 <-
> st_read("Data/NL_Municipalities2017/NL_Municipalities2017.TAB")
> View(NL_Municipalities2017)
> plot(st_geometry(NL_Municipalities2017),col = "darkgreen", border =
> "lightgray")
> View(NL_Municipalities2017) # issue with 'S?dwest-Frysl?n'; it shows as
> 'S<fa>dwest-Frysl<e2>n'
>
> # Using rgdal everything is fine...
> library(rgdal)
> nl2 <- readOGR(dsn = "Data/NL_Municipalities2017", layer =
> "NL_Municipalities2017")
> View(as.data.frame(nl2))
> library(mapview)
> mapview(nl2)
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From e.j.h.polle at gmail.com  Wed Jan 24 22:09:05 2018
From: e.j.h.polle at gmail.com (=?UTF-8?B?RWdnZS1KYW4gUG9sbMOp?=)
Date: Wed, 24 Jan 2018 22:09:05 +0100
Subject: [R-sig-Geo] Issue with st_read sf with Encoding for MapInfo
 file (Frisian municipality name)
In-Reply-To: <f3573fe2-a295-6d33-ef31-a48fed379bcd@wxs.nl>
References: <CAGVoNq2ZNXNB8btCt_pXwuWVNCY=H4wQD1W+yzW_tmq2k0aK3Q@mail.gmail.com>
 <CAGVoNq24Tmz5x=1r7ZvhY7ONx7rSYwvLDiFb_1r37FNqbbUvwQ@mail.gmail.com>
 <f3573fe2-a295-6d33-ef31-a48fed379bcd@wxs.nl>
Message-ID: <CAGVoNq198FvmTHyG7jakKHrXk6ZsQtRrFx=AfDeGNYYeD7hLwg@mail.gmail.com>

Hi Peter,

Thanks for your swift reaction. I followed the link you suggested and tried
to extent my st_read statement with an encoding parameter, but
unfortunately to no avail...

The issue has been solved, though, by following Edzer's suggestion to
abandon the shapefile (or - in my case - the MapInfo file) and to look for
an alternative. I have asked FME to output my sample data set to a GeoJSON
file, and now everything works fine in R :-)

Tnx again,

Egge-Jan

2018-01-23 22:20 GMT+01:00 Peter van Horssen <peter.vanhorssen at wxs.nl>:

> try here:
> https://github.com/r-spatial/sf/issues/5
> a similar issue with a solution ...
>
> greetings , Peter
>
>
>
>
> Op 23-1-2018 om 21:49 schreef Egge-Jan Poll?:
>
>> Hello,
>>
>> Would someone know a solution for this issue:
>>
>> When I load a MapInfo file with st_read (sf) I have an issue with the
>> Frisian municipality name 'S?dwest-Frysl?n'; it shows as
>> 'S<fa>dwest-Frysl<e2>n' :-( Some issue with the encoding...
>>
>> Below you will find a reproducible example, which will also download the
>> data set used.
>>
>> If I load the same data with readOGR, everything is fine.
>>
>> And if I load a comparable data set in ESRI SHP file format with st_read
>> (sf) there is no issue either.
>>
>> So it really has something to do with the MapInfo driver. I did not find a
>> solution yet, so any help would be appreciated.
>>
>> Cheers,
>>
>> Egge-Jan Poll?
>>
>>
>> REPRODUCIBLE EXAMPLE:
>> # Download and read the data
>> #
>> # Make sure you have your Working Directory properly set, e.g.:
>> # setwd("C:/RMOOC")
>> #
>> # Download
>> URL <- "http://www.twiav.nl/files/NL_Municipalities2017.zip"
>> datafile <- file.path(basename(URL))
>> dir.create("./Data", showWarnings = FALSE)
>> workingdirectory <- getwd()
>> setwd("./Data")
>> download.file(URL, destfile = datafile, mode = "wb")
>> unzip(datafile)
>> unlink(datafile)
>> rm(URL, datafile)
>> setwd(workingdirectory)
>> rm(workingdirectory)
>>
>> # Read
>> # Make sure the package "sf" is properly installed:
>> # install.packages("sf")
>> library(sf)
>> NL_Municipalities2017 <-
>> st_read("Data/NL_Municipalities2017/NL_Municipalities2017.TAB")
>> View(NL_Municipalities2017)
>> plot(st_geometry(NL_Municipalities2017),col = "darkgreen", border =
>> "lightgray")
>> View(NL_Municipalities2017) # issue with 'S?dwest-Frysl?n'; it shows as
>> 'S<fa>dwest-Frysl<e2>n'
>>
>> # Using rgdal everything is fine...
>> library(rgdal)
>> nl2 <- readOGR(dsn = "Data/NL_Municipalities2017", layer =
>> "NL_Municipalities2017")
>> View(as.data.frame(nl2))
>> library(mapview)
>> mapview(nl2)
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>

	[[alternative HTML version deleted]]


From stefano.sofia at regione.marche.it  Thu Jan 25 09:55:40 2018
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Thu, 25 Jan 2018 08:55:40 +0000
Subject: [R-sig-Geo] Plot a raster behind a shapefile
Message-ID: <8B435C9568170B469AE31E8891E8CC4F471EB3BB@ESINO.regionemarche.intra>

Dear  list users,
I need to plot a raster behind a shapefile. Both the raster and the shapefile have been built correctly, I checked it.

I created a raster called rain_rast through the command

rain_rast <- raster(OK_rain$krige_output)

with the characteristics here reported
# output:
#class       : RasterLayer
#dimensions  : 151, 125, 18875  (nrow, ncol, ncell)
#resolution  : 1000, 1000  (x, y)
#extent      : 284845.9, 409845.9, 4712479, 4863479  (xmin, xmax, ymin, ymax)
#coord. ref. : +init=epsg:32633 +proj=utm +zone=33 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0
#data source : in memory
#names       : var1.pred
#values      : 0.8162388, 46.54594  (min, max)

and I loaded a shapefile  called Marche_shape through the command

Marche_shape <- readOGR(dsn="Shapefile_regione_Marche", layer="Lim_reg_2012_wgs32633")

which is a shapefile with reference system EPSG:32633 - WGS 84 / UTM zone 33N and a unique layer called Lim_reg_2012_wgs32633.

Could somebody show me how to plot the raster behind the shapefile? (plot alone does not work, I tried with gplot but with no success).
Maybe gglopt2? I tried to study some examples found in the web, but again I could not let them work for me.

Thank you for your help
Stefano



         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Area Meteorologica e  Area nivologica - Centro Funzionale
Servizio Protezione Civile - Regione Marche
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

	[[alternative HTML version deleted]]


From barbosa at uevora.pt  Thu Jan 25 10:06:25 2018
From: barbosa at uevora.pt (A. Marcia BARBOSA)
Date: Thu, 25 Jan 2018 09:06:25 +0000
Subject: [R-sig-Geo] Plot a raster behind a shapefile
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F471EB3BB@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F471EB3BB@ESINO.regionemarche.intra>
Message-ID: <CAP9xbzyxEd2oiJyiQuhBbFdMTvYGV6W3dJnhtgzoYEuCN=RoCw@mail.gmail.com>

Hi,
Have you tried this?

plot(rain_rast)
plot(Marche_shape, add = TRUE)

	[[alternative HTML version deleted]]


From flobetz at web.de  Thu Jan 25 10:07:00 2018
From: flobetz at web.de (Florian Betz)
Date: Thu, 25 Jan 2018 10:07:00 +0100
Subject: [R-sig-Geo] Plot a raster behind a shapefile
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F471EB3BB@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F471EB3BB@ESINO.regionemarche.intra>
Message-ID: <48c0ac53-785b-2301-be3c-e00f45befa91@web.de>

You can try the following:

plot(rain_rast)
plot(Marche_shape, add=TRUE)

Good luck!

Flo

Am 25.01.2018 um 09:55 schrieb Stefano Sofia:
> Dear  list users,
> I need to plot a raster behind a shapefile. Both the raster and the shapefile have been built correctly, I checked it.
>
> I created a raster called rain_rast through the command
>
> rain_rast <- raster(OK_rain$krige_output)
>
> with the characteristics here reported
> # output:
> #class       : RasterLayer
> #dimensions  : 151, 125, 18875  (nrow, ncol, ncell)
> #resolution  : 1000, 1000  (x, y)
> #extent      : 284845.9, 409845.9, 4712479, 4863479  (xmin, xmax, ymin, ymax)
> #coord. ref. : +init=epsg:32633 +proj=utm +zone=33 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0
> #data source : in memory
> #names       : var1.pred
> #values      : 0.8162388, 46.54594  (min, max)
>
> and I loaded a shapefile  called Marche_shape through the command
>
> Marche_shape <- readOGR(dsn="Shapefile_regione_Marche", layer="Lim_reg_2012_wgs32633")
>
> which is a shapefile with reference system EPSG:32633 - WGS 84 / UTM zone 33N and a unique layer called Lim_reg_2012_wgs32633.
>
> Could somebody show me how to plot the raster behind the shapefile? (plot alone does not work, I tried with gplot but with no success).
> Maybe gglopt2? I tried to study some examples found in the web, but again I could not let them work for me.
>
> Thank you for your help
> Stefano
>
>
>
>           (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Area Meteorologica e  Area nivologica - Centro Funzionale
> Servizio Protezione Civile - Regione Marche
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Florian Betz
Gartenstra?e 13
86152 Augsburg, Deutschland

Tel.: 0176 20344096
Mail: flobetz at web.de


From gestauffer at gmail.com  Thu Jan 25 23:26:35 2018
From: gestauffer at gmail.com (Glenn Stauffer)
Date: Thu, 25 Jan 2018 16:26:35 -0600
Subject: [R-sig-Geo] Splitting spatial lines at self intersections (line
	crossings)
Message-ID: <006801d3962b$9059f110$b10dd330$@gmail.com>

I have a Spatial Lines object I would like to split at every point where the
line self-intersects (crosses or touches itself), or anywhere lines touch
each other, if there are multiple lines. 

I've tried using spatstat to convert the SpatialLines to a psp object and
then use the selfcrossing.psp function to find the intersection points (see
example below). But that seems to identify all the nodes, not just the
points where the line crosses. Also, even if it identified only the
crossings (which is what I want), I am not sure how to perform the next step
and split the lines at those points.

So, 1) I need to identify the crossings/touches, and 2) split the lines at
those points.

 

Essentially, what I am looking for is an R equivalent to the planarize
function in ArgGIS. Is there a relatively easy way to do this in R?

 

Thanks,

Glenn

 

Here is an example of what I have tried.

 

 

pts <- cbind(c(120:123,121,125),c(100,100,104,102,99,98))

pt2 <- cbind(c(124,124,123,118,124,125),c(100,97,100,104,106,110))

projstr <- "+init=epsg:3071"         # make everything in meters

L <- SpatialLines(list(Lines(list(Line(pts),Line(pt2)),"X")),proj4string =
CRS(projstr)) 

plot(L)

PSP <- as.psp.SpatialLines(L)

int <- selfcrossing.psp(PSP)

plot(int,add=TRUE,col="red") # identifies more than just the crossings

                                


	[[alternative HTML version deleted]]


From rubak at math.aau.dk  Fri Jan 26 07:48:30 2018
From: rubak at math.aau.dk (Ege Rubak)
Date: Fri, 26 Jan 2018 07:48:30 +0100
Subject: [R-sig-Geo] Splitting spatial lines at self intersections (line
 crossings)
In-Reply-To: <006801d3962b$9059f110$b10dd330$@gmail.com>
References: <006801d3962b$9059f110$b10dd330$@gmail.com>
Message-ID: <2a963040-f346-22c3-f373-8e90f84e823d@math.aau.dk>

The `psp` class in spatstat consists of individual line segments and 
`selfcrossing.psp` checks whether each individual line intersects one of 
the other lines, which happens at all the points in your plot.

If instead you treat each of the two line sequences as a `psp` you can 
check find the crossings of the two `psp` objects. I.e., continuing your 
code (with `spatstat` and `maptools` loaded):

L1 <- SpatialLines(list(Lines(list(Line(pts)), "X")))
L2 <- SpatialLines(list(Lines(list(Line(pt2)), "X")))
l1 <- as.psp(L1)
l2 <- as.psp(L2)
int <- crossing.psp(l1, l2)

This gives you the four intersections between the lines. I don't know of 
a simple way to do the next task in `spatstat`. A useful function if you 
are going to try to write some code is `test.crossing.psp` which gives 
you a logical matrix indicating which segments cross.

Cheers,
Ege

On 01/25/2018 11:26 PM, Glenn Stauffer wrote:
> I have a Spatial Lines object I would like to split at every point where the
> line self-intersects (crosses or touches itself), or anywhere lines touch
> each other, if there are multiple lines.
> 
> I've tried using spatstat to convert the SpatialLines to a psp object and
> then use the selfcrossing.psp function to find the intersection points (see
> example below). But that seems to identify all the nodes, not just the
> points where the line crosses. Also, even if it identified only the
> crossings (which is what I want), I am not sure how to perform the next step
> and split the lines at those points.
> 
> So, 1) I need to identify the crossings/touches, and 2) split the lines at
> those points.
> 
>   
> 
> Essentially, what I am looking for is an R equivalent to the planarize
> function in ArgGIS. Is there a relatively easy way to do this in R?
> 
>   
> 
> Thanks,
> 
> Glenn
> 
>   
> 
> Here is an example of what I have tried.
> 
>   
> 
>   
> 
> pts <- cbind(c(120:123,121,125),c(100,100,104,102,99,98))
> 
> pt2 <- cbind(c(124,124,123,118,124,125),c(100,97,100,104,106,110))
> 
> projstr <- "+init=epsg:3071"         # make everything in meters
> 
> L <- SpatialLines(list(Lines(list(Line(pts),Line(pt2)),"X")),proj4string =
> CRS(projstr))
> 
> plot(L)
> 
> PSP <- as.psp.SpatialLines(L)
> 
> int <- selfcrossing.psp(PSP)
> 
> plot(int,add=TRUE,col="red") # identifies more than just the crossings
> 
>                                  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From mdsumner at gmail.com  Fri Jan 26 13:12:44 2018
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 26 Jan 2018 12:12:44 +0000
Subject: [R-sig-Geo] Splitting spatial lines at self intersections (line
	crossings)
In-Reply-To: <2a963040-f346-22c3-f373-8e90f84e823d@math.aau.dk>
References: <006801d3962b$9059f110$b10dd330$@gmail.com>
 <2a963040-f346-22c3-f373-8e90f84e823d@math.aau.dk>
Message-ID: <CAAcGz9-PihNn=OrrZU1-b4gh9L7TgBLsa_1SduK_tS785Vyc-g@mail.gmail.com>

Ege: I don't believe that this code is enough to get coercion between sp
and spatstat:

pts <- cbind(c(120:123,121,125),c(100,100,104,102,99,98))
pt2 <- cbind(c(124,124,123,118,124,125),c(100,97,100,104,106,110))
library(sp)
library(spatstat)
L1 <- SpatialLines(list(Lines(list(Line(pts)), "X")))
L2 <- SpatialLines(list(Lines(list(Line(pt2)), "X")))
l1 <- as.psp(L1)
l2 <- as.psp(L2)
int <- crossing.psp(l1, l2)

Are we relying on some other code, or perhaps a specific version of
spatstat or its family?  (I know ways to convert from Spatial to psp, but I
was taken by this apparent lack of infrastructure - and I'm very keen on
seeing more bridges between these rich worlds).

Cheers, Mike


On Fri, 26 Jan 2018 at 17:48 Ege Rubak <rubak at math.aau.dk> wrote:

> The `psp` class in spatstat consists of individual line segments and
> `selfcrossing.psp` checks whether each individual line intersects one of
> the other lines, which happens at all the points in your plot.
>
> If instead you treat each of the two line sequences as a `psp` you can
> check find the crossings of the two `psp` objects. I.e., continuing your
> code (with `spatstat` and `maptools` loaded):
>
> L1 <- SpatialLines(list(Lines(list(Line(pts)), "X")))
> L2 <- SpatialLines(list(Lines(list(Line(pt2)), "X")))
> l1 <- as.psp(L1)
> l2 <- as.psp(L2)
> int <- crossing.psp(l1, l2)
>
> This gives you the four intersections between the lines. I don't know of
> a simple way to do the next task in `spatstat`. A useful function if you
> are going to try to write some code is `test.crossing.psp` which gives
> you a logical matrix indicating which segments cross.
>
> Cheers,
> Ege
>
> On 01/25/2018 11:26 PM, Glenn Stauffer wrote:
> > I have a Spatial Lines object I would like to split at every point where
> the
> > line self-intersects (crosses or touches itself), or anywhere lines touch
> > each other, if there are multiple lines.
> >
> > I've tried using spatstat to convert the SpatialLines to a psp object and
> > then use the selfcrossing.psp function to find the intersection points
> (see
> > example below). But that seems to identify all the nodes, not just the
> > points where the line crosses. Also, even if it identified only the
> > crossings (which is what I want), I am not sure how to perform the next
> step
> > and split the lines at those points.
> >
> > So, 1) I need to identify the crossings/touches, and 2) split the lines
> at
> > those points.
> >
> >
> >
> > Essentially, what I am looking for is an R equivalent to the planarize
> > function in ArgGIS. Is there a relatively easy way to do this in R?
> >
> >
> >
> > Thanks,
> >
> > Glenn
> >
> >
> >
> > Here is an example of what I have tried.
> >
> >
> >
> >
> >
> > pts <- cbind(c(120:123,121,125),c(100,100,104,102,99,98))
> >
> > pt2 <- cbind(c(124,124,123,118,124,125),c(100,97,100,104,106,110))
> >
> > projstr <- "+init=epsg:3071"         # make everything in meters
> >
> > L <- SpatialLines(list(Lines(list(Line(pts),Line(pt2)),"X")),proj4string
> =
> > CRS(projstr))
> >
> > plot(L)
> >
> > PSP <- as.psp.SpatialLines(L)
> >
> > int <- selfcrossing.psp(PSP)
> >
> > plot(int,add=TRUE,col="red") # identifies more than just the crossings
> >
> >
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From saubhagya at gatech.edu  Fri Jan 26 17:42:35 2018
From: saubhagya at gatech.edu (Rathore, Saubhagya Singh)
Date: Fri, 26 Jan 2018 16:42:35 +0000
Subject: [R-sig-Geo] R version 3.3.2,
 Windows 10: gstat package: Defining new correlation model in gstat
 package?
Message-ID: <CY4PR07MB30478F6DCB8E299C08C9A713CFE00@CY4PR07MB3047.namprd07.prod.outlook.com>

Hello Everyone,

Is it possible to define and use the new correlation model in `vgm` function of `gstat` package in R, in order to simulate random fields? I need to use correlation function (as suggested here[1] ) for the log-transformed exponentially correlated spatial data. The options available in `vgm` are "Exp", "Sph", "Gau", "Mat"

  [1]: https://stats.stackexchange.com/questions/325052/how-is-spatial-correlation-for-a-normally-distributed-data-related-to-spatial-co

Any suggestion/help would be appreciated.

Thanks

Saubhagya Singh Rathore
PhD Candidate
Civil and Environmental Engineering
[logos]

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20180126/4e4d7303/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.jpg
Type: image/jpeg
Size: 2207 bytes
Desc: image001.jpg
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20180126/4e4d7303/attachment.jpg>

From marcelino.delacruz at urjc.es  Fri Jan 26 18:04:01 2018
From: marcelino.delacruz at urjc.es (Marcelino de la Cruz Rot)
Date: Fri, 26 Jan 2018 18:04:01 +0100
Subject: [R-sig-Geo] Splitting spatial lines at self intersections (line
 crossings)
In-Reply-To: <CAAcGz9-PihNn=OrrZU1-b4gh9L7TgBLsa_1SduK_tS785Vyc-g@mail.gmail.com>
References: <006801d3962b$9059f110$b10dd330$@gmail.com>
 <2a963040-f346-22c3-f373-8e90f84e823d@math.aau.dk>
 <CAAcGz9-PihNn=OrrZU1-b4gh9L7TgBLsa_1SduK_tS785Vyc-g@mail.gmail.com>
Message-ID: <13bbe92b-5c4d-a4dc-3a42-ca372af6db50@urjc.es>

You should load before library(maptools) and the coercion is done.

Cheers

Marcelino




El 26/01/2018 a las 13:12, Michael Sumner escribi?:
> Ege: I don't believe that this code is enough to get coercion between sp
> and spatstat:
>
> pts <- cbind(c(120:123,121,125),c(100,100,104,102,99,98))
> pt2 <- cbind(c(124,124,123,118,124,125),c(100,97,100,104,106,110))
> library(sp)
> library(spatstat)
> L1 <- SpatialLines(list(Lines(list(Line(pts)), "X")))
> L2 <- SpatialLines(list(Lines(list(Line(pt2)), "X")))
> l1 <- as.psp(L1)
> l2 <- as.psp(L2)
> int <- crossing.psp(l1, l2)
>
> Are we relying on some other code, or perhaps a specific version of
> spatstat or its family?  (I know ways to convert from Spatial to psp, but I
> was taken by this apparent lack of infrastructure - and I'm very keen on
> seeing more bridges between these rich worlds).
>
> Cheers, Mike
>
>
> On Fri, 26 Jan 2018 at 17:48 Ege Rubak <rubak at math.aau.dk> wrote:
>
>> The `psp` class in spatstat consists of individual line segments and
>> `selfcrossing.psp` checks whether each individual line intersects one of
>> the other lines, which happens at all the points in your plot.
>>
>> If instead you treat each of the two line sequences as a `psp` you can
>> check find the crossings of the two `psp` objects. I.e., continuing your
>> code (with `spatstat` and `maptools` loaded):
>>
>> L1 <- SpatialLines(list(Lines(list(Line(pts)), "X")))
>> L2 <- SpatialLines(list(Lines(list(Line(pt2)), "X")))
>> l1 <- as.psp(L1)
>> l2 <- as.psp(L2)
>> int <- crossing.psp(l1, l2)
>>
>> This gives you the four intersections between the lines. I don't know of
>> a simple way to do the next task in `spatstat`. A useful function if you
>> are going to try to write some code is `test.crossing.psp` which gives
>> you a logical matrix indicating which segments cross.
>>
>> Cheers,
>> Ege
>>
>> On 01/25/2018 11:26 PM, Glenn Stauffer wrote:
>>> I have a Spatial Lines object I would like to split at every point where
>> the
>>> line self-intersects (crosses or touches itself), or anywhere lines touch
>>> each other, if there are multiple lines.
>>>
>>> I've tried using spatstat to convert the SpatialLines to a psp object and
>>> then use the selfcrossing.psp function to find the intersection points
>> (see
>>> example below). But that seems to identify all the nodes, not just the
>>> points where the line crosses. Also, even if it identified only the
>>> crossings (which is what I want), I am not sure how to perform the next
>> step
>>> and split the lines at those points.
>>>
>>> So, 1) I need to identify the crossings/touches, and 2) split the lines
>> at
>>> those points.
>>>
>>>
>>>
>>> Essentially, what I am looking for is an R equivalent to the planarize
>>> function in ArgGIS. Is there a relatively easy way to do this in R?
>>>
>>>
>>>
>>> Thanks,
>>>
>>> Glenn
>>>
>>>
>>>
>>> Here is an example of what I have tried.
>>>
>>>
>>>
>>>
>>>
>>> pts <- cbind(c(120:123,121,125),c(100,100,104,102,99,98))
>>>
>>> pt2 <- cbind(c(124,124,123,118,124,125),c(100,97,100,104,106,110))
>>>
>>> projstr <- "+init=epsg:3071"         # make everything in meters
>>>
>>> L <- SpatialLines(list(Lines(list(Line(pts),Line(pt2)),"X")),proj4string
>> =
>>> CRS(projstr))
>>>
>>> plot(L)
>>>
>>> PSP <- as.psp.SpatialLines(L)
>>>
>>> int <- selfcrossing.psp(PSP)
>>>
>>> plot(int,add=TRUE,col="red") # identifies more than just the crossings
>>>
>>>
>>>
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>

-- 
Marcelino de la Cruz Rot
Depto. de Biolog?a y Geolog?a
F?sica y Qu?mica Inorg?nica
Universidad Rey Juan Carlos
M?stoles Espa?a


From gestauffer at gmail.com  Fri Jan 26 20:22:30 2018
From: gestauffer at gmail.com (Glenn Stauffer)
Date: Fri, 26 Jan 2018 13:22:30 -0600
Subject: [R-sig-Geo] Error in file.exists(params[[i]]) : invalid 'file'
	argument when using v.clean function in RQGIS
Message-ID: <008001d396db$037aa590$0a6ff0b0$@gmail.com>

I am working with SpatialLines in R, and want to split lines at every point
where lines cross (like the Planarize function in ArcGIS). The R package
RQGIS makes QGIS functionality accessible in R (see example from Jannes
Muenchow at
http://r-sig-geo.2731867.n2.nabble.com/v-split-length-GRASS-in-R-td7590611.h
tml ), and the GRASS function v.clean should do exactly what I want.
However, I have not been able to get it to work, and have run into two
problems.

 

First, when I run the get_args_man() function I apparently a window that
pops up and says "

Runtime Error! 

Program: C\Program Files\R\R-3.4.0\bin\x64\RGui.exe

R6034

An application has made an attempt to load the C runtime library in
correctly.

Please contact the application's support team for more information."

 

I only get this the first time I run try running the get_args_man()
function, and despite the popup, the arguments are retrieved (the function
seems to work). Subsequent calls to the function do not generate the
message.

 

Secondly, when I call the run_qgi()s function, with 'alg="grass7:v.clean"',
I always get the error message "Error in file.exists(params[[i]]) : invalid
'file' argument". This does not happen when I run the example from the link
I referenced above (with alg="v.split"). I've tried running the function
line-by-line, and it trips at the following line within the run_qgis()
function:

"params <- pass_args(alg, params = params, NA_flag = NA_flag,qgis_env =
qgis_env)"

 

Can anyone suggest a cause or solution for either of these problems (but
especially the latter)? On the first problem, could this be related to a
permissions issue? 

 

Below is a contrived example that should illustrate what I am talking about
(unless the problems are specific to my computer). 

 

Thanks,

Glenn

 

#################

# Example Code

#################

 

library(sp)

library(RQGIS)

 

pts <- cbind(c(120:123,121,125),c(100,100,104,102,99,98))

pt2 <- cbind(c(124,124,123,118,124,125),c(100,97,100,104,106,110))

projstr <- "+init=epsg:3071"         # make everything in meters

L <- SpatialLines(list(Lines(list(Line(pts),Line(pt2)),"X")),proj4string =
CRS(projstr)) 

plot(L)

# indicate where QGIS is installed on your computer

qgis_env <- set_env("C:/Program Files/QGIS 2.14")

# get args for GRASS function (generates runtime error when first called)

args <- get_args_man("grass7:v.clean", qgis_env = qgis_env, options = TRUE)

# have a look at the GRASS online help

open_help("grass7:v.clean", qgis_env = qgis_env)

 

# specify the necessary arguments

args$input <- L

args$tool <- "break"

args$output <- file.path(tempdir(), "out.shp")

# load the output directly into R again

out <- run_qgis(alg = "grass7:v.clean", params = args,

                load_output = TRUE,

                qgis_env = qgis_env)

 

 

 

 


	[[alternative HTML version deleted]]


From afischbach at usgs.gov  Fri Jan 26 21:23:04 2018
From: afischbach at usgs.gov (Fischbach, Anthony)
Date: Fri, 26 Jan 2018 11:23:04 -0900
Subject: [R-sig-Geo] accessing spatial imagery via rgdal's web map tile
	service driver
Message-ID: <CA+ZRYj_c_LT8WYU+UEgmg-OZrNsXhTVT1jjZT0LXcDNf-R=HHg@mail.gmail.com>

I see that WMS ("OGC Web Map Service") and WMTS ("OGC Web Mab Tile
Service") are supported within my rgdal installation , however, it is
unclear how to call for WMTS imagery.
Please advise on how to access geo-referenced imagery through a web map
tile service, such as described here
(
https://wiki.earthdata.nasa.gov/display/GIBS/Map+Library+Usage#expand-GDALBasics
)
for gdal using the current rgdal version (under R version 3.4.3 rgdal
version 1.2-16)

	[[alternative HTML version deleted]]


From gestauffer at gmail.com  Fri Jan 26 22:51:18 2018
From: gestauffer at gmail.com (Glenn Stauffer)
Date: Fri, 26 Jan 2018 15:51:18 -0600
Subject: [R-sig-Geo] Error in file.exists(params[[i]]) : invalid 'file'
	argument when using v.clean function in RQGIS
In-Reply-To: <008001d396db$037aa590$0a6ff0b0$@gmail.com>
References: <008001d396db$037aa590$0a6ff0b0$@gmail.com>
Message-ID: <00a001d396ef$cc6caa20$6545fe60$@gmail.com>

I still don't know why I get the Runtime Error the first time I call the
function get_args_man(). 

 

But, more importantly, it looks my issue with the second problem was as
simple as the fact that I was trying to apply v.clean to a SpatialLines
feature instead of the required SpatialLinesDataFrame feature. It seems to
work now, and I'm pretty happy about that!

 

Glenn

 

From: Glenn Stauffer [mailto:gestauffer at gmail.com] 
Sent: Friday, January 26, 2018 1:23 PM
To: r-sig-geo at r-project.org
Subject: Error in file.exists(params[[i]]) : invalid 'file' argument when
using v.clean function in RQGIS

 

I am working with SpatialLines in R, and want to split lines at every point
where lines cross (like the Planarize function in ArcGIS). The R package
RQGIS makes QGIS functionality accessible in R (see example from Jannes
Muenchow at
http://r-sig-geo.2731867.n2.nabble.com/v-split-length-GRASS-in-R-td7590611.h
tml ), and the GRASS function v.clean should do exactly what I want.
However, I have not been able to get it to work, and have run into two
problems.

 

First, when I run the get_args_man() function I apparently a window that
pops up and says "

Runtime Error! 

Program: C\Program Files\R\R-3.4.0\bin\x64\RGui.exe

R6034

An application has made an attempt to load the C runtime library in
correctly.

Please contact the application's support team for more information."

 

I only get this the first time I run try running the get_args_man()
function, and despite the popup, the arguments are retrieved (the function
seems to work). Subsequent calls to the function do not generate the
message.

 

Secondly, when I call the run_qgi()s function, with 'alg="grass7:v.clean"',
I always get the error message "Error in file.exists(params[[i]]) : invalid
'file' argument". This does not happen when I run the example from the link
I referenced above (with alg="v.split"). I've tried running the function
line-by-line, and it trips at the following line within the run_qgis()
function:

"params <- pass_args(alg, params = params, NA_flag = NA_flag,qgis_env =
qgis_env)"

 

Can anyone suggest a cause or solution for either of these problems (but
especially the latter)? On the first problem, could this be related to a
permissions issue? 

 

Below is a contrived example that should illustrate what I am talking about
(unless the problems are specific to my computer). 

 

Thanks,

Glenn

 

#################

# Example Code

#################

 

library(sp)

library(RQGIS)

 

pts <- cbind(c(120:123,121,125),c(100,100,104,102,99,98))

pt2 <- cbind(c(124,124,123,118,124,125),c(100,97,100,104,106,110))

projstr <- "+init=epsg:3071"         # make everything in meters

L <- SpatialLines(list(Lines(list(Line(pts),Line(pt2)),"X")),proj4string =
CRS(projstr)) 

plot(L)

# indicate where QGIS is installed on your computer

qgis_env <- set_env("C:/Program Files/QGIS 2.14")

# get args for GRASS function (generates runtime error when first called)

args <- get_args_man("grass7:v.clean", qgis_env = qgis_env, options = TRUE)

# have a look at the GRASS online help

open_help("grass7:v.clean", qgis_env = qgis_env)

 

# specify the necessary arguments

args$input <- L

args$tool <- "break"

args$output <- file.path(tempdir(), "out.shp")

# load the output directly into R again

out <- run_qgis(alg = "grass7:v.clean", params = args,

                load_output = TRUE,

                qgis_env = qgis_env)

 

 

 

 


	[[alternative HTML version deleted]]


From gestauffer at gmail.com  Fri Jan 26 23:04:45 2018
From: gestauffer at gmail.com (Glenn Stauffer)
Date: Fri, 26 Jan 2018 16:04:45 -0600
Subject: [R-sig-Geo] Splitting spatial lines at self intersections (line
	crossings)
In-Reply-To: <004d01d396d3$80511660$80f34320$@gmail.com>
References: <006801d3962b$9059f110$b10dd330$@gmail.com>
 <2a963040-f346-22c3-f373-8e90f84e823d@math.aau.dk>
 <004d01d396d3$80511660$80f34320$@gmail.com>
Message-ID: <00a901d396f1$adbdd3e0$09397ba0$@gmail.com>

I think I have a solution now. 
To recap, I wanted to planarize a line feature (split every line at every
line crossing), and I wanted an R solution so I could iterate over many
feature objects. My solution obviously does not strictly use R, but it is
carried out completely from within R. I used the v.clean algorithm from
GRASS, passed as an argument to the run_qgis function from the RQGIS
package. Seems to do exactly what I want. 
My initial problem with v.clean was that I was passing a SpatialLines
feature instead of a SpatialLinesDataFrame feature to the algorithm.

Glenn

-----Original Message-----
From: Glenn Stauffer [mailto:gestauffer at gmail.com] 
Sent: Friday, January 26, 2018 12:29 PM
To: 'Ege Rubak' <rubak at math.aau.dk>
Subject: RE: [R-sig-Geo] Splitting spatial lines at self intersections (line
crossings)

I think I am really close to a solution using the RQGIS package and the
GRASS function v.clean. The v.clean function should do exactly what I want,
but I have not been able to get it to work yet from R, although I could get
another GRASS functions to work (see example from Jannes Muenchow at
http://r-sig-geo.2731867.n2.nabble.com/v-split-length-GRASS-in-R-td7590611.h
tml ). When I try v.clean, I keep getting an error " Error in
file.exists(params[[i]]) : invalid 'file' argument", and have not been able
to ferret out the cause. I am going to start a new thread about this, and
report back here if I can get resolution.

Glenn

-----Original Message-----
From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Ege
Rubak
Sent: Friday, January 26, 2018 12:49 AM
To: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] Splitting spatial lines at self intersections (line
crossings)

The `psp` class in spatstat consists of individual line segments and
`selfcrossing.psp` checks whether each individual line intersects one of the
other lines, which happens at all the points in your plot.

If instead you treat each of the two line sequences as a `psp` you can check
find the crossings of the two `psp` objects. I.e., continuing your code
(with `spatstat` and `maptools` loaded):

L1 <- SpatialLines(list(Lines(list(Line(pts)), "X")))
L2 <- SpatialLines(list(Lines(list(Line(pt2)), "X")))
l1 <- as.psp(L1)
l2 <- as.psp(L2)
int <- crossing.psp(l1, l2)

This gives you the four intersections between the lines. I don't know of a
simple way to do the next task in `spatstat`. A useful function if you are
going to try to write some code is `test.crossing.psp` which gives you a
logical matrix indicating which segments cross.

Cheers,
Ege

On 01/25/2018 11:26 PM, Glenn Stauffer wrote:
> I have a Spatial Lines object I would like to split at every point 
> where the line self-intersects (crosses or touches itself), or 
> anywhere lines touch each other, if there are multiple lines.
> 
> I've tried using spatstat to convert the SpatialLines to a psp object 
> and then use the selfcrossing.psp function to find the intersection 
> points (see example below). But that seems to identify all the nodes, 
> not just the points where the line crosses. Also, even if it 
> identified only the crossings (which is what I want), I am not sure 
> how to perform the next step and split the lines at those points.
> 
> So, 1) I need to identify the crossings/touches, and 2) split the 
> lines at those points.
> 
>   
> 
> Essentially, what I am looking for is an R equivalent to the planarize 
> function in ArgGIS. Is there a relatively easy way to do this in R?
> 
>   
> 
> Thanks,
> 
> Glenn
> 
>   
> 
> Here is an example of what I have tried.
> 
>   
> 
>   
> 
> pts <- cbind(c(120:123,121,125),c(100,100,104,102,99,98))
> 
> pt2 <- cbind(c(124,124,123,118,124,125),c(100,97,100,104,106,110))
> 
> projstr <- "+init=epsg:3071"         # make everything in meters
> 
> L <-
> SpatialLines(list(Lines(list(Line(pts),Line(pt2)),"X")),proj4string =
> CRS(projstr))
> 
> plot(L)
> 
> PSP <- as.psp.SpatialLines(L)
> 
> int <- selfcrossing.psp(PSP)
> 
> plot(int,add=TRUE,col="red") # identifies more than just the crossings
> 
>                                  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From mdsumner at gmail.com  Fri Jan 26 23:24:31 2018
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 26 Jan 2018 22:24:31 +0000
Subject: [R-sig-Geo] Splitting spatial lines at self intersections (line
	crossings)
In-Reply-To: <00a901d396f1$adbdd3e0$09397ba0$@gmail.com>
References: <006801d3962b$9059f110$b10dd330$@gmail.com>
 <2a963040-f346-22c3-f373-8e90f84e823d@math.aau.dk>
 <004d01d396d3$80511660$80f34320$@gmail.com>
 <00a901d396f1$adbdd3e0$09397ba0$@gmail.com>
Message-ID: <CAAcGz98Q5KVPTdHGkmNu06_3Sfebe4Rov2NjPOGL5KxRe-Fsng@mail.gmail.com>

I think rgeos::gNode will do it,  prior to decomposition, and perhaps
requiring a union beforehand -  there are other options, but I got side
tracked exploring them :)

On Sat, 27 Jan 2018, 09:05 Glenn Stauffer, <gestauffer at gmail.com> wrote:

> I think I have a solution now.
> To recap, I wanted to planarize a line feature (split every line at every
> line crossing), and I wanted an R solution so I could iterate over many
> feature objects. My solution obviously does not strictly use R, but it is
> carried out completely from within R. I used the v.clean algorithm from
> GRASS, passed as an argument to the run_qgis function from the RQGIS
> package. Seems to do exactly what I want.
> My initial problem with v.clean was that I was passing a SpatialLines
> feature instead of a SpatialLinesDataFrame feature to the algorithm.
>
> Glenn
>
> -----Original Message-----
> From: Glenn Stauffer [mailto:gestauffer at gmail.com]
> Sent: Friday, January 26, 2018 12:29 PM
> To: 'Ege Rubak' <rubak at math.aau.dk>
> Subject: RE: [R-sig-Geo] Splitting spatial lines at self intersections
> (line
> crossings)
>
> I think I am really close to a solution using the RQGIS package and the
> GRASS function v.clean. The v.clean function should do exactly what I want,
> but I have not been able to get it to work yet from R, although I could get
> another GRASS functions to work (see example from Jannes Muenchow at
>
> http://r-sig-geo.2731867.n2.nabble.com/v-split-length-GRASS-in-R-td7590611.h
> tml
> <http://r-sig-geo.2731867.n2.nabble.com/v-split-length-GRASS-in-R-td7590611.html>
> ). When I try v.clean, I keep getting an error " Error in
> file.exists(params[[i]]) : invalid 'file' argument", and have not been able
> to ferret out the cause. I am going to start a new thread about this, and
> report back here if I can get resolution.
>
> Glenn
>
> -----Original Message-----
> From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Ege
> Rubak
> Sent: Friday, January 26, 2018 12:49 AM
> To: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] Splitting spatial lines at self intersections
> (line
> crossings)
>
> The `psp` class in spatstat consists of individual line segments and
> `selfcrossing.psp` checks whether each individual line intersects one of
> the
> other lines, which happens at all the points in your plot.
>
> If instead you treat each of the two line sequences as a `psp` you can
> check
> find the crossings of the two `psp` objects. I.e., continuing your code
> (with `spatstat` and `maptools` loaded):
>
> L1 <- SpatialLines(list(Lines(list(Line(pts)), "X")))
> L2 <- SpatialLines(list(Lines(list(Line(pt2)), "X")))
> l1 <- as.psp(L1)
> l2 <- as.psp(L2)
> int <- crossing.psp(l1, l2)
>
> This gives you the four intersections between the lines. I don't know of a
> simple way to do the next task in `spatstat`. A useful function if you are
> going to try to write some code is `test.crossing.psp` which gives you a
> logical matrix indicating which segments cross.
>
> Cheers,
> Ege
>
> On 01/25/2018 11:26 PM, Glenn Stauffer wrote:
> > I have a Spatial Lines object I would like to split at every point
> > where the line self-intersects (crosses or touches itself), or
> > anywhere lines touch each other, if there are multiple lines.
> >
> > I've tried using spatstat to convert the SpatialLines to a psp object
> > and then use the selfcrossing.psp function to find the intersection
> > points (see example below). But that seems to identify all the nodes,
> > not just the points where the line crosses. Also, even if it
> > identified only the crossings (which is what I want), I am not sure
> > how to perform the next step and split the lines at those points.
> >
> > So, 1) I need to identify the crossings/touches, and 2) split the
> > lines at those points.
> >
> >
> >
> > Essentially, what I am looking for is an R equivalent to the planarize
> > function in ArgGIS. Is there a relatively easy way to do this in R?
> >
> >
> >
> > Thanks,
> >
> > Glenn
> >
> >
> >
> > Here is an example of what I have tried.
> >
> >
> >
> >
> >
> > pts <- cbind(c(120:123,121,125),c(100,100,104,102,99,98))
> >
> > pt2 <- cbind(c(124,124,123,118,124,125),c(100,97,100,104,106,110))
> >
> > projstr <- "+init=epsg:3071"         # make everything in meters
> >
> > L <-
> > SpatialLines(list(Lines(list(Line(pts),Line(pt2)),"X")),proj4string =
> > CRS(projstr))
> >
> > plot(L)
> >
> > PSP <- as.psp.SpatialLines(L)
> >
> > int <- selfcrossing.psp(PSP)
> >
> > plot(int,add=TRUE,col="red") # identifies more than just the crossings
> >
> >
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From d.orme at imperial.ac.uk  Sat Jan 27 14:47:12 2018
From: d.orme at imperial.ac.uk (Orme, David)
Date: Sat, 27 Jan 2018 13:47:12 +0000
Subject: [R-sig-Geo] Breaking a polygon at a line
Message-ID: <E22C3CE5-0893-4CFC-A86C-C17EFB453E9C@imperial.ac.uk>

Hi,

I?m trying to cut a polygon open into a linestring using a line string as a blade (for want of a better description). The specific use case is that I want to convert a polygon boundary into a GPX route and want to control the starting point.

Using ?sf?, an simple example of the inputs and target is:

poly <- st_sfc(st_polygon(list(matrix(c(0,2,2,0,0,0,0,2,2,0), ncol=2))))
line <- st_sfc(st_linestring(matrix(c(1,3,1,1), ncol=2)))

plot(poly, xlim=c(-1,4), ylim=c(-1,3), lwd=3, border='grey70')
plot(line, add=TRUE, col='red')

target <- st_sfc(st_linestring(matrix(c(2,2,0,0,2,2,1,0,0,2,2,1), ncol=2)))
text(st_coordinates(target))

Options:
- st_split() always returns the same feature type so it only splits if the line crosses the polygon boundary at least twice.
- st_cast() is converts the polygon to a linestring, but uses the first coordinate in the polygon as the starting point of the line string.

So, the clunky solution I can see is to use st_intersection to find a point on both the line and polygon, find distances from all points on the polygon boundary to that and then juggle some blocks of coordinates to get the order right.

Am I missing something? Bit of a fringe use-case, I suspect but I was curious if there is an existing solution.

Thanks,
David



	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Sat Jan 27 16:01:28 2018
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 27 Jan 2018 16:01:28 +0100
Subject: [R-sig-Geo] accessing spatial imagery via rgdal's web map tile
 service driver
In-Reply-To: <CA+ZRYj_c_LT8WYU+UEgmg-OZrNsXhTVT1jjZT0LXcDNf-R=HHg@mail.gmail.com>
References: <CA+ZRYj_c_LT8WYU+UEgmg-OZrNsXhTVT1jjZT0LXcDNf-R=HHg@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.1801271558260.498@reclus.nhh.no>

On Fri, 26 Jan 2018, Fischbach, Anthony wrote:

> I see that WMS ("OGC Web Map Service") and WMTS ("OGC Web Mab Tile
> Service") are supported within my rgdal installation , however, it is
> unclear how to call for WMTS imagery.
> Please advise on how to access geo-referenced imagery through a web map
> tile service, such as described here
> (
> https://wiki.earthdata.nasa.gov/display/GIBS/Map+Library+Usage#expand-GDALBasics
> )
> for gdal using the current rgdal version (under R version 3.4.3 rgdal
> version 1.2-16)

Do what anyone using GDAL drivers would do, refer to the documentation, in 
this case on http://www.gdal.org/frmt_wms.html.

Roger

>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From todd.mcdonnell at esenvironmental.com  Tue Jan 30 17:23:34 2018
From: todd.mcdonnell at esenvironmental.com (Todd McDonnell)
Date: Tue, 30 Jan 2018 08:23:34 -0800
Subject: [R-sig-Geo] Monte Carlo with mc2d
Message-ID: <001e01d399e6$aebb88d0$0c329a70$@esenvironmental.com>

Hi all,

 

I posted a question to Stack Overflow a couple weeks ago regarding Monte
Carlo simulation with mc2d with no replies:

https://stackoverflow.com/questions/48306933/grid-based-monte-carlo-simulati
on-using-mc2d

 

Might anyone here have a suggestion for how to address the error?

 

My approach is largely based on this advice:

http://r-sig-geo.2731867.n2.nabble.com/apply-monte-carlo-simulation-for-each
-cell-in-a-matrix-originally-raster-td7367094.html#a7367555

 

Thanks in advance for any suggestions,

Todd

 

--

Todd McDonnell

Research Scientist, Ph.D.

E&S Environmental Chemistry

2161 NW Fillmore Ave., Corvallis, OR

 


	[[alternative HTML version deleted]]


From vijaylulla at gmail.com  Tue Jan 30 20:36:16 2018
From: vijaylulla at gmail.com (Vijay Lulla)
Date: Tue, 30 Jan 2018 14:36:16 -0500
Subject: [R-sig-Geo] Monte Carlo with mc2d
In-Reply-To: <001e01d399e6$aebb88d0$0c329a70$@esenvironmental.com>
References: <001e01d399e6$aebb88d0$0c329a70$@esenvironmental.com>
Message-ID: <CAKkiGbvt5TkDhCXGMsR8Ks=Q8_csNG_h-7VC6w5ys-3MwO-atw@mail.gmail.com>

Return the min,mean,max values as a list of numbers and calc will create a
RasterStack.  ?`calc` states that 'calc' returns a RasterBrick if 'fun'
returns more than one number.  Below are a few minor changes I had to make
to your function.

fun <- function(x) {
  # Convert each raster to mcnode object
  dA <- mcdata(x[1], type="0")
  dB <- mcdata(x[2], type="0")
  dC <- mcdata(x[3], type="0")
  dD <- mcdata(x[4], type="0")

  # Define uniform distirbutions for each raster
  stA <- mcstoc(runif, type="U", min=dA-uA, max=dA+uA, rtrunc=TRUE, linf=0)
# modified: fixed typo!
  stB <- mcstoc(runif, type="U", min=dA-uB, max=dA+uB, rtrunc=TRUE, linf=0)
  stC <- mcstoc(runif, type="U", min=dA-uC, max=dA+uC, rtrunc=TRUE, linf=0)
  stD <- mcstoc(runif, type="U", min=dA-uD, max=dA+uD, rtrunc=TRUE, linf=0)

  # Apply Monte Carlo to this equation
  CL <- stA + stB + stC + stD
  # Extract the min, mean, and max CL from the 1000 iterations
  c(min(CL), mean(CL), max(CL))  # modified: return vector of numbers
}

HTH,
Vijay.


On Tue, Jan 30, 2018 at 11:23 AM, Todd McDonnell <
todd.mcdonnell at esenvironmental.com> wrote:

> Hi all,
>
>
>
> I posted a question to Stack Overflow a couple weeks ago regarding Monte
> Carlo simulation with mc2d with no replies:
>
> https://stackoverflow.com/questions/48306933/grid-based-
> monte-carlo-simulati
> on-using-mc2d
>
>
>
> Might anyone here have a suggestion for how to address the error?
>
>
>
> My approach is largely based on this advice:
>
> http://r-sig-geo.2731867.n2.nabble.com/apply-monte-carlo-
> simulation-for-each
> -cell-in-a-matrix-originally-raster-td7367094.html#a7367555
>
>
>
> Thanks in advance for any suggestions,
>
> Todd
>
>
>
> --
>
> Todd McDonnell
>
> Research Scientist, Ph.D.
>
> E&S Environmental Chemistry
>
> 2161 NW Fillmore Ave., Corvallis, OR
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Vijay Lulla, Ph.D.

Assistant Professor,
Dept. of Geography, IUPUI
425 University Blvd, CA-207C.
Indianapolis, IN-46202
vlulla at iupui.edu

<http://vijaylulla.com>
http://vijaylulla.com

	[[alternative HTML version deleted]]


From todd.mcdonnell at esenvironmental.com  Tue Jan 30 21:41:38 2018
From: todd.mcdonnell at esenvironmental.com (Todd McDonnell)
Date: Tue, 30 Jan 2018 12:41:38 -0800
Subject: [R-sig-Geo] Monte Carlo with mc2d
In-Reply-To: <CAKkiGbvt5TkDhCXGMsR8Ks=Q8_csNG_h-7VC6w5ys-3MwO-atw@mail.gmail.com>
References: <001e01d399e6$aebb88d0$0c329a70$@esenvironmental.com>
 <CAKkiGbvt5TkDhCXGMsR8Ks=Q8_csNG_h-7VC6w5ys-3MwO-atw@mail.gmail.com>
Message-ID: <007801d39a0a$ba396370$2eac2a50$@esenvironmental.com>

This works great, many thanks Vijay. I have updated the code on Stack Overflow as well.

 

Todd

 

From: Vijay Lulla [mailto:vijaylulla at gmail.com] 
Sent: Tuesday, January 30, 2018 11:36 AM
To: Todd McDonnell
Cc: R-sig-geo Mailing List
Subject: Re: [R-sig-Geo] Monte Carlo with mc2d

 

Return the min,mean,max values as a list of numbers and calc will create a RasterStack.  ?`calc` states that 'calc' returns a RasterBrick if 'fun' returns more than one number.  Below are a few minor changes I had to make to your function.

fun <- function(x) {
  # Convert each raster to mcnode object
  dA <- mcdata(x[1], type="0")
  dB <- mcdata(x[2], type="0")
  dC <- mcdata(x[3], type="0")
  dD <- mcdata(x[4], type="0")

  # Define uniform distirbutions for each raster
  stA <- mcstoc(runif, type="U", min=dA-uA, max=dA+uA, rtrunc=TRUE, linf=0) # modified: fixed typo!
  stB <- mcstoc(runif, type="U", min=dA-uB, max=dA+uB, rtrunc=TRUE, linf=0)
  stC <- mcstoc(runif, type="U", min=dA-uC, max=dA+uC, rtrunc=TRUE, linf=0)
  stD <- mcstoc(runif, type="U", min=dA-uD, max=dA+uD, rtrunc=TRUE, linf=0)

  # Apply Monte Carlo to this equation
  CL <- stA + stB + stC + stD
  # Extract the min, mean, and max CL from the 1000 iterations
  c(min(CL), mean(CL), max(CL))  # modified: return vector of numbers
}

HTH,

Vijay.

 

 

On Tue, Jan 30, 2018 at 11:23 AM, Todd McDonnell <todd.mcdonnell at esenvironmental.com> wrote:

Hi all,



I posted a question to Stack Overflow a couple weeks ago regarding Monte
Carlo simulation with mc2d with no replies:

https://stackoverflow.com/questions/48306933/grid-based-monte-carlo-simulati <https://stackoverflow.com/questions/48306933/grid-based-monte-carlo-simulation-using-mc2d> 
on-using-mc2d



Might anyone here have a suggestion for how to address the error?



My approach is largely based on this advice:

http://r-sig-geo.2731867.n2.nabble.com/apply-monte-carlo-simulation-for-each <http://r-sig-geo.2731867.n2.nabble.com/apply-monte-carlo-simulation-for-each-cell-in-a-matrix-originally-raster-td7367094.html#a7367555> 
-cell-in-a-matrix-originally-raster-td7367094.html#a7367555



Thanks in advance for any suggestions,

Todd



--

Todd McDonnell

Research Scientist, Ph.D.

E&S Environmental Chemistry

2161 NW Fillmore Ave., Corvallis, OR




        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo




-- 

Vijay Lulla, Ph.D.



Assistant Professor,

Dept. of Geography, IUPUI

425 University Blvd, CA-207C.

Indianapolis, IN-46202

vlulla at iupui.edu

 <http://vijaylulla.com> 


http://vijaylulla.com


	[[alternative HTML version deleted]]


From noitul7 at gmail.com  Wed Jan 31 20:08:03 2018
From: noitul7 at gmail.com (Sojin Lee)
Date: Wed, 31 Jan 2018 12:08:03 -0700
Subject: [R-sig-Geo] Correcting negative kriging weight in krigeST
Message-ID: <CAJHv-Snh1qfj6+Lj-_OTHqbqVYQ1L6CPjufPiRqz8un9CfdAsw@mail.gmail.com>

Dear R-sig-Geo users,

I'm currently using krigeST for 3-d geostationaly sattlite data
interpolation, and I'm trying to estimate "Interpolation variance" in
Yamamoto et al, 2000.
(https://link.springer.com/article/10.1023/A:1007577916868)

My problem is that the variance is somtimes negative. I'm thinking
that it is due to the negative kriging weights. I found that there is
a solution in Deutsch (1995)
(https://www.sciencedirect.com/science/article/pii/0098300496000052#).

But I'm not sure there is already a option in krigeST fuction. Could
you let me know about the solution?

Thank you for your consideration.


Best regards,

Sojin

	[[alternative HTML version deleted]]


