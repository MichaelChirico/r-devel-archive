From e.pebesma at geo.uu.nl  Mon Jan  1 16:47:24 2007
From: e.pebesma at geo.uu.nl (Edzer J. Pebesma)
Date: Mon, 01 Jan 2007 16:47:24 +0100
Subject: [R-sig-Geo] plot methods in sp
In-Reply-To: <45961C45.4040306@univ-fcomte.fr>
References: <45961C45.4040306@univ-fcomte.fr>
Message-ID: <45992D0C.9000105@geo.uu.nl>

Patrick, I can see this is confusing.

Besides methods(plot), try after library(sp) a

showMethods(plot)

to get an overview of the S4-style plot methods; methods(plot) only 
shows the S3-style plot methods. Then,

class?SpatialPolygons

gives methods available for this class, among which plot, and the html 
listing of plot methods has entries like

plot.SpatialPolygons,missing-method

that points to the same help page (which is rather brief).

getMethod("plot", c("SpatialPolygons", "missing"))

shows you the arguments this method takes, and shows that it actually 
calls plot.SpatialPolygons. This method is not exported from sp, so to 
view it you need to access it as

 sp:::plot.SpatialPolygons
 
the other sp functions it calls can also be accessed by preceding them 
with sp:::

I agree that more elaborate documentation along with examples would be 
useful.

Hope this helps,
--
Edzer

Patrick Giraudoux wrote:
> Dear listers,
>
> I am working since a while with the sp package and still wonder how the 
> plot methods are managed with sp spatial objects. For instance, 
> SpatialPolygonsDataFrame objects have obviously a plot method. However 
> it cannot be found in the list provided by methods(plot) . Furthermore 
> ?plot.SpatialPolygonsDataFrame, nor ?plot.SpatialPolygons, etc.. provide 
> a help, though the lattice function spplot is adequately documented.
>
> On the other hand, plot(myobject, border="grey"), with myobject a 
> SpatialPolygonsDataframe is well interpreted and recalls the syntax of 
> plot.polylist of matools (though myobject is far from being a polylist...).
>
> Can anybody (especially the package's authors...) comment on this? Where 
> a help with the list of the plot function arguments can be found?
>
> Thanks for any hint,
>
> Patrick
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From stratja at auburn.edu  Fri Jan  5 03:49:06 2007
From: stratja at auburn.edu (Jeffrey Stratford)
Date: Thu, 04 Jan 2007 20:49:06 -0600
Subject: [R-sig-Geo] random samples of a grid
Message-ID: <459D6842020000F20001D91A@TMIA1.AUBURN.EDU>

Hi,  is there a way to sample an ESRI grid using random sample points? 
In the past I used ESRI's spatial analyst but I would like to switch all
my analyses to R if possible.  The grid is from the National Land Cover
Dataset  (30m res, 7 landcover classes).  I had roadside points from
which I extracted data such as % grassland, % pine, etc in buffers of
90, 210, and 990 m radii.  I would like to generate 200 random samples
from the same map to compare the roadside points to random samples (and,
hopefully, there are no differences).   Make sense?  Hope so. 

Thanks,

Jeff

****************************************
Jeffrey A. Stratford, Ph.D.
Postdoctoral Associate
331 Funchess Hall
Department of Biological Sciences
Auburn University
Auburn, AL 36849
334-329-9198
FAX 334-844-9234
http://www.auburn.edu/~stratja



From e.pebesma at geo.uu.nl  Fri Jan  5 12:44:04 2007
From: e.pebesma at geo.uu.nl (Edzer J. Pebesma)
Date: Fri, 05 Jan 2007 12:44:04 +0100
Subject: [R-sig-Geo] random samples of a grid
In-Reply-To: <459D6842020000F20001D91A@TMIA1.AUBURN.EDU>
References: <459D6842020000F20001D91A@TMIA1.AUBURN.EDU>
Message-ID: <459E3A04.9030202@geo.uu.nl>

Jeff, you may want to have a look at function spsample in package sp.
--
Edzer

Jeffrey Stratford wrote:
> Hi,  is there a way to sample an ESRI grid using random sample points? 
> In the past I used ESRI's spatial analyst but I would like to switch all
> my analyses to R if possible.  The grid is from the National Land Cover
> Dataset  (30m res, 7 landcover classes).  I had roadside points from
> which I extracted data such as % grassland, % pine, etc in buffers of
> 90, 210, and 990 m radii.  I would like to generate 200 random samples
> from the same map to compare the roadside points to random samples (and,
> hopefully, there are no differences).   Make sense?  Hope so. 
>
> Thanks,
>
> Jeff
>
> ****************************************
> Jeffrey A. Stratford, Ph.D.
> Postdoctoral Associate
> 331 Funchess Hall
> Department of Biological Sciences
> Auburn University
> Auburn, AL 36849
> 334-329-9198
> FAX 334-844-9234
> http://www.auburn.edu/~stratja
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From patrick.giraudoux at univ-fcomte.fr  Fri Jan  5 12:54:43 2007
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Fri, 05 Jan 2007 12:54:43 +0100
Subject: [R-sig-Geo] R-sig-Geo Digest, Vol 41, Issue 2
In-Reply-To: <mailman.19.1167994807.12888.r-sig-geo@stat.math.ethz.ch>
References: <mailman.19.1167994807.12888.r-sig-geo@stat.math.ethz.ch>
Message-ID: <459E3C83.3080202@univ-fcomte.fr>

Jeffrey,

You may want to have a look at the maptools and sp packages. maptools 
has a readShapePoly() function which straightforward read polygon 
shapefiles (equivalent exist for "points" , "lines", "grid", etc.), and 
then you can use spsample() from the package sp.

sp and maptools combined provide extremely powerful tools for reading, 
handling (see eg the function overlay()) and writing shapefiles. The 
package rgdal even permit (among many other things) conversion between 
projections!!!

To be somehow used to S4 objects may be an advantage since each object 
once in R has a fixed structure organised with the concept of "slots" 
whose avantage is to be completely transparent and whose drawback is a 
relative level of complexity at first sight (but don't stay on this 
impression: one can go through quite easy).

Patrick



>
> Date: Thu, 04 Jan 2007 20:49:06 -0600
> From: "Jeffrey Stratford" <stratja at auburn.edu>
> Subject: [R-sig-Geo] random samples of a grid
> To: <r-sig-geo at stat.math.ethz.ch>
> Message-ID: <459D6842020000F20001D91A at TMIA1.AUBURN.EDU>
> Content-Type: text/plain; charset=US-ASCII
>
> Hi,  is there a way to sample an ESRI grid using random sample points? 
> In the past I used ESRI's spatial analyst but I would like to switch all
> my analyses to R if possible.  The grid is from the National Land Cover
> Dataset  (30m res, 7 landcover classes).  I had roadside points from
> which I extracted data such as % grassland, % pine, etc in buffers of
> 90, 210, and 990 m radii.  I would like to generate 200 random samples
> from the same map to compare the roadside points to random samples (and,
> hopefully, there are no differences).   Make sense?  Hope so. 
>
> Thanks,
>
> Jeff
>
> ****************************************
> Jeffrey A. Stratford, Ph.D.
> Postdoctoral Associate
> 331 Funchess Hall
> Department of Biological Sciences
> Auburn University
> Auburn, AL 36849
> 334-329-9198
> FAX 334-844-9234
> http://www.auburn.edu/~stratja
>
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> End of R-sig-Geo Digest, Vol 41, Issue 2
> ****************************************
>
>
>
>



From patrick.giraudoux at univ-fcomte.fr  Fri Jan  5 13:01:08 2007
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Fri, 05 Jan 2007 13:01:08 +0100
Subject: [R-sig-Geo] random samples of a grid
In-Reply-To: <mailman.19.1167994807.12888.r-sig-geo@stat.math.ethz.ch>
References: <mailman.19.1167994807.12888.r-sig-geo@stat.math.ethz.ch>
Message-ID: <459E3E04.2090305@univ-fcomte.fr>

Jeffrey,

You may want to have a look at the maptools and sp packages. maptools
has a readShapePoly() function which straightforward read polygon
shapefiles (equivalent exist for "points" , "lines", "grid", etc.), and
then you can use spsample() from the package sp.

sp and maptools combined provide extremely powerful tools for reading,
handling (see eg the function overlay()) and writing shapefiles. The
package rgdal even permit (among many other things) conversion between
projections!!!

To be somehow used to S4 objects may be an advantage since each object
once in R has a fixed structure organised with the concept of "slots"
whose avantage is to be completely transparent and whose drawback is a
relative level of complexity at first sight (but don't stay on this
impression: one can go through quite easy).

Patrick



>
> Date: Thu, 04 Jan 2007 20:49:06 -0600
> From: "Jeffrey Stratford" <stratja at auburn.edu>
> Subject: [R-sig-Geo] random samples of a grid
> To: <r-sig-geo at stat.math.ethz.ch>
> Message-ID: <459D6842020000F20001D91A at TMIA1.AUBURN.EDU>
> Content-Type: text/plain; charset=US-ASCII
>
> Hi,  is there a way to sample an ESRI grid using random sample points? 
> In the past I used ESRI's spatial analyst but I would like to switch all
> my analyses to R if possible.  The grid is from the National Land Cover
> Dataset  (30m res, 7 landcover classes).  I had roadside points from
> which I extracted data such as % grassland, % pine, etc in buffers of
> 90, 210, and 990 m radii.  I would like to generate 200 random samples
> from the same map to compare the roadside points to random samples (and,
> hopefully, there are no differences).   Make sense?  Hope so. 
>
> Thanks,
>
> Jeff
>
> ****************************************
> Jeffrey A. Stratford, Ph.D.
> Postdoctoral Associate
> 331 Funchess Hall
> Department of Biological Sciences
> Auburn University
> Auburn, AL 36849
> 334-329-9198
> FAX 334-844-9234
> http://www.auburn.edu/~stratja
>
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> End of R-sig-Geo Digest, Vol 41, Issue 2
> ****************************************
>
>
>
>



From patrick.giraudoux at univ-fcomte.fr  Fri Jan  5 16:31:11 2007
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Fri, 05 Jan 2007 16:31:11 +0100
Subject: [R-sig-Geo] random samples of a grid
In-Reply-To: <459E0270020000F20001D99C@TMIA1.AUBURN.EDU>
References: <459E0270020000F20001D99C@TMIA1.AUBURN.EDU>
Message-ID: <459E6F3F.7060000@univ-fcomte.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20070105/083aa628/attachment.pl>

From epistat at gmail.com  Mon Jan  8 09:52:49 2007
From: epistat at gmail.com (zhijie zhang)
Date: Mon, 8 Jan 2007 16:52:49 +0800
Subject: [R-sig-Geo] where goes wrong with my programs on geoRglm package?
Message-ID: <2fc17e30701080052k45042fcbi42bfee25bc15820b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20070108/66e5ab2f/attachment.pl>

From drf5n at maplepark.com  Tue Jan  9 20:01:02 2007
From: drf5n at maplepark.com (David Forrest)
Date: Tue, 9 Jan 2007 13:01:02 -0600 (CST)
Subject: [R-sig-Geo] sp for R V2.1.0
Message-ID: <Pine.LNX.4.64.0701091242570.10769@maplepark.com>

Hi All,

Does the install.packages('sp') on my R V2.1.0 (Debian Stable) report:

    no package 'sp' at the repositories in: download.packages(pkgs, destdir
    = tmpd, available = available

... because sp from CRAN depends on "R (>= 2.4.0), methods" ?

The machine is a production server, and I'd like to not mix the 
Debian releases on it if I can avoid it.  Its using some rusty old 
scripts with library(maps) on it.

Would you advise a separate R 2.4.0 + install for using sp on these 
machines?

Dave
-- 
  Dr. David Forrest
  drf at vims.edu                                    (804)684-7900w
  drf5n at maplepark.com                             (804)642-0662h
                                    http://maplepark.com/~drf5n/



From e.pebesma at geo.uu.nl  Tue Jan  9 20:55:03 2007
From: e.pebesma at geo.uu.nl (Edzer J. Pebesma)
Date: Tue, 09 Jan 2007 20:55:03 +0100
Subject: [R-sig-Geo] sp for R V2.1.0
In-Reply-To: <Pine.LNX.4.64.0701091242570.10769@maplepark.com>
References: <Pine.LNX.4.64.0701091242570.10769@maplepark.com>
Message-ID: <45A3F317.80700@geo.uu.nl>

David Forrest wrote:
> Hi All,
>
> Does the install.packages('sp') on my R V2.1.0 (Debian Stable) report:
>
>     no package 'sp' at the repositories in: download.packages(pkgs, destdir
>     = tmpd, available = available
>
> ... because sp from CRAN depends on "R (>= 2.4.0), methods" ?
>
> The machine is a production server, and I'd like to not mix the 
> Debian releases on it if I can avoid it.  Its using some rusty old 
> scripts with library(maps) on it.
>
> Would you advise a separate R 2.4.0 + install for using sp on these 
> machines?
>   
Dave,

library(maps) does not require sp. If you want to use sp, it doesn't
sound rusty to me. Alternatively, you could try to find sp sources that
were there when R was 2.1.0 (were they of any use back then?), perhaps
in some CRAN area that I couldn't find, or wait until Debian Etch
becomes stable, it has R 2.4.0. The general R attitude seems to be to
keep up with R release, don't expect backports of current packages.

Hth,
--
Edzer



From dray at biomserv.univ-lyon1.fr  Wed Jan 10 08:38:55 2007
From: dray at biomserv.univ-lyon1.fr (Stephane Dray)
Date: Wed, 10 Jan 2007 08:38:55 +0100
Subject: [R-sig-Geo] sp for R V2.1.0
In-Reply-To: <45A3F317.80700@geo.uu.nl>
References: <Pine.LNX.4.64.0701091242570.10769@maplepark.com>
	<45A3F317.80700@geo.uu.nl>
Message-ID: <1168414735.45a4980f913e4@webmail.univ-lyon1.fr>

Dear David,
you can simply add the line :

deb http://cran.R-project.org/bin/linux/debian stable/

to your sources.list. You can then obtain newer R versions for stable Debian.

Sincerely.


Selon "Edzer J. Pebesma" <e.pebesma at geo.uu.nl>:

> David Forrest wrote:
> > Hi All,
> >
> > Does the install.packages('sp') on my R V2.1.0 (Debian Stable) report:
> >
> >     no package 'sp' at the repositories in: download.packages(pkgs, destdir
> >     = tmpd, available = available
> >
> > ... because sp from CRAN depends on "R (>= 2.4.0), methods" ?
> >
> > The machine is a production server, and I'd like to not mix the
> > Debian releases on it if I can avoid it.  Its using some rusty old
> > scripts with library(maps) on it.
> >
> > Would you advise a separate R 2.4.0 + install for using sp on these
> > machines?
> >
> Dave,
>
> library(maps) does not require sp. If you want to use sp, it doesn't
> sound rusty to me. Alternatively, you could try to find sp sources that
> were there when R was 2.1.0 (were they of any use back then?), perhaps
> in some CRAN area that I couldn't find, or wait until Debian Etch
> becomes stable, it has R 2.4.0. The general R attitude seems to be to
> keep up with R release, don't expect backports of current packages.
>
> Hth,
> --
> Edzer
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


-- 
Stephane DRAY



From Roger.Bivand at nhh.no  Wed Jan 10 08:51:07 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 10 Jan 2007 08:51:07 +0100 (CET)
Subject: [R-sig-Geo] sp for R V2.1.0
In-Reply-To: <45A3F317.80700@geo.uu.nl>
Message-ID: <Pine.LNX.4.44.0701100848400.14970-100000@reclus.nhh.no>

On Tue, 9 Jan 2007, Edzer J. Pebesma wrote:

> David Forrest wrote:
> > Hi All,
> >
> > Does the install.packages('sp') on my R V2.1.0 (Debian Stable) report:
> >
> >     no package 'sp' at the repositories in: download.packages(pkgs, destdir
> >     = tmpd, available = available
> >
> > ... because sp from CRAN depends on "R (>= 2.4.0), methods" ?
> >
> > The machine is a production server, and I'd like to not mix the 
> > Debian releases on it if I can avoid it.  Its using some rusty old 
> > scripts with library(maps) on it.
> >
> > Would you advise a separate R 2.4.0 + install for using sp on these 
> > machines?
> >   
> Dave,
> 
> library(maps) does not require sp. If you want to use sp, it doesn't
> sound rusty to me. Alternatively, you could try to find sp sources that
> were there when R was 2.1.0 (were they of any use back then?), perhaps
> in some CRAN area that I couldn't find, or wait until Debian Etch
> becomes stable, it has R 2.4.0. The general R attitude seems to be to
> keep up with R release, don't expect backports of current packages.

There is a binary Windows build of 0.8-4 on CRAN for 2.1.*, so maybe try:

http://cran.r-project.org/src/contrib/Archive/S/sp_0.8-4.tar.gz

or earlier in the same archive location.

Roger

> 
> Hth,
> --
> Edzer
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From drf5n at maplepark.com  Wed Jan 10 17:56:07 2007
From: drf5n at maplepark.com (David Forrest)
Date: Wed, 10 Jan 2007 10:56:07 -0600 (CST)
Subject: [R-sig-Geo] sp for R V2.1.0
In-Reply-To: <1168414735.45a4980f913e4@webmail.univ-lyon1.fr>
References: <Pine.LNX.4.64.0701091242570.10769@maplepark.com>
	<45A3F317.80700@geo.uu.nl>
	<1168414735.45a4980f913e4@webmail.univ-lyon1.fr>
Message-ID: <Pine.LNX.4.64.0701100950280.7193@maplepark.com>

On Wed, 10 Jan 2007, Stephane Dray wrote:

> Dear David,
> you can simply add the line :
>
> deb http://cran.R-project.org/bin/linux/debian stable/
>
> to your sources.list. You can then obtain newer R versions for stable Debian.

Perfect.  That seems exactly like what I want.

Thanks,
Dave


>
> Sincerely.
>
>
> Selon "Edzer J. Pebesma" <e.pebesma at geo.uu.nl>:
>
>> David Forrest wrote:
>>> Hi All,
>>>
>>> Does the install.packages('sp') on my R V2.1.0 (Debian Stable) report:
>>>
>>>     no package 'sp' at the repositories in: download.packages(pkgs, destdir
>>>     = tmpd, available = available
>>>
>>> ... because sp from CRAN depends on "R (>= 2.4.0), methods" ?
>>>
>>> The machine is a production server, and I'd like to not mix the
>>> Debian releases on it if I can avoid it.  Its using some rusty old
>>> scripts with library(maps) on it.
>>>
>>> Would you advise a separate R 2.4.0 + install for using sp on these
>>> machines?
>>>
>> Dave,
>>
>> library(maps) does not require sp. If you want to use sp, it doesn't
>> sound rusty to me. Alternatively, you could try to find sp sources that
>> were there when R was 2.1.0 (were they of any use back then?), perhaps
>> in some CRAN area that I couldn't find, or wait until Debian Etch
>> becomes stable, it has R 2.4.0. The general R attitude seems to be to
>> keep up with R release, don't expect backports of current packages.
>>
>> Hth,
>> --
>> Edzer
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>
>
>

-- 
  Dr. David Forrest
  drf at vims.edu                                    (804)684-7900w
  drf5n at maplepark.com                             (804)642-0662h
                                    http://maplepark.com/~drf5n/



From reeves at nceas.ucsb.edu  Wed Jan 10 20:49:47 2007
From: reeves at nceas.ucsb.edu (Rick Reeves)
Date: Wed, 10 Jan 2007 11:49:47 -0800
Subject: [R-sig-Geo] What is the latest re: reading HDF files with R?
Message-ID: <45A5435B.8000309@nceas.ucsb.edu>


Greetings:

This week I am working with HDF format files containing ocean color 
imagery (CZCS, SeaWIFS) secured from NASA GSFC,
and would like to bring the image maps into the R environment.

One way I have done this is to use the SeaDAS software to extract a 
2-dim binary floating point matrix (from the HDF file)
and write it to disk, then use R pixmap() to read it in to a vector. 
This works, but one loses all of the image attributes
contained in the HDF header. Now, it would be good to read the HDF file 
directly into R, capturing the header attributes.

I have tried the R HDF5 library routine hdf5load(), which seems to read 
the new .hdf5 format
but NOT the older .hdf format (I tried, unsuccessfully)

Question is: Has anyone developed a technique to read HDF files with R?

Thanks in advance, Rick R

-- 
Rick Reeves	
Scientific Programmer / Analyst	
National Center for Ecological Analysis and Synthesis
UC Santa Barbara
reeves at nceas.ucsb.edu
www.nceas.ucsb.edu
805 892 2533

-------------- next part --------------
A non-text attachment was scrubbed...
Name: reeves.vcf
Type: text/x-vcard
Size: 339 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20070110/f6f90ad7/attachment.vcf>

From smitch at connect.carleton.ca  Wed Jan 10 20:51:43 2007
From: smitch at connect.carleton.ca (Scott W Mitchell)
Date: Wed, 10 Jan 2007 14:51:43 -0500
Subject: [R-sig-Geo] What is the latest re: reading HDF files with R?
In-Reply-To: <45A5435B.8000309@nceas.ucsb.edu>
References: <45A5435B.8000309@nceas.ucsb.edu>
Message-ID: <3C568AE0-CD70-4D50-8CFF-A96DD0DA75B7@connect.carleton.ca>

I have never done this, so may be missing something obvious, but can  
you not use rgdal ?  GDAL lists HDF4 as a supported format.

Cheers,
Scott

On 10-Jan-07, at 14:49, Rick Reeves wrote:

>
> Greetings:
>
> This week I am working with HDF format files containing ocean color  
> imagery (CZCS, SeaWIFS) secured from NASA GSFC,
> and would like to bring the image maps into the R environment.
>
> One way I have done this is to use the SeaDAS software to extract a  
> 2-dim binary floating point matrix (from the HDF file)
> and write it to disk, then use R pixmap() to read it in to a  
> vector. This works, but one loses all of the image attributes
> contained in the HDF header. Now, it would be good to read the HDF  
> file directly into R, capturing the header attributes.
>
> I have tried the R HDF5 library routine hdf5load(), which seems to  
> read the new .hdf5 format
> but NOT the older .hdf format (I tried, unsuccessfully)
>
> Question is: Has anyone developed a technique to read HDF files  
> with R?
>
> Thanks in advance, Rick R
>
> -- 
> Rick Reeves	
> Scientific Programmer / Analyst	
> National Center for Ecological Analysis and Synthesis
> UC Santa Barbara
> reeves at nceas.ucsb.edu
> www.nceas.ucsb.edu
> 805 892 2533
>
> <reeves.vcf>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From reeves at nceas.ucsb.edu  Wed Jan 10 20:55:55 2007
From: reeves at nceas.ucsb.edu (Rick Reeves)
Date: Wed, 10 Jan 2007 11:55:55 -0800
Subject: [R-sig-Geo] What is the latest re: reading HDF files with R?
In-Reply-To: <3C568AE0-CD70-4D50-8CFF-A96DD0DA75B7@connect.carleton.ca>
References: <45A5435B.8000309@nceas.ucsb.edu>
	<3C568AE0-CD70-4D50-8CFF-A96DD0DA75B7@connect.carleton.ca>
Message-ID: <45A544CB.4080001@nceas.ucsb.edu>

Good idea, Scott. I had forgotten about rgdal. Doesen't come up in the R 
topic search. RR

Scott W Mitchell wrote:
> I have never done this, so may be missing something obvious, but can 
> you not use rgdal ?  GDAL lists HDF4 as a supported format.
>
> Cheers,
> Scott
>
> On 10-Jan-07, at 14:49, Rick Reeves wrote:
>
>>
>> Greetings:
>>
>> This week I am working with HDF format files containing ocean color 
>> imagery (CZCS, SeaWIFS) secured from NASA GSFC,
>> and would like to bring the image maps into the R environment.
>>
>> One way I have done this is to use the SeaDAS software to extract a 
>> 2-dim binary floating point matrix (from the HDF file)
>> and write it to disk, then use R pixmap() to read it in to a vector. 
>> This works, but one loses all of the image attributes
>> contained in the HDF header. Now, it would be good to read the HDF 
>> file directly into R, capturing the header attributes.
>>
>> I have tried the R HDF5 library routine hdf5load(), which seems to 
>> read the new .hdf5 format
>> but NOT the older .hdf format (I tried, unsuccessfully)
>>
>> Question is: Has anyone developed a technique to read HDF files with R?
>>
>> Thanks in advance, Rick R
>>
>> --Rick Reeves   
>> Scientific Programmer / Analyst   
>> National Center for Ecological Analysis and Synthesis
>> UC Santa Barbara
>> reeves at nceas.ucsb.edu
>> www.nceas.ucsb.edu
>> 805 892 2533
>>
>> <reeves.vcf>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Rick Reeves	
Scientific Programmer / Analyst	
National Center for Ecological Analysis and Synthesis
UC Santa Barbara
reeves at nceas.ucsb.edu
www.nceas.ucsb.edu
805 892 2533

-------------- next part --------------
A non-text attachment was scrubbed...
Name: reeves.vcf
Type: text/x-vcard
Size: 339 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20070110/6d6748b4/attachment.vcf>

From Roger.Bivand at nhh.no  Wed Jan 10 21:02:33 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 10 Jan 2007 21:02:33 +0100 (CET)
Subject: [R-sig-Geo] What is the latest re: reading HDF files with R?
In-Reply-To: <45A544CB.4080001@nceas.ucsb.edu>
Message-ID: <Pine.LNX.4.44.0701102059080.14970-100000@reclus.nhh.no>

On Wed, 10 Jan 2007, Rick Reeves wrote:

> Good idea, Scott. I had forgotten about rgdal. Doesen't come up in the R 
> topic search. RR

You'll need a build of the GDAL library against HDF - which platform are
you using? I believe these formats can be accessed from GDAL, but
confirmation would be welcome. If not Windows, you will be installing a
source rgdal package anyway, if Windows, there are ways round using the
DLLs in FWTools - ask if you need guidance.

Roger

> 
> Scott W Mitchell wrote:
> > I have never done this, so may be missing something obvious, but can 
> > you not use rgdal ?  GDAL lists HDF4 as a supported format.
> >
> > Cheers,
> > Scott
> >
> > On 10-Jan-07, at 14:49, Rick Reeves wrote:
> >
> >>
> >> Greetings:
> >>
> >> This week I am working with HDF format files containing ocean color 
> >> imagery (CZCS, SeaWIFS) secured from NASA GSFC,
> >> and would like to bring the image maps into the R environment.
> >>
> >> One way I have done this is to use the SeaDAS software to extract a 
> >> 2-dim binary floating point matrix (from the HDF file)
> >> and write it to disk, then use R pixmap() to read it in to a vector. 
> >> This works, but one loses all of the image attributes
> >> contained in the HDF header. Now, it would be good to read the HDF 
> >> file directly into R, capturing the header attributes.
> >>
> >> I have tried the R HDF5 library routine hdf5load(), which seems to 
> >> read the new .hdf5 format
> >> but NOT the older .hdf format (I tried, unsuccessfully)
> >>
> >> Question is: Has anyone developed a technique to read HDF files with R?
> >>
> >> Thanks in advance, Rick R
> >>
> >> --Rick Reeves   
> >> Scientific Programmer / Analyst   
> >> National Center for Ecological Analysis and Synthesis
> >> UC Santa Barbara
> >> reeves at nceas.ucsb.edu
> >> www.nceas.ucsb.edu
> >> 805 892 2533
> >>
> >> <reeves.vcf>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at stat.math.ethz.ch
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From tkeitt at gmail.com  Wed Jan 10 22:43:17 2007
From: tkeitt at gmail.com (Tim Keitt)
Date: Wed, 10 Jan 2007 15:43:17 -0600
Subject: [R-sig-Geo] What is the latest re: reading HDF files with R?
In-Reply-To: <45A5435B.8000309@nceas.ucsb.edu>
References: <45A5435B.8000309@nceas.ucsb.edu>
Message-ID: <6262c54c0701101343g4b32b2devb5071122ba59f9d0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20070110/d3051c43/attachment.pl>

From mdsumner at utas.edu.au  Thu Jan 11 00:23:12 2007
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Thu, 11 Jan 2007 10:23:12 +1100
Subject: [R-sig-Geo] What is the latest re: reading HDF files with R?
In-Reply-To: <45A5435B.8000309@nceas.ucsb.edu>
References: <45A5435B.8000309@nceas.ucsb.edu>
Message-ID: <45A57560.6060501@utas.edu.au>

Rick Reeves wrote:
>
> Greetings:
>
> This week I am working with HDF format files containing ocean color 
> imagery (CZCS, SeaWIFS) secured from NASA GSFC,
> and would like to bring the image maps into the R environment.

I have had success using rgdal compiled on Windows against FWTools.  I 
have read data from MCSST, GISST, Quikscat, Pathfinder 4 and 5 
SeaWiFSand Modis files.  I've not tried CZCS. 

Usually you need to supply your own metadata, in order to read subsets 
etc. but it works.

Cheers, Mike.



From andy.jacobson at noaa.gov  Thu Jan 11 02:21:49 2007
From: andy.jacobson at noaa.gov (Andy Jacobson)
Date: Wed, 10 Jan 2007 18:21:49 -0700
Subject: [R-sig-Geo] What is the latest re: reading HDF files with R?
In-Reply-To: <45A5435B.8000309@nceas.ucsb.edu>
References: <45A5435B.8000309@nceas.ucsb.edu>
Message-ID: <E50906E6-A73F-40C6-9105-02A03C55D918@noaa.gov>

Hi Rick,

We've had success building an "hdfdump"--which is just ncdump from  
the standard netcdf package, configured to link with the hdf4 libs,  
then:

hdfdump foo.hdf|ncgen -b -o foo.nc

Then, of course, the excellent ncdf package can read it all in.

Best of luck,

Andy

-- 
Andy Jacobson
andy.jacobson at noaa.gov

NOAA Earth System Research Lab
Global Monitoring Division
325 Broadway
Boulder, Colorado 80305

303/497-4916



From drf5n at maplepark.com  Thu Jan 11 20:29:42 2007
From: drf5n at maplepark.com (David Forrest)
Date: Thu, 11 Jan 2007 13:29:42 -0600 (CST)
Subject: [R-sig-Geo] Marginless plot output for georegistration of output
	graphics
Message-ID: <Pine.LNX.4.64.0701111322050.23078@maplepark.com>

Hi All,

I'd like to make graphic files of plots with controlled pixel->coordinate 
mapping.  Ultimately, I'd like to get the graphs out into Google earth 
KML, but to to that, I need good control of the margins or framing around 
the plot.

Basically, I'm using a spatial polygons dataframe with some 
finite element (30K elements) model output.

png(file='inun.png',width=2000,height=2000,bg = "transparent")
plot(cb,xaxs='i',yaxs='i',
    xlim=bbox(cb)[1,],ylim=bbox(cb)[2,],lty=0,col=cb$inun*4)
dev.off();

but I still have an uneven margin/border around my graphic that is hard to 
correlate to the bbox.

Any hints?

Dave
-- 
  Dr. David Forrest
  drf at vims.edu                                    (804)684-7900w
  drf5n at maplepark.com                             (804)642-0662h
                                    http://maplepark.com/~drf5n/



From Roger.Bivand at nhh.no  Thu Jan 11 21:35:38 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 11 Jan 2007 21:35:38 +0100 (CET)
Subject: [R-sig-Geo] Marginless plot output for georegistration of
 output graphics
In-Reply-To: <Pine.LNX.4.64.0701111322050.23078@maplepark.com>
Message-ID: <Pine.LNX.4.44.0701112109380.17467-100000@reclus.nhh.no>

On Thu, 11 Jan 2007, David Forrest wrote:

> Hi All,
> 
> I'd like to make graphic files of plots with controlled pixel->coordinate 
> mapping.  Ultimately, I'd like to get the graphs out into Google earth 
> KML, but to to that, I need good control of the margins or framing around 
> the plot.
> 
> Basically, I'm using a spatial polygons dataframe with some 
> finite element (30K elements) model output.
> 
> png(file='inun.png',width=2000,height=2000,bg = "transparent")
> plot(cb,xaxs='i',yaxs='i',
>     xlim=bbox(cb)[1,],ylim=bbox(cb)[2,],lty=0,col=cb$inun*4)
> dev.off();
> 
> but I still have an uneven margin/border around my graphic that is hard to 
> correlate to the bbox.

Could you try rasterising your output to a raster in geographical
coordinates, creating the RGB bands by hand, and using functions in the
rgdal package to emit the PNG and WLD files? This isn't your case, but has
worked for the Meuse Bank data set.

The key bits are defining a bounding mask (if your data are not 
rectangular in geographical coordinates), creating a GridTopology in 
geographical coordinates, making a SpatialGrid, adding the mask and 
reducing to SpatialPixels, for you overlaying the SpatialPolygonDataFrame 
on the SpatialPixels to get a data class value for each pixel, put the 
data class values in the SpatialPixelsDataFrame, use vec2RGB with your 
choice of break points and palette to generate an RGB matrix, add red, 
green, and blue columns to the SpatialPixelsDataFrame:

RGB <- vec2RGB(llSPix$pred, breaks=fj7$brks, col=rev(bpy.colors(7)))
llSPix$red <- RGB[,1]
llSPix$green <- RGB[,2]
llSPix$blue <- RGB[,3]
fullgrid(llSPix) <- TRUE
llSPix$alpha <- as.integer(ifelse(is.na(llSPix$pred), 0, 255))

and finally use the alpha channel to drop the out-of-mask pixels after 
going back to a SpatialGridDataFrame. Having to set the three colour 
bands manually is rather clunky, but isn't that what scripts are for? Then 
write out:

dx <- create2GDAL(llSPix[c("red", "green", "blue", "alpha")], 
drivername="GTiff", type="Byte", options="ALPHA=YES")
png_dx <- copyDataset(dx, driver="PNG", options="WORLDFILE=YES")
GDAL.close(dx)
saveDataset(png_dx, filename="log_zinc.png", options="WORLDFILE=YES")
GDAL.close(png_dx)

The round-the-houses is needed because the GDAL PNG driver cannot create 
directly, just by copying, so we write to geotiff with alpha support and 
copy across to PNG with a world file. Open in GE adjusting the opacity to 
suit your taste, probably entering the bounds into the location tab by 
hand. The values from gdalinfo of the *.png file are fine, or the bbox() 
of the SpatialGrid object. If anyone knows how to get GE to use a *.wld 
file and read the location correctly, please say!

We can iterate this if you like, but once you've rasterised, the rest is 
feasible. With the output raster in geographical coordinates, it seems to 
work OK.

Best wishes,

Roger

> 
> Any hints?
> 
> Dave
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From drf5n at maplepark.com  Thu Jan 11 23:55:39 2007
From: drf5n at maplepark.com (David Forrest)
Date: Thu, 11 Jan 2007 16:55:39 -0600 (CST)
Subject: [R-sig-Geo] Marginless plot output for georegistration of
 output graphics
In-Reply-To: <Pine.LNX.4.44.0701112109380.17467-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0701112109380.17467-100000@reclus.nhh.no>
Message-ID: <Pine.LNX.4.64.0701111451190.23078@maplepark.com>

On Thu, 11 Jan 2007, Roger Bivand wrote:

> On Thu, 11 Jan 2007, David Forrest wrote:
>
>> Hi All,
>>
>> I'd like to make graphic files of plots with controlled pixel->coordinate
>> mapping.  Ultimately, I'd like to get the graphs out into Google earth
>> KML, but to to that, I need good control of the margins or framing around
>> the plot.
>>
>> Basically, I'm using a spatial polygons dataframe with some
>> finite element (30K elements) model output.
>>
>> png(file='inun.png',width=2000,height=2000,bg = "transparent")
>> plot(cb,xaxs='i',yaxs='i',
>>     xlim=bbox(cb)[1,],ylim=bbox(cb)[2,],lty=0,col=cb$inun*4)
>> dev.off();
>>
>> but I still have an uneven margin/border around my graphic that is hard to
>> correlate to the bbox.
>
> Could you try rasterising your output to a raster in geographical
> coordinates, creating the RGB bands by hand, and using functions in the
> rgdal package to emit the PNG and WLD files? This isn't your case, but has
> worked for the Meuse Bank data set.

At the core, my finite element model output is defined on either the 
elements (triangular polygons on a unstructured mesh) or nodes (points) 
and I'm looking for a way to create the graphics in different usable ways. 
I have a shapefile of my finite element grid in geographical coordinates, 
but I have a long multivariate timeseries for the element (polygons) that 
doesn't translate well to shapefiles.  I use R (and sometimes Matlab) for 
visualization.

Doing this gets me good graphics for day-to-day visualization:

cb<-readShapePoly('SHAP/grid.shp')
xx<-read.table('output.txt')
cb$inun<-xx[cb$ID,2]  #1# an indicator variable for inundation
plot(cp)              #  shows the 30k Triangle grid 
plot(cb,col=cb$inun*4,lty=0)  # Shows the inundated cells

Since the data is a multivariate timeseries, I've been saving captures of 
the graphics for animations of time and other explorations of the model 
data by mostly varying from the step #1# above, with many rasterizings.

For right now, it looks like I've got an old rdgal without vec2RGB, and 
might have to manually georeference plots from my static domain.

> The key bits are defining a bounding mask (if your data are not
> rectangular in geographical coordinates), creating a GridTopology in
> geographical coordinates, making a SpatialGrid, adding the mask and
> reducing to SpatialPixels, for you overlaying the SpatialPolygonDataFrame
> on the SpatialPixels to get a data class value for each pixel, put the
> data class values in the SpatialPixelsDataFrame, use vec2RGB with your
> choice of break points and palette to generate an RGB matrix, add red,
> green, and blue columns to the SpatialPixelsDataFrame:
>
> RGB <- vec2RGB(llSPix$pred, breaks=fj7$brks, col=rev(bpy.colors(7)))
> llSPix$red <- RGB[,1]
> llSPix$green <- RGB[,2]
> llSPix$blue <- RGB[,3]
> fullgrid(llSPix) <- TRUE
> llSPix$alpha <- as.integer(ifelse(is.na(llSPix$pred), 0, 255))
>
> and finally use the alpha channel to drop the out-of-mask pixels after
> going back to a SpatialGridDataFrame. Having to set the three colour
> bands manually is rather clunky, but isn't that what scripts are for? Then
> write out:
>
> dx <- create2GDAL(llSPix[c("red", "green", "blue", "alpha")],
> drivername="GTiff", type="Byte", options="ALPHA=YES")
> png_dx <- copyDataset(dx, driver="PNG", options="WORLDFILE=YES")
> GDAL.close(dx)
> saveDataset(png_dx, filename="log_zinc.png", options="WORLDFILE=YES")
> GDAL.close(png_dx)
>
> The round-the-houses is needed because the GDAL PNG driver cannot create
> directly, just by copying, so we write to geotiff with alpha support and
> copy across to PNG with a world file. Open in GE adjusting the opacity to
> suit your taste, probably entering the bounds into the location tab by
> hand. The values from gdalinfo of the *.png file are fine, or the bbox()
> of the SpatialGrid object. If anyone knows how to get GE to use a *.wld
> file and read the location correctly, please say!
>
> We can iterate this if you like, but once you've rasterised, the rest is
> feasible. With the output raster in geographical coordinates, it seems to
> work OK.
>
> Best wishes,
>
> Roger
>
>>
>> Any hints?
>>
>> Dave
>>
>
>

-- 
  Dr. David Forrest
  drf at vims.edu                                    (804)684-7900w
  drf5n at maplepark.com                             (804)642-0662h
                                    http://maplepark.com/~drf5n/



From patrick.giraudoux at univ-fcomte.fr  Sun Jan 14 15:28:17 2007
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 14 Jan 2007 15:28:17 +0100
Subject: [R-sig-Geo] reading a gps from R
Message-ID: <45AA3E01.1050205@univ-fcomte.fr>

Dear Listers,

I am trying to write R fonctions to read data from a gps through gpsbabel.

Within linux I have tried this (read garmin gps and write a tab 
delimited text file wp.txt) and it works well:

system("gpsbabel -w -i garmin -o openoffice /dev/ttyUSB0 
/home/giraudoux/wp.txt")

I have two questions:

1/ I wonder whether it would be technically possible to open the 
connexion directly to a R object (eg data.frame) rather than to write a 
text file (here wp.txt) ?

2/ I wonder how to open a USB device/port within a windows XP 
environment (linux equivalent of /dev/ttyUSB0).

Thanks in advance for any hint...

Patrick



From patrick.giraudoux at univ-fcomte.fr  Sun Jan 14 18:05:09 2007
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 14 Jan 2007 18:05:09 +0100
Subject: [R-sig-Geo] reading a gps from R
In-Reply-To: <45AA3E01.1050205@univ-fcomte.fr>
References: <45AA3E01.1050205@univ-fcomte.fr>
Message-ID: <45AA62C5.9030803@univ-fcomte.fr>

Sorry to answer to myself. I have found a solution for the 2nd question: 
from R within windows the gps can be read with:

shell("gpsbabel -w -i garmin -f com4: -o openoffice -F \"wpt.txt\"")

The 1th question about reading the gps data directly to an R object 
unstead of a text file is still unanswered...

Cheers,

Patrick



Patrick Giraudoux a ?crit :
> Dear Listers,
>
> I am trying to write R fonctions to read data from a gps through 
> gpsbabel.
>
> Within linux I have tried this (read garmin gps and write a tab 
> delimited text file wp.txt) and it works well:
>
> system("gpsbabel -w -i garmin -o openoffice /dev/ttyUSB0 
> /home/giraudoux/wp.txt")
>
> I have two questions:
>
> 1/ I wonder whether it would be technically possible to open the 
> connexion directly to a R object (eg data.frame) rather than to write 
> a text file (here wp.txt) ?
>
> 2/ I wonder how to open a USB device/port within a windows XP 
> environment (linux equivalent of /dev/ttyUSB0).
>
> Thanks in advance for any hint...
>
> Patrick
>
>
>



From Roger.Bivand at nhh.no  Sun Jan 14 18:27:49 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 14 Jan 2007 18:27:49 +0100 (CET)
Subject: [R-sig-Geo] reading a gps from R
In-Reply-To: <45AA62C5.9030803@univ-fcomte.fr>
Message-ID: <Pine.LNX.4.44.0701141812110.26000-100000@reclus.nhh.no>

Patrick,

On Sun, 14 Jan 2007, Patrick Giraudoux wrote:

> Sorry to answer to myself. I have found a solution for the 2nd question: 
> from R within windows the gps can be read with:
> 
> shell("gpsbabel -w -i garmin -f com4: -o openoffice -F \"wpt.txt\"")
> 

Good.

> The 1th question about reading the gps data directly to an R object 
> unstead of a text file is still unanswered...
> 

Since the files are not too large, would pasting an R temporary file into 
the system call, and then reading from it be a fix? I've tried "-" as the 
file name under Linux, and it does return the data to stdout (terminal 
screen), but I haven't got any further because on RedHat EL 4 I can't see 
how to use gpsbabel without being administrator (I've tried both the FC 
tips on the gpsbabel website with no effect). system(intern=TRUE) should 
grab that output:

wps <- system("gpsbabel -w -i garmin -f usb: -o tabsep -F -", intern=TRUE)
wps_df <- read.table(textConnection(wps), fill=TRUE)

but there is a lot of unneeded information there. Could the xcsv format be 
used with a suitable style?

Best wishes,

Roger


> Cheers,
> 
> Patrick
> 
> 
> 
> Patrick Giraudoux a ?crit :
> > Dear Listers,
> >
> > I am trying to write R fonctions to read data from a gps through 
> > gpsbabel.
> >
> > Within linux I have tried this (read garmin gps and write a tab 
> > delimited text file wp.txt) and it works well:
> >
> > system("gpsbabel -w -i garmin -o openoffice /dev/ttyUSB0 
> > /home/giraudoux/wp.txt")
> >
> > I have two questions:
> >
> > 1/ I wonder whether it would be technically possible to open the 
> > connexion directly to a R object (eg data.frame) rather than to write 
> > a text file (here wp.txt) ?
> >
> > 2/ I wonder how to open a USB device/port within a windows XP 
> > environment (linux equivalent of /dev/ttyUSB0).
> >
> > Thanks in advance for any hint...
> >
> > Patrick
> >
> >
> >
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From patrick.giraudoux at univ-fcomte.fr  Sun Jan 14 18:40:59 2007
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 14 Jan 2007 18:40:59 +0100
Subject: [R-sig-Geo] reading a gps from R
In-Reply-To: <Pine.LNX.4.44.0701141812110.26000-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0701141812110.26000-100000@reclus.nhh.no>
Message-ID: <45AA6B2B.5090903@univ-fcomte.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20070114/a823f06b/attachment.pl>

From Roger.Bivand at nhh.no  Sun Jan 14 21:42:28 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 14 Jan 2007 21:42:28 +0100 (CET)
Subject: [R-sig-Geo] reading a gps from R
In-Reply-To: <45AA6B2B.5090903@univ-fcomte.fr>
Message-ID: <Pine.LNX.4.44.0701142131200.26032-100000@reclus.nhh.no>

On Sun, 14 Jan 2007, Patrick Giraudoux wrote:

> Roger Bivand a ?crit :
> > Patrick,
> >
> > On Sun, 14 Jan 2007, Patrick Giraudoux wrote:
> >
> >   
> >> Sorry to answer to myself. I have found a solution for the 2nd question: 
> >> from R within windows the gps can be read with:
> >>
> >> shell("gpsbabel -w -i garmin -f com4: -o openoffice -F \"wpt.txt\"")
> >>
> >>     
> >
> > Good.
> >
> >   
> >> The 1th question about reading the gps data directly to an R object 
> >> unstead of a text file is still unanswered...
> >>
> >>     
> >
> > Since the files are not too large, would pasting an R temporary file into 
> > the system call, and then reading from it be a fix?
> Yes!!! Excellent idea...
> >  I've tried "-" as the 
> > file name under Linux, and it does return the data to stdout (terminal 
> > screen), but I haven't got any further because on RedHat EL 4 I can't see 
> > how to use gpsbabel without being administrator (I've tried both the FC 
> > tips on the gpsbabel website with no effect). system(intern=TRUE) should 
> > grab that output:
> >
> > wps <- system("gpsbabel -w -i garmin -f usb: -o tabsep -F -", intern=TRUE)
> > wps_df <- read.table(textConnection(wps), fill=TRUE)

If gpsbabel is on your Windows path, this should work on XP too, certainly 
the command itself works in a console (for me, with a Garmin USB cable).

> >
> > but there is a lot of unneeded information there. Could the xcsv format be 
> > used with a suitable style?
> >   
> I will explore that next week-end. Not to be an administrator seems not 
> to be a problem here with Ubuntu.
> 
> Anyway using a temporary file may make it for sure if one cannot go 
> through with writing straight into R
> 

Using intern=TRUE passes the whole text output to an R character vector, 
one element per waypoint. Then textConnection() reads the character vector 
as if it was a file - that should avoid the temporary file. It would be 
nice to choose the specific columns needed.

Roger

> Thanks a lot for the hint anyway..
> 
> Best wishes,
> 
> Patrick
> 
> > Best wishes,
> >
> > Roger
> >
> >
> >   
> >> Cheers,
> >>
> >> Patrick
> >>
> >>
> >>
> >> Patrick Giraudoux a ?crit :
> >>     
> >>> Dear Listers,
> >>>
> >>> I am trying to write R fonctions to read data from a gps through 
> >>> gpsbabel.
> >>>
> >>> Within linux I have tried this (read garmin gps and write a tab 
> >>> delimited text file wp.txt) and it works well:
> >>>
> >>> system("gpsbabel -w -i garmin -o openoffice /dev/ttyUSB0 
> >>> /home/giraudoux/wp.txt")
> >>>
> >>> I have two questions:
> >>>
> >>> 1/ I wonder whether it would be technically possible to open the 
> >>> connexion directly to a R object (eg data.frame) rather than to write 
> >>> a text file (here wp.txt) ?
> >>>
> >>> 2/ I wonder how to open a USB device/port within a windows XP 
> >>> environment (linux equivalent of /dev/ttyUSB0).
> >>>
> >>> Thanks in advance for any hint...
> >>>
> >>> Patrick
> >>>
> >>>
> >>>
> >>>       
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at stat.math.ethz.ch
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >>     
> >
> >   
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From patrick.giraudoux at univ-fcomte.fr  Sun Jan 14 23:41:42 2007
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 14 Jan 2007 23:41:42 +0100
Subject: [R-sig-Geo] reading a gps from R
In-Reply-To: <Pine.LNX.4.44.0701142131200.26032-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0701142131200.26032-100000@reclus.nhh.no>
Message-ID: <45AAB1A6.2090408@univ-fcomte.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20070114/229d8f44/attachment.pl>

From mihastaut at yahoo.co.uk  Mon Jan 15 16:35:27 2007
From: mihastaut at yahoo.co.uk (Miha Staut)
Date: Mon, 15 Jan 2007 15:35:27 +0000 (GMT)
Subject: [R-sig-Geo] Count of points inside multiple polygons
Message-ID: <463602.47997.qm@web25415.mail.ukl.yahoo.com>

Dear all,

I was wandering if there is a way to count the number of points inside multiple
polygons within R. 

Example:
I have an arbitrary number of criminal events with x and y coordinates spread
over a town. I would like to know the number of events for each constitutive
spatial unit of this town. Let us suppose those spatial units are about 100. 

The required approaches what is implented in the splancs function pip. Just for
all the polygons in the same operation.

Thanks for your suggestions,
Miha Staut



From b.rowlingson at lancaster.ac.uk  Mon Jan 15 19:06:16 2007
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 15 Jan 2007 18:06:16 +0000
Subject: [R-sig-Geo] Count of points inside multiple polygons
In-Reply-To: <463602.47997.qm@web25415.mail.ukl.yahoo.com>
References: <463602.47997.qm@web25415.mail.ukl.yahoo.com>
Message-ID: <45ABC298.1080205@lancaster.ac.uk>

Miha Staut wrote:
> Dear all,
> 
> I was wandering if there is a way to count the number of points inside multiple
> polygons within R. 

> The required approaches what is implented in the splancs function pip. Just for
> all the polygons in the same operation.
This is what programming languages are for!

  Write a loop over your polygons, then call pip for each polygon and 
all your points. Then pip tells you which points are in that polygon. 
Repeat your loop, tracking which points you found in which polygon in a 
matrix or vector. If you want to speed things up at the end and you know 
that your polygons dont overlap, you can exclude the points found to be 
in polygon N from tests with polygon >N.

  Quite what this loop looks like depends on how your polygons are 
stored. If they are just a list of 2-column matrices, then you are 
looping over a list. If they are areas in a shapefile, then you need to 
extract the ring from the shapefile and do pip with that.

  There are probably better ways to do this with sp or spatstat anyway, 
that work with the whole set of polygons at once.

Barry



From Roger.Bivand at nhh.no  Mon Jan 15 19:25:58 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 15 Jan 2007 19:25:58 +0100 (CET)
Subject: [R-sig-Geo] Count of points inside multiple polygons
In-Reply-To: <45ABC298.1080205@lancaster.ac.uk>
Message-ID: <Pine.LNX.4.44.0701151921250.27224-100000@reclus.nhh.no>

On Mon, 15 Jan 2007, Barry Rowlingson wrote:

> Miha Staut wrote:
> > Dear all,
> > 
> > I was wandering if there is a way to count the number of points inside
> > multiple polygons within R.
> 
> > The required approaches what is implented in the splancs function pip.
> > Just for all the polygons in the same operation.
> This is what programming languages are for!
> 
>   Write a loop over your polygons, then call pip for each polygon and 
> all your points. Then pip tells you which points are in that polygon. 
> Repeat your loop, tracking which points you found in which polygon in a 
> matrix or vector. If you want to speed things up at the end and you know 
> that your polygons dont overlap, you can exclude the points found to be 
> in polygon N from tests with polygon >N.
> 
>   Quite what this loop looks like depends on how your polygons are 
> stored. If they are just a list of 2-column matrices, then you are 
> looping over a list. If they are areas in a shapefile, then you need to 
> extract the ring from the shapefile and do pip with that.
> 
>   There are probably better ways to do this with sp or spatstat anyway, 
> that work with the whole set of polygons at once.

"Better" is still loops, but you get to avoid doing them yourself - look 
at the overlay methods in the sp package, overlaying SpatialPolygons on 
SpatialPoints should return a vector with a Polygons number for each 
point.

?"overlay-methods" and ?overlay should help.

Roger

> 
> Barry
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From drf5n at maplepark.com  Tue Jan 16 19:06:33 2007
From: drf5n at maplepark.com (David Forrest)
Date: Tue, 16 Jan 2007 12:06:33 -0600 (CST)
Subject: [R-sig-Geo] Marginless plot output for georegistration of
 output graphics
In-Reply-To: <Pine.LNX.4.44.0701112109380.17467-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0701112109380.17467-100000@reclus.nhh.no>
Message-ID: <Pine.LNX.4.64.0701151027540.9323@maplepark.com>

On Thu, 11 Jan 2007, Roger Bivand wrote:

> On Thu, 11 Jan 2007, David Forrest wrote:
>
>> Hi All,
...

I think I can make marginless plots in base, lattice, and sp graphics now, 
but I'm still missing something about the data ranges for spplot.

#################################
# Marginless plots in base graphics:
library(stats)
par.save<-par(no.readonly = TRUE);
par(mar=c(0,0,0,0))
plot(quakes$long,quakes$lat,xaxs='i',yaxs='i',xlab=FALSE,axes=FALSE)
par(par.save)

########### in lattice/trellis/grid
library(lattice)
theme.novpadding <-
# From Deepayan Sarkar's posting of 2006-10-12:
    list(layout.heights =
         list(top.padding = 0,
             main.key.padding = 0,
             key.axis.padding = 0,
             axis.xlab.padding = 0,
             xlab.key.padding = 0,
             key.sub.padding = 0,
             bottom.padding = 0),
         layout.widths =
         list(left.padding = 0,
             key.ylab.padding = 0,
             ylab.axis.padding = 0,
             axis.key.padding = 0,
             right.padding = 0))
print( # lattice/grid With device extents == data extents
xyplot(lat ~ long , data=quakes, pch=".",
        ,xlab=NULL,ylab=NULL
        ,scales=list(axs='i',draw=FALSE)
        ,par.settings=theme.novpadding))

#########  In spatial (with internal & device margin)
# An example of a marginless plot in library(sp)
library(sp)
qk<-SpatialPointsDataFrame(quakes[,c(2:1)],quakes)
proj4string(qk)<-CRS("+proj=longlat")
spplot(qk,'mag',key.space=list(x=0.25,y=.2,corner=c(1,1)),
        par.settings=theme.novpadding,scales=list(axs='i',draw=FALSE))

#####################

The device/aspect ratio margin is controllable and manageable with a 
mapasp(gk) based device call.

I'd still like to eliminate the remaining internal margin from around the 
plot.  I saw it once in my experimenting, but I am not sure if it was some 
interaction with par() or something and have not able to duplicate 
it.

Dave
-- 
  Dr. David Forrest
  drf at vims.edu                                    (804)684-7900w
  drf5n at maplepark.com                             (804)642-0662h
                                    http://maplepark.com/~drf5n/



From hywelm.jones at talk21.com  Wed Jan 17 10:58:10 2007
From: hywelm.jones at talk21.com (Hywel Jones)
Date: Wed, 17 Jan 2007 09:58:10 +0000 (GMT)
Subject: [R-sig-Geo] Variogram in spatial package
Message-ID: <20070117095810.37563.qmail@web86204.mail.ird.yahoo.com>

The help page for variogram in the spatial package
leaves my slightly uncertain about a few things. I'd
be grateful for confirmation of my understanding.

If I fit a trend surface using surf.ls, and then set
the krig parameter to use that object in the variogram
function, I'm assuming that the variogram produced is
calculated for the residuals contained in the trend
surface object. Is that right?

I'm afraid I don't have the references to check the
following either. Using notation of Cressie, am I
right in thinking that the y co-ordinate of the
variogram corresponds to gamma (or 2x gamma)? And x:
is that h? 

And then, how does h correspond to my original data?
i.e. do I interpret it as distance calculated with the
original x and y submitted to surf.ls, or as distance
calculated with the rescaled x and y used within
surf.ls (I understand that the internals rescale x and
y to -1:1).

I'd actually like to check for isotropy before using
this variogram function. Any suggestions as to
functions I might use?

Thanks in advance.

Hywel


		
___________________________________________________________ 
What kind of emailer are you? Find out today - get a free analysis of your email personality. Take the quiz at the Yahoo! Mail Championship. 
http://uk.rd.yahoo.com/evt=44106/*http://mail.yahoo.net/uk



From Roger.Bivand at nhh.no  Wed Jan 17 14:32:54 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 17 Jan 2007 14:32:54 +0100 (CET)
Subject: [R-sig-Geo] Marginless plot output for georegistration of
 output graphics
In-Reply-To: <Pine.LNX.4.64.0701151027540.9323@maplepark.com>
Message-ID: <Pine.LNX.4.44.0701171320280.31005-100000@reclus.nhh.no>

On Tue, 16 Jan 2007, David Forrest wrote:

> On Thu, 11 Jan 2007, Roger Bivand wrote:
> 
> > On Thu, 11 Jan 2007, David Forrest wrote:
> >
> >> Hi All,
> ...
> 
> I think I can make marginless plots in base, lattice, and sp graphics now, 
> but I'm still missing something about the data ranges for spplot.
> 
> #################################
> # Marginless plots in base graphics:
> library(stats)
> par.save<-par(no.readonly = TRUE);
> par(mar=c(0,0,0,0))
> plot(quakes$long,quakes$lat,xaxs='i',yaxs='i',xlab=FALSE,axes=FALSE)
> par(par.save)
> 
> ########### in lattice/trellis/grid
> library(lattice)
> theme.novpadding <-
> # From Deepayan Sarkar's posting of 2006-10-12:
>     list(layout.heights =
>          list(top.padding = 0,
>              main.key.padding = 0,
>              key.axis.padding = 0,
>              axis.xlab.padding = 0,
>              xlab.key.padding = 0,
>              key.sub.padding = 0,
>              bottom.padding = 0),
>          layout.widths =
>          list(left.padding = 0,
>              key.ylab.padding = 0,
>              ylab.axis.padding = 0,
>              axis.key.padding = 0,
>              right.padding = 0))
> print( # lattice/grid With device extents == data extents
> xyplot(lat ~ long , data=quakes, pch=".",
>         ,xlab=NULL,ylab=NULL
>         ,scales=list(axs='i',draw=FALSE)
>         ,par.settings=theme.novpadding))
> 
> #########  In spatial (with internal & device margin)
> # An example of a marginless plot in library(sp)
> library(sp)
> qk<-SpatialPointsDataFrame(quakes[,c(2:1)],quakes)
> proj4string(qk)<-CRS("+proj=longlat")
> spplot(qk,'mag',key.space=list(x=0.25,y=.2,corner=c(1,1)),
>         par.settings=theme.novpadding,scales=list(axs='i',draw=FALSE))
> 
> #####################
> 
> The device/aspect ratio margin is controllable and manageable with a 
> mapasp(gk) based device call.
> 
> I'd still like to eliminate the remaining internal margin from around the 
> plot.  I saw it once in my experimenting, but I am not sure if it was some 
> interaction with par() or something and have not able to duplicate 
> it.

What you are trying to do is effectively to implement a graphics device 
that only takes the printed area. For many polygons, I've tried overlaying 
on a SpatialGrid, but this is too time-consuming. I also looked at 
plotting to postscript, resetting the bounding box to be as tight as 
possible (script bbox.pl originally by Dov Grobgeld using GhostScript), 
and converting (Image Magic or other) to PNG, but am not there yet, 
although I think it is viable. The eps output is in its own coordinates, 
though, so the bounding box for GE will need to be extracted first. 

Another possibility is the xfig format and fig2dev, and looks promising:

library(maptools)
xx <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1], 
  IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
tf <- tempfile()
xfig(tf)
plot(xx)
dev.off()
tf2 <- tempfile()
system(paste("fig2dev -L png", tf, tf2))
system(paste("display", tf2))

does seem to work - using the width and height arguments in xfig() can add 
pixels, and extra arguments to fig2dev can change things too.

If anyone has lots of time to spare, a SpatialGridDataFrame device with 
red, green, blue and alpha channels would be nice (or a GDAL MEM device, 
or whatever).

Roger

> 
> Dave
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Wed Jan 17 15:08:53 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 17 Jan 2007 15:08:53 +0100 (CET)
Subject: [R-sig-Geo] Marginless plot output for georegistration of
 output graphics
In-Reply-To: <Pine.LNX.4.44.0701171320280.31005-100000@reclus.nhh.no>
Message-ID: <Pine.LNX.4.44.0701171440370.31005-100000@reclus.nhh.no>

On Wed, 17 Jan 2007, Roger Bivand wrote:

> On Tue, 16 Jan 2007, David Forrest wrote:
> 
> > On Thu, 11 Jan 2007, Roger Bivand wrote:
> > 
> > > On Thu, 11 Jan 2007, David Forrest wrote:
> > >
> > >> Hi All,
> > ...
> > 
> > I think I can make marginless plots in base, lattice, and sp graphics now, 
> > but I'm still missing something about the data ranges for spplot.
> > 
> > #################################
> > # Marginless plots in base graphics:
> > library(stats)
> > par.save<-par(no.readonly = TRUE);
> > par(mar=c(0,0,0,0))
> > plot(quakes$long,quakes$lat,xaxs='i',yaxs='i',xlab=FALSE,axes=FALSE)
> > par(par.save)
> > 
> > ########### in lattice/trellis/grid
> > library(lattice)
> > theme.novpadding <-
> > # From Deepayan Sarkar's posting of 2006-10-12:
> >     list(layout.heights =
> >          list(top.padding = 0,
> >              main.key.padding = 0,
> >              key.axis.padding = 0,
> >              axis.xlab.padding = 0,
> >              xlab.key.padding = 0,
> >              key.sub.padding = 0,
> >              bottom.padding = 0),
> >          layout.widths =
> >          list(left.padding = 0,
> >              key.ylab.padding = 0,
> >              ylab.axis.padding = 0,
> >              axis.key.padding = 0,
> >              right.padding = 0))
> > print( # lattice/grid With device extents == data extents
> > xyplot(lat ~ long , data=quakes, pch=".",
> >         ,xlab=NULL,ylab=NULL
> >         ,scales=list(axs='i',draw=FALSE)
> >         ,par.settings=theme.novpadding))
> > 
> > #########  In spatial (with internal & device margin)
> > # An example of a marginless plot in library(sp)
> > library(sp)
> > qk<-SpatialPointsDataFrame(quakes[,c(2:1)],quakes)
> > proj4string(qk)<-CRS("+proj=longlat")
> > spplot(qk,'mag',key.space=list(x=0.25,y=.2,corner=c(1,1)),
> >         par.settings=theme.novpadding,scales=list(axs='i',draw=FALSE))
> > 
> > #####################
> > 
> > The device/aspect ratio margin is controllable and manageable with a 
> > mapasp(gk) based device call.
> > 
> > I'd still like to eliminate the remaining internal margin from around the 
> > plot.  I saw it once in my experimenting, but I am not sure if it was some 
> > interaction with par() or something and have not able to duplicate 
> > it.
> 
> What you are trying to do is effectively to implement a graphics device 
> that only takes the printed area. For many polygons, I've tried overlaying 
> on a SpatialGrid, but this is too time-consuming. I also looked at 
> plotting to postscript, resetting the bounding box to be as tight as 
> possible (script bbox.pl originally by Dov Grobgeld using GhostScript), 
> and converting (Image Magic or other) to PNG, but am not there yet, 
> although I think it is viable. The eps output is in its own coordinates, 
> though, so the bounding box for GE will need to be extracted first. 
> 
> Another possibility is the xfig format and fig2dev, and looks promising:
> 
> library(maptools)
> xx <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1], 
>   IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
> tf <- tempfile()
> xfig(tf)
> plot(xx)
> dev.off()
> tf2 <- tempfile()
> system(paste("fig2dev -L png", tf, tf2))
> system(paste("display", tf2))
> 
> does seem to work - using the width and height arguments in xfig() can add 
> pixels, and extra arguments to fig2dev can change things too.

Although the output PNG looks nice with "+proj=longlat"-induced vertical 
stretch, I think the CRS should be reset to as.character(NA) to keep the 
original geographical coordinates aspect ratio (maybe this doesn't 
matter, the PNGs insert alike in GE). 

Getting the background transparent is an open issue, bg="transparent" in 
xfig() doesn't help, but there is a -g color argument to fig2dev, which 
needs investigation. 

Roger

> 
> If anyone has lots of time to spare, a SpatialGridDataFrame device with 
> red, green, blue and alpha channels would be nice (or a GDAL MEM device, 
> or whatever).
> 
> Roger
> 
> > 
> > Dave
> > 
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From drf5n at maplepark.com  Wed Jan 17 17:02:32 2007
From: drf5n at maplepark.com (David Forrest)
Date: Wed, 17 Jan 2007 10:02:32 -0600 (CST)
Subject: [R-sig-Geo] Marginless plot output for georegistration of
 output graphics
In-Reply-To: <Pine.LNX.4.44.0701171320280.31005-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0701171320280.31005-100000@reclus.nhh.no>
Message-ID: <Pine.LNX.4.64.0701170901230.3874@maplepark.com>

On Wed, 17 Jan 2007, Roger Bivand wrote:

> On Tue, 16 Jan 2007, David Forrest wrote:
>
>> On Thu, 11 Jan 2007, Roger Bivand wrote:
>>
>>> On Thu, 11 Jan 2007, David Forrest wrote:
>>>
>>>> Hi All,
>> ...
>>
>> I think I can make marginless plots in base, lattice, and sp graphics now,
>> but I'm still missing something about the data ranges for spplot.
>>
>> #################################
>> # Marginless plots in base graphics:
>> library(stats)
>> par.save<-par(no.readonly = TRUE);
>> par(mar=c(0,0,0,0))
>> plot(quakes$long,quakes$lat,xaxs='i',yaxs='i',xlab=FALSE,axes=FALSE)
>> par(par.save)
>>
>> ########### in lattice/trellis/grid
>> library(lattice)
>> theme.novpadding <-
>> # From Deepayan Sarkar's posting of 2006-10-12:
>>     list(layout.heights =
>>          list(top.padding = 0,
>>              main.key.padding = 0,
>>              key.axis.padding = 0,
>>              axis.xlab.padding = 0,
>>              xlab.key.padding = 0,
>>              key.sub.padding = 0,
>>              bottom.padding = 0),
>>          layout.widths =
>>          list(left.padding = 0,
>>              key.ylab.padding = 0,
>>              ylab.axis.padding = 0,
>>              axis.key.padding = 0,
>>              right.padding = 0))
>> print( # lattice/grid With device extents == data extents
>> xyplot(lat ~ long , data=quakes, pch=".",
>>         ,xlab=NULL,ylab=NULL
>>         ,scales=list(axs='i',draw=FALSE)
>>         ,par.settings=theme.novpadding))
>>
>> #########  In spatial (with internal & device margin)
>> # An example of a marginless plot in library(sp)
>> library(sp)
>> qk<-SpatialPointsDataFrame(quakes[,c(2:1)],quakes)
>> proj4string(qk)<-CRS("+proj=longlat")
>> spplot(qk,'mag',key.space=list(x=0.25,y=.2,corner=c(1,1)),
>>         par.settings=theme.novpadding,scales=list(axs='i',draw=FALSE))
>>
>> #####################
>>
>> The device/aspect ratio margin is controllable and manageable with a
>> mapasp(gk) based device call.
>>
>> I'd still like to eliminate the remaining internal margin from around the
>> plot.  I saw it once in my experimenting, but I am not sure if it was some
>> interaction with par() or something and have not able to duplicate
>> it.


I've solved this somewhat by explicitly setting the xlim and ylim.  With 
Using the theme.novpadding from above, this seems to work:
library(maptools)
library(sp)
library(stats)

qk<-SpatialPointsDataFrame(quakes[,c(2:1)],quakes)
proj4string(qk)<-CRS("+proj=longlat")
qk.p<-spplot(qk,'mag',key.space=list(x=0.25,y=.2,corner=c(1,1)),
        par.settings=theme.novpadding,
        scales=list(axs='i',draw=FALSE),
        xlim=bbox(qk)[1,],ylim=bbox(qk)[2,])

print(qk)

# With a controlled-size png file:
myheight=1024;mywidth=myheight/mapasp(qk)
png(file='mymap.png',width=mywidth,height=myheight)
print(qk.p)
dev.off()
bbox(qk)

However, now I'd like to be able to eliminate the key entirely.  It seems 
that the keys are handled differently between points, grid, lines, and 
polygons, and I'm not sure there is a general control at the spplot() 
level.

> What you are trying to do is effectively to implement a graphics device
> that only takes the printed area. For many polygons, I've tried overlaying

Exactly.

> on a SpatialGrid, but this is too time-consuming. I also looked at
> plotting to postscript, resetting the bounding box to be as tight as
> possible (script bbox.pl originally by Dov Grobgeld using GhostScript),
> and converting (Image Magic or other) to PNG, but am not there yet,
> although I think it is viable. The eps output is in its own coordinates,
> though, so the bounding box for GE will need to be extracted first.

Yes.  I do think that may be viable as well, but it does depend on making 
sure the plot does not draw any extraneous info like colorbars or keys. 
I'm not terribly skilled with OO programming and digging out just what 
happens behind a spplot(SpatialObject,...) or plot(SpatialObject) seems 
confusing.  (Besides 'plot' 'spplot', or '?plot' or '?ssplot' how do you 
see what happens next?)

Alternately, it might be enough to somehow report the extents of the 
graphics device in data coordinates.

> Another possibility is the xfig format and fig2dev, and looks promising:
>
> library(maptools)
> xx <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1],
>  IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
> tf <- tempfile()
> xfig(tf)
> plot(xx)
> dev.off()
> tf2 <- tempfile()
> system(paste("fig2dev -L png", tf, tf2))
> system(paste("display", tf2))
>
> does seem to work - using the width and height arguments in xfig() can add
> pixels, and extra arguments to fig2dev can change things too.

Hmm.  I'll look at that.

> If anyone has lots of time to spare, a SpatialGridDataFrame device with
> red, green, blue and alpha channels would be nice (or a GDAL MEM device,
> or whatever).
>
> Roger
>
>>
>> Dave
>>
>
>

-- 
  Dr. David Forrest
  drf at vims.edu                                    (804)684-7900w
  drf5n at maplepark.com                             (804)642-0662h
                                    http://maplepark.com/~drf5n/



From drf5n at maplepark.com  Wed Jan 17 17:40:16 2007
From: drf5n at maplepark.com (David Forrest)
Date: Wed, 17 Jan 2007 10:40:16 -0600 (CST)
Subject: [R-sig-Geo] Marginless plot output for georegistration of
 output graphics
In-Reply-To: <Pine.LNX.4.44.0701171440370.31005-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0701171440370.31005-100000@reclus.nhh.no>
Message-ID: <Pine.LNX.4.64.0701171002560.3874@maplepark.com>

On Wed, 17 Jan 2007, Roger Bivand wrote:
>
> Although the output PNG looks nice with "+proj=longlat"-induced vertical
> stretch, I think the CRS should be reset to as.character(NA) to keep the
> original geographical coordinates aspect ratio (maybe this doesn't
> matter, the PNGs insert alike in GE).

For the quakes data example, I assigned a CRS to make use of mapasp() to 
set the png() device sizes, otherwise it thinks the lat/long is "iso"  GE 
does do a vertical stretch.  Here's an example on the NC data.

library(maptools)
xx <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1],
IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
xx.p<-spplot(xx,'AREA',
        par.settings=theme.novpadding, # lattice theme from prior
        scales=list(axs='i',draw=FALSE),
        xlim=bbox(xx)[1,],ylim=bbox(xx)[2,])

tf2<-tempfile()

mywidth<-myheight<-600
if(mapasp(xx)>1)  mywidth<-myheight  /mapasp(xx)
if(mapasp(xx)<1)  myheight <-mywidth *mapasp(xx)
myheight<-myheight*(1-.045)  # key size hack

png(file=tf2,width=mywidth,height=myheight,bg='transparent')
print(xx.p)
dev.off()
system(paste("display", tf2))

I feel really close with this, except for the key.

> Getting the background transparent is an open issue, bg="transparent" in
> xfig() doesn't help, but there is a -g color argument to fig2dev, which
> needs investigation.
>
> Roger
>
>>
>> If anyone has lots of time to spare, a SpatialGridDataFrame device with
>> red, green, blue and alpha channels would be nice (or a GDAL MEM device,
>> or whatever).
>>
>> Roger
>>
>>>
>>> Dave
>>>
>>
>>
>
>

-- 
  Dr. David Forrest
  drf at vims.edu                                    (804)684-7900w
  drf5n at maplepark.com                             (804)642-0662h
                                    http://maplepark.com/~drf5n/



From drf5n at maplepark.com  Wed Jan 17 18:58:55 2007
From: drf5n at maplepark.com (David Forrest)
Date: Wed, 17 Jan 2007 11:58:55 -0600 (CST)
Subject: [R-sig-Geo] Marginless plot output for georegistration of
 output graphics
In-Reply-To: <Pine.LNX.4.64.0701171002560.3874@maplepark.com>
References: <Pine.LNX.4.44.0701171440370.31005-100000@reclus.nhh.no>
	<Pine.LNX.4.64.0701171002560.3874@maplepark.com>
Message-ID: <Pine.LNX.4.64.0701171140390.3874@maplepark.com>

On Wed, 17 Jan 2007, David Forrest wrote:

> On Wed, 17 Jan 2007, Roger Bivand wrote:
...
> I feel really close with this, except for the key.

Answering my own question by looking through the source at 
http://r-spatial.cvs.sourceforge.net/r-spatial/sp/R/spplot.R?view=markup I 
see that spplot uses levelplot for many of its plots and will then accept 
a colorkey=FALSE argument to inhibit the keys.  So, for everything but 
SpatialPointsDataFrames, maybe something like this would work:

library(maptools)
xx <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1],
IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))

xx.p<-spplot(xx,'AREA',
        par.settings=theme.novpadding, # lattice theme from prior
        scales=list(axs='i',draw=FALSE),
        xlim=bbox(xx)[1,],ylim=bbox(xx)[2,],colorkey=FALSE)

mywidth<-myheight<-600
if(mapasp(xx)>1)  mywidth  <-myheight / mapasp(xx)
if(mapasp(xx)<1)  myheight <-mywidth  * mapasp(xx)
tf2<-tempfile()
png(file=tf2,width=mywidth,height=myheight,bg='transparent')
print(xx.p)
dev.off()
system(paste("display", tf2))


What do I need to to do turn the key off for spplot(SpatialPointsData) ?

Dave
-- 
  Dr. David Forrest
  drf at vims.edu                                    (804)684-7900w
  drf5n at maplepark.com                             (804)642-0662h
                                    http://maplepark.com/~drf5n/



From Roger.Bivand at nhh.no  Wed Jan 17 19:44:18 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 17 Jan 2007 19:44:18 +0100 (CET)
Subject: [R-sig-Geo] Marginless plot output for georegistration of
 output graphics
In-Reply-To: <Pine.LNX.4.64.0701171140390.3874@maplepark.com>
Message-ID: <Pine.LNX.4.44.0701171903460.31005-100000@reclus.nhh.no>

On Wed, 17 Jan 2007, David Forrest wrote:

> On Wed, 17 Jan 2007, David Forrest wrote:
> 
> > On Wed, 17 Jan 2007, Roger Bivand wrote:
> ...
> > I feel really close with this, except for the key.
> 
> Answering my own question by looking through the source at 
> http://r-spatial.cvs.sourceforge.net/r-spatial/sp/R/spplot.R?view=markup I 
> see that spplot uses levelplot for many of its plots and will then accept 
> a colorkey=FALSE argument to inhibit the keys.  So, for everything but 
> SpatialPointsDataFrames, maybe something like this would work:
> 
> library(maptools)
> xx <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1],
> IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
> 
> xx.p<-spplot(xx,'AREA',
>         par.settings=theme.novpadding, # lattice theme from prior
>         scales=list(axs='i',draw=FALSE),
>         xlim=bbox(xx)[1,],ylim=bbox(xx)[2,],colorkey=FALSE)
> 
> mywidth<-myheight<-600
> if(mapasp(xx)>1)  mywidth  <-myheight / mapasp(xx)
> if(mapasp(xx)<1)  myheight <-mywidth  * mapasp(xx)
> tf2<-tempfile()
> png(file=tf2,width=mywidth,height=myheight,bg='transparent')
> print(xx.p)
> dev.off()
> system(paste("display", tf2))
> 
> 
> What do I need to to do turn the key off for spplot(SpatialPointsData) ?

I can't see it, I thought it might be auto.ket=FALSE, but it doesn't seem 
to be that. To be honest, I would feel more comfortable with base 
graphics and setting my own class intervals and colours. Lattice graphics 
seem more worth the trouble when conditioning, which isn't the case here. 
The aspect doesn't seem happy yet, and for NA and projected CRS, you get 
"iso" back instead of the aspect from mapasp.

Roger



> 
> Dave
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From drf5n at maplepark.com  Wed Jan 17 20:16:27 2007
From: drf5n at maplepark.com (David Forrest)
Date: Wed, 17 Jan 2007 13:16:27 -0600 (CST)
Subject: [R-sig-Geo] Marginless plot output for georegistration of
 output graphics
In-Reply-To: <Pine.LNX.4.44.0701171903460.31005-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0701171903460.31005-100000@reclus.nhh.no>
Message-ID: <Pine.LNX.4.64.0701171254190.3874@maplepark.com>

On Wed, 17 Jan 2007, Roger Bivand wrote:
...
>> What do I need to to do turn the key off for spplot(SpatialPointsData) ?
>
> I can't see it, I thought it might be auto.ket=FALSE, but it doesn't seem
> to be that. To be honest, I would feel more comfortable with base
> graphics and setting my own class intervals and colours. Lattice graphics
> seem more worth the trouble when conditioning, which isn't the case here.

Hmm.  I was thinking that the spplot() was the best-practices method for 
spatial data.

> The aspect doesn't seem happy yet, and for NA and projected CRS, you get
> "iso" back instead of the aspect from mapasp.

Is this a criticism of spplot() or the resultant png from the previous?

I've been working on a toGoogleEarth(spDf,zcol,title,filename) function 
with someone off-list that writes a png and its KML file.  It seems to
be working pretty well, and I'll see if he thinks its ready for sharing.

Dave
-- 
  Dr. David Forrest
  drf at vims.edu                                    (804)684-7900w
  drf5n at maplepark.com                             (804)642-0662h
                                    http://maplepark.com/~drf5n/



From Roger.Bivand at nhh.no  Wed Jan 17 20:56:19 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 17 Jan 2007 20:56:19 +0100 (CET)
Subject: [R-sig-Geo] Marginless plot output for georegistration of
 output graphics
In-Reply-To: <Pine.LNX.4.64.0701171254190.3874@maplepark.com>
Message-ID: <Pine.LNX.4.44.0701172050170.31005-100000@reclus.nhh.no>

On Wed, 17 Jan 2007, David Forrest wrote:

> On Wed, 17 Jan 2007, Roger Bivand wrote:
> ...
> >> What do I need to to do turn the key off for spplot(SpatialPointsData) ?
> >
> > I can't see it, I thought it might be auto.ket=FALSE, but it doesn't seem
> > to be that. To be honest, I would feel more comfortable with base
> > graphics and setting my own class intervals and colours. Lattice graphics
> > seem more worth the trouble when conditioning, which isn't the case here.
> 
> Hmm.  I was thinking that the spplot() was the best-practices method for 
> spatial data.

Yes and no. It is certainly best when the graphic is conditioned, and 
otherwise has the apparent advantage of automatic legends and class 
intervals. But it is difficult to use incrementally, so what you choose 
does depend on what you need to do.

> 
> > The aspect doesn't seem happy yet, and for NA and projected CRS, you get
> > "iso" back instead of the aspect from mapasp.
> 
> Is this a criticism of spplot() or the resultant png from the previous?
> 

Just a remark that in the GE context, we're dealing with geographical 
coordinates anyway, but in other contexts, mapasp() will return the string 
"iso", which fails in arithmetic operations.

> I've been working on a toGoogleEarth(spDf,zcol,title,filename) function 
> with someone off-list that writes a png and its KML file.  It seems to
> be working pretty well, and I'll see if he thinks its ready for sharing.
> 

The more the merrier! Auto-generating the KML to call the PNG would be 
very helpful, and would add to what we know about KML (there are traces on 
the Japanese R wiki too, but writing shaded polygons to text files is 
burdensome for larger data sets; PNGs are flexible).

Roger

> Dave
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From reeves at nceas.ucsb.edu  Wed Jan 17 22:46:38 2007
From: reeves at nceas.ucsb.edu (Rick Reeves)
Date: Wed, 17 Jan 2007 13:46:38 -0800
Subject: [R-sig-Geo] simple yet durable error when trying to build GDAL
 1.4.0 with HDF4 support
Message-ID: <45AE993E.8080903@nceas.ucsb.edu>


Hello All:

Ive searched for a solution to this elsewhere but now will post the 
question here:

Im building GDAL 1.4.0 library from source to include HDF4 library on
ubuntu linux Daper Drake.

Have expanded the HDF4 binaries (which include the libmfhdf.a archive 
required
by GDAL) and the GDAL source build archive and am running ./configure
per http://gdal.org/gdal_building.html. When I run the ./configure script
with the argument:

    --with-hdf4=/opt/4.2r1-linux (this path contains the libraries)..

I get the error :

  " configure: error: HDF4 support requested with arg /opt/4.2r1-linux,
   but neither hdf4 or mfhdf lib found."
 
Google search reveals that several others have encountered this issue
in the past, but no solution is posted.

Has anyone encountered and perhaps resolved this?

Thanks in advance,
Rick Reeves

-- 
Rick Reeves	
Scientific Programmer / Analyst	
National Center for Ecological Analysis and Synthesis
UC Santa Barbara
reeves at nceas.ucsb.edu
www.nceas.ucsb.edu
805 892 2533

-------------- next part --------------
A non-text attachment was scrubbed...
Name: reeves.vcf
Type: text/x-vcard
Size: 339 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20070117/e9eb6729/attachment.vcf>

From e.pebesma at geo.uu.nl  Thu Jan 18 09:31:44 2007
From: e.pebesma at geo.uu.nl (Edzer J Pebesma)
Date: Thu, 18 Jan 2007 09:31:44 +0100
Subject: [R-sig-Geo] Marginless plot output for georegistration of
 output graphics
In-Reply-To: <Pine.LNX.4.64.0701171254190.3874@maplepark.com>
References: <Pine.LNX.4.44.0701171903460.31005-100000@reclus.nhh.no>
	<Pine.LNX.4.64.0701171254190.3874@maplepark.com>
Message-ID: <45AF3070.5040108@geo.uu.nl>

David Forrest wrote:

>On Wed, 17 Jan 2007, Roger Bivand wrote:
>...
>  
>
>>>What do I need to to do turn the key off for spplot(SpatialPointsData) ?
>>>      
>>>
>>I can't see it, I thought it might be auto.ket=FALSE, but it doesn't seem
>>to be that. To be honest, I would feel more comfortable with base
>>graphics and setting my own class intervals and colours. Lattice graphics
>>seem more worth the trouble when conditioning, which isn't the case here.
>>    
>>
>
>Hmm.  I was thinking that the spplot() was the best-practices method for 
>spatial data.
>
spplot lets you choose class intervals and colours, but in a different 
way than base graphics do. I don't think there is a  best-practices for 
spatial data, in the end  best practice to me is that a plotting engine 
does not leave its traces in the plot. However, R has two plotting 
routes, base and lattice/grid, and sp provides (hopefully) convenient 
wrapper functions to use either. Lattice then has the added (major) 
advantage of auto-legends/classes (to some extent) and conditioning.

>
>  
>
>>The aspect doesn't seem happy yet, and for NA and projected CRS, you get
>>"iso" back instead of the aspect from mapasp.
>>    
>>
>
>Is this a criticism of spplot() or the resultant png from the previous?
>
I believe that spplot'ing SpatialPointDataFrames does call mapasp to set 
its aspect, just like the other ones.

I agree that not having a way to suppress the key in spplot for 
SpatialPointsDataFrame is an omission. I'll try to get the auto.key = 
FALSE working. There's quite some code in sp for this particular method, 
as xyplot (which it wraps) doesn't automatically classify points given 
an attribute value; the extra work is done in sp here, unlike the other 
spplot methods that wrap levelplot.
--
Edzer



From maris.gis at gmail.com  Thu Jan 18 10:43:39 2007
From: maris.gis at gmail.com (Maris Nartiss)
Date: Thu, 18 Jan 2007 11:43:39 +0200
Subject: [R-sig-Geo] simple yet durable error when trying to build GDAL
	1.4.0 with HDF4 support
In-Reply-To: <45AE993E.8080903@nceas.ucsb.edu>
References: <45AE993E.8080903@nceas.ucsb.edu>
Message-ID: <2b3d8c1c0701180143h2e7ab08cyadfbca57ad906831@mail.gmail.com>

Hi,

just a hint, maybee helps:
1) check, that libs are in /opr/foo and not /opt/foo/lib
2) add /opt/foo to /etc/ld.so.conf (sudo echo '/opt/foo' >> /etc/ld.so.conf)
3) run ldconfig as root (sudo ldconfig)
4) try to configure with same params.


Maris.


2007/1/17, Rick Reeves <reeves at nceas.ucsb.edu>:
>
> Hello All:
>
> Ive searched for a solution to this elsewhere but now will post the
> question here:
>
> Im building GDAL 1.4.0 library from source to include HDF4 library on
> ubuntu linux Daper Drake.
>
> Have expanded the HDF4 binaries (which include the libmfhdf.a archive
> required
> by GDAL) and the GDAL source build archive and am running ./configure
> per http://gdal.org/gdal_building.html. When I run the ./configure script
> with the argument:
>
>     --with-hdf4=/opt/4.2r1-linux (this path contains the libraries)..
>
> I get the error :
>
>   " configure: error: HDF4 support requested with arg /opt/4.2r1-linux,
>    but neither hdf4 or mfhdf lib found."
>
> Google search reveals that several others have encountered this issue
> in the past, but no solution is posted.
>
> Has anyone encountered and perhaps resolved this?
>
> Thanks in advance,
> Rick Reeves
>
> --
> Rick Reeves	
> Scientific Programmer / Analyst	
> National Center for Ecological Analysis and Synthesis
> UC Santa Barbara
> reeves at nceas.ucsb.edu
> www.nceas.ucsb.edu
> 805 892 2533
>
>
>



From drf5n at maplepark.com  Thu Jan 18 17:37:29 2007
From: drf5n at maplepark.com (David Forrest)
Date: Thu, 18 Jan 2007 10:37:29 -0600 (CST)
Subject: [R-sig-Geo] Marginless plot output for georegistration of
 output graphics
In-Reply-To: <45AF3070.5040108@geo.uu.nl>
References: <Pine.LNX.4.44.0701171903460.31005-100000@reclus.nhh.no>
	<Pine.LNX.4.64.0701171254190.3874@maplepark.com>
	<45AF3070.5040108@geo.uu.nl>
Message-ID: <Pine.LNX.4.64.0701181002460.26999@maplepark.com>

On Thu, 18 Jan 2007, Edzer J Pebesma wrote:

> David Forrest wrote:
>
>> On Wed, 17 Jan 2007, Roger Bivand wrote:
...
>> Hmm.  I was thinking that the spplot() was the best-practices method for
>> spatial data.
>>
> spplot lets you choose class intervals and colours, but in a different
> way than base graphics do. I don't think there is a  best-practices for
> spatial data, in the end  best practice to me is that a plotting engine
> does not leave its traces in the plot. However, R has two plotting
> routes, base and lattice/grid, and sp provides (hopefully) convenient
> wrapper functions to use either. Lattice then has the added (major)
> advantage of auto-legends/classes (to some extent) and conditioning.

I see.

In the documentation, the lattice-based 'spplot' seemed more prominent, 
and I found it unclear that the plot() was a good option.

On plot(SpatialPointsDataFrame) is it possible to eliminate the margins 
there as well?  I can do it with lattice using the theme.novplotting from 
before:

library(maptools);library(stats)
qk<-SpatialPointsDataFrame(quakes[,c(2:1)],quakes)
proj4string(qk)<-CRS("+proj=longlat")
qk.lp<-spplot(qk,'mag',key.space=list(x=0.25,y=.2,corner=c(1,1)),
        par.settings=theme.novpadding,
        scales=list(axs='i',draw=FALSE),
        xlim=bbox(qk)[1,],ylim=bbox(qk)[2,])
print(qk.lp)

# With a controlled-size png file:
myheight=600;mywidth=myheight/mapasp(qk) #
png(file='mymap.png',width=mywidth,height=myheight,bg='transparent')
print(qk.lp)
dev.off()
system(paste('display','mymap.png'))

######### back in base:
# Non-spatial as plot(x,y)  -- No margin
myheight=600;mywidth=myheight/mapasp(qk) #
png(file='mymap.png',width=mywidth,height=myheight,bg='transparent')
par(mar=c(0,0,0,0))
plot(qk$long,qk$lat,xaxs='i',yaxs='i',xlab=FALSE,axes=FALSE,
   xlim=bbox(qk)[1,],ylim=bbox(qk)[2,] # unnecessary
   )
dev.off()
system(paste('display','mymap.png'))

##########
# as SpatialPoints -- maybe the standard 4% margins?
myheight=600;mywidth=myheight/mapasp(qk) #
png(file='mymap.png',width=mywidth,height=myheight,bg='transparent')
par(mar=c(0,0,0,0))
plot(qk,xaxs='i',yaxs='i',xlab=FALSE,axes=FALSE,
xlim=bbox(qk)[1,],ylim=bbox(qk)[2,])
dev.off()
system(paste('display','mymap.png'))
#######################

The last two examples show a difference between the margin handling in 
plotting spatial points data and regular x,y data.

> I agree that not having a way to suppress the key in spplot for
> SpatialPointsDataFrame is an omission. I'll try to get the auto.key =
> FALSE working. There's quite some code in sp for this particular method,
> as xyplot (which it wraps) doesn't automatically classify points given
> an attribute value; the extra work is done in sp here, unlike the other
> spplot methods that wrap levelplot.

Cool.  Moving the key to inside the bbox is a bit awkward.

Thanks for your time,
Dave
-- 
  Dr. David Forrest
  drf at vims.edu                                    (804)684-7900w
  drf5n at maplepark.com                             (804)642-0662h
                                    http://maplepark.com/~drf5n/



From Roger.Bivand at nhh.no  Thu Jan 18 18:28:19 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 18 Jan 2007 18:28:19 +0100 (CET)
Subject: [R-sig-Geo] Marginless plot output for georegistration of
 output graphics
In-Reply-To: <Pine.LNX.4.64.0701181002460.26999@maplepark.com>
Message-ID: <Pine.LNX.4.44.0701181817490.396-100000@reclus.nhh.no>

On Thu, 18 Jan 2007, David Forrest wrote:

> On Thu, 18 Jan 2007, Edzer J Pebesma wrote:
> 
> > David Forrest wrote:
> >
> >> On Wed, 17 Jan 2007, Roger Bivand wrote:
> ...
> >> Hmm.  I was thinking that the spplot() was the best-practices method for
> >> spatial data.
> >>
> > spplot lets you choose class intervals and colours, but in a different
> > way than base graphics do. I don't think there is a  best-practices for
> > spatial data, in the end  best practice to me is that a plotting engine
> > does not leave its traces in the plot. However, R has two plotting
> > routes, base and lattice/grid, and sp provides (hopefully) convenient
> > wrapper functions to use either. Lattice then has the added (major)
> > advantage of auto-legends/classes (to some extent) and conditioning.
> 
> I see.
> 
> In the documentation, the lattice-based 'spplot' seemed more prominent, 
> and I found it unclear that the plot() was a good option.
> 
> On plot(SpatialPointsDataFrame) is it possible to eliminate the margins 
> there as well?  I can do it with lattice using the theme.novplotting from 
> before:
> 
> library(maptools);library(stats)
> qk<-SpatialPointsDataFrame(quakes[,c(2:1)],quakes)
> proj4string(qk)<-CRS("+proj=longlat")
> qk.lp<-spplot(qk,'mag',key.space=list(x=0.25,y=.2,corner=c(1,1)),
>         par.settings=theme.novpadding,
>         scales=list(axs='i',draw=FALSE),
>         xlim=bbox(qk)[1,],ylim=bbox(qk)[2,])
> print(qk.lp)
> 
> # With a controlled-size png file:
> myheight=600;mywidth=myheight/mapasp(qk) #
> png(file='mymap.png',width=mywidth,height=myheight,bg='transparent')
> print(qk.lp)
> dev.off()
> system(paste('display','mymap.png'))
> 
> ######### back in base:
> # Non-spatial as plot(x,y)  -- No margin
> myheight=600;mywidth=myheight/mapasp(qk) #
> png(file='mymap.png',width=mywidth,height=myheight,bg='transparent')
> par(mar=c(0,0,0,0))
> plot(qk$long,qk$lat,xaxs='i',yaxs='i',xlab=FALSE,axes=FALSE,
>    xlim=bbox(qk)[1,],ylim=bbox(qk)[2,] # unnecessary
>    )
> dev.off()
> system(paste('display','mymap.png'))
> 
> ##########
> # as SpatialPoints -- maybe the standard 4% margins?
> myheight=600;mywidth=myheight/mapasp(qk) #
> png(file='mymap.png',width=mywidth,height=myheight,bg='transparent')
> par(mar=c(0,0,0,0))
> plot(qk,xaxs='i',yaxs='i',xlab=FALSE,axes=FALSE,
> xlim=bbox(qk)[1,],ylim=bbox(qk)[2,])
> dev.off()
> system(paste('display','mymap.png'))
> #######################
> 
> The last two examples show a difference between the margin handling in 
> plotting spatial points data and regular x,y data.

I think that plot.window() inside plot.Spatial is not respecting the 
xaxs="i", yaxs="i" settings, probably they are not being passed through 
correctly. By forcing them inside plot.Spatial:

par(usr=c(t(bbox)))

we do get there, but that is certainly brutal. Setting them in par() also 
doesn't carry through plot.window().

Roger

> 
> > I agree that not having a way to suppress the key in spplot for
> > SpatialPointsDataFrame is an omission. I'll try to get the auto.key =
> > FALSE working. There's quite some code in sp for this particular method,
> > as xyplot (which it wraps) doesn't automatically classify points given
> > an attribute value; the extra work is done in sp here, unlike the other
> > spplot methods that wrap levelplot.
> 
> Cool.  Moving the key to inside the bbox is a bit awkward.
> 
> Thanks for your time,
> Dave
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From massimodisasha at yahoo.it  Fri Jan 19 12:21:45 2007
From: massimodisasha at yahoo.it (epifanio)
Date: Fri, 19 Jan 2007 12:21:45 +0100
Subject: [R-sig-Geo] Kriging on "srtm" data
Message-ID: <6393F5F9-9E94-47B1-A279-58486B59AE5F@yahoo.it>

         hi i've some problem to do a tutorial on the kriging  
interpolation
         i found instruction on how to interpolate the srtm data to  
increase the resolution :

	http://grass.itc.it/newsletter/GRASS_OSGeo_News_vol4.pdf

	at page 20 ...  at the line :

        grd <- GridTopology(cellcentre.offset=c(G\$west+(G\$ewres/2),
        G\$south+(G\$nsres/2)),cellsize=c(G\$ewres, G\ 
$nsres),cells.dim=c(G\$cols, G\$rows));


       i have a sintax error in grid function.

i'm missing or wrong something?

thanks for any suggestion :-)

Massimo.



From Roger.Bivand at nhh.no  Fri Jan 19 13:04:00 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 19 Jan 2007 13:04:00 +0100 (CET)
Subject: [R-sig-Geo] Kriging on "srtm" data
In-Reply-To: <6393F5F9-9E94-47B1-A279-58486B59AE5F@yahoo.it>
Message-ID: <Pine.LNX.4.44.0701191259270.1120-100000@reclus.nhh.no>

On Fri, 19 Jan 2007, epifanio wrote:

>          hi i've some problem to do a tutorial on the kriging  
> interpolation
>          i found instruction on how to interpolate the srtm data to  
> increase the resolution :
> 
> 	http://grass.itc.it/newsletter/GRASS_OSGeo_News_vol4.pdf
> 
> 	at page 20 ...  at the line :
> 
>         grd <- GridTopology(cellcentre.offset=c(G\$west+(G\$ewres/2),
>         G\$south+(G\$nsres/2)),cellsize=c(G\$ewres, G\ 
> $nsres),cells.dim=c(G\$cols, G\$rows));
> 

Perhaps the LaTeX \$ markup which got though into the published version is 
the problem? Try removing the backslashes?

> cars$speed
 [1]  4  4  7  7  8  9 10 10 10 11 11 12 12 12 12 13 13 13 13 14 14 14 14 
15 15
[26] 15 16 16 17 17 17 18 18 18 18 19 19 19 20 20 20 20 20 22 23 24 24 24 
24 25
> cars\$speed
Error: syntax error in "cars\"

Roger

> 
>        i have a sintax error in grid function.
> 
> i'm missing or wrong something?
> 
> thanks for any suggestion :-)
> 
> Massimo.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From gasper.cankar at ric.si  Mon Jan 22 07:31:30 2007
From: gasper.cankar at ric.si (Gasper Cankar)
Date: Mon, 22 Jan 2007 07:31:30 +0100
Subject: [R-sig-Geo] plotting only one shape from shapefile
Message-ID: <C437AF9075F4E84E86D34CDA5252B8EB30A8BF@intra2003.ric.si>

Hello!

I know this must be a very simple thing to do yet after one week of trying and going through the archives I don't find the answer. I'm either looking at the wrong places or I'm cursed;)

I imported our country's shapefile with 12 regions and I can draw the shape, but I'd like to extract (and draw) only one region from whole shape.


#This is original shapefile:
slo <- read.shape(file="d://D_E_L_O/slika_slo/slo.shp")
Shapefile type: Polygon, (5), # of Shapes: 12

# and plotting (simplified)
slomap <- Map2poly(slo)
plot(slomap)

How do I plot only one of the shapes? How do I extract it as separate object?

Thank everyone in advance for any help.

Ga?per



From Roger.Bivand at nhh.no  Mon Jan 22 09:10:43 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 22 Jan 2007 09:10:43 +0100 (CET)
Subject: [R-sig-Geo] plotting only one shape from shapefile
In-Reply-To: <C437AF9075F4E84E86D34CDA5252B8EB30A8BF@intra2003.ric.si>
Message-ID: <Pine.LNX.4.44.0701220859290.30606-100000@reclus.nhh.no>

On Mon, 22 Jan 2007, Gasper Cankar wrote:

> Hello!
> 
> I know this must be a very simple thing to do yet after one week of
> trying and going through the archives I don't find the answer. I'm
> either looking at the wrong places or I'm cursed;)

Using sp classes gives this kind of control, see example below.

> 
> I imported our country's shapefile with 12 regions and I can draw the
> shape, but I'd like to extract (and draw) only one region from whole
> shape.
> 
> 
> #This is original shapefile:
> slo <- read.shape(file="d://D_E_L_O/slika_slo/slo.shp")
> Shapefile type: Polygon, (5), # of Shapes: 12
> 
> # and plotting (simplified)
> slomap <- Map2poly(slo)
> plot(slomap)
> 
> How do I plot only one of the shapes? How do I extract it as separate object?
> 

library(maptools)
xx <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1], 
IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
names(xx)
xxx <- xx[xx$NAME == "Dare",]
opar <- par(mfrow=c(2,1), mar=c(0,0,0,0))
plot(xx, col=c(2,3)[as.integer(xx$NAME == "Dare")+1])
plot(xxx, col=3)
par(opar)

That is, SpatialPolygonDataFrame objects have a "[" method to be used for 
subsetting, and readShapePoly() creates a SpatialPolygonDataFrame object - 
like readOGR() in rgdal.

Roger


> Thank everyone in advance for any help.
> 
> Ga?per
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From massimodisasha at yahoo.it  Sat Jan 20 21:46:12 2007
From: massimodisasha at yahoo.it (epifanio)
Date: Sat, 20 Jan 2007 21:46:12 +0100
Subject: [R-sig-Geo] Kriging on "srtm" data
In-Reply-To: <mailman.11.1169290805.26437.r-sig-geo@stat.math.ethz.ch>
References: <mailman.11.1169290805.26437.r-sig-geo@stat.math.ethz.ch>
Message-ID: <B88DE65D-93D4-403B-B764-E0552F385D75@yahoo.it>

Hi,
i've tryed to delete the  "\" backslash,
now i've a different error, at the same line :

 > grd <- GridTopology(cellcentre.offset=c(G$west+(G$ewres/2), G$south 
+(G$nsres/2)), cellsize=c(G$ewres, G$nsres), cells.dim=c(G$cols, G 
$rows));
Errore in validObject(.Object) : invalid class "GridTopology" object:  
cellsize has incorrect dimension



this is my setting :

 > sessionInfo()
R version 2.4.1 (2006-12-18)
i386-apple-darwin8.8.1
locale:
C
attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"   
"methods"
[7] "base"
other attached packages:
    gstat  spatial spgrass6    rgdal maptools  foreign       sp
"0.9-35" "7.2-31"  "0.3-4"  "0.5-5"  "0.6-6" "0.8-18"  "0.9-4"
 >

  g.region eboli90 -p
projection: 1 (UTM)
zone:       33
datum:      wgs84
ellipsoid:  wgs84
north:      4506030
south:      4493970
west:       499590
east:       514350
nsres:      90
ewres:      90
rows:       134
cols:       164
cells:      21976

thanks for any help!

regards,
Massimo




Il giorno 20/gen/07, alle ore 12:00, r-sig-geo- 
request at stat.math.ethz.ch ha scritto:

> On Fri, 19 Jan 2007, epifanio wrote:
>
>>          hi i've some problem to do a tutorial on the kriging
>> interpolation
>>          i found instruction on how to interpolate the srtm data to
>> increase the resolution :
>>
>> 	http://grass.itc.it/newsletter/GRASS_OSGeo_News_vol4.pdf
>>
>> 	at page 20 ...  at the line :
>>
>>         grd <- GridTopology(cellcentre.offset=c(G\$west+(G\$ewres/2),
>>         G\$south+(G\$nsres/2)),cellsize=c(G\$ewres, G\
>> $nsres),cells.dim=c(G\$cols, G\$rows));
>>
>
> Perhaps the LaTeX \$ markup which got though into the published  
> version is
> the problem? Try removing the backslashes?
>
>> cars$speed
>  [1]  4  4  7  7  8  9 10 10 10 11 11 12 12 12 12 13 13 13 13 14 14  
> 14 14
> 15 15
> [26] 15 16 16 17 17 17 18 18 18 18 19 19 19 20 20 20 20 20 22 23 24  
> 24 24
> 24 25
>> cars\$speed
> Error: syntax error in "cars\"
>
> Roger
>
>>
>>        i have a sintax error in grid function.
>>
>> i'm missing or wrong something?
>>
>> thanks for any suggestion :-)
>>
>> Massimo.
>>



From Roger.Bivand at nhh.no  Mon Jan 22 12:05:45 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 22 Jan 2007 12:05:45 +0100 (CET)
Subject: [R-sig-Geo] Kriging on "srtm" data
In-Reply-To: <B88DE65D-93D4-403B-B764-E0552F385D75@yahoo.it>
Message-ID: <Pine.LNX.4.44.0701221203050.30606-100000@reclus.nhh.no>

On Sat, 20 Jan 2007, epifanio wrote:

> Hi,
> i've tryed to delete the  "\" backslash,
> now i've a different error, at the same line :
> 
>  > grd <- GridTopology(cellcentre.offset=c(G$west+(G$ewres/2), G$south 
> +(G$nsres/2)), cellsize=c(G$ewres, G$nsres), cells.dim=c(G$cols, G 
> $rows));
> Errore in validObject(.Object) : invalid class "GridTopology" object:  
> cellsize has incorrect dimension

If you had looked at the G object, you would have seen that the internal 
representation has changed (problems with g.region) since these notes were 
written.

Use the function gmeta2grd() instead of rolling it by hand - the function 
uses the updated representation without users needing to follow internal 
details.

Roger

> 
> 
> 
> this is my setting :
> 
>  > sessionInfo()
> R version 2.4.1 (2006-12-18)
> i386-apple-darwin8.8.1
> locale:
> C
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"   
> "methods"
> [7] "base"
> other attached packages:
>     gstat  spatial spgrass6    rgdal maptools  foreign       sp
> "0.9-35" "7.2-31"  "0.3-4"  "0.5-5"  "0.6-6" "0.8-18"  "0.9-4"
>  >
> 
>   g.region eboli90 -p
> projection: 1 (UTM)
> zone:       33
> datum:      wgs84
> ellipsoid:  wgs84
> north:      4506030
> south:      4493970
> west:       499590
> east:       514350
> nsres:      90
> ewres:      90
> rows:       134
> cols:       164
> cells:      21976
> 
> thanks for any help!
> 
> regards,
> Massimo
> 
> 
> 
> 
> Il giorno 20/gen/07, alle ore 12:00, r-sig-geo- 
> request at stat.math.ethz.ch ha scritto:
> 
> > On Fri, 19 Jan 2007, epifanio wrote:
> >
> >>          hi i've some problem to do a tutorial on the kriging
> >> interpolation
> >>          i found instruction on how to interpolate the srtm data to
> >> increase the resolution :
> >>
> >> 	http://grass.itc.it/newsletter/GRASS_OSGeo_News_vol4.pdf
> >>
> >> 	at page 20 ...  at the line :
> >>
> >>         grd <- GridTopology(cellcentre.offset=c(G\$west+(G\$ewres/2),
> >>         G\$south+(G\$nsres/2)),cellsize=c(G\$ewres, G\
> >> $nsres),cells.dim=c(G\$cols, G\$rows));
> >>
> >
> > Perhaps the LaTeX \$ markup which got though into the published  
> > version is
> > the problem? Try removing the backslashes?
> >
> >> cars$speed
> >  [1]  4  4  7  7  8  9 10 10 10 11 11 12 12 12 12 13 13 13 13 14 14  
> > 14 14
> > 15 15
> > [26] 15 16 16 17 17 17 18 18 18 18 19 19 19 20 20 20 20 20 22 23 24  
> > 24 24
> > 24 25
> >> cars\$speed
> > Error: syntax error in "cars\"
> >
> > Roger
> >
> >>
> >>        i have a sintax error in grid function.
> >>
> >> i'm missing or wrong something?
> >>
> >> thanks for any suggestion :-)
> >>
> >> Massimo.
> >>
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ibanez at bioef.org  Mon Jan 22 13:11:16 2007
From: ibanez at bioef.org (Berta)
Date: Mon, 22 Jan 2007 13:11:16 +0100
Subject: [R-sig-Geo] convUL to convert UTM in Lat/Long
Message-ID: <01b101c73e1e$6c198020$6601a8c0@BIOEF.ORG>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20070122/cebab88e/attachment.pl>

From isabel.garcia.rodriguez at uam.es  Mon Jan 22 13:52:54 2007
From: isabel.garcia.rodriguez at uam.es (isabel.garcia.rodriguez at uam.es)
Date: Mon, 22 Jan 2007 13:52:54 MET
Subject: [R-sig-Geo] Test for spatial autocorrelation among the residual of
	gwr
Message-ID: <200701221252.l0MCqs4U014579@asterix.ti.uam.es>

Hi there!

I would like to know how to carry out the test for spatial autocorrelation 
among the residuals of geographically weighted regression (Leung Y, Mei CG, 
Zhang WX 2000 Testing for spatial autocorrelation among the
residuals of the geographically weighted regression. Environment and Planning
A 32: 871-890) in R. I would appreciate any help about this matter.  

Thank you,

Isabel


--------------------------------------------------------------------------
Mensaje enviado mediante una herramienta Webmail integrada en *El Rincon*:
------------->>>>>>>>     https://rincon.uam.es     <<<<<<<<--------------



From ibanez at bioef.org  Mon Jan 22 15:46:09 2007
From: ibanez at bioef.org (Berta)
Date: Mon, 22 Jan 2007 15:46:09 +0100
Subject: [R-sig-Geo] convUL to convert UTM in Lat/Long
Message-ID: <032701c73e34$0f61aef0$6601a8c0@BIOEF.ORG>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20070122/ea6454e1/attachment.pl>

From Roger.Bivand at nhh.no  Mon Jan 22 16:05:21 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 22 Jan 2007 16:05:21 +0100 (CET)
Subject: [R-sig-Geo] convUL to convert UTM in Lat/Long
In-Reply-To: <01b101c73e1e$6c198020$6601a8c0@BIOEF.ORG>
Message-ID: <Pine.LNX.4.44.0701221535001.30747-100000@reclus.nhh.no>

On Mon, 22 Jan 2007, Berta wrote:

> 
> Hi R-geo users, I am trying to convert a data set in UTM (from Spain,
> zone=30) to the corresponding data set in longitude-latitude. Using
> convUL, it gives me strange results. Here I send my code, just in case
> somebody can tell me what i am missing. I suspect it has something to do
> with + proj or something that it is needed.  Thank you so much in
> advance, Berta
> 
> library(PBSmapping)
> datainUTM<-data.frame(cbind(c(559994, 559673),c(4781905,4781583), c(0, 0), c(1,2)))
> names(datainUTM)<-c("X", "Y", "PID", "POS")
> attr(datainUTM, "projection") <-"UTM"
> attr(datainUTM, "zone") <-30
> datosLL<-convUL(datainUTM)

Yes, can be reproduced, I've CC'ed the maintainer. I can't see anything 
wrong at the R level, but it seems that PBS is maybe expecting the UTM 
coordinates in km not m:

debug: if (inProj == "UTM") {
    inXY <- inXY * 1000
    toUTM <- FALSE
} else {
    toUTM <- TRUE
}

is rather tricky. Doing:

datainUTM$X <-  datainUTM$X/1000
datainUTM$Y <-  datainUTM$Y/1000
convUL(datainUTM)

does work.

Another possibility is:

library(rgdal)
SP <- SpatialPoints(cbind(datainUTM$X, datainUTM$Y), 
  proj4string=CRS("+proj=utm +zone=30"))
spTransform(SP, CRS("+proj=longlat"))

Roger


> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ibanez at bioef.org  Mon Jan 22 17:36:55 2007
From: ibanez at bioef.org (Berta)
Date: Mon, 22 Jan 2007 17:36:55 +0100
Subject: [R-sig-Geo] convUL to convert UTM in Lat/Long
References: <Pine.LNX.4.44.0701221535001.30747-100000@reclus.nhh.no>
Message-ID: <036301c73e43$88c9b580$6601a8c0@BIOEF.ORG>

Thanks Roger, it works perfectly. Just one thing. If I use the second 
option, I obtain (note that it is for other data point, for which I have the 
conversion from the GPS tool)

library(rgdal)
datainUTM<-data.frame(cbind(c(559835),c(4778818), c(0), c(1)))
names(datainUTM)<-c("X", "Y", "PID", "POS")
SP <- SpatialPoints(cbind(datainUTM$X, datainUTM$Y),
proj4string=CRS("+proj=utm +zone=30"))
spTransform(SP, CRS("+proj=longlat"))

#     coords.x1 coords.x2
#[1,] -2.263995  43.15975
#Coordinate Reference System (CRS) arguments:  +proj=longlat +ellps=WGS84

Which differs from what my collages expected, as the GPS (they say) says 
that the conversion for that UTM coordenates is 43? 09585' N, 02? 15840' H, 
and I do not find any similarities (even trying to change from decimals to 
minutes or seconds). May be something is missing in the GPS translation. Any 
clue of what I am missing will be appreciated.

Thank a lot for your help,

Berta






>
> Yes, can be reproduced, I've CC'ed the maintainer. I can't see anything
> wrong at the R level, but it seems that PBS is maybe expecting the UTM
> coordinates in km not m:
>
> debug: if (inProj == "UTM") {
>    inXY <- inXY * 1000
>    toUTM <- FALSE
> } else {
>    toUTM <- TRUE
> }
>
> is rather tricky. Doing:
>
> datainUTM$X <-  datainUTM$X/1000
> datainUTM$Y <-  datainUTM$Y/1000
> convUL(datainUTM)
>
> does work.
>
> Another possibility is:
>
> library(rgdal)
> SP <- SpatialPoints(cbind(datainUTM$X, datainUTM$Y),
>  proj4string=CRS("+proj=utm +zone=30"))
> spTransform(SP, CRS("+proj=longlat"))
>
> Roger
>
>
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> -- 
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>
>
>
>



From Roger.Bivand at nhh.no  Mon Jan 22 18:38:15 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 22 Jan 2007 18:38:15 +0100 (CET)
Subject: [R-sig-Geo] convUL to convert UTM in Lat/Long
In-Reply-To: <036301c73e43$88c9b580$6601a8c0@BIOEF.ORG>
Message-ID: <Pine.LNX.4.44.0701221823590.31529-100000@reclus.nhh.no>

On Mon, 22 Jan 2007, Berta wrote:

> Thanks Roger, it works perfectly. Just one thing. If I use the second 
> option, I obtain (note that it is for other data point, for which I have the 
> conversion from the GPS tool)
> 
> library(rgdal)
> datainUTM<-data.frame(cbind(c(559835),c(4778818), c(0), c(1)))
> names(datainUTM)<-c("X", "Y", "PID", "POS")
> SP <- SpatialPoints(cbind(datainUTM$X, datainUTM$Y),
> proj4string=CRS("+proj=utm +zone=30"))
> spTransform(SP, CRS("+proj=longlat"))
> 
> #     coords.x1 coords.x2
> #[1,] -2.263995  43.15975
> #Coordinate Reference System (CRS) arguments:  +proj=longlat +ellps=WGS84

It doesn't look as though this is the ED50 to WGS84 datum shift that you 
gave in your email that crossed with my reply. It may be that you need to 
find a correct +towgs84 for your location - it turns out that there are 
various ones across Europe - googling on "ED50 towgs84" gives lots of 
different values. Are your GPS values degree+decimal minute:

43? 9.585' N; 02? 15840' H

which would be decimal degree:

43.15975; 2.2640

wouldn't it? 

Roger

> 
> Which differs from what my collages expected, as the GPS (they say) says 
> that the conversion for that UTM coordenates is 43? 09585' N, 02? 15840' H, 
> and I do not find any similarities (even trying to change from decimals to 
> minutes or seconds). May be something is missing in the GPS translation. Any 
> clue of what I am missing will be appreciated.
> 
> Thank a lot for your help,
> 
> Berta
> 
> 
> 
> 
> 
> 
> >
> > Yes, can be reproduced, I've CC'ed the maintainer. I can't see anything
> > wrong at the R level, but it seems that PBS is maybe expecting the UTM
> > coordinates in km not m:
> >
> > debug: if (inProj == "UTM") {
> >    inXY <- inXY * 1000
> >    toUTM <- FALSE
> > } else {
> >    toUTM <- TRUE
> > }
> >
> > is rather tricky. Doing:
> >
> > datainUTM$X <-  datainUTM$X/1000
> > datainUTM$Y <-  datainUTM$Y/1000
> > convUL(datainUTM)
> >
> > does work.
> >
> > Another possibility is:
> >
> > library(rgdal)
> > SP <- SpatialPoints(cbind(datainUTM$X, datainUTM$Y),
> >  proj4string=CRS("+proj=utm +zone=30"))
> > spTransform(SP, CRS("+proj=longlat"))
> >
> > Roger
> >
> >
> >>
> >> [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at stat.math.ethz.ch
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >
> > -- 
> > Roger Bivand
> > Economic Geography Section, Department of Economics, Norwegian School of
> > Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> > Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> > e-mail: Roger.Bivand at nhh.no
> >
> >
> >
> >
> > 
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ibanez at bioef.org  Mon Jan 22 18:58:44 2007
From: ibanez at bioef.org (Berta)
Date: Mon, 22 Jan 2007 18:58:44 +0100
Subject: [R-sig-Geo] convUL to convert UTM in Lat/Long
References: <Pine.LNX.4.44.0701221823590.31529-100000@reclus.nhh.no>
Message-ID: <039d01c73e4e$f6843860$6601a8c0@BIOEF.ORG>


Thanks Roger,

I was not reading correctly the number they gave to me (obviosly, 43? 09585' 
means 43? + 9'585 minutes, so it is exactly what i had to obtain, 43.15975, 
the problem was that I am not familiar with the notation, and i expected a 
decimal point or something). So everything is now as we expected. Regarding 
the correction +towgs84, i will have a look at it, but what I needed to work 
out is already done with your help. Thanks again!!!

Berta


On Mon, 22 Jan 2007, Berta wrote:

> Thanks Roger, it works perfectly. Just one thing. If I use the second
> option, I obtain (note that it is for other data point, for which I have 
> the
> conversion from the GPS tool)
>
> library(rgdal)
> datainUTM<-data.frame(cbind(c(559835),c(4778818), c(0), c(1)))
> names(datainUTM)<-c("X", "Y", "PID", "POS")
> SP <- SpatialPoints(cbind(datainUTM$X, datainUTM$Y),
> proj4string=CRS("+proj=utm +zone=30"))
> spTransform(SP, CRS("+proj=longlat"))
>
> #     coords.x1 coords.x2
> #[1,] -2.263995  43.15975
> #Coordinate Reference System (CRS) arguments:  +proj=longlat +ellps=WGS84

It doesn't look as though this is the ED50 to WGS84 datum shift that you
gave in your email that crossed with my reply. It may be that you need to
find a correct +towgs84 for your location - it turns out that there are
various ones across Europe - googling on "ED50 towgs84" gives lots of
different values. Are your GPS values degree+decimal minute:

43? 9.585' N; 02? 15840' H

which would be decimal degree:

43.15975; 2.2640

wouldn't it?

Roger

>
> Which differs from what my collages expected, as the GPS (they say) says
> that the conversion for that UTM coordenates is 43? 09585' N, 02? 15840' 
> H,
> and I do not find any similarities (even trying to change from decimals to
> minutes or seconds). May be something is missing in the GPS translation. 
> Any
> clue of what I am missing will be appreciated.
>
> Thank a lot for your help,
>
> Berta
>
>
>
>
>
>
> >
> > Yes, can be reproduced, I've CC'ed the maintainer. I can't see anything
> > wrong at the R level, but it seems that PBS is maybe expecting the UTM
> > coordinates in km not m:
> >
> > debug: if (inProj == "UTM") {
> >    inXY <- inXY * 1000
> >    toUTM <- FALSE
> > } else {
> >    toUTM <- TRUE
> > }
> >
> > is rather tricky. Doing:
> >
> > datainUTM$X <-  datainUTM$X/1000
> > datainUTM$Y <-  datainUTM$Y/1000
> > convUL(datainUTM)
> >
> > does work.
> >
> > Another possibility is:
> >
> > library(rgdal)
> > SP <- SpatialPoints(cbind(datainUTM$X, datainUTM$Y),
> >  proj4string=CRS("+proj=utm +zone=30"))
> > spTransform(SP, CRS("+proj=longlat"))
> >
> > Roger
> >
> >
> >>
> >> [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at stat.math.ethz.ch
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >
> > -- 
> > Roger Bivand
> > Economic Geography Section, Department of Economics, Norwegian School of
> > Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> > Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> > e-mail: Roger.Bivand at nhh.no
> >
> >
> >
> >
> >
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From jkreitler at bren.ucsb.edu  Mon Jan 22 19:54:14 2007
From: jkreitler at bren.ucsb.edu (Jason Kreitler)
Date: Mon, 22 Jan 2007 10:54:14 -0800
Subject: [R-sig-Geo] fit points in GWR
Message-ID: <45B50856.3000300@bren.ucsb.edu>

All,

I am attempting to interpolate using the 'fit points' command within 
GWR, but continue to run into problems. Can you recommend some example 
code that utilizes the 'fit points' function? I haven't found an example 
within the documentation.

thanks much,
jason

-- 
Jason Kreitler
University of California, Santa Barbara
Bren School of Env. Sci. & Mgmt.
3017 Bren Hall
Santa Barbara, CA 93106

office: 805 893.7044
mobile: 805 403.9795
jkreitler at bren.ucsb.edu



From Roger.Bivand at nhh.no  Mon Jan 22 20:05:33 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 22 Jan 2007 20:05:33 +0100 (CET)
Subject: [R-sig-Geo] Test for spatial autocorrelation among the residual
 of gwr
In-Reply-To: <200701221252.l0MCqs4U014579@asterix.ti.uam.es>
Message-ID: <Pine.LNX.4.44.0701221942210.31529-100000@reclus.nhh.no>

On Mon, 22 Jan 2007 isabel.garcia.rodriguez at uam.es wrote:

> Hi there!
> 
> I would like to know how to carry out the test for spatial autocorrelation 
> among the residuals of geographically weighted regression (Leung Y, Mei CG, 
> Zhang WX 2000 Testing for spatial autocorrelation among the
> residuals of the geographically weighted regression. Environment and Planning
> A 32: 871-890) in R. I would appreciate any help about this matter.  

I have code for a Moran test, but if I remember correctly, based on
Brunsdon et al 1998. I do not know if it will run on spgwr output objects 
- it needs a listw list of neighbour weights argument from the spdep 
package. It is only suitable for smallish data sets, and I'm not sure 
whether I would trust it, even if it is correctly implemented. Please let 
me know offlist if you'd like a copy.

Roger

> 
> Thank you,
> 
> Isabel
> 
> 
> --------------------------------------------------------------------------
> Mensaje enviado mediante una herramienta Webmail integrada en *El Rincon*:
> ------------->>>>>>>>     https://rincon.uam.es     <<<<<<<<--------------
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Mon Jan 22 20:14:12 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 22 Jan 2007 20:14:12 +0100 (CET)
Subject: [R-sig-Geo] fit points in GWR
In-Reply-To: <45B50856.3000300@bren.ucsb.edu>
Message-ID: <Pine.LNX.4.44.0701222007580.31529-100000@reclus.nhh.no>

On Mon, 22 Jan 2007, Jason Kreitler wrote:

> All,
> 
> I am attempting to interpolate using the 'fit points' command within 
> GWR, but continue to run into problems. Can you recommend some example 
> code that utilizes the 'fit points' function? I haven't found an example 
> within the documentation.

GWR does not interpolate, it fits coefficients at fit points weighted by 
distances from the data points (where there are known values of the 
variables). The final example at the foot of the examples on the gwr() 
help page - example(gwr) - will run if you have packages maptools and 
gpclib installed (I think in the released version, YMMV), using a grid of 
SpatialPixels as fit.points=. It simply does gwr() for a regular grid of 
points within Georgia, after first merging the counties.

Hope this helps,

Roger

> 
> thanks much,
> jason
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From SchnuteJ at pac.dfo-mpo.gc.ca  Mon Jan 22 21:56:38 2007
From: SchnuteJ at pac.dfo-mpo.gc.ca (SchnuteJ at pac.dfo-mpo.gc.ca)
Date: Mon, 22 Jan 2007 12:56:38 -0800
Subject: [R-sig-Geo] convUL to convert UTM in Lat/Long
Message-ID: <63F107BCC37AEA49A75FD94AA3E07CB013AF27@pacpbsex01.pac.dfo-mpo.ca>

On Mon, 22 Jan 2007, Berta wrote:

> Hi R-geo users, I am trying to convert a data set in UTM (from Spain,
> zone=30) to the corresponding data set in longitude-latitude. Using
> convUL, it gives me strange results. Here I send my code, just in case
> somebody can tell me what i am missing. I suspect it has something to do
> with + proj or something that it is needed.  Thank you so much in
> advance, Berta
> 
> library(PBSmapping)
> datainUTM<-data.frame(cbind(c(559994, 559673),c(4781905,4781583), c(0, 0),
c(1,2)))
> names(datainUTM)<-c("X", "Y", "PID", "POS")
> attr(datainUTM, "projection") <-"UTM"
> attr(datainUTM, "zone") <-30
> datosLL<-convUL(datainUTM)

I'm following the thread that began with Berta's message above. Roger Bivand
correctly states that PBSmapping uses UTM coordinates measured in km, not m.
Currently, the help file doesn't mention this requirement. In the next
version, we'll fix the documentation (convUL.Rd). We may also add another
argument to "convUL" that allows a choice between "km" and "m". Thanks to
Berta and Roger for alerting us to this problem.

For the record, the following R code illustrates the identical conversion
using both PBSmapping and rgdal, based on three points mentioned in the
earlier correspondence:

# Load packages
require(PBSmapping); require(rgdal)

# Input data for PBS Mapping
datainUTM <- data.frame(cbind(
  c(559.994, 559.673, 559.835),
  c(4781.905, 4781.583, 4778.818),
  c(1,1,1), c(1,2,3)))
names(datainUTM) <- c("X", "Y", "PID", "POS")
attr(datainUTM, "projection") <- "UTM"
attr(datainUTM, "zone") <- 30

# PBS Mapping conversion
PBS.LLout <- convUL(datainUTM)

# SP conversion
SP <- SpatialPoints(cbind(1000*datainUTM$X, 1000*datainUTM$Y), 
  proj4string = CRS("+proj=utm +zone=30"))
SP.LLout <- spTransform(SP, CRS("+proj=longlat"))

# Display results
cat("UTM Input:\n"); print(datainUTM)
cat("\nPBS LL Output:\n"); print(PBS.LLout)
cat("\nSP LL Output:\n"); print(SP.LLout)

Happily (given completely independent code), both packages produce the same
results:

UTM Input:
        X        Y PID POS
1 559.994 4781.905   1   1
2 559.673 4781.583   1   2
3 559.835 4778.818   1   3

PBS LL Output:
          X        Y PID POS
1 -2.261705 43.18753   1   1
2 -2.265689 43.18466   1   2
3 -2.263995 43.15975   1   3

SP LL Output:
SpatialPoints:
     coords.x1 coords.x2
[1,] -2.261705  43.18753
[2,] -2.265689  43.18466
[3,] -2.263995  43.15975

We began developing PBS Mapping before we realized that Roger was working on
general spatial classes. In future releases, we hope to take much greater
advantage of his excellent work. PBS Mapping comes with an extensive User's
Guide (PBSmapping-UG.pdf) in the R library tree ..\library\PBSmapping. This
explains the goals of the package and includes figures that illustrate the
possibilities.

Jon

******************************************
Jon Schnute
Pacific Biological Station
3190 Hammond Bay Road
Nanaimo, BC V9T 6N7
CANADA

Tel: 250-756-7146
email: schnutej at pac.dfo-mpo.gc.ca



From pierces1 at msu.edu  Tue Jan 23 17:38:17 2007
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Tue, 23 Jan 2007 11:38:17 -0500
Subject: [R-sig-Geo] Transforming coordinates
Message-ID: <005901c73f0c$e2ca1380$0a00a8c0@TheVoid>

Hi folks,

I've read in a shapefile that was provided to me in the Michigan State Plane
(South) coordinate system using the following code. How would I now
transform the coordinates so that the point represented by [origin.x,
origin.y] becomes the new [0,0], and at the same time convert the units from
feet (the original units) to meters? 

# Define the projection details that match those attached to the shapefile I
received. 

projection.details <- paste("+proj=lcc", 
                            "+lat_1=42.10000000", 
                            "+lat_2=43.66666667", 
                            "+lat_0=41.50000000", 
                            "+lon_0=-84.36666667",
                            "+x_0=13123333.33333333", 
                            "+y_0=0.00000000", sep=" ")

# Read in the shapefile.

ESCA.boundaries <- readShapePoly("schoolbnd_new1.shp", 
                                 proj4string = CRS(projection.details),
                                 verbose=TRUE)

# Collect the coordinates for the new origin at the lower left corner of the
# study region and store them. 

origin.x <- bbox(ESCA.boundaries[16,])[1,1]
origin.y <- bbox(Longit.usable)[2,1]



Steven J. Pierce, M.S.
Doctoral Student in Ecological/Community Psychology
Department of Psychology
Michigan State University
240B Psychology Building
East Lansing, MI 48824-1116

E-mail: pierces1 at msu.edu
Web: http://www.psychology.msu.edu/eco/



From Roger.Bivand at nhh.no  Tue Jan 23 22:21:48 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 23 Jan 2007 22:21:48 +0100 (CET)
Subject: [R-sig-Geo] Transforming coordinates
In-Reply-To: <005901c73f0c$e2ca1380$0a00a8c0@TheVoid>
Message-ID: <Pine.LNX.4.44.0701232216220.32329-100000@reclus.nhh.no>

On Tue, 23 Jan 2007, Steven J. Pierce wrote:

> Hi folks,
> 
> I've read in a shapefile that was provided to me in the Michigan State Plane
> (South) coordinate system using the following code. How would I now
> transform the coordinates so that the point represented by [origin.x,
> origin.y] becomes the new [0,0], and at the same time convert the units from
> feet (the original units) to meters? 

The Michigan State Plane South NAD83 in feet seems to be EPSG code 2898, 
while the same in metres is EPSG code 2809. So assign "+init=epsg:2898" to 
the shapefile, and use spTransform() in rgdal to change to 
"+init=epsg:2809". From there on take the full parameters of code 2809, 
and change x_0= and y_0= to the bounding box bbox() minimum values in 
metres, and spTransform() again. I guess you need to do this, but it isn't 
clear why.

> 
> # Define the projection details that match those attached to the shapefile I
> received. 
> 
> projection.details <- paste("+proj=lcc", 
>                             "+lat_1=42.10000000", 
>                             "+lat_2=43.66666667", 
>                             "+lat_0=41.50000000", 
>                             "+lon_0=-84.36666667",
>                             "+x_0=13123333.33333333", 
>                             "+y_0=0.00000000", sep=" ")
> 
> # Read in the shapefile.
> 
> ESCA.boundaries <- readShapePoly("schoolbnd_new1.shp", 
>                                  proj4string = CRS(projection.details),
>                                  verbose=TRUE)
> 
> # Collect the coordinates for the new origin at the lower left corner of the
> # study region and store them. 
> 
> origin.x <- bbox(ESCA.boundaries[16,])[1,1]
> origin.y <- bbox(Longit.usable)[2,1]
> 
> 
> 
> Steven J. Pierce, M.S.
> Doctoral Student in Ecological/Community Psychology
> Department of Psychology
> Michigan State University
> 240B Psychology Building
> East Lansing, MI 48824-1116
> 
> E-mail: pierces1 at msu.edu
> Web: http://www.psychology.msu.edu/eco/
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From linard at geog.ucl.ac.be  Wed Jan 24 12:25:12 2007
From: linard at geog.ucl.ac.be (Catherine Linard)
Date: Wed, 24 Jan 2007 12:25:12 +0100
Subject: [R-sig-Geo] Spatial model in geoRglm
Message-ID: <20070124112218.3DC3CDB4FF@smtp-2.dynsipr.ucl.ac.be>

Hello,

I'm trying to use the geoRglm package to perform a Poisson spatial 
model. I looked at all commands in the package and I have some 
methodological and technical questions.

Firstly, if I understand well, there are two ways to perform a 
spatial regression with generalized linear models in geoRglm: (i) 
with bayesian methods with the 'pois.krige.bayes' procedure or (ii) 
with a Monte Carlo Maximum Likelihood estimation, with the 
'likfit.glsm' procedure. As I'm not used to work with Bayesian 
methods, I prefer the second method but get some error messages that 
I don't understand.

Here are my codes for a Poisson spatial model with 4 covariates:

 > lyme <- read.csv("Lyme.csv",header=TRUE,sep=";",dec=",")
 > geolyme <- as.geodata(lyme,coords.col = 2:3, data.col = 4, 
covar.col = 7:10, units.m.col = 6,borders = TRUE)
 > trend <- trend.spatial("1st", geolyme, add=~COV1+COV2+COV3+COV4)
 > mcmc <- mcmc.control(S.scale=0.00000004, thin=1,phi.scale=0.5) # 
S.scale was chosen to get an Acc.-rate close to 0.60.
 > glsmmcmc <- glsm.mcmc (geolyme, coords=geolyme$coords, 
data=geolyme$data, units.m=geolyme$units.m, model=list (trend=trend, 
beta=c(1,1,1,1,1,1,1), cov.pars=c(1,1), link="log", 
family="poisson"), mcmc.input=mcmc,messages=T)

iter. numb. 1000  : Acc.-rate =  0.589
MCMC performed: n.iter. =  1000 ; thinning =  1 ; burn.in =  0

 > mcmcobj <- prepare.likfit.glsm(glsmmcmc)
 > lik.1 <- likfit.glsm(mcmcobj,ini.phi=0.1)
--------------------------------------------------------------------
likfit.glsm: likelihood maximisation using the function optim.
phi =  0.1 tausq.rel =  0
    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
       0       0      0     Inf     Inf    Inf
Erreur dans .func.val(SivS, SivD, DivD, beta.hat[ll, ], sigmasq.hat[ll],  :
         Some function values are not finite

Any suggestions on how to resolve this problem will be appreciated. I 
hope that I'm not completely wrong. Otherwise, I will also appreciate 
examples of codes that implement a Poisson spatial regression model 
with different covariates in geoRglm.

Thank you very much for any help,


Catherine Linard
University of Louvain
Department of Geography
Place Pasteur, 3
B - 1348 Louvain-la-Neuve
BELGIUM

Tel: +32/10/47.28.67
Fax: +32/10/47.28.77
e-mail: linard at geog.ucl.ac.be
http://www.geo.ucl.ac.be/Recherche/Teledetection/integrated_studies.html



From pierces1 at msu.edu  Wed Jan 24 16:55:12 2007
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Wed, 24 Jan 2007 10:55:12 -0500
Subject: [R-sig-Geo] Transforming coordinates
In-Reply-To: <Pine.LNX.4.44.0701232216220.32329-100000@reclus.nhh.no>
References: <005901c73f0c$e2ca1380$0a00a8c0@TheVoid>
	<Pine.LNX.4.44.0701232216220.32329-100000@reclus.nhh.no>
Message-ID: <002601c73fd0$083e8150$9e5f0a23@TheVoid>

Thanks Roger. The immediate purpose is to produce a map of the neighborhoods
where our study is located with the x & y axes labeled so as to clearly
illustrate the size of the study region. But, I'll also be overlaying some
point pattern data collected via surveys of neighborhood residents and want
to do some trend surface modeling, variogram modeling, and kriging to
examine the spatial structure of certain survey measures. 

I've gotten the impression that in analyzing those kinds of data, such
coordinate transformations are not unusual. But, the spatial analysis class
I took generally used example datasets where coordinate systems were already
set up and never discussed that explicitly, so I'm trying to learn some of
this stuff on my own. 

Is there a better way to set up the coordinate system for this sort of
analysis? 

Steven J. Pierce
E-mail: pierces1 at msu.edu

-----Original Message-----
From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Sent: Tuesday, January 23, 2007 4:22 PM
To: Steven J. Pierce
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] Transforming coordinates

On Tue, 23 Jan 2007, Steven J. Pierce wrote:

> Hi folks,
> 
> I've read in a shapefile that was provided to me in the Michigan State 
> Plane
> (South) coordinate system using the following code. How would I now 
> transform the coordinates so that the point represented by [origin.x, 
> origin.y] becomes the new [0,0], and at the same time convert the 
> units from feet (the original units) to meters?

The Michigan State Plane South NAD83 in feet seems to be EPSG code 2898,
while the same in metres is EPSG code 2809. So assign "+init=epsg:2898" to
the shapefile, and use spTransform() in rgdal to change to
"+init=epsg:2809". From there on take the full parameters of code 2809, and
change x_0= and y_0= to the bounding box bbox() minimum values in metres,
and spTransform() again. I guess you need to do this, but it isn't clear
why.

> 
> # Define the projection details that match those attached to the 
> shapefile I received.
> 
> projection.details <- paste("+proj=lcc", 
>                             "+lat_1=42.10000000", 
>                             "+lat_2=43.66666667", 
>                             "+lat_0=41.50000000", 
>                             "+lon_0=-84.36666667",
>                             "+x_0=13123333.33333333", 
>                             "+y_0=0.00000000", sep=" ")
> 
> # Read in the shapefile.
> 
> ESCA.boundaries <- readShapePoly("schoolbnd_new1.shp", 
>                                  proj4string = CRS(projection.details),
>                                  verbose=TRUE)
> 
> # Collect the coordinates for the new origin at the lower left corner 
> of the # study region and store them.
> 
> origin.x <- bbox(ESCA.boundaries[16,])[1,1] origin.y <- 
> bbox(Longit.usable)[2,1]
> 
> 
> 
> Steven J. Pierce, M.S.
> Doctoral Student in Ecological/Community Psychology Department of 
> Psychology Michigan State University 240B Psychology Building East 
> Lansing, MI 48824-1116
> 
> E-mail: pierces1 at msu.edu
> Web: http://www.psychology.msu.edu/eco/
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

--
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Wed Jan 24 19:00:51 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 24 Jan 2007 19:00:51 +0100 (CET)
Subject: [R-sig-Geo] Transforming coordinates
In-Reply-To: <002601c73fd0$083e8150$9e5f0a23@TheVoid>
Message-ID: <Pine.LNX.4.44.0701241856250.522-100000@reclus.nhh.no>

On Wed, 24 Jan 2007, Steven J. Pierce wrote:

> Thanks Roger. The immediate purpose is to produce a map of the neighborhoods
> where our study is located with the x & y axes labeled so as to clearly
> illustrate the size of the study region. But, I'll also be overlaying some
> point pattern data collected via surveys of neighborhood residents and want
> to do some trend surface modeling, variogram modeling, and kriging to
> examine the spatial structure of certain survey measures. 
> 
> I've gotten the impression that in analyzing those kinds of data, such
> coordinate transformations are not unusual. But, the spatial analysis class
> I took generally used example datasets where coordinate systems were already
> set up and never discussed that explicitly, so I'm trying to learn some of
> this stuff on my own. 
> 
> Is there a better way to set up the coordinate system for this sort of
> analysis? 

For exchanging data with others, it is usually best to use a standard 
format. Then the different data sources can be combined without jumping 
through hoops (e.g. GPS readings). So using a custom origin (moving x_0 
and y_0 doesn't necessarily seem like a good idea. If you are using a 
trend surface though in lm(), big values especially of y (feet or metres 
from the Equator in some projections) blow up by the cube unless the 
software is smart and rescales them on the fly (surf.ls in spatial and 
gstat are smart).

Roger

> 
> Steven J. Pierce
> E-mail: pierces1 at msu.edu
> 
> -----Original Message-----
> From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
> Sent: Tuesday, January 23, 2007 4:22 PM
> To: Steven J. Pierce
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] Transforming coordinates
> 
> On Tue, 23 Jan 2007, Steven J. Pierce wrote:
> 
> > Hi folks,
> > 
> > I've read in a shapefile that was provided to me in the Michigan State 
> > Plane
> > (South) coordinate system using the following code. How would I now 
> > transform the coordinates so that the point represented by [origin.x, 
> > origin.y] becomes the new [0,0], and at the same time convert the 
> > units from feet (the original units) to meters?
> 
> The Michigan State Plane South NAD83 in feet seems to be EPSG code 2898,
> while the same in metres is EPSG code 2809. So assign "+init=epsg:2898" to
> the shapefile, and use spTransform() in rgdal to change to
> "+init=epsg:2809". From there on take the full parameters of code 2809, and
> change x_0= and y_0= to the bounding box bbox() minimum values in metres,
> and spTransform() again. I guess you need to do this, but it isn't clear
> why.
> 
> > 
> > # Define the projection details that match those attached to the 
> > shapefile I received.
> > 
> > projection.details <- paste("+proj=lcc", 
> >                             "+lat_1=42.10000000", 
> >                             "+lat_2=43.66666667", 
> >                             "+lat_0=41.50000000", 
> >                             "+lon_0=-84.36666667",
> >                             "+x_0=13123333.33333333", 
> >                             "+y_0=0.00000000", sep=" ")
> > 
> > # Read in the shapefile.
> > 
> > ESCA.boundaries <- readShapePoly("schoolbnd_new1.shp", 
> >                                  proj4string = CRS(projection.details),
> >                                  verbose=TRUE)
> > 
> > # Collect the coordinates for the new origin at the lower left corner 
> > of the # study region and store them.
> > 
> > origin.x <- bbox(ESCA.boundaries[16,])[1,1] origin.y <- 
> > bbox(Longit.usable)[2,1]
> > 
> > 
> > 
> > Steven J. Pierce, M.S.
> > Doctoral Student in Ecological/Community Psychology Department of 
> > Psychology Michigan State University 240B Psychology Building East 
> > Lansing, MI 48824-1116
> > 
> > E-mail: pierces1 at msu.edu
> > Web: http://www.psychology.msu.edu/eco/
> > 
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > 
> 
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From hi_ono2001 at yahoo.co.jp  Wed Jan 24 20:45:04 2007
From: hi_ono2001 at yahoo.co.jp (Hisaji ONO)
Date: Thu, 25 Jan 2007 04:45:04 +0900 (JST)
Subject: [R-sig-Geo] Any example using UMN Mapserver with R
Message-ID: <20070124194504.39472.qmail@web10915.mail.bbt.yahoo.co.jp>

Hello.

 UMN Mapserver is one of most famous Open Source Web GIS
Engine.

 Is there any example combine this with R for spatial data
mining etc?


 Regards.



From jkreitler at bren.ucsb.edu  Fri Jan 26 02:50:08 2007
From: jkreitler at bren.ucsb.edu (Jason Kreitler)
Date: Thu, 25 Jan 2007 17:50:08 -0800
Subject: [R-sig-Geo] gwr error
Message-ID: <45B95E50.6050808@bren.ucsb.edu>

all,
when running gwr i get the following error if i have fit points (either 
SpatialPoints or a grid) included in the analysis, but i do not get the 
error and the gwr routine runs when fit points are excluded. i don't 
understand this but i think the problem is in my dataset, not the fit 
points. could someone offer a suggestion based on the error below? i am 
reading in the data via the readShapePoints command in Maptools.

 >Error in validityMethod(object) : number of rows in data.frame and 
SpatialPoints don't match

all the rows within my data frame have a value (some zero), and R reads 
the correct number of rows when i do a summary, so i don't quite know 
what to do. Any ideas?
thanks much,
jason

-- 
Jason Kreitler
University of California, Santa Barbara
Bren School of Env. Sci. & Mgmt.
3017 Bren Hall
Santa Barbara, CA 93106

office: 805 893.7044
mobile: 805 403.9795
jkreitler at bren.ucsb.edu



From pedrosaw at gmail.com  Fri Jan 26 08:14:40 2007
From: pedrosaw at gmail.com (Pedro S. A. Wolf)
Date: Fri, 26 Jan 2007 00:14:40 -0700
Subject: [R-sig-Geo] calculating area
Message-ID: <e163468e0701252314v25a54771k219127639a9b82ca@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20070126/827ab39c/attachment.pl>

From Roger.Bivand at nhh.no  Fri Jan 26 09:34:22 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 26 Jan 2007 09:34:22 +0100 (CET)
Subject: [R-sig-Geo] calculating area
In-Reply-To: <e163468e0701252314v25a54771k219127639a9b82ca@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0701260922490.1847-100000@reclus.nhh.no>

On Fri, 26 Jan 2007, Pedro S. A. Wolf wrote:

>  I am a psychology student who has been using R to analyze experimental data
> mainly within the general linear model for about 2 years.  I have some
> working knowledge with R, but by no means would call myself proficient so
> bear with me.  Currently I'm running a series of experiments dealing with
> spatial data.  I'm tracking peoples movements using gps units which give me
> latitude, heading, longitude, speed, altitude, and time variables.  I have
> been using the packages "maps" and "mapproj" to plot the routes which these
> individuals take which is a great visualization tool.  I would like to know
> if there is a package or set of commands which would calculate the area
> these people occupy?  So far the closest I have been able to get to
> accomplishing this task is basically taking the max and min for both lat and
> long coordinates and calculating the size of that area, but I would like
> something more accurate.  Another thing I'm trying to accomplish is creating
> what I would call a density map. This is probably not the correct term so
> let me explain what I mean.  I'm trying to characterize how people occupy
> space.  Especially how people visit certain places more than others.  Is
> there a way to create a map which shows the amount of times a particular
> place is visited by these people both within subjects and a second map
> between subjects? Help would be greatly appreciated, as my academic advisors
> know next to nothing about working with this type of data.

If you think of including humans as animals, you'll find that field
scientists, for example ecologists, do this a good deal - see the package
adehabitat, perhaps function NNCH.area for Home Range Area. The package
trip also provides tools for handling spurious GPS reports. You may find 
that you need to transform the GPS coordinates from geographical to 
projected to make area calculation easier, and that maps and mapproj will 
limit what you can do, perhaps consider moving to sp, maptools and rgdal.

(There will be an R spatial workshop at the Association of American 
Geographers conference in San Francisco on Tuesday 17 April; the "tape" of 
Edzer Pebesma's eSeminar on R spatial classes and methods is not yet 
online, but we'll post when it is ready:

http://www.wun.ac.uk/ggisa/seminars/archive/2006_program/index.html

is where it should turn up).

Roger

> 
> Pedro
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Fri Jan 26 14:57:44 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 26 Jan 2007 14:57:44 +0100 (CET)
Subject: [R-sig-Geo] gwr error
In-Reply-To: <45B95E50.6050808@bren.ucsb.edu>
Message-ID: <Pine.LNX.4.44.0701261452050.2141-100000@reclus.nhh.no>

On Thu, 25 Jan 2007, Jason Kreitler wrote:

> all,
> when running gwr i get the following error if i have fit points (either 
> SpatialPoints or a grid) included in the analysis, but i do not get the 
> error and the gwr routine runs when fit points are excluded. i don't 
> understand this but i think the problem is in my dataset, not the fit 
> points. could someone offer a suggestion based on the error below? i am 
> reading in the data via the readShapePoints command in Maptools.
> 
>  >Error in validityMethod(object) : number of rows in data.frame and 
> SpatialPoints don't match

Yes, but since there is no context here, I can't tell. What is the context 
of the error message (verbatim)? What does traceback() say immediately 
after the error? Do you know that the objects being input in the gwr() 
call are what you think they are? Are you setting mutually contradictory 
arguments?

If need be, can you make your data objects available by save() as an 
.RData file? This is assuming you don't want to debug() gwr yourself to 
see where your assumptions and the code are misunderstanding each other?

Roger

> 
> all the rows within my data frame have a value (some zero), and R reads 
> the correct number of rows when i do a summary, so i don't quite know 
> what to do. Any ideas?
> thanks much,
> jason
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From White.Denis at epamail.epa.gov  Fri Jan 26 17:01:34 2007
From: White.Denis at epamail.epa.gov (White.Denis at epamail.epa.gov)
Date: Fri, 26 Jan 2007 08:01:34 -0800
Subject: [R-sig-Geo] calculating area
In-Reply-To: <Pine.LNX.4.44.0701260922490.1847-100000@reclus.nhh.no>
Message-ID: <OFBFB004ED.72D9DA66-ON8825726F.00575C92-8825726F.00580A65@epamail.epa.gov>

r-sig-geo-bounces at stat.math.ethz.ch wrote on 2007-01-26 00:34:22:

> On Fri, 26 Jan 2007, Pedro S. A. Wolf wrote:
>
> >  I am a psychology student who has been using R to analyze
experimental data
> > mainly within the general linear model for about 2 years.  I have
some
> > working knowledge with R, but by no means would call myself
proficient so
> > bear with me.  Currently I'm running a series of experiments dealing
with
> > spatial data.  I'm tracking peoples movements using gps units which
give me
> > latitude, heading, longitude, speed, altitude, and time variables.
I have
> > been using the packages "maps" and "mapproj" to plot the routes
which these
> > individuals take which is a great visualization tool.  I would like
to know
> > if there is a package or set of commands which would calculate the
area
> > these people occupy?  So far the closest I have been able to get to
> > accomplishing this task is basically taking the max and min for both
lat and
> > long coordinates and calculating the size of that area, but I would
like
> > something more accurate.  Another thing I'm trying to accomplish is
creating
> > what I would call a density map. This is probably not the correct
term so
> > let me explain what I mean.  I'm trying to characterize how people
occupy
> > space.  Especially how people visit certain places more than others.
Is
> > there a way to create a map which shows the amount of times a
particular
> > place is visited by these people both within subjects and a second
map
> > between subjects? Help would be greatly appreciated, as my academic
advisors
> > know next to nothing about working with this type of data.
>
> If you think of including humans as animals, you'll find that field
> scientists, for example ecologists, do this a good deal - see the
package
> adehabitat, perhaps function NNCH.area for Home Range Area. The
package
> trip also provides tools for handling spurious GPS reports. You may
find
> that you need to transform the GPS coordinates from geographical to
> projected to make area calculation easier, and that maps and mapproj
will
> limit what you can do, perhaps consider moving to sp, maptools and
rgdal.
>
> (There will be an R spatial workshop at the Association of American
> Geographers conference in San Francisco on Tuesday 17 April; the
"tape" of
> Edzer Pebesma's eSeminar on R spatial classes and methods is not yet
> online, but we'll post when it is ready:
>
> http://www.wun.ac.uk/ggisa/seminars/archive/2006_program/index.html
>
> is where it should turn up).
>
> Roger
>

Depending on where on earth your data are from, the area calculations
may
be confounded by the spherical (or ellipsoidal) shape of the earth.  So
think about using the difference in longitude as you approach the poles.
If your data are from a small area and you are only interested in
relative
differences in area then the geographic coordinates may be sufficient,
otherwise you may want to check out a web site on map projections and
choose one that will give you good area fidelity.  One class of map
projections has the property called equal-area, and preserves, in the
plane of the projection, the area relationships on the spherical (or
ellipsoidal) earth.

Denis

> >
> > Pedro
> >



From reeves at nceas.ucsb.edu  Fri Jan 26 18:54:53 2007
From: reeves at nceas.ucsb.edu (Rick Reeves)
Date: Fri, 26 Jan 2007 09:54:53 -0800
Subject: [R-sig-Geo] Processing HDF4 data files with R / GeospatialData
 Abstraction Library (GDAL)
Message-ID: <45BA406D.4050600@nceas.ucsb.edu>

Greetings:

Recently I augmented my installation of R ver 2.4.0 on Dapper Drake Linux
to read data files in Hierarchical Data Format Version 4 (HDF4) format. I
thought that the steps that I took might be useful to other R users who have
not yet had to modify one of the R packages to include a new capability.

Why did I need to have HDF4 support in R?
The rgdal package provides HDF image I/O support is however, the default
rgdal version downloaded from the archives supports only the HDF5 format,
which is not backwards-compatible with HDF4. Many spatial datasets
(for example, SeaWIFS digital ocean color imagery) distributed by
US government agencies are stored in HDF4 format.

Here is the procedure that I worked out:

To include HDF4, you have to download the HDF4 library
and then build a version of the  GDAL library that links
in the HDF4 support.

1) I downloaded and unpacked the hdf4,jpeg6 and szip libraries from:

 ftp.ncsa.uiuc.edu archives: 
/HDF: 4.2.rl-linux.tar.gz
/szip :/szip2.0-linux.noenc.tar.gz
/jpeg6b-linux-gcc3.4.3.tar.gz

  I did not need to build these libraries from source; instead, I just 
extracted
 the archive (.a) files  included with each distribution, and put them 
in a folder
 accessible to the GDAL library  build process. Call this library 
/opt/libs4GDAL
 for this discussion I put the following  files into this folder:
 libdf.a, libjpeg.a, libmfhdf.a, libsz.a,and libz.a

2) I built the GDAL library from source, linkin in the HDF file support.
    to do this: I ran the GDAL 'configure' script included with the distribution
   Note: To get a successful compilation, I had to modify the  configure script
   to include the correct location of the HDF source code include files:
   I added a line : HDF4_INCLUDE="-I/usr/include/hdf" at the place
   where the script tests for the existence of the include/hdf folder.Command
   used to run configure: ./configure --with-hdf4=/opt/libs4GDAL
   This built GDAL 1.4.0 library with HDF4 support

   To test the installation, I ran the GDAL gdalinfo and gdal_translate commands 
   from the command line to read several HDF4 SeaWIFSfiles. This succeeded

3) I started R from the command line, and installed GDAL support using the
    install.packages('rgdal')  command, which builds the library from 
source on
    linux machines.

4)I tested HDF support within R:

   library("rgdal")
   GDALinfo("an.hdf.file")
   hdfImage = readGDAL("an.hdf.file) // hdfImage is SpatialGridDataFrame
   image(hdfImage)   // displays the bitmap.

  These commands correctly read HDF files containing a single spectral
  band; however,  The rgdal routines do not appear to correctly read 
  HDF files containing multiple bands of imagery.
 
 The workaround here is to use the GDAL routines at the command 
 line  to extract the 'included' image planes into individual HDF4 files; 
 as noted above, rgdal routines correctly read the single band images.

Has anyone addressed the issue of processing multiple-band HDF4 files
with R / rgdal?

Cheers,

-- 
Rick Reeves	
Scientific Programmer / Analyst	
National Center for Ecological Analysis and Synthesis
UC Santa Barbara
reeves at nceas.ucsb.edu
www.nceas.ucsb.edu
805 892 2533

-------------- next part --------------
A non-text attachment was scrubbed...
Name: reeves.vcf
Type: text/x-vcard
Size: 339 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20070126/1ccb77ba/attachment.vcf>

From hywelm.jones at talk21.com  Fri Jan 26 22:50:09 2007
From: hywelm.jones at talk21.com (Hywel Jones)
Date: Fri, 26 Jan 2007 21:50:09 +0000 (GMT)
Subject: [R-sig-Geo] Fwd: Variogram in spatial package
Message-ID: <20070126215009.41503.qmail@web86206.mail.ird.yahoo.com>

A resubmission, as no one has replied and I still have
the problem.
--- Hywel Jones <hywelm.jones at talk21.com> wrote:

> Date: Wed, 17 Jan 2007 09:58:10 +0000 (GMT)
> From: Hywel Jones <hywelm.jones at talk21.com>
> Subject: Variogram in spatial package
> To: r-sig-geo at stat.math.ethz.ch
> 
> The help page for variogram in the spatial package
> leaves my slightly uncertain about a few things. I'd
> be grateful for confirmation of my understanding.
> 
> If I fit a trend surface using surf.ls, and then set
> the krig parameter to use that object in the
> variogram
> function, I'm assuming that the variogram produced
> is
> calculated for the residuals contained in the trend
> surface object. Is that right?
> 
> I'm afraid I don't have the references to check the
> following either. Using notation of Cressie, am I
> right in thinking that the y co-ordinate of the
> variogram corresponds to gamma (or 2x gamma)? And x:
> is that h? 
> 
> And then, how does h correspond to my original data?
> i.e. do I interpret it as distance calculated with
> the
> original x and y submitted to surf.ls, or as
> distance
> calculated with the rescaled x and y used within
> surf.ls (I understand that the internals rescale x
> and
> y to -1:1).
> 
> I'd actually like to check for isotropy before using
> this variogram function. Any suggestions as to
> functions I might use?
> 
> Thanks in advance.
> 
> Hywel
> 
> 
> 		
>
___________________________________________________________
> 
> What kind of emailer are you? Find out today - get a
> free analysis of your email personality. Take the
> quiz at the Yahoo! Mail Championship. 
>
http://uk.rd.yahoo.com/evt=44106/*http://mail.yahoo.net/uk
> 
> 



		
___________________________________________________________ 
Inbox full of unwanted email? Get leading protection and 1GB storage with All New Yahoo! Mail. http://uk.docs.yahoo.com/nowyoucan.html



From marco.helbich at gmx.at  Fri Jan 26 22:56:08 2007
From: marco.helbich at gmx.at (Marco Helbich)
Date: Fri, 26 Jan 2007 22:56:08 +0100
Subject: [R-sig-Geo] test the OLS presumption by a GWR model?
Message-ID: <20070126215608.35190@gmx.net>

Dear list members,

i have calculated a GWR model and concerning to this, i have a question: should i test the 'local' gwr output with the standard 'global' test procedures of a OLS model (e.g. Breusch-Pagan-Test)? If yes, which one? 

best regards
Marco
__________________

Marco Helbich
ISR
Postgasse 7/4/2
A-1010, Vienna

-- 
"Feel free" - 5 GB Mailbox, 50 FreeSMS/Monat ...



From paciorek at hsph.harvard.edu  Fri Jan 26 23:09:28 2007
From: paciorek at hsph.harvard.edu (Christopher Paciorek)
Date: Fri, 26 Jan 2007 17:09:28 -0500
Subject: [R-sig-Geo] Fwd: Variogram in spatial package
In-Reply-To: <20070126215009.41503.qmail@web86206.mail.ird.yahoo.com>
References: <20070126215009.41503.qmail@web86206.mail.ird.yahoo.com>
Message-ID: <45BA3526.10CD.002E.0@hsph.harvard.edu>

Hi Hywel,

I'm not familiar with 'spatial' but you might look at the variogram tools in 'geoR'.  This should allow you do look for anisotropy - I believe the function is vario4.

You should be able to check empirically if the variogram is on the residuals by comparing variogram with surf.ls with variogram without surf.ls but based on the residuals that you calculate yourself with lm().

Presumably 'x' is h, and you should be able to figure out the units based on the range of the 'x' axis...
I believe in geoR the output of variogram is labelled 'semivariance' so you can be sure it is gamma and not 2 gamma.
Not sure about variogram from 'spatial'.

 ----------------------------------------------------------------------------------------------
Chris Paciorek / Asst. Professor        Email: paciorek at hsph.harvard.edu
Department of Biostatistics             Voice: 617-432-4912
Harvard School of Public Health         Fax:   617-432-5619
655 Huntington Av., Bldg. 2-407         WWW: www.biostat.harvard.edu/~paciorek
Boston, MA 02115 USA                    Permanent forward: paciorek at alumni.cmu.edu

 
>>> Hywel Jones <hywelm.jones at talk21.com> 01/26/07 4:50 PM >>> 
A resubmission, as no one has replied and I still have
the problem.
---  Hywel Jones <hywelm.jones at talk21.com> wrote:

> Date: Wed, 17 Jan 2007 09:58:10 +0000 (GMT)
> From: Hywel Jones <hywelm.jones at talk21.com>
> Subject: Variogram in spatial package
> To: r- sig- geo at stat.math.ethz.ch
> 
> The help page for variogram in the spatial package
> leaves my slightly uncertain about a few things. I'd
> be grateful for confirmation of my understanding.
> 
> If I fit a trend surface using surf.ls, and then set
> the krig parameter to use that object in the
> variogram
> function, I'm assuming that the variogram produced
> is
> calculated for the residuals contained in the trend
> surface object. Is that right?
> 
> I'm afraid I don't have the references to check the
> following either. Using notation of Cressie, am I
> right in thinking that the y co- ordinate of the
> variogram corresponds to gamma (or 2x gamma)? And x:
> is that h? 
> 
> And then, how does h correspond to my original data?
> i.e. do I interpret it as distance calculated with
> the
> original x and y submitted to surf.ls, or as
> distance
> calculated with the rescaled x and y used within
> surf.ls (I understand that the internals rescale x
> and
> y to - 1:1).
> 
> I'd actually like to check for isotropy before using
> this variogram function. Any suggestions as to
> functions I might use?
> 
> Thanks in advance.
> 
> Hywel
> 
> 
> 		
>
___________________________________________________________
> 
> What kind of emailer are you? Find out today -  get a
> free analysis of your email personality. Take the
> quiz at the Yahoo! Mail Championship. 
>
http://uk.rd.yahoo.com/evt=44106/*http://mail.yahoo.net/uk
> 
> 



		
___________________________________________________________ 
Inbox full of unwanted email? Get leading protection and 1GB storage with All New Yahoo! Mail. http://uk.docs.yahoo.com/nowyoucan.html

_______________________________________________
R- sig- Geo mailing list
R- sig- Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r- sig- geo



From mdsumner at utas.edu.au  Sat Jan 27 04:12:25 2007
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Sat, 27 Jan 2007 14:12:25 +1100
Subject: [R-sig-Geo] Processing HDF4 data files with R /
 GeospatialDataAbstraction Library (GDAL)
Message-ID: <200701270312.l0R3CPG8006099@corinna.its.utas.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20070127/46803cfa/attachment.pl>

From Roger.Bivand at nhh.no  Sat Jan 27 22:06:29 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 27 Jan 2007 22:06:29 +0100 (CET)
Subject: [R-sig-Geo] Fwd: Variogram in spatial package
In-Reply-To: <20070126215009.41503.qmail@web86206.mail.ird.yahoo.com>
Message-ID: <Pine.LNX.4.44.0701272154480.7109-100000@reclus.nhh.no>

On Fri, 26 Jan 2007, Hywel Jones wrote:

> A resubmission, as no one has replied and I still have
> the problem.
> --- Hywel Jones <hywelm.jones at talk21.com> wrote:
> 
> > Date: Wed, 17 Jan 2007 09:58:10 +0000 (GMT)
> > From: Hywel Jones <hywelm.jones at talk21.com>
> > Subject: Variogram in spatial package
> > To: r-sig-geo at stat.math.ethz.ch
> > 
> > The help page for variogram in the spatial package
> > leaves my slightly uncertain about a few things. I'd
> > be grateful for confirmation of my understanding.

The spatial package is described in more detail in Venables, W. N. and
Ripley, B. D. (2002) _Modern Applied Statistics with S._ Fourth edition.  
Springer, as the help page says.

> > 
> > If I fit a trend surface using surf.ls, and then set
> > the krig parameter to use that object in the
> > variogram
> > function, I'm assuming that the variogram produced
> > is
> > calculated for the residuals contained in the trend
> > surface object. Is that right?

Yes, I believe so.

> > 
> > I'm afraid I don't have the references to check the
> > following either. Using notation of Cressie, am I
> > right in thinking that the y co-ordinate of the
> > variogram corresponds to gamma (or 2x gamma)? And x:
> > is that h? 

The documentation is the source code. Alternatively run the same data
through similar functions in the gstat, geoR, or fields packages to
cross-check?  My reading of MASS is that the plot is of the semi-variogram
with distances in the original scaling.

> > 
> > And then, how does h correspond to my original data?
> > i.e. do I interpret it as distance calculated with
> > the
> > original x and y submitted to surf.ls, or as
> > distance
> > calculated with the rescaled x and y used within
> > surf.ls (I understand that the internals rescale x
> > and
> > y to -1:1).
> > 
> > I'd actually like to check for isotropy before using
> > this variogram function. Any suggestions as to
> > functions I might use?

I don't think anisotropy is available in the spatial package, perhaps try 
one of the other packages?

> > 
> > Thanks in advance.
> > 
> > Hywel
> > 
> > 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Sat Jan 27 22:11:53 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 27 Jan 2007 22:11:53 +0100 (CET)
Subject: [R-sig-Geo] test the OLS presumption by a GWR model?
In-Reply-To: <20070126215608.35190@gmx.net>
Message-ID: <Pine.LNX.4.44.0701272207070.7109-100000@reclus.nhh.no>

On Fri, 26 Jan 2007, Marco Helbich wrote:

> Dear list members,
> 
> i have calculated a GWR model and concerning to this, i have a question:
> should i test the 'local' gwr output with the standard 'global' test
> procedures of a OLS model (e.g. Breusch-Pagan-Test)? If yes, which one?

The authors of the GWR book suggest some tests, but since Wheeler & 
Tiefelsdorf (2005) in Journal of Geographical Systems, I would suggest 
that caution in inference from standard (non-Bayesian) GWR is sensible. 
You could do BP tests on each iteration if the tests are well-defined for 
weighted regression. Most tests are however not set up to do this, for 
example bptest in the lmtest package has no weights= argument.

Roger

> 
> best regards
> Marco
> __________________
> 
> Marco Helbich
> ISR
> Postgasse 7/4/2
> A-1010, Vienna
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From mdsumner at utas.edu.au  Mon Jan 29 02:52:35 2007
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Mon, 29 Jan 2007 12:52:35 +1100
Subject: [R-sig-Geo] calculating area
In-Reply-To: <e163468e0701252314v25a54771k219127639a9b82ca@mail.gmail.com>
References: <e163468e0701252314v25a54771k219127639a9b82ca@mail.gmail.com>
Message-ID: <45BD5363.6000104@utas.edu.au>

Pedro S. A. Wolf wrote:
>  I am a psychology student who has been using R to analyze experimental data
> mainly within the general linear model for about 2 years.  I have some
> working knowledge with R, but by no means would call myself proficient so
> bear with me.  Currently I'm running a series of experiments dealing with
> spatial data.  I'm tracking peoples movements using gps units which give me
> latitude, heading, longitude, speed, altitude, and time variables.  I have
> been using the packages "maps" and "mapproj" to plot the routes which these
> individuals take which is a great visualization tool.  I would like to know
> if there is a package or set of commands which would calculate the area
> these people occupy?  So far the closest I have been able to get to
> accomplishing this task is basically taking the max and min for both lat and
> long coordinates and calculating the size of that area, but I would like
> something more accurate.  Another thing I'm trying to accomplish is creating
> what I would call a density map. This is probably not the correct term so
> let me explain what I mean.  I'm trying to characterize how people occupy
> space.  Especially how people visit certain places more than others.  Is
>   

This sounds to me like what marine biologists (seals, penguins, etc.) 
refer to as "time spent", and what seems to be
more generally referred to in terrestrial tracking as a "utilization 
distribution".

We routinely use simple interpolation and grid cell counts to provide a 
simple map of time spent (or diving effort or other foraging-proxy),
and I have functions to perform this for sets of individual tracks in 
the 'trip' package.  Another common method is to use
kernel density to try to smooth over the gaps between location estimates 
in tracks and provided a density
map of time spent - but both linear interpolation and kernel density 
provide only a very simplistic model of the
inferred motion.  

It's fine for a rough first pass, and we often use the count of grids 
cells for comparing different groups - the 'sp' package makes this very 
simple to do.

In terms of calculating area I see it as a matter of choosing the 
appropriate projection for your coordinates, and then defining the
grid of cells to make comparisons between times or groups.

I can provide an example of doing this in the trip package if that would 
help.

Cheers, Mike.



From macq at llnl.gov  Wed Jan 31 16:27:19 2007
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 31 Jan 2007 07:27:19 -0800
Subject: [R-sig-Geo] calculating area
In-Reply-To: <e163468e0701252314v25a54771k219127639a9b82ca@mail.gmail.com>
References: <e163468e0701252314v25a54771k219127639a9b82ca@mail.gmail.com>
Message-ID: <p06230905c1e66286897e@[128.115.153.6]>

At 12:14 AM -0700 1/26/07, Pedro S. A. Wolf wrote:
>  I am a psychology student who has been using R to analyze experimental data
>mainly within the general linear model for about 2 years.  I have some
>working knowledge with R, but by no means would call myself proficient so
>bear with me.  Currently I'm running a series of experiments dealing with
>spatial data.  I'm tracking peoples movements using gps units which give me
>latitude, heading, longitude, speed, altitude, and time variables.  I have
>been using the packages "maps" and "mapproj" to plot the routes which these
>individuals take which is a great visualization tool.  I would like to know
>if there is a package or set of commands which would calculate the area
>these people occupy?  So far the closest I have been able to get to
>accomplishing this task is basically taking the max and min for both lat and
>long coordinates and calculating the size of that area, but I would like
>something more accurate.

In addition to the good advice already sent by others:

A quick and simple improvement would be to get what's called the 
convex hull. See
   help.search('convex hull')
   ?chull
and some others.

The complex hull is a polygon, instead of the rectangle you're now 
using, that will more closely surround your locations. Then all you 
need is a function to calculate the area of a polygon. I know one or 
more exists in R or a package, but I don't recall the name (or names).

>   Another thing I'm trying to accomplish is creating
>what I would call a density map. This is probably not the correct term so
>let me explain what I mean.  I'm trying to characterize how people occupy
>space.  Especially how people visit certain places more than others.  Is
>there a way to create a map which shows the amount of times a particular
>place is visited by these people both within subjects and a second map
>between subjects? Help would be greatly appreciated, as my academic advisors
>know next to nothing about working with this type of data.
>
>Pedro
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at stat.math.ethz.ch
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-Don

-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



