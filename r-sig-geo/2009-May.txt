From chrissy.li at yahoo.com  Fri May  1 06:27:34 2009
From: chrissy.li at yahoo.com (Huizhu "Chrissy" Li)
Date: Thu, 30 Apr 2009 23:27:34 -0500
Subject: [R-sig-Geo] Cost distance analysis
Message-ID: <FF6A0F95D42347438A5CCC4E38C99D68@toshibauser>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090430/413bc42c/attachment.pl>

From regetz at nceas.ucsb.edu  Fri May  1 09:05:33 2009
From: regetz at nceas.ucsb.edu (Jim Regetz)
Date: Fri, 01 May 2009 00:05:33 -0700
Subject: [R-sig-Geo] IDvar argument to readShapeLines
Message-ID: <49FA9F3D.8050007@nceas.ucsb.edu>

I'm curious why the maptools functions readShapeLines and 
readShapePoints don't take an IDvar argument, even though their internal 
counterparts .shp2LinesDF and .Map2SPDF do? It appears only 
readShapePoly supports custom IDs in the wrapper function.

For lines, I realize I can change the FIDs afterwards using spChFIDs(). 
However, I have found that this doesn't scale well, with processing time 
seemingly O(n^2) with the number of features. It would thus be useful to 
be able to set custom IDs when the data is read in, as this is faster.

As an example, I recently used spChFIDs on a SpatialLinesDataFrame with 
~70000 features, and after 90 minutes it still hadn't completed (I gave 
up :). In contrast, I mimicked the internal code of readShapeLines with 
an added tweak to set IDs, and it took only 2.5 minutes to read the data 
and assign the IDs I specified:

library(maptools)
map <- suppressWarnings(read.shape("foo.shp"))
lyr <- suppressWarnings(maptools:::.shp2LinesDF(map,
   IDs=as.character(map$att.data$LABEL)))

Is there any reason why this might be a bad idea, in general?

Incidentally, my ultimate goal is to read in several such largish 
shapefiles (all with identical attributes) and spRbind them. So in fact 
I don't care so much *what* the IDs are, just that they be unique across 
all the layers so that rbind/spRbind will work. Should I be using a 
different approach altogether (sticking with R-based solutions)?

Thanks,
Jim

------------------------------
James Regetz, Ph.D.
Scientific Programmer/Analyst
National Center for Ecological Analysis & Synthesis
735 State St, Ste 300
Santa Barbara, CA 93101


From J.vanEtten at cgiar.org  Fri May  1 09:16:35 2009
From: J.vanEtten at cgiar.org (van Etten, Jacob (IRRI))
Date: Fri, 1 May 2009 15:16:35 +0800
Subject: [R-sig-Geo] Cost distance analysis
In-Reply-To: <FF6A0F95D42347438A5CCC4E38C99D68@toshibauser>
References: <FF6A0F95D42347438A5CCC4E38C99D68@toshibauser>
Message-ID: <AFBF317E3DEC0B43BF750B4618EBFA0D0178EAB5@HERMES>

gdistance, available on R-Forge. It works with raster also available on
R-Forge.

Jacob.

-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Huizhu
"Chrissy" Li
Sent: Friday, May 01, 2009 12:28 PM
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] Cost distance analysis

Dear All,

I am working on a project which involves shortest path, cost distance
analysis. I could not find any package in R that can do this analysis.
Does anyone know which package has related functions?
Thank you in advance!

Chrissy 
	[[alternative HTML version deleted]]


__________________________________________________
8O?lW"2aQE;"3,4sH]A?Cb7QSJOd?

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From milton.ruser at gmail.com  Fri May  1 15:36:03 2009
From: milton.ruser at gmail.com (milton ruser)
Date: Fri, 1 May 2009 09:36:03 -0400
Subject: [R-sig-Geo] Cost distance analysis
In-Reply-To: <FF6A0F95D42347438A5CCC4E38C99D68@toshibauser>
References: <FF6A0F95D42347438A5CCC4E38C99D68@toshibauser>
Message-ID: <3aaf1a030905010636h652b3cdbna957fd83edd2545b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090501/f4af9b47/attachment.pl>

From adam.okulicz.kozaryn at gmail.com  Fri May  1 16:17:33 2009
From: adam.okulicz.kozaryn at gmail.com (Adam Okulicz-Kozaryn)
Date: Fri, 1 May 2009 10:17:33 -0400
Subject: [R-sig-Geo] spdep: stsls; tot.solve=1e-12
In-Reply-To: <alpine.LRH.2.00.0904231316160.27708@reclus.nhh.no>
References: <3c75698d0904221720g7629780cna79cd6b03511841e@mail.gmail.com>
	<alpine.LRH.2.00.0904231316160.27708@reclus.nhh.no>
Message-ID: <3c75698d0905010717j50649e09q3ccb626fd8107e49@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090501/ff6dbfb4/attachment.pl>

From reeves at nceas.ucsb.edu  Fri May  1 18:17:50 2009
From: reeves at nceas.ucsb.edu (rick reeves)
Date: Fri, 01 May 2009 09:17:50 -0700
Subject: [R-sig-Geo] Cost distance analysis
In-Reply-To: <FF6A0F95D42347438A5CCC4E38C99D68@toshibauser>
References: <FF6A0F95D42347438A5CCC4E38C99D68@toshibauser>
Message-ID: <49FB20AE.10106@nceas.ucsb.edu>

Hi Chrissy:

I have had similar needs in the past, so I did some searching: The R 
package e1071 -

 http://cran.r-project.org/web/packages/e1071/index.html

..includes a routine for computing the shortest path distance matrix.

You might start with this package....

Or, the GRASS vector routine v.net.path might work for you.
There is a good data interface between R and GRASS: see the spgrass6 
package.

Rick Reeves


Huizhu "Chrissy" Li wrote:
> Dear All,
>
> I am working on a project which involves shortest path, cost distance analysis. I could not find any package in R that can do this analysis. Does anyone know which package has related functions?
> Thank you in advance!
>
> Chrissy 
> 	[[alternative HTML version deleted]]
>
>
> __________________________________________________
> 8O?lW"2aQE;"3,4sH]A?Cb7QSJOd?
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>   


-- 
Rick Reeves
Scientific Programmer/Analyst and Data Manager
National Center for Ecological Analysis and Synthesis
UC Santa Barbara
www.nceas.ucsb.edu
805 892 2533


From j.burke at earthlink.net  Sun May  3 05:52:36 2009
From: j.burke at earthlink.net (Jim Burke)
Date: Sat, 02 May 2009 22:52:36 -0500
Subject: [R-sig-Geo] How can I convert a "SpatialPolygons" object to a
	"polylist"?
Message-ID: <49FD1504.7060101@earthlink.net>

How can I convert a "SpatialPolygons" object to a "polylist" 

I have a file read in with "readShapePoly". This contains the polygon
long lats in a slot called "coords". I want to use the package "splancs"
"inout" function which works according to the doc with polygon data sets.
An example Map2Poly which works with "inout" lists itself as a class 
"polylist".  

Thanks,
Jim Burke


From j.burke at earthlink.net  Sun May  3 06:07:25 2009
From: j.burke at earthlink.net (Jim Burke)
Date: Sat, 02 May 2009 23:07:25 -0500
Subject: [R-sig-Geo] How can I convert a "SpatialPolygons" object to a
 "polylist"?
In-Reply-To: <49FD1504.7060101@earthlink.net>
References: <49FD1504.7060101@earthlink.net>
Message-ID: <49FD187D.2000706@earthlink.net>

And using shape2poly does not work either.

 >census_poly_sp <- shape2poly(census_sp, region.id = NULL)
Error in shape2poly(census_sp, region.id = NULL) :
  No shp component in this list


The above file was read in (see below). Internal
measurements are in long lats. I can spplot and
make a KML file just fine for example.
census_sp <- readShapePoly("HD_102_census_blocks_sp.shp",
IDvar="BLKIDFP00", proj4string=CRS("+init=epsg:4326"))


Thanks,
Jim Burke



Jim Burke wrote:
> How can I convert a "SpatialPolygons" object to a "polylist"
> I have a file read in with "readShapePoly". This contains the polygon
> long lats in a slot called "coords". I want to use the package "splancs"
> "inout" function which works according to the doc with polygon data sets.
> An example Map2Poly which works with "inout" lists itself as a class 
> "polylist". 
> Thanks,
> Jim Burke
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From gledson.picharski at yahoo.com.br  Sun May  3 16:31:56 2009
From: gledson.picharski at yahoo.com.br (Gledson Picharski)
Date: Sun, 3 May 2009 07:31:56 -0700 (PDT)
Subject: [R-sig-Geo] Res: How can I convert a "SpatialPolygons" object to a
	"polylist"?
In-Reply-To: <49FD187D.2000706@earthlink.net>
References: <49FD1504.7060101@earthlink.net> <49FD187D.2000706@earthlink.net>
Message-ID: <950968.77288.qm@web63104.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090503/d1a50ee5/attachment.pl>

From patrick.giraudoux at univ-fcomte.fr  Sun May  3 19:46:00 2009
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 03 May 2009 19:46:00 +0200
Subject: [R-sig-Geo] R-sig-Geo Digest, Vol 69, Issue 3
In-Reply-To: <mailman.9.1241344803.3388.r-sig-geo@stat.math.ethz.ch>
References: <mailman.9.1241344803.3388.r-sig-geo@stat.math.ethz.ch>
Message-ID: <49FDD858.5060806@univ-fcomte.fr>

>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sat, 02 May 2009 22:52:36 -0500
> From: Jim Burke <j.burke at earthlink.net>
> Subject: [R-sig-Geo] How can I convert a "SpatialPolygons" object to a
> 	"polylist"?
> To: r-sig-geo at stat.math.ethz.ch
> Message-ID: <49FD1504.7060101 at earthlink.net>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> How can I convert a "SpatialPolygons" object to a "polylist" 
>
> I have a file read in with "readShapePoly". This contains the polygon
> long lats in a slot called "coords". I want to use the package "splancs"
> "inout" function which works according to the doc with polygon data sets.
> An example Map2Poly which works with "inout" lists itself as a class 
> "polylist".  
>
> Thanks,
> Jim Burke


if your SpatialPolygons name is e.g. myObject

lapply(myObject at polygons, function(x) x at Polygons[[1]]@coords)

should make it in the very simple case (the most common too anyway) 
where each attribute line corresponds to one single polygon. It will 
provide you with a list whose elements will be the coordinates of each 
polygon.

More complex cases are a bit more difficult to handle

Patrick


From patrick.giraudoux at univ-fcomte.fr  Sun May  3 19:47:33 2009
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 03 May 2009 19:47:33 +0200
Subject: [R-sig-Geo] How can I convert a "SpatialPolygons" object,
 to a "polylist"?
In-Reply-To: <mailman.9.1241344803.3388.r-sig-geo@stat.math.ethz.ch>
References: <mailman.9.1241344803.3388.r-sig-geo@stat.math.ethz.ch>
Message-ID: <49FDD8B5.4030102@univ-fcomte.fr>

>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sat, 02 May 2009 22:52:36 -0500
> From: Jim Burke <j.burke at earthlink.net>
> Subject: [R-sig-Geo] How can I convert a "SpatialPolygons" object to a
> 	"polylist"?
> To: r-sig-geo at stat.math.ethz.ch
> Message-ID: <49FD1504.7060101 at earthlink.net>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> How can I convert a "SpatialPolygons" object to a "polylist" 
>
> I have a file read in with "readShapePoly". This contains the polygon
> long lats in a slot called "coords". I want to use the package "splancs"
> "inout" function which works according to the doc with polygon data sets.
> An example Map2Poly which works with "inout" lists itself as a class 
> "polylist".  
>
> Thanks,
> Jim Burke


if your SpatialPolygons name is e.g. myObject

lapply(myObject at polygons, function(x) x at Polygons[[1]]@coords)

should make it in the very simple case (the most common too anyway)
where each attribute line corresponds to one single polygon. It will
provide you with a list whose elements will be the coordinates of each
polygon.

More complex cases are a bit more difficult to handle

Patrick


From Adrian.Baddeley at csiro.au  Mon May  4 03:17:46 2009
From: Adrian.Baddeley at csiro.au (Adrian.Baddeley at csiro.au)
Date: Mon, 4 May 2009 09:17:46 +0800
Subject: [R-sig-Geo] Characterizing the position (central vs peripheral) of
 a point in a point pattern
Message-ID: <57DC18C299094D4299F837570C5DF1C5029DF2DA79@EXWA-MBX01.nexus.csiro.au>

Alexandre VILLERS alexandre.villers at cebc.cnrs.fr<mailto:alexandre.villers at cebc.cnrs.fr> wrote:
> I would like to characterize the position of  a given nest in a
> population of breeding birds. Does anyone know a statisitics (and
> associated R package) that could objectively tell whether a nest has a
> central or peripheral location ? It also needs to be density independent
> (not affected by sample size)

There are many ways of doing this. A pivotal question is: what do you want to happen
in the situation where the majority of birds cluster around the edge of the spatial domain,
or where the majority of bords cluster in the middle of the domain.
For example, suppose most birds prefer to nest close to the edge of a rocky island. Where should we draw the 50/50 line (i.e. where nests are neither central nor peripheral)? Is it (a)  through the middle of the island, halfway between the centre and the periphery of the rookery? or (b) through the middle of the population, with 50% of the nests on one side and 50% on the other side?

If the answer is (a) then you could simply measure distances. In the 'spatstat' package for example, if X is a point pattern of birds' nests,
               B <- ripras(X)
               C <- centroid.owin(B)
               DB <- distmap(as.psp(B))
               DC <- distmap(as.ppp(C, B))
               value <- DC[X]/(DC[X] + DB[X])
Then 'value' is a fraction that equals 0 at the centroid, 1 at the boundary, and 0.5 halfway between.

If the answer is (b) then you probably need to use quantiles of the distances.

               B <- ripras(X)
               DB <- distmap(as.psp(B))
               value <- rank(DB[X])/X$n

then 'value' is a fraction that approaches 1 for nests close to the boundary, approaches 0 for nests furthest from the boundary, and 0.5 for a nest which is closer to the boundary than 50% of the other nests, and further from the boundary than 50% of other nests.

Adrian Baddeley


From alexandre.villers at cebc.cnrs.fr  Mon May  4 15:06:10 2009
From: alexandre.villers at cebc.cnrs.fr (Alexandre VILLERS)
Date: Mon, 04 May 2009 15:06:10 +0200
Subject: [R-sig-Geo] converting raster into grid shapefile
Message-ID: <49FEE842.5000402@cebc.cnrs.fr>

Hello,

I'm currently working on MODIS data. The aim is to identify through 
spectral varitions across time crop type on a large region.
For that purpose, I have the type of crop on all plots of a 500 squared 
km study area (plot locations with a max of 10 m error) as a ESRI shapefile.
I already converted MODIS data as geotif for each spectral band of 
interest with the MODIS reprojection tool (see 
http://spatial-analyst.net/wiki/index.php?title=Download_and_resampling_of_MODIS_images 
for more details). I would like to get the % of each crop under each 
pixel (250 m wide) of the raster data for further analysis.
I would know how to do that with ArcGis, given an appropriate grid 
shapefile fitted on the raster. I would so be able (I hope) to work with 
grid number to isolate the ones of interest.
Does anyone see how to create such a grid shapefile, or better, to run 
the whole stuff with R ?

Best regards

Alex

-- 

Alexandre Villers
PhD Student
Team "Biodiversity"
Centre d'Etudes Biologiques de Chiz?-CNRS UPR1934
79360 Beauvoir sur Niort

Phone +33 (0)5 49 09 96 13
Fax   +33 (0)5 49 09 65 26




__________ Information from ESET Mail Security, version of virus signature database 4051 (20090504) __________

The message was checked by ESET Mail Security.
http://www.eset.com


From baenni at kiecks.de  Mon May  4 23:45:15 2009
From: baenni at kiecks.de (dominik baenninger)
Date: Mon, 04 May 2009 23:45:15 +0200
Subject: [R-sig-Geo] Large PDF files when using tiff raster images as
	background
Message-ID: <49FF61EB.7010102@kiecks.de>

Dear list,

When plotting spatial informaion it is common to use a pixel map as 
background. Therefore I used the following commands (in brief)

library(sp)
library(rgdal)

pdf()
readGDAL(geotiff-file)
image()
plot(...,add=T)
dev.off()

This works fine, however, the original tiff file has a size of about 
600kb, the pdf 20MB even I do not add  any further information. Since I 
like to add point and line information with the plot command I would 
like to generate some kind of vecotrbased graphics. Any idea how I can 
the geotiff-background without producing large files?

Thanks for any hint in advance.


From Roger.Bivand at nhh.no  Tue May  5 09:36:00 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 5 May 2009 09:36:00 +0200 (CEST)
Subject: [R-sig-Geo] Large PDF files when using tiff raster images as
 background
In-Reply-To: <49FF61EB.7010102@kiecks.de>
References: <49FF61EB.7010102@kiecks.de>
Message-ID: <alpine.LRH.2.00.0905050925160.1959@reclus.nhh.no>

On Mon, 4 May 2009, dominik baenninger wrote:

> Dear list,
>
> When plotting spatial informaion it is common to use a pixel map as 
> background. Therefore I used the following commands (in brief)
>
> library(sp)
> library(rgdal)
>
> pdf()
> readGDAL(geotiff-file)
> image()
> plot(...,add=T)
> dev.off()
>
> This works fine, however, the original tiff file has a size of about 600kb, 
> the pdf 20MB even I do not add  any further information.

You have (at least) two choices - making the choice depends on which 
output graphics device you want to use. All R graphics draw raster cells 
as filled rectangles, so that on a PDF you will get many filled 
rectangles, hence the size of the output file. To reduce the size, 
decimate the raster with the output.dim= argument in readGDAL - you lose 
resolution, but reduce the number of filled rectangles.

An alternative is to use a bitmapped device such as png(), possibly trying 
to set the width and height to suit the raster object - see GE_SpatialGrid 
in maptools for examples of the manipulations needed for making Google 
Earth PNG image overlays. A compressed bitmapped device will yield an 
image not dissimilar to the input raster in size.

Hope this helps,

Roger

> Since I like to add point and line information with the plot command I 
> would like to generate some kind of vecotrbased graphics. Any idea how I 
> can the geotiff-background without producing large files?
>
> Thanks for any hint in advance.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From david.march at uib.es  Tue May  5 09:57:39 2009
From: david.march at uib.es (=?ISO-8859-1?Q?David_March_Morl=E0?=)
Date: Tue, 05 May 2009 09:57:39 +0200
Subject: [R-sig-Geo] index of eccentricity
Message-ID: <49FFF173.7040907@uib.es>

Dear list,

I would like to calculate an index of eccentricity (ECC) of an animal's 
home range (a polygon determined with adehabitat package and then 
exported as shapefile). ECC=l/w, where 'l' is the maximum lenght of the 
polygon, and 'w' is the maximum width of the polygon. Could you 
suggestme any package that implements this function or that could help 
me to compute 'l' and 'w'?
Thank you,

-- 
David March Morl?
Doctorando / PhD candidate
Fisheries-GIS specialist
Instituto Mediterraneo de Estudios Avanzados (UIB-CSIC)
C/Miquel Marqu?s, 21
07190 Esporles
Islas Baleares - Spain
Tel: +34 971 610 896
Fax: +34 971 611 761
Email: david.march at uib.es


From alobolistas at gmail.com  Tue May  5 13:10:25 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 05 May 2009 13:10:25 +0200
Subject: [R-sig-Geo] spplot: no boundary lines for polygons
Message-ID: <4A001EA1.1060308@gmail.com>

I have a complex shape file imported to R via rgdal
as a SPolDF. I want to display continuous attributes
with a color key but the black boundaries
of the polygons, which are small in general, introduce
"too much black" in the plot and the spatial variation
of the attribute is not correctly displayed.

What I do is
spplot(MMAMBCGUcombi["DIFPW"])

(BTW, where is the code for fig. 3.6 in the book? Perhaps I should be
using plot() instead of spplot(), but cannot find how to select
the actual atribute in the SPolDF in plot())

Is there any way of not plotting the boundaries of the polygons?

Thanks

Agus


-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster


-------------- next part --------------
A non-text attachment was scrubbed...
Name: alobolistas.vcf
Type: text/x-vcard
Size: 251 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090505/90e5e2ba/attachment.vcf>

From Roger.Bivand at nhh.no  Tue May  5 15:46:10 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 5 May 2009 15:46:10 +0200 (CEST)
Subject: [R-sig-Geo] spplot: no boundary lines for polygons
In-Reply-To: <4A001EA1.1060308@gmail.com>
References: <4A001EA1.1060308@gmail.com>
Message-ID: <alpine.LRH.2.00.0905051526280.2656@reclus.nhh.no>

On Tue, 5 May 2009, Agustin Lobo wrote:

> I have a complex shape file imported to R via rgdal
> as a SPolDF. I want to display continuous attributes
> with a color key but the black boundaries
> of the polygons, which are small in general, introduce
> "too much black" in the plot and the spatial variation
> of the attribute is not correctly displayed.
>
> What I do is
> spplot(MMAMBCGUcombi["DIFPW"])

Yes, pass through the col="transparent" argument to the gpar() argument 
gp= in the underlying grid.polygon() function used.

>
> (BTW, where is the code for fig. 3.6 in the book? Perhaps I should be
> using plot() instead of spplot(), but cannot find how to select
> the actual atribute in the SPolDF in plot())

I think that the code is shown under the Figures menu, where you also find 
the reference to its placing in chunk 22 in vis_mod.R

>
> Is there any way of not plotting the boundaries of the polygons?
>

fortune("Yoda")

Roger

> Thanks
>
> Agus
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From alobolistas at gmail.com  Tue May  5 16:19:53 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 05 May 2009 16:19:53 +0200
Subject: [R-sig-Geo] readRAST6: too many open files
Message-ID: <4A004B09.7040006@gmail.com>

We're using
rastdum <- readRAST6("nomdum",cat=F,ignore.stderr = T)

(on a ubuntu 8.10 machine and R 2.9)
within a for() loop of hundreds of iterations.

At some point (ca. 199) we get an error
"Too many open files"

and suspect that this is because readRAST6() is opening
and not closing files. Is this a bug? I remember having
a similar problem with writeGDAL() on a win machine a long ago,
but that problem was fixed.

Thanks

Agus

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster
-------------- next part --------------
A non-text attachment was scrubbed...
Name: alobolistas.vcf
Type: text/x-vcard
Size: 251 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090505/433fbde5/attachment.vcf>

From Roger.Bivand at nhh.no  Tue May  5 17:04:13 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 5 May 2009 17:04:13 +0200 (CEST)
Subject: [R-sig-Geo] readRAST6: too many open files
In-Reply-To: <4A004B09.7040006@gmail.com>
References: <4A004B09.7040006@gmail.com>
Message-ID: <alpine.LRH.2.00.0905051639410.2950@reclus.nhh.no>

On Tue, 5 May 2009, Agustin Lobo wrote:

> We're using
> rastdum <- readRAST6("nomdum",cat=F,ignore.stderr = T)
>
> (on a ubuntu 8.10 machine and R 2.9)
> within a for() loop of hundreds of iterations.
>
> At some point (ca. 199) we get an error
> "Too many open files"
>
> and suspect that this is because readRAST6() is opening
> and not closing files. Is this a bug?

Possibly, but a complete sessionInfo() would be necessary - the versions 
of the packages involved may matter. Does this reproduce with readRAST6() 
in a loop reading say the same raster? I've run 300 reads of spearfish 
elevation.dem without seeing problems for:

> sessionInfo()
R version 2.9.0 (2009-04-17)
i386-pc-mingw32

locale:
LC_COLLATE=Norwegian (Bokm?l)_Norway.1252;LC_CTYPE=Norwegian 
(Bokm?l)_Norway.1252;LC_MONETARY=Norwegian 
(Bokm?l)_Norway.1252;LC_NUMERIC=C;LC_TIME=Norwegian (Bokm?l)_Norway.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] spgrass6_0.6-5 XML_2.3-0      rgdal_0.6-8    sp_0.9-36

loaded via a namespace (and not attached):
[1] grid_2.9.0      lattice_0.17-22

Roger

> I remember having
> a similar problem with writeGDAL() on a win machine a long ago,
> but that problem was fixed.
>
> Thanks
>
> Agus
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From alinashe at gmail.com  Tue May  5 17:16:29 2009
From: alinashe at gmail.com (Alina Sheyman)
Date: Tue, 5 May 2009 10:16:29 -0500
Subject: [R-sig-Geo] unique spatial polygons
In-Reply-To: <alpine.LRH.2.00.0904291918400.30188@reclus.nhh.no>
References: <f58db2700904281347q11449bcdl26571eb80aa6030c@mail.gmail.com>
	<alpine.LRH.2.00.0904290825150.30188@reclus.nhh.no>
	<f58db2700904290911r7a5ffe4ct4ed83ff16b1fca2c@mail.gmail.com>
	<alpine.LRH.2.00.0904291918400.30188@reclus.nhh.no>
Message-ID: <f58db2700905050816l6349c662oc2853e047130d2b4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090505/6a0bed53/attachment.pl>

From alobolistas at gmail.com  Tue May  5 17:18:36 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 05 May 2009 17:18:36 +0200
Subject: [R-sig-Geo] readRAST6: too many open files
In-Reply-To: <alpine.LRH.2.00.0905051639410.2950@reclus.nhh.no>
References: <4A004B09.7040006@gmail.com>
	<alpine.LRH.2.00.0905051639410.2950@reclus.nhh.no>
Message-ID: <4A0058CC.30108@gmail.com>

Here it is:

R version 2.9.0 (2009-04-17)
i486-pc-linux-gnu

locale:
LC_CTYPE=es_ES.UTF-8;LC_NUMERIC=C;LC_TIME=es_ES.UTF-8;LC_COLLATE=es_ES.UTF-8;LC_MONETARY=C;LC_MESSAGES=es_ES.UTF-8;LC_PAPER=es_ES.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=es_ES.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base    

other attached packages:
[1] spgrass6_0.6-4 XML_1.95-3     rgdal_0.6-7    sp_0.9-34    

loaded via a namespace (and not attached):
[1] grid_2.9.0      lattice_0.17-22


We are upgrading to match your versions, will retry and let you know

Agus

Roger Bivand wrote:
> On Tue, 5 May 2009, Agustin Lobo wrote:
>
>> We're using
>> rastdum <- readRAST6("nomdum",cat=F,ignore.stderr = T)
>>
>> (on a ubuntu 8.10 machine and R 2.9)
>> within a for() loop of hundreds of iterations.
>>
>> At some point (ca. 199) we get an error
>> "Too many open files"
>>
>> and suspect that this is because readRAST6() is opening
>> and not closing files. Is this a bug?
>
> Possibly, but a complete sessionInfo() would be necessary - the 
> versions of the packages involved may matter. Does this reproduce with 
> readRAST6() in a loop reading say the same raster? I've run 300 reads 
> of spearfish elevation.dem without seeing problems for:
>
>> sessionInfo()
> R version 2.9.0 (2009-04-17)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=Norwegian (Bokm?l)_Norway.1252;LC_CTYPE=Norwegian 
> (Bokm?l)_Norway.1252;LC_MONETARY=Norwegian 
> (Bokm?l)_Norway.1252;LC_NUMERIC=C;LC_TIME=Norwegian (Bokm?l)_Norway.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] spgrass6_0.6-5 XML_2.3-0      rgdal_0.6-8    sp_0.9-36
>
> loaded via a namespace (and not attached):
> [1] grid_2.9.0      lattice_0.17-22
>
> Roger
>
>> I remember having
>> a similar problem with writeGDAL() on a win machine a long ago,
>> but that problem was fixed.
>>
>> Thanks
>>
>> Agus
>>
>>
>
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-------------- next part --------------
A non-text attachment was scrubbed...
Name: alobolistas.vcf
Type: text/x-vcard
Size: 251 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090505/5975ab65/attachment.vcf>

From Roger.Bivand at nhh.no  Tue May  5 17:30:06 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 5 May 2009 17:30:06 +0200 (CEST)
Subject: [R-sig-Geo] readRAST6: too many open files
In-Reply-To: <4A0058CC.30108@gmail.com>
References: <4A004B09.7040006@gmail.com>
	<alpine.LRH.2.00.0905051639410.2950@reclus.nhh.no>
	<4A0058CC.30108@gmail.com>
Message-ID: <alpine.LRH.2.00.0905051728070.3146@reclus.nhh.no>

On Tue, 5 May 2009, Agustin Lobo wrote:

> Here it is:
>
> R version 2.9.0 (2009-04-17)
> i486-pc-linux-gnu
>
> locale:
> LC_CTYPE=es_ES.UTF-8;LC_NUMERIC=C;LC_TIME=es_ES.UTF-8;LC_COLLATE=es_ES.UTF-8;LC_MONETARY=C;LC_MESSAGES=es_ES.UTF-8;LC_PAPER=es_ES.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=es_ES.UTF-8;LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base 
> other attached packages:
> [1] spgrass6_0.6-4 XML_1.95-3     rgdal_0.6-7    sp_0.9-34 
> loaded via a namespace (and not attached):
> [1] grid_2.9.0      lattice_0.17-22
>
>
> We are upgrading to match your versions, will retry and let you know

Is it possible that this only happens with the default plugin=NULL 
argument to readRAST6(), and you have a GRASS GDAL plugin, so it gets 
auto-found and used? Does it still happen when plugin=FALSE?

Roger

>
> Agus
>
> Roger Bivand wrote:
>> On Tue, 5 May 2009, Agustin Lobo wrote:
>> 
>>> We're using
>>> rastdum <- readRAST6("nomdum",cat=F,ignore.stderr = T)
>>> 
>>> (on a ubuntu 8.10 machine and R 2.9)
>>> within a for() loop of hundreds of iterations.
>>> 
>>> At some point (ca. 199) we get an error
>>> "Too many open files"
>>> 
>>> and suspect that this is because readRAST6() is opening
>>> and not closing files. Is this a bug?
>> 
>> Possibly, but a complete sessionInfo() would be necessary - the versions of 
>> the packages involved may matter. Does this reproduce with readRAST6() in a 
>> loop reading say the same raster? I've run 300 reads of spearfish 
>> elevation.dem without seeing problems for:
>> 
>>> sessionInfo()
>> R version 2.9.0 (2009-04-17)
>> i386-pc-mingw32
>> 
>> locale:
>> LC_COLLATE=Norwegian (Bokm?l)_Norway.1252;LC_CTYPE=Norwegian 
>> (Bokm?l)_Norway.1252;LC_MONETARY=Norwegian 
>> (Bokm?l)_Norway.1252;LC_NUMERIC=C;LC_TIME=Norwegian (Bokm?l)_Norway.1252
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> other attached packages:
>> [1] spgrass6_0.6-5 XML_2.3-0      rgdal_0.6-8    sp_0.9-36
>> 
>> loaded via a namespace (and not attached):
>> [1] grid_2.9.0      lattice_0.17-22
>> 
>> Roger
>> 
>>> I remember having
>>> a similar problem with writeGDAL() on a win machine a long ago,
>>> but that problem was fixed.
>>> 
>>> Thanks
>>> 
>>> Agus
>>> 
>>> 
>> 
>> ------------------------------------------------------------------------
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From alinashe at gmail.com  Tue May  5 17:52:46 2009
From: alinashe at gmail.com (Alina Sheyman)
Date: Tue, 5 May 2009 10:52:46 -0500
Subject: [R-sig-Geo] unique spatial polygons
In-Reply-To: <f58db2700905050816l6349c662oc2853e047130d2b4@mail.gmail.com>
References: <f58db2700904281347q11449bcdl26571eb80aa6030c@mail.gmail.com>
	<alpine.LRH.2.00.0904290825150.30188@reclus.nhh.no>
	<f58db2700904290911r7a5ffe4ct4ed83ff16b1fca2c@mail.gmail.com>
	<alpine.LRH.2.00.0904291918400.30188@reclus.nhh.no>
	<f58db2700905050816l6349c662oc2853e047130d2b4@mail.gmail.com>
Message-ID: <f58db2700905050852v366526ach7311dbb10ec380e3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090505/eaea56c4/attachment.pl>

From Roger.Bivand at nhh.no  Tue May  5 18:29:26 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 5 May 2009 18:29:26 +0200 (CEST)
Subject: [R-sig-Geo] unique spatial polygons
In-Reply-To: <f58db2700905050852v366526ach7311dbb10ec380e3@mail.gmail.com>
References: <f58db2700904281347q11449bcdl26571eb80aa6030c@mail.gmail.com>
	<alpine.LRH.2.00.0904290825150.30188@reclus.nhh.no>
	<f58db2700904290911r7a5ffe4ct4ed83ff16b1fca2c@mail.gmail.com>
	<alpine.LRH.2.00.0904291918400.30188@reclus.nhh.no> 
	<f58db2700905050816l6349c662oc2853e047130d2b4@mail.gmail.com>
	<f58db2700905050852v366526ach7311dbb10ec380e3@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0905051820080.7655@reclus.nhh.no>

On Tue, 5 May 2009, Alina Sheyman wrote:

> and for some reason I am still getting the error that I have non-unique id's
> eventhough i had deduped both of my files. Any idea why this would be
> happening?

Please refer to comments below:

>
> On Tue, May 5, 2009 at 10:16 AM, Alina Sheyman <alinashe at gmail.com> wrote:
>
>>
>> I'm still working on trying to combine two spatial files.
>> So far I've done the following
>>
>> zipmaps1a<- unionSpatialPolygons(zipmaps1,IDs=paste(zipmaps1$ZCTA))
>> zipmaps1_df<- as(zipmaps1, "data.frame") [!duplicated(zipmaps1$ZCTA),
>> -(1:4)]
>> row.names(zipmaps1_df)<- paste(zipmaps1_df$ZCTA)
>> zipmaps1b <- SpatialPolygonsDataFrame(zipmaps1a,zipmaps1_df)
>>
>> zipmaps2a<- unionSpatialPolygons(zipmaps2,IDs=paste(zipmaps2$ZCTA))
>> zipmaps2_df<- as(zipmaps2, "data.frame") [!duplicated(zipmaps2$ZCTA),
>> -(1:4)]
>> row.names(zipmaps2_df)<- paste(zipmaps2_df$ZCTA)
>> zipmaps2b <- SpatialPolygonsDataFrame(zipmaps2a,zipmaps2_df)
>>
>> I've checked both of my files and at this point they DO both contain unique
>> id's - no duplicate records. However when I try to go ahead and combine them
>> using
>>
>> zipmaps_1_2 <- spRbind(spRbind(zipmaps1b, zipmaps1a))
>>
                   ^^^^^^^^^^^^^^^

Maybe I'm seeing double, but there do seem to be two spRbind() calls here. 
Are they really here, or an artefact of copy&paste? I cannot reproduce the 
problem. In addition, why are you using paste() on zipmaps2$ZCTA etc. in 
the unionSpatialPolygons() calls - shouldn't you use as.character()? have 
you examined the SpatialPolygons object IDs as I've suggested earlier?

(hint sapply(slot(zipmaps1a, "polygons"), slot, "ID"))

Do you have a local source of help, you do not seem to be making progress?

Roger

>> I get the following error message
>> Error in spRbind(spRbind(zipmaps1b, zipmaps1a)) :
>>   error in evaluating the argument 'obj' in selecting a method for function
>> 'spRbind'
>>
>> I'm not sure what else I need to specify in my spRbind command
>>
>>
>>
>> On Wed, Apr 29, 2009 at 12:32 PM, Roger Bivand <Roger.Bivand at nhh.no>wrote:
>>
>>> On Wed, 29 Apr 2009, Alina Sheyman wrote:
>>>
>>>  Using examples in Chapter 5, I am trying to get rid of non-unique
>>>> polygons.
>>>>
>>>
>>> Actually, maybe my advice wasn't well-judged, unless you are happy to
>>> interpret code in a fairly naked setting, you may actually need the book
>>> text to see what is going on. The code treats a number of different issues,
>>> not all of which are necessarily relevant for your case.
>>>
>>>  I'm working with a Massachusetts shapefile by zips. The file consists the
>>>> following fields
>>>> ZCTA  NAME LSAD   LSAD_TRANS
>>>>
>>>> I've done the following  to get rid of duplicate records
>>>>
>>>>  zipmaps1_df <- as(zipmaps1,
>>>>> "data.frame")[!duplicated(zipmaps1$LSAT_TRANS)]
>>>>>
>>>> # not LSAD_TRANS?
>>>
>>>> row.names(zipmaps1_df) <- zipmaps1_df$LSAD_TRANS
>>>>> zipmaps1a <- SpatialPolygonsDataFrame(zipmaps1, zipmaps1_df) ,
>>>>>
>>>>
>>>>
>>> I guess that you need all of the features (geometries) in zipmaps1, but
>>> that some zipcodes have several features. Don't discard geometries unless
>>> you know that that is what you really want to do. Even if they are not
>>> contiguous, use:
>>>
>>> zipmaps1u <- unionSpatialPolygons(as(zipmaps1, "SpatialPolygons"),
>>>  as.character(zipmaps1$LSAD_TRANS))
>>>
>>> to group all of the features belonging to each value of LSAD_TRANS as
>>> Polygon objects in unique Polygons objects (with multiple features).
>>>
>>> The output (re. your next mail) is a SpatialPolygons object. How you then
>>> aggregate the data.frame part of the input object is up to you. The ID
>>> values of the Polygons objects in zipmaps1u will be the unique values of
>>> LSAD_TRANS. Unless you need to work with attribute data, you could stay just
>>> with SpatialPolygons objects until you are through.
>>>
>>>  but get the following error message
>>>> Error in SpatialPolygonsDataFrame(zipmaps1, zipmaps1_df) :
>>>>  row.names of data and Polygons IDs do not match
>>>>
>>>>
>>>> How do I find out what field R is treating as Polygon ID, so that I can
>>>> set
>>>> my row.names to that?
>>>>
>>>
>>> If you need it later on, you could look at spChFIDs as I suggested before.
>>>
>>> Hope this helps,
>>>
>>> Roger
>>>
>>>
>>>
>>>>
>>>> On Wed, Apr 29, 2009 at 2:42 AM, Roger Bivand <Roger.Bivand at nhh.no>
>>>> wrote:
>>>>
>>>>  On Tue, 28 Apr 2009, Alina Sheyman wrote:
>>>>>
>>>>>  I'm trying to combine two shapefiles using
>>>>>
>>>>>> zipmaps5 <- spRbind(zipmaps1,zipmaps2)
>>>>>>
>>>>>> and getting the following error message
>>>>>> Error in spRbind(as(obj, "SpatialPolygons"), as(x, "SpatialPolygons"))
>>>>>> :
>>>>>>  non-unique polygon IDs
>>>>>>
>>>>>> Does anyone know how I can get rid of duplicate polygons in a
>>>>>> shapefile?
>>>>>>
>>>>>>
>>>>> This isn't the problem. The real problem is that zipmaps1 and zipmaps2
>>>>> have
>>>>> non-unique polygon IDs, so that it isn't obvious to the function what
>>>>> you
>>>>> want to do. By default:
>>>>>
>>>>> sapply(slot(zipmaps1, "polygons"), slot, "ID")
>>>>>
>>>>> is set to the FID of the shapefile in readOGR() and equivalently in
>>>>> readShapeSpatial() in maptools. These typically run 0:(n-1). For two
>>>>> objects, they obviously overlap. Please use spChFIDs() methods in
>>>>> maptools
>>>>> to assign IDs that are unique for the output object; in the worst case:
>>>>>
>>>>> zipmaps1 <- spChFIDs(zipmaps1, paste("map1", sapply(slot(zipmaps1,
>>>>>  "polygons"), slot, "ID"), sep="_"))
>>>>>
>>>>> and a different "map*" string for zipmaps2 will work, but a unique,
>>>>> meaningful ID is best.
>>>>>
>>>>> This is covered in detail in the code examples for Chapter 5 in our
>>>>> book,
>>>>> and on the help page for ?"spChFIDs-methods".
>>>>>
>>>>> Hope this helps,
>>>>>
>>>>> Roger
>>>>>
>>>>>
>>>>>  thank you!
>>>>>>
>>>>>>       [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>
>>>>>>
>>>>>>  --
>>>>> Roger Bivand
>>>>> Economic Geography Section, Department of Economics, Norwegian School of
>>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>
>>>>>
>>>>>
>>>>
>>> --
>>> Roger Bivand
>>> Economic Geography Section, Department of Economics, Norwegian School of
>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From alobolistas at gmail.com  Tue May  5 19:02:00 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 05 May 2009 19:02:00 +0200
Subject: [R-sig-Geo] readRAST6: too many open files
In-Reply-To: <alpine.LRH.2.00.0905051728070.3146@reclus.nhh.no>
References: <4A004B09.7040006@gmail.com>
	<alpine.LRH.2.00.0905051639410.2950@reclus.nhh.no>
	<4A0058CC.30108@gmail.com>
	<alpine.LRH.2.00.0905051728070.3146@reclus.nhh.no>
Message-ID: <4A007108.6040002@gmail.com>

Roger,

After upgrading, the test works with plugin=F,
while plugin=T produces the same result.

Also, ignore.stderr=T yields:

ERROR 6: SetColorTable() only supported for Byte or UInt16 bands in TIFF 
format.
WARNING: Input raster map constains cells with NULL-value (no-data). The
          value 999 was used to represent no-data values in the input
          map.You can specify nodata value by nodata parameter.
/media/Transcend/Montseny/GrassData//carlos/A_TOTAL/.tmp/caminoccg/nomdum 
has GDAL driver GTiff
and has 94 rows and 116 columns

which is not including any more the first lines that we had with the 
previous version:

raster map/current region mismatch detected in components:
            cols            rows origin.northing  origin.easting
            TRUE            TRUE           FALSE            TRUE
set plugin=TRUE to override; continuing with plugin=FALSE

Now we have:

 > sessionInfo()
R version 2.9.0 (2009-04-17)
i486-pc-linux-gnu

locale:
LC_CTYPE=es_ES.UTF-8;LC_NUMERIC=C;LC_TIME=es_ES.UTF-8;LC_COLLATE=es_ES.UTF-8;LC_MONETARY=C;LC_MESSAGES=es_ES.UTF-8;LC_PAPER=es_ES.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=es_ES.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] spgrass6_0.6-4 XML_1.95-3     rgdal_0.6-7    sp_0.9-36

loaded via a namespace (and not attached):
[1] grid_2.9.0      lattice_0.17-22
 >

We are trying now with our process, that takes much longer than the 
test, we'll let you know.

Thanks!

Agus


-------------- next part --------------
A non-text attachment was scrubbed...
Name: alobolistas.vcf
Type: text/x-vcard
Size: 251 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090505/fd026f53/attachment.vcf>

From Roger.Bivand at nhh.no  Tue May  5 19:13:52 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 5 May 2009 19:13:52 +0200 (CEST)
Subject: [R-sig-Geo] readRAST6: too many open files
In-Reply-To: <4A007108.6040002@gmail.com>
References: <4A004B09.7040006@gmail.com>
	<alpine.LRH.2.00.0905051639410.2950@reclus.nhh.no>
	<4A0058CC.30108@gmail.com>
	<alpine.LRH.2.00.0905051728070.3146@reclus.nhh.no>
	<4A007108.6040002@gmail.com>
Message-ID: <alpine.LRH.2.00.0905051905530.7655@reclus.nhh.no>

On Tue, 5 May 2009, Agustin Lobo wrote:

> Roger,
>
> After upgrading, the test works with plugin=F,
> while plugin=T produces the same result.
>

I find this too on Fedora 10, plugin=TRUE fails after a hundred or so 
calls, and then crashes R on a further command. With plugin=FALSE, there 
is no problem at all. The problem then lies in the plugin driver, which 
isn't anything that spgrass6 can do anything about. It looks as though the 
plugin is opening file handles to GRASS files but not closing them. I'll 
try to ask on the GDAL and grass-dev lists. For the time being, it seems 
best to use plugin=FALSE in readRAST6().

> Also, ignore.stderr=T yields:
>
> ERROR 6: SetColorTable() only supported for Byte or UInt16 bands in TIFF 
> format.

This is a GRASS version issue, more recent GRASS support a flag to avoid 
r.out.gdal trying to write non-existent colour tables. Could you repeat 
your GRASS version:

execGRASS("g.version")

should do it.

> WARNING: Input raster map constains cells with NULL-value (no-data). The
>         value 999 was used to represent no-data values in the input
>         map.You can specify nodata value by nodata parameter.

Maybe set a NODATA= value in the readRAST6() call to avoid heuristics 
trying to find a possible value?

Roger

> /media/Transcend/Montseny/GrassData//carlos/A_TOTAL/.tmp/caminoccg/nomdum has 
> GDAL driver GTiff
> and has 94 rows and 116 columns
>
> which is not including any more the first lines that we had with the previous 
> version:
>
> raster map/current region mismatch detected in components:
>           cols            rows origin.northing  origin.easting
>           TRUE            TRUE           FALSE            TRUE
> set plugin=TRUE to override; continuing with plugin=FALSE
>
> Now we have:
>
>> sessionInfo()
> R version 2.9.0 (2009-04-17)
> i486-pc-linux-gnu
>
> locale:
> LC_CTYPE=es_ES.UTF-8;LC_NUMERIC=C;LC_TIME=es_ES.UTF-8;LC_COLLATE=es_ES.UTF-8;LC_MONETARY=C;LC_MESSAGES=es_ES.UTF-8;LC_PAPER=es_ES.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=es_ES.UTF-8;LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] spgrass6_0.6-4 XML_1.95-3     rgdal_0.6-7    sp_0.9-36
>
> loaded via a namespace (and not attached):
> [1] grid_2.9.0      lattice_0.17-22
>>
>
> We are trying now with our process, that takes much longer than the test, 
> we'll let you know.
>
> Thanks!
>
> Agus
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Tue May  5 21:11:01 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 5 May 2009 21:11:01 +0200 (CEST)
Subject: [R-sig-Geo] readRAST6: too many open files
In-Reply-To: <alpine.LRH.2.00.0905051905530.7655@reclus.nhh.no>
References: <4A004B09.7040006@gmail.com>
	<alpine.LRH.2.00.0905051639410.2950@reclus.nhh.no>
	<4A0058CC.30108@gmail.com>
	<alpine.LRH.2.00.0905051728070.3146@reclus.nhh.no>
	<4A007108.6040002@gmail.com>
	<alpine.LRH.2.00.0905051905530.7655@reclus.nhh.no>
Message-ID: <alpine.LRH.2.00.0905052100510.8082@reclus.nhh.no>

On Tue, 5 May 2009, Roger Bivand wrote:

> On Tue, 5 May 2009, Agustin Lobo wrote:
>
>> Roger,
>> 
>> After upgrading, the test works with plugin=F,
>> while plugin=T produces the same result.
>> 
>
> I find this too on Fedora 10, plugin=TRUE fails after a hundred or so calls, 
> and then crashes R on a further command. With plugin=FALSE, there is no 
> problem at all. The problem then lies in the plugin driver, which isn't 
> anything that spgrass6 can do anything about. It looks as though the plugin 
> is opening file handles to GRASS files but not closing them. I'll try to ask 
> on the GDAL and grass-dev lists. For the time being, it seems best to use 
> plugin=FALSE in readRAST6().

A follow-up. The previous results were using a GDAL 1.5.3 RPM, linking 
against GRASS 6.3 libraries. Having built a fresh GDAL 1.6.0 from source, 
linked against a fresh GRASS 6.4.0 RC4, the plugin now works and does not 
crash R. Browsing the GDAL GRASS raster plugin, there seem to have been 
important commits between GDAL 1.5.3 and 1.6.0 (possibly also 1.5.4, 
untested). GRASS has also changed between 6.3 and 6.4.0 release 
candidates. So a possible solution is to upgrade both GDAL and GRASS, or 
at least GDAL.

Roger

>
>> Also, ignore.stderr=T yields:
>> 
>> ERROR 6: SetColorTable() only supported for Byte or UInt16 bands in TIFF 
>> format.
>
> This is a GRASS version issue, more recent GRASS support a flag to avoid 
> r.out.gdal trying to write non-existent colour tables. Could you repeat your 
> GRASS version:
>
> execGRASS("g.version")
>
> should do it.
>
>> WARNING: Input raster map constains cells with NULL-value (no-data). The
>>         value 999 was used to represent no-data values in the input
>>         map.You can specify nodata value by nodata parameter.
>
> Maybe set a NODATA= value in the readRAST6() call to avoid heuristics trying 
> to find a possible value?
>
> Roger
>
>> /media/Transcend/Montseny/GrassData//carlos/A_TOTAL/.tmp/caminoccg/nomdum 
>> has GDAL driver GTiff
>> and has 94 rows and 116 columns
>> 
>> which is not including any more the first lines that we had with the 
>> previous version:
>> 
>> raster map/current region mismatch detected in components:
>>           cols            rows origin.northing  origin.easting
>>           TRUE            TRUE           FALSE            TRUE
>> set plugin=TRUE to override; continuing with plugin=FALSE
>> 
>> Now we have:
>> 
>>> sessionInfo()
>> R version 2.9.0 (2009-04-17)
>> i486-pc-linux-gnu
>> 
>> locale:
>> LC_CTYPE=es_ES.UTF-8;LC_NUMERIC=C;LC_TIME=es_ES.UTF-8;LC_COLLATE=es_ES.UTF-8;LC_MONETARY=C;LC_MESSAGES=es_ES.UTF-8;LC_PAPER=es_ES.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=es_ES.UTF-8;LC_IDENTIFICATION=C
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> other attached packages:
>> [1] spgrass6_0.6-4 XML_1.95-3     rgdal_0.6-7    sp_0.9-36
>> 
>> loaded via a namespace (and not attached):
>> [1] grid_2.9.0      lattice_0.17-22
>>> 
>> 
>> We are trying now with our process, that takes much longer than the test, 
>> we'll let you know.
>> 
>> Thanks!
>> 
>> Agus
>> 
>> 
>> 
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From tsippel at gmail.com  Wed May  6 05:15:53 2009
From: tsippel at gmail.com (Tim Sippel)
Date: Wed, 6 May 2009 15:15:53 +1200
Subject: [R-sig-Geo] Gradient calculation with ESRI grid (.asc) format
Message-ID: <79a13c220905052015p4ef9a784t13e82afb465c5a36@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090506/202d0d11/attachment.pl>

From r.hijmans at gmail.com  Wed May  6 05:50:09 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Wed, 6 May 2009 11:50:09 +0800
Subject: [R-sig-Geo] Gradient calculation with ESRI grid (.asc) format
In-Reply-To: <79a13c220905052015p4ef9a784t13e82afb465c5a36@mail.gmail.com>
References: <79a13c220905052015p4ef9a784t13e82afb465c5a36@mail.gmail.com>
Message-ID: <dc22b2570905052050o1cf77e9ar65786896c2dc14ca@mail.gmail.com>

You could try the focalFilter function in the raster package:
install.packages("raster", repos="http://R-Forge.R-project.org")

with this argument for the Sobel filter:
filter=matrix(c(1,2,1,0,0,0,-1,-2,-1) / 4, nrow=3)

(For using raster this way you should upgrade to R 2.9 first, if you
have not done so yet; otherwise you will get an old version; this is
an unpleasant feature of R-forge)

Robert

On Wed, May 6, 2009 at 11:15 AM, Tim Sippel <tsippel at gmail.com> wrote:
> I'm looking to calculate gradients from oceanographic variables (ie. sea
> surface temperature, chlorophyll, etc.) for which I have downloaded in ESRI
> grid format (.asc). ?From some research on gradient analysis, I have found a
> few people who have used a Sobel filter to estimate gradients in images (ie.
> presumably .tif or similar files). ?However, I have tons of data in ESRI
> grid format, and all of it is unprojected (ie. lat/lon coordinates). ?I'd
> appreciate suggestions on this if anyone has ideas. ?One of the primary
> issues to overcome is that the units of my grids are different (ie.
> x=longitude, y=latitude, z=temperature) and my grid files span the entire
> south Pacific Ocean.
>
> Thanks,
>
> Tim
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From wroberts at csir.co.za  Wed May  6 09:14:09 2009
From: wroberts at csir.co.za (Wesley Roberts)
Date: Wed, 06 May 2009 09:14:09 +0200
Subject: [R-sig-Geo] EPSG codes for LO31 WGS84 projection data
Message-ID: <4A0154E1.8E3B.0073.0@csir.co.za>

Dear Colleagues,

I have a data set which is projected using the following projection, Hartebeeshoek94 Projection Gauss Conform LO31. This is a local projection used in South Africa. So far, I have only been able to find the EPSG code for the projection from http://spatialreference.org/ref/epsg/2054/ . I am actually looking for the Proj4 definition as the library in rgdal does not contain any information regarding the projection. Using the following command I found no information for the specified code

> poly <- readShapePoly("PCA_AreaOne_2_water_EPSG.shp", IDvar="cat", proj4string=CRS("+init=epsg:2054"))
Error in CRS("+init=epsg:2054") : no options found in 'init' file

Could someone please provide me with the full proj4 definition as the spatial reference site does not seem to have it.

Many thanks and kind regards,
Wesley




Wesley Roberts MSc.
Researcher: Earth Observation (Ecosystems)
Natural Resources and the Environment
CSIR
Tel: +27 (21) 888-2490
Fax: +27 (21) 888-2693

"To know the road ahead, ask those coming back."
- Chinese proverb




-- 
This message is subject to the CSIR's copyright terms and conditions, e-mail legal notice, and implemented Open Document Format (ODF) standard. 
The full disclaimer details can be found at http://www.csir.co.za/disclaimer.html.

This message has been scanned for viruses and dangerous content by MailScanner, 
and is believed to be clean.  MailScanner thanks Transtec Computers for their support.


From p.hiemstra at geo.uu.nl  Wed May  6 10:41:26 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Wed, 06 May 2009 10:41:26 +0200
Subject: [R-sig-Geo] EPSG codes for LO31 WGS84 projection data
In-Reply-To: <4A0154E1.8E3B.0073.0@csir.co.za>
References: <4A0154E1.8E3B.0073.0@csir.co.za>
Message-ID: <4A014D36.7080701@geo.uu.nl>

Hi Wesley,

A good source of information in regard of projections is the proj4 
mailing list:

http://lists.maptools.org/mailman/listinfo/proj

cheers,
Paul

Wesley Roberts wrote:
> Dear Colleagues,
>
> I have a data set which is projected using the following projection, Hartebeeshoek94 Projection Gauss Conform LO31. This is a local projection used in South Africa. So far, I have only been able to find the EPSG code for the projection from http://spatialreference.org/ref/epsg/2054/ . I am actually looking for the Proj4 definition as the library in rgdal does not contain any information regarding the projection. Using the following command I found no information for the specified code
>
>   
>> poly <- readShapePoly("PCA_AreaOne_2_water_EPSG.shp", IDvar="cat", proj4string=CRS("+init=epsg:2054"))
>>     
> Error in CRS("+init=epsg:2054") : no options found in 'init' file
>
> Could someone please provide me with the full proj4 definition as the spatial reference site does not seem to have it.
>
> Many thanks and kind regards,
> Wesley
>
>
>
>
> Wesley Roberts MSc.
> Researcher: Earth Observation (Ecosystems)
> Natural Resources and the Environment
> CSIR
> Tel: +27 (21) 888-2490
> Fax: +27 (21) 888-2693
>
> "To know the road ahead, ask those coming back."
> - Chinese proverb
>
>
>
>
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From wroberts at csir.co.za  Wed May  6 11:32:05 2009
From: wroberts at csir.co.za (Wesley Roberts)
Date: Wed, 06 May 2009 11:32:05 +0200
Subject: [R-sig-Geo] EPSG codes for LO31 WGS84 projection data
In-Reply-To: <4A014D36.7080701@geo.uu.nl>
References: <4A0154E1.8E3B.0073.0@csir.co.za> <4A014D36.7080701@geo.uu.nl>
Message-ID: <4A017535.8E3B.0073.0@csir.co.za>

Thanks Paul,

I did find the mailing list and am using the following proj4 definition for both my shapefile and imagery data. It seems to work in R so I am happy with the result.

+proj=tmerc +south +ellips=WGS84 +datum=WGS84 +lon_o=31 +k_0=1 +units=m +no_defs

As per usual I found the solution no long after posting to this list. In future I will post to an imaginary list :-) and hopefully the answer will follow.

Many thanks,
Wesley 
 
>>> Paul Hiemstra <p.hiemstra at geo.uu.nl> 05/06/09 10:41 AM >>> 
Hi Wesley,

A good source of information in regard of projections is the proj4 
mailing list:

http://lists.maptools.org/mailman/listinfo/proj

cheers,
Paul

Wesley Roberts wrote:
> Dear Colleagues,
>
> I have a data set which is projected using the following projection, Hartebeeshoek94 Projection Gauss Conform LO31. This is a local projection used in South Africa. So far, I have only been able to find the EPSG code for the projection from http://spatialreference.org/ref/epsg/2054/ . I am actually looking for the Proj4 definition as the library in rgdal does not contain any information regarding the projection. Using the following command I found no information for the specified code
>
>   
>> poly <- readShapePoly("PCA_AreaOne_2_water_EPSG.shp", IDvar="cat", proj4string=CRS("+init=epsg:2054"))
>>     
> Error in CRS("+init=epsg:2054") : no options found in 'init' file
>
> Could someone please provide me with the full proj4 definition as the spatial reference site does not seem to have it.
>
> Many thanks and kind regards,
> Wesley
>
>
>
>
> Wesley Roberts MSc.
> Researcher: Earth Observation (Ecosystems)
> Natural Resources and the Environment
> CSIR
> Tel: +27 (21) 888-2490
> Fax: +27 (21) 888-2693
>
> "To know the road ahead, ask those coming back."
> - Chinese proverb
>
>
>
>
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul



-- 
This message is subject to the CSIR's copyright terms and conditions, e-mail legal notice, and implemented Open Document Format (ODF) standard. 
The full disclaimer details can be found at http://www.csir.co.za/disclaimer.html.

This message has been scanned for viruses and dangerous content by MailScanner, 
and is believed to be clean.  MailScanner thanks Transtec Computers for their support.


From alobolistas at gmail.com  Wed May  6 11:34:31 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Wed, 06 May 2009 11:34:31 +0200
Subject: [R-sig-Geo] readRAST6: too many open files
In-Reply-To: <alpine.LRH.2.00.0905052100510.8082@reclus.nhh.no>
References: <4A004B09.7040006@gmail.com>
	<alpine.LRH.2.00.0905051639410.2950@reclus.nhh.no>
	<4A0058CC.30108@gmail.com>
	<alpine.LRH.2.00.0905051728070.3146@reclus.nhh.no>
	<4A007108.6040002@gmail.com>
	<alpine.LRH.2.00.0905051905530.7655@reclus.nhh.no>
	<alpine.LRH.2.00.0905052100510.8082@reclus.nhh.no>
Message-ID: <4A0159A7.4070704@gmail.com>

ok, thanks, we are using

 > system("g.version")
GRASS 6.3.0 (2008)

which is what comes for binaries for ubuntu 8.04 by now.
We should be compiling qgis, grass and gdal soon and will
try again and let you know.

Anyway, by now our process works using plugin=F and ignore.stderr=T
and the newest spgrass6, rgdal and sp packages.

Thanks a lot

Agus

Roger Bivand wrote:
> On Tue, 5 May 2009, Roger Bivand wrote:
>
>> On Tue, 5 May 2009, Agustin Lobo wrote:
>>
>>> Roger,
>>>
>>> After upgrading, the test works with plugin=F,
>>> while plugin=T produces the same result.
>>>
>>
>> I find this too on Fedora 10, plugin=TRUE fails after a hundred or so 
>> calls, and then crashes R on a further command. With plugin=FALSE, 
>> there is no problem at all. The problem then lies in the plugin 
>> driver, which isn't anything that spgrass6 can do anything about. It 
>> looks as though the plugin is opening file handles to GRASS files but 
>> not closing them. I'll try to ask on the GDAL and grass-dev lists. 
>> For the time being, it seems best to use plugin=FALSE in readRAST6().
>
> A follow-up. The previous results were using a GDAL 1.5.3 RPM, linking 
> against GRASS 6.3 libraries. Having built a fresh GDAL 1.6.0 from 
> source, linked against a fresh GRASS 6.4.0 RC4, the plugin now works 
> and does not crash R. Browsing the GDAL GRASS raster plugin, there 
> seem to have been important commits between GDAL 1.5.3 and 1.6.0 
> (possibly also 1.5.4, untested). GRASS has also changed between 6.3 
> and 6.4.0 release candidates. So a possible solution is to upgrade 
> both GDAL and GRASS, or at least GDAL.
>
> Roger
>
>>
>>> Also, ignore.stderr=T yields:
>>>
>>> ERROR 6: SetColorTable() only supported for Byte or UInt16 bands in 
>>> TIFF format.
>>
>> This is a GRASS version issue, more recent GRASS support a flag to 
>> avoid r.out.gdal trying to write non-existent colour tables. Could 
>> you repeat your GRASS version:
>>
>> execGRASS("g.version")
>>
>> should do it.
>>
>>> WARNING: Input raster map constains cells with NULL-value (no-data). 
>>> The
>>> value 999 was used to represent no-data values in the input
>>> map.You can specify nodata value by nodata parameter.
>>
>> Maybe set a NODATA= value in the readRAST6() call to avoid heuristics 
>> trying to find a possible value?
>>
>> Roger
>>
>>> /media/Transcend/Montseny/GrassData//carlos/A_TOTAL/.tmp/caminoccg/nomdum 
>>> has GDAL driver GTiff
>>> and has 94 rows and 116 columns
>>>
>>> which is not including any more the first lines that we had with the 
>>> previous version:
>>>
>>> raster map/current region mismatch detected in components:
>>> cols rows origin.northing origin.easting
>>> TRUE TRUE FALSE TRUE
>>> set plugin=TRUE to override; continuing with plugin=FALSE
>>>
>>> Now we have:
>>>
>>>> sessionInfo()
>>> R version 2.9.0 (2009-04-17)
>>> i486-pc-linux-gnu
>>>
>>> locale:
>>> LC_CTYPE=es_ES.UTF-8;LC_NUMERIC=C;LC_TIME=es_ES.UTF-8;LC_COLLATE=es_ES.UTF-8;LC_MONETARY=C;LC_MESSAGES=es_ES.UTF-8;LC_PAPER=es_ES.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=es_ES.UTF-8;LC_IDENTIFICATION=C 
>>>
>>>
>>> attached base packages:
>>> [1] stats graphics grDevices utils datasets methods base
>>>
>>> other attached packages:
>>> [1] spgrass6_0.6-4 XML_1.95-3 rgdal_0.6-7 sp_0.9-36
>>>
>>> loaded via a namespace (and not attached):
>>> [1] grid_2.9.0 lattice_0.17-22
>>>>
>>>
>>> We are trying now with our process, that takes much longer than the 
>>> test, we'll let you know.
>>>
>>> Thanks!
>>>
>>> Agus
>>>
>>>
>>>
>>
>>
>


From T.Hengl at uva.nl  Wed May  6 12:15:18 2009
From: T.Hengl at uva.nl (Hengl, T.)
Date: Wed, 6 May 2009 12:15:18 +0200
Subject: [R-sig-Geo] (no subject)
In-Reply-To: <4A0154E1.8E3B.0073.0@csir.co.za>
References: <4A0154E1.8E3B.0073.0@csir.co.za>
Message-ID: <8AA369FF-95A8-4643-A14A-EA4DB5707CEB@mimectl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090506/a1521d18/attachment.pl>

From Marie.CHARRU at engref.agroparistech.fr  Wed May  6 18:33:20 2009
From: Marie.CHARRU at engref.agroparistech.fr (Marie CHARRU)
Date: Wed, 06 May 2009 18:33:20 +0200
Subject: [R-sig-Geo] testing for spatial variability of the parameters
 in GWR with R
Message-ID: <4A01BBD0.9040200@engref.agroparistech.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090506/7fe5f376/attachment.pl>

From Roger.Bivand at nhh.no  Wed May  6 20:34:50 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 6 May 2009 20:34:50 +0200 (CEST)
Subject: [R-sig-Geo] testing for spatial variability of the parameters
 in GWR with R
In-Reply-To: <4A01BBD0.9040200@engref.agroparistech.fr>
References: <4A01BBD0.9040200@engref.agroparistech.fr>
Message-ID: <alpine.LRH.2.00.0905062017110.12568@reclus.nhh.no>

On Wed, 6 May 2009, Marie CHARRU wrote:

> Thank you Roger.
> I did'nt know what this LMZ.F3GWR.test() function was for. It seems that
> it is what I need, but when I try to run it, I have an error message
> coming up :
>
> /Error: cannot allocate vector of size 52.5 Mo.
>
> /I read on the R-sig-geo list that this could be due to the size of my
> dataset (3710 points) and that there was no way around... In that case,
> how to test big datasets ? The tests I'm doing now concern just one part
> of the total sample, so the problem will get bigger when I use all my data !
> Would a random selection of points in the dataset be suitable for
> testing the spatial variability of the parameters ?

All the tests on GWR involve operations on dense n by n matrices, 
which means that multiple versions of these matrices will be in memory. It 
is possible that LMZ.F3GWR.test() could be altered to use less memory, but 
even so this may not help enough. To check smaller data sets, you would 
need random tiles of the data (so that the relative postions are 
preserved).

Roger

>
> Thanks for your help
>
> Marie
>
> On Wed, 6 May 2009, Marie CHARRU wrote:
>
>> Hi !
>>
>> I would like to know how to carry out the test for spatial variability
>> of the parameters of a geographically weighted regression model in R.
>> A test using a Monte Carlo approach is described in Fotheringham &
>> al., 2002, but I can't find how to run it with R.
>> I would appreciate any help about this matter.
>
> See the LMZ.F3GWR.test() function in the spgwr package for the Leung et
> al. test - other tests for GWR against OLS, but not for coefficients,
> are in that package. The help page has examples. Are you looking for
> other tests?
>
> Hope this helps,
>
> Roger
>
> PS. Consider posting on the R-sig-geo list, where others may be able to
> help more.
>
>>
>> Thank you,
>>
>> Marie
>> / /
>>
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From wroberts at csir.co.za  Thu May  7 14:58:30 2009
From: wroberts at csir.co.za (Wesley Roberts)
Date: Thu, 07 May 2009 14:58:30 +0200
Subject: [R-sig-Geo] Classification of attribute table
Message-ID: <4A02F717.8E3B.0073.0@csir.co.za>

Dear R-sig-geo users,

I have the output of a watershed segmentation in vector format (shapefile) which has it's attribute table populated with statistics regarding spectral reflectance of each polygon object. The attribute data was sourced from a geographically co-incident aerial photograph. I would now like to classify the segments using the attribute data. This seems like an easy task but I am struggling to find a suitable method. I have looked at 'lda' and 'qda' in the MASS package but the selection of an appropriate model using 'cv1EMtrain' takes a really long time. In essence all I want to do is classify the 6 variable data set into 3 classes with the class for each case recorded in the attribute table. 

Any advice or suggestions would be greatly appreciated.

Many thanks and kind regards,
Wesley



Wesley Roberts MSc.
Researcher: Earth Observation (Ecosystems)
Natural Resources and the Environment
CSIR
Tel: +27 (21) 888-2490
Fax: +27 (21) 888-2693

"To know the road ahead, ask those coming back."
- Chinese proverb




-- 
This message is subject to the CSIR's copyright terms and conditions, e-mail legal notice, and implemented Open Document Format (ODF) standard. 
The full disclaimer details can be found at http://www.csir.co.za/disclaimer.html.

This message has been scanned for viruses and dangerous content by MailScanner, 
and is believed to be clean.  MailScanner thanks Transtec Computers for their support.


From markus.loecher at gmail.com  Thu May  7 19:09:42 2009
From: markus.loecher at gmail.com (Markus Loecher)
Date: Thu, 7 May 2009 13:09:42 -0400
Subject: [R-sig-Geo] RgoogleMaps package
Message-ID: <bf460e020905071009s408b10a7v33f32df9fb492460@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090507/d2e528f8/attachment.pl>

From etiennebr at gmail.com  Thu May  7 20:33:00 2009
From: etiennebr at gmail.com (Etienne Bellemare Racine)
Date: Thu, 07 May 2009 14:33:00 -0400
Subject: [R-sig-Geo] Change color of binary mask in spatstat
Message-ID: <4A03295C.3070604@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090507/950c7a9f/attachment.pl>

From renaud.lancelot at cirad.fr  Thu May  7 23:11:43 2009
From: renaud.lancelot at cirad.fr (Renaud Lancelot)
Date: Thu, 07 May 2009 23:11:43 +0200
Subject: [R-sig-Geo] UTM to longlat
Message-ID: <4A034E8F.3090807@cirad.fr>

Dear all,

I have a big dataset (> 200,000 lines) of georeferenced locations where 
the coordinates are given in UTM, spanning over several zones. Is is 
possible to convert all the UTM coordinates into longlat WGS84 with a 
single call ?

Renaud
-- 
Renaud Lancelot
EDEN Project, coordinator
http://www.eden-fp6project.net/

UMR CIRAD-INRA "Contr?le des maladies animales exotiques et ?mergentes"
Joint research unit "Control of emerging and exotic animal diseases"

CIRAD
Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier
http://www.cirad.fr  http://bluetongue.cirad.fr/

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69


From milton.ruser at gmail.com  Thu May  7 23:45:35 2009
From: milton.ruser at gmail.com (milton ruser)
Date: Thu, 7 May 2009 17:45:35 -0400
Subject: [R-sig-Geo] UTM to longlat
In-Reply-To: <4A034E8F.3090807@cirad.fr>
References: <4A034E8F.3090807@cirad.fr>
Message-ID: <3aaf1a030905071445w3c3b1c4bge8385162fa9fd5ef@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090507/91255a60/attachment.pl>

From edzer.pebesma at uni-muenster.de  Thu May  7 23:47:49 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 07 May 2009 23:47:49 +0200
Subject: [R-sig-Geo] UTM to longlat
In-Reply-To: <4A034E8F.3090807@cirad.fr>
References: <4A034E8F.3090807@cirad.fr>
Message-ID: <4A035705.5050800@uni-muenster.de>

Yes, but you will not like that call.

In R (package sp), each spatial data set can only have one single
projection. I'd suggest, in pseudo-code

- import the data into a data.frame
- for each UTM zone do:
   select the locations
   set their CRS
   reproject to long/lat
- cbind the locations to a single data structure
- convert back to data.frame if needed.
--
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de

Renaud Lancelot wrote:
> Dear all,
>
> I have a big dataset (> 200,000 lines) of georeferenced locations
> where the coordinates are given in UTM, spanning over several zones.
> Is is possible to convert all the UTM coordinates into longlat WGS84
> with a single call ?
>
> Renaud


From renaud.lancelot at gmail.com  Thu May  7 23:48:53 2009
From: renaud.lancelot at gmail.com (Renaud Lancelot)
Date: Thu, 7 May 2009 23:48:53 +0200
Subject: [R-sig-Geo] UTM to longlat
In-Reply-To: <3aaf1a030905071445w3c3b1c4bge8385162fa9fd5ef@mail.gmail.com>
References: <4A034E8F.3090807@cirad.fr>
	<3aaf1a030905071445w3c3b1c4bge8385162fa9fd5ef@mail.gmail.com>
Message-ID: <c2ee56800905071448o6498e97uba42b852ce5577bb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090507/06dba1fc/attachment.pl>

From renaud.lancelot at gmail.com  Thu May  7 23:54:53 2009
From: renaud.lancelot at gmail.com (Renaud Lancelot)
Date: Thu, 7 May 2009 23:54:53 +0200
Subject: [R-sig-Geo] UTM to longlat
In-Reply-To: <4A035705.5050800@uni-muenster.de>
References: <4A034E8F.3090807@cirad.fr> <4A035705.5050800@uni-muenster.de>
Message-ID: <c2ee56800905071454l4323c5f5yd1d54851057b7c5d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090507/0a4ea254/attachment.pl>

From j.burke at earthlink.net  Fri May  8 00:25:29 2009
From: j.burke at earthlink.net (Jim Burke)
Date: Thu, 07 May 2009 17:25:29 -0500
Subject: [R-sig-Geo] UTM to longlat
In-Reply-To: <c2ee56800905071454l4323c5f5yd1d54851057b7c5d@mail.gmail.com>
References: <4A034E8F.3090807@cirad.fr> <4A035705.5050800@uni-muenster.de>
	<c2ee56800905071454l4323c5f5yd1d54851057b7c5d@mail.gmail.com>
Message-ID: <4A035FD9.9020409@earthlink.net>

Its all quite simple I think (i.e. "hope"). Have
you used spTransform(rdgal)?

## here I have a file from a local group delivered
## in UTM format that I transformed OK to long-lat.

library(rgdal) # for map projection support; automatically loads sp
## transform internal measurements from UTM to long lat format
longlat_sp <- spTransform(UTM_format_sp, CRS("+init=epsg:4326"))
sapply(slot(longlat_sp, "polygons"), function(x) slot(x, "ID"))


 > showMethods("spTransform")
Function: spTransform (package rgdal)
x="SpatialGridDataFrame", CRSobj="CRS"
x="SpatialLines", CRSobj="CRS"
x="SpatialLinesDataFrame", CRSobj="CRS"
x="SpatialPixelsDataFrame", CRSobj="CRS"
x="SpatialPoints", CRSobj="CRS"
x="SpatialPointsDataFrame", CRSobj="CRS"
x="SpatialPolygons", CRSobj="CRS"
x="SpatialPolygonsDataFrame", CRSobj="CRS"

Hope this helps,
Jim Burke



Renaud Lancelot wrote:
> Thank you Edzer. I was hoping there was a simpler solution, but it's still
> fairly simple.
>
> Renaud
>
> 2009/5/7 Edzer Pebesma <edzer.pebesma at uni-muenster.de>
>
>   
>> Yes, but you will not like that call.
>>
>> In R (package sp), each spatial data set can only have one single
>> projection. I'd suggest, in pseudo-code
>>
>> - import the data into a data.frame
>> - for each UTM zone do:
>>   select the locations
>>   set their CRS
>>   reproject to long/lat
>> - cbind the locations to a single data structure
>> - convert back to data.frame if needed.
>> --
>> Edzer Pebesma
>> Institute for Geoinformatics (ifgi), University of M?nster
>> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
>> 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
>> http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de
>>
>> Renaud Lancelot wrote:
>>     
>>> Dear all,
>>>
>>> I have a big dataset (> 200,000 lines) of georeferenced locations
>>> where the coordinates are given in UTM, spanning over several zones.
>>> Is is possible to convert all the UTM coordinates into longlat WGS84
>>> with a single call ?
>>>
>>> Renaud
>>>       
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>     
>
>
>
>   
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From renaud.lancelot at gmail.com  Fri May  8 01:22:15 2009
From: renaud.lancelot at gmail.com (Renaud Lancelot)
Date: Fri, 8 May 2009 01:22:15 +0200
Subject: [R-sig-Geo] UTM to longlat
In-Reply-To: <4A035FD9.9020409@earthlink.net>
References: <4A034E8F.3090807@cirad.fr> <4A035705.5050800@uni-muenster.de>
	<c2ee56800905071454l4323c5f5yd1d54851057b7c5d@mail.gmail.com>
	<4A035FD9.9020409@earthlink.net>
Message-ID: <c2ee56800905071622n23ad9a83l29443eb086753da6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090508/61e4ed16/attachment.pl>

From tsippel at gmail.com  Fri May  8 04:26:26 2009
From: tsippel at gmail.com (Tim Sippel)
Date: Fri, 8 May 2009 14:26:26 +1200
Subject: [R-sig-Geo] Define projection using Raster package
Message-ID: <79a13c220905071926x4a9c3405j9e537a8145c1608e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090508/c9cfb6bf/attachment.pl>

From r.hijmans at gmail.com  Fri May  8 07:13:25 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Fri, 8 May 2009 13:13:25 +0800
Subject: [R-sig-Geo] Define projection using Raster package
In-Reply-To: <79a13c220905071926x4a9c3405j9e537a8145c1608e@mail.gmail.com>
References: <79a13c220905071926x4a9c3405j9e537a8145c1608e@mail.gmail.com>
Message-ID: <dc22b2570905072213j50335f72sa738b4a39cd48d8c@mail.gmail.com>

Tim,

"proj" is not a valid argument in raster(x, ... ) when x (the first
argument) is of class character (i.e. interpreted as a filename); but
I can add that argument. For now, what should work is:

r<-raster(paste(asc.in.dir, "\\", asc.in.files[i], sep=""))
projection(r) <- "+proj=tmerc +lat_0=0 +lon_0=0 +k=9996 +x_0=500000
+y_0=10000000"

Robert

On Fri, May 8, 2009 at 10:26 AM, Tim Sippel <tsippel at gmail.com> wrote:
> I need to take an ESRI grid (.asc) which is in geographic coordinates
> (lat/lon) and project it to UTM coordinates. ?The following command is
> giving me an error saying I'm giving it an undefined argument. ?I can read
> the raster without the projs arguement, but I'm stuck when adding that on.
>
>> r<-raster(paste(asc.in.dir, "\\", asc.in.files[i], sep=""),
> projs="+proj=tmerc +lat_0=0 +lon_0=0 +k=9996 +x_0=500000 +y_0=10000000")
> Error in .local(x, ...) :
> ?unused argument(s) (projs = "+proj=tmerc +lat_0=0 +lon_0=0 +k=9996
> +x_0=500000 +y_0=10000000")
>
> Thanks,
>
> Tim
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From hi_ono2001 at ybb.ne.jp  Fri May  8 07:45:09 2009
From: hi_ono2001 at ybb.ne.jp (Hisaji ONO)
Date: Fri, 8 May 2009 14:45:09 +0900 (JST)
Subject: [R-sig-Geo] Availability of Raster package for Win32
Message-ID: <20090508054509.99789.qmail@web10513.mail.ogk.yahoo.co.jp>

Hello.


  Raster package seems to be very interesting since it
doesn't require external applications.

 However currently, no binaries prepared for Win32.

 Will this Win32 binary available?



 Regards.


From Roger.Bivand at nhh.no  Fri May  8 07:49:35 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 8 May 2009 07:49:35 +0200 (CEST)
Subject: [R-sig-Geo] UTM to longlat
In-Reply-To: <c2ee56800905071622n23ad9a83l29443eb086753da6@mail.gmail.com>
References: <4A034E8F.3090807@cirad.fr> <4A035705.5050800@uni-muenster.de>
	<c2ee56800905071454l4323c5f5yd1d54851057b7c5d@mail.gmail.com>
	<4A035FD9.9020409@earthlink.net>
	<c2ee56800905071622n23ad9a83l29443eb086753da6@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0905080745530.32137@reclus.nhh.no>

On Fri, 8 May 2009, Renaud Lancelot wrote:

> Thank you, here is the full process trying to follow Edzer's suggestion:
>
> library(RODBC)
> library(rgdal)
> channel <- odbcConnectAccess("farms.mdb")
> sigal <- sqlQuery(channel, "select * from T_SIGAL")
> Liste <- by(sigal,
>            list(zone = sigal$zone),
>            function(x){
>                strg <- paste("+proj=utm +ellps=intl +zone=",
> unique(x$zone), sep = "")
>                SP <- SpatialPoints(cbind(x$UTM_X, x$UTM_Y),
> proj4string=CRS(strg))
>                as.data.frame(spTransform(SP, CRS("+proj=longlat
> +datum=WGS84")))
>                })
> sigal2 <- do.call("rbind", Liste)
> dimnames(sigal2) <- list(seq(nrow(sigal2)), c("x", "y"))
>
> Plotting the result looks fine but I need to check further.
>
> BTW, is it possible to stack directly the SpatialPoints objects?

Yes, you could use the spRbind() method in maptools:

library(maptools)
set.seed(1)
a <- SpatialPoints(matrix(runif(100), ncol=2))
b <- SpatialPoints(matrix(runif(100), ncol=2))
c <- spRbind(a, b)
plot(c, axes=TRUE)
points(a, col="green")
points(b, col="red")

Roger

>
> Thank you for your help!
>
> Renaud
>
> 2009/5/8 Jim Burke <j.burke at earthlink.net>
>
>> Its all quite simple I think (i.e. "hope"). Have
>> you used spTransform(rdgal)?
>>
>> ## here I have a file from a local group delivered
>> ## in UTM format that I transformed OK to long-lat.
>>
>> library(rgdal) # for map projection support; automatically loads sp
>> ## transform internal measurements from UTM to long lat format
>> longlat_sp <- spTransform(UTM_format_sp, CRS("+init=epsg:4326"))
>> sapply(slot(longlat_sp, "polygons"), function(x) slot(x, "ID"))
>>
>>
>>> showMethods("spTransform")
>> Function: spTransform (package rgdal)
>> x="SpatialGridDataFrame", CRSobj="CRS"
>> x="SpatialLines", CRSobj="CRS"
>> x="SpatialLinesDataFrame", CRSobj="CRS"
>> x="SpatialPixelsDataFrame", CRSobj="CRS"
>> x="SpatialPoints", CRSobj="CRS"
>> x="SpatialPointsDataFrame", CRSobj="CRS"
>> x="SpatialPolygons", CRSobj="CRS"
>> x="SpatialPolygonsDataFrame", CRSobj="CRS"
>>
>> Hope this helps,
>> Jim Burke
>>
>>
>>
>> Renaud Lancelot wrote:
>>
>>> Thank you Edzer. I was hoping there was a simpler solution, but it's still
>>> fairly simple.
>>>
>>> Renaud
>>>
>>> 2009/5/7 Edzer Pebesma <edzer.pebesma at uni-muenster.de>
>>>
>>>
>>>
>>>> Yes, but you will not like that call.
>>>>
>>>> In R (package sp), each spatial data set can only have one single
>>>> projection. I'd suggest, in pseudo-code
>>>>
>>>> - import the data into a data.frame
>>>> - for each UTM zone do:
>>>>  select the locations
>>>>  set their CRS
>>>>  reproject to long/lat
>>>> - cbind the locations to a single data structure
>>>> - convert back to data.frame if needed.
>>>> --
>>>> Edzer Pebesma
>>>> Institute for Geoinformatics (ifgi), University of M?nster
>>>> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
>>>> 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
>>>> http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de
>>>>
>>>> Renaud Lancelot wrote:
>>>>
>>>>
>>>>> Dear all,
>>>>>
>>>>> I have a big dataset (> 200,000 lines) of georeferenced locations
>>>>> where the coordinates are given in UTM, spanning over several zones.
>>>>> Is is possible to convert all the UTM coordinates into longlat WGS84
>>>>> with a single call ?
>>>>>
>>>>> Renaud
>>>>>
>>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>
>>>>
>>>
>>>
>>>
>>>  ------------------------------------------------------------------------
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>
>>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From r.hijmans at gmail.com  Fri May  8 07:50:53 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Fri, 8 May 2009 13:50:53 +0800
Subject: [R-sig-Geo] Availability of Raster package for Win32
In-Reply-To: <20090508054509.99789.qmail@web10513.mail.ogk.yahoo.co.jp>
References: <20090508054509.99789.qmail@web10513.mail.ogk.yahoo.co.jp>
Message-ID: <dc22b2570905072250i570558acl88033580aa246044@mail.gmail.com>

The raster package depends on rgdal and sp. It is under development in
R-forge (that is, it is not on CRAN yet). You can download the source
or install it directly on Win and Linux with this command:
install.packages("raster", repos="http://R-Forge.R-project.org")

Robert

On Fri, May 8, 2009 at 1:45 PM, Hisaji ONO <hi_ono2001 at ybb.ne.jp> wrote:
> Hello.
>
>
> ?Raster package seems to be very interesting since it
> doesn't require external applications.
>
> ?However currently, no binaries prepared for Win32.
>
> ?Will this Win32 binary available?
>
>
>
> ?Regards.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From Roger.Bivand at nhh.no  Fri May  8 08:02:03 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 8 May 2009 08:02:03 +0200 (CEST)
Subject: [R-sig-Geo] Define projection using Raster package
In-Reply-To: <dc22b2570905072213j50335f72sa738b4a39cd48d8c@mail.gmail.com>
References: <79a13c220905071926x4a9c3405j9e537a8145c1608e@mail.gmail.com>
	<dc22b2570905072213j50335f72sa738b4a39cd48d8c@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0905080756390.32137@reclus.nhh.no>

On Fri, 8 May 2009, Robert Hijmans wrote:

> Tim,
>
> "proj" is not a valid argument in raster(x, ... ) when x (the first
> argument) is of class character (i.e. interpreted as a filename); but
> I can add that argument. For now, what should work is:
>
> r<-raster(paste(asc.in.dir, "\\", asc.in.files[i], sep=""))
> projection(r) <- "+proj=tmerc +lat_0=0 +lon_0=0 +k=9996 +x_0=500000
> +y_0=10000000"

This answers the question of how to set the coordinate reference system. 
However, I think that Tim is also asking about how to warp from 
geographical coordinates to the specified projected coordinates. Should he 
use projectRaster() to do this?

Roger

>
> Robert
>
> On Fri, May 8, 2009 at 10:26 AM, Tim Sippel <tsippel at gmail.com> wrote:
>> I need to take an ESRI grid (.asc) which is in geographic coordinates
>> (lat/lon) and project it to UTM coordinates. ?The following command is
>> giving me an error saying I'm giving it an undefined argument. ?I can read
>> the raster without the projs arguement, but I'm stuck when adding that on.
>>
>>> r<-raster(paste(asc.in.dir, "\\", asc.in.files[i], sep=""),
>> projs="+proj=tmerc +lat_0=0 +lon_0=0 +k=9996 +x_0=500000 +y_0=10000000")
>> Error in .local(x, ...) :
>> ?unused argument(s) (projs = "+proj=tmerc +lat_0=0 +lon_0=0 +k=9996
>> +x_0=500000 +y_0=10000000")
>>
>> Thanks,
>>
>> Tim
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From renaud.lancelot at gmail.com  Fri May  8 08:14:57 2009
From: renaud.lancelot at gmail.com (Renaud Lancelot)
Date: Fri, 8 May 2009 08:14:57 +0200
Subject: [R-sig-Geo] UTM to longlat
In-Reply-To: <alpine.LRH.2.00.0905080745530.32137@reclus.nhh.no>
References: <4A034E8F.3090807@cirad.fr> <4A035705.5050800@uni-muenster.de>
	<c2ee56800905071454l4323c5f5yd1d54851057b7c5d@mail.gmail.com>
	<4A035FD9.9020409@earthlink.net>
	<c2ee56800905071622n23ad9a83l29443eb086753da6@mail.gmail.com>
	<alpine.LRH.2.00.0905080745530.32137@reclus.nhh.no>
Message-ID: <c2ee56800905072314x50a69d30s43f9bb28042a83ef@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090508/830ff1d5/attachment.pl>

From r.hijmans at gmail.com  Fri May  8 08:21:11 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Fri, 8 May 2009 14:21:11 +0800
Subject: [R-sig-Geo] Define projection using Raster package
In-Reply-To: <alpine.LRH.2.00.0905080756390.32137@reclus.nhh.no>
References: <79a13c220905071926x4a9c3405j9e537a8145c1608e@mail.gmail.com>
	<dc22b2570905072213j50335f72sa738b4a39cd48d8c@mail.gmail.com>
	<alpine.LRH.2.00.0905080756390.32137@reclus.nhh.no>
Message-ID: <dc22b2570905072321n4843a658h112a8816bad60e6b@mail.gmail.com>

Thanks Roger, you are right, I had missed that part (don't ask me how).

projectRaster() is indeed the function in raster to use (but it is a bit slow).

Something like
r<-raster(paste(asc.in.dir, "\\", asc.in.files[1], sep=""))
projection(r) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"

Create a projected raster 'template'
newproj <- "+proj=tmerc +lat_0=0 +lon_0=0 +k=9996 +x_0=500000 +y_0=10000000"
projras <- projectBbox(r, newproj)
# Adjust the cell size, e.g. and perhaps the extent
res(projras) <- 100000
# xmin(projras) <- ....


now do the loop

r<-raster(paste(asc.in.dir, "\\", asc.in.files[i], sep=""))
rr <- projectRaster(r, projras)

Robert

On Fri, May 8, 2009 at 2:02 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Fri, 8 May 2009, Robert Hijmans wrote:
>
>> Tim,
>>
>> "proj" is not a valid argument in raster(x, ... ) when x (the first
>> argument) is of class character (i.e. interpreted as a filename); but
>> I can add that argument. For now, what should work is:
>>
>> r<-raster(paste(asc.in.dir, "\\", asc.in.files[i], sep=""))
>> projection(r) <- "+proj=tmerc +lat_0=0 +lon_0=0 +k=9996 +x_0=500000
>> +y_0=10000000"
>
> This answers the question of how to set the coordinate reference system.
> However, I think that Tim is also asking about how to warp from geographical
> coordinates to the specified projected coordinates. Should he use
> projectRaster() to do this?
>
> Roger
>
>>
>> Robert
>>
>> On Fri, May 8, 2009 at 10:26 AM, Tim Sippel <tsippel at gmail.com> wrote:
>>>
>>> I need to take an ESRI grid (.asc) which is in geographic coordinates
>>> (lat/lon) and project it to UTM coordinates. ?The following command is
>>> giving me an error saying I'm giving it an undefined argument. ?I can
>>> read
>>> the raster without the projs arguement, but I'm stuck when adding that
>>> on.
>>>
>>>> r<-raster(paste(asc.in.dir, "\\", asc.in.files[i], sep=""),
>>>
>>> projs="+proj=tmerc +lat_0=0 +lon_0=0 +k=9996 +x_0=500000 +y_0=10000000")
>>> Error in .local(x, ...) :
>>> ?unused argument(s) (projs = "+proj=tmerc +lat_0=0 +lon_0=0 +k=9996
>>> +x_0=500000 +y_0=10000000")
>>>
>>> Thanks,
>>>
>>> Tim
>>>
>>> ? ? ? ?[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>


From marcelino.delacruz at upm.es  Fri May  8 11:06:45 2009
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Fri, 08 May 2009 11:06:45 +0200
Subject: [R-sig-Geo] Change color of binary mask in spatstat
In-Reply-To: <4A03295C.3070604@gmail.com>
References: <4A03295C.3070604@gmail.com>
Message-ID: <200905080906.n4896kiO017684@edison.ccupm.upm.es>

Hi Etienne,

Maybe this?

plot(as.mask(demopat$window), col=c(2,3))

Cheers,

Marcelino


At 20:33 07/05/2009, Etienne Bellemare Racine wrote:
>I would like to change the color of a binary mask when I plot it. The
>default is red and beige. I've tried setting col parameter, but it is
>only working with polygonal windows.
>
>data(demopat)
>plot(demopat$window, col=3)
>#Not OK :
>plot(as.mask(demopat$window), col=3)
>
>Thanks,
>Etienne
>
>         [[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at stat.math.ethz.ch
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo

________________________________

Marcelino de la Cruz Rot

Departamento de  Biolog?a Vegetal
E.U.T.I. Agr?cola
Universidad Polit?cnica de Madrid
28040-Madrid
Tel.: 91 336 54 35
Fax: 91 336 56 56
marcelino.delacruz at upm.es


From mike.elliott at openreach.co.uk  Fri May  8 13:46:06 2009
From: mike.elliott at openreach.co.uk (mike.elliott at openreach.co.uk)
Date: Fri, 8 May 2009 12:46:06 +0100
Subject: [R-sig-Geo] Calculating Risk at point locations (without
	rasterising)
Message-ID: <3D6621E58F6EA24C9D0CA72B2D8E15B3051078DC@E03MVB1-UKBR.domain1.systemhost.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090508/a8b37d2f/attachment.pl>

From facrimas at libero.it  Sat May  9 12:06:04 2009
From: facrimas at libero.it (facrimas at libero.it)
Date: Sat, 9 May 2009 12:06:04 +0200 (CEST)
Subject: [R-sig-Geo] indicator simple kriging with varying local mean on
	gstat
Message-ID: <30247661.908591241863564507.JavaMail.defaultUser@defaultHost>

Dear guys,

I want to use the indicator simple kriging with varying local mean on gstat.

Do you have a script example about it?

I do not understand which is the local mean that I have to put in the command 
of simple indicator kriging.....

 I do not also well understand whether if it is posssible to use the 
semivariogram model in SK, because theory tells that it need the covariance 
function.......

Any suggest?

Thank you.

Cristiano


From Nicholas.Nagle at Colorado.EDU  Sat May  9 17:19:31 2009
From: Nicholas.Nagle at Colorado.EDU (Nicholas N Nagle)
Date: Sat,  9 May 2009 09:19:31 -0600 (MDT)
Subject: [R-sig-Geo] Calculating Risk at point locations (without
 rasterising)
Message-ID: <20090509091931.AJC41863@riddler.int.colorado.edu>

You might consider setting your problem up as a GLM/GAM.  These use splines to to create a spatially smooth conditional mean surface.  You can find examples of this in:

Waller and Gotway. "Applied Spatial Statistics for Public Health Data"
and
Wood. "Generalized Additive Models: An introduction with R"

The latter also serves as a comprehensive guide to the mgcv package.

However, since these create smooth surfaces (and if you do not have spatially discontinuous covariate effects, you didn't mention this), I wouldn't expect the exact results to be that different from those obtained at the nearest raster cell.



Good luck,
Nicholas



Nicholas N. Nagle, Assistant Professor
University of Colorado
Department of Geography
UCB 260, Guggenheim 110
Boulder, CO 80309-0260
phone: 303-492-4794


From edzer.pebesma at uni-muenster.de  Sun May 10 22:41:34 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 10 May 2009 22:41:34 +0200
Subject: [R-sig-Geo] indicator simple kriging with varying local mean
 on	gstat
In-Reply-To: <30247661.908591241863564507.JavaMail.defaultUser@defaultHost>
References: <30247661.908591241863564507.JavaMail.defaultUser@defaultHost>
Message-ID: <4A073BFE.7080201@uni-muenster.de>

The simplest solution might be to just (simple) krige the residuals, and
add them to your known varying mean.

Please be aware that this "model" suggests residuals have mean-dependent
variance (p * (1-p)), and thus using a single variogram model for the
full set of residuals is not in accordance with theory.

I guess that this problem is larger than the one you mention --
covariances are simply derived from variograms that reach a sill by C(h)
= gamma(inf) - gamma(h).
--
Edzer

facrimas at libero.it wrote:
> Dear guys,
>
> I want to use the indicator simple kriging with varying local mean on gstat.
>
> Do you have a script example about it?
>
> I do not understand which is the local mean that I have to put in the command 
> of simple indicator kriging.....
>
>  I do not also well understand whether if it is posssible to use the 
> semivariogram model in SK, because theory tells that it need the covariance 
> function.......
>
> Any suggest?
>
> Thank you.
>
> Cristiano
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From milton.ruser at gmail.com  Sun May 10 23:30:16 2009
From: milton.ruser at gmail.com (milton ruser)
Date: Sun, 10 May 2009 17:30:16 -0400
Subject: [R-sig-Geo] Fwd: clump of binary pixels on raster package
Message-ID: <3aaf1a030905101430x438c1008l33c01389b1347579@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090510/d1840030/attachment.pl>

From dylan.beaudette at gmail.com  Mon May 11 00:42:56 2009
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Sun, 10 May 2009 15:42:56 -0700
Subject: [R-sig-Geo] Fwd: clump of binary pixels on raster package
In-Reply-To: <3aaf1a030905101430x438c1008l33c01389b1347579@mail.gmail.com>
References: <3aaf1a030905101430x438c1008l33c01389b1347579@mail.gmail.com>
Message-ID: <3c5546140905101542i538e37c9je3c892e89ecca864@mail.gmail.com>

Hi,

What version of GRASS are you using? Have you asked on the GRASS list
regarding the slow r.clump [-ing] ?

Cheers,

Dylan

On Sun, May 10, 2009 at 2:30 PM, milton ruser <milton.ruser at gmail.com> wrote:
> Dear all,
>
> sorry for this double-posting, I know it is not a good idea,
> but may be this list is more appropriated for this issue.
>
> Thanks a lot
>
> milton
>
> ---------- Forwarded message ----------
> From: milton ruser <milton.ruser at gmail.com>
> Date: Sat, May 9, 2009 at 5:59 PM
> Subject: clump of binary pixels on raster
> To: "r-help at r-project.org" <r-help at r-project.org>
>
>
> Dear all,
>
> I have a set od 30,000 binary landscapes, which represent habitat and
> non-habitat cover.
> I need to generate images that identify those neighbour (rule 8) pixels as
> one patch ID,
> and a different patch ID for each clump of pixels. I coded it using
> labcon(adehabitat),
> but as some of my landscapes have so many patches, labcon not finish and
> entry in
> a eternal looping. By other side, I coded another solution using R & grass
> (r.clump),
> but the solution is so slow, and as I need to run it a lot of time, I will
> need about 3 weeks
> to finish... I was thinking if raster package could do the job fastly than
> R-grass.
> Below you can find a simulation of what I need. On the second image, each
> color
> have different values.
>
> MyMatrix<-matrix(rep(0,100), ncol=10)
> MyMatrix[2:4,3:6]<-1
> MyMatrix[7:8,1:3]<-1
> MyMatrix[8,7:8]<-1
> MyMatrix[8,7:8]<-1
> MyMatrix[6:7,8:9]<-1
> x11(800,400)
> par(mfrow=c(1,2))
> image(MyMatrix)
>
> MyClusters<-matrix(rep(0,100), ncol=10)
> MyClusters[2:4,3:6]<-1
> MyClusters[7:8,1:3]<-2
> MyClusters[8,7:8]<-3
> MyClusters[8,7:8]<-4
> MyClusters[6:7,8:9]<-4
> image(MyClusters, col=c("transparent", 1,3,4,5))
>
> Regards a lot,
>
> milton
> brazil=toronto.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From J.vanEtten at cgiar.org  Mon May 11 01:56:47 2009
From: J.vanEtten at cgiar.org (van Etten, Jacob (IRRI))
Date: Mon, 11 May 2009 07:56:47 +0800
Subject: [R-sig-Geo] Fwd: clump of binary pixels on raster package
In-Reply-To: <3aaf1a030905101430x438c1008l33c01389b1347579@mail.gmail.com>
References: <3aaf1a030905101430x438c1008l33c01389b1347579@mail.gmail.com>
Message-ID: <AFBF317E3DEC0B43BF750B4618EBFA0D01840E0F@HERMES>

This seems to be a connected components problem, discussed recently on
this list.

Jacob.

-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of milton ruser
Sent: Monday, May 11, 2009 5:30 AM
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] Fwd: clump of binary pixels on raster package

Dear all,

sorry for this double-posting, I know it is not a good idea,
but may be this list is more appropriated for this issue.

Thanks a lot

milton

---------- Forwarded message ----------
From: milton ruser <milton.ruser at gmail.com>
Date: Sat, May 9, 2009 at 5:59 PM
Subject: clump of binary pixels on raster
To: "r-help at r-project.org" <r-help at r-project.org>


Dear all,

I have a set od 30,000 binary landscapes, which represent habitat and
non-habitat cover.
I need to generate images that identify those neighbour (rule 8) pixels
as
one patch ID,
and a different patch ID for each clump of pixels. I coded it using
labcon(adehabitat),
but as some of my landscapes have so many patches, labcon not finish and
entry in
a eternal looping. By other side, I coded another solution using R &
grass
(r.clump),
but the solution is so slow, and as I need to run it a lot of time, I
will
need about 3 weeks
to finish... I was thinking if raster package could do the job fastly
than
R-grass.
Below you can find a simulation of what I need. On the second image,
each
color
have different values.

MyMatrix<-matrix(rep(0,100), ncol=10)
MyMatrix[2:4,3:6]<-1
MyMatrix[7:8,1:3]<-1
MyMatrix[8,7:8]<-1
MyMatrix[8,7:8]<-1
MyMatrix[6:7,8:9]<-1
x11(800,400)
par(mfrow=c(1,2))
image(MyMatrix)

MyClusters<-matrix(rep(0,100), ncol=10)
MyClusters[2:4,3:6]<-1
MyClusters[7:8,1:3]<-2
MyClusters[8,7:8]<-3
MyClusters[8,7:8]<-4
MyClusters[6:7,8:9]<-4
image(MyClusters, col=c("transparent", 1,3,4,5))

Regards a lot,

milton
brazil=toronto.

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From gerald.jurasinski at uni-rostock.de  Mon May 11 09:31:40 2009
From: gerald.jurasinski at uni-rostock.de (Dr. Gerald Jurasinski)
Date: Mon, 11 May 2009 09:31:40 +0200
Subject: [R-sig-Geo] Rotating hexagonal grid
Message-ID: <974C3AAC-D108-474A-84DC-D32AD94031E2@uni-rostock.de>

Dear List,

There is a nice implementation to create hexagonal grids in the sp  
package as an option to the spsample method. Many thanks to Edzer for  
this. In the ASDAR book on page 137 it is written: "Note that an  
alternative hexagonal representation is obtained by rotating this grid  
90?; we will not further consider that here". That's a pity because  
that is what I would like to do. So can you give a  hint on how to  
obtain grid rotations? In general and specifically for hexagonal grids  
(I guess it is the same)? And is it possible to rotate the grid easily  
with whatever angle wanted? Maybe it would be interesting to include  
the grid rotation as an example in the spsample help?

Thank you very much
Best regards
Gerald

??????????????????

Dr. Gerald Jurasinski
Landscape Ecology and Site Evaluation
Institute for Management of Rural Areas
Faculty of Agricultural and Environmental Sciences
University of Rostock
Justus-von-Liebig-Weg 6
18059 Rostock
Germany

gerald.jurasinski at uni-rostock.de
http://www.auf.uni-rostock.de/loe
+49 381 4983225 (tel)
+49 381 4983222 (fax)


From milton.ruser at gmail.com  Mon May 11 11:07:58 2009
From: milton.ruser at gmail.com (milton ruser)
Date: Mon, 11 May 2009 05:07:58 -0400
Subject: [R-sig-Geo] Rotating hexagonal grid
In-Reply-To: <974C3AAC-D108-474A-84DC-D32AD94031E2@uni-rostock.de>
References: <974C3AAC-D108-474A-84DC-D32AD94031E2@uni-rostock.de>
Message-ID: <3aaf1a030905110207u731cb2e3tf7f64aeb9e15ba43@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090511/669f54ef/attachment.pl>

From mike.elliott at openreach.co.uk  Mon May 11 11:24:49 2009
From: mike.elliott at openreach.co.uk (mike.elliott at openreach.co.uk)
Date: Mon, 11 May 2009 10:24:49 +0100
Subject: [R-sig-Geo] Interpolation / smoothing of points (without raster
	grids)
In-Reply-To: <30247661.908591241863564507.JavaMail.defaultUser@defaultHost>
Message-ID: <3D6621E58F6EA24C9D0CA72B2D8E15B305107DE1@E03MVB1-UKBR.domain1.systemhost.net>

Hello - can anyone suggest functions/packages that allow interpolation /
smoothing of point data (without using raster grids)? i.e. which give
the results at the original point locations.

Many thanks, Mike Elliott.


From edzer.pebesma at uni-muenster.de  Mon May 11 11:51:02 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 11 May 2009 11:51:02 +0200
Subject: [R-sig-Geo] Interpolation / smoothing of points (without raster
 grids)
In-Reply-To: <3D6621E58F6EA24C9D0CA72B2D8E15B305107DE1@E03MVB1-UKBR.domain1.systemhost.net>
References: <3D6621E58F6EA24C9D0CA72B2D8E15B305107DE1@E03MVB1-UKBR.domain1.systemhost.net>
Message-ID: <4A07F506.2090800@uni-muenster.de>

I think many can do this; package gstat is the first one that comes to
my mind ;-)
It can also do cross validation, anticipating your next question.
--
Edzer

mike.elliott at openreach.co.uk wrote:
> Hello - can anyone suggest functions/packages that allow interpolation /
> smoothing of point data (without using raster grids)? i.e. which give
> the results at the original point locations.
>
> Many thanks, Mike Elliott.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From wroberts at csir.co.za  Mon May 11 14:35:49 2009
From: wroberts at csir.co.za (Wesley Roberts)
Date: Mon, 11 May 2009 14:35:49 +0200
Subject: [R-sig-Geo] Classification of attribute table
In-Reply-To: <1241712829.7290.11.camel@whitebox>
References: <16393_1241701319_1241701319_4A02F717.8E3B.0073.0@csir.co.za>
	<1241712829.7290.11.camel@whitebox>
Message-ID: <4A0837C5.8E3B.0073.0@csir.co.za>

Hi Dan,

Thanks for the advice. I want to classify my data into three classes; canopy, non-canopy and ground based on six input variables. The input variables are mean, min, max, median, var, stdev, and kurtosis of spatially co-incident spectra associated with each segment. I have 1916 cases and the data are formatted like an ESRI attribute table, each row corresponds to one particular segment,
      mean  min  max  median  var  stdev  kurtosis
1    
2        values extracted from the imagery
3
.
.1916

I would thus like to classify the segments into three classes and essentially add an additional column to the attribute table with values 1, 2, and 3 denoting the class of the particular segment. Ideally the classification must be un-supervised as the whole procedure should be as automatic as possible with limited input from the user. Initially I wanted to use lda (MASS) but it required training classes. 

An alternative option is to use the hypothesis that segments with brighter spectra are more likely to come from tree crowns and thus just subset / select the segments which fall into for example the 90th percentile and label those as tree crowns.

Many thanks,
Wesley

 

Wesley Roberts MSc.
Researcher: Earth Observation (Ecosystems)
Natural Resources and the Environment
CSIR
Tel: +27 (21) 888-2490
Fax: +27 (21) 888-2693

"To know the road ahead, ask those coming back."
- Chinese proverb



>>> Dan Putler <dan.putler at sauder.ubc.ca> 05/07/09 6:13 PM >>> 
Hi Wesley,

Is this classification problem or a clustering problem? Specifically, is
the ultimate goal to predict what segment a new polygon belongs in, or
are you trying to form 3 segments to begin with based on the six
measures you have available? If it is the latter, it is a cluster
analysis problem rather than a classification problem, and you'll want
to look at the Cluster Analysis and Finite Mixture Models task view at
http://cran.r-project.org/web/views/Cluster.html.

Dan

On Thu, 2009-05-07 at 14:58 +0200, Wesley Roberts wrote:
> Dear R-sig-geo users,
> 
> I have the output of a watershed segmentation in vector format (shapefile) which has it's attribute table populated with statistics regarding spectral reflectance of each polygon object. The attribute data was sourced from a geographically co-incident aerial photograph. I would now like to classify the segments using the attribute data. This seems like an easy task but I am struggling to find a suitable method. I have looked at 'lda' and 'qda' in the MASS package but the selection of an appropriate model using 'cv1EMtrain' takes a really long time. In essence all I want to do is classify the 6 variable data set into 3 classes with the class for each case recorded in the attribute table. 
> 
> Any advice or suggestions would be greatly appreciated.
> 
> Many thanks and kind regards,
> Wesley
> 
> 
> 
> Wesley Roberts MSc.
> Researcher: Earth Observation (Ecosystems)
> Natural Resources and the Environment
> CSIR
> Tel: +27 (21) 888-2490
> Fax: +27 (21) 888-2693
> 
> "To know the road ahead, ask those coming back."
> - Chinese proverb
> 
> 
> 
> 
-- 
Dan Putler
Sauder School of Business
University of British Columbia



-- 
This message is subject to the CSIR's copyright terms and conditions, e-mail legal notice, and implemented Open Document Format (ODF) standard. 
The full disclaimer details can be found at http://www.csir.co.za/disclaimer.html.

This message has been scanned for viruses and dangerous content by MailScanner, 
and is believed to be clean.  MailScanner thanks Transtec Computers for their support.


From Thierry.ONKELINX at inbo.be  Mon May 11 15:49:25 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 11 May 2009 15:49:25 +0200
Subject: [R-sig-Geo] Classification of attribute table
In-Reply-To: <4A0837C5.8E3B.0073.0@csir.co.za>
References: <16393_1241701319_1241701319_4A02F717.8E3B.0073.0@csir.co.za><1241712829.7290.11.camel@whitebox>
	<4A0837C5.8E3B.0073.0@csir.co.za>
Message-ID: <2E9C414912813E4EB981326983E0A1040682817E@inboexch.inbo.be>

Dear Wesley,

Have a look a kmeans clustering. That will allow you to divide the data
points in a given number of clusters without any other user input.

HTH,

Thierry


------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens Wesley Roberts
Verzonden: maandag 11 mei 2009 14:36
Aan: Dan Putler
CC: r-sig-geo at stat.math.ethz.ch
Onderwerp: Re: [R-sig-Geo] Classification of attribute table

Hi Dan,

Thanks for the advice. I want to classify my data into three classes;
canopy, non-canopy and ground based on six input variables. The input
variables are mean, min, max, median, var, stdev, and kurtosis of
spatially co-incident spectra associated with each segment. I have 1916
cases and the data are formatted like an ESRI attribute table, each row
corresponds to one particular segment,
      mean  min  max  median  var  stdev  kurtosis
1    
2        values extracted from the imagery
3
.
.1916

I would thus like to classify the segments into three classes and
essentially add an additional column to the attribute table with values
1, 2, and 3 denoting the class of the particular segment. Ideally the
classification must be un-supervised as the whole procedure should be as
automatic as possible with limited input from the user. Initially I
wanted to use lda (MASS) but it required training classes. 

An alternative option is to use the hypothesis that segments with
brighter spectra are more likely to come from tree crowns and thus just
subset / select the segments which fall into for example the 90th
percentile and label those as tree crowns.

Many thanks,
Wesley



Wesley Roberts MSc.
Researcher: Earth Observation (Ecosystems)
Natural Resources and the Environment
CSIR
Tel: +27 (21) 888-2490
Fax: +27 (21) 888-2693

"To know the road ahead, ask those coming back."
- Chinese proverb



>>> Dan Putler <dan.putler at sauder.ubc.ca> 05/07/09 6:13 PM >>> 
Hi Wesley,

Is this classification problem or a clustering problem? Specifically, is
the ultimate goal to predict what segment a new polygon belongs in, or
are you trying to form 3 segments to begin with based on the six
measures you have available? If it is the latter, it is a cluster
analysis problem rather than a classification problem, and you'll want
to look at the Cluster Analysis and Finite Mixture Models task view at
http://cran.r-project.org/web/views/Cluster.html.

Dan

On Thu, 2009-05-07 at 14:58 +0200, Wesley Roberts wrote:
> Dear R-sig-geo users,
> 
> I have the output of a watershed segmentation in vector format
(shapefile) which has it's attribute table populated with statistics
regarding spectral reflectance of each polygon object. The attribute
data was sourced from a geographically co-incident aerial photograph. I
would now like to classify the segments using the attribute data. This
seems like an easy task but I am struggling to find a suitable method. I
have looked at 'lda' and 'qda' in the MASS package but the selection of
an appropriate model using 'cv1EMtrain' takes a really long time. In
essence all I want to do is classify the 6 variable data set into 3
classes with the class for each case recorded in the attribute table. 
> 
> Any advice or suggestions would be greatly appreciated.
> 
> Many thanks and kind regards,
> Wesley
> 
> 
> 
> Wesley Roberts MSc.
> Researcher: Earth Observation (Ecosystems)
> Natural Resources and the Environment
> CSIR
> Tel: +27 (21) 888-2490
> Fax: +27 (21) 888-2693
> 
> "To know the road ahead, ask those coming back."
> - Chinese proverb
> 
> 
> 
> 
-- 
Dan Putler
Sauder School of Business
University of British Columbia



-- 
This message is subject to the CSIR's copyright terms and conditions,
e-mail legal notice, and implemented Open Document Format (ODF)
standard. 
The full disclaimer details can be found at
http://www.csir.co.za/disclaimer.html.

This message has been scanned for viruses and dangerous content by
MailScanner, 
and is believed to be clean.  MailScanner thanks Transtec Computers for
their support.

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.


From dylan.beaudette at gmail.com  Mon May 11 16:44:12 2009
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Mon, 11 May 2009 07:44:12 -0700
Subject: [R-sig-Geo] Classification of attribute table
In-Reply-To: <4A0837C5.8E3B.0073.0@csir.co.za>
References: <16393_1241701319_1241701319_4A02F717.8E3B.0073.0@csir.co.za>
	<1241712829.7290.11.camel@whitebox> <4A0837C5.8E3B.0073.0@csir.co.za>
Message-ID: <3c5546140905110744g37d449b4q5b96789570c41c3@mail.gmail.com>

See the clara() function from the cluster package. It scales fairly
well to larger-sizes data sets.

Cheers,
Dylan

On Mon, May 11, 2009 at 5:35 AM, Wesley Roberts <wroberts at csir.co.za> wrote:
> Hi Dan,
>
> Thanks for the advice. I want to classify my data into three classes; canopy, non-canopy and ground based on six input variables. The input variables are mean, min, max, median, var, stdev, and kurtosis of spatially co-incident spectra associated with each segment. I have 1916 cases and the data are formatted like an ESRI attribute table, each row corresponds to one particular segment,
> ? ? ?mean ?min ?max ?median ?var ?stdev ?kurtosis
> 1
> 2 ? ? ? ?values extracted from the imagery
> 3
> .
> .1916
>
> I would thus like to classify the segments into three classes and essentially add an additional column to the attribute table with values 1, 2, and 3 denoting the class of the particular segment. Ideally the classification must be un-supervised as the whole procedure should be as automatic as possible with limited input from the user. Initially I wanted to use lda (MASS) but it required training classes.
>
> An alternative option is to use the hypothesis that segments with brighter spectra are more likely to come from tree crowns and thus just subset / select the segments which fall into for example the 90th percentile and label those as tree crowns.
>
> Many thanks,
> Wesley
>
>
>
> Wesley Roberts MSc.
> Researcher: Earth Observation (Ecosystems)
> Natural Resources and the Environment
> CSIR
> Tel: +27 (21) 888-2490
> Fax: +27 (21) 888-2693
>
> "To know the road ahead, ask those coming back."
> - Chinese proverb
>
>
>
>>>> Dan Putler <dan.putler at sauder.ubc.ca> 05/07/09 6:13 PM >>>
> Hi Wesley,
>
> Is this classification problem or a clustering problem? Specifically, is
> the ultimate goal to predict what segment a new polygon belongs in, or
> are you trying to form 3 segments to begin with based on the six
> measures you have available? If it is the latter, it is a cluster
> analysis problem rather than a classification problem, and you'll want
> to look at the Cluster Analysis and Finite Mixture Models task view at
> http://cran.r-project.org/web/views/Cluster.html.
>
> Dan
>
> On Thu, 2009-05-07 at 14:58 +0200, Wesley Roberts wrote:
>> Dear R-sig-geo users,
>>
>> I have the output of a watershed segmentation in vector format (shapefile) which has it's attribute table populated with statistics regarding spectral reflectance of each polygon object. The attribute data was sourced from a geographically co-incident aerial photograph. I would now like to classify the segments using the attribute data. This seems like an easy task but I am struggling to find a suitable method. I have looked at 'lda' and 'qda' in the MASS package but the selection of an appropriate model using 'cv1EMtrain' takes a really long time. In essence all I want to do is classify the 6 variable data set into 3 classes with the class for each case recorded in the attribute table.
>>
>> Any advice or suggestions would be greatly appreciated.
>>
>> Many thanks and kind regards,
>> Wesley
>>
>>
>>
>> Wesley Roberts MSc.
>> Researcher: Earth Observation (Ecosystems)
>> Natural Resources and the Environment
>> CSIR
>> Tel: +27 (21) 888-2490
>> Fax: +27 (21) 888-2693
>>
>> "To know the road ahead, ask those coming back."
>> - Chinese proverb
>>
>>
>>
>>
> --
> Dan Putler
> Sauder School of Business
> University of British Columbia
>
>
>
> --
> This message is subject to the CSIR's copyright terms and conditions, e-mail legal notice, and implemented Open Document Format (ODF) standard.
> The full disclaimer details can be found at http://www.csir.co.za/disclaimer.html.
>
> This message has been scanned for viruses and dangerous content by MailScanner,
> and is believed to be clean. ?MailScanner thanks Transtec Computers for their support.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From dan.putler at sauder.ubc.ca  Mon May 11 17:54:19 2009
From: dan.putler at sauder.ubc.ca (Dan Putler)
Date: Mon, 11 May 2009 08:54:19 -0700
Subject: [R-sig-Geo] Classification of attribute table
In-Reply-To: <3c5546140905110744g37d449b4q5b96789570c41c3@mail.gmail.com>
References: <16393_1241701319_1241701319_4A02F717.8E3B.0073.0@csir.co.za>
	<1241712829.7290.11.camel@whitebox> <4A0837C5.8E3B.0073.0@csir.co.za>
	<3c5546140905110744g37d449b4q5b96789570c41c3@mail.gmail.com>
Message-ID: <1242057259.6764.11.camel@whitebox>

Hi Wesley,

So you just want to partition the 1916 cases into three clusters. This
is a clustering problem rather than a discriminant analysis oriented
classification problem. As a result, Dylan Beaudette's suggestion of
using the clara() function is pretty reasonable, but your data set isn't
so large that other (more computationally intensive) algorithms can't be
used (assuming you have a machine with a reasonable amount of memory in
it). Moreover, some of your measures are very highly correlated with one
another (var and stdev for instance), so you can probably reduce the
number of variables used in the clustering.

Is the 1916 cases fixed, or will you want to take new cases and then
assign them to one of the three clusters created using the original
1916? If this is the case, using model based clustering might make the
most sense since you have a clean way of assigning new cases to the
existing clusters based on the posterior probability of cluster
membership.

Dan

On Mon, 2009-05-11 at 07:44 -0700, Dylan Beaudette wrote:
> See the clara() function from the cluster package. It scales fairly
> well to larger-sizes data sets.
> 
> Cheers,
> Dylan
> 
> On Mon, May 11, 2009 at 5:35 AM, Wesley Roberts <wroberts at csir.co.za> wrote:
> > Hi Dan,
> >
> > Thanks for the advice. I want to classify my data into three classes; canopy, non-canopy and ground based on six input variables. The input variables are mean, min, max, median, var, stdev, and kurtosis of spatially co-incident spectra associated with each segment. I have 1916 cases and the data are formatted like an ESRI attribute table, each row corresponds to one particular segment,
> >      mean  min  max  median  var  stdev  kurtosis
> > 1
> > 2        values extracted from the imagery
> > 3
> > .
> > .1916
> >
> > I would thus like to classify the segments into three classes and essentially add an additional column to the attribute table with values 1, 2, and 3 denoting the class of the particular segment. Ideally the classification must be un-supervised as the whole procedure should be as automatic as possible with limited input from the user. Initially I wanted to use lda (MASS) but it required training classes.
> >
> > An alternative option is to use the hypothesis that segments with brighter spectra are more likely to come from tree crowns and thus just subset / select the segments which fall into for example the 90th percentile and label those as tree crowns.
> >
> > Many thanks,
> > Wesley
> >
> >
> >
> > Wesley Roberts MSc.
> > Researcher: Earth Observation (Ecosystems)
> > Natural Resources and the Environment
> > CSIR
> > Tel: +27 (21) 888-2490
> > Fax: +27 (21) 888-2693
> >
> > "To know the road ahead, ask those coming back."
> > - Chinese proverb
> >
> >
> >
> >>>> Dan Putler <dan.putler at sauder.ubc.ca> 05/07/09 6:13 PM >>>
> > Hi Wesley,
> >
> > Is this classification problem or a clustering problem? Specifically, is
> > the ultimate goal to predict what segment a new polygon belongs in, or
> > are you trying to form 3 segments to begin with based on the six
> > measures you have available? If it is the latter, it is a cluster
> > analysis problem rather than a classification problem, and you'll want
> > to look at the Cluster Analysis and Finite Mixture Models task view at
> > http://cran.r-project.org/web/views/Cluster.html.
> >
> > Dan
> >
> > On Thu, 2009-05-07 at 14:58 +0200, Wesley Roberts wrote:
> >> Dear R-sig-geo users,
> >>
> >> I have the output of a watershed segmentation in vector format (shapefile) which has it's attribute table populated with statistics regarding spectral reflectance of each polygon object. The attribute data was sourced from a geographically co-incident aerial photograph. I would now like to classify the segments using the attribute data. This seems like an easy task but I am struggling to find a suitable method. I have looked at 'lda' and 'qda' in the MASS package but the selection of an appropriate model using 'cv1EMtrain' takes a really long time. In essence all I want to do is classify the 6 variable data set into 3 classes with the class for each case recorded in the attribute table.
> >>
> >> Any advice or suggestions would be greatly appreciated.
> >>
> >> Many thanks and kind regards,
> >> Wesley
> >>
> >>
> >>
> >> Wesley Roberts MSc.
> >> Researcher: Earth Observation (Ecosystems)
> >> Natural Resources and the Environment
> >> CSIR
> >> Tel: +27 (21) 888-2490
> >> Fax: +27 (21) 888-2693
> >>
> >> "To know the road ahead, ask those coming back."
> >> - Chinese proverb
> >>
> >>
> >>
> >>
> > --
> > Dan Putler
> > Sauder School of Business
> > University of British Columbia
> >
> >
> >
> > --
> > This message is subject to the CSIR's copyright terms and conditions, e-mail legal notice, and implemented Open Document Format (ODF) standard.
> > The full disclaimer details can be found at http://www.csir.co.za/disclaimer.html.
> >
> > This message has been scanned for viruses and dangerous content by MailScanner,
> > and is believed to be clean.  MailScanner thanks Transtec Computers for their support.
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
-- 
Dan Putler
Sauder School of Business
University of British Columbia


From milton.ruser at gmail.com  Mon May 11 20:04:24 2009
From: milton.ruser at gmail.com (milton ruser)
Date: Mon, 11 May 2009 14:04:24 -0400
Subject: [R-sig-Geo] Fwd: clump of binary pixels on raster package
In-Reply-To: <AFBF317E3DEC0B43BF750B4618EBFA0D01840E0F@HERMES>
References: <3aaf1a030905101430x438c1008l33c01389b1347579@mail.gmail.com>
	<AFBF317E3DEC0B43BF750B4618EBFA0D01840E0F@HERMES>
Message-ID: <3aaf1a030905111104x6eb7c06dl3f899c8ac1121a1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090511/09681aeb/attachment.pl>

From Greg.Snow at imail.org  Mon May 11 21:56:34 2009
From: Greg.Snow at imail.org (Greg Snow)
Date: Mon, 11 May 2009 13:56:34 -0600
Subject: [R-sig-Geo] Rotating hexagonal grid
In-Reply-To: <974C3AAC-D108-474A-84DC-D32AD94031E2@uni-rostock.de>
References: <974C3AAC-D108-474A-84DC-D32AD94031E2@uni-rostock.de>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61D1C0C4B9@LP-EXMBVS10.CO.IHC.COM>

The last example in the help page for the my.symbols function in the TeachingDemos package shows a way to hand build a hexagonal grid, rotating this 90 degrees would not be difficult (interfacing it with whatever other tools you are using in sp may or may not be depending on what you are trying to do).

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-
> bounces at stat.math.ethz.ch] On Behalf Of Dr. Gerald Jurasinski
> Sent: Monday, May 11, 2009 1:32 AM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] Rotating hexagonal grid
> 
> Dear List,
> 
> There is a nice implementation to create hexagonal grids in the sp
> package as an option to the spsample method. Many thanks to Edzer for
> this. In the ASDAR book on page 137 it is written: "Note that an
> alternative hexagonal representation is obtained by rotating this grid
> 90?; we will not further consider that here". That's a pity because
> that is what I would like to do. So can you give a  hint on how to
> obtain grid rotations? In general and specifically for hexagonal grids
> (I guess it is the same)? And is it possible to rotate the grid easily
> with whatever angle wanted? Maybe it would be interesting to include
> the grid rotation as an example in the spsample help?
> 
> Thank you very much
> Best regards
> Gerald
> 
> ------------------
> 
> Dr. Gerald Jurasinski
> Landscape Ecology and Site Evaluation
> Institute for Management of Rural Areas
> Faculty of Agricultural and Environmental Sciences
> University of Rostock
> Justus-von-Liebig-Weg 6
> 18059 Rostock
> Germany
> 
> gerald.jurasinski at uni-rostock.de
> http://www.auf.uni-rostock.de/loe
> +49 381 4983225 (tel)
> +49 381 4983222 (fax)
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From J.vanEtten at cgiar.org  Tue May 12 05:45:58 2009
From: J.vanEtten at cgiar.org (van Etten, Jacob (IRRI))
Date: Tue, 12 May 2009 11:45:58 +0800
Subject: [R-sig-Geo] Fwd: clump of binary pixels on raster package
In-Reply-To: <3aaf1a030905111104x6eb7c06dl3f899c8ac1121a1@mail.gmail.com>
References: <3aaf1a030905101430x438c1008l33c01389b1347579@mail.gmail.com>
	<AFBF317E3DEC0B43BF750B4618EBFA0D01840E0F@HERMES>
	<3aaf1a030905111104x6eb7c06dl3f899c8ac1121a1@mail.gmail.com>
Message-ID: <AFBF317E3DEC0B43BF750B4618EBFA0D0188B22E@HERMES>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090512/e8b8bfb3/attachment.pl>

From J.vanEtten at cgiar.org  Tue May 12 07:17:46 2009
From: J.vanEtten at cgiar.org (van Etten, Jacob (IRRI))
Date: Tue, 12 May 2009 13:17:46 +0800
Subject: [R-sig-Geo] Fwd: clump of binary pixels on raster package
In-Reply-To: <AFBF317E3DEC0B43BF750B4618EBFA0D0188B22E@HERMES>
References: <3aaf1a030905101430x438c1008l33c01389b1347579@mail.gmail.com><AFBF317E3DEC0B43BF750B4618EBFA0D01840E0F@HERMES><3aaf1a030905111104x6eb7c06dl3f899c8ac1121a1@mail.gmail.com>
	<AFBF317E3DEC0B43BF750B4618EBFA0D0188B22E@HERMES>
Message-ID: <AFBF317E3DEC0B43BF750B4618EBFA0D0188B314@HERMES>

Now I realize that the function I sent earlier drops single-cell
patches, which might be a problem.

This version of the function takes them into account: 

clumps <- function(MM)
{
	val <- which(values(MM)==1)
	adj <- adjacency(MM,val,val,directions=8)
	adjv <- as.vector(t(adj))
	g <- graph(adjv, directed=FALSE)
	cl <- clusters(g)
	memb <- cl$membership[val+1]
	MC <- raster(MM)
	MC[val] <- memb
	return(MC)
}

Roughly same speed.

-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of van Etten,
Jacob (IRRI)
Sent: Tuesday, May 12, 2009 11:46 AM
To: milton ruser
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] Fwd: clump of binary pixels on raster package

Clumps (patches) from binary pixels

 

This is a solution using raster and igraph. 

 

(It seems that a raster only solution is underway.) 

 

=========================

 

install.packages("raster",repos="r-forge.r-project.org")

 

require(raster)

require(igraph)

 

#New function to make clumps, MM is a Raster object

 

clumps <- function(MM)

{

            adj <-
adjacency(MM,which(values(MM)==1),which(values(MM)==1),directions=8)

            adjv <- as.vector(t(adj))

            g <- graph(adjv, directed=FALSE)

            cl <- clusters(g)

            memb <- cbind(0:(length(cl$membership)-1),cl$membership)

            memb <- memb[memb[,2] %in% (which(cl$csize>1)-1),]

            MC <- raster(MM)

            MC[memb[,1]] <- memb[,2]

            return(MC)

}

 

#Your example

 

MyMatrix<-matrix(rep(0,100), ncol=10)

MyMatrix[2:4,3:6]<-1

MyMatrix[7:8,1:3]<-1

MyMatrix[8,7:8]<-1

MyMatrix[8,7:8]<-1

MyMatrix[6:7,8:9]<-1

 

# Make a raster from the matrix

MM <- raster(MyMatrix)

 

# Make a raster with clumps

MC <- clumps(MM)

 

#Make a matrix from it again

MyClusters <- matrix(values(MC),nrow=10,ncol=10)

image(MyClusters)

 

#Time evaluation with 100 500x500 rasters with random values (0,1)

eval <- function()

{

for(i in 1:100)

{

r1 <- raster(proj="",nrows=500,ncols=500)

r1[] <- sample(c(0,1), ncell(r1), replace=T)

clumps(r1)

}

}

 

system.time(eval())

 

====================================

 

My computer did this:

 

   user  system elapsed 

117.42        9.89  127.66 

 

This does not seem to run into problems. I have not compared with the
alternatives, but would be interested to know.

 

Jacob van Etten

________________________________

From: milton ruser [mailto:milton.ruser at gmail.com] 
Sent: Tuesday, May 12, 2009 2:04 AM
To: van Etten, Jacob (IRRI)
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] Fwd: clump of binary pixels on raster package



Dear Dylan and Jacob,



In fact I not wrote to GRASS list, because it is working grass, and as
my images are about 512x512, grass can deal with the r.clump without
problem. But it takes about 1min for each image (i have other steps not
mentioned that sum this 1min), and as I have about 30,000 images, it is
so many time.



Labcon/adehabitat is fast then r.clump/grass, but some times when images
have so many clumps, labcon() not finish the task, and not go to next
image (it appears like a spiral processing, without end). So labcon, for
this job, is not a good solution for me.



I was thinking about raster package, but the discussed issued on the
list not give - apparently - a solution like that one I need (see the
sample code).



By the way, I am running Vista on a dell 6GB ram machine.



Any other suggestion are welcome.



milton

brazil=toronto

On Sun, May 10, 2009 at 7:56 PM, van Etten, Jacob (IRRI)
<J.vanEtten at cgiar.org> wrote:

This seems to be a connected components problem, discussed recently on
this list.

Jacob.


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of milton ruser
Sent: Monday, May 11, 2009 5:30 AM
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] Fwd: clump of binary pixels on raster package

Dear all,

sorry for this double-posting, I know it is not a good idea,
but may be this list is more appropriated for this issue.

Thanks a lot

milton

---------- Forwarded message ----------
From: milton ruser <milton.ruser at gmail.com>
Date: Sat, May 9, 2009 at 5:59 PM
Subject: clump of binary pixels on raster
To: "r-help at r-project.org" <r-help at r-project.org>


Dear all,

I have a set od 30,000 binary landscapes, which represent habitat and
non-habitat cover.
I need to generate images that identify those neighbour (rule 8) pixels
as
one patch ID,
and a different patch ID for each clump of pixels. I coded it using
labcon(adehabitat),
but as some of my landscapes have so many patches, labcon not finish and
entry in
a eternal looping. By other side, I coded another solution using R &
grass
(r.clump),
but the solution is so slow, and as I need to run it a lot of time, I
will
need about 3 weeks
to finish... I was thinking if raster package could do the job fastly
than
R-grass.
Below you can find a simulation of what I need. On the second image,
each
color
have different values.

MyMatrix<-matrix(rep(0,100), ncol=10)
MyMatrix[2:4,3:6]<-1
MyMatrix[7:8,1:3]<-1
MyMatrix[8,7:8]<-1
MyMatrix[8,7:8]<-1
MyMatrix[6:7,8:9]<-1
x11(800,400)
par(mfrow=c(1,2))
image(MyMatrix)

MyClusters<-matrix(rep(0,100), ncol=10)
MyClusters[2:4,3:6]<-1
MyClusters[7:8,1:3]<-2
MyClusters[8,7:8]<-3
MyClusters[8,7:8]<-4
MyClusters[6:7,8:9]<-4
image(MyClusters, col=c("transparent", 1,3,4,5))

Regards a lot,

milton
brazil=toronto.

       [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo




	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From adrian at maths.uwa.edu.au  Tue May 12 10:15:14 2009
From: adrian at maths.uwa.edu.au (Adrian Baddeley)
Date: Tue, 12 May 2009 16:15:14 +0800
Subject: [R-sig-Geo] Interpolation / smoothing of points (without raster
	grids)
Message-ID: <4A093012.5020305@maths.uwa.edu.au>

Mike Elliott wrote:

 > can anyone suggest functions/packages that allow interpolation / 
smoothing
 > of point data (without using raster grids)? i.e. which give the 
results at the
 > original point locations.

The next version of spatstat (version 1.15-3) contains a function 
'densityatpoints' that
does this. It will be released in a day or two.

Adrian Baddeley


From mike.elliott at openreach.co.uk  Tue May 12 10:20:07 2009
From: mike.elliott at openreach.co.uk (mike.elliott at openreach.co.uk)
Date: Tue, 12 May 2009 09:20:07 +0100
Subject: [R-sig-Geo] Interpolation / smoothing of points (without raster
	grids)
In-Reply-To: <4A093012.5020305@maths.uwa.edu.au>
Message-ID: <3D6621E58F6EA24C9D0CA72B2D8E15B305173970@E03MVB1-UKBR.domain1.systemhost.net>

Adrian - will it allow a smoothing approach similar to a Gaussian
Kernel? Thankyou, Mike.

-----Original Message-----
From: Adrian Baddeley [mailto:adrian at maths.uwa.edu.au] 
Sent: 12 May 2009 09:15
To: Elliott,MR,Mike,BMK6 R; r-sig-geo at stat.math.ethz.ch
Subject: Interpolation / smoothing of points (without raster grids)

Mike Elliott wrote:

 > can anyone suggest functions/packages that allow interpolation /
smoothing  > of point data (without using raster grids)? i.e. which give
the results at the  > original point locations.

The next version of spatstat (version 1.15-3) contains a function
'densityatpoints' that does this. It will be released in a day or two.

Adrian Baddeley


From facrimas at libero.it  Tue May 12 10:29:05 2009
From: facrimas at libero.it (facrimas at libero.it)
Date: Tue, 12 May 2009 10:29:05 +0200 (CEST)
Subject: [R-sig-Geo] R: Re: indicator simple kriging with varying local mean
 on	gstat
Message-ID: <3456531.1055861242116945380.JavaMail.defaultUser@defaultHost>

Dear Edzer, 

Thanks for the answer, but I still have problems.....

II want to apply the indicator simple kriging with varying local mean, 
considering secondary exaustive information.
So, with the command subset I split the primary attribute belong to the 
respective class of the secondary information.

for instance:

>data.Ni1<-subset(jura.pred, jura.pred$Ni<15)

>data.Ni2<-subset(jura.pred, (jura.pred$Ni<=25 & jura.pred$Ni>15))

>data.Ni3<-subset(jura.pred, jura.pred$Ni>=25)

Then  I evaluate the percentage of value smaller than a threshold value, and 
I obtain an exaussive set of soft indicator data, defined as:

                              y(u;zk)= Prob {Z(u)<=zk : secondary information 
at u}   (test: Goovaerts - pag. 307)

with this value I calculate the residual respect at Indicator data that 
account for all available informations, and bulid the residual semivariogram.

Using that one, I want apply the simple indicator kriging, with the command

>resCd.4th.krige<-krige(data.Ni1$res.4thCd.1Ni~1, location=data.Ni1, 
newdata=grd, model = res.4thCd.1Ni.model, beta=VECTOR)

I use a local mean, but I have problems

than, I use a constant mean, and the error is:

         "gstat: value not allowed for: covariance from non-transitive 
variogram not allowed "

Theory give that in steady assumption, we have:

     C(h)=C(0)-gamma(h)

Can I put that in command krige?

Help me, please.....  I ended my ideas........................

grazie

Cristiano

>----Messaggio originale----
>Da: edzer.pebesma at uni-muenster.de
>Data: 10/05/2009 22.41
>A: "facrimas at libero.it"<facrimas at libero.it>
>Cc: <mike.elliott at openreach.co.uk>, <r-sig-geo at stat.math.ethz.ch>
>Ogg: Re: [R-sig-Geo] indicator simple kriging with varying local mean on	
gstat
>
>The simplest solution might be to just (simple) krige the residuals, and
>add them to your known varying mean.
>
>Please be aware that this "model" suggests residuals have mean-dependent
>variance (p * (1-p)), and thus using a single variogram model for the
>full set of residuals is not in accordance with theory.
>
>I guess that this problem is larger than the one you mention --
>covariances are simply derived from variograms that reach a sill by C(h)
>= gamma(inf) - gamma(h).
>--
>Edzer
>
>facrimas at libero.it wrote:
>> Dear guys,
>>
>> I want to use the indicator simple kriging with varying local mean on 
gstat.
>>
>> Do you have a script example about it?
>>
>> I do not understand which is the local mean that I have to put in the 
command 
>> of simple indicator kriging.....
>>
>>  I do not also well understand whether if it is posssible to use the 
>> semivariogram model in SK, because theory tells that it need the 
covariance 
>> function.......
>>
>> Any suggest?
>>
>> Thank you.
>>
>> Cristiano
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>   
>


From wroberts at csir.co.za  Tue May 12 11:10:51 2009
From: wroberts at csir.co.za (Wesley Roberts)
Date: Tue, 12 May 2009 11:10:51 +0200
Subject: [R-sig-Geo] Classification of attribute table
In-Reply-To: <1242057259.6764.11.camel@whitebox>
References: <16393_1241701319_1241701319_4A02F717.8E3B.0073.0@csir.co.za>
	<1241712829.7290.11.camel@whitebox> <4A0837C5.8E3B.0073.0@csir.co.za>
	<3c5546140905110744g37d449b4q5b96789570c41c3@mail.gmail.com>
	<1242057259.6764.11.camel@whitebox>
Message-ID: <4A09593B.8E3B.0073.0@csir.co.za>

Hi Dan, Dylan, Thierry & the rest of the list

Firstly, thanks for your input so far. Unfortunately I am running out of time as I need to get the analysis complete before IGARSS 09 in Cape Town so I don't think I will be able to implement your suggestions. In the meantime I have just selected segments which are above the 50th percentile and used those for further analysis (segments containing brighter values are considered tree crowns). I am not sure if classification could improve my tree counting accuracy, my intial results return +-70% accuracy when compared to field enumeration which I can improve upon by tweaking the watershed segmentation.

To answer your question Dan, the 1916 cases are fixed with no additional cases, although the same analysis will be applied in at least 10 other discrete plantation forest compartments. Perhaps the probability of cluster membership could be used in the rest of the compartments based on the initial clustering, not sure if that will work but could be interesting to test for the paper associated with this work.

Once I have finished the poster for IGARSS I will revisit the classification as this work is the final chapter of my PhD and would like to get it published.

Many thanks to the list for all your assistance.
Kind regards,
Wesley
 

Wesley Roberts MSc.
Researcher: Earth Observation (Ecosystems)
Natural Resources and the Environment
CSIR
Tel: +27 (21) 888-2490
Fax: +27 (21) 888-2693

"To know the road ahead, ask those coming back."
- Chinese proverb



>>> Dan Putler <dan.putler at sauder.ubc.ca> 05/11/09 5:54 PM >>> 
Hi Wesley,

So you just want to partition the 1916 cases into three clusters. This
is a clustering problem rather than a discriminant analysis oriented
classification problem. As a result, Dylan Beaudette's suggestion of
using the clara() function is pretty reasonable, but your data set isn't
so large that other (more computationally intensive) algorithms can't be
used (assuming you have a machine with a reasonable amount of memory in
it). Moreover, some of your measures are very highly correlated with one
another (var and stdev for instance), so you can probably reduce the
number of variables used in the clustering.

Is the 1916 cases fixed, or will you want to take new cases and then
assign them to one of the three clusters created using the original
1916? If this is the case, using model based clustering might make the
most sense since you have a clean way of assigning new cases to the
existing clusters based on the posterior probability of cluster
membership.

Dan

On Mon, 2009-05-11 at 07:44 -0700, Dylan Beaudette wrote:
> See the clara() function from the cluster package. It scales fairly
> well to larger-sizes data sets.
> 
> Cheers,
> Dylan
> 
> On Mon, May 11, 2009 at 5:35 AM, Wesley Roberts <wroberts at csir.co.za> wrote:
> > Hi Dan,
> >
> > Thanks for the advice. I want to classify my data into three classes; canopy, non-canopy and ground based on six input variables. The input variables are mean, min, max, median, var, stdev, and kurtosis of spatially co-incident spectra associated with each segment. I have 1916 cases and the data are formatted like an ESRI attribute table, each row corresponds to one particular segment,
> >      mean  min  max  median  var  stdev  kurtosis
> > 1
> > 2        values extracted from the imagery
> > 3
> > .
> > .1916
> >
> > I would thus like to classify the segments into three classes and essentially add an additional column to the attribute table with values 1, 2, and 3 denoting the class of the particular segment. Ideally the classification must be un-supervised as the whole procedure should be as automatic as possible with limited input from the user. Initially I wanted to use lda (MASS) but it required training classes.
> >
> > An alternative option is to use the hypothesis that segments with brighter spectra are more likely to come from tree crowns and thus just subset / select the segments which fall into for example the 90th percentile and label those as tree crowns.
> >
> > Many thanks,
> > Wesley
> >
> >
> >
> > Wesley Roberts MSc.
> > Researcher: Earth Observation (Ecosystems)
> > Natural Resources and the Environment
> > CSIR
> > Tel: +27 (21) 888-2490
> > Fax: +27 (21) 888-2693
> >
> > "To know the road ahead, ask those coming back."
> > - Chinese proverb
> >
> >
> >
> >>>> Dan Putler <dan.putler at sauder.ubc.ca> 05/07/09 6:13 PM >>>
> > Hi Wesley,
> >
> > Is this classification problem or a clustering problem? Specifically, is
> > the ultimate goal to predict what segment a new polygon belongs in, or
> > are you trying to form 3 segments to begin with based on the six
> > measures you have available? If it is the latter, it is a cluster
> > analysis problem rather than a classification problem, and you'll want
> > to look at the Cluster Analysis and Finite Mixture Models task view at
> > http://cran.r-project.org/web/views/Cluster.html.
> >
> > Dan
> >
> > On Thu, 2009-05-07 at 14:58 +0200, Wesley Roberts wrote:
> >> Dear R-sig-geo users,
> >>
> >> I have the output of a watershed segmentation in vector format (shapefile) which has it's attribute table populated with statistics regarding spectral reflectance of each polygon object. The attribute data was sourced from a geographically co-incident aerial photograph. I would now like to classify the segments using the attribute data. This seems like an easy task but I am struggling to find a suitable method. I have looked at 'lda' and 'qda' in the MASS package but the selection of an appropriate model using 'cv1EMtrain' takes a really long time. In essence all I want to do is classify the 6 variable data set into 3 classes with the class for each case recorded in the attribute table.
> >>
> >> Any advice or suggestions would be greatly appreciated.
> >>
> >> Many thanks and kind regards,
> >> Wesley
> >>
> >>
> >>
> >> Wesley Roberts MSc.
> >> Researcher: Earth Observation (Ecosystems)
> >> Natural Resources and the Environment
> >> CSIR
> >> Tel: +27 (21) 888-2490
> >> Fax: +27 (21) 888-2693
> >>
> >> "To know the road ahead, ask those coming back."
> >> - Chinese proverb
> >>
> >>
> >>
> >>
> > --
> > Dan Putler
> > Sauder School of Business
> > University of British Columbia
> >
> >
> >
> > --
> > This message is subject to the CSIR's copyright terms and conditions, e-mail legal notice, and implemented Open Document Format (ODF) standard.
> > The full disclaimer details can be found at http://www.csir.co.za/disclaimer.html.
> >
> > This message has been scanned for viruses and dangerous content by MailScanner,
> > and is believed to be clean.  MailScanner thanks Transtec Computers for their support.
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
-- 
Dan Putler
Sauder School of Business
University of British Columbia



-- 
This message is subject to the CSIR's copyright terms and conditions, e-mail legal notice, and implemented Open Document Format (ODF) standard. 
The full disclaimer details can be found at http://www.csir.co.za/disclaimer.html.

This message has been scanned for viruses and dangerous content by MailScanner, 
and is believed to be clean.  MailScanner thanks Transtec Computers for their support.


From p.hiemstra at geo.uu.nl  Tue May 12 11:36:48 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 12 May 2009 11:36:48 +0200
Subject: [R-sig-Geo] Interpolation / smoothing of points (without raster
 grids)
In-Reply-To: <3D6621E58F6EA24C9D0CA72B2D8E15B305107DE1@E03MVB1-UKBR.domain1.systemhost.net>
References: <3D6621E58F6EA24C9D0CA72B2D8E15B305107DE1@E03MVB1-UKBR.domain1.systemhost.net>
Message-ID: <4A094330.1090404@geo.uu.nl>

mike.elliott at openreach.co.uk wrote:
> Hello - can anyone suggest functions/packages that allow interpolation /
> smoothing of point data (without using raster grids)? i.e. which give
> the results at the original point locations.
>
> Many thanks, Mike Elliott.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   
If you could tell us more in detail what you want to do, we could offer 
you more guidance. To add to the promotion of packages that we wrote 
ourselves (edzer :)), you can also use automap, a package for automatic 
interpolation based on gstat and sp (two other packages). For 
cross-validation (if this is what you need) the following script will do 
the trick:

library(automap)
# Load the data
data(meuse)
coordinates(meuse) = ~x+y
data(meuse.grid)
gridded(meuse.grid) = ~x+y

# Perform cross-validation
kr.cv = autoKrige.cv(log(zinc)~1, meuse, model = c("Exp"))
kr_dist.cv = autoKrige.cv(log(zinc)~sqrt(dist), meuse,
            model = c("Exp"))
kr_dist_ffreq.cv = autoKrige.cv(log(zinc)~sqrt(dist)+ffreq,
           meuse, model = c("Exp"))
# Compare the results
compare.cv(kr.cv, kr_dist.cv, kr_dist_ffreq.cv)
compare.cv(kr.cv, kr_dist.cv, kr_dist_ffreq.cv,
           bubbleplots = TRUE)
compare.cv(kr.cv, kr_dist.cv, kr_dist_ffreq.cv,
           bubbleplots = TRUE, col.names = c("OK","UK1","UK2"))
compare.cv(kr.cv, kr_dist.cv, kr_dist_ffreq.cv,
           bubbleplots = TRUE, col.names = c("OK","UK1","UK2"),
           plot.diff = TRUE)

automap is available from CRAN.

cheers and good luck,
Paul

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From alobolistas at gmail.com  Tue May 12 17:17:27 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 12 May 2009 17:17:27 +0200
Subject: [R-sig-Geo] [R-sig-Debian] [Fwd: Re: ubuntu problem with
 'r-cran-robustbase' [FWD Agustin Lobo]]
In-Reply-To: <4A098738.80301@psu.edu>
References: <4A097A19.2010404@gmail.com> <4A098738.80301@psu.edu>
Message-ID: <4A099307.4010907@gmail.com>

Michael:

I do have the backports activated. This is the entry in my sources.list:
deb http://archive.ubuntu.com/ubuntu/ hardy-backports restricted main 
multiverse universe
deb-src http://archive.ubuntu.com/ubuntu/ hardy-backports restricted 
main multiverse universe

And this is the output to what you suggested.

root at alobo-laptop:/home/alobo# dpkg --get-selections | grep r-base
r-base-core                    install
r-base-dev                    install
r-base-html                    install
root at alobo-laptop:/home/alobo# dpkg --get-selections | grep r-cran
r-cran-abind                    deinstall
r-cran-boot                    install
r-cran-cluster                    install
r-cran-codetools                install
r-cran-effects                    deinstall
r-cran-foreign                    install
r-cran-kernsmooth                install
r-cran-lattice                    install
r-cran-matrix                    install
r-cran-mgcv                    install
r-cran-nlme                    install
r-cran-relimp                    deinstall
r-cran-robustbase                install
r-cran-rpart                    install
r-cran-survival                    install
r-cran-vr                    install

My system is uptodate, I regularly install what I'm told by Update Manager.

I'm going to uninstall and install back r-base from Synaptic.
If I keep having the same problem afterwards, do you expect
that installing everything from sources could solve the problem? Will it 
be hard ?
How much time should I pre-allocate?

Thanks

Agus




Michael Rutter wrote:
> Agus,
>
> robustbase just installed fine on my stock 8.04 system.  Please make 
> sure that you have added all the repositories and packages suggested 
> on this page:
>
> http://cran.r-project.org/bin/linux/ubuntu/
>
> Backports are important, and make sure you have r-base-dev
> installed.  You may also need to be root (via sudo) to install, 
> although there are instructions for local installation.  You can run 
> the following commands to see what R related packages you have installed.
>
> dpkg --get-selections | grep r-base
> dpkg --get-selections | grep r-cran
>
> Michael
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: alobolistas.vcf
Type: text/x-vcard
Size: 251 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090512/e2d3a980/attachment.vcf>

From alobolistas at gmail.com  Tue May 12 17:36:47 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 12 May 2009 17:36:47 +0200
Subject: [R-sig-Geo] [R-sig-Debian] [Fwd: Re: ubuntu problem with
 'r-cran-robustbase' [FWD Agustin Lobo]]
In-Reply-To: <4A099307.4010907@gmail.com>
References: <4A097A19.2010404@gmail.com> <4A098738.80301@psu.edu>
	<4A099307.4010907@gmail.com>
Message-ID: <4A09978F.4060306@gmail.com>

Martin,

Just uninstalled r-base-core ("complete removal" in Synaptic, which 
means that configuration files are removed also).
After that,
dpkg --get-selections | grep r-base

was giving no output
and
dpkg --get-selections | grep r-cran
r-cran-abind                    deinstall
r-cran-effects                    deinstall
r-cran-relimp                    deinstall

So I removed these 3 with apt-get -remove

Then I installed with apt-get:

sudo apt-get install r-base
sudo apt-get install r-base-dev
sudo apt-get install robustbase

No error messages.  But I started R and got the same error:

 > require(robustbase)
Loading required package: robustbase
Error in dyn.load(file, DLLpath = DLLpath, ...) :
  unable to load shared library 
'/usr/lib/R/site-library/robustbase/libs/robustbase.so':
  libRlapack.so: cannot open shared object file: No such file or directory

What else can be done if everything was removed and installed back again?
Is there any reason to think that installing R from sources is going to 
solve the problem?

Thanks
Agus

Agustin Lobo wrote:
> Michael:
>
> I do have the backports activated. This is the entry in my sources.list:
> deb http://archive.ubuntu.com/ubuntu/ hardy-backports restricted main 
> multiverse universe
> deb-src http://archive.ubuntu.com/ubuntu/ hardy-backports restricted 
> main multiverse universe
>
> And this is the output to what you suggested.
>
> root at alobo-laptop:/home/alobo# dpkg --get-selections | grep r-base
> r-base-core                    install
> r-base-dev                    install
> r-base-html                    install
> root at alobo-laptop:/home/alobo# dpkg --get-selections | grep r-cran
> r-cran-abind                    deinstall
> r-cran-boot                    install
> r-cran-cluster                    install
> r-cran-codetools                install
> r-cran-effects                    deinstall
> r-cran-foreign                    install
> r-cran-kernsmooth                install
> r-cran-lattice                    install
> r-cran-matrix                    install
> r-cran-mgcv                    install
> r-cran-nlme                    install
> r-cran-relimp                    deinstall
> r-cran-robustbase                install
> r-cran-rpart                    install
> r-cran-survival                    install
> r-cran-vr                    install
>
> My system is uptodate, I regularly install what I'm told by Update 
> Manager.
>
> I'm going to uninstall and install back r-base from Synaptic.
> If I keep having the same problem afterwards, do you expect
> that installing everything from sources could solve the problem? Will 
> it be hard ?
> How much time should I pre-allocate?
>
> Thanks
>
> Agus
>
>
>
>
> Michael Rutter wrote:
>> Agus,
>>
>> robustbase just installed fine on my stock 8.04 system.  Please make 
>> sure that you have added all the repositories and packages suggested 
>> on this page:
>>
>> http://cran.r-project.org/bin/linux/ubuntu/
>>
>> Backports are important, and make sure you have r-base-dev
>> installed.  You may also need to be root (via sudo) to install, 
>> although there are instructions for local installation.  You can run 
>> the following commands to see what R related packages you have 
>> installed.
>>
>> dpkg --get-selections | grep r-base
>> dpkg --get-selections | grep r-cran
>>
>> Michael
>>
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: alobolistas.vcf
Type: text/x-vcard
Size: 251 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090512/ed100b35/attachment.vcf>

From mudiver1200 at yahoo.com  Wed May 13 12:04:28 2009
From: mudiver1200 at yahoo.com (Tim Clark)
Date: Wed, 13 May 2009 03:04:28 -0700 (PDT)
Subject: [R-sig-Geo] Constraining movements in adehabitat
Message-ID: <405624.71844.qm@web36108.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090513/c0490c7b/attachment.pl>

From miguez at illinois.edu  Wed May 13 14:58:41 2009
From: miguez at illinois.edu (Fernando Miguez)
Date: Wed, 13 May 2009 08:58:41 -0400
Subject: [R-sig-Geo] Constraining movements in adehabitat
In-Reply-To: <405624.71844.qm@web36108.mail.mud.yahoo.com>
References: <405624.71844.qm@web36108.mail.mud.yahoo.com>
Message-ID: <4A0AC401.9060607@illinois.edu>

Dear All,

I hope this is a good place to post this. I'm working through the book 
"Applied Spatial Data Analysis with R" and on pg 59 the following code 
results in an error

 > data(meuse.riv)
 > meuse.lst <- list(Polygons(list(Polygon(meuse.riv))),"meuse.riv")
Error in Polygons(list(Polygon(meuse.riv))) : Single ID required

 > sessionInfo()
R version 2.9.0 (2009-04-17)
x86_64-pc-linux-gnu

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] graphics  grDevices utils     datasets  stats     methods   base

other attached packages:
[1] sp_0.9-32       mmisc_0.1-1     Hmisc_3.4-3     BioCro_0.250-5
[5] lattice_0.17-22

loaded via a namespace (and not attached):
[1] cluster_1.11.13 grid_2.9.0      tools_2.9.0

I didn't see anything in the Errata section for the book webpage about this.

Best wishes,

Fernando


-- 
Fernando E. Miguez
Energy Biosciences Institute
https://netfiles.uiuc.edu/miguez/www/


From miguez at illinois.edu  Wed May 13 15:01:09 2009
From: miguez at illinois.edu (Fernando Miguez)
Date: Wed, 13 May 2009 09:01:09 -0400
Subject: [R-sig-Geo]  Applied Spatial Data Analysis
In-Reply-To: <4A0AC401.9060607@illinois.edu>
References: <405624.71844.qm@web36108.mail.mud.yahoo.com>
	<4A0AC401.9060607@illinois.edu>
Message-ID: <4A0AC495.9090501@illinois.edu>

Dear All,

Sorry, by mistake I replied to the last message, but this is unrelated.

I hope this is a good place to post this. I'm working through the book 
"Applied Spatial Data Analysis with R" and on pg 59 the following code 
results in an error

 > data(meuse.riv)
 > meuse.lst <- list(Polygons(list(Polygon(meuse.riv))),"meuse.riv")
Error in Polygons(list(Polygon(meuse.riv))) : Single ID required

 > sessionInfo()
R version 2.9.0 (2009-04-17)
x86_64-pc-linux-gnu

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] graphics  grDevices utils     datasets  stats     methods   base

other attached packages:
[1] sp_0.9-32       mmisc_0.1-1     Hmisc_3.4-3     BioCro_0.250-5
[5] lattice_0.17-22

loaded via a namespace (and not attached):
[1] cluster_1.11.13 grid_2.9.0      tools_2.9.0

I didn't see anything in the Errata section for the book webpage about this.

Best wishes,

Fernando



-- 
Fernando E. Miguez
Energy Biosciences Institute
https://netfiles.uiuc.edu/miguez/www/


From miguez at illinois.edu  Wed May 13 15:08:12 2009
From: miguez at illinois.edu (Fernando Miguez)
Date: Wed, 13 May 2009 09:08:12 -0400
Subject: [R-sig-Geo] Applied Spatial Data Analysis
In-Reply-To: <4A0AC495.9090501@illinois.edu>
References: <405624.71844.qm@web36108.mail.mud.yahoo.com>
	<4A0AC401.9060607@illinois.edu> <4A0AC495.9090501@illinois.edu>
Message-ID: <4A0AC63C.6090100@illinois.edu>

Sorry, my mistake. This works

data(meuse.riv)
meuse.lst <- list(Polygons(list(Polygon(meuse.riv)),"meuse.riv"))

Fernando Miguez wrote:
> Dear All,
> 
> Sorry, by mistake I replied to the last message, but this is unrelated.
> 
> I hope this is a good place to post this. I'm working through the book 
> "Applied Spatial Data Analysis with R" and on pg 59 the following code 
> results in an error
> 
>  > data(meuse.riv)
>  > meuse.lst <- list(Polygons(list(Polygon(meuse.riv))),"meuse.riv")
> Error in Polygons(list(Polygon(meuse.riv))) : Single ID required
> 
>  > sessionInfo()
> R version 2.9.0 (2009-04-17)
> x86_64-pc-linux-gnu
> 
> locale:
> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C 
> 
> 
> attached base packages:
> [1] graphics  grDevices utils     datasets  stats     methods   base
> 
> other attached packages:
> [1] sp_0.9-32       mmisc_0.1-1     Hmisc_3.4-3     BioCro_0.250-5
> [5] lattice_0.17-22
> 
> loaded via a namespace (and not attached):
> [1] cluster_1.11.13 grid_2.9.0      tools_2.9.0
> 
> I didn't see anything in the Errata section for the book webpage about 
> this.
> 
> Best wishes,
> 
> Fernando
> 
> 
> 

-- 
Fernando E. Miguez
Energy Biosciences Institute
https://netfiles.uiuc.edu/miguez/www/


From marco.helbich at gmx.at  Wed May 13 15:37:34 2009
From: marco.helbich at gmx.at (Marco Helbich)
Date: Wed, 13 May 2009 15:37:34 +0200
Subject: [R-sig-Geo] stepwise algorithm for GWR
Message-ID: <20090513133734.158790@gmx.net>

Dear list!

I am doing some geographically weighted regression and I am intersted in the most suitable model (the one with the lowest AIC). Because there is no stepwise algorithm, I am trying to write a "brute force" function, which uses all possible variable combination, applies the gwr and returns the AIC value with the used variable combination in a dataframe. 
For instance the model below: gwr1: crime ~ income, gwr2: crime ~ housing, gwr3: crime ~ var1, gwr4: crime ~ income + housing, ... 

I hope my problem is clear and appreciate every hint! Thank you!

All the best
Marco

library(spgwr)
data(columbus)
columbus[,"var1"] <- rnorm(length(columbus[,1]))

col.bw <- gwr.sel(crime ~ income + housing + var1, data=columbus,
  coords=cbind(columbus$x, columbus$y))
col.gauss <- gwr(crime ~ income + housing + var1, data=columbus,
  coords=cbind(columbus$x, columbus$y), bandwidth=col.bw, hatmatrix=TRUE)
col.gauss
--


From mike.elliott at openreach.co.uk  Wed May 13 16:00:39 2009
From: mike.elliott at openreach.co.uk (mike.elliott at openreach.co.uk)
Date: Wed, 13 May 2009 15:00:39 +0100
Subject: [R-sig-Geo] Interpolation / smoothing of points (without raster
	grids)
In-Reply-To: <4A094330.1090404@geo.uu.nl>
Message-ID: <3D6621E58F6EA24C9D0CA72B2D8E15B305174453@E03MVB1-UKBR.domain1.systemhost.net>

My original post on this topic was far more detailed but I got very
little response so my second attempt was much more focussed. Here it is
to see if you are able to offer more help:

Sent: 08 May 2009 12:46
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] Calculating Risk at point locations
(withoutrasterising)

I would appreciate advice on how to do a spatial statistics task:
detecting points at a high risk of Cases (and cluster analysis). I have
semi-randomly located vector point data with 2 attributes (Cases and
Controls) at each point, i.e. marked point data. I want to apply spatial
smoothing as I hypothesize that the underlying process is such that
clusters of cases are of interest (although I also know that the process
operates on a small enough scale that isolated points with high numbers
of cases are also of interest). Having read the book by Bivand et al
"Applied Spatial Data Analysis with R" I was following the approach of
an inhomogeneous Poisson process analysis (p.175) to calculate a risk
image of log(cases/controls), which incidentally gives a few challenges
with divide by zeros. This risk image (I used data class ppp in R
library SpatStat as I had marked point data) is a raster interpolated
image, even though I originated with vector point data. However, the aim
of my analysis is to score each of the (vector) points with its risk
value, i.e. give each of my original vector points a new attribute
called Risk. For my application I am not interested in what happens in
between my point locations (as the point locations have a meaning). So
my problem is how to get the Risk value at the original point locations.
My current approach involves converting the points to raster, so I lose
the precise point location and I have a large data set so in practice
cannot set a very fine resolution. So my key question is: please, can
someone offer me advice on how to get the Risk value at the original
point locations? 

I wonder if I can avoid raster and do all processing in a vector map
(perhaps by interpolation or spline approximation). This would mean I
can avoid resampling a raster map back to the original vector point
locations as occasionally  the locations are so close (less than
resolution) this will create inaccuracy. 

(Background: I have not done much spatial statistics before so am trying
to keep it simple; I have used GRASS; not much experience with R).

When I originally import the map into R it has class
SpatialPointsDataFrame. Below are a couple of code examples:
> Case <- smooth.ppp(Cases,75, eps=50)   # smooth my Case data with a
kernel width of 75m; 50m pixel dimension in the resulting smoothed ppp.
> plot(eval.im( log((Case+9e-6)/(Control+1e-5)) + 0.3521755)) # to get
the Risk map; the 9e6- and 1e-5 are how I avoid divide by zero type
problems. 

-----Original Message-----
From: Paul Hiemstra [mailto:p.hiemstra at geo.uu.nl] 
Sent: 12 May 2009 10:37
To: Elliott,MR,Mike,BMK6 R
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] Interpolation / smoothing of points (without
raster grids)

mike.elliott at openreach.co.uk wrote:
> Hello - can anyone suggest functions/packages that allow interpolation

> / smoothing of point data (without using raster grids)? i.e. which 
> give the results at the original point locations.
>
> Many thanks, Mike Elliott.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   
If you could tell us more in detail what you want to do, we could offer
you more guidance. To add to the promotion of packages that we wrote
ourselves (edzer :)), you can also use automap, a package for automatic
interpolation based on gstat and sp (two other packages). For
cross-validation (if this is what you need) the following script will do
the trick:

library(automap)
# Load the data
data(meuse)
coordinates(meuse) = ~x+y
data(meuse.grid)
gridded(meuse.grid) = ~x+y

# Perform cross-validation
kr.cv = autoKrige.cv(log(zinc)~1, meuse, model = c("Exp")) kr_dist.cv =
autoKrige.cv(log(zinc)~sqrt(dist), meuse,
            model = c("Exp"))
kr_dist_ffreq.cv = autoKrige.cv(log(zinc)~sqrt(dist)+ffreq,
           meuse, model = c("Exp"))
# Compare the results
compare.cv(kr.cv, kr_dist.cv, kr_dist_ffreq.cv) compare.cv(kr.cv,
kr_dist.cv, kr_dist_ffreq.cv,
           bubbleplots = TRUE)
compare.cv(kr.cv, kr_dist.cv, kr_dist_ffreq.cv,
           bubbleplots = TRUE, col.names = c("OK","UK1","UK2"))
compare.cv(kr.cv, kr_dist.cv, kr_dist_ffreq.cv,
           bubbleplots = TRUE, col.names = c("OK","UK1","UK2"),
           plot.diff = TRUE)

automap is available from CRAN.

cheers and good luck,
Paul

--
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From yud at mail.montclair.edu  Wed May 13 16:04:22 2009
From: yud at mail.montclair.edu (Danlin Yu)
Date: Wed, 13 May 2009 10:04:22 -0400
Subject: [R-sig-Geo] stepwise algorithm for GWR
In-Reply-To: <20090513133734.158790@gmx.net>
References: <20090513133734.158790@gmx.net>
Message-ID: <4A0AD366.5060705@mail.montclair.edu>

Dear Marco:

Before doing so, you'll have to ask yourself that whether all those AICs 
are comparable among different model specifications. As a matter of 
fact, I believe it might be more plausible if you stepwise it first as a 
global model (OLS, after all, global models are an "averaged" view of 
the local models), and then work with the selected specification.

Hope this helps,

Danlin

Marco Helbich ??:
> Dear list!
>
> I am doing some geographically weighted regression and I am intersted in the most suitable model (the one with the lowest AIC). Because there is no stepwise algorithm, I am trying to write a "brute force" function, which uses all possible variable combination, applies the gwr and returns the AIC value with the used variable combination in a dataframe. 
> For instance the model below: gwr1: crime ~ income, gwr2: crime ~ housing, gwr3: crime ~ var1, gwr4: crime ~ income + housing, ... 
>
> I hope my problem is clear and appreciate every hint! Thank you!
>
> All the best
> Marco
>
> library(spgwr)
> data(columbus)
> columbus[,"var1"] <- rnorm(length(columbus[,1]))
>
> col.bw <- gwr.sel(crime ~ income + housing + var1, data=columbus,
>   coords=cbind(columbus$x, columbus$y))
> col.gauss <- gwr(crime ~ income + housing + var1, data=columbus,
>   coords=cbind(columbus$x, columbus$y), bandwidth=col.bw, hatmatrix=TRUE)
> col.gauss
> --
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
___________________________________________
Danlin Yu, Ph.D.
Assistant Professor of GIS and Urban Geography
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
email: yud at mail.montclair.edu
webpage: csam.montclair.edu/~yu


From Joshua.Myers at norfolk.gov  Wed May 13 17:00:23 2009
From: Joshua.Myers at norfolk.gov (Myers, Joshua)
Date: Wed, 13 May 2009 11:00:23 -0400
Subject: [R-sig-Geo] stepwise algorithm for GWR
In-Reply-To: <4A0AD366.5060705@mail.montclair.edu>
References: <20090513133734.158790@gmx.net>
	<4A0AD366.5060705@mail.montclair.edu>
Message-ID: <9B075A4C00AC004191F2A8C73EB78E62976D7A@MAILC-EVS.norfolk.gov>

Dear Marco,
	I think Danlin is more experienced with this than myself, but in
my experience I have found that best global OLS model is usually at
least somewhat different than the best GWR model.   I have found that
there is usually a slightly different variable set (at least in the two
datasets that I have been working with).  In my datasets I have also
found that it yields better results to not use a log or square root (or
any other like variable transformation) in the local model, whereas it
might make a difference in a global model.  I am not saying it will be
the same for you, but I am cautioning you to not just take what you see
the global case and apply it blindly to the local GWR case.  

	I have actually thought a lot about what you are suggesting, a
selection algorithm for gwr, but I haven't had the time to play with it
yet.  It can be noted, however, that any such search algorithm will take
a lonnnnggggg time.  It will probably need to be run overnight, unless
you have some kind supercomputing cluster.

-Josh

-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Danlin Yu
Sent: Wednesday, May 13, 2009 10:04 AM
To: Marco Helbich
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] stepwise algorithm for GWR

Dear Marco:

Before doing so, you'll have to ask yourself that whether all those AICs

are comparable among different model specifications. As a matter of 
fact, I believe it might be more plausible if you stepwise it first as a

global model (OLS, after all, global models are an "averaged" view of 
the local models), and then work with the selected specification.

Hope this helps,

Danlin

Marco Helbich ??:
> Dear list!
>
> I am doing some geographically weighted regression and I am intersted
in the most suitable model (the one with the lowest AIC). Because there
is no stepwise algorithm, I am trying to write a "brute force" function,
which uses all possible variable combination, applies the gwr and
returns the AIC value with the used variable combination in a dataframe.

> For instance the model below: gwr1: crime ~ income, gwr2: crime ~
housing, gwr3: crime ~ var1, gwr4: crime ~ income + housing, ... 
>
> I hope my problem is clear and appreciate every hint! Thank you!
>
> All the best
> Marco
>
> library(spgwr)
> data(columbus)
> columbus[,"var1"] <- rnorm(length(columbus[,1]))
>
> col.bw <- gwr.sel(crime ~ income + housing + var1, data=columbus,
>   coords=cbind(columbus$x, columbus$y))
> col.gauss <- gwr(crime ~ income + housing + var1, data=columbus,
>   coords=cbind(columbus$x, columbus$y), bandwidth=col.bw,
hatmatrix=TRUE)
> col.gauss
> --
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
___________________________________________
Danlin Yu, Ph.D.
Assistant Professor of GIS and Urban Geography
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
email: yud at mail.montclair.edu
webpage: csam.montclair.edu/~yu

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From marco.helbich at gmx.at  Wed May 13 17:54:23 2009
From: marco.helbich at gmx.at (Marco Helbich)
Date: Wed, 13 May 2009 17:54:23 +0200
Subject: [R-sig-Geo] stepwise algorithm for GWR
In-Reply-To: <4A0AD366.5060705@mail.montclair.edu>
References: <20090513133734.158790@gmx.net>
	<4A0AD366.5060705@mail.montclair.edu>
Message-ID: <20090513155423.158790@gmx.net>

Dear Danlin and Joshua,

first of all thank you for your replies! Here some further notes for clarification: I have already estimated a global ols model (based on stepwise model selection) and because of some spatial effects I recalculated it as simultaneous autoregressive model. After that I tested this model for non-stationarity... and voil? there is one. Now I want to compare this one with the one offering the lowest aic. 

All the best
Marco  



-------- Original-Nachricht --------
> Datum: Wed, 13 May 2009 10:04:22 -0400
> Von: Danlin Yu <yud at mail.montclair.edu>
> An: Marco Helbich <marco.helbich at gmx.at>
> CC: r-sig-geo at stat.math.ethz.ch
> Betreff: Re: [R-sig-Geo] stepwise algorithm for GWR

> Dear Marco:
> 
> Before doing so, you'll have to ask yourself that whether all those AICs 
> are comparable among different model specifications. As a matter of 
> fact, I believe it might be more plausible if you stepwise it first as a 
> global model (OLS, after all, global models are an "averaged" view of 
> the local models), and then work with the selected specification.
> 
> Hope this helps,
> 
> Danlin
> 
> Marco Helbich ??:
> > Dear list!
> >
> > I am doing some geographically weighted regression and I am intersted in
> the most suitable model (the one with the lowest AIC). Because there is no
> stepwise algorithm, I am trying to write a "brute force" function, which
> uses all possible variable combination, applies the gwr and returns the AIC
> value with the used variable combination in a dataframe. 
> > For instance the model below: gwr1: crime ~ income, gwr2: crime ~
> housing, gwr3: crime ~ var1, gwr4: crime ~ income + housing, ... 
> >
> > I hope my problem is clear and appreciate every hint! Thank you!
> >
> > All the best
> > Marco
> >
> > library(spgwr)
> > data(columbus)
> > columbus[,"var1"] <- rnorm(length(columbus[,1]))
> >
> > col.bw <- gwr.sel(crime ~ income + housing + var1, data=columbus,
> >   coords=cbind(columbus$x, columbus$y))
> > col.gauss <- gwr(crime ~ income + housing + var1, data=columbus,
> >   coords=cbind(columbus$x, columbus$y), bandwidth=col.bw,
> hatmatrix=TRUE)
> > col.gauss
> > --
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >   
> 
> -- 
> ___________________________________________
> Danlin Yu, Ph.D.
> Assistant Professor of GIS and Urban Geography
> Department of Earth & Environmental Studies
> Montclair State University
> Montclair, NJ, 07043
> Tel: 973-655-4313
> Fax: 973-655-4072
> email: yud at mail.montclair.edu
> webpage: csam.montclair.edu/~yu

--


From yud at mail.montclair.edu  Wed May 13 20:12:15 2009
From: yud at mail.montclair.edu (Danlin Yu)
Date: Wed, 13 May 2009 14:12:15 -0400
Subject: [R-sig-Geo] stepwise algorithm for GWR
In-Reply-To: <20090513155423.158790@gmx.net>
References: <20090513133734.158790@gmx.net>
	<4A0AD366.5060705@mail.montclair.edu>
	<20090513155423.158790@gmx.net>
Message-ID: <4A0B0D7F.1000809@mail.montclair.edu>

Marco:

That's the point - I don't think such comparison is quite appropriate (I 
might be wrong) since the model specifications are not the same. You can 
compare AICs across OLS, SAR, and GWR with the same specification (same 
set of dependent and independent variables), but it's quite doubtful to 
compare AICs across any of these with different specifications.

It really depends upon what's the purpose of your analysis. I assume you 
were trying to find the best model to fit your data. Maybe using all the 
models to do a prediction and calculate the RMSE could give you some hints?

Hope this helps.

Danlin

Marco Helbich ??:
> Dear Danlin and Joshua,
>
> first of all thank you for your replies! Here some further notes for clarification: I have already estimated a global ols model (based on stepwise model selection) and because of some spatial effects I recalculated it as simultaneous autoregressive model. After that I tested this model for non-stationarity... and voil? there is one. Now I want to compare this one with the one offering the lowest aic. 
>
> All the best
> Marco  
>
>
>
> -------- Original-Nachricht --------
>   
>> Datum: Wed, 13 May 2009 10:04:22 -0400
>> Von: Danlin Yu <yud at mail.montclair.edu>
>> An: Marco Helbich <marco.helbich at gmx.at>
>> CC: r-sig-geo at stat.math.ethz.ch
>> Betreff: Re: [R-sig-Geo] stepwise algorithm for GWR
>>     
>
>   
>> Dear Marco:
>>
>> Before doing so, you'll have to ask yourself that whether all those AICs 
>> are comparable among different model specifications. As a matter of 
>> fact, I believe it might be more plausible if you stepwise it first as a 
>> global model (OLS, after all, global models are an "averaged" view of 
>> the local models), and then work with the selected specification.
>>
>> Hope this helps,
>>
>> Danlin
>>
>> Marco Helbich ??:
>>     
>>> Dear list!
>>>
>>> I am doing some geographically weighted regression and I am intersted in
>>>       
>> the most suitable model (the one with the lowest AIC). Because there is no
>> stepwise algorithm, I am trying to write a "brute force" function, which
>> uses all possible variable combination, applies the gwr and returns the AIC
>> value with the used variable combination in a dataframe. 
>>     
>>> For instance the model below: gwr1: crime ~ income, gwr2: crime ~
>>>       
>> housing, gwr3: crime ~ var1, gwr4: crime ~ income + housing, ... 
>>     
>>> I hope my problem is clear and appreciate every hint! Thank you!
>>>
>>> All the best
>>> Marco
>>>
>>> library(spgwr)
>>> data(columbus)
>>> columbus[,"var1"] <- rnorm(length(columbus[,1]))
>>>
>>> col.bw <- gwr.sel(crime ~ income + housing + var1, data=columbus,
>>>   coords=cbind(columbus$x, columbus$y))
>>> col.gauss <- gwr(crime ~ income + housing + var1, data=columbus,
>>>   coords=cbind(columbus$x, columbus$y), bandwidth=col.bw,
>>>       
>> hatmatrix=TRUE)
>>     
>>> col.gauss
>>> --
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>   
>>>       
>> -- 
>> ___________________________________________
>> Danlin Yu, Ph.D.
>> Assistant Professor of GIS and Urban Geography
>> Department of Earth & Environmental Studies
>> Montclair State University
>> Montclair, NJ, 07043
>> Tel: 973-655-4313
>> Fax: 973-655-4072
>> email: yud at mail.montclair.edu
>> webpage: csam.montclair.edu/~yu
>>     
>
>   

-- 
___________________________________________
Danlin Yu, Ph.D.
Assistant Professor of GIS and Urban Geography
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
email: yud at mail.montclair.edu
webpage: csam.montclair.edu/~yu


From Joshua.Myers at norfolk.gov  Wed May 13 20:32:35 2009
From: Joshua.Myers at norfolk.gov (Myers, Joshua)
Date: Wed, 13 May 2009 14:32:35 -0400
Subject: [R-sig-Geo] stepwise algorithm for GWR
In-Reply-To: <4A0B0D7F.1000809@mail.montclair.edu>
References: <20090513133734.158790@gmx.net>
	<4A0AD366.5060705@mail.montclair.edu>
	<20090513155423.158790@gmx.net>
	<4A0B0D7F.1000809@mail.montclair.edu>
Message-ID: <9B075A4C00AC004191F2A8C73EB78E62976D7C@MAILC-EVS.norfolk.gov>

Marco,
	 I agree with Danlin.  You can use AIC to compare models of the same type (i.e. OLS) with different model specifications, or, you can use AIC to compare models of different types (SAR, OLS, GWR) but with the same model specification.  Alternatively, RMSE can be used to compare models of any type together no matter what specification, but there is no penalization for number of parameters used.  Oftentimes, we either have a fixed number of parameters or we have a good idea which parameters are best or interesting, so we are able to cut down on some of the many possible specification options.  

-Josh

-----Original Message-----
From: Danlin Yu [mailto:yud at mail.montclair.edu] 
Sent: Wednesday, May 13, 2009 2:12 PM
To: Marco Helbich
Cc: r-sig-geo at stat.math.ethz.ch; Myers, Joshua
Subject: Re: [R-sig-Geo] stepwise algorithm for GWR

Marco:

That's the point - I don't think such comparison is quite appropriate (I 
might be wrong) since the model specifications are not the same. You can 
compare AICs across OLS, SAR, and GWR with the same specification (same 
set of dependent and independent variables), but it's quite doubtful to 
compare AICs across any of these with different specifications.

It really depends upon what's the purpose of your analysis. I assume you 
were trying to find the best model to fit your data. Maybe using all the 
models to do a prediction and calculate the RMSE could give you some hints?

Hope this helps.

Danlin

Marco Helbich ??:
> Dear Danlin and Joshua,
>
> first of all thank you for your replies! Here some further notes for clarification: I have already estimated a global ols model (based on stepwise model selection) and because of some spatial effects I recalculated it as simultaneous autoregressive model. After that I tested this model for non-stationarity... and voil? there is one. Now I want to compare this one with the one offering the lowest aic. 
>
> All the best
> Marco  
>
>
>
> -------- Original-Nachricht --------
>   
>> Datum: Wed, 13 May 2009 10:04:22 -0400
>> Von: Danlin Yu <yud at mail.montclair.edu>
>> An: Marco Helbich <marco.helbich at gmx.at>
>> CC: r-sig-geo at stat.math.ethz.ch
>> Betreff: Re: [R-sig-Geo] stepwise algorithm for GWR
>>     
>
>   
>> Dear Marco:
>>
>> Before doing so, you'll have to ask yourself that whether all those AICs 
>> are comparable among different model specifications. As a matter of 
>> fact, I believe it might be more plausible if you stepwise it first as a 
>> global model (OLS, after all, global models are an "averaged" view of 
>> the local models), and then work with the selected specification.
>>
>> Hope this helps,
>>
>> Danlin
>>
>> Marco Helbich ??:
>>     
>>> Dear list!
>>>
>>> I am doing some geographically weighted regression and I am intersted in
>>>       
>> the most suitable model (the one with the lowest AIC). Because there is no
>> stepwise algorithm, I am trying to write a "brute force" function, which
>> uses all possible variable combination, applies the gwr and returns the AIC
>> value with the used variable combination in a dataframe. 
>>     
>>> For instance the model below: gwr1: crime ~ income, gwr2: crime ~
>>>       
>> housing, gwr3: crime ~ var1, gwr4: crime ~ income + housing, ... 
>>     
>>> I hope my problem is clear and appreciate every hint! Thank you!
>>>
>>> All the best
>>> Marco
>>>
>>> library(spgwr)
>>> data(columbus)
>>> columbus[,"var1"] <- rnorm(length(columbus[,1]))
>>>
>>> col.bw <- gwr.sel(crime ~ income + housing + var1, data=columbus,
>>>   coords=cbind(columbus$x, columbus$y))
>>> col.gauss <- gwr(crime ~ income + housing + var1, data=columbus,
>>>   coords=cbind(columbus$x, columbus$y), bandwidth=col.bw,
>>>       
>> hatmatrix=TRUE)
>>     
>>> col.gauss
>>> --
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>   
>>>       
>> -- 
>> ___________________________________________
>> Danlin Yu, Ph.D.
>> Assistant Professor of GIS and Urban Geography
>> Department of Earth & Environmental Studies
>> Montclair State University
>> Montclair, NJ, 07043
>> Tel: 973-655-4313
>> Fax: 973-655-4072
>> email: yud at mail.montclair.edu
>> webpage: csam.montclair.edu/~yu
>>     
>
>   

-- 
___________________________________________
Danlin Yu, Ph.D.
Assistant Professor of GIS and Urban Geography
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
email: yud at mail.montclair.edu
webpage: csam.montclair.edu/~yu


From marco.helbich at gmx.at  Wed May 13 21:11:45 2009
From: marco.helbich at gmx.at (Marco Helbich)
Date: Wed, 13 May 2009 21:11:45 +0200
Subject: [R-sig-Geo] stepwise algorithm for GWR
In-Reply-To: <9B075A4C00AC004191F2A8C73EB78E62976D7C@MAILC-EVS.norfolk.gov>
References: <20090513133734.158790@gmx.net>
	<4A0AD366.5060705@mail.montclair.edu> <20090513155423.158790@gmx.net>
	<4A0B0D7F.1000809@mail.montclair.edu>
	<9B075A4C00AC004191F2A8C73EB78E62976D7C@MAILC-EVS.norfolk.gov>
Message-ID: <20090513191145.240170@gmx.net>

Dear Joshua and Danlin,

your remarks are right, but I am not fully convinced. What are the differences between using it in an ols framwork and using it in a GWR one under the same conditions (same bandwith, amount of neighbors...)?
Any further hints?

Thank you and best regards
Marco


-------- Original-Nachricht --------
> Datum: Wed, 13 May 2009 14:32:35 -0400
> Von: "Myers, Joshua" <Joshua.Myers at norfolk.gov>
> An: "Danlin Yu" <yud at mail.montclair.edu>, "Marco Helbich" <marco.helbich at gmx.at>
> CC: r-sig-geo at stat.math.ethz.ch
> Betreff: RE: [R-sig-Geo] stepwise algorithm for GWR

> Marco,
> 	 I agree with Danlin.  You can use AIC to compare models of the same type
> (i.e. OLS) with different model specifications, or, you can use AIC to
> compare models of different types (SAR, OLS, GWR) but with the same model
> specification.  Alternatively, RMSE can be used to compare models of any type
> together no matter what specification, but there is no penalization for
> number of parameters used.  Oftentimes, we either have a fixed number of
> parameters or we have a good idea which parameters are best or interesting, so we
> are able to cut down on some of the many possible specification options.  
> 
> -Josh
> 
> -----Original Message-----
> From: Danlin Yu [mailto:yud at mail.montclair.edu] 
> Sent: Wednesday, May 13, 2009 2:12 PM
> To: Marco Helbich
> Cc: r-sig-geo at stat.math.ethz.ch; Myers, Joshua
> Subject: Re: [R-sig-Geo] stepwise algorithm for GWR
> 
> Marco:
> 
> That's the point - I don't think such comparison is quite appropriate (I 
> might be wrong) since the model specifications are not the same. You can 
> compare AICs across OLS, SAR, and GWR with the same specification (same 
> set of dependent and independent variables), but it's quite doubtful to 
> compare AICs across any of these with different specifications.
> 
> It really depends upon what's the purpose of your analysis. I assume you 
> were trying to find the best model to fit your data. Maybe using all the 
> models to do a prediction and calculate the RMSE could give you some
> hints?
> 
> Hope this helps.
> 
> Danlin
> 
> Marco Helbich ??:
> > Dear Danlin and Joshua,
> >
> > first of all thank you for your replies! Here some further notes for
> clarification: I have already estimated a global ols model (based on stepwise
> model selection) and because of some spatial effects I recalculated it as
> simultaneous autoregressive model. After that I tested this model for
> non-stationarity... and voil? there is one. Now I want to compare this one with
> the one offering the lowest aic. 
> >
> > All the best
> > Marco  
> >
> >
> >
> > -------- Original-Nachricht --------
> >   
> >> Datum: Wed, 13 May 2009 10:04:22 -0400
> >> Von: Danlin Yu <yud at mail.montclair.edu>
> >> An: Marco Helbich <marco.helbich at gmx.at>
> >> CC: r-sig-geo at stat.math.ethz.ch
> >> Betreff: Re: [R-sig-Geo] stepwise algorithm for GWR
> >>     
> >
> >   
> >> Dear Marco:
> >>
> >> Before doing so, you'll have to ask yourself that whether all those
> AICs 
> >> are comparable among different model specifications. As a matter of 
> >> fact, I believe it might be more plausible if you stepwise it first as
> a 
> >> global model (OLS, after all, global models are an "averaged" view of 
> >> the local models), and then work with the selected specification.
> >>
> >> Hope this helps,
> >>
> >> Danlin
> >>
> >> Marco Helbich ??:
> >>     
> >>> Dear list!
> >>>
> >>> I am doing some geographically weighted regression and I am intersted
> in
> >>>       
> >> the most suitable model (the one with the lowest AIC). Because there is
> no
> >> stepwise algorithm, I am trying to write a "brute force" function,
> which
> >> uses all possible variable combination, applies the gwr and returns the
> AIC
> >> value with the used variable combination in a dataframe. 
> >>     
> >>> For instance the model below: gwr1: crime ~ income, gwr2: crime ~
> >>>       
> >> housing, gwr3: crime ~ var1, gwr4: crime ~ income + housing, ... 
> >>     
> >>> I hope my problem is clear and appreciate every hint! Thank you!
> >>>
> >>> All the best
> >>> Marco
> >>>
> >>> library(spgwr)
> >>> data(columbus)
> >>> columbus[,"var1"] <- rnorm(length(columbus[,1]))
> >>>
> >>> col.bw <- gwr.sel(crime ~ income + housing + var1, data=columbus,
> >>>   coords=cbind(columbus$x, columbus$y))
> >>> col.gauss <- gwr(crime ~ income + housing + var1, data=columbus,
> >>>   coords=cbind(columbus$x, columbus$y), bandwidth=col.bw,
> >>>       
> >> hatmatrix=TRUE)
> >>     
> >>> col.gauss
> >>> --
> >>>
> >>> _______________________________________________
> >>> R-sig-Geo mailing list
> >>> R-sig-Geo at stat.math.ethz.ch
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>>   
> >>>       
> >> -- 
> >> ___________________________________________
> >> Danlin Yu, Ph.D.
> >> Assistant Professor of GIS and Urban Geography
> >> Department of Earth & Environmental Studies
> >> Montclair State University
> >> Montclair, NJ, 07043
> >> Tel: 973-655-4313
> >> Fax: 973-655-4072
> >> email: yud at mail.montclair.edu
> >> webpage: csam.montclair.edu/~yu
> >>     
> >
> >   
> 
> -- 
> ___________________________________________
> Danlin Yu, Ph.D.
> Assistant Professor of GIS and Urban Geography
> Department of Earth & Environmental Studies
> Montclair State University
> Montclair, NJ, 07043
> Tel: 973-655-4313
> Fax: 973-655-4072
> email: yud at mail.montclair.edu
> webpage: csam.montclair.edu/~yu

--


From milton.ruser at gmail.com  Thu May 14 00:55:06 2009
From: milton.ruser at gmail.com (milton ruser)
Date: Wed, 13 May 2009 18:55:06 -0400
Subject: [R-sig-Geo] Moran's I : list of neighbour and generating residual
	maps.
Message-ID: <3aaf1a030905131555n48be1f1g1b1e2329b5e4c31a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090513/77898ed2/attachment.pl>

From mudiver1200 at yahoo.com  Thu May 14 02:01:42 2009
From: mudiver1200 at yahoo.com (Tim Clark)
Date: Wed, 13 May 2009 17:01:42 -0700 (PDT)
Subject: [R-sig-Geo] Constraining movements in adehabitat
Message-ID: <453736.13646.qm@web36103.mail.mud.yahoo.com>


Dear List,

Sorry, this is a second attempt to post the same message.  My last one got scrubbed so I changed browser options.  Hopefully this one will make it!

I am using the package adehabitat to analyze the movement patterns and home range of the manta ray (Manta birostris) in Hawaii.  The manta rays in this study stayed close to shore, often feeding along the shore line or in small bays.  Since they can not go on land (being fish) their home range is obviously limited to the ocean area.  In calculating home range statistics, is there a way to limit the avalible area to the ocean.  I have read through the papers on Adehabitat but have not found a way to limit the area. The closest I have found is the function buffer().  Have I missed something?  Is there a way to constrain the movements so that kernels will only be computed for data points located in the ocean?

I appreciate your help and guidence.

Tim



Tim Clark
PhD Student 
University of Hawaii
Honolulu, HI 96816


From adrian at maths.uwa.edu.au  Thu May 14 04:02:04 2009
From: adrian at maths.uwa.edu.au (Adrian Baddeley)
Date: Thu, 14 May 2009 10:02:04 +0800
Subject: [R-sig-Geo] clump of binary pixels (connected components)
Message-ID: <4A0B7B9C.9090002@maths.uwa.edu.au>

There have been several questions posted on R-sig-Geo about how to 
identify connected components (clumps or clusters of contiguous pixels 
with the same value) in a pixel image.

The connected component transform has been implemented in the latest 
version of package 'spatstat' (version 1.15-3) thanks to Julian Burgos.

The command name is 'connected'.
Timing is roughly 1 second per megapixel (e.g. 0.25 seconds for a 512 x 
512 image).

Adrian Baddeley


From pinaud at cebc.cnrs.fr  Thu May 14 09:18:30 2009
From: pinaud at cebc.cnrs.fr (Pinaud David)
Date: Thu, 14 May 2009 09:18:30 +0200
Subject: [R-sig-Geo] Constraining movements in adehabitat
In-Reply-To: <453736.13646.qm@web36103.mail.mud.yahoo.com>
References: <453736.13646.qm@web36103.mail.mud.yahoo.com>
Message-ID: <4A0BC5C6.9000005@cebc.cnrs.fr>

Dear Tim,

You can try several papers from Jason Matthioploulos, among:
Matthiopoulos (2003) The use of space by animals as a function of 
accessibility and
preference - Ecological Modelling 159 239-268
Matthiopoulos, J. 2003. Model-supervised kernel smoothing for the 
estimation of
spatial usage. ? Oikos 102: 367?377.
Unfortunately, I don't know a R implementation to do this directly. One 
(quick and dirty) way could be to weight the output of the Kernel 
estimation by a raster representing distance to coast (or ocean/continent)?

Hope it helps

David

Tim Clark a ?crit :
> Dear List,
>
> Sorry, this is a second attempt to post the same message.  My last one got scrubbed so I changed browser options.  Hopefully this one will make it!
>
> I am using the package adehabitat to analyze the movement patterns and home range of the manta ray (Manta birostris) in Hawaii.  The manta rays in this study stayed close to shore, often feeding along the shore line or in small bays.  Since they can not go on land (being fish) their home range is obviously limited to the ocean area.  In calculating home range statistics, is there a way to limit the avalible area to the ocean.  I have read through the papers on Adehabitat but have not found a way to limit the area. The closest I have found is the function buffer().  Have I missed something?  Is there a way to co

> nstrain the movements so that kernels will only be computed for data points located in the ocean?
>
> I appreciate your help and guidence.
>
> Tim
>
>
>
> Tim Clark
> PhD Student 
> University of Hawaii
> Honolulu, HI 96816
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> __________ Information from ESET Mail Security, version of virus signature database 4073 (20090513) __________
>
> The message was checked by ESET Mail Security.
> http://www.eset.com
>
>
>
>
>
>   

-- 
***************************************************
David PINAUD
Ing?nieur de Recherche "Analyses spatiales"

Centre d'Etudes Biologiques de Chiz? - CNRS UPR1934
79360 Villiers-en-Bois, France 
poste 485
Tel: +33 (0)5.49.09.35.58
Fax: +33 (0)5.49.09.65.26
http://www.cebc.cnrs.fr/

***************************************************




__________ Information from ESET Mail Security, version of virus signature database 4073 (20090513) __________

The message was checked by ESET Mail Security.
http://www.eset.com

-------------- next part --------------
A non-text attachment was scrubbed...
Name: pinaud.vcf
Type: text/x-vcard
Size: 324 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090514/f7ee788a/attachment.vcf>

From wroberts at csir.co.za  Thu May 14 09:20:37 2009
From: wroberts at csir.co.za (Wesley Roberts)
Date: Thu, 14 May 2009 09:20:37 +0200
Subject: [R-sig-Geo] Calculating area of polygons
Message-ID: <4A0BE265.8E3B.0073.0@csir.co.za>

Dear list,

I would like to calculate the area of a polygon. I have found areapl() in splancs but am having trouble using it.

x<-1
poly <- readShapePoly("a1_l4_aerial_ws.shp", IDvar="cat", proj4string=CRS("+proj=tmerc +south +ellips=WGS84 +datum=WGS84 +lon_o=31 +k_0=1 +units=m +no_defs"))
poly_add <- poly[poly$cat[x], ]
areapl(poly_add)
Error in `[.data.frame`(x at data, i, j, ..., drop = FALSE) : 
  undefined columns selected

I have tried various combinations of commands with all returning either an error or 0. I know the area of the polygon is 4.760465 square meters (area slot) but cant seem to replicate this using areapl(). Is it possible to access the area slot directly instead of computing the area with areapl()? 

Many thanks,
Wesley 


Wesley Roberts MSc.
Researcher: Earth Observation (Ecosystems)
Natural Resources and the Environment
CSIR
Tel: +27 (21) 888-2490
Fax: +27 (21) 888-2693

"To know the road ahead, ask those coming back."
- Chinese proverb




-- 
This message is subject to the CSIR's copyright terms and conditions, e-mail legal notice, and implemented Open Document Format (ODF) standard. 
The full disclaimer details can be found at http://www.csir.co.za/disclaimer.html.

This message has been scanned for viruses and dangerous content by MailScanner, 
and is believed to be clean.  MailScanner thanks Transtec Computers for their support.


From Roger.Bivand at nhh.no  Thu May 14 09:51:31 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 14 May 2009 09:51:31 +0200 (CEST)
Subject: [R-sig-Geo] Calculating area of polygons
In-Reply-To: <4A0BE265.8E3B.0073.0@csir.co.za>
References: <4A0BE265.8E3B.0073.0@csir.co.za>
Message-ID: <alpine.LRH.2.00.0905140940210.2373@reclus.nhh.no>

On Thu, 14 May 2009, Wesley Roberts wrote:

> Dear list,
>
> I would like to calculate the area of a polygon. I have found areapl() in splancs but am having trouble using it.
>
> x<-1
> poly <- readShapePoly("a1_l4_aerial_ws.shp", IDvar="cat", proj4string=CRS("+proj=tmerc +south +ellips=WGS84 +datum=WGS84 +lon_o=31 +k_0=1 +units=m +no_defs"))
> poly_add <- poly[poly$cat[x], ]
> areapl(poly_add)
> Error in `[.data.frame`(x at data, i, j, ..., drop = FALSE) :
>  undefined columns selected

The areas are calculated when the Polygon objects are created - they are 
used internally for ordering the painting of the polygons, largest first):

library(rgdal)
scot_BNG <- readOGR(system.file("vectors", package = "rgdal")[1],
   "scot_BNG")
summary(scot_BNG)
getClass("Polygon")
areas <- sapply(slot(scot_BNG, "polygons"), function(x) sapply(slot(x,
  "Polygons"), slot, "area"))
str(areas)

areas is a list - each member is the vector of areas for rings belonging 
to the Polygons objects. You may also need to access the "hole" slot to 
see which "are" seen as holes for your data.

The areas are OK for planar coordinates, but only for these - for plotting 
the values, although not correct, are adequate for plot ordering.

Hope this helps,

Roger

>
> I have tried various combinations of commands with all returning either an error or 0. I know the area of the polygon is 4.760465 square meters (area slot) but cant seem to replicate this using areapl(). Is it possible to access the area slot directly instead of computing the area with areapl()?
>
> Many thanks,
> Wesley
>
>
> Wesley Roberts MSc.
> Researcher: Earth Observation (Ecosystems)
> Natural Resources and the Environment
> CSIR
> Tel: +27 (21) 888-2490
> Fax: +27 (21) 888-2693
>
> "To know the road ahead, ask those coming back."
> - Chinese proverb
>
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From wroberts at csir.co.za  Thu May 14 10:19:39 2009
From: wroberts at csir.co.za (Wesley Roberts)
Date: Thu, 14 May 2009 10:19:39 +0200
Subject: [R-sig-Geo] Calculating area of polygons
In-Reply-To: <alpine.LRH.2.00.0905140940210.2373@reclus.nhh.no>
References: <4A0BE265.8E3B.0073.0@csir.co.za>
	<alpine.LRH.2.00.0905140940210.2373@reclus.nhh.no>
Message-ID: <4A0BF03C.8E3B.0073.0@csir.co.za>

Thanks Roger,

Works a treat.

Wesley 
 
>>> Roger Bivand <Roger.Bivand at nhh.no> 05/14/09 9:51 AM >>> 
On Thu, 14 May 2009, Wesley Roberts wrote:

> Dear list,
>
> I would like to calculate the area of a polygon. I have found areapl() in splancs but am having trouble using it.
>
> x<-1
> poly <- readShapePoly("a1_l4_aerial_ws.shp", IDvar="cat", proj4string=CRS("+proj=tmerc +south +ellips=WGS84 +datum=WGS84 +lon_o=31 +k_0=1 +units=m +no_defs"))
> poly_add <- poly[poly$cat[x], ]
> areapl(poly_add)
> Error in `[.data.frame`(x at data, i, j, ..., drop = FALSE) :
>  undefined columns selected

The areas are calculated when the Polygon objects are created - they are 
used internally for ordering the painting of the polygons, largest first):

library(rgdal)
scot_BNG <- readOGR(system.file("vectors", package = "rgdal")[1],
   "scot_BNG")
summary(scot_BNG)
getClass("Polygon")
areas <- sapply(slot(scot_BNG, "polygons"), function(x) sapply(slot(x,
  "Polygons"), slot, "area"))
str(areas)

areas is a list - each member is the vector of areas for rings belonging 
to the Polygons objects. You may also need to access the "hole" slot to 
see which "are" seen as holes for your data.

The areas are OK for planar coordinates, but only for these - for plotting 
the values, although not correct, are adequate for plot ordering.

Hope this helps,

Roger

>
> I have tried various combinations of commands with all returning either an error or 0. I know the area of the polygon is 4.760465 square meters (area slot) but cant seem to replicate this using areapl(). Is it possible to access the area slot directly instead of computing the area with areapl()?
>
> Many thanks,
> Wesley
>
>
> Wesley Roberts MSc.
> Researcher: Earth Observation (Ecosystems)
> Natural Resources and the Environment
> CSIR
> Tel: +27 (21) 888-2490
> Fax: +27 (21) 888-2693
>
> "To know the road ahead, ask those coming back."
> - Chinese proverb
>
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



-- 
This message is subject to the CSIR's copyright terms and conditions, e-mail legal notice, and implemented Open Document Format (ODF) standard. 
The full disclaimer details can be found at http://www.csir.co.za/disclaimer.html.

This message has been scanned for viruses and dangerous content by MailScanner, 
and is believed to be clean.  MailScanner thanks Transtec Computers for their support.


From milton.ruser at gmail.com  Thu May 14 17:42:09 2009
From: milton.ruser at gmail.com (milton ruser)
Date: Thu, 14 May 2009 11:42:09 -0400
Subject: [R-sig-Geo] Fwd: Moran's I : list of neighbour and generating
	residual maps.
In-Reply-To: <3aaf1a030905131555n48be1f1g1b1e2329b5e4c31a@mail.gmail.com>
References: <3aaf1a030905131555n48be1f1g1b1e2329b5e4c31a@mail.gmail.com>
Message-ID: <3aaf1a030905140842k7369db93m3c95aac5ae5e300d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090514/7f63e2a9/attachment.pl>

From lborger at uoguelph.ca  Thu May 14 18:32:26 2009
From: lborger at uoguelph.ca (Luca Borger)
Date: Thu, 14 May 2009 12:32:26 -0400 (EDT)
Subject: [R-sig-Geo] Constraining movements in adehabitat
In-Reply-To: <449364755.1954841242318377843.JavaMail.root@huron.cs.uoguelph.ca>
Message-ID: <1538246537.1957871242318746511.JavaMail.root@huron.cs.uoguelph.ca>

Hi Tim,

as suggested by David the methods developed by Jason Matthiopolous would be the most adequate for your problem, but no one has implemented them in R (more on this below). An alternative useful one could be the so-called non-parametric kernel method of Getz et al.:

Getz WM, Fortmann-Roe S, Cross PC, Lyons AJ, Ryan SJ, et al. 2007 LoCoH: Nonparameteric Kernel Methods for Constructing Home Ranges and Utilization Distributions. PLoS ONE 2(2): e207. doi:10.1371/journal.pone.0000207 

also called local convex-hull home range method (LoCoH):

Getz, W. M. and C. C. Wilmers, 2004. A local nearest-neighbor convex-hull construction of home ranges and utilization distributions. Ecography 27:489-505

The method is especially well-suited to follow sharp habitat boundaries and exclude non-used or unavailable areas. Of course, how well it will work in your case will depend on how well you have sampled the movements of your study species, i.e. if your sampling regime (intensity and timing of sampling) is adequate for the movement characteristics of your population and the complexity of the landscape. The method is implemented in adehabitat/ArcGis, but a nice extension to run it in ArcView 3.x is also available from the first author's website. 


Given that we are on the r-sig-geo list, the two papers by Jason Matthiopolous mentioned by David are among the best contributions so far written regarding animal movements and home ranges, so if anyone would be willing and able (and have the time) to implement these methods in R I believe it would be very useful to many people ;-)



HTH


Cheers,


Luca


--------------------------------------------
Luca Borger, PhD
Postdoctoral Research Fellow
University of Guelph
Guelph, ON, Canada

email: lborger at uoguelph.ca
http://www.researcherid.com/rid/C-6003-2008
http://uoguelph.academia.edu/LucaBorger
--------------------------------------------


----- Messaggio originale -----
Da: r-sig-geo-request at stat.math.ethz.ch
A: r-sig-geo at stat.math.ethz.ch
Inviato: Gioved?, 14 maggio 2009 6:00:05 GMT -05:00 U.S.A./Canada, stati orientali
Oggetto: R-sig-Geo Digest, Vol 69, Issue 14

Send R-sig-Geo mailing list submissions to
	r-sig-geo at stat.math.ethz.ch

Message: 16
Date: Thu, 14 May 2009 09:18:30 +0200
From: Pinaud David <pinaud at cebc.cnrs.fr>
Subject: Re: [R-sig-Geo] Constraining movements in adehabitat
To: Tim Clark <mudiver1200 at yahoo.com>, R-sig-Geo at stat.math.ethz.ch
Message-ID: <4A0BC5C6.9000005 at cebc.cnrs.fr>
Content-Type: text/plain; charset="windows-1252"; Format="flowed"

Dear Tim,

You can try several papers from Jason Matthioploulos, among:
Matthiopoulos (2003) The use of space by animals as a function of 
accessibility and
preference - Ecological Modelling 159 239-268
Matthiopoulos, J. 2003. Model-supervised kernel smoothing for the 
estimation of
spatial usage. ? Oikos 102: 367?377.
Unfortunately, I don't know a R implementation to do this directly. One 
(quick and dirty) way could be to weight the output of the Kernel 
estimation by a raster representing distance to coast (or ocean/continent)?

Hope it helps

David

Tim Clark a ?crit :
> Dear List,
>
> Sorry, this is a second attempt to post the same message.  My last one got scrubbed so I changed browser options.  Hopefully this one will make it!
>
> I am using the package adehabitat to analyze the movement patterns and home range of the manta ray (Manta birostris) in Hawaii.  The manta rays in this study stayed close to shore, often feeding along the shore line or in small bays.  Since they can not go on land (being fish) their home range is obviously limited to the ocean area.  In calculating home range statistics, is there a way to limit the avalible area to the ocean.  I have read through the papers on Adehabitat but have not found a way to limit the area. The closest I have found is the function buffer().  Have I missed something?  Is there a way to co

> nstrain the movements so that kernels will only be computed for data points located in the ocean?
>
> I appreciate your help and guidence.
>
> Tim
>
>
>
> Tim Clark
> PhD Student 
> University of Hawaii
> Honolulu, HI 96816
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> __________ Information from ESET Mail Security, version of virus signature database 4073 (20090513) __________
>
> The message was checked by ESET Mail Security.
> http://www.eset.com
>
>
>
>
>
>   

-- 
***************************************************
David PINAUD
Ing?nieur de Recherche "Analyses spatiales"

Centre d'Etudes Biologiques de Chiz? - CNRS UPR1934
79360 Villiers-en-Bois, France 
poste 485
Tel: +33 (0)5.49.09.35.58
Fax: +33 (0)5.49.09.65.26
http://www.cebc.cnrs.fr/


From Roger.Bivand at nhh.no  Thu May 14 19:40:40 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 14 May 2009 19:40:40 +0200 (CEST)
Subject: [R-sig-Geo] Fwd: Moran's I : list of neighbour and generating
 residual maps.
In-Reply-To: <3aaf1a030905140842k7369db93m3c95aac5ae5e300d@mail.gmail.com>
References: <3aaf1a030905131555n48be1f1g1b1e2329b5e4c31a@mail.gmail.com>
	<3aaf1a030905140842k7369db93m3c95aac5ae5e300d@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0905141930120.3711@reclus.nhh.no>

On Thu, 14 May 2009, milton ruser wrote:

> Dear all,
>
> Sorry for I forward this message to the list, but I got one error during
> yesterday when send it, and I am not sorry if it worked fine.

Yes, the line with the overlay() got corrupted, and still is.

Try:

require(rgdal)
require(adehabitat)
(file1 <-  paste(system.file(package = "adehabitat"),
                "ascfiles/elevation.asc", sep = "/"))
el <- readGDAL(file1)
image(el, axes=T)
el.pix <- as(el, "SpatialPixelsDataFrame")
el.pol <- as.SpatialPolygons.SpatialPixels(el.pix)
rn <- sapply(slot(el.pol, "polygons"), function(x) slot(x, "ID"))
df <- data.frame(rn=rn, row.names=rn)
el.pol.spdf<-SpatialPolygonsDataFrame(el.pol, data=df)
el.pol.spdf$pixvalue <- el.pix$band1
spplot(el.pix, col.regions=heat.colors(20))
x11()
spplot(el.pol.spdf, "pixvalue", col.regions=heat.colors(20))

moves the values without overlaying - since the SpatialPixels and 
SpatialPolygons objects match one-to-one, this is OK.

>From here you need a neighbour object, for example:

gsz <- gridparameters(el)[,2]
d <- ceiling(sqrt(sum(gsz^2)))
library(spdep)
nb_queen <- dnearneigh(coordinates(el.pol.spdf), 0, d)
nb_queen

before calculating Moran's I:

moran.test(el.pol.spdf$pixvalue, nb2listw(nb_queen, style="C"))

There will typically be a lot of autocorrelation if the raster cell 
resolution is much finer than the "size" of the entities.

Hope this helps,

Roger

>
> Bests
>
> milton
>
> ---------- Forwarded message ----------
> From: milton ruser <milton.ruser at gmail.com>
> Date: Wed, May 13, 2009 at 6:55 PM
> Subject: Moran's I : list of neighbour and generating residual maps.
> To: r-sig-geo at stat.math.ethz.ch
>
>
> Dear GeoR Gurus,
>
> I have some raster maps, with continuous values, and I would like
> to (1) calculate Local Moran's I ;  (2) generate a residual map considering
> different lags. I am trying to follow the Bivand and colleague's book,
> but I don't know how to generate the neighbour list for each lag.
>
> On the page 268 of book one can find a example of how to
> plot the moran I index like moran.plot(NY8$Cases, listw=nb2listw (NY_b,
> style="C")).
>
> On the code I read a raster map, vectorize it (each pixel is one polygon),
> and
> the pixel value are stored as attribute for the polygon.
>
> So, if somebody can help to solve the TWO questions listed above
> I would be very thanks.
>
> Cheers
>
> milton
> ====
> require(rgdal)
> require(adehabitat)
> (file1 <-  paste(system.file(package = "adehabitat"),
>               "ascfiles/elevation.asc", sep = "/"))
> el <- readGDAL(file1)
> image(el, axes=T)
> el.pix <- as(el, "SpatialPixelsDataFrame")
> el.pol <- as.SpatialPolygons.SpatialPixels(el.pix)
> str(el.pol, max.level=2)
> el.pol at polygons[[1]]
> plot(el.pol)
>
> rn <- sapply(slot(el.pol, "polygons"), function(x) slot(x, "ID"))
> df <- data.frame(rn=rn, row.names=rn)
>
> el.pol.spdf<-SpatialPolygonsDataFrame(el.pol, data=df)
> el.pol.spdf at data$pixvalue<-overlay(el<el.pol.spdf at data$pixvalue%3C-overlay(el>,
> el.pix)@data[,1]
> image(el, axes=T)
> plot(el.pol, add=T)
> head(el.pol.spdf at data)
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From mudiver1200 at yahoo.com  Fri May 15 02:29:06 2009
From: mudiver1200 at yahoo.com (Tim Clark)
Date: Thu, 14 May 2009 17:29:06 -0700 (PDT)
Subject: [R-sig-Geo] Constraining movements in adehabitat
Message-ID: <168773.84994.qm@web36101.mail.mud.yahoo.com>


David,

Thanks for the info and the references.  I don't think I want to weight the kernel by the distance from shore since sometimes they are right on the shoreline (2 ft. of water), and they should have high UD's very close to shore.  I was hoping there would be an easy way to constrain the area available, but no one has offered any.  Second option is to cut out the land from the kernel distribution.  Any idea if this is possible?

Thanks,

Tim

Tim Clark
Department of Zoology 
University of Hawaii


--- On Wed, 5/13/09, Pinaud David <pinaud at cebc.cnrs.fr> wrote:

> From: Pinaud David <pinaud at cebc.cnrs.fr>
> Subject: Re: [R-sig-Geo] Constraining movements in adehabitat
> To: "Tim Clark" <mudiver1200 at yahoo.com>, R-sig-Geo at stat.math.ethz.ch
> Date: Wednesday, May 13, 2009, 9:18 PM
> Dear Tim,
> 
> You can try several papers from Jason Matthioploulos,
> among:
> Matthiopoulos (2003) The use of space by animals as a
> function of 
> accessibility and
> preference - Ecological Modelling 159 239-268
> Matthiopoulos, J. 2003. Model-supervised kernel smoothing
> for the 
> estimation of
> spatial usage. ? Oikos 102: 367?377.
> Unfortunately, I don't know a R implementation to do this
> directly. One 
> (quick and dirty) way could be to weight the output of the
> Kernel 
> estimation by a raster representing distance to coast (or
> ocean/continent)?
> 
> Hope it helps
> 
> David
> 
> Tim Clark a ?crit :
> > Dear List,
> >
> > Sorry, this is a second attempt to post the same
> message.? My last one got scrubbed so I changed browser
> options.? Hopefully this one will make it!
> >
> > I am using the package adehabitat to analyze the
> movement patterns and home range of the manta ray (Manta
> birostris) in Hawaii.? The manta rays in this study
> stayed close to shore, often feeding along the shore line or
> in small bays.? Since they can not go on land (being
> fish) their home range is obviously limited to the ocean
> area.? In calculating home range statistics, is there a
> way to limit the avalible area to the ocean.? I have
> read through the papers on Adehabitat but have not found a
> way to limit the area. The closest I have found is the
> function buffer().? Have I missed something?? Is
> there a way to co
> 
> > nstrain the movements so that kernels will only be
> computed for data points located in the ocean?
> >
> > I appreciate your help and guidence.
> >
> > Tim
> >
> >
> >
> > Tim Clark
> > PhD Student 
> > University of Hawaii
> > Honolulu, HI 96816
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> >
> > __________ Information from ESET Mail Security,
> version of virus signature database 4073 (20090513)
> __________
> >
> > The message was checked by ESET Mail Security.
> > http://www.eset.com
> >
> >
> >
> >
> >
> >???
> 
> -- 
> ***************************************************
> David PINAUD
> Ing?nieur de Recherche "Analyses spatiales"
> 
> Centre d'Etudes Biologiques de Chiz? - CNRS UPR1934
> 79360 Villiers-en-Bois, France 
> poste 485
> Tel: +33 (0)5.49.09.35.58
> Fax: +33 (0)5.49.09.65.26
> http://www.cebc.cnrs.fr/
> 
> ***************************************************
> 
> 
> 
> 
> __________ Information from ESET Mail Security, version of
> virus signature database 4073 (20090513) __________
> 
> The message was checked by ESET Mail Security.
> http://www.eset.com
> 
> 





From basille at biomserv.univ-lyon1.fr  Fri May 15 09:04:44 2009
From: basille at biomserv.univ-lyon1.fr (Mathieu Basille)
Date: Fri, 15 May 2009 09:04:44 +0200
Subject: [R-sig-Geo] Constraining movements in adehabitat
In-Reply-To: <168773.84994.qm@web36101.mail.mud.yahoo.com>
References: <168773.84994.qm@web36101.mail.mud.yahoo.com>
Message-ID: <4A0D140C.2060200@biomserv.univ-lyon1.fr>

Tim, did you have a look at the LoCoH method, as proposed by Luca?
As far as I understood your problem, it's a very neat answer to it.

Mathieu.


Tim Clark a ?crit :
 > David,
 > Thanks for the info and the references.  I don't think I want to 
weight the kernel by the distance from shore since sometimes they are 
right on the shoreline (2 ft. of water), and they should have high UD's 
very close to shore.  I was hoping there would be an easy way to 
constrain the area available, but no one has offered any.  Second option 
is to cut out the land from the kernel distribution.  Any idea if this 
is possible?
 > Thanks,
 > Tim
 > Tim ClarkDepartment of Zoology University of Hawaii


-- 

mathieu at lbbe:~$ whoami
 > Mathieu Basille, PhD

mathieu at lbbe:~$ locate
 > Laboratoire de Biom?trie et Biologie ?volutive
 > Universit? Claude Bernard Lyon 1 - France
 > http://lbbe.univ-lyon1.fr/

mathieu at lbbe:~$ info
 > http://ase-research.org/basille

mathieu at lbbe:~$ fortune
 > ``If you can't win by reason, go for volume.''
 > Calvin, by Bill Watterson.


From p.hiemstra at geo.uu.nl  Fri May 15 13:19:28 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Fri, 15 May 2009 13:19:28 +0200
Subject: [R-sig-Geo] problem with function project() in package rgdal
In-Reply-To: <49D88830.80902@cirad.fr>
References: <49D88830.80902@cirad.fr>
Message-ID: <4A0D4FC0.40506@geo.uu.nl>

Hi Renaud,

I don't get the same error, the piece of code runs fine. To which 
version of proj did you build rgdal? My versions are:

Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 1.4.4.0, released 2007/11/23
Path to GDAL shared files: /usr/share/gdal
Loaded PROJ.4 runtime: Rel. 4.6.0, 21 Dec 2007
Path to PROJ.4 shared files: (autodetected)

Googleing for "major axis or radius = 0 or not given" will give you some 
useful things to start with.

As a remark, I always transform my spatial data to sp-classes (using 
coordinates() or gridded(), see sp-docs) and then use spTransform to 
perform the reprojection.

cheers,
Paul

This is my sessionInfo():

R version 2.9.0 (2009-04-17)
i486-pc-linux-gnu

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] rgdal_0.6-5 sp_0.9-29

loaded via a namespace (and not attached):
[1] grid_2.9.0      lattice_0.17-20 tools_2.9.0


Renaud Lancelot wrote:
> Dear all,
>
> I meet a problem with the function project() in package rgdal:
>
>> library(rgdal)
>> data(state)
>> res <- project(cbind(state.center$x, state.center$y),
> +                "+proj=lcc +lat_1=48 +lat_2=33 +lon_0=-100")
> Error in project(cbind(state.center$x, state.center$y), "+proj=lcc
> +lat_1=48 +lat_2=33 +lon_0=-100") :
>   major axis or radius = 0 or not given
>
>
>> sessionInfo()
> R version 2.8.1 Patched (2009-02-17 r47956)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=French_France.1252;LC_CTYPE=French_France.1252;LC_MONETARY=French_France.1252;LC_NUMERIC=C;LC_TIME=French_France.1252 
>
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> [7] base
>
> other attached packages:
> [1] rgdal_0.6-7    sp_0.9-34      fortunes_1.3-6
>
> loaded via a namespace (and not attached):
> [1] grid_2.8.1      lattice_0.17-20 tools_2.8.1
>>
>
> Is this a bug?
>


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From wroberts at csir.co.za  Fri May 15 14:43:33 2009
From: wroberts at csir.co.za (Wesley Roberts)
Date: Fri, 15 May 2009 14:43:33 +0200
Subject: [R-sig-Geo] calculate minimum radial separation
Message-ID: <4A0D7F94.8E3B.0073.0@csir.co.za>

Dear r-sig-geo,

I would like to calculate the minimum radial separation of a polygon. Basically this involves finding the minimum and maximum distance from the centroid of a polygon to its boundary. I am using it to calculate a roundness index (or something approximating that). Using spstat classes and functionality I have been able to calculate the shortest distance between a centroid and its polygon boundary (bdist.points) but would now like to calculate the maximum distance and have not been able to find a suitable function to do so. Below is an example of what I am trying to do, however bdist.points only returns the shortest distance, how do I calculate the maximum distance? 

> w <- owin(c(10,20), c(10,30), unitname=c("foot","feet"))
> p <- ppp(15,20,window=w)
> bdist.points(p)
[1] 5

Is their a plug-and-play function in one of the spatial R packages to calculate the minimum maximum distance from a centroid to its polygon boundary?

Many thanks for your help,
Wesley





Wesley Roberts MSc.
Researcher: Earth Observation (Ecosystems)
Natural Resources and the Environment
CSIR
Tel: +27 (21) 888-2490
Fax: +27 (21) 888-2693

"To know the road ahead, ask those coming back."
- Chinese proverb




-- 
This message is subject to the CSIR's copyright terms and conditions, e-mail legal notice, and implemented Open Document Format (ODF) standard. 
The full disclaimer details can be found at http://www.csir.co.za/disclaimer.html.

This message has been scanned for viruses and dangerous content by MailScanner, 
and is believed to be clean.  MailScanner thanks Transtec Computers for their support.


From renaud.lancelot at cirad.fr  Fri May 15 17:54:09 2009
From: renaud.lancelot at cirad.fr (Renaud Lancelot)
Date: Fri, 15 May 2009 17:54:09 +0200
Subject: [R-sig-Geo] problem with function project() in package rgdal
In-Reply-To: <4A0D4FC0.40506@geo.uu.nl>
References: <49D88830.80902@cirad.fr> <4A0D4FC0.40506@geo.uu.nl>
Message-ID: <4A0D9021.2080001@cirad.fr>

Dear Paul,

Thank you for you reply. Everything works fine now with the current 
versions of R, rgdal and sp:

 > library(rgdal)
Le chargement a n?cessit? le package : sp
Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 1.6.0, released 2008/12/04
Path to GDAL shared files: C:/R/RLIBS/rgdal/gdal
Loaded PROJ.4 runtime: Rel. 4.6.1, 21 August 2008
Path to PROJ.4 shared files: C:/R/RLIBS/rgdal/proj
 > data(state)
 > res <- project(cbind(state.center$x, state.center$y), "+proj=lcc 
+lat_1=48 +lat_2=33 +lon_0=-100")
 > sessionInfo()
R version 2.9.0 (2009-04-17)
i386-pc-mingw32

locale:
LC_COLLATE=French_France.1252;LC_CTYPE=French_France.1252;LC_MONETARY=French_France.1252;LC_NUMERIC=C;LC_TIME=French_France.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] rgdal_0.6-8    sp_0.9-36      fortunes_1.3-6

loaded via a namespace (and not attached):
[1] grid_2.9.0      lattice_0.17-22 tools_2.9.0

I don't know what happened...

Best regards,

Renaud



Paul Hiemstra a ?crit :
> Hi Renaud,
> 
> I don't get the same error, the piece of code runs fine. To which 
> version of proj did you build rgdal? My versions are:
> 
> Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 1.4.4.0, released 2007/11/23
> Path to GDAL shared files: /usr/share/gdal
> Loaded PROJ.4 runtime: Rel. 4.6.0, 21 Dec 2007
> Path to PROJ.4 shared files: (autodetected)
> 
> Googleing for "major axis or radius = 0 or not given" will give you some 
> useful things to start with.
> 
> As a remark, I always transform my spatial data to sp-classes (using 
> coordinates() or gridded(), see sp-docs) and then use spTransform to 
> perform the reprojection.
> 
> cheers,
> Paul
> 
> This is my sessionInfo():
> 
> R version 2.9.0 (2009-04-17)
> i486-pc-linux-gnu
> 
> locale:
> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C 
> 
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] rgdal_0.6-5 sp_0.9-29
> 
> loaded via a namespace (and not attached):
> [1] grid_2.9.0      lattice_0.17-20 tools_2.9.0
> 
> 
> Renaud Lancelot wrote:
>> Dear all,
>>
>> I meet a problem with the function project() in package rgdal:
>>
>>> library(rgdal)
>>> data(state)
>>> res <- project(cbind(state.center$x, state.center$y),
>> +                "+proj=lcc +lat_1=48 +lat_2=33 +lon_0=-100")
>> Error in project(cbind(state.center$x, state.center$y), "+proj=lcc
>> +lat_1=48 +lat_2=33 +lon_0=-100") :
>>   major axis or radius = 0 or not given
>>
>>
>>> sessionInfo()
>> R version 2.8.1 Patched (2009-02-17 r47956)
>> i386-pc-mingw32
>>
>> locale:
>> LC_COLLATE=French_France.1252;LC_CTYPE=French_France.1252;LC_MONETARY=French_France.1252;LC_NUMERIC=C;LC_TIME=French_France.1252 
>>
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods
>> [7] base
>>
>> other attached packages:
>> [1] rgdal_0.6-7    sp_0.9-34      fortunes_1.3-6
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.8.1      lattice_0.17-20 tools_2.8.1
>>>
>>
>> Is this a bug?
>>
> 
> 

-- 
Renaud Lancelot
EDEN Project, coordinator
http://www.eden-fp6project.net/

UMR CIRAD-INRA "Contr?le des maladies animales exotiques et ?mergentes"
Joint research unit "Control of emerging and exotic animal diseases"

CIRAD
Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier
http://www.cirad.fr  http://bluetongue.cirad.fr/

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69


From aslez at ssc.wisc.edu  Mon May 18 00:35:21 2009
From: aslez at ssc.wisc.edu (aslez at ssc.wisc.edu)
Date: Sun, 17 May 2009 17:35:21 -0500 (CDT)
Subject: [R-sig-Geo] differences between gwr.sel and GWR3?
Message-ID: <2993.144.92.114.163.1242599721.squirrel@webmail.ssc.wisc.edu>

In general, what are the differences between the way in which gwr.sel and
Fotheringham et al.s GWR3 optimize bandwidths?  Should I be able to
replicate the optimal bandwidths suggested by GWR3 using gwr.sel?  Using
various datasets (including the Georgia data which accompanies both
packages), I have consistently found noticable differences in the
bandwidths suggested by each program.

Am I missing something?

Adam Slez
Department of Sociology
University of Wisconsin-Madison


From alobolistas at gmail.com  Mon May 18 19:36:31 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Mon, 18 May 2009 19:36:31 +0200
Subject: [R-sig-Geo] raster package
Message-ID: <4A119C9F.1000809@gmail.com>

I have to reclassify a large (> 8000x8000 pixels) geotif raster. I normally
would do it through grass (or saga) but would like to try the raster
package in R.
The problem is that I'm a bit confused on how to do it. My understanding
of the package
is that it provides a way to operate in the rasters by pieces, not having
to read the whole thing into memory. I've seen there's a function reclass()
but how do I actually read the raster? If I use readAll() this is going
to be as
using readGDAL() directly, so this is not the way. Do I have to use
a for() of readRows(), then reclass()? This seems a bit low-level. Is
there a way
of assigning the tif file to an R raster object and then just use
reclass() and R would
read the file by pieces as needed? That's what I would like to...

Agus


-------------- next part --------------
A non-text attachment was scrubbed...
Name: alobolistas.vcf
Type: text/x-vcard
Size: 251 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090518/5166a0ea/attachment.vcf>

From tsippel at gmail.com  Tue May 19 01:28:09 2009
From: tsippel at gmail.com (Tim Sippel)
Date: Tue, 19 May 2009 11:28:09 +1200
Subject: [R-sig-Geo] Raster package, projectRaster() filetype issue
Message-ID: <79a13c220905181628r616fefcdge19fac5af47309e1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090519/e2cc3c7e/attachment.pl>

From r.hijmans at gmail.com  Tue May 19 02:06:54 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Tue, 19 May 2009 08:06:54 +0800
Subject: [R-sig-Geo] raster package
In-Reply-To: <4A119C9F.1000809@gmail.com>
References: <4A119C9F.1000809@gmail.com>
Message-ID: <dc22b2570905181706w5302d428scd4392d465965ffd@mail.gmail.com>

Agus,

> Is there a way
> of assigning the tif file to an R raster object and then just use
> reclass() and R would
> read the file by pieces as needed? That's what I would like to...

That is exactly what is intended with reclass(). Something like this :

r <- raster('mytiffile.tif')
m <- matrix(0,1000,1, 1000, Inf, NA, ncol=2)
rc <- reclass(r, m, ...)

Robert

On Tue, May 19, 2009 at 1:36 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
> I have to reclassify a large (> 8000x8000 pixels) geotif raster. I normally
> would do it through grass (or saga) but would like to try the raster
> package in R.
> The problem is that I'm a bit confused on how to do it. My understanding
> of the package
> is that it provides a way to operate in the rasters by pieces, not having
> to read the whole thing into memory. I've seen there's a function reclass()
> but how do I actually read the raster? If I use readAll() this is going
> to be as
> using readGDAL() directly, so this is not the way. Do I have to use
> a for() of readRows(), then reclass()? This seems a bit low-level. Is
> there a way
> of assigning the tif file to an R raster object and then just use
> reclass() and R would
> read the file by pieces as needed? That's what I would like to...
>
> Agus
>
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From r.hijmans at gmail.com  Tue May 19 02:17:44 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Tue, 19 May 2009 08:17:44 +0800
Subject: [R-sig-Geo] Raster package, projectRaster() filetype issue
In-Reply-To: <79a13c220905181628r616fefcdge19fac5af47309e1@mail.gmail.com>
References: <79a13c220905181628r616fefcdge19fac5af47309e1@mail.gmail.com>
Message-ID: <dc22b2570905181717wbf54faasd141f606c1df5b7e@mail.gmail.com>

Tim,
Thanks, that is a bug. It has been fixed in Version 0.8.9-20
(19-May-2009). Automatic install should be available from r-forge in
24 hours.
Robert

On Tue, May 19, 2009 at 7:28 AM, Tim Sippel <tsippel at gmail.com> wrote:
> I'm using the raster package version 0.8.9-17 on R2.9.0. While using the
> function projectRaster I'm projecting my data and need to output a new ESRI
> grid (.asc). ?The following code I think should do the job, but it is
> writing two different files (.grd and .gri) instead of the .asc I need. ?Is
> this a bug?
>
> asc.in.dir<-"C:\\..\\raster.directory"
> asc.out.dir<-"C:\\...\\raster.directory\\UTMprojected"
> asc.in.files<-dir(asc.in.dir, pattern='.asc$')
> r<-raster(paste(asc.in.dir, "\\", asc.in.files[i], sep=""))
> r[]<-1:ncell(r)
> projection(r) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"
> newproj <- "+proj=sinu"
> projext <- projectExtent(object=r, projs=newproj)
> projras <- projectRaster(from=r, to=projext, method="ngb", filetype="ascii",
>
> ?filename=paste(asc.out.dir, "\\UTM <file://utm/>", asc.in.files[i],
> sep=""))
>
> Tim
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From milton.ruser at gmail.com  Tue May 19 03:51:37 2009
From: milton.ruser at gmail.com (milton ruser)
Date: Mon, 18 May 2009 21:51:37 -0400
Subject: [R-sig-Geo] subsetting SpatialGridDataFrame
Message-ID: <3aaf1a030905181851i51031f5bo64c6b77c3d874af2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090518/76dae7b0/attachment.pl>

From r.hijmans at gmail.com  Tue May 19 04:29:20 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Tue, 19 May 2009 10:29:20 +0800
Subject: [R-sig-Geo] rgdal project; inverse does not return original values
Message-ID: <dc22b2570905181929u686f3354n4f7910c335a59356@mail.gmail.com>

I am confused about this behavior of rgdal

> require(rgdal)
> # make a matrix of coordinates
> xygeo <- rbind(c(-180, 0), c(180,0), c(0,0), c(0,20), c(0,90))
> # project to sinusoidial
> xysin <- project(xygeo, "+proj=sinu", inv=FALSE)
> # project back to longlat
> xyinv <- project(xysin, "+proj=longlat", inv=TRUE)
> xygeo
     [,1] [,2]
[1,] -180    0
[2,]  180    0
[3,]    0    0
[4,]    0   20
[5,]    0   90
> xyinv
     [,1]      [,2]
[1,]  180         0
[2,] -180         0
[3,]    0         0
[4,]    0 126759249
[5,]    0 573070423
>

Why are rows 4 and 5 different?


An illustration of the same problem, using 'raster'

> library(raster)
> r <- raster(nrow=36, ncol=18,  projs= "+proj=longlat")
> xy <- xyFromCell(r,1:ncell(r))
> par(mfrow=c(1, 3))
> plot(xy) # ok
> xysin <- project(xy, "+proj=sinu", inv=FALSE)
> plot(xysin)   # nice
> xyinv <- project(xysin, "+proj=longlat", inv=TRUE)
> plot(xyinv)  # ???


Robert

> sessionInfo()
R version 2.9.0 (2009-04-17)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] rgdal_0.6-8 sp_0.9-34

loaded via a namespace (and not attached):
[1] grid_2.9.0      lattice_0.17-22
>


From r.hijmans at gmail.com  Tue May 19 04:41:52 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Tue, 19 May 2009 10:41:52 +0800
Subject: [R-sig-Geo] rgdal project;
	inverse does not return original values
In-Reply-To: <dc22b2570905181929u686f3354n4f7910c335a59356@mail.gmail.com>
References: <dc22b2570905181929u686f3354n4f7910c335a59356@mail.gmail.com>
Message-ID: <dc22b2570905181941u48bdb630v47d47a054a05b669@mail.gmail.com>

Sorry, that was stupid,
This:
 xyinv <- project(xysin, "+proj=longlat", inv=TRUE)

had to be:
 xyinv <- project(xysin, "+proj=sinu", inv=TRUE)

problem solved....

Robert

On Tue, May 19, 2009 at 10:29 AM, Robert Hijmans <r.hijmans at gmail.com> wrote:
> I am confused about this behavior of rgdal
>
>> require(rgdal)
>> # make a matrix of coordinates
>> xygeo <- rbind(c(-180, 0), c(180,0), c(0,0), c(0,20), c(0,90))
>> # project to sinusoidial
>> xysin <- project(xygeo, "+proj=sinu", inv=FALSE)
>> # project back to longlat
>> xyinv <- project(xysin, "+proj=longlat", inv=TRUE)
>> xygeo
> ? ? [,1] [,2]
> [1,] -180 ? ?0
> [2,] ?180 ? ?0
> [3,] ? ?0 ? ?0
> [4,] ? ?0 ? 20
> [5,] ? ?0 ? 90
>> xyinv
> ? ? [,1] ? ? ?[,2]
> [1,] ?180 ? ? ? ? 0
> [2,] -180 ? ? ? ? 0
> [3,] ? ?0 ? ? ? ? 0
> [4,] ? ?0 126759249
> [5,] ? ?0 573070423
>>
>
> Why are rows 4 and 5 different?
>
>
> An illustration of the same problem, using 'raster'
>
>> library(raster)
>> r <- raster(nrow=36, ncol=18, ?projs= "+proj=longlat")
>> xy <- xyFromCell(r,1:ncell(r))
>> par(mfrow=c(1, 3))
>> plot(xy) # ok
>> xysin <- project(xy, "+proj=sinu", inv=FALSE)
>> plot(xysin) ? # nice
>> xyinv <- project(xysin, "+proj=longlat", inv=TRUE)
>> plot(xyinv) ?# ???
>
>
> Robert
>
>> sessionInfo()
> R version 2.9.0 (2009-04-17)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] rgdal_0.6-8 sp_0.9-34
>
> loaded via a namespace (and not attached):
> [1] grid_2.9.0 ? ? ?lattice_0.17-22
>>
>


From Sarah.Spaulding at Colorado.EDU  Tue May 19 18:48:21 2009
From: Sarah.Spaulding at Colorado.EDU (Sarah A Spaulding)
Date: Tue, 19 May 2009 10:48:21 -0600 (MDT)
Subject: [R-sig-Geo] using Albers equal area conic projection
Message-ID: <20090519104821.AMU87991@superman.int.colorado.edu>

I working to generate a map of diatom species presence, abundance and relative abundance for the western US. I would like to use an Albers equal area conic projection, with standard parallels of 29.5, 45.5, and central meridion of 96. The map that I generate does not match the one that (at least I think) is an Albers projection.

Is it correct to specify the standard parallels in the parameter statement? For example,
map("world", projection ="albers", parameter =c(29.5,45.5), fill=FALSE, xlim=c(-125, -95), ylim = c(30,50))

How is the central meridian specified? I have tried using the "orientation" argument, but I don't think that is quite right, as I get rotated maps.

I appreciate suggestions on what I might be missing.

---------------------------------
# make a map of the US distribution


# read from one file that contains lat & lon sites for species
tax1 <- read.csv("EMAPweblist_2008_01_08.csv", header = T)

# specify the taxon column number in tax1
tax <- 217
  
library (maps)

# create a map using the Albers equal area conic projection  
# the standard parallels are 29.5 and 45.5, is it correct to place these in "parameters = c(29.5,45.5)"?
# the central meridian is 96, how is that designated? 

# create the map
map("world", projection ="albers", parameter =c(29.5,45.5), fill=FALSE, xlim=c(-125, -95), ylim = c(30,50))
map("state", projection ="", par=c(29.5,45.5), boundary = FALSE, lty = 2, add = TRUE)

map.axes()

# plot points on the map for species absence, presence and relative abundance
points (mapproject (tax1$LON_DD, tax1$LAT_DD, projection = "albers", par=c(29.5,45.5)), cex = .6, pch = 20)
points (mapproject (tax1$LON_DD, tax1$LAT_DD, projection = "albers", par=c(29.5,45.5)), lwd = 5, cex = (tax1$dummy_20 * 20), col = "red")

--------------------------
Sarah A. Spaulding
Ecologist, US Geological Survey


From pisicandru at hotmail.com  Tue May 19 20:24:07 2009
From: pisicandru at hotmail.com (Monica Pisica)
Date: Tue, 19 May 2009 18:24:07 +0000
Subject: [R-sig-Geo] read NITF save as geotif
Message-ID: <BAY130-W13069E5E83D8E69199C90FC35B0@phx.gbl>


Hi,
 
I have some NITF  (in lat long) files and i would like to save them as geotif. Things would be almost straightforward but .... the pixels in the original image are rectangular, and not square, so i cannot grid. Do you have any idea how i can go around this? 
 
Thanks, i will really appreciate that.
 
Monica
_________________________________________________________________
Insert movie times and more without leaving Hotmail?.

orial_QuickAdd1_052009

From prairie.picker at gmail.com  Tue May 19 20:47:14 2009
From: prairie.picker at gmail.com (Tyler Dean Rudolph)
Date: Tue, 19 May 2009 14:47:14 -0400
Subject: [R-sig-Geo] convert owin object to SpatialPolygons object (write
	buffered MCP to shapefile)
Message-ID: <9fb1ae890905191147y6655ffdcub08c967606416a4a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090519/05dbb4ac/attachment.pl>

From adrian at maths.uwa.edu.au  Wed May 20 03:51:09 2009
From: adrian at maths.uwa.edu.au (Adrian Baddeley)
Date: Wed, 20 May 2009 09:51:09 +0800
Subject: [R-sig-Geo] convert owin object to SpatialPolygons object (write
 buffered MCP to shapefile)
Message-ID: <4A13620D.8040000@maths.uwa.edu.au>

Tyler Dean Rudolph writes:

> I'd like to create a buffered minimum convex polygon around a set of points and write the buffered polygon to a shapefile. 
> I have two columns, x and y, for the geographic locations.  I can use convexhull.xy in spatstat to create the MCP as 
> an owin, then use dilate.owin to enlarge the window, but how can I now convert the owin (or im) object into a 
> SpatialPolygons object in order to write it to a shapefile?  

Take the convex hull of the boundary pixels:
          convexhull.xy(vertices(dilate.owin(convex.hull(ORIGINALDATA), RADIUS)))

This converts it to a polygonal owin object which you can then convert to a SpatialPolygons object using as(). 

Alternatively if you want the buffered region to have the same shape as the convex hull, so that the buffer is a "scalar dilation" i.e. simply an enlarged version of the convex hull, then use the function 'ripras'. In spatstat 1.15-3 and later, you can control the enlargement factor.

Adrian Baddeley


From a.lam at geo.uu.nl  Wed May 20 11:31:18 2009
From: a.lam at geo.uu.nl (Arien Lam)
Date: Wed, 20 May 2009 11:31:18 +0200 (CEST)
Subject: [R-sig-Geo] read NITF save as geotif
In-Reply-To: <BAY130-W13069E5E83D8E69199C90FC35B0@phx.gbl>
References: <BAY130-W13069E5E83D8E69199C90FC35B0@phx.gbl>
Message-ID: <ea7f5b8ceea3aa93ccdce93a1c8765c1.squirrel@webmail.geo.uu.nl>

Hi Monica,

It should be straightforward using rgdal. Gtiff output is default,
resolution is preserved by default, GDAL supports nitf (didn't test this)
and geotiff supports x resolution and y resolution separately (x and y
resolution may differ, but are constant for the image). So I expect the
following snippet to work (if it doesn't, show us what goes wrong):

require('rgdal')

GDALinfo('yourfile') # look at res.x and res.y

imagery <- readGDAL('yourfile')
writeGDAL(imagery, 'destinationfile')

GDALinfo('destinationfile')

Hope this helps,

Arien


On Tue, May 19, 2009 20:24, Monica Pisica wrote:
>
> Hi,
>
> I have some NITF  (in lat long) files and i would like to save them as
> geotif. Things would be almost straightforward but .... the pixels in the
> original image are rectangular, and not square, so i cannot grid. Do you
> have any idea how i can go around this?
>
> Thanks, i will really appreciate that.
>
> Monica
> _________________________________________________________________
> Insert movie times and more without leaving Hotmail?.
>
> orial_QuickAdd1_052009
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


-- 
drs. H.A. (Arien) Lam (Ph.D. student)
Department of Physical Geography
Faculty of Geosciences
Utrecht University, The Netherlands


From Pilar.Tugores at ba.ieo.es  Wed May 20 12:16:27 2009
From: Pilar.Tugores at ba.ieo.es (Pilar Tugores Ferra)
Date: Wed, 20 May 2009 12:16:27 +0200
Subject: [R-sig-Geo] shortest distance from points to polylines
In-Reply-To: <ea7f5b8ceea3aa93ccdce93a1c8765c1.squirrel@webmail.geo.uu.nl>
References: <BAY130-W13069E5E83D8E69199C90FC35B0@phx.gbl> 
	<ea7f5b8ceea3aa93ccdce93a1c8765c1.squirrel@webmail.geo.uu.nl>
Message-ID: <0838E01493845742A4D4039EA34EB1C1613230@ieopalma2.ba.ieo.es>


Hi list!
I need computing shortest distance from points to a polyline layer (coast line).
I've been searching all the morning a function in R that can do this but couldn't find anything! 
Is there any R function that do this? Or can anybody give me some hint about how it could be done?
Kind regards!
Pilar


M? Pilar Tugores Ferr?
PhD Student
Instituto Espa?ol de Oceanograf?a
Centro Oceanogr?fico de Baleares
Muelle de Poniente s/n
07015 Palma de Mallorca
Baleares, Espa?a
Telf.: (34) 971 401561

La informaci?n contenida en este e-mail y sus ficheros adjuntos es totalmente confidencial y no deber?a ser usado si no fuera usted alguno de los destinatarios. Si ha recibido este e-mail por error, por favor avise al remitente y b?rrelo de su buz?n o de cualquier otro medio de almacenamiento.   This email is confidential and should not be used by anyone who is not the original intended  recipient. If you have received this e-mail in  error please inform the sender and delete it from  your mailbox or any other storage mechanism.


From miguel.gil.biraud at ieee.org  Wed May 20 12:38:42 2009
From: miguel.gil.biraud at ieee.org (Miguel Eduardo Gil Biraud)
Date: Wed, 20 May 2009 12:38:42 +0200
Subject: [R-sig-Geo] shortest distance from points to polylines
In-Reply-To: <0838E01493845742A4D4039EA34EB1C1613230@ieopalma2.ba.ieo.es>
References: <BAY130-W13069E5E83D8E69199C90FC35B0@phx.gbl>
	<ea7f5b8ceea3aa93ccdce93a1c8765c1.squirrel@webmail.geo.uu.nl>
	<0838E01493845742A4D4039EA34EB1C1613230@ieopalma2.ba.ieo.es>
Message-ID: <bba7081f0905200338t77499b9dr1356bc724f38629b@mail.gmail.com>

Hi Pilar!

I found this exchange in the R-SIG-GEO mailing list...

http://markmail.org/message/yxysd44dekpr3de3?q=r-sig-geo+distance+point+shape

hope it helps!
Miguel

On Wed, May 20, 2009 at 12:16, Pilar Tugores Ferra
<Pilar.Tugores at ba.ieo.es> wrote:
>
> Hi list!
> I need computing shortest distance from points to a polyline layer (coast line).
> I've been searching all the morning a function in R that can do this but couldn't find anything!
> Is there any R function that do this? Or can anybody give me some hint about how it could be done?
> Kind regards!
> Pilar
>
>
> M? Pilar Tugores Ferr?
> PhD Student
> Instituto Espa?ol de Oceanograf?a
> Centro Oceanogr?fico de Baleares
> Muelle de Poniente s/n
> 07015 Palma de Mallorca
> Baleares, Espa?a
> Telf.: (34) 971 401561
>
> La informaci?n contenida en este e-mail y sus ficheros adjuntos es totalmente confidencial y no deber?a ser usado si no fuera usted alguno de los destinatarios. Si ha recibido este e-mail por error, por favor avise al remitente y b?rrelo de su buz?n o de cualquier otro medio de almacenamiento. ? This email is confidential and should not be used by anyone who is not the original intended ?recipient. If you have received this e-mail in ?error please inform the sender and delete it from ?your mailbox or any other storage mechanism.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
http://franchu.net


From ksafi at orn.mpg.de  Wed May 20 12:41:08 2009
From: ksafi at orn.mpg.de (Kamran Safi)
Date: Wed, 20 May 2009 12:41:08 +0200
Subject: [R-sig-Geo] shortest distance from points to polylines
In-Reply-To: <0838E01493845742A4D4039EA34EB1C1613230@ieopalma2.ba.ieo.es>
References: <BAY130-W13069E5E83D8E69199C90FC35B0@phx.gbl>
	<ea7f5b8ceea3aa93ccdce93a1c8765c1.squirrel@webmail.geo.uu.nl>
	<0838E01493845742A4D4039EA34EB1C1613230@ieopalma2.ba.ieo.es>
Message-ID: <4A13DE44.8020904@orn.mpg.de>

Hi Pilar,

I had to do the same recently and find the shortest distance from a 
point to a line. The solution I chose was to point sample the line and 
then find the nearest point from the sample. You can work with 
spsample() and spDistN1().
Here's the bit that did it for me (it can be written shorter):

tempPoints <- spsample(<Line>, n=samplesize, type="regular")  # sample 
it at an interval
tempPoints<- as.matrix(as.data.frame(tempPoints))   #get their coordinates
dists <- as.data.frame(cbind(Longitude=tempPoints[,1], 
Latitude=tempPoints[,2], distance=spDistsN1(as.matrix(tempPoints), 
c(<POF_Long>, <POF_Lat>), longlat=FALSE)))  #calculate the distances of 
the point of interest from the sample points on the segment
dists <- dists[order(dists$distance),]  #sort by distance
P1 <- dists[1,c("Longitude", "Latitude")] # get the closest point on the 
segment to the watch site

hth

Kami


Pilar Tugores Ferra wrote:
> Hi list!
> I need computing shortest distance from points to a polyline layer (coast line).
> I've been searching all the morning a function in R that can do this but couldn't find anything! 
> Is there any R function that do this? Or can anybody give me some hint about how it could be done?
> Kind regards!
> Pilar
>
>
> M? Pilar Tugores Ferr?
> PhD Student
> Instituto Espa?ol de Oceanograf?a
> Centro Oceanogr?fico de Baleares
> Muelle de Poniente s/n
> 07015 Palma de Mallorca
> Baleares, Espa?a
> Telf.: (34) 971 401561
>
> La informaci?n contenida en este e-mail y sus ficheros adjuntos es totalmente confidencial y no deber?a ser usado si no fuera usted alguno de los destinatarios. Si ha recibido este e-mail por error, por favor avise al remitente y b?rrelo de su buz?n o de cualquier otro medio de almacenamiento.   This email is confidential and should not be used by anyone who is not the original intended  recipient. If you have received this e-mail in  error please inform the sender and delete it from  your mailbox or any other storage mechanism.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>   

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/x-pkcs7-signature
Size: 3275 bytes
Desc: S/MIME Cryptographic Signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090520/0f88894f/attachment.bin>

From marcelino.delacruz at upm.es  Wed May 20 12:43:29 2009
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Wed, 20 May 2009 12:43:29 +0200
Subject: [R-sig-Geo] shortest distance from points to polylines
In-Reply-To: <0838E01493845742A4D4039EA34EB1C1613230@ieopalma2.ba.ieo.es
 >
References: <BAY130-W13069E5E83D8E69199C90FC35B0@phx.gbl>
	<ea7f5b8ceea3aa93ccdce93a1c8765c1.squirrel@webmail.geo.uu.nl>
	<0838E01493845742A4D4039EA34EB1C1613230@ieopalma2.ba.ieo.es>
Message-ID: <200905201043.n4KAhGCH010316@edison.ccupm.upm.es>

Hi Pilar,

One option could be converting  your point data 
to ppp and your  polyline to psp objects in spatstat.

Then, use nncross.


Cheers,


Marcelino


At 12:16 20/05/2009, Pilar Tugores Ferra wrote:

>Hi list!
>I need computing shortest distance from points 
>to a polyline layer (coast line).
>I've been searching all the morning a function 
>in R that can do this but couldn't find anything!
>Is there any R function that do this? Or can 
>anybody give me some hint about how it could be done?
>Kind regards!
>Pilar
>
>
>M? Pilar Tugores Ferr?
>PhD Student
>Instituto Espa?ol de Oceanograf?a
>Centro Oceanogr?fico de Baleares
>Muelle de Poniente s/n
>07015 Palma de Mallorca
>Baleares, Espa?a
>Telf.: (34) 971 401561
>
>La informaci?n contenida en este e-mail y sus 
>ficheros adjuntos es totalmente confidencial y 
>no deber?a ser usado si no fuera usted alguno de 
>los destinatarios. Si ha recibido este e-mail 
>por error, por favor avise al remitente y 
>b?rrelo de su buz?n o de cualquier otro medio de 
>almacenamiento.   This email is confidential and 
>should not be used by anyone who is not the 
>original intended  recipient. If you have 
>received this e-mail in  error please inform the 
>sender and delete it from  your mailbox or any other storage mechanism.
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at stat.math.ethz.ch
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo

________________________________

Marcelino de la Cruz Rot

Departamento de  Biolog?a Vegetal
E.U.T.I. Agr?cola
Universidad Polit?cnica de Madrid
28040-Madrid
Tel.: 91 336 54 35
Fax: 91 336 56 56
marcelino.delacruz at upm.es


From tech_dev at wildintellect.com  Wed May 20 14:33:03 2009
From: tech_dev at wildintellect.com (Alex Mandel)
Date: Wed, 20 May 2009 05:33:03 -0700
Subject: [R-sig-Geo] shortest distance from points to polylines
In-Reply-To: <0838E01493845742A4D4039EA34EB1C1613230@ieopalma2.ba.ieo.es>
References: <BAY130-W13069E5E83D8E69199C90FC35B0@phx.gbl>
	<ea7f5b8ceea3aa93ccdce93a1c8765c1.squirrel@webmail.geo.uu.nl>
	<0838E01493845742A4D4039EA34EB1C1613230@ieopalma2.ba.ieo.es>
Message-ID: <4A13F87F.4060309@wildintellect.com>

Pilar Tugores Ferra wrote:
> Hi list!
> I need computing shortest distance from points to a polyline layer (coast line).
> I've been searching all the morning a function in R that can do this but couldn't find anything! 
> Is there any R function that do this? Or can anybody give me some hint about how it could be done?
> Kind regards!
> Pilar
> 
> 
> M? Pilar Tugores Ferr?

This is more straightforward if you use GRASS.
v.distance

I seem to recall a library to allow you to connect and run GRASS
commands from R, but maybe google or someone can elaborate.
http://grass.osgeo.org/

Alex


From alobolistas at gmail.com  Wed May 20 15:44:33 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Wed, 20 May 2009 15:44:33 +0200
Subject: [R-sig-Geo] raster package
In-Reply-To: <dc22b2570905181706w5302d428scd4392d465965ffd@mail.gmail.com>
References: <4A119C9F.1000809@gmail.com>
	<dc22b2570905181706w5302d428scd4392d465965ffd@mail.gmail.com>
Message-ID: <4A140941.3030602@gmail.com>

Robert,

But then rc would be a large R object? I mean, assuming
mytiffile.tif is large (> 8000x8000 in my case).

I've tried:

 > CATLC <- 
raster("/media/Transcend/Mario/BCNmetrop/GEODATA_BCN/CATLCLU2002/CATLCLU2002.tif")
 > class(CATLC)
[1] "RasterLayer"
attr(,"package")
[1] "raster"
 > summary(CATLC)
Cells: 78062352
values not in memory

which is ok but then:

 > rectable <- read.table("reclas.txt", sep="=",na.strings = "end",nrows=23)
 > rectable <- cbind(rectable[,1],rectable[,1],rectable[,2])
 > CATLU1 <- reclass(CATLC,rectable, filetype="GTiff", file="CATLU1.tif")

The last command seems to take up all memory. The system slows down as 
if CATLU1
had been read into an R object.

Am I doing something wrong?

Agus

Robert Hijmans wrote:
> Agus,
>
>   
>> Is there a way
>> of assigning the tif file to an R raster object and then just use
>> reclass() and R would
>> read the file by pieces as needed? That's what I would like to...
>>     
>
> That is exactly what is intended with reclass(). Something like this :
>
> r <- raster('mytiffile.tif')
> m <- matrix(0,1000,1, 1000, Inf, NA, ncol=2)
> rc <- reclass(r, m, ...)
>
> Robert
>
> On Tue, May 19, 2009 at 1:36 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
>   
>> I have to reclassify a large (> 8000x8000 pixels) geotif raster. I normally
>> would do it through grass (or saga) but would like to try the raster
>> package in R.
>> The problem is that I'm a bit confused on how to do it. My understanding
>> of the package
>> is that it provides a way to operate in the rasters by pieces, not having
>> to read the whole thing into memory. I've seen there's a function reclass()
>> but how do I actually read the raster? If I use readAll() this is going
>> to be as
>> using readGDAL() directly, so this is not the way. Do I have to use
>> a for() of readRows(), then reclass()? This seems a bit low-level. Is
>> there a way
>> of assigning the tif file to an R raster object and then just use
>> reclass() and R would
>> read the file by pieces as needed? That's what I would like to...
>>
>> Agus
>>
>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>>     
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From pisicandru at hotmail.com  Wed May 20 16:27:11 2009
From: pisicandru at hotmail.com (Monica Pisica)
Date: Wed, 20 May 2009 14:27:11 +0000
Subject: [R-sig-Geo] read NITF save as geotif
In-Reply-To: <ea7f5b8ceea3aa93ccdce93a1c8765c1.squirrel@webmail.geo.uu.nl>
References: <BAY130-W13069E5E83D8E69199C90FC35B0@phx.gbl>
	<ea7f5b8ceea3aa93ccdce93a1c8765c1.squirrel@webmail.geo.uu.nl>
Message-ID: <BAY130-W1276C88F70013981BE3163C3580@phx.gbl>


Hi Arien,
 
Well, i hoped it was straight forward - but it seems it is not.
 
So if i use your code (which is almost like mine ....) i get this:
 
b1 <- readGDAL("myfile")
writeGDAL(b1, "test.tif")
Error: gridded(dataset) is not TRUE
 
If i try points2grid command i get:
 
 points2grid(b1, tolerance = 0.5)
cellcentre.offset -9.362957e+01 3.008636e+01
cellsize           8.535574e-09 7.422092e-09
cells.dim          9.000000e+06 9.000000e+06
Warning messages:
1: In points2grid(b1, tolerance = 0.5, round = 3, fuzz.tol = 4) :
  grid topology may be corrupt in dimwnsion 1
2: In points2grid(b1, tolerance = 0.5, round = 3, fuzz.tol = 4) :
  grid topology may be corrupt in dimwnsion 2

class(b1)
 
[1] "SpatialPointsDataFrame"
attr(,"package")
[1] "sp"

b1[1,]
          coordinates band1
1 (-93.6295, 30.1529)   286
 
summary(b1)

Object of class SpatialPointsDataFrame
Coordinates:
        min       max
x -93.62957 -93.55275
y  30.08636  30.15316
Is projected: FALSE 
proj4string :
[+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0]
Number of points: 9000000
Data attributes:
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  165.0   207.0   219.0   224.5   233.0  1449.0 

I am not sure if this is enough info, but if not i am sure i can post the file. Also i have to say that i read only part of the file - it is too bit it seems for my system to read all of it. I work on a 64 bit Windows machine with a 32 bit R 2.8.1 patch ( i know is kind of old but should not matter, i have all the packages just updated anyway).
 
Thanks,
 
Monica
----------------------------------------
> Date: Wed, 20 May 2009 11:31:18 +0200
> Subject: Re: [R-sig-Geo] read NITF save as geotif
> From: a.lam at geo.uu.nl
> To: pisicandru at hotmail.com
> CC: r-sig-geo at stat.math.ethz.ch
>
> Hi Monica,
>
> It should be straightforward using rgdal. Gtiff output is default,
> resolution is preserved by default, GDAL supports nitf (didn't test this)
> and geotiff supports x resolution and y resolution separately (x and y
> resolution may differ, but are constant for the image). So I expect the
> following snippet to work (if it doesn't, show us what goes wrong):
>
> require('rgdal')
>
> GDALinfo('yourfile') # look at res.x and res.y
>
> imagery <- readGDAL('yourfile')
> writeGDAL(imagery, 'destinationfile')
>
> GDALinfo('destinationfile')
>
> Hope this helps,
>
> Arien
>
>
> On Tue, May 19, 2009 20:24, Monica Pisica wrote:
>>
>> Hi,
>>
>> I have some NITF (in lat long) files and i would like to save them as
>> geotif. Things would be almost straightforward but .... the pixels in the
>> original image are rectangular, and not square, so i cannot grid. Do you
>> have any idea how i can go around this?
>>
>> Thanks, i will really appreciate that.
>>
>> Monica
>> _________________________________________________________________
>> Insert movie times and more without leaving Hotmail?.
>>
>> orial_QuickAdd1_052009
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
> --
> drs. H.A. (Arien) Lam (Ph.D. student)
> Department of Physical Geography
> Faculty of Geosciences
> Utrecht University, The Netherlands
>
>
_________________________________________________________________
Hotmail? has a new way to see what's up with your friends.

orial_WhatsNew1_052009

From tylerdeanrudolph at gmail.com  Wed May 20 17:28:49 2009
From: tylerdeanrudolph at gmail.com (Tyler Dean Rudolph)
Date: Wed, 20 May 2009 11:28:49 -0400
Subject: [R-sig-Geo] convert owin object to SpatialPolygons object (write
	buffered MCP to shapefile)
In-Reply-To: <9fb1ae890905191147y6655ffdcub08c967606416a4a@mail.gmail.com>
References: <9fb1ae890905191147y6655ffdcub08c967606416a4a@mail.gmail.com>
Message-ID: <9fb1ae890905200828v105d4f63sc2ab76762a982e7f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090520/473c84cd/attachment.pl>

From jo.lists at gmail.com  Wed May 20 17:34:24 2009
From: jo.lists at gmail.com (JiHO)
Date: Wed, 20 May 2009 11:34:24 -0400
Subject: [R-sig-Geo] Comparing spatial distributions - permutation test
	implementation
Message-ID: <1368C8E3-ECCE-4218-96AF-ABEDE2D45403@gmail.com>

Hello everyone,

I am looking at the joint spatial distribution of 2 kinds of organisms  
(estimated on a grid of points) and want to test for significant  
association or dissociation.

My first question is: do you know a nice technique to do that,  
considering that I have a limited number of points (36) but that they  
are repeated (4 times)? I did GLMs to test for correlations between  
the two (hence forgetting about the spatial aspect of it) and was  
previously pointed to the SADIE software. Would there be anything  
explicitly spatial and available in R please?

Then, Syrjala's test[1] seems appropriate and tests for differences in  
distribution. It computes a Cram?r-von Mises-type statistic and tests  
its significance with a permutation test.
I implemented the test in R and posted the code on these mailing  
lists[2]. Some people checked it and confirmed that the statistic  
gives correct results but my estimation of the p-value does not match  
the one predicted with the orignal software from Syrjala. I don't know  
what I am doing wrong. The permutation test is described by Syrjala as:

         (...) Under the null hypothesis,
         at a given sampling location (x_k, y_k), either density ob-
         servation y_i(x_k, y_k), i = 1, 2, is equally likely for each
         population. Thus, for a given data set, the distribution
         of the test statistic can be constructed by calculating
         the value of the test statistic for all 2^k pairwise per-
         mutations of the data set. (...) The level of signif-
         icance of a specific realization of the test statistic T is
         determined from its position in the ordered set of test
         statistic values from all 2^k permutations. (...)

My understanding is that, for each permutation I should choose a  
random number of points (between 1 and k), swap the values for species  
1 and species 2 at those points, and recompute the test on the new  
data. But this does not work :/ . Here is my code and associated data  
from Syrjala (for which I have reference values). Any advice would be  
very welcome (in particular if there is a way to leverage boot() for  
this).
NB: computing the 1000 permutations can be a bit lengthy, but  
fortunately, by using plyr, you get a nice progress bar to look at!

syrjala.stat <- function(x, y=NULL, var1=NULL, var2=NULL)
#
#	Compute Syrjala statistic
#	x, y			coordinates
#	var1, var2	value of 2 parameters both measured at (x,y) points
#	NB: x can also be a data.frame/matrix containing x,y,var1,var2 as  
columns
#
{
	# Input checks
	if (!is.null(ncol(x))) {
		if (ncol(x) == 4) {
			names(x) = c("x","y","var1","var2")
			dat = x
		} else {
			stop("Wrong number of columns in argument x")
		}
	} else {
		dat = data.frame(x, y, var1, var2)
	}

	# Normalize abundances
	dat$var1 = dat$var1/sum(dat$var1)
	dat$var2 = dat$var2/sum(dat$var2)

	# For each point (each line of dat)
	# compute the squared difference in gammas from each origin
	meanSqDiff = apply(dat, 1, function(d, coord, variab) {
		north = (coord$x>=d[1])
		east = (coord$y>=d[2])
		south = (coord$x<=d[1])
		west = (coord$y<=d[2])
		return( mean( c(
			(diff(sapply(variab[(north & east),], sum)))^2,
			(diff(sapply(variab[(south & east),], sum)))^2,
			(diff(sapply(variab[(south & west),], sum)))^2,
			(diff(sapply(variab[(north & west),], sum)))^2
			) )
		)
	}, dat[,c("x","y")], dat[,c("var1","var2")])

	# Compute the statistic (i.e. sum of mean squared differences)
	return(sum(meanSqDiff))
}


# Get data online : http://dl.getdropbox.com/u/1047321/syrjala_data_cod.csv
system("curl http://dl.getdropbox.com/u/1047321/syrjala_data_cod.csv >  
syrjala_data_cod.csv")

dataCod = read.csv(file = "syrjala_data_cod.csv", header = TRUE)

# Normalize abundances
dataCod$var1 = dataCod$var1/sum(dataCod$var1)
dataCod$var2 = dataCod$var2/sum(dataCod$var2)

# Number of permutations
nperm = 1000

# Create nperm-1 replicates of the data (one is the original  
observation)
d = rep(list(dataCod), nperm-1)

# Compute number of observations before to avoid doing that for every  
replicate
n = nrow(dataCod)

require(plyr)
# Permute some observations and compute the syrjala stat for each  
permutation
psis = ldply(d, .fun=function(x, n){
	# choose indices of observations to swap
	idx = sample(1:n, runif(1, min=1, max=n))
	# swap observations
	x[idx, 3:4] = x[idx, 4:3]
	# compute syrjala stat
	return(syrjala.stat(x))
}, n, .progress="text")
}

# Compute the syrjala stat for the observations
psi = syrjala.stat(dataCod)

# Estimate the pvalue
pvalue = (sum(psis>=psi)+1)/nperm

psi
pvalue
# Should be:
# statistic	= 0.224
# p-value	= 0.1900

Thank you very much in advance. Sincerely,

JiHO
---
http://jo.irisson.free.fr/

[1] A statistical test for a difference between the spatial  
distributions of two populations. Syrjala SE. Ecology. 1996;77(1):75?80.
http://dl.getdropbox.com/u/1047321/Syrjala1996.pdf

[2] https://stat.ethz.ch/pipermail/r-sig-geo/2008-February/ 
thread.html#3137


From Pilar.Tugores at ba.ieo.es  Wed May 20 19:51:44 2009
From: Pilar.Tugores at ba.ieo.es (Pilar Tugores Ferra)
Date: Wed, 20 May 2009 19:51:44 +0200
Subject: [R-sig-Geo] shortest distance from points to polylines
In-Reply-To: <4A13F87F.4060309@wildintellect.com>
References: <BAY130-W13069E5E83D8E69199C90FC35B0@phx.gbl><ea7f5b8ceea3aa93cc
	dce93a1c8765c1.squirrel@webmail.geo.uu.nl><0838E01493845742A4D4039EA34EB1C1
	613230@ieopalma2.ba.ieo.es> <4A13F87F.4060309@wildintellect.com>
Message-ID: <0838E01493845742A4D4039EA34EB1C16132AA@ieopalma2.ba.ieo.es>


I'm happy I succeeded in calculating shortest distance!
nncross () is great and distmap () really cool! 
Thank you all! :)



M? Pilar Tugores Ferr?
PhD Student
Instituto Espa?ol de Oceanograf?a
Centro Oceanogr?fico de Baleares
Muelle de Poniente s/n
07015 Palma de Mallorca
Baleares, Espa?a
Telf.: (34) 971 401561

-----Mensaje original-----
De: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] En nombre de Alex Mandel
Enviado el: 20 May 2009 14:33
CC: r-sig-geo at stat.math.ethz.ch
Asunto: Re: [R-sig-Geo] shortest distance from points to polylines

Pilar Tugores Ferra wrote:
> Hi list!
> I need computing shortest distance from points to a polyline layer (coast line).
> I've been searching all the morning a function in R that can do this but couldn't find anything! 
> Is there any R function that do this? Or can anybody give me some hint about how it could be done?
> Kind regards!
> Pilar
> 
> 
> M? Pilar Tugores Ferr?

This is more straightforward if you use GRASS.
v.distance

I seem to recall a library to allow you to connect and run GRASS
commands from R, but maybe google or someone can elaborate.
http://grass.osgeo.org/

Alex

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

La informaci?n contenida en este e-mail y sus ficheros adjuntos es totalmente confidencial y no deber?a ser usado si no fuera usted alguno de los destinatarios. Si ha recibido este e-mail por error, por favor avise al remitente y b?rrelo de su buz?n o de cualquier otro medio de almacenamiento.   This email is confidential and should not be used by anyone who is not the original intended  recipient. If you have received this e-mail in  error please inform the sender and delete it from  your mailbox or any other storage mechanism.


From marcelino.delacruz at upm.es  Thu May 21 11:40:19 2009
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Thu, 21 May 2009 11:40:19 +0200
Subject: [R-sig-Geo] Comparing spatial distributions - permutation test
 implementation
In-Reply-To: <1368C8E3-ECCE-4218-96AF-ABEDE2D45403@gmail.com>
References: <1368C8E3-ECCE-4218-96AF-ABEDE2D45403@gmail.com>
Message-ID: <200905210940.n4L9e5ar022253@edison.ccupm.upm.es>

Hi,

Jose M. Blanco-Moreno an myself have implemented 
Syrjala's test in the ecespa package. As a matter 
of fact, Jose M. has implemented a Frotran 
version of Syrjala's original QBasic function. 
Using your data the results are very close to 
your reported # statistic= 0.224 and # p-value       = 0.1900.


Cheers,

Marcelino



# with Fortran code
 > syrjala0(dataCod[,1:2], dataCod$var1, dataCod$var2,R=F,nsim=1000)
Cramer-von Misses test for the difference between
the spatial distributions of  dataCod$var1 and dataCod$var2
based on 1000 permutations.

    psi:     0.223504
    p-value: 0.2167832

Kolmogorov-Smirnov test for the difference between
the spatial distributions of  dataCod$var1 and dataCod$var2
based on 1000 permutations.

    psi:     0.061354
    p-value: 0.2867133


### With R-code (a bit lengthy, so I use only 100 permutations)
 > syrjala0(dataCod[,1:2], dataCod$var1, dataCod$var2,R=T,nsim=100)
Syrjala test for the difference between the spatial distributions of
  dataCod$var1 and  dataCod$var2 , based on 100 simulations

    psi:      0.223504
    p-value:  0.2079208







At 17:34 20/05/2009, JiHO wrote:
>Hello everyone,
>
>I am looking at the joint spatial distribution of 2 kinds of organisms
>(estimated on a grid of points) and want to test for significant
>association or dissociation.
>
>My first question is: do you know a nice technique to do that,
>considering that I have a limited number of points (36) but that they
>are repeated (4 times)? I did GLMs to test for correlations between
>the two (hence forgetting about the spatial aspect of it) and was
>previously pointed to the SADIE software. Would there be anything
>explicitly spatial and available in R please?
>
>Then, Syrjala's test[1] seems appropriate and tests for differences in
>distribution. It computes a Cram?r-von Mises-type statistic and tests
>its significance with a permutation test.
>I implemented the test in R and posted the code on these mailing
>lists[2]. Some people checked it and confirmed that the statistic
>gives correct results but my estimation of the p-value does not match
>the one predicted with the orignal software from Syrjala. I don't know
>what I am doing wrong. The permutation test is described by Syrjala as:
>
>         (...) Under the null hypothesis,
>         at a given sampling location (x_k, y_k), either density ob-
>         servation y_i(x_k, y_k), i = 1, 2, is equally likely for each
>         population. Thus, for a given data set, the distribution
>         of the test statistic can be constructed by calculating
>         the value of the test statistic for all 2^k pairwise per-
>         mutations of the data set. (...) The level of signif-
>         icance of a specific realization of the test statistic T is
>         determined from its position in the ordered set of test
>         statistic values from all 2^k permutations. (...)
>
>My understanding is that, for each permutation I should choose a
>random number of points (between 1 and k), swap the values for species
>1 and species 2 at those points, and recompute the test on the new
>data. But this does not work :/ . Here is my code and associated data
>from Syrjala (for which I have reference values). Any advice would be
>very welcome (in particular if there is a way to leverage boot() for
>this).
>NB: computing the 1000 permutations can be a bit lengthy, but
>fortunately, by using plyr, you get a nice progress bar to look at!
>
>syrjala.stat <- function(x, y=NULL, var1=NULL, var2=NULL)
>#
>#       Compute Syrjala statistic
>#       x, y                    coordinates
>#       var1, var2      value of 2 parameters both measured at (x,y) points
>#       NB: x can also be a data.frame/matrix containing x,y,var1,var2 as
>columns
>#
>{
>         # Input checks
>         if (!is.null(ncol(x))) {
>                 if (ncol(x) == 4) {
>                         names(x) = c("x","y","var1","var2")
>                         dat = x
>                 } else {
>                         stop("Wrong number of columns in argument x")
>                 }
>         } else {
>                 dat = data.frame(x, y, var1, var2)
>         }
>
>         # Normalize abundances
>         dat$var1 = dat$var1/sum(dat$var1)
>         dat$var2 = dat$var2/sum(dat$var2)
>
>         # For each point (each line of dat)
>         # compute the squared difference in gammas from each origin
>         meanSqDiff = apply(dat, 1, function(d, coord, variab) {
>                 north = (coord$x>=d[1])
>                 east = (coord$y>=d[2])
>                 south = (coord$x<=d[1])
>                 west = (coord$y<=d[2])
>                 return( mean( c(
>                         (diff(sapply(variab[(north & east),], sum)))^2,
>                         (diff(sapply(variab[(south & east),], sum)))^2,
>                         (diff(sapply(variab[(south & west),], sum)))^2,
>                         (diff(sapply(variab[(north & west),], sum)))^2
>                         ) )
>                 )
>         }, dat[,c("x","y")], dat[,c("var1","var2")])
>
>         # Compute the statistic (i.e. sum of mean squared differences)
>         return(sum(meanSqDiff))
>}
>
>
># Get data online : http://dl.getdropbox.com/u/1047321/syrjala_data_cod.csv
>system("curl http://dl.getdropbox.com/u/1047321/syrjala_data_cod.csv >
>syrjala_data_cod.csv")
>
>dataCod = read.csv(file = "syrjala_data_cod.csv", header = TRUE)
>
># Normalize abundances
>dataCod$var1 = dataCod$var1/sum(dataCod$var1)
>dataCod$var2 = dataCod$var2/sum(dataCod$var2)
>
># Number of permutations
>nperm = 1000
>
># Create nperm-1 replicates of the data (one is the original
>observation)
>d = rep(list(dataCod), nperm-1)
>
># Compute number of observations before to avoid doing that for every
>replicate
>n = nrow(dataCod)
>
>require(plyr)
># Permute some observations and compute the syrjala stat for each
>permutation
>psis = ldply(d, .fun=function(x, n){
>         # choose indices of observations to swap
>         idx = sample(1:n, runif(1, min=1, max=n))
>         # swap observations
>         x[idx, 3:4] = x[idx, 4:3]
>         # compute syrjala stat
>         return(syrjala.stat(x))
>}, n, .progress="text")
>}
>
># Compute the syrjala stat for the observations
>psi = syrjala.stat(dataCod)
>
># Estimate the pvalue
>pvalue = (sum(psis>=psi)+1)/nperm
>
>psi
>pvalue
># Should be:
># statistic     = 0.224
># p-value       = 0.1900
>
>Thank you very much in advance. Sincerely,
>
>JiHO
>---
>http://jo.irisson.free.fr/
>
>[1] A statistical test for a difference between the spatial
>distributions of two populations. Syrjala SE. Ecology. 1996;77(1):75?80.
>http://dl.getdropbox.com/u/1047321/Syrjala1996.pdf
>
>[2] https://stat.ethz.ch/pipermail/r-sig-geo/2008-February/ thread.html#3137
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at stat.math.ethz.ch
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo

________________________________

Marcelino de la Cruz Rot

Departamento de  Biolog?a Vegetal
E.U.T.I. Agr?cola
Universidad Polit?cnica de Madrid
28040-Madrid
Tel.: 91 336 54 35
Fax: 91 336 56 56
marcelino.delacruz at upm.es


From a.ghisla at studenti.uninsubria.it  Thu May 21 12:14:31 2009
From: a.ghisla at studenti.uninsubria.it (Anne Ghisla)
Date: Thu, 21 May 2009 12:14:31 +0200
Subject: [R-sig-Geo] [SoC] GRASS module for kriging - call for users
Message-ID: <1242900871.4154.5.camel@galadriel.uagra.net>

Hello list, and sorry for cross-posting,

my Google Summer of Code project aims to provide a wxPython interface to 
v.autokrige and to add functionality [0].
I would ask to people who perform kriging analyses (with GRASS, R or ArcGIS) 
what are the most common use cases, what they like and dislike in the 
interfaces and functionalities provided by the software they use. 

After some feedback about this, I will prepare the interface and load it on 
GRASS addons SVN repository [1] for comments.

many thanks in advance,

Anne Ghisla

[0]  
http://socghop.appspot.com/student_project/show/google/gsoc2009/osgeo/t124023165994
[1] https://svn.osgeo.org/grass/grass-addons/vector/
-- 
Please consider the environment before printing this email
Please do not send attachments in proprietary formats
http://www.gnu.org/philosophy/no-word-attachments.html
Use the UNI CEI Standard ISO/IEC 26300:2006
-----------------------------------------------------------
O< stop html mail - http://www.asciiribbon.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 197 bytes
Desc: Questa ? una parte del messaggio	firmata digitalmente
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090521/3a40811e/attachment.bin>

From jo.lists at gmail.com  Thu May 21 16:36:05 2009
From: jo.lists at gmail.com (JiHO)
Date: Thu, 21 May 2009 10:36:05 -0400
Subject: [R-sig-Geo] Comparing spatial distributions - permutation test
	implementation
In-Reply-To: <200905210940.n4L9e5ar022253@edison.ccupm.upm.es>
References: <1368C8E3-ECCE-4218-96AF-ABEDE2D45403@gmail.com>
	<200905210940.n4L9e5ar022253@edison.ccupm.upm.es>
Message-ID: <CC18D403-12F3-4581-A30D-B825C45F5CBE@gmail.com>

On 2009-May-21  , at 05:40 , Marcelino de la Cruz wrote:

> Jose M. Blanco-Moreno an myself have implemented Syrjala's test in  
> the ecespa package. As a matter of fact, Jose M. has implemented a  
> Frotran version of Syrjala's original QBasic function. Using your  
> data the results are very close to your reported # statistic= 0.224  
> and # p-value       = 0.1900.

Thanks a lot. Having the fortran implementation is very nice!
I still don't find the values computed with the quickbasic code but  
the values reported in the article for this data set are different  
from those computed with QB and actually closer to yours.

Looking at your code I still don't get what I am doing wrong though.  
It seems we both use sample to get a few of the columns and then swap  
them. Well, I'll use your test anyway.

JiHO
---
http://jo.irisson.free.fr/


From ajaldersley at hotmail.co.uk  Thu May 21 16:59:30 2009
From: ajaldersley at hotmail.co.uk (Andrew Aldersley)
Date: Thu, 21 May 2009 14:59:30 +0000
Subject: [R-sig-Geo] Interpolation of data
Message-ID: <SNT105-W2BA5CBA3AF49E7A547376E4590@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090521/f15e7719/attachment.pl>

From BRWIN338 at aol.com  Thu May 21 21:14:02 2009
From: BRWIN338 at aol.com (BRWIN338 at aol.com)
Date: Thu, 21 May 2009 15:14:02 EDT
Subject: [R-sig-Geo] Finding the county shapefile polygon closest to a
	long-lat position
Message-ID: <bf6.2eb3ce0e.374701fa@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090521/2946d74f/attachment.pl>

From Pilar.Tugores at ba.ieo.es  Thu May 21 22:25:00 2009
From: Pilar.Tugores at ba.ieo.es (Pilar Tugores Ferra)
Date: Thu, 21 May 2009 22:25:00 +0200
Subject: [R-sig-Geo] Finding the county shapefile polygon closest to
	along-lat position
References: <bf6.2eb3ce0e.374701fa@aol.com>
Message-ID: <0838E01493845742A4D4039EA34EB1C12AC212@ieopalma2.ba.ieo.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090521/ff3c7763/attachment.pl>

From p.hiemstra at geo.uu.nl  Thu May 21 23:23:44 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Thu, 21 May 2009 23:23:44 +0200
Subject: [R-sig-Geo] Finding the county shapefile polygon closest to a
 long-lat position
In-Reply-To: <bf6.2eb3ce0e.374701fa@aol.com>
References: <bf6.2eb3ce0e.374701fa@aol.com>
Message-ID: <4A15C660.1070606@geo.uu.nl>

Hi,

If you have your data loaded into R as spatial objects, you can find in 
which polygons the points fall using the overlay() function from the 
sp-pacakge. See the documentation there. I'm not sure what to do if the 
point falls outside a polygon and you need the nearest.

cheers,
Paul

BRWIN338 at aol.com schreef:
> Greetings
> I have a large number of long-lat locations dispersed over the  US and need 
>  
> to identify which US county that each point is located in  (or nearest to). 
>   
> After reading the past posts  and Roger's book, I have been able to use the 
> overlay function  
> to  identify the appropriate counties for the set of  locations 
> with  long-lats lying within or on a polygon boundary.   However, due to  
> longlat precision errors (I am assuming), some of the  points lie  outside 
> all of 
> my shapefile's county polygon  boundaries.   
>
> Is there an R function similar to "overlay" that I could use to find  which 
>  
> county polygon is closest to each of my longlat points that do  not lie  
> within the shapefile's polygons?  I have spent quite a  bit of time  
> searching 
> and browsing past list discussions and can seem  to find my  answer.
>
> My apologies if I have missed an obvious  answer.
>
> Joe          
>
>
> **************Huge savings on HDTVs from Dell.com! 
> (http://pr.atwola.com/promoclk/100126575x1221836042x1201399880/aol?redir=http:%2F%2Fad.doubleclick.ne
> t%2Fclk%3B215073686%3B37034322%3Bb)
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From adrian at maths.uwa.edu.au  Fri May 22 03:29:14 2009
From: adrian at maths.uwa.edu.au (Adrian Baddeley)
Date: Fri, 22 May 2009 09:29:14 +0800
Subject: [R-sig-Geo] convert owin object to SpatialPolygons object
Message-ID: <4A15FFEA.90406@maths.uwa.edu.au>

Tyler Dean Rudolph writes:

> However the conversion to a Spatial Polygons object does not seem to work

To convert an object of class 'owin' (spatstat) to 'SpatialPolygons' (sp) 
you can use the following code.

Adrian Baddeley

==================================================================================

# convert spatstat objects to sp classes

owin2Polygons <- function(x, id="1") {
  stopifnot(is.owin(x))
  x <- as.polygonal(x)
  closering <- function(df) { df[c(seq(nrow(df)), 1), ] }
  pieces <- lapply(x$bdry,
                   function(p) {
                     Polygon(coords=closering(cbind(p$x,p$y)),
                             hole=is.hole.xypolygon(p))  })
  z <- Polygons(pieces, id)
  return(z)
}

tess2SP <- function(x) {
  stopifnot(is.tess(x))
  y <- tiles(x)
  nam <- names(y)
  z <- list()
  for(i in seq(y))
    z[[i]] <- owin2Polygons(y[[i]], nam[i])
  return(SpatialPolygons(z))
}

owin2SP <- function(x) {
  stopifnot(is.owin(x))
  y <- owin2Polygons(x)
  z <- SpatialPolygons(list(y))
  return(z)
}


From Roger.Bivand at nhh.no  Fri May 22 10:44:38 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 22 May 2009 10:44:38 +0200 (CEST)
Subject: [R-sig-Geo] Finding the county shapefile polygon closest to
 along-lat position
In-Reply-To: <0838E01493845742A4D4039EA34EB1C12AC212@ieopalma2.ba.ieo.es>
References: <bf6.2eb3ce0e.374701fa@aol.com>
	<0838E01493845742A4D4039EA34EB1C12AC212@ieopalma2.ba.ieo.es>
Message-ID: <alpine.LRH.2.00.0905221034420.15099@reclus.nhh.no>

On Thu, 21 May 2009, Pilar Tugores Ferra wrote:

>
>
> Dear Joe,
> Maybe you could use a similar process that Marcelino suggested to me 
> yesterday in order to compute the shortest distance from points to a 
> polyline. You need to 1)convert your point data to ppp object in 
> spatstat, 2)coerce your polygon data to a psp object in spatstat. 
> 3)nncross between the two.
> You'll get "dist" - the nearest neighbour distance between the two 
> patterns and "which" the nearest neighbour index of the second pattern. 
> Maybe it won't be so straightforward to know which ids of the coerced 
> polyline correspond to each polygon but I am not sure about this point.

Thanks, Pilar!

The only possible weakness in this might be that the input points and 
polygon boundaries are in geographical, not projected (planar) 
coordinates, so if there are differences in distances on the plane and 
great circle distances, they might lead to the "outside" points being 
assigned to the wrong county.

Depending on how many there are, you might consider two alternatives, one 
visual inspection in Google Earth or similar (export the "outside" points 
with IDs as one KML, and the county boundaries you are using with 
writeOGR() in rgdal (or use those built into GE)); the other would be to 
use the closeness to the label points of the counties of the "outside" 
points - coordinates() of the SpatialPolygons* object retrieves these, so 
looping over the "outside" points in spDistsN1() in sp with longlat=TRUE 
would give the great circle distances.

Of course, the underlying issue is why they are outside - is this a datum 
shift problem (counties in NAD27 and points in NAD83/WGS84)? If you fixed 
that, they would match better.

Hope this helps,

Roger

> Best regards,
> Pilar
>
>
> -----Mensaje original-----
> De: r-sig-geo-bounces at stat.math.ethz.ch en nombre de BRWIN338 at aol.com
> Enviado el: jue 21/05/2009 21:14
> Para: r-sig-geo at stat.math.ethz.ch
> Asunto: [R-sig-Geo] Finding the county shapefile polygon closest to along-lat position
>
> Greetings
> I have a large number of long-lat locations dispersed over the  US and need
>
> to identify which US county that each point is located in  (or nearest to).
>
> After reading the past posts  and Roger's book, I have been able to use the
> overlay function
> to  identify the appropriate counties for the set of  locations
> with  long-lats lying within or on a polygon boundary.   However, due to
> longlat precision errors (I am assuming), some of the  points lie  outside
> all of
> my shapefile's county polygon  boundaries.
>
> Is there an R function similar to "overlay" that I could use to find  which
>
> county polygon is closest to each of my longlat points that do  not lie
> within the shapefile's polygons?  I have spent quite a  bit of time
> searching
> and browsing past list discussions and can seem  to find my  answer.
>
> My apologies if I have missed an obvious  answer.
>
> Joe
>
>
> **************Huge savings on HDTVs from Dell.com!
> (http://pr.atwola.com/promoclk/100126575x1221836042x1201399880/aol?redir=http:%2F%2Fad.doubleclick.ne
> t%2Fclk%3B215073686%3B37034322%3Bb)
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
> La informaci?n contenida en este e-mail y sus ficheros adjuntos es totalmente confidencial y no deber?a ser usado si no fuera usted alguno de los destinatarios. Si ha recibido este e-mail por error, por favor avise al remitente y b?rrelo de su buz?n o de cualquier otro medio de almacenamiento.   This email is confidential and should not be used by anyone who is not the original intended  recipient. If you have received this e-mail in  error please inform the sender and delete it from  your mailbox or any other storage mechanism.
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From torleif.lunde at cih.uib.no  Fri May 22 13:06:51 2009
From: torleif.lunde at cih.uib.no (Torleif Markussen Lunde)
Date: Fri, 22 May 2009 13:06:51 +0200
Subject: [R-sig-Geo] Finding the county shapefile polygon closest to
	along-lat position
In-Reply-To: <alpine.LRH.2.00.0905221034420.15099@reclus.nhh.no>
References: <bf6.2eb3ce0e.374701fa@aol.com>
	<0838E01493845742A4D4039EA34EB1C12AC212@ieopalma2.ba.ieo.es>
	<alpine.LRH.2.00.0905221034420.15099@reclus.nhh.no>
Message-ID: <200905221306.51647.torleif.lunde@cih.uib.no>

Hi Joe

Like Roger says you should first look at the possible datum problem. The 
example below shows one method to find the closest polygon, and to add that 
to the overlay. Notice however that if you change the projection and/or 
ellipsoid the closest points (end of lines) are different. Closest line in 
this case is calculated by:
abs((x2-x1)*(y1-y0)-(x1-x0)*(y2-y1))/sqrt(((x2-x1)^2+(y2-y1)^2))^2)

where x0, and y0 is the point, while x1, y1, and x2, y2 are the line ends.

To find the two closest points, spDistsN1 is used. 

Try to play with un-commenting polys <- spTransform(polys, CRS("+proj=moll 
+ellps=WGS84"))
and changing ll.logical=FALSE/TRUE (FALSE = Euclidean, TRUE = Great Circle 
distance)

One of the things you will see is that the closest points are different when 
you calculate the distance in km (ll.logical=TRUE) combined with 
proj4string=CRS("+proj=moll +ellps=WGS84")

I hope this gives some insight in the problem. 

The code can also be downloaded from http://open.uib.no/R/mindist.R

I do not guarantee the code is bug free.

You could try to replace polys with your polygon, and ssample with your 
points, and see if it makes sense.

Best wishes
Torleif



#################

library(rgdal)

#Make data
set.seed(7)
grd <- GridTopology(c(1,1), c(1,1), c(2,2))
polys <- as.SpatialPolygons.GridTopology(grd)
proj4string(polys) <- CRS(" +proj=longlat +ellps=WGS84" )

## Try uncommenting this line, and see what are the closest points in the last 
figure.
## In this case the same closest polygons are found, but not the same two 
closest points
#polys <- spTransform(polys, CRS("+proj=moll +ellps=sphere"))

ssample <- spsample(polys,n=10,type="random")

#displace points
slot(ssample, 'coords') <- slot(ssample, 'coords')-mean( 
slot(ssample, 'coords'))*.25


#overlay
overl <- overlay(polys, ssample)

#Show overlay
overl

#Which points are outside?
wh <- which(is.na(overl))

#Make plots
plot(polys, xlim=(c(bbox(polys)[1,])-c(1, -1)), 
      ylim=(c(bbox(polys)[2,])-c(1, -1)))
for (i in 1:4) points(slot(slot((slot(polys, 'polygons'))[[i]], 'Polygons')
[[1]], 'coords')[,1], slot(slot((slot(polys, 'polygons'))[[i]], 'Polygons')
[[1]], 'coords')[,2], col = i)
points(ssample)
for (i in 1:length(wh)) {
points(slot(ssample, 'coords')[wh[i],1], slot(ssample, 'coords')[wh[i],2], 
col=(i+1))
}


# Number of polygons to sapply over (or number of polygons). 
# With more polygons you could also try to only scan the lines around 
# the "4" polygons which center is closest to the outlying point(?)
nit <- dim(coordinates(polys))[1]

#Find the closest polygon, and paste the data in overl
overl.na <- sapply(1:length(wh), function (x) {
  x0 <- slot(ssample, 'coords')[wh[x],1]
  y0 <- slot(ssample, 'coords')[wh[x],2]

mn <- sapply(1:nit, function(y) {
    cc <- slot(slot((slot(polys, 'polygons'))[[y]], 'Polygons')
[[1]], 'coords')
    x1 <- cc[1:(dim(cc)[1]-1),1]
    x2 <- cc[2:dim(cc)[1],1]
    y1 <- cc[1:(dim(cc)[1]-1),2]
    y2 <- cc[2:dim(cc)[1],2]
    #calculate distance
    mn <- 
mean(abs((x2-x1)*(y1-y0)-(x1-x0)*(y2-y1))/sqrt(((x2-x1)^2+(y2-y1)^2)))
    return(mn)
  })

  wm <- which.min(mn)
  return(list(wm, x0, y0))
})

##Can leave out. This section is just for plotting lines
#lines. Shortest distance
lin  <- sapply(2:(length(wh)+1), function (x) {
    p1 <- matrix(unlist(overl.na[-1,(x-1)]),,2)
    pol.pos <- unlist(overl.na[1,])
    pol1 <- slot(slot((slot(polys, 'polygons'))[[pol.pos[x-1]]], 'Polygons')
[[1]], 'coords')[-1,]
    dst <- spDistsN1(pol1, p1, longlat=FALSE)
    wh.dst <- which.min(dst)
    ln <- Line(matrix( c(p1[,1], pol1[wh.dst, 1], p1[,2], pol1[wh.dst, 2]), 
2 ))
    return(ln)
  })

#lines, second shortest distance
lin2  <- sapply(2:(length(wh)+1), function (x) {
    p1 <- matrix(unlist(overl.na[-1,(x-1)]),,2)
    pol.pos <- unlist(overl.na[1,])
    pol1 <- slot(slot((slot(polys, 'polygons'))[[pol.pos[x-1]]], 'Polygons')
[[1]], 'coords')[-1,]
    dst <- spDistsN1(pol1, p1, longlat=FALSE)
    wh.dst <- which.min(dst)
    dst[wh.dst] <- NA
    wh.dst2 <- which.min(dst)
    ln2 <- Line(matrix( c(p1[,1], pol1[wh.dst2, 1], p1[,2], pol1[wh.dst2, 2]), 
2 ))
    return(ln2)
  })

#Convert to spatial lines
sl1 <- Lines(lin)
spl1 <- SpatialLines(list(sl1), proj4string = CRS(proj4string(polys)))
sl2 <- Lines(lin2)
spl2 <- SpatialLines(list(sl2), proj4string = CRS(proj4string(polys)))


##
#Add the new values to the overlay
overl[wh] <- unlist(overl.na[1,])

#Show overlay 
overl

#Add polygon
new.points <- SpatialPointsDataFrame(ssample, data.frame(polyid=overl))

polys <- SpatialPolygonsDataFrame(polys, 
data.frame(ID=c("p1", "p2", "p3", "p4")))

mypalette <- "red"
require(lattice)
trellis.par.set(sp.theme(regions = list(col = mypalette)))
spplot(new.points, 
      sp.layout = list(list("sp.polygons", polys, fill = 
c("grey10", "grey40", "grey60", "grey90")),
			list("sp.lines", spl1),
			list("sp.lines", spl2)), 
      xlim=(c(bbox(polys)[1,])-c(mean( slot(ssample, 'coords'))*.5, -mean( 
slot(ssample, 'coords'))*.5)), 
      ylim=(c(bbox(polys)[2,])-c(mean( slot(ssample, 'coords'))*.5, -mean( 
slot(ssample, 'coords'))*.5)))




##########

On Friday 22 May 2009 10:44:38 am Roger Bivand wrote:
> On Thu, 21 May 2009, Pilar Tugores Ferra wrote:
> > Dear Joe,
> > Maybe you could use a similar process that Marcelino suggested to me
> > yesterday in order to compute the shortest distance from points to a
> > polyline. You need to 1)convert your point data to ppp object in
> > spatstat, 2)coerce your polygon data to a psp object in spatstat.
> > 3)nncross between the two.
> > You'll get "dist" - the nearest neighbour distance between the two
> > patterns and "which" the nearest neighbour index of the second pattern.
> > Maybe it won't be so straightforward to know which ids of the coerced
> > polyline correspond to each polygon but I am not sure about this point.
>
> Thanks, Pilar!
>
> The only possible weakness in this might be that the input points and
> polygon boundaries are in geographical, not projected (planar)
> coordinates, so if there are differences in distances on the plane and
> great circle distances, they might lead to the "outside" points being
> assigned to the wrong county.
>
> Depending on how many there are, you might consider two alternatives, one
> visual inspection in Google Earth or similar (export the "outside" points
> with IDs as one KML, and the county boundaries you are using with
> writeOGR() in rgdal (or use those built into GE)); the other would be to
> use the closeness to the label points of the counties of the "outside"
> points - coordinates() of the SpatialPolygons* object retrieves these, so
> looping over the "outside" points in spDistsN1() in sp with longlat=TRUE
> would give the great circle distances.
>
> Of course, the underlying issue is why they are outside - is this a datum
> shift problem (counties in NAD27 and points in NAD83/WGS84)? If you fixed
> that, they would match better.
>
> Hope this helps,
>
> Roger
>
> > Best regards,
> > Pilar
> >
> >
> > -----Mensaje original-----
> > De: r-sig-geo-bounces at stat.math.ethz.ch en nombre de BRWIN338 at aol.com
> > Enviado el: jue 21/05/2009 21:14
> > Para: r-sig-geo at stat.math.ethz.ch
> > Asunto: [R-sig-Geo] Finding the county shapefile polygon closest to
> > along-lat position
> >
> > Greetings
> > I have a large number of long-lat locations dispersed over the  US and
> > need
> >
> > to identify which US county that each point is located in  (or nearest
> > to).
> >
> > After reading the past posts  and Roger's book, I have been able to use
> > the overlay function
> > to  identify the appropriate counties for the set of  locations
> > with  long-lats lying within or on a polygon boundary.   However, due to
> > longlat precision errors (I am assuming), some of the  points lie 
> > outside all of
> > my shapefile's county polygon  boundaries.
> >
> > Is there an R function similar to "overlay" that I could use to find 
> > which
> >
> > county polygon is closest to each of my longlat points that do  not lie
> > within the shapefile's polygons?  I have spent quite a  bit of time
> > searching
> > and browsing past list discussions and can seem  to find my  answer.
> >
> > My apologies if I have missed an obvious  answer.
> >
> > Joe
> >
> >
> > **************Huge savings on HDTVs from Dell.com!
> > (http://pr.atwola.com/promoclk/100126575x1221836042x1201399880/aol?redir=
> >http:%2F%2Fad.doubleclick.ne t%2Fclk%3B215073686%3B37034322%3Bb)
> >
> > 	[[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> >
> >
> > La informaci?n contenida en este e-mail y sus ficheros adjuntos es
> > totalmente confidencial y no deber?a ser usado si no fuera usted alguno
> > de los destinatarios. Si ha recibido este e-mail por error, por favor
> > avise al remitente y b?rrelo de su buz?n o de cualquier otro medio de
> > almacenamiento.   This email is confidential and should not be used by
> > anyone who is not the original intended  recipient. If you have received
> > this e-mail in  error please inform the sender and delete it from  your
> > mailbox or any other storage mechanism. [[alternative HTML version
> > deleted]]


From jean-paul.kibambe at uclouvain.be  Fri May 22 15:15:53 2009
From: jean-paul.kibambe at uclouvain.be (Jean-Paul Kibambe Lubamba)
Date: Fri, 22 May 2009 15:15:53 +0200 (CEST)
Subject: [R-sig-Geo] Constraining a linear regression model
Message-ID: <1ed84809aa89b5383511b576e78e3a8c.squirrel@mmp.sipr-dc.ucl.ac.be>

Hi All,

I have two questions:

I am computing a linear regression model with 0 as Intercept.

Well, I would like the sum of my predicted values be equal to a constant
and therefore analyze if my coefficients are significatively different
using or not this constraint.

Does anyone know how I can constrain my model in a such way?

Here is the code:

data<-read.table ("input.txt", header=T, dec=".", sep="\t"); attach(data)
lm <-lm(pop ~ ag + sav + mf -1, data=data)
pred <- predict(lm)
sum(pred)

So I want to constrain my sum (pred) to be equal to C, with C=sum(pop)



My second question is: is it possible to make the same constraint BUT with
C as a vector of values?

If I have 5 observations in 'data' (for simplification reasons), with
'pop' as the first column. I want to compute the same model as above with
a 'vector' of constraints. In that case, C=xi (with i from 1 to 3)

x1 = sum (data[c(2:4), 1])
x2 = sum(data [c(1,3), 1])
x3 = data[5,1]


Thanks in advance -- Any help is welcome!


Jean-Paul Kibambe


From e.jahanshiri at gmail.com  Sat May 23 05:31:07 2009
From: e.jahanshiri at gmail.com (Ebrahim Jahanshiri)
Date: Sat, 23 May 2009 11:31:07 +0800
Subject: [R-sig-Geo] R-sig-Geo Digest, Vol 69, Issue 21
In-Reply-To: <mailman.13.1242986402.30725.r-sig-geo@stat.math.ethz.ch>
References: <mailman.13.1242986402.30725.r-sig-geo@stat.math.ethz.ch>
Message-ID: <b0a6ce470905222031w4010f1feo1970e8bab178bae6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090523/677d23ff/attachment.pl>

From a.ghisla at studenti.uninsubria.it  Sat May 23 19:59:49 2009
From: a.ghisla at studenti.uninsubria.it (Anne Ghisla Insubriae)
Date: Sat, 23 May 2009 19:59:49 +0200
Subject: [R-sig-Geo] [Soc] GRASS module for kriging - call for users
 [was: R-sig-Geo Digest, Vol 69, Issue 21]
In-Reply-To: <b0a6ce470905222031w4010f1feo1970e8bab178bae6@mail.gmail.com>
References: <mailman.13.1242986402.30725.r-sig-geo@stat.math.ethz.ch>
	<b0a6ce470905222031w4010f1feo1970e8bab178bae6@mail.gmail.com>
Message-ID: <4A183995.7060606@studenti.uninsubria.it>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Ebrahim Jahanshiri a ?crit:
> Dear Anne,

Ebrahim,

> Thanks for the enquiry. I think we should have done this long before. I
> havent done any geostatistics with GRASS but I did alot in ArcGIS and also
> in R (variography). I have to tell you that ArcGIS is for those who want to
> have a surface only by just clicking on "finish" button trought its
> powerfull interface. That is, it does not provide a good scientific
> backgroud for you to check the procedure. for example how it fitted the
> variogram model or how exactly it does the "validation". That is why the
> "Geostatistical package" objects or classes are not available for the
> programmers to program with (there is a kriging in "Spatial analyst" package
> though that its object is programmable and I personally did some with it.
> but it lacks the variogram modeling). I think they are still working on it.
> In short I dont recommend ArcGIS for the so called scientific kriging. 

I was afraid of this. Therefore I guess an interface with too many
mandatory options would be considered overcomplicated.
There should be as more options as needed for a flexible calculations,
and also proper defaults to clik on Ok and get an acceptable result.
What do you think about this solution?

> In
> the other hand R is very powerfull in that it gives you freedom to do your
> own style through coding. I worked with "GeoR" pakcage and it is pretty nice
> both in terms of variography and kriging. There are other package like
> "Gstat" that I havent worked with but have good qualities. GeoR implements
> the so called "model based geostatistics" which is the application of
> bayesian statististics to the geostistics I guess and it is quite new.

I'm presently having a look at both geoR and gstat, and also the wrapper
package automap.
I guess that the first users of the new module would be already familiar
with R and GRASS, so their feedback about most used functions is very
important.

> I hope these comments were helpful and please let me know if you need any
> further explanation from me,

Very helpful, thank you very much!

> Ebrahim
>
best regards,
Anne

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.9 (MingW32)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iEYEARECAAYFAkoYOZUACgkQrgxAvFOwDdgNjgCfZEFAIMpX5zeZ/OdraSfbqcRJ
G7oAnRwIUfGvmTgOj3GSspTN/Lht0UG7
=KTO6
-----END PGP SIGNATURE-----


From Roger.Bivand at nhh.no  Sat May 23 20:10:34 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 23 May 2009 20:10:34 +0200 (CEST)
Subject: [R-sig-Geo] differences between gwr.sel and GWR3?
In-Reply-To: <2993.144.92.114.163.1242599721.squirrel@webmail.ssc.wisc.edu>
References: <2993.144.92.114.163.1242599721.squirrel@webmail.ssc.wisc.edu>
Message-ID: <alpine.LRH.2.00.0905231921370.20124@reclus.nhh.no>

On Sun, 17 May 2009, aslez at ssc.wisc.edu wrote:

> In general, what are the differences between the way in which gwr.sel and
> Fotheringham et al.s GWR3 optimize bandwidths?  Should I be able to
> replicate the optimal bandwidths suggested by GWR3 using gwr.sel?  Using
> various datasets (including the Georgia data which accompanies both
> packages), I have consistently found noticable differences in the
> bandwidths suggested by each program.
>
> Am I missing something?

Well, GWR3 is closed source, and the code in the R contributed package 
spgwr is open source, so that the only way that you can check is to try to 
reverse-engineer the settings that GWR3 may be using. You are not giving 
any specific cases here, so I'll oblige.

Fit the Georgia PctPov ~ PctEld model using X and Y as planar coordinates, 
CV, all observations, and GWR3 gives a bandwidth of 60133.3396 (metres I 
think). Use gwr.sel() in the same setting, and you get a bandwidth of 
59762.81 with a CV score of 2859.344. By reverse engineering (running 
gwr.sel() under debug(), and assigning y, x, coords, weights, and gweight 
to the global environment, and running gwr.cv.f() after gwr.sel() 
finished), and using the GWR3 bandwidth, we find its score (in the 
same metric as CV in gwr.sel()) is 2859.368, not a lot different.

So in this case, the reason seems to be that R's line search function 
optimize() is being slightly more eager in getting to the minimum of the 
CV score function. Both implementations are doing the same thing, but GWR3 
is letting the line search terminate earlier. I think that the same is 
happening with CV in the adaptive case.

Your choice as to what you prefer - I don't think that these differences 
are "noticable", they just stem from the use of different optimizers. In 
gwr.sel() it uses the default tolerances, but GWR3's choice to stop 
earlier is also OK for practical purposes. Using AIC depends on accepting 
extra assumptions about the "right" number of degrees of freedom in the 
number of parameters.

Does this address your concerns?

Hope this helps,

Roger

>
> Adam Slez
> Department of Sociology
> University of Wisconsin-Madison
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From dylan.beaudette at gmail.com  Sat May 23 21:07:34 2009
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Sat, 23 May 2009 12:07:34 -0700
Subject: [R-sig-Geo] [Soc] GRASS module for kriging - call for users
	[was: R-sig-Geo Digest, Vol 69, Issue 21]
In-Reply-To: <4A183995.7060606@studenti.uninsubria.it>
References: <mailman.13.1242986402.30725.r-sig-geo@stat.math.ethz.ch>
	<b0a6ce470905222031w4010f1feo1970e8bab178bae6@mail.gmail.com>
	<4A183995.7060606@studenti.uninsubria.it>
Message-ID: <3c5546140905231207n539eb305w1fffd83ceaca7b2a@mail.gmail.com>

On Sat, May 23, 2009 at 10:59 AM, Anne Ghisla Insubriae
<a.ghisla at studenti.uninsubria.it> wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Ebrahim Jahanshiri a ?crit:
>> Dear Anne,
>
> Ebrahim,
>
>> Thanks for the enquiry. I think we should have done this long before. I
>> havent done any geostatistics with GRASS but I did alot in ArcGIS and also
>> in R (variography). I have to tell you that ArcGIS is for those who want to
>> have a surface only by just clicking on "finish" button trought its
>> powerfull interface. That is, it does not provide a good scientific
>> backgroud for you to check the procedure. for example how it fitted the
>> variogram model or how exactly it does the "validation". That is why the
>> "Geostatistical package" objects or classes are not available for the
>> programmers to program with (there is a kriging in "Spatial analyst" package
>> though that its object is programmable and I personally did some with it.
>> but it lacks the variogram modeling). I think they are still working on it.
>> In short I dont recommend ArcGIS for the so called scientific kriging.
>
> I was afraid of this. Therefore I guess an interface with too many
> mandatory options would be considered overcomplicated.
> There should be as more options as needed for a flexible calculations,
> and also proper defaults to clik on Ok and get an acceptable result.
> What do you think about this solution?
>
>> In
>> the other hand R is very powerfull in that it gives you freedom to do your
>> own style through coding. I worked with "GeoR" pakcage and it is pretty nice
>> both in terms of variography and kriging. There are other package like
>> "Gstat" that I havent worked with but have good qualities. GeoR implements
>> the so called "model based geostatistics" which is the application of
>> bayesian statististics to the geostistics I guess and it is quite new.
>
> I'm presently having a look at both geoR and gstat, and also the wrapper
> package automap.
> I guess that the first users of the new module would be already familiar
> with R and GRASS, so their feedback about most used functions is very
> important.
>

Hi. It is alway nice to see people working GRASS SoC projects, thank you!

I would just add-- I think that all efforts to build onto existing
libraries would be a good thing. That is to say, try and work with
GRASS-R-gstat: this is by far one of the best implementations of
geostatistics available. Paul's automap would be another likely
candidate .

The real problem with a single GRASS module for 'kriging' is that the
operation requires careful thought and familiarity with the data-- not
really something that can be easily generalized to the conceptual
basis of a single GRASS module. Perhaps asking Edzer about room for
user-interface improvements in the gstat code would yield some good
starting points.

Cheers,
Dylan


From BRWIN338 at aol.com  Sun May 24 04:49:20 2009
From: BRWIN338 at aol.com (BRWIN338 at aol.com)
Date: Sat, 23 May 2009 22:49:20 EDT
Subject: [R-sig-Geo]  RE:Constraining a linear regression model
Message-ID: <be9.51d1b40f.374a0fb0@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090523/fc3e6789/attachment.pl>

From BRWIN338 at aol.com  Sun May 24 05:08:35 2009
From: BRWIN338 at aol.com (BRWIN338 at aol.com)
Date: Sat, 23 May 2009 23:08:35 EDT
Subject: [R-sig-Geo] Finding the county shapefile polygon closest to
	along-lat pos...
Message-ID: <d18.464a4da4.374a1433@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090523/4b707f90/attachment.pl>

From e.jahanshiri at gmail.com  Sun May 24 08:34:06 2009
From: e.jahanshiri at gmail.com (Ebrahim Jahanshiri)
Date: Sun, 24 May 2009 14:34:06 +0800
Subject: [R-sig-Geo] [Soc] GRASS module for kriging - call for users
	[was: R-sig-Geo Digest, Vol 69, Issue 21]
In-Reply-To: <4A183995.7060606@studenti.uninsubria.it>
References: <mailman.13.1242986402.30725.r-sig-geo@stat.math.ethz.ch>
	<b0a6ce470905222031w4010f1feo1970e8bab178bae6@mail.gmail.com>
	<4A183995.7060606@studenti.uninsubria.it>
Message-ID: <b0a6ce470905232334v4d43db97o5904beae9130c911@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090524/9b672ff0/attachment.pl>

From raphael.viscarra-rossel at csiro.au  Mon May 25 10:24:16 2009
From: raphael.viscarra-rossel at csiro.au (Viscarra Rossel, Raphael (CLW, Black Mountain))
Date: Mon, 25 May 2009 18:24:16 +1000
Subject: [R-sig-Geo] deleting grid points outside boundary
Message-ID: <5ED3CACC-F99E-4F6B-BDCA-BCEC0BBE71BB@csiro.au>

Hello,
I have been using gstat to krige maps over my study area.
The area is irregularly shaped and has quite a complex boundary.
I have made a regular (square) grid that covers my study area and made  
my estimates on this grid.
Now that I have my maps, I would like to 'mask out' or delete the  
areas in my map that are outside my study area - i.e. where I don't  
have any data, where the interpolations don't make sense. Essentially,  
I want to end up only with the estimates over my study area.

As I said, the boundary of the study area is quite complex so the  
chull method will not work well. I have seen a few posts where this  
was suggested.

I have the xy coordinates for the boundary (and a shape file) for the   
study area. I am wondering whether I could overlay it over the grid  
with my estimates and then use it to remove the bits on the grid that  
I don't want and so end up with a map of only the estimates over my  
study area.

Could someone help with this please?

Cheers

R.


From edzer.pebesma at uni-muenster.de  Mon May 25 11:15:39 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 25 May 2009 11:15:39 +0200
Subject: [R-sig-Geo] deleting grid points outside boundary
In-Reply-To: <5ED3CACC-F99E-4F6B-BDCA-BCEC0BBE71BB@csiro.au>
References: <5ED3CACC-F99E-4F6B-BDCA-BCEC0BBE71BB@csiro.au>
Message-ID: <4A1A61BB.5030604@uni-muenster.de>

Raphael,

you could read your shapefile with readOGR in package rgdal,
then use function overlay to find the points in the polygon,
along the lines of:

# grd is your full, rectangular grid
# polygon is the shapefile you read
require(sp)
fullgrid(grd) = FALSE
sel = !is.na(overlay(grd, polygon))
grd = grd[sel,]
plot(grd)
--
Edzer


Viscarra Rossel, Raphael (CLW, Black Mountain) wrote:
> Hello,
> I have been using gstat to krige maps over my study area.
> The area is irregularly shaped and has quite a complex boundary.
> I have made a regular (square) grid that covers my study area and made
> my estimates on this grid.
> Now that I have my maps, I would like to 'mask out' or delete the
> areas in my map that are outside my study area - i.e. where I don't
> have any data, where the interpolations don't make sense. Essentially,
> I want to end up only with the estimates over my study area.
>
> As I said, the boundary of the study area is quite complex so the
> chull method will not work well. I have seen a few posts where this
> was suggested.
>
> I have the xy coordinates for the boundary (and a shape file) for the 
> study area. I am wondering whether I could overlay it over the grid
> with my estimates and then use it to remove the bits on the grid that
> I don't want and so end up with a map of only the estimates over my
> study area.
>
> Could someone help with this please?
>
> Cheers
>
> R.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From edzer.pebesma at uni-muenster.de  Mon May 25 12:42:01 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 25 May 2009 12:42:01 +0200
Subject: [R-sig-Geo] [Soc] GRASS module for kriging - call for
 users	[was: R-sig-Geo Digest, Vol 69, Issue 21]
In-Reply-To: <b0a6ce470905232334v4d43db97o5904beae9130c911@mail.gmail.com>
References: <mailman.13.1242986402.30725.r-sig-geo@stat.math.ethz.ch>	<b0a6ce470905222031w4010f1feo1970e8bab178bae6@mail.gmail.com>	<4A183995.7060606@studenti.uninsubria.it>
	<b0a6ce470905232334v4d43db97o5904beae9130c911@mail.gmail.com>
Message-ID: <4A1A75F9.2090804@uni-muenster.de>

I believe that many interpolation problems "out there" are simple, and
can be solved using geostatistics with a "finish" or "interpolate"
button. A question I find interesting is whether this button should
always do its best, or should it be so clever to warn the user in case a
problem is not "that simple", and what the criteria are for this.

Of course this SoC project is about an "interpolate" button using open
source software, so the user is always able to find out every detail
behind it. But will she or he actually do this in a non-simple case?

As of your claim that no two geostatistical packages provide the same
result, as a more optimistic person I'd like to provide some
counter-evidence; please run:

require(gstat)
require(geoR)
xyz = data.frame(x = c(0,0,1), y = c(0, 1, 1), z = c(1,2,3))
coordinates(xyz)=~x+y
x0 = SpatialPoints(data.frame(x=0,y=.5))
kr1 = krige(z~1,xyz,x0,vgm(1, "Exp", 1))
kr2 = krige.conv(as.geodata(xyz), locations=coordinates(x0),
	krige=list(cov.model="exponential", cov.par=c(1,1)))
kr1
c(kr2$predict, kr2$krige.var)
kr1[[1]] - kr2$predict
kr1[[2]] - kr2$krige.var

I'd be more than happy if someone could repeat this, or another example,
with ArcGIS or other software, of course.
--
Edzer

Ebrahim Jahanshiri wrote:
> Dear Ann,
> I think having a "finish" button is the ulitimate thing that all of us
> looking for in a software!. Unfourtunately it is not possible. There are far
> too many issues regarding a good kriging operation that prevents you from
> trusting a nice package like "Geostatistical Analyst" in ArcGIS. The
> evidence is that you cant find two geostatistical package that their resutl
> is the same (I know this is a big statement but I have seen this for a
> couple of softwares!). I cant say the surface that is generated by ArcGIS is
> not accurate but it bothers me to not know what happens beneath the program
> when it fits the variogram and calculates the matrices for kriging and more
> importantly a "routine" that you mentioned will not work for all the data.
> So personaly I will go for the chors of GeoR or Gstat instead of using the
> ArcGIS. Though it is not complete and I have to admit that I have a lot of
> problem adapting to it.
> Ebrahim
> 
> On Sun, May 24, 2009 at 1:59 AM, Anne Ghisla Insubriae <
> a.ghisla at studenti.uninsubria.it> wrote:
> 
> Ebrahim Jahanshiri a ?crit:
>>>> Dear Anne,
> Ebrahim,
> 
>>>> Thanks for the enquiry. I think we should have done this long before. I
>>>> havent done any geostatistics with GRASS but I did alot in ArcGIS and
> also
>>>> in R (variography). I have to tell you that ArcGIS is for those who want
> to
>>>> have a surface only by just clicking on "finish" button trought its
>>>> powerfull interface. That is, it does not provide a good scientific
>>>> backgroud for you to check the procedure. for example how it fitted the
>>>> variogram model or how exactly it does the "validation". That is why the
>>>> "Geostatistical package" objects or classes are not available for the
>>>> programmers to program with (there is a kriging in "Spatial analyst"
> package
>>>> though that its object is programmable and I personally did some with it.
>>>> but it lacks the variogram modeling). I think they are still working on
> it.
>>>> In short I dont recommend ArcGIS for the so called scientific kriging.
> I was afraid of this. Therefore I guess an interface with too many
> mandatory options would be considered overcomplicated.
> There should be as more options as needed for a flexible calculations,
> and also proper defaults to clik on Ok and get an acceptable result.
> What do you think about this solution?
> 
>>>> In
>>>> the other hand R is very powerfull in that it gives you freedom to do
> your
>>>> own style through coding. I worked with "GeoR" pakcage and it is pretty
> nice
>>>> both in terms of variography and kriging. There are other package like
>>>> "Gstat" that I havent worked with but have good qualities. GeoR
> implements
>>>> the so called "model based geostatistics" which is the application of
>>>> bayesian statististics to the geostistics I guess and it is quite new.
> I'm presently having a look at both geoR and gstat, and also the wrapper
> package automap.
> I guess that the first users of the new module would be already familiar
> with R and GRASS, so their feedback about most used functions is very
> important.
> 
>>>> I hope these comments were helpful and please let me know if you need any
>>>> further explanation from me,
> Very helpful, thank you very much!
> 
>>>> Ebrahim
>>>>
> best regards,
> Anne
> 
>>

> ------------------------------------------------------------------------

> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From a.ghisla at studenti.uninsubria.it  Mon May 25 14:05:08 2009
From: a.ghisla at studenti.uninsubria.it (Anne Ghisla)
Date: Mon, 25 May 2009 14:05:08 +0200
Subject: [R-sig-Geo] [Soc] GRASS module for kriging - call for users
 [was: R-sig-Geo Digest, Vol 69, Issue 21]
In-Reply-To: <4A1A75F9.2090804@uni-muenster.de>
References: <mailman.13.1242986402.30725.r-sig-geo@stat.math.ethz.ch>
	<b0a6ce470905222031w4010f1feo1970e8bab178bae6@mail.gmail.com>
	<4A183995.7060606@studenti.uninsubria.it>
	<b0a6ce470905232334v4d43db97o5904beae9130c911@mail.gmail.com>
	<4A1A75F9.2090804@uni-muenster.de>
Message-ID: <1243253108.4167.40.camel@galadriel.uagra.net>

Edzer Pebesma escribi?:
> I believe that many interpolation problems "out there" are simple, and
> can be solved using geostatistics with a "finish" or "interpolate"
> button. A question I find interesting is whether this button should
> always do its best, or should it be so clever to warn the user in case a
> problem is not "that simple", and what the criteria are for this.

Hello Edzer and others that follow this thread,

as suggested by Ebrahim, most users would appreciate a tool able to
quietly fit the analysis to the data oddities, but surely I wouldn't
implement nor use a tool that automagically gives acceptable results
without tracking of the optimisation steps. I have some experience with
ArcView's Animal Movement[0]: I tested the tool in edge cases, where
algorithms *have to* crash, and it always succeeded without
explanations. 
Sincerely speaking, I'm not able to provide such intelligence to my
module in the near future. If we plan to add this functionality later, I
guess it will be good both to log the procedure and/or let user interact
and understand what it is happening in any moment.

Apropos of warning users about possibile difficulties, I think that the
cleverness needed to give such advices is quite hard to implement, but
not impossible. (/me thinks of strategy-missing hints in card games...).

> Of course this SoC project is about an "interpolate" button using open
> source software, so the user is always able to find out every detail
> behind it. But will she or he actually do this in a non-simple case?

I suppose the users to know what they're doing - R and GRASS users are
already aware that the tools they use can give meaningless answers and
it's up to them to use commands consciously. If users want to use
v.autokrige2 just to try it out, they will get the result of a standard
procedure. To obtain something better, they should know how to use the
'advanced' options.

> As of your claim that no two geostatistical packages provide the same
> result, as a more optimistic person I'd like to provide some
> counter-evidence; please run:
[cut]
> 
> I'd be more than happy if someone could repeat this, or another example,
> with ArcGIS or other software, of course.

Marked on the todo list, stay in touch :)

thank you very much,
Anne

[0] http://www.absc.usgs.gov/glba/gistools/animal_mvmt.htm

> Ebrahim Jahanshiri wrote:
> > Dear Ann,
> > I think having a "finish" button is the ulitimate thing that all of us
> > looking for in a software!. Unfourtunately it is not possible. There are far
> > too many issues regarding a good kriging operation that prevents you from
> > trusting a nice package like "Geostatistical Analyst" in ArcGIS. The
> > evidence is that you cant find two geostatistical package that their resutl
> > is the same (I know this is a big statement but I have seen this for a
> > couple of softwares!). I cant say the surface that is generated by ArcGIS is
> > not accurate but it bothers me to not know what happens beneath the program
> > when it fits the variogram and calculates the matrices for kriging and more
> > importantly a "routine" that you mentioned will not work for all the data.
> > So personaly I will go for the chors of GeoR or Gstat instead of using the
> > ArcGIS. Though it is not complete and I have to admit that I have a lot of
> > problem adapting to it.
> > Ebrahim
> > 
> > On Sun, May 24, 2009 at 1:59 AM, Anne Ghisla Insubriae <
> > a.ghisla at studenti.uninsubria.it> wrote:
> > 
> > Ebrahim Jahanshiri a ?crit:
> >>>> Dear Anne,
> > Ebrahim,
> > 
> >>>> Thanks for the enquiry. I think we should have done this long before. I
> >>>> havent done any geostatistics with GRASS but I did alot in ArcGIS and
> > also
> >>>> in R (variography). I have to tell you that ArcGIS is for those who want
> > to
> >>>> have a surface only by just clicking on "finish" button trought its
> >>>> powerfull interface. That is, it does not provide a good scientific
> >>>> backgroud for you to check the procedure. for example how it fitted the
> >>>> variogram model or how exactly it does the "validation". That is why the
> >>>> "Geostatistical package" objects or classes are not available for the
> >>>> programmers to program with (there is a kriging in "Spatial analyst"
> > package
> >>>> though that its object is programmable and I personally did some with it.
> >>>> but it lacks the variogram modeling). I think they are still working on
> > it.
> >>>> In short I dont recommend ArcGIS for the so called scientific kriging.
> > I was afraid of this. Therefore I guess an interface with too many
> > mandatory options would be considered overcomplicated.
> > There should be as more options as needed for a flexible calculations,
> > and also proper defaults to clik on Ok and get an acceptable result.
> > What do you think about this solution?
> > 
> >>>> In
> >>>> the other hand R is very powerfull in that it gives you freedom to do
> > your
> >>>> own style through coding. I worked with "GeoR" pakcage and it is pretty
> > nice
> >>>> both in terms of variography and kriging. There are other package like
> >>>> "Gstat" that I havent worked with but have good qualities. GeoR
> > implements
> >>>> the so called "model based geostatistics" which is the application of
> >>>> bayesian statististics to the geostistics I guess and it is quite new.
> > I'm presently having a look at both geoR and gstat, and also the wrapper
> > package automap.
> > I guess that the first users of the new module would be already familiar
> > with R and GRASS, so their feedback about most used functions is very
> > important.
> > 
> >>>> I hope these comments were helpful and please let me know if you need any
> >>>> further explanation from me,
> > Very helpful, thank you very much!
> > 
> >>>> Ebrahim
> >>>>
> > best regards,
> > Anne
> > 
> >>
> 
> > ------------------------------------------------------------------------
> 
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 197 bytes
Desc: Questa ? una parte del messaggio	firmata digitalmente
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090525/6ada584a/attachment.bin>

From e.jahanshiri at gmail.com  Mon May 25 14:45:11 2009
From: e.jahanshiri at gmail.com (Ebrahim Jahanshiri)
Date: Mon, 25 May 2009 20:45:11 +0800
Subject: [R-sig-Geo] [Soc] GRASS module for kriging - call for users
	[was: R-sig-Geo Digest, Vol 69, Issue 21]
In-Reply-To: <4A1A75F9.2090804@uni-muenster.de>
References: <mailman.13.1242986402.30725.r-sig-geo@stat.math.ethz.ch>
	<b0a6ce470905222031w4010f1feo1970e8bab178bae6@mail.gmail.com>
	<4A183995.7060606@studenti.uninsubria.it>
	<b0a6ce470905232334v4d43db97o5904beae9130c911@mail.gmail.com>
	<4A1A75F9.2090804@uni-muenster.de>
Message-ID: <b0a6ce470905250545h7ddbf610n2fbf81681e1380da@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090525/a724c0d6/attachment.pl>

From edzer.pebesma at uni-muenster.de  Mon May 25 15:21:15 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 25 May 2009 15:21:15 +0200
Subject: [R-sig-Geo] [Soc] GRASS module for kriging - call for users
 [was: R-sig-Geo Digest, Vol 69, Issue 21]
In-Reply-To: <b0a6ce470905250545h7ddbf610n2fbf81681e1380da@mail.gmail.com>
References: <mailman.13.1242986402.30725.r-sig-geo@stat.math.ethz.ch>	
	<b0a6ce470905222031w4010f1feo1970e8bab178bae6@mail.gmail.com>	
	<4A183995.7060606@studenti.uninsubria.it>	
	<b0a6ce470905232334v4d43db97o5904beae9130c911@mail.gmail.com>	
	<4A1A75F9.2090804@uni-muenster.de>
	<b0a6ce470905250545h7ddbf610n2fbf81681e1380da@mail.gmail.com>
Message-ID: <4A1A9B4B.5020106@uni-muenster.de>

Ebrahim Jahanshiri wrote:
> for kriging a preliminary analysis is important. We should know if the data
> has trend or how are the ouliers? should we remove them or not. Some of the
> kriging techniques like universal kriging create very odd values at some
> points if we dont deal with the data frist hand before kriging. I hope that
> we can come up with the software that does all this by itselft ( some sort
> of decision maker like AI). I hope to see this kind of sotware pretty soon
> and I wish it be open source.
>   
I agree that this would be nice.

We discussed this issue quite lengthy in the intamap consortium (see
http://www.intamap.org/ , and the wiki as well -- also interesting for
the SoC project). We concluded that for a generic automatic
interpolation algorithm users don't want this to be done automatically,
because no automatic algorithm can decide whether an outlier indicates a
measurement error or a disaster. Remember the ozone layer was overlooked
for many years because an automatic "outlier" algorithm was built in the
data processing chain.

Only if your application is domain specific you can do something useful,
e.g. use physical limits -- soil moisture content can never exceed 100%;
content variables need to be non-negative.

Of course you can add options, and build optional outlier filters. Then,
how should outliers be marked? Is there any agreement on this? What
would be the defaults for necessary parameters?

Automatic trend detection is another issue that is very interesting.

> On Mon, May 25, 2009 at 6:42 PM, Edzer Pebesma <
> edzer.pebesma at uni-muenster.de> wrote:
>
>   
>> I believe that many interpolation problems "out there" are simple, and
>> can be solved using geostatistics with a "finish" or "interpolate"
>> button. A question I find interesting is whether this button should
>> always do its best, or should it be so clever to warn the user in case a
>> problem is not "that simple", and what the criteria are for this.
>>
>> Of course this SoC project is about an "interpolate" button using open
>> source software, so the user is always able to find out every detail
>> behind it. But will she or he actually do this in a non-simple case?
>>
>> As of your claim that no two geostatistical packages provide the same
>> result, as a more optimistic person I'd like to provide some
>> counter-evidence; please run:
>>
>> require(gstat)
>> require(geoR)
>> xyz = data.frame(x = c(0,0,1), y = c(0, 1, 1), z = c(1,2,3))
>> coordinates(xyz)=~x+y
>> x0 = SpatialPoints(data.frame(x=0,y=.5))
>> kr1 = krige(z~1,xyz,x0,vgm(1, "Exp", 1))
>> kr2 = krige.conv(as.geodata(xyz), locations=coordinates(x0),
>>        krige=list(cov.model="exponential", cov.par=c(1,1)))
>> kr1
>> c(kr2$predict, kr2$krige.var)
>> kr1[[1]] - kr2$predict
>> kr1[[2]] - kr2$krige.var
>>
>> I'd be more than happy if someone could repeat this, or another example,
>> with ArcGIS or other software, of course.
>> --
>> Edzer
>>
>> Ebrahim Jahanshiri wrote:
>>     
>>> Dear Ann,
>>> I think having a "finish" button is the ulitimate thing that all of us
>>> looking for in a software!. Unfourtunately it is not possible. There are
>>>       
>> far
>>     
>>> too many issues regarding a good kriging operation that prevents you from
>>> trusting a nice package like "Geostatistical Analyst" in ArcGIS. The
>>> evidence is that you cant find two geostatistical package that their
>>>       
>> resutl
>>     
>>> is the same (I know this is a big statement but I have seen this for a
>>> couple of softwares!). I cant say the surface that is generated by ArcGIS
>>>       
>> is
>>     
>>> not accurate but it bothers me to not know what happens beneath the
>>>       
>> program
>>     
>>> when it fits the variogram and calculates the matrices for kriging and
>>>       
>> more
>>     
>>> importantly a "routine" that you mentioned will not work for all the
>>>       
>> data.
>>     
>>> So personaly I will go for the chors of GeoR or Gstat instead of using
>>>       
>> the
>>     
>>> ArcGIS. Though it is not complete and I have to admit that I have a lot
>>>       
>> of
>>     
>>> problem adapting to it.
>>> Ebrahim
>>>
>>> On Sun, May 24, 2009 at 1:59 AM, Anne Ghisla Insubriae <
>>> a.ghisla at studenti.uninsubria.it> wrote:
>>>
>>> Ebrahim Jahanshiri a ?crit:
>>>       
>>>>>> Dear Anne,
>>>>>>             
>>> Ebrahim,
>>>
>>>       
>>>>>> Thanks for the enquiry. I think we should have done this long before.
>>>>>>             
>> I
>>     
>>>>>> havent done any geostatistics with GRASS but I did alot in ArcGIS and
>>>>>>             
>>> also
>>>       
>>>>>> in R (variography). I have to tell you that ArcGIS is for those who
>>>>>>             
>> want
>>     
>>> to
>>>       
>>>>>> have a surface only by just clicking on "finish" button trought its
>>>>>> powerfull interface. That is, it does not provide a good scientific
>>>>>> backgroud for you to check the procedure. for example how it fitted
>>>>>>             
>> the
>>     
>>>>>> variogram model or how exactly it does the "validation". That is why
>>>>>>             
>> the
>>     
>>>>>> "Geostatistical package" objects or classes are not available for the
>>>>>> programmers to program with (there is a kriging in "Spatial analyst"
>>>>>>             
>>> package
>>>       
>>>>>> though that its object is programmable and I personally did some with
>>>>>>             
>> it.
>>     
>>>>>> but it lacks the variogram modeling). I think they are still working
>>>>>>             
>> on
>>     
>>> it.
>>>       
>>>>>> In short I dont recommend ArcGIS for the so called scientific kriging.
>>>>>>             
>>> I was afraid of this. Therefore I guess an interface with too many
>>> mandatory options would be considered overcomplicated.
>>> There should be as more options as needed for a flexible calculations,
>>> and also proper defaults to clik on Ok and get an acceptable result.
>>> What do you think about this solution?
>>>
>>>       
>>>>>> In
>>>>>> the other hand R is very powerfull in that it gives you freedom to do
>>>>>>             
>>> your
>>>       
>>>>>> own style through coding. I worked with "GeoR" pakcage and it is
>>>>>>             
>> pretty
>>     
>>> nice
>>>       
>>>>>> both in terms of variography and kriging. There are other package like
>>>>>> "Gstat" that I havent worked with but have good qualities. GeoR
>>>>>>             
>>> implements
>>>       
>>>>>> the so called "model based geostatistics" which is the application of
>>>>>> bayesian statististics to the geostistics I guess and it is quite new.
>>>>>>             
>>> I'm presently having a look at both geoR and gstat, and also the wrapper
>>> package automap.
>>> I guess that the first users of the new module would be already familiar
>>> with R and GRASS, so their feedback about most used functions is very
>>> important.
>>>
>>>       
>>>>>> I hope these comments were helpful and please let me know if you need
>>>>>>             
>> any
>>     
>>>>>> further explanation from me,
>>>>>>             
>>> Very helpful, thank you very much!
>>>
>>>       
>>>>>> Ebrahim
>>>>>>
>>>>>>             
>>> best regards,
>>> Anne
>>>
>>>       
>>> ------------------------------------------------------------------------
>>>       
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>       
>> --
>> Edzer Pebesma
>> Institute for Geoinformatics (ifgi), University of M?nster
>> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
>> 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
>> http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de
>>
>>     
>
>
>
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From j.burke at earthlink.net  Mon May 25 20:13:40 2009
From: j.burke at earthlink.net (Jim Burke)
Date: Mon, 25 May 2009 13:13:40 -0500
Subject: [R-sig-Geo] How to negate %in%
Message-ID: <4A1ADFD4.800@earthlink.net>

I can subset a "SpatialPolygonsDataFrame" from a
data frame containing a smaller subset of IDs. For
example below.

smaller_sp <- large_sp [large_sp$ID %in% smaller_df$ID,]

Given the above how can I do the logically opposite from
the %in% operation and get all those IDs not %in%?

I am processing two different sets of polygons (A,B) in
a loop. Operation is seeing in center points in polys B
fall in A. I would like to remove the spatial polygons
that I found (B) as I traverse the geographical area.

Thanks,
Jim Burke


From torleif.lunde at cih.uib.no  Mon May 25 20:26:06 2009
From: torleif.lunde at cih.uib.no (Torleif Markussen Lunde)
Date: Mon, 25 May 2009 20:26:06 +0200
Subject: [R-sig-Geo] How to negate %in%
In-Reply-To: <4A1ADFD4.800@earthlink.net>
References: <4A1ADFD4.800@earthlink.net>
Message-ID: <200905252026.06780.torleif.lunde@cih.uib.no>

Hi 

This (!) might work:

aa <- 1:10
bb <- 5:6

aa[!aa %in% bb]
[1]  1  2  3  4  7  8  9 10

aa[aa %in% bb]
[1] 5 6

Best wishes
Torleif


On Monday 25 May 2009 08:13:40 pm Jim Burke wrote:
> I can subset a "SpatialPolygonsDataFrame" from a
> data frame containing a smaller subset of IDs. For
> example below.
>
> smaller_sp <- large_sp [large_sp$ID %in% smaller_df$ID,]
>
> Given the above how can I do the logically opposite from
> the %in% operation and get all those IDs not %in%?
>
> I am processing two different sets of polygons (A,B) in
> a loop. Operation is seeing in center points in polys B
> fall in A. I would like to remove the spatial polygons
> that I found (B) as I traverse the geographical area.
>
> Thanks,
> Jim Burke
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From dan.putler at sauder.ubc.ca  Mon May 25 21:11:32 2009
From: dan.putler at sauder.ubc.ca (Dan Putler)
Date: Mon, 25 May 2009 12:11:32 -0700
Subject: [R-sig-Geo] How to negate %in%
Message-ID: <1243278692.6789.24.camel@whitebox>

Sorry, I sent my initial reply only to Jim, not the list.

Dan

-------- Forwarded Message --------
From: Jim Burke <j.burke at earthlink.net>
To: Dan Putler <dan.putler at sauder.ubc.ca>
Subject: Re: [R-sig-Geo] How to negate %in%
Date: Mon, 25 May 2009 14:01:26 -0500

Thanks Dan,

Both yours and Torleif's suggestions work with a
SpatialPolygonsDataFrame.   

It feels like Dan's suggestion works faster for
my 1,897 polygons.

Thanks again,
Jim Burke

Dan Putler wrote:
> Jim,
>
> A quick answer below.
>
> Dan
>
> On Mon, 2009-05-25 at 13:13 -0500, Jim Burke wrote:
>   
>> I can subset a "SpatialPolygonsDataFrame" from a
>> data frame containing a smaller subset of IDs. For
>> example below.
>>
>> smaller_sp <- large_sp [large_sp$ID %in% smaller_df$ID,]
>>     
>
> smaller_sp <- large_sp [!(large_sp$ID %in% smaller_df$ID),]
>   
>> Given the above how can I do the logically opposite from
>> the %in% operation and get all those IDs not %in%?
>>
>> I am processing two different sets of polygons (A,B) in
>> a loop. Operation is seeing in center points in polys B
>> fall in A. I would like to remove the spatial polygons
>> that I found (B) as I traverse the geographical area.
>>
>> Thanks,
>> Jim Burke
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>     

-- 
Dan Putler
Sauder School of Business
University of British Columbia


From j.burke at earthlink.net  Mon May 25 21:34:48 2009
From: j.burke at earthlink.net (Jim Burke)
Date: Mon, 25 May 2009 14:34:48 -0500
Subject: [R-sig-Geo] How to negate %in%
In-Reply-To: <200905252026.06780.torleif.lunde@cih.uib.no>
References: <4A1ADFD4.800@earthlink.net>
	<200905252026.06780.torleif.lunde@cih.uib.no>
Message-ID: <4A1AF2D8.1000104@earthlink.net>

Hi All,

Everyone's suggestions work. There are lots
of roads to solutions in R. This is wonderful!

It seems that Dan's and Pedro's solutions
work faster for my largish 1,897 spatial
polygon data frame.

Thanks,
Jim Burke

All replies are below.

=================================================
Hi This (!) might work:
aa <- 1:10
bb <- 5:6
aa[!aa %in% bb]     ## Yes it works
[1]  1  2  3  4  7  8  9 10
aa[aa %in% bb]
[1] 5 6
Best wishes
Torleif Markussen

===================================================
smaller_sp <- large_sp [!(large_sp$ID %in% smaller_df$ID),]
Dan Pulter

====================================================
smaller_sp <- large_sp [large_sp$ID %in% smaller_df$ID == FALSE,]
Pedro Mardones

Torleif Markussen Lunde wrote:
> Hi 
>
> This (!) might work:
>
> aa <- 1:10
> bb <- 5:6
>
> aa[!aa %in% bb]
> [1]  1  2  3  4  7  8  9 10
>
> aa[aa %in% bb]
> [1] 5 6
>
> Best wishes
> Torleif
>
>
> On Monday 25 May 2009 08:13:40 pm Jim Burke wrote:
>   
>> I can subset a "SpatialPolygonsDataFrame" from a
>> data frame containing a smaller subset of IDs. For
>> example below.
>>
>> smaller_sp <- large_sp [large_sp$ID %in% smaller_df$ID,]
>>
>> Given the above how can I do the logically opposite from
>> the %in% operation and get all those IDs not %in%?
>>
>> I am processing two different sets of polygons (A,B) in
>> a loop. Operation is seeing in center points in polys B
>> fall in A. I would like to remove the spatial polygons
>> that I found (B) as I traverse the geographical area.
>>
>> Thanks,
>> Jim Burke
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>     
>
>
>
>
>


From jo.lists at gmail.com  Mon May 25 22:08:41 2009
From: jo.lists at gmail.com (JiHO)
Date: Mon, 25 May 2009 16:08:41 -0400
Subject: [R-sig-Geo] How to negate %in%
In-Reply-To: <4A1AF2D8.1000104@earthlink.net>
References: <4A1ADFD4.800@earthlink.net>
	<200905252026.06780.torleif.lunde@cih.uib.no>
	<4A1AF2D8.1000104@earthlink.net>
Message-ID: <4F02D21E-B316-4169-B972-00D6B5DA640F@gmail.com>

On 2009-May-25  , at 15:34 , Jim Burke wrote:

> Everyone's suggestions work. There are lots
> of roads to solutions in R. This is wonderful!

There's even more. In the package Hmisc, there is a %nin% command that  
does what you want. It is less standard (requires an additional  
package) but more syntactically pleasing.

JiHO
---
http://jo.irisson.free.fr/


From Ingo.Holz at uni-hohenheim.de  Tue May 26 14:10:41 2009
From: Ingo.Holz at uni-hohenheim.de (Ingo Holz)
Date: Tue, 26 May 2009 14:10:41 +0200
Subject: [R-sig-Geo] spplot -  polygons with colored borderlines
Message-ID: <4A1BF861.15257.15BC200@ingoholz.uni-hohenheim.de>

Hi,

 I am using function spplot (library sp) to plot polygons:

 spplot(SPDF, "var", col.regions=topo.colors(100))

 SPDF is a SpatialPolygonsDataFrame

 Some of my polygons are very small and you can not see the color of the 
polygon (only the black borderlines).

 I could use 

 spplot(as(SPDF, "SpatialLinesDataFrame"), "variable1", 
col.regions=topo.colors(100))

 to get colored borderlines.

 Is there a possibility to get filled colored polygons with borderlines in the 
same color?

 Thank you for your help.
 Best wishes,
 Ingo


From T.Hengl at uva.nl  Tue May 26 14:14:13 2009
From: T.Hengl at uva.nl (Tomislav Hengl)
Date: Tue, 26 May 2009 14:14:13 +0200
Subject: [R-sig-Geo] Converting downloaded PNG images using RgoogleMaps to
	SpatialGridDataFrame class (proj4string?)
Message-ID: <A5EF951A1FB442AEAA4BCF56E77E33EA@pcibed193>


Hi all,

Thanks to Markus Loecher and colleagues we can now easily obtain background maps from Google Earth
and use it for plotting/interpretation of spatial data.  

This runs pretty smoothly (e.g. a map of the Netherlands):

> library(RgoogleMaps)
# obtain the API key and save into the home folder;
> MyMap <- GetMap.bbox(center=c(52.1551723,5.3872035), zoom=7, destfile="netherlands.png", maptype
="hybrid")
Read 1 item
[1] "http://maps.google.com/staticmap?center=52.1551723,5.3872035&zoom=7&size=640x640
+   &maptype=hybrid&format=png32&key=****&sensor=true"
trying URL 'http://maps.google.com/staticmap?center=52.1551723,5.3872035&zoom=7&size=640x640
+   &maptype=hybrid&format=png32&key=****=true'
Content type 'image/png' length 703541 bytes (687 Kb)
opened URL
downloaded 687 Kb

netherlands.png has GDAL driver PNG 
and has 640 rows and 640 columns
> PlotOnStaticMap(MyMap, lat=52.1551723, lon=5.3872035)

But how to convert this image into a SpatialGridDataFrame to allow overlays, export to GIS formats
etc?

I am not even sure what the correct proj4string for this image is?

> str(MyMap)  # this only gives coordinates of the centre
List of 4
 $ : num 52.2
 $ : num 5.39
 $ : num 7
 $ : num [1:640, 1:640] 187 60 66 1 66 202 151 1 214 220 ...
  ..- attr(*, "COL")= chr [1:256] "#88887C" "#887440" "#747838" "#0C1C20" ...
  ..- attr(*, "type")= chr "rgb"

> GDALinfo("netherlands.png")
# the coordinates are not embedded!


Thanks,

Tom Hengl
http://home.medewerker.uva.nl/t.hengl/


From Roger.Bivand at nhh.no  Tue May 26 14:36:01 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 26 May 2009 14:36:01 +0200 (CEST)
Subject: [R-sig-Geo] spplot -  polygons with colored borderlines
In-Reply-To: <4A1BF861.15257.15BC200@ingoholz.uni-hohenheim.de>
References: <4A1BF861.15257.15BC200@ingoholz.uni-hohenheim.de>
Message-ID: <alpine.LRH.2.00.0905261425370.3751@reclus.nhh.no>

On Tue, 26 May 2009, Ingo Holz wrote:

> Hi,
>
> I am using function spplot (library sp) to plot polygons:
>
> spplot(SPDF, "var", col.regions=topo.colors(100))
>
> SPDF is a SpatialPolygonsDataFrame
>
> Some of my polygons are very small and you can not see the color of the
> polygon (only the black borderlines).
>
> I could use
>
> spplot(as(SPDF, "SpatialLinesDataFrame"), "variable1",
> col.regions=topo.colors(100))
>
> to get colored borderlines.
>
> Is there a possibility to get filled colored polygons with borderlines 
> in the same color?

Although it isn't obvious, you use the col= argument passed through to 
grid.polygon() used internally - see ?gpar after loading the gris package. 
You'll find that col="transparent" is OK:

library(rgdal)
scot_BNG <- readOGR(system.file("vectors", package = "rgdal")[1],
   "scot_BNG")
spplot(scot_BNG, "SMR")
spplot(scot_BNG, "SMR", col="transparent")

Hope this helps,

Roger

>
> Thank you for your help.
> Best wishes,
> Ingo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Ingo.Holz at uni-hohenheim.de  Tue May 26 14:54:58 2009
From: Ingo.Holz at uni-hohenheim.de (Ingo Holz)
Date: Tue, 26 May 2009 14:54:58 +0200
Subject: [R-sig-Geo] spplot - polygons with colored borderlines
Message-ID: <4A1C02C2.738.1844F88@ingoholz.uni-hohenheim.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090526/9bad7799/attachment.pl>

From Roger.Bivand at nhh.no  Tue May 26 15:46:15 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 26 May 2009 15:46:15 +0200 (CEST)
Subject: [R-sig-Geo] spplot - polygons with colored borderlines
In-Reply-To: <4A1C02C2.738.1844F88@ingoholz.uni-hohenheim.de>
References: <4A1C02C2.738.1844F88@ingoholz.uni-hohenheim.de>
Message-ID: <alpine.LRH.2.00.0905261541140.3751@reclus.nhh.no>

On Tue, 26 May 2009, Ingo Holz wrote:

> Hi Roger,
>
> thank you for your reply. After sending my email to R-sig-Geo I recognized
> that you answered a similar question somedays ago.
>
> However, if I use col = "transparent" some of my polygons are only "colored
> dots in the space".
>
> Is there no posibility to get filled colored polygons and colored borders?

I believe that grid.polygon() as used in spplot() fills to the exact 
polygon boundary, so adding coloured boundary lines might only add a pixel 
in some places on some devices, half a point line width on vector devices. 
So if the polygons are only "dots", then that is simply their size. In 
spplot() I do not think that extracting and passing a colour vector is 
easy. It could be done with base graphics, but the plot order of the 
contiguous polygons would determine which got the extra pixels, and which 
got overpainted. I think that col="transparent" is about as much as you 
can get, really.

Roger

>
> Thank you,
> Ingo
>
>
> On Tue, 26 May 2009, Ingo Holz wrote:
>
>> Hi,
>>
>> I am using function spplot (library sp) to plot polygons:
>>
>> spplot(SPDF, "var", col.regions=topo.colors(100))
>>
>> SPDF is a SpatialPolygonsDataFrame
>>
>> Some of my polygons are very small and you can not see the color of the
>> polygon (only the black borderlines).
>>
>> I could use
>>
>> spplot(as(SPDF, "SpatialLinesDataFrame"), "variable1",
>> col.regions=topo.colors(100))
>>
>> to get colored borderlines.
>>
>> Is there a possibility to get filled colored polygons with borderlines
>> in the same color?
>
> Although it isn't obvious, you use the col= argument passed through to
> grid.polygon() used internally - see ?gpar after loading the gris package.
> You'll find that col="transparent" is OK:
>
> library(rgdal)
> scot_BNG <- readOGR(system.file("vectors", package = "rgdal")[1],
>   "scot_BNG")
> spplot(scot_BNG, "SMR")
> spplot(scot_BNG, "SMR", col="transparent")
>
> Hope this helps,
>
> Roger
>
>>
>> Thank you for your help.
>> Best wishes,
>> Ingo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From ewdw at bas.ac.uk  Tue May 26 16:10:57 2009
From: ewdw at bas.ac.uk (Wakefield, Ewan)
Date: Tue, 26 May 2009 15:10:57 +0100
Subject: [R-sig-Geo] nearest neighbour list from distance matrix, etc.
Message-ID: <28C15D104A882F47954DEE56148152CC015A20AB99@nerckwmb1.ad.nerc.ac.uk>

Hi everyone,

I have been constructing simple linear models of seabird colony size as a function of habitat availability. Given that my data obviously contain a spatial component, I would like to check whether both my response and residuals exhibit any spatial auto-correlation. I understand that I can test for this using Moran's I, calculated for pairs of colonies separated into different distance classes. However, this presents a number of problems:

1. All of the distance based methods I have come across for defining nearest neighbours require a matrix of point coordinates. The species I am working with do not fly over land, so the Euclidean or greater circle distance between colonies is not really appropriate. Hence, I have computed a matrix of the 'at sea' distance between all colonies. Is there any way to pass this to a function that defines nearest neighbours?

2. I only have data for 48 colonies and they are clustered in space. As such, I suspect I will end up with either many distance classes with none or very few pairs of colonies in them or just one or two distance classes with a larger number of pairs of colonies. Is there any rule of thumb for how many data are required for a reasonable estimate of Moran's I? Indeed, is Moran's I even appropriate in this case?

Sorry not to include any code, but that doesn't seem appropriate to my question.

Kind regards,

Ewan Wakefield (PhD Student)
British Antarctic Survey
High Cross
Madingley Road
Cambridge
CB3 0ET
UK

tel. +44(0)1223 221215
website www.antarctica.ac.uk


From T.Hengl at uva.nl  Tue May 26 18:03:39 2009
From: T.Hengl at uva.nl (Tomislav Hengl)
Date: Tue, 26 May 2009 18:03:39 +0200
Subject: [R-sig-Geo] Info: SAGA vs GRASS workshop,
	University of Zurich 29 August & 30 August 2009
Message-ID: <E6D186DA3D2F490980CB63D96F402C10@pcibed193>


Title: Automated analysis of elevation data in R+SAGA/GRASS
Venue: University of Zurich, Irchel Campus, 29 August & 30 August 2009
Workshop moderators: Tomislav Hengl / Carlos H. Grohmann
Registration fees: 150 CHF (PhD students)

For more info: http://2009.geomorphometry.org/ 

Summary: This workshop aims at PhD students and professionals interested to use open source software
packages for processing of their elevation data. R is the open-source version of the S language for
statistical computing; SAGA (System for Automated Geoscientific Analyses) and GRASS (Geographic
Resources Analysis Support System) are the two most used open-source desktop GIS for automated
analysis of elevation data. A combination of R+SAGA/GRASS provides a full integration of statistics
and geomorphometry.

The topics in this workshop will range from selection of grid cell size, choice of algorithms for
DEM generation and filtering, to geostatistical simulations and error propagation. The workshop
moderators will demonstrate that R+SAGA/GRASS is capable of handling such demanding tasks as DEM
generation from auxiliary maps, automated classification of landforms, and sub-grid parameterization
of surface models.
The course will focus on understanding R and SAGA/GRASS syntax and building scripts that can be used
to automate DEM-data processing. Each participant should come with a laptop PC and install all
software needed prior to the workshop. Registered participants will receive an USB stick with all
data sets and overheads at the beginning of the course. Participants will follow a case study that
focuses on generation of DEMs, extraction of DEM parameters and landform classes, and implementation
of error propagation in geomorphometry.

To register, fill in and forward the registrations forms available at:
http://2009.geomorphometry.org/registration.htm


From reeves at nceas.ucsb.edu  Tue May 26 18:57:40 2009
From: reeves at nceas.ucsb.edu (rick reeves)
Date: Tue, 26 May 2009 09:57:40 -0700
Subject: [R-sig-Geo] SP Spatial List operation - error in R 2.9 not in R 2.8
 (download example)
Message-ID: <4A1C1F84.7090005@nceas.ucsb.edu>

Hello List:

While writing an R script to display and subsample a raster image,
I encountered an error in the Spatial_.xxxx classes that occurs in
R ver 2.9, but not in R ver 2.8.

Note: I installed both versions within the last 5 days, and ran
the update.packages() command after each installation.

Please download the script (and a small sample image .tif file) at:

   http://www.nceas.ucsb.edu/scicomp/SpSamplingGridQuest.zip

(complete script replicated at bottom of this message)

Here is the problem:

I developed this script using R 2.8, and the results were as expected:
A subsampled image. But when I ran the script under R 2.9.0, the
subsampled image is 'empty'. Checking the data objects, the first
statement to exhibit a problem is:

SamplingPoints <- as(SamplingGrid,"SpatialPoints")

For statement: < str(SamplingPoints) >

R version 2.8.1 produces this result:

Formal class 'SpatialPoints' [package "sp"] with 3 slots
  ..@ coords     : num [1:24021, 1:2] -1759592 -1758712 -1757832 
-1756952 -1756072 ...
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : NULL
  .. .. ..$ : chr [1:2] "x" "y"
  ..@ bbox       : num [1:2, 1:2] -1760032 5929 -1621872 140569
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr [1:2] "x" "y"
  .. .. ..$ : chr [1:2] "min" "max"
  ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
  .. .. ..@ projargs: chr NA

But R version 2.9 produces this (incorrect) result. Compare the @coords slot
produced by each version:

Formal class 'SpatialPoints' [package "sp"] with 3 slots
  ..@ coords     : num [1:2, 1:2] -1759592 -1622312 6369 140129
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : NULL
  .. .. ..$ : chr [1:2] "x" "y"
  ..@ bbox       : num [1:2, 1:2] -1760032 5929 -1621872 140569
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr [1:2] "x" "y"
  .. .. ..$ : chr [1:2] "min" "max"
  ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
  .. .. ..@ projargs: chr NA
Warning message:
In data.row.names(row.names, rowsi, i) :
  some row.names duplicated: 
2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,
43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,.........

Have I made a coding mistake? Has anyone encountered a similar problem? 
Is there a fix underway?

Thanks for any information -

Rick R


-- 
Rick Reeves
Scientific Programmer/Analyst and Data Manager
National Center for Ecological Analysis and Synthesis
UC Santa Barbara
www.nceas.ucsb.edu
805 892 2533

The script: 

#########################################################################
# SubsampleImageFiles.r
#  
# This function reads a raster image file, and creates an output
# file with coarser spatial resolution. Technique used: Subsampling.
# Create a sampling grid at a different (usually coarser) resolution
# than the input image, 'overlay' the sampling grid on the input
# image, extract a point from the image at each grid location,
# and then write the sampling grid to an output file in .img format.
# 
# This example demonstrates the R feaures that read, write and display
# raster datasets AND use of the R Spatial objects used to store
# and manipulate raster images.
# 
# Note: as of May 22, 2009, this routine does not work properly
# under R version 2.9: 
# Statement 'SamplingPoints <- as(SamplingGrid,"SpatialPoints")': In R version 2.9,
#            creates incorrect Spatial Points object, with only 2 rows/columns. 
# 
# Author: Rick Reeves
# Date created: 29-Apr-2009                 
# Date modified: 20-May-2009                                                            
# NCEAS
#
#########################################################################
#
SubsampleImageFilesQuest <- function()
{
   library(rgdal)
   library(maptools)  
   library(Hmisc)
#
   SampleFactor <- 2 # A factor of 2 creates a new image with 1/2 the number of pixels as the input image
#
# Step 1) Read input image into a SpatialGridDataFrame object, then display.
# 
   InputImage <- readGDAL("NevadaSiteDEMAlbersSub.tif")      
#
# Create a basic 256-level grey scale 'ramp' for the DEM image
#   
   greys <- grey(0:256 / 256)   
   dev.set(1) # plot in new window      
   grob <- spplot(InputImage, "band1", col.regions=greys,cuts=length(greys))
   plot(grob)    
#
# Create a sampling grid, using the input image's spatial parameters  
#   
   SamplingGridTopology <- GridTopology(InputImage at bbox[,1],
                                       InputImage at grid@cellsize * SampleFactor,
                                       InputImage at grid@cells.dim / SampleFactor)
#
# Create the necessary data structures
#                                       
   SamplingGrid <- SpatialGrid(SamplingGridTopology)  
   OutSpatialGridSGDF <- as(SamplingGrid,"SpatialGridDataFrame")
   SamplingPoints <- as(SamplingGrid,"SpatialPoints")   # In R ver 2.9, this line generates a
#                                                       # SamplingPoints object with 2 rows, 2 cols. 
#                                                       # R ver 2.81 produces a  SamplingPoints object
                                                        # with same number of rows/cols as SamplingGrid
#                                                        
# Subsample the input image, create 
# a SpatialGridDataFrame object.
# 
   SamplingResultsSPDF <- overlay(InputImage,SamplingPoints)    
   OutSpatialGridSGDF at data <- SamplingResultsSPDF at data 
   OutSpatialGridSGDF at proj4string <- CRS(proj4string(InputImage))   
   gridded(OutSpatialGridSGDF) <- TRUE 
#
# use Hmisc library describe() function to compare the incoming and resampled images
#
   message("Summary of incoming and outgoing images (hit key to continue):") 
   Incoming = describe(InputImage at data)
   print(Incoming)
   Outgoing = describe(SamplingResultsSPDF at data)  
   print(Outgoing)
   browser() 
#   
   dev.set(1) # plot in new window
   grob <- spplot(OutSpatialGridSGDF, "band1", col.regions=greys,cuts=length(greys))
   plot(grob)   
}


From john.callahan at udel.edu  Tue May 26 20:22:59 2009
From: john.callahan at udel.edu (John Callahan)
Date: Tue, 26 May 2009 14:22:59 -0400
Subject: [R-sig-Geo] contour data
Message-ID: <4A1C3383.9020401@udel.edu>

I have a DEM (2 meter spacing, IMG file format) and I'd like to create 
contour vector data output, shapefiles would be great.  I just 
downloaded R 2.9.0.  Looking for more info, I keep finding references to 
the contour function in the grahics package, but that seems like it only 
produces plots instead of output vectors. 

I know the sp and spatstat packages are good for various types of 
geospatial analysis.  Is one of these 'the next generation' of the 
other?  Would you recommend one or the other specifically for contour 
generation from a DEM?   (My platform is Windows.)  Thanks.

- John


PS - At first pass, I'm going to give gdal_contour 
(http://www.gdal.org/gdal_contour.html) a try.  I'd really like to see 
how this compares with some method within R.

I'm also looking at SAGA for the R interface options.  I just installed 
the most recent QGIS with the ManageR plugin to see what tools that 
brings in.  And GRASS is always an option (either through QGIS or 
standalone) but I don't quite understand how mapsets work yet. 

**************************************************
John Callahan
Geospatial Application Developer
Delaware Geological Survey, University of Delaware
227 Academy St, Newark DE 19716-7501
Tel: (302) 831-3584  
Email: john.callahan at udel.edu
http://www.dgs.udel.edu


From Roger.Bivand at nhh.no  Tue May 26 20:41:23 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 26 May 2009 20:41:23 +0200 (CEST)
Subject: [R-sig-Geo] SP Spatial List operation - error in R 2.9 not in R
 2.8 (download example)
In-Reply-To: <4A1C1F84.7090005@nceas.ucsb.edu>
References: <4A1C1F84.7090005@nceas.ucsb.edu>
Message-ID: <alpine.LRH.2.00.0905262022590.5415@reclus.nhh.no>

On Tue, 26 May 2009, rick reeves wrote:

> Hello List:
>
> While writing an R script to display and subsample a raster image,
> I encountered an error in the Spatial_.xxxx classes that occurs in
> R ver 2.9, but not in R ver 2.8.

Thanks for a fully documented case. The key NEWS item in R 2.9.0 here is 
probably:

     o	Ambiguities in class inheritance and method selection resulting
 	from duplicates in superclasses are now resolved by requiring
 	(if possible) consistency with all the superclass inheritance. The
 	rules for method selection have been revised to take advantage of
 	the improved ordering.
 	See ?Methods and the reference there related to inheritance.

It is possible that your coding is sensitive to this, in that coercion 
(as()) is a method, and before 2.9.0 as(SamplingGrid, "SpatialPoints") did 
a silent coercion to SpatialPixels first, which was strictly not needed - 
a SpatialGrid does only have two points. I suggest that you remove:

    OutSpatialGridSGDF <- as(SamplingGrid, "SpatialGridDataFrame")

which creates an object that is defective (in 2.9.0 anyway), change

    SamplingPoints <- as(SamplingGrid,"SpatialPoints")

to

    SamplingPoints <- as(as(SamplingGrid, "SpatialPixels"),
        "SpatialPoints")

then just go for:

    SamplingResultsSPDF <- overlay(InputImage,SamplingPoints)
    gridded(SamplingResultsSPDF) <- TRUE

and just use that. Personally, I would avoid the @ operator for accessing 
slots, I never use it except deep in functions and very seldom then, it is 
much tidier to use accessor functions, which will then call validators to 
make sure the object didn't get perverted in some way.

So my diagnosis would be that you were relying on an ambiguity in the 
selection of methods by classes, and when the ambiguity was removed by 
changes to the methods package, it showed up the vulnerability in your 
code.

Does that seem reasonable?

Roger

>
> Note: I installed both versions within the last 5 days, and ran
> the update.packages() command after each installation.
>
> Please download the script (and a small sample image .tif file) at:
>
>  http://www.nceas.ucsb.edu/scicomp/SpSamplingGridQuest.zip
>
> (complete script replicated at bottom of this message)
>
> Here is the problem:
>
> I developed this script using R 2.8, and the results were as expected:
> A subsampled image. But when I ran the script under R 2.9.0, the
> subsampled image is 'empty'. Checking the data objects, the first
> statement to exhibit a problem is:
>
> SamplingPoints <- as(SamplingGrid,"SpatialPoints")
>
> For statement: < str(SamplingPoints) >
>
> R version 2.8.1 produces this result:
>
> Formal class 'SpatialPoints' [package "sp"] with 3 slots
> ..@ coords     : num [1:24021, 1:2] -1759592 -1758712 -1757832 -1756952 
> -1756072 ...
> .. ..- attr(*, "dimnames")=List of 2
> .. .. ..$ : NULL
> .. .. ..$ : chr [1:2] "x" "y"
> ..@ bbox       : num [1:2, 1:2] -1760032 5929 -1621872 140569
> .. ..- attr(*, "dimnames")=List of 2
> .. .. ..$ : chr [1:2] "x" "y"
> .. .. ..$ : chr [1:2] "min" "max"
> ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
> .. .. ..@ projargs: chr NA
>
> But R version 2.9 produces this (incorrect) result. Compare the @coords slot
> produced by each version:
>
> Formal class 'SpatialPoints' [package "sp"] with 3 slots
> ..@ coords     : num [1:2, 1:2] -1759592 -1622312 6369 140129
> .. ..- attr(*, "dimnames")=List of 2
> .. .. ..$ : NULL
> .. .. ..$ : chr [1:2] "x" "y"
> ..@ bbox       : num [1:2, 1:2] -1760032 5929 -1621872 140569
> .. ..- attr(*, "dimnames")=List of 2
> .. .. ..$ : chr [1:2] "x" "y"
> .. .. ..$ : chr [1:2] "min" "max"
> ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
> .. .. ..@ projargs: chr NA
> Warning message:
> In data.row.names(row.names, rowsi, i) :
> some row.names duplicated: 
> 2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,
> 43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,.........
>
> Have I made a coding mistake? Has anyone encountered a similar problem? Is 
> there a fix underway?
>
> Thanks for any information -
>
> Rick R
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Tue May 26 21:04:24 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 26 May 2009 21:04:24 +0200 (CEST)
Subject: [R-sig-Geo] contour data
In-Reply-To: <4A1C3383.9020401@udel.edu>
References: <4A1C3383.9020401@udel.edu>
Message-ID: <alpine.LRH.2.00.0905262041560.5415@reclus.nhh.no>

On Tue, 26 May 2009, John Callahan wrote:

> I have a DEM (2 meter spacing, IMG file format) and I'd like to create 
> contour vector data output, shapefiles would be great.  I just downloaded R 
> 2.9.0.  Looking for more info, I keep finding references to the contour 
> function in the grahics package, but that seems like it only produces plots 
> instead of output vectors. 
> I know the sp and spatstat packages are good for various types of geospatial 
> analysis.  Is one of these 'the next generation' of the other?  Would you 
> recommend one or the other specifically for contour generation from a DEM? 
> (My platform is Windows.)  Thanks.

Just roughly:

download.file("http://geomorphometry.org/data/DEM25m.zip",
   destfile="DEM25m.zip")
fname <- zip.file.extract(file="DEM25m.asc", zipname="DEM25m.zip")
file.copy(fname, "DEM25m.asc")
# to give some data to play with
library(rgdal)
dem <- readGDAL("DEM25m.asc")
# GDAL has many formats, IMG isn't very descriptive, try and see which 
# driver suits for reading to a SpatialGridDataFrame - I'm assuming one
# band only, using the first and only band next
im <- as.image.SpatialGridDataFrame(dem)
cl <- contourLines(im)
# contourLines() takes the same interval arguments as contour()
library(maptools)
SLDF <- ContourLines2SLDF(cl)
# convert to a SpatialLinesDataFrame with the contour labels as 
# attributes and export
writeOGR(SLDF, ".", "my_contours", driver="ESRI Shapefile")
mc <- readOGR(".", "my_contours")
summary(dem)
summary(mc)
image(dem, col=gray.colors(20))
plot(mc, col=terrain.colors(8), add=TRUE)

The colours in the last line are rather sleight of hand, but for 
demonstration they work this time.

Hope this helps,

Roger

>
> - John
>
>
> PS - At first pass, I'm going to give gdal_contour 
> (http://www.gdal.org/gdal_contour.html) a try.  I'd really like to see how 
> this compares with some method within R.
>
> I'm also looking at SAGA for the R interface options.  I just installed the 
> most recent QGIS with the ManageR plugin to see what tools that brings in. 
> And GRASS is always an option (either through QGIS or standalone) but I don't 
> quite understand how mapsets work yet. 
> **************************************************
> John Callahan
> Geospatial Application Developer
> Delaware Geological Survey, University of Delaware
> 227 Academy St, Newark DE 19716-7501
> Tel: (302) 831-3584  Email: john.callahan at udel.edu
> http://www.dgs.udel.edu
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From stefan.duke at gmail.com  Wed May 27 12:08:18 2009
From: stefan.duke at gmail.com (stefan.duke at gmail.com)
Date: Wed, 27 May 2009 12:08:18 +0200
Subject: [R-sig-Geo] ESRI Shapefile for EU-25 NUTS-1 and NUTS-2
Message-ID: <a211af3b0905270308w2774f7d4w8715c8dd01b659e8@mail.gmail.com>

Dear All,

I am looking for *.shp files for the whole EU covering NUTS-1 and
NUTS-2 level. There have been older posts about that, but these links
are already outdated. I assume that those files should  be available
at the Eurostat homepage. But I have rarely seen such an intelligible
web site (I even failed to register as a user to get access to the
support section).

I assume that such files should be easily and freely available. If I
am wrong, please correct me. If I am right, please send me a link.

Thanks for any suggestions!
Best,
Stefan


From annafreni at yahoo.it  Wed May 27 13:13:38 2009
From: annafreni at yahoo.it (anna freni sterrantino)
Date: Wed, 27 May 2009 11:13:38 +0000 (GMT)
Subject: [R-sig-Geo] nb object  for spatial weigths
Message-ID: <951219.87525.qm@web24102.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090527/59145c7c/attachment.pl>

From Roger.Bivand at nhh.no  Wed May 27 13:22:03 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 27 May 2009 13:22:03 +0200 (CEST)
Subject: [R-sig-Geo] ESRI Shapefile for EU-25 NUTS-1 and NUTS-2
In-Reply-To: <a211af3b0905270308w2774f7d4w8715c8dd01b659e8@mail.gmail.com>
References: <a211af3b0905270308w2774f7d4w8715c8dd01b659e8@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0905271312050.10191@reclus.nhh.no>

On Wed, 27 May 2009, stefan.duke at gmail.com wrote:

> Dear All,
>
> I am looking for *.shp files for the whole EU covering NUTS-1 and
> NUTS-2 level. There have been older posts about that, but these links
> are already outdated. I assume that those files should  be available
> at the Eurostat homepage. But I have rarely seen such an intelligible
> web site (I even failed to register as a user to get access to the
> support section).

Something like:

http://epp.eurostat.ec.europa.eu/portal/page/portal/region_cities/introduction

-> See also (upper right) GISCO

-> Geodata (left navbar) -> Reference

-> click on Administrative units/Statistical units top left in main pane

or directly:

http://epp.eurostat.ec.europa.eu/portal/page/portal/gisco/popups/references/Administrative units and Statistical units1

though you are right, it isn't easy to find. The 2003 offerings are only 
in personal geodatabase format, the 2006 in both shapefile and personal 
geodatabase format.

>
> I assume that such files should be easily and freely available. If I
> am wrong, please correct me. If I am right, please send me a link.

You are wrong, but the link is there. Note the conditions. There is a 
loooooong running campaign to convince European public mapping agencies to 
free their data, with little effect so far. Nationally, the statistics 
agencies are better at releasing boundary files than the mapping agencies. 
Your assumption is rational, but things take time.

Hope this helps,

Roger

>
> Thanks for any suggestions!
> Best,
> Stefan
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Wed May 27 13:31:48 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 27 May 2009 13:31:48 +0200 (CEST)
Subject: [R-sig-Geo] nb object  for spatial weigths
In-Reply-To: <951219.87525.qm@web24102.mail.ird.yahoo.com>
References: <951219.87525.qm@web24102.mail.ird.yahoo.com>
Message-ID: <alpine.LRH.2.00.0905271322520.10191@reclus.nhh.no>

On Wed, 27 May 2009, anna freni sterrantino wrote:

> Hi everyone,
> I'm a total newbie in geo, so sorry if my question is basic.
>
> Following chp 9 and chp 10  from "Applied Spatial Data Analysis with R",
> I 've got confused on how to get  from coordinates to a nb-object,
> to get to spatial weights need for modeling.
> Seems that the example at pag.245 :
>
> coords<- coordinates(Syracuse)
> IDs <- row.names(as(Syracuse, "data.frame"))
> library(tripack)
> Sy4_nb<- tri2nb(coords, row.names=IDs)
> Sy5_nb<- graph2nb(soi.graph(Sy4_nb, coords), row.names=IDs)
> Sy6_nb<- graph2nb(gabrielneigh(coords), row.names=IDs)
> Sy7_nb<- graph2nb(relativeneigh(coords), row.names=IDs)
>
> in not working anymore, due to the fact that  tri2nd has
> been deprecated; so I tried instead

I don't think that anything has happened to tri2nb(), which lives in 
spdep. If spdep wasn't loaded, you wouldn't find tri2nb() - was that the 
problem? The book code is run nightly on current R and the contributed 
packages, so I'd have expected to see any deviant behaviour already.

Roger

>
>
> tritest.tr <- tri.mesh(mydata$x,mydata$y)
> tritest.nb<- neighbours(tritest.tr)
> class(tritest.nb)
> [1] "list"
>
> how can I get tritest.tr to a nb object?
> Or there is another way ?
>
> Do I need necessarily a gal file? as I've seen in the examples.
> Thanks
>
> Anna
>
>
>
>
> >sessionInfo()
> R version 2.9.0 Patched (2009-05-03 r48460)
> i686-pc-linux-gnu
>
> locale:
> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] tripack_1.2-11  nlme_3.1-91     MASS_7.2-47     xtable_1.5-5
> [5] lattice_0.17-25 sp_0.9-36       sqldf_0-1.4     gsubfn_0.3-8
> [9]  proto_0.3-8     RSQLite_0.7-1   DBI_0.2-4       foreign_0.8-35
>
> loaded via a namespace (and not attached):
> [1] grid_2.9.0  tcltk_2.9.0 tools_2.9.0
>
>
>
>
> Anna Freni Sterrantino
> Ph.D Student
> Department of Statistics
> University of Bologna, Italy
> via Belle Arti 41, 40124 BO.
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From john.callahan at udel.edu  Wed May 27 15:34:40 2009
From: john.callahan at udel.edu (John Callahan)
Date: Wed, 27 May 2009 09:34:40 -0400
Subject: [R-sig-Geo] contour data
In-Reply-To: <alpine.LRH.2.00.0905262041560.5415@reclus.nhh.no>
References: <4A1C3383.9020401@udel.edu>
	<alpine.LRH.2.00.0905262041560.5415@reclus.nhh.no>
Message-ID: <4A1D4170.6040700@udel.edu>

Thank you!  You should remove the term "roughly" as it worked exactly as 
is.  All I needed to do is change the input file name.   The below ran 
perfectly, displaying the DEM and contours on a plot (bottom five lines) 
with output shapefiles of the vectors (the writeOGR command.)

library(rgdal)
dem <- readGDAL("C:\\data\\State2m\\dem1717.asc")
im <- as.image.SpatialGridDataFrame(dem)
cl <- contourLines(im,20)
library(maptools)
SLDF <- ContourLines2SLDF(cl)
writeOGR(SLDF, ".", "dem1717", driver="ESRI Shapefile")
mc <- readOGR(".", "dem1717")
summary(dem)
summary(mc)
image(dem, col=gray.colors(20))
plot(mc, col=terrain.colors(8), add=TRUE)


I used gdal_translate to easily extract my area of interest as an ASCII 
grid file and then ran your script.  Perfect.  I'm now looking at the 
parameters of contour/contourLines to create different levels of 
contours (like 2 foot or 5 meter.)   Thanks again!

- John



Roger Bivand wrote:
> On Tue, 26 May 2009, John Callahan wrote:
>
>> I have a DEM (2 meter spacing, IMG file format) and I'd like to 
>> create contour vector data output, shapefiles would be great.  I just 
>> downloaded R 2.9.0.  Looking for more info, I keep finding references 
>> to the contour function in the grahics package, but that seems like 
>> it only produces plots instead of output vectors. I know the sp and 
>> spatstat packages are good for various types of geospatial analysis.  
>> Is one of these 'the next generation' of the other?  Would you 
>> recommend one or the other specifically for contour generation from a 
>> DEM? (My platform is Windows.)  Thanks.
>
> Just roughly:
>
> download.file("http://geomorphometry.org/data/DEM25m.zip",
>   destfile="DEM25m.zip")
> fname <- zip.file.extract(file="DEM25m.asc", zipname="DEM25m.zip")
> file.copy(fname, "DEM25m.asc")
> # to give some data to play with
> library(rgdal)
> dem <- readGDAL("DEM25m.asc")
> # GDAL has many formats, IMG isn't very descriptive, try and see which 
> # driver suits for reading to a SpatialGridDataFrame - I'm assuming one
> # band only, using the first and only band next
> im <- as.image.SpatialGridDataFrame(dem)
> cl <- contourLines(im)
> # contourLines() takes the same interval arguments as contour()
> library(maptools)
> SLDF <- ContourLines2SLDF(cl)
> # convert to a SpatialLinesDataFrame with the contour labels as # 
> attributes and export
> writeOGR(SLDF, ".", "my_contours", driver="ESRI Shapefile")
> mc <- readOGR(".", "my_contours")
> summary(dem)
> summary(mc)
> image(dem, col=gray.colors(20))
> plot(mc, col=terrain.colors(8), add=TRUE)
>
> The colours in the last line are rather sleight of hand, but for 
> demonstration they work this time.
>
> Hope this helps,
>
> Roger
>
>>
>> - John
>>
>>
>> PS - At first pass, I'm going to give gdal_contour 
>> (http://www.gdal.org/gdal_contour.html) a try.  I'd really like to 
>> see how this compares with some method within R.
>>
>> I'm also looking at SAGA for the R interface options.  I just 
>> installed the most recent QGIS with the ManageR plugin to see what 
>> tools that brings in. And GRASS is always an option (either through 
>> QGIS or standalone) but I don't quite understand how mapsets work 
>> yet. **************************************************
>> John Callahan
>> Geospatial Application Developer
>> Delaware Geological Survey, University of Delaware
>> 227 Academy St, Newark DE 19716-7501
>> Tel: (302) 831-3584  Email: john.callahan at udel.edu
>> http://www.dgs.udel.edu
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From ba208 at exeter.ac.uk  Wed May 27 18:14:26 2009
From: ba208 at exeter.ac.uk (baptiste auguie)
Date: Wed, 27 May 2009 18:14:26 +0200
Subject: [R-sig-Geo] How to negate %in%
In-Reply-To: <4A1ADFD4.800@earthlink.net>
References: <4A1ADFD4.800@earthlink.net>
Message-ID: <1DDAFB67-9DC0-4206-8F5F-ED0B5E11CACE@exeter.ac.uk>

I like to use this one (albeit probably not the most efficient),

`%ni%` <- Negate(`%in%`)

baptiste

On 25 May 2009, at 20:13, Jim Burke wrote:

> I can subset a "SpatialPolygonsDataFrame" from a
> data frame containing a smaller subset of IDs. For
> example below.
>
> smaller_sp <- large_sp [large_sp$ID %in% smaller_df$ID,]
>
> Given the above how can I do the logically opposite from
> the %in% operation and get all those IDs not %in%?
>
> I am processing two different sets of polygons (A,B) in
> a loop. Operation is seeing in center points in polys B
> fall in A. I would like to remove the spatial polygons
> that I found (B) as I traverse the geographical area.
>
> Thanks,
> Jim Burke
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Greg.Snow at imail.org  Wed May 27 19:45:36 2009
From: Greg.Snow at imail.org (Greg Snow)
Date: Wed, 27 May 2009 11:45:36 -0600
Subject: [R-sig-Geo] ESRI Shapefile for EU-25 NUTS-1 and NUTS-2
In-Reply-To: <alpine.LRH.2.00.0905271312050.10191@reclus.nhh.no>
References: <a211af3b0905270308w2774f7d4w8715c8dd01b659e8@mail.gmail.com>
	<alpine.LRH.2.00.0905271312050.10191@reclus.nhh.no>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61D1FC1020@LP-EXMBVS10.CO.IHC.COM>

This site:

http://www.cloudmade.com/

has shape files based on the open street map project (http://www.openstreetmap.org/).

I don't know if the maps have the correct level of detail that the original poster wanted, but they are licensed under a creative commons license.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-
> bounces at stat.math.ethz.ch] On Behalf Of Roger Bivand
> Sent: Wednesday, May 27, 2009 5:22 AM
> To: stefan.duke at gmail.com
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] ESRI Shapefile for EU-25 NUTS-1 and NUTS-2
> 
> On Wed, 27 May 2009, stefan.duke at gmail.com wrote:
> 
> > Dear All,
> >
> > I am looking for *.shp files for the whole EU covering NUTS-1 and
> > NUTS-2 level. There have been older posts about that, but these links
> > are already outdated. I assume that those files should  be available
> > at the Eurostat homepage. But I have rarely seen such an intelligible
> > web site (I even failed to register as a user to get access to the
> > support section).
> 
> Something like:
> 
> http://epp.eurostat.ec.europa.eu/portal/page/portal/region_cities/intro
> duction
> 
> -> See also (upper right) GISCO
> 
> -> Geodata (left navbar) -> Reference
> 
> -> click on Administrative units/Statistical units top left in main
> pane
> 
> or directly:
> 
> http://epp.eurostat.ec.europa.eu/portal/page/portal/gisco/popups/refere
> nces/Administrative units and Statistical units1
> 
> though you are right, it isn't easy to find. The 2003 offerings are
> only
> in personal geodatabase format, the 2006 in both shapefile and personal
> geodatabase format.
> 
> >
> > I assume that such files should be easily and freely available. If I
> > am wrong, please correct me. If I am right, please send me a link.
> 
> You are wrong, but the link is there. Note the conditions. There is a
> loooooong running campaign to convince European public mapping agencies
> to
> free their data, with little effect so far. Nationally, the statistics
> agencies are better at releasing boundary files than the mapping
> agencies.
> Your assumption is rational, but things take time.
> 
> Hope this helps,
> 
> Roger
> 
> >
> > Thanks for any suggestions!
> > Best,
> > Stefan
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> 
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School
> of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From stefan.duke at gmail.com  Wed May 27 22:37:34 2009
From: stefan.duke at gmail.com (stefan.duke at gmail.com)
Date: Wed, 27 May 2009 22:37:34 +0200
Subject: [R-sig-Geo] ESRI Shapefile for EU-25 NUTS-1 and NUTS-2
In-Reply-To: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61D1FC1020@LP-EXMBVS10.CO.IHC.COM>
References: <a211af3b0905270308w2774f7d4w8715c8dd01b659e8@mail.gmail.com>
	<alpine.LRH.2.00.0905271312050.10191@reclus.nhh.no>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61D1FC1020@LP-EXMBVS10.CO.IHC.COM>
Message-ID: <a211af3b0905271337r7566ab24o4981a498a8e37079@mail.gmail.com>

Thanks a lot! That is very helpful!

BTW is there something I could do to support the campaign (e.g.write
an email to my MP)?


On Wed, May 27, 2009 at 7:45 PM, Greg Snow <Greg.Snow at imail.org> wrote:
> This site:
>
> http://www.cloudmade.com/
>
> has shape files based on the open street map project (http://www.openstreetmap.org/).
>
> I don't know if the maps have the correct level of detail that the original poster wanted, but they are licensed under a creative commons license.
>
> Hope this helps,
>
> --
> Gregory (Greg) L. Snow Ph.D.
> Statistical Data Center
> Intermountain Healthcare
> greg.snow at imail.org
> 801.408.8111
>
>
>> -----Original Message-----
>> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-
>> bounces at stat.math.ethz.ch] On Behalf Of Roger Bivand
>> Sent: Wednesday, May 27, 2009 5:22 AM
>> To: stefan.duke at gmail.com
>> Cc: r-sig-geo at stat.math.ethz.ch
>> Subject: Re: [R-sig-Geo] ESRI Shapefile for EU-25 NUTS-1 and NUTS-2
>>
>> On Wed, 27 May 2009, stefan.duke at gmail.com wrote:
>>
>> > Dear All,
>> >
>> > I am looking for *.shp files for the whole EU covering NUTS-1 and
>> > NUTS-2 level. There have been older posts about that, but these links
>> > are already outdated. I assume that those files should ?be available
>> > at the Eurostat homepage. But I have rarely seen such an intelligible
>> > web site (I even failed to register as a user to get access to the
>> > support section).
>>
>> Something like:
>>
>> http://epp.eurostat.ec.europa.eu/portal/page/portal/region_cities/intro
>> duction
>>
>> -> See also (upper right) GISCO
>>
>> -> Geodata (left navbar) -> Reference
>>
>> -> click on Administrative units/Statistical units top left in main
>> pane
>>
>> or directly:
>>
>> http://epp.eurostat.ec.europa.eu/portal/page/portal/gisco/popups/refere
>> nces/Administrative units and Statistical units1
>>
>> though you are right, it isn't easy to find. The 2003 offerings are
>> only
>> in personal geodatabase format, the 2006 in both shapefile and personal
>> geodatabase format.
>>
>> >
>> > I assume that such files should be easily and freely available. If I
>> > am wrong, please correct me. If I am right, please send me a link.
>>
>> You are wrong, but the link is there. Note the conditions. There is a
>> loooooong running campaign to convince European public mapping agencies
>> to
>> free their data, with little effect so far. Nationally, the statistics
>> agencies are better at releasing boundary files than the mapping
>> agencies.
>> Your assumption is rational, but things take time.
>>
>> Hope this helps,
>>
>> Roger
>>
>> >
>> > Thanks for any suggestions!
>> > Best,
>> > Stefan
>> >
>> > _______________________________________________
>> > R-sig-Geo mailing list
>> > R-sig-Geo at stat.math.ethz.ch
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School
>> of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From tsippel at gmail.com  Thu May 28 06:37:00 2009
From: tsippel at gmail.com (Tim Sippel)
Date: Thu, 28 May 2009 16:37:00 +1200
Subject: [R-sig-Geo] Problem with rand.kselect(adehabitat)
Message-ID: <79a13c220905272137k44ccc325q5f49fcfe8b45a8f4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090528/e1c70cb7/attachment.pl>

From tsippel at gmail.com  Thu May 28 06:40:36 2009
From: tsippel at gmail.com (Tim Sippel)
Date: Thu, 28 May 2009 16:40:36 +1200
Subject: [R-sig-Geo] Problem with rand.kselect(adehabitat)
In-Reply-To: <79a13c220905272137k44ccc325q5f49fcfe8b45a8f4@mail.gmail.com>
References: <79a13c220905272137k44ccc325q5f49fcfe8b45a8f4@mail.gmail.com>
Message-ID: <79a13c220905272140q47f89faahab1a2c700b599498@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090528/e1702164/attachment.pl>

From a.ghisla at studenti.uninsubria.it  Thu May 28 10:21:57 2009
From: a.ghisla at studenti.uninsubria.it (Anne Ghisla Insubriae)
Date: Thu, 28 May 2009 10:21:57 +0200
Subject: [R-sig-Geo] [Soc] GRASS module for kriging - call for users
 [was: R-sig-Geo Digest, Vol 69, Issue 21]
In-Reply-To: <3c5546140905231207n539eb305w1fffd83ceaca7b2a@mail.gmail.com>
References: <mailman.13.1242986402.30725.r-sig-geo@stat.math.ethz.ch>	
	<b0a6ce470905222031w4010f1feo1970e8bab178bae6@mail.gmail.com>	
	<4A183995.7060606@studenti.uninsubria.it>
	<3c5546140905231207n539eb305w1fffd83ceaca7b2a@mail.gmail.com>
Message-ID: <4A1E49A5.8010803@studenti.uninsubria.it>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Dylan Beaudette ha scritto:
[snip]
> Hi. It is alway nice to see people working GRASS SoC projects, thank you!
> 
> I would just add-- I think that all efforts to build onto existing
> libraries would be a good thing. That is to say, try and work with
> GRASS-R-gstat: this is by far one of the best implementations of
> geostatistics available. Paul's automap would be another likely
> candidate .

Hi Dylan, and sorry for late response,

there are two packages that provide kriging in R, and the discussion in
this thread leads to use one of them to avoid the differences in results
coming from implementation differences. On your advice I'll choose gstat
and automap, even if geoR looked very complete.
Maybe I could offer the user the choice bteween the two packages, in a
2.x release of the plugin. This could allow R users keep using their
preferred algorithms, what do you think?

> The real problem with a single GRASS module for 'kriging' is that the
> operation requires careful thought and familiarity with the data-- not
> really something that can be easily generalized to the conceptual
> basis of a single GRASS module. Perhaps asking Edzer about room for
> user-interface improvements in the gstat code would yield some good
> starting points.

Good - I'll ask him soon.

> Cheers,
> Dylan

cheers,
Anne

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.9 (MingW32)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org

iEYEARECAAYFAkoeSaQACgkQrgxAvFOwDdiYdQCeKVwmLg3D1DW4WTHAfficfN4b
7wcAn34f0lTzGrgstcWMJX5VqsKUh2ec
=NmbT
-----END PGP SIGNATURE-----


From giohappy at gmail.com  Thu May 28 12:13:34 2009
From: giohappy at gmail.com (G. Allegri)
Date: Thu, 28 May 2009 12:13:34 +0200
Subject: [R-sig-Geo] [Soc] GRASS module for kriging - call for users
	[was: R-sig-Geo Digest, Vol 69, Issue 21]
In-Reply-To: <4A1E49A5.8010803@studenti.uninsubria.it>
References: <mailman.13.1242986402.30725.r-sig-geo@stat.math.ethz.ch>
	<b0a6ce470905222031w4010f1feo1970e8bab178bae6@mail.gmail.com>
	<4A183995.7060606@studenti.uninsubria.it>
	<3c5546140905231207n539eb305w1fffd83ceaca7b2a@mail.gmail.com>
	<4A1E49A5.8010803@studenti.uninsubria.it>
Message-ID: <e12429640905280313r254be926xbe79d4acefd4cd5b@mail.gmail.com>

My two cents.
Some of the best interface features I've found in Isatis, one of the
best commercial geostatistical sw I've used, are:

 - interaction with the variogram map to select direction and plot the
ESPs together differentiating the various selected dirs with colors.
It permits to reveal anisitropies structures with a glance.
 - interaction with the variogram model (plotted with the ESP) to fit
it by hand. In practice you can change the model parameters (sill,
nugget, range) by clicking on the plot handles.
 - let the user select pairs from the variogram cloud and visualize
them on the map. It permits, for example, to see where high variances
pairs (linked with a line) are located.

Another useful feature is the visualization of the anisotropy
parameters on the variogram map (the cone). And, last, the possibility
to define visually the neighborhood as circle/ellipse.

Ok, lots of wishes, and I don't know how hard it would be to develop
them. I've just written them to share...

bye,
giovanni


http://www.geovariances.com/software/video-data-investigation-with-isatis-exploratory-data-analysis-ar0353.html

2009/5/28 Anne Ghisla Insubriae <a.ghisla at studenti.uninsubria.it>:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Dylan Beaudette ha scritto:
> [snip]
>> Hi. It is alway nice to see people working GRASS SoC projects, thank you!
>>
>> I would just add-- I think that all efforts to build onto existing
>> libraries would be a good thing. That is to say, try and work with
>> GRASS-R-gstat: this is by far one of the best implementations of
>> geostatistics available. Paul's automap would be another likely
>> candidate .
>
> Hi Dylan, and sorry for late response,
>
> there are two packages that provide kriging in R, and the discussion in
> this thread leads to use one of them to avoid the differences in results
> coming from implementation differences. On your advice I'll choose gstat
> and automap, even if geoR looked very complete.
> Maybe I could offer the user the choice bteween the two packages, in a
> 2.x release of the plugin. This could allow R users keep using their
> preferred algorithms, what do you think?
>
>> The real problem with a single GRASS module for 'kriging' is that the
>> operation requires careful thought and familiarity with the data-- not
>> really something that can be easily generalized to the conceptual
>> basis of a single GRASS module. Perhaps asking Edzer about room for
>> user-interface improvements in the gstat code would yield some good
>> starting points.
>
> Good - I'll ask him soon.
>
>> Cheers,
>> Dylan
>
> cheers,
> Anne
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.9 (MingW32)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org
>
> iEYEARECAAYFAkoeSaQACgkQrgxAvFOwDdiYdQCeKVwmLg3D1DW4WTHAfficfN4b
> 7wcAn34f0lTzGrgstcWMJX5VqsKUh2ec
> =NmbT
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From bal22 at sussex.ac.uk  Thu May 28 12:38:17 2009
From: bal22 at sussex.ac.uk (Benjamin Laken)
Date: Thu, 28 May 2009 11:38:17 +0100
Subject: [R-sig-Geo] How to overlay dahed contours on to filled contours?
Message-ID: <4A1E6999.8020202@sussex.ac.uk>

Hi everyone,
I have two seperate netcdf files with 2D data (of dims 72x7), and I need 
one to be a standard filled contour, however I need the other to be 
overlaid on top of the initial filled contour as contour lines.
Any ideas on how I can do this?
(Or at least how I can make a plot with the contours as lines so i can 
cheat and overlay them in adobe illustrator?)

Thanks
--Ben


From dylan.beaudette at gmail.com  Thu May 28 16:30:39 2009
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Thu, 28 May 2009 07:30:39 -0700
Subject: [R-sig-Geo] [Soc] GRASS module for kriging - call for users
	[was: R-sig-Geo Digest, Vol 69, Issue 21]
In-Reply-To: <4A1E49A5.8010803@studenti.uninsubria.it>
References: <mailman.13.1242986402.30725.r-sig-geo@stat.math.ethz.ch>
	<b0a6ce470905222031w4010f1feo1970e8bab178bae6@mail.gmail.com>
	<4A183995.7060606@studenti.uninsubria.it>
	<3c5546140905231207n539eb305w1fffd83ceaca7b2a@mail.gmail.com>
	<4A1E49A5.8010803@studenti.uninsubria.it>
Message-ID: <3c5546140905280730y75a616d8wc4b2a06992f520ef@mail.gmail.com>

On Thu, May 28, 2009 at 1:21 AM, Anne Ghisla Insubriae
<a.ghisla at studenti.uninsubria.it> wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Dylan Beaudette ha scritto:
> [snip]
>> Hi. It is alway nice to see people working GRASS SoC projects, thank you!
>>
>> I would just add-- I think that all efforts to build onto existing
>> libraries would be a good thing. That is to say, try and work with
>> GRASS-R-gstat: this is by far one of the best implementations of
>> geostatistics available. Paul's automap would be another likely
>> candidate .
>
> Hi Dylan, and sorry for late response,
>
> there are two packages that provide kriging in R, and the discussion in
> this thread leads to use one of them to avoid the differences in results
> coming from implementation differences. On your advice I'll choose gstat
> and automap, even if geoR looked very complete.
> Maybe I could offer the user the choice bteween the two packages, in a
> 2.x release of the plugin. This could allow R users keep using their
> preferred algorithms, what do you think?

Hi. Thank you for considering my suggestion, but note that I am by no
means an authority on the implementation of geostatistical routines. I
wouldn't want to upset the author of geoR over my personal
preferences. That said, I have found the features, ease of use, and
support for gstat ideal. Giving users a choice is always a good
thing-- I think that there will be many happy users if both
implementations are available.

>
>> The real problem with a single GRASS module for 'kriging' is that the
>> operation requires careful thought and familiarity with the data-- not
>> really something that can be easily generalized to the conceptual
>> basis of a single GRASS module. Perhaps asking Edzer about room for
>> user-interface improvements in the gstat code would yield some good
>> starting points.
>
> Good - I'll ask him soon.

Great. The points brought up down-thread by G. Allegri (although
partially implemented in gstat) would be a good starting point for
development of interactive variogram analysis.

Cheers,
Dylan


> cheers,
> Anne
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.9 (MingW32)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org
>
> iEYEARECAAYFAkoeSaQACgkQrgxAvFOwDdiYdQCeKVwmLg3D1DW4WTHAfficfN4b
> 7wcAn34f0lTzGrgstcWMJX5VqsKUh2ec
> =NmbT
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From BRWIN338 at aol.com  Thu May 28 18:43:21 2009
From: BRWIN338 at aol.com (BRWIN338 at aol.com)
Date: Thu, 28 May 2009 12:43:21 EDT
Subject: [R-sig-Geo] Problems loading hydrosanity package
Message-ID: <ce1.4c535888.37501929@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090528/11c1c389/attachment.pl>

From Roger.Bivand at nhh.no  Thu May 28 19:14:51 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 28 May 2009 19:14:51 +0200 (CEST)
Subject: [R-sig-Geo] Problems loading hydrosanity package
In-Reply-To: <ce1.4c535888.37501929@aol.com>
References: <ce1.4c535888.37501929@aol.com>
Message-ID: <alpine.LRH.2.00.0905281905310.3858@reclus.nhh.no>

On Thu, 28 May 2009, BRWIN338 at aol.com wrote:

> Good Morning:
>
> I need to construct a set of Thiessen Polygons centered around 
> approximately 4500 longlat positions in the US.  After searching the R 
> site, I was going to attempt to use the arealsubPolygons function in the 
> hydrosanity package.  I am using a Windows system.
>
> When attempting to call the package I get the following error messages
> under both R2.8.1 and R2.9.0.
> ##################################################################
>> require(hydrosanity)
> Loading required package:  hydrosanity
> Loading required package: playwith
> Loading required package:  lattice
> Loading required package: cairoDevice
> Error in inDL(x,  as.logical(local), as.logical(now), ...) :
> unable to load shared  library
> 'C:/PROGRA~1/R/R-28~1.1/library/cairoDevice/libs/cairoDevice.dll':
> LoadLibrary failure:  The specified module could not be found.
>
>
> Error: package 'cairoDevice' could not be  loaded
> ###################################################################
> I have tried downloading the package and it's dependencies from  several
> locations and get the same errors each time.
>
> Any suggestions with respect to this package or others that I might  use to
> construct my polygons would be appreciated.  I need a set  of polygons that
> cover the entire US county polygon.

The package description does say that it is "under development and should 
not be considered stable", seems honest. Look at the code in its URL:

http://code.google.com/p/hydrosanity/source/browse/trunk/R/spatial_functions.R

find the function and its dependencies, load sp first, and probably a 
matrix of boundary coordinates for a representation that has a coercion 
method to gpc.poly, your point matrix, a vector of IDs, and source the 
function locally. That avoids resolving all the dependencies needed for 
the GUI in the package, and ought to work. Watch the min.area.pct= 
argument as small polygons may go away.

Should work with some tweaking.

Roger

>
> Joe
> **************Cooking Dinner For Two? Sign Up & Get Immediate Member-Only
> Savings.
> (http://pr.atwola.com/promoclk/100126575x1222652750x1201460983/aol?redir=http:%2F%2Fad.doubleclick.net%2Fclk%3B215225797%3B37274671%3Bq%3Fhttp:%2
> F%2Frecipes.cookingfor2.pillsbury.com%2F%3FESRC%3D934)
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From felix at nfrac.org  Fri May 29 01:43:14 2009
From: felix at nfrac.org (Felix Andrews)
Date: Fri, 29 May 2009 09:43:14 +1000
Subject: [R-sig-Geo] Problems loading hydrosanity package
In-Reply-To: <alpine.LRH.2.00.0905281905310.3858@reclus.nhh.no>
References: <ce1.4c535888.37501929@aol.com>
	<alpine.LRH.2.00.0905281905310.3858@reclus.nhh.no>
Message-ID: <94730b8a0905281643l134512bbn9d731d80585ead16@mail.gmail.com>

2009/5/29 Roger Bivand <Roger.Bivand at nhh.no>:
> On Thu, 28 May 2009, BRWIN338 at aol.com wrote:
>
>> Good Morning:
>>
>> I need to construct a set of Thiessen Polygons centered around
>> approximately 4500 longlat positions in the US.  After searching the R site,
>> I was going to attempt to use the arealsubPolygons function in the
>> hydrosanity package.  I am using a Windows system.
>>
>> When attempting to call the package I get the following error messages
>> under both R2.8.1 and R2.9.0.
>> ##################################################################
>>>
>>> require(hydrosanity)
>>
>> Loading required package:  hydrosanity
>> Loading required package: playwith
>> Loading required package:  lattice
>> Loading required package: cairoDevice
>> Error in inDL(x,  as.logical(local), as.logical(now), ...) :
>> unable to load shared  library
>> 'C:/PROGRA~1/R/R-28~1.1/library/cairoDevice/libs/cairoDevice.dll':
>> LoadLibrary failure:  The specified module could not be found.
>>
>>
>> Error: package 'cairoDevice' could not be  loaded
>> ###################################################################
>> I have tried downloading the package and it's dependencies from  several
>> locations and get the same errors each time.
>>
>> Any suggestions with respect to this package or others that I might  use
>> to
>> construct my polygons would be appreciated.  I need a set  of polygons
>> that
>> cover the entire US county polygon.
>
> The package description does say that it is "under development and should
> not be considered stable", seems honest. Look at the code in its URL:
>
> http://code.google.com/p/hydrosanity/source/browse/trunk/R/spatial_functions.R
>
> find the function and its dependencies, load sp first, and probably a matrix
> of boundary coordinates for a representation that has a coercion method to
> gpc.poly, your point matrix, a vector of IDs, and source the function
> locally. That avoids resolving all the dependencies needed for the GUI in
> the package, and ought to work. Watch the min.area.pct= argument as small
> polygons may go away.
>
> Should work with some tweaking.

I tried

library(sp)
library(tripack)
library(gpclib)
foo <- arealSubPolygons(state.center, IDs = state.name)
class(foo)
[1] "SpatialPolygons"

But I can't seem to plot the result...
spplot(foo)
Error in function (classes, fdef, mtable)  :
  unable to find an inherited method for function "spplot", for
signature "SpatialPolygons"

Note also that you can construct Thiessen / Voronoi Polygons for
plotting with the tileplot function in latticeExtra:

library(latticeExtra)
tileplot(x ~ x * y, state.center, border = "black", points=FALSE)

See the code for panel.voronoi for how it is done
(it has two implementations, based on either tripack or deldir).


Hope that helps
-Felix


-- 
Felix Andrews / ???
Post-Doctoral Fellow
Integrated Catchment Assessment and Management (iCAM) Centre
Fenner School of Environment and Society [Bldg 48a]
The Australian National University
Canberra ACT 0200 Australia
M: +61 410 400 963
T: + 61 2 6125 1670
E: felix.andrews at anu.edu.au
CRICOS Provider No. 00120C
-- 
http://www.neurofractal.org/felix/


From Roger.Bivand at nhh.no  Fri May 29 10:11:55 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 29 May 2009 10:11:55 +0200 (CEST)
Subject: [R-sig-Geo] Problems loading hydrosanity package
In-Reply-To: <94730b8a0905281643l134512bbn9d731d80585ead16@mail.gmail.com>
References: <ce1.4c535888.37501929@aol.com>
	<alpine.LRH.2.00.0905281905310.3858@reclus.nhh.no>
	<94730b8a0905281643l134512bbn9d731d80585ead16@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0905291002170.6510@reclus.nhh.no>

On Fri, 29 May 2009, Felix Andrews wrote:

> 2009/5/29 Roger Bivand <Roger.Bivand at nhh.no>:
>> On Thu, 28 May 2009, BRWIN338 at aol.com wrote:
>>
>>> Good Morning:
>>>
>>> I need to construct a set of Thiessen Polygons centered around
>>> approximately 4500 longlat positions in the US.  After searching the R site,
>>> I was going to attempt to use the arealsubPolygons function in the
>>> hydrosanity package.  I am using a Windows system.
>>>
>>> When attempting to call the package I get the following error messages
>>> under both R2.8.1 and R2.9.0.
>>> ##################################################################
>>>>
>>>> require(hydrosanity)
>>>
>>> Loading required package:  hydrosanity
>>> Loading required package: playwith
>>> Loading required package:  lattice
>>> Loading required package: cairoDevice
>>> Error in inDL(x,  as.logical(local), as.logical(now), ...) :
>>> unable to load shared  library
>>> 'C:/PROGRA~1/R/R-28~1.1/library/cairoDevice/libs/cairoDevice.dll':
>>> LoadLibrary failure:  The specified module could not be found.
>>>
>>>
>>> Error: package 'cairoDevice' could not be  loaded
>>> ###################################################################
>>> I have tried downloading the package and it's dependencies from  several
>>> locations and get the same errors each time.
>>>
>>> Any suggestions with respect to this package or others that I might  use
>>> to
>>> construct my polygons would be appreciated.  I need a set  of polygons
>>> that
>>> cover the entire US county polygon.
>>
>> The package description does say that it is "under development and should
>> not be considered stable", seems honest. Look at the code in its URL:
>>
>> http://code.google.com/p/hydrosanity/source/browse/trunk/R/spatial_functions.R
>>
>> find the function and its dependencies, load sp first, and probably a matrix
>> of boundary coordinates for a representation that has a coercion method to
>> gpc.poly, your point matrix, a vector of IDs, and source the function
>> locally. That avoids resolving all the dependencies needed for the GUI in
>> the package, and ought to work. Watch the min.area.pct= argument as small
>> polygons may go away.
>>
>> Should work with some tweaking.
>
> I tried
>
> library(sp)
> library(tripack)
> library(gpclib)
> foo <- arealSubPolygons(state.center, IDs = state.name)
> class(foo)
> [1] "SpatialPolygons"
>
> But I can't seem to plot the result...
> spplot(foo)
> Error in function (classes, fdef, mtable)  :
>  unable to find an inherited method for function "spplot", for
> signature "SpatialPolygons"

Well, there isn't a method, because they only exist for Spatial*DataFrame 
objects for obvious reasons. Just use base graphics plot() methods for the 
Spatial* classes. I guess that the boundary argument is usually a matrix - 
does it have to be a single ring, or can it be several rings?

By the way, was there an explanation for the failed cairoDevice 
dependency? Keeping control of dependencies like those in this package is 
seriously challenging.

Roger

>
> Note also that you can construct Thiessen / Voronoi Polygons for
> plotting with the tileplot function in latticeExtra:
>
> library(latticeExtra)
> tileplot(x ~ x * y, state.center, border = "black", points=FALSE)
>
> See the code for panel.voronoi for how it is done
> (it has two implementations, based on either tripack or deldir).
>
>
> Hope that helps
> -Felix
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From edzer.pebesma at uni-muenster.de  Fri May 29 11:36:08 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 29 May 2009 11:36:08 +0200
Subject: [R-sig-Geo] using gwr for interpolation
Message-ID: <4A1FAC88.5070608@uni-muenster.de>

Can I use gwr for interpolation?

I would for example use something like

library(spgwr)
data(meuse)
coordinates(meuse) = ~x+y
data(meuse.grid)
gridded(meuse.grid) = ~x+y
x = gwr(cadmium ~ dist, meuse, bandwidth = 228, fit.points = meuse.grid)
spplot(x$SDF["gwr.e"])

But it doesn't give what I'd expected - somehow nicely interpolated
cadmium values. I probably misused fit.points, but I couldn't see any
predict method. Is this possible at all?

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From torleif.lunde at cih.uib.no  Fri May 29 13:15:01 2009
From: torleif.lunde at cih.uib.no (Torleif Markussen Lunde)
Date: Fri, 29 May 2009 13:15:01 +0200
Subject: [R-sig-Geo] using gwr for interpolation
In-Reply-To: <4A1FAC88.5070608@uni-muenster.de>
References: <4A1FAC88.5070608@uni-muenster.de>
Message-ID: <200905291315.01700.torleif.lunde@cih.uib.no>

Hi

I think the error is in .GWR_int line 42:
df[i, (m + 3)] <- ei[i]

ei will have length equal to dim(data)[1], while i is equal to 
nrow(fit.points). So as i > dim(data)[1] ei[i] will be NA. 

This could explain why only the first 155 points are evaluated (in your 
example).

Best wishes
Torleif

On Friday 29 May 2009 11:36:08 am Edzer Pebesma wrote:
> Can I use gwr for interpolation?
>
> I would for example use something like
>
> library(spgwr)
> data(meuse)
> coordinates(meuse) = ~x+y
> data(meuse.grid)
> gridded(meuse.grid) = ~x+y
> x = gwr(cadmium ~ dist, meuse, bandwidth = 228, fit.points = meuse.grid)
> spplot(x$SDF["gwr.e"])
>
> But it doesn't give what I'd expected - somehow nicely interpolated
> cadmium values. I probably misused fit.points, but I couldn't see any
> predict method. Is this possible at all?


From Roger.Bivand at nhh.no  Fri May 29 13:24:27 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 29 May 2009 13:24:27 +0200 (CEST)
Subject: [R-sig-Geo] using gwr for interpolation
In-Reply-To: <4A1FAC88.5070608@uni-muenster.de>
References: <4A1FAC88.5070608@uni-muenster.de>
Message-ID: <alpine.LRH.2.00.0905291315560.7802@reclus.nhh.no>

On Fri, 29 May 2009, Edzer Pebesma wrote:

> Can I use gwr for interpolation?
>
> I would for example use something like
>
> library(spgwr)
> data(meuse)
> coordinates(meuse) = ~x+y
> data(meuse.grid)
> gridded(meuse.grid) = ~x+y
> x = gwr(cadmium ~ dist, meuse, bandwidth = 228, fit.points = meuse.grid)
> spplot(x$SDF["gwr.e"])

Since GWR was created to look at *coefficient* variability, prediction 
isn't a natural, and fit.points are assumed just to be points, not points 
with attributes; there is nothing in Forthingham et al. (2002) about 
prediction. So:

spplot(x$SDF, "dist")

>
> But it doesn't give what I'd expected - somehow nicely interpolated
> cadmium values. I probably misused fit.points, but I couldn't see any
> predict method. Is this possible at all?
>

fortune("Yoda")
gwrcoefs <- as.matrix(as(x$SDF, "data.frame")[,2:3])
X <- model.matrix( ~ dist, meuse.grid)
meuse.grid$pred <- apply(gwrcoefs * X, 1, sum)
spplot(meuse.grid, "pred")

It could be written into gwr(), or as a predict() method, but that might 
require changes in the gwr object to make sure that the predicted 
attribute values were properly keyed to the fit point locations. To get 
standard errors, you'd need to store more of the objects returned by 
lm.wfit() for each fit point, which could be done, but should it?

Hope this helps,

Roger
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Fri May 29 13:34:03 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 29 May 2009 13:34:03 +0200 (CEST)
Subject: [R-sig-Geo] using gwr for interpolation
In-Reply-To: <200905291315.01700.torleif.lunde@cih.uib.no>
References: <4A1FAC88.5070608@uni-muenster.de>
	<200905291315.01700.torleif.lunde@cih.uib.no>
Message-ID: <alpine.LRH.2.00.0905291332430.7802@reclus.nhh.no>

On Fri, 29 May 2009, Torleif Markussen Lunde wrote:

> Hi
>
> I think the error is in .GWR_int line 42:
> df[i, (m + 3)] <- ei[i]
>
> ei will have length equal to dim(data)[1], while i is equal to
> nrow(fit.points). So as i > dim(data)[1] ei[i] will be NA.
>
> This could explain why only the first 155 points are evaluated (in your
> example).

Right, thanks. Residuals are only defined when the fit points are the same 
as the data points - when fit points are given, NA should be returned.

Roger

>
> Best wishes
> Torleif
>
> On Friday 29 May 2009 11:36:08 am Edzer Pebesma wrote:
>> Can I use gwr for interpolation?
>>
>> I would for example use something like
>>
>> library(spgwr)
>> data(meuse)
>> coordinates(meuse) = ~x+y
>> data(meuse.grid)
>> gridded(meuse.grid) = ~x+y
>> x = gwr(cadmium ~ dist, meuse, bandwidth = 228, fit.points = meuse.grid)
>> spplot(x$SDF["gwr.e"])
>>
>> But it doesn't give what I'd expected - somehow nicely interpolated
>> cadmium values. I probably misused fit.points, but I couldn't see any
>> predict method. Is this possible at all?
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From adriantoti at gmail.com  Fri May 29 20:27:56 2009
From: adriantoti at gmail.com (Adrian Toti)
Date: Fri, 29 May 2009 14:27:56 -0400
Subject: [R-sig-Geo] Spatial regression
Message-ID: <d8e1ff280905291127g2d4a13f6ie985782faa13f659@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090529/5c1b2874/attachment.pl>

From debeaudette at ucdavis.edu  Fri May 29 23:26:56 2009
From: debeaudette at ucdavis.edu (Dylan Beaudette)
Date: Fri, 29 May 2009 14:26:56 -0700
Subject: [R-sig-Geo] spgrass6 and R 2.9
Message-ID: <200905291426.56291.dylan.beaudette@gmail.com>

Hi,

Just upgraded to R 2.9.0 this morning, and tried to update all of my packages. 
Everyhing seemed to work, except spgrass6. Manually removing the old packing 
and installing fresh resulted in:

install.packages('spgrass6', dep=TRUE)
trying URL 'http://cran.cnr.Berkeley.edu/src/contrib/spgrass6_0.6-6.tar.gz'
Content type 'application/x-gzip' length 332298 bytes (324 Kb)
opened URL
==================================================
downloaded 324 Kb

* Installing *source* package 'spgrass6' ...
** R
** inst
** preparing package for lazy loading
Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 1.7.0dev, released 2008/11/26
Path to GDAL shared files: /usr/local/share/gdal
Loaded PROJ.4 runtime: Rel. 4.6.0, 21 Dec 2007
Path to PROJ.4 shared files: (autodetected)
** help
*** installing help indices
 >>> Building/Updating help pages for package 'spgrass6'
     Formats: text html latex example 
  execGRASS                         text    html    latex   example
  gmeta6                            text    html    latex   example
  initGRASS                         text    html    latex   example
  readRAST6                         text    html    latex   example
  readVECT6                         text    html    latex   example
  spgrass6                          text    html    latex   example
** building package indices ...
* DONE (spgrass6)
*** glibc detected *** /usr/local/lib/R/bin/exec/R: double free or corruption 
(fasttop): 0x096ac2b0 ***


At this point R stops responding, and I have to issue a `kill -9` to make 
regain control of the shell.

Any ideas?

Dylan

-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341


From torleif.lunde at cih.uib.no  Sat May 30 00:02:22 2009
From: torleif.lunde at cih.uib.no (Torleif Markussen Lunde)
Date: Sat, 30 May 2009 00:02:22 +0200
Subject: [R-sig-Geo] spgrass6 and R 2.9
In-Reply-To: <200905291426.56291.dylan.beaudette@gmail.com>
References: <200905291426.56291.dylan.beaudette@gmail.com>
Message-ID: <200905300002.23063.torleif.lunde@cih.uib.no>

Hi

First try updating glibc, and install spgrass6 again. If this does not work 
you could try 

export MALLOC_CHECK_=0

before you start R. The error might be related to "somewhere something" is 
trying to free memory that has already been unallocated. I don't know the 
details here, but it could be worth a try?

Best wishes 
Torleif


On Friday 29 May 2009 11:26:56 pm Dylan Beaudette wrote:
> Hi,
>
> Just upgraded to R 2.9.0 this morning, and tried to update all of my
> packages. Everyhing seemed to work, except spgrass6. Manually removing the
> old packing and installing fresh resulted in:
>
> install.packages('spgrass6', dep=TRUE)
> trying URL 'http://cran.cnr.Berkeley.edu/src/contrib/spgrass6_0.6-6.tar.gz'
> Content type 'application/x-gzip' length 332298 bytes (324 Kb)
> opened URL
> ==================================================
> downloaded 324 Kb
>
> * Installing *source* package 'spgrass6' ...
> ** R
> ** inst
> ** preparing package for lazy loading
> Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 1.7.0dev, released 2008/11/26
> Path to GDAL shared files: /usr/local/share/gdal
> Loaded PROJ.4 runtime: Rel. 4.6.0, 21 Dec 2007
> Path to PROJ.4 shared files: (autodetected)
> ** help
> *** installing help indices
>
>  >>> Building/Updating help pages for package 'spgrass6'
>
>      Formats: text html latex example
>   execGRASS                         text    html    latex   example
>   gmeta6                            text    html    latex   example
>   initGRASS                         text    html    latex   example
>   readRAST6                         text    html    latex   example
>   readVECT6                         text    html    latex   example
>   spgrass6                          text    html    latex   example
> ** building package indices ...
> * DONE (spgrass6)
> *** glibc detected *** /usr/local/lib/R/bin/exec/R: double free or
> corruption (fasttop): 0x096ac2b0 ***
>
>
> At this point R stops responding, and I have to issue a `kill -9` to make
> regain control of the shell.
>
> Any ideas?
>
> Dylan


From felix at nfrac.org  Sat May 30 10:33:00 2009
From: felix at nfrac.org (Felix Andrews)
Date: Sat, 30 May 2009 18:33:00 +1000
Subject: [R-sig-Geo] Problems loading hydrosanity package
In-Reply-To: <alpine.LRH.2.00.0905291002170.6510@reclus.nhh.no>
References: <ce1.4c535888.37501929@aol.com>
	<alpine.LRH.2.00.0905281905310.3858@reclus.nhh.no> 
	<94730b8a0905281643l134512bbn9d731d80585ead16@mail.gmail.com> 
	<alpine.LRH.2.00.0905291002170.6510@reclus.nhh.no>
Message-ID: <94730b8a0905300133g1b89df33n67954c8b91c03c48@mail.gmail.com>

2009/5/29 Roger Bivand <Roger.Bivand at nhh.no>:
> On Fri, 29 May 2009, Felix Andrews wrote:
>
>> 2009/5/29 Roger Bivand <Roger.Bivand at nhh.no>:
>>>
>>> On Thu, 28 May 2009, BRWIN338 at aol.com wrote:
>>>
>>>> Good Morning:
>>>>
>>>> I need to construct a set of Thiessen Polygons centered around
>>>> approximately 4500 longlat positions in the US.  After searching the R
>>>> site,
>>>> I was going to attempt to use the arealsubPolygons function in the
>>>> hydrosanity package.  I am using a Windows system.
>>>>
>>>> When attempting to call the package I get the following error messages
>>>> under both R2.8.1 and R2.9.0.
>>>> ##################################################################
>>>>>
>>>>> require(hydrosanity)
>>>>
>>>> Loading required package:  hydrosanity
>>>> Loading required package: playwith
>>>> Loading required package:  lattice
>>>> Loading required package: cairoDevice
>>>> Error in inDL(x,  as.logical(local), as.logical(now), ...) :
>>>> unable to load shared  library
>>>> 'C:/PROGRA~1/R/R-28~1.1/library/cairoDevice/libs/cairoDevice.dll':
>>>> LoadLibrary failure:  The specified module could not be found.
>>>>
>>>>
>>>> Error: package 'cairoDevice' could not be  loaded
>>>> ###################################################################
>>>> I have tried downloading the package and it's dependencies from  several
>>>> locations and get the same errors each time.
>>>>
>>>> Any suggestions with respect to this package or others that I might  use
>>>> to
>>>> construct my polygons would be appreciated.  I need a set  of polygons
>>>> that
>>>> cover the entire US county polygon.
>>>
>>> The package description does say that it is "under development and should
>>> not be considered stable", seems honest. Look at the code in its URL:
>>>
>>>
>>> http://code.google.com/p/hydrosanity/source/browse/trunk/R/spatial_functions.R
>>>
>>> find the function and its dependencies, load sp first, and probably a
>>> matrix
>>> of boundary coordinates for a representation that has a coercion method
>>> to
>>> gpc.poly, your point matrix, a vector of IDs, and source the function
>>> locally. That avoids resolving all the dependencies needed for the GUI in
>>> the package, and ought to work. Watch the min.area.pct= argument as small
>>> polygons may go away.
>>>
>>> Should work with some tweaking.
>>
>> I tried
>>
>> library(sp)
>> library(tripack)
>> library(gpclib)

Sorry, I forgot the crucial step of sourcing the function -- as an
alternative to installing the whole package, with its dependencies on
RGtk2 etc --:
source("http://hydrosanity.googlecode.com/svn/trunk/R/spatial_functions.R")

>> foo <- arealSubPolygons(state.center, IDs = state.name)
>> class(foo)
>> [1] "SpatialPolygons"

ok, try

with(state.center, {
  plot(foo, xlim=range(x), ylim = range(y))
  text(x, y, state.abb) })

>>
>> But I can't seem to plot the result...
>> spplot(foo)
>> Error in function (classes, fdef, mtable)  :
>>  unable to find an inherited method for function "spplot", for
>> signature "SpatialPolygons"
>
> Well, there isn't a method, because they only exist for Spatial*DataFrame
> objects for obvious reasons. Just use base graphics plot() methods for the
> Spatial* classes.

Those reasons are not obvious to me: I prefer to use Lattice graphics
rather than base graphics, even if I do not need to use conditioning.
The Lattice system is object-based and very flexible; e.g. one can
concatenate or overlay Lattice plot panels using the tools in the
latticeExtra package.

>  I guess that the boundary argument is usually a matrix -
> does it have to be a single ring, or can it be several rings?

Yes, you can use a matrix like
boundary = coordinates(myPolygon)  (from an sp Polygon class)
But in theory you can supply anything that can be converted with
as(boundary, "gpc.poly")
It should be possible to specify multiple polygons that way; check the
gpclib package.

>
> By the way, was there an explanation for the failed cairoDevice dependency?
> Keeping control of dependencies like those in this package is seriously
> challenging.

Yes, the error message indicated that the cairoDevice DLL was missing.
The most likely cause of that is that the GTK+ libraries have not been
installed. Installation instructions are available at
http://hydrosanity.googlecode.com/

The comment about the package being unstable/incomplete is certainly
true, and it has not been actively maintained for the last year or so.

>
> Roger
>
>>
>> Note also that you can construct Thiessen / Voronoi Polygons for
>> plotting with the tileplot function in latticeExtra:
>>
>> library(latticeExtra)
>> tileplot(x ~ x * y, state.center, border = "black", points=FALSE)
>>
>> See the code for panel.voronoi for how it is done
>> (it has two implementations, based on either tripack or deldir).
>>
>>
>> Hope that helps
>> -Felix
>>
>>
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>



-- 
Felix Andrews / ???
Post-Doctoral Fellow
Integrated Catchment Assessment and Management (iCAM) Centre
Fenner School of Environment and Society [Bldg 48a]
The Australian National University
Canberra ACT 0200 Australia
M: +61 410 400 963
T: + 61 2 6125 1670
E: felix.andrews at anu.edu.au
CRICOS Provider No. 00120C
-- 
http://www.neurofractal.org/felix/


