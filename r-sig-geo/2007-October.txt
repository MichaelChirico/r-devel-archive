From felix at nfrac.org  Mon Oct  1 07:46:03 2007
From: felix at nfrac.org (Felix Andrews)
Date: Mon, 1 Oct 2007 15:46:03 +1000
Subject: [R-sig-Geo] Plotting point labels along with points using
	spplot sp.layout list
In-Reply-To: <1458.71.102.146.37.1191097723.squirrel@webmail.nceas.ucsb.edu>
References: <1458.71.102.146.37.1191097723.squirrel@webmail.nceas.ucsb.edu>
Message-ID: <94730b8a0709302246y5db5b7bfv75154575b31b68f0@mail.gmail.com>

On 9/30/07, reeves at nceas.ucsb.edu <reeves at nceas.ucsb.edu> wrote:
> # Assume: ss[] is a char vector of point labels, one per Centroid element..
> # display list entries for first two points
> #
> pt1 = list("sp.text",c(LatLongs[1,1],LatLongs[1,2]),ss[1],col="white",pos=2)
> pt2 = list("sp.text",c(LatLongs[2,1],LatLongs[2,2]),ss[2],col="white",pos=2)
> #
> # I could create these for all 'n' list elements I suppose, but then the
> code is not general.

Look at sp.text, it is nothing but a constrained version of panel.text:

> sp.text
function (loc, txt, ...)
{
    if (length(loc) != 2)
        stop("loc should have length 2")
    if (!is.numeric(loc))
        stop("loc should be numeric")
    panel.text(loc[1], loc[2], txt, ...)
}
<environment: namespace:sp>

So you can just do this:
ptLabels <- list("panel.text", LatLongs[,1], LatLongs[,2], labels=ss,
col="white", pos=2)

You might also be interested in maptools::pointLabel to place the
labels so they don't overlap.

Felix


On 9/30/07, reeves at nceas.ucsb.edu <reeves at nceas.ucsb.edu> wrote:
> Hello:
>
> Im working on a method to create multilayer raster/vector plots using
> spplot() and supporting functions. The question is: how do I efficiently
> add display list instructions for plotting the point labels that works
> for different sized point vectors?
>
> Here is a working 'brute force' approach (I have omitted the string parsing
> code that produces the point labels) that creates the plot and labels the
> first two points only:
>
> library(sp)
> library(rgdal)
> library(maptools)
> #
> # read files
> #
> Counties  <- readShapePoly("PugetSoundCountiesClp2.shp")
> psImg     <- readGDAL("PugetSoundSub1.img")
> Centroids <- readShapePoints("PSCentroidPointShape")
>
> len = length(Centroids at coords)
> LatLongs = Centroids at coords
> dim(LatLongs) = c(len/2,2)
> #
> # spplot 'sp.layout' list entries (demote polygons to spatial lines).
> #
> points <- list("sp.points", Centroids,  pch = 21,col="green")
> Counties_lines <- as(Counties, "SpatialLines")
> polys <- list("sp.lines", Counties_lines, col="white")
> greys <- grey(0:256 / 256)
> #
> # Assume: ss[] is a char vector of point labels, one per Centroid element..
> # display list entries for first two points
> #
> pt1 = list("sp.text",c(LatLongs[1,1],LatLongs[1,2]),ss[1],col="white",pos=2)
> pt2 = list("sp.text",c(LatLongs[2,1],LatLongs[2,2]),ss[2],col="white",pos=2)
> #
> # I could create these for all 'n' list elements I suppose, but then the
> code is not general.
> #
> grob2 = spplot(psImg, "band1", col.regions=greys,
> sp.layout=list(points,pl1,pl2,polys),cuts=length(greys),
> colorkey=FALSE,scales=list(draw=TRUE))
> #
> plot(grob2)
>
> Something tells me Im doing this the hard way...
> I could construct the arguments to list() dynamically with string building
> code, and then call() or eval() the command, but isnt there a much simpler
> way to 1) tell sp.layout to add the point labels or 2) add the labels to
> the
> plot in a separate command? I have tried separate text() and
> update(trellis.last.object()) commands to no avail.
>
> Suggestions?
>
> Regards, Rick Reeves / NCEAS
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


-- 
Felix Andrews / ???
PhD candidate
Integrated Catchment Assessment and Management Centre
The Fenner School of Environment and Society
The Australian National University (Building 48A), ACT 0200
Beijing Bag, Locked Bag 40, Kingston ACT 2604
http://www.neurofractal.org/felix/
3358 543D AAC6 22C2 D336  80D9 360B 72DD 3E4C F5D8



From hi_ono2001 at yahoo.co.jp  Mon Oct  1 12:28:44 2007
From: hi_ono2001 at yahoo.co.jp (Hisaji ONO)
Date: Mon, 1 Oct 2007 19:28:44 +0900 (JST)
Subject: [R-sig-Geo] Barry Rowlingson's "Arlat" on FOSS4G 2007
Message-ID: <20071001102844.42991.qmail@web10709.mail.bbt.yahoo.co.jp>

Hello.

 Last week, I participated in FOSS4G
2007(http://www.foss4g2007.org) held in Victoria, British
Columbia, Canada.

 In this conference's program ,  Barry Rowlingson
presented "Delivering Tropical Medicine Solutions with
Integrated Open Source GIS and Statistics." 
 This presentation was about integrated system called
"Arlat" using Quantum GIS for desktop mapping and R for
the statistics engine connected by
Python(http://www.foss4g2007.org/presentations/view.php?abstract_id=135).
 
 Unfortunately, I participated in another presentation and
missed this one.

 I've developed SDAM(Spatial Data Analysis Machine) using
R, R(D)COM and GeoTools. So I've been very interested in
"Arlat."


 Does anyone has more information about this "Arlat."



Regards.



From v.gomezrubio at imperial.ac.uk  Mon Oct  1 13:32:08 2007
From: v.gomezrubio at imperial.ac.uk (Virgilio Gomez-Rubio)
Date: Mon, 01 Oct 2007 12:32:08 +0100
Subject: [R-sig-Geo] Barry Rowlingson's "Arlat" on FOSS4G 2007
In-Reply-To: <20071001102844.42991.qmail@web10709.mail.bbt.yahoo.co.jp>
References: <20071001102844.42991.qmail@web10709.mail.bbt.yahoo.co.jp>
Message-ID: <1191238328.703.19.camel@fh-vrubio>

Dear Hisaji,

I found this technical report which may be of your interest:

http://www.bepress.com/cgi/viewcontent.cgi?article=1103&context=jhubiostat

It describes the methodological methods and the implementation. There
are some screen shots as well.

Is anyone else doing similar stuff? I mean, developing a GIS for Spatial
Epidemiology. I am very interested in the subject and I would like to
know what is going on out there.

Hisaji, could you send more information about your SDAM?

Best,

Virgilio



On Mon, 2007-10-01 at 19:28 +0900, Hisaji ONO wrote:
> Hello.
> 
>  Last week, I participated in FOSS4G
> 2007(http://www.foss4g2007.org) held in Victoria, British
> Columbia, Canada.
> 
>  In this conference's program ,  Barry Rowlingson
> presented "Delivering Tropical Medicine Solutions with
> Integrated Open Source GIS and Statistics." 
>  This presentation was about integrated system called
> "Arlat" using Quantum GIS for desktop mapping and R for
> the statistics engine connected by
> Python(http://www.foss4g2007.org/presentations/view.php?abstract_id=135).
>  
>  Unfortunately, I participated in another presentation and
> missed this one.
> 
>  I've developed SDAM(Spatial Data Analysis Machine) using
> R, R(D)COM and GeoTools. So I've been very interested in
> "Arlat."
> 
> 
>  Does anyone has more information about this "Arlat."
> 
> 
> 
> Regards.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From borghor at yahoo.ca  Mon Oct  1 16:52:35 2007
From: borghor at yahoo.ca (bertrand toupin)
Date: Mon, 1 Oct 2007 10:52:35 -0400 (EDT)
Subject: [R-sig-Geo] Signification of variance and error in "krige" and
	"krige.cv"
In-Reply-To: <Pine.LNX.4.64.0709041407360.29743@reclus.nhh.no>
Message-ID: <183378.96160.qm@web52909.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071001/a39c92c0/attachment.pl>

From colinr23 at gmail.com  Mon Oct  1 17:17:38 2007
From: colinr23 at gmail.com (colin)
Date: Mon, 01 Oct 2007 08:17:38 -0700
Subject: [R-sig-Geo] Barry Rowlingson's "Arlat" on FOSS4G 2007
In-Reply-To: <1191238328.703.19.camel@fh-vrubio>
References: <20071001102844.42991.qmail@web10709.mail.bbt.yahoo.co.jp>
	<1191238328.703.19.camel@fh-vrubio>
Message-ID: <1191251858.15197.10.camel@rick>

Hi all, I'm also very interested in GIS for spatial epidemiology.  I
attended Dr Rowlingson's talk and was really impressed with the use of
QGIS as a client for developing add-ons in addition to its integration
with R! 

I too am interested in any additional info and examples on this topic...

Regards,

Colin

On Mon, 2007-01-10 at 12:32 +0100, Virgilio Gomez-Rubio wrote:
> Dear Hisaji,
> 
> I found this technical report which may be of your interest:
> 
> http://www.bepress.com/cgi/viewcontent.cgi?article=1103&context=jhubiostat
> 
> It describes the methodological methods and the implementation. There
> are some screen shots as well.
> 
> Is anyone else doing similar stuff? I mean, developing a GIS for Spatial
> Epidemiology. I am very interested in the subject and I would like to
> know what is going on out there.
> 
> Hisaji, could you send more information about your SDAM?
> 
> Best,
> 
> Virgilio
> 
> 
> 
> On Mon, 2007-10-01 at 19:28 +0900, Hisaji ONO wrote:
> > Hello.
> > 
> >  Last week, I participated in FOSS4G
> > 2007(http://www.foss4g2007.org) held in Victoria, British
> > Columbia, Canada.
> > 
> >  In this conference's program ,  Barry Rowlingson
> > presented "Delivering Tropical Medicine Solutions with
> > Integrated Open Source GIS and Statistics." 
> >  This presentation was about integrated system called
> > "Arlat" using Quantum GIS for desktop mapping and R for
> > the statistics engine connected by
> > Python(http://www.foss4g2007.org/presentations/view.php?abstract_id=135).
> >  
> >  Unfortunately, I participated in another presentation and
> > missed this one.
> > 
> >  I've developed SDAM(Spatial Data Analysis Machine) using
> > R, R(D)COM and GeoTools. So I've been very interested in
> > "Arlat."
> > 
> > 
> >  Does anyone has more information about this "Arlat."
> > 
> > 
> > 
> > Regards.
> > 
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From Agustin.Lobo at ija.csic.es  Mon Oct  1 17:30:32 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Mon, 01 Oct 2007 17:30:32 +0200
Subject: [R-sig-Geo] Barry Rowlingson's "Arlat" on FOSS4G 2007
In-Reply-To: <1191251858.15197.10.camel@rick>
References: <20071001102844.42991.qmail@web10709.mail.bbt.yahoo.co.jp>	<1191238328.703.19.camel@fh-vrubio>
	<1191251858.15197.10.camel@rick>
Message-ID: <47011298.4060909@ija.csic.es>

Any way of getting the pdf of the talk? I'm interested
both on the epidemiology application and on
the R-QGis integration.

Agus

colin escribi?:
> Hi all, I'm also very interested in GIS for spatial epidemiology.  I
> attended Dr Rowlingson's talk and was really impressed with the use of
> QGIS as a client for developing add-ons in addition to its integration
> with R! 
> 
> I too am interested in any additional info and examples on this topic...
> 
> Regards,
> 
> Colin
> 
> On Mon, 2007-01-10 at 12:32 +0100, Virgilio Gomez-Rubio wrote:
>> Dear Hisaji,
>>
>> I found this technical report which may be of your interest:
>>
>> http://www.bepress.com/cgi/viewcontent.cgi?article=1103&context=jhubiostat
>>
>> It describes the methodological methods and the implementation. There
>> are some screen shots as well.
>>
>> Is anyone else doing similar stuff? I mean, developing a GIS for Spatial
>> Epidemiology. I am very interested in the subject and I would like to
>> know what is going on out there.
>>
>> Hisaji, could you send more information about your SDAM?
>>
>> Best,
>>
>> Virgilio
>>
>>
>>
>> On Mon, 2007-10-01 at 19:28 +0900, Hisaji ONO wrote:
>>> Hello.
>>>
>>>  Last week, I participated in FOSS4G
>>> 2007(http://www.foss4g2007.org) held in Victoria, British
>>> Columbia, Canada.
>>>
>>>  In this conference's program ,  Barry Rowlingson
>>> presented "Delivering Tropical Medicine Solutions with
>>> Integrated Open Source GIS and Statistics." 
>>>  This presentation was about integrated system called
>>> "Arlat" using Quantum GIS for desktop mapping and R for
>>> the statistics engine connected by
>>> Python(http://www.foss4g2007.org/presentations/view.php?abstract_id=135).
>>>  
>>>  Unfortunately, I participated in another presentation and
>>> missed this one.
>>>
>>>  I've developed SDAM(Spatial Data Analysis Machine) using
>>> R, R(D)COM and GeoTools. So I've been very interested in
>>> "Arlat."
>>>
>>>
>>>  Does anyone has more information about this "Arlat."
>>>
>>>
>>>
>>> Regards.
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Agustin.Lobo at ija.csic.es  Mon Oct  1 17:30:50 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Mon, 01 Oct 2007 17:30:50 +0200
Subject: [R-sig-Geo] Barry Rowlingson's "Arlat" on FOSS4G 2007
In-Reply-To: <1191251858.15197.10.camel@rick>
References: <20071001102844.42991.qmail@web10709.mail.bbt.yahoo.co.jp>	<1191238328.703.19.camel@fh-vrubio>
	<1191251858.15197.10.camel@rick>
Message-ID: <470112AA.1060806@ija.csic.es>

Any way of getting the pdf of the talk? I'm interested
both on the epidemiology application and on
the R-QGis integration.

Agus

colin escribi?:
> Hi all, I'm also very interested in GIS for spatial epidemiology.  I
> attended Dr Rowlingson's talk and was really impressed with the use of
> QGIS as a client for developing add-ons in addition to its integration
> with R! 
> 
> I too am interested in any additional info and examples on this topic...
> 
> Regards,
> 
> Colin
> 
> On Mon, 2007-01-10 at 12:32 +0100, Virgilio Gomez-Rubio wrote:
>> Dear Hisaji,
>>
>> I found this technical report which may be of your interest:
>>
>> http://www.bepress.com/cgi/viewcontent.cgi?article=1103&context=jhubiostat
>>
>> It describes the methodological methods and the implementation. There
>> are some screen shots as well.
>>
>> Is anyone else doing similar stuff? I mean, developing a GIS for Spatial
>> Epidemiology. I am very interested in the subject and I would like to
>> know what is going on out there.
>>
>> Hisaji, could you send more information about your SDAM?
>>
>> Best,
>>
>> Virgilio
>>
>>
>>
>> On Mon, 2007-10-01 at 19:28 +0900, Hisaji ONO wrote:
>>> Hello.
>>>
>>>  Last week, I participated in FOSS4G
>>> 2007(http://www.foss4g2007.org) held in Victoria, British
>>> Columbia, Canada.
>>>
>>>  In this conference's program ,  Barry Rowlingson
>>> presented "Delivering Tropical Medicine Solutions with
>>> Integrated Open Source GIS and Statistics." 
>>>  This presentation was about integrated system called
>>> "Arlat" using Quantum GIS for desktop mapping and R for
>>> the statistics engine connected by
>>> Python(http://www.foss4g2007.org/presentations/view.php?abstract_id=135).
>>>  
>>>  Unfortunately, I participated in another presentation and
>>> missed this one.
>>>
>>>  I've developed SDAM(Spatial Data Analysis Machine) using
>>> R, R(D)COM and GeoTools. So I've been very interested in
>>> "Arlat."
>>>
>>>
>>>  Does anyone has more information about this "Arlat."
>>>
>>>
>>>
>>> Regards.
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From reeves at nceas.ucsb.edu  Mon Oct  1 19:09:48 2007
From: reeves at nceas.ucsb.edu (Rick Reeves)
Date: Mon, 01 Oct 2007 10:09:48 -0700
Subject: [R-sig-Geo] Plotting point labels along with points using
 spplot sp.layout list
In-Reply-To: <94730b8a0709302246y5db5b7bfv75154575b31b68f0@mail.gmail.com>
References: <1458.71.102.146.37.1191097723.squirrel@webmail.nceas.ucsb.edu>
	<94730b8a0709302246y5db5b7bfv75154575b31b68f0@mail.gmail.com>
Message-ID: <470129DC.8070003@nceas.ucsb.edu>


Thanks Felix, this is the answer that I was looking for!



points <- list("sp.points", Centroids, pch = 21,col="green")
polys <- list("sp.lines", Counties_lines, col="white")
ptLabels =
list("panel.text",LatLongs[,1],LatLongs[,2],labels=ss,col="white",pos=2)
print("plotting the grob")
browser()
grob2 = spplot(psImg, "band1", col.regions=greys,
sp.layout=list(points,ptLabels,polys),cuts=length(greys),
colorkey=FALSE,scales=list(draw=TRUE))
plot(grob2)

the complete example will soon be posted on my Web site:

http://nceas.ucsb.edu/scicomp/GISSeminar/UseCases/MapProdWithRGraphics/OneMapProdWithRGraphics.html

Regards, Rick R

Felix Andrews wrote:
> On 9/30/07, reeves at nceas.ucsb.edu <reeves at nceas.ucsb.edu> wrote:
>   
>> # Assume: ss[] is a char vector of point labels, one per Centroid element..
>> # display list entries for first two points
>> #
>> pt1 = list("sp.text",c(LatLongs[1,1],LatLongs[1,2]),ss[1],col="white",pos=2)
>> pt2 = list("sp.text",c(LatLongs[2,1],LatLongs[2,2]),ss[2],col="white",pos=2)
>> #
>> # I could create these for all 'n' list elements I suppose, but then the
>> code is not general.
>>     
>
> Look at sp.text, it is nothing but a constrained version of panel.text:
>
>   
>> sp.text
>>     
> function (loc, txt, ...)
> {
>     if (length(loc) != 2)
>         stop("loc should have length 2")
>     if (!is.numeric(loc))
>         stop("loc should be numeric")
>     panel.text(loc[1], loc[2], txt, ...)
> }
> <environment: namespace:sp>
>
> So you can just do this:
> ptLabels <- list("panel.text", LatLongs[,1], LatLongs[,2], labels=ss,
> col="white", pos=2)
>
> You might also be interested in maptools::pointLabel to place the
> labels so they don't overlap.
>
> Felix
>
>
> On 9/30/07, reeves at nceas.ucsb.edu <reeves at nceas.ucsb.edu> wrote:
>   
>> Hello:
>>
>> Im working on a method to create multilayer raster/vector plots using
>> spplot() and supporting functions. The question is: how do I efficiently
>> add display list instructions for plotting the point labels that works
>> for different sized point vectors?
>>
>> Here is a working 'brute force' approach (I have omitted the string parsing
>> code that produces the point labels) that creates the plot and labels the
>> first two points only:
>>
>> library(sp)
>> library(rgdal)
>> library(maptools)
>> #
>> # read files
>> #
>> Counties  <- readShapePoly("PugetSoundCountiesClp2.shp")
>> psImg     <- readGDAL("PugetSoundSub1.img")
>> Centroids <- readShapePoints("PSCentroidPointShape")
>>
>> len = length(Centroids at coords)
>> LatLongs = Centroids at coords
>> dim(LatLongs) = c(len/2,2)
>> #
>> # spplot 'sp.layout' list entries (demote polygons to spatial lines).
>> #
>> points <- list("sp.points", Centroids,  pch = 21,col="green")
>> Counties_lines <- as(Counties, "SpatialLines")
>> polys <- list("sp.lines", Counties_lines, col="white")
>> greys <- grey(0:256 / 256)
>> #
>> # Assume: ss[] is a char vector of point labels, one per Centroid element..
>> # display list entries for first two points
>> #
>> pt1 = list("sp.text",c(LatLongs[1,1],LatLongs[1,2]),ss[1],col="white",pos=2)
>> pt2 = list("sp.text",c(LatLongs[2,1],LatLongs[2,2]),ss[2],col="white",pos=2)
>> #
>> # I could create these for all 'n' list elements I suppose, but then the
>> code is not general.
>> #
>> grob2 = spplot(psImg, "band1", col.regions=greys,
>> sp.layout=list(points,pl1,pl2,polys),cuts=length(greys),
>> colorkey=FALSE,scales=list(draw=TRUE))
>> #
>> plot(grob2)
>>
>> Something tells me Im doing this the hard way...
>> I could construct the arguments to list() dynamically with string building
>> code, and then call() or eval() the command, but isnt there a much simpler
>> way to 1) tell sp.layout to add the point labels or 2) add the labels to
>> the
>> plot in a separate command? I have tried separate text() and
>> update(trellis.last.object()) commands to no avail.
>>
>> Suggestions?
>>
>> Regards, Rick Reeves / NCEAS
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>     
>
>
>   
-------------- next part --------------
A non-text attachment was scrubbed...
Name: reeves.vcf
Type: text/x-vcard
Size: 350 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071001/5877be5f/attachment.vcf>

From scionforbai at gmail.com  Mon Oct  1 19:47:51 2007
From: scionforbai at gmail.com (Scionforbai)
Date: Mon, 1 Oct 2007 19:47:51 +0200
Subject: [R-sig-Geo] Signification of variance and error in "krige" and
	"krige.cv"
In-Reply-To: <183378.96160.qm@web52909.mail.re2.yahoo.com>
References: <Pine.LNX.4.64.0709041407360.29743@reclus.nhh.no>
	<183378.96160.qm@web52909.mail.re2.yahoo.com>
Message-ID: <e9ee1f0a0710011047t1db8d1dcq3ef5ef8ba709dfb1@mail.gmail.com>

> I obtain some interesting results.  For example, the variance from
> "krige" is around 24 and 40 (mm?  same unit as the raw variable?),

If it is a variance, then it is obviously in mm?.

> So, is it normal that the variance is so high?
> Does it mean that the interpolation that I did have a major flaw?

Estimation variance only depends on data points and variogram (or
covariance) model that you have chosen. It is of course 0 in the data
points (check this in particular), increases with the distance from
the nearest data point. Maximum of this estimation error should be
comparable to the population's variance (or the sill of the variogram,
if it has one).

Now: which variogram model did you use? A linear one? Have you got the
same amount of data for the temperature and for the precipitation?
Anyway: such variance is not so big. You should standardize it on the
stdev of your data to convince yourself. The fact that estimation
variance for the temperature is so low, is due to its low variability
(range: 26-29, as I understand from your mail), and *that* is
particular, not the wider range for the estimation variance of
precipitation.
I hope I answered your questions, regards

ScionForbai

From rowlings at fyb028000002.lancs.ac.uk  Tue Oct  2 08:01:16 2007
From: rowlings at fyb028000002.lancs.ac.uk (Barry Rowlingson)
Date: Tue, 2 Oct 2007 07:01:16 +0100
Subject: [R-sig-Geo] Barry Rowlingson's "Arlat" on FOSS4G 2007
In-Reply-To: <20071001102844.42991.qmail@web10709.mail.bbt.yahoo.co.jp>
References: <20071001102844.42991.qmail@web10709.mail.bbt.yahoo.co.jp>
Message-ID: <20071002060116.GB9716@fyb028000002>

>  Does anyone has more information about this "Arlat."

 I'll try and sort this out once I get back from my travels in a week or 
so!

Barry



From bulten at netmarkpatent.com  Thu Oct  4 13:56:45 2007
From: bulten at netmarkpatent.com (NETMARK PATENT)
Date: Thu, 4 Oct 2007 14:56:45 +0300
Subject: [R-sig-Geo] =?windows-1254?q?T=FCrk_Patent_Enstit=FCs=FC_ve_Mo=F0?=
	=?windows-1254?q?olistan_Fikri_M=FClkiyet_Ofisi_Dayan=FD=FEmas=FD?=
Message-ID: <3852-220071044115645288@ugur>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071004/16373b45/attachment.pl>

From patrick.giraudoux at univ-fcomte.fr  Sat Oct  6 10:00:33 2007
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sat, 06 Oct 2007 10:00:33 +0200
Subject: [R-sig-Geo] R-2.6.0 and RWinEdt
Message-ID: <470740A1.2050300@univ-fcomte.fr>

Dear Listers,

I have just installed R-2.6.0 and the RWinEdt package 1.7-6 under 
Windows XP.

The R-WinEdt menu well appears at launching (the command 
library(RWinEdt) is in .Rprofile), but  WinEdt is NOT started 
automatically (this was not the case in the earlier versions of R). When 
WinEdt is started by hand (eg double-click on a RWinEdt alias after R 
launching), syntax highlighting and connexion to R works well.

Any idea about how to fix this and get WinEdt automatically started when 
library(RWinEdt) is called?

Patrick



From patrick.giraudoux at univ-fcomte.fr  Sat Oct  6 10:14:01 2007
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sat, 06 Oct 2007 10:14:01 +0200
Subject: [R-sig-Geo] R-2.6.0 and RWinEdt
Message-ID: <470743C9.7030000@univ-fcomte.fr>

Sorry and aoplogize for this message which was not intended to this list 
but to R-help... Please don't take it into account.




Dear Listers,

I have just installed R-2.6.0 and the RWinEdt package 1.7-6 under
Windows XP.

The R-WinEdt menu well appears at launching (the command
library(RWinEdt) is in .Rprofile), but  WinEdt is NOT started
automatically (this was not the case in the earlier versions of R). When
WinEdt is started by hand (eg double-click on a RWinEdt alias after R
launching), syntax highlighting and connexion to R works well.

Any idea about how to fix this and get WinEdt automatically started when
library(RWinEdt) is called?

Patrick



From evakaiserseder at hotmail.com  Wed Oct  3 08:18:36 2007
From: evakaiserseder at hotmail.com (Eva Kaiserseder)
Date: Wed, 3 Oct 2007 08:18:36 +0200
Subject: [R-sig-Geo] jitter coordinates
Message-ID: <BLU104-W14D72044FE8646CF343F94DFAF0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071003/57c99cdb/attachment.pl>

From tskam at smu.edu.sg  Fri Oct  5 03:22:46 2007
From: tskam at smu.edu.sg (KAM Tin Seong)
Date: Fri, 5 Oct 2007 09:22:46 +0800
Subject: [R-sig-Geo] Import polygon shp into spatstat
Message-ID: <FA3090E732DC6A4EB8E2D875EEB486A562CE2D@EX01.staff.smu.edu.sg>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071005/ee75507d/attachment.pl>

From marco.helbich at gmx.at  Sat Oct  6 14:32:51 2007
From: marco.helbich at gmx.at (Marco Helbich)
Date: Sat, 6 Oct 2007 14:32:51 +0200
Subject: [R-sig-Geo] R-sig-Geo Digest, Vol 50, Issue 4
References: <mailman.7.1191664802.32446.r-sig-geo@stat.math.ethz.ch>
Message-ID: <000a01c80815$03d8e2a0$0300a8c0@mirk>

Dear Kam Tin Seong,

try something like this:
w <- readShapePoly("xxxx.shp")
W <-as(as(w, "SpatialPolygons"), "owin")  # polygon window
plot(W)
pts.ppp <- as.ppp(xykoord, W) # xykoord=point pattern
summary(pts.ppp)
plot(pts.ppp)

Best regards
Marco
______________________________

Marco Helbich
Institute for Urban and Regional Research, 
Austrian Academy of Sciences 
Postgasse 7/4/2, A-1010 Vienna, Austria
phone: +43 (1) 51581-3494
mail: marco.helbich (at) oeaw.ac.at 

> 
> ------------------------------
> 
> Message: 4
> Date: Fri, 5 Oct 2007 09:22:46 +0800
> From: "KAM Tin Seong" <tskam at smu.edu.sg>
> Subject: Re: [R-sig-Geo] Import polygon shp into spatstat
> To: <r-sig-geo at stat.math.ethz.ch>
> Message-ID:
> <FA3090E732DC6A4EB8E2D875EEB486A562CE2D at EX01.staff.smu.edu.sg>
> Content-Type: text/plain
> 
> Hi all,
> 
> I have a polygon drawing in shpefile format and would like to use this
> drawing to define the boundary of my study area using spatstat.  Can
> someone advice me how to go about doing it?
> 
> Dr Kam Tin Seong 
> Practice Associate Professor 
> School of Information Systems 
> 
> Singapore Management University 
> 80 Stamford Road 
> Singapore 178902 
> e-mail: tskam at smu.edu.sg 
> DID: + 65 6828 0932
> 
>



From andrew.niccolai at yale.edu  Sat Oct  6 14:40:48 2007
From: andrew.niccolai at yale.edu (Andrew Niccolai)
Date: Sat, 6 Oct 2007 08:40:48 -0400
Subject: [R-sig-Geo] Image Template Matching
In-Reply-To: <Pine.LNX.4.64.0709280924190.9185@reclus.nhh.no>
References: <2fc17e30709230449g4ef21536x6cb3a4d3d6193c79@mail.gmail.com>
	<Pine.LNX.4.64.0709232134110.18256@reclus.nhh.no>
	<2fc17e30709231823l63c1c44xad41df9fc8e162a6@mail.gmail.com>
	<Pine.LNX.4.64.0709240707490.19983@reclus.nhh.no><2fc17e30709242336u4f286094t9567bc66303b5e70@mail.gmail.com>
	<Pine.LNX.4.64.0709280924190.9185@reclus.nhh.no>
Message-ID: <000001c80816$1fc6bcc0$0601a8c0@D3K86YB1>

Hello spatial R community,

Can anyone help me to convert the following algorithm to R code that will
allow me to take a subset of an image and then produce an image that
"targets" the areas of the original larger image that are highly correlated
with the template image?

Any help would be enormously appreciated.

Thanks in advance



TEMPLATE MATCHING ALGORITHM:

   Read in two images, template and target 

 

   min_correlation = -1;

 

   for x = 0 to target.width-template.width{

     for y = 0 to target.height-template.height{

           correlation = correlate(template, target, x, y)

           if (min_correlation <0 or correlation < min_correlation){

              min_correlation = correlation

              min_x = x

              min_y = y

           }

    }

  }   

 

  for x = 0 to template.width{

     for y = 0 to template.height{

        target(min_x + x, min_y + y) = some distinctive colour

    }

. }

 

  write the modified target image to a new file. 


Andrew Niccolai
Doctoral Candidate
Yale School of Forestry



From jorge.de-jesus at jrc.it  Mon Oct  8 09:50:28 2007
From: jorge.de-jesus at jrc.it (Jorge de Jesus)
Date: Mon, 08 Oct 2007 09:50:28 +0200
Subject: [R-sig-Geo] problem loading sp using Rpy (python)
Message-ID: <4709E144.6050002@jrc.it>

Hi to all
I am working on Python and Rpy to make automatic interpolations. I need
to use the sp library of R.

When Rpy calls my R scripts it creates an error saying that the sp
package can't be loaded. But inside the R environment everything works ok.

When I removed sp and then reinstalled I got the following error:

trying URL
'http://rm.mirror.garr.it/mirrors/CRAN/src/contrib/sp_0.9-14.tar.gz'
Content type 'application/x-gzip' length 359180 bytes
opened URL
==================================================
downloaded 350Kb

* Installing *source* package 'sp' ...
** libs
Error in library.dynam(lib, package, package.lib) :
shared library 'sp' not found
In addition: Warning messages:
1: package 'sp' contains no R code in: loadNamespace(package,
c(which.lib.loc, lib.loc), keep.source = keep.source)
2: S3 methods ?as.data.frame.SpatialPoints?,
?as.data.frame.SpatialPixels?, ?as.data.frame.SpatialGrid?,
?as.data.frame.SpatialPointsDataFrame?,
?as.data.frame.SpatialPixelsDataFrame?,
?as.data.frame.SpatialGridDataFrame?,
?as.data.frame.SpatialLinesDataFrame?,
?as.data.frame.SpatialPolygonsDataFrame?, ?as.data.frame.GridTopology?,
?as.matrix.SpatialGridDataFrame?, ?as.matrix.SpatialPixelsDataFrame?,
?cbind.SpatialGridDataFrame?, ?contour.SpatialPixelsDataFrame?,
?contour.SpatialGridDataFrame?, ?dim.SpatialPointsDataFrame?,
?image.SpatialPixelsDataFrame?, ?image.SpatialGridDataFrame?,
?lines.Line?, ?lines.Lines?, ?lines.SpatialLines?,
?lines.SpatialLinesDataFrame?, ?names.SpatialPointsDataFrame?,
?names.SpatialPixelsDataFrame?, ?names.SpatialGridDataFrame?,
?names.SpatialLinesDataFrame?, ?names.SpatialPolygonsDataFrame?,
?names<-.SpatialPointsDataFrame?, ?names<-.SpatialPolygonsDa [... truncated]
During startup - Warning message:
package sp in options("defaultPackages") was not found
gcc -std=gnu99 -I/usr/local/lib/R/include -I/usr/local/lib/R/include
-I/usr/local/include -fpic -g -O2 -c gcdist.c -o gcdist.o
gcc -std=gnu99 -I/usr/local/lib/R/include -I/usr/local/lib/R/include
-I/usr/local/include -fpic -g -O2 -c init.c -o init.o
gcc -std=gnu99 -I/usr/local/lib/R/include -I/usr/local/lib/R/include
-I/usr/local/include -fpic -g -O2 -c pip.c -o pip.o
gcc -std=gnu99 -I/usr/local/lib/R/include -I/usr/local/lib/R/include
-I/usr/local/include -fpic -g -O2 -c Rcentroid.c -o Rcentroid.o
gcc -std=gnu99 -I/usr/local/lib/R/include -I/usr/local/lib/R/include
-I/usr/local/include -fpic -g -O2 -c zerodist.c -o zerodist.o
gcc -std=gnu99 -shared -L/usr/local/lib -o sp.so gcdist.o init.o pip.o
Rcentroid.o zerodist.o -L/usr/local/lib/R/lib -lR
** R
** data
** demo
** inst
** preparing package for lazy loading
Error in code2LazyLoadDB(package, lib.loc = lib.loc, keep.source =
keep.source, :
name space must not be loaded.
Execution halted
ERROR: lazy loading failed for package 'sp'
** Removing '/usr/local/lib/R/library/sp'

The downloaded packages are in
/tmp/RtmpttNUa3/downloaded_packages
Warning message:
installation of package 'sp' had non-zero exit status in: install.packages()


Also I managed to get some extra info from Rpy, where it says the sp
library isn't loaded because of R_alloc() and some namespace problem(?).

Can anyone give me some help on understanding what is the problem and
how to fix it ??

Thanks
Jorge


-- 
Eng. Jorge Samuel Mendes de Jesus

European Commission (EC)
Joint Research Centre Directorate (DG JRC)
Institute for Environment and Sustainability (IES)
TP 441, Via Fermi 1
21020 Ispra (VA)
Italy

Phone: +39 0332 78 3536
Fax:   +39 0332 78 5466

http://rem.jrc.cec.eu.int

"The views expressed are purely those of the writer and may not in any circumstances be regarded as stating an official position of the European Commission"



From hzambran.newsgroups at gmail.com  Mon Oct  8 14:38:02 2007
From: hzambran.newsgroups at gmail.com (Mauricio Zambrano)
Date: Mon, 8 Oct 2007 14:38:02 +0200
Subject: [R-sig-Geo] directional semivariograms on the same graph
Message-ID: <63d616b0710080538m325faa5eif2d0ff6553e3dd85@mail.gmail.com>

R.2.5.1 and gstat 0.9-39.
--------------------------------

Hi,

Does anybody knows how to plot two or more semivariogams on the same
graph ?, I mean, only one x axis and only one Y axis and between them,
 2 or more directional semivariograms ?.

I defined:

jura.pred.xy <- jura.pred
names(jura.pred.xy)[1:2] <- c("x", "y")
coordinates(jura.pred.xy) <- ~x+y

and after I tried with:

Zn.vgm <- variogram(Zn~1, jura.pred.xy, alpha=c(22.5, 67.5, 112.5,
157.5), cutoff=2,  boundaries=c(0.1, 0.2*(1:10)), tol.hor=22.5)
plot(Zn.vgm, type="b", as.table=TRUE, main='Zn data', panel=panel.superpose)

but I got:
plot(Zn.vgm, type="b", as.table=TRUE, main='Zn data', panel=panel.superpose)

After I tried with:

Zn.vgm1 <- variogram(Zn~1, jura.pred.xy, alpha=c(22.5), cutoff=2,
boundaries=c(0.1, 0.2*(1:10)), tol.hor=22.5)
Zn.vgm2 <- variogram(Zn~1, jura.pred.xy, alpha=c(67.5), cutoff=2,
boundaries=c(0.1, 0.2*(1:10)), tol.hor=22.5)

plot(Zn.vgm1, type="b", as.table=TRUE, main='Zn data, Alpha=22.5?')
plot(Zn.vgm2, type="b", as.table=TRUE, main='Zn data, Alpha=67.5?', add=TRUE)

but only remains the second graph.

Thanks in advance

Mauricio



From e.pebesma at geo.uu.nl  Tue Oct  9 10:36:20 2007
From: e.pebesma at geo.uu.nl (Edzer J. Pebesma)
Date: Tue, 09 Oct 2007 10:36:20 +0200
Subject: [R-sig-Geo] directional semivariograms on the same graph
In-Reply-To: <63d616b0710080538m325faa5eif2d0ff6553e3dd85@mail.gmail.com>
References: <63d616b0710080538m325faa5eif2d0ff6553e3dd85@mail.gmail.com>
Message-ID: <470B3D84.4020907@geo.uu.nl>

Mauricio, it's easier than you think; try

Zn.vgm1 <- variogram(Zn~1, jura.pred.xy, alpha=c(22.5, 67.5), cutoff=2,  
boundaries=c(0.1, 0.2*(1:10)), tol.hor=22.5)

plot(Zn.vgm1) # with 2 panels
plot(Zn.vgm1, multipanel=FALSE) # in a single panel

the add=TRUE does not work as the plot methods for gstat variograms uses 
xyplot in lattice. You can of course change the variogram into a 
data.frame and then use base plot methods.
--
Edzer

Mauricio Zambrano wrote:
> R.2.5.1 and gstat 0.9-39.
> --------------------------------
>
> Hi,
>
> Does anybody knows how to plot two or more semivariogams on the same
> graph ?, I mean, only one x axis and only one Y axis and between them,
>  2 or more directional semivariograms ?.
>
> I defined:
>
> jura.pred.xy <- jura.pred
> names(jura.pred.xy)[1:2] <- c("x", "y")
> coordinates(jura.pred.xy) <- ~x+y
>
> and after I tried with:
>
> Zn.vgm <- variogram(Zn~1, jura.pred.xy, alpha=c(22.5, 67.5, 112.5,
> 157.5), cutoff=2,  boundaries=c(0.1, 0.2*(1:10)), tol.hor=22.5)
> plot(Zn.vgm, type="b", as.table=TRUE, main='Zn data', panel=panel.superpose)
>
> but I got:
> plot(Zn.vgm, type="b", as.table=TRUE, main='Zn data', panel=panel.superpose)
>
> After I tried with:
>
> Zn.vgm1 <- variogram(Zn~1, jura.pred.xy, alpha=c(22.5), cutoff=2,
> boundaries=c(0.1, 0.2*(1:10)), tol.hor=22.5)
> Zn.vgm2 <- variogram(Zn~1, jura.pred.xy, alpha=c(67.5), cutoff=2,
> boundaries=c(0.1, 0.2*(1:10)), tol.hor=22.5)
>
> plot(Zn.vgm1, type="b", as.table=TRUE, main='Zn data, Alpha=22.5?')
> plot(Zn.vgm2, type="b", as.table=TRUE, main='Zn data, Alpha=67.5?', add=TRUE)
>
> but only remains the second graph.
>
> Thanks in advance
>
> Mauricio
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Roger.Bivand at nhh.no  Tue Oct  9 11:12:39 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 9 Oct 2007 11:12:39 +0200 (CEST)
Subject: [R-sig-Geo] problem loading sp using Rpy (python)
In-Reply-To: <4709E144.6050002@jrc.it>
References: <4709E144.6050002@jrc.it>
Message-ID: <Pine.LNX.4.64.0710091103460.28159@reclus.nhh.no>

On Mon, 8 Oct 2007, Jorge de Jesus wrote:

> Hi to all
> I am working on Python and Rpy to make automatic interpolations. I need
> to use the sp library of R.
>
> When Rpy calls my R scripts it creates an error saying that the sp
> package can't be loaded. But inside the R environment everything works ok.

Is Rpy respecting your R_LIBS setting - that is, is it finding the library 
in which the sp package is installed? From the output below, I think you 
should read up on having multiple libraries, and maybe using .libPaths() 
to manage them from within R. Installing contributed packages in the main 
R library is not wise, if you need control of what your system is doing.

>
> When I removed sp and then reinstalled I got the following error:
>

You have not included the verbatim code, please do, otherwise interpreting 
the output is guesswork.

> trying URL
> 'http://rm.mirror.garr.it/mirrors/CRAN/src/contrib/sp_0.9-14.tar.gz'
> Content type 'application/x-gzip' length 359180 bytes
> opened URL
> ==================================================
> downloaded 350Kb
>
> * Installing *source* package 'sp' ...

You did intend to install the *source* package? How was your R installed, 
from source (always most robust)?

Please always include sessionInfo() output. In such cases, please also try 
several mirrors too, just in case a particular mirror is not carrying a 
good copy.

> ** libs
> Error in library.dynam(lib, package, package.lib) :
> shared library 'sp' not found
> In addition: Warning messages:
> 1: package 'sp' contains no R code in: loadNamespace(package,
> c(which.lib.loc, lib.loc), keep.source = keep.source)
> 2: S3 methods ?as.data.frame.SpatialPoints?,
> ?as.data.frame.SpatialPixels?, ?as.data.frame.SpatialGrid?,
> ?as.data.frame.SpatialPointsDataFrame?,
> ?as.data.frame.SpatialPixelsDataFrame?,
> ?as.data.frame.SpatialGridDataFrame?,
> ?as.data.frame.SpatialLinesDataFrame?,
> ?as.data.frame.SpatialPolygonsDataFrame?, ?as.data.frame.GridTopology?,
> ?as.matrix.SpatialGridDataFrame?, ?as.matrix.SpatialPixelsDataFrame?,
> ?cbind.SpatialGridDataFrame?, ?contour.SpatialPixelsDataFrame?,
> ?contour.SpatialGridDataFrame?, ?dim.SpatialPointsDataFrame?,
> ?image.SpatialPixelsDataFrame?, ?image.SpatialGridDataFrame?,
> ?lines.Line?, ?lines.Lines?, ?lines.SpatialLines?,
> ?lines.SpatialLinesDataFrame?, ?names.SpatialPointsDataFrame?,
> ?names.SpatialPixelsDataFrame?, ?names.SpatialGridDataFrame?,
> ?names.SpatialLinesDataFrame?, ?names.SpatialPolygonsDataFrame?,
> ?names<-.SpatialPointsDataFrame?, ?names<-.SpatialPolygonsDa [... truncated]
> During startup - Warning message:
> package sp in options("defaultPackages") was not found
> gcc -std=gnu99 -I/usr/local/lib/R/include -I/usr/local/lib/R/include
> -I/usr/local/include -fpic -g -O2 -c gcdist.c -o gcdist.o
> gcc -std=gnu99 -I/usr/local/lib/R/include -I/usr/local/lib/R/include
> -I/usr/local/include -fpic -g -O2 -c init.c -o init.o
> gcc -std=gnu99 -I/usr/local/lib/R/include -I/usr/local/lib/R/include
> -I/usr/local/include -fpic -g -O2 -c pip.c -o pip.o
> gcc -std=gnu99 -I/usr/local/lib/R/include -I/usr/local/lib/R/include
> -I/usr/local/include -fpic -g -O2 -c Rcentroid.c -o Rcentroid.o
> gcc -std=gnu99 -I/usr/local/lib/R/include -I/usr/local/lib/R/include
> -I/usr/local/include -fpic -g -O2 -c zerodist.c -o zerodist.o
> gcc -std=gnu99 -shared -L/usr/local/lib -o sp.so gcdist.o init.o pip.o
> Rcentroid.o zerodist.o -L/usr/local/lib/R/lib -lR
> ** R
> ** data
> ** demo
> ** inst
> ** preparing package for lazy loading
> Error in code2LazyLoadDB(package, lib.loc = lib.loc, keep.source =
> keep.source, :
> name space must not be loaded.
> Execution halted
> ERROR: lazy loading failed for package 'sp'
> ** Removing '/usr/local/lib/R/library/sp'
>
> The downloaded packages are in
> /tmp/RtmpttNUa3/downloaded_packages
> Warning message:
> installation of package 'sp' had non-zero exit status in: install.packages()
>
>
> Also I managed to get some extra info from Rpy, where it says the sp
> library isn't loaded because of R_alloc() and some namespace problem(?).
>
> Can anyone give me some help on understanding what is the problem and
> how to fix it ??
>
> Thanks
> Jorge
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From klaus.ecker at wsl.ch  Tue Oct  9 18:26:07 2007
From: klaus.ecker at wsl.ch (Klaus Ecker)
Date: Tue, 09 Oct 2007 18:26:07 +0200
Subject: [R-sig-Geo] interpolating presence absence data with external drift
Message-ID: <6.2.3.4.1.20071009172227.03143898@mailbi.wsl.ch>

Hello

I want to incorporate an external trend when 
interpolating binary data (presence absence data 
from vegetation records). To my understanding 
universal kriging does not work with binary 
response data and does not apply generalized 
linear models for the covariates. Does geoRglm provide these opportunities?

Kriging residuals from a deterministic model 
(regression kriging) would allow for logistic 
regression models to be used for the trend. 
However, applications of regression kriging in 
ecology are rare, especially in recent years. Is there anything wrong about it?

With logistic regression the variogramm is 
commonly calculated on standardised (Pearson) 
residuals. But I have never seen how to back 
transform them before they are added to the 
logistic trend model. Is it correct to multiply 
the kriging predictions by the square root of the 
variance of the response residuals?

Many thanks

Klaus





______________________________________________


Klaus Ecker
Swiss Federal Research Institute WSL
Biodiversity and Conservation Biology
Spatial Ecology
Z?rcherstrasse 111
CH-8903 Birmensdorf (SWITZERLAND)

phone: +41-44-7392-378
fax: +41-44-7392-215
e-mail: klaus.ecker at wsl.ch
internet: http://www.wsl.ch



From e.pebesma at geo.uu.nl  Tue Oct  9 21:16:05 2007
From: e.pebesma at geo.uu.nl (Edzer J. Pebesma)
Date: Tue, 09 Oct 2007 21:16:05 +0200
Subject: [R-sig-Geo] interpolating presence absence data with external
 drift
In-Reply-To: <6.2.3.4.1.20071009172227.03143898@mailbi.wsl.ch>
References: <6.2.3.4.1.20071009172227.03143898@mailbi.wsl.ch>
Message-ID: <470BD375.4020402@geo.uu.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071009/5f88da8e/attachment.pl>

From dale.w.steele at gmail.com  Wed Oct 10 03:16:05 2007
From: dale.w.steele at gmail.com (Dale Steele)
Date: Tue, 9 Oct 2007 21:16:05 -0400
Subject: [R-sig-Geo] problem simulating random point patterns
Message-ID: <72e8303a0710091816v2145ea8bnb6226c4d7cc73a12@mail.gmail.com>

I'm trying to reproduce a randomization test for complete spatial
randomness (described in Manly, 2007 Randomization, Bootstrap and
Monte Carlo Methods in Biology). As a first step, I am generating
random point processes in a rectangle.  I can reproduce results in the
book when I generate data as follows:

# (1)
nsim <- 999
xmin <- 0; xmax <- 40
ymin <- 0; ymax <- 50
npoints <- 22
xpoly <- c(0,40,40,0)
ypoly <- c(0,0,50,50)
poly <- as.points(xpoly, ypoly)

# generate an array of nsim random spatial point patterns, each with npoints
rpoints <- array(NA, dim=c(npoints,2,nsim))
  for (i in 1:nsim) {
  rpoints[ , ,i] <- cbind(runif(npoints,min=xmin,
max=xmax),runif(npoints,min=xmin,max=xmax))
}

However, when I use either the csr() function from splancs or
runifpoint from spatstat, the randomization distributions of my
statistic (mean kth nearest neighbor distance) are similar, but do not
reproduce the results of simulations using (1) to simulate the data.

I would expect that (1), (2) and (3) would be identical for a
rectangular sampling area.  Would like to extend to irregular
polygons.  Am I missing something simple here?  Thanks!  --Dale

# (1) generate an array of nsim random spatial point patterns within a
specific polygon area
library(splancs)
rpoints <- array(NA, dim=c(npoints,2,nsim))
  for (i in 1:nsim) {
    rpoints[, ,i] <- csr(poly, npoints)
  }

###  (2) same as above using spatstat runifpoint
library(spatstat)
rpoints <- array(NA, dim=c(npoints,2,nsim))
  for (i in 1:nsim) {
    rpoints[, ,i] <-  runifpoint(npoints,
win=owin(c(xmin,xmax),c(ymin,ymax)), giveup=1000)
  }



From Roger.Bivand at nhh.no  Wed Oct 10 09:21:11 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 10 Oct 2007 09:21:11 +0200 (CEST)
Subject: [R-sig-Geo] problem simulating random point patterns
In-Reply-To: <72e8303a0710091816v2145ea8bnb6226c4d7cc73a12@mail.gmail.com>
References: <72e8303a0710091816v2145ea8bnb6226c4d7cc73a12@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0710100844590.31696@reclus.nhh.no>

On Tue, 9 Oct 2007, Dale Steele wrote:

> I'm trying to reproduce a randomization test for complete spatial
> randomness (described in Manly, 2007 Randomization, Bootstrap and
> Monte Carlo Methods in Biology). As a first step, I am generating
> random point processes in a rectangle.  I can reproduce results in the
> book when I generate data as follows:
>
> # (1)
> nsim <- 999
> xmin <- 0; xmax <- 40
> ymin <- 0; ymax <- 50
> npoints <- 22
> xpoly <- c(0,40,40,0)
> ypoly <- c(0,0,50,50)
> poly <- as.points(xpoly, ypoly)
>
> # generate an array of nsim random spatial point patterns, each with npoints
> rpoints <- array(NA, dim=c(npoints,2,nsim))
>  for (i in 1:nsim) {
>  rpoints[ , ,i] <- cbind(runif(npoints,min=xmin,
> max=xmax),runif(npoints,min=xmin,max=xmax))
> }
>
> However, when I use either the csr() function from splancs or
> runifpoint from spatstat, the randomization distributions of my
> statistic (mean kth nearest neighbor distance) are similar, but do not
> reproduce the results of simulations using (1) to simulate the data.
>
> I would expect that (1), (2) and (3) would be identical for a
> rectangular sampling area.  Would like to extend to irregular
> polygons.  Am I missing something simple here?  Thanks!  --Dale

One of the features of open source software is that you can read the code. 
Just entering the function name with no brackets at the prompt shows the 
R code of the function.

Tracing back from csr() in splancs, you get to ranpts() then gen(), where 
you can see that runif() is being used slightly differently, to 
accommodate irregular polygons; if you has used set.seed(), you would 
probably have seen detail differences. pip() at the end of gen() can also 
give different answers to the in/out question for points falling exactly 
on the boundary than you might expect.

Similarly, looking at runifpoint() in spatstat takes you to runifrect(), 
which again makes heuristic adjustments to the number of points being 
sampled to suit a range of windows, with some sampled points being 
discarded if they are superfluous.

Finally, the spsample methods in the sp package also provide a solution, 
based on Brian Ripley's 1981 Spatial Statistics, for which you can read 
the R code. The sample.Spatial() method also uses runif() internally, in 
your case:

W <- new("Spatial", bbox=matrix(c(0,0,40,50), nrow=2, dimnames=list(NULL,
   c("min", "max"))))
coordinates(spsample(W, npoints, type="random"))

retrieves the coordinates. So you can trace through what all of these 
variants are doing in R code, and setting set.seed() to a fixed number, 
you can provide all the methods with the same stream of random numbers. 
Using debug() to step through an example run, you'll be able to find out 
exactly why what you expect isn't happening.

Please recall that splancs and spatstat are based on decades of 
experience. For corroboration, you can also read the underlying C code 
under Psim() in spatial, written by Brian Ripley (and supporting his book 
with Bill Venables: Modern Applied Statistics with S) - hint: it is using 
the C API to runif() as you see in spatial/src/pps.c.

Hope this helps,

Roger

>
> # (1) generate an array of nsim random spatial point patterns within a
> specific polygon area
> library(splancs)
> rpoints <- array(NA, dim=c(npoints,2,nsim))
>  for (i in 1:nsim) {
>    rpoints[, ,i] <- csr(poly, npoints)
>  }
>
> ###  (2) same as above using spatstat runifpoint
> library(spatstat)
> rpoints <- array(NA, dim=c(npoints,2,nsim))
>  for (i in 1:nsim) {
>    rpoints[, ,i] <-  runifpoint(npoints,
> win=owin(c(xmin,xmax),c(ymin,ymax)), giveup=1000)
>  }
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From jorge.de-jesus at jrc.it  Fri Oct 12 09:00:11 2007
From: jorge.de-jesus at jrc.it (Jorge de Jesus)
Date: Fri, 12 Oct 2007 09:00:11 +0200
Subject: [R-sig-Geo] problem loading library sp on Rpy (solved!!!)
Message-ID: <470F1B7B.6000608@jrc.it>

Hi to all
First I would like to thank all the replies that I had concerning the
problem of loading sp library from Rpy.

The problem with the library was caused by bad linking, so the best
solution was to reinstall R and Rpy, I followed these steps and it worked.
- Downloaded the new R-2.6.0, my previous version was 2.5.1
- R configure options: ./configure --with-gnu-ld --disable-fast-install
--enable-R-shlib --enable-BLAS-shlib
- Link from /usr/local/lib/R/lib/libR.so to /usr/local/lib and also
/usr/lib (just to be certain)
- downloaded the necessary packages
sp-0.9-14,sgeostat-1.0.21,e1071_1.5-1.6 and automap_0.4.1
- ldconfig
- Installed the packages using R CMD and not the install.packages() from
inside R
- Installed Rpy

So now my Python/Rpy can load the sp library without any problems
Thanks


-- 
Eng. Jorge Samuel Mendes de Jesus

European Commission (EC)
Joint Research Centre Directorate (DG JRC)
Institute for Environment and Sustainability (IES)
TP 441, Via Fermi 1
21020 Ispra (VA)
Italy

Phone: +39 0332 78 3536
Fax:   +39 0332 78 5466

http://rem.jrc.cec.eu.int

"The views expressed are purely those of the writer and may not in any circumstances be regarded as stating an official position of the European Commission"



From bchristo at email.arizona.edu  Fri Oct 12 09:44:54 2007
From: bchristo at email.arizona.edu (Brad Christoffersen)
Date: Fri, 12 Oct 2007 00:44:54 -0700
Subject: [R-sig-Geo] upper bounds for values in color scale in spplot
Message-ID: <20071012004454.yisg4wkckc0s0cks@www.email.arizona.edu>

Dear R mappers,

I'm just getting started with sp and maptools in R, and I have limited
familiarity with lattice() and how spplot interfaces with lattice() in terms of
commands.  I would like to know how to keep the range of values represented by a
color scale on a series of maps constant.

This is the code I'm running that generates 8 maps across 4 rows and 2 columns. 
You will see that it produces maps that have different upper bounds on the
respective color scales.  I'm interested in having a constant color scale for
each group of 4 maps (1 scale for each column of maps that are plotted) based
on the largest value in the data (or by just prescribing the upper and lower
bounds with constants).

Any help is much appreciated!
Thanks,
Brad C.

library(lattice)
library(sp)
library(maptools)
test <- read.table(##see data below##)
attach(test)
trellis.par.set(sp.theme()) # sets bpy.colors() ramp
seasons <- c("winter", "spring", "summer", "fall")
for(i in 1:length(seasons)){
	coords <- cbind(as.numeric(as.character(test[quarter %in% seasons[i],"lon"])),
as.numeric(as.character(test[quarter %in% seasons[i],"lat"])))
	data <- as.data.frame(test[quarter %in% seasons[i],c("alpha.hat","beta.hat")])
	test.sp <- SpatialPixelsDataFrame(coords, data)
	alpha <- spplot(test.sp, "alpha.hat", scales = list(draw = TRUE))
#		xlab="Degrees longitude", ylab="Degrees latitude", cex=.01)
	beta <- spplot(test.sp, "beta.hat", scales = list(draw = TRUE))
#		xlab="Degrees longitude", ylab="Degrees latitude")
	print(alpha, split = c(1,i,2,4), more=TRUE)
	if(i != 4) print(beta, split = c(2,i,2,4), more=TRUE) else print(beta, split =
c(2,i,2,4), more=FALSE)
	}

#### data to import into "test" above ####
# Exported using write.csv()

"","lon","lat","quarter","alpha.hat","beta.hat"
"1","-92","15","fall",6.65227439310417,56.98796936965
"2","-91","16","fall",5.7887515614357,61.4959602856346
"3","-92","16","fall",8.3574938986946,39.3233936656175
"4","-93","16","fall",6.59178338045291,51.1710742349428
"5","-94","16","fall",4.59110354447175,72.4631790313551
"6","-96","16","fall",3.39120062305053,61.3498455235854
"7","-97","16","fall",3.72637499733858,52.3827509555908
"8","-100","17","fall",3.32679271676835,57.9245201009673
"9","-92","17","fall",7.8180071249829,42.72784154996
"10","-93","17","fall",6.83894383129027,54.4726918059386
"3190","-92","15","winter",5.46418721415736,54.6602669154477
"3191","-91","16","winter",10.2567049399226,26.8445099823192
"3192","-92","16","winter",8.47780749631668,32.3555645381505
"3193","-93","16","winter",8.02490919053258,38.1741888219237
"3194","-94","16","winter",9.26825779141845,31.6804438316389
"3195","-96","16","winter",7.42583760477561,32.4318502183180
"3196","-97","16","winter",7.15366354446019,30.4092071610074
"3197","-100","17","winter",5.67248315575543,44.0629887199626
"3198","-92","17","winter",11.0324295494684,28.5398502105252
"3199","-93","17","winter",12.8600152825316,25.8707202327790
"1064","-92","15","spring",3.61863154993334,165.857349319137
"1065","-91","16","spring",10.1643339841701,35.2421643628567
"1066","-92","16","spring",7.57240369751446,46.9922847457852
"1067","-93","16","spring",6.22249309807625,56.292359117006
"1068","-94","16","spring",4.68274375255797,74.3825475754281
"1069","-96","16","spring",5.53655775167911,44.1263777723619
"1070","-97","16","spring",7.97757426122346,27.6282118121658
"1071","-100","17","spring",6.56565778175741,31.7130717161184
"1072","-92","17","spring",7.6609568130759,55.1152061731614
"1073","-93","17","spring",8.0322728962686,50.598411876406
"2127","-92","15","summer",9.72176297639579,71.2388658845007
"2128","-91","16","summer",16.4747820437274,24.4358645774566
"2129","-92","16","summer",14.0292926267460,27.8787650995959
"2130","-93","16","summer",13.1831296281448,27.3284323593481
"2131","-94","16","summer",6.1805787873833,58.44229189654
"2132","-96","16","summer",5.77117377664185,41.3812553952903
"2133","-97","16","summer",5.98738435242406,35.7155813363363
"2134","-100","17","summer",5.72083279663587,37.0908537701739
"2135","-92","17","summer",9.2083842635031,55.218659463404
"2136","-93","17","summer",13.5244943586978,37.5585163321001



From Roger.Bivand at nhh.no  Fri Oct 12 10:53:39 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 12 Oct 2007 10:53:39 +0200 (CEST)
Subject: [R-sig-Geo] upper bounds for values in color scale in spplot
In-Reply-To: <20071012004454.yisg4wkckc0s0cks@www.email.arizona.edu>
References: <20071012004454.yisg4wkckc0s0cks@www.email.arizona.edu>
Message-ID: <Pine.LNX.4.64.0710121051010.14723@reclus.nhh.no>

On Fri, 12 Oct 2007, Brad Christoffersen wrote:

> Dear R mappers,
>
> I'm just getting started with sp and maptools in R, and I have limited 
> familiarity with lattice() and how spplot interfaces with lattice() in 
> terms of commands.  I would like to know how to keep the range of values 
> represented by a color scale on a series of maps constant.

Reading the levelplot help page after library(lattice) usually helps. The 
arguments you need are at= and col.regions=, which let you fix the class 
intervals and the colour palette. You will need to try out values that 
suit, but this should get you there.

Roger

>
> This is the code I'm running that generates 8 maps across 4 rows and 2 columns.
> You will see that it produces maps that have different upper bounds on the
> respective color scales.  I'm interested in having a constant color scale for
> each group of 4 maps (1 scale for each column of maps that are plotted) based
> on the largest value in the data (or by just prescribing the upper and lower
> bounds with constants).
>
> Any help is much appreciated!
> Thanks,
> Brad C.
>
> library(lattice)
> library(sp)
> library(maptools)
> test <- read.table(##see data below##)
> attach(test)
> trellis.par.set(sp.theme()) # sets bpy.colors() ramp
> seasons <- c("winter", "spring", "summer", "fall")
> for(i in 1:length(seasons)){
> 	coords <- cbind(as.numeric(as.character(test[quarter %in% seasons[i],"lon"])),
> as.numeric(as.character(test[quarter %in% seasons[i],"lat"])))
> 	data <- as.data.frame(test[quarter %in% seasons[i],c("alpha.hat","beta.hat")])
> 	test.sp <- SpatialPixelsDataFrame(coords, data)
> 	alpha <- spplot(test.sp, "alpha.hat", scales = list(draw = TRUE))
> #		xlab="Degrees longitude", ylab="Degrees latitude", cex=.01)
> 	beta <- spplot(test.sp, "beta.hat", scales = list(draw = TRUE))
> #		xlab="Degrees longitude", ylab="Degrees latitude")
> 	print(alpha, split = c(1,i,2,4), more=TRUE)
> 	if(i != 4) print(beta, split = c(2,i,2,4), more=TRUE) else print(beta, split =
> c(2,i,2,4), more=FALSE)
> 	}
>
> #### data to import into "test" above ####
> # Exported using write.csv()
>
> "","lon","lat","quarter","alpha.hat","beta.hat"
> "1","-92","15","fall",6.65227439310417,56.98796936965
> "2","-91","16","fall",5.7887515614357,61.4959602856346
> "3","-92","16","fall",8.3574938986946,39.3233936656175
> "4","-93","16","fall",6.59178338045291,51.1710742349428
> "5","-94","16","fall",4.59110354447175,72.4631790313551
> "6","-96","16","fall",3.39120062305053,61.3498455235854
> "7","-97","16","fall",3.72637499733858,52.3827509555908
> "8","-100","17","fall",3.32679271676835,57.9245201009673
> "9","-92","17","fall",7.8180071249829,42.72784154996
> "10","-93","17","fall",6.83894383129027,54.4726918059386
> "3190","-92","15","winter",5.46418721415736,54.6602669154477
> "3191","-91","16","winter",10.2567049399226,26.8445099823192
> "3192","-92","16","winter",8.47780749631668,32.3555645381505
> "3193","-93","16","winter",8.02490919053258,38.1741888219237
> "3194","-94","16","winter",9.26825779141845,31.6804438316389
> "3195","-96","16","winter",7.42583760477561,32.4318502183180
> "3196","-97","16","winter",7.15366354446019,30.4092071610074
> "3197","-100","17","winter",5.67248315575543,44.0629887199626
> "3198","-92","17","winter",11.0324295494684,28.5398502105252
> "3199","-93","17","winter",12.8600152825316,25.8707202327790
> "1064","-92","15","spring",3.61863154993334,165.857349319137
> "1065","-91","16","spring",10.1643339841701,35.2421643628567
> "1066","-92","16","spring",7.57240369751446,46.9922847457852
> "1067","-93","16","spring",6.22249309807625,56.292359117006
> "1068","-94","16","spring",4.68274375255797,74.3825475754281
> "1069","-96","16","spring",5.53655775167911,44.1263777723619
> "1070","-97","16","spring",7.97757426122346,27.6282118121658
> "1071","-100","17","spring",6.56565778175741,31.7130717161184
> "1072","-92","17","spring",7.6609568130759,55.1152061731614
> "1073","-93","17","spring",8.0322728962686,50.598411876406
> "2127","-92","15","summer",9.72176297639579,71.2388658845007
> "2128","-91","16","summer",16.4747820437274,24.4358645774566
> "2129","-92","16","summer",14.0292926267460,27.8787650995959
> "2130","-93","16","summer",13.1831296281448,27.3284323593481
> "2131","-94","16","summer",6.1805787873833,58.44229189654
> "2132","-96","16","summer",5.77117377664185,41.3812553952903
> "2133","-97","16","summer",5.98738435242406,35.7155813363363
> "2134","-100","17","summer",5.72083279663587,37.0908537701739
> "2135","-92","17","summer",9.2083842635031,55.218659463404
> "2136","-93","17","summer",13.5244943586978,37.5585163321001
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From hzambran.newsgroups at gmail.com  Fri Oct 12 13:26:33 2007
From: hzambran.newsgroups at gmail.com (Mauricio Zambrano)
Date: Fri, 12 Oct 2007 13:26:33 +0200
Subject: [R-sig-Geo] directional semivariograms on the same graph
In-Reply-To: <470B3D84.4020907@geo.uu.nl>
References: <63d616b0710080538m325faa5eif2d0ff6553e3dd85@mail.gmail.com>
	<470B3D84.4020907@geo.uu.nl>
Message-ID: <63d616b0710120426g1fa93ff3s60b24d8c1660b8f0@mail.gmail.com>

Thanks a lot Edzer. It works !

And sorry, because I search in the lattice documentation without any
results, and, likely becuase I was very tired and confused, I didn't
see the MULTIPANEL option description in the gstat.pdf file.

Thanks again,

Mauricio



From b.rowlingson at lancaster.ac.uk  Fri Oct 12 13:45:57 2007
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 12 Oct 2007 12:45:57 +0100
Subject: [R-sig-Geo] Barry Rowlingson's "Arlat" on FOSS4G 2007
In-Reply-To: <470112AA.1060806@ija.csic.es>
References: <20071001102844.42991.qmail@web10709.mail.bbt.yahoo.co.jp>	<1191238328.703.19.camel@fh-vrubio>	<1191251858.15197.10.camel@rick>
	<470112AA.1060806@ija.csic.es>
Message-ID: <470F5E75.9040109@lancaster.ac.uk>

Agustin Lobo wrote:
> Any way of getting the pdf of the talk? I'm interested
> both on the epidemiology application and on
> the R-QGis integration.

  I've just uploaded my slides, although I'm not sure how much sense 
they make without my witty narrative that goes along with it :) Did 
anyone record my talk for posterity?

  Link here:

http://www.foss4g2007.org/presentations/view.php?abstract_id=135

Barry



From edzer.pebesma at uni-muenster.de  Fri Oct 12 13:38:57 2007
From: edzer.pebesma at uni-muenster.de (Edzer J. Pebesma)
Date: Fri, 12 Oct 2007 13:38:57 +0200
Subject: [R-sig-Geo] upper bounds for values in color scale in spplot
In-Reply-To: <20071012004454.yisg4wkckc0s0cks@www.email.arizona.edu>
References: <20071012004454.yisg4wkckc0s0cks@www.email.arizona.edu>
Message-ID: <470F5CD1.6040303@uni-muenster.de>

Brad, you might want to try to construct one spplot per column, having 
the scale perhaps horizontally on the bottom, and combing them using the 
print(..., more = T) on trellis objects (see ?print.trellis in package 
lattice). An issue might be to get the maps at exactly the same scale, 
as the print command addresses the full print object including the 
possibly varying scale/text; I often fought with this but have no solution.
--
Edzer

Brad Christoffersen wrote:
> Dear R mappers,
>
> I'm just getting started with sp and maptools in R, and I have limited
> familiarity with lattice() and how spplot interfaces with lattice() in terms of
> commands.  I would like to know how to keep the range of values represented by a
> color scale on a series of maps constant.
>
> This is the code I'm running that generates 8 maps across 4 rows and 2 columns. 
> You will see that it produces maps that have different upper bounds on the
> respective color scales.  I'm interested in having a constant color scale for
> each group of 4 maps (1 scale for each column of maps that are plotted) based
> on the largest value in the data (or by just prescribing the upper and lower
> bounds with constants).
>
> Any help is much appreciated!
> Thanks,
> Brad C.



From v.gomezrubio at imperial.ac.uk  Fri Oct 12 13:48:04 2007
From: v.gomezrubio at imperial.ac.uk (Virgilio Gomez-Rubio)
Date: Fri, 12 Oct 2007 12:48:04 +0100
Subject: [R-sig-Geo] Barry Rowlingson's "Arlat" on FOSS4G 2007
In-Reply-To: <470F5E75.9040109@lancaster.ac.uk>
References: <20071001102844.42991.qmail@web10709.mail.bbt.yahoo.co.jp>
	<1191238328.703.19.camel@fh-vrubio>	<1191251858.15197.10.camel@rick>
	<470112AA.1060806@ija.csic.es>  <470F5E75.9040109@lancaster.ac.uk>
Message-ID: <1192189684.11001.21.camel@fh-vrubio>

Barry,

Thanks for the slides and congratulations for the hard work. My question
nos is whether Arlat (and any other source code) available on-line.

Best,

Virgilio


On Fri, 2007-10-12 at 12:45 +0100, Barry Rowlingson wrote:
> Agustin Lobo wrote:
> > Any way of getting the pdf of the talk? I'm interested
> > both on the epidemiology application and on
> > the R-QGis integration.
> 
>   I've just uploaded my slides, although I'm not sure how much sense 
> they make without my witty narrative that goes along with it :) Did 
> anyone record my talk for posterity?
> 
>   Link here:
> 
> http://www.foss4g2007.org/presentations/view.php?abstract_id=135
> 
> Barry
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From edzer.pebesma at uni-muenster.de  Fri Oct 12 13:54:11 2007
From: edzer.pebesma at uni-muenster.de (Edzer J. Pebesma)
Date: Fri, 12 Oct 2007 13:54:11 +0200
Subject: [R-sig-Geo] Barry Rowlingson's "Arlat" on FOSS4G 2007
In-Reply-To: <470F5E75.9040109@lancaster.ac.uk>
References: <20071001102844.42991.qmail@web10709.mail.bbt.yahoo.co.jp>	<1191238328.703.19.camel@fh-vrubio>	<1191251858.15197.10.camel@rick>	<470112AA.1060806@ija.csic.es>
	<470F5E75.9040109@lancaster.ac.uk>
Message-ID: <470F6063.8020706@uni-muenster.de>

I'm sorry I missed this talk Barry, but the slides were a pleasure to go 
through!

What was the argument not to go with OpenEV with communication through 
Rserve?

Thanks,
--
Edzer

Barry Rowlingson wrote:
> Agustin Lobo wrote:
>   
>> Any way of getting the pdf of the talk? I'm interested
>> both on the epidemiology application and on
>> the R-QGis integration.
>>     
>
>   I've just uploaded my slides, although I'm not sure how much sense 
> they make without my witty narrative that goes along with it :) Did 
> anyone record my talk for posterity?
>
>   Link here:
>
> http://www.foss4g2007.org/presentations/view.php?abstract_id=135
>
> Barry
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From b.rowlingson at lancaster.ac.uk  Fri Oct 12 14:01:57 2007
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 12 Oct 2007 13:01:57 +0100
Subject: [R-sig-Geo] Barry Rowlingson's "Arlat" on FOSS4G 2007
In-Reply-To: <1192189684.11001.21.camel@fh-vrubio>
References: <20071001102844.42991.qmail@web10709.mail.bbt.yahoo.co.jp>	
	<1191238328.703.19.camel@fh-vrubio>	<1191251858.15197.10.camel@rick>	
	<470112AA.1060806@ija.csic.es> <470F5E75.9040109@lancaster.ac.uk>
	<1192189684.11001.21.camel@fh-vrubio>
Message-ID: <470F6235.8090705@lancaster.ac.uk>

Virgilio Gomez-Rubio wrote:
> Barry,
> 
> Thanks for the slides and congratulations for the hard work. My question
> nos is whether Arlat (and any other source code) available on-line.

  The source code of the R-package for Arlat is here:

http://www.maths.lancs.ac.uk/Software/Arlat/

  BUT! There's very minimal documentation or examples. You may have 
trouble making it work, or even working out which functions to call. One 
day I'll write the documentation...

Barry



From b.rowlingson at lancaster.ac.uk  Fri Oct 12 14:07:09 2007
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 12 Oct 2007 13:07:09 +0100
Subject: [R-sig-Geo] Barry Rowlingson's "Arlat" on FOSS4G 2007
In-Reply-To: <470F6063.8020706@uni-muenster.de>
References: <20071001102844.42991.qmail@web10709.mail.bbt.yahoo.co.jp>	<1191238328.703.19.camel@fh-vrubio>	<1191251858.15197.10.camel@rick>	<470112AA.1060806@ija.csic.es>
	<470F5E75.9040109@lancaster.ac.uk>
	<470F6063.8020706@uni-muenster.de>
Message-ID: <470F636D.2000304@lancaster.ac.uk>

Edzer J. Pebesma wrote:
> I'm sorry I missed this talk Barry, but the slides were a pleasure to go 
> through!
> 
> What was the argument not to go with OpenEV with communication through 
> Rserve?

  Efficiency: Rserve has to convert the data to the Rserve wire 
protocol, send it down the loopback network and unconvert it at the 
other end, whereas Rpy does conversion in memory when needed and there's 
no transport.

  Simplicity: Using Rserve means making sure the separate Rserve process 
fires up when you need it, whereas Rpy just loads up libR.so  (or .dll) 
and works like that.

  User-friendliness: OpenEV is not the most standard-looking GIS program 
on the planet - it was never really designed to be a general purpose 
vector and raster GIS anyway, which is what Qgis does well.

That's probably enough reasons!

Barry



From dylan.beaudette at gmail.com  Fri Oct 12 22:28:12 2007
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Fri, 12 Oct 2007 13:28:12 -0700
Subject: [R-sig-Geo] Barry Rowlingson's "Arlat" on FOSS4G 2007
In-Reply-To: <470F5E75.9040109@lancaster.ac.uk>
References: <20071001102844.42991.qmail@web10709.mail.bbt.yahoo.co.jp>
	<470112AA.1060806@ija.csic.es> <470F5E75.9040109@lancaster.ac.uk>
Message-ID: <200710121328.12895.dylan.beaudette@gmail.com>

On Friday 12 October 2007, Barry Rowlingson wrote:
> Agustin Lobo wrote:
> > Any way of getting the pdf of the talk? I'm interested
> > both on the epidemiology application and on
> > the R-QGis integration.
>
>   I've just uploaded my slides, although I'm not sure how much sense
> they make without my witty narrative that goes along with it :) Did
> anyone record my talk for posterity?
>
>   Link here:
>
> http://www.foss4g2007.org/presentations/view.php?abstract_id=135
>
> Barry
>

Excellent presentation, on an excellent use of FOSS GIS+R !!

Cheers,

Dylan


-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341



From anne.goarant at cebc.cnrs.fr  Tue Oct 16 09:02:14 2007
From: anne.goarant at cebc.cnrs.fr (Anne GOARANT)
Date: Tue, 16 Oct 2007 09:02:14 +0200
Subject: [R-sig-Geo] Adding a map to a filled.contour plot
In-Reply-To: <200710121328.12895.dylan.beaudette@gmail.com>
References: <20071001102844.42991.qmail@web10709.mail.bbt.yahoo.co.jp>	<470112AA.1060806@ija.csic.es>
	<470F5E75.9040109@lancaster.ac.uk>
	<200710121328.12895.dylan.beaudette@gmail.com>
Message-ID: <471461F6.8010707@cebc.cnrs.fr>

Dear List,

I am using the filled.contour function with the argument plot.axis = 
{map('worldHires',add=T)} to add the world map to my plot.

filled.contour(x,y,z,plot.axes = {map('worldHires',add=T,fill=T)})

The problem is that the longitudes of my matrix go from 0 (at Greenwich) 
to 360 which seem not to be the same for the map function (whose 
longitudes go from -180 to 180). Hence only one part of the map appears 
on the plot (South Africa and Australia). Do you know a way to get the 
whole map on the plot?

Cheers,

Anne




________ Information from NOD32 ________
This message was checked by NOD32 Antivirus System for Linux Mail Servers.
http://www.eset.com



From Roger.Bivand at nhh.no  Tue Oct 16 09:27:57 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 16 Oct 2007 09:27:57 +0200 (CEST)
Subject: [R-sig-Geo] Adding a map to a filled.contour plot
In-Reply-To: <471461F6.8010707@cebc.cnrs.fr>
References: <20071001102844.42991.qmail@web10709.mail.bbt.yahoo.co.jp>
	<470112AA.1060806@ija.csic.es> <470F5E75.9040109@lancaster.ac.uk>
	<200710121328.12895.dylan.beaudette@gmail.com>
	<471461F6.8010707@cebc.cnrs.fr>
Message-ID: <Pine.LNX.4.64.0710160918440.22362@reclus.nhh.no>

On Tue, 16 Oct 2007, Anne GOARANT wrote:

> Dear List,
>
> I am using the filled.contour function with the argument plot.axis =
> {map('worldHires',add=T)} to add the world map to my plot.
>
> filled.contour(x,y,z,plot.axes = {map('worldHires',add=T,fill=T)})
>
> The problem is that the longitudes of my matrix go from 0 (at Greenwich)
> to 360 which seem not to be the same for the map function (whose
> longitudes go from -180 to 180). Hence only one part of the map appears
> on the plot (South Africa and Australia). Do you know a way to get the
> whole map on the plot?

Two possibilities: forego higher resolution and use "world2" in maps, or 
manipulate x in the filled.contours() call, something like (untried):

xx <- ifelse(x <= 180, x, -(360 - x))

which ought to work even if your x range extends below 0.

Roger


>
> Cheers,
>
> Anne
>
>
>
>
> ________ Information from NOD32 ________
> This message was checked by NOD32 Antivirus System for Linux Mail Servers.
> http://www.eset.com
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Tue Oct 16 09:52:18 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 16 Oct 2007 09:52:18 +0200 (CEST)
Subject: [R-sig-Geo] sp_0.9-16 source on CRAN
Message-ID: <Pine.LNX.4.64.0710160944460.22362@reclus.nhh.no>

A new version of the foundation sp package is reaching CRAN mirrors, and 
Windows and OSX binaries should follow within a day or so. There is a 
significant change in how SpatialGrid objects are created, which we hope 
will not affect users negatively, and which is giving a two orders of 
magnitude speedup for reading larger rasters (single band 900 by 3600 down 
from 12 minutes to 6 seconds on an older 1.5GHz machine).

If anyone sees any negative impacts, please contact the authors 
immediately directly.

Roger

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From evakaiserseder at hotmail.com  Wed Oct 17 08:31:46 2007
From: evakaiserseder at hotmail.com (Eva Kaiserseder)
Date: Wed, 17 Oct 2007 08:31:46 +0200
Subject: [R-sig-Geo] add random fluctuation x and y coordinates
Message-ID: <BLU104-W2D5C1AC4BF59BAF82A74DDF9D0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071017/f97ce938/attachment.pl>

From Agustin.Lobo at ija.csic.es  Wed Oct 17 09:51:35 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Wed, 17 Oct 2007 09:51:35 +0200
Subject: [R-sig-Geo] add random fluctuation x and y coordinates
In-Reply-To: <BLU104-W2D5C1AC4BF59BAF82A74DDF9D0@phx.gbl>
References: <BLU104-W2D5C1AC4BF59BAF82A74DDF9D0@phx.gbl>
Message-ID: <4715BF07.8090702@ija.csic.es>

I've you use runif:

 > options(digits=11)
 > v1 <- c(428381.60000, 428871.60000, 408027.20000, 406870.40000)
 > v1
[1] 428381.6 428871.6 408027.2 406870.4
 > v1+r
[1] 428381.59167 428871.60388 408027.19276 406870.39058

I've you use jitter:
 > jitter(v1,0.01)
[1] 428382.48671 428872.43348 408026.50774 406869.64816

Agus

Eva Kaiserseder escribi?:
> Dear List,Sorry for posting again the same question but up to now not all things are clear.
> I've got a point pattern and a few events have duplicated coordinates. In this way I want to add a minimal random fluctuation in the x and y direction/coordinates. If I use the jitter-function my fluctuations are too large. So I tried to control it with the amount argument, but I can't find a solution. How can I restrict them to the decimal places?Thanks a lot for your help!Best regards, Eva
> I tried something like this, to add fluctuation after the second decimal place:
> v1 <- c(428381.6, 428871.6, 408027.2, 406870.4)
> v2 <- c(293884.6, 292929.8, 292621.0, 292014.1)
> test <- as.data.frame(cbind(v1, v2))
> colnames(test) <- c("x", "y")
> coordinates(test) <- c("x","y")
> # ? ? ? ? ?
> r <- runif(length(v1), -0.01, 0.01)
> jitter(test$x, amount = test$x + r)
> jcoord <- cbind(jitter(test[,1], amount = test[,1] + r), jitter(test[,2], amount = test[,2] + r))
>  
> _________________________________________________________________
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Thierry.ONKELINX at inbo.be  Wed Oct 17 09:49:17 2007
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 17 Oct 2007 09:49:17 +0200
Subject: [R-sig-Geo] add random fluctuation x and y coordinates
In-Reply-To: <BLU104-W2D5C1AC4BF59BAF82A74DDF9D0@phx.gbl>
References: <BLU104-W2D5C1AC4BF59BAF82A74DDF9D0@phx.gbl>
Message-ID: <2E9C414912813E4EB981326983E0A10403C4739F@inboexch.inbo.be>

You need to do 

jitter(test$x, amount = 0.01)

instead of

jitter(test$x, amount = test$x + 0.01)

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be 

Do not put your faith in what statistics say until you have carefully
considered what they do not say.  ~William W. Watt
A statistical analysis, properly conducted, is a delicate dissection of
uncertainties, a surgery of suppositions. ~M.J.Moroney



> -----Oorspronkelijk bericht-----
> Van: r-sig-geo-bounces at stat.math.ethz.ch 
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens Eva Kaiserseder
> Verzonden: woensdag 17 oktober 2007 8:32
> Aan: r-sig-geo at stat.math.ethz.ch
> Onderwerp: [R-sig-Geo] add random fluctuation x and y coordinates
> 
> 
> Dear List,Sorry for posting again the same question but up to 
> now not all things are clear.
> I've got a point pattern and a few events have duplicated 
> coordinates. In this way I want to add a minimal random 
> fluctuation in the x and y direction/coordinates. If I use 
> the jitter-function my fluctuations are too large. So I tried 
> to control it with the amount argument, but I can't find a 
> solution. How can I restrict them to the decimal 
> places?Thanks a lot for your help!Best regards, Eva I tried 
> something like this, to add fluctuation after the second 
> decimal place:
> v1 <- c(428381.6, 428871.6, 408027.2, 406870.4)
> v2 <- c(293884.6, 292929.8, 292621.0, 292014.1) test <- 
> as.data.frame(cbind(v1, v2))
> colnames(test) <- c("x", "y")
> coordinates(test) <- c("x","y")
> # ? ? ? ? ?
> r <- runif(length(v1), -0.01, 0.01)
> jitter(test$x, amount = test$x + r)
> jcoord <- cbind(jitter(test[,1], amount = test[,1] + r), 
> jitter(test[,2], amount = test[,2] + r))
>  
> _________________________________________________________________
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 



From cajaeg at googlemail.com  Wed Oct 17 16:09:04 2007
From: cajaeg at googlemail.com (Carsten Jaeger)
Date: Wed, 17 Oct 2007 16:09:04 +0200
Subject: [R-sig-Geo] Error loading rgdal package on Fedora 7
Message-ID: <1192630144.32633.6.camel@localhost.localdomain>

Hello,

I'm using R version 2.5.1 on Fedora 7. I just installed the rgdal
package from source, compilation was without problems. However, when I
try to load the package I get the following error message:

> library(rgdal)
Loading required package: rgdal
Loading required package: sp
Error in dyn.load(x, as.logical(local), as.logical(now)) : 
	unable to load shared library '/home/xxxx/R/rgdal/libs/rgdal.so':
  /usr/lib/atlas/liblapack.so.3: undefined symbol: ATL_chemv
[1] FALSE

Obviously, liblapack.so.3 is incompatible with rgdal.so. ATLAS version
is 3.6.0 which is the most current version available for F7 as rpm
(atlas-3.6.0-11.fc6). 

Any ideas? Does upgrading to ATLAS 3.8 help?

Thanks in advance,

Carsten



From Roger.Bivand at nhh.no  Wed Oct 17 16:22:21 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 17 Oct 2007 16:22:21 +0200 (CEST)
Subject: [R-sig-Geo] Error loading rgdal package on Fedora 7
In-Reply-To: <1192630144.32633.6.camel@localhost.localdomain>
References: <1192630144.32633.6.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.64.0710171617590.4042@reclus.nhh.no>

On Wed, 17 Oct 2007, Carsten Jaeger wrote:

> Hello,
>
> I'm using R version 2.5.1 on Fedora 7. I just installed the rgdal
> package from source, compilation was without problems. However, when I
> try to load the package I get the following error message:
>
>> library(rgdal)
> Loading required package: rgdal
> Loading required package: sp
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
> 	unable to load shared library '/home/xxxx/R/rgdal/libs/rgdal.so':
>  /usr/lib/atlas/liblapack.so.3: undefined symbol: ATL_chemv
> [1] FALSE
>
> Obviously, liblapack.so.3 is incompatible with rgdal.so. ATLAS version
> is 3.6.0 which is the most current version available for F7 as rpm
> (atlas-3.6.0-11.fc6).

Where did your gdal come from? The rgdal package does not depend on 
lapack, nor as far as I know does gdal itself (it links against the gdal 
and proj4 shared objects). Can you use any of the gdal utilities, such as 
gdalinfo or ogrinfo from the command line?

I have a Fedora 7 box, installed gdal and rgdal from source, do not use 
ATLAS and have no lapack or blas RPMs after earlier version problems (R 
uses the one it is shipped with - but not for rgdal, I believe).

Roger

>
> Any ideas? Does upgrading to ATLAS 3.8 help?
>
> Thanks in advance,
>
> Carsten
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From jseavey at email.smith.edu  Wed Oct 17 16:47:31 2007
From: jseavey at email.smith.edu (Jennifer Seavey)
Date: Wed, 17 Oct 2007 10:47:31 -0400
Subject: [R-sig-Geo] moran's I correlogram
Message-ID: <4715E83B.2D9A.0026.0@email.smith.edu>

I am looking for R packages that create a moran's I correlogram with ordinal data.
my data format is x , y coordinates with a z values that ranges between 0-4.
another concern i have is that my sample size is 250 and over 60% have a z value of 0. So i am concerned that the uneven nature of the z values will show autocorrelation when it is simply a matter that most of the data points have this value.
Your advice/ thoughts are appreciated.
Thanks
Jenn



From cajaeg at googlemail.com  Wed Oct 17 16:55:31 2007
From: cajaeg at googlemail.com (Carsten Jaeger)
Date: Wed, 17 Oct 2007 16:55:31 +0200
Subject: [R-sig-Geo] Error loading rgdal package on Fedora 7
In-Reply-To: <Pine.LNX.4.64.0710171617590.4042@reclus.nhh.no>
References: <1192630144.32633.6.camel@localhost.localdomain>
	<Pine.LNX.4.64.0710171617590.4042@reclus.nhh.no>
Message-ID: <1192632931.32633.23.camel@localhost.localdomain>

On Wed, 2007-10-17 at 16:22 +0200, Roger Bivand wrote:
> On Wed, 17 Oct 2007, Carsten Jaeger wrote:
> 
> > Hello,
> >
> > I'm using R version 2.5.1 on Fedora 7. I just installed the rgdal
> > package from source, compilation was without problems. However, when I
> > try to load the package I get the following error message:
> >
> >> library(rgdal)
> > Loading required package: rgdal
> > Loading required package: sp
> > Error in dyn.load(x, as.logical(local), as.logical(now)) :
> > 	unable to load shared library '/home/xxxx/R/rgdal/libs/rgdal.so':
> >  /usr/lib/atlas/liblapack.so.3: undefined symbol: ATL_chemv
> > [1] FALSE
> >
> > Obviously, liblapack.so.3 is incompatible with rgdal.so. ATLAS version
> > is 3.6.0 which is the most current version available for F7 as rpm
> > (atlas-3.6.0-11.fc6).
> 
> Where did your gdal come from? The rgdal package does not depend on 
> lapack, nor as far as I know does gdal itself (it links against the gdal 
> and proj4 shared objects). Can you use any of the gdal utilities, such as 
> gdalinfo or ogrinfo from the command line?

Hello Roger, 

thanks four your fast response. gdal is also installed from rpm

$ rpm -q gdal gdal-devel
gdal-1.4.2-2.fc7
gdal-devel-1.4.2-2.fc7

ldd tells me that /usr/lib/libgdal.so.1 is linked against the liblapack from atlas:

$ ldd /usr/lib/libgdal.so.1 | grep lapack
liblapack.so.3 => /usr/lib/atlas/liblapack.so.3 (0x67e0f000)

And yes, gdalinfo and ogrinfo seem to work from the command line, at
least for some sample files (I'm just starting to use these tools and
have not tested them with every driver).

> 
> I have a Fedora 7 box, installed gdal and rgdal from source, do not use 
> ATLAS and have no lapack or blas RPMs after earlier version problems (R 
> uses the one it is shipped with - but not for rgdal, I believe).

So I'll have to build everything manually, I guess ...

> 
> Roger
> 
> >
> > Any ideas? Does upgrading to ATLAS 3.8 help?
> >
> > Thanks in advance,
> >
> > Carsten
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>



From Roger.Bivand at nhh.no  Wed Oct 17 17:03:50 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 17 Oct 2007 17:03:50 +0200 (CEST)
Subject: [R-sig-Geo] Error loading rgdal package on Fedora 7
In-Reply-To: <1192632931.32633.23.camel@localhost.localdomain>
References: <1192630144.32633.6.camel@localhost.localdomain> 
	<Pine.LNX.4.64.0710171617590.4042@reclus.nhh.no>
	<1192632931.32633.23.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.64.0710171658340.4042@reclus.nhh.no>

On Wed, 17 Oct 2007, Carsten Jaeger wrote:

> On Wed, 2007-10-17 at 16:22 +0200, Roger Bivand wrote:
>> On Wed, 17 Oct 2007, Carsten Jaeger wrote:
>>
>>> Hello,
>>>
>>> I'm using R version 2.5.1 on Fedora 7. I just installed the rgdal
>>> package from source, compilation was without problems. However, when I
>>> try to load the package I get the following error message:
>>>
>>>> library(rgdal)
>>> Loading required package: rgdal
>>> Loading required package: sp
>>> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>>> 	unable to load shared library '/home/xxxx/R/rgdal/libs/rgdal.so':
>>>  /usr/lib/atlas/liblapack.so.3: undefined symbol: ATL_chemv
>>> [1] FALSE
>>>
>>> Obviously, liblapack.so.3 is incompatible with rgdal.so. ATLAS version
>>> is 3.6.0 which is the most current version available for F7 as rpm
>>> (atlas-3.6.0-11.fc6).
>>
>> Where did your gdal come from? The rgdal package does not depend on
>> lapack, nor as far as I know does gdal itself (it links against the gdal
>> and proj4 shared objects). Can you use any of the gdal utilities, such as
>> gdalinfo or ogrinfo from the command line?
>
> Hello Roger,
>
> thanks four your fast response. gdal is also installed from rpm
>
> $ rpm -q gdal gdal-devel
> gdal-1.4.2-2.fc7
> gdal-devel-1.4.2-2.fc7
>
> ldd tells me that /usr/lib/libgdal.so.1 is linked against the liblapack from atlas:
>
> $ ldd /usr/lib/libgdal.so.1 | grep lapack
> liblapack.so.3 => /usr/lib/atlas/liblapack.so.3 (0x67e0f000)
>
> And yes, gdalinfo and ogrinfo seem to work from the command line, at
> least for some sample files (I'm just starting to use these tools and
> have not tested them with every driver).
>
>>
>> I have a Fedora 7 box, installed gdal and rgdal from source, do not use
>> ATLAS and have no lapack or blas RPMs after earlier version problems (R
>> uses the one it is shipped with - but not for rgdal, I believe).
>
> So I'll have to build everything manually, I guess ...

Yes, it looks as though the gdal rpm with its own lapack dependency may be 
conflicting with R's own? I cannot see a direct gdal -> lapack dependency 
on the GDAL site, maybe a build of a GRASS rpm with an unnecessary 
dependency on lapack (it is not used), and gdal depending on that?

Building from source does give the comfort of tailored software, suiting 
the machine platform (until one upgrades the platform, of course).

Roger

>
>>
>> Roger
>>
>>>
>>> Any ideas? Does upgrading to ATLAS 3.8 help?
>>>
>>> Thanks in advance,
>>>
>>> Carsten
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From cajaeg at googlemail.com  Wed Oct 17 17:15:44 2007
From: cajaeg at googlemail.com (Carsten Jaeger)
Date: Wed, 17 Oct 2007 17:15:44 +0200
Subject: [R-sig-Geo] Error loading rgdal package on Fedora 7
In-Reply-To: <Pine.LNX.4.64.0710171658340.4042@reclus.nhh.no>
References: <1192630144.32633.6.camel@localhost.localdomain>
	<Pine.LNX.4.64.0710171617590.4042@reclus.nhh.no>
	<1192632931.32633.23.camel@localhost.localdomain>
	<Pine.LNX.4.64.0710171658340.4042@reclus.nhh.no>
Message-ID: <1192634144.32633.27.camel@localhost.localdomain>


> Yes, it looks as though the gdal rpm with its own lapack dependency may be 
> conflicting with R's own? I cannot see a direct gdal -> lapack dependency 
> on the GDAL site, maybe a build of a GRASS rpm with an unnecessary 
> dependency on lapack (it is not used), and gdal depending on that?

Your assumption is correct, gdal.so.1 is also linked against various
grass libraries. I'll try to build a local gdal and use that for
building the rgdal package.

Thank again,

Carsten



From dw at life.ku.dk  Thu Oct 18 14:47:14 2007
From: dw at life.ku.dk (=?ISO-8859-15?Q?Dvora-Lai=F4=20Wulfsohn?=)
Date: Thu, 18 Oct 2007 14:47:14 +0200
Subject: [R-sig-Geo] Error message in spgwr :
	SpatialPointsDataFrame...row.names of	data and coords do not match
Message-ID: <4717725C.C6E5.00FB.0@life.ku.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071018/b56128e8/attachment.pl>

From Roger.Bivand at nhh.no  Thu Oct 18 15:08:37 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 18 Oct 2007 15:08:37 +0200 (CEST)
Subject: [R-sig-Geo] Error message in spgwr :
 SpatialPointsDataFrame...row.names of	data and coords do not match
In-Reply-To: <4717725C.C6E5.00FB.0@life.ku.dk>
References: <4717725C.C6E5.00FB.0@life.ku.dk>
Message-ID: <Pine.LNX.4.64.0710181459350.11150@reclus.nhh.no>

On Thu, 18 Oct 2007, Dvora-Lai? Wulfsohn wrote:

> Hi
>
> I am (newly) testing out the package spgwr to run GWR in R v. 2.5.1.
>
> I am trying to run the gwr() function with the following command:
>
> model1 <- gwr(Nfix.ma~peaDM.ma, data=gwr.dat, coords=gwr.loc, bandwidth=200,
> +               gweight=gwr.bisquare, hatmatrix=TRUE, se.fit=TRUE)
>
> and get no output, but only the Error message:
>
> Error in SpatialPointsDataFrame(coords = fit.points, data = df, proj4string = CRS(p4s)) :
>        row.names of data and coords do not match
>
> However, a check of rownames() in both my data (gwr.dat) and coords (gwr.loc) reveals no differences between the two.
>
> Perhaps, the error is due to something else altogether related to coordinates in the sp package?
>
> My gwr.loc is a 55x2 matrix (Easting, Northing, 55 locations) and the gwr.dat is a  33x55 data.frame (with the first two columns also containing the Easting, Northing data).

Please try to coerce gwr.dat to a SpatialPointsDataFrame, and omit the 
coords= argument:

coordinates(gwr.dat) <- c(1,2)

should do it. The coords= argument is only retained for backward 
compatibility. If you like, you can send the file from:

save(gwr.dat, gwr.loc, file="rownames_problem.RData")

to me off-list, so that I can trap this particular problem.

Roger

>
> Can anyone advise?
>
> Thanks,
>
> Dvor
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From loecher at eden.rutgers.edu  Thu Oct 18 17:25:04 2007
From: loecher at eden.rutgers.edu (Markus Loecher)
Date: Thu, 18 Oct 2007 11:25:04 -0400 (EDT)
Subject: [R-sig-Geo] estimating overdispersed spatial Poisson process
Message-ID: <33031963.539021192721104051.JavaMail.tomcat@terraza>

Dear R users,
I have a "spatial" (1D) grid of points; the hypothesis is that each is generating data according to an overdispersed Poisson prcoess with unknown parameters.
My question is twofold:
- Ignoring the spatial aspect, how can I estimate the two parameters independently for each grid point in R (using glm perhaps ? But how exactly)
- How would I include spatial correlations into this model ?

Thanks a lot,

Markus



From Roger.Bivand at nhh.no  Fri Oct 19 09:00:09 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 19 Oct 2007 09:00:09 +0200 (CEST)
Subject: [R-sig-Geo] moran's I correlogram
In-Reply-To: <4715E83B.2D9A.0026.0@email.smith.edu>
References: <4715E83B.2D9A.0026.0@email.smith.edu>
Message-ID: <Pine.LNX.4.64.0710190856150.14698@reclus.nhh.no>

On Wed, 17 Oct 2007, Jennifer Seavey wrote:

> I am looking for R packages that create a moran's I correlogram with 
> ordinal data. my data format is x , y coordinates with a z values that 
> ranges between 0-4. another concern i have is that my sample size is 250 
> and over 60% have a z value of 0. So i am concerned that the uneven 
> nature of the z values will show autocorrelation when it is simply a 
> matter that most of the data points have this value. Your advice/ 
> thoughts are appreciated. Thanks Jenn

Have you considered using join counts (joincount.multi() in spdep)? This 
avoids using the misleading metric in moran.test, but does not use the 
fact that a 3/4 join says more than a 0/4 join. This would have to be 
covered in the description of the output figure. Constructing weights 
lists for successive distance bands, it should be possible to plot a join 
count "correlogram".

Roger

>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From marco.helbich at gmx.at  Fri Oct 19 10:47:45 2007
From: marco.helbich at gmx.at (Marco Helbich)
Date: Fri, 19 Oct 2007 10:47:45 +0200
Subject: [R-sig-Geo] read gpx file
Message-ID: <20071019084745.252350@gmx.net>

Dear List,

the readGPS function from the maptools package is able to read waypoints from an 'attached GPS'. But what about reading gpx-fils, is there a function available to import such data? the OGR vector formats are not supporting it...

best regards,
Marco

--
Marco Helbich
Institute for Urban and Regional Research,
Austrian Academy of Sciences
Postgasse 7/4/2, A-1010 Vienna, Austria
mail: marco.helbich (at) oeaw.ac.at 
-- 
Ist Ihr Browser Vista-kompatibel? Jetzt die neuesten 
Browser-Versionen downloaden: http://www.gmx.net/de/go/browser



From Roger.Bivand at nhh.no  Fri Oct 19 10:59:37 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 19 Oct 2007 10:59:37 +0200 (CEST)
Subject: [R-sig-Geo] read gpx file
In-Reply-To: <20071019084745.252350@gmx.net>
References: <20071019084745.252350@gmx.net>
Message-ID: <Pine.LNX.4.64.0710191057300.14698@reclus.nhh.no>

On Fri, 19 Oct 2007, Marco Helbich wrote:

> Dear List,
>
> the readGPS function from the maptools package is able to read waypoints 
> from an 'attached GPS'. But what about reading gpx-fils, is there a 
> function available to import such data? the OGR vector formats are not 
> supporting it...

As you can see by looking at the code, the function is simply a wrapper 
for a system() call to gpsbabel. So there is no reason why the arguments 
could not be modified to tell gpsbabel to read a *.gpx file and write it 
to R - contributions welcome!

Roger

>
> best regards,
> Marco
>
> --
> Marco Helbich
> Institute for Urban and Regional Research,
> Austrian Academy of Sciences
> Postgasse 7/4/2, A-1010 Vienna, Austria
> mail: marco.helbich (at) oeaw.ac.at
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Agustin.Lobo at ija.csic.es  Fri Oct 19 11:02:15 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Fri, 19 Oct 2007 11:02:15 +0200
Subject: [R-sig-Geo] moran's I correlogram
In-Reply-To: <4715E83B.2D9A.0026.0@email.smith.edu>
References: <4715E83B.2D9A.0026.0@email.smith.edu>
Message-ID: <47187297.70802@ija.csic.es>

Jeniffer,

Lance Waller provides some code:
http://www.sph.emory.edu/~lwaller/ch7index.htm

Not sure if it would fit your particular requirement, though.

Agus

Jennifer Seavey escribi?:
> I am looking for R packages that create a moran's I correlogram with ordinal data.
> my data format is x , y coordinates with a z values that ranges between 0-4.
> another concern i have is that my sample size is 250 and over 60% have a z value of 0. So i am concerned that the uneven nature of the z values will show autocorrelation when it is simply a matter that most of the data points have this value.
> Your advice/ thoughts are appreciated.
> Thanks
> Jenn
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Agustin.Lobo at ija.csic.es  Mon Oct 22 16:31:40 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Mon, 22 Oct 2007 16:31:40 +0200
Subject: [R-sig-Geo] v.stats.rast for category raster or vector cross
	statistics
Message-ID: <471CB44C.4090807@ija.csic.es>

Dear lists,

Given Av (vector of polygons) and Br (raster of a categorical variable, 
i.e. a classification or a soil map) I want to calculate
for each polygon in Av, the surface of each category from Br.

v.stats.rast almost does it, but calculates lumped stats for each 
polygon (i.e, assumes that Br is a continuous variable).

Alternatively, I could have Br as another vector Bv, but don't find
the way of calculating cross stats as r.stats -a in=Ar,Br would do for 
raster layers.

Converting Av into raster Ar is inconvenient, as the polygons are few 
and small and would have to use a very samll cell size (Br is large)

Any easier way through R?

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From perrygeo at gmail.com  Mon Oct 22 17:22:18 2007
From: perrygeo at gmail.com (Matthew Perry)
Date: Mon, 22 Oct 2007 08:22:18 -0700
Subject: [R-sig-Geo] [STATSGRASS] v.stats.rast for category raster or
	vector cross statistics
In-Reply-To: <471CB44C.4090807@ija.csic.es>
References: <471CB44C.4090807@ija.csic.es>
Message-ID: <5383fa5e0710220822u5ee1ea37j9d5781ae2d631f1@mail.gmail.com>

Agustin,


I would suggest taking a look at starspan
(http://starspan.casil.ucdavis.edu/). It specializes in
vector-on-raster analyses and has a --count-by-class flag for
categorical rasters. I wrote a bit more about it at
http://www.perrygeo.net/wordpress/?p=30 .

- matt
 On 10/22/07, Agustin Lobo <Agustin.Lobo at ija.csic.es> wrote:
> Dear lists,
>
> Given Av (vector of polygons) and Br (raster of a categorical variable,
> i.e. a classification or a soil map) I want to calculate
> for each polygon in Av, the surface of each category from Br.
>
> v.stats.rast almost does it, but calculates lumped stats for each
> polygon (i.e, assumes that Br is a continuous variable).
>

> Alternatively, I could have Br as another vector Bv, but don't find
> the way of calculating cross stats as r.stats -a in=Ar,Br would do for
> raster layers.
>
> Converting Av into raster Ar is inconvenient, as the polygons are few
> and small and would have to use a very samll cell size (Br is large)
>
> Any easier way through R?
>
> --
> Dr. Agustin Lobo
> Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
> LLuis Sole Sabaris s/n
> 08028 Barcelona
> Spain
> Tel. 34 934095410
> Fax. 34 934110012
> email: Agustin.Lobo at ija.csic.es
> http://www.ija.csic.es/gt/obster
>
> _______________________________________________
> statsgrass mailing list
> statsgrass at grass.itc.it
> http://grass.itc.it/mailman/listinfo/statsgrass
>


-- 
Matthew T. Perry
http://www.perrygeo.net

"Never ascribe to malice, that which can be adequately explained by
incompetence."



From Roger.Bivand at nhh.no  Mon Oct 22 21:27:54 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 22 Oct 2007 21:27:54 +0200 (CEST)
Subject: [R-sig-Geo] [STATSGRASS] v.stats.rast for category raster or
 vector cross statistics
In-Reply-To: <5383fa5e0710220822u5ee1ea37j9d5781ae2d631f1@mail.gmail.com>
References: <471CB44C.4090807@ija.csic.es>
	<5383fa5e0710220822u5ee1ea37j9d5781ae2d631f1@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0710222123350.17661@reclus.nhh.no>

On Mon, 22 Oct 2007, Matthew Perry wrote:

> Agustin,
>
>
> I would suggest taking a look at starspan
> (http://starspan.casil.ucdavis.edu/). It specializes in
> vector-on-raster analyses and has a --count-by-class flag for
> categorical rasters. I wrote a bit more about it at
> http://www.perrygeo.net/wordpress/?p=30 .
>
> - matt
> On 10/22/07, Agustin Lobo <Agustin.Lobo at ija.csic.es> wrote:
>> Dear lists,
>>
>> Given Av (vector of polygons) and Br (raster of a categorical variable,
>> i.e. a classification or a soil map) I want to calculate
>> for each polygon in Av, the surface of each category from Br.
>>
>> v.stats.rast almost does it, but calculates lumped stats for each
>> polygon (i.e, assumes that Br is a continuous variable).
>>
>
>> Alternatively, I could have Br as another vector Bv, but don't find
>> the way of calculating cross stats as r.stats -a in=Ar,Br would do for
>> raster layers.
>>
>> Converting Av into raster Ar is inconvenient, as the polygons are few
>> and small and would have to use a very samll cell size (Br is large)
>>
>> Any easier way through R?

StarSpan is a good suggestion for heavy lifting. Within R, you could look 
at the overlay methods in sp to create a vector for polygon membership of 
raster size, then write a tapply function to accumulate tables with zero 
counts on categories by the polygon index.

Roger

>>
>> --
>> Dr. Agustin Lobo
>> Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
>> LLuis Sole Sabaris s/n
>> 08028 Barcelona
>> Spain
>> Tel. 34 934095410
>> Fax. 34 934110012
>> email: Agustin.Lobo at ija.csic.es
>> http://www.ija.csic.es/gt/obster
>>
>> _______________________________________________
>> statsgrass mailing list
>> statsgrass at grass.itc.it
>> http://grass.itc.it/mailman/listinfo/statsgrass
>>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From zev at zevross.com  Mon Oct 22 21:46:43 2007
From: zev at zevross.com (Zev Ross)
Date: Mon, 22 Oct 2007 19:46:43 +0000 (UTC)
Subject: [R-sig-Geo] spautolm or errorsarlm (and gstat question)
Message-ID: <loom.20071022T194410-997@post.gmane.org>

Hi All,

Just wondering if A) there is a prediction function
 associated with spautolm or B) if there is a way
to get the errorsarlm to accept the "weights" argument
similar to lm. As far as I can tell spautolm accepts 
non-spatial-weights but doesn't predict and 
errorsarlm predicts but doesn't accept "weights" 
is this true? And a somewhat unrelated question 
-- can someone tell me how, in R, to specify a nugget
that is half microscale variation and half measurement
error. I see in the GSTAT manual that it's possible, 
but I can't figure out the coding in R.

So if I have the following:

vgmRaw<-vgm(35, "Sph",range=1000,nugget=10)
vFitRaw<-fit.variogram(variogram(no2.ppb~1, 
data=x.oehha, width=250), model=vgmRaw,
  fit.method=2)

How do I make the nugget half and half?

Thank you! Zev



From Agustin.Lobo at ija.csic.es  Tue Oct 23 12:58:27 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Tue, 23 Oct 2007 12:58:27 +0200
Subject: [R-sig-Geo] SaTScan: (geo)graphical visualization in R?
Message-ID: <471DD3D3.3040104@ija.csic.es>

Has anyone written R scripts to visualize SaTScan output
or anything that could be useful as an starting point?
(just to avoid unnecessary work!)

SaTScan: http://www.satscan.org/

Agus

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From v.gomezrubio at imperial.ac.uk  Tue Oct 23 13:15:08 2007
From: v.gomezrubio at imperial.ac.uk (Virgilio Gomez-Rubio)
Date: Tue, 23 Oct 2007 12:15:08 +0100
Subject: [R-sig-Geo] SaTScan: (geo)graphical visualization in R?
In-Reply-To: <471DD3D3.3040104@ija.csic.es>
References: <471DD3D3.3040104@ija.csic.es>
Message-ID: <1193138108.1343.40.camel@fh-vrubio>

Dear Agustin,

We implemented some of these tests in DCLuster. I was planning to
include some functions to exploit the results from Kulldorff's test in
the next release, so any comments will be welcome.

Meanwhile, the way we presented the  results was to plot all the
centroids in a color (say, blue) and the centroids of the areas included
in the cluster in a different colour (red). Instead of just the
centroids you may prefer to fill areas in the cluster in a colour and
leave the others in white. 

But I guess that what you want is to import the results from SatScan,
right? I am afraid that I have done nothing about that.

Hope this helps.

Virgilio


On Tue, 2007-10-23 at 12:58 +0200, Agustin Lobo wrote:
> Has anyone written R scripts to visualize SaTScan output
> or anything that could be useful as an starting point?
> (just to avoid unnecessary work!)
> 
> SaTScan: http://www.satscan.org/
> 
> Agus
>



From Agustin.Lobo at ija.csic.es  Tue Oct 23 13:45:28 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Tue, 23 Oct 2007 13:45:28 +0200
Subject: [R-sig-Geo] SaTScan: (geo)graphical visualization in R?
In-Reply-To: <1193138108.1343.40.camel@fh-vrubio>
References: <471DD3D3.3040104@ija.csic.es> <1193138108.1343.40.camel@fh-vrubio>
Message-ID: <471DDED8.6010305@ija.csic.es>

Virgilio,

DCLuster is certainly a good alternative tool.
Perhaps another solution could be just reading SaTScan output
into R and making objects like those
in DCLuster, then using the same graphical tools. We'll see.

Thanks!

Agus

Virgilio Gomez-Rubio escribi?:
> Dear Agustin,
> 
> We implemented some of these tests in DCLuster. I was planning to
> include some functions to exploit the results from Kulldorff's test in
> the next release, so any comments will be welcome.
> 
> Meanwhile, the way we presented the  results was to plot all the
> centroids in a color (say, blue) and the centroids of the areas included
> in the cluster in a different colour (red). Instead of just the
> centroids you may prefer to fill areas in the cluster in a colour and
> leave the others in white. 
> 
> But I guess that what you want is to import the results from SatScan,
> right? I am afraid that I have done nothing about that.
> 
> Hope this helps.
> 
> Virgilio
> 
> 
> On Tue, 2007-10-23 at 12:58 +0200, Agustin Lobo wrote:
>> Has anyone written R scripts to visualize SaTScan output
>> or anything that could be useful as an starting point?
>> (just to avoid unnecessary work!)
>>
>> SaTScan: http://www.satscan.org/
>>
>> Agus
>>
> 
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Agustin.Lobo at ija.csic.es  Tue Oct 23 15:30:15 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Tue, 23 Oct 2007 15:30:15 +0200
Subject: [R-sig-Geo] overlay polygons (from shp) and raster (from geotif)
Message-ID: <471DF767.2050609@ija.csic.es>

Hi there!

I'm trying to do the overlay of polygons on raster.

I do:

pols <- readOGR("../AllTransectPolygons02", layer="AllTransectPolygons02")
a <- readGDAL("t1s2comb/t1s2combfim95.tif") #geotif file

str(a) shows the correct proj info:
   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
   .. .. ..@ projargs: chr " +proj=utm +zone=18 +south +ellps=WGS72 
+units=m +no_defs"

My goal is to get, for each polygon in pols,
the surface covered by each value of a.

Then:

delme <- overlay(pols, a)
delme
      AREA PERIMETER Site
NA     NA        NA <NA>
NA.1   NA        NA <NA>

which is not too useful and

delme2 <- overlay(a, pols)

takes for ever and what I finally get is:

 > str(delme2)
  num [1:207024] NA NA NA NA NA NA NA NA NA NA ...
 > delme2[!is.na(delme2)]
  [1]  86  86  86  86  87  87  87  87  88  88  88  88  89  89  89  89 
90  90
[19]  90  90  90  91  91  92  92  93  93  93  93  94  94  94  95  95  95  96
[37]  96  96  96  98 101 101 101 101 102 102 102 102 104 104 104 104 104 104
[55] 104 104 105 105 105 105 105 105 106 106 106 106

that is, just the ids of the polygons on the cells of a.

Note that the extent of pols is much larger than
the one of a (i.e., may polygons are outside the raster and I'm not
interested on those). Also, cells are much larger then the width of
the polygons (I can send a jpg with an example).

So it's clear I'm doing something wrong... any advice?

Thanks


-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Roger.Bivand at nhh.no  Tue Oct 23 16:14:45 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 23 Oct 2007 16:14:45 +0200 (CEST)
Subject: [R-sig-Geo] overlay polygons (from shp) and raster (from geotif)
In-Reply-To: <471DF767.2050609@ija.csic.es>
References: <471DF767.2050609@ija.csic.es>
Message-ID: <Pine.LNX.4.64.0710231559340.19559@reclus.nhh.no>

On Tue, 23 Oct 2007, Agustin Lobo wrote:

> Hi there!
>
> I'm trying to do the overlay of polygons on raster.
>
> I do:
>
> pols <- readOGR("../AllTransectPolygons02", layer="AllTransectPolygons02")
> a <- readGDAL("t1s2comb/t1s2combfim95.tif") #geotif file
>
> str(a) shows the correct proj info:
>   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>   .. .. ..@ projargs: chr " +proj=utm +zone=18 +south +ellps=WGS72
> +units=m +no_defs"
>
> My goal is to get, for each polygon in pols,
> the surface covered by each value of a.
>
> Then:
>
> delme <- overlay(pols, a)
> delme
>      AREA PERIMETER Site
> NA     NA        NA <NA>
> NA.1   NA        NA <NA>
>
> which is not too useful and
>
> delme2 <- overlay(a, pols)
>
> takes for ever and what I finally get is:
>
> > str(delme2)
>  num [1:207024] NA NA NA NA NA NA NA NA NA NA ...
> > delme2[!is.na(delme2)]
>  [1]  86  86  86  86  87  87  87  87  88  88  88  88  89  89  89  89
> 90  90
> [19]  90  90  90  91  91  92  92  93  93  93  93  94  94  94  95  95  95  96
> [37]  96  96  96  98 101 101 101 101 102 102 102 102 104 104 104 104 104 104
> [55] 104 104 105 105 105 105 105 105 106 106 106 106
>
> that is, just the ids of the polygons on the cells of a.

This is what you would need, using this column to make a 
SpatialPixelsDataFrame out of the input data, then doing a tapply or 
similar to tabulate the categories.

But with 200K cells, large cells, and small polygons, the point-in-polygon 
approach is converting the cells to their cell centre points, and missing 
most of the cell-polygon overlaps, that is those where the cell centre 
falls outside the polygon. Large cells and small polygons is not really 
the usual case. In addition, it might be helpful to subset pols first to 
avoid looping over polygons that cannot belong to a.

I'm not sure how starspan does polygon/cell overlay - if it measures the 
overlap area, you might find that more helpful. If not, reduce pols to the 
a area, and resample a to a finer resolution so that multiple cells fit 
inside each polygon (change g.region in GRASS, for example). It will take 
time to do, because it does a C point-in-polygon operation for each 
polygon (in nested lapply() calls).

Hope this helps,

Roger

>
> Note that the extent of pols is much larger than
> the one of a (i.e., may polygons are outside the raster and I'm not
> interested on those). Also, cells are much larger then the width of
> the polygons (I can send a jpg with an example).
>
> So it's clear I'm doing something wrong... any advice?
>
> Thanks
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Agustin.Lobo at ija.csic.es  Tue Oct 23 17:53:38 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Tue, 23 Oct 2007 17:53:38 +0200
Subject: [R-sig-Geo] overlay polygons (from shp) and raster (from geotif)
In-Reply-To: <Pine.LNX.4.64.0710231559340.19559@reclus.nhh.no>
References: <471DF767.2050609@ija.csic.es>
	<Pine.LNX.4.64.0710231559340.19559@reclus.nhh.no>
Message-ID: <471E1902.5010203@ija.csic.es>

Thanks,

but note that:

 > "Large cells and small
 > polygons is not really the usual case."

...except when you carry out ground work for satellite imagery!

According to the doc, starspan counts pixels intersected by the vector
provided the intersection is larger than a user-define threshold, thus 
would not solve the problem either (but have not actually tried it yet).

In R, may be I could
1. Vectorize the raster cells (only those that are not NA in delme), 
thus creating av.
2. Intersect the 2 polygons, thus creating a new set of polygons (pols2)
3. Use overlay with the new polygon pols2 and the vectorized version 
(av) of the raster a.

What do you think?

Agus


Roger Bivand escribi?:
> On Tue, 23 Oct 2007, Agustin Lobo wrote:
> 
>> Hi there!
>>
>> I'm trying to do the overlay of polygons on raster.
>>
>> I do:
>>
>> pols <- readOGR("../AllTransectPolygons02", 
>> layer="AllTransectPolygons02")
>> a <- readGDAL("t1s2comb/t1s2combfim95.tif") #geotif file
>>
>> str(a) shows the correct proj info:
>>   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>>   .. .. ..@ projargs: chr " +proj=utm +zone=18 +south +ellps=WGS72
>> +units=m +no_defs"
>>
>> My goal is to get, for each polygon in pols,
>> the surface covered by each value of a.
>>
>> Then:
>>
>> delme <- overlay(pols, a)
>> delme
>>      AREA PERIMETER Site
>> NA     NA        NA <NA>
>> NA.1   NA        NA <NA>
>>
>> which is not too useful and
>>
>> delme2 <- overlay(a, pols)
>>
>> takes for ever and what I finally get is:
>>
>> > str(delme2)
>>  num [1:207024] NA NA NA NA NA NA NA NA NA NA ...
>> > delme2[!is.na(delme2)]
>>  [1]  86  86  86  86  87  87  87  87  88  88  88  88  89  89  89  89
>> 90  90
>> [19]  90  90  90  91  91  92  92  93  93  93  93  94  94  94  95  95  
>> 95  96
>> [37]  96  96  96  98 101 101 101 101 102 102 102 102 104 104 104 104 
>> 104 104
>> [55] 104 104 105 105 105 105 105 105 106 106 106 106
>>
>> that is, just the ids of the polygons on the cells of a.
> 
> This is what you would need, using this column to make a 
> SpatialPixelsDataFrame out of the input data, then doing a tapply or 
> similar to tabulate the categories.
> 
> But with 200K cells, large cells, and small polygons, the 
> point-in-polygon approach is converting the cells to their cell centre 
> points, and missing most of the cell-polygon overlaps, that is those 
> where the cell centre falls outside the polygon. Large cells and small 
> polygons is not really the usual case. In addition, it might be helpful 
> to subset pols first to avoid looping over polygons that cannot belong 
> to a.
> 
> I'm not sure how starspan does polygon/cell overlay - if it measures the 
> overlap area, you might find that more helpful. If not, reduce pols to 
> the a area, and resample a to a finer resolution so that multiple cells 
> fit inside each polygon (change g.region in GRASS, for example). It will 
> take time to do, because it does a C point-in-polygon operation for each 
> polygon (in nested lapply() calls).
> 
> Hope this helps,
> 
> Roger
> 
>>
>> Note that the extent of pols is much larger than
>> the one of a (i.e., may polygons are outside the raster and I'm not
>> interested on those). Also, cells are much larger then the width of
>> the polygons (I can send a jpg with an example).
>>
>> So it's clear I'm doing something wrong... any advice?
>>
>> Thanks
>>
>>
>>
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Roger.Bivand at nhh.no  Tue Oct 23 20:17:13 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 23 Oct 2007 20:17:13 +0200 (CEST)
Subject: [R-sig-Geo] overlay polygons (from shp) and raster (from geotif)
In-Reply-To: <471E1902.5010203@ija.csic.es>
References: <471DF767.2050609@ija.csic.es>
	<Pine.LNX.4.64.0710231559340.19559@reclus.nhh.no>
	<471E1902.5010203@ija.csic.es>
Message-ID: <Pine.LNX.4.64.0710232011520.19559@reclus.nhh.no>

On Tue, 23 Oct 2007, Agustin Lobo wrote:

> Thanks,
>
> but note that:
>
>>  "Large cells and small
>>  polygons is not really the usual case."
>
> ...except when you carry out ground work for satellite imagery!
>
> According to the doc, starspan counts pixels intersected by the vector
> provided the intersection is larger than a user-define threshold, thus would 
> not solve the problem either (but have not actually tried it yet).
>
> In R, may be I could
> 1. Vectorize the raster cells (only those that are not NA in delme), thus 
> creating av.

There are facilities in sp for this - to make SpatialPolygons from 
SpatialPixels.

> 2. Intersect the 2 polygons, thus creating a new set of polygons (pols2)

This would possibly involve using gpclib directly - there is code in 
maptools for going between SpatialPolygons and the gpclib representation, 
but it is still inside functions.

> 3. Use overlay with the new polygon pols2 and the vectorized version (av) of 
> the raster a.

There is no polygon/polygon overlay method in sp - you'd need to keep 
track of which polygon is which in step 2.

I think I still prefer resampling a in a GIS to a higher resolution and 
using what exists.

Roger

>
> What do you think?
>
> Agus
>
>
> Roger Bivand escribi?:
>>  On Tue, 23 Oct 2007, Agustin Lobo wrote:
>> 
>> >  Hi there!
>> > 
>> >  I'm trying to do the overlay of polygons on raster.
>> > 
>> >  I do:
>> > 
>> >  pols <- readOGR("../AllTransectPolygons02", 
>> >  layer="AllTransectPolygons02")
>> >  a <- readGDAL("t1s2comb/t1s2combfim95.tif") #geotif file
>> > 
>> >  str(a) shows the correct proj info:
>> >    ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>> >    .. .. ..@ projargs: chr " +proj=utm +zone=18 +south +ellps=WGS72
>> >  +units=m +no_defs"
>> > 
>> >  My goal is to get, for each polygon in pols,
>> >  the surface covered by each value of a.
>> > 
>> >  Then:
>> > 
>> >  delme <- overlay(pols, a)
>> >  delme
>> >       AREA PERIMETER Site
>> >  NA     NA        NA <NA>
>> >  NA.1   NA        NA <NA>
>> > 
>> >  which is not too useful and
>> > 
>> >  delme2 <- overlay(a, pols)
>> > 
>> >  takes for ever and what I finally get is:
>> > 
>> > >  str(delme2)
>> >   num [1:207024] NA NA NA NA NA NA NA NA NA NA ...
>> > >  delme2[!is.na(delme2)]
>> >  [1]  86  86  86  86  87  87  87  87  88  88  88  88  89  89  89  89
>> >  90  90
>> >  [19]  90  90  90  91  91  92  92  93  93  93  93  94  94  94  95  95  95 
>> >  96
>> >  [37]  96  96  96  98 101 101 101 101 102 102 102 102 104 104 104 104 104 
>> >  104
>> >  [55] 104 104 105 105 105 105 105 105 106 106 106 106
>> > 
>> >  that is, just the ids of the polygons on the cells of a.
>>
>>  This is what you would need, using this column to make a
>>  SpatialPixelsDataFrame out of the input data, then doing a tapply or
>>  similar to tabulate the categories.
>>
>>  But with 200K cells, large cells, and small polygons, the point-in-polygon
>>  approach is converting the cells to their cell centre points, and missing
>>  most of the cell-polygon overlaps, that is those where the cell centre
>>  falls outside the polygon. Large cells and small polygons is not really
>>  the usual case. In addition, it might be helpful to subset pols first to
>>  avoid looping over polygons that cannot belong to a.
>>
>>  I'm not sure how starspan does polygon/cell overlay - if it measures the
>>  overlap area, you might find that more helpful. If not, reduce pols to the
>>  a area, and resample a to a finer resolution so that multiple cells fit
>>  inside each polygon (change g.region in GRASS, for example). It will take
>>  time to do, because it does a C point-in-polygon operation for each
>>  polygon (in nested lapply() calls).
>>
>>  Hope this helps,
>>
>>  Roger
>> 
>> > 
>> >  Note that the extent of pols is much larger than
>> >  the one of a (i.e., may polygons are outside the raster and I'm not
>> >  interested on those). Also, cells are much larger then the width of
>> >  the polygons (I can send a jpg with an example).
>> > 
>> >  So it's clear I'm doing something wrong... any advice?
>> > 
>> >  Thanks
>> > 
>> > 
>> >
>> 
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From paallen at attglobal.net  Wed Oct 24 03:34:17 2007
From: paallen at attglobal.net (paallen at attglobal.net)
Date: Wed, 24 Oct 2007 01:34:17 +0000
Subject: [R-sig-Geo] Export akima grid with gdal
Message-ID: <200710240134.l9O1YHBR015609@hypatia.math.ethz.ch>

Hi all,

I have gridded some data using akima's
interp.new() function.  I now want to export to
something that ArcGIS can read directly.  I was
thinking about something like a geotiff, or a
simple bil.

How do I export this akima list object using gdal?
 In know that I have to convert the list to a
spatialgrid but I just cannot manage it.

thanks,

Phillip J. Allen
Geochemist.



From mdsumner at utas.edu.au  Wed Oct 24 03:56:19 2007
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Wed, 24 Oct 2007 12:56:19 +1100
Subject: [R-sig-Geo] Export akima grid with gdal
Message-ID: <200710240156.l9O1uJTN015088@corinna.its.utas.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071024/bbcb9681/attachment.pl>

From evakaiserseder at hotmail.com  Wed Oct 24 08:31:53 2007
From: evakaiserseder at hotmail.com (Eva Kaiserseder)
Date: Wed, 24 Oct 2007 08:31:53 +0200
Subject: [R-sig-Geo] plotting kernel density estimations
Message-ID: <BLU104-W22060518AD70A97E1D3570DF940@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071024/4da5a855/attachment.pl>

From Agustin.Lobo at ija.csic.es  Wed Oct 24 09:06:29 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Wed, 24 Oct 2007 09:06:29 +0200
Subject: [R-sig-Geo] overlay polygons (from shp) and raster (from geotif)
In-Reply-To: <Pine.LNX.4.64.0710232011520.19559@reclus.nhh.no>
References: <471DF767.2050609@ija.csic.es>
	<Pine.LNX.4.64.0710231559340.19559@reclus.nhh.no>
	<471E1902.5010203@ija.csic.es>
	<Pine.LNX.4.64.0710232011520.19559@reclus.nhh.no>
Message-ID: <471EEEF5.60808@ija.csic.es>

Roger,

A raster with the required resolution would be huge, although I can make 
an script setting the region for each polygon, doing the operation and
combining all the tables afterwards. This is an alternative.

But I still think that a vector-based solution is more appropriate for 
this problem. I thought I could use joinPolys from PBSmapping, it has an
intersection operator.

My problem is that I've not found the way of making SpatialPolygons from
SpatialPixels as you suggest. I've tried with adehabitat, but getcontour 
loses isolated pixels and does not transfer pixel values to the 
polygons. How could I convert the  "SpatialGridDataFrame" into an 
SpatialPolygons object? Then I would need to convert to PBSmapping 
Polysets...

BTW, there is no vector intersection in grass either, am I wrong?

Thanks,

Agus

Roger Bivand escribi?:
> On Tue, 23 Oct 2007, Agustin Lobo wrote:
> 
>> Thanks,
>>
>> but note that:
>>
>>>  "Large cells and small
>>>  polygons is not really the usual case."
>>
>> ...except when you carry out ground work for satellite imagery!
>>
>> According to the doc, starspan counts pixels intersected by the vector
>> provided the intersection is larger than a user-define threshold, thus 
>> would not solve the problem either (but have not actually tried it yet).
>>
>> In R, may be I could
>> 1. Vectorize the raster cells (only those that are not NA in delme), 
>> thus creating av.
> 
> There are facilities in sp for this - to make SpatialPolygons from 
> SpatialPixels.
> 
>> 2. Intersect the 2 polygons, thus creating a new set of polygons (pols2)
> 
> This would possibly involve using gpclib directly - there is code in 
> maptools for going between SpatialPolygons and the gpclib 
> representation, but it is still inside functions.
> 
>> 3. Use overlay with the new polygon pols2 and the vectorized version 
>> (av) of the raster a.
> 
> There is no polygon/polygon overlay method in sp - you'd need to keep 
> track of which polygon is which in step 2.
> 
> I think I still prefer resampling a in a GIS to a higher resolution and 
> using what exists.
> 
> Roger
> 
>>
>> What do you think?
>>
>> Agus
>>
>>
>> Roger Bivand escribi?:
>>>  On Tue, 23 Oct 2007, Agustin Lobo wrote:
>>>
>>> >  Hi there!
>>> > >  I'm trying to do the overlay of polygons on raster.
>>> > >  I do:
>>> > >  pols <- readOGR("../AllTransectPolygons02", >  
>>> layer="AllTransectPolygons02")
>>> >  a <- readGDAL("t1s2comb/t1s2combfim95.tif") #geotif file
>>> > >  str(a) shows the correct proj info:
>>> >    ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>>> >    .. .. ..@ projargs: chr " +proj=utm +zone=18 +south +ellps=WGS72
>>> >  +units=m +no_defs"
>>> > >  My goal is to get, for each polygon in pols,
>>> >  the surface covered by each value of a.
>>> > >  Then:
>>> > >  delme <- overlay(pols, a)
>>> >  delme
>>> >       AREA PERIMETER Site
>>> >  NA     NA        NA <NA>
>>> >  NA.1   NA        NA <NA>
>>> > >  which is not too useful and
>>> > >  delme2 <- overlay(a, pols)
>>> > >  takes for ever and what I finally get is:
>>> > > >  str(delme2)
>>> >   num [1:207024] NA NA NA NA NA NA NA NA NA NA ...
>>> > >  delme2[!is.na(delme2)]
>>> >  [1]  86  86  86  86  87  87  87  87  88  88  88  88  89  89  89  89
>>> >  90  90
>>> >  [19]  90  90  90  91  91  92  92  93  93  93  93  94  94  94  95  
>>> 95  95 >  96
>>> >  [37]  96  96  96  98 101 101 101 101 102 102 102 102 104 104 104 
>>> 104 104 >  104
>>> >  [55] 104 104 105 105 105 105 105 105 106 106 106 106
>>> > >  that is, just the ids of the polygons on the cells of a.
>>>
>>>  This is what you would need, using this column to make a
>>>  SpatialPixelsDataFrame out of the input data, then doing a tapply or
>>>  similar to tabulate the categories.
>>>
>>>  But with 200K cells, large cells, and small polygons, the 
>>> point-in-polygon
>>>  approach is converting the cells to their cell centre points, and 
>>> missing
>>>  most of the cell-polygon overlaps, that is those where the cell centre
>>>  falls outside the polygon. Large cells and small polygons is not really
>>>  the usual case. In addition, it might be helpful to subset pols 
>>> first to
>>>  avoid looping over polygons that cannot belong to a.
>>>
>>>  I'm not sure how starspan does polygon/cell overlay - if it measures 
>>> the
>>>  overlap area, you might find that more helpful. If not, reduce pols 
>>> to the
>>>  a area, and resample a to a finer resolution so that multiple cells fit
>>>  inside each polygon (change g.region in GRASS, for example). It will 
>>> take
>>>  time to do, because it does a C point-in-polygon operation for each
>>>  polygon (in nested lapply() calls).
>>>
>>>  Hope this helps,
>>>
>>>  Roger
>>>
>>> > >  Note that the extent of pols is much larger than
>>> >  the one of a (i.e., may polygons are outside the raster and I'm not
>>> >  interested on those). Also, cells are much larger then the width of
>>> >  the polygons (I can send a jpg with an example).
>>> > >  So it's clear I'm doing something wrong... any advice?
>>> > >  Thanks
>>> > > >
>>>
>>
>>
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Roger.Bivand at nhh.no  Wed Oct 24 09:37:15 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 24 Oct 2007 09:37:15 +0200 (CEST)
Subject: [R-sig-Geo] Export akima grid with gdal
In-Reply-To: <200710240156.l9O1uJTN015088@corinna.its.utas.edu.au>
References: <200710240156.l9O1uJTN015088@corinna.its.utas.edu.au>
Message-ID: <Pine.LNX.4.64.0710240934190.10352@reclus.nhh.no>

On Wed, 24 Oct 2007, Michael Sumner wrote:

> Hi, not sure if sp already has something like this, but it's fairly
> simple anyway. I have this function in the package "trip". "x" is a
> standard R XYZ list object, as expected by image():
>
>
> image2Grid <-
> function (x, p4 = NA)
> {
>    if (!all(names(x) %in% c("x", "y", "z")))
>        stop("image must have components x, y, and z")
>    cells.dim <- dim(x$z)
>    xx <- x$x
>    yy <- x$y
>    lx <- length(xx)
>    ly <- length(yy)
>    if (all(c(lx, ly) == (cells.dim + 1))) {
>        print("corners")
>        xx <- xx[-1] - diff(xx[1:2])/2
>        yy <- yy[-1] - diff(yy[1:2])/2
>    }
>    SpatialGridDataFrame(GridTopology(c(xx[1], yy[1]), c(diff(xx[1:2]),
>        diff(yy[1:2])), cells.dim), data.frame(z = as.vector(x$z[,
>        ncol(x$z):1])), proj4string = CRS(p4))
> }

There is a method to coerce from a matrix to a SpatialGridDataFrame, but 
not for the (x, y, z) list case - if it would be sensible, and if you 
agree, we could easily add it.

Roger


>
>
> ==============Original message text===============
> On Wed, 24 Oct 2007 12:34:17 +1100 paallen at attglobal.net wrote:
>
> Hi all,
>
> I have gridded some data using akima's
> interp.new() function.  I now want to export to
> something that ArcGIS can read directly.  I was
> thinking about something like a geotiff, or a
> simple bil.
>
> How do I export this akima list object using gdal?
> In know that I have to convert the list to a
> spatialgrid but I just cannot manage it.
>
> thanks,
>
> Phillip J. Allen
> Geochemist.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> ===========End of original message text===========
>
>
>
> If it wasn't backed-up, then it wasn't important. ~ Anon sysadmin
>
> Mike Sumner (Phd. Candidate)
> http://www.antcrc.utas.edu.au/~mdsumner/ http://www.zoo.utas.edu.au/awru/  IASOS/AWRU
> University of Tasmania
> Private Bag 80
> Hobart Tasmania 7001
> AUSTRALIA
> Email: mdsumner at utas.edu.au
> Phone: 03 6226 1752 (W)
>       0408599921   (M)
> Fax:   03 6226 2745
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Wed Oct 24 09:52:57 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 24 Oct 2007 09:52:57 +0200 (CEST)
Subject: [R-sig-Geo] plotting kernel density estimations
In-Reply-To: <BLU104-W22060518AD70A97E1D3570DF940@phx.gbl>
References: <BLU104-W22060518AD70A97E1D3570DF940@phx.gbl>
Message-ID: <Pine.LNX.4.64.0710240947390.10352@reclus.nhh.no>

On Wed, 24 Oct 2007, Eva Kaiserseder wrote:

>
> Dear List, thank you for your last reply! Sorry, but here's another 
> one.I've 4 Kernel Density Estimations (with splancs: spkernel2d()) and 
> want to plot them altogether (2x2).In this case the spplot-function 
> doesn't work very well, because only one legend/range of value grouping 
> is possible.Also the par(mfrow=c(2,2) and layout(matrix(c(1,2,3,4), 2, 
> 2)) doesn't work and plots only one over all subplots.Any suggestions? 
> Best regardsEva--

(Please do not use HTML in your postings, just plain text)

Do not combine par(mfrow=c()) and layout() - use either one or the other 
unless you actually want to mix them up. Using par(mfrow=c()) should be 
sufficient. In fact, if your density maps are for the same variable but 
with different bandwidths, you need to look at the at=, cuts=, and/or 
col.regions= arguments to spplot(). If for different variables, then your 
choice of par(mfrow=c()) looks OK.

Roger

>
> _________________________________________________________________
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Wed Oct 24 10:17:44 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 24 Oct 2007 10:17:44 +0200 (CEST)
Subject: [R-sig-Geo] overlay polygons (from shp) and raster (from geotif)
In-Reply-To: <471EEEF5.60808@ija.csic.es>
References: <471DF767.2050609@ija.csic.es>
	<Pine.LNX.4.64.0710231559340.19559@reclus.nhh.no>
	<471E1902.5010203@ija.csic.es>
	<Pine.LNX.4.64.0710232011520.19559@reclus.nhh.no>
	<471EEEF5.60808@ija.csic.es>
Message-ID: <Pine.LNX.4.64.0710240954340.10352@reclus.nhh.no>

On Wed, 24 Oct 2007, Agustin Lobo wrote:

> Roger,
>
> A raster with the required resolution would be huge, although I can make an 
> script setting the region for each polygon, doing the operation and
> combining all the tables afterwards. This is an alternative.

Look at something like this to get a list of bounding boxes:

lapply(slot(pols, "polygons"), function(x) sp:::bbox.Polygons(x))

which you could run out through g.region to set high resolution for each 
Polygons object in turn.

>
> But I still think that a vector-based solution is more appropriate for this 
> problem. I thought I could use joinPolys from PBSmapping, it has an
> intersection operator.
>
> My problem is that I've not found the way of making SpatialPolygons from
> SpatialPixels as you suggest.

as(as(a, "SpatialPixels"), "SpatialPolygons")

or equivalently

sp:::as.SpatialPolygons.SpatialPixels

but you need to watch the IDs.

> I've tried with adehabitat, but getcontour loses isolated pixels and 
> does not transfer pixel values to the polygons. How could I convert the 
> "SpatialGridDataFrame" into an SpatialPolygons object? Then I would need 
> to convert to PBSmapping Polysets...
>

I would go straight to gpclib, which is what PBSmapping is using (in its 
own form) internally.

For each Polygons object (slot(polys, "polygons")), find the raster cells 
that intersect the bounding box of the object. Build gpclib polygon 
rectangles by hand, and intersect with the Polygons object using code from 
maptools, for example from checkPolygonsHoles(), to build the gpclib 
objects. Then analyse the result to retrieve the intersections, possibly 
by area.

> BTW, there is no vector intersection in grass either, am I wrong?
>

I think that there is v.overlay in 6.2 and 6.3 CVS, which might work from 
r.to.vect (without corner smoothing), but I do not know how you will be 
able to count the raster categories.

Roger

> Thanks,
>
> Agus
>
> Roger Bivand escribi?:
>>  On Tue, 23 Oct 2007, Agustin Lobo wrote:
>> 
>> >  Thanks,
>> > 
>> >  but note that:
>> > 
>> > >   "Large cells and small
>> > >   polygons is not really the usual case."
>> > 
>> >  ...except when you carry out ground work for satellite imagery!
>> > 
>> >  According to the doc, starspan counts pixels intersected by the vector
>> >  provided the intersection is larger than a user-define threshold, thus 
>> >  would not solve the problem either (but have not actually tried it yet).
>> > 
>> >  In R, may be I could
>> >  1. Vectorize the raster cells (only those that are not NA in delme), 
>> >  thus creating av.
>>
>>  There are facilities in sp for this - to make SpatialPolygons from
>>  SpatialPixels.
>> 
>> >  2. Intersect the 2 polygons, thus creating a new set of polygons (pols2)
>>
>>  This would possibly involve using gpclib directly - there is code in
>>  maptools for going between SpatialPolygons and the gpclib representation,
>>  but it is still inside functions.
>> 
>> >  3. Use overlay with the new polygon pols2 and the vectorized version 
>> >  (av) of the raster a.
>>
>>  There is no polygon/polygon overlay method in sp - you'd need to keep
>>  track of which polygon is which in step 2.
>>
>>  I think I still prefer resampling a in a GIS to a higher resolution and
>>  using what exists.
>>
>>  Roger
>> 
>> > 
>> >  What do you think?
>> > 
>> >  Agus
>> > 
>> > 
>> >  Roger Bivand escribi?:
>> > >   On Tue, 23 Oct 2007, Agustin Lobo wrote:
>> > > 
>> > > >   Hi there!
>> > > > >   I'm trying to do the overlay of polygons on raster.
>> > > > >   I do:
>> > > > >   pols <- readOGR("../AllTransectPolygons02", > 
>> > >  layer="AllTransectPolygons02")
>> > > >   a <- readGDAL("t1s2comb/t1s2combfim95.tif") #geotif file
>> > > > >   str(a) shows the correct proj info:
>> > > >     ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>> > > >     .. .. ..@ projargs: chr " +proj=utm +zone=18 +south +ellps=WGS72
>> > > >   +units=m +no_defs"
>> > > > >   My goal is to get, for each polygon in pols,
>> > > >   the surface covered by each value of a.
>> > > > >   Then:
>> > > > >   delme <- overlay(pols, a)
>> > > >   delme
>> > > >        AREA PERIMETER Site
>> > > >   NA     NA        NA <NA>
>> > > >   NA.1   NA        NA <NA>
>> > > > >   which is not too useful and
>> > > > >   delme2 <- overlay(a, pols)
>> > > > >   takes for ever and what I finally get is:
>> > > > > >   str(delme2)
>> > > >    num [1:207024] NA NA NA NA NA NA NA NA NA NA ...
>> > > > >   delme2[!is.na(delme2)]
>> > > >   [1]  86  86  86  86  87  87  87  87  88  88  88  88  89  89  89  89
>> > > >   90  90
>> > > >   [19]  90  90  90  91  91  92  92  93  93  93  93  94  94  94  95 
>> > >  95  95 >  96
>> > > >   [37]  96  96  96  98 101 101 101 101 102 102 102 102 104 104 104 
>> > >  104 104 >  104
>> > > >   [55] 104 104 105 105 105 105 105 105 106 106 106 106
>> > > > >   that is, just the ids of the polygons on the cells of a.
>> > > 
>> > >   This is what you would need, using this column to make a
>> > >   SpatialPixelsDataFrame out of the input data, then doing a tapply or
>> > >   similar to tabulate the categories.
>> > > 
>> > >  But with 200K cells, large cells, and small polygons, the 
>> > >  point-in-polygon
>> > >  approach is converting the cells to their cell centre points, and 
>> > >  missing
>> > >   most of the cell-polygon overlaps, that is those where the cell 
>> > >   centre
>> > >   falls outside the polygon. Large cells and small polygons is not 
>> > >   really
>> > >   the usual case. In addition, it might be helpful to subset pols 
>> > >  first to
>> > >   avoid looping over polygons that cannot belong to a.
>> > > 
>> > >  I'm not sure how starspan does polygon/cell overlay - if it measures 
>> > >  the
>> > >  overlap area, you might find that more helpful. If not, reduce pols to 
>> > >  the
>> > >   a area, and resample a to a finer resolution so that multiple cells 
>> > >   fit
>> > >   inside each polygon (change g.region in GRASS, for example). It will 
>> > >  take
>> > >   time to do, because it does a C point-in-polygon operation for each
>> > >   polygon (in nested lapply() calls).
>> > > 
>> > >   Hope this helps,
>> > > 
>> > >   Roger
>> > > 
>> > > > >   Note that the extent of pols is much larger than
>> > > >   the one of a (i.e., may polygons are outside the raster and I'm not
>> > > >   interested on those). Also, cells are much larger then the width of
>> > > >   the polygons (I can send a jpg with an example).
>> > > > >   So it's clear I'm doing something wrong... any advice?
>> > > > >   Thanks
>> > > > > > 
>> > > 
>> > 
>> >
>> 
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From mdsumner at utas.edu.au  Wed Oct 24 13:19:07 2007
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Wed, 24 Oct 2007 22:19:07 +1100
Subject: [R-sig-Geo] Export akima grid with gdal
In-Reply-To: <Pine.LNX.4.64.0710240934190.10352@reclus.nhh.no>
References: <200710240156.l9O1uJTN015088@corinna.its.utas.edu.au>
	<Pine.LNX.4.64.0710240934190.10352@reclus.nhh.no>
Message-ID: <471F2A2B.2030805@utas.edu.au>

I have used that function many times with no apparent problems, so I 
would be more than happy for it to be included in the sp suite! 

Cheers, Mike.


Roger Bivand wrote:
> On Wed, 24 Oct 2007, Michael Sumner wrote:
>
>> Hi, not sure if sp already has something like this, but it's fairly
>> simple anyway. I have this function in the package "trip". "x" is a
>> standard R XYZ list object, as expected by image():
>>
>>
>> image2Grid <-
>> function (x, p4 = NA)
>> {
>>    if (!all(names(x) %in% c("x", "y", "z")))
>>        stop("image must have components x, y, and z")
>>    cells.dim <- dim(x$z)
>>    xx <- x$x
>>    yy <- x$y
>>    lx <- length(xx)
>>    ly <- length(yy)
>>    if (all(c(lx, ly) == (cells.dim + 1))) {
>>        print("corners")
>>        xx <- xx[-1] - diff(xx[1:2])/2
>>        yy <- yy[-1] - diff(yy[1:2])/2
>>    }
>>    SpatialGridDataFrame(GridTopology(c(xx[1], yy[1]), c(diff(xx[1:2]),
>>        diff(yy[1:2])), cells.dim), data.frame(z = as.vector(x$z[,
>>        ncol(x$z):1])), proj4string = CRS(p4))
>> }
>
> There is a method to coerce from a matrix to a SpatialGridDataFrame, 
> but not for the (x, y, z) list case - if it would be sensible, and if 
> you agree, we could easily add it.
>
> Roger
>
>
>>
>>
>> ==============Original message text===============
>> On Wed, 24 Oct 2007 12:34:17 +1100 paallen at attglobal.net wrote:
>>
>> Hi all,
>>
>> I have gridded some data using akima's
>> interp.new() function.  I now want to export to
>> something that ArcGIS can read directly.  I was
>> thinking about something like a geotiff, or a
>> simple bil.
>>
>> How do I export this akima list object using gdal?
>> In know that I have to convert the list to a
>> spatialgrid but I just cannot manage it.
>>
>> thanks,
>>
>> Phillip J. Allen
>> Geochemist.
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> ===========End of original message text===========
>>
>>
>>
>> If it wasn't backed-up, then it wasn't important. ~ Anon sysadmin
>>
>> Mike Sumner (Phd. Candidate)
>> http://www.antcrc.utas.edu.au/~mdsumner/ 
>> http://www.zoo.utas.edu.au/awru/  IASOS/AWRU
>> University of Tasmania
>> Private Bag 80
>> Hobart Tasmania 7001
>> AUSTRALIA
>> Email: mdsumner at utas.edu.au
>> Phone: 03 6226 1752 (W)
>>       0408599921   (M)
>> Fax:   03 6226 2745
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>



From Agustin.Lobo at ija.csic.es  Thu Oct 25 10:39:56 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Thu, 25 Oct 2007 10:39:56 +0200
Subject: [R-sig-Geo] identify for SpatialGridDataFrame objects?
Message-ID: <4720565C.2030407@ija.csic.es>

Is it possible to display a SpatialGridDataFrame object
and use identify() to check values? I've tried after displaying
with image() and always get
warning: no point with 0.25 inches

This is what I do:
image(delme.cl.im, col = bpy.colors(n=10))

identify(delme.cl.im at data$band1)

If I use
identify(delme.cl.im)
I get:
Error in as.double(y) : cannot coerce to vector


Thanks!

Agus
-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From marcelino.delacruz at upm.es  Thu Oct 25 11:05:43 2007
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Thu, 25 Oct 2007 11:05:43 +0200
Subject: [R-sig-Geo] identify for SpatialGridDataFrame objects?
In-Reply-To: <4720565C.2030407@ija.csic.es>
References: <4720565C.2030407@ija.csic.es>
Message-ID: <6.1.2.0.1.20071025110217.02113210@correo.upm.es>

Agus:

I don't konw the structure of  "delme.cl.im", but with the 
SpatialGridDataFrame example of meuse:

data(meuse.grid) # only the non-missing valued cells
coordinates(meuse.grid) = c("x", "y") # promote to SpatialPointsDataFrame
gridded(meuse.grid) <- TRUE # promote to SpatialPixelsDataFrame
x = as(meuse.grid, "SpatialGridDataFrame") # creates the full grid
x[["idist"]] = 1 - x[["dist"]] # assigns new attribute
image(x["idist"]) # note the single [ for attribute selection


identify(coordinates(x), labels=x$idist)
works fine.

Hope this helps,


Marcelino



At 10:39 25/10/2007, Agustin Lobo wrote:
>Is it possible to display a SpatialGridDataFrame object
>and use identify() to check values? I've tried after displaying
>with image() and always get
>warning: no point with 0.25 inches
>
>This is what I do:
>image(delme.cl.im, col = bpy.colors(n=10))
>
>identify(delme.cl.im at data$band1)
>
>If I use
>identify(delme.cl.im)
>I get:
>Error in as.double(y) : cannot coerce to vector
>
>
>Thanks!
>
>Agus
>--
>Dr. Agustin Lobo
>Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
>LLuis Sole Sabaris s/n
>08028 Barcelona
>Spain
>Tel. 34 934095410
>Fax. 34 934110012
>email: Agustin.Lobo at ija.csic.es
>http://www.ija.csic.es/gt/obster
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at stat.math.ethz.ch
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo


***************************************
Marcelino de la Cruz Rot
Depto. Biologia Vegetal
ETS Ingenieros Agronomos
Universidad Politecnica de Madrid
28040-Madrid
SPAIN



From bulten at netmarkpatent.com  Thu Oct 25 14:22:43 2007
From: bulten at netmarkpatent.com (NETMARK PATENT)
Date: Thu, 25 Oct 2007 15:22:43 +0300
Subject: [R-sig-Geo] =?windows-1254?q?Netmark_Patent=2C_NETMARK_KOB=DD_ile?=
	=?windows-1254?q?_Sekt=F6re_Yeni_Bir_Soluk_Getiriyor!?=
Message-ID: <3844-2200710425122243149@ugur>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071025/c4162eb0/attachment.pl>

From Agustin.Lobo at ija.csic.es  Thu Oct 25 21:04:08 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Thu, 25 Oct 2007 21:04:08 +0200
Subject: [R-sig-Geo] image display of rgdal-imported color composite image
Message-ID: <4720E8A8.7050502@ija.csic.es>

Hi,

Is image() able to display a color composite?

I've made an 8 bit color composite (with another software), saved it as
geotif and then, in R:

t1pcs <- readGDAL("G:/PERU/imorm2007/test1TNT/PC1_3s8.tif")
image(t1pcs)

but the color table seems wrong. I've checked with other programs, i.e.,
IrfanView, and the file is correct. So I think that the problem is that
col = heat.colors(12) is set by default, and the SpatialGridDataFrame
object created by rgdal does not keep the color table.

I've also tried with a 24-bit composite, and in that case rgdal imports
as a 3-layer image.

Is there any specific way I could import the color table of the
composite image?

Thanks
-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From mdsumner at utas.edu.au  Thu Oct 25 21:37:48 2007
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Fri, 26 Oct 2007 06:37:48 +1100
Subject: [R-sig-Geo] image display of rgdal-imported color composite
	image
In-Reply-To: <4720E8A8.7050502@ija.csic.es>
References: <4720E8A8.7050502@ija.csic.es>
Message-ID: <4720F08C.7080604@utas.edu.au>

By default, image() displays the first band of a SpatialGrid*DataFrame - 
controlled by the second argument - column number or name.

You can display a 3-band RGB image by creating a new band and lut - 
check out the example in  ?SGDF2PCT



Agustin Lobo wrote:
> Hi,
>
> Is image() able to display a color composite?
>
> I've made an 8 bit color composite (with another software), saved it as
> geotif and then, in R:
>
> t1pcs <- readGDAL("G:/PERU/imorm2007/test1TNT/PC1_3s8.tif")
> image(t1pcs)
>
> but the color table seems wrong. I've checked with other programs, i.e.,
> IrfanView, and the file is correct. So I think that the problem is that
> col = heat.colors(12) is set by default, and the SpatialGridDataFrame
> object created by rgdal does not keep the color table.
>
> I've also tried with a 24-bit composite, and in that case rgdal imports
> as a 3-layer image.
>
> Is there any specific way I could import the color table of the
> composite image?
>
> Thanks
>



From tkeitt at gmail.com  Thu Oct 25 22:10:34 2007
From: tkeitt at gmail.com (Tim Keitt)
Date: Thu, 25 Oct 2007 15:10:34 -0500
Subject: [R-sig-Geo] image display of rgdal-imported color composite
	image
In-Reply-To: <4720E8A8.7050502@ija.csic.es>
References: <4720E8A8.7050502@ija.csic.es>
Message-ID: <6262c54c0710251310i387814d8p38118812902d5f4d@mail.gmail.com>

On 10/25/07, Agustin Lobo <Agustin.Lobo at ija.csic.es> wrote:
> Hi,
>
> Is image() able to display a color composite?

The displayDataset() function should use the colormap. You will need
to open with GDAL.open().

THK

>
> I've made an 8 bit color composite (with another software), saved it as
> geotif and then, in R:
>
> t1pcs <- readGDAL("G:/PERU/imorm2007/test1TNT/PC1_3s8.tif")
> image(t1pcs)
>
> but the color table seems wrong. I've checked with other programs, i.e.,
> IrfanView, and the file is correct. So I think that the problem is that
> col = heat.colors(12) is set by default, and the SpatialGridDataFrame
> object created by rgdal does not keep the color table.
>
> I've also tried with a 24-bit composite, and in that case rgdal imports
> as a 3-layer image.
>
> Is there any specific way I could import the color table of the
> composite image?
>
> Thanks
> --
> Dr. Agustin Lobo
> Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
> LLuis Sole Sabaris s/n
> 08028 Barcelona
> Spain
> Tel. 34 934095410
> Fax. 34 934110012
> email: Agustin.Lobo at ija.csic.es
> http://www.ija.csic.es/gt/obster
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


-- 
Timothy H. Keitt, University of Texas at Austin
Contact info and schedule at http://www.keittlab.org/tkeitt/
Reprints at http://www.keittlab.org/tkeitt/papers/
ODF attachment? See http://www.openoffice.org/



From gerald.jurasinski at uni-rostock.de  Fri Oct 26 10:17:35 2007
From: gerald.jurasinski at uni-rostock.de (Gerald Jurasinski)
Date: Fri, 26 Oct 2007 10:17:35 +0200
Subject: [R-sig-Geo] Sampling random plots
Message-ID: <A46447DF-0627-44AE-A6B1-64A63E50F2BD@uni-rostock.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071026/b5e9821a/attachment.pl>

From Roger.Bivand at nhh.no  Fri Oct 26 10:35:16 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 26 Oct 2007 10:35:16 +0200 (CEST)
Subject: [R-sig-Geo] Sampling random plots
In-Reply-To: <A46447DF-0627-44AE-A6B1-64A63E50F2BD@uni-rostock.de>
References: <A46447DF-0627-44AE-A6B1-64A63E50F2BD@uni-rostock.de>
Message-ID: <Pine.LNX.4.64.0710261030110.12531@reclus.nhh.no>

On Fri, 26 Oct 2007, Gerald Jurasinski wrote:

> Dear List,
>
> Could someone please help me, with a tiny question?
>
> I have read in a shapefile with readShapePoly:
> sr <- readShapePoly("study_region")
>
> It just contains of one polygon.
>
> As i would like to sample random locations inside i do:
> > sr.pts <- sample.Polygon(sr, 60)

You can just do spsample(sr, ...), which will traverse your object to get 
to the single Polygon, sr is what class(sr) says.

>
> However, the function tells me, that there is no "area" slot in the
> object:
> Error in getPolygonAreaSlot(x) : no Slot of name "area" for this
> object of class "SpatialPolygonsDataFrame".
>
> But when looking at the object, there is a slot called "area" (see
> below). Do i have to convert the sr object to another spatial object
> which can better be handled by package sp functions (because it was
> read in with a maptools function)? And by the way, why there is no
> rgdal binary for mac on CRAN?
>

Because the external dependencies for the many OSX versions and platforms 
are too complicated for the CRAN OSX builder to support. Please follow the 
instructions on:

http://www.sal.uiuc.edu/tools/tools-sum/rgeo/rgeo-detail/map-packages-on-cran

to build from source. 32-bit Windows is simpler to support because there 
are fewer moving targets, and Uwe Ligges has been very generous in helping 
to automate the build process.

Roger

>
> > sr
> An object of class ?SpatialPolygonsDataFrame?
> Slot "data":
>   Id
> 0  0
>
> Slot "polygons":
> [[1]]
> An object of class ?Polygons?
> Slot "Polygons":
> [[1]]
> An object of class ?Polygon?
> Slot "labpt":
> [1] 4510732 6009121
>
> Slot "area":
> [1] 250264.9
>
> Slot "hole":
> [1] FALSE
>
> Slot "ringDir":
> [1] 1
>
> Slot "coords":
>          [,1]    [,2]
>  [1,] 4510328 6008870
>  [2,] 4510339 6008963
>  [3,] 4510347 6009007
>  [4,] 4510371 6009123
>  [5,] 4510386 6009155
>  [6,] 4510427 6009198
>  [7,] 4510456 6009218
>  [8,] 4510536 6009269
>  [9,] 4510590 6009324
> [10,] 4510655 6009395
> [11,] 4510704 6009380
> [12,] 4510752 6009358
> [13,] 4510899 6009300
> [14,] 4511018 6009246
> [15,] 4511127 6009077
> [16,] 4511246 6009065
> [17,] 4511343 6009053
> [18,] 4511213 6008975
> [19,] 4511176 6008970
> [20,] 4511123 6008980
> [21,] 4511077 6009002
> [22,] 4511007 6009021
> [23,] 4510939 6009028
> [24,] 4510866 6009021
> [25,] 4510790 6009007
> [26,] 4510723 6008985
> [27,] 4510643 6008953
> [28,] 4510579 6008934
> [29,] 4510510 6008921
> [30,] 4510420 6008893
> [31,] 4510328 6008870
>
>
>
> Slot "plotOrder":
> [1] 1
>
> Slot "labpt":
> [1] 4510732 6009121
>
> Slot "ID":
> [1] "0"
>
> Slot "area":
> [1] 250264.9
>
>
>
> Slot "plotOrder":
> [1] 1
>
> Slot "bbox":
>        min     max
> r1 4510328 4511343
> r2 6008870 6009395
>
> Slot "proj4string":
> CRS arguments: NA
>
>
>
> ??????????????????
>
> Dr. Gerald Jurasinski
> Landscape Ecology and Site Evaluation
> Institute for Management of Rural Areas
> Faculty of Agricultural and Environmental Sciences
> University of Rostock
> Justus-von-Liebig-Weg 6
> 18059 Rostock
> Germany
>
> gerald.jurasinski at uni-rostock.de
> http://www.auf.uni-rostock.de/loe
> +49 381 4983225 (tel)
> +49 381 4983222 (fax)
>
>
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From mgallay01 at qub.ac.uk  Fri Oct 26 11:28:09 2007
From: mgallay01 at qub.ac.uk (Michal Gallay)
Date: 26 Oct 2007 10:28:09 +0100
Subject: [R-sig-Geo] SpatialPixel and SpatialPoints Overlay output
In-Reply-To: <Pine.LNX.4.64.0710261030110.12531@reclus.nhh.no>
References: <A46447DF-0627-44AE-A6B1-64A63E50F2BD@uni-rostock.de>
	<Pine.LNX.4.64.0710261030110.12531@reclus.nhh.no>
Message-ID: <Prayer.1.0.12.0710261028090.708@localhost.localdomain>

Hello R User's,

I am struggling with overlaying 2 rasters datasets. Both were ASCII grids 
and loaded via read.asciigrid. One as SpatialPixelDataFrame and another 
converted to SpatialPointsDataFrame.

The are shifted with respect to each other and the aim is to get the values 
from raster1 in the overaly region with raster2. However, the overaly does 
not give the values which are in raster1 at data, but the values' 
order(position in the vector).

Could anyone advise why is that? Is there a simple way how to actually clip 
them according to the overlay region?

Thank you very much.

Regards,

Michal




-- 
Michal Gallay

Postgraduate Research Student
School of Geography, Archaeology and Palaeoecology
Queen's University
Belfast BT7 1NN
Northern Ireland

Tel: +44(0)2890 273929
Fax: +44(0)2890 973212
email: mgallay01 at qub.ac.uk
www: www.qub.ac.uk/geog



From Agustin.Lobo at ija.csic.es  Fri Oct 26 12:39:44 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Fri, 26 Oct 2007 12:39:44 +0200
Subject: [R-sig-Geo] Problem closing gdal file
Message-ID: <4721C3F0.6060207@ija.csic.es>

Hi!

After writing a geotif file with
writeGDAL(delme.cl.im,"t1cl100.tif",drivername = "GTiff")

the file seems to remain open, cannot move it or rename it
in the OS

I've tried closing it with
GDAL.close("t1cl100")

but...
Error in slot(dataset, "handle") :
   cannot get a slot ("handle") from an object of type "character"

Is there a better way to solve this problem than just exiting R?

Thanks!

Agus
-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Agustin.Lobo at ija.csic.es  Fri Oct 26 13:41:46 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Fri, 26 Oct 2007 13:41:46 +0200
Subject: [R-sig-Geo] Boundary of SpatialGridDataFrame ?
Message-ID: <4721D27A.20206@ija.csic.es>

Is it possible to get the boundary polygon
of a SpatialGridDataFrame object resulting from
a geotif image imported through rgdal?

My goal is to divide that rectangle
into two polygons defined by a
"SpatialLinesDataFrame" object (shp imported through
readOGR) and then overlay on the SpatialGridDataFrame object
to extract raster values from each polygon and compare.

Thanks!

Agus
-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Roger.Bivand at nhh.no  Fri Oct 26 14:51:34 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 26 Oct 2007 14:51:34 +0200 (CEST)
Subject: [R-sig-Geo] SpatialPixel and SpatialPoints Overlay output
In-Reply-To: <Prayer.1.0.12.0710261028090.708@localhost.localdomain>
References: <A46447DF-0627-44AE-A6B1-64A63E50F2BD@uni-rostock.de>
	<Pine.LNX.4.64.0710261030110.12531@reclus.nhh.no>
	<Prayer.1.0.12.0710261028090.708@localhost.localdomain>
Message-ID: <Pine.LNX.4.64.0710261448380.12531@reclus.nhh.no>

On Fri, 26 Oct 2007, Michal Gallay wrote:

> Hello R User's,
>
> I am struggling with overlaying 2 rasters datasets. Both were ASCII grids
> and loaded via read.asciigrid. One as SpatialPixelDataFrame and another
> converted to SpatialPointsDataFrame.
>
> The are shifted with respect to each other and the aim is to get the values
> from raster1 in the overaly region with raster2. However, the overaly does
> not give the values which are in raster1 at data, but the values'
> order(position in the vector).
>
> Could anyone advise why is that? Is there a simple way how to actually clip
> them according to the overlay region?

In general (not just in this context, but for many non-spatial objects 
too), use the [ operator: raster1 at data[o,] to extract the values as a data 
frame for the o indices returned by overlay(), or (most likely) 
raster1 at data[o, 1] as a vector.

Roger

>
> Thank you very much.
>
> Regards,
>
> Michal
>
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Fri Oct 26 15:01:30 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 26 Oct 2007 15:01:30 +0200 (CEST)
Subject: [R-sig-Geo] Boundary of SpatialGridDataFrame ?
In-Reply-To: <4721D27A.20206@ija.csic.es>
References: <4721D27A.20206@ija.csic.es>
Message-ID: <Pine.LNX.4.64.0710261459530.12531@reclus.nhh.no>

On Fri, 26 Oct 2007, Agustin Lobo wrote:

> Is it possible to get the boundary polygon
> of a SpatialGridDataFrame object resulting from
> a geotif image imported through rgdal?

bbox()? The boundary of a SpatialGrid is by definition a rectangle, and 
bbox() reports the full extent of the raster. The values then need 
repeating to get the five coordinates for a rectangle polygon.

Roger

>
> My goal is to divide that rectangle
> into two polygons defined by a
> "SpatialLinesDataFrame" object (shp imported through
> readOGR) and then overlay on the SpatialGridDataFrame object
> to extract raster values from each polygon and compare.
>
> Thanks!
>
> Agus
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Fri Oct 26 15:03:49 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 26 Oct 2007 15:03:49 +0200 (CEST)
Subject: [R-sig-Geo] Problem closing gdal file
In-Reply-To: <4721C3F0.6060207@ija.csic.es>
References: <4721C3F0.6060207@ija.csic.es>
Message-ID: <Pine.LNX.4.64.0710261502100.12531@reclus.nhh.no>

On Fri, 26 Oct 2007, Agustin Lobo wrote:

> Hi!
>
> After writing a geotif file with
> writeGDAL(delme.cl.im,"t1cl100.tif",drivername = "GTiff")
>
> the file seems to remain open, cannot move it or rename it
> in the OS

I'm looking into this, but without the output of sessionInfo(), it isn't 
easy. May I assume that this is a Windows system? If so, have you built 
your own GDAL and rgdal, or are you using the binary Windows package?

Roger

>
> I've tried closing it with
> GDAL.close("t1cl100")
>
> but...
> Error in slot(dataset, "handle") :
>   cannot get a slot ("handle") from an object of type "character"
>
> Is there a better way to solve this problem than just exiting R?
>
> Thanks!
>
> Agus
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From g.m.f.vanderheijden04 at leeds.ac.uk  Fri Oct 26 18:11:36 2007
From: g.m.f.vanderheijden04 at leeds.ac.uk (Geertje Van der Heijden)
Date: Fri, 26 Oct 2007 17:11:36 +0100
Subject: [R-sig-Geo] Spdep: help needed calculating Moran's I
Message-ID: <E193A286CE83354EB8BAB315F8BE62D317D685@HERMES4.ds.leeds.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071026/07fc79ab/attachment.pl>

From fieldsh at mail.med.upenn.edu  Fri Oct 26 18:37:19 2007
From: fieldsh at mail.med.upenn.edu (Sam Field)
Date: Fri, 26 Oct 2007 12:37:19 -0400
Subject: [R-sig-Geo] Spdep: help needed calculating Moran's I
In-Reply-To: <E193A286CE83354EB8BAB315F8BE62D317D685@HERMES4.ds.leeds.ac.uk>
References: <E193A286CE83354EB8BAB315F8BE62D317D685@HERMES4.ds.leeds.ac.uk>
Message-ID: <1193416639.472217bf17dbe@webmail.pobox.upenn.edu>

The value of the Moran's I will always depend on how the spatial weight matrix
is defined (and thus more specifically on your choice of an upper bound for
dnearneigh()).  I don't know if there are any statistical criteria for choosing
an upper bound - I imagine somebody has looked into this - I usually use a
substantively grounded criteria.  Ask yourself, for example, at what distance is
interaction between proximate geographic units no longer possible?  What is
generating (do you think) the spatial autocorrelation in residual species
richness?  What important variables have you left out and on what spatial scale
do their influences operate?  

The other, technical consideration, is to pick a number that does not generate
very many spatial isolates (i.e. geographic units with no neighbors). 

  

hope this helps!

Sam



Quoting Geertje Van der Heijden <g.m.f.vanderheijden04 at leeds.ac.uk>:

> Hi,
> 
> I have just posted the same question on the general R help mailing list,
> but thought that this list might be more appropriate. I am a new user of
> R.
> 
> Here is my problem:
> I have 58 sites from across South America. I have done a regression
> analysis to relate environmental and biogeographical variables to
> species richness and want to test whether my residuals are
> autocorrelated. As far as I understand the Moran's I, I have to take all
> possible combinations between all points into account to test this. So I
> have used dnearneigh() with the lower boundary set to 0 and the upper
> boundary set arbitrarily high to make sure all connections are included.
> 
> 
> >coords <- as.matrix(cbind(lowland$long, lowland$lat))
> >coord.nb <- dnearneigh(coords, 0, 10000, longlat=TRUE)
> >coord.list <- nb2listw(coord.nb, style="W")
> >lianasp.lm <- lm(lianasprich ~ log(averdist) + dsl + lianadens +
> wooddens)
> >lm.morantest(lianasp.lm, coord.list, alternative="two.sided")
> 
> However, this gives me a Moran's I which is exactly the same as the
> expected Moran's I (and hence a p-value of 1). If I change the lower or
> upper boundary slightly so that not all possible links are taken into
> account, the value is different, but still really near to the expected
> Moran's I. I don't understand why these values are or the same or nearly
> so.
> 
> I am new to spatial statistics, so this might me a really basic question
> and my appologies if it is, but I am generally a bit at a loss now about
> the Moran's I and I am wondering if I have calculated it right. Have
> used to right method to convert my coordinates into neighbourhood
> distances (and if not, which method should I have used) and am I
> understanding and calculation the Moran's I correctly?
> 
> Any help would be greatly appreciated.
> 
> Many thanks,
> Geertje
> 
> ~~~~
> Geertje van der Heijden
> PhD student
> Tropical Ecology
> School of Geography
> University of Leeds
> Leeds LS2 9JT
> 
> Tel: (+44)(0)113 3433345 
> Email: g.m.f.vanderheijden04 at leeds.ac.uk
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 


-- 
********Note the new contact information*******

Samuel H. Field, Ph.D. 
Senior Research Investigator
CHERP/Division of Internal Medicine - University of Pennsylvania
Philadelphia VA Medical Center
3900 Woodland Ave (9 East)
Philadelphia, PA 19104
(215) 823-5800 EXT. 6155 (Office)
(215) 823-6330 (Fax)



From Roger.Bivand at nhh.no  Fri Oct 26 19:40:32 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 26 Oct 2007 19:40:32 +0200 (CEST)
Subject: [R-sig-Geo] Spdep: help needed calculating Moran's I
In-Reply-To: <1193416639.472217bf17dbe@webmail.pobox.upenn.edu>
References: <E193A286CE83354EB8BAB315F8BE62D317D685@HERMES4.ds.leeds.ac.uk>
	<1193416639.472217bf17dbe@webmail.pobox.upenn.edu>
Message-ID: <Pine.LNX.4.64.0710261934550.14444@reclus.nhh.no>

On Fri, 26 Oct 2007, Sam Field wrote:

> The value of the Moran's I will always depend on how the spatial weight 
> matrix is defined (and thus more specifically on your choice of an upper 
> bound for dnearneigh()).  I don't know if there are any statistical 
> criteria for choosing an upper bound - I imagine somebody has looked 
> into this - I usually use a substantively grounded criteria.  Ask 
> yourself, for example, at what distance is interaction between proximate 
> geographic units no longer possible?  What is generating (do you think) 
> the spatial autocorrelation in residual species richness?  What 
> important variables have you left out and on what spatial scale do their 
> influences operate?
>
> The other, technical consideration, is to pick a number that does not 
> generate very many spatial isolates (i.e. geographic units with no 
> neighbors).
>

This is good advice. A third possibility, given that you have to make an 
a-priori choice which neighbours are proximate neighbours, is to use your 
original everyone-in binary weights, but to generalise them as inverse 
distance weights - see the example using nbdists() on the nb2listw() help 
page, using the glist= argument. Then nearer neighbours get more weight, 
ones further away less weight (you will also need the longlat=TRUE 
argument).

Roger


>
>
> hope this helps!
>
> Sam
>
>
>
> Quoting Geertje Van der Heijden <g.m.f.vanderheijden04 at leeds.ac.uk>:
>
>> Hi,
>>
>> I have just posted the same question on the general R help mailing list,
>> but thought that this list might be more appropriate. I am a new user of
>> R.
>>
>> Here is my problem:
>> I have 58 sites from across South America. I have done a regression
>> analysis to relate environmental and biogeographical variables to
>> species richness and want to test whether my residuals are
>> autocorrelated. As far as I understand the Moran's I, I have to take all
>> possible combinations between all points into account to test this. So I
>> have used dnearneigh() with the lower boundary set to 0 and the upper
>> boundary set arbitrarily high to make sure all connections are included.
>>
>>
>>> coords <- as.matrix(cbind(lowland$long, lowland$lat))
>>> coord.nb <- dnearneigh(coords, 0, 10000, longlat=TRUE)
>>> coord.list <- nb2listw(coord.nb, style="W")
>>> lianasp.lm <- lm(lianasprich ~ log(averdist) + dsl + lianadens +
>> wooddens)
>>> lm.morantest(lianasp.lm, coord.list, alternative="two.sided")
>>
>> However, this gives me a Moran's I which is exactly the same as the
>> expected Moran's I (and hence a p-value of 1). If I change the lower or
>> upper boundary slightly so that not all possible links are taken into
>> account, the value is different, but still really near to the expected
>> Moran's I. I don't understand why these values are or the same or nearly
>> so.
>>
>> I am new to spatial statistics, so this might me a really basic question
>> and my appologies if it is, but I am generally a bit at a loss now about
>> the Moran's I and I am wondering if I have calculated it right. Have
>> used to right method to convert my coordinates into neighbourhood
>> distances (and if not, which method should I have used) and am I
>> understanding and calculation the Moran's I correctly?
>>
>> Any help would be greatly appreciated.
>>
>> Many thanks,
>> Geertje
>>
>> ~~~~
>> Geertje van der Heijden
>> PhD student
>> Tropical Ecology
>> School of Geography
>> University of Leeds
>> Leeds LS2 9JT
>>
>> Tel: (+44)(0)113 3433345
>> Email: g.m.f.vanderheijden04 at leeds.ac.uk
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From dylan.beaudette at gmail.com  Fri Oct 26 19:58:49 2007
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Fri, 26 Oct 2007 10:58:49 -0700
Subject: [R-sig-Geo] coordinate precision using rgdal
Message-ID: <200710261058.49235.dylan.beaudette@gmail.com>

Hi,

noticed that when I import a shapefil with readOGR()  the coordinates are 
truncated to integers. Is there some way to prevent this type of behaviour?

cheers,

Dylan

-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341



From Roger.Bivand at nhh.no  Fri Oct 26 20:04:49 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 26 Oct 2007 20:04:49 +0200 (CEST)
Subject: [R-sig-Geo] coordinate precision using rgdal
In-Reply-To: <200710261058.49235.dylan.beaudette@gmail.com>
References: <200710261058.49235.dylan.beaudette@gmail.com>
Message-ID: <Pine.LNX.4.64.0710262003430.14444@reclus.nhh.no>

On Fri, 26 Oct 2007, Dylan Beaudette wrote:

> Hi,
>
> noticed that when I import a shapefil with readOGR()  the coordinates are
> truncated to integers. Is there some way to prevent this type of behaviour?

Can you please document this - are you being misled by the representation 
in default print? Do you have a test file and sessionInfo() etc?

Roger

>
> cheers,
>
> Dylan
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From dylan.beaudette at gmail.com  Fri Oct 26 21:48:32 2007
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Fri, 26 Oct 2007 12:48:32 -0700
Subject: [R-sig-Geo] coordinate precision using rgdal [solved]
In-Reply-To: <Pine.LNX.4.64.0710262132000.14444@reclus.nhh.no>
References: <200710261058.49235.dylan.beaudette@gmail.com>
	<200710261112.27619.dylan.beaudette@gmail.com>
	<Pine.LNX.4.64.0710262132000.14444@reclus.nhh.no>
Message-ID: <200710261248.32204.dylan.beaudette@gmail.com>

On Friday 26 October 2007, Roger Bivand wrote:
> On Fri, 26 Oct 2007, Dylan Beaudette wrote:
> > On Friday 26 October 2007, Roger Bivand wrote:
> >> On Fri, 26 Oct 2007, Dylan Beaudette wrote:
> >>> Hi,
> >>>
> >>> noticed that when I import a shapefil with readOGR()  the coordinates
> >>> are truncated to integers. Is there some way to prevent this type of
> >>> behaviour?
> >>

As usualy Roger saved the day.

The print method for an sp object will only print integer coordinates, even 
though they are stored as double precision internally. 

for an object called 'x' read in via readOGR()

print(coordinates(x)[1:5,], digits=15)

        coords.x1  coords.x2
[1,] 6615306.65 1959209.25
[2,] 6629710.25 1955324.95
[3,] 6623808.65 1953662.05
[4,] 6628580.05 1950899.85
[5,] 6633176.65 1950432.55

... look good!

Thanks Roger.


-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341



From edzer.pebesma at uni-muenster.de  Fri Oct 26 23:07:52 2007
From: edzer.pebesma at uni-muenster.de (Edzer J. Pebesma)
Date: Fri, 26 Oct 2007 23:07:52 +0200
Subject: [R-sig-Geo] coordinate precision using rgdal [solved]
In-Reply-To: <200710261248.32204.dylan.beaudette@gmail.com>
References: <200710261058.49235.dylan.beaudette@gmail.com>	<200710261112.27619.dylan.beaudette@gmail.com>	<Pine.LNX.4.64.0710262132000.14444@reclus.nhh.no>
	<200710261248.32204.dylan.beaudette@gmail.com>
Message-ID: <47225728.3010004@uni-muenster.de>

Dylan Beaudette wrote:
> On Friday 26 October 2007, Roger Bivand wrote:
>   
>> On Fri, 26 Oct 2007, Dylan Beaudette wrote:
>>     
>>> On Friday 26 October 2007, Roger Bivand wrote:
>>>       
>>>> On Fri, 26 Oct 2007, Dylan Beaudette wrote:
>>>>         
>>>>> Hi,
>>>>>
>>>>> noticed that when I import a shapefil with readOGR()  the coordinates
>>>>> are truncated to integers. Is there some way to prevent this type of
>>>>> behaviour?
>>>>>           
>
> As usualy Roger saved the day.
>
> The print method for an sp object will only print integer coordinates, even 
> though they are stored as double precision internally. 
>   
In your particular case yes, but it is the number of digits that's lower 
than you want by default, there's no defaulting to integers if 
coordinates are say less than 1e6.
--
Edzer



From hengl at science.uva.nl  Mon Oct 29 08:43:55 2007
From: hengl at science.uva.nl (Tomislav Hengl)
Date: Mon, 29 Oct 2007 08:43:55 +0100
Subject: [R-sig-Geo] Spdep: help needed calculating Moran's I
In-Reply-To: <E193A286CE83354EB8BAB315F8BE62D317D685@HERMES4.ds.leeds.ac.uk>
Message-ID: <000a01c819ff$758d0470$3a871291@pcibed193>



You can also fit a variogram to the residuals using the gstat package and then record the nugget and
sill variation (see http://www.gstat.org/manual/node7.html). I do not know how to test that the
nugget variation is statistically significant from the sill variation. You could split the variogram
cloud into closer points and more distant points and then run some statistical tests on the two
sub-sets (e.g. the t-test). But where to put a boundary between closer/more distant points?

Tom Hengl
http://spatial-analyst.net 



-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
Geertje Van der Heijden
Sent: vrijdag 26 oktober 2007 18:12
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] Spdep: help needed calculating Moran's I

Hi,

I have just posted the same question on the general R help mailing list,
but thought that this list might be more appropriate. I am a new user of
R.

Here is my problem:
I have 58 sites from across South America. I have done a regression
analysis to relate environmental and biogeographical variables to
species richness and want to test whether my residuals are
autocorrelated. As far as I understand the Moran's I, I have to take all
possible combinations between all points into account to test this. So I
have used dnearneigh() with the lower boundary set to 0 and the upper
boundary set arbitrarily high to make sure all connections are included.


>coords <- as.matrix(cbind(lowland$long, lowland$lat))
>coord.nb <- dnearneigh(coords, 0, 10000, longlat=TRUE)
>coord.list <- nb2listw(coord.nb, style="W")
>lianasp.lm <- lm(lianasprich ~ log(averdist) + dsl + lianadens +
wooddens)
>lm.morantest(lianasp.lm, coord.list, alternative="two.sided")

However, this gives me a Moran's I which is exactly the same as the
expected Moran's I (and hence a p-value of 1). If I change the lower or
upper boundary slightly so that not all possible links are taken into
account, the value is different, but still really near to the expected
Moran's I. I don't understand why these values are or the same or nearly
so.

I am new to spatial statistics, so this might me a really basic question
and my appologies if it is, but I am generally a bit at a loss now about
the Moran's I and I am wondering if I have calculated it right. Have
used to right method to convert my coordinates into neighbourhood
distances (and if not, which method should I have used) and am I
understanding and calculation the Moran's I correctly?

Any help would be greatly appreciated.

Many thanks,
Geertje

~~~~
Geertje van der Heijden
PhD student
Tropical Ecology
School of Geography
University of Leeds
Leeds LS2 9JT

Tel: (+44)(0)113 3433345 
Email: g.m.f.vanderheijden04 at leeds.ac.uk



	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From Agustin.Lobo at ija.csic.es  Mon Oct 29 10:16:30 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Mon, 29 Oct 2007 10:16:30 +0100
Subject: [R-sig-Geo] "Abridged" description of SpatialPolygonsDataFrame
	objects?
Message-ID: <4725A4EE.8030406@ija.csic.es>

Hi!

If I do str(a) where a is a SpatialGridDataFrame, I get
a description of the structure that is readable,
but for SpatialPolygonsDataFrame the output of str() is
too long. Is there any way of looking at the
structure of a SpatialPolygonsDataFrame object just down to
a certain level? For example, not getting the structure of the
each polygon but getting the first one only.

Thanks
Agus
-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From mdsumner at utas.edu.au  Mon Oct 29 11:11:51 2007
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Mon, 29 Oct 2007 21:11:51 +1100
Subject: [R-sig-Geo] "Abridged" description of SpatialPolygonsDataFrame
 objects?
In-Reply-To: <4725A4EE.8030406@ija.csic.es>
References: <4725A4EE.8030406@ija.csic.es>
Message-ID: <4725B1E7.5030903@utas.edu.au>

If "d" is a SPolyDF

## first row/object
d[1,]
str(d[1,])

## the first Polygons object itself  (Polygons can be of many)
d at polygons[[1]]
str(d at polygons[[1]])

## the first Polygon in the first Polygons object
d at polygons[[1]]@Polygons[[1]]
str(d at polygons[[1]]@Polygons[[1]])



Agustin Lobo wrote:
> Hi!
>
> If I do str(a) where a is a SpatialGridDataFrame, I get
> a description of the structure that is readable,
> but for SpatialPolygonsDataFrame the output of str() is
> too long. Is there any way of looking at the
> structure of a SpatialPolygonsDataFrame object just down to
> a certain level? For example, not getting the structure of the
> each polygon but getting the first one only.
>
> Thanks
> Agus
>



From Agustin.Lobo at ija.csic.es  Mon Oct 29 18:53:08 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Mon, 29 Oct 2007 18:53:08 +0100
Subject: [R-sig-Geo] Centroids and getSpPPolygonsLabptSlots
Message-ID: <47261E04.5030304@ija.csic.es>

I have just incidentally learned in the sp doc that 
getSpPPolygonsLabptSlots() actually retrieves the coordinates
of the centroids. The index page of the sp doc just states:
getSpPPolygonsLabptSlots 	Class "SpatialPolygonsDataFrame"

adding a mention to the fact that getSpPPolygonsLabptSlots retrieves the
coordinates of the centroids would be very helpful. Previously, I 
thought I had to convert to a PBSmapping object and use calcCentroid().

Agus

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Agustin.Lobo at ija.csic.es  Mon Oct 29 20:15:49 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Mon, 29 Oct 2007 20:15:49 +0100
Subject: [R-sig-Geo] Subsetting SpatialPolygonsDataFrame and empty ID slots
Message-ID: <47263165.30309@ija.csic.es>

Dear list,

I have imported a shp file with:

> pols <- readOGR("../AllTransectPolygons02", 
layer="AllTransectPolygons02")

> class(pols)
[1] "SpatialPolygonsDataFrame"
attr(,"package")
[1] "sp"

> pols at data
     AREA PERIMETER               Site
0   2500      1010           Lupuna 1
1   2500      1010           Lupuna 3
2   2500      1010           Lupuna 2
3   2500      1010             Aleman
4   2500      1010        Zancudoyacu
etc

and now I want to select few polygons according
to a vector of Site names.

Thinking on how doing this, I thought I could select
the corresponding IDs in the data table and then use
the ID slot in the polygons, but
I've found that the polygons themselves actually
lack the ID information:

> getPolygonsIDSlot(pols)
Error in getPolygonsIDSlot(pols) :
   no slot of name "ID" for this object of class "SpatialPolygonsDataFrame"

How does sp relate the data table to the polygons if there is no ID?

In any case, which would the most efficient way of subseting
the SpatialPolygonsDataFrame into another SpatialPolygonsDataFrame
with the selected polygons? Should I convert to a maptools object
and use subset.polylist()? If so, how do I convert? I've tried:

pols.maptools <- SpatialPolygons2PolySet(pols)

but the data table is lost.

Thanks!

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster


-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Roger.Bivand at nhh.no  Mon Oct 29 21:06:25 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 29 Oct 2007 21:06:25 +0100 (CET)
Subject: [R-sig-Geo] Centroids and getSpPPolygonsLabptSlots
In-Reply-To: <47261E04.5030304@ija.csic.es>
References: <47261E04.5030304@ija.csic.es>
Message-ID: <Pine.LNX.4.64.0710292048360.12782@reclus.nhh.no>

On Mon, 29 Oct 2007, Agustin Lobo wrote:

> I have just incidentally learned in the sp doc that
> getSpPPolygonsLabptSlots() actually retrieves the coordinates
> of the centroids. The index page of the sp doc just states:
> getSpPPolygonsLabptSlots 	Class "SpatialPolygonsDataFrame"
>
> adding a mention to the fact that getSpPPolygonsLabptSlots retrieves the
> coordinates of the centroids would be very helpful. Previously, I
> thought I had to convert to a PBSmapping object and use calcCentroid().

And coordinates(x) returns the same points for x a 
SpatialPolygonsDataFrame (strictly the centroids of the largest component 
polygon by area, with no guarantee that it does not fall in a hole in that 
polygon. The very long names are just wrappers for losts of nested slot() 
and sapply() calls.

The documentation weaknesses are obvious, but are hard to address, because 
the sp package itself has little example data - there is more in maptools 
- and because new style classes and methods for them are harder to 
document than old style classes and methods. I'll try to make the 
documentation simpler and easier to search.

Roger

>
> Agus
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Mon Oct 29 21:41:11 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 29 Oct 2007 21:41:11 +0100 (CET)
Subject: [R-sig-Geo] Subsetting SpatialPolygonsDataFrame and empty ID
 slots
In-Reply-To: <47263165.30309@ija.csic.es>
References: <47263165.30309@ija.csic.es>
Message-ID: <Pine.LNX.4.64.0710292125580.12782@reclus.nhh.no>

On Mon, 29 Oct 2007, Agustin Lobo wrote:

> Dear list,
>
> I have imported a shp file with:
>
>> pols <- readOGR("../AllTransectPolygons02",
> layer="AllTransectPolygons02")
>
>> class(pols)
> [1] "SpatialPolygonsDataFrame"
> attr(,"package")
> [1] "sp"
>
>> pols at data
>     AREA PERIMETER               Site
> 0   2500      1010           Lupuna 1
> 1   2500      1010           Lupuna 3
> 2   2500      1010           Lupuna 2
> 3   2500      1010             Aleman
> 4   2500      1010        Zancudoyacu
> etc
>
> and now I want to select few polygons according
> to a vector of Site names.
>
> Thinking on how doing this, I thought I could select
> the corresponding IDs in the data table and then use
> the ID slot in the polygons, but
> I've found that the polygons themselves actually
> lack the ID information:
>

Please treat all the long named access thingies in sp as deprecated - they 
will be flagged as such in the next release, and removed one release after 
that. S4 is not like that.

library(sp)
library(rgdal)
example(readOGR)
class(Up)
getSlots(class(Up))
class(slot(Up, "polygons")[[1]])
getSlots(class(slot(Up, "polygons")[1]))

So:

sapply(slot(Up, "polygons"), function(x) slot(x, "ID"))

>> getPolygonsIDSlot(pols)
> Error in getPolygonsIDSlot(pols) :
>   no slot of name "ID" for this object of class "SpatialPolygonsDataFrame"
>
> How does sp relate the data table to the polygons if there is no ID?
>

Of course there is an ID, but you can get at either by:

sapply(slot(pols, "polygons"), function(x) slot(x, "ID"))

or

rownames(as(pols, "data.frame"))


> In any case, which would the most efficient way of subseting
> the SpatialPolygonsDataFrame into another SpatialPolygonsDataFrame
> with the selected polygons?

Returning to the original question, subsetting is simply by the "[" 
operator, just like any other data.frame:

sites_Lupuna <- length(grep("Lupuna", as.character(pols$Site))) > 0
summary(sites_Lupuna)
pols_Lupuna <- pols[sites_Lupuna,]

Just think of Spatial*DataFrame objects as data.frame objects and things 
will be much clearer.

Roger

> Should I convert to a maptools object
> and use subset.polylist()? If so, how do I convert? I've tried:
>
> pols.maptools <- SpatialPolygons2PolySet(pols)
>

PS. PolySet objects are really for drawing coastlines in this context.

> but the data table is lost.
>
> Thanks!
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From hi_ono2001 at yahoo.co.jp  Tue Oct 30 04:05:18 2007
From: hi_ono2001 at yahoo.co.jp (Hisaji ONO)
Date: Tue, 30 Oct 2007 12:05:18 +0900 (JST)
Subject: [R-sig-Geo] About Insightful's S-Plus "SpatialStats" package
Message-ID: <20071030030518.52898.qmail@web10708.mail.bbt.yahoo.co.jp>

Hello.

 Recently Insightful's S-Plus library has been ported to R
package.

 However "SpatialStats" package still not yet.

 Does Anyone know whether Insightful people will open
their spatial package including MA function(spdep not
supported) etc


 Regards.



From Agustin.Lobo at ija.csic.es  Tue Oct 30 07:28:11 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Tue, 30 Oct 2007 07:28:11 +0100
Subject: [R-sig-Geo] Centroids and getSpPPolygonsLabptSlots
In-Reply-To: <Pine.LNX.4.64.0710292048360.12782@reclus.nhh.no>
References: <47261E04.5030304@ija.csic.es>
	<Pine.LNX.4.64.0710292048360.12782@reclus.nhh.no>
Message-ID: <4726CEFB.6090106@ija.csic.es>

Making doc is very hard, and usually not a task that can be
accomplished by the developer alone, as he/she holds many
connexions in his mind that are not there for the rest of
people. Considering this, the current doc is a very good start point. 
I'm starting sort of "operational guide", based on
how to do some common (from my point of view) tasks. Although
I confess that this is an egoistic effort (I normally use
sp very intensively during few weeks for a given phase of the projects,
then get busy with other tasks for months and thus forget many things 
for the next time), I'll be happy
sharing this doc. My 5 cents!

Agus

Roger Bivand escribi?:
> On Mon, 29 Oct 2007, Agustin Lobo wrote:
> 
>> I have just incidentally learned in the sp doc that
>> getSpPPolygonsLabptSlots() actually retrieves the coordinates
>> of the centroids. The index page of the sp doc just states:
>> getSpPPolygonsLabptSlots     Class "SpatialPolygonsDataFrame"
>>
>> adding a mention to the fact that getSpPPolygonsLabptSlots retrieves the
>> coordinates of the centroids would be very helpful. Previously, I
>> thought I had to convert to a PBSmapping object and use calcCentroid().
> 
> And coordinates(x) returns the same points for x a 
> SpatialPolygonsDataFrame (strictly the centroids of the largest 
> component polygon by area, with no guarantee that it does not fall in a 
> hole in that polygon. The very long names are just wrappers for losts of 
> nested slot() and sapply() calls.
> 
> The documentation weaknesses are obvious, but are hard to address, 
> because the sp package itself has little example data - there is more in 
> maptools - and because new style classes and methods for them are harder 
> to document than old style classes and methods. I'll try to make the 
> documentation simpler and easier to search.
> 
> Roger
> 
>>
>> Agus
>>
>>
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From tskam at smu.edu.sg  Mon Oct 29 10:43:31 2007
From: tskam at smu.edu.sg (KAM Tin Seong)
Date: Mon, 29 Oct 2007 17:43:31 +0800
Subject: [R-sig-Geo] R library to perform Small Area Estimation
Message-ID: <FA3090E732DC6A4EB8E2D875EEB486A562CE83@EX01.staff.smu.edu.sg>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071029/0931ba04/attachment.pl>

From Roger.Bivand at nhh.no  Tue Oct 30 08:27:53 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 30 Oct 2007 08:27:53 +0100 (CET)
Subject: [R-sig-Geo] About Insightful's S-Plus "SpatialStats" package
In-Reply-To: <20071030030518.52898.qmail@web10708.mail.bbt.yahoo.co.jp>
References: <20071030030518.52898.qmail@web10708.mail.bbt.yahoo.co.jp>
Message-ID: <Pine.LNX.4.64.0710300821230.14848@reclus.nhh.no>

On Tue, 30 Oct 2007, Hisaji ONO wrote:

> Hello.
>
> Recently Insightful's S-Plus library has been ported to R
> package.
>
> However "SpatialStats" package still not yet.

Insightful have added R-style packages to S-Plus, so that R contributed 
packages can be built for S-Plus, rather than the other way round. There 
may be interest in providing some R-spatial packages for S-Plus; sp and 
gstat have been built for S-Plus in the past. I am not aware of Insightful 
considering releasing the SpatialStats module in other forms.

>
> Does Anyone know whether Insightful people will open
> their spatial package including MA function(spdep not
> supported) etc

spautolm() now has MA support, thanks to a generous contribution by Jielai 
Ma, family="SMA", but for obvious reasons, no sparse matrix support, so 
only for up to moderate numbers of observations (say 1500+). "CAR" and 
"SAR" can be used with sparse matrix methods.

Best wishes,

Roger

>
>
> Regards.
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Agustin.Lobo at ija.csic.es  Tue Oct 30 12:14:22 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Tue, 30 Oct 2007 12:14:22 +0100
Subject: [R-sig-Geo] plot of sp SpatialPolygonsDataFrame: col not working?
Message-ID: <4727120E.1070104@ija.csic.es>

Dear list,

I'm plotting polygons with:
displayDataset(GDAL.open("G:/PERU/imorm2007/test1TNT/PC1_3s.tif"))
plot(boundary,lwd=2,col=2,add=T)
plot(pols.ferns3,col=3,lwd=1,add=T)

(cannot use spplot because I need the add=T)
but the polygons are actually black, ignoring col. I think that this is
because the boundaries of the polygons get displayed in black, 
regardless of the filling color, and my polygons are very narrow at this 
scale (which is the one I need). Is there any way of changing the color 
of the boundaries or just not displaying boundaries?

Thanks!

Agus
-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Agustin.Lobo at ija.csic.es  Tue Oct 30 12:14:49 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Tue, 30 Oct 2007 12:14:49 +0100
Subject: [R-sig-Geo] Subsetting SpatialPolygonsDataFrame and empty ID
 slots
In-Reply-To: <Pine.LNX.4.64.0710292125580.12782@reclus.nhh.no>
References: <47263165.30309@ija.csic.es>
	<Pine.LNX.4.64.0710292125580.12782@reclus.nhh.no>
Message-ID: <47271229.8060702@ija.csic.es>

That's really helpful, thanks.

For "everyday" use, I've made:

"slotspol" <- function(pol, sl="ID")
sapply(slot(pol, "polygons"), function(x) slot(x, sl))

Which can be used for any slot name:
slotspol(Up)
slotspol(Up,"area")

Also, few questions:
1. I observe that pols$Site is identical to pols at data$Site. Is not 
pols at data$Site the correct syntax? I mean that we retrieve variable 
"Site" from slot "data" in object "pols".

2. In your code, I don't understand
sites_Lupuna <- length(grep("Lupuna", as.character(pols$Site))) > 0

because the result is just T (the result of length(grep("Lupuna", 
as.character(pols$Site)))  is 3)
and thus subsetting with sites_Lupuna yields an object that is identical
to the original:

 > pols_Lupuna <- pols[sites_Lupuna,]
 > length(pols_Lupuna at polygons)
[1] 140
 > length(pols at polygons)
[1] 140

Instead:
 > sites_Lupuna <- grep("Lupuna", as.character(pols$Site))
 > sites_Lupuna
[1] 1 2 3
 > pols_Lupuna <- pols[sites_Lupuna,]

seems to provide a correctly subset of the original pols object ("Lupuna 
1", "Lupuna 2", "Lupuna 3")

Am I wrong? I feel quite insecure on this.

Agus

Roger Bivand escribi?:
> On Mon, 29 Oct 2007, Agustin Lobo wrote:
> 
>> Dear list,
>>
>> I have imported a shp file with:
>>
>>> pols <- readOGR("../AllTransectPolygons02",
>> layer="AllTransectPolygons02")
>>
>>> class(pols)
>> [1] "SpatialPolygonsDataFrame"
>> attr(,"package")
>> [1] "sp"
>>
>>> pols at data
>>     AREA PERIMETER               Site
>> 0   2500      1010           Lupuna 1
>> 1   2500      1010           Lupuna 3
>> 2   2500      1010           Lupuna 2
>> 3   2500      1010             Aleman
>> 4   2500      1010        Zancudoyacu
>> etc
>>
>> and now I want to select few polygons according
>> to a vector of Site names.
>>
>> Thinking on how doing this, I thought I could select
>> the corresponding IDs in the data table and then use
>> the ID slot in the polygons, but
>> I've found that the polygons themselves actually
>> lack the ID information:
>>
> 
> Please treat all the long named access thingies in sp as deprecated - 
> they will be flagged as such in the next release, and removed one 
> release after that. S4 is not like that.
> 
> library(sp)
> library(rgdal)
> example(readOGR)
> class(Up)
> getSlots(class(Up))
> class(slot(Up, "polygons")[[1]])
> getSlots(class(slot(Up, "polygons")[1]))
> 
> So:
> 
> sapply(slot(Up, "polygons"), function(x) slot(x, "ID"))
> 
>>> getPolygonsIDSlot(pols)
>> Error in getPolygonsIDSlot(pols) :
>>   no slot of name "ID" for this object of class 
>> "SpatialPolygonsDataFrame"
>>
>> How does sp relate the data table to the polygons if there is no ID?
>>
> 
> Of course there is an ID, but you can get at either by:
> 
> sapply(slot(pols, "polygons"), function(x) slot(x, "ID"))
> 
> or
> 
> rownames(as(pols, "data.frame"))
> 
> 
>> In any case, which would the most efficient way of subseting
>> the SpatialPolygonsDataFrame into another SpatialPolygonsDataFrame
>> with the selected polygons?
> 
> Returning to the original question, subsetting is simply by the "[" 
> operator, just like any other data.frame:
> 
> sites_Lupuna <- length(grep("Lupuna", as.character(pols$Site))) > 0
> summary(sites_Lupuna)
> pols_Lupuna <- pols[sites_Lupuna,]
> 
> Just think of Spatial*DataFrame objects as data.frame objects and things 
> will be much clearer.
> 
> Roger
> 
>> Should I convert to a maptools object
>> and use subset.polylist()? If so, how do I convert? I've tried:
>>
>> pols.maptools <- SpatialPolygons2PolySet(pols)
>>
> 
> PS. PolySet objects are really for drawing coastlines in this context.
> 
>> but the data table is lost.
>>
>> Thanks!
>>
>>
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From rob.robinson at bto.org  Tue Oct 30 12:20:02 2007
From: rob.robinson at bto.org (Rob Robinson)
Date: Tue, 30 Oct 2007 11:20:02 -0000
Subject: [R-sig-Geo] plot of sp SpatialPolygonsDataFrame: col not
	working?
In-Reply-To: <4727120E.1070104@ija.csic.es>
Message-ID: <002701c81ae6$d0c2d990$5285c3c1@btodomain.bto.org>

Agus,
 Try the border= option in plot, I think I had a similar problem...
Cheers
rob

*** Want to know about Britain's birds? Try  www.bto.org/birdfacts ***

Dr Rob Robinson, Senior Population Biologist
British Trust for Ornithology, The Nunnery, Thetford, Norfolk, IP24 2PU
Ph: +44 (0)1842 750050         E: rob.robinson at bto.org
Fx: +44 (0)1842 750030         W: http://www.bto.org
eSafe scanned this email for viruses, vandals and malicious content (!)

==== "How can anyone be enlightened, when truth is so poorly lit" =====
  

> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch 
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Agustin Lobo
> Sent: 30 October 2007 11:14
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] plot of sp SpatialPolygonsDataFrame: col 
> not working?
> 
> Dear list,
> 
> I'm plotting polygons with:
> displayDataset(GDAL.open("G:/PERU/imorm2007/test1TNT/PC1_3s.tif"))
> plot(boundary,lwd=2,col=2,add=T)
> plot(pols.ferns3,col=3,lwd=1,add=T)
> 
> (cannot use spplot because I need the add=T) but the polygons 
> are actually black, ignoring col. I think that this is 
> because the boundaries of the polygons get displayed in 
> black, regardless of the filling color, and my polygons are 
> very narrow at this scale (which is the one I need). Is there 
> any way of changing the color of the boundaries or just not 
> displaying boundaries?
> 
> Thanks!
> 
> Agus
> --
> Dr. Agustin Lobo
> Institut de Ciencies de la Terra "Jaume Almera" (CSIC) LLuis 
> Sole Sabaris s/n
> 08028 Barcelona
> Spain
> Tel. 34 934095410
> Fax. 34 934110012
> email: Agustin.Lobo at ija.csic.es
> http://www.ija.csic.es/gt/obster
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Roger.Bivand at nhh.no  Tue Oct 30 12:24:55 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 30 Oct 2007 12:24:55 +0100 (CET)
Subject: [R-sig-Geo] Subsetting SpatialPolygonsDataFrame and empty ID
 slots
In-Reply-To: <47271229.8060702@ija.csic.es>
References: <47263165.30309@ija.csic.es>
	<Pine.LNX.4.64.0710292125580.12782@reclus.nhh.no>
	<47271229.8060702@ija.csic.es>
Message-ID: <Pine.LNX.4.64.0710301215400.14848@reclus.nhh.no>

On Tue, 30 Oct 2007, Agustin Lobo wrote:

> That's really helpful, thanks.
>
> For "everyday" use, I've made:
>
> "slotspol" <- function(pol, sl="ID")
> sapply(slot(pol, "polygons"), function(x) slot(x, sl))
>
> Which can be used for any slot name:
> slotspol(Up)
> slotspol(Up,"area")
>
> Also, few questions:
> 1. I observe that pols$Site is identical to pols at data$Site. Is not 
> pols at data$Site the correct syntax? I mean that we retrieve variable "Site" 
> from slot "data" in object "pols".

Both are possible, but "$" methods are provided for all Spatial*DataFrame 
objects so that they behave like regular data frames in many settings, so 
that coercing to data frame becomes unnecessary. Using the "@" directly is 
not necessarily safe, so in particular please use the "$<-" method for 
writing to (possibly new) variables in the Spatial*DataFrame. To see how 
"$" works, try using a Spatial*DataFrame as the data= argument in lm() or 
glm(), etc. It just "works".

>
> 2. In your code, I don't understand
> sites_Lupuna <- length(grep("Lupuna", as.character(pols$Site))) > 0
>
> because the result is just T (the result of length(grep("Lupuna", 
> as.character(pols$Site)))  is 3)
> and thus subsetting with sites_Lupuna yields an object that is identical
> to the original:

I don't have your data, so I cannot set up the condition vector exactly. 
Here I was trying to be too clever, you want a vector of TRUE or FALSE 
values of length 140, and this condition wasn't the right one.

cond <- "Aleman" %in% as.character(pols$Site)

should just have TRUE for Aleman, not otherwise. Your understanding below 
is OK.

Roger

>
>>  pols_Lupuna <- pols[sites_Lupuna,]
>>  length(pols_Lupuna at polygons)
> [1] 140
>>  length(pols at polygons)
> [1] 140
>
> Instead:
>>  sites_Lupuna <- grep("Lupuna", as.character(pols$Site))
>>  sites_Lupuna
> [1] 1 2 3
>>  pols_Lupuna <- pols[sites_Lupuna,]
>
> seems to provide a correctly subset of the original pols object ("Lupuna 1", 
> "Lupuna 2", "Lupuna 3")
>
> Am I wrong? I feel quite insecure on this.
>
> Agus
>
> Roger Bivand escribi?:
>>  On Mon, 29 Oct 2007, Agustin Lobo wrote:
>> 
>> >  Dear list,
>> > 
>> >  I have imported a shp file with:
>> > 
>> > >  pols <- readOGR("../AllTransectPolygons02",
>> >  layer="AllTransectPolygons02")
>> > 
>> > >  class(pols)
>> >  [1] "SpatialPolygonsDataFrame"
>> >  attr(,"package")
>> >  [1] "sp"
>> > 
>> > >  pols at data
>> >      AREA PERIMETER               Site
>> >  0   2500      1010           Lupuna 1
>> >  1   2500      1010           Lupuna 3
>> >  2   2500      1010           Lupuna 2
>> >  3   2500      1010             Aleman
>> >  4   2500      1010        Zancudoyacu
>> >  etc
>> > 
>> >  and now I want to select few polygons according
>> >  to a vector of Site names.
>> > 
>> >  Thinking on how doing this, I thought I could select
>> >  the corresponding IDs in the data table and then use
>> >  the ID slot in the polygons, but
>> >  I've found that the polygons themselves actually
>> >  lack the ID information:
>> >
>>
>>  Please treat all the long named access thingies in sp as deprecated - they
>>  will be flagged as such in the next release, and removed one release after
>>  that. S4 is not like that.
>>
>>  library(sp)
>>  library(rgdal)
>>  example(readOGR)
>>  class(Up)
>>  getSlots(class(Up))
>>  class(slot(Up, "polygons")[[1]])
>>  getSlots(class(slot(Up, "polygons")[1]))
>>
>>  So:
>>
>>  sapply(slot(Up, "polygons"), function(x) slot(x, "ID"))
>> 
>> > >  getPolygonsIDSlot(pols)
>> >  Error in getPolygonsIDSlot(pols) :
>> >    no slot of name "ID" for this object of class 
>> >  "SpatialPolygonsDataFrame"
>> > 
>> >  How does sp relate the data table to the polygons if there is no ID?
>> >
>>
>>  Of course there is an ID, but you can get at either by:
>>
>>  sapply(slot(pols, "polygons"), function(x) slot(x, "ID"))
>>
>>  or
>>
>>  rownames(as(pols, "data.frame"))
>>
>> 
>> >  In any case, which would the most efficient way of subseting
>> >  the SpatialPolygonsDataFrame into another SpatialPolygonsDataFrame
>> >  with the selected polygons?
>>
>>  Returning to the original question, subsetting is simply by the "["
>>  operator, just like any other data.frame:
>>
>>  sites_Lupuna <- length(grep("Lupuna", as.character(pols$Site))) > 0
>>  summary(sites_Lupuna)
>>  pols_Lupuna <- pols[sites_Lupuna,]
>>
>>  Just think of Spatial*DataFrame objects as data.frame objects and things
>>  will be much clearer.
>>
>>  Roger
>> 
>> >  Should I convert to a maptools object
>> >  and use subset.polylist()? If so, how do I convert? I've tried:
>> > 
>> >  pols.maptools <- SpatialPolygons2PolySet(pols)
>> >
>>
>>  PS. PolySet objects are really for drawing coastlines in this context.
>> 
>> >  but the data table is lost.
>> > 
>> >  Thanks!
>> > 
>> >
>> 
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From Roger.Bivand at nhh.no  Tue Oct 30 12:26:49 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 30 Oct 2007 12:26:49 +0100 (CET)
Subject: [R-sig-Geo] plot of sp SpatialPolygonsDataFrame: col not
	working?
In-Reply-To: <4727120E.1070104@ija.csic.es>
References: <4727120E.1070104@ija.csic.es>
Message-ID: <Pine.LNX.4.64.0710301225401.14848@reclus.nhh.no>

On Tue, 30 Oct 2007, Agustin Lobo wrote:

> Dear list,
>
> I'm plotting polygons with:
> displayDataset(GDAL.open("G:/PERU/imorm2007/test1TNT/PC1_3s.tif"))
> plot(boundary,lwd=2,col=2,add=T)
> plot(pols.ferns3,col=3,lwd=1,add=T)
>
> (cannot use spplot because I need the add=T)
> but the polygons are actually black, ignoring col. I think that this is
> because the boundaries of the polygons get displayed in black,
> regardless of the filling color, and my polygons are very narrow at this
> scale (which is the one I need). Is there any way of changing the color
> of the boundaries or just not displaying boundaries?

border=3 or border="transparent"

should do it.

Roger

>
> Thanks!
>
> Agus
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Agustin.Lobo at ija.csic.es  Tue Oct 30 13:16:44 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Tue, 30 Oct 2007 13:16:44 +0100
Subject: [R-sig-Geo] Done!: Simultaneous interactive plot of hc dendrogram
 and geographic display
Message-ID: <472720AC.60107@ija.csic.es>

Well, thanks to the many inputs I've got, I've been able of
displaying a hc tree on one graphic display and, through the
use of identify.hc() click a branch and get the involved polygons
geographically displayed on another graphic window. It is inspired on 
the barplot example in the help page for identify.hc.

The normal situation would be clustering in the data slot
of the SpatialPolygonsDataFrame object. Here I'm using
a different table because I did not have the sps composition
for all the transects (polygons).

In the example below, ferns is a transects x sps data frame, where
the transects are some of the polygons in pols.

ferns.raup <- vegdist(ferns,method="raup")
ferns.hc <- hclust(ferns.raup)
plot(ferns.hc)
get(getOption("device"))()
nD <- dev.cur()
image(t1pc1s)
plot(boundary,lwd=2,col=2,add=T)
dev.set(dev.prev())
identify(ferns.hc, MAXCLUST=17,  FUN=function(k) {color=readline("Enter 
color: "); 
plot(polysubset(polys=pols,tabla=ferns,posic=k),add=T,lwd=3,border=color,col=color)}, 
DEV.FUN = nD)

The involved function is:

"polysubset" 
<-function(polys=pols,tabla=ferns,pos.nom="fern.class",posics=k)
{
	tabla <- tabla[posics,]
	sel <- match(names(tabla[,pos.nom]),polys at data$Site)
	polys[sel,]
}

Agus

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From zev at zevross.com  Tue Oct 30 14:35:12 2007
From: zev at zevross.com (Zev Ross)
Date: Tue, 30 Oct 2007 13:35:12 +0000 (UTC)
Subject: [R-sig-Geo] GSTAT - measurement vs microscale variation
Message-ID: <loom.20071030T133119-294@post.gmane.org>

Hi All,

I folded this question into a previous post, but I think it may have gotten
missed. Just wondering if someone could tell me how, in GSTAT, one would specify
the nugget as measurement error vs microscale variation in kriging. I have
multiple measurements at the same location and I'd like to use these to
determine the measurement error. I've figured out how to do this in geoR, but as
most of my scripts are written in R using GSTAT, I'd rather use that.

Thank you! Zev



From v.gomezrubio at imperial.ac.uk  Tue Oct 30 16:35:20 2007
From: v.gomezrubio at imperial.ac.uk (Virgilio Gomez-Rubio)
Date: Tue, 30 Oct 2007 15:35:20 +0000
Subject: [R-sig-Geo] R library to perform Small Area Estimation
In-Reply-To: <FA3090E732DC6A4EB8E2D875EEB486A562CE83@EX01.staff.smu.edu.sg>
References: <FA3090E732DC6A4EB8E2D875EEB486A562CE83@EX01.staff.smu.edu.sg>
Message-ID: <1193758520.6138.44.camel@fh-vrubio>

Hi,

You may check packages survey and sampling, available from CRAN. There
is also SAE, available at http://www.bias-project.org.uk/software , but
I guess that you already know that one. :) SAE is still in development
(the code is usable though) and it includes a vignette with examples on
various methods for Small Area Estimation. 

Some other stuff from the Social Sciences Task View may be of interest,
but it will depend on the type of estimates that you want to use.

Hope this helps,

Virgilio


On Mon, 2007-10-29 at 17:43 +0800, KAM Tin Seong wrote:
> Hi R community, I am interested on R library that perform Small Area
> Estimation and wonder if anyone have came across.
> 
> Thanks in advance.
> 
> Dr Kam Tin Seong 
> Practice Associate Professor 
> School of Information Systems 
> 
> Singapore Management University 
> 80 Stamford Road 
> Singapore 178902 
> e-mail: tskam at smu.edu.sg 
> DID: + 65 6828 0932
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From Agustin.Lobo at ija.csic.es  Tue Oct 30 19:38:39 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Tue, 30 Oct 2007 19:38:39 +0100
Subject: [R-sig-Geo] "Abridged" description of SpatialPolygonsDataFrame
 objects?
In-Reply-To: <4725B1E7.5030903@utas.edu.au>
References: <4725A4EE.8030406@ija.csic.es> <4725B1E7.5030903@utas.edu.au>
Message-ID: <47277A2F.9090200@ija.csic.es>

The problem is that, in such a way, the user
does not get a list (and description) of
slots data, proj4string etc.
According to mail exchanged with Roger,
a good way to start would be:

getSlots(class(d))

and then, as you say,

str(d at polygons[[1]])

Agus



Michael Sumner escribi?:
> If "d" is a SPolyDF
> 
> ## first row/object
> d[1,]
> str(d[1,])
> 
> ## the first Polygons object itself  (Polygons can be of many)
> d at polygons[[1]]
> str(d at polygons[[1]])
> 
> ## the first Polygon in the first Polygons object
> d at polygons[[1]]@Polygons[[1]]
> str(d at polygons[[1]]@Polygons[[1]])
> 
> 
> 
> Agustin Lobo wrote:
>> Hi!
>>
>> If I do str(a) where a is a SpatialGridDataFrame, I get
>> a description of the structure that is readable,
>> but for SpatialPolygonsDataFrame the output of str() is
>> too long. Is there any way of looking at the
>> structure of a SpatialPolygonsDataFrame object just down to
>> a certain level? For example, not getting the structure of the
>> each polygon but getting the first one only.
>>
>> Thanks
>> Agus
>>   
> 
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Agustin.Lobo at ija.csic.es  Tue Oct 30 20:06:28 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Tue, 30 Oct 2007 20:06:28 +0100
Subject: [R-sig-Geo] Divide a polygon by a line?
Message-ID: <472780B4.1090509@ija.csic.es>

Is it possible to divide a polygon by a line
into 2 polygons?

Agus
-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Roger.Bivand at nhh.no  Tue Oct 30 20:22:29 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 30 Oct 2007 20:22:29 +0100 (CET)
Subject: [R-sig-Geo] Divide a polygon by a line?
In-Reply-To: <472780B4.1090509@ija.csic.es>
References: <472780B4.1090509@ija.csic.es>
Message-ID: <Pine.LNX.4.64.0710302018000.14848@reclus.nhh.no>

On Tue, 30 Oct 2007, Agustin Lobo wrote:

> Is it possible to divide a polygon by a line
> into 2 polygons?

No, in general. All computational geometry ends up in having to deal with 
the type of polygon. A convex polygon is one thing, and can be divided 
into two parts, but a general polygon may be concave, and the number of 
parts does not have to be two - the line could cross it multiple times. 
The approach taken in the Rgshhs function in maptools is to overlay a 
rectangular box over the polygon(s), and see what comes out, but quite 
often it isn't two (or in that case a single part within the rectangle).

Roger

>
> Agus
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From zev at zevross.com  Tue Oct 30 21:25:23 2007
From: zev at zevross.com (Zev Ross)
Date: Tue, 30 Oct 2007 20:25:23 +0000 (UTC)
Subject: [R-sig-Geo] geoR nugget and coincident locations
Message-ID: <loom.20071030T201748-354@post.gmane.org>

Hi All,

At many monitoring locations we've taken two air quality samples. Rather than
simply average these values, I want to krige all the observations and
accommodate the different values at coincident locations by including
measurement error in the nugget. 

When I run the code based on geoR, though, I get an error that the coincident
locations may "cause crashes in some matrices operations" and I'm wondering if
someone could shed light on the issue -- is this what you'd expect with
coincident locations? Is the code below incorrectly specified?

Thank you, Zev

# ----set up the modelling and validation samples as geodata

model.a<-as.geodata(samples.hull, coords.col=c("x", "y"), 
	data.col="no2.ppb",
	covar.col=c("phase", "traffic)  )

validation.a<-as.geodata(samples.val, coords.col=c("x", "y"), 
	data.col="no2.ppb",
	covar.col=c("phase", "traffic) )

#-----use the modeling samples to estimate the variogram

myvario<-variog(model.a, option="bin",  
	breaks=seq(1,10000, by=300), maxdist=10000,
	trend=~phase+traffic)

#----- fit the variogram

myfit<-variofit(myvario, ini.cov.pars=c(15, 1000), 
	cov.model="spherical")

#----- set kriging to include a trend AND split 
#----- the nugget into micro and measurement

KC<-krige.control(type="ok", obj.model=myfit, micro=myfit$nugget/2,
	trend.d=trend.spatial(~phase+traffic, model.a),
	trend.l=trend.spatial(~phase+traffic, validation.a))

# ----krige 
mykrige<-krige.conv(model.a,locations=validation.a$coords, 
	krige=KC, output=output.control(signal=F) 

# here is the warning

krige.conv: model with covariates matrix provided by the user
krige.conv: Kriging performed using global neighbourhood 
Warning message:
Two or more pairs of data at coincident (or very close) locations. 
This may cause crashes in some matrices operations.
 in: varcov.spatial(coords = coords, cov.model = cov.model, kappa = kappa,



From paulojus at c3sl.ufpr.br  Tue Oct 30 22:02:49 2007
From: paulojus at c3sl.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Tue, 30 Oct 2007 19:02:49 -0200 (BRST)
Subject: [R-sig-Geo] geoR nugget and coincident locations
In-Reply-To: <loom.20071030T201748-354@post.gmane.org>
References: <loom.20071030T201748-354@post.gmane.org>
Message-ID: <Pine.LNX.4.58.0710301859310.20381@talisker.c3sl.ufpr.br>

Dear Zev

The warning is really just a warning and not an error...

the point is you may need some data manipulation in order to run the
analysis you anty.

Firts of all the fact you have duplicated information in (some) locations
may give you the opportunity to split you negget parameter estimate in
measurement error and micro-scale variation.
One possibility to compute the former using the duplicated data (locations
as "blocks" and subtract this from the nugget. The difference givesyouy
the latter.
You can them use thei information when kriging with krige.conv()

hope this helps, otherwise contact me again for further details

best


Paulo Justiniano Ribeiro Jr
LEG (Laborat?rio de Estat?stica e Geoinforma??o)
Universidade Federal do Paran?
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 3361 3573
Fax: (+55) 41 3361 3141
e-mail: paulojus AT  ufpr  br
http://www.leg.ufpr.br/~paulojus

On Tue, 30 Oct 2007, Zev Ross wrote:

> Hi All,
>
> At many monitoring locations we've taken two air quality samples. Rather than
> simply average these values, I want to krige all the observations and
> accommodate the different values at coincident locations by including
> measurement error in the nugget.
>
> When I run the code based on geoR, though, I get an error that the coincident
> locations may "cause crashes in some matrices operations" and I'm wondering if
> someone could shed light on the issue -- is this what you'd expect with
> coincident locations? Is the code below incorrectly specified?
>
> Thank you, Zev
>
> # ----set up the modelling and validation samples as geodata
>
> model.a<-as.geodata(samples.hull, coords.col=c("x", "y"),
> 	data.col="no2.ppb",
> 	covar.col=c("phase", "traffic)  )
>
> validation.a<-as.geodata(samples.val, coords.col=c("x", "y"),
> 	data.col="no2.ppb",
> 	covar.col=c("phase", "traffic) )
>
> #-----use the modeling samples to estimate the variogram
>
> myvario<-variog(model.a, option="bin",
> 	breaks=seq(1,10000, by=300), maxdist=10000,
> 	trend=~phase+traffic)
>
> #----- fit the variogram
>
> myfit<-variofit(myvario, ini.cov.pars=c(15, 1000),
> 	cov.model="spherical")
>
> #----- set kriging to include a trend AND split
> #----- the nugget into micro and measurement
>
> KC<-krige.control(type="ok", obj.model=myfit, micro=myfit$nugget/2,
> 	trend.d=trend.spatial(~phase+traffic, model.a),
> 	trend.l=trend.spatial(~phase+traffic, validation.a))
>
> # ----krige
> mykrige<-krige.conv(model.a,locations=validation.a$coords,
> 	krige=KC, output=output.control(signal=F)
>
> # here is the warning
>
> krige.conv: model with covariates matrix provided by the user
> krige.conv: Kriging performed using global neighbourhood
> Warning message:
> Two or more pairs of data at coincident (or very close) locations.
> This may cause crashes in some matrices operations.
>  in: varcov.spatial(coords = coords, cov.model = cov.model, kappa = kappa,
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From zev at zevross.com  Wed Oct 31 00:37:03 2007
From: zev at zevross.com (Zev Ross)
Date: Tue, 30 Oct 2007 19:37:03 -0400
Subject: [R-sig-Geo] geoR nugget and coincident locations
In-Reply-To: <Pine.LNX.4.58.0710301859310.20381@talisker.c3sl.ufpr.br>
References: <loom.20071030T201748-354@post.gmane.org>
	<Pine.LNX.4.58.0710301859310.20381@talisker.c3sl.ufpr.br>
Message-ID: <4727C01F.9040405@zevross.com>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071030/366c0462/attachment.html>

From hi_ono2001 at ybb.ne.jp  Wed Oct 31 01:48:50 2007
From: hi_ono2001 at ybb.ne.jp (Hisaji ONO)
Date: Wed, 31 Oct 2007 09:48:50 +0900 (JST)
Subject: [R-sig-Geo] About Insightful's S-Plus "SpatialStats" package
In-Reply-To: <Pine.LNX.4.64.0710300821230.14848@reclus.nhh.no>
Message-ID: <20071031004850.84788.qmail@web10702.mail.bbt.yahoo.co.jp>

Thank you for kind answer.

 BTW, how about your spatial statistics book?



                                        Regards.


--- Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Tue, 30 Oct 2007, Hisaji ONO wrote:
> 
> > Hello.
> >
> > Recently Insightful's S-Plus library has been
> ported to R
> > package.
> >
> > However "SpatialStats" package still not yet.
> 
> Insightful have added R-style packages to S-Plus, so
> that R contributed 
> packages can be built for S-Plus, rather than the
> other way round. There 
> may be interest in providing some R-spatial packages
> for S-Plus; sp and 
> gstat have been built for S-Plus in the past. I am
> not aware of Insightful 
> considering releasing the SpatialStats module in
> other forms.
> 
> >
> > Does Anyone know whether Insightful people will
> open
> > their spatial package including MA function(spdep
> not
> > supported) etc
> 
> spautolm() now has MA support, thanks to a generous
> contribution by Jielai 
> Ma, family="SMA", but for obvious reasons, no sparse
> matrix support, so 
> only for up to moderate numbers of observations (say
> 1500+). "CAR" and 
> "SAR" can be used with sparse matrix methods.
> 
> Best wishes,
> 
> Roger
> 
> >
> >
> > Regards.
> >
> >
> 
> -- 
> Roger Bivand
> Economic Geography Section, Department of Economics,
> Norwegian School of
> Economics and Business Administration, Helleveien
> 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Agustin.Lobo at ija.csic.es  Wed Oct 31 08:10:36 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Wed, 31 Oct 2007 08:10:36 +0100
Subject: [R-sig-Geo] Divide a polygon by a line?
In-Reply-To: <Pine.LNX.4.64.0710302018000.14848@reclus.nhh.no>
References: <472780B4.1090509@ija.csic.es>
	<Pine.LNX.4.64.0710302018000.14848@reclus.nhh.no>
Message-ID: <47282A6C.4060409@ija.csic.es>

I've finally done this operation with a GIS. I was trying to
perform all this part of the project within R, trying not to use
any other tool, as a test. It's clear that the boundary
between GIS and spatial analysis is more and more fuzzy.
In my opinion, just importing and exporting between
R and a GIS (i.e. grass) is getting increasingly inconvenient, as
the GIS operations become more an more intermixed
with the analysis. Perhaps the direct integration
of R and Qgis could be a solution (if at least direct
display of R spatial objects in QGis were possible!). But, at this point,
I don't know if this particular operation (dividing the polygon
into two by a line) could have been done in QGis. I used
a commercial vector-based software just because it's the
the tool we normally use and could not put more time
in exploring this issue.

Thanks!

Agus

Roger Bivand escribi?:
> On Tue, 30 Oct 2007, Agustin Lobo wrote:
> 
>> Is it possible to divide a polygon by a line
>> into 2 polygons?
> 
> No, in general. All computational geometry ends up in having to deal 
> with the type of polygon. A convex polygon is one thing, and can be 
> divided into two parts, but a general polygon may be concave, and the 
> number of parts does not have to be two - the line could cross it 
> multiple times. The approach taken in the Rgshhs function in maptools is 
> to overlay a rectangular box over the polygon(s), and see what comes 
> out, but quite often it isn't two (or in that case a single part within 
> the rectangle).
> 
> Roger
> 
>>
>> Agus
>>
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From edzer.pebesma at uni-muenster.de  Wed Oct 31 09:29:02 2007
From: edzer.pebesma at uni-muenster.de (Edzer J. Pebesma)
Date: Wed, 31 Oct 2007 09:29:02 +0100
Subject: [R-sig-Geo] GSTAT - measurement vs microscale variation
In-Reply-To: <loom.20071030T133119-294@post.gmane.org>
References: <loom.20071030T133119-294@post.gmane.org>
Message-ID: <47283CCE.9090109@uni-muenster.de>

Zev,

you can use the "Err" variogram model to denote micro variation as 
opposed to nugget. The only effect it has is that for a new prediction 
on an observation location the measurement error-free process is 
predicted, and not the observation process itself. Semivariance of an 
observation with itself remains zero, so it doesn't allow for duplicate 
observations. In terms of predictions, it is "as if" you predict right 
next to a prediction location in case the prediction location coincides 
with an observation location (implying that the predicted surface is 
continuous); in terms of prediction variance, it is "as if" you predict 
for a very small block, meaning the nugget is removed from the 
prediction variance.

Below is an example for the meuse data set.
--
Edzer

 > library(gstat)
Loading required package: sp
 > data(meuse)
 > meuse0 = meuse
 > coordinates(meuse) = ~x+y
 > # prediction at observation location:
 > krige(log(zinc)~1,meuse,meuse[1,],vgm(.5, "Exp",300,.5))
[using ordinary kriging]
       coordinates var1.pred var1.var
1 (181072, 333611)  6.929517        0
 > krige(log(zinc)~1,meuse,meuse[1,],vgm(.5, 
"Exp",300,add.to=vgm(.5,"Err",0)))
[using ordinary kriging]
       coordinates var1.pred  var1.var
1 (181072, 333611)   6.57884 0.1801634
 > cc = coordinates(meuse)
 > cc[1,] = cc[1,]+0.01 # 1 cm shift on a 5 km region
 > coordinates(meuse0)=cc
 > krige(log(zinc)~1,meuse,meuse[1,],vgm(.5, "Exp",300,.5))
[using ordinary kriging]
       coordinates var1.pred var1.var
1 (181072, 333611)  6.929517        0
 > krige(log(zinc)~1,meuse,meuse0[1,],vgm(.5, "Exp",300,.5))
[using ordinary kriging]
       coordinates var1.pred var1.var
1 (181072, 333611)  6.578803 0.680188
 > krige(log(zinc)~1,meuse,meuse0[1,],vgm(.5, 
"Exp",300,add.to=vgm(.5,"Err",0)))
[using ordinary kriging]
       coordinates var1.pred  var1.var
1 (181072, 333611)  6.578803 0.1801880 # same prediction, variance 0.5 less
 > krige(log(zinc)~1,meuse,meuse[1,],vgm(.5, 
"Exp",300,.5),block=c(0.01,0.01))
[using ordinary kriging]
       coordinates var1.pred  var1.var
1 (181072, 333611)  6.578836 0.1801594



Zev Ross wrote:
> Hi All,
>
> I folded this question into a previous post, but I think it may have gotten
> missed. Just wondering if someone could tell me how, in GSTAT, one would specify
> the nugget as measurement error vs microscale variation in kriging. I have
> multiple measurements at the same location and I'd like to use these to
> determine the measurement error. I've figured out how to do this in geoR, but as
> most of my scripts are written in R using GSTAT, I'd rather use that.
>
> Thank you! Zev
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From g.m.f.vanderheijden04 at leeds.ac.uk  Wed Oct 31 12:54:39 2007
From: g.m.f.vanderheijden04 at leeds.ac.uk (Geertje Van der Heijden)
Date: Wed, 31 Oct 2007 11:54:39 -0000
Subject: [R-sig-Geo] Spdep: help needed calculating Moran's I
In-Reply-To: <Pine.LNX.4.64.0710261934550.14444@reclus.nhh.no>
Message-ID: <E193A286CE83354EB8BAB315F8BE62D317D69B@HERMES4.ds.leeds.ac.uk>

Hi,

Many thanks for the suggestions! I have figured out how to do it now.

Geertje


~~~~
Geertje van der Heijden
PhD student
Tropical Ecology
School of Geography
University of Leeds
Leeds LS2 9JT

Tel: (+44)(0)113 3433345 
Email: g.m.f.vanderheijden04 at leeds.ac.uk


-----Original Message-----
From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Sent: 26 October 2007 18:41
To: Sam Field
Cc: Geertje Van der Heijden; r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] Spdep: help needed calculating Moran's I

On Fri, 26 Oct 2007, Sam Field wrote:

> The value of the Moran's I will always depend on how the spatial 
> weight matrix is defined (and thus more specifically on your choice of

> an upper bound for dnearneigh()).  I don't know if there are any 
> statistical criteria for choosing an upper bound - I imagine somebody 
> has looked into this - I usually use a substantively grounded 
> criteria.  Ask yourself, for example, at what distance is interaction 
> between proximate geographic units no longer possible?  What is 
> generating (do you think) the spatial autocorrelation in residual 
> species richness?  What important variables have you left out and on 
> what spatial scale do their influences operate?
>
> The other, technical consideration, is to pick a number that does not 
> generate very many spatial isolates (i.e. geographic units with no 
> neighbors).
>

This is good advice. A third possibility, given that you have to make an
a-priori choice which neighbours are proximate neighbours, is to use
your original everyone-in binary weights, but to generalise them as
inverse distance weights - see the example using nbdists() on the
nb2listw() help page, using the glist= argument. Then nearer neighbours
get more weight, ones further away less weight (you will also need the
longlat=TRUE argument).

Roger


>
>
> hope this helps!
>
> Sam
>
>
>
> Quoting Geertje Van der Heijden <g.m.f.vanderheijden04 at leeds.ac.uk>:
>
>> Hi,
>>
>> I have just posted the same question on the general R help mailing
list,
>> but thought that this list might be more appropriate. I am a new user
of
>> R.
>>
>> Here is my problem:
>> I have 58 sites from across South America. I have done a regression
>> analysis to relate environmental and biogeographical variables to
>> species richness and want to test whether my residuals are
>> autocorrelated. As far as I understand the Moran's I, I have to take
all
>> possible combinations between all points into account to test this.
So I
>> have used dnearneigh() with the lower boundary set to 0 and the upper
>> boundary set arbitrarily high to make sure all connections are
included.
>>
>>
>>> coords <- as.matrix(cbind(lowland$long, lowland$lat))
>>> coord.nb <- dnearneigh(coords, 0, 10000, longlat=TRUE)
>>> coord.list <- nb2listw(coord.nb, style="W")
>>> lianasp.lm <- lm(lianasprich ~ log(averdist) + dsl + lianadens +
>> wooddens)
>>> lm.morantest(lianasp.lm, coord.list, alternative="two.sided")
>>
>> However, this gives me a Moran's I which is exactly the same as the
>> expected Moran's I (and hence a p-value of 1). If I change the lower
or
>> upper boundary slightly so that not all possible links are taken into
>> account, the value is different, but still really near to the
expected
>> Moran's I. I don't understand why these values are or the same or
nearly
>> so.
>>
>> I am new to spatial statistics, so this might me a really basic
question
>> and my appologies if it is, but I am generally a bit at a loss now
about
>> the Moran's I and I am wondering if I have calculated it right. Have
>> used to right method to convert my coordinates into neighbourhood
>> distances (and if not, which method should I have used) and am I
>> understanding and calculation the Moran's I correctly?
>>
>> Any help would be greatly appreciated.
>>
>> Many thanks,
>> Geertje
>>
>> ~~~~
>> Geertje van der Heijden
>> PhD student
>> Tropical Ecology
>> School of Geography
>> University of Leeds
>> Leeds LS2 9JT
>>
>> Tel: (+44)(0)113 3433345
>> Email: g.m.f.vanderheijden04 at leeds.ac.uk
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From zev at zevross.com  Wed Oct 31 16:34:57 2007
From: zev at zevross.com (Zev Ross)
Date: Wed, 31 Oct 2007 11:34:57 -0400
Subject: [R-sig-Geo] GSTAT - measurement vs microscale variation
In-Reply-To: <47283CCE.9090109@uni-muenster.de>
References: <loom.20071030T133119-294@post.gmane.org>
	<47283CCE.9090109@uni-muenster.de>
Message-ID: <4728A0A1.4000207@zevross.com>

Hi Edzer,

Very useful, thank you. You might be able to tell from my posts that I'm 
running these in parallel in GSTAT and geoR and comparing. It seems from 
your note and example that it might simply be easier to add a centimeter 
(provided a centimeter doesn't matter in the real world) to all the 
coordinates. This way one would not need to keep track of the different 
variances at coincident locations. Do you think this would be an 
acceptable approach?

In terms of your coding, I'm a little uncertain about the meaning of the 
add.to argument and how one might code, for example, half micro-scale 
and half-measurement error. For the example you give, if there was a 
nugget of 0.1 (half micro and half measurement) does my coding below 
look correct? Why is fit.variogram not fitting on the model with error 
-- it's not fitting any of the models I try with measurement error?

Zev

myvgmA<-vgm(.5, "Exp",300, nugget=0.1)
myvgmB<-vgm(.5, "Exp",300,nugget=0.05, add.to=vgm(.05,"Err",0))

fit.variogram(variogram(log(zinc)~1,meuse),model=myvgmA)
  model     psill    range
1   Nug 0.0000000   0.0000
2   Exp 0.7186526 449.7581


fit.variogram(variogram(log(zinc)~1,meuse),model=myvgmB)
  model psill range
1   Err  0.05     0
2   Nug  0.05     0
3   Exp  0.50   300





Edzer J. Pebesma wrote:
> Zev,
>
> you can use the "Err" variogram model to denote micro variation as 
> opposed to nugget. The only effect it has is that for a new prediction 
> on an observation location the measurement error-free process is 
> predicted, and not the observation process itself. Semivariance of an 
> observation with itself remains zero, so it doesn't allow for 
> duplicate observations. In terms of predictions, it is "as if" you 
> predict right next to a prediction location in case the prediction 
> location coincides with an observation location (implying that the 
> predicted surface is continuous); in terms of prediction variance, it 
> is "as if" you predict for a very small block, meaning the nugget is 
> removed from the prediction variance.
>
> Below is an example for the meuse data set.
> -- 
> Edzer
>
> > library(gstat)
> Loading required package: sp
> > data(meuse)
> > meuse0 = meuse
> > coordinates(meuse) = ~x+y
> > # prediction at observation location:
> > krige(log(zinc)~1,meuse,meuse[1,],vgm(.5, "Exp",300,.5))
> [using ordinary kriging]
>       coordinates var1.pred var1.var
> 1 (181072, 333611)  6.929517        0
> > krige(log(zinc)~1,meuse,meuse[1,],vgm(.5, 
> "Exp",300,add.to=vgm(.5,"Err",0)))
> [using ordinary kriging]
>       coordinates var1.pred  var1.var
> 1 (181072, 333611)   6.57884 0.1801634
> > cc = coordinates(meuse)
> > cc[1,] = cc[1,]+0.01 # 1 cm shift on a 5 km region
> > coordinates(meuse0)=cc
> > krige(log(zinc)~1,meuse,meuse[1,],vgm(.5, "Exp",300,.5))
> [using ordinary kriging]
>       coordinates var1.pred var1.var
> 1 (181072, 333611)  6.929517        0
> > krige(log(zinc)~1,meuse,meuse0[1,],vgm(.5, "Exp",300,.5))
> [using ordinary kriging]
>       coordinates var1.pred var1.var
> 1 (181072, 333611)  6.578803 0.680188
> > krige(log(zinc)~1,meuse,meuse0[1,],vgm(.5, 
> "Exp",300,add.to=vgm(.5,"Err",0)))
> [using ordinary kriging]
>       coordinates var1.pred  var1.var
> 1 (181072, 333611)  6.578803 0.1801880 # same prediction, variance 0.5 
> less
> > krige(log(zinc)~1,meuse,meuse[1,],vgm(.5, 
> "Exp",300,.5),block=c(0.01,0.01))
> [using ordinary kriging]
>       coordinates var1.pred  var1.var
> 1 (181072, 333611)  6.578836 0.1801594
>
>
>
> Zev Ross wrote:
>> Hi All,
>>
>> I folded this question into a previous post, but I think it may have 
>> gotten
>> missed. Just wondering if someone could tell me how, in GSTAT, one 
>> would specify
>> the nugget as measurement error vs microscale variation in kriging. I 
>> have
>> multiple measurements at the same location and I'd like to use these to
>> determine the measurement error. I've figured out how to do this in 
>> geoR, but as
>> most of my scripts are written in R using GSTAT, I'd rather use that.
>>
>> Thank you! Zev
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>   
>
>
>

-- 
Zev Ross
ZevRoss Spatial Analysis
303 Fairmount Ave
Ithaca, NY 14850
607-277-0004 (phone)
866-877-3690 (fax, toll-free)
zev at zevross.com



From edzer.pebesma at uni-muenster.de  Wed Oct 31 17:40:05 2007
From: edzer.pebesma at uni-muenster.de (Edzer J. Pebesma)
Date: Wed, 31 Oct 2007 17:40:05 +0100
Subject: [R-sig-Geo] GSTAT - measurement vs microscale variation
In-Reply-To: <4728A0A1.4000207@zevross.com>
References: <loom.20071030T133119-294@post.gmane.org>
	<47283CCE.9090109@uni-muenster.de> <4728A0A1.4000207@zevross.com>
Message-ID: <4728AFE5.3080404@uni-muenster.de>

Zev Ross wrote:
> Hi Edzer,
>
> Very useful, thank you. You might be able to tell from my posts that 
> I'm running these in parallel in GSTAT and geoR and comparing. It 
> seems from your note and example that it might simply be easier to add 
> a centimeter (provided a centimeter doesn't matter in the real world) 
> to all the coordinates. This way one would not need to keep track of 
> the different variances at coincident locations. Do you think this 
> would be an acceptable approach?
>
> In terms of your coding, I'm a little uncertain about the meaning of 
> the add.to argument and how one might code, for example, half 
> micro-scale and half-measurement error. For the example you give, if 
> there was a nugget of 0.1 (half micro and half measurement) does my 
> coding below look correct? 
Yes
> Why is fit.variogram not fitting on the model with error -- it's not 
> fitting any of the models I try with measurement error?
Because both effects are collinear in the fit.

I will need to look a bit closer (meaning, in the code), as it surprised 
me that fitting a "Err" effect with no nugget did not work; I think it 
should.

You can find out fit success (to some degree) by looking at the 
"singular" attribute:

 > myvgmB<-vgm(.5, "Exp",300, add.to=vgm(.05,"Err",0))
 > fit.variogram(variogram(log(zinc)~1,meuse),model=myvgmB)
  model psill range
1   Err  0.05     0
2   Exp  0.50   300
 > x = fit.variogram(variogram(log(zinc)~1,meuse),model=myvgmB)
 > attributes(x)
$names
[1] "model" "psill" "range" "kappa" "ang1"  "ang2"  "ang3"  "anis1" "anis2"

$row.names
[1] 1 2

$class
[1] "variogramModel" "data.frame"   

$singular
[1] TRUE

$SSErr
[1] 0.0001155682

 > attr(x, "singular")
[1] TRUE
--
Edzer
>
> Zev
>
> myvgmA<-vgm(.5, "Exp",300, nugget=0.1)
> myvgmB<-vgm(.5, "Exp",300,nugget=0.05, add.to=vgm(.05,"Err",0))
>
> fit.variogram(variogram(log(zinc)~1,meuse),model=myvgmA)
>  model     psill    range
> 1   Nug 0.0000000   0.0000
> 2   Exp 0.7186526 449.7581
>
>
> fit.variogram(variogram(log(zinc)~1,meuse),model=myvgmB)
>  model psill range
> 1   Err  0.05     0
> 2   Nug  0.05     0
> 3   Exp  0.50   300
>
>
>
>
>
> Edzer J. Pebesma wrote:
>> Zev,
>>
>> you can use the "Err" variogram model to denote micro variation as 
>> opposed to nugget. The only effect it has is that for a new 
>> prediction on an observation location the measurement error-free 
>> process is predicted, and not the observation process itself. 
>> Semivariance of an observation with itself remains zero, so it 
>> doesn't allow for duplicate observations. In terms of predictions, it 
>> is "as if" you predict right next to a prediction location in case 
>> the prediction location coincides with an observation location 
>> (implying that the predicted surface is continuous); in terms of 
>> prediction variance, it is "as if" you predict for a very small 
>> block, meaning the nugget is removed from the prediction variance.
>>
>> Below is an example for the meuse data set.
>> -- 
>> Edzer
>>
>> > library(gstat)
>> Loading required package: sp
>> > data(meuse)
>> > meuse0 = meuse
>> > coordinates(meuse) = ~x+y
>> > # prediction at observation location:
>> > krige(log(zinc)~1,meuse,meuse[1,],vgm(.5, "Exp",300,.5))
>> [using ordinary kriging]
>>       coordinates var1.pred var1.var
>> 1 (181072, 333611)  6.929517        0
>> > krige(log(zinc)~1,meuse,meuse[1,],vgm(.5, 
>> "Exp",300,add.to=vgm(.5,"Err",0)))
>> [using ordinary kriging]
>>       coordinates var1.pred  var1.var
>> 1 (181072, 333611)   6.57884 0.1801634
>> > cc = coordinates(meuse)
>> > cc[1,] = cc[1,]+0.01 # 1 cm shift on a 5 km region
>> > coordinates(meuse0)=cc
>> > krige(log(zinc)~1,meuse,meuse[1,],vgm(.5, "Exp",300,.5))
>> [using ordinary kriging]
>>       coordinates var1.pred var1.var
>> 1 (181072, 333611)  6.929517        0
>> > krige(log(zinc)~1,meuse,meuse0[1,],vgm(.5, "Exp",300,.5))
>> [using ordinary kriging]
>>       coordinates var1.pred var1.var
>> 1 (181072, 333611)  6.578803 0.680188
>> > krige(log(zinc)~1,meuse,meuse0[1,],vgm(.5, 
>> "Exp",300,add.to=vgm(.5,"Err",0)))
>> [using ordinary kriging]
>>       coordinates var1.pred  var1.var
>> 1 (181072, 333611)  6.578803 0.1801880 # same prediction, variance 
>> 0.5 less
>> > krige(log(zinc)~1,meuse,meuse[1,],vgm(.5, 
>> "Exp",300,.5),block=c(0.01,0.01))
>> [using ordinary kriging]
>>       coordinates var1.pred  var1.var
>> 1 (181072, 333611)  6.578836 0.1801594
>>
>>
>>
>> Zev Ross wrote:
>>> Hi All,
>>>
>>> I folded this question into a previous post, but I think it may have 
>>> gotten
>>> missed. Just wondering if someone could tell me how, in GSTAT, one 
>>> would specify
>>> the nugget as measurement error vs microscale variation in kriging. 
>>> I have
>>> multiple measurements at the same location and I'd like to use these to
>>> determine the measurement error. I've figured out how to do this in 
>>> geoR, but as
>>> most of my scripts are written in R using GSTAT, I'd rather use that.
>>>
>>> Thank you! Zev
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>   
>>
>>
>>
>



From zev at zevross.com  Wed Oct 31 17:49:29 2007
From: zev at zevross.com (Zev Ross)
Date: Wed, 31 Oct 2007 12:49:29 -0400
Subject: [R-sig-Geo] GSTAT - measurement vs microscale variation
In-Reply-To: <4728AFE5.3080404@uni-muenster.de>
References: <loom.20071030T133119-294@post.gmane.org>
	<47283CCE.9090109@uni-muenster.de> <4728A0A1.4000207@zevross.com>
	<4728AFE5.3080404@uni-muenster.de>
Message-ID: <4728B219.8020707@zevross.com>

Edzer,

Thanks again. If both effects (microscale variation and measurement 
error) are collinear in the fit should one not try to include both? 
Perhaps it's simply better to jitter by a centimeter. And by the way, 
I'm doing universal kriging with the krige function, is there a way to 
get out the beta coefficients? As in:

krige(formula=no2.ppb~traffic, mydata, newdata=mynewdata,model=vgmRaw)

I'd like to get the WLS or GLS estimate of traffic.

This back and forth is asking a lot of your time, I really appreciate 
your quick replies. Thanks!

Zev

Edzer J. Pebesma wrote:
> Zev Ross wrote:
>> Hi Edzer,
>>
>> Very useful, thank you. You might be able to tell from my posts that 
>> I'm running these in parallel in GSTAT and geoR and comparing. It 
>> seems from your note and example that it might simply be easier to 
>> add a centimeter (provided a centimeter doesn't matter in the real 
>> world) to all the coordinates. This way one would not need to keep 
>> track of the different variances at coincident locations. Do you 
>> think this would be an acceptable approach?
>>
>> In terms of your coding, I'm a little uncertain about the meaning of 
>> the add.to argument and how one might code, for example, half 
>> micro-scale and half-measurement error. For the example you give, if 
>> there was a nugget of 0.1 (half micro and half measurement) does my 
>> coding below look correct? 
> Yes
>> Why is fit.variogram not fitting on the model with error -- it's not 
>> fitting any of the models I try with measurement error?
> Because both effects are collinear in the fit.
>
> I will need to look a bit closer (meaning, in the code), as it 
> surprised me that fitting a "Err" effect with no nugget did not work; 
> I think it should.
>
> You can find out fit success (to some degree) by looking at the 
> "singular" attribute:
>
> > myvgmB<-vgm(.5, "Exp",300, add.to=vgm(.05,"Err",0))
> > fit.variogram(variogram(log(zinc)~1,meuse),model=myvgmB)
>  model psill range
> 1   Err  0.05     0
> 2   Exp  0.50   300
> > x = fit.variogram(variogram(log(zinc)~1,meuse),model=myvgmB)
> > attributes(x)
> $names
> [1] "model" "psill" "range" "kappa" "ang1"  "ang2"  "ang3"  "anis1" 
> "anis2"
>
> $row.names
> [1] 1 2
>
> $class
> [1] "variogramModel" "data.frame"  
> $singular
> [1] TRUE
>
> $SSErr
> [1] 0.0001155682
>
> > attr(x, "singular")
> [1] TRUE
> -- 
> Edzer
>>
>> Zev
>>
>> myvgmA<-vgm(.5, "Exp",300, nugget=0.1)
>> myvgmB<-vgm(.5, "Exp",300,nugget=0.05, add.to=vgm(.05,"Err",0))
>>
>> fit.variogram(variogram(log(zinc)~1,meuse),model=myvgmA)
>>  model     psill    range
>> 1   Nug 0.0000000   0.0000
>> 2   Exp 0.7186526 449.7581
>>
>>
>> fit.variogram(variogram(log(zinc)~1,meuse),model=myvgmB)
>>  model psill range
>> 1   Err  0.05     0
>> 2   Nug  0.05     0
>> 3   Exp  0.50   300
>>
>>
>>
>>
>>
>> Edzer J. Pebesma wrote:
>>> Zev,
>>>
>>> you can use the "Err" variogram model to denote micro variation as 
>>> opposed to nugget. The only effect it has is that for a new 
>>> prediction on an observation location the measurement error-free 
>>> process is predicted, and not the observation process itself. 
>>> Semivariance of an observation with itself remains zero, so it 
>>> doesn't allow for duplicate observations. In terms of predictions, 
>>> it is "as if" you predict right next to a prediction location in 
>>> case the prediction location coincides with an observation location 
>>> (implying that the predicted surface is continuous); in terms of 
>>> prediction variance, it is "as if" you predict for a very small 
>>> block, meaning the nugget is removed from the prediction variance.
>>>
>>> Below is an example for the meuse data set.
>>> -- 
>>> Edzer
>>>
>>> > library(gstat)
>>> Loading required package: sp
>>> > data(meuse)
>>> > meuse0 = meuse
>>> > coordinates(meuse) = ~x+y
>>> > # prediction at observation location:
>>> > krige(log(zinc)~1,meuse,meuse[1,],vgm(.5, "Exp",300,.5))
>>> [using ordinary kriging]
>>>       coordinates var1.pred var1.var
>>> 1 (181072, 333611)  6.929517        0
>>> > krige(log(zinc)~1,meuse,meuse[1,],vgm(.5, 
>>> "Exp",300,add.to=vgm(.5,"Err",0)))
>>> [using ordinary kriging]
>>>       coordinates var1.pred  var1.var
>>> 1 (181072, 333611)   6.57884 0.1801634
>>> > cc = coordinates(meuse)
>>> > cc[1,] = cc[1,]+0.01 # 1 cm shift on a 5 km region
>>> > coordinates(meuse0)=cc
>>> > krige(log(zinc)~1,meuse,meuse[1,],vgm(.5, "Exp",300,.5))
>>> [using ordinary kriging]
>>>       coordinates var1.pred var1.var
>>> 1 (181072, 333611)  6.929517        0
>>> > krige(log(zinc)~1,meuse,meuse0[1,],vgm(.5, "Exp",300,.5))
>>> [using ordinary kriging]
>>>       coordinates var1.pred var1.var
>>> 1 (181072, 333611)  6.578803 0.680188
>>> > krige(log(zinc)~1,meuse,meuse0[1,],vgm(.5, 
>>> "Exp",300,add.to=vgm(.5,"Err",0)))
>>> [using ordinary kriging]
>>>       coordinates var1.pred  var1.var
>>> 1 (181072, 333611)  6.578803 0.1801880 # same prediction, variance 
>>> 0.5 less
>>> > krige(log(zinc)~1,meuse,meuse[1,],vgm(.5, 
>>> "Exp",300,.5),block=c(0.01,0.01))
>>> [using ordinary kriging]
>>>       coordinates var1.pred  var1.var
>>> 1 (181072, 333611)  6.578836 0.1801594
>>>
>>>
>>>
>>> Zev Ross wrote:
>>>> Hi All,
>>>>
>>>> I folded this question into a previous post, but I think it may 
>>>> have gotten
>>>> missed. Just wondering if someone could tell me how, in GSTAT, one 
>>>> would specify
>>>> the nugget as measurement error vs microscale variation in kriging. 
>>>> I have
>>>> multiple measurements at the same location and I'd like to use 
>>>> these to
>>>> determine the measurement error. I've figured out how to do this in 
>>>> geoR, but as
>>>> most of my scripts are written in R using GSTAT, I'd rather use that.
>>>>
>>>> Thank you! Zev
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>   
>>>
>>>
>>>
>>
>
>
>

-- 
Zev Ross
ZevRoss Spatial Analysis
303 Fairmount Ave
Ithaca, NY 14850
607-277-0004 (phone)
866-877-3690 (fax, toll-free)
zev at zevross.com



From edzer.pebesma at uni-muenster.de  Wed Oct 31 18:07:20 2007
From: edzer.pebesma at uni-muenster.de (Edzer J. Pebesma)
Date: Wed, 31 Oct 2007 18:07:20 +0100
Subject: [R-sig-Geo] GSTAT - measurement vs microscale variation
In-Reply-To: <4728B219.8020707@zevross.com>
References: <loom.20071030T133119-294@post.gmane.org>
	<47283CCE.9090109@uni-muenster.de> <4728A0A1.4000207@zevross.com>
	<4728AFE5.3080404@uni-muenster.de> <4728B219.8020707@zevross.com>
Message-ID: <4728B648.3060102@uni-muenster.de>

You can.

It is a bit of a hack, but predict.gstat() has a BLUE=TRUE optional 
argument, to return the trend component only rather than trend + 
predicted residual as kriging does. Then, if you specify the predictor 
values for the new location as c(1,0,0,... etc), you get out the trend 
coefficient estimate for that location (location matters if you use 
local search neighbourhoods).
--
Edzer

Zev Ross wrote:
> Edzer,
>
> Thanks again. If both effects (microscale variation and measurement 
> error) are collinear in the fit should one not try to include both?
I can't follow you here. Collinear means: unable to fit both. Like 
fitting two intercepts instead of one.
> Perhaps it's simply better to jitter by a centimeter. And by the way, 
> I'm doing universal kriging with the krige function, is there a way to 
> get out the beta coefficients? As in:
>
> krige(formula=no2.ppb~traffic, mydata, newdata=mynewdata,model=vgmRaw)
>
> I'd like to get the WLS or GLS estimate of traffic.
>
> This back and forth is asking a lot of your time, I really appreciate 
> your quick replies. Thanks!
>
> Zev
>
> Edzer J. Pebesma wrote:
>> Zev Ross wrote:
>>> Hi Edzer,
>>>
>>> Very useful, thank you. You might be able to tell from my posts that 
>>> I'm running these in parallel in GSTAT and geoR and comparing. It 
>>> seems from your note and example that it might simply be easier to 
>>> add a centimeter (provided a centimeter doesn't matter in the real 
>>> world) to all the coordinates. This way one would not need to keep 
>>> track of the different variances at coincident locations. Do you 
>>> think this would be an acceptable approach?
>>>
>>> In terms of your coding, I'm a little uncertain about the meaning of 
>>> the add.to argument and how one might code, for example, half 
>>> micro-scale and half-measurement error. For the example you give, if 
>>> there was a nugget of 0.1 (half micro and half measurement) does my 
>>> coding below look correct? 
>> Yes
>>> Why is fit.variogram not fitting on the model with error -- it's not 
>>> fitting any of the models I try with measurement error?
>> Because both effects are collinear in the fit.
>>
>> I will need to look a bit closer (meaning, in the code), as it 
>> surprised me that fitting a "Err" effect with no nugget did not work; 
>> I think it should.
>>
>> You can find out fit success (to some degree) by looking at the 
>> "singular" attribute:
>>
>> > myvgmB<-vgm(.5, "Exp",300, add.to=vgm(.05,"Err",0))
>> > fit.variogram(variogram(log(zinc)~1,meuse),model=myvgmB)
>>  model psill range
>> 1   Err  0.05     0
>> 2   Exp  0.50   300
>> > x = fit.variogram(variogram(log(zinc)~1,meuse),model=myvgmB)
>> > attributes(x)
>> $names
>> [1] "model" "psill" "range" "kappa" "ang1"  "ang2"  "ang3"  "anis1" 
>> "anis2"
>>
>> $row.names
>> [1] 1 2
>>
>> $class
>> [1] "variogramModel" "data.frame"  $singular
>> [1] TRUE
>>
>> $SSErr
>> [1] 0.0001155682
>>
>> > attr(x, "singular")
>> [1] TRUE
>> -- 
>> Edzer
>>>
>>> Zev
>>>
>>> myvgmA<-vgm(.5, "Exp",300, nugget=0.1)
>>> myvgmB<-vgm(.5, "Exp",300,nugget=0.05, add.to=vgm(.05,"Err",0))
>>>
>>> fit.variogram(variogram(log(zinc)~1,meuse),model=myvgmA)
>>>  model     psill    range
>>> 1   Nug 0.0000000   0.0000
>>> 2   Exp 0.7186526 449.7581
>>>
>>>
>>> fit.variogram(variogram(log(zinc)~1,meuse),model=myvgmB)
>>>  model psill range
>>> 1   Err  0.05     0
>>> 2   Nug  0.05     0
>>> 3   Exp  0.50   300
>>>
>>>
>>>
>>>
>>>
>>> Edzer J. Pebesma wrote:
>>>> Zev,
>>>>
>>>> you can use the "Err" variogram model to denote micro variation as 
>>>> opposed to nugget. The only effect it has is that for a new 
>>>> prediction on an observation location the measurement error-free 
>>>> process is predicted, and not the observation process itself. 
>>>> Semivariance of an observation with itself remains zero, so it 
>>>> doesn't allow for duplicate observations. In terms of predictions, 
>>>> it is "as if" you predict right next to a prediction location in 
>>>> case the prediction location coincides with an observation location 
>>>> (implying that the predicted surface is continuous); in terms of 
>>>> prediction variance, it is "as if" you predict for a very small 
>>>> block, meaning the nugget is removed from the prediction variance.
>>>>
>>>> Below is an example for the meuse data set.
>>>> -- 
>>>> Edzer
>>>>
>>>> > library(gstat)
>>>> Loading required package: sp
>>>> > data(meuse)
>>>> > meuse0 = meuse
>>>> > coordinates(meuse) = ~x+y
>>>> > # prediction at observation location:
>>>> > krige(log(zinc)~1,meuse,meuse[1,],vgm(.5, "Exp",300,.5))
>>>> [using ordinary kriging]
>>>>       coordinates var1.pred var1.var
>>>> 1 (181072, 333611)  6.929517        0
>>>> > krige(log(zinc)~1,meuse,meuse[1,],vgm(.5, 
>>>> "Exp",300,add.to=vgm(.5,"Err",0)))
>>>> [using ordinary kriging]
>>>>       coordinates var1.pred  var1.var
>>>> 1 (181072, 333611)   6.57884 0.1801634
>>>> > cc = coordinates(meuse)
>>>> > cc[1,] = cc[1,]+0.01 # 1 cm shift on a 5 km region
>>>> > coordinates(meuse0)=cc
>>>> > krige(log(zinc)~1,meuse,meuse[1,],vgm(.5, "Exp",300,.5))
>>>> [using ordinary kriging]
>>>>       coordinates var1.pred var1.var
>>>> 1 (181072, 333611)  6.929517        0
>>>> > krige(log(zinc)~1,meuse,meuse0[1,],vgm(.5, "Exp",300,.5))
>>>> [using ordinary kriging]
>>>>       coordinates var1.pred var1.var
>>>> 1 (181072, 333611)  6.578803 0.680188
>>>> > krige(log(zinc)~1,meuse,meuse0[1,],vgm(.5, 
>>>> "Exp",300,add.to=vgm(.5,"Err",0)))
>>>> [using ordinary kriging]
>>>>       coordinates var1.pred  var1.var
>>>> 1 (181072, 333611)  6.578803 0.1801880 # same prediction, variance 
>>>> 0.5 less
>>>> > krige(log(zinc)~1,meuse,meuse[1,],vgm(.5, 
>>>> "Exp",300,.5),block=c(0.01,0.01))
>>>> [using ordinary kriging]
>>>>       coordinates var1.pred  var1.var
>>>> 1 (181072, 333611)  6.578836 0.1801594
>>>>
>>>>
>>>>
>>>> Zev Ross wrote:
>>>>> Hi All,
>>>>>
>>>>> I folded this question into a previous post, but I think it may 
>>>>> have gotten
>>>>> missed. Just wondering if someone could tell me how, in GSTAT, one 
>>>>> would specify
>>>>> the nugget as measurement error vs microscale variation in 
>>>>> kriging. I have
>>>>> multiple measurements at the same location and I'd like to use 
>>>>> these to
>>>>> determine the measurement error. I've figured out how to do this 
>>>>> in geoR, but as
>>>>> most of my scripts are written in R using GSTAT, I'd rather use that.
>>>>>
>>>>> Thank you! Zev
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>   
>>>>
>>>>
>>>>
>>>
>>
>>
>>
>



From fieldsh at mail.med.upenn.edu  Wed Oct 31 21:46:38 2007
From: fieldsh at mail.med.upenn.edu (Sam Field)
Date: Wed, 31 Oct 2007 16:46:38 -0400
Subject: [R-sig-Geo] centering explanatory variables around spatial lag
In-Reply-To: <4728B219.8020707@zevross.com>
References: <loom.20071030T133119-294@post.gmane.org>
	<47283CCE.9090109@uni-muenster.de> <4728A0A1.4000207@zevross.com>
	<4728AFE5.3080404@uni-muenster.de> <4728B219.8020707@zevross.com>
Message-ID: <1193863597.4728e9ae0050b@webmail.pobox.upenn.edu>

List,

When the influence of explanatory variables "spills over" into adjacent or
proximate spatial units, one way to model this would be to include a spatially
lagged explanatory variable (WX). If there exists a significant spatially lagged
association, then (it would seem to me) the influence of X would be biased if it
is correlated with WX (which it would be if X was non_randomly distributed in
space). In other words, the effect of X is confounded with WX if the two are
correlated AND both have independent impacts on the outcome.  It would seem that
a properly specified model would include both the effects of X and WX.  One
potential problem is that X and WX maybe highly correlated leading to
instability in the estimation of their independent effects.  It seems a
solution, analogous to what is often done in multi-level models, is to center X
on its spatial average, WX.  Thus,

yhat = b0 + b1(X - WX) + b2(WX).

where the influence of WX is now a function of two parameters: (b2-b1)WX and the
null H0:b2-b1 = 0

Is there a reason not to do this with spatially lagged explanatory variables? 
Is there any literature on this?  I have an empirical example in which the
results from centering versus non centering differ dramatically, so I want to
make sure that the situation is analogous to the multi-level case before
proceeding.  I could do some simulation, but I thought I would ask the list first.



thanks!



Sam







 




-- 
********Note the new contact information*******

Samuel H. Field, Ph.D. 
Senior Research Investigator
CHERP/Division of Internal Medicine - University of Pennsylvania
Philadelphia VA Medical Center
3900 Woodland Ave (9 East)
Philadelphia, PA 19104
(215) 823-5800 EXT. 6155 (Office)
(215) 823-6330 (Fax)



