From jwm302 at gmail.com  Mon Sep  1 12:06:02 2014
From: jwm302 at gmail.com (Justin Michell)
Date: Mon, 1 Sep 2014 12:06:02 +0200
Subject: [R-sig-Geo] Raster Layers same resolution but not the same
	coordinates over the same area
In-Reply-To: <CANtt_hzbGJgPHZTgs01gzSi_FxpLae=_2xg1c9xbkEJ6jRz3ow@mail.gmail.com>
References: <FEFE7375-7C62-47E7-B906-BB257581C587@gmail.com>
	<csym1f9skc7sbexltddb6dc3.1403877499889@email.android.com>
	<4A71BF68-2BC3-48FC-B988-80CB966F46FF@gmail.com>
	<CABG0rfvymz-7HXdcPS3DvXzQ9eDuojP-sDWZqxP6+5iuiJ46zQ@mail.gmail.com>
	<5B0127DE-CE8B-4E9D-B9D2-238B92178A79@gmail.com>
	<A618DF42-6AAF-48F6-B886-94B33A64517E@gmail.com>
	<CANtt_hzbGJgPHZTgs01gzSi_FxpLae=_2xg1c9xbkEJ6jRz3ow@mail.gmail.com>
Message-ID: <788E51AC-EAC8-4BFC-B620-C4D5FDE8023A@gmail.com>

Hi Robert

All right, I see. Do my layers not match because my resolution is slightly different between the rasters (do they have to be exact to some decimal level?) or because my dimensions are not the same? Or do these differences (resolutions/dimensions) amount to the the same thing? I apologize if this has been dealt with previously somewhere on this list.

I thought they would match after changing the projection for NDVI because my MODIS NDVI data is at 1-kilometer spatial resolution and so is my worldclim data. 

I was using this approach (advised by a previous post that gdalwarp reprojects/resamples all at once):

> # Warp
> gdalwarp(srcfile=sdsList, t_srs="+proj=longlat +datum=WGS84 +no_defs",
> dstfile=file.path(dir, ?NDVI.tif'))


Would I still need afterwards to complete resampling correctly set the smallest nrow (x) and ncol (y) among the rasters. So something like this:

s <- raster(nrow=x, nrow=y)

NDVIRaster <- resample(NDVIRaster, s, method=?ngb?)

Justin


On Aug 31, 2014, at 12:46 AM, Robert J. Hijmans <r.hijmans at gmail.com> wrote:

> Justin,
> 
> The RasterStack approach is fine, but as you show, the layers do not
> match. The resolution of NDVIStack is larger than the resolution of
> rainStack; it seems that you did not resample the NDVI data correctly.
> 
> Robert
> 
> 
> 
> On Sat, Aug 30, 2014 at 4:31 AM, Justin Michell <jwm302 at gmail.com> wrote:
>> My apologies, I forgot to send as plain text.
>> 
>> On Aug 30, 2014, at 1:27 PM, Justin Michell <jwm302 at gmail.com> wrote:
>> 
>>> Hi Jonathan
>>> 
>>> I tried that.. But I am but the results don?t make sense:
>>> 
>>>> head(NDVIStackDf)
>>>        x         y     NDVI1     NDVI2    NDVI3     NDVI4    NDVI5     NDVI6     NDVI7     NDVI8     NDVI9    NDVI10    NDVI11    NDVI12
>>> 1 29.42809 -1.002081 0.7196462 0.6093929 0.614475 0.7851786 0.799475 0.7241929 0.5946000 0.5948500 0.6585143 0.7874357 0.8305786 0.7774929
>>> 2 29.43662 -1.002081 0.7103154 0.5823500 0.572225 0.7867429 0.794050 0.7445643 0.6033786 0.5635429 0.6421857 0.7802786 0.8300643 0.7886786
>>> 3 29.44514 -1.002081 0.7303692 0.6254571 0.599350 0.7771143 0.785850 0.7510071 0.6404571 0.6197286 0.6770929 0.7686786 0.8169571 0.7957786
>>> 4 29.45367 -1.002081 0.7641923 0.6890714 0.657850 0.7936786 0.809975 0.7805429 0.6769643 0.6590714 0.7165357 0.7843357 0.8283286 0.8231500
>>> 5 29.46220 -1.002081 0.8057769 0.7500714 0.718175 0.8208786 0.838575 0.8126500 0.7345786 0.7359571 0.7661214 0.8087214 0.8442643 0.8380071
>>> 6 29.47073 -1.002081 0.8065615 0.7627071 0.730550 0.8142214 0.841100 0.8252000 0.7574786 0.7425071 0.7590571 0.8025071 0.8518357 0.8430286
>>>> head(rainStackDf)
>>>        x         y rain1 rain2 rain3 rain4 rain5 rain6 rain7 rain8 rain9 rain10 rain11 rain12
>>> 1 29.42917 -1.004167    66    68    85   116   105    61    40    85   110    125    118     85
>>> 2 29.43750 -1.004167    66    69    85   117   106    61    40    85   110    125    119     86
>>> 3 29.44583 -1.004167    66    68    84   116   106    60    39    84   110    124    118     85
>>> 4 29.45417 -1.004167    65    67    83   116   105    60    39    83   108    123    117     84
>>> 5 29.46250 -1.004167    65    68    83   117   106    59    38    83   109    124    118     84
>>> 6 29.47083 -1.004167    66    68    84   118   107    59    38    83   110    125    119     85
>>>> mystackDf <- stack(NDVIStackDf, rainStackDf)
>>>> 
>>>> head(mystackDf)
>>>   values ind
>>> 1 29.42809   x
>>> 2 29.43662   x
>>> 3 29.44514   x
>>> 4 29.45367   x
>>> 5 29.46220   x
>>> 6 29.47073   x
>>> 
>>> Is there a better way maybe without using data frames?
>>> 
>>> I tried stacking the stacks too:
>>> 
>>>> s1 <- stack(NDVIStack, rainStack)
>>> Error in compareRaster(x) : different number or columns
>>>> rainStack
>>> class       : RasterStack
>>> dimensions  : 1287, 1321, 1700127, 12  (nrow, ncol, ncell, nlayers)
>>> resolution  : 0.008333333, 0.008333333  (x, y)
>>> extent      : 29.425, 40.43333, -11.725, -1  (xmin, xmax, ymin, ymax)
>>> coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
>>> names       : rain1, rain2, rain3, rain4, rain5, rain6, rain7, rain8, rain9, rain10, rain11, rain12
>>> min values  :     7,     5,    31,    13,     0,     0,     0,     0,     0,      0,     22,     32
>>> max values  :   391,   392,   563,   746,   473,   159,   109,   106,   164,    247,    349,    464
>>> 
>>>> NDVIStack
>>> class       : RasterStack
>>> dimensions  : 1258, 1291, 1624078, 12  (nrow, ncol, ncell, nlayers)
>>> resolution  : 0.008526982, 0.008525437  (x, y)
>>> extent      : 29.425, 40.43333, -11.725, -1  (xmin, xmax, ymin, ymax)
>>> coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
>>> names       :      NDVI1,      NDVI2,      NDVI3,      NDVI4,      NDVI5,      NDVI6,      NDVI7,      NDVI8,      NDVI9,     NDVI10,     NDVI11,     NDVI12
>>> min values  : -0.1524615, -0.1353071, -0.1970500, -0.1632071, -0.1919250, -0.1647286, -0.1665000, -0.1693357, -0.1852643, -0.1733714, -0.1555357, -0.1682571
>>> max values  :  0.9153615,  0.9013000,  0.9295500,  0.9134643,  0.9421750,  0.9158357,  0.9000071,  0.9009786,  0.8733571,  0.8792429,  0.9151357,  0.9233000
>>> 
>>> Thanks
>>> Justin
>>> 
>>> On Jun 30, 2014, at 5:55 PM, Jonathan Greenberg <jgrn at illinois.edu> wrote:
>>> 
>>>> Justin:
>>>> 
>>>> It would make more sense, if you insist on working with data.frames,
>>>> for you to create a single stack with all of your predictor and
>>>> response variables, and then do your extraction -- that way you don't
>>>> need to worry about a merge after the fact.  The chances of the
>>>> coordinates being EXACT I suspect are very low, which is why the
>>>> merge() is failing.
>>>> 
>>>> Basically:
>>>> 
>>>> mystack <- stack(meanTempStackDf, rainStackDf)
>>>> 
>>>> ... Then you can extract the data.
>>>> 
>>>> --j
>>>> 
>>>> On Mon, Jun 30, 2014 at 6:22 AM, Justin Michell <jwm302 at gmail.com> wrote:
>>>>> Dear Niandou
>>>>> 
>>>>> No I have not received any feedback.
>>>>> 
>>>>> I do have some thoughts though. Is it possible/or at least would it make sense to get values in NDVI layer (average of nearby cells?) at the coordinates of raster values in other layers which one wants to merge with?
>>>>> 
>>>>> I am not very well versed in these things so it?s just a thought- not sure how it would be implemented in R.
>>>>> 
>>>>> Regards
>>>>> Justin
>>>>> 
>>>>> 
>>>>> On Jun 27, 2014, at 3:58 PM, ISSAKA NIANDOU, Yacouba <niandouy at who.int> wrote:
>>>>> 
>>>>>> Niandou
>>>>> 
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at r-project.org
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>> 
>>>> 
>>>> 
>>>> --
>>>> Jonathan A. Greenberg, PhD
>>>> Assistant Professor
>>>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>>>> Department of Geography and Geographic Information Science
>>>> University of Illinois at Urbana-Champaign
>>>> 259 Computing Applications Building, MC-150
>>>> 605 East Springfield Avenue
>>>> Champaign, IL  61820-6371
>>>> Phone: 217-300-1924
>>>> http://www.geog.illinois.edu/~jgrn/
>>>> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>>> 
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Mon Sep  1 19:13:24 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Mon, 1 Sep 2014 10:13:24 -0700
Subject: [R-sig-Geo] Raster Layers same resolution but not the same
 coordinates over the same area
In-Reply-To: <788E51AC-EAC8-4BFC-B620-C4D5FDE8023A@gmail.com>
References: <FEFE7375-7C62-47E7-B906-BB257581C587@gmail.com>
	<csym1f9skc7sbexltddb6dc3.1403877499889@email.android.com>
	<4A71BF68-2BC3-48FC-B988-80CB966F46FF@gmail.com>
	<CABG0rfvymz-7HXdcPS3DvXzQ9eDuojP-sDWZqxP6+5iuiJ46zQ@mail.gmail.com>
	<5B0127DE-CE8B-4E9D-B9D2-238B92178A79@gmail.com>
	<A618DF42-6AAF-48F6-B886-94B33A64517E@gmail.com>
	<CANtt_hzbGJgPHZTgs01gzSi_FxpLae=_2xg1c9xbkEJ6jRz3ow@mail.gmail.com>
	<788E51AC-EAC8-4BFC-B620-C4D5FDE8023A@gmail.com>
Message-ID: <CANtt_hxmRGugBMyLLw-QOY=rQE-4YJtMMRSrEvznOTN=hu212A@mail.gmail.com>

Justin,

I would not call this a slight difference (several rows and columns
difference, whereas these numbers have to be the same to align the
cells):

>>> dimensions  : 1287, 1321, 1700127, 12  (nrow, ncol, ncell, nlayers)
>>> resolution  : 0.008333333, 0.008333333  (x, y)

>>> dimensions  : 1258, 1291, 1624078, 12  (nrow, ncol, ncell, nlayers)
>>> resolution  : 0.008526982, 0.008525437  (x, y)


You need to tell GDALwarp not only the extent you want, but also the
number of rows and columns (or the resolution, but that is more prone
to creating slight differences due to imprecision).
But by far the easiest solution is to use this:

NDVI <- projectRaster("original ndivi data stack", rainStack)

( that takes a little longer to run, but it should not be too bad for
these data (not that much), and would have been much faster overall,
of course, if you take all your time into account).

Robert


On Mon, Sep 1, 2014 at 3:06 AM, Justin Michell <jwm302 at gmail.com> wrote:
> Hi Robert
>
> All right, I see. Do my layers not match because my resolution is slightly different between the rasters (do they have to be exact to some decimal level?) or because my dimensions are not the same? Or do these differences (resolutions/dimensions) amount to the the same thing? I apologize if this has been dealt with previously somewhere on this list.
>
> I thought they would match after changing the projection for NDVI because my MODIS NDVI data is at 1-kilometer spatial resolution and so is my worldclim data.
>
> I was using this approach (advised by a previous post that gdalwarp reprojects/resamples all at once):
>
>> # Warp
>> gdalwarp(srcfile=sdsList, t_srs="+proj=longlat +datum=WGS84 +no_defs",
>> dstfile=file.path(dir, ?NDVI.tif'))
>
>
> Would I still need afterwards to complete resampling correctly set the smallest nrow (x) and ncol (y) among the rasters. So something like this:
>
> s <- raster(nrow=x, nrow=y)
>
> NDVIRaster <- resample(NDVIRaster, s, method=?ngb?)
>
> Justin
>
>
> On Aug 31, 2014, at 12:46 AM, Robert J. Hijmans <r.hijmans at gmail.com> wrote:
>
>> Justin,
>>
>> The RasterStack approach is fine, but as you show, the layers do not
>> match. The resolution of NDVIStack is larger than the resolution of
>> rainStack; it seems that you did not resample the NDVI data correctly.
>>
>> Robert
>>
>>
>>
>> On Sat, Aug 30, 2014 at 4:31 AM, Justin Michell <jwm302 at gmail.com> wrote:
>>> My apologies, I forgot to send as plain text.
>>>
>>> On Aug 30, 2014, at 1:27 PM, Justin Michell <jwm302 at gmail.com> wrote:
>>>
>>>> Hi Jonathan
>>>>
>>>> I tried that.. But I am but the results don?t make sense:
>>>>
>>>>> head(NDVIStackDf)
>>>>        x         y     NDVI1     NDVI2    NDVI3     NDVI4    NDVI5     NDVI6     NDVI7     NDVI8     NDVI9    NDVI10    NDVI11    NDVI12
>>>> 1 29.42809 -1.002081 0.7196462 0.6093929 0.614475 0.7851786 0.799475 0.7241929 0.5946000 0.5948500 0.6585143 0.7874357 0.8305786 0.7774929
>>>> 2 29.43662 -1.002081 0.7103154 0.5823500 0.572225 0.7867429 0.794050 0.7445643 0.6033786 0.5635429 0.6421857 0.7802786 0.8300643 0.7886786
>>>> 3 29.44514 -1.002081 0.7303692 0.6254571 0.599350 0.7771143 0.785850 0.7510071 0.6404571 0.6197286 0.6770929 0.7686786 0.8169571 0.7957786
>>>> 4 29.45367 -1.002081 0.7641923 0.6890714 0.657850 0.7936786 0.809975 0.7805429 0.6769643 0.6590714 0.7165357 0.7843357 0.8283286 0.8231500
>>>> 5 29.46220 -1.002081 0.8057769 0.7500714 0.718175 0.8208786 0.838575 0.8126500 0.7345786 0.7359571 0.7661214 0.8087214 0.8442643 0.8380071
>>>> 6 29.47073 -1.002081 0.8065615 0.7627071 0.730550 0.8142214 0.841100 0.8252000 0.7574786 0.7425071 0.7590571 0.8025071 0.8518357 0.8430286
>>>>> head(rainStackDf)
>>>>        x         y rain1 rain2 rain3 rain4 rain5 rain6 rain7 rain8 rain9 rain10 rain11 rain12
>>>> 1 29.42917 -1.004167    66    68    85   116   105    61    40    85   110    125    118     85
>>>> 2 29.43750 -1.004167    66    69    85   117   106    61    40    85   110    125    119     86
>>>> 3 29.44583 -1.004167    66    68    84   116   106    60    39    84   110    124    118     85
>>>> 4 29.45417 -1.004167    65    67    83   116   105    60    39    83   108    123    117     84
>>>> 5 29.46250 -1.004167    65    68    83   117   106    59    38    83   109    124    118     84
>>>> 6 29.47083 -1.004167    66    68    84   118   107    59    38    83   110    125    119     85
>>>>> mystackDf <- stack(NDVIStackDf, rainStackDf)
>>>>>
>>>>> head(mystackDf)
>>>>   values ind
>>>> 1 29.42809   x
>>>> 2 29.43662   x
>>>> 3 29.44514   x
>>>> 4 29.45367   x
>>>> 5 29.46220   x
>>>> 6 29.47073   x
>>>>
>>>> Is there a better way maybe without using data frames?
>>>>
>>>> I tried stacking the stacks too:
>>>>
>>>>> s1 <- stack(NDVIStack, rainStack)
>>>> Error in compareRaster(x) : different number or columns
>>>>> rainStack
>>>> class       : RasterStack
>>>> dimensions  : 1287, 1321, 1700127, 12  (nrow, ncol, ncell, nlayers)
>>>> resolution  : 0.008333333, 0.008333333  (x, y)
>>>> extent      : 29.425, 40.43333, -11.725, -1  (xmin, xmax, ymin, ymax)
>>>> coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
>>>> names       : rain1, rain2, rain3, rain4, rain5, rain6, rain7, rain8, rain9, rain10, rain11, rain12
>>>> min values  :     7,     5,    31,    13,     0,     0,     0,     0,     0,      0,     22,     32
>>>> max values  :   391,   392,   563,   746,   473,   159,   109,   106,   164,    247,    349,    464
>>>>
>>>>> NDVIStack
>>>> class       : RasterStack
>>>> dimensions  : 1258, 1291, 1624078, 12  (nrow, ncol, ncell, nlayers)
>>>> resolution  : 0.008526982, 0.008525437  (x, y)
>>>> extent      : 29.425, 40.43333, -11.725, -1  (xmin, xmax, ymin, ymax)
>>>> coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
>>>> names       :      NDVI1,      NDVI2,      NDVI3,      NDVI4,      NDVI5,      NDVI6,      NDVI7,      NDVI8,      NDVI9,     NDVI10,     NDVI11,     NDVI12
>>>> min values  : -0.1524615, -0.1353071, -0.1970500, -0.1632071, -0.1919250, -0.1647286, -0.1665000, -0.1693357, -0.1852643, -0.1733714, -0.1555357, -0.1682571
>>>> max values  :  0.9153615,  0.9013000,  0.9295500,  0.9134643,  0.9421750,  0.9158357,  0.9000071,  0.9009786,  0.8733571,  0.8792429,  0.9151357,  0.9233000
>>>>
>>>> Thanks
>>>> Justin
>>>>
>>>> On Jun 30, 2014, at 5:55 PM, Jonathan Greenberg <jgrn at illinois.edu> wrote:
>>>>
>>>>> Justin:
>>>>>
>>>>> It would make more sense, if you insist on working with data.frames,
>>>>> for you to create a single stack with all of your predictor and
>>>>> response variables, and then do your extraction -- that way you don't
>>>>> need to worry about a merge after the fact.  The chances of the
>>>>> coordinates being EXACT I suspect are very low, which is why the
>>>>> merge() is failing.
>>>>>
>>>>> Basically:
>>>>>
>>>>> mystack <- stack(meanTempStackDf, rainStackDf)
>>>>>
>>>>> ... Then you can extract the data.
>>>>>
>>>>> --j
>>>>>
>>>>> On Mon, Jun 30, 2014 at 6:22 AM, Justin Michell <jwm302 at gmail.com> wrote:
>>>>>> Dear Niandou
>>>>>>
>>>>>> No I have not received any feedback.
>>>>>>
>>>>>> I do have some thoughts though. Is it possible/or at least would it make sense to get values in NDVI layer (average of nearby cells?) at the coordinates of raster values in other layers which one wants to merge with?
>>>>>>
>>>>>> I am not very well versed in these things so it?s just a thought- not sure how it would be implemented in R.
>>>>>>
>>>>>> Regards
>>>>>> Justin
>>>>>>
>>>>>>
>>>>>> On Jun 27, 2014, at 3:58 PM, ISSAKA NIANDOU, Yacouba <niandouy at who.int> wrote:
>>>>>>
>>>>>>> Niandou
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at r-project.org
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> Jonathan A. Greenberg, PhD
>>>>> Assistant Professor
>>>>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>>>>> Department of Geography and Geographic Information Science
>>>>> University of Illinois at Urbana-Champaign
>>>>> 259 Computing Applications Building, MC-150
>>>>> 605 East Springfield Avenue
>>>>> Champaign, IL  61820-6371
>>>>> Phone: 217-300-1924
>>>>> http://www.geog.illinois.edu/~jgrn/
>>>>> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>>>>
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From r.hijmans at gmail.com  Mon Sep  1 19:56:26 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Mon, 1 Sep 2014 10:56:26 -0700
Subject: [R-sig-Geo] apply "raster::aggregate" to multi-layer raster
 stack,
 using function that processes values from multiple layers to create a single
 layer?
In-Reply-To: <CAMX4SAPjCSVRY5QpxzDdOTG8Tign3Zav1xOOY7z6na+6RHx1_g@mail.gmail.com>
References: <CAMX4SANgy4xTTvFL5tS2yEi6_FKzNrRQUDgmv5ZwztAej=pEow@mail.gmail.com>
	<CANtt_hwJ_vJwfaOR_ezeT9CaTRPhM77+sdq8boMFYp73sbb_XA@mail.gmail.com>
	<CAMX4SAPjCSVRY5QpxzDdOTG8Tign3Zav1xOOY7z6na+6RHx1_g@mail.gmail.com>
Message-ID: <CANtt_hzDNqz4i57eMGdqXzd-fTsr1as65LOgddG6H-MGvw7raQ@mail.gmail.com>

Aggregate in the development version of raster now has this
functionality (aggregation over space and layers ("time") in one step)
. I would appreciate it if you or others can test it.
install.packages("raster", repos="http://R-Forge.R-project.org")
Robert

On Sat, Jun 21, 2014 at 9:26 AM, Carlos Carroll
<klamathconservation at gmail.com> wrote:
> While mean of calc(y, mean) would allow me to operate on the original stack,
> and then subsequently aggregate the results, what I need to do is operate on
> the entire set of values within the aggregation window (x * y * nlayers) in
> one go, because I am deriving a multivariate distance metric (below).
>
> multidist <- function(x,...)
> {
> footprintsize<-225
> numvars<-3
> meandist <- mean(dist(matrix(x,footprintsize,numvars), method =
> "euclidean"),na.rm=TRUE)
> return(meandist)
> }
>
>
>
> On Sat, Jun 21, 2014 at 4:35 AM, Robert J. Hijmans <r.hijmans at gmail.com>
> wrote:
>>
>> Carlos,
>>
>> How about:
>>
>> x <- mean(y)
>>
>> or
>>
>> x <- calc(y, mean)
>>
>> Robert
>>
>>
>>
>> On Fri, Jun 20, 2014 at 2:50 PM, Carlos Carroll
>> <klamathconservation at gmail.com> wrote:
>> > When I use "aggregate" (package raster) on a multi-layer stack, with a
>> > function such as "mean", it returns a second multi-layer stack at the
>> > aggregated resolution. The function is applied separately to values from
>> > each layer in turn.
>> > What I want to do is send the vector/matrix of values extracted across
>> > all
>> > layers to the user-defined function, which returns a single value that
>> > would then go to form the output, a single layer raster or stack.
>> > I can do this for a focal function using package spatial.tools, e.g.:
>> >
>> > v<-rasterEngine(w,fun=mean,window_dims = c(15,15,3))  ## for a 3 band
>> > stack
>> > with a window size of 15 by 15.
>> >
>> > But I just need the value at the aggregate resolution, so running a
>> > focal
>> > function takes ~200 times longer than necessary in this case.
>> > Is it possible to use raster::aggregate or another function to do a
>> > similar
>> > multi-layer operation?
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-Geo mailing list
>> > R-sig-Geo at r-project.org
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From azvoleff at conservation.org  Tue Sep  2 18:33:33 2014
From: azvoleff at conservation.org (Alex Zvoleff)
Date: Tue, 2 Sep 2014 12:33:33 -0400
Subject: [R-sig-Geo] Unexpected behavior of raster "mask" function
In-Reply-To: <CANtt_hwx2gFhfa8k9Sp96mVB4JHaaOhiyqaMjtvEM5XdS1+5cg@mail.gmail.com>
References: <CACwzsXHyCH09+qsPdre8NmNxE3BjehOcyuOmkAhKPn7UpAgA1w@mail.gmail.com>
	<CANtt_hwx2gFhfa8k9Sp96mVB4JHaaOhiyqaMjtvEM5XdS1+5cg@mail.gmail.com>
Message-ID: <CACwzsXE7YoRESVVVFDRjwtuXfxgUdnP+1dLrGCGkbMqMpfqSTQ@mail.gmail.com>

Thanks Robert! Exactly what I needed.

Best,
Alex


On Sat, Aug 30, 2014 at 6:31 PM, Robert J. Hijmans <r.hijmans at gmail.com>
wrote:

> Alex,
> Thanks for the clear example. I had not considered that case.
> I have added an argument 'updateNA' to the mask function (version
> 2.2-43) such that you can do:
>
> masked_image <- mask(img, msk, updatevalue=2, updateNA=TRUE)
>
> That is, if updateNA is TRUE, NA cells outside the mask are also updated.
>
> Robert
>
>
> On Fri, Jul 18, 2014 at 11:18 AM, Alex Zvoleff
> <azvoleff at conservation.org> wrote:
> > I am using the mask function in the raster package (2.2-38) to mask out
> > areas within an image that are outside an area of interest (AOI). There
> are
> > NAs within this AOI that are meaningful - after masking the image I am
> > using freq to tabulate these NAs along with the other values in my AOI.
> For
> > this reason, I am using the "updatevalue" option in the mask function to
> > recode all areas outside of my AOI to a value (say 99) so that I can
> ignore
> > these areas in subsequent analysis, without having ignored areas share a
> > value (NA) with areas inside my AOI.
> >
> > However, the mask function does not operate as I expected - areas in the
> > image that should be masked but that are NA prior to masking are not set
> to
> > "updatevalue". Is there an way to tell the mask function to recode all
> > areas (regardless of their initial value) to updatevalue? The below
> example
> > shows my problem:
> >
> > library(raster)
> > # Setup an image with two NA values. Make one NA value inside
> > # the AOI, and make the other outside the AOI
> > img <- matrix(1, nrow=5, ncol=5)
> > img[3, 2] <- NA # Inside AOI
> > img[1, 2] <- NA # Outside AOI
> > img <- raster(img)
> > plot(img)
> >
> > # Setup a mask where only the 3x3 region in the center of img is retained
> > msk <- matrix(1, nrow=5, ncol=5)
> > msk[1,] <- NA
> > msk[5,] <- NA
> > msk[,1] <- NA
> > msk[,5] <- NA
> > msk <- raster(msk)
> > plot(msk)
> >
> > # Apply mask
> > masked_image <- mask(img, msk, updatevalue=2)
> >
> > # Notice that cell (1, 2) of masked_image is NA, instead of the
> updatevalue
> > (2).
> > # This cell was not affected by the mask because it was NA prior to
> calling
> > mask.
> > # Is there a way to tell the mask function to set all masked areas to
> > updatevalue,
> > # regardless of whether a cell is NA prior to masking?
> > plot(masked_image)
> >
> > Thanks,
> > Alex
> >
> > --
> > Alex Zvoleff
> > Postdoctoral Associate
> > Tropical Ecology Assessment and Monitoring (TEAM) Network
> > Conservation International
> > 2011 Crystal Dr. Suite 500, Arlington, Virginia 22202, USA
> > Tel: +1-703-341-2749, Fax: +1-703-979-0953, Skype: azvoleff
> > http://www.teamnetwork.org | http://www.conservation.org
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Alex Zvoleff
Postdoctoral Associate
Tropical Ecology Assessment and Monitoring (TEAM) Network
Conservation International
2011 Crystal Dr. Suite 500, Arlington, Virginia 22202, USA
Tel: +1-703-341-2749, Fax: +1-703-979-0953, Skype: azvoleff
http://www.teamnetwork.org | http://www.conservation.org

	[[alternative HTML version deleted]]


From r.hijmans at gmail.com  Tue Sep  2 18:41:37 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 2 Sep 2014 09:41:37 -0700
Subject: [R-sig-Geo] raster::extract fails on brick but works on
 individual layers of brick
In-Reply-To: <53D2B2A1.6080402@gmail.com>
References: <CAEVpnsEKcbasN=UThFCbdYusvk3EuJ1XV9iEYxGXZv9o1A6jNQ@mail.gmail.com>
	<CALuVVaanebwpnUqpbSMPEu5_vHwrS_eEXJHKby8HodgAykYF3g@mail.gmail.com>
	<53D2B2A1.6080402@gmail.com>
Message-ID: <CANtt_hy-khm2yBHpuYd+o97=5FVuJprUM94MNQY+H=-Kra2zjQ@mail.gmail.com>

Frank,
I hope this issue has been solved in the development version.
install.packages("raster", repos="http://R-Forge.R-project.org")
I would appreciate feedback.
Best, Robert

On Fri, Jul 25, 2014 at 12:40 PM, Frank Davenport
<frank.davenport at gmail.com> wrote:
> Sorry for the mutliple postings but I found another solution using
> raster::disaggregate(). Essentially the same as resample but prerserves all
> the cell values. The fundamental issue was the small size of the polygons
> compared to the cells (which can be problematic when using weights()).
>
> See the discussion here:
> https://stackoverflow.com/questions/17766989/extract-data-from-raster-with-small-polygons-rounded-weights-too-small
>
>
> g2<-raster::disaggregate(g,10)
> test1<-extract(g2,dsd,fun=mean,na.rm=T,weights=T,small=T)
>
> On 7/23/14 10:07 AM, Lyndon Estes wrote:
>>
>> Hi Frank,
>>
>> I think the mean function is getting in the way, since if you want to
>> extra the values for all cells each polygon overlaps, the outputs will
>> first end up in a list.
>>
>> test1 <- extract(g, dsd, weights = TRUE, small = TRUE)
>>
>> Will get the cell values for each polygon from each layer in the
>> brick, along with their weight (while allowing very small polygons to
>> get their underlying cell values).
>>
>> I would then process the mean function on the list.
>>
>> v <- t(sapply(test1, function(x) apply(t(sapply(1:nrow(x), function(y)
>> x[y, 1:10] * x[y, 11])), 2, sum)))  # matrix of annual values per
>> polygon
>>
>> Hope this helps.
>>
>> Cheers, Lyndon
>>
>>
>> On Wed, Jul 23, 2014 at 12:17 PM, Frank Davenport
>> <frank.davenport at gmail.com> wrote:
>>>
>>> Hello,
>>>
>>> I am using extract() to aggregate values from a raster to a polygon. The
>>> raster is a brick object. Extract fails on the brick object but succeeds
>>> when applied on each individual layer of the brick (via a for() loop). I
>>> would use this as a work around but in my actual scenario the brick is
>>> much
>>> bigger and the individual approach is too slow.
>>>
>>> The specific error message is: "Error in t(sapply(res, meanfunc)) :
>>> error
>>> in evaluating the argument 'x' in selecting a method for function 't':
>>> Error in apply(x, 1, function(X) { : dim(X) must have a positive length"
>>>
>>> I believe this has something to do with the relative sizes of the
>>> polygons
>>> (small) and the grid cells. I have successfully extracted this brick to
>>> another shapefile that had much larger polygons. Likewise I can also do
>>> the
>>> extraction if I resample the cells to a smaller resolution (not shown
>>> below).
>>>
>>>
>>> Finally the extract will work if I set 'na.rm=F' but then produces mostly
>>> NA's, even though there are no NAs in the brick. I realize this might be
>>> something to do with the dataType(). However that does not explain why
>>> extract works on individual layers, but not the whole brick.
>>>
>>> Reproducible code is below and prettier example can be found here:
>>> http://rpubs.com/frank_davenport/22698
>>>
>>> The data necessary to run the example can be found here:
>>> https://dl.dropboxusercontent.com/u/9577903/99_raster_bugreport.Rdata
>>>
>>> Thank you for your help and apologies if a solution is already posted.
>>>
>>> Frank
>>>
>>>> rm(list=ls())
>>>> library(raster)
>>>
>>> Loading required package: sp
>>>>
>>>> ##-Download data from here:
>>>
>>> https://dl.dropboxusercontent.com/u/9577903/99_raster_bugreport.Rdata
>>>>
>>>> ##contains 'dsd' a spatial polygons data.frame and 'g' a raster brick
>>>
>>> with 10 layers
>>>>
>>>> load('~/Dropbox/Public/99_raster_bugreport.Rdata')
>>>>
>>>> dsd
>>>
>>> class       : SpatialPolygonsDataFrame
>>> features    : 36
>>> extent      : 34.04665, 39.70319, -4.67742, 1.19921  (xmin, xmax, ymin,
>>> ymax)
>>> coord. ref. : +proj=longlat +a=6378249.145 +b=6356514.96582849 +no_defs
>>> variables   : 4
>>> names       : Province, District,         Division, uidu
>>> min values  :  CENTRAL,  BUNGOMA, ABOTHUGUCHI WEST,    1
>>> max values  :  WESTERN,   VIHIGA,            WINAM,   44
>>>>
>>>> g
>>>
>>> class       : RasterBrick
>>> dimensions  : 24, 20, 480, 10  (nrow, ncol, ncell, nlayers)
>>> resolution  : 0.5, 0.5  (x, y)
>>> extent      : 33, 43, -6, 6  (xmin, xmax, ymin, ymax)
>>> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
>>> data source : in memory
>>> names       : X1999.03.01, X1999.03.02, X1999.03.03, X1999.03.04,
>>> X1999.03.05, X1999.03.06, X1999.03.07, X1999.03.08, X1999.03.09,
>>> X1999.03.10
>>> min values  :    22.47562,    22.44415,    22.25507,    22.23166,
>>> 22.12387,    22.42477,    22.27802,    22.15134,    22.36218,    22.33447
>>> max values  :    41.47818,    40.53116,    41.54944,    42.33093,
>>> 41.67810,    40.79260,    41.83319,    40.83359,    41.12604,    42.00555
>>>
>>>> #---Show the data
>>>> plot(g[[1]])
>>>> plot(dsd,add=T)
>>>>
>>>> #--Try to extract, with weights yeilds an error
>>>> test1<-extract(g,dsd,fun=mean,na.rm=T,weights=T)
>>>
>>> Error in t(sapply(res, meanfunc)) :
>>>    error in evaluating the argument 'x' in selecting a method for
>>> function
>>> 't': Error in apply(x, 1, function(X) { : dim(X) must have a positive
>>> length
>>>>
>>>> #--Extract without weights--produces NA's for most polygons
>>>> test2<-extract(g,dsd,fun=mean,na.m=T)
>>>> head(test2)
>>>
>>>       X1999.03.01 X1999.03.02 X1999.03.03 X1999.03.04 X1999.03.05
>>> X1999.03.06 X1999.03.07 X1999.03.08 X1999.03.09 X1999.03.10
>>> [1,]          NA          NA          NA          NA          NA
>>> NA          NA          NA          NA          NA
>>> [2,]          NA          NA          NA          NA          NA
>>> NA          NA          NA          NA          NA
>>> [3,]          NA          NA          NA          NA          NA
>>> NA          NA          NA          NA          NA
>>> [4,]          NA          NA          NA          NA          NA
>>> NA          NA          NA          NA          NA
>>> [5,]          NA          NA          NA          NA          NA
>>> NA          NA          NA          NA          NA
>>> [6,]          NA          NA          NA          NA          NA
>>> NA          NA          NA          NA          NA
>>>>
>>>> summary(test2)
>>>
>>>    X1999.03.01     X1999.03.02     X1999.03.03     X1999.03.04
>>> X1999.03.05     X1999.03.06     X1999.03.07     X1999.03.08
>>>   Min.   :24.47   Min.   :25.21   Min.   :24.67   Min.   :25.47   Min.
>>> :27.42   Min.   :25.38   Min.   :25.93   Min.   :24.11
>>>   1st Qu.:29.29   1st Qu.:30.99   1st Qu.:29.55   1st Qu.:30.83   1st
>>> Qu.:31.58   1st Qu.:29.78   1st Qu.:29.51   1st Qu.:28.35
>>>   Median :30.31   Median :33.63   Median :31.13   Median :31.88   Median
>>> :33.32   Median :30.31   Median :30.52   Median :29.71
>>>   Mean   :29.87   Mean   :32.75   Mean   :30.41   Mean   :31.78   Mean
>>> :32.61   Mean   :29.71   Mean   :29.90   Mean   :29.19
>>>   3rd Qu.:31.86   3rd Qu.:36.08   3rd Qu.:32.59   3rd Qu.:34.37   3rd
>>> Qu.:34.73   3rd Qu.:30.60   3rd Qu.:31.32   3rd Qu.:30.82
>>>   Max.   :32.81   Max.   :37.00   Max.   :33.45   Max.   :35.77   Max.
>>> :35.42   Max.   :31.98   Max.   :31.69   Max.   :32.53
>>>   NA's   :30      NA's   :30      NA's   :30      NA's   :30      NA's
>>> :30      NA's   :30      NA's   :30      NA's   :30
>>>    X1999.03.09     X1999.03.10
>>>   Min.   :25.98   Min.   :25.53
>>>   1st Qu.:29.53   1st Qu.:30.73
>>>   Median :30.57   Median :31.06
>>>   Mean   :30.12   Mean   :31.24
>>>   3rd Qu.:31.41   3rd Qu.:33.52
>>>   Max.   :32.75   Max.   :34.83
>>>   NA's   :30      NA's   :30
>>>>
>>>> #--Extract each layer seperatley--works but is SLOW
>>>> glist<-vector(mode='list',length=nlayers(g))
>>>>
>>>> for(i in 1:length(glist)){
>>>
>>> +   glist[[i]]<-extract(g[[i]],dsd,fun=mean,na.rm=T,weigths=T)
>>> + }
>>>>
>>>> sessionInfo()
>>>
>>> R version 3.1.0 (2014-04-10)
>>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>>>
>>> locale:
>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] raster_2.2-31 sp_1.0-15
>>>
>>> loaded via a namespace (and not attached):
>>> [1] grid_3.1.0      lattice_0.20-29 tools_3.1.0
>>>          [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> --
> Frank Davenport, Ph.D
> Climate Hazards Group
> UCSB Geography
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Tue Sep  2 18:46:39 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 2 Sep 2014 09:46:39 -0700
Subject: [R-sig-Geo] Count values "greater than" in rasterbrick layers
In-Reply-To: <1406061390595-7586782.post@n2.nabble.com>
References: <1405504258.52913.YahooMailNeo@web121901.mail.ne1.yahoo.com>
	<1406061390595-7586782.post@n2.nabble.com>
Message-ID: <CANtt_hzhyKNpeBhhYd+H1J5oSM9=QYpq2vku=m_aebwNwTwW_w@mail.gmail.com>

Thiago,
Here are more direct approaches:

# generate raster data
r <- raster(ncol=384, nrow=190)
b <- brick(sapply(1:31, function(i) setValues(r, rnorm(ncell(r), i, 3))))

# sum up rain
acc.rain <- sum(b)

# count wet days
wet.days <- sum(b > 0)

or with calc
wet.days <-  calc(b, function(x) sum(x > 0))

Robert

On Tue, Jul 22, 2014 at 1:36 PM, dschneiderch
<Dominik.Schneider at colorado.edu> wrote:
> Thiago -
> With regards to your original attempt for part b, I  believe using length()
> instead of sum() will get you what you want.  In this case, sum(x) and
> sum(x[x>1]) are the same assuming you have no values less than 1. Length can
> be used as a proxy for counting how many days rain>1.
>
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Count-values-greater-than-in-rasterbrick-layers-tp7586746p7586782.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From dupouey at nancy.inra.fr  Wed Sep  3 13:56:01 2014
From: dupouey at nancy.inra.fr (Jean-Luc Dupouey)
Date: Wed, 03 Sep 2014 13:56:01 +0200
Subject: [R-sig-Geo] regularly subset (subsample) a raster and get a raster
Message-ID: <540701D1.6060403@nancy.inra.fr>

Dear forumites,

Using R, I want to regularly subsample a raster (for example, one point 
over two), and get a raster.

Usual R subsampling works with raster layers:

MyRaster[seq(1,nrow(MyRaster),2),seq(1,ncol(MyRaster),2))]

but it only gives in return a vector of values, not a raster layer 
object. All the raster information is lost (spatial reference, etc.).

How can I subsample my initial raster and still keep a raster?

I thought of using "aggregate" or "crop" functions, but I am working on 
large datasets, and I would prefer to avoid any unnecessary calculations.

Thank you in advance,

Jean-Luc


From loic.dutrieux at wur.nl  Wed Sep  3 14:39:20 2014
From: loic.dutrieux at wur.nl (=?windows-1252?Q?Lo=EFc?=)
Date: Wed, 3 Sep 2014 14:39:20 +0200
Subject: [R-sig-Geo] regularly subset (subsample) a raster and get a
	raster
In-Reply-To: <540701D1.6060403@nancy.inra.fr>
References: <540701D1.6060403@nancy.inra.fr>
Message-ID: <54070BF8.4060207@wur.nl>

Hi Jean-Luc,

Aggregate sounds like a safe option (memory safe and you do not lose the 
spatial information). Give it a try, it may not have such a big overhead.

## R
library(raster)
r <- raster(system.file(package = 'raster', 'external/test.grd'))
fun <- function(x) x[1]
r2 <- aggregate(r, by = 2, FUN = fun)

Best regards,

--
Lo?c Dutrieux
Laboratory of Geo-Information Sciences and Remote Sensing
Wageningen University
The Netherlands


On 03/09/2014 13:56, Jean-Luc Dupouey wrote:
> Dear forumites,
>
> Using R, I want to regularly subsample a raster (for example, one point
> over two), and get a raster.
>
> Usual R subsampling works with raster layers:
>
> MyRaster[seq(1,nrow(MyRaster),2),seq(1,ncol(MyRaster),2))]
>
> but it only gives in return a vector of values, not a raster layer
> object. All the raster information is lost (spatial reference, etc.).
>
> How can I subsample my initial raster and still keep a raster?
>
> I thought of using "aggregate" or "crop" functions, but I am working on
> large datasets, and I would prefer to avoid any unnecessary calculations.
>
> Thank you in advance,
>
> Jean-Luc
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From tuthalija at gmail.com  Wed Sep  3 16:41:24 2014
From: tuthalija at gmail.com (N St)
Date: Wed, 3 Sep 2014 17:41:24 +0300
Subject: [R-sig-Geo] Trellis with spplot
Message-ID: <CAGm1btVNgQS5chgcUT8LaFNmK8-BBUJ+pSdRdxOROw6UWDdDGg@mail.gmail.com>

Hello

I would like to facet a spplot with the factors of one variable (like
a xyplot(y~x|A)). I want to use spplot because I have to add others
polygons layers. In my reproducible example below I would like to end
up with three plots, one for each categorie (1,2,3) in a trellis

--------------------------

library(sp); library(lattice) ; library(RColorBrewer) ; library(latticeExtra)
data(meuse)
coordinates(meuse) <- c("x", "y")
cc <- coordinates(meuse)
m.sl <- SpatialLines(list(Lines(list(Line(cc)), "line1")))
data(meuse.riv)
meuse.lst <- list(Polygons(list(Polygon(meuse.riv)), "meuse.riv"))
meuse.pol <- SpatialPolygonsDataFrame(SpatialPolygons(meuse.lst),
data.frame(1), match.ID=FALSE)

colfactor = RColorBrewer:::brewer.pal(3,"Accent")
pts <- list("sp.points", meuse, pch = 16, col = colfactor, cex=2,  )
meuse.layout <- list(pts)

l <- spplot(meuse, c("soil"), scales=list(draw=T), asp="iso",
col.regions=colfactor, cex=2)
p <- spplot(meuse.pol, fill="blue")
l+p


-----------------------------
It sounds really easy but I couldn't find an answer.

Best Regards
Nebi


From edzer.pebesma at uni-muenster.de  Wed Sep  3 16:57:09 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 03 Sep 2014 16:57:09 +0200
Subject: [R-sig-Geo] Trellis with spplot
In-Reply-To: <CAGm1btVNgQS5chgcUT8LaFNmK8-BBUJ+pSdRdxOROw6UWDdDGg@mail.gmail.com>
References: <CAGm1btVNgQS5chgcUT8LaFNmK8-BBUJ+pSdRdxOROw6UWDdDGg@mail.gmail.com>
Message-ID: <54072C45.5030501@uni-muenster.de>

Thanks for the reproducible example:

On 09/03/2014 04:41 PM, N St wrote:
> Hello
> 
> I would like to facet a spplot with the factors of one variable (like
> a xyplot(y~x|A)). I want to use spplot because I have to add others
> polygons layers. In my reproducible example below I would like to end
> up with three plots, one for each categorie (1,2,3) in a trellis
> 
> --------------------------
> 
> library(sp); library(lattice) ; library(RColorBrewer) ; library(latticeExtra)
> data(meuse)
> coordinates(meuse) <- c("x", "y")
> cc <- coordinates(meuse)
> m.sl <- SpatialLines(list(Lines(list(Line(cc)), "line1")))
> data(meuse.riv)
> meuse.lst <- list(Polygons(list(Polygon(meuse.riv)), "meuse.riv"))
> meuse.pol <- SpatialPolygonsDataFrame(SpatialPolygons(meuse.lst),
> data.frame(1), match.ID=FALSE)
> 
> colfactor = RColorBrewer:::brewer.pal(3,"Accent")
> pts <- list("sp.points", meuse, pch = 16, col = colfactor, cex=2,  )
> meuse.layout <- list(pts)
> 
> l <- spplot(meuse, c("soil"), scales=list(draw=T), asp="iso",
> col.regions=colfactor, cex=2)
> p <- spplot(meuse.pol, fill="blue")
> l+p

meuse$soil1 = ifelse(meuse$soil == 1, 1, NA)
meuse$soil2 = ifelse(meuse$soil == 2, 2, NA)
meuse$soil3 = ifelse(meuse$soil == 3, 3, NA)
l <- spplot(meuse, c("soil1", "soil2", "soil3"))
l+p

might get you somewhere, maybe not where you want to be, but at least
each category has a panel.

> 
> -----------------------------
> It sounds really easy but I couldn't find an answer.
> 
> Best Regards
> Nebi
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140903/c1eb63ab/attachment.bin>

From tim.appelhans at gmail.com  Wed Sep  3 17:40:16 2014
From: tim.appelhans at gmail.com (Tim Appelhans)
Date: Wed, 03 Sep 2014 17:40:16 +0200
Subject: [R-sig-Geo] Trellis with spplot
In-Reply-To: <CAGm1btVNgQS5chgcUT8LaFNmK8-BBUJ+pSdRdxOROw6UWDdDGg@mail.gmail.com>
References: <CAGm1btVNgQS5chgcUT8LaFNmK8-BBUJ+pSdRdxOROw6UWDdDGg@mail.gmail.com>
Message-ID: <54073660.3060106@gmail.com>

Dear Nebi,
find one solution below. What you can do is split your meuse data set 
according to the factor you like (in your example 'soil'). Then, after 
making sure you have the same bounding box for each subset (I just too 
the one from the overall meuse data), you can produce a plot for each 
subset and put them back together using 'Reduce()'. The only thing that 
is not straight-forward with this approach is the creation of the 
legend. For this I have included a little example using the grid package 
to focus on a certain region of your plot (in your example case the 
empty bottom right panel) and then draw a key from scratch using 
lattice::draw.key(). This is a bit more tedious, but it will give you 
complete control over your layout.

Hope that helps.

Best
Tim

On 09/03/2014 04:41 PM, N St wrote:
> Hello
>
> I would like to facet a spplot with the factors of one variable (like
> a xyplot(y~x|A)). I want to use spplot because I have to add others
> polygons layers. In my reproducible example below I would like to end
> up with three plots, one for each categorie (1,2,3) in a trellis
>
> --------------------------
>
> library(sp); library(lattice) ; library(RColorBrewer) ; library(latticeExtra)
> data(meuse)
> coordinates(meuse) <- c("x", "y")
> cc <- coordinates(meuse)
> m.sl <- SpatialLines(list(Lines(list(Line(cc)), "line1")))
> data(meuse.riv)
> meuse.lst <- list(Polygons(list(Polygon(meuse.riv)), "meuse.riv"))
> meuse.pol <- SpatialPolygonsDataFrame(SpatialPolygons(meuse.lst),
> data.frame(1), match.ID=FALSE)
>
> colfactor = RColorBrewer:::brewer.pal(3,"Accent")
> pts <- list("sp.points", meuse, pch = 16, col = colfactor, cex=2,  )
> meuse.layout <- list(pts)
library(gridExtra)

## split meuse data according to soil levels
meuse.splt <- split(meuse, f = meuse$soil)

## create spplot for each subset of the previous split
l.lst <- lapply(seq(meuse.splt), function(i) {
   dat <- meuse.splt[[i]]
   dat at bbox <- bbox(meuse)
   spplot(dat, c("soil"), scales=list(draw=T), asp="iso",
          col.regions=colfactor[[i]], cex=2,
          auto.key = FALSE,
          as.table = TRUE)
})

## function to combine the individual plots
outLayout <- function(x, y) {
   update(c(x, y,
            layout = c(2, 2)), x.same = TRUE, y.same = TRUE,
          between = list(y = 0.3, x = 0.3))
}

## combine the plots
l <- Reduce(outLayout, l.lst)

## draw the plot to a new page
grid.newpage()

print(l + p, newpage = FALSE)

## focus on plotting area
downViewport(trellis.vpname(name = "figure"))

## set up new viewport for drawing the legend
vp1 <- viewport(x = 1, y = 0,
                 height = 0.4, width = 0.2,
                 just = c("right", "bottom"),
                 name = "legend.vp")

## focus on new viewport
pushViewport(vp1)

## draw legend
draw.key(list(text=list(c("1", "2", "3"),
                         cex = 1),
               columns = 1, rows = 3,
               points = list(pch = 16,
                             cex = 2,
                             col = colfactor),
               padding.text = 2),
          draw = T,
          vp = viewport(x = unit(0.5, "npc"),
                        y = unit(0.5, "npc"),
                        just = "centre"))

## re-focus on entire drawing area (i.e. the plotting device)
upViewport(0)
>
> l <- spplot(meuse, c("soil"), scales=list(draw=T), asp="iso",
> col.regions=colfactor, cex=2)
> p <- spplot(meuse.pol, fill="blue")
> l+p
>
>
> -----------------------------
> It sounds really easy but I couldn't find an answer.
>
> Best Regards
> Nebi
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
#####################################
Tim Appelhans
Department of Geography
Environmental Informatics
Philipps Universit?t Marburg
Deutschhausstra?e 12
35032 Marburg (Paketpost: 35037 Marburg)
Germany

Tel +49 (0) 6421 28-25957

http://environmentalinformatics-marburg.de/


From r.hijmans at gmail.com  Wed Sep  3 18:50:12 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 3 Sep 2014 09:50:12 -0700
Subject: [R-sig-Geo] regularly subset (subsample) a raster and get a
	raster
In-Reply-To: <54070BF8.4060207@wur.nl>
References: <540701D1.6060403@nancy.inra.fr>
	<54070BF8.4060207@wur.nl>
Message-ID: <CANtt_hzW+BRJn7hQOWAJuGhEqDeRF-aDJgYBVQDut9oYnMwwHg@mail.gmail.com>

Jean-Luc,

You can also use sampleRegular with argument asRaster=TRUE. For example:

sampleRegular(MyRaster, 1000, asRaster=TRUE)

Robert

On Wed, Sep 3, 2014 at 5:39 AM, Lo?c <loic.dutrieux at wur.nl> wrote:
> Hi Jean-Luc,
>
> Aggregate sounds like a safe option (memory safe and you do not lose the
> spatial information). Give it a try, it may not have such a big overhead.
>
> ## R
> library(raster)
> r <- raster(system.file(package = 'raster', 'external/test.grd'))
> fun <- function(x) x[1]
> r2 <- aggregate(r, by = 2, FUN = fun)
>
> Best regards,
>
> --
> Lo?c Dutrieux
> Laboratory of Geo-Information Sciences and Remote Sensing
> Wageningen University
> The Netherlands
>
>
>
> On 03/09/2014 13:56, Jean-Luc Dupouey wrote:
>>
>> Dear forumites,
>>
>> Using R, I want to regularly subsample a raster (for example, one point
>> over two), and get a raster.
>>
>> Usual R subsampling works with raster layers:
>>
>> MyRaster[seq(1,nrow(MyRaster),2),seq(1,ncol(MyRaster),2))]
>>
>> but it only gives in return a vector of values, not a raster layer
>> object. All the raster information is lost (spatial reference, etc.).
>>
>> How can I subsample my initial raster and still keep a raster?
>>
>> I thought of using "aggregate" or "crop" functions, but I am working on
>> large datasets, and I would prefer to avoid any unnecessary calculations.
>>
>> Thank you in advance,
>>
>> Jean-Luc
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From macqueen1 at llnl.gov  Wed Sep  3 19:02:05 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 3 Sep 2014 17:02:05 +0000
Subject: [R-sig-Geo] Using spTransform() to reproduce another software
 package's transformation
In-Reply-To: <alpine.LRH.2.03.1408302025490.15324@reclus.nhh.no>
References: <10CAD6CB-3271-4A3E-BFF0-3C71C3A79317@llnl.gov>
	<B078CDF40DFE4045AF172A8B4F68FC4857C79B8226@DKRDSEXC016.vestas.net>
	<alpine.LRH.2.03.1408290916450.8617@reclus.nhh.no>
	<alpine.LRH.2.03.1408302025490.15324@reclus.nhh.no>
Message-ID: <D02C818F.109485%macqueen1@llnl.gov>

Roger, Hermann, Frede,

My thanks to all who took a look at this. Your responses, including
Roger?s re-expression using cs2cs on the proj list and the discussion
there (subject: NAD_1983_To_WGS_1984_5), are very helpful.

The proj.4 parameters that Roger has provided do better than I had been
able to achieve, such that I am completely comfortable telling my
co-workers that I can reproduce their coordinate transformations. And at a
programmatic level, that is what I really needed, so thanks!


-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062




On 8/30/14, 12:00 PM, "Roger Bivand" <Roger.Bivand at nhh.no> wrote:

>On Fri, 29 Aug 2014, Roger Bivand wrote:
>
>> On Fri, 29 Aug 2014, Frede Aakmann T?gersen wrote:
>>
>>> Hi
>>> 
>>> It seems to me that you think that ESRI performs the "correct"
>>> transformation.
>>
>> Thanks, Frede. My guess is that this is a question for the proj-devel
>>list, 
>> probably using cs2cs as the workhorse. Please re-cast your example to
>>use 
>> cs2cs from the console prompt - I think that will be the most efficient
>> resolution. I can post on the proj list if you like.
>
>Having posted on the proj list, and after being helped by Hermann Peifer,
>this now does better:
>
>crs.step1.cf <- CRS(paste("+proj=lcc +lat_1=38.43333333333333",
>"+lat_2=37.06666666666667 +lat_0=36.5 +lon_0=-120.5",
>"+x_0=2000000.0 +y_0=500000.0 +ellps=GRS80 +units=us-ft +no_defs",
>"+towgs84=-0.991,1.9072,0.5129,0.025789908,0.0096501,0.0116599,0.0"))
>crs.step1.cf
>locs.step1.cf <- spTransform(locs.ll, crs.step1.cf)
>coordinates(locs.step1.esri)-coordinates(locs.step1.cf)
>#         coords.x1     coords.x2
>#[1,] -3.469177e-06 -5.122274e-08
>#[2,] -3.418885e-06 -7.846393e-08
>
>
>locs.tmp <- locs.step1.cf
>suppressWarnings(proj4string(locs.tmp) <- CRS(paste("+proj=lcc",
>"+lat_1=38.43333333333333 +lat_2=37.06666666666667 +lat_0=36.5",
>"+lon_0=-120.5 +x_0=2000000.0 +y_0=500000.0 +ellps=GRS80 +units=us-ft",
>"+no_defs +nadgrids=@null")))
>locs.step2.cfb <- spTransform(locs.tmp, CRS("+init=epsg:26743"))
>coordinates(locs.ref)-coordinates(locs.step2.cfb)
>#         coords.x1     coords.x2
>#[1,] -1.028087e-05 -5.030306e-07
>#[2,] -1.081964e-05 -5.360343e-07
>
>This with (forthcoming) PROJ.4 4.9.0 and (forthcoming) rgdal 0.9-1, not
>checked with earlier versions, but should work. The sources are not very
>forthcoming on why the +nadgrids=@null trick works, but it appears to
>force the omission a step in datum transformation, which itself is a
>multi-step process internally.
>
>Hope this helps,
>
>Roger
>
>>
>> I suspect that the +/- 1m is what is available, but if it was possible
>>to 
>> help in the PROJ.4 framework, all other downstream software components
>>would 
>> benefit.
>>
>> I do see that Frank Warmerdam posted:
>>
>> http://lists.maptools.org/pipermail/proj/2008-September/003833.html
>>
>> 6 years ago in answer to a question about NAD_1983_To_WGS_1984_5.
>>
>> Hope this helps,
>>
>> Roger
>>
>>> 
>>>> From 
>>>> 
>>>>http://help.arcgis.com/en/arcgisdesktop/10.0/help/index.html#//003r0000
>>>>0010000000:
>>> 
>>> <quote start>
>>> Converting between NAD 1983 and WGS 1984
>>> 
>>> Originally, NAD 1983 and WGS 1984 were considered coincident. To
>>>minimize 
>>> coordinate changes, NAD 1983 is tied to the North American and Pacific
>>>(for 
>>> Hawaii, and so on) plates. WGS 1984 is tied to the International
>>> Terrestrial Reference System (ITRF), which is independent of the
>>>tectonic 
>>> plates. Over time, the two coordinate systems have become increasingly
>>> different.
>>> 
>>> NAD_1983_To_WGS_1984_1: Published accuracy from EPSG is 2 meters. This
>>> transformation applies to the entire North American continent. This
>>> transformation uses the geocentric translation method, with the
>>> transformation's parameters (dx, dy, and dz) all equal to zeroes. This
>>> transformation treats the NAD 1983 and WGS 1984 datums as though they
>>>are 
>>> equivalent.
>>> NAD_1983_To_WGS_1984_2: Calculated by the U. S. Defence Mapping Agency
>>> (DMA), now known as the National Geospatial Intelligence Agency (NGA),
>>>for 
>>> the Aleutian islands. Accuracy is listed by EPSG at +/-8 m.
>>> NAD_1983_To_WGS_1984_3: Calculated by the NGA for Hawaii. Accuracy is
>>> listed by EPSG at +/-4 m.
>>> NAD_1983_To_WGS_1984_4: Formerly applied within the 48 contiguous
>>>states, 
>>> but is superseded by _5. This transformation method should no longer
>>>be 
>>> used.
>>> NAD_1983_To_WGS_1984_5: Transformation parameters calculated by the
>>>U.S. 
>>> National Geodetic Survey (NGS) using CORS stations, and ties WGS 1984
>>>to 
>>> ITRF96. Accuracy according to EPSG is +/- 1 meter.
>>> NAD_1983_To_WGS_1984_6, _7, and _8: Canadian NTv2 transformations, for
>>>the 
>>> Quebec, Saskatchewan, and Alberta provinces, respectively.
>>> <quote end>
>>> 
>>> So the precision of NAD_1983_To_WGS_1984_5 according to EPSG is +- 1
>>>meter 
>>> so if your results are in feet then they are within that limit.
>>> 
>>> In R the parameters for PROJ.4 are:
>>> 
>>>> CRS("+init=epsg:26743")
>>> CRS arguments:
>>> +init=epsg:26743 +proj=lcc +lat_1=38.43333333333333
>>> +lat_2=37.06666666666667 +lat_0=36.5 +lon_0=-120.5
>>> +x_0=609601.2192024384 +y_0=0 +datum=NAD27 +units=us-ft +no_defs
>>> +ellps=clrk66 +nadgrids=@conus, at alaska, at ntv2_0.gsb, at ntv1_can.dat
>>> +towgs=-3.746315,1.876856
>>> 
>>> This corresponds to what you can find on www.epsg-registry.org
>>> 
>>> Is there a corresponding EPSG code for the ESRI NAD_1983_To_WGS_1984_5
>>> transformation? Or can you by any other means find something similar
>>>to the 
>>> CRS arguments? If so we can compare the CRS arguments from R and ESRI.
>>> 
>>> 
>>> 
>>> 
>>> Yours sincerely / Med venlig hilsen
>>> 
>>> 
>>> Frede Aakmann T?gersen
>>> Specialist, M.Sc., Ph.D.
>>> Plant Performance & Modeling
>>> 
>>> Technology & Service Solutions
>>> T +45 9730 5135
>>> M +45 2547 6050
>>> frtog at vestas.com
>>> http://www.vestas.com
>>> 
>>> Company reg. name: Vestas Wind Systems A/S
>>> This e-mail is subject to our e-mail disclaimer statement.
>>> Please refer to www.vestas.com/legal/notice
>>> If you have received this e-mail in error please contact the sender.
>>> 
>>> 
>>>> -----Original Message-----
>>>> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
>>>> project.org] On Behalf Of MacQueen, Don
>>>> Sent: 29. august 2014 01:58
>>>> To: r-sig-geo at r-project.org
>>>> Subject: [R-sig-Geo] Using spTransform() to reproduce another software
>>>> package's transformation
>>>> 
>>>> The program I work for has specified the use of a local coordinate
>>>> reference
>>>> system and a method for transforming and projecting from WGS84
>>>>long/lat
>>>> to the local system. They use ESRI products to convert from long/lat
>>>>to 
>>>> the
>>>> local system.
>>>> 
>>>> Since I do everything in R, naturally I wish to use spTransform() to
>>>> replicate
>>>> their conversion. I've been using spTransform() for a number of years
>>>>now,
>>>> and thought I understood what I've been doing.
>>>> 
>>>> But I have run into trouble. I would appreciate any advice.
>>>> 
>>>> I believe I have a reproducible example. Toward the end of this email
>>>>are 
>>>> R
>>>> expressions (based on dput) that will create two SpatialPoints
>>>>objects 
>>>> that
>>>> are used in the example. They need to be created first, before
>>>>running the
>>>> example.
>>>> 
>>>> ####
>>>> ## before adding further detail and the example, here are some
>>>>references
>>>> ####
>>>> 
>>>> (1)
>>>> 
>>>>http://downloads2.esri.com/support/TechArticles/Geographic_Transformati
>>>> ons_10.1.zip
>>>> (2)
>>>> 
>>>>http://resources.arcgis.com/en/help/main/10.2/index.html#/Equation_base
>>>> d_methods/003r00000012000000/
>>>> (3)
>>>> http://resources.arcgis.com/en/help/main/10.2/index.html#/Grid_based_m
>>>> ethods/003r00000013000000/
>>>> 
>>>> 
>>>> 
>>>> The programs's specified CRS is epsg 26743 = California State Plane
>>>>Zone 3
>>>> NAD27 US feet (out of my control!)
>>>> 
>>>> The specified method for transforming and projecting from WGS84
>>>>long/lat
>>>> to the local CRS consists of two steps:
>>>>  1) transform and project to epsg 2227 = California State Plane Zone
>>>>3 
>>>> NAD83
>>>> US feet
>>>>  2) transform to epsg 26743 = California State Plane Zone 3 NAD27 US
>>>>feet
>>>> 
>>>> When doing the steps in the ESRI software's projection tool:
>>>>  step 1) use what ESRI calls "NAD_1983_To_WGS_1984_5"  (wkid 1515 in
>>>> reference 1)
>>>>  step 2) use what ESRI calls "NAD_1927_To_NAD_1983_NADCON"  (wkid 1241
>>>> in reference 1)
>>>> 
>>>> According to reference 1 "NAD_1983_To_WGS_1984_5" is a "coordinate
>>>> frame" transformation.
>>>> Based on reference 2, this means it is a 7 parameter Bursa-Wolf method
>>>> Also based on reference 1, "NAD_1927_To_NAD_1983_NADCON" is a grid-
>>>> based method
>>>> 
>>>> 
>>>> As I hope you will see, a naive use of spTransform() produces
>>>>coordinates
>>>> that differ from the ESRI two-step process by approximately 3.7 ft
>>>>(x) and 
>>>> -
>>>> 1.9 ft (y). This is too large for our use case. I also believe as a
>>>>matter 
>>>> of
>>>> principle that it should be possible to do better (I'd like to
>>>>believe 
>>>> that any
>>>> transformation possible in ESRI is also possible using PROJ.4).
>>>> 
>>>> 
>>>> ##
>>>> ## reproducible example begins
>>>> ##
>>>> 
>>>> ## define two example points in WGS84 long/lat
>>>> locs.xy <- cbind(
>>>>              c(-121.524764291826,-121.523480804667),
>>>>              c(37.6600366036405,37.6543604613483)
>>>>              )
>>>> 
>>>> locs.ll <- SpatialPoints(locs.xy, proj4string=CRS("+proj=longlat
>>>> +datum=WGS84") )
>>>> 
>>>> ## source the expressions near the bottom of this email to create
>>>> ##    locs.ref
>>>> ##    locs.step1.esri
>>>> 
>>>> ## use spTransform to go from WGS84 to the local system in one step:
>>>> locs.26743 <- spTransform(locs.ll, CRS("+init=epsg:26743"))
>>>> 
>>>> ## not close enough:
>>>> coordinates(locs.ref)-coordinates(locs.26743)
>>>> ##      coords.x1 coords.x2
>>>> ## [1,]  3.746539 -1.876668
>>>> ## [2,]  3.746607 -1.876466
>>>> 
>>>> 
>>>> ## spTransform equivalent of ESRI step 1
>>>> locs.step1.proj4 <- spTransform(locs.ll, CRS("+init=epsg:2227"))
>>>> 
>>>> ## not close enough, essentially the same difference as above
>>>> coordinates(locs.step1.esri)-coordinates(locs.step1.proj4)
>>>> ##      coords.x1 coords.x2
>>>> ## [1,]  3.746244 -1.877057
>>>> ## [2,]  3.746315 -1.876856
>>>> 
>>>> 
>>>> ## next, try the spTransform equivalent of ESRI step 1, but
>>>>specifying the
>>>> seven parameters
>>>> ## note, had to reverse the sign of the rotation args from wkid 1515
>>>>in
>>>> reference 1;
>>>> ## evidently the PROJ.4 default is the "position vector" method
>>>>(reference 
>>>> 2)
>>>> 
>>>> crs.step1.cf <- CRS('+proj=lcc +lat_1=38.43333333333333
>>>> +lat_2=37.06666666666667 +lat_0=36.5 +lon_0=-120.5\
>>>>  +x_0=2000000.0 +y_0=500000.0 +ellps=GRS80 +datum=NAD83\
>>>>  +units=us-ft +no_defs\
>>>>  +towgs84=-0.991,1.9072,0.5129,0.025789908,0.0096501,0.0116599,0.0')
>>>> 
>>>> ## by the way, this alternative to specifying the CRS gives the same
>>>> result
>>>> ##  crs.step1.cf <- CRS("+init=epsg:2227 +towgs84=-
>>>> 0.991,1.9072,0.5129,0.025789908,0.0096501,0.0116599,0.0")
>>>> 
>>>> locs.step1.cf <- spTransform(locs.ll, crs.step1.cf)
>>>> 
>>>> ## good enough (hooray!)
>>>> coordinates(locs.step1.esri)-coordinates(locs.step1.cf)
>>>> ##          coords.x1     coords.x2
>>>> ## [1,] -3.469177e-06 -5.122274e-08
>>>> ## [2,] -3.418885e-06 -7.380731e-08
>>>> 
>>>> 
>>>> 
>>>> ## now try for step 2 using spTranform()
>>>> locs.step2.cf <- spTransform(locs.step1.cf, CRS("+init=epsg:26743"))
>>>> 
>>>> ## the original difference is back!
>>>> coordinates(locs.ref)-coordinates(locs.step2.cf)
>>>> ##      coords.x1 coords.x2
>>>> ## [1,]  3.746539 -1.876668
>>>> ## [2,]  3.746608 -1.876466
>>>> 
>>>> ## the implication is that in doing the transformation to epsg 26743,
>>>>it
>>>> reversed the effect of the 7-parameter method
>>>> 
>>>> ## attempt to prevent that:
>>>> 
>>>> locs.tmp <- locs.step1.cf
>>>> proj4string(locs.tmp) <- CRS("+init=epsg:2227")
>>>> ## Warning message:
>>>> ## In `proj4string<-`(`*tmp*`, value = <S4 object of class "CRS">) :
>>>> ##   A new CRS was assigned to an object with an existing CRS:
>>>> ## +proj=lcc +lat_1=38.43333333333333 +lat_2=37.06666666666667
>>>> +lat_0=36.5 +lon_0=-120.5 +x_0=2000000.0 +y_0=500000.0 +ellps=GRS80
>>>> +datum=NAD83 +units=us-ft +no_defs +towgs84=-
>>>> 0.991,1.9072,0.5129,0.025789908,0.0096501,0.0116599,0.0
>>>> ## without reprojecting.
>>>> ## For reprojection, use function spTransform in package rgdal
>>>> 
>>>> locs.step2.cfb <- spTransform(locs.tmp, CRS("+init=epsg:26743"))
>>>> 
>>>> ## This actually works; the difference is now acceptably small
>>>> coordinates(locs.ref)-coordinates(locs.step2.cfb)
>>>> ##         coords.x1    coords.x2
>>>> ## [1,] 0.0003266879 0.0006651825
>>>> ## [2,] 0.0003261503 0.0006651356
>>>> 
>>>> 
>>>> ## Another way, perhaps more appropriate (and with no warning message)
>>>> is recreate the SpatialPoints
>>>> ## object instead of modifying it:
>>>> locs.tmp <- SpatialPoints(coordinates(locs.step1.cf),
>>>> proj4string=CRS("+init=epsg:2227"))
>>>> locs.step2.cfb <- spTransform(locs.tmp, CRS("+init=epsg:26743"))
>>>> 
>>>> coordinates(locs.ref)-coordinates(locs.step2.cfb)
>>>> ##         coords.x1    coords.x2
>>>> ## [1,] 0.0003266879 0.0006651825
>>>> ## [2,] 0.0003261503 0.0006651356
>>>> 
>>>> 
>>>> 
>>>> This suggests to me that in PROJ.4 the specifications for the CRS are
>>>>in 
>>>> some
>>>> way mixed in with the specifications for how the geographic
>>>>transformation
>>>> is performed. Apparently, one cannot specify the transformation method
>>>> independent of the CRS specification. To put it another way, I have
>>>>two 
>>>> ways
>>>> of converting from the original CRS to the first step's target CRS.
>>>>The 
>>>> target
>>>> CRS is the same either way. But a second conversion to another CRS is
>>>> affected by the method of the first one.
>>>> 
>>>> Have I interpreted correctly? If so, I guess it doesn't seem
>>>> appropriate-the
>>>> conversion from one CRS to another should depend only on what the CRS
>>>>is,
>>>> not on how it got there.
>>>> 
>>>> Is there something I don't understand so that this kind of dependency
>>>>is
>>>> appropriate?
>>>> 
>>>> In the end, I guess I do have a solution, but I kind of don't like
>>>>it. I 
>>>> have to
>>>> insert a "correction" to the CRS. Is there a better way?
>>>> 
>>>> 
>>>> 
>>>> 
>>>> #####
>>>> ### source the following to create objects used by the reproducible
>>>> example
>>>> above
>>>> #####
>>>> 
>>>> ## the two points converted from long/lat using the complete ESRI
>>>>"two-
>>>> step process"
>>>> ## saved as a shapefile, loaded into R using readOGR(). Then just the
>>>> coordinates
>>>> ## were "dput"
>>>> locs.ref <- new(
>>>>               "SpatialPoints",
>>>>               coords = structure(c(1703671.30566227, 1704020.20113366,
>>>>                 424014.398045834, 421943.708664294), .Dim = c(2L, 2L),
>>>>                 .Dimnames = list(NULL, c("coords.x1", "coords.x2")))
>>>>               , bbox = structure(
>>>>                   c(1703671.30566227, 421943.708664294,
>>>>                     1704020.20113366, 424014.398045834),
>>>>                   .Dim = c(2L, 2L),
>>>>                   .Dimnames = list(c("coords.x1",  "coords.x2"),
>>>>c("min", 
>>>> "max")))
>>>>               , proj4string =
>>>>               new("CRS",
>>>>                   projargs = "+proj=lcc +lat_1=37.06666666666667
>>>> +lat_2=38.43333333333333 +lat_0=36.5 +lon_0=-120.5
>>>> +x_0=609601.2192024384 +y_0=0 +datum=NAD27 +units=us-ft +no_defs
>>>> +ellps=clrk66 +nadgrids=@conus, at alaska, at ntv2_0.gsb, at ntv1_can.dat"
>>>>                   )
>>>>               )
>>>> 
>>>> 
>>>> ## the points converted to epsg 2227 using ESRI's step 1
>>>> ## saved as a shapefile, loaded into R using readOGR
>>>> ## Then just the coordinates were "dput"
>>>> locs.step1.esri <- new(
>>>>                      "SpatialPoints",
>>>>                      coords = structure(c(6265039.1378244,
>>>> 6265388.04257557,
>>>>                        2064418.92932968, 2062348.22239488), .Dim =
>>>>c(2L, 
>>>> 2L),
>>>>                        .Dimnames = list(NULL, c("coords.x1",
>>>> "coords.x2")))
>>>>                      , bbox = structure(
>>>>                          c(6265039.1378244, 2062348.22239488,
>>>>                            6265388.04257557, 2064418.92932968),
>>>>                          .Dim = c(2L, 2L),
>>>>                          .Dimnames = list(c("coords.x1",
>>>>"coords.x2"), 
>>>> c("min", "max")))
>>>>                      , proj4string = new("CRS",
>>>>                          projargs = "+proj=lcc
>>>>+lat_1=37.06666666666667
>>>> +lat_2=38.43333333333333 +lat_0=36.5 +lon_0=-120.5 +x_0=2000000
>>>> +y_0=500000.0000000001 +datum=NAD83 +units=us-ft +no_defs
>>>> +ellps=GRS80 +towgs84=0,0,0"
>>>>                          )
>>>>                      )
>>>> 
>>>> 
>>>> #####
>>>> ###package and session information
>>>> #####
>>>> 
>>>> 
>>>> Loading required package: sp
>>>> Checking rgeos availability: TRUE
>>>> 
>>>> Loading required package: rgdal
>>>> rgdal: version: 0.8-16, (SVN revision 498)
>>>> Geospatial Data Abstraction Library extensions to R successfully
>>>>loaded
>>>> Loaded GDAL runtime: GDAL 1.11.0, released 2014/04/16
>>>> Path to GDAL shared files:
>>>> /Users/macqueen1/Library/R/3.1/library/rgdal/gdal
>>>> Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
>>>> Path to PROJ.4 shared files:
>>>> /Users/macqueen1/Library/R/3.1/library/rgdal/proj
>>>> 
>>>> 
>>>>> sessionInfo()
>>>> R version 3.1.1 (2014-07-10)
>>>> Platform: x86_64-apple-darwin13.1.0 (64-bit)
>>>> 
>>>> locale:
>>>> [1] C
>>>> 
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>> 
>>>> other attached packages:
>>>> [1] sp_1.0-15       rgdal_0.8-16    maptools_0.8-30 xlsx_0.5.5
>>>> [5] xlsxjars_0.6.0  rJava_0.9-6     rmacq_1.3-1
>>>> 
>>>> loaded via a namespace (and not attached):
>>>> [1] foreign_0.8-61  grid_3.1.1      lattice_0.20-29 tools_3.1.1
>>>> 
>>>> ----
>>>> two final comments:
>>>> 
>>>> I understand that this is really a PROJ.4 question, so I hope that
>>>> R-sig-geo
>>>> folks don't mind too much; apologies in advance if so.
>>>> 
>>>> I hope my email software truly sends a plain text email like it
>>>>claims. 
>>>> But I'm
>>>> not sure I trust it!
>>>> 
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> 
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> 
>>
>>
>
>-- 
>Roger Bivand
>Department of Economics, Norwegian School of Economics,
>Helleveien 30, N-5045 Bergen, Norway.
>voice: +47 55 95 93 55; fax +47 55 95 91 00
>e-mail: Roger.Bivand at nhh.no


From frtog at vestas.com  Wed Sep  3 19:40:21 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Wed, 3 Sep 2014 19:40:21 +0200
Subject: [R-sig-Geo] Using spTransform() to reproduce another software
 package's transformation
Message-ID: <u23rca5uan4u4fim69t6war2.1409766018315@email.android.com>

Thanks guys.

I'm a novice but still learning and your expertise is very much appreciated.

Thank you very much.

Br. Frede


Sendt fra Samsung mobil


-------- Oprindelig meddelelse --------
Fra: Hermann Peifer
Dato:03/09/2014 19.27 (GMT+01:00)
Til: "MacQueen, Don" ,Roger.Bivand at nhh.no
Cc: r-sig-geo at r-project.org,Frede Aakmann T?gersen
Emne: Re: [R-sig-Geo] Using spTransform() to reproduce another software package's transformation

On 2014-09-03 19:02, MacQueen, Don wrote:
> Roger, Hermann, Frede,
>
> My thanks to all who took a look at this. Your responses, including
> Roger?s re-expression using cs2cs on the proj list and the discussion
> there (subject: NAD_1983_To_WGS_1984_5), are very helpful.
>
> The proj.4 parameters that Roger has provided do better than I had been
> able to achieve, such that I am completely comfortable telling my
> co-workers that I can reproduce their coordinate transformations. And at a
> programmatic level, that is what I really needed, so thanks!
>
>
> -Don
>

You are welcome. Just a final thought: one could reduce the 2-step
transformation to a singe step by reverting the signs of all 7
transformation parameters. This would basically change the "towgs84"
parameters into "fromwgs84" parameters. See the example below.

Regards, Hermann


Input coordinates (locs.xy):
-121.524764291826 37.6600366036405
-121.523480804667 37.6543604613483

Expected output in EPSG:26743, if I understood it right
1703671.30566227 424014.398045834
1704020.20113366 421943.708664294

$ cs2cs -f "%16.9f" +init=epsg:4326
+towgs84=0.991,-1.9072,-0.5129,-0.025789908,-0.0096501,-0.0116599,0.0
+to +init=epsg:26743 locs.xy

1703671.305668926       424014.397713636      1.854101732
1704020.201140860       421943.708332143      1.854560674

	[[alternative HTML version deleted]]


From r.hijmans at gmail.com  Wed Sep  3 20:07:14 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 3 Sep 2014 11:07:14 -0700
Subject: [R-sig-Geo] raster - 4D Bricks
In-Reply-To: <CAAcGz990Lp-GhXM6woNbG06T0UCCw2tMsqBMS+iJg1mQw57h6Q@mail.gmail.com>
References: <CAGBzUO9GunwRVUe_2zMaVQn0LT02wH=JCkknS-N7fAo3vsLOhw@mail.gmail.com>
	<CAAcGz9_Uo8Qh7quyvKMQta-=dHnUEe5kjKUXjy0dFQ2pWEyBiQ@mail.gmail.com>
	<CAGBzUO-70X42FiCmZgS-r6RH54fyOMz=6WGfVOfg69vfzp7Kng@mail.gmail.com>
	<CAAcGz990Lp-GhXM6woNbG06T0UCCw2tMsqBMS+iJg1mQw57h6Q@mail.gmail.com>
Message-ID: <CANtt_hwnPX4P06KKD5h6=RQmHbno7n-G=bbFG1xJD7ay050smA@mail.gmail.com>

Mark and Mike,
Thanks for reporting and clarifying. Fixed, I think, in raster version 2.2-45.
Robert

On Wed, Jul 30, 2014 at 1:13 AM, Michael Sumner <mdsumner at gmail.com> wrote:
> Hello,
>
> Thanks for clarifying, I get that problem too.  If I get a chance I'll
> have a closer look, but otherwise here's my notes for now.
>
> Note that conversion to stack allows it to work:
> library(raster)
> Loading required package: sp
> b <- brick('http://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/godas/pottmp.2013.nc',
> lvar=3, level=1, varname='pottmp')
> dropLayer(stack(b), 1:2)
>
> I presume you are getting this url read via the ncdf4 package? (And
> not via the GDAL DODS driver, for example).
>
> I get the same problem with subset() where i is longer than 1
> (dropLayer is a wrapper around subset). Below is my subset traceback
> and session info.
>
> Cheers, Mike.
>
> subset(x, 1:2)
> Error in (function (classes, fdef, mtable)  :
>   unable to find an inherited method for function ?extent? for
> signature ?"character"?
> In addition: Warning message:
> In .stackCDF(x, varname = varname, bands = bands) :
>   pottmp has 4 dimensions, I am using the last one
>> traceback()
> 8: stop(gettextf("unable to find an inherited method for function %s
> for signature %s",
>        sQuote(fdef at generic), sQuote(cnames)), domain = NA)
> 7: (function (classes, fdef, mtable)
>    {
>        methods <- .findInheritedMethods(classes, fdef, mtable)
>        if (length(methods) == 1L)
>            return(methods[[1L]])
>        else if (length(methods) == 0L) {
>            cnames <- paste0("\"", sapply(classes, as.character),
>                "\"", collapse = ", ")
>            stop(gettextf("unable to find an inherited method for
> function %s for signature %s",
>                sQuote(fdef at generic), sQuote(cnames)), domain = NA)
>        }
>        else stop("Internal error in finding inherited methods; didn't
> return a unique method",
>            domain = NA)
>    })(list("character"), function (x, ...)
>    standardGeneric("extent"), <environment>)
> 6: extent(x)
> 5: setExtent(x, value)
> 4: `extent<-`(`*tmp*`, value = <S4 object of class "Extent">)
> 3: .local(x, ...)
> 2: subset(x, 1:2)
> 1: subset(x, 1:2)
>
> sessionInfo()
> R version 3.1.0 (2014-04-10)
> Platform: x86_64-redhat-linux-gnu (64-bit)
>
> locale:
> [1] C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] ncdf4_1.12    raster_2.2-31 sp_1.0-15
>
> loaded via a namespace (and not attached):
> [1] grid_3.1.0      lattice_0.20-29 tools_3.1.0
>
>
>
>
>
>
> On Wed, Jul 30, 2014 at 5:45 PM, Mark Payne <markpayneatwork at gmail.com> wrote:
>> No, apparently it is still a brick:
>>
>>> class(b)
>> [1] "RasterBrick"
>> attr(,"package")
>> [1] "raster"
>>
>>
>> Here is a minimum (not)-working example, based on this post, which seems to
>> be having similar problems:
>> http://r-sig-geo.2731867.n2.nabble.com/Subset-a-Raster-object-read-from-a-4D-NetCDF-file-td7586200.html
>>
>> Example follows:
>>> library(raster)
>> Loading required package: sp
>>> b <-
>>> brick('http://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/godas/pottmp.2013.nc',
>>> lvar=3, level=1, varname='pottmp')
>>> b
>> class       : RasterBrick
>> dimensions  : 418, 360, 150480, 12  (nrow, ncol, ncell, nlayers)
>> resolution  : 1, 0.3333309  (x, y)
>> extent      : 0, 360, -74.66667, 64.66567  (xmin, xmax, ymin, ymax)
>> coord. ref. : +proj=longlat +datum=WGS84
>> data source :
>> http://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/godas/pottmp.2013.nc
>> names       : X2013.01.01, X2013.02.01, X2013.03.01, X2013.04.01,
>> X2013.05.01, X2013.06.01, X2013.07.01, X2013.08.01, X2013.09.01,
>> X2013.10.01, X2013.11.01, X2013.12.01
>> Date        : 2013-01-01, 2013-02-01, 2013-03-01, 2013-04-01, 2013-05-01,
>> 2013-06-01, 2013-07-01, 2013-08-01, 2013-09-01, 2013-10-01, 2013-11-01,
>> 2013-12-01
>> varname     : pottmp
>> level       : 1
>>
>>> dropLayer(b,1)
>>
>> Error in (function (classes, fdef, mtable)  :
>>   unable to find an inherited method for function ?extent? for signature
>> ?"character"?
>> In addition: Warning message:
>> In .stackCDF(x, varname = varname, bands = bands) :
>>   pottmp has 4 dimensions, I am using the last one
>>>
>>
>>
>>
>> On 29 July 2014 13:24, Michael Sumner <mdsumner at gmail.com> wrote:
>>>
>>> Are you sure that your "b" is still really a RasterBrick? That message
>>> comes if you give the functions character:
>>>
>>> library(raster)
>>> dropLayer("sometext", 1)
>>> Error in (function (classes, fdef, mtable)  :
>>>   unable to find an inherited method for function ?dropLayer? for
>>> signature ?"character"?
>>>
>>> (Basically because the functions are all generics, they scans through
>>> available methods and tells you it can't find one for "character").
>>>
>>> It works for me, see contrived example below that I had on hand due to
>>> obscure testing many years ago.
>>> (There is warning related to subsetting a linked-4D file, but that
>>> seems harmless).
>>>
>>> But, also try selecting only the bands you want at read time (or even
>>> just use a stack), so
>>>
>>> b <- brick("/blah/blah/ncep_07c_tho_all_1948-2010.mon.nc", level = 3,
>>> band = 1:5)
>>>
>>> Cheers, Mike.
>>>
>>> ## create a 4D NetCDF file in R
>>> ## load NetCDF package
>>> library(RNetCDF)
>>> ## generate 4D data - 1:N
>>> dims <- c(2, 3, 2, 2)
>>> a <- array(data = 1:prod(dims), dim = dims)
>>>
>>> ## create NetCDF file
>>> nc <- create.nc("test-1.nc")
>>> ## coordinate values for NetCDF (to test transform and band metadata)
>>> x <- seq(0, 5, length = dim(a)[1])
>>> y <- seq(0, 2, length = dim(a)[2])
>>> c3 <- seq(0, 1, length = dim(a)[3])
>>> c4 <- seq(0, 1, length = dim(a)[4])
>>>
>>> ## dimensions
>>> dim.def.nc(nc, "x", length(x))
>>> dim.def.nc(nc, "y", length(y))
>>> dim.def.nc(nc, "c3", length(c3))
>>> dim.def.nc(nc, "c4", length(c4))
>>>
>>> ## variables
>>> var.def.nc(nc, "a", "NC_DOUBLE", c(0, 1, 2, 3))
>>> var.def.nc(nc, "x", "NC_DOUBLE", 0)
>>> var.def.nc(nc, "y", "NC_DOUBLE", 1)
>>> var.def.nc(nc, "c3", "NC_DOUBLE", 2)
>>> var.def.nc(nc, "c4", "NC_DOUBLE", 3)
>>> ## write the data (all at once, no start/count)
>>> var.put.nc(nc, "a", a)
>>> var.put.nc(nc, "x", x)
>>> var.put.nc(nc, "y", y)
>>> var.put.nc(nc, "c3", c3)
>>> var.put.nc(nc, "c4", c4)
>>> ## finish up
>>> close.nc(nc)
>>>
>>> library(raster)
>>> b <- brick("test-1.nc", level = 2)
>>> nlevels(b)
>>> dropLayer(b, 1)
>>> class       : RasterLayer
>>> band        : 2  (of  2  bands)
>>> dimensions  : 3, 2, 6  (nrow, ncol, ncell)
>>> resolution  : 5, 1  (x, y)
>>> extent      : -2.5, 7.5, -0.5, 2.5  (xmin, xmax, ymin, ymax)
>>> coord. ref. : NA
>>> data source : C:\temp\test-1.nc
>>> names       : X1
>>> z-value     : 1
>>> zvar        : a
>>> level       : 1
>>>
>>> Warning message:
>>> In .rasterObjectFromCDF(x, type = objecttype, band = band, ...) :
>>>   "level" set to 1 (there are 2 levels)
>>>
>>>
>>> On Tue, Jul 29, 2014 at 7:43 PM, Mark Payne <markpayneatwork at gmail.com>
>>> wrote:
>>> > Hi,
>>> >
>>> > I have a 4D climate model output that I am trying to work with via
>>> > raster,
>>> > and that is unfortunately giving problems. I create the object as a
>>> > brick:
>>> >
>>> >> b
>>> > class       : RasterBrick
>>> > dimensions  : 220, 254, 55880, 756  (nrow, ncol, ncell, nlayers)
>>> > resolution  : 1, 1  (x, y)
>>> > extent      : 0.5, 254.5, 0.5, 220.5  (xmin, xmax, ymin, ymax)
>>> > coord. ref. : +proj=longlat +datum=WGS84
>>> > data source : /home/mpayne/Documents/NACLIM/
>>> > ncep_07c_tho_all_1948-2010.mon.nc
>>> > names       : X19480131, X19480229, X19480331, X19480430, X19480531,
>>> > X19480630, X19480731, X19480831, X19480930, X19481031, X19481130,
>>> > X19481231, X19490131, X19490228, X19490331, ...
>>> > z-value     : 19480131, 20101231 (min, max)
>>> > varname     : var2
>>> > level       : 3
>>> >
>>> > But I would like to drop a lot of the layers, so I try:
>>> >
>>> >> dropLayer(b,1:5)
>>> > Error in (function (classes, fdef, mtable)  :
>>> >   unable to find an inherited method for function ?extent? for signature
>>> > ?"character"?
>>> >>
>>> >
>>> > And get a rather strange error.... Trying subset instead:
>>> >
>>> >> subset(b,1:5)
>>> > Error in (function (classes, fdef, mtable)  :
>>> >   unable to find an inherited method for function ?extent? for signature
>>> > ?"character"?
>>> >>
>>> > Gives the same error. I'm assuming that this is related to the 4D nature
>>> > of
>>> > the data, as I can't reproduce it elsewise, e.g. using the examples...
>>> > Any
>>> > ideas?
>>> >
>>> > Best wishes,
>>> >
>>> > Mark
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> >
>>> > _______________________________________________
>>> > R-sig-Geo mailing list
>>> > R-sig-Geo at r-project.org
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> >
>>>
>>>
>>>
>>> --
>>> Michael Sumner
>>> Software and Database Engineer
>>> Australian Antarctic Division
>>> Hobart, Australia
>>> e-mail: mdsumner at gmail.com
>>
>>
>
>
>
> --
> Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> Hobart, Australia
> e-mail: mdsumner at gmail.com
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Wed Sep  3 23:10:04 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 3 Sep 2014 14:10:04 -0700
Subject: [R-sig-Geo] raster plotting question: figured it out
In-Reply-To: <FF9DB805FC41CC4E95825A50F68063021AA534EB@columbia.uhd.campus>
References: <FF9DB805FC41CC4E95825A50F68063021AA534B7@columbia.uhd.campus>
	<CAPKp32v7mBNDoCE88BO5uMts+8Cm34L6wU_mtq1kY8=RW_7JPg@mail.gmail.com>
	<FF9DB805FC41CC4E95825A50F68063021AA534EB@columbia.uhd.campus>
Message-ID: <CANtt_hxqgoTcANsjnDqjO_r1EKoJ+eP_p4-bRghT2yKBY=ERGA@mail.gmail.com>

Erin,

This is not a good approach:

min1 <- min(a at data@values,b at data@values)
max1 <- max(a at data@values,b at data@values)

Because many RasterLayer objects won't have any values there. It is
another example of why you should not poke inside of S4 objects if
there are functions to do that for you.
This is a better approach:

min1 <- min(minValue(a), minValue(b))
max1 <- max(maxValue(a), maxValue(b))

Robert


On Fri, Jul 25, 2014 at 12:09 PM, Hodgess, Erin <HodgessE at uhd.edu> wrote:
> Sure!
>
>
>
> No prob:
>
>
>
> min1 <- min(a at data@values,b at data@values<mailto:a at data@values,b at data@values>)
>
> max1 <- max(a at data@values,b at data@values<mailto:a at data@values,b at data@values>)
>
> bk1 <- seq(from=min1,to=max1,len=6)  #note: make the len whatever you wish
>
> par(mfrow=c(1,2))
>
> plot(a,breaks=bk1)
>
> plot(b,breaks=bk1)
>
>
>
> Thanks!
>
>
>
> I'm glad to hear that somebody else might use it....thought I was just being a complete doofus!
>
>
>
> Take care,
>
> Erin
>
>
>
> ________________________________
> From: Michael Treglia [mtreglia at gmail.com]
> Sent: Friday, July 25, 2014 1:42 PM
> To: Hodgess, Erin
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] raster plotting question: figured it out
>
> Hey Erin,
> Could you please include the solution? I haven't had to do that, but I'm sure that I (and others) will probably have to in the future, so it may be useful to have the solution in this thread
> Thanks!
> Mike
>
>
> On Fri, Jul 25, 2014 at 2:25 PM, Hodgess, Erin <HodgessE at uhd.edu<mailto:HodgessE at uhd.edu>> wrote:
> Sorry for the trouble.
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From lwwhdz at gmail.com  Thu Sep  4 04:57:42 2014
From: lwwhdz at gmail.com (lwwhdz)
Date: Thu, 4 Sep 2014 10:57:42 +0800
Subject: [R-sig-Geo] How to draw two variogram curves in one plot
Message-ID: <2014090410574022712010@gmail.com>

Dear all
     I am doing some work on regression kriging in R. Now I want to plot the varigrom curves of the dependent variable (A) and the regression residuals (B) before kriging. With this plot, I can easily to compare the autocorrelation (e.g. sill, range & nugget) of A and B.  I tried the following two commond, but it failed. 
......
plot(variogram(A~1,data), vgm_a,  pch = 19, col = "black", lwd=2, add=TRUE) 
plot(variogram(B~1,data), vgm_b,  pch = 19, col = "black", lwd=2) 
......
    Is there anyone have any ideas? Thanks very much!



Wang Li
Phd Candidate in University of Chinese Academy of Sciences (UCAS) and Institute of Remote Sensing and Digital Earth, CAS,The State Key Laboratory of Remote Sensing Science
CAS Olympic S&T Park, No. 20 at Datun Road, Chaoyang, Beijing, P.R.C. (P. O. Box 9718)
lwwhdz at sina.com
lwwhdz at gmail.com
(+86)18810433086

	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Thu Sep  4 08:06:51 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 04 Sep 2014 08:06:51 +0200
Subject: [R-sig-Geo] How to draw two variogram curves in one plot
In-Reply-To: <2014090410574022712010@gmail.com>
References: <2014090410574022712010@gmail.com>
Message-ID: <5408017B.7070801@uni-muenster.de>



On 09/04/2014 04:57 AM, lwwhdz wrote:
> Dear all
>      I am doing some work on regression kriging in R. Now I want to plot the varigrom curves of the dependent variable (A) and the regression residuals (B) before kriging. With this plot, I can easily to compare the autocorrelation (e.g. sill, range & nugget) of A and B.  I tried the following two commond, but it failed. 
> ......
> plot(variogram(A~1,data), vgm_a,  pch = 19, col = "black", lwd=2, add=TRUE) 
> plot(variogram(B~1,data), vgm_b,  pch = 19, col = "black", lwd=2) 
> ......
>     Is there anyone have any ideas? Thanks very much!

Yes, compose incrementally using base plot:

a = variogram(A~1,data)
b = variogram(B~1,data)
plot(gamma ~ dist, a, pch = 19)
points(gamma ~ dist, b, pch = 20) # use another pch!
lines(variogramLine(vgm_a, max(a$gamma)))
lines(variogramLine(vgm_b, max(a$gamma), col = 2))

in the plot() command you probably want to specify xlim and ylim in
order to have (0,0) as the plot origin.

> 
> 
> Wang Li
> Phd Candidate in University of Chinese Academy of Sciences (UCAS) and Institute of Remote Sensing and Digital Earth, CAS,The State Key Laboratory of Remote Sensing Science
> CAS Olympic S&T Park, No. 20 at Datun Road, Chaoyang, Beijing, P.R.C. (P. O. Box 9718)
> lwwhdz at sina.com
> lwwhdz at gmail.com
> (+86)18810433086
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140904/717e65ee/attachment.bin>

From edzer.pebesma at uni-muenster.de  Thu Sep  4 10:18:33 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 04 Sep 2014 10:18:33 +0200
Subject: [R-sig-Geo] How to draw two variogram curves in one plot
In-Reply-To: <5408017B.7070801@uni-muenster.de>
References: <2014090410574022712010@gmail.com>
	<5408017B.7070801@uni-muenster.de>
Message-ID: <54082059.2020506@uni-muenster.de>



On 09/04/2014 08:06 AM, Edzer Pebesma wrote:
> 
> 
> On 09/04/2014 04:57 AM, lwwhdz wrote:
>> Dear all
>>      I am doing some work on regression kriging in R. Now I want to plot the varigrom curves of the dependent variable (A) and the regression residuals (B) before kriging. With this plot, I can easily to compare the autocorrelation (e.g. sill, range & nugget) of A and B.  I tried the following two commond, but it failed. 
>> ......
>> plot(variogram(A~1,data), vgm_a,  pch = 19, col = "black", lwd=2, add=TRUE) 
>> plot(variogram(B~1,data), vgm_b,  pch = 19, col = "black", lwd=2) 
>> ......
>>     Is there anyone have any ideas? Thanks very much!
> 
> Yes, compose incrementally using base plot:
> 
> a = variogram(A~1,data)
> b = variogram(B~1,data)
> plot(gamma ~ dist, a, pch = 19)
> points(gamma ~ dist, b, pch = 20) # use another pch!
> lines(variogramLine(vgm_a, max(a$gamma)))
> lines(variogramLine(vgm_b, max(a$gamma), col = 2))

this should of course have been max(a$dist) instead of max(a$gamma), and
even better the maximum of xlim, if you specify that.


> 
> in the plot() command you probably want to specify xlim and ylim in
> order to have (0,0) as the plot origin.
> 
>>
>>
>> Wang Li
>> Phd Candidate in University of Chinese Academy of Sciences (UCAS) and Institute of Remote Sensing and Digital Earth, CAS,The State Key Laboratory of Remote Sensing Science
>> CAS Olympic S&T Park, No. 20 at Datun Road, Chaoyang, Beijing, P.R.C. (P. O. Box 9718)
>> lwwhdz at sina.com
>> lwwhdz at gmail.com
>> (+86)18810433086
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> 
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140904/02f4f2bb/attachment.bin>

From M.Huck at derby.ac.uk  Thu Sep  4 11:23:02 2014
From: M.Huck at derby.ac.uk (Maren Huck)
Date: Thu, 4 Sep 2014 10:23:02 +0100
Subject: [R-sig-Geo] LSCV hlim
Message-ID: <0E1E893FE7447F4F883C415B21D0E5E9012BEC0A4A63@MKT-MBX01.university.ds.derby.ac.uk>

Dear All,

I think I have a problem understanding the meaning of hlim when calculating the kernel bandwidth using LSCV. As I understood the help page, the LSCV would be searched within the limits of "ranging from hlim[1]*href to hlim[2]*href". So if the href is for example 23.7, I would expect that under the default setting where hlim is defined to be c(0.1,1.5) my LSCV-h would be estimated to be somewhere between 2.37 and 47.4.
With my dataset (sorry, not attached, since I am not sure how to), I get 3.7. So far so good, although this gives a rediculously small home-range.
If I now play around with the limits I can get very different values, e.g.,
> udLSCV<- kernelUD(E500sp, h="LSCV", hlim = c(0.001, 10))
> udLSCV at h$h        # gives you the value of h
[1] 4.811839

> udLSCV<- kernelUD(E500sp, h="LSCV", ,hlim = c(0.001, 100))
> udLSCV at h$h        # gives you the value of h
[1] 23.96653

> udLSCV<- kernelUD(E500sp, h="LSCV", ,hlim = c(0.001, 1000))
> udLSCV at h$h        # gives you the value of h
[1] 239.4542

If LSCV "forces" me to play around with these limits to get a home-range that "looks" sensible, what is the point of using a supposedly more "objective" estimator, rather than using some rule-of-thumb or user-defined method (e.g., Schuler, K. L., G. M. Schroeder, J. A. Jenks, and J. G. Kie. 2013. Ad-hoc smoothing parameter performance in kernel estimates of GPS-derived home ranges. Wildlife Biology. In press.)?
Or is there also an "objective" way on how to decide on reasonable limits for LSCV to get a reasonable home-range?

Thanks in advance for any suggestions,
Maren


Maren Huck
Dep. of Biological and Forensic Sciences
University of Derby
Kedleston Road
Derby DE22 1GB
U.K.

The University of Derby has a published policy regarding email and reserves the right to monitor email traffic. If you believe this was sent to you in error, please select unsubscribe.

Unsubscribe and Security information contact:   infosec at derby.ac.uk
For all FOI requests please contact:   foi at derby.ac.uk
All other Contacts are at http://www.derby.ac.uk/its/contacts/


From mauriziomarchi85 at gmail.com  Thu Sep  4 16:40:31 2014
From: mauriziomarchi85 at gmail.com (Maurizio Marchi)
Date: Thu, 4 Sep 2014 16:40:31 +0200
Subject: [R-sig-Geo] Collinearity test domain
Message-ID: <CANJhsN0iwHTAmdTfVi-XxqbYb8h67-2so0BZKU0WLy=ZbBcXBA@mail.gmail.com>

Hallo everybody,
I have a question about Ecological Niche Modelling / Species Distribution
Modelling.

If I want to study the distribution of a species in present and future
time, to remove redundancy and collinearity between predictors should I
test predictors' correlation/covariance/collinearity using a database
including only presence/absence available points or should I have to use
the whole region I'm studing (e.g. the whole Europe?)

as example:
Presence points: Forest national inventory surveys classified as "pinus
nigra stands"
Absence/Pseudo absence points: Forest national inventory surveys NOT
classified as "pinus nigra stands"
Study region: Italy

many thanks,
Maurizio

-- 
Maurizio Marchi, Ph.D. student
Florence, Italy
ID skype: maurizioxyz
Ubuntu 14.04 LTS
linux user 552742

	[[alternative HTML version deleted]]


From dschlaep at uwyo.edu  Fri Sep  5 09:49:26 2014
From: dschlaep at uwyo.edu (Daniel Rodolphe Schlaepfer)
Date: Fri, 5 Sep 2014 07:49:26 +0000
Subject: [R-sig-Geo] Extracting one cell only with raster's rasterToPoints()
Message-ID: <5A3F281B-083E-46A3-8FBF-3F2B5945D0D8@uwyo.edu>

Hello all,

I converted a large set of rasters to spatial points. One of the rasters had only one cell that was to be converted; the raster package function rasterToPoints() failed, but the function would work for spatial=FALSE and of course also if there is more than one cell to convert.

Example:
r <- raster(nrow=5, ncol=5)
r[] <- 0
r[1] <- 1
p <- rasterToPoints(x=r, fun=function(x) x >= 1, spatial=TRUE) #Error in (function (classes, fdef, mtable)  : unable to find an inherited method for function ?coordinates? for signature ?"numeric"?
p <- rasterToPoints(x=r, fun=function(x) x >= 1, spatial=FALSE) #This works

r[2] <- 1
p <- rasterToPoints(x=r, fun=function(x) x >= 1, spatial=TRUE) #This works


It appears that there is a small solution to fix the rasterToPoints() function: add drop=FALSE to the xyv object in the return call of the if(spatial){}, i.e., change
return(SpatialPointsDataFrame(coords = xyv[, 1:2], data = v, proj4string = crs))
to
return(SpatialPointsDataFrame(coords = xyv[, 1:2, drop=FALSE], data = v, proj4string = crd))


Sincerely,
Daniel Schlaepfer


My sessionInfo():
#R version 3.1.1 (2014-07-10)
#Platform: x86_64-apple-darwin13.3.0 (64-bit)
#
#locale:
#[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
#
#attached base packages:
#[1] stats     graphics  grDevices
#[4] utils     datasets  methods
#[7] base
#
#other attached packages:
#[1] raster_2.2-48 sp_1.0-15
#
#loaded via a namespace (and not attached):
#[1] grid_3.1.1      lattice_0.20-29




-------------------------------------------------------
Daniel Schlaepfer
University of Wyoming, Laramie, WY 82071
-------------------------------------------------------


	[[alternative HTML version deleted]]


From pep.bioalerts at gmail.com  Fri Sep  5 20:06:47 2014
From: pep.bioalerts at gmail.com (Josep M Serra diaz)
Date: Fri, 5 Sep 2014 11:06:47 -0700
Subject: [R-sig-Geo] Raster focal Error with NAonly + na.rm=T,
	how to select NAonly focal cells?
Message-ID: <CAF8H1dfTJ5TBTg_S2C3-znxaoxNEedZ8T_Qm6FZ8sS3dZuvuDw@mail.gmail.com>

Dear listers,

I have been trying to understand why I am getting this Error when using the
focal function

Error in fun(x, na.rm = TRUE) : unused argument (na.rm = TRUE)



I am trying to build an iteration where NA values in a raster are
substituted by a random sample from the focal window (3x3 window).

That is, my center NA value would take random values of the 3x3 window
without considering NAs
I tried to reproduce an example here


Example:

library (raster)

a <- matrix (c(1,2,4,5,
               2,NA,NA,1,
               3,2,4,5,
               2,3,4,NA,
               NA,2,1,3),ncol=4)

r <-raster (a)
matrix.weights <- matrix(rep(1,times=9),ncol=3)
matrix.weights

r2 <- focal (r,w=matrix.weights,fun = function(x){sample(x,size=1)}, pad=T,
padValue=NA, NAonly=T, na.rm=T)

Error in fun(x, na.rm = TRUE) : unused argument (na.rm = TRUE)


The error likely makes sense here because the function sample does not
accept na.rm argument,


I also tried
r3 <- focal (r,w=matrix.weights,fun = function
(x){sample(na.omit(x),size=1)},pad=T,padValue=NA,NAonly=T)

Error in fun(x, na.rm = TRUE) : unused argument (na.rm = TRUE)

withouth the NAonly argument it does work, however
r4 <- focal (r,w=matrix.weights,fun = function
(x){sample(na.omit(x),size=1)},pad=T,padValue=NA)


How can I make it to select only NAonly cells for focal? I have a pretty
big raster that doing it without NAonly=T can be ...slow

Thanks,

Josep

	[[alternative HTML version deleted]]


From r.hijmans at gmail.com  Fri Sep  5 20:16:42 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Fri, 5 Sep 2014 11:16:42 -0700
Subject: [R-sig-Geo] Raster focal Error with NAonly + na.rm=T,
 how to select NAonly focal cells?
In-Reply-To: <CAF8H1dfTJ5TBTg_S2C3-znxaoxNEedZ8T_Qm6FZ8sS3dZuvuDw@mail.gmail.com>
References: <CAF8H1dfTJ5TBTg_S2C3-znxaoxNEedZ8T_Qm6FZ8sS3dZuvuDw@mail.gmail.com>
Message-ID: <CANtt_hwNZP0-=Q-jBM3OTOwovu-2US8Otq4D2=1cprUfnbZDNQ@mail.gmail.com>

Joseph,

The errors go away if you add ellipses to your functions, to let the
na.rm pass through (even if you ignore it).

r3 <- focal (r,w=matrix.weights,fun = function(x,
...){sample(na.omit(x),size=1)},pad=T,padValue=NA,NAonly=T)

The perhaps surprising error with r3 occurs because when NAonly ==
TRUE, na.rm is set to TRUE internally. I will remove that; as it may
not be desirable in all cases.

Robert

On Fri, Sep 5, 2014 at 11:06 AM, Josep M Serra diaz
<pep.bioalerts at gmail.com> wrote:
> Dear listers,
>
> I have been trying to understand why I am getting this Error when using the
> focal function
>
> Error in fun(x, na.rm = TRUE) : unused argument (na.rm = TRUE)
>
>
>
> I am trying to build an iteration where NA values in a raster are
> substituted by a random sample from the focal window (3x3 window).
>
> That is, my center NA value would take random values of the 3x3 window
> without considering NAs
> I tried to reproduce an example here
>
>
> Example:
>
> library (raster)
>
> a <- matrix (c(1,2,4,5,
>                2,NA,NA,1,
>                3,2,4,5,
>                2,3,4,NA,
>                NA,2,1,3),ncol=4)
>
> r <-raster (a)
> matrix.weights <- matrix(rep(1,times=9),ncol=3)
> matrix.weights
>
> r2 <- focal (r,w=matrix.weights,fun = function(x){sample(x,size=1)}, pad=T,
> padValue=NA, NAonly=T, na.rm=T)
>
> Error in fun(x, na.rm = TRUE) : unused argument (na.rm = TRUE)
>
>
> The error likely makes sense here because the function sample does not
> accept na.rm argument,
>
>
> I also tried
> r3 <- focal (r,w=matrix.weights,fun = function
> (x){sample(na.omit(x),size=1)},pad=T,padValue=NA,NAonly=T)
>
> Error in fun(x, na.rm = TRUE) : unused argument (na.rm = TRUE)
>
> withouth the NAonly argument it does work, however
> r4 <- focal (r,w=matrix.weights,fun = function
> (x){sample(na.omit(x),size=1)},pad=T,padValue=NA)
>
>
> How can I make it to select only NAonly cells for focal? I have a pretty
> big raster that doing it without NAonly=T can be ...slow
>
> Thanks,
>
> Josep
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From jrotundo at unr.edu.ar  Fri Sep  5 20:29:28 2014
From: jrotundo at unr.edu.ar (=?UTF-8?Q?Jos=C3=A9_Luis_Rotundo?=)
Date: Fri, 5 Sep 2014 15:29:28 -0300
Subject: [R-sig-Geo] How to deal with data points having the same lat long
	position?
Message-ID: <CADBY2pqA0ESLRgLCqvHqne-aTB-vY+mxdGeATeRcMfrJsmmxzg@mail.gmail.com>

Dear list,

I am working with a database of farm yields across USA and the objective is
to map soybean yields. To preserve the identity of the farmers, they only
provided the zipcode of the farm. Then I attached the zip code lat and
long. The problem I have is that several farms belongs to the same zipcode
and therefore they have the same lat and long. Having this repeated
locations troubles the construction of the variogram.

Option (A) was to average these values, but I loss almost 4000 data points
out of 15000.

Option (B) would be to slightly modify the lat and long values.

My questions:

1. Does anyone knows a way to efficiently detect and slightly  modify the
repeated lat and long values?.
2. Is there any other way to deal with repeated values when doing variograms
?

any help will be appreciated.

Best,

Jose



-- 


Jos? L. Rotundo
CONICET
Facultad de Ciencias Agrarias
Univ. Nacional de Rosario
Zavalla, Santa Fe
Argentina

	[[alternative HTML version deleted]]


From cswingle at swingleydev.com  Fri Sep  5 21:29:58 2014
From: cswingle at swingleydev.com (Christopher Swingley)
Date: Fri, 5 Sep 2014 11:29:58 -0800
Subject: [R-sig-Geo] How to deal with data points having the same lat
	long position?
In-Reply-To: <CADBY2pqA0ESLRgLCqvHqne-aTB-vY+mxdGeATeRcMfrJsmmxzg@mail.gmail.com>
References: <CADBY2pqA0ESLRgLCqvHqne-aTB-vY+mxdGeATeRcMfrJsmmxzg@mail.gmail.com>
Message-ID: <CAHsw44-bkhmgkwqCiPE108x+5STKHpzJB5ZYy4z-mPVTpN+bSQ@mail.gmail.com>

Jose,

On Fri, Sep 5, 2014 at 10:29 AM, Jos? Luis Rotundo <jrotundo at unr.edu.ar> wrote:
> I am working with a database of farm yields across USA and the objective is
> to map soybean yields. To preserve the identity of the farmers, they only
> provided the zipcode of the farm. Then I attached the zip code lat and
> long. The problem I have is that several farms belongs to the same zipcode
> and therefore they have the same lat and long. Having this repeated
> locations troubles the construction of the variogram.

Wouldn't it be better to attach the sum of the soybean yields assigned
to a zip code to a vector layer containing zip code boundaries?  I can
imagine that if you assign values to a single point (even jittered
when there are duplicates for single zip code) per zip code, that you
won't wind up with a very accurate representation of the spatial
pattern because the area each zip code covers will be different.

Cheers,

Chris
-- 
Christopher Swingley
Fairbanks, Alaska
http://swingleydev.com/
cswingle at swingleydev.com


From clint at ecy.wa.gov  Fri Sep  5 22:13:03 2014
From: clint at ecy.wa.gov (Clint Bowman)
Date: Fri, 5 Sep 2014 13:13:03 -0700 (PDT)
Subject: [R-sig-Geo] How to deal with data points having the same lat
 long position?
In-Reply-To: <CAHsw44-bkhmgkwqCiPE108x+5STKHpzJB5ZYy4z-mPVTpN+bSQ@mail.gmail.com>
References: <CADBY2pqA0ESLRgLCqvHqne-aTB-vY+mxdGeATeRcMfrJsmmxzg@mail.gmail.com>
	<CAHsw44-bkhmgkwqCiPE108x+5STKHpzJB5ZYy4z-mPVTpN+bSQ@mail.gmail.com>
Message-ID: <alpine.LRH.2.11.1409051310000.7121@aeolus.ecy.wa.gov>

Jose,

Are your units of yield in quantity/area or total quantity?  If yield is 
quantity/area, I think I would compute the average for each county with a 
reported yield.

Clint

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Fri, 5 Sep 2014, Christopher Swingley wrote:

> Jose,
>
> On Fri, Sep 5, 2014 at 10:29 AM, Jos? Luis Rotundo <jrotundo at unr.edu.ar> wrote:
>> I am working with a database of farm yields across USA and the objective is
>> to map soybean yields. To preserve the identity of the farmers, they only
>> provided the zipcode of the farm. Then I attached the zip code lat and
>> long. The problem I have is that several farms belongs to the same zipcode
>> and therefore they have the same lat and long. Having this repeated
>> locations troubles the construction of the variogram.
>
> Wouldn't it be better to attach the sum of the soybean yields assigned
> to a zip code to a vector layer containing zip code boundaries?  I can
> imagine that if you assign values to a single point (even jittered
> when there are duplicates for single zip code) per zip code, that you
> won't wind up with a very accurate representation of the spatial
> pattern because the area each zip code covers will be different.
>
> Cheers,
>
> Chris
> -- 
> Christopher Swingley
> Fairbanks, Alaska
> http://swingleydev.com/
> cswingle at swingleydev.com
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

From rotundo.jose at gmail.com  Sat Sep  6 00:26:44 2014
From: rotundo.jose at gmail.com (=?UTF-8?Q?Jos=C3=A9_Luis_Rotundo?=)
Date: Fri, 5 Sep 2014 19:26:44 -0300
Subject: [R-sig-Geo] How to deal with data points having the same lat
	long position?
In-Reply-To: <alpine.LRH.2.11.1409051310000.7121@aeolus.ecy.wa.gov>
References: <CADBY2pqA0ESLRgLCqvHqne-aTB-vY+mxdGeATeRcMfrJsmmxzg@mail.gmail.com>
	<CAHsw44-bkhmgkwqCiPE108x+5STKHpzJB5ZYy4z-mPVTpN+bSQ@mail.gmail.com>
	<alpine.LRH.2.11.1409051310000.7121@aeolus.ecy.wa.gov>
Message-ID: <CADBY2pofvJeXomFcxjBu5A190uZOmerG-LZb-bZ0xUUL5rjPrg@mail.gmail.com>

Thanks Clint. I could try that. But I wanted to have data by lat and long
location.

Best regards,

Jose




2014-09-05 17:13 GMT-03:00 Clint Bowman <clint at ecy.wa.gov>:

> Jose,
>
> Are your units of yield in quantity/area or total quantity?  If yield is
> quantity/area, I think I would compute the average for each county with a
> reported yield.
>
> Clint
>
> Clint Bowman                    INTERNET:       clint at ecy.wa.gov
> Air Quality Modeler             INTERNET:       clint at math.utah.edu
> Department of Ecology           VOICE:          (360) 407-6815
> PO Box 47600                    FAX:            (360) 407-7534
> Olympia, WA 98504-7600
>
>         USPS:           PO Box 47600, Olympia, WA 98504-7600
>         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
>
>
> On Fri, 5 Sep 2014, Christopher Swingley wrote:
>
>  Jose,
>>
>> On Fri, Sep 5, 2014 at 10:29 AM, Jos? Luis Rotundo <jrotundo at unr.edu.ar>
>> wrote:
>>
>>> I am working with a database of farm yields across USA and the objective
>>> is
>>> to map soybean yields. To preserve the identity of the farmers, they only
>>> provided the zipcode of the farm. Then I attached the zip code lat and
>>> long. The problem I have is that several farms belongs to the same
>>> zipcode
>>> and therefore they have the same lat and long. Having this repeated
>>> locations troubles the construction of the variogram.
>>>
>>
>> Wouldn't it be better to attach the sum of the soybean yields assigned
>> to a zip code to a vector layer containing zip code boundaries?  I can
>> imagine that if you assign values to a single point (even jittered
>> when there are duplicates for single zip code) per zip code, that you
>> won't wind up with a very accurate representation of the spatial
>> pattern because the area each zip code covers will be different.
>>
>> Cheers,
>>
>> Chris
>> --
>> Christopher Swingley
>> Fairbanks, Alaska
>> http://swingleydev.com/
>> cswingle at swingleydev.com
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


-- 


Jos? L. Rotundo
CONICET
Facultad de Ciencias Agrarias
Univ. Nacional de Rosario
Zavalla, Santa Fe
Argentina

	[[alternative HTML version deleted]]


From rotundo.jose at gmail.com  Sat Sep  6 00:28:21 2014
From: rotundo.jose at gmail.com (=?UTF-8?Q?Jos=C3=A9_Luis_Rotundo?=)
Date: Fri, 5 Sep 2014 19:28:21 -0300
Subject: [R-sig-Geo] How to deal with data points having the same lat
	long position?
In-Reply-To: <CAHsw44-bkhmgkwqCiPE108x+5STKHpzJB5ZYy4z-mPVTpN+bSQ@mail.gmail.com>
References: <CADBY2pqA0ESLRgLCqvHqne-aTB-vY+mxdGeATeRcMfrJsmmxzg@mail.gmail.com>
	<CAHsw44-bkhmgkwqCiPE108x+5STKHpzJB5ZYy4z-mPVTpN+bSQ@mail.gmail.com>
Message-ID: <CADBY2prHi8+ZMdefwrYtngxNhri0ipW8+w-c6NzR68Gj5aXzAA@mail.gmail.com>

Christopher,

Thank you very much for your suggestion. It might work.

Best,

Jose




2014-09-05 16:29 GMT-03:00 Christopher Swingley <cswingle at swingleydev.com>:

> Jose,
>
> On Fri, Sep 5, 2014 at 10:29 AM, Jos? Luis Rotundo <jrotundo at unr.edu.ar>
> wrote:
> > I am working with a database of farm yields across USA and the objective
> is
> > to map soybean yields. To preserve the identity of the farmers, they only
> > provided the zipcode of the farm. Then I attached the zip code lat and
> > long. The problem I have is that several farms belongs to the same
> zipcode
> > and therefore they have the same lat and long. Having this repeated
> > locations troubles the construction of the variogram.
>
> Wouldn't it be better to attach the sum of the soybean yields assigned
> to a zip code to a vector layer containing zip code boundaries?  I can
> imagine that if you assign values to a single point (even jittered
> when there are duplicates for single zip code) per zip code, that you
> won't wind up with a very accurate representation of the spatial
> pattern because the area each zip code covers will be different.
>
> Cheers,
>
> Chris
> --
> Christopher Swingley
> Fairbanks, Alaska
> http://swingleydev.com/
> cswingle at swingleydev.com
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 


Jos? L. Rotundo
CONICET
Facultad de Ciencias Agrarias
Univ. Nacional de Rosario
Zavalla, Santa Fe
Argentina

	[[alternative HTML version deleted]]


From clint at ecy.wa.gov  Sat Sep  6 00:43:02 2014
From: clint at ecy.wa.gov (Clint Bowman)
Date: Fri, 5 Sep 2014 15:43:02 -0700 (PDT)
Subject: [R-sig-Geo] How to deal with data points having the same lat
 long position?
In-Reply-To: <CADBY2pofvJeXomFcxjBu5A190uZOmerG-LZb-bZ0xUUL5rjPrg@mail.gmail.com>
References: <CADBY2pqA0ESLRgLCqvHqne-aTB-vY+mxdGeATeRcMfrJsmmxzg@mail.gmail.com>
	<CAHsw44-bkhmgkwqCiPE108x+5STKHpzJB5ZYy4z-mPVTpN+bSQ@mail.gmail.com>
	<alpine.LRH.2.11.1409051310000.7121@aeolus.ecy.wa.gov>
	<CADBY2pofvJeXomFcxjBu5A190uZOmerG-LZb-bZ0xUUL5rjPrg@mail.gmail.com>
Message-ID: <alpine.LRH.2.11.1409051537190.7121@aeolus.ecy.wa.gov>

Jose,

Sorry I wasn't sufficiently clear.  Because your data has only zip codes 
for location, you've merged in the centroid (lon.lat) for each zip code 
into your dataset.  Then after averaging within each zip code you will 
have just a single value for each zip code and the (lon,lat) coordinates 
associated with it.  Now you can construct your variogram and continue 
with your analysis.  You will lose any information that the intra-zip code 
variability could contribute.

Clint

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Fri, 5 Sep 2014, Jos? Luis Rotundo wrote:

> Thanks Clint. I could try that. But I wanted to have data by lat and long location.?
> Best regards,
> 
> Jose
> 
> 
> 
> 
> 2014-09-05 17:13 GMT-03:00 Clint Bowman <clint at ecy.wa.gov>:
>       Jose,
>
>       Are your units of yield in quantity/area or total quantity?? If yield is quantity/area, I think I would compute the average for each county with a
>       reported yield.
>
>       Clint
>
>       Clint Bowman? ? ? ? ? ? ? ? ? ? INTERNET:? ? ? ?clint at ecy.wa.gov
>       Air Quality Modeler? ? ? ? ? ? ?INTERNET:? ? ? ?clint at math.utah.edu
>       Department of Ecology? ? ? ? ? ?VOICE:? ? ? ? ? (360) 407-6815
>       PO Box 47600? ? ? ? ? ? ? ? ? ? FAX:? ? ? ? ? ? (360) 407-7534
>       Olympia, WA 98504-7600
>
>       ? ? ? ? USPS:? ? ? ? ? ?PO Box 47600, Olympia, WA 98504-7600
>       ? ? ? ? Parcels:? ? ? ? 300 Desmond Drive, Lacey, WA 98503-1274
>
>       On Fri, 5 Sep 2014, Christopher Swingley wrote:
>
>             Jose,
>
>             On Fri, Sep 5, 2014 at 10:29 AM, Jos? Luis Rotundo <jrotundo at unr.edu.ar> wrote:
>                   I am working with a database of farm yields across USA and the objective is
>                   to map soybean yields. To preserve the identity of the farmers, they only
>                   provided the zipcode of the farm. Then I attached the zip code lat and
>                   long. The problem I have is that several farms belongs to the same zipcode
>                   and therefore they have the same lat and long. Having this repeated
>                   locations troubles the construction of the variogram.
> 
>
>             Wouldn't it be better to attach the sum of the soybean yields assigned
>             to a zip code to a vector layer containing zip code boundaries?? I can
>             imagine that if you assign values to a single point (even jittered
>             when there are duplicates for single zip code) per zip code, that you
>             won't wind up with a very accurate representation of the spatial
>             pattern because the area each zip code covers will be different.
>
>             Cheers,
>
>             Chris
>             --
>             Christopher Swingley
>             Fairbanks, Alaska
>             http://swingleydev.com/
>             cswingle at swingleydev.com
>
>             _______________________________________________
>             R-sig-Geo mailing list
>             R-sig-Geo at r-project.org
>             https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 
> 
> 
> --
> 
> 
> Jos? L. Rotundo
> CONICET
> Facultad de Ciencias Agrarias
> Univ. Nacional de Rosario
> Zavalla, Santa Fe
> Argentina
> 
>

From darunabas at gmail.com  Sat Sep  6 19:10:24 2014
From: darunabas at gmail.com (Barnabas Daru)
Date: Sat, 6 Sep 2014 19:10:24 +0200
Subject: [R-sig-Geo] Automate the extraction of climate variable at
 different time depths from netcdf in r
Message-ID: <CA+R607EimFZvQXjmjp0B1KSQgmaXz6=n8zZsCJ+AS4Ccsix+_g@mail.gmail.com>

Dear all,
I write to seek help with extracting climate data at various times and
depth from NETCDF in R.
The climate data is sea surface temperature monthly means from 1854 to
2014.
My goal is to automate the extraction of SST climate data for a set of
points with different time depths.

I have successfully used the 'brick' function in the raster package to get
climate data at various time depths as follows:

b <- brick("~sst.mnmean.nc", varname="sst")

mydate <- b[["X1869.09.01"]] # SST for September in 1869

mydata <- read.csv("~Species one.csv")

mydataSPDF <- SpatialPointsDataFrame(mydata[,5:6],data.frame(mydata))

extract.mydata <- extract(mydate, mydataSPDF, sp=TRUE)

extract.mydata <- data.frame(extract.mydata)

write.csv(extract.mydata, file = "Species_one_extracted.csv")

My major challenge is that I have to keep extracting manually for each time
depth, then copy and paste in the main dataframe and the data has about
3000 observations, meaning I have to keep copying and pasting ~3000 times
for one species!
Is there a way I can iterate the process in R to loop through each month's
climate and extract the data for each point and time depth rather than to
do it manually?

Here's how my data frame looks like:
  Date year month day lon lat SST  1855-01-01 1855 1 1 11.6861 57.7254
3.440000057  1859-07-26 1859 7 26 25.46122 60.26766 13.25  1860-01-01 1860 1
1 10.9154 53.9484 15.10999966  1861-07-10 1861 7 10 7.79588 58.08673
15.71000004  1861-07-26 1861 7 26 -2.84072 54.0778  1861-08-17 1861 8 17
11.9792 57.51298  1862-01-01 1862 1 1 22.20467 60.27955  1862-08-05 1862 8 5
11.78316 57.61649  1862-08-23 1862 8 23 11.9792 57.51298  1863-08-26 1863 8
26 10.72237 59.97258  1863-08-28 1863 8 28 15.53721 56.20091  1863-09-22
1863 9 22 16.37849 56.84255  1864-07-05 1864 7 5 -4.07097 51.09542
1864-07-18 1864 7 18 -4.21368 51.0928  1864-08-26 1864 8 26 -4.07097
51.09542  1865-09-07 1865 9 7 10.76144 59.91271  1865-09-27 1865 9 27
10.53107 60.43395  1867-08-28 1867 8 28 12.82669 55.86822  1868-01-01 1868 1
1 12.8944 56.6897  1868-01-01 1868 1 1 4.82685 53.13793
Thanks and kind regards
Barnabas Daru

-- 

  \-/
   /\
  /--|
 /---/ *Daru, Barnabas Haruna*
 |--/  PhD Candidate,
 \-/   African Centre for DNA Barcoding,
 /\    University of Johannesburg,
/--\   PO BOX 524 Auckland Park, 2006,
|---\  South Africa
 \---\ Lab: +27 11 559 3477
  \--| Mobile: +27 7381 89 583
   \-/
   /\  My homepage: http://barnabasdaru.com
<http://acdb.co.za/index.php?page=mr-barnabas-h-daru>
  /--\

	[[alternative HTML version deleted]]


From glara63 at gmail.com  Sat Sep  6 19:27:14 2014
From: glara63 at gmail.com (Gustavo Lara)
Date: Sat, 6 Sep 2014 12:27:14 -0500
Subject: [R-sig-Geo] Is possible to get a interpolated gradient from kriging
 interpolation with gstat?
Message-ID: <CAE1vicm9dBjhnaVeR9C7JgAh4zY1jORhsTjpkSdiwn=h-1VcvA@mail.gmail.com>

Good day, please apologize the typo.

I am trying to use the gstat package implemented in R, to perform the
interpolation of molecular potential energy surfaces (PES) for a chemical
reaction. This surface is needed to integrate the Newton equations of
motion, and in this way simulate the reaction dynamic. Then, I need to
interpolate the gradient energy at differents non-sampled spatial
coordinate, from a non-grided set of data points. In each data point, I
have a Taylor expansion of the energy until second order, as function of
the spatial coordinates.

I want to use the advantages of the various kriging methods implemented in
the gstat packge and check which scheme is better for the PES
interpolation, but some questions are still unresolved for me:

It is possible to interpolate a N-dimensional surface (with N > 3) with
kriging in gstat?

Is posible to perform the interpolation of a vectorial field (like the
gradient) in gstat?

It is posible to perform the interpolation of a matrix (like the second
derivatives) in gstat?

Like the energy is a scalar field, it is posible to get the gradient energy
from the interpolated energy with kriging in gstat.

Thank you for your time and help!

With best regards,

	[[alternative HTML version deleted]]


From r.hijmans at gmail.com  Sun Sep  7 05:23:10 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sat, 6 Sep 2014 20:23:10 -0700
Subject: [R-sig-Geo] Automate the extraction of climate variable at
 different time depths from netcdf in r
In-Reply-To: <CA+R607EimFZvQXjmjp0B1KSQgmaXz6=n8zZsCJ+AS4Ccsix+_g@mail.gmail.com>
References: <CA+R607EimFZvQXjmjp0B1KSQgmaXz6=n8zZsCJ+AS4Ccsix+_g@mail.gmail.com>
Message-ID: <CANtt_hzyrcRhqgYtAnkwT+waY03vD6N5w2PKjjPyFsEpXwBWLQ@mail.gmail.com>

Barnabas, ,
You can try something like this:

b <- brick("~sst.mnmean.nc", varname="sst")
# loop over species, or combine all species into one data.frame?
mydata <- read.csv("~Species one.csv")
extract.mydata <- extract(b, mydata[,5:6])
write.csv(extract.mydata, file = "Species_one_extracted.csv")

Robert

On Sat, Sep 6, 2014 at 10:10 AM, Barnabas Daru <darunabas at gmail.com> wrote:
> Dear all,
> I write to seek help with extracting climate data at various times and
> depth from NETCDF in R.
> The climate data is sea surface temperature monthly means from 1854 to
> 2014.
> My goal is to automate the extraction of SST climate data for a set of
> points with different time depths.
>
> I have successfully used the 'brick' function in the raster package to get
> climate data at various time depths as follows:
>
> b <- brick("~sst.mnmean.nc", varname="sst")
>
> mydate <- b[["X1869.09.01"]] # SST for September in 1869
>
> mydata <- read.csv("~Species one.csv")
>
> mydataSPDF <- SpatialPointsDataFrame(mydata[,5:6],data.frame(mydata))
>
> extract.mydata <- extract(mydate, mydataSPDF, sp=TRUE)
>
> extract.mydata <- data.frame(extract.mydata)
>
> write.csv(extract.mydata, file = "Species_one_extracted.csv")
>
> My major challenge is that I have to keep extracting manually for each time
> depth, then copy and paste in the main dataframe and the data has about
> 3000 observations, meaning I have to keep copying and pasting ~3000 times
> for one species!
> Is there a way I can iterate the process in R to loop through each month's
> climate and extract the data for each point and time depth rather than to
> do it manually?
>
> Here's how my data frame looks like:
>   Date year month day lon lat SST  1855-01-01 1855 1 1 11.6861 57.7254
> 3.440000057  1859-07-26 1859 7 26 25.46122 60.26766 13.25  1860-01-01 1860 1
> 1 10.9154 53.9484 15.10999966  1861-07-10 1861 7 10 7.79588 58.08673
> 15.71000004  1861-07-26 1861 7 26 -2.84072 54.0778  1861-08-17 1861 8 17
> 11.9792 57.51298  1862-01-01 1862 1 1 22.20467 60.27955  1862-08-05 1862 8 5
> 11.78316 57.61649  1862-08-23 1862 8 23 11.9792 57.51298  1863-08-26 1863 8
> 26 10.72237 59.97258  1863-08-28 1863 8 28 15.53721 56.20091  1863-09-22
> 1863 9 22 16.37849 56.84255  1864-07-05 1864 7 5 -4.07097 51.09542
> 1864-07-18 1864 7 18 -4.21368 51.0928  1864-08-26 1864 8 26 -4.07097
> 51.09542  1865-09-07 1865 9 7 10.76144 59.91271  1865-09-27 1865 9 27
> 10.53107 60.43395  1867-08-28 1867 8 28 12.82669 55.86822  1868-01-01 1868 1
> 1 12.8944 56.6897  1868-01-01 1868 1 1 4.82685 53.13793
> Thanks and kind regards
> Barnabas Daru
>
> --
>
>   \-/
>    /\
>   /--|
>  /---/ *Daru, Barnabas Haruna*
>  |--/  PhD Candidate,
>  \-/   African Centre for DNA Barcoding,
>  /\    University of Johannesburg,
> /--\   PO BOX 524 Auckland Park, 2006,
> |---\  South Africa
>  \---\ Lab: +27 11 559 3477
>   \--| Mobile: +27 7381 89 583
>    \-/
>    /\  My homepage: http://barnabasdaru.com
> <http://acdb.co.za/index.php?page=mr-barnabas-h-daru>
>   /--\
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From dr_achughes at hotmail.co.uk  Sun Sep  7 10:31:36 2014
From: dr_achughes at hotmail.co.uk (Alice C. Hughes)
Date: Sun, 7 Sep 2014 09:31:36 +0100
Subject: [R-sig-Geo] R: individuals distribution points in paired polygons
In-Reply-To: <DUB126-W85ABE194AC5F7405FB7C8DDC00@phx.gbl>
References: <001101cf639e$d6cfa9f0$846efdd0$@arpa.sardegna.it>,
	<535FE602.8070605@gmail.com>,
	<002f01cf7051$a09e3b20$e1dab160$@arpa.sardegna.it>,
	<CAJRR3XMoc=vcpPqX12wshpBZnuz+O=+3rBnr3JyXVM9TSZ2hRw@mail.gmail.com>,
	<000901cf70db$8377f7e0$8a67e7a0$@arpa.sardegna.it>,
	<53760556.2060401@gmail.com>,
	<DUB126-W85ABE194AC5F7405FB7C8DDC00@phx.gbl>
Message-ID: <DUB126-W38FD6A70DE088531ECBE9DDDC00@phx.gbl>

I have distribution points (in excel or spatial point form) for a set ofindividuals and a file of polygons-with matching IDs: so each individual hasa set of points and a polygon with the same IDs: but there are 100's to1000's of individuals. What I would like to do is to go through and for each individual find thetotal number of points and the number which fall within the appropriatepolygon, then have the output in spreadsheet form with a column for ID;Total number of points; points in polygon. Each individual has a polygon with the same name, but every code I've seenso far can't differentiate, or scroll through multiple point files withunique IDs

Alice C. HughesAssociate ProfessorCentre for Integrative Conservation,Xishuangbanna Tropical Botanical Garden,Chinese Academy of SciencesMenglun, Mengla, Yunnan 666303, P.R. ChinaPh: 15198676559achughes at xtbg.ac.cn

> Date: Fri, 16 May 2014 14:32:22 +0200
> From: rubenfcasal at gmail.com
> To: mfiori at arpa.sardegna.it
> CC: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] R:  R: Regression Kriging cross validation
> 
> Hi Michele,
> 
> Kriging methods assume that the variogram is known, although it is not 
> in practice. With your procedure, the whole prediction method is 
> reproduced (adding the extra-variability due to the estimation of the 
> variogram), so a better approximation to the variability of the 
> prediction error should be (in principle) obtained.
> 
> Excuse the rush...
> 
> Ruben Fernandez-Casal
> 
> 
> El 16/05/2014 9:50, Michele Fiori escribi?:
> > Dear All,
> > Finally I managed to develop this ad hoc procedure for the regression kriging cross validation; I tried to test the kriging part (the regression part has been already tested successfully) by comparison with the krige.cv function and I noticed that there are small discrepancies. I verified that they are due to the fact that in my case the variogram is recalculated for each step, while the function runs using the same initial variogram obtained on the complete set of data.
> > What do you think about?
> > Michele
> >
> > ARPAS - Environmental Protection Agency of Sardinia MeteoClimatic
> > Department - Meteorological Service
> >
> > Viale Porto Torres 119 - 07100 Sassari, Italy Tel + 39 079 258617 Fax
> > + 39 079 262681 www.sardegnaambiente.it/arpas
> >
> > #################### Cross validation REGRESSION KRIGING (leave on out)
> > 					
> > 	PP03.lm <- lm(reg, prec2)
> > 	Nstazioni <- length(prec2$NOME_STAZ)
> > 	for (i in 1:Nstazioni) 	
> > 	{
> > 		###  regression step for point ?i?
> >
> > 		prec2.i <- prec2[-i,] 		
> >    		md.i <- lm(reg, data=prec2.i)
> > 	  		ypredlm.i <- predict(md.i,prec2[i,])
> > 	  		err[i] <- (ypredlm.i - prec2$PP03[i])^2
> > 		res[i] <- (ypredlm.i - prec2$PP03[i])
> >
> > 		###  kriging step for residual point ?i?
> >
> > 		PP03i.rsvar <- variogram(prec2.i$residuals~1, prec2.i)
> > 		PP03i.ivgm <- vgm(nugget=0, model="Sph", range=sqrt(diff(prec2.i at bbox["x",])^2 + diff(prec2.i at bbox["y",])^2)/4, psill=var(prec2.i$residuals))
> > 		PP03i.rvgm <- fit.variogram(PP03i.rsvar, model=PP03i.ivgm)
> > 		ypredok.i<- krige(md.i$residuals~1, prec2.i, prec2[i,], PP03i.rvgm)
> > 		ypredok.i$var1.pred
> >
> > 		###  Regression + kriging predicted value for point ?i?
> > 		
> > 		ypred.i <- ypredlm.i + ypredok.i$var1.pred
> > 	
> > 	   	err[i] <- (ypred.i - prec2$PP03[i])^2
> > 		ypred[i] <- ypred.i		
> > 	}
> > 	err <-c(err)
> > 	ypred <-c(ypred)	
> > 	
> > 	###   mean squared error
> > 	
> > 	MSE <- sum(err)/(Nstazioni)		
> > 	MSE
> >
> > 	###   root mean square error
> >
> > 	RMSE.rk <- MSE^0.5
> > 	RMSE.rk
> >
> > Da: Moshood Agba Bakare [mailto:bakare at ualberta.ca]
> > Inviato: gioved? 15 maggio 2014 17:39
> > A: Michele Fiori
> > Cc: rubenfcasal; r-sig-geo at r-project.org
> > Oggetto: Re: [R-sig-Geo] R: Regression Kriging cross validation
> >
> > Hi Michele,
> > I have similar problem. I used ordinary kriging and inverse distance weighting method (IDW) to generate set of interpolated values from the same interpolation grid. I don't understand how cross validation can be done to come up with diagnostic statistics such as mse, rmse to use as basis for identifying the best interpolation method. I used krige.cv but I encountered error message. Please any advice on what to do please?
> >
> > ## Create grid for the interpolation through ordinary kriging and idw
> >
> > grid <- expand.grid(easting = seq(from = 299678, to = 301299, by=10),
> > northing=seq(from = 5737278, to = 5738129, by=10))
> >
> >
> > ## convert the grid to SpatialPixel class to indicate gridded spatial data
> >
> > coordinates(grid)<-~easting + northing
> > proj4string(grid)<-CRS("+proj=utm +zone=12 +ellps=WGS84 +datum=WGS84 +units=m +no_defs +towgs84=0,0,0")
> > gridded(grid)<- TRUE
> >
> > #### Ordinary kriging
> >
> > prok <- krige(id="yield",yield ~ 1, canmod.sp, newdata = grid, model=exp.mod,nmax=20,maxdist=33.0)
> >
> > ## Inverse Distance Weighting (IDW) Interpolation method
> >
> > yield.idw = idw(yield~1, canmod.sp, grid,nmax=20,maxdist=33.0,idp=1)
> >
> >
> > Thanks
> > Moshood
> >
> >
> > On Thu, May 15, 2014 at 9:23 AM, Michele Fiori <mfiori at arpa.sardegna.it> wrote:
> > Thank you for your kind reply
> > therefore as I have used the Osl method for regression, my result will never
> > match the universal kriging; However, in order to validate my method, I'm
> > trying to implement in the script a calculation loop witch runs n times (the
> > number of stations) regression + kriging without one station at a time.
> > Thank you again
> > Michele
> >
> >
> > -----Messaggio originale-----
> > Da: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-project.org]
> > Per conto di rubenfcasal
> > Inviato: marted? 29 aprile 2014 19:49
> > A: r-sig-geo at r-project.org
> > Oggetto: Re: [R-sig-Geo] Regression Kriging cross validation
> >
> > Hello Michele,
> >
> >       Universal kriging is equivalent to Linear Regression (with the
> > generalized-least-squaresestimator) + Simple Kriging of residuals (e.g.
> > Cressie, 1993, section 3.4.5). The differences you observe are probably due
> > to the use of ordinary least squares. If you use (leave-one-out)
> > cross-validation with krige.cv (considering the UK model), the trend is also
> > re-estimated at each prediction location. From my point of view, this would
> > be the recommended way to proceed.
> >       As far as I know, there are no available implementations of the
> > procedure you are suggesting.
> >
> >       Best regards,
> >           Rub?n.
> >
> >
> > El 29/04/2014 13:33, Michele Fiori escribi?:
> >> Hi everyone,
> >> I am working on rainfall interpolation using regression kriging method
> >> and I need suggestions on how I can carry out a cross validation
> >> (leave-one-out) for this elaboration. At first I tried to apply
> >> directly Krige.cv, similarly to UK method (example for october:
> >> PP10uk.cv <- krige.cv(reg, prec2, PP10.vgm)), but unfortunately when I
> >> applied Universal Kriging on the same data, I realized that UK map was a
> > little different from RK map.
> >> So my question is: How could I manage universal kriging in order to
> >> make it equivalent to regression kriging and use the above
> >> cross-validation, or is there another different method to apply cross
> >> validation (leave-one-out) on Regression Kriging interpolation?
> >> Below my code:
> >> Many thanks
> >>
> >> Michele Fiori
> >>
> >> ARPAS - Environmental Protection Agency of Sardinia MeteoClimatic
> >> Department - Meteorological Service
> >>
> >> Viale Porto Torres 119 - 07100 Sassari, Italy Tel + 39 079 258617 Fax
> >> + 39 079 262681 www.sardegnaambiente.it/arpas
> >>
> >> ####  Creating SpatialPixelDataFrame ("dem" - 250x250 m grid)
> >>        ....
> >> ####  Loading Precipitation data
> >>        prec2 <- read.table("prec2.txt", sep="\t", header =TRUE)
> >>        coordinates(prec2) <- c("x", "y")
> >>        proj4string(prec2) <- CRS("+init=epsg:32632")
> >> ####  Linear regression Model
> >>        mod.gen <- lm(PP10 ~ QUOTA_MARE + UTM_EST + UTM_NORD + DIST_MARE,
> >> prec2)
> >>        step1 <- stepAIC(mod.gen, direction="both")
> >>        reg <- formula(step1)
> >>        PP10.lm <- lm(reg, prec2)
> >>        summary(PP10.lm)
> >>        prec2$residuals <- residuals(PP10.lm)
> >>        dem$predlm <- predict(PP10.lm, dem)
> >> ####  Variogram of residuals
> >>        PP10.vgm <- vgm(nugget=51.46, model="Sph", range=38038.89,
> >> psill=86.44)
> >> ####  Ordinary Kriging of residuals
> >>        PP10.okr <- krige(PP10.lm$residuals ~ 1, prec2, dem, PP10.vgm,
> >> maxdist=Inf)
> >>        dem$varokr <- PP10.okr$var1.pred
> >> ####  Regression Kriging (Linear Regression + Ordinary Kriging of
> >> residuals)
> >>        dem$vark <- dem$predlm + dem$varokr
> >> ####  Universal kriging
> >>        PP10.uk <- krige(reg, prec2, dem, PP10.vgm, maxdist=Inf)
> >>        dem$varuk <- PP10.uk$var1.pred
> >>        dem$difference <- dem$vark - dem$varuk
> >>        spplot(dem[c("difference")], col.regions=terrain.colors(25),
> >> contour=FALSE, cuts = 15)
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at r-project.org
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> >
> >
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
 		 	   		   		 	   		  
	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Sun Sep  7 11:33:11 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 07 Sep 2014 11:33:11 +0200
Subject: [R-sig-Geo] R: individuals distribution points in paired
	polygons
In-Reply-To: <DUB126-W38FD6A70DE088531ECBE9DDDC00@phx.gbl>
References: <001101cf639e$d6cfa9f0$846efdd0$@arpa.sardegna.it>,
	<535FE602.8070605@gmail.com>,
	<002f01cf7051$a09e3b20$e1dab160$@arpa.sardegna.it>,
	<CAJRR3XMoc=vcpPqX12wshpBZnuz+O=+3rBnr3JyXVM9TSZ2hRw@mail.gmail.com>,
	<000901cf70db$8377f7e0$8a67e7a0$@arpa.sardegna.it>,
	<53760556.2060401@gmail.com>,
	<DUB126-W85ABE194AC5F7405FB7C8DDC00@phx.gbl>
	<DUB126-W38FD6A70DE088531ECBE9DDDC00@phx.gbl>
Message-ID: <540C2657.4010408@uni-muenster.de>

You are replying to a message that has nothing to do with your email,
please start a new thread when the topic is new.

The problem you sketch sounds rather trivial, but your question is hard
to answer as long as we can't see how your data is organized: that they
are in excel or in files is not enough.

Please provide a small and reproducible example in R, with an
explanation where you got stuck.

On 09/07/2014 10:31 AM, Alice C. Hughes wrote:
> I have distribution points (in excel or spatial point form) for a set ofindividuals and a file of polygons-with matching IDs: so each individual hasa set of points and a polygon with the same IDs: but there are 100's to1000's of individuals. What I would like to do is to go through and for each individual find thetotal number of points and the number which fall within the appropriatepolygon, then have the output in spreadsheet form with a column for ID;Total number of points; points in polygon. Each individual has a polygon with the same name, but every code I've seenso far can't differentiate, or scroll through multiple point files withunique IDs
> 
> Alice C. HughesAssociate ProfessorCentre for Integrative Conservation,Xishuangbanna Tropical Botanical Garden,Chinese Academy of SciencesMenglun, Mengla, Yunnan 666303, P.R. ChinaPh: 15198676559achughes at xtbg.ac.cn
> 
>> Date: Fri, 16 May 2014 14:32:22 +0200
>> From: rubenfcasal at gmail.com
>> To: mfiori at arpa.sardegna.it
>> CC: r-sig-geo at r-project.org
>> Subject: Re: [R-sig-Geo] R:  R: Regression Kriging cross validation
>>
>> Hi Michele,
>>
>> Kriging methods assume that the variogram is known, although it is not 
>> in practice. With your procedure, the whole prediction method is 
>> reproduced (adding the extra-variability due to the estimation of the 
>> variogram), so a better approximation to the variability of the 
>> prediction error should be (in principle) obtained.
>>
>> Excuse the rush...
>>
>> Ruben Fernandez-Casal
>>
>>
>> El 16/05/2014 9:50, Michele Fiori escribi?:
>>> Dear All,
>>> Finally I managed to develop this ad hoc procedure for the regression kriging cross validation; I tried to test the kriging part (the regression part has been already tested successfully) by comparison with the krige.cv function and I noticed that there are small discrepancies. I verified that they are due to the fact that in my case the variogram is recalculated for each step, while the function runs using the same initial variogram obtained on the complete set of data.
>>> What do you think about?
>>> Michele
>>>
>>> ARPAS - Environmental Protection Agency of Sardinia MeteoClimatic
>>> Department - Meteorological Service
>>>
>>> Viale Porto Torres 119 - 07100 Sassari, Italy Tel + 39 079 258617 Fax
>>> + 39 079 262681 www.sardegnaambiente.it/arpas
>>>
>>> #################### Cross validation REGRESSION KRIGING (leave on out)
>>> 					
>>> 	PP03.lm <- lm(reg, prec2)
>>> 	Nstazioni <- length(prec2$NOME_STAZ)
>>> 	for (i in 1:Nstazioni) 	
>>> 	{
>>> 		###  regression step for point ?i?
>>>
>>> 		prec2.i <- prec2[-i,] 		
>>>    		md.i <- lm(reg, data=prec2.i)
>>> 	  		ypredlm.i <- predict(md.i,prec2[i,])
>>> 	  		err[i] <- (ypredlm.i - prec2$PP03[i])^2
>>> 		res[i] <- (ypredlm.i - prec2$PP03[i])
>>>
>>> 		###  kriging step for residual point ?i?
>>>
>>> 		PP03i.rsvar <- variogram(prec2.i$residuals~1, prec2.i)
>>> 		PP03i.ivgm <- vgm(nugget=0, model="Sph", range=sqrt(diff(prec2.i at bbox["x",])^2 + diff(prec2.i at bbox["y",])^2)/4, psill=var(prec2.i$residuals))
>>> 		PP03i.rvgm <- fit.variogram(PP03i.rsvar, model=PP03i.ivgm)
>>> 		ypredok.i<- krige(md.i$residuals~1, prec2.i, prec2[i,], PP03i.rvgm)
>>> 		ypredok.i$var1.pred
>>>
>>> 		###  Regression + kriging predicted value for point ?i?
>>> 		
>>> 		ypred.i <- ypredlm.i + ypredok.i$var1.pred
>>> 	
>>> 	   	err[i] <- (ypred.i - prec2$PP03[i])^2
>>> 		ypred[i] <- ypred.i		
>>> 	}
>>> 	err <-c(err)
>>> 	ypred <-c(ypred)	
>>> 	
>>> 	###   mean squared error
>>> 	
>>> 	MSE <- sum(err)/(Nstazioni)		
>>> 	MSE
>>>
>>> 	###   root mean square error
>>>
>>> 	RMSE.rk <- MSE^0.5
>>> 	RMSE.rk
>>>
>>> Da: Moshood Agba Bakare [mailto:bakare at ualberta.ca]
>>> Inviato: gioved? 15 maggio 2014 17:39
>>> A: Michele Fiori
>>> Cc: rubenfcasal; r-sig-geo at r-project.org
>>> Oggetto: Re: [R-sig-Geo] R: Regression Kriging cross validation
>>>
>>> Hi Michele,
>>> I have similar problem. I used ordinary kriging and inverse distance weighting method (IDW) to generate set of interpolated values from the same interpolation grid. I don't understand how cross validation can be done to come up with diagnostic statistics such as mse, rmse to use as basis for identifying the best interpolation method. I used krige.cv but I encountered error message. Please any advice on what to do please?
>>>
>>> ## Create grid for the interpolation through ordinary kriging and idw
>>>
>>> grid <- expand.grid(easting = seq(from = 299678, to = 301299, by=10),
>>> northing=seq(from = 5737278, to = 5738129, by=10))
>>>
>>>
>>> ## convert the grid to SpatialPixel class to indicate gridded spatial data
>>>
>>> coordinates(grid)<-~easting + northing
>>> proj4string(grid)<-CRS("+proj=utm +zone=12 +ellps=WGS84 +datum=WGS84 +units=m +no_defs +towgs84=0,0,0")
>>> gridded(grid)<- TRUE
>>>
>>> #### Ordinary kriging
>>>
>>> prok <- krige(id="yield",yield ~ 1, canmod.sp, newdata = grid, model=exp.mod,nmax=20,maxdist=33.0)
>>>
>>> ## Inverse Distance Weighting (IDW) Interpolation method
>>>
>>> yield.idw = idw(yield~1, canmod.sp, grid,nmax=20,maxdist=33.0,idp=1)
>>>
>>>
>>> Thanks
>>> Moshood
>>>
>>>
>>> On Thu, May 15, 2014 at 9:23 AM, Michele Fiori <mfiori at arpa.sardegna.it> wrote:
>>> Thank you for your kind reply
>>> therefore as I have used the Osl method for regression, my result will never
>>> match the universal kriging; However, in order to validate my method, I'm
>>> trying to implement in the script a calculation loop witch runs n times (the
>>> number of stations) regression + kriging without one station at a time.
>>> Thank you again
>>> Michele
>>>
>>>
>>> -----Messaggio originale-----
>>> Da: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-project.org]
>>> Per conto di rubenfcasal
>>> Inviato: marted? 29 aprile 2014 19:49
>>> A: r-sig-geo at r-project.org
>>> Oggetto: Re: [R-sig-Geo] Regression Kriging cross validation
>>>
>>> Hello Michele,
>>>
>>>       Universal kriging is equivalent to Linear Regression (with the
>>> generalized-least-squaresestimator) + Simple Kriging of residuals (e.g.
>>> Cressie, 1993, section 3.4.5). The differences you observe are probably due
>>> to the use of ordinary least squares. If you use (leave-one-out)
>>> cross-validation with krige.cv (considering the UK model), the trend is also
>>> re-estimated at each prediction location. From my point of view, this would
>>> be the recommended way to proceed.
>>>       As far as I know, there are no available implementations of the
>>> procedure you are suggesting.
>>>
>>>       Best regards,
>>>           Rub?n.
>>>
>>>
>>> El 29/04/2014 13:33, Michele Fiori escribi?:
>>>> Hi everyone,
>>>> I am working on rainfall interpolation using regression kriging method
>>>> and I need suggestions on how I can carry out a cross validation
>>>> (leave-one-out) for this elaboration. At first I tried to apply
>>>> directly Krige.cv, similarly to UK method (example for october:
>>>> PP10uk.cv <- krige.cv(reg, prec2, PP10.vgm)), but unfortunately when I
>>>> applied Universal Kriging on the same data, I realized that UK map was a
>>> little different from RK map.
>>>> So my question is: How could I manage universal kriging in order to
>>>> make it equivalent to regression kriging and use the above
>>>> cross-validation, or is there another different method to apply cross
>>>> validation (leave-one-out) on Regression Kriging interpolation?
>>>> Below my code:
>>>> Many thanks
>>>>
>>>> Michele Fiori
>>>>
>>>> ARPAS - Environmental Protection Agency of Sardinia MeteoClimatic
>>>> Department - Meteorological Service
>>>>
>>>> Viale Porto Torres 119 - 07100 Sassari, Italy Tel + 39 079 258617 Fax
>>>> + 39 079 262681 www.sardegnaambiente.it/arpas
>>>>
>>>> ####  Creating SpatialPixelDataFrame ("dem" - 250x250 m grid)
>>>>        ....
>>>> ####  Loading Precipitation data
>>>>        prec2 <- read.table("prec2.txt", sep="\t", header =TRUE)
>>>>        coordinates(prec2) <- c("x", "y")
>>>>        proj4string(prec2) <- CRS("+init=epsg:32632")
>>>> ####  Linear regression Model
>>>>        mod.gen <- lm(PP10 ~ QUOTA_MARE + UTM_EST + UTM_NORD + DIST_MARE,
>>>> prec2)
>>>>        step1 <- stepAIC(mod.gen, direction="both")
>>>>        reg <- formula(step1)
>>>>        PP10.lm <- lm(reg, prec2)
>>>>        summary(PP10.lm)
>>>>        prec2$residuals <- residuals(PP10.lm)
>>>>        dem$predlm <- predict(PP10.lm, dem)
>>>> ####  Variogram of residuals
>>>>        PP10.vgm <- vgm(nugget=51.46, model="Sph", range=38038.89,
>>>> psill=86.44)
>>>> ####  Ordinary Kriging of residuals
>>>>        PP10.okr <- krige(PP10.lm$residuals ~ 1, prec2, dem, PP10.vgm,
>>>> maxdist=Inf)
>>>>        dem$varokr <- PP10.okr$var1.pred
>>>> ####  Regression Kriging (Linear Regression + Ordinary Kriging of
>>>> residuals)
>>>>        dem$vark <- dem$predlm + dem$varokr
>>>> ####  Universal kriging
>>>>        PP10.uk <- krige(reg, prec2, dem, PP10.vgm, maxdist=Inf)
>>>>        dem$varuk <- PP10.uk$var1.pred
>>>>        dem$difference <- dem$vark - dem$varuk
>>>>        spplot(dem[c("difference")], col.regions=terrain.colors(25),
>>>> contour=FALSE, cuts = 15)
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>  		 	   		   		 	   		  
> 	[[alternative HTML version deleted]]
> 
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140907/0ed93722/attachment.bin>

From b.rowlingson at lancaster.ac.uk  Sun Sep  7 11:57:58 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sun, 7 Sep 2014 10:57:58 +0100
Subject: [R-sig-Geo] R: individuals distribution points in paired
	polygons
In-Reply-To: <fc39e3f8a79d41e7b1c926ceecb135ee@EX-1-HT0.lancs.local>
References: <001101cf639e$d6cfa9f0$846efdd0$@arpa.sardegna.it>
	<535FE602.8070605@gmail.com>
	<002f01cf7051$a09e3b20$e1dab160$@arpa.sardegna.it>
	<CAJRR3XMoc=vcpPqX12wshpBZnuz+O=+3rBnr3JyXVM9TSZ2hRw@mail.gmail.com>
	<000901cf70db$8377f7e0$8a67e7a0$@arpa.sardegna.it>
	<53760556.2060401@gmail.com>
	<DUB126-W85ABE194AC5F7405FB7C8DDC00@phx.gbl>
	<fc39e3f8a79d41e7b1c926ceecb135ee@EX-1-HT0.lancs.local>
Message-ID: <CANVKczMi+QuCtC+d+3jpsXa7=nx7X3932-cDaBnA9wDKYiftgg@mail.gmail.com>

On Sun, Sep 7, 2014 at 9:31 AM, Alice C. Hughes
<dr_achughes at hotmail.co.uk> wrote:
> I have distribution points (in excel or spatial point form) for a set ofindividuals and a file of polygons-with matching IDs: so each individual hasa set of points and a polygon with the same IDs:

 Sounds like you have a dataset of  Person_ID, Polygon_ID pairs - two columns...

>but there are 100's to1000's of individuals.

 and 100 or a 1000 rows for each individual times however many
observations for each individual. Not exactly Big Data...

> What I would like to do is to go through and for each individual find thetotal number of points and the number which fall within the appropriatepolygon

Assuming your data are in a dataframe called "distribution", then
that's trivially:

 table(distribution$Person_ID)

and

 table(distribution$Person_ID, distribution$PolygonID)

> then have the output in spreadsheet form with a column for ID;Total number of points; points in polygon. Each individual has a polygon with the same name, but every code I've seenso far can't differentiate, or scroll through multiple point files withunique IDs

 Now here's where we get lost. Multiple "point files" wth unique IDs?
What are "point files"? Where did they come from? You need to clearly
state the structure of your data, what you've read into R, and give
some summaries of it.

Barry


From dr_achughes at hotmail.co.uk  Sun Sep  7 13:16:21 2014
From: dr_achughes at hotmail.co.uk (Alice C. Hughes)
Date: Sun, 7 Sep 2014 12:16:21 +0100
Subject: [R-sig-Geo] R: individuals distribution points in paired
 polygons
In-Reply-To: <CANVKczMi+QuCtC+d+3jpsXa7=nx7X3932-cDaBnA9wDKYiftgg@mail.gmail.com>
References: <001101cf639e$d6cfa9f0$846efdd0$@arpa.sardegna.it>,
	<535FE602.8070605@gmail.com>,
	<002f01cf7051$a09e3b20$e1dab160$@arpa.sardegna.it>,
	<CAJRR3XMoc=vcpPqX12wshpBZnuz+O=+3rBnr3JyXVM9TSZ2hRw@mail.gmail.com>,
	<000901cf70db$8377f7e0$8a67e7a0$@arpa.sardegna.it>,
	<53760556.2060401@gmail.com>,
	<DUB126-W85ABE194AC5F7405FB7C8DDC00@phx.gbl>,
	<fc39e3f8a79d41e7b1c926ceecb135ee@EX-1-HT0.lancs.local>,
	<CANVKczMi+QuCtC+d+3jpsXa7=nx7X3932-cDaBnA9wDKYiftgg@mail.gmail.com>
Message-ID: <DUB126-W14D354EBF0AA1CCDA81D64DDC00@phx.gbl>

Hi Barry
Thanks. The distribution data for each individual is in an excel sheet with the individuals ID, and the lat and long it was recorded. There is one to several hundred distribution locality (point) records for each individual. I also have a polygon (from another source) for each of those individuals-and I want to know how many of the distribution points for each individual fall into the appropriate polygons.
Though the distribution data is in excel-each record refers to a point, and I have a point (i.e. GIS version of each-both for all the individuals together, and is folder with each separated: which could also be used).What I would envisage is a script that reads through the polygon names, to get the list of individuals, and then goes through the list finding how many of the records of each one fall within that individuals polygon
Thanks so much
Alice

Alice C. HughesAssociate ProfessorCentre for Integrative Conservation,Xishuangbanna Tropical Botanical Garden,Chinese Academy of SciencesMenglun, Mengla, Yunnan 666303, P.R. ChinaPh: 15198676559achughes at xtbg.ac.cn

> Date: Sun, 7 Sep 2014 10:57:58 +0100
> Subject: Re: [R-sig-Geo] R: individuals distribution points in paired polygons
> From: b.rowlingson at lancaster.ac.uk
> To: dr_achughes at hotmail.co.uk
> CC: rubenfcasal at gmail.com; mfiori at arpa.sardegna.it; r-sig-geo at r-project.org
> 
> On Sun, Sep 7, 2014 at 9:31 AM, Alice C. Hughes
> <dr_achughes at hotmail.co.uk> wrote:
> > I have distribution points (in excel or spatial point form) for a set ofindividuals and a file of polygons-with matching IDs: so each individual hasa set of points and a polygon with the same IDs:
> 
>  Sounds like you have a dataset of  Person_ID, Polygon_ID pairs - two columns...
> 
> >but there are 100's to1000's of individuals.
> 
>  and 100 or a 1000 rows for each individual times however many
> observations for each individual. Not exactly Big Data...
> 
> > What I would like to do is to go through and for each individual find thetotal number of points and the number which fall within the appropriatepolygon
> 
> Assuming your data are in a dataframe called "distribution", then
> that's trivially:
> 
>  table(distribution$Person_ID)
> 
> and
> 
>  table(distribution$Person_ID, distribution$PolygonID)
> 
> > then have the output in spreadsheet form with a column for ID;Total number of points; points in polygon. Each individual has a polygon with the same name, but every code I've seenso far can't differentiate, or scroll through multiple point files withunique IDs
> 
>  Now here's where we get lost. Multiple "point files" wth unique IDs?
> What are "point files"? Where did they come from? You need to clearly
> state the structure of your data, what you've read into R, and give
> some summaries of it.
> 
> Barry
 		 	   		  
	[[alternative HTML version deleted]]


From darunabas at gmail.com  Sun Sep  7 17:58:27 2014
From: darunabas at gmail.com (Barnabas Daru)
Date: Sun, 7 Sep 2014 17:58:27 +0200
Subject: [R-sig-Geo] Automate the extraction of climate variable at
	different time depths from netcdf in r
In-Reply-To: <CANtt_hzyrcRhqgYtAnkwT+waY03vD6N5w2PKjjPyFsEpXwBWLQ@mail.gmail.com>
References: <CA+R607EimFZvQXjmjp0B1KSQgmaXz6=n8zZsCJ+AS4Ccsix+_g@mail.gmail.com>
	<CANtt_hzyrcRhqgYtAnkwT+waY03vD6N5w2PKjjPyFsEpXwBWLQ@mail.gmail.com>
Message-ID: <DBB31DC6-0AAE-4258-8E23-2B7B66650F76@gmail.com>

Hi Robert,
Thanks very much for your suggestion.
I tried the code you provided and it work! Many thanks.
However, it tends to extract the SST values for all the points and for time periods including even the years that I don't desire. This means I will have to delete one-by-one, the values for the years that I do not desire and keep only the ones I want.
I thought there is a way I could simply ask R to print in one column, the extracted values associated with only the years for which point data is available.
Thanks and kind regards
Barnabas



  \-/
   /\
  /--|    
 /---/ Barnabas Daru
 |--/  PhD Candidate,
 \-/   African Centre for DNA Barcoding,
 /\    University of Johannesburg,
/--\   PO Box 524, Auckland Park, 2006,
|---\  Johannesburg, South Africa.
 \---\ Lab: +27 11 559 3477        
  \--| Mobile: +277 3818 9583
   \-/ Website: www.barnabasdaru.com
   /\        
  /--\ 
 
#?if you can think it, you can do it.
 




On Sep 7, 2014, at 5:23 AM, Robert J. Hijmans wrote:

> Barnabas, ,
> You can try something like this:
> 
> b <- brick("~sst.mnmean.nc", varname="sst")
> # loop over species, or combine all species into one data.frame?
> mydata <- read.csv("~Species one.csv")
> extract.mydata <- extract(b, mydata[,5:6])
> write.csv(extract.mydata, file = "Species_one_extracted.csv")
> 
> Robert


	[[alternative HTML version deleted]]


From nessnjor at gmail.com  Sun Sep  7 18:57:19 2014
From: nessnjor at gmail.com (Kristin)
Date: Sun, 7 Sep 2014 09:57:19 -0700 (PDT)
Subject: [R-sig-Geo] Automate the extraction of climate variable at
 different time depths from netcdf in r
In-Reply-To: <CANtt_hzyrcRhqgYtAnkwT+waY03vD6N5w2PKjjPyFsEpXwBWLQ@mail.gmail.com>
References: <CA+R607EimFZvQXjmjp0B1KSQgmaXz6=n8zZsCJ+AS4Ccsix+_g@mail.gmail.com>
	<CANtt_hzyrcRhqgYtAnkwT+waY03vD6N5w2PKjjPyFsEpXwBWLQ@mail.gmail.com>
Message-ID: <1410109039367-7587080.post@n2.nabble.com>

Hello
I?m having similar problem, do not seem to find obvious solution on the net.  

I have a raster brick of 464 layers, each layer representing time defined as
number from 1 to 464. 
The number is stored here: 
rasterbrick at z$days

and has values from 1 to 464

Then I have 2800 space time locations of field data sampling. These are both
irregular sampling locations and some irregular sampling dates at same
sampling locations. Dates are also defined as numbers from 1 to 464. Each
individual point is then identified by lat and lon at different times.
This is what my dataframe looks like: 

Lat, Lon, days
64   -21    23
63   -19    52
63   -19    53
66   -25    23 
.... 

So what I want to do is to extract values from the raster brick at a certain
location, but only where the date numbers from both the raster brick and the
locations match, but not for all times for all locations as the extract from
raster brick does. 

atb, 
Kristin
 



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Automate-the-extraction-of-climate-variable-at-different-time-depths-from-netcdf-in-r-tp7587070p7587080.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From kridox at ymail.com  Mon Sep  8 03:16:35 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Mon, 8 Sep 2014 10:16:35 +0900
Subject: [R-sig-Geo] Automate the extraction of climate variable at
 different time depths from netcdf in r
In-Reply-To: <1410109039367-7587080.post@n2.nabble.com>
References: <CA+R607EimFZvQXjmjp0B1KSQgmaXz6=n8zZsCJ+AS4Ccsix+_g@mail.gmail.com>
	<CANtt_hzyrcRhqgYtAnkwT+waY03vD6N5w2PKjjPyFsEpXwBWLQ@mail.gmail.com>
	<1410109039367-7587080.post@n2.nabble.com>
Message-ID: <CAAcyNCxgQped87qi+nUa2+_FuMxwRp0t7Je1J8BcnNZOuPkKYQ@mail.gmail.com>

Hi Kristin,

Please start a new thread for your own question, thank you.

Regards,
Pascal

On Mon, Sep 8, 2014 at 1:57 AM, Kristin <nessnjor at gmail.com> wrote:
> Hello
> I?m having similar problem, do not seem to find obvious solution on the net.
>
> I have a raster brick of 464 layers, each layer representing time defined as
> number from 1 to 464.
> The number is stored here:
> rasterbrick at z$days
>
> and has values from 1 to 464
>
> Then I have 2800 space time locations of field data sampling. These are both
> irregular sampling locations and some irregular sampling dates at same
> sampling locations. Dates are also defined as numbers from 1 to 464. Each
> individual point is then identified by lat and lon at different times.
> This is what my dataframe looks like:
>
> Lat, Lon, days
> 64   -21    23
> 63   -19    52
> 63   -19    53
> 66   -25    23
> ....
>
> So what I want to do is to extract values from the raster brick at a certain
> location, but only where the date numbers from both the raster brick and the
> locations match, but not for all times for all locations as the extract from
> raster brick does.
>
> atb,
> Kristin
>
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Automate-the-extraction-of-climate-variable-at-different-time-depths-from-netcdf-in-r-tp7587070p7587080.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From nessnjor at gmail.com  Mon Sep  8 10:55:10 2014
From: nessnjor at gmail.com (Kristin)
Date: Mon, 8 Sep 2014 01:55:10 -0700 (PDT)
Subject: [R-sig-Geo] Extract points from raster brick by both location and a
 matching attributes.
Message-ID: <1410166510788-7587083.post@n2.nabble.com>

Hi

I have a raster brick of 464 layers, each layer representing time defined as
number from 1 to 464.
The numbers are stored here:
rasterbrick at z$days

and have values from 1 to 464

Then I have 2800 space time locations of field data sampling. These are both
irregular sampling locations and some irregular sampling dates at same
sampling locations. Dates are also defined as numbers from 1 to 464. Each
individual point is then identified by lat and lon at different times.
This is what my dataframe looks like:

Lat, Lon, days
64   -21    23
63   -19    52
63   -19    53
66   -25    23
....

So what I want to do is to extract values from the raster brick at a certain
location, but only where the date numbers from both the raster brick and the
locations match, but not for all times for all locations as the extract from
raster brick does.

And if it helps, then below is the structure of my raster brick: 
> str (rasterbrick)
Formal class 'RasterBrick' [package "raster"] with 12 slots
  ..@ file    :Formal class '.RasterFile' [package "raster"] with 13 slots
  .. .. ..@ name        : chr "C:\\Gudrun\\DINEOF_NIALL\\R\\chl.nc"
  .. .. ..@ datanotation: chr "FLT4S"
  .. .. ..@ byteorder   : chr "little"
  .. .. ..@ nodatavalue : num -9999
  .. .. ..@ NAchanged   : logi FALSE
  .. .. ..@ nbands      : int 464
  .. .. ..@ bandorder   : chr "BIL"
  .. .. ..@ offset      : int 0
  .. .. ..@ toptobottom : logi TRUE
  .. .. ..@ blockrows   : int 0
  .. .. ..@ blockcols   : int 0
  .. .. ..@ driver      : chr "netcdf"
  .. .. ..@ open        : logi FALSE
  ..@ data    :Formal class '.MultipleRasterData' [package "raster"] with 14
slots
  .. .. ..@ values    : logi[0 , 0 ] 
  .. .. ..@ offset    : num 0
  .. .. ..@ gain      : num 1
  .. .. ..@ inmemory  : logi FALSE
  .. .. ..@ fromdisk  : logi TRUE
  .. .. ..@ nlayers   : int 464
  .. .. ..@ dropped   : NULL
  .. .. ..@ isfactor  : logi FALSE
  .. .. ..@ attributes: list()
  .. .. ..@ haveminmax: logi FALSE
  .. .. ..@ min       : num [1:464] Inf Inf Inf Inf Inf ...
  .. .. ..@ max       : num [1:464] -Inf -Inf -Inf -Inf -Inf ...
  .. .. ..@ unit      : chr "units"
  .. .. ..@ names     : chr [1:464] "X341" "X41" "X169" "X281" ...
  ..@ legend  :Formal class '.RasterLegend' [package "raster"] with 5 slots
  .. .. ..@ type      : chr(0) 
  .. .. ..@ values    : logi(0) 
  .. .. ..@ color     : logi(0) 
  .. .. ..@ names     : logi(0) 
  .. .. ..@ colortable: logi(0) 
  ..@ title   : chr "var3d"
  ..@ extent  :Formal class 'Extent' [package "raster"] with 4 slots
  .. .. ..@ xmin: num -30
  .. .. ..@ xmax: num -8.01
  .. .. ..@ ymin: num 60
  .. .. ..@ ymax: num 68
  ..@ rotated : logi FALSE
  ..@ rotation:Formal class '.Rotation' [package "raster"] with 2 slots
  .. .. ..@ geotrans: num(0) 
  .. .. ..@ transfun:function ()  
  ..@ ncols   : int 440
  ..@ nrows   : int 160
  ..@ crs     :Formal class 'CRS' [package "sp"] with 1 slots
  .. .. ..@ projargs: chr "+proj=longlat +datum=WGS84"
  ..@ history : list()
  ..@ z       :List of 1
  .. ..$ days: int [1:464(1d)] 341 41 169 281 409 69 197 309 437 101 ...

atb,
Kristin



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Extract-points-from-raster-brick-by-both-location-and-a-matching-attributes-tp7587083.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From rubenfcasal at gmail.com  Mon Sep  8 12:23:23 2014
From: rubenfcasal at gmail.com (rubenfcasal)
Date: Mon, 08 Sep 2014 12:23:23 +0200
Subject: [R-sig-Geo] Automate the extraction of climate variable at
 different time depths from netcdf in r
In-Reply-To: <CA+R607EimFZvQXjmjp0B1KSQgmaXz6=n8zZsCJ+AS4Ccsix+_g@mail.gmail.com>
References: <CA+R607EimFZvQXjmjp0B1KSQgmaXz6=n8zZsCJ+AS4Ccsix+_g@mail.gmail.com>
Message-ID: <540D839B.6060303@gmail.com>

Hello,

     I use the attached script to extract climate data from the OISST 
sea surface temperature netCDF "sst.wkmean.1990-present.nc". This script 
is a slight modification of one written by Luke Miller (downloaded from 
his web page http://lukemiller.org, some years ago...  ) to convert the 
data to sp/spacetime classes (easily to handle, subset,...).

     I just realised that Luke Miller has updated the original script. 
See: 
http://lukemiller.org/index.php/2014/01/noaa-oisst-v2-high-resolution-daily-sea-surface-temperatures-with-r/

     I hope it helps...

     Best Regards, Ruben FC


El 06/09/2014 19:10, Barnabas Daru escribi?:
> Dear all,
> I write to seek help with extracting climate data at various times and
> depth from NETCDF in R.
> The climate data is sea surface temperature monthly means from 1854 to
> 2014.
> My goal is to automate the extraction of SST climate data for a set of
> points with different time depths.
>
> I have successfully used the 'brick' function in the raster package to get
> climate data at various time depths as follows:
>
> b <- brick("~sst.mnmean.nc", varname="sst")
>
> mydate <- b[["X1869.09.01"]] # SST for September in 1869
>
> mydata <- read.csv("~Species one.csv")
>
> mydataSPDF <- SpatialPointsDataFrame(mydata[,5:6],data.frame(mydata))
>
> extract.mydata <- extract(mydate, mydataSPDF, sp=TRUE)
>
> extract.mydata <- data.frame(extract.mydata)
>
> write.csv(extract.mydata, file = "Species_one_extracted.csv")
>
> My major challenge is that I have to keep extracting manually for each time
> depth, then copy and paste in the main dataframe and the data has about
> 3000 observations, meaning I have to keep copying and pasting ~3000 times
> for one species!
> Is there a way I can iterate the process in R to loop through each month's
> climate and extract the data for each point and time depth rather than to
> do it manually?
>
> Here's how my data frame looks like:
>    Date year month day lon lat SST  1855-01-01 1855 1 1 11.6861 57.7254
> 3.440000057  1859-07-26 1859 7 26 25.46122 60.26766 13.25  1860-01-01 1860 1
> 1 10.9154 53.9484 15.10999966  1861-07-10 1861 7 10 7.79588 58.08673
> 15.71000004  1861-07-26 1861 7 26 -2.84072 54.0778  1861-08-17 1861 8 17
> 11.9792 57.51298  1862-01-01 1862 1 1 22.20467 60.27955  1862-08-05 1862 8 5
> 11.78316 57.61649  1862-08-23 1862 8 23 11.9792 57.51298  1863-08-26 1863 8
> 26 10.72237 59.97258  1863-08-28 1863 8 28 15.53721 56.20091  1863-09-22
> 1863 9 22 16.37849 56.84255  1864-07-05 1864 7 5 -4.07097 51.09542
> 1864-07-18 1864 7 18 -4.21368 51.0928  1864-08-26 1864 8 26 -4.07097
> 51.09542  1865-09-07 1865 9 7 10.76144 59.91271  1865-09-27 1865 9 27
> 10.53107 60.43395  1867-08-28 1867 8 28 12.82669 55.86822  1868-01-01 1868 1
> 1 12.8944 56.6897  1868-01-01 1868 1 1 4.82685 53.13793
> Thanks and kind regards
> Barnabas Daru
>

-------------- next part --------------
# Filename: NOAA_OISST_extraction.R
# 
# Author: Luke Miller   Mar 1, 2011
# http://lukemiller.org/
# Modified by: Ruben Fernandez-Casal Ap 20, 2012 (sp, spacetime classes)
###############################################################################
# library(sp)
library(spacetime)
library(ncdf)  # NetCDF (Network Common Data Form) http://www.unidata.ucar.edu/software/netcdf/

# For info on the NOAA Optimum Interpolated Sea Surface Temperature V2 (OISST):
# http://www.esrl.noaa.gov/psd/data/gridded/data.noaa.oisst.v2.html

# This script works on the OISST sea surface temperature netCDF file called 
# sst.wkmean.1990-present.nc, which must be downloaded into the current 
# working directory (file size is >135MB currently)

# The OISST grid layout is 1 degree latitudes from 89.5 to -89.5 degrees north.
# The longitude grid is 1 degree bins, 0.5 to 359.5 degrees east.
# The SST values are given in degrees Celsius.
# Time values are "days since 1800-1-1 00:00", starting from 69395
# Time delta_t is 0000-00-07 00:00, indices range from 0 to 1103 currently
# The time values in the sst field give the 1st day of the week for each 
# weekly temperature value (though the data are meant to be centered on 
# Wednesday of that week), starting at 69395 = 12/31/1989.
# Use as.Date(69395,origin = '1800-1-1') to convert the netCDF day value to a 
# human readable form. 

lats = seq(89.5,-89.5,-1) #generate set of grid cell latitudes (center of cell)
lons = seq(0.5,359.5,1) #generate set of grid cell longitudes (center of cell)

##Ask user to enter the boundaries of the search area
#cat("Enter longitude of western edge of search area (degrees east 0 to 359)\n")
#lon1 = scan(what = numeric(0),n = 1)
#cat("Enter longitude of eastern edge of search area (degrees east 0 to 359)\n")
#lon2 = scan(what = numeric(0),n = 1)
#cat("Enter latitude of northern edge\n")
#cat("of search area (degrees north, 89.5 to -89.5\n")
#lat1 = scan(what = numeric(0),n = 1)
#cat("Enter latitude of southern edge\n")
#cat("of search area (degrees north, 89.5 to -89.5\n")
#lat2 = scan(what = numeric(0),n = 1)

lon1 = 0
lon2 = 360
lat1 = 90
lat2 = -90

#lon1 = -11 + 360
#lon2 = -7 + 360
#lat1 = 45
#lat2 = 40

lon1a = which.min(abs(lon1 - lons)) #get index of nearest longitude value
lon2a = which.min(abs(lon2 - lons)) #get index of nearest longitude value
lat1a = which.min(abs(lat1 - lats)) #get index of nearest latitude value
lat2a = which.min(abs(lat2 - lats)) #get index of nearest latitude value
#The lon/lat 1a/2a values should now correspond to indices in the netCDF file
#for the desired grid cell. 
nlon = (lon2a - lon1a) + 1 #get number of longitudes to extract
nlat = (lat2a - lat1a) + 1 #get number of latitudes to extract

##Ask the user to enter the dates of interest
#cat("Enter the starting date in the form: 1990-1-31\n")
#date1 = scan(what = character(0),n = 1)
#cat("Enter the ending date in the form: 1990-1-31\n")
#date2 = scan(what = character(0),n = 1)

date1 = '2012-04-15'  # date1 = '2012-02-05'
date2 = '2012-04-15'

date1 = as.Date(date1, format = "%Y-%m-%d") #convert to Date object
date2 = as.Date(date2, format = "%Y-%m-%d") #convert to Date object

#Open the netCDF file for reading. 
nc = open.ncdf("sst.wkmean.1990-present.nc")
#print.ncdf(nc) will show info about the structure of the netCDF file

#Extract available dates from netCDF file
ncdates = nc$dim$time$vals
ncdates = as.Date(ncdates,origin = '1800-1-1') #available time points in nc

date1a = which.min(abs(date1 - ncdates)) #get index of nearest time point
date2a = which.min(abs(date2 - ncdates)) #get index of nearest time point
ndates = (date2a - date1a) + 1 #get number of time steps to extract

#Extract the data from the netCDF file to a matrix or array called 'sstout'. 
sstout = get.var.ncdf(nc, varid = 'sst', start = c(lon1a,lat1a,date1a),
		count = c(nlon,nlat,ndates))
#If you only retrieve one time point, sstout will be a 2D matrix with 
#longitudes running down the rows, and latitudes across the columns. 
#For example, Column 1, sstout[1:nrow(sstout),1], will contain sst values for 
#each of the longitude values at the northern-most latitude in your search 
#area, with the first row, sstout[1,1], being the western-most longitude, and 
#the last row being the eastern edge of your search area.
#If you retrieve multiple time points, sstout will be a 3D array, where time is
#the 3rd dimension. Lat/lon will be arranged the same as the 2D case. 

#The vector 'datesout' will hold the Date values associated with each set of 
#sst values in the sstout array, should you need to access them.
datesout = ncdates[date1a:date2a]

###############################################################################
###############################################################################
# The NOAA OISST files contain sea surface temperatures for the entire globe,
# including on the continents. This clearly isn't right, so they also supply a
# land-sea mask file in netCDF format at the website listed at the start of 
# this script. 
# We use the values (0 or 1) stored in the mask file to turn all of the 
# continent areas into NA's. 

nc2 = open.ncdf('lsmask.nc') #open land-sea mask
mask = get.var.ncdf(nc2, varid = "mask",start = c(lon1a,lat1a,1),
		count = c(nlon,nlat,1)) #get land-sea mask values (0 or 1)

mask = ifelse(mask == 0,NA,1) #replace 0's with NA's

goodlons = lons[lon1a:lon2a]
goodlats = lats[lat1a:lat2a]
index <- goodlons > 191 # Atlantic "view"
# index <- FALSE for Pacific "view"
goodlons[index] <- goodlons[index] - 360

llCRS <- CRS("+proj=longlat +ellps=WGS84")
cellcentre <- c(min(goodlons),min(goodlats))
cellsize <- c(1,1)
sstout.grid <- GridTopology( cellcentre.offset=cellcentre, cellsize=cellsize, cells.dim=c(length(goodlons),length(goodlats)))

jet.colors <- colorRampPalette(c("#00007F", "blue", "#007FFF", "cyan", "#7FFF7F", "yellow", "#FF7F00", "red", "#7F0000"))

if (is.matrix(sstout)) { 
#if there is only 1 time point (2D matrix) -> sp::SpatialGridDataFrame
	sstout = sstout * mask #all masked values become NA	
  sstdf <- data.frame(sst=as.numeric(rbind(sstout[index,],sstout[!index,])))
  attr(sstdf,"label") <- datesout
  sstsp <-  SpatialGridDataFrame(sstout.grid, sstdf, proj4string=llCRS)
  # save(sstsp,file="sstsp.rda")
  image(sstsp, col=jet.colors(128), axes=TRUE)
  title(attr(sstsp at data,"label"))
  # Importar datos de paquetes
  #  library(maps)
  #  library(maptools)
  #  world <- map("world", fill=TRUE, plot = FALSE)   # Hay un mapa con mayor resoluci?n en mapdata::worldHires
  #  world_pol <- map2SpatialPolygons(world, world$names, CRS("+proj=longlat +ellps=WGS84"))
  #  plot(world_pol, col='white', add=TRUE)
} else {
#if ssout is a 3D matrix  -> spacetime::STFDF
	dims = dim(sstout)
	sstdf <- c()
	for (i in 1:dims[3]){
		sstout[,,i] = sstout[,,i] * mask #all masked values become NA
		sstdf <- cbind(sstdf, as.numeric(rbind(sstout[index,,i],sstout[!index,,i])))
	}
  stfdf <- STFDF(SpatialGrid(sstout.grid, proj4string=llCRS), as.POSIXct(datesout), 
                data.frame(sst=as.vector(sstdf)))
  # save(stfdf,file="sstst.rda")
  library(lattice)
  stplot(stfdf[,c(1,2,dims[3]-1,dims[3])],col.regions=jet.colors(128))

}

From ftonini84 at gmail.com  Mon Sep  8 16:36:38 2014
From: ftonini84 at gmail.com (Francesco Tonini)
Date: Mon, 08 Sep 2014 10:36:38 -0400
Subject: [R-sig-Geo] Space-time GWR in R
Message-ID: <540DBEF6.1010001@gmail.com>

Dear all,

Are you aware of any R package implementing space-time GWR?

Thank you,
Francesco


From rodaromero at gmail.com  Tue Sep  9 04:32:50 2014
From: rodaromero at gmail.com (David Romero)
Date: Mon, 8 Sep 2014 21:32:50 -0500
Subject: [R-sig-Geo] Anselin Local Moran's I with R
Message-ID: <CAJx8RnGpB+t2Lwqx7npGAXH5sb0igctttuWqwkQrXX3iYk3AQQ@mail.gmail.com>

Hello,

Could somebody help me with the method to compute the Cluster and Outlier
Analysis using spdep and obtain Local I Index, Z-scores and cluster type
like with the Arcgis tool.
My data are points with temperature value.

Thank you,

David Romero
phD student
Instituto de Geograf?a
UNAM

	[[alternative HTML version deleted]]


From mathieu.rajerison at gmail.com  Tue Sep  9 14:31:54 2014
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Tue, 9 Sep 2014 14:31:54 +0200
Subject: [R-sig-Geo] Anselin Local Moran's I with R
In-Reply-To: <CAJx8RnGpB+t2Lwqx7npGAXH5sb0igctttuWqwkQrXX3iYk3AQQ@mail.gmail.com>
References: <CAJx8RnGpB+t2Lwqx7npGAXH5sb0igctttuWqwkQrXX3iYk3AQQ@mail.gmail.com>
Message-ID: <CAGfc75k3_J6gXz4_-aeO_HwgMKqo1La6E5wOOsr7QO0n6Q4s+g@mail.gmail.com>

Hello,

See a loot at spdep, especially localmoran function
http://www.inside-r.org/packages/cran/spdep/docs/localmoran

Best,

Mathieu

2014-09-09 4:32 GMT+02:00 David Romero <rodaromero at gmail.com>:

> Hello,
>
> Could somebody help me with the method to compute the Cluster and Outlier
> Analysis using spdep and obtain Local I Index, Z-scores and cluster type
> like with the Arcgis tool.
> My data are points with temperature value.
>
> Thank you,
>
> David Romero
> phD student
> Instituto de Geograf?a
> UNAM
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Tue Sep  9 15:24:11 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 9 Sep 2014 15:24:11 +0200
Subject: [R-sig-Geo] Anselin Local Moran's I with R
In-Reply-To: <CAJx8RnGpB+t2Lwqx7npGAXH5sb0igctttuWqwkQrXX3iYk3AQQ@mail.gmail.com>
References: <CAJx8RnGpB+t2Lwqx7npGAXH5sb0igctttuWqwkQrXX3iYk3AQQ@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1409091435370.29346@reclus.nhh.no>

On Tue, 9 Sep 2014, David Romero wrote:

> Hello,
>
> Could somebody help me with the method to compute the Cluster and Outlier
> Analysis using spdep and obtain Local I Index, Z-scores and cluster type
> like with the Arcgis tool.

Preferably not. The Arcgis tool answers lots of the wrong questions 
wrongly. If you take multiple comparisons seriously - see ?p.adjust - and 
treat permutations of all values except i to permutation bootstrap with 
reserve (use localmoran.sad() or localmoran.exact() instead), you'll 
realise that the z-scores are deceptive, and the "cluster" types (HH/LL, 
LH/HL) wrongheaded if you colour only "significant" ones - they are only 
significant in most cases before correcting for multiple comparisons. 
Further, if the mean model is mis-specified (yi - \bar{y} uses \bar{y} 
alone as the mean model), there may well not be any autocorrelation 
anyway, just omitted spatially patterned covariates.

> My data are points with temperature value.

In your case temperature should surely be related to elevation, and very 
likely to urban density before trying to measure local residual 
autocorrelation. Just because they do this in Arcgis, it doesn't mean that 
it is an appropriate procedure.

Hope this clarifies,

Roger

>
> Thank you,
>
> David Romero
> phD student
> Instituto de Geograf?a
> UNAM
>
> 	[[alternative HTML version deleted]]

PS. Please only post plain text, HTML is bulkier and can carry harmful 
payloads.


>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From rodaromero at gmail.com  Tue Sep  9 18:50:06 2014
From: rodaromero at gmail.com (David Romero)
Date: Tue, 9 Sep 2014 11:50:06 -0500
Subject: [R-sig-Geo] Anselin Local Moran's I with R
In-Reply-To: <alpine.LRH.2.03.1409091435370.29346@reclus.nhh.no>
References: <CAJx8RnGpB+t2Lwqx7npGAXH5sb0igctttuWqwkQrXX3iYk3AQQ@mail.gmail.com>
	<alpine.LRH.2.03.1409091435370.29346@reclus.nhh.no>
Message-ID: <CAJx8RnFXPZ=BJHMExXWx0HHs1fu1_zNPGoa3XGHA3osDjKUUUQ@mail.gmail.com>

Hello Roger,

Thank you for aclarations. Obviously, climatic data are dependent of
elevation. I wished to calculate local Moran as an exploratory method
to identifie outliers before computing semivariograms. Could you
suggest a better method?

Thank you,

David

2014-09-09 8:24 GMT-05:00 Roger Bivand <Roger.Bivand at nhh.no>:
> On Tue, 9 Sep 2014, David Romero wrote:
>
>> Hello,
>>
>> Could somebody help me with the method to compute the Cluster and Outlier
>> Analysis using spdep and obtain Local I Index, Z-scores and cluster type
>> like with the Arcgis tool.
>
>
> Preferably not. The Arcgis tool answers lots of the wrong questions wrongly.
> If you take multiple comparisons seriously - see ?p.adjust - and treat
> permutations of all values except i to permutation bootstrap with reserve
> (use localmoran.sad() or localmoran.exact() instead), you'll realise that
> the z-scores are deceptive, and the "cluster" types (HH/LL, LH/HL)
> wrongheaded if you colour only "significant" ones - they are only
> significant in most cases before correcting for multiple comparisons.
> Further, if the mean model is mis-specified (yi - \bar{y} uses \bar{y} alone
> as the mean model), there may well not be any autocorrelation anyway, just
> omitted spatially patterned covariates.
>
>> My data are points with temperature value.
>
>
> In your case temperature should surely be related to elevation, and very
> likely to urban density before trying to measure local residual
> autocorrelation. Just because they do this in Arcgis, it doesn't mean that
> it is an appropriate procedure.
>
> Hope this clarifies,
>
> Roger
>
>>
>> Thank you,
>>
>> David Romero
>> phD student
>> Instituto de Geograf?a
>> UNAM
>>
>>         [[alternative HTML version deleted]]
>
>
> PS. Please only post plain text, HTML is bulkier and can carry harmful
> payloads.
>
>
>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no


From trichter at uni-bremen.de  Wed Sep 10 13:23:50 2014
From: trichter at uni-bremen.de (Tim Richter-Heitmann)
Date: Wed, 10 Sep 2014 13:23:50 +0200
Subject: [R-sig-Geo] Distance binning within variograms
In-Reply-To: <mailman.19.1410343205.14620.r-sig-geo@r-project.org>
References: <mailman.19.1410343205.14620.r-sig-geo@r-project.org>
Message-ID: <541034C6.2050606@uni-bremen.de>

Hi there!

First thank you very much for answering my last question in such a 
depth. As suggested, i am proceeding with variograms, and i have now to 
decide how to bin my data.

First, my data is organised like this:

http://s1.postimg.org/bkjgdavvj/image.png

10m x 10m, subdivided in 30 plots, which are sampled twice in close 
proximity, making it 60 samples per grid.
The distances of my 60*59/2 point pairs within the grid are like this:

summary(dist(aug.dis))
    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
   0.500   3.307   5.035   5.126   6.872  11.920


Here is the histogram, classified by 50cm lags:

http://s28.postimg.org/49iqyz8jh/Hist_aug.jpg

For binning the distances, I have read that "As a guide, Isaacs and 
Srivastava* suggest that if the samples are located on a pseudoregular 
grid, the grid spacing is usually a good lag size. If the sampling is 
random (as in this case), the average distance between neighboring 
samples can be used as an initial lag size." 
(http://webhelp.esri.com/arcgisdesktop/9.3/tutorials/geostat/Geostat_3_2.htm).

Now, if i go with the basic variogram in sdpep with everything on default:

variogram(mydata[,1]~1, mydata]

  np     dist       gamma dir.hor dir.ver   id
1   31 0.500000 0.001113978       0       0 var1
2   10 0.769093 0.000617368       0       0 var1
3   18 1.128502 0.001945660       0       0 var1
4   27 1.281212 0.002560873       0       0 var1
5   50 1.601944 0.002974914       0       0 var1
6   51 1.940722 0.001848663       0       0 var1
7   54 2.236781 0.002047786       0       0 var1
8   63 2.540425 0.002047856       0       0 var1
9   54 2.830686 0.002353565       0       0 var1
10  78 3.088837 0.002293626       0       0 var1
11 101 3.425051 0.002118441       0       0 var1
12  60 3.708046 0.002641097       0       0 var1
13  83 4.008823 0.001944181       0       0 var1
14  38 4.266185 0.002779340       0       0 var1



I am getting 14 bins, being separated my about 20-35 cms, so it seems 
that the absolute lag size was not used, correct? So, i wonder how above 
statement fits into the picture here.

For the actual modell fitting i am using "autofitVariogram" of the 
package automap, and hereby i may choose the binning for myself, but by 
the number of minimum points per bin.
Thing is, i dont get the same binning size as with sdpep, raising the 
question, what actually makes sense for my data.
Example:
autofitVariogram(mydata[,1]~1, mydata, model=c("Exp", "Sph"),
                          GLS.model=TRUE,
                          miscFitOptions=list(merge.small.bins=TRUE, 
min.np.bin=1),
                          cutoff=8, width=1,
                          verbose=TRUE)

Even with the non-conservative setting min.np.bin ( ~ minimum necessary 
points to form a bin) of 1, i am getting:

np      dist        gamma dir.hor dir.ver   id
1  31 0.5000000 0.0010506776       0       0 var1
2   2 0.6800000 0.0001693078       0       0 var1
3  19 0.9544668 0.0005623298       0       0 var1
4  44 1.3611090 0.0012611147       0       0 var1
5 133 1.9898870 0.0010649182       0       0 var1
6 134 2.7270631 0.0011212414       0       0 var1
7 153 3.4178791 0.0008814734       0       0 var1
8 240 4.2357844 0.0011453654       0       0 var1


Which has much less resolution as the sdpep binning, especially at 
greater distances. If i am going too high for the nin.np.bin, i even 
miss the second distance  (in both cases a severe drop in variance for 
the second row), making this question
even more crucial. I really dont want to mess up, so please if you have 
any advise, let me know. Here are example variograms from the data above.

*with automap, min.np.bin**=10*
http://s10.postimg.org/6kxj37i6x/Bin_10.jpg

*with automap, min.np.bin=20*
http://s10.postimg.org/f1x1e4mvt/bin20.jpg

*with spdep, plot(variogram)**, default options*
http://s10.postimg.org/gsg2fm4ex/sdpep.jpg

You see, different conclusions could be drawn (in the 2nd picture, a 
trend to a spatial model could be observed).

I also wondering: The way to judge if my data follows a non-random 
spatial process is visually. Is there any numerical parameter of the 
variogram that back ups my visual judgment, like with Moran or Geary?

Thank you very much!

Tim

	[[alternative HTML version deleted]]


From jwm302 at gmail.com  Wed Sep 10 16:42:18 2014
From: jwm302 at gmail.com (Justin Michell)
Date: Wed, 10 Sep 2014 16:42:18 +0200
Subject: [R-sig-Geo] Construct prediction grid that has a value for each
	corresponding predictor raster grid cell
Message-ID: <12EBC68A-F29F-489C-9C6B-1C4E099C7E53@gmail.com>

I have aligned raster layers as follows:

> NDVI1
class       : RasterLayer 
dimensions  : 1287, 1321, 1700127  (nrow, ncol, ncell)
resolution  : 0.008333333, 0.008333333  (x, y)
extent      : 29.425, 40.43333, -11.725, -1  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 
data source : in memory
names       : layer.1.1.1 
values      : -0.1524615, 0.9153615  (min, max)

> rain1
class       : RasterLayer 
dimensions  : 1287, 1321, 1700127  (nrow, ncol, ncell)
resolution  : 0.008333333, 0.008333333  (x, y)
extent      : 29.425, 40.43333, -11.725, -1  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 
data source : in memory
names       : layer.1.1.1 
values      : 7, 391  (min, max)


I have used spBayes::spGLM to get spatial estimates for a logit model (based on predictors including NDVI and rainfall). 

I now wish to construct a prediction grid so that I can produce a continuous map of my predicted response based on draws from the predictive posterior distribution (using output from spBayes::spPredict). 

What is the best strategy? Should I extend the range of prediction grid to be rectangular (and then recreate raster layers not cropped to my country of interest so that the grid has complete data). Perhaps by using raster::drawExtent() I can ?draw? a rectangle over my domain and use those bounds as input for prediction grid.

I was initially thinking of just creating a grid at the same 1x1km resolution as climate layers like so:

grid <- raster(nrows=nrow(NDVI1), ncols=ncol(NDVI1), 
            xmn=bbox(NDVI1)[1], xmx=bbox(NDVI1)[3], 
            ymn=bbox(NDVI1)[2], ymx=bbox(NDVI1)[4])


Thanks and Regards
Justin Michell

From Roger.Bivand at nhh.no  Wed Sep 10 18:40:38 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 10 Sep 2014 18:40:38 +0200
Subject: [R-sig-Geo] Anselin Local Moran's I with R
In-Reply-To: <CAJx8RnFXPZ=BJHMExXWx0HHs1fu1_zNPGoa3XGHA3osDjKUUUQ@mail.gmail.com>
References: <CAJx8RnGpB+t2Lwqx7npGAXH5sb0igctttuWqwkQrXX3iYk3AQQ@mail.gmail.com>
	<alpine.LRH.2.03.1409091435370.29346@reclus.nhh.no>
	<CAJx8RnFXPZ=BJHMExXWx0HHs1fu1_zNPGoa3XGHA3osDjKUUUQ@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1409101834410.4767@reclus.nhh.no>

On Tue, 9 Sep 2014, David Romero wrote:

> Hello Roger,
>
> Thank you for aclarations. Obviously, climatic data are dependent of
> elevation. I wished to calculate local Moran as an exploratory method
> to identifie outliers before computing semivariograms. Could you
> suggest a better method?

Why would local Moran's I indicate outliers - do you mean very large L/H 
or H/L values, in which neighbouring observations are very dissimilar? I 
assume your data are from weather stations, so point support, rather than 
remotely sensed. Shouldn't a map of residuals from fitting a mean model 
(including relevant covariates and/or trend) with carefully chosen class 
intervals be sufficient? If you need contrasts between proximate 
neighbours, maybe just plot the variable of interest against its spatial 
lag, and choose those stations with big differences.

Hope this helps,

Roger

>
> Thank you,
>
> David
>
> 2014-09-09 8:24 GMT-05:00 Roger Bivand <Roger.Bivand at nhh.no>:
>> On Tue, 9 Sep 2014, David Romero wrote:
>>
>>> Hello,
>>>
>>> Could somebody help me with the method to compute the Cluster and Outlier
>>> Analysis using spdep and obtain Local I Index, Z-scores and cluster type
>>> like with the Arcgis tool.
>>
>>
>> Preferably not. The Arcgis tool answers lots of the wrong questions wrongly.
>> If you take multiple comparisons seriously - see ?p.adjust - and treat
>> permutations of all values except i to permutation bootstrap with reserve
>> (use localmoran.sad() or localmoran.exact() instead), you'll realise that
>> the z-scores are deceptive, and the "cluster" types (HH/LL, LH/HL)
>> wrongheaded if you colour only "significant" ones - they are only
>> significant in most cases before correcting for multiple comparisons.
>> Further, if the mean model is mis-specified (yi - \bar{y} uses \bar{y} alone
>> as the mean model), there may well not be any autocorrelation anyway, just
>> omitted spatially patterned covariates.
>>
>>> My data are points with temperature value.
>>
>>
>> In your case temperature should surely be related to elevation, and very
>> likely to urban density before trying to measure local residual
>> autocorrelation. Just because they do this in Arcgis, it doesn't mean that
>> it is an appropriate procedure.
>>
>> Hope this clarifies,
>>
>> Roger
>>
>>>
>>> Thank you,
>>>
>>> David Romero
>>> phD student
>>> Instituto de Geograf?a
>>> UNAM
>>>
>>>         [[alternative HTML version deleted]]
>>
>>
>> PS. Please only post plain text, HTML is bulkier and can carry harmful
>> payloads.
>>
>>
>>
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From frank.davenport at gmail.com  Thu Sep 11 00:22:45 2014
From: frank.davenport at gmail.com (Frank Davenport)
Date: Wed, 10 Sep 2014 15:22:45 -0700
Subject: [R-sig-Geo] raster::extract fails on brick but works on
 individual layers of brick
In-Reply-To: <CANtt_hy-khm2yBHpuYd+o97=5FVuJprUM94MNQY+H=-Kra2zjQ@mail.gmail.com>
References: <CAEVpnsEKcbasN=UThFCbdYusvk3EuJ1XV9iEYxGXZv9o1A6jNQ@mail.gmail.com>	<CALuVVaanebwpnUqpbSMPEu5_vHwrS_eEXJHKby8HodgAykYF3g@mail.gmail.com>	<53D2B2A1.6080402@gmail.com>
	<CANtt_hy-khm2yBHpuYd+o97=5FVuJprUM94MNQY+H=-Kra2zjQ@mail.gmail.com>
Message-ID: <5410CF35.2050405@gmail.com>

Hi Robert-

I was unable to install the development version, however I did update to 
raster- 2.3-0 and the issue appears to be resolved. I can run 
extract(..,..,mean) with or without weights and get values each time, 
without having to use dissagregate first.

However I noticed now that the 'weights' colunm sums to one. This what I 
would like from a weights column however this is not the how weights 
behaved in the past, as per this discussion:

https://stackoverflow.com/questions/17766989/extract-data-from-raster-with-small-polygons-rounded-weights-too-small


My new question: Has the weights function fundamentally changed or is it 
different only when the polygons are significantly smaller than the 
raster cells? Or put another way, if I re-run old code that uses 
weights=T, should I expect different answers?

Thanks again for the great package!

Frank

Here is my code and session info:

 > library(raster)
Loading required package: sp
Warning message:
package ?raster? was built under R version 3.1.1
 > #install.packages("raster", repos="http://R-Forge.R-project.org")
 >
 > load('~/Dropbox/Public/99_raster_bugreport.Rdata') 
#https://dl.dropboxusercontent.com/u/9577903/99_raster_bugreport.Rdata
 > test1<-extract(g,dsd,fun=mean,na.rm=T,weights=T) #No Error
 > test2<-extract(g,dsd,fun=mean,na.rm=T,weights=F) #No Error
 >
 > test3<-extract(g,dsd,weights=T) #just get the weights
 >
 > test3[[1]][,'weight'] #the weights column sums to 1
[1] 0.6 0.4

 >
 > sessionInfo()
R version 3.1.0 (2014-04-10)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base

other attached packages:
[1] raster_2.3-0 sp_1.0-15

loaded via a namespace (and not attached):
[1] grid_3.1.0      lattice_0.20-29 tools_3.1.0
On 9/2/14 9:41 AM, Robert J. Hijmans wrote:
> Frank,
> I hope this issue has been solved in the development version.
> install.packages("raster", repos="http://R-Forge.R-project.org")
> I would appreciate feedback.
> Best, Robert
>
> On Fri, Jul 25, 2014 at 12:40 PM, Frank Davenport
> <frank.davenport at gmail.com> wrote:
>> Sorry for the mutliple postings but I found another solution using
>> raster::disaggregate(). Essentially the same as resample but prerserves all
>> the cell values. The fundamental issue was the small size of the polygons
>> compared to the cells (which can be problematic when using weights()).
>>
>> See the discussion here:
>> https://stackoverflow.com/questions/17766989/extract-data-from-raster-with-small-polygons-rounded-weights-too-small
>>
>>
>> g2<-raster::disaggregate(g,10)
>> test1<-extract(g2,dsd,fun=mean,na.rm=T,weights=T,small=T)
>>
>> On 7/23/14 10:07 AM, Lyndon Estes wrote:
>>> Hi Frank,
>>>
>>> I think the mean function is getting in the way, since if you want to
>>> extra the values for all cells each polygon overlaps, the outputs will
>>> first end up in a list.
>>>
>>> test1 <- extract(g, dsd, weights = TRUE, small = TRUE)
>>>
>>> Will get the cell values for each polygon from each layer in the
>>> brick, along with their weight (while allowing very small polygons to
>>> get their underlying cell values).
>>>
>>> I would then process the mean function on the list.
>>>
>>> v <- t(sapply(test1, function(x) apply(t(sapply(1:nrow(x), function(y)
>>> x[y, 1:10] * x[y, 11])), 2, sum)))  # matrix of annual values per
>>> polygon
>>>
>>> Hope this helps.
>>>
>>> Cheers, Lyndon
>>>
>>>
>>> On Wed, Jul 23, 2014 at 12:17 PM, Frank Davenport
>>> <frank.davenport at gmail.com> wrote:
>>>> Hello,
>>>>
>>>> I am using extract() to aggregate values from a raster to a polygon. The
>>>> raster is a brick object. Extract fails on the brick object but succeeds
>>>> when applied on each individual layer of the brick (via a for() loop). I
>>>> would use this as a work around but in my actual scenario the brick is
>>>> much
>>>> bigger and the individual approach is too slow.
>>>>
>>>> The specific error message is: "Error in t(sapply(res, meanfunc)) :
>>>> error
>>>> in evaluating the argument 'x' in selecting a method for function 't':
>>>> Error in apply(x, 1, function(X) { : dim(X) must have a positive length"
>>>>
>>>> I believe this has something to do with the relative sizes of the
>>>> polygons
>>>> (small) and the grid cells. I have successfully extracted this brick to
>>>> another shapefile that had much larger polygons. Likewise I can also do
>>>> the
>>>> extraction if I resample the cells to a smaller resolution (not shown
>>>> below).
>>>>
>>>>
>>>> Finally the extract will work if I set 'na.rm=F' but then produces mostly
>>>> NA's, even though there are no NAs in the brick. I realize this might be
>>>> something to do with the dataType(). However that does not explain why
>>>> extract works on individual layers, but not the whole brick.
>>>>
>>>> Reproducible code is below and prettier example can be found here:
>>>> http://rpubs.com/frank_davenport/22698
>>>>
>>>> The data necessary to run the example can be found here:
>>>> https://dl.dropboxusercontent.com/u/9577903/99_raster_bugreport.Rdata
>>>>
>>>> Thank you for your help and apologies if a solution is already posted.
>>>>
>>>> Frank
>>>>
>>>>> rm(list=ls())
>>>>> library(raster)
>>>> Loading required package: sp
>>>>> ##-Download data from here:
>>>> https://dl.dropboxusercontent.com/u/9577903/99_raster_bugreport.Rdata
>>>>> ##contains 'dsd' a spatial polygons data.frame and 'g' a raster brick
>>>> with 10 layers
>>>>> load('~/Dropbox/Public/99_raster_bugreport.Rdata')
>>>>>
>>>>> dsd
>>>> class       : SpatialPolygonsDataFrame
>>>> features    : 36
>>>> extent      : 34.04665, 39.70319, -4.67742, 1.19921  (xmin, xmax, ymin,
>>>> ymax)
>>>> coord. ref. : +proj=longlat +a=6378249.145 +b=6356514.96582849 +no_defs
>>>> variables   : 4
>>>> names       : Province, District,         Division, uidu
>>>> min values  :  CENTRAL,  BUNGOMA, ABOTHUGUCHI WEST,    1
>>>> max values  :  WESTERN,   VIHIGA,            WINAM,   44
>>>>> g
>>>> class       : RasterBrick
>>>> dimensions  : 24, 20, 480, 10  (nrow, ncol, ncell, nlayers)
>>>> resolution  : 0.5, 0.5  (x, y)
>>>> extent      : 33, 43, -6, 6  (xmin, xmax, ymin, ymax)
>>>> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
>>>> data source : in memory
>>>> names       : X1999.03.01, X1999.03.02, X1999.03.03, X1999.03.04,
>>>> X1999.03.05, X1999.03.06, X1999.03.07, X1999.03.08, X1999.03.09,
>>>> X1999.03.10
>>>> min values  :    22.47562,    22.44415,    22.25507,    22.23166,
>>>> 22.12387,    22.42477,    22.27802,    22.15134,    22.36218,    22.33447
>>>> max values  :    41.47818,    40.53116,    41.54944,    42.33093,
>>>> 41.67810,    40.79260,    41.83319,    40.83359,    41.12604,    42.00555
>>>>
>>>>> #---Show the data
>>>>> plot(g[[1]])
>>>>> plot(dsd,add=T)
>>>>>
>>>>> #--Try to extract, with weights yeilds an error
>>>>> test1<-extract(g,dsd,fun=mean,na.rm=T,weights=T)
>>>> Error in t(sapply(res, meanfunc)) :
>>>>     error in evaluating the argument 'x' in selecting a method for
>>>> function
>>>> 't': Error in apply(x, 1, function(X) { : dim(X) must have a positive
>>>> length
>>>>> #--Extract without weights--produces NA's for most polygons
>>>>> test2<-extract(g,dsd,fun=mean,na.m=T)
>>>>> head(test2)
>>>>        X1999.03.01 X1999.03.02 X1999.03.03 X1999.03.04 X1999.03.05
>>>> X1999.03.06 X1999.03.07 X1999.03.08 X1999.03.09 X1999.03.10
>>>> [1,]          NA          NA          NA          NA          NA
>>>> NA          NA          NA          NA          NA
>>>> [2,]          NA          NA          NA          NA          NA
>>>> NA          NA          NA          NA          NA
>>>> [3,]          NA          NA          NA          NA          NA
>>>> NA          NA          NA          NA          NA
>>>> [4,]          NA          NA          NA          NA          NA
>>>> NA          NA          NA          NA          NA
>>>> [5,]          NA          NA          NA          NA          NA
>>>> NA          NA          NA          NA          NA
>>>> [6,]          NA          NA          NA          NA          NA
>>>> NA          NA          NA          NA          NA
>>>>> summary(test2)
>>>>     X1999.03.01     X1999.03.02     X1999.03.03     X1999.03.04
>>>> X1999.03.05     X1999.03.06     X1999.03.07     X1999.03.08
>>>>    Min.   :24.47   Min.   :25.21   Min.   :24.67   Min.   :25.47   Min.
>>>> :27.42   Min.   :25.38   Min.   :25.93   Min.   :24.11
>>>>    1st Qu.:29.29   1st Qu.:30.99   1st Qu.:29.55   1st Qu.:30.83   1st
>>>> Qu.:31.58   1st Qu.:29.78   1st Qu.:29.51   1st Qu.:28.35
>>>>    Median :30.31   Median :33.63   Median :31.13   Median :31.88   Median
>>>> :33.32   Median :30.31   Median :30.52   Median :29.71
>>>>    Mean   :29.87   Mean   :32.75   Mean   :30.41   Mean   :31.78   Mean
>>>> :32.61   Mean   :29.71   Mean   :29.90   Mean   :29.19
>>>>    3rd Qu.:31.86   3rd Qu.:36.08   3rd Qu.:32.59   3rd Qu.:34.37   3rd
>>>> Qu.:34.73   3rd Qu.:30.60   3rd Qu.:31.32   3rd Qu.:30.82
>>>>    Max.   :32.81   Max.   :37.00   Max.   :33.45   Max.   :35.77   Max.
>>>> :35.42   Max.   :31.98   Max.   :31.69   Max.   :32.53
>>>>    NA's   :30      NA's   :30      NA's   :30      NA's   :30      NA's
>>>> :30      NA's   :30      NA's   :30      NA's   :30
>>>>     X1999.03.09     X1999.03.10
>>>>    Min.   :25.98   Min.   :25.53
>>>>    1st Qu.:29.53   1st Qu.:30.73
>>>>    Median :30.57   Median :31.06
>>>>    Mean   :30.12   Mean   :31.24
>>>>    3rd Qu.:31.41   3rd Qu.:33.52
>>>>    Max.   :32.75   Max.   :34.83
>>>>    NA's   :30      NA's   :30
>>>>> #--Extract each layer seperatley--works but is SLOW
>>>>> glist<-vector(mode='list',length=nlayers(g))
>>>>>
>>>>> for(i in 1:length(glist)){
>>>> +   glist[[i]]<-extract(g[[i]],dsd,fun=mean,na.rm=T,weigths=T)
>>>> + }
>>>>> sessionInfo()
>>>> R version 3.1.0 (2014-04-10)
>>>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>>>>
>>>> locale:
>>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>> other attached packages:
>>>> [1] raster_2.2-31 sp_1.0-15
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] grid_3.1.0      lattice_0.20-29 tools_3.1.0
>>>>           [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> --
>> Frank Davenport, Ph.D
>> Climate Hazards Group
>> UCSB Geography
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Frank Davenport Ph.D
Climate Hazards Group
UCSB Geography


From r.hijmans at gmail.com  Thu Sep 11 18:04:57 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 11 Sep 2014 09:04:57 -0700
Subject: [R-sig-Geo] raster::extract fails on brick but works on
 individual layers of brick
In-Reply-To: <5410CF35.2050405@gmail.com>
References: <CAEVpnsEKcbasN=UThFCbdYusvk3EuJ1XV9iEYxGXZv9o1A6jNQ@mail.gmail.com>
	<CALuVVaanebwpnUqpbSMPEu5_vHwrS_eEXJHKby8HodgAykYF3g@mail.gmail.com>
	<53D2B2A1.6080402@gmail.com>
	<CANtt_hy-khm2yBHpuYd+o97=5FVuJprUM94MNQY+H=-Kra2zjQ@mail.gmail.com>
	<5410CF35.2050405@gmail.com>
Message-ID: <CANtt_hyz4JSDpMYr=n1cpOHsaEbxD1MR1SP-B+dngjRz2Jn5PA@mail.gmail.com>

Frank,
Thanks for your feedback. I indeed added some code to get the weights
adding up to 1 in more (all) cases. The difference is proportional and
the results should otherwise be the same.
Robert

On Wed, Sep 10, 2014 at 3:22 PM, Frank Davenport
<frank.davenport at gmail.com> wrote:
> Hi Robert-
>
> I was unable to install the development version, however I did update to
> raster- 2.3-0 and the issue appears to be resolved. I can run
> extract(..,..,mean) with or without weights and get values each time,
> without having to use dissagregate first.
>
> However I noticed now that the 'weights' colunm sums to one. This what I
> would like from a weights column however this is not the how weights behaved
> in the past, as per this discussion:
>
> https://stackoverflow.com/questions/17766989/extract-data-from-raster-with-small-polygons-rounded-weights-too-small
>
>
> My new question: Has the weights function fundamentally changed or is it
> different only when the polygons are significantly smaller than the raster
> cells? Or put another way, if I re-run old code that uses weights=T, should
> I expect different answers?
>
> Thanks again for the great package!
>
> Frank
>
> Here is my code and session info:
>
>> library(raster)
> Loading required package: sp
> Warning message:
> package ?raster? was built under R version 3.1.1
>> #install.packages("raster", repos="http://R-Forge.R-project.org")
>>
>> load('~/Dropbox/Public/99_raster_bugreport.Rdata')
>> #https://dl.dropboxusercontent.com/u/9577903/99_raster_bugreport.Rdata
>> test1<-extract(g,dsd,fun=mean,na.rm=T,weights=T) #No Error
>> test2<-extract(g,dsd,fun=mean,na.rm=T,weights=F) #No Error
>>
>> test3<-extract(g,dsd,weights=T) #just get the weights
>>
>> test3[[1]][,'weight'] #the weights column sums to 1
> [1] 0.6 0.4
>
>>
>> sessionInfo()
> R version 3.1.0 (2014-04-10)
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
> other attached packages:
> [1] raster_2.3-0 sp_1.0-15
>
> loaded via a namespace (and not attached):
> [1] grid_3.1.0      lattice_0.20-29 tools_3.1.0
> On 9/2/14 9:41 AM, Robert J. Hijmans wrote:
>>
>> Frank,
>> I hope this issue has been solved in the development version.
>> install.packages("raster", repos="http://R-Forge.R-project.org")
>> I would appreciate feedback.
>> Best, Robert
>>
>> On Fri, Jul 25, 2014 at 12:40 PM, Frank Davenport
>> <frank.davenport at gmail.com> wrote:
>>>
>>> Sorry for the mutliple postings but I found another solution using
>>> raster::disaggregate(). Essentially the same as resample but prerserves
>>> all
>>> the cell values. The fundamental issue was the small size of the polygons
>>> compared to the cells (which can be problematic when using weights()).
>>>
>>> See the discussion here:
>>>
>>> https://stackoverflow.com/questions/17766989/extract-data-from-raster-with-small-polygons-rounded-weights-too-small
>>>
>>>
>>> g2<-raster::disaggregate(g,10)
>>> test1<-extract(g2,dsd,fun=mean,na.rm=T,weights=T,small=T)
>>>
>>> On 7/23/14 10:07 AM, Lyndon Estes wrote:
>>>>
>>>> Hi Frank,
>>>>
>>>> I think the mean function is getting in the way, since if you want to
>>>> extra the values for all cells each polygon overlaps, the outputs will
>>>> first end up in a list.
>>>>
>>>> test1 <- extract(g, dsd, weights = TRUE, small = TRUE)
>>>>
>>>> Will get the cell values for each polygon from each layer in the
>>>> brick, along with their weight (while allowing very small polygons to
>>>> get their underlying cell values).
>>>>
>>>> I would then process the mean function on the list.
>>>>
>>>> v <- t(sapply(test1, function(x) apply(t(sapply(1:nrow(x), function(y)
>>>> x[y, 1:10] * x[y, 11])), 2, sum)))  # matrix of annual values per
>>>> polygon
>>>>
>>>> Hope this helps.
>>>>
>>>> Cheers, Lyndon
>>>>
>>>>
>>>> On Wed, Jul 23, 2014 at 12:17 PM, Frank Davenport
>>>> <frank.davenport at gmail.com> wrote:
>>>>>
>>>>> Hello,
>>>>>
>>>>> I am using extract() to aggregate values from a raster to a polygon.
>>>>> The
>>>>> raster is a brick object. Extract fails on the brick object but
>>>>> succeeds
>>>>> when applied on each individual layer of the brick (via a for() loop).
>>>>> I
>>>>> would use this as a work around but in my actual scenario the brick is
>>>>> much
>>>>> bigger and the individual approach is too slow.
>>>>>
>>>>> The specific error message is: "Error in t(sapply(res, meanfunc)) :
>>>>> error
>>>>> in evaluating the argument 'x' in selecting a method for function 't':
>>>>> Error in apply(x, 1, function(X) { : dim(X) must have a positive
>>>>> length"
>>>>>
>>>>> I believe this has something to do with the relative sizes of the
>>>>> polygons
>>>>> (small) and the grid cells. I have successfully extracted this brick to
>>>>> another shapefile that had much larger polygons. Likewise I can also do
>>>>> the
>>>>> extraction if I resample the cells to a smaller resolution (not shown
>>>>> below).
>>>>>
>>>>>
>>>>> Finally the extract will work if I set 'na.rm=F' but then produces
>>>>> mostly
>>>>> NA's, even though there are no NAs in the brick. I realize this might
>>>>> be
>>>>> something to do with the dataType(). However that does not explain why
>>>>> extract works on individual layers, but not the whole brick.
>>>>>
>>>>> Reproducible code is below and prettier example can be found here:
>>>>> http://rpubs.com/frank_davenport/22698
>>>>>
>>>>> The data necessary to run the example can be found here:
>>>>> https://dl.dropboxusercontent.com/u/9577903/99_raster_bugreport.Rdata
>>>>>
>>>>> Thank you for your help and apologies if a solution is already posted.
>>>>>
>>>>> Frank
>>>>>
>>>>>> rm(list=ls())
>>>>>> library(raster)
>>>>>
>>>>> Loading required package: sp
>>>>>>
>>>>>> ##-Download data from here:
>>>>>
>>>>> https://dl.dropboxusercontent.com/u/9577903/99_raster_bugreport.Rdata
>>>>>>
>>>>>> ##contains 'dsd' a spatial polygons data.frame and 'g' a raster brick
>>>>>
>>>>> with 10 layers
>>>>>>
>>>>>> load('~/Dropbox/Public/99_raster_bugreport.Rdata')
>>>>>>
>>>>>> dsd
>>>>>
>>>>> class       : SpatialPolygonsDataFrame
>>>>> features    : 36
>>>>> extent      : 34.04665, 39.70319, -4.67742, 1.19921  (xmin, xmax, ymin,
>>>>> ymax)
>>>>> coord. ref. : +proj=longlat +a=6378249.145 +b=6356514.96582849 +no_defs
>>>>> variables   : 4
>>>>> names       : Province, District,         Division, uidu
>>>>> min values  :  CENTRAL,  BUNGOMA, ABOTHUGUCHI WEST,    1
>>>>> max values  :  WESTERN,   VIHIGA,            WINAM,   44
>>>>>>
>>>>>> g
>>>>>
>>>>> class       : RasterBrick
>>>>> dimensions  : 24, 20, 480, 10  (nrow, ncol, ncell, nlayers)
>>>>> resolution  : 0.5, 0.5  (x, y)
>>>>> extent      : 33, 43, -6, 6  (xmin, xmax, ymin, ymax)
>>>>> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
>>>>> data source : in memory
>>>>> names       : X1999.03.01, X1999.03.02, X1999.03.03, X1999.03.04,
>>>>> X1999.03.05, X1999.03.06, X1999.03.07, X1999.03.08, X1999.03.09,
>>>>> X1999.03.10
>>>>> min values  :    22.47562,    22.44415,    22.25507,    22.23166,
>>>>> 22.12387,    22.42477,    22.27802,    22.15134,    22.36218,
>>>>> 22.33447
>>>>> max values  :    41.47818,    40.53116,    41.54944,    42.33093,
>>>>> 41.67810,    40.79260,    41.83319,    40.83359,    41.12604,
>>>>> 42.00555
>>>>>
>>>>>> #---Show the data
>>>>>> plot(g[[1]])
>>>>>> plot(dsd,add=T)
>>>>>>
>>>>>> #--Try to extract, with weights yeilds an error
>>>>>> test1<-extract(g,dsd,fun=mean,na.rm=T,weights=T)
>>>>>
>>>>> Error in t(sapply(res, meanfunc)) :
>>>>>     error in evaluating the argument 'x' in selecting a method for
>>>>> function
>>>>> 't': Error in apply(x, 1, function(X) { : dim(X) must have a positive
>>>>> length
>>>>>>
>>>>>> #--Extract without weights--produces NA's for most polygons
>>>>>> test2<-extract(g,dsd,fun=mean,na.m=T)
>>>>>> head(test2)
>>>>>
>>>>>        X1999.03.01 X1999.03.02 X1999.03.03 X1999.03.04 X1999.03.05
>>>>> X1999.03.06 X1999.03.07 X1999.03.08 X1999.03.09 X1999.03.10
>>>>> [1,]          NA          NA          NA          NA          NA
>>>>> NA          NA          NA          NA          NA
>>>>> [2,]          NA          NA          NA          NA          NA
>>>>> NA          NA          NA          NA          NA
>>>>> [3,]          NA          NA          NA          NA          NA
>>>>> NA          NA          NA          NA          NA
>>>>> [4,]          NA          NA          NA          NA          NA
>>>>> NA          NA          NA          NA          NA
>>>>> [5,]          NA          NA          NA          NA          NA
>>>>> NA          NA          NA          NA          NA
>>>>> [6,]          NA          NA          NA          NA          NA
>>>>> NA          NA          NA          NA          NA
>>>>>>
>>>>>> summary(test2)
>>>>>
>>>>>     X1999.03.01     X1999.03.02     X1999.03.03     X1999.03.04
>>>>> X1999.03.05     X1999.03.06     X1999.03.07     X1999.03.08
>>>>>    Min.   :24.47   Min.   :25.21   Min.   :24.67   Min.   :25.47   Min.
>>>>> :27.42   Min.   :25.38   Min.   :25.93   Min.   :24.11
>>>>>    1st Qu.:29.29   1st Qu.:30.99   1st Qu.:29.55   1st Qu.:30.83   1st
>>>>> Qu.:31.58   1st Qu.:29.78   1st Qu.:29.51   1st Qu.:28.35
>>>>>    Median :30.31   Median :33.63   Median :31.13   Median :31.88
>>>>> Median
>>>>> :33.32   Median :30.31   Median :30.52   Median :29.71
>>>>>    Mean   :29.87   Mean   :32.75   Mean   :30.41   Mean   :31.78   Mean
>>>>> :32.61   Mean   :29.71   Mean   :29.90   Mean   :29.19
>>>>>    3rd Qu.:31.86   3rd Qu.:36.08   3rd Qu.:32.59   3rd Qu.:34.37   3rd
>>>>> Qu.:34.73   3rd Qu.:30.60   3rd Qu.:31.32   3rd Qu.:30.82
>>>>>    Max.   :32.81   Max.   :37.00   Max.   :33.45   Max.   :35.77   Max.
>>>>> :35.42   Max.   :31.98   Max.   :31.69   Max.   :32.53
>>>>>    NA's   :30      NA's   :30      NA's   :30      NA's   :30      NA's
>>>>> :30      NA's   :30      NA's   :30      NA's   :30
>>>>>     X1999.03.09     X1999.03.10
>>>>>    Min.   :25.98   Min.   :25.53
>>>>>    1st Qu.:29.53   1st Qu.:30.73
>>>>>    Median :30.57   Median :31.06
>>>>>    Mean   :30.12   Mean   :31.24
>>>>>    3rd Qu.:31.41   3rd Qu.:33.52
>>>>>    Max.   :32.75   Max.   :34.83
>>>>>    NA's   :30      NA's   :30
>>>>>>
>>>>>> #--Extract each layer seperatley--works but is SLOW
>>>>>> glist<-vector(mode='list',length=nlayers(g))
>>>>>>
>>>>>> for(i in 1:length(glist)){
>>>>>
>>>>> +   glist[[i]]<-extract(g[[i]],dsd,fun=mean,na.rm=T,weigths=T)
>>>>> + }
>>>>>>
>>>>>> sessionInfo()
>>>>>
>>>>> R version 3.1.0 (2014-04-10)
>>>>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>>>>>
>>>>> locale:
>>>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>>>
>>>>> attached base packages:
>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>
>>>>> other attached packages:
>>>>> [1] raster_2.2-31 sp_1.0-15
>>>>>
>>>>> loaded via a namespace (and not attached):
>>>>> [1] grid_3.1.0      lattice_0.20-29 tools_3.1.0
>>>>>           [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at r-project.org
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>> --
>>> Frank Davenport, Ph.D
>>> Climate Hazards Group
>>> UCSB Geography
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> --
> Frank Davenport Ph.D
> Climate Hazards Group
> UCSB Geography
>


From r.hijmans at gmail.com  Thu Sep 11 18:06:29 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 11 Sep 2014 09:06:29 -0700
Subject: [R-sig-Geo] Construct prediction grid that has a value for each
 corresponding predictor raster grid cell
In-Reply-To: <12EBC68A-F29F-489C-9C6B-1C4E099C7E53@gmail.com>
References: <12EBC68A-F29F-489C-9C6B-1C4E099C7E53@gmail.com>
Message-ID: <CANtt_hx5ROCZKWMhD4wmfmSumh==GuxTmXk+im2p7Ch6SNFX=Q@mail.gmail.com>

Justin,

See  ?raster::predict

Robert

On Wed, Sep 10, 2014 at 7:42 AM, Justin Michell <jwm302 at gmail.com> wrote:
> I have aligned raster layers as follows:
>
>> NDVI1
> class       : RasterLayer
> dimensions  : 1287, 1321, 1700127  (nrow, ncol, ncell)
> resolution  : 0.008333333, 0.008333333  (x, y)
> extent      : 29.425, 40.43333, -11.725, -1  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
> data source : in memory
> names       : layer.1.1.1
> values      : -0.1524615, 0.9153615  (min, max)
>
>> rain1
> class       : RasterLayer
> dimensions  : 1287, 1321, 1700127  (nrow, ncol, ncell)
> resolution  : 0.008333333, 0.008333333  (x, y)
> extent      : 29.425, 40.43333, -11.725, -1  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
> data source : in memory
> names       : layer.1.1.1
> values      : 7, 391  (min, max)
>
>
> I have used spBayes::spGLM to get spatial estimates for a logit model (based on predictors including NDVI and rainfall).
>
> I now wish to construct a prediction grid so that I can produce a continuous map of my predicted response based on draws from the predictive posterior distribution (using output from spBayes::spPredict).
>
> What is the best strategy? Should I extend the range of prediction grid to be rectangular (and then recreate raster layers not cropped to my country of interest so that the grid has complete data). Perhaps by using raster::drawExtent() I can ?draw? a rectangle over my domain and use those bounds as input for prediction grid.
>
> I was initially thinking of just creating a grid at the same 1x1km resolution as climate layers like so:
>
> grid <- raster(nrows=nrow(NDVI1), ncols=ncol(NDVI1),
>             xmn=bbox(NDVI1)[1], xmx=bbox(NDVI1)[3],
>             ymn=bbox(NDVI1)[2], ymx=bbox(NDVI1)[4])
>
>
> Thanks and Regards
> Justin Michell
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Thu Sep 11 18:07:44 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 11 Sep 2014 09:07:44 -0700
Subject: [R-sig-Geo] Extract points from raster brick by both location
 and a matching attributes.
In-Reply-To: <1410166510788-7587083.post@n2.nabble.com>
References: <1410166510788-7587083.post@n2.nabble.com>
Message-ID: <CANtt_hxG7yV5xnym=Bv-9OEDWvgoyZ0wj79YnABCMydDDun60w@mail.gmail.com>

I would extract all values and select the ones I need after that. The
alternative is to extract values layer by layer, that is probably less
efficient.
Robert

On Mon, Sep 8, 2014 at 1:55 AM, Kristin <nessnjor at gmail.com> wrote:
> Hi
>
> I have a raster brick of 464 layers, each layer representing time defined as
> number from 1 to 464.
> The numbers are stored here:
> rasterbrick at z$days
>
> and have values from 1 to 464
>
> Then I have 2800 space time locations of field data sampling. These are both
> irregular sampling locations and some irregular sampling dates at same
> sampling locations. Dates are also defined as numbers from 1 to 464. Each
> individual point is then identified by lat and lon at different times.
> This is what my dataframe looks like:
>
> Lat, Lon, days
> 64   -21    23
> 63   -19    52
> 63   -19    53
> 66   -25    23
> ....
>
> So what I want to do is to extract values from the raster brick at a certain
> location, but only where the date numbers from both the raster brick and the
> locations match, but not for all times for all locations as the extract from
> raster brick does.
>
> And if it helps, then below is the structure of my raster brick:
>> str (rasterbrick)
> Formal class 'RasterBrick' [package "raster"] with 12 slots
>   ..@ file    :Formal class '.RasterFile' [package "raster"] with 13 slots
>   .. .. ..@ name        : chr "C:\\Gudrun\\DINEOF_NIALL\\R\\chl.nc"
>   .. .. ..@ datanotation: chr "FLT4S"
>   .. .. ..@ byteorder   : chr "little"
>   .. .. ..@ nodatavalue : num -9999
>   .. .. ..@ NAchanged   : logi FALSE
>   .. .. ..@ nbands      : int 464
>   .. .. ..@ bandorder   : chr "BIL"
>   .. .. ..@ offset      : int 0
>   .. .. ..@ toptobottom : logi TRUE
>   .. .. ..@ blockrows   : int 0
>   .. .. ..@ blockcols   : int 0
>   .. .. ..@ driver      : chr "netcdf"
>   .. .. ..@ open        : logi FALSE
>   ..@ data    :Formal class '.MultipleRasterData' [package "raster"] with 14
> slots
>   .. .. ..@ values    : logi[0 , 0 ]
>   .. .. ..@ offset    : num 0
>   .. .. ..@ gain      : num 1
>   .. .. ..@ inmemory  : logi FALSE
>   .. .. ..@ fromdisk  : logi TRUE
>   .. .. ..@ nlayers   : int 464
>   .. .. ..@ dropped   : NULL
>   .. .. ..@ isfactor  : logi FALSE
>   .. .. ..@ attributes: list()
>   .. .. ..@ haveminmax: logi FALSE
>   .. .. ..@ min       : num [1:464] Inf Inf Inf Inf Inf ...
>   .. .. ..@ max       : num [1:464] -Inf -Inf -Inf -Inf -Inf ...
>   .. .. ..@ unit      : chr "units"
>   .. .. ..@ names     : chr [1:464] "X341" "X41" "X169" "X281" ...
>   ..@ legend  :Formal class '.RasterLegend' [package "raster"] with 5 slots
>   .. .. ..@ type      : chr(0)
>   .. .. ..@ values    : logi(0)
>   .. .. ..@ color     : logi(0)
>   .. .. ..@ names     : logi(0)
>   .. .. ..@ colortable: logi(0)
>   ..@ title   : chr "var3d"
>   ..@ extent  :Formal class 'Extent' [package "raster"] with 4 slots
>   .. .. ..@ xmin: num -30
>   .. .. ..@ xmax: num -8.01
>   .. .. ..@ ymin: num 60
>   .. .. ..@ ymax: num 68
>   ..@ rotated : logi FALSE
>   ..@ rotation:Formal class '.Rotation' [package "raster"] with 2 slots
>   .. .. ..@ geotrans: num(0)
>   .. .. ..@ transfun:function ()
>   ..@ ncols   : int 440
>   ..@ nrows   : int 160
>   ..@ crs     :Formal class 'CRS' [package "sp"] with 1 slots
>   .. .. ..@ projargs: chr "+proj=longlat +datum=WGS84"
>   ..@ history : list()
>   ..@ z       :List of 1
>   .. ..$ days: int [1:464(1d)] 341 41 169 281 409 69 197 309 437 101 ...
>
> atb,
> Kristin
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Extract-points-from-raster-brick-by-both-location-and-a-matching-attributes-tp7587083.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Thu Sep 11 18:10:48 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 11 Sep 2014 09:10:48 -0700
Subject: [R-sig-Geo] Collinearity test domain
In-Reply-To: <CANJhsN0iwHTAmdTfVi-XxqbYb8h67-2so0BZKU0WLy=ZbBcXBA@mail.gmail.com>
References: <CANJhsN0iwHTAmdTfVi-XxqbYb8h67-2so0BZKU0WLy=ZbBcXBA@mail.gmail.com>
Message-ID: <CANtt_hyfbvaMvTcwpj2rUYAum+Kq=VanAdy5xrYd9bhdx_99ZQ@mail.gmail.com>

Maurizio,
One typically cares about collinearity because it can lead to a sub
optimal model. The model is only affected by the data it sees.
Therefore only the values at your presence/absence points matter.
Robert

On Thu, Sep 4, 2014 at 7:40 AM, Maurizio Marchi
<mauriziomarchi85 at gmail.com> wrote:
> Hallo everybody,
> I have a question about Ecological Niche Modelling / Species Distribution
> Modelling.
>
> If I want to study the distribution of a species in present and future
> time, to remove redundancy and collinearity between predictors should I
> test predictors' correlation/covariance/collinearity using a database
> including only presence/absence available points or should I have to use
> the whole region I'm studing (e.g. the whole Europe?)
>
> as example:
> Presence points: Forest national inventory surveys classified as "pinus
> nigra stands"
> Absence/Pseudo absence points: Forest national inventory surveys NOT
> classified as "pinus nigra stands"
> Study region: Italy
>
> many thanks,
> Maurizio
>
> --
> Maurizio Marchi, Ph.D. student
> Florence, Italy
> ID skype: maurizioxyz
> Ubuntu 14.04 LTS
> linux user 552742
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Thu Sep 11 18:47:11 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 11 Sep 2014 09:47:11 -0700
Subject: [R-sig-Geo] Automate the extraction of climate variable at
 different time depths from netcdf in r
In-Reply-To: <DBB31DC6-0AAE-4258-8E23-2B7B66650F76@gmail.com>
References: <CA+R607EimFZvQXjmjp0B1KSQgmaXz6=n8zZsCJ+AS4Ccsix+_g@mail.gmail.com>
	<CANtt_hzyrcRhqgYtAnkwT+waY03vD6N5w2PKjjPyFsEpXwBWLQ@mail.gmail.com>
	<DBB31DC6-0AAE-4258-8E23-2B7B66650F76@gmail.com>
Message-ID: <CANtt_hykKBtGFPvvuSJfku6hyW-YtNUhonKYSfo8OQXCR5fKow@mail.gmail.com>

Barnabas,
I doubt you will need to "delete one-by-one, the values for the years
that I do not desire". There surely are basic R tricks for that.
Perhaps the below example can get you there:

## example data
#raster
b <- brick(system.file("external/rlogo.grd", package="raster"))
# points
set.seed(0)
p <- xyFromCell(b, sample(ncell(b), 10))
# "years"
y <- cbind(y1=sample(0:1, 10, replace=TRUE), y2=sample(0:1, 10,
replace=TRUE), y3=sample(0:1, 10, replace=TRUE))


# extract all
e <- extract(b, p)
# combine data
x <- data.frame(x=p[,1], y=p[,2], year=rep(1:3, each=nrow(p)),
include=as.vector(y), value=as.vector(e))
# select values you want
x[x$include==1, ]

Whether the above works for you really depends on how you need to get
the values for further processing.

Robert



On Sun, Sep 7, 2014 at 8:58 AM, Barnabas Daru <darunabas at gmail.com> wrote:
> Hi Robert,
> Thanks very much for your suggestion.
> I tried the code you provided and it work! Many thanks.
> However, it tends to extract the SST values for all the points and for time
> periods including even the years that I don't desire. This means I will have
> to delete one-by-one, the values for the years that I do not desire and keep
> only the ones I want.
> I thought there is a way I could simply ask R to print in one column, the
> extracted values associated with only the years for which point data is
> available.
> Thanks and kind regards
> Barnabas
>
>
>
>   \-/
>    /\
>   /--|
>  /---/ Barnabas Daru
>  |--/  PhD Candidate,
>  \-/   African Centre for DNA Barcoding,
>  /\    University of Johannesburg,
> /--\   PO Box 524, Auckland Park, 2006,
> |---\  Johannesburg, South Africa.
>  \---\ Lab: +27 11 559 3477
>   \--| Mobile: +277 3818 9583
>    \-/ Website: www.barnabasdaru.com
>    /\
>   /--\
>
> #?if you can think it, you can do it.
>
>
>
>
>
> On Sep 7, 2014, at 5:23 AM, Robert J. Hijmans wrote:
>
> Barnabas, ,
> You can try something like this:
>
> b <- brick("~sst.mnmean.nc", varname="sst")
> # loop over species, or combine all species into one data.frame?
> mydata <- read.csv("~Species one.csv")
> extract.mydata <- extract(b, mydata[,5:6])
> write.csv(extract.mydata, file = "Species_one_extracted.csv")
>
> Robert
>
>


From daniel.santos at inpe.br  Thu Sep 11 21:04:54 2014
From: daniel.santos at inpe.br (Daniel Teixeira dos Santos)
Date: Thu, 11 Sep 2014 16:04:54 -0300
Subject: [R-sig-Geo] Ploting objects of class 'STT' with stplot
Message-ID: <CAMHD-CA6j7s7JxiAbhfK1dvmWD8p_Auyt6O2eRqVp2i4CQijJA@mail.gmail.com>

Hello,

I am beginning with spacetime and just tried some examples of code with it.
I have tried to plot an object of class 'STT' and got this error message:


> stplot(stt)
Erro em (function (classes, fdef, mtable)  :
  unable to find an inherited method for function ?stplot? for signature
?"STT"?


The code I've used to create the 'stt' object is the same example code of
the documentation for "STT" class:


library(spacetime)
library(sp)
m = 3# nr of trajectories
n = 100 # length of each
l = vector("list", m)
t0 = as.POSIXct("2013-05-05",tz="GMT")
set.seed(1331) # fix randomness
for (i in 1:m) {
x = cumsum(rnorm(n))
y = cumsum(rnorm(n))
sp = SpatialPoints(cbind(x,y))
#t = t0 + (0:(n-1) + (i-1)*n) * 60
t = t0 + (0:(n-1) + (i-1)*n/2) * 60
l[[i]] = STI(sp, t)
}
stt= STT(l)
sttdf = STTDF(stt, data.frame(attr = rnorm(n*m), id = paste("ID", rep(1:m,
each=n))))


Isn't it supposed to have a method for plotting "STT" objects?


--
Daniel Teixeira dos Santos
Mestrando em Computa??o Aplicada (INPE)
Bacharel em Ci?ncia da Computa??o (UFLA)

	[[alternative HTML version deleted]]


From bakare at ualberta.ca  Thu Sep 11 21:36:25 2014
From: bakare at ualberta.ca (Moshood Agba Bakare)
Date: Thu, 11 Sep 2014 13:36:25 -0600
Subject: [R-sig-Geo] Search radius for spatial interpolation over different
	years
Message-ID: <CAJRR3XMoBQs07b=ao32dbYF0qOrNBbuk-ZXyr+j_xeBbaH98cQ@mail.gmail.com>

Dear All,

4-year yield monitor data from a field has a practical range of 39.6, 99.6,
47.7, and 59.4 meters in year 2008, 2009, 2010, and 2011 respectively.
Their spatial pattern is best described with exponential variogram model. I
intend to assess the stability of the spatial pattern over the four years.
I created a common interpolation grid where the interpolated values will be
obtained through ordinary kriging and inverse distance weighting method.

I am a little bit worry on which of the practical ranges to be used as my
search radius (maxdist of krige) . I am thinking of using the same search
radius for each year in order not to be biased in comparing their
interpolated values. Or should I use their respective practical range since
it varies from one year to the other. Please advise me.

Thank you all.

	[[alternative HTML version deleted]]


From ferra.xu at yahoo.com  Thu Sep 11 22:00:29 2014
From: ferra.xu at yahoo.com (Ferra Xu)
Date: Thu, 11 Sep 2014 13:00:29 -0700
Subject: [R-sig-Geo] =?utf-8?q?5-D_Kernel_density_estimation_in_R_using_?=
 =?utf-8?b?4oCca2Rl4oCdIGZ1bmN0aW9u?=
Message-ID: <1410465629.55153.YahooMailNeo@web125103.mail.ne1.yahoo.com>

 I want to perform Kernel density estimate for a 5-dimensional data (x,y,z,time,size) by using "kde" function in "ks" library of R. In it's manual it says it can do Kernel density estimate for 1- to 
6-dimensional data (Page 24 of manual: http://cran.r-project.org/web/packages/ks/ks.pdf).
My problem is that it says for more than 3 dimensions I need to 
specify eval.points. I don't know how can I specify the evaluation 
points because there is no example for more than 3 dimensions. For 
example if I want to generate equal boxes in the 3-D rectangular space 
of the problem and specify the center of each box as the eval-point, 
what should I do?
Here is my data:
422.697323164.198862.4574198.0837966360.83367586423.008236163.324340.555132637.584774550.893893903204.733908218.363651.939787437.883243120.912809449203.963056218.48080.372379143.217759030.926406005100.72758146.608761.402234149.415105190.782807523453.335182244.255211.629251751.737791750.903910803134.909462210.963332.238911953.134335210.896529401135.300562212.020550.673954167.550737450.748783521258.237117134.297352.120529176.340325870.735699304341.305271149.269533.71895894.339754830.849509216307.13892559.605710.6311074106.96367150.987923188307.7687558.914532.6496741113.85153070.802115718415.025535217.173981.7155688115.74646030.875580325414.977687216.733271.7107369115.97769480.767143582311.006135173.243782.7819572120.80795660.925380118310.116929174.281224.3318722129.26484010.776528535347.26091137.349463.5155427136.78512910.851787115351.31762433.657030.5806926138.73492840.9097230174.47189259.420681.4062959139.05437830.9672709765.48022359.728572.7326106139.2
1142770.987787428199.51302321.533022.5163259143.58956250.864164659198.71803123.501630.4801849147.22804660.74158733326.65051735.20190.8246514150.48765060.74478820225.08937990.478250.8700944152.19440460.77725247626.30743988.415522.4422487155.90900260.952215177234.282901236.114221.8115261155.96581440.776284654235.052948236.774371.9644963156.69002970.94428544823.04820298.62613.4573048159.77009120.77305749121.51669598.054312.5029284160.82029970.978779087213.936324151.870133.1042192161.06124890.80499513277.887935197.257531.3659279163.6731420.758978575277.239746197.540012.2109361166.26298680.775325157
And this is the code that I am using:
library(ks)library(rgl)kern <-read.table(file.choose(),sep=",")hat <-kde(kern)
It works for up to 3 dimensions but for 4 and 5 dimensions it says:  need to specify eval.points for more than 3 dimensions. 

	[[alternative HTML version deleted]]


From ferra.xu at yahoo.com  Thu Sep 11 22:03:40 2014
From: ferra.xu at yahoo.com (Ferra Xu)
Date: Thu, 11 Sep 2014 13:03:40 -0700
Subject: [R-sig-Geo]
 =?utf-8?q?5-D_Kernel_density_estimation_in_R_using_?=
 =?utf-8?b?4oCca2Rl4oCdIGZ1bmN0aW9u?=
In-Reply-To: <1410465629.55153.YahooMailNeo@web125103.mail.ne1.yahoo.com>
References: <1410465629.55153.YahooMailNeo@web125103.mail.ne1.yahoo.com>
Message-ID: <1410465820.67745.YahooMailNeo@web125102.mail.ne1.yahoo.com>

Sorry, if the data is not clear here please take a look at this link: 5-D Kernel density estimation in R using ?kde? function
  
             
5-D Kernel density estimation in R using ?kde? function
I want to perform Kernel density estimate for a 5-dimensional data (x,y,z,time,size) by using "kde" function in "ks" library of R. In it's manual it says it can d...  
View on stackoverflow.com Preview by Yahoo  
  
 


On Thursday, September 11, 2014 1:00 PM, Ferra Xu <ferra.xu at yahoo.com> wrote:
 


 I want to perform Kernel density estimate for a 5-dimensional data (x,y,z,time,size) by using "kde" function in "ks" library of R. In it's manual it says it can do Kernel density estimate for 1- to 
6-dimensional data (Page 24 of manual: http://cran.r-project.org/web/packages/ks/ks.pdf).
My problem is that it says for more than 3 dimensions I need to 
specify eval.points. I don't know how can I specify the evaluation 
points because there is no example for more than 3 dimensions. For 
example if I want to generate equal boxes in the 3-D rectangular space 
of the problem and specify the center of each box as the eval-point, 
what should I do?
Here is my data:
422.697323164.198862.4574198.0837966360.83367586423.008236163.324340.555132637.584774550.893893903204.733908218.363651.939787437.883243120.912809449203.963056218.48080.372379143.217759030.926406005100.72758146.608761.402234149.415105190.782807523453.335182244.255211.629251751.737791750.903910803134.909462210.963332.238911953.134335210.896529401135.300562212.020550.673954167.550737450.748783521258.237117134.297352.120529176.340325870.735699304341.305271149.269533.71895894.339754830.849509216307.13892559.605710.6311074106.96367150.987923188307.7687558.914532.6496741113.85153070.802115718415.025535217.173981.7155688115.74646030.875580325414.977687216.733271.7107369115.97769480.767143582311.006135173.243782.7819572120.80795660.925380118310.116929174.281224.3318722129.26484010.776528535347.26091137.349463.5155427136.78512910.851787115351.31762433.657030.5806926138.73492840.9097230174.47189259.420681.4062959139.05437830.9672709765.48022359.728572.7326106139.2
1142770.987787428199.51302321.533022.5163259143.58956250.864164659198.71803123.501630.4801849147.22804660.74158733326.65051735.20190.8246514150.48765060.74478820225.08937990.478250.8700944152.19440460.77725247626.30743988.415522.4422487155.90900260.952215177234.282901236.114221.8115261155.96581440.776284654235.052948236.774371.9644963156.69002970.94428544823.04820298.62613.4573048159.77009120.77305749121.51669598.054312.5029284160.82029970.978779087213.936324151.870133.1042192161.06124890.80499513277.887935197.257531.3659279163.6731420.758978575277.239746197.540012.2109361166.26298680.775325157
And this is the code that I am using:
library(ks)library(rgl)kern <-read.table(file.choose(),sep=",")hat <-kde(kern)
It works for up to 3 dimensions but for 4 and 5 dimensions it says:  need to specify eval.points for more than 3 dimensions. 
	[[alternative HTML version deleted]]


From graham.b.mcnamara at gmail.com  Thu Sep 11 22:17:00 2014
From: graham.b.mcnamara at gmail.com (Graham Bond McNamara)
Date: Thu, 11 Sep 2014 22:17:00 +0200
Subject: [R-sig-Geo] gIntersection gives error (may not contain geometry
	collections)
Message-ID: <CAPoG4sgUbft1ZhUTYGmcDLrvp0ngPH1jHQqF11pbLYZOU2hPHg@mail.gmail.com>

I am trying to use gIntersection like so:

gIntersection(mypolys.spdf, mylines.sldf, byid=c(TRUE,TRUE))

This intersection between the polygons in the SpatialPolygonsDataFrame
and the lines in the SpatialLinesDataFrame should result in a new
SpatialLines object. I have used this before and this works.

However, on my new dataset, I get the following error:

output subgeometry 3195, row.name: 24 3759
subsubgeometry 0: Point
subsubgeometry 1: LineString
Error in RGEOSBinTopoFunc(spgeom1, spgeom2, byid, id, drop_not_poly,
"rgeos_intersection") :
  Geometry collections may not contain other geometry collections

I have inspected mypolys.spdf and my lines.sldf, and they are not
geometry collections, but just the spdf and sldf. So I don't know
where the "Point" and "LineString" are coming from (what is a
LineString anyway?).

The culprit seems to be the combination of  poly 24 and line 3759.
There is nothing wrong with it per se, but it's a line that exactly
overlaps the polygon border. I thought perhaps that was the problem?

I am not allowed to share my actual data, but it looks like this:

Sr1 = Polygon(cbind(c(1,2,2,4,4,1,1),c(1,1,3,3,5,5,1)))
Sr2 = Polygon(cbind(c(2,4,4,2,2),c(1,1,3,3,1)))
Srs1 = Polygons(list(Sr1), "1")
Srs2 = Polygons(list(Sr2), "2")
SpP = SpatialPolygons(list(Srs1,Srs2), 1:2)
plot(SpP) # example neighborhoods

l1 = cbind(c(2,2),c(2,4))
Sl1 = Line(l1)
S1 = Lines(list(Sl1), ID="1")
Sl = SpatialLines(list(S1))
plot(Sl, add=TRUE, col="green", lwd=3)

gIntersection works:

gInt <- gIntersection(SpP, Sl, byid=c(TRUE, TRUE))

The line hugging the border intersects both poly 1 and poly 2, so this
line is split up and reproduced twice.

In summary: gIntersection works even when a line is exactly on the
poly's border. This means I am no closer to understanding my error
message. Can anyone help?

Cheers,
Graham


From edzer.pebesma at uni-muenster.de  Thu Sep 11 23:33:36 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 11 Sep 2014 23:33:36 +0200
Subject: [R-sig-Geo] Ploting objects of class 'STT' with stplot
In-Reply-To: <CAMHD-CA6j7s7JxiAbhfK1dvmWD8p_Auyt6O2eRqVp2i4CQijJA@mail.gmail.com>
References: <CAMHD-CA6j7s7JxiAbhfK1dvmWD8p_Auyt6O2eRqVp2i4CQijJA@mail.gmail.com>
Message-ID: <54121530.6050104@uni-muenster.de>



On 09/11/2014 09:04 PM, Daniel Teixeira dos Santos wrote:
> Hello,
> 
> I am beginning with spacetime and just tried some examples of code with it.
> I have tried to plot an object of class 'STT' and got this error message:
> 
> 
>> stplot(stt)
> Erro em (function (classes, fdef, mtable)  :
>   unable to find an inherited method for function ?stplot? for signature
> ?"STT"?
> 
> 
> The code I've used to create the 'stt' object is the same example code of
> the documentation for "STT" class:
> 
> 
> library(spacetime)
> library(sp)
> m = 3# nr of trajectories
> n = 100 # length of each
> l = vector("list", m)
> t0 = as.POSIXct("2013-05-05",tz="GMT")
> set.seed(1331) # fix randomness
> for (i in 1:m) {
> x = cumsum(rnorm(n))
> y = cumsum(rnorm(n))
> sp = SpatialPoints(cbind(x,y))
> #t = t0 + (0:(n-1) + (i-1)*n) * 60
> t = t0 + (0:(n-1) + (i-1)*n/2) * 60
> l[[i]] = STI(sp, t)
> }
> stt= STT(l)
> sttdf = STTDF(stt, data.frame(attr = rnorm(n*m), id = paste("ID", rep(1:m,
> each=n))))
> 
> 
> Isn't it supposed to have a method for plotting "STT" objects?

yes, this is a bug, fixed on github. It will however give you the same as

stplot(sttdf)

which is rather primitive too.

FYI, there is now a package called trajectories on CRAN, which has more
useful plotting methods for trajectory data. I think it does a better
job representing trajectories, and I hope to see future development
there rather than in spacetime.

Thanks for the clear report,

> 
> 
> --
> Daniel Teixeira dos Santos
> Mestrando em Computa??o Aplicada (INPE)
> Bacharel em Ci?ncia da Computa??o (UFLA)
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140911/bb3ffd84/attachment.bin>

From Roger.Bivand at nhh.no  Thu Sep 11 23:33:33 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 11 Sep 2014 23:33:33 +0200
Subject: [R-sig-Geo] gIntersection gives error (may not contain geometry
 collections)
In-Reply-To: <CAPoG4sgUbft1ZhUTYGmcDLrvp0ngPH1jHQqF11pbLYZOU2hPHg@mail.gmail.com>
References: <CAPoG4sgUbft1ZhUTYGmcDLrvp0ngPH1jHQqF11pbLYZOU2hPHg@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1409112326180.14586@reclus.nhh.no>

On Thu, 11 Sep 2014, Graham Bond McNamara wrote:

> I am trying to use gIntersection like so:
>
> gIntersection(mypolys.spdf, mylines.sldf, byid=c(TRUE,TRUE))
>
> This intersection between the polygons in the SpatialPolygonsDataFrame
> and the lines in the SpatialLinesDataFrame should result in a new
> SpatialLines object. I have used this before and this works.
>
> However, on my new dataset, I get the following error:
>
> output subgeometry 3195, row.name: 24 3759
> subsubgeometry 0: Point
> subsubgeometry 1: LineString
> Error in RGEOSBinTopoFunc(spgeom1, spgeom2, byid, id, drop_not_poly,
> "rgeos_intersection") :
>  Geometry collections may not contain other geometry collections
>
> I have inspected mypolys.spdf and my lines.sldf, and they are not
> geometry collections, but just the spdf and sldf. So I don't know
> where the "Point" and "LineString" are coming from (what is a
> LineString anyway?).

Briefly, an input Polygons object and an input Lines object intersect at a 
point and a line, so returning a collection of objects of different types. 
Almost certainly the intention is to drop the point (a line of no length), 
as is already optionally done when a polygon/polygon intersection returns 
polygon and non-polygon (point or line) objects - the drop_not_poly= 
argument. Your case suggests that this should be checked again, to change 
the present argument to drop points for lines and points/lines for 
polygons. The details of the meanings of operations are found in the JTS 
references in the package.

Hope this clarifies,

Roger

>
> The culprit seems to be the combination of  poly 24 and line 3759.
> There is nothing wrong with it per se, but it's a line that exactly
> overlaps the polygon border. I thought perhaps that was the problem?
>
> I am not allowed to share my actual data, but it looks like this:
>
> Sr1 = Polygon(cbind(c(1,2,2,4,4,1,1),c(1,1,3,3,5,5,1)))
> Sr2 = Polygon(cbind(c(2,4,4,2,2),c(1,1,3,3,1)))
> Srs1 = Polygons(list(Sr1), "1")
> Srs2 = Polygons(list(Sr2), "2")
> SpP = SpatialPolygons(list(Srs1,Srs2), 1:2)
> plot(SpP) # example neighborhoods
>
> l1 = cbind(c(2,2),c(2,4))
> Sl1 = Line(l1)
> S1 = Lines(list(Sl1), ID="1")
> Sl = SpatialLines(list(S1))
> plot(Sl, add=TRUE, col="green", lwd=3)
>
> gIntersection works:
>
> gInt <- gIntersection(SpP, Sl, byid=c(TRUE, TRUE))
>
> The line hugging the border intersects both poly 1 and poly 2, so this
> line is split up and reproduced twice.
>
> In summary: gIntersection works even when a line is exactly on the
> poly's border. This means I am no closer to understanding my error
> message. Can anyone help?
>
> Cheers,
> Graham
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From graham.b.mcnamara at gmail.com  Fri Sep 12 00:07:45 2014
From: graham.b.mcnamara at gmail.com (Graham B. McNamara)
Date: Fri, 12 Sep 2014 00:07:45 +0200
Subject: [R-sig-Geo] gIntersection gives error (may not contain geometry
	collections)
In-Reply-To: <alpine.LRH.2.03.1409112326180.14586@reclus.nhh.no>
References: <CAPoG4sgUbft1ZhUTYGmcDLrvp0ngPH1jHQqF11pbLYZOU2hPHg@mail.gmail.com>
	<alpine.LRH.2.03.1409112326180.14586@reclus.nhh.no>
Message-ID: <CAPoG4si7y-Nr3b_UNjHXhXgQ7fcPSU8v5nD7yepY0mOHJw6BAQ@mail.gmail.com>

Thanks for the referralI. I will start reading up on JTS.

I still don't understand why the example I provided does not run into
problems with this, though. The line and polygon border in my actual
data look similar to the example.





On Thu, Sep 11, 2014 at 11:33 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Thu, 11 Sep 2014, Graham Bond McNamara wrote:
>
>> I am trying to use gIntersection like so:
>>
>> gIntersection(mypolys.spdf, mylines.sldf, byid=c(TRUE,TRUE))
>>
>> This intersection between the polygons in the SpatialPolygonsDataFrame
>> and the lines in the SpatialLinesDataFrame should result in a new
>> SpatialLines object. I have used this before and this works.
>>
>> However, on my new dataset, I get the following error:
>>
>> output subgeometry 3195, row.name: 24 3759
>> subsubgeometry 0: Point
>> subsubgeometry 1: LineString
>> Error in RGEOSBinTopoFunc(spgeom1, spgeom2, byid, id, drop_not_poly,
>> "rgeos_intersection") :
>>  Geometry collections may not contain other geometry collections
>>
>> I have inspected mypolys.spdf and my lines.sldf, and they are not
>> geometry collections, but just the spdf and sldf. So I don't know
>> where the "Point" and "LineString" are coming from (what is a
>> LineString anyway?).
>
>
> Briefly, an input Polygons object and an input Lines object intersect at a
> point and a line, so returning a collection of objects of different types.
> Almost certainly the intention is to drop the point (a line of no length),
> as is already optionally done when a polygon/polygon intersection returns
> polygon and non-polygon (point or line) objects - the drop_not_poly=
> argument. Your case suggests that this should be checked again, to change
> the present argument to drop points for lines and points/lines for polygons.
> The details of the meanings of operations are found in the JTS references in
> the package.
>
> Hope this clarifies,
>
> Roger
>
>>
>> The culprit seems to be the combination of  poly 24 and line 3759.
>> There is nothing wrong with it per se, but it's a line that exactly
>> overlaps the polygon border. I thought perhaps that was the problem?
>>
>> I am not allowed to share my actual data, but it looks like this:
>>
>> Sr1 = Polygon(cbind(c(1,2,2,4,4,1,1),c(1,1,3,3,5,5,1)))
>> Sr2 = Polygon(cbind(c(2,4,4,2,2),c(1,1,3,3,1)))
>> Srs1 = Polygons(list(Sr1), "1")
>> Srs2 = Polygons(list(Sr2), "2")
>> SpP = SpatialPolygons(list(Srs1,Srs2), 1:2)
>> plot(SpP) # example neighborhoods
>>
>> l1 = cbind(c(2,2),c(2,4))
>> Sl1 = Line(l1)
>> S1 = Lines(list(Sl1), ID="1")
>> Sl = SpatialLines(list(S1))
>> plot(Sl, add=TRUE, col="green", lwd=3)
>>
>> gIntersection works:
>>
>> gInt <- gIntersection(SpP, Sl, byid=c(TRUE, TRUE))
>>
>> The line hugging the border intersects both poly 1 and poly 2, so this
>> line is split up and reproduced twice.
>>
>> In summary: gIntersection works even when a line is exactly on the
>> poly's border. This means I am no closer to understanding my error
>> message. Can anyone help?
>>
>> Cheers,
>> Graham
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>


From vitale232 at gmail.com  Fri Sep 12 01:01:35 2014
From: vitale232 at gmail.com (Andrew Vitale)
Date: Thu, 11 Sep 2014 16:01:35 -0700
Subject: [R-sig-Geo] Create raster layer that counts SpatialPoint occurrence
	within cells
Message-ID: <CAFTcopfCzMV8bg3X6g6bTUNPDWHkd_-3B=wptjozfVj1ygxv-g@mail.gmail.com>

Hello all,

I have a Python script that searches Twitter for tweets that meet certain
criteria and records the coordinates of those tweets.  This leaves me with
a CSV that can then easily be read into R as a SpatialPoints object.

Once I have the SpatialPoints, I would like to make a raster layer that has
the count of tweet locations that occur within each cell of that raster
layer.

I have a working script, but I feel like my way of doing this is very
inefficient.  Does anyone know a better way to produce a map similar to
this?  I'm also interested in other suggestions of how to visualize these
data.

The example below shows my approach to this problem.  I believe the weak
point of the code is my for loop.  I would like to increase efficiency, as
I plan to use this approach on much larger datasets.  Thanks for your
advice!

-Andrew Vitale

The example:


library(raster)

## Create a set of random long/lat coordinates
## that are centred around a "metro" area.
## These data mimic the CSV of tweet coords I read in to R
n = 500
set.seed(232)
x = rnorm(n, -96, 5)
y = rnorm(n, 32, 5)
xy = cbind(x, y)

## Create a SpatialPoints object of the "tweets"
tweets = SpatialPoints(xy)
proj4string(tweets) = CRS('+proj=longlat +datum=WGS84')

## Create an empty template raster for rasterizing the points and
## create an empty list to store each rasterized point
r = raster(nrow=90, ncol=180)
l = list()

## Loop through the tweets one point (row) at a time and create
## a raster with the value of 1 at the location of the tweet.
## Store the raster layers created for each tweet in a list.
## This loop is the slow part of my code. ##
for(i in 1:length(tweets)){
  p = tweets[i, ]
  l[[i]] = rasterize(p, r)
}

## Create a raster stack from the list
s = stack(l)

## Sum the stack layers together ignoring NA values, which
## produces a raster layer of counts.  Set 0 values to NA
counts = sum(s, na.rm=TRUE)
counts[counts == 0] = NA

## Plot the raster layer
plot(counts)

-- 
*Andrew P. Vitale*
Masters Student
Department of Geography
University of Nevada, Reno
vitale232 at gmail.com

	[[alternative HTML version deleted]]


From agus.camacho at gmail.com  Fri Sep 12 01:13:13 2014
From: agus.camacho at gmail.com (Agus Camacho)
Date: Thu, 11 Sep 2014 20:13:13 -0300
Subject: [R-sig-Geo] Distances from points to coast do not make sense.
Message-ID: <CALsJ7pT9XJ5Djips7cMk_iyhiZAE5=29NpOTO3V9nm+Y=G1qMQ@mail.gmail.com>

I have two species, one is widespread in Africa (varanus niloticus) and the
other is distributed across a region of new Guinea (Varanus prasinus). I
calculated the mean distance to coast of their respective geographic
records using the following script:

x1 is a dataframe with two columns: Longitude and Latitude of geographic
records

meandist=rep(0,length(levels(x$Species)))
distance=rep(NA,dim(x1)[1])

for(n in 1:dim(x1)[1])
{
 distance[n]=(dist2Line(cbind(x1[n,1],x1[n,2]),LAcl,distfun=distVincentyEllipsoid)/1000)[1]
}
meandist=mean(distance)

The problem is that geographic records from the african species is giving
me shorter distances to the coast (mean=6677) than the species from new
guinea(mean=12417). I already plotted the species records and checked there
are not bizarre records. I can send the records for anyone insterested.

Thanks in advance.
Agus



-- 
Agust?n Camacho Guerrero.
Doutor em Zoologia.
Laborat?rio de Herpetologia, Departamento de Zoologia, Instituto de
Bioci?ncias, USP.
Rua do Mat?o, trav. 14, n? 321, Cidade Universit?ria,
S?o Paulo - SP, CEP: 05508-090, Brasil.

	[[alternative HTML version deleted]]


From r.hijmans at gmail.com  Fri Sep 12 02:06:06 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 11 Sep 2014 17:06:06 -0700
Subject: [R-sig-Geo] Create raster layer that counts SpatialPoint
 occurrence within cells
In-Reply-To: <CAFTcopfCzMV8bg3X6g6bTUNPDWHkd_-3B=wptjozfVj1ygxv-g@mail.gmail.com>
References: <CAFTcopfCzMV8bg3X6g6bTUNPDWHkd_-3B=wptjozfVj1ygxv-g@mail.gmail.com>
Message-ID: <CANtt_hyHzifQYjLivqS3k033LkziDXVAH-s4H+SKn0KUorKkJw@mail.gmail.com>

Hi Andrew,

There is no need to loop over rasterize. This should do it:

library(raster)
n = 500
set.seed(232)
x = rnorm(n, -96, 5)
y = rnorm(n, 32, 5)

xy = cbind(x, y)
r = raster(nrow=90, ncol=180)
rr = rasterize(xy, r, fun='count')

Best, Robert

On Thu, Sep 11, 2014 at 4:01 PM, Andrew Vitale <vitale232 at gmail.com> wrote:
> Hello all,
>
> I have a Python script that searches Twitter for tweets that meet certain
> criteria and records the coordinates of those tweets.  This leaves me with
> a CSV that can then easily be read into R as a SpatialPoints object.
>
> Once I have the SpatialPoints, I would like to make a raster layer that has
> the count of tweet locations that occur within each cell of that raster
> layer.
>
> I have a working script, but I feel like my way of doing this is very
> inefficient.  Does anyone know a better way to produce a map similar to
> this?  I'm also interested in other suggestions of how to visualize these
> data.
>
> The example below shows my approach to this problem.  I believe the weak
> point of the code is my for loop.  I would like to increase efficiency, as
> I plan to use this approach on much larger datasets.  Thanks for your
> advice!
>
> -Andrew Vitale
>
> The example:
>
>
> library(raster)
>
> ## Create a set of random long/lat coordinates
> ## that are centred around a "metro" area.
> ## These data mimic the CSV of tweet coords I read in to R
> n = 500
> set.seed(232)
> x = rnorm(n, -96, 5)
> y = rnorm(n, 32, 5)
> xy = cbind(x, y)
>
> ## Create a SpatialPoints object of the "tweets"
> tweets = SpatialPoints(xy)
> proj4string(tweets) = CRS('+proj=longlat +datum=WGS84')
>
> ## Create an empty template raster for rasterizing the points and
> ## create an empty list to store each rasterized point
> r = raster(nrow=90, ncol=180)
> l = list()
>
> ## Loop through the tweets one point (row) at a time and create
> ## a raster with the value of 1 at the location of the tweet.
> ## Store the raster layers created for each tweet in a list.
> ## This loop is the slow part of my code. ##
> for(i in 1:length(tweets)){
>   p = tweets[i, ]
>   l[[i]] = rasterize(p, r)
> }
>
> ## Create a raster stack from the list
> s = stack(l)
>
> ## Sum the stack layers together ignoring NA values, which
> ## produces a raster layer of counts.  Set 0 values to NA
> counts = sum(s, na.rm=TRUE)
> counts[counts == 0] = NA
>
> ## Plot the raster layer
> plot(counts)
>
> --
> *Andrew P. Vitale*
> Masters Student
> Department of Geography
> University of Nevada, Reno
> vitale232 at gmail.com
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From basille.web at ase-research.org  Fri Sep 12 02:11:42 2014
From: basille.web at ase-research.org (Mathieu Basille)
Date: Thu, 11 Sep 2014 20:11:42 -0400
Subject: [R-sig-Geo] Create raster layer that counts SpatialPoint
 occurrence within cells
In-Reply-To: <CAFTcopfCzMV8bg3X6g6bTUNPDWHkd_-3B=wptjozfVj1ygxv-g@mail.gmail.com>
References: <CAFTcopfCzMV8bg3X6g6bTUNPDWHkd_-3B=wptjozfVj1ygxv-g@mail.gmail.com>
Message-ID: <54123A3E.3010901@ase-research.org>

Hi Andrew,

The answer from Robert is very neat! Alternatively, you may also have a 
look at `count.points` in the package adehabitatMA (which was developed for 
animal locations!). Here is a working example from the vignette (p.17):

library(adehabitatMA)

## Load the data
data(lynxjura)

## `map` is a SpatialPixelsDataFrame
map <- lynxjura$map
class(map)

## `locs` is a SpatialPointsDataFrame
locs <- lynxjura$loc
class(locs)

## Plot the map + points
image(map, 1)
points(locs, pch=3)

## Count the number of points per pixel and map the result
cp <- count.points(locs, map)
image(cp)

## `cp` is a SpatialPixelsDataFrame
class(cp)

Hope this helps,
Mathieu.


Le 11/09/2014 19:01, Andrew Vitale a ?crit :
> Hello all,
>
> I have a Python script that searches Twitter for tweets that meet certain
> criteria and records the coordinates of those tweets.  This leaves me with
> a CSV that can then easily be read into R as a SpatialPoints object.
>
> Once I have the SpatialPoints, I would like to make a raster layer that has
> the count of tweet locations that occur within each cell of that raster
> layer.
>
> I have a working script, but I feel like my way of doing this is very
> inefficient.  Does anyone know a better way to produce a map similar to
> this?  I'm also interested in other suggestions of how to visualize these
> data.
>
> The example below shows my approach to this problem.  I believe the weak
> point of the code is my for loop.  I would like to increase efficiency, as
> I plan to use this approach on much larger datasets.  Thanks for your
> advice!
>
> -Andrew Vitale
>
> The example:
>
>
> library(raster)
>
> ## Create a set of random long/lat coordinates
> ## that are centred around a "metro" area.
> ## These data mimic the CSV of tweet coords I read in to R
> n = 500
> set.seed(232)
> x = rnorm(n, -96, 5)
> y = rnorm(n, 32, 5)
> xy = cbind(x, y)
>
> ## Create a SpatialPoints object of the "tweets"
> tweets = SpatialPoints(xy)
> proj4string(tweets) = CRS('+proj=longlat +datum=WGS84')
>
> ## Create an empty template raster for rasterizing the points and
> ## create an empty list to store each rasterized point
> r = raster(nrow=90, ncol=180)
> l = list()
>
> ## Loop through the tweets one point (row) at a time and create
> ## a raster with the value of 1 at the location of the tweet.
> ## Store the raster layers created for each tweet in a list.
> ## This loop is the slow part of my code. ##
> for(i in 1:length(tweets)){
>    p = tweets[i, ]
>    l[[i]] = rasterize(p, r)
> }
>
> ## Create a raster stack from the list
> s = stack(l)
>
> ## Sum the stack layers together ignoring NA values, which
> ## produces a raster layer of counts.  Set 0 values to NA
> counts = sum(s, na.rm=TRUE)
> counts[counts == 0] = NA
>
> ## Plot the raster layer
> plot(counts)
>

-- 

~$ whoami
Mathieu Basille
http://ase-research.org/basille

~$ locate --details
University of Florida \\
Fort Lauderdale Research and Education Center
(+1) 954-577-6314

~$ fortune
? Le tout est de tout dire, et je manque de mots
Et je manque de temps, et je manque d'audace. ?
  -- Paul ?luard


From r.hijmans at gmail.com  Fri Sep 12 02:25:18 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 11 Sep 2014 17:25:18 -0700
Subject: [R-sig-Geo] Distances from points to coast do not make sense.
In-Reply-To: <CALsJ7pT9XJ5Djips7cMk_iyhiZAE5=29NpOTO3V9nm+Y=G1qMQ@mail.gmail.com>
References: <CALsJ7pT9XJ5Djips7cMk_iyhiZAE5=29NpOTO3V9nm+Y=G1qMQ@mail.gmail.com>
Message-ID: <CANtt_hze-8xt-R4bYO-4aoQ=DkQtt2A+6OC2iBcxkYnD4B8nkg@mail.gmail.com>

The below seems to work correctly (albeit slowly).


library(maptools)
library(raster)
library(geosphere)

data(wrld_simpl)
w <- aggregate(wrld_simpl)
af = cbind(16, 13)
ng <- cbind(139, -4)
p <- rbind(af, ng)
dist2Line(p, w)


On Thu, Sep 11, 2014 at 4:13 PM, Agus Camacho <agus.camacho at gmail.com> wrote:
> I have two species, one is widespread in Africa (varanus niloticus) and the
> other is distributed across a region of new Guinea (Varanus prasinus). I
> calculated the mean distance to coast of their respective geographic
> records using the following script:
>
> x1 is a dataframe with two columns: Longitude and Latitude of geographic
> records
>
> meandist=rep(0,length(levels(x$Species)))
> distance=rep(NA,dim(x1)[1])
>
> for(n in 1:dim(x1)[1])
> {
>  distance[n]=(dist2Line(cbind(x1[n,1],x1[n,2]),LAcl,distfun=distVincentyEllipsoid)/1000)[1]
> }
> meandist=mean(distance)
>
> The problem is that geographic records from the african species is giving
> me shorter distances to the coast (mean=6677) than the species from new
> guinea(mean=12417). I already plotted the species records and checked there
> are not bizarre records. I can send the records for anyone insterested.
>
> Thanks in advance.
> Agus
>
>
>
> --
> Agust?n Camacho Guerrero.
> Doutor em Zoologia.
> Laborat?rio de Herpetologia, Departamento de Zoologia, Instituto de
> Bioci?ncias, USP.
> Rua do Mat?o, trav. 14, n? 321, Cidade Universit?ria,
> S?o Paulo - SP, CEP: 05508-090, Brasil.
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From frtog at vestas.com  Fri Sep 12 07:12:52 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Fri, 12 Sep 2014 07:12:52 +0200
Subject: [R-sig-Geo] 5-D Kernel density estimation in R using "kde"
 function
In-Reply-To: <1410465629.55153.YahooMailNeo@web125103.mail.ne1.yahoo.com>
References: <1410465629.55153.YahooMailNeo@web125103.mail.ne1.yahoo.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C7BEF61B@DKRDSEXC016.vestas.net>

Hi

Doesn't ?kde tell you all about specifying the grid at which you want your kernel density evaluated?

>From the man page for kde:

Details:

     For d=1, if 'h' is missing, the default bandwidth is 'hpi'.  For
     d>1, if 'H' is missing, the default is 'Hpi'.

     For d=1, 2, 3, 4, and if 'eval.points' is not specified, then the
     density estimate is computed over a grid defined by 'gridsize' (if
     'binned=FALSE') or by 'bgridsize' (if 'binned=TRUE').  If
     'eval.points' is specified, then the density estimate is computed
     exactly at 'eval.points'.  For d>4, the kernel density estimate is
     computed exactly and 'eval.points' must be specified.

     For d=1, if 'positive=TRUE' then 'x<-log(x+adj.positive)' where
     the default 'adj.positive' is the minimum of 'x'.

     The effective support for a normal kernel is 'supp', i.e.  all
     values outside '[-supp,supp]^d' are set to zero.

     The default 'xmin' is 'min(x)-Hmax*supp' and 'xmax' is
     'max(x)+Hmax*supp' where 'Hmax' is the maximum of the diagonal
     elements of 'H'. The grid produced is the outer product of
     '[xmin[1], xmax[1]]', ..., '[xmin[d], xmax[d]]'.

     The default 'bgridsize, gridsize' are d=1: 401; d=2: rep(151, 2);
     d=3: rep(31, 3); d=4: rep(21,4).

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> project.org] On Behalf Of Ferra Xu
> Sent: 11. september 2014 22:00
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] 5-D Kernel density estimation in R using "kde" function
> 
>  I want to perform Kernel density estimate for a 5-dimensional data
> (x,y,z,time,size) by using "kde" function in "ks" library of R. In it's manual it
> says it can do Kernel density estimate for 1- to
> 6-dimensional data (Page 24 of manual: http://cran.r-
> project.org/web/packages/ks/ks.pdf).
> My problem is that it says for more than 3 dimensions I need to
> specify eval.points. I don't know how can I specify the evaluation
> points because there is no example for more than 3 dimensions. For
> example if I want to generate equal boxes in the 3-D rectangular space
> of the problem and specify the center of each box as the eval-point,
> what should I do?
> Here is my data:
> 422.697323164.198862.4574198.0837966360.83367586423.008236163.324340.5
> 55132637.584774550.893893903204.733908218.363651.939787437.883243120.9
> 12809449203.963056218.48080.372379143.217759030.926406005100.72758146.
> 608761.402234149.415105190.782807523453.335182244.255211.629251751.737
> 791750.903910803134.909462210.963332.238911953.134335210.896529401135.
> 300562212.020550.673954167.550737450.748783521258.237117134.297352.120
> 529176.340325870.735699304341.305271149.269533.71895894.339754830.8495
> 09216307.13892559.605710.6311074106.96367150.987923188307.7687558.9145
> 32.6496741113.85153070.802115718415.025535217.173981.7155688115.746460
> 30.875580325414.977687216.733271.7107369115.97769480.767143582311.0061
> 35173.243782.7819572120.80795660.925380118310.116929174.281224.3318722
> 129.26484010.776528535347.26091137.349463.5155427136.78512910.85178711
> 5351.31762433.657030.5806926138.73492840.9097230174.47189259.420681.40
> 62959139.05437830.9672709765.48022359.728572.7326106139.2
> 1142770.987787428199.51302321.533022.5163259143.58956250.864164659198.
> 71803123.501630.4801849147.22804660.74158733326.65051735.20190.8246514
> 150.48765060.74478820225.08937990.478250.8700944152.19440460.777252476
> 26.30743988.415522.4422487155.90900260.952215177234.282901236.114221.8
> 115261155.96581440.776284654235.052948236.774371.9644963156.69002970.9
> 4428544823.04820298.62613.4573048159.77009120.77305749121.51669598.054
> 312.5029284160.82029970.978779087213.936324151.870133.1042192161.06124
> 890.80499513277.887935197.257531.3659279163.6731420.758978575277.23974
> 6197.540012.2109361166.26298680.775325157
> And this is the code that I am using:
> library(ks)library(rgl)kern <-read.table(file.choose(),sep=",")hat <-kde(kern)
> It works for up to 3 dimensions but for 4 and 5 dimensions it says:  need to
> specify eval.points for more than 3 dimensions.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From andreasft at gmail.com  Fri Sep 12 09:35:29 2014
From: andreasft at gmail.com (=?UTF-8?Q?Andreas_For=C3=B8_Tollefsen?=)
Date: Fri, 12 Sep 2014 09:35:29 +0200
Subject: [R-sig-Geo] knearneigh: data non-numeric
Message-ID: <CAGMz7D=a0Fw7Fd55dEha2NSFcZ64NH9nmBJdmpW-UdiJWmhEug@mail.gmail.com>

Hi all,

I have never experienced this issue before, but I assume there is something
in my spatialpolygondataframe causing this.
Whenever I try to create a knn object using these data, I get the error
"knearneigh: data non-numeric".

The code used:
knearneigh(gadmsimpl4_poly,k = 4,longlat = FALSE)
Error in knearneigh(gadmsimpl4_poly, k = 4, longlat = FALSE) :
knearneigh: data non-numeric

Any ideas what might be causing this error? I cannot remember seeing this
before.

Andreas

Metadata:
> class(gadmsimpl3_poly)
[1] "SpatialPolygonsDataFrame"
attr(,"package")
[1] "sp"
> length(colnames(gadmsimpl3_poly at data))
[1] 84
> length(gadmsimpl3_poly)
[1] 1095
> gadmsimpl3_poly at bbox
        min      max
x -25.36181 50.48654
y -34.63487 25.00001
> gadmsimpl3_poly at proj4string
CRS arguments:
 +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0

	[[alternative HTML version deleted]]


From frtog at vestas.com  Fri Sep 12 10:01:14 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Fri, 12 Sep 2014 10:01:14 +0200
Subject: [R-sig-Geo] knearneigh: data non-numeric
In-Reply-To: <CAGMz7D=a0Fw7Fd55dEha2NSFcZ64NH9nmBJdmpW-UdiJWmhEug@mail.gmail.com>
References: <CAGMz7D=a0Fw7Fd55dEha2NSFcZ64NH9nmBJdmpW-UdiJWmhEug@mail.gmail.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C7BEF73C@DKRDSEXC016.vestas.net>

Hi

You are showing metadata for gadmsimpl3_poly

But the error you see is for object gadmsimpl4_poly.

Does that have something to do with your problem?

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 

> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> project.org] On Behalf Of Andreas For? Tollefsen
> Sent: 12. september 2014 09:35
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] knearneigh: data non-numeric
> 
> Hi all,
> 
> I have never experienced this issue before, but I assume there is something
> in my spatialpolygondataframe causing this.
> Whenever I try to create a knn object using these data, I get the error
> "knearneigh: data non-numeric".
> 
> The code used:
> knearneigh(gadmsimpl4_poly,k = 4,longlat = FALSE)
> Error in knearneigh(gadmsimpl4_poly, k = 4, longlat = FALSE) :
> knearneigh: data non-numeric
> 
> Any ideas what might be causing this error? I cannot remember seeing this
> before.
> 
> Andreas
> 
> Metadata:
> > class(gadmsimpl3_poly)
> [1] "SpatialPolygonsDataFrame"
> attr(,"package")
> [1] "sp"
> > length(colnames(gadmsimpl3_poly at data))
> [1] 84
> > length(gadmsimpl3_poly)
> [1] 1095
> > gadmsimpl3_poly at bbox
>         min      max
> x -25.36181 50.48654
> y -34.63487 25.00001
> > gadmsimpl3_poly at proj4string
> CRS arguments:
>  +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From edzer.pebesma at uni-muenster.de  Fri Sep 12 10:06:02 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 12 Sep 2014 10:06:02 +0200
Subject: [R-sig-Geo] knearneigh: data non-numeric
In-Reply-To: <CAGMz7D=a0Fw7Fd55dEha2NSFcZ64NH9nmBJdmpW-UdiJWmhEug@mail.gmail.com>
References: <CAGMz7D=a0Fw7Fd55dEha2NSFcZ64NH9nmBJdmpW-UdiJWmhEug@mail.gmail.com>
Message-ID: <5412A96A.4000704@uni-muenster.de>

if this is knearneigh in spdep, the documentations says:

     knearneigh(x, k=1, longlat = NULL, RANN=TRUE)

Arguments:

       x: matrix of point coordinates or a SpatialPoints object
       ...

if the documentation is correct, it should not work with spatial
polygons objects for x. Maybe you meant:

knearneigh(coordinates(gadmsimpl4_poly), k = 4, longlat = FALSE)

in order to find the knn's from the polygon centroids?

On 09/12/2014 09:35 AM, Andreas For? Tollefsen wrote:
> Hi all,
> 
> I have never experienced this issue before, but I assume there is something
> in my spatialpolygondataframe causing this.
> Whenever I try to create a knn object using these data, I get the error
> "knearneigh: data non-numeric".
> 
> The code used:
> knearneigh(gadmsimpl4_poly,k = 4,longlat = FALSE)
> Error in knearneigh(gadmsimpl4_poly, k = 4, longlat = FALSE) :
> knearneigh: data non-numeric
> 
> Any ideas what might be causing this error? I cannot remember seeing this
> before.
> 
> Andreas
> 
> Metadata:
>> class(gadmsimpl3_poly)
> [1] "SpatialPolygonsDataFrame"
> attr(,"package")
> [1] "sp"
>> length(colnames(gadmsimpl3_poly at data))
> [1] 84
>> length(gadmsimpl3_poly)
> [1] 1095
>> gadmsimpl3_poly at bbox
>         min      max
> x -25.36181 50.48654
> y -34.63487 25.00001
>> gadmsimpl3_poly at proj4string
> CRS arguments:
>  +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140912/5ce451bb/attachment.bin>

From Roger.Bivand at nhh.no  Fri Sep 12 10:06:46 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 12 Sep 2014 10:06:46 +0200
Subject: [R-sig-Geo] knearneigh: data non-numeric
In-Reply-To: <CAGMz7D=a0Fw7Fd55dEha2NSFcZ64NH9nmBJdmpW-UdiJWmhEug@mail.gmail.com>
References: <CAGMz7D=a0Fw7Fd55dEha2NSFcZ64NH9nmBJdmpW-UdiJWmhEug@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1409120956260.17207@reclus.nhh.no>

On Fri, 12 Sep 2014, Andreas For? Tollefsen wrote:

> Hi all,
>
> I have never experienced this issue before, but I assume there is something
> in my spatialpolygondataframe causing this.
> Whenever I try to create a knn object using these data, I get the error
> "knearneigh: data non-numeric".

Which versions of the function actually worked with a 
SpatialPolygonsDataFrame? As far as I can see, this has always failed with 
the same error message; since 2007 x can be an object inheriting from 
SpatialPoints.

The justification is to oblige the user to acknowledge that while point 
support is accepted without question, the change of support from areal to 
point is something the user needs to take responsibility for, for example 
using coordinates() to extract the label point of the largest exterior 
ring in the Polygons object.

Hope this clarifies,

Roger

>
> The code used:
> knearneigh(gadmsimpl4_poly,k = 4,longlat = FALSE)
> Error in knearneigh(gadmsimpl4_poly, k = 4, longlat = FALSE) :
> knearneigh: data non-numeric
>
> Any ideas what might be causing this error? I cannot remember seeing this
> before.
>
> Andreas
>
> Metadata:
>> class(gadmsimpl3_poly)
> [1] "SpatialPolygonsDataFrame"
> attr(,"package")
> [1] "sp"
>> length(colnames(gadmsimpl3_poly at data))
> [1] 84
>> length(gadmsimpl3_poly)
> [1] 1095
>> gadmsimpl3_poly at bbox
>        min      max
> x -25.36181 50.48654
> y -34.63487 25.00001
>> gadmsimpl3_poly at proj4string
> CRS arguments:
> +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From andreasft at gmail.com  Fri Sep 12 10:11:12 2014
From: andreasft at gmail.com (=?UTF-8?Q?Andreas_For=C3=B8_Tollefsen?=)
Date: Fri, 12 Sep 2014 10:11:12 +0200
Subject: [R-sig-Geo] knearneigh: data non-numeric
In-Reply-To: <alpine.LRH.2.03.1409120956260.17207@reclus.nhh.no>
References: <CAGMz7D=a0Fw7Fd55dEha2NSFcZ64NH9nmBJdmpW-UdiJWmhEug@mail.gmail.com>
	<alpine.LRH.2.03.1409120956260.17207@reclus.nhh.no>
Message-ID: <CAGMz7DmHCH1vi5DeQxc+hB2+dcdFbktA7bpbMLptLSLtbp1grw@mail.gmail.com>

Absolutely. I think it was just too early in the morning.
I forgot the difference between using poly2nb and knearneigh.
Using coordinates() works fine.

Sorry for the confusion.


2014-09-12 10:06 GMT+02:00 Roger Bivand <Roger.Bivand at nhh.no>:

> On Fri, 12 Sep 2014, Andreas For? Tollefsen wrote:
>
>  Hi all,
>>
>> I have never experienced this issue before, but I assume there is
>> something
>> in my spatialpolygondataframe causing this.
>> Whenever I try to create a knn object using these data, I get the error
>> "knearneigh: data non-numeric".
>>
>
> Which versions of the function actually worked with a
> SpatialPolygonsDataFrame? As far as I can see, this has always failed with
> the same error message; since 2007 x can be an object inheriting from
> SpatialPoints.
>
> The justification is to oblige the user to acknowledge that while point
> support is accepted without question, the change of support from areal to
> point is something the user needs to take responsibility for, for example
> using coordinates() to extract the label point of the largest exterior ring
> in the Polygons object.
>
> Hope this clarifies,
>
> Roger
>
>
>> The code used:
>> knearneigh(gadmsimpl4_poly,k = 4,longlat = FALSE)
>> Error in knearneigh(gadmsimpl4_poly, k = 4, longlat = FALSE) :
>> knearneigh: data non-numeric
>>
>> Any ideas what might be causing this error? I cannot remember seeing this
>> before.
>>
>> Andreas
>>
>> Metadata:
>>
>>> class(gadmsimpl3_poly)
>>>
>> [1] "SpatialPolygonsDataFrame"
>> attr(,"package")
>> [1] "sp"
>>
>>> length(colnames(gadmsimpl3_poly at data))
>>>
>> [1] 84
>>
>>> length(gadmsimpl3_poly)
>>>
>> [1] 1095
>>
>>> gadmsimpl3_poly at bbox
>>>
>>        min      max
>> x -25.36181 50.48654
>> y -34.63487 25.00001
>>
>>> gadmsimpl3_poly at proj4string
>>>
>> CRS arguments:
>> +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>

	[[alternative HTML version deleted]]


From vitale232 at gmail.com  Fri Sep 12 17:31:56 2014
From: vitale232 at gmail.com (Andrew Vitale)
Date: Fri, 12 Sep 2014 08:31:56 -0700
Subject: [R-sig-Geo] Create raster layer that counts SpatialPoint
 occurrence within cells
In-Reply-To: <54123A3E.3010901@ase-research.org>
References: <CAFTcopfCzMV8bg3X6g6bTUNPDWHkd_-3B=wptjozfVj1ygxv-g@mail.gmail.com>
	<54123A3E.3010901@ase-research.org>
Message-ID: <CAFTcopfYwwV2eQ_ji58NoO6ucQq-ez9g-aFgz_WcYxErdGV4FQ@mail.gmail.com>

Thanks for the answers!  Robert's answer gives a tremendous increase in
speed.

Original code:
   user  system elapsed
  5.344   0.123   5.488

Robert's code:
   user  system elapsed
  0.170   0.002   0.173



On Thu, Sep 11, 2014 at 5:11 PM, Mathieu Basille <
basille.web at ase-research.org> wrote:

> Hi Andrew,
>
> The answer from Robert is very neat! Alternatively, you may also have a
> look at `count.points` in the package adehabitatMA (which was developed for
> animal locations!). Here is a working example from the vignette (p.17):
>
> library(adehabitatMA)
>
> ## Load the data
> data(lynxjura)
>
> ## `map` is a SpatialPixelsDataFrame
> map <- lynxjura$map
> class(map)
>
> ## `locs` is a SpatialPointsDataFrame
> locs <- lynxjura$loc
> class(locs)
>
> ## Plot the map + points
> image(map, 1)
> points(locs, pch=3)
>
> ## Count the number of points per pixel and map the result
> cp <- count.points(locs, map)
> image(cp)
>
> ## `cp` is a SpatialPixelsDataFrame
> class(cp)
>
> Hope this helps,
> Mathieu.
>
>
> Le 11/09/2014 19:01, Andrew Vitale a ?crit :
>
>> Hello all,
>>
>>
>> I have a Python script that searches Twitter for tweets that meet certain
>> criteria and records the coordinates of those tweets.  This leaves me with
>> a CSV that can then easily be read into R as a SpatialPoints object.
>>
>> Once I have the SpatialPoints, I would like to make a raster layer that
>> has
>> the count of tweet locations that occur within each cell of that raster
>> layer.
>>
>> I have a working script, but I feel like my way of doing this is very
>> inefficient.  Does anyone know a better way to produce a map similar to
>> this?  I'm also interested in other suggestions of how to visualize these
>> data.
>>
>> The example below shows my approach to this problem.  I believe the weak
>> point of the code is my for loop.  I would like to increase efficiency, as
>> I plan to use this approach on much larger datasets.  Thanks for your
>> advice!
>>
>> -Andrew Vitale
>>
>> The example:
>>
>>
>> library(raster)
>>
>> ## Create a set of random long/lat coordinates
>> ## that are centred around a "metro" area.
>> ## These data mimic the CSV of tweet coords I read in to R
>> n = 500
>> set.seed(232)
>> x = rnorm(n, -96, 5)
>> y = rnorm(n, 32, 5)
>> xy = cbind(x, y)
>>
>> ## Create a SpatialPoints object of the "tweets"
>> tweets = SpatialPoints(xy)
>> proj4string(tweets) = CRS('+proj=longlat +datum=WGS84')
>>
>> ## Create an empty template raster for rasterizing the points and
>> ## create an empty list to store each rasterized point
>> r = raster(nrow=90, ncol=180)
>> l = list()
>>
>> ## Loop through the tweets one point (row) at a time and create
>> ## a raster with the value of 1 at the location of the tweet.
>> ## Store the raster layers created for each tweet in a list.
>> ## This loop is the slow part of my code. ##
>> for(i in 1:length(tweets)){
>>    p = tweets[i, ]
>>    l[[i]] = rasterize(p, r)
>> }
>>
>> ## Create a raster stack from the list
>> s = stack(l)
>>
>> ## Sum the stack layers together ignoring NA values, which
>> ## produces a raster layer of counts.  Set 0 values to NA
>> counts = sum(s, na.rm=TRUE)
>> counts[counts == 0] = NA
>>
>> ## Plot the raster layer
>> plot(counts)
>>
>>
> --
>
> ~$ whoami
> Mathieu Basille
> http://ase-research.org/basille
>
> ~$ locate --details
> University of Florida \\
> Fort Lauderdale Research and Education Center
> (+1) 954-577-6314
>
> ~$ fortune
> ? Le tout est de tout dire, et je manque de mots
> Et je manque de temps, et je manque d'audace. ?
>  -- Paul ?luard
>
>


-- 
*Andrew P. Vitale*
Masters Student
Department of Geography
University of Nevada, Reno
vitale232 at gmail.com

	[[alternative HTML version deleted]]


From afischbach at usgs.gov  Fri Sep 12 20:14:24 2014
From: afischbach at usgs.gov (Anthony Fischbach)
Date: Fri, 12 Sep 2014 11:14:24 -0700 (PDT)
Subject: [R-sig-Geo] plotKML organizing folders
Message-ID: <1410545664528-7587119.post@n2.nabble.com>

I wish to allow users of my kml to select specific classes of entities by
folders within the virtual globe display.
For example (using the standard plotKML dataset) I wish to allow users to
select 'class A' and 'class B' bigfoot sightings by selecting folders that
have intuitive names.

## Toy example:
require(plotKML)
require(sp)
data(bigfoot) ## Load standard dataframe 
bigfootA<-head(bigfoot) ## grab the top of the dataframe, which has class A
sightings
bigfootB<-tail(bigfoot)  ## grab the bottom of the dataframe, which has
class B sightings
## cast both dataframes into spatialPointsDataFrames with defined coordinate
reference systems
coordinates(bigfootA)<-c('Lon','Lat') ## Cast as spatial points dataframe
proj4string(bigfootA)<-CRS("+proj=longlat +ellps=WGS84 +datum=WGS84
+no_defs")  ## assign a coordinate reference system
coordinates(bigfootB)<-c('Lon','Lat') ## Cast as spatial points dataframe
proj4string(bigfootB)<-CRS("+proj=longlat +ellps=WGS84 +datum=WGS84
+no_defs")  ## assign a coordinate reference system

kml_open(file.name='BigWithFolders.kml', folder.name = 'Big Foot',
kml_visibility=TRUE )
	## Build the points by each class
		kml_layer.SpatialPoints(obj=bigfootA, points_names=bigfootA at data$NAMES, 
			colour='green',  LabelScale=0.8, 
			shape='http://plotkml.r-forge.r-project.org/3Dballyellow.png',
			alpha=0.6, balloon=TRUE) ##  
		kml_layer.SpatialPoints(obj=bigfootB, points_names=bigfootB at data$NAMES, 
			colour='yellow',  LabelScale=0.8, 
			shape='http://plotkml.r-forge.r-project.org/3Dballyellow.png',
			alpha=0.6, balloon=TRUE) ##  
			
kml_close(file.name='BigWithFolders.kml')
### End Toy example

This produces the kml with two folders, both named 'SpatialPointsDataFrame'.
Is there a way to set the names of each subordinate folder?



-----
Tony Fischbach, Wildlife Biologist
Walrus Research Program
Alaska Science Center
U.S. Geological Survey
4210 University Drive
Anchorage, AK 99508-4650

AFischbach at usgs.gov
http://alaska.usgs.gov/science/biology/walrus
--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/plotKML-organizing-folders-tp7587119.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From bernd.vogelgesang at gmx.de  Sat Sep 13 19:04:06 2014
From: bernd.vogelgesang at gmx.de (Bernd Vogelgesang)
Date: Sat, 13 Sep 2014 19:04:06 +0200
Subject: [R-sig-Geo] Intended usage of gIntersection ?
Message-ID: <op.xl4xo4ayl2i25i@bernd-terra-pc>

Dear list,

I'm trying to intersect two SpatialPolygonsDataFrames imported from shape  
files. (readOGR)
The idea is to get the new polygons + the merged attributes of both  
layers, but the outcome is a SpatialPolygon class without a data slot.

Is this the intended behaviour of gIntersection or is there something  
broken in my R-Installation, cause I googled now for 2 days to find a  
solution on that problem, but only found two hits on stackexchange where  
people had similar problems, and no working solution (at least for me),  
nor was I able to find any standard recipt how to join the attributes back  
to the new polygons.

So obviously only rare people seem to have the need to get also the data  
 from an intersection or do I miss some really basic R-capabilities not  
worth to write down in any documentation??

Hope someone can shed some light
Thanks
Bernd

-- 
Bernd Vogelgesang
Siedlerstra?e 2
91083 Baiersdorf/Igelsdorf
Tel: 09133-825374


From r.hijmans at gmail.com  Sat Sep 13 19:44:50 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sat, 13 Sep 2014 10:44:50 -0700
Subject: [R-sig-Geo] Intended usage of gIntersection ?
In-Reply-To: <op.xl4xo4ayl2i25i@bernd-terra-pc>
References: <op.xl4xo4ayl2i25i@bernd-terra-pc>
Message-ID: <CANtt_hwJAoOx3ZVOmCnFu248QwdR0q7Q+UVQw-3f+mQgs7M=XA@mail.gmail.com>

The raster package has a few functions that extend rgeos by also
attempting to handle attribute data as well. In this case, see
raster::intersect
And the list of functions here:
?"raster-package"
(section XIV)

Robert

On Sat, Sep 13, 2014 at 10:04 AM, Bernd Vogelgesang
<bernd.vogelgesang at gmx.de> wrote:
> Dear list,
>
> I'm trying to intersect two SpatialPolygonsDataFrames imported from shape
> files. (readOGR)
> The idea is to get the new polygons + the merged attributes of both layers,
> but the outcome is a SpatialPolygon class without a data slot.
>
> Is this the intended behaviour of gIntersection or is there something broken
> in my R-Installation, cause I googled now for 2 days to find a solution on
> that problem, but only found two hits on stackexchange where people had
> similar problems, and no working solution (at least for me), nor was I able
> to find any standard recipt how to join the attributes back to the new
> polygons.
>
> So obviously only rare people seem to have the need to get also the data
> from an intersection or do I miss some really basic R-capabilities not worth
> to write down in any documentation??
>
> Hope someone can shed some light
> Thanks
> Bernd
>
> --
> Bernd Vogelgesang
> Siedlerstra?e 2
> 91083 Baiersdorf/Igelsdorf
> Tel: 09133-825374
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Sat Sep 13 21:07:06 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 13 Sep 2014 21:07:06 +0200
Subject: [R-sig-Geo] Intended usage of gIntersection ?
In-Reply-To: <op.xl4xo4ayl2i25i@bernd-terra-pc>
References: <op.xl4xo4ayl2i25i@bernd-terra-pc>
Message-ID: <alpine.LRH.2.03.1409132057370.28459@reclus.nhh.no>

On Sat, 13 Sep 2014, Bernd Vogelgesang wrote:

> Dear list,
>
> I'm trying to intersect two SpatialPolygonsDataFrames imported from shape 
> files. (readOGR)
> The idea is to get the new polygons + the merged attributes of both 
> layers, but the outcome is a SpatialPolygon class without a data slot.

Since there are no general matches between intersected spatial objects, 
any arbitrary operations on attributes require assumptions about unknown 
user intentions. This is why no data slots should be passed through.

If the attributes are just identifiers and the intersection operation used 
byid=TRUE or at least one of the byid was TRUE, then they are easy to 
retreive using the string value of the ro.names() of the intersection 
objects. If they are say counts, or any other aggregate value belonging to 
the input objects, until someone decides how to transfer the value, nobody 
can know. Say one intersected object looses 75% of its area - should the 
numerical attributes be reduced by 75%?

The design of gIntesection() is inentional, because only the user can know 
what to do with attributes of entities that have their geometries changed. 
Different users may make different assumptions, but there is no general 
solution beyond passing through the IDs of the intersecting geometries, as 
is done in the row.names() mechanism.

Hope this clarifies,

Roger

>
> Is this the intended behaviour of gIntersection or is there something 
> broken in my R-Installation, cause I googled now for 2 days to find a 
> solution on that problem, but only found two hits on stackexchange where 
> people had similar problems, and no working solution (at least for me), 
> nor was I able to find any standard recipt how to join the attributes back 
> to the new polygons.
>
> So obviously only rare people seem to have the need to get also the data 
> from an intersection or do I miss some really basic R-capabilities not 
> worth to write down in any documentation??
>
> Hope someone can shed some light
> Thanks
> Bernd
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From bernd.vogelgesang at gmx.de  Sat Sep 13 21:58:59 2014
From: bernd.vogelgesang at gmx.de (Bernd Vogelgesang)
Date: Sat, 13 Sep 2014 21:58:59 +0200
Subject: [R-sig-Geo] Intended usage of gIntersection ?
In-Reply-To: <CANtt_hwJAoOx3ZVOmCnFu248QwdR0q7Q+UVQw-3f+mQgs7M=XA@mail.gmail.com>
References: <op.xl4xo4ayl2i25i@bernd-terra-pc>
	<CANtt_hwJAoOx3ZVOmCnFu248QwdR0q7Q+UVQw-3f+mQgs7M=XA@mail.gmail.com>
Message-ID: <op.xl45slygl2i25i@bernd-terra-pc>

Hi Robert,

GREAT! It works!
I think you saved my week(end).
Would have never guessed that the raster package will do such things, so I  
completely avoided to search in such a direction.

Maybe I will learn to do the trick with gIntersection one day, but for  
today, I'm on the winner street again with raster intersect, Crazy!

Cheers
Bernd

Am 13.09.2014, 19:44 Uhr, schrieb Robert J. Hijmans <r.hijmans at gmail.com>:

> The raster package has a few functions that extend rgeos by also
> attempting to handle attribute data as well. In this case, see
> raster::intersect
> And the list of functions here:
> ?"raster-package"
> (section XIV)
>
> Robert
>
> On Sat, Sep 13, 2014 at 10:04 AM, Bernd Vogelgesang
> <bernd.vogelgesang at gmx.de> wrote:
>> Dear list,
>>
>> I'm trying to intersect two SpatialPolygonsDataFrames imported from  
>> shape
>> files. (readOGR)
>> The idea is to get the new polygons + the merged attributes of both  
>> layers,
>> but the outcome is a SpatialPolygon class without a data slot.
>>
>> Is this the intended behaviour of gIntersection or is there something  
>> broken
>> in my R-Installation, cause I googled now for 2 days to find a solution  
>> on
>> that problem, but only found two hits on stackexchange where people had
>> similar problems, and no working solution (at least for me), nor was I  
>> able
>> to find any standard recipt how to join the attributes back to the new
>> polygons.
>>
>> So obviously only rare people seem to have the need to get also the data
>> from an intersection or do I miss some really basic R-capabilities not  
>> worth
>> to write down in any documentation??
>>
>> Hope someone can shed some light
>> Thanks
>> Bernd
>>
>> --
>> Bernd Vogelgesang
>> Siedlerstra?e 2
>> 91083 Baiersdorf/Igelsdorf
>> Tel: 09133-825374
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


-- 
Bernd Vogelgesang
Siedlerstra?e 2
91083 Baiersdorf/Igelsdorf
Tel: 09133-825374


From txomingo99 at gmail.com  Sun Sep 14 11:36:29 2014
From: txomingo99 at gmail.com (DAlcaraz)
Date: Sun, 14 Sep 2014 02:36:29 -0700 (PDT)
Subject: [R-sig-Geo] Does plotKML handle skewed diverging continuous raster?
Message-ID: <1410687389252-7587124.post@n2.nabble.com>

Hi,
First of all, thank you very much for your great job with the plotKML
package for R. It is simply GREAT!!!
However, I've been fighting during one week with this issue and I wonder
whether the package still does not handle it.
How can a plot a kml from a raster whose values show deviations from 0, but
follow an skewed distribution? 
Ideally, I would like negative values in reds, positive values in blues, and
zero values in grey.

Thank you very much in advance for your help.
Domingo

PS: I've pasted below a trivial example showing how the "plot" function can
handle this issue but the plotKML does not.

install.packages("raster", dep=T)
install.packages("RColorBrewer", dep=T)
install.packages("plotKML", dep=T)
library(raster)
library(RColorBrewer)
library(plotKML)

r<- raster(ncol=5,nrow=2)
values(r) <- c(-5,-4,-1,0,0,3,-2,-6,-6,-6) #Positive and Negative changes
as.matrix(r)
hist(r, main="Diverging skewed distribution of raster data")

DivColorBreaks <- c(-6,-3,-0.1,0.1,3,6)# 
NDivBreaks <- length(DivColorBreaks)-1 
DivColPalette <- colorRampPalette((brewer.pal(NDivBreaks, "RdBu")),
space="Lab")
DivCols <- DivColPalette(NDivBreaks)

plot(r, useRaster=FALSE,
     col=  DivCols, breaks=DivColorBreaks)
#In the plot graph:
#pixel r1,c3 = -1 is in reds. CORRECT
#pixels r1,c4&5 = 0 are in grey. CORRECT

kml_open("DivSkewd.kml")
kml_layer.Raster(r, plot.legend = TRUE, metadata = NULL,  
                 png.width = ncol(r), png.height = nrow(r), 
                 min.png.width = 800, 
                 colour_scale =  DivCols, #the problem must be here?
                 #Here I would need sth like "breaks=DivColorBreaks"
                 raster_name="DivSkewd.png")    
kml_close("DivSkewd.kml")
#In DivSkewd.png:
#pixel r1,c3 = -1 is in grey. INCORRECT
#pixels r1,c4&5 = 0 are in blue. INCORRECT

#How could I plot the raster so that it fairly displays 
#which pixels have negative values in red and positive values in blue?



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Does-plotKML-handle-skewed-diverging-continuous-raster-tp7587124.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From b.rowlingson at lancaster.ac.uk  Sun Sep 14 12:28:38 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sun, 14 Sep 2014 11:28:38 +0100
Subject: [R-sig-Geo] Intended usage of gIntersection ?
In-Reply-To: <f9198423d5c54208964f7514c7d7adfe@EX-1-HT0.lancs.local>
References: <op.xl4xo4ayl2i25i@bernd-terra-pc>
	<CANtt_hwJAoOx3ZVOmCnFu248QwdR0q7Q+UVQw-3f+mQgs7M=XA@mail.gmail.com>
	<f9198423d5c54208964f7514c7d7adfe@EX-1-HT0.lancs.local>
Message-ID: <CANVKczOYrLVAbaao82wWzCr2cxBdcv2jaFBB4dQxf0evVZYcWQ@mail.gmail.com>

I think we should merge and unify sp, rgdal, rgeos and raster...

 > require(gis)

/dreams


On Sat, Sep 13, 2014 at 8:58 PM, Bernd Vogelgesang
<bernd.vogelgesang at gmx.de> wrote:
> Hi Robert,
>
> GREAT! It works!
> I think you saved my week(end).
> Would have never guessed that the raster package will do such things, so I
> completely avoided to search in such a direction.
>
> Maybe I will learn to do the trick with gIntersection one day, but for
> today, I'm on the winner street again with raster intersect, Crazy!
>
> Cheers
> Bernd
>
> Am 13.09.2014, 19:44 Uhr, schrieb Robert J. Hijmans <r.hijmans at gmail.com>:
>
>> The raster package has a few functions that extend rgeos by also
>> attempting to handle attribute data as well. In this case, see
>> raster::intersect
>> And the list of functions here:
>> ?"raster-package"
>> (section XIV)
>>
>> Robert
>>
>> On Sat, Sep 13, 2014 at 10:04 AM, Bernd Vogelgesang
>> <bernd.vogelgesang at gmx.de> wrote:
>>> Dear list,
>>>
>>> I'm trying to intersect two SpatialPolygonsDataFrames imported from
>>> shape
>>> files. (readOGR)
>>> The idea is to get the new polygons + the merged attributes of both
>>> layers,
>>> but the outcome is a SpatialPolygon class without a data slot.
>>>
>>> Is this the intended behaviour of gIntersection or is there something
>>> broken
>>> in my R-Installation, cause I googled now for 2 days to find a solution
>>> on
>>> that problem, but only found two hits on stackexchange where people had
>>> similar problems, and no working solution (at least for me), nor was I
>>> able
>>> to find any standard recipt how to join the attributes back to the new
>>> polygons.
>>>
>>> So obviously only rare people seem to have the need to get also the data
>>> from an intersection or do I miss some really basic R-capabilities not
>>> worth
>>> to write down in any documentation??
>>>
>>> Hope someone can shed some light
>>> Thanks
>>> Bernd
>>>
>>> --
>>> Bernd Vogelgesang
>>> Siedlerstra?e 2
>>> 91083 Baiersdorf/Igelsdorf
>>> Tel: 09133-825374
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> --
> Bernd Vogelgesang
> Siedlerstra?e 2
> 91083 Baiersdorf/Igelsdorf
> Tel: 09133-825374
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From hengl at spatial-analyst.net  Sun Sep 14 14:16:54 2014
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Sun, 14 Sep 2014 14:16:54 +0200
Subject: [R-sig-Geo] Does plotKML handle skewed diverging continuous
	raster?
In-Reply-To: <1410687389252-7587124.post@n2.nabble.com>
References: <1410687389252-7587124.post@n2.nabble.com>
Message-ID: <54158736.5000407@spatial-analyst.net>


You need to classify the data using the 'cut' function e.g.:

library(RColorBrewer)
library(plotKML)
data(eberg_grid)
gridded(eberg_grid) <- ~x+y
proj4string(eberg_grid) <- CRS("+init=epsg:31467")
eberg_grid$r <- eberg_grid$TWISRT6-mean(eberg_grid$TWISRT6)
DivColPalette <- colorRampPalette((brewer.pal(NDivBreaks, "RdBu")),
space="Lab")
DivColorBreaks <- c(min(eberg_grid$r),-1,-0.1,0.1,1,max(eberg_grid$r))
eberg_grid$rc <- cut(eberg_grid$r, breaks=DivColorBreaks, 
include.lowest=TRUE)
summary(eberg_grid$rc)
plotKML(eberg_grid["rc"], 
colour_scale=DivColPalette(length(levels(eberg_grid$rc))))

I've just discovered a small bug in my 'reproject.R' script that 
re-orders the class names, so you will need to get plotKML Version: 
0.4-6 from R-forge to get exactly what you look for:

install.packages("plotKML", repos=c("http://R-Forge.R-project.org"))

HTH,

T. Hengl

On 14-9-2014 11:36, DAlcaraz wrote:
> Hi,
> First of all, thank you very much for your great job with the plotKML
> package for R. It is simply GREAT!!!
> However, I've been fighting during one week with this issue and I wonder
> whether the package still does not handle it.
> How can a plot a kml from a raster whose values show deviations from 0, but
> follow an skewed distribution?
> Ideally, I would like negative values in reds, positive values in blues, and
> zero values in grey.
>
> Thank you very much in advance for your help.
> Domingo
>
> PS: I've pasted below a trivial example showing how the "plot" function can
> handle this issue but the plotKML does not.
>
> install.packages("raster", dep=T)
> install.packages("RColorBrewer", dep=T)
> install.packages("plotKML", dep=T)
> library(raster)
> library(RColorBrewer)
> library(plotKML)
>
> r<- raster(ncol=5,nrow=2)
> values(r) <- c(-5,-4,-1,0,0,3,-2,-6,-6,-6) #Positive and Negative changes
> as.matrix(r)
> hist(r, main="Diverging skewed distribution of raster data")
>
> DivColorBreaks <- c(-6,-3,-0.1,0.1,3,6)#
> NDivBreaks <- length(DivColorBreaks)-1
> DivColPalette <- colorRampPalette((brewer.pal(NDivBreaks, "RdBu")),
> space="Lab")
> DivCols <- DivColPalette(NDivBreaks)
>
> plot(r, useRaster=FALSE,
>       col=  DivCols, breaks=DivColorBreaks)
> #In the plot graph:
> #pixel r1,c3 = -1 is in reds. CORRECT
> #pixels r1,c4&5 = 0 are in grey. CORRECT
>
> kml_open("DivSkewd.kml")
> kml_layer.Raster(r, plot.legend = TRUE, metadata = NULL,
>                   png.width = ncol(r), png.height = nrow(r),
>                   min.png.width = 800,
>                   colour_scale =  DivCols, #the problem must be here?
>                   #Here I would need sth like "breaks=DivColorBreaks"
>                   raster_name="DivSkewd.png")
> kml_close("DivSkewd.kml")
> #In DivSkewd.png:
> #pixel r1,c3 = -1 is in grey. INCORRECT
> #pixels r1,c4&5 = 0 are in blue. INCORRECT
>
> #How could I plot the raster so that it fairly displays
> #which pixels have negative values in red and positive values in blue?
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Does-plotKML-handle-skewed-diverging-continuous-raster-tp7587124.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From md.franklin at gmail.com  Sun Sep 14 16:58:37 2014
From: md.franklin at gmail.com (frankma)
Date: Sun, 14 Sep 2014 07:58:37 -0700 (PDT)
Subject: [R-sig-Geo] SpatioTemporal package error
Message-ID: <1410706717877-7587127.post@n2.nabble.com>

Dear all,

I'm using the SpatioTemporal package
(http://cran.r-project.org/web/packages/SpatioTemporal/vignettes/ST_tutorial.pdf)
which is fantastic for spatio-temporal analysis however I've come across
hurdle that I cannot get over at the moment. Any help that anyone may be
able to give would be greatly appreciated.

I am afraid that my ignorance is likely causing a simple error, however, I
have not been able to resolve it.

Whilst estimating parameters I use:

model.dim <- loglikeSTdim(mesa.model)
str(model.dim) 

and return:

List of 12
 $ T              : int 48
 $ m              : int 2
 $ n              : int 26
 $ n.obs          : int 26
 $ p              : Named int [1:2] 4 2
  ..- attr(*, "names")= chr [1:2] "const" "V1"
 $ L              : int 1
 $ npars.beta.covf: Named int [1:2] 2 2
  ..- attr(*, "names")= chr [1:2] "exp" "exp"
 $ npars.beta.tot : Named int [1:2] 2 2
  ..- attr(*, "names")= chr [1:2] "exp" "exp"
 $ npars.nu.covf  : int 2
 $ npars.nu.tot   : int 3
 $ nparam.cov     : int 7
 $ nparam         : int 14


Then attempt to set up the model using these starting values (I have tried
countless others):

x.init <- cbind(c( rep(2, model.dim$nparam.cov-1), 2),c( rep(c(1,-2),
model.dim$m+1),1))

rownames(x.init) <- loglikeSTnames(mesa.model, all=FALSE)

est.mesa.model <- estimate(mesa.model, x.init,type="p", hessian.all=TRUE)
Optimisation using starting value 1/2
N = 7, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       1764.7  |proj g|=           17
At iterate    10  f =      -1868.3  |proj g|=        0.8506

iterations 13
function evaluations 20
segments explored during Cauchy searches 17
BFGS updates skipped 0
active bounds at final generalized Cauchy point 0
norm of the final projected gradient 0.0222348
final function value -1868.35

F = -1868.35
final  value -1868.352505 
converged

Error in diag(solve(res[[i]]$hessian)) : 
  error in evaluating the argument 'x' in selecting a method for function
'diag': Error in solve.default(res[[i]]$hessian) : 
  Lapack routine dgesv: system is exactly singular: U[1,1] = 0

The error above seems simple but I can't figure out how it occurs. Any help
you can give would be greatly appreciated.

Kind regards,

Matthew Franklin
University of Sheffield



-----
Matthew Franklin
School of Mathematics and Statistics
University of Sheffield
--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/SpatioTemporal-package-error-tp7587127.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From HodgessE at uhd.edu  Mon Sep 15 20:10:03 2014
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Mon, 15 Sep 2014 18:10:03 +0000
Subject: [R-sig-Geo] krigeST question (yet again!)
Message-ID: <FF9DB805FC41CC4E95825A50F68063021AA9C5CA@columbia.uhd.campus>

Hello r-Sig-Geo-ers!



I have a goofy question (surprise!), please:



When we use krigeST, we can predict spatially in many locations other than the original data locations.  Can we also predict temporally farther out, please?  For instance, say my data set runs from Jan 2014 - Aug 2014, and I want to predict from Sep - Oct 2014.  Could I set that up in in my prediction set (such that it would be "reasonable"), please?



Thanks,

Sincerely,

Erin



	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Mon Sep 15 21:11:05 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 15 Sep 2014 21:11:05 +0200
Subject: [R-sig-Geo] krigeST question (yet again!)
In-Reply-To: <FF9DB805FC41CC4E95825A50F68063021AA9C5CA@columbia.uhd.campus>
References: <FF9DB805FC41CC4E95825A50F68063021AA9C5CA@columbia.uhd.campus>
Message-ID: <541739C9.9040805@uni-muenster.de>

Erin, gstat::krigeST does not have the conception of a data extent
outside of which interpolation is prohibited. With data from Texas, you
can interpolate to Antarctica. Likewise, you can make predictions for
the next century. The software only translates the model assumptions
into predictions. It is you who needs to decide to (for) what extent
these assumptions make sense.

On 09/15/2014 08:10 PM, Hodgess, Erin wrote:
> Hello r-Sig-Geo-ers!
> 
> 
> 
> I have a goofy question (surprise!), please:
> 
> 
> 
> When we use krigeST, we can predict spatially in many locations other than the original data locations.  Can we also predict temporally farther out, please?  For instance, say my data set runs from Jan 2014 - Aug 2014, and I want to predict from Sep - Oct 2014.  Could I set that up in in my prediction set (such that it would be "reasonable"), please?
> 
> 
> 
> Thanks,
> 
> Sincerely,
> 
> Erin
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140915/a4960395/attachment.bin>

From chrisclementsresearch at gmail.com  Tue Sep 16 10:32:08 2014
From: chrisclementsresearch at gmail.com (Chris Clements)
Date: Tue, 16 Sep 2014 10:32:08 +0200
Subject: [R-sig-Geo] Wrap around distribution
Message-ID: <7DECE75D-A2CC-48EE-A425-C4DFBF51B68F@gmail.com>

Dear all,

I am currently plotting very simple marine species distributions based on presence data using gConvexhull. The species I am working on is large and cosmopolitan, so I would like to be able to plot a distribution that ?wraps? around the world, but in a 2d. So it the below example, the polygon would extend east and west to the edge of the world map:

rm(list=ls())
library(maptools)
library(rgeos)
data(wrld_simpl)

sightings <- gConvexHull(readWKT("GEOMETRYCOLLECTION(POINT(-120  -45), POINT(20  0), POINT(0  30), POINT(150 -50), POINT(-160  20), POINT(60 -10), POINT(145  -5))"))

plot(sightings, col="lightblue", lty=0, xlim=c(-180, 180))

plot(wrld_simpl, add=T, col="black")


Any help much appreciated.
Chris


_______________________________________________

Dr Christopher Clements

The University of Z?rich,
Switzerland

Research: www.chrisclementsresearch.co.uk
Email: chrisclementsresearch at gmail.com
Mobile: (+44)7708945975
Twitter: CClements88
Skype: chris.clements88





	[[alternative HTML version deleted]]


From adiez at uv.es  Tue Sep 16 14:11:12 2014
From: adiez at uv.es (Agustin Diez Castillo)
Date: Tue, 16 Sep 2014 14:11:12 +0200
Subject: [R-sig-Geo] really slow plot of Portugal
Message-ID: <D484B3E0-CF87-464F-A96B-6DBF8362A5F0@uv.es>

Hi,
I don?t know if this is related with the crisis, but Switzerland works wether Portugal or Spain take forever and even freezes R. Same with spplot. Any clues? 
# Switzerland
library(sp)
con <- url("http://gadm.org/data/rda/CHE_adm0.RData")
print(load(con))
[1] "gadm"
close(con)
plot(gadm)
system.time(plot(gadm))
  user  system elapsed 
 0.026   0.001   0.028 
system.time(spplot(gadm))
  user  system elapsed 
 0.022   0.000   0.022 

#Portugal, sometimes the session got halted for a while, even with the system claiming that R is not responding (in mac)
con <- url("http://gadm.org/data/rda/PRT_adm0.RData")
print(load(con))
close(con)
[1] "gadm"
system.time(plot(gadm))
  user  system elapsed 
556.032   1.133 565.243

#Spain
con <- url("http://gadm.org/data/rda/ESP_adm0.RData")
print(load(con))
[1] "gadm"
close(con)
system.time(plot(gadm))
  user  system elapsed 
62.595   0.237  62.974 

sessionInfo()
R version 3.1.1 Patched (2014-07-13 r66131)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] rgeos_0.3-6     maptools_0.8-30 sp_1.0-15      

loaded via a namespace (and not attached):
 [1] colorspace_1.2-4 digest_0.6.4     dismo_0.9-3      foreign_0.8-61   ggplot2_1.0.0    grid_3.1.1       gtable_0.1.2     lattice_0.20-29  MASS_7.3-33     
[10] munsell_0.4.2    plyr_1.8.1       proto_0.3-10     raster_2.2-31    Rcpp_0.11.2      reshape2_1.4     scales_0.2.4     stringr_0.6.2    tools_3.1.1     


	[[alternative HTML version deleted]]


From trichter at uni-bremen.de  Tue Sep 16 15:16:27 2014
From: trichter at uni-bremen.de (Tim Richter-Heitmann)
Date: Tue, 16 Sep 2014 15:16:27 +0200
Subject: [R-sig-Geo] (residual) variograms and trend adjustment
In-Reply-To: <mailman.15.1410861604.22633.r-sig-geo@r-project.org>
References: <mailman.15.1410861604.22633.r-sig-geo@r-project.org>
Message-ID: <5418382B.5090704@uni-bremen.de>

Hi!

I just had a talk with a reviewer of my thesis. He strongly criticized 
the way i was interpreting variograms without previous trend adjustment.
In fact, i am following the route in "Applied Spatial Data Analysis with 
R", chapter 8. On page 218, i think its stated the basic assumption of 
the variogram is that the variance of the random function Z is solely
based on the separation distances. However, it was said that variograms 
should only display the residuals of Z (y=mx+b+e), never the complete 
term. I first should identify non-spatial trends in the data.
I find this very difficult without knowing the autocorrelation of a 
dataset. So, the real question is, what comes first: Autocorrelation or 
pairwise correlations of observations?
Starting with page 230 of the same book, there is a tutorial for 
residual variogramming, but i think this assumes that i already know the 
functions i want to test, or?
How would you deal with this remark?

Thanks, Tim


From jon.skoien at jrc.ec.europa.eu  Tue Sep 16 15:23:22 2014
From: jon.skoien at jrc.ec.europa.eu (Jon Skoien)
Date: Tue, 16 Sep 2014 15:23:22 +0200
Subject: [R-sig-Geo] really slow plot of Portugal
In-Reply-To: <D484B3E0-CF87-464F-A96B-6DBF8362A5F0@uv.es>
References: <D484B3E0-CF87-464F-A96B-6DBF8362A5F0@uv.es>
Message-ID: <541839CA.3030900@jrc.ec.europa.eu>

Hi Augustin,
I guess this is related to the complexity of the border. Switzerland is 
defined by some nice lines (although not as simple as some of the 
borders in Sahara), Portugal and Spain have coastlines which can be 
rather complex, including their islands. Setting
prt = gadm
che = gadm
after downloading each of them, I get:
 > object.size(che)
63296 bytes
 > object.size(prt)
8013800 bytes
The SpatialPolygonsDataFrame-object of Portugal is 126 times the 
corresponding of Switzerland, additionally I guess there is also some 
non-linear scaling of the plotting time. To reduce plotting time for 
Portugal and Spain, you can try gSimplify from rgeos.

Cheers,
Jon





On 9/16/2014 2:11 PM, Agustin Diez Castillo wrote:
> Hi,
> I don?t know if this is related with the crisis, but Switzerland works wether Portugal or Spain take forever and even freezes R. Same with spplot. Any clues?
> # Switzerland
> library(sp)
> con <- url("http://gadm.org/data/rda/CHE_adm0.RData")
> print(load(con))
> [1] "gadm"
> close(con)
> plot(gadm)
> system.time(plot(gadm))
>    user  system elapsed
>   0.026   0.001   0.028
> system.time(spplot(gadm))
>    user  system elapsed
>   0.022   0.000   0.022
>
> #Portugal, sometimes the session got halted for a while, even with the system claiming that R is not responding (in mac)
> con <- url("http://gadm.org/data/rda/PRT_adm0.RData")
> print(load(con))
> close(con)
> [1] "gadm"
> system.time(plot(gadm))
>    user  system elapsed
> 556.032   1.133 565.243
>
> #Spain
> con <- url("http://gadm.org/data/rda/ESP_adm0.RData")
> print(load(con))
> [1] "gadm"
> close(con)
> system.time(plot(gadm))
>    user  system elapsed
> 62.595   0.237  62.974
>
> sessionInfo()
> R version 3.1.1 Patched (2014-07-13 r66131)
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] rgeos_0.3-6     maptools_0.8-30 sp_1.0-15
>
> loaded via a namespace (and not attached):
>   [1] colorspace_1.2-4 digest_0.6.4     dismo_0.9-3      foreign_0.8-61   ggplot2_1.0.0    grid_3.1.1       gtable_0.1.2     lattice_0.20-29  MASS_7.3-33
> [10] munsell_0.4.2    plyr_1.8.1       proto_0.3-10     raster_2.2-31    Rcpp_0.11.2      reshape2_1.4     scales_0.2.4     stringr_0.6.2    tools_3.1.1
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Jon Olav Sk?ien
Joint Research Centre - European Commission
Institute for Environment and Sustainability (IES)
Climate Risk Management Unit

Via Fermi 2749, TP 100-01,  I-21027 Ispra (VA), ITALY

jon.skoien at jrc.ec.europa.eu
Tel:  +39 0332 789205

Disclaimer: Views expressed in this email are those of the individual 
and do not necessarily represent official views of the European Commission.


From adiez at uv.es  Wed Sep 17 10:31:35 2014
From: adiez at uv.es (Agustin Diez Castillo)
Date: Wed, 17 Sep 2014 10:31:35 +0200
Subject: [R-sig-Geo] ssplot freezes R [was] really slow plot of Portugal
In-Reply-To: <541839CA.3030900@jrc.ec.europa.eu>
References: <D484B3E0-CF87-464F-A96B-6DBF8362A5F0@uv.es>
	<541839CA.3030900@jrc.ec.europa.eu>
Message-ID: <4B065880-CB42-4205-9F1E-895AE7040FEE@uv.es>

Hi Jon,
This explain why it takes so long for drawing but not why R is freezing with ssplot.
Did you test this spplot in a no Mac machine?
In my machine when working it takes 21000 times more to draw Portugal instead of the expected 126.
Thanks
On 16Sep, 2014, at 3:23 PM, Jon Skoien <jon.skoien at jrc.ec.europa.eu> wrote:

> Hi Augustin,
> I guess this is related to the complexity of the border. Switzerland is defined by some nice lines (although not as simple as some of the borders in Sahara), Portugal and Spain have coastlines which can be rather complex, including their islands. Setting
> prt = gadm
> che = gadm
> after downloading each of them, I get:
> > object.size(che)
> 63296 bytes
> > object.size(prt)
> 8013800 bytes
> The SpatialPolygonsDataFrame-object of Portugal is 126 times the corresponding of Switzerland, additionally I guess there is also some non-linear scaling of the plotting time. To reduce plotting time for Portugal and Spain, you can try gSimplify from rgeos.
> 
> Cheers,
> Jon
> 
> 
> 
> 
> 
> On 9/16/2014 2:11 PM, Agustin Diez Castillo wrote:
>> Hi,
>> I don?t know if this is related with the crisis, but Switzerland works wether Portugal or Spain take forever and even freezes R. Same with spplot. Any clues?
>> # Switzerland
>> library(sp)
>> con <- url("http://gadm.org/data/rda/CHE_adm0.RData")
>> print(load(con))
>> [1] "gadm"
>> close(con)
>> plot(gadm)
>> system.time(plot(gadm))
>>   user  system elapsed
>>  0.026   0.001   0.028
>> system.time(spplot(gadm))
>>   user  system elapsed
>>  0.022   0.000   0.022
>> 
>> #Portugal, sometimes the session got halted for a while, even with the system claiming that R is not responding (in mac)
>> con <- url("http://gadm.org/data/rda/PRT_adm0.RData")
>> print(load(con))
>> close(con)
>> [1] "gadm"
>> system.time(plot(gadm))
>>   user  system elapsed
>> 556.032   1.133 565.243
>> 
>> #Spain
>> con <- url("http://gadm.org/data/rda/ESP_adm0.RData")
>> print(load(con))
>> [1] "gadm"
>> close(con)
>> system.time(plot(gadm))
>>   user  system elapsed
>> 62.595   0.237  62.974
>> 
>> sessionInfo()
>> R version 3.1.1 Patched (2014-07-13 r66131)
>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>> 
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> other attached packages:
>> [1] rgeos_0.3-6     maptools_0.8-30 sp_1.0-15
>> 
>> loaded via a namespace (and not attached):
>>  [1] colorspace_1.2-4 digest_0.6.4     dismo_0.9-3      foreign_0.8-61   ggplot2_1.0.0    grid_3.1.1       gtable_0.1.2     lattice_0.20-29  MASS_7.3-33
>> [10] munsell_0.4.2    plyr_1.8.1       proto_0.3-10     raster_2.2-31    Rcpp_0.11.2      reshape2_1.4     scales_0.2.4     stringr_0.6.2    tools_3.1.1
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> 
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
> 
> -- 
> Jon Olav Sk?ien
> Joint Research Centre - European Commission
> Institute for Environment and Sustainability (IES)
> Climate Risk Management Unit
> 
> Via Fermi 2749, TP 100-01,  I-21027 Ispra (VA), ITALY
> 
> jon.skoien at jrc.ec.europa.eu
> Tel:  +39 0332 789205
> 
> Disclaimer: Views expressed in this email are those of the individual and do not necessarily represent official views of the European Commission.
> 
> 


From jon.skoien at jrc.ec.europa.eu  Wed Sep 17 11:24:44 2014
From: jon.skoien at jrc.ec.europa.eu (Jon Skoien)
Date: Wed, 17 Sep 2014 11:24:44 +0200
Subject: [R-sig-Geo] ssplot freezes R [was] really slow plot of Portugal
In-Reply-To: <4B065880-CB42-4205-9F1E-895AE7040FEE@uv.es>
References: <D484B3E0-CF87-464F-A96B-6DBF8362A5F0@uv.es>
	<541839CA.3030900@jrc.ec.europa.eu>
	<4B065880-CB42-4205-9F1E-895AE7040FEE@uv.es>
Message-ID: <5419535C.4040201@jrc.ec.europa.eu>

Hi Agustin,

I didn't try all your commands last time, most plotting run faster for 
me (Windows 7, R 3.1-1, sp 1.0-15, rgdal 0.8-16). If you call spplot 
without selecting one of the features, it might be rather slow or freeze 
as they have 70 columns => 70 maps. Do you really want to plot all these 
maps in a matrix form? Anyway,
spplot(gadm, "Shape_Area")
should for example be faster. If you still struggle, you can look at the 
result of summaryRprof() after running:

Rprof()
spplot(gadm, "shape_area")
Rprof(NULL)

and post it to the list if you have questions about it.

Hope this helps,
Jon



On 9/17/2014 10:31 AM, Agustin Diez Castillo wrote:
> Hi Jon,
> This explain why it takes so long for drawing but not why R is freezing with ssplot.
> Did you test this spplot in a no Mac machine?
> In my machine when working it takes 21000 times more to draw Portugal instead of the expected 126.
> Thanks
> On 16Sep, 2014, at 3:23 PM, Jon Skoien <jon.skoien at jrc.ec.europa.eu> wrote:
>
>> Hi Augustin,
>> I guess this is related to the complexity of the border. Switzerland is defined by some nice lines (although not as simple as some of the borders in Sahara), Portugal and Spain have coastlines which can be rather complex, including their islands. Setting
>> prt = gadm
>> che = gadm
>> after downloading each of them, I get:
>>> object.size(che)
>> 63296 bytes
>>> object.size(prt)
>> 8013800 bytes
>> The SpatialPolygonsDataFrame-object of Portugal is 126 times the corresponding of Switzerland, additionally I guess there is also some non-linear scaling of the plotting time. To reduce plotting time for Portugal and Spain, you can try gSimplify from rgeos.
>>
>> Cheers,
>> Jon
>>
>>
>>
>>
>>
>> On 9/16/2014 2:11 PM, Agustin Diez Castillo wrote:
>>> Hi,
>>> I don?t know if this is related with the crisis, but Switzerland works wether Portugal or Spain take forever and even freezes R. Same with spplot. Any clues?
>>> # Switzerland
>>> library(sp)
>>> con <- url("http://gadm.org/data/rda/CHE_adm0.RData")
>>> print(load(con))
>>> [1] "gadm"
>>> close(con)
>>> plot(gadm)
>>> system.time(plot(gadm))
>>>    user  system elapsed
>>>   0.026   0.001   0.028
>>> system.time(spplot(gadm))
>>>    user  system elapsed
>>>   0.022   0.000   0.022
>>>
>>> #Portugal, sometimes the session got halted for a while, even with the system claiming that R is not responding (in mac)
>>> con <- url("http://gadm.org/data/rda/PRT_adm0.RData")
>>> print(load(con))
>>> close(con)
>>> [1] "gadm"
>>> system.time(plot(gadm))
>>>    user  system elapsed
>>> 556.032   1.133 565.243
>>>
>>> #Spain
>>> con <- url("http://gadm.org/data/rda/ESP_adm0.RData")
>>> print(load(con))
>>> [1] "gadm"
>>> close(con)
>>> system.time(plot(gadm))
>>>    user  system elapsed
>>> 62.595   0.237  62.974
>>>
>>> sessionInfo()
>>> R version 3.1.1 Patched (2014-07-13 r66131)
>>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>>>
>>> locale:
>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] rgeos_0.3-6     maptools_0.8-30 sp_1.0-15
>>>
>>> loaded via a namespace (and not attached):
>>>   [1] colorspace_1.2-4 digest_0.6.4     dismo_0.9-3      foreign_0.8-61   ggplot2_1.0.0    grid_3.1.1       gtable_0.1.2     lattice_0.20-29  MASS_7.3-33
>>> [10] munsell_0.4.2    plyr_1.8.1       proto_0.3-10     raster_2.2-31    Rcpp_0.11.2      reshape2_1.4     scales_0.2.4     stringr_0.6.2    tools_3.1.1
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>>
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Jon Olav Sk?ien
>> Joint Research Centre - European Commission
>> Institute for Environment and Sustainability (IES)
>> Climate Risk Management Unit
>>
>> Via Fermi 2749, TP 100-01,  I-21027 Ispra (VA), ITALY
>>
>> jon.skoien at jrc.ec.europa.eu
>> Tel:  +39 0332 789205
>>
>> Disclaimer: Views expressed in this email are those of the individual and do not necessarily represent official views of the European Commission.
>>
>>
>

-- 
Jon Olav Sk?ien
Joint Research Centre - European Commission
Institute for Environment and Sustainability (IES)
Climate Risk Management Unit

Via Fermi 2749, TP 100-01,  I-21027 Ispra (VA), ITALY

jon.skoien at jrc.ec.europa.eu
Tel:  +39 0332 789205

Disclaimer: Views expressed in this email are those of the individual 
and do not necessarily represent official views of the European Commission.


From hengl at spatial-analyst.net  Wed Sep 17 12:27:37 2014
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Wed, 17 Sep 2014 12:27:37 +0200
Subject: [R-sig-Geo] plotKML organizing folders
In-Reply-To: <1410545664528-7587119.post@n2.nabble.com>
References: <1410545664528-7587119.post@n2.nabble.com>
Message-ID: <54196219.3060305@spatial-analyst.net>


I've added an extra argument called "subfolder.name" 
(http://plotkml.r-forge.r-project.org/layer.SpatialPoints.html) so you 
can rename your sub-folders e.g.:

library(plotKML)
library(sp)
demo(meuse, echo=FALSE)
kml(meuse, colour=zinc, subfolder.name="Zinc in ppm")
system("open meuse.kml")

To install plotKML v0.4-6 please use:

install.packages("plotKML", repos="http://R-Forge.R-project.org", 
type="source")

HTH,

T. Hengl

On 12-9-2014 20:14, Anthony Fischbach wrote:
> I wish to allow users of my kml to select specific classes of entities by
> folders within the virtual globe display.
> For example (using the standard plotKML dataset) I wish to allow users to
> select 'class A' and 'class B' bigfoot sightings by selecting folders that
> have intuitive names.
>
> ## Toy example:
> require(plotKML)
> require(sp)
> data(bigfoot) ## Load standard dataframe
> bigfootA<-head(bigfoot) ## grab the top of the dataframe, which has class A
> sightings
> bigfootB<-tail(bigfoot)  ## grab the bottom of the dataframe, which has
> class B sightings
> ## cast both dataframes into spatialPointsDataFrames with defined coordinate
> reference systems
> coordinates(bigfootA)<-c('Lon','Lat') ## Cast as spatial points dataframe
> proj4string(bigfootA)<-CRS("+proj=longlat +ellps=WGS84 +datum=WGS84
> +no_defs")  ## assign a coordinate reference system
> coordinates(bigfootB)<-c('Lon','Lat') ## Cast as spatial points dataframe
> proj4string(bigfootB)<-CRS("+proj=longlat +ellps=WGS84 +datum=WGS84
> +no_defs")  ## assign a coordinate reference system
>
> kml_open(file.name='BigWithFolders.kml', folder.name = 'Big Foot',
> kml_visibility=TRUE )
> 	## Build the points by each class
> 		kml_layer.SpatialPoints(obj=bigfootA, points_names=bigfootA at data$NAMES,
> 			colour='green',  LabelScale=0.8,
> 			shape='http://plotkml.r-forge.r-project.org/3Dballyellow.png',
> 			alpha=0.6, balloon=TRUE) ##
> 		kml_layer.SpatialPoints(obj=bigfootB, points_names=bigfootB at data$NAMES,
> 			colour='yellow',  LabelScale=0.8,
> 			shape='http://plotkml.r-forge.r-project.org/3Dballyellow.png',
> 			alpha=0.6, balloon=TRUE) ##
> 			
> kml_close(file.name='BigWithFolders.kml')
> ### End Toy example
>
> This produces the kml with two folders, both named 'SpatialPointsDataFrame'.
> Is there a way to set the names of each subordinate folder?
>
>
>
> -----
> Tony Fischbach, Wildlife Biologist
> Walrus Research Program
> Alaska Science Center
> U.S. Geological Survey
> 4210 University Drive
> Anchorage, AK 99508-4650
>
> AFischbach at usgs.gov
> http://alaska.usgs.gov/science/biology/walrus
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/plotKML-organizing-folders-tp7587119.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From virgilio.gomez at uclm.es  Wed Sep 17 14:00:14 2014
From: virgilio.gomez at uclm.es (Virgilio =?ISO-8859-1?Q?G=F3mez-Rubio?=)
Date: Wed, 17 Sep 2014 14:00:14 +0200
Subject: [R-sig-Geo] ssplot freezes R [was] really slow plot of Portugal
In-Reply-To: <4B065880-CB42-4205-9F1E-895AE7040FEE@uv.es>
References: <D484B3E0-CF87-464F-A96B-6DBF8362A5F0@uv.es>
	<541839CA.3030900@jrc.ec.europa.eu>
	<4B065880-CB42-4205-9F1E-895AE7040FEE@uv.es>
Message-ID: <1410955214.2670.2.camel@Virgilio-Gomez>

Hi,

This takes a few second on my laptop with Ubuntu. So it may be an issue
with your plotting device. Have you tried to plot it in a PDF or PNG?

Best wishes,

Virgilio

El mi?, 17-09-2014 a las 10:31 +0200, Agustin Diez Castillo escribi?:
> Hi Jon,
> This explain why it takes so long for drawing but not why R is freezing with ssplot.
> Did you test this spplot in a no Mac machine?
> In my machine when working it takes 21000 times more to draw Portugal instead of the expected 126.
> Thanks
> On 16Sep, 2014, at 3:23 PM, Jon Skoien <jon.skoien at jrc.ec.europa.eu> wrote:
> 
> > Hi Augustin,
> > I guess this is related to the complexity of the border. Switzerland is defined by some nice lines (although not as simple as some of the borders in Sahara), Portugal and Spain have coastlines which can be rather complex, including their islands. Setting
> > prt = gadm
> > che = gadm
> > after downloading each of them, I get:
> > > object.size(che)
> > 63296 bytes
> > > object.size(prt)
> > 8013800 bytes
> > The SpatialPolygonsDataFrame-object of Portugal is 126 times the corresponding of Switzerland, additionally I guess there is also some non-linear scaling of the plotting time. To reduce plotting time for Portugal and Spain, you can try gSimplify from rgeos.
> > 
> > Cheers,
> > Jon
> > 
> > 
> > 
> > 
> > 
> > On 9/16/2014 2:11 PM, Agustin Diez Castillo wrote:
> >> Hi,
> >> I don?t know if this is related with the crisis, but Switzerland works wether Portugal or Spain take forever and even freezes R. Same with spplot. Any clues?
> >> # Switzerland
> >> library(sp)
> >> con <- url("http://gadm.org/data/rda/CHE_adm0.RData")
> >> print(load(con))
> >> [1] "gadm"
> >> close(con)
> >> plot(gadm)
> >> system.time(plot(gadm))
> >>   user  system elapsed
> >>  0.026   0.001   0.028
> >> system.time(spplot(gadm))
> >>   user  system elapsed
> >>  0.022   0.000   0.022
> >> 
> >> #Portugal, sometimes the session got halted for a while, even with the system claiming that R is not responding (in mac)
> >> con <- url("http://gadm.org/data/rda/PRT_adm0.RData")
> >> print(load(con))
> >> close(con)
> >> [1] "gadm"
> >> system.time(plot(gadm))
> >>   user  system elapsed
> >> 556.032   1.133 565.243
> >> 
> >> #Spain
> >> con <- url("http://gadm.org/data/rda/ESP_adm0.RData")
> >> print(load(con))
> >> [1] "gadm"
> >> close(con)
> >> system.time(plot(gadm))
> >>   user  system elapsed
> >> 62.595   0.237  62.974
> >> 
> >> sessionInfo()
> >> R version 3.1.1 Patched (2014-07-13 r66131)
> >> Platform: x86_64-apple-darwin10.8.0 (64-bit)
> >> 
> >> locale:
> >> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> >> 
> >> attached base packages:
> >> [1] stats     graphics  grDevices utils     datasets  methods   base
> >> 
> >> other attached packages:
> >> [1] rgeos_0.3-6     maptools_0.8-30 sp_1.0-15
> >> 
> >> loaded via a namespace (and not attached):
> >>  [1] colorspace_1.2-4 digest_0.6.4     dismo_0.9-3      foreign_0.8-61   ggplot2_1.0.0    grid_3.1.1       gtable_0.1.2     lattice_0.20-29  MASS_7.3-33
> >> [10] munsell_0.4.2    plyr_1.8.1       proto_0.3-10     raster_2.2-31    Rcpp_0.11.2      reshape2_1.4     scales_0.2.4     stringr_0.6.2    tools_3.1.1
> >> 
> >> 
> >> 	[[alternative HTML version deleted]]
> >> 
> >> 
> >> 
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at r-project.org
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >> 
> > 
> > -- 
> > Jon Olav Sk?ien
> > Joint Research Centre - European Commission
> > Institute for Environment and Sustainability (IES)
> > Climate Risk Management Unit
> > 
> > Via Fermi 2749, TP 100-01,  I-21027 Ispra (VA), ITALY
> > 
> > jon.skoien at jrc.ec.europa.eu
> > Tel:  +39 0332 789205
> > 
> > Disclaimer: Views expressed in this email are those of the individual and do not necessarily represent official views of the European Commission.
> > 
> > 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From tyler.j.frazier at icloud.com  Wed Sep 17 22:01:04 2014
From: tyler.j.frazier at icloud.com (Tyler Frazier)
Date: Wed, 17 Sep 2014 22:01:04 +0200
Subject: [R-sig-Geo] modify legend on levelplot
Message-ID: <6D53A091-8C9C-4243-84B0-85E9D85A15BE@icloud.com>

Hello,

I would like to modify my legend on a rasterVis levelplot() but can?t figure it out.

I use

p <- levelplot(x_rat, main = ?title", margin = FALSE, xlab = NULL, ylab = NULL, auto.key=list(space="top", columns=3), col.regions=c(?gray','darkgreen','tomato4','yellow','purple','blue','azure2','orange','hotpink','peachpuff','salmon2'))
p + layer(sp.lines(borders, lwd=1.2, col='gray60'))

with the idea that the auto.key command will center the legend at the top of the plot, three items at a time (3 per column, 4 rows with the last row having 2).  

I would also like to locate the legend inside the borders over part of the main plot area where the map is less informative (with an opaque white background inside the legend box).

Any suggestions would be appreciated.

Thank you,
Tyler
-------------------------------------------------------------------------
Tyler Frazier
Center for Development Research (ZEF-C)
University of Bonn
53113 Bonn, DE
+49 (0) 228 73 4949 (office)
+49 (0) 152 1018 2718 (handy)
-------------------------------------------------------------------------







	[[alternative HTML version deleted]]


From agus.camacho at gmail.com  Wed Sep 17 23:13:58 2014
From: agus.camacho at gmail.com (Agus Camacho)
Date: Wed, 17 Sep 2014 18:13:58 -0300
Subject: [R-sig-Geo] Distances from points to coast do not make sense.
In-Reply-To: <CANtt_hxPruQ-_HUBJ2QQDfBR99bf+JH1festpj-pm56wO1Rw-A@mail.gmail.com>
References: <CALsJ7pT9XJ5Djips7cMk_iyhiZAE5=29NpOTO3V9nm+Y=G1qMQ@mail.gmail.com>
	<CANtt_hze-8xt-R4bYO-4aoQ=DkQtt2A+6OC2iBcxkYnD4B8nkg@mail.gmail.com>
	<CALsJ7pThrumWbu7ghSNODQ9QbQov+vhD_U5cdA9xB6rsvinJVw@mail.gmail.com>
	<CANtt_hxPruQ-_HUBJ2QQDfBR99bf+JH1festpj-pm56wO1Rw-A@mail.gmail.com>
Message-ID: <CALsJ7pTU7cjMMZTJD4G6BZO48Bg-cN=x1it+cCT9P=_PQFC-ag@mail.gmail.com>

Thanks again Robert,

In case it is of help for any body, after trying several combinations, the
fastest solution I got to calculate minimum distances to coast was:

require(PBSmapping)

wcoastline <- importShapefile("GSHHS_c_L1.shp")
w=as.matrix(wcoastline[,c('X','Y')])

# You will need x1, an object with: 1) long 2)lat coordinates

require(sp)
  distance=rep(NA,dim(x1)[1])
  for(n in 1:dim(x1)[1])
    {
    distance[n]=min(spDistsN1(w,cbind(x[n,1], x1[n,2]),longlat=TRUE))
  }
  meandist=mean(distance)#
}

Cheers,
Agus

2014-09-12 2:17 GMT-03:00 Robert J. Hijmans <r.hijmans at gmail.com>:

> On Thu, Sep 11, 2014 at 9:53 PM, Agus Camacho <agus.camacho at gmail.com>
> wrote:
> > Many thanks Robert, it actually works,
> >
> > I still would like using the coast lines from the file GSHHS_c_L1.shp I
> was
> > originally using because seems to be much faster and contain coast lines
> of
> > the world. I think it should work, however, i dont know why i cant take
> > correct distances from this lines.
> >
>
> should work too
>
> > Here is the script that im using for obtaining the world coastline from
> the
> > file and getting the distances, anybody might want the .shp file just
> ask to
> > me.
> >
> > library(geosphere)
> > wcoastline = PBSmapping::importShapefile("GSHHS_c_L1.shp")
> > wcl = as.matrix(wcoastline[,c("X","Y")])
> >
> > dist2Line(cbind(141.3311, -6.826087), cl)[1]/1000# fast but wrong
> distance
>
> what is "cl"? Is it "wcl" but that is a matrix, not lines.
>
>
> >
> >
> How about
>
> library(maptools)
> library(raster)
> library(geosphere)
> w = shapefile("GSHHS_c_L1.shp")
> dist2Line(cbind(141.3311, -6.826087), w)[1]/1000# very slow but right
>
>
> Robert
>
> > Cheers and a hug for the people of the last Geostat!
> > Agus
> >
> >
> > 2014-09-11 21:25 GMT-03:00 Robert J. Hijmans <r.hijmans at gmail.com>:
> >
> >> The below seems to work correctly (albeit slowly).
> >>
> >>
> >> library(maptools)
> >> library(raster)
> >> library(geosphere)
> >>
> >> data(wrld_simpl)
> >> w <- aggregate(wrld_simpl)
> >> af = cbind(16, 13)
> >> ng <- cbind(139, -4)
> >> p <- rbind(af, ng)
> >> dist2Line(p, w)
> >>
> >>
> >> On Thu, Sep 11, 2014 at 4:13 PM, Agus Camacho <agus.camacho at gmail.com>
> >> wrote:
> >> > I have two species, one is widespread in Africa (varanus niloticus)
> and
> >> > the
> >> > other is distributed across a region of new Guinea (Varanus
> prasinus). I
> >> > calculated the mean distance to coast of their respective geographic
> >> > records using the following script:
> >> >
> >> > x1 is a dataframe with two columns: Longitude and Latitude of
> geographic
> >> > records
> >> >
> >> > meandist=rep(0,length(levels(x$Species)))
> >> > distance=rep(NA,dim(x1)[1])
> >> >
> >> > for(n in 1:dim(x1)[1])
> >> > {
> >> >
> >> >
> distance[n]=(dist2Line(cbind(x1[n,1],x1[n,2]),LAcl,distfun=distVincentyEllipsoid)/1000)[1]
> >> > }
> >> > meandist=mean(distance)
> >> >
> >> > The problem is that geographic records from the african species is
> >> > giving
> >> > me shorter distances to the coast (mean=6677) than the species from
> new
> >> > guinea(mean=12417). I already plotted the species records and checked
> >> > there
> >> > are not bizarre records. I can send the records for anyone
> insterested.
> >> >
> >> > Thanks in advance.
> >> > Agus
> >> >
> >> >
> >> >
> >> > --
> >> > Agust?n Camacho Guerrero.
> >> > Doutor em Zoologia.
> >> > Laborat?rio de Herpetologia, Departamento de Zoologia, Instituto de
> >> > Bioci?ncias, USP.
> >> > Rua do Mat?o, trav. 14, n? 321, Cidade Universit?ria,
> >> > S?o Paulo - SP, CEP: 05508-090, Brasil.
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> >
> >> > _______________________________________________
> >> > R-sig-Geo mailing list
> >> > R-sig-Geo at r-project.org
> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >> >
> >
> >
> >
> >
> > --
> > Agust?n Camacho Guerrero.
> > Doutor em Zoologia.
> > Laborat?rio de Herpetologia, Departamento de Zoologia, Instituto de
> > Bioci?ncias, USP.
> > Rua do Mat?o, trav. 14, n? 321, Cidade Universit?ria,
> > S?o Paulo - SP, CEP: 05508-090, Brasil.
>



-- 
Agust?n Camacho Guerrero.
Doutor em Zoologia.
Laborat?rio de Herpetologia, Departamento de Zoologia, Instituto de
Bioci?ncias, USP.
Rua do Mat?o, trav. 14, n? 321, Cidade Universit?ria,
S?o Paulo - SP, CEP: 05508-090, Brasil.

	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Thu Sep 18 11:51:36 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 18 Sep 2014 10:51:36 +0100
Subject: [R-sig-Geo] Distances from points to coast do not make sense.
In-Reply-To: <7dd41ae85a06466692c97a4be4165e1f@EX-0-HT0.lancs.local>
References: <CALsJ7pT9XJ5Djips7cMk_iyhiZAE5=29NpOTO3V9nm+Y=G1qMQ@mail.gmail.com>
	<CANtt_hze-8xt-R4bYO-4aoQ=DkQtt2A+6OC2iBcxkYnD4B8nkg@mail.gmail.com>
	<CALsJ7pThrumWbu7ghSNODQ9QbQov+vhD_U5cdA9xB6rsvinJVw@mail.gmail.com>
	<CANtt_hxPruQ-_HUBJ2QQDfBR99bf+JH1festpj-pm56wO1Rw-A@mail.gmail.com>
	<7dd41ae85a06466692c97a4be4165e1f@EX-0-HT0.lancs.local>
Message-ID: <CANVKczNns29WvqN=1W+1c6GN6bWsJaD_sJ8W=yUeoE1yHOHRug@mail.gmail.com>

On Wed, Sep 17, 2014 at 10:13 PM, Agus Camacho <agus.camacho at gmail.com> wrote:
> Thanks again Robert,
>
> In case it is of help for any body, after trying several combinations, the
> fastest solution I got to calculate minimum distances to coast was:
>
> require(PBSmapping)
>
> wcoastline <- importShapefile("GSHHS_c_L1.shp")
> w=as.matrix(wcoastline[,c('X','Y')])
>
> # You will need x1, an object with: 1) long 2)lat coordinates
>
> require(sp)
>   distance=rep(NA,dim(x1)[1])
>   for(n in 1:dim(x1)[1])
>     {
>     distance[n]=min(spDistsN1(w,cbind(x[n,1], x1[n,2]),longlat=TRUE))
>   }
>   meandist=mean(distance)#
> }

 If I read that correctly, it doesn't do what you want it to do. It's
computing the distance to the nearest *vertex* of the coastline. A
long straight or simplified coastline could have vertices a long way
apart, and you'll get the wrong answer.

Here X is very close to the coastline but quite far from the vertices.
You'll get the vertex distance. Y is the same distance to the
coastline, but gets the correct small distance from the nearest
vertex:

                   X                Y
 *-----------------------------------*--------------* (proportional font needed)

I think someone has already given you a solution that computes
distance to lines, it may be slower but it has the property of being
correct!

Barry


From jbechara at lri-lb.org  Thu Sep 18 11:57:16 2014
From: jbechara at lri-lb.org (Joseph Bechara)
Date: Thu, 18 Sep 2014 12:57:16 +0300
Subject: [R-sig-Geo] Error in file(fn, "rb") : cannot open the connection
In-Reply-To: <CANtt_hxmRGugBMyLLw-QOY=rQE-4YJtMMRSrEvznOTN=hu212A@mail.gmail.com>
Message-ID: <1357795418-3028@kerio.lri-lb.org>


Dear All,?
? ? I'm facing the below highlighted error when trying to plot or write the below Agg[[1]] raster layer.Can somebody help me to solve the issue?


> Agg[[1]]class ? ? ? : RasterLayer?dimensions ?: 73636, 55024, 4051747264 ?(nrow, ncol, ncell)resolution ?: 2.5, 2.5 ?(x, y)extent ? ? ?: 696228.3, 833788.3, 3659895, 3843985 ?(xmin, xmax, ymin, ymax)coord. ref. : +proj=utm +zone=36 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0?data source : C:\Users\Said\AppData\Local\Temp\R_raster_tmp\Said\raster_tmp_2014-08-29_161527_102453.grd?names ? ? ? : ann_Rad?values ? ? ?: 336.418, 2096430 ?(min, max)

> plot(Agg[[1]])Error in file(fn, "rb") : cannot open the connectionIn addition: Warning message:In file(fn, "rb") :? cannot open file 'C:\Users\Said\AppData\Local\Temp\R_raster_tmp\Said\raster_tmp_2014-08-29_161527_102453.gri': No such file or directory
>Ann_Rad<-writeRaster(Agg[[1]], filename="C:/Input_tif/write/Ann_Rad1.ing", format="HFA")Error in file(fn, "rb") : cannot open the connectionIn addition: Warning message:In file(fn, "rb") :? cannot open file 'C:\Users\Said\AppData\Local\Temp\R_raster_tmp\Said\raster_tmp_2014-08-29_161527_102453.gri': No such file or directory>?
	[[alternative HTML version deleted]]


From oscar.perpinan at upm.es  Thu Sep 18 12:57:03 2014
From: oscar.perpinan at upm.es (=?UTF-8?Q?Oscar_Perpi=C3=B1an?=)
Date: Thu, 18 Sep 2014 12:57:03 +0200
Subject: [R-sig-Geo] modify legend on levelplot
In-Reply-To: <6D53A091-8C9C-4243-84B0-85E9D85A15BE@icloud.com>
References: <6D53A091-8C9C-4243-84B0-85E9D85A15BE@icloud.com>
Message-ID: <CAMLL7bm8Qzp4tS5E9QaQv8MWRD_aJOBCe8wdRpM-UfQUfvC6Cg@mail.gmail.com>

Hi,

This is not possible with the default colorkey mechanism of levelplot. You
have to disable it (colorkey=FALSE) and define a custom key using the "key"
argument. It expects a list whose components define the elements of the
legend. You should read the help page of lattice::xyplot for details about
"key".

Here you have a toy example that you should adapt to your needs:

library(rasterVis)

## Define a categorical raster
r <- raster(nrow=10, ncol=10)
r[] = 1
r[51:100] = 3
r[3:6, 1:5] = 5
r <- ratify(r)

## Levels
rat <- levels(r)[[1]]
rat$landcover <- c('Pine', 'Oak', 'Meadow')
levels(r) <- rat

## Key
myColors <- c('palegreen', 'midnightblue', 'indianred1')
myKey <- list(text=list(lab=rat$landcover),
              rectangles=list(col = myColors),
              space='inside',
              columns=3)

levelplot(r, col.regions = myColors, colorkey = FALSE, key = myKey)

Hope it helps.

Best,

Oscar.
-----------------------------------------------------------------
Oscar Perpi??n Lamigueiro
Dpto. Ingenier?a El?ctrica (ETSIDI-UPM)
Grupo de Sistemas Fotovoltaicos (IES-UPM)
URL: http://oscarperpinan.github.io

2014-09-17 22:01 GMT+02:00 Tyler Frazier <tyler.j.frazier at icloud.com>:

> Hello,
>
> I would like to modify my legend on a rasterVis levelplot() but can?t
> figure it out.
>
> I use
>
> p <- levelplot(x_rat, main = ?title", margin = FALSE, xlab = NULL, ylab =
> NULL, auto.key=list(space="top", columns=3),
> col.regions=c(?gray','darkgreen','tomato4','yellow','purple','blue','azure2','orange','hotpink','peachpuff','salmon2'))
> p + layer(sp.lines(borders, lwd=1.2, col='gray60'))
>
> with the idea that the auto.key command will center the legend at the top
> of the plot, three items at a time (3 per column, 4 rows with the last row
> having 2).
>
> I would also like to locate the legend inside the borders over part of the
> main plot area where the map is less informative (with an opaque white
> background inside the legend box).
>
> Any suggestions would be appreciated.
>
> Thank you,
> Tyler
> -------------------------------------------------------------------------
> Tyler Frazier
> Center for Development Research (ZEF-C)
> University of Bonn
> 53113 Bonn, DE
> +49 (0) 228 73 4949 (office)
> +49 (0) 152 1018 2718 (handy)
> -------------------------------------------------------------------------
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

	[[alternative HTML version deleted]]


From solmaz.ahmadi at ut.ac.ir  Thu Sep 18 14:36:22 2014
From: solmaz.ahmadi at ut.ac.ir (solmaz.ahmadi)
Date: Thu, 18 Sep 2014 17:06:22 +0430
Subject: [R-sig-Geo] Problem in creating neighbors,
 area and perimeter in spatial econometrics using R
Message-ID: <9592c03c747106789a8133f01374504b@ut.ac.ir>

 

Hi. 

I'm working on a `spatial cross section model` with
`R-programming-language `. I'm running these codes which refers to
`anselin data` (spatial_columbus) in `spdep` package. I found them from
these links: 

MAIN PAGE :
https://sites.google.com/site/econometricsacademy/econometrics-models/spatial-econometrics


DATASET :
https://docs.google.com/file/d/0BwogTI8d6EEiZVdBSlgwdmFjTUk/edit?pli=1 

 library(spdep)# Loading required package: sp &Loading required package:
Matrix 

 data(Columbus) 

 mydata<-columbus 

 attach(mydata) 

 y<-cbind(CRIME) 

 x<-cbind(INC,HOVAL) 

 xy<-cbind(mydata$X, mydata$Y) 

 neighbors<-col.gal.nb 

 coords<-coords 

 summary(neighbors) 

When I used these codes for data (columbus) in `spdep` package,
everything is fine, but when I want apply them to my data (human capital
index) I'm not able to define `neighborhood` for my data . My problem is
in this line `( neighbor<-col.gal.nb)`.it's the neighbors list from an
original `GAL-format file` and it's a pre-defined file . I don't know
any codes for creating neighbors to my data and I think my data
framework is different from spatial Columbus data framework (There is
`AREA`, `PERIMETER`,`ID` and `POLYID` columns that I don't have these
columns in my data framework). 

The help link for `col.gal.nb` is here (you can open this link in R
environment after above codes) 

 http://127.0.0.1:20991/library/spdep/html/columbus.html 

MY QUESTIONS ARE: 

1. How can I use `ArcGIS` to create `AREA` and `PERIMETER` to my data
file? I have some counties as samples. Are any easier solution for
finding these values or I should only use `ArcGIS` for this purpose? 

2. Which code pack can I use to creating neighbors based on contiguity
and distance in `R`? 

My dependent variable is `HCI `and `Y` is latitude, `X` is longitude and
other variables are independent variables. 

My data set framework :
http://www.mediafire.com/view/lf43qm1h5ptztt6/spatial_columbus.csv 

Pre-defined framwwork :
http://www.mediafire.com/view/ml76tbrf6p69vkf/human_capital_index.csv 

Thank you so much for your kind helps. 

 
	[[alternative HTML version deleted]]


From cyndyh at nmsu.edu  Thu Sep 18 19:34:53 2014
From: cyndyh at nmsu.edu (Cynthia Hart)
Date: Thu, 18 Sep 2014 10:34:53 -0700
Subject: [R-sig-Geo] Trying to install rgdal from source on Windows 7 (and
	failing)
Message-ID: <541B17BD.5070207@nmsu.edu>

I have been using the (wonderfully useful) rgdal package for some time 
now, but I now have a need to incorporate rgdal with PostGIS/PostgreSQL, 
so, I find that I need more drivers than were included with the CRAN 
release version of rdgal that I was using.  I have GDAL already 
installed.   However, I am unable to build rgdal from source.  I have 
the rgdal_0.8-16.tar file, and when I try to run install.packages from 
this tar file, I get"

	install.packages("C:\\JORNADA\\rgdal_0.8-16.tar", repos = NULL, type="source")
	Installing package into ?C:/Users/cynthart/Documents/R/win-library/3.0?
	(as ?lib? is unspecified)
	* installing *source* package 'rgdal' ...
	** package 'rgdal' successfully unpacked and MD5 sums checked
*	cp: cannot stat `/share/proj': No such file or directory
	cp: cannot stat `/share/gdal': No such file or directory*
	ERROR: configuration failed for package 'rgdal'
	* removing 'C:/Users/cynthart/Documents/R/win-library/3.0/rgdal'
	Warning in install.packages :
   	running command '"C:/PROGRA~1/R/R-30~1.1/bin/x64/R" CMD INSTALL -l "C:\Users\cynthart\Doc		uments\R\win-library\3.0" "C:/JORNADA/rgdal_0.8-16.tar"' had status 1
	Warning in install.packages :
   	installation of package ?C:/JORNADA/rgdal_0.8-16.tar? had non-zero exit status

I basically understand the error, but I do not know how to go about 'fixing' it.  Can anyone please point me in the right direction?  Thank you!



	[[alternative HTML version deleted]]


From geponce at gmail.com  Thu Sep 18 21:41:36 2014
From: geponce at gmail.com (Guillermo E. Ponce-Campos)
Date: Thu, 18 Sep 2014 12:41:36 -0700
Subject: [R-sig-Geo] Using "rasterize" with parallel...
Message-ID: <CAGKzJ7rwoFd8j9oOJ=xf1o+UQ-kQBt0k7TJg2u=umNuUj70MoQ@mail.gmail.com>

GetXYfromRaster <- function (vraster.template, vshp.file, vext) {

if (nchar(vshp.file) < 1) {
    vshp.file <- tk_choose.files(caption="Select shapefile...")
    vshp.file <- readShapeSpatial(vshp.file)
  } else {
    vshp.file <- readShapeSpatial(vshp.file)
  }

  ## Cluster for parallelization
  cl <- makeCluster(detectCores()-2)
  registerDoParallel(cl)
  if (nchar(vraster.template) < 1) {
    vraster.template <- tk_choose.files(caption="Select raster template...")
    mc <- foreach (i = 1:1, .packages = "raster") %dopar% {
      vraster.template <- raster(vraster.template)
      vraster.template <- crop (vraster.template, vext)
    }
  } else {
    mc <- foreach (i = 1:1, .packages = "raster") %dopar% {
       vraster.template <- raster(vraster.template)
       vraster.template <- crop (vraster.template, vext)
    }
  }
  mc <- foreach (i = 1:1, .packages = "raster") %dopar% {
     vshp.crop <- crop(vshp.file, vraster.template)
     vrasterized <- rasterize(vshp.crop, vraster.template, field="OBJECTID")

  }
  vxy.coords <- coordinates(vrasterized)

  stopCluster(cl)

  return (as.data.frame(vxy.coords))

}

I'm getting the following error when I call that function...

Error in { :
  task 1 failed - "unable to find an inherited method for function extent
for signature "character""

Doing the traceback, the error comes from the call to "rasterize".  Is it
possible to use rasterize in this way?

Any hint?

Guillermo

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Thu Sep 18 22:41:25 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 19 Sep 2014 08:41:25 +1200
Subject: [R-sig-Geo] Distances from points to coast do not make sense.
In-Reply-To: <CANVKczNns29WvqN=1W+1c6GN6bWsJaD_sJ8W=yUeoE1yHOHRug@mail.gmail.com>
References: <CALsJ7pT9XJ5Djips7cMk_iyhiZAE5=29NpOTO3V9nm+Y=G1qMQ@mail.gmail.com>	<CANtt_hze-8xt-R4bYO-4aoQ=DkQtt2A+6OC2iBcxkYnD4B8nkg@mail.gmail.com>	<CALsJ7pThrumWbu7ghSNODQ9QbQov+vhD_U5cdA9xB6rsvinJVw@mail.gmail.com>	<CANtt_hxPruQ-_HUBJ2QQDfBR99bf+JH1festpj-pm56wO1Rw-A@mail.gmail.com>	<7dd41ae85a06466692c97a4be4165e1f@EX-0-HT0.lancs.local>
	<CANVKczNns29WvqN=1W+1c6GN6bWsJaD_sJ8W=yUeoE1yHOHRug@mail.gmail.com>
Message-ID: <541B4375.8050401@auckland.ac.nz>

On 18/09/14 21:51, Barry Rowlingson wrote:
> On Wed, Sep 17, 2014 at 10:13 PM, Agus Camacho <agus.camacho at gmail.com> wrote:

<SNIP>

> I think someone has already given you a solution that computes
> distance to lines, it may be slower but it has the property of being
> correct!

Fortune nomination!

cheers,

Rolf

-- 
Rolf Turner
Technical Editor ANZJS


From loic.dutrieux at wur.nl  Fri Sep 19 09:55:32 2014
From: loic.dutrieux at wur.nl (Dutrieux, Loic)
Date: Fri, 19 Sep 2014 07:55:32 +0000
Subject: [R-sig-Geo] Trying to install rgdal from source on Windows 7
 (and	failing)
In-Reply-To: <541B17BD.5070207@nmsu.edu>
References: <541B17BD.5070207@nmsu.edu>
Message-ID: <A83620D4CC4762448EFB789FD6E9BBB742A2CFB4@SCOMP0937.wurnet.nl>

You may try some steps documented in the README.windows file, included in the package sources. https://r-forge.r-project.org/scm/viewvc.php/pkg/inst/README.windows?view=markup&root=rgdal
But note that the file has not been updated in a little while. I can't tell whether this is still likely to work or not...

Cheers,
Lo?c
________________________________________
From: r-sig-geo-bounces at r-project.org [r-sig-geo-bounces at r-project.org] on behalf of Cynthia Hart [cyndyh at nmsu.edu]
Sent: Thursday, September 18, 2014 7:34 PM
To: r-sig-geo at r-project.org
Cc: cyndyh at nmsu.edu
Subject: [R-sig-Geo] Trying to install rgdal from source on Windows 7 (and      failing)

I have been using the (wonderfully useful) rgdal package for some time
now, but I now have a need to incorporate rgdal with PostGIS/PostgreSQL,
so, I find that I need more drivers than were included with the CRAN
release version of rdgal that I was using.  I have GDAL already
installed.   However, I am unable to build rgdal from source.  I have
the rgdal_0.8-16.tar file, and when I try to run install.packages from
this tar file, I get"

        install.packages("C:\\JORNADA\\rgdal_0.8-16.tar", repos = NULL, type="source")
        Installing package into ?C:/Users/cynthart/Documents/R/win-library/3.0?
        (as ?lib? is unspecified)
        * installing *source* package 'rgdal' ...
        ** package 'rgdal' successfully unpacked and MD5 sums checked
*       cp: cannot stat `/share/proj': No such file or directory
        cp: cannot stat `/share/gdal': No such file or directory*
        ERROR: configuration failed for package 'rgdal'
        * removing 'C:/Users/cynthart/Documents/R/win-library/3.0/rgdal'
        Warning in install.packages :
        running command '"C:/PROGRA~1/R/R-30~1.1/bin/x64/R" CMD INSTALL -l "C:\Users\cynthart\Doc               uments\R\win-library\3.0" "C:/JORNADA/rgdal_0.8-16.tar"' had status 1
        Warning in install.packages :
        installation of package ?C:/JORNADA/rgdal_0.8-16.tar? had non-zero exit status

I basically understand the error, but I do not know how to go about 'fixing' it.  Can anyone please point me in the right direction?  Thank you!



        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Fri Sep 19 10:15:30 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 19 Sep 2014 10:15:30 +0200
Subject: [R-sig-Geo] Trying to install rgdal from source on Windows 7
 (and	failing)
In-Reply-To: <A83620D4CC4762448EFB789FD6E9BBB742A2CFB4@SCOMP0937.wurnet.nl>
References: <541B17BD.5070207@nmsu.edu>
	<A83620D4CC4762448EFB789FD6E9BBB742A2CFB4@SCOMP0937.wurnet.nl>
Message-ID: <alpine.LRH.2.03.1409191005000.3380@reclus.nhh.no>

On Fri, 19 Sep 2014, Dutrieux, Loic wrote:

> You may try some steps documented in the README.windows file, included 
> in the package sources. 
> https://r-forge.r-project.org/scm/viewvc.php/pkg/inst/README.windows?view=markup&root=rgdal

Thank you for pointing to this file.

> But note that the file has not been updated in a little while. I can't 
> tell whether this is still likely to work or not...
>

This is correct.

My feeling is that installing rgdal from source on Windows is going to 
take (much) more time learning about compilers and their peculiarities 
than using command line utilities distributed in the PostGIS bundle for 
Windows:

http://postgis.net/windows_downloads

There shp2pgsql and pgsql2shp are mentioned, but as GDAL is also 
installed, ogr2ogr would let you use other intermediate file formats than 
ESRI Shapefiles, provided that the drivers are in the rgdal Windows binary 
package. Writing a small R function to run and check system() or system2() 
to run the command line utilities from inside R will be much easier than 
installing rgdal from source unless you know a lot about the compliers 
used with PostGIS and R. It also removes concerns that some components may 
be 32-bit or 64-bit.

Hope this helps,

Roger

> Cheers,
> Lo?c
> ________________________________________
> From: r-sig-geo-bounces at r-project.org [r-sig-geo-bounces at r-project.org] on behalf of Cynthia Hart [cyndyh at nmsu.edu]
> Sent: Thursday, September 18, 2014 7:34 PM
> To: r-sig-geo at r-project.org
> Cc: cyndyh at nmsu.edu
> Subject: [R-sig-Geo] Trying to install rgdal from source on Windows 7 (and      failing)
>
> I have been using the (wonderfully useful) rgdal package for some time
> now, but I now have a need to incorporate rgdal with PostGIS/PostgreSQL,
> so, I find that I need more drivers than were included with the CRAN
> release version of rdgal that I was using.  I have GDAL already
> installed.   However, I am unable to build rgdal from source.  I have
> the rgdal_0.8-16.tar file, and when I try to run install.packages from
> this tar file, I get"
>
>        install.packages("C:\\JORNADA\\rgdal_0.8-16.tar", repos = NULL, type="source")
>        Installing package into ?C:/Users/cynthart/Documents/R/win-library/3.0?
>        (as ?lib? is unspecified)
>        * installing *source* package 'rgdal' ...
>        ** package 'rgdal' successfully unpacked and MD5 sums checked
> *       cp: cannot stat `/share/proj': No such file or directory
>        cp: cannot stat `/share/gdal': No such file or directory*
>        ERROR: configuration failed for package 'rgdal'
>        * removing 'C:/Users/cynthart/Documents/R/win-library/3.0/rgdal'
>        Warning in install.packages :
>        running command '"C:/PROGRA~1/R/R-30~1.1/bin/x64/R" CMD INSTALL -l "C:\Users\cynthart\Doc               uments\R\win-library\3.0" "C:/JORNADA/rgdal_0.8-16.tar"' had status 1
>        Warning in install.packages :
>        installation of package ?C:/JORNADA/rgdal_0.8-16.tar? had non-zero exit status
>
> I basically understand the error, but I do not know how to go about 'fixing' it.  Can anyone please point me in the right direction?  Thank you!
>
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From srinivasv at feralindia.org  Fri Sep 19 10:44:48 2014
From: srinivasv at feralindia.org (Srinivas V)
Date: Fri, 19 Sep 2014 14:14:48 +0530
Subject: [R-sig-Geo] Error in zapply?
Message-ID: <541BED00.4080809@feralindia.org>

Hi,

I have a raster brick of MODIS 8 day LST data and I'm trying to generate 
a brick with monthly maximum LST values for the time period 2000-2013.  
I'm using the zoo and raster packages to get monthly averages, however 
it appears that the zapply function does not handle 1st January very 
well.To illustrate the problem I have provided outputs for a single 
year, instead of returning a brick with 12 layers it returns a brick 
with 13 layers and the first layer is assigned to December of the 
previous year.

I have also manually changed the time stamp from 1st January to 3rd 
January and it works fine. However to do this across multiple tiles and 
across years is going to problematic and I cannot automate the 
processing.  Is this a bug and what is the alternative?

I would appreciate any advice on dealing with this issue.

Thanks!

library(raster)
library(zoo)


 > dy #dates extracted from file names
  [1] "2010-01-01 IST" "2010-01-09 IST" "2010-01-17 IST" "2010-01-25 
IST" "2010-02-02 IST" "2010-02-10 IST" "2010-02-18 IST" "2010-02-26 IST" 
"2010-03-06 IST" "2010-03-14 IST" "2010-03-22 IST" "2010-03-30 IST"
[13] "2010-04-07 IST" "2010-04-15 IST" "2010-04-23 IST" "2010-05-01 IST" 
"2010-05-09 IST" "2010-05-17 IST" "2010-05-25 IST" "2010-06-02 IST" 
"2010-06-10 IST" "2010-06-18 IST" "2010-06-26 IST" "2010-07-04 IST"
[25] "2010-07-12 IST" "2010-07-20 IST" "2010-07-28 IST" "2010-08-05 IST" 
"2010-08-13 IST" "2010-08-21 IST" "2010-08-29 IST" "2010-09-06 IST" 
"2010-09-14 IST" "2010-09-22 IST" "2010-09-30 IST" "2010-10-08 IST"
[37] "2010-10-16 IST" "2010-10-24 IST" "2010-11-01 IST" "2010-11-09 IST" 
"2010-11-17 IST" "2010-11-25 IST" "2010-12-03 IST" "2010-12-11 IST" 
"2010-12-19 IST" "2010-12-27 IST"

 > as.yearmon(dy)# no problem here, as.yearmon() is a function from 
package zoo

  [1] "Jan 2010" "Jan 2010" "Jan 2010" "Jan 2010" "Feb 2010" "Feb 2010" 
"Feb 2010" "Feb 2010" "Mar 2010" "Mar 2010" "Mar 2010" "Mar 2010" "Apr 
2010" "Apr 2010" "Apr 2010" "May 2010" "May 2010" "May 2010" "May 2010"
[20] "Jun 2010" "Jun 2010" "Jun 2010" "Jun 2010" "Jul 2010" "Jul 2010" 
"Jul 2010" "Jul 2010" "Aug 2010" "Aug 2010" "Aug 2010" "Aug 2010" "Sep 
2010" "Sep 2010" "Sep 2010" "Sep 2010" "Oct 2010" "Oct 2010" "Oct 2010"
[39] "Nov 2010" "Nov 2010" "Nov 2010" "Nov 2010" "Dec 2010" "Dec 2010" 
"Dec 2010" "Dec 2010"

 > LSTWG<-setZ(LSTWG,as.POSIXct(dy))#setZ used to set time stamp

 > LSTWG #raster brick for year 2010
class       : RasterBrick
dimensions  : 3334, 2294, 7648196, 46  (nrow, ncol, ncell, nlayers)
resolution  : 1000.16, 999.8986  (x, y)
extent      : -728812.9, 1565553, -1033.987, 3332628  (xmin, xmax, ymin, 
ymax)
coord. ref. : +proj=utm +no_defs +zone=43 +a=6378137 +rf=298.257223563 
+towgs84=0.000,0.000,0.000 +to_meter=1
data source : in memory
names       : X2010.01.01, X2010.01.09, X2010.01.17, X2010.01.25, 
X2010.02.02, X2010.02.10, X2010.02.18, X2010.02.26, X2010.03.06, 
X2010.03.14, X2010.03.22, X2010.03.30, X2010.04.07, X2010.04.15, 
X2010.04.23, ...
min values  :       13279,       13136,       13159, 13201,       
13116,       13179,       13379,       13522, 13622,       13758,       
13901,       13865,       14132, 14007,       13915, ...
max values  :       15612,       15722,       15766, 15734,       
15808,       16005,       16145,       16223, 16409,       16493,       
16333,       16496,       16546, 16694,       16716, ...
time        : 2010-01-01, 2010-12-27 (min, max)

 > LSTWGm<-zApply(LSTWG,by=as.yearmon,fun=max)

 > LSTWGm #instead of returning a brick with 12 layers it returns a 
brick with 13 layers and the first layer is assigned to December of the 
previous year
class       : RasterBrick
dimensions  : 3334, 2294, 7648196, 13  (nrow, ncol, ncell, nlayers)
resolution  : 1000.16, 999.8986  (x, y)
extent      : -728812.9, 1565553, -1033.987, 3332628  (xmin, xmax, ymin, 
ymax)
coord. ref. : +proj=utm +no_defs +zone=43 +a=6378137 +rf=298.257223563 
+towgs84=0.000,0.000,0.000 +to_meter=1
data source : 
/tmp/R_raster_karthik/raster_tmp_2014-09-09_114458_2361_81754.grd
names       : Dec.2009, Jan.2010, Feb.2010, Mar.2010, Apr.2010, 
May.2010, Jun.2010, Jul.2010, Aug.2010, Sep.2010, Oct.2010, Nov.2010, 
Dec.2010
min values  :    13279,    13201,    13522,    13901,    14132, 
14360,    13865,    12649,    12048,    14142,    14031, 13868,    13667
max values  :    15612,    15766,    16223,    16496,    16716, 
16647,    16671,    16357,    16439,    16467,    16382, 15886,    15671
             : Dec 2009, Jan 2010, Feb 2010, Mar 2010, Apr 2010, May 
2010, Jun 2010, Jul 2010, Aug 2010, Sep 2010, Oct 2010, Nov 2010, Dec 2010

 >fix(dy)#changed time stamp of first tile to 3rd January

 > dy
  [1] "2010-01-03 IST" "2010-01-09 IST" "2010-01-17 IST" "2010-01-25 
IST" "2010-02-02 IST" "2010-02-10 IST" "2010-02-18 IST" "2010-02-26 IST" 
"2010-03-06 IST" "2010-03-14 IST" "2010-03-22 IST" "2010-03-30 IST"
[13] "2010-04-07 IST" "2010-04-15 IST" "2010-04-23 IST" "2010-05-01 IST" 
"2010-05-09 IST" "2010-05-17 IST" "2010-05-25 IST" "2010-06-02 IST" 
"2010-06-10 IST" "2010-06-18 IST" "2010-06-26 IST" "2010-07-04 IST"
[25] "2010-07-12 IST" "2010-07-20 IST" "2010-07-28 IST" "2010-08-05 IST" 
"2010-08-13 IST" "2010-08-21 IST" "2010-08-29 IST" "2010-09-06 IST" 
"2010-09-14 IST" "2010-09-22 IST" "2010-09-30 IST" "2010-10-08 IST"
[37] "2010-10-16 IST" "2010-10-24 IST" "2010-11-01 IST" "2010-11-09 IST" 
"2010-11-17 IST" "2010-11-25 IST" "2010-12-03 IST" "2010-12-11 IST" 
"2010-12-19 IST" "2010-12-27 IST"

 > LSTWG<-setZ(LSTWG,as.POSIXct(dy))

 > LSTWG #raster brick for year 2010, time stamp manually changed.

class       : RasterBrick
dimensions  : 3334, 2294, 7648196, 46  (nrow, ncol, ncell, nlayers)
resolution  : 1000.16, 999.8986  (x, y)
extent      : -728812.9, 1565553, -1033.987, 3332628  (xmin, xmax, ymin, 
ymax)
coord. ref. : +proj=utm +no_defs +zone=43 +a=6378137 +rf=298.257223563 
+towgs84=0.000,0.000,0.000 +to_meter=1
data source : in memory
names       : X2010.01.01, X2010.01.09, X2010.01.17, X2010.01.25, 
X2010.02.02, X2010.02.10, X2010.02.18, X2010.02.26, X2010.03.06, 
X2010.03.14, X2010.03.22, X2010.03.30, X2010.04.07, X2010.04.15, 
X2010.04.23, ...
min values  :       13279,       13136,       13159, 13201,       
13116,       13179,       13379,       13522, 13622,       13758,       
13901,       13865,       14132, 14007,       13915, ...
max values  :       15612,       15722,       15766, 15734,       
15808,       16005,       16145,       16223, 16409,       16493,       
16333,       16496,       16546, 16694,       16716, ...
time        : 2010-01-03, 2010-12-27 (min, max)

 > LSTWGm<-zApply(LSTWG,by=as.yearmon,fun=max)

 > LSTWGm
class       : RasterBrick
dimensions  : 3334, 2294, 7648196, 12  (nrow, ncol, ncell, nlayers)
resolution  : 1000.16, 999.8986  (x, y)
extent      : -728812.9, 1565553, -1033.987, 3332628  (xmin, xmax, ymin, 
ymax)
coord. ref. : +proj=utm +no_defs +zone=43 +a=6378137 +rf=298.257223563 
+towgs84=0.000,0.000,0.000 +to_meter=1
data source : 
/tmp/R_raster_karthik/raster_tmp_2014-09-09_114723_2361_46029.grd
names       : Jan.2010, Feb.2010, Mar.2010, Apr.2010, May.2010, 
Jun.2010, Jul.2010, Aug.2010, Sep.2010, Oct.2010, Nov.2010, Dec.2010
min values  :    13279,    13522,    13901,    14132,    14360, 
13865,    12649,    12048,    14142,    14031,    13868,    13667
max values  :    15766,    16223,    16496,    16716,    16647, 
16671,    16357,    16439,    16467,    16382,    15886,    15671
             : Jan 2010, Feb 2010, Mar 2010, Apr 2010, May 2010, Jun 
2010, Jul 2010, Aug 2010, Sep 2010, Oct 2010, Nov 2010, Dec 2010


Regards

-- 

Srinivas Vaidyanathan
Senior Research Fellow
Foundation for Ecological Research, Advocacy & Learning
Web: www.feralindia.org


From R.Catarino at MARLAB.AC.UK  Fri Sep 19 11:18:57 2014
From: R.Catarino at MARLAB.AC.UK (Rui Catarino)
Date: Fri, 19 Sep 2014 09:18:57 +0000
Subject: [R-sig-Geo] Spatial maximisation problem using polygons
Message-ID: <E6A33FD8E2E10040B0E8A72F3FAA0F49010477@sose0027g.marlab.ac.uk>

Hi,

This is not a very objective question and I apologise for that in advance.  What I'm really looking for is some pointers on where to start or where to look for information. I've been looking in the web for the last couple of days and found very little. That might be because I'm failing in using the right key words or R is not the tool which I doubt, so here I am asking the experts.

So basically I have a grid in which, each cell is a square and it has a certain value. The grid values change every week and every week I need to generate multiple polygons of fixed size (4 cells of the grid). The polygons value (sum of cell values) should be maximised but polygons cannot be adjacent and need to have a spacing of at least one cell between them.

The task will get a lot more complex with a few more constrains but I think if I get some pointers, papers or similar examples I could start from there.
I can generate the grid but I failed to find similar examples in the internet on regular polygon placement or maximisation.

Any help will be very much appreciated.
Cheers


Rui Catarino
Data Analyst/Modeller
Fishery Analysis and Assessment Group
Marine Scotland - Science

Scottish Government | B15 | Marine Laboratory, 375, Victoria Road | Aberdeen AB11 9DB

Tel:  +44 (0)1224 295572
Mob:+44 (0)7530 240666
Fax: +44 (0)1224 295511
r.catarino at marlab.ac.uk<mailto:r.catarino at marlab.ac.uk>
rui.catarino at scotland.gsi.gov.uk<mailto:rui.catarino at scotland.gsi.gov.uk>
www.scotland.gov.uk/marinescotland<http://www.scotland.gov.uk/marinescotland>


______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________
	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Fri Sep 19 11:23:11 2014
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 19 Sep 2014 19:23:11 +1000
Subject: [R-sig-Geo] Trying to install rgdal from source on Windows 7
	(and failing)
In-Reply-To: <alpine.LRH.2.03.1409191005000.3380@reclus.nhh.no>
References: <541B17BD.5070207@nmsu.edu>
	<A83620D4CC4762448EFB789FD6E9BBB742A2CFB4@SCOMP0937.wurnet.nl>
	<alpine.LRH.2.03.1409191005000.3380@reclus.nhh.no>
Message-ID: <CAAcGz9_ELs=f9hnpGO689Fh1gC2UVfqEjOHqy-ujX9ZFkqnerA@mail.gmail.com>

Do we have the process used by CRAN to cross compile for Windows? I have
the original notes but they are not complete especially for non gurus. It
seems that prospects for support are more likely with this approach. I find
the Windows config path very hard to understand.

Still, I am keen to get this on Windows too if anyone else wants to start
digging.

rgdal2 works with GDAL 2.0 but requires the linux gdal-config to be
present. rgdal won't work with GDAL 2.0 but again I can spend time in the
hole if others are able to help or encourage.

I am not sure many users realize the enormity of this impending crisis

Cheers, Mike
On 19 Sep 2014 18:17, "Roger Bivand" <Roger.Bivand at nhh.no> wrote:

> On Fri, 19 Sep 2014, Dutrieux, Loic wrote:
>
>  You may try some steps documented in the README.windows file, included in
>> the package sources. https://r-forge.r-project.org/
>> scm/viewvc.php/pkg/inst/README.windows?view=markup&root=rgdal
>>
>
> Thank you for pointing to this file.
>
>  But note that the file has not been updated in a little while. I can't
>> tell whether this is still likely to work or not...
>>
>>
> This is correct.
>
> My feeling is that installing rgdal from source on Windows is going to
> take (much) more time learning about compilers and their peculiarities than
> using command line utilities distributed in the PostGIS bundle for Windows:
>
> http://postgis.net/windows_downloads
>
> There shp2pgsql and pgsql2shp are mentioned, but as GDAL is also
> installed, ogr2ogr would let you use other intermediate file formats than
> ESRI Shapefiles, provided that the drivers are in the rgdal Windows binary
> package. Writing a small R function to run and check system() or system2()
> to run the command line utilities from inside R will be much easier than
> installing rgdal from source unless you know a lot about the compliers used
> with PostGIS and R. It also removes concerns that some components may be
> 32-bit or 64-bit.
>
> Hope this helps,
>
> Roger
>
>  Cheers,
>> Lo?c
>> ________________________________________
>> From: r-sig-geo-bounces at r-project.org [r-sig-geo-bounces at r-project.org]
>> on behalf of Cynthia Hart [cyndyh at nmsu.edu]
>> Sent: Thursday, September 18, 2014 7:34 PM
>> To: r-sig-geo at r-project.org
>> Cc: cyndyh at nmsu.edu
>> Subject: [R-sig-Geo] Trying to install rgdal from source on Windows 7
>> (and      failing)
>>
>> I have been using the (wonderfully useful) rgdal package for some time
>> now, but I now have a need to incorporate rgdal with PostGIS/PostgreSQL,
>> so, I find that I need more drivers than were included with the CRAN
>> release version of rdgal that I was using.  I have GDAL already
>> installed.   However, I am unable to build rgdal from source.  I have
>> the rgdal_0.8-16.tar file, and when I try to run install.packages from
>> this tar file, I get"
>>
>>        install.packages("C:\\JORNADA\\rgdal_0.8-16.tar", repos = NULL,
>> type="source")
>>        Installing package into ?C:/Users/cynthart/Documents/
>> R/win-library/3.0?
>>        (as ?lib? is unspecified)
>>        * installing *source* package 'rgdal' ...
>>        ** package 'rgdal' successfully unpacked and MD5 sums checked
>> *       cp: cannot stat `/share/proj': No such file or directory
>>        cp: cannot stat `/share/gdal': No such file or directory*
>>        ERROR: configuration failed for package 'rgdal'
>>        * removing 'C:/Users/cynthart/Documents/R/win-library/3.0/rgdal'
>>        Warning in install.packages :
>>        running command '"C:/PROGRA~1/R/R-30~1.1/bin/x64/R" CMD INSTALL
>> -l "C:\Users\cynthart\Doc               uments\R\win-library\3.0"
>> "C:/JORNADA/rgdal_0.8-16.tar"' had status 1
>>        Warning in install.packages :
>>        installation of package ?C:/JORNADA/rgdal_0.8-16.tar? had non-zero
>> exit status
>>
>> I basically understand the error, but I do not know how to go about
>> 'fixing' it.  Can anyone please point me in the right direction?  Thank you!
>>
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Fri Sep 19 12:14:42 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 19 Sep 2014 12:14:42 +0200
Subject: [R-sig-Geo] Trying to install rgdal from source on Windows 7
 (and failing)
In-Reply-To: <CAAcGz9_ELs=f9hnpGO689Fh1gC2UVfqEjOHqy-ujX9ZFkqnerA@mail.gmail.com>
References: <541B17BD.5070207@nmsu.edu>
	<A83620D4CC4762448EFB789FD6E9BBB742A2CFB4@SCOMP0937.wurnet.nl>
	<alpine.LRH.2.03.1409191005000.3380@reclus.nhh.no>
	<CAAcGz9_ELs=f9hnpGO689Fh1gC2UVfqEjOHqy-ujX9ZFkqnerA@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1409191125570.3380@reclus.nhh.no>

On Fri, 19 Sep 2014, Michael Sumner wrote:

> Do we have the process used by CRAN to cross compile for Windows? I have
> the original notes but they are not complete especially for non gurus. It
> seems that prospects for support are more likely with this approach. I find
> the Windows config path very hard to understand.
>
> Still, I am keen to get this on Windows too if anyone else wants to start
> digging.

CRAN Windows rgdal binary packages are built statically linked (OSX 
binaries are also statically linked), so it is very much harder to include 
drivers involving external libraries.

For OSX, Kyngchaos remains a viable alternative for binary installs of 
rgdal.

It may be worth revisiting OSGeo4W as a route to a (slightly) wider range 
of drivers under Windows. There has been some mention of R on the 
OSGeo4W-dev list and in a ticket:

http://trac.osgeo.org/osgeo4w/ticket/413

but I think that it would call for a good deal of commitment to get 
OSGeo4W with rgdal, R, and more drivers to the level of Kyngchaos for OSX.

In general the conservative approach taken for CRAN external dependencies 
is well-motivated. The GDAL, PROJ.4 and GEOS external dependencies are 
satisfied thanks to work by Brian Ripley, Uwe Ligges and Simon Urbanek. 
For the vast majority of users, these drivers are sufficient. For almost 
everybody else, using a command line utility via system() is the best 
route to take. The level of complexity increases as a power of the number 
of different components and compilers.


>
> rgdal2 works with GDAL 2.0 but requires the linux gdal-config to be
> present. rgdal won't work with GDAL 2.0 but again I can spend time in the
> hole if others are able to help or encourage.
>

It may be worth adding the required #ifdef code to support GDAL 2.0 in 
rgdal, but GDAL 2.0 is not close to release. There is discussion on 
releasing GDAL 1.11.1, and current rgdal works as expected with the 
current 1.11 development branch of GDAL:

http://lists.osgeo.org/pipermail/gdal-dev/2014-September/040077.html

as well as the forthcoming PROJ.4 4.9.0:

http://lists.maptools.org/pipermail/proj/2014-September/006911.html

especially as GDAL 1.11.* is the stable branch and GDAL 2.* is still 
effectively experimental.

> I am not sure many users realize the enormity of this impending crisis

The real danger to GDAL and PROJ.4 is the very narrow developer base, 
(PROJ.4: > 90% commits Frank Warmerdam; GDAL: 23% commits Frank Warmerdam, 
50% Even Roualt, others most often in specific drivers or SWIG 
interfaces).

We all owe them more than we can imagine for their dedication and 
commitment.

Roger



>
> Cheers, Mike
> On 19 Sep 2014 18:17, "Roger Bivand" <Roger.Bivand at nhh.no> wrote:
>
>> On Fri, 19 Sep 2014, Dutrieux, Loic wrote:
>>
>>  You may try some steps documented in the README.windows file, included in
>>> the package sources. https://r-forge.r-project.org/
>>> scm/viewvc.php/pkg/inst/README.windows?view=markup&root=rgdal
>>>
>>
>> Thank you for pointing to this file.
>>
>>  But note that the file has not been updated in a little while. I can't
>>> tell whether this is still likely to work or not...
>>>
>>>
>> This is correct.
>>
>> My feeling is that installing rgdal from source on Windows is going to
>> take (much) more time learning about compilers and their peculiarities than
>> using command line utilities distributed in the PostGIS bundle for Windows:
>>
>> http://postgis.net/windows_downloads
>>
>> There shp2pgsql and pgsql2shp are mentioned, but as GDAL is also
>> installed, ogr2ogr would let you use other intermediate file formats than
>> ESRI Shapefiles, provided that the drivers are in the rgdal Windows binary
>> package. Writing a small R function to run and check system() or system2()
>> to run the command line utilities from inside R will be much easier than
>> installing rgdal from source unless you know a lot about the compliers used
>> with PostGIS and R. It also removes concerns that some components may be
>> 32-bit or 64-bit.
>>
>> Hope this helps,
>>
>> Roger
>>
>>  Cheers,
>>> Lo?c
>>> ________________________________________
>>> From: r-sig-geo-bounces at r-project.org [r-sig-geo-bounces at r-project.org]
>>> on behalf of Cynthia Hart [cyndyh at nmsu.edu]
>>> Sent: Thursday, September 18, 2014 7:34 PM
>>> To: r-sig-geo at r-project.org
>>> Cc: cyndyh at nmsu.edu
>>> Subject: [R-sig-Geo] Trying to install rgdal from source on Windows 7
>>> (and      failing)
>>>
>>> I have been using the (wonderfully useful) rgdal package for some time
>>> now, but I now have a need to incorporate rgdal with PostGIS/PostgreSQL,
>>> so, I find that I need more drivers than were included with the CRAN
>>> release version of rdgal that I was using.  I have GDAL already
>>> installed.   However, I am unable to build rgdal from source.  I have
>>> the rgdal_0.8-16.tar file, and when I try to run install.packages from
>>> this tar file, I get"
>>>
>>>        install.packages("C:\\JORNADA\\rgdal_0.8-16.tar", repos = NULL,
>>> type="source")
>>>        Installing package into ?C:/Users/cynthart/Documents/
>>> R/win-library/3.0?
>>>        (as ?lib? is unspecified)
>>>        * installing *source* package 'rgdal' ...
>>>        ** package 'rgdal' successfully unpacked and MD5 sums checked
>>> *       cp: cannot stat `/share/proj': No such file or directory
>>>        cp: cannot stat `/share/gdal': No such file or directory*
>>>        ERROR: configuration failed for package 'rgdal'
>>>        * removing 'C:/Users/cynthart/Documents/R/win-library/3.0/rgdal'
>>>        Warning in install.packages :
>>>        running command '"C:/PROGRA~1/R/R-30~1.1/bin/x64/R" CMD INSTALL
>>> -l "C:\Users\cynthart\Doc               uments\R\win-library\3.0"
>>> "C:/JORNADA/rgdal_0.8-16.tar"' had status 1
>>>        Warning in install.packages :
>>>        installation of package ?C:/JORNADA/rgdal_0.8-16.tar? had non-zero
>>> exit status
>>>
>>> I basically understand the error, but I do not know how to go about
>>> 'fixing' it.  Can anyone please point me in the right direction?  Thank you!
>>>
>>>
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From r.hijmans at gmail.com  Fri Sep 19 16:01:41 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Fri, 19 Sep 2014 07:01:41 -0700
Subject: [R-sig-Geo] Spatial maximisation problem using polygons
In-Reply-To: <E6A33FD8E2E10040B0E8A72F3FAA0F49010477@sose0027g.marlab.ac.uk>
References: <E6A33FD8E2E10040B0E8A72F3FAA0F49010477@sose0027g.marlab.ac.uk>
Message-ID: <CANtt_hyMTs4V_xDey5UUO36+nm4togks7USYUrtysxPWNXAKjw@mail.gmail.com>

Rui,
You could create a matrix (=raster) and a function that creates a
valid set of groups of 4 cells that are not adjacent. The function
should return the solution (output matrix values: TRUE or FALSE) and
the sum of the selected values. Then use the optim function to
optimize based on the sum. When you have an optimal solution, create a
raster from the matrix and coerce that to polygons.

On Fri, Sep 19, 2014 at 2:18 AM, Rui Catarino <R.Catarino at marlab.ac.uk> wrote:
> Hi,
>
> This is not a very objective question and I apologise for that in advance.  What I'm really looking for is some pointers on where to start or where to look for information. I've been looking in the web for the last couple of days and found very little. That might be because I'm failing in using the right key words or R is not the tool which I doubt, so here I am asking the experts.
>
> So basically I have a grid in which, each cell is a square and it has a certain value. The grid values change every week and every week I need to generate multiple polygons of fixed size (4 cells of the grid). The polygons value (sum of cell values) should be maximised but polygons cannot be adjacent and need to have a spacing of at least one cell between them.
>
> The task will get a lot more complex with a few more constrains but I think if I get some pointers, papers or similar examples I could start from there.
> I can generate the grid but I failed to find similar examples in the internet on regular polygon placement or maximisation.
>
> Any help will be very much appreciated.
> Cheers
>
>
> Rui Catarino
> Data Analyst/Modeller
> Fishery Analysis and Assessment Group
> Marine Scotland - Science
>
> Scottish Government | B15 | Marine Laboratory, 375, Victoria Road | Aberdeen AB11 9DB
>
> Tel:  +44 (0)1224 295572
> Mob:+44 (0)7530 240666
> Fax: +44 (0)1224 295511
> r.catarino at marlab.ac.uk<mailto:r.catarino at marlab.ac.uk>
> rui.catarino at scotland.gsi.gov.uk<mailto:rui.catarino at scotland.gsi.gov.uk>
> www.scotland.gov.uk/marinescotland<http://www.scotland.gov.uk/marinescotland>
>
>
> ______________________________________________________________________
> This email has been scanned by the Symantec Email Security.cloud service.
> For more information please visit http://www.symanteccloud.com
> ______________________________________________________________________
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From cyndyh at nmsu.edu  Fri Sep 19 20:38:39 2014
From: cyndyh at nmsu.edu (Cynthia Hart)
Date: Fri, 19 Sep 2014 11:38:39 -0700
Subject: [R-sig-Geo] Trying to install rgdal from source on Windows 7
 (and	failing)
In-Reply-To: <alpine.LRH.2.03.1409191005000.3380@reclus.nhh.no>
References: <541B17BD.5070207@nmsu.edu>
	<A83620D4CC4762448EFB789FD6E9BBB742A2CFB4@SCOMP0937.wurnet.nl>
	<alpine.LRH.2.03.1409191005000.3380@reclus.nhh.no>
Message-ID: <541C782F.2010804@nmsu.edu>

Ah.  So, at the least I am not missing something obvious.  But I had 
missed knowing about the Window PostGIS tools!  Thank you, Roger; what 
you suggest sounds like a good route for me to take, for the time being.

Cynthia

On 9/19/2014 1:15 AM, Roger Bivand wrote:
> On Fri, 19 Sep 2014, Dutrieux, Loic wrote:
>
>> You may try some steps documented in the README.windows file, 
>> included in the package sources. 
>> https://r-forge.r-project.org/scm/viewvc.php/pkg/inst/README.windows?view=markup&root=rgdal
>
> Thank you for pointing to this file.
>
>> But note that the file has not been updated in a little while. I 
>> can't tell whether this is still likely to work or not...
>>
>
> This is correct.
>
> My feeling is that installing rgdal from source on Windows is going to 
> take (much) more time learning about compilers and their peculiarities 
> than using command line utilities distributed in the PostGIS bundle 
> for Windows:
>
> http://postgis.net/windows_downloads
>
> There shp2pgsql and pgsql2shp are mentioned, but as GDAL is also 
> installed, ogr2ogr would let you use other intermediate file formats 
> than ESRI Shapefiles, provided that the drivers are in the rgdal 
> Windows binary package. Writing a small R function to run and check 
> system() or system2() to run the command line utilities from inside R 
> will be much easier than installing rgdal from source unless you know 
> a lot about the compliers used with PostGIS and R. It also removes 
> concerns that some components may be 32-bit or 64-bit.
>
> Hope this helps,
>
> Roger
>
>> Cheers,
>> Lo?c
>> ________________________________________
>> From: r-sig-geo-bounces at r-project.org 
>> [r-sig-geo-bounces at r-project.org] on behalf of Cynthia Hart 
>> [cyndyh at nmsu.edu]
>> Sent: Thursday, September 18, 2014 7:34 PM
>> To: r-sig-geo at r-project.org
>> Cc: cyndyh at nmsu.edu
>> Subject: [R-sig-Geo] Trying to install rgdal from source on Windows 7 
>> (and      failing)
>>
>> I have been using the (wonderfully useful) rgdal package for some time
>> now, but I now have a need to incorporate rgdal with PostGIS/PostgreSQL,
>> so, I find that I need more drivers than were included with the CRAN
>> release version of rdgal that I was using.  I have GDAL already
>> installed.   However, I am unable to build rgdal from source.  I have
>> the rgdal_0.8-16.tar file, and when I try to run install.packages from
>> this tar file, I get"
>>
>>        install.packages("C:\\JORNADA\\rgdal_0.8-16.tar", repos = 
>> NULL, type="source")
>>        Installing package into 
>> ?C:/Users/cynthart/Documents/R/win-library/3.0?
>>        (as ?lib? is unspecified)
>>        * installing *source* package 'rgdal' ...
>>        ** package 'rgdal' successfully unpacked and MD5 sums checked
>> *       cp: cannot stat `/share/proj': No such file or directory
>>        cp: cannot stat `/share/gdal': No such file or directory*
>>        ERROR: configuration failed for package 'rgdal'
>>        * removing 'C:/Users/cynthart/Documents/R/win-library/3.0/rgdal'
>>        Warning in install.packages :
>>        running command '"C:/PROGRA~1/R/R-30~1.1/bin/x64/R" CMD 
>> INSTALL -l "C:\Users\cynthart\Doc uments\R\win-library\3.0" 
>> "C:/JORNADA/rgdal_0.8-16.tar"' had status 1
>>        Warning in install.packages :
>>        installation of package ?C:/JORNADA/rgdal_0.8-16.tar? had 
>> non-zero exit status
>>
>> I basically understand the error, but I do not know how to go about 
>> 'fixing' it.  Can anyone please point me in the right direction?  
>> Thank you!
>>
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From brian.buma at uas.alaska.edu  Sat Sep 20 02:37:30 2014
From: brian.buma at uas.alaska.edu (Brian Buma)
Date: Fri, 19 Sep 2014 16:37:30 -0800
Subject: [R-sig-Geo] Mosaic Rasters
Message-ID: <CAM25M7rSaNd=y5=7hw2moZ4s--UbRRKTLrY9jRyzrY1Uir2DGg@mail.gmail.com>

I apologize I don't have reproduce-able code, but I don't entirely
understand the error.

I have a list of rasters which are all subsets of the same watershed,
created from a lidar dataset.  Because of memory limitations, I had to
process in chunks, and now I'm mosaicing them back together.  The code is a
quick for loop, and it loads one, mosaics it to the previous one, and then
moves onto the next one.

However, sometimes I get an error of "Error in v[cells, i] <-
getValues(x[[i]]) :
  number of items to replace is not a multiple of replacement length"

I understand what that means in terms of vectors and things, but I don't
get it for the raster.  I thought perhaps it was because each chunk wasn't
exactly the same size in terms of rows and columns (all are the same
resolution).  But if I skip the chunks that kick out that error, then go
back and mosaic them at the end, it works.  So with careful ordering of my
input chunks, I can get the whole mosaic out.  Why would that be?
 Shouldn't mosaic be able to handle all sorts of various extents, assuming
the projection, resolution, and origin are the same?  Maybe that's not the
problem?

Again, apologize for not having more info to go on, but I don't really know
what is going wrong so I can't recreate the error in a code snippet.

-brian

	[[alternative HTML version deleted]]


From loic.dutrieux at wur.nl  Sat Sep 20 16:02:09 2014
From: loic.dutrieux at wur.nl (=?windows-1252?Q?Lo=EFc?=)
Date: Sat, 20 Sep 2014 16:02:09 +0200
Subject: [R-sig-Geo] Error in zapply?
In-Reply-To: <541BED00.4080809@feralindia.org>
References: <541BED00.4080809@feralindia.org>
Message-ID: <541D88E1.2070700@wur.nl>

Hi Srivinas,

The as.POSIXct() is probably the reason why it falls back in the 
previous year for January 1st. If dates is sufficient, then use as.Date().

See reproducible example:

library(raster)
library(zoo)

time <- as.Date("2004-01-01") + seq(0,365,8)
r <- raster(nc=10, nr=10)
s <- brick(lapply(1:length(time), function(x) setValues(r, 
G0dm[x]+100*rnorm(ncell(r)) )))
s <- setZ(s, time)

zApply(s, by = as.yearmon, fun = max)

Hope this helps,
Lo?c


On 19/09/2014 10:44, Srinivas V wrote:
> Hi,
>
> I have a raster brick of MODIS 8 day LST data and I'm trying to generate
> a brick with monthly maximum LST values for the time period 2000-2013.
> I'm using the zoo and raster packages to get monthly averages, however
> it appears that the zapply function does not handle 1st January very
> well.To illustrate the problem I have provided outputs for a single
> year, instead of returning a brick with 12 layers it returns a brick
> with 13 layers and the first layer is assigned to December of the
> previous year.
>
> I have also manually changed the time stamp from 1st January to 3rd
> January and it works fine. However to do this across multiple tiles and
> across years is going to problematic and I cannot automate the
> processing.  Is this a bug and what is the alternative?
>
> I would appreciate any advice on dealing with this issue.
>
> Thanks!
>
> library(raster)
> library(zoo)
>
>
>   > dy #dates extracted from file names
>    [1] "2010-01-01 IST" "2010-01-09 IST" "2010-01-17 IST" "2010-01-25
> IST" "2010-02-02 IST" "2010-02-10 IST" "2010-02-18 IST" "2010-02-26 IST"
> "2010-03-06 IST" "2010-03-14 IST" "2010-03-22 IST" "2010-03-30 IST"
> [13] "2010-04-07 IST" "2010-04-15 IST" "2010-04-23 IST" "2010-05-01 IST"
> "2010-05-09 IST" "2010-05-17 IST" "2010-05-25 IST" "2010-06-02 IST"
> "2010-06-10 IST" "2010-06-18 IST" "2010-06-26 IST" "2010-07-04 IST"
> [25] "2010-07-12 IST" "2010-07-20 IST" "2010-07-28 IST" "2010-08-05 IST"
> "2010-08-13 IST" "2010-08-21 IST" "2010-08-29 IST" "2010-09-06 IST"
> "2010-09-14 IST" "2010-09-22 IST" "2010-09-30 IST" "2010-10-08 IST"
> [37] "2010-10-16 IST" "2010-10-24 IST" "2010-11-01 IST" "2010-11-09 IST"
> "2010-11-17 IST" "2010-11-25 IST" "2010-12-03 IST" "2010-12-11 IST"
> "2010-12-19 IST" "2010-12-27 IST"
>
>   > as.yearmon(dy)# no problem here, as.yearmon() is a function from
> package zoo
>
>    [1] "Jan 2010" "Jan 2010" "Jan 2010" "Jan 2010" "Feb 2010" "Feb 2010"
> "Feb 2010" "Feb 2010" "Mar 2010" "Mar 2010" "Mar 2010" "Mar 2010" "Apr
> 2010" "Apr 2010" "Apr 2010" "May 2010" "May 2010" "May 2010" "May 2010"
> [20] "Jun 2010" "Jun 2010" "Jun 2010" "Jun 2010" "Jul 2010" "Jul 2010"
> "Jul 2010" "Jul 2010" "Aug 2010" "Aug 2010" "Aug 2010" "Aug 2010" "Sep
> 2010" "Sep 2010" "Sep 2010" "Sep 2010" "Oct 2010" "Oct 2010" "Oct 2010"
> [39] "Nov 2010" "Nov 2010" "Nov 2010" "Nov 2010" "Dec 2010" "Dec 2010"
> "Dec 2010" "Dec 2010"
>
>   > LSTWG<-setZ(LSTWG,as.POSIXct(dy))#setZ used to set time stamp
>
>   > LSTWG #raster brick for year 2010
> class       : RasterBrick
> dimensions  : 3334, 2294, 7648196, 46  (nrow, ncol, ncell, nlayers)
> resolution  : 1000.16, 999.8986  (x, y)
> extent      : -728812.9, 1565553, -1033.987, 3332628  (xmin, xmax, ymin,
> ymax)
> coord. ref. : +proj=utm +no_defs +zone=43 +a=6378137 +rf=298.257223563
> +towgs84=0.000,0.000,0.000 +to_meter=1
> data source : in memory
> names       : X2010.01.01, X2010.01.09, X2010.01.17, X2010.01.25,
> X2010.02.02, X2010.02.10, X2010.02.18, X2010.02.26, X2010.03.06,
> X2010.03.14, X2010.03.22, X2010.03.30, X2010.04.07, X2010.04.15,
> X2010.04.23, ...
> min values  :       13279,       13136,       13159, 13201,
> 13116,       13179,       13379,       13522, 13622,       13758,
> 13901,       13865,       14132, 14007,       13915, ...
> max values  :       15612,       15722,       15766, 15734,
> 15808,       16005,       16145,       16223, 16409,       16493,
> 16333,       16496,       16546, 16694,       16716, ...
> time        : 2010-01-01, 2010-12-27 (min, max)
>
>   > LSTWGm<-zApply(LSTWG,by=as.yearmon,fun=max)
>
>   > LSTWGm #instead of returning a brick with 12 layers it returns a
> brick with 13 layers and the first layer is assigned to December of the
> previous year
> class       : RasterBrick
> dimensions  : 3334, 2294, 7648196, 13  (nrow, ncol, ncell, nlayers)
> resolution  : 1000.16, 999.8986  (x, y)
> extent      : -728812.9, 1565553, -1033.987, 3332628  (xmin, xmax, ymin,
> ymax)
> coord. ref. : +proj=utm +no_defs +zone=43 +a=6378137 +rf=298.257223563
> +towgs84=0.000,0.000,0.000 +to_meter=1
> data source :
> /tmp/R_raster_karthik/raster_tmp_2014-09-09_114458_2361_81754.grd
> names       : Dec.2009, Jan.2010, Feb.2010, Mar.2010, Apr.2010,
> May.2010, Jun.2010, Jul.2010, Aug.2010, Sep.2010, Oct.2010, Nov.2010,
> Dec.2010
> min values  :    13279,    13201,    13522,    13901,    14132,
> 14360,    13865,    12649,    12048,    14142,    14031, 13868,    13667
> max values  :    15612,    15766,    16223,    16496,    16716,
> 16647,    16671,    16357,    16439,    16467,    16382, 15886,    15671
>               : Dec 2009, Jan 2010, Feb 2010, Mar 2010, Apr 2010, May
> 2010, Jun 2010, Jul 2010, Aug 2010, Sep 2010, Oct 2010, Nov 2010, Dec 2010
>
>   >fix(dy)#changed time stamp of first tile to 3rd January
>
>   > dy
>    [1] "2010-01-03 IST" "2010-01-09 IST" "2010-01-17 IST" "2010-01-25
> IST" "2010-02-02 IST" "2010-02-10 IST" "2010-02-18 IST" "2010-02-26 IST"
> "2010-03-06 IST" "2010-03-14 IST" "2010-03-22 IST" "2010-03-30 IST"
> [13] "2010-04-07 IST" "2010-04-15 IST" "2010-04-23 IST" "2010-05-01 IST"
> "2010-05-09 IST" "2010-05-17 IST" "2010-05-25 IST" "2010-06-02 IST"
> "2010-06-10 IST" "2010-06-18 IST" "2010-06-26 IST" "2010-07-04 IST"
> [25] "2010-07-12 IST" "2010-07-20 IST" "2010-07-28 IST" "2010-08-05 IST"
> "2010-08-13 IST" "2010-08-21 IST" "2010-08-29 IST" "2010-09-06 IST"
> "2010-09-14 IST" "2010-09-22 IST" "2010-09-30 IST" "2010-10-08 IST"
> [37] "2010-10-16 IST" "2010-10-24 IST" "2010-11-01 IST" "2010-11-09 IST"
> "2010-11-17 IST" "2010-11-25 IST" "2010-12-03 IST" "2010-12-11 IST"
> "2010-12-19 IST" "2010-12-27 IST"
>
>   > LSTWG<-setZ(LSTWG,as.POSIXct(dy))
>
>   > LSTWG #raster brick for year 2010, time stamp manually changed.
>
> class       : RasterBrick
> dimensions  : 3334, 2294, 7648196, 46  (nrow, ncol, ncell, nlayers)
> resolution  : 1000.16, 999.8986  (x, y)
> extent      : -728812.9, 1565553, -1033.987, 3332628  (xmin, xmax, ymin,
> ymax)
> coord. ref. : +proj=utm +no_defs +zone=43 +a=6378137 +rf=298.257223563
> +towgs84=0.000,0.000,0.000 +to_meter=1
> data source : in memory
> names       : X2010.01.01, X2010.01.09, X2010.01.17, X2010.01.25,
> X2010.02.02, X2010.02.10, X2010.02.18, X2010.02.26, X2010.03.06,
> X2010.03.14, X2010.03.22, X2010.03.30, X2010.04.07, X2010.04.15,
> X2010.04.23, ...
> min values  :       13279,       13136,       13159, 13201,
> 13116,       13179,       13379,       13522, 13622,       13758,
> 13901,       13865,       14132, 14007,       13915, ...
> max values  :       15612,       15722,       15766, 15734,
> 15808,       16005,       16145,       16223, 16409,       16493,
> 16333,       16496,       16546, 16694,       16716, ...
> time        : 2010-01-03, 2010-12-27 (min, max)
>
>   > LSTWGm<-zApply(LSTWG,by=as.yearmon,fun=max)
>
>   > LSTWGm
> class       : RasterBrick
> dimensions  : 3334, 2294, 7648196, 12  (nrow, ncol, ncell, nlayers)
> resolution  : 1000.16, 999.8986  (x, y)
> extent      : -728812.9, 1565553, -1033.987, 3332628  (xmin, xmax, ymin,
> ymax)
> coord. ref. : +proj=utm +no_defs +zone=43 +a=6378137 +rf=298.257223563
> +towgs84=0.000,0.000,0.000 +to_meter=1
> data source :
> /tmp/R_raster_karthik/raster_tmp_2014-09-09_114723_2361_46029.grd
> names       : Jan.2010, Feb.2010, Mar.2010, Apr.2010, May.2010,
> Jun.2010, Jul.2010, Aug.2010, Sep.2010, Oct.2010, Nov.2010, Dec.2010
> min values  :    13279,    13522,    13901,    14132,    14360,
> 13865,    12649,    12048,    14142,    14031,    13868,    13667
> max values  :    15766,    16223,    16496,    16716,    16647,
> 16671,    16357,    16439,    16467,    16382,    15886,    15671
>               : Jan 2010, Feb 2010, Mar 2010, Apr 2010, May 2010, Jun
> 2010, Jul 2010, Aug 2010, Sep 2010, Oct 2010, Nov 2010, Dec 2010
>
>
> Regards
>


From edzer.pebesma at uni-muenster.de  Sat Sep 20 16:32:59 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sat, 20 Sep 2014 16:32:59 +0200
Subject: [R-sig-Geo] %over% is omitting data
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3AC5F15@inbomail.inbo.be>
References: <AA818EAD2576BC488B4F623941DA7427F3AC5F15@inbomail.inbo.be>
Message-ID: <541D901B.8040304@uni-muenster.de>

Thierry, after looking at the data you sent me off-list, it turns out
that some polygons are contained in others. I tried:

x = over(basis.poly, basis.poly)
> any(x != 1:102)
[1] TRUE
> x[x != 1:102]
9731827  911327
     53      85

and plotted them with the ones you found omitted:

plot(basis.poly[c(53,54,85,86),])

over(x,y) or x %over% y returns a list with indexes with the first hit.
If you want all hits, try

over(x, y, returnList = TRUE)

and go through the list.

Hth,

On 07/25/2014 03:16 PM, ONKELINX, Thierry wrote:
> Dear all,
> 
> I use %over% to append the attributes of the SpatialPolygonsDataFrame to a SpatialGridDataFrame. It works fine expect for two polygons. Both are completely contained by the grid (see the summary below) and are large enough. Both cover several grid cell completely, so there should be output. Neither polygon is marked as a hole.
> 
> I'm out of ideas on what is going wrong. Any suggestions are welcome. I can send the data off list if required. The rda file is 4.3MB
> 
> Best regards,
> 
> Thierry
> 
>> library(rgdal)
>> combination <- basis.grid %over% basis.poly
>>   summary(combination)
>        ID
>  8731563:    607
>  9413613:    520
>  7623223:    359
>  3044067:    354
>  6812906:    337
>  (Other):   4757
>  NA's   :1111136
>>   summary(basis.grid)
> Object of class SpatialGridDataFrame
> Coordinates:
>         min      max
> x  22573.66 243973.7
> y 184600.44 235100.4
> Is projected: TRUE
> proj4string :
> [+proj=lcc +lat_1=49.8333339 +lat_2=51.16666733333333 +lat_0=90 +lon_0=4.367486666666666
> +x_0=150000.01256 +y_0=5400088.4378 +ellps=intl +units=m +no_defs]
> Grid attributes:
>   cellcentre.offset cellsize cells.dim
> x          22623.66      100      2214
> y         184650.44      100       505
> Data attributes:
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>       0  279500  559000  559000  838600 1118000
>>   summary(basis.poly)
> Object of class SpatialPolygonsDataFrame
> Coordinates:
>         min      max
> x  22573.66 243877.2
> y 184600.44 235090.9
> Is projected: TRUE
> proj4string :
> [+proj=lcc +lat_1=49.8333339 +lat_2=51.16666733333333 +lat_0=90 +lon_0=4.367486666666666
> +x_0=150000.01256 +y_0=5400088.4378 +ellps=intl +units=m +no_defs]
> Data attributes:
> 1104276 1184605 1212939 1321132  150057 1640781 1757090 1770778 1855918 2001918 2090205 2370933
>       1       1       1       1       1       1       1       1       1       1       1       1
>  241856 2590901 2659228 2957550 3040078 3042825 3044067  316529 3178448 3230545 3322126 3384170
>       1       1       1       1       1       1       1       1       1       1       1       1
> 3394372 3633380 3714251 3833887 3839772 3920302 3974872 4012319  411473 4155071 4193712  422510
>       1       1       1       1       1       1       1       1       1       1       1       1
> 4230828 4300995 4352428 4393061  446323 4477397 4559869 4599815 4720075 4849248  493549 4940272
>       1       1       1       1       1       1       1       1       1       1       1       1
> 5005842 5236141 5434095 5539529 5853116 5904606 6048855 6211032 6252318   63260 6377909 6496260
>       1       1       1       1       1       1       1       1       1       1       1       1
> 6812906 6890180 6958065 7190203 7284585 7316045 7389494 7477761 7484048 7613684 7618484 7623223
>       1       1       1       1       1       1       1       1       1       1       1       1
> 7682161 7708077  784327 7865873 7951049  798473 8175618 8208627 8227675 8359132 8370365 8434383
>       1       1       1       1       1       1       1       1       1       1       1       1
>  852311 8591606 8705267 8731563 8759351 8788624 8869929 8932474 8952361 9091973 9095956  911327
>       1       1       1       1       1       1       1       1       1       1       1       1
> 9228048 9296002 9413613 (Other)
>       1       1       1       3
>> which.missing <- which(!basis.poly$ID %in% unique(combination$ID))
>> which.missing
> [1] 54 86
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> 
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140920/57036b16/attachment.bin>

From r.hijmans at gmail.com  Mon Sep 22 12:50:09 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Mon, 22 Sep 2014 03:50:09 -0700
Subject: [R-sig-Geo] Mosaic Rasters
In-Reply-To: <CAM25M7rSaNd=y5=7hw2moZ4s--UbRRKTLrY9jRyzrY1Uir2DGg@mail.gmail.com>
References: <CAM25M7rSaNd=y5=7hw2moZ4s--UbRRKTLrY9jRyzrY1Uir2DGg@mail.gmail.com>
Message-ID: <CANtt_hwN6Bn=H1HYxWrFoHgqjGD8zczOzhELv=kKG12-7NgWEg@mail.gmail.com>

Brian,

What you can do in a situation like this (clearly a bug; difficult to
reproduce) is with your list "x":

y <- sapply(x, raster) # remove all valus
save(y, file='mosaic.RData')

and send the file (and explanation of how you get the error) to the
package maintainer (i.e., me, in this case).

Best, Robert

On Fri, Sep 19, 2014 at 5:37 PM, Brian Buma <brian.buma at uas.alaska.edu> wrote:
> I apologize I don't have reproduce-able code, but I don't entirely
> understand the error.
>
> I have a list of rasters which are all subsets of the same watershed,
> created from a lidar dataset.  Because of memory limitations, I had to
> process in chunks, and now I'm mosaicing them back together.  The code is a
> quick for loop, and it loads one, mosaics it to the previous one, and then
> moves onto the next one.
>
> However, sometimes I get an error of "Error in v[cells, i] <-
> getValues(x[[i]]) :
>   number of items to replace is not a multiple of replacement length"
>
> I understand what that means in terms of vectors and things, but I don't
> get it for the raster.  I thought perhaps it was because each chunk wasn't
> exactly the same size in terms of rows and columns (all are the same
> resolution).  But if I skip the chunks that kick out that error, then go
> back and mosaic them at the end, it works.  So with careful ordering of my
> input chunks, I can get the whole mosaic out.  Why would that be?
>  Shouldn't mosaic be able to handle all sorts of various extents, assuming
> the projection, resolution, and origin are the same?  Maybe that's not the
> problem?
>
> Again, apologize for not having more info to go on, but I don't really know
> what is going wrong so I can't recreate the error in a code snippet.
>
> -brian
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From jquets.rsiggeo at gmail.com  Mon Sep 22 13:17:34 2014
From: jquets.rsiggeo at gmail.com (jquets rsiggeo)
Date: Mon, 22 Sep 2014 13:17:34 +0200
Subject: [R-sig-Geo] rescaling spatstat owin window
Message-ID: <CAHJYoURmHU2-f655JfuNw5CJhj914St0MZQGCsTdxKizfT6uiA@mail.gmail.com>

Dear all,

does anybody know how to rescale a spatstat owin window (i.e. multiplying
all x and y coordinates of the polygon boundary with a certain factor)?

kind regards,
Jan

	[[alternative HTML version deleted]]


From marcelino.delacruz at upm.es  Mon Sep 22 14:14:32 2014
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Mon, 22 Sep 2014 14:14:32 +0200
Subject: [R-sig-Geo] rescaling spatstat owin window
In-Reply-To: <CAHJYoURmHU2-f655JfuNw5CJhj914St0MZQGCsTdxKizfT6uiA@mail.gmail.com>
References: <CAHJYoURmHU2-f655JfuNw5CJhj914St0MZQGCsTdxKizfT6uiA@mail.gmail.com>
Message-ID: <542012A8.9000904@upm.es>

It depends on what do you exactly mean by "rescale". May be with 
dilation() or affine():

  plot(letterR, xlim=c(0,10), ylim=c(0,10), main="")
  plot(dilation(letterR, .2), add=T, border=2)
  plot(affine(letterR, mat=diag(c(2,2)),vec=c(-2,-.65)), add=T, border=3)

Cheers,

Marcelino



El 22/09/2014 a las #4, jquets rsiggeo escribi?:
> Dear all,
>
> does anybody know how to rescale a spatstat owin window (i.e. multiplying
> all x and y coordinates of the polygon boundary with a certain factor)?
>
> kind regards,
> Jan
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From jquets.rsiggeo at gmail.com  Mon Sep 22 14:32:13 2014
From: jquets.rsiggeo at gmail.com (jquets rsiggeo)
Date: Mon, 22 Sep 2014 14:32:13 +0200
Subject: [R-sig-Geo] rescaling spatstat owin window
In-Reply-To: <542012A8.9000904@upm.es>
References: <CAHJYoURmHU2-f655JfuNw5CJhj914St0MZQGCsTdxKizfT6uiA@mail.gmail.com>
	<542012A8.9000904@upm.es>
Message-ID: <CAHJYoUTL21YQ2cYC5s0SL1XDOURZmtANQOAE9A6DXkF20OKoBw@mail.gmail.com>

Hi Marcelino,

by rescaling I mean changing the size of the polygon without changing its
shape,

so affine seems indeed what I'm looking for,

thanks!
Jan

2014-09-22 14:14 GMT+02:00 Marcelino de la Cruz <marcelino.delacruz at upm.es>:

> It depends on what do you exactly mean by "rescale". May be with
> dilation() or affine():
>
>  plot(letterR, xlim=c(0,10), ylim=c(0,10), main="")
>  plot(dilation(letterR, .2), add=T, border=2)
>  plot(affine(letterR, mat=diag(c(2,2)),vec=c(-2,-.65)), add=T, border=3)
>
> Cheers,
>
> Marcelino
>
>
>
> El 22/09/2014 a las #4, jquets rsiggeo escribi?:
>
>> Dear all,
>>
>> does anybody know how to rescale a spatstat owin window (i.e. multiplying
>> all x and y coordinates of the polygon boundary with a certain factor)?
>>
>> kind regards,
>> Jan
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Mon Sep 22 23:19:56 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 23 Sep 2014 09:19:56 +1200
Subject: [R-sig-Geo] rescaling spatstat owin window
In-Reply-To: <CAHJYoUTL21YQ2cYC5s0SL1XDOURZmtANQOAE9A6DXkF20OKoBw@mail.gmail.com>
References: <CAHJYoURmHU2-f655JfuNw5CJhj914St0MZQGCsTdxKizfT6uiA@mail.gmail.com>	<542012A8.9000904@upm.es>
	<CAHJYoUTL21YQ2cYC5s0SL1XDOURZmtANQOAE9A6DXkF20OKoBw@mail.gmail.com>
Message-ID: <5420927C.2000705@auckland.ac.nz>

On 23/09/14 00:32, jquets rsiggeo wrote:
> Hi Marcelino,
>
> by rescaling I mean changing the size of the polygon without changing its
> shape,
>
> so affine seems indeed what I'm looking for.


In addition to affine() you might also want to think about using 
rescale() and scalardilate().

I always find rescaling, simple though it is, to be a bit head-twisting.
Remember that if you "rescale everything" then replotting the 
"everything" will look no different than before; all you have really 
done is change the units (e.g. from metres to furlongs).  An obvious 
assertion but one that needs to be kept in mind (at least in my mind!).

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS


From adrian.baddeley at uwa.edu.au  Tue Sep 23 12:13:10 2014
From: adrian.baddeley at uwa.edu.au (Adrian Baddeley)
Date: Tue, 23 Sep 2014 18:13:10 +0800
Subject: [R-sig-Geo] rescale spatstat owin
In-Reply-To: <mailman.13.1411466404.30946.r-sig-geo@r-project.org>
References: <mailman.13.1411466404.30946.r-sig-geo@r-project.org>
Message-ID: <CF5661163F77A44781208D9AC4FDEA72751E90D1AE@IS-WIN-376.staffad.uwa.edu.au>

Jan Quets <jquets.rsiggeo at gmail.com> writes:

> does anybody know how to rescale a spatstat owin window (i.e. multiplying
> all x and y coordinates of the polygon boundary with a certain factor)?

scalardilate(W, f)

where W is your window and 'f' is the scaling factor (a single number). This will multiply all coordinates
by the number f.  The unit of length will be unchanged (so the resulting window is physically larger than
the original, if f > 1).

If you want to rescale a window from one unit of length to another, use 'rescale'.
For example if the window coordinates were given in metres and you want to convert them to kilometres,

   rescale(W, 1000)
or better
   rescale(W, 1000, unitname="km")

The result of 'rescale' is physically equivalent to the original, but is expressed in different units.

See help(scalardilate) and help(rescale).

Prof Adrian Baddeley FAA
University of Western Australia

From tyler.j.frazier at icloud.com  Tue Sep 23 20:01:14 2014
From: tyler.j.frazier at icloud.com (Tyler Frazier)
Date: Tue, 23 Sep 2014 20:01:14 +0200
Subject: [R-sig-Geo] which.max() limit in raster package for RasterBrick
Message-ID: <2F0B2008-7A95-42B4-8D6E-296C6B6A39D4@icloud.com>

Dear group,

I have a RasterBrick with 16 layers created with the stack command like so:

f <- list.files(pattern="*.nc$", recursive=TRUE)
r <- raster(f[1], band = 1)
harvest_area <- stack(r)
harvest_area at layers <- sapply(f, function(x) {r at file@name=x;r})
names(harvest_area) <- sub("\\/.*", "", f)

and then I want to apply which.max() to determine which layer is max for each grid cell.  It seems which.max() returns an error for a brick with more than 5? layers.

I have attempted various approaches to determine the max of each grid cell within a RasterBrick with more than 5 layers, but the only thing I can get to work is a very verbose approach (following the msg).

Various approaches using a defined function as such:

con <- function(condition, trueValue, falseValue) {return(condition * trueValue + (!condition)*falseValue)} 

including:

for (k in 1:length(harvest_area)) {test <- con(harvest_area[[k]] > harvest_area[[-k]], k, 0)}

and:

dom_ha <- con(harvest_area[[1]] > harvest_area[[-1]], 1,
		  con(harvest_area[[2]] > harvest_area[[-2]], 2,
		  con(harvest_area[[3]] > harvest_area[[-3]], 3,
                  con(harvest_area[[4]] > harvest_area[[-4]], 4,
                  con(harvest_area[[5]] > harvest_area[[-5]], 5,
                  con(harvest_area[[6]] > harvest_area[[-6]], 6,
                  con(harvest_area[[7]] > harvest_area[[-7]], 7,
                  con(harvest_area[[8]] > harvest_area[[-8]], 8,
                  con(harvest_area[[9]] > harvest_area[[-9]], 9,
                  con(harvest_area[[10]] > harvest_area[[-10]], 10,
                  con(harvest_area[[11]] > harvest_area[[-11]], 11,
                  con(harvest_area[[12]] > harvest_area[[-12]], 12,
                  con(harvest_area[[13]] > harvest_area[[-13]], 13,
                  con(harvest_area[[14]] > harvest_area[[-14]], 14,
                  con(harvest_area[[15]] > harvest_area[[-15]], 15,
                  con(harvest_area[[16]] > harvest_area[[-16]], 16, 0
                   ))))))))))))))))

didn?t work.  I also tried using stackApply() with function(x) but it returned an error similar to the which.max() > 5.  The only thing that work is the following, but its so verbose.  

Any suggestions will be much appreciated.

Thank you,
Tyler

dom_ha <- con(harvest_area[[1]] > harvest_area[[2]] & 
           harvest_area[[1]] > harvest_area[[3]] & 
           harvest_area[[1]] > harvest_area[[4]] & 
           harvest_area[[1]] > harvest_area[[5]] &
           harvest_area[[1]] > harvest_area[[6]] &
           harvest_area[[1]] > harvest_area[[7]] &
           harvest_area[[1]] > harvest_area[[8]] &
           harvest_area[[1]] > harvest_area[[9]] &
           harvest_area[[1]] > harvest_area[[10]] &
           harvest_area[[1]] > harvest_area[[11]] &
           harvest_area[[1]] > harvest_area[[12]] &
           harvest_area[[1]] > harvest_area[[13]] &
           harvest_area[[1]] > harvest_area[[14]] &
           harvest_area[[1]] > harvest_area[[15]] &
           harvest_area[[1]] > harvest_area[[16]], 1,
           
       con(harvest_area[[2]] > harvest_area[[1]] & 
           harvest_area[[2]] > harvest_area[[3]] & 
           harvest_area[[2]] > harvest_area[[4]] & 
           harvest_area[[2]] > harvest_area[[5]] &
           harvest_area[[2]] > harvest_area[[6]] &
           harvest_area[[2]] > harvest_area[[7]] &
           harvest_area[[2]] > harvest_area[[8]] &
           harvest_area[[2]] > harvest_area[[9]] &
           harvest_area[[2]] > harvest_area[[10]] &
           harvest_area[[2]] > harvest_area[[11]] &
           harvest_area[[2]] > harvest_area[[12]] &
           harvest_area[[2]] > harvest_area[[13]] &
           harvest_area[[2]] > harvest_area[[14]] &
           harvest_area[[2]] > harvest_area[[15]] &
           harvest_area[[2]] > harvest_area[[16]], 2,

       con(harvest_area[[3]] > harvest_area[[1]] & 
           harvest_area[[3]] > harvest_area[[2]] & 
           harvest_area[[3]] > harvest_area[[4]] & 
           harvest_area[[3]] > harvest_area[[5]] &
           harvest_area[[3]] > harvest_area[[6]] &
           harvest_area[[3]] > harvest_area[[7]] &
           harvest_area[[3]] > harvest_area[[8]] &
           harvest_area[[3]] > harvest_area[[9]] &
           harvest_area[[3]] > harvest_area[[10]] &
           harvest_area[[3]] > harvest_area[[11]] &
           harvest_area[[3]] > harvest_area[[12]] &
           harvest_area[[3]] > harvest_area[[13]] &
           harvest_area[[3]] > harvest_area[[14]] &
           harvest_area[[3]] > harvest_area[[15]] &
           harvest_area[[3]] > harvest_area[[16]], 3,  
           
       con(harvest_area[[4]] > harvest_area[[1]] & 
           harvest_area[[4]] > harvest_area[[2]] & 
           harvest_area[[4]] > harvest_area[[3]] & 
           harvest_area[[4]] > harvest_area[[5]] &
           harvest_area[[4]] > harvest_area[[6]] &
           harvest_area[[4]] > harvest_area[[7]] &
           harvest_area[[4]] > harvest_area[[8]] &
           harvest_area[[4]] > harvest_area[[9]] &
           harvest_area[[4]] > harvest_area[[10]] &
           harvest_area[[4]] > harvest_area[[11]] &
           harvest_area[[4]] > harvest_area[[12]] &
           harvest_area[[4]] > harvest_area[[13]] &
           harvest_area[[4]] > harvest_area[[14]] &
           harvest_area[[4]] > harvest_area[[15]] &
           harvest_area[[4]] > harvest_area[[16]], 4,          

       con(harvest_area[[5]] > harvest_area[[1]] & 
           harvest_area[[5]] > harvest_area[[2]] & 
           harvest_area[[5]] > harvest_area[[3]] & 
           harvest_area[[5]] > harvest_area[[4]] &
           harvest_area[[5]] > harvest_area[[6]] &
           harvest_area[[5]] > harvest_area[[7]] &
           harvest_area[[5]] > harvest_area[[8]] &
           harvest_area[[5]] > harvest_area[[9]] &
           harvest_area[[5]] > harvest_area[[10]] &
           harvest_area[[5]] > harvest_area[[11]] &
           harvest_area[[5]] > harvest_area[[12]] &
           harvest_area[[5]] > harvest_area[[13]] &
           harvest_area[[5]] > harvest_area[[14]] &
           harvest_area[[5]] > harvest_area[[15]] &
           harvest_area[[5]] > harvest_area[[16]], 5,
           
       con(harvest_area[[6]] > harvest_area[[1]] & 
           harvest_area[[6]] > harvest_area[[2]] & 
           harvest_area[[6]] > harvest_area[[3]] & 
           harvest_area[[6]] > harvest_area[[4]] &
           harvest_area[[6]] > harvest_area[[5]] &
           harvest_area[[6]] > harvest_area[[7]] &
           harvest_area[[6]] > harvest_area[[8]] &
           harvest_area[[6]] > harvest_area[[9]] &
           harvest_area[[6]] > harvest_area[[10]] &
           harvest_area[[6]] > harvest_area[[11]] &
           harvest_area[[6]] > harvest_area[[12]] &
           harvest_area[[6]] > harvest_area[[13]] &
           harvest_area[[6]] > harvest_area[[14]] &
           harvest_area[[6]] > harvest_area[[15]] &
           harvest_area[[6]] > harvest_area[[16]], 6,
           
       con(harvest_area[[7]] > harvest_area[[1]] & 
           harvest_area[[7]] > harvest_area[[2]] & 
           harvest_area[[7]] > harvest_area[[3]] & 
           harvest_area[[7]] > harvest_area[[4]] &
           harvest_area[[7]] > harvest_area[[5]] &
           harvest_area[[7]] > harvest_area[[6]] &
           harvest_area[[7]] > harvest_area[[8]] &
           harvest_area[[7]] > harvest_area[[9]] &
           harvest_area[[7]] > harvest_area[[10]] &
           harvest_area[[7]] > harvest_area[[11]] &
           harvest_area[[7]] > harvest_area[[12]] &
           harvest_area[[7]] > harvest_area[[13]] &
           harvest_area[[7]] > harvest_area[[14]] &
           harvest_area[[7]] > harvest_area[[15]] &
           harvest_area[[7]] > harvest_area[[16]], 7,
           
       con(harvest_area[[8]] > harvest_area[[1]] & 
           harvest_area[[8]] > harvest_area[[2]] & 
           harvest_area[[8]] > harvest_area[[3]] & 
           harvest_area[[8]] > harvest_area[[4]] &
           harvest_area[[8]] > harvest_area[[5]] &
           harvest_area[[8]] > harvest_area[[6]] &
           harvest_area[[8]] > harvest_area[[7]] &
           harvest_area[[8]] > harvest_area[[9]] &
           harvest_area[[8]] > harvest_area[[10]] &
           harvest_area[[8]] > harvest_area[[11]] &
           harvest_area[[8]] > harvest_area[[12]] &
           harvest_area[[8]] > harvest_area[[13]] &
           harvest_area[[8]] > harvest_area[[14]] &
           harvest_area[[8]] > harvest_area[[15]] &
           harvest_area[[8]] > harvest_area[[16]], 8,
           
       con(harvest_area[[9]] > harvest_area[[1]] & 
           harvest_area[[9]] > harvest_area[[2]] & 
           harvest_area[[9]] > harvest_area[[3]] & 
           harvest_area[[9]] > harvest_area[[4]] &
           harvest_area[[9]] > harvest_area[[5]] &
           harvest_area[[9]] > harvest_area[[6]] &
           harvest_area[[9]] > harvest_area[[7]] &
           harvest_area[[9]] > harvest_area[[8]] &
           harvest_area[[9]] > harvest_area[[10]] &
           harvest_area[[9]] > harvest_area[[11]] &
           harvest_area[[9]] > harvest_area[[12]] &
           harvest_area[[9]] > harvest_area[[13]] &
           harvest_area[[9]] > harvest_area[[14]] &
           harvest_area[[9]] > harvest_area[[15]] &
           harvest_area[[9]] > harvest_area[[16]], 9,
           
       con(harvest_area[[10]] > harvest_area[[1]] & 
           harvest_area[[10]] > harvest_area[[2]] & 
           harvest_area[[10]] > harvest_area[[3]] & 
           harvest_area[[10]] > harvest_area[[4]] &
           harvest_area[[10]] > harvest_area[[5]] &
           harvest_area[[10]] > harvest_area[[6]] &
           harvest_area[[10]] > harvest_area[[7]] &
           harvest_area[[10]] > harvest_area[[8]] &
           harvest_area[[10]] > harvest_area[[9]] &
           harvest_area[[10]] > harvest_area[[11]] &
           harvest_area[[10]] > harvest_area[[12]] &
           harvest_area[[10]] > harvest_area[[13]] &
           harvest_area[[10]] > harvest_area[[14]] &
           harvest_area[[10]] > harvest_area[[15]] &
           harvest_area[[10]] > harvest_area[[16]], 10,
           
       con(harvest_area[[11]] > harvest_area[[1]] & 
           harvest_area[[11]] > harvest_area[[2]] & 
           harvest_area[[11]] > harvest_area[[3]] & 
           harvest_area[[11]] > harvest_area[[4]] &
           harvest_area[[11]] > harvest_area[[5]] &
           harvest_area[[11]] > harvest_area[[6]] &
           harvest_area[[11]] > harvest_area[[7]] &
           harvest_area[[11]] > harvest_area[[8]] &
           harvest_area[[11]] > harvest_area[[9]] &
           harvest_area[[11]] > harvest_area[[10]] &
           harvest_area[[11]] > harvest_area[[12]] &
           harvest_area[[11]] > harvest_area[[13]] &
           harvest_area[[11]] > harvest_area[[14]] &
           harvest_area[[11]] > harvest_area[[15]] &
           harvest_area[[11]] > harvest_area[[16]], 11,
           
       con(harvest_area[[12]] > harvest_area[[1]] & 
           harvest_area[[12]] > harvest_area[[2]] & 
           harvest_area[[12]] > harvest_area[[3]] & 
           harvest_area[[12]] > harvest_area[[4]] &
           harvest_area[[12]] > harvest_area[[5]] &
           harvest_area[[12]] > harvest_area[[6]] &
           harvest_area[[12]] > harvest_area[[7]] &
           harvest_area[[12]] > harvest_area[[8]] &
           harvest_area[[12]] > harvest_area[[9]] &
           harvest_area[[12]] > harvest_area[[10]] &
           harvest_area[[12]] > harvest_area[[11]] &
           harvest_area[[12]] > harvest_area[[13]] &
           harvest_area[[12]] > harvest_area[[14]] &
           harvest_area[[12]] > harvest_area[[15]] &
           harvest_area[[12]] > harvest_area[[16]], 12,
           
       con(harvest_area[[13]] > harvest_area[[1]] & 
           harvest_area[[13]] > harvest_area[[2]] & 
           harvest_area[[13]] > harvest_area[[3]] & 
           harvest_area[[13]] > harvest_area[[4]] &
           harvest_area[[13]] > harvest_area[[5]] &
           harvest_area[[13]] > harvest_area[[6]] &
           harvest_area[[13]] > harvest_area[[7]] &
           harvest_area[[13]] > harvest_area[[8]] &
           harvest_area[[13]] > harvest_area[[9]] &
           harvest_area[[13]] > harvest_area[[10]] &
           harvest_area[[13]] > harvest_area[[11]] &
           harvest_area[[13]] > harvest_area[[12]] &
           harvest_area[[13]] > harvest_area[[14]] &
           harvest_area[[13]] > harvest_area[[15]] &
           harvest_area[[13]] > harvest_area[[16]], 13, 
           
       con(harvest_area[[14]] > harvest_area[[1]] & 
           harvest_area[[14]] > harvest_area[[2]] & 
           harvest_area[[14]] > harvest_area[[3]] & 
           harvest_area[[14]] > harvest_area[[4]] &
           harvest_area[[14]] > harvest_area[[5]] &
           harvest_area[[14]] > harvest_area[[6]] &
           harvest_area[[14]] > harvest_area[[7]] &
           harvest_area[[14]] > harvest_area[[8]] &
           harvest_area[[14]] > harvest_area[[9]] &
           harvest_area[[14]] > harvest_area[[10]] &
           harvest_area[[14]] > harvest_area[[11]] &
           harvest_area[[14]] > harvest_area[[12]] &
           harvest_area[[14]] > harvest_area[[13]] &
           harvest_area[[14]] > harvest_area[[15]] &
           harvest_area[[14]] > harvest_area[[16]], 14, 
           
       con(harvest_area[[15]] > harvest_area[[1]] & 
           harvest_area[[15]] > harvest_area[[2]] & 
           harvest_area[[15]] > harvest_area[[3]] & 
           harvest_area[[15]] > harvest_area[[4]] &
           harvest_area[[15]] > harvest_area[[5]] &
           harvest_area[[15]] > harvest_area[[6]] &
           harvest_area[[15]] > harvest_area[[7]] &
           harvest_area[[15]] > harvest_area[[8]] &
           harvest_area[[15]] > harvest_area[[9]] &
           harvest_area[[15]] > harvest_area[[10]] &
           harvest_area[[15]] > harvest_area[[11]] &
           harvest_area[[15]] > harvest_area[[12]] &
           harvest_area[[15]] > harvest_area[[13]] &
           harvest_area[[15]] > harvest_area[[14]] &
           harvest_area[[15]] > harvest_area[[16]], 15,
           
       con(harvest_area[[16]] > harvest_area[[1]] & 
           harvest_area[[16]] > harvest_area[[2]] & 
           harvest_area[[16]] > harvest_area[[3]] & 
           harvest_area[[16]] > harvest_area[[4]] &
           harvest_area[[16]] > harvest_area[[5]] &
           harvest_area[[16]] > harvest_area[[6]] &
           harvest_area[[16]] > harvest_area[[7]] &
           harvest_area[[16]] > harvest_area[[8]] &
           harvest_area[[16]] > harvest_area[[9]] &
           harvest_area[[16]] > harvest_area[[10]] &
           harvest_area[[16]] > harvest_area[[11]] &
           harvest_area[[16]] > harvest_area[[12]] &
           harvest_area[[16]] > harvest_area[[13]] &
           harvest_area[[16]] > harvest_area[[14]] &
           harvest_area[[16]] > harvest_area[[15]], 16, 0
           
))))))))))))))))


-------------------------------------------------------------------------
Tyler Frazier
Center for Development Research (ZEF-C)
University of Bonn
53113 Bonn, DE
+49 (0) 228 73 4949 (office)
+49 (0) 152 1018 2718 (handy)
-------------------------------------------------------------------------







	[[alternative HTML version deleted]]


From r.hijmans at gmail.com  Tue Sep 23 21:01:55 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 23 Sep 2014 12:01:55 -0700
Subject: [R-sig-Geo] which.max() limit in raster package for RasterBrick
In-Reply-To: <2F0B2008-7A95-42B4-8D6E-296C6B6A39D4@icloud.com>
References: <2F0B2008-7A95-42B4-8D6E-296C6B6A39D4@icloud.com>
Message-ID: <CANtt_hw=x74Mkd8DKbFC9aAOruFJQeaPbCiM75mAepxhiYpBKQ@mail.gmail.com>

Tyler,

It is probably useful to study the vignette that comes with the raster
package if you have not done so. Also please provide a reproducible
example, if possible, and report the error message you get. Presumably
it is:  "Error in which.min(harvest_area) : not yet implemented for
large objects". I will fix that.

In this case, I think you can do the following if there are no cells
with NA for all layers:

x <- calc(harvest_area, which.max)

else you can do:

x = calc(b, function(i){ v <- which.max(i); ifelse(length(v) == 0, NA, v)})


By the way, it is not a good idea to write to slots "@" of Raster*
objects as you do. I think your first lines of code can be replaced
with

f <- list.files(pattern="*.nc$", recursive=TRUE)
harvest_area <- stack(f)
# or if specifying the band is necessary:
harvest_area <- stack(lapply(f, function(i) raster(i, band=1)))
names(harvest_area) <- sub("\\/.*", "", f)

Robert


2014-09-23 11:01 GMT-07:00 Tyler Frazier <tyler.j.frazier at icloud.com>:
> Dear group,
>
> I have a RasterBrick with 16 layers created with the stack command like so:
>
> f <- list.files(pattern="*.nc$", recursive=TRUE)
> r <- raster(f[1], band = 1)
> harvest_area <- stack(r)
> harvest_area at layers <- sapply(f, function(x) {r at file@name=x;r})
> names(harvest_area) <- sub("\\/.*", "", f)
>
> and then I want to apply which.max() to determine which layer is max for each grid cell.  It seems which.max() returns an error for a brick with more than 5? layers.
>
> I have attempted various approaches to determine the max of each grid cell within a RasterBrick with more than 5 layers, but the only thing I can get to work is a very verbose approach (following the msg).
>
> Various approaches using a defined function as such:
>
> con <- function(condition, trueValue, falseValue) {return(condition * trueValue + (!condition)*falseValue)}
>
> including:
>
> for (k in 1:length(harvest_area)) {test <- con(harvest_area[[k]] > harvest_area[[-k]], k, 0)}
>
> and:
>
> dom_ha <- con(harvest_area[[1]] > harvest_area[[-1]], 1,
>                   con(harvest_area[[2]] > harvest_area[[-2]], 2,
>                   con(harvest_area[[3]] > harvest_area[[-3]], 3,
>                   con(harvest_area[[4]] > harvest_area[[-4]], 4,
>                   con(harvest_area[[5]] > harvest_area[[-5]], 5,
>                   con(harvest_area[[6]] > harvest_area[[-6]], 6,
>                   con(harvest_area[[7]] > harvest_area[[-7]], 7,
>                   con(harvest_area[[8]] > harvest_area[[-8]], 8,
>                   con(harvest_area[[9]] > harvest_area[[-9]], 9,
>                   con(harvest_area[[10]] > harvest_area[[-10]], 10,
>                   con(harvest_area[[11]] > harvest_area[[-11]], 11,
>                   con(harvest_area[[12]] > harvest_area[[-12]], 12,
>                   con(harvest_area[[13]] > harvest_area[[-13]], 13,
>                   con(harvest_area[[14]] > harvest_area[[-14]], 14,
>                   con(harvest_area[[15]] > harvest_area[[-15]], 15,
>                   con(harvest_area[[16]] > harvest_area[[-16]], 16, 0
>                    ))))))))))))))))
>
> didn?t work.  I also tried using stackApply() with function(x) but it returned an error similar to the which.max() > 5.  The only thing that work is the following, but its so verbose.
>
> Any suggestions will be much appreciated.
>
> Thank you,
> Tyler
>
> dom_ha <- con(harvest_area[[1]] > harvest_area[[2]] &
>            harvest_area[[1]] > harvest_area[[3]] &
>            harvest_area[[1]] > harvest_area[[4]] &
>            harvest_area[[1]] > harvest_area[[5]] &
>            harvest_area[[1]] > harvest_area[[6]] &
>            harvest_area[[1]] > harvest_area[[7]] &
>            harvest_area[[1]] > harvest_area[[8]] &
>            harvest_area[[1]] > harvest_area[[9]] &
>            harvest_area[[1]] > harvest_area[[10]] &
>            harvest_area[[1]] > harvest_area[[11]] &
>            harvest_area[[1]] > harvest_area[[12]] &
>            harvest_area[[1]] > harvest_area[[13]] &
>            harvest_area[[1]] > harvest_area[[14]] &
>            harvest_area[[1]] > harvest_area[[15]] &
>            harvest_area[[1]] > harvest_area[[16]], 1,
>
>        con(harvest_area[[2]] > harvest_area[[1]] &
>            harvest_area[[2]] > harvest_area[[3]] &
>            harvest_area[[2]] > harvest_area[[4]] &
>            harvest_area[[2]] > harvest_area[[5]] &
>            harvest_area[[2]] > harvest_area[[6]] &
>            harvest_area[[2]] > harvest_area[[7]] &
>            harvest_area[[2]] > harvest_area[[8]] &
>            harvest_area[[2]] > harvest_area[[9]] &
>            harvest_area[[2]] > harvest_area[[10]] &
>            harvest_area[[2]] > harvest_area[[11]] &
>            harvest_area[[2]] > harvest_area[[12]] &
>            harvest_area[[2]] > harvest_area[[13]] &
>            harvest_area[[2]] > harvest_area[[14]] &
>            harvest_area[[2]] > harvest_area[[15]] &
>            harvest_area[[2]] > harvest_area[[16]], 2,
>
>        con(harvest_area[[3]] > harvest_area[[1]] &
>            harvest_area[[3]] > harvest_area[[2]] &
>            harvest_area[[3]] > harvest_area[[4]] &
>            harvest_area[[3]] > harvest_area[[5]] &
>            harvest_area[[3]] > harvest_area[[6]] &
>            harvest_area[[3]] > harvest_area[[7]] &
>            harvest_area[[3]] > harvest_area[[8]] &
>            harvest_area[[3]] > harvest_area[[9]] &
>            harvest_area[[3]] > harvest_area[[10]] &
>            harvest_area[[3]] > harvest_area[[11]] &
>            harvest_area[[3]] > harvest_area[[12]] &
>            harvest_area[[3]] > harvest_area[[13]] &
>            harvest_area[[3]] > harvest_area[[14]] &
>            harvest_area[[3]] > harvest_area[[15]] &
>            harvest_area[[3]] > harvest_area[[16]], 3,
>
>        con(harvest_area[[4]] > harvest_area[[1]] &
>            harvest_area[[4]] > harvest_area[[2]] &
>            harvest_area[[4]] > harvest_area[[3]] &
>            harvest_area[[4]] > harvest_area[[5]] &
>            harvest_area[[4]] > harvest_area[[6]] &
>            harvest_area[[4]] > harvest_area[[7]] &
>            harvest_area[[4]] > harvest_area[[8]] &
>            harvest_area[[4]] > harvest_area[[9]] &
>            harvest_area[[4]] > harvest_area[[10]] &
>            harvest_area[[4]] > harvest_area[[11]] &
>            harvest_area[[4]] > harvest_area[[12]] &
>            harvest_area[[4]] > harvest_area[[13]] &
>            harvest_area[[4]] > harvest_area[[14]] &
>            harvest_area[[4]] > harvest_area[[15]] &
>            harvest_area[[4]] > harvest_area[[16]], 4,
>
>        con(harvest_area[[5]] > harvest_area[[1]] &
>            harvest_area[[5]] > harvest_area[[2]] &
>            harvest_area[[5]] > harvest_area[[3]] &
>            harvest_area[[5]] > harvest_area[[4]] &
>            harvest_area[[5]] > harvest_area[[6]] &
>            harvest_area[[5]] > harvest_area[[7]] &
>            harvest_area[[5]] > harvest_area[[8]] &
>            harvest_area[[5]] > harvest_area[[9]] &
>            harvest_area[[5]] > harvest_area[[10]] &
>            harvest_area[[5]] > harvest_area[[11]] &
>            harvest_area[[5]] > harvest_area[[12]] &
>            harvest_area[[5]] > harvest_area[[13]] &
>            harvest_area[[5]] > harvest_area[[14]] &
>            harvest_area[[5]] > harvest_area[[15]] &
>            harvest_area[[5]] > harvest_area[[16]], 5,
>
>        con(harvest_area[[6]] > harvest_area[[1]] &
>            harvest_area[[6]] > harvest_area[[2]] &
>            harvest_area[[6]] > harvest_area[[3]] &
>            harvest_area[[6]] > harvest_area[[4]] &
>            harvest_area[[6]] > harvest_area[[5]] &
>            harvest_area[[6]] > harvest_area[[7]] &
>            harvest_area[[6]] > harvest_area[[8]] &
>            harvest_area[[6]] > harvest_area[[9]] &
>            harvest_area[[6]] > harvest_area[[10]] &
>            harvest_area[[6]] > harvest_area[[11]] &
>            harvest_area[[6]] > harvest_area[[12]] &
>            harvest_area[[6]] > harvest_area[[13]] &
>            harvest_area[[6]] > harvest_area[[14]] &
>            harvest_area[[6]] > harvest_area[[15]] &
>            harvest_area[[6]] > harvest_area[[16]], 6,
>
>        con(harvest_area[[7]] > harvest_area[[1]] &
>            harvest_area[[7]] > harvest_area[[2]] &
>            harvest_area[[7]] > harvest_area[[3]] &
>            harvest_area[[7]] > harvest_area[[4]] &
>            harvest_area[[7]] > harvest_area[[5]] &
>            harvest_area[[7]] > harvest_area[[6]] &
>            harvest_area[[7]] > harvest_area[[8]] &
>            harvest_area[[7]] > harvest_area[[9]] &
>            harvest_area[[7]] > harvest_area[[10]] &
>            harvest_area[[7]] > harvest_area[[11]] &
>            harvest_area[[7]] > harvest_area[[12]] &
>            harvest_area[[7]] > harvest_area[[13]] &
>            harvest_area[[7]] > harvest_area[[14]] &
>            harvest_area[[7]] > harvest_area[[15]] &
>            harvest_area[[7]] > harvest_area[[16]], 7,
>
>        con(harvest_area[[8]] > harvest_area[[1]] &
>            harvest_area[[8]] > harvest_area[[2]] &
>            harvest_area[[8]] > harvest_area[[3]] &
>            harvest_area[[8]] > harvest_area[[4]] &
>            harvest_area[[8]] > harvest_area[[5]] &
>            harvest_area[[8]] > harvest_area[[6]] &
>            harvest_area[[8]] > harvest_area[[7]] &
>            harvest_area[[8]] > harvest_area[[9]] &
>            harvest_area[[8]] > harvest_area[[10]] &
>            harvest_area[[8]] > harvest_area[[11]] &
>            harvest_area[[8]] > harvest_area[[12]] &
>            harvest_area[[8]] > harvest_area[[13]] &
>            harvest_area[[8]] > harvest_area[[14]] &
>            harvest_area[[8]] > harvest_area[[15]] &
>            harvest_area[[8]] > harvest_area[[16]], 8,
>
>        con(harvest_area[[9]] > harvest_area[[1]] &
>            harvest_area[[9]] > harvest_area[[2]] &
>            harvest_area[[9]] > harvest_area[[3]] &
>            harvest_area[[9]] > harvest_area[[4]] &
>            harvest_area[[9]] > harvest_area[[5]] &
>            harvest_area[[9]] > harvest_area[[6]] &
>            harvest_area[[9]] > harvest_area[[7]] &
>            harvest_area[[9]] > harvest_area[[8]] &
>            harvest_area[[9]] > harvest_area[[10]] &
>            harvest_area[[9]] > harvest_area[[11]] &
>            harvest_area[[9]] > harvest_area[[12]] &
>            harvest_area[[9]] > harvest_area[[13]] &
>            harvest_area[[9]] > harvest_area[[14]] &
>            harvest_area[[9]] > harvest_area[[15]] &
>            harvest_area[[9]] > harvest_area[[16]], 9,
>
>        con(harvest_area[[10]] > harvest_area[[1]] &
>            harvest_area[[10]] > harvest_area[[2]] &
>            harvest_area[[10]] > harvest_area[[3]] &
>            harvest_area[[10]] > harvest_area[[4]] &
>            harvest_area[[10]] > harvest_area[[5]] &
>            harvest_area[[10]] > harvest_area[[6]] &
>            harvest_area[[10]] > harvest_area[[7]] &
>            harvest_area[[10]] > harvest_area[[8]] &
>            harvest_area[[10]] > harvest_area[[9]] &
>            harvest_area[[10]] > harvest_area[[11]] &
>            harvest_area[[10]] > harvest_area[[12]] &
>            harvest_area[[10]] > harvest_area[[13]] &
>            harvest_area[[10]] > harvest_area[[14]] &
>            harvest_area[[10]] > harvest_area[[15]] &
>            harvest_area[[10]] > harvest_area[[16]], 10,
>
>        con(harvest_area[[11]] > harvest_area[[1]] &
>            harvest_area[[11]] > harvest_area[[2]] &
>            harvest_area[[11]] > harvest_area[[3]] &
>            harvest_area[[11]] > harvest_area[[4]] &
>            harvest_area[[11]] > harvest_area[[5]] &
>            harvest_area[[11]] > harvest_area[[6]] &
>            harvest_area[[11]] > harvest_area[[7]] &
>            harvest_area[[11]] > harvest_area[[8]] &
>            harvest_area[[11]] > harvest_area[[9]] &
>            harvest_area[[11]] > harvest_area[[10]] &
>            harvest_area[[11]] > harvest_area[[12]] &
>            harvest_area[[11]] > harvest_area[[13]] &
>            harvest_area[[11]] > harvest_area[[14]] &
>            harvest_area[[11]] > harvest_area[[15]] &
>            harvest_area[[11]] > harvest_area[[16]], 11,
>
>        con(harvest_area[[12]] > harvest_area[[1]] &
>            harvest_area[[12]] > harvest_area[[2]] &
>            harvest_area[[12]] > harvest_area[[3]] &
>            harvest_area[[12]] > harvest_area[[4]] &
>            harvest_area[[12]] > harvest_area[[5]] &
>            harvest_area[[12]] > harvest_area[[6]] &
>            harvest_area[[12]] > harvest_area[[7]] &
>            harvest_area[[12]] > harvest_area[[8]] &
>            harvest_area[[12]] > harvest_area[[9]] &
>            harvest_area[[12]] > harvest_area[[10]] &
>            harvest_area[[12]] > harvest_area[[11]] &
>            harvest_area[[12]] > harvest_area[[13]] &
>            harvest_area[[12]] > harvest_area[[14]] &
>            harvest_area[[12]] > harvest_area[[15]] &
>            harvest_area[[12]] > harvest_area[[16]], 12,
>
>        con(harvest_area[[13]] > harvest_area[[1]] &
>            harvest_area[[13]] > harvest_area[[2]] &
>            harvest_area[[13]] > harvest_area[[3]] &
>            harvest_area[[13]] > harvest_area[[4]] &
>            harvest_area[[13]] > harvest_area[[5]] &
>            harvest_area[[13]] > harvest_area[[6]] &
>            harvest_area[[13]] > harvest_area[[7]] &
>            harvest_area[[13]] > harvest_area[[8]] &
>            harvest_area[[13]] > harvest_area[[9]] &
>            harvest_area[[13]] > harvest_area[[10]] &
>            harvest_area[[13]] > harvest_area[[11]] &
>            harvest_area[[13]] > harvest_area[[12]] &
>            harvest_area[[13]] > harvest_area[[14]] &
>            harvest_area[[13]] > harvest_area[[15]] &
>            harvest_area[[13]] > harvest_area[[16]], 13,
>
>        con(harvest_area[[14]] > harvest_area[[1]] &
>            harvest_area[[14]] > harvest_area[[2]] &
>            harvest_area[[14]] > harvest_area[[3]] &
>            harvest_area[[14]] > harvest_area[[4]] &
>            harvest_area[[14]] > harvest_area[[5]] &
>            harvest_area[[14]] > harvest_area[[6]] &
>            harvest_area[[14]] > harvest_area[[7]] &
>            harvest_area[[14]] > harvest_area[[8]] &
>            harvest_area[[14]] > harvest_area[[9]] &
>            harvest_area[[14]] > harvest_area[[10]] &
>            harvest_area[[14]] > harvest_area[[11]] &
>            harvest_area[[14]] > harvest_area[[12]] &
>            harvest_area[[14]] > harvest_area[[13]] &
>            harvest_area[[14]] > harvest_area[[15]] &
>            harvest_area[[14]] > harvest_area[[16]], 14,
>
>        con(harvest_area[[15]] > harvest_area[[1]] &
>            harvest_area[[15]] > harvest_area[[2]] &
>            harvest_area[[15]] > harvest_area[[3]] &
>            harvest_area[[15]] > harvest_area[[4]] &
>            harvest_area[[15]] > harvest_area[[5]] &
>            harvest_area[[15]] > harvest_area[[6]] &
>            harvest_area[[15]] > harvest_area[[7]] &
>            harvest_area[[15]] > harvest_area[[8]] &
>            harvest_area[[15]] > harvest_area[[9]] &
>            harvest_area[[15]] > harvest_area[[10]] &
>            harvest_area[[15]] > harvest_area[[11]] &
>            harvest_area[[15]] > harvest_area[[12]] &
>            harvest_area[[15]] > harvest_area[[13]] &
>            harvest_area[[15]] > harvest_area[[14]] &
>            harvest_area[[15]] > harvest_area[[16]], 15,
>
>        con(harvest_area[[16]] > harvest_area[[1]] &
>            harvest_area[[16]] > harvest_area[[2]] &
>            harvest_area[[16]] > harvest_area[[3]] &
>            harvest_area[[16]] > harvest_area[[4]] &
>            harvest_area[[16]] > harvest_area[[5]] &
>            harvest_area[[16]] > harvest_area[[6]] &
>            harvest_area[[16]] > harvest_area[[7]] &
>            harvest_area[[16]] > harvest_area[[8]] &
>            harvest_area[[16]] > harvest_area[[9]] &
>            harvest_area[[16]] > harvest_area[[10]] &
>            harvest_area[[16]] > harvest_area[[11]] &
>            harvest_area[[16]] > harvest_area[[12]] &
>            harvest_area[[16]] > harvest_area[[13]] &
>            harvest_area[[16]] > harvest_area[[14]] &
>            harvest_area[[16]] > harvest_area[[15]], 16, 0
>
> ))))))))))))))))
>
>
> -------------------------------------------------------------------------
> Tyler Frazier
> Center for Development Research (ZEF-C)
> University of Bonn
> 53113 Bonn, DE
> +49 (0) 228 73 4949 (office)
> +49 (0) 152 1018 2718 (handy)
> -------------------------------------------------------------------------
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From a.mosnier at gmail.com  Wed Sep 24 15:59:07 2014
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Wed, 24 Sep 2014 09:59:07 -0400
Subject: [R-sig-Geo] Extracting raster weighted mean without NAs
Message-ID: <CANkFkEeUCh_wYKqT_rnwNT=Rb8qvB7rzVf7920JLyA0eooo1wg@mail.gmail.com>

Hi,

I need to extract the mean value of raster values into several
spatialPolygons.
I use the extract function from the raster package with the weight option
in order to take into account the area of each raster cell with data
included into each polygon.
However, I want to make the calculation even if some cells contain NAs,

Here is a small code to explain my case:

library(raster)
mat <- matrix(rep(c(4,5,3,2,1), 5), ncol=5)
r <- raster(mat)
r[2,4] <- NA
plot(r)
corners1 <- rbind(c(0.2,0.1), c(0.2,0.7), c(0.4, 0.7), c(0.4,0.1),
c(0.2,0.1))
corners2 <- rbind(c(0.7,0.1), c(0.7,0.7), c(0.9, 0.7), c(0.9,0.1),
c(0.7,0.1))
polys <- SpatialPolygons(list(Polygons(list(Polygon(corners1)), ID="1"),
Polygons(list(Polygon(corners2)), ID="2")))
plot(polys, add=T)

extract(r, polys, weight=TRUE, fun=mean, na.rm=TRUE, small=TRUE)

>[1] 2.666667       NA



Note: The use of the parameter na.rn=TRUE does not resolve my issue.

Any workaround ?

Thanks,

Arnaud

	[[alternative HTML version deleted]]


From jstachel at sfwmd.gov  Wed Sep 24 16:14:27 2014
From: jstachel at sfwmd.gov (Stachelek, Joseph)
Date: Wed, 24 Sep 2014 14:14:27 +0000
Subject: [R-sig-Geo] Extracting raster weighted mean without NAs
In-Reply-To: <CANkFkEeUCh_wYKqT_rnwNT=Rb8qvB7rzVf7920JLyA0eooo1wg@mail.gmail.com>
References: <CANkFkEeUCh_wYKqT_rnwNT=Rb8qvB7rzVf7920JLyA0eooo1wg@mail.gmail.com>
Message-ID: <D51374C4B889BC47B3C5286047C86DA18EF88D6E@whqembx03p.ad.sfwmd.gov>

I think you can avoid returning NA if you use the example code for extract with polygons with weights but change the last two lines to:

v <- extract(r, polys, weights=TRUE)
sapply(v, function(x) sum(apply(x, 1, prod),na.rm=T) / sum(x[,2],na.rm=T))

-----Original Message-----
From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Arnaud Mosnier
Sent: Wednesday, September 24, 2014 9:59 AM
To: r-sig-geo at r-project.org; Robert Hijmans
Subject: [R-sig-Geo] Extracting raster weighted mean without NAs

Hi,

I need to extract the mean value of raster values into several
spatialPolygons.
I use the extract function from the raster package with the weight option
in order to take into account the area of each raster cell with data
included into each polygon.
However, I want to make the calculation even if some cells contain NAs,

Here is a small code to explain my case:

library(raster)
mat <- matrix(rep(c(4,5,3,2,1), 5), ncol=5)
r <- raster(mat)
r[2,4] <- NA
plot(r)
corners1 <- rbind(c(0.2,0.1), c(0.2,0.7), c(0.4, 0.7), c(0.4,0.1),
c(0.2,0.1))
corners2 <- rbind(c(0.7,0.1), c(0.7,0.7), c(0.9, 0.7), c(0.9,0.1),
c(0.7,0.1))
polys <- SpatialPolygons(list(Polygons(list(Polygon(corners1)), ID="1"),
Polygons(list(Polygon(corners2)), ID="2")))
plot(polys, add=T)

extract(r, polys, weight=TRUE, fun=mean, na.rm=TRUE, small=TRUE)

>[1] 2.666667       NA



Note: The use of the parameter na.rn=TRUE does not resolve my issue.

Any workaround ?

Thanks,

Arnaud

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


We value your opinion. Please take a few minutes to share your comments on the service you received from the District by clicking on this link<http://my.sfwmd.gov/portal/page/portal/pg_grp_surveysystem/survey%20ext?pid=1653>.


From kridox at ymail.com  Wed Sep 24 16:19:20 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 24 Sep 2014 23:19:20 +0900
Subject: [R-sig-Geo] Extracting raster weighted mean without NAs
In-Reply-To: <CANkFkEeUCh_wYKqT_rnwNT=Rb8qvB7rzVf7920JLyA0eooo1wg@mail.gmail.com>
References: <CANkFkEeUCh_wYKqT_rnwNT=Rb8qvB7rzVf7920JLyA0eooo1wg@mail.gmail.com>
Message-ID: <CAAcyNCybO2yMU655Kd0-EcCC7bQYg1u1ja6BubmjWGmBS+St5g@mail.gmail.com>

Hi Arnaud,

It works for me with raster version 2.3-0. Please provide the output
of sessionInfo().

                [,1]
[1,] 2.666667
[2,] 2.454545

Regards,
Pascal

On Wed, Sep 24, 2014 at 10:59 PM, Arnaud Mosnier <a.mosnier at gmail.com> wrote:
> Hi,
>
> I need to extract the mean value of raster values into several
> spatialPolygons.
> I use the extract function from the raster package with the weight option
> in order to take into account the area of each raster cell with data
> included into each polygon.
> However, I want to make the calculation even if some cells contain NAs,
>
> Here is a small code to explain my case:
>
> library(raster)
> mat <- matrix(rep(c(4,5,3,2,1), 5), ncol=5)
> r <- raster(mat)
> r[2,4] <- NA
> plot(r)
> corners1 <- rbind(c(0.2,0.1), c(0.2,0.7), c(0.4, 0.7), c(0.4,0.1),
> c(0.2,0.1))
> corners2 <- rbind(c(0.7,0.1), c(0.7,0.7), c(0.9, 0.7), c(0.9,0.1),
> c(0.7,0.1))
> polys <- SpatialPolygons(list(Polygons(list(Polygon(corners1)), ID="1"),
> Polygons(list(Polygon(corners2)), ID="2")))
> plot(polys, add=T)
>
> extract(r, polys, weight=TRUE, fun=mean, na.rm=TRUE, small=TRUE)
>
>>[1] 2.666667       NA
>
>
>
> Note: The use of the parameter na.rn=TRUE does not resolve my issue.
>
> Any workaround ?
>
> Thanks,
>
> Arnaud
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From a.mosnier at gmail.com  Wed Sep 24 16:26:11 2014
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Wed, 24 Sep 2014 10:26:11 -0400
Subject: [R-sig-Geo] Extracting raster weighted mean without NAs
In-Reply-To: <CAAcyNCybO2yMU655Kd0-EcCC7bQYg1u1ja6BubmjWGmBS+St5g@mail.gmail.com>
References: <CANkFkEeUCh_wYKqT_rnwNT=Rb8qvB7rzVf7920JLyA0eooo1wg@mail.gmail.com>
	<CAAcyNCybO2yMU655Kd0-EcCC7bQYg1u1ja6BubmjWGmBS+St5g@mail.gmail.com>
Message-ID: <CANkFkEcOJJbNRqsgrrkBx6DOfwqZY=OC7ny=VYMLPoX37xk_tg@mail.gmail.com>

You are right Pascal ... !
I was not up to date !

Thanks

Arnaud


2014-09-24 10:19 GMT-04:00 Pascal Oettli <kridox at ymail.com>:

> Hi Arnaud,
>
> It works for me with raster version 2.3-0. Please provide the output
> of sessionInfo().
>
>                 [,1]
> [1,] 2.666667
> [2,] 2.454545
>
> Regards,
> Pascal
>
> On Wed, Sep 24, 2014 at 10:59 PM, Arnaud Mosnier <a.mosnier at gmail.com>
> wrote:
> > Hi,
> >
> > I need to extract the mean value of raster values into several
> > spatialPolygons.
> > I use the extract function from the raster package with the weight option
> > in order to take into account the area of each raster cell with data
> > included into each polygon.
> > However, I want to make the calculation even if some cells contain NAs,
> >
> > Here is a small code to explain my case:
> >
> > library(raster)
> > mat <- matrix(rep(c(4,5,3,2,1), 5), ncol=5)
> > r <- raster(mat)
> > r[2,4] <- NA
> > plot(r)
> > corners1 <- rbind(c(0.2,0.1), c(0.2,0.7), c(0.4, 0.7), c(0.4,0.1),
> > c(0.2,0.1))
> > corners2 <- rbind(c(0.7,0.1), c(0.7,0.7), c(0.9, 0.7), c(0.9,0.1),
> > c(0.7,0.1))
> > polys <- SpatialPolygons(list(Polygons(list(Polygon(corners1)), ID="1"),
> > Polygons(list(Polygon(corners2)), ID="2")))
> > plot(polys, add=T)
> >
> > extract(r, polys, weight=TRUE, fun=mean, na.rm=TRUE, small=TRUE)
> >
> >>[1] 2.666667       NA
> >
> >
> >
> > Note: The use of the parameter na.rn=TRUE does not resolve my issue.
> >
> > Any workaround ?
> >
> > Thanks,
> >
> > Arnaud
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
> --
> Pascal Oettli
> Project Scientist
> JAMSTEC
> Yokohama, Japan
>

	[[alternative HTML version deleted]]


From bakare at ualberta.ca  Wed Sep 24 19:12:40 2014
From: bakare at ualberta.ca (Moshood Agba Bakare)
Date: Wed, 24 Sep 2014 11:12:40 -0600
Subject: [R-sig-Geo] interpretation ordinary kriging prediction and variance
	maps
Message-ID: <CAJRR3XP5WMM+7mdKivK6B4E=5cUx5szFi3k1bpcumckhUu7rng@mail.gmail.com>

Hi All,

Please could anyone guide me on how to interpret prediction and variance
maps from ordinary kriging interpolation? What do I need to look for? How
do I go about reading and interpreting the maps? In some literature, the
square root of the kriging variance is obtained to come up with standard
error map. Which one is better to present, standard error or kriging
variance map?

Thanks

	[[alternative HTML version deleted]]


From kmb56 at berkeley.edu  Thu Sep 25 00:00:27 2014
From: kmb56 at berkeley.edu (Kenny Bell)
Date: Wed, 24 Sep 2014 15:00:27 -0700
Subject: [R-sig-Geo] PBSmapping calcArea
Message-ID: <CALOjXYSSZ_E0i5W+VoEd3xMH=KdP=MSd=F0z+NMiFBBZ1mhaNQ@mail.gmail.com>

Hi all,

I am trying to use calcArea to get the areas of the following polygons at
the following link:

https://www.dropbox.com/s/v1fjsdkcyxw61qt/rsiggeoQ.RData?dl=0

I use:

library(PBSmapping)
areaY <- calcArea(smallYPolySet, rollup = 2)

which gives the output:

> areaY
  PID SID        area
1   1   1  38.7704526
2   2   1 116.6810084
3   2   2   0.9844843

The second polygon has a hole which can be seen with:

plotLines(smallYPolySet)

However, the rollup = 2 option should see the hole and subtract the area
and return the difference, as I understand. The above shows they are
specified separately.

Can someone help me with any/all of:

1) working out whether the hole is identified in the smallYPolySet object
2) flagging an element of a polyset as a hole
2) automatically determining if a polygon is a hole

Any help would be very much appreciated!

Thanks,
Kenny

	[[alternative HTML version deleted]]


From katharine.walter at yale.edu  Thu Sep 25 03:23:35 2014
From: katharine.walter at yale.edu (Katharine Walter)
Date: Wed, 24 Sep 2014 21:23:35 -0400
Subject: [R-sig-Geo] Extract attributes from spatial polygons dataframe to
 another spatial polygons dataframe
Message-ID: <CACAXSaWSEWJoONkNP+_yz=gGOLdYYVpC66d37x-HcGKVmTeftQ@mail.gmail.com>

Hi,

I would like to extract attributes from one spatial polygons dataframe to
another.

Specifically, I have a spatial polygons dataframe representing data
collected for towns and I would like to extract data into another overlaid
spatial polygon dataframe (a regular grid).  The dataframe is
complex--several variables are measured for several years for each town.
Ideally, what I would like to do do is weight the variables measured at the
town-level by the proportion of the town's area in each grid cell so that I
can find a total for the grid cell in question.  I have looked through the
offerings for spatial polygon dataframes, but have not found any tool for
this.

Is the best way to do this to create a RasterStack for each variable of
interest which includes a RasterLayer for each year of interest and then
use extract(town, grid, weight=T) over each variable/year in questions?  Or
is there a way to do this if the data is represented as a STFDF or a
spatial polygons dataframe?

Thank you for your help!

	[[alternative HTML version deleted]]


From justiceaheto at yahoo.com  Thu Sep 25 04:25:25 2014
From: justiceaheto at yahoo.com (Justice Moses K. Aheto)
Date: Wed, 24 Sep 2014 19:25:25 -0700
Subject: [R-sig-Geo] Spatial and multilevel model with kriging/interpolation
	in R
Message-ID: <1411611925.8381.YahooMailNeo@web120901.mail.ne1.yahoo.com>

Dear All,
Please, I wish to analyse a spatial data in R through multilevel approach with my main primary objective been to interpolate for unsampled locations in my study region. Children in my data set are nested within households in the study locations and my multilevel model (without spatial) showed significant household random effects hence my choice to employ spatial analysis with multilevel approach. 
The need to include household random effects in my spatial model makes it a bit difficult for me to implement in R unlike the standard geostatical analysis. 
I have 'SpatialPointsDataFrame' containing my geographical coordinates (longitude and latitude) as well as my response and covariates.  
The spatial mixed effects model I wish to fit and interpolate is: Yij(t) = Xij(t)? +hj+S(t)+?ij           (1)
where
i=individual child, j=household, X(t)= spatial referenced non-random covariates, S(t)= spatially correlated stationary Gaussian process. 
?ij =nugget effect/measurement error, Yij(t) = response of
child i in household j at location t and is a continuous variable, hj =household level random effects and ?=regression coefficients (spatial trend parameter). 
Specifically, S(t)~N(0,?2H11(?) ), where ?2  is the variance (partial sill),  H11(?) is the correlation
matrix based on valid correlation function h(u; ?), where u is the distance
between locations and ? is the correlation parameter (range).
hj~N(0, ?2h), where ?2h is the household level variance
?ij~N(0,?2), where ?2 is
the nugget effect/measurement error. 

I am trying to achieve the above task through geostatistical analysis but other methods which can be implemented in R are also welcomed.


Please, could somebody help me with some papers in the literature, existing packages in R which are related to my problem as well as providing me with R codes to implement this assuming someone has already done this kind of multilevel spatial regression and interpolation in R or other packages. 

Many thanks for your help in advance. 


Kind regards

*****************************************
Justice Moses K. Aheto
PhD Candidate in Medicine (United Kingdom)
MSc Medical Statistics (United Kingdom)
BSc Statistics (Ghana)
HND Statistics (Ghana)

Chief Executive Officer
Statistics and Analytics Consultancy Services Ltd.

Skype: jascall12
Mobile:
 +447417589148.
	[[alternative HTML version deleted]]


From hc10024 at gmail.com  Thu Sep 25 07:57:41 2014
From: hc10024 at gmail.com (Helen Chen)
Date: Wed, 24 Sep 2014 22:57:41 -0700
Subject: [R-sig-Geo] fitting variogram in regrssion kriging
Message-ID: <CAKjCKvFnQhFRXeZr-HTaA4VhO_Kv7RDdNXFKRhqZDoG3qu9OAw@mail.gmail.com>

Hi,

I am following the code provide from this link:
http://spatial-analyst.net/wiki/index.php?title=Regression-kriging_guide)
with my own data.

but I got stuck in fitting variogram, the error message is as follow:

> vgm_precip_r <- fit.variogram(variogram(annaul_2001~mask_10m.asc,
precip), model=null.vgm)
Error in na.fail.default(list(annaul_2001 = c(945.134, 648.716, 559.562,  :
  missing values in object

But I have checked that there is no missing value in my rainfall data. Any
help would be very much appreciated.

Helen

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Thu Sep 25 08:23:19 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 25 Sep 2014 08:23:19 +0200
Subject: [R-sig-Geo] PBSmapping calcArea
In-Reply-To: <CALOjXYSSZ_E0i5W+VoEd3xMH=KdP=MSd=F0z+NMiFBBZ1mhaNQ@mail.gmail.com>
References: <CALOjXYSSZ_E0i5W+VoEd3xMH=KdP=MSd=F0z+NMiFBBZ1mhaNQ@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1409250758230.19848@reclus.nhh.no>

On Thu, 25 Sep 2014, Kenny Bell wrote:

> Hi all,
>
> I am trying to use calcArea to get the areas of the following polygons at
> the following link:
>
> https://www.dropbox.com/s/v1fjsdkcyxw61qt/rsiggeoQ.RData?dl=0

Thanks for providing a reproducible example.

>
> I use:
>
> library(PBSmapping)
> areaY <- calcArea(smallYPolySet, rollup = 2)
>
> which gives the output:
>
>> areaY
>  PID SID        area
> 1   1   1  38.7704526
> 2   2   1 116.6810084
> 3   2   2   0.9844843
>
> The second polygon has a hole which can be seen with:
>
> plotLines(smallYPolySet)
>
> However, the rollup = 2 option should see the hole and subtract the area
> and return the difference, as I understand. The above shows they are
> specified separately.
>
> Can someone help me with any/all of:
>
> 1) working out whether the hole is identified in the smallYPolySet object
> 2) flagging an element of a polyset as a hole
> 2) automatically determining if a polygon is a hole
>

Do everything step-by-step under your own control, using the standard sp 
class toolset:

load("rsiggeoQ.RData")
tail(smallYPolySet)
library(PBSmapping)
library(maptools)
sp <- PolySet2SpatialPolygons(smallYPolySet)
# function does not try to detect holes, as they may be wrong
sapply(slot(sp, "polygons"), function(p) sapply(slot(p, "Polygons"), slot,
  "hole")) # no holes
sapply(slot(sp, "polygons"), comment)
sp <- createSPComment(sp)
sapply(slot(sp, "polygons"), comment) # still no holes,
# the comment encodes to which exterior ring "0" in each Polygons object
# each hole belongs
library(rgeos)
slot(sp, "polygons") <- lapply(slot(sp, "polygons"), checkPolygonsHoles)
sapply(slot(sp, "polygons"), function(p) sapply(slot(p, "Polygons"), slot,
  "hole")) # to show change
sapply(slot(sp, "polygons"), comment) # to show change 
# hole now correctly assigned
library(rgdal)
sp_utm <- spTransform(sp, CRS("+proj=utm +zone=24 +units=km"))
gArea(sp_utm, byid=TRUE)

smallYPolySet1 <- smallYPolySet[c(1:59, 65:60),]
calcArea(smallYPolySet1, rollup=2)

I think that the specific problem is that your PolySet PID 2 SID 2 does 
not have POS in descending order (see tail() above) - a change made in the 
S3 class to try to say whether a ring is a hole or not; the sp Polygon 
class has a "hole" slot which is set TRUE when we know that it is a hole, 
and which can be checked and corrected using maptools::checkPolygonsHoles 
on Polygons objects (those with both exterior and possibly interior 
rings). Using a convenience function like calcArea isn't convenient when 
the object isn't what you think it is.

Hope this clarifies,

Roger

> Any help would be very much appreciated!
>
> Thanks,
> Kenny
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From Thierry.ONKELINX at inbo.be  Thu Sep 25 09:27:03 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 25 Sep 2014 07:27:03 +0000
Subject: [R-sig-Geo] Spatial and multilevel model with
 kriging/interpolation	in R
In-Reply-To: <1411611925.8381.YahooMailNeo@web120901.mail.ne1.yahoo.com>
References: <1411611925.8381.YahooMailNeo@web120901.mail.ne1.yahoo.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AF50B7@inbomail.inbo.be>

Have a look at the INLA package (www.r-inla.org)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-project.org] Namens Justice Moses K. Aheto
Verzonden: donderdag 25 september 2014 4:25
Aan: r-sig-geo at r-project.org
Onderwerp: [R-sig-Geo] Spatial and multilevel model with kriging/interpolation in R

Dear All,
Please, I wish to analyse a spatial data in R through multilevel approach with my main primary objective been to interpolate for unsampled locations in my study region. Children in my data set are nested within households in the study locations and my multilevel model (without spatial) showed significant household random effects hence my choice to employ spatial analysis with multilevel approach.
The need to include household random effects in my spatial model makes it a bit difficult for me to implement in R unlike the standard geostatical analysis.
I have 'SpatialPointsDataFrame' containing my geographical coordinates (longitude and latitude) as well as my response and covariates.
The spatial mixed effects model I wish to fit and interpolate is: Yij(t) = Xij(t)? +hj+S(t)+?ij           (1)
where
i=individual child, j=household, X(t)= spatial referenced non-random covariates, S(t)= spatially correlated stationary Gaussian process.
?ij =nugget effect/measurement error, Yij(t) = response of child i in household j at location t and is a continuous variable, hj =household level random effects and ?=regression coefficients (spatial trend parameter).
Specifically, S(t)~N(0,?2H11(?) ), where ?2  is the variance (partial sill),  H11(?) is the correlation matrix based on valid correlation function h(u; ?), where u is the distance between locations and ? is the correlation parameter (range).
hj~N(0, ?2h), where ?2h is the household level variance ?ij~N(0,?2), where ?2 is the nugget effect/measurement error.

I am trying to achieve the above task through geostatistical analysis but other methods which can be implemented in R are also welcomed.


Please, could somebody help me with some papers in the literature, existing packages in R which are related to my problem as well as providing me with R codes to implement this assuming someone has already done this kind of multilevel spatial regression and interpolation in R or other packages.

Many thanks for your help in advance.


Kind regards

*****************************************
Justice Moses K. Aheto
PhD Candidate in Medicine (United Kingdom) MSc Medical Statistics (United Kingdom) BSc Statistics (Ghana) HND Statistics (Ghana)

Chief Executive Officer
Statistics and Analytics Consultancy Services Ltd.

Skype: jascall12
Mobile:
 +447417589148.
        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.

From hengl at spatial-analyst.net  Thu Sep 25 09:57:45 2014
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Thu, 25 Sep 2014 09:57:45 +0200
Subject: [R-sig-Geo] fitting variogram in regrssion kriging
In-Reply-To: <CAKjCKvFnQhFRXeZr-HTaA4VhO_Kv7RDdNXFKRhqZDoG3qu9OAw@mail.gmail.com>
References: <CAKjCKvFnQhFRXeZr-HTaA4VhO_Kv7RDdNXFKRhqZDoG3qu9OAw@mail.gmail.com>
Message-ID: <5423CAF9.8080901@spatial-analyst.net>


Helen,

Most likely you need to subset the missing values by using e.g. 
"precip[!is.na(precip$annaul_2001),]", but it is difficult to see if you 
maybe have a typo with variable names.

Try using "traceback()" and check the amount of missing values by using 
e.g. "summary(is.na(precip$annaul_2001))" and/or 
"summary(complete.cases(precip))".

HTH,

T. (Tom) Hengl
Researcher @ ISRIC - World Soil Information
Url: http://www.wageningenur.nl/en/Persons/dr.-T-Tom-Hengl.htm
Network: http://profiles.google.com/tom.hengl
Publications: http://scholar.google.com/citations?user=2oYU7S8AAAAJ


On 25-9-2014 7:57, Helen Chen wrote:
> Hi,
>
> I am following the code provide from this link:
> http://spatial-analyst.net/wiki/index.php?title=Regression-kriging_guide)
> with my own data.
>
> but I got stuck in fitting variogram, the error message is as follow:
>
>> vgm_precip_r <- fit.variogram(variogram(annaul_2001~mask_10m.asc,
> precip), model=null.vgm)
> Error in na.fail.default(list(annaul_2001 = c(945.134, 648.716, 559.562,  :
>    missing values in object
>
> But I have checked that there is no missing value in my rainfall data. Any
> help would be very much appreciated.
>
> Helen
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From edzer.pebesma at uni-muenster.de  Thu Sep 25 11:04:04 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 25 Sep 2014 11:04:04 +0200
Subject: [R-sig-Geo] fitting variogram in regrssion kriging
In-Reply-To: <5423CAF9.8080901@spatial-analyst.net>
References: <CAKjCKvFnQhFRXeZr-HTaA4VhO_Kv7RDdNXFKRhqZDoG3qu9OAw@mail.gmail.com>
	<5423CAF9.8080901@spatial-analyst.net>
Message-ID: <5423DA84.3030201@uni-muenster.de>

We can only speculate, but mask_10m.asc may contain missing values, and
not refer to rainfall (directly).

On 09/25/2014 09:57 AM, Tomislav Hengl wrote:
> 
> Helen,
> 
> Most likely you need to subset the missing values by using e.g.
> "precip[!is.na(precip$annaul_2001),]", but it is difficult to see if you
> maybe have a typo with variable names.
> 
> Try using "traceback()" and check the amount of missing values by using
> e.g. "summary(is.na(precip$annaul_2001))" and/or
> "summary(complete.cases(precip))".
> 
> HTH,
> 
> T. (Tom) Hengl
> Researcher @ ISRIC - World Soil Information
> Url: http://www.wageningenur.nl/en/Persons/dr.-T-Tom-Hengl.htm
> Network: http://profiles.google.com/tom.hengl
> Publications: http://scholar.google.com/citations?user=2oYU7S8AAAAJ
> 
> 
> On 25-9-2014 7:57, Helen Chen wrote:
>> Hi,
>>
>> I am following the code provide from this link:
>> http://spatial-analyst.net/wiki/index.php?title=Regression-kriging_guide)
>> with my own data.
>>
>> but I got stuck in fitting variogram, the error message is as follow:
>>
>>> vgm_precip_r <- fit.variogram(variogram(annaul_2001~mask_10m.asc,
>> precip), model=null.vgm)
>> Error in na.fail.default(list(annaul_2001 = c(945.134, 648.716,
>> 559.562,  :
>>    missing values in object
>>
>> But I have checked that there is no missing value in my rainfall data.
>> Any
>> help would be very much appreciated.
>>
>> Helen
>>
>>     [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140925/eac885b7/attachment.bin>

From frtog at vestas.com  Thu Sep 25 11:11:31 2014
From: frtog at vestas.com (=?utf-8?B?RnJlZGUgQWFrbWFubiBUw7hnZXJzZW4=?=)
Date: Thu, 25 Sep 2014 11:11:31 +0200
Subject: [R-sig-Geo] Spatial and multilevel model with
 kriging/interpolation	in R
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3AF50B7@inbomail.inbo.be>
References: <1411611925.8381.YahooMailNeo@web120901.mail.ne1.yahoo.com>
	<AA818EAD2576BC488B4F623941DA7427F3AF50B7@inbomail.inbo.be>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C7DE892F@DKRDSEXC016.vestas.net>

Hi

As Thierry points out INLA is certainly one way to go. Very powerful. For some inspiration see the tutorials and example on the INLA web site. Perhaps the geostatinla package for R (http://pbrown.ca/geostatsp/document-rev.pdf) can be of use for you. Also the section on geoadditive models in http://www.rni.helsinki.fi/~jmh/mrf08/R-INLA.pdf may give you some ideas.

The nlme package for R can fit the same kind of models, see e.g. http://www.ats.ucla.edu/stat/r/faq/spatial_regression.htm. 


Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 

> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> project.org] On Behalf Of ONKELINX, Thierry
> Sent: 25. september 2014 09:27
> To: Justice Moses K. Aheto; r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] Spatial and multilevel model with
> kriging/interpolation in R
> 
> Have a look at the INLA package (www.r-inla.org)
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
> 
> To call in the statistician after the experiment is done may be no more than
> asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> -----Oorspronkelijk bericht-----
> Van: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> project.org] Namens Justice Moses K. Aheto
> Verzonden: donderdag 25 september 2014 4:25
> Aan: r-sig-geo at r-project.org
> Onderwerp: [R-sig-Geo] Spatial and multilevel model with
> kriging/interpolation in R
> 
> Dear All,
> Please, I wish to analyse a spatial data in R through multilevel approach with
> my main primary objective been to interpolate for unsampled locations in my
> study region. Children in my data set are nested within households in the
> study locations and my multilevel model (without spatial) showed significant
> household random effects hence my choice to employ spatial analysis with
> multilevel approach.
> The need to include household random effects in my spatial model makes it a
> bit difficult for me to implement in R unlike the standard geostatical analysis.
> I have 'SpatialPointsDataFrame' containing my geographical coordinates
> (longitude and latitude) as well as my response and covariates.
> The spatial mixed effects model I wish to fit and interpolate is: Yij(t) = Xij(t)?
> +hj+S(t)+?ij           (1)
> where
> i=individual child, j=household, X(t)= spatial referenced non-random
> covariates, S(t)= spatially correlated stationary Gaussian process.
> ?ij =nugget effect/measurement error, Yij(t) = response of child i in
> household j at location t and is a continuous variable, hj =household level
> random effects and ?=regression coefficients (spatial trend parameter).
> Specifically, S(t)~N(0,?2H11(?) ), where ?2  is the variance (partial sill),
> H11(?) is the correlation matrix based on valid correlation function h(u; ?),
> where u is the distance between locations and ? is the correlation parameter
> (range).
> hj~N(0, ?2h), where ?2h is the household level variance ?ij~N(0,?2), where
> ?2 is the nugget effect/measurement error.
> 
> I am trying to achieve the above task through geostatistical analysis but other
> methods which can be implemented in R are also welcomed.
> 
> 
> Please, could somebody help me with some papers in the literature, existing
> packages in R which are related to my problem as well as providing me with R
> codes to implement this assuming someone has already done this kind of
> multilevel spatial regression and interpolation in R or other packages.
> 
> Many thanks for your help in advance.
> 
> 
> Kind regards
> 
> *****************************************
> Justice Moses K. Aheto
> PhD Candidate in Medicine (United Kingdom) MSc Medical Statistics (United
> Kingdom) BSc Statistics (Ghana) HND Statistics (Ghana)
> 
> Chief Executive Officer
> Statistics and Analytics Consultancy Services Ltd.
> 
> Skype: jascall12
> Mobile:
>  +447417589148.
>         [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer
> en binden het INBO onder geen enkel beding, zolang dit bericht niet
> bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the
> writer and may not be regarded as stating an official position of INBO, as long
> as the message is not confirmed by a duly signed document.
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

From macqueen1 at llnl.gov  Thu Sep 25 20:25:33 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 25 Sep 2014 18:25:33 +0000
Subject: [R-sig-Geo] Identifying which points are in which cluster
Message-ID: <D049AC2C.10CCF6%macqueen1@llnl.gov>

In the following reproducible example I have created a
SpatialPointsDataFrame with three clusters of points. What I?m looking for
is a (good) way to add to the SPDF a column which identifies which cluster
each point is in.

?? begin example ---

require(sp)
require(rgeos)


## construct at SpatialPointsDataFrame with three "clusters"
ctrs <- cbind(x=c( 7000,  8000,  9000),
              y=c(12000, 13000, 14000))

pts <- cbind(rep(ctrs[,1],3)+runif(9,-20,20),
             rep(ctrs[,2],3) + runif(9, -20,20))

plot(pts)

pts <- SpatialPointsDataFrame(pts, data.frame(name=letters[1:9]) ,
proj4string=CRS('+init=epsg:26943'))

plot(pts)

## now pretend I don't which points are in which cluster
tmp1 <- gBuffer(pts, width=30, byid=TRUE)
tmp2 <- gUnaryUnion(tmp1)

## tmp2 is now a SpatialPolygons object
## with three Polygons, one for each "cluster"

plot(tmp2, usePolypath=FALSE)
plot(pts, add=TRUE)
points(ctrs, col='red', pch=3, cex=0.5)

? end example ?

Now I need a way to identify which point is in which polygon, and add a
variable to the data frame slot of pts with that information.

I?m sure I can work it out by digging into the structure of tmp2 and
pulling out the individual polygons using a loop, but I?m hoping there?s a
higher level solution, possibly using some combination of lapply() or
sapply() with over(). But I have not been able to come up with it.

Thanks
-Don


By the way, searching through old r-sig-geo emails, I found
  tmp.cc <- hclust(dist(coordinates(pts)), "complete")
  tmp.50 <- cutree(tmp.cc, h=50)

and this works for this example (thanks to marcelino.delacruz at upm.es), but
it?s not clear to me which approach will be better in the long run for my
applications.

And I see something could be done with spdep:dnearneigh(), but the output
structure is a little complex and I don?t understand it well enough.


So I would still appreciate suggestions for a solution based on points in
polygons and the data structures in the example.

Thanks very much
-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


From justiceaheto at yahoo.com  Thu Sep 25 21:40:38 2014
From: justiceaheto at yahoo.com (Justice Moses K. Aheto)
Date: Thu, 25 Sep 2014 12:40:38 -0700
Subject: [R-sig-Geo] Spatial and multilevel model with
	kriging/interpolation in R
Message-ID: <1411674038.22118.YahooMailNeo@web120903.mail.ne1.yahoo.com>

Hello Thierry and Frede,
Many thanks for your assistance and I do appreciate it very much and I will have a look at inla as suggested.
Frede, I know how to fit the model in nlme package using lme but the major problem is how to use the model in lme for kriging and interpolation for on a grid/mesh. The model I fitted in lme last week Monday is shown below: 

m1 <- lme(haz2 ~m5newf+v445new+hw1new+v012+v190newf+b0new+v481new+m18new, random = ~ 1|hhid, method="ML",data = d1) # Multilevel model (no spatial component)
plot(Variogram(m1,form=~x+y)) # Plotting the variogram from the above model

# Updating my model with spatial autocorrelation using Gaussian spatial correlation. I have tried Gaussian,exponential and spherical spatial correlation and the Gaussian fits my data better (shown below): 

spg <- update(m1, correlation = corGaus(value=c(2000,0.6),form = ~ x+ y,nugget=T)) # initial values for range and nugget effects are 2000 and 0.6 respectively. 
summary(spg)
plot(Variogram(spg,form=~x+y)) # Plotting the variogram 

>From here, I need to use the spatial model above (spg) to do the kriging/interpolation on a grid (mesh) to be obtained from my data and I struggling to find my way out of it as of last week Monday 15th Sept.
The size of my data is too large if not I would have attached it for the purpose of reproducibility. 
I will definitely have a look also at INLA as suggested and I am looking forward to more suggestions. 
Many thanks to you All. 
 
Kind regards

*****************************************
Justice Moses K. Aheto
PhD Candidate in Medicine (United Kingdom)
MSc Medical Statistics (United Kingdom)
BSc Statistics (Ghana)
HND Statistics (Ghana)

Chief Executive Officer
Statistics and Analytics Consultancy Services Ltd.

Skype: jascall12
Mobile: +447417589148.
	[[alternative HTML version deleted]]


From bakare at ualberta.ca  Thu Sep 25 22:24:24 2014
From: bakare at ualberta.ca (Moshood Agba Bakare)
Date: Thu, 25 Sep 2014 14:24:24 -0600
Subject: [R-sig-Geo] guide to interpretation of kriged maps
Message-ID: <CAJRR3XNG08bjPp3zo_tdozMgt6E-1ZrQUHBHUT4XO+DJMoGFCQ@mail.gmail.com>

Hi All,
I am yet to get response on tips to guide me in interpreting the
interpolated surface and kriging variance maps obtained from spatial
interpolation into regular grids.

Thank you.

	[[alternative HTML version deleted]]


From yuzhou at mcw.edu  Fri Sep 26 02:51:51 2014
From: yuzhou at mcw.edu (Zhou, Yuhong)
Date: Fri, 26 Sep 2014 00:51:51 +0000
Subject: [R-sig-Geo] use quadtree idea to create densified grids containing
 maximum number points
Message-ID: <EDA9F8F3A77B6F4DB5AC0A79CE8BA9B921B2A1D4@MCWMB5.mcwcorp.net>

The goal is to divide a bounding square into nonuniform grids, constraining
that each grid does not contain maximum number points.

The origins (lower-left corner) and the side length of the square are given
to define the bounding square. A point threshold, for example, a value of 50
is chosen. The points shapefile is available, from which the projection can
be determined. The points shapefile has a variable called Obs, describing
how many observations are attached to that point.

The quadtree idea is employed to do this. If the number of original data
points/observations in the bounding square is larger than the size of the
threshold, we split the study space into four separate, equal-area
rectangles. Then the number of points/observations within each rectangle is
counted. If the value exceeds the threshold, that rectangle is further
subdivided. This is repeated for all rectangles, at all levels of
subdivision, until no rectangle has a number of original data points in
excess of the threshold.

I have written a function to try to achieve this. The current code run
recursively, but never ends the recursion.  Either something is wrong with
the return(), or with the structure of the function. I also want to record
the XY coordinates of grids that are leaves, and trace their
grid-parents/grandparents/...., but not know how to get it coded correctly.

Here is the code:
## origin, delta -> bounding square
## points (shapefile)
## threshold
##  xy_df to record the XY of child/leaf grids
## id - indexing the classes of leaf/parent

quadtree <- function(origin, delta, threshold=50, points, strCRS, id=1, xy_df) {
  d = 4
  ## Get the cellcenter and cell size
  cs <- c(delta/2, delta/2) ## cell size
  cd <- c(2,2) ## same for quadtree division
  cc <- origin + (cs/2) ##cellcenter

  ## create the grid structure and spatial grid data frame
  grd <- GridTopology(cellcentre.offset=cc, cellsize=cs, cells.dim=cd)
  sp_grd_all <- SpatialGridDataFrame(grd,data=data.frame(id=1:prod(cd)),proj4string=strCRS)

  ## overlay with the points to get the sum of the attribute values (e.g. #observations) of the points
  newgrd <-aggregate(pointshp[names(pointshp) == "Obs"], sp_grd_all, FUN =sum)
  sp_grd_all[["Obs"]] <- newgrd at data

  ## Loop each grid, if the number of observations within the grid does not exceed the threshold value (maximum number of observations a grid can
accommadate), add the XY coordinates of the grid to a dataframe; otherwise, split/divide the grid into four quadrants (recursively call the function quadtree);
  for (j in 1:4) {
    if ((sp_grd_all$Obs[j,1] <=k)) {
      x = coordinates(sp_grd_all)[j,1]
      y = coordinates(sp_grd_all)[j,2]
      newdf <-data.frame(xcoor=x, ycoor=y)
      colnames(newdf)<-colnames(xy_df)
      xy_df <- rbind(xy_df, newdf)

      #rv = list(id=id+j, xcoor=x, ycoor=y)  ## i also want to create a class for the child grid; but not sure whether the coding is correct
      #class(rv) <- "quadtree.leaf"
    }
    else{

      co1 <- coordinates(sp_grd_all)[j,] - (cs/2) ## calculate the origins (the lower-left corner) of each sub-grid
      len1 <- len/2  ## calculate the total length of the sub-grid
      quadtree(co1, len1, k, points, boundary, strCRS, id+j,xy_df)  ## recursive call function to divide the grid to quadrants

      #rv <- list(index=j, qt=quadtree(co1, len1, k, points, boundary, strCRS, id+j))
      #class(rv) <- "quadtree"  ## i also want to create a class for the parent grid;
    }
    ## return(xy_df)   ## when I included the return() here, the code stops when a leaf/child is found; when i removed it, the recursive call never ends.
  }
}


Any feedbacks/suggestions/references to similar functions will be
appreciated. Thank you!

Jo


From hc10024 at gmail.com  Fri Sep 26 09:35:09 2014
From: hc10024 at gmail.com (Helen Chen)
Date: Fri, 26 Sep 2014 00:35:09 -0700
Subject: [R-sig-Geo] fitting variogram in regrssion kriging
In-Reply-To: <5423DA84.3030201@uni-muenster.de>
References: <CAKjCKvFnQhFRXeZr-HTaA4VhO_Kv7RDdNXFKRhqZDoG3qu9OAw@mail.gmail.com>
	<5423CAF9.8080901@spatial-analyst.net>
	<5423DA84.3030201@uni-muenster.de>
Message-ID: <CAKjCKvGXvc5Zv_4z0i_yLDwjw1E5jyOzEDPzrnLGuCVRw70B8g@mail.gmail.com>

Hi,

Thanks for your response. I have used traceback() and found out that the
bug is in the mask_10m.asc.

The following is the message:

12: stop("missing values in object")
11: na.fail.default(list(annaul_2001 = c(945.134, 648.716, 559.562,
    655.574, 771.144, 805.434, 1276.604, 519.938, 1036.574, 763.016,
    757.428, 1062.482, 851.662, 720.852, 672.084, 855.218, 599.948,
    745.744, 685.292, 699.77, 775.97, 752.602, 573.786, 755.65, 628.904,
    849.63, 741.426, 676.402, 909.066, 695.452, 577.85, 707.644,
    762, 824.738, 919.48, 653.034, 781.304, 886.968, 828.802, 842.518,
    459.994, 624.84), mask_10m.asc = c(88.5786418914795, 45.8059759140015,
    15.0768859386444, 12.3127512931824, 71.3703689575195, 152.519027709961,
    1005.87916564941, 11.7274975776672, NA, 228.937419891357,
181.906177520752,
    318.3203125, 502.518295288086, NA, 42.9922714233398, NA, NA,
    104.217571258545, 177.359172821045, 232.616687774658, 457.08145904541,
    398.026458740234, NA, 232.151866912842, 64.8636112213135,
320.606918334961,
    154.726047515869, 240.452461242676, NA, 293.9072265625, NA,
181.774570465088,
    222.223022460938, 192.939517974854, 583.289840698242, 782.529495239258,
    497.32640838623, 1249.03039550781, 347.13688659668, NA, NA, NA
    )))

I have tried to use na.omit to remove the NAs from mask_10m.asc, but it
seems not work in this case.

Do you have any idea about how to get rid of NAs from ascii data? I have
attache the ascii file and precipitation file I used.

Many thanks in advance.

Best,

Helen?
 mask_10m.asc
<https://docs.google.com/file/d/0BxOsJNA0fHDrZjBSZURXNTBNWWM/edit?usp=drive_web>
?

2014-09-25 2:04 GMT-07:00 Edzer Pebesma <edzer.pebesma at uni-muenster.de>:

> We can only speculate, but mask_10m.asc may contain missing values, and
> not refer to rainfall (directly).
>
> On 09/25/2014 09:57 AM, Tomislav Hengl wrote:
> >
> > Helen,
> >
> > Most likely you need to subset the missing values by using e.g.
> > "precip[!is.na(precip$annaul_2001),]", but it is difficult to see if you
> > maybe have a typo with variable names.
> >
> > Try using "traceback()" and check the amount of missing values by using
> > e.g. "summary(is.na(precip$annaul_2001))" and/or
> > "summary(complete.cases(precip))".
> >
> > HTH,
> >
> > T. (Tom) Hengl
> > Researcher @ ISRIC - World Soil Information
> > Url: http://www.wageningenur.nl/en/Persons/dr.-T-Tom-Hengl.htm
> > Network: http://profiles.google.com/tom.hengl
> > Publications: http://scholar.google.com/citations?user=2oYU7S8AAAAJ
> >
> >
> > On 25-9-2014 7:57, Helen Chen wrote:
> >> Hi,
> >>
> >> I am following the code provide from this link:
> >>
> http://spatial-analyst.net/wiki/index.php?title=Regression-kriging_guide)
> >> with my own data.
> >>
> >> but I got stuck in fitting variogram, the error message is as follow:
> >>
> >>> vgm_precip_r <- fit.variogram(variogram(annaul_2001~mask_10m.asc,
> >> precip), model=null.vgm)
> >> Error in na.fail.default(list(annaul_2001 = c(945.134, 648.716,
> >> 559.562,  :
> >>    missing values in object
> >>
> >> But I have checked that there is no missing value in my rainfall data.
> >> Any
> >> help would be very much appreciated.
> >>
> >> Helen
> >>
> >>     [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at r-project.org
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
> 83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140926/eb0766a1/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 2001_stations_rainfall_0923.csv
Type: text/csv
Size: 1332 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140926/eb0766a1/attachment.bin>

From edzer.pebesma at uni-muenster.de  Fri Sep 26 11:17:29 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 26 Sep 2014 11:17:29 +0200
Subject: [R-sig-Geo] fitting variogram in regrssion kriging
In-Reply-To: <CAKjCKvGXvc5Zv_4z0i_yLDwjw1E5jyOzEDPzrnLGuCVRw70B8g@mail.gmail.com>
References: <CAKjCKvFnQhFRXeZr-HTaA4VhO_Kv7RDdNXFKRhqZDoG3qu9OAw@mail.gmail.com>	<5423CAF9.8080901@spatial-analyst.net>	<5423DA84.3030201@uni-muenster.de>
	<CAKjCKvGXvc5Zv_4z0i_yLDwjw1E5jyOzEDPzrnLGuCVRw70B8g@mail.gmail.com>
Message-ID: <54252F29.90202@uni-muenster.de>

Is mask_10m.asc a component of (column in) precip, or is it a separate
object? We need to see the full script that includes the steps that were
taken to constructed precip in order to help.

On 09/26/2014 09:35 AM, Helen Chen wrote:
> Hi,
> 
> Thanks for your response. I have used traceback() and found out that the
> bug is in the mask_10m.asc.
> 
> The following is the message:
> 
> 12: stop("missing values in object")
> 11: na.fail.default(list(annaul_2001 = c(945.134, 648.716, 559.562, 
>     655.574, 771.144, 805.434, 1276.604, 519.938, 1036.574, 763.016, 
>     757.428, 1062.482, 851.662, 720.852, 672.084, 855.218, 599.948, 
>     745.744, 685.292, 699.77, 775.97, 752.602, 573.786, 755.65, 628.904, 
>     849.63, 741.426, 676.402, 909.066, 695.452, 577.85, 707.644, 
>     762, 824.738, 919.48, 653.034, 781.304, 886.968, 828.802, 842.518, 
>     459.994, 624.84), mask_10m.asc = c(88.5786418914795, 45.8059759140015, 
>     15.0768859386444, 12.3127512931824, 71.3703689575195, 152.519027709961, 
>     1005.87916564941, 11.7274975776672, NA, 228.937419891357,
> 181.906177520752, 
>     318.3203125, 502.518295288086, NA, 42.9922714233398, NA, NA, 
>     104.217571258545, 177.359172821045, 232.616687774658, 457.08145904541, 
>     398.026458740234, NA, 232.151866912842, 64.8636112213135,
> 320.606918334961, 
>     154.726047515869, 240.452461242676, NA, 293.9072265625, NA,
> 181.774570465088, 
>     222.223022460938, 192.939517974854, 583.289840698242, 782.529495239258, 
>     497.32640838623, 1249.03039550781, 347.13688659668, NA, NA, NA
>     )))
> 
> I have tried to use na.omit to remove the NAs from mask_10m.asc, but it
> seems not work in this case.
> 
> Do you have any idea about how to get rid of NAs from ascii data? I have
> attache the ascii file and precipitation file I used.
> 
> Many thanks in advance.
> 
> Best,
> 
> Helen?
>  mask_10m.asc
> <https://docs.google.com/file/d/0BxOsJNA0fHDrZjBSZURXNTBNWWM/edit?usp=drive_web>
> ?
> 
> 2014-09-25 2:04 GMT-07:00 Edzer Pebesma <edzer.pebesma at uni-muenster.de
> <mailto:edzer.pebesma at uni-muenster.de>>:
> 
>     We can only speculate, but mask_10m.asc may contain missing values, and
>     not refer to rainfall (directly).
> 
>     On 09/25/2014 09:57 AM, Tomislav Hengl wrote:
>     >
>     > Helen,
>     >
>     > Most likely you need to subset the missing values by using e.g.
>     > "precip[!is.na <http://is.na>(precip$annaul_2001),]", but it is
>     difficult to see if you
>     > maybe have a typo with variable names.
>     >
>     > Try using "traceback()" and check the amount of missing values by
>     using
>     > e.g. "summary(is.na <http://is.na>(precip$annaul_2001))" and/or
>     > "summary(complete.cases(precip))".
>     >
>     > HTH,
>     >
>     > T. (Tom) Hengl
>     > Researcher @ ISRIC - World Soil Information
>     > Url: http://www.wageningenur.nl/en/Persons/dr.-T-Tom-Hengl.htm
>     > Network: http://profiles.google.com/tom.hengl
>     > Publications: http://scholar.google.com/citations?user=2oYU7S8AAAAJ
>     >
>     >
>     > On 25-9-2014 7:57, Helen Chen wrote:
>     >> Hi,
>     >>
>     >> I am following the code provide from this link:
>     >>
>     http://spatial-analyst.net/wiki/index.php?title=Regression-kriging_guide)
>     >> with my own data.
>     >>
>     >> but I got stuck in fitting variogram, the error message is as follow:
>     >>
>     >>> vgm_precip_r <- fit.variogram(variogram(annaul_2001~mask_10m.asc,
>     >> precip), model=null.vgm)
>     >> Error in na.fail.default(list(annaul_2001 = c(945.134, 648.716,
>     >> 559.562,  :
>     >>    missing values in object
>     >>
>     >> But I have checked that there is no missing value in my rainfall
>     data.
>     >> Any
>     >> help would be very much appreciated.
>     >>
>     >> Helen
>     >>
>     >>     [[alternative HTML version deleted]]
>     >>
>     >> _______________________________________________
>     >> R-sig-Geo mailing list
>     >> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>     >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>     >>
>     >
>     > _______________________________________________
>     > R-sig-Geo mailing list
>     > R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
>     --
>     Edzer Pebesma
>     Institute for Geoinformatics (ifgi), University of M?nster
>     Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
>     83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795
> 
> 
>     _______________________________________________
>     R-sig-Geo mailing list
>     R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140926/36f328a2/attachment.bin>

From hc10024 at gmail.com  Fri Sep 26 11:27:07 2014
From: hc10024 at gmail.com (Helen Chen)
Date: Fri, 26 Sep 2014 02:27:07 -0700
Subject: [R-sig-Geo] fitting variogram in regrssion kriging
In-Reply-To: <54252F29.90202@uni-muenster.de>
References: <CAKjCKvFnQhFRXeZr-HTaA4VhO_Kv7RDdNXFKRhqZDoG3qu9OAw@mail.gmail.com>
	<5423CAF9.8080901@spatial-analyst.net>
	<5423DA84.3030201@uni-muenster.de>
	<CAKjCKvGXvc5Zv_4z0i_yLDwjw1E5jyOzEDPzrnLGuCVRw70B8g@mail.gmail.com>
	<54252F29.90202@uni-muenster.de>
Message-ID: <CAKjCKvGj2GAxeebx-QnaeNRfvsskvGiAPEGBM=vq_frVW6UeAA@mail.gmail.com>

Hi,

Thanks for your response. The mask_10m.asc is a DEM data, not a column of
precipitation.

The precipitation data is generated from 42 rain gauges data. The first
column is Y, the second column is X, and the third column is rainfall
amounts (mm).

The following  is the script I adopted from the regression-Kriging guide
website:

library(sp)
library(lattice)
trellis.par.set(sp.theme()) # plots the final predictions using
blue-pink-yellow legend

precip <- read.csv("2001_stations_rainfall_0923.csv",header=T)
str(precip)
coordinates(precip)=~Lon+Lat   # this makes depth a SpatialPointsDataFrame
str(precip)

elevation = read.asciigrid("mask_10m.asc")  # reads ArcInfo Ascii raster map
eleok=na.omit(elevation)



elevation[!is.na(elevation),]
str(eleok)
spplot(eleok, scales=list(draw=T), sp.layout=list("sp.points", precip,
pch="+"))


#Plot the xy graph target versus predictor:

elev.ov = overlay(eleok, precip)  # create grid-points overlay
str(elev.ov at data)
precip$mask_10m.asc =elev.ov$mask_10m.asc  # copy the slope values

lm.precip <- lm(annaul_2001~mask_10m.asc, as.data.frame(precip))
summary(lm.precip)

plot(annaul_2001~mask_10m.asc, as.data.frame(precip))
abline(lm(annaul_2001~mask_10m.asc, as.data.frame(precip)))

#Fit the variogram model of the residuals:

library(gstat)
null.vgm <- vgm(var(precip$annaul_2001), "Sph",
sqrt(areaSpatialGrid(elevation))/4, nugget=0) # initial parameters
vgm_precip_r <- fit.variogram(variogram(annaul_2001~mask_10m.asc, precip),
model=null.vgm)
plot(variogram(annaul_total_2001.mm.~mask_10m.asc, precip), vgm_precip_r,
main="fitted by gstat")

I am stuck in the "vgm_precip_r <-
fit.variogram(variogram(annaul_2001~mask_10m.asc, precip), model=null.vgm)"
line

Thanks again for your time and help.

Helen

2014-09-26 2:17 GMT-07:00 Edzer Pebesma <edzer.pebesma at uni-muenster.de>:

> Is mask_10m.asc a component of (column in) precip, or is it a separate
> object? We need to see the full script that includes the steps that were
> taken to constructed precip in order to help.
>
> On 09/26/2014 09:35 AM, Helen Chen wrote:
> > Hi,
> >
> > Thanks for your response. I have used traceback() and found out that the
> > bug is in the mask_10m.asc.
> >
> > The following is the message:
> >
> > 12: stop("missing values in object")
> > 11: na.fail.default(list(annaul_2001 = c(945.134, 648.716, 559.562,
> >     655.574, 771.144, 805.434, 1276.604, 519.938, 1036.574, 763.016,
> >     757.428, 1062.482, 851.662, 720.852, 672.084, 855.218, 599.948,
> >     745.744, 685.292, 699.77, 775.97, 752.602, 573.786, 755.65, 628.904,
> >     849.63, 741.426, 676.402, 909.066, 695.452, 577.85, 707.644,
> >     762, 824.738, 919.48, 653.034, 781.304, 886.968, 828.802, 842.518,
> >     459.994, 624.84), mask_10m.asc = c(88.5786418914795,
> 45.8059759140015,
> >     15.0768859386444, 12.3127512931824, 71.3703689575195,
> 152.519027709961,
> >     1005.87916564941, 11.7274975776672, NA, 228.937419891357,
> > 181.906177520752,
> >     318.3203125, 502.518295288086, NA, 42.9922714233398, NA, NA,
> >     104.217571258545, 177.359172821045, 232.616687774658,
> 457.08145904541,
> >     398.026458740234, NA, 232.151866912842, 64.8636112213135,
> > 320.606918334961,
> >     154.726047515869, 240.452461242676, NA, 293.9072265625, NA,
> > 181.774570465088,
> >     222.223022460938, 192.939517974854, 583.289840698242,
> 782.529495239258,
> >     497.32640838623, 1249.03039550781, 347.13688659668, NA, NA, NA
> >     )))
> >
> > I have tried to use na.omit to remove the NAs from mask_10m.asc, but it
> > seems not work in this case.
> >
> > Do you have any idea about how to get rid of NAs from ascii data? I have
> > attache the ascii file and precipitation file I used.
> >
> > Many thanks in advance.
> >
> > Best,
> >
> > Helen?
> >  mask_10m.asc
> > <
> https://docs.google.com/file/d/0BxOsJNA0fHDrZjBSZURXNTBNWWM/edit?usp=drive_web
> >
> > ?
> >
> > 2014-09-25 2:04 GMT-07:00 Edzer Pebesma <edzer.pebesma at uni-muenster.de
> > <mailto:edzer.pebesma at uni-muenster.de>>:
> >
> >     We can only speculate, but mask_10m.asc may contain missing values,
> and
> >     not refer to rainfall (directly).
> >
> >     On 09/25/2014 09:57 AM, Tomislav Hengl wrote:
> >     >
> >     > Helen,
> >     >
> >     > Most likely you need to subset the missing values by using e.g.
> >     > "precip[!is.na <http://is.na>(precip$annaul_2001),]", but it is
> >     difficult to see if you
> >     > maybe have a typo with variable names.
> >     >
> >     > Try using "traceback()" and check the amount of missing values by
> >     using
> >     > e.g. "summary(is.na <http://is.na>(precip$annaul_2001))" and/or
> >     > "summary(complete.cases(precip))".
> >     >
> >     > HTH,
> >     >
> >     > T. (Tom) Hengl
> >     > Researcher @ ISRIC - World Soil Information
> >     > Url: http://www.wageningenur.nl/en/Persons/dr.-T-Tom-Hengl.htm
> >     > Network: http://profiles.google.com/tom.hengl
> >     > Publications:
> http://scholar.google.com/citations?user=2oYU7S8AAAAJ
> >     >
> >     >
> >     > On 25-9-2014 7:57, Helen Chen wrote:
> >     >> Hi,
> >     >>
> >     >> I am following the code provide from this link:
> >     >>
> >
> http://spatial-analyst.net/wiki/index.php?title=Regression-kriging_guide)
> >     >> with my own data.
> >     >>
> >     >> but I got stuck in fitting variogram, the error message is as
> follow:
> >     >>
> >     >>> vgm_precip_r <- fit.variogram(variogram(annaul_2001~mask_10m.asc,
> >     >> precip), model=null.vgm)
> >     >> Error in na.fail.default(list(annaul_2001 = c(945.134, 648.716,
> >     >> 559.562,  :
> >     >>    missing values in object
> >     >>
> >     >> But I have checked that there is no missing value in my rainfall
> >     data.
> >     >> Any
> >     >> help would be very much appreciated.
> >     >>
> >     >> Helen
> >     >>
> >     >>     [[alternative HTML version deleted]]
> >     >>
> >     >> _______________________________________________
> >     >> R-sig-Geo mailing list
> >     >> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
> >     >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >     >>
> >     >
> >     > _______________________________________________
> >     > R-sig-Geo mailing list
> >     > R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> >     --
> >     Edzer Pebesma
> >     Institute for Geoinformatics (ifgi), University of M?nster
> >     Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
> >     83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795
> >
> >
> >     _______________________________________________
> >     R-sig-Geo mailing list
> >     R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> >
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
> 83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795
>
>

	[[alternative HTML version deleted]]


From stephen.roecker at outlook.com  Fri Sep 26 16:34:19 2014
From: stephen.roecker at outlook.com (Stephen Roecker)
Date: Fri, 26 Sep 2014 14:34:19 +0000
Subject: [R-sig-Geo] gdal --config options
Message-ID: <BLU178-W5144BBCB629DCB1ADCC8A6E4BF0@phx.gbl>

I'm using the gdaUtils and raster packages and was wondering if it's
possible to specify --config options, using any of their functions
(e.g. gdalwarp, writeRaster, etc)? I've tried accomplishing this using
the additional_commands arguement in gdawarp with no success. Can
someone provide an example?

Stephen 		 	   		  
	[[alternative HTML version deleted]]


From jwm302 at gmail.com  Fri Sep 26 19:27:08 2014
From: jwm302 at gmail.com (Justin Michell)
Date: Fri, 26 Sep 2014 19:27:08 +0200
Subject: [R-sig-Geo] Construct prediction grid that has a value for each
	corresponding predictor raster grid cell
In-Reply-To: <CANtt_hx5ROCZKWMhD4wmfmSumh==GuxTmXk+im2p7Ch6SNFX=Q@mail.gmail.com>
References: <12EBC68A-F29F-489C-9C6B-1C4E099C7E53@gmail.com>
	<CANtt_hx5ROCZKWMhD4wmfmSumh==GuxTmXk+im2p7Ch6SNFX=Q@mail.gmail.com>
Message-ID: <8E4A06BB-F77E-4735-9BB5-78D7C8E85B5B@gmail.com>

Thank you, Roger. I have a grid now and I am in the process of experimenting with different resolutions for prediction, but I am worried that the yearly averaged predictor variables in the grid have some NA values in them. I only cropped my WorldClim data because it was already at the correct resolution:

# smaller extent and coarser res than original question posted
> meanTempStack 
class       : RasterBrick 
dimensions  : 36, 37, 1332, 12  (nrow, ncol, ncell, nlayers)
resolution  : 0.1666667, 0.1666667  (x, y)
extent      : 33.66667, 39.83333, -8.833333, -2.833333  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0 
data source : in memory
names       : meanTemp1, meanTemp2, meanTemp3, meanTemp4, meanTemp5, meanTemp6, meanTemp7, meanTemp8, meanTemp9, meanTemp10, meanTemp11, meanTemp12 
min values  :       6.3,       7.0,       7.1,       6.2,       5.1,       4.1,       3.2,       3.6,       4.6,        5.7,        6.0,        6.2 
max values  :      29.2,      29.4,      29.5,      28.4,      27.5,      26.8,      26.1,      25.9,      26.3,       27.1,       28.2,       28.9 

> class(grid)
[1] "SpatialPixelsDataFrame"
attr(,"package")
[1] ?sp"

> nrow(grid)
[1] 1332

sum(as.numeric(is.na(grid$meanTemp)))
[1] 54

sum(as.numeric(is.na(grid$NDVI)))
[1] 27

Some rows in my raster for all months have an NA value. My climate data comes from WorldClim and MODIS NDVI data. 

My question is will the fact that not each grid cell is complete affect the prediction? And is there something I can check for along the way before I put raster stacks into a grid to control for NA?s if it is a problem. 

Thanks 
Justin


On Sep 11, 2014, at 6:06 PM, Robert J. Hijmans <r.hijmans at gmail.com> wrote:

> Justin,
> 
> See  ?raster::predict
> 
> Robert
> 
> On Wed, Sep 10, 2014 at 7:42 AM, Justin Michell <jwm302 at gmail.com> wrote:
>> I have aligned raster layers as follows:
>> 
>>> NDVI1
>> class       : RasterLayer
>> dimensions  : 1287, 1321, 1700127  (nrow, ncol, ncell)
>> resolution  : 0.008333333, 0.008333333  (x, y)
>> extent      : 29.425, 40.43333, -11.725, -1  (xmin, xmax, ymin, ymax)
>> coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
>> data source : in memory
>> names       : layer.1.1.1
>> values      : -0.1524615, 0.9153615  (min, max)
>> 
>>> rain1
>> class       : RasterLayer
>> dimensions  : 1287, 1321, 1700127  (nrow, ncol, ncell)
>> resolution  : 0.008333333, 0.008333333  (x, y)
>> extent      : 29.425, 40.43333, -11.725, -1  (xmin, xmax, ymin, ymax)
>> coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
>> data source : in memory
>> names       : layer.1.1.1
>> values      : 7, 391  (min, max)
>> 
>> 
>> I have used spBayes::spGLM to get spatial estimates for a logit model (based on predictors including NDVI and rainfall).
>> 
>> I now wish to construct a prediction grid so that I can produce a continuous map of my predicted response based on draws from the predictive posterior distribution (using output from spBayes::spPredict).
>> 
>> What is the best strategy? Should I extend the range of prediction grid to be rectangular (and then recreate raster layers not cropped to my country of interest so that the grid has complete data). Perhaps by using raster::drawExtent() I can ?draw? a rectangle over my domain and use those bounds as input for prediction grid.
>> 
>> I was initially thinking of just creating a grid at the same 1x1km resolution as climate layers like so:
>> 
>> grid <- raster(nrows=nrow(NDVI1), ncols=ncol(NDVI1),
>>            xmn=bbox(NDVI1)[1], xmx=bbox(NDVI1)[3],
>>            ymn=bbox(NDVI1)[2], ymx=bbox(NDVI1)[4])
>> 
>> 
>> Thanks and Regards
>> Justin Michell
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From jwm302 at gmail.com  Fri Sep 26 19:30:05 2014
From: jwm302 at gmail.com (Justin Michell)
Date: Fri, 26 Sep 2014 19:30:05 +0200
Subject: [R-sig-Geo] Construct prediction grid that has a value for each
	corresponding predictor raster grid cell
In-Reply-To: <8E4A06BB-F77E-4735-9BB5-78D7C8E85B5B@gmail.com>
References: <12EBC68A-F29F-489C-9C6B-1C4E099C7E53@gmail.com>
	<CANtt_hx5ROCZKWMhD4wmfmSumh==GuxTmXk+im2p7Ch6SNFX=Q@mail.gmail.com>
	<8E4A06BB-F77E-4735-9BB5-78D7C8E85B5B@gmail.com>
Message-ID: <63E183EB-A739-4191-AD86-CD14E4D433DF@gmail.com>

Apologies. Robert, I mean. 

On Sep 26, 2014, at 7:27 PM, Justin Michell <jwm302 at gmail.com> wrote:

> Thank you, Roger. I have a grid now and I am in the process of experimenting with different resolutions for prediction, but I am worried that the yearly averaged predictor variables in the grid have some NA values in them. I only cropped my WorldClim data because it was already at the correct resolution:
> 
> # smaller extent and coarser res than original question posted
>> meanTempStack 
> class       : RasterBrick 
> dimensions  : 36, 37, 1332, 12  (nrow, ncol, ncell, nlayers)
> resolution  : 0.1666667, 0.1666667  (x, y)
> extent      : 33.66667, 39.83333, -8.833333, -2.833333  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0 
> data source : in memory
> names       : meanTemp1, meanTemp2, meanTemp3, meanTemp4, meanTemp5, meanTemp6, meanTemp7, meanTemp8, meanTemp9, meanTemp10, meanTemp11, meanTemp12 
> min values  :       6.3,       7.0,       7.1,       6.2,       5.1,       4.1,       3.2,       3.6,       4.6,        5.7,        6.0,        6.2 
> max values  :      29.2,      29.4,      29.5,      28.4,      27.5,      26.8,      26.1,      25.9,      26.3,       27.1,       28.2,       28.9 
> 
>> class(grid)
> [1] "SpatialPixelsDataFrame"
> attr(,"package")
> [1] ?sp"
> 
>> nrow(grid)
> [1] 1332
> 
> sum(as.numeric(is.na(grid$meanTemp)))
> [1] 54
> 
> sum(as.numeric(is.na(grid$NDVI)))
> [1] 27
> 
> Some rows in my raster for all months have an NA value. My climate data comes from WorldClim and MODIS NDVI data. 
> 
> My question is will the fact that not each grid cell is complete affect the prediction? And is there something I can check for along the way before I put raster stacks into a grid to control for NA?s if it is a problem. 
> 
> Thanks 
> Justin
> 
> 
> On Sep 11, 2014, at 6:06 PM, Robert J. Hijmans <r.hijmans at gmail.com> wrote:
> 
>> Justin,
>> 
>> See  ?raster::predict
>> 
>> Robert
>> 
>> On Wed, Sep 10, 2014 at 7:42 AM, Justin Michell <jwm302 at gmail.com> wrote:
>>> I have aligned raster layers as follows:
>>> 
>>>> NDVI1
>>> class       : RasterLayer
>>> dimensions  : 1287, 1321, 1700127  (nrow, ncol, ncell)
>>> resolution  : 0.008333333, 0.008333333  (x, y)
>>> extent      : 29.425, 40.43333, -11.725, -1  (xmin, xmax, ymin, ymax)
>>> coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
>>> data source : in memory
>>> names       : layer.1.1.1
>>> values      : -0.1524615, 0.9153615  (min, max)
>>> 
>>>> rain1
>>> class       : RasterLayer
>>> dimensions  : 1287, 1321, 1700127  (nrow, ncol, ncell)
>>> resolution  : 0.008333333, 0.008333333  (x, y)
>>> extent      : 29.425, 40.43333, -11.725, -1  (xmin, xmax, ymin, ymax)
>>> coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0
>>> data source : in memory
>>> names       : layer.1.1.1
>>> values      : 7, 391  (min, max)
>>> 
>>> 
>>> I have used spBayes::spGLM to get spatial estimates for a logit model (based on predictors including NDVI and rainfall).
>>> 
>>> I now wish to construct a prediction grid so that I can produce a continuous map of my predicted response based on draws from the predictive posterior distribution (using output from spBayes::spPredict).
>>> 
>>> What is the best strategy? Should I extend the range of prediction grid to be rectangular (and then recreate raster layers not cropped to my country of interest so that the grid has complete data). Perhaps by using raster::drawExtent() I can ?draw? a rectangle over my domain and use those bounds as input for prediction grid.
>>> 
>>> I was initially thinking of just creating a grid at the same 1x1km resolution as climate layers like so:
>>> 
>>> grid <- raster(nrows=nrow(NDVI1), ncols=ncol(NDVI1),
>>>           xmn=bbox(NDVI1)[1], xmx=bbox(NDVI1)[3],
>>>           ymn=bbox(NDVI1)[2], ymx=bbox(NDVI1)[4])
>>> 
>>> 
>>> Thanks and Regards
>>> Justin Michell
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 


From jbechara at lri-lb.org  Sat Sep 27 21:41:21 2014
From: jbechara at lri-lb.org (Joseph Bechara)
Date: Sat, 27 Sep 2014 22:41:21 +0300
Subject: [R-sig-Geo] zonal statistics as table
In-Reply-To: <8E4A06BB-F77E-4735-9BB5-78D7C8E85B5B@gmail.com>
Message-ID: <2170494810-4076@kerio.lri-lb.org>


Dear all,
? I'm looking for a R code that do the same work of "zonal statistics as table" of ArcIS.I found that the function zonal can do it but the issue is that I have large inputs raster and polygons.I'll appreciate if somebody ca help me.
polygons layers contains 9 millions rowsraster is 30 Gb
Regards,?


	[[alternative HTML version deleted]]


From forrest at ufl.edu  Sun Sep 28 00:05:29 2014
From: forrest at ufl.edu (Forrest Stevens)
Date: Sat, 27 Sep 2014 18:05:29 -0400
Subject: [R-sig-Geo] zonal statistics as table
In-Reply-To: <2170494810-4076@kerio.lri-lb.org>
References: <8E4A06BB-F77E-4735-9BB5-78D7C8E85B5B@gmail.com>
	<2170494810-4076@kerio.lri-lb.org>
Message-ID: <CAEBQMM=-1Efa13gYw47DDNsU9NUYg6gwYDqh2AmHe1C9xzVLEw@mail.gmail.com>

Hi Joseph.. With datasets that large, in my experience you're looking at
spatial subsetting to get something manageable and I've given up on zonal()
as it's just too slow for my needs. Rather, I would do your own feature to
raster conversion on the polygons based on the raster layer so cells
overlap exactly, then for your subsets convert the data to data.table
objects and run your aggregations using that very fast package.

When it comes to zonal statistics R is just a bit cumbersome for anything
larger than the smallest datasets.  I'd be happy to hear anyone else's
thoughts and be corrected if there's a more efficient way to do it!

Sincrerly,
Forrest

--
Forrest R. Stevens
Ph.D. Candidate, QSE3 IGERT Fellow
Department of Geography
Land Use and Environmental Change Institute
University of Florida
www.clas.ufl.edu/users/forrest

On Sat, Sep 27, 2014 at 3:41 PM, Joseph Bechara <jbechara at lri-lb.org> wrote:

>
> Dear all,
>   I'm looking for a R code that do the same work of "zonal statistics as
> table" of ArcIS.I found that the function zonal can do it but the issue is
> that I have large inputs raster and polygons.I'll appreciate if somebody ca
> help me.
> polygons layers contains 9 millions rowsraster is 30 Gb
> Regards,
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From jgrn at illinois.edu  Sun Sep 28 05:52:19 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Sat, 27 Sep 2014 22:52:19 -0500
Subject: [R-sig-Geo] gdal --config options
In-Reply-To: <BLU178-W5144BBCB629DCB1ADCC8A6E4BF0@phx.gbl>
References: <BLU178-W5144BBCB629DCB1ADCC8A6E4BF0@phx.gbl>
Message-ID: <CABG0rfvH=YQoc_=YnPJL9XhrZ=Vgd672YepJGZyeD5S2ogjwog@mail.gmail.com>

Stephen:

Can you expand on this a bit?  What, exactly, are you trying to do?  I
don't see a config flag in gdalwarp:
http://www.gdal.org/gdalwarp.html

--j

On Fri, Sep 26, 2014 at 9:34 AM, Stephen Roecker
<stephen.roecker at outlook.com> wrote:
> I'm using the gdaUtils and raster packages and was wondering if it's
> possible to specify --config options, using any of their functions
> (e.g. gdalwarp, writeRaster, etc)? I've tried accomplishing this using
> the additional_commands arguement in gdawarp with no success. Can
> someone provide an example?
>
> Stephen
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From jengelmann at cgdev.org  Sun Sep 28 16:16:35 2014
From: jengelmann at cgdev.org (Jens Engelmann (jengelmann@cgdev.org))
Date: Sun, 28 Sep 2014 14:16:35 +0000
Subject: [R-sig-Geo] zonal statistics as table
In-Reply-To: <CAEBQMM=-1Efa13gYw47DDNsU9NUYg6gwYDqh2AmHe1C9xzVLEw@mail.gmail.com>
References: <8E4A06BB-F77E-4735-9BB5-78D7C8E85B5B@gmail.com>
	<2170494810-4076@kerio.lri-lb.org>,
	<CAEBQMM=-1Efa13gYw47DDNsU9NUYg6gwYDqh2AmHe1C9xzVLEw@mail.gmail.com>
Message-ID: <97D1F716D34D934FACC3F30C14A4158D87C69086@Mail.CGDEV.ORG>

Hi Joseph,

I faced a similar problem at my current work. I do not believe that R currently has a solution to efficiently calculate raster stats on such a large dataset. Instead, I would look at the raster_stats utility in python:

https://github.com/perrygeo/python-raster-stats

I found this module to be extremely efficient and you can pipe the results into R to work with afterwards.

Cheers,
Jens

Jens Engelmann
Research Assistant
Center for Global Development
Independent Research & Practical Ideas for Global Prosperity
Phone: 1 202 416-4027
Email: jengelmann at cgdev.org
 
________________________________________
From: r-sig-geo-bounces at r-project.org [r-sig-geo-bounces at r-project.org] on behalf of Forrest Stevens [forrest at ufl.edu]
Sent: Saturday, September 27, 2014 6:05 PM
To: Joseph Bechara
Cc: R-SIG list
Subject: Re: [R-sig-Geo] zonal statistics as table

Hi Joseph.. With datasets that large, in my experience you're looking at
spatial subsetting to get something manageable and I've given up on zonal()
as it's just too slow for my needs. Rather, I would do your own feature to
raster conversion on the polygons based on the raster layer so cells
overlap exactly, then for your subsets convert the data to data.table
objects and run your aggregations using that very fast package.

When it comes to zonal statistics R is just a bit cumbersome for anything
larger than the smallest datasets.  I'd be happy to hear anyone else's
thoughts and be corrected if there's a more efficient way to do it!

Sincrerly,
Forrest

--
Forrest R. Stevens
Ph.D. Candidate, QSE3 IGERT Fellow
Department of Geography
Land Use and Environmental Change Institute
University of Florida
www.clas.ufl.edu/users/forrest

On Sat, Sep 27, 2014 at 3:41 PM, Joseph Bechara <jbechara at lri-lb.org> wrote:

>
> Dear all,
>   I'm looking for a R code that do the same work of "zonal statistics as
> table" of ArcIS.I found that the function zonal can do it but the issue is
> that I have large inputs raster and polygons.I'll appreciate if somebody ca
> help me.
> polygons layers contains 9 millions rowsraster is 30 Gb
> Regards,
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From kmb56 at berkeley.edu  Mon Sep 29 00:09:40 2014
From: kmb56 at berkeley.edu (Kenny Bell)
Date: Sun, 28 Sep 2014 15:09:40 -0700
Subject: [R-sig-Geo] Accessing the ids of neighbours in spdep
Message-ID: <CALOjXYRrHSt4kN3k5RKLiuEdZ_yjYwNnYAVGncJP3-jA02Mz2g@mail.gmail.com>

Hi,

I am trying to get an actual list of neighbour ids out of an nb object. For
example, I have

library(spdep)
example(columbus)
xx <- poly2nb(columbus)

What would be my command to get the list of neighbours as a list of
character vectors?

Thanks so much for any help,
Kenny

	[[alternative HTML version deleted]]


From berniekruger at gmail.com  Mon Sep 29 00:48:06 2014
From: berniekruger at gmail.com (Bernie Kruger)
Date: Sun, 28 Sep 2014 15:48:06 -0700 (PDT)
Subject: [R-sig-Geo] R Basic Spatial Interpolation
Message-ID: <1411944486283-7587199.post@n2.nabble.com>

I am a bit lost at the moment trying to find an R package/method to solve my
very basic problem. I think this might be the right forum to help me out. I
have a very simple dataset with Lat/Lon, Temp and Time as observations of
temperature at specific weather stations. 

All I want to do is to ?predict? missing temperatures at specific Lat/Lon
locations not covered by the weather stations. This need not to be highly
accurate, but purely indicative of what the temperature could be. 

I suspect I am after Spatial Interpolation, but I also read about Kriging
etc. 

I have played around with various methods/packages (Akima/Kriging) and it
does my head in - no success. Any suggestions/help please? 

Cheers 
B



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/R-Basic-Spatial-Interpolation-tp7587199.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From mtreglia at gmail.com  Mon Sep 29 06:16:49 2014
From: mtreglia at gmail.com (Michael Treglia)
Date: Sun, 28 Sep 2014 23:16:49 -0500
Subject: [R-sig-Geo] zonal statistics as table
In-Reply-To: <97D1F716D34D934FACC3F30C14A4158D87C69086@Mail.CGDEV.ORG>
References: <8E4A06BB-F77E-4735-9BB5-78D7C8E85B5B@gmail.com>
	<2170494810-4076@kerio.lri-lb.org>
	<CAEBQMM=-1Efa13gYw47DDNsU9NUYg6gwYDqh2AmHe1C9xzVLEw@mail.gmail.com>
	<97D1F716D34D934FACC3F30C14A4158D87C69086@Mail.CGDEV.ORG>
Message-ID: <CAPKp32tSADPFaZUazu3hQzcuJi+h9PePvfgWJbwi8-cqeFBpMA@mail.gmail.com>

I've had the same experiences as described above... Depending on exactly
what stats you need to calculate, you might want to check out SAGA GIS (
http://saga-gis.org/).  I've generally found it to work great on giant
rasters, though you might hit a limit depending on your hardware. The tool
you'd look for is in Shapes-Grid -> Grid Statistics for Polygons.

Alternatively, I've had some success with PostGIS - this code was designed
to give counts of unique pixel values within polygons:
https://github.com/RENCI-Ecohydro/OSS-2014/blob/master/Scripts/Database_PostGIS_Analyses_MLT.txt

Sorry that's not an R answer (:-\), but hope it helps.

Mike

On Sun, Sep 28, 2014 at 9:16 AM, Jens Engelmann (jengelmann at cgdev.org) <
jengelmann at cgdev.org> wrote:

> Hi Joseph,
>
> I faced a similar problem at my current work. I do not believe that R
> currently has a solution to efficiently calculate raster stats on such a
> large dataset. Instead, I would look at the raster_stats utility in python:
>
> https://github.com/perrygeo/python-raster-stats
>
> I found this module to be extremely efficient and you can pipe the results
> into R to work with afterwards.
>
> Cheers,
> Jens
>
> Jens Engelmann
> Research Assistant
> Center for Global Development
> Independent Research & Practical Ideas for Global Prosperity
> Phone: 1 202 416-4027
> Email: jengelmann at cgdev.org
>
> ________________________________________
> From: r-sig-geo-bounces at r-project.org [r-sig-geo-bounces at r-project.org]
> on behalf of Forrest Stevens [forrest at ufl.edu]
> Sent: Saturday, September 27, 2014 6:05 PM
> To: Joseph Bechara
> Cc: R-SIG list
> Subject: Re: [R-sig-Geo] zonal statistics as table
>
> Hi Joseph.. With datasets that large, in my experience you're looking at
> spatial subsetting to get something manageable and I've given up on zonal()
> as it's just too slow for my needs. Rather, I would do your own feature to
> raster conversion on the polygons based on the raster layer so cells
> overlap exactly, then for your subsets convert the data to data.table
> objects and run your aggregations using that very fast package.
>
> When it comes to zonal statistics R is just a bit cumbersome for anything
> larger than the smallest datasets.  I'd be happy to hear anyone else's
> thoughts and be corrected if there's a more efficient way to do it!
>
> Sincrerly,
> Forrest
>
> --
> Forrest R. Stevens
> Ph.D. Candidate, QSE3 IGERT Fellow
> Department of Geography
> Land Use and Environmental Change Institute
> University of Florida
> www.clas.ufl.edu/users/forrest
>
> On Sat, Sep 27, 2014 at 3:41 PM, Joseph Bechara <jbechara at lri-lb.org>
> wrote:
>
> >
> > Dear all,
> >   I'm looking for a R code that do the same work of "zonal statistics as
> > table" of ArcIS.I found that the function zonal can do it but the issue
> is
> > that I have large inputs raster and polygons.I'll appreciate if somebody
> ca
> > help me.
> > polygons layers contains 9 millions rowsraster is 30 Gb
> > Regards,
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From frtog at vestas.com  Mon Sep 29 07:17:51 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Mon, 29 Sep 2014 07:17:51 +0200
Subject: [R-sig-Geo] Accessing the ids of neighbours in spdep
In-Reply-To: <CALOjXYRrHSt4kN3k5RKLiuEdZ_yjYwNnYAVGncJP3-jA02Mz2g@mail.gmail.com>
References: <CALOjXYRrHSt4kN3k5RKLiuEdZ_yjYwNnYAVGncJP3-jA02Mz2g@mail.gmail.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C7E7694B@DKRDSEXC016.vestas.net>

Hi

I'm not really sure I understand you but perhaps something like this:

lapply(xx, paste, collapse = ", ")

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> project.org] On Behalf Of Kenny Bell
> Sent: 29. september 2014 00:10
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] Accessing the ids of neighbours in spdep
> 
> Hi,
> 
> I am trying to get an actual list of neighbour ids out of an nb object. For
> example, I have
> 
> library(spdep)
> example(columbus)
> xx <- poly2nb(columbus)
> 
> What would be my command to get the list of neighbours as a list of
> character vectors?
> 
> Thanks so much for any help,
> Kenny
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From frtog at vestas.com  Mon Sep 29 08:55:08 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Mon, 29 Sep 2014 08:55:08 +0200
Subject: [R-sig-Geo] Spatial and multilevel model
	with	kriging/interpolation in R
In-Reply-To: <1411674038.22118.YahooMailNeo@web120903.mail.ne1.yahoo.com>
References: <1411674038.22118.YahooMailNeo@web120903.mail.ne1.yahoo.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C7E769D8@DKRDSEXC016.vestas.net>

Hi

Even though there is a predict() for lme objects and it is easy to put up a regular grid over your region using the coordinates then you do not have values of your covariates at these coordinates making the predict() function fail. One way to go is to use some imputation methods to get values of your covariates at unobserved locations. However you probably need to come up with a joint distribution of response and covariates. That can become somewhat nasty I think.

Using INLA that is based on a Bayesian approach to statistical modelling where it is  easy to build joint distributions of variables this may be the way to go. I don't know the exact properties of your model variables but a joint Gaussian distribution may very well suits your needs on the original scale or on a transformed scale.

An example that may be the starting point for your model and direct you in putting up some R code may be Chapter 4 in http://www.math.ntnu.no/inla/r-inla.org/tutorials/spde/spde-tutorial.pdf. 

If you have further questions on INLA I think that you may get more response on the INLA discussion forum (see e.g. http://www.r-inla.org/) than on r-sig-geo mail list.


Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> project.org] On Behalf Of Justice Moses K. Aheto
> Sent: 25. september 2014 21:41
> To: geo-r-r-project
> Subject: Re: [R-sig-Geo] Spatial and multilevel model with
> kriging/interpolation in R
> 
> Hello Thierry and Frede,
> Many thanks for your assistance and I do appreciate it very much and I will
> have a look at inla as suggested.
> Frede, I know how to fit the model in nlme package using lme but the major
> problem is how to use the model in lme for kriging and interpolation for on a
> grid/mesh. The model I fitted in lme last week Monday is shown below:
> 
> m1 <- lme(haz2
> ~m5newf+v445new+hw1new+v012+v190newf+b0new+v481new+m18new,
> random = ~ 1|hhid, method="ML",data = d1) # Multilevel model (no spatial
> component)
> plot(Variogram(m1,form=~x+y)) # Plotting the variogram from the above
> model
> 
> # Updating my model with spatial autocorrelation using Gaussian spatial
> correlation. I have tried Gaussian,exponential and spherical spatial
> correlation and the Gaussian fits my data better (shown below):
> 
> spg <- update(m1, correlation = corGaus(value=c(2000,0.6),form = ~ x+
> y,nugget=T)) # initial values for range and nugget effects are 2000 and 0.6
> respectively.
> summary(spg)
> plot(Variogram(spg,form=~x+y)) # Plotting the variogram
> 
> >From here, I need to use the spatial model above (spg) to do the
> kriging/interpolation on a grid (mesh) to be obtained from my data and I
> struggling to find my way out of it as of last week Monday 15th Sept.
> The size of my data is too large if not I would have attached it for the purpose
> of reproducibility.
> I will definitely have a look also at INLA as suggested and I am looking forward
> to more suggestions.
> Many thanks to you All.
> 
> Kind regards
> 
> *****************************************
> Justice Moses K. Aheto
> PhD Candidate in Medicine (United Kingdom)
> MSc Medical Statistics (United Kingdom)
> BSc Statistics (Ghana)
> HND Statistics (Ghana)
> 
> Chief Executive Officer
> Statistics and Analytics Consultancy Services Ltd.
> 
> Skype: jascall12
> Mobile: +447417589148.
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From frtog at vestas.com  Mon Sep 29 08:59:57 2014
From: frtog at vestas.com (=?utf-8?B?RnJlZGUgQWFrbWFubiBUw7hnZXJzZW4=?=)
Date: Mon, 29 Sep 2014 08:59:57 +0200
Subject: [R-sig-Geo] R Basic Spatial Interpolation
In-Reply-To: <1411944486283-7587199.post@n2.nabble.com>
References: <1411944486283-7587199.post@n2.nabble.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C7E769DF@DKRDSEXC016.vestas.net>

Hi

It is kind of difficult to help you since we don't know what you have tried and what failed for you. Could you share your R code with error messages and preferably elaborate on what you really want to get from an interpolation. You are talking about meteorological data observed in 2D and perhaps in time. Do you want some kind of spatio-temporal model?

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> project.org] On Behalf Of Bernie Kruger
> Sent: 29. september 2014 00:48
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] R Basic Spatial Interpolation
> 
> I am a bit lost at the moment trying to find an R package/method to solve my
> very basic problem. I think this might be the right forum to help me out. I
> have a very simple dataset with Lat/Lon, Temp and Time as observations of
> temperature at specific weather stations.
> 
> All I want to do is to ?predict? missing temperatures at specific Lat/Lon
> locations not covered by the weather stations. This need not to be highly
> accurate, but purely indicative of what the temperature could be.
> 
> I suspect I am after Spatial Interpolation, but I also read about Kriging
> etc.
> 
> I have played around with various methods/packages (Akima/Kriging) and it
> does my head in - no success. Any suggestions/help please?
> 
> Cheers
> B
> 
> 
> 
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/R-
> Basic-Spatial-Interpolation-tp7587199.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

From leigh.kroeger at gmail.com  Mon Sep 29 10:22:45 2014
From: leigh.kroeger at gmail.com (Leigh Kroeger)
Date: Mon, 29 Sep 2014 11:22:45 +0300
Subject: [R-sig-Geo] Shapefiles and occurrence data
Message-ID: <CAObCpXM1TwPAKG1MLmZAFq6PivvcTQGtsS4eUt1itnXtETC9UA@mail.gmail.com>

Hello,

I am new to SDMs and spatial modelling. I have downloaded and subsetting
data from one species in the Mediterranean from GBIF. I have changed the
lat and lon to x and y spatial coordinates and now wish to marry them on
top of a gridded shapefile which has been uploaded successfully into R.

any tips for direction?

-- 
*Leigh A. Kroeger*
<*)))><

*PhD Candidate - Marine Ecology*
?????? ????? ?????
?????????? ?? ????

	[[alternative HTML version deleted]]


From f.rodriguez.sanc at gmail.com  Mon Sep 29 11:13:40 2014
From: f.rodriguez.sanc at gmail.com (Francisco Rodriguez Sanchez)
Date: Mon, 29 Sep 2014 11:13:40 +0200
Subject: [R-sig-Geo] Shapefiles and occurrence data
In-Reply-To: <CAObCpXM1TwPAKG1MLmZAFq6PivvcTQGtsS4eUt1itnXtETC9UA@mail.gmail.com>
References: <CAObCpXM1TwPAKG1MLmZAFq6PivvcTQGtsS4eUt1itnXtETC9UA@mail.gmail.com>
Message-ID: <542922C4.2090604@gmail.com>

Hi Leigh,

Some good tutorials to start:

http://cran.r-project.org/web/packages/dismo/vignettes/sdm.pdf

http://ropensci.org/blog/2014/04/22/rwbclimate-sp/

http://pakillo.github.io/R-GIS-tutorial/


Note you can obtain GBIF distribution data and climate data directy from 
R (check links above).

Hope this helps,

Paco

El 29/09/2014 10:22, Leigh Kroeger escribi?:
> Hello,
>
> I am new to SDMs and spatial modelling. I have downloaded and subsetting
> data from one species in the Mediterranean from GBIF. I have changed the
> lat and lon to x and y spatial coordinates and now wish to marry them on
> top of a gridded shapefile which has been uploaded successfully into R.
>
> any tips for direction?
>

-- 
Dr Francisco Rodriguez-Sanchez
Integrative Ecology Group
Estacion Biologica de Do?ana - CSIC
Avda. Americo Vespucio s/n
41092 Sevilla (Spain)
http://bit.ly/frod_san


From Roger.Bivand at nhh.no  Mon Sep 29 11:53:58 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 29 Sep 2014 11:53:58 +0200
Subject: [R-sig-Geo] Accessing the ids of neighbours in spdep
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C7E7694B@DKRDSEXC016.vestas.net>
References: <CALOjXYRrHSt4kN3k5RKLiuEdZ_yjYwNnYAVGncJP3-jA02Mz2g@mail.gmail.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C7E7694B@DKRDSEXC016.vestas.net>
Message-ID: <alpine.LRH.2.03.1409291144470.23196@reclus.nhh.no>

On Mon, 29 Sep 2014, Frede Aakmann T?gersen wrote:

> Hi
>
> I'm not really sure I understand you but perhaps something like this:
>
> lapply(xx, paste, collapse = ", ")

Yes, this is the closest we can get without more input from Kenny.

This gives the 1-base integer indices in a list of single element 
character vectors. If the output should be a character vector with the 
same number of elements as the input:

lapply(xx, as.character)

will do it. But the IDs of the underlying entities (could be FIPS, NUTS3, 
whatever) are in attr(xx, "region.id"), so to get those:

lapply(xx, function(x) attr(xx, "region.id")[x])

is needed, or if a list of single element character vectors is required:

lapply(xx, function(x) paste(attr(xx, "region.id")[x], collapse = ", "))

Here the IDs are 0-based rather than 1-based, but the attr(xx, 
"region.id") values are arbitrary - they are taken from row.names() of the 
spatial object unless given as an argument to functions creating the "nb" 
object.

Hope this clarifies,

Roger

>
> Yours sincerely / Med venlig hilsen
>
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>
>> -----Original Message-----
>> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
>> project.org] On Behalf Of Kenny Bell
>> Sent: 29. september 2014 00:10
>> To: r-sig-geo at r-project.org
>> Subject: [R-sig-Geo] Accessing the ids of neighbours in spdep
>>
>> Hi,
>>
>> I am trying to get an actual list of neighbour ids out of an nb object. For
>> example, I have
>>
>> library(spdep)
>> example(columbus)
>> xx <- poly2nb(columbus)
>>
>> What would be my command to get the list of neighbours as a list of
>> character vectors?
>>
>> Thanks so much for any help,
>> Kenny
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From annajess at gmx.de  Mon Sep 29 12:40:25 2014
From: annajess at gmx.de (Anna-Marie Corman)
Date: Mon, 29 Sep 2014 12:40:25 +0200
Subject: [R-sig-Geo] Calculating distance to nest with spDistsN1
Message-ID: <54293719.3010302@gmx.de>

Dear list,

I have a question regarding the spDistsN1 function. I want to calculate 
the distance of each flight position to the relevant nest position. My 
dataset consists of several birds with a differing number of trips. 
There is a unique trip_id with the first number regarding to the bird 
and the second number regarding to the trip.

          coordinates       Date     Time Speed Direction col_lat col_long dist_col
1 (7.87248, 54.1866) 04.07.2014 09:25:00  0.02    314.57 54.1866   7.8724      0.0
2 (7.87148, 54.1869) 04.07.2014 09:30:00 19.11      1.31 54.1866   7.8724      0.1
3  (7.87166, 54.185) 04.07.2014 09:35:00 14.98    224.79 54.1866   7.8724      0.2
4 (7.88635, 54.1569) 04.07.2014 09:40:00 11.44    136.97 54.1866   7.8724      3.4
5 (7.92096, 54.1363) 04.07.2014 09:45:00  0.28    262.14 54.1866   7.8724      6.4
6  (7.91931, 54.136) 04.07.2014 09:50:00  0.42    218.89 54.1866   7.8724      6.4
   trip_no bird_id trip_id                  DT           date_time
1       1       1     1.1 04.07.2014 09:25:00 2014-07-04 09:25:00
2       1       1     1.1 04.07.2014 09:30:00 2014-07-04 09:30:00
3       1       1     1.1 04.07.2014 09:35:00 2014-07-04 09:35:00
4       1       1     1.1 04.07.2014 09:40:00 2014-07-04 09:40:00
5       1       1     1.1 04.07.2014 09:45:00 2014-07-04 09:45:00
6       1       1     1.1 04.07.2014 09:50:00 2014-07-04 09:50:00



Formerly, when I only had one bird and so only one nest position (here 
col_lat & col_long), I did the following:

spDistsN1(coordinates(dat at coords), matrix(c(8.3495235,54.7042698), nrow 
= 1), longlat = T)

and this worked fine.

But now I want to calculate the distance from nest for each bird 
simultaneously. Must be simple, but I do not get it. I thought I could 
simply use

spDistsN1(coordinates(dat at coords), matrix(c(dat$col_long,dat$col_lat), 
nrow = 1), longlat = T)

instead, but it does not work.

Do you have any idea how to solve the "problem"?

Thanks a lot in advance.

Best,
Anna

	[[alternative HTML version deleted]]


From kmb56 at berkeley.edu  Mon Sep 29 22:10:50 2014
From: kmb56 at berkeley.edu (Kenny Bell)
Date: Mon, 29 Sep 2014 13:10:50 -0700
Subject: [R-sig-Geo] Accessing the ids of neighbours in spdep
In-Reply-To: <alpine.LRH.2.03.1409291144470.23196@reclus.nhh.no>
References: <CALOjXYRrHSt4kN3k5RKLiuEdZ_yjYwNnYAVGncJP3-jA02Mz2g@mail.gmail.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C7E7694B@DKRDSEXC016.vestas.net>
	<alpine.LRH.2.03.1409291144470.23196@reclus.nhh.no>
Message-ID: <CALOjXYSK1p1+m9_isSUdRx9ipkApJ7KPdob4ZVWDJsryaXwTug@mail.gmail.com>

Hi all,

This last one was what I was after:

lapply(xx, function(x) paste(attr(xx, "region.id")[x], collapse = ", "))

Thanks so much!
Kenny


On Mon, Sep 29, 2014 at 2:53 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Mon, 29 Sep 2014, Frede Aakmann T?gersen wrote:
>
>  Hi
>>
>> I'm not really sure I understand you but perhaps something like this:
>>
>> lapply(xx, paste, collapse = ", ")
>>
>
> Yes, this is the closest we can get without more input from Kenny.
>
> This gives the 1-base integer indices in a list of single element
> character vectors. If the output should be a character vector with the same
> number of elements as the input:
>
> lapply(xx, as.character)
>
> will do it. But the IDs of the underlying entities (could be FIPS, NUTS3,
> whatever) are in attr(xx, "region.id"), so to get those:
>
> lapply(xx, function(x) attr(xx, "region.id")[x])
>
> is needed, or if a list of single element character vectors is required:
>
> lapply(xx, function(x) paste(attr(xx, "region.id")[x], collapse = ", "))
>
> Here the IDs are 0-based rather than 1-based, but the attr(xx, "region.id")
> values are arbitrary - they are taken from row.names() of the spatial
> object unless given as an argument to functions creating the "nb" object.
>
> Hope this clarifies,
>
> Roger
>
>
>
>> Yours sincerely / Med venlig hilsen
>>
>>
>> Frede Aakmann T?gersen
>> Specialist, M.Sc., Ph.D.
>> Plant Performance & Modeling
>>
>> Technology & Service Solutions
>> T +45 9730 5135
>> M +45 2547 6050
>> frtog at vestas.com
>> http://www.vestas.com
>>
>> Company reg. name: Vestas Wind Systems A/S
>> This e-mail is subject to our e-mail disclaimer statement.
>> Please refer to www.vestas.com/legal/notice
>> If you have received this e-mail in error please contact the sender.
>>
>>
>>  -----Original Message-----
>>> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
>>> project.org] On Behalf Of Kenny Bell
>>> Sent: 29. september 2014 00:10
>>> To: r-sig-geo at r-project.org
>>> Subject: [R-sig-Geo] Accessing the ids of neighbours in spdep
>>>
>>> Hi,
>>>
>>> I am trying to get an actual list of neighbour ids out of an nb object.
>>> For
>>> example, I have
>>>
>>> library(spdep)
>>> example(columbus)
>>> xx <- poly2nb(columbus)
>>>
>>> What would be my command to get the list of neighbours as a list of
>>> character vectors?
>>>
>>> Thanks so much for any help,
>>> Kenny
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>



-- 
Kendon Bell
Email: kmb56 at berkeley.edu
Phone: (510) 612-3375

Ph.D. Student
Department of Agricultural & Resource Economics
University of California, Berkeley

Graduate Student Researcher
Energy Biosciences Institute
http://www.energybiosciencesinstitute.org/

	[[alternative HTML version deleted]]


From st_john_brown at yahoo.com  Tue Sep 30 03:04:08 2014
From: st_john_brown at yahoo.com (St John Brown)
Date: Mon, 29 Sep 2014 18:04:08 -0700
Subject: [R-sig-Geo] Calculating distance to nest with spDistsN1
In-Reply-To: <54293719.3010302@gmx.de>
References: <54293719.3010302@gmx.de>
Message-ID: <1412039048.73741.YahooMailNeo@web122404.mail.ne1.yahoo.com>

Anna-Marie,

If you look at the documentation for spDistsN1 (i.e. run "?spDistsN1"), you will see that the second argument is suppose to be a single 2D point, and not many 2D points. As per the documentation descripttion, "the function returns a vector of distances between a matrix of 2D points ... and a single 2D point."

I am not 100% sure I understand what you are trying to do, but I think what you are looking for is the spDists function. Compare the results of my output from using spDistsN1 versus spDists.

I hope this helps.

St. John

make_locations = function(n){
  lon = runif(n=n,min=7,max=8)
  lat = runif(n=n,min=50,max=60)
  locations = matrix(append(lon, lat), nrow=n, ncol=2)
  colnames(locations) = c("lon", "lat")
  rownames(locations) = 1:n
  return(locations)
}

set.seed(1)
flight_locations = make_locations(n=3)
nest_locations = make_locations(n=3)

flight_locations
nest_locations

spDistsN1(flight_locations, nest_locations[1,], longlat=T)
spDists(flight_locations, nest_locations, longlat=T)


On Monday, September 29, 2014 5:47 AM, Anna-Marie Corman <annajess at gmx.de> wrote:



Dear list,

I have a question regarding the spDistsN1 function. I want to calculate 
the distance of each flight position to the relevant nest position. My 
dataset consists of several birds with a differing number of trips. 
There is a unique trip_id with the first number regarding to the bird 
and the second number regarding to the trip.

          coordinates       Date     Time Speed Direction col_lat col_long dist_col
1 (7.87248, 54.1866) 04.07.2014 09:25:00  0.02    314.57 54.1866   7.8724      0.0
2 (7.87148, 54.1869) 04.07.2014 09:30:00 19.11      1.31 54.1866   7.8724      0.1
3  (7.87166, 54.185) 04.07.2014 09:35:00 14.98    224.79 54.1866   7.8724      0.2
4 (7.88635, 54.1569) 04.07.2014 09:40:00 11.44    136.97 54.1866   7.8724      3.4
5 (7.92096, 54.1363) 04.07.2014 09:45:00  0.28    262.14 54.1866   7.8724      6.4
6  (7.91931, 54.136) 04.07.2014 09:50:00  0.42    218.89 54.1866   7.8724      6.4
   trip_no bird_id trip_id                  DT           date_time
1       1       1     1.1 04.07.2014 09:25:00 2014-07-04 09:25:00
2       1       1     1.1 04.07.2014 09:30:00 2014-07-04 09:30:00
3       1       1     1.1 04.07.2014 09:35:00 2014-07-04 09:35:00
4       1       1     1.1 04.07.2014 09:40:00 2014-07-04 09:40:00
5       1       1     1.1 04.07.2014 09:45:00 2014-07-04 09:45:00
6       1       1     1.1 04.07.2014 09:50:00 2014-07-04 09:50:00



Formerly, when I only had one bird and so only one nest position (here 
col_lat & col_long), I did the following:

spDistsN1(coordinates(dat at coords), matrix(c(8.3495235,54.7042698), nrow 
= 1), longlat = T)

and this worked fine.

But now I want to calculate the distance from nest for each bird 
simultaneously. Must be simple, but I do not get it. I thought I could 
simply use

spDistsN1(coordinates(dat at coords), matrix(c(dat$col_long,dat$col_lat), 
nrow = 1), longlat = T)

instead, but it does not work.

Do you have any idea how to solve the "problem"?

Thanks a lot in advance.

Best,
Anna

    [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From frtog at vestas.com  Tue Sep 30 08:18:12 2014
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 30 Sep 2014 08:18:12 +0200
Subject: [R-sig-Geo] Calculating distance to nest with spDistsN1
In-Reply-To: <1412039048.73741.YahooMailNeo@web122404.mail.ne1.yahoo.com>
References: <54293719.3010302@gmx.de>
	<1412039048.73741.YahooMailNeo@web122404.mail.ne1.yahoo.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857C7E76E95@DKRDSEXC016.vestas.net>

Hi

Using spDists  will also give Anna-Maria the distance between a bird's nest and the endpoints of another birds trips.

Here is a way to achieve what I think Anna-Maria wants. Working with a SpatialPointsDataFrame objects complicates things so I will show how to it with an ordinary data.frame. Also I think that Anna-Maria has coded the trip_no, bird_id, and trip_id variables in a wrong way (see how I think the data should look below).

My assumptions:

1. The coordinates(dat) is the coordinates of end of trips
2. col_lat and col_long is the coordinates of nests
3. My example has two birds with id 1 and 2
4. Bird 1 has 4 trips with id 1,2,3,4 and bird 2 has 3 trips with id 1,2,3

## Here is a somewhat altered version of Anna-Maria's data:
dat <- read.table(text = 
"lon lat Date Time Speed Direction col_lat col_long dist_col trip_no bird_id trip_id DT date_time
7.87248 54.1866 '04.07.2014' '09:25:00' 0.02 314.57 54.1866 7.8724 0.0 1 1 1.1 '04.07.2014 09:25:00' '2014-07-04 09:25:00'
7.87148 54.1869 '04.07.2014' '09:30:00' 19.11 1.31 54.1866 7.8724 0.1 2 1 2.1 '04.07.2014 09:30:00' '2014-07-04 09:30:00'
7.87166 54.1850 '04.07.2014' '09:35:00' 14.98 224.79 54.1866 7.8724 0.2 3 1 3.1 '04.07.2014 09:35:00' '2014-07-04 09:35:00'
7.87168 54.1851 '04.07.2014' '09:35:00' 14.98 224.79 54.1866 7.8724 0.2 4 1 4.1 '04.07.2014 09:35:00' '2014-07-04 09:35:00'
7.88635 54.1569 '04.07.2014' '09:40:00' 11.44 136.97 54.2 7.9 3.4 1 2 1.2 '04.07.2014 09:40:00' '2014-07-04 09:40:00'
7.92096 54.1363 '04.07.2014' '09:45:00' 0.28 262.14 54.2 7.9 6.4 2 2 2.2 '04.07.2014 09:45:00' '2014-07-04 09:45:00'
7.91931 54.1360 '04.07.2014' '09:50:00' 0.42 218.89 54.2 7.9 6.4 3 2 3.2 '04.07.2014 09:50:00' '2014-07-04 09:50:00'",
                  h = TRUE, sep = " ")

## Now for each bird nest find the distances in km to end point of each birds trips:
trip_distances <- sapply(unique(dat$bird_id), function(id)
    spDistsN1(as.matrix(subset(dat, bird_id == id , select = c("lon", "lat"))),
              as.matrix(subset(dat, bird_id == id, select = c("col_long", "col_lat"))[1,]), longlat=T))

## have a look at the result
print(trip_distances)

## unlist the trip_distances and add that as a column to dat. The order of the unlist should match the row order of dat.
dat$trip_distances  <- unlist(trip_distances)

## print dat
print(dat)

Hope that is what Anna-Maria really wants.

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> project.org] On Behalf Of St John Brown
> Sent: 30. september 2014 03:04
> To: Anna-Marie Corman; R-sig-Geo at r-project.org
> Subject: Re: [R-sig-Geo] Calculating distance to nest with spDistsN1
> 
> Anna-Marie,
> 
> If you look at the documentation for spDistsN1 (i.e. run "?spDistsN1"), you
> will see that the second argument is suppose to be a single 2D point, and not
> many 2D points. As per the documentation descripttion, "the function
> returns a vector of distances between a matrix of 2D points ... and a single 2D
> point."
> 
> I am not 100% sure I understand what you are trying to do, but I think what
> you are looking for is the spDists function. Compare the results of my output
> from using spDistsN1 versus spDists.
> 
> I hope this helps.
> 
> St. John
> 
> make_locations = function(n){
>   lon = runif(n=n,min=7,max=8)
>   lat = runif(n=n,min=50,max=60)
>   locations = matrix(append(lon, lat), nrow=n, ncol=2)
>   colnames(locations) = c("lon", "lat")
>   rownames(locations) = 1:n
>   return(locations)
> }
> 
> set.seed(1)
> flight_locations = make_locations(n=3)
> nest_locations = make_locations(n=3)
> 
> flight_locations
> nest_locations
> 
> spDistsN1(flight_locations, nest_locations[1,], longlat=T)
> spDists(flight_locations, nest_locations, longlat=T)
> 
> 
> On Monday, September 29, 2014 5:47 AM, Anna-Marie Corman
> <annajess at gmx.de> wrote:
> 
> 
> 
> Dear list,
> 
> I have a question regarding the spDistsN1 function. I want to calculate
> the distance of each flight position to the relevant nest position. My
> dataset consists of several birds with a differing number of trips.
> There is a unique trip_id with the first number regarding to the bird
> and the second number regarding to the trip.
> 
>           coordinates       Date     Time Speed Direction col_lat col_long dist_col
> 1 (7.87248, 54.1866) 04.07.2014 09:25:00  0.02    314.57 54.1866   7.8724      0.0
> 2 (7.87148, 54.1869) 04.07.2014 09:30:00 19.11      1.31 54.1866   7.8724      0.1
> 3  (7.87166, 54.185) 04.07.2014 09:35:00 14.98    224.79 54.1866   7.8724      0.2
> 4 (7.88635, 54.1569) 04.07.2014 09:40:00 11.44    136.97 54.1866   7.8724      3.4
> 5 (7.92096, 54.1363) 04.07.2014 09:45:00  0.28    262.14 54.1866   7.8724      6.4
> 6  (7.91931, 54.136) 04.07.2014 09:50:00  0.42    218.89 54.1866   7.8724      6.4
>    trip_no bird_id trip_id                  DT           date_time
> 1       1       1     1.1 04.07.2014 09:25:00 2014-07-04 09:25:00
> 2       1       1     1.1 04.07.2014 09:30:00 2014-07-04 09:30:00
> 3       1       1     1.1 04.07.2014 09:35:00 2014-07-04 09:35:00
> 4       1       1     1.1 04.07.2014 09:40:00 2014-07-04 09:40:00
> 5       1       1     1.1 04.07.2014 09:45:00 2014-07-04 09:45:00
> 6       1       1     1.1 04.07.2014 09:50:00 2014-07-04 09:50:00
> 
> 
> 
> Formerly, when I only had one bird and so only one nest position (here
> col_lat & col_long), I did the following:
> 
> spDistsN1(coordinates(dat at coords), matrix(c(8.3495235,54.7042698), nrow
> = 1), longlat = T)
> 
> and this worked fine.
> 
> But now I want to calculate the distance from nest for each bird
> simultaneously. Must be simple, but I do not get it. I thought I could
> simply use
> 
> spDistsN1(coordinates(dat at coords), matrix(c(dat$col_long,dat$col_lat),
> nrow = 1), longlat = T)
> 
> instead, but it does not work.
> 
> Do you have any idea how to solve the "problem"?
> 
> Thanks a lot in advance.
> 
> Best,
> Anna
> 
>     [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Tue Sep 30 08:38:22 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 30 Sep 2014 08:38:22 +0200
Subject: [R-sig-Geo] Calculating distance to nest with spDistsN1
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C7E76E95@DKRDSEXC016.vestas.net>
References: <54293719.3010302@gmx.de>
	<1412039048.73741.YahooMailNeo@web122404.mail.ne1.yahoo.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C7E76E95@DKRDSEXC016.vestas.net>
Message-ID: <alpine.LRH.2.03.1409300826210.29661@reclus.nhh.no>

On Tue, 30 Sep 2014, Frede Aakmann T?gersen wrote:

> Hi
>
> Using spDists will also give Anna-Maria the distance between a bird's 
> nest and the endpoints of another birds trips.
>
> Here is a way to achieve what I think Anna-Maria wants. Working with a 
> SpatialPointsDataFrame objects complicates things so I will show how to 
> it with an ordinary data.frame. Also I think that Anna-Maria has coded 
> the trip_no, bird_id, and trip_id variables in a wrong way (see how I 
> think the data should look below).

Right, the representation in SpatialPointsDataFrame objects is not ideal 
for this kind of data.

I suggest looking at the new trajectories package on CRAN, which has a 
vignette explaining the new classes defined there, and which seem to 
match the birds well.

It is very possible that the authors of the package could provide a method 
for this kind of distance calculation (between trajectories and points). 
In addition, given the restricted extent of the data, it would almost 
certainly be of advantage to project to the plane, then using measures in 
m.

Roger

>
> My assumptions:
>
> 1. The coordinates(dat) is the coordinates of end of trips
> 2. col_lat and col_long is the coordinates of nests
> 3. My example has two birds with id 1 and 2
> 4. Bird 1 has 4 trips with id 1,2,3,4 and bird 2 has 3 trips with id 1,2,3
>
> ## Here is a somewhat altered version of Anna-Maria's data:
> dat <- read.table(text =
> "lon lat Date Time Speed Direction col_lat col_long dist_col trip_no bird_id trip_id DT date_time
> 7.87248 54.1866 '04.07.2014' '09:25:00' 0.02 314.57 54.1866 7.8724 0.0 1 1 1.1 '04.07.2014 09:25:00' '2014-07-04 09:25:00'
> 7.87148 54.1869 '04.07.2014' '09:30:00' 19.11 1.31 54.1866 7.8724 0.1 2 1 2.1 '04.07.2014 09:30:00' '2014-07-04 09:30:00'
> 7.87166 54.1850 '04.07.2014' '09:35:00' 14.98 224.79 54.1866 7.8724 0.2 3 1 3.1 '04.07.2014 09:35:00' '2014-07-04 09:35:00'
> 7.87168 54.1851 '04.07.2014' '09:35:00' 14.98 224.79 54.1866 7.8724 0.2 4 1 4.1 '04.07.2014 09:35:00' '2014-07-04 09:35:00'
> 7.88635 54.1569 '04.07.2014' '09:40:00' 11.44 136.97 54.2 7.9 3.4 1 2 1.2 '04.07.2014 09:40:00' '2014-07-04 09:40:00'
> 7.92096 54.1363 '04.07.2014' '09:45:00' 0.28 262.14 54.2 7.9 6.4 2 2 2.2 '04.07.2014 09:45:00' '2014-07-04 09:45:00'
> 7.91931 54.1360 '04.07.2014' '09:50:00' 0.42 218.89 54.2 7.9 6.4 3 2 3.2 '04.07.2014 09:50:00' '2014-07-04 09:50:00'",
>                  h = TRUE, sep = " ")
>
> ## Now for each bird nest find the distances in km to end point of each birds trips:
> trip_distances <- sapply(unique(dat$bird_id), function(id)
>    spDistsN1(as.matrix(subset(dat, bird_id == id , select = c("lon", "lat"))),
>              as.matrix(subset(dat, bird_id == id, select = c("col_long", "col_lat"))[1,]), longlat=T))
>
> ## have a look at the result
> print(trip_distances)
>
> ## unlist the trip_distances and add that as a column to dat. The order of the unlist should match the row order of dat.
> dat$trip_distances  <- unlist(trip_distances)
>
> ## print dat
> print(dat)
>
> Hope that is what Anna-Maria really wants.
>
> Yours sincerely / Med venlig hilsen
>
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>
>> -----Original Message-----
>> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
>> project.org] On Behalf Of St John Brown
>> Sent: 30. september 2014 03:04
>> To: Anna-Marie Corman; R-sig-Geo at r-project.org
>> Subject: Re: [R-sig-Geo] Calculating distance to nest with spDistsN1
>>
>> Anna-Marie,
>>
>> If you look at the documentation for spDistsN1 (i.e. run "?spDistsN1"), you
>> will see that the second argument is suppose to be a single 2D point, and not
>> many 2D points. As per the documentation descripttion, "the function
>> returns a vector of distances between a matrix of 2D points ... and a single 2D
>> point."
>>
>> I am not 100% sure I understand what you are trying to do, but I think what
>> you are looking for is the spDists function. Compare the results of my output
>> from using spDistsN1 versus spDists.
>>
>> I hope this helps.
>>
>> St. John
>>
>> make_locations = function(n){
>>   lon = runif(n=n,min=7,max=8)
>>   lat = runif(n=n,min=50,max=60)
>>   locations = matrix(append(lon, lat), nrow=n, ncol=2)
>>   colnames(locations) = c("lon", "lat")
>>   rownames(locations) = 1:n
>>   return(locations)
>> }
>>
>> set.seed(1)
>> flight_locations = make_locations(n=3)
>> nest_locations = make_locations(n=3)
>>
>> flight_locations
>> nest_locations
>>
>> spDistsN1(flight_locations, nest_locations[1,], longlat=T)
>> spDists(flight_locations, nest_locations, longlat=T)
>>
>>
>> On Monday, September 29, 2014 5:47 AM, Anna-Marie Corman
>> <annajess at gmx.de> wrote:
>>
>>
>>
>> Dear list,
>>
>> I have a question regarding the spDistsN1 function. I want to calculate
>> the distance of each flight position to the relevant nest position. My
>> dataset consists of several birds with a differing number of trips.
>> There is a unique trip_id with the first number regarding to the bird
>> and the second number regarding to the trip.
>>
>>           coordinates       Date     Time Speed Direction col_lat col_long dist_col
>> 1 (7.87248, 54.1866) 04.07.2014 09:25:00  0.02    314.57 54.1866   7.8724      0.0
>> 2 (7.87148, 54.1869) 04.07.2014 09:30:00 19.11      1.31 54.1866   7.8724      0.1
>> 3  (7.87166, 54.185) 04.07.2014 09:35:00 14.98    224.79 54.1866   7.8724      0.2
>> 4 (7.88635, 54.1569) 04.07.2014 09:40:00 11.44    136.97 54.1866   7.8724      3.4
>> 5 (7.92096, 54.1363) 04.07.2014 09:45:00  0.28    262.14 54.1866   7.8724      6.4
>> 6  (7.91931, 54.136) 04.07.2014 09:50:00  0.42    218.89 54.1866   7.8724      6.4
>>    trip_no bird_id trip_id                  DT           date_time
>> 1       1       1     1.1 04.07.2014 09:25:00 2014-07-04 09:25:00
>> 2       1       1     1.1 04.07.2014 09:30:00 2014-07-04 09:30:00
>> 3       1       1     1.1 04.07.2014 09:35:00 2014-07-04 09:35:00
>> 4       1       1     1.1 04.07.2014 09:40:00 2014-07-04 09:40:00
>> 5       1       1     1.1 04.07.2014 09:45:00 2014-07-04 09:45:00
>> 6       1       1     1.1 04.07.2014 09:50:00 2014-07-04 09:50:00
>>
>>
>>
>> Formerly, when I only had one bird and so only one nest position (here
>> col_lat & col_long), I did the following:
>>
>> spDistsN1(coordinates(dat at coords), matrix(c(8.3495235,54.7042698), nrow
>> = 1), longlat = T)
>>
>> and this worked fine.
>>
>> But now I want to calculate the distance from nest for each bird
>> simultaneously. Must be simple, but I do not get it. I thought I could
>> simply use
>>
>> spDistsN1(coordinates(dat at coords), matrix(c(dat$col_long,dat$col_lat),
>> nrow = 1), longlat = T)
>>
>> instead, but it does not work.
>>
>> Do you have any idea how to solve the "problem"?
>>
>> Thanks a lot in advance.
>>
>> Best,
>> Anna
>>
>>     [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From annajess at gmx.de  Tue Sep 30 08:33:49 2014
From: annajess at gmx.de (Anna-Marie Corman)
Date: Tue, 30 Sep 2014 08:33:49 +0200
Subject: [R-sig-Geo] Calculating distance to nest with spDistsN1
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857C7E76E95@DKRDSEXC016.vestas.net>
References: <54293719.3010302@gmx.de>
	<1412039048.73741.YahooMailNeo@web122404.mail.ne1.yahoo.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C7E76E95@DKRDSEXC016.vestas.net>
Message-ID: <542A4ECD.7080404@gmx.de>

Dear St. John and Frede,

thanks a lot for your help. I think I made my question not clear enough 
and was confusing instead. Sorry for this.
The data are ordered: there are several birds and each bird has done a 
varying number of trips. The coordinates are the different positions of 
each bird's trip starting and ending at its nest. So, first, there is 
bird 1 with several prositions of trip 1, following several positions of 
trip 2 and so on. That is why I produced a new unique variable where 
trip no. and bird id are included so that there are no (timestamp) 
replicates. So the data set starts with trip_id 1.1 several times and 
then 1.2,  1.3 and so on.
Col_long and col_lat are the nest positions of each bird. I tried to 
calculate the distance of each GPS position during the trips 
(coordinates) to the corresponding nest of the relevant bird. So, I 
could do it with spDistsN1, but then I have to separate the different 
birds, i.e. use several datasets. But as this would take a lot of time, 
I would rather use one dataset with all birds included...

Here is a structure of my data:Formal class 'SpatialPointsDataFrame' 
[package "sp"] with 5 slots
   ..@ data       :'data.frame':    13099 obs. of  14 variables:
   .. ..$ Date     : Factor w/ 69 levels "01.08.2014","01.09.2014",..: 7 
7 7 7 7 7 7 7 7 7 ...
   .. ..$ Time     : Factor w/ 2391 levels " 03:00:35"," 03:00:44",..: 
2156 2157 2158 2160 2161 2162 2163 2165 2166 2168 ...
   .. ..$ Speed    : num [1:13099] 0.02 19.11 14.98 11.44 0.28 ...
   .. ..$ Direction: num [1:13099] 314.57 1.31 224.79 136.97 262.14 ...
   .. ..$ col_lat  : num [1:13099] 54.2 54.2 54.2 54.2 54.2 ...
   .. ..$ col_long : num [1:13099] 7.87 7.87 7.87 7.87 7.87 ...
   .. ..$ trip_no  : int [1:13099] 1 1 1 1 1 1 1 1 1 1 ...
   .. ..$ bird_id  : int [1:13099] 1 1 1 1 1 1 1 1 1 1 ...
   .. ..$ trip_id  : chr [1:13099] "1.1" "1.1" "1.1" "1.1" ...
   .. ..$ DT       : chr [1:13099] "04.07.2014 09:25:00" "04.07.2014 
09:30:00" "04.07.2014 09:35:00" "04.07.2014 09:40:00" ...
   .. ..$ date_time: POSIXct[1:13099], format: "2014-07-04 09:25:00" 
"2014-07-04 09:30:00" "2014-07-04 09:35:00" ...
   .. ..$ dist     : num [1:13099] 0 0.0726 0.2122 3.2709 3.2187 ...
   .. ..$ speed    : num [1:13099] 0 0.871 2.547 39.25 38.625 ...
   ..@ coords.nrs : int [1:2] 4 3
   ..@ coords     : num [1:13099, 1:2] 7.87 7.87 7.87 7.89 7.92 ...
   .. ..- attr(*, "dimnames")=List of 2
   .. .. ..$ : NULL
   .. .. ..$ : chr [1:2] "Long" "Lat"
   ..@ bbox       : num [1:2, 1:2] 5.36 53.71 8.57 57.01
   .. ..- attr(*, "dimnames")=List of 2
   .. .. ..$ : chr [1:2] "Long" "Lat"
   .. .. ..$ : chr [1:2] "min" "max"
   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
   .. .. ..@ projargs: chr NA

I will try St. John's solution out... Maybe it is also possible with a 
loop: dat$home <- spDistsN1(coordinates(dat at coords), 
matrix(c(dat$col_long[i],dat$col_lat[i]), nrow = 1), longlat = T)
but I'm not really sure which for argument to use then...

Thanks a lot again.

Best wishes,
Anna

Am 30.09.2014 08:18, schrieb Frede Aakmann T?gersen:
> Hi
>
> Using spDists  will also give Anna-Maria the distance between a bird's nest and the endpoints of another birds trips.
>
> Here is a way to achieve what I think Anna-Maria wants. Working with a SpatialPointsDataFrame objects complicates things so I will show how to it with an ordinary data.frame. Also I think that Anna-Maria has coded the trip_no, bird_id, and trip_id variables in a wrong way (see how I think the data should look below).
>
> My assumptions:
>
> 1. The coordinates(dat) is the coordinates of end of trips
> 2. col_lat and col_long is the coordinates of nests
> 3. My example has two birds with id 1 and 2
> 4. Bird 1 has 4 trips with id 1,2,3,4 and bird 2 has 3 trips with id 1,2,3
>
> ## Here is a somewhat altered version of Anna-Maria's data:
> dat <- read.table(text =
> "lon lat Date Time Speed Direction col_lat col_long dist_col trip_no bird_id trip_id DT date_time
> 7.87248 54.1866 '04.07.2014' '09:25:00' 0.02 314.57 54.1866 7.8724 0.0 1 1 1.1 '04.07.2014 09:25:00' '2014-07-04 09:25:00'
> 7.87148 54.1869 '04.07.2014' '09:30:00' 19.11 1.31 54.1866 7.8724 0.1 2 1 2.1 '04.07.2014 09:30:00' '2014-07-04 09:30:00'
> 7.87166 54.1850 '04.07.2014' '09:35:00' 14.98 224.79 54.1866 7.8724 0.2 3 1 3.1 '04.07.2014 09:35:00' '2014-07-04 09:35:00'
> 7.87168 54.1851 '04.07.2014' '09:35:00' 14.98 224.79 54.1866 7.8724 0.2 4 1 4.1 '04.07.2014 09:35:00' '2014-07-04 09:35:00'
> 7.88635 54.1569 '04.07.2014' '09:40:00' 11.44 136.97 54.2 7.9 3.4 1 2 1.2 '04.07.2014 09:40:00' '2014-07-04 09:40:00'
> 7.92096 54.1363 '04.07.2014' '09:45:00' 0.28 262.14 54.2 7.9 6.4 2 2 2.2 '04.07.2014 09:45:00' '2014-07-04 09:45:00'
> 7.91931 54.1360 '04.07.2014' '09:50:00' 0.42 218.89 54.2 7.9 6.4 3 2 3.2 '04.07.2014 09:50:00' '2014-07-04 09:50:00'",
>                    h = TRUE, sep = " ")
>
> ## Now for each bird nest find the distances in km to end point of each birds trips:
> trip_distances <- sapply(unique(dat$bird_id), function(id)
>      spDistsN1(as.matrix(subset(dat, bird_id == id , select = c("lon", "lat"))),
>                as.matrix(subset(dat, bird_id == id, select = c("col_long", "col_lat"))[1,]), longlat=T))
>
> ## have a look at the result
> print(trip_distances)
>
> ## unlist the trip_distances and add that as a column to dat. The order of the unlist should match the row order of dat.
> dat$trip_distances  <- unlist(trip_distances)
>
> ## print dat
> print(dat)
>
> Hope that is what Anna-Maria really wants.
>
> Yours sincerely / Med venlig hilsen
>
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>
>> -----Original Message-----
>> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
>> project.org] On Behalf Of St John Brown
>> Sent: 30. september 2014 03:04
>> To: Anna-Marie Corman; R-sig-Geo at r-project.org
>> Subject: Re: [R-sig-Geo] Calculating distance to nest with spDistsN1
>>
>> Anna-Marie,
>>
>> If you look at the documentation for spDistsN1 (i.e. run "?spDistsN1"), you
>> will see that the second argument is suppose to be a single 2D point, and not
>> many 2D points. As per the documentation descripttion, "the function
>> returns a vector of distances between a matrix of 2D points ... and a single 2D
>> point."
>>
>> I am not 100% sure I understand what you are trying to do, but I think what
>> you are looking for is the spDists function. Compare the results of my output
>> from using spDistsN1 versus spDists.
>>
>> I hope this helps.
>>
>> St. John
>>
>> make_locations = function(n){
>>    lon = runif(n=n,min=7,max=8)
>>    lat = runif(n=n,min=50,max=60)
>>    locations = matrix(append(lon, lat), nrow=n, ncol=2)
>>    colnames(locations) = c("lon", "lat")
>>    rownames(locations) = 1:n
>>    return(locations)
>> }
>>
>> set.seed(1)
>> flight_locations = make_locations(n=3)
>> nest_locations = make_locations(n=3)
>>
>> flight_locations
>> nest_locations
>>
>> spDistsN1(flight_locations, nest_locations[1,], longlat=T)
>> spDists(flight_locations, nest_locations, longlat=T)
>>
>>
>> On Monday, September 29, 2014 5:47 AM, Anna-Marie Corman
>> <annajess at gmx.de> wrote:
>>
>>
>>
>>


	[[alternative HTML version deleted]]


From swagathnavin82 at gmail.com  Tue Sep 30 08:51:41 2014
From: swagathnavin82 at gmail.com (Swagath Navin Manohar)
Date: Tue, 30 Sep 2014 12:21:41 +0530
Subject: [R-sig-Geo] Re-projection with project raster results in rotated
	plot
Message-ID: <542A52FD.4000302@gmail.com>

Hello all,

I have a problem concerning re-projecting a raster from EPSG:3035 to 
sr-org: 29, wrf-lambert-conformal-conic which results in a rotated plot.

Here is the code I used:

raster1=rasterFromXYZ(radon[, c("x", "y", "rn")])

####http://spatialreference.org/ref/epsg/3035/proj4/

crs(raster1)='+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 
+ellps=GRS80 +units=m +no_defs'

####to this new projection
########http://spatialreference.org/ref/sr-org/wrf-lambert-conformal-conic/

newproj <- "+proj=lcc +lat_1=33 +lat_2=45 +lat_0=40 +lon_0=-97 +x_0=0 
+y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"

raster2 <- projectRaster(raster2, crs=newproj, res=5000, method='bilinear')

Here is the output: http://s7.postimg.org/g8adezsdn/Page_1_rasters.jpg

I hope someone can give me a hint about what I am doing wrong here.
Thanks a lot for your time.
Navin


From r.hijmans at gmail.com  Tue Sep 30 18:16:02 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 30 Sep 2014 09:16:02 -0700
Subject: [R-sig-Geo] Calculating distance to nest with spDistsN1
In-Reply-To: <542A4ECD.7080404@gmx.de>
References: <54293719.3010302@gmx.de>
	<1412039048.73741.YahooMailNeo@web122404.mail.ne1.yahoo.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857C7E76E95@DKRDSEXC016.vestas.net>
	<542A4ECD.7080404@gmx.de>
Message-ID: <CANtt_hydhoEMR+Q0eNbzYr3mqCp0kv2rLJ+1kfp-su9j08bNEA@mail.gmail.com>

Anna-Marie,

If I (and Frede) understand the problem, then you can use the
raster::pointDistance function or similar functions in the geosphere
package.

dat <- read.table(text =
"lon lat Date Time Speed Direction col_lat col_long dist_col trip_no
bird_id trip_id DT date_time
7.87248 54.1866 '04.07.2014' '09:25:00' 0.02 314.57 54.1866 7.8724 0.0
1 1 1.1 '04.07.2014 09:25:00' '2014-07-04 09:25:00'
7.87148 54.1869 '04.07.2014' '09:30:00' 19.11 1.31 54.1866 7.8724 0.1
2 1 2.1 '04.07.2014 09:30:00' '2014-07-04 09:30:00'
7.87166 54.1850 '04.07.2014' '09:35:00' 14.98 224.79 54.1866 7.8724
0.2 3 1 3.1 '04.07.2014 09:35:00' '2014-07-04 09:35:00'
7.87168 54.1851 '04.07.2014' '09:35:00' 14.98 224.79 54.1866 7.8724
0.2 4 1 4.1 '04.07.2014 09:35:00' '2014-07-04 09:35:00'
7.88635 54.1569 '04.07.2014' '09:40:00' 11.44 136.97 54.2 7.9 3.4 1 2
1.2 '04.07.2014 09:40:00' '2014-07-04 09:40:00'
7.92096 54.1363 '04.07.2014' '09:45:00' 0.28 262.14 54.2 7.9 6.4 2 2
2.2 '04.07.2014 09:45:00' '2014-07-04 09:45:00'
7.91931 54.1360 '04.07.2014' '09:50:00' 0.42 218.89 54.2 7.9 6.4 3 2
3.2 '04.07.2014 09:50:00' '2014-07-04 09:50:00'",
                  h = TRUE, sep = " ")


library(raster)
dat$distance <- pointDistance(dat[, c('lon', 'lat')], dat[,
c('col_long', 'col_lat')], lonlat=TRUE)
dat


Robert

On Mon, Sep 29, 2014 at 11:33 PM, Anna-Marie Corman <annajess at gmx.de> wrote:
> Dear St. John and Frede,
>
> thanks a lot for your help. I think I made my question not clear enough
> and was confusing instead. Sorry for this.
> The data are ordered: there are several birds and each bird has done a
> varying number of trips. The coordinates are the different positions of
> each bird's trip starting and ending at its nest. So, first, there is
> bird 1 with several prositions of trip 1, following several positions of
> trip 2 and so on. That is why I produced a new unique variable where
> trip no. and bird id are included so that there are no (timestamp)
> replicates. So the data set starts with trip_id 1.1 several times and
> then 1.2,  1.3 and so on.
> Col_long and col_lat are the nest positions of each bird. I tried to
> calculate the distance of each GPS position during the trips
> (coordinates) to the corresponding nest of the relevant bird. So, I
> could do it with spDistsN1, but then I have to separate the different
> birds, i.e. use several datasets. But as this would take a lot of time,
> I would rather use one dataset with all birds included...
>
> Here is a structure of my data:Formal class 'SpatialPointsDataFrame'
> [package "sp"] with 5 slots
>    ..@ data       :'data.frame':    13099 obs. of  14 variables:
>    .. ..$ Date     : Factor w/ 69 levels "01.08.2014","01.09.2014",..: 7
> 7 7 7 7 7 7 7 7 7 ...
>    .. ..$ Time     : Factor w/ 2391 levels " 03:00:35"," 03:00:44",..:
> 2156 2157 2158 2160 2161 2162 2163 2165 2166 2168 ...
>    .. ..$ Speed    : num [1:13099] 0.02 19.11 14.98 11.44 0.28 ...
>    .. ..$ Direction: num [1:13099] 314.57 1.31 224.79 136.97 262.14 ...
>    .. ..$ col_lat  : num [1:13099] 54.2 54.2 54.2 54.2 54.2 ...
>    .. ..$ col_long : num [1:13099] 7.87 7.87 7.87 7.87 7.87 ...
>    .. ..$ trip_no  : int [1:13099] 1 1 1 1 1 1 1 1 1 1 ...
>    .. ..$ bird_id  : int [1:13099] 1 1 1 1 1 1 1 1 1 1 ...
>    .. ..$ trip_id  : chr [1:13099] "1.1" "1.1" "1.1" "1.1" ...
>    .. ..$ DT       : chr [1:13099] "04.07.2014 09:25:00" "04.07.2014
> 09:30:00" "04.07.2014 09:35:00" "04.07.2014 09:40:00" ...
>    .. ..$ date_time: POSIXct[1:13099], format: "2014-07-04 09:25:00"
> "2014-07-04 09:30:00" "2014-07-04 09:35:00" ...
>    .. ..$ dist     : num [1:13099] 0 0.0726 0.2122 3.2709 3.2187 ...
>    .. ..$ speed    : num [1:13099] 0 0.871 2.547 39.25 38.625 ...
>    ..@ coords.nrs : int [1:2] 4 3
>    ..@ coords     : num [1:13099, 1:2] 7.87 7.87 7.87 7.89 7.92 ...
>    .. ..- attr(*, "dimnames")=List of 2
>    .. .. ..$ : NULL
>    .. .. ..$ : chr [1:2] "Long" "Lat"
>    ..@ bbox       : num [1:2, 1:2] 5.36 53.71 8.57 57.01
>    .. ..- attr(*, "dimnames")=List of 2
>    .. .. ..$ : chr [1:2] "Long" "Lat"
>    .. .. ..$ : chr [1:2] "min" "max"
>    ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>    .. .. ..@ projargs: chr NA
>
> I will try St. John's solution out... Maybe it is also possible with a
> loop: dat$home <- spDistsN1(coordinates(dat at coords),
> matrix(c(dat$col_long[i],dat$col_lat[i]), nrow = 1), longlat = T)
> but I'm not really sure which for argument to use then...
>
> Thanks a lot again.
>
> Best wishes,
> Anna
>
> Am 30.09.2014 08:18, schrieb Frede Aakmann T?gersen:
>> Hi
>>
>> Using spDists  will also give Anna-Maria the distance between a bird's nest and the endpoints of another birds trips.
>>
>> Here is a way to achieve what I think Anna-Maria wants. Working with a SpatialPointsDataFrame objects complicates things so I will show how to it with an ordinary data.frame. Also I think that Anna-Maria has coded the trip_no, bird_id, and trip_id variables in a wrong way (see how I think the data should look below).
>>
>> My assumptions:
>>
>> 1. The coordinates(dat) is the coordinates of end of trips
>> 2. col_lat and col_long is the coordinates of nests
>> 3. My example has two birds with id 1 and 2
>> 4. Bird 1 has 4 trips with id 1,2,3,4 and bird 2 has 3 trips with id 1,2,3
>>
>> ## Here is a somewhat altered version of Anna-Maria's data:
>> dat <- read.table(text =
>> "lon lat Date Time Speed Direction col_lat col_long dist_col trip_no bird_id trip_id DT date_time
>> 7.87248 54.1866 '04.07.2014' '09:25:00' 0.02 314.57 54.1866 7.8724 0.0 1 1 1.1 '04.07.2014 09:25:00' '2014-07-04 09:25:00'
>> 7.87148 54.1869 '04.07.2014' '09:30:00' 19.11 1.31 54.1866 7.8724 0.1 2 1 2.1 '04.07.2014 09:30:00' '2014-07-04 09:30:00'
>> 7.87166 54.1850 '04.07.2014' '09:35:00' 14.98 224.79 54.1866 7.8724 0.2 3 1 3.1 '04.07.2014 09:35:00' '2014-07-04 09:35:00'
>> 7.87168 54.1851 '04.07.2014' '09:35:00' 14.98 224.79 54.1866 7.8724 0.2 4 1 4.1 '04.07.2014 09:35:00' '2014-07-04 09:35:00'
>> 7.88635 54.1569 '04.07.2014' '09:40:00' 11.44 136.97 54.2 7.9 3.4 1 2 1.2 '04.07.2014 09:40:00' '2014-07-04 09:40:00'
>> 7.92096 54.1363 '04.07.2014' '09:45:00' 0.28 262.14 54.2 7.9 6.4 2 2 2.2 '04.07.2014 09:45:00' '2014-07-04 09:45:00'
>> 7.91931 54.1360 '04.07.2014' '09:50:00' 0.42 218.89 54.2 7.9 6.4 3 2 3.2 '04.07.2014 09:50:00' '2014-07-04 09:50:00'",
>>                    h = TRUE, sep = " ")
>>
>> ## Now for each bird nest find the distances in km to end point of each birds trips:
>> trip_distances <- sapply(unique(dat$bird_id), function(id)
>>      spDistsN1(as.matrix(subset(dat, bird_id == id , select = c("lon", "lat"))),
>>                as.matrix(subset(dat, bird_id == id, select = c("col_long", "col_lat"))[1,]), longlat=T))
>>
>> ## have a look at the result
>> print(trip_distances)
>>
>> ## unlist the trip_distances and add that as a column to dat. The order of the unlist should match the row order of dat.
>> dat$trip_distances  <- unlist(trip_distances)
>>
>> ## print dat
>> print(dat)
>>
>> Hope that is what Anna-Maria really wants.
>>
>> Yours sincerely / Med venlig hilsen
>>
>>
>> Frede Aakmann T?gersen
>> Specialist, M.Sc., Ph.D.
>> Plant Performance & Modeling
>>
>> Technology & Service Solutions
>> T +45 9730 5135
>> M +45 2547 6050
>> frtog at vestas.com
>> http://www.vestas.com
>>
>> Company reg. name: Vestas Wind Systems A/S
>> This e-mail is subject to our e-mail disclaimer statement.
>> Please refer to www.vestas.com/legal/notice
>> If you have received this e-mail in error please contact the sender.
>>
>>
>>> -----Original Message-----
>>> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
>>> project.org] On Behalf Of St John Brown
>>> Sent: 30. september 2014 03:04
>>> To: Anna-Marie Corman; R-sig-Geo at r-project.org
>>> Subject: Re: [R-sig-Geo] Calculating distance to nest with spDistsN1
>>>
>>> Anna-Marie,
>>>
>>> If you look at the documentation for spDistsN1 (i.e. run "?spDistsN1"), you
>>> will see that the second argument is suppose to be a single 2D point, and not
>>> many 2D points. As per the documentation descripttion, "the function
>>> returns a vector of distances between a matrix of 2D points ... and a single 2D
>>> point."
>>>
>>> I am not 100% sure I understand what you are trying to do, but I think what
>>> you are looking for is the spDists function. Compare the results of my output
>>> from using spDistsN1 versus spDists.
>>>
>>> I hope this helps.
>>>
>>> St. John
>>>
>>> make_locations = function(n){
>>>    lon = runif(n=n,min=7,max=8)
>>>    lat = runif(n=n,min=50,max=60)
>>>    locations = matrix(append(lon, lat), nrow=n, ncol=2)
>>>    colnames(locations) = c("lon", "lat")
>>>    rownames(locations) = 1:n
>>>    return(locations)
>>> }
>>>
>>> set.seed(1)
>>> flight_locations = make_locations(n=3)
>>> nest_locations = make_locations(n=3)
>>>
>>> flight_locations
>>> nest_locations
>>>
>>> spDistsN1(flight_locations, nest_locations[1,], longlat=T)
>>> spDists(flight_locations, nest_locations, longlat=T)
>>>
>>>
>>> On Monday, September 29, 2014 5:47 AM, Anna-Marie Corman
>>> <annajess at gmx.de> wrote:
>>>
>>>
>>>
>>>
>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From annajess at gmx.de  Tue Sep 30 20:10:01 2014
From: annajess at gmx.de (Anna-Marie Corman)
Date: Tue, 30 Sep 2014 20:10:01 +0200
Subject: [R-sig-Geo] Calculating distance to nest with spDistsN1
In-Reply-To: <CANtt_hydhoEMR+Q0eNbzYr3mqCp0kv2rLJ+1kfp-su9j08bNEA@mail.gmail.com>
References: <54293719.3010302@gmx.de>	<1412039048.73741.YahooMailNeo@web122404.mail.ne1.yahoo.com>	<B078CDF40DFE4045AF172A8B4F68FC4857C7E76E95@DKRDSEXC016.vestas.net>	<542A4ECD.7080404@gmx.de>
	<CANtt_hydhoEMR+Q0eNbzYr3mqCp0kv2rLJ+1kfp-su9j08bNEA@mail.gmail.com>
Message-ID: <542AF1F9.4020002@gmx.de>

Hi Robert,

thanks a lot. Your solution worked very well!!!

Best,
Anna

Am 30.09.2014 18:16, schrieb Robert J. Hijmans:
> Anna-Marie,
>
> If I (and Frede) understand the problem, then you can use the
> raster::pointDistance function or similar functions in the geosphere
> package.
>
> dat <- read.table(text =
> "lon lat Date Time Speed Direction col_lat col_long dist_col trip_no
> bird_id trip_id DT date_time
> 7.87248 54.1866 '04.07.2014' '09:25:00' 0.02 314.57 54.1866 7.8724 0.0
> 1 1 1.1 '04.07.2014 09:25:00' '2014-07-04 09:25:00'
> 7.87148 54.1869 '04.07.2014' '09:30:00' 19.11 1.31 54.1866 7.8724 0.1
> 2 1 2.1 '04.07.2014 09:30:00' '2014-07-04 09:30:00'
> 7.87166 54.1850 '04.07.2014' '09:35:00' 14.98 224.79 54.1866 7.8724
> 0.2 3 1 3.1 '04.07.2014 09:35:00' '2014-07-04 09:35:00'
> 7.87168 54.1851 '04.07.2014' '09:35:00' 14.98 224.79 54.1866 7.8724
> 0.2 4 1 4.1 '04.07.2014 09:35:00' '2014-07-04 09:35:00'
> 7.88635 54.1569 '04.07.2014' '09:40:00' 11.44 136.97 54.2 7.9 3.4 1 2
> 1.2 '04.07.2014 09:40:00' '2014-07-04 09:40:00'
> 7.92096 54.1363 '04.07.2014' '09:45:00' 0.28 262.14 54.2 7.9 6.4 2 2
> 2.2 '04.07.2014 09:45:00' '2014-07-04 09:45:00'
> 7.91931 54.1360 '04.07.2014' '09:50:00' 0.42 218.89 54.2 7.9 6.4 3 2
> 3.2 '04.07.2014 09:50:00' '2014-07-04 09:50:00'",
>                    h = TRUE, sep = " ")
>
>
> library(raster)
> dat$distance <- pointDistance(dat[, c('lon', 'lat')], dat[,
> c('col_long', 'col_lat')], lonlat=TRUE)
> dat
>
>
> Robert
>
>


From justiceaheto at yahoo.com  Tue Sep 30 21:40:27 2014
From: justiceaheto at yahoo.com (Justice Moses K. Aheto)
Date: Tue, 30 Sep 2014 12:40:27 -0700
Subject: [R-sig-Geo] Spatial and multilevel model with
	kriging/interpolation	in R
Message-ID: <1412106027.18783.YahooMailNeo@web120904.mail.ne1.yahoo.com>

Dear Frede,
Many thanks for all your help (papers and suggestions/ideas) and I am very grateful for this.
Yes, you are right, joint Gaussian distribution is best for my situation.  
I have had a look at INLA as you suggested and still exploring it to find out if I can figure out something from there and I will notify the list if I am successful regarding this hoping that it might help others too in the future.
Also, I have had a looked at geostatsp/geostatinla packages but it seems they are tailored towards fitting standard spatial regression models without considering random effects at other higher levels of the data (say children nested within households in which I wish to accommodate the household specific random effects in my analysis)
 
I am still reading more literature on this and I am looking forward to more suggestions too. 
Many thanks. 
 
Kind regards

*****************************************
Justice Moses K. Aheto
PhD Candidate in Medicine (United Kingdom)
MSc Medical Statistics (United Kingdom)
BSc Statistics (Ghana)
HND Statistics (Ghana)

Chief Executive Officer
Statistics and Analytics Consultancy Services Ltd.

Skype: jascall12
Mobile: +447417589148.
	[[alternative HTML version deleted]]


From paul.feichtinger at tum.de  Tue Sep 30 22:50:33 2014
From: paul.feichtinger at tum.de (Feichtinger, Paul)
Date: Tue, 30 Sep 2014 20:50:33 +0000
Subject: [R-sig-Geo] Specification tests in spatial models
Message-ID: <bf6b4e93ba284d11b9e8faa732ffc096@BADWLRZ-SW13MB1.ads.mwn.de>

Dear mailing list members,

we estimate a general spatial model to investigate the determinants of agricultural land prices. The functional form is a log-log specification. In testing we perform, among others, "spatial-tests" like Moran's I and LM tests. Our question is, are there any possibilities to test for misspecification  of the functional form (log-log) 1) which make sense in this circumstances and 2) which are available in R packages like sphet?

Any comments would be of great help!

Thank you,

Paul

---
Technische Universit?t M?nchen - TUM
Paul Feichtinger
Lehrstuhl f?r Volkswirtschaftslehre, Umwelt?konomie und Agrarpolitik

Alte Akademie 14
85354 Freising
Tel: +49.8161.71.3574
Fax: +49.8161.71.3408
e-mail: Paul.Feichtinger at tum.de


	[[alternative HTML version deleted]]


