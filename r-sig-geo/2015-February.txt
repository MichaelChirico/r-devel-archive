From y.gyasi-agyei at cqu.edu.au  Sun Feb  1 07:19:13 2015
From: y.gyasi-agyei at cqu.edu.au (Yeboah Gyasi-Agyei)
Date: Sun, 1 Feb 2015 06:19:13 +0000
Subject: [R-sig-Geo] help kriging using gstat and covariance table
Message-ID: <716a04dc11bd4dcc93151a450f588664@EXCH01.staff.ad.cqu.edu.au>

I would like to know whether R gstat package (or any other) can be set up for the following scenario.

1)            Kriging/Simulation of Gaussian random fields over 128x128 grids with values known at about 100 locations to be preserved - i.e. conditional simulation.
2)            The covariance is a matrix (in a tabular form) instead of a functional relationship. The table will be the same size as the grid 128x128, giving the correlation/covariance between each grid and the others and therefore symmetric.

Thanks for your advice/solution.

	[[alternative HTML version deleted]]


From panpan.2010 at qq.com  Mon Feb  2 06:54:53 2015
From: panpan.2010 at qq.com (silverlining)
Date: Sun, 1 Feb 2015 22:54:53 -0700 (MST)
Subject: [R-sig-Geo] input shapefile to build graph-using R
Message-ID: <1422856493453-7587718.post@n2.nabble.com>

When using igraph to do network analysis- computing closeness for road
network, I confront these problems. I am trying to input shapefile data(line
and vertex), the R code is as follows:
library(igraph)
library(maptools)
pl <-
readShapeLines("H:/data/Beijing_NatrualRoads.shp",proj4string=CRS("+proj=Mercator_Auxiliary_Sphere
+datum=WGS84"))
pt <-
readShapePoints("H:/data/Beijing_NatrualRoads_ND_Junctions.shp",proj4string=CRS("+proj=Mercator_Auxiliary_Sphere
+datum=WGS84"))

Then errors occurs when trying to build graph using function
"graph.data.frame":
> g <- graph.data.frame(pl, directed=FALSE, vertices=pt)
Error in graph.data.frame(pl, directed = FALSE, vertices = pt) :
  Duplicate vertex names
Warning:
In graph.data.frame(pl, directed = FALSE, vertices = pt) :
  In `d' `NA' elements were replaced with string "NA"

Could anyone help me to solve these problems, thank you very much.



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/input-shapefile-to-build-graph-using-R-tp7587718.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From panpan.2010 at qq.com  Mon Feb  2 09:32:18 2015
From: panpan.2010 at qq.com (silverlining)
Date: Mon, 2 Feb 2015 01:32:18 -0700 (MST)
Subject: [R-sig-Geo] input shapefile to build graph-using R
In-Reply-To: <1422856493453-7587718.post@n2.nabble.com>
References: <1422856493453-7587718.post@n2.nabble.com>
Message-ID: <1422865938486-7587719.post@n2.nabble.com>

> # Load libraries
> library(spdep)
> library(igraph)
> library(maptools)
> pl <- readShapeLines("H:/data/Beijing_NatrualRoads.shp",
+ proj4string=CRS("+proj=Mercator_Auxiliary_Sphere +datum=WGS84"))
> pt <- readShapePoints("H:/data/Beijing_NatrualRoads_computejunctions.shp",
+ proj4string=CRS("+proj=Mercator_Auxiliary_Sphere +datum=WGS84"))
> g <- graph.data.frame(pl, directed=TRUE, vertices=pt)
Error in graph.data.frame(pl, directed = TRUE, vertices = pt) : 
  Duplicate vertex names
In addition: Warning message:
In graph.data.frame(pl, directed = TRUE, vertices = pt) :
  In `d' `NA' elements were replaced with string "NA"
> cl<-closeness(g, mode = c("out"),weights = NULL, normalized = TRUE)
Error in match(x, table, nomatch = 0L) : object 'g' not found
> 
<http://r-sig-geo.2731867.n2.nabble.com/file/n7587719/R_error.jpg> 



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/input-shapefile-to-build-graph-using-R-tp7587718p7587719.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From frtog at vestas.com  Mon Feb  2 11:13:47 2015
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Mon, 2 Feb 2015 11:13:47 +0100
Subject: [R-sig-Geo] input shapefile to build graph-using R
In-Reply-To: <1422865938486-7587719.post@n2.nabble.com>
References: <1422856493453-7587718.post@n2.nabble.com>
	<1422865938486-7587719.post@n2.nabble.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857CBB1DC6B@DKRDSEXC016.vestas.net>

Dear "whoever you are"

You give way to little information in order to make us able help you. Just posting a jpg image of the error message already presented doesn't help either.

Posting the following will probably enable us to help you better.

1) Immediately after the error show the output from a call to traceback()
2) If not providing the data, then show calls to str() on the imported data, 'lt' and 'pt'
3) Provide the output from sessionInfo()

>From the error message:

> Error in graph.data.frame(pl, directed = TRUE, vertices = pt) :
>   Duplicate vertex names

it seems like the vertices in the pt object has not been named in an unique way since that is probably needed.

Also from the warning the error just above seems to be related to the namings of the vertices. More than one vertex was missing an ID:

> In addition: Warning message:
> In graph.data.frame(pl, directed = TRUE, vertices = pt) :
>   In `d' `NA' elements were replaced with string "NA"

graph.data.frame seems to convert factor vector to a vector of strings which in this case gives identical ids with names NA. 

By the way, on many email lists it would be seen courteously of you to provide you affiliation so people can see who they are dealing with.


Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of
> silverlining
> Sent: 2. februar 2015 09:32
> To: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] input shapefile to build graph-using R
> 
> > # Load libraries
> > library(spdep)
> > library(igraph)
> > library(maptools)
> > pl <- readShapeLines("H:/data/Beijing_NatrualRoads.shp",
> + proj4string=CRS("+proj=Mercator_Auxiliary_Sphere +datum=WGS84"))
> > pt <-
> readShapePoints("H:/data/Beijing_NatrualRoads_computejunctions.shp",
> + proj4string=CRS("+proj=Mercator_Auxiliary_Sphere +datum=WGS84"))
> > g <- graph.data.frame(pl, directed=TRUE, vertices=pt)
> Error in graph.data.frame(pl, directed = TRUE, vertices = pt) :
>   Duplicate vertex names
> In addition: Warning message:
> In graph.data.frame(pl, directed = TRUE, vertices = pt) :
>   In `d' `NA' elements were replaced with string "NA"
> > cl<-closeness(g, mode = c("out"),weights = NULL, normalized = TRUE)
> Error in match(x, table, nomatch = 0L) : object 'g' not found
> >
> <http://r-sig-geo.2731867.n2.nabble.com/file/n7587719/R_error.jpg>
> 
> 
> 
> --
> View this message in context: http://r-sig-
> geo.2731867.n2.nabble.com/input-shapefile-to-build-graph-using-R-
> tp7587718p7587719.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Mon Feb  2 12:13:59 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 2 Feb 2015 12:13:59 +0100
Subject: [R-sig-Geo] input shapefile to build graph-using R
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857CBB1DC6B@DKRDSEXC016.vestas.net>
References: <1422856493453-7587718.post@n2.nabble.com>
	<1422865938486-7587719.post@n2.nabble.com>
	<B078CDF40DFE4045AF172A8B4F68FC4857CBB1DC6B@DKRDSEXC016.vestas.net>
Message-ID: <alpine.LFD.2.11.1502021208310.15055@reclus.nhh.no>

On Mon, 2 Feb 2015, Frede Aakmann T?gersen wrote:

> Dear "whoever you are"
>
> You give way to little information in order to make us able help you. 
> Just posting a jpg image of the error message already presented doesn't 
> help either.

Exactly. In addition, the JPG is only on Nabble (with advertisements), and 
not on the actual list.

What puzzles me most is why the OP thinks that the input objects d and 
vertices (which should be data.frame objects) are the 
SpatialLinesDataFrame and SpatialPointsDataFrame objects read with (very) 
outdated functions in maptools. d should be:

"A data frame containing a symbolic edge list in the first two columns. 
Additional columns are considered as edge attributes."

Reading the help pages of functions one uses, and checking that the 
objects being passed as argument values actually meet the conditions 
stipulated, should really come before posting a question. Reading the 
posting guide is also warmly reccommended.

Roger

>
> Posting the following will probably enable us to help you better.
>
> 1) Immediately after the error show the output from a call to traceback()
> 2) If not providing the data, then show calls to str() on the imported data, 'lt' and 'pt'
> 3) Provide the output from sessionInfo()
>
>> From the error message:
>
>> Error in graph.data.frame(pl, directed = TRUE, vertices = pt) :
>>   Duplicate vertex names
>
> it seems like the vertices in the pt object has not been named in an unique way since that is probably needed.
>
> Also from the warning the error just above seems to be related to the namings of the vertices. More than one vertex was missing an ID:
>
>> In addition: Warning message:
>> In graph.data.frame(pl, directed = TRUE, vertices = pt) :
>>   In `d' `NA' elements were replaced with string "NA"
>
> graph.data.frame seems to convert factor vector to a vector of strings which in this case gives identical ids with names NA.
>
> By the way, on many email lists it would be seen courteously of you to provide you affiliation so people can see who they are dealing with.
>
>
> Yours sincerely / Med venlig hilsen
>
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>
>> -----Original Message-----
>> From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of
>> silverlining
>> Sent: 2. februar 2015 09:32
>> To: r-sig-geo at r-project.org
>> Subject: Re: [R-sig-Geo] input shapefile to build graph-using R
>>
>>> # Load libraries
>>> library(spdep)
>>> library(igraph)
>>> library(maptools)
>>> pl <- readShapeLines("H:/data/Beijing_NatrualRoads.shp",
>> + proj4string=CRS("+proj=Mercator_Auxiliary_Sphere +datum=WGS84"))
>>> pt <-
>> readShapePoints("H:/data/Beijing_NatrualRoads_computejunctions.shp",
>> + proj4string=CRS("+proj=Mercator_Auxiliary_Sphere +datum=WGS84"))
>>> g <- graph.data.frame(pl, directed=TRUE, vertices=pt)
>> Error in graph.data.frame(pl, directed = TRUE, vertices = pt) :
>>   Duplicate vertex names
>> In addition: Warning message:
>> In graph.data.frame(pl, directed = TRUE, vertices = pt) :
>>   In `d' `NA' elements were replaced with string "NA"
>>> cl<-closeness(g, mode = c("out"),weights = NULL, normalized = TRUE)
>> Error in match(x, table, nomatch = 0L) : object 'g' not found
>>>
>> <http://r-sig-geo.2731867.n2.nabble.com/file/n7587719/R_error.jpg>
>>
>>
>>
>> --
>> View this message in context: http://r-sig-
>> geo.2731867.n2.nabble.com/input-shapefile-to-build-graph-using-R-
>> tp7587718p7587719.html
>> Sent from the R-sig-geo mailing list archive at Nabble.com.
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From mtreglia at gmail.com  Mon Feb  2 16:30:47 2015
From: mtreglia at gmail.com (Michael Treglia)
Date: Mon, 2 Feb 2015 09:30:47 -0600
Subject: [R-sig-Geo] Quadrat Variance Analyses in R?
Message-ID: <CAPKp32tD-Jr=JYfCwoSVpBJRfmKo4grzBnBkvY1evuQPmtgniQ@mail.gmail.com>

Hi All,

I was wondering if anybody has suggestions for packages with-which to do
quadrat-based contiguous units analysis (e.g., paired quadrat variance,
two-term local quadrat variance, etc).

Or would these analyses involve writing my own functions, probably based on
quadrat functions in spatstat?

(I've searched around the web a bunch, but haven't really found anything
about carrying out such analyses in R).

Any suggestions are welcome.
Thanks!
Mike

	[[alternative HTML version deleted]]


From jstachel at sfwmd.gov  Mon Feb  2 17:09:21 2015
From: jstachel at sfwmd.gov (Stachelek, Joseph)
Date: Mon, 2 Feb 2015 16:09:21 +0000
Subject: [R-sig-Geo] Quadrat Variance Analyses in R?
In-Reply-To: <CAPKp32tD-Jr=JYfCwoSVpBJRfmKo4grzBnBkvY1evuQPmtgniQ@mail.gmail.com>
References: <CAPKp32tD-Jr=JYfCwoSVpBJRfmKo4grzBnBkvY1evuQPmtgniQ@mail.gmail.com>
Message-ID: <D51374C4B889BC47B3C5286047C86DA19032D3A2@whqembx03p.ad.sfwmd.gov>

I use passage (http://www.passagesoftware.net/) to do quadrat analysis. It accepts command line input so I wrote a shell script that can be called from and return results to R.


-----Original Message-----
From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Michael Treglia
Sent: Monday, February 02, 2015 10:31 AM
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] Quadrat Variance Analyses in R?

Hi All,

I was wondering if anybody has suggestions for packages with-which to do
quadrat-based contiguous units analysis (e.g., paired quadrat variance,
two-term local quadrat variance, etc).

Or would these analyses involve writing my own functions, probably based on
quadrat functions in spatstat?

(I've searched around the web a bunch, but haven't really found anything
about carrying out such analyses in R).

Any suggestions are welcome.
Thanks!
Mike

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


We value your opinion. Please take a few minutes to share your comments on the service you received from the District by clicking on this link<http://my.sfwmd.gov/portal/page/portal/pg_grp_surveysystem/survey%20ext?pid=1653>.


From r.hijmans at gmail.com  Mon Feb  2 18:31:15 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Mon, 2 Feb 2015 09:31:15 -0800
Subject: [R-sig-Geo] transformin multipart shapefile to singlepart
	shapefile
In-Reply-To: <1422703064617-7587716.post@n2.nabble.com>
References: <4D356FCA.8080603@wiwi.hu-berlin.de>
	<AANLkTikzyxCOR+6FesCxa3wNPfvqFZnJnZ1=25PkFgxJ@mail.gmail.com>
	<4D36B2D4.4090302@wiwi.hu-berlin.de>
	<1422703064617-7587716.post@n2.nabble.com>
Message-ID: <CANtt_hyWvVabRoNNji46YdPS50o=iUoo75YRMSCLvcs4VSApGQ@mail.gmail.com>

Jean-Luc
I think you can use the disaggregate method (in package sp) for that.
Robert

On Sat, Jan 31, 2015 at 3:17 AM, Jean-Luc DUPOUEY <dupouey at nancy.inra.fr> wrote:
> I faced the same question recently: how to tranform a multipart polygon layer
> into single polygons? Here is a little bit more general function to do that.
> It keeps the initial ID of the polygons, adding a sequence number. The
> initial plot order and projection information are also kept.
>
> But pay attention, holes are automatically converted into islands, because
> holes cannot be single polygons.
>
> I am interested in improving this function. Thanks in advance,
>
> JL Dupouey
>
> #JL Dupouey INRA-Nancy 2015/01/31
>
> #convert a multipart SpatialPolygons object to a single part SpatialPolygons
> object
> #plot order: keeps the initial plot order
> #p4s: keeps the initial p4s, if not NA
> #ID: keeps the initial ID of the multipart polygons, and add a numeric
> increasing index from 1 to n
> # in order of presence of the single polygons wich compose the multipart
> polygon, if there is more then one part
>
> multitoone=function(mpart)
>
> {
> #vector of number of elementary polygons in each multipart polygon (for
> calculation of plot order, and initialization of islands)
> nbpoly=sapply(mpart at polygons,function(x){length(x at Polygons)})
>
> #initialize the list of single Polygons to be built
> islands=vector("list",sum(nbpoly))
> #initialize the vector plot order of single polygons to be built
> plotorder=vector("integer",sum(nbpoly))
>
> #index of current single Polygons
> k=0
>
> #loop on all Polygons of the object
>
> for (i in 1:length(mpart))
> {
>
> #current multiple polygon
> pols=mpart at polygons[[i]]@Polygons
> ID=mpart at polygons[[i]]@ID
>
> #number of polygons to plot before the current multiple one
> prev=sum(nbpoly[mpart at plotOrder<mpart at plotOrder[i]])
>
> #loop on each elementary polygon of the current multiple polygon
>
> for (j in 1:length(pols))
>  { k=k+1
>    IDs=ifelse(length(pols)>1,paste(ID,'-',j,sep=''),ID)
>    islands[[k]] = Polygons(list(pols[[j]]), IDs)
>
> plotorder[k]=rank(mpart at polygons[[i]]@plotOrder,ties.method="first")[j]+prev
> }
> }#end on loop on all Polygons of the object
>
> multitoone = SpatialPolygons(islands,pO=plotorder)
> if (!is.na(proj4string(mpart))) proj4string(multitoone)=proj4string(mpart)
>
> return(multitoone)
> }
>
>
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/transformin-multipart-shapefile-to-singlepart-shapefile-tp5935148p7587716.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From mtreglia at gmail.com  Mon Feb  2 21:24:04 2015
From: mtreglia at gmail.com (Michael Treglia)
Date: Mon, 2 Feb 2015 14:24:04 -0600
Subject: [R-sig-Geo] Quadrat Variance Analyses in R?
In-Reply-To: <D51374C4B889BC47B3C5286047C86DA19032D3A2@whqembx03p.ad.sfwmd.gov>
References: <CAPKp32tD-Jr=JYfCwoSVpBJRfmKo4grzBnBkvY1evuQPmtgniQ@mail.gmail.com>
	<D51374C4B889BC47B3C5286047C86DA19032D3A2@whqembx03p.ad.sfwmd.gov>
Message-ID: <CAPKp32s_GQBVT39dZ9F-aLbwX5QCW3dFcR3JyV7EatAAsgsWLw@mail.gmail.com>

Thanks Joseph  - I might just use that then (I like passage, but was trying
to keep in R if I could - the shell script is a good idea though).

Best,
Mike

On Mon, Feb 2, 2015 at 10:09 AM, Stachelek, Joseph <jstachel at sfwmd.gov>
wrote:

> I use passage (http://www.passagesoftware.net/) to do quadrat analysis.
> It accepts command line input so I wrote a shell script that can be called
> from and return results to R.
>
>
> -----Original Message-----
> From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of
> Michael Treglia
> Sent: Monday, February 02, 2015 10:31 AM
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] Quadrat Variance Analyses in R?
>
> Hi All,
>
> I was wondering if anybody has suggestions for packages with-which to do
> quadrat-based contiguous units analysis (e.g., paired quadrat variance,
> two-term local quadrat variance, etc).
>
> Or would these analyses involve writing my own functions, probably based on
> quadrat functions in spatstat?
>
> (I've searched around the web a bunch, but haven't really found anything
> about carrying out such analyses in R).
>
> Any suggestions are welcome.
> Thanks!
> Mike
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> We value your opinion. Please take a few minutes to share your comments on
> the service you received from the District by clicking on this link<
> http://my.sfwmd.gov/portal/page/portal/pg_grp_surveysystem/survey%20ext?pid=1653
> >.
>

	[[alternative HTML version deleted]]


From jed.long at st-andrews.ac.uk  Tue Feb  3 10:52:05 2015
From: jed.long at st-andrews.ac.uk (JLong)
Date: Tue, 3 Feb 2015 02:52:05 -0700 (MST)
Subject: [R-sig-Geo] grid in adehabitatHR
In-Reply-To: <CALC46t_msue9oh3ykUnx=vOKF-pFZBmUnffXG2n0LZvSNU7LVw@mail.gmail.com>
References: <CALC46t_msue9oh3ykUnx=vOKF-pFZBmUnffXG2n0LZvSNU7LVw@mail.gmail.com>
Message-ID: <1422957125784-7587727.post@n2.nabble.com>

Hi David,

The kernelUD 'grid' parameter expects a SpatialPixels object that represents
the raster upon which you wish to estimate the animal UD. You are passing in
only a raster with 4 pixels, which I think represent the outer corners of
the raster upon which you wish to estimate the UD. Alternatively, the grid
parameter can accept a number that represents the pixel size, and it will
automatically build the raster for you.

The problem lies in your buildup definition of the SpatialPixelsDataFrame
object. When you define a 'grid' you need to identify the locations of each
pixel in the grid and save those as columns x  and y  in the data frame. See
the 'expand.grid' function and the meuse.grid example in the function
'coordinates'.

As a test just try:
kud=kernelUD(detections[,1],h=h, grid=40, kern=c("bivnorm"))


Then, the process if you wish to define your own grid would then be:
x <- seq(xmin,xmax,by=resolution)  # where resolution is the pixel size you
desire
y <- seq(ymin,ymax,by=resolution)
xy <- expand.grid(x=x,y=y)
coordinates(xy) <- ~x+y
gridded(xy) <- TRUE
class(xy)

kud=kernelUD(detections[,1],h=h, grid=xy, kern=c("bivnorm"))

Cheers,
Jed




-----
Jed Long
Lecturer in GeoInformatics
Department of Geography & Sustainable Development
University of St Andrews, UK
--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/grid-in-adehabitatHR-tp7587722p7587727.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From chirleu at gmail.com  Tue Feb  3 15:37:27 2015
From: chirleu at gmail.com (chirleu)
Date: Tue, 3 Feb 2015 07:37:27 -0700 (MST)
Subject: [R-sig-Geo] grid in adehabitatHR
In-Reply-To: <1422957125784-7587727.post@n2.nabble.com>
References: <CALC46t_msue9oh3ykUnx=vOKF-pFZBmUnffXG2n0LZvSNU7LVw@mail.gmail.com>
	<1422957125784-7587727.post@n2.nabble.com>
Message-ID: <CALC46t_qMTRveZJvRCFxFb+FeU1hVrK21Cyphgm_2hXTYMkmFQ@mail.gmail.com>

Hi Jed,
It worked! So thank you. I was close. I think I was passing a complet grid
(not only 4 points):
loc4=raster(loc,nrows=1000,ncols=1000)
but for some reason did not work. It seems the key is the expand.grid
function.

Cheers,

David

2015-02-03 10:52 GMT+01:00 JLong [via R-sig-geo] <
ml-node+s2731867n7587727h27 at n2.nabble.com>:

> Hi David,
>
> The kernelUD 'grid' parameter expects a SpatialPixels object that
> represents the raster upon which you wish to estimate the animal UD. You
> are passing in only a raster with 4 pixels, which I think represent the
> outer corners of the raster upon which you wish to estimate the UD.
> Alternatively, the grid parameter can accept a number that represents the
> pixel size, and it will automatically build the raster for you.
>
> The problem lies in your buildup definition of the SpatialPixelsDataFrame
> object. When you define a 'grid' you need to identify the locations of each
> pixel in the grid and save those as columns x  and y  in the data frame.
> See the 'expand.grid' function and the meuse.grid example in the function
> 'coordinates'.
>
> As a test just try:
> kud=kernelUD(detections[,1],h=h, grid=40, kern=c("bivnorm"))
>
>
> Then, the process if you wish to define your own grid would then be:
> x <- seq(xmin,xmax,by=resolution)  # where resolution is the pixel size
> you desire
> y <- seq(ymin,ymax,by=resolution)
> xy <- expand.grid(x=x,y=y)
> coordinates(xy) <- ~x+y
> gridded(xy) <- TRUE
> class(xy)
>
> kud=kernelUD(detections[,1],h=h, grid=xy, kern=c("bivnorm"))
>
> Cheers,
> Jed
>  Jed Long
> Lecturer in GeoInformatics
> Department of Geography & Sustainable Development
> University of St Andrews, UK
>
>
> ------------------------------
>  If you reply to this email, your message will be added to the discussion
> below:
>
> http://r-sig-geo.2731867.n2.nabble.com/grid-in-adehabitatHR-tp7587722p7587727.html
>  To unsubscribe from grid in adehabitatHR, click here
> <http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=7587722&code=Y2hpcmxldUBnbWFpbC5jb218NzU4NzcyMnw3MzA1Njc5Nw==>
> .
> NAML
> <http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>




--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/grid-in-adehabitatHR-tp7587722p7587728.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Dominik.Schneider at colorado.edu  Wed Feb  4 20:40:39 2015
From: Dominik.Schneider at colorado.edu (Dominik Schneider)
Date: Wed, 4 Feb 2015 12:40:39 -0700
Subject: [R-sig-Geo] stack many files without loading into memory
Message-ID: <CAHYDKLY3GBbCk8dNw0Jpp0xy-vxAxdbhZdEjSqv339W2Yfmj9Q@mail.gmail.com>

Hi -
I have some data on a server but would like to bring them local in a
somewhat compressed format that is still easy to access.

/Volumes/hD/2012 -> 100 geotiffs
~/project/data/ -> store those geotiffs here without needing server access.

untested, I think I could do something like:
s=stack()
writeRaster(s,'2012stack')
fn=list.files('/Volumes/hD/2012',pattern='*.tif',full.names=T)
lapply(fn,function(f){
s=stack('2012stack')
r=raster(f)
names(r)=gsub(pattern='.tif',replacement='',basename(f))
s=addLayer(s,r)
writeRaster(s,'2012stack')
})
Or is it better to save to a .RData?
Is there a better way that doesn't require me to loop through each geotiff
since I can't load it all into memory.
Thanks
Dominik

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Wed Feb  4 20:50:13 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 04 Feb 2015 19:50:13 +0000
Subject: [R-sig-Geo] stack many files without loading into memory
References: <CAHYDKLY3GBbCk8dNw0Jpp0xy-vxAxdbhZdEjSqv339W2Yfmj9Q@mail.gmail.com>
Message-ID: <CAAcGz99tz-Dw4=KLX1zRYupXRv5++ObTeL8n3HGSfSJia3HOzQ@mail.gmail.com>

Why not stack(fn)

?

On Thu, 5 Feb 2015 06:41 Dominik Schneider <Dominik.Schneider at colorado.edu>
wrote:

> Hi -
> I have some data on a server but would like to bring them local in a
> somewhat compressed format that is still easy to access.
>
> /Volumes/hD/2012 -> 100 geotiffs
> ~/project/data/ -> store those geotiffs here without needing server access.
>
> untested, I think I could do something like:
> s=stack()
> writeRaster(s,'2012stack')
> fn=list.files('/Volumes/hD/2012',pattern='*.tif',full.names=T)
> lapply(fn,function(f){
> s=stack('2012stack')
> r=raster(f)
> names(r)=gsub(pattern='.tif',replacement='',basename(f))
> s=addLayer(s,r)
> writeRaster(s,'2012stack')
> })
> Or is it better to save to a .RData?
> Is there a better way that doesn't require me to loop through each geotiff
> since I can't load it all into memory.
> Thanks
> Dominik
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From Dominik.Schneider at colorado.edu  Wed Feb  4 20:51:33 2015
From: Dominik.Schneider at colorado.edu (Dominik Schneider)
Date: Wed, 4 Feb 2015 12:51:33 -0700
Subject: [R-sig-Geo] stack many files without loading into memory
In-Reply-To: <CAAcGz99tz-Dw4=KLX1zRYupXRv5++ObTeL8n3HGSfSJia3HOzQ@mail.gmail.com>
References: <CAHYDKLY3GBbCk8dNw0Jpp0xy-vxAxdbhZdEjSqv339W2Yfmj9Q@mail.gmail.com>
	<CAAcGz99tz-Dw4=KLX1zRYupXRv5++ObTeL8n3HGSfSJia3HOzQ@mail.gmail.com>
Message-ID: <CAHYDKLZD8wm0_ZJZin9EtcjEZW3EQ8R_qGosnGdOducKMqGw9g@mail.gmail.com>

Wouldn't that keep the link to the server on which they are stored now?

Dominik Schneider
o 303.735.6296 | c 518.956.3978


On Wed, Feb 4, 2015 at 12:50 PM, Michael Sumner <mdsumner at gmail.com> wrote:

> Why not stack(fn)
>
> ?
>
> On Thu, 5 Feb 2015 06:41 Dominik Schneider <Dominik.Schneider at colorado.edu>
> wrote:
>
>> Hi -
>> I have some data on a server but would like to bring them local in a
>> somewhat compressed format that is still easy to access.
>>
>> /Volumes/hD/2012 -> 100 geotiffs
>> ~/project/data/ -> store those geotiffs here without needing server
>> access.
>>
>> untested, I think I could do something like:
>> s=stack()
>> writeRaster(s,'2012stack')
>> fn=list.files('/Volumes/hD/2012',pattern='*.tif',full.names=T)
>> lapply(fn,function(f){
>> s=stack('2012stack')
>> r=raster(f)
>> names(r)=gsub(pattern='.tif',replacement='',basename(f))
>> s=addLayer(s,r)
>> writeRaster(s,'2012stack')
>> })
>> Or is it better to save to a .RData?
>> Is there a better way that doesn't require me to loop through each geotiff
>> since I can't load it all into memory.
>> Thanks
>> Dominik
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>

	[[alternative HTML version deleted]]


From Dominik.Schneider at colorado.edu  Wed Feb  4 21:41:01 2015
From: Dominik.Schneider at colorado.edu (Dominik Schneider)
Date: Wed, 4 Feb 2015 13:41:01 -0700
Subject: [R-sig-Geo] stack many files without loading into memory
In-Reply-To: <CAHYDKLZD8wm0_ZJZin9EtcjEZW3EQ8R_qGosnGdOducKMqGw9g@mail.gmail.com>
References: <CAHYDKLY3GBbCk8dNw0Jpp0xy-vxAxdbhZdEjSqv339W2Yfmj9Q@mail.gmail.com>
	<CAAcGz99tz-Dw4=KLX1zRYupXRv5++ObTeL8n3HGSfSJia3HOzQ@mail.gmail.com>
	<CAHYDKLZD8wm0_ZJZin9EtcjEZW3EQ8R_qGosnGdOducKMqGw9g@mail.gmail.com>
Message-ID: <CAHYDKLbEVfxYLzeHBJAbRUQxx+RwYCYtGfNoz4o6s2HP0Yc48A@mail.gmail.com>

I think you are correct.
s=stack(fn,quick=T)
writeRaster(s,'localpath/2012data')

would get the data local. I guess the trade off is that the file size is an
order of magnitude bigger than if I saved them in an .RData file but much
quicker to access.
ds

On Wed, Feb 4, 2015 at 12:51 PM, Dominik Schneider <
dominik.schneider at colorado.edu> wrote:

> Wouldn't that keep the link to the server on which they are stored now?
>
> On Wed, Feb 4, 2015 at 12:50 PM, Michael Sumner <mdsumner at gmail.com>
> wrote:
>
>> Why not stack(fn)
>>
>> ?
>>
>> On Thu, 5 Feb 2015 06:41 Dominik Schneider <
>> Dominik.Schneider at colorado.edu> wrote:
>>
>>> Hi -
>>> I have some data on a server but would like to bring them local in a
>>> somewhat compressed format that is still easy to access.
>>>
>>> /Volumes/hD/2012 -> 100 geotiffs
>>> ~/project/data/ -> store those geotiffs here without needing server
>>> access.
>>>
>>> untested, I think I could do something like:
>>> s=stack()
>>> writeRaster(s,'2012stack')
>>> fn=list.files('/Volumes/hD/2012',pattern='*.tif',full.names=T)
>>> lapply(fn,function(f){
>>> s=stack('2012stack')
>>> r=raster(f)
>>> names(r)=gsub(pattern='.tif',replacement='',basename(f))
>>> s=addLayer(s,r)
>>> writeRaster(s,'2012stack')
>>> })
>>> Or is it better to save to a .RData?
>>> Is there a better way that doesn't require me to loop through each
>>> geotiff
>>> since I can't load it all into memory.
>>> Thanks
>>> Dominik
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Wed Feb  4 22:38:49 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 04 Feb 2015 21:38:49 +0000
Subject: [R-sig-Geo] stack many files without loading into memory
References: <CAHYDKLY3GBbCk8dNw0Jpp0xy-vxAxdbhZdEjSqv339W2Yfmj9Q@mail.gmail.com>
	<CAAcGz99tz-Dw4=KLX1zRYupXRv5++ObTeL8n3HGSfSJia3HOzQ@mail.gmail.com>
	<CAHYDKLZD8wm0_ZJZin9EtcjEZW3EQ8R_qGosnGdOducKMqGw9g@mail.gmail.com>
	<CAHYDKLbEVfxYLzeHBJAbRUQxx+RwYCYtGfNoz4o6s2HP0Yc48A@mail.gmail.com>
Message-ID: <CAAcGz99D1K8_+y7=exw7Pv5NqaCsfDA6Aa2N5uvEfvtKZENpqw@mail.gmail.com>

On Thu Feb 05 2015 at 7:41:33 AM Dominik Schneider <
Dominik.Schneider at colorado.edu> wrote:

> I think you are correct.
> s=stack(fn,quick=T)
> writeRaster(s,'localpath/2012data')
>
>

Ugh, sorry yes that's me reading too fast. I should have suggested the next
step to writeRaster, I'm not sure why you don't include the file extension
here though? Why not

writeRaster(s,'localpath/2012data.grd')




would get the data local. I guess the trade off is that the file size is an
> order of magnitude bigger than if I saved them in an .RData file but much
> quicker to access.
>

You might achieve similar compression if you choose GeoTIFF, with the right
options (and you need rgdal). Try a test with a single layer, e.g.

s=stack(fn,quick = TRUE)
require(rgdal)
writeRaster(s[[1]],'localpath/2012data_temp01.tif', options =
c("COMPRESS=LZW", "TILED=YES")

Does the file size of "2012data_temp01.tif" look promising?

The native "rasterfile" format does not support compression as far as I
know. Tiling may be of help or hindrance, depending on the dimensions and
the extra margin added by the tiles if they need to extend beyond the
margins - you can control tile size with BLOCKX/YSIZE  if needed:
http://www.gdal.org/frmt_gtiff.html

(NetCDF4 - with ncdf4 package - can also compress and tile natively, but I
haven't tried that via raster myself).

Cheers, Mike.


> ds
>
> On Wed, Feb 4, 2015 at 12:51 PM, Dominik Schneider <
> dominik.schneider at colorado.edu> wrote:
>
>> Wouldn't that keep the link to the server on which they are stored now?
>>
> On Wed, Feb 4, 2015 at 12:50 PM, Michael Sumner <mdsumner at gmail.com>
>> wrote:
>>
>>> Why not stack(fn)
>>>
>>> ?
>>>
>>> On Thu, 5 Feb 2015 06:41 Dominik Schneider <
>>> Dominik.Schneider at colorado.edu> wrote:
>>>
>>>> Hi -
>>>> I have some data on a server but would like to bring them local in a
>>>> somewhat compressed format that is still easy to access.
>>>>
>>>> /Volumes/hD/2012 -> 100 geotiffs
>>>> ~/project/data/ -> store those geotiffs here without needing server
>>>> access.
>>>>
>>>> untested, I think I could do something like:
>>>> s=stack()
>>>> writeRaster(s,'2012stack')
>>>> fn=list.files('/Volumes/hD/2012',pattern='*.tif',full.names=T)
>>>> lapply(fn,function(f){
>>>> s=stack('2012stack')
>>>> r=raster(f)
>>>> names(r)=gsub(pattern='.tif',replacement='',basename(f))
>>>> s=addLayer(s,r)
>>>> writeRaster(s,'2012stack')
>>>> })
>>>> Or is it better to save to a .RData?
>>>> Is there a better way that doesn't require me to loop through each
>>>> geotiff
>>>> since I can't load it all into memory.
>>>> Thanks
>>>> Dominik
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>
>>

	[[alternative HTML version deleted]]


From ptitle at umich.edu  Thu Feb  5 05:55:57 2015
From: ptitle at umich.edu (Pascal Title)
Date: Wed, 4 Feb 2015 23:55:57 -0500
Subject: [R-sig-Geo] supplying multiple coordinates to shortestPath
Message-ID: <CAPSA=ydRJj0Mj8mCMnJ4rfvo49z0v3BBSp0gDxO4cU=v0wC4HQ@mail.gmail.com>

Hi,

In the shortestPath( ) function of the R package gdistance, the
documentation seems to imply (at least according to my interpretation) that
I should supply one point as a starting coordinate, but that I should be
able to supply a matrix of coordinates as endpoints for path calculations.
However, if I try this, I get an error. Am I doing something wrong, or am I
misinterpreting the documentation?

See code below. All advice greatly appreciated!

-Pascal

CODE:

require(maptools)
require(gdistance)

#create world raster
data(wrld_simpl)
r <- raster()
r <-rasterize(wrld_simpl, r, progress='text')

#make land off bounds
r[is.na(r)] <- -999
r[r > -999] <- NA
r[r == -999] <- 1

tr <- transition(r, mean, directions = 8)
tr <- geoCorrection(tr, "c")

coordmat <- cbind(c(0,-150,150), c(0, 20, 20))

#single coordinates supplied -- works
shortestPath(tr, coordmat[1,], coordmat[2,], output='SpatialLines')

#multiple coordinates supplied to 'goal', returns error
shortestPath(tr, coordmat[2,], coordmat, output='SpatialLines')

Error in .local(obj, ...) :
  cannot derive coordinates from non-numeric matrix

-- 

Pascal Title
PhD candidate | Rabosky Lab
Dept of Ecology and Evolutionary Biology
University of Michigan
ptitle at umich.edu

pascaltitle.weebly.com

	[[alternative HTML version deleted]]


From thi_veloso at yahoo.com.br  Thu Feb  5 19:22:25 2015
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Thu, 5 Feb 2015 18:22:25 +0000 (UTC)
Subject: [R-sig-Geo] How to apply this function on each raster stack layer?
Message-ID: <109259438.222447.1423160545467.JavaMail.yahoo@mail.yahoo.com>

Hi all,

I am trying to write an efficient script to calibrate hundreds of Landsat 8 images. At a certain point of the calibration steps, I need to apply some coefficients in each layer of a raster stack.


This is one sample stack:fn <- system.file("external/test.grd", package="raster")

s  <- stack(fn, fn)

And these are sample coefficients:
mult <- c(0.0003342, 0.0005534) 
add  <- c(0.1, 0.2) 


What I need to is to apply each index of the coefficients to the correspondent index of the stack layer, like in this example:

s[[1]] <- (s[[1]] * mult[1]) + add[1]
s[[2]] <- (s[[2]] * mult[2]) + add[2]

This is my poor attempt, which obviously does not work:

cal.fun <- function(x) { 
x <- (x * mult) + add 
}

s.cal <- calc(s, cal.fun, progress='text')


Any ideas on how to do that?
 
Many thanks,
--
Thiago V. dos Santos
PhD student
Land and Atmospheric Science
University of Minnesota
http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
Phone: (612) 323 9898


From Hollister.Jeff at epa.gov  Thu Feb  5 20:31:15 2015
From: Hollister.Jeff at epa.gov (Hollister, Jeff)
Date: Thu, 5 Feb 2015 19:31:15 +0000
Subject: [R-sig-Geo] gDistance problem on RHEL 6 64-bit
Message-ID: <BY1PR09MB0341DDD0B8A7B28AF5E4AEDA813B0@BY1PR09MB0341.namprd09.prod.outlook.com>

Hello all,

I am having a problem with rgeos::gDistance on RHEL 6.  Everytime I try to get a point to point distance, I get

R: GeometryComponentFilter.cpp:34: virtual void geos::geom::GeometryComponentFilter::filter_ro(const geos::geom::Geometry*): Assertion `0' failed.
Aborted (core dumped)

This only occurs on my RHEL 6 machine.  Win 7 and Ubuntu 14.04 work fine.

Some code to reproduce the problem:
library(sp)
library(rgeos)
pt1<-SpatialPoints(data.frame(x=c(1,3),y=c(3,1)))
pt2<-SpatialPoints(data.frame(x=1,y=1))
gDistance(pt2,pt1)

More info:
> sessionInfo()
R version 3.1.2 (2014-10-31)
Platform: x86_64-redhat-linux-gnu (64-bit)

locale:
[1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
[3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
[5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
[7] LC_PAPER=en_US.UTF-8       LC_NAME=C
[9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] rgeos_0.3-8 sp_1.0-15

loaded via a namespace (and not attached):
[1] grid_3.1.2      lattice_0.20-29

Thanks,
Jeff Hollister

*****************************
Dr. Jeffrey W. Hollister
Research Ecologist
27 Tarzwell Drive
Narragansett, RI 02879
(o) 401 782 9655
hollister.jeff at epa.gov<mailto:hollister.jeff at epa.gov>
Personal Site<http://jwhollister.com/>
*****************************


	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Thu Feb  5 21:28:07 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 5 Feb 2015 21:28:07 +0100
Subject: [R-sig-Geo] gDistance problem on RHEL 6 64-bit
In-Reply-To: <BY1PR09MB0341DDD0B8A7B28AF5E4AEDA813B0@BY1PR09MB0341.namprd09.prod.outlook.com>
References: <BY1PR09MB0341DDD0B8A7B28AF5E4AEDA813B0@BY1PR09MB0341.namprd09.prod.outlook.com>
Message-ID: <alpine.LFD.2.11.1502052113440.11015@reclus.nhh.no>

On Thu, 5 Feb 2015, Hollister, Jeff wrote:

> Hello all,
>
> I am having a problem with rgeos::gDistance on RHEL 6.  Everytime I try 
> to get a point to point distance, I get
>
> R: GeometryComponentFilter.cpp:34: virtual void geos::geom::GeometryComponentFilter::filter_ro(const geos::geom::Geometry*): Assertion `0' failed.
> Aborted (core dumped)
>
> This only occurs on my RHEL 6 machine.  Win 7 and Ubuntu 14.04 work fine.

The key question is how you installed rgeos and GEOS on these platforms. 
Most likely rgeos on Windows 7 is the CRAN binary statically linked to 
GEOS, and on RHEL6 and Ubuntu 14.04 rgeos is installed from source and 
links to the GEOS found on those platforms. We need the output of:

version_GEOS()

on each platform. Most likely you've not installed GEOS from source on 
either of the two Linux platforms. The cause is most likely a mismatch on 
the RHEL platform, possibly that GEOS has fallen behind C++, or that GEOS 
got updated without you re-installing rgeos. Is gDistance() the only 
function that doesn't work - can you run example(gDistance) and/or the 
examples of other functions?

Roger

>
> Some code to reproduce the problem:
> library(sp)
> library(rgeos)
> pt1<-SpatialPoints(data.frame(x=c(1,3),y=c(3,1)))
> pt2<-SpatialPoints(data.frame(x=1,y=1))
> gDistance(pt2,pt1)
>
> More info:
>> sessionInfo()
> R version 3.1.2 (2014-10-31)
> Platform: x86_64-redhat-linux-gnu (64-bit)
>
> locale:
> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] rgeos_0.3-8 sp_1.0-15
>
> loaded via a namespace (and not attached):
> [1] grid_3.1.2      lattice_0.20-29
>
> Thanks,
> Jeff Hollister
>
> *****************************
> Dr. Jeffrey W. Hollister
> Research Ecologist
> 27 Tarzwell Drive
> Narragansett, RI 02879
> (o) 401 782 9655
> hollister.jeff at epa.gov<mailto:hollister.jeff at epa.gov>
> Personal Site<http://jwhollister.com/>
> *****************************
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From Hollister.Jeff at epa.gov  Thu Feb  5 22:06:30 2015
From: Hollister.Jeff at epa.gov (Hollister, Jeff)
Date: Thu, 5 Feb 2015 21:06:30 +0000
Subject: [R-sig-Geo] gDistance problem on RHEL 6 64-bit
In-Reply-To: <alpine.LFD.2.11.1502052113440.11015@reclus.nhh.no>
References: <BY1PR09MB0341DDD0B8A7B28AF5E4AEDA813B0@BY1PR09MB0341.namprd09.prod.outlook.com>
	<alpine.LFD.2.11.1502052113440.11015@reclus.nhh.no>
Message-ID: <BN3PR09MB03383AB3E12AE9FA663BB0E6813B0@BN3PR09MB0338.namprd09.prod.outlook.com>

Roger,

Thanks for getting back to me.  I thought it was a GEOS problem too.  I have updated it and re-installed rgeos.

Curret GEOS is:
> version_GEOS()
[1] "3.4.2-CAPI-1.8.2 r3921"

I tried several of the other rgeos examples (gBuffer, gWithin, gEnvelope, gUnion, gLength ...) and they all worked.  gDistance bombs the same as before, as does gWithinDistance.

My version of gcc appears to be a bit old:

-bash-4.1$ gcc --version
gcc (GCC) 4.4.7 20120313 (Red Hat 4.4.7-11)

Could that be the issue?

Thanks again for your help!
Cheers,
Jeff



*****************************
Dr. Jeffrey W. Hollister
Research Ecologist
27 Tarzwell Drive
Narragansett, RI 02879
(o) 401 782 9655
hollister.jeff at epa.gov
Personal Site
*****************************

-----Original Message-----
From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Sent: Thursday, February 05, 2015 3:28 PM
To: Hollister, Jeff
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] gDistance problem on RHEL 6 64-bit

On Thu, 5 Feb 2015, Hollister, Jeff wrote:

> Hello all,
>
> I am having a problem with rgeos::gDistance on RHEL 6.  Everytime I 
> try to get a point to point distance, I get
>
> R: GeometryComponentFilter.cpp:34: virtual void geos::geom::GeometryComponentFilter::filter_ro(const geos::geom::Geometry*): Assertion `0' failed.
> Aborted (core dumped)
>
> This only occurs on my RHEL 6 machine.  Win 7 and Ubuntu 14.04 work fine.

The key question is how you installed rgeos and GEOS on these platforms. 
Most likely rgeos on Windows 7 is the CRAN binary statically linked to GEOS, and on RHEL6 and Ubuntu 14.04 rgeos is installed from source and links to the GEOS found on those platforms. We need the output of:

version_GEOS()

on each platform. Most likely you've not installed GEOS from source on either of the two Linux platforms. The cause is most likely a mismatch on the RHEL platform, possibly that GEOS has fallen behind C++, or that GEOS got updated without you re-installing rgeos. Is gDistance() the only function that doesn't work - can you run example(gDistance) and/or the examples of other functions?

Roger

>
> Some code to reproduce the problem:
> library(sp)
> library(rgeos)
> pt1<-SpatialPoints(data.frame(x=c(1,3),y=c(3,1)))
> pt2<-SpatialPoints(data.frame(x=1,y=1))
> gDistance(pt2,pt1)
>
> More info:
>> sessionInfo()
> R version 3.1.2 (2014-10-31)
> Platform: x86_64-redhat-linux-gnu (64-bit)
>
> locale:
> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] rgeos_0.3-8 sp_1.0-15
>
> loaded via a namespace (and not attached):
> [1] grid_3.1.2      lattice_0.20-29
>
> Thanks,
> Jeff Hollister
>
> *****************************
> Dr. Jeffrey W. Hollister
> Research Ecologist
> 27 Tarzwell Drive
> Narragansett, RI 02879
> (o) 401 782 9655
> hollister.jeff at epa.gov<mailto:hollister.jeff at epa.gov>
> Personal Site<http://jwhollister.com/>
> *****************************
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

--
Roger Bivand
Department of Economics, Norwegian School of Economics, Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From karljarvis at gmail.com  Fri Feb  6 01:31:59 2015
From: karljarvis at gmail.com (karljarvis)
Date: Thu, 5 Feb 2015 17:31:59 -0700 (MST)
Subject: [R-sig-Geo] supplying multiple coordinates to shortestPath
In-Reply-To: <CAPSA=ydRJj0Mj8mCMnJ4rfvo49z0v3BBSp0gDxO4cU=v0wC4HQ@mail.gmail.com>
References: <CAPSA=ydRJj0Mj8mCMnJ4rfvo49z0v3BBSp0gDxO4cU=v0wC4HQ@mail.gmail.com>
Message-ID: <1423182719372-7587739.post@n2.nabble.com>

Hi Pascal,
It doesn't like that you are finding the path from coordmat[2,] to itself.
This works, though:

shortestPath(tr, coordmat[2,], coordmat[c(1,3),], output='SpatialLines')

Best,
Karl



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/supplying-multiple-coordinates-to-shortestPath-tp7587734p7587739.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From frtog at vestas.com  Fri Feb  6 07:25:44 2015
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Fri, 6 Feb 2015 07:25:44 +0100
Subject: [R-sig-Geo] How to apply this function on each raster stack
 layer?
In-Reply-To: <109259438.222447.1423160545467.JavaMail.yahoo@mail.yahoo.com>
References: <109259438.222447.1423160545467.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC4857CCD6A794@DKRDSEXC016.vestas.net>

Hi Thiago

I think that the forceapply argument of calc() is what you need; see ?calc. Here is the relevant part from the man:

     The intent of some functions can be ambiguous. Consider:

     'library(raster)'

     'r <- raster(volcano)'

     'calc(r, function(x) x * 1:10)'

     In this case, the cell values are multiplied in a vectorized
     manner and a single layer is returned where the first cell has
     been multiplied with one, the second cell with two, the 11th cell
     with one again, and so on. But perhaps the intent was to create 10
     new layers ('x*1, x*2, ...')? This can be achieved by using
     argument 'forceapply=TRUE'

     'calc(r, function(x) x * 1:10), forceapply=TRUE'


Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of
> Thiago V. dos Santos
> Sent: 5. februar 2015 19:22
> To: R-SIG list
> Subject: [R-sig-Geo] How to apply this function on each raster stack layer?
> 
> Hi all,
> 
> I am trying to write an efficient script to calibrate hundreds of Landsat 8
> images. At a certain point of the calibration steps, I need to apply some
> coefficients in each layer of a raster stack.
> 
> 
> This is one sample stack:fn <- system.file("external/test.grd",
> package="raster")
> 
> s  <- stack(fn, fn)
> 
> And these are sample coefficients:
> mult <- c(0.0003342, 0.0005534)
> add  <- c(0.1, 0.2)
> 
> 
> What I need to is to apply each index of the coefficients to the
> correspondent index of the stack layer, like in this example:
> 
> s[[1]] <- (s[[1]] * mult[1]) + add[1]
> s[[2]] <- (s[[2]] * mult[2]) + add[2]
> 
> This is my poor attempt, which obviously does not work:
> 
> cal.fun <- function(x) {
> x <- (x * mult) + add
> }
> 
> s.cal <- calc(s, cal.fun, progress='text')
> 
> 
> Any ideas on how to do that?
> 
> Many thanks,
> --
> Thiago V. dos Santos
> PhD student
> Land and Atmospheric Science
> University of Minnesota
> http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSa
> ntos/index.htm
> Phone: (612) 323 9898
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From loic.dutrieux at wur.nl  Fri Feb  6 09:06:55 2015
From: loic.dutrieux at wur.nl (Dutrieux, Loic)
Date: Fri, 6 Feb 2015 08:06:55 +0000
Subject: [R-sig-Geo] How to apply this function on each raster stack
 layer?
In-Reply-To: <B078CDF40DFE4045AF172A8B4F68FC4857CCD6A794@DKRDSEXC016.vestas.net>
References: <109259438.222447.1423160545467.JavaMail.yahoo@mail.yahoo.com>,
	<B078CDF40DFE4045AF172A8B4F68FC4857CCD6A794@DKRDSEXC016.vestas.net>
Message-ID: <1423210015097.16399@wur.nl>

Hi Thiago,

The approach you took seems correct. See example below.

library(raster)
fn <- system.file("external/test.grd", package="raster")
s  <- stack(fn, fn)

# And these are sample coefficients:
mult <- c(0.0003342, 0.0005534) 
add  <- c(0.1, 0.2) 

# define calc function
fun <- function(x) {
    y <- x * mult + add
    return(y)
}

out <- calc(x = s, fun = fun)

# For each band individually
s2 <- s
s2[[1]] <- (s2[[1]] * mult[1]) + add[1]
s2[[2]] <- (s2[[2]] * mult[2]) + add[2]

all.equal(out, s2)


Best regards,
---
Lo?c Dutrieux
PhD student
Laboratory of Geo Information Science and Remote Sensing
Wageningen University
The Netherlands
________________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of Frede Aakmann T?gersen <frtog at vestas.com>
Sent: Friday, February 6, 2015 7:25 AM
To: Thiago V. dos Santos; R-SIG list
Subject: Re: [R-sig-Geo] How to apply this function on each raster stack layer?

Hi Thiago

I think that the forceapply argument of calc() is what you need; see ?calc. Here is the relevant part from the man:

     The intent of some functions can be ambiguous. Consider:

     'library(raster)'

     'r <- raster(volcano)'

     'calc(r, function(x) x * 1:10)'

     In this case, the cell values are multiplied in a vectorized
     manner and a single layer is returned where the first cell has
     been multiplied with one, the second cell with two, the 11th cell
     with one again, and so on. But perhaps the intent was to create 10
     new layers ('x*1, x*2, ...')? This can be achieved by using
     argument 'forceapply=TRUE'

     'calc(r, function(x) x * 1:10), forceapply=TRUE'


Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender.


> -----Original Message-----
> From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of
> Thiago V. dos Santos
> Sent: 5. februar 2015 19:22
> To: R-SIG list
> Subject: [R-sig-Geo] How to apply this function on each raster stack layer?
>
> Hi all,
>
> I am trying to write an efficient script to calibrate hundreds of Landsat 8
> images. At a certain point of the calibration steps, I need to apply some
> coefficients in each layer of a raster stack.
>
>
> This is one sample stack:fn <- system.file("external/test.grd",
> package="raster")
>
> s  <- stack(fn, fn)
>
> And these are sample coefficients:
> mult <- c(0.0003342, 0.0005534)
> add  <- c(0.1, 0.2)
>
>
> What I need to is to apply each index of the coefficients to the
> correspondent index of the stack layer, like in this example:
>
> s[[1]] <- (s[[1]] * mult[1]) + add[1]
> s[[2]] <- (s[[2]] * mult[2]) + add[2]
>
> This is my poor attempt, which obviously does not work:
>
> cal.fun <- function(x) {
> x <- (x * mult) + add
> }
>
> s.cal <- calc(s, cal.fun, progress='text')
>
>
> Any ideas on how to do that?
>
> Many thanks,
> --
> Thiago V. dos Santos
> PhD student
> Land and Atmospheric Science
> University of Minnesota
> http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSa
> ntos/index.htm
> Phone: (612) 323 9898
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Fri Feb  6 11:04:53 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 6 Feb 2015 11:04:53 +0100
Subject: [R-sig-Geo] gDistance problem on RHEL 6 64-bit
In-Reply-To: <BN3PR09MB03383AB3E12AE9FA663BB0E6813B0@BN3PR09MB0338.namprd09.prod.outlook.com>
References: <BY1PR09MB0341DDD0B8A7B28AF5E4AEDA813B0@BY1PR09MB0341.namprd09.prod.outlook.com>
	<alpine.LFD.2.11.1502052113440.11015@reclus.nhh.no>
	<BN3PR09MB03383AB3E12AE9FA663BB0E6813B0@BN3PR09MB0338.namprd09.prod.outlook.com>
Message-ID: <alpine.LFD.2.11.1502061043490.26800@reclus.nhh.no>

On Thu, 5 Feb 2015, Hollister, Jeff wrote:

> Roger,
>
> Thanks for getting back to me.  I thought it was a GEOS problem too.  I 
> have updated it and re-installed rgeos.
>
> Curret GEOS is:
>> version_GEOS()
> [1] "3.4.2-CAPI-1.8.2 r3921"
>
> I tried several of the other rgeos examples (gBuffer, gWithin, 
> gEnvelope, gUnion, gLength ...) and they all worked.  gDistance bombs 
> the same as before, as does gWithinDistance.
>
> My version of gcc appears to be a bit old:
>
> -bash-4.1$ gcc --version
> gcc (GCC) 4.4.7 20120313 (Red Hat 4.4.7-11)
>
> Could that be the issue?

No, since the other examples work, it isn't likely. On my former RHEL5, 
gcc is 4.1.2 of 2008 and still works.

If you need to follow this up, that is that your RHEL6 machine is mission 
critical, make sure that it is fully updated, remove and reinstall GEOS, 
run /sbin/ldconfig, look for other GEOS installations, remove all GEOS, 
reinstall GEOS; once you are sure that GEOS is installed uniquely, and 
runs its own make check correctly, remove rgeos and reinstall it. If the 
problem persists, run R under GDB (R -d gdb) to give a traceback on error, 
and run:

.Call("rgeos_distance", rgeos:::.RGEOS_HANDLE, pt2, pt1, c(FALSE, FALSE),
   PACKAGE = "rgeos")

as the most stripped-down version. What is of interest is where in 
src/rgeos_misc.c in rgeos_distancefunc() the failure occurs, that is, does 
it occur in converting the sp objects into GEOS representation, in 
computing the distance, or in destroying the GEOS representations of the 
input objects?

Does gDistance(pt2, pt1, byid=TRUE) make a difference (probably not)?

Roger


>
> Thanks again for your help!
> Cheers,
> Jeff
>
>
>
> *****************************
> Dr. Jeffrey W. Hollister
> Research Ecologist
> 27 Tarzwell Drive
> Narragansett, RI 02879
> (o) 401 782 9655
> hollister.jeff at epa.gov
> Personal Site
> *****************************
>
> -----Original Message-----
> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Sent: Thursday, February 05, 2015 3:28 PM
> To: Hollister, Jeff
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] gDistance problem on RHEL 6 64-bit
>
> On Thu, 5 Feb 2015, Hollister, Jeff wrote:
>
>> Hello all,
>>
>> I am having a problem with rgeos::gDistance on RHEL 6.  Everytime I
>> try to get a point to point distance, I get
>>
>> R: GeometryComponentFilter.cpp:34: virtual void 
>> geos::geom::GeometryComponentFilter::filter_ro(const 
>> geos::geom::Geometry*): Assertion `0' failed. Aborted (core dumped)
>>
>> This only occurs on my RHEL 6 machine.  Win 7 and Ubuntu 14.04 work fine.
>
> The key question is how you installed rgeos and GEOS on these platforms.
> Most likely rgeos on Windows 7 is the CRAN binary statically linked to GEOS, and on RHEL6 and Ubuntu 14.04 rgeos is installed from source and links to the GEOS found on those platforms. We need the output of:
>
> version_GEOS()
>
> on each platform. Most likely you've not installed GEOS from source on either of the two Linux platforms. The cause is most likely a mismatch on the RHEL platform, possibly that GEOS has fallen behind C++, or that GEOS got updated without you re-installing rgeos. Is gDistance() the only function that doesn't work - can you run example(gDistance) and/or the examples of other functions?
>
> Roger
>
>>
>> Some code to reproduce the problem:
>> library(sp)
>> library(rgeos)
>> pt1<-SpatialPoints(data.frame(x=c(1,3),y=c(3,1)))
>> pt2<-SpatialPoints(data.frame(x=1,y=1))
>> gDistance(pt2,pt1)
>>
>> More info:
>>> sessionInfo()
>> R version 3.1.2 (2014-10-31)
>> Platform: x86_64-redhat-linux-gnu (64-bit)
>>
>> locale:
>> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] rgeos_0.3-8 sp_1.0-15
>>
>> loaded via a namespace (and not attached):
>> [1] grid_3.1.2      lattice_0.20-29
>>
>> Thanks,
>> Jeff Hollister
>>
>> *****************************
>> Dr. Jeffrey W. Hollister
>> Research Ecologist
>> 27 Tarzwell Drive
>> Narragansett, RI 02879
>> (o) 401 782 9655
>> hollister.jeff at epa.gov<mailto:hollister.jeff at epa.gov>
>> Personal Site<http://jwhollister.com/>
>> *****************************
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics, Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From Hollister.Jeff at epa.gov  Fri Feb  6 17:00:49 2015
From: Hollister.Jeff at epa.gov (Hollister, Jeff)
Date: Fri, 6 Feb 2015 16:00:49 +0000
Subject: [R-sig-Geo] gDistance problem on RHEL 6 64-bit
In-Reply-To: <alpine.LFD.2.11.1502061043490.26800@reclus.nhh.no>
References: <BY1PR09MB0341DDD0B8A7B28AF5E4AEDA813B0@BY1PR09MB0341.namprd09.prod.outlook.com>
	<alpine.LFD.2.11.1502052113440.11015@reclus.nhh.no>
	<BN3PR09MB03383AB3E12AE9FA663BB0E6813B0@BN3PR09MB0338.namprd09.prod.outlook.com>
	<alpine.LFD.2.11.1502061043490.26800@reclus.nhh.no>
Message-ID: <BN3PR09MB03381093246554E88C6C8A6A81380@BN3PR09MB0338.namprd09.prod.outlook.com>

Roger,

Thanks again for your help on this.  It is appreciated!

I'll work on getting everything removed and start from what is hopefully a clean install of GEOS and rgeos and go from there.  Will let the list know what I find out.

Also, byid=T bombs out the same.

Cheers,
Jeff



-----Original Message-----
From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Sent: Friday, February 06, 2015 5:05 AM
To: Hollister, Jeff
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] gDistance problem on RHEL 6 64-bit

On Thu, 5 Feb 2015, Hollister, Jeff wrote:

> Roger,
>
> Thanks for getting back to me.  I thought it was a GEOS problem too.  
> I have updated it and re-installed rgeos.
>
> Curret GEOS is:
>> version_GEOS()
> [1] "3.4.2-CAPI-1.8.2 r3921"
>
> I tried several of the other rgeos examples (gBuffer, gWithin, 
> gEnvelope, gUnion, gLength ...) and they all worked.  gDistance bombs 
> the same as before, as does gWithinDistance.
>
> My version of gcc appears to be a bit old:
>
> -bash-4.1$ gcc --version
> gcc (GCC) 4.4.7 20120313 (Red Hat 4.4.7-11)
>
> Could that be the issue?

No, since the other examples work, it isn't likely. On my former RHEL5, gcc is 4.1.2 of 2008 and still works.

If you need to follow this up, that is that your RHEL6 machine is mission critical, make sure that it is fully updated, remove and reinstall GEOS, run /sbin/ldconfig, look for other GEOS installations, remove all GEOS, reinstall GEOS; once you are sure that GEOS is installed uniquely, and runs its own make check correctly, remove rgeos and reinstall it. If the problem persists, run R under GDB (R -d gdb) to give a traceback on error, and run:

.Call("rgeos_distance", rgeos:::.RGEOS_HANDLE, pt2, pt1, c(FALSE, FALSE),
   PACKAGE = "rgeos")

as the most stripped-down version. What is of interest is where in src/rgeos_misc.c in rgeos_distancefunc() the failure occurs, that is, does it occur in converting the sp objects into GEOS representation, in computing the distance, or in destroying the GEOS representations of the input objects?

Does gDistance(pt2, pt1, byid=TRUE) make a difference (probably not)?

Roger


>
> Thanks again for your help!
> Cheers,
> Jeff
>
>
>
> *****************************
> Dr. Jeffrey W. Hollister
> Research Ecologist
> 27 Tarzwell Drive
> Narragansett, RI 02879
> (o) 401 782 9655
> hollister.jeff at epa.gov
> Personal Site
> *****************************
>
> -----Original Message-----
> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Sent: Thursday, February 05, 2015 3:28 PM
> To: Hollister, Jeff
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] gDistance problem on RHEL 6 64-bit
>
> On Thu, 5 Feb 2015, Hollister, Jeff wrote:
>
>> Hello all,
>>
>> I am having a problem with rgeos::gDistance on RHEL 6.  Everytime I 
>> try to get a point to point distance, I get
>>
>> R: GeometryComponentFilter.cpp:34: virtual void 
>> geos::geom::GeometryComponentFilter::filter_ro(const
>> geos::geom::Geometry*): Assertion `0' failed. Aborted (core dumped)
>>
>> This only occurs on my RHEL 6 machine.  Win 7 and Ubuntu 14.04 work fine.
>
> The key question is how you installed rgeos and GEOS on these platforms.
> Most likely rgeos on Windows 7 is the CRAN binary statically linked to GEOS, and on RHEL6 and Ubuntu 14.04 rgeos is installed from source and links to the GEOS found on those platforms. We need the output of:
>
> version_GEOS()
>
> on each platform. Most likely you've not installed GEOS from source on either of the two Linux platforms. The cause is most likely a mismatch on the RHEL platform, possibly that GEOS has fallen behind C++, or that GEOS got updated without you re-installing rgeos. Is gDistance() the only function that doesn't work - can you run example(gDistance) and/or the examples of other functions?
>
> Roger
>
>>
>> Some code to reproduce the problem:
>> library(sp)
>> library(rgeos)
>> pt1<-SpatialPoints(data.frame(x=c(1,3),y=c(3,1)))
>> pt2<-SpatialPoints(data.frame(x=1,y=1))
>> gDistance(pt2,pt1)
>>
>> More info:
>>> sessionInfo()
>> R version 3.1.2 (2014-10-31)
>> Platform: x86_64-redhat-linux-gnu (64-bit)
>>
>> locale:
>> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] rgeos_0.3-8 sp_1.0-15
>>
>> loaded via a namespace (and not attached):
>> [1] grid_3.1.2      lattice_0.20-29
>>
>> Thanks,
>> Jeff Hollister
>>
>> *****************************
>> Dr. Jeffrey W. Hollister
>> Research Ecologist
>> 27 Tarzwell Drive
>> Narragansett, RI 02879
>> (o) 401 782 9655
>> hollister.jeff at epa.gov<mailto:hollister.jeff at epa.gov>
>> Personal Site<http://jwhollister.com/>
>> *****************************
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics, Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

--
Roger Bivand
Department of Economics, Norwegian School of Economics, Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From Dominik.Schneider at colorado.edu  Fri Feb  6 18:32:14 2015
From: Dominik.Schneider at colorado.edu (dschneiderch)
Date: Fri, 6 Feb 2015 10:32:14 -0700 (MST)
Subject: [R-sig-Geo] writeRaster does not preserve names when writing to
	NetCDF
In-Reply-To: <CANVKczMa+8dDdoeMueHus2VV6gS0Oet0kBs08h6om0iog0+XnQ@mail.gmail.com>
References: <CAGBzUO8nkr3xUYyaG_xaFa5n3uoLMRT3W5Qnm2bPUgLA4DAY9A@mail.gmail.com>
	<CANVKczOsi_FQu=maNYmwvUJWabCnpGd9b8fHRoqdEa2C1rNxBg@mail.gmail.com>
	<CANVKczMa+8dDdoeMueHus2VV6gS0Oet0kBs08h6om0iog0+XnQ@mail.gmail.com>
Message-ID: <1423243934203-7587744.post@n2.nabble.com>

I was running into this problem and wondering if there was any progress?
As a workaround, I was trying to add an attribute to my variable using
ncput_att but it doesn't show more than 1 (no warning was shown that only 1
could be accepted and the min/max attributes have a value for each layer).

r=raster(matrix(runif(9),nrow=3))
r2=raster(matrix(runif(9),nrow=3))
s=stack(r,r2)
names(s)=c('X20120101','X20120108')

writeRaster(s,filename='~/Desktop/test.nc', format='CDF', varname='swe',
varunit='meters', xname='long', xunit='deg', yname='lat', yunit='deg',
zname='time', zunit='day', overwrite=T, NAflag=-99)

#Note the names of the written stack are generic.
#Now I try to add an attribute to the swe variable in the file so I can
retrieve later but it only lists the first name
n=nc_open('~/Desktop/test.nc',write=T)
ncatt_put(n,varid='swe',attname='dates',attval=names(s),prec='text')
nc_close(n)

nc_open('~/Desktop/test.nc',write=F)
File ~/Desktop/test.nc (NC_FORMAT_CLASSIC):

     1 variables (excluding dimension variables):
        float swe[long,lat,time]   
            units: meters
            _FillValue: -99
            missing_value: -99
            long_name: swe
            min: 0.0572868520393968
             min: 0.1845921901986
            max: 0.852122258627787
             max: 0.772868746891618
            dates: X20120101

     3 dimensions:
        long  Size:3
            units: degrees_east
            long_name: long
        lat  Size:3
            units: degrees_north
            long_name: lat
        time  Size:2   *** is unlimited ***
            units: day
            long_name: time

    3 global attributes:
        Conventions: CF-1.4
        created_by: R, packages ncdf and raster (version 2.3-24)
        date: 2015-02-06 10:18:51


Could that be a bug in ncatt_put? Or, are there any suggestions for storing
irregular spatial-temporal data (consistent spatial grid, but inconsistent
time slices that therefore require some annotation about the date)
 



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/writeRaster-does-not-preserve-names-when-writing-to-NetCDF-tp7586909p7587744.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Dominik.Schneider at colorado.edu  Fri Feb  6 18:42:28 2015
From: Dominik.Schneider at colorado.edu (dschneiderch)
Date: Fri, 6 Feb 2015 10:42:28 -0700 (MST)
Subject: [R-sig-Geo] stack many files without loading into memory
In-Reply-To: <CAAcGz99D1K8_+y7=exw7Pv5NqaCsfDA6Aa2N5uvEfvtKZENpqw@mail.gmail.com>
References: <CAHYDKLY3GBbCk8dNw0Jpp0xy-vxAxdbhZdEjSqv339W2Yfmj9Q@mail.gmail.com>
	<CAAcGz99tz-Dw4=KLX1zRYupXRv5++ObTeL8n3HGSfSJia3HOzQ@mail.gmail.com>
	<CAHYDKLZD8wm0_ZJZin9EtcjEZW3EQ8R_qGosnGdOducKMqGw9g@mail.gmail.com>
	<CAHYDKLbEVfxYLzeHBJAbRUQxx+RwYCYtGfNoz4o6s2HP0Yc48A@mail.gmail.com>
	<CAAcGz99D1K8_+y7=exw7Pv5NqaCsfDA6Aa2N5uvEfvtKZENpqw@mail.gmail.com>
Message-ID: <1423244548009-7587745.post@n2.nabble.com>

Hi Michael -
Yes saving as GTiff with the compression options reduced the file size from
~10MB to ~2.5M for a single file but I am having a lot of trouble getting it
to save the whole stack. I'm definitely running out of memory on my computer
so maybe R is being slow and timing out? I've left it overnight with no
success (for a single year). That said, is there some overhead involved in
this? 112files * 10MB is only 1.12 GB 
I might try this on the command line with gdal tools.

Another issue that I'm encountering is that I don't seem to be able to save
layer names either in GTiff or CDF. Since these are ~100 remote sensing
images from the year, I need to be able to annotate the layer name so I know
the date (I actually posted onto an older thread about this specific to CDF
format because it came up in something else I was doing.)
Thanks for your help.



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/stack-many-files-without-loading-into-memory-tp7587729p7587745.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Hollister.Jeff at epa.gov  Fri Feb  6 19:17:21 2015
From: Hollister.Jeff at epa.gov (Hollister, Jeff)
Date: Fri, 6 Feb 2015 18:17:21 +0000
Subject: [R-sig-Geo] gDistance problem on RHEL 6 64-bit
In-Reply-To: <alpine.LFD.2.11.1502061043490.26800@reclus.nhh.no>
References: <BY1PR09MB0341DDD0B8A7B28AF5E4AEDA813B0@BY1PR09MB0341.namprd09.prod.outlook.com>
	<alpine.LFD.2.11.1502052113440.11015@reclus.nhh.no>
	<BN3PR09MB03383AB3E12AE9FA663BB0E6813B0@BN3PR09MB0338.namprd09.prod.outlook.com>
	<alpine.LFD.2.11.1502061043490.26800@reclus.nhh.no>
Message-ID: <BN3PR09MB0338ABA0D06ECB4FA0AD26F681380@BN3PR09MB0338.namprd09.prod.outlook.com>

Roger (and List),

I think I am giving up on this one.  

make check failed with:
lt-XMLTester: ../../../source/headers/geos/geom/GeometryFilter.h:61: virtual void geos::geom::GeometryFilter::filter_ro(const geos::geom::Geometry*): Assertion `0' failed.
./testrunner: line 1:  2094 Aborted                 (core dumped) ./XMLTester -v ./testLeaksBig.xml ./hexwkb.xml ./test.xml ./linemerge.xml ./TestInteriorPoint.xml ./TestCentroid.xml .
FAIL: testrunner

I even tried various versions of GEOS (3.3.9, 3.1.1) with the same result on make check.

I am thinking it is something specific to this machine.  I have other machines available that work fine so will use those instead.  If I do eventually track down what was causing the problem I will provide an update.

Thanks again!

Jeff

*****************************
Dr. Jeffrey W. Hollister
Research Ecologist
27 Tarzwell Drive
Narragansett, RI 02879
(o) 401 782 9655
hollister.jeff at epa.gov
Personal Site
*****************************

-----Original Message-----
From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Sent: Friday, February 06, 2015 5:05 AM
To: Hollister, Jeff
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] gDistance problem on RHEL 6 64-bit

On Thu, 5 Feb 2015, Hollister, Jeff wrote:

> Roger,
>
> Thanks for getting back to me.  I thought it was a GEOS problem too.  
> I have updated it and re-installed rgeos.
>
> Curret GEOS is:
>> version_GEOS()
> [1] "3.4.2-CAPI-1.8.2 r3921"
>
> I tried several of the other rgeos examples (gBuffer, gWithin, 
> gEnvelope, gUnion, gLength ...) and they all worked.  gDistance bombs 
> the same as before, as does gWithinDistance.
>
> My version of gcc appears to be a bit old:
>
> -bash-4.1$ gcc --version
> gcc (GCC) 4.4.7 20120313 (Red Hat 4.4.7-11)
>
> Could that be the issue?

No, since the other examples work, it isn't likely. On my former RHEL5, gcc is 4.1.2 of 2008 and still works.

If you need to follow this up, that is that your RHEL6 machine is mission critical, make sure that it is fully updated, remove and reinstall GEOS, run /sbin/ldconfig, look for other GEOS installations, remove all GEOS, reinstall GEOS; once you are sure that GEOS is installed uniquely, and runs its own make check correctly, remove rgeos and reinstall it. If the problem persists, run R under GDB (R -d gdb) to give a traceback on error, and run:

.Call("rgeos_distance", rgeos:::.RGEOS_HANDLE, pt2, pt1, c(FALSE, FALSE),
   PACKAGE = "rgeos")

as the most stripped-down version. What is of interest is where in src/rgeos_misc.c in rgeos_distancefunc() the failure occurs, that is, does it occur in converting the sp objects into GEOS representation, in computing the distance, or in destroying the GEOS representations of the input objects?

Does gDistance(pt2, pt1, byid=TRUE) make a difference (probably not)?

Roger


>
> Thanks again for your help!
> Cheers,
> Jeff
>
>
>
> *****************************
> Dr. Jeffrey W. Hollister
> Research Ecologist
> 27 Tarzwell Drive
> Narragansett, RI 02879
> (o) 401 782 9655
> hollister.jeff at epa.gov
> Personal Site
> *****************************
>
> -----Original Message-----
> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Sent: Thursday, February 05, 2015 3:28 PM
> To: Hollister, Jeff
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] gDistance problem on RHEL 6 64-bit
>
> On Thu, 5 Feb 2015, Hollister, Jeff wrote:
>
>> Hello all,
>>
>> I am having a problem with rgeos::gDistance on RHEL 6.  Everytime I 
>> try to get a point to point distance, I get
>>
>> R: GeometryComponentFilter.cpp:34: virtual void 
>> geos::geom::GeometryComponentFilter::filter_ro(const
>> geos::geom::Geometry*): Assertion `0' failed. Aborted (core dumped)
>>
>> This only occurs on my RHEL 6 machine.  Win 7 and Ubuntu 14.04 work fine.
>
> The key question is how you installed rgeos and GEOS on these platforms.
> Most likely rgeos on Windows 7 is the CRAN binary statically linked to GEOS, and on RHEL6 and Ubuntu 14.04 rgeos is installed from source and links to the GEOS found on those platforms. We need the output of:
>
> version_GEOS()
>
> on each platform. Most likely you've not installed GEOS from source on either of the two Linux platforms. The cause is most likely a mismatch on the RHEL platform, possibly that GEOS has fallen behind C++, or that GEOS got updated without you re-installing rgeos. Is gDistance() the only function that doesn't work - can you run example(gDistance) and/or the examples of other functions?
>
> Roger
>
>>
>> Some code to reproduce the problem:
>> library(sp)
>> library(rgeos)
>> pt1<-SpatialPoints(data.frame(x=c(1,3),y=c(3,1)))
>> pt2<-SpatialPoints(data.frame(x=1,y=1))
>> gDistance(pt2,pt1)
>>
>> More info:
>>> sessionInfo()
>> R version 3.1.2 (2014-10-31)
>> Platform: x86_64-redhat-linux-gnu (64-bit)
>>
>> locale:
>> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] rgeos_0.3-8 sp_1.0-15
>>
>> loaded via a namespace (and not attached):
>> [1] grid_3.1.2      lattice_0.20-29
>>
>> Thanks,
>> Jeff Hollister
>>
>> *****************************
>> Dr. Jeffrey W. Hollister
>> Research Ecologist
>> 27 Tarzwell Drive
>> Narragansett, RI 02879
>> (o) 401 782 9655
>> hollister.jeff at epa.gov<mailto:hollister.jeff at epa.gov>
>> Personal Site<http://jwhollister.com/>
>> *****************************
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics, Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

--
Roger Bivand
Department of Economics, Norwegian School of Economics, Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From thi_veloso at yahoo.com.br  Fri Feb  6 20:40:39 2015
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Fri, 6 Feb 2015 19:40:39 +0000 (UTC)
Subject: [R-sig-Geo] How to apply this function on each raster stack
 layer?
In-Reply-To: <1423210015097.16399@wur.nl>
References: <1423210015097.16399@wur.nl>
Message-ID: <894127247.590885.1423251639364.JavaMail.yahoo@mail.yahoo.com>

Frede and Loic,
Thanks a lot for your feedback. I just realized that a simple multiplication?
s1 <- (s * mult) + add
not only works but is much faster than the function I wrote. Raster is a really well-implemented package.?Greetings,
--
Thiago V. dos Santos
PhD student
Land and Atmospheric Science
University of Minnesota
http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
Phone: (612) 323 9898 

     On Friday, February 6, 2015 2:07 AM, "Dutrieux, Loic" <loic.dutrieux at wur.nl> wrote:
   

 Hi Thiago,

The approach you took seems correct. See example below.

library(raster)
fn <- system.file("external/test.grd", package="raster")
s? <- stack(fn, fn)

# And these are sample coefficients:
mult <- c(0.0003342, 0.0005534) 
add? <- c(0.1, 0.2) 

# define calc function
fun <- function(x) {
? ? y <- x * mult + add
? ? return(y)
}

out <- calc(x = s, fun = fun)

# For each band individually
s2 <- s
s2[[1]] <- (s2[[1]] * mult[1]) + add[1]
s2[[2]] <- (s2[[2]] * mult[2]) + add[2]

all.equal(out, s2)


Best regards,
---
Lo?c Dutrieux
PhD student
Laboratory of Geo Information Science and Remote Sensing
Wageningen University
The Netherlands
________________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of Frede Aakmann T?gersen <frtog at vestas.com>
Sent: Friday, February 6, 2015 7:25 AM
To: Thiago V. dos Santos; R-SIG list
Subject: Re: [R-sig-Geo] How to apply this function on each raster stack layer?

Hi Thiago

I think that the forceapply argument of calc() is what you need; see ?calc. Here is the relevant part from the man:

? ? The intent of some functions can be ambiguous. Consider:

? ? 'library(raster)'

? ? 'r <- raster(volcano)'

? ? 'calc(r, function(x) x * 1:10)'

? ? In this case, the cell values are multiplied in a vectorized
? ? manner and a single layer is returned where the first cell has
? ? been multiplied with one, the second cell with two, the 11th cell
? ? with one again, and so on. But perhaps the intent was to create 10
? ? new layers ('x*1, x*2, ...')? This can be achieved by using
? ? argument 'forceapply=TRUE'

? ? 'calc(r, function(x) x * 1:10), forceapply=TRUE'


Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender.


> -----Original Message-----
> From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of
> Thiago V. dos Santos
> Sent: 5. februar 2015 19:22
> To: R-SIG list
> Subject: [R-sig-Geo] How to apply this function on each raster stack layer?
>
> Hi all,
>
> I am trying to write an efficient script to calibrate hundreds of Landsat 8
> images. At a certain point of the calibration steps, I need to apply some
> coefficients in each layer of a raster stack.
>
>
> This is one sample stack:fn <- system.file("external/test.grd",
> package="raster")
>
> s? <- stack(fn, fn)
>
> And these are sample coefficients:
> mult <- c(0.0003342, 0.0005534)
> add? <- c(0.1, 0.2)
>
>
> What I need to is to apply each index of the coefficients to the
> correspondent index of the stack layer, like in this example:
>
> s[[1]] <- (s[[1]] * mult[1]) + add[1]
> s[[2]] <- (s[[2]] * mult[2]) + add[2]
>
> This is my poor attempt, which obviously does not work:
>
> cal.fun <- function(x) {
> x <- (x * mult) + add
> }
>
> s.cal <- calc(s, cal.fun, progress='text')
>
>
> Any ideas on how to do that?
>
> Many thanks,
> --
> Thiago V. dos Santos
> PhD student
> Land and Atmospheric Science
> University of Minnesota
> http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSa
> ntos/index.htm
> Phone: (612) 323 9898
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


   
	[[alternative HTML version deleted]]


From Dominik.Schneider at colorado.edu  Fri Feb  6 21:30:16 2015
From: Dominik.Schneider at colorado.edu (dschneiderch)
Date: Fri, 6 Feb 2015 13:30:16 -0700 (MST)
Subject: [R-sig-Geo] stack many files without loading into memory
In-Reply-To: <1423244548009-7587745.post@n2.nabble.com>
References: <CAHYDKLY3GBbCk8dNw0Jpp0xy-vxAxdbhZdEjSqv339W2Yfmj9Q@mail.gmail.com>
	<CAAcGz99tz-Dw4=KLX1zRYupXRv5++ObTeL8n3HGSfSJia3HOzQ@mail.gmail.com>
	<CAHYDKLZD8wm0_ZJZin9EtcjEZW3EQ8R_qGosnGdOducKMqGw9g@mail.gmail.com>
	<CAHYDKLbEVfxYLzeHBJAbRUQxx+RwYCYtGfNoz4o6s2HP0Yc48A@mail.gmail.com>
	<CAAcGz99D1K8_+y7=exw7Pv5NqaCsfDA6Aa2N5uvEfvtKZENpqw@mail.gmail.com>
	<1423244548009-7587745.post@n2.nabble.com>
Message-ID: <1423254616364-7587748.post@n2.nabble.com>

Ok -  Looks like it worked this time for 112 files from 2012. The netcdf is
2.25 GB while the compressed multiband geotiff is 510MB. Does the netcdf
have so much overhead- the 112 file at 10MB each are only 1.12 GB
individually?
I like the tidiness of 1 file per year so I'll have to play with how easily
these can be accessed and the best way of annotating the layers. I was just
reading that netcdf4 is based on hdf5 with a subset of features so I might
look to see if hdf5 can do what I want. 
Thanks
ds



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/stack-many-files-without-loading-into-memory-tp7587729p7587748.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From thi_veloso at yahoo.com.br  Fri Feb  6 23:06:31 2015
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Fri, 6 Feb 2015 22:06:31 +0000 (UTC)
Subject: [R-sig-Geo] Applying a simple math on a big stack takes a long
 time. How to improve it?
Message-ID: <64629957.617777.1423260391801.JavaMail.yahoo@mail.yahoo.com>

Hi all,

I am processing some GeoTiff rasters with 60 files in total (might be more), which are relatively big: resolution is about 7800 x 7700 at 30m res and total file size is around 120MB (Landsat 8 images). I am trying to do a simple math equation calculation (please see the end of the code) on a stack of six of those images:



# create some artificial data 
# this is used within a loop with all files (~60) in the directory 

r <- raster(nrows=7801, ncols=7711) 
r[] <- runif(ncell(r),0,65000) 
s.dn <- stack(r,r,r,r,r,r) 

# Define calibration factors 
rad.mult.fact <- c(0.012852, 0.013161, 0.012128, 
0.010227, 0.006258, 0.001556) 

rad.add.fact  <- c(-64.2618, -65.8048, -60.6386, 
-51.1339, -31.2914) 

#convert DN to TOA radiance 
s.rad <- (s.dn * rad.mult.fact) + rad.add.fact

#write file 
writeRaster(s.rad, filename='teste.tif', format="GTiff", overwrite=TRUE) 



The calculation runs extremely slow and takes about 10 minutes on my dual-core system with 8GB RAM. Three 2.8GB files are written on my temp dir during calculations. Finally, by the end I receive a warning:



Warning message: 
In (s.img * rad.mult.fact) + rad.add.fact : 
number of items to replace is not a multiple of replacement length 


I wonder if there is a way to optimise that script? And why calculation is so slow in my case? What is causing the warning message and how to fix it?

Many thanks,
--
Thiago V. dos Santos
PhD student
Land and Atmospheric Science
University of Minnesota
http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
Phone: (612) 323 9898


From jbaldwin at fs.fed.us  Fri Feb  6 23:55:09 2015
From: jbaldwin at fs.fed.us (Baldwin, Jim -FS)
Date: Fri, 6 Feb 2015 22:55:09 +0000
Subject: [R-sig-Geo] Applying a simple math on a big stack takes a long
 time. How to improve it?
In-Reply-To: <64629957.617777.1423260391801.JavaMail.yahoo@mail.yahoo.com>
References: <64629957.617777.1423260391801.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <DDC5EC9B78340042B0D5A0C3789D45691A5303E2@001FSN2MPN1-061.001f.mgd2.msft.net>

rad.mult.fact has length 6 and rad.add.fact has length 5.  Does that affect the calculations?

Jim


-----Original Message-----
From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Thiago V. dos Santos
Sent: Friday, February 06, 2015 2:07 PM
To: R-SIG list
Subject: [R-sig-Geo] Applying a simple math on a big stack takes a long time. How to improve it?

Hi all,

I am processing some GeoTiff rasters with 60 files in total (might be more), which are relatively big: resolution is about 7800 x 7700 at 30m res and total file size is around 120MB (Landsat 8 images). I am trying to do a simple math equation calculation (please see the end of the code) on a stack of six of those images:



# create some artificial data
# this is used within a loop with all files (~60) in the directory

r <- raster(nrows=7801, ncols=7711)
r[] <- runif(ncell(r),0,65000)
s.dn <- stack(r,r,r,r,r,r)

# Define calibration factors
rad.mult.fact <- c(0.012852, 0.013161, 0.012128, 0.010227, 0.006258, 0.001556)

rad.add.fact  <- c(-64.2618, -65.8048, -60.6386, -51.1339, -31.2914)

#convert DN to TOA radiance
s.rad <- (s.dn * rad.mult.fact) + rad.add.fact

#write file
writeRaster(s.rad, filename='teste.tif', format="GTiff", overwrite=TRUE)



The calculation runs extremely slow and takes about 10 minutes on my dual-core system with 8GB RAM. Three 2.8GB files are written on my temp dir during calculations. Finally, by the end I receive a warning:



Warning message:
In (s.img * rad.mult.fact) + rad.add.fact :
number of items to replace is not a multiple of replacement length


I wonder if there is a way to optimise that script? And why calculation is so slow in my case? What is causing the warning message and how to fix it?

Many thanks,
--
Thiago V. dos Santos
PhD student
Land and Atmospheric Science
University of Minnesota
http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
Phone: (612) 323 9898

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo




This electronic message contains information generated by the USDA solely for the intended recipients. Any unauthorized interception of this message or the use or disclosure of the information it contains may violate the law and subject the violator to civil or criminal penalties. If you believe you have received this message in error, please notify the sender and delete the email immediately.


From thi_veloso at yahoo.com.br  Sat Feb  7 00:14:22 2015
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Fri, 6 Feb 2015 23:14:22 +0000 (UTC)
Subject: [R-sig-Geo] Applying a simple math on a big stack takes a long
 time. How to improve it?
In-Reply-To: <DDC5EC9B78340042B0D5A0C3789D45691A5303E2@001FSN2MPN1-061.001f.mgd2.msft.net>
References: <DDC5EC9B78340042B0D5A0C3789D45691A5303E2@001FSN2MPN1-061.001f.mgd2.msft.net>
Message-ID: <374746120.647413.1423264462883.JavaMail.yahoo@mail.yahoo.com>

Ops, by bad, I missed one value when writing the simplified script to the list. The correct vector should be:

rad.add.fact  <- c(-64.2618, -65.8048, -60.6386, 
-51.1339, -31.2914, -28.2876) 


Thanks for pointing that out.

This vanishes the warning message but apparently doesn't affect the calculation since it is still VERY slow.

 
Greetings,
--
Thiago V. dos Santos
PhD student
Land and Atmospheric Science
University of Minnesota
http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
Phone: (612) 323 9898



On Friday, February 6, 2015 4:55 PM, "Baldwin, Jim -FS" <jbaldwin at fs.fed.us> wrote:
rad.mult.fact has length 6 and rad.add.fact has length 5.  Does that affect the calculations?

Jim



-----Original Message-----
From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Thiago V. dos Santos
Sent: Friday, February 06, 2015 2:07 PM
To: R-SIG list
Subject: [R-sig-Geo] Applying a simple math on a big stack takes a long time. How to improve it?

Hi all,

I am processing some GeoTiff rasters with 60 files in total (might be more), which are relatively big: resolution is about 7800 x 7700 at 30m res and total file size is around 120MB (Landsat 8 images). I am trying to do a simple math equation calculation (please see the end of the code) on a stack of six of those images:



# create some artificial data
# this is used within a loop with all files (~60) in the directory

r <- raster(nrows=7801, ncols=7711)
r[] <- runif(ncell(r),0,65000)
s.dn <- stack(r,r,r,r,r,r)

# Define calibration factors
rad.mult.fact <- c(0.012852, 0.013161, 0.012128, 0.010227, 0.006258, 0.001556)

rad.add.fact  <- c(-64.2618, -65.8048, -60.6386, -51.1339, -31.2914)

#convert DN to TOA radiance
s.rad <- (s.dn * rad.mult.fact) + rad.add.fact

#write file
writeRaster(s.rad, filename='teste.tif', format="GTiff", overwrite=TRUE)



The calculation runs extremely slow and takes about 10 minutes on my dual-core system with 8GB RAM. Three 2.8GB files are written on my temp dir during calculations. Finally, by the end I receive a warning:



Warning message:
In (s.img * rad.mult.fact) + rad.add.fact :
number of items to replace is not a multiple of replacement length


I wonder if there is a way to optimise that script? And why calculation is so slow in my case? What is causing the warning message and how to fix it?

Many thanks,
--
Thiago V. dos Santos
PhD student
Land and Atmospheric Science
University of Minnesota
http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
Phone: (612) 323 9898

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo




This electronic message contains information generated by the USDA solely for the intended recipients. Any unauthorized interception of this message or the use or disclosure of the information it contains may violate the law and subject the violator to civil or criminal penalties. If you believe you have received this message in error, please notify the sender and delete the email immediately.


From mdsumner at gmail.com  Sat Feb  7 00:40:21 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 06 Feb 2015 23:40:21 +0000
Subject: [R-sig-Geo] Applying a simple math on a big stack takes a long
 time. How to improve it?
Message-ID: <CAAcGz9_nDb-adM7R8dLfXNK3cuRy+OSQXf4e51YHgbPE6h_wMg@mail.gmail.com>

On Sat, 7 Feb 2015 10:17 Thiago V. dos Santos <thi_veloso at yahoo.com.br>
wrote:

> Ops, by bad, I missed one value when writing the simplified script to the
> list. The correct vector should be:
>
> rad.add.fact  <- c(-64.2618, -65.8048, -60.6386,
> -51.1339, -31.2914, -28.2876)
>
>
> Thanks for pointing that out.
>
> This vanishes the warning message but apparently doesn't affect the
> calculation since it is still VERY slow.
>
>
>
Try writing to a different physical disk than is being read from. Something
like:

s <- stack(list.files("C:/data"), pattern = "tif")

writeRaster(s, filename='D:/teste.tif', format="GTiff", overwrite=TRUE)

Maybe that can help.

Mike


> Greetings,
> --
> Thiago V. dos Santos
> PhD student
> Land and Atmospheric Science
> University of Minnesota
> http://www.laas.umn.edu/CurrentStudents/MeettheStudents/Thia
> godosSantos/index.htm
> Phone: (612) 323 9898
>
>
>
> On Friday, February 6, 2015 4:55 PM, "Baldwin, Jim -FS" <
> jbaldwin at fs.fed.us> wrote:
> rad.mult.fact has length 6 and rad.add.fact has length 5.  Does that
> affect the calculations?
>
> Jim
>
>
>
> -----Original Message-----
> From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of
> Thiago V. dos Santos
> Sent: Friday, February 06, 2015 2:07 PM
> To: R-SIG list
> Subject: [R-sig-Geo] Applying a simple math on a big stack takes a long
> time. How to improve it?
>
> Hi all,
>
> I am processing some GeoTiff rasters with 60 files in total (might be
> more), which are relatively big: resolution is about 7800 x 7700 at 30m res
> and total file size is around 120MB (Landsat 8 images). I am trying to do a
> simple math equation calculation (please see the end of the code) on a
> stack of six of those images:
>
>
>
> # create some artificial data
> # this is used within a loop with all files (~60) in the directory
>
> r <- raster(nrows=7801, ncols=7711)
> r[] <- runif(ncell(r),0,65000)
> s.dn <- stack(r,r,r,r,r,r)
>
> # Define calibration factors
> rad.mult.fact <- c(0.012852, 0.013161, 0.012128, 0.010227, 0.006258,
> 0.001556)
>
> rad.add.fact  <- c(-64.2618, -65.8048, -60.6386, -51.1339, -31.2914)
>
> #convert DN to TOA radiance
> s.rad <- (s.dn * rad.mult.fact) + rad.add.fact
>
> #write file
> writeRaster(s.rad, filename='teste.tif', format="GTiff", overwrite=TRUE)
>
>
>
> The calculation runs extremely slow and takes about 10 minutes on my
> dual-core system with 8GB RAM. Three 2.8GB files are written on my temp dir
> during calculations. Finally, by the end I receive a warning:
>
>
>
> Warning message:
> In (s.img * rad.mult.fact) + rad.add.fact :
> number of items to replace is not a multiple of replacement length
>
>
> I wonder if there is a way to optimise that script? And why calculation is
> so slow in my case? What is causing the warning message and how to fix it?
>
> Many thanks,
> --
> Thiago V. dos Santos
> PhD student
> Land and Atmospheric Science
> University of Minnesota
> http://www.laas.umn.edu/CurrentStudents/MeettheStudents/Thia
> godosSantos/index.htm
> Phone: (612) 323 9898
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
>
> This electronic message contains information generated by the USDA solely
> for the intended recipients. Any unauthorized interception of this message
> or the use or disclosure of the information it contains may violate the law
> and subject the violator to civil or criminal penalties. If you believe you
> have received this message in error, please notify the sender and delete
> the email immediately.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From cafpx at hotmail.com  Fri Feb  6 17:03:48 2015
From: cafpx at hotmail.com (Karloz)
Date: Fri, 6 Feb 2015 11:03:48 -0500
Subject: [R-sig-Geo] R-sig-Geo Digest, Vol 138, Issue 4
Message-ID: <BLU436-SMTP945E9AEA211F93B19374A9A3390@phx.gbl>



r-sig-geo-request at r-project.org wrote:

>Send R-sig-Geo mailing list submissions to
>	r-sig-geo at r-project.org
>
>To subscribe or unsubscribe via the World Wide Web, visit
>	https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>or, via email, send a message with subject or body 'help' to
>	r-sig-geo-request at r-project.org
>
>You can reach the person managing the list at
>	r-sig-geo-owner at r-project.org
>
>When replying, please edit your Subject line so it is more specific
>than "Re: Contents of R-sig-Geo digest..."
>
>
>Today's Topics:
>
>   1. Re: grid in adehabitatHR (chirleu)
>
>
>----------------------------------------------------------------------
>
>Message: 1
>Date: Tue, 3 Feb 2015 07:37:27 -0700 (MST)
>From: chirleu <chirleu at gmail.com>
>To: r-sig-geo at r-project.org
>Subject: Re: [R-sig-Geo] grid in adehabitatHR
>Message-ID:
>	<CALC46t_qMTRveZJvRCFxFb+FeU1hVrK21Cyphgm_2hXTYMkmFQ at mail.gmail.com>
>Content-Type: text/plain; charset=us-ascii
>
>Hi Jed,
>It worked! So thank you. I was close. I think I was passing a complet grid
>(not only 4 points):
>loc4=raster(loc,nrows=1000,ncols=1000)
>but for some reason did not work. It seems the key is the expand.grid
>function.
>
>Cheers,
>
>David
>
>2015-02-03 10:52 GMT+01:00 JLong [via R-sig-geo] <
>ml-node+s2731867n7587727h27 at n2.nabble.com>:
>
>> Hi David,
>>
>> The kernelUD 'grid' parameter expects a SpatialPixels object that
>> represents the raster upon which you wish to estimate the animal UD. You
>> are passing in only a raster with 4 pixels, which I think represent the
>> outer corners of the raster upon which you wish to estimate the UD.
>> Alternatively, the grid parameter can accept a number that represents the
>> pixel size, and it will automatically build the raster for you.
>>
>> The problem lies in your buildup definition of the SpatialPixelsDataFrame
>> object. When you define a 'grid' you need to identify the locations of each
>> pixel in the grid and save those as columns x  and y  in the data frame.
>> See the 'expand.grid' function and the meuse.grid example in the function
>> 'coordinates'.
>>
>> As a test just try:
>> kud=kernelUD(detections[,1],h=h, grid=40, kern=c("bivnorm"))
>>
>>
>> Then, the process if you wish to define your own grid would then be:
>> x <- seq(xmin,xmax,by=resolution)  # where resolution is the pixel size
>> you desire
>> y <- seq(ymin,ymax,by=resolution)
>> xy <- expand.grid(x=x,y=y)
>> coordinates(xy) <- ~x+y
>> gridded(xy) <- TRUE
>> class(xy)
>>
>> kud=kernelUD(detections[,1],h=h, grid=xy, kern=c("bivnorm"))
>>
>> Cheers,
>> Jed
>>  Jed Long
>> Lecturer in GeoInformatics
>> Department of Geography & Sustainable Development
>> University of St Andrews, UK
>>
>>
>> ------------------------------
>>  If you reply to this email, your message will be added to the discussion
>> below:
>>
>> http://r-sig-geo.2731867.n2.nabble.com/grid-in-adehabitatHR-tp7587722p7587727.html
>>  To unsubscribe from grid in adehabitatHR, click here
>> <http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=7587722&code=Y2hpcmxldUBnbWFpbC5jb218NzU4NzcyMnw3MzA1Njc5Nw==>
>> .
>> NAML
>> <http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>>
>
>
>
>
>--
>View this message in context: http://r-sig-geo.2731867.n2.nabble.com/grid-in-adehabitatHR-tp7587722p7587728.html
>Sent from the R-sig-geo mailing list archive at Nabble.com.
>
>
>
>------------------------------
>
>Subject: Digest Footer
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at r-project.org
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>------------------------------
>
>End of R-sig-Geo Digest, Vol 138, Issue 4
>*****************************************
>

From barbara.szabo.elte at gmail.com  Sat Feb  7 16:55:22 2015
From: barbara.szabo.elte at gmail.com (=?ISO-8859-1?Q?Barbara_Szab=F3?=)
Date: Sat, 7 Feb 2015 16:55:22 +0100
Subject: [R-sig-Geo] CRS for the European Biogeographical Regions in R
Message-ID: <CAEtKYzJa62FAoswP-gxjKZzyiQJOV5pj6hfpuEWrF5bz0siz=Q@mail.gmail.com>

Hi,
i`d be interested if somebody would help me in the CRS for the European
Biogeographical Regions data base.

I have coordinates, already saved as SpatialPolygon in lat-long

sp_poly at bbox

     min      max

x 40.933 59.30397

y 13.633 27.53300
I have to check in which polygons this coordinates belong to. The function
over() should do the job, if both data sets are in the same CRS.


The shape file of the biogeographical regions can be downloaded at
http://www.eea.europa.eu/data-and-maps/data/biogeographical-regions-europe

The CRS is NA when reading it with
library(maptoos)
eea <- readShapeLines("BiogeoRegions2011")
The data lays in the bbox of 943619 489768 8663038 7880872
On the website there is an information on the CRS:
urn:ogc:def:crs:EPSG:6.11:4326

The problem seems to be to specify the correct CRS in eea. First I do not
know the CRS and second if I assume one, I get an error:
proj4string(eea) <- CRS("+proj=longlat +ellps=WGS84")
Error in proj4string. Geographical CRS given to non-conformance data:
8663038.09057 ....

Any ideas which bringing me nearer to a solution are very welcome - thanks
a lot in advance.

Best,
Barbara

	[[alternative HTML version deleted]]


From kardinal.eros at gmail.com  Sat Feb  7 17:53:00 2015
From: kardinal.eros at gmail.com (Roland Kaiser)
Date: Sat, 7 Feb 2015 17:53:00 +0100
Subject: [R-sig-Geo] CRS for the European Biogeographical Regions in R
In-Reply-To: <CAEtKYzJa62FAoswP-gxjKZzyiQJOV5pj6hfpuEWrF5bz0siz=Q@mail.gmail.com>
References: <CAEtKYzJa62FAoswP-gxjKZzyiQJOV5pj6hfpuEWrF5bz0siz=Q@mail.gmail.com>
Message-ID: <5598E02C-20DC-4BCA-9D7A-FDA698257EB3@gmail.com>

Hi Barbara,

the data set projection is EPSG:3035 - ETRS89 / ETRS-LAEA.

llibrary(sp)
library(rgdal)

#	the projection information is given in the *.qpj file
#	unfortunately, it is not read from the dataset by the OGR driver
#	we have do define it manually by specifing argument p4s
pg <- readOGR(dsn = "BiogeoRegions2011_shapefile",
	layer = "BiogeoRegions2011", p4s = "+init=epsg:3035")
proj4string(pg)

#	example points
pt <- data.frame(x = c(14,28), y = c(41, 59), id = 1:2)
coordinates(pt) <- ~x+y
proj4string(pt) <- CRS("+init=epsg:4326")
proj4string(pt)

#	project to CRS of pg	
pt <- spTransform(pt, CRS("+init=epsg:3035"))

over(pt, pg)

Cheers, Roli


> Am 07.02.2015 um 16:55 schrieb Barbara Szab? <barbara.szabo.elte at gmail.com>:
> 
> Hi,
> i`d be interested if somebody would help me in the CRS for the European
> Biogeographical Regions data base.
> 
> I have coordinates, already saved as SpatialPolygon in lat-long
> 
> sp_poly at bbox
> 
>     min      max
> 
> x 40.933 59.30397
> 
> y 13.633 27.53300
> I have to check in which polygons this coordinates belong to. The function
> over() should do the job, if both data sets are in the same CRS.
> 
> 
> The shape file of the biogeographical regions can be downloaded at
> http://www.eea.europa.eu/data-and-maps/data/biogeographical-regions-europe
> 
> The CRS is NA when reading it with
> library(maptoos)
> eea <- readShapeLines("BiogeoRegions2011")
> The data lays in the bbox of 943619 489768 8663038 7880872
> On the website there is an information on the CRS:
> urn:ogc:def:crs:EPSG:6.11:4326
> 
> The problem seems to be to specify the correct CRS in eea. First I do not
> know the CRS and second if I assume one, I get an error:
> proj4string(eea) <- CRS("+proj=longlat +ellps=WGS84")
> Error in proj4string. Geographical CRS given to non-conformance data:
> 8663038.09057 ....
> 
> Any ideas which bringing me nearer to a solution are very welcome - thanks
> a lot in advance.
> 
> Best,
> Barbara
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From barbara.szabo.elte at gmail.com  Sat Feb  7 18:32:50 2015
From: barbara.szabo.elte at gmail.com (=?ISO-8859-1?Q?Barbara_Szab=F3?=)
Date: Sat, 7 Feb 2015 18:32:50 +0100
Subject: [R-sig-Geo] CRS for the European Biogeographical Regions in R
In-Reply-To: <5598E02C-20DC-4BCA-9D7A-FDA698257EB3@gmail.com>
References: <CAEtKYzJa62FAoswP-gxjKZzyiQJOV5pj6hfpuEWrF5bz0siz=Q@mail.gmail.com>
	<5598E02C-20DC-4BCA-9D7A-FDA698257EB3@gmail.com>
Message-ID: <CAEtKYzKPjgYRfJ+LQEUibV35NasYA44opYFdU36NuvK3r8wfEQ@mail.gmail.com>

Wow, thank you so, it works!
You saved my day :), otherwise I could spend some more hours on it...

Bests
Barbara


2015-02-07 17:53 GMT+01:00 Roland Kaiser <kardinal.eros at gmail.com>:

> Hi Barbara,
>
> the data set projection is EPSG:3035 - ETRS89 / ETRS-LAEA.
>
> llibrary(sp)
> library(rgdal)
>
> #       the projection information is given in the *.qpj file
> #       unfortunately, it is not read from the dataset by the OGR driver
> #       we have do define it manually by specifing argument p4s
> pg <- readOGR(dsn = "BiogeoRegions2011_shapefile",
>         layer = "BiogeoRegions2011", p4s = "+init=epsg:3035")
> proj4string(pg)
>
> #       example points
> pt <- data.frame(x = c(14,28), y = c(41, 59), id = 1:2)
> coordinates(pt) <- ~x+y
> proj4string(pt) <- CRS("+init=epsg:4326")
> proj4string(pt)
>
> #       project to CRS of pg
> pt <- spTransform(pt, CRS("+init=epsg:3035"))
>
> over(pt, pg)
>
> Cheers, Roli
>
>
> > Am 07.02.2015 um 16:55 schrieb Barbara Szab? <
> barbara.szabo.elte at gmail.com>:
> >
> > Hi,
> > i`d be interested if somebody would help me in the CRS for the European
> > Biogeographical Regions data base.
> >
> > I have coordinates, already saved as SpatialPolygon in lat-long
> >
> > sp_poly at bbox
> >
> >     min      max
> >
> > x 40.933 59.30397
> >
> > y 13.633 27.53300
> > I have to check in which polygons this coordinates belong to. The
> function
> > over() should do the job, if both data sets are in the same CRS.
> >
> >
> > The shape file of the biogeographical regions can be downloaded at
> >
> http://www.eea.europa.eu/data-and-maps/data/biogeographical-regions-europe
> >
> > The CRS is NA when reading it with
> > library(maptoos)
> > eea <- readShapeLines("BiogeoRegions2011")
> > The data lays in the bbox of 943619 489768 8663038 7880872
> > On the website there is an information on the CRS:
> > urn:ogc:def:crs:EPSG:6.11:4326
> >
> > The problem seems to be to specify the correct CRS in eea. First I do not
> > know the CRS and second if I assume one, I get an error:
> > proj4string(eea) <- CRS("+proj=longlat +ellps=WGS84")
> > Error in proj4string. Geographical CRS given to non-conformance data:
> > 8663038.09057 ....
> >
> > Any ideas which bringing me nearer to a solution are very welcome -
> thanks
> > a lot in advance.
> >
> > Best,
> > Barbara
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From duncan at mcpherson.org.uk  Sun Feb  8 09:28:28 2015
From: duncan at mcpherson.org.uk (Duncan McPherson)
Date: Sun, 8 Feb 2015 08:28:28 +0000
Subject: [R-sig-Geo] multiple geometry columns in a table reading from
	PostGIS to rgdal
Message-ID: <9A644B0E-38BD-4B2C-A70B-6FDB21524EAA@mcpherson.org.uk>

Dear list

Has the syntax changed for specifying which geometry column to import in rgdal when built against GDAL 1.11 when there are multiple geometry columns in a single table? RFC41 (http://trac.osgeo.org/gdal/wiki/rfc41_multiple_geometry_fields) seems to say something about this, but I?m not sure what the implications are for rgdal.

I have recently updated rgdal and gdal and previously functioning code now doesn?t. With the old version, rgdal built from source linked to GDAL=1.9.2 this would work (it also works with rgdal built against GDAL=1.10) :

dsn=?PG:dbname=[dbname] user=[username]"
sha<- readOGR(dsn, ?table(geom_col_1)")
# Layer gets imported

But with rgdal built against GDAL 1.11.1:

dsn=?PG:dbname=[dbname] user=[username]"
sha<- readOGR(dsn, "table(geom_col_1)")
# Error in ogrInfo(dsn = dsn, layer = layer, encoding = encoding, use_iconv = use_iconv,  : 
#                      Layer not found

I build rgdal from source on mac osx. Some more details of my setup:
 
library(rgdal)
# Loading required package: sp
# rgdal: version: 0.9-1, (SVN revision 518)
# Geospatial Data Abstraction Library extensions to R successfully loaded
# Loaded GDAL runtime: GDAL 1.11.1, released 2014/09/24
# Path to GDAL shared files: /Library/Frameworks/GDAL.framework/Versions/1.11/Resources/gdal
# Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
# Path to PROJ.4 shared files: (autodetected)
ogrListLayers(dsn)
# [1] "sha_fe?      //and the other tables with geometry columns
# attr(,"driver")
# [1] "PostgreSQL"
# attr(,"nlayers?)
# [1] 20

You can see that the table is listed but not the columns, and there are 20 layers. If I go to the terminal I get

DMcPiMac:~ duncan$ ogrinfo -ro PG:?dbname=[dbname] user=[username]'
INFO: Open of `PG:dbname=[dbname] user=[username]'
      using driver `PostgreSQL' successful.
1: sha_fe (Multi Polygon, Multi Polygon)
? upto 20

And the geometries are there:

DMcPiMac:~ duncan$ ogrinfo -ro -al -so PG:?dbname=[dbname] user=[username]?
...
Layer name: sha_fe
Geometry (the_geom): Multi Polygon
Geometry (geom_low): Multi Polygon
...

Which suggests that there are two MultiPolygon columns in that table, and that there are considered to be 20 layers. 

If I clean and build rgdal against GDAL 1.9 or 1.10 the old behaviour returns:

> ogrListLayers(dsn)
[1] "sha_fe(geom_low)"  "sha_fe(the_geom)?
# and the rest of the layers
attr(,"driver")
[1] "PostgreSQL"
attr(,"nlayers")
[1] 24

Many thanks for help with this.

Duncan

From b.rowlingson at lancaster.ac.uk  Sun Feb  8 12:37:23 2015
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sun, 8 Feb 2015 11:37:23 +0000
Subject: [R-sig-Geo] CRS for the European Biogeographical Regions in R
In-Reply-To: <5598E02C-20DC-4BCA-9D7A-FDA698257EB3@gmail.com>
References: <CAEtKYzJa62FAoswP-gxjKZzyiQJOV5pj6hfpuEWrF5bz0siz=Q@mail.gmail.com>
	<5598E02C-20DC-4BCA-9D7A-FDA698257EB3@gmail.com>
Message-ID: <CANVKczOXMmJqNbQxsE5sAvoAQatV3Aj+PBkYe2DwVSzMBxaDXA@mail.gmail.com>

On Sat, Feb 7, 2015 at 4:53 PM, Roland Kaiser <kardinal.eros at gmail.com> wrote:

> #       the projection information is given in the *.qpj file

I can't see a *.qpj file in that shapefile. There is a *.prj file
which contains projection info.

> #       unfortunately, it is not read from the dataset by the OGR driver

The *.prj file **is** read when using readOGR:

 > r=readOGR(".","BiogeoRegions2011")
 OGR data source with driver: ESRI Shapefile
 Source: ".", layer: "BiogeoRegions2011"
 with 12 features and 4 fields
 Feature type: wkbPolygon with 2 dimensions
 > proj4string(r)
 [1] "+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000
+ellps=GRS80 +units=m +no_defs"

- that's a full projection specification, rather than an epsg code
though, because that's what's in the file.

> #       we have do define it manually by specifing argument p4s

No we don't!

> pg <- readOGR(dsn = "BiogeoRegions2011_shapefile",
>         layer = "BiogeoRegions2011", p4s = "+init=epsg:3035")

Is the .prj file text coding the same projection as epsg:3035?
http://epsg.io/ says 3035 is:

+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80
+towgs84=0,0,0,0,0,0,0 +units=m +no_defs

So yes. But there's no need to specify it in readOGR since you have
the .prj file. The maptools functions readShapeSpatial and friends
ignore the .prj file - I don't know why they exist any more!

 > r2=readShapeSpatial("BiogeoRegions2011.shp")
 > proj4string(r2)
[1] NA

Ouch.

Barry


From kardinal.eros at gmail.com  Sun Feb  8 13:54:55 2015
From: kardinal.eros at gmail.com (Roland Kaiser)
Date: Sun, 8 Feb 2015 13:54:55 +0100
Subject: [R-sig-Geo] CRS for the European Biogeographical Regions in R
In-Reply-To: <CANVKczOXMmJqNbQxsE5sAvoAQatV3Aj+PBkYe2DwVSzMBxaDXA@mail.gmail.com>
References: <CAEtKYzJa62FAoswP-gxjKZzyiQJOV5pj6hfpuEWrF5bz0siz=Q@mail.gmail.com>
	<5598E02C-20DC-4BCA-9D7A-FDA698257EB3@gmail.com>
	<CANVKczOXMmJqNbQxsE5sAvoAQatV3Aj+PBkYe2DwVSzMBxaDXA@mail.gmail.com>
Message-ID: <FE6A441E-8733-419F-9EFA-544CC9527EE9@gmail.com>

Hi!

Sorry for the confusion, I followed the link on the top the page "Note: new version is available!?.
For some reason, this ZIP archive has a *.qpj instead of *.prj file.

Of course, readOGR treats the *prj correctly, if present!

-Roli

> Am 08.02.2015 um 12:37 schrieb Barry Rowlingson <b.rowlingson at lancaster.ac.uk>:
> 
> On Sat, Feb 7, 2015 at 4:53 PM, Roland Kaiser <kardinal.eros at gmail.com> wrote:
> 
>> #       the projection information is given in the *.qpj file
> 
> I can't see a *.qpj file in that shapefile. There is a *.prj file
> which contains projection info.
> 
>> #       unfortunately, it is not read from the dataset by the OGR driver
> 
> The *.prj file **is** read when using readOGR:
> 
>> r=readOGR(".","BiogeoRegions2011")
> OGR data source with driver: ESRI Shapefile
> Source: ".", layer: "BiogeoRegions2011"
> with 12 features and 4 fields
> Feature type: wkbPolygon with 2 dimensions
>> proj4string(r)
> [1] "+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000
> +ellps=GRS80 +units=m +no_defs"
> 
> - that's a full projection specification, rather than an epsg code
> though, because that's what's in the file.
> 
>> #       we have do define it manually by specifing argument p4s
> 
> No we don't!
> 
>> pg <- readOGR(dsn = "BiogeoRegions2011_shapefile",
>>        layer = "BiogeoRegions2011", p4s = "+init=epsg:3035")
> 
> Is the .prj file text coding the same projection as epsg:3035?
> http://epsg.io/ says 3035 is:
> 
> +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80
> +towgs84=0,0,0,0,0,0,0 +units=m +no_defs
> 
> So yes. But there's no need to specify it in readOGR since you have
> the .prj file. The maptools functions readShapeSpatial and friends
> ignore the .prj file - I don't know why they exist any more!
> 
>> r2=readShapeSpatial("BiogeoRegions2011.shp")
>> proj4string(r2)
> [1] NA
> 
> Ouch.
> 
> Barry


From barbara.szabo.elte at gmail.com  Sun Feb  8 15:17:33 2015
From: barbara.szabo.elte at gmail.com (=?ISO-8859-1?Q?Barbara_Szab=F3?=)
Date: Sun, 8 Feb 2015 15:17:33 +0100
Subject: [R-sig-Geo] CRS for the European Biogeographical Regions in R
In-Reply-To: <FE6A441E-8733-419F-9EFA-544CC9527EE9@gmail.com>
References: <CAEtKYzJa62FAoswP-gxjKZzyiQJOV5pj6hfpuEWrF5bz0siz=Q@mail.gmail.com>
	<5598E02C-20DC-4BCA-9D7A-FDA698257EB3@gmail.com>
	<CANVKczOXMmJqNbQxsE5sAvoAQatV3Aj+PBkYe2DwVSzMBxaDXA@mail.gmail.com>
	<FE6A441E-8733-419F-9EFA-544CC9527EE9@gmail.com>
Message-ID: <CAEtKYzKQzvCM7j+iLnKNjuMDEh9Wy-SiYA3WS0Jd19ggr=mpAQ@mail.gmail.com>

Dear Roli, dear Barry, dear all,

unfortunately, I cannot find out what is going wrong with my example.
The problem seems to be very basic, but after searching and reading a
lot, I do not come to a solution. It seems that either the
transformation of the WGS84 lat/long to epsg:4326 is somehow wrong or
the biogeographical region CRS is in another reference system than the
.prj file reported. Any help would be wonderful. Thanks in advance.

library(sp)
library(rgdal)

### possible basic problem:
### data in lat/lon -- WGS84, some stations in slovenia:
pt <- data.frame("lat"=c(45.900,46.500,46.067),
"lon"=c(13.633,13.717,14.517), "stid"=c("psi004","psi006","psi003"))
coordinates(pt) <- ~lat+lon
proj4string(pt) <- CRS("+init=epsg:4326")
proj4string(pt)
#[1] "+init=epsg:4326 +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
+towgs84=0,0,0"
## projection seems to be wrong since of negative numbers?
pt at coords

#         lat        lon
#[1,] 8295839 -96345.163
#[2,] 8355036 -58479.199
#[3,] 8286066   1886.133



#################################################
### full example:
pg <- readOGR(dsn = "data/eea",
              layer = "BiogeoRegions2011", p4s = "+init=epsg:3035")
proj4string(pg)

# [1] "+init=epsg:3035 +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000
+y_0=3210000 #+ellps=GRS80 +units=m +no_defs"

## three stations from slovenia:

pt <- data.frame("lat"=c(45.900,46.500,46.067),
"lon"=c(13.633,13.717,14.517), "stid"=c("psi004","psi006","psi003"))

coordinates(pt) <- ~lat+lon
proj4string(pt) <- CRS("+init=epsg:4326")
proj4string(pt)

#[1] "+init=epsg:4326 +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
+towgs84=0,0,0"

##       project to CRS of pg
pt <- spTransform(pt, CRS("+init=epsg:3035"))
res <- over(pt, pg)
res

#  NAME ABBRE code label
#1 <NA>  <NA> <NA>  <NA>
#2 <NA>  <NA> <NA>  <NA>
#3 <NA>  <NA> <NA>  <NA>

## example of a polygon:
summary(pg at polygons[[1]]@Polygons[[1]]@coords)

#       V1                V2
# Min.   :4389214   Min.   :1178199
# 1st Qu.:4396641   1st Qu.:1186794
# Median :4407574   Median :1191444
# Mean   :4405907   Mean   :1193508
# 3rd Qu.:4413052   3rd Qu.:1200195
# Max.   :4421392   Max.   :1207598

pt at coords

#         lat        lon
#[1,] 8295839 -96345.163
#[2,] 8355036 -58479.199
#[3,] 8286066   1886.133



2015-02-08 13:54 GMT+01:00 Roland Kaiser <kardinal.eros at gmail.com>:

> Hi!
>
> Sorry for the confusion, I followed the link on the top the page "Note:
> new version is available!".
> For some reason, this ZIP archive has a *.qpj instead of *.prj file.
>
> Of course, readOGR treats the *prj correctly, if present!
>
> -Roli
>
> > Am 08.02.2015 um 12:37 schrieb Barry Rowlingson <
> b.rowlingson at lancaster.ac.uk>:
> >
> > On Sat, Feb 7, 2015 at 4:53 PM, Roland Kaiser <kardinal.eros at gmail.com>
> wrote:
> >
> >> #       the projection information is given in the *.qpj file
> >
> > I can't see a *.qpj file in that shapefile. There is a *.prj file
> > which contains projection info.
> >
> >> #       unfortunately, it is not read from the dataset by the OGR driver
> >
> > The *.prj file **is** read when using readOGR:
> >
> >> r=readOGR(".","BiogeoRegions2011")
> > OGR data source with driver: ESRI Shapefile
> > Source: ".", layer: "BiogeoRegions2011"
> > with 12 features and 4 fields
> > Feature type: wkbPolygon with 2 dimensions
> >> proj4string(r)
> > [1] "+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000
> > +ellps=GRS80 +units=m +no_defs"
> >
> > - that's a full projection specification, rather than an epsg code
> > though, because that's what's in the file.
> >
> >> #       we have do define it manually by specifing argument p4s
> >
> > No we don't!
> >
> >> pg <- readOGR(dsn = "BiogeoRegions2011_shapefile",
> >>        layer = "BiogeoRegions2011", p4s = "+init=epsg:3035")
> >
> > Is the .prj file text coding the same projection as epsg:3035?
> > http://epsg.io/ says 3035 is:
> >
> > +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80
> > +towgs84=0,0,0,0,0,0,0 +units=m +no_defs
> >
> > So yes. But there's no need to specify it in readOGR since you have
> > the .prj file. The maptools functions readShapeSpatial and friends
> > ignore the .prj file - I don't know why they exist any more!
> >
> >> r2=readShapeSpatial("BiogeoRegions2011.shp")
> >> proj4string(r2)
> > [1] NA
> >
> > Ouch.
> >
> > Barry
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From kardinal.eros at gmail.com  Sun Feb  8 15:26:10 2015
From: kardinal.eros at gmail.com (Roland Kaiser)
Date: Sun, 8 Feb 2015 15:26:10 +0100
Subject: [R-sig-Geo] CRS for the European Biogeographical Regions in R
In-Reply-To: <CAEtKYzKQzvCM7j+iLnKNjuMDEh9Wy-SiYA3WS0Jd19ggr=mpAQ@mail.gmail.com>
References: <CAEtKYzJa62FAoswP-gxjKZzyiQJOV5pj6hfpuEWrF5bz0siz=Q@mail.gmail.com>
	<5598E02C-20DC-4BCA-9D7A-FDA698257EB3@gmail.com>
	<CANVKczOXMmJqNbQxsE5sAvoAQatV3Aj+PBkYe2DwVSzMBxaDXA@mail.gmail.com>
	<FE6A441E-8733-419F-9EFA-544CC9527EE9@gmail.com>
	<CAEtKYzKQzvCM7j+iLnKNjuMDEh9Wy-SiYA3WS0Jd19ggr=mpAQ@mail.gmail.com>
Message-ID: <2664339C-577A-4FC2-8225-C5910443E6E6@gmail.com>

Hi Barbara!

the problem is related as to how you specified the formula.
?coordinates says ? in the form of e.g. ~x+y ? (in your case x = lon[gitude], y = lat[itude})

coordiantes(pt) <- lon+lat

is what you want.

?Roli


> Am 08.02.2015 um 15:17 schrieb Barbara Szab? <barbara.szabo.elte at gmail.com>:
> 
> Dear Roli, dear Barry, dear all,
> 
> unfortunately, I cannot find out what is going wrong with my example.
> The problem seems to be very basic, but after searching and reading a
> lot, I do not come to a solution. It seems that either the
> transformation of the WGS84 lat/long to epsg:4326 is somehow wrong or
> the biogeographical region CRS is in another reference system than the
> .prj file reported. Any help would be wonderful. Thanks in advance.
> 
> library(sp)
> library(rgdal)
> 
> ### possible basic problem:
> ### data in lat/lon -- WGS84, some stations in slovenia:
> pt <- data.frame("lat"=c(45.900,46.500,46.067),
> "lon"=c(13.633,13.717,14.517), "stid"=c("psi004","psi006","psi003"))
> coordinates(pt) <- ~lat+lon
> proj4string(pt) <- CRS("+init=epsg:4326")
> proj4string(pt)
> #[1] "+init=epsg:4326 +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
> +towgs84=0,0,0"
> ## projection seems to be wrong since of negative numbers?
> pt at coords
> 
> #         lat        lon
> #[1,] 8295839 -96345.163 <tel:96345.163>
> #[2,] 8355036 -58479.199
> #[3,] 8286066   1886.133
> 
> 
> 
> #################################################
> ### full example:
> pg <- readOGR(dsn = "data/eea",
>               layer = "BiogeoRegions2011", p4s = "+init=epsg:3035")
> proj4string(pg)
> 
> # [1] "+init=epsg:3035 +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000
> +y_0=3210000 #+ellps=GRS80 +units=m +no_defs"
> 
> ## three stations from slovenia:
> 
> pt <- data.frame("lat"=c(45.900,46.500,46.067),
> "lon"=c(13.633,13.717,14.517), "stid"=c("psi004","psi006","psi003"))
> 
> coordinates(pt) <- ~lat+lon
> proj4string(pt) <- CRS("+init=epsg:4326")
> proj4string(pt)
> 
> #[1] "+init=epsg:4326 +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
> +towgs84=0,0,0"
> 
> ##       project to CRS of pg
> pt <- spTransform(pt, CRS("+init=epsg:3035"))
> res <- over(pt, pg)
> res
> 
> #  NAME ABBRE code label
> #1 <NA>  <NA> <NA>  <NA>
> #2 <NA>  <NA> <NA>  <NA>
> #3 <NA>  <NA> <NA>  <NA>
> 
> ## example of a polygon:
> summary(pg at polygons[[1]]@Polygons[[1]]@coords)
> 
> #       V1                V2
> # Min.   :4389214   Min.   :1178199
> # 1st Qu.:4396641   1st Qu.:1186794
> # Median :4407574   Median :1191444
> # Mean   :4405907   Mean   :1193508
> # 3rd Qu.:4413052   3rd Qu.:1200195
> # Max.   :4421392   Max.   :1207598
> 
> pt at coords
> 
> #         lat        lon
> #[1,] 8295839 -96345.163 <tel:96345.163>
> #[2,] 8355036 -58479.199
> #[3,] 8286066   1886.133
> 
> 
> 
> 2015-02-08 13:54 GMT+01:00 Roland Kaiser <kardinal.eros at gmail.com <mailto:kardinal.eros at gmail.com>>:
> Hi!
> 
> Sorry for the confusion, I followed the link on the top the page "Note: new version is available!?.
> For some reason, this ZIP archive has a *.qpj instead of *.prj file.
> 
> Of course, readOGR treats the *prj correctly, if present!
> 
> -Roli
> 
> > Am 08.02.2015 um 12:37 schrieb Barry Rowlingson <b.rowlingson at lancaster.ac.uk <mailto:b.rowlingson at lancaster.ac.uk>>:
> >
> > On Sat, Feb 7, 2015 at 4:53 PM, Roland Kaiser <kardinal.eros at gmail.com <mailto:kardinal.eros at gmail.com>> wrote:
> >
> >> #       the projection information is given in the *.qpj file
> >
> > I can't see a *.qpj file in that shapefile. There is a *.prj file
> > which contains projection info.
> >
> >> #       unfortunately, it is not read from the dataset by the OGR driver
> >
> > The *.prj file **is** read when using readOGR:
> >
> >> r=readOGR(".","BiogeoRegions2011")
> > OGR data source with driver: ESRI Shapefile
> > Source: ".", layer: "BiogeoRegions2011"
> > with 12 features and 4 fields
> > Feature type: wkbPolygon with 2 dimensions
> >> proj4string(r)
> > [1] "+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000
> > +ellps=GRS80 +units=m +no_defs"
> >
> > - that's a full projection specification, rather than an epsg code
> > though, because that's what's in the file.
> >
> >> #       we have do define it manually by specifing argument p4s
> >
> > No we don't!
> >
> >> pg <- readOGR(dsn = "BiogeoRegions2011_shapefile",
> >>        layer = "BiogeoRegions2011", p4s = "+init=epsg:3035")
> >
> > Is the .prj file text coding the same projection as epsg:3035?
> > http://epsg.io/ <http://epsg.io/> says 3035 is:
> >
> > +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80
> > +towgs84=0,0,0,0,0,0,0 +units=m +no_defs
> >
> > So yes. But there's no need to specify it in readOGR since you have
> > the .prj file. The maptools functions readShapeSpatial and friends
> > ignore the .prj file - I don't know why they exist any more!
> >
> >> r2=readShapeSpatial("BiogeoRegions2011.shp")
> >> proj4string(r2)
> > [1] NA
> >
> > Ouch.
> >
> > Barry
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
> 
> 
> 
> 


	[[alternative HTML version deleted]]


From jane.juen.yang at gmail.com  Mon Feb  9 06:20:20 2015
From: jane.juen.yang at gmail.com (Jane Yang)
Date: Mon, 9 Feb 2015 07:20:20 +0200
Subject: [R-sig-Geo] Topo to raster in R
Message-ID: <CAOV4xw9kXB+YHcxKrtU_08o=J810brpp2QTUASNf0Fu4Q2Ct3A@mail.gmail.com>

Hi all,

Happy Monday! Hoping the collective genius of this listserv can help me. I
have vector contours data (source:
http://192.156.137.110/gis/search.asp?id=318) that I would like to convert
to a surface raster. Two questions:

   1. What are peoples' opinions about the use of spgrass6's r.surf.contour
   functionality vs raster's rasterize function? My basic understanding is
   that GRASS has a more robust algorithm for interpolation, but please do
   correct me if I'm mistaken.

   2. I have been pursuing the r.surf.contour option because initial trials
   with rasterize hasn't converted the majority of the data in the vector
   contour file. However, when I try to load the vector file into a temporary
   GRASS environment, I hit the following error in red, that results in no
   data being transferred over to the raster.

initGRASS("/Applications/GRASS-6.4.app/Contents/MacOS", home=tempdir(),
    override = T)
system("g.region -d")
execGRASS("v.in.ogr", dsn = "path/to/file,
    layer = "kenya_rainfall_distribution", output = "rf_raw2",
    snap = 1e-14)
Warning message:
In execGRASS("v.in.ogr", dsn = paste(dd, "rainfall", "ilri", sep = "/"),  :
  The command:
v.in.ogr dsn=/VOLUMES/AUSTEN/OAF/KE-exp-extras/data/rainfall/ilri
layer=kenya_rainfall_distribution output=rf_raw2 snap=1e-14
produced at least one warning during execution:
ERROR 4: .shx file is unreadable, or corrupt.
ERROR 4: Failed to open file
/VOLUMES/AUSTEN/OAF/KE-exp-extras/data/rainfall/ilri/._kenya_rainfall_distribution.shp.
It may be corrupt or read-only file accessed in update mode.

execGRASS("v.to.rast", input = "rf_raw2", output = "rf_rast", column =
"COLOR",
    labelcolumn = "TYPE")
rf.raster <- execGRASS("r.surf.contour", input = "rf_rast",
    output = "rfraster")

rf.raster
[1] 0
attr(,"resOut")
character(0)
attr(,"resErr")
[1] "   0%\b\b\b\b\b 100%\b\b\b\b\b"


However, I have no problem plotting the map in base plot. Any suggestions
on how to work around this would be much appreciated.

Thank you,
Jane

	[[alternative HTML version deleted]]


From Rainer at krugs.de  Mon Feb  9 13:36:51 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Mon, 09 Feb 2015 13:36:51 +0100
Subject: [R-sig-Geo] Topo to raster in R
In-Reply-To: <CAOV4xw9kXB+YHcxKrtU_08o=J810brpp2QTUASNf0Fu4Q2Ct3A@mail.gmail.com>
	(Jane Yang's message of "Mon, 9 Feb 2015 07:20:20 +0200")
References: <CAOV4xw9kXB+YHcxKrtU_08o=J810brpp2QTUASNf0Fu4Q2Ct3A@mail.gmail.com>
Message-ID: <m2mw4n45y4.fsf@krugs.de>

Jane Yang <jane.juen.yang at gmail.com> writes:

> Hi all,
>
> Happy Monday! Hoping the collective genius of this listserv can help me. I
> have vector contours data (source:
> http://192.156.137.110/gis/search.asp?id=318) that I would like to convert
> to a surface raster. Two questions:
>
>    1. What are peoples' opinions about the use of spgrass6's r.surf.contour
>    functionality vs raster's rasterize function? My basic understanding is
>    that GRASS has a more robust algorithm for interpolation, but please do
>    correct me if I'm mistaken.
>
>    2. I have been pursuing the r.surf.contour option because initial trials
>    with rasterize hasn't converted the majority of the data in the vector
>    contour file. However, when I try to load the vector file into a temporary
>    GRASS environment, I hit the following error in red, that results in no
>    data being transferred over to the raster.
>
> initGRASS("/Applications/GRASS-6.4.app/Contents/MacOS", home=tempdir(),
>     override = T)
> system("g.region -d")
> execGRASS("v.in.ogr", dsn = "path/to/file,
>     layer = "kenya_rainfall_distribution", output = "rf_raw2",
>     snap = 1e-14)
> Warning message:
> In execGRASS("v.in.ogr", dsn = paste(dd, "rainfall", "ilri", sep = "/"),  :
>   The command:
> v.in.ogr dsn=/VOLUMES/AUSTEN/OAF/KE-exp-extras/data/rainfall/ilri
> layer=kenya_rainfall_distribution output=rf_raw2 snap=1e-14
> produced at least one warning during execution:

> ERROR 4: .shx file is unreadable, or corrupt.

The question is: is your .shx file readable or is it corrupt?

If I understand correctly, this file contains a spatial index, so I
think you can rename it and try again?

The rest should be follow-up errors.

Hope this helps,

Rainer


> ERROR 4: Failed to open file
> /VOLUMES/AUSTEN/OAF/KE-exp-extras/data/rainfall/ilri/._kenya_rainfall_distribution.shp.
> It may be corrupt or read-only file accessed in update mode.
>
> execGRASS("v.to.rast", input = "rf_raw2", output = "rf_rast", column =
> "COLOR",
>     labelcolumn = "TYPE")
> rf.raster <- execGRASS("r.surf.contour", input = "rf_rast",
>     output = "rfraster")
>
> rf.raster
> [1] 0
> attr(,"resOut")
> character(0)
> attr(,"resErr")
> [1] "   0%\b\b\b\b\b 100%\b\b\b\b\b"
>
>
> However, I have no problem plotting the map in base plot. Any suggestions
> on how to work around this would be much appreciated.
>
> Thank you,
> Jane
>
> 	[[alternative HTML version deleted]]

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 494 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150209/729c5a2e/attachment.bin>

From barbara.szabo.elte at gmail.com  Mon Feb  9 15:19:40 2015
From: barbara.szabo.elte at gmail.com (=?ISO-8859-1?Q?Barbara_Szab=F3?=)
Date: Mon, 9 Feb 2015 15:19:40 +0100
Subject: [R-sig-Geo] CRS for the European Biogeographical Regions in R
In-Reply-To: <2664339C-577A-4FC2-8225-C5910443E6E6@gmail.com>
References: <CAEtKYzJa62FAoswP-gxjKZzyiQJOV5pj6hfpuEWrF5bz0siz=Q@mail.gmail.com>
	<5598E02C-20DC-4BCA-9D7A-FDA698257EB3@gmail.com>
	<CANVKczOXMmJqNbQxsE5sAvoAQatV3Aj+PBkYe2DwVSzMBxaDXA@mail.gmail.com>
	<FE6A441E-8733-419F-9EFA-544CC9527EE9@gmail.com>
	<CAEtKYzKQzvCM7j+iLnKNjuMDEh9Wy-SiYA3WS0Jd19ggr=mpAQ@mail.gmail.com>
	<2664339C-577A-4FC2-8225-C5910443E6E6@gmail.com>
Message-ID: <CAEtKYzJ35UkQ7DpcutTpSGBpRDMGOj2cR=FbXqQVy7aW3DSBhg@mail.gmail.com>

Hi Roli,

yeah, this was really the problem and now i have what i wanted.
Thank you!

Barbara


2015-02-08 15:26 GMT+01:00 Roland Kaiser <kardinal.eros at gmail.com>:

> Hi Barbara!
>
> the problem is related as to how you specified the formula.
> ?coordinates says ... in the form of e.g. ~x+y ... (in your case x =
> lon[gitude], y = lat[itude})
>
> coordiantes(pt) <- lon+lat
>
> is what you want.
>
> -Roli
>
>
> Am 08.02.2015 um 15:17 schrieb Barbara Szab? <barbara.szabo.elte at gmail.com
> >:
>
> Dear Roli, dear Barry, dear all,
>
> unfortunately, I cannot find out what is going wrong with my example.
> The problem seems to be very basic, but after searching and reading a
> lot, I do not come to a solution. It seems that either the
> transformation of the WGS84 lat/long to epsg:4326 is somehow wrong or
> the biogeographical region CRS is in another reference system than the
> .prj file reported. Any help would be wonderful. Thanks in advance.
>
> library(sp)
> library(rgdal)
>
> ### possible basic problem:
> ### data in lat/lon -- WGS84, some stations in slovenia:
> pt <- data.frame("lat"=c(45.900,46.500,46.067),
> "lon"=c(13.633,13.717,14.517), "stid"=c("psi004","psi006","psi003"))
> coordinates(pt) <- ~lat+lon
> proj4string(pt) <- CRS("+init=epsg:4326")
> proj4string(pt)
> #[1] "+init=epsg:4326 +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
> +towgs84=0,0,0"
> ## projection seems to be wrong since of negative numbers?
> pt at coords
>
> #         lat        lon
> #[1,] 8295839 -96345.163
> #[2,] 8355036 -58479.199
> #[3,] 8286066   1886.133
>
>
>
> #################################################
> ### full example:
> pg <- readOGR(dsn = "data/eea",
>               layer = "BiogeoRegions2011", p4s = "+init=epsg:3035")
> proj4string(pg)
>
> # [1] "+init=epsg:3035 +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000
> +y_0=3210000 #+ellps=GRS80 +units=m +no_defs"
>
> ## three stations from slovenia:
>
> pt <- data.frame("lat"=c(45.900,46.500,46.067),
> "lon"=c(13.633,13.717,14.517), "stid"=c("psi004","psi006","psi003"))
>
> coordinates(pt) <- ~lat+lon
> proj4string(pt) <- CRS("+init=epsg:4326")
> proj4string(pt)
>
> #[1] "+init=epsg:4326 +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
> +towgs84=0,0,0"
>
> ##       project to CRS of pg
> pt <- spTransform(pt, CRS("+init=epsg:3035"))
> res <- over(pt, pg)
> res
>
> #  NAME ABBRE code label
> #1 <NA>  <NA> <NA>  <NA>
> #2 <NA>  <NA> <NA>  <NA>
> #3 <NA>  <NA> <NA>  <NA>
>
> ## example of a polygon:
> summary(pg at polygons[[1]]@Polygons[[1]]@coords)
>
> #       V1                V2
> # Min.   :4389214   Min.   :1178199
> # 1st Qu.:4396641   1st Qu.:1186794
> # Median :4407574   Median :1191444
> # Mean   :4405907   Mean   :1193508
> # 3rd Qu.:4413052   3rd Qu.:1200195
> # Max.   :4421392   Max.   :1207598
>
> pt at coords
>
> #         lat        lon
> #[1,] 8295839 -96345.163
> #[2,] 8355036 -58479.199
> #[3,] 8286066   1886.133
>
>
>
> 2015-02-08 13:54 GMT+01:00 Roland Kaiser <kardinal.eros at gmail.com>:
>
>> Hi!
>>
>> Sorry for the confusion, I followed the link on the top the page "Note:
>> new version is available!".
>> For some reason, this ZIP archive has a *.qpj instead of *.prj file.
>>
>> Of course, readOGR treats the *prj correctly, if present!
>>
>> -Roli
>>
>> > Am 08.02.2015 um 12:37 schrieb Barry Rowlingson <
>> b.rowlingson at lancaster.ac.uk>:
>> >
>> > On Sat, Feb 7, 2015 at 4:53 PM, Roland Kaiser <kardinal.eros at gmail.com>
>> wrote:
>> >
>> >> #       the projection information is given in the *.qpj file
>> >
>> > I can't see a *.qpj file in that shapefile. There is a *.prj file
>> > which contains projection info.
>> >
>> >> #       unfortunately, it is not read from the dataset by the OGR
>> driver
>> >
>> > The *.prj file **is** read when using readOGR:
>> >
>> >> r=readOGR(".","BiogeoRegions2011")
>> > OGR data source with driver: ESRI Shapefile
>> > Source: ".", layer: "BiogeoRegions2011"
>> > with 12 features and 4 fields
>> > Feature type: wkbPolygon with 2 dimensions
>> >> proj4string(r)
>> > [1] "+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000
>> > +ellps=GRS80 +units=m +no_defs"
>> >
>> > - that's a full projection specification, rather than an epsg code
>> > though, because that's what's in the file.
>> >
>> >> #       we have do define it manually by specifing argument p4s
>> >
>> > No we don't!
>> >
>> >> pg <- readOGR(dsn = "BiogeoRegions2011_shapefile",
>> >>        layer = "BiogeoRegions2011", p4s = "+init=epsg:3035")
>> >
>> > Is the .prj file text coding the same projection as epsg:3035?
>> > http://epsg.io/ says 3035 is:
>> >
>> > +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80
>> > +towgs84=0,0,0,0,0,0,0 +units=m +no_defs
>> >
>> > So yes. But there's no need to specify it in readOGR since you have
>> > the .prj file. The maptools functions readShapeSpatial and friends
>> > ignore the .prj file - I don't know why they exist any more!
>> >
>> >> r2=readShapeSpatial("BiogeoRegions2011.shp")
>> >> proj4string(r2)
>> > [1] NA
>> >
>> > Ouch.
>> >
>> > Barry
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Mon Feb  9 16:23:11 2015
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 9 Feb 2015 15:23:11 +0000
Subject: [R-sig-Geo] CRS for the European Biogeographical Regions in R
In-Reply-To: <60171c7487ba4a74994c8bd86d1841a9@EX-0-HT0.lancs.local>
References: <CAEtKYzJa62FAoswP-gxjKZzyiQJOV5pj6hfpuEWrF5bz0siz=Q@mail.gmail.com>
	<5598E02C-20DC-4BCA-9D7A-FDA698257EB3@gmail.com>
	<CANVKczOXMmJqNbQxsE5sAvoAQatV3Aj+PBkYe2DwVSzMBxaDXA@mail.gmail.com>
	<60171c7487ba4a74994c8bd86d1841a9@EX-0-HT0.lancs.local>
Message-ID: <CANVKczOcdJGc_4xifLUS9k+uNrN9542c74L39gMk1JdF9Jy8dA@mail.gmail.com>

On Sun, Feb 8, 2015 at 12:54 PM, Roland Kaiser <kardinal.eros at gmail.com> wrote:
> Hi!
>
> Sorry for the confusion, I followed the link on the top the page "Note: new version is available!?.
> For some reason, this ZIP archive has a *.qpj instead of *.prj file.
>
> Of course, readOGR treats the *prj correctly, if present!


With the qpj file:

 > r = readOGR(".","BiogeoRegions2011")
OGR data source with driver: ESRI Shapefile
Source: ".", layer: "BiogeoRegions2011"
with 12 features and 5 fields
Feature type: wkbPolygon with 2 dimensions

Fails:

 > proj4string(r)
[1] NA

But if you simply rename the .qpj file as .prj then:

 > file.rename("BiogeoRegions2011.qpj","BiogeoRegions2011.prj")
[1] TRUE

Maybe...

 > r = readOGR(".","BiogeoRegions2011")
OGR data source with driver: ESRI Shapefile
Source: ".", layer: "BiogeoRegions2011"
with 12 features and 5 fields
Feature type: wkbPolygon with 2 dimensions

It all works:

 > proj4string(r)
[1] "+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000
+ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs"

Is a .qpj file a projection written by QGIS for some reason?

Barry

> -Roli
>
>> Am 08.02.2015 um 12:37 schrieb Barry Rowlingson <b.rowlingson at lancaster.ac.uk>:
>>
>> On Sat, Feb 7, 2015 at 4:53 PM, Roland Kaiser <kardinal.eros at gmail.com> wrote:
>>
>>> #       the projection information is given in the *.qpj file
>>
>> I can't see a *.qpj file in that shapefile. There is a *.prj file
>> which contains projection info.
>>
>>> #       unfortunately, it is not read from the dataset by the OGR driver
>>
>> The *.prj file **is** read when using readOGR:
>>
>>> r=readOGR(".","BiogeoRegions2011")
>> OGR data source with driver: ESRI Shapefile
>> Source: ".", layer: "BiogeoRegions2011"
>> with 12 features and 4 fields
>> Feature type: wkbPolygon with 2 dimensions
>>> proj4string(r)
>> [1] "+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000
>> +ellps=GRS80 +units=m +no_defs"
>>
>> - that's a full projection specification, rather than an epsg code
>> though, because that's what's in the file.
>>
>>> #       we have do define it manually by specifing argument p4s
>>
>> No we don't!
>>
>>> pg <- readOGR(dsn = "BiogeoRegions2011_shapefile",
>>>        layer = "BiogeoRegions2011", p4s = "+init=epsg:3035")
>>
>> Is the .prj file text coding the same projection as epsg:3035?
>> http://epsg.io/ says 3035 is:
>>
>> +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80
>> +towgs84=0,0,0,0,0,0,0 +units=m +no_defs
>>
>> So yes. But there's no need to specify it in readOGR since you have
>> the .prj file. The maptools functions readShapeSpatial and friends
>> ignore the .prj file - I don't know why they exist any more!
>>
>>> r2=readShapeSpatial("BiogeoRegions2011.shp")
>>> proj4string(r2)
>> [1] NA
>>
>> Ouch.
>>
>> Barry
>


From albin.blaschka at standortsanalyse.net  Mon Feb  9 16:33:42 2015
From: albin.blaschka at standortsanalyse.net (Albin Blaschka)
Date: Mon, 09 Feb 2015 16:33:42 +0100
Subject: [R-sig-Geo] CRS for the European Biogeographical Regions in R
In-Reply-To: <CANVKczOcdJGc_4xifLUS9k+uNrN9542c74L39gMk1JdF9Jy8dA@mail.gmail.com>
References: <CAEtKYzJa62FAoswP-gxjKZzyiQJOV5pj6hfpuEWrF5bz0siz=Q@mail.gmail.com>	<5598E02C-20DC-4BCA-9D7A-FDA698257EB3@gmail.com>	<CANVKczOXMmJqNbQxsE5sAvoAQatV3Aj+PBkYe2DwVSzMBxaDXA@mail.gmail.com>	<60171c7487ba4a74994c8bd86d1841a9@EX-0-HT0.lancs.local>
	<CANVKczOcdJGc_4xifLUS9k+uNrN9542c74L39gMk1JdF9Jy8dA@mail.gmail.com>
Message-ID: <54D8D356.4020203@standortsanalyse.net>


Hello!

> Is a .qpj file a projection written by QGIS for some reason?

http://hub.qgis.org/issues/2123
http://hub.qgis.org/issues/2154

Found here:
https://github.com/mapbox/node-srs/issues/34
> It's [.qpj] what GDAL's OSRExportToWkt() returns and what can fed into OSRImportFromWkt() without hassle.
 > While OGR morphs the WKT into an ESRI WKT format for the .prj and back


Greetings,
Albin


Am 09.02.2015 um 16:23 schrieb Barry Rowlingson:
> On Sun, Feb 8, 2015 at 12:54 PM, Roland Kaiser <kardinal.eros at gmail.com> wrote:
>> Hi!
>>
>> Sorry for the confusion, I followed the link on the top the page "Note: new version is available!?.
>> For some reason, this ZIP archive has a *.qpj instead of *.prj file.
>>
>> Of course, readOGR treats the *prj correctly, if present!
>
>
> With the qpj file:
>
>   > r = readOGR(".","BiogeoRegions2011")
> OGR data source with driver: ESRI Shapefile
> Source: ".", layer: "BiogeoRegions2011"
> with 12 features and 5 fields
> Feature type: wkbPolygon with 2 dimensions
>
> Fails:
>
>   > proj4string(r)
> [1] NA
>
> But if you simply rename the .qpj file as .prj then:
>
>   > file.rename("BiogeoRegions2011.qpj","BiogeoRegions2011.prj")
> [1] TRUE
>
> Maybe...
>
>   > r = readOGR(".","BiogeoRegions2011")
> OGR data source with driver: ESRI Shapefile
> Source: ".", layer: "BiogeoRegions2011"
> with 12 features and 5 fields
> Feature type: wkbPolygon with 2 dimensions
>
> It all works:
>
>   > proj4string(r)
> [1] "+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000
> +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs"
>
> Is a .qpj file a projection written by QGIS for some reason?
>
> Barry
>
>> -Roli
>>
>>> Am 08.02.2015 um 12:37 schrieb Barry Rowlingson <b.rowlingson at lancaster.ac.uk>:
>>>
>>> On Sat, Feb 7, 2015 at 4:53 PM, Roland Kaiser <kardinal.eros at gmail.com> wrote:
>>>
>>>> #       the projection information is given in the *.qpj file
>>>
>>> I can't see a *.qpj file in that shapefile. There is a *.prj file
>>> which contains projection info.
>>>
>>>> #       unfortunately, it is not read from the dataset by the OGR driver
>>>
>>> The *.prj file **is** read when using readOGR:
>>>
>>>> r=readOGR(".","BiogeoRegions2011")
>>> OGR data source with driver: ESRI Shapefile
>>> Source: ".", layer: "BiogeoRegions2011"
>>> with 12 features and 4 fields
>>> Feature type: wkbPolygon with 2 dimensions
>>>> proj4string(r)
>>> [1] "+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000
>>> +ellps=GRS80 +units=m +no_defs"
>>>
>>> - that's a full projection specification, rather than an epsg code
>>> though, because that's what's in the file.
>>>
>>>> #       we have do define it manually by specifing argument p4s
>>>
>>> No we don't!
>>>
>>>> pg <- readOGR(dsn = "BiogeoRegions2011_shapefile",
>>>>         layer = "BiogeoRegions2011", p4s = "+init=epsg:3035")
>>>
>>> Is the .prj file text coding the same projection as epsg:3035?
>>> http://epsg.io/ says 3035 is:
>>>
>>> +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80
>>> +towgs84=0,0,0,0,0,0,0 +units=m +no_defs
>>>
>>> So yes. But there's no need to specify it in readOGR since you have
>>> the .prj file. The maptools functions readShapeSpatial and friends
>>> ignore the .prj file - I don't know why they exist any more!
>>>
>>>> r2=readShapeSpatial("BiogeoRegions2011.shp")
>>>> proj4string(r2)
>>> [1] NA
>>>
>>> Ouch.
>>>
>>> Barry
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
| Albin Blaschka, Mag.rer.nat.
| Etrichstrasse 26, A-5020 Salzburg
| * www.albinblaschka.info *
| * www.researchgate.net/profile/Albin_Blaschka *
| - It's hard to live in the mountains, hard but not hopeless!


From alexandresantosbr at yahoo.com.br  Mon Feb  9 18:09:33 2015
From: alexandresantosbr at yahoo.com.br (Alexandre Santos)
Date: Mon, 9 Feb 2015 17:09:33 +0000 (UTC)
Subject: [R-sig-Geo] Move all the polygon vertices
Message-ID: <1590792229.1991974.1423501773145.JavaMail.yahoo@mail.yahoo.com>

Dear Members,
? ? ? I created a polygon (c1) below with the vertices data in UTMand I would like to know, if there are any function to move all the vertice in 30 metersinside with the reduction of my polygon area?

#Polygon coordinates --------------------------------------------------------------x.coords1<-c(371299.9, ? ?371266.4, ? ?371205.6, ? ?371111.8, 371047.6, ? ?371018.2, ? ?371014.0,? ? ? ? ? ? ? 371009.3, ? ?370983.1, ? ?370919.7, ? ?370853.6, 370785.6, ? ?370748.8, ? ?370711.8,? ? ? ? ? ? ? 370687.8, ? ?370696.4, ? ?370785.9, ? ?370885.5, 371035.8, ? ?371148.1, ? ?371205.2,? ? ? ? ? ? ? 371231.7, ? ?371236.5, ? ?371240.3, ? ?371285.8, 371326.5, ? ?371397.2, ? ?371417.1,? ? ? ? ? ? ? 371432.9, ? ?371445.0, ? ?371455.7, ? ?371466.4, 371476.6, ? ?371502.6, ? ?371536.0,? ? ? ? ? ? ? 371550.0, ? ?371546.8, ? ?371528.3, ? ?371470.0, 371393.3, ? ?371299.9, ? ?371299.9)
y.coords1<-c(8246589, ? ?8246560, ? ?8246508, ? ?8246428, 8246373, ? ?8246349, ? ?8246348,? ? ? ? ? ? ?8246352, ? ?8246385, ? ?8246465, ? ?8246551, 8246638, ? ?8246685, ? ?8246732,? ? ? ? ? ? ?8246764, ? ?8246771, ? ?8246846, ? ?8246932, 8247062, ? ?8247160, ? ?8247209,? ? ? ? ? ? ?8247230, ? ?8247224, ? ?8247221, ? ?8247160, 8247107, ? ?8247016, ? ?8246991,? ? ? ? ? ? ?8246967, ? ?8246939, ? ?8246914, ? ?8246892, 8246875, ? ?8246846, ? ?8246821,? ? ? ? ? ? ?8246809, ? ?8246802, ? ?8246785, ? ?8246735, 8246669, ? ?8246589, ? ?8246589)

# Create a polygont05<-unique(data.frame(x=rev(x.coords1),y=rev(y.coords1)))c1 = cbind (t05$x, t05$y)r1 = rbind (c1, c1[1, ]) ?# juntaplot(c1) ##Plot the polygonpolygon(c1)## Countour#
Thanks in advance,
Alexandre
	[[alternative HTML version deleted]]


From g.ottoni at gmail.com  Mon Feb  9 18:10:06 2015
From: g.ottoni at gmail.com (Guilherme Ottoni)
Date: Mon, 9 Feb 2015 15:10:06 -0200
Subject: [R-sig-Geo] Local indicators for categorical data - spatial analysis
Message-ID: <CAK0WGMZC0iPTNd8jhf6LUD4hvw8je7WSjAVNuaPRHNtWWp3-HQ@mail.gmail.com>

Hi listers,

I'm in the final sprint at my thesis in poverty and I would like to try to
find clusters, like LISA's clusters, for vulnerability to poverty. However,
my data is categorical, 3 categories, and LISA suits better in continuous
data.

I have been searching about any software or script which executes the
join-count test for 3 categories at individual level. In other words, a
LISA ,or LICD as Boots named it in the paper Developing Local Measures of
Spatial Association for Categorical Data.

All I have found so far is the Join-Count statistic for the whole data.

Does anyone know if something has already been done at this area?

PS: sorry for the grammar errors.

Guilherme

	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Mon Feb  9 18:57:08 2015
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 9 Feb 2015 17:57:08 +0000
Subject: [R-sig-Geo] Move all the polygon vertices
In-Reply-To: <1590792229.1991974.1423501773145.JavaMail.yahoo@mail.yahoo.com>
References: <1590792229.1991974.1423501773145.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CANVKczPaJGx8+jvy-v5WgTF7wVH4aabJs4f_OreDaY1_4hf-Mw@mail.gmail.com>

You need the sp package for making spatial polygons objects and the
rgeos package for doing buffering:

library(sp)
# convert your `r1` into a SpatialPolygons object:

p = SpatialPolygons(list(Polygons(list(Polygon(r1)),ID=1)))
plot(p)

library(rgeos)
# use a negative buffer for inside buffers:
bp = gBuffer(p, width=-30)
plot(bp, add=TRUE)

That should do it...

Barry



On Mon, Feb 9, 2015 at 5:09 PM, Alexandre Santos
<alexandresantosbr at yahoo.com.br> wrote:
> Dear Members,
>       I created a polygon (c1) below with the vertices data in UTMand I would like to know, if there are any function to move all the vertice in 30 metersinside with the reduction of my polygon area?
>
> #Polygon coordinates --------------------------------------------------------------x.coords1<-c(371299.9,    371266.4,    371205.6,    371111.8, 371047.6,    371018.2,    371014.0,              371009.3,    370983.1,    370919.7,    370853.6, 370785.6,    370748.8,    370711.8,              370687.8,    370696.4,    370785.9,    370885.5, 371035.8,    371148.1,    371205.2,              371231.7,    371236.5,    371240.3,    371285.8, 371326.5,    371397.2,    371417.1,              371432.9,    371445.0,    371455.7,    371466.4, 371476.6,    371502.6,    371536.0,              371550.0,    371546.8,    371528.3,    371470.0, 371393.3,    371299.9,    371299.9)
> y.coords1<-c(8246589,    8246560,    8246508,    8246428, 8246373,    8246349,    8246348,             8246352,    8246385,    8246465,    8246551, 8246638,    8246685,    8246732,             8246764,    8246771,    8246846,    8246932, 8247062,    8247160,    8247209,             8247230,    8247224,    8247221,    8247160, 8247107,    8247016,    8246991,             8246967,    8246939,    8246914,    8246892, 8246875,    8246846,    8246821,             8246809,    8246802,    8246785,    8246735, 8246669,    8246589,    8246589)
>
> # Create a polygont05<-unique(data.frame(x=rev(x.coords1),y=rev(y.coords1)))c1 = cbind (t05$x, t05$y)r1 = rbind (c1, c1[1, ])  # juntaplot(c1) ##Plot the polygonpolygon(c1)## Countour#
> Thanks in advance,
> Alexandre
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From subbu_843 at yahoo.co.in  Mon Feb  9 20:48:33 2015
From: subbu_843 at yahoo.co.in (subash)
Date: Mon, 9 Feb 2015 12:48:33 -0700 (MST)
Subject: [R-sig-Geo] block and output grid size in block kriging
Message-ID: <1423511313010-7587770.post@n2.nabble.com>

Dear Group,

I was using bock kriging  for groundwater level data. I was wondering, if
the output.grd size and the block size can be different.

For example, In the example for the case given below, I need block kriged
average of 5000x5000. The output grid size given is 1000m*1000m. Is it
correct?

Or should the output.grd size also be 5000mx5000m as in block size?


# IMP : There are the centre coordinates for block kriging and not corner
coordiantes.
Xmin = 581000 + 2500
/Xmax = 711000 - 2500
Ymin = 1266000 + 2500
Ymax = 1371000 - 2500

output.grd = expand.grid(x=seq(from=Xmin, to=Xmax,by=1000),y=seq(from=Ymin,
to=Ymax, by=1000))
coordinates(output.grd) = c("x", "y")
gridded(output.grd) = TRUE

krig =
krige(borewell.piezo[,3]~1,location~Easting+Northing,data=borewell.piezo,newdata=output.grd,model
= vario.fit,block=c(5000,5000))/


Thanks & Regards,
Subash



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/block-and-output-grid-size-in-block-kriging-tp7587770.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From edzer.pebesma at uni-muenster.de  Mon Feb  9 20:52:32 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 09 Feb 2015 20:52:32 +0100
Subject: [R-sig-Geo] block and output grid size in block kriging
In-Reply-To: <1423511313010-7587770.post@n2.nabble.com>
References: <1423511313010-7587770.post@n2.nabble.com>
Message-ID: <54D91000.1030301@uni-muenster.de>



On 02/09/2015 08:48 PM, subash wrote:
> Dear Group,
> 
> I was using bock kriging  for groundwater level data. I was wondering, if
> the output.grd size and the block size can be different.

Yes, they can be different. Blocks are centered over grid cell centers,
and may overlap, be identical to grid cells, or smaller than grid cells
and have space between them.

> 
> For example, In the example for the case given below, I need block kriged
> average of 5000x5000. The output grid size given is 1000m*1000m. Is it
> correct?
> 
> Or should the output.grd size also be 5000mx5000m as in block size?
> 
> 
> # IMP : There are the centre coordinates for block kriging and not corner
> coordiantes.
> Xmin = 581000 + 2500
> /Xmax = 711000 - 2500
> Ymin = 1266000 + 2500
> Ymax = 1371000 - 2500
> 
> output.grd = expand.grid(x=seq(from=Xmin, to=Xmax,by=1000),y=seq(from=Ymin,
> to=Ymax, by=1000))
> coordinates(output.grd) = c("x", "y")
> gridded(output.grd) = TRUE
> 
> krig =
> krige(borewell.piezo[,3]~1,location~Easting+Northing,data=borewell.piezo,newdata=output.grd,model
> = vario.fit,block=c(5000,5000))/
> 
> 
> Thanks & Regards,
> Subash
> 
> 
> 
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/block-and-output-grid-size-in-block-kriging-tp7587770.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics, University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences: http://elsevier.com/locate/inca/398

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150209/814ae8de/attachment.bin>

From macqueen1 at llnl.gov  Tue Feb 10 00:44:46 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 9 Feb 2015 23:44:46 +0000
Subject: [R-sig-Geo] Problem with getGridIndex() ?
Message-ID: <D0FE866D.11E168%macqueen1@llnl.gov>

I have defined an example SpatialPointsDataFrame, and then a GridTopology
following the example in Applied Spatial Data Analysis with R (2008, pg
48-49). With them, getGridIndex() fails. Suggestions would be much
appreciated.

Here's the (reproducible) example:

------------------------------------
require(sp)

spd <- data.frame(x=c(0,100), y=c(2,95), z=1:2)
coordinates(spd) <- c('x','y')

cdim <- 5
bb <- bbox(spd)
cs <- c(cdim, cdim)               ## cellsize
cc <- bb[,1] + cs/2               ## the lower left cell center
cd <- ceiling(diff(t(bb))/cs)     ## cells to over all the data

gr <- GridTopology(cellcentre.offset=cc,
                   cellsize=cs,
                   cells.dim=cd)

cnum <- getGridIndex( coordinates(spd), gr)



Which results in:

> cnum <- getGridIndex( coordinates(spd), gr)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
      0       5      10      10      15      20
Error in getGridIndex(coordinates(spd), gr) : this.idx out of range

------------------------------------

This looks like a boundary issue, in that the upper and lower boundaries
of the grid cells in the x dimension are 0, 100, and so are the upper and
lower x coordinates.


I looked at getGridIndex, and found that changing
   outside = this.idx >= grid at cells.dim[i] | this.idx < 0
to
   outside = this.idx > grid at cells.dim[i] | this.idx < 0

"fixes" the error in this example.

However, in my original example, which I will share upon request, it gets
past the "out of range" error, but then fails with the "index outside
boundaries" error.



------------------------------------
R was started using
   R --vanilla

> sessionInfo()
R version 3.1.2 (2014-10-31)
Platform: x86_64-apple-darwin13.4.0 (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] sp_1.0-17

loaded via a namespace (and not attached):
[1] grid_3.1.2      lattice_0.20-29



-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


From subbu_843 at yahoo.co.in  Tue Feb 10 06:21:42 2015
From: subbu_843 at yahoo.co.in (subash)
Date: Mon, 9 Feb 2015 22:21:42 -0700 (MST)
Subject: [R-sig-Geo] block and output grid size in block kriging
In-Reply-To: <54D91000.1030301@uni-muenster.de>
References: <1423511313010-7587770.post@n2.nabble.com>
	<54D91000.1030301@uni-muenster.de>
Message-ID: <1423545702243-7587773.post@n2.nabble.com>

Dear Edzer,

Thanks for quick reply. A question still lingering in my mind is below

In a similar lines I was using block kriging of rainfall with block size of
25x25Km. The output grid  chosen is 1x1Km. This is resulting in kriging
estimate computed at 1x1Km . However, my interest is to get 25x25Km kriging
estimate.

The approach I tried was setting the output grid mesh as 25Km, but this is
wrong as the block average would be arrived from 1 point only.

output.grd = expand.grid(x=seq(from=tmp$min[1],
to=tmp$max[1],by=1),y=seq(from=tmp$min[2], to=tmp$max[2], by=1))
coordinates(output.grd) = c("x", "y")
gridded(output.grd) = TRUE

block_Krig = krige(stn.rain.data[,3]~1,location = ~easting+northing, data =
stn.rain.data,newdata=output.grd,model = clim.vrmod,block=c(25,25)) 

What is that I am missing.


Thanks in advance
Subash



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/block-and-output-grid-size-in-block-kriging-tp7587770p7587773.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From edzer.pebesma at uni-muenster.de  Tue Feb 10 08:04:47 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 10 Feb 2015 08:04:47 +0100
Subject: [R-sig-Geo] block and output grid size in block kriging
In-Reply-To: <1423545702243-7587773.post@n2.nabble.com>
References: <1423511313010-7587770.post@n2.nabble.com>	<54D91000.1030301@uni-muenster.de>
	<1423545702243-7587773.post@n2.nabble.com>
Message-ID: <54D9AD8F.8000905@uni-muenster.de>



On 02/10/2015 06:21 AM, subash wrote:
> Dear Edzer,
> 
> Thanks for quick reply. A question still lingering in my mind is below
> 
> In a similar lines I was using block kriging of rainfall with block size of
> 25x25Km. The output grid  chosen is 1x1Km. This is resulting in kriging
> estimate computed at 1x1Km . However, my interest is to get 25x25Km kriging
> estimate.

So, set up a prediction grid (newdata) with 1 km x 1 km, and specify
block = c(25, 25), assuming km is your distance unit - that seems to be
what you do below.

> 
> The approach I tried was setting the output grid mesh as 25Km, but this is
> wrong as the block average would be arrived from 1 point only.

I don't understand this sentence.

> 
> output.grd = expand.grid(x=seq(from=tmp$min[1],
> to=tmp$max[1],by=1),y=seq(from=tmp$min[2], to=tmp$max[2], by=1))
> coordinates(output.grd) = c("x", "y")
> gridded(output.grd) = TRUE
> 
> block_Krig = krige(stn.rain.data[,3]~1,location = ~easting+northing, data =
> stn.rain.data,newdata=output.grd,model = clim.vrmod,block=c(25,25)) 
> 
> What is that I am missing.

I don't know. For more readable code, I'd suggest:

# assume col 3 in stn.rain.data is called "prec"
coordinates(stn.rain.data) = ~easting + northing
block_Krig = krige(prec~1, stn.rain.data, output.grd, clim.vrmod,
	block = c(25,25))

> 
> 
> Thanks in advance
> Subash
> 
> 
> 
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/block-and-output-grid-size-in-block-kriging-tp7587770p7587773.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics, University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences: http://elsevier.com/locate/inca/398

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150210/ba71b838/attachment.bin>

From g.ottoni at gmail.com  Tue Feb 10 19:55:25 2015
From: g.ottoni at gmail.com (Guilherme Ottoni)
Date: Tue, 10 Feb 2015 16:55:25 -0200
Subject: [R-sig-Geo] Local indicators for categorical data - spatial analysis
Message-ID: <CAK0WGMYE3ZUSUEeK+H3DMLmYw1dB2FijHz_guQPbf93FqGYc=g@mail.gmail.com>

I think the last e-mail was not ideally configured for the list, so
I'm re-sending it. Sorry if it duplicates.


Hi listers,

I'm in the final sprint at my thesis in poverty and I would like to
try to find clusters, like LISA's clusters, for vulnerability to
poverty. However, my data is categorical, 3 categories, and LISA suits
better in continuous data.

I have been searching about any software or script which executes the
join-count test for 3 categories at individual level. In other words,
a LISA ,or LICD as Boots named it in the paper Developing Local
Measures of Spatial Association for Categorical Data.

All I have found so far is the Join-Count statistic for the whole data.

Does anyone know if something has already been done at this area?

PS: sorry for the grammar errors.

Guilherme


From jed.long at st-andrews.ac.uk  Wed Feb 11 10:52:34 2015
From: jed.long at st-andrews.ac.uk (JLong)
Date: Wed, 11 Feb 2015 02:52:34 -0700 (MST)
Subject: [R-sig-Geo] Local indicators for categorical data - spatial
	analysis
In-Reply-To: <CAK0WGMYE3ZUSUEeK+H3DMLmYw1dB2FijHz_guQPbf93FqGYc=g@mail.gmail.com>
References: <CAK0WGMYE3ZUSUEeK+H3DMLmYw1dB2FijHz_guQPbf93FqGYc=g@mail.gmail.com>
Message-ID: <1423648354897-7587776.post@n2.nabble.com>

Hi Guilherme,

Send me an email to jed.long at st-andrews.ac.uk
I think I have some software/code that Barry Boots developed way back then
somewhere on my machine...

Cheers,
Jed




-----
Jed Long
Lecturer in GeoInformatics
Department of Geography & Sustainable Development
University of St Andrews, UK
--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Local-indicators-for-categorical-data-spatial-analysis-tp7587775p7587776.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Wed Feb 11 13:34:36 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 11 Feb 2015 13:34:36 +0100
Subject: [R-sig-Geo] Local indicators for categorical data - spatial
 analysis
In-Reply-To: <1423648354897-7587776.post@n2.nabble.com>
References: <CAK0WGMYE3ZUSUEeK+H3DMLmYw1dB2FijHz_guQPbf93FqGYc=g@mail.gmail.com>
	<1423648354897-7587776.post@n2.nabble.com>
Message-ID: <alpine.LFD.2.11.1502111255160.32577@reclus.nhh.no>

On Wed, 11 Feb 2015, JLong wrote:

> Hi Guilherme,
>
> Send me an email to jed.long at st-andrews.ac.uk
> I think I have some software/code that Barry Boots developed way back then
> somewhere on my machine...

LICD are not implemented, but you can get part of the way (just the 
tabulations) by:

library(spdep)
data(oldcol)
HICRIME <- cut(COL.OLD$CRIME, breaks=c(0,35,80), labels=c("low","high"))
names(HICRIME) <- rownames(COL.OLD)
lw <- nb2listw(COL.nb, style="B")
joincount.multi(HICRIME, lw)

for a global baseline, and

Vis <- lapply(1:length(HICRIME), function(i) listw2star(lw, i, "B",
   n=length(HICRIME), D=NULL, a=NULL))
ljcs <- t(sapply(Vis, function(x) { res <- joincount.multi(HICRIME, x,
   zero.policy=TRUE); res[-nrow(res),1]}))

There are warnings because inference fails (as it should), but the tally 
is the same, with:

apply(ljcs, 2, sum)/2

giving the counts of joins by type, dropping double-counting in the 
summation. listw2star() is used in localmoran.sad() and elsewhere to 
generate observation-wise weights objects. This isn't an implementation of 
LICD in that the subregion for each i is simply its set of neighbours, not 
a moving window, but at least provides a basis for classification.

As with other LISA, it is important to remove the effects of covariates, 
so that an inferential approach might be based on GLM residuals (just a 
speculation).

Hope this helps,

Roger

>
> Cheers,
> Jed
>
>
>
>
> -----
> Jed Long
> Lecturer in GeoInformatics
> Department of Geography & Sustainable Development
> University of St Andrews, UK
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Local-indicators-for-categorical-data-spatial-analysis-tp7587775p7587776.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From chirleu at gmail.com  Thu Feb 12 09:51:21 2015
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Thu, 12 Feb 2015 09:51:21 +0100
Subject: [R-sig-Geo] differences in home range estimation between kernelUD
 (adehabitatHR) and kernel2d (splancs)
Message-ID: <CALC46t9wMRidGiiK5cCqxorZGafhfh5v3FVonZbcc1HMkWbAEw@mail.gmail.com>

Hi list,
I'm estimating home range sizes (95% kernel) for 40 fish individuals.
I replicated the estimations with two different functions in two different
R-libraries: kernelUD in adehabitatHR and kernel2d in splancs.
I'm getting quite different results from both methods, even if I use the
same smoothing factor and the same grid.

The code to estimate the kernels is (I'm not including the code to get the
HR area since I just want to know if the code below should provide the same
results):

######################################### with adehabitatHR
# Define grid
x <- seq(495000,499000,by=10)  # where resolution is the grid size you
desire
y <- seq(6494000,6498500,by=10)
xy <- expand.grid(x=x,y=y)
coordinates(xy) <- ~x+y
proj4string(xy) <- CRS("+proj=utm +zone=32")
gridded(xy) <- TRUE
class(xy)

h=50        # set bandwidth:
g=xy        # set grid, xy is the study area
e=0.5       # set extent

# Kernel
 kud1=kernelUD(detections[,1],h=h, grid=g, extent=e,kern=c("bivnorm"))

######################################### with splancs
# Define polygon
polyx<-c(495000,499000,499000,495000,495000)
polyy<-c(6494000,6494000,6498500,6498500,6494000)
plot(polyx,polyy)
points(detections)
polygon<-data.frame(x=polyx,y=polyy)
polygon<-as.matrix(polygon)

# Kernel
kud2<-kernel2d(coordinates(detections),polygon,h0=50,nx=1000,ny=1000)

## END ##

This is the xyplot of the estimates from both methods. See that
adehabitatHR overestimates quite a lot (HR are much more rounded than with
splancs) and that there are three points which do not fall in the straight
line...this intrigues me a lot...

[image: Im?genes integradas 1]

I know the resolution of both grids is not exactly the same. Correct me if
needed, but in the case of adehabitat the resolution is 10 meters, and in
the case of splancs is 4 meters on the Longitude and 4.5 meters on the
Latitude. But I feel that this is not causing the difference, since I have
tested many different resolutions in adehabitatHR and got very very similar
results in all cases.
So why am I getting so different results? Shouldn't I expect approximately
the same results? Is there any difference in the way that both functions
estimate the kernel? I could provide some data if it is needed, but I guess
my question is quite general about the differences between both functions.

Thanks in advance,

David
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150212/542210a6/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 16205 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150212/542210a6/attachment.png>

From subbu_843 at yahoo.co.in  Thu Feb 12 16:19:26 2015
From: subbu_843 at yahoo.co.in (subash)
Date: Thu, 12 Feb 2015 08:19:26 -0700 (MST)
Subject: [R-sig-Geo] block and output grid size in block kriging
In-Reply-To: <54D9AD8F.8000905@uni-muenster.de>
References: <1423511313010-7587770.post@n2.nabble.com>
	<54D91000.1030301@uni-muenster.de>
	<1423545702243-7587773.post@n2.nabble.com>
	<54D9AD8F.8000905@uni-muenster.de>
Message-ID: <1423754366066-7587780.post@n2.nabble.com>

Dear Edzer, 

To understand why block kriging results vary,with different grid sizes, to
keep gridsize identical to grid cells, and smaller than grid cells.

library(gstat)
data(meuse)
coordinates(meuse) = ~x+y
data(meuse.grid)
gridded(meuse.grid) = ~x+y

lzn.vgm<- variogram(log(zinc)~1, meuse)
lzn.fit1 <- fit.variogram(lzn.vgm, model=vgm(psill=1, model="Sph",
range=900, nugget=1))
plot(lzn.vgm, lzn.fit1)

# Ordinary kriging
lzn.ok <- krige(log(zinc)~1, meuse, meuse.grid, model = lzn.fit1)

#Block kriging 
lzn.bok <- krige(log(zinc)~1, meuse, meuse.grid, model = lzn.fit1,
block=c(40,40))

# Choosing a random location with the centre coordiantes(xx,yy) and find the
corresponding block kriged estimate
xx = 181140
yy = 333100
est.bk = lzn.bok$var1.pred[(lzn.bok$x==xx)&(lzn.bok$y==yy)]
[1] 6.499158
est.ok =lzn.ok$var1.pred[(lzn.ok$x==xx)&(lzn.ok$y==yy)]
[1] 6.499624

Why are the kriging estimates at a point different in block and ordinary
kriging, when the grid size is isentical to (40 x 40) or less than(20x20)
the meuse data.

Thanks







diff= m.bk - est.bk



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/block-and-output-grid-size-in-block-kriging-tp7587770p7587780.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From edzer.pebesma at uni-muenster.de  Thu Feb 12 16:30:23 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 12 Feb 2015 16:30:23 +0100
Subject: [R-sig-Geo] block and output grid size in block kriging
In-Reply-To: <1423754366066-7587780.post@n2.nabble.com>
References: <1423511313010-7587770.post@n2.nabble.com>	<54D91000.1030301@uni-muenster.de>	<1423545702243-7587773.post@n2.nabble.com>	<54D9AD8F.8000905@uni-muenster.de>
	<1423754366066-7587780.post@n2.nabble.com>
Message-ID: <54DCC70F.9040004@uni-muenster.de>



On 02/12/2015 04:19 PM, subash wrote:
> Dear Edzer, 
> 
> To understand why block kriging results vary,with different grid sizes, to
> keep gridsize identical to grid cells, and smaller than grid cells.
> 
> library(gstat)
> data(meuse)
> coordinates(meuse) = ~x+y
> data(meuse.grid)
> gridded(meuse.grid) = ~x+y
> 
> lzn.vgm<- variogram(log(zinc)~1, meuse)
> lzn.fit1 <- fit.variogram(lzn.vgm, model=vgm(psill=1, model="Sph",
> range=900, nugget=1))
> plot(lzn.vgm, lzn.fit1)
> 
> # Ordinary kriging
> lzn.ok <- krige(log(zinc)~1, meuse, meuse.grid, model = lzn.fit1)
> 
> #Block kriging 
> lzn.bok <- krige(log(zinc)~1, meuse, meuse.grid, model = lzn.fit1,
> block=c(40,40))
> 
> # Choosing a random location with the centre coordiantes(xx,yy) and find the
> corresponding block kriged estimate
> xx = 181140
> yy = 333100
> est.bk = lzn.bok$var1.pred[(lzn.bok$x==xx)&(lzn.bok$y==yy)]
> [1] 6.499158
> est.ok =lzn.ok$var1.pred[(lzn.ok$x==xx)&(lzn.ok$y==yy)]
> [1] 6.499624
> 
> Why are the kriging estimates at a point different in block and ordinary
> kriging, when the grid size is isentical to (40 x 40) or less than(20x20)
> the meuse data.

because lzn.ok contains ordinary point kriging estimates, for points
laid out on a grid, and lzn.bok contains ordinary 40 m x 40 m block
kriging estimates: a different quantity is predicted.

> 
> Thanks
> 
> 
> 
> 
> 
> 
> 
> diff= m.bk - est.bk
> 
> 
> 
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/block-and-output-grid-size-in-block-kriging-tp7587770p7587780.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics, University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences: http://elsevier.com/locate/inca/398

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150212/d43ed3a4/attachment.bin>

From subbu_843 at yahoo.co.in  Thu Feb 12 17:22:51 2015
From: subbu_843 at yahoo.co.in (subash)
Date: Thu, 12 Feb 2015 09:22:51 -0700 (MST)
Subject: [R-sig-Geo] block and output grid size in block kriging
In-Reply-To: <1423754366066-7587780.post@n2.nabble.com>
References: <1423511313010-7587770.post@n2.nabble.com>
	<54D91000.1030301@uni-muenster.de>
	<1423545702243-7587773.post@n2.nabble.com>
	<54D9AD8F.8000905@uni-muenster.de>
	<1423754366066-7587780.post@n2.nabble.com>
Message-ID: <1423758171180-7587782.post@n2.nabble.com>

Dear Edzer,

Thanks for the clarification.Still it not clear to me.

I added an image below showing the block and the grids. If my visualization
is correct then for a block of (40,40), there is only 1 grid points. If Yes,
then ordinary kriging estimate and block kriging estimate for block size
(40,40) should be same.

<http://r-sig-geo.2731867.n2.nabble.com/file/n7587782/block_kriging_framework.png> 

Thanks in advance



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/block-and-output-grid-size-in-block-kriging-tp7587770p7587782.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From edzer.pebesma at uni-muenster.de  Thu Feb 12 19:20:55 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 12 Feb 2015 19:20:55 +0100
Subject: [R-sig-Geo] block and output grid size in block kriging
In-Reply-To: <1423758171180-7587782.post@n2.nabble.com>
References: <1423511313010-7587770.post@n2.nabble.com>	<54D91000.1030301@uni-muenster.de>	<1423545702243-7587773.post@n2.nabble.com>	<54D9AD8F.8000905@uni-muenster.de>	<1423754366066-7587780.post@n2.nabble.com>
	<1423758171180-7587782.post@n2.nabble.com>
Message-ID: <54DCEF07.7060002@uni-muenster.de>

The drawing (thanks!) suggests that you think that the point over which
a kriging block is centered is not the center point of a grid cell. This
is wrong: the coordinates of grid cells, obtained e.g. by

require(sp)
demo(meuse, ask = FALSE)
coordinates(meuse.grid)

are grid cell centers. You can verify this, e.g. for the first 20 grid
cells / pixels with

plot(as(meuse.grid[1:20,], "SpatialPolygons"))
points(meuse.grid[1:20,])

I also tried to point out in my previous answer that you are not looking
at "ordinary kriging" vs "block kriging", but at "ordinary point
kriging" vs. "ordinary block kriging". If your observations are not
constant and you don't use a pure nugget model, point kriging and block
kriging estimates will always be different.


On 02/12/2015 05:22 PM, subash wrote:
> Dear Edzer,
> 
> Thanks for the clarification.Still it not clear to me.
> 
> I added an image below showing the block and the grids. If my visualization
> is correct then for a block of (40,40), there is only 1 grid points. If Yes,
> then ordinary kriging estimate and block kriging estimate for block size
> (40,40) should be same.
> 
> <http://r-sig-geo.2731867.n2.nabble.com/file/n7587782/block_kriging_framework.png> 
> 
> Thanks in advance
> 
> 
> 
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/block-and-output-grid-size-in-block-kriging-tp7587770p7587782.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics, University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences: http://elsevier.com/locate/inca/398

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150212/557e67f7/attachment.bin>

From GLockhar at virginiaaquarium.com  Thu Feb 12 20:39:21 2015
From: GLockhar at virginiaaquarium.com (Gwen G. Lockhart)
Date: Thu, 12 Feb 2015 19:39:21 +0000
Subject: [R-sig-Geo] adehabitatHR KD ID and XY assignment
Message-ID: <6283DCD085FC0B4084E8AA65D9A7A1ECFF8B63AF@VBMS0008.vbgov.com>





Hello Everyone...

I am fairly new to R. I would like to use the adehabitatHR package to create kernel density and isopleths from my sea turtle GPS data. I?m running into some issues?

Basically I am having trouble assigning IDs and XY fields within R to create KDs and MCPs.

Thank you in advance for any help!

Gwen




#loading packages
`library(adehabitatHR)
library(raster)
library(rgdal)
library(maptools)`

#read CSV with UTM xy and ids

    track<-
read.table("T:/GIS/Data/Tracking/state_space_model/20150210_AbHabiatatHRmodel/All_prelim_model_6hr_utm_forage_10A.csv",
   header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE)

# Turn track into a SpatialPointsDataFrame sby specifying that the "X" and "Y" columns are the coordinates:
coordinates(track) <- c("X", "Y")
class(track)
plot(track)


#Project into utm:
proj4string(track) <- CRS("+init=epsg:32618")
#read shore;ine file
shore <- readShapeSpatial("C:/Users/gemme001/Desktop/R_state_space/STATES_VA_COAST_UTM.shp", delete_null_obj=TRUE)
plot(shore)
proj4string(shore) <- CRS("+init=epsg:32618")


#Add to list the list with the names "map" and "relocs"
my.homerange.data <- list(map = shore, relocs = track)

#####THIS IS WHERE I AM RUNNING INTO ISSUES#####
#Assign IDs and XY ? the IDs work but coordinates don?t work.  I get the following error: Error in `[.data.frame`(x at data, i, j, ..., drop = FALSE) : undefined columns selected
id<-my.homerange.data$relocs$Name
xy<-(my.homerange.data$relocs["X","Y"]


#Create CP ? this works
cp <- mcp(my.homerange.data$relocs[,1], percent=95)
class(cp)
plot(cp)


#Create KUD.  This doesn?t work.  I get the following:  Error in xy.coords(x, y, xlabel, ylabel, log) : 'x' is a list, but does not have components 'x' and 'y'
kud <- kernelUD(track[,1], h="href")

	[[alternative HTML version deleted]]


From giuseppe.amatulli at gmail.com  Thu Feb 12 22:51:07 2015
From: giuseppe.amatulli at gmail.com (Giuseppe Amatulli)
Date: Thu, 12 Feb 2015 16:51:07 -0500
Subject: [R-sig-Geo] Fwd: SPATIO-TEMPORAL ANALYSIS AND BIG DATA PROCESSING
 USING FREE AND OPEN SOURCE SOFTWARE
In-Reply-To: <CAKoiDHJ17n2R16yfOsD6hjoUNwxTKNKtVMNtNBrAzGT71CoTjw@mail.gmail.com>
References: <CAKoiDHJ17n2R16yfOsD6hjoUNwxTKNKtVMNtNBrAzGT71CoTjw@mail.gmail.com>
Message-ID: <CAKoiDHKncPmh93qmNVPcG-P4fBoXEcdw8toxuaEqvoTgfkmqqg@mail.gmail.com>

HI,
Apologies for cross-posting:

Summer school organized by www.spatial-ecology.net:

*SPATIO-TEMPORAL ANALYSIS AND BIG DATA PROCESSING USING FREE AND OPEN
SOURCE SOFTWARE *(basic and advanced levels)

Over the last few decades there has been an explosion in the availability
of data for environmental research, and in particular for spatio-temporal
analysis. We are now able to address a number of important questions, both
new and old, with unprecedented rigor and generality. Leveraging these
exciting new data streams requires tools and increasingly complex
workflows. This 6-day course introduces a set of free and open source
software (GRASS, R, Python, AWK, BASH, GDAL) to perform spatio-temporal
analysis and modelling of environmental data in a Linux environment. We
also introduce multi-core, cloud and cluster computation procedures. The
course consists of a set of lectures and practical hands-on sessions in
which participants perform spatial and temporal analysis using Geographic
Information System and Remote Sensing concepts. Although courses focuses on
the command line instead of the graphical user interface, no prior
experience with programming or command line interfaces is assumed or
required.  To cater to students with prior programming experience, we will
hold parallel sessions that introduce more advanced material. Our main
focus is on teaching self learning and problem solving more than the use of
specific tools (see: our teaching method
<http://www.spatial-ecology.net/giuseppe/publications/Amatulli_et_al_OGRS.pdf>)
so participants will be able to progress and adapt to learn the newest
available data science techniques.

*Location:  15-20 June 2015 - Matera - Italy*

More info at www.spatial-ecology.net:Staff

Dr. Giuseppe Amatulli (Yale University, USA
<http://sbsc.yale.edu/giuseppe-amatulli> ; www.spatial-ecology.net)

Dr. Stefano Casalegno (University of Exeter, UK
<http://www.exeter.ac.uk/esi/people/casalegno/> ; www.spatial-ecology.net)

Dr. Pieter Kempeneers (VITO <https://vito.be/en/land-use> ; pktools
<http://pktools.nongnu.org/html/index.html>)

Dr. Daniel McInerney ( Coillte Teoranta <http://www.coillte.ie>)

-- 
Giuseppe Amatulli, Ph.D.

Department of Ecology and Evolutionary Biology, Yale University.
Jetz Lab, Room 405

P.O. Box 208106
New Haven, CT 06520-8106
Teaching: spatial-ecology.net
Work:  http://sbsc.yale.edu/giuseppe-amatulli
<http://www.spatial-ecology.net>

	[[alternative HTML version deleted]]


From corderos at umich.edu  Thu Feb 12 23:09:27 2015
From: corderos at umich.edu (Silvia Cordero-Sancho)
Date: Thu, 12 Feb 2015 17:09:27 -0500
Subject: [R-sig-Geo] spatstat error: owin & "im" object
Message-ID: <CAORmci-3H98AL_j9vBM7FxDjveSPMDjR+34wV=LaC2TQg+BL9g@mail.gmail.com>

Hello SIG-GEO community,

I followed the example for the Extract.im function to "subset" a object of
class "im" to the extent of an owin.

# make up an image
 X <- setcov(unit.square())
 plot <http://inside-r.org/r-doc/graphics/plot>(X)

 # a rectangular subset
 W <- owin(c <http://inside-r.org/r-doc/base/c>(0,0.5),c
<http://inside-r.org/r-doc/base/c>(0.2,0.8))
 Y <- X[W]
 plot <http://inside-r.org/r-doc/graphics/plot>(Y)


However, when I applied to my data, it does not properly work, the output
object is not a 'im'

Here the code:

# 1. Import tiff format file. It is a raster file, spatial resolution 30 x
30 m,  ny=2667, nx=700. Pixel value ranges: 1 to 11, each one represent a
category.

tn<-as(readGDAL("..../rasters/tnn.tif"),"im")
> class(tn)
[1] "im"

# 2. Subset to owin extent:

> class(W)
[1] "owin"

# note: *W* was created from a irregular polygonal shapefile, and it is the
same file used to define the owin for the point pattern

tn2<-tn[W]
class(tn2)
[1] "integer"


The same problem occur with all the tiff-format imported grids, (e.g. DEM)


Has anyone experienced this problem before? Does anyone has a suggestion? I
will appreciate your input

Thank you

Silvia Cordero

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Fri Feb 13 01:14:23 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 13 Feb 2015 13:14:23 +1300
Subject: [R-sig-Geo] spatstat error: owin & "im" object
In-Reply-To: <CAORmci-3H98AL_j9vBM7FxDjveSPMDjR+34wV=LaC2TQg+BL9g@mail.gmail.com>
References: <CAORmci-3H98AL_j9vBM7FxDjveSPMDjR+34wV=LaC2TQg+BL9g@mail.gmail.com>
Message-ID: <54DD41DF.2020901@auckland.ac.nz>


See at end.


On 13/02/15 11:09, Silvia Cordero-Sancho wrote:

> Hello SIG-GEO community,
>
> I followed the example for the Extract.im function to "subset" a object of
> class "im" to the extent of an owin.
>
> # make up an image
>   X <- setcov(unit.square())
>   plot <http://inside-r.org/r-doc/graphics/plot>(X)
>
>   # a rectangular subset
>   W <- owin(c <http://inside-r.org/r-doc/base/c>(0,0.5),c
> <http://inside-r.org/r-doc/base/c>(0.2,0.8))
>   Y <- X[W]
>   plot <http://inside-r.org/r-doc/graphics/plot>(Y)
>
>
> However, when I applied to my data, it does not properly work, the output
> object is not a 'im'
>
> Here the code:
>
> # 1. Import tiff format file. It is a raster file, spatial resolution 30 x
> 30 m,  ny=2667, nx=700. Pixel value ranges: 1 to 11, each one represent a
> category.
>
> tn<-as(readGDAL("..../rasters/tnn.tif"),"im")
>> class(tn)
> [1] "im"
>
> # 2. Subset to owin extent:
>
>> class(W)
> [1] "owin"
>
> # note: *W* was created from a irregular polygonal shapefile, and it is the
> same file used to define the owin for the point pattern
>
> tn2<-tn[W]
> class(tn2)
> [1] "integer"
>
>
> The same problem occur with all the tiff-format imported grids, (e.g. DEM)
>
>
> Has anyone experienced this problem before? Does anyone has a suggestion? I
> will appreciate your input.

Nothing whatever to do with "tiff" images.  The crux of the problem is 
that in your toy example, W was a rectangle; in your "real" example, W 
was a polygon.

If X is an image and W is a window, then

    X[W]

is an image *only* when W is a rectangle.  If W is not a rectangle, then
you need to do

    X[W,drop=FALSE]

to get an image as the result.  (Otherwise you get a *vector* of the 
pixel values for pixels that fall inside W.)

This is all spelled out in the help file for "[.im" but the help is 
lengthy, the possibilities are manifold and the issue is complex, so you 
would have to read the help file *very* carefully to figure this out.

I hope that the situation is clear now.

cheers,

Rolf Turner


-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From sfick at ucdavis.edu  Fri Feb 13 02:06:29 2015
From: sfick at ucdavis.edu (sfick)
Date: Thu, 12 Feb 2015 18:06:29 -0700 (MST)
Subject: [R-sig-Geo] writeOGR with 2+ layers in 1 KML file
In-Reply-To: <23DE6D62-91B6-46B2-8740-C4A03D351D4A@berkeley.edu>
References: <23DE6D62-91B6-46B2-8740-C4A03D351D4A@berkeley.edu>
Message-ID: <1423789589694-7587788.post@n2.nabble.com>

David Holstius wrote
> Hi, I would like to write two different Spatial* objects, as two different
> layers, to the same KML file using rgdal::writeOGR(). 
> 
> If I do something like:
> 
>   > writeOGR(bar, driver="KML", dsn="foo.kml", layer="bar")
> 
> ... I get a KML Document with a Folder element inside named "bar". So far,
> so good. 
> 
> But if I follow that with:
> 
>   > writeOGR(baz, driver="KML", dsn="foo.kml", layer="baz")
> 
> ... the contents of foo.kml are obliterated and replaced with new
> contents. I would prefer that another Folder, named "baz", be created in
> "foo.kml" without erasing any other Folder elements.
> 
> Is this possible? Is there a flag I didn't find? Am I doing it wrong? Many
> thanks in advance,
> 
> Very best,
> David
> 
> --
> David Holstius
> PhD Student in Environmental Health Sciences
> UC Berkeley School of Public Health
> 
> _______________________________________________
> R-sig-Geo mailing list

> R-sig-Geo@

> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

Since kml is essentially xml, one can create multiple files then combine
them manually, provided each file has the same structure...

... something like... 

mergeKML <- function(filename, x = list() ) { 
	require(XML)
	doc <- xmlRoot(xmlTreeParse(x[[1]], getDTD=F))
	for(i in 2:length(x)){
		y <- xmlRoot(xmlTreeParse(x[[i]]))
		doc[["Document"]][[i+1]] <- y[["Document"]][["Folder"]]
		doc[["Document"]][[i+2]] <- y[["Document"]][["Schema"]]
		}
	saveXML(doc, file= filename)
}
	
writeOGR(bar, driver="KML", dsn="foo.kml", layer="bar")
writeOGR(baz, driver="KML", dsn="baz.kml", layer="baz")
mergeKML('out.kml', list('foo.kml','baz.kml') )


-Steve




--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/writeOGR-with-2-layers-in-1-KML-file-tp6243676p7587788.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From FVASBIEN at atmo-alsace.net  Fri Feb 13 12:03:39 2015
From: FVASBIEN at atmo-alsace.net (FVASBIEN at atmo-alsace.net)
Date: Fri, 13 Feb 2015 12:03:39 +0100
Subject: [R-sig-Geo] SpTransform problem : conversion from WGS84 to UTM32N
	unregular
Message-ID: <OFCC57BD15.0DA1F4D4-ONC1257DEB.003C5169-C1257DEB.003CC2AC@atmo-alsace.net>


Hi list,

I use a kriging package for several years and it works successfully in my
automated air-quality forecasting chain, by using old versions of
libraries(e.g. 2009/2010 versions of sp, rgdal, ?).
Currently, I?ve to change of server (from 32 bits to 64 bits) and I?ve
installed the same package (and so the last delivered versions of
libraries) on this new server.

I encounter an annoying problem: by using strictly the same package and the
same inputs data, the conversion of grids from Lon-Lat WGS84 (irregular
grid) to UTM32 doesn?t lead to a strictly regular grid, and this leads to a
problem for the kriging process.
By using the old libraries versions, the UTM32 grid obtained is strictly
regular with a step of 3km !

Concretely, my package begins by extracting the longitude and latitude of
my CTM model outputs at 3km resolution. I assign to these data the WGS84
projection via the attribute "CRS (" + init = epsg: 4326 ")". After this
treatment, I obtain as expected a list of lon-lat on each cell centroide.
This is the next step which raises concern: to convert this grid into a
regular grid, I apply the grid conversion into utm32 via the spTransform
package and the attribute "CRS ("+proj=utm +zone=32 +ellps=intl
+towgs84=-87, -96 , -120 +units=m +no_defs?)". My domain covers the East of
France and goes across Germany, hence the ?towgs84? params added.
After this treatment, I obtain the coordinates of my grid in UTM32 North
zone, but these are not strictly regular (decimal data appear) and the step
never strictly equals to 3km.

Does anyone have any feedback or experience about my problem ? I thought to
an update in the attributes of the spTransform package, but I?ve found no
answer yet?
Any information regarding my problem would be nice !

Thanks you,

Greetings,
Florent.

From bernd.vogelgesang at gmx.de  Fri Feb 13 13:05:34 2015
From: bernd.vogelgesang at gmx.de (Bernd Vogelgesang)
Date: Fri, 13 Feb 2015 13:05:34 +0100
Subject: [R-sig-Geo] Calculate new value with area from the according
 polygon without merging data frames
Message-ID: <op.xtzvvk2al2i25i@bernd-terra-pc>

Dear list,
this is likely to be more a "normal" R question, but as it has also to a  
little with spatial stuff, I dare to ask here.

I have a data frame "df" with column POLYID and column TIME and also a  
SpatialPolygonsDataFrame "Shape" also with a column POLYID.
Now I would like to calculate a new column PRESENCE with TIME /  
area(Shape) where the POLYID's from both data frames are matched.

It's easy to do this simply by merging the data frames and then do the  
calculation, but I would like to learn how to avoid to bloat my data  
frames always with columns for a one-time-usage and then delete them  
again. I know/hope there must be a simple way to lookup values from  
another data frame, but did not succeed so far.

Already tried  multiple ways, e.g. sth like

df$PRESENCE <- df$TIME / area(Shape[subset(Shape at data,POLYID %in%  
df$POLYID)])

but, ... nothing works so far.

Any help appreciated.

Cheers
Bernd

p.s. sorry for not delivering a reproducible example, but for "experts",  
the problem might be obvious nevertheless.
-- 
Bernd Vogelgesang
Siedlerstra?e 2
91083 Baiersdorf/Igelsdorf
Tel: 09133-825374


From Roger.Bivand at nhh.no  Fri Feb 13 14:07:43 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 13 Feb 2015 14:07:43 +0100
Subject: [R-sig-Geo] SpTransform problem : conversion from WGS84 to
 UTM32N unregular
In-Reply-To: <OFCC57BD15.0DA1F4D4-ONC1257DEB.003C5169-C1257DEB.003CC2AC@atmo-alsace.net>
References: <OFCC57BD15.0DA1F4D4-ONC1257DEB.003C5169-C1257DEB.003CC2AC@atmo-alsace.net>
Message-ID: <alpine.LFD.2.11.1502131338560.15359@reclus.nhh.no>

On Fri, 13 Feb 2015, FVASBIEN at atmo-alsace.net wrote:

>
> Hi list,
>
> I use a kriging package for several years and it works successfully in my
> automated air-quality forecasting chain, by using old versions of
> libraries(e.g. 2009/2010 versions of sp, rgdal, ?).
> Currently, I?ve to change of server (from 32 bits to 64 bits) and I?ve
> installed the same package (and so the last delivered versions of
> libraries) on this new server.

This does not tell us your platform, R or package versions. Critically, 
you do not say how you installed rgdal. If we assume 2010, then this may 
be R 2.11; this indicates rgdal 0.6-29 as a Windows binary for which we 
could determine the version of the external PROJ4 library used for 
coordinate transformation (the earliest Windows binary on CRAN for R 2.9 
is 0.6-24).

If Linux, http://cran.r-project.org/src/contrib/Archive/rgdal gives the 
release archive. In running R and loaded rgdal, getPROJ4VersionInfo() 
provides the version of PROJ4. What would then be important is which PROJ4 
version was used, and possibly how it was installed. If .deb or .rpm, this 
may be interpolated. Changes in spTransform since rgdal migrated from 
sourceforge to R-Forge in September 2010 are:

https://r-forge.r-project.org/scm/viewvc.php/pkg/R/project.R?root=rgdal&r1=263&r2=508

from around l. 71, and

https://r-forge.r-project.org/scm/viewvc.php/pkg/src/projectit.cpp?root=rgdal&r1=263&r2=508

from line 254.


>
> I encounter an annoying problem: by using strictly the same package and the
> same inputs data, the conversion of grids from Lon-Lat WGS84 (irregular
> grid) to UTM32 doesn?t lead to a strictly regular grid, and this leads to a
> problem for the kriging process.
> By using the old libraries versions, the UTM32 grid obtained is strictly
> regular with a step of 3km !

This is not a reproducible example. You should provide actual copy&paste 
code. The opportunities for user error are endless.

>
> Concretely, my package begins by extracting the longitude and latitude of
> my CTM model outputs at 3km resolution. I assign to these data the WGS84
> projection via the attribute "CRS (" + init = epsg: 4326 ")". After this
> treatment, I obtain as expected a list of lon-lat on each cell centroide.
> This is the next step which raises concern: to convert this grid into a
> regular grid, I apply the grid conversion into utm32 via the spTransform
> package and the attribute "CRS ("+proj=utm +zone=32 +ellps=intl
> +towgs84=-87, -96 , -120 +units=m +no_defs?)".

spTransform() is a method, spaces are not permitted in +towgs84=.

My domain covers the East of
> France and goes across Germany, hence the ?towgs84? params added.
> After this treatment, I obtain the coordinates of my grid in UTM32 North
> zone, but these are not strictly regular (decimal data appear) and the step
> never strictly equals to 3km.
>
> Does anyone have any feedback or experience about my problem ? I thought to
> an update in the attributes of the spTransform package, but I?ve found no
> answer yet?

Did you just ask, or actually look at the source? Do you have properly 
journalled history files for what you say you did on 5-year-old software? 
How do we know that this is neither a consequence of changing from 32-bit 
to 64-bit, nor user error?

I have already seen this posting twice as list admin, and did ask 
explicitly for:

"Well-constructed self-contained examples get answers very quickly, 
hand-waving gets ignored. Here you must document which versions performed 
as you expected, and which do not now (use sessionInfo() and report full 
message output as packages are loaded). It could be that the earlier 
behaviour was a user error or bug corrected in a newer release."

I don't think that you followed my advice.

Roger


> Any information regarding my problem would be nice !
>
> Thanks you,
>
> Greetings,
> Florent.
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From mark at dimensionaledge.com  Sun Feb 15 02:21:43 2015
From: mark at dimensionaledge.com (Mark Wynter)
Date: Sun, 15 Feb 2015 11:51:43 +1030
Subject: [R-sig-Geo] Fwd: SPATIO-TEMPORAL ANALYSIS AND BIG DATA PROCESSING
	USING FREE AND OPEN SOURCE SOFTWARE
In-Reply-To: <mailman.13.1423825206.10875.r-sig-geo@r-project.org>
References: <mailman.13.1423825206.10875.r-sig-geo@r-project.org>
Message-ID: <D1FC8FCB-9937-4029-9510-B4D73BC698AC@dimensionaledge.com>

Hi Giuseppe,

Looks like a really interesting, and well thought through course.

Many of the teachings (particularly around parallelisation and scaling using Linux and open source software) I?m using on a daily basis, but within a big business context.  I?m continually amazed about what you can do once you know how to use these tools, but also dismayed by the complete lack of awareness within the broader business and analytics community.  If there?s one tool I would recommend you add to the curriculum, and that is PostgreSQL/PostGIS - and the multiple roles it can serve as a database backend for grass, R and as a stand alone geo-processing engine (which can also be scripted and parallelised using GNU Parallel/ xargs etc).

I?ve also observed another key skills gap around ?getting started? with cloud computing, and how to build a secure geo-analytics computing stack with all the open source packages. Many people don?t have an IT department, and those that do, probably want to avoid the red tape that often kills innovation initiatives.  I taught myself and started out purely connecting via SSH command line. I then gained a whole step-change in experience when I installed remote desktop on AWS cloud servers - plus QGIS / RStudio on the cloud desktop - so I could scale up the backend processing solutions, and visualise the outputs dynamically without being constrained by the upload and download links and without the need to continually shovel data between the cloud servers and my desktop.  Setting up a stack can be easy or difficult depending on which version of linux, and whether you have to build some of the packages from source because of dependency hell etc.  I started with Ubuntu, and have now have a full, and latest version stack deployed on RHEL/Centos because much of my work is with enterprise. 

I truly believe that accelerated learning programs in scientific computing can have huge benefits for, as well as open up career pathways for members of,  the broader data science and business analytics community.  Many businesses are relative newcomers to the field of Big Data - hence I?m confident analytics professionals can gain a lot from the teachings of environmental science?

Good luck for the course.  I?d be keen to get involved should another opportunity arise into the future.

Kind regards

Mark

> ------------------------------
> 
> Message: 6
> Date: Thu, 12 Feb 2015 16:51:07 -0500
> From: Giuseppe Amatulli <giuseppe.amatulli at gmail.com>
> To: R-SIG list <r-sig-geo at r-project.org>
> Subject: [R-sig-Geo] Fwd: SPATIO-TEMPORAL ANALYSIS AND BIG DATA
> 	PROCESSING USING FREE AND OPEN SOURCE SOFTWARE
> Message-ID:
> 	<CAKoiDHKncPmh93qmNVPcG-P4fBoXEcdw8toxuaEqvoTgfkmqqg at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
> 
> HI,
> Apologies for cross-posting:
> 
> Summer school organized by www.spatial-ecology.net:
> 
> *SPATIO-TEMPORAL ANALYSIS AND BIG DATA PROCESSING USING FREE AND OPEN
> SOURCE SOFTWARE *(basic and advanced levels)
> 
> Over the last few decades there has been an explosion in the availability
> of data for environmental research, and in particular for spatio-temporal
> analysis. We are now able to address a number of important questions, both
> new and old, with unprecedented rigor and generality. Leveraging these
> exciting new data streams requires tools and increasingly complex
> workflows. This 6-day course introduces a set of free and open source
> software (GRASS, R, Python, AWK, BASH, GDAL) to perform spatio-temporal
> analysis and modelling of environmental data in a Linux environment. We
> also introduce multi-core, cloud and cluster computation procedures. The
> course consists of a set of lectures and practical hands-on sessions in
> which participants perform spatial and temporal analysis using Geographic
> Information System and Remote Sensing concepts. Although courses focuses on
> the command line instead of the graphical user interface, no prior
> experience with programming or command line interfaces is assumed or
> required.  To cater to students with prior programming experience, we will
> hold parallel sessions that introduce more advanced material. Our main
> focus is on teaching self learning and problem solving more than the use of
> specific tools (see: our teaching method
> <http://www.spatial-ecology.net/giuseppe/publications/Amatulli_et_al_OGRS.pdf>)
> so participants will be able to progress and adapt to learn the newest
> available data science techniques.
> 
> *Location:  15-20 June 2015 - Matera - Italy*
> 
> More info at www.spatial-ecology.net:Staff
> 
> Dr. Giuseppe Amatulli (Yale University, USA
> <http://sbsc.yale.edu/giuseppe-amatulli> ; www.spatial-ecology.net)
> 
> Dr. Stefano Casalegno (University of Exeter, UK
> <http://www.exeter.ac.uk/esi/people/casalegno/> ; www.spatial-ecology.net)
> 
> Dr. Pieter Kempeneers (VITO <https://vito.be/en/land-use> ; pktools
> <http://pktools.nongnu.org/html/index.html>)
> 
> Dr. Daniel McInerney ( Coillte Teoranta <http://www.coillte.ie>)
> 
> -- 
> Giuseppe Amatulli, Ph.D.
> 
> Department of Ecology and Evolutionary Biology, Yale University.
> Jetz Lab, Room 405
> 
> P.O. Box 208106
> New Haven, CT 06520-8106
> Teaching: spatial-ecology.net
> Work:  http://sbsc.yale.edu/giuseppe-amatulli
> <http://www.spatial-ecology.net>
> 
> 	[[alternative HTML version deleted]]


From pan.sapiens.it at gmail.com  Tue Feb 17 11:35:31 2015
From: pan.sapiens.it at gmail.com (Ivan Palmegiani)
Date: Tue, 17 Feb 2015 12:35:31 +0200
Subject: [R-sig-Geo] Calculate shortest distance between points belonging to
 different polygons
Message-ID: <54E31973.5070301@gmail.com>

Dear members of the list,

I'm handling a SpatialPointsDataFrame with 100 ramdom points distributed 
within 13 different polygons.

 > randp
                     coordinates   Point_ID   Polygon_ ID
0  (690926.8, 7522595)         1_hs                    13
1  (696727.1, 7576122)         2_hs                      6
...
...
98 (728199.9, 7549810)     99_hs                    12
99 (723428.1, 7545891)   100_hs                    12

I need to calculate the shortest distance between points belonging to 
different polygons. Basically I'd like to do what nndist {spatstat} 
does. The difference is that the distance should be calculated between 
groups of points instead of within a group of points.

I tried to use "aggregate" as suggested below but it didn't work out for me.
http://www.inside-r.org/packages/cran/spatstat/docs/nndist

Please find my try below:

 > randp.df<-data.frame(randp)
 > randp.hs.df
        Point_ID     coords.x1      coords.x2   Polygon_ ID
0            1_hs     690926.8       7522595 13
1            2_hs     696727.1       7576122 6
2            3_hs     723480.7       7546594 12

library(spatstat)

# Calculate nearest neighbors within a polygon
 > nn.within.pol<-nndist(randp.df[,c(2,3)],by=marks(randp.df$Polygon_ID))
 > nn.within.pol
  [1]  2579.42199  1391.88915    59.85628   734.95108   734.95108 
840.65125   957.47838   741.58160   955.26483  3307.59444 1361.64626  
2682.70690
  ...
  ...
  [97]  1349.88694   955.26483  3166.00894   705.25663
# Ok but these are not the distances I need

# Calculate nearest neighbors between polygons
nn.between.pol<-aggregate(nn.within.pol, 
by=list(from=marks(randp.df$Polygon_ID)), min)
# Error in aggregate.data.frame(as.data.frame(x), ...) : arguments must 
have same length

 > nn.between.hs<-aggregate(randp.hs.df[,c(2,3)], 
by=list(randp.df$Polygon_ID), nndist)
 > nn.between.hs

The outcome is an asymmetric data frame (dim 13, 6) with a lot of empty 
cells and values that look unlikely to be distances.

The result I'd like to get is a matrix (dim 100, 1) with the distances 
between each random point and its nearest neighbor belonging to a 
different polygon (i.e. its nearest neighbor having a different Polygon_ID).

Can someone kindly correct my script or suggest a function able to do 
the job?

Cheers,

Ivan


From thierry.onkelinx at inbo.be  Tue Feb 17 12:21:34 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 17 Feb 2015 12:21:34 +0100
Subject: [R-sig-Geo] Calculate shortest distance between points
 belonging to different polygons
In-Reply-To: <54E31973.5070301@gmail.com>
References: <54E31973.5070301@gmail.com>
Message-ID: <CAJuCY5xbqER3G2yNFhVbDTKhs7W3RND-9J+_YMoc3x2rnakV8Q@mail.gmail.com>

Here is an example using ddply() to do the aggregation

library(spatstat)
library(plyr)
n <- 100
set.seed(123)
point <- matrix(runif(2 * n), ncol = 2)
colnames(point) <- c("X", "Y")
point <- data.frame(point, Polygon = factor(LETTERS[kmeans(point,
13)$cluster]))
pattern <- as.ppp(point, W = owin(0:1, 0:1))

distance <- as.data.frame(nndist(pattern, by = pattern$marks))
distance$Origin <- point$Polygon
ddply(distance, "Origin", function(x){
  ignore.vars <- c(levels(x$Origin)[x$Origin[1]], "Origin")
  x <- x[, !colnames(x) %in% ignore.vars]
  data.frame(
    Distance = apply(x, 1, min),
    Target = colnames(x)[apply(x, 1, which.min)]
  )
})

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-02-17 11:35 GMT+01:00 Ivan Palmegiani <pan.sapiens.it at gmail.com>:

> Dear members of the list,
>
> I'm handling a SpatialPointsDataFrame with 100 ramdom points distributed
> within 13 different polygons.
>
> > randp
>                     coordinates   Point_ID   Polygon_ ID
> 0  (690926.8, 7522595)         1_hs                    13
> 1  (696727.1, 7576122)         2_hs                      6
> ...
> ...
> 98 (728199.9, 7549810)     99_hs                    12
> 99 (723428.1, 7545891) 100_hs                    12
>
> I need to calculate the shortest distance between points belonging to
> different polygons. Basically I'd like to do what nndist {spatstat} does.
> The difference is that the distance should be calculated between groups of
> points instead of within a group of points.
>
> I tried to use "aggregate" as suggested below but it didn't work out for
> me.
> http://www.inside-r.org/packages/cran/spatstat/docs/nndist
>
> Please find my try below:
>
> > randp.df<-data.frame(randp)
> > randp.hs.df
>        Point_ID     coords.x1      coords.x2   Polygon_ ID
> 0            1_hs     690926.8       7522595 13
> 1            2_hs     696727.1       7576122 6
> 2            3_hs     723480.7       7546594 12
>
> library(spatstat)
>
> # Calculate nearest neighbors within a polygon
> > nn.within.pol<-nndist(randp.df[,c(2,3)],by=marks(randp.df$Polygon_ID))
> > nn.within.pol
>  [1]  2579.42199  1391.88915    59.85628   734.95108   734.95108
> 840.65125   957.47838   741.58160   955.26483  3307.59444 1361.64626
> 2682.70690
>  ...
>  ...
>  [97]  1349.88694   955.26483  3166.00894   705.25663
> # Ok but these are not the distances I need
>
> # Calculate nearest neighbors between polygons
> nn.between.pol<-aggregate(nn.within.pol, by=list(from=marks(randp.df$Polygon_ID)),
> min)
> # Error in aggregate.data.frame(as.data.frame(x), ...) : arguments must
> have same length
>
> > nn.between.hs<-aggregate(randp.hs.df[,c(2,3)],
> by=list(randp.df$Polygon_ID), nndist)
> > nn.between.hs
>
> The outcome is an asymmetric data frame (dim 13, 6) with a lot of empty
> cells and values that look unlikely to be distances.
>
> The result I'd like to get is a matrix (dim 100, 1) with the distances
> between each random point and its nearest neighbor belonging to a different
> polygon (i.e. its nearest neighbor having a different Polygon_ID).
>
> Can someone kindly correct my script or suggest a function able to do the
> job?
>
> Cheers,
>
> Ivan
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From pan.sapiens.it at gmail.com  Tue Feb 17 13:31:51 2015
From: pan.sapiens.it at gmail.com (Ivan Palmegiani)
Date: Tue, 17 Feb 2015 14:31:51 +0200
Subject: [R-sig-Geo] Calculate shortest distance between points
 belonging to different polygons
In-Reply-To: <CAJuCY5xbqER3G2yNFhVbDTKhs7W3RND-9J+_YMoc3x2rnakV8Q@mail.gmail.com>
References: <54E31973.5070301@gmail.com>
	<CAJuCY5xbqER3G2yNFhVbDTKhs7W3RND-9J+_YMoc3x2rnakV8Q@mail.gmail.com>
Message-ID: <54E334B7.5060608@gmail.com>

Dear Thierry,

Thanks for your prompt reply!
I must admit I'm not familiar with ddply(), I'd need further advice from 
you.

 > randp.ppp<-as.ppp(randp.df)
 > randp.hs.ppp
marked planar point pattern: 100 points
Mark variables: Point_ID, Polygon_ ID
window: rectangle = [650602.2, 766311.2] x [7503238, 7607430] units

 > distance<-as.data.frame(nndist(randp.ppp, by = randp.ppp$Polygon_ID))
 > distance
     nndist(randp.ppp, by = randp.hs.ppp$Polygon_ID)
1                                   2579.42199
2                                   1391.88915
3                                     59.85628
...
...
98                                   955.26483
99                                  3166.00894
100                                  705.25663

 > distance$Origin<-as.factor(randp.df$Polygon_ID)
 > distance$Origin
   [1] 13 6  12 5  5  12 12 10 8  3  5  13 3  3  10 3  5  3  13 3  2 3  
12 6  5  13 3  2  3  3  9  1  3  4  12 6  12 12 10 2  13 3  6  3 3  6  
3  9  1
  ...
  [99] 12 12
Levels: 1 2 3 4 5 6 7 8 9 10 11 12 13

 > ddply(distance, "Origin", function(x){
+   ignore.vars<-c(levels(x$Origin)[x$Origin[1]], "Origin")
+   x<-x[,!colnames(x) %in% ignore.vars]
+   data.frame(
+     Distance = apply(x, 1, min),
+     Target = colnames(x)[apply(x, 1, which.min)]
+   )
+ })
Error: dim(X) must have a positive length

Sorry but I can't spot the problem.

Sincerely,

Ivan

On 17-Feb-15 13:21, Thierry Onkelinx wrote:
> Here is an example using ddply() to do the aggregation
>
> library(spatstat)
> library(plyr)
> n <- 100
> set.seed(123)
> point <- matrix(runif(2 * n), ncol = 2)
> colnames(point) <- c("X", "Y")
> point <- data.frame(point, Polygon = factor(LETTERS[kmeans(point, 
> 13)$cluster]))
> pattern <- as.ppp(point, W = owin(0:1, 0:1))
>
> distance <- as.data.frame(nndist(pattern, by = pattern$marks))
> distance$Origin <- point$Polygon
> ddply(distance, "Origin", function(x){
>   ignore.vars <- c(levels(x$Origin)[x$Origin[1]], "Origin")
>   x <- x[, !colnames(x) %in% ignore.vars]
>   data.frame(
>     Distance = apply(x, 1, min),
>     Target = colnames(x)[apply(x, 1, which.min)]
>   )
> })
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data. ~ John Tukey
>
> 2015-02-17 11:35 GMT+01:00 Ivan Palmegiani <pan.sapiens.it at gmail.com 
> <mailto:pan.sapiens.it at gmail.com>>:
>
>     Dear members of the list,
>
>     I'm handling a SpatialPointsDataFrame with 100 ramdom points
>     distributed within 13 different polygons.
>
>     > randp
>                         coordinates   Point_ID   Polygon_ ID
>     0  (690926.8, 7522595)         1_hs                    13
>     1  (696727.1, 7576122)         2_hs                      6
>     ...
>     ...
>     98 (728199.9, 7549810)     99_hs                    12
>     99 (723428.1, 7545891) 100 <tel:7545891%29%20%20%20100>_hs       
>                 12
>
>     I need to calculate the shortest distance between points belonging
>     to different polygons. Basically I'd like to do what nndist
>     {spatstat} does. The difference is that the distance should be
>     calculated between groups of points instead of within a group of
>     points.
>
>     I tried to use "aggregate" as suggested below but it didn't work
>     out for me.
>     http://www.inside-r.org/packages/cran/spatstat/docs/nndist
>
>     Please find my try below:
>
>     > randp.df<-data.frame(randp)
>     > randp.hs.df
>            Point_ID     coords.x1      coords.x2   Polygon_ ID
>     0            1_hs     690926.8       7522595 13
>     1            2_hs     696727.1       7576122 6
>     2            3_hs     723480.7       7546594 12
>
>     library(spatstat)
>
>     # Calculate nearest neighbors within a polygon
>     >
>     nn.within.pol<-nndist(randp.df[,c(2,3)],by=marks(randp.df$Polygon_ID))
>     > nn.within.pol
>      [1]  2579.42199  1391.88915    59.85628   734.95108  734.95108
>     840.65125   957.47838   741.58160   955.26483 3307.59444
>     1361.64626  2682.70690
>      ...
>      ...
>      [97]  1349.88694   955.26483  3166.00894   705.25663
>     # Ok but these are not the distances I need
>
>     # Calculate nearest neighbors between polygons
>     nn.between.pol<-aggregate(nn.within.pol,
>     by=list(from=marks(randp.df$Polygon_ID)), min)
>     # Error in aggregate.data.frame(as.data.frame(x), ...) : arguments
>     must have same length
>
>     > nn.between.hs<-aggregate(randp.hs.df[,c(2,3)],
>     by=list(randp.df$Polygon_ID), nndist)
>     > nn.between.hs
>
>     The outcome is an asymmetric data frame (dim 13, 6) with a lot of
>     empty cells and values that look unlikely to be distances.
>
>     The result I'd like to get is a matrix (dim 100, 1) with the
>     distances between each random point and its nearest neighbor
>     belonging to a different polygon (i.e. its nearest neighbor having
>     a different Polygon_ID).
>
>     Can someone kindly correct my script or suggest a function able to
>     do the job?
>
>     Cheers,
>
>     Ivan
>
>     _______________________________________________
>     R-sig-Geo mailing list
>     R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Feb 17 13:41:27 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 17 Feb 2015 13:41:27 +0100
Subject: [R-sig-Geo] Calculate shortest distance between points
 belonging to different polygons
In-Reply-To: <54E334B7.5060608@gmail.com>
References: <54E31973.5070301@gmail.com>
	<CAJuCY5xbqER3G2yNFhVbDTKhs7W3RND-9J+_YMoc3x2rnakV8Q@mail.gmail.com>
	<54E334B7.5060608@gmail.com>
Message-ID: <CAJuCY5zA6hmmVQeydD_YgvykYY57MmVzOk9WYQJOxQYEJ6rnCg@mail.gmail.com>

Can you provide a reproducible example?

The output of as.data.frame(nndist(randp.ppp, by = randp.ppp$Polygon_ID))
should be a data.frame with one row per point and one column per polygon.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-02-17 13:31 GMT+01:00 Ivan Palmegiani <pan.sapiens.it at gmail.com>:

>  Dear Thierry,
>
> Thanks for your prompt reply!
> I must admit I'm not familiar with ddply(), I'd need further advice from
> you.
>
> > randp.ppp<-as.ppp(randp.df)
> > randp.hs.ppp
> marked planar point pattern: 100 points
> Mark variables: Point_ID, Polygon_ ID
> window: rectangle = [650602.2, 766311.2] x [7503238, 7607430] units
>
> > distance<-as.data.frame(nndist(randp.ppp, by = randp.ppp$Polygon_ID))
> > distance
>     nndist(randp.ppp, by = randp.hs.ppp$Polygon_ID)
> 1                                   2579.42199
> 2                                   1391.88915
> 3                                     59.85628
> ...
> ...
> 98                                   955.26483
> 99                                  3166.00894
> 100                                  705.25663
>
> > distance$Origin<-as.factor(randp.df$Polygon_ID)
> > distance$Origin
>   [1] 13 6  12 5  5  12 12 10 8  3  5  13 3  3  10 3  5  3  13 3  2  3  12
> 6  5  13 3  2  3  3  9  1  3  4  12 6  12 12 10 2  13 3  6  3  3  6  3  9
> 1
>  ...
>  [99] 12 12
> Levels: 1 2 3 4 5 6 7 8 9 10 11 12 13
>
> > ddply(distance, "Origin", function(x){
> +   ignore.vars<-c(levels(x$Origin)[x$Origin[1]], "Origin")
> +   x<-x[,!colnames(x) %in% ignore.vars]
> +   data.frame(
> +     Distance = apply(x, 1, min),
> +     Target = colnames(x)[apply(x, 1, which.min)]
> +   )
> + })
> Error: dim(X) must have a positive length
>
> Sorry but I can't spot the problem.
>
> Sincerely,
>
> Ivan
>
>
> On 17-Feb-15 13:21, Thierry Onkelinx wrote:
>
>  Here is an example using ddply() to do the aggregation
>
> library(spatstat)
> library(plyr)
> n <- 100
> set.seed(123)
> point <- matrix(runif(2 * n), ncol = 2)
> colnames(point) <- c("X", "Y")
> point <- data.frame(point, Polygon = factor(LETTERS[kmeans(point,
> 13)$cluster]))
> pattern <- as.ppp(point, W = owin(0:1, 0:1))
>
> distance <- as.data.frame(nndist(pattern, by = pattern$marks))
> distance$Origin <- point$Polygon
> ddply(distance, "Origin", function(x){
>   ignore.vars <- c(levels(x$Origin)[x$Origin[1]], "Origin")
>   x <- x[, !colnames(x) %in% ignore.vars]
>   data.frame(
>     Distance = apply(x, 1, min),
>     Target = colnames(x)[apply(x, 1, which.min)]
>   )
> })
>
>  Best regards,
>
> Thierry
>
>  ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-02-17 11:35 GMT+01:00 Ivan Palmegiani <pan.sapiens.it at gmail.com>:
>
>> Dear members of the list,
>>
>> I'm handling a SpatialPointsDataFrame with 100 ramdom points distributed
>> within 13 different polygons.
>>
>> > randp
>>                     coordinates   Point_ID   Polygon_ ID
>> 0  (690926.8, 7522595)         1_hs                    13
>> 1  (696727.1, 7576122)         2_hs                      6
>> ...
>> ...
>> 98 (728199.9, 7549810)     99_hs                    12
>> 99 (723428.1, 7545891) 100 <7545891%29%20%20%20100>_hs
>>   12
>>
>> I need to calculate the shortest distance between points belonging to
>> different polygons. Basically I'd like to do what nndist {spatstat} does.
>> The difference is that the distance should be calculated between groups of
>> points instead of within a group of points.
>>
>> I tried to use "aggregate" as suggested below but it didn't work out for
>> me.
>> http://www.inside-r.org/packages/cran/spatstat/docs/nndist
>>
>> Please find my try below:
>>
>> > randp.df<-data.frame(randp)
>> > randp.hs.df
>>        Point_ID     coords.x1      coords.x2   Polygon_ ID
>> 0            1_hs     690926.8       7522595 13
>> 1            2_hs     696727.1       7576122 6
>> 2            3_hs     723480.7       7546594 12
>>
>> library(spatstat)
>>
>> # Calculate nearest neighbors within a polygon
>> > nn.within.pol<-nndist(randp.df[,c(2,3)],by=marks(randp.df$Polygon_ID))
>> > nn.within.pol
>>  [1]  2579.42199  1391.88915    59.85628   734.95108   734.95108
>> 840.65125   957.47838   741.58160   955.26483  3307.59444 1361.64626
>> 2682.70690
>>  ...
>>  ...
>>  [97]  1349.88694   955.26483  3166.00894   705.25663
>> # Ok but these are not the distances I need
>>
>> # Calculate nearest neighbors between polygons
>> nn.between.pol<-aggregate(nn.within.pol,
>> by=list(from=marks(randp.df$Polygon_ID)), min)
>> # Error in aggregate.data.frame(as.data.frame(x), ...) : arguments must
>> have same length
>>
>> > nn.between.hs<-aggregate(randp.hs.df[,c(2,3)],
>> by=list(randp.df$Polygon_ID), nndist)
>> > nn.between.hs
>>
>> The outcome is an asymmetric data frame (dim 13, 6) with a lot of empty
>> cells and values that look unlikely to be distances.
>>
>> The result I'd like to get is a matrix (dim 100, 1) with the distances
>> between each random point and its nearest neighbor belonging to a different
>> polygon (i.e. its nearest neighbor having a different Polygon_ID).
>>
>> Can someone kindly correct my script or suggest a function able to do the
>> job?
>>
>> Cheers,
>>
>> Ivan
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
>

	[[alternative HTML version deleted]]


From adrian.baddeley at uwa.edu.au  Tue Feb 17 15:01:57 2015
From: adrian.baddeley at uwa.edu.au (Adrian Baddeley)
Date: Tue, 17 Feb 2015 22:01:57 +0800
Subject: [R-sig-Geo] Calculate shortest distance between points belonging to
 different polygons
Message-ID: <CF5661163F77A44781208D9AC4FDEA72013BA6EBE1C2@IS-WIN-376.staffad.uwa.edu.au>

Ivan Palmegiani <pan.sapiens.it at gmail.com> writes:

> I'm handling a SpatialPointsDataFrame with 100 ramdom points distributed
> within 13 different polygons.
> 
 > randp
>                      coordinates   Point_ID   Polygon_ ID
> 0  (690926.8, 7522595)         1_hs                    13
> 1  (696727.1, 7576122)         2_hs                      6

> I need to calculate the shortest distance between points belonging to
> different polygons. Basically I'd like to do what nndist {spatstat} does.
> The difference is that the distance should be calculated between
> groups of points instead of within a group of points.

              Well, nndist {spatstat} does that too.

> I tried to use "aggregate" as suggested below but it didn't work out for me.
> http://www.inside-r.org/packages/cran/spatstat/docs/nndist

> Please find my try below:

>  > randp.df<-data.frame(randp)
>  > randp.hs.df
>         Point_ID     coords.x1      coords.x2   Polygon_ ID
> 0            1_hs     690926.8       7522595 13
> 1            2_hs     696727.1       7576122 6
> 2            3_hs     723480.7       7546594 12

> library(spatstat)

> # Calculate nearest neighbors within a polygon
>  > nn.within.pol<-nndist(randp.df[,c(2,3)],by=marks(randp.df$Polygon_ID))

              'marks' is not appropriate here.
              marks() is a function that extracts the marks from a marked point pattern (class 'ppp')
              but you are applying it to a numeric vector. The result is NULL.

              The argument 'by' should be a factor that determines the grouping.

              Just change 'marks' to 'factor' so that the numeric polygon ID will be treated as a factor,

 nn.within.pol<-nndist(randp.df[,c(2,3)],by=factor(randp.df$Polygon_ID))
 
               and proceed as before (also changing the other instances of 'marks' to 'factor')



Adrian Baddeley
spatstat author


From pan.sapiens.it at gmail.com  Wed Feb 18 05:32:01 2015
From: pan.sapiens.it at gmail.com (Ivan Palmegiani)
Date: Wed, 18 Feb 2015 06:32:01 +0200
Subject: [R-sig-Geo] Calculate shortest distance between points
 belonging to different polygons
In-Reply-To: <CF5661163F77A44781208D9AC4FDEA72013BA6EBE1C2@IS-WIN-376.staffad.uwa.edu.au>
References: <CF5661163F77A44781208D9AC4FDEA72013BA6EBE1C2@IS-WIN-376.staffad.uwa.edu.au>
Message-ID: <54E415C1.5060905@gmail.com>

Dear Adrian,

Thank you very much!

I made the change you suggested and the outcome is not exactly the one I 
wanted...but it's very close to it!

 > library(spatstat)
 > nn.within.pol<-nndist(randp.df[,c(2,3)], by=factor(randp.df$Polygon_ID))
 > nn.within.pol

                            1                   2                 3     
               4                     5                   6               
7                     8                   9         10              
11                    12              13
   [1,]  77758.488  71978.036 33715.961  62236.2421  84528.6758 
47206.9703 26370.4913  39448.7910  40198.916  68559.0147  67769.69 
39298.45411  2579.422
   [2,]  63404.130  93535.612 64780.940  21597.4530  32485.1889 
1391.8891 38473.2915  69642.7457  24374.408  15070.9926  70237.22 
35217.62792 49217.807
   [3,]  37861.018  53839.721 27587.333  59658.5379  58107.6351 
35133.6718 48282.9013  75710.3428  48898.652  52273.7298 33882.71    
59.85628 36756.945
   ...
  [98,] 114435.572 111577.598 73735.852  65518.7127 102369.5236 
65629.7084 29330.3308    955.2648  39271.208  81234.4457 107270.98 
74005.63912 30371.918
  [99,]  32283.616  52705.045 28666.796  61665.1649  55854.9164 
36094.8633 53239.2478  81208.2781  52669.590  52158.4953  30242.29 
3166.00894 42467.270
[100,]  38187.593  53418.183 27001.456  60050.0374  58795.8736 
35555.5710 48200.6059  75445.7086  49047.448  52858.1932  33791.42 
705.25663 36323.229

In fact, I realized that I do not need to make recourse to /aggregate()/ 
because in the matrix above I already have the information I need. I 
just need to extract it.
Is there any way to prevent the function to calculate the distance 
between a point and its nn within the same group (i.e. distance [1, 13]; 
[2, 6]; [3, 12]; etc.)?

If not, I will just extract the second shortest distance per point (the 
shortest one is certainly within the same group) and I will get exactly 
the information I need.

Thanks again!

Sincerely,

Ivan


On 17-Feb-15 16:01, Adrian Baddeley wrote:
> Ivan Palmegiani <pan.sapiens.it at gmail.com> writes:
>
>> I'm handling a SpatialPointsDataFrame with 100 ramdom points distributed
>> within 13 different polygons.
>>
>   > randp
>>                       coordinates   Point_ID   Polygon_ ID
>> 0  (690926.8, 7522595)         1_hs                    13
>> 1  (696727.1, 7576122)         2_hs                      6
>> I need to calculate the shortest distance between points belonging to
>> different polygons. Basically I'd like to do what nndist {spatstat} does.
>> The difference is that the distance should be calculated between
>> groups of points instead of within a group of points.
>                Well, nndist {spatstat} does that too.
>
>> I tried to use "aggregate" as suggested below but it didn't work out for me.
>> http://www.inside-r.org/packages/cran/spatstat/docs/nndist
>> Please find my try below:
>>   > randp.df<-data.frame(randp)
>>   > randp.hs.df
>>          Point_ID     coords.x1      coords.x2   Polygon_ ID
>> 0            1_hs     690926.8       7522595 13
>> 1            2_hs     696727.1       7576122 6
>> 2            3_hs     723480.7       7546594 12
>> library(spatstat)
>> # Calculate nearest neighbors within a polygon
>>   > nn.within.pol<-nndist(randp.df[,c(2,3)],by=marks(randp.df$Polygon_ID))
>                'marks' is not appropriate here.
>                marks() is a function that extracts the marks from a marked point pattern (class 'ppp')
>                but you are applying it to a numeric vector. The result is NULL.
>
>                The argument 'by' should be a factor that determines the grouping.
>
>                Just change 'marks' to 'factor' so that the numeric polygon ID will be treated as a factor,
>
>   nn.within.pol<-nndist(randp.df[,c(2,3)],by=factor(randp.df$Polygon_ID))
>   
>                 and proceed as before (also changing the other instances of 'marks' to 'factor')
>
>
>
> Adrian Baddeley
> spatstat author
>
>


	[[alternative HTML version deleted]]


From adrian.baddeley at uwa.edu.au  Wed Feb 18 12:02:28 2015
From: adrian.baddeley at uwa.edu.au (Adrian Baddeley)
Date: Wed, 18 Feb 2015 19:02:28 +0800
Subject: [R-sig-Geo] Calculate shortest distance between points
 belonging to different polygons
In-Reply-To: <54E415C1.5060905@gmail.com>
References: <CF5661163F77A44781208D9AC4FDEA72013BA6EBE1C2@IS-WIN-376.staffad.uwa.edu.au>,
	<54E415C1.5060905@gmail.com>
Message-ID: <CF5661163F77A44781208D9AC4FDEA72013BA6EBE1CA@IS-WIN-376.staffad.uwa.edu.au>

After you do 
    > nn.within.pol<-nndist(randp.df[,c(2,3)], by=factor(randp.df$Polygon_ID))

the result nn.within.pol is a matrix with one row for each data point, and
one column for each polygon. The entry on row i, column j is the distance 
from the i-th data point to its nearest neighbour in polygon j.

It's still not clear to me what you wanted to calculate.

Do you want the minimum distance between any two points in different polygons?
For each possible pair of polygons? or... ?

The command 
      
     >   aggregate(nn.within.pol, by=list(from=factor(randp.df$PolygonID)), min)

would yield a matrix, with one row and column for each polygon,
in which the [i,j] entry is the minimum distance between any point in polygon i
and any point in polygon j. On the diagonal the [i,i] entry would give the minimum
nearest-neighbour distance for the pattern of points within polygon i.


Prof Adrian Baddeley FAA
Curtin University
________________________________________
From: Ivan Palmegiani [pan.sapiens.it at gmail.com]
Sent: Wednesday, 18 February 2015 12:32 PM
To: Adrian Baddeley
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] Calculate shortest distance between points belonging to different polygons

Dear Adrian,

Thank you very much!

I made the change you suggested and the outcome is not exactly the one I wanted...but it's very close to it!

> library(spatstat)
> nn.within.pol<-nndist(randp.df[,c(2,3)], by=factor(randp.df$Polygon_ID))
> nn.within.pol

                           1                   2                 3                     4                     5                   6                     7                     8                   9                   10              11                    12              13
  [1,]  77758.488  71978.036 33715.961  62236.2421  84528.6758 47206.9703 26370.4913  39448.7910  40198.916  68559.0147  67769.69 39298.45411  2579.422
  [2,]  63404.130  93535.612 64780.940  21597.4530  32485.1889  1391.8891 38473.2915  69642.7457  24374.408  15070.9926  70237.22 35217.62792 49217.807
  [3,]  37861.018  53839.721 27587.333  59658.5379  58107.6351 35133.6718 48282.9013  75710.3428  48898.652  52273.7298  33882.71    59.85628 36756.945
  ...
 [98,] 114435.572 111577.598 73735.852  65518.7127 102369.5236 65629.7084 29330.3308    955.2648  39271.208  81234.4457 107270.98 74005.63912 30371.918
 [99,]  32283.616  52705.045 28666.796  61665.1649  55854.9164 36094.8633 53239.2478  81208.2781  52669.590  52158.4953  30242.29  3166.00894 42467.270
[100,]  38187.593  53418.183 27001.456  60050.0374  58795.8736 35555.5710 48200.6059  75445.7086  49047.448  52858.1932  33791.42   705.25663 36323.229

In fact, I realized that I do not need to make recourse to aggregate() because in the matrix above I already have the information I need. I just need to extract it.
Is there any way to prevent the function to calculate the distance between a point and its nn within the same group (i.e. distance [1, 13]; [2, 6]; [3, 12]; etc.)?

If not, I will just extract the second shortest distance per point (the shortest one is certainly within the same group) and I will get exactly the information I need.

Thanks again!

Sincerely,

Ivan


On 17-Feb-15 16:01, Adrian Baddeley wrote:

Ivan Palmegiani <pan.sapiens.it at gmail.com><mailto:pan.sapiens.it at gmail.com> writes:



I'm handling a SpatialPointsDataFrame with 100 ramdom points distributed
within 13 different polygons.



 > randp


                     coordinates   Point_ID   Polygon_ ID
0  (690926.8, 7522595)         1_hs                    13
1  (696727.1, 7576122)         2_hs                      6





I need to calculate the shortest distance between points belonging to
different polygons. Basically I'd like to do what nndist {spatstat} does.
The difference is that the distance should be calculated between
groups of points instead of within a group of points.



              Well, nndist {spatstat} does that too.



I tried to use "aggregate" as suggested below but it didn't work out for me.
http://www.inside-r.org/packages/cran/spatstat/docs/nndist





Please find my try below:





 > randp.df<-data.frame(randp)
 > randp.hs.df
        Point_ID     coords.x1      coords.x2   Polygon_ ID
0            1_hs     690926.8       7522595 13
1            2_hs     696727.1       7576122 6
2            3_hs     723480.7       7546594 12





library(spatstat)





# Calculate nearest neighbors within a polygon
 > nn.within.pol<-nndist(randp.df[,c(2,3)],by=marks(randp.df$Polygon_ID))



              'marks' is not appropriate here.
              marks() is a function that extracts the marks from a marked point pattern (class 'ppp')
              but you are applying it to a numeric vector. The result is NULL.

              The argument 'by' should be a factor that determines the grouping.

              Just change 'marks' to 'factor' so that the numeric polygon ID will be treated as a factor,

 nn.within.pol<-nndist(randp.df[,c(2,3)],by=factor(randp.df$Polygon_ID))

               and proceed as before (also changing the other instances of 'marks' to 'factor')



Adrian Baddeley
spatstat author


From pan.sapiens.it at gmail.com  Wed Feb 18 15:11:40 2015
From: pan.sapiens.it at gmail.com (Ivan Palmegiani)
Date: Wed, 18 Feb 2015 16:11:40 +0200
Subject: [R-sig-Geo] Calculate shortest distance between points
 belonging to different polygons
In-Reply-To: <CF5661163F77A44781208D9AC4FDEA72013BA6EBE1CA@IS-WIN-376.staffad.uwa.edu.au>
References: <CF5661163F77A44781208D9AC4FDEA72013BA6EBE1C2@IS-WIN-376.staffad.uwa.edu.au>,
	<54E415C1.5060905@gmail.com>
	<CF5661163F77A44781208D9AC4FDEA72013BA6EBE1CA@IS-WIN-376.staffad.uwa.edu.au>
Message-ID: <54E49D9C.60409@gmail.com>

Dear Adrian,

Thanks for your explanation.

My goal is measuring the minimum distance from each data point to its 
nearest neighbor belonging to a different polygon (a pair of point then).
In fact, this distance is in the matrix resulting from

> nn.pol<-nndist(randp.df[,c(2,3)], by=factor(randp.df$Polygon_ID)

The polygons I'm considering are relatively small and distant each other 
so, in my case, the distance between data points belonging to the same 
polygon is certainly shorter that the distance to data points belonging 
to other polygons. Thus, the smallest value of each row is the distance 
from a data point to its nearest neighbor within the same polygon, while 
the second smallest value of each row is the distance from a data point 
and its nearest neighbor belonging to another polygon.

The latter value is the distance I want and I extracted it from the 
matrix using the following /for/ loop:

> min.dist<-NULL

> for(i in 1:nrow(nn.pol)){

+ min.dist.temp<-min(nn.pol[i,] [nn.pol[i,] != min(nn.pol[i,])])

+ min.dist<-as.vector(c(min.dist,min.dist.temp))

+ }

Maybe not the most elegant way to do it...but it worked. The result is a 
vector whose length is equal to the number of data point.

> head(nn.dist.hs)

[1] 26370.49 15070.99 27587.33 15722.28 15186.39 31147.84


If the polygons were large and tangential or overlapping, I could not 
know which value I should have extracted because the distance between 
two points belonging to the same polygon might be larger than the 
distance between two points belonging to different polygons.

Thus, my question: is there a way to calculate the distance from each 
data point and its nearest neighbor (only one) belonging to a different 
polygon?

Regards,

Ivan
On 18-Feb-15 13:02, Adrian Baddeley wrote:
> After you do
>      > nn.within.pol<-nndist(randp.df[,c(2,3)], by=factor(randp.df$Polygon_ID))
>
> the result nn.within.pol is a matrix with one row for each data point, and
> one column for each polygon. The entry on row i, column j is the distance
> from the i-th data point to its nearest neighbour in polygon j.
>
> It's still not clear to me what you wanted to calculate.
>
> Do you want the minimum distance between any two points in different polygons?
> For each possible pair of polygons? or... ?
>
> The command
>        
>       >   aggregate(nn.within.pol, by=list(from=factor(randp.df$PolygonID)), min)
>
> would yield a matrix, with one row and column for each polygon,
> in which the [i,j] entry is the minimum distance between any point in polygon i
> and any point in polygon j. On the diagonal the [i,i] entry would give the minimum
> nearest-neighbour distance for the pattern of points within polygon i.
>
>
> Prof Adrian Baddeley FAA
> Curtin University
> ________________________________________
> From: Ivan Palmegiani [pan.sapiens.it at gmail.com]
> Sent: Wednesday, 18 February 2015 12:32 PM
> To: Adrian Baddeley
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] Calculate shortest distance between points belonging to different polygons
>
> Dear Adrian,
>
> Thank you very much!
>
> I made the change you suggested and the outcome is not exactly the one I wanted...but it's very close to it!
>
>> library(spatstat)
>> nn.within.pol<-nndist(randp.df[,c(2,3)], by=factor(randp.df$Polygon_ID))
>> nn.within.pol
>                             1                   2                 3                     4                     5                   6                     7                     8                   9                   10              11                    12              13
>    [1,]  77758.488  71978.036 33715.961  62236.2421  84528.6758 47206.9703 26370.4913  39448.7910  40198.916  68559.0147  67769.69 39298.45411  2579.422
>    [2,]  63404.130  93535.612 64780.940  21597.4530  32485.1889  1391.8891 38473.2915  69642.7457  24374.408  15070.9926  70237.22 35217.62792 49217.807
>    [3,]  37861.018  53839.721 27587.333  59658.5379  58107.6351 35133.6718 48282.9013  75710.3428  48898.652  52273.7298  33882.71    59.85628 36756.945
>    ...
>   [98,] 114435.572 111577.598 73735.852  65518.7127 102369.5236 65629.7084 29330.3308    955.2648  39271.208  81234.4457 107270.98 74005.63912 30371.918
>   [99,]  32283.616  52705.045 28666.796  61665.1649  55854.9164 36094.8633 53239.2478  81208.2781  52669.590  52158.4953  30242.29  3166.00894 42467.270
> [100,]  38187.593  53418.183 27001.456  60050.0374  58795.8736 35555.5710 48200.6059  75445.7086  49047.448  52858.1932  33791.42   705.25663 36323.229
>
> In fact, I realized that I do not need to make recourse to aggregate() because in the matrix above I already have the information I need. I just need to extract it.
> Is there any way to prevent the function to calculate the distance between a point and its nn within the same group (i.e. distance [1, 13]; [2, 6]; [3, 12]; etc.)?
>
> If not, I will just extract the second shortest distance per point (the shortest one is certainly within the same group) and I will get exactly the information I need.
>
> Thanks again!
>
> Sincerely,
>
> Ivan
>
>
> On 17-Feb-15 16:01, Adrian Baddeley wrote:
>
> Ivan Palmegiani <pan.sapiens.it at gmail.com><mailto:pan.sapiens.it at gmail.com> writes:
>
>
>
> I'm handling a SpatialPointsDataFrame with 100 ramdom points distributed
> within 13 different polygons.
>
>
>
>   > randp
>
>
>                       coordinates   Point_ID   Polygon_ ID
> 0  (690926.8, 7522595)         1_hs                    13
> 1  (696727.1, 7576122)         2_hs                      6
>
>
>
>
>
> I need to calculate the shortest distance between points belonging to
> different polygons. Basically I'd like to do what nndist {spatstat} does.
> The difference is that the distance should be calculated between
> groups of points instead of within a group of points.
>
>
>
>                Well, nndist {spatstat} does that too.
>
>
>
> I tried to use "aggregate" as suggested below but it didn't work out for me.
> http://www.inside-r.org/packages/cran/spatstat/docs/nndist
>
>
>
>
>
> Please find my try below:
>
>
>
>
>
>   > randp.df<-data.frame(randp)
>   > randp.hs.df
>          Point_ID     coords.x1      coords.x2   Polygon_ ID
> 0            1_hs     690926.8       7522595 13
> 1            2_hs     696727.1       7576122 6
> 2            3_hs     723480.7       7546594 12
>
>
>
>
>
> library(spatstat)
>
>
>
>
>
> # Calculate nearest neighbors within a polygon
>   > nn.within.pol<-nndist(randp.df[,c(2,3)],by=marks(randp.df$Polygon_ID))
>
>
>
>                'marks' is not appropriate here.
>                marks() is a function that extracts the marks from a marked point pattern (class 'ppp')
>                but you are applying it to a numeric vector. The result is NULL.
>
>                The argument 'by' should be a factor that determines the grouping.
>
>                Just change 'marks' to 'factor' so that the numeric polygon ID will be treated as a factor,
>
>   nn.within.pol<-nndist(randp.df[,c(2,3)],by=factor(randp.df$Polygon_ID))
>
>                 and proceed as before (also changing the other instances of 'marks' to 'factor')
>
>
>
> Adrian Baddeley
> spatstat author
>
>
>
>


	[[alternative HTML version deleted]]


From adrian.baddeley at uwa.edu.au  Thu Feb 19 01:53:43 2015
From: adrian.baddeley at uwa.edu.au (Adrian Baddeley)
Date: Thu, 19 Feb 2015 08:53:43 +0800
Subject: [R-sig-Geo] Calculate shortest distance between points
 belonging to different polygons
In-Reply-To: <54E49D9C.60409@gmail.com>
References: <CF5661163F77A44781208D9AC4FDEA72013BA6EBE1C2@IS-WIN-376.staffad.uwa.edu.au>,
	<54E415C1.5060905@gmail.com>
	<CF5661163F77A44781208D9AC4FDEA72013BA6EBE1CA@IS-WIN-376.staffad.uwa.edu.au>,
	<54E49D9C.60409@gmail.com>
Message-ID: <CF5661163F77A44781208D9AC4FDEA72013BA6EBE1CC@IS-WIN-376.staffad.uwa.edu.au>

> Thus, my question: is there a way to calculate the distance from each data point and its nearest neighbor (only one) belonging to a different polygon?

OK. First do

      f <- factor(randp.df$Polygon_ID)
      M <-nndist(randp.df[,c(2,3)], by=f)

which is equivalent to what you did before. 
Next in the matrix M we're going to change M[i, Ji] to have the value infinity,
where Ji is the index of the polygon that contains the i-th data point:

     Ji <- as.integer(f)
     ii <- seq_len(nrow(M))
     M[ cbind(ii, Ji) ] <- Inf

Then just take the row-wise minimum

     dmin <- apply(M, 1, min)



Prof Adrian Baddeley FAA
Curtin University
________________________________________
From: Ivan Palmegiani [pan.sapiens.it at gmail.com]
Sent: Wednesday, 18 February 2015 10:11 PM
To: Adrian Baddeley
Cc: r-sig-geo at r-project.org; r.turner at auckland.ac.nz; Ege Rubak
Subject: Re: [R-sig-Geo] Calculate shortest distance between points belonging to different polygons

Dear Adrian,

Thanks for your explanation.

My goal is measuring the minimum distance from each data point to its nearest neighbor belonging to a different polygon (a pair of point then).
In fact, this distance is in the matrix resulting from

> nn.pol<-nndist(randp.df[,c(2,3)], by=factor(randp.df$Polygon_ID)

The polygons I'm considering are relatively small and distant each other so, in my case, the distance between data points belonging to the same polygon is certainly shorter that the distance to data points belonging to other polygons. Thus, the smallest value of each row is the distance from a data point to its nearest neighbor within the same polygon, while the second smallest value of each row is the distance from a data point and its nearest neighbor belonging to another polygon.

The latter value is the distance I want and I extracted it from the matrix using the following for loop:


> min.dist<-NULL

> for(i in 1:nrow(nn.pol)){

+ min.dist.temp<-min(nn.pol[i,] [nn.pol[i,] != min(nn.pol[i,])])

+ min.dist<-as.vector(c(min.dist,min.dist.temp))

+ }

Maybe not the most elegant way to do it...but it worked. The result is a vector whose length is equal to the number of data point.


> head(nn.dist.hs)

[1] 26370.49 15070.99 27587.33 15722.28 15186.39 31147.84

If the polygons were large and tangential or overlapping, I could not know which value I should have extracted because the distance between two points belonging to the same polygon might be larger than the distance between two points belonging to different polygons.

Thus, my question: is there a way to calculate the distance from each data point and its nearest neighbor (only one) belonging to a different polygon?

Regards,

Ivan


From pan.sapiens.it at gmail.com  Fri Feb 20 06:01:01 2015
From: pan.sapiens.it at gmail.com (Ivan Palmegiani)
Date: Fri, 20 Feb 2015 07:01:01 +0200
Subject: [R-sig-Geo] Calculate shortest distance between points
 belonging to different polygons
In-Reply-To: <CF5661163F77A44781208D9AC4FDEA72013BA6EBE1CC@IS-WIN-376.staffad.uwa.edu.au>
References: <CF5661163F77A44781208D9AC4FDEA72013BA6EBE1C2@IS-WIN-376.staffad.uwa.edu.au>,
	<54E415C1.5060905@gmail.com>
	<CF5661163F77A44781208D9AC4FDEA72013BA6EBE1CA@IS-WIN-376.staffad.uwa.edu.au>,
	<54E49D9C.60409@gmail.com>
	<CF5661163F77A44781208D9AC4FDEA72013BA6EBE1CC@IS-WIN-376.staffad.uwa.edu.au>
Message-ID: <54E6BF8D.1090407@gmail.com>

Good morning Adrian,

I implemented your suggestion and it worked perfectly. Thanks for your 
support!

Sincerely,

Ivan

On 19-Feb-15 2:53, Adrian Baddeley wrote:
>> Thus, my question: is there a way to calculate the distance from each data point and its nearest neighbor (only one) belonging to a different polygon?
> OK. First do
>
>        f <- factor(randp.df$Polygon_ID)
>        M <-nndist(randp.df[,c(2,3)], by=f)
>
> which is equivalent to what you did before.
> Next in the matrix M we're going to change M[i, Ji] to have the value infinity,
> where Ji is the index of the polygon that contains the i-th data point:
>
>       Ji <- as.integer(f)
>       ii <- seq_len(nrow(M))
>       M[ cbind(ii, Ji) ] <- Inf
>
> Then just take the row-wise minimum
>
>       dmin <- apply(M, 1, min)
>
>
>
> Prof Adrian Baddeley FAA
> Curtin University
> ________________________________________
> From: Ivan Palmegiani [pan.sapiens.it at gmail.com]
> Sent: Wednesday, 18 February 2015 10:11 PM
> To: Adrian Baddeley
> Cc: r-sig-geo at r-project.org; r.turner at auckland.ac.nz; Ege Rubak
> Subject: Re: [R-sig-Geo] Calculate shortest distance between points belonging to different polygons
>
> Dear Adrian,
>
> Thanks for your explanation.
>
> My goal is measuring the minimum distance from each data point to its nearest neighbor belonging to a different polygon (a pair of point then).
> In fact, this distance is in the matrix resulting from
>
>> nn.pol<-nndist(randp.df[,c(2,3)], by=factor(randp.df$Polygon_ID)
> The polygons I'm considering are relatively small and distant each other so, in my case, the distance between data points belonging to the same polygon is certainly shorter that the distance to data points belonging to other polygons. Thus, the smallest value of each row is the distance from a data point to its nearest neighbor within the same polygon, while the second smallest value of each row is the distance from a data point and its nearest neighbor belonging to another polygon.
>
> The latter value is the distance I want and I extracted it from the matrix using the following for loop:
>
>
>> min.dist<-NULL
>> for(i in 1:nrow(nn.pol)){
> + min.dist.temp<-min(nn.pol[i,] [nn.pol[i,] != min(nn.pol[i,])])
>
> + min.dist<-as.vector(c(min.dist,min.dist.temp))
>
> + }
>
> Maybe not the most elegant way to do it...but it worked. The result is a vector whose length is equal to the number of data point.
>
>
>> head(nn.dist.hs)
> [1] 26370.49 15070.99 27587.33 15722.28 15186.39 31147.84
>
> If the polygons were large and tangential or overlapping, I could not know which value I should have extracted because the distance between two points belonging to the same polygon might be larger than the distance between two points belonging to different polygons.
>
> Thus, my question: is there a way to calculate the distance from each data point and its nearest neighbor (only one) belonging to a different polygon?
>
> Regards,
>
> Ivan
>


From gab.cozzi at gmail.com  Fri Feb 20 11:43:46 2015
From: gab.cozzi at gmail.com (Gabriele Cozzi)
Date: Fri, 20 Feb 2015 11:43:46 +0100
Subject: [R-sig-Geo] dynamic (interactive) representation of several GPS
	trajectories
Message-ID: <CADr8yXACua3zdBUM+61kyhouCuH=+xackEo-wo4g7fZ2GO2wZA@mail.gmail.com>

Dear list,

I have relocation data for about 20 individuals (ID) for a total of about
70K rows organised in the following data frame:
timevar <-as.numeric(Timestamp); SB is categorical with 2 levels, the other
variables are self-explanatory I think

ID       Date        Time           Timestamp              Lon       Lat
         Alti SB timevar
D 2013-01-01 18:40:00 2013-01-01 18:40:00 21.85803 -26.99953 917  0    1500
D 2013-01-01 18:55:00 2013-01-01 18:55:00 21.85877 -27.00000 921  0    2400
D 2013-01-01 19:10:00 2013-01-01 19:10:00 21.85907 -27.00015 925  0    3300
A 2013-01-01 19:27:00 2013-01-01 19:27:00 21.85875 -27.00142 922  1    4320
A 2013-01-02 06:40:00 2013-01-02 06:40:00 21.85872 -27.00142 919  1   44700
A 2013-01-02 06:55:00 2013-01-02 06:55:00 21.86060 -27.00090 916  0   45600
..    ...............     ...........           ......................
   ........      .........      ....  ..    ......

What I would like to do is to create an animated plot where I can see how
the various individuals move in relationship to each other.

The gvisMotionChart() function from the googleVis package does what I need
on a small subset of my data but it crashes if I try to do the same on the
entire data set.

A reproducible example for two individuals:
     x <- rnorm(40, 21, 0.5)
     y <- rnorm(40, -27, 0.5)
     ID <- rep(c("A","B"), each=20)
     Alt <- floor(rnorm(40, 900, 10))
     tvar <- 1:40
     tvarA <- sample(tvar,20)
     tvarB <- setdiff(tvar, tvarA)

     DF <- data.frame(ID,x,y,Alt,tvar = c(tvarA,tvarB))
     DF <- DF[order(DF$ID,DF$tvar),]

     library(googleVis)
     plot(gvisMotionChart(DF, idvar="ID", timevar= "tvar"))


An alternative along the lines of what I want would be  the
trajdyn{adehabitatLT}, even if it does not allow dynamic movements of more
than one individual at the time, which is unfortunate in my case.

Any suggestion regarding alternative packages/functions is highly
appreciated.

Thanks in advance,
Gabriele


-- 
Gabriele Cozzi
Postdoctoral Research Associate
Population Ecology Research Group
http://www.popecol.org

Zurich University
Institute of Evolutionary Biology and Environmental Studies
Winterthurerstr. 190
8057 Zurich - Switzerland
E-mail: gabriele.cozzi at uzh.ch
Office: 34-J-38
Phone: +41(0)44 635 47 56
Fax: +41(0)16355711
http://www.ieu.uzh.ch

	[[alternative HTML version deleted]]


From roman.lustrik at gmail.com  Fri Feb 20 11:56:54 2015
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Fri, 20 Feb 2015 11:56:54 +0100
Subject: [R-sig-Geo] dynamic (interactive) representation of several GPS
	trajectories
In-Reply-To: <CADr8yXACua3zdBUM+61kyhouCuH=+xackEo-wo4g7fZ2GO2wZA@mail.gmail.com>
References: <CADr8yXACua3zdBUM+61kyhouCuH=+xackEo-wo4g7fZ2GO2wZA@mail.gmail.com>
Message-ID: <CAHT1vpgRm6iiEDAABXDuHm=0RW0ckVwJOWtfwTAiMH-0axGxWQ@mail.gmail.com>

Hello Gabriele,

have you considered "slicing" your data according to time, put everything
in a RasterStack or RasterBrick and visualize it using some other package,
like `animate`? I think this example (
http://vis.supstat.com/2012/11/brownian-motion-with-r/) is close to what
you're after. What is the desired format you're shooting for? A gif? Or
does it have to be embedded in html?

Cheers,
Roman

On Fri, Feb 20, 2015 at 11:43 AM, Gabriele Cozzi <gab.cozzi at gmail.com>
wrote:

> Dear list,
>
> I have relocation data for about 20 individuals (ID) for a total of about
> 70K rows organised in the following data frame:
> timevar <-as.numeric(Timestamp); SB is categorical with 2 levels, the other
> variables are self-explanatory I think
>
> ID       Date        Time           Timestamp              Lon       Lat
>          Alti SB timevar
> D 2013-01-01 18:40:00 2013-01-01 18:40:00 21.85803 -26.99953 917  0    1500
> D 2013-01-01 18:55:00 2013-01-01 18:55:00 21.85877 -27.00000 921  0    2400
> D 2013-01-01 19:10:00 2013-01-01 19:10:00 21.85907 -27.00015 925  0    3300
> A 2013-01-01 19:27:00 2013-01-01 19:27:00 21.85875 -27.00142 922  1    4320
> A 2013-01-02 06:40:00 2013-01-02 06:40:00 21.85872 -27.00142 919  1   44700
> A 2013-01-02 06:55:00 2013-01-02 06:55:00 21.86060 -27.00090 916  0   45600
> ..    ...............     ...........           ......................
>    ........      .........      ....  ..    ......
>
> What I would like to do is to create an animated plot where I can see how
> the various individuals move in relationship to each other.
>
> The gvisMotionChart() function from the googleVis package does what I need
> on a small subset of my data but it crashes if I try to do the same on the
> entire data set.
>
> A reproducible example for two individuals:
>      x <- rnorm(40, 21, 0.5)
>      y <- rnorm(40, -27, 0.5)
>      ID <- rep(c("A","B"), each=20)
>      Alt <- floor(rnorm(40, 900, 10))
>      tvar <- 1:40
>      tvarA <- sample(tvar,20)
>      tvarB <- setdiff(tvar, tvarA)
>
>      DF <- data.frame(ID,x,y,Alt,tvar = c(tvarA,tvarB))
>      DF <- DF[order(DF$ID,DF$tvar),]
>
>      library(googleVis)
>      plot(gvisMotionChart(DF, idvar="ID", timevar= "tvar"))
>
>
> An alternative along the lines of what I want would be  the
> trajdyn{adehabitatLT}, even if it does not allow dynamic movements of more
> than one individual at the time, which is unfortunate in my case.
>
> Any suggestion regarding alternative packages/functions is highly
> appreciated.
>
> Thanks in advance,
> Gabriele
>
>
> --
> Gabriele Cozzi
> Postdoctoral Research Associate
> Population Ecology Research Group
> http://www.popecol.org
>
> Zurich University
> Institute of Evolutionary Biology and Environmental Studies
> Winterthurerstr. 190
> 8057 Zurich - Switzerland
> E-mail: gabriele.cozzi at uzh.ch
> Office: 34-J-38
> Phone: +41(0)44 635 47 56
> Fax: +41(0)16355711
> http://www.ieu.uzh.ch
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
In God we trust, all others bring data.

	[[alternative HTML version deleted]]


From jgrn at illinois.edu  Fri Feb 20 21:05:13 2015
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Fri, 20 Feb 2015 20:05:13 +0000
Subject: [R-sig-Geo] Proper algorithms for computing slopes for global/polar
	DEMs?
Message-ID: <CABG0rftQKo+u3kCaT7Sm1kbO=LbvCV3YfNGOQNheePA+iQ4AwQ@mail.gmail.com>

r-sig-geo'ers:

We're trying to figure out a good algorithm for computing topographic slope
for Alaska, which is both huge and near the pole.  Our DEM is currently in
geographic coordinates, but we need slope over a fixed distance (change in
elevation vs. horizontal meters).  The issue is, there is no projection to
switch this to to get an accurate set of slope calculations.  Of course
with degrees, the X and Y distances change over the globe -- so the
horizontal distances will be variables from one window to the next.  I have
seen various solutions published, but I wanted to see if someone knows of a
decent coded-up algorithm for this.  Thoughts?

Some background:
http://gis.stackexchange.com/questions/14750/how-to-use-srtm-global-dem-for-slope-calculation/40464#40464

--j

	[[alternative HTML version deleted]]


From clint at ecy.wa.gov  Fri Feb 20 21:38:56 2015
From: clint at ecy.wa.gov (Clint Bowman)
Date: Fri, 20 Feb 2015 12:38:56 -0800 (PST)
Subject: [R-sig-Geo] Proper algorithms for computing slopes for
 global/polar DEMs?
In-Reply-To: <CABG0rftQKo+u3kCaT7Sm1kbO=LbvCV3YfNGOQNheePA+iQ4AwQ@mail.gmail.com>
References: <CABG0rftQKo+u3kCaT7Sm1kbO=LbvCV3YfNGOQNheePA+iQ4AwQ@mail.gmail.com>
Message-ID: <alpine.LRH.2.11.1502201235330.18806@aeolus.ecy.wa.gov>

Have you thought about a Lambert Conformal projection?  I'd think you 
could adjust the projection parameters to get a pretty nice grid over 
Alaska.  I'm sure the mesoscale modelers at UA-Fairbanks have worked this 
out.

Clint

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Fri, 20 Feb 2015, Jonathan Greenberg wrote:

> r-sig-geo'ers:
>
> We're trying to figure out a good algorithm for computing topographic slope
> for Alaska, which is both huge and near the pole.  Our DEM is currently in
> geographic coordinates, but we need slope over a fixed distance (change in
> elevation vs. horizontal meters).  The issue is, there is no projection to
> switch this to to get an accurate set of slope calculations.  Of course
> with degrees, the X and Y distances change over the globe -- so the
> horizontal distances will be variables from one window to the next.  I have
> seen various solutions published, but I wanted to see if someone knows of a
> decent coded-up algorithm for this.  Thoughts?
>
> Some background:
> http://gis.stackexchange.com/questions/14750/how-to-use-srtm-global-dem-for-slope-calculation/40464#40464
>
> --j
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From clint at ecy.wa.gov  Fri Feb 20 22:07:47 2015
From: clint at ecy.wa.gov (Clint Bowman)
Date: Fri, 20 Feb 2015 13:07:47 -0800 (PST)
Subject: [R-sig-Geo] Proper algorithms for computing slopes for
 global/polar DEMs?
In-Reply-To: <alpine.LRH.2.11.1502201235330.18806@aeolus.ecy.wa.gov>
References: <CABG0rftQKo+u3kCaT7Sm1kbO=LbvCV3YfNGOQNheePA+iQ4AwQ@mail.gmail.com>
	<alpine.LRH.2.11.1502201235330.18806@aeolus.ecy.wa.gov>
Message-ID: <alpine.LRH.2.11.1502201305100.18806@aeolus.ecy.wa.gov>

Also Roland Stull at U British Columbia is doing high resolution numerical 
weather prediction in the Canadian Arctic.  Again, I'm sure he has worked 
out the topographic issues.

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Fri, 20 Feb 2015, Clint Bowman wrote:

> Have you thought about a Lambert Conformal projection?  I'd think you could 
> adjust the projection parameters to get a pretty nice grid over Alaska.  I'm 
> sure the mesoscale modelers at UA-Fairbanks have worked this out.
>
> Clint
>
> Clint Bowman			INTERNET:	clint at ecy.wa.gov
> Air Quality Modeler		INTERNET:	clint at math.utah.edu
> Department of Ecology		VOICE:		(360) 407-6815
> PO Box 47600			FAX:		(360) 407-7534
> Olympia, WA 98504-7600
>
>         USPS:           PO Box 47600, Olympia, WA 98504-7600
>         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
>
> On Fri, 20 Feb 2015, Jonathan Greenberg wrote:
>
>>  r-sig-geo'ers:
>>
>>  We're trying to figure out a good algorithm for computing topographic
>>  slope
>>  for Alaska, which is both huge and near the pole.  Our DEM is currently in
>>  geographic coordinates, but we need slope over a fixed distance (change in
>>  elevation vs. horizontal meters).  The issue is, there is no projection to
>>  switch this to to get an accurate set of slope calculations.  Of course
>>  with degrees, the X and Y distances change over the globe -- so the
>>  horizontal distances will be variables from one window to the next.  I
>>  have
>>  seen various solutions published, but I wanted to see if someone knows of
>>  a
>>  decent coded-up algorithm for this.  Thoughts?
>>
>>  Some background:
>>  http://gis.stackexchange.com/questions/14750/how-to-use-srtm-global-dem-for-slope-calculation/40464#40464
>>
>>  --j
>>
>>   [[alternative HTML version deleted]]
>>
>>  _______________________________________________
>>  R-sig-Geo mailing list
>>  R-sig-Geo at r-project.org
>>  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From basille.web at ase-research.org  Fri Feb 20 22:39:30 2015
From: basille.web at ase-research.org (Mathieu Basille)
Date: Fri, 20 Feb 2015 16:39:30 -0500
Subject: [R-sig-Geo] dynamic (interactive) representation of several GPS
 trajectories
In-Reply-To: <CADr8yXACua3zdBUM+61kyhouCuH=+xackEo-wo4g7fZ2GO2wZA@mail.gmail.com>
References: <CADr8yXACua3zdBUM+61kyhouCuH=+xackEo-wo4g7fZ2GO2wZA@mail.gmail.com>
Message-ID: <54E7A992.9080203@ase-research.org>

In addition to Roman's suggestion, I tweaked the function 'plot.ltraj' to 
successfully implement a non-interactive version of what (I think) you 
want, that is a video (for an interactive version of it, keep reading and 
see below, but there would be only one individual unfortunately). Among a 
few other things, the function now allows to plot all (selected) 
individuals on the same plot (argument 'by = "none"), which is relevant for 
your purpose. It also allow you to modify point/line graphical settings.

The modified function is available in the package "hab":

http://ase-research.org/basille/hab

(probably better to install the one from GitHub directly)

Keep in mind that this is not a package as stable as adehabitatLT. I do my 
best, but use at your own risks! ;)

Now, if you would like to export a video, you could use the modified 
'plot.ltraj' to do essentially the following steps:

* prepare a time sequence
* use this sequence to loop over the whole ltraj, subset the relevant time 
period, and plot it
* export as PNG at each step
* use ffmpeg to convert it in mp4 video

The resulting video looks like this:

http://ase-research.org/basille/pres/Basille_FLREC_2014/video/wost.mp4

or that:

http://ase-research.org/basille/pres/Basille_FLREC_2014/video/wost-dark.mp4

with different graphical parameters. In details (but you'll have to adjust 
it to your own data), it goes like this ['wlt' is the ltraj object]:

## ================================================ ##
## Load 'hab' and 'lubridate' (for time management)
library(hab)
library(lubridate)

## Prepare the sequence (tseq12 every 12 hours)
tseq12 <- seq(ymd("20090301"), ymd("20111231"), by = 3600*12)
length(tseq12)

## Prepare the graphical parameters with the complete plot
library(RColorBrewer)
wcol <- brewer.pal(8, "Dark2")
names(wcol) <- burst(wlt)
par(mar = c(0, 0, 0, 0), bg = "#3b3f43")
plot(wlt, by = "none", axes = FALSE, ppar = list(pch = 20, col = wcol), 
lpar = list(col = wcol, lwd = 3), spoldf = wMapc, spoldfpar = list(col = 
"#ecececff", border = NA), final = FALSE)
text(x = 0, y = 3000000, label = paste(month(tseq12[1], label = TRUE), 
year(tseq12[1]), sep = "\n"), cex = 3, col = "#ecececff")

## And plot windows of 5 days in a loop
library(Cairo)
for (i in 1:length(tseq12)) {
     CairoPNG(filename = paste0("img/wost", sprintf("%05d", i),
         ".png"), bg = "#fdfbf4ff", width = 1000, height = 1000)
     par(mar = c(0, 0, 0, 0), bg = "#fdfbf4ff")
     plot(subset(wlt, date >= tseq12[i] & date < tseq12[i] + 3600 *
         24 * 5), by = "none", axes = FALSE, ppar = list(pch = 20,
         col = wcol, cex = 4), lpar = list(col = wcol, lwd = 12),
         spoldf = wMapc, spoldfpar = list(col = "white", border = 
"#a6a6a6ff", lwd = 3),
         final = FALSE, xlim = range(coordinates(wostsub)[, "x"]),
         ylim = range(coordinates(wostsub)[, "y"]))
     text(x = 0, y = 3e+06, label = paste(month(tseq12[i], label = TRUE),
         year(tseq12[i]), sep = "\n"), cex = 6, col = "#a6a6a6ff")
     dev.off()
}

## Finally convert to a video with ffmpeg
## https://trac.ffmpeg.org/wiki/Create%20a%20video%20slideshow%20from%20images
system("ffmpeg -r 0.3 -framerate 30 -i img/wost%05d.png -c:v libx264 
-pix_fmt yuv420p video/wost.mp4")
## ================================================ ##

Looks quite complicated, but I promise it's not that difficult!

Now for the interactive version: I also tweaked 'trajdyn' quite a bit: it 
allows to display only a given number of steps, increment by a given number 
of steps, change point/line graphical parameters, etc. *But* it doesn't 
allow to display several bursts/individuals at once, just as 'plot.ltraj' 
now does... This is a strong limitation to what you want to achieve, and 
I'm afraid that implementing it (which would be interesting, but I did not 
have that in mind yet) would be a tremendous work.

Hope this helps,
Mathieu.


Le 20/02/2015 05:43, Gabriele Cozzi a ?crit :
> Dear list,
>
> I have relocation data for about 20 individuals (ID) for a total of about
> 70K rows organised in the following data frame:
> timevar <-as.numeric(Timestamp); SB is categorical with 2 levels, the other
> variables are self-explanatory I think
>
> ID       Date        Time           Timestamp              Lon       Lat
>           Alti SB timevar
> D 2013-01-01 18:40:00 2013-01-01 18:40:00 21.85803 -26.99953 917  0    1500
> D 2013-01-01 18:55:00 2013-01-01 18:55:00 21.85877 -27.00000 921  0    2400
> D 2013-01-01 19:10:00 2013-01-01 19:10:00 21.85907 -27.00015 925  0    3300
> A 2013-01-01 19:27:00 2013-01-01 19:27:00 21.85875 -27.00142 922  1    4320
> A 2013-01-02 06:40:00 2013-01-02 06:40:00 21.85872 -27.00142 919  1   44700
> A 2013-01-02 06:55:00 2013-01-02 06:55:00 21.86060 -27.00090 916  0   45600
> ..    ...............     ...........           ......................
>     ........      .........      ....  ..    ......
>
> What I would like to do is to create an animated plot where I can see how
> the various individuals move in relationship to each other.
>
> The gvisMotionChart() function from the googleVis package does what I need
> on a small subset of my data but it crashes if I try to do the same on the
> entire data set.
>
> A reproducible example for two individuals:
>       x <- rnorm(40, 21, 0.5)
>       y <- rnorm(40, -27, 0.5)
>       ID <- rep(c("A","B"), each=20)
>       Alt <- floor(rnorm(40, 900, 10))
>       tvar <- 1:40
>       tvarA <- sample(tvar,20)
>       tvarB <- setdiff(tvar, tvarA)
>
>       DF <- data.frame(ID,x,y,Alt,tvar = c(tvarA,tvarB))
>       DF <- DF[order(DF$ID,DF$tvar),]
>
>       library(googleVis)
>       plot(gvisMotionChart(DF, idvar="ID", timevar= "tvar"))
>
>
> An alternative along the lines of what I want would be  the
> trajdyn{adehabitatLT}, even if it does not allow dynamic movements of more
> than one individual at the time, which is unfortunate in my case.
>
> Any suggestion regarding alternative packages/functions is highly
> appreciated.
>
> Thanks in advance,
> Gabriele
>
>

-- 

~$ whoami
Mathieu Basille
http://ase-research.org/basille

~$ locate --details
University of Florida \\
Fort Lauderdale Research and Education Center
(+1) 954-577-6314

~$ fortune
? Le tout est de tout dire, et je manque de mots
Et je manque de temps, et je manque d'audace. ?
  -- Paul ?luard

-- 

~$ whoami
Mathieu Basille
http://ase-research.org/basille

~$ locate --details
University of Florida \\
Fort Lauderdale Research and Education Center
(+1) 954-577-6314

~$ fortune
? Le tout est de tout dire, et je manque de mots
Et je manque de temps, et je manque d'audace. ?
  -- Paul ?luard


From tkeitt at utexas.edu  Fri Feb 20 23:53:42 2015
From: tkeitt at utexas.edu (Tim Keitt)
Date: Fri, 20 Feb 2015 16:53:42 -0600
Subject: [R-sig-Geo] Proper algorithms for computing slopes for
 global/polar DEMs?
In-Reply-To: <CABG0rftQKo+u3kCaT7Sm1kbO=LbvCV3YfNGOQNheePA+iQ4AwQ@mail.gmail.com>
References: <CABG0rftQKo+u3kCaT7Sm1kbO=LbvCV3YfNGOQNheePA+iQ4AwQ@mail.gmail.com>
Message-ID: <CANnL8gowviKWjF_hgpZhBR1m9M-KdmZb5fxS8Wg_X0TW-DtrOQ@mail.gmail.com>

On Fri, Feb 20, 2015 at 2:05 PM, Jonathan Greenberg <jgrn at illinois.edu>
wrote:

> r-sig-geo'ers:
>
> We're trying to figure out a good algorithm for computing topographic slope
> for Alaska, which is both huge and near the pole.  Our DEM is currently in
> geographic coordinates, but we need slope over a fixed distance (change in
> elevation vs. horizontal meters).  The issue is, there is no projection to
> switch this to to get an accurate set of slope calculations.  Of course
> with degrees, the X and Y distances change over the globe -- so the
> horizontal distances will be variables from one window to the next.  I have
> seen various solutions published, but I wanted to see if someone knows of a
> decent coded-up algorithm for this.  Thoughts?
>
> Some background:
>
> http://gis.stackexchange.com/questions/14750/how-to-use-srtm-global-dem-for-slope-calculation/40464#40464
>
> --j
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

But slope is linear, so just take the ratio dz/dx (in one dimension --
slightly more involved in 2d as I assume you want the slope along the
steepest gradient). You just need the distance between grid cells and the
elevation change.

THK

-- 
http://www.keittlab.org/

	[[alternative HTML version deleted]]


From jgcorripio at mac.com  Sat Feb 21 13:32:18 2015
From: jgcorripio at mac.com (Javier G. Corripio)
Date: Sat, 21 Feb 2015 13:32:18 +0100
Subject: [R-sig-Geo] Proper algorithms for computing slopes for
	global/polar DEMs?
In-Reply-To: <mailman.14.1424516405.8489.r-sig-geo@r-project.org>
References: <mailman.14.1424516405.8489.r-sig-geo@r-project.org>
Message-ID: <3E893A30-6B22-46D8-B39B-C97BEF5CA0E7@mac.com>

I think the package raster calculates slope for DEMs in geographic coordinates see ?terrain

If you want a more generic algorithm see Corripio 2003:
http://www.meteoexploration.com/R/insol/data/Corripio03_IJGIS.pdf  It is described for regular grid cells but it is applicable to irregular ones. Insol calculates slope but only for regular squared cells.

If you can neglect curvature of the earth (big IF, but if you can't, slope might be very variable),
for every grid cell in your DEM you can define two vectors, one along longitude and other along latitude to the nearest grid cell point east and north respectively. The distance between points can be calculated with haversine to avoid extra coding (package geosphere), then the vector components would be X=(dx,0,Dzx), Y=(0,dy,Dzy)
dx is distance along parallel of same latitude,
dy is distance along meridian of same longitude,
and Dz is diference in altitude along x or y respectively.

The vector normal to the surface is the vector product N = (X/|X|) x (Y/|Y|), and from the result the slope and aspect can be calculated: slope = acos(Nz)

Javier

> Subject: [R-sig-Geo] Proper algorithms for computing slopes for global/polar DEMs?
> 

-- 
**************************************
Javier G. Corripio, PhD
email: jgcorripio at mac.com
            jgc at meteoexploration.com
url: http://www.meteoexploration.com





	[[alternative HTML version deleted]]


From jsheehan06 at gmail.com  Sun Feb 22 05:06:21 2015
From: jsheehan06 at gmail.com (js_wvu15)
Date: Sat, 21 Feb 2015 21:06:21 -0700 (MST)
Subject: [R-sig-Geo] spatstat predict rhohat question
Message-ID: <1424577981933-7587812.post@n2.nabble.com>

Hello,

I'm using spatstat 1.40-0 in R version 3.1.2 and encountered this warning
for predict.rhohat when the rhohat object is a fitted point process model
and the window is irregular:

Warning message:
In Y * lambda :
  longer object length is not a multiple of shorter object length

I managed to duplicate my warning:

library(spatstat)
X <- rpoispp(function(x,y){exp(3+3*x)})
win1 <- owin(poly=list(list(x=c(0,1,1,0), y=c(0,0,1,1)),
	list(x=c(0.6,0.4,0.4,0.6), y=c(0.2,0.2,0.4,0.4))))
X1 <- X[win1]
fit1 <- ppm(X1, ~x)
rho1 <- rhohat(fit1, "y")
plot(predict(rho1)) ###get the warning

I researched the warning but couldn't figure it out. Any help is greatly
appreciated!

Jim Sheehan
West Virginia, USA



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/spatstat-predict-rhohat-question-tp7587812.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From r.turner at auckland.ac.nz  Sun Feb 22 08:18:32 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 22 Feb 2015 20:18:32 +1300
Subject: [R-sig-Geo] spatstat predict rhohat question
In-Reply-To: <1424577981933-7587812.post@n2.nabble.com>
References: <1424577981933-7587812.post@n2.nabble.com>
Message-ID: <54E982C8.8070805@auckland.ac.nz>



Thank you for the *excellently* reproducible example.  We are looking 
into it and will get back to you.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


On 22/02/15 17:06, js_wvu15 wrote:
> Hello,
>
> I'm using spatstat 1.40-0 in R version 3.1.2 and encountered this warning
> for predict.rhohat when the rhohat object is a fitted point process model
> and the window is irregular:
>
> Warning message:
> In Y * lambda :
>    longer object length is not a multiple of shorter object length
>
> I managed to duplicate my warning:
>
> library(spatstat)
> X <- rpoispp(function(x,y){exp(3+3*x)})
> win1 <- owin(poly=list(list(x=c(0,1,1,0), y=c(0,0,1,1)),
> 	list(x=c(0.6,0.4,0.4,0.6), y=c(0.2,0.2,0.4,0.4))))
> X1 <- X[win1]
> fit1 <- ppm(X1, ~x)
> rho1 <- rhohat(fit1, "y")
> plot(predict(rho1)) ###get the warning
>
> I researched the warning but couldn't figure it out. Any help is greatly
> appreciated!


From r.turner at auckland.ac.nz  Mon Feb 23 08:00:03 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 23 Feb 2015 20:00:03 +1300
Subject: [R-sig-Geo] spatstat predict rhohat question
In-Reply-To: <54E982C8.8070805@auckland.ac.nz>
References: <1424577981933-7587812.post@n2.nabble.com>
	<54E982C8.8070805@auckland.ac.nz>
Message-ID: <54EACFF3.8020208@auckland.ac.nz>



There was indeed a bug in predict.rhohat().  It is has now been fixed 
and the correct version of the function will be included in the next 
release of *spatstat* --- said release should happen "real soon now". :-)

In the mean time, anyone who needs a corrected version urgenty should 
contact me off-list.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From gab.cozzi at gmail.com  Mon Feb 23 10:08:49 2015
From: gab.cozzi at gmail.com (Gabriele Cozzi)
Date: Mon, 23 Feb 2015 10:08:49 +0100
Subject: [R-sig-Geo] dynamic (interactive) representation of several GPS
	trajectories
In-Reply-To: <54E7A992.9080203@ase-research.org>
References: <CADr8yXACua3zdBUM+61kyhouCuH=+xackEo-wo4g7fZ2GO2wZA@mail.gmail.com>
	<54E7A992.9080203@ase-research.org>
Message-ID: <CADr8yXCeginTi8DG_LXq2p4mzxZdWS9P_0sagaDBvhORm1oKDw@mail.gmail.com>

Roman,
thanks for your input. Animate works fine.


Mathieu,
thanks a lot for the codes! I will soon try them out on my data.

Cheers,
Gabriele



On Fri, Feb 20, 2015 at 10:39 PM, Mathieu Basille <
basille.web at ase-research.org> wrote:

> In addition to Roman's suggestion, I tweaked the function 'plot.ltraj' to
> successfully implement a non-interactive version of what (I think) you
> want, that is a video (for an interactive version of it, keep reading and
> see below, but there would be only one individual unfortunately). Among a
> few other things, the function now allows to plot all (selected)
> individuals on the same plot (argument 'by = "none"), which is relevant for
> your purpose. It also allow you to modify point/line graphical settings.
>
> The modified function is available in the package "hab":
>
> http://ase-research.org/basille/hab
>
> (probably better to install the one from GitHub directly)
>
> Keep in mind that this is not a package as stable as adehabitatLT. I do my
> best, but use at your own risks! ;)
>
> Now, if you would like to export a video, you could use the modified
> 'plot.ltraj' to do essentially the following steps:
>
> * prepare a time sequence
> * use this sequence to loop over the whole ltraj, subset the relevant time
> period, and plot it
> * export as PNG at each step
> * use ffmpeg to convert it in mp4 video
>
> The resulting video looks like this:
>
> http://ase-research.org/basille/pres/Basille_FLREC_2014/video/wost.mp4
>
> or that:
>
> http://ase-research.org/basille/pres/Basille_FLREC_
> 2014/video/wost-dark.mp4
>
> with different graphical parameters. In details (but you'll have to adjust
> it to your own data), it goes like this ['wlt' is the ltraj object]:
>
> ## ================================================ ##
> ## Load 'hab' and 'lubridate' (for time management)
> library(hab)
> library(lubridate)
>
> ## Prepare the sequence (tseq12 every 12 hours)
> tseq12 <- seq(ymd("20090301"), ymd("20111231"), by = 3600*12)
> length(tseq12)
>
> ## Prepare the graphical parameters with the complete plot
> library(RColorBrewer)
> wcol <- brewer.pal(8, "Dark2")
> names(wcol) <- burst(wlt)
> par(mar = c(0, 0, 0, 0), bg = "#3b3f43")
> plot(wlt, by = "none", axes = FALSE, ppar = list(pch = 20, col = wcol),
> lpar = list(col = wcol, lwd = 3), spoldf = wMapc, spoldfpar = list(col =
> "#ecececff", border = NA), final = FALSE)
> text(x = 0, y = 3000000, label = paste(month(tseq12[1], label = TRUE),
> year(tseq12[1]), sep = "\n"), cex = 3, col = "#ecececff")
>
> ## And plot windows of 5 days in a loop
> library(Cairo)
> for (i in 1:length(tseq12)) {
>     CairoPNG(filename = paste0("img/wost", sprintf("%05d", i),
>         ".png"), bg = "#fdfbf4ff", width = 1000, height = 1000)
>     par(mar = c(0, 0, 0, 0), bg = "#fdfbf4ff")
>     plot(subset(wlt, date >= tseq12[i] & date < tseq12[i] + 3600 *
>         24 * 5), by = "none", axes = FALSE, ppar = list(pch = 20,
>         col = wcol, cex = 4), lpar = list(col = wcol, lwd = 12),
>         spoldf = wMapc, spoldfpar = list(col = "white", border =
> "#a6a6a6ff", lwd = 3),
>         final = FALSE, xlim = range(coordinates(wostsub)[, "x"]),
>         ylim = range(coordinates(wostsub)[, "y"]))
>     text(x = 0, y = 3e+06, label = paste(month(tseq12[i], label = TRUE),
>         year(tseq12[i]), sep = "\n"), cex = 6, col = "#a6a6a6ff")
>     dev.off()
> }
>
> ## Finally convert to a video with ffmpeg
> ## https://trac.ffmpeg.org/wiki/Create%20a%20video%
> 20slideshow%20from%20images
> system("ffmpeg -r 0.3 -framerate 30 -i img/wost%05d.png -c:v libx264
> -pix_fmt yuv420p video/wost.mp4")
> ## ================================================ ##
>
> Looks quite complicated, but I promise it's not that difficult!
>
> Now for the interactive version: I also tweaked 'trajdyn' quite a bit: it
> allows to display only a given number of steps, increment by a given number
> of steps, change point/line graphical parameters, etc. *But* it doesn't
> allow to display several bursts/individuals at once, just as 'plot.ltraj'
> now does... This is a strong limitation to what you want to achieve, and
> I'm afraid that implementing it (which would be interesting, but I did not
> have that in mind yet) would be a tremendous work.
>
> Hope this helps,
> Mathieu.
>
>
> Le 20/02/2015 05:43, Gabriele Cozzi a ?crit :
>
>  Dear list,
>>
>> I have relocation data for about 20 individuals (ID) for a total of about
>> 70K rows organised in the following data frame:
>> timevar <-as.numeric(Timestamp); SB is categorical with 2 levels, the
>> other
>> variables are self-explanatory I think
>>
>> ID       Date        Time           Timestamp              Lon       Lat
>>           Alti SB timevar
>> D 2013-01-01 18:40:00 2013-01-01 18:40:00 21.85803 -26.99953 917  0
>> 1500
>> D 2013-01-01 18:55:00 2013-01-01 18:55:00 21.85877 -27.00000 921  0
>> 2400
>> D 2013-01-01 19:10:00 2013-01-01 19:10:00 21.85907 -27.00015 925  0
>> 3300
>> A 2013-01-01 19:27:00 2013-01-01 19:27:00 21.85875 -27.00142 922  1
>> 4320
>> A 2013-01-02 06:40:00 2013-01-02 06:40:00 21.85872 -27.00142 919  1
>>  44700
>> A 2013-01-02 06:55:00 2013-01-02 06:55:00 21.86060 -27.00090 916  0
>>  45600
>> ..    ...............     ...........           ......................
>>     ........      .........      ....  ..    ......
>>
>> What I would like to do is to create an animated plot where I can see how
>> the various individuals move in relationship to each other.
>>
>> The gvisMotionChart() function from the googleVis package does what I need
>> on a small subset of my data but it crashes if I try to do the same on the
>> entire data set.
>>
>> A reproducible example for two individuals:
>>       x <- rnorm(40, 21, 0.5)
>>       y <- rnorm(40, -27, 0.5)
>>       ID <- rep(c("A","B"), each=20)
>>       Alt <- floor(rnorm(40, 900, 10))
>>       tvar <- 1:40
>>       tvarA <- sample(tvar,20)
>>       tvarB <- setdiff(tvar, tvarA)
>>
>>       DF <- data.frame(ID,x,y,Alt,tvar = c(tvarA,tvarB))
>>       DF <- DF[order(DF$ID,DF$tvar),]
>>
>>       library(googleVis)
>>       plot(gvisMotionChart(DF, idvar="ID", timevar= "tvar"))
>>
>>
>> An alternative along the lines of what I want would be  the
>> trajdyn{adehabitatLT}, even if it does not allow dynamic movements of more
>> than one individual at the time, which is unfortunate in my case.
>>
>> Any suggestion regarding alternative packages/functions is highly
>> appreciated.
>>
>> Thanks in advance,
>> Gabriele
>>
>>
>>
> --
>
> ~$ whoami
> Mathieu Basille
> http://ase-research.org/basille
>
> ~$ locate --details
> University of Florida \\
> Fort Lauderdale Research and Education Center
> (+1) 954-577-6314
>
> ~$ fortune
> ? Le tout est de tout dire, et je manque de mots
> Et je manque de temps, et je manque d'audace. ?
>  -- Paul ?luard
>
> --
>
> ~$ whoami
> Mathieu Basille
> http://ase-research.org/basille
>
> ~$ locate --details
> University of Florida \\
> Fort Lauderdale Research and Education Center
> (+1) 954-577-6314
>
> ~$ fortune
> ? Le tout est de tout dire, et je manque de mots
> Et je manque de temps, et je manque d'audace. ?
>  -- Paul ?luard
>
>


-- 
Gabriele Cozzi
Postdoctoral Research Associate
Population Ecology Research Group
http://www.popecol.org

Zurich University
Institute of Evolutionary Biology and Environmental Studies
Winterthurerstr. 190
8057 Zurich - Switzerland
E-mail: gabriele.cozzi at uzh.ch
Office: 34-J-38
Phone: +41(0)44 635 47 56
Fax: +41(0)16355711
http://www.ieu.uzh.ch

	[[alternative HTML version deleted]]


From agus.camacho at gmail.com  Mon Feb 23 20:17:13 2015
From: agus.camacho at gmail.com (Agus Camacho)
Date: Mon, 23 Feb 2015 16:17:13 -0300
Subject: [R-sig-Geo] Calculating alternative measures of model performance
 for species distribution models
Message-ID: <CALsJ7pT+Z4eUqHg4j46mAYhJNoYm45M3_vwkYp6Y9V8SQiMgWA@mail.gmail.com>

Dear all,

Im now struggling with the problem of demonstrating the performance of
species distribution models that I created (SDMs).

The area under the curve has been largely criticised:

http://onlinelibrary.wiley.com/doi/10.1111/j.1466-8238.2007.00358.x/full
http://www.riceanalytics.com/db3/00232/riceanalytics.com/_download/Is%20the%20AUC%20the%20Best%20Measure.pdf
http://www.mssanz.org.au/modsim09/J1/liu_c_J1b.pdf

And Robert has gently provided a workaround in R:
http://cran.r-project.org/web/packages/dismo/vignettes/sdm.pdf

Still, I'd like to compute a " straight classification error rate and
average squared error", as proposed by Rice, or then, the proportion of
explained deviance D2 or the , the coefficient of determination,as proposed
by Liu. However, I was not able to implement that in R.

Would anybody have a suggestion?

Here goes a reproducible example (it takes a little to run):

set.seed(64)
require(raster)
require(dismo)
x=data.frame(Longitude=rnorm(30,mean=-50,
s=3),Latitude=rnorm(30,mean=-10,s=3))

# calculate extent square for x
ext = extent( min(x$Longitude), max(x$Longitude), min(x$Latitude),
max(x$Latitude))

# dowload envir from here:
https://www.dropbox.com/s/3ctpfbij04kgcq7/LA.environment.grd?dl=0

envir = stack("C:/Users/Agus/Dropbox/Distributional range
size/rasters/LA.environment.grd")

# special division of presence and test data for removing spatial sorting
bias for calculation of AUC (Hijmans sdm in R 2014 and Hijmans 2012)
nr <- nrow(x)
s <- sample(nr, 0.25 * nr)
pres_train <- x[-s,]
pres_test <- x[s, ]

nr <- nrow(backgr)
s <- sample(nr, 0.25 * nr)

backgr <- randomPoints(envir, n=100)
back_train <- backgr[-s, ]
back_test <- backgr[s, ]
sb <- ssb(pres_test, back_test, pres_train)


xm <- maxent(envir,
            pres_train,
            factors=c(
"HWSD_ADD_PROP",
"HWSD_AWC_CLASS",
"HWSD_DRAINAGE",
"HWSD_T_CEC_CLAY",
"HWSD_T_CEC_SOIL",
#"HWSD_T_ECE",
"HWSD_T_ESP",
#"HWSD_T_OC",
"HWSD_T_PH_H2O",
"HWSD_T_TEXTURE",
"HWSD_T_USDA_TEX_CLASS"
                    ),
             removeDuplicates=TRUE)

# evaluate model
e = try(evaluate(pres_test, back_test, xm, envir),silent=T)


Thanks in advance.
-- 
Agust?n Camacho Guerrero.
Doutor em Zoologia.
Laborat?rio de Herpetologia, Departamento de Zoologia, Instituto de
Bioci?ncias, USP.
Rua do Mat?o, trav. 14, n? 321, Cidade Universit?ria,
S?o Paulo - SP, CEP: 05508-090, Brasil.

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Mon Feb 23 21:55:51 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 24 Feb 2015 09:55:51 +1300
Subject: [R-sig-Geo] spatstat predict rhohat question
In-Reply-To: <1424577981933-7587812.post@n2.nabble.com>
References: <1424577981933-7587812.post@n2.nabble.com>
Message-ID: <54EB93D7.9020507@auckland.ac.nz>



A follow-up to my previous post:  Adrian tells me that a revision of 
spatstat (version 1.41-0), which contains the fix to the 
predict.rhohat() problem, will *probably* be submitted to CRAN today.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
Home phone: +64-9-480-4619


From flaxman at gmail.com  Mon Feb 23 21:57:09 2015
From: flaxman at gmail.com (Seth Flaxman)
Date: Mon, 23 Feb 2015 15:57:09 -0500
Subject: [R-sig-Geo] nonseparable space/time covariance functions in an LGCP?
Message-ID: <CAPGk9pe7kZtb5=Q42a+UpQAY6eYHpwPgidF2UXM7S=v3AciUYA@mail.gmail.com>

Hi list.

I'm looking to fit a spatiotemporal log-Gaussian Cox Process (LGCP)
with a nonseparable covariance function. Before I do the
implementation from scratch (actually I'm thinking about using Stan),
does anyone know of a package or code in any language
(R/WinBugs/matlab/C++) that does something similar? I've looked at
INLA and Benjamin Taylor's lgcp package in R. I've also looked at GPML
and GPStuff. The latter two come the closest; I think for those I'd
just need to implement the nonseparable covariance.

And while I'm writing, I'm curious if there's some other model class /
method that comes to mind--the problem I'm tackling is one where I'm
specifically interested in comparing a model with a separable
covariance function (i.e. space and time decompose multiplicatively or
additively) to a model with a nonseparable covariance function, also
known as "space/time" interaction. I know about space/time interaction
tests like Knox and Mantel, and I know there are some tests (Fuentes
has one) for nonseparability, but I want something model based.

Thanks,
Seth


From mloranty at colgate.edu  Mon Feb 23 22:14:07 2015
From: mloranty at colgate.edu (Mike Loranty)
Date: Mon, 23 Feb 2015 16:14:07 -0500
Subject: [R-sig-Geo] pixel-wsie correlation between raster stack and numeric
	vector?
Message-ID: <CAFXTRemWcc+m3a-MJGvV-zzMY_Le7A4H9SNpDa-S_RPuQYJHug@mail.gmail.com>

Hi All,

Is there a way (e.g. existing function) to calculate correlation
coefficients between a raster stack and a numeric vector? For example,
between gridded vegetation indices and a vector of atmospheric oscillation
indices (e.g. ENSO, NAO, etc...).

Thanks,
Michael Loranty
Assistant Professor
Department of Geography
Colgate University
315.228.6057
mloranty at colgate.edu
http://mikeloranty.wordpress.com/

	[[alternative HTML version deleted]]


From tea3rd at gmail.com  Tue Feb 24 15:18:40 2015
From: tea3rd at gmail.com (Thomas Adams)
Date: Tue, 24 Feb 2015 09:18:40 -0500
Subject: [R-sig-Geo] pixel-wsie correlation between raster stack and
 numeric vector?
In-Reply-To: <CAFXTRemWcc+m3a-MJGvV-zzMY_Le7A4H9SNpDa-S_RPuQYJHug@mail.gmail.com>
References: <CAFXTRemWcc+m3a-MJGvV-zzMY_Le7A4H9SNpDa-S_RPuQYJHug@mail.gmail.com>
Message-ID: <CAGxgkWjeGCNKCBWH8nogG85vbGcQhsj2aU9wqHeZhYyktN_52Q@mail.gmail.com>

Michael,

I would combine the use of GRASS GIS and R (making use of spgrass7); first,
using the vector point locations:

(0) import raster and vector data into GRASS GIS
(1) use GRASS v.sample (http://grass.osgeo.org/grass70/manuals/v.sample.html)
to sample the raster data at the vector point locations
(2) launch R within the GRASS GIS session, load spgrass7 library
(3) within R (using spgrass7) read the both vector datasets (the original
vector data and new data from using v.sample) from GRASS
(4) do R statistical analyses

All this can be easily scripted for batch processing.

Tom

On Mon, Feb 23, 2015 at 4:14 PM, Mike Loranty <mloranty at colgate.edu> wrote:

> Hi All,
>
> Is there a way (e.g. existing function) to calculate correlation
> coefficients between a raster stack and a numeric vector? For example,
> between gridded vegetation indices and a vector of atmospheric oscillation
> indices (e.g. ENSO, NAO, etc...).
>
> Thanks,
> Michael Loranty
> Assistant Professor
> Department of Geography
> Colgate University
> 315.228.6057
> mloranty at colgate.edu
> http://mikeloranty.wordpress.com/
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From jwesroberts at gmail.com  Tue Feb 24 17:39:07 2015
From: jwesroberts at gmail.com (Wesley Roberts)
Date: Tue, 24 Feb 2015 18:39:07 +0200
Subject: [R-sig-Geo] Generate a multi-ring buffer - Windows 8 - R 3.1.1
Message-ID: <CAFik=FdreRG8tnU-JDOFM1ZeO3rHsXNzGtESffDh9DcDyDVPJw@mail.gmail.com>

Dear R-Sig_Geo,

I would like to create a multi ring buffer around a point. I have not been
able to find a built in application to do this. So far I have been using
gBuffer with increasing widths within a for loop. Each of the individual
buffers is then stored in a list. In the past, I have merged multiple
SpatialPolygonsDataFrame's by storing each one in a list and then calling
do.call with an rbind which has worked perfectly well. Now however I
receive the following error

Error in validObject(res) :
  invalid class ?SpatialPolygons? object: non-unique Polygons ID slot values


Here is some re-producible code to highlight my problem. Any help would be
greatly appreciated.

#########################################################################################################
library(rgeos)
p<-as.data.frame(matrix(741788.1,8294212,ncol=2,nrow=1))
names(p)<-c("X","Y")
coordinates(p) <- ~X+Y
projection(p)<-CRS("+proj=utm +zone=35 +south +datum=WGS84 +units=m
+no_defs")
buff.list<-list()
i=1
for (i in 1:18){
  x.1<-gBuffer(p,width=i*10)
  df<-as.data.frame(matrix(i,ncol=1,nrow=1))
  x.2<-SpatialPolygonsDataFrame(x.1, df, match.ID = FALSE)
  row.names(x.2 at data)<-i
  buff.list[i]<-x.2
  i=i+1
}
buff.out<-do.call(rbind,buff.list)
#########################################################################################################

Many thanks and kind regards,
Wesley

-- 
Wesley Roberts
jwesroberts at gmail.com
Cell: +27(0)83 5355 646
skype: roberts-w

I hear...I forget
I see...and I remember
I do...and I understand
Ancient Chinese Proverb

	[[alternative HTML version deleted]]


From damianmaddalena at gmail.com  Tue Feb 24 18:19:54 2015
From: damianmaddalena at gmail.com (Damian Maddalena)
Date: Tue, 24 Feb 2015 12:19:54 -0500
Subject: [R-sig-Geo] Creating a data frame from a set of rasters that
 includes XY values as columns
Message-ID: <54ECB2BA.3060101@gmail.com>

Hello.

I am trying to create a data frame from a series of rasters that 
includes a column for each raster and a column for the corresponding XY 
values. IE: I want each row to be the cell values at every XY location.

For example, if I pull down the worldclim bioclim data (below), I would 
like to unpack one or more rasters from the raster stack and assemble 
them as a data frame with X and Y as an attribute. IE: I want a data 
frame where each record is a cell, and the attributes are X,Y,Z1...Zx.

 > library(raster)
 > d <- getData('worldclim', var='bio', res=10)

I have done this in GRASS with all data imported but I would like to try 
to do it in R in the most succinct way possible. I am getting tripped up 
on the structure of the raster stack.

Any hints on how to proceed would be appreciated. Should I just pull out 
the raster values, turn them into a vector, slap them into a data frame, 
then append the range for the XY? Would that line up correctly?

Thank you.

-Damian

-- 
?Science knows it doesn't know everything; otherwise, it'd stop. But just because science doesn't know everything doesn't mean you can fill in the gaps with whatever fairy tale most appeals to you.? ~Dara ? Briain


From edzer.pebesma at uni-muenster.de  Tue Feb 24 19:26:34 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 24 Feb 2015 19:26:34 +0100
Subject: [R-sig-Geo] Creating a data frame from a set of rasters that
 includes XY values as columns
In-Reply-To: <54ECB2BA.3060101@gmail.com>
References: <54ECB2BA.3060101@gmail.com>
Message-ID: <54ECC25A.5010902@uni-muenster.de>



On 02/24/2015 06:19 PM, Damian Maddalena wrote:
> Hello.
> 
> I am trying to create a data frame from a series of rasters that
> includes a column for each raster and a column for the corresponding XY
> values. IE: I want each row to be the cell values at every XY location.
> 
> For example, if I pull down the worldclim bioclim data (below), I would
> like to unpack one or more rasters from the raster stack and assemble
> them as a data frame with X and Y as an attribute. IE: I want a data
> frame where each record is a cell, and the attributes are X,Y,Z1...Zx.
> 
>> library(raster)
>> d <- getData('worldclim', var='bio', res=10)
> 
> I have done this in GRASS with all data imported but I would like to try
> to do it in R in the most succinct way possible. I am getting tripped up
> on the structure of the raster stack.
> 
> Any hints on how to proceed would be appreciated. Should I just pull out
> the raster values, turn them into a vector, slap them into a data frame,
> then append the range for the XY? Would that line up correctly?
> 

Yes, or even simpler:

> as(as(d, "SpatialPointsDataFrame"), "data.frame")[1:5,]
  bio1 bio2 bio3  bio4 bio5 bio6 bio7 bio8 bio9 bio10 bio11 bio12
1 -174   67   17 11862   37 -356  393  -31 -307    -7  -307   144
2 -174   67   17 11870   37 -355  392  -30 -219    -7  -307   143
3 -172   68   17 11872   39 -354  393  -29 -217    -5  -305   136
4 -173   68   17 11887   39 -354  393  -29 -217    -5  -306   136
5 -173   68   17 11877   39 -354  393  -29 -217    -6  -306   136
  bio13 bio14 bio15 bio16 bio17 bio18 bio19         x        y
1    22     7    38    59    24    50    24 -37.91667 83.58333
2    22     7    42    59    23    50    24 -37.75000 83.58333
3    22     6    42    57    22    49    23 -36.91667 83.58333
4    22     6    42    57    22    49    23 -36.75000 83.58333
5    22     6    42    57    22    49    23 -36.58333 83.58333

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150224/3dc3facc/attachment.bin>

From vitale232 at gmail.com  Tue Feb 24 19:28:05 2015
From: vitale232 at gmail.com (Andrew Vitale)
Date: Tue, 24 Feb 2015 10:28:05 -0800
Subject: [R-sig-Geo] Creating a data frame from a set of rasters that
 includes XY values as columns
In-Reply-To: <54ECB2BA.3060101@gmail.com>
References: <54ECB2BA.3060101@gmail.com>
Message-ID: <CAFTcopeaLAaauzgPvTNXKge-LXO8yf=nGPChhc4gp7_q5bx=dg@mail.gmail.com>

Something like this should do the trick, depending on the size of the
raster stack and the computing environment of course:

library(raster)

fn <- system.file("external/test.grd", package="raster")
s <- stack(fn, fn)
r <- raster(fn)
s <- stack(r, fn)

dfs <- as.data.frame(s, xy=TRUE)


checkout ?raster:::as.data.frame for more options

-Andrew

On Tue, Feb 24, 2015 at 9:19 AM, Damian Maddalena <damianmaddalena at gmail.com
> wrote:

> Hello.
>
> I am trying to create a data frame from a series of rasters that includes
> a column for each raster and a column for the corresponding XY values. IE:
> I want each row to be the cell values at every XY location.
>
> For example, if I pull down the worldclim bioclim data (below), I would
> like to unpack one or more rasters from the raster stack and assemble them
> as a data frame with X and Y as an attribute. IE: I want a data frame where
> each record is a cell, and the attributes are X,Y,Z1...Zx.
>
> > library(raster)
> > d <- getData('worldclim', var='bio', res=10)
>
> I have done this in GRASS with all data imported but I would like to try
> to do it in R in the most succinct way possible. I am getting tripped up on
> the structure of the raster stack.
>
> Any hints on how to proceed would be appreciated. Should I just pull out
> the raster values, turn them into a vector, slap them into a data frame,
> then append the range for the XY? Would that line up correctly?
>
> Thank you.
>
> -Damian
>
> --
> ?Science knows it doesn't know everything; otherwise, it'd stop. But just
> because science doesn't know everything doesn't mean you can fill in the
> gaps with whatever fairy tale most appeals to you.? ~Dara ? Briain
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
*Andrew P. Vitale*
Masters Student
Department of Geography
University of Nevada, Reno
vitale232 at gmail.com

	[[alternative HTML version deleted]]


From gosz at gmx.de  Tue Feb 24 19:41:48 2015
From: gosz at gmx.de (Guido Schulz)
Date: Tue, 24 Feb 2015 19:41:48 +0100
Subject: [R-sig-Geo] Modeling SAR Origin-Destination flows with R?
Message-ID: <54ECC5EC.1060709@gmx.de>

Hi there,

I would like to model SAR Origin-Destination (migration) flows using the
model specification proposed by LeSage & Pace
(http://www4.fe.uc.pt/spatial/doc/lecture7.pdf, page8, equation [10]):

y = rho1*W_o*y + rho2*W_d*y + rho3*W_w*y + alpha*iota + X_d*beta_d +
X_o*beta_o + D*gamma + epsilon

Where "o" stands for origin and "d" for destination.

What is crucial about the model is, that we have the spatially lagged
responses of the origin AND the destination, as well as the spatially
lagged predictors of the origin AND the destination in the SAR equation.
-----------------------------------------
Do you have any ideas how to implement such a model in R?

Is there a way to specify a spdep::lagsarlm in that way or should I use
a different package/function? As far as I can see there spdep::lagsarlm
allows only for ONE "listw".

Best & thx,

Guido


From Sascha.Georgy at gmx.de  Tue Feb 24 21:29:24 2015
From: Sascha.Georgy at gmx.de (Sascha)
Date: Tue, 24 Feb 2015 13:29:24 -0700 (MST)
Subject: [R-sig-Geo] How can I set an xts Attribut to STFDF?
Message-ID: <1424809764492-7587827.post@n2.nabble.com>

Hello,

I'm using spacetime in R. This is my STFDF: PM10.02:

str(PM10.02)
Formal class 'STFDF' [package "spacetime"] with 4 slots
  ..@ data   :'data.frame':	129210 obs. of  1 variable:
  .. ..$ values: num [1:129210] NA 18 21 26 36 17 14 15 20 NA ...
  ..@ sp     :Formal class 'SpatialPointsDataFrame' [package "sp"] with 5
slots
  .. .. ..@ data       :'data.frame':	354 obs. of  4 variables:
  .. .. .. ..$ names: Factor w/ 354 levels "DEBB001","DEBB006",..: 1 2 3 4 5
6 7 8 9 10 ...
  .. .. .. ..$ code : Factor w/ 354 levels "DEBB001","DEBB006",..: 1 2 3 4 5
6 7 8 9 10 ...
  .. .. .. ..$ name : Factor w/ 354 levels "\x8a\xbehringen",..: 58 67 94
251 289 292 343 285 253 153 ...
  .. .. .. ..$ area : Factor w/ 3 levels "rural","suburban",..: 2 3 2 3 3 2
2 2 2 2 ...
  .. .. ..@ coords.nrs : int [1:2] 5 6
  .. .. ..@ coords     : num [1:354, 1:2] 14.1 14.3 14.6 13.1 14 ...
  .. .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. .. ..$ : NULL
  .. .. .. .. ..$ : chr [1:2] "x" "y"
  .. .. ..@ bbox       : num [1:2, 1:2] 6.38 47.55 14.99 54.92
  .. .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. .. ..$ : chr [1:2] "x" "y"
  .. .. .. .. ..$ : chr [1:2] "min" "max"
  .. .. ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
  .. .. .. .. ..@ projargs: chr "+proj=longlat +datum=WGS84 +ellps=WGS84
+towgs84=0,0,0"
  ..@ time   :An ?xts? object on 2002-01-01/2002-12-31 containing:
  Data: int [1:365, 1] 1 2 3 4 5 6 7 8 9 10 ...
  Indexed by objects of class: [POSIXct,POSIXt] TZ: 
 xts Attributes:  
 NULL
  ..@ endTime: POSIXct[1:365], format: "2002-01-02 13:00:00" "2002-01-03
13:00:00" ?

How can I set the   xts Attributes:  ????

I think this Attribut is necessary for plotting acf in days (e.g.
Pebesma/Gr?ler (2014: 4) Spatio-temporal geostatistics using gstat  
). When I plot 4 stations, time-lag is shown as 10000 steps. 

Here the strukture from the rural - STFDF (package spacetime): 

str(rural)
Formal class 'STFDF' [package "spacetime"] with 4 slots
  ..@ data   :'data.frame':	306810 obs. of  1 variable:
  .. ..$ PM10: num [1:306810] NA NA NA NA NA NA NA NA NA NA ...
  ..@ sp     :Formal class 'SpatialPoints' [package "sp"] with 3 slots
  .. .. ..@ coords     : num [1:70, 1:2] 9.59 9.69 9.79 13.65 13.3 ...
  .. .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. .. ..$ : chr [1:70] "DESH001" "DENI063" "DEUB038" "DEBE056" ...
  .. .. .. .. ..$ : chr [1:2] "coords.x1" "coords.x2"
  .. .. ..@ bbox       : num [1:2, 1:2] 6.28 47.81 14.79 54.92
  .. .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. .. ..$ : chr [1:2] "coords.x1" "coords.x2"
  .. .. .. .. ..$ : chr [1:2] "min" "max"
  .. .. ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
  .. .. .. .. ..@ projargs: chr "+init=epsg:4326 +proj=longlat +ellps=WGS84
+datum=WGS84 +no_defs +towgs84=0,0,0"
  ..@ time   :An ?xts? object on 1997-12-31/2009-12-30 containing:
  Data: int [1:4383, 1] 1 2 3 4 5 6 7 8 9 10 ...
  Indexed by objects of class: [Date] TZ: 
  xts Attributes:  
List of 1
  .. ..$ timeIsInterval: logi TRUE
  ..@ endTime: POSIXct[1:4383], format: "1998-01-01 01:00:00" "1998-01-02
01:00:00" ...

In this form plotting is possible. 

Thanks in advance
Sascha




--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/How-can-I-set-an-xts-Attribut-to-STFDF-tp7587827.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From r.hijmans at gmail.com  Wed Feb 25 05:32:21 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 24 Feb 2015 20:32:21 -0800
Subject: [R-sig-Geo] pixel-wsie correlation between raster stack and
 numeric vector?
In-Reply-To: <CAFXTRemWcc+m3a-MJGvV-zzMY_Le7A4H9SNpDa-S_RPuQYJHug@mail.gmail.com>
References: <CAFXTRemWcc+m3a-MJGvV-zzMY_Le7A4H9SNpDa-S_RPuQYJHug@mail.gmail.com>
Message-ID: <CANtt_hyMaUym_Bm09nkz=VpC=VgZZGb5CEUwoU+mEmA+bN176Q@mail.gmail.com>

MIke, I think you can use the 'calc' function for that:

library(raster)
# example data
set.seed(0)
s <- stack(system.file("external/rlogo.grd", package="raster"))
s <- stack(s, s[[1]]*runif(ncell(s)), s[[2]]*runif(ncell(s))/10,
s[[3]]*runif(ncell(s))+10)

# example vector
v <- 1:6

x <- calc(s, fun=function(x) cor(x, v))
plot(x)

Robert


On Mon, Feb 23, 2015 at 1:14 PM, Mike Loranty <mloranty at colgate.edu> wrote:
> Hi All,
>
> Is there a way (e.g. existing function) to calculate correlation
> coefficients between a raster stack and a numeric vector? For example,
> between gridded vegetation indices and a vector of atmospheric oscillation
> indices (e.g. ENSO, NAO, etc...).
>
> Thanks,
> Michael Loranty
> Assistant Professor
> Department of Geography
> Colgate University
> 315.228.6057
> mloranty at colgate.edu
> http://mikeloranty.wordpress.com/
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From jwesroberts at gmail.com  Wed Feb 25 07:35:42 2015
From: jwesroberts at gmail.com (Wesley Roberts)
Date: Wed, 25 Feb 2015 08:35:42 +0200
Subject: [R-sig-Geo] Generate a multi-ring buffer - Windows 8 - R 3.1.1
In-Reply-To: <CANtt_hwAaW41Gi6hgSzbURYxuhPFEta4WkhCdGqwr5XDbKUWVQ@mail.gmail.com>
References: <CAFik=FdreRG8tnU-JDOFM1ZeO3rHsXNzGtESffDh9DcDyDVPJw@mail.gmail.com>
	<CANtt_hwAaW41Gi6hgSzbURYxuhPFEta4WkhCdGqwr5XDbKUWVQ@mail.gmail.com>
Message-ID: <CAFik=FeZ2Fr+YHeLpZYzUXtUYVVni=QTKYBDS8KVEak1dR0n2A@mail.gmail.com>

Many thanks Robert,

Your suggestions worked a treat.


Wesley

On Wed, Feb 25, 2015 at 6:37 AM, Robert J. Hijmans <r.hijmans at gmail.com>
wrote:

> Wesley,
>
> Your code should work if you change:
>
>   row.names(x.2 at data)<-i
> to
>   row.names(x.2) <- as.character(i)
>
>
> Alternatively you can use raster::bind
> library(raster)
> buff.out <- do.call(bind, buff.list)
>
> Which also allows you to use a much simplified loop:
>
> buff.list <- list()
> for (i in 1:18) {
>     buff.list[i] <- gBuffer(p,width=i*10)
> }
> buff.out <- do.call(bind,buff.list)
>
>
> Robert
>
> On Tue, Feb 24, 2015 at 8:39 AM, Wesley Roberts <jwesroberts at gmail.com>
> wrote:
> > Dear R-Sig_Geo,
> >
> > I would like to create a multi ring buffer around a point. I have not
> been
> > able to find a built in application to do this. So far I have been using
> > gBuffer with increasing widths within a for loop. Each of the individual
> > buffers is then stored in a list. In the past, I have merged multiple
> > SpatialPolygonsDataFrame's by storing each one in a list and then calling
> > do.call with an rbind which has worked perfectly well. Now however I
> > receive the following error
> >
> > Error in validObject(res) :
> >   invalid class ?SpatialPolygons? object: non-unique Polygons ID slot
> values
> >
> >
> > Here is some re-producible code to highlight my problem. Any help would
> be
> > greatly appreciated.
> >
> >
> #########################################################################################################
> > library(rgeos)
> > p<-as.data.frame(matrix(741788.1,8294212,ncol=2,nrow=1))
> > names(p)<-c("X","Y")
> > coordinates(p) <- ~X+Y
> > projection(p)<-CRS("+proj=utm +zone=35 +south +datum=WGS84 +units=m
> > +no_defs")
> > buff.list<-list()
> > i=1
> > for (i in 1:18){
> >   x.1<-gBuffer(p,width=i*10)
> >   df<-as.data.frame(matrix(i,ncol=1,nrow=1))
> >   x.2<-SpatialPolygonsDataFrame(x.1, df, match.ID = FALSE)
> >   row.names(x.2 at data)<-i
> >   buff.list[i]<-x.2
> >   i=i+1
> > }
> > buff.out<-do.call(rbind,buff.list)
> >
> #########################################################################################################
> >
> > Many thanks and kind regards,
> > Wesley
> >
> > --
> > Wesley Roberts
> > jwesroberts at gmail.com
> > Cell: +27(0)83 5355 646
> > skype: roberts-w
> >
> > I hear...I forget
> > I see...and I remember
> > I do...and I understand
> > Ancient Chinese Proverb
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Dr Wesley Roberts
jwesroberts at gmail.com
Cell: +27(0)83 5355 646
skype: roberts-w

I hear...I forget
I see...and I remember
I do...and I understand
Ancient Chinese Proverb

	[[alternative HTML version deleted]]


From dave.gregovich at alaska.gov  Wed Feb 25 22:50:20 2015
From: dave.gregovich at alaska.gov (Gregovich, Dave P (DFG))
Date: Wed, 25 Feb 2015 21:50:20 +0000
Subject: [R-sig-Geo] Replacing values in large rasters using conditional
	statements
Message-ID: <174524AB15B8E6478D6F927B2131B09B7BB95BF6@SOAJNUEXMB3.soa.alaska.gov>


Hello,
I often replace values in a raster based on values of another raster, like this:

n.row <- n.col <- 100
a <-raster(nrows=n.row,ncols=n.col)
b <- a
a[]<-rnorm(ncell(a))
b[]<-rnorm(ncell(b))
a[b > 0] <- 1

What would analogous code be that works for large rasters without running into vector size allocation problems?

Thanks kindly for any time you spend!

Dave.
__________________________________
Dave Gregovich
Research Analyst
Alaska Department of Fish and Game
Wildlife Conservation Division
Douglas, AK 99821
(907) 465-4291
dave.gregovich at alaska.gov
__________________________________


	[[alternative HTML version deleted]]


From Dominik.Schneider at colorado.edu  Thu Feb 26 05:00:40 2015
From: Dominik.Schneider at colorado.edu (dschneiderch)
Date: Wed, 25 Feb 2015 21:00:40 -0700 (MST)
Subject: [R-sig-Geo] stack many files without loading into memory
In-Reply-To: <1423254616364-7587748.post@n2.nabble.com>
References: <CAHYDKLY3GBbCk8dNw0Jpp0xy-vxAxdbhZdEjSqv339W2Yfmj9Q@mail.gmail.com>
	<CAAcGz99tz-Dw4=KLX1zRYupXRv5++ObTeL8n3HGSfSJia3HOzQ@mail.gmail.com>
	<CAHYDKLZD8wm0_ZJZin9EtcjEZW3EQ8R_qGosnGdOducKMqGw9g@mail.gmail.com>
	<CAHYDKLbEVfxYLzeHBJAbRUQxx+RwYCYtGfNoz4o6s2HP0Yc48A@mail.gmail.com>
	<CAAcGz99D1K8_+y7=exw7Pv5NqaCsfDA6Aa2N5uvEfvtKZENpqw@mail.gmail.com>
	<1423244548009-7587745.post@n2.nabble.com>
	<1423254616364-7587748.post@n2.nabble.com>
Message-ID: <CAHYDKLYiLaoMyQL9TmNGk0XyNNcYQ=cE9esHiGLmOSBy6s1ytA@mail.gmail.com>

Just wanted to update this thread in case anyone else comes looking. Some
of these things were not immediately clear to me.
I ended up doing:
library(raster)
library(ncdf4)
fn=list.files('serverpath')
fnstack=stack(fn)
layerdates=names(fnstack)
#instead of writeRaster, use ncdf4 directly to get around the issue in this
thread
<http://r-sig-geo.2731867.n2.nabble.com/writeRaster-does-not-preserve-names-when-writing-to-NetCDF-td7586909.html>
.
dim1=ncdim_def('Long','degree',seq(-112.25,-104.125,0.00416666667))
dim2=ncdim_def('Lat','degree',seq(43.75,33,-0.00416666667))
dim3=ncdim_def('time','yrdoy',unlim=T,vals=layerdates)#where layerdates is
a vector something like 20120101, 20120109,...etc since thats what my files
were called.
var=ncvar_def('swe','meters',dim=list(dim1,dim2,dim3),missval=-99,longname='snow
water equivalent',compression=9)
#important to note, dim1 is the x direction and should be ascending. dim2
is the y direction and should be descending. this is because the cell
numbers from a raster* object start top-left and count by row.
outputfn='localpath'
newnc=nc_create(outputfn,var)
ncvar_put(newnc, var, vals=getValues(fnstack))
ncatt_put(ncnew,0,'proj4string','+proj=longlat +datum=WGS84')#add a global
attribute defining the geographic information.
nc_close(newnc)

Then when I open the file:
ncnew=nc_open(outputfn)
ncnew$dim[[3]]$vals  #this will give the list of dates stored above in
dim3. you can get the spatial coordinates likewise in dim[[1]] and
dim[[2]]  (or ncnew$dim$Lat$vals etc.)
lyr=grep('20120109',ncnew$dim[[3]]$vals) #use grep to find the date again
ncvar_get(ncnew,start=c(1,1,lyr),count=c(-1,-1,1))#get the raster I stored
for that date.
nc_close(outputfn)

Hope that helps someone!

Dominik Schneider
o 303.735.6296 | c 518.956.3978


On Fri, Feb 6, 2015 at 1:30 PM, dschneiderch [via R-sig-geo] <
ml-node+s2731867n7587748h90 at n2.nabble.com> wrote:

> Ok -  Looks like it worked this time for 112 files from 2012. The netcdf
> is 2.25 GB while the compressed multiband geotiff is 510MB. Does the netcdf
> have so much overhead- the 112 file at 10MB each are only 1.12 GB
> individually?
> I like the tidiness of 1 file per year so I'll have to play with how
> easily these can be accessed and the best way of annotating the layers. I
> was just reading that netcdf4 is based on hdf5 with a subset of features so
> I might look to see if hdf5 can do what I want.
> Thanks
> ds
>
> ------------------------------
>  If you reply to this email, your message will be added to the discussion
> below:
>
> http://r-sig-geo.2731867.n2.nabble.com/stack-many-files-without-loading-into-memory-tp7587729p7587748.html
>  To unsubscribe from stack many files without loading into memory, click
> here
> <http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=7587729&code=RG9taW5pay5TY2huZWlkZXJAY29sb3JhZG8uZWR1fDc1ODc3Mjl8LTEwMzMyMTA1OQ==>
> .
> NAML
> <http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>




--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/stack-many-files-without-loading-into-memory-tp7587729p7587831.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From yuster0 at gmail.com  Thu Feb 26 07:35:58 2015
From: yuster0 at gmail.com (Yuster Ronoh)
Date: Thu, 26 Feb 2015 09:35:58 +0300
Subject: [R-sig-Geo] Same code line for graph with different output messages
Message-ID: <CAP6hh3_d6FeOok_PK=sH0KnnH5jGXPwxko4Th6Co55WczfepeA@mail.gmail.com>

Dear r-geo members
Iam using example from creating maps with R by Robin Lovelace example  and
 I tried to plot map of active sport participant using the two codes, line
one gave me the error messages and line two gave me plot of active sport
partcipation in londe
1.plot(lnd_sport[lnd_sport$Partic_per > 25, ])
2.plot(lnd_sport[lnd_sport$Partic_Per > 25, ])
R-output
code for line 1
 > plot(lnd_sport[lnd_sport$Partic_per > 25, ])
Error in plot(lnd_sport[lnd_sport$Partic_per > 25, ]) :
  error in evaluating the argument 'x' in selecting a method for function
'plot': Error in if (is.numeric(i) && i < 0) { :
  missing value where TRUE/FALSE needed
code for line 2
 > plot(lnd_sport[lnd_sport$Partic_Per > 25, ]) # plotted actual graph
could some one explain what is happening

	[[alternative HTML version deleted]]


From frtog at vestas.com  Thu Feb 26 09:16:29 2015
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Thu, 26 Feb 2015 09:16:29 +0100
Subject: [R-sig-Geo] Same code line for graph with different output
 messages
In-Reply-To: <CAP6hh3_d6FeOok_PK=sH0KnnH5jGXPwxko4Th6Co55WczfepeA@mail.gmail.com>
References: <CAP6hh3_d6FeOok_PK=sH0KnnH5jGXPwxko4Th6Co55WczfepeA@mail.gmail.com>
Message-ID: <B078CDF40DFE4045AF172A8B4F68FC48587FAE811E@DKRDSEXC016.vestas.net>

Hi Yuster

The problem is about understanding basic R. 

The R parser is case sensitive, so the column name Partic_per is different from the name Partic_Per. The latter is a column name in the data frame Ind_sport whereas the former is not a column in that data frame. So basically lnd_sport$Partic_per is parsed to NULL and this gives the error message you see from R when trying to do the indexing lnd_sport[lnd_sport$Partic_per > 25, ].

Yours sincerely / Med venlig hilsen


Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 


> -----Original Message-----
> From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of
> Yuster Ronoh
> Sent: 26. februar 2015 07:36
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] Same code line for graph with different output
> messages
> 
> Dear r-geo members
> Iam using example from creating maps with R by Robin Lovelace example
> and
>  I tried to plot map of active sport participant using the two codes, line
> one gave me the error messages and line two gave me plot of active sport
> partcipation in londe
> 1.plot(lnd_sport[lnd_sport$Partic_per > 25, ])
> 2.plot(lnd_sport[lnd_sport$Partic_Per > 25, ])
> R-output
> code for line 1
>  > plot(lnd_sport[lnd_sport$Partic_per > 25, ])
> Error in plot(lnd_sport[lnd_sport$Partic_per > 25, ]) :
>   error in evaluating the argument 'x' in selecting a method for function
> 'plot': Error in if (is.numeric(i) && i < 0) { :
>   missing value where TRUE/FALSE needed
> code for line 2
>  > plot(lnd_sport[lnd_sport$Partic_Per > 25, ]) # plotted actual graph
> could some one explain what is happening
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From mathieu.rajerison at gmail.com  Thu Feb 26 14:24:59 2015
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Thu, 26 Feb 2015 14:24:59 +0100
Subject: [R-sig-Geo] Generate N points along a SpatialLines object
Message-ID: <CAGfc75ka_9Qy+dzAdCZkYvLtuZN6xXn_9qR8Ay-OtU=qEem=mg@mail.gmail.com>

Hi List,


I try to generate N points along a a continental coastline with
spatstat::pointsOnLines

If I give a small number of points (like N = 10), then 931 points are
returned. That's because 931 segments are generated from my initial
coastline data.

I'd like to know how to generate exactly N points, equally spaced, from a
SpatialLines object, without GRASS, nor QGIS


Thanks in advance for any answer,

Mathieu

	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Thu Feb 26 14:40:15 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 26 Feb 2015 14:40:15 +0100
Subject: [R-sig-Geo] Generate N points along a SpatialLines object
In-Reply-To: <CAGfc75ka_9Qy+dzAdCZkYvLtuZN6xXn_9qR8Ay-OtU=qEem=mg@mail.gmail.com>
References: <CAGfc75ka_9Qy+dzAdCZkYvLtuZN6xXn_9qR8Ay-OtU=qEem=mg@mail.gmail.com>
Message-ID: <54EF223F.9030004@uni-muenster.de>

Mathieu, sp::spsample samples SpatialLines objects, and has an argument
type = "regular".

On 02/26/2015 02:24 PM, Mathieu Rajerison wrote:
> Hi List,
> 
> 
> I try to generate N points along a a continental coastline with
> spatstat::pointsOnLines
> 
> If I give a small number of points (like N = 10), then 931 points are
> returned. That's because 931 segments are generated from my initial
> coastline data.
> 
> I'd like to know how to generate exactly N points, equally spaced, from a
> SpatialLines object, without GRASS, nor QGIS
> 
> 
> Thanks in advance for any answer,
> 
> Mathieu
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150226/468df075/attachment.bin>

From p.woods at qub.ac.uk  Thu Feb 26 14:50:20 2015
From: p.woods at qub.ac.uk (Paul Woods)
Date: Thu, 26 Feb 2015 13:50:20 +0000
Subject: [R-sig-Geo] Integrating a trajectory
Message-ID: <0EEB7287-F598-456F-930F-61F0A64FA1A5@qub.ac.uk>

Hi everyone,

Perhaps this is a little removed from strict geography, but you seem to be a clever bunch.

I?m looking for a method in R or Python to integrate along a trajectory, through a regular grid. So, imagine an aeroplane flying from London to New York? I want to calculate how much material in the atmosphere the aeroplane comes into contact with. I have a regular grid with the density of the atmosphere at each lon, lat, altitude grid point, but of course the plane does not travel along grid lines, so some interpolation would be needed. Any ideas on where to start in calculating how much atmosphere a plane would scoop up from London to New York?

Thanks,

Paul.

From macqueen1 at llnl.gov  Thu Feb 26 17:26:17 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 26 Feb 2015 16:26:17 +0000
Subject: [R-sig-Geo] Integrating a trajectory
Message-ID: <D1148613.120829%macqueen1@llnl.gov>

In two dimensions, interp() from the akima package would be a good
starting point. You might have to first generate a set of suitably spaced
lon,lat coordinates along the trajectory, depending on how the trajectory
is stored.

In the absence of something already existing for your 3d situation, I
suppose it could be done by first interpolating in 2d at altitudes above
and below the trajectory, then doing vertical interpolation between them.
I doubt that would be the most accurate interpolation, but it might be
good enough.

If you go to CRAN task view "CRAN Task View: Handling and Analyzing
Spatio-Temporal Data", there is a whole section "Moving objects,
Trajectories".

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 2/26/15, 5:50 AM, "Paul Woods" <p.woods at qub.ac.uk> wrote:

>Hi everyone,
>
>Perhaps this is a little removed from strict geography, but you seem to
>be a clever bunch.
>
>I?m looking for a method in R or Python to integrate along a trajectory,
>through a regular grid. So, imagine an aeroplane flying from London to
>New York? I want to calculate how much material in the atmosphere the
>aeroplane comes into contact with. I have a regular grid with the density
>of the atmosphere at each lon, lat, altitude grid point, but of course
>the plane does not travel along grid lines, so some interpolation would
>be needed. Any ideas on where to start in calculating how much atmosphere
>a plane would scoop up from London to New York?
>
>Thanks,
>
>Paul.
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at r-project.org
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From edzer.pebesma at uni-muenster.de  Thu Feb 26 17:55:44 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 26 Feb 2015 17:55:44 +0100
Subject: [R-sig-Geo] Integrating a trajectory
In-Reply-To: <D1148613.120829%macqueen1@llnl.gov>
References: <D1148613.120829%macqueen1@llnl.gov>
Message-ID: <54EF5010.4070909@uni-muenster.de>



On 02/26/2015 05:26 PM, MacQueen, Don wrote:
> If you go to CRAN task view "CRAN Task View: Handling and Analyzing
> Spatio-Temporal Data", there is a whole section "Moving objects,
> Trajectories".

Following up: for your problem, does the temporal aspect matter, or are
you interested in an integral along a line, i.e. is the problem purely
spatial? Is your grid three-dimensional? Is it a grid in latitude/longitude?
-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20150226/501d467e/attachment.bin>

From p.woods at qub.ac.uk  Thu Feb 26 18:41:30 2015
From: p.woods at qub.ac.uk (Paul Woods)
Date: Thu, 26 Feb 2015 17:41:30 +0000
Subject: [R-sig-Geo] Integrating a trajectory
In-Reply-To: <54EF5010.4070909@uni-muenster.de>
References: <D1148613.120829%macqueen1@llnl.gov>,
	<54EF5010.4070909@uni-muenster.de>
Message-ID: <10A69099-AAFF-4677-B48F-7857F53F08A7@qub.ac.uk>

Edzer,

Yes, time does matter, but I think in the initial stages I will consider a steady state. The grid is 3 dimensional, but for simplicity could be represented as a Cartesian grid. 

Thanks for the suggestion, Don. 


> On 26 Feb 2015, at 16:56, Edzer Pebesma <edzer.pebesma at uni-muenster.de> wrote:
> 
> 
> 
>> On 02/26/2015 05:26 PM, MacQueen, Don wrote:
>> If you go to CRAN task view "CRAN Task View: Handling and Analyzing
>> Spatio-Temporal Data", there is a whole section "Moving objects,
>> Trajectories".
> 
> Following up: for your problem, does the temporal aspect matter, or are
> you interested in an integral along a line, i.e. is the problem purely
> spatial? Is your grid three-dimensional? Is it a grid in latitude/longitude?
> -- 
> Edzer Pebesma
> Institute for Geoinformatics (ifgi),  University of M?nster,
> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> Journal of Statistical Software:   http://www.jstatsoft.org/
> Computers & Geosciences:   http://elsevier.com/locate/cageo/
> Spatial Statistics Society http://www.spatialstatistics.info
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From dave.gregovich at alaska.gov  Thu Feb 26 19:16:31 2015
From: dave.gregovich at alaska.gov (Gregovich, Dave P (DFG))
Date: Thu, 26 Feb 2015 18:16:31 +0000
Subject: [R-sig-Geo] Replacing values in large rasters using conditional
	statements
Message-ID: <174524AB15B8E6478D6F927B2131B09B7BB95CCD@SOAJNUEXMB3.soa.alaska.gov>

Well, This may be somewhat remedial for some, but it is a voyage of discovery for me:

It appears that using the 'overlay' function is the analogous method I was looking for. I am not absolutely positive it works for *very* large rasters.
But it does seem to work with the 5 X 10^8-cell rasters I am currently working with:


>Hello,

>I often replace values in a raster based on values of another raster, like this:



>n.row <- n.col <- 100

>a <-raster(nrows=n.row,ncols=n.col)

>b <- a

>a[]<-rnorm(ncell(a))

>b[]<-rnorm(ncell(b))

>a[b > 0] <- 1



>What would analogous code be that works for large rasters without running into vector size allocation problems?

#First method as illustrated above.
n.row <- n.col <- 1000
a <-raster(nrows=n.row,ncols=n.col)
b <- a
a[]<-rnorm(ncell(a))
b[]<-rnorm(ncell(b))
out.1 <- a
out.1[b > 0] <- 1

#second method using 'overlay'...
out.2 <- overlay(a,b,fun=function(x,y){
                                                z <- x
                                                z[y > 0] <- 1
                                                return(z)
                                })

#check the two methods are identical
all(getValues(out.1) == getValues(out.2))

My initial indications are that 'overlay' is working really well with large, stored-on-disk rasters, and doesn't seem *too* slow
I hope this is helpful to some of you.

Thanks kindly.

__________________________________
Dave Gregovich
Research Analyst
Alaska Department of Fish and Game
Wildlife Conservation Division
Douglas, AK 99821
(907) 465-4291
dave.gregovich at alaska.gov
__________________________________


	[[alternative HTML version deleted]]


From zilefacelvis at yahoo.com  Thu Feb 26 22:43:49 2015
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Thu, 26 Feb 2015 21:43:49 +0000 (UTC)
Subject: [R-sig-Geo] Visualize negative/poitive data using levelplot in R
Message-ID: <1474553176.1188027.1424987029645.JavaMail.yahoo@mail.yahoo.com>

Hello,
I need your insigts on how to visualize/map data that spans negative and positive values. I have 6 rasters which have been stacked together (s) and will subsequently be plotted via?levelplotfunction in R. Below are the?max?and?min?values for each?raster.39.2887, 53.09207  (min, max) # r1

-32.4956, -27.25534  (min, max)# r2

-14.37683, -11.37742  (min, max)# r3

 9.512934, 13.60197  (min, max)# r4

-4.993901, -1.851784  (min, max)# r5

-8.190711, -5.104764  (min, max)# r6At the moment, I am able to produce my map via:library(raster)
library(rasterVis)
library(colorRamp)
    s <- stack(r1,r2,r3,r4,r5,r6)
    themes2 <- colorRampPalette(c("darkred", "red3", "orange", "yellow", "lightskyblue", "royalblue3", "darkblue"))(19)
    myat =unique(seq(floor(min(s)) ,ceiling(max(s)),length.out=20))
    myat=round(myat,digits = 0)#     
    #themes <- rasterTheme(region=rev(brewer.pal(11,'RdYlBu')))
    myColorkey <- list(at=myat,space = "right",labels=list(cex=1,at=myat))

    if (dev.cur() == 1) x11(width=18,height=18)

    levelplot(s, layout=c(3, 2), index.cond=list(c(1, 3, 5, 2, 4, 6)),col.regions=themes2,  
              margin=FALSE,xlab=NULL,at =unique(seq(floor(min(s)) ,ceiling(max(s)),length.out=20)),
              par.strip.text=list(cex=0),colorkey=myColorkey,scales=list(alternating=F))NOTE: I need a single colorkeyProblem: rasters with smaller vs larger values get suppressed and the information on the map is not well visualized. How can I visualize such data using?levelplot?with this large range?You can generate 6 rasters with values within the ranges shown above to give me further clues.Thanks for your help!?The colorkey must not be red to blue. Something likehttp://iges.org/grads/gadoc/colorcontrol.html?"The Default Rainbow Palette" would do.


	[[alternative HTML version deleted]]


From mathieu.rajerison at gmail.com  Fri Feb 27 11:15:28 2015
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Fri, 27 Feb 2015 11:15:28 +0100
Subject: [R-sig-Geo] Generate N points along a SpatialLines object
In-Reply-To: <54EF223F.9030004@uni-muenster.de>
References: <CAGfc75ka_9Qy+dzAdCZkYvLtuZN6xXn_9qR8Ay-OtU=qEem=mg@mail.gmail.com>
	<54EF223F.9030004@uni-muenster.de>
Message-ID: <CAGfc75mjusEBr0HeLtMXD_B136BSY+_UgvW3rrs1OZep_V74QA@mail.gmail.com>

Ok nice !

I did'nt even notice spsample could work on SpatialLines object !..

2015-02-26 14:40 GMT+01:00 Edzer Pebesma <edzer.pebesma at uni-muenster.de>:

> Mathieu, sp::spsample samples SpatialLines objects, and has an argument
> type = "regular".
>
> On 02/26/2015 02:24 PM, Mathieu Rajerison wrote:
> > Hi List,
> >
> >
> > I try to generate N points along a a continental coastline with
> > spatstat::pointsOnLines
> >
> > If I give a small number of points (like N = 10), then 931 points are
> > returned. That's because 931 segments are generated from my initial
> > coastline data.
> >
> > I'd like to know how to generate exactly N points, equally spaced, from a
> > SpatialLines object, without GRASS, nor QGIS
> >
> >
> > Thanks in advance for any answer,
> >
> > Mathieu
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi),  University of M?nster,
> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> Journal of Statistical Software:   http://www.jstatsoft.org/
> Computers & Geosciences:   http://elsevier.com/locate/cageo/
> Spatial Statistics Society http://www.spatialstatistics.info
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

	[[alternative HTML version deleted]]


From Bastien.Ferland-Raymond at mffp.gouv.qc.ca  Fri Feb 27 15:26:40 2015
From: Bastien.Ferland-Raymond at mffp.gouv.qc.ca (Bastien.Ferland-Raymond at mffp.gouv.qc.ca)
Date: Fri, 27 Feb 2015 09:26:40 -0500
Subject: [R-sig-Geo] Problem with using multicore resample in Raster package
Message-ID: <161DC602615F6943A19BAEA3DBF2E4B901C28B5D4EFB@HARFANG.intranet.mrn.gouv>

Dear all,

I wrote a code last year that was running well.  I've retried the same code this month and it's not working anymore.  The problem arise from using cluster to do resampling in the raster package on multiple threads.  I've tried on two computers, both have the problem.

Here is a reproducible example :

###

library(raster)
#Loading required package: sp
 ## prepare the test rasters
r1 <- raster(nrows=1000, ncols=1000, xmn=0, xmx=1000)
set.seed(123)
values(r1) <- round(rnorm(1000000,100,20))
r2 <- raster(nrows=1000, ncols=1000, xmn=.2, xmx=1000.2)
 ## testing resample without multicore
resamp.single <- resample(r1, r2)
 ## testing resample with multicore
beginCluster(11)
#Loading required namespace: snow
resamp.multi <- resample(r1, r2)
#Using cluster with 11 nodes
#Error in UseMethod("recvOneData") :
# no applicable method for 'recvOneData' applied to an object of class "c('SOCKcluster', 'cluster')"
endCluster()
#Error in UseMethod("stopCluster") :
# no applicable method for 'stopCluster' applied to an object of class "c('SOCKcluster', 'cluster')"
 sessionInfo()
#R version 3.1.2 (2014-10-31)
#Platform: x86_64-w64-mingw32/x64 (64-bit)

#locale:
#[1] LC_COLLATE=French_Canada.1252  LC_CTYPE=French_Canada.1252
#[3] LC_MONETARY=French_Canada.1252 LC_NUMERIC=C
#[5] LC_TIME=French_Canada.1252

#attached base packages:
#[1] stats     graphics  grDevices utils     datasets  methods   base

#other attached packages:
#[1] raster_2.3-24 sp_1.0-17

#loaded via a namespace (and not attached):
#[1] grid_3.1.2      lattice_0.20-30 snow_0.3-13


Any idea what the problem is?

Thanks

Bastien Ferland-Raymond, M.Sc. Stat., M.Sc. Biol.
Division des orientations et projets sp?ciaux
Direction des inventaires forestiers
Minist?re des For?ts, de la Faune et des Parcs


	[[alternative HTML version deleted]]


From mtreglia at gmail.com  Fri Feb 27 16:55:01 2015
From: mtreglia at gmail.com (Michael Treglia)
Date: Fri, 27 Feb 2015 09:55:01 -0600
Subject: [R-sig-Geo] Problem with using multicore resample in Raster
	package
In-Reply-To: <161DC602615F6943A19BAEA3DBF2E4B901C28B5D4EFB@HARFANG.intranet.mrn.gouv>
References: <161DC602615F6943A19BAEA3DBF2E4B901C28B5D4EFB@HARFANG.intranet.mrn.gouv>
Message-ID: <CAPKp32s6EDqOTERyjaOWS8f4XZK2ks2pM41tb8bWqdSe-mcnDQ@mail.gmail.com>

Haven't tried to troubleshoot the problem, but your code works fine for me.

Looks like I'm running a slightly older versions of packages (notably, for
raster). My session info is below.  Here's my session info in case it helps:

R version 3.1.2 (2014-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] snow_0.3-13   raster_2.2-31 sp_1.0-15

loaded via a namespace (and not attached):
[1] grid_3.1.2      lattice_0.20-29

-Mike T

On Fri, Feb 27, 2015 at 8:26 AM, <Bastien.Ferland-Raymond at mffp.gouv.qc.ca>
wrote:

> Dear all,
>
> I wrote a code last year that was running well.  I've retried the same
> code this month and it's not working anymore.  The problem arise from using
> cluster to do resampling in the raster package on multiple threads.  I've
> tried on two computers, both have the problem.
>
> Here is a reproducible example :
>
> ###
>
> library(raster)
> #Loading required package: sp
>  ## prepare the test rasters
> r1 <- raster(nrows=1000, ncols=1000, xmn=0, xmx=1000)
> set.seed(123)
> values(r1) <- round(rnorm(1000000,100,20))
> r2 <- raster(nrows=1000, ncols=1000, xmn=.2, xmx=1000.2)
>  ## testing resample without multicore
> resamp.single <- resample(r1, r2)
>  ## testing resample with multicore
> beginCluster(11)
> #Loading required namespace: snow
> resamp.multi <- resample(r1, r2)
> #Using cluster with 11 nodes
> #Error in UseMethod("recvOneData") :
> # no applicable method for 'recvOneData' applied to an object of class
> "c('SOCKcluster', 'cluster')"
> endCluster()
> #Error in UseMethod("stopCluster") :
> # no applicable method for 'stopCluster' applied to an object of class
> "c('SOCKcluster', 'cluster')"
>  sessionInfo()
> #R version 3.1.2 (2014-10-31)
> #Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> #locale:
> #[1] LC_COLLATE=French_Canada.1252  LC_CTYPE=French_Canada.1252
> #[3] LC_MONETARY=French_Canada.1252 LC_NUMERIC=C
> #[5] LC_TIME=French_Canada.1252
>
> #attached base packages:
> #[1] stats     graphics  grDevices utils     datasets  methods   base
>
> #other attached packages:
> #[1] raster_2.3-24 sp_1.0-17
>
> #loaded via a namespace (and not attached):
> #[1] grid_3.1.2      lattice_0.20-30 snow_0.3-13
>
>
> Any idea what the problem is?
>
> Thanks
>
> Bastien Ferland-Raymond, M.Sc. Stat., M.Sc. Biol.
> Division des orientations et projets sp?ciaux
> Direction des inventaires forestiers
> Minist?re des For?ts, de la Faune et des Parcs
>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

	[[alternative HTML version deleted]]


From r.hijmans at gmail.com  Fri Feb 27 19:09:52 2015
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Fri, 27 Feb 2015 10:09:52 -0800
Subject: [R-sig-Geo] Problem with using multicore resample in Raster
	package
In-Reply-To: <161DC602615F6943A19BAEA3DBF2E4B901C28B5D4EFB@HARFANG.intranet.mrn.gouv>
References: <161DC602615F6943A19BAEA3DBF2E4B901C28B5D4EFB@HARFANG.intranet.mrn.gouv>
Message-ID: <CANtt_hwm5-u9MvymgW=2F9vP1J7qbKY8g_wSbrLw9YorDRNQWg@mail.gmail.com>

Bastien,

This arises from a change in CRAN policy (the requirement to use
"requireNamespace" instead of "require") which somehow creates a
problem for snow::recvOneData. This is all a bit mysterious to me. The
development version uses require again for the snow package such that
things work as they should. Please use that version for now:

install.packages("raster", repos="http://R-Forge.R-project.org")

Robert



On Fri, Feb 27, 2015 at 6:26 AM,
<Bastien.Ferland-Raymond at mffp.gouv.qc.ca> wrote:
> Dear all,
>
> I wrote a code last year that was running well.  I've retried the same code this month and it's not working anymore.  The problem arise from using cluster to do resampling in the raster package on multiple threads.  I've tried on two computers, both have the problem.
>
> Here is a reproducible example :
>
> ###
>
> library(raster)
> #Loading required package: sp
>  ## prepare the test rasters
> r1 <- raster(nrows=1000, ncols=1000, xmn=0, xmx=1000)
> set.seed(123)
> values(r1) <- round(rnorm(1000000,100,20))
> r2 <- raster(nrows=1000, ncols=1000, xmn=.2, xmx=1000.2)
>  ## testing resample without multicore
> resamp.single <- resample(r1, r2)
>  ## testing resample with multicore
> beginCluster(11)
> #Loading required namespace: snow
> resamp.multi <- resample(r1, r2)
> #Using cluster with 11 nodes
> #Error in UseMethod("recvOneData") :
> # no applicable method for 'recvOneData' applied to an object of class "c('SOCKcluster', 'cluster')"
> endCluster()
> #Error in UseMethod("stopCluster") :
> # no applicable method for 'stopCluster' applied to an object of class "c('SOCKcluster', 'cluster')"
>  sessionInfo()
> #R version 3.1.2 (2014-10-31)
> #Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> #locale:
> #[1] LC_COLLATE=French_Canada.1252  LC_CTYPE=French_Canada.1252
> #[3] LC_MONETARY=French_Canada.1252 LC_NUMERIC=C
> #[5] LC_TIME=French_Canada.1252
>
> #attached base packages:
> #[1] stats     graphics  grDevices utils     datasets  methods   base
>
> #other attached packages:
> #[1] raster_2.3-24 sp_1.0-17
>
> #loaded via a namespace (and not attached):
> #[1] grid_3.1.2      lattice_0.20-30 snow_0.3-13
>
>
> Any idea what the problem is?
>
> Thanks
>
> Bastien Ferland-Raymond, M.Sc. Stat., M.Sc. Biol.
> Division des orientations et projets sp?ciaux
> Direction des inventaires forestiers
> Minist?re des For?ts, de la Faune et des Parcs
>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From oscar.perpinan at gmail.com  Sat Feb 28 08:17:05 2015
From: oscar.perpinan at gmail.com (=?UTF-8?Q?Oscar_Perpi=C3=B1an?=)
Date: Sat, 28 Feb 2015 08:17:05 +0100
Subject: [R-sig-Geo] Visualize negative/poitive data using levelplot in R
In-Reply-To: <1474553176.1188027.1424987029645.JavaMail.yahoo@mail.yahoo.com>
References: <1474553176.1188027.1424987029645.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAMLL7bkkcpsK5HZ3P-RH_aiLUaLJpRPvb=pAhKcyGRD-sY=2_A@mail.gmail.com>

Hello,

You did answer this same question at stackoverflow (
http://stackoverflow.com/q/28753126/964866) without letting us know about
it. This post is worth reading if you really need to do cross-posting (
http://www.coderanch.com/how-to/java/BeForthrightWhenCrossPostingToOtherSites
):


This practice may not be in the interests of the ranchers who might be
responding to your posts. Many folks may find that they have wasted their
time and effort. You certainly don't want to annoy those you want to help
you, so you might want to make the experience as painless as possible.
The best way to do something like this (without ticking people off) would
be to let people know upfront that the crossposting is occurring. This
makes the most sense if there's a respectable delay between posting in one
forum and another, e.g:
"I posted this question the other day in SomeOtherForum.com [link], but
wasn't able to get a good answer, so now I'm asking here..."


I have just posted a simple answer to your question which I reproduce here:

In my opinion, you have two choices:

1. Use a different key for each graph.
2. Rescale the data to create a common scale.

Because you need a single colorkey you should rescale the data. Although
this document (
http://www.perceptualedge.com/articles/visual_business_intelligence/dual-scaled_axes.pdf)
is about time series, it gives good advices about this issue.

Best,

Oscar.

-----------------------------------------------------------------
Oscar Perpi??n Lamigueiro
Dpto. Ing. El?ctrica, Electr?nica, Autom?tica y F?sica Aplicada (ETSIDI-UPM)
Grupo de Sistemas Fotovoltaicos (IES-UPM)
URL: http://oscarperpinan.github.io

2015-02-26 22:43 GMT+01:00 Zilefac Elvis via R-sig-Geo <
r-sig-geo at r-project.org>:

> Hello,
> I need your insigts on how to visualize/map data that spans negative and
> positive values. I have 6 rasters which have been stacked together (s) and
> will subsequently be plotted via levelplotfunction in R. Below are
> the max and min values for each raster.39.2887, 53.09207  (min, max) # r1
>
> -32.4956, -27.25534  (min, max)# r2
>
> -14.37683, -11.37742  (min, max)# r3
>
>  9.512934, 13.60197  (min, max)# r4
>
> -4.993901, -1.851784  (min, max)# r5
>
> -8.190711, -5.104764  (min, max)# r6At the moment, I am able to produce my
> map via:library(raster)
> library(rasterVis)
> library(colorRamp)
>     s <- stack(r1,r2,r3,r4,r5,r6)
>     themes2 <- colorRampPalette(c("darkred", "red3", "orange", "yellow",
> "lightskyblue", "royalblue3", "darkblue"))(19)
>     myat =unique(seq(floor(min(s)) ,ceiling(max(s)),length.out=20))
>     myat=round(myat,digits = 0)#
>     #themes <- rasterTheme(region=rev(brewer.pal(11,'RdYlBu')))
>     myColorkey <- list(at=myat,space = "right",labels=list(cex=1,at=myat))
>
>     if (dev.cur() == 1) x11(width=18,height=18)
>
>     levelplot(s, layout=c(3, 2), index.cond=list(c(1, 3, 5, 2, 4,
> 6)),col.regions=themes2,
>               margin=FALSE,xlab=NULL,at =unique(seq(floor(min(s))
> ,ceiling(max(s)),length.out=20)),
>
> par.strip.text=list(cex=0),colorkey=myColorkey,scales=list(alternating=F))NOTE:
> I need a single colorkeyProblem: rasters with smaller vs larger values get
> suppressed and the information on the map is not well visualized. How can I
> visualize such data using levelplot with this large range?You can generate
> 6 rasters with values within the ranges shown above to give me further
> clues.Thanks for your help! The colorkey must not be red to blue. Something
> likehttp://iges.org/grads/gadoc/colorcontrol.html "The Default Rainbow
> Palette" would do.
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From cmohamma at gmail.com  Sat Feb 28 09:45:40 2015
From: cmohamma at gmail.com (Cyrus Mohammadian)
Date: Sat, 28 Feb 2015 00:45:40 -0800
Subject: [R-sig-Geo] still having problems installing rgdal on osx mavericks
Message-ID: <AA6DBEE7-7E43-492E-8094-349CE52973D0@gmail.com>

Hey Everyone,

I?m having problems installing and loading rgal on mavericks. I know there is a lot written on the net about it but I have not been able to successfully install the package. I downloaded the .tgz file and I installed the package from source but every time I attempt to load the library my R workspace crashes. Any help would be fantastic. If upgrading to Yosemite solves the problem I?m willing to upgrade but only if I can be sure. Thanks everyone!

Best,

Cyrus Mohammadian

From zilefacelvis at yahoo.com  Sat Feb 28 16:42:02 2015
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Sat, 28 Feb 2015 15:42:02 +0000 (UTC)
Subject: [R-sig-Geo] Visualize negative/poitive data using levelplot in R
In-Reply-To: <CAMLL7bkkcpsK5HZ3P-RH_aiLUaLJpRPvb=pAhKcyGRD-sY=2_A@mail.gmail.com>
References: <CAMLL7bkkcpsK5HZ3P-RH_aiLUaLJpRPvb=pAhKcyGRD-sY=2_A@mail.gmail.com>
Message-ID: <585124858.331614.1425138122888.JavaMail.yahoo@mail.yahoo.com>

Many thanks, Oscar for these suggestions.I needed urgent suggestions because the?deadline for the article to be resubmitted was nearbyCheers,AT.
	[[alternative HTML version deleted]]


From jrcoyle at live.unc.edu  Sat Feb 28 17:32:51 2015
From: jrcoyle at live.unc.edu (jcoyle)
Date: Sat, 28 Feb 2015 09:32:51 -0700 (MST)
Subject: [R-sig-Geo] Create listw or nb object from binary edge matrix
Message-ID: <1425141171309-7587849.post@n2.nabble.com>

I am trying to create an nb or listw object for use with spdep functions from
a binary matrix with 1 indicating that two 'regions' are neighbors. However,
the following code does not produce a neighbors list as I think it should
after reading  this previous post
<https://stat.ethz.ch/pipermail/r-sig-geo/2009-February/005070.html>  :mat =
matrix(0, 4, 4)mat[1,2] = 1mat[2,1] = 1mat[3,4] = 1mat[4,3] = 1lw =
mat2listw(mat)lw$neighborsWhat am I doing wrong?Thanks!Jes



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Create-listw-or-nb-object-from-binary-edge-matrix-tp7587849.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Sat Feb 28 22:07:45 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 28 Feb 2015 22:07:45 +0100
Subject: [R-sig-Geo] Create listw or nb object from binary edge matrix
In-Reply-To: <1425141171309-7587849.post@n2.nabble.com>
References: <1425141171309-7587849.post@n2.nabble.com>
Message-ID: <alpine.LFD.2.11.1502282200500.32564@reclus.nhh.no>

On Sat, 28 Feb 2015, jcoyle wrote:

> I am trying to create an nb or listw object for use with spdep functions from
> a binary matrix with 1 indicating that two 'regions' are neighbors. However,
> the following code does not produce a neighbors list as I think it should
> after reading  this previous post
> <https://stat.ethz.ch/pipermail/r-sig-geo/2009-February/005070.html>  :mat =
> matrix(0, 4, 4)mat[1,2] = 1mat[2,1] = 1mat[3,4] = 1mat[4,3] = 1lw =
> mat2listw(mat)lw$neighborsWhat am I doing wrong?Thanks!Jes
>

I suppose you meant:

library(spdep)
mat = matrix(0, 4, 4)
mat[1,2] = 1
mat[2,1] = 1
mat[3,4] = 1
mat[4,3] = 1
   mat
lw = mat2listw(mat)
lw$neighbors

but

lw$neighbours

is OK, as:

all.equal(nb2mat(lw$neighbours, style="B"), mat, check.attributes=FALSE)

shows. Use of British English spelling is rooted in usage in Cliff & Ord 
(1973).

Roger

>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Create-listw-or-nb-object-from-binary-edge-matrix-tp7587849.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Sat Feb 28 22:11:47 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 28 Feb 2015 22:11:47 +0100
Subject: [R-sig-Geo] still having problems installing rgdal on osx
 mavericks
In-Reply-To: <AA6DBEE7-7E43-492E-8094-349CE52973D0@gmail.com>
References: <AA6DBEE7-7E43-492E-8094-349CE52973D0@gmail.com>
Message-ID: <alpine.LFD.2.11.1502282210220.32564@reclus.nhh.no>

On Sat, 28 Feb 2015, Cyrus Mohammadian wrote:

> Hey Everyone,
>
> I?m having problems installing and loading rgal on mavericks. I know 
> there is a lot written on the net about it but I have not been able to 
> successfully install the package. I downloaded the .tgz file and I 
> installed the package from source but every time I attempt to load the 
> library my R workspace crashes. Any help would be fantastic. If

As you should know, files with the *.tgz extension are Mac Binary 
packages. Those with *.tar.gz are source packages. Is this the cause of 
your confusion?

Roger

> upgrading to Yosemite solves the problem I?m willing to upgrade but only 
> if I can be sure. Thanks everyone!
>
> Best,
>
> Cyrus Mohammadian
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

