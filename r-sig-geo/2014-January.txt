From HodgessE at uhd.edu  Wed Jan  1 02:55:44 2014
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Wed, 1 Jan 2014 01:55:44 +0000
Subject: [R-sig-Geo] problems with plotting STFDF
Message-ID: <FF9DB805FC41CC4E95825A50F680630217AF7BEA@challenger.uhd.campus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140101/a0894ecb/attachment.pl>

From HodgessE at uhd.edu  Wed Jan  1 03:27:27 2014
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Wed, 1 Jan 2014 02:27:27 +0000
Subject: [R-sig-Geo] a space-time question
Message-ID: <FF9DB805FC41CC4E95825A50F680630217AF7E4E@challenger.uhd.campus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140101/7dc75874/attachment.pl>

From Roger.Bivand at nhh.no  Wed Jan  1 18:27:39 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 1 Jan 2014 18:27:39 +0100
Subject: [R-sig-Geo] Remove holes from a SpatialPolygon
In-Reply-To: <CAGBzUO-BTF4AcdUQ6YrjCNiy6crv8MVgne8uRv9xu0qMr=vhCA@mail.gmail.com>
References: <CAGBzUO-BTF4AcdUQ6YrjCNiy6crv8MVgne8uRv9xu0qMr=vhCA@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1401011806510.1970@reclus.nhh.no>

On Tue, 31 Dec 2013, Mark Payne wrote:

> Hi,
>
> I have a SpatialPolygon that I have created through a series of
> processing steps. The SP consists of one outer-boundary, with a series
> of holes punched in it - think of it as the coastline of an island
> with a series of lakes in it. However, I am only interested in the
> "external" coastline and don't want the "lakes". How do I best remove
> these holes?

For reproducibility:

library(maptools)
NZy <- c(-53,-29)
NZx <- c(160,180)
NZ <- Rgshhs(gshhs.c.b, xlim=NZx, ylim=NZy, level=2)$SP
NZp <- slot(NZ, "polygons")
holes <- lapply(NZp, function(x) sapply(slot(x, "Polygons"), slot,
   "hole"))
res <- lapply(1:length(NZp), function(i) slot(NZp[[i]],
   "Polygons")[!holes[[i]]])
IDs <- row.names(NZ)
NZfill <- SpatialPolygons(lapply(1:length(res), function(i)
   Polygons(res[[i]], ID=IDs[i])), proj4string=CRS(proj4string(NZ)))

Using the creation functions should ensure reasonable reconstruction, with 
two reservations:

1) this provides no protection against an exterior ring nesting inside 
another exterior ring, so needing a hole to avoid overlapping, and

2) this doesn't secure the correct construction of comments, needed by 
GEOS/rgeos to place interior rings in the correct exterior rings.

You can handle the latter (and possibly your error with your code), by 
assigning comments or by removing them:

slot(NZfill, "polygons") <- lapply(slot(NZfill, "polygons"),
   checkPolygonsHoles)

will assign comments, seen by:

lapply(slot(NZfill, "polygons"), comment)

or remove them by:

slot(NZfill, "polygons") <- lapply(slot(NZfill, "polygons"),
   "comment<-", NULL)

In rgeos, a NULL comment forces the internal generation of comments, the 
correct comments in the Polygons objects avoid using time to do this, but 
stale comments (like yours) are not corrected, and generate an error.

It is hard to keep track if you don't learn to like and use *apply.

Hope this helps,

Roger

>
> Here is what I have tried so far (bufr is the object of interest)
>
> holes <- sapply(bufr at polygons[[1]]@Polygons,slot,"hole")
> bufr.hole.free <- bufr
> bufr.hole.free at polygons[[1]]@Polygons <-
> bufr.hole.free at polygons[[1]]@Polygons[!holes]
> bufr.hole.free at polygons[[1]]@plotOrder <-
> as.integer(rank(bufr.hole.free at polygons[[1]]@plotOrder[holes]))
>
> However, this fails when I try to use it later with rgeos:
>
> roi.raw <- gDifference(bufr.hole.free,borders)
> Error in RGEOSBinTopoFunc(spgeom1, spgeom2, byid, id, "rgeos_difference") :
>  lengths of comment and Polygons slot differ
>
>
> How should I remove the holes in a manner that maintains the integrity
> of the SpatialPolygons class?
>
> Mark
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Lee.Hachadoorian+L at gmail.com  Wed Jan  1 21:16:27 2014
From: Lee.Hachadoorian+L at gmail.com (Lee Hachadoorian)
Date: Wed, 1 Jan 2014 15:16:27 -0500
Subject: [R-sig-Geo] Minor rgdal tip: Use geometry column name to access
 PostGIS inherited tables
Message-ID: <52C4779B.4000501@gmail.com>

I was using rgdal to load a PostGIS table which is a child table in a 
partitioning scheme. (Common setup, see e.g. ?3.1.3 in PostGIS in 
Action.) I kept getting the message "Layer not found". It turns out that 
in this case you can't use the table name as the layer name, you have to 
use "table_name(geometry_column_name)".

Perhaps this is already widely known, but it is difficult to Google and 
behaves differently from OGR. Even though both ogrinfo (the GDAL/OGR 
utility) and ogrListLayers (the R function) will find child tables and 
list them in the "table_name(geometry_column_name)" form, ogrinfo and 
ogr2ogr support accessing the layer just using "table_name", as long as 
that is the single geometry column in the table. ogrInfo (the R 
function) and readOGR require appending the geometry column name.

Best,
--Lee

-- 
Lee Hachadoorian
Assistant Professor in Geography, Dartmouth College
http://geospatial.commons.gc.cuny.edu
http://freecity.commons.gc.cuny.edu


From rvaldezr at gmail.com  Fri Jan  3 22:00:14 2014
From: rvaldezr at gmail.com (Rolando Valdez)
Date: Fri, 3 Jan 2014 22:00:14 +0100
Subject: [R-sig-Geo] Represent data on map
Message-ID: <003001cf08c6$cddb6c90$699245b0$@gmail.com>

Hi,

I'm trying to represent data (unemployment rate) on a map. 

This is what I have:

> library(sp)
> library(maptools)
Checking rgeos availability: TRUE
> map <- readShapeSpatial("ESTADOS")
> read.csv("C:\\Users\\Rolando\\Documents\\Maestr?a en Econom?a\\3er Semestre\\AEMT\\desempleo_est.csv")
> spplot(map, c("2000"))
Error en `[.data.frame`(obj at data, zcol) : undefined columns selected

> unem <- read.csv("C:\\Users\\Rolando\\Documents\\Maestr?a en Econom?a\\3er Semestre\\AEMT\\desempleo_est.csv")
> names(unem)
[1] "num_est" "est"     "X2000"   "X2005"   "X2010"   "X2013"

I hope you can help me, this is my first time in R.

Regards,

Rol~


From macqueen1 at llnl.gov  Sat Jan  4 00:06:33 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 3 Jan 2014 23:06:33 +0000
Subject: [R-sig-Geo] Represent data on map
In-Reply-To: <003001cf08c6$cddb6c90$699245b0$@gmail.com>
References: <003001cf08c6$cddb6c90$699245b0$@gmail.com>
Message-ID: <CEEC8044.E824D%macqueen1@llnl.gov>

Cannot help much without more information, but try:

  names(map)

Then pick one of the column names. Apparently, "2000" is not the name of a
column of data in the map object.
If map is like unem, then perhaps

  spplot(map, 'X2000')

is what you need.

Note, the c() in
  c("2000")
is not necessary. Simply
  "2000"
would be sufficient.

I am not familiar with the readShapeSpatial function; I always use
readOGR() from the sp package.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 1/3/14 1:00 PM, "Rolando Valdez" <rvaldezr at gmail.com> wrote:

>Hi,
>
>I'm trying to represent data (unemployment rate) on a map.
>
>This is what I have:
>
>> library(sp)
>> library(maptools)
>Checking rgeos availability: TRUE
>> map <- readShapeSpatial("ESTADOS")
>> read.csv("C:\\Users\\Rolando\\Documents\\Maestr?a en Econom?a\\3er
>>Semestre\\AEMT\\desempleo_est.csv")
>> spplot(map, c("2000"))
>Error en `[.data.frame`(obj at data, zcol) : undefined columns selected
>
>> unem <- read.csv("C:\\Users\\Rolando\\Documents\\Maestr?a en
>>Econom?a\\3er Semestre\\AEMT\\desempleo_est.csv")
>> names(unem)
>[1] "num_est" "est"     "X2000"   "X2005"   "X2010"   "X2013"
>
>I hope you can help me, this is my first time in R.
>
>Regards,
>
>Rol~
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at r-project.org
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From rvaldezr at gmail.com  Sat Jan  4 21:33:18 2014
From: rvaldezr at gmail.com (Rolando Valdez)
Date: Sat, 4 Jan 2014 21:33:18 +0100
Subject: [R-sig-Geo] +AFs-R-sig-Geo+AF0- Represent data on map
In-Reply-To: <CEEC8044.E824D%macqueen1@llnl.gov>
References: +ADw-003001cf08c6+ACQ-cddb6c90+ACQ-699245b0+ACQAQA-gmail.com+AD4-
	+ADw-CEEC8044.E824D+ACU-macqueen1+AEA-llnl.gov+AD4-
Message-ID: <001301cf098c$34e862b0$9eb92810$@gmail.com>

It didn't work.

+AD4- names(map)
+AFs-1+AF0- +ACI-CVE+AF8-EDO+ACI-    +ACI-NOMBRE+AF8-EDO+ACI-
+AD4- names(unem)
+AFs-1+AF0- +ACI-num+AF8-est+ACI- +ACI-est+ACI-     +ACI-X2000+ACI-   +ACI-X2005+ACI-   +ACI-X2010+ACI-   +ACI-X2013+ACI-  
+AD4- spplot(map, 'X2000')
Error en +AGAAWw-.data.frame+AGA-(obj+AEA-data, zcol) : undefined columns selected

Is it a problema having separate shapefile information of statistic?, because there are two files, the .shp and csv, although these have the same identificator. I mean, the +ACI-CVE+AF8-EDO+ACI- +AD0- +ACI-num+AF8-est+ACI- and +ACI-NOMBRE+AF8-EDO+ACI- +AD0- +ACI-est+ACI- are the same value. I'm thinking if I have to paste the csv columns to the map object.

Thanks,

Rol+AH4-

-----Mensaje original-----
De: MacQueen, Don +AFs-mailto:macqueen1+AEA-llnl.gov+AF0- 
Enviado el: s+AOE-bado, 4 de enero de 2014 12:07 a. m.
Para: Rolando Valdez+ADs- r-sig-geo+AEA-r-project.org
Asunto: Re: +AFs-R-sig-Geo+AF0- Represent data on map

Cannot help much without more information, but try:

  names(map)

Then pick one of the column names. Apparently, +ACI-2000+ACI- is not the name of a column of data in the map object.
If map is like unem, then perhaps

  spplot(map, 'X2000')

is what you need.

Note, the c() in
  c(+ACI-2000+ACI-)
is not necessary. Simply
  +ACI-2000+ACI-
would be sufficient.

I am not familiar with the readShapeSpatial function+ADs- I always use
readOGR() from the sp package.

-Don

--
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 1/3/14 1:00 PM, +ACI-Rolando Valdez+ACI- +ADw-rvaldezr+AEA-gmail.com+AD4- wrote:

+AD4-Hi,
+AD4-
+AD4-I'm trying to represent data (unemployment rate) on a map.
+AD4-
+AD4-This is what I have:
+AD4-
+AD4APg- library(sp)
+AD4APg- library(maptools)
+AD4-Checking rgeos availability: TRUE
+AD4APg- map +ADw-- readShapeSpatial(+ACI-ESTADOS+ACI-)
+AD4APg- read.csv(+ACI-C:+AFwAXA-Users+AFwAXA-Rolando+AFwAXA-Documents+AFwAXA-Maestr+AO0-a en Econom+AO0-a+AFwAXA-3er
+AD4APg-Semestre+AFwAXA-AEMT+AFwAXA-desempleo+AF8-est.csv+ACI-)
+AD4APg- spplot(map, c(+ACI-2000+ACI-))
+AD4-Error en +AGAAWw-.data.frame+AGA-(obj+AEA-data, zcol) : undefined columns selected
+AD4-
+AD4APg- unem +ADw-- read.csv(+ACI-C:+AFwAXA-Users+AFwAXA-Rolando+AFwAXA-Documents+AFwAXA-Maestr+AO0-a en 
+AD4APg-Econom+AO0-a+AFwAXA-3er Semestre+AFwAXA-AEMT+AFwAXA-desempleo+AF8-est.csv+ACI-)
+AD4APg- names(unem)
+AD4AWw-1+AF0- +ACI-num+AF8-est+ACI- +ACI-est+ACI-     +ACI-X2000+ACI-   +ACI-X2005+ACI-   +ACI-X2010+ACI-   +ACI-X2013+ACI-
+AD4-
+AD4-I hope you can help me, this is my first time in R.
+AD4-
+AD4-Regards,
+AD4-
+AD4-Rol+AH4-
+AD4-
+AD4AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBf-
+AD4-R-sig-Geo mailing list
+AD4-R-sig-Geo+AEA-r-project.org
+AD4-https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From julleeyaw at yahoo.ca  Sun Jan  5 19:20:40 2014
From: julleeyaw at yahoo.ca (Julie Lee-Yaw)
Date: Sun, 5 Jan 2014 10:20:40 -0800 (PST)
Subject: [R-sig-Geo] editing/"moving" coordinates of shape file
Message-ID: <1388946040.15998.YahooMailBasic@web142504.mail.bf1.yahoo.com>

Hi 

I have two shapefiles that I am reading in to R via maptools (readShapePoly): for example, shape 1 is a map of the lower 48 US states and shape 2 is a polygon that represents a very crude buffer region around the Mississippi River. 

I ultimately want to create two new shapefiles representing the region west of the buffer zone (including the buffer) and the region east of the buffer zone (also including the buffer?so effectively two new shapefiles that only overlap via the buffer). Note this is sort of a splitting of the US shapefile into two, with the need to preserve the shape that bisected the original continent.

In ArcGIS, one way to do this would be to save the buffer shapefile as a new shp and manually "edit" some of the coordinates. So to create the "eastern" region, I would change the eastern-most points in the buffer polygon so that the shape extends well past the eastern edge of the continent; I could then crop this new shapefile by the continent to get the final eastern region.

I think I can pull everything in to PBSmapping format and use the joinPolys function to do the latter part of this process (e.g. crop to continent) but how can I modify/edit coordinates of the original buffer polygon to overshoot the continent boundaries? I see that "coords" is a slot in my buffer polygon but I haven't been able to figure out how to extract the coordinates from a polygon shapefile, let alone change them.  

Any suggestions on how to access the coordinates for purposes of changing them? Or better yet, a more efficient way to tackle this type of problem?

Thanks in advance!


From edzer.pebesma at uni-muenster.de  Sun Jan  5 19:32:58 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 05 Jan 2014 19:32:58 +0100
Subject: [R-sig-Geo] +AFs-R-sig-Geo+AF0- Represent data on map
In-Reply-To: <001301cf098c$34e862b0$9eb92810$@gmail.com>
References: +ADw-003001cf08c6+ACQ-cddb6c90+ACQ-699245b0+ACQAQA-gmail.com+AD4-	+ADw-CEEC8044.E824D+ACU-macqueen1+AEA-llnl.gov+AD4-
	<001301cf098c$34e862b0$9eb92810$@gmail.com>
Message-ID: <52C9A55A.9050404@uni-muenster.de>



On 01/04/2014 09:33 PM, Rolando Valdez wrote:
> It didn't work.
> 
>> names(map)
> [1] "CVE_EDO"    "NOMBRE_EDO"
>> names(unem)
> [1] "num_est" "est"     "X2000"   "X2005"   "X2010"   "X2013"  
>> spplot(map, 'X2000')
> Error en `[.data.frame`(obj at data, zcol) : undefined columns selected
> 
no, because X2000 will be sought in object 'map'. In case 'map' and
'unem' have exactly identical geometries (polygons?), and these
geometries occur in the same order, then

map$X2000 = unem$X2000

may suffice. If not, you might need to do a spatial match, e.g. by

library(sp)
data(meuse)
coordinates(meuse) = ~x+y
data(meuse.grid)
coordinates(meuse.grid) = ~x+y
gridded(meuse.grid) = TRUE

try(meuse$dist <- meuse.grid$dist) # fails, as geometries don't match

meuse$dist = over(meuse, meuse.grid)$dist # uses a spatial match

but still, if unem and map are both polygon geometries this may lead to
errors, as over() finds (first) intersecting polygons, and neighbouring
polygons touch each other, so intersect too.


> Is it a problema having separate shapefile information of statistic?, because there are two files, the .shp and csv, although these have the same identificator. I mean, the "CVE_EDO" = "num_est" and "NOMBRE_EDO" = "est" are the same value. I'm thinking if I have to paste the csv columns to the map object.
> 
> Thanks,
> 
> Rol~
> 
> -----Mensaje original-----
> De: MacQueen, Don [mailto:macqueen1 at llnl.gov] 
> Enviado el: s?bado, 4 de enero de 2014 12:07 a. m.
> Para: Rolando Valdez; r-sig-geo at r-project.org
> Asunto: Re: [R-sig-Geo] Represent data on map
> 
> Cannot help much without more information, but try:
> 
>   names(map)
> 
> Then pick one of the column names. Apparently, "2000" is not the name of a column of data in the map object.
> If map is like unem, then perhaps
> 
>   spplot(map, 'X2000')
> 
> is what you need.
> 
> Note, the c() in
>   c("2000")
> is not necessary. Simply
>   "2000"
> would be sufficient.
> 
> I am not familiar with the readShapeSpatial function; I always use
> readOGR() from the sp package.
> 
> -Don
> 
> --
> Don MacQueen
> 
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> 
> 
> 
> 
> 
> On 1/3/14 1:00 PM, "Rolando Valdez" <rvaldezr at gmail.com> wrote:
> 
>> Hi,
>>
>> I'm trying to represent data (unemployment rate) on a map.
>>
>> This is what I have:
>>
>>> library(sp)
>>> library(maptools)
>> Checking rgeos availability: TRUE
>>> map <- readShapeSpatial("ESTADOS")
>>> read.csv("C:\\Users\\Rolando\\Documents\\Maestr?a en Econom?a\\3er
>>> Semestre\\AEMT\\desempleo_est.csv")
>>> spplot(map, c("2000"))
>> Error en `[.data.frame`(obj at data, zcol) : undefined columns selected
>>
>>> unem <- read.csv("C:\\Users\\Rolando\\Documents\\Maestr?a en 
>>> Econom?a\\3er Semestre\\AEMT\\desempleo_est.csv")
>>> names(unem)
>> [1] "num_est" "est"     "X2000"   "X2005"   "X2010"   "X2013"
>>
>> I hope you can help me, this is my first time in R.
>>
>> Regards,
>>
>> Rol~
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 555 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140105/a514af13/attachment.bin>

From edzer.pebesma at uni-muenster.de  Sun Jan  5 20:32:47 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 05 Jan 2014 20:32:47 +0100
Subject: [R-sig-Geo] problems with plotting STFDF
In-Reply-To: <FF9DB805FC41CC4E95825A50F680630217AF7BEA@challenger.uhd.campus>
References: <FF9DB805FC41CC4E95825A50F680630217AF7BEA@challenger.uhd.campus>
Message-ID: <52C9B35F.50907@uni-muenster.de>

Thanks, Erin; the first function should be available when loading
package spacetime; I adapted kml_layer.STIDF in plotkml (on r-forge
svn), to accomodate to your second problem.

On 01/01/2014 02:55 AM, Hodgess, Erin wrote:
> Hello again!  Happy New Year!
> 
> Here is the solution for this particular situation.  Note:  thanks to many people for the help.  Anyhow, I started with looking at page 28 in the gstat vignette for krigeST.  If you work through that, you obtain an object called DE_kriged, which is an STFDF.
> 
> I copied some code from the following website:
> 
> (https://r-forge.r-project.org/scm/viewvc.php/pkg/R/coerce.R?view=markup&root=spacetime
> <https://r-forge.r-project.org/scm/viewvc.php/pkg/R/coerce.R?view=markup&root=spacetime&pathrev=25>)
> 
> to get the as.STIDF.STFDF lines:
> 
> 
> 
> # STFDF -> STIDF
> as.STIDF.STFDF = function(from) {
>         as(as(from, "STSDF"), "STIDF")
> }
> setAs("STFDF", "STIDF", as.STIDF.STFDF)
> 
> 
> Now:
> 
>>  DE1 <- as.STIDF.STFDF(DE_kriged)
> 
> DE1 is an STIDF object, which is good, but the @sp section is a Spatial Pixels object.
> 
> Next I copied over the function kml_layer.STIDF to new_STIDF.R and added the following section (see the note)
> 
> new.STIDF <-
> function (obj, dtime = "", ...)
> {
>     if (all(dtime == 0)) {
>         TimeSpan.begin = format(time(obj at time), "%Y-%m-%dT%H:%M:%SZ")
>         TimeSpan.end = TimeSpan.begin
>     }
>     else {
>         if (length(obj at time) > 1 & !nzchar(dtime)) {
>         print(obj at time)
>             period <- periodicity(obj at time)
>             dtime <- period$frequency
>         }
>         TimeSpan.begin <- format(as.POSIXct(unclass(as.POSIXct(time(obj at time))) -
>             dtime/2, origin = "1970-01-01"), "%Y-%m-%dT%H:%M:%SZ")
>         TimeSpan.end <- format(as.POSIXct(unclass(as.POSIXct(time(obj at time))) +
>             dtime/2, origin = "1970-01-01"), "%Y-%m-%dT%H:%M:%SZ")
>     }
>     if (class(obj at sp) == "SpatialPoints" | class(obj at sp) == "SpatialPointsDataFrame") {
>         sp <- SpatialPointsDataFrame(obj at sp, obj at data)
>         kml_layer.SpatialPoints(obj = sp, TimeSpan.begin = TimeSpan.begin,
>             TimeSpan.end = TimeSpan.end, ...)
>     }
>     else {
>         if (class(obj at sp) == "SpatialPolygons" | class(obj at sp) ==
>             "SpatialPolygonsDataFrame") {
>             sp <- SpatialPolygonsDataFrame(obj at sp, obj at data)
>             kml_layer.SpatialPolygons(obj = sp, TimeSpan.begin = TimeSpan.begin,
>                 TimeSpan.end = TimeSpan.end, ...)
>         }
>         else {
>             if (class(obj at sp) == "SpatialLines" | class(obj at sp) ==
>                 "SpatialLinesDataFrame") {
>                 sp <- SpatialLinesDataFrame(obj at sp, obj at data)
>                 kml_layer.SpatialLines(obj = sp, TimeSpan.begin = TimeSpan.begin,
>                   TimeSpan.end = TimeSpan.end, ...)
>             }
> 
> ###########################################################
> #  New for Spatial Pixels                                 #
> ##########################################################
>         else {
>             if (class(obj at sp) == "SpatialPixels" | class(obj at sp) ==
>                 "SpatialPixelsDataFrame") {
>                 sp <- SpatialPixelsDataFrame(obj at sp, obj at data)
>                 kml_layer.SpatialPoints(obj = sp, TimeSpan.begin = TimeSpan.begin,
>                   TimeSpan.end = TimeSpan.end, ...)
>             }
> 
> 
> 
>             else {
>                 stop("The STIDF object does not extend SpatialPoints*, SpatialLines* or SpatialPolygons*")
>             }
>         }
>     }
> }
> }
> 
> Finally, I ran this:
>> library(plotKML)
> plotKML version 0.4-0 (2013-11-15)
> URL: http://plotkml.r-forge.r-project.org/
> Warning message:
> replacing previous import by ?zoo::as.zoo? when loading ?gstat?
>> library(gstat)
> Loading required package: sp
>> kml_open("stuff2.kml")
> KML file opened for writing...
>> new.STIDF(DE1,dtime=24*3600,colour=var1.pred)
> Parsing to KML...
>> kml_close("stuff2.kml")
> Closing  stuff2.kml
>>
> 
> All is well.  Google Earth lets you run the kml file and show the time change, as it should.
> 
> Hope this might help someone!
> 
> Thanks,
> Erin
> 
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 555 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140105/d7288dd9/attachment.bin>

From bgr at bgs.ac.uk  Mon Jan  6 12:52:31 2014
From: bgr at bgs.ac.uk (Rawlins, Barry G.)
Date: Mon, 6 Jan 2014 11:52:31 +0000
Subject: [R-sig-Geo] Distance of points along an irregular linear feature -
 not quite "alongTrackDistance" in geosphere
Message-ID: <C1D2C279E163C549802E18252065A441066DE75FEA@nerckwmbc.ad.nerc.ac.uk>

Hello

I would like to compute distances between a series of points along an irregular linear feature (in this case a river channel). We have 36 sampling locations along the channel and I want to compute the downstream distances of each from the start of the channel. It appears that the function alongTrackDistance in the "geosphere" package does this for a regular path but not an irregular one. Do you know if there is a package/function that would do so for an irregular path? I have done some searching but cannot find anything.

I assume the computations necessary to do this would discretise a linear feature into a series of points and measure the cumulative distance along it.

Best wishes, Barry


This message (and any attachments) is for the recipient ...{{dropped:6}}


From rvaldezr at gmail.com  Mon Jan  6 16:00:51 2014
From: rvaldezr at gmail.com (Rolando Valdez)
Date: Mon, 6 Jan 2014 16:00:51 +0100
Subject: [R-sig-Geo] +AFs-R-sig-Geo+AF0- +-AFs-R-sig-Geo+-AF0- Represent
	data on map
In-Reply-To: <52C9A55A.9050404@uni-muenster.de>
References: +-ADw-003001cf08c6+-ACQ-cddb6c90+-ACQ-699245b0+-ACQAQA-gmail.com+-AD4-	+-ADw-CEEC8044.E824D+-ACU-macqueen1+-AEA-llnl.gov+-AD4-	+ADw-001301cf098c+ACQ-34e862b0+ACQ-9eb92810+ACQAQA-gmail.com+AD4-
	+ADw-52C9A55A.9050404+AEA-uni-muenster.de+AD4-
Message-ID: <000a01cf0af0$18145c10$483d1430$@gmail.com>

I could not work with the information by separately. I modified +ACI-manually+ACI- the +ACo-.dbf file associated to the +ACo-.shp file. I just pasted the columns with the information in the +ACo-.dbf file because I couldn't do it with R.

After that, I did:

library(sp)
library(maptools)
map +ADw-- readShapeSpatial(+ACI-ESTADOS+ACI-)
library(lattice)
trellis.par.set(sp.theme())
spplot(map, c(+ACI-A2010+ACI-, +ACI-A2013+ACI-, +ACI-A2000+ACI-, +ACI-A2005+ACI-), names.attr +AD0- c(+ACI-2010+ACI-, +ACI-2013+ACI-, +ACI-2000+ACI-, +ACI-2005+ACI-),
main +AD0- +ACI-Desempleo por estados en M+AOk-xico, 2000-2013+ACI-)

And this is the result: https://skydrive.live.com/redir?resid+AD0-C319779BEF3A0241+ACE-1539+ACY-authkey+AD0AIQ-AMe4-a2kRUFmAyM+ACY-v+AD0-3+ACY-ithint+AD0-photo+ACU-2c.png

Now, my trouble is the scale, that is in integer numbers, how do I can set the scale with decimals and the halves values (like 1.5, 2.5, 3.5.....)?.

I tried with:

spplot(map, c(+ACI-A2010+ACI-, +ACI-A2013+ACI-, +ACI-A2000+ACI-, +ACI-A2005+ACI-), names.attr +AD0- c(+ACI-2010+ACI-, +ACI-2013+ACI-, +ACI-2000+ACI-, +ACI-2005+ACI-),
main +AD0- +ACI-Desempleo por estados en M+AOk-xico, 2000-2013+ACI-, scale +AD0- 0.5, which +AD0- 2)

...and didn't work.

I hope you can help me.

Regards,

Rol+AH4-

-----Mensaje original-----
De: r-sig-geo-bounces+AEA-r-project.org +AFs-mailto:r-sig-geo-bounces+AEA-r-project.org+AF0- En nombre de Edzer Pebesma
Enviado el: domingo, 5 de enero de 2014 07:33 p. m.
Para: r-sig-geo+AEA-r-project.org
Asunto: Re: +AFs-R-sig-Geo+AF0- +-AFs-R-sig-Geo+-AF0- Represent data on map



On 01/04/2014 09:33 PM, Rolando Valdez wrote:
+AD4- It didn't work.
+AD4- 
+AD4APg- names(map)
+AD4- +AFs-1+AF0- +ACI-CVE+AF8-EDO+ACI-    +ACI-NOMBRE+AF8-EDO+ACI-
+AD4APg- names(unem)
+AD4- +AFs-1+AF0- +ACI-num+AF8-est+ACI- +ACI-est+ACI-     +ACI-X2000+ACI-   +ACI-X2005+ACI-   +ACI-X2010+ACI-   +ACI-X2013+ACI-  
+AD4APg- spplot(map, 'X2000')
+AD4- Error en +AGAAWw-.data.frame+AGA-(obj+AEA-data, zcol) : undefined columns selected
+AD4- 
no, because X2000 will be sought in object 'map'. In case 'map' and 'unem' have exactly identical geometries (polygons?), and these geometries occur in the same order, then

map+ACQ-X2000 +AD0- unem+ACQ-X2000

may suffice. If not, you might need to do a spatial match, e.g. by

library(sp)
data(meuse)
coordinates(meuse) +AD0- +AH4-x+-y
data(meuse.grid)
coordinates(meuse.grid) +AD0- +AH4-x+-y
gridded(meuse.grid) +AD0- TRUE

try(meuse+ACQ-dist +ADw-- meuse.grid+ACQ-dist) +ACM- fails, as geometries don't match

meuse+ACQ-dist +AD0- over(meuse, meuse.grid)+ACQ-dist +ACM- uses a spatial match

but still, if unem and map are both polygon geometries this may lead to errors, as over() finds (first) intersecting polygons, and neighbouring polygons touch each other, so intersect too.


+AD4- Is it a problema having separate shapefile information of statistic?, because there are two files, the .shp and csv, although these have the same identificator. I mean, the +ACI-CVE+AF8-EDO+ACI- +AD0- +ACI-num+AF8-est+ACI- and +ACI-NOMBRE+AF8-EDO+ACI- +AD0- +ACI-est+ACI- are the same value. I'm thinking if I have to paste the csv columns to the map object.
+AD4- 
+AD4- Thanks,
+AD4- 
+AD4- Rol+AH4-
+AD4- 
+AD4- -----Mensaje original-----
+AD4- De: MacQueen, Don +AFs-mailto:macqueen1+AEA-llnl.gov+AF0- Enviado el: s+AOE-bado, 4 de 
+AD4- enero de 2014 12:07 a. m.
+AD4- Para: Rolando Valdez+ADs- r-sig-geo+AEA-r-project.org
+AD4- Asunto: Re: +AFs-R-sig-Geo+AF0- Represent data on map
+AD4- 
+AD4- Cannot help much without more information, but try:
+AD4- 
+AD4-   names(map)
+AD4- 
+AD4- Then pick one of the column names. Apparently, +ACI-2000+ACI- is not the name of a column of data in the map object.
+AD4- If map is like unem, then perhaps
+AD4- 
+AD4-   spplot(map, 'X2000')
+AD4- 
+AD4- is what you need.
+AD4- 
+AD4- Note, the c() in
+AD4-   c(+ACI-2000+ACI-)
+AD4- is not necessary. Simply
+AD4-   +ACI-2000+ACI-
+AD4- would be sufficient.
+AD4- 
+AD4- I am not familiar with the readShapeSpatial function+ADs- I always use
+AD4- readOGR() from the sp package.
+AD4- 
+AD4- -Don
+AD4- 
+AD4- --
+AD4- Don MacQueen
+AD4- 
+AD4- Lawrence Livermore National Laboratory
+AD4- 7000 East Ave., L-627
+AD4- Livermore, CA 94550
+AD4- 925-423-1062
+AD4- 
+AD4- 
+AD4- 
+AD4- 
+AD4- 
+AD4- On 1/3/14 1:00 PM, +ACI-Rolando Valdez+ACI- +ADw-rvaldezr+AEA-gmail.com+AD4- wrote:
+AD4- 
+AD4APg- Hi,
+AD4APg-
+AD4APg- I'm trying to represent data (unemployment rate) on a map.
+AD4APg-
+AD4APg- This is what I have:
+AD4APg-
+AD4APgA+- library(sp)
+AD4APgA+- library(maptools)
+AD4APg- Checking rgeos availability: TRUE
+AD4APgA+- map +ADw-- readShapeSpatial(+ACI-ESTADOS+ACI-)
+AD4APgA+- read.csv(+ACI-C:+AFwAXA-Users+AFwAXA-Rolando+AFwAXA-Documents+AFwAXA-Maestr+AO0-a en Econom+AO0-a+AFwAXA-3er
+AD4APgA+- Semestre+AFwAXA-AEMT+AFwAXA-desempleo+AF8-est.csv+ACI-)
+AD4APgA+- spplot(map, c(+ACI-2000+ACI-))
+AD4APg- Error en +AGAAWw-.data.frame+AGA-(obj+AEA-data, zcol) : undefined columns selected
+AD4APg-
+AD4APgA+- unem +ADw-- read.csv(+ACI-C:+AFwAXA-Users+AFwAXA-Rolando+AFwAXA-Documents+AFwAXA-Maestr+AO0-a en 
+AD4APgA+- Econom+AO0-a+AFwAXA-3er Semestre+AFwAXA-AEMT+AFwAXA-desempleo+AF8-est.csv+ACI-)
+AD4APgA+- names(unem)
+AD4APg- +AFs-1+AF0- +ACI-num+AF8-est+ACI- +ACI-est+ACI-     +ACI-X2000+ACI-   +ACI-X2005+ACI-   +ACI-X2010+ACI-   +ACI-X2013+ACI-
+AD4APg-
+AD4APg- I hope you can help me, this is my first time in R.
+AD4APg-
+AD4APg- Regards,
+AD4APg-
+AD4APg- Rol+AH4-
+AD4APg-
+AD4APg- +AF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXw-
+AD4APg- R-sig-Geo mailing list
+AD4APg- R-sig-Geo+AEA-r-project.org
+AD4APg- https://stat.ethz.ch/mailman/listinfo/r-sig-geo
+AD4- 
+AD4- 
+AD4- 
+AD4- +AF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXw-
+AD4- R-sig-Geo mailing list
+AD4- R-sig-Geo+AEA-r-project.org
+AD4- https://stat.ethz.ch/mailman/listinfo/r-sig-geo
+AD4- 

--
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M+APw-nster Heisenbergstra+AN8-e 2, 48149 M+APw-nster, Germany. Phone: +-49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795


From ROONEYJ4 at tcd.ie  Tue Jan  7 02:13:35 2014
From: ROONEYJ4 at tcd.ie (James Rooney)
Date: Tue, 7 Jan 2014 01:13:35 +0000
Subject: [R-sig-Geo] algorthirm to join polygons based on population
	properties
Message-ID: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE37@GOMAIL.college.tcd.ie>

Dear all,

I have dataset with very many more polygons than cases. I wish to apply Bayesian smoothing to areal disease rates, however I have too many polygons and need a smart way to combine them so that there are less overall polygons.
Bascially I need to only combine polygons of similar population density and it would be best if the new polygons have a distribution of total population that was within a limited range/normally distributed.

I can of course come up with some way of doing this myself, but I'm not keen to reinvent the wheel and so I am wondering - are there any smart algorithms already out there for doing this kind of thing ?

Thanks,
James

From Roger.Bivand at nhh.no  Tue Jan  7 09:28:48 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 7 Jan 2014 09:28:48 +0100
Subject: [R-sig-Geo] algorthirm to join polygons based on population
 properties
In-Reply-To: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE37@GOMAIL.college.tcd.ie>
References: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE37@GOMAIL.college.tcd.ie>
Message-ID: <alpine.LRH.2.03.1401070913050.2070@reclus.nhh.no>

On Tue, 7 Jan 2014, James Rooney wrote:

> Dear all,
>
> I have dataset with very many more polygons than cases. I wish to apply 
> Bayesian smoothing to areal disease rates, however I have too many 
> polygons and need a smart way to combine them so that there are less 
> overall polygons.
> Bascially I need to only combine polygons of similar population density 
> and it would be best if the new polygons have a distribution of total 
> population that was within a limited range/normally distributed.

This is not clear. Do you mean density (count/area) or just count? If you 
have "too many polygons", then probably you haven't thought through your 
sampling design - you need polygons with the correct support for the data 
collection protocol used. Are you looking at postcode polygons and sparse 
geocoded cases, with many empty postcodes? Are postcodes the relevant 
support?

If you think through support first (Gotway & Young 2002), then ad hoc 
aggregation (that's the easy part) may be replaced by appropriate 
aggregation (postcodes by health agency, surgery, etc.). The aggregation 
can be done with rgeos::gUnaryUnion, but you need a vector assigning 
polygons to aggregates first, preferably coded so that the data can be 
maptools::spCbind using well-matched row.names of the aggregated 
SpatialPolygons and data.frame objects to key on observation IDs.

First clarity on support, then aggregate polygons to appropriate support, 
then merge. Otherwise you are ignoring the uncertainty introduced into 
your Bayesian analysis by the aggregation (dfferent aggregations will give 
different results). There are good chapters on this in the Handbook of 
Spatial Statistics by Gelfand and Wakefield/Lyons.

Hope this clarifies,

Roger

>
> I can of course come up with some way of doing this myself, but I'm not 
> keen to reinvent the wheel and so I am wondering - are there any smart 
> algorithms already out there for doing this kind of thing ?
>
> Thanks,
> James
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From ROONEYJ4 at tcd.ie  Tue Jan  7 10:57:27 2014
From: ROONEYJ4 at tcd.ie (James Rooney)
Date: Tue, 7 Jan 2014 09:57:27 +0000
Subject: [R-sig-Geo] algorthirm to join polygons based on population
 properties
In-Reply-To: <alpine.LRH.2.03.1401070913050.2070@reclus.nhh.no>
References: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE37@GOMAIL.college.tcd.ie>,
	<alpine.LRH.2.03.1401070913050.2070@reclus.nhh.no>
Message-ID: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE38@GOMAIL.college.tcd.ie>

Hi Roger,

Thanks for your reply. Coding the joins is not a problem I've already done that on a smaller scale in a different project.

No postcodes in my country. I have polygon data from the census and I have geocoded cases for every case of a rare disease. This is all pretty much fixed there is nothing I can do about it. I have performed an analysis based on about 3500 polygons and that works ok. However the population data has bad maths properties. There I'm now working with newer data using 18,000 polygons and the same cases. This population data has better maths properties (i.e. population per polygon is more symmetrically distributed). But there are too many polygons - most of the polygons have no cases. So when I do Bayesian smoothing I just end up with a uniform map of Relative Risk =1 everywhere as all the polygons with cases are all surrounded by polygons with no cases.

I figure to get around this I either fiddle with the spatial weighting (seems unwise), or join polygons in some sensible fashion. My question was really wondering are there algorithms to deduce a list of polygon joins based on polygon properties. For example - I don't want to join urban and rural polygons as I am interested in the association of population density with incidence rate. I'm also interested in the relationship with social deprivation - so I don't want to join an area of high deprivation with and area of low deprivation. Basically I want to know is there a package that will create me a join list based on such rules ? I can of course write some code to do it but I was hoping not to have to spend the time on it!

James
________________________________________
From: Roger Bivand [Roger.Bivand at nhh.no]
Sent: 07 January 2014 08:28
To: James Rooney
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] algorthirm to join polygons based on population properties

On Tue, 7 Jan 2014, James Rooney wrote:

> Dear all,
>
> I have dataset with very many more polygons than cases. I wish to apply
> Bayesian smoothing to areal disease rates, however I have too many
> polygons and need a smart way to combine them so that there are less
> overall polygons.
> Bascially I need to only combine polygons of similar population density
> and it would be best if the new polygons have a distribution of total
> population that was within a limited range/normally distributed.

This is not clear. Do you mean density (count/area) or just count? If you
have "too many polygons", then probably you haven't thought through your
sampling design - you need polygons with the correct support for the data
collection protocol used. Are you looking at postcode polygons and sparse
geocoded cases, with many empty postcodes? Are postcodes the relevant
support?

If you think through support first (Gotway & Young 2002), then ad hoc
aggregation (that's the easy part) may be replaced by appropriate
aggregation (postcodes by health agency, surgery, etc.). The aggregation
can be done with rgeos::gUnaryUnion, but you need a vector assigning
polygons to aggregates first, preferably coded so that the data can be
maptools::spCbind using well-matched row.names of the aggregated
SpatialPolygons and data.frame objects to key on observation IDs.

First clarity on support, then aggregate polygons to appropriate support,
then merge. Otherwise you are ignoring the uncertainty introduced into
your Bayesian analysis by the aggregation (dfferent aggregations will give
different results). There are good chapters on this in the Handbook of
Spatial Statistics by Gelfand and Wakefield/Lyons.

Hope this clarifies,

Roger

>
> I can of course come up with some way of doing this myself, but I'm not
> keen to reinvent the wheel and so I am wondering - are there any smart
> algorithms already out there for doing this kind of thing ?
>
> Thanks,
> James
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

--
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Tue Jan  7 11:12:22 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 7 Jan 2014 11:12:22 +0100
Subject: [R-sig-Geo] algorthirm to join polygons based on population
 properties
In-Reply-To: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE38@GOMAIL.college.tcd.ie>
References: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE37@GOMAIL.college.tcd.ie>,
	<alpine.LRH.2.03.1401070913050.2070@reclus.nhh.no>
	<75C8D19A1470D344A8AF5312F01160A602BBB78CFE38@GOMAIL.college.tcd.ie>
Message-ID: <alpine.LRH.2.03.1401071102380.2422@reclus.nhh.no>

On Tue, 7 Jan 2014, James Rooney wrote:

> Hi Roger,
>
> Thanks for your reply. Coding the joins is not a problem I've already 
> done that on a smaller scale in a different project.
>
> No postcodes in my country. I have polygon data from the census and I 
> have geocoded cases for every case of a rare disease. This is all pretty 
> much fixed there is nothing I can do about it. I have performed an 
> analysis based on about 3500 polygons and that works ok. However the 
> population data has bad maths properties. There I'm now working with 
> newer data using 18,000 polygons and the same cases. This population 
> data has better maths properties (i.e. population per polygon is more 
> symmetrically distributed). But there are too many polygons - most of 
> the polygons have no cases. So when I do Bayesian smoothing I just end 
> up with a uniform map of Relative Risk =1 everywhere as all the polygons 
> with cases are all surrounded by polygons with no cases.
>
> I figure to get around this I either fiddle with the spatial weighting 
> (seems unwise), or join polygons in some sensible fashion. My question 
> was really wondering are there algorithms to deduce a list of polygon 
> joins based on polygon properties. For example - I don't want to join 
> urban and rural polygons as I am interested in the association of 
> population density with incidence rate. I'm also interested in the 
> relationship with social deprivation - so I don't want to join an area 
> of high deprivation with and area of low deprivation. Basically I want 
> to know is there a package that will create me a join list based on such 
> rules ? I can of course write some code to do it but I was hoping not to 
> have to spend the time on it!

Briefly, you have a regionalisation problem in addition to MAUP, so have a 
look at spdep::skater and the underlying paper:

Assuncao, R. M, Neves, M. C., Camara, G. and Freitas, C. da C. (2006). 
Efficient regionalization techniques for socio-economic geographical units 
using minimum spanning trees. International Journal of Geographical 
Information Science Vol. 20, No. 7, August 2006, 797-811.

However, different criteria and clustering variable subsets will give 
different output regional aggregates. You may like to check robustness by 
comparing summary statistics for the aggregates, and by comparing output 
risk values under different aggregations.

The key functions in this approach now support parallel execution, look 
carefully at the examples using the Boston dataset at the foot of the help 
page, and note the differences between Windows and Linux/OSX.

Hope this helps,

Roger


>
> James
> ________________________________________
> From: Roger Bivand [Roger.Bivand at nhh.no]
> Sent: 07 January 2014 08:28
> To: James Rooney
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] algorthirm to join polygons based on population properties
>
> On Tue, 7 Jan 2014, James Rooney wrote:
>
>> Dear all,
>>
>> I have dataset with very many more polygons than cases. I wish to apply
>> Bayesian smoothing to areal disease rates, however I have too many
>> polygons and need a smart way to combine them so that there are less
>> overall polygons.
>> Bascially I need to only combine polygons of similar population density
>> and it would be best if the new polygons have a distribution of total
>> population that was within a limited range/normally distributed.
>
> This is not clear. Do you mean density (count/area) or just count? If you
> have "too many polygons", then probably you haven't thought through your
> sampling design - you need polygons with the correct support for the data
> collection protocol used. Are you looking at postcode polygons and sparse
> geocoded cases, with many empty postcodes? Are postcodes the relevant
> support?
>
> If you think through support first (Gotway & Young 2002), then ad hoc
> aggregation (that's the easy part) may be replaced by appropriate
> aggregation (postcodes by health agency, surgery, etc.). The aggregation
> can be done with rgeos::gUnaryUnion, but you need a vector assigning
> polygons to aggregates first, preferably coded so that the data can be
> maptools::spCbind using well-matched row.names of the aggregated
> SpatialPolygons and data.frame objects to key on observation IDs.
>
> First clarity on support, then aggregate polygons to appropriate support,
> then merge. Otherwise you are ignoring the uncertainty introduced into
> your Bayesian analysis by the aggregation (dfferent aggregations will give
> different results). There are good chapters on this in the Handbook of
> Spatial Statistics by Gelfand and Wakefield/Lyons.
>
> Hope this clarifies,
>
> Roger
>
>>
>> I can of course come up with some way of doing this myself, but I'm not
>> keen to reinvent the wheel and so I am wondering - are there any smart
>> algorithms already out there for doing this kind of thing ?
>>
>> Thanks,
>> James
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From ROONEYJ4 at tcd.ie  Tue Jan  7 11:15:44 2014
From: ROONEYJ4 at tcd.ie (James Rooney)
Date: Tue, 7 Jan 2014 10:15:44 +0000
Subject: [R-sig-Geo] algorthirm to join polygons based on population
 properties
In-Reply-To: <alpine.LRH.2.03.1401071102380.2422@reclus.nhh.no>
References: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE37@GOMAIL.college.tcd.ie>,
	<alpine.LRH.2.03.1401070913050.2070@reclus.nhh.no>
	<75C8D19A1470D344A8AF5312F01160A602BBB78CFE38@GOMAIL.college.tcd.ie>,
	<alpine.LRH.2.03.1401071102380.2422@reclus.nhh.no>
Message-ID: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE39@GOMAIL.college.tcd.ie>

Ok thanks Roger I'll read up on that!

Many thanks!
James
________________________________________
From: Roger Bivand [Roger.Bivand at nhh.no]
Sent: 07 January 2014 10:12
To: James Rooney
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] algorthirm to join polygons based on population properties

On Tue, 7 Jan 2014, James Rooney wrote:

> Hi Roger,
>
> Thanks for your reply. Coding the joins is not a problem I've already
> done that on a smaller scale in a different project.
>
> No postcodes in my country. I have polygon data from the census and I
> have geocoded cases for every case of a rare disease. This is all pretty
> much fixed there is nothing I can do about it. I have performed an
> analysis based on about 3500 polygons and that works ok. However the
> population data has bad maths properties. There I'm now working with
> newer data using 18,000 polygons and the same cases. This population
> data has better maths properties (i.e. population per polygon is more
> symmetrically distributed). But there are too many polygons - most of
> the polygons have no cases. So when I do Bayesian smoothing I just end
> up with a uniform map of Relative Risk =1 everywhere as all the polygons
> with cases are all surrounded by polygons with no cases.
>
> I figure to get around this I either fiddle with the spatial weighting
> (seems unwise), or join polygons in some sensible fashion. My question
> was really wondering are there algorithms to deduce a list of polygon
> joins based on polygon properties. For example - I don't want to join
> urban and rural polygons as I am interested in the association of
> population density with incidence rate. I'm also interested in the
> relationship with social deprivation - so I don't want to join an area
> of high deprivation with and area of low deprivation. Basically I want
> to know is there a package that will create me a join list based on such
> rules ? I can of course write some code to do it but I was hoping not to
> have to spend the time on it!

Briefly, you have a regionalisation problem in addition to MAUP, so have a
look at spdep::skater and the underlying paper:

Assuncao, R. M, Neves, M. C., Camara, G. and Freitas, C. da C. (2006).
Efficient regionalization techniques for socio-economic geographical units
using minimum spanning trees. International Journal of Geographical
Information Science Vol. 20, No. 7, August 2006, 797-811.

However, different criteria and clustering variable subsets will give
different output regional aggregates. You may like to check robustness by
comparing summary statistics for the aggregates, and by comparing output
risk values under different aggregations.

The key functions in this approach now support parallel execution, look
carefully at the examples using the Boston dataset at the foot of the help
page, and note the differences between Windows and Linux/OSX.

Hope this helps,

Roger


>
> James
> ________________________________________
> From: Roger Bivand [Roger.Bivand at nhh.no]
> Sent: 07 January 2014 08:28
> To: James Rooney
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] algorthirm to join polygons based on population properties
>
> On Tue, 7 Jan 2014, James Rooney wrote:
>
>> Dear all,
>>
>> I have dataset with very many more polygons than cases. I wish to apply
>> Bayesian smoothing to areal disease rates, however I have too many
>> polygons and need a smart way to combine them so that there are less
>> overall polygons.
>> Bascially I need to only combine polygons of similar population density
>> and it would be best if the new polygons have a distribution of total
>> population that was within a limited range/normally distributed.
>
> This is not clear. Do you mean density (count/area) or just count? If you
> have "too many polygons", then probably you haven't thought through your
> sampling design - you need polygons with the correct support for the data
> collection protocol used. Are you looking at postcode polygons and sparse
> geocoded cases, with many empty postcodes? Are postcodes the relevant
> support?
>
> If you think through support first (Gotway & Young 2002), then ad hoc
> aggregation (that's the easy part) may be replaced by appropriate
> aggregation (postcodes by health agency, surgery, etc.). The aggregation
> can be done with rgeos::gUnaryUnion, but you need a vector assigning
> polygons to aggregates first, preferably coded so that the data can be
> maptools::spCbind using well-matched row.names of the aggregated
> SpatialPolygons and data.frame objects to key on observation IDs.
>
> First clarity on support, then aggregate polygons to appropriate support,
> then merge. Otherwise you are ignoring the uncertainty introduced into
> your Bayesian analysis by the aggregation (dfferent aggregations will give
> different results). There are good chapters on this in the Handbook of
> Spatial Statistics by Gelfand and Wakefield/Lyons.
>
> Hope this clarifies,
>
> Roger
>
>>
>> I can of course come up with some way of doing this myself, but I'm not
>> keen to reinvent the wheel and so I am wondering - are there any smart
>> algorithms already out there for doing this kind of thing ?
>>
>> Thanks,
>> James
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

--
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From kuroda.cpa at gmail.com  Tue Jan  7 12:19:31 2014
From: kuroda.cpa at gmail.com (Kuroda)
Date: Tue, 7 Jan 2014 20:19:31 +0900
Subject: [R-sig-Geo] algorthirm to join polygons based on population
	properties
In-Reply-To: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE39@GOMAIL.college.tcd.ie>
References: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE37@GOMAIL.college.tcd.ie>
	<alpine.LRH.2.03.1401070913050.2070@reclus.nhh.no>
	<75C8D19A1470D344A8AF5312F01160A602BBB78CFE38@GOMAIL.college.tcd.ie>
	<alpine.LRH.2.03.1401071102380.2422@reclus.nhh.no>
	<75C8D19A1470D344A8AF5312F01160A602BBB78CFE39@GOMAIL.college.tcd.ie>
Message-ID: <CAEm_FZiW8cs1yWFE4ouHDenWC_Gva9P7Y4_QGsa9x7QzgmwD=A@mail.gmail.com>

Professor Rooney:

As professor Bivand remarked, key words are "regionalization,"
"region building," "zoning design," or "constrained spatial clustering."

Cf. Duque, J. C., Ramos, R. and Surinach, J. (2007) Supervised
regionalization methods: International Regional Science Review, 30
(3), 195-220.

It might help you below...

AMOEBA
http://cran.r-project.org/web/packages/AMOEBA/
(It looks like a clustering method that provides NON-exclusive clusters)

REDCAP
http://www.spatialdatamining.org/software/redcap
As far as I know, REDCAP has not implemented in R yet, unfortunately.

I hope this helps.

Sho Kuroda

--
Sho Kuroda (Mr.)
kuroda.cpa at gmail.com



2014/1/7 James Rooney <ROONEYJ4 at tcd.ie>:
> Ok thanks Roger I'll read up on that!
>
> Many thanks!
> James
> ________________________________________
> From: Roger Bivand [Roger.Bivand at nhh.no]
> Sent: 07 January 2014 10:12
> To: James Rooney
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] algorthirm to join polygons based on population properties
>
> On Tue, 7 Jan 2014, James Rooney wrote:
>
>> Hi Roger,
>>
>> Thanks for your reply. Coding the joins is not a problem I've already
>> done that on a smaller scale in a different project.
>>
>> No postcodes in my country. I have polygon data from the census and I
>> have geocoded cases for every case of a rare disease. This is all pretty
>> much fixed there is nothing I can do about it. I have performed an
>> analysis based on about 3500 polygons and that works ok. However the
>> population data has bad maths properties. There I'm now working with
>> newer data using 18,000 polygons and the same cases. This population
>> data has better maths properties (i.e. population per polygon is more
>> symmetrically distributed). But there are too many polygons - most of
>> the polygons have no cases. So when I do Bayesian smoothing I just end
>> up with a uniform map of Relative Risk =1 everywhere as all the polygons
>> with cases are all surrounded by polygons with no cases.
>>
>> I figure to get around this I either fiddle with the spatial weighting
>> (seems unwise), or join polygons in some sensible fashion. My question
>> was really wondering are there algorithms to deduce a list of polygon
>> joins based on polygon properties. For example - I don't want to join
>> urban and rural polygons as I am interested in the association of
>> population density with incidence rate. I'm also interested in the
>> relationship with social deprivation - so I don't want to join an area
>> of high deprivation with and area of low deprivation. Basically I want
>> to know is there a package that will create me a join list based on such
>> rules ? I can of course write some code to do it but I was hoping not to
>> have to spend the time on it!
>
> Briefly, you have a regionalisation problem in addition to MAUP, so have a
> look at spdep::skater and the underlying paper:
>
> Assuncao, R. M, Neves, M. C., Camara, G. and Freitas, C. da C. (2006).
> Efficient regionalization techniques for socio-economic geographical units
> using minimum spanning trees. International Journal of Geographical
> Information Science Vol. 20, No. 7, August 2006, 797-811.
>
> However, different criteria and clustering variable subsets will give
> different output regional aggregates. You may like to check robustness by
> comparing summary statistics for the aggregates, and by comparing output
> risk values under different aggregations.
>
> The key functions in this approach now support parallel execution, look
> carefully at the examples using the Boston dataset at the foot of the help
> page, and note the differences between Windows and Linux/OSX.
>
> Hope this helps,
>
> Roger
>
>
>>
>> James
>> ________________________________________
>> From: Roger Bivand [Roger.Bivand at nhh.no]
>> Sent: 07 January 2014 08:28
>> To: James Rooney
>> Cc: r-sig-geo at r-project.org
>> Subject: Re: [R-sig-Geo] algorthirm to join polygons based on population properties
>>
>> On Tue, 7 Jan 2014, James Rooney wrote:
>>
>>> Dear all,
>>>
>>> I have dataset with very many more polygons than cases. I wish to apply
>>> Bayesian smoothing to areal disease rates, however I have too many
>>> polygons and need a smart way to combine them so that there are less
>>> overall polygons.
>>> Bascially I need to only combine polygons of similar population density
>>> and it would be best if the new polygons have a distribution of total
>>> population that was within a limited range/normally distributed.
>>
>> This is not clear. Do you mean density (count/area) or just count? If you
>> have "too many polygons", then probably you haven't thought through your
>> sampling design - you need polygons with the correct support for the data
>> collection protocol used. Are you looking at postcode polygons and sparse
>> geocoded cases, with many empty postcodes? Are postcodes the relevant
>> support?
>>
>> If you think through support first (Gotway & Young 2002), then ad hoc
>> aggregation (that's the easy part) may be replaced by appropriate
>> aggregation (postcodes by health agency, surgery, etc.). The aggregation
>> can be done with rgeos::gUnaryUnion, but you need a vector assigning
>> polygons to aggregates first, preferably coded so that the data can be
>> maptools::spCbind using well-matched row.names of the aggregated
>> SpatialPolygons and data.frame objects to key on observation IDs.
>>
>> First clarity on support, then aggregate polygons to appropriate support,
>> then merge. Otherwise you are ignoring the uncertainty introduced into
>> your Bayesian analysis by the aggregation (dfferent aggregations will give
>> different results). There are good chapters on this in the Handbook of
>> Spatial Statistics by Gelfand and Wakefield/Lyons.
>>
>> Hope this clarifies,
>>
>> Roger
>>
>>>
>>> I can of course come up with some way of doing this myself, but I'm not
>>> keen to reinvent the wheel and so I am wondering - are there any smart
>>> algorithms already out there for doing this kind of thing ?
>>>
>>> Thanks,
>>> James
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From ROONEYJ4 at tcd.ie  Tue Jan  7 15:50:55 2014
From: ROONEYJ4 at tcd.ie (James Rooney)
Date: Tue, 7 Jan 2014 14:50:55 +0000
Subject: [R-sig-Geo] algorthirm to join polygons based on population
 properties
In-Reply-To: <CAEm_FZiW8cs1yWFE4ouHDenWC_Gva9P7Y4_QGsa9x7QzgmwD=A@mail.gmail.com>
References: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE37@GOMAIL.college.tcd.ie>
	<alpine.LRH.2.03.1401070913050.2070@reclus.nhh.no>
	<75C8D19A1470D344A8AF5312F01160A602BBB78CFE38@GOMAIL.college.tcd.ie>
	<alpine.LRH.2.03.1401071102380.2422@reclus.nhh.no>
	<75C8D19A1470D344A8AF5312F01160A602BBB78CFE39@GOMAIL.college.tcd.ie>,
	<CAEm_FZiW8cs1yWFE4ouHDenWC_Gva9P7Y4_QGsa9x7QzgmwD=A@mail.gmail.com>
Message-ID: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE3B@GOMAIL.college.tcd.ie>

Dear Mr Kuroda,

Many thanks for the information. I will have to take some time to digest the various links I've been sent, and learn the new lingo!

And I appreciate the honorary promotion, but it is not 'Professor' Rooney at all!
Dr Rooney if you like titles - though I personally much prefer to be called James!

James
________________________________________
From: Kuroda [kuroda.cpa at gmail.com]
Sent: 07 January 2014 11:19
To: James Rooney
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] algorthirm to join polygons based on population properties

Professor Rooney:

As professor Bivand remarked, key words are "regionalization,"
"region building," "zoning design," or "constrained spatial clustering."

Cf. Duque, J. C., Ramos, R. and Surinach, J. (2007) Supervised
regionalization methods: International Regional Science Review, 30
(3), 195-220.

It might help you below...

AMOEBA
http://cran.r-project.org/web/packages/AMOEBA/
(It looks like a clustering method that provides NON-exclusive clusters)

REDCAP
http://www.spatialdatamining.org/software/redcap
As far as I know, REDCAP has not implemented in R yet, unfortunately.

I hope this helps.

Sho Kuroda

--
Sho Kuroda (Mr.)
kuroda.cpa at gmail.com



2014/1/7 James Rooney <ROONEYJ4 at tcd.ie>:
> Ok thanks Roger I'll read up on that!
>
> Many thanks!
> James
> ________________________________________
> From: Roger Bivand [Roger.Bivand at nhh.no]
> Sent: 07 January 2014 10:12
> To: James Rooney
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] algorthirm to join polygons based on population properties
>
> On Tue, 7 Jan 2014, James Rooney wrote:
>
>> Hi Roger,
>>
>> Thanks for your reply. Coding the joins is not a problem I've already
>> done that on a smaller scale in a different project.
>>
>> No postcodes in my country. I have polygon data from the census and I
>> have geocoded cases for every case of a rare disease. This is all pretty
>> much fixed there is nothing I can do about it. I have performed an
>> analysis based on about 3500 polygons and that works ok. However the
>> population data has bad maths properties. There I'm now working with
>> newer data using 18,000 polygons and the same cases. This population
>> data has better maths properties (i.e. population per polygon is more
>> symmetrically distributed). But there are too many polygons - most of
>> the polygons have no cases. So when I do Bayesian smoothing I just end
>> up with a uniform map of Relative Risk =1 everywhere as all the polygons
>> with cases are all surrounded by polygons with no cases.
>>
>> I figure to get around this I either fiddle with the spatial weighting
>> (seems unwise), or join polygons in some sensible fashion. My question
>> was really wondering are there algorithms to deduce a list of polygon
>> joins based on polygon properties. For example - I don't want to join
>> urban and rural polygons as I am interested in the association of
>> population density with incidence rate. I'm also interested in the
>> relationship with social deprivation - so I don't want to join an area
>> of high deprivation with and area of low deprivation. Basically I want
>> to know is there a package that will create me a join list based on such
>> rules ? I can of course write some code to do it but I was hoping not to
>> have to spend the time on it!
>
> Briefly, you have a regionalisation problem in addition to MAUP, so have a
> look at spdep::skater and the underlying paper:
>
> Assuncao, R. M, Neves, M. C., Camara, G. and Freitas, C. da C. (2006).
> Efficient regionalization techniques for socio-economic geographical units
> using minimum spanning trees. International Journal of Geographical
> Information Science Vol. 20, No. 7, August 2006, 797-811.
>
> However, different criteria and clustering variable subsets will give
> different output regional aggregates. You may like to check robustness by
> comparing summary statistics for the aggregates, and by comparing output
> risk values under different aggregations.
>
> The key functions in this approach now support parallel execution, look
> carefully at the examples using the Boston dataset at the foot of the help
> page, and note the differences between Windows and Linux/OSX.
>
> Hope this helps,
>
> Roger
>
>
>>
>> James
>> ________________________________________
>> From: Roger Bivand [Roger.Bivand at nhh.no]
>> Sent: 07 January 2014 08:28
>> To: James Rooney
>> Cc: r-sig-geo at r-project.org
>> Subject: Re: [R-sig-Geo] algorthirm to join polygons based on population properties
>>
>> On Tue, 7 Jan 2014, James Rooney wrote:
>>
>>> Dear all,
>>>
>>> I have dataset with very many more polygons than cases. I wish to apply
>>> Bayesian smoothing to areal disease rates, however I have too many
>>> polygons and need a smart way to combine them so that there are less
>>> overall polygons.
>>> Bascially I need to only combine polygons of similar population density
>>> and it would be best if the new polygons have a distribution of total
>>> population that was within a limited range/normally distributed.
>>
>> This is not clear. Do you mean density (count/area) or just count? If you
>> have "too many polygons", then probably you haven't thought through your
>> sampling design - you need polygons with the correct support for the data
>> collection protocol used. Are you looking at postcode polygons and sparse
>> geocoded cases, with many empty postcodes? Are postcodes the relevant
>> support?
>>
>> If you think through support first (Gotway & Young 2002), then ad hoc
>> aggregation (that's the easy part) may be replaced by appropriate
>> aggregation (postcodes by health agency, surgery, etc.). The aggregation
>> can be done with rgeos::gUnaryUnion, but you need a vector assigning
>> polygons to aggregates first, preferably coded so that the data can be
>> maptools::spCbind using well-matched row.names of the aggregated
>> SpatialPolygons and data.frame objects to key on observation IDs.
>>
>> First clarity on support, then aggregate polygons to appropriate support,
>> then merge. Otherwise you are ignoring the uncertainty introduced into
>> your Bayesian analysis by the aggregation (dfferent aggregations will give
>> different results). There are good chapters on this in the Handbook of
>> Spatial Statistics by Gelfand and Wakefield/Lyons.
>>
>> Hope this clarifies,
>>
>> Roger
>>
>>>
>>> I can of course come up with some way of doing this myself, but I'm not
>>> keen to reinvent the wheel and so I am wondering - are there any smart
>>> algorithms already out there for doing this kind of thing ?
>>>
>>> Thanks,
>>> James
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From jgrn at illinois.edu  Tue Jan  7 16:53:18 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Tue, 7 Jan 2014 09:53:18 -0600
Subject: [R-sig-Geo] Prototyping some new features in rasterEngine...
Message-ID: <CABG0rfuZ-RUSbs6gbfeuH5APd2DBGM8xYRzA0Fy2fNbfv7FOWw@mail.gmail.com>

Folks:

I released a new beta of spatial.tools today:

install.packages("spatial.tools", repos="http://R-Forge.R-project.org")

There are a few major new features I was hoping to get some eyes on to
work out any bugs prior to a CRAN push:

1) rasterEngine can now process and return > 1 file at a time.  The
function should return a list of arrays corresponding to each file
(each array should be the same number of rows and columns) and, if you
want the outputs to be permanent, set the filename parameter to be a
vector of output file names.
2) I'm trying out a (very) experimental feature that
byte-code-compiles your function prior to executing it (call
rasterEngine with compileFunction=TRUE).  I'm hoping for longer, more
intensive functions this may shave some time off the execution.
3) I implemented a setMinMax function that hopefully will make those
annoying warnings go away at the end.
4) I implemented Robert Hijmans hdr() function within rasterEngine
(modify with the "additional_header" parameter), and defaulted it to
ENVI.  Any output file(s) will now automatically be openable in most
GIS systems.  Note the normal "raster" header will also be created.
5) The focal function now has a "chunk" version, where the input to
your function, rather than being a single focal window at a time, is
an "unspooled" array of dimensions:
column,focal_window_length,band

Where the second dimension is the focal window "unravelled" for a
given focal position into a vector starting from the top left, moving
left-to-right, top-to-bottom.  Conceptually this is more difficult to
understand, but will allow for more rapid, vectorized processing.
Compare these two (switch the return statements with the commented-out
one to see the multiple-file-output in action):

###

install.packages("spatial.tools", repos="http://R-Forge.R-project.org")
library(spatial.tools)
# sfQuickInit() # Uncomment out to run in parallel

tahoe_highrez <- brick(system.file("external/tahoe_highrez.tif",
package="spatial.tools"))

# Single focal window function:
local_smoother <- function(x,...)
{
# Assumes a 3-d array representing
# a single local window, and return
# a single value or a vector of values.
smoothed <- apply(x,3,mean)
# Uncomment for multiple output files:
# return(list(smoothed,smoothed*100))
return(smoothed)
}
# Apply the function to a 3x3 window:
system.time(
tahoe_3x3_smoothed <-
focal_hpc(x=tahoe_highrez,fun=local_smoother,window_dims=c(3,3))
)

# "Unravelled" focal window function:
local_smoother_fast <- function(x,...)
{
x_dims <- dim(x)
x_dims_out <- c(x_dims[1],1,3)
meanx <- array(colMeans(aperm(x,c(2,1,3))),dim=x_dims_out)
# Uncomment for multiple output files:
# return(list(meanx,meanx*100))
return(meanx)
}

system.time(
tahoe_3x3_smoothed_fast <-
focal_hpc(x=tahoe_highrez,fun=local_smoother_fast,window_dims=c(3,3),processing_unit="chunk")
)

# sfQuickStop() # Uncomment out to run in parallel

###

-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From jgrn at illinois.edu  Tue Jan  7 19:34:10 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Tue, 7 Jan 2014 12:34:10 -0600
Subject: [R-sig-Geo] Prototyping some new features in rasterEngine...
In-Reply-To: <CABG0rfuZ-RUSbs6gbfeuH5APd2DBGM8xYRzA0Fy2fNbfv7FOWw@mail.gmail.com>
References: <CABG0rfuZ-RUSbs6gbfeuH5APd2DBGM8xYRzA0Fy2fNbfv7FOWw@mail.gmail.com>
Message-ID: <CABG0rft_vDYtGTK9NWJkNz9LmpZeXRufO5BCtbic454E2wNqiA@mail.gmail.com>

Doh, sent the wrong examples.  Swap in "rasterEngine" for "focal_hpc"
(generally, avoid using focal_hpc)

install.packages("spatial.tools", repos="http://R-Forge.R-project.org")
library(spatial.tools)
# sfQuickInit() # Uncomment out to run in parallel

tahoe_highrez <- brick(system.file("external/tahoe_highrez.tif",
package="spatial.tools"))

# Single focal window function:
local_smoother <- function(x,...)
{
# Assumes a 3-d array representing
# a single local window, and return
# a single value or a vector of values.
smoothed <- apply(x,3,mean)
# Uncomment for multiple output files:
# return(list(smoothed,smoothed*100))
return(smoothed)
}
# Apply the function to a 3x3 window:
system.time(
tahoe_3x3_smoothed <-
rasterEngine(x=tahoe_highrez,fun=local_smoother,window_dims=c(3,3))
)

# "Unravelled" focal window function:
local_smoother_fast <- function(x,...)
{
x_dims <- dim(x)
x_dims_out <- c(x_dims[1],1,3)
meanx <- array(colMeans(aperm(x,c(2,1,3))),dim=x_dims_out)
# Uncomment for multiple output files:
# return(list(meanx,meanx*100))
return(meanx)
}

system.time(
tahoe_3x3_smoothed_fast <-
rasterEngine(x=tahoe_highrez,fun=local_smoother_fast,window_dims=c(3,3),processing_unit="chunk")
)

# sfQuickStop() # Uncomment out to run in parallel

--j

On Tue, Jan 7, 2014 at 9:53 AM, Jonathan Greenberg <jgrn at illinois.edu> wrote:
> Folks:
>
> I released a new beta of spatial.tools today:
>
> install.packages("spatial.tools", repos="http://R-Forge.R-project.org")
>
> There are a few major new features I was hoping to get some eyes on to
> work out any bugs prior to a CRAN push:
>
> 1) rasterEngine can now process and return > 1 file at a time.  The
> function should return a list of arrays corresponding to each file
> (each array should be the same number of rows and columns) and, if you
> want the outputs to be permanent, set the filename parameter to be a
> vector of output file names.
> 2) I'm trying out a (very) experimental feature that
> byte-code-compiles your function prior to executing it (call
> rasterEngine with compileFunction=TRUE).  I'm hoping for longer, more
> intensive functions this may shave some time off the execution.
> 3) I implemented a setMinMax function that hopefully will make those
> annoying warnings go away at the end.
> 4) I implemented Robert Hijmans hdr() function within rasterEngine
> (modify with the "additional_header" parameter), and defaulted it to
> ENVI.  Any output file(s) will now automatically be openable in most
> GIS systems.  Note the normal "raster" header will also be created.
> 5) The focal function now has a "chunk" version, where the input to
> your function, rather than being a single focal window at a time, is
> an "unspooled" array of dimensions:
> column,focal_window_length,band
>
> Where the second dimension is the focal window "unravelled" for a
> given focal position into a vector starting from the top left, moving
> left-to-right, top-to-bottom.  Conceptually this is more difficult to
> understand, but will allow for more rapid, vectorized processing.
> Compare these two (switch the return statements with the commented-out
> one to see the multiple-file-output in action):
>
> ###
>
> install.packages("spatial.tools", repos="http://R-Forge.R-project.org")
> library(spatial.tools)
> # sfQuickInit() # Uncomment out to run in parallel
>
> tahoe_highrez <- brick(system.file("external/tahoe_highrez.tif",
> package="spatial.tools"))
>
> # Single focal window function:
> local_smoother <- function(x,...)
> {
> # Assumes a 3-d array representing
> # a single local window, and return
> # a single value or a vector of values.
> smoothed <- apply(x,3,mean)
> # Uncomment for multiple output files:
> # return(list(smoothed,smoothed*100))
> return(smoothed)
> }
> # Apply the function to a 3x3 window:
> system.time(
> tahoe_3x3_smoothed <-
> focal_hpc(x=tahoe_highrez,fun=local_smoother,window_dims=c(3,3))
> )
>
> # "Unravelled" focal window function:
> local_smoother_fast <- function(x,...)
> {
> x_dims <- dim(x)
> x_dims_out <- c(x_dims[1],1,3)
> meanx <- array(colMeans(aperm(x,c(2,1,3))),dim=x_dims_out)
> # Uncomment for multiple output files:
> # return(list(meanx,meanx*100))
> return(meanx)
> }
>
> system.time(
> tahoe_3x3_smoothed_fast <-
> focal_hpc(x=tahoe_highrez,fun=local_smoother_fast,window_dims=c(3,3),processing_unit="chunk")
> )
>
> # sfQuickStop() # Uncomment out to run in parallel
>
> ###
>
> --
> Jonathan A. Greenberg, PhD
> Assistant Professor
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Department of Geography and Geographic Information Science
> University of Illinois at Urbana-Champaign
> 259 Computing Applications Building, MC-150
> 605 East Springfield Avenue
> Champaign, IL  61820-6371
> Phone: 217-300-1924
> http://www.geog.illinois.edu/~jgrn/
> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From virgilio.gomez at uclm.es  Tue Jan  7 19:52:58 2014
From: virgilio.gomez at uclm.es (Virgilio =?ISO-8859-1?Q?G=F3mez-Rubio?=)
Date: Tue, 07 Jan 2014 19:52:58 +0100
Subject: [R-sig-Geo] algorthirm to join polygons based on population
 properties
In-Reply-To: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE38@GOMAIL.college.tcd.ie>
References: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE37@GOMAIL.college.tcd.ie>
	, <alpine.LRH.2.03.1401070913050.2070@reclus.nhh.no>
	<75C8D19A1470D344A8AF5312F01160A602BBB78CFE38@GOMAIL.college.tcd.ie>
Message-ID: <1389120778.2798.2.camel@virgil-HP-Compaq-8000-Elite-USDT-PC>

Dear James,

In addition to what others have suggested, you may want to try a
different modelling approach using zero-inflated models. If you are
working on a rare disease, a zero-inflated model can accommodate the
high number of zeroes better than standard models.

Best wishes,

Virgilio

On mar, 2014-01-07 at 09:57 +0000, James Rooney wrote:
> Hi Roger,
> 
> Thanks for your reply. Coding the joins is not a problem I've already done that on a smaller scale in a different project.
> 
> No postcodes in my country. I have polygon data from the census and I have geocoded cases for every case of a rare disease. This is all pretty much fixed there is nothing I can do about it. I have performed an analysis based on about 3500 polygons and that works ok. However the population data has bad maths properties. There I'm now working with newer data using 18,000 polygons and the same cases. This population data has better maths properties (i.e. population per polygon is more symmetrically distributed). But there are too many polygons - most of the polygons have no cases. So when I do Bayesian smoothing I just end up with a uniform map of Relative Risk =1 everywhere as all the polygons with cases are all surrounded by polygons with no cases.
> 
> I figure to get around this I either fiddle with the spatial weighting (seems unwise), or join polygons in some sensible fashion. My question was really wondering are there algorithms to deduce a list of polygon joins based on polygon properties. For example - I don't want to join urban and rural polygons as I am interested in the association of population density with incidence rate. I'm also interested in the relationship with social deprivation - so I don't want to join an area of high deprivation with and area of low deprivation. Basically I want to know is there a package that will create me a join list based on such rules ? I can of course write some code to do it but I was hoping not to have to spend the time on it!
> 
> James
> ________________________________________
> From: Roger Bivand [Roger.Bivand at nhh.no]
> Sent: 07 January 2014 08:28
> To: James Rooney
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] algorthirm to join polygons based on population properties
> 
> On Tue, 7 Jan 2014, James Rooney wrote:
> 
> > Dear all,
> >
> > I have dataset with very many more polygons than cases. I wish to apply
> > Bayesian smoothing to areal disease rates, however I have too many
> > polygons and need a smart way to combine them so that there are less
> > overall polygons.
> > Bascially I need to only combine polygons of similar population density
> > and it would be best if the new polygons have a distribution of total
> > population that was within a limited range/normally distributed.
> 
> This is not clear. Do you mean density (count/area) or just count? If you
> have "too many polygons", then probably you haven't thought through your
> sampling design - you need polygons with the correct support for the data
> collection protocol used. Are you looking at postcode polygons and sparse
> geocoded cases, with many empty postcodes? Are postcodes the relevant
> support?
> 
> If you think through support first (Gotway & Young 2002), then ad hoc
> aggregation (that's the easy part) may be replaced by appropriate
> aggregation (postcodes by health agency, surgery, etc.). The aggregation
> can be done with rgeos::gUnaryUnion, but you need a vector assigning
> polygons to aggregates first, preferably coded so that the data can be
> maptools::spCbind using well-matched row.names of the aggregated
> SpatialPolygons and data.frame objects to key on observation IDs.
> 
> First clarity on support, then aggregate polygons to appropriate support,
> then merge. Otherwise you are ignoring the uncertainty introduced into
> your Bayesian analysis by the aggregation (dfferent aggregations will give
> different results). There are good chapters on this in the Handbook of
> Spatial Statistics by Gelfand and Wakefield/Lyons.
> 
> Hope this clarifies,
> 
> Roger
> 
> >
> > I can of course come up with some way of doing this myself, but I'm not
> > keen to reinvent the wheel and so I am wondering - are there any smart
> > algorithms already out there for doing this kind of thing ?
> >
> > Thanks,
> > James
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> 
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From tsippel at gmail.com  Tue Jan  7 21:25:23 2014
From: tsippel at gmail.com (Tim Sippel)
Date: Tue, 7 Jan 2014 12:25:23 -0800
Subject: [R-sig-Geo] Rasterize polygons
Message-ID: <CANgNK77JF99VK-V=pywgrYO35_hSdSkULOZUqyrnTcaUdJd3Pg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140107/c3736bc9/attachment.pl>

From r.hijmans at gmail.com  Tue Jan  7 22:57:48 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 7 Jan 2014 13:57:48 -0800
Subject: [R-sig-Geo] Rasterize polygons
In-Reply-To: <CANgNK77JF99VK-V=pywgrYO35_hSdSkULOZUqyrnTcaUdJd3Pg@mail.gmail.com>
References: <CANgNK77JF99VK-V=pywgrYO35_hSdSkULOZUqyrnTcaUdJd3Pg@mail.gmail.com>
Message-ID: <CANtt_hxk3q0Gxn2UmQxeC6mVcJ5N_77p4B4b16KPv+7zHje=MQ@mail.gmail.com>

Tim,

To count the number of points (obsdeep) in each polygon, you can do:

table( over(SpatialPoints(obsdeep), poly) )

There is no role for rasterizing polygons here. But to answer your
question: you are getting a count of 1 because there is never more
than 1 polygon that matches a raster cell (no overlapping polygons).

Robert



On Tue, Jan 7, 2014 at 12:25 PM, Tim Sippel <tsippel at gmail.com> wrote:
> Hi-
> I need to count the number of observations in each of 8 polygons.  I'm
> using the raster package for this, but am having trouble getting what I
> need. Why am I getting a count of 1 in each of the polygons defined below?
>
> Sample data can be downloaded here:
> https://drive.google.com/file/d/0B0d3zfSSPFQsVS04aExhbl9hUU0/edit?usp=sharing
>
>
> library(raster)
>
> #polygons
> reg1<-Polygon(coords=cbind(c(200,220,220,200,200), c(0,0,10,10,0)));
> r1<-Polygons(list(reg1), 'reg1')
> reg2<-Polygon(coords=cbind(c(185,200,200,185,185), c(0,0,10,10,0)));
> r2<-Polygons(list(reg2), 'reg2')
> reg3<-Polygon(coords=cbind(c(200,225,225,200,200), c(10,10,20,20,10)));
> r3<-Polygons(list(reg3), 'reg3')
> reg4<-Polygon(coords=cbind(c(180,200,200,180,180), c(10,10,20,20,10)));
> r4<-Polygons(list(reg4), 'reg4')
> reg5<-Polygon(coords=cbind(c(200,225,225,200,200), c(20,20,30,30,20)));
> r5<-Polygons(list(reg5), 'reg5')
> reg6<-Polygon(coords=cbind(c(180,200,200,180,180), c(20,20,30,30,20)));
> r6<-Polygons(list(reg6), 'reg6')
> reg7<-Polygon(coords=cbind(c(200,235,235,200,200), c(30,30,45,45,30)));
> r7<-Polygons(list(reg7), 'reg7')
> reg8<-Polygon(coords=cbind(c(180,200,200,180,180), c(30,30,45,45,30)));
> r8<-Polygons(list(reg8), 'reg8')
> poly<-SpatialPolygons(Srl=list(r1,r2,r3,r4,r5,r6,r7,r8), pO=1:8)
>
> #raster setup
> xmn=170; xmx=240; ymn=-5; ymx=50
> grid<-raster(nrows=length(seq(ymn,ymx,by=5))-1,
> ncols=length(seq(xmn,xmx,by=5))-1, xmn=xmn, xmx=xmx, ymn=ymn, ymx=ymx); grid
>
> # rasterize & plot
> obsdeep<-rasterize(x=poly, y=grid, field=obs.deep$Longitude1, fun="count")
> plot(obsdeep); plot(poly, add=T)
>
> Many thanks,
>
> Tim
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From ROONEYJ4 at tcd.ie  Wed Jan  8 00:56:07 2014
From: ROONEYJ4 at tcd.ie (James Rooney)
Date: Tue, 7 Jan 2014 23:56:07 +0000
Subject: [R-sig-Geo] algorthirm to join polygons based on population
 properties
In-Reply-To: <1389120778.2798.2.camel@virgil-HP-Compaq-8000-Elite-USDT-PC>
References: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE37@GOMAIL.college.tcd.ie>	,
	<alpine.LRH.2.03.1401070913050.2070@reclus.nhh.no>
	<75C8D19A1470D344A8AF5312F01160A602BBB78CFE38@GOMAIL.college.tcd.ie>,
	<1389120778.2798.2.camel@virgil-HP-Compaq-8000-Elite-USDT-PC>
Message-ID: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE3C@GOMAIL.college.tcd.ie>

Dear Virgilio,

Thanks very much for the suggestion. I'll read up on it too! 

James
________________________________________
From: Virgilio G?mez-Rubio [virgilio.gomez at uclm.es]
Sent: 07 January 2014 18:52
To: James Rooney
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] algorthirm to join polygons based on population properties

Dear James,

In addition to what others have suggested, you may want to try a
different modelling approach using zero-inflated models. If you are
working on a rare disease, a zero-inflated model can accommodate the
high number of zeroes better than standard models.

Best wishes,

Virgilio

On mar, 2014-01-07 at 09:57 +0000, James Rooney wrote:
> Hi Roger,
>
> Thanks for your reply. Coding the joins is not a problem I've already done that on a smaller scale in a different project.
>
> No postcodes in my country. I have polygon data from the census and I have geocoded cases for every case of a rare disease. This is all pretty much fixed there is nothing I can do about it. I have performed an analysis based on about 3500 polygons and that works ok. However the population data has bad maths properties. There I'm now working with newer data using 18,000 polygons and the same cases. This population data has better maths properties (i.e. population per polygon is more symmetrically distributed). But there are too many polygons - most of the polygons have no cases. So when I do Bayesian smoothing I just end up with a uniform map of Relative Risk =1 everywhere as all the polygons with cases are all surrounded by polygons with no cases.
>
> I figure to get around this I either fiddle with the spatial weighting (seems unwise), or join polygons in some sensible fashion. My question was really wondering are there algorithms to deduce a list of polygon joins based on polygon properties. For example - I don't want to join urban and rural polygons as I am interested in the association of population density with incidence rate. I'm also interested in the relationship with social deprivation - so I don't want to join an area of high deprivation with and area of low deprivation. Basically I want to know is there a package that will create me a join list based on such rules ? I can of course write some code to do it but I was hoping not to have to spend the time on it!
>
> James
> ________________________________________
> From: Roger Bivand [Roger.Bivand at nhh.no]
> Sent: 07 January 2014 08:28
> To: James Rooney
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] algorthirm to join polygons based on population properties
>
> On Tue, 7 Jan 2014, James Rooney wrote:
>
> > Dear all,
> >
> > I have dataset with very many more polygons than cases. I wish to apply
> > Bayesian smoothing to areal disease rates, however I have too many
> > polygons and need a smart way to combine them so that there are less
> > overall polygons.
> > Bascially I need to only combine polygons of similar population density
> > and it would be best if the new polygons have a distribution of total
> > population that was within a limited range/normally distributed.
>
> This is not clear. Do you mean density (count/area) or just count? If you
> have "too many polygons", then probably you haven't thought through your
> sampling design - you need polygons with the correct support for the data
> collection protocol used. Are you looking at postcode polygons and sparse
> geocoded cases, with many empty postcodes? Are postcodes the relevant
> support?
>
> If you think through support first (Gotway & Young 2002), then ad hoc
> aggregation (that's the easy part) may be replaced by appropriate
> aggregation (postcodes by health agency, surgery, etc.). The aggregation
> can be done with rgeos::gUnaryUnion, but you need a vector assigning
> polygons to aggregates first, preferably coded so that the data can be
> maptools::spCbind using well-matched row.names of the aggregated
> SpatialPolygons and data.frame objects to key on observation IDs.
>
> First clarity on support, then aggregate polygons to appropriate support,
> then merge. Otherwise you are ignoring the uncertainty introduced into
> your Bayesian analysis by the aggregation (dfferent aggregations will give
> different results). There are good chapters on this in the Handbook of
> Spatial Statistics by Gelfand and Wakefield/Lyons.
>
> Hope this clarifies,
>
> Roger
>
> >
> > I can of course come up with some way of doing this myself, but I'm not
> > keen to reinvent the wheel and so I am wondering - are there any smart
> > algorithms already out there for doing this kind of thing ?
> >
> > Thanks,
> > James
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From tsippel at gmail.com  Wed Jan  8 02:17:24 2014
From: tsippel at gmail.com (Tim Sippel)
Date: Tue, 7 Jan 2014 17:17:24 -0800
Subject: [R-sig-Geo] Rasterize polygons
In-Reply-To: <CANtt_hxk3q0Gxn2UmQxeC6mVcJ5N_77p4B4b16KPv+7zHje=MQ@mail.gmail.com>
References: <CANgNK77JF99VK-V=pywgrYO35_hSdSkULOZUqyrnTcaUdJd3Pg@mail.gmail.com>
	<CANtt_hxk3q0Gxn2UmQxeC6mVcJ5N_77p4B4b16KPv+7zHje=MQ@mail.gmail.com>
Message-ID: <CANgNK76hZH6LhLsmBQ8U8rDLrX3Y-bbpmT8BAn1A21278rxJOA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140107/71454a56/attachment.pl>

From cmora at dal.ca  Wed Jan  8 08:36:49 2014
From: cmora at dal.ca (Camilo Mora)
Date: Wed, 08 Jan 2014 03:36:49 -0400
Subject: [R-sig-Geo] Raster in parallel computing?
Message-ID: <20140108033649.17751q89tghr47xc@wm3.dal.ca>

Hi everyone,

I am using the package "raster" to interpolate a large number of  
rasters (~1million) of different resolutions to a unique 1degree  
resolution grid and wonder if you know if it is possible to do this in  
parallel computer?.

My code (example below) works like a charm but it will take 30 days to  
process all the rasters. Sadly, the process only uses one core of my  
computer. I wonder if there is a way to run this code (example below)  
in parallel computer?.

Thanks,

Camilo

####TEST CODE######
library (raster)

#creates 3 test rasters
a <- raster(nrow=3, ncol=3)
a[] <- 1:9

b <- raster(nrow=3, ncol=3)
b[] <- 10:18

c <- raster(nrow=3, ncol=3)
c[] <- 19:27

#concatenates the rasters
d<-brick(a,b,c)

#creates a raster at a different resolution
s <- raster(nrow=10, ncol=10)

#interpolates data from the brick to the new resolution
s <- resample(d, s, method='bilinear')


From roman.lustrik at gmail.com  Wed Jan  8 09:28:23 2014
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Wed, 8 Jan 2014 09:28:23 +0100
Subject: [R-sig-Geo] Raster in parallel computing?
In-Reply-To: <20140108033649.17751q89tghr47xc@wm3.dal.ca>
References: <20140108033649.17751q89tghr47xc@wm3.dal.ca>
Message-ID: <CAHT1vpia9Ae8Mo9Xgh5BrT7GYGFieHiwBxONbkCi0WEui92jqg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140108/2aafada2/attachment.ksh>

From Roger.Bivand at nhh.no  Wed Jan  8 12:18:58 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 8 Jan 2014 12:18:58 +0100
Subject: [R-sig-Geo] Raster in parallel computing?
In-Reply-To: <20140108033649.17751q89tghr47xc@wm3.dal.ca>
References: <20140108033649.17751q89tghr47xc@wm3.dal.ca>
Message-ID: <alpine.LRH.2.03.1401081214220.7518@reclus.nhh.no>

Did you notice the thread started yesterday that appears to meet your 
need:

https://stat.ethz.ch/pipermail/r-sig-geo/2014-January/020156.html

It is always a good idea to look at the list archives, a search on:

"list:R-sig-geo raster parallel"

gives a number of potentially interesting hits. You could then preface 
your posting by saying that you have already tried some possible 
solutions, and would like help with them.

Roger

On Wed, 8 Jan 2014, Camilo Mora wrote:

> Hi everyone,
>
> I am using the package "raster" to interpolate a large number of rasters 
> (~1million) of different resolutions to a unique 1degree resolution grid and 
> wonder if you know if it is possible to do this in parallel computer?.
>
> My code (example below) works like a charm but it will take 30 days to 
> process all the rasters. Sadly, the process only uses one core of my 
> computer. I wonder if there is a way to run this code (example below) in 
> parallel computer?.
>
> Thanks,
>
> Camilo
>
> ####TEST CODE######
> library (raster)
>
> #creates 3 test rasters
> a <- raster(nrow=3, ncol=3)
> a[] <- 1:9
>
> b <- raster(nrow=3, ncol=3)
> b[] <- 10:18
>
> c <- raster(nrow=3, ncol=3)
> c[] <- 19:27
>
> #concatenates the rasters
> d<-brick(a,b,c)
>
> #creates a raster at a different resolution
> s <- raster(nrow=10, ncol=10)
>
> #interpolates data from the brick to the new resolution
> s <- resample(d, s, method='bilinear')
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From matteo.mattiuzzi at boku.ac.at  Wed Jan  8 15:01:00 2014
From: matteo.mattiuzzi at boku.ac.at (Matteo Mattiuzzi)
Date: Wed, 08 Jan 2014 15:01:00 +0100
Subject: [R-sig-Geo] Raster in parallel computing?
In-Reply-To: <20140108033649.17751q89tghr47xc@wm3.dal.ca>
References: <20140108033649.17751q89tghr47xc@wm3.dal.ca>
Message-ID: <52CD682C020000270001E766@gwia2.boku.ac.at>

Camillo,
I think your example is missing important information, especially the context of this processing step, that matters a lot for the solution to choose.
based on you example I could suggest you to try something like that:


library(raster)
#creates 3 test rasters
a <- raster(nrow=3, ncol=3)
a[] <- 1:9


b <- raster(nrow=3, ncol=3)
b[] <- 10:18


c <- raster(nrow=3, ncol=3)
c[] <- 19:27


#concatenates the rasters
# d<-brick(a,b,c) # I have removed this as it is not meaningful for the testrun
infiles <- list(a,b,c)


#creates a raster at a different resolution
s <- raster(nrow=10, ncol=10)
#####


beginCluster() # see help
cl<-getCluster() 
exportCluster(cl,"s") # export to cluster the target raster 's', so it is available to resample fun.
res <- parLapply(cl,infiles,fun=function(x){resample(x,s)}) # I can imagine you need the filename argument in ?resample, this could be added here (in fun) 


I'm not sure what happenes having 1million of files open, using the 'filename' argument and overwriting the result of xx<-resample(x,s) maybe this could be avoided (here a idea that should work if files are on disk filename(a)!="" and not created as in your example):
 
#not tested!
parfun <- function(x){
inname <- filename(x)
outname <- gsub(inname,pattern=paste0(extension(inname),"$"),replacement=paste0("_resampled",extension(inname),"$")) # 
xx<- resample(x,s,filename=outname, method='bilinear')
return(NULL)}


res <- parLapply(cl,infiles,fun=parfun) # result is on disk and not in your R session (res).



Matteo


>>> Camilo Mora <cmora at dal.ca> 01/08/14 8:40 AM >>>
Hi everyone,

I am using the package "raster" to interpolate a large number of  
rasters (~1million) of different resolutions to a unique 1degree  
resolution grid and wonder if you know if it is possible to do this in  
parallel computer?.

My code (example below) works like a charm but it will take 30 days to  
process all the rasters. Sadly, the process only uses one core of my  
computer. I wonder if there is a way to run this code (example below)  
in parallel computer?.

Thanks,

Camilo

####TEST CODE######
library (raster)

#creates 3 test rasters
a <- raster(nrow=3, ncol=3)
a[] <- 1:9

b <- raster(nrow=3, ncol=3)
b[] <- 10:18

c <- raster(nrow=3, ncol=3)
c[] <- 19:27

#concatenates the rasters
d<-brick(a,b,c)

#creates a raster at a different resolution
s <- raster(nrow=10, ncol=10)

#interpolates data from the brick to the new resolution
s <- resample(d, s, method='bilinear')

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From ROONEYJ4 at tcd.ie  Wed Jan  8 16:37:01 2014
From: ROONEYJ4 at tcd.ie (James Rooney)
Date: Wed, 8 Jan 2014 15:37:01 +0000
Subject: [R-sig-Geo] algorthirm to join polygons based on population
 properties
In-Reply-To: <alpine.LRH.2.03.1401071102380.2422@reclus.nhh.no>
References: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE37@GOMAIL.college.tcd.ie>,
	<alpine.LRH.2.03.1401070913050.2070@reclus.nhh.no>
	<75C8D19A1470D344A8AF5312F01160A602BBB78CFE38@GOMAIL.college.tcd.ie>,
	<alpine.LRH.2.03.1401071102380.2422@reclus.nhh.no>
Message-ID: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE3D@GOMAIL.college.tcd.ie>

Hi Roger,

I have been trying to recreate the Boston example using my data set.
I am running into an error with the nbcosts command that I don't understand.

> lcosts <-nbcosts(SAPs.nb,dpad)
Error in nbcosts(SAPs.nb, dpad) : nbcosts:26disjoint connected subgraphs

SAPs.nb is the neighbourhood matrix.

What does this error mean ? I have not been able to understand it despite reading the help files.

Thanks,
James

________________________________________
From: Roger Bivand [Roger.Bivand at nhh.no]
Sent: 07 January 2014 10:12
To: James Rooney
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] algorthirm to join polygons based on population properties

On Tue, 7 Jan 2014, James Rooney wrote:

> Hi Roger,
>
> Thanks for your reply. Coding the joins is not a problem I've already
> done that on a smaller scale in a different project.
>
> No postcodes in my country. I have polygon data from the census and I
> have geocoded cases for every case of a rare disease. This is all pretty
> much fixed there is nothing I can do about it. I have performed an
> analysis based on about 3500 polygons and that works ok. However the
> population data has bad maths properties. There I'm now working with
> newer data using 18,000 polygons and the same cases. This population
> data has better maths properties (i.e. population per polygon is more
> symmetrically distributed). But there are too many polygons - most of
> the polygons have no cases. So when I do Bayesian smoothing I just end
> up with a uniform map of Relative Risk =1 everywhere as all the polygons
> with cases are all surrounded by polygons with no cases.
>
> I figure to get around this I either fiddle with the spatial weighting
> (seems unwise), or join polygons in some sensible fashion. My question
> was really wondering are there algorithms to deduce a list of polygon
> joins based on polygon properties. For example - I don't want to join
> urban and rural polygons as I am interested in the association of
> population density with incidence rate. I'm also interested in the
> relationship with social deprivation - so I don't want to join an area
> of high deprivation with and area of low deprivation. Basically I want
> to know is there a package that will create me a join list based on such
> rules ? I can of course write some code to do it but I was hoping not to
> have to spend the time on it!

Briefly, you have a regionalisation problem in addition to MAUP, so have a
look at spdep::skater and the underlying paper:

Assuncao, R. M, Neves, M. C., Camara, G. and Freitas, C. da C. (2006).
Efficient regionalization techniques for socio-economic geographical units
using minimum spanning trees. International Journal of Geographical
Information Science Vol. 20, No. 7, August 2006, 797-811.

However, different criteria and clustering variable subsets will give
different output regional aggregates. You may like to check robustness by
comparing summary statistics for the aggregates, and by comparing output
risk values under different aggregations.

The key functions in this approach now support parallel execution, look
carefully at the examples using the Boston dataset at the foot of the help
page, and note the differences between Windows and Linux/OSX.

Hope this helps,

Roger


>
> James
> ________________________________________
> From: Roger Bivand [Roger.Bivand at nhh.no]
> Sent: 07 January 2014 08:28
> To: James Rooney
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] algorthirm to join polygons based on population properties
>
> On Tue, 7 Jan 2014, James Rooney wrote:
>
>> Dear all,
>>
>> I have dataset with very many more polygons than cases. I wish to apply
>> Bayesian smoothing to areal disease rates, however I have too many
>> polygons and need a smart way to combine them so that there are less
>> overall polygons.
>> Bascially I need to only combine polygons of similar population density
>> and it would be best if the new polygons have a distribution of total
>> population that was within a limited range/normally distributed.
>
> This is not clear. Do you mean density (count/area) or just count? If you
> have "too many polygons", then probably you haven't thought through your
> sampling design - you need polygons with the correct support for the data
> collection protocol used. Are you looking at postcode polygons and sparse
> geocoded cases, with many empty postcodes? Are postcodes the relevant
> support?
>
> If you think through support first (Gotway & Young 2002), then ad hoc
> aggregation (that's the easy part) may be replaced by appropriate
> aggregation (postcodes by health agency, surgery, etc.). The aggregation
> can be done with rgeos::gUnaryUnion, but you need a vector assigning
> polygons to aggregates first, preferably coded so that the data can be
> maptools::spCbind using well-matched row.names of the aggregated
> SpatialPolygons and data.frame objects to key on observation IDs.
>
> First clarity on support, then aggregate polygons to appropriate support,
> then merge. Otherwise you are ignoring the uncertainty introduced into
> your Bayesian analysis by the aggregation (dfferent aggregations will give
> different results). There are good chapters on this in the Handbook of
> Spatial Statistics by Gelfand and Wakefield/Lyons.
>
> Hope this clarifies,
>
> Roger
>
>>
>> I can of course come up with some way of doing this myself, but I'm not
>> keen to reinvent the wheel and so I am wondering - are there any smart
>> algorithms already out there for doing this kind of thing ?
>>
>> Thanks,
>> James
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

--
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From cmora at DAL.CA  Wed Jan  8 19:00:17 2014
From: cmora at DAL.CA (Camilo Mora)
Date: Wed, 08 Jan 2014 14:00:17 -0400
Subject: [R-sig-Geo] Raster in parallel computing?
In-Reply-To: <alpine.LRH.2.03.1401081214220.7518@reclus.nhh.no>
References: <20140108033649.17751q89tghr47xc@wm3.dal.ca>
	<alpine.LRH.2.03.1401081214220.7518@reclus.nhh.no>
Message-ID: <20140108140017.6646792e0f73erk0@wm3.dal.ca>

Thank you Roger,

Yes I should have mentioned that I have looked extensively over this  
question. Curiously, Jonathan From "spatial.tools" provided me with  
some advice as his tool at the current time does not run the function  
"resample".

Thanks again,

Camilo



Quoting Roger Bivand <Roger.Bivand at nhh.no>:

> Did you notice the thread started yesterday that appears to meet your need:
>
> https://stat.ethz.ch/pipermail/r-sig-geo/2014-January/020156.html
>
> It is always a good idea to look at the list archives, a search on:
>
> "list:R-sig-geo raster parallel"
>
> gives a number of potentially interesting hits. You could then  
> preface your posting by saying that you have already tried some  
> possible solutions, and would like help with them.
>
> Roger
>
> On Wed, 8 Jan 2014, Camilo Mora wrote:
>
>> Hi everyone,
>>
>> I am using the package "raster" to interpolate a large number of  
>> rasters (~1million) of different resolutions to a unique 1degree  
>> resolution grid and wonder if you know if it is possible to do this  
>> in parallel computer?.
>>
>> My code (example below) works like a charm but it will take 30 days  
>> to process all the rasters. Sadly, the process only uses one core  
>> of my computer. I wonder if there is a way to run this code  
>> (example below) in parallel computer?.
>>
>> Thanks,
>>
>> Camilo
>>
>> ####TEST CODE######
>> library (raster)
>>
>> #creates 3 test rasters
>> a <- raster(nrow=3, ncol=3)
>> a[] <- 1:9
>>
>> b <- raster(nrow=3, ncol=3)
>> b[] <- 10:18
>>
>> c <- raster(nrow=3, ncol=3)
>> c[] <- 19:27
>>
>> #concatenates the rasters
>> d<-brick(a,b,c)
>>
>> #creates a raster at a different resolution
>> s <- raster(nrow=10, ncol=10)
>>
>> #interpolates data from the brick to the new resolution
>> s <- resample(d, s, method='bilinear')
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> -- 
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>
>


From jgrn at illinois.edu  Wed Jan  8 20:13:03 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Wed, 8 Jan 2014 13:13:03 -0600
Subject: [R-sig-Geo] Raster in parallel computing?
In-Reply-To: <20140108140017.6646792e0f73erk0@wm3.dal.ca>
References: <20140108033649.17751q89tghr47xc@wm3.dal.ca>
	<alpine.LRH.2.03.1401081214220.7518@reclus.nhh.no>
	<20140108140017.6646792e0f73erk0@wm3.dal.ca>
Message-ID: <CABG0rfuzmggnA07u2jiqoxgN73Jks_VrRSQy3G2hTDTt_kipGA@mail.gmail.com>

Hi all:

Wanted to respond a bit to this thread.  rasterEngine is designed for
parallel processing a single file (via chunking the inputs and parsing
each chunk to a different worker).  I do have a parallel resample
algorithm on my radar, and I think I could adapt it for use with
rasterEngine.  However, this particular test case, that many files
need a highly optimized system, so I think would benefit from:

1) Using e.g. gdalwarp natively from GDAL, which should be a lot
faster than any resampling techniques I've seen in any software
package.  You can use gdalUtils for a within-R wrapper for the core
GDAL binaries:
install.packages("gdalUtils", repos="http://R-Forge.R-project.org")

Note that I just pushed version 0.2.0 to both r-forge and to CRAN.
Waiting to hear from CRAN, as soon as they accept it I'll make a
general announcement.

2) As Matteo mentioned, the "unit" of parallelization with that many
files should be the file itself (not within-file parallelization).  In
general, I recommend you develop your parallel code using foreach, and
then use whatever parallel backend you want.  "parallel" is now built
into the core R, so you might want to stick with that as a backend
rather than snow/snowfall.  foreach is, in my opinion, conceptually
easier than the other parallel packages, and is also very flexible
(you can move your code from a single, multicore machine to an OpenMPI
cluster with little effort).  This will only execute the resampling
one per worker, so multiple files being open shouldn't be an issue
(since if you have 8 workers, you'll only have 8 files open at a
time).

To be clear, we're talking about the difference between:
(what rasterEngine does):
fileA -> fileA_chunk1 -> worker1
        -> fileA_chunk2 -> worker2

(what Matteo and I are proposing):
fileA -> worker1
fileB -> worker2

Be aware that resampling is I/O intensive, so parallel processing the
files may not give you much (or any) benefit, if you are on a single
hard drive.  Even minor tweaks like reading from one drive and writing
to another may generate some additional speed.

If you've never learned parallel computing in R, I HIGHLY recommend
working through:
http://trg.apbionet.org/euasiagrid/docs/parallelR.notes.pdf

This is the best tutorial I've seen on parallel computing in R.
Wherever it says library("snow") I'd recommend switching that with
library("parallel"), and pay attention to the foreach discussion.

--j



On Wed, Jan 8, 2014 at 12:00 PM, Camilo Mora <cmora at dal.ca> wrote:
> Thank you Roger,
>
> Yes I should have mentioned that I have looked extensively over this
> question. Curiously, Jonathan From "spatial.tools" provided me with some
> advice as his tool at the current time does not run the function "resample".
>
> Thanks again,
>
> Camilo
>
>
>
>
> Quoting Roger Bivand <Roger.Bivand at nhh.no>:
>
>> Did you notice the thread started yesterday that appears to meet your
>> need:
>>
>> https://stat.ethz.ch/pipermail/r-sig-geo/2014-January/020156.html
>>
>> It is always a good idea to look at the list archives, a search on:
>>
>> "list:R-sig-geo raster parallel"
>>
>> gives a number of potentially interesting hits. You could then preface
>> your posting by saying that you have already tried some possible solutions,
>> and would like help with them.
>>
>> Roger
>>
>> On Wed, 8 Jan 2014, Camilo Mora wrote:
>>
>>> Hi everyone,
>>>
>>> I am using the package "raster" to interpolate a large number of rasters
>>> (~1million) of different resolutions to a unique 1degree resolution grid and
>>> wonder if you know if it is possible to do this in parallel computer?.
>>>
>>> My code (example below) works like a charm but it will take 30 days to
>>> process all the rasters. Sadly, the process only uses one core of my
>>> computer. I wonder if there is a way to run this code (example below) in
>>> parallel computer?.
>>>
>>> Thanks,
>>>
>>> Camilo
>>>
>>> ####TEST CODE######
>>> library (raster)
>>>
>>> #creates 3 test rasters
>>> a <- raster(nrow=3, ncol=3)
>>> a[] <- 1:9
>>>
>>> b <- raster(nrow=3, ncol=3)
>>> b[] <- 10:18
>>>
>>> c <- raster(nrow=3, ncol=3)
>>> c[] <- 19:27
>>>
>>> #concatenates the rasters
>>> d<-brick(a,b,c)
>>>
>>> #creates a raster at a different resolution
>>> s <- raster(nrow=10, ncol=10)
>>>
>>> #interpolates data from the brick to the new resolution
>>> s <- resample(d, s, method='bilinear')
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From r.hijmans at gmail.com  Wed Jan  8 20:27:26 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 8 Jan 2014 11:27:26 -0800
Subject: [R-sig-Geo] Raster in parallel computing?
In-Reply-To: <20140108140017.6646792e0f73erk0@wm3.dal.ca>
References: <20140108033649.17751q89tghr47xc@wm3.dal.ca>
	<alpine.LRH.2.03.1401081214220.7518@reclus.nhh.no>
	<20140108140017.6646792e0f73erk0@wm3.dal.ca>
Message-ID: <CANtt_hwiQOqz_7m_OFiUVAyvr3X1AmkMrdiex_yuBVnz=-bivQ@mail.gmail.com>

Camilo,

The simplest approach is below, but that is inefficient here, at least
in this example, as this is designed to work for large files
that are processes in chunks. The problem here is not that the files
are large, but that they are many.
This uses beginCluster from the raster package. Normally you would
need to use clusterR, which does not work for resample; but resample
has build-in support.

beginCluster()

res <- list()
#for (i in 1:length(v)) {
for (i in 1:10) { # subset for the example
f <- paste0(path, 'r_', i, '.tif')
res[i] <- resample(v[[i]], s, method='bilinear', filename=f, overwrite=TRUE)
}

# However, if the rasters (or groups) have the same dimensions:
ss <- stack(v)
rs <- resample(v[[i]], s, method='bilinear', filename='test.tif',
overwrite=TRUE)

endCluster()


# Alternatively:


library(doParallel)
library(foreach)
registerDoParallel(cl = detectCores()-2) #choose how many cores
getDoParWorkers()
x <- foreach(i = 1:length(v), .packages = "raster") %dopar% {
f <- paste0(path, 'r_', i, '.tif')
resample(v[[i]], s, method='bilinear', filename=f, overwrite=TRUE)
}

# Or in groups

x <- foreach(i = 1:10, .packages = "raster") %dopar% {
f <- paste0(path, 'r_', i, '.tif')
j <- (i-1)*10+1
d <- stack(v[j:(j+9)])
resample(d, s, method='bilinear', filename=f, overwrite=TRUE)
}





On Wed, Jan 8, 2014 at 10:00 AM, Camilo Mora <cmora at dal.ca> wrote:
> Thank you Roger,
>
> Yes I should have mentioned that I have looked extensively over this
> question. Curiously, Jonathan From "spatial.tools" provided me with some
> advice as his tool at the current time does not run the function "resample".
>
> Thanks again,
>
> Camilo
>
>
>
>
> Quoting Roger Bivand <Roger.Bivand at nhh.no>:
>
>> Did you notice the thread started yesterday that appears to meet your
>> need:
>>
>> https://stat.ethz.ch/pipermail/r-sig-geo/2014-January/020156.html
>>
>> It is always a good idea to look at the list archives, a search on:
>>
>> "list:R-sig-geo raster parallel"
>>
>> gives a number of potentially interesting hits. You could then preface
>> your posting by saying that you have already tried some possible solutions,
>> and would like help with them.
>>
>> Roger
>>
>> On Wed, 8 Jan 2014, Camilo Mora wrote:
>>
>>> Hi everyone,
>>>
>>> I am using the package "raster" to interpolate a large number of rasters
>>> (~1million) of different resolutions to a unique 1degree resolution grid and
>>> wonder if you know if it is possible to do this in parallel computer?.
>>>
>>> My code (example below) works like a charm but it will take 30 days to
>>> process all the rasters. Sadly, the process only uses one core of my
>>> computer. I wonder if there is a way to run this code (example below) in
>>> parallel computer?.
>>>
>>> Thanks,
>>>
>>> Camilo
>>>
>>> ####TEST CODE######
>>> library (raster)
>>>
>>> #creates 3 test rasters
>>> a <- raster(nrow=3, ncol=3)
>>> a[] <- 1:9
>>>
>>> b <- raster(nrow=3, ncol=3)
>>> b[] <- 10:18
>>>
>>> c <- raster(nrow=3, ncol=3)
>>> c[] <- 19:27
>>>
>>> #concatenates the rasters
>>> d<-brick(a,b,c)
>>>
>>> #creates a raster at a different resolution
>>> s <- raster(nrow=10, ncol=10)
>>>
>>> #interpolates data from the brick to the new resolution
>>> s <- resample(d, s, method='bilinear')
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Wed Jan  8 20:37:45 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 8 Jan 2014 11:37:45 -0800
Subject: [R-sig-Geo] Raster in parallel computing?
In-Reply-To: <CABG0rfuzmggnA07u2jiqoxgN73Jks_VrRSQy3G2hTDTt_kipGA@mail.gmail.com>
References: <20140108033649.17751q89tghr47xc@wm3.dal.ca>
	<alpine.LRH.2.03.1401081214220.7518@reclus.nhh.no>
	<20140108140017.6646792e0f73erk0@wm3.dal.ca>
	<CABG0rfuzmggnA07u2jiqoxgN73Jks_VrRSQy3G2hTDTt_kipGA@mail.gmail.com>
Message-ID: <CANtt_hxkmCXrNuu0Jm_ZjcNw2x4i2hD2cGiyOfB0tCRoaAdxKQ@mail.gmail.com>

Jonathan,

Thanks for that useful guidance. You write that "resampling is I/O
intensive, so parallel processing the files may not give you much (or
any) benefit". I do not think that is true. Comparted to other
functions resample is relatively slow because it needs to match all
the old cells to the new cells, which is -- in its current simple
implementation -- rather CPU intensive.

By using a Stack (or Brick), the number of computations needed is
strongly reduced. So I think the first step to this problem is to
group sets of rasters and stack these. After that, the build in
support for might be more efficient than the foreach approach that I
showed, but I would not bet on that. A simple way to improve I/O, see
?rasterOptions (increase chunksize and maxmemory), but be conservative
with that when also using parallel computing.

Robert


On Wed, Jan 8, 2014 at 11:13 AM, Jonathan Greenberg <jgrn at illinois.edu> wrote:
> Hi all:
>
> Wanted to respond a bit to this thread.  rasterEngine is designed for
> parallel processing a single file (via chunking the inputs and parsing
> each chunk to a different worker).  I do have a parallel resample
> algorithm on my radar, and I think I could adapt it for use with
> rasterEngine.  However, this particular test case, that many files
> need a highly optimized system, so I think would benefit from:
>
> 1) Using e.g. gdalwarp natively from GDAL, which should be a lot
> faster than any resampling techniques I've seen in any software
> package.  You can use gdalUtils for a within-R wrapper for the core
> GDAL binaries:
> install.packages("gdalUtils", repos="http://R-Forge.R-project.org")
>
> Note that I just pushed version 0.2.0 to both r-forge and to CRAN.
> Waiting to hear from CRAN, as soon as they accept it I'll make a
> general announcement.
>
> 2) As Matteo mentioned, the "unit" of parallelization with that many
> files should be the file itself (not within-file parallelization).  In
> general, I recommend you develop your parallel code using foreach, and
> then use whatever parallel backend you want.  "parallel" is now built
> into the core R, so you might want to stick with that as a backend
> rather than snow/snowfall.  foreach is, in my opinion, conceptually
> easier than the other parallel packages, and is also very flexible
> (you can move your code from a single, multicore machine to an OpenMPI
> cluster with little effort).  This will only execute the resampling
> one per worker, so multiple files being open shouldn't be an issue
> (since if you have 8 workers, you'll only have 8 files open at a
> time).
>
> To be clear, we're talking about the difference between:
> (what rasterEngine does):
> fileA -> fileA_chunk1 -> worker1
>         -> fileA_chunk2 -> worker2
>
> (what Matteo and I are proposing):
> fileA -> worker1
> fileB -> worker2
>
> Be aware that resampling is I/O intensive, so parallel processing the
> files may not give you much (or any) benefit, if you are on a single
> hard drive.  Even minor tweaks like reading from one drive and writing
> to another may generate some additional speed.
>
> If you've never learned parallel computing in R, I HIGHLY recommend
> working through:
> http://trg.apbionet.org/euasiagrid/docs/parallelR.notes.pdf
>
> This is the best tutorial I've seen on parallel computing in R.
> Wherever it says library("snow") I'd recommend switching that with
> library("parallel"), and pay attention to the foreach discussion.
>
> --j
>
>
>
> On Wed, Jan 8, 2014 at 12:00 PM, Camilo Mora <cmora at dal.ca> wrote:
>> Thank you Roger,
>>
>> Yes I should have mentioned that I have looked extensively over this
>> question. Curiously, Jonathan From "spatial.tools" provided me with some
>> advice as his tool at the current time does not run the function "resample".
>>
>> Thanks again,
>>
>> Camilo
>>
>>
>>
>>
>> Quoting Roger Bivand <Roger.Bivand at nhh.no>:
>>
>>> Did you notice the thread started yesterday that appears to meet your
>>> need:
>>>
>>> https://stat.ethz.ch/pipermail/r-sig-geo/2014-January/020156.html
>>>
>>> It is always a good idea to look at the list archives, a search on:
>>>
>>> "list:R-sig-geo raster parallel"
>>>
>>> gives a number of potentially interesting hits. You could then preface
>>> your posting by saying that you have already tried some possible solutions,
>>> and would like help with them.
>>>
>>> Roger
>>>
>>> On Wed, 8 Jan 2014, Camilo Mora wrote:
>>>
>>>> Hi everyone,
>>>>
>>>> I am using the package "raster" to interpolate a large number of rasters
>>>> (~1million) of different resolutions to a unique 1degree resolution grid and
>>>> wonder if you know if it is possible to do this in parallel computer?.
>>>>
>>>> My code (example below) works like a charm but it will take 30 days to
>>>> process all the rasters. Sadly, the process only uses one core of my
>>>> computer. I wonder if there is a way to run this code (example below) in
>>>> parallel computer?.
>>>>
>>>> Thanks,
>>>>
>>>> Camilo
>>>>
>>>> ####TEST CODE######
>>>> library (raster)
>>>>
>>>> #creates 3 test rasters
>>>> a <- raster(nrow=3, ncol=3)
>>>> a[] <- 1:9
>>>>
>>>> b <- raster(nrow=3, ncol=3)
>>>> b[] <- 10:18
>>>>
>>>> c <- raster(nrow=3, ncol=3)
>>>> c[] <- 19:27
>>>>
>>>> #concatenates the rasters
>>>> d<-brick(a,b,c)
>>>>
>>>> #creates a raster at a different resolution
>>>> s <- raster(nrow=10, ncol=10)
>>>>
>>>> #interpolates data from the brick to the new resolution
>>>> s <- resample(d, s, method='bilinear')
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics,
>>> Helleveien 30, N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; fax +47 55 95 95 43
>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
> --
> Jonathan A. Greenberg, PhD
> Assistant Professor
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Department of Geography and Geographic Information Science
> University of Illinois at Urbana-Champaign
> 259 Computing Applications Building, MC-150
> 605 East Springfield Avenue
> Champaign, IL  61820-6371
> Phone: 217-300-1924
> http://www.geog.illinois.edu/~jgrn/
> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Wed Jan  8 20:39:28 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 8 Jan 2014 11:39:28 -0800
Subject: [R-sig-Geo] Raster in parallel computing?
In-Reply-To: <CANtt_hwiQOqz_7m_OFiUVAyvr3X1AmkMrdiex_yuBVnz=-bivQ@mail.gmail.com>
References: <20140108033649.17751q89tghr47xc@wm3.dal.ca>
	<alpine.LRH.2.03.1401081214220.7518@reclus.nhh.no>
	<20140108140017.6646792e0f73erk0@wm3.dal.ca>
	<CANtt_hwiQOqz_7m_OFiUVAyvr3X1AmkMrdiex_yuBVnz=-bivQ@mail.gmail.com>
Message-ID: <CANtt_hwzwmNBgwBTfVTzq2BWKUTHoNy9aMqRQnKynHmG=BwH+Q@mail.gmail.com>

Sorry my earlier message missed the first part of the script, now included:

The simplest approach is below, but that is inefficient here, at least
in this example, as this is designed to work for large files
that are processes in chunks. The problem here is not that the files
are large, but that they are many.
This uses beginCluster from the raster package. Normally you would
need to use clusterR, which does not work for resample; but resample
has build-in support.


library (raster)
#creates 3 test rasters
r <- raster(nrow=3, ncol=3)
v <- sapply(1:1000, function(i) setValues(r, runif(ncell(r))))
s <- raster(nrow=10, ncol=10)
path <- ''

beginCluster()

res <- list()
#for (i in 1:length(v)) {
for (i in 1:10) { # subset for the example
f <- paste0(path, 'r_', i, '.tif')
res[i] <- resample(v[[i]], s, method='bilinear', filename=f, overwrite=TRUE)
}

# However, if the rasters (or groups) have the same dimensions:
ss <- stack(v)
rs <- resample(v[[i]], s, method='bilinear', filename='test.tif',
overwrite=TRUE)

endCluster()


# Alternatively:


library(doParallel)
library(foreach)
registerDoParallel(cl = detectCores()-2) #choose how many cores
getDoParWorkers()
x <- foreach(i = 1:length(v), .packages = "raster") %dopar% {
f <- paste0(path, 'r_', i, '.tif')
resample(v[[i]], s, method='bilinear', filename=f, overwrite=TRUE)
}

# Or in groups

x <- foreach(i = 1:10, .packages = "raster") %dopar% {
f <- paste0(path, 'r_', i, '.tif')
j <- (i-1)*10+1
d <- stack(v[j:(j+9)])
resample(d, s, method='bilinear', filename=f, overwrite=TRUE)
}

On Wed, Jan 8, 2014 at 11:27 AM, Robert J. Hijmans <r.hijmans at gmail.com> wrote:
> Camilo,
>
> The simplest approach is below, but that is inefficient here, at least
> in this example, as this is designed to work for large files
> that are processes in chunks. The problem here is not that the files
> are large, but that they are many.
> This uses beginCluster from the raster package. Normally you would
> need to use clusterR, which does not work for resample; but resample
> has build-in support.
>
> beginCluster()
>
> res <- list()
> #for (i in 1:length(v)) {
> for (i in 1:10) { # subset for the example
> f <- paste0(path, 'r_', i, '.tif')
> res[i] <- resample(v[[i]], s, method='bilinear', filename=f, overwrite=TRUE)
> }
>
> # However, if the rasters (or groups) have the same dimensions:
> ss <- stack(v)
> rs <- resample(v[[i]], s, method='bilinear', filename='test.tif',
> overwrite=TRUE)
>
> endCluster()
>
>
> # Alternatively:
>
>
> library(doParallel)
> library(foreach)
> registerDoParallel(cl = detectCores()-2) #choose how many cores
> getDoParWorkers()
> x <- foreach(i = 1:length(v), .packages = "raster") %dopar% {
> f <- paste0(path, 'r_', i, '.tif')
> resample(v[[i]], s, method='bilinear', filename=f, overwrite=TRUE)
> }
>
> # Or in groups
>
> x <- foreach(i = 1:10, .packages = "raster") %dopar% {
> f <- paste0(path, 'r_', i, '.tif')
> j <- (i-1)*10+1
> d <- stack(v[j:(j+9)])
> resample(d, s, method='bilinear', filename=f, overwrite=TRUE)
> }
>
>
>
>
>
> On Wed, Jan 8, 2014 at 10:00 AM, Camilo Mora <cmora at dal.ca> wrote:
>> Thank you Roger,
>>
>> Yes I should have mentioned that I have looked extensively over this
>> question. Curiously, Jonathan From "spatial.tools" provided me with some
>> advice as his tool at the current time does not run the function "resample".
>>
>> Thanks again,
>>
>> Camilo
>>
>>
>>
>>
>> Quoting Roger Bivand <Roger.Bivand at nhh.no>:
>>
>>> Did you notice the thread started yesterday that appears to meet your
>>> need:
>>>
>>> https://stat.ethz.ch/pipermail/r-sig-geo/2014-January/020156.html
>>>
>>> It is always a good idea to look at the list archives, a search on:
>>>
>>> "list:R-sig-geo raster parallel"
>>>
>>> gives a number of potentially interesting hits. You could then preface
>>> your posting by saying that you have already tried some possible solutions,
>>> and would like help with them.
>>>
>>> Roger
>>>
>>> On Wed, 8 Jan 2014, Camilo Mora wrote:
>>>
>>>> Hi everyone,
>>>>
>>>> I am using the package "raster" to interpolate a large number of rasters
>>>> (~1million) of different resolutions to a unique 1degree resolution grid and
>>>> wonder if you know if it is possible to do this in parallel computer?.
>>>>
>>>> My code (example below) works like a charm but it will take 30 days to
>>>> process all the rasters. Sadly, the process only uses one core of my
>>>> computer. I wonder if there is a way to run this code (example below) in
>>>> parallel computer?.
>>>>
>>>> Thanks,
>>>>
>>>> Camilo
>>>>
>>>> ####TEST CODE######
>>>> library (raster)
>>>>
>>>> #creates 3 test rasters
>>>> a <- raster(nrow=3, ncol=3)
>>>> a[] <- 1:9
>>>>
>>>> b <- raster(nrow=3, ncol=3)
>>>> b[] <- 10:18
>>>>
>>>> c <- raster(nrow=3, ncol=3)
>>>> c[] <- 19:27
>>>>
>>>> #concatenates the rasters
>>>> d<-brick(a,b,c)
>>>>
>>>> #creates a raster at a different resolution
>>>> s <- raster(nrow=10, ncol=10)
>>>>
>>>> #interpolates data from the brick to the new resolution
>>>> s <- resample(d, s, method='bilinear')
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics,
>>> Helleveien 30, N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; fax +47 55 95 95 43
>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Wed Jan  8 20:58:45 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 8 Jan 2014 20:58:45 +0100
Subject: [R-sig-Geo] algorthirm to join polygons based on population
 properties
In-Reply-To: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE3D@GOMAIL.college.tcd.ie>
References: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE37@GOMAIL.college.tcd.ie>,
	<alpine.LRH.2.03.1401070913050.2070@reclus.nhh.no>
	<75C8D19A1470D344A8AF5312F01160A602BBB78CFE38@GOMAIL.college.tcd.ie>,
	<alpine.LRH.2.03.1401071102380.2422@reclus.nhh.no>
	<75C8D19A1470D344A8AF5312F01160A602BBB78CFE3D@GOMAIL.college.tcd.ie>
Message-ID: <alpine.LRH.2.03.1401082053140.11773@reclus.nhh.no>

On Wed, 8 Jan 2014, James Rooney wrote:

> Hi Roger,
>
> I have been trying to recreate the Boston example using my data set.
> I am running into an error with the nbcosts command that I don't understand.
>
>> lcosts <-nbcosts(SAPs.nb,dpad)
> Error in nbcosts(SAPs.nb, dpad) : nbcosts:26disjoint connected subgraphs

A connected graph is one in which there are no breaks, so that you could 
in principle create one region, if that is what the data suggest. You have 
26 disjoint (but internally connected) subgraphs, so you can either 
connect them by defining the neighbours in a different way, by dropping 
subgraphs with no cases, or by regionalising the subgraphs separately. See 
spdep::n.comp.nb for a tool to identify (and tally) your subgraphs. My 
guess is that many are not large, so can be discarded without prejudice. 
Use table() on the vector component returned by n.comp.nb() to tally the 
subgraphs, then see which ones have no cases.

Hope this helps,

Roger

>
> SAPs.nb is the neighbourhood matrix.
>
> What does this error mean ? I have not been able to understand it despite reading the help files.
>
> Thanks,
> James
>
> ________________________________________
> From: Roger Bivand [Roger.Bivand at nhh.no]
> Sent: 07 January 2014 10:12
> To: James Rooney
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] algorthirm to join polygons based on population properties
>
> On Tue, 7 Jan 2014, James Rooney wrote:
>
>> Hi Roger,
>>
>> Thanks for your reply. Coding the joins is not a problem I've already
>> done that on a smaller scale in a different project.
>>
>> No postcodes in my country. I have polygon data from the census and I
>> have geocoded cases for every case of a rare disease. This is all pretty
>> much fixed there is nothing I can do about it. I have performed an
>> analysis based on about 3500 polygons and that works ok. However the
>> population data has bad maths properties. There I'm now working with
>> newer data using 18,000 polygons and the same cases. This population
>> data has better maths properties (i.e. population per polygon is more
>> symmetrically distributed). But there are too many polygons - most of
>> the polygons have no cases. So when I do Bayesian smoothing I just end
>> up with a uniform map of Relative Risk =1 everywhere as all the polygons
>> with cases are all surrounded by polygons with no cases.
>>
>> I figure to get around this I either fiddle with the spatial weighting
>> (seems unwise), or join polygons in some sensible fashion. My question
>> was really wondering are there algorithms to deduce a list of polygon
>> joins based on polygon properties. For example - I don't want to join
>> urban and rural polygons as I am interested in the association of
>> population density with incidence rate. I'm also interested in the
>> relationship with social deprivation - so I don't want to join an area
>> of high deprivation with and area of low deprivation. Basically I want
>> to know is there a package that will create me a join list based on such
>> rules ? I can of course write some code to do it but I was hoping not to
>> have to spend the time on it!
>
> Briefly, you have a regionalisation problem in addition to MAUP, so have a
> look at spdep::skater and the underlying paper:
>
> Assuncao, R. M, Neves, M. C., Camara, G. and Freitas, C. da C. (2006).
> Efficient regionalization techniques for socio-economic geographical units
> using minimum spanning trees. International Journal of Geographical
> Information Science Vol. 20, No. 7, August 2006, 797-811.
>
> However, different criteria and clustering variable subsets will give
> different output regional aggregates. You may like to check robustness by
> comparing summary statistics for the aggregates, and by comparing output
> risk values under different aggregations.
>
> The key functions in this approach now support parallel execution, look
> carefully at the examples using the Boston dataset at the foot of the help
> page, and note the differences between Windows and Linux/OSX.
>
> Hope this helps,
>
> Roger
>
>
>>
>> James
>> ________________________________________
>> From: Roger Bivand [Roger.Bivand at nhh.no]
>> Sent: 07 January 2014 08:28
>> To: James Rooney
>> Cc: r-sig-geo at r-project.org
>> Subject: Re: [R-sig-Geo] algorthirm to join polygons based on population properties
>>
>> On Tue, 7 Jan 2014, James Rooney wrote:
>>
>>> Dear all,
>>>
>>> I have dataset with very many more polygons than cases. I wish to apply
>>> Bayesian smoothing to areal disease rates, however I have too many
>>> polygons and need a smart way to combine them so that there are less
>>> overall polygons.
>>> Bascially I need to only combine polygons of similar population density
>>> and it would be best if the new polygons have a distribution of total
>>> population that was within a limited range/normally distributed.
>>
>> This is not clear. Do you mean density (count/area) or just count? If you
>> have "too many polygons", then probably you haven't thought through your
>> sampling design - you need polygons with the correct support for the data
>> collection protocol used. Are you looking at postcode polygons and sparse
>> geocoded cases, with many empty postcodes? Are postcodes the relevant
>> support?
>>
>> If you think through support first (Gotway & Young 2002), then ad hoc
>> aggregation (that's the easy part) may be replaced by appropriate
>> aggregation (postcodes by health agency, surgery, etc.). The aggregation
>> can be done with rgeos::gUnaryUnion, but you need a vector assigning
>> polygons to aggregates first, preferably coded so that the data can be
>> maptools::spCbind using well-matched row.names of the aggregated
>> SpatialPolygons and data.frame objects to key on observation IDs.
>>
>> First clarity on support, then aggregate polygons to appropriate support,
>> then merge. Otherwise you are ignoring the uncertainty introduced into
>> your Bayesian analysis by the aggregation (dfferent aggregations will give
>> different results). There are good chapters on this in the Handbook of
>> Spatial Statistics by Gelfand and Wakefield/Lyons.
>>
>> Hope this clarifies,
>>
>> Roger
>>
>>>
>>> I can of course come up with some way of doing this myself, but I'm not
>>> keen to reinvent the wheel and so I am wondering - are there any smart
>>> algorithms already out there for doing this kind of thing ?
>>>
>>> Thanks,
>>> James
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From cmora at dal.ca  Wed Jan  8 22:32:28 2014
From: cmora at dal.ca (Camilo Mora)
Date: Wed, 08 Jan 2014 17:32:28 -0400
Subject: [R-sig-Geo] Raster in parallel computing?
In-Reply-To: <52CD682C020000270001E766@gwia2.boku.ac.at>
References: <20140108033649.17751q89tghr47xc@wm3.dal.ca>
	<52CD682C020000270001E766@gwia2.boku.ac.at>
Message-ID: <20140108173228.12214ede2gly2sqo@wm3.dal.ca>

Thank you very much all for your help on this.

A functional code to "resample" many rasters is below. It takes about  
three seconds to resample 1000 rasters. This functionality in R is  
pretty amazing, really.


library (raster)
library(doParallel)
library(foreach)

#creates 3 test rasters
r <- raster(nrow=3, ncol=3)
v <- sapply(1:1000, function(i) setValues(r, runif(ncell(r))))
s <- raster(nrow=10, ncol=10)

#cluster
cl <- makeCluster(detectCores()-2)    #create a cluster
registerDoParallel(cl)                #register the cluster

#code to be clustered
x <- foreach(i = 1:length(v), .packages = "raster") %dopar% {
resamp <- resample(v[[i]], s, method='bilinear')
}

ss <- brick(x)

#stop the cluster
stopCluster(cl)


From jgrn at illinois.edu  Wed Jan  8 23:42:18 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Wed, 8 Jan 2014 16:42:18 -0600
Subject: [R-sig-Geo] gdalUtils 0.2.0 now on CRAN
Message-ID: <CABG0rfs2QVzFmjQ7QAya-G84Ci+kDHvDStT95jijdOYCiCaKEQ@mail.gmail.com>

I would like to announce a new R package "gdalUtils", now on CRAN.
gdalUtils is a set of R wrappers for most of the GDAL utility programs
(http://gdal.org/gdal_utilities.html).  gdalUtils is a collaboration
between Matteo Mattiuzzi and me.

gdalUtils requires an already-installed GDAL on your system:
http://trac.osgeo.org/gdal/wiki/DownloadingGdalBinaries

For Windows, I recommend installing QGIS Standalone
(http://www.qgis.org/en/site/forusers/download.html) which appears to
have the most up-to-date binaries of GDAL for the Windows operating
system including support for HDF4/5 files.

Note that this is NOT a replacement for Roger Bivand's fantastic rgdal
package, it is a complementary package that simply provides R-wrappers
for functions like gdalwarp, gdal_translate, ogr2ogr, etc.  We've
tried to make the interface more R-like in terms of input parameters,
and have provided some additional features such as (when relevant)
returning outputs in Robert Hijman's raster format.  The parameter
naming and the documentation follows GDAL, with permission from Frank
Warmerdam (lead GDAL developer).

We have also provided some value-added functions such as
batch_gdal_translate and get_subdatasets (for extracting subdataset
names from HDF4/5 and NetCDF files).

I will note the primary motivation for developing this package was
initially to provide (finally) HDF4/5 file support to Windows users
(for Landsat and MODIS processing, among other things).  However, many
of the GDAL functions provide additional capabilities that R functions
do not currently have, and they are quite a bit faster than most of
their R equivalents (compare projectRaster_rigorous in my
spatial.tools package to gdalwarp(...,method="mode") for an example).

When you first fire it up, it may take a bit to search for a valid
GDAL install on your computer.  If you have more than one (Windows
users may find this), it will use the latest version.  We tried to
make this system-agnostic, but let us know if you have any problems
getting the functions to work.  The best way to test is:
library(gdalUtils)
gdalinfo(version=TRUE)
gdalinfo(formats=TRUE)

Cheers!

--j

-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From cebulmer at telus.net  Thu Jan  9 01:12:11 2014
From: cebulmer at telus.net (Chuck Bulmer)
Date: Wed, 8 Jan 2014 16:12:11 -0800 (PST)
Subject: [R-sig-Geo] raster writing saga grids.
Message-ID: <1389226331265-7585506.post@n2.nabble.com>

Hi
I am still having problems writing saga grids from raster package. From a
previous thread ( Nov 19, 2013 Guillaume Drolet writeRaster and raster give
same error after package update) it appeared that the problem was solved by
an update but I am running the newest version of raster and still having
trouble. 

I've been working around this problem, but would prefer not to have to spell
out the crs each time I load a raster as all of my grids use the same crs. 

Are others still experiencing this, or perhaps have I got other issues in my
system.

Thanks!

Chuck

This read command fails:
a <- raster(paste(dir_data,"\\BC_grids\\one_habc.sdat",sep=""))
Error in if (is.null(projs) | is.na(projs) | nchar(projs) < 3) { : 
  argument is of length zero
In addition: Warning message:
In is.na(projs) : is.na() applied to non-(list or vector) of type 'NULL'

This one works:
a <- raster(paste(dir_data,"\\BC_grids\\one_habc.sdat",sep=""),
crs="+proj=aea +lat_1=50 +lat_2=58.5 +lat_0=45 +lon_0=-126 +x_0=1000000
+y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs ")

This write command fails to write a saga grid:
> writeRaster(one_habc_b,filename=paste(dir_name,"\\ED_data\\grids\\one_HABC_b.sdat",sep=""),format="SAGA",overwrite=TRUE)
Error in if (is.null(projs) | is.na(projs) | nchar(projs) < 3) { : 
  argument is of length zero
In addition: Warning message:
In is.na(projs) : is.na() applied to non-(list or vector) of type 'NULL'

This one works if I save as ascii
writeRaster(one_habc_b,filename=paste(dir_name,"\\ED_data\\grids\\one_HABC_b.asc",sep=""),format="ascii",overwrite=TRUE)

This one works if I use gdal to create the saga grid:
writeGDAL(as(one_habc_b, 'SpatialGridDataFrame'), fname =
paste(dir_name,"\\ED_data\\grids\\one_HABC_b.sdat",sep=""), drivername =
"SAGA")

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252   
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] randomForest_4.6-7 maptools_0.8-27    rgeos_0.3-2        rgdal_0.8-13      
raster_2.1-66      sp_1.0-14         
 [7] RSAGA_0.93-6       plyr_1.8           shapefiles_0.7     gstat_1.0-18      
foreign_0.8-57    

loaded via a namespace (and not attached):
[1] grid_3.0.2       intervals_0.14.0 lattice_0.20-24  spacetime_1.0-9 
tools_3.0.2      xts_0.9-7       
[7] zoo_1.7-10      



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/raster-writing-saga-grids-tp7585506.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From cebulmer at telus.net  Thu Jan  9 01:38:18 2014
From: cebulmer at telus.net (Chuck Bulmer)
Date: Wed, 8 Jan 2014 16:38:18 -0800 (PST)
Subject: [R-sig-Geo] raster writing saga grids.
In-Reply-To: <1389226331265-7585506.post@n2.nabble.com>
References: <1389226331265-7585506.post@n2.nabble.com>
Message-ID: <1389227898120-7585507.post@n2.nabble.com>

Apologies.

I just noticed in my previous post I was actually running raster v 2.1-66. 

But I have tried again and get the same trouble with v 2.2-5 and with 2.2-6,
though the error message is formatted slightly differently

> writeRaster(one_habc_b,filename=paste(dir_name,"\\ED_data\\grids\\one_HABC_b.sdat",sep=""),format="SAGA",overwrite=TRUE)
Error in if (is.na(crs)) { : argument is of length zero
In addition: Warning message:
In is.na(crs) : is.na() applied to non-(list or vector) of type 'NULL'

Sorry for the confusion, but I'm still stumped..

Thanks for any help you can provide

Chuck



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/raster-writing-saga-grids-tp7585506p7585507.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From r.hijmans at gmail.com  Thu Jan  9 07:50:51 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 8 Jan 2014 22:50:51 -0800
Subject: [R-sig-Geo] raster writing saga grids.
In-Reply-To: <1389227898120-7585507.post@n2.nabble.com>
References: <1389226331265-7585506.post@n2.nabble.com>
	<1389227898120-7585507.post@n2.nabble.com>
Message-ID: <CANtt_hzw_U=qdZSJ=fbYceD7Nxw=qW_TyR-gc2Qeze_z2CqXCw@mail.gmail.com>

Chuck,
Thanks for reporting this. Annoying how this bug has been persistent.
I believe it is gone now in version 2.2-7. Should be available for
testing from R-Forge in a couple of hours.
Robert

On Wed, Jan 8, 2014 at 4:38 PM, Chuck Bulmer <cebulmer at telus.net> wrote:
> Apologies.
>
> I just noticed in my previous post I was actually running raster v 2.1-66.
>
> But I have tried again and get the same trouble with v 2.2-5 and with 2.2-6,
> though the error message is formatted slightly differently
>
>> writeRaster(one_habc_b,filename=paste(dir_name,"\\ED_data\\grids\\one_HABC_b.sdat",sep=""),format="SAGA",overwrite=TRUE)
> Error in if (is.na(crs)) { : argument is of length zero
> In addition: Warning message:
> In is.na(crs) : is.na() applied to non-(list or vector) of type 'NULL'
>
> Sorry for the confusion, but I'm still stumped..
>
> Thanks for any help you can provide
>
> Chuck
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/raster-writing-saga-grids-tp7585506p7585507.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Rainer at krugs.de  Thu Jan  9 09:28:08 2014
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 9 Jan 2014 09:28:08 +0100
Subject: [R-sig-Geo] gdalUtils 0.2.0 now on CRAN
In-Reply-To: <CABG0rfs2QVzFmjQ7QAya-G84Ci+kDHvDStT95jijdOYCiCaKEQ@mail.gmail.com>
References: <CABG0rfs2QVzFmjQ7QAya-G84Ci+kDHvDStT95jijdOYCiCaKEQ@mail.gmail.com>
Message-ID: <52CE5D98.7010303@krugs.de>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1



On 01/08/14, 23:42 , Jonathan Greenberg wrote:
> I would like to announce a new R package "gdalUtils", now on CRAN. 
> gdalUtils is a set of R wrappers for most of the GDAL utility
> programs (http://gdal.org/gdal_utilities.html).  gdalUtils is a
> collaboration between Matteo Mattiuzzi and me.
> 
> gdalUtils requires an already-installed GDAL on your system: 
> http://trac.osgeo.org/gdal/wiki/DownloadingGdalBinaries
> 
> For Windows, I recommend installing QGIS Standalone 
> (http://www.qgis.org/en/site/forusers/download.html) which appears
> to have the most up-to-date binaries of GDAL for the Windows
> operating system including support for HDF4/5 files.
> 
> Note that this is NOT a replacement for Roger Bivand's fantastic
> rgdal package, it is a complementary package that simply provides
> R-wrappers for functions like gdalwarp, gdal_translate, ogr2ogr,
> etc.  We've tried to make the interface more R-like in terms of
> input parameters, and have provided some additional features such
> as (when relevant) returning outputs in Robert Hijman's raster
> format.  The parameter naming and the documentation follows GDAL,
> with permission from Frank Warmerdam (lead GDAL developer).
> 
> We have also provided some value-added functions such as 
> batch_gdal_translate and get_subdatasets (for extracting
> subdataset names from HDF4/5 and NetCDF files).
> 
> I will note the primary motivation for developing this package was 
> initially to provide (finally) HDF4/5 file support to Windows
> users (for Landsat and MODIS processing, among other things).
> However, many of the GDAL functions provide additional capabilities
> that R functions do not currently have, and they are quite a bit
> faster than most of their R equivalents (compare
> projectRaster_rigorous in my spatial.tools package to
> gdalwarp(...,method="mode") for an example).
> 
> When you first fire it up, it may take a bit to search for a valid 
> GDAL install on your computer.  If you have more than one (Windows 
> users may find this), it will use the latest version.  We tried to 
> make this system-agnostic, but let us know if you have any
> problems getting the functions to work.  The best way to test is: 
> library(gdalUtils) gdalinfo(version=TRUE) gdalinfo(formats=TRUE)

Very nice - haven't tried any working examples, but it installs on a
mac without problems and finds the gdal installation installed via
homebrew.

But I have some questions:

The automatic search is nice - but I unlinked gdal via homebrew, i.e.
the links to the binaries and libraries are not in the path anymore,
and I could not load gdalUtils anymore, as the gdalUtils did not find
the libraries anymore (understandable). But it seams, that gdalUtils
did not search for gdal, which is installed as a Framework as well.
Now I removed gdalUtils again and installed it again, with gdal still
unlinked, but it did not install as it did not find the gdal
libraries, despite gdal being available in a framework (see
http://www.kyngchaos.com/software/frameworks for the ones installed -
they are quite popular, and required, among GRASS and QGIS users on Mac).

Question 1:

Would it be possible, to include the gdal Frameworks in the search path?

At the end is a layout of the directory structure of the gdal frameworks.

Question 2:

Is it (or would it) be possible to manually set the installation of
gdal to be used? This would make comparison of versions of gdal as
well as reproducible research much easier.

Question 3:

I can't test it right now, but I assume that gdalUtils does search for
a new gdal installation if it can't find the one used before? Is there
a way of initiating the search (and selection) if a newer version has
been installed?

Thanks for a very neat package,

Rainer

Directory structure of the GDAL.Framework on a MAC:

/Library/Frameworks/GDAL.framework/
??? Headers -> Versions/Current/Headers
??? Programs -> Versions/Current/Programs
??? Resources -> Versions/Current/Resources
??? Versions
?   ??? 1.10
?   ?   ??? Headers
?   ?   ??? Libraries
?   ?   ?   ??? ogdi
?   ?   ??? PlugIns
?   ?   ??? Programs
?   ?   ??? Python
?   ?   ?   ??? 2.6
?   ?   ?   ?   ??? site-packages
?   ?   ?   ?       ??? osgeo
?   ?   ?   ??? 2.7
?   ?   ?       ??? site-packages
?   ?   ?           ??? osgeo
?   ?   ??? Resources
?   ?   ?   ??? doc
?   ?   ?   ?   ??? gdal
?   ?   ?   ?       ??? java
?   ?   ?   ?       ?   ??? org
?   ?   ?   ?       ?   ?   ??? gdal
?   ?   ?   ?       ?   ?       ??? gdal
?   ?   ?   ?       ?   ?       ??? gdalconst
?   ?   ?   ?       ?   ?       ??? ogr
?   ?   ?   ?       ?   ?       ??? osr
?   ?   ?   ?       ?   ??? resources
?   ?   ?   ?       ??? ogr
?   ?   ?   ??? gdal
?   ?   ??? unix
?   ?       ??? bin
?   ?       ??? include -> ../Headers
?   ?       ??? lib
?   ??? 1.9
?   ?   ??? Headers
?   ?   ??? Libraries
?   ?   ?   ??? ogdi
?   ?   ??? PlugIns
?   ?   ??? Programs
?   ?   ??? Python
?   ?   ?   ??? 2.6
?   ?   ?   ?   ??? site-packages
?   ?   ?   ?       ??? osgeo
?   ?   ?   ??? 2.7
?   ?   ?       ??? site-packages
?   ?   ?           ??? osgeo
?   ?   ??? Resources
?   ?   ?   ??? doc
?   ?   ?   ?   ??? gdal
?   ?   ?   ?       ??? java
?   ?   ?   ?       ?   ??? org
?   ?   ?   ?       ?   ?   ??? gdal
?   ?   ?   ?       ?   ?       ??? gdal
?   ?   ?   ?       ?   ?       ??? gdalconst
?   ?   ?   ?       ?   ?       ??? ogr
?   ?   ?   ?       ?   ?       ??? osr
?   ?   ?   ?       ?   ??? resources
?   ?   ?   ?       ??? ogr
?   ?   ?   ??? gdal
?   ?   ??? unix
?   ?       ??? bin
?   ?       ??? include -> ../Headers
?   ?       ??? lib
?   ??? Current -> 1.10
??? unix -> Versions/Current/unix


> 
> Cheers!
> 
> --j
> 

- -- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQEcBAEBAgAGBQJSzl2YAAoJENvXNx4PUvmCp6sH/3KD9/vKJlBms+OOuRbD2MjS
6PmSXT4e0J2MpUDQbm3xBDMFNPa7EtlWMeYHvAQHdKfRF87/n6ZTcW0wIxIhmIcC
/3q0lx/yipjXScR2EerMyX3B1bVCRNHFgi5BjNnDUrX6lfNm4DD8HqV6Rn5AxJZE
NkSZ+mQPJ7UgqV9awNtd2QlK+qyjq7TeFrprNrKuoXZ8ALJjZSXn70WDh7jARvP6
zD/rjHFB83Kk61+A0TRBeWfXWtVy1CJZCR0cCXoofBNjT8kYu2EUsWtYqj6EmKBX
1ThW6/yTst9t1cs+j6kDhBG3c+rJ14mx5nkOUXRzCk6wfu/bdGMGoVbEPjW4PII=
=kSdZ
-----END PGP SIGNATURE-----


From diregola at gmail.com  Thu Jan  9 11:50:29 2014
From: diregola at gmail.com (Margherita Di Leo)
Date: Thu, 9 Jan 2014 11:50:29 +0100
Subject: [R-sig-Geo] Call for papers: Geospatial Semantic Array Programming
Message-ID: <CABa=8QrHzkxyrV-5ODpTLSPCiACXxmxKX1-GWPqody0=s3XpFA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140109/66a43838/attachment.pl>

From clancy.birrell at gmail.com  Thu Jan  9 13:01:08 2014
From: clancy.birrell at gmail.com (clancy.birrell)
Date: Thu, 9 Jan 2014 04:01:08 -0800 (PST)
Subject: [R-sig-Geo] rbind of SpPolDFs
In-Reply-To: <alpine.LRH.2.00.1005181633360.20109@reclus.nhh.no>
References: <AANLkTin-j86M9qlOtQpWGtO9ptAw1-uTwbpRqxeo6stY@mail.gmail.com>
	<alpine.LRH.2.00.1005181633360.20109@reclus.nhh.no>
Message-ID: <1389268868402-7585511.post@n2.nabble.com>

I was having a similar problem and this worked perfectly.
Thanks Roger, you are the bomb.



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/rbind-of-SpPolDFs-tp5070215p7585511.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From alobolistas at gmail.com  Thu Jan  9 15:11:44 2014
From: alobolistas at gmail.com (Agustin Lobo)
Date: Thu, 9 Jan 2014 15:11:44 +0100
Subject: [R-sig-Geo] writeRaster() error with raster_2.2-5
Message-ID: <CAG4NReJF+7VD43Mh1ZT-WPu4ikEzvBgrs12fj06q_+StpZ2dmA@mail.gmail.com>

I'm getting this problem with raster_2.2-5 rgdal_0.8-14 (was working
until I updated):

test <- raster(matrix(10,nrow=4,ncol=4))
writeRaster(test,file="test",format="GTiff",overwrite=TRUE)

Error in .getGDALtransient(x, filename = filename, options = options,  :
  could not find function "GDALcall"

Instead
writeGDAL(as(test, "SpatialGridDataFrame"), fname ="test")
works fine.

It looks like the same problem we had few weeks ago is back
http://r-sig-geo.2731867.n2.nabble.com/Error-in-gd-SetProject-transient-crs-r-td7585330.html#a7585432

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-pc-linux-gnu (64-bit)

rgdal: version: 0.8-14, (SVN revision 496)
Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 1.10.0, released 2013/04/24
Path to GDAL shared files: /usr/share/gdal/1.10
Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
Path to PROJ.4 shared files: (autodetected)

Tried with raster version in R-forge, same problem

Agus


From ROONEYJ4 at tcd.ie  Thu Jan  9 16:57:56 2014
From: ROONEYJ4 at tcd.ie (James Rooney)
Date: Thu, 9 Jan 2014 15:57:56 +0000
Subject: [R-sig-Geo] algorthirm to join polygons based on population
 properties
In-Reply-To: <alpine.LRH.2.03.1401082053140.11773@reclus.nhh.no>
References: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE37@GOMAIL.college.tcd.ie>,
	<alpine.LRH.2.03.1401070913050.2070@reclus.nhh.no>
	<75C8D19A1470D344A8AF5312F01160A602BBB78CFE38@GOMAIL.college.tcd.ie>,
	<alpine.LRH.2.03.1401071102380.2422@reclus.nhh.no>
	<75C8D19A1470D344A8AF5312F01160A602BBB78CFE3D@GOMAIL.college.tcd.ie>,
	<alpine.LRH.2.03.1401082053140.11773@reclus.nhh.no>
Message-ID: <75C8D19A1470D344A8AF5312F01160A602BBB78CFE42@GOMAIL.college.tcd.ie>

Hi Roger,

Many thanks this was a useful suggestion.
The table to tally sub-graphs looked like this:

> table(t$comp.id)
    1     2     3     4     5     6     7     8     9 
18414     2     4     5     4     2     3     5    17 

I was able to plot these subgraphs and can see these are mostly islands and peninsulas etc. Now that I know what the problem is I should be able to fix it.
Many thanks!
James
________________________________________
From: Roger Bivand [Roger.Bivand at nhh.no]
Sent: 08 January 2014 19:58
To: James Rooney
Cc: r-sig-geo at r-project.org
Subject: RE: [R-sig-Geo] algorthirm to join polygons based on population properties

On Wed, 8 Jan 2014, James Rooney wrote:

> Hi Roger,
>
> I have been trying to recreate the Boston example using my data set.
> I am running into an error with the nbcosts command that I don't understand.
>
>> lcosts <-nbcosts(SAPs.nb,dpad)
> Error in nbcosts(SAPs.nb, dpad) : nbcosts:26disjoint connected subgraphs

A connected graph is one in which there are no breaks, so that you could
in principle create one region, if that is what the data suggest. You have
26 disjoint (but internally connected) subgraphs, so you can either
connect them by defining the neighbours in a different way, by dropping
subgraphs with no cases, or by regionalising the subgraphs separately. See
spdep::n.comp.nb for a tool to identify (and tally) your subgraphs. My
guess is that many are not large, so can be discarded without prejudice.
Use table() on the vector component returned by n.comp.nb() to tally the
subgraphs, then see which ones have no cases.

Hope this helps,

Roger

>
> SAPs.nb is the neighbourhood matrix.
>
> What does this error mean ? I have not been able to understand it despite reading the help files.
>
> Thanks,
> James
>
> ________________________________________
> From: Roger Bivand [Roger.Bivand at nhh.no]
> Sent: 07 January 2014 10:12
> To: James Rooney
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] algorthirm to join polygons based on population properties
>
> On Tue, 7 Jan 2014, James Rooney wrote:
>
>> Hi Roger,
>>
>> Thanks for your reply. Coding the joins is not a problem I've already
>> done that on a smaller scale in a different project.
>>
>> No postcodes in my country. I have polygon data from the census and I
>> have geocoded cases for every case of a rare disease. This is all pretty
>> much fixed there is nothing I can do about it. I have performed an
>> analysis based on about 3500 polygons and that works ok. However the
>> population data has bad maths properties. There I'm now working with
>> newer data using 18,000 polygons and the same cases. This population
>> data has better maths properties (i.e. population per polygon is more
>> symmetrically distributed). But there are too many polygons - most of
>> the polygons have no cases. So when I do Bayesian smoothing I just end
>> up with a uniform map of Relative Risk =1 everywhere as all the polygons
>> with cases are all surrounded by polygons with no cases.
>>
>> I figure to get around this I either fiddle with the spatial weighting
>> (seems unwise), or join polygons in some sensible fashion. My question
>> was really wondering are there algorithms to deduce a list of polygon
>> joins based on polygon properties. For example - I don't want to join
>> urban and rural polygons as I am interested in the association of
>> population density with incidence rate. I'm also interested in the
>> relationship with social deprivation - so I don't want to join an area
>> of high deprivation with and area of low deprivation. Basically I want
>> to know is there a package that will create me a join list based on such
>> rules ? I can of course write some code to do it but I was hoping not to
>> have to spend the time on it!
>
> Briefly, you have a regionalisation problem in addition to MAUP, so have a
> look at spdep::skater and the underlying paper:
>
> Assuncao, R. M, Neves, M. C., Camara, G. and Freitas, C. da C. (2006).
> Efficient regionalization techniques for socio-economic geographical units
> using minimum spanning trees. International Journal of Geographical
> Information Science Vol. 20, No. 7, August 2006, 797-811.
>
> However, different criteria and clustering variable subsets will give
> different output regional aggregates. You may like to check robustness by
> comparing summary statistics for the aggregates, and by comparing output
> risk values under different aggregations.
>
> The key functions in this approach now support parallel execution, look
> carefully at the examples using the Boston dataset at the foot of the help
> page, and note the differences between Windows and Linux/OSX.
>
> Hope this helps,
>
> Roger
>
>
>>
>> James
>> ________________________________________
>> From: Roger Bivand [Roger.Bivand at nhh.no]
>> Sent: 07 January 2014 08:28
>> To: James Rooney
>> Cc: r-sig-geo at r-project.org
>> Subject: Re: [R-sig-Geo] algorthirm to join polygons based on population properties
>>
>> On Tue, 7 Jan 2014, James Rooney wrote:
>>
>>> Dear all,
>>>
>>> I have dataset with very many more polygons than cases. I wish to apply
>>> Bayesian smoothing to areal disease rates, however I have too many
>>> polygons and need a smart way to combine them so that there are less
>>> overall polygons.
>>> Bascially I need to only combine polygons of similar population density
>>> and it would be best if the new polygons have a distribution of total
>>> population that was within a limited range/normally distributed.
>>
>> This is not clear. Do you mean density (count/area) or just count? If you
>> have "too many polygons", then probably you haven't thought through your
>> sampling design - you need polygons with the correct support for the data
>> collection protocol used. Are you looking at postcode polygons and sparse
>> geocoded cases, with many empty postcodes? Are postcodes the relevant
>> support?
>>
>> If you think through support first (Gotway & Young 2002), then ad hoc
>> aggregation (that's the easy part) may be replaced by appropriate
>> aggregation (postcodes by health agency, surgery, etc.). The aggregation
>> can be done with rgeos::gUnaryUnion, but you need a vector assigning
>> polygons to aggregates first, preferably coded so that the data can be
>> maptools::spCbind using well-matched row.names of the aggregated
>> SpatialPolygons and data.frame objects to key on observation IDs.
>>
>> First clarity on support, then aggregate polygons to appropriate support,
>> then merge. Otherwise you are ignoring the uncertainty introduced into
>> your Bayesian analysis by the aggregation (dfferent aggregations will give
>> different results). There are good chapters on this in the Handbook of
>> Spatial Statistics by Gelfand and Wakefield/Lyons.
>>
>> Hope this clarifies,
>>
>> Roger
>>
>>>
>>> I can of course come up with some way of doing this myself, but I'm not
>>> keen to reinvent the wheel and so I am wondering - are there any smart
>>> algorithms already out there for doing this kind of thing ?
>>>
>>> Thanks,
>>> James
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>
>
>

--
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From cebulmer at telus.net  Thu Jan  9 17:26:56 2014
From: cebulmer at telus.net (Chuck Bulmer)
Date: Thu, 9 Jan 2014 08:26:56 -0800 (PST)
Subject: [R-sig-Geo] raster writing saga grids.
In-Reply-To: <1389226331265-7585506.post@n2.nabble.com>
References: <1389226331265-7585506.post@n2.nabble.com>
Message-ID: <1389284816737-7585514.post@n2.nabble.com>

It is now working with 2.2-7

Thanks very much Robert.



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/raster-writing-saga-grids-tp7585506p7585514.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From jgrn at illinois.edu  Thu Jan  9 18:46:29 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Thu, 9 Jan 2014 11:46:29 -0600
Subject: [R-sig-Geo] gdalUtils 0.2.0 now on CRAN
In-Reply-To: <52CE5D98.7010303@krugs.de>
References: <CABG0rfs2QVzFmjQ7QAya-G84Ci+kDHvDStT95jijdOYCiCaKEQ@mail.gmail.com>
	<52CE5D98.7010303@krugs.de>
Message-ID: <CABG0rfvzkP-NJ+vH_MQ=vbdQsBrDRkLPFUP7Whiq=j4DcovabA@mail.gmail.com>

Rainer:

Responses below!

On Thu, Jan 9, 2014 at 2:28 AM, Rainer M Krug <Rainer at krugs.de> wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
>
>

>
> Very nice - haven't tried any working examples, but it installs on a
> mac without problems and finds the gdal installation installed via
> homebrew.
>
> But I have some questions:
>
> The automatic search is nice - but I unlinked gdal via homebrew, i.e.
> the links to the binaries and libraries are not in the path anymore,
> and I could not load gdalUtils anymore, as the gdalUtils did not find
> the libraries anymore (understandable). But it seams, that gdalUtils
> did not search for gdal, which is installed as a Framework as well.
> Now I removed gdalUtils again and installed it again, with gdal still
> unlinked, but it did not install as it did not find the gdal
> libraries, despite gdal being available in a framework (see
> http://www.kyngchaos.com/software/frameworks for the ones installed -
> they are quite popular, and required, among GRASS and QGIS users on Mac).

Quick question: did you try restarting R AFTER you unlinked the
homebrew version?  Here's why I ask: the first time you run ANY
gdalUtils in a session, what it does is spiders your system for
working GDAL installations (in fact, it looks for the frameworks
first).  After this first time, it won't re-scan the drive unless you
do one of two things: 1) restart R and re-load GDALUtils, or 2) run
gdal_setInstallation(rescan=TRUE)

> Question 1:
>
> Would it be possible, to include the gdal Frameworks in the search path?

These are the common locations it searches for, before it attempts a
brute-force search of your whole drive:

if (.Platform$OS=="unix")
{
common_locations <- c(
# UNIX systems
"/usr/bin",
"/usr/local/bin",
# Mac
# Kyngchaos frameworks:
"/Library/Frameworks/GDAL.framework/Programs",
# MacPorts:
"/opt/local/bin"
)
}
if (.Platform$OS=="windows")
{
common_locations <- c(
"C:\\Program Files",
"C:\\Program Files (x86)",
"C:\\OSGeo4W"
)
}

I use those frameworks, and the function worked for me, but let me
know if it failed to find yours (perhaps I'll strip the /Programs from
the search path?)  It is easy for me to add new search locations, so
if there are other common locations for ANY OS just let me know.

>
> At the end is a layout of the directory structure of the gdal frameworks.
>
> Question 2:
>
> Is it (or would it) be possible to manually set the installation of
> gdal to be used? This would make comparison of versions of gdal as
> well as reproducible research much easier.

Yes, we can add in this functionality at a future date.  Right now,
you can check to see what your installs are by:
gdal_setInstallation(rescan=TRUE)
getOption("gdalUtils_gdalPath")

In general, gdalUtils will use the first element of the
getOption("gdalUtils_gdalPath"), which is chosen by the most recent
version (by date).

> Question 3:
>
> I can't test it right now, but I assume that gdalUtils does search for
> a new gdal installation if it can't find the one used before? Is there
> a way of initiating the search (and selection) if a newer version has
> been installed?

Yep, as I said either restart R or run:
gdal_setInstallation(rescan=TRUE)

>
> Thanks for a very neat package,
>
> Rainer
>
> Directory structure of the GDAL.Framework on a MAC:
>
> /Library/Frameworks/GDAL.framework/
> ??? Headers -> Versions/Current/Headers
> ??? Programs -> Versions/Current/Programs
> ??? Resources -> Versions/Current/Resources
> ??? Versions
> ?   ??? 1.10
> ?   ?   ??? Headers
> ?   ?   ??? Libraries
> ?   ?   ?   ??? ogdi
> ?   ?   ??? PlugIns
> ?   ?   ??? Programs
> ?   ?   ??? Python
> ?   ?   ?   ??? 2.6
> ?   ?   ?   ?   ??? site-packages
> ?   ?   ?   ?       ??? osgeo
> ?   ?   ?   ??? 2.7
> ?   ?   ?       ??? site-packages
> ?   ?   ?           ??? osgeo
> ?   ?   ??? Resources
> ?   ?   ?   ??? doc
> ?   ?   ?   ?   ??? gdal
> ?   ?   ?   ?       ??? java
> ?   ?   ?   ?       ?   ??? org
> ?   ?   ?   ?       ?   ?   ??? gdal
> ?   ?   ?   ?       ?   ?       ??? gdal
> ?   ?   ?   ?       ?   ?       ??? gdalconst
> ?   ?   ?   ?       ?   ?       ??? ogr
> ?   ?   ?   ?       ?   ?       ??? osr
> ?   ?   ?   ?       ?   ??? resources
> ?   ?   ?   ?       ??? ogr
> ?   ?   ?   ??? gdal
> ?   ?   ??? unix
> ?   ?       ??? bin
> ?   ?       ??? include -> ../Headers
> ?   ?       ??? lib
> ?   ??? 1.9
> ?   ?   ??? Headers
> ?   ?   ??? Libraries
> ?   ?   ?   ??? ogdi
> ?   ?   ??? PlugIns
> ?   ?   ??? Programs
> ?   ?   ??? Python
> ?   ?   ?   ??? 2.6
> ?   ?   ?   ?   ??? site-packages
> ?   ?   ?   ?       ??? osgeo
> ?   ?   ?   ??? 2.7
> ?   ?   ?       ??? site-packages
> ?   ?   ?           ??? osgeo
> ?   ?   ??? Resources
> ?   ?   ?   ??? doc
> ?   ?   ?   ?   ??? gdal
> ?   ?   ?   ?       ??? java
> ?   ?   ?   ?       ?   ??? org
> ?   ?   ?   ?       ?   ?   ??? gdal
> ?   ?   ?   ?       ?   ?       ??? gdal
> ?   ?   ?   ?       ?   ?       ??? gdalconst
> ?   ?   ?   ?       ?   ?       ??? ogr
> ?   ?   ?   ?       ?   ?       ??? osr
> ?   ?   ?   ?       ?   ??? resources
> ?   ?   ?   ?       ??? ogr
> ?   ?   ?   ??? gdal
> ?   ?   ??? unix
> ?   ?       ??? bin
> ?   ?       ??? include -> ../Headers
> ?   ?       ??? lib
> ?   ??? Current -> 1.10
> ??? unix -> Versions/Current/unix
>
>
>>
>> Cheers!
>>
>> --j
>>
>
> - --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
> Biology, UCT), Dipl. Phys. (Germany)
>
> Centre of Excellence for Invasion Biology
> Stellenbosch University
> South Africa
>
> Tel :       +33 - (0)9 53 10 27 44
> Cell:       +33 - (0)6 85 62 59 98
> Fax :       +33 - (0)9 58 10 27 44
>
> Fax (D):    +49 - (0)3 21 21 25 22 44
>
> email:      Rainer at krugs.de
>
> Skype:      RMkrug
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
> Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/
>
> iQEcBAEBAgAGBQJSzl2YAAoJENvXNx4PUvmCp6sH/3KD9/vKJlBms+OOuRbD2MjS
> 6PmSXT4e0J2MpUDQbm3xBDMFNPa7EtlWMeYHvAQHdKfRF87/n6ZTcW0wIxIhmIcC
> /3q0lx/yipjXScR2EerMyX3B1bVCRNHFgi5BjNnDUrX6lfNm4DD8HqV6Rn5AxJZE
> NkSZ+mQPJ7UgqV9awNtd2QlK+qyjq7TeFrprNrKuoXZ8ALJjZSXn70WDh7jARvP6
> zD/rjHFB83Kk61+A0TRBeWfXWtVy1CJZCR0cCXoofBNjT8kYu2EUsWtYqj6EmKBX
> 1ThW6/yTst9t1cs+j6kDhBG3c+rJ14mx5nkOUXRzCk6wfu/bdGMGoVbEPjW4PII=
> =kSdZ
> -----END PGP SIGNATURE-----



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From tkeitt at utexas.edu  Thu Jan  9 19:10:26 2014
From: tkeitt at utexas.edu (Tim Keitt)
Date: Thu, 9 Jan 2014 12:10:26 -0600
Subject: [R-sig-Geo] gdalUtils 0.2.0 now on CRAN
In-Reply-To: <CABG0rfvzkP-NJ+vH_MQ=vbdQsBrDRkLPFUP7Whiq=j4DcovabA@mail.gmail.com>
References: <CABG0rfs2QVzFmjQ7QAya-G84Ci+kDHvDStT95jijdOYCiCaKEQ@mail.gmail.com>
	<52CE5D98.7010303@krugs.de>
	<CABG0rfvzkP-NJ+vH_MQ=vbdQsBrDRkLPFUP7Whiq=j4DcovabA@mail.gmail.com>
Message-ID: <CANnL8gpzLs7stQU6uAXGtW18bcmNH2YteogT_D=pnkH8S+Gj+w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140109/3487f842/attachment.pl>

From jgrn at illinois.edu  Thu Jan  9 19:43:20 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Thu, 9 Jan 2014 12:43:20 -0600
Subject: [R-sig-Geo] gdalUtils 0.2.0 now on CRAN
In-Reply-To: <CANnL8gpzLs7stQU6uAXGtW18bcmNH2YteogT_D=pnkH8S+Gj+w@mail.gmail.com>
References: <CABG0rfs2QVzFmjQ7QAya-G84Ci+kDHvDStT95jijdOYCiCaKEQ@mail.gmail.com>
	<52CE5D98.7010303@krugs.de>
	<CABG0rfvzkP-NJ+vH_MQ=vbdQsBrDRkLPFUP7Whiq=j4DcovabA@mail.gmail.com>
	<CANnL8gpzLs7stQU6uAXGtW18bcmNH2YteogT_D=pnkH8S+Gj+w@mail.gmail.com>
Message-ID: <CABG0rftdyGVmZKhzRQfWzYVUPjceTgr1pxBQn8Jg1RmDBadcxw@mail.gmail.com>

Tim: thanks! We have something similar, where the package uses a
Sys.which() to see if gdalinfo is available in the PATH as one of its
attempts to find a valid install.

Rainer et al: I pushed version 0.2.3 to R-forge (you'll need to SVN it
until R-forge builds the new package later today/tomorrow) which now
supports a fixed search_path parameter.  To use this:

gdal_setInstallation(search_path="/pathto/your/favorite/GDAL/",rescan=TRUE)

If it finds a valid gdalinfo in that path, it will use that one (thus
forcing gdalUtils to use a specific install).  If it doesn't find it,
it will search as usual.  Note that I updated the help for
gdal_setInstallation to better explain how gdalUtils searches for a
valid install.

Here's the R-forge site:
https://r-forge.r-project.org/projects/gdalutils/

--j

On Thu, Jan 9, 2014 at 12:10 PM, Tim Keitt <tkeitt at utexas.edu> wrote:
> You might also try "gdal-config --prefix". Of course that wont work if
> gdal-config not installed or in the path.
>
> THK
>
>
> On Thu, Jan 9, 2014 at 11:46 AM, Jonathan Greenberg <jgrn at illinois.edu>
> wrote:
>>
>> Rainer:
>>
>> Responses below!
>>
>> On Thu, Jan 9, 2014 at 2:28 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>> > -----BEGIN PGP SIGNED MESSAGE-----
>> > Hash: SHA1
>> >
>> >
>> >
>>
>> >
>> > Very nice - haven't tried any working examples, but it installs on a
>> > mac without problems and finds the gdal installation installed via
>> > homebrew.
>> >
>> > But I have some questions:
>> >
>> > The automatic search is nice - but I unlinked gdal via homebrew, i.e.
>> > the links to the binaries and libraries are not in the path anymore,
>> > and I could not load gdalUtils anymore, as the gdalUtils did not find
>> > the libraries anymore (understandable). But it seams, that gdalUtils
>> > did not search for gdal, which is installed as a Framework as well.
>> > Now I removed gdalUtils again and installed it again, with gdal still
>> > unlinked, but it did not install as it did not find the gdal
>> > libraries, despite gdal being available in a framework (see
>> > http://www.kyngchaos.com/software/frameworks for the ones installed -
>> > they are quite popular, and required, among GRASS and QGIS users on
>> > Mac).
>>
>> Quick question: did you try restarting R AFTER you unlinked the
>> homebrew version?  Here's why I ask: the first time you run ANY
>> gdalUtils in a session, what it does is spiders your system for
>> working GDAL installations (in fact, it looks for the frameworks
>> first).  After this first time, it won't re-scan the drive unless you
>> do one of two things: 1) restart R and re-load GDALUtils, or 2) run
>> gdal_setInstallation(rescan=TRUE)
>>
>> > Question 1:
>> >
>> > Would it be possible, to include the gdal Frameworks in the search path?
>>
>> These are the common locations it searches for, before it attempts a
>> brute-force search of your whole drive:
>>
>> if (.Platform$OS=="unix")
>> {
>> common_locations <- c(
>> # UNIX systems
>> "/usr/bin",
>> "/usr/local/bin",
>> # Mac
>> # Kyngchaos frameworks:
>> "/Library/Frameworks/GDAL.framework/Programs",
>> # MacPorts:
>> "/opt/local/bin"
>> )
>> }
>> if (.Platform$OS=="windows")
>> {
>> common_locations <- c(
>> "C:\\Program Files",
>> "C:\\Program Files (x86)",
>> "C:\\OSGeo4W"
>> )
>> }
>>
>> I use those frameworks, and the function worked for me, but let me
>> know if it failed to find yours (perhaps I'll strip the /Programs from
>> the search path?)  It is easy for me to add new search locations, so
>> if there are other common locations for ANY OS just let me know.
>>
>> >
>> > At the end is a layout of the directory structure of the gdal
>> > frameworks.
>> >
>> > Question 2:
>> >
>> > Is it (or would it) be possible to manually set the installation of
>> > gdal to be used? This would make comparison of versions of gdal as
>> > well as reproducible research much easier.
>>
>> Yes, we can add in this functionality at a future date.  Right now,
>> you can check to see what your installs are by:
>> gdal_setInstallation(rescan=TRUE)
>> getOption("gdalUtils_gdalPath")
>>
>> In general, gdalUtils will use the first element of the
>> getOption("gdalUtils_gdalPath"), which is chosen by the most recent
>> version (by date).
>>
>> > Question 3:
>> >
>> > I can't test it right now, but I assume that gdalUtils does search for
>> > a new gdal installation if it can't find the one used before? Is there
>> > a way of initiating the search (and selection) if a newer version has
>> > been installed?
>>
>> Yep, as I said either restart R or run:
>> gdal_setInstallation(rescan=TRUE)
>>
>> >
>> > Thanks for a very neat package,
>> >
>> > Rainer
>> >
>> > Directory structure of the GDAL.Framework on a MAC:
>> >
>> > /Library/Frameworks/GDAL.framework/
>> > ??? Headers -> Versions/Current/Headers
>> > ??? Programs -> Versions/Current/Programs
>> > ??? Resources -> Versions/Current/Resources
>> > ??? Versions
>> > ?   ??? 1.10
>> > ?   ?   ??? Headers
>> > ?   ?   ??? Libraries
>> > ?   ?   ?   ??? ogdi
>> > ?   ?   ??? PlugIns
>> > ?   ?   ??? Programs
>> > ?   ?   ??? Python
>> > ?   ?   ?   ??? 2.6
>> > ?   ?   ?   ?   ??? site-packages
>> > ?   ?   ?   ?       ??? osgeo
>> > ?   ?   ?   ??? 2.7
>> > ?   ?   ?       ??? site-packages
>> > ?   ?   ?           ??? osgeo
>> > ?   ?   ??? Resources
>> > ?   ?   ?   ??? doc
>> > ?   ?   ?   ?   ??? gdal
>> > ?   ?   ?   ?       ??? java
>> > ?   ?   ?   ?       ?   ??? org
>> > ?   ?   ?   ?       ?   ?   ??? gdal
>> > ?   ?   ?   ?       ?   ?       ??? gdal
>> > ?   ?   ?   ?       ?   ?       ??? gdalconst
>> > ?   ?   ?   ?       ?   ?       ??? ogr
>> > ?   ?   ?   ?       ?   ?       ??? osr
>> > ?   ?   ?   ?       ?   ??? resources
>> > ?   ?   ?   ?       ??? ogr
>> > ?   ?   ?   ??? gdal
>> > ?   ?   ??? unix
>> > ?   ?       ??? bin
>> > ?   ?       ??? include -> ../Headers
>> > ?   ?       ??? lib
>> > ?   ??? 1.9
>> > ?   ?   ??? Headers
>> > ?   ?   ??? Libraries
>> > ?   ?   ?   ??? ogdi
>> > ?   ?   ??? PlugIns
>> > ?   ?   ??? Programs
>> > ?   ?   ??? Python
>> > ?   ?   ?   ??? 2.6
>> > ?   ?   ?   ?   ??? site-packages
>> > ?   ?   ?   ?       ??? osgeo
>> > ?   ?   ?   ??? 2.7
>> > ?   ?   ?       ??? site-packages
>> > ?   ?   ?           ??? osgeo
>> > ?   ?   ??? Resources
>> > ?   ?   ?   ??? doc
>> > ?   ?   ?   ?   ??? gdal
>> > ?   ?   ?   ?       ??? java
>> > ?   ?   ?   ?       ?   ??? org
>> > ?   ?   ?   ?       ?   ?   ??? gdal
>> > ?   ?   ?   ?       ?   ?       ??? gdal
>> > ?   ?   ?   ?       ?   ?       ??? gdalconst
>> > ?   ?   ?   ?       ?   ?       ??? ogr
>> > ?   ?   ?   ?       ?   ?       ??? osr
>> > ?   ?   ?   ?       ?   ??? resources
>> > ?   ?   ?   ?       ??? ogr
>> > ?   ?   ?   ??? gdal
>> > ?   ?   ??? unix
>> > ?   ?       ??? bin
>> > ?   ?       ??? include -> ../Headers
>> > ?   ?       ??? lib
>> > ?   ??? Current -> 1.10
>> > ??? unix -> Versions/Current/unix
>> >
>> >
>> >>
>> >> Cheers!
>> >>
>> >> --j
>> >>
>> >
>> > - --
>> > Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
>> > Biology, UCT), Dipl. Phys. (Germany)
>> >
>> > Centre of Excellence for Invasion Biology
>> > Stellenbosch University
>> > South Africa
>> >
>> > Tel :       +33 - (0)9 53 10 27 44
>> > Cell:       +33 - (0)6 85 62 59 98
>> > Fax :       +33 - (0)9 58 10 27 44
>> >
>> > Fax (D):    +49 - (0)3 21 21 25 22 44
>> >
>> > email:      Rainer at krugs.de
>> >
>> > Skype:      RMkrug
>> > -----BEGIN PGP SIGNATURE-----
>> > Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
>> > Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/
>> >
>> > iQEcBAEBAgAGBQJSzl2YAAoJENvXNx4PUvmCp6sH/3KD9/vKJlBms+OOuRbD2MjS
>> > 6PmSXT4e0J2MpUDQbm3xBDMFNPa7EtlWMeYHvAQHdKfRF87/n6ZTcW0wIxIhmIcC
>> > /3q0lx/yipjXScR2EerMyX3B1bVCRNHFgi5BjNnDUrX6lfNm4DD8HqV6Rn5AxJZE
>> > NkSZ+mQPJ7UgqV9awNtd2QlK+qyjq7TeFrprNrKuoXZ8ALJjZSXn70WDh7jARvP6
>> > zD/rjHFB83Kk61+A0TRBeWfXWtVy1CJZCR0cCXoofBNjT8kYu2EUsWtYqj6EmKBX
>> > 1ThW6/yTst9t1cs+j6kDhBG3c+rJ14mx5nkOUXRzCk6wfu/bdGMGoVbEPjW4PII=
>> > =kSdZ
>> > -----END PGP SIGNATURE-----
>>
>>
>>
>> --
>> Jonathan A. Greenberg, PhD
>> Assistant Professor
>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>> Department of Geography and Geographic Information Science
>> University of Illinois at Urbana-Champaign
>> 259 Computing Applications Building, MC-150
>> 605 East Springfield Avenue
>> Champaign, IL  61820-6371
>> Phone: 217-300-1924
>> http://www.geog.illinois.edu/~jgrn/
>> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
>
> --
> http://www.keittlab.org/



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From julleeyaw at yahoo.ca  Thu Jan  9 20:59:14 2014
From: julleeyaw at yahoo.ca (Julie Lee-Yaw)
Date: Thu, 9 Jan 2014 11:59:14 -0800 (PST)
Subject: [R-sig-Geo] Help with getting and processing MODIS data
Message-ID: <1389297554.95170.YahooMailNeo@web142502.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140109/4219dda0/attachment.pl>

From Rainer at krugs.de  Thu Jan  9 21:07:42 2014
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 9 Jan 2014 21:07:42 +0100
Subject: [R-sig-Geo] gdalUtils 0.2.0 now on CRAN
In-Reply-To: <CABG0rfvzkP-NJ+vH_MQ=vbdQsBrDRkLPFUP7Whiq=j4DcovabA@mail.gmail.com>
References: <CABG0rfs2QVzFmjQ7QAya-G84Ci+kDHvDStT95jijdOYCiCaKEQ@mail.gmail.com>	<52CE5D98.7010303@krugs.de>
	<CABG0rfvzkP-NJ+vH_MQ=vbdQsBrDRkLPFUP7Whiq=j4DcovabA@mail.gmail.com>
Message-ID: <52CF018E.7040909@krugs.de>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 01/09/14, 18:46 , Jonathan Greenberg wrote:
> Rainer:
Hi


> 
> Responses below!
> 
> On Thu, Jan 9, 2014 at 2:28 AM, Rainer M Krug <Rainer at krugs.de>
> wrote:
> 
> 
> Very nice - haven't tried any working examples, but it installs on
> a mac without problems and finds the gdal installation installed
> via homebrew.
> 
> But I have some questions:
> 
> The automatic search is nice - but I unlinked gdal via homebrew,
> i.e. the links to the binaries and libraries are not in the path
> anymore, and I could not load gdalUtils anymore, as the gdalUtils
> did not find the libraries anymore (understandable). But it seams,
> that gdalUtils did not search for gdal, which is installed as a
> Framework as well. Now I removed gdalUtils again and installed it
> again, with gdal still unlinked, but it did not install as it did
> not find the gdal libraries, despite gdal being available in a
> framework (see http://www.kyngchaos.com/software/frameworks for the
> ones installed - they are quite popular, and required, among GRASS
> and QGIS users on Mac).
> 
>> Quick question: did you try restarting R AFTER you unlinked the 
>> homebrew version?  Here's why I ask: the first time you run ANY 
>> gdalUtils in a session, what it does is spiders your system for 
>> working GDAL installations (in fact, it looks for the frameworks 
>> first).  After this first time, it won't re-scan the drive unless
>> you do one of two things: 1) restart R and re-load GDALUtils, or
>> 2) run gdal_setInstallation(rescan=TRUE)


Yes, I restarted R afterwards - see transcript below:

####################################
Rainers-MacBook-Pro-2:~ rainerkrug$ brew unlink gdal
Unlinking /usr/local/Cellar/gdal/1.10.1... 163 links removed
Rainers-MacBook-Pro-2:~ rainerkrug$ R

R version 3.0.2 Patched (2014-01-07 r64692) -- "Frisbee Sailing"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin10.8.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> library(gdalUtils)
Error in dyn.load(file, DLLpath = DLLpath, ...) :
  unable to load shared object
'/Users/rainerkrug/Library/R/3.0/library/rgdal/libs/rgdal.so':
  dlopen(/Users/rainerkrug/Library/R/3.0/library/rgdal/libs/rgdal.so,
6): Library not loaded: /usr/local/lib/libgdal.1.dylib
  Referenced from:
/Users/rainerkrug/Library/R/3.0/library/rgdal/libs/rgdal.so
  Reason: image not found
Error: package or namespace load failed for ?gdalUtils?
> 
####################################

and I obviously can not call the command, as the package is not loaded.

But I just realized what the problem is: the importing on rgdal. If I
unlink, rgdal does not load anymore as it is compiled using the
homebrew gdal version, and consequently gdalUtils does not load
anymore. So the problem is not directly with gdalUtils. But this
raises an important question: what happens if rgdal and gdalUtils are
using different gdal versions? I think this could call for
inconsistencies.

As gdalUtils depends on rgdal, I would actually suggest to use the
same gdal installation as rgdal, if this is possible.

> 
> Question 1:
> 
> Would it be possible, to include the gdal Frameworks in the search
> path?
> 
>> These are the common locations it searches for, before it
>> attempts a brute-force search of your whole drive:
> 
>> if (.Platform$OS=="unix") { common_locations <- c( # UNIX
>> systems "/usr/bin", "/usr/local/bin", # Mac # Kyngchaos
>> frameworks: "/Library/Frameworks/GDAL.framework/Programs", #
>> MacPorts: "/opt/local/bin" ) } if (.Platform$OS=="windows") { 
>> common_locations <- c( "C:\\Program Files", "C:\\Program Files
>> (x86)", "C:\\OSGeo4W" ) }
> 
>> I use those frameworks, and the function worked for me, but let
>> me know if it failed to find yours (perhaps I'll strip the
>> /Programs from the search path?)  It is easy for me to add new
>> search locations, so if there are other common locations for ANY
>> OS just let me know.
> 

As mentioned above, the problem is the importing of rgdal.

> 
> At the end is a layout of the directory structure of the gdal
> frameworks.
> 
> Question 2:
> 
> Is it (or would it) be possible to manually set the installation
> of gdal to be used? This would make comparison of versions of gdal
> as well as reproducible research much easier.
> 
>> Yes, we can add in this functionality at a future date.  Right
>> now, you can check to see what your installs are by: 
>> gdal_setInstallation(rescan=TRUE) 
>> getOption("gdalUtils_gdalPath")
> 
>> In general, gdalUtils will use the first element of the 
>> getOption("gdalUtils_gdalPath"), which is chosen by the most
>> recent version (by date).

As mentioned above, due to the importing of rgdal, I would suggest to
use the same version as rgdal, if possible, to keep it consistent and
reproducible.

> 
> Question 3:
> 
> I can't test it right now, but I assume that gdalUtils does search
> for a new gdal installation if it can't find the one used before?
> Is there a way of initiating the search (and selection) if a newer
> version has been installed?
> 
>> Yep, as I said either restart R or run: 
>> gdal_setInstallation(rescan=TRUE)

OK.

Hope my comments are useful,

Rainer

> 
> 
> Thanks for a very neat package,
> 
> Rainer
> 
> Directory structure of the GDAL.Framework on a MAC:
> 
> /Library/Frameworks/GDAL.framework/ ??? Headers ->
> Versions/Current/Headers ??? Programs -> Versions/Current/Programs 
> ??? Resources -> Versions/Current/Resources ??? Versions ?   ???
> 1.10 ?   ?   ??? Headers ?   ?   ??? Libraries ?   ?   ?   ???
> ogdi ?   ?   ??? PlugIns ?   ?   ??? Programs ?   ?   ??? Python ?
> ?   ?   ??? 2.6 ?   ?   ?   ?   ??? site-packages ?   ?   ?   ?
> ??? osgeo ?   ?   ?   ??? 2.7 ?   ?   ?       ??? site-packages ?
> ?   ?           ??? osgeo ?   ?   ??? Resources ?   ?   ?   ???
> doc ?   ?   ?   ?   ??? gdal ?   ?   ?   ?       ??? java ?   ?   ?
> ?       ?   ??? org ?   ?   ?   ?       ?   ?   ??? gdal ?   ?   ?
> ?       ?   ?       ??? gdal ?   ?   ?   ?       ?   ?       ???
> gdalconst ?   ?   ?   ?       ?   ?       ??? ogr ?   ?   ?   ?
> ?   ?       ??? osr ?   ?   ?   ?       ?   ??? resources ?   ?   ?
> ?       ??? ogr ?   ?   ?   ??? gdal ?   ?   ??? unix ?   ?
> ??? bin ?   ?       ??? include -> ../Headers ?   ?       ??? lib ?
> ??? 1.9 ?   ?   ??? Headers ?   ?   ??? Libraries ?   ?   ?   ???
> ogdi ?   ?   ??? PlugIns ?   ?   ??? Programs ?   ?   ??? Python ?
> ?   ?   ??? 2.6 ?   ?   ?   ?   ??? site-packages ?   ?   ?   ?
> ??? osgeo ?   ?   ?   ??? 2.7 ?   ?   ?       ??? site-packages ?
> ?   ?           ??? osgeo ?   ?   ??? Resources ?   ?   ?   ???
> doc ?   ?   ?   ?   ??? gdal ?   ?   ?   ?       ??? java ?   ?   ?
> ?       ?   ??? org ?   ?   ?   ?       ?   ?   ??? gdal ?   ?   ?
> ?       ?   ?       ??? gdal ?   ?   ?   ?       ?   ?       ???
> gdalconst ?   ?   ?   ?       ?   ?       ??? ogr ?   ?   ?   ?
> ?   ?       ??? osr ?   ?   ?   ?       ?   ??? resources ?   ?   ?
> ?       ??? ogr ?   ?   ?   ??? gdal ?   ?   ??? unix ?   ?
> ??? bin ?   ?       ??? include -> ../Headers ?   ?       ??? lib ?
> ??? Current -> 1.10 ??? unix -> Versions/Current/unix
> 
> 
>>>> 
>>>> Cheers!
>>>> 
>>>> --j
>>>> 
> 
> 
> 
> 

- -- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQEcBAEBAgAGBQJSzwGOAAoJENvXNx4PUvmCNcUH/RHSZJgaIbMsipZUD2dCL+Fx
dTquYOrt7v1w1JZ+nrVNcU65o9Dp91GmGQ2w61EF9l+59y3e91UynFu94/OLEZIb
37aZvss28lsRW1MokJZRBWor8z3EQNY2kq8c4GOZoMBIRTT+LK9Mvv/EQXcntP0P
LXyTb3fXdXE/GePOteiG2vyCzu36maENbfbY5nqVIiu+qO5H60HcFmJR7FcX1Ty/
Q8BQ4vMkJQm6tJ2ozUJNHccgb0klNqUEp1Kwmiufen1m4jN3Qv9v1epAFLz6KArx
7j5O4pGLzdQXbnEjLSCwS1GL8P6+jWXzbiZA1KX+FI2xypu762b5tKXcw5eVw6w=
=tCRS
-----END PGP SIGNATURE-----


From Rainer at krugs.de  Thu Jan  9 21:15:08 2014
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 9 Jan 2014 21:15:08 +0100
Subject: [R-sig-Geo] gdalUtils 0.2.0 now on CRAN
In-Reply-To: <CABG0rftdyGVmZKhzRQfWzYVUPjceTgr1pxBQn8Jg1RmDBadcxw@mail.gmail.com>
References: <CABG0rfs2QVzFmjQ7QAya-G84Ci+kDHvDStT95jijdOYCiCaKEQ@mail.gmail.com>	<52CE5D98.7010303@krugs.de>	<CABG0rfvzkP-NJ+vH_MQ=vbdQsBrDRkLPFUP7Whiq=j4DcovabA@mail.gmail.com>	<CANnL8gpzLs7stQU6uAXGtW18bcmNH2YteogT_D=pnkH8S+Gj+w@mail.gmail.com>
	<CABG0rftdyGVmZKhzRQfWzYVUPjceTgr1pxBQn8Jg1RmDBadcxw@mail.gmail.com>
Message-ID: <52CF034C.9060505@krugs.de>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1



On 01/09/14, 19:43 , Jonathan Greenberg wrote:
> Tim: thanks! We have something similar, where the package uses a 
> Sys.which() to see if gdalinfo is available in the PATH as one of
> its attempts to find a valid install.
> 
> Rainer et al: I pushed version 0.2.3 to R-forge (you'll need to SVN
> it until R-forge builds the new package later today/tomorrow) which
> now supports a fixed search_path parameter.  To use this:
> 
> gdal_setInstallation(search_path="/pathto/your/favorite/GDAL/",rescan=TRUE)
>
>  If it finds a valid gdalinfo in that path, it will use that one
> (thus forcing gdalUtils to use a specific install).  If it doesn't
> find it, it will search as usual.  Note that I updated the help
> for gdal_setInstallation to better explain how gdalUtils searches
> for a valid install.

This sounds very useful. But to come back to the importing of rgdal,
which was causing my problem: As gdalUtils is quite useful without
rgdal, would it be possible to move rgdal to Enhances and to disable
the functions which require rgdal when rgdal is not installed?
And if rgdal is installed, to use the same gdal installation (I don't
know if this is the case already)?

Just a ciosmetic suggestion: it would be nice if, when loadu=ing the
package via library(gdalUtils), that the gdal version and path could
be printed.

Thanks,

Rainer


> 
> Here's the R-forge site: 
> https://r-forge.r-project.org/projects/gdalutils/
> 
> --j
> 
> On Thu, Jan 9, 2014 at 12:10 PM, Tim Keitt <tkeitt at utexas.edu>
> wrote:
>> You might also try "gdal-config --prefix". Of course that wont
>> work if gdal-config not installed or in the path.
>> 
>> THK
>> 
>> 
>> On Thu, Jan 9, 2014 at 11:46 AM, Jonathan Greenberg
>> <jgrn at illinois.edu> wrote:
>>> 
>>> Rainer:
>>> 
>>> Responses below!
>>> 
>>> On Thu, Jan 9, 2014 at 2:28 AM, Rainer M Krug <Rainer at krugs.de>
>>> wrote:
> 
> 
>>>> 
> 
> Very nice - haven't tried any working examples, but it installs on
> a mac without problems and finds the gdal installation installed
> via homebrew.
> 
> But I have some questions:
> 
> The automatic search is nice - but I unlinked gdal via homebrew,
> i.e. the links to the binaries and libraries are not in the path
> anymore, and I could not load gdalUtils anymore, as the gdalUtils
> did not find the libraries anymore (understandable). But it seams,
> that gdalUtils did not search for gdal, which is installed as a
> Framework as well. Now I removed gdalUtils again and installed it
> again, with gdal still unlinked, but it did not install as it did
> not find the gdal libraries, despite gdal being available in a
> framework (see http://www.kyngchaos.com/software/frameworks for the
> ones installed - they are quite popular, and required, among GRASS
> and QGIS users on Mac).
>>>> 
>>>> Quick question: did you try restarting R AFTER you unlinked
>>>> the homebrew version?  Here's why I ask: the first time you
>>>> run ANY gdalUtils in a session, what it does is spiders your
>>>> system for working GDAL installations (in fact, it looks for
>>>> the frameworks first).  After this first time, it won't
>>>> re-scan the drive unless you do one of two things: 1) restart
>>>> R and re-load GDALUtils, or 2) run 
>>>> gdal_setInstallation(rescan=TRUE)
>>>> 
> Question 1:
> 
> Would it be possible, to include the gdal Frameworks in the search
> path?
>>>> 
>>>> These are the common locations it searches for, before it
>>>> attempts a brute-force search of your whole drive:
>>>> 
>>>> if (.Platform$OS=="unix") { common_locations <- c( # UNIX
>>>> systems "/usr/bin", "/usr/local/bin", # Mac # Kyngchaos
>>>> frameworks: "/Library/Frameworks/GDAL.framework/Programs", #
>>>> MacPorts: "/opt/local/bin" ) } if (.Platform$OS=="windows") 
>>>> { common_locations <- c( "C:\\Program Files", "C:\\Program
>>>> Files (x86)", "C:\\OSGeo4W" ) }
>>>> 
>>>> I use those frameworks, and the function worked for me, but
>>>> let me know if it failed to find yours (perhaps I'll strip
>>>> the /Programs from the search path?)  It is easy for me to
>>>> add new search locations, so if there are other common
>>>> locations for ANY OS just let me know.
>>>> 
> 
> At the end is a layout of the directory structure of the gdal 
> frameworks.
> 
> Question 2:
> 
> Is it (or would it) be possible to manually set the installation
> of gdal to be used? This would make comparison of versions of gdal
> as well as reproducible research much easier.
>>>> 
>>>> Yes, we can add in this functionality at a future date.
>>>> Right now, you can check to see what your installs are by: 
>>>> gdal_setInstallation(rescan=TRUE) 
>>>> getOption("gdalUtils_gdalPath")
>>>> 
>>>> In general, gdalUtils will use the first element of the 
>>>> getOption("gdalUtils_gdalPath"), which is chosen by the most
>>>> recent version (by date).
>>>> 
> Question 3:
> 
> I can't test it right now, but I assume that gdalUtils does search
> for a new gdal installation if it can't find the one used before?
> Is there a way of initiating the search (and selection) if a newer
> version has been installed?
>>>> 
>>>> Yep, as I said either restart R or run: 
>>>> gdal_setInstallation(rescan=TRUE)
>>>> 
> 
> Thanks for a very neat package,
> 
> Rainer
> 
> Directory structure of the GDAL.Framework on a MAC:
> 
> /Library/Frameworks/GDAL.framework/ ??? Headers ->
> Versions/Current/Headers ??? Programs -> Versions/Current/Programs 
> ??? Resources -> Versions/Current/Resources ??? Versions ?   ???
> 1.10 ?   ?   ??? Headers ?   ?   ??? Libraries ?   ?   ?   ???
> ogdi ?   ?   ??? PlugIns ?   ?   ??? Programs ?   ?   ??? Python ?
> ?   ?   ??? 2.6 ?   ?   ?   ?   ??? site-packages ?   ?   ?   ?
> ??? osgeo ?   ?   ?   ??? 2.7 ?   ?   ?       ??? site-packages ?
> ?   ?           ??? osgeo ?   ?   ??? Resources ?   ?   ?   ???
> doc ?   ?   ?   ?   ??? gdal ?   ?   ?   ?       ??? java ?   ?   ?
> ?       ?   ??? org ?   ?   ?   ?       ?   ?   ??? gdal ?   ?   ?
> ?       ?   ?       ??? gdal ?   ?   ?   ?       ?   ?       ???
> gdalconst ?   ?   ?   ?       ?   ?       ??? ogr ?   ?   ?   ?
> ?   ?       ??? osr ?   ?   ?   ?       ?   ??? resources ?   ?   ?
> ?       ??? ogr ?   ?   ?   ??? gdal ?   ?   ??? unix ?   ?
> ??? bin ?   ?       ??? include -> ../Headers ?   ?       ??? lib ?
> ??? 1.9 ?   ?   ??? Headers ?   ?   ??? Libraries ?   ?   ?   ???
> ogdi ?   ?   ??? PlugIns ?   ?   ??? Programs ?   ?   ??? Python ?
> ?   ?   ??? 2.6 ?   ?   ?   ?   ??? site-packages ?   ?   ?   ?
> ??? osgeo ?   ?   ?   ??? 2.7 ?   ?   ?       ??? site-packages ?
> ?   ?           ??? osgeo ?   ?   ??? Resources ?   ?   ?   ???
> doc ?   ?   ?   ?   ??? gdal ?   ?   ?   ?       ??? java ?   ?   ?
> ?       ?   ??? org ?   ?   ?   ?       ?   ?   ??? gdal ?   ?   ?
> ?       ?   ?       ??? gdal ?   ?   ?   ?       ?   ?       ???
> gdalconst ?   ?   ?   ?       ?   ?       ??? ogr ?   ?   ?   ?
> ?   ?       ??? osr ?   ?   ?   ?       ?   ??? resources ?   ?   ?
> ?       ??? ogr ?   ?   ?   ??? gdal ?   ?   ??? unix ?   ?
> ??? bin ?   ?       ??? include -> ../Headers ?   ?       ??? lib ?
> ??? Current -> 1.10 ??? unix -> Versions/Current/unix
> 
> 
>>>>>> 
>>>>>> Cheers!
>>>>>> 
>>>>>> --j
>>>>>> 
> 
>>> 
>>> 
>>> 
>>> -- Jonathan A. Greenberg, PhD Assistant Professor Global
>>> Environmental Analysis and Remote Sensing (GEARS) Laboratory 
>>> Department of Geography and Geographic Information Science 
>>> University of Illinois at Urbana-Champaign 259 Computing
>>> Applications Building, MC-150 605 East Springfield Avenue 
>>> Champaign, IL  61820-6371 Phone: 217-300-1924 
>>> http://www.geog.illinois.edu/~jgrn/ AIM: jgrn307, MSN:
>>> jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>>> 
>>> _______________________________________________ R-sig-Geo
>>> mailing list R-sig-Geo at r-project.org 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>> 
>> 
>> 
>> -- http://www.keittlab.org/
> 
> 
> 

- -- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQEcBAEBAgAGBQJSzwNMAAoJENvXNx4PUvmCjHAIAJQG7cMz0BgzTQEYdgMl3/xi
1TH+8rgLFREc/J5DTm24ohpS+SwMDFVVsDeBoPYWX+RWyImN54OuozW4dnAO3Z7t
8xt15eZaBi/u8PncYlqht9END7nBi1RmIznb5VIMdkqCtT1FfhycsUuSRqTeJaX8
0ocaDFIkJTY76UJQ2w9TYVMLuYByNMbr8Y5B6PDCqHiNG0JTT46CfKReP3JlVbPd
gEnlSA4FD3h8ACBfJUP7/pSkNj+AzmufBqZPczIJSHYL8dxC03FvAn2FTQcYwL2M
p376qaThGvgOjN1QrebNffzPm96nyh4DYZPT2lCFeqYwFP0+JANGreEaNzO+flA=
=Jeqi
-----END PGP SIGNATURE-----


From jgrn at illinois.edu  Thu Jan  9 22:13:34 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Thu, 9 Jan 2014 15:13:34 -0600
Subject: [R-sig-Geo] gdalUtils 0.2.0 now on CRAN
In-Reply-To: <52CF034C.9060505@krugs.de>
References: <CABG0rfs2QVzFmjQ7QAya-G84Ci+kDHvDStT95jijdOYCiCaKEQ@mail.gmail.com>
	<52CE5D98.7010303@krugs.de>
	<CABG0rfvzkP-NJ+vH_MQ=vbdQsBrDRkLPFUP7Whiq=j4DcovabA@mail.gmail.com>
	<CANnL8gpzLs7stQU6uAXGtW18bcmNH2YteogT_D=pnkH8S+Gj+w@mail.gmail.com>
	<CABG0rftdyGVmZKhzRQfWzYVUPjceTgr1pxBQn8Jg1RmDBadcxw@mail.gmail.com>
	<52CF034C.9060505@krugs.de>
Message-ID: <CABG0rfvK1L+QKS1j0wt9Undc-WGep-EE13ypxPy_-XAf-6Fpaw@mail.gmail.com>

Ok, pushed a new version (0.2.4) to R-forge following these
suggestions (rgdal and raster are now moved to "Suggests", and the
examples should hopefully be updated to support it).

Rainer: would you mind testing this out?  Try it with and without
outputRaster=TRUE (it should fail on outputRaster=TRUE if you don't
have rgdal installed).

--j

On Thu, Jan 9, 2014 at 2:15 PM, Rainer M Krug <Rainer at krugs.de> wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
>
>
> On 01/09/14, 19:43 , Jonathan Greenberg wrote:
>> Tim: thanks! We have something similar, where the package uses a
>> Sys.which() to see if gdalinfo is available in the PATH as one of
>> its attempts to find a valid install.
>>
>> Rainer et al: I pushed version 0.2.3 to R-forge (you'll need to SVN
>> it until R-forge builds the new package later today/tomorrow) which
>> now supports a fixed search_path parameter.  To use this:
>>
>> gdal_setInstallation(search_path="/pathto/your/favorite/GDAL/",rescan=TRUE)
>>
>>  If it finds a valid gdalinfo in that path, it will use that one
>> (thus forcing gdalUtils to use a specific install).  If it doesn't
>> find it, it will search as usual.  Note that I updated the help
>> for gdal_setInstallation to better explain how gdalUtils searches
>> for a valid install.
>
> This sounds very useful. But to come back to the importing of rgdal,
> which was causing my problem: As gdalUtils is quite useful without
> rgdal, would it be possible to move rgdal to Enhances and to disable
> the functions which require rgdal when rgdal is not installed?
> And if rgdal is installed, to use the same gdal installation (I don't
> know if this is the case already)?
>
> Just a ciosmetic suggestion: it would be nice if, when loadu=ing the
> package via library(gdalUtils), that the gdal version and path could
> be printed.
>
> Thanks,
>
> Rainer
>
>
>>
>> Here's the R-forge site:
>> https://r-forge.r-project.org/projects/gdalutils/
>>
>> --j
>>
>> On Thu, Jan 9, 2014 at 12:10 PM, Tim Keitt <tkeitt at utexas.edu>
>> wrote:
>>> You might also try "gdal-config --prefix". Of course that wont
>>> work if gdal-config not installed or in the path.
>>>
>>> THK
>>>
>>>
>>> On Thu, Jan 9, 2014 at 11:46 AM, Jonathan Greenberg
>>> <jgrn at illinois.edu> wrote:
>>>>
>>>> Rainer:
>>>>
>>>> Responses below!
>>>>
>>>> On Thu, Jan 9, 2014 at 2:28 AM, Rainer M Krug <Rainer at krugs.de>
>>>> wrote:
>>
>>
>>>>>
>>
>> Very nice - haven't tried any working examples, but it installs on
>> a mac without problems and finds the gdal installation installed
>> via homebrew.
>>
>> But I have some questions:
>>
>> The automatic search is nice - but I unlinked gdal via homebrew,
>> i.e. the links to the binaries and libraries are not in the path
>> anymore, and I could not load gdalUtils anymore, as the gdalUtils
>> did not find the libraries anymore (understandable). But it seams,
>> that gdalUtils did not search for gdal, which is installed as a
>> Framework as well. Now I removed gdalUtils again and installed it
>> again, with gdal still unlinked, but it did not install as it did
>> not find the gdal libraries, despite gdal being available in a
>> framework (see http://www.kyngchaos.com/software/frameworks for the
>> ones installed - they are quite popular, and required, among GRASS
>> and QGIS users on Mac).
>>>>>
>>>>> Quick question: did you try restarting R AFTER you unlinked
>>>>> the homebrew version?  Here's why I ask: the first time you
>>>>> run ANY gdalUtils in a session, what it does is spiders your
>>>>> system for working GDAL installations (in fact, it looks for
>>>>> the frameworks first).  After this first time, it won't
>>>>> re-scan the drive unless you do one of two things: 1) restart
>>>>> R and re-load GDALUtils, or 2) run
>>>>> gdal_setInstallation(rescan=TRUE)
>>>>>
>> Question 1:
>>
>> Would it be possible, to include the gdal Frameworks in the search
>> path?
>>>>>
>>>>> These are the common locations it searches for, before it
>>>>> attempts a brute-force search of your whole drive:
>>>>>
>>>>> if (.Platform$OS=="unix") { common_locations <- c( # UNIX
>>>>> systems "/usr/bin", "/usr/local/bin", # Mac # Kyngchaos
>>>>> frameworks: "/Library/Frameworks/GDAL.framework/Programs", #
>>>>> MacPorts: "/opt/local/bin" ) } if (.Platform$OS=="windows")
>>>>> { common_locations <- c( "C:\\Program Files", "C:\\Program
>>>>> Files (x86)", "C:\\OSGeo4W" ) }
>>>>>
>>>>> I use those frameworks, and the function worked for me, but
>>>>> let me know if it failed to find yours (perhaps I'll strip
>>>>> the /Programs from the search path?)  It is easy for me to
>>>>> add new search locations, so if there are other common
>>>>> locations for ANY OS just let me know.
>>>>>
>>
>> At the end is a layout of the directory structure of the gdal
>> frameworks.
>>
>> Question 2:
>>
>> Is it (or would it) be possible to manually set the installation
>> of gdal to be used? This would make comparison of versions of gdal
>> as well as reproducible research much easier.
>>>>>
>>>>> Yes, we can add in this functionality at a future date.
>>>>> Right now, you can check to see what your installs are by:
>>>>> gdal_setInstallation(rescan=TRUE)
>>>>> getOption("gdalUtils_gdalPath")
>>>>>
>>>>> In general, gdalUtils will use the first element of the
>>>>> getOption("gdalUtils_gdalPath"), which is chosen by the most
>>>>> recent version (by date).
>>>>>
>> Question 3:
>>
>> I can't test it right now, but I assume that gdalUtils does search
>> for a new gdal installation if it can't find the one used before?
>> Is there a way of initiating the search (and selection) if a newer
>> version has been installed?
>>>>>
>>>>> Yep, as I said either restart R or run:
>>>>> gdal_setInstallation(rescan=TRUE)
>>>>>
>>
>> Thanks for a very neat package,
>>
>> Rainer
>>
>> Directory structure of the GDAL.Framework on a MAC:
>>
>> /Library/Frameworks/GDAL.framework/ ??? Headers ->
>> Versions/Current/Headers ??? Programs -> Versions/Current/Programs
>> ??? Resources -> Versions/Current/Resources ??? Versions ?   ???
>> 1.10 ?   ?   ??? Headers ?   ?   ??? Libraries ?   ?   ?   ???
>> ogdi ?   ?   ??? PlugIns ?   ?   ??? Programs ?   ?   ??? Python ?
>> ?   ?   ??? 2.6 ?   ?   ?   ?   ??? site-packages ?   ?   ?   ?
>> ??? osgeo ?   ?   ?   ??? 2.7 ?   ?   ?       ??? site-packages ?
>> ?   ?           ??? osgeo ?   ?   ??? Resources ?   ?   ?   ???
>> doc ?   ?   ?   ?   ??? gdal ?   ?   ?   ?       ??? java ?   ?   ?
>> ?       ?   ??? org ?   ?   ?   ?       ?   ?   ??? gdal ?   ?   ?
>> ?       ?   ?       ??? gdal ?   ?   ?   ?       ?   ?       ???
>> gdalconst ?   ?   ?   ?       ?   ?       ??? ogr ?   ?   ?   ?
>> ?   ?       ??? osr ?   ?   ?   ?       ?   ??? resources ?   ?   ?
>> ?       ??? ogr ?   ?   ?   ??? gdal ?   ?   ??? unix ?   ?
>> ??? bin ?   ?       ??? include -> ../Headers ?   ?       ??? lib ?
>> ??? 1.9 ?   ?   ??? Headers ?   ?   ??? Libraries ?   ?   ?   ???
>> ogdi ?   ?   ??? PlugIns ?   ?   ??? Programs ?   ?   ??? Python ?
>> ?   ?   ??? 2.6 ?   ?   ?   ?   ??? site-packages ?   ?   ?   ?
>> ??? osgeo ?   ?   ?   ??? 2.7 ?   ?   ?       ??? site-packages ?
>> ?   ?           ??? osgeo ?   ?   ??? Resources ?   ?   ?   ???
>> doc ?   ?   ?   ?   ??? gdal ?   ?   ?   ?       ??? java ?   ?   ?
>> ?       ?   ??? org ?   ?   ?   ?       ?   ?   ??? gdal ?   ?   ?
>> ?       ?   ?       ??? gdal ?   ?   ?   ?       ?   ?       ???
>> gdalconst ?   ?   ?   ?       ?   ?       ??? ogr ?   ?   ?   ?
>> ?   ?       ??? osr ?   ?   ?   ?       ?   ??? resources ?   ?   ?
>> ?       ??? ogr ?   ?   ?   ??? gdal ?   ?   ??? unix ?   ?
>> ??? bin ?   ?       ??? include -> ../Headers ?   ?       ??? lib ?
>> ??? Current -> 1.10 ??? unix -> Versions/Current/unix
>>
>>
>>>>>>>
>>>>>>> Cheers!
>>>>>>>
>>>>>>> --j
>>>>>>>
>>
>>>>
>>>>
>>>>
>>>> -- Jonathan A. Greenberg, PhD Assistant Professor Global
>>>> Environmental Analysis and Remote Sensing (GEARS) Laboratory
>>>> Department of Geography and Geographic Information Science
>>>> University of Illinois at Urbana-Champaign 259 Computing
>>>> Applications Building, MC-150 605 East Springfield Avenue
>>>> Champaign, IL  61820-6371 Phone: 217-300-1924
>>>> http://www.geog.illinois.edu/~jgrn/ AIM: jgrn307, MSN:
>>>> jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>>>>
>>>> _______________________________________________ R-sig-Geo
>>>> mailing list R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>>
>>>
>>> -- http://www.keittlab.org/
>>
>>
>>
>
> - --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
> Biology, UCT), Dipl. Phys. (Germany)
>
> Centre of Excellence for Invasion Biology
> Stellenbosch University
> South Africa
>
> Tel :       +33 - (0)9 53 10 27 44
> Cell:       +33 - (0)6 85 62 59 98
> Fax :       +33 - (0)9 58 10 27 44
>
> Fax (D):    +49 - (0)3 21 21 25 22 44
>
> email:      Rainer at krugs.de
>
> Skype:      RMkrug
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
> Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/
>
> iQEcBAEBAgAGBQJSzwNMAAoJENvXNx4PUvmCjHAIAJQG7cMz0BgzTQEYdgMl3/xi
> 1TH+8rgLFREc/J5DTm24ohpS+SwMDFVVsDeBoPYWX+RWyImN54OuozW4dnAO3Z7t
> 8xt15eZaBi/u8PncYlqht9END7nBi1RmIznb5VIMdkqCtT1FfhycsUuSRqTeJaX8
> 0ocaDFIkJTY76UJQ2w9TYVMLuYByNMbr8Y5B6PDCqHiNG0JTT46CfKReP3JlVbPd
> gEnlSA4FD3h8ACBfJUP7/pSkNj+AzmufBqZPczIJSHYL8dxC03FvAn2FTQcYwL2M
> p376qaThGvgOjN1QrebNffzPm96nyh4DYZPT2lCFeqYwFP0+JANGreEaNzO+flA=
> =Jeqi
> -----END PGP SIGNATURE-----



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From alobolistas at gmail.com  Fri Jan 10 09:11:13 2014
From: alobolistas at gmail.com (Agustin Lobo)
Date: Fri, 10 Jan 2014 09:11:13 +0100
Subject: [R-sig-Geo] writeRaster() error with raster_2.2-5
In-Reply-To: <CAG4NReJF+7VD43Mh1ZT-WPu4ikEzvBgrs12fj06q_+StpZ2dmA@mail.gmail.com>
References: <CAG4NReJF+7VD43Mh1ZT-WPu4ikEzvBgrs12fj06q_+StpZ2dmA@mail.gmail.com>
Message-ID: <CAG4NReJGYs2HraM4hbYLwvebV4tg9KmQna09cmAuQmY2LSKEeg@mail.gmail.com>

The error vanishes after starting a new R session.
This is probably a consequence of having installed the package from within
RStudio, even if the previous version was actually not loaded.
I will add "install from raw R session" and "re-start R after package
installation"
to my protocol before actually reporting an error. Apologies.

Agus



On Thu, Jan 9, 2014 at 3:11 PM, Agustin Lobo <alobolistas at gmail.com> wrote:
> I'm getting this problem with raster_2.2-5 rgdal_0.8-14 (was working
> until I updated):
>
> test <- raster(matrix(10,nrow=4,ncol=4))
> writeRaster(test,file="test",format="GTiff",overwrite=TRUE)
>
> Error in .getGDALtransient(x, filename = filename, options = options,  :
>   could not find function "GDALcall"
>
> Instead
> writeGDAL(as(test, "SpatialGridDataFrame"), fname ="test")
> works fine.
>
> It looks like the same problem we had few weeks ago is back
> http://r-sig-geo.2731867.n2.nabble.com/Error-in-gd-SetProject-transient-crs-r-td7585330.html#a7585432
>
>> sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> rgdal: version: 0.8-14, (SVN revision 496)
> Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 1.10.0, released 2013/04/24
> Path to GDAL shared files: /usr/share/gdal/1.10
> Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
> Path to PROJ.4 shared files: (autodetected)
>
> Tried with raster version in R-forge, same problem
>
> Agus


From Rainer at krugs.de  Fri Jan 10 09:50:50 2014
From: Rainer at krugs.de (Rainer M Krug)
Date: Fri, 10 Jan 2014 09:50:50 +0100
Subject: [R-sig-Geo] gdalUtils 0.2.0 now on CRAN
In-Reply-To: <CABG0rfvK1L+QKS1j0wt9Undc-WGep-EE13ypxPy_-XAf-6Fpaw@mail.gmail.com>
References: <CABG0rfs2QVzFmjQ7QAya-G84Ci+kDHvDStT95jijdOYCiCaKEQ@mail.gmail.com>	<52CE5D98.7010303@krugs.de>	<CABG0rfvzkP-NJ+vH_MQ=vbdQsBrDRkLPFUP7Whiq=j4DcovabA@mail.gmail.com>	<CANnL8gpzLs7stQU6uAXGtW18bcmNH2YteogT_D=pnkH8S+Gj+w@mail.gmail.com>	<CABG0rftdyGVmZKhzRQfWzYVUPjceTgr1pxBQn8Jg1RmDBadcxw@mail.gmail.com>	<52CF034C.9060505@krugs.de>
	<CABG0rfvK1L+QKS1j0wt9Undc-WGep-EE13ypxPy_-XAf-6Fpaw@mail.gmail.com>
Message-ID: <52CFB46A.6000707@krugs.de>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1



On 01/09/14, 22:13 , Jonathan Greenberg wrote:
> Ok, pushed a new version (0.2.4) to R-forge following these 
> suggestions (rgdal and raster are now moved to "Suggests", and the 
> examples should hopefully be updated to support it).

OK - It installs and loads with disfunctional rgdal (I assume the
worst case scenario).

I then linked gdal again, and it is using the homebrew version (which
is good).

But I get the following:

###################################
> str(getOption("gdalUtils_gdalPath"))
List of 2
 $ :List of 5
  ..$ path            : chr "/usr/local/bin/"
  ..$ version         :List of 1
  .. ..$ version: chr "1.10.1"
  ..$ date            :List of 1
  .. ..$ date: chr "2013-08-26"
.
.SNIP
.
$ :List of 5
  ..$ path            : chr
"/Library/Frameworks/GDAL.framework/Versions/1.10/Programs/"
  ..$ version         :List of 1
  .. ..$ version: chr "1.10.1"
  ..$ date            :List of 1
  .. ..$ date: chr "2013-08-26"
.
.SNIP
.
###################################

but I have 1.9 installed as well - is it on purpose that gdalUtils
does not find this version as it is older?

> 
> Rainer: would you mind testing this out?  Try it with and without 
> outputRaster=TRUE (it should fail on outputRaster=TRUE if you
> don't have rgdal installed).

Haven't worked with gdalUtils yet - could you tell me which command I
should try with the outputRaster argument?

Cheers,

Rainer

> 
> --j
> 
> On Thu, Jan 9, 2014 at 2:15 PM, Rainer M Krug <Rainer at krugs.de>
> wrote:
> 
> 
> On 01/09/14, 19:43 , Jonathan Greenberg wrote:
>>>> Tim: thanks! We have something similar, where the package
>>>> uses a Sys.which() to see if gdalinfo is available in the
>>>> PATH as one of its attempts to find a valid install.
>>>> 
>>>> Rainer et al: I pushed version 0.2.3 to R-forge (you'll need
>>>> to SVN it until R-forge builds the new package later
>>>> today/tomorrow) which now supports a fixed search_path
>>>> parameter.  To use this:
>>>> 
>>>> gdal_setInstallation(search_path="/pathto/your/favorite/GDAL/",rescan=TRUE)
>>>>
>>>>
>>>> 
If it finds a valid gdalinfo in that path, it will use that one
>>>> (thus forcing gdalUtils to use a specific install).  If it
>>>> doesn't find it, it will search as usual.  Note that I
>>>> updated the help for gdal_setInstallation to better explain
>>>> how gdalUtils searches for a valid install.
> 
> This sounds very useful. But to come back to the importing of
> rgdal, which was causing my problem: As gdalUtils is quite useful
> without rgdal, would it be possible to move rgdal to Enhances and
> to disable the functions which require rgdal when rgdal is not
> installed? And if rgdal is installed, to use the same gdal
> installation (I don't know if this is the case already)?
> 
> Just a ciosmetic suggestion: it would be nice if, when loadu=ing
> the package via library(gdalUtils), that the gdal version and path
> could be printed.
> 
> Thanks,
> 
> Rainer
> 
> 
>>>> 
>>>> Here's the R-forge site: 
>>>> https://r-forge.r-project.org/projects/gdalutils/
>>>> 
>>>> --j
>>>> 
>>>> On Thu, Jan 9, 2014 at 12:10 PM, Tim Keitt
>>>> <tkeitt at utexas.edu> wrote:
>>>>> You might also try "gdal-config --prefix". Of course that
>>>>> wont work if gdal-config not installed or in the path.
>>>>> 
>>>>> THK
>>>>> 
>>>>> 
>>>>> On Thu, Jan 9, 2014 at 11:46 AM, Jonathan Greenberg 
>>>>> <jgrn at illinois.edu> wrote:
>>>>>> 
>>>>>> Rainer:
>>>>>> 
>>>>>> Responses below!
>>>>>> 
>>>>>> On Thu, Jan 9, 2014 at 2:28 AM, Rainer M Krug
>>>>>> <Rainer at krugs.de> wrote:
>>>> 
>>>> 
>>>>>>> 
>>>> 
>>>> Very nice - haven't tried any working examples, but it
>>>> installs on a mac without problems and finds the gdal
>>>> installation installed via homebrew.
>>>> 
>>>> But I have some questions:
>>>> 
>>>> The automatic search is nice - but I unlinked gdal via
>>>> homebrew, i.e. the links to the binaries and libraries are
>>>> not in the path anymore, and I could not load gdalUtils
>>>> anymore, as the gdalUtils did not find the libraries anymore
>>>> (understandable). But it seams, that gdalUtils did not search
>>>> for gdal, which is installed as a Framework as well. Now I
>>>> removed gdalUtils again and installed it again, with gdal
>>>> still unlinked, but it did not install as it did not find the
>>>> gdal libraries, despite gdal being available in a framework
>>>> (see http://www.kyngchaos.com/software/frameworks for the 
>>>> ones installed - they are quite popular, and required, among
>>>> GRASS and QGIS users on Mac).
>>>>>>> 
>>>>>>> Quick question: did you try restarting R AFTER you
>>>>>>> unlinked the homebrew version?  Here's why I ask: the
>>>>>>> first time you run ANY gdalUtils in a session, what it
>>>>>>> does is spiders your system for working GDAL
>>>>>>> installations (in fact, it looks for the frameworks
>>>>>>> first).  After this first time, it won't re-scan the
>>>>>>> drive unless you do one of two things: 1) restart R and
>>>>>>> re-load GDALUtils, or 2) run 
>>>>>>> gdal_setInstallation(rescan=TRUE)
>>>>>>> 
>>>> Question 1:
>>>> 
>>>> Would it be possible, to include the gdal Frameworks in the
>>>> search path?
>>>>>>> 
>>>>>>> These are the common locations it searches for, before
>>>>>>> it attempts a brute-force search of your whole drive:
>>>>>>> 
>>>>>>> if (.Platform$OS=="unix") { common_locations <- c( #
>>>>>>> UNIX systems "/usr/bin", "/usr/local/bin", # Mac #
>>>>>>> Kyngchaos frameworks:
>>>>>>> "/Library/Frameworks/GDAL.framework/Programs", # 
>>>>>>> MacPorts: "/opt/local/bin" ) } if
>>>>>>> (.Platform$OS=="windows") { common_locations <- c(
>>>>>>> "C:\\Program Files", "C:\\Program Files (x86)",
>>>>>>> "C:\\OSGeo4W" ) }
>>>>>>> 
>>>>>>> I use those frameworks, and the function worked for me,
>>>>>>> but let me know if it failed to find yours (perhaps
>>>>>>> I'll strip the /Programs from the search path?)  It is
>>>>>>> easy for me to add new search locations, so if there
>>>>>>> are other common locations for ANY OS just let me
>>>>>>> know.
>>>>>>> 
>>>> 
>>>> At the end is a layout of the directory structure of the
>>>> gdal frameworks.
>>>> 
>>>> Question 2:
>>>> 
>>>> Is it (or would it) be possible to manually set the
>>>> installation of gdal to be used? This would make comparison
>>>> of versions of gdal as well as reproducible research much
>>>> easier.
>>>>>>> 
>>>>>>> Yes, we can add in this functionality at a future
>>>>>>> date. Right now, you can check to see what your
>>>>>>> installs are by: gdal_setInstallation(rescan=TRUE) 
>>>>>>> getOption("gdalUtils_gdalPath")
>>>>>>> 
>>>>>>> In general, gdalUtils will use the first element of
>>>>>>> the getOption("gdalUtils_gdalPath"), which is chosen by
>>>>>>> the most recent version (by date).
>>>>>>> 
>>>> Question 3:
>>>> 
>>>> I can't test it right now, but I assume that gdalUtils does
>>>> search for a new gdal installation if it can't find the one
>>>> used before? Is there a way of initiating the search (and
>>>> selection) if a newer version has been installed?
>>>>>>> 
>>>>>>> Yep, as I said either restart R or run: 
>>>>>>> gdal_setInstallation(rescan=TRUE)
>>>>>>> 
>>>> 
>>>> Thanks for a very neat package,
>>>> 
>>>> Rainer
>>>> 
>>>> Directory structure of the GDAL.Framework on a MAC:
>>>> 
>>>> /Library/Frameworks/GDAL.framework/ ??? Headers -> 
>>>> Versions/Current/Headers ??? Programs ->
>>>> Versions/Current/Programs ??? Resources ->
>>>> Versions/Current/Resources ??? Versions ?   ??? 1.10 ?   ?
>>>> ??? Headers ?   ?   ??? Libraries ?   ?   ?   ??? ogdi ?   ?
>>>> ??? PlugIns ?   ?   ??? Programs ?   ?   ??? Python ? ?   ?
>>>> ??? 2.6 ?   ?   ?   ?   ??? site-packages ?   ?   ?   ? ???
>>>> osgeo ?   ?   ?   ??? 2.7 ?   ?   ?       ??? site-packages
>>>> ? ?   ?           ??? osgeo ?   ?   ??? Resources ?   ?   ?
>>>> ??? doc ?   ?   ?   ?   ??? gdal ?   ?   ?   ?       ??? java
>>>> ?   ?   ? ?       ?   ??? org ?   ?   ?   ?       ?   ?   ???
>>>> gdal ?   ?   ? ?       ?   ?       ??? gdal ?   ?   ?   ?
>>>> ?   ?       ??? gdalconst ?   ?   ?   ?       ?   ?       ???
>>>> ogr ?   ?   ?   ? ?   ?       ??? osr ?   ?   ?   ?       ?
>>>> ??? resources ?   ?   ? ?       ??? ogr ?   ?   ?   ??? gdal
>>>> ?   ?   ??? unix ?   ? ??? bin ?   ?       ??? include ->
>>>> ../Headers ?   ?       ??? lib ? ??? 1.9 ?   ?   ??? Headers
>>>> ?   ?   ??? Libraries ?   ?   ?   ??? ogdi ?   ?   ???
>>>> PlugIns ?   ?   ??? Programs ?   ?   ??? Python ? ?   ?   ???
>>>> 2.6 ?   ?   ?   ?   ??? site-packages ?   ?   ?   ? ??? osgeo
>>>> ?   ?   ?   ??? 2.7 ?   ?   ?       ??? site-packages ? ?   ?
>>>> ??? osgeo ?   ?   ??? Resources ?   ?   ?   ??? doc ?   ?   ?
>>>> ?   ??? gdal ?   ?   ?   ?       ??? java ?   ?   ? ?       ?
>>>> ??? org ?   ?   ?   ?       ?   ?   ??? gdal ?   ?   ? ?
>>>> ?   ?       ??? gdal ?   ?   ?   ?       ?   ?       ??? 
>>>> gdalconst ?   ?   ?   ?       ?   ?       ??? ogr ?   ?   ?
>>>> ? ?   ?       ??? osr ?   ?   ?   ?       ?   ??? resources ?
>>>> ?   ? ?       ??? ogr ?   ?   ?   ??? gdal ?   ?   ??? unix ?
>>>> ? ??? bin ?   ?       ??? include -> ../Headers ?   ?
>>>> ??? lib ? ??? Current -> 1.10 ??? unix ->
>>>> Versions/Current/unix
>>>> 
>>>> 
>>>>>>>>> 
>>>>>>>>> Cheers!
>>>>>>>>> 
>>>>>>>>> --j
>>>>>>>>> 
>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> -- Jonathan A. Greenberg, PhD Assistant Professor Global 
>>>>>> Environmental Analysis and Remote Sensing (GEARS)
>>>>>> Laboratory Department of Geography and Geographic
>>>>>> Information Science University of Illinois at
>>>>>> Urbana-Champaign 259 Computing Applications Building,
>>>>>> MC-150 605 East Springfield Avenue Champaign, IL
>>>>>> 61820-6371 Phone: 217-300-1924 
>>>>>> http://www.geog.illinois.edu/~jgrn/ AIM: jgrn307, MSN: 
>>>>>> jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>>>>>> 
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list R-sig-Geo at r-project.org 
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> -- http://www.keittlab.org/
>>>> 
>>>> 
>>>> 
> 
> 
> 
> 

- -- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQEcBAEBAgAGBQJSz7RqAAoJENvXNx4PUvmCXVgH/0/sTGd62EFLyNV+3P0p8WuJ
nZJQrIOJtQqq8B5Ds7gXY5yvaWxbXqEPgqe1a7sldybrcux7c7srTbslV1aX0rAg
oZHaNvBYwdPfZZFM9JQfZn9XSa2kGYo9VMkLCcjCBo/Bdn4V3ITeoUpuuRqLpsZ5
bl85aR3mOCeKXpQII+1kqWZGgOg6BfnmGWriKy96U2Mi4DwHSpD2qXqr5wkevItZ
ADb8sTJvfmrsUHrzJyOMU2qO1G779Zy4/QrbT/9bQe5fJotw0Rv/pm0091ESxncE
sJZcis1HLauD+i1V74aZmDG8lDGisVaDOqkTtdzgjOUAIeKs7zEcd46UoAmzpOs=
=lofs
-----END PGP SIGNATURE-----


From eddieatr at gmail.com  Fri Jan 10 11:00:56 2014
From: eddieatr at gmail.com (Eddie Smith)
Date: Fri, 10 Jan 2014 10:00:56 +0000
Subject: [R-sig-Geo] Why does focal() reduce the rows and columns of my
	raster?
Message-ID: <CABaJH78uVOGqvb6yWC3A13pXevzVs-0CAPsvtFoRUwWDRO-udQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140110/a9a3f7dc/attachment.pl>

From jillian.deines at gmail.com  Fri Jan 10 17:04:26 2014
From: jillian.deines at gmail.com (Jill Deines)
Date: Fri, 10 Jan 2014 11:04:26 -0500
Subject: [R-sig-Geo] Help with getting and processing MODIS data
Message-ID: <CAKCTE4zfgoS-1h0UkuHZO=hpHOi6gJr5RQd7JKNQByCiU4J9Ng@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140110/ba097fa4/attachment.pl>

From jgrn at illinois.edu  Fri Jan 10 17:14:12 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Fri, 10 Jan 2014 10:14:12 -0600
Subject: [R-sig-Geo] Why does focal() reduce the rows and columns of my
	raster?
In-Reply-To: <CABaJH78uVOGqvb6yWC3A13pXevzVs-0CAPsvtFoRUwWDRO-udQ@mail.gmail.com>
References: <CABaJH78uVOGqvb6yWC3A13pXevzVs-0CAPsvtFoRUwWDRO-udQ@mail.gmail.com>
Message-ID: <CABG0rftPfEeySsj+H4uqCgMMy-WZgypu9u8LQhJ6sziYGJ_FcA@mail.gmail.com>

Hi Eddie:

focal windows, because they are centered around a cell, have to know
how to deal with edge pixels.  In the case of a 3x3 window, both the
first/last row and first/last column are "special cases" because the
3x3 window surrounding those pixels runs off of the image.  Focal
analyses have to know how to treat these locations.  Take a look at
the "pad" parameter to understand what focal is doing in these special
cases.

--j

On Fri, Jan 10, 2014 at 4:00 AM, Eddie Smith <eddieatr at gmail.com> wrote:
> Hi guys,
>
> This is my first attemp using focal() in raster package.
>
> Looking at the raster dimension after running focal(), it seems that
> everything is OK until I plot the raster and found  out that the first and
> last column/row has been change to NA.
>
> Any help guys?
>
> Thanks in advance.
>
> r <- raster(ncols=5, nrows=5, xmn=0)
> r[] <- runif(ncell(r))
> r
>> r
> class       : RasterLayer
> dimensions  : 10, 10, 100  (nrow, ncol, ncell)
> resolution  : 18, 18  (x, y)
> extent      : 0, 180, -90, 90  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> data source : in memory
> names       : layer
> values      : 0.01734865, 0.9977548  (min, max)
>
> # 3x3 mean filter
> r3 <- focal(r, w=matrix(1/9,nrow=3,ncol=3))
> r3
>> r3
> class       : RasterLayer
> dimensions  : 10, 10, 100  (nrow, ncol, ncell)
> resolution  : 18, 18  (x, y)
> extent      : 0, 180, -90, 90  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> data source : in memory
> names       : layer
> values      : 0.346758, 0.6850644  (min, max)
>
> #plot 2 rasters
> par(mfrow=c(1,2))
> plot(r)
> plot(r3)
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From ing.cg.andressanchez at hotmail.com  Fri Jan 10 17:57:52 2014
From: ing.cg.andressanchez at hotmail.com (Andres Sanchez)
Date: Fri, 10 Jan 2014 08:57:52 -0800 (PST)
Subject: [R-sig-Geo] Error in the implementation of function K
Message-ID: <1389373072643-7585527.post@n2.nabble.com>

Good day,

I been reading manual of package Stpp, to need implementate the STIKhat
function but i am a begineer,
I read the manual and either run the example but when I try to do that with
my data I get the following error.


<http://r-sig-geo.2731867.n2.nabble.com/file/n7585527/Error_en_la_funcion_K.jpg> 


Please help me, not that I'm wrong and I reviewed the functions but not the
error which can be



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Error-in-the-implementation-of-function-K-tp7585527.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From samanmonfared1 at gmail.com  Sat Jan 11 10:12:38 2014
From: samanmonfared1 at gmail.com (Saman Monfared)
Date: Sat, 11 Jan 2014 12:42:38 +0330
Subject: [R-sig-Geo] Problem about ST kriging in gstat
Message-ID: <CAOytA4ajLiKmKkmzn25AG-r4fMjCbX66Csn_b76_DUiP5ieijA@mail.gmail.com>

Dear list,
I try to ST modeling of TB incidence rate in 38 center on 6 years.
My problem is all ST predictions values
are equal for all points of space and time except the first timelag. I
have examined this program for some another data set but the problem
remains.
All reqires data and program are attached.

rm(list=ls())
library("gstat")
library("spacetime")
dd<-read.table("TBincidencerate1.txt",header=T)
loc<-read.table("kashmarloc.txt",header=T)
coordinates(loc) = ~x+y
dd$time = ISOdate(dd$year,dd$mounth,dd$day,0)
stations = 4:41
w=STFDF(loc,dd$time,data.frame(values = as.vector(t(dd[stations]/12))))
gg<-read.table("point.pred.TB.txt",header=T)
grd = SpatialPixels(SpatialPoints(gg))
plot(grd)
tgrd = seq(min(index(w)), max(index(w))+2*360*24*3600,length=6)
tgrd
library(lattice)
pred.grd = STF(grd, tgrd)
plot(pred.grd )
vv<-variogramST(values ~ 1,w,tlags=0:15,cutoff=55000)
plot(vv,map=F,np=TRUE,cex=1,lwd=1.5,pch=19)
wireframe(gamma~spacelag+timelag,vv,drape =T,scales=list(arrows=F,
mai=c(4,5,2,2)),zlab=expression(gamma),
,light.source = c(10,0,10))
separableModel <- vgmST("separable",space=vgm(.23,"Hol",5000,.77),
time =vgm(.84,"Hol",150,0), sill=20)
wireframe(model~spacelag+timelag,variogramSurface(separableModel,vv),
drape =T,light.source =c(10,0,10),scales=list(arrows=F))
ff<-fit.StVariogram(vv,separableModel, method ="L-BFGS-B",wles =T)
ff
#     range.s     nugget.s      range.t     nugget.t         sill
#4999.9993501    0.7498763  150.0034786    0.2262177   14.0396906

wireframe(model~spacelag+timelag,variogramSurface(ff,vv),drape =T,
,light.source = c(10,0,10),scales=list(arrows=F),
zlab=expression(gamma),main="fitted variogram ")
TB.ST = krigeST(values~1,w,pred.grd,ff)
stplot(TB.ST)

Thanks.

Saman.

-- 
Saman Monfared
Msc, Department of Statistics, Shiraz University,
Shiraz 71454, Iran
Email: Samanmonfared1 at gmail.com

Tel: +98 917 5305167
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ST-TB.rar
Type: application/rar
Size: 11202 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140111/63762a06/attachment.bin>

From cadrew at ncsu.edu  Sat Jan 11 20:44:04 2014
From: cadrew at ncsu.edu (Ashton Drew)
Date: Sat, 11 Jan 2014 14:44:04 -0500
Subject: [R-sig-Geo] reclassify question
Message-ID: <CAHvKwC5P7Htc=J_brGQsyszV9g0L_Y-dAGnBLVny7drCCxroKg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140111/084630c4/attachment.pl>

From edzer.pebesma at uni-muenster.de  Sat Jan 11 21:48:36 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sat, 11 Jan 2014 21:48:36 +0100
Subject: [R-sig-Geo] Problem about ST kriging in gstat
In-Reply-To: <CAOytA4ajLiKmKkmzn25AG-r4fMjCbX66Csn_b76_DUiP5ieijA@mail.gmail.com>
References: <CAOytA4ajLiKmKkmzn25AG-r4fMjCbX66Csn_b76_DUiP5ieijA@mail.gmail.com>
Message-ID: <52D1AE24.5070400@uni-muenster.de>

I re-ran your analysis, and see nothing strange; predictions vary over
space and time. Maybe you work with old(er) versions of packages? (It
seems so: newer versions of gstat require you to add a library(sp) on
the top of the script)

On 01/11/2014 10:12 AM, Saman Monfared wrote:
> Dear list,
> I try to ST modeling of TB incidence rate in 38 center on 6 years.
> My problem is all ST predictions values
> are equal for all points of space and time except the first timelag. I
> have examined this program for some another data set but the problem
> remains.
> All reqires data and program are attached.
> 
> rm(list=ls())
> library("gstat")
> library("spacetime")
> dd<-read.table("TBincidencerate1.txt",header=T)
> loc<-read.table("kashmarloc.txt",header=T)
> coordinates(loc) = ~x+y
> dd$time = ISOdate(dd$year,dd$mounth,dd$day,0)
> stations = 4:41
> w=STFDF(loc,dd$time,data.frame(values = as.vector(t(dd[stations]/12))))
> gg<-read.table("point.pred.TB.txt",header=T)
> grd = SpatialPixels(SpatialPoints(gg))
> plot(grd)
> tgrd = seq(min(index(w)), max(index(w))+2*360*24*3600,length=6)
> tgrd
> library(lattice)
> pred.grd = STF(grd, tgrd)
> plot(pred.grd )
> vv<-variogramST(values ~ 1,w,tlags=0:15,cutoff=55000)
> plot(vv,map=F,np=TRUE,cex=1,lwd=1.5,pch=19)
> wireframe(gamma~spacelag+timelag,vv,drape =T,scales=list(arrows=F,
> mai=c(4,5,2,2)),zlab=expression(gamma),
> ,light.source = c(10,0,10))
> separableModel <- vgmST("separable",space=vgm(.23,"Hol",5000,.77),
> time =vgm(.84,"Hol",150,0), sill=20)
> wireframe(model~spacelag+timelag,variogramSurface(separableModel,vv),
> drape =T,light.source =c(10,0,10),scales=list(arrows=F))
> ff<-fit.StVariogram(vv,separableModel, method ="L-BFGS-B",wles =T)
> ff
> #     range.s     nugget.s      range.t     nugget.t         sill
> #4999.9993501    0.7498763  150.0034786    0.2262177   14.0396906
> 
> wireframe(model~spacelag+timelag,variogramSurface(ff,vv),drape =T,
> ,light.source = c(10,0,10),scales=list(arrows=F),
> zlab=expression(gamma),main="fitted variogram ")
> TB.ST = krigeST(values~1,w,pred.grd,ff)
> stplot(TB.ST)
> 
> Thanks.
> 
> Saman.
> 
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 555 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140111/bac1167b/attachment.bin>

From jordan.chamberlin at gmail.com  Sun Jan 12 07:42:10 2014
From: jordan.chamberlin at gmail.com (Jordan Chamberlin)
Date: Sun, 12 Jan 2014 08:42:10 +0200
Subject: [R-sig-Geo] reclassify question
In-Reply-To: <CAHvKwC5P7Htc=J_brGQsyszV9g0L_Y-dAGnBLVny7drCCxroKg@mail.gmail.com>
References: <CAHvKwC5P7Htc=J_brGQsyszV9g0L_Y-dAGnBLVny7drCCxroKg@mail.gmail.com>
Message-ID: <52D23942.6080900@gmail.com>

Hi Ashton,

There are a few different ways to solve this.  See the reclassify help 
for clues, e.g. "You can also provide a two column matrix ("is", 
"becomes") which can be useful for integer values."

Alternatively, given how your reclassification table is currently set 
up, try specifying your reclassify operation as:

ecos = reclassify(testarea, recls, right=NA)

The "right=NA" argument should make each range open at both right and 
left boundaries. As it stands, 71 is not getting reclassified because 
the length of the classification is essentially zero (because the right 
boundary is closed).

Good luck!

Jordan

On 1/11/2014 9:44 PM, Ashton Drew wrote:
> I have just started switching from Arc to R for some of my spatial analyses
> and am stuck on a reclassification problem.  I am trying to use reclassify
> from the package raster.  I have been able to run the examples, but cannot
> run my own data.  I have tried to provide an example of my code using a
> small subset of my data.  The reclassify does work for some values (about
> 9/10 of the grid cells), but not all.  In the example below, values 71,
> 145, and 231 are not reclassified.
>
> The primary difference that I can find between my data and the worked
> examples is that all examples seem to assume that a range of values from
> continuous data are being reclassified, while my data are categorical
> (numerical codes for land cover classes).  Instead of a range to single
> value reclassification, I just want to reclassify each value to a single
> different value (in some cases, some of the original data can be treated as
> if they are a range, as shown in the example reclass matrix, but in reality
> this is not the case).  I thought maybe I could just put the same value in
> both the min and max columns, but that did not seem to work (value 71 in
> the example).  But that is not the only problem, because 145 and 231 are
> both values that I treated as if they were part of a range.  I do not get
> any error
> messages, just some values do not reclassify.
>
> So I am out of ideas.  If I cannot use reclassify, is there another way to
> classify ordinal or categorical raster data when I am not reclassifying a
> range to single value? Thank you for any help!
>
>> testarea
> class       : RasterLayer
> dimensions  : 34, 33, 1122  (nrow, ncol, ncell)
> resolution  : 30, 30  (x, y)
> extent      : 1200009, 1200999, 999992.1, 1001012  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0
> +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs
> data source : in memory
> names       : segap_scope
> values      : 1, 231  (min, max)
> attributes  :
>          ID   COUNT
> CLASS_NAMES       RED     GREEN      BLUE OPACITY
>   from:   1 7128758                                  Open Water (Fresh)
> 0.3568627 0.4588235 0.6392157       1
>   to  : 253  427139 Southern and Central Appalachian Oak Forest - Xeric
> 0.5372549 0.6666667 0.3294118       1
>
>> #Open reclass table.  Three columns From/To Values for input range, new
> value for output
>> recls = read.csv(file="
> SecondReclassTable_Rinput.csv", head=FALSE,
> sep=",")
>> recls = as.matrix(recls)
>> recls
>         V1  V2 V3
>   [1,]   1   7  0
>   [2,]  10  12  1
>   [3,]  16  26  0
>   [4,]  30  33  6
>   [5,]  35  37  0
>   [6,]  38  60  6
>   [7,]  61  64  4
>   [8,]  66  68  6
>   [9,]  71  71  4
> [10,]  72  74  3
> [11,]  76  77  4
> [12,]  79  79  3
> [13,]  82  82  6
> [14,]  85  85  4
> [15,]  86  86  6
> [16,]  90  96  4
> [17,]  98  99  6
> [18,] 100 100  4
> [19,] 102 109  6
> [20,] 118 118  0
> [21,] 119 119  6
> [22,] 124 127  0
> [23,] 141 143  1
> [24,] 145 149  0
> [25,] 151 182  2
> [26,] 183 188  4
> [27,] 192 206  2
> [28,] 207 207  0
> [29,] 213 216  5
> [30,] 217 217  1
> [31,] 218 228  5
> [32,] 231 233  4
> [33,] 238 238  2
> [34,] 245 250  5
> [35,] 253 253  6
>
>
>> ecos = reclassify(testarea, recls)
>>
>> ecos
> class       : RasterLayer
> dimensions  : 34, 33, 1122  (nrow, ncol, ncell)
> resolution  : 30, 30  (x, y)
> extent      : 1200009, 1200999, 999992.1, 1001012  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0
> +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs
> data source : in memory
> names       : layer
> values      : 0, 231  (min, max)
>
>


From jgrn at illinois.edu  Sun Jan 12 21:03:36 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Sun, 12 Jan 2014 14:03:36 -0600
Subject: [R-sig-Geo] Help with getting and processing MODIS data
In-Reply-To: <CAKCTE4zfgoS-1h0UkuHZO=hpHOi6gJr5RQd7JKNQByCiU4J9Ng@mail.gmail.com>
References: <CAKCTE4zfgoS-1h0UkuHZO=hpHOi6gJr5RQd7JKNQByCiU4J9Ng@mail.gmail.com>
Message-ID: <CABG0rfv=5AAPD12ey6hcSV6k33z=MLsXgNNnHzjdba8cOQ4kHA@mail.gmail.com>

Hi Julie:

You might want to check our new package gdalUtils (the r-forge version
is the current best):
install.packages("gdalUtils", repos="http://R-Forge.R-project.org")

You'll need to install GDAL first if you don't have it
(http://trac.osgeo.org/gdal/wiki/DownloadingGdalBinaries)

Take a look at the examples from ?get_subdatasets and ?gdal_translate
(I even have a sample MODIS tile, I think an EVI/NDVI, in the
package).

--j

On Fri, Jan 10, 2014 at 10:04 AM, Jill Deines <jillian.deines at gmail.com> wrote:
> Hi Julie,
>
> I haven't used the modisDownload package you mention, but I have had great
> success with another MODIS package in development, MODIS, which can be
> found here:
>
> https://r-forge.r-project.org/R/?group_id=1252
>
> It can use the MRT or use gdal binaries directly.  It's slightly
> complicated to set up the dependencies, but once it is, it makes batch
> downloading, mosaicing, and reprojecting incredibly easy.
>
> Steven Mosher wrote a nice tutorial for this package that helped me a lot
> with the set-up that can be found here:
> http://stevemosher.wordpress.com/modis-tutorial/
>
> It's slightly outdated - you no longer need to be able to build the package
> yourself (just download from the link above), and it was written when MODIS
> still used a ftp server instead of the updated http server, so I'd
> recommend starting on this page (and reading the comments for a few
> updates):
> http://stevemosher.wordpress.com/modis-reprojection-tool/, and probably
> skipping the last two pages.
>
> It's written for Windows installs, but I assume it can be adapted for a
> Mac.  You can use either MRT or gdal, so only one of these needs to be
> installed.  I find the gdal version easier to set the projection output,
> but the MRT is a bit faster.
>
> Once installed:
>
> library(MODIS)
>
> # set storage paths
>
> # for storing downloaded data
> MODISoptions(localArcPath = 'setFilepathForRawTiles')
>
> # for storing output
> MODISoptions(outDirPath = 'setFilepathForOutput')
>
> # check setup
> MODISoptions()
>
> __________
> Then use either function 'runGdal' or 'runMrt' to process with either tool.
>  The package has pretty good help files.
>
> Jill
>
>
>
>
>
>> Message: 8
>> Date: Thu, 9 Jan 2014 11:59:14 -0800 (PST)
>> From: Julie Lee-Yaw <julleeyaw at yahoo.ca>
>> To: "r-sig-geo at r-project.org" <r-sig-geo at r-project.org>
>> Subject: [R-sig-Geo] Help with getting and processing MODIS data
>> Message-ID:
>>         <1389297554.95170.YahooMailNeo at web142502.mail.bf1.yahoo.com>
>> Content-Type: text/plain
>>
>> Hi all
>>
>> I am fairly new to GIS and R and am trying to download, reproject, mosaic
>> and save MODIS NDVI and EVI data as a geotiff. I need tiles from across
>> North America, so a lot of data and would prefer to find an automatic
>> solution. I've come across modisDownload but can't seem to get it to work?I
>> think the code below manages  to download the hdf files but I don't see the
>> geotiff mosaic file that I expect (code based on tutorial found at
>> http://r-gis.net/?q=ModisDownload):
>>
>> I am using a mac and the MRT bin folder is stored in my "Applications"
>> folder.
>> ######### setwd("./MODIS") # set directory to location R script and where
>> I want the output
>> mrtpath<-"/Applications/bin" # tell R where MRT is stored
>> source('ModisDownload.R') # run the R script from r-gis.net
>> library(RCurl) #raster package is already loaded
>> x=3 # Now as per the online tutorial which gives code to do the following
>> # Downloads selected tiles, and mosaic, reproject them in UTM_WGS84, zone
>> 30 projection and convert all bands into Geotif format (the original HDF
>> will be deleted!)
>> ModisDownload(x=x,h=c(17,18),v=c(4,5),dates="2011.05.01",MRTpath=mrtpath,proj_type="UTM",utm_zone=30,datum="WGS84",pixel_size=1000)
>> #########
>>
>> Can anyone tell me what I'm doing wrong? The code seems to run but only
>> produces four hdf files? I'm open to other suggestions as to how to get and
>> process MODIS data?even the MRT tool seems to be giving me trouble so if
>> there is a step-by-step tutorial for beginners out there for how to do
>> this, I'd really appreciate a point in the right direction!
>>
>> Thanks
>>         [[alternative HTML version deleted]]
>>
>>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From alobolistas at gmail.com  Mon Jan 13 09:07:30 2014
From: alobolistas at gmail.com (Agustin Lobo)
Date: Mon, 13 Jan 2014 09:07:30 +0100
Subject: [R-sig-Geo] reclassify question
In-Reply-To: <CAHvKwC5P7Htc=J_brGQsyszV9g0L_Y-dAGnBLVny7drCCxroKg@mail.gmail.com>
References: <CAHvKwC5P7Htc=J_brGQsyszV9g0L_Y-dAGnBLVny7drCCxroKg@mail.gmail.com>
Message-ID: <CAG4NReJ2_aQE4sg_=ZZoHkopsApuaVWf_MFxVQyTMMq44MNbnQ@mail.gmail.com>

Ashton,

We had had this problem with categorical values in the past, and
precisely this is why
Robert introduced specific support. From the help page of reclassify:
"You can also provide a two column matrix ("is", "becomes") which can
be useful for integer values. In that case, the right argument is
automatically set to NA"

If you use a range, note also the information of the help page on
which bounds are included in the range (arguments right and
include.lowest)

Agus


On Sat, Jan 11, 2014 at 8:44 PM, Ashton Drew <cadrew at ncsu.edu> wrote:
> I have just started switching from Arc to R for some of my spatial analyses
> and am stuck on a reclassification problem.  I am trying to use reclassify
> from the package raster.  I have been able to run the examples, but cannot
> run my own data.  I have tried to provide an example of my code using a
> small subset of my data.  The reclassify does work for some values (about
> 9/10 of the grid cells), but not all.  In the example below, values 71,
> 145, and 231 are not reclassified.
>
> The primary difference that I can find between my data and the worked
> examples is that all examples seem to assume that a range of values from
> continuous data are being reclassified, while my data are categorical
> (numerical codes for land cover classes).  Instead of a range to single
> value reclassification, I just want to reclassify each value to a single
> different value (in some cases, some of the original data can be treated as
> if they are a range, as shown in the example reclass matrix, but in reality
> this is not the case).  I thought maybe I could just put the same value in
> both the min and max columns, but that did not seem to work (value 71 in
> the example).  But that is not the only problem, because 145 and 231 are
> both values that I treated as if they were part of a range.  I do not get
> any error
> messages, just some values do not reclassify.
>
> So I am out of ideas.  If I cannot use reclassify, is there another way to
> classify ordinal or categorical raster data when I am not reclassifying a
> range to single value? Thank you for any help!
>
>> testarea
>
> class       : RasterLayer
> dimensions  : 34, 33, 1122  (nrow, ncol, ncell)
> resolution  : 30, 30  (x, y)
> extent      : 1200009, 1200999, 999992.1, 1001012  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0
> +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs
> data source : in memory
> names       : segap_scope
> values      : 1, 231  (min, max)
> attributes  :
>         ID   COUNT
> CLASS_NAMES       RED     GREEN      BLUE OPACITY
>  from:   1 7128758                                  Open Water (Fresh)
> 0.3568627 0.4588235 0.6392157       1
>  to  : 253  427139 Southern and Central Appalachian Oak Forest - Xeric
> 0.5372549 0.6666667 0.3294118       1
>
>>
>> #Open reclass table.  Three columns From/To Values for input range, new
> value for output
>> recls = read.csv(file="
> SecondReclassTable_Rinput.csv", head=FALSE,
> sep=",")
>> recls = as.matrix(recls)
>> recls
>
>        V1  V2 V3
>  [1,]   1   7  0
>  [2,]  10  12  1
>  [3,]  16  26  0
>  [4,]  30  33  6
>  [5,]  35  37  0
>  [6,]  38  60  6
>  [7,]  61  64  4
>  [8,]  66  68  6
>  [9,]  71  71  4
> [10,]  72  74  3
> [11,]  76  77  4
> [12,]  79  79  3
> [13,]  82  82  6
> [14,]  85  85  4
> [15,]  86  86  6
> [16,]  90  96  4
> [17,]  98  99  6
> [18,] 100 100  4
> [19,] 102 109  6
> [20,] 118 118  0
> [21,] 119 119  6
> [22,] 124 127  0
> [23,] 141 143  1
> [24,] 145 149  0
> [25,] 151 182  2
> [26,] 183 188  4
> [27,] 192 206  2
> [28,] 207 207  0
> [29,] 213 216  5
> [30,] 217 217  1
> [31,] 218 228  5
> [32,] 231 233  4
> [33,] 238 238  2
> [34,] 245 250  5
> [35,] 253 253  6
>
>
>>
>> ecos = reclassify(testarea, recls)
>>
>> ecos
> class       : RasterLayer
> dimensions  : 34, 33, 1122  (nrow, ncol, ncell)
> resolution  : 30, 30  (x, y)
> extent      : 1200009, 1200999, 999992.1, 1001012  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0
> +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs
> data source : in memory
> names       : layer
> values      : 0, 231  (min, max)
>
>
> --
> --
> C. Ashton Drew, PhD
> NC Fish and Wildlife Coop. Research Unit
> Dept. of Applied Ecology
> North Carolina State University
> cell: 919-886-2811
> email: cadrew at ncsu.edu
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From b.naimi at utwente.nl  Mon Jan 13 11:15:23 2014
From: b.naimi at utwente.nl (b.naimi at utwente.nl)
Date: Mon, 13 Jan 2014 10:15:23 +0000
Subject: [R-sig-Geo] Help with getting and processing MODIS data
Message-ID: <F4F0D729F6AAFE47A105B7809266251710EF7078@EXMBX21.ad.utwente.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140113/dea93ce9/attachment.pl>

From arnold_salvacion at yahoo.com  Mon Jan 13 15:24:25 2014
From: arnold_salvacion at yahoo.com (Arnold Salvacion)
Date: Mon, 13 Jan 2014 22:24:25 +0800 (SGT)
Subject: [R-sig-Geo] Raster Zonal Histogram
Message-ID: <1389623065.4872.YahooMailNeo@web192704.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140113/363548f8/attachment.pl>

From alobolistas at gmail.com  Mon Jan 13 15:58:50 2014
From: alobolistas at gmail.com (Agustin Lobo)
Date: Mon, 13 Jan 2014 15:58:50 +0100
Subject: [R-sig-Geo] Differences in plot(),
	levelplot() and QGIS for raster objects
Message-ID: <CAG4NReJ2WzvhPAg_w+C_n23m_gUWM0Ez50=vJZQp+TNi7UY6ow@mail.gmail.com>

Hi!

I'm observing differences in plots of raster
objects using plot(), levelplot() and Qgis.

I've made an html page to show the problem:
https://dl.dropboxusercontent.com/u/3180464/testplot_levelplot_log.html

The pdf with the plots:
https://dl.dropboxusercontent.com/u/3180464/testplot_levelplot.pdf

As it is not easy to make a reproducible example, I've also uploaded
the actual raster (6 layers) in rda format (to be incorporated
with load()):
https://dl.dropboxusercontent.com/u/3180464/imamed.rda

Note this is
class       : RasterBrick
dimensions  : 1024, 1280, 1310720, 6  (nrow, ncol, ncell, nlayers)

Although I've decided going on with the mosaic made for QGIS, I'd appreciate
any comments on why such differences occur.

Thanks,

Agus


From francescokar at gmail.com  Mon Jan 13 16:52:17 2014
From: francescokar at gmail.com (Francesco Carrer)
Date: Mon, 13 Jan 2014 15:52:17 +0000
Subject: [R-sig-Geo] Help L Function
Message-ID: <CAKEj=dirSbHAPp0w7ydfAdOS5VFZm1QfvfF_-h_VbZNcHCQD6w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140113/3931ab9c/attachment.pl>

From marcelino.delacruz at upm.es  Mon Jan 13 17:09:25 2014
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Mon, 13 Jan 2014 17:09:25 +0100
Subject: [R-sig-Geo] Help L Function
In-Reply-To: <CAKEj=dirSbHAPp0w7ydfAdOS5VFZm1QfvfF_-h_VbZNcHCQD6w@mail.gmail.com>
References: <CAKEj=dirSbHAPp0w7ydfAdOS5VFZm1QfvfF_-h_VbZNcHCQD6w@mail.gmail.com>
Message-ID: <52D40FB5.8000608@upm.es>

Yes, it is possible and very easy. How do you extract your p-value 
depends on wether you are making a pointwise or a global test. See the 
help page of envelope(). You can also try a maximum absolute deviation 
test with dclf.test().


Cheers,

Marcelino




El 13/01/2014 16:52, Francesco Carrer escribi?:
> Hi,
>
> I have a distribution of artifact within an archaeological surface
> (dataset: ID, DIMENSION, X, Y), and I need to verify which is the degree of
> aggregation of these artifacts at different scales. I applied the L
> Function (Lest in spatstat), and plotted the resulting observed values of
> L(r) against the highest and lowest simulated values of L(r). Is it
> possible to extract a p-value that assess that the aggregation of my data
> is significantly higher (or lower) than the simulate values?
>
> Francesco Carrer
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From r.turner at auckland.ac.nz  Mon Jan 13 20:40:46 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 14 Jan 2014 08:40:46 +1300
Subject: [R-sig-Geo] Help L Function
In-Reply-To: <52D40FB5.8000608@upm.es>
References: <CAKEj=dirSbHAPp0w7ydfAdOS5VFZm1QfvfF_-h_VbZNcHCQD6w@mail.gmail.com>
	<52D40FB5.8000608@upm.es>
Message-ID: <52D4413E.9090607@auckland.ac.nz>


I would like to add:

* If you perform a pointwise test, the value of "r" at which you conduct 
the test much be chosen a priori --- before collecting, or at least 
before "looking at" the data.  Otherwise the associated p-value is 
meaningless. It is *very* unlikely that you had an a priori value of r 
in mind!

* A test based on the global envelope will not have very much power.

* My guess is that the dclf.test() route is your best bet.

cheers,

Rolf Turner

On 14/01/14 05:09, Marcelino de la Cruz wrote:

> Yes, it is possible and very easy. How do you extract your p-value
> depends on wether you are making a pointwise or a global test. See the
> help page of envelope(). You can also try a maximum absolute deviation
> test with dclf.test().
>
>
> Cheers,
>
> Marcelino
>
>
>
>
> El 13/01/2014 16:52, Francesco Carrer escribi?:
>> Hi,
>>
>> I have a distribution of artifact within an archaeological surface
>> (dataset: ID, DIMENSION, X, Y), and I need to verify which is the
>> degree of
>> aggregation of these artifacts at different scales. I applied the L
>> Function (Lest in spatstat), and plotted the resulting observed values of
>> L(r) against the highest and lowest simulated values of L(r). Is it
>> possible to extract a p-value that assess that the aggregation of my data
>> is significantly higher (or lower) than the simulate values?


From julleeyaw at yahoo.ca  Mon Jan 13 20:41:56 2014
From: julleeyaw at yahoo.ca (Julie Lee-Yaw)
Date: Mon, 13 Jan 2014 11:41:56 -0800 (PST)
Subject: [R-sig-Geo] Help with getting and processing MODIS data
In-Reply-To: <F4F0D729F6AAFE47A105B7809266251710EF7078@EXMBX21.ad.utwente.nl>
References: <F4F0D729F6AAFE47A105B7809266251710EF7078@EXMBX21.ad.utwente.nl>
Message-ID: <1389642116.11831.YahooMailNeo@web142501.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140113/8f5c1cfd/attachment.pl>

From hengl at spatial-analyst.net  Mon Jan 13 20:47:57 2014
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Mon, 13 Jan 2014 20:47:57 +0100
Subject: [R-sig-Geo] problems with plotting STFDF
In-Reply-To: <FF9DB805FC41CC4E95825A50F680630217AF7BEA@challenger.uhd.campus>
References: <FF9DB805FC41CC4E95825A50F680630217AF7BEA@challenger.uhd.campus>
Message-ID: <52D442ED.6020508@spatial-analyst.net>


 From plotKML 0.4-1 is now possible to plot results of 'krigeST' 
(http://www.inside-r.org/node/176602) directly in Google Earth. This is 
an example:

library(plotKML)
library(gstat)
library(sp)
library(spacetime)
sumMetricVgm <- vgmST("sumMetric",
                       space=vgm( 4.4, "Lin", 196.6,  3),
                       time =vgm( 2.2, "Lin",   1.1,  2),
                       joint=vgm(34.6, "Exp", 136.6, 12),
                       stAni=51.7)

data(air)

rr <- rural[,"2005-06-01/2005-06-03"]
rr <- as(rr,"STSDF")

x1 <- seq(from=6,to=15,by=1)
x2 <- seq(from=48,to=55,by=1)

DE_gridded <- SpatialPoints(cbind(rep(x1,length(x2)), 
rep(x2,each=length(x1))),
                             proj4string=CRS(proj4string(rr at sp)))
gridded(DE_gridded) <- TRUE
DE_pred <- STF(sp=as(DE_gridded,"SpatialPoints"), time=rr at time)
DE_kriged <- krigeST(PM10~1, data=rr, newdata=DE_pred,
                      modelList=sumMetricVgm)
gridded(DE_kriged at sp) <- TRUE
stplot(DE_kriged)

## plot in Google Earth:
png.width = DE_kriged at sp@grid at cells.dim[1]*20
png.height = DE_kriged at sp@grid at cells.dim[2]*20
z.lim = range(DE_kriged at data, na.rm=TRUE)
plotKML(DE_kriged, png.width=png.width,
         png.height=png.height, z.lim=z.lim)
## add observations points:
rr.sti <- as(rr, "STIDF")
plotKML(rr.sti, z.lim=z.lim)

the output looks like this:

http://plotkml.r-forge.r-project.org/DE_kriged.kmz

Note that I had to set the PNG width and height 20 time larger because 
otherwise plots in Google Earth are very fuzzy.

T. Hengl
https://www.vcard.wur.nl/Views/Profile/View.aspx?id=37263


On 1-1-2014 2:55, Hodgess, Erin wrote:
> Hello again!  Happy New Year!
>
> Here is the solution for this particular situation.  Note:  thanks to many people for the help.  Anyhow, I started with looking at page 28 in the gstat vignette for krigeST.  If you work through that, you obtain an object called DE_kriged, which is an STFDF.
>
> I copied some code from the following website:
>
> (https://r-forge.r-project.org/scm/viewvc.php/pkg/R/coerce.R?view=markup&root=spacetime
> <https://r-forge.r-project.org/scm/viewvc.php/pkg/R/coerce.R?view=markup&root=spacetime&pathrev=25>)
>
> to get the as.STIDF.STFDF lines:
>
>
>
> # STFDF -> STIDF
> as.STIDF.STFDF = function(from) {
>          as(as(from, "STSDF"), "STIDF")
> }
> setAs("STFDF", "STIDF", as.STIDF.STFDF)
>
>
> Now:
>
>>   DE1 <- as.STIDF.STFDF(DE_kriged)
>
> DE1 is an STIDF object, which is good, but the @sp section is a Spatial Pixels object.
>
> Next I copied over the function kml_layer.STIDF to new_STIDF.R and added the following section (see the note)
>
> new.STIDF <-
> function (obj, dtime = "", ...)
> {
>      if (all(dtime == 0)) {
>          TimeSpan.begin = format(time(obj at time), "%Y-%m-%dT%H:%M:%SZ")
>          TimeSpan.end = TimeSpan.begin
>      }
>      else {
>          if (length(obj at time) > 1 & !nzchar(dtime)) {
>          print(obj at time)
>              period <- periodicity(obj at time)
>              dtime <- period$frequency
>          }
>          TimeSpan.begin <- format(as.POSIXct(unclass(as.POSIXct(time(obj at time))) -
>              dtime/2, origin = "1970-01-01"), "%Y-%m-%dT%H:%M:%SZ")
>          TimeSpan.end <- format(as.POSIXct(unclass(as.POSIXct(time(obj at time))) +
>              dtime/2, origin = "1970-01-01"), "%Y-%m-%dT%H:%M:%SZ")
>      }
>      if (class(obj at sp) == "SpatialPoints" | class(obj at sp) == "SpatialPointsDataFrame") {
>          sp <- SpatialPointsDataFrame(obj at sp, obj at data)
>          kml_layer.SpatialPoints(obj = sp, TimeSpan.begin = TimeSpan.begin,
>              TimeSpan.end = TimeSpan.end, ...)
>      }
>      else {
>          if (class(obj at sp) == "SpatialPolygons" | class(obj at sp) ==
>              "SpatialPolygonsDataFrame") {
>              sp <- SpatialPolygonsDataFrame(obj at sp, obj at data)
>              kml_layer.SpatialPolygons(obj = sp, TimeSpan.begin = TimeSpan.begin,
>                  TimeSpan.end = TimeSpan.end, ...)
>          }
>          else {
>              if (class(obj at sp) == "SpatialLines" | class(obj at sp) ==
>                  "SpatialLinesDataFrame") {
>                  sp <- SpatialLinesDataFrame(obj at sp, obj at data)
>                  kml_layer.SpatialLines(obj = sp, TimeSpan.begin = TimeSpan.begin,
>                    TimeSpan.end = TimeSpan.end, ...)
>              }
>
> ###########################################################
> #  New for Spatial Pixels                                 #
> ##########################################################
>          else {
>              if (class(obj at sp) == "SpatialPixels" | class(obj at sp) ==
>                  "SpatialPixelsDataFrame") {
>                  sp <- SpatialPixelsDataFrame(obj at sp, obj at data)
>                  kml_layer.SpatialPoints(obj = sp, TimeSpan.begin = TimeSpan.begin,
>                    TimeSpan.end = TimeSpan.end, ...)
>              }
>
>
>
>              else {
>                  stop("The STIDF object does not extend SpatialPoints*, SpatialLines* or SpatialPolygons*")
>              }
>          }
>      }
> }
> }
>
> Finally, I ran this:
>> library(plotKML)
> plotKML version 0.4-0 (2013-11-15)
> URL: http://plotkml.r-forge.r-project.org/
> Warning message:
> replacing previous import by ?zoo::as.zoo? when loading ?gstat?
>> library(gstat)
> Loading required package: sp
>> kml_open("stuff2.kml")
> KML file opened for writing...
>> new.STIDF(DE1,dtime=24*3600,colour=var1.pred)
> Parsing to KML...
>> kml_close("stuff2.kml")
> Closing  stuff2.kml
>>
>
> All is well.  Google Earth lets you run the kml file and show the time change, as it should.
>
> Hope this might help someone!
>
> Thanks,
> Erin
>
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From HodgessE at uhd.edu  Mon Jan 13 21:09:55 2014
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Mon, 13 Jan 2014 20:09:55 +0000
Subject: [R-sig-Geo] vgmST question
Message-ID: <FF9DB805FC41CC4E95825A50F680630217AFBE39@challenger.uhd.campus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140113/f17589c0/attachment.pl>

From oscar.perpinan at gmail.com  Mon Jan 13 23:49:09 2014
From: oscar.perpinan at gmail.com (=?ISO-8859-1?Q?Oscar_Perpi=F1an?=)
Date: Mon, 13 Jan 2014 23:49:09 +0100
Subject: [R-sig-Geo] Raster Zonal Histogram
In-Reply-To: <1389623065.4872.YahooMailNeo@web192704.mail.sg3.yahoo.com>
References: <1389623065.4872.YahooMailNeo@web192704.mail.sg3.yahoo.com>
Message-ID: <CAMLL7bmyVAkS9ntS_forfy=nehg0jc7Mbr7ooqGryM--AmXrqA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140113/99295ee8/attachment.pl>

From julleeyaw at yahoo.ca  Tue Jan 14 00:39:48 2014
From: julleeyaw at yahoo.ca (Julie Lee-Yaw)
Date: Mon, 13 Jan 2014 15:39:48 -0800 (PST)
Subject: [R-sig-Geo] resampling MODIS-based raster to PRISM raster to obtain
	same extent
Message-ID: <1389656388.34766.YahooMailNeo@web124502.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140113/88e82614/attachment.pl>

From adrian.baddeley at uwa.edu.au  Tue Jan 14 02:23:56 2014
From: adrian.baddeley at uwa.edu.au (Adrian Baddeley)
Date: Tue, 14 Jan 2014 09:23:56 +0800
Subject: [R-sig-Geo] Help L Function
In-Reply-To: <52D4413E.9090607@auckland.ac.nz>
References: <CAKEj=dirSbHAPp0w7ydfAdOS5VFZm1QfvfF_-h_VbZNcHCQD6w@mail.gmail.com>
	<52D40FB5.8000608@upm.es>,<52D4413E.9090607@auckland.ac.nz>
Message-ID: <CF5661163F77A44781208D9AC4FDEA7226E8DF9771@IS-WIN-376.staffad.uwa.edu.au>

Firstly some comments to the original questioner.

      1. If you really need to do a formal test and obtain a p-value,
      then before doing this, it is important to verify that the point pattern is homogeneous
      (at least that the density of points per unit area is not spatially-varying)
      because this is an underlying assumption of the 'L' function. 
      In spatstat you can use quadrat.test, kstest or bermantest for example.

      2. The result of *any* test based on L will depend on the value or values of distance 'r'
      that are used. If you choose to use mad.test() or dclf.test() then it is best
      to choose the interval of 'r' values to be slightly larger than the range over which
      you suspect a spatial interaction is likely.

      3. Assuming you want to test CSR (complete spatial randomness) against the
      alternative of clustering or repulsion, it would be best to use the argument
      simulate=expression(runifpoint(n, W)) in the call to 'envelope',
      where n is the number of points in your dataset, and W is the window.
      Then the simulated patterns have the same number of points as the dataset.

      4. An alternative to a hypothesis test would be a confidence interval for the
       true L function. You can get this using the spatstat function 'lohboot' for example
       (or using the asymptotic variance estimates provided in the Lest/Kest functions).

And some comments to the experts:
 
      5. Establishing that the point process is stationary, is crucial to the validity of these methods.

      6. There is no uniformly most powerful test.
        If the alternative hypothesis is a point process with finite range R, 
        and we use mad.test() or dclf.test() over the interval of r values [0, s], 
        then the power of both tests is maximised when s is slightly greater than R, 
        and dclf.test() achieves a higher maximum power than mad.test(), 
        but the power of dclf.test() often drops off dramatically as s increases beyond R, 
        while the power of mad.test() never does. See Baddeley et al (2014)

      7. Therefore the optimal choice of test depends on how much we know
       about the (maximum) range of interaction R. If we know R = 4 metres, 
       then we should probably choose dclf.test() with s = 4.5. If we don't know
       anything about the spatial interactions, then we should use mad.test().

      8. Monte Carlo tests based on fitted models are typically conservative
       (i.e. true probability of type I error is smaller than nominal probability alpha;
       true p-value is smaller than calculated p-value).
       In this context the conservatism can be extreme.
       This can be avoided in the case where CSR is the null hypothesis,
       by conditioning on n, as advised in #3 above. Otherwise it is a problem.

Reference: 

   @Article{bdhlmn14,
  author =	 {A. Baddeley and P.J. Diggle and A. Hardegen and
                  T. Lawrence and R. Milne and G.M. Nair},
  title =	 {On tests of spatial pattern based on simulation
                  envelopes},
  journal =	 {Ecological Monographs},
  year =	 2014,
  note =	 {In press}
}
      


Prof Adrian Baddeley FAA
University of Western Australia
________________________________________
From: Rolf Turner [r.turner at auckland.ac.nz]
Sent: Tuesday, 14 January 2014 3:40 AM
To: Marcelino de la Cruz
Cc: r-sig-geo at r-project.org; Adrian Baddeley
Subject: Re: [R-sig-Geo] Help L Function

I would like to add:

* If you perform a pointwise test, the value of "r" at which you conduct
the test much be chosen a priori --- before collecting, or at least
before "looking at" the data.  Otherwise the associated p-value is
meaningless. It is *very* unlikely that you had an a priori value of r
in mind!

* A test based on the global envelope will not have very much power.

* My guess is that the dclf.test() route is your best bet.

cheers,

Rolf Turner

On 14/01/14 05:09, Marcelino de la Cruz wrote:

> Yes, it is possible and very easy. How do you extract your p-value
> depends on wether you are making a pointwise or a global test. See the
> help page of envelope(). You can also try a maximum absolute deviation
> test with dclf.test().
>
>
> Cheers,
>
> Marcelino
>
>
>
>
> El 13/01/2014 16:52, Francesco Carrer escribi?:
>> Hi,
>>
>> I have a distribution of artifact within an archaeological surface
>> (dataset: ID, DIMENSION, X, Y), and I need to verify which is the
>> degree of
>> aggregation of these artifacts at different scales. I applied the L
>> Function (Lest in spatstat), and plotted the resulting observed values of
>> L(r) against the highest and lowest simulated values of L(r). Is it
>> possible to extract a p-value that assess that the aggregation of my data
>> is significantly higher (or lower) than the simulate values?


From tea3rd at gmail.com  Tue Jan 14 05:32:46 2014
From: tea3rd at gmail.com (Thomas Adams)
Date: Tue, 14 Jan 2014 12:32:46 +0800
Subject: [R-sig-Geo] resampling MODIS-based raster to PRISM raster to
 obtain same extent
In-Reply-To: <1389656388.34766.YahooMailNeo@web124502.mail.ne1.yahoo.com>
References: <1389656388.34766.YahooMailNeo@web124502.mail.ne1.yahoo.com>
Message-ID: <CAGxgkWiiKXYM+_XRO=eqpvp5QjTc4hKGKcM2U07icsHoqBCyGA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140114/263ac807/attachment.pl>

From julleeyaw at yahoo.ca  Tue Jan 14 09:23:29 2014
From: julleeyaw at yahoo.ca (Julie Lee-Yaw)
Date: Tue, 14 Jan 2014 00:23:29 -0800 (PST)
Subject: [R-sig-Geo] resampling MODIS-based raster to PRISM raster to
	obtain same extent
In-Reply-To: <CAGxgkWiiKXYM+_XRO=eqpvp5QjTc4hKGKcM2U07icsHoqBCyGA@mail.gmail.com>
References: <1389656388.34766.YahooMailNeo@web124502.mail.ne1.yahoo.com>
	<CAGxgkWiiKXYM+_XRO=eqpvp5QjTc4hKGKcM2U07icsHoqBCyGA@mail.gmail.com>
Message-ID: <1389687809.30342.YahooMailNeo@web124503.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140114/b55d0fde/attachment.pl>

From tea3rd at gmail.com  Tue Jan 14 09:36:47 2014
From: tea3rd at gmail.com (Thomas Adams)
Date: Tue, 14 Jan 2014 16:36:47 +0800
Subject: [R-sig-Geo] resampling MODIS-based raster to PRISM raster to
 obtain same extent
In-Reply-To: <1389687809.30342.YahooMailNeo@web124503.mail.ne1.yahoo.com>
References: <1389656388.34766.YahooMailNeo@web124502.mail.ne1.yahoo.com>
	<CAGxgkWiiKXYM+_XRO=eqpvp5QjTc4hKGKcM2U07icsHoqBCyGA@mail.gmail.com>
	<1389687809.30342.YahooMailNeo@web124503.mail.ne1.yahoo.com>
Message-ID: <CAGxgkWiYkSZZrqt6Yb0Go7JE+izeOptSi4bLqf0Xes+rR9DB+w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140114/3ce40d26/attachment.pl>

From bmartinez at ucm.es  Tue Jan 14 12:18:42 2014
From: bmartinez at ucm.es (beatriz martinez miranzo)
Date: Tue, 14 Jan 2014 12:18:42 +0100
Subject: [R-sig-Geo] Kerneloverlap function
Message-ID: <CAJ--3WjB65TsNkV8Q=CmYCEhF+Rzvp089pgAiwEodc=Exh_4zQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140114/283cf416/attachment.pl>

From r.hijmans at gmail.com  Tue Jan 14 19:23:43 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 14 Jan 2014 10:23:43 -0800
Subject: [R-sig-Geo] Raster Zonal Histogram
In-Reply-To: <CAMLL7bmyVAkS9ntS_forfy=nehg0jc7Mbr7ooqGryM--AmXrqA@mail.gmail.com>
References: <1389623065.4872.YahooMailNeo@web192704.mail.sg3.yahoo.com>
	<CAMLL7bmyVAkS9ntS_forfy=nehg0jc7Mbr7ooqGryM--AmXrqA@mail.gmail.com>
Message-ID: <CANtt_hxd14pBA8sm=m0ziq2BV1j=C2vq45VnbYFV=kVOY_pM8Q@mail.gmail.com>

Arnold,

Here is an alternative to the rasterVis / levelplot approach that
Oscar suggested. Three approaches to make a matrix with the counts by
class and zone. These can then be used with base/plot commands, or
perhaps with ggplot; here illustrated with barplot.

Robert

library(raster)
# example data (taken from ?zonal)
r <- raster(ncols=10, nrows=10)
set.seed(0)
# random values between 0 and 65
slope <- setValues(r, runif(ncell(r)) * 65)
# landuse zones
landuse <- setValues(r, rep(1:5, each=20))

# approach 1
# make individual layers for each land use class
z <- layerize(landuse, falseNA=TRUE)
# make slope by land use layers
sz <- z * slope
m <- matrix(c(0,5,1, 5,15,2, 15,30,3, 30,45,4, 45,65,5), ncol=3, byrow=TRUE)
rr <- reclassify(sz, m, include.lowest=TRUE, right=FALSE)
f1 <- freq(rr, merge=TRUE, useNA='no')
f1 <- as.matrix(f1[,-1])

# approach 2
m <- matrix(c(0,5,1, 5,15,2, 15,30,3, 30,45,4, 45,65,5), ncol=3, byrow=TRUE)
sl <- reclassify(slope, m, include.lowest=TRUE, right=FALSE)
ct <- crosstab(sl, landuse, long=TRUE)
f2 <- reshape(ct, direction='wide', idvar='layer.1', timevar='layer.2')
f2 <- as.matrix(f2[,-1])

# approach 3
z <- layerize(landuse, falseNA=TRUE)
sz <- z * slope
x <- hist(sz, breaks=c(0,5,15,30,45,65))
f3 <- sapply(x, function(i) i$counts)

# f1, f2, f3, can be plotted like this
x11()
f <- f1
colnames(f) <- paste0('landuse', 1:ncol(f))
barplot(f, beside=TRUE, col=terrain.colors(5), ylim=c(0,10))
legend(1.5, 10, c('0-5', '5-15', '15-30', '30-45', '45-60'),
fill=terrain.colors(5), cex=.75)



On Mon, Jan 13, 2014 at 2:49 PM, Oscar Perpi?an
<oscar.perpinan at gmail.com> wrote:
> Hello,
>
> In rasterVis there is a method to produce histograms with a formula and a
> Raster* object. The last example of the help page of rasterVis::histogram
> illustrates this usage.
> In the formula, you can include names of layers, "x" and "y" (coordinates),
> and "dirXY" if you supply this argument in histogram.
>
> Best,
>
> Oscar.
>
> Oscar Perpi??n Lamigueiro
> Dpto. Ingenier?a El?ctrica (ETSIDI-UPM)
> Grupo de Sistemas Fotovoltaicos (IES-UPM)
> URL: http://oscarperpinan.github.io
> Twitter: @oscarperpinan
> LinkedIn: http://es.linkedin.com/in/oscarperpinan
> El 13/01/2014 15:28, "Arnold Salvacion" <arnold_salvacion at yahoo.com>
> escribi?:
>
>> Dear Colleagues,
>>
>> Good day!
>>
>> Just want to ask if there is already a similar package or function in R
>> which do the same as the Zonal Histogram (
>> http://webhelp.esri.com/arcgisdesktop/9.3/index.cfm?TopicName=Using_the_ArcGIS_Spatial_Analyst_toolbar_to_create_a_Zonal_Histogram)
>> in ArcGIS?
>>
>> Best regards,
>>
>> Arnold
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From r.hijmans at gmail.com  Tue Jan 14 20:11:00 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 14 Jan 2014 11:11:00 -0800
Subject: [R-sig-Geo] resampling MODIS-based raster to PRISM raster to
 obtain same extent
In-Reply-To: <1389656388.34766.YahooMailNeo@web124502.mail.ne1.yahoo.com>
References: <1389656388.34766.YahooMailNeo@web124502.mail.ne1.yahoo.com>
Message-ID: <CANtt_hx33uuecNwSLcyeR4pGsHssnMXU91d1+gW46b3vHVoyXQ@mail.gmail.com>

Julie,
You raise an important question that is often overlooked. While it is
possible to use resample as you suggest; you would want to avoid it
because it leads to loss of data quality (although in practice this is
often minimal and irrelevant).

You state that you "project it to the same geographic coordinate
system as PRISM precip. data". But that is an incomplete statement for
raster data. What you need to do is to project the NDVI data to the
raster definition used by PRISM. That includes the coordinate system,
but also the origin (or extent) and resolution of that raster. I do
not think MRT supports setting these parameters; in which case you
should not use it. You can use GDAL instead. On Linux this can be done
with rgdal; on windows you can use FWTools instead, or perhaps the new
gdalUtils package?

Robert

On Mon, Jan 13, 2014 at 3:39 PM, Julie Lee-Yaw <julleeyaw at yahoo.ca> wrote:
> Hi
>
> Using a combination of the scripts provided here (by Babak N.): http://r-gis.net/?q=ModisDownload and the MODIS reproject tool, I've finally managed to download NDVI data for North America and project it to the same geographic coordinate system as PRISM precip. data (e.g. http://www.prism.oregonstate.edu) for the same time period.
>
> I now want to stack these two rasters. My NDVI layer has a greater extent than the PRISM layer so I crop the former by the latter using:
>
> croppedNDVI<-crop(NDVI,prism)
>
>
> But when I look at the resulting raster, I see that the extent still doesn't line up. I think this is an issue with cells of the two rasters being "off" centre from each other. I can use the following to get them to align:
>
> adjustNDVI<-resample(croppedNDVI,prism)
>
>
> Now I can stack the "adjustNDVI" and "prism" layers as the extents match. But I am wondering whether this is valid? Why were the initial rasters misaligned in the first place given that I specified the same resolution and geographic coordinate system/datum when I processed the MODIS file? I'm grateful for any clarification!
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From alexandresantosbr at yahoo.com.br  Wed Jan 15 17:33:29 2014
From: alexandresantosbr at yahoo.com.br (ASANTOS)
Date: Wed, 15 Jan 2014 13:33:29 -0300
Subject: [R-sig-Geo] Problem in represents shapefile in Landsat image
Message-ID: <52D6B859.4000603@yahoo.com.br>

Dear Members,

      I would like to represents my contour area (contorno_line object) 
(53,22ha) in shapefile format in a Landsat 5 images (r1a, r2a and r3a), 
but I don't know why my area drops in a river, I verify the proj4string 
and both are "+proj=utm +zone=23 +south +datum=WGS84 +units=m +no_defs" 
and it's OK and the shapefile was create with the use of geodetic GPS. I 
suspect that some kind of transformation is necessary in Landsat image 
before the use or any projection problem, Any member can helps me. 
Follow my scrip:

require(raster)
require(sp)
require(maptools)

#STARTS
##------------------------------------------------------------------------------
## Bands 5, 4 e 3 of Landsat 5
#
#Download
links <- c(
"https://www.dropbox.com/s/6oie1ns3w52ur96/band5.crop.tif",
"https://www.dropbox.com/s/aa333he7g7vxcsj/band4.crop.tif",
"https://www.dropbox.com/s/3d7ad89uddx57o8/band3.crop.tif")

tokens    <- gsub("^.*/s/","",dirname(links))
fileNames <- basename(links)
newLinks  <- file.path("http://dl.dropbox.com/s", tokens, fileNames); 
newLinks

for (a in newLinks) {
           tryCatch(download.file(a, dest=basename(a), mode='wb'),
                               error=function(...) print("Falha no 
download!"))}

#Graphic representation of satellite images
r1a<-  raster(c("band5.crop.tif"))
r2a<-  raster(c("band4.crop.tif"))
r3a<-  raster(c("band3.crop.tif"))
landa<- stack(r1a,r2a,r3a)
plotRGB(landa)
#

#-------------------------------------------------------------------------------
#Download of the contour in shapefile
links <- c(
"https://www.dropbox.com/s/1oz5lhnk96jih3w/Tamandua288.dbf",
"https://www.dropbox.com/s/6b3uygyrjhq1bby/Tamandua288.shp",
"https://www.dropbox.com/s/wntluhn8bi7us2f/Tamandua288.shx")

tokens    <- gsub("^.*/s/","",dirname(links))
fileNames <- basename(links)
newLinks  <- file.path("http://dl.dropbox.com/s", tokens, fileNames); 
newLinks

for (a in newLinks) {
           tryCatch(download.file(a, dest=basename(a), mode='wb'),
                               error=function(...) print("Falha no 
download!"))}

contorno_line <- readShapeLines ("Tamandua288.shp", 
proj4string=CRS("+proj=utm +zone=23 +south +datum=WGS84 +units=m +no_defs"))
lines(contorno_line,col="red") # And the area drops inside a river.
#
#END


Thanks,

-- 
======================================================================
Alexandre dos Santos
Prote??o Florestal - Forest Protection
IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
Campus C?ceres
Caixa Postal 244
Avenida dos Ramires, s/n
Bairro: Distrito Industrial
C?ceres - MT                      CEP: 78.200-000
Fone: (+55) 65 8132-8112 (TIM)   (+55) 65 9686-6970 (VIVO)

         alexandre.santos at cas.ifmt.edu.br
Lattes: http://lattes.cnpq.br/1360403201088680


From thi_veloso at yahoo.com.br  Wed Jan 15 22:22:10 2014
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Wed, 15 Jan 2014 13:22:10 -0800
Subject: [R-sig-Geo] gdalUtils 0.2.0 now on CRAN
In-Reply-To: <CABG0rfs2QVzFmjQ7QAya-G84Ci+kDHvDStT95jijdOYCiCaKEQ@mail.gmail.com>
References: <CABG0rfs2QVzFmjQ7QAya-G84Ci+kDHvDStT95jijdOYCiCaKEQ@mail.gmail.com>
Message-ID: <1389820930.57241.YahooMailNeo@web121906.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140115/6ce617fd/attachment.pl>

From jgrn at illinois.edu  Thu Jan 16 05:50:26 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Wed, 15 Jan 2014 22:50:26 -0600
Subject: [R-sig-Geo] gdalUtils 0.2.0 now on CRAN
In-Reply-To: <1389820930.57241.YahooMailNeo@web121906.mail.ne1.yahoo.com>
References: <CABG0rfs2QVzFmjQ7QAya-G84Ci+kDHvDStT95jijdOYCiCaKEQ@mail.gmail.com>
	<1389820930.57241.YahooMailNeo@web121906.mail.ne1.yahoo.com>
Message-ID: <CABG0rfvz-5A9_z9P06HeeSWQvxSRd2wki5HvAr1qhpKdOck4NQ@mail.gmail.com>

Hi Thiago:

In general, this should have a small overhead compared to running GDAL
purely command line, but it really is just the GDAL binaries you are
running anyway (the wrapper calls those binaries directly).  The
overhead comes from the initial search/validation of the GDAL install
(a once-per-session occurrence).

Cheers!

--j

On Wed, Jan 15, 2014 at 3:22 PM, Thiago V. dos Santos
<thi_veloso at yahoo.com.br> wrote:
> Dear Jonathan,
>
> First of all, congratulations on the package. It installed without a glitch
> in all of my platforms: Mac, Windows and Linux.
>
> However, I have a question on the speed of the wrapper functions.
>
> In the past sometimes I caught myself using GDAL instead of R for some
> routines when dealing with really large datasets (1GB+ shapefiles and 2GB+
> rasters). Most of the routines were resampling and reprojection.
>
> While R used to run for several hours, GDAL binaries finished the task in a
> matter of seconds.
>
> Unfortunately I don't have access to those previous large datasets to
> perform some tests with the package, and this is why I ask you: do you think
> that gdalUtils functions are as fast as the GDAL binaries?
>
> Many thanks in advance. Congratulations once again for the very useful
> package!
>
> Greetings,
> --
> Thiago V. dos Santos
> PhD student
> Land and Atmospheric Science
> University of Minnesota
> http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
> Phone: (612) 323 9898
>
>
> On Wednesday, January 8, 2014 4:43 PM, Jonathan Greenberg
> <jgrn at illinois.edu> wrote:
> I would like to announce a new R package "gdalUtils", now on CRAN.
> gdalUtils is a set of R wrappers for most of the GDAL utility programs
> (http://gdal.org/gdal_utilities.html).  gdalUtils is a collaboration
> between Matteo Mattiuzzi and me.
>
> gdalUtils requires an already-installed GDAL on your system:
> http://trac.osgeo.org/gdal/wiki/DownloadingGdalBinaries
>
> For Windows, I recommend installing QGIS Standalone
> (http://www.qgis.org/en/site/forusers/download.html) which appears to
> have the most up-to-date binaries of GDAL for the Windows operating
> system including support for HDF4/5 files.
>
> Note that this is NOT a replacement for Roger Bivand's fantastic rgdal
> package, it is a complementary package that simply provides R-wrappers
> for functions like gdalwarp, gdal_translate, ogr2ogr, etc.  We've
> tried to make the interface more R-like in terms of input parameters,
> and have provided some additional features such as (when relevant)
> returning outputs in Robert Hijman's raster format.  The parameter
> naming and the documentation follows GDAL, with permission from Frank
> Warmerdam (lead GDAL developer).
>
> We have also provided some value-added functions such as
> batch_gdal_translate and get_subdatasets (for extracting subdataset
> names from HDF4/5 and NetCDF files).
>
> I will note the primary motivation for developing this package was
> initially to provide (finally) HDF4/5 file support to Windows users
> (for Landsat and MODIS processing, among other things).  However, many
> of the GDAL functions provide additional capabilities that R functions
> do not currently have, and they are quite a bit faster than most of
> their R equivalents (compare projectRaster_rigorous in my
> spatial.tools package to gdalwarp(...,method="mode") for an example).
>
> When you first fire it up, it may take a bit to search for a valid
> GDAL install on your computer.  If you have more than one (Windows
> users may find this), it will use the latest version.  We tried to
> make this system-agnostic, but let us know if you have any problems
> getting the functions to work.  The best way to test is:
> library(gdalUtils)
> gdalinfo(version=TRUE)
> gdalinfo(formats=TRUE)
>
> Cheers!
>
> --j
>
> --
> Jonathan A. Greenberg, PhD
> Assistant Professor
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Department of Geography and Geographic Information Science
> University of Illinois at Urbana-Champaign
> 259 Computing Applications Building, MC-150
> 605 East Springfield Avenue
> Champaign, IL  61820-6371
> Phone: 217-300-1924
> http://www.geog.illinois.edu/~jgrn/
> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From alobolistas at gmail.com  Thu Jan 16 16:09:44 2014
From: alobolistas at gmail.com (Agustin Lobo)
Date: Thu, 16 Jan 2014 16:09:44 +0100
Subject: [R-sig-Geo] as.raster() does not work for RImageJ objects
Message-ID: <CAG4NRe+TPNk+Xv9Qwnd2n7LoJofyJ_1VqL_=N4bbt_0AjqJsGg@mail.gmail.com>

Hi!

While the following works fine:
install.packages("/home/alobo/Downloads/RImageJ_0.2-146.tar.gz", repos
= NULL, type="source")
require(RImageJ)
require(raster)
logo <- system.file( "images", "R.jpg", package = "RImageJ" )
image = IJ$openImage( logo )
class(image)
plot(c(100, 250), c(300, 450), type = "n", xlab="", ylab="")
rasterImage(image, 100, 300, 150, 350, interpolate=FALSE)

(note that the example in
http://romainfrancois.blog.free.fr/index.php?category/R-package/RImageJ
is currently wrong, it must be rasterImage() and not raster()

But as.raster() (the most important for me) does not work:

> class(image)
[1] "jobjRef"
attr(,"package")
[1] "rJava"
> r <- as.raster(image)
Error in as.raster.jobjRef(image) : attempt to apply non-function

see ?as.raster.jobjRef

Any fix?

Thanks
Agus


From jgrn at illinois.edu  Thu Jan 16 19:52:15 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Thu, 16 Jan 2014 12:52:15 -0600
Subject: [R-sig-Geo] Current options for creating/querying vector data
 WITHOUT loading them into memory?
Message-ID: <CABG0rftwKno4x_wt7CO76FT_2CPwdGQ4_qi9X3N7eJxwRWvY2A@mail.gmail.com>

r-sig-geo'ers:

As vector datasets are getting a lot larger, there is a limitation
with the Spatial* formats in that they must be loaded into main
memory.  I was curious what folks who have been dealing with massive
vector files have come up with working within the R environment?  Has
anyone played around with file geodatabases or spatialite formats (for
instance)?  How are you creating/querying the data?

Thanks!

--j

-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From b.rowlingson at lancaster.ac.uk  Thu Jan 16 20:09:36 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 16 Jan 2014 19:09:36 +0000
Subject: [R-sig-Geo] Current options for creating/querying vector data
 WITHOUT loading them into memory?
In-Reply-To: <4b03005cc0074cadb3d9511b1624856f@EX-1-HT0.lancs.local>
References: <4b03005cc0074cadb3d9511b1624856f@EX-1-HT0.lancs.local>
Message-ID: <CANVKczMBQ-3HzeyAP5YrFjZ1rybuRuh02ZoDgmcLaUzhA2bJ_Q@mail.gmail.com>

Well, back when I wrote 'rmap' I abstracted out the storage of the
data from the data object... So your object in R could represent a
subset of a shapefile, and the code only grabbed that chunk of the
shapefile when it was needed, for example to plot (the R object was
basically the name of the shapefile plus a selection vector).

Then we threw that code out and sp classes were born!

 I've often thought about restoring some of this kind of
functionality, but R's object-oriented classes just frustrate me. Its
not so simple to build a superclass of sp class objects. Or maybe it
is now? For some value of 'simple'...

 Suppose you had a gigantic spatialite db - if you want to work with
it spatially (mapping, rgeos) you are going to have to get the bits
you need into main memory, so the simplest is just to load selections
into sp-class objects. Is that already possible with the OGR
spatialite driver? Can you also load subsets of shapefiles using some
SQL passed to the OGR shapefile driver?

 What would you want to do on whole-dataset objects of this class?
Would you want to do the processing on the database if possible (if
its PostGIS or Spatialite)? Or have an automatic chunking procedure
for operations that don't need the whole database at once, such as
finding centroids of polygons?

Hmmm thoughts thoughts thoughts and no action :( Sorry!

Barry



On Thu, Jan 16, 2014 at 6:52 PM, Jonathan Greenberg <jgrn at illinois.edu> wrote:
> r-sig-geo'ers:
>
> As vector datasets are getting a lot larger, there is a limitation
> with the Spatial* formats in that they must be loaded into main
> memory.  I was curious what folks who have been dealing with massive
> vector files have come up with working within the R environment?  Has
> anyone played around with file geodatabases or spatialite formats (for
> instance)?  How are you creating/querying the data?
>
> Thanks!
>
> --j
>
> --
> Jonathan A. Greenberg, PhD
> Assistant Professor
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Department of Geography and Geographic Information Science
> University of Illinois at Urbana-Champaign
> 259 Computing Applications Building, MC-150
> 605 East Springfield Avenue
> Champaign, IL  61820-6371
> Phone: 217-300-1924
> http://www.geog.illinois.edu/~jgrn/
> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From tkeitt at utexas.edu  Thu Jan 16 20:10:44 2014
From: tkeitt at utexas.edu (Tim Keitt)
Date: Thu, 16 Jan 2014 13:10:44 -0600
Subject: [R-sig-Geo] Current options for creating/querying vector data
 WITHOUT loading them into memory?
In-Reply-To: <CABG0rftwKno4x_wt7CO76FT_2CPwdGQ4_qi9X3N7eJxwRWvY2A@mail.gmail.com>
References: <CABG0rftwKno4x_wt7CO76FT_2CPwdGQ4_qi9X3N7eJxwRWvY2A@mail.gmail.com>
Message-ID: <CANnL8go7dtr2EtYUkS1F5+Ncvqr+Y3D1F3eebFRKeDP35dSESQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140116/f93559f5/attachment.pl>

From tkeitt at utexas.edu  Thu Jan 16 20:14:56 2014
From: tkeitt at utexas.edu (Tim Keitt)
Date: Thu, 16 Jan 2014 13:14:56 -0600
Subject: [R-sig-Geo] Current options for creating/querying vector data
 WITHOUT loading them into memory?
In-Reply-To: <CANVKczMBQ-3HzeyAP5YrFjZ1rybuRuh02ZoDgmcLaUzhA2bJ_Q@mail.gmail.com>
References: <4b03005cc0074cadb3d9511b1624856f@EX-1-HT0.lancs.local>
	<CANVKczMBQ-3HzeyAP5YrFjZ1rybuRuh02ZoDgmcLaUzhA2bJ_Q@mail.gmail.com>
Message-ID: <CANnL8grCHUBaqG2iyFpMWEbRcvSqu3X=D=RCf4cDpA7K6XRn-g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140116/4edab001/attachment.pl>

From jgrn at illinois.edu  Thu Jan 16 20:40:26 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Thu, 16 Jan 2014 13:40:26 -0600
Subject: [R-sig-Geo] Current options for creating/querying vector data
 WITHOUT loading them into memory?
In-Reply-To: <CANnL8grCHUBaqG2iyFpMWEbRcvSqu3X=D=RCf4cDpA7K6XRn-g@mail.gmail.com>
References: <4b03005cc0074cadb3d9511b1624856f@EX-1-HT0.lancs.local>
	<CANVKczMBQ-3HzeyAP5YrFjZ1rybuRuh02ZoDgmcLaUzhA2bJ_Q@mail.gmail.com>
	<CANnL8grCHUBaqG2iyFpMWEbRcvSqu3X=D=RCf4cDpA7K6XRn-g@mail.gmail.com>
Message-ID: <CABG0rfvVbT9_sgm15MTDa=wrHzPVW7TFXWZB9yt+ZkPGHgTp0Q@mail.gmail.com>

I've wondered if it would be possible to do something like what Robert
did with the raster() package, where the analysis (read/write) was
being done on-demand on the data rather than entirely in-memory.
Vector data is, of course, much more complicated to come up with
elegant solutions than raster data, but I think some basic
functionality would be great.  Perhaps spatialite as a backbone (since
you can easily install sqlite executable via the Rsqlite package, and
there is a now-abandoned but available code base in
http://cran.r-project.org/web/packages/SQLiteMap/ (I spoke to the
developer who said he won't be updating it) that might allow for a
relatively easy cross-platform install of the spatialite addon.
Something that would fill in the gap between the Spatial* classes
(which won't scale to large datasets) and PostGIS (which requires much
more complex installation requirements)?

How does spatialite perform in terms of large queries?  I imagine not
as well as PostGIS, but does it at least scale memory-wise on most
standard queries?

--j

On Thu, Jan 16, 2014 at 1:14 PM, Tim Keitt <tkeitt at utexas.edu> wrote:
>
>
>
> On Thu, Jan 16, 2014 at 1:09 PM, Barry Rowlingson
> <b.rowlingson at lancaster.ac.uk> wrote:
>>
>> Well, back when I wrote 'rmap' I abstracted out the storage of the
>> data from the data object... So your object in R could represent a
>> subset of a shapefile, and the code only grabbed that chunk of the
>> shapefile when it was needed, for example to plot (the R object was
>> basically the name of the shapefile plus a selection vector).
>>
>> Then we threw that code out and sp classes were born!
>>
>>  I've often thought about restoring some of this kind of
>> functionality, but R's object-oriented classes just frustrate me. Its
>> not so simple to build a superclass of sp class objects. Or maybe it
>> is now? For some value of 'simple'...
>>
>>  Suppose you had a gigantic spatialite db - if you want to work with
>> it spatially (mapping, rgeos) you are going to have to get the bits
>> you need into main memory, so the simplest is just to load selections
>> into sp-class objects. Is that already possible with the OGR
>> spatialite driver? Can you also load subsets of shapefiles using some
>> SQL passed to the OGR shapefile driver?
>>
>>  What would you want to do on whole-dataset objects of this class?
>> Would you want to do the processing on the database if possible (if
>> its PostGIS or Spatialite)? Or have an automatic chunking procedure
>> for operations that don't need the whole database at once, such as
>> finding centroids of polygons?
>>
>> Hmmm thoughts thoughts thoughts and no action :( Sorry!
>
>
> Barry,
>
> I'll have more to say on this in a couple of weeks.
>
> THK
>
>>
>>
>> Barry
>>
>>
>>
>> On Thu, Jan 16, 2014 at 6:52 PM, Jonathan Greenberg <jgrn at illinois.edu>
>> wrote:
>> > r-sig-geo'ers:
>> >
>> > As vector datasets are getting a lot larger, there is a limitation
>> > with the Spatial* formats in that they must be loaded into main
>> > memory.  I was curious what folks who have been dealing with massive
>> > vector files have come up with working within the R environment?  Has
>> > anyone played around with file geodatabases or spatialite formats (for
>> > instance)?  How are you creating/querying the data?
>> >
>> > Thanks!
>> >
>> > --j
>> >
>> > --
>> > Jonathan A. Greenberg, PhD
>> > Assistant Professor
>> > Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>> > Department of Geography and Geographic Information Science
>> > University of Illinois at Urbana-Champaign
>> > 259 Computing Applications Building, MC-150
>> > 605 East Springfield Avenue
>> > Champaign, IL  61820-6371
>> > Phone: 217-300-1924
>> > http://www.geog.illinois.edu/~jgrn/
>> > AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>> >
>> > _______________________________________________
>> > R-sig-Geo mailing list
>> > R-sig-Geo at r-project.org
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
>
> --
> http://www.keittlab.org/



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From tkeitt at utexas.edu  Thu Jan 16 21:49:31 2014
From: tkeitt at utexas.edu (Tim Keitt)
Date: Thu, 16 Jan 2014 14:49:31 -0600
Subject: [R-sig-Geo] Current options for creating/querying vector data
 WITHOUT loading them into memory?
In-Reply-To: <CABG0rfvVbT9_sgm15MTDa=wrHzPVW7TFXWZB9yt+ZkPGHgTp0Q@mail.gmail.com>
References: <4b03005cc0074cadb3d9511b1624856f@EX-1-HT0.lancs.local>
	<CANVKczMBQ-3HzeyAP5YrFjZ1rybuRuh02ZoDgmcLaUzhA2bJ_Q@mail.gmail.com>
	<CANnL8grCHUBaqG2iyFpMWEbRcvSqu3X=D=RCf4cDpA7K6XRn-g@mail.gmail.com>
	<CABG0rfvVbT9_sgm15MTDa=wrHzPVW7TFXWZB9yt+ZkPGHgTp0Q@mail.gmail.com>
Message-ID: <CANnL8gpCz=BtFo0k-gVDRoNfv7NAg09SJ4djfoNKqGvHk6i_3g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140116/82c1776b/attachment.pl>

From julleeyaw at yahoo.ca  Fri Jan 17 08:48:13 2014
From: julleeyaw at yahoo.ca (Julie Lee-Yaw)
Date: Thu, 16 Jan 2014 23:48:13 -0800 (PST)
Subject: [R-sig-Geo] resampling MODIS-based raster to PRISM raster to
	obtain same extent
In-Reply-To: <CANtt_hx33uuecNwSLcyeR4pGsHssnMXU91d1+gW46b3vHVoyXQ@mail.gmail.com>
References: <1389656388.34766.YahooMailNeo@web124502.mail.ne1.yahoo.com>
	<CANtt_hx33uuecNwSLcyeR4pGsHssnMXU91d1+gW46b3vHVoyXQ@mail.gmail.com>
Message-ID: <1389944893.78524.YahooMailNeo@web124501.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140116/6fc39fb3/attachment.pl>

From alobolistas at gmail.com  Fri Jan 17 09:09:25 2014
From: alobolistas at gmail.com (Agustin Lobo)
Date: Fri, 17 Jan 2014 09:09:25 +0100
Subject: [R-sig-Geo] as.raster() does not work for RImageJ objects
In-Reply-To: <CAG4NRe+TPNk+Xv9Qwnd2n7LoJofyJ_1VqL_=N4bbt_0AjqJsGg@mail.gmail.com>
References: <CAG4NRe+TPNk+Xv9Qwnd2n7LoJofyJ_1VqL_=N4bbt_0AjqJsGg@mail.gmail.com>
Message-ID: <CAG4NReLA0=6MSse1OT0fR2vFe_hSpddXtPhjiGZdJ+Z0A=wHWA@mail.gmail.com>

Actually, in OSX, there is no error message at using as.raster(), but
it does not work either:

r <- as.raster(image)
class(r)

[1] "raster"
> str(r)
'raster' chr [1:76, 1:100] "#ffffff" "#ffffff" "#ffffff" "#ffffff"
"#ffffff" "#ffffff" "#ffffff" ...

which is not the structure a raster object should have.

Then:

r <- as.raster.jobjRef(image)
Error: could not find function "as.raster.jobjRef"

while ?as.raster.jobjRef shows the help page
the function as.raster.jobjRef" is not in the workspace (and this is
also the case in linux):
> search()
 [1] ".GlobalEnv"        "package:RImageJ"   "package:rJava"
"package:raster"    "package:sp"
 [6] "tools:rstudio"     "package:stats"     "package:graphics"
"package:grDevices" "package:utils"
[11] "package:datasets"  "package:methods"   "Autoloads"
"package:base"
> ls(2)
[1] "IJ"              "IJWindowManager" "ImageJ"


R version 3.0.2 (2013-09-25)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
  [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
  [1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
  [1] RImageJ_0.2-146 rJava_0.9-6     raster_2.1-66   sp_1.0-13

loaded via a namespace (and not attached):
  [1] grid_3.0.2      lattice_0.20-23 tools_3.0.2


Agus

On Thu, Jan 16, 2014 at 4:09 PM, Agustin Lobo <alobolistas at gmail.com> wrote:
> Hi!
>
> While the following works fine:
> install.packages("/home/alobo/Downloads/RImageJ_0.2-146.tar.gz", repos
> = NULL, type="source")
> require(RImageJ)
> require(raster)
> logo <- system.file( "images", "R.jpg", package = "RImageJ" )
> image = IJ$openImage( logo )
> class(image)
> plot(c(100, 250), c(300, 450), type = "n", xlab="", ylab="")
> rasterImage(image, 100, 300, 150, 350, interpolate=FALSE)
>
> (note that the example in
> http://romainfrancois.blog.free.fr/index.php?category/R-package/RImageJ
> is currently wrong, it must be rasterImage() and not raster()
>
> But as.raster() (the most important for me) does not work:
>
>> class(image)
> [1] "jobjRef"
> attr(,"package")
> [1] "rJava"
>> r <- as.raster(image)
> Error in as.raster.jobjRef(image) : attempt to apply non-function
>
> see ?as.raster.jobjRef
>
> Any fix?
>
> Thanks
> Agus


From mdsumner at gmail.com  Fri Jan 17 09:26:43 2014
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 17 Jan 2014 19:26:43 +1100
Subject: [R-sig-Geo] as.raster() does not work for RImageJ objects
In-Reply-To: <CAG4NReLA0=6MSse1OT0fR2vFe_hSpddXtPhjiGZdJ+Z0A=wHWA@mail.gmail.com>
References: <CAG4NRe+TPNk+Xv9Qwnd2n7LoJofyJ_1VqL_=N4bbt_0AjqJsGg@mail.gmail.com>
	<CAG4NReLA0=6MSse1OT0fR2vFe_hSpddXtPhjiGZdJ+Z0A=wHWA@mail.gmail.com>
Message-ID: <CAAcGz9_zt-oRd7_-ncjGmSqdNcFb97RH9VeC=74JXN+Tu4bdzg@mail.gmail.com>

You are see a clash of the grDevices::as.raster with the raster
package. grDevices is loaded by default, and has a (S3) method for
whatever your image is (a matrix?).

It seems like the S4 raster::as.raster should allow these to "pass
through" to the underlying S3 method.

I can't look any closer right now





On Fri, Jan 17, 2014 at 7:09 PM, Agustin Lobo <alobolistas at gmail.com> wrote:
> Actually, in OSX, there is no error message at using as.raster(), but
> it does not work either:
>
> r <- as.raster(image)
> class(r)
>
> [1] "raster"
>> str(r)
> 'raster' chr [1:76, 1:100] "#ffffff" "#ffffff" "#ffffff" "#ffffff"
> "#ffffff" "#ffffff" "#ffffff" ...
>
> which is not the structure a raster object should have.
>
> Then:
>
> r <- as.raster.jobjRef(image)
> Error: could not find function "as.raster.jobjRef"
>
> while ?as.raster.jobjRef shows the help page
> the function as.raster.jobjRef" is not in the workspace (and this is
> also the case in linux):
>> search()
>  [1] ".GlobalEnv"        "package:RImageJ"   "package:rJava"
> "package:raster"    "package:sp"
>  [6] "tools:rstudio"     "package:stats"     "package:graphics"
> "package:grDevices" "package:utils"
> [11] "package:datasets"  "package:methods"   "Autoloads"
> "package:base"
>> ls(2)
> [1] "IJ"              "IJWindowManager" "ImageJ"
>
>
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
> locale:
>   [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
>   [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
>   [1] RImageJ_0.2-146 rJava_0.9-6     raster_2.1-66   sp_1.0-13
>
> loaded via a namespace (and not attached):
>   [1] grid_3.0.2      lattice_0.20-23 tools_3.0.2
>
>
> Agus
>
> On Thu, Jan 16, 2014 at 4:09 PM, Agustin Lobo <alobolistas at gmail.com> wrote:
>> Hi!
>>
>> While the following works fine:
>> install.packages("/home/alobo/Downloads/RImageJ_0.2-146.tar.gz", repos
>> = NULL, type="source")
>> require(RImageJ)
>> require(raster)
>> logo <- system.file( "images", "R.jpg", package = "RImageJ" )
>> image = IJ$openImage( logo )
>> class(image)
>> plot(c(100, 250), c(300, 450), type = "n", xlab="", ylab="")
>> rasterImage(image, 100, 300, 150, 350, interpolate=FALSE)
>>
>> (note that the example in
>> http://romainfrancois.blog.free.fr/index.php?category/R-package/RImageJ
>> is currently wrong, it must be rasterImage() and not raster()
>>
>> But as.raster() (the most important for me) does not work:
>>
>>> class(image)
>> [1] "jobjRef"
>> attr(,"package")
>> [1] "rJava"
>>> r <- as.raster(image)
>> Error in as.raster.jobjRef(image) : attempt to apply non-function
>>
>> see ?as.raster.jobjRef
>>
>> Any fix?
>>
>> Thanks
>> Agus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Michael Sumner
Hobart, Australia
e-mail: mdsumner at gmail.com


From alobolistas at gmail.com  Fri Jan 17 10:24:49 2014
From: alobolistas at gmail.com (Agustin Lobo)
Date: Fri, 17 Jan 2014 10:24:49 +0100
Subject: [R-sig-Geo] Problem in represents shapefile in Landsat image
In-Reply-To: <52D6B859.4000603@yahoo.com.br>
References: <52D6B859.4000603@yahoo.com.br>
Message-ID: <CAG4NReLky-yurn7Uo4qZO3x1k+rG2QxPN1ZfERYpxY70KA5p5Q@mail.gmail.com>

Alexandre,

You should also have a prj file for your shapefile. This is where all
the projection info is
stored.
Once you get it, try reading with readOGR(), i.e.

require(rgdal)
contorno_line <- readOGR(dsn="path to the shapefile", layer="Tamandua288")

And verify that the slots proj4string in both raster and vector are
identical, i.e
using
projection(landa)
projection(contorno_line)

and verify that they do overlay:
plot(landa[[3]])
plot(contorno_line,add=TRUE)

If both projection() match but the objects do not overlay, then the
most likely is that the 2 objects are actually not
in the same projection (Datum difference?) as you think, note that
lacking a prj file should make you feel uncomfortable. If you do not
have the prj, then you must get the information on projection and
datum and either make a prj on your own or set the projection in R

Agus

On Wed, Jan 15, 2014 at 5:33 PM, ASANTOS <alexandresantosbr at yahoo.com.br> wrote:
> Dear Members,
>
>      I would like to represents my contour area (contorno_line object)
> (53,22ha) in shapefile format in a Landsat 5 images (r1a, r2a and r3a), but
> I don't know why my area drops in a river, I verify the proj4string and both
> are "+proj=utm +zone=23 +south +datum=WGS84 +units=m +no_defs" and it's OK
> and the shapefile was create with the use of geodetic GPS. I suspect that
> some kind of transformation is necessary in Landsat image before the use or
> any projection problem, Any member can helps me. Follow my scrip:
>
> require(raster)
> require(sp)
> require(maptools)
>
> #STARTS
> ##------------------------------------------------------------------------------
> ## Bands 5, 4 e 3 of Landsat 5
> #
> #Download
> links <- c(
> "https://www.dropbox.com/s/6oie1ns3w52ur96/band5.crop.tif",
> "https://www.dropbox.com/s/aa333he7g7vxcsj/band4.crop.tif",
> "https://www.dropbox.com/s/3d7ad89uddx57o8/band3.crop.tif")
>
> tokens    <- gsub("^.*/s/","",dirname(links))
> fileNames <- basename(links)
> newLinks  <- file.path("http://dl.dropbox.com/s", tokens, fileNames);
> newLinks
>
> for (a in newLinks) {
>           tryCatch(download.file(a, dest=basename(a), mode='wb'),
>                               error=function(...) print("Falha no
> download!"))}
>
> #Graphic representation of satellite images
> r1a<-  raster(c("band5.crop.tif"))
> r2a<-  raster(c("band4.crop.tif"))
> r3a<-  raster(c("band3.crop.tif"))
> landa<- stack(r1a,r2a,r3a)
> plotRGB(landa)
> #
>
> #-------------------------------------------------------------------------------
> #Download of the contour in shapefile
> links <- c(
> "https://www.dropbox.com/s/1oz5lhnk96jih3w/Tamandua288.dbf",
> "https://www.dropbox.com/s/6b3uygyrjhq1bby/Tamandua288.shp",
> "https://www.dropbox.com/s/wntluhn8bi7us2f/Tamandua288.shx")
>
> tokens    <- gsub("^.*/s/","",dirname(links))
> fileNames <- basename(links)
> newLinks  <- file.path("http://dl.dropbox.com/s", tokens, fileNames);
> newLinks
>
> for (a in newLinks) {
>           tryCatch(download.file(a, dest=basename(a), mode='wb'),
>                               error=function(...) print("Falha no
> download!"))}
>
> contorno_line <- readShapeLines ("Tamandua288.shp",
> proj4string=CRS("+proj=utm +zone=23 +south +datum=WGS84 +units=m +no_defs"))
> lines(contorno_line,col="red") # And the area drops inside a river.
> #
> #END
>
>
> Thanks,
>
> --
> ======================================================================
> Alexandre dos Santos
> Prote??o Florestal - Forest Protection
> IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
> Campus C?ceres
> Caixa Postal 244
> Avenida dos Ramires, s/n
> Bairro: Distrito Industrial
> C?ceres - MT                      CEP: 78.200-000
> Fone: (+55) 65 8132-8112 (TIM)   (+55) 65 9686-6970 (VIVO)
>
>         alexandre.santos at cas.ifmt.edu.br
> Lattes: http://lattes.cnpq.br/1360403201088680
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From alobolistas at gmail.com  Fri Jan 17 14:45:30 2014
From: alobolistas at gmail.com (Agustin Lobo)
Date: Fri, 17 Jan 2014 14:45:30 +0100
Subject: [R-sig-Geo] as.raster() does not work for RImageJ objects
In-Reply-To: <CAAcGz9_zt-oRd7_-ncjGmSqdNcFb97RH9VeC=74JXN+Tu4bdzg@mail.gmail.com>
References: <CAG4NRe+TPNk+Xv9Qwnd2n7LoJofyJ_1VqL_=N4bbt_0AjqJsGg@mail.gmail.com>
	<CAG4NReLA0=6MSse1OT0fR2vFe_hSpddXtPhjiGZdJ+Z0A=wHWA@mail.gmail.com>
	<CAAcGz9_zt-oRd7_-ncjGmSqdNcFb97RH9VeC=74JXN+Tu4bdzg@mail.gmail.com>
Message-ID: <CAG4NReKpcnnJMXRpz0mScWogCMoEEdwiuLfqtF3=sgq0vbUJQA@mail.gmail.com>

ok, thanks. I did not know that there was another class raster in
another package.

This means that we cannot convert from RImageJ objects to
raster::raster objects.
But we can use RImageJ to process, save to disk and read back as raster:raster:

logo <- system.file( "images", "R.jpg", package = "RImageJ" )
image = IJ$openImage( logo )
image$show()
IJ$run( "8-bit" )
IJ$run( "Invert" )
IJ$save( "bw-google.gif" )
image$close()

r4 <- raster("bw-google.gif")
plot(r4)
summary(r4)
extent(r4)

Hopefully I'll be able to use RImageJ for applying smoothing filters
and other image processing
methods that are too slow within R, without having to leave the R
scripting environment.

Agus

On Fri, Jan 17, 2014 at 9:26 AM, Michael Sumner <mdsumner at gmail.com> wrote:
> You are see a clash of the grDevices::as.raster with the raster
> package. grDevices is loaded by default, and has a (S3) method for
> whatever your image is (a matrix?).
>
> It seems like the S4 raster::as.raster should allow these to "pass
> through" to the underlying S3 method.
>
> I can't look any closer right now
>
>
>
>
>
> On Fri, Jan 17, 2014 at 7:09 PM, Agustin Lobo <alobolistas at gmail.com> wrote:
>> Actually, in OSX, there is no error message at using as.raster(), but
>> it does not work either:
>>
>> r <- as.raster(image)
>> class(r)
>>
>> [1] "raster"
>>> str(r)
>> 'raster' chr [1:76, 1:100] "#ffffff" "#ffffff" "#ffffff" "#ffffff"
>> "#ffffff" "#ffffff" "#ffffff" ...
>>
>> which is not the structure a raster object should have.
>>
>> Then:
>>
>> r <- as.raster.jobjRef(image)
>> Error: could not find function "as.raster.jobjRef"
>>
>> while ?as.raster.jobjRef shows the help page
>> the function as.raster.jobjRef" is not in the workspace (and this is
>> also the case in linux):
>>> search()
>>  [1] ".GlobalEnv"        "package:RImageJ"   "package:rJava"
>> "package:raster"    "package:sp"
>>  [6] "tools:rstudio"     "package:stats"     "package:graphics"
>> "package:grDevices" "package:utils"
>> [11] "package:datasets"  "package:methods"   "Autoloads"
>> "package:base"
>>> ls(2)
>> [1] "IJ"              "IJWindowManager" "ImageJ"
>>
>>
>> R version 3.0.2 (2013-09-25)
>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>>
>> locale:
>>   [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>>   [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>>   [1] RImageJ_0.2-146 rJava_0.9-6     raster_2.1-66   sp_1.0-13
>>
>> loaded via a namespace (and not attached):
>>   [1] grid_3.0.2      lattice_0.20-23 tools_3.0.2
>>
>>
>> Agus
>>
>> On Thu, Jan 16, 2014 at 4:09 PM, Agustin Lobo <alobolistas at gmail.com> wrote:
>>> Hi!
>>>
>>> While the following works fine:
>>> install.packages("/home/alobo/Downloads/RImageJ_0.2-146.tar.gz", repos
>>> = NULL, type="source")
>>> require(RImageJ)
>>> require(raster)
>>> logo <- system.file( "images", "R.jpg", package = "RImageJ" )
>>> image = IJ$openImage( logo )
>>> class(image)
>>> plot(c(100, 250), c(300, 450), type = "n", xlab="", ylab="")
>>> rasterImage(image, 100, 300, 150, 350, interpolate=FALSE)
>>>
>>> (note that the example in
>>> http://romainfrancois.blog.free.fr/index.php?category/R-package/RImageJ
>>> is currently wrong, it must be rasterImage() and not raster()
>>>
>>> But as.raster() (the most important for me) does not work:
>>>
>>>> class(image)
>>> [1] "jobjRef"
>>> attr(,"package")
>>> [1] "rJava"
>>>> r <- as.raster(image)
>>> Error in as.raster.jobjRef(image) : attempt to apply non-function
>>>
>>> see ?as.raster.jobjRef
>>>
>>> Any fix?
>>>
>>> Thanks
>>> Agus
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
> --
> Michael Sumner
> Hobart, Australia
> e-mail: mdsumner at gmail.com
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From ben.graeler at uni-muenster.de  Fri Jan 17 15:57:57 2014
From: ben.graeler at uni-muenster.de (=?ISO-8859-1?Q?Benedikt_Gr=E4ler?=)
Date: Fri, 17 Jan 2014 15:57:57 +0100
Subject: [R-sig-Geo] interactive spatio-temporal variogram exploration
Message-ID: <52D944F5.8030603@uni-muenster.de>

Dear list members,

motivated by a post from Erin Hodgess earlier this week, I put together
an "interactive spatio-temporal variogram exploration tool". It is a
shiny app based on gstat and is available at:

http://giv-graeler.uni-muenster.de:3838/spacetime/

The code of this shiny app can be obtained from github:

https://github.com/BenGraeler/copulatheque/tree/master/spacetime

After downloading the files, the shiny app should as well run locally
(using the shiny package from CRAN).

For numerical optimisation of the (pre-selected) parameters, the gstat
function "fit.StVariogram" (based on "optim") might be a helpful tool.

I hope this will be helpful to some of you,

 Ben


-- 
Benedikt Gr?ler

ifgi - Institute for Geoinformatics
University of Muenster

http://ifgi.uni-muenster.de/graeler

Phone: +49 251 83-33082
Mail: ben.graeler at uni-muenster.de


From brent.wilson at unb.ca  Fri Jan 17 16:01:31 2014
From: brent.wilson at unb.ca (Brent Wilson)
Date: Fri, 17 Jan 2014 11:01:31 -0400
Subject: [R-sig-Geo] random allocation of samples to polygons (with a
 predefined sampling intensity for each polygon)
Message-ID: <CAP3XK_9a2gG0027OxOT6c98cpZEb9ouRKNTA652jckLJ1e5s1w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140117/15cf0fe7/attachment.pl>

From virgilio.gomez at uclm.es  Fri Jan 17 17:11:20 2014
From: virgilio.gomez at uclm.es (Virgilio =?ISO-8859-1?Q?G=F3mez-Rubio?=)
Date: Fri, 17 Jan 2014 17:11:20 +0100
Subject: [R-sig-Geo] interactive spatio-temporal variogram exploration
In-Reply-To: <52D944F5.8030603@uni-muenster.de>
References: <52D944F5.8030603@uni-muenster.de>
Message-ID: <1389975080.2423.6.camel@virgil-HP-Compaq-8000-Elite-USDT-PC>

Dear Benedikt,

Many thanks for your nice example!! I am wondering whether it could be
possible to modify your code to allow the user to upload a file with the
data to be used. For example, a 3-column CSV file with x, y and variable
value. I am not a shiny user so I am not sure whether this is possible
at all. I'd like to try a similar approach for disease mapping where the
user can upload disease data plus boundaries and then try some spatial
smoothing models.

Best wishes,

Virgilio 

On vie, 2014-01-17 at 15:57 +0100, Benedikt Gr?ler wrote:
> Dear list members,
> 
> motivated by a post from Erin Hodgess earlier this week, I put together
> an "interactive spatio-temporal variogram exploration tool". It is a
> shiny app based on gstat and is available at:
> 
> http://giv-graeler.uni-muenster.de:3838/spacetime/
> 
> The code of this shiny app can be obtained from github:
> 
> https://github.com/BenGraeler/copulatheque/tree/master/spacetime
> 
> After downloading the files, the shiny app should as well run locally
> (using the shiny package from CRAN).
> 
> For numerical optimisation of the (pre-selected) parameters, the gstat
> function "fit.StVariogram" (based on "optim") might be a helpful tool.
> 
> I hope this will be helpful to some of you,
> 
>  Ben
> 
>


From jgrn at illinois.edu  Fri Jan 17 19:56:31 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Fri, 17 Jan 2014 12:56:31 -0600
Subject: [R-sig-Geo] Current options for creating/querying vector data
 WITHOUT loading them into memory?
In-Reply-To: <CANnL8gpCz=BtFo0k-gVDRoNfv7NAg09SJ4djfoNKqGvHk6i_3g@mail.gmail.com>
References: <4b03005cc0074cadb3d9511b1624856f@EX-1-HT0.lancs.local>
	<CANVKczMBQ-3HzeyAP5YrFjZ1rybuRuh02ZoDgmcLaUzhA2bJ_Q@mail.gmail.com>
	<CANnL8grCHUBaqG2iyFpMWEbRcvSqu3X=D=RCf4cDpA7K6XRn-g@mail.gmail.com>
	<CABG0rfvVbT9_sgm15MTDa=wrHzPVW7TFXWZB9yt+ZkPGHgTp0Q@mail.gmail.com>
	<CANnL8gpCz=BtFo0k-gVDRoNfv7NAg09SJ4djfoNKqGvHk6i_3g@mail.gmail.com>
Message-ID: <CABG0rfv9Kur1CCHcsGbn5Fiyyb6K7Mbwec+ihuxj+YK26xqrbA@mail.gmail.com>

Across all vector formats, which do you think would be a good
intermediate between in-memory Spatial* and PostGIS?  I'd put a few
stipulations:
1) The format should be open source and supported by existing APIs (OGR/rgeos)
2) It should be portable (file-based)
3) It should be "scalable" (able to support arbitrarily large vector databases)

Cheers!

--j

On Thu, Jan 16, 2014 at 2:49 PM, Tim Keitt <tkeitt at utexas.edu> wrote:
>
>
>
> On Thu, Jan 16, 2014 at 1:40 PM, Jonathan Greenberg <jgrn at illinois.edu>
> wrote:
>>
>> I've wondered if it would be possible to do something like what Robert
>> did with the raster() package, where the analysis (read/write) was
>> being done on-demand on the data rather than entirely in-memory.
>> Vector data is, of course, much more complicated to come up with
>> elegant solutions than raster data, but I think some basic
>> functionality would be great.  Perhaps spatialite as a backbone (since
>> you can easily install sqlite executable via the Rsqlite package, and
>> there is a now-abandoned but available code base in
>> http://cran.r-project.org/web/packages/SQLiteMap/ (I spoke to the
>> developer who said he won't be updating it) that might allow for a
>> relatively easy cross-platform install of the spatialite addon.
>> Something that would fill in the gap between the Spatial* classes
>> (which won't scale to large datasets) and PostGIS (which requires much
>> more complex installation requirements)?
>>
>> How does spatialite perform in terms of large queries?  I imagine not
>> as well as PostGIS, but does it at least scale memory-wise on most
>> standard queries?
>
>
> I've not used it. Generally sqlite is faster than postgresql but not as
> reliable. I just don't want to learn another syntax variation. Utilizing
> spatial indices for example in spatialite requires explicit modification of
> your SQL queries. There is no automatic index queries based on the planner
> as in postgresql. But its a very useful tool as you can do everything out of
> a single file on disk.
>
> THK
>
>>
>>
>> --j
>>
>> On Thu, Jan 16, 2014 at 1:14 PM, Tim Keitt <tkeitt at utexas.edu> wrote:
>> >
>> >
>> >
>> > On Thu, Jan 16, 2014 at 1:09 PM, Barry Rowlingson
>> > <b.rowlingson at lancaster.ac.uk> wrote:
>> >>
>> >> Well, back when I wrote 'rmap' I abstracted out the storage of the
>> >> data from the data object... So your object in R could represent a
>> >> subset of a shapefile, and the code only grabbed that chunk of the
>> >> shapefile when it was needed, for example to plot (the R object was
>> >> basically the name of the shapefile plus a selection vector).
>> >>
>> >> Then we threw that code out and sp classes were born!
>> >>
>> >>  I've often thought about restoring some of this kind of
>> >> functionality, but R's object-oriented classes just frustrate me. Its
>> >> not so simple to build a superclass of sp class objects. Or maybe it
>> >> is now? For some value of 'simple'...
>> >>
>> >>  Suppose you had a gigantic spatialite db - if you want to work with
>> >> it spatially (mapping, rgeos) you are going to have to get the bits
>> >> you need into main memory, so the simplest is just to load selections
>> >> into sp-class objects. Is that already possible with the OGR
>> >> spatialite driver? Can you also load subsets of shapefiles using some
>> >> SQL passed to the OGR shapefile driver?
>> >>
>> >>  What would you want to do on whole-dataset objects of this class?
>> >> Would you want to do the processing on the database if possible (if
>> >> its PostGIS or Spatialite)? Or have an automatic chunking procedure
>> >> for operations that don't need the whole database at once, such as
>> >> finding centroids of polygons?
>> >>
>> >> Hmmm thoughts thoughts thoughts and no action :( Sorry!
>> >
>> >
>> > Barry,
>> >
>> > I'll have more to say on this in a couple of weeks.
>> >
>> > THK
>> >
>> >>
>> >>
>> >> Barry
>> >>
>> >>
>> >>
>> >> On Thu, Jan 16, 2014 at 6:52 PM, Jonathan Greenberg <jgrn at illinois.edu>
>> >> wrote:
>> >> > r-sig-geo'ers:
>> >> >
>> >> > As vector datasets are getting a lot larger, there is a limitation
>> >> > with the Spatial* formats in that they must be loaded into main
>> >> > memory.  I was curious what folks who have been dealing with massive
>> >> > vector files have come up with working within the R environment?  Has
>> >> > anyone played around with file geodatabases or spatialite formats
>> >> > (for
>> >> > instance)?  How are you creating/querying the data?
>> >> >
>> >> > Thanks!
>> >> >
>> >> > --j
>> >> >
>> >> > --
>> >> > Jonathan A. Greenberg, PhD
>> >> > Assistant Professor
>> >> > Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>> >> > Department of Geography and Geographic Information Science
>> >> > University of Illinois at Urbana-Champaign
>> >> > 259 Computing Applications Building, MC-150
>> >> > 605 East Springfield Avenue
>> >> > Champaign, IL  61820-6371
>> >> > Phone: 217-300-1924
>> >> > http://www.geog.illinois.edu/~jgrn/
>> >> > AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype:
>> >> > jgrn3007
>> >> >
>> >> > _______________________________________________
>> >> > R-sig-Geo mailing list
>> >> > R-sig-Geo at r-project.org
>> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >>
>> >> _______________________________________________
>> >> R-sig-Geo mailing list
>> >> R-sig-Geo at r-project.org
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >
>> >
>> >
>> >
>> > --
>> > http://www.keittlab.org/
>>
>>
>>
>> --
>> Jonathan A. Greenberg, PhD
>> Assistant Professor
>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>> Department of Geography and Geographic Information Science
>> University of Illinois at Urbana-Champaign
>> 259 Computing Applications Building, MC-150
>> 605 East Springfield Avenue
>> Champaign, IL  61820-6371
>> Phone: 217-300-1924
>> http://www.geog.illinois.edu/~jgrn/
>> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>
>
>
>
> --
> http://www.keittlab.org/



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From Roger.Bivand at nhh.no  Fri Jan 17 20:22:50 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 17 Jan 2014 20:22:50 +0100
Subject: [R-sig-Geo] Current options for creating/querying vector data
 WITHOUT loading them into memory?
In-Reply-To: <CABG0rfv9Kur1CCHcsGbn5Fiyyb6K7Mbwec+ihuxj+YK26xqrbA@mail.gmail.com>
References: <4b03005cc0074cadb3d9511b1624856f@EX-1-HT0.lancs.local>
	<CANVKczMBQ-3HzeyAP5YrFjZ1rybuRuh02ZoDgmcLaUzhA2bJ_Q@mail.gmail.com>
	<CANnL8grCHUBaqG2iyFpMWEbRcvSqu3X=D=RCf4cDpA7K6XRn-g@mail.gmail.com>
	<CABG0rfvVbT9_sgm15MTDa=wrHzPVW7TFXWZB9yt+ZkPGHgTp0Q@mail.gmail.com>
	<CANnL8gpCz=BtFo0k-gVDRoNfv7NAg09SJ4djfoNKqGvHk6i_3g@mail.gmail.com>
	<CABG0rfv9Kur1CCHcsGbn5Fiyyb6K7Mbwec+ihuxj+YK26xqrbA@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1401172001360.31221@reclus.nhh.no>

On Fri, 17 Jan 2014, Jonathan Greenberg wrote:

> Across all vector formats, which do you think would be a good
> intermediate between in-memory Spatial* and PostGIS?  I'd put a few
> stipulations:
> 1) The format should be open source and supported by existing APIs 
> (OGR/rgeos)
> 2) It should be portable (file-based)
> 3) It should be "scalable" (able to support arbitrarily large vector 
> databases)

Could I ask for a range of use cases? The sp classes are designed for 
statistical analysis, so in general some hundreds of thousands of 
observations/features should suffice amply. The use cases should 
demonstrate which kinds of objects and functionalities are thought 
necessary. The fact that there is lots of data doesn't mean that it is all 
needed for analysis or inference, or even visualization, I think?

Have you considered interfacing the OGR utilities from the system() call 
to subset features/fields?

I think that 2) - file-based - is moot, if there is that much data, it 
needs to be in a database system, possibly with an OGR driver, which OGR 
utilities could access.

Have you considered Terralib (now 4, the development version 5 will be 
closer to GDAL/OGR)? My intuition is that this is a viable solution.

We really also need to accommodate space-time objects in any significant 
revision, I think - or at least prepare object structures that are 
forward-looking with regard to temporal data.

I have asked several times for volunteers to rewrite rgdal::readOGR 
(without anyone stepping forward), because it is fairly inefficient, and 
should support SQL queries introduced in GDAL/OGR from 1.8. Supporting the 
OGR SQL dialect means that all drivers support queries on FID and field 
values.

Within the next four years, I will be giving up maintenance of rgdal and 
rgeos (possibly other packages too). I can help, but users do not deserve 
key packages potentially compromised by the health and poor 
responsiveness of an emeritus. Forward planning is needed for others to 
take on these responsibilities before it becomes a matter of urgency. The 
pool of active developers must be enlarged this year.

Roger

>
> Cheers!
>
> --j
>
> On Thu, Jan 16, 2014 at 2:49 PM, Tim Keitt <tkeitt at utexas.edu> wrote:
>>
>>
>>
>> On Thu, Jan 16, 2014 at 1:40 PM, Jonathan Greenberg <jgrn at illinois.edu>
>> wrote:
>>>
>>> I've wondered if it would be possible to do something like what Robert
>>> did with the raster() package, where the analysis (read/write) was
>>> being done on-demand on the data rather than entirely in-memory.
>>> Vector data is, of course, much more complicated to come up with
>>> elegant solutions than raster data, but I think some basic
>>> functionality would be great.  Perhaps spatialite as a backbone (since
>>> you can easily install sqlite executable via the Rsqlite package, and
>>> there is a now-abandoned but available code base in
>>> http://cran.r-project.org/web/packages/SQLiteMap/ (I spoke to the
>>> developer who said he won't be updating it) that might allow for a
>>> relatively easy cross-platform install of the spatialite addon.
>>> Something that would fill in the gap between the Spatial* classes
>>> (which won't scale to large datasets) and PostGIS (which requires much
>>> more complex installation requirements)?
>>>
>>> How does spatialite perform in terms of large queries?  I imagine not
>>> as well as PostGIS, but does it at least scale memory-wise on most
>>> standard queries?
>>
>>
>> I've not used it. Generally sqlite is faster than postgresql but not as
>> reliable. I just don't want to learn another syntax variation. Utilizing
>> spatial indices for example in spatialite requires explicit modification of
>> your SQL queries. There is no automatic index queries based on the planner
>> as in postgresql. But its a very useful tool as you can do everything out of
>> a single file on disk.
>>
>> THK
>>
>>>
>>>
>>> --j
>>>
>>> On Thu, Jan 16, 2014 at 1:14 PM, Tim Keitt <tkeitt at utexas.edu> wrote:
>>>>
>>>>
>>>>
>>>> On Thu, Jan 16, 2014 at 1:09 PM, Barry Rowlingson
>>>> <b.rowlingson at lancaster.ac.uk> wrote:
>>>>>
>>>>> Well, back when I wrote 'rmap' I abstracted out the storage of the
>>>>> data from the data object... So your object in R could represent a
>>>>> subset of a shapefile, and the code only grabbed that chunk of the
>>>>> shapefile when it was needed, for example to plot (the R object was
>>>>> basically the name of the shapefile plus a selection vector).
>>>>>
>>>>> Then we threw that code out and sp classes were born!
>>>>>
>>>>>  I've often thought about restoring some of this kind of
>>>>> functionality, but R's object-oriented classes just frustrate me. Its
>>>>> not so simple to build a superclass of sp class objects. Or maybe it
>>>>> is now? For some value of 'simple'...
>>>>>
>>>>>  Suppose you had a gigantic spatialite db - if you want to work with
>>>>> it spatially (mapping, rgeos) you are going to have to get the bits
>>>>> you need into main memory, so the simplest is just to load selections
>>>>> into sp-class objects. Is that already possible with the OGR
>>>>> spatialite driver? Can you also load subsets of shapefiles using some
>>>>> SQL passed to the OGR shapefile driver?
>>>>>
>>>>>  What would you want to do on whole-dataset objects of this class?
>>>>> Would you want to do the processing on the database if possible (if
>>>>> its PostGIS or Spatialite)? Or have an automatic chunking procedure
>>>>> for operations that don't need the whole database at once, such as
>>>>> finding centroids of polygons?
>>>>>
>>>>> Hmmm thoughts thoughts thoughts and no action :( Sorry!
>>>>
>>>>
>>>> Barry,
>>>>
>>>> I'll have more to say on this in a couple of weeks.
>>>>
>>>> THK
>>>>
>>>>>
>>>>>
>>>>> Barry
>>>>>
>>>>>
>>>>>
>>>>> On Thu, Jan 16, 2014 at 6:52 PM, Jonathan Greenberg <jgrn at illinois.edu>
>>>>> wrote:
>>>>>> r-sig-geo'ers:
>>>>>>
>>>>>> As vector datasets are getting a lot larger, there is a limitation
>>>>>> with the Spatial* formats in that they must be loaded into main
>>>>>> memory.  I was curious what folks who have been dealing with massive
>>>>>> vector files have come up with working within the R environment?  Has
>>>>>> anyone played around with file geodatabases or spatialite formats
>>>>>> (for
>>>>>> instance)?  How are you creating/querying the data?
>>>>>>
>>>>>> Thanks!
>>>>>>
>>>>>> --j
>>>>>>
>>>>>> --
>>>>>> Jonathan A. Greenberg, PhD
>>>>>> Assistant Professor
>>>>>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>>>>>> Department of Geography and Geographic Information Science
>>>>>> University of Illinois at Urbana-Champaign
>>>>>> 259 Computing Applications Building, MC-150
>>>>>> 605 East Springfield Avenue
>>>>>> Champaign, IL  61820-6371
>>>>>> Phone: 217-300-1924
>>>>>> http://www.geog.illinois.edu/~jgrn/
>>>>>> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype:
>>>>>> jgrn3007
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at r-project.org
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at r-project.org
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> http://www.keittlab.org/
>>>
>>>
>>>
>>> --
>>> Jonathan A. Greenberg, PhD
>>> Assistant Professor
>>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>>> Department of Geography and Geographic Information Science
>>> University of Illinois at Urbana-Champaign
>>> 259 Computing Applications Building, MC-150
>>> 605 East Springfield Avenue
>>> Champaign, IL  61820-6371
>>> Phone: 217-300-1924
>>> http://www.geog.illinois.edu/~jgrn/
>>> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>>
>>
>>
>>
>> --
>> http://www.keittlab.org/
>
>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From tkeitt at utexas.edu  Fri Jan 17 23:57:07 2014
From: tkeitt at utexas.edu (Tim Keitt)
Date: Fri, 17 Jan 2014 16:57:07 -0600
Subject: [R-sig-Geo] Current options for creating/querying vector data
 WITHOUT loading them into memory?
In-Reply-To: <alpine.LRH.2.03.1401172001360.31221@reclus.nhh.no>
References: <4b03005cc0074cadb3d9511b1624856f@EX-1-HT0.lancs.local>
	<CANVKczMBQ-3HzeyAP5YrFjZ1rybuRuh02ZoDgmcLaUzhA2bJ_Q@mail.gmail.com>
	<CANnL8grCHUBaqG2iyFpMWEbRcvSqu3X=D=RCf4cDpA7K6XRn-g@mail.gmail.com>
	<CABG0rfvVbT9_sgm15MTDa=wrHzPVW7TFXWZB9yt+ZkPGHgTp0Q@mail.gmail.com>
	<CANnL8gpCz=BtFo0k-gVDRoNfv7NAg09SJ4djfoNKqGvHk6i_3g@mail.gmail.com>
	<CABG0rfv9Kur1CCHcsGbn5Fiyyb6K7Mbwec+ihuxj+YK26xqrbA@mail.gmail.com>
	<alpine.LRH.2.03.1401172001360.31221@reclus.nhh.no>
Message-ID: <CANnL8gowzfEeRXoLGtVpLQsQeMf5fPUFEaeb4ZtBfQ_Mrz6ekg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140117/3b87f47d/attachment.pl>

From Roger.Bivand at nhh.no  Sat Jan 18 08:31:17 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 18 Jan 2014 08:31:17 +0100
Subject: [R-sig-Geo] Current options for creating/querying vector data
 WITHOUT loading them into memory?
In-Reply-To: <CANnL8gowzfEeRXoLGtVpLQsQeMf5fPUFEaeb4ZtBfQ_Mrz6ekg@mail.gmail.com>
References: <4b03005cc0074cadb3d9511b1624856f@EX-1-HT0.lancs.local>
	<CANVKczMBQ-3HzeyAP5YrFjZ1rybuRuh02ZoDgmcLaUzhA2bJ_Q@mail.gmail.com>
	<CANnL8grCHUBaqG2iyFpMWEbRcvSqu3X=D=RCf4cDpA7K6XRn-g@mail.gmail.com>
	<CABG0rfvVbT9_sgm15MTDa=wrHzPVW7TFXWZB9yt+ZkPGHgTp0Q@mail.gmail.com>
	<CANnL8gpCz=BtFo0k-gVDRoNfv7NAg09SJ4djfoNKqGvHk6i_3g@mail.gmail.com>
	<CABG0rfv9Kur1CCHcsGbn5Fiyyb6K7Mbwec+ihuxj+YK26xqrbA@mail.gmail.com>
	<alpine.LRH.2.03.1401172001360.31221@reclus.nhh.no>
	<CANnL8gowzfEeRXoLGtVpLQsQeMf5fPUFEaeb4ZtBfQ_Mrz6ekg@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1401180811460.1016@reclus.nhh.no>

On Fri, 17 Jan 2014, Tim Keitt wrote:

> On Fri, Jan 17, 2014 at 1:22 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Fri, 17 Jan 2014, Jonathan Greenberg wrote:
>>
>>  Across all vector formats, which do you think would be a good
>>> intermediate between in-memory Spatial* and PostGIS?  I'd put a few
>>> stipulations:
>>> 1) The format should be open source and supported by existing APIs
>>> (OGR/rgeos)
>>> 2) It should be portable (file-based)
>>> 3) It should be "scalable" (able to support arbitrarily large vector
>>> databases)
>>>
>>
>> Could I ask for a range of use cases? The sp classes are designed for
>> statistical analysis, so in general some hundreds of thousands of
>> observations/features should suffice amply. The use cases should
>> demonstrate which kinds of objects and functionalities are thought
>> necessary. The fact that there is lots of data doesn't mean that it is all
>> needed for analysis or inference, or even visualization, I think?
>>
>> Have you considered interfacing the OGR utilities from the system() call
>> to subset features/fields?
>>
>> I think that 2) - file-based - is moot, if there is that much data, it
>> needs to be in a database system, possibly with an OGR driver, which OGR
>> utilities could access.
>>
>> Have you considered Terralib (now 4, the development version 5 will be
>> closer to GDAL/OGR)? My intuition is that this is a viable solution.
>>
>> We really also need to accommodate space-time objects in any significant
>> revision, I think - or at least prepare object structures that are
>> forward-looking with regard to temporal data.
>>
>> I have asked several times for volunteers to rewrite rgdal::readOGR
>> (without anyone stepping forward), because it is fairly inefficient, and
>> should support SQL queries introduced in GDAL/OGR from 1.8. Supporting the
>> OGR SQL dialect means that all drivers support queries on FID and field
>> values.
>>
>> Within the next four years, I will be giving up maintenance of rgdal and
>> rgeos (possibly other packages too). I can help, but users do not deserve
>> key packages potentially compromised by the health and poor responsiveness
>> of an emeritus. Forward planning is needed for others to take on these
>> responsibilities before it becomes a matter of urgency. The pool of active
>> developers must be enlarged this year.
>>
>
> Roger,
>
> Thank you for your maintenance efforts!
>
> I've drifted towards postgis/C++ over time in my own work, but am now 
> developing some courses around R. I anticipate being fairly active with 
> R development going forward. I have a full rewrite of the OGR io bits 
> that I will make available soon. It works really well when your data are 
> in postgis or any other OGR format.

Tim,

This is very positive, thanks! When you are ready (or even before!), I'd 
strongly encourage others to get to know more of the rgdal/rgeos 
internals, and developments in the underlying software and standards. I'll 
be speaking at OGRS in Helsinki in June (http://2014.ogrs-community.org); 
could we use that as a tentative time frame (especially if interacting 
with others in the open source geospatial communities may be helpful)? 
Should we try to put an RFC together (and put it on R-forge, for example)?

I have considered using the OGC/GEOS representation under a thin "new" sp, 
but couldn't see how to avoid having at least one representation of 
geometries in memory. The sp <-> GEOS bridge in rgeos is there and sort-of 
works (the classes don't map exactly), but involves a lot of conversion. 
As OGR can link to GEOS, it might make sense to consider merging the 
packages. I couldn't see how to approach the elegance of your external 
pointer code for low-level GDAL interaction - pointing to an open GDAL 
object, but then regular grids have sparse geometries.

Roger

>
> THK
>
>
>>
>> Roger
>>
>>
>>
>>> Cheers!
>>>
>>> --j
>>>
>>> On Thu, Jan 16, 2014 at 2:49 PM, Tim Keitt <tkeitt at utexas.edu> wrote:
>>>
>>>>
>>>>
>>>>
>>>> On Thu, Jan 16, 2014 at 1:40 PM, Jonathan Greenberg <jgrn at illinois.edu>
>>>> wrote:
>>>>
>>>>>
>>>>> I've wondered if it would be possible to do something like what Robert
>>>>> did with the raster() package, where the analysis (read/write) was
>>>>> being done on-demand on the data rather than entirely in-memory.
>>>>> Vector data is, of course, much more complicated to come up with
>>>>> elegant solutions than raster data, but I think some basic
>>>>> functionality would be great.  Perhaps spatialite as a backbone (since
>>>>> you can easily install sqlite executable via the Rsqlite package, and
>>>>> there is a now-abandoned but available code base in
>>>>> http://cran.r-project.org/web/packages/SQLiteMap/ (I spoke to the
>>>>> developer who said he won't be updating it) that might allow for a
>>>>> relatively easy cross-platform install of the spatialite addon.
>>>>> Something that would fill in the gap between the Spatial* classes
>>>>> (which won't scale to large datasets) and PostGIS (which requires much
>>>>> more complex installation requirements)?
>>>>>
>>>>> How does spatialite perform in terms of large queries?  I imagine not
>>>>> as well as PostGIS, but does it at least scale memory-wise on most
>>>>> standard queries?
>>>>>
>>>>
>>>>
>>>> I've not used it. Generally sqlite is faster than postgresql but not as
>>>> reliable. I just don't want to learn another syntax variation. Utilizing
>>>> spatial indices for example in spatialite requires explicit modification
>>>> of
>>>> your SQL queries. There is no automatic index queries based on the
>>>> planner
>>>> as in postgresql. But its a very useful tool as you can do everything
>>>> out of
>>>> a single file on disk.
>>>>
>>>> THK
>>>>
>>>>
>>>>>
>>>>> --j
>>>>>
>>>>> On Thu, Jan 16, 2014 at 1:14 PM, Tim Keitt <tkeitt at utexas.edu> wrote:
>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> On Thu, Jan 16, 2014 at 1:09 PM, Barry Rowlingson
>>>>>> <b.rowlingson at lancaster.ac.uk> wrote:
>>>>>>
>>>>>>>
>>>>>>> Well, back when I wrote 'rmap' I abstracted out the storage of the
>>>>>>> data from the data object... So your object in R could represent a
>>>>>>> subset of a shapefile, and the code only grabbed that chunk of the
>>>>>>> shapefile when it was needed, for example to plot (the R object was
>>>>>>> basically the name of the shapefile plus a selection vector).
>>>>>>>
>>>>>>> Then we threw that code out and sp classes were born!
>>>>>>>
>>>>>>>  I've often thought about restoring some of this kind of
>>>>>>> functionality, but R's object-oriented classes just frustrate me. Its
>>>>>>> not so simple to build a superclass of sp class objects. Or maybe it
>>>>>>> is now? For some value of 'simple'...
>>>>>>>
>>>>>>>  Suppose you had a gigantic spatialite db - if you want to work with
>>>>>>> it spatially (mapping, rgeos) you are going to have to get the bits
>>>>>>> you need into main memory, so the simplest is just to load selections
>>>>>>> into sp-class objects. Is that already possible with the OGR
>>>>>>> spatialite driver? Can you also load subsets of shapefiles using some
>>>>>>> SQL passed to the OGR shapefile driver?
>>>>>>>
>>>>>>>  What would you want to do on whole-dataset objects of this class?
>>>>>>> Would you want to do the processing on the database if possible (if
>>>>>>> its PostGIS or Spatialite)? Or have an automatic chunking procedure
>>>>>>> for operations that don't need the whole database at once, such as
>>>>>>> finding centroids of polygons?
>>>>>>>
>>>>>>> Hmmm thoughts thoughts thoughts and no action :( Sorry!
>>>>>>>
>>>>>>
>>>>>>
>>>>>> Barry,
>>>>>>
>>>>>> I'll have more to say on this in a couple of weeks.
>>>>>>
>>>>>> THK
>>>>>>
>>>>>>
>>>>>>>
>>>>>>> Barry
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> On Thu, Jan 16, 2014 at 6:52 PM, Jonathan Greenberg <
>>>>>>> jgrn at illinois.edu>
>>>>>>> wrote:
>>>>>>>
>>>>>>>> r-sig-geo'ers:
>>>>>>>>
>>>>>>>> As vector datasets are getting a lot larger, there is a limitation
>>>>>>>> with the Spatial* formats in that they must be loaded into main
>>>>>>>> memory.  I was curious what folks who have been dealing with massive
>>>>>>>> vector files have come up with working within the R environment?  Has
>>>>>>>> anyone played around with file geodatabases or spatialite formats
>>>>>>>> (for
>>>>>>>> instance)?  How are you creating/querying the data?
>>>>>>>>
>>>>>>>> Thanks!
>>>>>>>>
>>>>>>>> --j
>>>>>>>>
>>>>>>>> --
>>>>>>>> Jonathan A. Greenberg, PhD
>>>>>>>> Assistant Professor
>>>>>>>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>>>>>>>> Department of Geography and Geographic Information Science
>>>>>>>> University of Illinois at Urbana-Champaign
>>>>>>>> 259 Computing Applications Building, MC-150
>>>>>>>> 605 East Springfield Avenue
>>>>>>>> Champaign, IL  61820-6371
>>>>>>>> Phone: 217-300-1924
>>>>>>>> http://www.geog.illinois.edu/~jgrn/
>>>>>>>> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype:
>>>>>>>> jgrn3007
>>>>>>>>
>>>>>>>> _______________________________________________
>>>>>>>> R-sig-Geo mailing list
>>>>>>>> R-sig-Geo at r-project.org
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>>
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-Geo mailing list
>>>>>>> R-sig-Geo at r-project.org
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> http://www.keittlab.org/
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> Jonathan A. Greenberg, PhD
>>>>> Assistant Professor
>>>>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>>>>> Department of Geography and Geographic Information Science
>>>>> University of Illinois at Urbana-Champaign
>>>>> 259 Computing Applications Building, MC-150
>>>>> 605 East Springfield Avenue
>>>>> Champaign, IL  61820-6371
>>>>> Phone: 217-300-1924
>>>>> http://www.geog.illinois.edu/~jgrn/
>>>>> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>>>>>
>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> http://www.keittlab.org/
>>>>
>>>
>>>
>>>
>>>
>>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From HodgessE at uhd.edu  Sat Jan 18 19:00:24 2014
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Sat, 18 Jan 2014 18:00:24 +0000
Subject: [R-sig-Geo] interactive spatio-temporal variogram exploration
In-Reply-To: <1389975080.2423.6.camel@virgil-HP-Compaq-8000-Elite-USDT-PC>
References: <52D944F5.8030603@uni-muenster.de>,
	<1389975080.2423.6.camel@virgil-HP-Compaq-8000-Elite-USDT-PC>
Message-ID: <FF9DB805FC41CC4E95825A50F680630217B01F19@challenger.uhd.campus>

For what it's worth, I'm working on an RcmdrPlugin package to do kriging and maps and maybe spatio-temporal stuff, if anyone might be interested
________________________________________
From: r-sig-geo-bounces at r-project.org [r-sig-geo-bounces at r-project.org] on behalf of Virgilio G?mez-Rubio [virgilio.gomez at uclm.es]
Sent: Friday, January 17, 2014 10:11 AM
To: Benedikt Gr?ler
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] interactive spatio-temporal variogram exploration

Dear Benedikt,

Many thanks for your nice example!! I am wondering whether it could be
possible to modify your code to allow the user to upload a file with the
data to be used. For example, a 3-column CSV file with x, y and variable
value. I am not a shiny user so I am not sure whether this is possible
at all. I'd like to try a similar approach for disease mapping where the
user can upload disease data plus boundaries and then try some spatial
smoothing models.

Best wishes,

Virgilio

On vie, 2014-01-17 at 15:57 +0100, Benedikt Gr?ler wrote:
> Dear list members,
>
> motivated by a post from Erin Hodgess earlier this week, I put together
> an "interactive spatio-temporal variogram exploration tool". It is a
> shiny app based on gstat and is available at:
>
> http://giv-graeler.uni-muenster.de:3838/spacetime/
>
> The code of this shiny app can be obtained from github:
>
> https://github.com/BenGraeler/copulatheque/tree/master/spacetime
>
> After downloading the files, the shiny app should as well run locally
> (using the shiny package from CRAN).
>
> For numerical optimisation of the (pre-selected) parameters, the gstat
> function "fit.StVariogram" (based on "optim") might be a helpful tool.
>
> I hope this will be helpful to some of you,
>
>  Ben
>
>

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From tkeitt at utexas.edu  Sat Jan 18 19:32:33 2014
From: tkeitt at utexas.edu (Tim Keitt)
Date: Sat, 18 Jan 2014 12:32:33 -0600
Subject: [R-sig-Geo] Current options for creating/querying vector data
 WITHOUT loading them into memory?
In-Reply-To: <alpine.LRH.2.03.1401180811460.1016@reclus.nhh.no>
References: <4b03005cc0074cadb3d9511b1624856f@EX-1-HT0.lancs.local>
	<CANVKczMBQ-3HzeyAP5YrFjZ1rybuRuh02ZoDgmcLaUzhA2bJ_Q@mail.gmail.com>
	<CANnL8grCHUBaqG2iyFpMWEbRcvSqu3X=D=RCf4cDpA7K6XRn-g@mail.gmail.com>
	<CABG0rfvVbT9_sgm15MTDa=wrHzPVW7TFXWZB9yt+ZkPGHgTp0Q@mail.gmail.com>
	<CANnL8gpCz=BtFo0k-gVDRoNfv7NAg09SJ4djfoNKqGvHk6i_3g@mail.gmail.com>
	<CABG0rfv9Kur1CCHcsGbn5Fiyyb6K7Mbwec+ihuxj+YK26xqrbA@mail.gmail.com>
	<alpine.LRH.2.03.1401172001360.31221@reclus.nhh.no>
	<CANnL8gowzfEeRXoLGtVpLQsQeMf5fPUFEaeb4ZtBfQ_Mrz6ekg@mail.gmail.com>
	<alpine.LRH.2.03.1401180811460.1016@reclus.nhh.no>
Message-ID: <CANnL8gon83OrF1=WM4GmpvQYez77m+=6dfuhoA44n3a4Xo1ReQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140118/7eebb848/attachment.pl>

From pickering at penguin.kobe-u.ac.jp  Mon Jan 20 08:41:20 2014
From: pickering at penguin.kobe-u.ac.jp (Steve Pickering)
Date: Mon, 20 Jan 2014 16:41:20 +0900
Subject: [R-sig-Geo] Converting shapefile from gridded to lat/ lng
Message-ID: <CAEdPBsH-o_EgnK_kHPLBMsaCPHxpTS+aVrp5rLoj10KQTQYmHg@mail.gmail.com>

Apologies if this seems a trivial one, but I know I'm missing something.

I am working with a shapefile of local authorities in England and
Wales (available here:
http://www.sharegeo.ac.uk/download/10672/330/Local%20Authority%20District%20Population%20for%20England%20and%20Wales%20-%20Census%202011.zip
)

The shapefile is in a gridded format, but I need to convert to a
conventional lat/ lng coordinates format, and then plot in the usual
way.

Can you help?  Many thanks!

library(sp)
library(maptools)
authoritiesMap = readShapePoly("LAD_Pop_EngWales2011")
plot(authoritiesMap)

 - Steve.

Steve Pickering
Assistant Professor
Kobe University
2-1 Rokkodai-cho
Nada-ku, Kobe
657-8501 Japan
pickering at penguin.kobe-u.ac.jp
http://www.stevepickering.net


From kridox at ymail.com  Mon Jan 20 09:10:43 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Mon, 20 Jan 2014 17:10:43 +0900
Subject: [R-sig-Geo] Converting shapefile from gridded to lat/ lng
In-Reply-To: <CAEdPBsH-o_EgnK_kHPLBMsaCPHxpTS+aVrp5rLoj10KQTQYmHg@mail.gmail.com>
References: <CAEdPBsH-o_EgnK_kHPLBMsaCPHxpTS+aVrp5rLoj10KQTQYmHg@mail.gmail.com>
Message-ID: <CAAcyNCyQH+Eq7q7yiO-v1QvDxCL__3dt_rmAQkuEFPqO5G2t-g@mail.gmail.com>

Hello,

Maybe something like that:


library(sp)
library(maptools)
library(rgdal)

crs.ll <- "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0"
crs.tmerc <- "+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717
+x_0=400000 +y_0=-100000 +ellps=airy +datum=OSGB36 +units=m +no_defs"

authoritiesMap.TMERC <- readShapePoly("LAD_Pop_EngWales2011",
proj4string=CRS(crs.tmerc))
authoritiesMap.LL <- spTransform(authoritiesMap.TMERC, CRS(crs.ll))

par(mfrow=c(1,2), las=1)
plot(authoritiesMap.TMERC)
axis(1)
axis(2)
title(main="Transverse Mercator")
plot(authoritiesMap.LL)
axis(1)
axis(2)
title(main="LongLat")


HTH,
Pascal

On 20 January 2014 16:41, Steve Pickering
<pickering at penguin.kobe-u.ac.jp> wrote:
> Apologies if this seems a trivial one, but I know I'm missing something.
>
> I am working with a shapefile of local authorities in England and
> Wales (available here:
> http://www.sharegeo.ac.uk/download/10672/330/Local%20Authority%20District%20Population%20for%20England%20and%20Wales%20-%20Census%202011.zip
> )
>
> The shapefile is in a gridded format, but I need to convert to a
> conventional lat/ lng coordinates format, and then plot in the usual
> way.
>
> Can you help?  Many thanks!
>
> library(sp)
> library(maptools)
> authoritiesMap = readShapePoly("LAD_Pop_EngWales2011")
> plot(authoritiesMap)
>
>  - Steve.
>
> Steve Pickering
> Assistant Professor
> Kobe University
> 2-1 Rokkodai-cho
> Nada-ku, Kobe
> 657-8501 Japan
> pickering at penguin.kobe-u.ac.jp
> http://www.stevepickering.net
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From b.rowlingson at lancaster.ac.uk  Mon Jan 20 09:25:19 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 20 Jan 2014 08:25:19 +0000
Subject: [R-sig-Geo] Converting shapefile from gridded to lat/ lng
In-Reply-To: <c09f128d483c4a32ab69c6b78c68a5ff@EX-1-HT0.lancs.local>
References: <CAEdPBsH-o_EgnK_kHPLBMsaCPHxpTS+aVrp5rLoj10KQTQYmHg@mail.gmail.com>
	<c09f128d483c4a32ab69c6b78c68a5ff@EX-1-HT0.lancs.local>
Message-ID: <CANVKczPpYHwmdMV8OOgyWGC1Y-BSPy2x6F7utmqt8Vio01+3+A@mail.gmail.com>

On Mon, Jan 20, 2014 at 8:10 AM, Pascal Oettli <kridox at ymail.com> wrote:

> crs.ll <- "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0"
> crs.tmerc <- "+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717
> +x_0=400000 +y_0=-100000 +ellps=airy +datum=OSGB36 +units=m +no_defs"
>
> authoritiesMap.TMERC <- readShapePoly("LAD_Pop_EngWales2011",
> proj4string=CRS(crs.tmerc))

proj4string(authorities.Map) = CRS(crs.tmerc) # surely?

> authoritiesMap.LL <- spTransform(authoritiesMap.TMERC, CRS(crs.ll))

If you use readOGR from package:rgdal *and* your shapefile comes with
the correct .prj file (in the same folder with the .shp and .dbf) then
the spatial polygons object will already have the correct CRS assigned
to it and you can skip half these steps. Something like:

map = readOGR(".","LAD_Pop_EngWales2011")
mapLL = spTransform(map, CRS("+init=epsg:4326"))

 - epsg code 4326 is the lat-long system as used by GPS. epsg code
27700 is the UK national grid format which might be what you original
file is, or something else entirely! Anyway, if you've got a .prj
file, its a two-liner.


From kridox at ymail.com  Mon Jan 20 09:32:19 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Mon, 20 Jan 2014 17:32:19 +0900
Subject: [R-sig-Geo] Converting shapefile from gridded to lat/ lng
In-Reply-To: <CANVKczPpYHwmdMV8OOgyWGC1Y-BSPy2x6F7utmqt8Vio01+3+A@mail.gmail.com>
References: <CAEdPBsH-o_EgnK_kHPLBMsaCPHxpTS+aVrp5rLoj10KQTQYmHg@mail.gmail.com>
	<c09f128d483c4a32ab69c6b78c68a5ff@EX-1-HT0.lancs.local>
	<CANVKczPpYHwmdMV8OOgyWGC1Y-BSPy2x6F7utmqt8Vio01+3+A@mail.gmail.com>
Message-ID: <CAAcyNCzv9TpAcaHNuS4gU2ttEJZP5BSU==5X+V1hNmRuJDMezg@mail.gmail.com>

Hello,

Thank you Barry. Always interesting to learn something.

Regards,
Pascal


On 20 January 2014 17:25, Barry Rowlingson <b.rowlingson at lancaster.ac.uk> wrote:
> On Mon, Jan 20, 2014 at 8:10 AM, Pascal Oettli <kridox at ymail.com> wrote:
>
>> crs.ll <- "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0"
>> crs.tmerc <- "+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717
>> +x_0=400000 +y_0=-100000 +ellps=airy +datum=OSGB36 +units=m +no_defs"
>>
>> authoritiesMap.TMERC <- readShapePoly("LAD_Pop_EngWales2011",
>> proj4string=CRS(crs.tmerc))
>
> proj4string(authorities.Map) = CRS(crs.tmerc) # surely?
>
>> authoritiesMap.LL <- spTransform(authoritiesMap.TMERC, CRS(crs.ll))
>
> If you use readOGR from package:rgdal *and* your shapefile comes with
> the correct .prj file (in the same folder with the .shp and .dbf) then
> the spatial polygons object will already have the correct CRS assigned
> to it and you can skip half these steps. Something like:
>
> map = readOGR(".","LAD_Pop_EngWales2011")
> mapLL = spTransform(map, CRS("+init=epsg:4326"))
>
>  - epsg code 4326 is the lat-long system as used by GPS. epsg code
> 27700 is the UK national grid format which might be what you original
> file is, or something else entirely! Anyway, if you've got a .prj
> file, its a two-liner.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From pickering at penguin.kobe-u.ac.jp  Mon Jan 20 09:48:58 2014
From: pickering at penguin.kobe-u.ac.jp (Steve Pickering)
Date: Mon, 20 Jan 2014 17:48:58 +0900
Subject: [R-sig-Geo] Converting shapefile from gridded to lat/ lng
In-Reply-To: <CAAcyNCzv9TpAcaHNuS4gU2ttEJZP5BSU==5X+V1hNmRuJDMezg@mail.gmail.com>
References: <CAEdPBsH-o_EgnK_kHPLBMsaCPHxpTS+aVrp5rLoj10KQTQYmHg@mail.gmail.com>
	<c09f128d483c4a32ab69c6b78c68a5ff@EX-1-HT0.lancs.local>
	<CANVKczPpYHwmdMV8OOgyWGC1Y-BSPy2x6F7utmqt8Vio01+3+A@mail.gmail.com>
	<CAAcyNCzv9TpAcaHNuS4gU2ttEJZP5BSU==5X+V1hNmRuJDMezg@mail.gmail.com>
Message-ID: <CAEdPBsGsv1cQX6u7LEjvHmh7pKn-uYS+UyaeOXBEF28sciR_jA@mail.gmail.com>

Thank you both, this is perfect.  I wonder if there is a way using
Pascal's approach to then plot it as an unprojected map, rather than
with transverse Mercator.  Sorry, I'll stop bothering you after this
question!

 - Steve.
Steve Pickering
Assistant Professor
Graduate School of Law
Kobe University
2-1 Rokkodai-cho
Nada-ku, Kobe
657-8501 Japan
pickering at penguin.kobe-u.ac.jp
http://www.stevepickering.net


On 20 January 2014 17:32, Pascal Oettli <kridox at ymail.com> wrote:
> Hello,
>
> Thank you Barry. Always interesting to learn something.
>
> Regards,
> Pascal
>
>
> On 20 January 2014 17:25, Barry Rowlingson <b.rowlingson at lancaster.ac.uk> wrote:
>> On Mon, Jan 20, 2014 at 8:10 AM, Pascal Oettli <kridox at ymail.com> wrote:
>>
>>> crs.ll <- "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0"
>>> crs.tmerc <- "+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717
>>> +x_0=400000 +y_0=-100000 +ellps=airy +datum=OSGB36 +units=m +no_defs"
>>>
>>> authoritiesMap.TMERC <- readShapePoly("LAD_Pop_EngWales2011",
>>> proj4string=CRS(crs.tmerc))
>>
>> proj4string(authorities.Map) = CRS(crs.tmerc) # surely?
>>
>>> authoritiesMap.LL <- spTransform(authoritiesMap.TMERC, CRS(crs.ll))
>>
>> If you use readOGR from package:rgdal *and* your shapefile comes with
>> the correct .prj file (in the same folder with the .shp and .dbf) then
>> the spatial polygons object will already have the correct CRS assigned
>> to it and you can skip half these steps. Something like:
>>
>> map = readOGR(".","LAD_Pop_EngWales2011")
>> mapLL = spTransform(map, CRS("+init=epsg:4326"))
>>
>>  - epsg code 4326 is the lat-long system as used by GPS. epsg code
>> 27700 is the UK national grid format which might be what you original
>> file is, or something else entirely! Anyway, if you've got a .prj
>> file, its a two-liner.
>
>
>
> --
> Pascal Oettli
> Project Scientist
> JAMSTEC
> Yokohama, Japan
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From i.mandl at gmx.at  Mon Jan 20 10:02:04 2014
From: i.mandl at gmx.at (Isabella Mandl)
Date: Mon, 20 Jan 2014 10:02:04 +0100
Subject: [R-sig-Geo] Problems with adehabitat and gpclib
In-Reply-To: <52DCE222.8070307@gmx.at>
References: <52DCE222.8070307@gmx.at>
Message-ID: <52DCE60C.2060907@gmx.at>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140120/bc222adb/attachment.pl>

From Roger.Bivand at nhh.no  Mon Jan 20 10:29:41 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 20 Jan 2014 10:29:41 +0100
Subject: [R-sig-Geo] Problems with adehabitat and gpclib
In-Reply-To: <52DCE60C.2060907@gmx.at>
References: <52DCE222.8070307@gmx.at> <52DCE60C.2060907@gmx.at>
Message-ID: <alpine.LRH.2.03.1401201006030.3994@reclus.nhh.no>

On Mon, 20 Jan 2014, Isabella Mandl wrote:

>
> Hello everyone,
>
> I'm quite new to R and have done a few basic Intro tutorials so far. To
> clarify: I'm using the newest version of R (3.0.2.) with RStudio on a
> Windows 7 PC.
>
> I intend on using R to draw up and analyse LoCoH home ranges for a small
> data set I have. Now I'm trying to familiarise myself with /adehabitat/
> and /adehabitatHR/.
> However, when I try to run through the tutorials with the sample data I
> encounter problems with the package /gpclib/. I have done some research
> on in and I understand that /gpclib/ requires a permit and shouldn't be
> used - apparently the package /rgeos/ can substitute  for it. This,
> however does not seem to work for me.
>
> If I try to install /gpclib/ (from a download as no binary version
> available for windows) I get this:

(unless you have installed R-tools, you cannot install source packages on 
Windows, because they need compilers that you do not have, hence the 
error).

Did you go to:

http://cran.r-project.org/bin/windows/contrib/r-release/ReadMe

from:

http://cran.r-project.org/web/packages/gpclib/index.html

and then read:

"Packages
 	RSvgDevice, RSVGTipsDevice, StreamingLm, TwoPhaseInd, eco, gpclib,
 	ifa, translate
are not checked nor distributed due to crashes under Windows or
extremely unstable check results that switch forth and back between OK
and ERROR or WARNING."

So there is a good reason for the Windows binary not being provided, see:

http://www.r-project.org/nosvn/R.check/r-release-windows-ix86+x86_64/gpclib-00check.html

This is over and above the known licence issue with gpclib.

The date on the tutorial you refer to is 2005, so you can safely assume 
that its shelf-life is exceeded.

Please do refer to adehabitatHR and the functions provided there, unless 
you really need to reproduce research done with the source you refer to. 
LoCoH.k.area() and LoCoH.k() work as expected in the example given in 
?LoCoH.k for current R:

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-unknown-linux-gnu (64-bit)
...
other attached packages:
  [1] rgeos_0.3-2         maptools_0.8-27     adehabitatHR_0.4.10
  [4] adehabitatLT_0.3.14 CircStats_0.2-4     boot_1.3-9
  [7] MASS_7.3-29         adehabitatMA_0.3.8  ade4_1.6-2
[10] deldir_0.1-1        sp_1.0-14

loaded via a namespace (and not attached):
[1] foreign_0.8-57  grid_3.0.2      lattice_0.20-24 tcltk_3.0.2
[5] tools_3.0.2

Unless authors of online "advice" instrument their contributions to track 
developments in the software used, they shouls always include the output 
of sessionInfo(), so that those needing to reproduce their results can 
install *those versions* of the software. On CRAN, all versions are still 
available in archive sections, so we try as hard as we can to permit 
reproduction of results, but you may not have access to the hardware 
and OS used (so OS and hardware bugs may not be reproducible).

Hope this clarifies,

Roger

>
>> install.packages("C:/Users/Isabella/Downloads/gpclib_1.5-5.tar.gz", repos = NULL, type = "source")
> Installing package into 'C:/Users/Isabella/Documents/R/win-library/3.0'
> (as 'lib' is unspecified)
> * installing *source* package 'gpclib' ...
> ** package 'gpclib' successfully unpacked and MD5 sums checked
> ** libs
> ERROR: compilation failed for package 'gpclib'
> * removing 'C:/Users/Isabella/Documents/R/win-library/3.0/gpclib'
> Warning in install.packages :
>   running command '"C:/PROGRA~1/R/R-30~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\Isabella\Documents\R\win-library\3.0" "C:/Users/Isabella/Downloads/gpclib_1.5-5.tar.gz"' had status 1
> Warning in install.packages :
>   installation of package 'C:/Users/Isabella/Downloads/gpclib_1.5-5.tar.gz' had non-zero exit status
>
>
> Consequently I tend to get this message:
>
> In library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :
>   there is no package called 'gpclib'
>
>
> This here is the closest what I found to relate to my problem but I
> don't really understand what to do:
> http://tlocoh.r-forge.r-project.org/manual_install.html
> This was the tutorial I'm trying to walk through:
> http://locoh.cnr.berkeley.edu/rtutorial
>
> What I am looking for now are is some easy-to-understand guidance of how
> to get /adehabitat/ to work without /gpclib/ *OR* how to get /gpclib/ to
> work.
>
> Please let me know if you need more information or what I am doing
> wrong, I'm grateful for any help.
>
> Cheers, Bella
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Mon Jan 20 11:03:35 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 20 Jan 2014 11:03:35 +0100
Subject: [R-sig-Geo] GEOSTAT course 15-22 June 2014, Bergen,
	Norway: registration open!
Message-ID: <alpine.LRH.2.03.1401201051570.3994@reclus.nhh.no>

The GEOSTAT 2014 Summer School for PhD students and R-sig-geo enthusiasts 
will be held this year at the Norwegian School of Economics (NHH), Bergen, 
Norway in the period 15-22 June 2014 (arrive Sunday to depart Sunday). The 
topics include: spatial and spatio-temporal data and analysis in R, R as a 
GIS, spatial data modelling with raster package, visualization of spatial 
and spatio-temporal data in Google Earth, GRASS GIS and QGIS tutorials, 
and spatio-temporal geostatistics.

This summer school is limited to 50 participants (two parallel sessions). 
Selection of candidates is based on a ranking system, which is based on: 
time of registration, solidarity (participants further away from the venue 
receive higher ranking), academic record, and contributions to open source 
projects. The registration costs for the summer school are typically 
between EUR 300 - 400; these cover the actual costs, no profits are made. 
The organizers provide no funding/scholarships to participants. 
Participants from ODA-listed countries, however, can apply for a 
subsidized price for registration costs.

To register for this summer school please visit the event homepage at:

http://www.geostat-course.org/Bergen_2014

The registration deadline is 1st March 2014.

Lecturers:

* Roger Bivand: Representing and handling spatial and spatio-temporal data
     in R

* Robert Hijmans: Spatial modeling with environmental data (raster and
     dismo packages)

* Edzer Pebesma: Spatial and spatio-temporal statistics with R: an
     introduction

* Barry Rowlingson: QGIS + R tutorial

* Tomislav Hengl: plotKML tutorial (visualization of spatial and
     spatio-temporal data from R to Google Earth)

* Markus Metz: GRASS GIS 7 tutorial / update

* Benedikt Gr?ler: Spatio-temporal geostatistics: choosing and fitting
     models, interpolation (gstat tutorial)


-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From jacqueline.schweizer at wuestundpartner.com  Mon Jan 20 17:00:27 2014
From: jacqueline.schweizer at wuestundpartner.com (Jacqueline Schweizer)
Date: Mon, 20 Jan 2014 17:00:27 +0100
Subject: [R-sig-Geo] SpatialLine from Line-object
Message-ID: <31E5887C-1841-4D31-81EC-04AF35EAC4DD@wuestundpartner.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140120/1cf8ec64/attachment.pl>

From rafael.wueest at gmail.com  Mon Jan 20 17:42:08 2014
From: rafael.wueest at gmail.com (=?ISO-8859-1?Q?Rafael_W=FCest?=)
Date: Mon, 20 Jan 2014 17:42:08 +0100
Subject: [R-sig-Geo] SpatialLine from Line-object
In-Reply-To: <31E5887C-1841-4D31-81EC-04AF35EAC4DD@wuestundpartner.com>
References: <31E5887C-1841-4D31-81EC-04AF35EAC4DD@wuestundpartner.com>
Message-ID: <52DD51E0.2080603@gmail.com>

Hi Jaqueline

t.lines1 <- SpatialLines(list(Lines(t.linelist, ID=1)))

should do it not that in ?SpatialLines

...
SpatialLines(LinesList, proj4string = CRS(as.character(NA)))
...
LinesList is supposed to be a "list with objects of class Lines-class"

HTH,
Rafael


On 20.01.14 17:00, Jacqueline Schweizer wrote:
>
> Hello everybody,
>
> I am trying to make a commuter-map, where lines going from one region to all the surrounding regions represent the amount of commuters by there thickness.
>
> Let's say I do this for region number 1: I create a dataframe with all the coordinate couples of an inner point of region number 1 to the inner points of 2 surrounding regions. then I make a loop, that creates a list containing all the single lines from this point.
>
> Now for my mapping, I'd like to have a SpatialLineDataFrame -> somehow I cannot create a SpatialLine form my Line-object. Firstly I create the list with all the single Line-objects in it. Then I create a Lines-object by just simply adding an ID. For the SpatialLines I seem to need a proj4string-specification? I tried to use one of a different Shapefile, that uses the same coordinate-system etc. but that doesnt work.
>
> I am sure this is a basic problem, can anyone help me?
> Thanks in advance
>
> Jacqueline
>
>
>
>
>
> t.coord <- data.frame(gemvon=c(1,1), gemnach=c(1,2), XCOORD_1= c(682460.5, 682460.5), YCOORD_1=c(248579.4, 248579.4), XCOORD_2 <- c(685766.5, 674783.5), YCOORD_2 <- c(253025.6, 248746.7))
> head(t.coord)
> #  gemvon gemnach XCOORD_1 YCOORD_1 XCOORD_2 YCOORD_2
> #1      1       1 682460.5 248579.4 685766.5 253025.6
> #2      1       2 682460.5 248579.4 674783.5 248746.7
>
>
> # list of single lines (as an example: only two lines)
>
> t.linelist 	<- list()
>
> for (j in 1:2) {
>
> t.linelist[[j]]			<- Line(rbind(c(t.coord[j, 3], t.coord[j, 4]), c(t.coord[j, 5], t.coord[j, 6])) )
> }
>
> t.linelist
>
> [[1]]
> An object of class "Line"
> Slot "coords":
>           [,1]     [,2]
> [1,] 682460.5 248579.4
> [2,] 685766.5 253025.6
>
>
> [[2]]
> An object of class "Line"
> Slot "coords":
>           [,1]     [,2]
> [1,] 682460.5 248579.4
> [2,] 674783.5 248746.7
>
> t.lines1 <- SpatialLines(Lines(t.linelist, ID=1) )
>
> Fehler in as.list.default(X) :
>    Keine Methode um diese S4 Klasse in einen Vektor zu verwandeln
>
>
>
>
>
>
>
> Disclaimer\ \ Die in dieser E-Mail enthaltenen Informati...{{dropped:27}}
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Rafael W?est
rafael.wueest at gmail.com
http://www.rowueest.net


From b.rowlingson at lancaster.ac.uk  Mon Jan 20 17:43:13 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 20 Jan 2014 16:43:13 +0000
Subject: [R-sig-Geo] SpatialLine from Line-object
In-Reply-To: <8cc123d0b1b749a38d4e3a6f8820abba@EX-0-HT0.lancs.local>
References: <8cc123d0b1b749a38d4e3a6f8820abba@EX-0-HT0.lancs.local>
Message-ID: <CANVKczNt_h_dPXMtNki+hda_gNSg9=3-h1+cU49+nT7JcpgvEg@mail.gmail.com>

On Mon, Jan 20, 2014 at 4:00 PM, Jacqueline Schweizer
<jacqueline.schweizer at wuestundpartner.com> wrote:
> t.lines1 <- SpatialLines(Lines(t.linelist, ID=1) )

close! Lacking a list( ) to wrap the Lines:

t.lines1 <- SpatialLines(list(Lines(t.linelist, ID=1) ))

from the help:

Usage:

     SpatialLines(LinesList, proj4string = CRS(as.character(NA)))

LinesList: list with objects of class Lines-class

Barry


From brent.wilson at unb.ca  Mon Jan 20 18:11:54 2014
From: brent.wilson at unb.ca (Brent Wilson)
Date: Mon, 20 Jan 2014 13:11:54 -0400
Subject: [R-sig-Geo] Recalling shapefile attributes to apply to polygons
	using a loop
Message-ID: <CAP3XK_-qFTv3HU8_aNrs8CCDnB0hdjt3zqYF78iqd+APg-tN2g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140120/acc982ec/attachment.pl>

From r.hijmans at gmail.com  Mon Jan 20 21:45:46 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Mon, 20 Jan 2014 12:45:46 -0800
Subject: [R-sig-Geo] Recalling shapefile attributes to apply to polygons
 using a loop
In-Reply-To: <CAP3XK_-qFTv3HU8_aNrs8CCDnB0hdjt3zqYF78iqd+APg-tN2g@mail.gmail.com>
References: <CAP3XK_-qFTv3HU8_aNrs8CCDnB0hdjt3zqYF78iqd+APg-tN2g@mail.gmail.com>
Message-ID: <CANtt_hzW97QEODwQM9RpeKn1Xe=S0Gbot59kRpyJrJa2Xsftdw@mail.gmail.com>

Brent, In your questions to the list, please use reproducible
examples, as below.

# get a SpatialPolygonsDataFrame
library(raster)
p <- shapefile(system.file("external/lux.shp", package="raster"))

# add sample size variable
p$samplingintensity <- ceiling(runif(length(p)) * 10)
head(p)

# sample:
allocation <- sapply(1:length(p), function(i) spsample(p[i,],
n=p$samplingintensity[i], type='random'))


Best, Robert

On Mon, Jan 20, 2014 at 9:11 AM, Brent Wilson <brent.wilson at unb.ca> wrote:
> I have a list of polygons from a shapefile that I'm looping through to
> assign random sampling locations to. In the loop, I wish to access the
> original polygon attributes table to apply a sampling intensity that is
> unique to each polygon (from a column under 'samplingintensity'). Is there
> a way to apply this (e.g., n = polygon$samplingintensity) or are the
> polygon attributes stripped away at this point using the slot function?
>
> # read in polygon shapefile
> strataboundaries <- readOGR('strataboundaries.shp',
> layer='strataboundaries')# allocate samples to polygons
> allocation <- sapply(slot(strataboundaries, 'polygons'), function(i)
> spsample(i, *n=3*, type='random'))
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Mon Jan 20 22:01:41 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Mon, 20 Jan 2014 13:01:41 -0800
Subject: [R-sig-Geo] resampling MODIS-based raster to PRISM raster to
 obtain same extent
In-Reply-To: <1389944893.78524.YahooMailNeo@web124501.mail.ne1.yahoo.com>
References: <1389656388.34766.YahooMailNeo@web124502.mail.ne1.yahoo.com>
	<CANtt_hx33uuecNwSLcyeR4pGsHssnMXU91d1+gW46b3vHVoyXQ@mail.gmail.com>
	<1389944893.78524.YahooMailNeo@web124501.mail.ne1.yahoo.com>
Message-ID: <CANtt_hyeukgbo-QhS9O54kWBvoevo2-X5kPb14w2dyWWzRSW_g@mail.gmail.com>

Julie,

Yes, in that case the projection (coordinate reference system -- CRS)
will be the same. That is sufficient for vector data (points, lines,
polygons), but not for raster data. For raster data you also need to
match the resolution and origin such that the cells are aligned. With
origin I refer to the location nearest to (0, 0) that the edge of a
particular raster could come if only the extent is changed (resolution
is fixed). If origins are not the same, the rasters are not aligned,
and you cannot directly compare values for matching cells (as cells do
not match). Even if two rasters are aligned, you may still need to
crop/expand one or both such that they get exactly the same extent
(bounding box).  resample can come to the rescue here but it is
preferable to avoid it. See the raster package vignette for more info.

I am under the impression that the MRT does not allow you to set an
origin. If that is true, then it is an inadequate tool for changing
the projection of raster data and I would use GDAL instead. On linux
you can have rgdal with HDF5 support, but not on windows. But on
windows you can use command line GDAL (from FWtools)  perhaps via the
new gdalUtils package.

Robert


On Thu, Jan 16, 2014 at 11:48 PM, Julie Lee-Yaw <julleeyaw at yahoo.ca> wrote:
> Hi Robert,
>
> Thanks for the response. I have done a bit more reading but am still
> struggling to understand: if I set the datum (NAD83) and the resolution of
> the NDVI data to match that of the prism data is that not sufficient for
> compatible projections? Does the datum not provide the origin? The extent is
> what I am now trying to adjust (e.g. the NDVI data is for all of North
> America, the PRISM data is for the US only). Or do you mean something else
> by extent?
>
> The prism data has a prj file that reads:
>
> GEOGCS["NAD83",DATUM["D_North_American_1983",SPHEROID["GRS_1980",6378137.0,298.257222101]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]]
>
> Thanks again for the help!
>
> Julie
>
>
>
>
> On Tuesday, January 14, 2014 8:11:01 PM, Robert J. Hijmans
> <r.hijmans at gmail.com> wrote:
> Julie,
> You raise an important question that is often overlooked. While it is
> possible to use resample as you suggest; you would want to avoid it
> because it leads to loss of data quality (although in practice this is
> often minimal and irrelevant).
>
> You state that you "project it to the same geographic coordinate
> system as PRISM precip. data". But that is an incomplete statement for
> raster data. What you need to do is to project the NDVI data to the
> raster definition used by PRISM. That includes the coordinate system,
> but also the origin (or extent) and resolution of that raster. I do
> not think MRT supports setting these parameters; in which case you
> should not use it. You can use GDAL instead. On Linux this can be done
> with rgdal; on windows you can use FWTools instead, or perhaps the new
> gdalUtils package?
>
> Robert
>
> On Mon, Jan 13, 2014 at 3:39 PM, Julie Lee-Yaw <julleeyaw at yahoo.ca> wrote:
>> Hi
>>
>> Using a combination of the scripts provided here (by Babak N.):
>> http://r-gis.net/?q=ModisDownload and the MODIS reproject tool, I've finally
>> managed to download NDVI data for North America and project it to the same
>> geographic coordinate system as PRISM precip. data (e.g.
>> http://www.prism.oregonstate.edu) for the same time period.
>>
>> I now want to stack these two rasters. My NDVI layer has a greater extent
>> than the PRISM layer so I crop the former by the latter using:
>>
>> croppedNDVI<-crop(NDVI,prism)
>>
>>
>> But when I look at the resulting raster, I see that the extent still
>> doesn't line up. I think this is an issue with cells of the two rasters
>> being "off" centre from each other. I can use the following to get them to
>> align:
>>
>> adjustNDVI<-resample(croppedNDVI,prism)
>>
>>
>> Now I can stack the "adjustNDVI" and "prism" layers as the extents match.
>> But I am wondering whether this is valid? Why were the initial rasters
>> misaligned in the first place given that I specified the same resolution and
>> geographic coordinate system/datum when I processed the MODIS file? I'm
>> grateful for any clarification!
>>        [[alternative HTML version deleted]]
>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From r.hijmans at gmail.com  Mon Jan 20 22:15:09 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Mon, 20 Jan 2014 13:15:09 -0800
Subject: [R-sig-Geo] as.raster() does not work for RImageJ objects
In-Reply-To: <CAG4NReKpcnnJMXRpz0mScWogCMoEEdwiuLfqtF3=sgq0vbUJQA@mail.gmail.com>
References: <CAG4NRe+TPNk+Xv9Qwnd2n7LoJofyJ_1VqL_=N4bbt_0AjqJsGg@mail.gmail.com>
	<CAG4NReLA0=6MSse1OT0fR2vFe_hSpddXtPhjiGZdJ+Z0A=wHWA@mail.gmail.com>
	<CAAcGz9_zt-oRd7_-ncjGmSqdNcFb97RH9VeC=74JXN+Tu4bdzg@mail.gmail.com>
	<CAG4NReKpcnnJMXRpz0mScWogCMoEEdwiuLfqtF3=sgq0vbUJQA@mail.gmail.com>
Message-ID: <CANtt_hzPqtxpko0RyWvCyKWO9ZWujrB4pKOh1MSdO67TUhvLDQ@mail.gmail.com>

Agus,

as.raster returns a 'raster' object as defined in the graphics package
(or thereabouts). I assume that what you want is to coerce to a
RasterLayer (from the raster package). That is typically done with

raster(image)
# or
as(image, 'RasterLayer')

Robert



On Fri, Jan 17, 2014 at 5:45 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
> ok, thanks. I did not know that there was another class raster in
> another package.
>
> This means that we cannot convert from RImageJ objects to
> raster::raster objects.
> But we can use RImageJ to process, save to disk and read back as raster:raster:
>
> logo <- system.file( "images", "R.jpg", package = "RImageJ" )
> image = IJ$openImage( logo )
> image$show()
> IJ$run( "8-bit" )
> IJ$run( "Invert" )
> IJ$save( "bw-google.gif" )
> image$close()
>
> r4 <- raster("bw-google.gif")
> plot(r4)
> summary(r4)
> extent(r4)
>
> Hopefully I'll be able to use RImageJ for applying smoothing filters
> and other image processing
> methods that are too slow within R, without having to leave the R
> scripting environment.
>
> Agus
>
> On Fri, Jan 17, 2014 at 9:26 AM, Michael Sumner <mdsumner at gmail.com> wrote:
>> You are see a clash of the grDevices::as.raster with the raster
>> package. grDevices is loaded by default, and has a (S3) method for
>> whatever your image is (a matrix?).
>>
>> It seems like the S4 raster::as.raster should allow these to "pass
>> through" to the underlying S3 method.
>>
>> I can't look any closer right now
>>
>>
>>
>>
>>
>> On Fri, Jan 17, 2014 at 7:09 PM, Agustin Lobo <alobolistas at gmail.com> wrote:
>>> Actually, in OSX, there is no error message at using as.raster(), but
>>> it does not work either:
>>>
>>> r <- as.raster(image)
>>> class(r)
>>>
>>> [1] "raster"
>>>> str(r)
>>> 'raster' chr [1:76, 1:100] "#ffffff" "#ffffff" "#ffffff" "#ffffff"
>>> "#ffffff" "#ffffff" "#ffffff" ...
>>>
>>> which is not the structure a raster object should have.
>>>
>>> Then:
>>>
>>> r <- as.raster.jobjRef(image)
>>> Error: could not find function "as.raster.jobjRef"
>>>
>>> while ?as.raster.jobjRef shows the help page
>>> the function as.raster.jobjRef" is not in the workspace (and this is
>>> also the case in linux):
>>>> search()
>>>  [1] ".GlobalEnv"        "package:RImageJ"   "package:rJava"
>>> "package:raster"    "package:sp"
>>>  [6] "tools:rstudio"     "package:stats"     "package:graphics"
>>> "package:grDevices" "package:utils"
>>> [11] "package:datasets"  "package:methods"   "Autoloads"
>>> "package:base"
>>>> ls(2)
>>> [1] "IJ"              "IJWindowManager" "ImageJ"
>>>
>>>
>>> R version 3.0.2 (2013-09-25)
>>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>>>
>>> locale:
>>>   [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>
>>> attached base packages:
>>>   [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>>   [1] RImageJ_0.2-146 rJava_0.9-6     raster_2.1-66   sp_1.0-13
>>>
>>> loaded via a namespace (and not attached):
>>>   [1] grid_3.0.2      lattice_0.20-23 tools_3.0.2
>>>
>>>
>>> Agus
>>>
>>> On Thu, Jan 16, 2014 at 4:09 PM, Agustin Lobo <alobolistas at gmail.com> wrote:
>>>> Hi!
>>>>
>>>> While the following works fine:
>>>> install.packages("/home/alobo/Downloads/RImageJ_0.2-146.tar.gz", repos
>>>> = NULL, type="source")
>>>> require(RImageJ)
>>>> require(raster)
>>>> logo <- system.file( "images", "R.jpg", package = "RImageJ" )
>>>> image = IJ$openImage( logo )
>>>> class(image)
>>>> plot(c(100, 250), c(300, 450), type = "n", xlab="", ylab="")
>>>> rasterImage(image, 100, 300, 150, 350, interpolate=FALSE)
>>>>
>>>> (note that the example in
>>>> http://romainfrancois.blog.free.fr/index.php?category/R-package/RImageJ
>>>> is currently wrong, it must be rasterImage() and not raster()
>>>>
>>>> But as.raster() (the most important for me) does not work:
>>>>
>>>>> class(image)
>>>> [1] "jobjRef"
>>>> attr(,"package")
>>>> [1] "rJava"
>>>>> r <- as.raster(image)
>>>> Error in as.raster.jobjRef(image) : attempt to apply non-function
>>>>
>>>> see ?as.raster.jobjRef
>>>>
>>>> Any fix?
>>>>
>>>> Thanks
>>>> Agus
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>>
>> --
>> Michael Sumner
>> Hobart, Australia
>> e-mail: mdsumner at gmail.com
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From joshfirth at hotmail.com  Tue Jan 21 08:10:14 2014
From: joshfirth at hotmail.com (buzzfuzz006)
Date: Mon, 20 Jan 2014 23:10:14 -0800 (PST)
Subject: [R-sig-Geo] voronoi (thiessen) polygons inside irregular area
In-Reply-To: <CAGfc75kur4T3SqgZbSjvLjhGUe0cWv3m=krVGfO2c_OevFxkbA@mail.gmail.com>
References: <002d01cebf65$fd57b9b0$f8072d10$@stuba.sk>
	<CAGfc75kur4T3SqgZbSjvLjhGUe0cWv3m=krVGfO2c_OevFxkbA@mail.gmail.com>
Message-ID: <1390288214159-7585593.post@n2.nabble.com>

Hi,
Is there a simple way to draw voronoi/thiessen polygons inside an irregular
polygon similar to this, but where the polygons created do not extend over
the boundaries of the overlaying polygon. E.g
Using the packages

library(spatstat);library(spdep)

If we had set points:

x<-c(0.9,1.7,2.4,2.9,4.83, 0.73, 2.31, 3.69, 4.23, 2.86, 1.91, 4.32, 4.60,
1.82)
y<-c(1.9,0.9,2.8,1.9,1.81, 1.66, 4.54, 5.66, 1.99, 4.03, 4.32, 5.98, 5.56,
3.41)

within the set irregular polygon:

x.p<-c(0.1, 6.0, 6.0, 1.0, 5.0, 3.0, 3.5, 0.1)
y.p<-c(0.1, 1.0, 6.5, 5.5, 5.0, 1.0, 4.8, 5.0)

now I set the polygon to needed dirichlet format

poly.l<-list(x.p,y.p)
names(poly.l)<-c("x","y")

and create the spatial point pattern

poly.w.points<-ppp(x=x,y=y,poly=poly.l)

then carry out the voronoi tessellation

spatstat.options("gpclib"=T)
tess<-dirichlet(poly.w.points)

unfortunately if we are to plot this it looks like this

plot(tess)
text(x,y,1:length(x))

and if we check the neighbours we see that the voronoi polygons extend
outside the polygon area
tess.sp<-as(tess,"SpatialPolygons")
neighs<-poly2nb(tess.sp)

e.g.
neighs[10]
shows that point 10 is neighbours (shares boundary) with 8,9 and 13 ? whilst
I want a result whereby 10 would only be neighbours with 7,11,14 and 3.




--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/voronoi-thiessen-polygons-inside-irregular-area-tp7584761p7585593.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From alobolistas at gmail.com  Tue Jan 21 09:00:22 2014
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 21 Jan 2014 09:00:22 +0100
Subject: [R-sig-Geo] as.raster() does not work for RImageJ objects
In-Reply-To: <CANtt_hzPqtxpko0RyWvCyKWO9ZWujrB4pKOh1MSdO67TUhvLDQ@mail.gmail.com>
References: <CAG4NRe+TPNk+Xv9Qwnd2n7LoJofyJ_1VqL_=N4bbt_0AjqJsGg@mail.gmail.com>
	<CAG4NReLA0=6MSse1OT0fR2vFe_hSpddXtPhjiGZdJ+Z0A=wHWA@mail.gmail.com>
	<CAAcGz9_zt-oRd7_-ncjGmSqdNcFb97RH9VeC=74JXN+Tu4bdzg@mail.gmail.com>
	<CAG4NReKpcnnJMXRpz0mScWogCMoEEdwiuLfqtF3=sgq0vbUJQA@mail.gmail.com>
	<CANtt_hzPqtxpko0RyWvCyKWO9ZWujrB4pKOh1MSdO67TUhvLDQ@mail.gmail.com>
Message-ID: <CAG4NReLDjTsbTy7w13jY9DnUz=L4VshUhdqsz2RRrJZn-y5TRg@mail.gmail.com>

Robert,

Had tried that, sorry I forgot reporting it:
logo <- system.file( "images", "R.jpg", package = "RImageJ" )
image = IJ$openImage( logo )
r2 <- raster(image)

Error in (function (classes, fdef, mtable)  :
  unable to find an inherited method for function ?raster? for
signature ?"jobjRef"?

The workaround I posted is not bad in my current case, in particular because
ImageJ does not deal with image files of >3 bands (AFAIK), and because
I have to process
each band independently anyway (in this particular application).

A much better solution would be connecting the raster package to the
OTB, ITk or openCV
libraries for image processing. I think I'll be able to do some
testing with OTB from within R,
as there is a python API and R and python talk to each other fluently.
There is also some work on integrating ITk within R
http://www.itk.org/Wiki/Proposals:Integration_with_R_Language
which should be useful for doing the same for OTB (which is sort of
ITk derivate for Remote Sensing imagery)
but have not tried myself.

Agus

On Mon, Jan 20, 2014 at 10:15 PM, Robert J. Hijmans <r.hijmans at gmail.com> wrote:
> Agus,
>
> as.raster returns a 'raster' object as defined in the graphics package
> (or thereabouts). I assume that what you want is to coerce to a
> RasterLayer (from the raster package). That is typically done with
>
> raster(image)
> # or
> as(image, 'RasterLayer')
>
> Robert
>
>
>
> On Fri, Jan 17, 2014 at 5:45 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
>> ok, thanks. I did not know that there was another class raster in
>> another package.
>>
>> This means that we cannot convert from RImageJ objects to
>> raster::raster objects.
>> But we can use RImageJ to process, save to disk and read back as raster:raster:
>>
>> logo <- system.file( "images", "R.jpg", package = "RImageJ" )
>> image = IJ$openImage( logo )
>> image$show()
>> IJ$run( "8-bit" )
>> IJ$run( "Invert" )
>> IJ$save( "bw-google.gif" )
>> image$close()
>>
>> r4 <- raster("bw-google.gif")
>> plot(r4)
>> summary(r4)
>> extent(r4)
>>
>> Hopefully I'll be able to use RImageJ for applying smoothing filters
>> and other image processing
>> methods that are too slow within R, without having to leave the R
>> scripting environment.
>>
>> Agus
>>
>> On Fri, Jan 17, 2014 at 9:26 AM, Michael Sumner <mdsumner at gmail.com> wrote:
>>> You are see a clash of the grDevices::as.raster with the raster
>>> package. grDevices is loaded by default, and has a (S3) method for
>>> whatever your image is (a matrix?).
>>>
>>> It seems like the S4 raster::as.raster should allow these to "pass
>>> through" to the underlying S3 method.
>>>
>>> I can't look any closer right now
>>>
>>>
>>>
>>>
>>>
>>> On Fri, Jan 17, 2014 at 7:09 PM, Agustin Lobo <alobolistas at gmail.com> wrote:
>>>> Actually, in OSX, there is no error message at using as.raster(), but
>>>> it does not work either:
>>>>
>>>> r <- as.raster(image)
>>>> class(r)
>>>>
>>>> [1] "raster"
>>>>> str(r)
>>>> 'raster' chr [1:76, 1:100] "#ffffff" "#ffffff" "#ffffff" "#ffffff"
>>>> "#ffffff" "#ffffff" "#ffffff" ...
>>>>
>>>> which is not the structure a raster object should have.
>>>>
>>>> Then:
>>>>
>>>> r <- as.raster.jobjRef(image)
>>>> Error: could not find function "as.raster.jobjRef"
>>>>
>>>> while ?as.raster.jobjRef shows the help page
>>>> the function as.raster.jobjRef" is not in the workspace (and this is
>>>> also the case in linux):
>>>>> search()
>>>>  [1] ".GlobalEnv"        "package:RImageJ"   "package:rJava"
>>>> "package:raster"    "package:sp"
>>>>  [6] "tools:rstudio"     "package:stats"     "package:graphics"
>>>> "package:grDevices" "package:utils"
>>>> [11] "package:datasets"  "package:methods"   "Autoloads"
>>>> "package:base"
>>>>> ls(2)
>>>> [1] "IJ"              "IJWindowManager" "ImageJ"
>>>>
>>>>
>>>> R version 3.0.2 (2013-09-25)
>>>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>>>>
>>>> locale:
>>>>   [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>>>
>>>> attached base packages:
>>>>   [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>> other attached packages:
>>>>   [1] RImageJ_0.2-146 rJava_0.9-6     raster_2.1-66   sp_1.0-13
>>>>
>>>> loaded via a namespace (and not attached):
>>>>   [1] grid_3.0.2      lattice_0.20-23 tools_3.0.2
>>>>
>>>>
>>>> Agus
>>>>
>>>> On Thu, Jan 16, 2014 at 4:09 PM, Agustin Lobo <alobolistas at gmail.com> wrote:
>>>>> Hi!
>>>>>
>>>>> While the following works fine:
>>>>> install.packages("/home/alobo/Downloads/RImageJ_0.2-146.tar.gz", repos
>>>>> = NULL, type="source")
>>>>> require(RImageJ)
>>>>> require(raster)
>>>>> logo <- system.file( "images", "R.jpg", package = "RImageJ" )
>>>>> image = IJ$openImage( logo )
>>>>> class(image)
>>>>> plot(c(100, 250), c(300, 450), type = "n", xlab="", ylab="")
>>>>> rasterImage(image, 100, 300, 150, 350, interpolate=FALSE)
>>>>>
>>>>> (note that the example in
>>>>> http://romainfrancois.blog.free.fr/index.php?category/R-package/RImageJ
>>>>> is currently wrong, it must be rasterImage() and not raster()
>>>>>
>>>>> But as.raster() (the most important for me) does not work:
>>>>>
>>>>>> class(image)
>>>>> [1] "jobjRef"
>>>>> attr(,"package")
>>>>> [1] "rJava"
>>>>>> r <- as.raster(image)
>>>>> Error in as.raster.jobjRef(image) : attempt to apply non-function
>>>>>
>>>>> see ?as.raster.jobjRef
>>>>>
>>>>> Any fix?
>>>>>
>>>>> Thanks
>>>>> Agus
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>>
>>> --
>>> Michael Sumner
>>> Hobart, Australia
>>> e-mail: mdsumner at gmail.com
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From alobolistas at gmail.com  Tue Jan 21 09:03:03 2014
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 21 Jan 2014 09:03:03 +0100
Subject: [R-sig-Geo] resampling MODIS-based raster to PRISM raster to
 obtain same extent
In-Reply-To: <CANtt_hyeukgbo-QhS9O54kWBvoevo2-X5kPb14w2dyWWzRSW_g@mail.gmail.com>
References: <1389656388.34766.YahooMailNeo@web124502.mail.ne1.yahoo.com>
	<CANtt_hx33uuecNwSLcyeR4pGsHssnMXU91d1+gW46b3vHVoyXQ@mail.gmail.com>
	<1389944893.78524.YahooMailNeo@web124501.mail.ne1.yahoo.com>
	<CANtt_hyeukgbo-QhS9O54kWBvoevo2-X5kPb14w2dyWWzRSW_g@mail.gmail.com>
Message-ID: <CAG4NReJA1cNs2DabtEyWjSnbEiO=m7ndaC0dtzmYo3f6us8S-w@mail.gmail.com>

Another option would be doing it through grass commands.
Agus

On Mon, Jan 20, 2014 at 10:01 PM, Robert J. Hijmans <r.hijmans at gmail.com> wrote:
> Julie,
>
> Yes, in that case the projection (coordinate reference system -- CRS)
> will be the same. That is sufficient for vector data (points, lines,
> polygons), but not for raster data. For raster data you also need to
> match the resolution and origin such that the cells are aligned. With
> origin I refer to the location nearest to (0, 0) that the edge of a
> particular raster could come if only the extent is changed (resolution
> is fixed). If origins are not the same, the rasters are not aligned,
> and you cannot directly compare values for matching cells (as cells do
> not match). Even if two rasters are aligned, you may still need to
> crop/expand one or both such that they get exactly the same extent
> (bounding box).  resample can come to the rescue here but it is
> preferable to avoid it. See the raster package vignette for more info.
>
> I am under the impression that the MRT does not allow you to set an
> origin. If that is true, then it is an inadequate tool for changing
> the projection of raster data and I would use GDAL instead. On linux
> you can have rgdal with HDF5 support, but not on windows. But on
> windows you can use command line GDAL (from FWtools)  perhaps via the
> new gdalUtils package.
>
> Robert
>
>
> On Thu, Jan 16, 2014 at 11:48 PM, Julie Lee-Yaw <julleeyaw at yahoo.ca> wrote:
>> Hi Robert,
>>
>> Thanks for the response. I have done a bit more reading but am still
>> struggling to understand: if I set the datum (NAD83) and the resolution of
>> the NDVI data to match that of the prism data is that not sufficient for
>> compatible projections? Does the datum not provide the origin? The extent is
>> what I am now trying to adjust (e.g. the NDVI data is for all of North
>> America, the PRISM data is for the US only). Or do you mean something else
>> by extent?
>>
>> The prism data has a prj file that reads:
>>
>> GEOGCS["NAD83",DATUM["D_North_American_1983",SPHEROID["GRS_1980",6378137.0,298.257222101]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]]
>>
>> Thanks again for the help!
>>
>> Julie
>>
>>
>>
>>
>> On Tuesday, January 14, 2014 8:11:01 PM, Robert J. Hijmans
>> <r.hijmans at gmail.com> wrote:
>> Julie,
>> You raise an important question that is often overlooked. While it is
>> possible to use resample as you suggest; you would want to avoid it
>> because it leads to loss of data quality (although in practice this is
>> often minimal and irrelevant).
>>
>> You state that you "project it to the same geographic coordinate
>> system as PRISM precip. data". But that is an incomplete statement for
>> raster data. What you need to do is to project the NDVI data to the
>> raster definition used by PRISM. That includes the coordinate system,
>> but also the origin (or extent) and resolution of that raster. I do
>> not think MRT supports setting these parameters; in which case you
>> should not use it. You can use GDAL instead. On Linux this can be done
>> with rgdal; on windows you can use FWTools instead, or perhaps the new
>> gdalUtils package?
>>
>> Robert
>>
>> On Mon, Jan 13, 2014 at 3:39 PM, Julie Lee-Yaw <julleeyaw at yahoo.ca> wrote:
>>> Hi
>>>
>>> Using a combination of the scripts provided here (by Babak N.):
>>> http://r-gis.net/?q=ModisDownload and the MODIS reproject tool, I've finally
>>> managed to download NDVI data for North America and project it to the same
>>> geographic coordinate system as PRISM precip. data (e.g.
>>> http://www.prism.oregonstate.edu) for the same time period.
>>>
>>> I now want to stack these two rasters. My NDVI layer has a greater extent
>>> than the PRISM layer so I crop the former by the latter using:
>>>
>>> croppedNDVI<-crop(NDVI,prism)
>>>
>>>
>>> But when I look at the resulting raster, I see that the extent still
>>> doesn't line up. I think this is an issue with cells of the two rasters
>>> being "off" centre from each other. I can use the following to get them to
>>> align:
>>>
>>> adjustNDVI<-resample(croppedNDVI,prism)
>>>
>>>
>>> Now I can stack the "adjustNDVI" and "prism" layers as the extents match.
>>> But I am wondering whether this is valid? Why were the initial rasters
>>> misaligned in the first place given that I specified the same resolution and
>>> geographic coordinate system/datum when I processed the MODIS file? I'm
>>> grateful for any clarification!
>>>        [[alternative HTML version deleted]]
>>>
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From julleeyaw at yahoo.ca  Tue Jan 21 14:42:31 2014
From: julleeyaw at yahoo.ca (Julie Lee-Yaw)
Date: Tue, 21 Jan 2014 05:42:31 -0800 (PST)
Subject: [R-sig-Geo] resampling MODIS-based raster to PRISM raster to
	obtain same extent
In-Reply-To: <CAG4NReJA1cNs2DabtEyWjSnbEiO=m7ndaC0dtzmYo3f6us8S-w@mail.gmail.com>
References: <1389656388.34766.YahooMailNeo@web124502.mail.ne1.yahoo.com>	<CANtt_hx33uuecNwSLcyeR4pGsHssnMXU91d1+gW46b3vHVoyXQ@mail.gmail.com>	<1389944893.78524.YahooMailNeo@web124501.mail.ne1.yahoo.com>	<CANtt_hyeukgbo-QhS9O54kWBvoevo2-X5kPb14w2dyWWzRSW_g@mail.gmail.com>
	<CAG4NReJA1cNs2DabtEyWjSnbEiO=m7ndaC0dtzmYo3f6us8S-w@mail.gmail.com>
Message-ID: <1390311751.63652.YahooMailNeo@web124504.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140121/f27895a4/attachment.pl>

From r.hijmans at gmail.com  Tue Jan 21 17:32:53 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 21 Jan 2014 08:32:53 -0800
Subject: [R-sig-Geo] resampling MODIS-based raster to PRISM raster to
 obtain same extent
In-Reply-To: <1390311751.63652.YahooMailNeo@web124504.mail.ne1.yahoo.com>
References: <1389656388.34766.YahooMailNeo@web124502.mail.ne1.yahoo.com>
	<CANtt_hx33uuecNwSLcyeR4pGsHssnMXU91d1+gW46b3vHVoyXQ@mail.gmail.com>
	<1389944893.78524.YahooMailNeo@web124501.mail.ne1.yahoo.com>
	<CANtt_hyeukgbo-QhS9O54kWBvoevo2-X5kPb14w2dyWWzRSW_g@mail.gmail.com>
	<CAG4NReJA1cNs2DabtEyWjSnbEiO=m7ndaC0dtzmYo3f6us8S-w@mail.gmail.com>
	<1390311751.63652.YahooMailNeo@web124504.mail.ne1.yahoo.com>
Message-ID: <CANtt_hwyC8ir_uctwTwBhCJDp21j-DfdnJ5RWPOuNaxGa=adYw@mail.gmail.com>

Julie,
I think you had the PRISM and MODIS data in the same projection right?
At that point you can use resample in the raster package (or
elsewhere) to line one up with the other. That is what most people do.
Robert

On Tue, Jan 21, 2014 at 5:42 AM, Julie Lee-Yaw <julleeyaw at yahoo.ca> wrote:
> Thank you Agus and Robert for the suggestions. Unfortunately, I'm a little
> intimidated by GRASS and rgdal. I've had no experience with GRASS and very
> little experience with rgdal. Are there any examples you can point me to for
> the specific exercise of reprojecting raster data? I'm an absolute beginner
> here.
>
> Furthermore, the trick with the MODIS data is that the original downloaded
> data is in hdf format (which the raster package can't read?not sure about
> rgdal). Given this issue, I'm wondering if my strategy should be to
> initially reproject and save the MODIS data as geoTiff using the MRT tool
> and then use rgdal or GRASS to finish the job (e.g. specify the original
> reference system and then reproject to the parameters of the PRISM data)?
> Here I'm not even sure how to find information on the native origin of the
> MODIS files?I don't see anything in the MRT documentation about what the
> origin gets set to (you are right Robert?there  isn't an option for setting
> this so it must be doing it automatically).
>
> The PRISM data files only come with the following info in the prj file:
>
> GEOGCS["NAD83",DATUM["D_North_American_1983",SPHEROID["GRS_1980",6378137.0,298.257222101]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]]
>
> Is the PRIMEM["Greenwich", 0.0] specifying the origin in this case? Is
> origin the same as reference coordinate?
>
> Finally, in case it is relevant, both the PRISM and the MODIS rasters (after
> directly projecting using the MRT tool) give the following as the coord
> reference (and have the same resolutions)?
>
> R +proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0
>
> The extents on the other hand are different.
>
> Thanks again for the continued help! It is much appreciated!
>
> Julie
>
>
>
>
> On Tuesday, January 21, 2014 9:03:03 AM, Agustin Lobo
> <alobolistas at gmail.com> wrote:
> Another option would be doing it through grass commands.
> Agus
>
> On Mon, Jan 20, 2014 at 10:01 PM, Robert J. Hijmans <r.hijmans at gmail.com>
> wrote:
>> Julie,
>>
>> Yes, in that case the projection (coordinate reference system -- CRS)
>> will be the same. That is sufficient for vector data (points, lines,
>> polygons), but not for raster data. For raster data you also need to
>> match the resolution and origin such that the cells are aligned. With
>> origin I refer to the location nearest to (0, 0) that the edge of a
>> particular raster could come if only the extent is changed (resolution
>> is fixed). If origins are not the same, the rasters are not aligned,
>> and you cannot directly compare values for matching cells (as cells do
>> not match). Even if two rasters are aligned, you may still need to
>> crop/expand one or both such that they get exactly the same extent
>> (bounding box).  resample can come to the rescue here but it is
>> preferable to avoid it. See the raster package vignette for more info.
>>
>> I am under the impression that the MRT does not allow you to set an
>> origin. If that is true, then it is an inadequate tool for changing
>> the projection of raster data and I would use GDAL instead. On linux
>> you can have rgdal with HDF5 support, but not on windows. But on
>> windows you can use command line GDAL (from FWtools)  perhaps via the
>> new gdalUtils package.
>>
>> Robert
>>
>>
>> On Thu, Jan 16, 2014 at 11:48 PM, Julie Lee-Yaw <julleeyaw at yahoo.ca>
>> wrote:
>>> Hi Robert,
>>>
>>> Thanks for the response. I have done a bit more reading but am still
>>> struggling to understand: if I set the datum (NAD83) and the resolution
>>> of
>>> the NDVI data to match that of the prism data is that not sufficient for
>>> compatible projections? Does the datum not provide the origin? The extent
>>> is
>>> what I am now trying to adjust (e.g. the NDVI data is for all of North
>>> America, the PRISM data is for the US only). Or do you mean something
>>> else
>>> by extent?
>>>
>>> The prism data has a prj file that reads:
>>>
>>>
>>> GEOGCS["NAD83",DATUM["D_North_American_1983",SPHEROID["GRS_1980",6378137.0,298.257222101]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]]
>>>
>>> Thanks again for the help!
>>>
>>> Julie
>>>
>>>
>>>
>>>
>>> On Tuesday, January 14, 2014 8:11:01 PM, Robert J. Hijmans
>>> <r.hijmans at gmail.com> wrote:
>>> Julie,
>>> You raise an important question that is often overlooked. While it is
>>> possible to use resample as you suggest; you would want to avoid it
>>> because it leads to loss of data quality (although in practice this is
>>> often minimal and irrelevant).
>>>
>>> You state that you "project it to the same geographic coordinate
>>> system as PRISM precip. data". But that is an incomplete statement for
>>> raster data. What you need to do is to project the NDVI data to the
>>> raster definition used by PRISM. That includes the coordinate system,
>>> but also the origin (or extent) and resolution of that raster. I do
>>> not think MRT supports setting these parameters; in which case you
>>> should not use it. You can use GDAL instead. On Linux this can be done
>>> with rgdal; on windows you can use FWTools instead, or perhaps the new
>>> gdalUtils package?
>>>
>>> Robert
>>>
>>> On Mon, Jan 13, 2014 at 3:39 PM, Julie Lee-Yaw <julleeyaw at yahoo.ca>
>>> wrote:
>>>> Hi
>>>>
>>>> Using a combination of the scripts provided here (by Babak N.):
>>>> http://r-gis.net/?q=ModisDownload and the MODIS reproject tool, I've
>>>> finally
>>>> managed to download NDVI data for North America and project it to the
>>>> same
>>>> geographic coordinate system as PRISM precip. data (e.g.
>>>> http://www.prism.oregonstate.edu) for the same time period.
>>>>
>>>> I now want to stack these two rasters. My NDVI layer has a greater
>>>> extent
>>>> than the PRISM layer so I crop the former by the latter using:
>>>>
>>>> croppedNDVI<-crop(NDVI,prism)
>>>>
>>>>
>>>> But when I look at the resulting raster, I see that the extent still
>>>> doesn't line up. I think this is an issue with cells of the two rasters
>>>> being "off" centre from each other. I can use the following to get them
>>>> to
>>>> align:
>>>>
>>>> adjustNDVI<-resample(croppedNDVI,prism)
>>>>
>>>>
>>>> Now I can stack the "adjustNDVI" and "prism" layers as the extents
>>>> match.
>>>> But I am wondering whether this is valid? Why were the initial rasters
>>>> misaligned in the first place given that I specified the same resolution
>>>> and
>>>> geographic coordinate system/datum when I processed the MODIS file? I'm
>>>> grateful for any clarification!
>>>>        [[alternative HTML version deleted]]
>>>>
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>>>>
>>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From jgrn at illinois.edu  Tue Jan 21 17:40:40 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Tue, 21 Jan 2014 10:40:40 -0600
Subject: [R-sig-Geo] resampling MODIS-based raster to PRISM raster to
 obtain same extent
In-Reply-To: <1390311751.63652.YahooMailNeo@web124504.mail.ne1.yahoo.com>
References: <1389656388.34766.YahooMailNeo@web124502.mail.ne1.yahoo.com>
	<CANtt_hx33uuecNwSLcyeR4pGsHssnMXU91d1+gW46b3vHVoyXQ@mail.gmail.com>
	<1389944893.78524.YahooMailNeo@web124501.mail.ne1.yahoo.com>
	<CANtt_hyeukgbo-QhS9O54kWBvoevo2-X5kPb14w2dyWWzRSW_g@mail.gmail.com>
	<CAG4NReJA1cNs2DabtEyWjSnbEiO=m7ndaC0dtzmYo3f6us8S-w@mail.gmail.com>
	<1390311751.63652.YahooMailNeo@web124504.mail.ne1.yahoo.com>
Message-ID: <CABG0rftBL9OoRs0eaPt0fToy7EBDU4Wn1X5_mCWSwDiSWKREmw@mail.gmail.com>

Julie:

First off, what you are attempting to do is a bit complicated, so try
to not be intimidated!

Second: it might help to understand that HDF files aren't rasters,
persay, they are scientific data "containers" that can CONTAIN raster
files.  So, often the first step is to extract the raster subcomponent
of the HDF file into something more usable.

As Robert mentioned, I have a package designed to make this quite a
bit easier.  First, install a GDAL release that supports HDF4/5 from
http://trac.osgeo.org/gdal/wiki/DownloadingGdalBinaries.  On Windows,
this is Osgeo4w.  On Mac this is the Kyngesburye GDAL Frameworks.

Next:

install.packages("gdalUtils", repos="http://R-Forge.R-project.org")
# Note that I'm suggesting the r-forge version which has some key
fixes vs. the CRAN version

Third, you now can run the utilities.  You want to figure out which
subset to extract first using:
library("gdalUtils")
?get_subdatasets
get_subdatasets("pathto/my.hdf") # Look at the examples of this function
# This will return a list of subdatasets.  Make note of the number of
the one you want.

# Now, you can extract that subdataset to any format you want via
gdal_translate:
?gdal_translate
my_hdf_to_tiff <-
gdal_translate("pathto/my.hdf","my_modis_extracted.tif",sd_index=X,output_raster=TRUE)
# Where X is the number of the subdataset you got from get_subdatasets()

# Finally, to sync all the files to the same projection, you can use
my other package "spatial.tools"
install.packages("spatial.tools")
library("spatial.tools")
# And use spatial_sync_raster
?spatial_sync_raster

This function takes two inputs, "unsynced" (the file you are going to
reproject/extend/crop) and "reference" (the file that serves as the
reference projection, resolution, and extent).  Check the parameters
to understand which resampling it will use.

This puts a bunch of steps together in one: reprojection, resampling,
cropping, and expanding the raster.  The final product will be the
unsynced file that will exactly match the projection, extent and pixel
size of the reference.

Hope this helps!

--j

On Tue, Jan 21, 2014 at 7:42 AM, Julie Lee-Yaw <julleeyaw at yahoo.ca> wrote:
> Thank you Agus and Robert for the suggestions. Unfortunately, I'm a little intimidated by GRASS and rgdal. I've had no experience with GRASS and very little experience with rgdal. Are there any examples you can point me to for the specific exercise of reprojecting raster data? I'm an absolute beginner here.
>
> Furthermore, the trick with the MODIS data is that the original downloaded data is in hdf format (which the raster package can't read?not sure about rgdal). Given this issue, I'm wondering if my strategy should be to initially reproject and save the MODIS data as geoTiff using the MRT tool and then use rgdal or GRASS to finish the job (e.g. specify the original reference system and then reproject to the parameters of the PRISM data)? Here I'm not even sure how to find information on the native origin of the MODIS files?I don't see anything in the MRT documentation about what the origin gets set to (you are right Robert?there  isn't an option for setting this so it must be doing it automatically).
>
> The PRISM data files only come with the following info in the prj file:
>
> GEOGCS["NAD83",DATUM["D_North_American_1983",SPHEROID["GRS_1980",6378137.0,298.257222101]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]]
>
> Is the PRIMEM["Greenwich", 0.0] specifying the origin in this case? Is origin the same as reference coordinate?
>
> Finally, in case it is relevant, both the PRISM and the MODIS rasters (after directly projecting using the MRT tool) give the following as the coord reference (and have the same resolutions)?
>
> R +proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0
>
>
> The extents on the other hand are different.
>
> Thanks again for the continued help! It is much appreciated!
>
> Julie
>
>
>
>
>
> On Tuesday, January 21, 2014 9:03:03 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
>
> Another option would be doing it through grass commands.
> Agus
>
> On Mon, Jan 20, 2014 at 10:01 PM, Robert J. Hijmans <r.hijmans at gmail.com> wrote:
>> Julie,
>>
>> Yes, in that case the projection (coordinate reference system -- CRS)
>> will be the same. That is sufficient for vector data (points, lines,
>> polygons), but not for raster data. For raster data you also need to
>> match the resolution and origin such that the cells are aligned. With
>> origin I refer to the location nearest to (0, 0) that the edge of a
>> particular raster could come if only the extent is changed (resolution
>> is fixed). If origins are not the same, the rasters are not aligned,
>> and you cannot directly compare values for matching cells (as cells do
>> not match). Even if two rasters are aligned, you may still need to
>> crop/expand one or both such that they get exactly the same extent
>> (bounding box).  resample can come to the rescue here but it is
>> preferable to avoid it. See the raster package vignette for more info.
>>
>> I am under the impression that the MRT does not allow you to set an
>> origin. If that is true, then it is an inadequate tool for changing
>> the projection of raster data and I would use GDAL instead. On linux
>> you can have rgdal with HDF5 support, but not on windows. But on
>> windows you can use command line GDAL (from FWtools)  perhaps via the
>> new gdalUtils package.
>>
>> Robert
>>
>>
>> On Thu, Jan 16, 2014 at 11:48 PM, Julie Lee-Yaw <julleeyaw at yahoo.ca> wrote:
>>> Hi Robert,
>>>
>>> Thanks for the response. I have done a bit more reading but am still
>>> struggling to understand: if I set the datum (NAD83) and the resolution of
>>> the NDVI data to match that of the prism data is that not sufficient for
>>> compatible projections? Does the datum not provide the origin? The extent is
>>> what I am now trying to adjust (e.g. the NDVI data is for all of North
>>> America, the PRISM data is for the US only). Or do you mean something else
>>> by extent?
>>>
>>> The prism data has a prj file that reads:
>>>
>>> GEOGCS["NAD83",DATUM["D_North_American_1983",SPHEROID["GRS_1980",6378137.0,298.257222101]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]]
>>>
>>> Thanks again for the help!
>>>
>>> Julie
>>>
>>>
>>>
>>>
>>> On Tuesday, January 14, 2014 8:11:01 PM, Robert J. Hijmans
>>> <r.hijmans at gmail.com> wrote:
>>> Julie,
>>> You raise an important question that is often overlooked. While it is
>>> possible to use resample as you suggest; you would want to avoid it
>>> because it leads to loss of data quality (although in practice this is
>>> often minimal and irrelevant).
>>>
>>> You state that you "project it to the same geographic coordinate
>>> system as PRISM precip. data". But that is an incomplete statement for
>>> raster data. What you need to do is to project the NDVI data to the
>>> raster definition used by PRISM. That includes the coordinate system,
>>> but also the origin (or extent) and resolution of that raster. I do
>>> not think MRT supports setting these parameters; in which case you
>>> should not use it. You can use GDAL instead. On Linux this can be done
>>> with rgdal; on windows you can use FWTools instead, or perhaps the new
>>> gdalUtils package?
>>>
>>> Robert
>>>
>>> On Mon, Jan 13, 2014 at 3:39 PM, Julie Lee-Yaw <julleeyaw at yahoo.ca> wrote:
>>>> Hi
>>>>
>>>> Using a combination of the scripts provided here (by Babak N.):
>>>> http://r-gis.net/?q=ModisDownload and the MODIS reproject tool, I've finally
>>>> managed to download NDVI data for North America and project it to the same
>>>> geographic coordinate system as PRISM precip. data (e.g.
>>>> http://www.prism.oregonstate.edu) for the same time period.
>>>>
>>>> I now want to stack these two rasters. My NDVI layer has a greater extent
>>>> than the PRISM layer so I crop the former by the latter using:
>>>>
>>>> croppedNDVI<-crop(NDVI,prism)
>>>>
>>>>
>>>> But when I look at the resulting raster, I see that the extent still
>>>> doesn't line up. I think this is an issue with cells of the two rasters
>>>> being "off" centre from each other. I can use the following to get them to
>>>> align:
>>>>
>>>> adjustNDVI<-resample(croppedNDVI,prism)
>>>>
>>>>
>>>> Now I can stack the "adjustNDVI" and "prism" layers as the extents match.
>>>> But I am wondering whether this is valid? Why were the initial rasters
>>>> misaligned in the first place given that I specified the same resolution and
>>>> geographic coordinate system/datum when I processed the MODIS file? I'm
>>>> grateful for any clarification!
>>>>        [[alternative HTML version deleted]]
>>>>
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>>>>
>>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From tea3rd at gmail.com  Tue Jan 21 17:55:00 2014
From: tea3rd at gmail.com (Thomas Adams)
Date: Tue, 21 Jan 2014 11:55:00 -0500
Subject: [R-sig-Geo] resampling MODIS-based raster to PRISM raster to
 obtain same extent
In-Reply-To: <1390311751.63652.YahooMailNeo@web124504.mail.ne1.yahoo.com>
References: <1389656388.34766.YahooMailNeo@web124502.mail.ne1.yahoo.com>
	<CANtt_hx33uuecNwSLcyeR4pGsHssnMXU91d1+gW46b3vHVoyXQ@mail.gmail.com>
	<1389944893.78524.YahooMailNeo@web124501.mail.ne1.yahoo.com>
	<CANtt_hyeukgbo-QhS9O54kWBvoevo2-X5kPb14w2dyWWzRSW_g@mail.gmail.com>
	<CAG4NReJA1cNs2DabtEyWjSnbEiO=m7ndaC0dtzmYo3f6us8S-w@mail.gmail.com>
	<1390311751.63652.YahooMailNeo@web124504.mail.ne1.yahoo.com>
Message-ID: <CAGxgkWjaoKUYq_rZ=fx1H-+dJsjwJ=vewt4Ra4y2LD8NuAFfjg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140121/e6ebe0ac/attachment.pl>

From r.hijmans at gmail.com  Tue Jan 21 18:04:15 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 21 Jan 2014 09:04:15 -0800
Subject: [R-sig-Geo] resampling MODIS-based raster to PRISM raster to
 obtain same extent
In-Reply-To: <CABG0rftBL9OoRs0eaPt0fToy7EBDU4Wn1X5_mCWSwDiSWKREmw@mail.gmail.com>
References: <1389656388.34766.YahooMailNeo@web124502.mail.ne1.yahoo.com>
	<CANtt_hx33uuecNwSLcyeR4pGsHssnMXU91d1+gW46b3vHVoyXQ@mail.gmail.com>
	<1389944893.78524.YahooMailNeo@web124501.mail.ne1.yahoo.com>
	<CANtt_hyeukgbo-QhS9O54kWBvoevo2-X5kPb14w2dyWWzRSW_g@mail.gmail.com>
	<CAG4NReJA1cNs2DabtEyWjSnbEiO=m7ndaC0dtzmYo3f6us8S-w@mail.gmail.com>
	<1390311751.63652.YahooMailNeo@web124504.mail.ne1.yahoo.com>
	<CABG0rftBL9OoRs0eaPt0fToy7EBDU4Wn1X5_mCWSwDiSWKREmw@mail.gmail.com>
Message-ID: <CANtt_hzW-26tq1VnSXg5ibLssr+_h=uJUj9U5vkLoE3TxRUcrQ@mail.gmail.com>

I think it would make more sense to use gdalwarp here, as you would be
done in one step (projection, resolution, and extent). Robert

On Tue, Jan 21, 2014 at 8:40 AM, Jonathan Greenberg <jgrn at illinois.edu> wrote:
> Julie:
>
> First off, what you are attempting to do is a bit complicated, so try
> to not be intimidated!
>
> Second: it might help to understand that HDF files aren't rasters,
> persay, they are scientific data "containers" that can CONTAIN raster
> files.  So, often the first step is to extract the raster subcomponent
> of the HDF file into something more usable.
>
> As Robert mentioned, I have a package designed to make this quite a
> bit easier.  First, install a GDAL release that supports HDF4/5 from
> http://trac.osgeo.org/gdal/wiki/DownloadingGdalBinaries.  On Windows,
> this is Osgeo4w.  On Mac this is the Kyngesburye GDAL Frameworks.
>
> Next:
>
> install.packages("gdalUtils", repos="http://R-Forge.R-project.org")
> # Note that I'm suggesting the r-forge version which has some key
> fixes vs. the CRAN version
>
> Third, you now can run the utilities.  You want to figure out which
> subset to extract first using:
> library("gdalUtils")
> ?get_subdatasets
> get_subdatasets("pathto/my.hdf") # Look at the examples of this function
> # This will return a list of subdatasets.  Make note of the number of
> the one you want.
>
> # Now, you can extract that subdataset to any format you want via
> gdal_translate:
> ?gdal_translate
> my_hdf_to_tiff <-
> gdal_translate("pathto/my.hdf","my_modis_extracted.tif",sd_index=X,output_raster=TRUE)
> # Where X is the number of the subdataset you got from get_subdatasets()
>
> # Finally, to sync all the files to the same projection, you can use
> my other package "spatial.tools"
> install.packages("spatial.tools")
> library("spatial.tools")
> # And use spatial_sync_raster
> ?spatial_sync_raster
>
> This function takes two inputs, "unsynced" (the file you are going to
> reproject/extend/crop) and "reference" (the file that serves as the
> reference projection, resolution, and extent).  Check the parameters
> to understand which resampling it will use.
>
> This puts a bunch of steps together in one: reprojection, resampling,
> cropping, and expanding the raster.  The final product will be the
> unsynced file that will exactly match the projection, extent and pixel
> size of the reference.
>
> Hope this helps!
>
> --j
>
> On Tue, Jan 21, 2014 at 7:42 AM, Julie Lee-Yaw <julleeyaw at yahoo.ca> wrote:
>> Thank you Agus and Robert for the suggestions. Unfortunately, I'm a little intimidated by GRASS and rgdal. I've had no experience with GRASS and very little experience with rgdal. Are there any examples you can point me to for the specific exercise of reprojecting raster data? I'm an absolute beginner here.
>>
>> Furthermore, the trick with the MODIS data is that the original downloaded data is in hdf format (which the raster package can't read?not sure about rgdal). Given this issue, I'm wondering if my strategy should be to initially reproject and save the MODIS data as geoTiff using the MRT tool and then use rgdal or GRASS to finish the job (e.g. specify the original reference system and then reproject to the parameters of the PRISM data)? Here I'm not even sure how to find information on the native origin of the MODIS files?I don't see anything in the MRT documentation about what the origin gets set to (you are right Robert?there  isn't an option for setting this so it must be doing it automatically).
>>
>> The PRISM data files only come with the following info in the prj file:
>>
>> GEOGCS["NAD83",DATUM["D_North_American_1983",SPHEROID["GRS_1980",6378137.0,298.257222101]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]]
>>
>> Is the PRIMEM["Greenwich", 0.0] specifying the origin in this case? Is origin the same as reference coordinate?
>>
>> Finally, in case it is relevant, both the PRISM and the MODIS rasters (after directly projecting using the MRT tool) give the following as the coord reference (and have the same resolutions)?
>>
>> R +proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0
>>
>>
>> The extents on the other hand are different.
>>
>> Thanks again for the continued help! It is much appreciated!
>>
>> Julie
>>
>>
>>
>>
>>
>> On Tuesday, January 21, 2014 9:03:03 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
>>
>> Another option would be doing it through grass commands.
>> Agus
>>
>> On Mon, Jan 20, 2014 at 10:01 PM, Robert J. Hijmans <r.hijmans at gmail.com> wrote:
>>> Julie,
>>>
>>> Yes, in that case the projection (coordinate reference system -- CRS)
>>> will be the same. That is sufficient for vector data (points, lines,
>>> polygons), but not for raster data. For raster data you also need to
>>> match the resolution and origin such that the cells are aligned. With
>>> origin I refer to the location nearest to (0, 0) that the edge of a
>>> particular raster could come if only the extent is changed (resolution
>>> is fixed). If origins are not the same, the rasters are not aligned,
>>> and you cannot directly compare values for matching cells (as cells do
>>> not match). Even if two rasters are aligned, you may still need to
>>> crop/expand one or both such that they get exactly the same extent
>>> (bounding box).  resample can come to the rescue here but it is
>>> preferable to avoid it. See the raster package vignette for more info.
>>>
>>> I am under the impression that the MRT does not allow you to set an
>>> origin. If that is true, then it is an inadequate tool for changing
>>> the projection of raster data and I would use GDAL instead. On linux
>>> you can have rgdal with HDF5 support, but not on windows. But on
>>> windows you can use command line GDAL (from FWtools)  perhaps via the
>>> new gdalUtils package.
>>>
>>> Robert
>>>
>>>
>>> On Thu, Jan 16, 2014 at 11:48 PM, Julie Lee-Yaw <julleeyaw at yahoo.ca> wrote:
>>>> Hi Robert,
>>>>
>>>> Thanks for the response. I have done a bit more reading but am still
>>>> struggling to understand: if I set the datum (NAD83) and the resolution of
>>>> the NDVI data to match that of the prism data is that not sufficient for
>>>> compatible projections? Does the datum not provide the origin? The extent is
>>>> what I am now trying to adjust (e.g. the NDVI data is for all of North
>>>> America, the PRISM data is for the US only). Or do you mean something else
>>>> by extent?
>>>>
>>>> The prism data has a prj file that reads:
>>>>
>>>> GEOGCS["NAD83",DATUM["D_North_American_1983",SPHEROID["GRS_1980",6378137.0,298.257222101]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]]
>>>>
>>>> Thanks again for the help!
>>>>
>>>> Julie
>>>>
>>>>
>>>>
>>>>
>>>> On Tuesday, January 14, 2014 8:11:01 PM, Robert J. Hijmans
>>>> <r.hijmans at gmail.com> wrote:
>>>> Julie,
>>>> You raise an important question that is often overlooked. While it is
>>>> possible to use resample as you suggest; you would want to avoid it
>>>> because it leads to loss of data quality (although in practice this is
>>>> often minimal and irrelevant).
>>>>
>>>> You state that you "project it to the same geographic coordinate
>>>> system as PRISM precip. data". But that is an incomplete statement for
>>>> raster data. What you need to do is to project the NDVI data to the
>>>> raster definition used by PRISM. That includes the coordinate system,
>>>> but also the origin (or extent) and resolution of that raster. I do
>>>> not think MRT supports setting these parameters; in which case you
>>>> should not use it. You can use GDAL instead. On Linux this can be done
>>>> with rgdal; on windows you can use FWTools instead, or perhaps the new
>>>> gdalUtils package?
>>>>
>>>> Robert
>>>>
>>>> On Mon, Jan 13, 2014 at 3:39 PM, Julie Lee-Yaw <julleeyaw at yahoo.ca> wrote:
>>>>> Hi
>>>>>
>>>>> Using a combination of the scripts provided here (by Babak N.):
>>>>> http://r-gis.net/?q=ModisDownload and the MODIS reproject tool, I've finally
>>>>> managed to download NDVI data for North America and project it to the same
>>>>> geographic coordinate system as PRISM precip. data (e.g.
>>>>> http://www.prism.oregonstate.edu) for the same time period.
>>>>>
>>>>> I now want to stack these two rasters. My NDVI layer has a greater extent
>>>>> than the PRISM layer so I crop the former by the latter using:
>>>>>
>>>>> croppedNDVI<-crop(NDVI,prism)
>>>>>
>>>>>
>>>>> But when I look at the resulting raster, I see that the extent still
>>>>> doesn't line up. I think this is an issue with cells of the two rasters
>>>>> being "off" centre from each other. I can use the following to get them to
>>>>> align:
>>>>>
>>>>> adjustNDVI<-resample(croppedNDVI,prism)
>>>>>
>>>>>
>>>>> Now I can stack the "adjustNDVI" and "prism" layers as the extents match.
>>>>> But I am wondering whether this is valid? Why were the initial rasters
>>>>> misaligned in the first place given that I specified the same resolution and
>>>>> geographic coordinate system/datum when I processed the MODIS file? I'm
>>>>> grateful for any clarification!
>>>>>        [[alternative HTML version deleted]]
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at r-project.org
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>>>>
>>>>
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>         [[alternative HTML version deleted]]
>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
>
> --
> Jonathan A. Greenberg, PhD
> Assistant Professor
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Department of Geography and Geographic Information Science
> University of Illinois at Urbana-Champaign
> 259 Computing Applications Building, MC-150
> 605 East Springfield Avenue
> Champaign, IL  61820-6371
> Phone: 217-300-1924
> http://www.geog.illinois.edu/~jgrn/
> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From r.turner at auckland.ac.nz  Tue Jan 21 23:53:45 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 22 Jan 2014 11:53:45 +1300
Subject: [R-sig-Geo] voronoi (thiessen) polygons inside irregular area
In-Reply-To: <1390288214159-7585593.post@n2.nabble.com>
References: <002d01cebf65$fd57b9b0$f8072d10$@stuba.sk>
	<CAGfc75kur4T3SqgZbSjvLjhGUe0cWv3m=krVGfO2c_OevFxkbA@mail.gmail.com>
	<1390288214159-7585593.post@n2.nabble.com>
Message-ID: <52DEFA79.8030100@auckland.ac.nz>


The problem is that the tile corresponding to point 8 consists of
two discontiguous polygons one of which is empty of points of the 
pattern.  The empty polygon is juxtaposed with one of the polygons
comprising the tile for point 10, which makes points 10 and 8 neighbours.

I think it suffices to eliminate from each tile any polygons that do not 
contain any points of the pattern.  The following function does
that:

bar <- function(X) {
require(spatstat)
ttt <- dirichlet(X)
sss <- ttt$tiles
f <- function(x,pat){
     www <- lapply(x$bdry,function(y){owin(poly=y)})
     gp  <- sapply(www,function(w){
                any(inside.owin(pat$x,pat$y,w))})
     www[[seq(along=gp)[gp]]]
}
rrr <- lapply(sss,f,pat=X)
ttt$tiles <- rrr
ttt
}

Try:

junk <- bar(poly.w.points)
junk.sp <- as(junk,"SpatialPolygons")
nays <- poly2nb(junk.sp)
nays[10] # Gives 3  7 11 14.  OMMMMMMM!!!!

Rolf Turner

On 21/01/14 20:10, buzzfuzz006 wrote:

> Hi,
> Is there a simple way to draw voronoi/thiessen polygons inside an irregular
> polygon similar to this, but where the polygons created do not extend over
> the boundaries of the overlaying polygon. E.g
> Using the packages
>
> library(spatstat);library(spdep)
>
> If we had set points:
>
> x<-c(0.9,1.7,2.4,2.9,4.83, 0.73, 2.31, 3.69, 4.23, 2.86, 1.91, 4.32, 4.60,
> 1.82)
> y<-c(1.9,0.9,2.8,1.9,1.81, 1.66, 4.54, 5.66, 1.99, 4.03, 4.32, 5.98, 5.56,
> 3.41)
>
> within the set irregular polygon:
>
> x.p<-c(0.1, 6.0, 6.0, 1.0, 5.0, 3.0, 3.5, 0.1)
> y.p<-c(0.1, 1.0, 6.5, 5.5, 5.0, 1.0, 4.8, 5.0)
>
> now I set the polygon to needed dirichlet format
>
> poly.l<-list(x.p,y.p)
> names(poly.l)<-c("x","y")
>
> and create the spatial point pattern
>
> poly.w.points<-ppp(x=x,y=y,poly=poly.l)
>
> then carry out the voronoi tessellation
>
> spatstat.options("gpclib"=T)
> tess<-dirichlet(poly.w.points)
>
> unfortunately if we are to plot this it looks like this
>
> plot(tess)
> text(x,y,1:length(x))
>
> and if we check the neighbours we see that the voronoi polygons extend
> outside the polygon area
> tess.sp<-as(tess,"SpatialPolygons")
> neighs<-poly2nb(tess.sp)
>
> e.g.
> neighs[10]
> shows that point 10 is neighbours (shares boundary) with 8,9 and 13 ? whilst
> I want a result whereby 10 would only be neighbours with 7,11,14 and 3.


From adrian.baddeley at uwa.edu.au  Wed Jan 22 02:57:14 2014
From: adrian.baddeley at uwa.edu.au (Adrian Baddeley)
Date: Wed, 22 Jan 2014 09:57:14 +0800
Subject: [R-sig-Geo] voronoi (thiessen) polygons inside irregular area
In-Reply-To: <52DEFA79.8030100@auckland.ac.nz>
References: <002d01cebf65$fd57b9b0$f8072d10$@stuba.sk>
	<CAGfc75kur4T3SqgZbSjvLjhGUe0cWv3m=krVGfO2c_OevFxkbA@mail.gmail.com>
	<1390288214159-7585593.post@n2.nabble.com>,
	<52DEFA79.8030100@auckland.ac.nz>
Message-ID: <CF5661163F77A44781208D9AC4FDEA7226E8DF9789@IS-WIN-376.staffad.uwa.edu.au>

Josh Firth asks about Dirichlet-Voronoi-Thiessen polygons in an irregular area.

The Dirichlet tile of each data point is the set that is closer to this point than to 
any of the other data points. 'Closer' is measured by Euclidean distance. 
Basically you're saying that you want to replace Euclidean distance by 
another measure of distance - say, the shortest-path distance inside the non-convex window.

Tinkering with the results of the Dirichlet tessellation is not going to do this;
you'd need a completely different algorithm.

Rolf Turner writes:
> I think it suffices to eliminate from each tile any polygons that do not
> contain any points of the pattern.  

This is not a solution because it removes part of the window. 

The code in Rolf's solution is not going to work if the window has holes 
(since some of the $bdry[[i]] could be holes rather than positive boundaries).
  
Also, an idiom like
    ttt$tiles <- xxx
is dangerous, and in this case, will lead to problems, because it is no longer true that
the union of tt$tiles is equal to tt$window.  The correct way to create a changed tessellation
is something like
     tess(tlles=xxx, window=www).


Prof Adrian Baddeley FAA
University of Western Australia
________________________________________
From: Rolf Turner [r.turner at auckland.ac.nz]
Sent: Wednesday, 22 January 2014 6:53 AM
To: buzzfuzz006
Cc: r-sig-geo at r-project.org; Adrian Baddeley
Subject: Re: [R-sig-Geo] voronoi (thiessen) polygons inside irregular area

The problem is that the tile corresponding to point 8 consists of
two discontiguous polygons one of which is empty of points of the
pattern.  The empty polygon is juxtaposed with one of the polygons
comprising the tile for point 10, which makes points 10 and 8 neighbours.

I think it suffices to eliminate from each tile any polygons that do not
contain any points of the pattern.  The following function does
that:

bar <- function(X) {
require(spatstat)
ttt <- dirichlet(X)
sss <- ttt$tiles
f <- function(x,pat){
     www <- lapply(x$bdry,function(y){owin(poly=y)})
     gp  <- sapply(www,function(w){
                any(inside.owin(pat$x,pat$y,w))})
     www[[seq(along=gp)[gp]]]
}
rrr <- lapply(sss,f,pat=X)
ttt$tiles <- rrr
ttt
}

Try:

junk <- bar(poly.w.points)
junk.sp <- as(junk,"SpatialPolygons")
nays <- poly2nb(junk.sp)
nays[10] # Gives 3  7 11 14.  OMMMMMMM!!!!

Rolf Turner

On 21/01/14 20:10, buzzfuzz006 wrote:

> Hi,
> Is there a simple way to draw voronoi/thiessen polygons inside an irregular
> polygon similar to this, but where the polygons created do not extend over
> the boundaries of the overlaying polygon. E.g
> Using the packages
>
> library(spatstat);library(spdep)
>
> If we had set points:
>
> x<-c(0.9,1.7,2.4,2.9,4.83, 0.73, 2.31, 3.69, 4.23, 2.86, 1.91, 4.32, 4.60,
> 1.82)
> y<-c(1.9,0.9,2.8,1.9,1.81, 1.66, 4.54, 5.66, 1.99, 4.03, 4.32, 5.98, 5.56,
> 3.41)
>
> within the set irregular polygon:
>
> x.p<-c(0.1, 6.0, 6.0, 1.0, 5.0, 3.0, 3.5, 0.1)
> y.p<-c(0.1, 1.0, 6.5, 5.5, 5.0, 1.0, 4.8, 5.0)
>
> now I set the polygon to needed dirichlet format
>
> poly.l<-list(x.p,y.p)
> names(poly.l)<-c("x","y")
>
> and create the spatial point pattern
>
> poly.w.points<-ppp(x=x,y=y,poly=poly.l)
>
> then carry out the voronoi tessellation
>
> spatstat.options("gpclib"=T)
> tess<-dirichlet(poly.w.points)
>
> unfortunately if we are to plot this it looks like this
>
> plot(tess)
> text(x,y,1:length(x))
>
> and if we check the neighbours we see that the voronoi polygons extend
> outside the polygon area
> tess.sp<-as(tess,"SpatialPolygons")
> neighs<-poly2nb(tess.sp)
>
> e.g.
> neighs[10]
> shows that point 10 is neighbours (shares boundary) with 8,9 and 13 ? whilst
> I want a result whereby 10 would only be neighbours with 7,11,14 and 3.


From kapoor.ab at gmail.com  Wed Jan 22 07:57:15 2014
From: kapoor.ab at gmail.com (Abhishek Kapoor)
Date: Tue, 21 Jan 2014 22:57:15 -0800 (PST)
Subject: [R-sig-Geo] plotGoogleMaps - Represent Text on map
Message-ID: <1390373835414-7585603.post@n2.nabble.com>

Hi Sir,

is it possible to plot map using factor variable?

I am trying to plot ATMs, Hospital, and restaurant location (Lat/Long) and
with address but i m not getting desired result.

Below is the code

 
eq <- read.csv ('C:/Users/abc/Desktop/2013_08_01_NCR_Master.csv')
str (eq)

'data.frame':   13430 obs. of  6 variables:
 $ Type       : Factor w/ 3 levels "ATM","Hospital",..: 2 2 2 2 2 2 2 2 2 2
...
 $ Lat        : num  28.5 28.5 28.4 28.6 28.7 ...
 $ Lng        : num  77 77 77 77 77 ...
 $ PhoneNumber: Factor w/ 5562 levels "","0","011 2004 4406",..: 4922 1 2610
1 1 2669 1 2652 1 4075 ...
 $ Address    : Factor w/ 13394 levels "???, IGI Airport T3 Road, IGI
Airport, New Delhi, DL",..: 11064 11071 13208 9306 12497 2644 10809 9722
6499 12089 ...
 $ Type1      : int  2 2 2 2 2 2 2 2 2 2 ...

coordinates(eq) = ~Lng + Lat
proj4string(eq) = CRS("+proj=longlat +datum=WGS84")
eq <- SpatialPointsDataFrame( eq , data = data.frame( id = row.names( eq ) )
)

ma<-plotGoogleMaps(eq,zcol="Type", colPalette=c("#FFF7BC",
"#FEC44F","#D95F0E"),filename='myMap82.html',mapTypeId= 'TERRAIN',
fitBounds=T)

but it is not producing desired results
I want only 3 color bubbles by "Type" - ATM, Hospital & Restaurants 

I hope you can help me, this is my first time in R. 

I am using Windows and R is 3.0.2
Thanks in advance

Regards
Abhishek



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/plotGoogleMaps-Represent-Text-on-map-tp7585603.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From milan.kili11 at gmail.com  Wed Jan 22 13:21:24 2014
From: milan.kili11 at gmail.com (Milan Kilibarda)
Date: Wed, 22 Jan 2014 13:21:24 +0100
Subject: [R-sig-Geo] plotGoogleMaps - Represent Text on map
In-Reply-To: <1390373835414-7585603.post@n2.nabble.com>
References: <1390373835414-7585603.post@n2.nabble.com>
Message-ID: <CAPSaU-9MhqCSVqeuk+iMNqK5BxXPT7iJ5hSK+SAwfi29oz4k8Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140122/5976c4c7/attachment.pl>

From alobolistas at gmail.com  Wed Jan 22 13:26:24 2014
From: alobolistas at gmail.com (Agustin Lobo)
Date: Wed, 22 Jan 2014 13:26:24 +0100
Subject: [R-sig-Geo] tolerance in points2grid()
Message-ID: <CAG4NRe+O6_JAvHyMoCOX4vqTdgPfBVNO8herqnE=Q9bmR9oLdg@mail.gmail.com>

Hi!

I do
points2grid(tmetad1)

and get:
suggested tolerance minimum: 0.000856898
Error in points2grid(tmetad1) :
  dimension 2 : coordinate intervals are not constant

then just try:
tmetadg <- points2grid(tmetad1,tolerance=0.000856898)

and works fine. But this is very inconvenient unless the task is being carried
interactively. Is there a way of actually geting the value of the
suggested tolerance into
a variable?
Also, why not having the option:

tmetadg <- points2grid(tmetad1,tolerance="suggested")

Thanks

Agus


From b.rowlingson at lancaster.ac.uk  Wed Jan 22 14:03:30 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 22 Jan 2014 13:03:30 +0000
Subject: [R-sig-Geo] tolerance in points2grid()
In-Reply-To: <2c04b067d0374bdabb882dae0360db3f@EX-1-HT0.lancs.local>
References: <2c04b067d0374bdabb882dae0360db3f@EX-1-HT0.lancs.local>
Message-ID: <CANVKczPD_3iUESWe+_D6E3EVHUDJSacaZmHur3RJ3GTY7t3axw@mail.gmail.com>

On Wed, Jan 22, 2014 at 12:26 PM, Agustin Lobo <alobolistas at gmail.com> wrote:
> Hi!
>
> I do
> points2grid(tmetad1)
>
> and get:
> suggested tolerance minimum: 0.000856898
> Error in points2grid(tmetad1) :
>   dimension 2 : coordinate intervals are not constant
>
> then just try:
> tmetadg <- points2grid(tmetad1,tolerance=0.000856898)
>
> and works fine. But this is very inconvenient unless the task is being carried
> interactively. Is there a way of actually geting the value of the
> suggested tolerance into
> a variable?
> Also, why not having the option:
>
> tmetadg <- points2grid(tmetad1,tolerance="suggested")
>

 I don't see a way of getting this short of really hacky methods
(wrapping the call in a "try", capturing the output, parsing it to get
the suggested value). Better to just look at the source code and use
that.

 Its a bit of a twisty turny maze of diffs and floors and maxes and
mins, but its there. One complication is that the tolerance is
computed independently for each dimension, so what you actually need
to do is loop over dimensions and use the largest computed suggested
tolerance. At the moment the code stop()s when it hits the first
tolerance fail:

 > xy=SpatialPoints(cbind(c(1,2,3,4,5.01),c(1,2,3,4,5.02)))

> points2grid(xy)
suggested tolerance minimum: 0.01
Error in points2grid(xy) :
  dimension 1 : coordinate intervals are not constant

 oops, dimension 1 (x) out of tolerance, lets' up that:

> points2grid(xy, tolerance=0.01)
suggested tolerance minimum: 0.02
Error in points2grid(xy, tolerance = 0.01) :
  dimension 2 : coordinate intervals are not constant

 and now dimension 2 is out. I guess this would be a pain in a ten
dimensional universe...

 Barry


From Nathaniel.L.Mikle-1 at ou.edu  Wed Jan 22 21:48:58 2014
From: Nathaniel.L.Mikle-1 at ou.edu (nate_m)
Date: Wed, 22 Jan 2014 12:48:58 -0800 (PST)
Subject: [R-sig-Geo] Breakpoint analysis with two variables
Message-ID: <1390423738606-7585607.post@n2.nabble.com>

Hi all,

I am a beginner, so bear with me please. My goal is to perform breakpoint
analysis (package 'segmented') on each cell of two raster stacks (11 files
thick each). Some cells throughout both bricks are NA, so I have to skip
these as well. My goal is to output breakpoints with confidence intervals
based on the two variables for each cell. Here is my code and the error, I
think I am doing something incorrectly with data types;

library(raster)
#each stack is 11 rasters thick
y1 <- stack(y2)
x1 <- stack(x2)

#testing on small region
y <- crop(y1, extent(-103,-102,37,38))
x <- crop(x1, extent(-103,-102,37,38))

fun1 <- function(x) {
  m <- NA
  try(m <- lm(x ~ y), silent=T)
  m
}

library(segmented)

fun2 <- function(x) {
  m <- NA
  try(m <- segmented(x, ~y, psi=150), silent=T)
  m
}

fun3 <- function(x) {
  m <- NA
  try(m <- confint(x), silent=T)
  m
}

e1 <- calc(y, fun1)
os <- calc(e1, fun2)
results <- calc(os, fun3)

This is the error I receive after running the first function with e1;

Error in model.frame.default(formula = x ~ y, drop.unused.levels = TRUE) : 
  invalid type (S4) for variable 'y'

If anybody has a thought as to what I am doing wrong, it would be of great
help! Additionally, I would like to set "psi" from the segmented package
with values from a raster- is this possible?

Thanks in advance,
Nate



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Breakpoint-analysis-with-two-variables-tp7585607.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From claudia.kappa at libero.it  Wed Jan 22 23:15:52 2014
From: claudia.kappa at libero.it (claudia.kappa at libero.it)
Date: Wed, 22 Jan 2014 23:15:52 +0100 (CET)
Subject: [R-sig-Geo] problem about ST COVARIANCE
Message-ID: <869244725.19392771390428952005.JavaMail.actor@webmail43>

Dear list,
I try to calculate spatio-temporal COVARIANCE for r5to10 STFDF (as seen in 
gstat vignette).
I'm using the following command:

vv=variogram(PM10~1,r5to10[,1:200], width=20, cutoff=200, covariance=TRUE)

but I see this error:

Error in VgmAverage(ret, ...) : unused argument (covariance = TRUE)
In addition: There were 50 or more warnings (use warnings() to see the first 
50)


Could you help me with this?

Thanks

Claudia


From r.hijmans at gmail.com  Thu Jan 23 03:07:50 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 22 Jan 2014 18:07:50 -0800
Subject: [R-sig-Geo] Breakpoint analysis with two variables
In-Reply-To: <1390423738606-7585607.post@n2.nabble.com>
References: <1390423738606-7585607.post@n2.nabble.com>
Message-ID: <CANtt_hz-qhKk1uYdQ6C7KxbDdmEUYE_dxN+BoEVJV1sjnO1nyw@mail.gmail.com>

Nate,
With questions like this, please provide a fully reproducible example
with data created by the script or from example data from a package
(see the examples in the help files and the list archives for how to
that).

The error occurs because fun1 returns either NA or an object of class
'lm' (instead of a number). See ?calc for how to use lm with calc.
Robert


On Wed, Jan 22, 2014 at 12:48 PM, nate_m <Nathaniel.L.Mikle-1 at ou.edu> wrote:
> Hi all,
>
> I am a beginner, so bear with me please. My goal is to perform breakpoint
> analysis (package 'segmented') on each cell of two raster stacks (11 files
> thick each). Some cells throughout both bricks are NA, so I have to skip
> these as well. My goal is to output breakpoints with confidence intervals
> based on the two variables for each cell. Here is my code and the error, I
> think I am doing something incorrectly with data types;
>
> library(raster)
> #each stack is 11 rasters thick
> y1 <- stack(y2)
> x1 <- stack(x2)
>
> #testing on small region
> y <- crop(y1, extent(-103,-102,37,38))
> x <- crop(x1, extent(-103,-102,37,38))
>
> fun1 <- function(x) {
>   m <- NA
>   try(m <- lm(x ~ y), silent=T)
>   m
> }
>
> library(segmented)
>
> fun2 <- function(x) {
>   m <- NA
>   try(m <- segmented(x, ~y, psi=150), silent=T)
>   m
> }
>
> fun3 <- function(x) {
>   m <- NA
>   try(m <- confint(x), silent=T)
>   m
> }
>
> e1 <- calc(y, fun1)
> os <- calc(e1, fun2)
> results <- calc(os, fun3)
>
> This is the error I receive after running the first function with e1;
>
> Error in model.frame.default(formula = x ~ y, drop.unused.levels = TRUE) :
>   invalid type (S4) for variable 'y'
>
> If anybody has a thought as to what I am doing wrong, it would be of great
> help! Additionally, I would like to set "psi" from the segmented package
> with values from a raster- is this possible?
>
> Thanks in advance,
> Nate
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Breakpoint-analysis-with-two-variables-tp7585607.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From kapoor.ab at gmail.com  Thu Jan 23 06:22:53 2014
From: kapoor.ab at gmail.com (Abhishek Kapoor)
Date: Wed, 22 Jan 2014 21:22:53 -0800 (PST)
Subject: [R-sig-Geo] plotGoogleMaps - Represent Text on map
In-Reply-To: <CAPSaU-9MhqCSVqeuk+iMNqK5BxXPT7iJ5hSK+SAwfi29oz4k8Q@mail.gmail.com>
References: <1390373835414-7585603.post@n2.nabble.com>
	<CAPSaU-9MhqCSVqeuk+iMNqK5BxXPT7iJ5hSK+SAwfi29oz4k8Q@mail.gmail.com>
Message-ID: <CA+6VSRgFOsHYYx6nKqEEjVisRO3GyV-O3oS87Sj=S40Ze=64-A@mail.gmail.com>

Thanks a lot.

Its working now :)

Regards
Abhishek


On Wed, Jan 22, 2014 at 5:52 PM, Milan Kilibarda [via R-sig-geo] <
ml-node+s2731867n7585604h15 at n2.nabble.com> wrote:

> Dear Abhishek,
>
> Here is reproducible example, doing what you want to get. I guess.
>
> Best,
>
> Milan
>
>
> library(plotGoogleMaps)
>
> # Point data
>
> data(meuse)
> coordinates(meuse)<-~x+y
> proj4string(meuse) <- CRS('+init=epsg:28992')
>
> ma<-plotGoogleMaps(meuse,zcol="ffreq",
> colPalette=c("#FFF7BC","#FEC44F","#D95F0E"),
>                    filename='myMap82.html',mapTypeId= 'TERRAIN',
>                    fitBounds=T)
>
>
> #################
> # Show text in markers
>
> meuse$ffreq2 <- factor(meuse$ffreq, labels = c("One", "Two", "Three"))
>
> ma<-plotGoogleMaps(meuse,zcol="ffreq2",
> colPalette=c("#FFF7BC","#FEC44F","#D95F0E"),
>                    filename='myMap82.html',mapTypeId= 'TERRAIN',
>                    fitBounds=T)
>
> #################
> # Show just labels (text) without markers
>
> ma<-plotGoogleMaps(meuse,zcol="ffreq2",
>                    iconMarker= iconlabels(meuse$ffreq2,
> colPalette=c("#FFF7BC","#FEC44F","#D95F0E")),
>                    colPalette=c("#FFF7BC","#FEC44F","#D95F0E"),
>                    filename='myMap82.html',mapTypeId= 'TERRAIN',
>                    fitBounds=T)
>
>
>
>
> On Wed, Jan 22, 2014 at 7:57 AM, Abhishek Kapoor <[hidden email]<http://user/SendEmail.jtp?type=node&node=7585604&i=0>>wrote:
>
>
> > Hi Sir,
> >
> > is it possible to plot map using factor variable?
> >
> > I am trying to plot ATMs, Hospital, and restaurant location (Lat/Long)
> and
> > with address but i m not getting desired result.
> >
> > Below is the code
> >
> >
> > eq <- read.csv ('C:/Users/abc/Desktop/2013_08_01_NCR_Master.csv')
> > str (eq)
> >
> > 'data.frame':   13430 obs. of  6 variables:
> >  $ Type       : Factor w/ 3 levels "ATM","Hospital",..: 2 2 2 2 2 2 2 2
> 2 2
> > ...
> >  $ Lat        : num  28.5 28.5 28.4 28.6 28.7 ...
> >  $ Lng        : num  77 77 77 77 77 ...
> >  $ PhoneNumber: Factor w/ 5562 levels "","0","011 2004 4406",..: 4922 1
> > 2610
> > 1 1 2669 1 2652 1 4075 ...
> >  $ Address    : Factor w/ 13394 levels "???, IGI Airport T3 Road, IGI
> > Airport, New Delhi, DL",..: 11064 11071 13208 9306 12497 2644 10809 9722
> > 6499 12089 ...
> >  $ Type1      : int  2 2 2 2 2 2 2 2 2 2 ...
> >
> > coordinates(eq) = ~Lng + Lat
> > proj4string(eq) = CRS("+proj=longlat +datum=WGS84")
> > eq <- SpatialPointsDataFrame( eq , data = data.frame( id = row.names( eq
> )
> > )
> > )
> >
> > ma<-plotGoogleMaps(eq,zcol="Type", colPalette=c("#FFF7BC",
> > "#FEC44F","#D95F0E"),filename='myMap82.html',mapTypeId= 'TERRAIN',
> > fitBounds=T)
> >
> > but it is not producing desired results
> > I want only 3 color bubbles by "Type" - ATM, Hospital & Restaurants
> >
> > I hope you can help me, this is my first time in R.
> >
> > I am using Windows and R is 3.0.2
> > Thanks in advance
> >
> > Regards
> > Abhishek
> >
> >
> >
> > --
> > View this message in context:
> >
> http://r-sig-geo.2731867.n2.nabble.com/plotGoogleMaps-Represent-Text-on-map-tp7585603.html
> > Sent from the R-sig-geo mailing list archive at Nabble.com.
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > [hidden email] <http://user/SendEmail.jtp?type=node&node=7585604&i=1>
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
>
>
> --
> Milan Kilibarda
>
> University of Belgrade,
> Faculty of Civil Engineering,
> Department of Geodesy and Geoinformatics,
> Address: Bulevar kralja Aleksandra 73  11000 Belgrade, Serbia,
> Mail:  [hidden email]<http://user/SendEmail.jtp?type=node&node=7585604&i=2>
>
> tel:+381 11 3218516
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> [hidden email] <http://user/SendEmail.jtp?type=node&node=7585604&i=3>
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> ------------------------------
>  If you reply to this email, your message will be added to the discussion
> below:
>
> http://r-sig-geo.2731867.n2.nabble.com/plotGoogleMaps-Represent-Text-on-map-tp7585603p7585604.html
>  To unsubscribe from plotGoogleMaps - Represent Text on map, click here<http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=7585603&code=a2Fwb29yLmFiQGdtYWlsLmNvbXw3NTg1NjAzfDE5NTg4MDkyNjg=>
> .
> NAML<http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>




--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/plotGoogleMaps-Represent-Text-on-map-tp7585603p7585610.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From kridox at ymail.com  Thu Jan 23 06:52:40 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 23 Jan 2014 14:52:40 +0900
Subject: [R-sig-Geo] problem about ST COVARIANCE
In-Reply-To: <869244725.19392771390428952005.JavaMail.actor@webmail43>
References: <869244725.19392771390428952005.JavaMail.actor@webmail43>
Message-ID: <CAAcyNCxCaXQCWpfuXmTojKshVcfXt6Ds9BcVHpQ4Gik1xNDGyg@mail.gmail.com>

Hello,

The message is quite clear : 'covariance' is not an argument of the
'variogram' function.

Regards,
Pascal

On 23 January 2014 07:15, claudia.kappa at libero.it
<claudia.kappa at libero.it> wrote:
> Dear list,
> I try to calculate spatio-temporal COVARIANCE for r5to10 STFDF (as seen in
> gstat vignette).
> I'm using the following command:
>
> vv=variogram(PM10~1,r5to10[,1:200], width=20, cutoff=200, covariance=TRUE)
>
> but I see this error:
>
> Error in VgmAverage(ret, ...) : unused argument (covariance = TRUE)
> In addition: There were 50 or more warnings (use warnings() to see the first
> 50)
>
>
> Could you help me with this?
>
> Thanks
>
> Claudia
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From joshfirth at hotmail.com  Thu Jan 23 09:38:28 2014
From: joshfirth at hotmail.com (Josh Firth)
Date: Thu, 23 Jan 2014 00:38:28 -0800 (PST)
Subject: [R-sig-Geo] voronoi (thiessen) polygons inside irregular area
In-Reply-To: <CF5661163F77A44781208D9AC4FDEA7226E8DF9789@IS-WIN-376.staffad.uwa.edu.au>
References: <002d01cebf65$fd57b9b0$f8072d10$@stuba.sk>
	<CAGfc75kur4T3SqgZbSjvLjhGUe0cWv3m=krVGfO2c_OevFxkbA@mail.gmail.com>
	<1390288214159-7585593.post@n2.nabble.com>
	<52DEFA79.8030100@auckland.ac.nz>
	<CF5661163F77A44781208D9AC4FDEA7226E8DF9789@IS-WIN-376.staffad.uwa.edu.au>
Message-ID: <1390466308369-7585612.post@n2.nabble.com>

Rolf Turners solution to Dirichlet-Voronoi-Thiessen polygons in an irregular
area, by elimination from each tile any polygons that do not contain any
points of the pattern, allows a rough determination of first order
neighbours. This is currently the best option for me. However, it will
suffer if the areas of the polygons are needed, or if the overlaying polygon
has holes, and could also sometimes miss first order neighbours e.g. if in
the first example given, the points of interest were sometime like:
     x<-c(0.9,1.7,2.4,2.9,4.83, 0.73, 2.6, 3.69, 4.23, 2.86, 1.91, 4.32,
4.60, 1.82,0.5)
    y<-c(1.9,0.9,2.8,1.9,1.81, 1.66, 4.7, 5.66, 1.99, 4.03, 4.32, 5.98,
5.56, 3.41,5.5)

and the polygon was

x.p<-c(0.1, 6.0, 6.0, 0.1, 5.0, 3.0, 3.5, 0.1)
y.p<-c(0.1, 1.0, 6.5, 5.5, 5.0, 1.0, 4.8, 5.0) 

then following the previous code given:

poly.l<-list(x.p,y.p)
names(poly.l)<-c("x","y") 
poly.w.points<-ppp(x=x,y=y,poly=poly.l)
spatstat.options("gpclib"=T)

and applying Rolf turner's function

bar <- function(X) {
require(spatstat)
ttt <- dirichlet(X)
sss <- ttt$tiles
f <- function(x,pat){
     www <- lapply(x$bdry,function(y){owin(poly=y)})
     gp  <- sapply(www,function(w){
                any(inside.owin(pat$x,pat$y,w))})
     www[[seq(along=gp)[gp]]]
}
rrr <- lapply(sss,f,pat=X)
ttt$tiles <- rrr
ttt
} 
junk <- bar(poly.w.points)
junk.sp <- as(junk,"SpatialPolygons")
nays <- poly2nb(junk.sp)
nays[8]

shows that 8 is not a first order neighbour with 15, even though it would be
desirable that they are:
plot(junk)
text(x,y,1:length(x))

Adrian Baddeley also points out that a completely different algorithm (not
currently available in R?) may be the best route. Would another potential
solution be to split (using more thiessen polygons) the area of polygons
that DO NOT contain a 'point of interest' to belong to surrounding polygons
that DO contain a point of interest? 

Any suggestions of potential methods to achieve (even if imperfectly) the
final goal of 'Dirichlet-like' tiles within an irregular area are much
appreciated!

Josh Firth











--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/voronoi-thiessen-polygons-inside-irregular-area-tp7584761p7585612.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From hengl at spatial-analyst.net  Thu Jan 23 10:56:45 2014
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Thu, 23 Jan 2014 10:56:45 +0100
Subject: [R-sig-Geo] Problems with plotting large factor-type rasters using
 the raster package
Message-ID: <52E0E75D.9050309@spatial-analyst.net>


Hi Robert,

I am having problems with plotting factor-type rasters using the raster 
package (v. 2.1-49). Here is the error message I get:

library(raster)
library(plotKML)
## smaller raster:
data(eberg_grid)
gridded(eberg_grid) <- ~x+y
eberg_grid$CL <- cut(eberg_grid$DEMSRT6, breaks=c(200,250,300,350))
r <- raster(eberg_grid["CL"])
image(r, col=c("red","green","blue"))
## This works fine; now lets try with a larger raster (>5e5 pixels):
sp <- SpatialPixelsDataFrame(spsample(eberg_grid, n=1e6, 
type="regular"), data=data.frame(v=runif(1000^2)))
sp$CL <- cut(sp$v, breaks=c(0.1,0.2,0.3,0.4))
r2 <- raster(sp["CL"])
image(r2)

Error in .checkLevels(levels(x)[[1]], value) :
   new raster attributes (factor values) should be in a data.frame 
(inside a list)

Somehow, image function in the raster package does not want to plot 
large rasters that are of factor type. I've looked at the source code 
(https://r-forge.r-project.org/scm/viewvc.php/pkg/raster/R/image.R?view=markup&root=raster), 
and it looks as the problem is with the "maxpixels" argument (if the new 
raster has >5e5 pixels, the function breaks).

thank you,

T. (Tom) Hengl
Url: http://www.wageningenur.nl/en/Persons/dr.-T-Tom-Hengl.htm
Network: http://profiles.google.com/tom.hengl
Publications: http://scholar.google.com/citations?user=2oYU7S8AAAAJ


From kridox at ymail.com  Thu Jan 23 11:12:33 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 23 Jan 2014 19:12:33 +0900
Subject: [R-sig-Geo] Problems with plotting large factor-type rasters
 using the raster package
In-Reply-To: <52E0E75D.9050309@spatial-analyst.net>
References: <52E0E75D.9050309@spatial-analyst.net>
Message-ID: <CAAcyNCzy2hwDeuGQjrzsDdi2tkXS+4LAB_in0HO623E_8=hepg@mail.gmail.com>

Hello,

You can set a larger number of pixels in the "image" function:

> image(r2, maxpixels=5e6)

Or I missunderstood the problem.

Regards,
Pascal

On 23 January 2014 18:56, Tomislav Hengl <hengl at spatial-analyst.net> wrote:
>
> Hi Robert,
>
> I am having problems with plotting factor-type rasters using the raster
> package (v. 2.1-49). Here is the error message I get:
>
> library(raster)
> library(plotKML)
> ## smaller raster:
> data(eberg_grid)
> gridded(eberg_grid) <- ~x+y
> eberg_grid$CL <- cut(eberg_grid$DEMSRT6, breaks=c(200,250,300,350))
> r <- raster(eberg_grid["CL"])
> image(r, col=c("red","green","blue"))
> ## This works fine; now lets try with a larger raster (>5e5 pixels):
> sp <- SpatialPixelsDataFrame(spsample(eberg_grid, n=1e6, type="regular"),
> data=data.frame(v=runif(1000^2)))
> sp$CL <- cut(sp$v, breaks=c(0.1,0.2,0.3,0.4))
> r2 <- raster(sp["CL"])
> image(r2)
>
> Error in .checkLevels(levels(x)[[1]], value) :
>   new raster attributes (factor values) should be in a data.frame (inside a
> list)
>
> Somehow, image function in the raster package does not want to plot large
> rasters that are of factor type. I've looked at the source code
> (https://r-forge.r-project.org/scm/viewvc.php/pkg/raster/R/image.R?view=markup&root=raster),
> and it looks as the problem is with the "maxpixels" argument (if the new
> raster has >5e5 pixels, the function breaks).
>
> thank you,
>
> T. (Tom) Hengl
> Url: http://www.wageningenur.nl/en/Persons/dr.-T-Tom-Hengl.htm
> Network: http://profiles.google.com/tom.hengl
> Publications: http://scholar.google.com/citations?user=2oYU7S8AAAAJ
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From hengl at spatial-analyst.net  Thu Jan 23 11:52:20 2014
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Thu, 23 Jan 2014 11:52:20 +0100
Subject: [R-sig-Geo] Problems with plotting large factor-type rasters
 using the raster package
In-Reply-To: <CAAcyNCzy2hwDeuGQjrzsDdi2tkXS+4LAB_in0HO623E_8=hepg@mail.gmail.com>
References: <52E0E75D.9050309@spatial-analyst.net>
	<CAAcyNCzy2hwDeuGQjrzsDdi2tkXS+4LAB_in0HO623E_8=hepg@mail.gmail.com>
Message-ID: <52E0F464.5060807@spatial-analyst.net>


Hi Pascal,

Setting maxpixels works indeed (thanx for spotting this). Nevertheless, 
I would adjust the code so that the "raster::image" method does not 
break due to some invisible parameter.

T. (Tom) Hengl
Url: http://www.wageningenur.nl/en/Persons/dr.-T-Tom-Hengl.htm
Network: http://profiles.google.com/tom.hengl
Publications: http://scholar.google.com/citations?user=2oYU7S8AAAAJ

On 23-1-2014 11:12, Pascal Oettli wrote:
> Hello,
>
> You can set a larger number of pixels in the "image" function:
>
>> image(r2, maxpixels=5e6)
>
> Or I missunderstood the problem.
>
> Regards,
> Pascal
>
> On 23 January 2014 18:56, Tomislav Hengl <hengl at spatial-analyst.net> wrote:
>>
>> Hi Robert,
>>
>> I am having problems with plotting factor-type rasters using the raster
>> package (v. 2.1-49). Here is the error message I get:
>>
>> library(raster)
>> library(plotKML)
>> ## smaller raster:
>> data(eberg_grid)
>> gridded(eberg_grid) <- ~x+y
>> eberg_grid$CL <- cut(eberg_grid$DEMSRT6, breaks=c(200,250,300,350))
>> r <- raster(eberg_grid["CL"])
>> image(r, col=c("red","green","blue"))
>> ## This works fine; now lets try with a larger raster (>5e5 pixels):
>> sp <- SpatialPixelsDataFrame(spsample(eberg_grid, n=1e6, type="regular"),
>> data=data.frame(v=runif(1000^2)))
>> sp$CL <- cut(sp$v, breaks=c(0.1,0.2,0.3,0.4))
>> r2 <- raster(sp["CL"])
>> image(r2)
>>
>> Error in .checkLevels(levels(x)[[1]], value) :
>>    new raster attributes (factor values) should be in a data.frame (inside a
>> list)
>>
>> Somehow, image function in the raster package does not want to plot large
>> rasters that are of factor type. I've looked at the source code
>> (https://r-forge.r-project.org/scm/viewvc.php/pkg/raster/R/image.R?view=markup&root=raster),
>> and it looks as the problem is with the "maxpixels" argument (if the new
>> raster has >5e5 pixels, the function breaks).
>>
>> thank you,
>>
>> T. (Tom) Hengl
>> Url: http://www.wageningenur.nl/en/Persons/dr.-T-Tom-Hengl.htm
>> Network: http://profiles.google.com/tom.hengl
>> Publications: http://scholar.google.com/citations?user=2oYU7S8AAAAJ
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>


From darunabas at gmail.com  Thu Jan 23 12:53:39 2014
From: darunabas at gmail.com (Barnabas Daru)
Date: Thu, 23 Jan 2014 13:53:39 +0200
Subject: [R-sig-Geo] Creating presence/absence from grid cells & polygons
Message-ID: <427C1B61-D89E-4DFC-963E-B8343B3D25E9@gmail.com>

Dear list members,
I will like to create a presence/absence matrix using R where rows represent grid cells and columns species. 

I have a set of overlapping polygons each representing the distribution of different species and grid cells (also shapefiles generated using fishnet tool in ArcMap) to show presence or absence of species within the grid cells. 

In Arcmap, I was able to do this successfully for few species as follows:
(1) I merged the polygons
(2) I performed spatial intersect of the merged maps on the grid cells
(3) From the result, I used the dataframe (dbf) of the intersect to create the presence absence matrix using the function sample2matrix in the R package picante. The 3 columns of the dataframe are:
plots | abundance | species

However, given the number of merged maps (over 200 overlapping polygons), the analysis in Arcmap got stalled and never proceed to completion. 
I will therefore like to do this in R. 
I will greatly appreciate any R code to help me do this. 

Thanks and kind regards
Barnabas


From alobolistas at gmail.com  Thu Jan 23 14:06:38 2014
From: alobolistas at gmail.com (Agustin Lobo)
Date: Thu, 23 Jan 2014 14:06:38 +0100
Subject: [R-sig-Geo] From Spatial Points Data Frame to Spatial Polygons Data
	Frame
Message-ID: <CAG4NReJLQjcuhfAoODVO3SFn7soYjFC2YAtKB0ft4W_AtxhQBQ@mail.gmail.com>

Hi!

I'm trying to convert an SPointsDF of a set of points
distributed as the centers of the cells of a 4x5 grid
into a SPolygonsDF
This is because the data actually come from the cell and not
just from its center, and want to be able to export as shape and display the
polygon grid on top of other information. The central points
are not sufficient.

The way I'm doing it is not good because I lose the slot data
of the SPointsDF. I can attach the data to the polygons afterwards, but
the original points follow a weird order and I'm concerned about
not attaching the data in the correct order.
Hopefully somebody can suggest an alternative way that would keep
the data slot.

What I do is:

load("https://dl.dropboxusercontent.com/u/3180464/tmetad1.rda")
tmetadg  <- points2grid(tmetad1,tolerance=0.000856898)
tmetadg2  <- SpatialGrid(tmetadg, proj4string=CRS("+init=epsg:4326"))
tmetadpol <- as(tmetadg2, "SpatialPolygons")

I can try with:
tmetadpolDF <- SpatialPolygonsDataFrame(tmetadpol,data=tmetad1 at data,match.ID=FALSE)

but the data actually get in a wrong order (by rows instead of by columns).
The row.names of tmetad1 at coords are not saved in tmetadg, so do not
see how I could
use match.ID.

Thanks

Agus


From edzer.pebesma at uni-muenster.de  Thu Jan 23 15:03:05 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 23 Jan 2014 15:03:05 +0100
Subject: [R-sig-Geo] From Spatial Points Data Frame to Spatial Polygons
 Data Frame
In-Reply-To: <CAG4NReJLQjcuhfAoODVO3SFn7soYjFC2YAtKB0ft4W_AtxhQBQ@mail.gmail.com>
References: <CAG4NReJLQjcuhfAoODVO3SFn7soYjFC2YAtKB0ft4W_AtxhQBQ@mail.gmail.com>
Message-ID: <52E12119.8020400@uni-muenster.de>

try:

x = as(SpatialPixelsDataFrame(tmetad1, tmetad1 at data, tolerance=.00086),
	"SpatialPolygonsDataFrame")
spplot(x[2])

On 01/23/2014 02:06 PM, Agustin Lobo wrote:
> Hi!
> 
> I'm trying to convert an SPointsDF of a set of points
> distributed as the centers of the cells of a 4x5 grid
> into a SPolygonsDF
> This is because the data actually come from the cell and not
> just from its center, and want to be able to export as shape and display the
> polygon grid on top of other information. The central points
> are not sufficient.
> 
> The way I'm doing it is not good because I lose the slot data
> of the SPointsDF. I can attach the data to the polygons afterwards, but
> the original points follow a weird order and I'm concerned about
> not attaching the data in the correct order.
> Hopefully somebody can suggest an alternative way that would keep
> the data slot.
> 
> What I do is:
> 
> load("https://dl.dropboxusercontent.com/u/3180464/tmetad1.rda")
> tmetadg  <- points2grid(tmetad1,tolerance=0.000856898)
> tmetadg2  <- SpatialGrid(tmetadg, proj4string=CRS("+init=epsg:4326"))
> tmetadpol <- as(tmetadg2, "SpatialPolygons")
> 
> I can try with:
> tmetadpolDF <- SpatialPolygonsDataFrame(tmetadpol,data=tmetad1 at data,match.ID=FALSE)
> 
> but the data actually get in a wrong order (by rows instead of by columns).
> The row.names of tmetad1 at coords are not saved in tmetadg, so do not
> see how I could
> use match.ID.
> 
> Thanks
> 
> Agus
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 555 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140123/cc727864/attachment.bin>

From alobolistas at gmail.com  Thu Jan 23 15:58:48 2014
From: alobolistas at gmail.com (Agustin Lobo)
Date: Thu, 23 Jan 2014 15:58:48 +0100
Subject: [R-sig-Geo] From Spatial Points Data Frame to Spatial Polygons
 Data Frame
In-Reply-To: <52E12119.8020400@uni-muenster.de>
References: <CAG4NReJLQjcuhfAoODVO3SFn7soYjFC2YAtKB0ft4W_AtxhQBQ@mail.gmail.com>
	<52E12119.8020400@uni-muenster.de>
Message-ID: <CAG4NReLze2tw=JXm1FZffH-0NTYtWh5zsp-uWYiKK2iW2X-OQw@mail.gmail.com>

Thanks, works perfectly!
Much better through SpatialPixelsDataFrame than through grid.
This is also simplifying another script.
Agus

On Thu, Jan 23, 2014 at 3:03 PM, Edzer Pebesma
<edzer.pebesma at uni-muenster.de> wrote:
> try:
>
> x = as(SpatialPixelsDataFrame(tmetad1, tmetad1 at data, tolerance=.00086),
>         "SpatialPolygonsDataFrame")
> spplot(x[2])
>
> On 01/23/2014 02:06 PM, Agustin Lobo wrote:
>> Hi!
>>
>> I'm trying to convert an SPointsDF of a set of points
>> distributed as the centers of the cells of a 4x5 grid
>> into a SPolygonsDF
>> This is because the data actually come from the cell and not
>> just from its center, and want to be able to export as shape and display the
>> polygon grid on top of other information. The central points
>> are not sufficient.
>>
>> The way I'm doing it is not good because I lose the slot data
>> of the SPointsDF. I can attach the data to the polygons afterwards, but
>> the original points follow a weird order and I'm concerned about
>> not attaching the data in the correct order.
>> Hopefully somebody can suggest an alternative way that would keep
>> the data slot.
>>
>> What I do is:
>>
>> load("https://dl.dropboxusercontent.com/u/3180464/tmetad1.rda")
>> tmetadg  <- points2grid(tmetad1,tolerance=0.000856898)
>> tmetadg2  <- SpatialGrid(tmetadg, proj4string=CRS("+init=epsg:4326"))
>> tmetadpol <- as(tmetadg2, "SpatialPolygons")
>>
>> I can try with:
>> tmetadpolDF <- SpatialPolygonsDataFrame(tmetadpol,data=tmetad1 at data,match.ID=FALSE)
>>
>> but the data actually get in a wrong order (by rows instead of by columns).
>> The row.names of tmetad1 at coords are not saved in tmetadg, so do not
>> see how I could
>> use match.ID.
>>
>> Thanks
>>
>> Agus
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
> 83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From alobolistas at gmail.com  Thu Jan 23 16:17:10 2014
From: alobolistas at gmail.com (Agustin Lobo)
Date: Thu, 23 Jan 2014 16:17:10 +0100
Subject: [R-sig-Geo] raster::raster from SpatialPixelsDataFrame object
Message-ID: <CAG4NReJ871AXH6c-j+BTUJ_mFMebb8WXCqMjkJnOj+L5kzaqzw@mail.gmail.com>

In order to convert a SpatialPixelsDataFrame object "m" into a raster I just do
data(meuse.grid)
m = SpatialPixelsDataFrame(points = meuse.grid[c("x", "y")], data = meuse.grid)
m at data <- data.frame(name="A",m at data)
r <- raster(m)

but the actual values are taken from the first column as I'm not
selecting the numeric field in
the table.
Is there a way to select the field as in rasterize?

r2 <- rasterize(x=m,y=r, field="dist")

It would make sense doing this in just one command.

Thanks

Agus


From edzer.pebesma at uni-muenster.de  Thu Jan 23 16:36:00 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 23 Jan 2014 16:36:00 +0100
Subject: [R-sig-Geo] raster::raster from SpatialPixelsDataFrame object
In-Reply-To: <CAG4NReJ871AXH6c-j+BTUJ_mFMebb8WXCqMjkJnOj+L5kzaqzw@mail.gmail.com>
References: <CAG4NReJ871AXH6c-j+BTUJ_mFMebb8WXCqMjkJnOj+L5kzaqzw@mail.gmail.com>
Message-ID: <52E136E0.2060100@uni-muenster.de>



On 01/23/2014 04:17 PM, Agustin Lobo wrote:
> In order to convert a SpatialPixelsDataFrame object "m" into a raster I just do
> data(meuse.grid)
> m = SpatialPixelsDataFrame(points = meuse.grid[c("x", "y")], data = meuse.grid)
> m at data <- data.frame(name="A",m at data)
> r <- raster(m)
> 
> but the actual values are taken from the first column as I'm not
> selecting the numeric field in
> the table.
> Is there a way to select the field as in rasterize?

you mean, like in:

r <- raster(m[3])

or

r <- raster(m["ffreq"])

?

> 
> r2 <- rasterize(x=m,y=r, field="dist")
> 
> It would make sense doing this in just one command.
> 
> Thanks
> 
> Agus
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 555 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140123/9af4455e/attachment.bin>

From r.hijmans at gmail.com  Thu Jan 23 19:32:27 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 23 Jan 2014 10:32:27 -0800
Subject: [R-sig-Geo] raster::raster from SpatialPixelsDataFrame object
In-Reply-To: <52E136E0.2060100@uni-muenster.de>
References: <CAG4NReJ871AXH6c-j+BTUJ_mFMebb8WXCqMjkJnOj+L5kzaqzw@mail.gmail.com>
	<52E136E0.2060100@uni-muenster.de>
Message-ID: <CANtt_hxMESRuQnG0DU945CjQciXf0N+5cLXs+9xirmMBUhjv8A@mail.gmail.com>

# or  more directly:

data(meuse.grid)
rasterFromXYZ(meuse.grid[,c(1:2, 5)])

# or via a RasterBrick

m = SpatialPixelsDataFrame(points = meuse.grid[c("x", "y")], data = meuse.grid)
m at data <- data.frame(name="A",m at data)

b <- brick(m)
b[["ffreq"]]


# also: there is no "raster" object (there is a function) in the
raster package. You mean 'RasterLayer'



On Thu, Jan 23, 2014 at 7:36 AM, Edzer Pebesma
<edzer.pebesma at uni-muenster.de> wrote:
>
>
> On 01/23/2014 04:17 PM, Agustin Lobo wrote:
>> In order to convert a SpatialPixelsDataFrame object "m" into a raster I just do
>> data(meuse.grid)
>> m = SpatialPixelsDataFrame(points = meuse.grid[c("x", "y")], data = meuse.grid)
>> m at data <- data.frame(name="A",m at data)
>> r <- raster(m)
>>
>> but the actual values are taken from the first column as I'm not
>> selecting the numeric field in
>> the table.
>> Is there a way to select the field as in rasterize?
>
> you mean, like in:
>
> r <- raster(m[3])
>
> or
>
> r <- raster(m["ffreq"])
>
> ?
>
>>
>> r2 <- rasterize(x=m,y=r, field="dist")
>>
>> It would make sense doing this in just one command.
>>
>> Thanks
>>
>> Agus
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
> 83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From r.hijmans at gmail.com  Thu Jan 23 19:51:12 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 23 Jan 2014 10:51:12 -0800
Subject: [R-sig-Geo] Creating presence/absence from grid cells & polygons
In-Reply-To: <427C1B61-D89E-4DFC-963E-B8343B3D25E9@gmail.com>
References: <427C1B61-D89E-4DFC-963E-B8343B3D25E9@gmail.com>
Message-ID: <CANtt_hyTbwS2fdGtbmP91rjK=8w6JoBMHLDTZ-gx8ozjikq0BQ@mail.gmail.com>

Here is an approach:

library(raster)
p1 <- rbind(c(-180,-20), c(-140,55), c(10, 0), c(-140,-60), c(-180,-20))
hole <- rbind(c(-150,-20), c(-100,-10), c(-110,20), c(-150,-20))
sp1 <- SpatialPolygons(list(Polygons(list(Polygon(p1), Polygon(hole,
hole=TRUE)), 1)))
sp2 <- SpatialPolygons(list(Polygons(list(Polygon(rbind(c(-10,0),
c(140,60), c(160,0), c(140,-55), c(-10,0)))), 2)))
sp3 <- SpatialPolygons(list(Polygons(list(Polygon(rbind(c(-125,0),
c(0,60), c(40,5), c(15,-45), c(-125,0)))), 3)))

species <- list(sp1, sp2, sp3)
r <- raster(ncol=90, nrow=45)

rasters <- list()
for (i in 1:length(species)) {
   rasters[[i]] <- rasterize(species[[i]], r, field=1, background=0)
}
s <- stack(rasters)
x <- as.data.frame(s)

# alternatively, look at 'over' in sp.

################

# And this is how you might do it with shapefiles from a single directory
sps = list.files(pattern='.shp$')
# adjust raster to your taste (extent, resolution)
r <- raster(ncol=90, nrow=45)

rasters <- list()
for (i in 1:length(sps)) {
   sp <- shapefile(sps[i])
   f <- extension(sp, '.grd')
   rasters[[i]] <- rasterize(species[[i]], r, field=1, background=0,
filename=f, overwrite=TRUE)
}
s <- stack(rasters)
x <- as.data.frame(s)


On Thu, Jan 23, 2014 at 3:53 AM, Barnabas Daru <darunabas at gmail.com> wrote:
> Dear list members,
> I will like to create a presence/absence matrix using R where rows represent grid cells and columns species.
>
> I have a set of overlapping polygons each representing the distribution of different species and grid cells (also shapefiles generated using fishnet tool in ArcMap) to show presence or absence of species within the grid cells.
>
> In Arcmap, I was able to do this successfully for few species as follows:
> (1) I merged the polygons
> (2) I performed spatial intersect of the merged maps on the grid cells
> (3) From the result, I used the dataframe (dbf) of the intersect to create the presence absence matrix using the function sample2matrix in the R package picante. The 3 columns of the dataframe are:
> plots | abundance | species
>
> However, given the number of merged maps (over 200 overlapping polygons), the analysis in Arcmap got stalled and never proceed to completion.
> I will therefore like to do this in R.
> I will greatly appreciate any R code to help me do this.
>
> Thanks and kind regards
> Barnabas
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From darunabas at gmail.com  Thu Jan 23 21:05:49 2014
From: darunabas at gmail.com (Barnabas Daru)
Date: Thu, 23 Jan 2014 22:05:49 +0200
Subject: [R-sig-Geo] Creating presence/absence from grid cells & polygons
In-Reply-To: <CANtt_hyTbwS2fdGtbmP91rjK=8w6JoBMHLDTZ-gx8ozjikq0BQ@mail.gmail.com>
References: <427C1B61-D89E-4DFC-963E-B8343B3D25E9@gmail.com>
	<CANtt_hyTbwS2fdGtbmP91rjK=8w6JoBMHLDTZ-gx8ozjikq0BQ@mail.gmail.com>
Message-ID: <CA+R607EJ_8EPj+sUp0Jdzo89RfbHfcxmv6Pc4V3jnkMD+vWm=A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140123/496c0757/attachment.pl>

From ndcNS at hampshire.edu  Thu Jan 23 22:33:24 2014
From: ndcNS at hampshire.edu (Noah D. Charney)
Date: Thu, 23 Jan 2014 16:33:24 -0500
Subject: [R-sig-Geo] Converting OPeNDAP ASCIIs to rasters
Message-ID: <CAEogV+Taup6egH3Axugp9Pj0Fa=uEOCrk6qm8GKRHJ1SSJ58Ng@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140123/3a1a391d/attachment.pl>

From alobolistas at gmail.com  Fri Jan 24 09:34:10 2014
From: alobolistas at gmail.com (Agustin Lobo)
Date: Fri, 24 Jan 2014 09:34:10 +0100
Subject: [R-sig-Geo] raster::raster from SpatialPixelsDataFrame object
In-Reply-To: <52E136E0.2060100@uni-muenster.de>
References: <CAG4NReJ871AXH6c-j+BTUJ_mFMebb8WXCqMjkJnOj+L5kzaqzw@mail.gmail.com>
	<52E136E0.2060100@uni-muenster.de>
Message-ID: <CAG4NReLHpcq=j5CSBOdZ5WpAFpHx8JKKaM0qAT1o4L09j0Cyjg@mail.gmail.com>

Thanks.
It would be good having this documented in the help page of raster.
The closest is for
## S4 method for signature 'SpatialPixels'
raster(x, layer=1, values=TRUE)

which does not provide any clue for the case of SpatialPixelsDataFrame objects.
Another suggestion: a syntax similar to the one in rasterize() would
make sense for consistency,
ie. having the following
r <- raster(x=m, field="dist")

as a valid command also would be helpful for the user (similar syntax
for similar tasks is the only way to remember a language)

Agus

On Thu, Jan 23, 2014 at 4:36 PM, Edzer Pebesma
<edzer.pebesma at uni-muenster.de> wrote:
>
>
> On 01/23/2014 04:17 PM, Agustin Lobo wrote:
>> In order to convert a SpatialPixelsDataFrame object "m" into a raster I just do
>> data(meuse.grid)
>> m = SpatialPixelsDataFrame(points = meuse.grid[c("x", "y")], data = meuse.grid)
>> m at data <- data.frame(name="A",m at data)
>> r <- raster(m)
>>
>> but the actual values are taken from the first column as I'm not
>> selecting the numeric field in
>> the table.
>> Is there a way to select the field as in rasterize?
>
> you mean, like in:
>
> r <- raster(m[3])
>
> or
>
> r <- raster(m["ffreq"])
>
> ?
>
>>
>> r2 <- rasterize(x=m,y=r, field="dist")
>>
>> It would make sense doing this in just one command.
>>
>> Thanks
>>
>> Agus
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
> 83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From pauloeducardoso at gmail.com  Fri Jan 24 12:27:11 2014
From: pauloeducardoso at gmail.com (pecardoso)
Date: Fri, 24 Jan 2014 03:27:11 -0800 (PST)
Subject: [R-sig-Geo] writeRaster error: unknown file format
Message-ID: <1390562831848-7585627.post@n2.nabble.com>

I'm getting an error with writeRaster with apparent no particular reason.

The procedure I'm following:

*1. *reading an original landsat OLI band (TIF) downloaded from
http://earthexplorer.usgs.gov/

band <- raster(file.path(dir.work, 'LC81810682013122LGN01_B2.tif'), package
= "raster")

band
class       : RasterLayer 
dimensions  : 7311, 7521, 54986031  (nrow, ncol, ncell)
resolution  : 30, 30  (x, y)
extent      : 370485, 596115, -1388715, -1169385  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=utm +zone=33 +datum=WGS84 +units=m +no_defs +ellps=WGS84
+towgs84=0,0,0 
data source :
D:\Dropbox\Kumbira2010\Landsat\LC81810682013122LGN01\LC81810682013122LGN01_B2.tif 
names       : LC81810682013122LGN01_B2 
values      : 0, 65535  (min, max)

*2. *crop band to a given extent 
myext <- extent(c(416985, 425295, -1241505, -1226985))
cropb <- crop(band, myext)
dataType(cropb)
[1] "INT2U # just like the original

*3. *Write IDRISI raster file
writeRaster(band2.ae, filename = file.path(tempdir(),'cropb.rst'), format =
'IDRISI', overwrite = TRUE)

Error in .setFileExtensionHeader(filename, filetype) : 
  unknown file format

Running from RStudio Version 0.98.490 
> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-w64-mingw32/x64 (64-bit)

I get the same behaviour with raster 2.2-5 package 
locale:
[1] LC_COLLATE=Portuguese_Portugal.1252  LC_CTYPE=Portuguese_Portugal.1252   
[3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C                        
[5] LC_TIME=Portuguese_Portugal.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] rgdal_0.8-14  raster_2.2-12 sp_1.0-14    

loaded via a namespace (and not attached):
[1] grid_3.0.2      lattice_0.20-24 tools_3.0.2 




--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/writeRaster-error-unknown-file-format-tp7585627.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Fri Jan 24 13:34:17 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 24 Jan 2014 13:34:17 +0100
Subject: [R-sig-Geo] writeRaster error: unknown file format
In-Reply-To: <1390562831848-7585627.post@n2.nabble.com>
References: <1390562831848-7585627.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.03.1401241329090.12878@reclus.nhh.no>

On Fri, 24 Jan 2014, pecardoso wrote:

> I'm getting an error with writeRaster with apparent no particular reason.
>
> The procedure I'm following:
>
> *1. *reading an original landsat OLI band (TIF) downloaded from
> http://earthexplorer.usgs.gov/
>
> band <- raster(file.path(dir.work, 'LC81810682013122LGN01_B2.tif'), package
> = "raster")
>
> band
> class       : RasterLayer
> dimensions  : 7311, 7521, 54986031  (nrow, ncol, ncell)
> resolution  : 30, 30  (x, y)
> extent      : 370485, 596115, -1388715, -1169385  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=utm +zone=33 +datum=WGS84 +units=m +no_defs +ellps=WGS84
> +towgs84=0,0,0
> data source :
> D:\Dropbox\Kumbira2010\Landsat\LC81810682013122LGN01\LC81810682013122LGN01_B2.tif
> names       : LC81810682013122LGN01_B2
> values      : 0, 65535  (min, max)
>
> *2. *crop band to a given extent
> myext <- extent(c(416985, 425295, -1241505, -1226985))
> cropb <- crop(band, myext)
> dataType(cropb)
> [1] "INT2U # just like the original
>
> *3. *Write IDRISI raster file
> writeRaster(band2.ae, filename = file.path(tempdir(),'cropb.rst'), format =
> 'IDRISI', overwrite = TRUE)
>
> Error in .setFileExtensionHeader(filename, filetype) :
>  unknown file format

Did you follow the advice on:

?writeRaster

and run:

writeFormats()

to see which drivers are available on your platform? Hint:

http://www.gdal.org/formats_list.html

shows that the Idrisi raster format is called "RST".

Also, everything is always clearer when run in an R console interactively, 
not through R Studio. R Studio assumes that you know what you are doing 
when coding/scripting, something that doesn't apply to anyone I've met, 
especially including myself.

Hope this clarifies,

Roger

>
> Running from RStudio Version 0.98.490
>> sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> I get the same behaviour with raster 2.2-5 package
> locale:
> [1] LC_COLLATE=Portuguese_Portugal.1252  LC_CTYPE=Portuguese_Portugal.1252
> [3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C
> [5] LC_TIME=Portuguese_Portugal.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] rgdal_0.8-14  raster_2.2-12 sp_1.0-14
>
> loaded via a namespace (and not attached):
> [1] grid_3.0.2      lattice_0.20-24 tools_3.0.2
>
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/writeRaster-error-unknown-file-format-tp7585627.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From eddieatr at gmail.com  Fri Jan 24 16:00:57 2014
From: eddieatr at gmail.com (Eddie Smith)
Date: Fri, 24 Jan 2014 15:00:57 +0000
Subject: [R-sig-Geo] writeRaster error: unknown file format
In-Reply-To: <1390562831848-7585627.post@n2.nabble.com>
References: <1390562831848-7585627.post@n2.nabble.com>
Message-ID: <CABaJH78VGqsHof7uET8F-GwcXpPe+1sxamOO2-5a1OirW3+H=Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140124/42f6e9c9/attachment.pl>

From eddieatr at gmail.com  Fri Jan 24 16:02:21 2014
From: eddieatr at gmail.com (Eddie Smith)
Date: Fri, 24 Jan 2014 15:02:21 +0000
Subject: [R-sig-Geo] writeRaster error: unknown file format
In-Reply-To: <CABaJH78VGqsHof7uET8F-GwcXpPe+1sxamOO2-5a1OirW3+H=Q@mail.gmail.com>
References: <1390562831848-7585627.post@n2.nabble.com>
	<CABaJH78VGqsHof7uET8F-GwcXpPe+1sxamOO2-5a1OirW3+H=Q@mail.gmail.com>
Message-ID: <CABaJH79ANPtLyw9qLWGRH6dWsbGcKFATrDcu2BKs94t6Ze4xaA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140124/aac347af/attachment.pl>

From annagfoss at gmail.com  Fri Jan 24 16:05:29 2014
From: annagfoss at gmail.com (Annalisa Minelli)
Date: Fri, 24 Jan 2014 16:05:29 +0100
Subject: [R-sig-Geo] error in compiling rgdal 0.8-14
Message-ID: <CAHeOUhwzRvmawzsCus=yMB9xjXbKOBGMKe1uR2oKFjNLWyJfPQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140124/903dad1f/attachment.pl>

From pauloeducardoso at gmail.com  Fri Jan 24 16:53:13 2014
From: pauloeducardoso at gmail.com (pecardoso)
Date: Fri, 24 Jan 2014 07:53:13 -0800 (PST)
Subject: [R-sig-Geo] writeRaster error: unknown file format
In-Reply-To: <alpine.LRH.2.03.1401241329090.12878@reclus.nhh.no>
References: <1390562831848-7585627.post@n2.nabble.com>
	<alpine.LRH.2.03.1401241329090.12878@reclus.nhh.no>
Message-ID: <1390578793076-7585632.post@n2.nabble.com>

Hello all. Thanks for your time.

Robert, True about format, but 'IDRISI' file format is also there and I've
used format = 'IDRISI' ultil recently, and it was working just fine with
exactly the same procedure.

About running scripts from RStudio and R console, I'm not skilled enough to
understand the differences.

in my system, writeFormats() returns:

name        long_name                                
[1,] "raster"    "R-raster"                               
[2,] "SAGA"      "SAGA GIS"                               
[3,] "IDRISI"    "IDRISI"
...
[36,] "RST"       "Idrisi Raster A.1" 

With older versions of raster package, the argument format='IDRISI' also
produced 'IDRISI Raster A.1' files.

Latest version in fact is not accepting format = 'IDRISI' for the
RasterLayer created from reading the 16 bis Landsat TIF file and is
returning the error:
Error in .setFileExtensionHeader(filename, filetype) : unknown file format

Changing to format = 'RST' isn't better. I get the error:
Error in .local(.Object, ...) : Unable to create dataset

The behavior is the same running this from  within RStudio and from the R
console.

Maybe with the same data it would be better, or reproducible.

Here
<https://www.dropbox.com/s/is2td4t6uwc44fq/LC81810682013122LGN01_B2.TIF> 
the link to the landast image (107Mb).

For the resulting RasterLayer
GDALinfo('...\\LC81810682013122LGN01_B2.tif')
rows        7311 
columns     7521 
bands       1 
lower left origin.x        370485 
lower left origin.y        -1388715 
res.x       30 
res.y       30 
ysign       -1 
oblique.x   0 
oblique.y   0 
driver      GTiff 
projection  +proj=utm +zone=33 +datum=WGS84 +units=m +no_defs 
file        C:\Users\Strix\Downloads\LC81810682013122LGN01_B2.tif 
apparent band summary:
  GDType hasNoDataValue NoDataValue blockSize1 blockSize2
1 UInt16          FALSE           0          1       7521
apparent band statistics:
  Bmin  Bmax Bmean Bsd
1    0 65535    NA  NA
Metadata:
AREA_OR_POINT=Point 
Warning message:
statistics not supported by this driver

Eddie, I generally do not use setwd when sharing scripts with colleagues. I
usually define paths to some shared folder. It's not working anyway. From my
sessionInfo string you will se that I'm running rgdal.

Could it be something with rgdal (and gdal) installation after package
update? For a  similar problem
<http://r-sig-geo.2731867.n2.nabble.com/problem-with-writeRaster-and-GeoTIFF-format-td7583541.html>  
users suggests re-install of rgdal, gdal and its libraries.



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/writeRaster-error-unknown-file-format-tp7585627p7585632.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From annagfoss at gmail.com  Fri Jan 24 17:01:51 2014
From: annagfoss at gmail.com (Annalisa Minelli)
Date: Fri, 24 Jan 2014 17:01:51 +0100
Subject: [R-sig-Geo] error in compiling rgdal 0.8-14
In-Reply-To: <CAHeOUhwzRvmawzsCus=yMB9xjXbKOBGMKe1uR2oKFjNLWyJfPQ@mail.gmail.com>
References: <CAHeOUhwzRvmawzsCus=yMB9xjXbKOBGMKe1uR2oKFjNLWyJfPQ@mail.gmail.com>
Message-ID: <CAHeOUhwcPE6WOPDf6-PYMaJkDahWQwQi7j893iJYRrdUwjm03Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140124/1eed8c08/attachment.pl>

From Roger.Bivand at nhh.no  Fri Jan 24 17:41:08 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 24 Jan 2014 17:41:08 +0100
Subject: [R-sig-Geo] error in compiling rgdal 0.8-14
In-Reply-To: <CAHeOUhwcPE6WOPDf6-PYMaJkDahWQwQi7j893iJYRrdUwjm03Q@mail.gmail.com>
References: <CAHeOUhwzRvmawzsCus=yMB9xjXbKOBGMKe1uR2oKFjNLWyJfPQ@mail.gmail.com>
	<CAHeOUhwcPE6WOPDf6-PYMaJkDahWQwQi7j893iJYRrdUwjm03Q@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1401241739150.15688@reclus.nhh.no>

On Fri, 24 Jan 2014, Annalisa Minelli wrote:

> I correct myself anch close the task.

But a very useful heads-up, so that rgdal can be prepared for use with the 
development version of proj, so at its next release, rgdal should also 
support > 4.8.

Roger

> I was working on proj trunk  when I experienced this problem. I parallel
> have another installation where rgdal had no problem and it was compiled
> under PROJ 4.8 instead.
> So I downloaded and recompiled the proj 4.8, added the right paths and now
> it works.
>
> Sorry for the mail.
>
> Annalisa
>
>
> 2014/1/24 Annalisa Minelli <annagfoss at gmail.com>
>
>> Dear all,
>> I freshly compiled my SIG tools on my fresh linux installation (Ubuntu
>> 12.04 LTS).
>> I compiled GDAL and PROJ (v.4.9) too.
>> The problem is that when I install rgdal by package using the command:
>>
>> R CMD INSTALL --configure-args='--with-proj-include=/usr/local/includes/
>> --with-proj-lib=/usr/local/lib/proj --with-proj-share=/usr/share/proj/'
>> /home/infolab/Downloads/rgdal
>>
>> I receive the following error:
>>
>> ...
>> checking PROJ.4 Version 4.7 or earlier... no
>> configure: PROJ_LIB: /usr/share/proj/
>> proj_conf_test.c:3:7: error: conflicting types for 'pj_open_lib'
>> /usr/local/include/proj_api.h:146:8: note: previous declaration of
>> 'pj_open_lib' was here
>> ...
>>
>> so not only seems not to find PROJ library (despite of the arguments
>> passed), but it seems encoutering an internal conflict with the file
>> proj_api.h
>>
>> I compiled both proj and gdal, and no other conflicting copies are
>> installed (e.g. by package).
>>
>> Here there's the url to the complete output of the command:
>> http://pastebin.com/embed_iframe.php?i=KqhPyTiy
>>
>>
>> Any idea/suggestion is well accepted.
>> Annalisa
>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From tirth38 at gmail.com  Sat Jan 25 04:30:48 2014
From: tirth38 at gmail.com (Tirth Bhatta)
Date: Fri, 24 Jan 2014 22:30:48 -0500
Subject: [R-sig-Geo] Spatio-temporal data
Message-ID: <CAOxU+bUdJpao4-0-orKJWycgG3Gp7kveRUcLiUzj-m3VnTFhTw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140124/fbf78507/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Sat Jan 25 10:30:07 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sat, 25 Jan 2014 09:30:07 +0000
Subject: [R-sig-Geo] Spatio-temporal data
In-Reply-To: <e40ef404d2e0478aa57a37de47a16c63@EX-1-HT0.lancs.local>
References: <e40ef404d2e0478aa57a37de47a16c63@EX-1-HT0.lancs.local>
Message-ID: <CANVKczPnmv8tgwuEAKKNdk_hLOMLNtp+jr2=ZfZNH3U5WrrGGg@mail.gmail.com>

On Sat, Jan 25, 2014 at 3:30 AM, Tirth Bhatta <tirth38 at gmail.com> wrote:
> Hi Everyone,
>
> I am currently working on a dataset that requires me to incorporate space
> and time. Space (area--census tracts) is invariant, so change in my
> variable is occurring only in terms of time. I have a count variable (count
> of disease cases) followed over time. I know I can change it to rate and
> use Gaussian models. I was trying to find out, if there are any
> spatio-temporal models that allow me to use Poisson models. I may be wrong,
> but I could only find Bayesian spatial-temporal models. Am I making a
> correct assessment? If not, what R-packages would you recommend for me? I
> saw that R-INLA may also be used, but I am not sure if I can use predictors
> in the model?

 You seem to be putting the cart before the horse. There may be lots
of spatio-temporal models (and I could probably make up some more
before lunch) but will they answer the question you want answering?

 We don't know, because you've not told us what the question is! Do
you want to know if there's spatial variability? Space-time
clustering? Correlation with a covariate? Are some areas increasing
faster than others? Etc!

 There's no point trying to find out what statistical models have been
implemented unless we know what you are trying to find out from your
data.

Barry


From alxcart at gmail.com  Sat Jan 25 11:44:07 2014
From: alxcart at gmail.com (alxcart at gmail.com)
Date: Sat, 25 Jan 2014 10:44:07 -0000
Subject: [R-sig-Geo] =?utf-8?q?Sem_t=C3=ADtulo?=
Message-ID: <s322333913502916152000@gmail.com>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140125/bf3e5e78/attachment.html>

From tirth38 at gmail.com  Sat Jan 25 18:17:12 2014
From: tirth38 at gmail.com (Tirth Bhatta)
Date: Sat, 25 Jan 2014 12:17:12 -0500
Subject: [R-sig-Geo] Spatio-temporal data
In-Reply-To: <CANVKczPnmv8tgwuEAKKNdk_hLOMLNtp+jr2=ZfZNH3U5WrrGGg@mail.gmail.com>
References: <e40ef404d2e0478aa57a37de47a16c63@EX-1-HT0.lancs.local>
	<CANVKczPnmv8tgwuEAKKNdk_hLOMLNtp+jr2=ZfZNH3U5WrrGGg@mail.gmail.com>
Message-ID: <CAOxU+bXbb=-ELx5ggrQwy5XPv4r+wUv_hovoKmRZC+0re2KZew@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140125/99b2af16/attachment.pl>

From markpayneatwork at gmail.com  Mon Jan 27 11:40:20 2014
From: markpayneatwork at gmail.com (Mark Payne)
Date: Mon, 27 Jan 2014 11:40:20 +0100
Subject: [R-sig-Geo] sp::makegrid() bbox does not fully cover object
Message-ID: <CAGBzUO_rt6zF9Vk_zrHyBdUB1YC7j0TrumwMPTB0VFrO=cz7nA@mail.gmail.com>

Hi,

I have been playing with the makegrid function, and discovered
something interesting. For example, consider the domain of the meuse
data

> data(meuse)
> coordinates(meuse) <- ~x+y
> bbox(meuse)
     min    max
x 178605 181390
y 329714 333611

Now make a grid, and check its domain

> grd <- makegrid(meuse,cellsize=100)
> head(grd)
      x1     x2
1 180000 330000
2 180100 330000
3 180200 330000
4 180300 330000
5 180400 330000
6 180500 330000
> t(sapply(grd,range))  %Transposed to be in the same format as bbox()
     [,1]   [,2]
x1 180000 181300
x2 330000 333600


Note that the domain of the grid does not fully cover the meuse data
set. I won't call this a bug, but it was certaintly unexpected - I was
expecting the full domain to be covered by the grid - and this created
quite some problems around the edges of the polygon I am working with.

Is this by design? Could the addition of a full.coverage argument be
useful here, to give the user extra flexibility?

Mark


From edzer.pebesma at uni-muenster.de  Mon Jan 27 13:26:39 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 27 Jan 2014 13:26:39 +0100
Subject: [R-sig-Geo] sp::makegrid() bbox does not fully cover object
In-Reply-To: <CAGBzUO_rt6zF9Vk_zrHyBdUB1YC7j0TrumwMPTB0VFrO=cz7nA@mail.gmail.com>
References: <CAGBzUO_rt6zF9Vk_zrHyBdUB1YC7j0TrumwMPTB0VFrO=cz7nA@mail.gmail.com>
Message-ID: <52E6507F.80709@uni-muenster.de>



On 01/27/2014 11:40 AM, Mark Payne wrote:
> I won't call this a bug,

Definitely a bug; will look into it -- thanks for reporting!
-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 555 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140127/729a198f/attachment.bin>

From alobolistas at gmail.com  Mon Jan 27 14:13:13 2014
From: alobolistas at gmail.com (Agustin Lobo)
Date: Mon, 27 Jan 2014 14:13:13 +0100
Subject: [R-sig-Geo] Can coordinate intervals be not constant in
	SpatialPixelsDataFrame object??
Message-ID: <CAG4NReJaQJX1uWCG-EKOMtgMPkCJKCeGKgudz_vA08GxY1Y3jQ@mail.gmail.com>

Still doubts regarding the conversion to SpatialPixelsDataFrame-
I do:
load("https://dl.dropboxusercontent.com/u/3180464/delme.rda")
class(delme)
delmepx <- SpatialPixelsDataFrame(delme, data=delme at data, tolerance=0.000856898)
delmepol <- as(delmepx,"SpatialPolygonsDataFrame")
delmepx2 <- SpatialPixelsDataFrame(coordinates(delmepol), delmepol at data)
suggested tolerance minimum: 0.000635728
Error in points2grid(points, tolerance, round) :
  dimension 1 : coordinate intervals are not constant

I understand that I must set the tolerance value to create delmepx
because the coordinate intervals
in delme are not constant. But once I've made delmepx, the intervals
for the polygon centers of delmepol
should be constant because have been derived from a
SpatialPixelsDataFrame object. Yet I get the "coordinate intervals are
not constant" error.

This is not big deal in practice (can just keep delmepx), but wish to
understand.

Thanks

Agus


From edzer.pebesma at uni-muenster.de  Mon Jan 27 15:19:23 2014
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 27 Jan 2014 15:19:23 +0100
Subject: [R-sig-Geo] Can coordinate intervals be not constant in
 SpatialPixelsDataFrame object??
In-Reply-To: <CAG4NReJaQJX1uWCG-EKOMtgMPkCJKCeGKgudz_vA08GxY1Y3jQ@mail.gmail.com>
References: <CAG4NReJaQJX1uWCG-EKOMtgMPkCJKCeGKgudz_vA08GxY1Y3jQ@mail.gmail.com>
Message-ID: <52E66AEB.6060809@uni-muenster.de>



On 01/27/2014 02:13 PM, Agustin Lobo wrote:
> Still doubts regarding the conversion to SpatialPixelsDataFrame-
> I do:
> load("https://dl.dropboxusercontent.com/u/3180464/delme.rda")
> class(delme)
> delmepx <- SpatialPixelsDataFrame(delme, data=delme at data, tolerance=0.000856898)

SpatialPixelsDataFrame extend SpatialPointsDataFrame and hence contain
the coordinates of each pixel. You need to set the tolerance so it can
approximate the grid layout, which is not regular, but the original
coordinates are not changed. When you would do

fullgrid(delmepx)=TRUE

or alternatively

delmepx = as(delmepx, "SpatialGridDataFrame")

we no longer have pixels, and coordinates are implicit, and later on
derived from the grid layout -- meaning, they've changed.

After this, the error message you see later on vanishes.

Hth,


> delmepol <- as(delmepx,"SpatialPolygonsDataFrame")
> delmepx2 <- SpatialPixelsDataFrame(coordinates(delmepol), delmepol at data)
> suggested tolerance minimum: 0.000635728
> Error in points2grid(points, tolerance, round) :
>   dimension 1 : coordinate intervals are not constant
> 
> I understand that I must set the tolerance value to create delmepx
> because the coordinate intervals
> in delme are not constant. But once I've made delmepx, the intervals
> for the polygon centers of delmepol
> should be constant because have been derived from a
> SpatialPixelsDataFrame object. Yet I get the "coordinate intervals are
> not constant" error.
> 
> This is not big deal in practice (can just keep delmepx), but wish to
> understand.
> 
> Thanks
> 
> Agus
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany. Phone: +49 251
83 33081 http://ifgi.uni-muenster.de GPG key ID 0xAC227795

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 555 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140127/2b6fe289/attachment.bin>

From r.hijmans at gmail.com  Mon Jan 27 18:55:03 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Mon, 27 Jan 2014 09:55:03 -0800
Subject: [R-sig-Geo] writeRaster error: unknown file format
In-Reply-To: <1390578793076-7585632.post@n2.nabble.com>
References: <1390562831848-7585627.post@n2.nabble.com>
	<alpine.LRH.2.03.1401241329090.12878@reclus.nhh.no>
	<1390578793076-7585632.post@n2.nabble.com>
Message-ID: <CANtt_hyoQfvkY335jbuBb41mwJ5ohi1t+rH32PZ6h7SFbGTqVw@mail.gmail.com>

Paulo,

This has been fixed in raster 2.2-16 (development version). You can
install and try it:
install.packages("raster", repos="http://R-Forge.R-project.org")

Robert

On Fri, Jan 24, 2014 at 7:53 AM, pecardoso <pauloeducardoso at gmail.com> wrote:
> Hello all. Thanks for your time.
>
> Robert, True about format, but 'IDRISI' file format is also there and I've
> used format = 'IDRISI' ultil recently, and it was working just fine with
> exactly the same procedure.
>
> About running scripts from RStudio and R console, I'm not skilled enough to
> understand the differences.
>
> in my system, writeFormats() returns:
>
> name        long_name
> [1,] "raster"    "R-raster"
> [2,] "SAGA"      "SAGA GIS"
> [3,] "IDRISI"    "IDRISI"
> ...
> [36,] "RST"       "Idrisi Raster A.1"
>
> With older versions of raster package, the argument format='IDRISI' also
> produced 'IDRISI Raster A.1' files.
>
> Latest version in fact is not accepting format = 'IDRISI' for the
> RasterLayer created from reading the 16 bis Landsat TIF file and is
> returning the error:
> Error in .setFileExtensionHeader(filename, filetype) : unknown file format
>
> Changing to format = 'RST' isn't better. I get the error:
> Error in .local(.Object, ...) : Unable to create dataset
>
> The behavior is the same running this from  within RStudio and from the R
> console.
>
> Maybe with the same data it would be better, or reproducible.
>
> Here
> <https://www.dropbox.com/s/is2td4t6uwc44fq/LC81810682013122LGN01_B2.TIF>
> the link to the landast image (107Mb).
>
> For the resulting RasterLayer
> GDALinfo('...\\LC81810682013122LGN01_B2.tif')
> rows        7311
> columns     7521
> bands       1
> lower left origin.x        370485
> lower left origin.y        -1388715
> res.x       30
> res.y       30
> ysign       -1
> oblique.x   0
> oblique.y   0
> driver      GTiff
> projection  +proj=utm +zone=33 +datum=WGS84 +units=m +no_defs
> file        C:\Users\Strix\Downloads\LC81810682013122LGN01_B2.tif
> apparent band summary:
>   GDType hasNoDataValue NoDataValue blockSize1 blockSize2
> 1 UInt16          FALSE           0          1       7521
> apparent band statistics:
>   Bmin  Bmax Bmean Bsd
> 1    0 65535    NA  NA
> Metadata:
> AREA_OR_POINT=Point
> Warning message:
> statistics not supported by this driver
>
> Eddie, I generally do not use setwd when sharing scripts with colleagues. I
> usually define paths to some shared folder. It's not working anyway. From my
> sessionInfo string you will se that I'm running rgdal.
>
> Could it be something with rgdal (and gdal) installation after package
> update? For a  similar problem
> <http://r-sig-geo.2731867.n2.nabble.com/problem-with-writeRaster-and-GeoTIFF-format-td7583541.html>
> users suggests re-install of rgdal, gdal and its libraries.
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/writeRaster-error-unknown-file-format-tp7585627p7585632.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Mon Jan 27 19:00:59 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Mon, 27 Jan 2014 10:00:59 -0800
Subject: [R-sig-Geo] Creating presence/absence from grid cells & polygons
In-Reply-To: <CA+R607EJ_8EPj+sUp0Jdzo89RfbHfcxmv6Pc4V3jnkMD+vWm=A@mail.gmail.com>
References: <427C1B61-D89E-4DFC-963E-B8343B3D25E9@gmail.com>
	<CANtt_hyTbwS2fdGtbmP91rjK=8w6JoBMHLDTZ-gx8ozjikq0BQ@mail.gmail.com>
	<CA+R607EJ_8EPj+sUp0Jdzo89RfbHfcxmv6Pc4V3jnkMD+vWm=A@mail.gmail.com>
Message-ID: <CANtt_hw+xfN8U7aM84gebaSQejKHJexDEvi_yDOLRPu=LnKdXg@mail.gmail.com>

Barnabas,

In my example the IDs are the same as the rows on the data.frame (row
1 is cell 1, etc). Cells are numbered from left to right and then from
top to bottom. See
http://cran.r-project.org/web/packages/raster/vignettes/Raster.pdf
for more info

If you have merged your species polygons you can subset them within
the loop (i.e. iterate over the length of the polygons = iterating
over species)

It seems that your 'grid' consists of polygons that you are
intersecting with your species ranges. It is probably better to define
and use a raster as I showed. If you insist on the polygons-grid
route, you can use "intersect"; but that may fail; there was a reason
why ArcGIS crashed....  Here is a simple example:

library(raster)
# some example data
p1 <- Polygons(list(Polygon(rbind(c(-180,-20), c(-140,55), c(10, 0),
c(-140,-60), c(-180,-20)))), 1)
p2 <- Polygons(list(Polygon(rbind(c(-10,0), c(140,60), c(160,0),
c(140,-55), c(-10,0)))), 2)
p3 <- Polygons(list(Polygon(rbind(c(-125,0), c(0,60), c(40,5),
c(15,-45), c(-125,0)))), 3)
sp <- SpatialPolygons( list( p1 , p2, p3), proj4string=CRS('+proj=utm
+zone=1') )
sp <- SpatialPolygonsDataFrame(sp, data.frame(species=1:3))

r <- raster(ncol=90, nrow=45, crs='+proj=utm +zone=1')
p <- rasterToPolygons(r)
p$cell <- 1:ncell(r)
p$layer <- NULL

v <- intersect(sp, p)

m <- as.matrix(table(v$cell, v$species))
m[1:10, ]

Robert

Robert

On Thu, Jan 23, 2014 at 12:05 PM, Barnabas Daru <darunabas at gmail.com> wrote:
> Hi Robert
>
> Thanks very much for your reply and the code you provide. When I run the
> code, I could not get the rows to give me the IDs of the grid cells.
>
> In my case, I have two sets of data.
>
> The first set are polygons of several species distributions merged together
> with the attribute of the merged polygon representing the species names.
>
> The second set are the grid cells prepared in ArcMap and they are of fixed
> size, 50 by 50 km. Each grid has an ID and longitude/latitude locality. My
> aim is to know which species is present in each grid, thereby creating a
> presence/absence matrix where the columns are the names of the species in
> the merged file, and rows are the IDs of the grid cells.
>
> If it is OK by you, I can send you a subset of the data as shapefiles to see
> what I mean.
>
> Thanks and kind regards
>
> Barnabas Daru
>
>
>
> On Thu, Jan 23, 2014 at 8:51 PM, Robert J. Hijmans <r.hijmans at gmail.com>
> wrote:
>>
>> Here is an approach:
>>
>> library(raster)
>> p1 <- rbind(c(-180,-20), c(-140,55), c(10, 0), c(-140,-60), c(-180,-20))
>> hole <- rbind(c(-150,-20), c(-100,-10), c(-110,20), c(-150,-20))
>> sp1 <- SpatialPolygons(list(Polygons(list(Polygon(p1), Polygon(hole,
>> hole=TRUE)), 1)))
>> sp2 <- SpatialPolygons(list(Polygons(list(Polygon(rbind(c(-10,0),
>> c(140,60), c(160,0), c(140,-55), c(-10,0)))), 2)))
>> sp3 <- SpatialPolygons(list(Polygons(list(Polygon(rbind(c(-125,0),
>> c(0,60), c(40,5), c(15,-45), c(-125,0)))), 3)))
>>
>> species <- list(sp1, sp2, sp3)
>> r <- raster(ncol=90, nrow=45)
>>
>> rasters <- list()
>> for (i in 1:length(species)) {
>>    rasters[[i]] <- rasterize(species[[i]], r, field=1, background=0)
>> }
>> s <- stack(rasters)
>> x <- as.data.frame(s)
>>
>> # alternatively, look at 'over' in sp.
>>
>> ################
>>
>> # And this is how you might do it with shapefiles from a single directory
>> sps = list.files(pattern='.shp$')
>> # adjust raster to your taste (extent, resolution)
>> r <- raster(ncol=90, nrow=45)
>>
>> rasters <- list()
>> for (i in 1:length(sps)) {
>>    sp <- shapefile(sps[i])
>>    f <- extension(sp, '.grd')
>>    rasters[[i]] <- rasterize(species[[i]], r, field=1, background=0,
>> filename=f, overwrite=TRUE)
>> }
>> s <- stack(rasters)
>> x <- as.data.frame(s)
>>
>>
>> On Thu, Jan 23, 2014 at 3:53 AM, Barnabas Daru <darunabas at gmail.com>
>> wrote:
>> > Dear list members,
>> > I will like to create a presence/absence matrix using R where rows
>> > represent grid cells and columns species.
>> >
>> > I have a set of overlapping polygons each representing the distribution
>> > of different species and grid cells (also shapefiles generated using fishnet
>> > tool in ArcMap) to show presence or absence of species within the grid
>> > cells.
>> >
>> > In Arcmap, I was able to do this successfully for few species as
>> > follows:
>> > (1) I merged the polygons
>> > (2) I performed spatial intersect of the merged maps on the grid cells
>> > (3) From the result, I used the dataframe (dbf) of the intersect to
>> > create the presence absence matrix using the function sample2matrix in the R
>> > package picante. The 3 columns of the dataframe are:
>> > plots | abundance | species
>> >
>> > However, given the number of merged maps (over 200 overlapping
>> > polygons), the analysis in Arcmap got stalled and never proceed to
>> > completion.
>> > I will therefore like to do this in R.
>> > I will greatly appreciate any R code to help me do this.
>> >
>> > Thanks and kind regards
>> > Barnabas
>> >
>> > _______________________________________________
>> > R-sig-Geo mailing list
>> > R-sig-Geo at r-project.org
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
>
> --
>
>   \-/
>    /\
>   /--|
>  /---/ Daru, Barnabas Haruna
>  |--/  PhD Candidate,
>  \-/   African Centre for DNA Barcoding,
>  /\    University of Johannesburg,
> /--\   PO BOX 524 Auckland Park, 2006,
> |---\  South Africa
>  \---\ Lab: +27 11 559 3477
>   \--| Mobile: +27 7381 89 583
>    \-/
>    /\  My homepage: http://barnabasdaru.com
>   /--\
>
>


From noam.ross at gmail.com  Mon Jan 27 22:39:46 2014
From: noam.ross at gmail.com (Noam Ross)
Date: Mon, 27 Jan 2014 13:39:46 -0800
Subject: [R-sig-Geo] Replicating spatstat::pcfcross
Message-ID: <CA+Ygi5=TxarbRKvGe0ZbO=pcnzrv4Af=4x+u_wangnuAvKE3vw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140127/983b274d/attachment.pl>

From pauloeducardoso at gmail.com  Tue Jan 28 02:01:43 2014
From: pauloeducardoso at gmail.com (pecardoso)
Date: Mon, 27 Jan 2014 17:01:43 -0800 (PST)
Subject: [R-sig-Geo] writeRaster error: unknown file format
In-Reply-To: <CANtt_hyoQfvkY335jbuBb41mwJ5ohi1t+rH32PZ6h7SFbGTqVw@mail.gmail.com>
References: <1390562831848-7585627.post@n2.nabble.com>
	<alpine.LRH.2.03.1401241329090.12878@reclus.nhh.no>
	<1390578793076-7585632.post@n2.nabble.com>
	<CANtt_hyoQfvkY335jbuBb41mwJ5ohi1t+rH32PZ6h7SFbGTqVw@mail.gmail.com>
Message-ID: <CAF7LwDah2S6bswKPQMsYxTwaef_BVaah+k0THRJGWznhPBCSGg@mail.gmail.com>

Robert,

Thank you for your message. First thing, raster package is simply amazing.

I've installed raster v2.2-16.
I've imported the TIF from the dropbox link with

i.l8 <- raster('D:\\Dropbox\\Public\\LC81810682013122LGN01_B2.TIF',
               package = "raster")
> i.l8
class       : RasterLayer
dimensions  : 7311, 7521, 54986031  (nrow, ncol, ncell)
resolution  : 30, 30  (x, y)
extent      : 370485, 596115, -1388715, -1169385  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=utm +zone=33 +datum=WGS84 +units=m +no_defs
+ellps=WGS84 +towgs84=0,0,0
data source : D:\Dropbox\Public\LC81810682013122LGN01_B2.TIF
names       : LC81810682013122LGN01_B2
values      : 0, 65535  (min, max)

I'm also able to generate a RST file from the rasterLayer i.l8 with

writeRaster(band, filename = 'D:\\l8_b2.rst', format = 'IDRISI', overwrite
= TRUE)

IDRISI Taiga can read the RST file but the file format is tagged as "IDRISI
x A1" and not "IDRISI Raster A1"

I still not being able to generate the RST file with

writeRaster(band, filename = 'D:\\l8_b2.rst', format = 'RST', overwrite =
TRUE)

Error in .local(.Object, ...) : Unable to create dataset

But it works fine with writeGDAL:

writeGDAL(as(i.l8, "SpatialGridDataFrame"), fname = "D:\l8_gdal.rst",
drivername = "RST")

IDRISI Taiga read it and tag the file format as "IDRISI Raster A1", just
like the ones generated internally with import functions from IDRISI.

writeRaster with format = 'IDRISI' generetes a 230,732 MB idrisi file while
a 214,790 MB file is generated with writeGDAL and drivername = 'RST'

I can't figure out why.



Paulo Eduardo Cardoso



2014-01-27 Robert Hijmans [via R-sig-geo] <
ml-node+s2731867n7585643h37 at n2.nabble.com>

> Paulo,
>
> This has been fixed in raster 2.2-16 (development version). You can
> install and try it:
> install.packages("raster", repos="http://R-Forge.R-project.org")
>
> Robert
>
> On Fri, Jan 24, 2014 at 7:53 AM, pecardoso <[hidden email]<http://user/SendEmail.jtp?type=node&node=7585643&i=0>>
> wrote:
>
> > Hello all. Thanks for your time.
> >
> > Robert, True about format, but 'IDRISI' file format is also there and
> I've
> > used format = 'IDRISI' ultil recently, and it was working just fine with
> > exactly the same procedure.
> >
> > About running scripts from RStudio and R console, I'm not skilled enough
> to
> > understand the differences.
> >
> > in my system, writeFormats() returns:
> >
> > name        long_name
> > [1,] "raster"    "R-raster"
> > [2,] "SAGA"      "SAGA GIS"
> > [3,] "IDRISI"    "IDRISI"
> > ...
> > [36,] "RST"       "Idrisi Raster A.1"
> >
> > With older versions of raster package, the argument format='IDRISI' also
> > produced 'IDRISI Raster A.1' files.
> >
> > Latest version in fact is not accepting format = 'IDRISI' for the
> > RasterLayer created from reading the 16 bis Landsat TIF file and is
> > returning the error:
> > Error in .setFileExtensionHeader(filename, filetype) : unknown file
> format
> >
> > Changing to format = 'RST' isn't better. I get the error:
> > Error in .local(.Object, ...) : Unable to create dataset
> >
> > The behavior is the same running this from  within RStudio and from the
> R
> > console.
> >
> > Maybe with the same data it would be better, or reproducible.
> >
> > Here
> > <https://www.dropbox.com/s/is2td4t6uwc44fq/LC81810682013122LGN01_B2.TIF>
>
> > the link to the landast image (107Mb).
> >
> > For the resulting RasterLayer
> > GDALinfo('...\\LC81810682013122LGN01_B2.tif')
> > rows        7311
> > columns     7521
> > bands       1
> > lower left origin.x        370485
> > lower left origin.y        -1388715
> > res.x       30
> > res.y       30
> > ysign       -1
> > oblique.x   0
> > oblique.y   0
> > driver      GTiff
> > projection  +proj=utm +zone=33 +datum=WGS84 +units=m +no_defs
> > file        C:\Users\Strix\Downloads\LC81810682013122LGN01_B2.tif
> > apparent band summary:
> >   GDType hasNoDataValue NoDataValue blockSize1 blockSize2
> > 1 UInt16          FALSE           0          1       7521
> > apparent band statistics:
> >   Bmin  Bmax Bmean Bsd
> > 1    0 65535    NA  NA
> > Metadata:
> > AREA_OR_POINT=Point
> > Warning message:
> > statistics not supported by this driver
> >
> > Eddie, I generally do not use setwd when sharing scripts with
> colleagues. I
> > usually define paths to some shared folder. It's not working anyway.
> From my
> > sessionInfo string you will se that I'm running rgdal.
> >
> > Could it be something with rgdal (and gdal) installation after package
> > update? For a  similar problem
> > <
> http://r-sig-geo.2731867.n2.nabble.com/problem-with-writeRaster-and-GeoTIFF-format-td7583541.html>
>
> > users suggests re-install of rgdal, gdal and its libraries.
> >
> >
> >
> > --
> > View this message in context:
> http://r-sig-geo.2731867.n2.nabble.com/writeRaster-error-unknown-file-format-tp7585627p7585632.html
>
> > Sent from the R-sig-geo mailing list archive at Nabble.com.
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > [hidden email] <http://user/SendEmail.jtp?type=node&node=7585643&i=1>
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> [hidden email] <http://user/SendEmail.jtp?type=node&node=7585643&i=2>
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> ------------------------------
>  If you reply to this email, your message will be added to the discussion
> below:
>
> http://r-sig-geo.2731867.n2.nabble.com/writeRaster-error-unknown-file-format-tp7585627p7585643.html
>  To unsubscribe from writeRaster error: unknown file format, click here<http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=7585627&code=cGF1bG9lZHVjYXJkb3NvQGdtYWlsLmNvbXw3NTg1NjI3fDIxMDEwOTczNDM=>
> .
> NAML<http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>




--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/writeRaster-error-unknown-file-format-tp7585627p7585646.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From adrian.baddeley at uwa.edu.au  Tue Jan 28 05:39:21 2014
From: adrian.baddeley at uwa.edu.au (Adrian Baddeley)
Date: Tue, 28 Jan 2014 12:39:21 +0800
Subject: [R-sig-Geo] Replicating spatstat::pcfcross
In-Reply-To: <52E6EF39.1000904@auckland.ac.nz>
References: <CA+Ygi5=TxarbRKvGe0ZbO=pcnzrv4Af=4x+u_wangnuAvKE3vw@mail.gmail.com>,
	<52E6EF39.1000904@auckland.ac.nz>
Message-ID: <CF5661163F77A44781208D9AC4FDEA7226E8DF97B0@IS-WIN-376.staffad.uwa.edu.au>

On 28/01/14 10:39, Noam Ross wrote:

> I have an application for which I need very fast calculation of the pair
> correlation function between two point types in a marked point pattern.
> I'm attempting to replicate results from spatstat::pcfcross. I wrote a
> quick-and-dirty version of this function to ensure that I understood it

Oh, I *so* wanted to channel Brian Ripley there for a moment %^]

In the line 

 > cp$wt = A / (W - abs(cp$dx))*(H - abs(cp$dy))

you need to put parentheses around the denominator,
because a/b*c  is parsed as (a/b)*c. Because of this line, the weights are incorrect;
they are sometimes less than 1 (instead of being always > 1) which is 
causing most of the negative bias.

The sharp drop in the estimate at r ~~ rmax is caused by the line 
     cp <- closepairs(pp, rmax)
which restricts the calculation to pairs of points with distance <= rmax.
Contributions to the kernel estimate of pcf(rmax) can occur 
from interpoint distances slightly greater than rmax. In the call to closepairs()
you need to replace 'rmax' by 'rmax + kwide' where 'kwide' is the width 
of the support of the kernel.

There are several other idiosyncrasies (things that will only
work if the window is a rectangle, there are only two possible marks, etc)
but no other major problems.

Thank you for communicating this question. It has spurred me to get on with
implementing a faster version of pcfcross in 'spatstat'.

Adrian Baddeley
----

On 28/01/14 10:39, Noam Ross wrote:

> I have an application for which I need very fast calculation of the pair
> correlation function between two point types in a marked point pattern.
>
> I'm attempting to replicate results from spatstat::pcfcross.  I wrote a
> quick-and-dirty version of this function to ensure that I understood it
> properly before moving everything to C and optimizing for my particular
> application. However, I'm not quite getting the same results as with
> pcfcross.
>
> I note that, while pcfcross calculates the pcf for each mark type, then
> calculates the cross-pcf from those, I am calculating the cross-pcf
> directly from the distances between heterogeneous pairs. This seems like a
> more efficient approach when I am only interested in the latter. The
> resulting estimated pcf consistently lower than that from pcfcross at long
> distances, and sometimes very different from pcfcross near r=0.  What could
> account for this difference? Is it expected given the different methods?
>
> I've included the function below and an example plotting the spatstat and
> my own version against each other.
>
> #set.seed(0)
> library(spatstat)
> pp = rmpoispp(lambda=c(100,100), win=c(0,1,0,1), types=c("S", "I"))
>
> pcfcross2 <- function(pp, rmax = 0.25, stoyan = 0.15) {
>
>    #Generate distances between close pairs, limit only to heterogenous pairs
>    cp = closepairs(pp, rmax)
>    dups = duplicated(cp$d)
>    cp = lapply(cp, function(z) z[!dups])
>    Infected = as.integer(marks(pp) == "I")
>    SIpairs = which(Infected[cp$i] + Infected[cp$j] == 1)
>    cp = lapply(cp, function(z) z[SIpairs])
>
>    #ppp statistics
>    win = as.owin(pp)
>    H = diff(win$yrange)
>    W = diff(win$xrange)
>    A = H*W
>    lambda = sqrt(prod(intensity(pp))/A)
>
>    #calculate translational edge weights
>    cp$wt = A / (W - abs(cp$dx))*(H - abs(cp$dy))
>    wtot = sum(cp$wt)
>
>    #Density parameters and calculation
>    h <- stoyan/sqrt(pp$n/A)
>    bw <- h/sqrt(5)
>    dens = density.default(cp$d, weights=cp$wt/wtot, bw = bw,
>                           kernel="epanechnikov", from=0, to=rmax,
>                           n = 513)
>
>    #Scale to g(r)
>    r = dens$x
>    y = dens$y*wtot / (2*pi*r*lambda^2*A)
>    y[which(y==Inf)] = NA
>    return(data.frame(r=r, y=y))
> }
>
>
> pcf1 = pcfcross(pp, "S", "I", correction="translate")
> plot(pcf1)
> pcf2 = pcfcross2(pp)
> lines(pcf2, col="blue")


From milan.kili11 at gmail.com  Tue Jan 28 14:29:40 2014
From: milan.kili11 at gmail.com (Milan Kilibarda)
Date: Tue, 28 Jan 2014 14:29:40 +0100
Subject: [R-sig-Geo] Spatial and spatio-temporal modelling of meteorological
 and climatic variables using Open Source software (R + OSGeo)
Message-ID: <CAPSaU-8PKcdDfG3XU+bbQfYB9zN3Lt60KaMTxqZUjY44A5Oztg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140128/28a2f335/attachment.pl>

From jacqueline.schweizer at wuestundpartner.com  Tue Jan 28 16:08:06 2014
From: jacqueline.schweizer at wuestundpartner.com (Jacqueline Schweizer)
Date: Tue, 28 Jan 2014 16:08:06 +0100
Subject: [R-sig-Geo] Calculate distance along a path
Message-ID: <C76D1EE0-34CA-4142-9C96-8228DB359824@wuestundpartner.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140128/1027a0e9/attachment.pl>

From rafael.wueest at gmail.com  Tue Jan 28 16:14:33 2014
From: rafael.wueest at gmail.com (=?ISO-8859-1?Q?Rafael_W=FCest?=)
Date: Tue, 28 Jan 2014 16:14:33 +0100
Subject: [R-sig-Geo] Calculate distance along a path
In-Reply-To: <C76D1EE0-34CA-4142-9C96-8228DB359824@wuestundpartner.com>
References: <C76D1EE0-34CA-4142-9C96-8228DB359824@wuestundpartner.com>
Message-ID: <52E7C959.3020905@gmail.com>

http://rpubs.com/geospacedman/routing

could be a start...

Hope this helps,
Rafael


On 28.01.14 16:08, Jacqueline Schweizer wrote:
>
>
> Hi everybody,
>
> Eventually I am trying to calculate a grid, that represents the distance from each cell to the nearest bus stop. So for my area of interest, I have a grid showing the amount of meters  to the next stop. But I don't want to have the euclidean distance, I would like to calculate the distance along a path (streets, foot path etc.). I am ignoring elevation, so I will only have the horizontal walking distance. The calculation can be between the grid and the bus stop - points (raster to point) or between grid points and bus stop-points (point to point).
>
> I know that this is doable in ArcGIS, but since I am working in R and don't have the sufficient license in ArcGIS, I am trying to find out, whether it is possible in R. I already have checked out the package gdistance, but that only entails grid-calculations and wont follow along a path.
>
> Has anyone done something similar to this or has an input?
>
> Cheers,
> Jacqueline
>
> Disclaimer\ \ Die in dieser E-Mail enthaltenen Informati...{{dropped:27}}
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Rafael W?est
rafael.wueest at gmail.com
http://www.rowueest.net


From babadoncarlos at gmail.com  Tue Jan 28 16:37:39 2014
From: babadoncarlos at gmail.com (Don Carlos)
Date: Tue, 28 Jan 2014 16:37:39 +0100
Subject: [R-sig-Geo] rastervVis : adding point locations to a hovmoller plot
Message-ID: <CAFTQVoCbo0TD0R4O8h44vddNYWBo_FKE3WXg-PyxpkcnosCSbA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140128/e9d0dfe6/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Tue Jan 28 17:23:07 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 28 Jan 2014 16:23:07 +0000
Subject: [R-sig-Geo] Calculate distance along a path
In-Reply-To: <a1ce4902d1ba49c8a198af144e47bd50@EX-1-HT0.lancs.local>
References: <C76D1EE0-34CA-4142-9C96-8228DB359824@wuestundpartner.com>
	<a1ce4902d1ba49c8a198af144e47bd50@EX-1-HT0.lancs.local>
Message-ID: <CANVKczMGXXzAyVxTNZL67sP7iM6DPS9t+AQMEO+0YR-91JgGjw@mail.gmail.com>

On Tue, Jan 28, 2014 at 3:14 PM, Rafael W?est <rafael.wueest at gmail.com> wrote:
> http://rpubs.com/geospacedman/routing
>
> could be a start...
>
> Hope this helps,

 Looks good.

 You need three data sets - a line data set of the paths, a point data
set of the bus stops, and a point data set of the grids.

 From line data set you build a topological graph with distance as edge weights.

 Snap the bus stop and grid centres to the nearest point on a path.

 Do shortest-distance path search between grid cells and bus stops.

 It would be useful to know how complex your path network is, and how
many grid cells you want to do, and how many bus stops you have. But
in principle all the functions are there in the igraph, sp, and rgeos
packages (and a few others).

 R is a construction kit....

Barry


From j.garcia-pintado at reading.ac.uk  Tue Jan 28 18:31:57 2014
From: j.garcia-pintado at reading.ac.uk (Javier Garcia-Pintado)
Date: Tue, 28 Jan 2014 17:31:57 +0000
Subject: [R-sig-Geo] Calculate distance along a path
In-Reply-To: <CANVKczMGXXzAyVxTNZL67sP7iM6DPS9t+AQMEO+0YR-91JgGjw@mail.gmail.com>
References: <C76D1EE0-34CA-4142-9C96-8228DB359824@wuestundpartner.com>
	<a1ce4902d1ba49c8a198af144e47bd50@EX-1-HT0.lancs.local>,
	<CANVKczMGXXzAyVxTNZL67sP7iM6DPS9t+AQMEO+0YR-91JgGjw@mail.gmail.com>
Message-ID: <E82BBC061BBD7448BC7905721F497B07700E2BA9@vime-mbx5.rdg.ac.uk>

Hi Jaqueline,

Yes, as Barry indicates this can be well done in R. I've done that [using rgeos, sp & igraph] for assimilation of sparse selected satellite info [your busses] into 2d flood models in braided systems [your cells] which follow a predefined skeleton of connectivity (e.g. urban areas of a network of rural channels).

>From my experience the only I can add on top of what has been said is that building a graph including all points in the polylines you may have, may result in a daunting graph. I believe it will result in a much faster calculation to assume that each polyline is an edge bounded by two vertices [junctions between polylines], and embed the length of the polyline into the properties of the associated graph to obtain the shortest path between vertices as a preprocessing step. If, e.g. we say a node is any point in a polyline, and a vertex is just the starting or ending point of that polyline, then we would be further interested in getting between-node distances.

Specifically, you can obtain the nearest point in a path to your cells [this nearest point is not neccesarily an explicit node in an existing polyline, but could faill in a segment between consecutive points]. Then, this nearest  point has a "chainage" [a along-polyline distance from its starting vertex]. You can use that chainage to obtain the shortest along-network distance for points wich are not vertices in the graph, by using the previously igraph-calculated between-vertex shortest distances, and adding the "chainages". Note in this step there is a little more to think about the 4 or 5 possible shortest paths, but surely you'll come across it when you reach this point.

I've done all this in R and works beautifully.

Good luck,

Javier

---
Dr. Javier Garc?a-Pintado
National Centre for Earth Observation (ESSC-NCEO)
Data Assimilation Research Centre
School of Mathematical and Physical Sciences
University of Reading
Tel: +44(0)1183787722
j.garcia-pintado at reading.ac.uk
http://www.nceo.ac.uk/


________________________________________
From: r-sig-geo-bounces at r-project.org [r-sig-geo-bounces at r-project.org] on behalf of Barry Rowlingson [b.rowlingson at lancaster.ac.uk]
Sent: 28 January 2014 16:23
To: Rafael W?est
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] Calculate distance along a path

On Tue, Jan 28, 2014 at 3:14 PM, Rafael W?est <rafael.wueest at gmail.com> wrote:
> http://rpubs.com/geospacedman/routing
>
> could be a start...
>
> Hope this helps,

 Looks good.

 You need three data sets - a line data set of the paths, a point data
set of the bus stops, and a point data set of the grids.

 From line data set you build a topological graph with distance as edge weights.

 Snap the bus stop and grid centres to the nearest point on a path.

 Do shortest-distance path search between grid cells and bus stops.

 It would be useful to know how complex your path network is, and how
many grid cells you want to do, and how many bus stops you have. But
in principle all the functions are there in the igraph, sp, and rgeos
packages (and a few others).

 R is a construction kit....

Barry

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Nathaniel.L.Mikle-1 at ou.edu  Tue Jan 28 21:20:28 2014
From: Nathaniel.L.Mikle-1 at ou.edu (nate_m)
Date: Tue, 28 Jan 2014 12:20:28 -0800 (PST)
Subject: [R-sig-Geo] Breakpoint analysis with two variables
In-Reply-To: <CANtt_hz-qhKk1uYdQ6C7KxbDdmEUYE_dxN+BoEVJV1sjnO1nyw@mail.gmail.com>
References: <1390423738606-7585607.post@n2.nabble.com>
	<CANtt_hz-qhKk1uYdQ6C7KxbDdmEUYE_dxN+BoEVJV1sjnO1nyw@mail.gmail.com>
Message-ID: <1390940428080-7585654.post@n2.nabble.com>

Hi Robert,

Thanks for taking the time to provide suggestions. Below is what I've worked
out, and I can now retrieve variables from lm (in this case the two
coefficients), but can't figure out how to save an entire "lm object" for
each cell to feed into the "segmented" portion of my script. So basically,
I'm looking to somehow save an entire "lm object" in raster brick form to
then utilize in the next step (where library(segmented) begins). Any ideas?

library(raster)
x <- raster(nrow=10, ncol=10)
y <- raster(nrow=10, ncol=10)
r <- stack( sapply(1:11, function(i) setValues(x, rnorm(ncell(x), i, 3) )) )
s <- stack( sapply(1:11, function(i) setValues(y, rnorm(ncell(y), i, 3) )) )
z <- stack(r,s)
z[1] <- NA
fun <- function(x) { if (is.na(x)) { return(cbind(NA,NA)) } else lm(x[1:11]
~ x[12:22])$coefficients }

g2 <- calc(z, fun)
g2

library(segmented)
min_x <- calc(r, min)
fun2 <- function(x) { if (is.na(x)) { return(cbind(NA,NA,NA,NA)) } else
segmented(x, ~s, psi = min_x)$coefficients }

seg_g2 <- calc(g2, fun2)



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Breakpoint-analysis-with-two-variables-tp7585607p7585654.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From r.hijmans at gmail.com  Tue Jan 28 21:54:48 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 28 Jan 2014 12:54:48 -0800
Subject: [R-sig-Geo] Breakpoint analysis with two variables
In-Reply-To: <1390940428080-7585654.post@n2.nabble.com>
References: <1390423738606-7585607.post@n2.nabble.com>
	<CANtt_hz-qhKk1uYdQ6C7KxbDdmEUYE_dxN+BoEVJV1sjnO1nyw@mail.gmail.com>
	<1390940428080-7585654.post@n2.nabble.com>
Message-ID: <CANtt_hxCk5Ru30JSXY=jEiCVRk3hyC6gA4e1V3dT2Mvp-HFc-w@mail.gmail.com>

Nate,

I do not think you need to save the lm object. Instead you can write a
function that does the whole process. It appears your intention is
something like this:

fun <- function(x) {
    if ( is.na(x[1])  ) {  # or a variation on that such as  all(is.na(x))
         return( c(NA, NA,NA, NA) )
     } else {
         coef <- lm(x[1:11] ~ x[12:22])$coefficients
         segmented(coef, ~s, psi = min(x[1:11], na.rm=TRUE))$coefficients
     }
}


> z <- calc(z, fun)

Error in .calcTest(x[1:5], fun, na.rm, forcefun, forceapply) :
  cannot use this function

# That does not work, but that is probably because your call to
segmented in incorrect. The function should normally work for a single
cell (and that is how you can test it):

> d <-  z[10]
> fun(d)

Error in segmented.default(coef, ~s, psi = min(x[1:11], na.rm = TRUE)) :
  No default method for segmented

# or for a few cellls
> apply(d[1:5], 1, fun)
Error in apply(d[1:5], 1, fun) : dim(X) must have a positive length
>


Robert

On Tue, Jan 28, 2014 at 12:20 PM, nate_m <Nathaniel.L.Mikle-1 at ou.edu> wrote:
> Hi Robert,
>
> Thanks for taking the time to provide suggestions. Below is what I've worked
> out, and I can now retrieve variables from lm (in this case the two
> coefficients), but can't figure out how to save an entire "lm object" for
> each cell to feed into the "segmented" portion of my script. So basically,
> I'm looking to somehow save an entire "lm object" in raster brick form to
> then utilize in the next step (where library(segmented) begins). Any ideas?
>
> library(raster)
> x <- raster(nrow=10, ncol=10)
> y <- raster(nrow=10, ncol=10)
> r <- stack( sapply(1:11, function(i) setValues(x, rnorm(ncell(x), i, 3) )) )
> s <- stack( sapply(1:11, function(i) setValues(y, rnorm(ncell(y), i, 3) )) )
> z <- stack(r,s)
> z[1] <- NA
> fun <- function(x) { if (is.na(x)) { return(cbind(NA,NA)) } else lm(x[1:11]
> ~ x[12:22])$coefficients }
>
> g2 <- calc(z, fun)
> g2
>
> library(segmented)
> min_x <- calc(r, min)
> fun2 <- function(x) { if (is.na(x)) { return(cbind(NA,NA,NA,NA)) } else
> segmented(x, ~s, psi = min_x)$coefficients }
>
> seg_g2 <- calc(g2, fun2)
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Breakpoint-analysis-with-two-variables-tp7585607p7585654.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Tue Jan 28 21:57:29 2014
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 28 Jan 2014 12:57:29 -0800
Subject: [R-sig-Geo] writeRaster error: unknown file format
In-Reply-To: <CAF7LwDah2S6bswKPQMsYxTwaef_BVaah+k0THRJGWznhPBCSGg@mail.gmail.com>
References: <1390562831848-7585627.post@n2.nabble.com>
	<alpine.LRH.2.03.1401241329090.12878@reclus.nhh.no>
	<1390578793076-7585632.post@n2.nabble.com>
	<CANtt_hyoQfvkY335jbuBb41mwJ5ohi1t+rH32PZ6h7SFbGTqVw@mail.gmail.com>
	<CAF7LwDah2S6bswKPQMsYxTwaef_BVaah+k0THRJGWznhPBCSGg@mail.gmail.com>
Message-ID: <CANtt_hyUwkE-n2Tc13xO1Kh==p8hq7BS_AseER6A3QN9SZNSnQ@mail.gmail.com>

Paulo,

Thank you.

This has been fixed now on R-Forge. The problem was with the (new)
default (that I am starting to regret) of using FLT8S (64 bit floats)
for writing to files. IDRISI does not support that; this has now been
caught.
In the current version, something like this should work (explicitly
setting the data type):

writeRaster(band, filename = 'D:\\l8_b2.rst', format = 'RST',
datatype='FLT4S', overwrite =TRUE)

Robert

On Mon, Jan 27, 2014 at 5:01 PM, pecardoso <pauloeducardoso at gmail.com> wrote:
> Robert,
>
> Thank you for your message. First thing, raster package is simply amazing.
>
> I've installed raster v2.2-16.
> I've imported the TIF from the dropbox link with
>
> i.l8 <- raster('D:\\Dropbox\\Public\\LC81810682013122LGN01_B2.TIF',
>                package = "raster")
>> i.l8
> class       : RasterLayer
> dimensions  : 7311, 7521, 54986031  (nrow, ncol, ncell)
> resolution  : 30, 30  (x, y)
> extent      : 370485, 596115, -1388715, -1169385  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=utm +zone=33 +datum=WGS84 +units=m +no_defs
> +ellps=WGS84 +towgs84=0,0,0
> data source : D:\Dropbox\Public\LC81810682013122LGN01_B2.TIF
> names       : LC81810682013122LGN01_B2
> values      : 0, 65535  (min, max)
>
> I'm also able to generate a RST file from the rasterLayer i.l8 with
>
> writeRaster(band, filename = 'D:\\l8_b2.rst', format = 'IDRISI', overwrite
> = TRUE)
>
> IDRISI Taiga can read the RST file but the file format is tagged as "IDRISI
> x A1" and not "IDRISI Raster A1"
>
> I still not being able to generate the RST file with
>
> writeRaster(band, filename = 'D:\\l8_b2.rst', format = 'RST', overwrite =
> TRUE)
>
> Error in .local(.Object, ...) : Unable to create dataset
>
> But it works fine with writeGDAL:
>
> writeGDAL(as(i.l8, "SpatialGridDataFrame"), fname = "D:\l8_gdal.rst",
> drivername = "RST")
>
> IDRISI Taiga read it and tag the file format as "IDRISI Raster A1", just
> like the ones generated internally with import functions from IDRISI.
>
> writeRaster with format = 'IDRISI' generetes a 230,732 MB idrisi file while
> a 214,790 MB file is generated with writeGDAL and drivername = 'RST'
>
> I can't figure out why.
>
>
>
> Paulo Eduardo Cardoso
>
>
>
> 2014-01-27 Robert Hijmans [via R-sig-geo] <
> ml-node+s2731867n7585643h37 at n2.nabble.com>
>
>> Paulo,
>>
>> This has been fixed in raster 2.2-16 (development version). You can
>> install and try it:
>> install.packages("raster", repos="http://R-Forge.R-project.org")
>>
>> Robert
>>
>> On Fri, Jan 24, 2014 at 7:53 AM, pecardoso <[hidden email]<http://user/SendEmail.jtp?type=node&node=7585643&i=0>>
>> wrote:
>>
>> > Hello all. Thanks for your time.
>> >
>> > Robert, True about format, but 'IDRISI' file format is also there and
>> I've
>> > used format = 'IDRISI' ultil recently, and it was working just fine with
>> > exactly the same procedure.
>> >
>> > About running scripts from RStudio and R console, I'm not skilled enough
>> to
>> > understand the differences.
>> >
>> > in my system, writeFormats() returns:
>> >
>> > name        long_name
>> > [1,] "raster"    "R-raster"
>> > [2,] "SAGA"      "SAGA GIS"
>> > [3,] "IDRISI"    "IDRISI"
>> > ...
>> > [36,] "RST"       "Idrisi Raster A.1"
>> >
>> > With older versions of raster package, the argument format='IDRISI' also
>> > produced 'IDRISI Raster A.1' files.
>> >
>> > Latest version in fact is not accepting format = 'IDRISI' for the
>> > RasterLayer created from reading the 16 bis Landsat TIF file and is
>> > returning the error:
>> > Error in .setFileExtensionHeader(filename, filetype) : unknown file
>> format
>> >
>> > Changing to format = 'RST' isn't better. I get the error:
>> > Error in .local(.Object, ...) : Unable to create dataset
>> >
>> > The behavior is the same running this from  within RStudio and from the
>> R
>> > console.
>> >
>> > Maybe with the same data it would be better, or reproducible.
>> >
>> > Here
>> > <https://www.dropbox.com/s/is2td4t6uwc44fq/LC81810682013122LGN01_B2.TIF>
>>
>> > the link to the landast image (107Mb).
>> >
>> > For the resulting RasterLayer
>> > GDALinfo('...\\LC81810682013122LGN01_B2.tif')
>> > rows        7311
>> > columns     7521
>> > bands       1
>> > lower left origin.x        370485
>> > lower left origin.y        -1388715
>> > res.x       30
>> > res.y       30
>> > ysign       -1
>> > oblique.x   0
>> > oblique.y   0
>> > driver      GTiff
>> > projection  +proj=utm +zone=33 +datum=WGS84 +units=m +no_defs
>> > file        C:\Users\Strix\Downloads\LC81810682013122LGN01_B2.tif
>> > apparent band summary:
>> >   GDType hasNoDataValue NoDataValue blockSize1 blockSize2
>> > 1 UInt16          FALSE           0          1       7521
>> > apparent band statistics:
>> >   Bmin  Bmax Bmean Bsd
>> > 1    0 65535    NA  NA
>> > Metadata:
>> > AREA_OR_POINT=Point
>> > Warning message:
>> > statistics not supported by this driver
>> >
>> > Eddie, I generally do not use setwd when sharing scripts with
>> colleagues. I
>> > usually define paths to some shared folder. It's not working anyway.
>> From my
>> > sessionInfo string you will se that I'm running rgdal.
>> >
>> > Could it be something with rgdal (and gdal) installation after package
>> > update? For a  similar problem
>> > <
>> http://r-sig-geo.2731867.n2.nabble.com/problem-with-writeRaster-and-GeoTIFF-format-td7583541.html>
>>
>> > users suggests re-install of rgdal, gdal and its libraries.
>> >
>> >
>> >
>> > --
>> > View this message in context:
>> http://r-sig-geo.2731867.n2.nabble.com/writeRaster-error-unknown-file-format-tp7585627p7585632.html
>>
>> > Sent from the R-sig-geo mailing list archive at Nabble.com.
>> >
>> > _______________________________________________
>> > R-sig-Geo mailing list
>> > [hidden email] <http://user/SendEmail.jtp?type=node&node=7585643&i=1>
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> [hidden email] <http://user/SendEmail.jtp?type=node&node=7585643&i=2>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>> ------------------------------
>>  If you reply to this email, your message will be added to the discussion
>> below:
>>
>> http://r-sig-geo.2731867.n2.nabble.com/writeRaster-error-unknown-file-format-tp7585627p7585643.html
>>  To unsubscribe from writeRaster error: unknown file format, click here<http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=7585627&code=cGF1bG9lZHVjYXJkb3NvQGdtYWlsLmNvbXw3NTg1NjI3fDIxMDEwOTczNDM=>
>> .
>> NAML<http://r-sig-geo.2731867.n2.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>>
>
>
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/writeRaster-error-unknown-file-format-tp7585627p7585646.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From pauloeducardoso at gmail.com  Tue Jan 28 23:35:57 2014
From: pauloeducardoso at gmail.com (pecardoso)
Date: Tue, 28 Jan 2014 14:35:57 -0800 (PST)
Subject: [R-sig-Geo] writeRaster error: unknown file format
In-Reply-To: <CANtt_hyUwkE-n2Tc13xO1Kh==p8hq7BS_AseER6A3QN9SZNSnQ@mail.gmail.com>
References: <1390562831848-7585627.post@n2.nabble.com>
	<alpine.LRH.2.03.1401241329090.12878@reclus.nhh.no>
	<1390578793076-7585632.post@n2.nabble.com>
	<CANtt_hyoQfvkY335jbuBb41mwJ5ohi1t+rH32PZ6h7SFbGTqVw@mail.gmail.com>
	<CAF7LwDah2S6bswKPQMsYxTwaef_BVaah+k0THRJGWznhPBCSGg@mail.gmail.com>
	<CANtt_hyUwkE-n2Tc13xO1Kh==p8hq7BS_AseER6A3QN9SZNSnQ@mail.gmail.com>
Message-ID: <1390948557393-7585657.post@n2.nabble.com>

Robert,

Thank you for following this.

It is now able to write the RST object with signed integer datatype:

writeRaster(i.l8, filename = 'D:\\l8_b2.rst', format = 'RST', overwrite =
TRUE, datatype = "INT2S", NAflag = -9999)

I get the same error when i try to use unsigned "INT2U" data type of i.l8
object.

> dataType(i.l8)
[1] "INT2U"

Nonetheless, IDRISI Taiga can read the RST file and from the IDRISI file
Metadata all tags seems to be ok:

file format : Idrisi Raster A.1
file title  : 
data type   : integer
file type   : binary
columns     : 7521
rows        : 7311
ref. system : utm-33n
ref. units  : m
unit dist.  : 1

It is the first type writeRaster correctly assign the integer data type and
correctly assigning ref system (utm-33n in this particular case).

Fine.

One detail. I don't think this may influence sny further analysis using
other environments that not R but in fact, Landsat scenes are provided as
unsigned integer (8 or 16 bits).






--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/writeRaster-error-unknown-file-format-tp7585627p7585657.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From jacqueline.schweizer at wuestundpartner.com  Wed Jan 29 09:03:34 2014
From: jacqueline.schweizer at wuestundpartner.com (Jacqueline Schweizer)
Date: Wed, 29 Jan 2014 09:03:34 +0100
Subject: [R-sig-Geo] Calculate distance along a path
In-Reply-To: <E82BBC061BBD7448BC7905721F497B07700E2BA9@vime-mbx5.rdg.ac.uk>
References: <C76D1EE0-34CA-4142-9C96-8228DB359824@wuestundpartner.com>
	<a1ce4902d1ba49c8a198af144e47bd50@EX-1-HT0.lancs.local>,
	<CANVKczMGXXzAyVxTNZL67sP7iM6DPS9t+AQMEO+0YR-91JgGjw@mail.gmail.com>
	<E82BBC061BBD7448BC7905721F497B07700E2BA9@vime-mbx5.rdg.ac.uk>
Message-ID: <13C26C0B-A1F0-4B45-B665-44611667B732@wuestundpartner.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140129/1c0e1128/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Wed Jan 29 10:14:41 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 29 Jan 2014 09:14:41 +0000
Subject: [R-sig-Geo] Calculate distance along a path
In-Reply-To: <1312b6f832a64670b5620bd3e3811d44@EX-0-HT0.lancs.local>
References: <C76D1EE0-34CA-4142-9C96-8228DB359824@wuestundpartner.com>
	<a1ce4902d1ba49c8a198af144e47bd50@EX-1-HT0.lancs.local>
	<CANVKczMGXXzAyVxTNZL67sP7iM6DPS9t+AQMEO+0YR-91JgGjw@mail.gmail.com>
	<E82BBC061BBD7448BC7905721F497B07700E2BA9@vime-mbx5.rdg.ac.uk>
	<1312b6f832a64670b5620bd3e3811d44@EX-0-HT0.lancs.local>
Message-ID: <CANVKczNH3MnuU+fMj+T3gyvDKhq7G0x_P1Nr56GYSp5DtFah5A@mail.gmail.com>

On Wed, Jan 29, 2014 at 8:03 AM, Jacqueline Schweizer
<jacqueline.schweizer at wuestundpartner.com> wrote:
> Good morning,
>
> Thank you very much for the inputs!
>
> As for the amount of stops and scale of the area: eventually I would like to
> do this for the whole of Switzerland, probably in a 10m-Grid. That means
> there are about 50 Million grid cells. As for the stops, there will be
> around 24'000. As for the path-network I plan on using the
> OpenStreetMap-Layer for roads and footpath, so that is a fairly  large as
> well.

 I would definitely look at the `osmar` package which can read
OpenStreetMap vector data and convert it to a graph network. But
yikes, thats going to be a big network and a big grid. Possibly too
big a road network for R to handle unless you have ginormous amounts
of RAM in your machine.

 I think Javier's plan is as follows, and its a good one...

 You don't do any routing. What you do is construct a graph that
includes path vertices and bus stop vertices. Then for each path
vertex, construct the distance to the nearest bus stop vertex (should
be code for this in igraph). This is done in reverse, by an algorithm
that sets off 'walkers' from each bus stop, marking off the distance
travelled, until two walkers meet up when they stop. Once all the
walkers have met or reached dead ends, the process stops. Now you have
a path network with the distance to the nearest bus stop written on
each path vertex.

[Note no routing is required, this is what's called a `breadth first`
traverse of the graph (essentially at every fork in the road you send
two people off walking and reporting back the distance) as opposed to
a 'depth first' search which is where a single walker keeps going
until the end of the road then backtracks and tries all the forks yet
to be visited.]

Now you have a path network with distances, and you only have to find
the nearest point on the path network for each grid cell, and read off
the distance.

There's some interpolation needed where grid cells are near the centre
of a line segment, and similarly for bus stops so its not totally
straightforward, but should be a lot quicker than 50,000,000 routing
calculations, which will take two days at a rate of 10 routes per
second, assuming you can build the thing in RAM. How much RAM can you
rent for two days from Amazon?

I'm not certain this algorithm exists in igraph or elsewhere for R,
but I do think its a standard distance algorithm. MIght have a look
later.

It will be very useful to know how far the nearest bus stop is when
I'm on top of a mountain in the alps....

Barry


From j.garcia-pintado at reading.ac.uk  Wed Jan 29 10:53:03 2014
From: j.garcia-pintado at reading.ac.uk (Javier Garcia-Pintado)
Date: Wed, 29 Jan 2014 09:53:03 +0000
Subject: [R-sig-Geo] Calculate distance along a path
In-Reply-To: <13C26C0B-A1F0-4B45-B665-44611667B732@wuestundpartner.com>
References: <C76D1EE0-34CA-4142-9C96-8228DB359824@wuestundpartner.com>
	<a1ce4902d1ba49c8a198af144e47bd50@EX-1-HT0.lancs.local>,
	<CANVKczMGXXzAyVxTNZL67sP7iM6DPS9t+AQMEO+0YR-91JgGjw@mail.gmail.com>
	<E82BBC061BBD7448BC7905721F497B07700E2BA9@vime-mbx5.rdg.ac.uk>,
	<13C26C0B-A1F0-4B45-B665-44611667B732@wuestundpartner.com>
Message-ID: <E82BBC061BBD7448BC7905721F497B07700E2C6D@vime-mbx5.rdg.ac.uk>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140129/7d2ebbf0/attachment.html>

From j.garcia-pintado at reading.ac.uk  Wed Jan 29 11:18:48 2014
From: j.garcia-pintado at reading.ac.uk (Javier Garcia-Pintado)
Date: Wed, 29 Jan 2014 10:18:48 +0000
Subject: [R-sig-Geo] Calculate distance along a path
In-Reply-To: <CANVKczNH3MnuU+fMj+T3gyvDKhq7G0x_P1Nr56GYSp5DtFah5A@mail.gmail.com>
References: <C76D1EE0-34CA-4142-9C96-8228DB359824@wuestundpartner.com>
	<a1ce4902d1ba49c8a198af144e47bd50@EX-1-HT0.lancs.local>
	<CANVKczMGXXzAyVxTNZL67sP7iM6DPS9t+AQMEO+0YR-91JgGjw@mail.gmail.com>
	<E82BBC061BBD7448BC7905721F497B07700E2BA9@vime-mbx5.rdg.ac.uk>
	<1312b6f832a64670b5620bd3e3811d44@EX-0-HT0.lancs.local>,
	<CANVKczNH3MnuU+fMj+T3gyvDKhq7G0x_P1Nr56GYSp5DtFah5A@mail.gmail.com>
Message-ID: <E82BBC061BBD7448BC7905721F497B07700E2C9F@vime-mbx5.rdg.ac.uk>

Hi Barry.

Thanks! Very good input!

I completely agree. They need to think about their specific requirements. In our case we needed to know the distance from any location to all "buses" (out satellite info), for our data assimilation problems.

Jaqueline, 
I also dont know about any published function in R to obtain the closest point [be it a node or in the middle of a segment] in a SpatialLinesDataFrame to a given point/s, but it could be out there. FYI, the function I had to build for this relies on rotations of the segments. Note for many intermediate steps you may store results in binary matrices, and then access them later as required.

Cheers,
Javier

---
Dr. Javier Garc?a-Pintado
National Centre for Earth Observation (ESSC-NCEO)
Data Assimilation Research Centre
School of Mathematical and Physical Sciences
University of Reading
Tel: +44(0)1183787722
j.garcia-pintado at reading.ac.uk
http://www.nceo.ac.uk/


________________________________________
From: b.rowlingson at gmail.com [b.rowlingson at gmail.com] on behalf of Barry Rowlingson [b.rowlingson at lancaster.ac.uk]
Sent: 29 January 2014 09:14
To: Jacqueline Schweizer
Cc: Javier Garcia-Pintado; Rafael W?est; r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] Calculate distance along a path

On Wed, Jan 29, 2014 at 8:03 AM, Jacqueline Schweizer
<jacqueline.schweizer at wuestundpartner.com> wrote:
> Good morning,
>
> Thank you very much for the inputs!
>
> As for the amount of stops and scale of the area: eventually I would like to
> do this for the whole of Switzerland, probably in a 10m-Grid. That means
> there are about 50 Million grid cells. As for the stops, there will be
> around 24'000. As for the path-network I plan on using the
> OpenStreetMap-Layer for roads and footpath, so that is a fairly  large as
> well.

 I would definitely look at the `osmar` package which can read
OpenStreetMap vector data and convert it to a graph network. But
yikes, thats going to be a big network and a big grid. Possibly too
big a road network for R to handle unless you have ginormous amounts
of RAM in your machine.

 I think Javier's plan is as follows, and its a good one...

 You don't do any routing. What you do is construct a graph that
includes path vertices and bus stop vertices. Then for each path
vertex, construct the distance to the nearest bus stop vertex (should
be code for this in igraph). This is done in reverse, by an algorithm
that sets off 'walkers' from each bus stop, marking off the distance
travelled, until two walkers meet up when they stop. Once all the
walkers have met or reached dead ends, the process stops. Now you have
a path network with the distance to the nearest bus stop written on
each path vertex.

[Note no routing is required, this is what's called a `breadth first`
traverse of the graph (essentially at every fork in the road you send
two people off walking and reporting back the distance) as opposed to
a 'depth first' search which is where a single walker keeps going
until the end of the road then backtracks and tries all the forks yet
to be visited.]

Now you have a path network with distances, and you only have to find
the nearest point on the path network for each grid cell, and read off
the distance.

There's some interpolation needed where grid cells are near the centre
of a line segment, and similarly for bus stops so its not totally
straightforward, but should be a lot quicker than 50,000,000 routing
calculations, which will take two days at a rate of 10 routes per
second, assuming you can build the thing in RAM. How much RAM can you
rent for two days from Amazon?

I'm not certain this algorithm exists in igraph or elsewhere for R,
but I do think its a standard distance algorithm. MIght have a look
later.

It will be very useful to know how far the nearest bus stop is when
I'm on top of a mountain in the alps....

Barry


From Roger.Bivand at nhh.no  Wed Jan 29 11:46:16 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 29 Jan 2014 11:46:16 +0100
Subject: [R-sig-Geo] Calculate distance along a path
In-Reply-To: <E82BBC061BBD7448BC7905721F497B07700E2C9F@vime-mbx5.rdg.ac.uk>
References: <C76D1EE0-34CA-4142-9C96-8228DB359824@wuestundpartner.com>
	<a1ce4902d1ba49c8a198af144e47bd50@EX-1-HT0.lancs.local>
	<CANVKczMGXXzAyVxTNZL67sP7iM6DPS9t+AQMEO+0YR-91JgGjw@mail.gmail.com>
	<E82BBC061BBD7448BC7905721F497B07700E2BA9@vime-mbx5.rdg.ac.uk>
	<1312b6f832a64670b5620bd3e3811d44@EX-0-HT0.lancs.local>,
	<CANVKczNH3MnuU+fMj+T3gyvDKhq7G0x_P1Nr56GYSp5DtFah5A@mail.gmail.com>
	<E82BBC061BBD7448BC7905721F497B07700E2C9F@vime-mbx5.rdg.ac.uk>
Message-ID: <alpine.LRH.2.03.1401291132060.28321@reclus.nhh.no>

On Wed, 29 Jan 2014, Javier Garcia-Pintado wrote:

> Hi Barry.
>
> Thanks! Very good input!
>
> I completely agree. They need to think about their specific 
> requirements. In our case we needed to know the distance from any 
> location to all "buses" (out satellite info), for our data assimilation 
> problems.
>
> Jaqueline,
> I also dont know about any published function in R to obtain the closest 
> point [be it a node or in the middle of a segment] in a 
> SpatialLinesDataFrame to a given point/s, but it could be out there.

maptools::snapPointsToLines by Germ?n Carrillo - please use SVN 
revision 279 from R-Forge until the next maptools release.

library(sp)
library(rgeos)
l1 <- readWKT("LINESTRING(0 0, 1 1)")
set.seed(1)
pts <- SpatialPoints(cbind(runif(5), runif(5)))
plot(l1, axes=TRUE)
points(pts)
text(coordinates(pts), labels=row.names(pts), pos=4)
library(maptools)
res <- snapPointsToLines(pts, l1)
points(res, pch=16, col="red")
text(coordinates(res), labels=row.names(res), pos=4, col="red")

Roger


> FYI, the function I had to build for this relies on rotations of the 
> segments. Note for many intermediate steps you may store results in 
> binary matrices, and then access them later as required.
>
> Cheers,
> Javier
>
> ---
> Dr. Javier Garc?a-Pintado
> National Centre for Earth Observation (ESSC-NCEO)
> Data Assimilation Research Centre
> School of Mathematical and Physical Sciences
> University of Reading
> Tel: +44(0)1183787722
> j.garcia-pintado at reading.ac.uk
> http://www.nceo.ac.uk/
>
>
> ________________________________________
> From: b.rowlingson at gmail.com [b.rowlingson at gmail.com] on behalf of Barry Rowlingson [b.rowlingson at lancaster.ac.uk]
> Sent: 29 January 2014 09:14
> To: Jacqueline Schweizer
> Cc: Javier Garcia-Pintado; Rafael W?est; r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] Calculate distance along a path
>
> On Wed, Jan 29, 2014 at 8:03 AM, Jacqueline Schweizer
> <jacqueline.schweizer at wuestundpartner.com> wrote:
>> Good morning,
>>
>> Thank you very much for the inputs!
>>
>> As for the amount of stops and scale of the area: eventually I would like to
>> do this for the whole of Switzerland, probably in a 10m-Grid. That means
>> there are about 50 Million grid cells. As for the stops, there will be
>> around 24'000. As for the path-network I plan on using the
>> OpenStreetMap-Layer for roads and footpath, so that is a fairly  large as
>> well.
>
> I would definitely look at the `osmar` package which can read
> OpenStreetMap vector data and convert it to a graph network. But
> yikes, thats going to be a big network and a big grid. Possibly too
> big a road network for R to handle unless you have ginormous amounts
> of RAM in your machine.
>
> I think Javier's plan is as follows, and its a good one...
>
> You don't do any routing. What you do is construct a graph that
> includes path vertices and bus stop vertices. Then for each path
> vertex, construct the distance to the nearest bus stop vertex (should
> be code for this in igraph). This is done in reverse, by an algorithm
> that sets off 'walkers' from each bus stop, marking off the distance
> travelled, until two walkers meet up when they stop. Once all the
> walkers have met or reached dead ends, the process stops. Now you have
> a path network with the distance to the nearest bus stop written on
> each path vertex.
>
> [Note no routing is required, this is what's called a `breadth first`
> traverse of the graph (essentially at every fork in the road you send
> two people off walking and reporting back the distance) as opposed to
> a 'depth first' search which is where a single walker keeps going
> until the end of the road then backtracks and tries all the forks yet
> to be visited.]
>
> Now you have a path network with distances, and you only have to find
> the nearest point on the path network for each grid cell, and read off
> the distance.
>
> There's some interpolation needed where grid cells are near the centre
> of a line segment, and similarly for bus stops so its not totally
> straightforward, but should be a lot quicker than 50,000,000 routing
> calculations, which will take two days at a rate of 10 routes per
> second, assuming you can build the thing in RAM. How much RAM can you
> rent for two days from Amazon?
>
> I'm not certain this algorithm exists in igraph or elsewhere for R,
> but I do think its a standard distance algorithm. MIght have a look
> later.
>
> It will be very useful to know how far the nearest bus stop is when
> I'm on top of a mountain in the alps....
>
> Barry
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From ryanmurphyri at gmail.com  Wed Jan 29 23:34:58 2014
From: ryanmurphyri at gmail.com (Ryan Murphy)
Date: Wed, 29 Jan 2014 14:34:58 -0800
Subject: [R-sig-Geo] describing variance within/between spatial clusters
Message-ID: <CAN1oVSfGjwqX03J8vhJhnvfuNBFff1UYAavb2UZNV4wH_Opc7g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140129/e4833ad8/attachment.pl>

From lareina.laflair at gmail.com  Thu Jan 30 04:27:14 2014
From: lareina.laflair at gmail.com (Lareina La Flair)
Date: Wed, 29 Jan 2014 22:27:14 -0500
Subject: [R-sig-Geo] Moran's I Weight Matrix in R (error: objects of
	different length)
Message-ID: <CAJXq52mVA7HVORGYRDy1=JsNQxzBf-CH=LGqeSwsRLLKatct2Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140129/bd428fe6/attachment.pl>

From Roger.Bivand at nhh.no  Thu Jan 30 08:42:35 2014
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 30 Jan 2014 08:42:35 +0100
Subject: [R-sig-Geo] Moran's I Weight Matrix in R (error: objects of
 different length)
In-Reply-To: <CAJXq52mVA7HVORGYRDy1=JsNQxzBf-CH=LGqeSwsRLLKatct2Q@mail.gmail.com>
References: <CAJXq52mVA7HVORGYRDy1=JsNQxzBf-CH=LGqeSwsRLLKatct2Q@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1401300822590.9210@reclus.nhh.no>

On Thu, 30 Jan 2014, Lareina La Flair wrote:

> Good evening,
>
> I'm new to spatial analysis R and therefore to this group but am thankful
> for any level of feedback on my question that follows.  I've encountered an
> error in calculating Moran's I using the spdep package in R and am unable
> to isolate the problem on my own:
>
> *Error in moran.test(AODED$adcount/AODED$POP100, nb2listw(BC_nb, style =
> "B")) : objects of different length*
>
> How might I begin solving this problem?
>
> My code, adapted from prior posts on this subject:
>
> *# load data for 70 area units*
>
> *AODED<-read.csv("AODEDlags_R.csv",header=TRUE)
> *
>
>
> *BC <- readShapePoly("StudyareaZC11.shp") *
>
> *# create a weight matrix*
>
> *BC_nb <- poly2nb(as(BC, "SpatialPolygons"))
> X <- nb2mat(BC_nb,zero.policy=TRUE)
> n<-length(BC_nb)
> *
>
> *Nbr.matrix<-matrix(0,n,n) for(i in 1:n) *
>
> *  Nbr.matrix[i,BC_nb[[i]]]<-1**> BC_nb*
>
> I have 70 area units, yet the weight matrix counts 71:
>
> *Neighbour list object:*
> *Number of regions: 71 *
> *Number of nonzero links: 320 *
> *Percentage nonzero weights: 6.347947 *
> *Average number of links: 4.507042 *

The very odd appearance of your posting is caused by rendering from 
(forbidden) HTML. Only post plain text, please - HTML postings can contain 
malicious payloads and are not permitted).

If you have 71 entities in BC, you'll get 71 regions in BC_nb for obvious 
reasons. You should combine the attribute data object with the geometries 
- see the vignette in the maptools package:

library(maptools)
vignette("combine_maptools")

In this way, you should be able to work out which of your 70 observations 
in AODED match the 71 geometries in BC (hopefully you have unique IDs in 
both the CSV and the shapefile that can be matched). You are the only 
person who can do this, as a random deletion of a geometry by the software 
(to make things easier) doesn't make any sense.

>
> Any insights on this problem and/or references to prior posts are welcome.

Prior posts may not be any guidance unless you understand what they are 
doing. You references to nb2mat, and your very odd if() loop suggest that 
you have to try to understand harder, as the steps involving X and 
Nbr.matrix are neither clear (maybe the HTML problem) nor necessary. If 
you refer to a prior post, do include its unique URL, preferably by thread 
from:

https://stat.ethz.ch/pipermail/r-sig-geo/

so that we can see what you are referring to. Reading the help pages of 
the functions carefully is also always sensible. Always also check the 
sizes of input objects; doing:

dim(BC)
dim(AODED)

after reading them would have alerted you to the size problem. Usually 
also look at the output of summary() of input objects (also maybe str() or 
head() for non-Spatial objects), to be sure that they are what you think 
they are.

Hope this helps,

Roger

> Thank you.
>
> Respectfully,
> Lareina
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From oscar.perpinan at upm.es  Thu Jan 30 10:44:39 2014
From: oscar.perpinan at upm.es (Oscar =?utf-8?B?UGVycGnDscOhbg==?= Lamigueiro)
Date: Thu, 30 Jan 2014 10:44:39 +0100
Subject: [R-sig-Geo] rastervVis : adding point locations to a hovmoller
	plot
In-Reply-To: <CAFTQVoCbo0TD0R4O8h44vddNYWBo_FKE3WXg-PyxpkcnosCSbA@mail.gmail.com>
References: <CAFTQVoCbo0TD0R4O8h44vddNYWBo_FKE3WXg-PyxpkcnosCSbA@mail.gmail.com>
Message-ID: <87d2j94xdk.fsf@upm.es>

Hello, 

The easiest solution is using the +.trellis function provided by the
latticeExtra package (automatically loaded with rasterVis). I have
modified a bit your example to show the usage:

idx <- seq(as.Date('2008-01-15'), as.Date('2008-3-15'), 'month')
SISmm <- setZ(St, idx)
hov <- hovmoller(SISmm, contour=FALSE, panel=panel.levelplot.raster,
                 yscale.components=yscale.raster.subticks,
                 interpolate=TRUE,
                 par.settings=RdBuTheme)

#location data in decimal degrees. these are the points I want to add onto the hovmoller plot
x <- c(50 , 25, 0)
date <- as.Date(c('2008-01-15', '2008-02-15','2008-03-15'))
loc <- data.frame(x, date)

## Here we use +.trellis to overlay the points
hov + xyplot(date ~ x, data=loc)

Best,

Oscar.

Don Carlos writes:

> Dear r sig geo users,
>
> I trying to add location points (longitude-time) onto a hovmoller plot
> (rasterVis). These are locations of objects at given longitude and time.
>
> An example of what I want to do here
>
> library("rasterVis")
> library("lattice")
> r <- raster(nrows=10, ncols=10)
> r <- setValues(r, 1:ncell(r))
> r1 <- raster(nrows=10, ncols=10)
> r1 <- setValues(r1, 1:ncell(r))
> r2 <- raster(nrows=10, ncols=10)
> r2 <- setValues(r2, 1:ncell(r))
> St=stack(r,r1,r2)
> idx <- seq(as.Date('2008-01-15'), as.Date('2008-1-17'), 'day')
> SISmm <- setZ(St, idx)
> hov<-hovmoller(SISmm, contour=FALSE, panel=panel.levelplot.raster,
> yscale.components=yscale.
> raster.subticks,interpolate=TRUE,
> par.settings=RdBuTheme)
>
> #location data in decimal degrees. these are the points I want to add onto
> the hovmoller plot
> x<-c(50.00000,25.00000,0.00000)
> date<-as.Date('2008-01-15', '2008-01-15','2008-01-17')
> loc<-data.frame(x,date)
>
> #attempt to overlay the location onto the hov plot. This is clearly not the
> correct approach but I am still at the very bottom of the R learning
> curve...
> plot(hov, position=c(0,0,1,1))
> plot(loc,position=c(0,0,1,1),newpage=F)
>
> Thankful for any pointers or suggestions.
>
> Regards,
>
> Don
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


-- 
Oscar Perpi??n Lamigueiro
Dpto. Ingenier?a El?ctrica (ETSIDI-UPM)
Grupo de Sistemas Fotovoltaicos (IES-UPM)
URL: http://oscarperpinan.github.io
Twitter: @oscarperpinan


From jgrn at illinois.edu  Fri Jan 31 03:25:58 2014
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Thu, 30 Jan 2014 20:25:58 -0600
Subject: [R-sig-Geo] gdalUtils update
Message-ID: <CABG0rfuqPGVHPrKw6K4nuyk7=qsFBuDp4O=qqU_cBdeCvYz-0Q@mail.gmail.com>

r-sig-geo'ers:

gdalUtils 0.3.1 is now up on CRAN -- this should fix issues some of
you were having getting the utility to find your installation of GDAL
correctly.  Let me know if there are any remaining issues!

--j

-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From mspinola10 at gmail.com  Fri Jan 31 23:13:42 2014
From: mspinola10 at gmail.com (=?ISO-8859-1?Q?Manuel_Sp=EDnola?=)
Date: Fri, 31 Jan 2014 16:13:42 -0600
Subject: [R-sig-Geo] writeRaster do not take the coordinate reference from
	the raster
Message-ID: <CABkCotTPshHu4SXuanLhX_i-jFHiyZYr-PKJbGeEsKnLvX_Gfg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140131/c88aff9c/attachment.pl>

