From r.turner at auckland.ac.nz  Sun Apr  1 01:06:07 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 1 Apr 2018 11:06:07 +1200
Subject: [R-sig-Geo] 
 [FORGED]  Estimate of the intensity of a point process,
 as a function of a marked point process as covariate.
In-Reply-To: <f56bf85a-30d9-2977-7dd3-2af7171bfcff@yahoo.com.br>
References: <f56bf85a-30d9-2977-7dd3-2af7171bfcff@yahoo.com.br>
Message-ID: <57a567dc-1278-86a6-09ce-a40492e49727@auckland.ac.nz>


On 01/04/18 09:36, ASANTOS via R-sig-Geo wrote:

> Dear R Sig Geo Members,
> 
>  ??? I've like to know if there are any function in any package for 
> estimation density in a marked point process (e.g. geographic position 
> and size of ants nests in square meters). My goal will be represents the 
> density of ants nest estimated, but use nests sizes as covariate, this 
> is possible?

The Smooth.ppp() function in the spatstat package might be what you are 
looking for.

Using nest sizes as a *covariate* does not make sense to me.  A 
covariate should be defined at all points of the observation window, not 
just at the points of the observed pattern.

See

   Adrian Baddeley, Ege Rubak, Rolf Turner (2015). Spatial Point
   Patterns: Methodology and Applications with R. London: Chapman and
   Hall/CRC Press, 2015. URL
 
http://www.crcpress.com/Spatial-Point-Patterns-Methodology-and-Applications-with-R/Baddeley-Rubak-Turner/9781482210200/

particularly section 5.6.4, pages 147, 148.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From alexandresantosbr at yahoo.com.br  Mon Apr  2 02:02:40 2018
From: alexandresantosbr at yahoo.com.br (ASANTOS)
Date: Sun, 1 Apr 2018 20:02:40 -0400
Subject: [R-sig-Geo] 
 [FORGED]  Estimate of the intensity of a point process,
 as a function of a marked point process as covariate.
In-Reply-To: <57a567dc-1278-86a6-09ce-a40492e49727@auckland.ac.nz>
References: <f56bf85a-30d9-2977-7dd3-2af7171bfcff@yahoo.com.br>
 <57a567dc-1278-86a6-09ce-a40492e49727@auckland.ac.nz>
Message-ID: <18bdc29d-2aef-5c4b-0636-b8e4ecc95610@yahoo.com.br>

Thanks a lot Dr. Turner, I will read it.

Best wishes,

Alexandre

-- 
======================================================================
Alexandre dos Santos
Prote??o Florestal
IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
Campus C?ceres
Caixa Postal 244
Avenida dos Ramires, s/n
Bairro: Distrito Industrial
C?ceres - MT                      CEP: 78.200-000
Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)

         alexandre.santos at cas.ifmt.edu.br
Lattes: http://lattes.cnpq.br/1360403201088680
OrcID: orcid.org/0000-0001-8232-6722
Researchgate: www.researchgate.net/profile/Alexandre_Santos10
LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
======================================================================

Em 31/03/2018 19:06, Rolf Turner escreveu:
>
> On 01/04/18 09:36, ASANTOS via R-sig-Geo wrote:
>
>> Dear R Sig Geo Members,
>>
>> ???? I've like to know if there are any function in any package for 
>> estimation density in a marked point process (e.g. geographic 
>> position and size of ants nests in square meters). My goal will be 
>> represents the density of ants nest estimated, but use nests sizes as 
>> covariate, this is possible?
>
> The Smooth.ppp() function in the spatstat package might be what you 
> are looking for.
>
> Using nest sizes as a *covariate* does not make sense to me.? A 
> covariate should be defined at all points of the observation window, 
> not just at the points of the observed pattern.
>
> See
>
> ? Adrian Baddeley, Ege Rubak, Rolf Turner (2015). Spatial Point
> ? Patterns: Methodology and Applications with R. London: Chapman and
> ? Hall/CRC Press, 2015. URL
>
> http://www.crcpress.com/Spatial-Point-Patterns-Methodology-and-Applications-with-R/Baddeley-Rubak-Turner/9781482210200/ 
>
>
> particularly section 5.6.4, pages 147, 148.
>
> cheers,
>
> Rolf Turner
>


From Jin.Li at ga.gov.au  Wed Apr  4 01:07:01 2018
From: Jin.Li at ga.gov.au (Li Jin)
Date: Tue, 3 Apr 2018 23:07:01 +0000
Subject: [R-sig-Geo] xgboost: problems with predictions for count data
 [SEC=UNCLASSIFIED]
Message-ID: <fee9e7bf759746128860d2d393a019cb@win-exch-prod01.prod.lan>

Hi All,

I tried to use xgboost to model and predict count data. The predictions are however not as expected as shown below.
# sponge count data in library(spm)
    library(spm)
data(sponge)
data(sponge.grid)
names(sponge)
[1] "easting"  "northing" "sponge"   "tpi3"     "var7"     "entro7"   "bs34"     "bs11"
names(sponge.grid)
[1] "easting"  "northing" "tpi3"     "var7"     "entro7"   "bs34"     "bs11"
    range(sponge[, c(3)])
[1]  1 39 # count sample data

# the expected predictions are:
set.seed(1234)
gbmpred1 <- gbmpred(sponge[, -c(3)], sponge[, 3], sponge.grid[, c(1:2)], sponge.grid, family = "poisson", n.cores=2)
range(gbmpred1$Predictions)
[1] 10.04643 31.39230 # the expected predictions

# Here are results from xgboost
# use count:poisson
library(xgboost)
    xgbst2.1 <- xgboost(data = as.matrix(sponge[, -c(3)]), label = sponge[, 3], max_depth = 2, eta = 0.001, nthread = 6, nrounds = 3000, objective = "count:poisson")
    xgbstpred2 <- predict(xgbst2.1, as.matrix(sponge.grid))
head(xgbstpred2)
range(xgbstpred2)
[1] 1.109032 4.083049 # much lower than expected
    table(xgbstpred2)
                1.10903215408325 1.26556181907654   3.578040599823 4.08304929733276  # only four predictions, why?
                36535             2714            40930            15351

   plot(gbmpred1$Predictions, xgbstpred2)

   # use reg:linear
    xgbst2.2 <- xgboost(data = as.matrix(sponge[, -c(3)]), label = sponge[, 3], max_depth = 2, eta = 0.001, nthread = 6, nrounds = 3000, objective = "reg:linear")
    xgbstpred2.2 <- predict(xgbst2.2, as.matrix(sponge.grid))
    head(xgbstpred2.2)
    table(xgbstpred2.2)
    range( xgbstpred2.2)
[1]  9.019174 23.060669 # this is much closer to but still lower than what expected

   plot(gbmpred1$Predictions, xgbstpred2.2)

# use count:poisson and subsample = 0.5
set.seed(1234)
    param <- list(max_depth = 2, eta = 0.001, gamma = 0.001, subsample = 0.5, silent = 1, nthread = 6, objective = "count:poisson")
    xgbst2.4 <- xgboost(data = as.matrix(sponge[, -c(3)]), label = sponge[, 3], params = param, nrounds = 3000)
    xgbstpred2.4 <- predict(xgbst2.4, as.matrix(sponge.grid))
    head(xgbstpred2.4)
    table(xgbstpred2.4)
    range(xgbstpred2.4)
[1] 1.188561 3.986767 # this is much lower than what expected

   plot(gbmpred1$Predictions, xgbstpred2.4)
  plot(xgbstpred2.2, xgbstpred2.4)

All these were run in R 3.3.3 on Windows"
> Sys.info()
                     sysname                      release
                   "Windows"                      "7 x64"
                     version
"build 7601, Service Pack 1"
                     machine
                    "x86-64"

Have I miss-specified or missed some parameters? Or there is a bug in xgboost. I am grateful for any help.

Kind regards,
Jin

Jin Li, PhD | Spatial Modeller / Computational Statistician
National Earth and Marine Observations | Environmental Geoscience Division
t:  +61 2 6249 9899    www.ga.gov.au<http://www.ga.gov.au/>

Geoscience Australia Disclaimer: This e-mail (and files transmitted with it) is intended only for the person or entity to which it is addressed. If you are not the intended recipient, then you have received this e-mail by mistake and any use, dissemination, forwarding, printing or copying of this e-mail and its file attachments is prohibited. The security of emails transmitted cannot be guaranteed; by forwarding or replying to this email, you acknowledge and accept these risks.
-------------------------------------------------------------------------------------------------------------------------


	[[alternative HTML version deleted]]


From julian.burgos at hafogvatn.is  Wed Apr  4 12:17:44 2018
From: julian.burgos at hafogvatn.is (Julian M. Burgos)
Date: Wed, 04 Apr 2018 10:17:44 +0000
Subject: [R-sig-Geo] Terrain Analysis
In-Reply-To: <51a1f2ce-6460-e052-a124-469c684929f3@umn.edu>
References: <51a1f2ce-6460-e052-a124-469c684929f3@umn.edu>
Message-ID: <xgztvsrxol3.fsf@hafogvatn.is>

Richard, the natural option is the "raster" package.  You may also want
to consider the "star" package, which is in early stages of developing.

https://www.rdocumentation.org/packages/stars/versions/0.1-1

Julian

Richard Barnes writes:

> I am thinking of building an R wrapper for my RichDEM raster terrain
> analysis library (https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Frichdem.readthedocs.io%2Fen%2Flatest%2F&data=02%7C01%7C%7C3869a031682740ec8e6208d59687202f%7C8e105b94435e4303a61063620dbe162b%7C0%7C1%7C636580429486153526&sdata=7uWjSqbS%2FPyyu3y9vTKyH7FyAapiEyoHfbcGAYhKSMg%3D&reserved=0).
>
> The library's been designed in C++ with this in mind. The only
> requirement is the ability to pass pointers to raw POD arrays to the
> library.
>
> My question is: which R package would be best to use for storing/loading
> raster data?
>
> Best regards,
> Richard Barnesc
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=02%7C01%7C%7C3869a031682740ec8e6208d59687202f%7C8e105b94435e4303a61063620dbe162b%7C0%7C1%7C636580429486153526&sdata=Eg3uk2etdcXW1VGIqIHTwI4UX7D92%2BfJmWDiIudv8Ds%3D&reserved=0


--
Julian Mariano Burgos, PhD
Hafranns?knastofnun, ranns?kna- og r??gjafarstofnun hafs og vatna/
Marine and Freshwater Research Institute
Botnsj?varsvi?s / Demersal Division
Sk?lagata 4, 121 Reykjav?k, Iceland
S?mi/Telephone : +354-5752037
Br?fs?mi/Telefax:  +354-5752001
Netfang/Email: julian.burgos at hafogvatn.is


From yalassefa at gmail.com  Thu Apr  5 05:44:59 2018
From: yalassefa at gmail.com (Yalemzewod Gelaw)
Date: Thu, 5 Apr 2018 13:44:59 +1000
Subject: [R-sig-Geo] help
Message-ID: <CAFoeBZm2dpUp76fXTDyPgYjn0B9WEaoNUNBEcoryUuTJtX7Y7g@mail.gmail.com>

I am a new student to R learning for spatial analysis. I was hoping someone
could help me with the
error message I keep getting when I try to convert the neighbour data to a
listw object use the nb2listw()  function.

plot(xw_nbq, coords,add=TRUE,col="red")> summary(xw_nbq)


Neighbour list object:
Number of regions: 140
Number of nonzero links: 680
Percentage nonzero weights: 3.469388
Average number of links: 4.857143
2 regions with no links:
3 138
Link number distribution:

 0  1  2  3  4  5  6  7  8  9
 2  6  4 16 32 35 17 13 13  2
6 least connected regions:
11 32 57 117 124 137 with 1 link
2 most connected regions:
28 71 with 9 links

?when I try to run nb2listw, i got repated error following the below error
message. ?

xlist <- nb2listw(neighbours,glist = NULL,style = "W",zero.policy
=TRU) > summary.listw(xlist)
Error in summary.listw(xlist) : regions with no neighbours found, use
zero.policy=TRUE

I wonder if someone advises me how to fix the error message from my working
directory
?


*Regards, *

Yalem

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20180405/ea70cb24/attachment.html>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot.png
Type: image/png
Size: 14965 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20180405/ea70cb24/attachment.png>

From M.Boer at westernsydney.edu.au  Thu Apr  5 09:38:31 2018
From: M.Boer at westernsydney.edu.au (Matthias Boer)
Date: Thu, 5 Apr 2018 07:38:31 +0000
Subject: [R-sig-Geo] netcdf data from Antarctica in rotated latlong - how to
 reproject to normal geographical coordinate system
Message-ID: <ME1PR01MB1044D60D3EDB249FBBC27A48B3BB0@ME1PR01MB1044.ausprd01.prod.outlook.com>

Hi all

I am having trouble extracting some climate time series for a series of field sites in Antarctica from a netcdf file with a rotated pole projection. The file (gridded monthly temperatures for 1979-2016) includes these details about the projection:
float rotated_pole[]
            grid_mapping_name: rotated_latitude_longitude
            grid_north_pole_latitude: -180
            grid_north_pole_longitude: -150
            proj4_params: -m 57.295779506 +proj=ob_tran +o_proj=latlon +o_lat_p=-180.0 +lon_0=30.0
            proj_parameters: -m 57.295779506 +proj=ob_tran +o_proj=latlon +o_lat_p=-180.0 +lon_0=30.0
            projection_name: rotated_latitude_longitude
            long_name: projection details
            EPSG_code:

I can read the netcdf file into R:
tst.s <- stack("filename.nc", varname="var1")

but this gives a couple of warnings that raster can't understand the projection:
Warning messages:
1: In .stackCDF(x, varname = varname, bands = bands) :
  tskin has 4 dimensions, I am using the last one
2: In .getCRSfromGridMap4(atts) : cannot process these parts of the CRS:
grid_north_pole_latitude=-180; grid_north_pole_longitude=-150; proj4_params=-m 57.295779506 +proj=ob_tran +o_proj=latlon +o_lat_p=-180.0 +lon_0=30.0; proj_parameters=-m 57.295779506 +proj=ob_tran +o_proj=latlon +o_lat_p=-180.0 +lon_0=30.0; projection_name=rotated_latitude_longitude; long_name=projection details; EPSG_code=
3: In .getCRSfromGridMap4(atts) : cannot create a valid CRS
grid_north_pole_latitude=-180; grid_north_pole_longitude=-150; proj4_params=-m 57.295779506 +proj=ob_tran +o_proj=latlon +o_lat_p=-180.0 +lon_0=30.0; proj_parameters=-m 57.295779506 +proj=ob_tran +o_proj=latlon +o_lat_p=-180.0 +lon_0=30.0; projection_name=rotated_latitude_longitude; long_name=projection details; EPSG_code=


Could anyone point me to some code to assign the correct CRS to the imported stack 'tst.s' and then to project it to the 'normal' geographical coordinate system, so I can extract time series for the field site coordinates which are in 'normal' latlong.

Thanks a lot for your time.

Cheers,
Matthias



------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Dr. Matthias M Boer
Hawkesbury Institute for the Environment<http://www.westernsydney.edu.au/hie> | Western Sydney University | Hawkesbury Campus, Richmond, NSW 2753, AUSTRALIA
P: +61-(0)2-4570-1373 (direct) | P: +61-(0)2-4570-1941 (admin) | E: m.boer at westernsydney.edu.au

Postal address: Locked Bag 1797 | Penrith, NSW 2751, AUSTRALIA
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Thu Apr  5 09:49:56 2018
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 5 Apr 2018 09:49:56 +0200
Subject: [R-sig-Geo] help
In-Reply-To: <CAFoeBZm2dpUp76fXTDyPgYjn0B9WEaoNUNBEcoryUuTJtX7Y7g@mail.gmail.com>
References: <CAFoeBZm2dpUp76fXTDyPgYjn0B9WEaoNUNBEcoryUuTJtX7Y7g@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.1804050941240.26268@reclus.nhh.no>

On Thu, 5 Apr 2018, Yalemzewod Gelaw wrote:

> I am a new student to R learning for spatial analysis. I was hoping someone
> could help me with the
> error message I keep getting when I try to convert the neighbour data to a
> listw object use the nb2listw()  function.
>
> plot(xw_nbq, coords,add=TRUE,col="red")> summary(xw_nbq)
>
>
> Neighbour list object:
> Number of regions: 140
> Number of nonzero links: 680
> Percentage nonzero weights: 3.469388
> Average number of links: 4.857143
> 2 regions with no links:
> 3 138
> Link number distribution:
>
> 0  1  2  3  4  5  6  7  8  9
> 2  6  4 16 32 35 17 13 13  2
> 6 least connected regions:
> 11 32 57 117 124 137 with 1 link
> 2 most connected regions:
> 28 71 with 9 links
>
> ?when I try to run nb2listw, i got repated error following the below error
> message. ?
>
> xlist <- nb2listw(neighbours,glist = NULL,style = "W",zero.policy
> =TRU) > summary.listw(xlist)
> Error in summary.listw(xlist) : regions with no neighbours found, use
> zero.policy=TRUE

Please do not send HTML-formatted messages.

You need to continue using zero.policy=TRUE when using an object created 
with no-neighbour observations. You can also set a pre-session global 
option using set.ZeroPolicyOption(TRUE), which is checked first in 
functions using the zero.policy= argument. set.ZeroPolicyOption(TRUE) 
outputs the value of get.ZeroPolicyOption() before making the change.

You should always find out why you have no-neighbour observations. From 
your attached image, it looks as though you have a faulty set of polygons, 
and have used poly2nb() to find border contiguities. My guess is that the 
polygons with no neighbours have borders that almost touch - look at the 
snap= argument in poly2nb(). There are also other near-contiguities to be 
found - had the input boundaries been line-generalized?

Roger

>
> I wonder if someone advises me how to fix the error message from my working
> directory
> ?
>
>
> *Regards, *
>
> Yalem
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From Roger.Bivand at nhh.no  Thu Apr  5 10:03:59 2018
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 5 Apr 2018 10:03:59 +0200
Subject: [R-sig-Geo] 
 netcdf data from Antarctica in rotated latlong - how to
 reproject to normal geographical coordinate system
In-Reply-To: <ME1PR01MB1044D60D3EDB249FBBC27A48B3BB0@ME1PR01MB1044.ausprd01.prod.outlook.com>
References: <ME1PR01MB1044D60D3EDB249FBBC27A48B3BB0@ME1PR01MB1044.ausprd01.prod.outlook.com>
Message-ID: <alpine.LFD.2.21.1804050957430.26268@reclus.nhh.no>

On Thu, 5 Apr 2018, Matthias Boer wrote:

> Hi all
>
> I am having trouble extracting some climate time series for a series of field sites in Antarctica from a netcdf file with a rotated pole projection. The file (gridded monthly temperatures for 1979-2016) includes these details about the projection:
> float rotated_pole[]
>            grid_mapping_name: rotated_latitude_longitude
>            grid_north_pole_latitude: -180
>            grid_north_pole_longitude: -150

>            proj4_params: -m 57.295779506 +proj=ob_tran +o_proj=latlon 
> +o_lat_p=-180.0 +lon_0=30.0

>            proj_parameters: -m 57.295779506 +proj=ob_tran +o_proj=latlon 
> +o_lat_p=-180.0 +lon_0=30.0

>            projection_name: rotated_latitude_longitude
>            long_name: projection details
>            EPSG_code:
>
> I can read the netcdf file into R:
> tst.s <- stack("filename.nc", varname="var1")

You'll need to look for the arguments supporting +proj=ob_tran 
(use_ob_tran=) in rgdal::spTransform(). +proj=ob_tran is a complete mess, 
and until the next release of GDAL, the GDAL netcdf driver will not 
understand these either. Your best bet may be not to warp the input grids, 
but to transform the field sites point coordinates to ob_tran to extract 
the data you need (checking that the transformation seems sensible).

Roger

>
> but this gives a couple of warnings that raster can't understand the projection:
> Warning messages:
> 1: In .stackCDF(x, varname = varname, bands = bands) :
>  tskin has 4 dimensions, I am using the last one
> 2: In .getCRSfromGridMap4(atts) : cannot process these parts of the CRS:
> grid_north_pole_latitude=-180; grid_north_pole_longitude=-150; proj4_params=-m 57.295779506 +proj=ob_tran +o_proj=latlon +o_lat_p=-180.0 +lon_0=30.0; proj_parameters=-m 57.295779506 +proj=ob_tran +o_proj=latlon +o_lat_p=-180.0 +lon_0=30.0; projection_name=rotated_latitude_longitude; long_name=projection details; EPSG_code=
> 3: In .getCRSfromGridMap4(atts) : cannot create a valid CRS
> grid_north_pole_latitude=-180; grid_north_pole_longitude=-150; proj4_params=-m 57.295779506 +proj=ob_tran +o_proj=latlon +o_lat_p=-180.0 +lon_0=30.0; proj_parameters=-m 57.295779506 +proj=ob_tran +o_proj=latlon +o_lat_p=-180.0 +lon_0=30.0; projection_name=rotated_latitude_longitude; long_name=projection details; EPSG_code=
>
>
> Could anyone point me to some code to assign the correct CRS to the 
> imported stack 'tst.s' and then to project it to the 'normal' 
> geographical coordinate system, so I can extract time series for the 
> field site coordinates which are in 'normal' latlong.
>
> Thanks a lot for your time.
>
> Cheers,
> Matthias
>
>
>
> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> Dr. Matthias M Boer
> Hawkesbury Institute for the Environment<http://www.westernsydney.edu.au/hie> | Western Sydney University | Hawkesbury Campus, Richmond, NSW 2753, AUSTRALIA
> P: +61-(0)2-4570-1373 (direct) | P: +61-(0)2-4570-1941 (admin) | E: m.boer at westernsydney.edu.au
>
> Postal address: Locked Bag 1797 | Penrith, NSW 2751, AUSTRALIA
> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From andrewaduff at gmail.com  Thu Apr  5 15:00:29 2018
From: andrewaduff at gmail.com (Andrew Duff)
Date: Thu, 5 Apr 2018 07:00:29 -0600
Subject: [R-sig-Geo] help
In-Reply-To: <CAFoeBZm2dpUp76fXTDyPgYjn0B9WEaoNUNBEcoryUuTJtX7Y7g@mail.gmail.com>
References: <CAFoeBZm2dpUp76fXTDyPgYjn0B9WEaoNUNBEcoryUuTJtX7Y7g@mail.gmail.com>
Message-ID: <CAO2uuDQ_TNduYuSCH4A_e4VHSOEqWYLfS3XNtOb5f3j74yhZPw@mail.gmail.com>

Shouldn't this line be

xlist <- nb2listw(neighbours,glist = NULL,style = "W",zero.policy =TRUE)


instead of


xlist <- nb2listw(neighbours,glist = NULL,style = "W",zero.policy =TRU)

?



On Wed, Apr 4, 2018 at 9:44 PM, Yalemzewod Gelaw <yalassefa at gmail.com>
wrote:

> I am a new student to R learning for spatial analysis. I was hoping
> someone could help me with the
> error message I keep getting when I try to convert the neighbour data to a
> listw object use the nb2listw()  function.
>
> plot(xw_nbq, coords,add=TRUE,col="red")> summary(xw_nbq)
>
>
> Neighbour list object:
> Number of regions: 140
> Number of nonzero links: 680
> Percentage nonzero weights: 3.469388
> Average number of links: 4.857143
> 2 regions with no links:
> 3 138
> Link number distribution:
>
>  0  1  2  3  4  5  6  7  8  9
>  2  6  4 16 32 35 17 13 13  2
> 6 least connected regions:
> 11 32 57 117 124 137 with 1 link
> 2 most connected regions:
> 28 71 with 9 links
>
> ?when I try to run nb2listw, i got repated error following the below error
> message. ?
>
> xlist <- nb2listw(neighbours,glist = NULL,style = "W",zero.policy =TRU) > summary.listw(xlist)
> Error in summary.listw(xlist) : regions with no neighbours found, use
> zero.policy=TRUE
>
> I wonder if someone advises me how to fix the error message from my
> working directory
> ?
>
>
> *Regards, *
>
> Yalem
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Thu Apr  5 15:23:53 2018
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 05 Apr 2018 13:23:53 +0000
Subject: [R-sig-Geo] 
 netcdf data from Antarctica in rotated latlong - how to
 reproject to normal geographical coordinate system
In-Reply-To: <alpine.LFD.2.21.1804050957430.26268@reclus.nhh.no>
References: <ME1PR01MB1044D60D3EDB249FBBC27A48B3BB0@ME1PR01MB1044.ausprd01.prod.outlook.com>
 <alpine.LFD.2.21.1804050957430.26268@reclus.nhh.no>
Message-ID: <CAAcGz995_8zOqum9x6r+P1SSYuSJSPf24XG0HP9G0Yb0vwygJQ@mail.gmail.com>

On Thu, 5 Apr 2018 at 18:04 Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Thu, 5 Apr 2018, Matthias Boer wrote:
>
> > Hi all
> >
> > I am having trouble extracting some climate time series for a series of
> field sites in Antarctica from a netcdf file with a rotated pole
> projection. The file (gridded monthly temperatures for 1979-2016) includes
> these details about the projection:
> > float rotated_pole[]
> >            grid_mapping_name: rotated_latitude_longitude
> >            grid_north_pole_latitude: -180
> >            grid_north_pole_longitude: -150
>
> >            proj4_params: -m 57.295779506 +proj=ob_tran +o_proj=latlon
> > +o_lat_p=-180.0 +lon_0=30.0
>
> >            proj_parameters: -m 57.295779506 +proj=ob_tran +o_proj=latlon
> > +o_lat_p=-180.0 +lon_0=30.0
>
> >            projection_name: rotated_latitude_longitude
> >            long_name: projection details
> >            EPSG_code:
> >
> > I can read the netcdf file into R:
> > tst.s <- stack("filename.nc", varname="var1")
>
> You'll need to look for the arguments supporting +proj=ob_tran
> (use_ob_tran=) in rgdal::spTransform(). +proj=ob_tran is a complete mess,
> and until the next release of GDAL, the GDAL netcdf driver will not
> understand these either. Your best bet may be not to warp the input grids,
> but to transform the field sites point coordinates to ob_tran to extract
> the data you need (checking that the transformation seems sensible).
>
> Roger
>
>
Just to echo Roger's expert knowledge of the vagaries of ob_tran support
here - this is a fraught area, and the general advice to *transform your
query to the grid, rather than vice versa* is so very important. If you can
make a map with the grid - plot(tst.s[[1]]) - and then add vector (points,
lines, polygons) data to that  by transforming them to that space then you
know for sure it can all work, and be optimized and automated.The effort is
in getting the transformation of a few points assured, and then you can
bundle it all up.

It's not obvious, and I'm happy to discuss in detail offline to get a
solution - it always takes a bit of back and forth and experimenting -
which is hard to get across in a public forum - for my own purposes, seeing
real world example data (especially Antarctic!) is always welcome as grist
for understanding.

Can you share a file? (Offline if need be).

Cheers, Mike.


>
> > but this gives a couple of warnings that raster can't understand the
> projection:
> > Warning messages:
> > 1: In .stackCDF(x, varname = varname, bands = bands) :
> >  tskin has 4 dimensions, I am using the last one
> > 2: In .getCRSfromGridMap4(atts) : cannot process these parts of the CRS:
> > grid_north_pole_latitude=-180; grid_north_pole_longitude=-150;
> proj4_params=-m 57.295779506 +proj=ob_tran +o_proj=latlon +o_lat_p=-180.0
> +lon_0=30.0; proj_parameters=-m 57.295779506 +proj=ob_tran +o_proj=latlon
> +o_lat_p=-180.0 +lon_0=30.0; projection_name=rotated_latitude_longitude;
> long_name=projection details; EPSG_code=
> > 3: In .getCRSfromGridMap4(atts) : cannot create a valid CRS
> > grid_north_pole_latitude=-180; grid_north_pole_longitude=-150;
> proj4_params=-m 57.295779506 +proj=ob_tran +o_proj=latlon +o_lat_p=-180.0
> +lon_0=30.0; proj_parameters=-m 57.295779506 +proj=ob_tran +o_proj=latlon
> +o_lat_p=-180.0 +lon_0=30.0; projection_name=rotated_latitude_longitude;
> long_name=projection details; EPSG_code=
> >
> >
> > Could anyone point me to some code to assign the correct CRS to the
> > imported stack 'tst.s' and then to project it to the 'normal'
> > geographical coordinate system, so I can extract time series for the
> > field site coordinates which are in 'normal' latlong.
> >
> > Thanks a lot for your time.
> >
> > Cheers,
> > Matthias
> >
> >
> >
> >
> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> > Dr. Matthias M Boer
> > Hawkesbury Institute for the Environment<
> http://www.westernsydney.edu.au/hie> | Western Sydney University |
> Hawkesbury Campus, Richmond, NSW 2753, AUSTRALIA
> > P: +61-(0)2-4570-1373 <+61%202%204570%201373> (direct) | P:
> +61-(0)2-4570-1941 <+61%202%204570%201941> (admin) | E:
> m.boer at westernsydney.edu.au
> >
> > Postal address: Locked Bag 1797 | Penrith, NSW 2751, AUSTRALIA
> >
> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55 <+47%2055%2095%2093%2055>; e-mail:
> Roger.Bivand at nhh.no
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From tom.hengl at gmail.com  Sun Apr  8 22:04:56 2018
From: tom.hengl at gmail.com (Tomislav Hengl)
Date: Sun, 8 Apr 2018 22:04:56 +0200
Subject: [R-sig-Geo] =?utf-8?q?Ecology=E2=80=99s_remote-sensing_revolutio?=
 =?utf-8?q?n=2C_article_in_Nature?=
Message-ID: <2200dd6b-65e9-886e-4cda-f569f776a36d@gmail.com>


"Ecology?s remote-sensing revolution"
https://www.nature.com/articles/d41586-018-03924-9
Nature 556, 137-138 (2018)
doi: 10.1038/d41586-018-03924-9

R is also mentioned, specifically packages "getSpatialData" and 
"RStoolbox". Also QGIS is mentioned.


From thi_veloso at yahoo.com.br  Tue Apr 10 18:45:45 2018
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Tue, 10 Apr 2018 16:45:45 +0000 (UTC)
Subject: [R-sig-Geo] Substitute raster stack values based on matrix index
References: <30727914.1309338.1523378745255.ref@mail.yahoo.com>
Message-ID: <30727914.1309338.1523378745255@mail.yahoo.com>

I have a large (7000x7000, 10-layered) raster stack whose values range from 0 to 100.

I need to modify the raster values using the a "lookup table" consisted of a matrix which is 100 rows long by 10 cols wide, where the number of rows is associated with the 0-100 value range of the raster and the number of columns relates to the number of layers of the raster stack.?

The following code creates a toy example of my dataset:

# Create raster stackr <- raster(ncol=50, nrow=50)s <- stack(lapply(1:10, function(x) setValues(r, 1:ncell(r))))

# Create lookup tablem <- matrix(sample(100, 100*10, TRUE), 100, 10)

Therefore, I need to loop through each cell of the raster and check its value. For example, if the cell value is `20`, then the new value will be reassigned from the 20th line and 1st column in the matrix.

And so on for the 2nd raster stack layer and 2nd matrix column. And so on for the remaining raster stack layers and matrix columns.

Any ideas on how to do that?

I know this sounds a bit cumbersome, but that's how a few ISRIC-WISE's soil datasets are organized!
Greetings,?-- Thiago V. dos Santos
Postdoctoral Research FellowDepartment of Climate and Space Science and EngineeringUniversity of Michigan

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Tue Apr 10 19:09:15 2018
From: btupper at bigelow.org (Ben Tupper)
Date: Tue, 10 Apr 2018 13:09:15 -0400
Subject: [R-sig-Geo] 
 Substitute raster stack values based on matrix index
In-Reply-To: <30727914.1309338.1523378745255@mail.yahoo.com>
References: <30727914.1309338.1523378745255.ref@mail.yahoo.com>
 <30727914.1309338.1523378745255@mail.yahoo.com>
Message-ID: <D0D9DC39-3ABF-464E-8053-4A769635F0FB@bigelow.org>

Hi,

I think you want to reform your lookup table into a 2 column matrix with columns from_value and to_value, and then use raster::reclassify()

The one thing that makes me hesitate is the lookup rule you describe.  If a cell has a value of 20 then assign lut value m[20,1]  So does that mean a cell value of 49 gets assigned  m[40,10] ?  What happens to a cell value of 3?  These is no m[0,3].

Cheers,
Ben 


> On Apr 10, 2018, at 12:45 PM, Thiago V. dos Santos via R-sig-Geo <r-sig-geo at r-project.org> wrote:
> 
> I have a large (7000x7000, 10-layered) raster stack whose values range from 0 to 100.
> 
> I need to modify the raster values using the a "lookup table" consisted of a matrix which is 100 rows long by 10 cols wide, where the number of rows is associated with the 0-100 value range of the raster and the number of columns relates to the number of layers of the raster stack. 
> 
> The following code creates a toy example of my dataset:
> 
> # Create raster stackr <- raster(ncol=50, nrow=50)s <- stack(lapply(1:10, function(x) setValues(r, 1:ncell(r))))
> 
> # Create lookup tablem <- matrix(sample(100, 100*10, TRUE), 100, 10)
> 
> Therefore, I need to loop through each cell of the raster and check its value. For example, if the cell value is `20`, then the new value will be reassigned from the 20th line and 1st column in the matrix.
> 
> And so on for the 2nd raster stack layer and 2nd matrix column. And so on for the remaining raster stack layers and matrix columns.
> 
> Any ideas on how to do that?
> 
> I know this sounds a bit cumbersome, but that's how a few ISRIC-WISE's soil datasets are organized!
> Greetings, -- Thiago V. dos Santos
> Postdoctoral Research FellowDepartment of Climate and Space Science and EngineeringUniversity of Michigan
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Tick Forecasting: https://eco.bigelow.org/





	[[alternative HTML version deleted]]


From kkilpatrick at rsmas.miami.edu  Tue Apr 10 20:43:54 2018
From: kkilpatrick at rsmas.miami.edu (Kilpatrick, Katherine A)
Date: Tue, 10 Apr 2018 18:43:54 +0000
Subject: [R-sig-Geo] 
 Substitute raster stack values based on matrix index
In-Reply-To: <30727914.1309338.1523378745255@mail.yahoo.com>
References: <30727914.1309338.1523378745255.ref@mail.yahoo.com>
 <30727914.1309338.1523378745255@mail.yahoo.com>
Message-ID: <F8ACEDDE-153F-4E68-9A7A-22D5F8F42E6A@miami.edu>

Maybe something along this line?..assuming I understood the problem properly

for (i in 1:nlayers(stackr)) {

    layer <- stackr[[i]]  # get a layer from the stack
    ID_layer<- 1:ncell(layer[[1]])  # create cell ids for the layer

    for (j in 1:nrow(tablem)) {

        x <- rep(j,ncell(layer))  # LUT row number to test match
        replace <- layer[ID_Raster] == x  # test if cell value matches LUT row number
        layer[ID_Raster[replace]] <- tablem[j,i]

    }

    stackr[[i]] <- layer  # put the update layer back in the stack
}



---------------------------------------------------------------------
Katherine (Kay) Kilpatrick
Oceanographer
University of Miami Rosenstiel School for Marine and Atmospheric Science
Satellite Remote Sensing Laboratory






On Apr 10, 2018, at 12:45 PM, Thiago V. dos Santos via R-sig-Geo <r-sig-geo at r-project.org<mailto:r-sig-geo at r-project.org>> wrote:

I have a large (7000x7000, 10-layered) raster stack whose values range from 0 to 100.

I need to modify the raster values using the a "lookup table" consisted of a matrix which is 100 rows long by 10 cols wide, where the number of rows is associated with the 0-100 value range of the raster and the number of columns relates to the number of layers of the raster stack.

The following code creates a toy example of my dataset:

# Create raster stackr <- raster(ncol=50, nrow=50)s <- stack(lapply(1:10, function(x) setValues(r, 1:ncell(r))))

# Create lookup tablem <- matrix(sample(100, 100*10, TRUE), 100, 10)

Therefore, I need to loop through each cell of the raster and check its value. For example, if the cell value is `20`, then the new value will be reassigned from the 20th line and 1st column in the matrix.

And so on for the 2nd raster stack layer and 2nd matrix column. And so on for the remaining raster stack layers and matrix columns.

Any ideas on how to do that?

I know this sounds a bit cumbersome, but that's how a few ISRIC-WISE's soil datasets are organized!
Greetings, -- Thiago V. dos Santos
Postdoctoral Research FellowDepartment of Climate and Space Science and EngineeringUniversity of Michigan

[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=02%7C01%7Ckkilpatrick%40rsmas.miami.edu%7Cb434162221bf48ebef6408d59f028904%7C2a144b72f23942d48c0e6f0f17c48e33%7C0%7C1%7C636589755609404744&sdata=vjhu941iiiyOT%2BsRlvda7biPX6NAtr%2B07NcVvCGU8Ao%3D&reserved=0


	[[alternative HTML version deleted]]


From crockwood at pointblue.org  Tue Apr 10 21:49:07 2018
From: crockwood at pointblue.org (Cotton Rockwood)
Date: Tue, 10 Apr 2018 19:49:07 +0000
Subject: [R-sig-Geo] 
 Substitute raster stack values based on matrix index
In-Reply-To: <F8ACEDDE-153F-4E68-9A7A-22D5F8F42E6A@miami.edu>
References: <30727914.1309338.1523378745255.ref@mail.yahoo.com>
 <30727914.1309338.1523378745255@mail.yahoo.com>
 <F8ACEDDE-153F-4E68-9A7A-22D5F8F42E6A@miami.edu>
Message-ID: <DM2PR04MB70115257FAEEF138E09EA6CB9BE0@DM2PR04MB701.namprd04.prod.outlook.com>

Hi Thiago -
Here is an approach using 'mapply' and 'reclassify'. I changed your example raster stack so the values range from 1:100 rather than 1:ncell(r) since that is what you stated in your problem:

# Create raster stack
r <- raster(ncol=50, nrow=50)
s <- stack(lapply(1:10, function(x) setValues(r, rep(1:100, each=(ncell(r)/100)))))

# Create lookup table
m <- as.data.frame(matrix(sample(100, 100*10, TRUE), 100, 10))

# create new stack with lookup
new.stack <- stack(mapply(FUN = function(x, y) {
  lookup <- matrix(cbind(1:length(y), y), ncol=2)
  reclassify(x, lookup)
}, x = as.list(s), y = m))

plot(s); plot(new.stack)

Cheers,
Cotton

-----Original Message-----
From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Kilpatrick, Katherine A
Sent: Tuesday, April 10, 2018 11:44 AM
To: Thiago V. dos Santos <thi_veloso at yahoo.com.br>
Cc: R-sig-geo Mailing List <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Substitute raster stack values based on matrix index

Maybe something along this line?..assuming I understood the problem properly

for (i in 1:nlayers(stackr)) {

    layer <- stackr[[i]]  # get a layer from the stack
    ID_layer<- 1:ncell(layer[[1]])  # create cell ids for the layer

    for (j in 1:nrow(tablem)) {

        x <- rep(j,ncell(layer))  # LUT row number to test match
        replace <- layer[ID_Raster] == x  # test if cell value matches LUT row number
        layer[ID_Raster[replace]] <- tablem[j,i]

    }

    stackr[[i]] <- layer  # put the update layer back in the stack }



---------------------------------------------------------------------
Katherine (Kay) Kilpatrick
Oceanographer
University of Miami Rosenstiel School for Marine and Atmospheric Science Satellite Remote Sensing Laboratory






On Apr 10, 2018, at 12:45 PM, Thiago V. dos Santos via R-sig-Geo <r-sig-geo at r-project.org<mailto:r-sig-geo at r-project.org>> wrote:

I have a large (7000x7000, 10-layered) raster stack whose values range from 0 to 100.

I need to modify the raster values using the a "lookup table" consisted of a matrix which is 100 rows long by 10 cols wide, where the number of rows is associated with the 0-100 value range of the raster and the number of columns relates to the number of layers of the raster stack.

The following code creates a toy example of my dataset:

# Create raster stackr <- raster(ncol=50, nrow=50)s <- stack(lapply(1:10, function(x) setValues(r, 1:ncell(r))))

# Create lookup tablem <- matrix(sample(100, 100*10, TRUE), 100, 10)

Therefore, I need to loop through each cell of the raster and check its value. For example, if the cell value is `20`, then the new value will be reassigned from the 20th line and 1st column in the matrix.

And so on for the 2nd raster stack layer and 2nd matrix column. And so on for the remaining raster stack layers and matrix columns.

Any ideas on how to do that?

I know this sounds a bit cumbersome, but that's how a few ISRIC-WISE's soil datasets are organized!
Greetings, -- Thiago V. dos Santos
Postdoctoral Research FellowDepartment of Climate and Space Science and EngineeringUniversity of Michigan

[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=02%7C01%7Ckkilpatrick%40rsmas.miami.edu%7Cb434162221bf48ebef6408d59f028904%7C2a144b72f23942d48c0e6f0f17c48e33%7C0%7C1%7C636589755609404744&sdata=vjhu941iiiyOT%2BsRlvda7biPX6NAtr%2B07NcVvCGU8Ao%3D&reserved=0


	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

From tom.hengl at gmail.com  Tue Apr 10 22:26:25 2018
From: tom.hengl at gmail.com (Tomislav Hengl)
Date: Tue, 10 Apr 2018 22:26:25 +0200
Subject: [R-sig-Geo] Worked out example of spatiotemporal interpolation of
 daily precipitation?
Message-ID: <bd4af7e7-760c-af83-600c-5dfbb9913abd@gmail.com>


We are looking for a worked out example of spatiotemporal interpolation 
(using spatiotemporal kriging / regression-kriging or universal kriging) 
of daily precipitation in R. Daily precipitation is a zero-inflated 
variable so using some model based geostatistical solution 
(https://www.jstatsoft.org/article/view/v063i12/v63i12.pdf) is probably 
not an option?

We would like to compare geostatistical interpolation with the spacetime RF:

https://github.com/thengl/GeoMLA#prediction-of-spatio-temporal-variable

thank you,

T. Hengl
https://orcid.org/0000-0002-9921-5129


From roberto.patuelli at unibo.it  Wed Apr 11 17:31:27 2018
From: roberto.patuelli at unibo.it (Roberto Patuelli)
Date: Wed, 11 Apr 2018 15:31:27 +0000
Subject: [R-sig-Geo] How to create a regular grid?
Message-ID: <efef9a966df74a7480435ac8ea74532c@E13-MBX3-DR.personale.dir.unibo.it>

Dear All,

Maybe a basic question:

How can I create - for simulation purposes - a regular grid (a raster) N by N on which to generate a rook spatial weights matrix (listw or nb object)?

I actually only need to obtain the listw/nb object for such regular grid.

It feels like this is very simple, but somehow I'm stuck.

Thanks
Roberto

********************
Roberto Patuelli, Ph.D.
Department of Economics
University of Bologna
Rimini campus
Italy


From b.rowlingson at lancaster.ac.uk  Wed Apr 11 18:19:07 2018
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 11 Apr 2018 17:19:07 +0100
Subject: [R-sig-Geo] How to create a regular grid?
In-Reply-To: <efef9a966df74a7480435ac8ea74532c@E13-MBX3-DR.personale.dir.unibo.it>
References: <efef9a966df74a7480435ac8ea74532c@E13-MBX3-DR.personale.dir.unibo.it>
Message-ID: <CANVKczMh70esF0f0q28wfkBc=tiqWc7UQh0h1NQRVNdViLXTOA@mail.gmail.com>

`cell2nb` in spdep will do exactly that:

 library(sp)
 library(spdep)
 plot(cell2nb(5,5),coords=expand.grid(1:5,1:5))

If you want the points as sp class objects, feed SpatialPoints from
expand.grid:

pts = sp::SpatialPoints(expand.grid(x=1:N,y=1:N))

Barry


On Wed, Apr 11, 2018 at 4:31 PM, Roberto Patuelli <roberto.patuelli at unibo.it
> wrote:

> Dear All,
>
> Maybe a basic question:
>
> How can I create - for simulation purposes - a regular grid (a raster) N
> by N on which to generate a rook spatial weights matrix (listw or nb
> object)?
>
> I actually only need to obtain the listw/nb object for such regular grid.
>
> It feels like this is very simple, but somehow I'm stuck.
>
> Thanks
> Roberto
>
> ********************
> Roberto Patuelli, Ph.D.
> Department of Economics
> University of Bologna
> Rimini campus
> Italy
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From yalassefa at gmail.com  Sat Apr 14 07:18:11 2018
From: yalassefa at gmail.com (Yalemzewod Gelaw)
Date: Sat, 14 Apr 2018 15:18:11 +1000
Subject: [R-sig-Geo] 'help'
Message-ID: <CAFoeBZkYRYs56Ps1PNBca_G8aYC2Uov0MM6r0Go_Q_sgni=K6g@mail.gmail.com>

Hi

I tried to compute the Moran's I statistics using GIS and R. However, I got
different values.

Could you please brief me how the difference can occurs?

Using GIS

 Global Moran's I Summary

Moran's Index:   0.151485

Expected Index:  -0.007692

Variance:        0.001040

z-score:         4.935027

p-value:         0.000001



Using R

Moran I test under randomisation

data:  Dat$allprop

weights: Xlist

Moran I statistic standard deviate = 0.82453, p-value = 0.4096

alternative hypothesis: two.sided

sample estimates:

Moran I statistic       Expectation          Variance

      0.034154753      -0.007299270       0.002527644

NB: in the neighbour links there are 2 regions with no links


Thank you for any help



*Regards, *

Yalem

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Sat Apr 14 17:31:02 2018
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sat, 14 Apr 2018 11:31:02 -0400
Subject: [R-sig-Geo] 'help'
In-Reply-To: <CAFoeBZkYRYs56Ps1PNBca_G8aYC2Uov0MM6r0Go_Q_sgni=K6g@mail.gmail.com>
References: <CAFoeBZkYRYs56Ps1PNBca_G8aYC2Uov0MM6r0Go_Q_sgni=K6g@mail.gmail.com>
Message-ID: <CAM_vju=FoOKrdzE5WjBWx-_rWTiPdqxz=vO4zZ0jgJgUBwmCrQ@mail.gmail.com>

Hi,

It's pretty much impossible, since we don't know what GIS software you
used, what commands, what R package and code, or what your data look
like.

As a starting point, I'd suggest carefully rereading the help files
for both the GIS and the R functions, to make sure that they are doing
the same thing, and what you expect them to, and to review your data
in both places to ensure that it is the same values and projection,
etc. It is entirely possible that one software is scaling your data
for you automatically, or some other processing step that is not
duplicated by the other software.

If trying those things doesn't clarify it for you, then please post
back to the list with more information about the software and data
you're using.

Sarah

On Sat, Apr 14, 2018 at 1:18 AM, Yalemzewod Gelaw <yalassefa at gmail.com> wrote:
> Hi
>
> I tried to compute the Moran's I statistics using GIS and R. However, I got
> different values.
>
> Could you please brief me how the difference can occurs?
>
> Using GIS
>
>  Global Moran's I Summary
>
> Moran's Index:   0.151485
>
> Expected Index:  -0.007692
>
> Variance:        0.001040
>
> z-score:         4.935027
>
> p-value:         0.000001
>
>
>
> Using R
>
> Moran I test under randomisation
>
> data:  Dat$allprop
>
> weights: Xlist
>
> Moran I statistic standard deviate = 0.82453, p-value = 0.4096
>
> alternative hypothesis: two.sided
>
> sample estimates:
>
> Moran I statistic       Expectation          Variance
>
>       0.034154753      -0.007299270       0.002527644
>
> NB: in the neighbour links there are 2 regions with no links
>
>
> Thank you for any help
>
>
>
> *Regards, *
>
> Yalem



-- 
Sarah Goslee
http://www.functionaldiversity.org


From Roger.Bivand at nhh.no  Sat Apr 14 18:55:32 2018
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 14 Apr 2018 18:55:32 +0200
Subject: [R-sig-Geo] 'help'
In-Reply-To: <CAM_vju=FoOKrdzE5WjBWx-_rWTiPdqxz=vO4zZ0jgJgUBwmCrQ@mail.gmail.com>
References: <CAFoeBZkYRYs56Ps1PNBca_G8aYC2Uov0MM6r0Go_Q_sgni=K6g@mail.gmail.com>
 <CAM_vju=FoOKrdzE5WjBWx-_rWTiPdqxz=vO4zZ0jgJgUBwmCrQ@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.1804141851330.5137@reclus.nhh.no>

On Sat, 14 Apr 2018, Sarah Goslee wrote:

> Hi,
>
> It's pretty much impossible, since we don't know what GIS software you
> used, what commands, what R package and code, or what your data look
> like.
>
> As a starting point, I'd suggest carefully rereading the help files
> for both the GIS and the R functions, to make sure that they are doing
> the same thing, and what you expect them to, and to review your data
> in both places to ensure that it is the same values and projection,
> etc. It is entirely possible that one software is scaling your data
> for you automatically, or some other processing step that is not
> duplicated by the other software.
>
> If trying those things doesn't clarify it for you, then please post
> back to the list with more information about the software and data
> you're using.

Yes, the problem is most likely that the weights and data are the same, 
but in GIS or R the data are sorted differently than the weights. 
Alternatively, the weights may be different for the same data. For R, it 
would help to see how you constructed the weights object. If the GIS is 
ArcGIS, for the same weights and data, we know what differences may be 
expected, and any such differences would not affect your conclusion.

Roger

>
> Sarah
>
> On Sat, Apr 14, 2018 at 1:18 AM, Yalemzewod Gelaw <yalassefa at gmail.com> wrote:
>> Hi
>>
>> I tried to compute the Moran's I statistics using GIS and R. However, I got
>> different values.
>>
>> Could you please brief me how the difference can occurs?
>>
>> Using GIS
>>
>>  Global Moran's I Summary
>>
>> Moran's Index:   0.151485
>>
>> Expected Index:  -0.007692
>>
>> Variance:        0.001040
>>
>> z-score:         4.935027
>>
>> p-value:         0.000001
>>
>>
>>
>> Using R
>>
>> Moran I test under randomisation
>>
>> data:  Dat$allprop
>>
>> weights: Xlist
>>
>> Moran I statistic standard deviate = 0.82453, p-value = 0.4096
>>
>> alternative hypothesis: two.sided
>>
>> sample estimates:
>>
>> Moran I statistic       Expectation          Variance
>>
>>       0.034154753      -0.007299270       0.002527644
>>
>> NB: in the neighbour links there are 2 regions with no links
>>
>>
>> Thank you for any help
>>
>>
>>
>> *Regards, *
>>
>> Yalem
>
>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From alobolistas at gmail.com  Tue Apr 17 13:18:15 2018
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 17 Apr 2018 13:18:15 +0200
Subject: [R-sig-Geo] Change in rasterToPolygons() behaviour
Message-ID: <CAG4NReJwt0DN+zd0Tk0vUVWRwrU_-QT+6HJwBygdo0A6=r-RXg@mail.gmail.com>

Recycling an old script, I've found that rasterToPolygons()
produces an error if not all stack bands are of the same type:

file <- system.file("external/test.grd", package="raster") s <-
stack(file, file, file)
s2 <- (s[[3]]-s[[2]])/(s[[3]]-s[[2]])
s1 <- stack(file, file, file)
s2 <- (s1[[3]]-s1[[2]])/(s1[[3]]-s1[[2]])
s <- addLayer(s1,s2)
sg <- rasterToPolygons(s,fun=NULL)
Error in `colnames<-`(`*tmp*`, value = c("x", "y", names(x))) :
  length of 'dimnames' [2] not equal to array extent

This used to work. The following works now:
 s <- addLayer(s1*1.0,s2)
 sg <- rasterToPolygons(s,fun=NULL)

Just reporting for other inattentive users like me (if any).

Agus


From jwism002 at odu.edu  Tue Apr 17 16:08:15 2018
From: jwism002 at odu.edu (Jeri Wisman)
Date: Tue, 17 Apr 2018 09:08:15 -0500
Subject: [R-sig-Geo] Rasterize function
Message-ID: <CACPuJ4nxPL+9+uT=z7U8TTc17Fpuv1jqgaiKcOmgXDvFDpNatg@mail.gmail.com>

Hi all -

I am working on a code trying to "rasterize" spatial polygons created by
kernelUD but somewhere in the code the values are getting lost and not
translating when I created a raster dateframe and try to tie in the polygon
lat/lon values into the raster frame. Attached is my code and data.

Thanks!
*Jeri Wisman* | Masters Candidate
Old Dominion University
Department of Biological Sciences
Mills Godwin Building, Room 312
Norfolk VA 23529 USA

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20180417/0fda7095/attachment.html>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: COTE_2017_KernelDensity_code_JLW.R
Type: application/octet-stream
Size: 3704 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20180417/0fda7095/attachment.obj>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: cote_2017_alldata_1km_16825.csv
Type: application/vnd.ms-excel
Size: 6568 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20180417/0fda7095/attachment.xlb>

From mdsumner at gmail.com  Tue Apr 17 16:44:36 2018
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 17 Apr 2018 14:44:36 +0000
Subject: [R-sig-Geo] Rasterize function
In-Reply-To: <CACPuJ4nxPL+9+uT=z7U8TTc17Fpuv1jqgaiKcOmgXDvFDpNatg@mail.gmail.com>
References: <CACPuJ4nxPL+9+uT=z7U8TTc17Fpuv1jqgaiKcOmgXDvFDpNatg@mail.gmail.com>
Message-ID: <CAAcGz9_6tZGJEw1PkDHKBygb3jxb-nvz=dLPD7YsAQWEPhAODg@mail.gmail.com>

On Wed, 18 Apr 2018 at 00:08 Jeri Wisman <jwism002 at odu.edu> wrote:

> Hi all -
>
> I am working on a code trying to "rasterize" spatial polygons created by
> kernelUD but somewhere in the code the values are getting lost and not
> translating when I created a raster dateframe and try to tie in the polygon
> lat/lon values into the raster frame. Attached is my code and data.
>

Hi, this is not really acceptable as a question to this list, because we
have to go through your script to figure out what you are referring to.

But, my guess is you want the "field" argument to ?rasterize:

> If x is a Spatial*DataFrame, this can be the column name of the variable
to be transferred. If missing, the attribute index is used (i.e.
> numbers from 1 to the number of features).

Your line

r.polys <- rasterize(shp, r)

will put the row number of shp into the appropriate pixel of r.polys, but
you might want to set

r.polys <- rasterize(shp, r, field = "somename")

where "somename" is a member of names(shp).

Just a guess.

Cheers, Mike



> Thanks!
> *Jeri Wisman* | Masters Candidate
> Old Dominion University
> Department of Biological Sciences
> Mills Godwin Building, Room 312
> Norfolk VA 23529 USA
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Apr 17 21:18:54 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 17 Apr 2018 21:18:54 +0200
Subject: [R-sig-Geo] 
 Worked out example of spatiotemporal interpolation of
 daily precipitation?
In-Reply-To: <bd4af7e7-760c-af83-600c-5dfbb9913abd@gmail.com>
References: <bd4af7e7-760c-af83-600c-5dfbb9913abd@gmail.com>
Message-ID: <CAJuCY5w-FuOUbz5ctrwO6HHpMSxyb9Nk2CHJ62qvM+cbniMfzw@mail.gmail.com>

Dear Tomislav,

Blangiardo and Cameletti (2015) Spatial and Spatio-temporal Bayesian
Models with R - INLA models the Parana state rainfall data (chapter
8). See https://sites.google.com/a/r-inla.org/stbook/ Not kriging but
maybe useful for you.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-04-10 22:26 GMT+02:00 Tomislav Hengl <tom.hengl at gmail.com>:
>
> We are looking for a worked out example of spatiotemporal interpolation
> (using spatiotemporal kriging / regression-kriging or universal kriging) of
> daily precipitation in R. Daily precipitation is a zero-inflated variable so
> using some model based geostatistical solution
> (https://www.jstatsoft.org/article/view/v063i12/v63i12.pdf) is probably not
> an option?
>
> We would like to compare geostatistical interpolation with the spacetime RF:
>
> https://github.com/thengl/GeoMLA#prediction-of-spatio-temporal-variable
>
> thank you,
>
> T. Hengl
> https://orcid.org/0000-0002-9921-5129
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Virgilio.Gomez at uclm.es  Tue Apr 17 23:44:30 2018
From: Virgilio.Gomez at uclm.es (Virgilio Gomez Rubio)
Date: Tue, 17 Apr 2018 21:44:30 +0000
Subject: [R-sig-Geo] 
 Worked out example of spatiotemporal interpolation of
 daily precipitation?
In-Reply-To: <CAJuCY5w-FuOUbz5ctrwO6HHpMSxyb9Nk2CHJ62qvM+cbniMfzw@mail.gmail.com>
References: <bd4af7e7-760c-af83-600c-5dfbb9913abd@gmail.com>
 <CAJuCY5w-FuOUbz5ctrwO6HHpMSxyb9Nk2CHJ62qvM+cbniMfzw@mail.gmail.com>
Message-ID: <D852C0D2-D8F6-4CFF-99E0-55716FB5027F@uclm.es>

Hi,

> Blangiardo and Cameletti (2015) Spatial and Spatio-temporal Bayesian
> Models with R - INLA models the Parana state rainfall data (chapter
> 8). See https://sites.google.com/a/r-inla.org/stbook/ Not kriging but
> maybe useful for you.
> 

This is also modeled in the SPDE tutorial http://www.r-inla.org/examples/tutorials/spde-tutorial . Also, I have fitted a space-time model using INLA for the Ireland wind data described in the spacetime vignette. Not really what you want, but you can change the likelihood to a zero-inflated one (INLA provides several of them) if that is what you want?

Best,

Virgilio


From Andy.Bunn at wwu.edu  Wed Apr 18 21:03:21 2018
From: Andy.Bunn at wwu.edu (Andy Bunn)
Date: Wed, 18 Apr 2018 19:03:21 +0000
Subject: [R-sig-Geo] Raster stream network to lines
Message-ID: <72D29A91-596D-4323-AA2A-09A1A3440C58@wwu.edu>

I have a raster of streams with 0 being non-stream and 1 being stream. Is there a way to convert this into a SpatialLinesDataFrame? rasterToContour() almost does what I want but fails to draw the line on queens rules, etc. Example here:

library(raster)
foo <- matrix(0,ncol=9,nrow=9)
foo[1:4,3] <- 1
foo[5,4] <- 1
foo[6:9,5] <- 1
foo <- raster(foo)
plot(foo)
bar <- rasterToContour(foo,nlevels=1)
plot(bar)

How can I get a continuous line in this example? Many thanks, Andy

	[[alternative HTML version deleted]]


From joseph.stachelek at gmail.com  Wed Apr 18 22:17:02 2018
From: joseph.stachelek at gmail.com (Joseph Stachelek)
Date: Wed, 18 Apr 2018 16:17:02 -0400
Subject: [R-sig-Geo] Raster stream network to lines
In-Reply-To: <72D29A91-596D-4323-AA2A-09A1A3440C58@wwu.edu>
References: <72D29A91-596D-4323-AA2A-09A1A3440C58@wwu.edu>
Message-ID: <1524082622.2072.2.camel@gmail.com>

Hi Andy,

I have posted some code showing one way of doing this
with the `sf` package:

https://gist.github.com/jsta/d8d8e8d79877c720b6842ae8efa2
b9b8

If you are doing this a lot I recommend picking up GRASS:

https://grasswiki.osgeo.org/wiki/R.stream.*_modules
https://grass.osgeo.org/grass74/manuals/r.to.vect.html

--Joe

-----Original Message-----
From: Andy Bunn <Andy.Bunn at wwu.edu>
To: R-sig-Geo <r-sig-geo at r-project.org>
Subject: [R-sig-Geo] Raster stream network to lines
Date: Wed, 18 Apr 2018 19:03:21 +0000

I have a raster of streams with 0 being non-stream and 1
being stream. Is there a way to convert this into a
SpatialLinesDataFrame? rasterToContour() almost does what
I want but fails to draw the line on queens rules, etc.
Example here:

library(raster)
foo <- matrix(0,ncol=9,nrow=9)
foo[1:4,3] <- 1
foo[5,4] <- 1
foo[6:9,5] <- 1
foo <- raster(foo)
plot(foo)
bar <- rasterToContour(foo,nlevels=1)
plot(bar)

How can I get a continuous line in this example? Many
thanks, Andy

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Andy.Bunn at wwu.edu  Thu Apr 19 00:22:05 2018
From: Andy.Bunn at wwu.edu (Andy Bunn)
Date: Wed, 18 Apr 2018 22:22:05 +0000
Subject: [R-sig-Geo] Raster stream network to lines
In-Reply-To: <1524082622.2072.2.camel@gmail.com>
References: <72D29A91-596D-4323-AA2A-09A1A3440C58@wwu.edu>
 <1524082622.2072.2.camel@gmail.com>
Message-ID: <DAB462F0-B7E1-4E0A-980E-8CF3635EBAEC@wwu.edu>

Brilliant! And a heck of a workaround. But what if foo is a projected raster? I can add a projection system but all the coordinate info is lost in the shuffle.

?On 4/18/18, 1:17 PM, "Joseph Stachelek" <joseph.stachelek at gmail.com> wrote:

    Hi Andy,
    
    I have posted some code showing one way of doing this
    with the `sf` package:
    
    https://gist.github.com/jsta/d8d8e8d79877c720b6842ae8efa2
    b9b8
    
    If you are doing this a lot I recommend picking up GRASS:
    
    https://grasswiki.osgeo.org/wiki/R.stream.*_modules
    https://grass.osgeo.org/grass74/manuals/r.to.vect.html
    
    --Joe
    
    -----Original Message-----
    From: Andy Bunn <Andy.Bunn at wwu.edu>
    To: R-sig-Geo <r-sig-geo at r-project.org>
    Subject: [R-sig-Geo] Raster stream network to lines
    Date: Wed, 18 Apr 2018 19:03:21 +0000
    
    I have a raster of streams with 0 being non-stream and 1
    being stream. Is there a way to convert this into a
    SpatialLinesDataFrame? rasterToContour() almost does what
    I want but fails to draw the line on queens rules, etc.
    Example here:
    
    library(raster)
    foo <- matrix(0,ncol=9,nrow=9)
    foo[1:4,3] <- 1
    foo[5,4] <- 1
    foo[6:9,5] <- 1
    foo <- raster(foo)
    plot(foo)
    bar <- rasterToContour(foo,nlevels=1)
    plot(bar)
    
    How can I get a continuous line in this example? Many
    thanks, Andy
    
    	[[alternative HTML version deleted]]
    
    _______________________________________________
    R-sig-Geo mailing list
    R-sig-Geo at r-project.org
    https://stat.ethz.ch/mailman/listinfo/r-sig-geo
    


From mdsumner at gmail.com  Thu Apr 19 05:30:22 2018
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 19 Apr 2018 03:30:22 +0000
Subject: [R-sig-Geo] Raster stream network to lines
In-Reply-To: <DAB462F0-B7E1-4E0A-980E-8CF3635EBAEC@wwu.edu>
References: <72D29A91-596D-4323-AA2A-09A1A3440C58@wwu.edu>
 <1524082622.2072.2.camel@gmail.com>
 <DAB462F0-B7E1-4E0A-980E-8CF3635EBAEC@wwu.edu>
Message-ID: <CAAcGz983x-NPbfbe790vPRDw-GLF4zf+WsuYAOgzBjHRAWTg9w@mail.gmail.com>

Not much to add but if you didn't notice there is a degenerate line in that
isolated pixel, so if you were looking at sets of connected pixels in turn
you could possibly re-process the output of contourLines to join things up:

cl <- contourLines(list(x = xFromCol(foo), y  = rev(yFromRow(foo)), z =
as.matrix(t(flip(foo, "y")))), levels = 1)

## the third one is a nearly-degenerate line in the centre of the isolated
cell
cl[[3]]

Cheers, Mike.

On Thu, 19 Apr 2018 at 08:22 Andy Bunn <Andy.Bunn at wwu.edu> wrote:

> Brilliant! And a heck of a workaround. But what if foo is a projected
> raster? I can add a projection system but all the coordinate info is lost
> in the shuffle.
>
> ?On 4/18/18, 1:17 PM, "Joseph Stachelek" <joseph.stachelek at gmail.com>
> wrote:
>
>     Hi Andy,
>
>     I have posted some code showing one way of doing this
>     with the `sf` package:
>
>     https://gist.github.com/jsta/d8d8e8d79877c720b6842ae8efa2
>     b9b8
>
>     If you are doing this a lot I recommend picking up GRASS:
>
>     https://grasswiki.osgeo.org/wiki/R.stream.*_modules
>     https://grass.osgeo.org/grass74/manuals/r.to.vect.html
>
>     --Joe
>
>     -----Original Message-----
>     From: Andy Bunn <Andy.Bunn at wwu.edu>
>     To: R-sig-Geo <r-sig-geo at r-project.org>
>     Subject: [R-sig-Geo] Raster stream network to lines
>     Date: Wed, 18 Apr 2018 19:03:21 +0000
>
>     I have a raster of streams with 0 being non-stream and 1
>     being stream. Is there a way to convert this into a
>     SpatialLinesDataFrame? rasterToContour() almost does what
>     I want but fails to draw the line on queens rules, etc.
>     Example here:
>
>     library(raster)
>     foo <- matrix(0,ncol=9,nrow=9)
>     foo[1:4,3] <- 1
>     foo[5,4] <- 1
>     foo[6:9,5] <- 1
>     foo <- raster(foo)
>     plot(foo)
>     bar <- rasterToContour(foo,nlevels=1)
>     plot(bar)
>
>     How can I get a continuous line in this example? Many
>     thanks, Andy
>
>         [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-Geo mailing list
>     R-sig-Geo at r-project.org
>     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From elias.medeiros at posgrad.ufla.br  Thu Apr 19 12:18:06 2018
From: elias.medeiros at posgrad.ufla.br (ELIAS SILVA DE MEDEIROS)
Date: Thu, 19 Apr 2018 07:18:06 -0300 (BRT)
Subject: [R-sig-Geo] GAMLSS - Trend spatio-temporal
Message-ID: <475262473.7518999.1524133086580.JavaMail.zimbra@posgrad.ufla.br>

Hello people. 
I'm using gstat for spatiotemporal analysis. 
Great software! 
I am suggesting the adjustment of GAMLSS models to model the trend. 
And the residuals of this model in kriging (krigeST (residues ~ 1). 

I wonder if it makes sense to adjust the trend with gamlss models? I have noticed that in several papers the authors use a normal multiple regression (lm (y ~ x1 + x2)). 

Thanks. 

-- 
Atenciosamente, 
Elias Silva de Medeiros 
Contato: (67) 8467-0684 

Gradua??o em Estat?stica (UEPB) 
Mestre em Ci?ncias - Estat?stica e Experimenta??o Agron?mica (USP) 
Doutorando em Estatistia e Experimenta??o Agropecu?ria (UFLA) 

"Jesus ? o maior de todas as coisas." 
Deus ? Bom!!! 

	[[alternative HTML version deleted]]


From Andy.Bunn at wwu.edu  Thu Apr 19 19:01:47 2018
From: Andy.Bunn at wwu.edu (Andy Bunn)
Date: Thu, 19 Apr 2018 17:01:47 +0000
Subject: [R-sig-Geo] Raster stream network to lines
In-Reply-To: <CAAcGz983x-NPbfbe790vPRDw-GLF4zf+WsuYAOgzBjHRAWTg9w@mail.gmail.com>
References: <72D29A91-596D-4323-AA2A-09A1A3440C58@wwu.edu>
 <1524082622.2072.2.camel@gmail.com>
 <DAB462F0-B7E1-4E0A-980E-8CF3635EBAEC@wwu.edu>
 <CAAcGz983x-NPbfbe790vPRDw-GLF4zf+WsuYAOgzBjHRAWTg9w@mail.gmail.com>
Message-ID: <E4DBC3DD-32E5-4218-911E-470C57D16C72@wwu.edu>

While Joe?s solution worked great (except the projection info) I know when I?m beat. I used the channel network tool in QGIS.

From: Michael Sumner <mdsumner at gmail.com>
Date: Wednesday, April 18, 2018 at 8:30 PM
To: Andy Bunn <Andy.Bunn at wwu.edu>
Cc: Joseph Stachelek <joseph.stachelek at gmail.com>, R-sig-Geo <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Raster stream network to lines

Not much to add but if you didn't notice there is a degenerate line in that isolated pixel, so if you were looking at sets of connected pixels in turn you could possibly re-process the output of contourLines to join things up:

cl <- contourLines(list(x = xFromCol(foo), y  = rev(yFromRow(foo)), z = as.matrix(t(flip(foo, "y")))), levels = 1)

## the third one is a nearly-degenerate line in the centre of the isolated cell
cl[[3]]

Cheers, Mike.

On Thu, 19 Apr 2018 at 08:22 Andy Bunn <Andy.Bunn at wwu.edu<mailto:Andy.Bunn at wwu.edu>> wrote:
Brilliant! And a heck of a workaround. But what if foo is a projected raster? I can add a projection system but all the coordinate info is lost in the shuffle.

On 4/18/18, 1:17 PM, "Joseph Stachelek" <joseph.stachelek at gmail.com<mailto:joseph.stachelek at gmail.com>> wrote:

    Hi Andy,

    I have posted some code showing one way of doing this
    with the `sf` package:

    https://gist.github.com/jsta/d8d8e8d79877c720b6842ae8efa2
    b9b8

    If you are doing this a lot I recommend picking up GRASS:

    https://grasswiki.osgeo.org/wiki/R.stream.*_modules
    https://grass.osgeo.org/grass74/manuals/r.to.vect.html

    --Joe

    -----Original Message-----
    From: Andy Bunn <Andy.Bunn at wwu.edu<mailto:Andy.Bunn at wwu.edu>>
    To: R-sig-Geo <r-sig-geo at r-project.org<mailto:r-sig-geo at r-project.org>>
    Subject: [R-sig-Geo] Raster stream network to lines
    Date: Wed, 18 Apr 2018 19:03:21 +0000

    I have a raster of streams with 0 being non-stream and 1
    being stream. Is there a way to convert this into a
    SpatialLinesDataFrame? rasterToContour() almost does what
    I want but fails to draw the line on queens rules, etc.
    Example here:

    library(raster)
    foo <- matrix(0,ncol=9,nrow=9)
    foo[1:4,3] <- 1
    foo[5,4] <- 1
    foo[6:9,5] <- 1
    foo <- raster(foo)
    plot(foo)
    bar <- rasterToContour(foo,nlevels=1)
    plot(bar)

    How can I get a continuous line in this example? Many
    thanks, Andy

        [[alternative HTML version deleted]]

    _______________________________________________
    R-sig-Geo mailing list
    R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
    https://stat.ethz.ch/mailman/listinfo/r-sig-geo


_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo
--
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From julleeyaw at yahoo.ca  Fri Apr 20 19:47:51 2018
From: julleeyaw at yahoo.ca (Julie Lee-Yaw)
Date: Fri, 20 Apr 2018 17:47:51 +0000 (UTC)
Subject: [R-sig-Geo] Odd behavior with rasterToPolygons function in Raster
 package
References: <2005889741.3226850.1524246471146.ref@mail.yahoo.com>
Message-ID: <2005889741.3226850.1524246471146@mail.yahoo.com>

Hello,
I've got a raster with values 1 and NA. I'm attempting to convert to a polygon using the rasterToPolygons function with dissolve=TRUE. The raster is in an equal area projection (+proj=aea +lat_1=-5 +lat_2=-42 +lat_0=-32 +lon_0=-60 +x_0=0 +y_0=0 +ellps=aust_SA +units=m +no_defs )
When I use this command on the projected raster:
sh<-rasterToPolygons(myraster,dissolve=TRUE)
I get a SpatialPolygonsDataFrame with a single polygon but this plots several?lines in the polygon (dissolve function partially working but not plotting as a simple perimeter of the polygon).
If I project the raster to a geographic coordinate system ("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"), I get the expected plot.
Both plots are attached.
I would appreciate any insight. This is part of a larger script and the projected raster/polygon is desirable.
Thanks


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20180420/5a5ca18c/attachment.html>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: geo_coordinates.pdf
Type: application/pdf
Size: 9030 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20180420/5a5ca18c/attachment.pdf>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: aea_projected.pdf
Type: application/pdf
Size: 13452 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20180420/5a5ca18c/attachment-0001.pdf>

From ubfa915 at mail.bbk.ac.uk  Sat Apr 21 18:05:09 2018
From: ubfa915 at mail.bbk.ac.uk (David Unwin)
Date: Sat, 21 Apr 2018 17:05:09 +0100
Subject: [R-sig-Geo] problem with enveloped test in spatstat
Message-ID: <CAE--03ajqRMAmD+3qAxq29F3tMPgaPP-FSWsxtysyg_oeyZr_w@mail.gmail.com>

Can any *spatstat* user explain to me why the two p-values obtained below
for an envelope test against CSR are so different?



> data(swedishpines)

> d<-swedishpines

> plot(d)

> mad.test(d,Kest,nsim=999,verbose=F)



        Maximum absolute deviation test of CSR

        Monte Carlo test based on 999 simulations

        Summary function: K(r)

        Reference function: theoretical

        Alternative: two.sided

        Interval of distance values: [0, 24] units (one unit = 0.1 metres)

        Test statistic: Maximum absolute deviation

        Deviation = observed minus theoretical



data:  d

mad = 150.69, rank = 216, p-value = *0.216*



> mad.test(d,*Lest*,nsim=999,verbose=F)



        Maximum absolute deviation test of CSR

        Monte Carlo test based on 999 simulations

        Summary function: L(r)

        Reference function: theoretical

        Alternative: two.sided

        Interval of distance values: [0, 24] units (one unit = 0.1 metres)

        Test statistic: Maximum absolute deviation

        Deviation = observed minus theoretical



data:  d

mad = 2.9921, rank = 9, p-value = *0.009*



*!!!*



These data are dispersed relative to CSR:

>kl<-envelope(d,Kest,nsim=999,correction="border")

>plot(kl)


Dave Unwin

	[[alternative HTML version deleted]]


From marcelino.delacruz at urjc.es  Sat Apr 21 23:50:32 2018
From: marcelino.delacruz at urjc.es (Marcelino de la Cruz Rot)
Date: Sat, 21 Apr 2018 23:50:32 +0200
Subject: [R-sig-Geo] problem with enveloped test in spatstat
In-Reply-To: <CAE--03ajqRMAmD+3qAxq29F3tMPgaPP-FSWsxtysyg_oeyZr_w@mail.gmail.com>
References: <CAE--03ajqRMAmD+3qAxq29F3tMPgaPP-FSWsxtysyg_oeyZr_w@mail.gmail.com>
Message-ID: <0a4e0d42-15a1-9f5e-4b63-c5db091fd7c2@urjc.es>

Hi David,

This is very clearly explained in page 393 of Baddeley et al. 2015.

Basically, the MAD test is affected by transformations of the summary 
function, with the L-function providing more powerful tests because of 
its stabilization of the variance.

If you are interested in point pattern analysis I would recommend you to 
get a copy of this nice book.


Cheers,

Marcelino


Adrian Baddeley, Ege Rubak, Rolf Turner (2015). Spatial Point Patterns: 
Methodology and Applications with R. London: Chapman and
 ? Hall/CRC Press.
http://www.crcpress.com/Spatial-Point-Patterns-Methodology-and-Applications-with-R/Baddeley-Rubak-Turner/9781482210200/ 







El 21/04/2018 a las 18:05, David Unwin escribi?:
> Can any *spatstat* user explain to me why the two p-values obtained below
> for an envelope test against CSR are so different?
>
>
>
>> data(swedishpines)
>> d<-swedishpines
>> plot(d)
>> mad.test(d,Kest,nsim=999,verbose=F)
>
>
>          Maximum absolute deviation test of CSR
>
>          Monte Carlo test based on 999 simulations
>
>          Summary function: K(r)
>
>          Reference function: theoretical
>
>          Alternative: two.sided
>
>          Interval of distance values: [0, 24] units (one unit = 0.1 metres)
>
>          Test statistic: Maximum absolute deviation
>
>          Deviation = observed minus theoretical
>
>
>
> data:  d
>
> mad = 150.69, rank = 216, p-value = *0.216*
>
>
>
>> mad.test(d,*Lest*,nsim=999,verbose=F)
>
>
>          Maximum absolute deviation test of CSR
>
>          Monte Carlo test based on 999 simulations
>
>          Summary function: L(r)
>
>          Reference function: theoretical
>
>          Alternative: two.sided
>
>          Interval of distance values: [0, 24] units (one unit = 0.1 metres)
>
>          Test statistic: Maximum absolute deviation
>
>          Deviation = observed minus theoretical
>
>
>
> data:  d
>
> mad = 2.9921, rank = 9, p-value = *0.009*
>
>
>
> *!!!*
>
>
>
> These data are dispersed relative to CSR:
>
>> kl<-envelope(d,Kest,nsim=999,correction="border")
>> plot(kl)
>
> Dave Unwin
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> .
>

-- 
Marcelino de la Cruz Rot
Depto. de Biolog?a y Geolog?a
F?sica y Qu?mica Inorg?nica
Universidad Rey Juan Carlos
M?stoles Espa?a


From ubfa915 at mail.bbk.ac.uk  Sun Apr 22 09:46:01 2018
From: ubfa915 at mail.bbk.ac.uk (David Unwin)
Date: Sun, 22 Apr 2018 08:46:01 +0100
Subject: [R-sig-Geo] problem with enveloped test in spatstat
In-Reply-To: <0a4e0d42-15a1-9f5e-4b63-c5db091fd7c2@urjc.es>
References: <CAE--03ajqRMAmD+3qAxq29F3tMPgaPP-FSWsxtysyg_oeyZr_w@mail.gmail.com>
 <0a4e0d42-15a1-9f5e-4b63-c5db091fd7c2@urjc.es>
Message-ID: <CAE--03b4iteqZk8gLAUYOU-xWyVRt34Tqj-vm4B3wX=e1jAWXQ@mail.gmail.com>

Many thanks.  It is a superb book and amazing value for money.  My only
excuse is that I have not as yet got to page 392.  Plotting the functions
also makes it a lot clearer.
Dave

On 21 April 2018 at 22:50, Marcelino de la Cruz Rot <
marcelino.delacruz at urjc.es> wrote:

> Hi David,
>
> This is very clearly explained in page 393 of Baddeley et al. 2015.
>
> Basically, the MAD test is affected by transformations of the summary
> function, with the L-function providing more powerful tests because of its
> stabilization of the variance.
>
> If you are interested in point pattern analysis I would recommend you to
> get a copy of this nice book.
>
>
> Cheers,
>
> Marcelino
>
>
> Adrian Baddeley, Ege Rubak, Rolf Turner (2015). Spatial Point Patterns:
> Methodology and Applications with R. London: Chapman and
>   Hall/CRC Press.
> http://www.crcpress.com/Spatial-Point-Patterns-Methodology-
> and-Applications-with-R/Baddeley-Rubak-Turner/9781482210200/
>
>
>
>
>
>
> El 21/04/2018 a las 18:05, David Unwin escribi?:
>
>> Can any *spatstat* user explain to me why the two p-values obtained below
>> for an envelope test against CSR are so different?
>>
>>
>>
>> data(swedishpines)
>>> d<-swedishpines
>>> plot(d)
>>> mad.test(d,Kest,nsim=999,verbose=F)
>>>
>>
>>
>>          Maximum absolute deviation test of CSR
>>
>>          Monte Carlo test based on 999 simulations
>>
>>          Summary function: K(r)
>>
>>          Reference function: theoretical
>>
>>          Alternative: two.sided
>>
>>          Interval of distance values: [0, 24] units (one unit = 0.1
>> metres)
>>
>>          Test statistic: Maximum absolute deviation
>>
>>          Deviation = observed minus theoretical
>>
>>
>>
>> data:  d
>>
>> mad = 150.69, rank = 216, p-value = *0.216*
>>
>>
>>
>> mad.test(d,*Lest*,nsim=999,verbose=F)
>>>
>>
>>
>>          Maximum absolute deviation test of CSR
>>
>>          Monte Carlo test based on 999 simulations
>>
>>          Summary function: L(r)
>>
>>          Reference function: theoretical
>>
>>          Alternative: two.sided
>>
>>          Interval of distance values: [0, 24] units (one unit = 0.1
>> metres)
>>
>>          Test statistic: Maximum absolute deviation
>>
>>          Deviation = observed minus theoretical
>>
>>
>>
>> data:  d
>>
>> mad = 2.9921, rank = 9, p-value = *0.009*
>>
>>
>>
>> *!!!*
>>
>>
>>
>> These data are dispersed relative to CSR:
>>
>> kl<-envelope(d,Kest,nsim=999,correction="border")
>>> plot(kl)
>>>
>>
>> Dave Unwin
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> .
>>
>>
> --
> Marcelino de la Cruz Rot
> Depto. de Biolog?a y Geolog?a
> F?sica y Qu?mica Inorg?nica
> Universidad Rey Juan Carlos
> M?stoles Espa?a
>
>


-- 


David J. Unwin
Professor Emeritus in Geography
Birkbeck, University of London
Phone  +44(0)1604 686526 Mobile: +44(0)7840 297239 (text preferred)
SKYPE: david.unwin99

	[[alternative HTML version deleted]]


From njb8 at st-andrews.ac.uk  Wed Apr 25 09:45:18 2018
From: njb8 at st-andrews.ac.uk (Nicholas Bradley)
Date: Wed, 25 Apr 2018 08:45:18 +0100
Subject: [R-sig-Geo] problem with enveloped test in spatstat
In-Reply-To: <CAE--03b4iteqZk8gLAUYOU-xWyVRt34Tqj-vm4B3wX=e1jAWXQ@mail.gmail.com>
References: <CAE--03ajqRMAmD+3qAxq29F3tMPgaPP-FSWsxtysyg_oeyZr_w@mail.gmail.com>
 <0a4e0d42-15a1-9f5e-4b63-c5db091fd7c2@urjc.es>
 <CAE--03b4iteqZk8gLAUYOU-xWyVRt34Tqj-vm4B3wX=e1jAWXQ@mail.gmail.com>
Message-ID: <CAASf6dtAzWf=59=BJdOFu+HmGjv0Z=TYjntfZ_SSh9xeNfmsWg@mail.gmail.com>

Good morning

I hope you are well

I have a question regarding the persp and perspPoints functions

I have the x and y spatial coordinates and also the altitude of all these
coordinates. However, despite consulting several manuals, I have as yet
been unable to create a terrain elevation plot and also to plot the points.
I have only managed to create a persp image showing density

I would therefore appreciate very much if anyone could be so kind as to help

Thank you very much

Kind regards

Nicholas

On 22 April 2018 at 08:46, David Unwin <ubfa915 at mail.bbk.ac.uk> wrote:

> Many thanks.  It is a superb book and amazing value for money.  My only
> excuse is that I have not as yet got to page 392.  Plotting the functions
> also makes it a lot clearer.
> Dave
>
> On 21 April 2018 at 22:50, Marcelino de la Cruz Rot <
> marcelino.delacruz at urjc.es> wrote:
>
> > Hi David,
> >
> > This is very clearly explained in page 393 of Baddeley et al. 2015.
> >
> > Basically, the MAD test is affected by transformations of the summary
> > function, with the L-function providing more powerful tests because of
> its
> > stabilization of the variance.
> >
> > If you are interested in point pattern analysis I would recommend you to
> > get a copy of this nice book.
> >
> >
> > Cheers,
> >
> > Marcelino
> >
> >
> > Adrian Baddeley, Ege Rubak, Rolf Turner (2015). Spatial Point Patterns:
> > Methodology and Applications with R. London: Chapman and
> >   Hall/CRC Press.
> > http://www.crcpress.com/Spatial-Point-Patterns-Methodology-
> > and-Applications-with-R/Baddeley-Rubak-Turner/9781482210200/
> >
> >
> >
> >
> >
> >
> > El 21/04/2018 a las 18:05, David Unwin escribi?:
> >
> >> Can any *spatstat* user explain to me why the two p-values obtained
> below
> >> for an envelope test against CSR are so different?
> >>
> >>
> >>
> >> data(swedishpines)
> >>> d<-swedishpines
> >>> plot(d)
> >>> mad.test(d,Kest,nsim=999,verbose=F)
> >>>
> >>
> >>
> >>          Maximum absolute deviation test of CSR
> >>
> >>          Monte Carlo test based on 999 simulations
> >>
> >>          Summary function: K(r)
> >>
> >>          Reference function: theoretical
> >>
> >>          Alternative: two.sided
> >>
> >>          Interval of distance values: [0, 24] units (one unit = 0.1
> >> metres)
> >>
> >>          Test statistic: Maximum absolute deviation
> >>
> >>          Deviation = observed minus theoretical
> >>
> >>
> >>
> >> data:  d
> >>
> >> mad = 150.69, rank = 216, p-value = *0.216*
> >>
> >>
> >>
> >> mad.test(d,*Lest*,nsim=999,verbose=F)
> >>>
> >>
> >>
> >>          Maximum absolute deviation test of CSR
> >>
> >>          Monte Carlo test based on 999 simulations
> >>
> >>          Summary function: L(r)
> >>
> >>          Reference function: theoretical
> >>
> >>          Alternative: two.sided
> >>
> >>          Interval of distance values: [0, 24] units (one unit = 0.1
> >> metres)
> >>
> >>          Test statistic: Maximum absolute deviation
> >>
> >>          Deviation = observed minus theoretical
> >>
> >>
> >>
> >> data:  d
> >>
> >> mad = 2.9921, rank = 9, p-value = *0.009*
> >>
> >>
> >>
> >> *!!!*
> >>
> >>
> >>
> >> These data are dispersed relative to CSR:
> >>
> >> kl<-envelope(d,Kest,nsim=999,correction="border")
> >>> plot(kl)
> >>>
> >>
> >> Dave Unwin
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at r-project.org
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >> .
> >>
> >>
> > --
> > Marcelino de la Cruz Rot
> > Depto. de Biolog?a y Geolog?a
> > F?sica y Qu?mica Inorg?nica
> > Universidad Rey Juan Carlos
> > M?stoles Espa?a
> >
> >
>
>
> --
>
>
> David J. Unwin
> Professor Emeritus in Geography
> Birkbeck, University of London
> Phone  +44(0)1604 686526 Mobile: +44(0)7840 297239 (text preferred)
> SKYPE: david.unwin99
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Kind regards

Nicholas Bradley

PhD Candidate
School of International Relations
University of St Andrews

	[[alternative HTML version deleted]]


From paulo.flores.mail at gmail.com  Wed Apr 25 12:26:23 2018
From: paulo.flores.mail at gmail.com (Paulo Flores Ribeiro)
Date: Wed, 25 Apr 2018 11:26:23 +0100
Subject: [R-sig-Geo] Polygon width
Message-ID: <5c45c439-d75a-f3d0-ad96-5c9f3530a935@gmail.com>

Hello,

I have a shapefile with ca. 25000 polygons. Each polygon has an average 
of 40 vertices (nodes). I would like to extract, for each polygon, the 
distance separating the two most distant vertices (aka "polygon 
diagonal" or "maximum polygon width"). It is not important whether the 
polygon is convex or concave, so the lines connecting the vertices can 
be inside or outside the polygon. The desired result would be a 
two-column array, with a number of rows equal to the number of polygons, 
and where the first column is the id of the polygons, and the second the 
"maximum width" of the corresponding polygon.

What would be the best way to do this, considering that the calculation 
will probably require frequent updates (e.g. due to changes in the shape 
of the polygons)?

Thanks in advance,

PauloFR


From b.rowlingson at lancaster.ac.uk  Wed Apr 25 13:27:19 2018
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 25 Apr 2018 12:27:19 +0100
Subject: [R-sig-Geo] Polygon width
In-Reply-To: <5c45c439-d75a-f3d0-ad96-5c9f3530a935@gmail.com>
References: <5c45c439-d75a-f3d0-ad96-5c9f3530a935@gmail.com>
Message-ID: <CANVKczMmXsa0DTzgw7xnAs=a_+Z4WmTiQ=5q+YLiP4Bv75J3aw@mail.gmail.com>

Do you want great-circle distance or is your space small enough that you
can use planar coordinates?

Are your polygons all single rings or are there islands and/or holes? Does
that matter?

The straightforward way would be to coerce the polygons to points, compute
the distance matrix, then take the maximum. Depending on if you are reading
your shapefile into sp or sf classes, the functions would be a bit
different. You should try and implement the straightforward way, test it
for correctness, and then worry about the "best way" if the straightforward
way isn't what you need. Its often the case that "best" ways need fancy
data structures or complex algorithms with more opportunity for bugs. Start
simple, work up.

For example, using sf, here's the max distance between any points in the
first feature of `pcs`

> max(st_distance(st_cast(st_geometry(pcs[1,]),"POINT")))
172.556 m

loop from 1 to N or otherwise apply over the features, and you're done.

Barry



On Wed, Apr 25, 2018 at 11:26 AM, Paulo Flores Ribeiro <
paulo.flores.mail at gmail.com> wrote:

> Hello,
>
> I have a shapefile with ca. 25000 polygons. Each polygon has an average of
> 40 vertices (nodes). I would like to extract, for each polygon, the
> distance separating the two most distant vertices (aka "polygon diagonal"
> or "maximum polygon width"). It is not important whether the polygon is
> convex or concave, so the lines connecting the vertices can be inside or
> outside the polygon. The desired result would be a two-column array, with a
> number of rows equal to the number of polygons, and where the first column
> is the id of the polygons, and the second the "maximum width" of the
> corresponding polygon.
>
> What would be the best way to do this, considering that the calculation
> will probably require frequent updates (e.g. due to changes in the shape of
> the polygons)?
>
> Thanks in advance,
>
> PauloFR
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From ubfa915 at mail.bbk.ac.uk  Wed Apr 25 14:05:00 2018
From: ubfa915 at mail.bbk.ac.uk (David Unwin)
Date: Wed, 25 Apr 2018 13:05:00 +0100
Subject: [R-sig-Geo] Interpolation
Message-ID: <CAE--03ZX-HbiBL1NF8qJAqO6_3uG3dKGBQ711aT1bs=GSeZSkw@mail.gmail.com>

a) Create a txt file looking something like:



X     Y     Z

0.3   6.1   870

1.4   6.2   793

2.4   6.1   755

etc

5.7   3     830



b) Thee column names are obvious. Then a possible workflow is:


topo_datatable <- read.table(choose.files(), header = TRUE)#read in

library(maptools)# two packages needed

library(gstat)

coordinates(topo_datatable) <- c("X", "Y")#create spatial object

#create grid for estimates

topo_grid <- spsample(topo_datatable, "regular", n=3720)

gridded(topo_grid) <- TRUE

fullgrid(topo_grid) <- TRUE

#this is simple inverse distance interpolation

#with a distance exponent of 2.0. There are lots of other options

exp<- 2.0

topo_idw <- idw(Z~1,topo_datatable,newdata=topo_grid,idp=exp)

#map the results, lots of options

im <- as.image.SpatialGridDataFrame(topo_idw)

topo_SLDF <- ContourLines2SLDF(contourLines(im))

topo_spl <- list("sp.lines", topo_SLDF)

spplot(topo_idw, "var1.pred", sp.layout=topo_spl)

image(topo_idw, "var1.pred", col=terrain.colors(20))

contour(topo_idw, "var1.pred", add=TRUE)

Dave Unwin

	[[alternative HTML version deleted]]


From paulo.flores.mail at gmail.com  Wed Apr 25 18:24:57 2018
From: paulo.flores.mail at gmail.com (Paulo Flores Ribeiro)
Date: Wed, 25 Apr 2018 17:24:57 +0100
Subject: [R-sig-Geo] Polygon width
In-Reply-To: <CANVKczMmXsa0DTzgw7xnAs=a_+Z4WmTiQ=5q+YLiP4Bv75J3aw@mail.gmail.com>
References: <5c45c439-d75a-f3d0-ad96-5c9f3530a935@gmail.com>
 <CANVKczMmXsa0DTzgw7xnAs=a_+Z4WmTiQ=5q+YLiP4Bv75J3aw@mail.gmail.com>
Message-ID: <7d23def1-8d31-20e8-33e5-874287db1d52@gmail.com>

Thank you, Barry. I am using planar coordinates (meters) and Euclidean 
distances. The shape or size of the polygons is not important (for 
illustration purposes, imagine that polygons are farm boundaries and 
that each farm is a single polygon). I know how to extract the maximum 
distance in a single polygon by calculating the distance matrix and 
selecting the maximum value. My "difficulty" is exactly in the coding of 
the loop process (or in the construction of the "function" to be used in 
the apply approach), so that I can apply it "automatically" to 25,000 
polygons. I am using the rgadl package, but I can switch to sf.
Thanks for any help.
Cheers,
PauloFR

?s 12:27 de 25-04-2018, Barry Rowlingson escreveu:
> Do you want great-circle distance or is your space small enough that 
> you can use planar coordinates?
>
> Are your polygons all single rings or are there islands and/or holes? 
> Does that matter?
>
> The straightforward way would be to coerce the polygons to points, 
> compute the distance matrix, then take the maximum. Depending on if 
> you are reading your shapefile into sp or sf classes, the functions 
> would be a bit different. You should try and implement the 
> straightforward way, test it for correctness, and then worry about the 
> "best way" if the straightforward way isn't what you need. Its often 
> the case that "best" ways need fancy data structures or complex 
> algorithms with more opportunity for bugs. Start simple, work up.
>
> For example, using sf, here's the max distance between any points in 
> the first feature of `pcs`
>
> > max(st_distance(st_cast(st_geometry(pcs[1,]),"POINT")))
> 172.556 m
>
> loop from 1 to N or otherwise apply over the features, and you're done.
>
> Barry
>
>
>
> On Wed, Apr 25, 2018 at 11:26 AM, Paulo Flores Ribeiro 
> <paulo.flores.mail at gmail.com <mailto:paulo.flores.mail at gmail.com>> wrote:
>
>     Hello,
>
>     I have a shapefile with ca. 25000 polygons. Each polygon has an
>     average of 40 vertices (nodes). I would like to extract, for each
>     polygon, the distance separating the two most distant vertices
>     (aka "polygon diagonal" or "maximum polygon width"). It is not
>     important whether the polygon is convex or concave, so the lines
>     connecting the vertices can be inside or outside the polygon. The
>     desired result would be a two-column array, with a number of rows
>     equal to the number of polygons, and where the first column is the
>     id of the polygons, and the second the "maximum width" of the
>     corresponding polygon.
>
>     What would be the best way to do this, considering that the
>     calculation will probably require frequent updates (e.g. due to
>     changes in the shape of the polygons)?
>
>     Thanks in advance,
>
>     PauloFR
>
>     _______________________________________________
>     R-sig-Geo mailing list
>     R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>
>
>
> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient> 
> 	Sem v?rus. www.avg.com 
> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient> 
>
>
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>


	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Wed Apr 25 19:16:20 2018
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 25 Apr 2018 18:16:20 +0100
Subject: [R-sig-Geo] Polygon width
In-Reply-To: <d4d69c68389740dfa4b01b9cd22695d2@AM6PR04MB4264.eurprd04.prod.outlook.com>
References: <5c45c439-d75a-f3d0-ad96-5c9f3530a935@gmail.com>
 <CANVKczMmXsa0DTzgw7xnAs=a_+Z4WmTiQ=5q+YLiP4Bv75J3aw@mail.gmail.com>
 <d4d69c68389740dfa4b01b9cd22695d2@AM6PR04MB4264.eurprd04.prod.outlook.com>
Message-ID: <CANVKczN7MQ8EX=bXjW5paKiu8j0jWUb57OvmVY=44fUt31D0uQ@mail.gmail.com>

Loop over the row indexes of an sf-class object `pctest`, applying a
function given the row index which returns the distance:

 > ppa =
sapply(1:nrow(pctest),function(i){max(st_distance(st_cast(st_geometry(pctest[i,]),"POINT")))})
 > ppa
  [1] 172.55598 360.77081 107.53889 137.17785  51.66645 132.82052 113.00875
  [8] 161.02432 141.13909  88.67002

If you want to make that a new column, do `pctest$maxdist = ppa`

And test on a simple example - make sure a unit square returns
approximately sqrt(2)!

Barry




On Wed, Apr 25, 2018 at 5:24 PM, Paulo Flores Ribeiro <
paulo.flores.mail at gmail.com> wrote:

> Thank you, Barry. I am using planar coordinates (meters) and Euclidean
> distances. The shape or size of the polygons is not important (for
> illustration purposes, imagine that polygons are farm boundaries and that
> each farm is a single polygon). I know how to extract the maximum
> distance in a single polygon by calculating the distance matrix and
> selecting the maximum value. My "difficulty" is exactly in the coding of
> the loop process (or in the construction of the "function" to be used in
> the apply approach), so that I can apply it "automatically" to 25,000
> polygons. I am using the rgadl package, but I can switch to sf.
> Thanks for any help.
> Cheers,
> PauloFR
>
> ?s 12:27 de 25-04-2018, Barry Rowlingson escreveu:
>
> Do you want great-circle distance or is your space small enough that you
> can use planar coordinates?
>
> Are your polygons all single rings or are there islands and/or holes? Does
> that matter?
>
> The straightforward way would be to coerce the polygons to points, compute
> the distance matrix, then take the maximum. Depending on if you are reading
> your shapefile into sp or sf classes, the functions would be a bit
> different. You should try and implement the straightforward way, test it
> for correctness, and then worry about the "best way" if the straightforward
> way isn't what you need. Its often the case that "best" ways need fancy
> data structures or complex algorithms with more opportunity for bugs. Start
> simple, work up.
>
> For example, using sf, here's the max distance between any points in the
> first feature of `pcs`
>
> > max(st_distance(st_cast(st_geometry(pcs[1,]),"POINT")))
> 172.556 m
>
> loop from 1 to N or otherwise apply over the features, and you're done.
>
> Barry
>
>
>
> On Wed, Apr 25, 2018 at 11:26 AM, Paulo Flores Ribeiro <
> paulo.flores.mail at gmail.com> wrote:
>
>> Hello,
>>
>> I have a shapefile with ca. 25000 polygons. Each polygon has an average
>> of 40 vertices (nodes). I would like to extract, for each polygon, the
>> distance separating the two most distant vertices (aka "polygon diagonal"
>> or "maximum polygon width"). It is not important whether the polygon is
>> convex or concave, so the lines connecting the vertices can be inside or
>> outside the polygon. The desired result would be a two-column array, with a
>> number of rows equal to the number of polygons, and where the first column
>> is the id of the polygons, and the second the "maximum width" of the
>> corresponding polygon.
>>
>> What would be the best way to do this, considering that the calculation
>> will probably require frequent updates (e.g. due to changes in the shape of
>> the polygons)?
>>
>> Thanks in advance,
>>
>> PauloFR
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
>
> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient> Sem
> v?rus. www.avg.com
> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient>
> <#m_-2085622191602335703_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
>
>

	[[alternative HTML version deleted]]


From paulo.flores.mail at gmail.com  Wed Apr 25 19:31:17 2018
From: paulo.flores.mail at gmail.com (Paulo Flores Ribeiro)
Date: Wed, 25 Apr 2018 18:31:17 +0100
Subject: [R-sig-Geo] Polygon width
In-Reply-To: <CANVKczN7MQ8EX=bXjW5paKiu8j0jWUb57OvmVY=44fUt31D0uQ@mail.gmail.com>
References: <5c45c439-d75a-f3d0-ad96-5c9f3530a935@gmail.com>
 <CANVKczMmXsa0DTzgw7xnAs=a_+Z4WmTiQ=5q+YLiP4Bv75J3aw@mail.gmail.com>
 <d4d69c68389740dfa4b01b9cd22695d2@AM6PR04MB4264.eurprd04.prod.outlook.com>
 <CANVKczN7MQ8EX=bXjW5paKiu8j0jWUb57OvmVY=44fUt31D0uQ@mail.gmail.com>
Message-ID: <a9405abe-e4ce-b0d1-72ee-5d659616e6d9@gmail.com>

Thank you, Barry! In the meanwhile, I've been exploring other paths and 
I think I found another solution, using loop. For a 
SpatialPolygonsDataFrame named "map4" the code was:

dmax <- data.frame()
for (i in 1:nrow(map4)) {
 ? poly = map4 at polygons[[i]]@Polygons[[1]]@coords
 ? dmax <- rbind.data.frame(dmax, max(dist(cbind(poly[,1],poly[,2]))))
}
print(dmax)

Anyway, I'll certainly try out your alternative solution, based on the 
(s)apply function, to see which one is most efficient.

Thank you so much again,

PauloFR


?s 18:16 de 25-04-2018, Barry Rowlingson escreveu:
> Loop over the row indexes of an sf-class object `pctest`, applying a 
> function given the row index which returns the distance:
>
> ?> ppa = 
> sapply(1:nrow(pctest),function(i){max(st_distance(st_cast(st_geometry(pctest[i,]),"POINT")))})
> ?> ppa
> ? [1] 172.55598 360.77081 107.53889 137.17785? 51.66645 132.82052 
> 113.00875
> ? [8] 161.02432 141.13909? 88.67002
>
> If you want to make that a new column, do `pctest$maxdist = ppa`
>
> And test on a simple example - make sure a unit square returns 
> approximately sqrt(2)!
>
> Barry
>
>
>
>
> On Wed, Apr 25, 2018 at 5:24 PM, Paulo Flores Ribeiro 
> <paulo.flores.mail at gmail.com <mailto:paulo.flores.mail at gmail.com>> wrote:
>
>     Thank you, Barry. I am using planar coordinates (meters) and
>     Euclidean distances. The shape or size of the polygons is not
>     important (for illustration purposes, imagine that polygons are
>     farm boundaries and that each farm is a single polygon). I know
>     how to extract the maximum distance in a single polygon by
>     calculating the distance matrix and selecting the maximum value.
>     My "difficulty" is exactly in the coding of the loop process (or
>     in the construction of the "function" to be used in the apply
>     approach), so that I can apply it "automatically" to 25,000
>     polygons. I am using the rgadl package, but I can switch to sf.
>     Thanks for any help.
>     Cheers,
>     PauloFR
>
>     ?s 12:27 de 25-04-2018, Barry Rowlingson escreveu:
>>     Do you want great-circle distance or is your space small enough
>>     that you can use planar coordinates?
>>
>>     Are your polygons all single rings or are there islands and/or
>>     holes? Does that matter?
>>
>>     The straightforward way would be to coerce the polygons to
>>     points, compute the distance matrix, then take the maximum.
>>     Depending on if you are reading your shapefile into sp or sf
>>     classes, the functions would be a bit different. You should try
>>     and implement the straightforward way, test it for correctness,
>>     and then worry about the "best way" if the straightforward way
>>     isn't what you need. Its often the case that "best" ways need
>>     fancy data structures or complex algorithms with more opportunity
>>     for bugs. Start simple, work up.
>>
>>     For example, using sf, here's the max distance between any points
>>     in the first feature of `pcs`
>>
>>     > max(st_distance(st_cast(st_geometry(pcs[1,]),"POINT")))
>>     172.556 m
>>
>>     loop from 1 to N or otherwise apply over the features, and you're
>>     done.
>>
>>     Barry
>>
>>
>>
>>     On Wed, Apr 25, 2018 at 11:26 AM, Paulo Flores Ribeiro
>>     <paulo.flores.mail at gmail.com
>>     <mailto:paulo.flores.mail at gmail.com>> wrote:
>>
>>         Hello,
>>
>>         I have a shapefile with ca. 25000 polygons. Each polygon has
>>         an average of 40 vertices (nodes). I would like to extract,
>>         for each polygon, the distance separating the two most
>>         distant vertices (aka "polygon diagonal" or "maximum polygon
>>         width"). It is not important whether the polygon is convex or
>>         concave, so the lines connecting the vertices can be inside
>>         or outside the polygon. The desired result would be a
>>         two-column array, with a number of rows equal to the number
>>         of polygons, and where the first column is the id of the
>>         polygons, and the second the "maximum width" of the
>>         corresponding polygon.
>>
>>         What would be the best way to do this, considering that the
>>         calculation will probably require frequent updates (e.g. due
>>         to changes in the shape of the polygons)?
>>
>>         Thanks in advance,
>>
>>         PauloFR
>>
>>         _______________________________________________
>>         R-sig-Geo mailing list
>>         R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>>         https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>         <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>>
>>
>>
>>     <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient>
>>     	Sem v?rus. www.avg.com
>>     <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient>
>>
>>
>
>


From b.rowlingson at lancaster.ac.uk  Wed Apr 25 22:02:44 2018
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 25 Apr 2018 21:02:44 +0100
Subject: [R-sig-Geo] Polygon width
In-Reply-To: <d6b89f16d69848178a7c404ee0078220@AM6PR04MB4264.eurprd04.prod.outlook.com>
References: <5c45c439-d75a-f3d0-ad96-5c9f3530a935@gmail.com>
 <CANVKczMmXsa0DTzgw7xnAs=a_+Z4WmTiQ=5q+YLiP4Bv75J3aw@mail.gmail.com>
 <d4d69c68389740dfa4b01b9cd22695d2@AM6PR04MB4264.eurprd04.prod.outlook.com>
 <CANVKczN7MQ8EX=bXjW5paKiu8j0jWUb57OvmVY=44fUt31D0uQ@mail.gmail.com>
 <d6b89f16d69848178a7c404ee0078220@AM6PR04MB4264.eurprd04.prod.outlook.com>
Message-ID: <CANVKczO+wWWMft-j8AWypw_=etb_nb0A0nM094L+B2YZsighUQ@mail.gmail.com>

Growing a data frame is usually a bad idea, and R can get slow as the
system may have to create a fresh data frame each time. If you want to use
a for-loop, make a vector or data frame of the right size beforehand and
then fill it element-by-element - sketch:

n = nrow(data)
result = rep(NA, n)
for(i in 1:n){
  result[i] = something(i)
}




On Wed, Apr 25, 2018 at 6:31 PM, Paulo Flores Ribeiro <
paulo.flores.mail at gmail.com> wrote:

> Thank you, Barry! In the meanwhile, I've been exploring other paths and
> I think I found another solution, using loop. For a
> SpatialPolygonsDataFrame named "map4" the code was:
>
> dmax <- data.frame()
> for (i in 1:nrow(map4)) {
>    poly = map4 at polygons[[i]]@Polygons[[1]]@coords
>    dmax <- rbind.data.frame(dmax, max(dist(cbind(poly[,1],poly[,2]))))
> }
> print(dmax)
>
> Anyway, I'll certainly try out your alternative solution, based on the
> (s)apply function, to see which one is most efficient.
>
> Thank you so much again,
>
> PauloFR
>
>
> ?s 18:16 de 25-04-2018, Barry Rowlingson escreveu:
> > Loop over the row indexes of an sf-class object `pctest`, applying a
> > function given the row index which returns the distance:
> >
> >  > ppa =
> > sapply(1:nrow(pctest),function(i){max(st_distance(
> st_cast(st_geometry(pctest[i,]),"POINT")))})
> >  > ppa
> >   [1] 172.55598 360.77081 107.53889 137.17785  51.66645 132.82052
> > 113.00875
> >   [8] 161.02432 141.13909  88.67002
> >
> > If you want to make that a new column, do `pctest$maxdist = ppa`
> >
> > And test on a simple example - make sure a unit square returns
> > approximately sqrt(2)!
> >
> > Barry
> >
> >
> >
> >
> > On Wed, Apr 25, 2018 at 5:24 PM, Paulo Flores Ribeiro
> > <paulo.flores.mail at gmail.com <mailto:paulo.flores.mail at gmail.com>>
> wrote:
> >
> >     Thank you, Barry. I am using planar coordinates (meters) and
> >     Euclidean distances. The shape or size of the polygons is not
> >     important (for illustration purposes, imagine that polygons are
> >     farm boundaries and that each farm is a single polygon). I know
> >     how to extract the maximum distance in a single polygon by
> >     calculating the distance matrix and selecting the maximum value.
> >     My "difficulty" is exactly in the coding of the loop process (or
> >     in the construction of the "function" to be used in the apply
> >     approach), so that I can apply it "automatically" to 25,000
> >     polygons. I am using the rgadl package, but I can switch to sf.
> >     Thanks for any help.
> >     Cheers,
> >     PauloFR
> >
> >     ?s 12:27 de 25-04-2018, Barry Rowlingson escreveu:
> >>     Do you want great-circle distance or is your space small enough
> >>     that you can use planar coordinates?
> >>
> >>     Are your polygons all single rings or are there islands and/or
> >>     holes? Does that matter?
> >>
> >>     The straightforward way would be to coerce the polygons to
> >>     points, compute the distance matrix, then take the maximum.
> >>     Depending on if you are reading your shapefile into sp or sf
> >>     classes, the functions would be a bit different. You should try
> >>     and implement the straightforward way, test it for correctness,
> >>     and then worry about the "best way" if the straightforward way
> >>     isn't what you need. Its often the case that "best" ways need
> >>     fancy data structures or complex algorithms with more opportunity
> >>     for bugs. Start simple, work up.
> >>
> >>     For example, using sf, here's the max distance between any points
> >>     in the first feature of `pcs`
> >>
> >>     > max(st_distance(st_cast(st_geometry(pcs[1,]),"POINT")))
> >>     172.556 m
> >>
> >>     loop from 1 to N or otherwise apply over the features, and you're
> >>     done.
> >>
> >>     Barry
> >>
> >>
> >>
> >>     On Wed, Apr 25, 2018 at 11:26 AM, Paulo Flores Ribeiro
> >>     <paulo.flores.mail at gmail.com
> >>     <mailto:paulo.flores.mail at gmail.com>> wrote:
> >>
> >>         Hello,
> >>
> >>         I have a shapefile with ca. 25000 polygons. Each polygon has
> >>         an average of 40 vertices (nodes). I would like to extract,
> >>         for each polygon, the distance separating the two most
> >>         distant vertices (aka "polygon diagonal" or "maximum polygon
> >>         width"). It is not important whether the polygon is convex or
> >>         concave, so the lines connecting the vertices can be inside
> >>         or outside the polygon. The desired result would be a
> >>         two-column array, with a number of rows equal to the number
> >>         of polygons, and where the first column is the id of the
> >>         polygons, and the second the "maximum width" of the
> >>         corresponding polygon.
> >>
> >>         What would be the best way to do this, considering that the
> >>         calculation will probably require frequent updates (e.g. due
> >>         to changes in the shape of the polygons)?
> >>
> >>         Thanks in advance,
> >>
> >>         PauloFR
> >>
> >>         _______________________________________________
> >>         R-sig-Geo mailing list
> >>         R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
> >>         https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>         <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
> >>
> >>
> >>
> >>     <http://www.avg.com/email-signature?utm_medium=email&
> utm_source=link&utm_campaign=sig-email&utm_content=emailclient>
> >>      Sem v?rus. www.avg.com
> >>     <http://www.avg.com/email-signature?utm_medium=email&
> utm_source=link&utm_campaign=sig-email&utm_content=emailclient>
> >>
> >>
> >
> >
>
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Wed Apr 25 23:55:02 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 26 Apr 2018 09:55:02 +1200
Subject: [R-sig-Geo] problem with enveloped test in spatstat
In-Reply-To: <CAASf6dtAzWf=59=BJdOFu+HmGjv0Z=TYjntfZ_SSh9xeNfmsWg@mail.gmail.com>
References: <CAE--03ajqRMAmD+3qAxq29F3tMPgaPP-FSWsxtysyg_oeyZr_w@mail.gmail.com>
 <0a4e0d42-15a1-9f5e-4b63-c5db091fd7c2@urjc.es>
 <CAE--03b4iteqZk8gLAUYOU-xWyVRt34Tqj-vm4B3wX=e1jAWXQ@mail.gmail.com>
 <CAASf6dtAzWf=59=BJdOFu+HmGjv0Z=TYjntfZ_SSh9xeNfmsWg@mail.gmail.com>
Message-ID: <9d982d65-cd56-331b-8448-702ccdcb1cc3@auckland.ac.nz>

On 25/04/18 19:45, Nicholas Bradley wrote:
> Good morning
> 
> I hope you are well
> 
> I have a question regarding the persp and perspPoints functions
> 
> I have the x and y spatial coordinates and also the altitude of all these
> coordinates. However, despite consulting several manuals, I have as yet
> been unable to create a terrain elevation plot and also to plot the points.
> I have only managed to create a persp image showing density
> 
> I would therefore appreciate very much if anyone could be so kind as to help.

Please don't hijack threads.  Your question has nothing to do with 
envelope tests.  You have a new question, so start a new thread with an 
appropriate subject line.

I shall shortly attempt to answer your question in such a new thread.

cheers,

Rolf Turner


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r.turner at auckland.ac.nz  Thu Apr 26 00:03:50 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 26 Apr 2018 10:03:50 +1200
Subject: [R-sig-Geo] Terrain elevation plots with points shown --- spatstat.
Message-ID: <ea9060df-1791-0c9a-f2db-d0783681e504@auckland.ac.nz>

On 25/04/18 19:45, Nicholas Bradley wrote (in a miss-titled post):

> Good morning
> 
> I hope you are well
> 
> I have a question regarding the persp and perspPoints functions
> 
> I have the x and y spatial coordinates and also the altitude of all
> these coordinates. However, despite consulting several manuals, I
> have as yet been unable to create a terrain elevation plot and also
> to plot the points.
> I have only managed to create a persp image showing density
> 
> I would therefore appreciate very much if anyone could be so kind as to help.

Your question is a bit vague and does not supply anything like a 
reproducible example, so it is hard to answer.

The cover of the book (Baddeley et al.) that Marcelino de la Cruz Rot 
has referred to, in the thread that you hijacked, displays a plot that 
might be something like what you want.  The code for producing this plot 
can be found in the online supplement to that book at:

     http://book.spatstat.org/chapter-code/chapter09.html

For your convenience here are the relevant lines of code:

     library(spatstat)
     fit     <- ppm(bei ~ polynom(grad, elev, 2), data=bei.extra)
     lamhat  <- predict(fit)
     col.lam <- topo.colors
     col.pts <- 1
     M       <- persp(bei.extra$elev, colin=lamhat,
                      colmap=col.lam, shade=0.4, theta=-55,
                      phi=25, expand=6, box=FALSE,
                      apron=TRUE,  visible=TRUE, main="")
                perspPoints(bei, Z=bei.extra$elev, M=M,
                            pch=".", col=col.pts, cex=1.25)

HTH

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ranjanmano167 at gmail.com  Thu Apr 26 00:12:07 2018
From: ranjanmano167 at gmail.com (Manoranjan Muthusamy)
Date: Wed, 25 Apr 2018 23:12:07 +0100
Subject: [R-sig-Geo] Co-kriging when the variable of interest and auxiliary
 variable(s) are not measured at the same locations
Message-ID: <CANqyHbQ-grgyRQGtODKWk4bXtBEf79y4bskEE2rMu28cO2M+wg@mail.gmail.com>

This is the first time I'm using ko-kriging in gstat. My problem is that
I'm not sure how to prepare the data frame to supply to co-kriging when the
variable of interest and auxiliary variables are not measured at the same
locations.

Data frame with the variable of interest, z_ar, is voi_gs

> head(voi_gs)
             x        y     z_ar
8974  312216.6 530439.8 49.03470
8283  312084.6 530559.8 57.15355
5057  311772.6 530883.8 49.13453
1551  311976.6 531207.8 44.73679
10116 312168.6 530163.8 50.45549
6155  312528.6 530787.8 62.70750

Data frame with the auxiliary variable, z_ptsis aux_gs

> head(aux_gs)
            x        y    z_pts
9564 312198.6 530313.8 75.91368
6584 311766.6 530745.8 38.87462
2138 311562.6 531153.8 58.62555
9110 312534.6 530421.8 68.35654
9525 312366.6 530325.8 54.26653
7497 311442.6 530649.8 38.95024

I combined them into one data frame to supply to variogram() and
krige() functions.
Since non of the locations are same between voi_gs and aux_gs, I introduced
NA values and combined them in the following way

> aux_gs$z_ar=NA
> voi_gs$z_pts=NA
> comb_gs=rbind(aux_gs,voi_gs)
> head(comb_gs)
            x        y    z_pts z_ar
9564 312198.6 530313.8 75.91368   NA
6584 311766.6 530745.8 38.87462   NA
2138 311562.6 531153.8 58.62555   NA
9110 312534.6 530421.8 68.35654   NA
9525 312366.6 530325.8 54.26653   NA
7497 311442.6 530649.8 38.95024   NA
> tail(comb_gs)
            x        y z_pts     z_ar
180  312468.6 531363.8    NA 70.54528
8633 312264.6 530511.8    NA 44.34631
7694 312492.6 530631.8    NA 57.30173
1079 312108.6 531255.8    NA 46.96482
2230 311124.6 531135.8    NA 40.36449
2201 312312.6 531147.8    NA 44.85896

and then constructing cross-variogram

> coordinates(comb_gs) = ~x+y
> g = gstat(formula=z_pts~z_ar, data=comb_gs)
> vg = variogram(g)

but variogram function does not accept NA values and gives me an error. I
know I can't have NA values in the data, but I don't know how else I can
create the data frame to construct the cross-variogram. Any help is really
appreciated. Thanks.

	[[alternative HTML version deleted]]


From gestauffer at gmail.com  Thu Apr 26 18:31:55 2018
From: gestauffer at gmail.com (Glenn Stauffer)
Date: Thu, 26 Apr 2018 11:31:55 -0500
Subject: [R-sig-Geo] Error using spsample on SpatialLines in Linux OS
Message-ID: <008e01d3dd7c$18130820$48391860$@gmail.com>

I ran across a problem when trying to use spsample to sample points along a
line, while in a Linux OS (Mint 18.3). The following code (which works fine
in Win 10): 

 

pts <- matrix(c(c(6000,6015,6021,6035,6050),
c(6000,5995,6000,6040,6095)),5,2,byrow=FALSE)
L = SpatialLines(list(Lines(list(Line(coordinates(pts))),"X")),proj4string =
CRS("+init=epsg:3071"))
plot(L)
Lsamp <- spsample(L,10,type="regular",offset=0.5) # this is the line that
generates the error

 

produces the following error:

 

Error in .C("sp_lengths", x, y, n, lengths, lonlat, PACKAGE = "sp") : 
  "sp_lengths" not available for .C() for package "sp"

Could this be related to some wrong versions of certain dependencies (e.g.,
GDAL)? I don't know much about that, but I did run into that issue with
trying to install other packages (rgeos, sf). In any case, how can I prevent
this error?

 

Thanks, 

Glenn

 

 


	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Thu Apr 26 18:34:37 2018
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 26 Apr 2018 18:34:37 +0200
Subject: [R-sig-Geo] Error using spsample on SpatialLines in Linux OS
In-Reply-To: <008e01d3dd7c$18130820$48391860$@gmail.com>
References: <008e01d3dd7c$18130820$48391860$@gmail.com>
Message-ID: <11130866-7cf5-b6c1-8d04-953d24d65659@uni-muenster.de>

I would try reinstalling the package.

On 04/26/2018 06:31 PM, Glenn Stauffer wrote:
> I ran across a problem when trying to use spsample to sample points along a
> line, while in a Linux OS (Mint 18.3). The following code (which works fine
> in Win 10): 
> 
>  
> 
> pts <- matrix(c(c(6000,6015,6021,6035,6050),
> c(6000,5995,6000,6040,6095)),5,2,byrow=FALSE)
> L = SpatialLines(list(Lines(list(Line(coordinates(pts))),"X")),proj4string =
> CRS("+init=epsg:3071"))
> plot(L)
> Lsamp <- spsample(L,10,type="regular",offset=0.5) # this is the line that
> generates the error
> 
>  
> 
> produces the following error:
> 
>  
> 
> Error in .C("sp_lengths", x, y, n, lengths, lonlat, PACKAGE = "sp") : 
>   "sp_lengths" not available for .C() for package "sp"
> 
> Could this be related to some wrong versions of certain dependencies (e.g.,
> GDAL)? I don't know much about that, but I did run into that issue with
> trying to install other packages (rgeos, sf). In any case, how can I prevent
> this error?
> 
>  
> 
> Thanks, 
> 
> Glenn
> 
>  
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48151 Muenster, Germany
Phone: +49 251 8333081


From gestauffer at gmail.com  Thu Apr 26 18:52:50 2018
From: gestauffer at gmail.com (Glenn Stauffer)
Date: Thu, 26 Apr 2018 11:52:50 -0500
Subject: [R-sig-Geo] Error using spsample on SpatialLines in Linux OS
In-Reply-To: <11130866-7cf5-b6c1-8d04-953d24d65659@uni-muenster.de>
References: <008e01d3dd7c$18130820$48391860$@gmail.com>
 <11130866-7cf5-b6c1-8d04-953d24d65659@uni-muenster.de>
Message-ID: <00a001d3dd7f$04376280$0ca62780$@gmail.com>

Do you mean the sp package? I should have mentioned that I already tried
that.

-----Original Message-----
From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Edzer
Pebesma
Sent: Thursday, April 26, 2018 11:35 AM
To: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] Error using spsample on SpatialLines in Linux OS

I would try reinstalling the package.

On 04/26/2018 06:31 PM, Glenn Stauffer wrote:
> I ran across a problem when trying to use spsample to sample points 
> along a line, while in a Linux OS (Mint 18.3). The following code 
> (which works fine in Win 10):
> 
>  
> 
> pts <- matrix(c(c(6000,6015,6021,6035,6050),
> c(6000,5995,6000,6040,6095)),5,2,byrow=FALSE)
> L = 
> SpatialLines(list(Lines(list(Line(coordinates(pts))),"X")),proj4string 
> =
> CRS("+init=epsg:3071"))
> plot(L)
> Lsamp <- spsample(L,10,type="regular",offset=0.5) # this is the line 
> that generates the error
> 
>  
> 
> produces the following error:
> 
>  
> 
> Error in .C("sp_lengths", x, y, n, lengths, lonlat, PACKAGE = "sp") : 
>   "sp_lengths" not available for .C() for package "sp"
> 
> Could this be related to some wrong versions of certain dependencies 
> (e.g., GDAL)? I don't know much about that, but I did run into that 
> issue with trying to install other packages (rgeos, sf). In any case, 
> how can I prevent this error?
> 
>  
> 
> Thanks,
> 
> Glenn
> 
>  
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

--
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48151 Muenster, Germany
Phone: +49 251 8333081

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From chino_tones at hotmail.com  Thu Apr 26 18:55:12 2018
From: chino_tones at hotmail.com (Joelle k. Akram)
Date: Thu, 26 Apr 2018 16:55:12 +0000
Subject: [R-sig-Geo] gstat - variogram fit analysis question
Message-ID: <YQXPR0101MB139749E6DBA5841D3D6F5671908E0@YQXPR0101MB1397.CANPRD01.PROD.OUTLOOK.COM>

hello,


my fitted vgm using Gaussian model ('Gau') via 'fit.variogram' in gstat looks as follows:

[cid:c41e92ec-56ae-42df-8131-1e2d960e0ce3]


Here are my questions:


1)-is Gaussian model an optimal choice

2)- my coordinates which I use for variogram fitting is in (lat, long), should I use UTM instead?

3)- does the general variogram look visually correct , i.e., nugget, sill, and range values?


thanks,

Joe

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20180426/5b13989e/attachment.html>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: pastedImage.png
Type: image/png
Size: 11465 bytes
Desc: pastedImage.png
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20180426/5b13989e/attachment.png>

From macqueen1 at llnl.gov  Fri Apr 27 18:14:01 2018
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 27 Apr 2018 16:14:01 +0000
Subject: [R-sig-Geo] Error using spsample on SpatialLines in Linux OS
In-Reply-To: <00a001d3dd7f$04376280$0ca62780$@gmail.com>
References: <008e01d3dd7c$18130820$48391860$@gmail.com>
 <11130866-7cf5-b6c1-8d04-953d24d65659@uni-muenster.de>
 <00a001d3dd7f$04376280$0ca62780$@gmail.com>
Message-ID: <3C2BF1B5-0545-47F6-8A6C-65BCE7832A64@llnl.gov>

The code also works fine on my Mac, and an RHEL (linux) machine to which I have access (though both are still at R 3.4.2 and sp_1.2-5).

You could focus in on the problem a bit by trying the following (I expect you will see the same error)

> sp::LineLength(pts)
[1] 123.0096

Starting with spsample(), and drilling down, eventually LineLength() calls the C function sp_lengths.  LineLength() is pretty simple, and I don't see any evidence that it depends on other packages. I'm not the expert that Edzer is, but it pretty much looks like an installation problem with sp, sorry to say. I can't think of anything else...

Sorry I'm not more helpful,
-Don


> sp::LineLength(pts, sum=FALSE)
[1] 15.81139  7.81025 42.37924 57.00877

> SpatialLinesLengths(L)
[1] 123.0096

> LinesLength(L at lines[[1]])
[1] 123.0096


> sessionInfo()
R version 3.4.2 (2017-09-28)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: OS X El Capitan 10.11.6

Matrix products: default
BLAS: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRblas.0.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] sp_1.2-5

loaded via a namespace (and not attached):
 [1] compiler_3.4.2     colorspace_1.3-2   scales_0.5.0.9000  lazyeval_0.2.1    
 [5] plyr_1.8.4         rgdal_1.2-13       tools_3.4.2        gtable_0.2.0      
 [9] tibble_1.3.4       Rcpp_0.12.14       ggplot2_2.2.1.9000 grid_3.4.2        
[13] rlang_0.1.2        munsell_0.4.3      lattice_0.20-35   

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 4/26/18, 9:52 AM, "R-sig-Geo on behalf of Glenn Stauffer" <r-sig-geo-bounces at r-project.org on behalf of gestauffer at gmail.com> wrote:

    Do you mean the sp package? I should have mentioned that I already tried
    that.
    
    -----Original Message-----
    From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Edzer
    Pebesma
    Sent: Thursday, April 26, 2018 11:35 AM
    To: r-sig-geo at r-project.org
    Subject: Re: [R-sig-Geo] Error using spsample on SpatialLines in Linux OS
    
    I would try reinstalling the package.
    
    On 04/26/2018 06:31 PM, Glenn Stauffer wrote:
    > I ran across a problem when trying to use spsample to sample points 
    > along a line, while in a Linux OS (Mint 18.3). The following code 
    > (which works fine in Win 10):
    > 
    >  
    > 
    > pts <- matrix(c(c(6000,6015,6021,6035,6050),
    > c(6000,5995,6000,6040,6095)),5,2,byrow=FALSE)
    > L = 
    > SpatialLines(list(Lines(list(Line(coordinates(pts))),"X")),proj4string 
    > =
    > CRS("+init=epsg:3071"))
    > plot(L)
    > Lsamp <- spsample(L,10,type="regular",offset=0.5) # this is the line 
    > that generates the error
    > 
    >  
    > 
    > produces the following error:
    > 
    >  
    > 
    > Error in .C("sp_lengths", x, y, n, lengths, lonlat, PACKAGE = "sp") : 
    >   "sp_lengths" not available for .C() for package "sp"
    > 
    > Could this be related to some wrong versions of certain dependencies 
    > (e.g., GDAL)? I don't know much about that, but I did run into that 
    > issue with trying to install other packages (rgeos, sf). In any case, 
    > how can I prevent this error?
    > 
    >  
    > 
    > Thanks,
    > 
    > Glenn
    > 
    >  
    > 
    >  
    > 
    > 
    > 	[[alternative HTML version deleted]]
    > 
    > _______________________________________________
    > R-sig-Geo mailing list
    > R-sig-Geo at r-project.org
    > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
    > 
    
    --
    Edzer Pebesma
    Institute for Geoinformatics
    Heisenbergstrasse 2, 48151 Muenster, Germany
    Phone: +49 251 8333081
    
    _______________________________________________
    R-sig-Geo mailing list
    R-sig-Geo at r-project.org
    https://stat.ethz.ch/mailman/listinfo/r-sig-geo
    
    _______________________________________________
    R-sig-Geo mailing list
    R-sig-Geo at r-project.org
    https://stat.ethz.ch/mailman/listinfo/r-sig-geo
    


From gestauffer at gmail.com  Fri Apr 27 19:15:34 2018
From: gestauffer at gmail.com (Glenn Stauffer)
Date: Fri, 27 Apr 2018 12:15:34 -0500
Subject: [R-sig-Geo] Error using spsample on SpatialLines in Linux OS
In-Reply-To: <3C2BF1B5-0545-47F6-8A6C-65BCE7832A64@llnl.gov>
References: <008e01d3dd7c$18130820$48391860$@gmail.com>
 <11130866-7cf5-b6c1-8d04-953d24d65659@uni-muenster.de>
 <00a001d3dd7f$04376280$0ca62780$@gmail.com>
 <3C2BF1B5-0545-47F6-8A6C-65BCE7832A64@llnl.gov>
Message-ID: <004601d3de4b$5bd92fb0$138b8f10$@gmail.com>

Thanks. I'm out of the office until Monday, but I'll try your suggestions next week. I do suspect that maybe there is some little piece missing in the installation (of sp or something else) that just didn't quite go right in Mint (I'm new to Mint). 

Glenn

-----Original Message-----
From: MacQueen, Don [mailto:macqueen1 at llnl.gov] 
Sent: Friday, April 27, 2018 11:14 AM
To: Glenn Stauffer <gestauffer at gmail.com>; r-sig-geo at r-project.org
Cc: 'Edzer Pebesma' <edzer.pebesma at uni-muenster.de>
Subject: Re: [R-sig-Geo] Error using spsample on SpatialLines in Linux OS

The code also works fine on my Mac, and an RHEL (linux) machine to which I have access (though both are still at R 3.4.2 and sp_1.2-5).

You could focus in on the problem a bit by trying the following (I expect you will see the same error)

> sp::LineLength(pts)
[1] 123.0096

Starting with spsample(), and drilling down, eventually LineLength() calls the C function sp_lengths.  LineLength() is pretty simple, and I don't see any evidence that it depends on other packages. I'm not the expert that Edzer is, but it pretty much looks like an installation problem with sp, sorry to say. I can't think of anything else...

Sorry I'm not more helpful,
-Don


> sp::LineLength(pts, sum=FALSE)
[1] 15.81139  7.81025 42.37924 57.00877

> SpatialLinesLengths(L)
[1] 123.0096

> LinesLength(L at lines[[1]])
[1] 123.0096


> sessionInfo()
R version 3.4.2 (2017-09-28)
Platform: x86_64-apple-darwin15.6.0 (64-bit) Running under: OS X El Capitan 10.11.6

Matrix products: default
BLAS: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRblas.0.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] sp_1.2-5

loaded via a namespace (and not attached):
 [1] compiler_3.4.2     colorspace_1.3-2   scales_0.5.0.9000  lazyeval_0.2.1    
 [5] plyr_1.8.4         rgdal_1.2-13       tools_3.4.2        gtable_0.2.0      
 [9] tibble_1.3.4       Rcpp_0.12.14       ggplot2_2.2.1.9000 grid_3.4.2        
[13] rlang_0.1.2        munsell_0.4.3      lattice_0.20-35   

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 4/26/18, 9:52 AM, "R-sig-Geo on behalf of Glenn Stauffer" <r-sig-geo-bounces at r-project.org on behalf of gestauffer at gmail.com> wrote:

    Do you mean the sp package? I should have mentioned that I already tried
    that.
    
    -----Original Message-----
    From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Edzer
    Pebesma
    Sent: Thursday, April 26, 2018 11:35 AM
    To: r-sig-geo at r-project.org
    Subject: Re: [R-sig-Geo] Error using spsample on SpatialLines in Linux OS
    
    I would try reinstalling the package.
    
    On 04/26/2018 06:31 PM, Glenn Stauffer wrote:
    > I ran across a problem when trying to use spsample to sample points 
    > along a line, while in a Linux OS (Mint 18.3). The following code 
    > (which works fine in Win 10):
    > 
    >  
    > 
    > pts <- matrix(c(c(6000,6015,6021,6035,6050),
    > c(6000,5995,6000,6040,6095)),5,2,byrow=FALSE)
    > L = 
    > SpatialLines(list(Lines(list(Line(coordinates(pts))),"X")),proj4string 
    > =
    > CRS("+init=epsg:3071"))
    > plot(L)
    > Lsamp <- spsample(L,10,type="regular",offset=0.5) # this is the line 
    > that generates the error
    > 
    >  
    > 
    > produces the following error:
    > 
    >  
    > 
    > Error in .C("sp_lengths", x, y, n, lengths, lonlat, PACKAGE = "sp") : 
    >   "sp_lengths" not available for .C() for package "sp"
    > 
    > Could this be related to some wrong versions of certain dependencies 
    > (e.g., GDAL)? I don't know much about that, but I did run into that 
    > issue with trying to install other packages (rgeos, sf). In any case, 
    > how can I prevent this error?
    > 
    >  
    > 
    > Thanks,
    > 
    > Glenn
    > 
    >  
    > 
    >  
    > 
    > 
    > 	[[alternative HTML version deleted]]
    > 
    > _______________________________________________
    > R-sig-Geo mailing list
    > R-sig-Geo at r-project.org
    > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
    > 
    
    --
    Edzer Pebesma
    Institute for Geoinformatics
    Heisenbergstrasse 2, 48151 Muenster, Germany
    Phone: +49 251 8333081
    
    _______________________________________________
    R-sig-Geo mailing list
    R-sig-Geo at r-project.org
    https://stat.ethz.ch/mailman/listinfo/r-sig-geo
    
    _______________________________________________
    R-sig-Geo mailing list
    R-sig-Geo at r-project.org
    https://stat.ethz.ch/mailman/listinfo/r-sig-geo
    


From saiku1 at umbc.edu  Sun Apr 29 05:16:05 2018
From: saiku1 at umbc.edu (Sai Kumar Popuri)
Date: Sat, 28 Apr 2018 20:16:05 -0700
Subject: [R-sig-Geo] Location level analysis of spatio-temporal data
Message-ID: <CABs4MWKk6uXCiEO2+bT-NkU6Giy1AjANRyACAdFuDVxxui9h-A@mail.gmail.com>

Hi,

I am new to spatio-temporal analysis and trying to understand some basics.
Suppose I have a large spatio-temporal data. I can either fit an advanced
model with a spatio-temporal covariance structure or I could fit a time
series model at each location separately. When are these two approaches
similar? When is the second approach justified?

Thank you,
Sai

	[[alternative HTML version deleted]]


From brunsesti at gmail.com  Sun Apr 29 11:24:17 2018
From: brunsesti at gmail.com (Bruno Sesti)
Date: Sun, 29 Apr 2018 11:24:17 +0200
Subject: [R-sig-Geo] Spatio-temporal variography: variogram parameters
 setting
Message-ID: <CAFnjcD058+aZ_XZkoQfynDizb+1XgkGzydx6y2MiZC34Kw7LuA@mail.gmail.com>

Hi,
I am trying to do spatio-temporal kriging in R.
I would like to ask you if there are R tools to fit the parameters of
function variogramST in optimal way. In particular I refer to parameters
tlag, tunit, twindow, width, boundaries and par.scale ?
How can I get the pairs of points identified by the field np (in the
structure returned by variogramST) in each spatio-temporal lags?

Kind regards

	[[alternative HTML version deleted]]


From englishchristophera at gmail.com  Mon Apr 30 04:50:53 2018
From: englishchristophera at gmail.com (chris english)
Date: Sun, 29 Apr 2018 22:50:53 -0400
Subject: [R-sig-Geo] Location level analysis of spatio-temporal data
In-Reply-To: <CABs4MWKk6uXCiEO2+bT-NkU6Giy1AjANRyACAdFuDVxxui9h-A@mail.gmail.com>
References: <CABs4MWKk6uXCiEO2+bT-NkU6Giy1AjANRyACAdFuDVxxui9h-A@mail.gmail.com>
Message-ID: <CAASFQpTFuyT8zC6FqgW6hynLM1aAgEMaRPnPcjSYTCfmKZmsuQ@mail.gmail.com>

Sai,

There is something like take it from the end to the beginning and back, or
beginning to end and back to
the beginning and end and back, and ask yourself what does my data
recommend. The end is how I suppose you
generally anticipate analyzing/modeling the data, and the beginning being
your understanding of how the data
was collected and its vagaries.

If you sampled your data, say .60 in a train set and reduced each variable
to its quantile median
     quantile(your_data[[x]][, 'your_one_of_many_variables'], type =8)[[3]]
# without na.rm = TRUE anticipating running this through caret 'gbm'
and then examine influence of time as against space among your variables.

Space can be characterized in a lot of dimensions, and then you have time
which seems often to be like a sampling rate upon those
potentially many spatial characteristics, But give it a try anyway and find
if time isn't up there in position one or two in variable importance with
spatial variables after you run your data through gbm.

For further reading I would suggest the work of Emmanual Parzen and also
his work in collaboration with Subhadeep (Deep) Mukhopadhyay
on why quantile median might be your special friend.

As ever, I probably shouldn't comment as I know little and there are much
better informed scientists here. The interesting claim to be
wrestled from the Parzen/Mukhopadhyay material is that the data (that you
have) informs the sufficient statistics to be found and that specific
domain knowledge is not necessary to such. This, is the claim, is the power
of the quantile median analysis.

Does this relieve you of answering your question of whether to apply
spatio-temporal upon the whole set, or time series upon a sampling point;
hard to say but Parzen/Mukhopadhyay say, give me your data and I'll give
you your sufficient statistics. It will, I suspect, at the very least
confirm
or disprove the proposition that your data is spatio-temporal (since you
don't say what it is) as a received notion, which is a good starting point
in any case.

My thoughts,
Chris


On Sat, Apr 28, 2018 at 11:16 PM, Sai Kumar Popuri <saiku1 at umbc.edu> wrote:

> Hi,
>
> I am new to spatio-temporal analysis and trying to understand some basics.
> Suppose I have a large spatio-temporal data. I can either fit an advanced
> model with a spatio-temporal covariance structure or I could fit a time
> series model at each location separately. When are these two approaches
> similar? When is the second approach justified?
>
> Thank you,
> Sai
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From englishchristophera at gmail.com  Mon Apr 30 05:11:09 2018
From: englishchristophera at gmail.com (chris english)
Date: Sun, 29 Apr 2018 23:11:09 -0400
Subject: [R-sig-Geo] Location level analysis of spatio-temporal data
In-Reply-To: <b62fa56635688c863366983355dd78e1@mx.google.com>
References: <CAASFQpTFuyT8zC6FqgW6hynLM1aAgEMaRPnPcjSYTCfmKZmsuQ@mail.gmail.com>
 <b62fa56635688c863366983355dd78e1@mx.google.com>
Message-ID: <CAASFQpTE4HKFwDGxe7EPccSQbQQmJ37_eRWAz_m8uNcnLocOSQ@mail.gmail.com>

Geez Marilyn, I would have thought, given your proclivity for geospatial
statistics you'd pretty well know where I was,
within a mile and a second or two. I guess you can check with Sai, as you
popped up the moment I replied to him.
Sigh. What will I tell my wife?
Chris

On Sun, Apr 29, 2018 at 10:54 PM, Marilyn Dean <lillynrose112 at blackkick.pw>
wrote:

> chris,  I'm not for anything too crazy I am Marilyn Dean and age is not
> too big of a deal {as long as you are handsome and respectful as long as
> you are a good guy . I just want to have a time if you know what I mean ;)
>
>
>  also, whats your location? whats the plan for first meet?|
>
> On Sun, 29 Apr 2018 at 08:51 PM, chris english <
> englishchristophera at gmail.com> wrote:
>
>>
>>
>>
>>

	[[alternative HTML version deleted]]


From b.graeler at 52north.org  Mon Apr 30 09:18:37 2018
From: b.graeler at 52north.org (=?UTF-8?Q?Dr._Benedikt_Gr=c3=a4ler?=)
Date: Mon, 30 Apr 2018 09:18:37 +0200
Subject: [R-sig-Geo] Spatio-temporal variography: variogram parameters
 setting
In-Reply-To: <CAFnjcD058+aZ_XZkoQfynDizb+1XgkGzydx6y2MiZC34Kw7LuA@mail.gmail.com>
References: <CAFnjcD058+aZ_XZkoQfynDizb+1XgkGzydx6y2MiZC34Kw7LuA@mail.gmail.com>
Message-ID: <5ddd8e8a-20c4-bbbd-0d33-38e035a66862@52north.org>



On 29.04.2018 11:24, Bruno Sesti wrote:
> Hi,
> I am trying to do spatio-temporal kriging in R.
> I would like to ask you if there are R tools to fit the parameters of
> function variogramST in optimal way. In particular I refer to parameters
"Optimal" depends on the random field that you are about to model and 
the way how you prepared your data.

> tlag, 
The temporal lags. If your data is recorded/stored in regular time 
intervals and prepared as STFDF/STSDF, then the tlag vector indicates 
temporal ids. E.g.: assume regular daily data, then 0:5 denotes pairs at 
the same day, 1, 2, 3, 4, and 5 days difference.
If your data is irregular and an explicit temporal binning needs to be 
carried out, tlag refers to actual time differences and c(0,6,12,24) 
would result in temporal bins of simultaneous observations, >0 to 6, 6 
to 12, 12 to 24 secs/minutes/hours/days/weeks where the unit depends on 
the argument of tunit. You can gradually increase the range and see 
where the vgm surface begins to flatten. For regular daily data for 
instance, 0:5 or 0:7 is often already enough.

> tunit,
the temporal unit of the tlags argument if it is not a regular structure.

> twindow,
an integer that indicates the number of temporal jumps to be used when 
creating the temporal distance matrix - no need to provide it explicitly

> width,
the spatial width of the bins, default: cutoff/15

> boundaries
a vector that allows to explicitly provide spatial boundaries - instead 
of 15 equidistant bins (take a look at your number of pairs and merge 
for instance too less populated bins)

  and > par.scale ?Do you mean parscale in calling fit.StVariogram? This 
is to ease the numerical optimization of optim (e.g. changing the range 
by 1 m most likely effects the vgm surface less than increasing the sill 
by 1; parscale shall help to make these scales more alike). See the help 
of optim for further details. Often, optim succeeds without parscale 
been explicitly set. The order corresponds to the order of parameters in 
the spatio-temporal model as indicated e.g. by the function extractParNames.

> How can I get the pairs of points identified by the field np (in the
> structure returned by variogramST) in each spatio-temporal lags?
np just indicates the number of pairs identified. The pairs themselves 
are not persistently stored at any time. You would have to re-do the 
selection manually.

HTH

> 
> Kind regards
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Dr. Benedikt Gr?ler
52?North Initiative for Geospatial Open Source Software GmbH
Martin-Luther-King-Weg 24
48155 Muenster, Germany

E-Mail: b.graeler at 52north.org
Fon: +49-(0)-251/396371-39
Fax: +49-(0)-251/396371-11

http://52north.org/
Twitter: @FiveTwoN

General Managers: Dr. Albert Remke, Dr. Andreas Wytzisk
Local Court Muenster HRB 10849


From Roger.Bivand at nhh.no  Mon Apr 30 09:50:46 2018
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 30 Apr 2018 09:50:46 +0200
Subject: [R-sig-Geo] Location level analysis of spatio-temporal data
In-Reply-To: <CAASFQpTFuyT8zC6FqgW6hynLM1aAgEMaRPnPcjSYTCfmKZmsuQ@mail.gmail.com>
References: <CABs4MWKk6uXCiEO2+bT-NkU6Giy1AjANRyACAdFuDVxxui9h-A@mail.gmail.com>
 <CAASFQpTFuyT8zC6FqgW6hynLM1aAgEMaRPnPcjSYTCfmKZmsuQ@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.1804300945060.17769@reclus.nhh.no>

Please never respond to spamming on-list. All the R lists are under attack 
from at least one possibly breached cloud email provider, where posters or 
responders may receive spam on posting. Your local spam filter may catch 
these, but because the origin is authenticated (not by us), your spam 
filter may not work. See:

https://stat.ethz.ch/pipermail/r-help/2018-April/452613.html

for more details.

Roger Bivand
List admin.

On Mon, 30 Apr 2018, chris english wrote:

> Sai,
>
> There is something like take it from the end to the beginning and back, or
> beginning to end and back to
> the beginning and end and back, and ask yourself what does my data
> recommend. The end is how I suppose you
> generally anticipate analyzing/modeling the data, and the beginning being
> your understanding of how the data
> was collected and its vagaries.
>
> If you sampled your data, say .60 in a train set and reduced each variable
> to its quantile median
>     quantile(your_data[[x]][, 'your_one_of_many_variables'], type =8)[[3]]
> # without na.rm = TRUE anticipating running this through caret 'gbm'
> and then examine influence of time as against space among your variables.
>
> Space can be characterized in a lot of dimensions, and then you have time
> which seems often to be like a sampling rate upon those
> potentially many spatial characteristics, But give it a try anyway and find
> if time isn't up there in position one or two in variable importance with
> spatial variables after you run your data through gbm.
>
> For further reading I would suggest the work of Emmanual Parzen and also
> his work in collaboration with Subhadeep (Deep) Mukhopadhyay
> on why quantile median might be your special friend.
>
> As ever, I probably shouldn't comment as I know little and there are much
> better informed scientists here. The interesting claim to be
> wrestled from the Parzen/Mukhopadhyay material is that the data (that you
> have) informs the sufficient statistics to be found and that specific
> domain knowledge is not necessary to such. This, is the claim, is the power
> of the quantile median analysis.
>
> Does this relieve you of answering your question of whether to apply
> spatio-temporal upon the whole set, or time series upon a sampling point;
> hard to say but Parzen/Mukhopadhyay say, give me your data and I'll give
> you your sufficient statistics. It will, I suspect, at the very least
> confirm
> or disprove the proposition that your data is spatio-temporal (since you
> don't say what it is) as a received notion, which is a good starting point
> in any case.
>
> My thoughts,
> Chris
>
>
> On Sat, Apr 28, 2018 at 11:16 PM, Sai Kumar Popuri <saiku1 at umbc.edu> wrote:
>
>> Hi,
>>
>> I am new to spatio-temporal analysis and trying to understand some basics.
>> Suppose I have a large spatio-temporal data. I can either fit an advanced
>> model with a spatio-temporal covariance structure or I could fit a time
>> series model at each location separately. When are these two approaches
>> similar? When is the second approach justified?
>>
>> Thank you,
>> Sai
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


