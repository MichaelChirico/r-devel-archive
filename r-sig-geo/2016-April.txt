From giuseppe.amatulli at gmail.com  Fri Apr  1 19:00:16 2016
From: giuseppe.amatulli at gmail.com (Giuseppe Amatulli)
Date: Fri, 1 Apr 2016 13:00:16 -0400
Subject: [R-sig-Geo] Summers schools in Geo-Data Processing
Message-ID: <CAKoiDH+XDg8sU_UkZacMDaHkxTM_Vn3p+y9NCtk7bUVt1oVe_A@mail.gmail.com>

Apologies for cross-posting:

We are pleased to announce: *R**egistration open now for two Summer Schools*
organized by www.spatial-ecology.net held at the University of Basilicata,
Matera, Italy:

*- Spatio-Temporal Data Analyses Using Free and Open Source Software
**(6th-10th
June 2016)*

*An immersion 5 day experience opening new horizons on the use of the vast
potentials of the Linux environment and the command line approach to
process data using Bash, AWK, Python, GRASS, QGIS, GDAL/OGR, R, PKtools,
Openforis. **We will guide newbies who have never used a command line
terminal to a stage which will allow them to understand and use very
advanced open source data processing routines. Our focus is to enhance the
approach of self-learning allowing participants to keep on progressing and
updating their skills in a continuously evolving technological environment.*

*----------------------------------------------------*

*- Hands-on Open Source Drone Mapping and High Performance Computing for
Big Geo-Data **(13th-17th June 2016)*

*Another 5 day immersion experience on advanced data processing using high
performance computers (HPC) and emerging technologies such as drone
mapping, rasdaman (Fastest Array Database on Earth) and cloud computing. We
provide a walk-through journey from the introduction of Linux operating
system and different open source software (Python, GRASS, GDAL/OGR, R,
PKtools, Openforis) to capturing data out in the field using an Unmanned
Aerial Vehicle, to complex image processing and data analyses. We focus on
how maximising computation performance using multicore on single computer,
switching to distributed clusters of computers (using grid engine
scheduler) and ultimately data analytics with cutting edge rasdaman
software (Big Data Analytics Server).*


More information and registrations:

www.spatial-ecology.net/upcoming-events

https://www.facebook.com/spatialecology
<http://www.spatial-ecology.net/upcoming-events>> see events
info at spatial-ecology.net

-- 
Giuseppe Amatulli, Ph.D.

Department of Ecology and Evolutionary Biology, Yale University.
Jetz Lab, OML Room 405

P.O. Box 208106
165 PROSPECT ST
New Haven, CT 06520-8106
Teaching: spatial-ecology.net
Work:  http://sbsc.yale.edu/giuseppe-amatulli
<http://www.spatial-ecology.net>

	[[alternative HTML version deleted]]


From karlashikev at gmail.com  Sun Apr  3 15:53:00 2016
From: karlashikev at gmail.com (Karla Shikev)
Date: Sun, 3 Apr 2016 10:53:00 -0300
Subject: [R-sig-Geo] generating object with multiple polygons
Message-ID: <CAPU4_4piYEai_La9pJH84=90hhO=pV_-bQTPXmRczeC+fJeBHA@mail.gmail.com>

Dear all,

This might be a newbie question, so I'd appreciate your patience with this.

I'm obtaining climatic data from worldclim and generating polygons based on
different climatic limits:

library(raster)
xx<-getData('worldclim', var='bio', res=10)$bio1
slice1 <- rasterToPolygons(xx, fun = function(x) {x > 200 & x < 260})
slice2 <- rasterToPolygons(xx, fun = function(x) {x > 250 & x < 300})

Now, I'd like to combine "slice1" and "slice2" into the same
"SpatialPolygonsDataFrame" object, but I do not want to merge them.

Any help will be greatly appreciated.

Karla

	[[alternative HTML version deleted]]


From tephilippi at gmail.com  Sun Apr  3 22:15:12 2016
From: tephilippi at gmail.com (Tom Philippi)
Date: Sun, 3 Apr 2016 13:15:12 -0700
Subject: [R-sig-Geo] generating object with multiple polygons
In-Reply-To: <CAPU4_4piYEai_La9pJH84=90hhO=pV_-bQTPXmRczeC+fJeBHA@mail.gmail.com>
References: <CAPU4_4piYEai_La9pJH84=90hhO=pV_-bQTPXmRczeC+fJeBHA@mail.gmail.com>
Message-ID: <CALyPt8yuiXQN=_DOjwQmJYYwPT5rdo+WjCDcEHnyNgGCy-QOvg@mail.gmail.com>

Karla--
If you want a SpatialPolygonsDataFrame with both slices of polygons, you
can use spatial rbind.  The issue that may trip you up is that your slice1
and slice2 objects might not have unique polygon IDs.  Perhaps the simplest
solution is to use the spChFIDs in sp, with some prefix distinguishing
slice1 from slice2.  I assume you're generating some attributes as
variables in the data frame to distinguish the different polygons; you can
use those values as the prefix.  You can google this, or start with:
http://www.inside-r.org/packages/cran/sp/docs/as.data.frame.SpatialPolygonsDataFrame
http://gis.stackexchange.com/questions/32732/proper-way-to-rbind-spatialpolygonsdataframes-with-identical-polygon-ids

Tom 2

On Sun, Apr 3, 2016 at 6:53 AM, Karla Shikev <karlashikev at gmail.com> wrote:

> Dear all,
>
> This might be a newbie question, so I'd appreciate your patience with this.
>
> I'm obtaining climatic data from worldclim and generating polygons based on
> different climatic limits:
>
> library(raster)
> xx<-getData('worldclim', var='bio', res=10)$bio1
> slice1 <- rasterToPolygons(xx, fun = function(x) {x > 200 & x < 260})
> slice2 <- rasterToPolygons(xx, fun = function(x) {x > 250 & x < 300})
>
> Now, I'd like to combine "slice1" and "slice2" into the same
> "SpatialPolygonsDataFrame" object, but I do not want to merge them.
>
> Any help will be greatly appreciated.
>
> Karla
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From uzzal at gist.ac.kr  Mon Apr  4 14:57:39 2016
From: uzzal at gist.ac.kr (uzzal at gist.ac.kr)
Date: Mon, 4 Apr 2016 21:57:39 +0900
Subject: [R-sig-Geo] Is there option for 'repeated K-fold cross validation'
 in gstat package?
In-Reply-To: <CALyPt8yuiXQN=_DOjwQmJYYwPT5rdo+WjCDcEHnyNgGCy-QOvg@mail.gmail.com>
References: <CAPU4_4piYEai_La9pJH84=90hhO=pV_-bQTPXmRczeC+fJeBHA@mail.gmail.com>
	<CALyPt8yuiXQN=_DOjwQmJYYwPT5rdo+WjCDcEHnyNgGCy-QOvg@mail.gmail.com>
Message-ID: <Mime4j.294a.2b51d2ee8724a608.153e1599cc4@gist.ac.kr>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160404/0dcc833f/attachment.html>

From r.hijmans at gmail.com  Mon Apr  4 18:04:10 2016
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Mon, 4 Apr 2016 09:04:10 -0700
Subject: [R-sig-Geo] generating object with multiple polygons
In-Reply-To: <CAPU4_4piYEai_La9pJH84=90hhO=pV_-bQTPXmRczeC+fJeBHA@mail.gmail.com>
References: <CAPU4_4piYEai_La9pJH84=90hhO=pV_-bQTPXmRczeC+fJeBHA@mail.gmail.com>
Message-ID: <CANtt_hwb=-OSrBJcMtqY0p_5SWrb-bv9u1gHOhdJETX5jVGNQA@mail.gmail.com>

Karla,
You can do

library(raster)
slices <- bind(slice1, slice2)

Robert

On Sun, Apr 3, 2016 at 6:53 AM, Karla Shikev <karlashikev at gmail.com> wrote:
> Dear all,
>
> This might be a newbie question, so I'd appreciate your patience with this.
>
> I'm obtaining climatic data from worldclim and generating polygons based on
> different climatic limits:
>
> library(raster)
> xx<-getData('worldclim', var='bio', res=10)$bio1
> slice1 <- rasterToPolygons(xx, fun = function(x) {x > 200 & x < 260})
> slice2 <- rasterToPolygons(xx, fun = function(x) {x > 250 & x < 300})
>
> Now, I'd like to combine "slice1" and "slice2" into the same
> "SpatialPolygonsDataFrame" object, but I do not want to merge them.
>
> Any help will be greatly appreciated.
>
> Karla
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From karlashikev at gmail.com  Mon Apr  4 21:21:04 2016
From: karlashikev at gmail.com (Karla Shikev)
Date: Mon, 4 Apr 2016 16:21:04 -0300
Subject: [R-sig-Geo] generating object with multiple polygons
In-Reply-To: <CANtt_hwb=-OSrBJcMtqY0p_5SWrb-bv9u1gHOhdJETX5jVGNQA@mail.gmail.com>
References: <CAPU4_4piYEai_La9pJH84=90hhO=pV_-bQTPXmRczeC+fJeBHA@mail.gmail.com>
	<CANtt_hwb=-OSrBJcMtqY0p_5SWrb-bv9u1gHOhdJETX5jVGNQA@mail.gmail.com>
Message-ID: <CAPU4_4rW2KuGT33c3DOa30aBqhbzL7=ga=m0DGszf8H3DRirFA@mail.gmail.com>

Thanks, Robert and Tom. The bind command worked like a charm!

On Mon, Apr 4, 2016 at 1:04 PM, Robert J. Hijmans <r.hijmans at gmail.com>
wrote:

> Karla,
> You can do
>
> library(raster)
> slices <- bind(slice1, slice2)
>
> Robert
>
> On Sun, Apr 3, 2016 at 6:53 AM, Karla Shikev <karlashikev at gmail.com>
> wrote:
> > Dear all,
> >
> > This might be a newbie question, so I'd appreciate your patience with
> this.
> >
> > I'm obtaining climatic data from worldclim and generating polygons based
> on
> > different climatic limits:
> >
> > library(raster)
> > xx<-getData('worldclim', var='bio', res=10)$bio1
> > slice1 <- rasterToPolygons(xx, fun = function(x) {x > 200 & x < 260})
> > slice2 <- rasterToPolygons(xx, fun = function(x) {x > 250 & x < 300})
> >
> > Now, I'd like to combine "slice1" and "slice2" into the same
> > "SpatialPolygonsDataFrame" object, but I do not want to merge them.
> >
> > Any help will be greatly appreciated.
> >
> > Karla
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From karlashikev at gmail.com  Mon Apr  4 21:32:26 2016
From: karlashikev at gmail.com (Karla Shikev)
Date: Mon, 4 Apr 2016 16:32:26 -0300
Subject: [R-sig-Geo] problem with rasterToPolygons x worldclim
Message-ID: <CAPU4_4pURuP2Zq_o_oW3E7bPOi9Chxmc=HwsdrWaDOYRc30W6g@mail.gmail.com>

Dear all,

Here's an issue that is related to the previous one. In the commands below
I'm trying to make a polygon for all the regions within a range of mean
annual temps. However, rasterToPolygons will draw a square around each
value in the original raster, rather than providing me the actual polygon,
given that resolution. Any hints? Again, any help will be greatly
appreciated.

Karla

_____

library(raster)

r<-getData('worldclim', var='bio', res=10)$bio1

e <- extent(-140,-100, 50, 60)

xx<-crop(r,e)

slice1<-rasterToPolygons(xx, fun = function(x) {x > 40 & x < 60})

plot(slice1)

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Mon Apr  4 22:38:01 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Mon, 04 Apr 2016 20:38:01 +0000
Subject: [R-sig-Geo] problem with rasterToPolygons x worldclim
In-Reply-To: <CAPU4_4pURuP2Zq_o_oW3E7bPOi9Chxmc=HwsdrWaDOYRc30W6g@mail.gmail.com>
References: <CAPU4_4pURuP2Zq_o_oW3E7bPOi9Chxmc=HwsdrWaDOYRc30W6g@mail.gmail.com>
Message-ID: <CAAcGz9-xMF1fxF+7LDCtkbd3cbmzg5TSnVmNWQ97TCYkM_Nrdw@mail.gmail.com>

Read the help for rasterToPolygons, alternatively try chaining
rasterToContour and rgeos::gPolygonize.

The latter may need coaxing if your edges meet the raster extents.

Cheers, Mike

On Tue, 5 Apr 2016, 05:32 Karla Shikev <karlashikev at gmail.com> wrote:

> Dear all,
>
> Here's an issue that is related to the previous one. In the commands below
> I'm trying to make a polygon for all the regions within a range of mean
> annual temps. However, rasterToPolygons will draw a square around each
> value in the original raster, rather than providing me the actual polygon,
> given that resolution. Any hints? Again, any help will be greatly
> appreciated.
>
> Karla
>
> _____
>
> library(raster)
>
> r<-getData('worldclim', var='bio', res=10)$bio1
>
> e <- extent(-140,-100, 50, 60)
>
> xx<-crop(r,e)
>
> slice1<-rasterToPolygons(xx, fun = function(x) {x > 40 & x < 60})
>
> plot(slice1)
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From uzzal at gist.ac.kr  Tue Apr  5 07:02:28 2016
From: uzzal at gist.ac.kr (uzzal at gist.ac.kr)
Date: Tue, 5 Apr 2016 14:02:28 +0900
Subject: [R-sig-Geo] How to perform 'repeated K-fold cross validation' using
 gstat package?
In-Reply-To: <Mime4j.294a.2b51d2ee8724a608.153e1599cc4@gist.ac.kr>
References: <CAPU4_4piYEai_La9pJH84=90hhO=pV_-bQTPXmRczeC+fJeBHA@mail.gmail.com>
	<CALyPt8yuiXQN=_DOjwQmJYYwPT5rdo+WjCDcEHnyNgGCy-QOvg@mail.gmail.com>
	<Mime4j.294a.2b51d2ee8724a608.153e1599cc4@gist.ac.kr>
Message-ID: <Mime4j.3653.847c65750c29ce16.153e4ccec63@gist.ac.kr>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160405/60ed28f8/attachment.html>

From edzer.pebesma at uni-muenster.de  Tue Apr  5 08:47:10 2016
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 5 Apr 2016 08:47:10 +0200
Subject: [R-sig-Geo] How to perform 'repeated K-fold cross validation'
 using gstat package?
In-Reply-To: <Mime4j.3653.847c65750c29ce16.153e4ccec63@gist.ac.kr>
References: <CAPU4_4piYEai_La9pJH84=90hhO=pV_-bQTPXmRczeC+fJeBHA@mail.gmail.com>
	<CALyPt8yuiXQN=_DOjwQmJYYwPT5rdo+WjCDcEHnyNgGCy-QOvg@mail.gmail.com>
	<Mime4j.294a.2b51d2ee8724a608.153e1599cc4@gist.ac.kr>
	<Mime4j.3653.847c65750c29ce16.153e4ccec63@gist.ac.kr>
Message-ID: <57035F6E.1020408@uni-muenster.de>

Please don't repeat questions to this list when there is no answer
within 24 hours; there are over 3000 subscribers.

The link you point to demonstrates how to use a for loop to repeat a
certain procedure, such as cross validation. Study it well, and ask
yourself what information you want to retain from each loop iteration,
and what you want to do with it afterwards.

On 05/04/16 07:02, uzzal at gist.ac.kr wrote:
> By using gstat package, I can do 5-fold cross validation. How can
> I write the code/create the loop for "Repeated 5-fold cross validation"
> for 10 repeat. Code for 5-fold cross validation is given below. I knew
> about 'repeated k-fold cross validation' from here
> <http://stats.stackexchange.com/questions/103459/how-do-i-know-which-method-of-cross-validation-is-best>.
> 
> 
> library(sp)
> data(meuse)  
> coordinates(meuse) <- ~x+y
> m <- vgm(.59, "Sph", 874, .04)
> 
> 
> # five-fold cross validation:
> x <- krige.cv(log(zinc)~1, meuse, m, nmax = 40, nfold=5)
> str(x)
> (R <-cor(x$observed, x$var1.pred))
> (RMSE<- sqrt(mean((x$var1.pred-x$observed)^2)))
> 
> 
> Orpheus
> 
> --------- ?? ?? ---------
> 
>     *????* : <uzzal at gist.ac.kr>
>     *????* : r-sig-geo <r-sig-geo at r-project.org>
>     *????* : 2016? Apr 4?(Mon) 22:02:51
>     *??* : [R-sig-Geo] Is there option for 'repeated K-fold cross
>     validation' in gstat package?
> 
>     I am working with spatial dataset. I have done ordinary kriging on
>     this dataset using gstat package in R. I want to do 'repeated
>     K-fold cross validation' using krige.cv function of gstat package.
>     as far as I know using krige.cv function K-fold/n-fold cross
>     validation is possible. Is there any option of doing 'repeated
>     K-fold cross validation'  in gstat? or K-fold cross validation is
>     enough to check the relation between observed values and kriging
>     predicted values?
> 
> 
>     I came to know about 'repeated K-fold cross validation'  from here.
>     <http://stats.stackexchange.com/questions/103459/how-do-i-know-which-method-of-cross-validation-is-best> Any
>     kind help will be appreciable.
> 
> 
>     Orpheus
> 
>     --------- ?? ?? ---------
> 
>         *????* : Tom Philippi <tephilippi at gmail.com>
>         *????* : Karla Shikev <karlashikev at gmail.com>
>         *??* : r-sig-geo <r-sig-geo at r-project.org>
>         *????* : 2016? Apr 4?(Mon) 05:17:16
>         *??* : Re: [R-sig-Geo] generating object with multiple polygons
> 
>         Karla--
>         If you want a SpatialPolygonsDataFrame with both slices of polygons, you
>         can use spatial rbind.  The issue that may trip you up is that your slice1
>         and slice2 objects might not have unique polygon IDs.  Perhaps the simplest
>         solution is to use the spChFIDs in sp, with some prefix distinguishing
>         slice1 from slice2.  I assume you're generating some attributes as
>         variables in the data frame to distinguish the different polygons; you can
>         use those values as the prefix.  You can google this, or start with:
>         http://www.inside-r.org/packages/cran/sp/docs/as.data.frame.SpatialPolygonsDataFrame
>         http://gis.stackexchange.com/questions/32732/proper-way-to-rbind-spatialpolygonsdataframes-with-identical-polygon-ids
> 
>         Tom 2
> 
>         On Sun, Apr 3, 2016 at 6:53 AM, Karla Shikev wrote: > Dear all, > > This might be a newbie question, so I'd
>         appreciate your patience with this. > > I'm obtaining climatic
>         data from worldclim and generating polygons based on > different
>         climatic limits: > > library(raster) > xx<-getData('worldclim',
>         var='bio', res=10)$bio1 > slice1 <- rasterToPolygons(xx, fun =
>         function(x) {x > 200 & x < 260}) > slice2 <-
>         rasterToPolygons(xx, fun = function(x) {x > 250 & x < 300}) > >
>         Now, I'd like to combine "slice1" and "slice2" into the same >
>         "SpatialPolygonsDataFrame" object, but I do not want to merge
>         them. > > Any help will be greatly appreciated. > > Karla > >
>         [[alternative HTML version deleted]] > >
>         _______________________________________________ > R-sig-Geo
>         mailing list > R-sig-Geo at r-project.org >
>         https://stat.ethz.ch/mailman/listinfo/r-sig-geo > [[alternative
>         HTML version deleted]]
>         _______________________________________________ R-sig-Geo
>         mailing list R-sig-Geo at r-project.org
>         https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics  (ifgi),  University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160405/ead05212/attachment.bin>

From geponce at gmail.com  Tue Apr  5 10:14:29 2016
From: geponce at gmail.com (Guillermo E. Ponce-Campos)
Date: Tue, 5 Apr 2016 01:14:29 -0700
Subject: [R-sig-Geo] Raster-extract function with cluster...
Message-ID: <CAGKzJ7oJ9sHixpFb=isW8JLmZutLr_u8TJyzEap1Xig54ZAWWQ@mail.gmail.com>

Hi,

Does anyone has experienced issues using "extract" function from raster
Package using a cluster?

I want to make a simple extraction of pixels from rasters using a
multi-polygon shapefile.

I'm just doing something like:

beginCluster(20)

# Create list with raster filenames
my700.rasters <- list.files("\\.tif$")
# Load shapefile
multiPoly <- shapefile('../muti_polygons.shp')

rstack <- stack(my700.rasters)
rextract <- extract(rstack, multiPoly, fun=mean, na.rm=TRUE, df=TRUE)

Is it possible that the final arrange of data extracted for each polygon
doesn't match the sequence of each polygon within "multiPoly" due to the
parallelization, mixing the sequence of results?

I expect something like this as part of the data.frame (df=TRUE):

ID, Raster1, Raster2, Raster3,...
1, 0.344, 0.444, 0.455,...
2, 1.234, 2.334, 5.444,...
3, 4.555, 6.777,4.666,...
where ID is a sequence of numbers that corresponds to the sequence within
"multiPoly"

multiPoly at data
ID, OBJECTID, Name, Area
1, 2323, Lake1, 234.33
2, 3444, Pond, 20.33
3, 456, Pond1, 33.33

However, the ID's do not match...  If I do it for a single polygon I can
identify the values for that specific polygon.  However, when I run it for
several polygons, the polygon identified doesn't m atch with the ID in the
resulting data frame.

Does anyone has experienced something similar?

My guess is that cluster/parallel is mixing the order of the results... I'm
testing without cluster, just to confirm this...

Best,
Guillermo

	[[alternative HTML version deleted]]


From madiazl at gmail.com  Tue Apr  5 11:29:14 2016
From: madiazl at gmail.com (Andres Diaz)
Date: Tue, 5 Apr 2016 11:29:14 +0200
Subject: [R-sig-Geo] Equivalent imclearborder matlab function
Message-ID: <CAMXOh=214J3yx5_VqAZy39O2eXDEAJQwhnnWkwNZEGP8f7hHiQ@mail.gmail.com>

Hi everybody,

Someone known an equivalent function for imclearborder? Basically
imclearborder detects when a path is connected to the border of a matrix
(raster, grid etc..) and remove the binary data

In the example of mathlab (BW is the original matrix):

BW = [0     0     0     0     0     0     0     0     0
      0     0     0     0     0     0     0     0     0
      0     0     0     0     0     0     0     0     0
      1     0     0     1     1     1     0     0     0
      0     1     0     1     1     1     0     0     0
      0     0     0     1     1     1     0     0     0
      0     0     0     0     0     0     0     0     0
      0     0     0     0     0     0     0     0     0
      0     0     0     0     0     0     0     0     0];


Clear pixels on the border of the image using 4-connectivity.

BWc1 = imclearborder(BW,4)


BWc1 =

     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0
     0     0     0     1     1     1     0     0     0
     0     1     0     1     1     1     0     0     0
     0     0     0     1     1     1     0     0     0
     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0


 Note that imclearborder does not clear the pixel at (5,2) because, with
4-connectivity, it is not considered connected to the border pixel at (4,1).

with 8-conectivity

BWc2 = imclearborder(BW,8)


BWc2 =

     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0
     0     0     0     1     1     1     0     0     0
     0     0     0     1     1     1     0     0     0
     0     0     0     1     1     1     0     0     0
     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0


Thank you in advance.



Andr?s D.

	[[alternative HTML version deleted]]


From marine.regis at hotmail.fr  Tue Apr  5 18:40:34 2016
From: marine.regis at hotmail.fr (Marine Regis)
Date: Tue, 5 Apr 2016 16:40:34 +0000
Subject: [R-sig-Geo] Dissolve holes in a polygon
Message-ID: <AMSPR07MB4701A08BA20F368B60DBB82E29E0@AMSPR07MB470.eurprd07.prod.outlook.com>

Hello,


I have a raster with only NA cells and cells with a value of 1. After converting the raster into polygons with the function gdal_rasterize {gdalUtils}, I obtain a polygon with holes because of NA cells. How can I dissolve the holes in the polygon ?


Thank you very much for your time.

Have a nice day

Marine

	[[alternative HTML version deleted]]


From selebatsom at yahoo.co.uk  Wed Apr  6 00:43:02 2016
From: selebatsom at yahoo.co.uk (moses selebatso)
Date: Tue, 5 Apr 2016 22:43:02 +0000 (UTC)
Subject: [R-sig-Geo] Setting order of levels of factor using
	sciplot_bargraph.CI
References: <1396772753.5623170.1459896182773.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1396772753.5623170.1459896182773.JavaMail.yahoo@mail.yahoo.com>

I?am trying?to plot bargraph using bargraph.CI? but?it used default order (alphabetical order). However, ?I would to display in the re-ordered levels. I managed to re-order, but I cannot get the new order on the graph display! See my scripts below and please help.
> h<-read.csv("clipboard",sep="\t")
> attach(h)
> order <- factor(order, levels = c("Wet", "Cold Early-Dry", "Hot Late-Dry"), ordered = TRUE)
> order
[1] Wet??????????? Cold Early-Dry Hot Late-Dry? 
Levels: Wet Cold Early-Dry Hot Late-Dry
> bargraph.CI(Season, Grass.Height, group = Habitat, data = h, xlab = "Season", ylab = "Grass Height (cm)", cex.lab = 1.5, x.leg = 1.5,col = "black", angle = 45, cex.names = 1, density = c(0,20), legend = TRUE)


Regards,
Moses SELEBATSO Home:?? ?(+267) 318 5219 (H)??Mobile: ?(+267) 716 39370? or? (+267) 738 39370"Those who will?ALWAYS agree with you may be oppressed by you"
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160405/59cfbae3/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: datauri-file.png
Type: image/png
Size: 13215 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160405/59cfbae3/attachment.png>

From rodaromero at gmail.com  Wed Apr  6 00:47:09 2016
From: rodaromero at gmail.com (David Romero)
Date: Tue, 5 Apr 2016 17:47:09 -0500
Subject: [R-sig-Geo] linear model with sill
Message-ID: <CAJx8RnH2tSsk3BWFLLSiVJHOsHTFasG1KezBX3a-fhAAbKvmBA@mail.gmail.com>

Hello listers,

I am elaborating variograms with geoR and testing models, I'd like to
know how I can test linear model with a sill.

    v1 = variog(PmmRG,
max.dist=50000,direction=0,tolerance=22.5,unit.angle="degrees",option
= c("bin"),breaks=brk)
    ols<- variofit(v1,cov.model="linear", wei="cressie")

Thanks and regards,

David


From morera.virginia at gmail.com  Wed Apr  6 12:00:03 2016
From: morera.virginia at gmail.com (Virginia Morera Pujol)
Date: Wed, 6 Apr 2016 12:00:03 +0200
Subject: [R-sig-Geo] different models
Message-ID: <CAJ3XaKd=t2=jjZPqfwKFSaay=oKX4_3QEx5GwQeFFqzmWn_Mzg@mail.gmail.com>

Hi all,

This might be a very dumb question that shows I have very little idea of
what I am talking about, but I'll risk it:

What is the difference between fitting a model using these 3 different
syntaxes?

1/ fit1 <- ppm(ppp, ~covariate),
2/ fit2 <- ppm(ppp, ~x+y+Z, covariates=list(Z=covariate))
3/ fit3 <- ppm(ppp, ~x+y+covariate)

where ppp is my point pattern and "covariate" is a pixel image? I realise
the outputs of 2 and 3 are the same and different to that of 1, so I guess
the question really is

a/ Is there any difference, practical or in the actual computations of the
model, between using 2 and 3?
b/ What is the difference between (2&3) and 1?

Thanks a lot,

Virginia Morera
PhD Student
Department of Animal Biology
University of Barcelona

Aquest correu electr?nic i els annexos poden contenir informaci?
confidencial o protegida legalment i est? adre?at exclusivament a la
persona o entitat destinat?ria. Si no sou  el destinatari final o la
persona encarregada de rebre?l, no esteu autoritzat a llegir-lo,
retenir-lo, modificar-lo, distribuir-lo, copiar-lo ni a revelar-ne el
contingut. Si heu rebut aquest correu electr?nic per error, us preguem que
n?informeu al remitent i que elimineu del sistema el missatge i el material
annex que pugui contenir. Gr?cies per la vostra col?laboraci?.

Este correo electr?nico y sus anexos pueden contener informaci?n
confidencial o legalmente protegida y est? exclusivamente dirigido a la
persona o entidad destinataria. Si usted no es el destinatario final o la
persona encargada de recibirlo, no est? autorizado a leerlo, retenerlo,
modificarlo, distribuirlo, copiarlo ni a revelar su contenido. Si ha
recibido este mensaje electr?nico por error, le rogamos que informe al
remitente y elimine del sistema el mensaje y el material anexo que pueda
contener. Gracias por su colaboraci?n.

This email message and any documents attached to it may contain
confidential or legally protected material and are intended solely for the
use of the individual or organization to whom they are addressed. We remind
you that if you are not the intended recipient of this email message or the
person responsible for processing it, then you are not authorized to read,
save, modify, send, copy or disclose any of its contents. If you have
received this email message by mistake, we kindly ask you to inform the
sender of this and to eliminate both the message and any attachments it
carries from your account.Thank you for your collaboration.

	[[alternative HTML version deleted]]


From thi_veloso at yahoo.com.br  Wed Apr  6 14:00:44 2016
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Wed, 6 Apr 2016 12:00:44 +0000 (UTC)
Subject: [R-sig-Geo] Faster way to extract raster values using multiple
	polygons?
References: <258604906.59719.1459944044625.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <258604906.59719.1459944044625.JavaMail.yahoo@mail.yahoo.com>

Dear all,

I am trying to extract a time series from a raster brick using multiple polygons.

The raster brick is a global temperature netcdf file with 1200 layers (months) and the polygons are each of the 5567 municipalities in Brazil. I intend to extract the temperature time series for each municipality.

As a final result, I would like to have a data frame containing: -the name and coordinates of the municipality, -the date tag from the raster, and -the extracted temperature value.

My initial, VERY SLOW attempt was something like this:


library(raster)

# Create some sample raster data
idx <- seq(as.Date("1960/1/1"), as.Date("1990/12/01"), by = "month")
r <- raster(ncol=360, nrow=180)
b <- brick(lapply(1:length(idx), function(x) setValues(r, runif(ncell(r)))))
b <- setZ(b, idx)

# Import polygon data
br <- getData("GADM", country="Brazil", level=2) # about 7MB to download

# Subset the SMALLEST state - only 75 municipalities
br_sub <- br[br$NAME_1=="Sergipe" & !is.na(br$NAME_1),]
plot(br_sub)

# Now let's extract the data for each municipality
beginCluster()
e <- extract(b, br_sub, fun=mean, df=T)
endCluster()


Even using the smallest state possible, this example takes about 20 minutes to run on a dual-core 2.5GHz Macbook Pro using four threads. As a reference, there are states with over 850 municipalities. And remember, in total there are over 5500 municipalities I need to extract the data for.

I have the feeling that my code is not very optimized.

Has anybody ever dealt with this amount of data in this kind of raster operation? Is there any fastest way to achieve my expected result?
Thanks in advance,
-- Thiago V. dos Santos

PhD student
Land and Atmospheric Science

University of Minnesota


From karlashikev at gmail.com  Wed Apr  6 15:45:36 2016
From: karlashikev at gmail.com (Karla Shikev)
Date: Wed, 6 Apr 2016 10:45:36 -0300
Subject: [R-sig-Geo] problem with rasterToPolygons x worldclim
In-Reply-To: <CAAcGz9-xMF1fxF+7LDCtkbd3cbmzg5TSnVmNWQ97TCYkM_Nrdw@mail.gmail.com>
References: <CAPU4_4pURuP2Zq_o_oW3E7bPOi9Chxmc=HwsdrWaDOYRc30W6g@mail.gmail.com>
	<CAAcGz9-xMF1fxF+7LDCtkbd3cbmzg5TSnVmNWQ97TCYkM_Nrdw@mail.gmail.com>
Message-ID: <CAPU4_4rABWSC-78b1sN5=utH0O7fpQVeSrfrhzVAu6JLkRTJeQ@mail.gmail.com>

Hi Michael,

Thanks for the tips. I tried the help for rasterToPolygons, but none of the
options (e.g. dissolve=TRUE) made any difference. I tried gPolygonize and
it worked, except for (as you predicted), if the edges meet the raster
extents - but that definitely was an advance!

I really appreciate your help and if you just point the way I can try to go
after what needs to be done, but right now I?m stumped.

best, Karla.

On Mon, Apr 4, 2016 at 5:38 PM, Michael Sumner <mdsumner at gmail.com> wrote:

> Read the help for rasterToPolygons, alternatively try chaining
> rasterToContour and rgeos::gPolygonize.
>
> The latter may need coaxing if your edges meet the raster extents.
>
> Cheers, Mike
>
> On Tue, 5 Apr 2016, 05:32 Karla Shikev <karlashikev at gmail.com> wrote:
>
>> Dear all,
>>
>> Here's an issue that is related to the previous one. In the commands below
>> I'm trying to make a polygon for all the regions within a range of mean
>> annual temps. However, rasterToPolygons will draw a square around each
>> value in the original raster, rather than providing me the actual polygon,
>> given that resolution. Any hints? Again, any help will be greatly
>> appreciated.
>>
>> Karla
>>
>> _____
>>
>> library(raster)
>>
>> r<-getData('worldclim', var='bio', res=10)$bio1
>>
>> e <- extent(-140,-100, 50, 60)
>>
>> xx<-crop(r,e)
>>
>> slice1<-rasterToPolygons(xx, fun = function(x) {x > 40 & x < 60})
>>
>> plot(slice1)
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
>

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Wed Apr  6 16:22:43 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 06 Apr 2016 14:22:43 +0000
Subject: [R-sig-Geo] problem with rasterToPolygons x worldclim
In-Reply-To: <CAPU4_4rABWSC-78b1sN5=utH0O7fpQVeSrfrhzVAu6JLkRTJeQ@mail.gmail.com>
References: <CAPU4_4pURuP2Zq_o_oW3E7bPOi9Chxmc=HwsdrWaDOYRc30W6g@mail.gmail.com>
	<CAAcGz9-xMF1fxF+7LDCtkbd3cbmzg5TSnVmNWQ97TCYkM_Nrdw@mail.gmail.com>
	<CAPU4_4rABWSC-78b1sN5=utH0O7fpQVeSrfrhzVAu6JLkRTJeQ@mail.gmail.com>
Message-ID: <CAAcGz99ZOh6nGPiAPwDgqC56X4320oGDHn1z=amS6M+Q4yn0bA@mail.gmail.com>

On Wed, 6 Apr 2016 at 23:45 Karla Shikev <karlashikev at gmail.com> wrote:

>
> Hi Michael,
>
> Thanks for the tips. I tried the help for rasterToPolygons, but none of
> the options (e.g. dissolve=TRUE) made any difference. I tried gPolygonize
> and it worked, except for (as you predicted), if the edges meet the raster
> extents - but that definitely was an advance!
>
>
I see the issue, the fun argument to rasterToPolygons is masking out values
from that interval, but it's not setting them all to the same value - so
you still get individual pixel polygons unless you mask on presence in the
interval or not (as a binary):

library(raster)

r<-getData('worldclim', var='bio', res=10)$bio1

e <- extent(-140,-100, 50, 60)

xx <- crop(r,e)
## mask out pixel values first
xx <- xx > 40 & xx < 60

## 576 polygons
slice1<- rasterToPolygons(xx, fun = function(x) {x == 1})
## 1 polygon
slice2 <- rasterToPolygons(xx,  fun = function(x) {x == 1}, dissolve = TRUE)


Still it's not a very nice polygon, if I can I'll try a different way.

Cheers, Mike.




>
> I really appreciate your help and if you just point the way I can try to
> go after what needs to be done, but right now I?m stumped.
>
> best, Karla.
>
> On Mon, Apr 4, 2016 at 5:38 PM, Michael Sumner <mdsumner at gmail.com> wrote:
>
>> Read the help for rasterToPolygons, alternatively try chaining
>> rasterToContour and rgeos::gPolygonize.
>>
>> The latter may need coaxing if your edges meet the raster extents.
>>
>> Cheers, Mike
>>
>> On Tue, 5 Apr 2016, 05:32 Karla Shikev <karlashikev at gmail.com> wrote:
>>
>>> Dear all,
>>>
>>> Here's an issue that is related to the previous one. In the commands
>>> below
>>> I'm trying to make a polygon for all the regions within a range of mean
>>> annual temps. However, rasterToPolygons will draw a square around each
>>> value in the original raster, rather than providing me the actual
>>> polygon,
>>> given that resolution. Any hints? Again, any help will be greatly
>>> appreciated.
>>>
>>> Karla
>>>
>>> _____
>>>
>>> library(raster)
>>>
>>> r<-getData('worldclim', var='bio', res=10)$bio1
>>>
>>> e <- extent(-140,-100, 50, 60)
>>>
>>> xx<-crop(r,e)
>>>
>>> slice1<-rasterToPolygons(xx, fun = function(x) {x > 40 & x < 60})
>>>
>>> plot(slice1)
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>> --
>> Dr. Michael Sumner
>> Software and Database Engineer
>> Australian Antarctic Division
>> 203 Channel Highway
>> Kingston Tasmania 7050 Australia
>>
>>
> --
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Wed Apr  6 16:33:41 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 06 Apr 2016 14:33:41 +0000
Subject: [R-sig-Geo] problem with rasterToPolygons x worldclim
In-Reply-To: <CAAcGz99ZOh6nGPiAPwDgqC56X4320oGDHn1z=amS6M+Q4yn0bA@mail.gmail.com>
References: <CAPU4_4pURuP2Zq_o_oW3E7bPOi9Chxmc=HwsdrWaDOYRc30W6g@mail.gmail.com>
	<CAAcGz9-xMF1fxF+7LDCtkbd3cbmzg5TSnVmNWQ97TCYkM_Nrdw@mail.gmail.com>
	<CAPU4_4rABWSC-78b1sN5=utH0O7fpQVeSrfrhzVAu6JLkRTJeQ@mail.gmail.com>
	<CAAcGz99ZOh6nGPiAPwDgqC56X4320oGDHn1z=amS6M+Q4yn0bA@mail.gmail.com>
Message-ID: <CAAcGz9-B9Y80DAntCj-D0HKFLkcD5N4JuP=C_Gwvbpj1Yw9wFg@mail.gmail.com>

On Thu, 7 Apr 2016 at 00:22 Michael Sumner <mdsumner at gmail.com> wrote:

> On Wed, 6 Apr 2016 at 23:45 Karla Shikev <karlashikev at gmail.com> wrote:
>
>>
>> Hi Michael,
>>
>> Thanks for the tips. I tried the help for rasterToPolygons, but none of
>> the options (e.g. dissolve=TRUE) made any difference. I tried gPolygonize
>> and it worked, except for (as you predicted), if the edges meet the raster
>> extents - but that definitely was an advance!
>>
>>
> I see the issue, the fun argument to rasterToPolygons is masking out
> values from that interval, but it's not setting them all to the same value
> - so you still get individual pixel polygons unless you mask on presence in
> the interval or not (as a binary):
>
> library(raster)
>
> r<-getData('worldclim', var='bio', res=10)$bio1
>
> e <- extent(-140,-100, 50, 60)
>
> xx <- crop(r,e)
> ## mask out pixel values first
> xx <- xx > 40 & xx < 60
>
> ## 576 polygons
> slice1<- rasterToPolygons(xx, fun = function(x) {x == 1})
> ## 1 polygon
> slice2 <- rasterToPolygons(xx,  fun = function(x) {x == 1}, dissolve =
> TRUE)
>
>
> Still it's not a very nice polygon, if I can I'll try a different way.
>
> Cheers, Mike.
>
>
>
>

You can use tricks to fill the outer edge so you get a valid contour line
all the way around (it's not always going to work - see here for the
explanation by whuber:
http://gis.stackexchange.com/questions/61550/colouring-areas-between-vector-contours
)

Is this better? Maybe - there are lots of other ways - maybe a buffer on
this gives roughly what you need. Maybe you only need a total area so
summing pixels after filtering is better?

Would be nice to have contouring that reliably produced polygons, but it's
a tricky problem. Other kinds of shape-finding might be better, with
alphahull on the pixel points perhaps, but you quickly get into "geometry
fudger" territory here rather than objective measures.

HTH




>
>>
>> I really appreciate your help and if you just point the way I can try to
>> go after what needs to be done, but right now I?m stumped.
>>
>> best, Karla.
>>
>> On Mon, Apr 4, 2016 at 5:38 PM, Michael Sumner <mdsumner at gmail.com>
>> wrote:
>>
>>> Read the help for rasterToPolygons, alternatively try chaining
>>> rasterToContour and rgeos::gPolygonize.
>>>
>>> The latter may need coaxing if your edges meet the raster extents.
>>>
>>> Cheers, Mike
>>>
>>> On Tue, 5 Apr 2016, 05:32 Karla Shikev <karlashikev at gmail.com> wrote:
>>>
>>>> Dear all,
>>>>
>>>> Here's an issue that is related to the previous one. In the commands
>>>> below
>>>> I'm trying to make a polygon for all the regions within a range of mean
>>>> annual temps. However, rasterToPolygons will draw a square around each
>>>> value in the original raster, rather than providing me the actual
>>>> polygon,
>>>> given that resolution. Any hints? Again, any help will be greatly
>>>> appreciated.
>>>>
>>>> Karla
>>>>
>>>> _____
>>>>
>>>> library(raster)
>>>>
>>>> r<-getData('worldclim', var='bio', res=10)$bio1
>>>>
>>>> e <- extent(-140,-100, 50, 60)
>>>>
>>>> xx<-crop(r,e)
>>>>
>>>> slice1<-rasterToPolygons(xx, fun = function(x) {x > 40 & x < 60})
>>>>
>>>> plot(slice1)
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>> --
>>> Dr. Michael Sumner
>>> Software and Database Engineer
>>> Australian Antarctic Division
>>> 203 Channel Highway
>>> Kingston Tasmania 7050 Australia
>>>
>>>
>> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
> --
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Wed Apr  6 16:34:29 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 06 Apr 2016 14:34:29 +0000
Subject: [R-sig-Geo] problem with rasterToPolygons x worldclim
In-Reply-To: <CAAcGz9-B9Y80DAntCj-D0HKFLkcD5N4JuP=C_Gwvbpj1Yw9wFg@mail.gmail.com>
References: <CAPU4_4pURuP2Zq_o_oW3E7bPOi9Chxmc=HwsdrWaDOYRc30W6g@mail.gmail.com>
	<CAAcGz9-xMF1fxF+7LDCtkbd3cbmzg5TSnVmNWQ97TCYkM_Nrdw@mail.gmail.com>
	<CAPU4_4rABWSC-78b1sN5=utH0O7fpQVeSrfrhzVAu6JLkRTJeQ@mail.gmail.com>
	<CAAcGz99ZOh6nGPiAPwDgqC56X4320oGDHn1z=amS6M+Q4yn0bA@mail.gmail.com>
	<CAAcGz9-B9Y80DAntCj-D0HKFLkcD5N4JuP=C_Gwvbpj1Yw9wFg@mail.gmail.com>
Message-ID: <CAAcGz99ojvQqQHqA=iPjDLwusxP7OdH2h8NO6fg1ROJc_8eFFQ@mail.gmail.com>

On Thu, 7 Apr 2016 at 00:33 Michael Sumner <mdsumner at gmail.com> wrote:

> On Thu, 7 Apr 2016 at 00:22 Michael Sumner <mdsumner at gmail.com> wrote:
>
>> On Wed, 6 Apr 2016 at 23:45 Karla Shikev <karlashikev at gmail.com> wrote:
>>
>>>
>>> Hi Michael,
>>>
>>> Thanks for the tips. I tried the help for rasterToPolygons, but none of
>>> the options (e.g. dissolve=TRUE) made any difference. I tried gPolygonize
>>> and it worked, except for (as you predicted), if the edges meet the raster
>>> extents - but that definitely was an advance!
>>>
>>>
>> I see the issue, the fun argument to rasterToPolygons is masking out
>> values from that interval, but it's not setting them all to the same value
>> - so you still get individual pixel polygons unless you mask on presence in
>> the interval or not (as a binary):
>>
>> library(raster)
>>
>> r<-getData('worldclim', var='bio', res=10)$bio1
>>
>> e <- extent(-140,-100, 50, 60)
>>
>> xx <- crop(r,e)
>> ## mask out pixel values first
>> xx <- xx > 40 & xx < 60
>>
>> ## 576 polygons
>> slice1<- rasterToPolygons(xx, fun = function(x) {x == 1})
>> ## 1 polygon
>> slice2 <- rasterToPolygons(xx,  fun = function(x) {x == 1}, dissolve =
>> TRUE)
>>
>>
>> Still it's not a very nice polygon, if I can I'll try a different way.
>>
>> Cheers, Mike.
>>
>>
>>
>>
>
> You can use tricks to fill the outer edge so you get a valid contour line
> all the way around (it's not always going to work - see here for the
> explanation by whuber:
> http://gis.stackexchange.com/questions/61550/colouring-areas-between-vector-contours
> )
>
>

Sorry, forgot the code!

library(raster)

r<-getData('worldclim', var='bio', res=10)$bio1

e <- extent(-140,-100, 50, 60)

xx <- crop(r,e)

## buffer out a little
xx2 <- extend(xx, extent(xx) + res(xx) * 4, value = NA_real_)

## set missing to less than interval
xx2[is.na(xx2)] <- cellStats(xx2, min)
## now contour
cl <- rasterToContour(xx2 > 40 & xx2 < 60, level = 1)

pp <- rgeos::gUnionCascaded(rgeos::gPolygonize(cl))
pp
plot(pp, col = "grey")




> Is this better? Maybe - there are lots of other ways - maybe a buffer on
> this gives roughly what you need. Maybe you only need a total area so
> summing pixels after filtering is better?
>
> Would be nice to have contouring that reliably produced polygons, but it's
> a tricky problem. Other kinds of shape-finding might be better, with
> alphahull on the pixel points perhaps, but you quickly get into "geometry
> fudger" territory here rather than objective measures.
>
> HTH
>
>
>
>
>>
>>>
>>> I really appreciate your help and if you just point the way I can try to
>>> go after what needs to be done, but right now I?m stumped.
>>>
>>> best, Karla.
>>>
>>> On Mon, Apr 4, 2016 at 5:38 PM, Michael Sumner <mdsumner at gmail.com>
>>> wrote:
>>>
>>>> Read the help for rasterToPolygons, alternatively try chaining
>>>> rasterToContour and rgeos::gPolygonize.
>>>>
>>>> The latter may need coaxing if your edges meet the raster extents.
>>>>
>>>> Cheers, Mike
>>>>
>>>> On Tue, 5 Apr 2016, 05:32 Karla Shikev <karlashikev at gmail.com> wrote:
>>>>
>>>>> Dear all,
>>>>>
>>>>> Here's an issue that is related to the previous one. In the commands
>>>>> below
>>>>> I'm trying to make a polygon for all the regions within a range of mean
>>>>> annual temps. However, rasterToPolygons will draw a square around each
>>>>> value in the original raster, rather than providing me the actual
>>>>> polygon,
>>>>> given that resolution. Any hints? Again, any help will be greatly
>>>>> appreciated.
>>>>>
>>>>> Karla
>>>>>
>>>>> _____
>>>>>
>>>>> library(raster)
>>>>>
>>>>> r<-getData('worldclim', var='bio', res=10)$bio1
>>>>>
>>>>> e <- extent(-140,-100, 50, 60)
>>>>>
>>>>> xx<-crop(r,e)
>>>>>
>>>>> slice1<-rasterToPolygons(xx, fun = function(x) {x > 40 & x < 60})
>>>>>
>>>>> plot(slice1)
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at r-project.org
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>>> --
>>>> Dr. Michael Sumner
>>>> Software and Database Engineer
>>>> Australian Antarctic Division
>>>> 203 Channel Highway
>>>> Kingston Tasmania 7050 Australia
>>>>
>>>>
>>> --
>> Dr. Michael Sumner
>> Software and Database Engineer
>> Australian Antarctic Division
>> 203 Channel Highway
>> Kingston Tasmania 7050 Australia
>>
>> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
> --
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From vinhdizzo at gmail.com  Wed Apr  6 16:45:21 2016
From: vinhdizzo at gmail.com (Vinh Nguyen)
Date: Wed, 6 Apr 2016 07:45:21 -0700
Subject: [R-sig-Geo] readOGR not reading in prj file?
Message-ID: <CA+2Dmwj6US8i_YvUQ3BJocrKbxo1jkpBH1LA=zKZLbP1jNGK8g@mail.gmail.com>

Hi,

I'm currently using rgdal v 1.1-1 on R 3.2.2.  It appears my
projection file is not being read in by readOGR:

> dFloodRisk <- readOGR(floodshapedir, shapebase)
OGR data source with driver: ESRI Shapefile
Source: "FloodShapes", layer: "2013Spring_Flood_Drawn"
with 8 features
It has 2 fields
> proj4string(dFloodRisk)
[1] NA

I have to manually pass in the CRS:
> dFloodRisk <- readOGR(floodshapedir, paste0(curYear, 'Spring_Flood_Drawn'), p4s='+init=EPSG:3857')
OGR data source with driver: ESRI Shapefile
Source: "FloodShapes", layer: "2013Spring_Flood_Drawn"
with 8 features
It has 2 fields
> proj4string(dFloodRisk)
[1] "+init=EPSG:3857 +proj=merc +a=6378137 +b=6378137 +lat_ts=0.0
+lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +no_defs"

Any thoughts on why readOGR doesn't automatically read in the prj
file?  Here's the content of the prj file:
PROJCS["WGS_1984_Web_Mercator_Auxiliary_Sphere",GEOGCS["GCS_WGS_1984",DATUM["D_WGS_1984",SPHEROID["WGS_1984",6378137.0,298.257223563]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]],PROJECTION["Mercator_Auxiliary_Sphere"],PARAMETER["False_Easting",0.0],PARAMETER["False_Northing",0.0],PARAMETER["Central_Meridian",0.0],PARAMETER["Standard_Parallel_1",0.0],PARAMETER["Auxiliary_Sphere_Type",0.0],UNIT["Meter",1.0]]

Thanks so much for your help.

-- Vinh


From vinhdizzo at gmail.com  Wed Apr  6 16:52:01 2016
From: vinhdizzo at gmail.com (Vinh Nguyen)
Date: Wed, 6 Apr 2016 07:52:01 -0700
Subject: [R-sig-Geo] can't read in shapefile
Message-ID: <CA+2DmwgzxVe+GKSGWOcNzy=d7ej2Tq9Vna-JbV78f_aq2Nu1AQ@mail.gmail.com>

Hi,

I have two shapefiles, both generated from ArcGIS using similar
methods.  I was able to read in one file using readOGR but not the
other.  Any thoughts on how best to figure out why I can't read in the
file?  Here's the error:

> dFloodRisk <- readOGR(floodshapedir, shapefilebase, verbose=TRUE)
Error in ogrInfo(dsn = dsn, layer = layer, encoding = encoding,
use_iconv = use_iconv,  :
  Cannot open layer
> traceback()
5: .Call("ogrInfo", as.character(dsn), as.character(layer), PACKAGE = "rgdal")
4: ogrInfo(dsn = dsn, layer = layer, encoding = encoding, use_iconv = use_iconv,
       swapAxisOrder = swapAxisOrder, require_geomType = require_geomType)
3: withCallingHandlers(expr, message = function(c)
invokeRestart("muffleMessage"))
2: suppressMessages(ogr_info <- ogrInfo(dsn = dsn, layer = layer,
       encoding = encoding, use_iconv = use_iconv, swapAxisOrder =
swapAxisOrder,
       require_geomType = require_geomType))
1: readOGR(floodshapedir, shapefilebase,
       verbose = TRUE)

Thanks for your help.

-- Vinh


From sebastien.piguet.1 at gmail.com  Wed Apr  6 17:14:43 2016
From: sebastien.piguet.1 at gmail.com (=?UTF-8?Q?S=C3=A9bastien_Piguet?=)
Date: Wed, 6 Apr 2016 17:14:43 +0200
Subject: [R-sig-Geo] ERA Interim Daily Data - Query historical data for a
 point (defined by lat and lon)
Message-ID: <CAG_N2V4e16BSU6pMshqNf-m8LBSui=C-aSPXwZOjjqpwHjfrvA@mail.gmail.com>

Hi,

I am currently trying to query ECMWF data (
http://apps.ecmwf.int/datasets/data/interim-full-daily/levtype=sfc/) for a
point (lon,lat) ~ (-71.5333,-32.7723). I query an area around this point as
showed below:
[image: Inline image 1]
Then, I use R to open the grip file:

library(rgdal)
library(maptools)
library(raster)
library(RCurl)
library(stringr)

setwd("XXXXXX")
#Initialize raster stack
rs<-stack()

#Get filenames in the folder
filePath<-"YYY"
fileNms<-list.files(filePath)

#Define Point of interest lon / lat
point <- cbind(-71.5333,-32.7723)

# DB loading
grib <- readGDAL(paste(filePath,fileNms[1], sep=""))

# Selection of significant height of total swell = param 237 (
http://www.ecmwf.int/sites/default/files/elibrary/2011/8174-era-interim-archive-version-20.pdf
)
rLayer<-raster(grib, 237)
rLayer


I get the following results:

> summary(rLayer)          band62
Min.    10.25290
1st Qu. 10.33603
Median  10.41916
3rd Qu. 10.41916
Max.    10.41916
NA's    15.00000> summary(rasterToPoints(rLayer))       x
 y              band62
 Min.   :288.0   Min.   :-33.75   Min.   :10.25
 1st Qu.:288.0   1st Qu.:-33.00   1st Qu.:10.34
 Median :288.0   Median :-32.25   Median :10.42
 Mean   :288.2   Mean   :-32.75   Mean   :10.36
 3rd Qu.:288.4   3rd Qu.:-32.25   3rd Qu.:10.42
 Max.   :288.8   Max.   :-32.25   Max.   :10.42

My problems are the following:
1) Latitude is similar from what I expected  but not the longitude.

2) Data about date does not appear

Thank you so much for your help !

Sebastien
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160406/b3c0dfa0/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 11233 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160406/b3c0dfa0/attachment.png>

From mutiibwa2000 at yahoo.com  Wed Apr  6 17:24:33 2016
From: mutiibwa2000 at yahoo.com (Denis mutiibwa)
Date: Wed, 6 Apr 2016 15:24:33 +0000 (UTC)
Subject: [R-sig-Geo] readOGR not reading in prj file?
In-Reply-To: <CA+2Dmwj6US8i_YvUQ3BJocrKbxo1jkpBH1LA=zKZLbP1jNGK8g@mail.gmail.com>
References: <CA+2Dmwj6US8i_YvUQ3BJocrKbxo1jkpBH1LA=zKZLbP1jNGK8g@mail.gmail.com>
Message-ID: <710820352.179145.1459956273335.JavaMail.yahoo@mail.yahoo.com>

Hi Vinh,proj4string function is giving you NA because "shapebase" shapefile doesn't have an auxiliary file "shapebase.prj"?Denis Mutiibwa, 

    On Wednesday, April 6, 2016 10:46 AM, Vinh Nguyen <vinhdizzo at gmail.com> wrote:
 

 >Hi,

>I'm currently using rgdal v 1.1-1 on R 3.2.2.? It appears my
>projection file is not being read in by readOGR:
>
>> dFloodRisk <- readOGR(floodshapedir, shapebase)
>OGR data source with driver: ESRI Shapefile
>Source: "FloodShapes", layer: "2013Spring_Flood_Drawn"
>with 8 features
>It has 2 fields
> proj4string(dFloodRisk)
>[1] NA
>
>I have to manually pass in the CRS:
>> dFloodRisk <- readOGR(floodshapedir, paste0(curYear, 'Spring_Flood_Drawn'), p4s='+init=EPSG:3857')
>OGR data source with driver: ESRI Shapefile
>Source: "FloodShapes", layer: "2013Spring_Flood_Drawn"
>with 8 features
>It has 2 fields
>> proj4string(dFloodRisk)
>[1] "+init=EPSG:3857 +proj=merc +a=6378137 +b=6378137 +lat_ts=0.0
>+lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +no_defs"
>
>Any thoughts on why readOGR doesn't automatically read in the prj
>file?? Here's the content of the prj file:
>PROJCS["WGS_1984_Web_Mercator_Auxiliary_Sphere",GEOGCS["GCS_WGS_1984",DATUM["D_WGS_1984",SPHEROID["WGS_1984",6378137.0,298.257223563]],PRIMEM["Gree>nwich",0.0],UNIT["Degree",0.0174532925199433]],PROJECTION["Mercator_Auxiliary_Sphere"],PARAMETER["False_Easting",0.0],PARAMETER["False_Northing",0.0],PARAMETER[">>Central_Meridian",0.0],PARAMETER["Standard_Parallel_1",0.0],PARAMETER["Auxiliary_Sphere_Type",0.0],UNIT["Meter",1.0]]
>
>Thanks so much for your help.
>
>-- Vinh

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


  
	[[alternative HTML version deleted]]


From vinhdizzo at gmail.com  Wed Apr  6 17:32:36 2016
From: vinhdizzo at gmail.com (Vinh Nguyen)
Date: Wed, 6 Apr 2016 08:32:36 -0700
Subject: [R-sig-Geo] readOGR not reading in prj file?
In-Reply-To: <710820352.179145.1459956273335.JavaMail.yahoo@mail.yahoo.com>
References: <CA+2Dmwj6US8i_YvUQ3BJocrKbxo1jkpBH1LA=zKZLbP1jNGK8g@mail.gmail.com>
	<710820352.179145.1459956273335.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+2DmwjRwwZM339c_sAsRxeTV6GY0w-Toet5+tU+S-KpS=nbew@mail.gmail.com>

On Wed, Apr 6, 2016 at 8:24 AM, Denis mutiibwa <mutiibwa2000 at yahoo.com> wrote:
> Hi Vinh,
> proj4string function is giving you NA because "shapebase" shapefile doesn't
> have an auxiliary file "shapebase.prj"
>
> Denis Mutiibwa,


Thanks for your response Denis.  The following files are all in the directory:
2014Spring_Flood_Drawn.cpg  2014Spring_Flood_Drawn.sbx
2014Spring_Flood_Drawn.dbf  2014Spring_Flood_Drawn.shp
2014Spring_Flood_Drawn.prj  2014Spring_Flood_Drawn.shp.xml
2014Spring_Flood_Drawn.sbn  2014Spring_Flood_Drawn.shx

So, the prj file is there...or am I misunderstanding?  Thanks.

-- Vinh


From mutiibwa2000 at yahoo.com  Wed Apr  6 17:41:28 2016
From: mutiibwa2000 at yahoo.com (Denis mutiibwa)
Date: Wed, 6 Apr 2016 15:41:28 +0000 (UTC)
Subject: [R-sig-Geo] readOGR not reading in prj file?
In-Reply-To: <CA+2DmwjRwwZM339c_sAsRxeTV6GY0w-Toet5+tU+S-KpS=nbew@mail.gmail.com>
References: <CA+2DmwjRwwZM339c_sAsRxeTV6GY0w-Toet5+tU+S-KpS=nbew@mail.gmail.com>
Message-ID: <1452897716.185160.1459957288192.JavaMail.yahoo@mail.yahoo.com>

Where is "shapebase" coming from?If those are the files in the directory, your scripts should as below:dir.path <- directory pathdFloodRisk <- readOGR(dir.path, "2014Spring_Flood_Drawn")proj4string(dFloodRisk)?
Denis Mutiibwa 

    On Wednesday, April 6, 2016 11:32 AM, Vinh Nguyen <vinhdizzo at gmail.com> wrote:
 

 On Wed, Apr 6, 2016 at 8:24 AM, Denis mutiibwa <mutiibwa2000 at yahoo.com> wrote:
>> Hi Vinh,
>> proj4string function is giving you NA because "shapebase" shapefile doesn't
>> have an auxiliary file "shapebase.prj"
>>
>> Denis Mutiibwa,
>
>
>Thanks for your response Denis.? The following files are all in the directory:
>2014Spring_Flood_Drawn.cpg? 2014Spring_Flood_Drawn.sbx
>2014Spring_Flood_Drawn.dbf? 2014Spring_Flood_Drawn.shp
>2014Spring_Flood_Drawn.prj? 2014Spring_Flood_Drawn.shp.xml
>2014Spring_Flood_Drawn.sbn? 2014Spring_Flood_Drawn.shx
>
>So, the prj file is there...or am I misunderstanding?? Thanks.>
>
>-- Vinh


  
	[[alternative HTML version deleted]]


From btupper at bigelow.org  Wed Apr  6 17:48:47 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Wed, 6 Apr 2016 11:48:47 -0400
Subject: [R-sig-Geo] Faster way to extract raster values using multiple
	polygons?
In-Reply-To: <258604906.59719.1459944044625.JavaMail.yahoo@mail.yahoo.com>
References: <258604906.59719.1459944044625.JavaMail.yahoo.ref@mail.yahoo.com>
	<258604906.59719.1459944044625.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6C0509A0-DD79-415A-B21F-4F6713C80DD9@bigelow.org>

Hi,

The resolution of your raster data (1 degree) is much more coarse than what your polygons represent.  Could you short-circuit the process by assuming that the temp at the centroid of each polygon would suitably represent the mean temperature across each polygon?  Unless you have some much bigger polygons, I can't imagine it will be very far off. If so, then you could pretty quickly extract the values for each layer in the raster at each centroid.  Perhaps like this?

cents <- coordinates(br_sub)
v <- extract(b, cents)

Is that close enough?

Cheers,
Ben

> On Apr 6, 2016, at 8:00 AM, Thiago V. dos Santos via R-sig-Geo <r-sig-geo at r-project.org> wrote:
> 
> Dear all,
> 
> I am trying to extract a time series from a raster brick using multiple polygons.
> 
> The raster brick is a global temperature netcdf file with 1200 layers (months) and the polygons are each of the 5567 municipalities in Brazil. I intend to extract the temperature time series for each municipality.
> 
> As a final result, I would like to have a data frame containing: -the name and coordinates of the municipality, -the date tag from the raster, and -the extracted temperature value.
> 
> My initial, VERY SLOW attempt was something like this:
> 
> 
> library(raster)
> 
> # Create some sample raster data
> idx <- seq(as.Date("1960/1/1"), as.Date("1990/12/01"), by = "month")
> r <- raster(ncol=360, nrow=180)
> b <- brick(lapply(1:length(idx), function(x) setValues(r, runif(ncell(r)))))
> b <- setZ(b, idx)
> 
> # Import polygon data
> br <- getData("GADM", country="Brazil", level=2) # about 7MB to download
> 
> # Subset the SMALLEST state - only 75 municipalities
> br_sub <- br[br$NAME_1=="Sergipe" & !is.na(br$NAME_1),]
> plot(br_sub)
> 
> # Now let's extract the data for each municipality
> beginCluster()
> e <- extract(b, br_sub, fun=mean, df=T)
> endCluster()
> 
> 
> Even using the smallest state possible, this example takes about 20 minutes to run on a dual-core 2.5GHz Macbook Pro using four threads. As a reference, there are states with over 850 municipalities. And remember, in total there are over 5500 municipalities I need to extract the data for.
> 
> I have the feeling that my code is not very optimized.
> 
> Has anybody ever dealt with this amount of data in this kind of raster operation? Is there any fastest way to achieve my expected result?
> Thanks in advance,
> -- Thiago V. dos Santos
> 
> PhD student
> Land and Atmospheric Science
> 
> University of Minnesota
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From vinhdizzo at gmail.com  Wed Apr  6 17:53:55 2016
From: vinhdizzo at gmail.com (Vinh Nguyen)
Date: Wed, 6 Apr 2016 08:53:55 -0700
Subject: [R-sig-Geo] readOGR not reading in prj file?
In-Reply-To: <1452897716.185160.1459957288192.JavaMail.yahoo@mail.yahoo.com>
References: <CA+2DmwjRwwZM339c_sAsRxeTV6GY0w-Toet5+tU+S-KpS=nbew@mail.gmail.com>
	<1452897716.185160.1459957288192.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+2DmwgWq6B_gt14tvcZsTNi+6qG-11b5Vu1D4WHv1_L+7vo4Q@mail.gmail.com>

On Wed, Apr 6, 2016 at 8:41 AM, Denis mutiibwa <mutiibwa2000 at yahoo.com> wrote:
> Where is "shapebase" coming from?
> If those are the files in the directory, your scripts should as below:
> dir.path <- directory path
> dFloodRisk <- readOGR(dir.path, "2014Spring_Flood_Drawn")
> proj4string(dFloodRisk)

I'm reading the files in exactly as you are suggesting (floodshapedir
and shapebase are variables) as seen in the output below:

> dFloodRisk <- readOGR(floodshapedir, shapebase)
OGR data source with driver: ESRI Shapefile
Source: "FloodShapes", layer: "2013Spring_Flood_Drawn"

Just not sure why the prj file is not being read in.  Thanks.

-- Vinh


From mutiibwa2000 at yahoo.com  Wed Apr  6 17:58:40 2016
From: mutiibwa2000 at yahoo.com (Denis mutiibwa)
Date: Wed, 6 Apr 2016 15:58:40 +0000 (UTC)
Subject: [R-sig-Geo] readOGR not reading in prj file?
In-Reply-To: <CA+2DmwgWq6B_gt14tvcZsTNi+6qG-11b5Vu1D4WHv1_L+7vo4Q@mail.gmail.com>
References: <CA+2DmwgWq6B_gt14tvcZsTNi+6qG-11b5Vu1D4WHv1_L+7vo4Q@mail.gmail.com>
Message-ID: <1738369436.203731.1459958320211.JavaMail.yahoo@mail.yahoo.com>

readOGR(dir.path, "argv2")
it seems "argv2" has to be the shapefile name not a variable name ??Denis Mutiibwa 

    On Wednesday, April 6, 2016 11:54 AM, Vinh Nguyen <vinhdizzo at gmail.com> wrote:
 

 On Wed, Apr 6, 2016 at 8:41 AM, Denis mutiibwa <mutiibwa2000 at yahoo.com> wrote:
>> Where is "shapebase" coming from?
>> If those are the files in the directory, your scripts should as below:
>> dir.path <- directory path
>> dFloodRisk <- readOGR(dir.path, "2014Spring_Flood_Drawn")
>> proj4string(dFloodRisk)
>
>I'm reading the files in exactly as you are suggesting (floodshapedir
>and shapebase are variables) as seen in the output below:
>
>> dFloodRisk <- readOGR(floodshapedir, shapebase)
>OGR data source with driver: ESRI Shapefile
>Source: "FloodShapes", layer: "2013Spring_Flood_Drawn"
>
>Just not sure why the prj file is not being read in.? Thanks.>
>
>-- Vinh


  
	[[alternative HTML version deleted]]


From vinhdizzo at gmail.com  Wed Apr  6 18:11:03 2016
From: vinhdizzo at gmail.com (Vinh Nguyen)
Date: Wed, 6 Apr 2016 09:11:03 -0700
Subject: [R-sig-Geo] readOGR not reading in prj file?
In-Reply-To: <1738369436.203731.1459958320211.JavaMail.yahoo@mail.yahoo.com>
References: <CA+2DmwgWq6B_gt14tvcZsTNi+6qG-11b5Vu1D4WHv1_L+7vo4Q@mail.gmail.com>
	<1738369436.203731.1459958320211.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+2Dmwja1gg7USuchgVfV4FGvFjesDh6mBKA5ET2J3E00TCaGg@mail.gmail.com>

On Wed, Apr 6, 2016 at 8:58 AM, Denis mutiibwa <mutiibwa2000 at yahoo.com> wrote:
> readOGR(dir.path, "argv2")
> it seems "argv2" has to be the shapefile name not a variable name


My 'floodshapedir' and 'shapebase' are both variables with path stored
in.  Here's the function call with the strings explicitly passed.  I
don't think it's an issue with these paths.

> dFloodRisk <- readOGR('FloodShapes', '2013Spring_Flood_Drawn', verbose=TRUE)
OGR data source with driver: ESRI Shapefile
Source: "FloodShapes", layer: "2013Spring_Flood_Drawn"
with 8 features
It has 2 fields
> proj4string(dFloodRisk)
[1] NA

-- Vinh


From vinhdizzo at gmail.com  Wed Apr  6 19:33:36 2016
From: vinhdizzo at gmail.com (Vinh Nguyen)
Date: Wed, 6 Apr 2016 10:33:36 -0700
Subject: [R-sig-Geo] readOGR not reading in prj file?
In-Reply-To: <570546F7.6050501@uni-muenster.de>
References: <CA+2DmwgWq6B_gt14tvcZsTNi+6qG-11b5Vu1D4WHv1_L+7vo4Q@mail.gmail.com>
	<1738369436.203731.1459958320211.JavaMail.yahoo@mail.yahoo.com>
	<CA+2Dmwja1gg7USuchgVfV4FGvFjesDh6mBKA5ET2J3E00TCaGg@mail.gmail.com>
	<570546F7.6050501@uni-muenster.de>
Message-ID: <CA+2DmwjsTdvYk+0UZiYFjbfFga5m2b0cf8usK5rvKLigbEAiyA@mail.gmail.com>

On Apr 6, 2016 10:27 AM, "Edzer Pebesma" <edzer.pebesma at uni-muenster.de>
wrote:
>
> What are the contents of the 2013Spring_Flood_Drawn.prj file?
>

Here's the content of the prj file:
PROJCS["WGS_1984_Web_Mercator_Auxiliary_Sphere",GEOGCS["GCS_WGS_1984",DATUM["D_WGS_1984",SPHEROID["WGS_1984",6378137.0,298.257223563]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]],PROJECTION["Mercator_Auxiliary_Sphere"],PARAMETER["False_Easting",0.0],PARAMETER["False_Northing",0.0],PARAMETER["Central_Meridian",0.0],PARAMETER["Standard_Parallel_1",0.0],PARAMETER["Auxiliary_Sphere_Type",0.0],UNIT["Meter",1.0]]

Thanks so much for your help.

	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Wed Apr  6 19:42:06 2016
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 6 Apr 2016 19:42:06 +0200
Subject: [R-sig-Geo] readOGR not reading in prj file?
In-Reply-To: <CA+2DmwjsTdvYk+0UZiYFjbfFga5m2b0cf8usK5rvKLigbEAiyA@mail.gmail.com>
References: <CA+2DmwgWq6B_gt14tvcZsTNi+6qG-11b5Vu1D4WHv1_L+7vo4Q@mail.gmail.com>
	<1738369436.203731.1459958320211.JavaMail.yahoo@mail.yahoo.com>
	<CA+2Dmwja1gg7USuchgVfV4FGvFjesDh6mBKA5ET2J3E00TCaGg@mail.gmail.com>
	<570546F7.6050501@uni-muenster.de>
	<CA+2DmwjsTdvYk+0UZiYFjbfFga5m2b0cf8usK5rvKLigbEAiyA@mail.gmail.com>
Message-ID: <57054A6E.6050803@uni-muenster.de>



On 06/04/16 19:33, Vinh Nguyen wrote:
> 
> On Apr 6, 2016 10:27 AM, "Edzer Pebesma" <edzer.pebesma at uni-muenster.de
> <mailto:edzer.pebesma at uni-muenster.de>> wrote:
>>
>> What are the contents of the 2013Spring_Flood_Drawn.prj file?
>>
> 
> Here's the content of the prj file:
> PROJCS["WGS_1984_Web_Mercator_Auxiliary_Sphere",GEOGCS["GCS_WGS_1984",DATUM["D_WGS_1984",SPHEROID["WGS_1984",6378137.0,298.257223563]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]],PROJECTION["Mercator_Auxiliary_Sphere"],PARAMETER["False_Easting",0.0],PARAMETER["False_Northing",0.0],PARAMETER["Central_Meridian",0.0],PARAMETER["Standard_Parallel_1",0.0],PARAMETER["Auxiliary_Sphere_Type",0.0],UNIT["Meter",1.0]]
> 
> Thanks so much for your help.
> 

When I replace the .prj file of an arbitrary shapefile with these
contents, it gets read well. Have you tried with current R (3.2.4) and
rgdal (1.1.7)?
-- 
Edzer Pebesma
Institute for Geoinformatics  (ifgi),  University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160406/8c354da4/attachment.bin>

From vinhdizzo at gmail.com  Wed Apr  6 22:36:48 2016
From: vinhdizzo at gmail.com (Vinh Nguyen)
Date: Wed, 6 Apr 2016 13:36:48 -0700
Subject: [R-sig-Geo] readOGR not reading in prj file?
In-Reply-To: <57054A6E.6050803@uni-muenster.de>
References: <CA+2DmwgWq6B_gt14tvcZsTNi+6qG-11b5Vu1D4WHv1_L+7vo4Q@mail.gmail.com>
	<1738369436.203731.1459958320211.JavaMail.yahoo@mail.yahoo.com>
	<CA+2Dmwja1gg7USuchgVfV4FGvFjesDh6mBKA5ET2J3E00TCaGg@mail.gmail.com>
	<570546F7.6050501@uni-muenster.de>
	<CA+2DmwjsTdvYk+0UZiYFjbfFga5m2b0cf8usK5rvKLigbEAiyA@mail.gmail.com>
	<57054A6E.6050803@uni-muenster.de>
Message-ID: <CA+2DmwjXKYeuFegQ7JdS8kRDd7nM+KB9sSG5JoF7Pe4uAE5r0w@mail.gmail.com>

On Wed, Apr 6, 2016 at 10:42 AM, Edzer Pebesma
<edzer.pebesma at uni-muenster.de> wrote:
> When I replace the .prj file of an arbitrary shapefile with these
> contents, it gets read well. Have you tried with current R (3.2.4) and
> rgdal (1.1.7)?


Thanks Edzer, upgrading rgdal to 1.1.8 works.  Consider this issue close.

-- Vinh


From r.turner at auckland.ac.nz  Thu Apr  7 05:11:20 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 7 Apr 2016 15:11:20 +1200
Subject: [R-sig-Geo] [FORGED]  different models
In-Reply-To: <CAJ3XaKd=t2=jjZPqfwKFSaay=oKX4_3QEx5GwQeFFqzmWn_Mzg@mail.gmail.com>
References: <CAJ3XaKd=t2=jjZPqfwKFSaay=oKX4_3QEx5GwQeFFqzmWn_Mzg@mail.gmail.com>
Message-ID: <5705CFD8.3020700@auckland.ac.nz>

On 06/04/16 22:00, Virginia Morera Pujol wrote:
> Hi all,
>
> This might be a very dumb question that shows I have very little idea of
> what I am talking about, but I'll risk it:
>
> What is the difference between fitting a model using these 3 different
> syntaxes?
>
> 1/ fit1 <- ppm(ppp, ~covariate),
> 2/ fit2 <- ppm(ppp, ~x+y+Z, covariates=list(Z=covariate))
> 3/ fit3 <- ppm(ppp, ~x+y+covariate)
>
> where ppp is my point pattern and "covariate" is a pixel image? I realise
> the outputs of 2 and 3 are the same and different to that of 1, so I guess
> the question really is
>
> a/ Is there any difference, practical or in the actual computations of the
> model, between using 2 and 3?
> b/ What is the difference between (2&3) and 1?

(1) There is essentially no difference between fits 2 & 3.  The fit 2 
syntax is provided so that the user can have the relevant covariates 
bundled up in a list without any need to extract these covariates from 
that list.   With the fit 2 syntax you don't need to have all covariates 
present in your workspace.

E.g.: fit <- ppm(bei ~ elev + grad, data=bei.extra)

(2) The fit 2 syntax is essentially the same as that used by lm() and 
glm() and was designed in imitation thereof.

(3) The preferred structure of a call to ppm() is

     fit2 <- ppm(ppp ~ x + y + Z, data=list(Z=covariate))

Note:  "data" rather than "covariates"; no comma between the name of the 
response variable ("ppp") and the formula.

This makes the syntax identical to that of lm() and glm().

The syntax that you used is a remnant of earlier versions of spatstat 
and remains acceptable for reasons of backward compatibility.

(4) The difference between model 1 and models 2 and 3 is that models 2 
and 3 involve the Cartesian coordinates "x" and "y".  Model 1 is such 
that the model intensity takes the form

    exp(beta_0 + beta_1 * covariate)

In models 2 and 3 the model intensity takes the (more complex) form

    exp(beta_0 + beta_1 * x + beta_2 *y beta_3 * covariate)

Note that "x" and "y" are *reserved* names.  You cannot use these names 
for any covariates *other than* the Cartesian coordinates.

(5) The name "covariate" is probably *not* a good name for a covariate.
As fortune(77) puts it "Would you call your dog 'dog'?"

(6) Likewise (and even more so) "ppp" is *not* a good name for a point 
pattern, since it clashes the name of the creator function ppp().

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From morera.virginia at gmail.com  Thu Apr  7 09:52:14 2016
From: morera.virginia at gmail.com (Virginia Morera Pujol)
Date: Thu, 7 Apr 2016 09:52:14 +0200
Subject: [R-sig-Geo] [FORGED]  different models
In-Reply-To: <5705CFD8.3020700@auckland.ac.nz>
References: <CAJ3XaKd=t2=jjZPqfwKFSaay=oKX4_3QEx5GwQeFFqzmWn_Mzg@mail.gmail.com>
	<5705CFD8.3020700@auckland.ac.nz>
Message-ID: <CAJ3XaKde+_=h3JbsZf012BZEZ7Ugz0jqtp+aNZdN6oLN8nbO4Q@mail.gmail.com>

Hi Rolf,

Thank you for your very complete response. If I understand it correctly
then, I should just include the Cartesian coordinates in my covariates list
if I want to model the intensity specifically in relation to them as well
as the covariates, correct?

Oh, and just for clarification, I do not name my point patterns "ppp" and
my covariates "covariate" (although I kind of like the idea of calling my
dog "dog"). I was just trying to make a general example, but thanks for the
heads up anyway!

Best,

Virginia Morera
PhD Student
Department of Animal Biology
University of Barcelona

Aquest correu electr?nic i els annexos poden contenir informaci?
confidencial o protegida legalment i est? adre?at exclusivament a la
persona o entitat destinat?ria. Si no sou  el destinatari final o la
persona encarregada de rebre?l, no esteu autoritzat a llegir-lo,
retenir-lo, modificar-lo, distribuir-lo, copiar-lo ni a revelar-ne el
contingut. Si heu rebut aquest correu electr?nic per error, us preguem que
n?informeu al remitent i que elimineu del sistema el missatge i el material
annex que pugui contenir. Gr?cies per la vostra col?laboraci?.

Este correo electr?nico y sus anexos pueden contener informaci?n
confidencial o legalmente protegida y est? exclusivamente dirigido a la
persona o entidad destinataria. Si usted no es el destinatario final o la
persona encargada de recibirlo, no est? autorizado a leerlo, retenerlo,
modificarlo, distribuirlo, copiarlo ni a revelar su contenido. Si ha
recibido este mensaje electr?nico por error, le rogamos que informe al
remitente y elimine del sistema el mensaje y el material anexo que pueda
contener. Gracias por su colaboraci?n.

This email message and any documents attached to it may contain
confidential or legally protected material and are intended solely for the
use of the individual or organization to whom they are addressed. We remind
you that if you are not the intended recipient of this email message or the
person responsible for processing it, then you are not authorized to read,
save, modify, send, copy or disclose any of its contents. If you have
received this email message by mistake, we kindly ask you to inform the
sender of this and to eliminate both the message and any attachments it
carries from your account.Thank you for your collaboration.

2016-04-07 5:11 GMT+02:00 Rolf Turner <r.turner at auckland.ac.nz>:

> On 06/04/16 22:00, Virginia Morera Pujol wrote:
>
>> Hi all,
>>
>> This might be a very dumb question that shows I have very little idea of
>> what I am talking about, but I'll risk it:
>>
>> What is the difference between fitting a model using these 3 different
>> syntaxes?
>>
>> 1/ fit1 <- ppm(ppp, ~covariate),
>> 2/ fit2 <- ppm(ppp, ~x+y+Z, covariates=list(Z=covariate))
>> 3/ fit3 <- ppm(ppp, ~x+y+covariate)
>>
>> where ppp is my point pattern and "covariate" is a pixel image? I realise
>> the outputs of 2 and 3 are the same and different to that of 1, so I guess
>> the question really is
>>
>> a/ Is there any difference, practical or in the actual computations of the
>> model, between using 2 and 3?
>> b/ What is the difference between (2&3) and 1?
>>
>
> (1) There is essentially no difference between fits 2 & 3.  The fit 2
> syntax is provided so that the user can have the relevant covariates
> bundled up in a list without any need to extract these covariates from that
> list.   With the fit 2 syntax you don't need to have all covariates present
> in your workspace.
>
> E.g.: fit <- ppm(bei ~ elev + grad, data=bei.extra)
>
> (2) The fit 2 syntax is essentially the same as that used by lm() and
> glm() and was designed in imitation thereof.
>
> (3) The preferred structure of a call to ppm() is
>
>     fit2 <- ppm(ppp ~ x + y + Z, data=list(Z=covariate))
>
> Note:  "data" rather than "covariates"; no comma between the name of the
> response variable ("ppp") and the formula.
>
> This makes the syntax identical to that of lm() and glm().
>
> The syntax that you used is a remnant of earlier versions of spatstat and
> remains acceptable for reasons of backward compatibility.
>
> (4) The difference between model 1 and models 2 and 3 is that models 2 and
> 3 involve the Cartesian coordinates "x" and "y".  Model 1 is such that the
> model intensity takes the form
>
>    exp(beta_0 + beta_1 * covariate)
>
> In models 2 and 3 the model intensity takes the (more complex) form
>
>    exp(beta_0 + beta_1 * x + beta_2 *y beta_3 * covariate)
>
> Note that "x" and "y" are *reserved* names.  You cannot use these names
> for any covariates *other than* the Cartesian coordinates.
>
> (5) The name "covariate" is probably *not* a good name for a covariate.
> As fortune(77) puts it "Would you call your dog 'dog'?"
>
> (6) Likewise (and even more so) "ppp" is *not* a good name for a point
> pattern, since it clashes the name of the creator function ppp().
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Thu Apr  7 09:57:08 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 7 Apr 2016 09:57:08 +0200
Subject: [R-sig-Geo] readOGR not reading in prj file?
In-Reply-To: <CA+2DmwjXKYeuFegQ7JdS8kRDd7nM+KB9sSG5JoF7Pe4uAE5r0w@mail.gmail.com>
References: <CA+2DmwgWq6B_gt14tvcZsTNi+6qG-11b5Vu1D4WHv1_L+7vo4Q@mail.gmail.com>
	<1738369436.203731.1459958320211.JavaMail.yahoo@mail.yahoo.com>
	<CA+2Dmwja1gg7USuchgVfV4FGvFjesDh6mBKA5ET2J3E00TCaGg@mail.gmail.com>
	<570546F7.6050501@uni-muenster.de>
	<CA+2DmwjsTdvYk+0UZiYFjbfFga5m2b0cf8usK5rvKLigbEAiyA@mail.gmail.com>
	<57054A6E.6050803@uni-muenster.de>
	<CA+2DmwjXKYeuFegQ7JdS8kRDd7nM+KB9sSG5JoF7Pe4uAE5r0w@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1604070954120.3027@reclus.nhh.no>

On Wed, 6 Apr 2016, Vinh Nguyen wrote:

> On Wed, Apr 6, 2016 at 10:42 AM, Edzer Pebesma
> <edzer.pebesma at uni-muenster.de> wrote:
>> When I replace the .prj file of an arbitrary shapefile with these
>> contents, it gets read well. Have you tried with current R (3.2.4) and
>> rgdal (1.1.7)?
>
>
> Thanks Edzer, upgrading rgdal to 1.1.8 works.  Consider this issue close.

For completeness, which OS was this, and how was GDAL installed - do you 
recall what GDAL version was reported when rgdal loaded?

If Windows CRAN binary, it is possible that the underlying GDAL version of 
the spatial reference code and EPSG databases changed - there were no 
relevant changes in rgdal itself, I think.

Roger

>
> -- Vinh
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


From jo.lists at gmail.com  Thu Apr  7 11:47:15 2016
From: jo.lists at gmail.com (JiHO)
Date: Thu, 7 Apr 2016 11:47:15 +0200
Subject: [R-sig-Geo] Regionalisation of a large raster (a way to speed up
	spdep::skater?)
Message-ID: <CAKhbdUaRkzxAxVP5n2aPxPgg-vGBEzhp8MRTdGtdCeZRbPh4RQ@mail.gmail.com>

Hi everyone,

I want to perform regionalisation (i.e. spatially constrained
clustering) of a raster grid. The raster rectangle has ~90,000 pixels.
In it, I am only interested in a region within a specific, somewhat
convoluted, shape (i.e. the sea pixels, excluding land) which
represents ~35,000 pixels.

I have been able to convert pixels to polygons and remove a few odd
bits in order to compute a neighbourhood list representing one fully
connected graph, with spdep::poly2nb (there is probably a more clever
way for a large regular grid but this works reasonably quickly). From
it, I have computed the weights (based on 46 variables measured in
each pixel) and the minimum spanning tree. And then I fed this MST and
data to spdep::skater, and asked to resolve 7 clusters (number based
on a priori knowledge). It's been running for ~10 hours on 12 cores
(on Xeon CPUs at 3.40GHz), each eating up to 5GB of RAM, and I have no
idea if it is any close to finishing.

Eventually, I'll want to resolve from 5 to 12 clusters and compute
some a posteriori metrics to decide on the ideal number of clusters. I
can dedicate a few more cores but that will not be enough to speed it
up significantly.

Is there any clever way to speed spdep::skater up, that would maybe
exploit the fact that I am working on a regular grid?

I've thought about computing 100 to 200 clusters using regular k-means
(or pam) and then consider those as input polygons to skater but many
clusters end up as pixels scattered all over the place.
I've considered adding lat and lon to the data fed to the k-means at
this preliminary step to force spatial contiguity, but that becomes a
bit difficult to justify cleanly in a methods section of a paper, and
does not really work (regions are still scattered locally).
Of course I could reduce the resolution of the original data but that
would be a shame.
Finally, I've thought about:
1- run skater on low resolution data (few, large pixels)
2- group the central (large) pixels of each region as a polygon and
break appart pixels on the border into smaller pixels
3- compute average characteristics on these new pixels
4- re-run skater with large central polygons intact and smaller
pixel-polygons on the borders
and repeat this until the borders are well defined
But this involves quite a bit of coding and I am not really sure how
representative the mean characteristics would be for each large area.
Before embarking on this, I wanted to check whether another solution
existed.

Does anyone have experience with ClusterPy
http://www.rise-group.org/risem/clusterpy/, especially in terms of
speed? And in terms of which algorithm resembles skater most? or is
most robust? (I understand the concepts behind skater, I'm not
confident with the others).

Thank you in advance. Sincerely,

Jean-Olivier Irisson
?
Universit? Pierre et Marie Curie
Laboratoire d'Oc?anographie de Villefranche
2 Quai de la Corderie, 06230 Villefranche-sur-Mer
Tel: +33 04 93 76 38 04
Mob: +33 06 21 05 19 90
http://www.obs-vlfr.fr/~irisson/
Send me large files at: http://www.obs-vlfr.fr/~irisson/upload/


From r.turner at auckland.ac.nz  Thu Apr  7 12:02:54 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 7 Apr 2016 22:02:54 +1200
Subject: [R-sig-Geo] [FORGED]  different models
In-Reply-To: <CAJ3XaKde+_=h3JbsZf012BZEZ7Ugz0jqtp+aNZdN6oLN8nbO4Q@mail.gmail.com>
References: <CAJ3XaKd=t2=jjZPqfwKFSaay=oKX4_3QEx5GwQeFFqzmWn_Mzg@mail.gmail.com>
	<5705CFD8.3020700@auckland.ac.nz>
	<CAJ3XaKde+_=h3JbsZf012BZEZ7Ugz0jqtp+aNZdN6oLN8nbO4Q@mail.gmail.com>
Message-ID: <5706304E.2070700@auckland.ac.nz>

On 07/04/16 19:52, Virginia Morera Pujol wrote:
> Hi Rolf,
>
> Thank you for your very complete response. If I understand it correctly
> then, I should just include the Cartesian coordinates in my covariates
> list if I want to model the intensity specifically in relation to them
> as well as the covariates, correct?

Well, in a word, yes.  Dunno what more I can say without inducing 
obfuscation instead of clarification (of what is actually a simple issue.)

The best way to get an understanding of what is involved, IMHO, is to do 
some experimentation.  Fit some models to some data, plot the fitted 
surfaces (either as image plots or perspective plots) and see what the 
results look like.

<SNIP>

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From adrian.baddeley at curtin.edu.au  Thu Apr  7 13:05:36 2016
From: adrian.baddeley at curtin.edu.au (Adrian Baddeley)
Date: Thu, 7 Apr 2016 11:05:36 +0000
Subject: [R-sig-Geo]  different models
In-Reply-To: <HK2PR02MB1459DBAD9919F695625B1532A4900@HK2PR02MB1459.apcprd02.prod.outlook.com>
References: <CAJ3XaKd=t2=jjZPqfwKFSaay=oKX4_3QEx5GwQeFFqzmWn_Mzg@mail.gmail.com>
	<5705CFD8.3020700@auckland.ac.nz>
	<CAJ3XaKde+_=h3JbsZf012BZEZ7Ugz0jqtp+aNZdN6oLN8nbO4Q@mail.gmail.com>,
	<5706304E.2070700@auckland.ac.nz>,
	<HK2PR02MB1459DBAD9919F695625B1532A4900@HK2PR02MB1459.apcprd02.prod.outlook.com>
Message-ID: <HK2PR02MB14591EE7FC303411B0CCE930A4900@HK2PR02MB1459.apcprd02.prod.outlook.com>

Please read chapter 9 of the spatstat book for a detailed explanation of what the model formulas mean (and what they don't mean). You can download this chapter for free from the companion website <spatstat.github.io/book/>

Adrian

Prof Adrian Baddeley DSc FAA
Department of Mathematics and Statistics
Curtin University, Perth, Western Australia


From morera.virginia at gmail.com  Thu Apr  7 13:08:27 2016
From: morera.virginia at gmail.com (Virginia Morera Pujol)
Date: Thu, 7 Apr 2016 13:08:27 +0200
Subject: [R-sig-Geo] different models
In-Reply-To: <HK2PR02MB14591EE7FC303411B0CCE930A4900@HK2PR02MB1459.apcprd02.prod.outlook.com>
References: <CAJ3XaKd=t2=jjZPqfwKFSaay=oKX4_3QEx5GwQeFFqzmWn_Mzg@mail.gmail.com>
	<5705CFD8.3020700@auckland.ac.nz>
	<CAJ3XaKde+_=h3JbsZf012BZEZ7Ugz0jqtp+aNZdN6oLN8nbO4Q@mail.gmail.com>
	<5706304E.2070700@auckland.ac.nz>
	<HK2PR02MB1459DBAD9919F695625B1532A4900@HK2PR02MB1459.apcprd02.prod.outlook.com>
	<HK2PR02MB14591EE7FC303411B0CCE930A4900@HK2PR02MB1459.apcprd02.prod.outlook.com>
Message-ID: <CAJ3XaKdQFTcZGVYPn25x_CGX1eGz3OQgYvMuYoFJgBry=H5v2A@mail.gmail.com>

Thank you very much both, Adrian and Rolf,

I will most certainly check that chapter out.



Virginia Morera
PhD Student
Department of Animal Biology
University of Barcelona

Aquest correu electr?nic i els annexos poden contenir informaci?
confidencial o protegida legalment i est? adre?at exclusivament a la
persona o entitat destinat?ria. Si no sou  el destinatari final o la
persona encarregada de rebre?l, no esteu autoritzat a llegir-lo,
retenir-lo, modificar-lo, distribuir-lo, copiar-lo ni a revelar-ne el
contingut. Si heu rebut aquest correu electr?nic per error, us preguem que
n?informeu al remitent i que elimineu del sistema el missatge i el material
annex que pugui contenir. Gr?cies per la vostra col?laboraci?.

Este correo electr?nico y sus anexos pueden contener informaci?n
confidencial o legalmente protegida y est? exclusivamente dirigido a la
persona o entidad destinataria. Si usted no es el destinatario final o la
persona encargada de recibirlo, no est? autorizado a leerlo, retenerlo,
modificarlo, distribuirlo, copiarlo ni a revelar su contenido. Si ha
recibido este mensaje electr?nico por error, le rogamos que informe al
remitente y elimine del sistema el mensaje y el material anexo que pueda
contener. Gracias por su colaboraci?n.

This email message and any documents attached to it may contain
confidential or legally protected material and are intended solely for the
use of the individual or organization to whom they are addressed. We remind
you that if you are not the intended recipient of this email message or the
person responsible for processing it, then you are not authorized to read,
save, modify, send, copy or disclose any of its contents. If you have
received this email message by mistake, we kindly ask you to inform the
sender of this and to eliminate both the message and any attachments it
carries from your account.Thank you for your collaboration.

2016-04-07 13:05 GMT+02:00 Adrian Baddeley <adrian.baddeley at curtin.edu.au>:

> Please read chapter 9 of the spatstat book for a detailed explanation of
> what the model formulas mean (and what they don't mean). You can download
> this chapter for free from the companion website <spatstat.github.io/book/
> >
>
> Adrian
>
> Prof Adrian Baddeley DSc FAA
> Department of Mathematics and Statistics
> Curtin University, Perth, Western Australia
>
>

	[[alternative HTML version deleted]]


From naimi.b at gmail.com  Thu Apr  7 14:00:30 2016
From: naimi.b at gmail.com (Babak Naimi)
Date: Thu, 07 Apr 2016 12:00:30 +0000
Subject: [R-sig-Geo] Null distribution of a categorical variable to test
	local spatial association
Message-ID: <CAGL-CGBBaQ3=VoYMGKmaypu3amQ+k_gvFg4Uns3yMuQdMk=EVw@mail.gmail.com>

Dear list,

I am exploring the solutions to generate a null distribution of a spatial
categorical variable (e.g., land use map). I am going to use the null
distribution in the procedure of testing whether local spatial association
(measured by a new statistics, named ELSA) at each location of the
categorical variable is significant, by simply using a non-parametric
bootstrap randomization approach to test ELSA against the null
distribution. The procedure is as follows:
1- we quantify Ei (ELSA at site i in the original data) at each location;
2- generate the null distribution; 3- using a Monte Carlo simulation with R
runs, we use a bootstrapping procedure through which a sample is drawn from
the null distribution at each run; 4- every time we quantify E*i (ELSA at
site i in the bootstrap sample); 5- test the number of runs that #(Ei >=
E*i) is valid; and finally 6- calculate a pseudo p-value using (1 + #(Ei >=
E*i) ) / (R + 1)
This is a straightforward approach that is also used in significance
testing based on other indices, (e.g., Local Moran's I).

The problem I have is how to generate the null distribution. I know that
the approach has been used in the other studies, is based on shuffling the
spatial locations randomly to get the null distribution, but to me it does
not make sense as it can cause a problem for the cases with uneven
distribution on events (different classes in the categorical maps). For
example, imaging a map with two categories A and B, and the frequency of
class A is 95% of the entire study area while class B can be seen in only
5% of the area. If we shuffle the locations randomly, do we really get a
null distribution of the classes? or the supposedly null distribution has a
high chance of still be spatially autocorrelated for class A?

The solution I figured out so far, is to assume in the null hypothesis that
the events are distributed uniformly and independently in the given
locations, and thus, the null distribution can be constructed by drawing a
sample at each location from the events (m categorical classes: c1....cm)
each having a probability of 1/m.

However, since I am not a statistician, I was wondering if this can be a
right solution. And if so, whether there is a difference between using this
approach for a real categorical variable, or a discretized variable from a
continuous variable.

Your advises would be highly appreciated.

Best regards,
Babak

------------
Babak Naimi
Center for Macroecology, Evolution, and Climate (CMEC),
University of Copenhagen, Denmark
Website: www.r-gis.net

	[[alternative HTML version deleted]]


From maglau at Princeton.EDU  Thu Apr  7 16:24:01 2016
From: maglau at Princeton.EDU (Maggie CY Lau)
Date: Thu, 7 Apr 2016 14:24:01 +0000
Subject: [R-sig-Geo] proj4string error on data.frame generated from NCEP data
Message-ID: <06ABC08E-8837-4010-A2D0-A6A1197571C4@exchange.Princeton.EDU>

HI all,

I am an ecologist who would like to use several datasets generated by NCEP reanalysis. I attempted to use the R package "RNCEP" to extract the data and generate .tiff files. These files will be analyzed by a student using ArcMap. I created the data fame with the information I need, but had problem exporting the data into .tiff file that can be projected in polar stereograph in ArcMap. The use of "+proj=longlat + datum=WGS84" gave the following error message:

Error in `proj4string<-`(`*tmp*`, value = <S4 object of class "CRS">) :
  Geographical CRS given to non-conformant data: 91.25

Then I tried using ""+proj=stere +lat_0=90 +lat_ts=60 +lon_0=0 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs". proj4string went fine but the export tiff appeared as a box image instead of an angular one.

Please kindly check the following codes from the line "library(sp)" onward.

Thanks,
Maggie Lau

====
install.packages("RNCEP", dependencies=TRUE)
install.packages(c('abind', 'maps', 'fields', 'tgp', 'fossil'), dependencies=TRUE)
install.packages("raster")
install.packages("rgdal")

library(RNCEP)
air.sig995.extent <- NCEP.gather(variable='air.sig995', level='surface', months.minmax=c(7),
years.minmax=c(2011), lat.southnorth=c(60,89.9), lon.westeast=c(-179,180),
reanalysis2=FALSE, return.units=TRUE)
air.sig995.ag <- NCEP.aggregate(wx.data=air.sig995.extent, YEARS=TRUE, MONTHS=TRUE,
DAYS=FALSE, HOURS=FALSE, fxn='mean')
dimnames(air.sig995.ag)[[3]][1]
air.sig995.ag.df <- NCEP.array2df(air.sig995.ag[,,1], var.names = 'Temperature')

library(sp)
coordinates(air.sig995.ag.df) <- ~longitude+latitude
gridded(air.sig995.ag.df) <- TRUE
crs <- "+proj=longlat + datum=WGS84"
proj4string(air.sig995.ag.df) <- CRS(crs)
#stere <- "+proj=stere +lat_0=90 +lat_ts=60 +lon_0=0
# +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
#proj4string(air.sig995.ag.df) <- CRS(stere)

library(raster)
ras <- raster(air.sig995.ag.df)
writeRaster(ras, 'air.sig995.Jul.ag.tif', overwrite=TRUE)




	[[alternative HTML version deleted]]


From mestre.frederico at gmail.com  Thu Apr  7 18:36:10 2016
From: mestre.frederico at gmail.com (Frederico Mestre)
Date: Thu, 7 Apr 2016 17:36:10 +0100
Subject: [R-sig-Geo] Error with r.mask through rgrass7
Message-ID: <CAPfBvqyfDagz+hCvSOSX2d+pnhfvKMtpiqWTzOa41FaCERAXnA@mail.gmail.com>

Hello all,

I've got R 3.2.4, GRASS GIS 7.1.svn, and rgrass7 installed.

I've started my GRASS session from R with:

initGRASS(gisBase = "C:/Program Files/GRASS GIS 7.1.svn", home = tempdir(),
override = TRUE)

Then I tried to use r.mask from R and I got the following error:

Error in system(cmd0, intern = TRUE) : 'r.mask.exe' not found
Error in parseGRASS(cmd, legacyExec = legacyExec) : r.mask not found

Anyone can help with this?

Thanks.
Frederico Mestre

	[[alternative HTML version deleted]]


From vinhdizzo at gmail.com  Thu Apr  7 18:51:08 2016
From: vinhdizzo at gmail.com (Vinh Nguyen)
Date: Thu, 7 Apr 2016 09:51:08 -0700
Subject: [R-sig-Geo] readOGR not reading in prj file?
In-Reply-To: <alpine.LFD.2.20.1604070954120.3027@reclus.nhh.no>
References: <CA+2DmwgWq6B_gt14tvcZsTNi+6qG-11b5Vu1D4WHv1_L+7vo4Q@mail.gmail.com>
	<1738369436.203731.1459958320211.JavaMail.yahoo@mail.yahoo.com>
	<CA+2Dmwja1gg7USuchgVfV4FGvFjesDh6mBKA5ET2J3E00TCaGg@mail.gmail.com>
	<570546F7.6050501@uni-muenster.de>
	<CA+2DmwjsTdvYk+0UZiYFjbfFga5m2b0cf8usK5rvKLigbEAiyA@mail.gmail.com>
	<57054A6E.6050803@uni-muenster.de>
	<CA+2DmwjXKYeuFegQ7JdS8kRDd7nM+KB9sSG5JoF7Pe4uAE5r0w@mail.gmail.com>
	<alpine.LFD.2.20.1604070954120.3027@reclus.nhh.no>
Message-ID: <CA+2DmwiO=PgLBNg6Xrtxn3dmEfG+TFN5s8J_n+UfSfPLevJWAw@mail.gmail.com>

On Apr 7, 2016 12:58 AM, "Roger Bivand" <Roger.Bivand at nhh.no> wrote:
>
> On Wed, 6 Apr 2016, Vinh Nguyen wrote:
>
>> On Wed, Apr 6, 2016 at 10:42 AM, Edzer Pebesma
>> <edzer.pebesma at uni-muenster.de> wrote:
>>>
>>> When I replace the .prj file of an arbitrary shapefile with these
>>> contents, it gets read well. Have you tried with current R (3.2.4) and
>>> rgdal (1.1.7)?
>>
>>
>>
>> Thanks Edzer, upgrading rgdal to 1.1.8 works.  Consider this issue close.
>
>
> For completeness, which OS was this, and how was GDAL installed - do you
recall what GDAL version was reported when rgdal loaded?
>
> If Windows CRAN binary, it is possible that the underlying GDAL version
of the spatial reference code and EPSG databases changed - there were no
relevant changes in rgdal itself, I think.
>

Windows. I don't have the log with gdal version. Your assessment is
probably correct. Thanks.

	[[alternative HTML version deleted]]


From jstachel at sfwmd.gov  Thu Apr  7 19:24:05 2016
From: jstachel at sfwmd.gov (Stachelek, Joseph)
Date: Thu, 7 Apr 2016 17:24:05 +0000
Subject: [R-sig-Geo] unionSpatialPolygons from the command-line
Message-ID: <D51374C4B889BC47B3C5286047C86DA1A02C06A4@whqembx03p.ad.sfwmd.gov>

Hello,

I am trying to call "maptools::unionSpatialPolygons()" from the command-line. To illustrate the problem, I can call example(unionSpatialPolygons) from an interactive session but running an R script (testmaptools.R) containing:

`library(maptools)`
`example(unionSpatialPolygons)`

yields:

`$ Rscript testmaptools.R`
> WARNING: ignoring environment value of R_HOME
> Loading required package: sp
> Checking rgeos availability: TRUE

> unnSpP> if (rgeosStatus()) {
> unnSpP+ nc1 <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1],
> unnSpP+  proj4string=CRS("+proj=longlat +datum=NAD27"))
> unnSpP+ lps <- coordinates(nc1)
> unnSpP+ ID <- cut(lps[,1], quantile(lps[,1]), include.lowest=TRUE)
> unnSpP+ reg4 <- unionSpatialPolygons(nc1, ID)
> unnSpP+ row.names(reg4)
> unnSpP+ }
> Error in rgeos::gUnaryUnion(spgeom = SpP, id = IDs) :
>   Invalid geometry, may only be applied to polygons
> Calls: example ... eval -> eval -> unionSpatialPolygons -> <Anonymous>
> Execution halted

Is this not possible?

Thank you,

Joseph Stachelek


We value your opinion. Please take a few minutes to shar...{{dropped:8}}


From frtog at vestas.com  Fri Apr  8 08:50:13 2016
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Fri, 8 Apr 2016 06:50:13 +0000
Subject: [R-sig-Geo] FW: proj4string error on data.frame generated from NCEP
	data
References: <06ABC08E-8837-4010-A2D0-A6A1197571C4@exchange.Princeton.EDU>  
Message-ID: <HE1PR04MB12768868B967B476105FB16ADB910@HE1PR04MB1276.eurprd04.prod.outlook.com>

Reposting again again without data. So fetch the data yourself :-(

Yours sincerely / Med venlig hilsen

Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 



-----Original Message-----
From: Frede Aakmann T?gersen 
Sent: 8. april 2016 08:46
To: Maggie CY Lau (maglau at princeton.edu)
Cc: r-sig-geo at r-project.org
Subject: FW: proj4string error on data.frame generated from NCEP data

Reposting without attachments.

Yours sincerely / Med venlig hilsen

Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 



-----Original Message-----
From: Frede Aakmann T?gersen 
Sent: 8. april 2016 08:01
To: 'Maggie CY Lau'; r-sig-geo at r-project.org
Subject: RE: proj4string error on data.frame generated from NCEP data

Hi Maggie

Your error message says that there is some coordinates with latitudes above 90 degrees.

The problem seems to arise from the call to gridded. See below for a dput'ed version of the dataframe "air.sig995.ag.df" called "friend" in my code. This is what I found out:

> coordinates(friend) <- ~longitude+latitude
> bbox(friend)
             min max
longitude -177.5 180
latitude    60.0  90
> apply(coordinates(friend), 2, range)
     longitude latitude
[1,]    -177.5       60
[2,]     180.0       90

After using gridded() the bounding box is enlarged somewhat but the coordinates still unchanged.

> gridded(friend) <- TRUE
> bbox(friend)
              min    max
longitude -178.75 181.25
latitude    58.75  91.25
> apply(coordinates(friend), 2, range)
     longitude latitude
[1,]    -177.5       60
[2,]     180.0       90
>

If you leave out the gridded() part I guess you can proceed towards your goal. Here I did:

## this was okay
> crs <- "+proj=longlat +datum=WGS84"
> proj4string(friend) <- crs

## see attached plot
> png("longlat.png")
> plot(friend)
> dev.off()

Do a reprojection with spTransform():

> stere <- "+proj=stere +lat_0=90 +lat_ts=60 +lon_0=0 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
> friend.stere <- spTransform(friend, CRS(stere))

And the plot is attached:

> png("stere.png")
> plot(friend.stere)
> dev.off()
X11cairo 

Why gridded() is extending domain outside permissible values for longitude and latitude I don't know.

\Frede

##### friend is a copy of air.sig995.ag.df <- NCEP.array2df(air.sig995.ag[,,1], var.names = 'Temperature')

## DELETED

Yours sincerely / Med venlig hilsen

Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 



-----Original Message-----
From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Maggie CY Lau
Sent: 7. april 2016 16:24
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] proj4string error on data.frame generated from NCEP data

HI all,

I am an ecologist who would like to use several datasets generated by NCEP reanalysis. I attempted to use the R package "RNCEP" to extract the data and generate .tiff files. These files will be analyzed by a student using ArcMap. I created the data fame with the information I need, but had problem exporting the data into .tiff file that can be projected in polar stereograph in ArcMap. The use of "+proj=longlat + datum=WGS84" gave the following error message:

Error in `proj4string<-`(`*tmp*`, value = <S4 object of class "CRS">) :
  Geographical CRS given to non-conformant data: 91.25

Then I tried using ""+proj=stere +lat_0=90 +lat_ts=60 +lon_0=0 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs". proj4string went fine but the export tiff appeared as a box image instead of an angular one.

Please kindly check the following codes from the line "library(sp)" onward.

Thanks,
Maggie Lau

====
install.packages("RNCEP", dependencies=TRUE)
install.packages(c('abind', 'maps', 'fields', 'tgp', 'fossil'), dependencies=TRUE)
install.packages("raster")
install.packages("rgdal")

library(RNCEP)
air.sig995.extent <- NCEP.gather(variable='air.sig995', level='surface', months.minmax=c(7),
years.minmax=c(2011), lat.southnorth=c(60,89.9), lon.westeast=c(-179,180),
reanalysis2=FALSE, return.units=TRUE)
air.sig995.ag <- NCEP.aggregate(wx.data=air.sig995.extent, YEARS=TRUE, MONTHS=TRUE,
DAYS=FALSE, HOURS=FALSE, fxn='mean')
dimnames(air.sig995.ag)[[3]][1]
air.sig995.ag.df <- NCEP.array2df(air.sig995.ag[,,1], var.names = 'Temperature')

library(sp)
coordinates(air.sig995.ag.df) <- ~longitude+latitude
gridded(air.sig995.ag.df) <- TRUE
crs <- "+proj=longlat + datum=WGS84"
proj4string(air.sig995.ag.df) <- CRS(crs)
#stere <- "+proj=stere +lat_0=90 +lat_ts=60 +lon_0=0
# +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
#proj4string(air.sig995.ag.df) <- CRS(stere)

library(raster)
ras <- raster(air.sig995.ag.df)
writeRaster(ras, 'air.sig995.Jul.ag.tif', overwrite=TRUE)




	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From loic.dutrieux at wur.nl  Fri Apr  8 11:42:18 2016
From: loic.dutrieux at wur.nl (=?UTF-8?Q?Lo=c3=afc_Dutrieux?=)
Date: Fri, 8 Apr 2016 11:42:18 +0200
Subject: [R-sig-Geo] FW: proj4string error on data.frame generated from
 NCEP data
In-Reply-To: <HE1PR04MB12768868B967B476105FB16ADB910@HE1PR04MB1276.eurprd04.prod.outlook.com>
References: <06ABC08E-8837-4010-A2D0-A6A1197571C4@exchange.Princeton.EDU>
	<HE1PR04MB12768868B967B476105FB16ADB910@HE1PR04MB1276.eurprd04.prod.outlook.com>
Message-ID: <57077CFA.80003@wur.nl>



On 04/08/2016 08:50 AM, Frede Aakmann T?gersen wrote:
> Reposting again again without data. So fetch the data yourself :-(
>
> Yours sincerely / Med venlig hilsen
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>
>
> -----Original Message-----
> From: Frede Aakmann T?gersen
> Sent: 8. april 2016 08:46
> To: Maggie CY Lau (maglau at princeton.edu)
> Cc: r-sig-geo at r-project.org
> Subject: FW: proj4string error on data.frame generated from NCEP data
>
> Reposting without attachments.
>
> Yours sincerely / Med venlig hilsen
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>
>
> -----Original Message-----
> From: Frede Aakmann T?gersen
> Sent: 8. april 2016 08:01
> To: 'Maggie CY Lau'; r-sig-geo at r-project.org
> Subject: RE: proj4string error on data.frame generated from NCEP data
>
> Hi Maggie
>
> Your error message says that there is some coordinates with latitudes above 90 degrees.
>
> The problem seems to arise from the call to gridded. See below for a dput'ed version of the dataframe "air.sig995.ag.df" called "friend" in my code. This is what I found out:
>
>> coordinates(friend) <- ~longitude+latitude
>> bbox(friend)
>               min max
> longitude -177.5 180
> latitude    60.0  90
>> apply(coordinates(friend), 2, range)
>       longitude latitude
> [1,]    -177.5       60
> [2,]     180.0       90
>
> After using gridded() the bounding box is enlarged somewhat but the coordinates still unchanged.
>
>> gridded(friend) <- TRUE
>> bbox(friend)
>                min    max
> longitude -178.75 181.25
> latitude    58.75  91.25
>> apply(coordinates(friend), 2, range)
>       longitude latitude
> [1,]    -177.5       60
> [2,]     180.0       90
>>
>
> If you leave out the gridded() part I guess you can proceed towards your goal. Here I did:
>
> ## this was okay
>> crs <- "+proj=longlat +datum=WGS84"
>> proj4string(friend) <- crs
>
> ## see attached plot
>> png("longlat.png")
>> plot(friend)
>> dev.off()
>
> Do a reprojection with spTransform():
>
>> stere <- "+proj=stere +lat_0=90 +lat_ts=60 +lon_0=0 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
>> friend.stere <- spTransform(friend, CRS(stere))
>
> And the plot is attached:
>
>> png("stere.png")
>> plot(friend.stere)
>> dev.off()
> X11cairo
>
> Why gridded() is extending domain outside permissible values for longitude and latitude I don't know.

My guess is that gridded assumes coordinates provided correspond to 
pixels centers, while top-left coordinates are provided.

Cheers,
Lo?c

>
> \Frede
>
> ##### friend is a copy of air.sig995.ag.df <- NCEP.array2df(air.sig995.ag[,,1], var.names = 'Temperature')
>
> ## DELETED
>
> Yours sincerely / Med venlig hilsen
>
> Frede Aakmann T?gersen
> Specialist, M.Sc., Ph.D.
> Plant Performance & Modeling
>
> Technology & Service Solutions
> T +45 9730 5135
> M +45 2547 6050
> frtog at vestas.com
> http://www.vestas.com
>
> Company reg. name: Vestas Wind Systems A/S
> This e-mail is subject to our e-mail disclaimer statement.
> Please refer to www.vestas.com/legal/notice
> If you have received this e-mail in error please contact the sender.
>
>
>
> -----Original Message-----
> From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Maggie CY Lau
> Sent: 7. april 2016 16:24
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] proj4string error on data.frame generated from NCEP data
>
> HI all,
>
> I am an ecologist who would like to use several datasets generated by NCEP reanalysis. I attempted to use the R package "RNCEP" to extract the data and generate .tiff files. These files will be analyzed by a student using ArcMap. I created the data fame with the information I need, but had problem exporting the data into .tiff file that can be projected in polar stereograph in ArcMap. The use of "+proj=longlat + datum=WGS84" gave the following error message:
>
> Error in `proj4string<-`(`*tmp*`, value = <S4 object of class "CRS">) :
>    Geographical CRS given to non-conformant data: 91.25
>
> Then I tried using ""+proj=stere +lat_0=90 +lat_ts=60 +lon_0=0 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs". proj4string went fine but the export tiff appeared as a box image instead of an angular one.
>
> Please kindly check the following codes from the line "library(sp)" onward.
>
> Thanks,
> Maggie Lau
>
> ====
> install.packages("RNCEP", dependencies=TRUE)
> install.packages(c('abind', 'maps', 'fields', 'tgp', 'fossil'), dependencies=TRUE)
> install.packages("raster")
> install.packages("rgdal")
>
> library(RNCEP)
> air.sig995.extent <- NCEP.gather(variable='air.sig995', level='surface', months.minmax=c(7),
> years.minmax=c(2011), lat.southnorth=c(60,89.9), lon.westeast=c(-179,180),
> reanalysis2=FALSE, return.units=TRUE)
> air.sig995.ag <- NCEP.aggregate(wx.data=air.sig995.extent, YEARS=TRUE, MONTHS=TRUE,
> DAYS=FALSE, HOURS=FALSE, fxn='mean')
> dimnames(air.sig995.ag)[[3]][1]
> air.sig995.ag.df <- NCEP.array2df(air.sig995.ag[,,1], var.names = 'Temperature')
>
> library(sp)
> coordinates(air.sig995.ag.df) <- ~longitude+latitude
> gridded(air.sig995.ag.df) <- TRUE
> crs <- "+proj=longlat + datum=WGS84"
> proj4string(air.sig995.ag.df) <- CRS(crs)
> #stere <- "+proj=stere +lat_0=90 +lat_ts=60 +lon_0=0
> # +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
> #proj4string(air.sig995.ag.df) <- CRS(stere)
>
> library(raster)
> ras <- raster(air.sig995.ag.df)
> writeRaster(ras, 'air.sig995.Jul.ag.tif', overwrite=TRUE)
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From edzer.pebesma at uni-muenster.de  Fri Apr  8 12:01:29 2016
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 8 Apr 2016 12:01:29 +0200
Subject: [R-sig-Geo] FW: proj4string error on data.frame generated from
 NCEP data
In-Reply-To: <57077CFA.80003@wur.nl>
References: <06ABC08E-8837-4010-A2D0-A6A1197571C4@exchange.Princeton.EDU>
	<HE1PR04MB12768868B967B476105FB16ADB910@HE1PR04MB1276.eurprd04.prod.outlook.com>
	<57077CFA.80003@wur.nl>
Message-ID: <57078179.2010405@uni-muenster.de>



On 08/04/16 11:42, Lo?c Dutrieux wrote:
> 
> 
> On 04/08/2016 08:50 AM, Frede Aakmann T?gersen wrote:
>> Reposting again again without data. So fetch the data yourself :-(
>>
>> Yours sincerely / Med venlig hilsen
>>
>> Frede Aakmann T?gersen
>> Specialist, M.Sc., Ph.D.
>> Plant Performance & Modeling
>>
>> Technology & Service Solutions
>> T +45 9730 5135
>> M +45 2547 6050
>> frtog at vestas.com
>> http://www.vestas.com
>>
>> Company reg. name: Vestas Wind Systems A/S
>> This e-mail is subject to our e-mail disclaimer statement.
>> Please refer to www.vestas.com/legal/notice
>> If you have received this e-mail in error please contact the sender.
>>
>>
>>
>> -----Original Message-----
>> From: Frede Aakmann T?gersen
>> Sent: 8. april 2016 08:46
>> To: Maggie CY Lau (maglau at princeton.edu)
>> Cc: r-sig-geo at r-project.org
>> Subject: FW: proj4string error on data.frame generated from NCEP data
>>
>> Reposting without attachments.
>>
>> Yours sincerely / Med venlig hilsen
>>
>> Frede Aakmann T?gersen
>> Specialist, M.Sc., Ph.D.
>> Plant Performance & Modeling
>>
>> Technology & Service Solutions
>> T +45 9730 5135
>> M +45 2547 6050
>> frtog at vestas.com
>> http://www.vestas.com
>>
>> Company reg. name: Vestas Wind Systems A/S
>> This e-mail is subject to our e-mail disclaimer statement.
>> Please refer to www.vestas.com/legal/notice
>> If you have received this e-mail in error please contact the sender.
>>
>>
>>
>> -----Original Message-----
>> From: Frede Aakmann T?gersen
>> Sent: 8. april 2016 08:01
>> To: 'Maggie CY Lau'; r-sig-geo at r-project.org
>> Subject: RE: proj4string error on data.frame generated from NCEP data
>>
>> Hi Maggie
>>
>> Your error message says that there is some coordinates with latitudes
>> above 90 degrees.
>>
>> The problem seems to arise from the call to gridded. See below for a
>> dput'ed version of the dataframe "air.sig995.ag.df" called "friend" in
>> my code. This is what I found out:
>>
>>> coordinates(friend) <- ~longitude+latitude
>>> bbox(friend)
>>               min max
>> longitude -177.5 180
>> latitude    60.0  90
>>> apply(coordinates(friend), 2, range)
>>       longitude latitude
>> [1,]    -177.5       60
>> [2,]     180.0       90
>>
>> After using gridded() the bounding box is enlarged somewhat but the
>> coordinates still unchanged.
>>
>>> gridded(friend) <- TRUE
>>> bbox(friend)
>>                min    max
>> longitude -178.75 181.25
>> latitude    58.75  91.25
>>> apply(coordinates(friend), 2, range)
>>       longitude latitude
>> [1,]    -177.5       60
>> [2,]     180.0       90
>>>
>>
>> If you leave out the gridded() part I guess you can proceed towards
>> your goal. Here I did:
>>
>> ## this was okay
>>> crs <- "+proj=longlat +datum=WGS84"
>>> proj4string(friend) <- crs
>>
>> ## see attached plot
>>> png("longlat.png")
>>> plot(friend)
>>> dev.off()
>>
>> Do a reprojection with spTransform():
>>
>>> stere <- "+proj=stere +lat_0=90 +lat_ts=60 +lon_0=0 +k=1 +x_0=0
>>> +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
>>> friend.stere <- spTransform(friend, CRS(stere))
>>
>> And the plot is attached:
>>
>>> png("stere.png")
>>> plot(friend.stere)
>>> dev.off()
>> X11cairo
>>
>> Why gridded() is extending domain outside permissible values for
>> longitude and latitude I don't know.
> 
> My guess is that gridded assumes coordinates provided correspond to
> pixels centers, 

that is correct.

> while top-left coordinates are provided.
> 
> Cheers,
> Lo?c
> 
>>
>> \Frede
>>
>> ##### friend is a copy of air.sig995.ag.df <-
>> NCEP.array2df(air.sig995.ag[,,1], var.names = 'Temperature')
>>
>> ## DELETED
>>
>> Yours sincerely / Med venlig hilsen
>>
>> Frede Aakmann T?gersen
>> Specialist, M.Sc., Ph.D.
>> Plant Performance & Modeling
>>
>> Technology & Service Solutions
>> T +45 9730 5135
>> M +45 2547 6050
>> frtog at vestas.com
>> http://www.vestas.com
>>
>> Company reg. name: Vestas Wind Systems A/S
>> This e-mail is subject to our e-mail disclaimer statement.
>> Please refer to www.vestas.com/legal/notice
>> If you have received this e-mail in error please contact the sender.
>>
>>
>>
>> -----Original Message-----
>> From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of
>> Maggie CY Lau
>> Sent: 7. april 2016 16:24
>> To: r-sig-geo at r-project.org
>> Subject: [R-sig-Geo] proj4string error on data.frame generated from
>> NCEP data
>>
>> HI all,
>>
>> I am an ecologist who would like to use several datasets generated by
>> NCEP reanalysis. I attempted to use the R package "RNCEP" to extract
>> the data and generate .tiff files. These files will be analyzed by a
>> student using ArcMap. I created the data fame with the information I
>> need, but had problem exporting the data into .tiff file that can be
>> projected in polar stereograph in ArcMap. The use of "+proj=longlat +
>> datum=WGS84" gave the following error message:
>>
>> Error in `proj4string<-`(`*tmp*`, value = <S4 object of class "CRS">) :
>>    Geographical CRS given to non-conformant data: 91.25
>>
>> Then I tried using ""+proj=stere +lat_0=90 +lat_ts=60 +lon_0=0 +k=1
>> +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs".
>> proj4string went fine but the export tiff appeared as a box image
>> instead of an angular one.
>>
>> Please kindly check the following codes from the line "library(sp)"
>> onward.
>>
>> Thanks,
>> Maggie Lau
>>
>> ====
>> install.packages("RNCEP", dependencies=TRUE)
>> install.packages(c('abind', 'maps', 'fields', 'tgp', 'fossil'),
>> dependencies=TRUE)
>> install.packages("raster")
>> install.packages("rgdal")
>>
>> library(RNCEP)
>> air.sig995.extent <- NCEP.gather(variable='air.sig995',
>> level='surface', months.minmax=c(7),
>> years.minmax=c(2011), lat.southnorth=c(60,89.9),
>> lon.westeast=c(-179,180),
>> reanalysis2=FALSE, return.units=TRUE)
>> air.sig995.ag <- NCEP.aggregate(wx.data=air.sig995.extent, YEARS=TRUE,
>> MONTHS=TRUE,
>> DAYS=FALSE, HOURS=FALSE, fxn='mean')
>> dimnames(air.sig995.ag)[[3]][1]
>> air.sig995.ag.df <- NCEP.array2df(air.sig995.ag[,,1], var.names =
>> 'Temperature')
>>
>> library(sp)
>> coordinates(air.sig995.ag.df) <- ~longitude+latitude
>> gridded(air.sig995.ag.df) <- TRUE
>> crs <- "+proj=longlat + datum=WGS84"
>> proj4string(air.sig995.ag.df) <- CRS(crs)
>> #stere <- "+proj=stere +lat_0=90 +lat_ts=60 +lon_0=0
>> # +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
>> #proj4string(air.sig995.ag.df) <- CRS(stere)
>>
>> library(raster)
>> ras <- raster(air.sig995.ag.df)
>> writeRaster(ras, 'air.sig995.Jul.ag.tif', overwrite=TRUE)
>>
>>
>>
>>
>>     [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics  (ifgi),  University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160408/bf32c847/attachment.bin>

From loic.dutrieux at wur.nl  Fri Apr  8 12:27:51 2016
From: loic.dutrieux at wur.nl (=?UTF-8?Q?Lo=c3=afc_Dutrieux?=)
Date: Fri, 8 Apr 2016 12:27:51 +0200
Subject: [R-sig-Geo] FW: proj4string error on data.frame generated from
 NCEP data
In-Reply-To: <57077CFA.80003@wur.nl>
References: <06ABC08E-8837-4010-A2D0-A6A1197571C4@exchange.Princeton.EDU>
	<HE1PR04MB12768868B967B476105FB16ADB910@HE1PR04MB1276.eurprd04.prod.outlook.com>
	<57077CFA.80003@wur.nl>
Message-ID: <570787A7.3040406@wur.nl>


>>
>> -----Original Message-----
>> From: Frede Aakmann T?gersen
>> Sent: 8. april 2016 08:01
>> To: 'Maggie CY Lau'; r-sig-geo at r-project.org
>> Subject: RE: proj4string error on data.frame generated from NCEP data
>>
>> Hi Maggie
>>
>> Your error message says that there is some coordinates with latitudes
>> above 90 degrees.
>>
>> The problem seems to arise from the call to gridded. See below for a
>> dput'ed version of the dataframe "air.sig995.ag.df" called "friend" in
>> my code. This is what I found out:
>>
>>> coordinates(friend) <- ~longitude+latitude
>>> bbox(friend)
>>               min max
>> longitude -177.5 180
>> latitude    60.0  90
>>> apply(coordinates(friend), 2, range)
>>       longitude latitude
>> [1,]    -177.5       60
>> [2,]     180.0       90
>>
>> After using gridded() the bounding box is enlarged somewhat but the
>> coordinates still unchanged.
>>
>>> gridded(friend) <- TRUE
>>> bbox(friend)
>>                min    max
>> longitude -178.75 181.25
>> latitude    58.75  91.25
>>> apply(coordinates(friend), 2, range)
>>       longitude latitude
>> [1,]    -177.5       60
>> [2,]     180.0       90
>>>
>>
>> If you leave out the gridded() part I guess you can proceed towards
>> your goal. Here I did:
>>
>> ## this was okay
>>> crs <- "+proj=longlat +datum=WGS84"
>>> proj4string(friend) <- crs
>>
>> ## see attached plot
>>> png("longlat.png")
>>> plot(friend)
>>> dev.off()
>>
>> Do a reprojection with spTransform():
>>
>>> stere <- "+proj=stere +lat_0=90 +lat_ts=60 +lon_0=0 +k=1 +x_0=0
>>> +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
>>> friend.stere <- spTransform(friend, CRS(stere))
>>
>> And the plot is attached:
>>
>>> png("stere.png")
>>> plot(friend.stere)
>>> dev.off()
>> X11cairo
>>
>> Why gridded() is extending domain outside permissible values for
>> longitude and latitude I don't know.
>
> My guess is that gridded assumes coordinates provided correspond to
> pixels centers, while top-left coordinates are provided.

However, I don't understand why raster does not complain about a raster 
having an extent beyond the boundaries of its CRS.
If I do:

library(RNCEP)
library(raster)

air.sig995.extent <- NCEP.gather(variable='air.sig995', level='surface', 
months.minmax=c(7),
                                  years.minmax=c(2011), 
lat.southnorth=c(60,89.9), lon.westeast=c(-179,180),
                                  reanalysis2=FALSE, return.units=TRUE)
air.sig995.ag <- NCEP.aggregate(wx.data=air.sig995.extent, YEARS=TRUE, 
MONTHS=TRUE,
                                 DAYS=FALSE, HOURS=FALSE, fxn='mean')
air.sig995.ag.df <- NCEP.array2df(air.sig995.ag[,,1], var.names = 
'Temperature')
# Reorder columns
df <- air.sig995.ag.df[,c(2,1,3)]
r <- rasterFromXYZ(df, crs = CRS('+proj=longlat +datum=WGS84'))
r
plot(r)
writeRaster(r, '~/sandbox/arctic.tif')

everything works... (but is probably wrong)

Cheers,
Lo?c

>
> Cheers,
> Lo?c
>
>>
>> \Frede
>>
>> ##### friend is a copy of air.sig995.ag.df <-
>> NCEP.array2df(air.sig995.ag[,,1], var.names = 'Temperature')
>>
>> ## DELETED
>>
>> Yours sincerely / Med venlig hilsen
>>
>> Frede Aakmann T?gersen
>> Specialist, M.Sc., Ph.D.
>> Plant Performance & Modeling
>>
>> Technology & Service Solutions
>> T +45 9730 5135
>> M +45 2547 6050
>> frtog at vestas.com
>> http://www.vestas.com
>>
>> Company reg. name: Vestas Wind Systems A/S
>> This e-mail is subject to our e-mail disclaimer statement.
>> Please refer to www.vestas.com/legal/notice
>> If you have received this e-mail in error please contact the sender.
>>
>>
>>
>> -----Original Message-----
>> From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of
>> Maggie CY Lau
>> Sent: 7. april 2016 16:24
>> To: r-sig-geo at r-project.org
>> Subject: [R-sig-Geo] proj4string error on data.frame generated from
>> NCEP data
>>
>> HI all,
>>
>> I am an ecologist who would like to use several datasets generated by
>> NCEP reanalysis. I attempted to use the R package "RNCEP" to extract
>> the data and generate .tiff files. These files will be analyzed by a
>> student using ArcMap. I created the data fame with the information I
>> need, but had problem exporting the data into .tiff file that can be
>> projected in polar stereograph in ArcMap. The use of "+proj=longlat +
>> datum=WGS84" gave the following error message:
>>
>> Error in `proj4string<-`(`*tmp*`, value = <S4 object of class "CRS">) :
>>    Geographical CRS given to non-conformant data: 91.25
>>
>> Then I tried using ""+proj=stere +lat_0=90 +lat_ts=60 +lon_0=0 +k=1
>> +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs".
>> proj4string went fine but the export tiff appeared as a box image
>> instead of an angular one.
>>
>> Please kindly check the following codes from the line "library(sp)"
>> onward.
>>
>> Thanks,
>> Maggie Lau
>>
>> ====
>> install.packages("RNCEP", dependencies=TRUE)
>> install.packages(c('abind', 'maps', 'fields', 'tgp', 'fossil'),
>> dependencies=TRUE)
>> install.packages("raster")
>> install.packages("rgdal")
>>
>> library(RNCEP)
>> air.sig995.extent <- NCEP.gather(variable='air.sig995',
>> level='surface', months.minmax=c(7),
>> years.minmax=c(2011), lat.southnorth=c(60,89.9),
>> lon.westeast=c(-179,180),
>> reanalysis2=FALSE, return.units=TRUE)
>> air.sig995.ag <- NCEP.aggregate(wx.data=air.sig995.extent, YEARS=TRUE,
>> MONTHS=TRUE,
>> DAYS=FALSE, HOURS=FALSE, fxn='mean')
>> dimnames(air.sig995.ag)[[3]][1]
>> air.sig995.ag.df <- NCEP.array2df(air.sig995.ag[,,1], var.names =
>> 'Temperature')
>>
>> library(sp)
>> coordinates(air.sig995.ag.df) <- ~longitude+latitude
>> gridded(air.sig995.ag.df) <- TRUE
>> crs <- "+proj=longlat + datum=WGS84"
>> proj4string(air.sig995.ag.df) <- CRS(crs)
>> #stere <- "+proj=stere +lat_0=90 +lat_ts=60 +lon_0=0
>> # +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
>> #proj4string(air.sig995.ag.df) <- CRS(stere)
>>
>> library(raster)
>> ras <- raster(air.sig995.ag.df)
>> writeRaster(ras, 'air.sig995.Jul.ag.tif', overwrite=TRUE)
>>
>>
>>
>>
>>     [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From milujisb at gmail.com  Fri Apr  8 12:29:33 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Fri, 8 Apr 2016 12:29:33 +0200
Subject: [R-sig-Geo] Add Two-Headed Arrow in map legend
Message-ID: <CAMLwc7OO6ZkM8pU2kHziWjygg4SNoMCzjXi8OHZ8Hsr-Wp7+YA@mail.gmail.com>

I am trying to draw maps for the world using:

library(rworldmap)
library(maptools)
library(foreign)
library(RColorBrewer)
library(ggplot2)
library(countrycode)

tmp2<- dput(head(pece,10))
structure(list(iso3 = c("AUS", "AUT", "BEL", "CAN", "CHE", "CHL",
"CZE", "DEU", "DNK", "ESP"), eps_score = c(0.877343773841858,
2.68984365463257, 1.31406247615814, 1.98046875, 2.61666655540466,
NA, 1.44414067268372, 2.34257817268372, 2.89687490463257, 2.15937495231628
), gov_eff = c(1.76499999562899, 1.85666667421659, 1.74500000476837,
1.88416666785876, 1.99181815710935, 1.21499997377396, 0.865833342075348,
1.64999999602636, 2.15416664878527, 1.36833332975705), sh_va_enint =
c(13.4375638961792,
8.90904521942139, 10.368335723877, 14.0469560623169, NA, NA,
13.5679216384888, 9.67090892791748, 10.5978908538818, 8.34146690368652
), rd_in_va = c(2.17547988891602, 2.47147130966187, 2.53955459594727,
2.01138758659363, NA, NA, 1.49587619304657, 2.72330951690674,
2.5316367149353, 1.48551619052887)), datalabel = "", time.stamp = " 9 Mar
2016 17:43", .Names = c("iso3",
"eps_score", "gov_eff", "sh_va_enint", "rd_in_va"), formats = c("%9s",
"%8.0g", "%10.0g", "%9.0g", "%9.0g"), types = c(6L, 254L, 255L,
254L, 254L), val.labels = c("", "", "", "", ""), var.labels = c("",
"(mean) eps_score", "(mean) gov_eff", "(mean) sh_va_enint", "(mean)
rd_in_va"
), expansion.fields = list(c("_dta", "ReS_i", "countrycode"),
    c("_dta", "ReS_ver", "v.2"), c("_dta", "ReS_j", "year"),
    c("_dta", "ReS_str", "0"), c("_dta", "ReS_Xij", "a_"), c("_dta",
    "__JVarLab", "ACT"), c("_dta", "__XijVarLabrdd_", "(sum) rdd"
    ), c("_dta", "__XijVarLabp", "Value"), c("_dta", "__XijVarLabpop",
    "Population"), c("_dta", "__XijVarLabest_lu_f", "Source of lu"
    ), c("_dta", "__XijVarLablu", "Percentage of No Schooling"
    ), c("_dta", "__XijVarLabest_lp_f", "Source of lp"), c("_dta",
    "__XijVarLablp", "Percentage of Primary"), c("_dta", "__XijVarLablh",
    "Percentage of Tertiary"), c("_dta", "__XijVarLabest_lh_f",
    "Source of lh"), c("_dta", "__XijVarLabls", "Percentage of Secondary"
    ), c("_dta", "__XijVarLabest_ls_f", "Source of ls"), c("_dta",
    "__XijVarLabvalue", "Value"), c("_dta", "_TStvar", "year"
    ), c("_dta", "_TSpanel", "id2"), c("_dta", "_TSdelta",
"+1.0000000000000X+000"
    ), c("_dta", "_TSitrvl", "1"), c("_dta", "tis", "year"),
    c("_dta", "iis", "id2")), version = 12L, row.names = c("1",
"2", "3", "4", "5", "6", "7", "8", "9", "10"), class = "data.frame")
n <- joinCountryData2Map(pece, joinCode="ISO3", nameJoinColumn="iso3")
n <- n[-which(row.names(n)=='Antarctica'),]

# EPS
colourPalette <- rev(brewer.pal(7, "RdYlGn"))

eps <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
Score",colourPalette=colourPalette,
                      catMethod="fixedWidth", missingCountryCol = "white",
addLegend=FALSE)
do.call(addMapLegend, c(eps, legendLabels="all", legendWidth=0.5))

Instead of adding numeric based legend, I would like to add a two-headed
arrow with some text. I would be grateful for any help. Thank you!

Sincerely,

Milu

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Fri Apr  8 13:15:27 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 8 Apr 2016 13:15:27 +0200
Subject: [R-sig-Geo] unionSpatialPolygons from the command-line
In-Reply-To: <D51374C4B889BC47B3C5286047C86DA1A02C06A4@whqembx03p.ad.sfwmd.gov>
References: <D51374C4B889BC47B3C5286047C86DA1A02C06A4@whqembx03p.ad.sfwmd.gov>
Message-ID: <alpine.LFD.2.20.1604081311580.24178@reclus.nhh.no>

On Thu, 7 Apr 2016, Stachelek, Joseph wrote:

> Hello,
>
> I am trying to call "maptools::unionSpatialPolygons()" from the command-line. To illustrate the problem, I can call example(unionSpatialPolygons) from an interactive session but running an R script (testmaptools.R) containing:
>
> `library(maptools)`
> `example(unionSpatialPolygons)`
>

With R --vanilla < testmaptools.R

and adding print(sessionInfo()) to the script, we see:

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

and it runs correctly. With

Rscript testmaptools.R

we see:

attached base packages:
[1] stats     graphics  grDevices utils     datasets  base

The script runs using Rscript if library(methods) is added as the first 
line. This issue has been seen elsewhere recently in another context, we 
don't know why.

Hope this clarifies,

Roger

> yields:
>
> `$ Rscript testmaptools.R`
>> WARNING: ignoring environment value of R_HOME
>> Loading required package: sp
>> Checking rgeos availability: TRUE
>
>> unnSpP> if (rgeosStatus()) {
>> unnSpP+ nc1 <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1],
>> unnSpP+  proj4string=CRS("+proj=longlat +datum=NAD27"))
>> unnSpP+ lps <- coordinates(nc1)
>> unnSpP+ ID <- cut(lps[,1], quantile(lps[,1]), include.lowest=TRUE)
>> unnSpP+ reg4 <- unionSpatialPolygons(nc1, ID)
>> unnSpP+ row.names(reg4)
>> unnSpP+ }
>> Error in rgeos::gUnaryUnion(spgeom = SpP, id = IDs) :
>>   Invalid geometry, may only be applied to polygons
>> Calls: example ... eval -> eval -> unionSpatialPolygons -> <Anonymous>
>> Execution halted
>
> Is this not possible?
>
> Thank you,
>
> Joseph Stachelek
>
>
> We value your opinion. Please take a few minutes to shar...{{dropped:8}}
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


From edzer.pebesma at uni-muenster.de  Fri Apr  8 17:54:56 2016
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 8 Apr 2016 17:54:56 +0200
Subject: [R-sig-Geo] unionSpatialPolygons from the command-line
In-Reply-To: <alpine.LFD.2.20.1604081311580.24178@reclus.nhh.no>
References: <D51374C4B889BC47B3C5286047C86DA1A02C06A4@whqembx03p.ad.sfwmd.gov>
	<alpine.LFD.2.20.1604081311580.24178@reclus.nhh.no>
Message-ID: <5707D450.7010804@uni-muenster.de>

For package sp, I moved "methods" from Imports: to Depends: in order to
avoid this problem with future sp versions or packages with sp in Depends:

On 08/04/16 13:15, Roger Bivand wrote:
> On Thu, 7 Apr 2016, Stachelek, Joseph wrote:
> 
>> Hello,
>>
>> I am trying to call "maptools::unionSpatialPolygons()" from the
>> command-line. To illustrate the problem, I can call
>> example(unionSpatialPolygons) from an interactive session but running
>> an R script (testmaptools.R) containing:
>>
>> `library(maptools)`
>> `example(unionSpatialPolygons)`
>>
> 
> With R --vanilla < testmaptools.R
> 
> and adding print(sessionInfo()) to the script, we see:
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> and it runs correctly. With
> 
> Rscript testmaptools.R
> 
> we see:
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  base
> 
> The script runs using Rscript if library(methods) is added as the first
> line. This issue has been seen elsewhere recently in another context, we
> don't know why.
> 
> Hope this clarifies,
> 
> Roger
> 
>> yields:
>>
>> `$ Rscript testmaptools.R`
>>> WARNING: ignoring environment value of R_HOME
>>> Loading required package: sp
>>> Checking rgeos availability: TRUE
>>
>>> unnSpP> if (rgeosStatus()) {
>>> unnSpP+ nc1 <- readShapePoly(system.file("shapes/sids.shp",
>>> package="maptools")[1],
>>> unnSpP+  proj4string=CRS("+proj=longlat +datum=NAD27"))
>>> unnSpP+ lps <- coordinates(nc1)
>>> unnSpP+ ID <- cut(lps[,1], quantile(lps[,1]), include.lowest=TRUE)
>>> unnSpP+ reg4 <- unionSpatialPolygons(nc1, ID)
>>> unnSpP+ row.names(reg4)
>>> unnSpP+ }
>>> Error in rgeos::gUnaryUnion(spgeom = SpP, id = IDs) :
>>>   Invalid geometry, may only be applied to polygons
>>> Calls: example ... eval -> eval -> unionSpatialPolygons -> <Anonymous>
>>> Execution halted
>>
>> Is this not possible?
>>
>> Thank you,
>>
>> Joseph Stachelek
>>
>>
>> We value your opinion. Please take a few minutes to shar...{{dropped:8}}
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> 

-- 
Edzer Pebesma
Institute for Geoinformatics  (ifgi),  University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160408/da77fca8/attachment.bin>

From thi_veloso at yahoo.com.br  Sat Apr  9 05:56:14 2016
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Sat, 9 Apr 2016 03:56:14 +0000 (UTC)
Subject: [R-sig-Geo] Faster way to extract raster values using multiple
 polygons?
In-Reply-To: <6C0509A0-DD79-415A-B21F-4F6713C80DD9@bigelow.org>
References: <258604906.59719.1459944044625.JavaMail.yahoo.ref@mail.yahoo.com>
	<258604906.59719.1459944044625.JavaMail.yahoo@mail.yahoo.com>
	<6C0509A0-DD79-415A-B21F-4F6713C80DD9@bigelow.org>
Message-ID: <480349596.457034.1460174174154.JavaMail.yahoo@mail.yahoo.com>

Hi Ben,


Thank you so much for the suggestion. 

It is pretty fast, and I guess it's a good assumption for temperature. I'll have to do the same with precipitation, which is way more spatially variable than temperature. In that case, I think I'll have to wait the 10 hours it takes to run "extract" using a mean value of all cells covering a polygon.

It is a one-time processing anyway, so I should not worry too much about the waiting time.

Greetings,
-- Thiago V. dos Santos

PhD student
Land and Atmospheric Science
University of Minnesota




On Wednesday, April 6, 2016 10:48 AM, Ben Tupper <btupper at bigelow.org> wrote:
Hi,

The resolution of your raster data (1 degree) is much more coarse than what your polygons represent.  Could you short-circuit the process by assuming that the temp at the centroid of each polygon would suitably represent the mean temperature across each polygon?  Unless you have some much bigger polygons, I can't imagine it will be very far off. If so, then you could pretty quickly extract the values for each layer in the raster at each centroid.  Perhaps like this?

cents <- coordinates(br_sub)
v <- extract(b, cents)

Is that close enough?

Cheers,
Ben


> On Apr 6, 2016, at 8:00 AM, Thiago V. dos Santos via R-sig-Geo <r-sig-geo at r-project.org> wrote:
> 
> Dear all,
> 
> I am trying to extract a time series from a raster brick using multiple polygons.
> 
> The raster brick is a global temperature netcdf file with 1200 layers (months) and the polygons are each of the 5567 municipalities in Brazil. I intend to extract the temperature time series for each municipality.
> 
> As a final result, I would like to have a data frame containing: -the name and coordinates of the municipality, -the date tag from the raster, and -the extracted temperature value.
> 
> My initial, VERY SLOW attempt was something like this:
> 
> 
> library(raster)
> 
> # Create some sample raster data
> idx <- seq(as.Date("1960/1/1"), as.Date("1990/12/01"), by = "month")
> r <- raster(ncol=360, nrow=180)
> b <- brick(lapply(1:length(idx), function(x) setValues(r, runif(ncell(r)))))
> b <- setZ(b, idx)
> 
> # Import polygon data
> br <- getData("GADM", country="Brazil", level=2) # about 7MB to download
> 
> # Subset the SMALLEST state - only 75 municipalities
> br_sub <- br[br$NAME_1=="Sergipe" & !is.na(br$NAME_1),]
> plot(br_sub)
> 
> # Now let's extract the data for each municipality
> beginCluster()
> e <- extract(b, br_sub, fun=mean, df=T)
> endCluster()
> 
> 
> Even using the smallest state possible, this example takes about 20 minutes to run on a dual-core 2.5GHz Macbook Pro using four threads. As a reference, there are states with over 850 municipalities. And remember, in total there are over 5500 municipalities I need to extract the data for.
> 
> I have the feeling that my code is not very optimized.
> 
> Has anybody ever dealt with this amount of data in this kind of raster operation? Is there any fastest way to achieve my expected result?
> Thanks in advance,
> -- Thiago V. dos Santos
> 
> PhD student
> Land and Atmospheric Science
> 
> University of Minnesota
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From maglau at Princeton.EDU  Sat Apr  9 13:34:16 2016
From: maglau at Princeton.EDU (Maggie CY Lau)
Date: Sat, 9 Apr 2016 11:34:16 +0000
Subject: [R-sig-Geo] proj4string error on data.frame generated from NCEP
 data
In-Reply-To: <570787A7.3040406@wur.nl>
References: <06ABC08E-8837-4010-A2D0-A6A1197571C4@exchange.Princeton.EDU>
	<HE1PR04MB12768868B967B476105FB16ADB910@HE1PR04MB1276.eurprd04.prod.outlook.com>
	<57077CFA.80003@wur.nl> <570787A7.3040406@wur.nl>
Message-ID: <B3DFAB39-6E4C-4413-9B98-D610D2A1B167@exchange.Princeton.EDU>

Frede, Lo?c, Edzer, thank you very much for your responses.

The coding lines provided Frede and Lo?c worked. The tif file was imported into ArcMap and could be viewed in different projections. 


On Apr 8, 2016, at 6:27 AM, Lo?c Dutrieux wrote:

> 
>>> 
>>> -----Original Message-----
>>> From: Frede Aakmann T?gersen
>>> Sent: 8. april 2016 08:01
>>> To: 'Maggie CY Lau'; r-sig-geo at r-project.org
>>> Subject: RE: proj4string error on data.frame generated from NCEP data
>>> 
>>> Hi Maggie
>>> 
>>> Your error message says that there is some coordinates with latitudes
>>> above 90 degrees.
>>> 
>>> The problem seems to arise from the call to gridded. See below for a
>>> dput'ed version of the dataframe "air.sig995.ag.df" called "friend" in
>>> my code. This is what I found out:
>>> 
>>>> coordinates(friend) <- ~longitude+latitude
>>>> bbox(friend)
>>>              min max
>>> longitude -177.5 180
>>> latitude    60.0  90
>>>> apply(coordinates(friend), 2, range)
>>>      longitude latitude
>>> [1,]    -177.5       60
>>> [2,]     180.0       90
>>> 
>>> After using gridded() the bounding box is enlarged somewhat but the
>>> coordinates still unchanged.
>>> 
>>>> gridded(friend) <- TRUE
>>>> bbox(friend)
>>>               min    max
>>> longitude -178.75 181.25
>>> latitude    58.75  91.25
>>>> apply(coordinates(friend), 2, range)
>>>      longitude latitude
>>> [1,]    -177.5       60
>>> [2,]     180.0       90
>>>> 
>>> 
>>> If you leave out the gridded() part I guess you can proceed towards
>>> your goal. Here I did:
>>> 
>>> ## this was okay
>>>> crs <- "+proj=longlat +datum=WGS84"
>>>> proj4string(friend) <- crs
>>> 
>>> ## see attached plot
>>>> png("longlat.png")
>>>> plot(friend)
>>>> dev.off()
>>> 
>>> Do a reprojection with spTransform():
>>> 
>>>> stere <- "+proj=stere +lat_0=90 +lat_ts=60 +lon_0=0 +k=1 +x_0=0
>>>> +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
>>>> friend.stere <- spTransform(friend, CRS(stere))
>>> 
>>> And the plot is attached:
>>> 
>>>> png("stere.png")
>>>> plot(friend.stere)
>>>> dev.off()
>>> X11cairo
>>> 
>>> Why gridded() is extending domain outside permissible values for
>>> longitude and latitude I don't know.
>> 
>> My guess is that gridded assumes coordinates provided correspond to
>> pixels centers, while top-left coordinates are provided.
> 
> However, I don't understand why raster does not complain about a raster having an extent beyond the boundaries of its CRS.
> If I do:
> 
> library(RNCEP)
> library(raster)
> 
> air.sig995.extent <- NCEP.gather(variable='air.sig995', level='surface', months.minmax=c(7),
>                                 years.minmax=c(2011), lat.southnorth=c(60,89.9), lon.westeast=c(-179,180),
>                                 reanalysis2=FALSE, return.units=TRUE)
> air.sig995.ag <- NCEP.aggregate(wx.data=air.sig995.extent, YEARS=TRUE, MONTHS=TRUE,
>                                DAYS=FALSE, HOURS=FALSE, fxn='mean')
> air.sig995.ag.df <- NCEP.array2df(air.sig995.ag[,,1], var.names = 'Temperature')
> # Reorder columns
> df <- air.sig995.ag.df[,c(2,1,3)]
> r <- rasterFromXYZ(df, crs = CRS('+proj=longlat +datum=WGS84'))
> r
> plot(r)
> writeRaster(r, '~/sandbox/arctic.tif')
> 
> everything works... (but is probably wrong)
> 
> Cheers,
> Lo?c
> 
>> 
>> Cheers,
>> Lo?c
>> 
>>> 
>>> \Frede
>>> 
>>> ##### friend is a copy of air.sig995.ag.df <-
>>> NCEP.array2df(air.sig995.ag[,,1], var.names = 'Temperature')
>>> 
>>> ## DELETED
>>> 
>>> Yours sincerely / Med venlig hilsen
>>> 
>>> Frede Aakmann T?gersen
>>> Specialist, M.Sc., Ph.D.
>>> Plant Performance & Modeling
>>> 
>>> Technology & Service Solutions
>>> T +45 9730 5135
>>> M +45 2547 6050
>>> frtog at vestas.com
>>> http://www.vestas.com
>>> 
>>> Company reg. name: Vestas Wind Systems A/S
>>> This e-mail is subject to our e-mail disclaimer statement.
>>> Please refer to www.vestas.com/legal/notice
>>> If you have received this e-mail in error please contact the sender.
>>> 
>>> 
>>> 
>>> -----Original Message-----
>>> From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of
>>> Maggie CY Lau
>>> Sent: 7. april 2016 16:24
>>> To: r-sig-geo at r-project.org
>>> Subject: [R-sig-Geo] proj4string error on data.frame generated from
>>> NCEP data
>>> 
>>> HI all,
>>> 
>>> I am an ecologist who would like to use several datasets generated by
>>> NCEP reanalysis. I attempted to use the R package "RNCEP" to extract
>>> the data and generate .tiff files. These files will be analyzed by a
>>> student using ArcMap. I created the data fame with the information I
>>> need, but had problem exporting the data into .tiff file that can be
>>> projected in polar stereograph in ArcMap. The use of "+proj=longlat +
>>> datum=WGS84" gave the following error message:
>>> 
>>> Error in `proj4string<-`(`*tmp*`, value = <S4 object of class "CRS">) :
>>>   Geographical CRS given to non-conformant data: 91.25
>>> 
>>> Then I tried using ""+proj=stere +lat_0=90 +lat_ts=60 +lon_0=0 +k=1
>>> +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs".
>>> proj4string went fine but the export tiff appeared as a box image
>>> instead of an angular one.
>>> 
>>> Please kindly check the following codes from the line "library(sp)"
>>> onward.
>>> 
>>> Thanks,
>>> Maggie Lau
>>> 
>>> ====
>>> install.packages("RNCEP", dependencies=TRUE)
>>> install.packages(c('abind', 'maps', 'fields', 'tgp', 'fossil'),
>>> dependencies=TRUE)
>>> install.packages("raster")
>>> install.packages("rgdal")
>>> 
>>> library(RNCEP)
>>> air.sig995.extent <- NCEP.gather(variable='air.sig995',
>>> level='surface', months.minmax=c(7),
>>> years.minmax=c(2011), lat.southnorth=c(60,89.9),
>>> lon.westeast=c(-179,180),
>>> reanalysis2=FALSE, return.units=TRUE)
>>> air.sig995.ag <- NCEP.aggregate(wx.data=air.sig995.extent, YEARS=TRUE,
>>> MONTHS=TRUE,
>>> DAYS=FALSE, HOURS=FALSE, fxn='mean')
>>> dimnames(air.sig995.ag)[[3]][1]
>>> air.sig995.ag.df <- NCEP.array2df(air.sig995.ag[,,1], var.names =
>>> 'Temperature')
>>> 
>>> library(sp)
>>> coordinates(air.sig995.ag.df) <- ~longitude+latitude
>>> gridded(air.sig995.ag.df) <- TRUE
>>> crs <- "+proj=longlat + datum=WGS84"
>>> proj4string(air.sig995.ag.df) <- CRS(crs)
>>> #stere <- "+proj=stere +lat_0=90 +lat_ts=60 +lon_0=0
>>> # +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
>>> #proj4string(air.sig995.ag.df) <- CRS(stere)
>>> 
>>> library(raster)
>>> ras <- raster(air.sig995.ag.df)
>>> writeRaster(ras, 'air.sig995.Jul.ag.tif', overwrite=TRUE)
>>> 
>>> 
>>> 
>>> 
>>>    [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> 
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> 
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

Maggie C.Y. Lau, PhD
Department of Geosciences
B80 Guyot Hall
Princeton University
Princeton, NJ 08544, US
Cell: +1-609-356-8145


From rodaromero at gmail.com  Sat Apr  9 17:39:59 2016
From: rodaromero at gmail.com (David Romero)
Date: Sat, 9 Apr 2016 10:39:59 -0500
Subject: [R-sig-Geo]  linear model with sill
In-Reply-To: <CAJx8RnH2tSsk3BWFLLSiVJHOsHTFasG1KezBX3a-fhAAbKvmBA@mail.gmail.com>
References: <CAJx8RnH2tSsk3BWFLLSiVJHOsHTFasG1KezBX3a-fhAAbKvmBA@mail.gmail.com>
Message-ID: <5709224F.4070200@gmail.com>

Hello listers,

I am elaborating variograms with geoR and testing models, I'd like to 
know how I can test linear model with a sill.

v1 = variog(PmmRG, 
max.dist=50000,direction=0,tolerance=22.5,unit.angle="degrees",option = 
c("bin"),breaks=brk)
ols<- variofit(v1,cov.model="linear", wei="cressie")

Thanks and regards,

David


From twah at gmx.ch  Mon Apr 11 13:40:29 2016
From: twah at gmx.ch (twah at gmx.ch)
Date: Mon, 11 Apr 2016 13:40:29 +0200
Subject: [R-sig-Geo] errorsarlm from spdep package / error message
Message-ID: <570B8D2D.8000305@gmx.ch>

Hi all

I am trying to debug my R project. As I invoke the "errorsarlm" function 
from the "spdep" package, I am getting the following error:

Error in as.vector(residuals(lm.target)) :
   '.SigArgs' is shorter than '.SigLength' says it should be

I have no clue why this error message arises. An internet search did not 
give an answer, either. Do some of you know? I am not sure whether or 
not I have to provide a minimal reproducible code in this mailing list?

Thanks


From Roger.Bivand at nhh.no  Mon Apr 11 13:59:27 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 11 Apr 2016 13:59:27 +0200
Subject: [R-sig-Geo] errorsarlm from spdep package / error message
In-Reply-To: <570B8D2D.8000305@gmx.ch>
References: <570B8D2D.8000305@gmx.ch>
Message-ID: <alpine.LFD.2.20.1604111355190.7495@reclus.nhh.no>

On Mon, 11 Apr 2016, twah at gmx.ch wrote:

> Hi all
>
> I am trying to debug my R project. As I invoke the "errorsarlm" function from 
> the "spdep" package, I am getting the following error:
>
> Error in as.vector(residuals(lm.target)) :
>   '.SigArgs' is shorter than '.SigLength' says it should be

Please provide the output of traceback(), entered immediately after the 
error. Please also give the output of sessionInfo(), showing your 
platform, R and spdep version. This doesn't happen in general, so please 
also provide an example using a built-in data set that triggers the issue.

Roger

>
> I have no clue why this error message arises. An internet search did not give 
> an answer, either. Do some of you know? I am not sure whether or not I have 
> to provide a minimal reproducible code in this mailing list?
>
> Thanks
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


From nell.redu at hotmail.fr  Mon Apr 11 16:56:52 2016
From: nell.redu at hotmail.fr (Nelly Reduan)
Date: Mon, 11 Apr 2016 14:56:52 +0000
Subject: [R-sig-Geo] How to reduce the buffering time with the function
 "buffer" (package raster)
Message-ID: <CY1PR0501MB1772C3ADEB76DE9BF66FA42299940@CY1PR0501MB1772.namprd05.prod.outlook.com>

Hello,


I would like to build 100-m buffers (representing ecological corridors) around land cover attributes in a raster layer and to assign a given value (i.e., value of 13) to buffer cells.


To do this, I'm using the function "buffer" (package raster) to draw the buffers around particular raster cells (i.e., cell values of 2 and 5). For example, in the image below, the buffers are represented in blue (cell values of 13) and the particular raster cells are represented in yellow (cell values of 2).


The problem is that the time to run the function "buffer" is very low because I have a raster of 5000000 cells. Does anyone know how I can reduce the buffering time ?


Thanks a lot for your time.

Have a nice day.

Nell


[cid:a5aea5ef-e76e-4670-9473-25ebaa73f0a3]
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160411/85f0be16/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Capture.PNG
Type: image/png
Size: 12209 bytes
Desc: Capture.PNG
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160411/85f0be16/attachment.png>

From r-sig-geo at forreststevens.com  Mon Apr 11 18:09:59 2016
From: r-sig-geo at forreststevens.com (Forrest Stevens)
Date: Mon, 11 Apr 2016 16:09:59 +0000
Subject: [R-sig-Geo] How to reduce the buffering time with the function
 "buffer" (package raster)
In-Reply-To: <CY1PR0501MB1772C3ADEB76DE9BF66FA42299940@CY1PR0501MB1772.namprd05.prod.outlook.com>
References: <CY1PR0501MB1772C3ADEB76DE9BF66FA42299940@CY1PR0501MB1772.namprd05.prod.outlook.com>
Message-ID: <CAEBQMM=QON_LKAC8z9UMvUwBSu3+q3EcJzNKPkmn==jvS+9cCQ@mail.gmail.com>

Five million cells isn't all that many, how slow is too slow? Buffering a
raster of about 10 million cells on my laptop takes on the order of 20
seconds or so for a binary raster. Is it possible that you're fighting
memory problems?

In the past when doing multiple ring buffers I've found it faster to
calculate a distance-to raster first, and then apply multiple logical
comparisons on the distance raster.  I don't know if this applies to your
situation or not but it's one trick that might help.

Sincerely,
Forrest

On Mon, Apr 11, 2016 at 10:58 AM Nelly Reduan <nell.redu at hotmail.fr> wrote:

> Hello,
>
>
> I would like to build 100-m buffers (representing ecological corridors)
> around land cover attributes in a raster layer and to assign a given value
> (i.e., value of 13) to buffer cells.
>
>
> To do this, I'm using the function "buffer" (package raster) to draw the
> buffers around particular raster cells (i.e., cell values of 2 and 5). For
> example, in the image below, the buffers are represented in blue (cell
> values of 13) and the particular raster cells are represented in yellow
> (cell values of 2).
>
>
> The problem is that the time to run the function "buffer" is very low
> because I have a raster of 5000000 cells. Does anyone know how I can reduce
> the buffering time ?
>
>
> Thanks a lot for your time.
>
> Have a nice day.
>
> Nell
>
> [image: Capture.PNG]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160411/159ec27b/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Capture.PNG
Type: image/png
Size: 12209 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160411/159ec27b/attachment.png>

From flaxman at gmail.com  Mon Apr 11 23:50:12 2016
From: flaxman at gmail.com (Seth Flaxman)
Date: Mon, 11 Apr 2016 22:50:12 +0100
Subject: [R-sig-Geo] kernel intensity estimation for a spatiotemporal point
	process
Message-ID: <CAPGk9pdrd3eGSwiEC8uOjK54SRhC=jhWWweX_d_o+50V0FrzMA@mail.gmail.com>

Does anyone know of a package implementing kernel intensity estimation for
a spatiotemporal point process? (I'm not treating time in a special way, so
something for a 3-dimensional point process would be fine.)

Thanks,
Seth

	[[alternative HTML version deleted]]


From sa462 at cornell.edu  Tue Apr 12 00:22:16 2016
From: sa462 at cornell.edu (Samar Deen)
Date: Mon, 11 Apr 2016 18:22:16 -0400
Subject: [R-sig-Geo] Fwd: Error is spdep spautolm()
In-Reply-To: <CAKY_pX7c745CN1zBAQOXiYEXcrsJDhUXHqQF9xmX-1-A6ZnzLw@mail.gmail.com>
References: <CAKY_pX67HevwVCcqjpy8dLbJ=xEmEWvVtPrS09xtGRAQ0bJXfw@mail.gmail.com>
	<CAKY_pX7c745CN1zBAQOXiYEXcrsJDhUXHqQF9xmX-1-A6ZnzLw@mail.gmail.com>
Message-ID: <CAKY_pX5d+Csyd2S4RkD_xUXdaeyXXSmNTLsbPsD5ydwRDXy1vA@mail.gmail.com>

I was running a CAR with different inputs into the function, but have a few
errors that I am unable to resolve.

CAR1 = spautolm(s2008 ~ 1, data = df4, listw = gab.nhbr.listw,
+ weights = 1, family = "CAR")
Error in model.frame.default(formula = s2008 ~ 1, data = df4, weights = 1,
 :
  variable lengths differ (found for '(weights)')

CAR1 = spautolm(s2008 ~ 1, data = df4, listw = gab.nhbr.listw,
+ weights = tempmean, family = "CAR")
Error in validObject(.Object) :
  invalid class ?dgRMatrix? object: slot j is not increasing inside a column

Here in both cases I used a Delaunay Triangulation to determine neighbors
and also made the neighbors symmetric using the command:

nc_nb.tri <- make.sym.nb(nc_nb.tri)

In my code I also have other methods for determining the neighbors. I seem
to be getting different errors for all.

I would really appreciate any guidance on how I may resolve this error.

Any help will be really appreciated.

Thank you & Regards,

My code is pasted below:

library(Matrix)
library(spdep)
library(RColorBrewer)

#Get cents3
setwd("~/Desktop/Flounder")
cents3 <- read.csv("cents3.csv")

#Subset the relevant data
df=data.frame(cents3)
df2 <- subset(df, select = c(8,9,41,49,50))
df3 <- df2[complete.cases(df2), ]
df4 <- na.omit(df3)
coordinates(df4) = c("x","y")

##SET the neighbours
coords = coordinates(df4)
IDs = row.names(data.frame(df4))

# Delaunay Triangulation

nc_nb.tri = tri2nb(coords,row.names=IDs)
nc_nb.tri <- make.sym.nb(nc_nb.tri)
#
plot(df4, border = "grey")
plot(nc_nb.tri, coordinates(df4), add = TRUE, col = "blue")

# Sphere of Influence

nc_nb.soi = graph2nb(soi.graph(nc_nb.tri,coords),row.names=IDs)
nc_nb.soi <- make.sym.nb(nc_nb.soi)

#
plot(df4, border = "grey")
plot(nc_nb.soi, coordinates(df4), add = TRUE, col = "blue")

# Relative Graph
#
nc_nb.relative = graph2nb(relativeneigh(coords),row.names=IDs)
#
plot(df4, border = "grey")
plot(nc_nb.relative, coordinates(df4), add = TRUE, col = "blue")
#
# Neighbors based on distance (Here all neighbors withing 30 miles
# This one is a bit messy
nc_nb.dnn = dnearneigh(cbind(df4$x,df4$y),0,2,row.names=IDs)
#
plot(df4, border = "grey")
plot(nc_nb.dnn, coordinates(df4), add = TRUE, col = "blue")
#
# K nearest neighbors
#
nc_nb.knn = knn2nb(knearneigh(coordinates(df4),k=5),row.names=IDs)
nc_nb.knn <- make.sym.nb(nc_nb.knn)
#
plot(df4, border = "grey")
plot(nc_nb.knn, coordinates(df4), add = TRUE, col = "blue")
#

#7- Making Neighborhood Wieghts
#
# Compute distances between neighbors

gab.dist = nbdists(nc_nb.tri, cbind(df4$x, df4$y))
#
# Create a spatial neighbor object from weights object
# using inverse distance weighting, style B gives equal weights to the
nrihbors
gab.nhbr = listw2sn(nb2listw(nc_nb.tri, glist = gab.dist,
                             style = "U", zero.policy = TRUE))
#
# The distance between neighbor i and j
dij = gab.nhbr[, 3]
#
# SSTobserved
n = df4$tempmean
#
# Scaled inverse distance
el1 = min(dij)/dij
#
# Square root of ratio of central fish to neighbor fish quantities
#not needed
el2 = sqrt(n[gab.nhbr$to]/n[gab.nhbr$from])
#
# Combine distance and birth weightings
gab.nhbr$weights = el1
#
# Create spatial weights object from spatial neighbor object
gab.nhbr.listw = sn2listw(gab.nhbr)

gab.nhbr.listw$style <- "W"

#8- CAR with no predictor
#when wieght = 1 it will be propotional to the variance-
#since it is a standardized survey across the region we can assume it is 1

CAR1 = spautolm(s2008 ~ tempmean, data = df4, listw = gab.nhbr.listw,
               verbose = TRUE, family = "CAR", method = "Matrix_J")

CAR1 = spautolm(s2008 ~ 1, data = df4, listw = gab.nhbr.listw,
                weights = 1, family = "CAR")

summary(CAR1)

	[[alternative HTML version deleted]]


From nell.redu at hotmail.fr  Tue Apr 12 00:56:51 2016
From: nell.redu at hotmail.fr (Nelly Reduan)
Date: Mon, 11 Apr 2016 22:56:51 +0000
Subject: [R-sig-Geo] How to reduce the buffering time with the function
 "buffer" (package raster)
In-Reply-To: <CAEBQMM=QON_LKAC8z9UMvUwBSu3+q3EcJzNKPkmn==jvS+9cCQ@mail.gmail.com>
References: <CY1PR0501MB1772C3ADEB76DE9BF66FA42299940@CY1PR0501MB1772.namprd05.prod.outlook.com>,
	<CAEBQMM=QON_LKAC8z9UMvUwBSu3+q3EcJzNKPkmn==jvS+9cCQ@mail.gmail.com>
Message-ID: <CY1PR0501MB1772661FD5CC5C18111F3DB999940@CY1PR0501MB1772.namprd05.prod.outlook.com>

Thank you very much Forrest for your answer. I don't think I have memory problems (my computer has a 32 GB memory).


Here is my code to draw the 100-m buffers with the function "buffer" (package raster):

r1 <- r ## r is the original raster and has a resolution of 10m
r1[(r1[]!=2 & r1[]!=5)]=NA
plot(r1)
r2 <- buffer(r1, 10)


I also tested the function distance (package raster):

r1 <- r ## r is the original raster and has a resolution of 10m
r1[(r1[]!=2 & r1[]!=5)]=NA
plot(r1)
r3 <- distance(r1)


In the two cases, I stopped the functions afer 5 hours as this was too long ! For the moment, I haven't find solutions.


Thanks a lot for your time.

Have a nice day.

Nell



________________________________
De : Forrest Stevens <r-sig-geo at forreststevens.com>
Envoy? : lundi 11 avril 2016 09:09
? : Nelly Reduan; r-sig-geo at r-project.org
Objet : Re: [R-sig-Geo] How to reduce the buffering time with the function "buffer" (package raster)

Five million cells isn't all that many, how slow is too slow? Buffering a raster of about 10 million cells on my laptop takes on the order of 20 seconds or so for a binary raster. Is it possible that you're fighting memory problems?

In the past when doing multiple ring buffers I've found it faster to calculate a distance-to raster first, and then apply multiple logical comparisons on the distance raster.  I don't know if this applies to your situation or not but it's one trick that might help.

Sincerely,
Forrest

On Mon, Apr 11, 2016 at 10:58 AM Nelly Reduan <nell.redu at hotmail.fr<mailto:nell.redu at hotmail.fr>> wrote:

Hello,


I would like to build 100-m buffers (representing ecological corridors) around land cover attributes in a raster layer and to assign a given value (i.e., value of 13) to buffer cells.


To do this, I'm using the function "buffer" (package raster) to draw the buffers around particular raster cells (i.e., cell values of 2 and 5). For example, in the image below, the buffers are represented in blue (cell values of 13) and the particular raster cells are represented in yellow (cell values of 2).


The problem is that the time to run the function "buffer" is very low because I have a raster of 5000000 cells. Does anyone know how I can reduce the buffering time ?


Thanks a lot for your time.

Have a nice day.

Nell


[Capture.PNG]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160411/f693f7d7/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Capture.PNG
Type: image/png
Size: 12209 bytes
Desc: Capture.PNG
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160411/f693f7d7/attachment.png>

From r-sig-geo at forreststevens.com  Tue Apr 12 03:55:49 2016
From: r-sig-geo at forreststevens.com (Forrest Stevens)
Date: Tue, 12 Apr 2016 01:55:49 +0000
Subject: [R-sig-Geo] How to reduce the buffering time with the function
 "buffer" (package raster)
In-Reply-To: <CY1PR0501MB1772661FD5CC5C18111F3DB999940@CY1PR0501MB1772.namprd05.prod.outlook.com>
References: <CY1PR0501MB1772C3ADEB76DE9BF66FA42299940@CY1PR0501MB1772.namprd05.prod.outlook.com>
	<CAEBQMM=QON_LKAC8z9UMvUwBSu3+q3EcJzNKPkmn==jvS+9cCQ@mail.gmail.com>
	<CY1PR0501MB1772661FD5CC5C18111F3DB999940@CY1PR0501MB1772.namprd05.prod.outlook.com>
Message-ID: <CAEBQMMmDZXP7K+6U8AAYrb5BOpPaVuc5_GSF9cQrdA8RciGDkA@mail.gmail.com>

And this is for a raster with around 5 milliion cells? Your results
surprise me a bit, especially if the bottleneck is at the call to
buffer()/distance().  Your best bet is to wait for a response from Robert
Hijmans or someone else working on the package, they might have some other
tricks up their sleeves. In any case, I agree, 5+ hours is extremely
excessive.

Sincerely,
Forrest

On Mon, Apr 11, 2016 at 6:57 PM Nelly Reduan <nell.redu at hotmail.fr> wrote:

> Thank you very much Forrest for your answer. I don't think I have memory
> problems (my computer has a 32 GB memory).
>
>
> Here is my code to draw the 100-m buffers with the function "buffer"
> (package raster):
>
> r1 <- r ## r is the original raster and has a resolution of 10m
> r1[(r1[]!=2 & r1[]!=5)]=NA
> plot(r1)
> r2 <- buffer(r1, 10)
>
>
> I also tested the function distance (package raster):
>
> r1 <- r ## r is the original raster and has a resolution of 10m
> r1[(r1[]!=2 & r1[]!=5)]=NA
> plot(r1)
> r3 <- distance(r1)
>
>
> In the two cases, I stopped the functions afer 5 hours as this was too
> long ! For the moment, I haven't find solutions.
>
>
> Thanks a lot for your time.
>
> Have a nice day.
>
> Nell
>
>
>
>
> ------------------------------
> *De :* Forrest Stevens <r-sig-geo at forreststevens.com>
> *Envoy? :* lundi 11 avril 2016 09:09
> *? :* Nelly Reduan; r-sig-geo at r-project.org
> *Objet :* Re: [R-sig-Geo] How to reduce the buffering time with the
> function "buffer" (package raster)
>
> Five million cells isn't all that many, how slow is too slow? Buffering a
> raster of about 10 million cells on my laptop takes on the order of 20
> seconds or so for a binary raster. Is it possible that you're fighting
> memory problems?
>
> In the past when doing multiple ring buffers I've found it faster to
> calculate a distance-to raster first, and then apply multiple logical
> comparisons on the distance raster.  I don't know if this applies to your
> situation or not but it's one trick that might help.
>
> Sincerely,
> Forrest
>
> On Mon, Apr 11, 2016 at 10:58 AM Nelly Reduan <nell.redu at hotmail.fr>
> wrote:
>
>> Hello,
>>
>>
>> I would like to build 100-m buffers (representing ecological corridors)
>> around land cover attributes in a raster layer and to assign a given value
>> (i.e., value of 13) to buffer cells.
>>
>>
>> To do this, I'm using the function "buffer" (package raster) to draw the
>> buffers around particular raster cells (i.e., cell values of 2 and 5). For
>> example, in the image below, the buffers are represented in blue (cell
>> values of 13) and the particular raster cells are represented in yellow
>> (cell values of 2).
>>
>>
>> The problem is that the time to run the function "buffer" is very low
>> because I have a raster of 5000000 cells. Does anyone know how I can reduce
>> the buffering time ?
>>
>>
>> Thanks a lot for your time.
>>
>> Have a nice day.
>>
>> Nell
>>
>> [image: Capture.PNG]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160412/22c1a547/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Capture.PNG
Type: image/png
Size: 12209 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160412/22c1a547/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Capture.PNG
Type: image/png
Size: 12209 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160412/22c1a547/attachment-0001.png>

From Roger.Bivand at nhh.no  Tue Apr 12 10:53:45 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 12 Apr 2016 10:53:45 +0200
Subject: [R-sig-Geo] Fwd: Error is spdep spautolm()
In-Reply-To: <CAKY_pX5d+Csyd2S4RkD_xUXdaeyXXSmNTLsbPsD5ydwRDXy1vA@mail.gmail.com>
References: <CAKY_pX67HevwVCcqjpy8dLbJ=xEmEWvVtPrS09xtGRAQ0bJXfw@mail.gmail.com>
	<CAKY_pX7c745CN1zBAQOXiYEXcrsJDhUXHqQF9xmX-1-A6ZnzLw@mail.gmail.com>
	<CAKY_pX5d+Csyd2S4RkD_xUXdaeyXXSmNTLsbPsD5ydwRDXy1vA@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1604121022400.13223@reclus.nhh.no>

On Tue, 12 Apr 2016, Samar Deen wrote:

> I was running a CAR with different inputs into the function, but have a few
> errors that I am unable to resolve.
>
> CAR1 = spautolm(s2008 ~ 1, data = df4, listw = gab.nhbr.listw,
> + weights = 1, family = "CAR")
> Error in model.frame.default(formula = s2008 ~ 1, data = df4, weights = 1,
> :
>  variable lengths differ (found for '(weights)')

This is trivial, input weights must be of the same length as the number of 
observations.

> weights <- 1
> length(weights)
[1] 1

... more below

>
> CAR1 = spautolm(s2008 ~ 1, data = df4, listw = gab.nhbr.listw,
> + weights = tempmean, family = "CAR")
> Error in validObject(.Object) :
>  invalid class ?dgRMatrix? object: slot j is not increasing inside a column
>
> Here in both cases I used a Delaunay Triangulation to determine neighbors
> and also made the neighbors symmetric using the command:
>
> nc_nb.tri <- make.sym.nb(nc_nb.tri)
>
> In my code I also have other methods for determining the neighbors. I seem
> to be getting different errors for all.
>
> I would really appreciate any guidance on how I may resolve this error.

(I have access to the data from an earlier offline exchange involving 
issues with missing data)

The points are (most likely) in geographical coordinates, so almost all 
of your attempts to create neighbour objects are wrong - all graph methods 
are only on the plane. Distances can be used when longlat=TRUE only.

Your use of scaled inverted spatial weights is contorted and the declared 
listw object style wrong, this ought to be sufficient:

gab.dist.sinv <- lapply(gab.dist, function(x) min(unlist(gab.dist))/x)

Much seems to have been copied from a script detailing analysis of the NC 
SIDS data set (the 30 mile threshold was used there).

It isn't obvious what you are trying to do.

Roger

>
> Any help will be really appreciated.
>
> Thank you & Regards,
>
> My code is pasted below:
>
> library(Matrix)
> library(spdep)
> library(RColorBrewer)
>
> #Get cents3
> setwd("~/Desktop/Flounder")
> cents3 <- read.csv("cents3.csv")
>
> #Subset the relevant data
> df=data.frame(cents3)
> df2 <- subset(df, select = c(8,9,41,49,50))
> df3 <- df2[complete.cases(df2), ]
> df4 <- na.omit(df3)
> coordinates(df4) = c("x","y")
>
> ##SET the neighbours
> coords = coordinates(df4)
> IDs = row.names(data.frame(df4))
>
> # Delaunay Triangulation
>
> nc_nb.tri = tri2nb(coords,row.names=IDs)
> nc_nb.tri <- make.sym.nb(nc_nb.tri)
> #
> plot(df4, border = "grey")
> plot(nc_nb.tri, coordinates(df4), add = TRUE, col = "blue")
>
> # Sphere of Influence
>
> nc_nb.soi = graph2nb(soi.graph(nc_nb.tri,coords),row.names=IDs)
> nc_nb.soi <- make.sym.nb(nc_nb.soi)
>
> #
> plot(df4, border = "grey")
> plot(nc_nb.soi, coordinates(df4), add = TRUE, col = "blue")
>
> # Relative Graph
> #
> nc_nb.relative = graph2nb(relativeneigh(coords),row.names=IDs)
> #
> plot(df4, border = "grey")
> plot(nc_nb.relative, coordinates(df4), add = TRUE, col = "blue")
> #
> # Neighbors based on distance (Here all neighbors withing 30 miles
> # This one is a bit messy
> nc_nb.dnn = dnearneigh(cbind(df4$x,df4$y),0,2,row.names=IDs)
> #
> plot(df4, border = "grey")
> plot(nc_nb.dnn, coordinates(df4), add = TRUE, col = "blue")
> #
> # K nearest neighbors
> #
> nc_nb.knn = knn2nb(knearneigh(coordinates(df4),k=5),row.names=IDs)
> nc_nb.knn <- make.sym.nb(nc_nb.knn)
> #
> plot(df4, border = "grey")
> plot(nc_nb.knn, coordinates(df4), add = TRUE, col = "blue")
> #
>
> #7- Making Neighborhood Wieghts
> #
> # Compute distances between neighbors
>
> gab.dist = nbdists(nc_nb.tri, cbind(df4$x, df4$y))
> #
> # Create a spatial neighbor object from weights object
> # using inverse distance weighting, style B gives equal weights to the
> nrihbors
> gab.nhbr = listw2sn(nb2listw(nc_nb.tri, glist = gab.dist,
>                             style = "U", zero.policy = TRUE))
> #
> # The distance between neighbor i and j
> dij = gab.nhbr[, 3]
> #
> # SSTobserved
> n = df4$tempmean
> #
> # Scaled inverse distance
> el1 = min(dij)/dij
> #
> # Square root of ratio of central fish to neighbor fish quantities
> #not needed
> el2 = sqrt(n[gab.nhbr$to]/n[gab.nhbr$from])
> #
> # Combine distance and birth weightings
> gab.nhbr$weights = el1
> #
> # Create spatial weights object from spatial neighbor object
> gab.nhbr.listw = sn2listw(gab.nhbr)
>
> gab.nhbr.listw$style <- "W"
>
> #8- CAR with no predictor
> #when wieght = 1 it will be propotional to the variance-
> #since it is a standardized survey across the region we can assume it is 1
>
> CAR1 = spautolm(s2008 ~ tempmean, data = df4, listw = gab.nhbr.listw,
>               verbose = TRUE, family = "CAR", method = "Matrix_J")
>
> CAR1 = spautolm(s2008 ~ 1, data = df4, listw = gab.nhbr.listw,
>                weights = 1, family = "CAR")
>
> summary(CAR1)
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412

From Roger.Bivand at nhh.no  Tue Apr 12 12:40:19 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 12 Apr 2016 12:40:19 +0200
Subject: [R-sig-Geo] Fwd: Error is spdep spautolm()
In-Reply-To: <alpine.LFD.2.20.1604121022400.13223@reclus.nhh.no>
References: <CAKY_pX67HevwVCcqjpy8dLbJ=xEmEWvVtPrS09xtGRAQ0bJXfw@mail.gmail.com>
	<CAKY_pX7c745CN1zBAQOXiYEXcrsJDhUXHqQF9xmX-1-A6ZnzLw@mail.gmail.com>
	<CAKY_pX5d+Csyd2S4RkD_xUXdaeyXXSmNTLsbPsD5ydwRDXy1vA@mail.gmail.com>
	<alpine.LFD.2.20.1604121022400.13223@reclus.nhh.no>
Message-ID: <alpine.LFD.2.20.1604121238520.13223@reclus.nhh.no>

On Tue, 12 Apr 2016, Roger Bivand wrote:

> On Tue, 12 Apr 2016, Samar Deen wrote:
>
>>  I was running a CAR with different inputs into the function, but have a
>>  few
>>  errors that I am unable to resolve.
>>
>>  CAR1 = spautolm(s2008 ~ 1, data = df4, listw = gab.nhbr.listw,
>>  + weights = 1, family = "CAR")
>>  Error in model.frame.default(formula = s2008 ~ 1, data = df4, weights = 1,
>>  :
>>   variable lengths differ (found for '(weights)')
>
> This is trivial, input weights must be of the same length as the number of 
> observations.
>
>>  weights <- 1
>>  length(weights)
> [1] 1
>
> ... more below
>
>>
>>  CAR1 = spautolm(s2008 ~ 1, data = df4, listw = gab.nhbr.listw,
>>  + weights = tempmean, family = "CAR")
>>  Error in validObject(.Object) :
>>   invalid class ?dgRMatrix? object: slot j is not increasing inside a
>>   column

This was a long-standing and previously unknown bug in sn2listw() used 
inside tri2nb(), and a new release of spdep has been submitted to CRAN.

Roger

>>
>>  Here in both cases I used a Delaunay Triangulation to determine neighbors
>>  and also made the neighbors symmetric using the command:
>>
>>  nc_nb.tri <- make.sym.nb(nc_nb.tri)
>>
>>  In my code I also have other methods for determining the neighbors. I seem
>>  to be getting different errors for all.
>>
>>  I would really appreciate any guidance on how I may resolve this error.
>
> (I have access to the data from an earlier offline exchange involving issues 
> with missing data)
>
> The points are (most likely) in geographical coordinates, so almost all of 
> your attempts to create neighbour objects are wrong - all graph methods are 
> only on the plane. Distances can be used when longlat=TRUE only.
>
> Your use of scaled inverted spatial weights is contorted and the declared 
> listw object style wrong, this ought to be sufficient:
>
> gab.dist.sinv <- lapply(gab.dist, function(x) min(unlist(gab.dist))/x)
>
> Much seems to have been copied from a script detailing analysis of the NC 
> SIDS data set (the 30 mile threshold was used there).
>
> It isn't obvious what you are trying to do.
>
> Roger
>
>>
>>  Any help will be really appreciated.
>>
>>  Thank you & Regards,
>>
>>  My code is pasted below:
>>
>>  library(Matrix)
>>  library(spdep)
>>  library(RColorBrewer)
>>
>>  #Get cents3
>>  setwd("~/Desktop/Flounder")
>>  cents3 <- read.csv("cents3.csv")
>>
>>  #Subset the relevant data
>>  df=data.frame(cents3)
>>  df2 <- subset(df, select = c(8,9,41,49,50))
>>  df3 <- df2[complete.cases(df2), ]
>>  df4 <- na.omit(df3)
>>  coordinates(df4) = c("x","y")
>>
>>  ##SET the neighbours
>>  coords = coordinates(df4)
>>  IDs = row.names(data.frame(df4))
>>
>>  # Delaunay Triangulation
>>
>>  nc_nb.tri = tri2nb(coords,row.names=IDs)
>>  nc_nb.tri <- make.sym.nb(nc_nb.tri)
>>  #
>>  plot(df4, border = "grey")
>>  plot(nc_nb.tri, coordinates(df4), add = TRUE, col = "blue")
>>
>>  # Sphere of Influence
>>
>>  nc_nb.soi = graph2nb(soi.graph(nc_nb.tri,coords),row.names=IDs)
>>  nc_nb.soi <- make.sym.nb(nc_nb.soi)
>>
>>  #
>>  plot(df4, border = "grey")
>>  plot(nc_nb.soi, coordinates(df4), add = TRUE, col = "blue")
>> 
>> #  Relative Graph
>> #
>>  nc_nb.relative = graph2nb(relativeneigh(coords),row.names=IDs)
>>  #
>>  plot(df4, border = "grey")
>>  plot(nc_nb.relative, coordinates(df4), add = TRUE, col = "blue")
>> # 
>> #  Neighbors based on distance (Here all neighbors withing 30 miles
>> #  This one is a bit messy
>>  nc_nb.dnn = dnearneigh(cbind(df4$x,df4$y),0,2,row.names=IDs)
>>  #
>>  plot(df4, border = "grey")
>>  plot(nc_nb.dnn, coordinates(df4), add = TRUE, col = "blue")
>> # 
>> #  K nearest neighbors
>> #
>>  nc_nb.knn = knn2nb(knearneigh(coordinates(df4),k=5),row.names=IDs)
>>  nc_nb.knn <- make.sym.nb(nc_nb.knn)
>>  #
>>  plot(df4, border = "grey")
>>  plot(nc_nb.knn, coordinates(df4), add = TRUE, col = "blue")
>>  #
>>
>>  #7- Making Neighborhood Wieghts
>> # 
>> # Compute distances between neighbors
>>
>>  gab.dist = nbdists(nc_nb.tri, cbind(df4$x, df4$y))
>> # 
>> #  Create a spatial neighbor object from weights object
>> #  using inverse distance weighting, style B gives equal weights to the
>>  nrihbors
>>  gab.nhbr = listw2sn(nb2listw(nc_nb.tri, glist = gab.dist,
>>                              style = "U", zero.policy = TRUE))
>> # 
>> # The distance between neighbor i and j
>>  dij = gab.nhbr[, 3]
>> # 
>> # SSTobserved
>>  n = df4$tempmean
>> # 
>> # Scaled inverse distance
>>  el1 = min(dij)/dij
>> # 
>> # Square root of ratio of central fish to neighbor fish quantities
>> # not needed
>>  el2 = sqrt(n[gab.nhbr$to]/n[gab.nhbr$from])
>> # 
>> # Combine distance and birth weightings
>>  gab.nhbr$weights = el1
>> # 
>> # Create spatial weights object from spatial neighbor object
>>  gab.nhbr.listw = sn2listw(gab.nhbr)
>>
>>  gab.nhbr.listw$style <- "W"
>>
>>  #8- CAR with no predictor
>> # when wieght = 1 it will be propotional to the variance-
>> # since it is a standardized survey across the region we can assume it is 1
>>
>>  CAR1 = spautolm(s2008 ~ tempmean, data = df4, listw = gab.nhbr.listw,
>>                verbose = TRUE, family = "CAR", method = "Matrix_J")
>>
>>  CAR1 = spautolm(s2008 ~ 1, data = df4, listw = gab.nhbr.listw,
>>                 weights = 1, family = "CAR")
>>
>>  summary(CAR1)
>>
>>   [[alternative HTML version deleted]]
>>
>>  _______________________________________________
>>  R-sig-Geo mailing list
>>  R-sig-Geo at r-project.org
>>  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412

From nell.redu at hotmail.fr  Tue Apr 12 18:33:05 2016
From: nell.redu at hotmail.fr (Nelly Reduan)
Date: Tue, 12 Apr 2016 16:33:05 +0000
Subject: [R-sig-Geo] How to reduce the buffering time with the function
 "buffer" (package raster)
In-Reply-To: <CAEBQMMmDZXP7K+6U8AAYrb5BOpPaVuc5_GSF9cQrdA8RciGDkA@mail.gmail.com>
References: <CY1PR0501MB1772C3ADEB76DE9BF66FA42299940@CY1PR0501MB1772.namprd05.prod.outlook.com>
	<CAEBQMM=QON_LKAC8z9UMvUwBSu3+q3EcJzNKPkmn==jvS+9cCQ@mail.gmail.com>
	<CY1PR0501MB1772661FD5CC5C18111F3DB999940@CY1PR0501MB1772.namprd05.prod.outlook.com>,
	<CAEBQMMmDZXP7K+6U8AAYrb5BOpPaVuc5_GSF9cQrdA8RciGDkA@mail.gmail.com>
Message-ID: <CY1PR0501MB177226E5AECCB30C7DA2086599950@CY1PR0501MB1772.namprd05.prod.outlook.com>

Yes, I tested the functions "distance" and "buffer" by using a cropped raster with around 5 million cells. But my original raster has 48096864 cells. Ideally, I would like to build the buffers from my original raster. Here are some characteristics of the original raster:


class       : RasterLayer

dimensions  : 4876, 9864, 48096864  (nrow, ncol, ncell)

extent      : 188384.5, 484304.5, 4914481, 5060761  (xmin, xmax, ymin, ymax)

coord. ref. : +proj=tmerc +lat_0=0 +lon_0=-73.5 +k=0.9999 +x_0=304800 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs


Thanks a lot for your help.

Have a nice day.

Nell



________________________________
De : Forrest Stevens <r-sig-geo at forreststevens.com>
Envoy? : lundi 11 avril 2016 18:55
? : Nelly Reduan; Forrest Stevens; r-sig-geo at r-project.org
Objet : Re: [R-sig-Geo] How to reduce the buffering time with the function "buffer" (package raster)

And this is for a raster with around 5 milliion cells? Your results surprise me a bit, especially if the bottleneck is at the call to buffer()/distance().  Your best bet is to wait for a response from Robert Hijmans or someone else working on the package, they might have some other tricks up their sleeves. In any case, I agree, 5+ hours is extremely excessive.

Sincerely,
Forrest

On Mon, Apr 11, 2016 at 6:57 PM Nelly Reduan <nell.redu at hotmail.fr<mailto:nell.redu at hotmail.fr>> wrote:

Thank you very much Forrest for your answer. I don't think I have memory problems (my computer has a 32 GB memory).


Here is my code to draw the 100-m buffers with the function "buffer" (package raster):

r1 <- r ## r is the original raster and has a resolution of 10m
r1[(r1[]!=2 & r1[]!=5)]=NA
plot(r1)
r2 <- buffer(r1, 10)


I also tested the function distance (package raster):

r1 <- r ## r is the original raster and has a resolution of 10m
r1[(r1[]!=2 & r1[]!=5)]=NA
plot(r1)
r3 <- distance(r1)


In the two cases, I stopped the functions afer 5 hours as this was too long ! For the moment, I haven't find solutions.


Thanks a lot for your time.

Have a nice day.

Nell



________________________________
De : Forrest Stevens <r-sig-geo at forreststevens.com<mailto:r-sig-geo at forreststevens.com>>
Envoy? : lundi 11 avril 2016 09:09
? : Nelly Reduan; r-sig-geo at r-project.org<mailto:r-sig-geo at r-project.org>
Objet : Re: [R-sig-Geo] How to reduce the buffering time with the function "buffer" (package raster)

Five million cells isn't all that many, how slow is too slow? Buffering a raster of about 10 million cells on my laptop takes on the order of 20 seconds or so for a binary raster. Is it possible that you're fighting memory problems?

In the past when doing multiple ring buffers I've found it faster to calculate a distance-to raster first, and then apply multiple logical comparisons on the distance raster.  I don't know if this applies to your situation or not but it's one trick that might help.

Sincerely,
Forrest

On Mon, Apr 11, 2016 at 10:58 AM Nelly Reduan <nell.redu at hotmail.fr<mailto:nell.redu at hotmail.fr>> wrote:

Hello,


I would like to build 100-m buffers (representing ecological corridors) around land cover attributes in a raster layer and to assign a given value (i.e., value of 13) to buffer cells.


To do this, I'm using the function "buffer" (package raster) to draw the buffers around particular raster cells (i.e., cell values of 2 and 5). For example, in the image below, the buffers are represented in blue (cell values of 13) and the particular raster cells are represented in yellow (cell values of 2).


The problem is that the time to run the function "buffer" is very low because I have a raster of 5000000 cells. Does anyone know how I can reduce the buffering time ?


Thanks a lot for your time.

Have a nice day.

Nell


[Capture.PNG]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From tiernanmartin at gmail.com  Tue Apr 12 21:42:22 2016
From: tiernanmartin at gmail.com (Tiernan Martin)
Date: Tue, 12 Apr 2016 19:42:22 +0000
Subject: [R-sig-Geo] Drawing the maximum-area rectangle in a non-convex
	polygon
Message-ID: <CAEo23y7cPO9JCWUcKFhbkzFfUJU66bMKEvrPeMZkeg13tNTepA@mail.gmail.com>

Does anyone know if there is an R package out there with an algorithm which
finds the maximum-area rectangle that can fit within a non-convex polygon?
I have Googled, searched the R Sig Geo archives, and created a post on the
GIS Stackexchange to no avail.

Here is an example of the type of output I am looking for:
http://d3plus.org/assets/posts/largestRect/img/solution.png

As you can probably infer from the image, the algorithm searches for the
rectangle with the largest area that will fit within the boundary of the
non-convex polygon. My project will be applying this analysis to a set of
parcels (aka plots, plats, or cadastres) in order to estimate the footprint
of a largest rectangular building that could be built on each parcel. The
image linked above comes from the following post which showcases the type
of algorithm that would be useful for my project:
http://d3plus.org/blog/behind-the-scenes/2014/07/08/largest-rect/

Is there an existing R package that I could use to conduct such an analysis
of several non-convex polygon? Or perhaps a set of functions from a
combination of packages?

Thank you in advance,

Tiernan

PS ? here's a link to my (very similarly worded) SO post:
http://gis.stackexchange.com/questions/186881/is-there-an-r-package-for-finding-the-largest-rectangle-in-a-non-convex-polygon

	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Tue Apr 12 22:57:56 2016
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 12 Apr 2016 21:57:56 +0100
Subject: [R-sig-Geo] Drawing the maximum-area rectangle in a non-convex
	polygon
In-Reply-To: <CAEo23y7cPO9JCWUcKFhbkzFfUJU66bMKEvrPeMZkeg13tNTepA@mail.gmail.com>
References: <CAEo23y7cPO9JCWUcKFhbkzFfUJU66bMKEvrPeMZkeg13tNTepA@mail.gmail.com>
Message-ID: <CANVKczPG+ej0bHsXh2xKf=eJEUk3ksyrd-wOLjdadPdRj1sz2Q@mail.gmail.com>

Could you simply use the Javascript code in that web page via one of
the R-Javascript interface packages?

On Tue, Apr 12, 2016 at 8:42 PM, Tiernan Martin <tiernanmartin at gmail.com> wrote:
> Does anyone know if there is an R package out there with an algorithm which
> finds the maximum-area rectangle that can fit within a non-convex polygon?
> I have Googled, searched the R Sig Geo archives, and created a post on the
> GIS Stackexchange to no avail.
>
> Here is an example of the type of output I am looking for:
> http://d3plus.org/assets/posts/largestRect/img/solution.png
>
> As you can probably infer from the image, the algorithm searches for the
> rectangle with the largest area that will fit within the boundary of the
> non-convex polygon. My project will be applying this analysis to a set of
> parcels (aka plots, plats, or cadastres) in order to estimate the footprint
> of a largest rectangular building that could be built on each parcel. The
> image linked above comes from the following post which showcases the type
> of algorithm that would be useful for my project:
> http://d3plus.org/blog/behind-the-scenes/2014/07/08/largest-rect/
>
> Is there an existing R package that I could use to conduct such an analysis
> of several non-convex polygon? Or perhaps a set of functions from a
> combination of packages?
>
> Thank you in advance,
>
> Tiernan
>
> PS ? here's a link to my (very similarly worded) SO post:
> http://gis.stackexchange.com/questions/186881/is-there-an-r-package-for-finding-the-largest-rectangle-in-a-non-convex-polygon
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From tiernanmartin at gmail.com  Tue Apr 12 23:48:30 2016
From: tiernanmartin at gmail.com (Tiernan Martin)
Date: Tue, 12 Apr 2016 21:48:30 +0000
Subject: [R-sig-Geo] Drawing the maximum-area rectangle in a non-convex
	polygon
In-Reply-To: <CANVKczPG+ej0bHsXh2xKf=eJEUk3ksyrd-wOLjdadPdRj1sz2Q@mail.gmail.com>
References: <CAEo23y7cPO9JCWUcKFhbkzFfUJU66bMKEvrPeMZkeg13tNTepA@mail.gmail.com>
	<CANVKczPG+ej0bHsXh2xKf=eJEUk3ksyrd-wOLjdadPdRj1sz2Q@mail.gmail.com>
Message-ID: <CAEo23y7k1ME8HR0J0TR8x+Np8G4Xv3mfE1T_TvUaO+tFfk9VSg@mail.gmail.com>

Hi Barry ?

Are you referring to the javascript code detailed here:
http://d3plus.org/assets/posts/largestRect/src/largestRect.coffee ?

I don't know much about running javascript in R, but I would be willing to
give it a shot for this project. However, since this would be my first time
trying to run JS code in R (and given that the algorithm itself isn't
exactly a simple one) I thought I would start by querying the R user
community to see if there's already an R implementation of something
similar. It had also occurred to me that I could attempt to reimplement the
JS code using R functions, but that project quickly took me beyond my R
skill set.

It certainly seems to be the sort of spatial analysis problem that could be
applicable to lots of different projects, so I'm hoping to get some
feedback from folks with deeper understanding of programming and R ? or
simply to have someone point out a nicely packaged set of functions that
could do this analysis.

Thanks for your advice, Barry!



On Tue, Apr 12, 2016 at 1:57 PM Barry Rowlingson <
b.rowlingson at lancaster.ac.uk> wrote:

> Could you simply use the Javascript code in that web page via one of
> the R-Javascript interface packages?
>
> On Tue, Apr 12, 2016 at 8:42 PM, Tiernan Martin <tiernanmartin at gmail.com>
> wrote:
> > Does anyone know if there is an R package out there with an algorithm
> which
> > finds the maximum-area rectangle that can fit within a non-convex
> polygon?
> > I have Googled, searched the R Sig Geo archives, and created a post on
> the
> > GIS Stackexchange to no avail.
> >
> > Here is an example of the type of output I am looking for:
> > http://d3plus.org/assets/posts/largestRect/img/solution.png
> >
> > As you can probably infer from the image, the algorithm searches for the
> > rectangle with the largest area that will fit within the boundary of the
> > non-convex polygon. My project will be applying this analysis to a set of
> > parcels (aka plots, plats, or cadastres) in order to estimate the
> footprint
> > of a largest rectangular building that could be built on each parcel. The
> > image linked above comes from the following post which showcases the type
> > of algorithm that would be useful for my project:
> > http://d3plus.org/blog/behind-the-scenes/2014/07/08/largest-rect/
> >
> > Is there an existing R package that I could use to conduct such an
> analysis
> > of several non-convex polygon? Or perhaps a set of functions from a
> > combination of packages?
> >
> > Thank you in advance,
> >
> > Tiernan
> >
> > PS ? here's a link to my (very similarly worded) SO post:
> >
> http://gis.stackexchange.com/questions/186881/is-there-an-r-package-for-finding-the-largest-rectangle-in-a-non-convex-polygon
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From sa462 at cornell.edu  Wed Apr 13 04:54:26 2016
From: sa462 at cornell.edu (Samar Deen)
Date: Tue, 12 Apr 2016 22:54:26 -0400
Subject: [R-sig-Geo] Fwd: Error is spdep spautolm()
In-Reply-To: <alpine.LFD.2.20.1604121238520.13223@reclus.nhh.no>
References: <CAKY_pX67HevwVCcqjpy8dLbJ=xEmEWvVtPrS09xtGRAQ0bJXfw@mail.gmail.com>
	<CAKY_pX7c745CN1zBAQOXiYEXcrsJDhUXHqQF9xmX-1-A6ZnzLw@mail.gmail.com>
	<CAKY_pX5d+Csyd2S4RkD_xUXdaeyXXSmNTLsbPsD5ydwRDXy1vA@mail.gmail.com>
	<alpine.LFD.2.20.1604121022400.13223@reclus.nhh.no>
	<alpine.LFD.2.20.1604121238520.13223@reclus.nhh.no>
Message-ID: <CAKY_pX5wKRiT0NscLN78JODxmPF3VDixsnW4Zkh3qSx9MqB27g@mail.gmail.com>

Thank you. I made the recommended changes and the CAR function is now
working.
Regards,

On Tue, Apr 12, 2016 at 6:40 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Tue, 12 Apr 2016, Roger Bivand wrote:
>
> On Tue, 12 Apr 2016, Samar Deen wrote:
>>
>>  I was running a CAR with different inputs into the function, but have a
>>>  few
>>>  errors that I am unable to resolve.
>>>
>>>  CAR1 = spautolm(s2008 ~ 1, data = df4, listw = gab.nhbr.listw,
>>>  + weights = 1, family = "CAR")
>>>  Error in model.frame.default(formula = s2008 ~ 1, data = df4, weights =
>>> 1,
>>>  :
>>>   variable lengths differ (found for '(weights)')
>>>
>>
>> This is trivial, input weights must be of the same length as the number
>> of observations.
>>
>>  weights <- 1
>>>  length(weights)
>>>
>> [1] 1
>>
>> ... more below
>>
>>
>>>  CAR1 = spautolm(s2008 ~ 1, data = df4, listw = gab.nhbr.listw,
>>>  + weights = tempmean, family = "CAR")
>>>  Error in validObject(.Object) :
>>>   invalid class ?dgRMatrix? object: slot j is not increasing inside a
>>>   column
>>>
>>
> This was a long-standing and previously unknown bug in sn2listw() used
> inside tri2nb(), and a new release of spdep has been submitted to CRAN.
>
> Roger
>
>
>>>  Here in both cases I used a Delaunay Triangulation to determine
>>> neighbors
>>>  and also made the neighbors symmetric using the command:
>>>
>>>  nc_nb.tri <- make.sym.nb(nc_nb.tri)
>>>
>>>  In my code I also have other methods for determining the neighbors. I
>>> seem
>>>  to be getting different errors for all.
>>>
>>>  I would really appreciate any guidance on how I may resolve this error.
>>>
>>
>> (I have access to the data from an earlier offline exchange involving
>> issues with missing data)
>>
>> The points are (most likely) in geographical coordinates, so almost all
>> of your attempts to create neighbour objects are wrong - all graph methods
>> are only on the plane. Distances can be used when longlat=TRUE only.
>>
>> Your use of scaled inverted spatial weights is contorted and the declared
>> listw object style wrong, this ought to be sufficient:
>>
>> gab.dist.sinv <- lapply(gab.dist, function(x) min(unlist(gab.dist))/x)
>>
>> Much seems to have been copied from a script detailing analysis of the NC
>> SIDS data set (the 30 mile threshold was used there).
>>
>> It isn't obvious what you are trying to do.
>>
>> Roger
>>
>>
>>>  Any help will be really appreciated.
>>>
>>>  Thank you & Regards,
>>>
>>>  My code is pasted below:
>>>
>>>  library(Matrix)
>>>  library(spdep)
>>>  library(RColorBrewer)
>>>
>>>  #Get cents3
>>>  setwd("~/Desktop/Flounder")
>>>  cents3 <- read.csv("cents3.csv")
>>>
>>>  #Subset the relevant data
>>>  df=data.frame(cents3)
>>>  df2 <- subset(df, select = c(8,9,41,49,50))
>>>  df3 <- df2[complete.cases(df2), ]
>>>  df4 <- na.omit(df3)
>>>  coordinates(df4) = c("x","y")
>>>
>>>  ##SET the neighbours
>>>  coords = coordinates(df4)
>>>  IDs = row.names(data.frame(df4))
>>>
>>>  # Delaunay Triangulation
>>>
>>>  nc_nb.tri = tri2nb(coords,row.names=IDs)
>>>  nc_nb.tri <- make.sym.nb(nc_nb.tri)
>>>  #
>>>  plot(df4, border = "grey")
>>>  plot(nc_nb.tri, coordinates(df4), add = TRUE, col = "blue")
>>>
>>>  # Sphere of Influence
>>>
>>>  nc_nb.soi = graph2nb(soi.graph(nc_nb.tri,coords),row.names=IDs)
>>>  nc_nb.soi <- make.sym.nb(nc_nb.soi)
>>>
>>>  #
>>>  plot(df4, border = "grey")
>>>  plot(nc_nb.soi, coordinates(df4), add = TRUE, col = "blue")
>>>
>>> #  Relative Graph
>>> #
>>>  nc_nb.relative = graph2nb(relativeneigh(coords),row.names=IDs)
>>>  #
>>>  plot(df4, border = "grey")
>>>  plot(nc_nb.relative, coordinates(df4), add = TRUE, col = "blue")
>>> # #  Neighbors based on distance (Here all neighbors withing 30 miles
>>> #  This one is a bit messy
>>>  nc_nb.dnn = dnearneigh(cbind(df4$x,df4$y),0,2,row.names=IDs)
>>>  #
>>>  plot(df4, border = "grey")
>>>  plot(nc_nb.dnn, coordinates(df4), add = TRUE, col = "blue")
>>> # #  K nearest neighbors
>>> #
>>>  nc_nb.knn = knn2nb(knearneigh(coordinates(df4),k=5),row.names=IDs)
>>>  nc_nb.knn <- make.sym.nb(nc_nb.knn)
>>>  #
>>>  plot(df4, border = "grey")
>>>  plot(nc_nb.knn, coordinates(df4), add = TRUE, col = "blue")
>>>  #
>>>
>>>  #7- Making Neighborhood Wieghts
>>> # # Compute distances between neighbors
>>>
>>>  gab.dist = nbdists(nc_nb.tri, cbind(df4$x, df4$y))
>>> # #  Create a spatial neighbor object from weights object
>>> #  using inverse distance weighting, style B gives equal weights to the
>>>  nrihbors
>>>  gab.nhbr = listw2sn(nb2listw(nc_nb.tri, glist = gab.dist,
>>>                              style = "U", zero.policy = TRUE))
>>> # # The distance between neighbor i and j
>>>  dij = gab.nhbr[, 3]
>>> # # SSTobserved
>>>  n = df4$tempmean
>>> # # Scaled inverse distance
>>>  el1 = min(dij)/dij
>>> # # Square root of ratio of central fish to neighbor fish quantities
>>> # not needed
>>>  el2 = sqrt(n[gab.nhbr$to]/n[gab.nhbr$from])
>>> # # Combine distance and birth weightings
>>>  gab.nhbr$weights = el1
>>> # # Create spatial weights object from spatial neighbor object
>>>  gab.nhbr.listw = sn2listw(gab.nhbr)
>>>
>>>  gab.nhbr.listw$style <- "W"
>>>
>>>  #8- CAR with no predictor
>>> # when wieght = 1 it will be propotional to the variance-
>>> # since it is a standardized survey across the region we can assume it
>>> is 1
>>>
>>>  CAR1 = spautolm(s2008 ~ tempmean, data = df4, listw = gab.nhbr.listw,
>>>                verbose = TRUE, family = "CAR", method = "Matrix_J")
>>>
>>>  CAR1 = spautolm(s2008 ~ 1, data = df4, listw = gab.nhbr.listw,
>>>                 weights = 1, family = "CAR")
>>>
>>>  summary(CAR1)
>>>
>>>   [[alternative HTML version deleted]]
>>>
>>>  _______________________________________________
>>>  R-sig-Geo mailing list
>>>  R-sig-Geo at r-project.org
>>>  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>
>>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
> http://depsy.org/person/434412
>



-- 
Samar Deen

Summer Research Fellow,  Atkinson Center for a Sustainable Future
PhD Student, Department of Natural Resources, Cornell University
M.P.A. Cornell University, 2011

Phone: +1 607 793 4200
Skype ID: samarnasiruddeen

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Wed Apr 13 05:36:45 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 13 Apr 2016 03:36:45 +0000
Subject: [R-sig-Geo] How to reduce the buffering time with the function
 "buffer" (package raster)
In-Reply-To: <CY1PR0501MB177226E5AECCB30C7DA2086599950@CY1PR0501MB1772.namprd05.prod.outlook.com>
References: <CY1PR0501MB1772C3ADEB76DE9BF66FA42299940@CY1PR0501MB1772.namprd05.prod.outlook.com>
	<CAEBQMM=QON_LKAC8z9UMvUwBSu3+q3EcJzNKPkmn==jvS+9cCQ@mail.gmail.com>
	<CY1PR0501MB1772661FD5CC5C18111F3DB999940@CY1PR0501MB1772.namprd05.prod.outlook.com>
	<CAEBQMMmDZXP7K+6U8AAYrb5BOpPaVuc5_GSF9cQrdA8RciGDkA@mail.gmail.com>
	<CY1PR0501MB177226E5AECCB30C7DA2086599950@CY1PR0501MB1772.namprd05.prod.outlook.com>
Message-ID: <CAAcGz9_Ffof2x9+LfQnThZF14y-0VOk9_dUF5hmQmk=+fSMzTA@mail.gmail.com>

I think we still haven't seen a print of the raster object?

It may be a tiled file on disk? Try readAll to pull into memory, if it is
tiled and read in on demand via gdal tools like extract will be very slow
since access is done line by line.

But just guessing, please give full details and ideally a reproducible
example.

Cheers, Mije

On Wed, 13 Apr 2016, 02:33 Nelly Reduan <nell.redu at hotmail.fr> wrote:

> Yes, I tested the functions "distance" and "buffer" by using a cropped
> raster with around 5 million cells. But my original raster has 48096864
> cells. Ideally, I would like to build the buffers from my original raster.
> Here are some characteristics of the original raster:
>
>
> class       : RasterLayer
>
> dimensions  : 4876, 9864, 48096864  (nrow, ncol, ncell)
>
> extent      : 188384.5, 484304.5, 4914481, 5060761  (xmin, xmax, ymin,
> ymax)
>
> coord. ref. : +proj=tmerc +lat_0=0 +lon_0=-73.5 +k=0.9999 +x_0=304800
> +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs
>
>
> Thanks a lot for your help.
>
> Have a nice day.
>
> Nell
>
>
>
> ________________________________
> De : Forrest Stevens <r-sig-geo at forreststevens.com>
> Envoy? : lundi 11 avril 2016 18:55
> ? : Nelly Reduan; Forrest Stevens; r-sig-geo at r-project.org
> Objet : Re: [R-sig-Geo] How to reduce the buffering time with the function
> "buffer" (package raster)
>
> And this is for a raster with around 5 milliion cells? Your results
> surprise me a bit, especially if the bottleneck is at the call to
> buffer()/distance().  Your best bet is to wait for a response from Robert
> Hijmans or someone else working on the package, they might have some other
> tricks up their sleeves. In any case, I agree, 5+ hours is extremely
> excessive.
>
> Sincerely,
> Forrest
>
> On Mon, Apr 11, 2016 at 6:57 PM Nelly Reduan <nell.redu at hotmail.fr<mailto:
> nell.redu at hotmail.fr>> wrote:
>
> Thank you very much Forrest for your answer. I don't think I have memory
> problems (my computer has a 32 GB memory).
>
>
> Here is my code to draw the 100-m buffers with the function "buffer"
> (package raster):
>
> r1 <- r ## r is the original raster and has a resolution of 10m
> r1[(r1[]!=2 & r1[]!=5)]=NA
> plot(r1)
> r2 <- buffer(r1, 10)
>
>
> I also tested the function distance (package raster):
>
> r1 <- r ## r is the original raster and has a resolution of 10m
> r1[(r1[]!=2 & r1[]!=5)]=NA
> plot(r1)
> r3 <- distance(r1)
>
>
> In the two cases, I stopped the functions afer 5 hours as this was too
> long ! For the moment, I haven't find solutions.
>
>
> Thanks a lot for your time.
>
> Have a nice day.
>
> Nell
>
>
>
> ________________________________
> De : Forrest Stevens <r-sig-geo at forreststevens.com<mailto:
> r-sig-geo at forreststevens.com>>
> Envoy? : lundi 11 avril 2016 09:09
> ? : Nelly Reduan; r-sig-geo at r-project.org<mailto:r-sig-geo at r-project.org>
> Objet : Re: [R-sig-Geo] How to reduce the buffering time with the function
> "buffer" (package raster)
>
> Five million cells isn't all that many, how slow is too slow? Buffering a
> raster of about 10 million cells on my laptop takes on the order of 20
> seconds or so for a binary raster. Is it possible that you're fighting
> memory problems?
>
> In the past when doing multiple ring buffers I've found it faster to
> calculate a distance-to raster first, and then apply multiple logical
> comparisons on the distance raster.  I don't know if this applies to your
> situation or not but it's one trick that might help.
>
> Sincerely,
> Forrest
>
> On Mon, Apr 11, 2016 at 10:58 AM Nelly Reduan <nell.redu at hotmail.fr
> <mailto:nell.redu at hotmail.fr>> wrote:
>
> Hello,
>
>
> I would like to build 100-m buffers (representing ecological corridors)
> around land cover attributes in a raster layer and to assign a given value
> (i.e., value of 13) to buffer cells.
>
>
> To do this, I'm using the function "buffer" (package raster) to draw the
> buffers around particular raster cells (i.e., cell values of 2 and 5). For
> example, in the image below, the buffers are represented in blue (cell
> values of 13) and the particular raster cells are represented in yellow
> (cell values of 2).
>
>
> The problem is that the time to run the function "buffer" is very low
> because I have a raster of 5000000 cells. Does anyone know how I can reduce
> the buffering time ?
>
>
> Thanks a lot for your time.
>
> Have a nice day.
>
> Nell
>
>
> [Capture.PNG]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Wed Apr 13 13:51:09 2016
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 13 Apr 2016 12:51:09 +0100
Subject: [R-sig-Geo] Drawing the maximum-area rectangle in a non-convex
	polygon
In-Reply-To: <CAEo23y7k1ME8HR0J0TR8x+Np8G4Xv3mfE1T_TvUaO+tFfk9VSg@mail.gmail.com>
References: <CAEo23y7cPO9JCWUcKFhbkzFfUJU66bMKEvrPeMZkeg13tNTepA@mail.gmail.com>
	<CANVKczPG+ej0bHsXh2xKf=eJEUk3ksyrd-wOLjdadPdRj1sz2Q@mail.gmail.com>
	<CAEo23y7k1ME8HR0J0TR8x+Np8G4Xv3mfE1T_TvUaO+tFfk9VSg@mail.gmail.com>
Message-ID: <CANVKczPJoNP4yzzOwrfSX8365KaDKw0uBdjQm0NP_gwhWEvEHA@mail.gmail.com>

On Tue, Apr 12, 2016 at 10:48 PM, Tiernan Martin
<tiernanmartin at gmail.com> wrote:
> Hi Barry ?
>
> Are you referring to the javascript code detailed here:
> http://d3plus.org/assets/posts/largestRect/src/largestRect.coffee ?
>
> I don't know much about running javascript in R, but I would be willing to
> give it a shot for this project. However, since this would be my first time
> trying to run JS code in R (and given that the algorithm itself isn't
> exactly a simple one) I thought I would start by querying the R user
> community to see if there's already an R implementation of something
> similar. It had also occurred to me that I could attempt to reimplement the
> JS code using R functions, but that project quickly took me beyond my R
> skill set.

 Check out the V8 and js packages. That script you linked to is
actually CoffeeScript, but that's a thin shell around Javscript and
"transpiling" to JS is covered in the vignettes of the V8 and js
packages somewhere. Then all you need to do (hah!) is load the d3
javascript library into a V8 context, pass some parameters, and run...
Simple... ummm... maybe.


> It certainly seems to be the sort of spatial analysis problem that could be
> applicable to lots of different projects, so I'm hoping to get some
> feedback from folks with deeper understanding of programming and R ? or
> simply to have someone point out a nicely packaged set of functions that
> could do this analysis.

 I've had a quick look at the CoffeeScript and while it could be
converted to R there's a lot of looping and I suspect it might be
painfully slow unless you spend lots of time to consider the algorithm
so you can write it in properly idiomatic R. It might even benefit you
to rewrite it in C or C++....

Barry


From agrant11 at vols.utk.edu  Wed Apr 13 19:19:48 2016
From: agrant11 at vols.utk.edu (Grant, Alannie-Grace)
Date: Wed, 13 Apr 2016 10:19:48 -0700
Subject: [R-sig-Geo] Testing for differences in Niche Breadth using Levins'
 B calculated from Maxent SDMs
Message-ID: <CAO9AMNRMHGN84n9PYSpKF0sy9D7DZ7iAkpk7nd=aEaSScTmFMQ@mail.gmail.com>

Good Day R-Sig-Geo Friends,

I am interested in testing whether sister species pairs (species with trait
A vs species with trait B) have significant differences in niche breadth.

To do this, I have generated for each species pair 100 Maxent bootstrap
replicates. For each of these replicates I have calculated the niche
breadth using Levins' B from ENMTools.

Now I would like to use these values for a significance test. Is it
incorrect to use a t-test to look for difference between species pairs due
to the lack of independence of the replicates? Is it better to use a
nonparametric test? If so, why and what should the sample size be and which
test?

Finally, I am also interested to know whether groups of species with trait
A and groups of species with trait B have differences in niche breadth.
Using the same data above, what is the most appropriate statistical test
and appropriate sample size?

Sample data:

species A   species B0.168581128 0.0924769420.138468258
0.0975361750.16412658  0.1076619820.16371685  0.1032603730.162732326
0.1217574970.129050784 0.1130964890.126583781 0.1149817320.176855441
0.0993640140.257605323 0.1037768860.182453389 0.1082939280.175081388
0.106879389

Thanks for reading and I am very interested to know your suggestions.
Best,

-- 
Alannie-Grace Grant
Graduate Student
Kalisz Lab
University of Tennessee - Knoxville

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=oa-2200-a>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=oa-2200-a>
<#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From nell.redu at hotmail.fr  Thu Apr 14 03:17:25 2016
From: nell.redu at hotmail.fr (Nelly Reduan)
Date: Thu, 14 Apr 2016 01:17:25 +0000
Subject: [R-sig-Geo] How to reduce the buffering time with the function
 "buffer" (package raster)
In-Reply-To: <CAAcGz9_Ffof2x9+LfQnThZF14y-0VOk9_dUF5hmQmk=+fSMzTA@mail.gmail.com>
References: <CY1PR0501MB1772C3ADEB76DE9BF66FA42299940@CY1PR0501MB1772.namprd05.prod.outlook.com>
	<CAEBQMM=QON_LKAC8z9UMvUwBSu3+q3EcJzNKPkmn==jvS+9cCQ@mail.gmail.com>
	<CY1PR0501MB1772661FD5CC5C18111F3DB999940@CY1PR0501MB1772.namprd05.prod.outlook.com>
	<CAEBQMMmDZXP7K+6U8AAYrb5BOpPaVuc5_GSF9cQrdA8RciGDkA@mail.gmail.com>
	<CY1PR0501MB177226E5AECCB30C7DA2086599950@CY1PR0501MB1772.namprd05.prod.outlook.com>,
	<CAAcGz9_Ffof2x9+LfQnThZF14y-0VOk9_dUF5hmQmk=+fSMzTA@mail.gmail.com>
Message-ID: <CY1PR0501MB1772FE403FAFCFCBAE00AFC199960@CY1PR0501MB1772.namprd05.prod.outlook.com>

I put a cropped raster with 3581676 cells in the link below:


https://www.dropbox.com/sh/ewaz4yncdqt7kxj/AAAEHyuWyHzBE7gSINA1oayTa?dl=0


Here is my code to built the buffers:

rf <- clip_buff

rf [(rf != 2 & rf != 3)] <- NA

plot(rf)

system.time(corr <- buffer(rf, 10))

system.time(dist_rf <- distance(rf))


I stopped the code with the functions "buffer" and "distance" after two hours.


Thanks a lot for your time.

Have a nice day.

Nell



________________________________
De : Michael Sumner <mdsumner at gmail.com>
Envoy? : mardi 12 avril 2016 20:36
? : Nelly Reduan; Forrest Stevens; r-sig-geo at r-project.org
Objet : Re: [R-sig-Geo] How to reduce the buffering time with the function "buffer" (package raster)


I think we still haven't seen a print of the raster object?

It may be a tiled file on disk? Try readAll to pull into memory, if it is tiled and read in on demand via gdal tools like extract will be very slow since access is done line by line.

But just guessing, please give full details and ideally a reproducible example.

Cheers, Mije

On Wed, 13 Apr 2016, 02:33 Nelly Reduan <nell.redu at hotmail.fr<mailto:nell.redu at hotmail.fr>> wrote:
Yes, I tested the functions "distance" and "buffer" by using a cropped raster with around 5 million cells. But my original raster has 48096864 cells. Ideally, I would like to build the buffers from my original raster. Here are some characteristics of the original raster:


class       : RasterLayer

dimensions  : 4876, 9864, 48096864  (nrow, ncol, ncell)

extent      : 188384.5, 484304.5, 4914481, 5060761  (xmin, xmax, ymin, ymax)

coord. ref. : +proj=tmerc +lat_0=0 +lon_0=-73.5 +k=0.9999 +x_0=304800 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs


Thanks a lot for your help.

Have a nice day.

Nell



________________________________
De : Forrest Stevens <r-sig-geo at forreststevens.com<mailto:r-sig-geo at forreststevens.com>>
Envoy? : lundi 11 avril 2016 18:55
? : Nelly Reduan; Forrest Stevens; r-sig-geo at r-project.org<mailto:r-sig-geo at r-project.org>
Objet : Re: [R-sig-Geo] How to reduce the buffering time with the function "buffer" (package raster)

And this is for a raster with around 5 milliion cells? Your results surprise me a bit, especially if the bottleneck is at the call to buffer()/distance().  Your best bet is to wait for a response from Robert Hijmans or someone else working on the package, they might have some other tricks up their sleeves. In any case, I agree, 5+ hours is extremely excessive.

Sincerely,
Forrest

On Mon, Apr 11, 2016 at 6:57 PM Nelly Reduan <nell.redu at hotmail.fr<mailto:nell.redu at hotmail.fr><mailto:nell.redu at hotmail.fr<mailto:nell.redu at hotmail.fr>>> wrote:

Thank you very much Forrest for your answer. I don't think I have memory problems (my computer has a 32 GB memory).


Here is my code to draw the 100-m buffers with the function "buffer" (package raster):

r1 <- r ## r is the original raster and has a resolution of 10m
r1[(r1[]!=2 & r1[]!=5)]=NA
plot(r1)
r2 <- buffer(r1, 10)


I also tested the function distance (package raster):

r1 <- r ## r is the original raster and has a resolution of 10m
r1[(r1[]!=2 & r1[]!=5)]=NA
plot(r1)
r3 <- distance(r1)


In the two cases, I stopped the functions afer 5 hours as this was too long ! For the moment, I haven't find solutions.


Thanks a lot for your time.

Have a nice day.

Nell



________________________________
De : Forrest Stevens <r-sig-geo at forreststevens.com<mailto:r-sig-geo at forreststevens.com><mailto:r-sig-geo at forreststevens.com<mailto:r-sig-geo at forreststevens.com>>>
Envoy? : lundi 11 avril 2016 09:09
? : Nelly Reduan; r-sig-geo at r-project.org<mailto:r-sig-geo at r-project.org><mailto:r-sig-geo at r-project.org<mailto:r-sig-geo at r-project.org>>
Objet : Re: [R-sig-Geo] How to reduce the buffering time with the function "buffer" (package raster)

Five million cells isn't all that many, how slow is too slow? Buffering a raster of about 10 million cells on my laptop takes on the order of 20 seconds or so for a binary raster. Is it possible that you're fighting memory problems?

In the past when doing multiple ring buffers I've found it faster to calculate a distance-to raster first, and then apply multiple logical comparisons on the distance raster.  I don't know if this applies to your situation or not but it's one trick that might help.

Sincerely,
Forrest

On Mon, Apr 11, 2016 at 10:58 AM Nelly Reduan <nell.redu at hotmail.fr<mailto:nell.redu at hotmail.fr><mailto:nell.redu at hotmail.fr<mailto:nell.redu at hotmail.fr>>> wrote:

Hello,


I would like to build 100-m buffers (representing ecological corridors) around land cover attributes in a raster layer and to assign a given value (i.e., value of 13) to buffer cells.


To do this, I'm using the function "buffer" (package raster) to draw the buffers around particular raster cells (i.e., cell values of 2 and 5). For example, in the image below, the buffers are represented in blue (cell values of 13) and the particular raster cells are represented in yellow (cell values of 2).


The problem is that the time to run the function "buffer" is very low because I have a raster of 5000000 cells. Does anyone know how I can reduce the buffering time ?


Thanks a lot for your time.

Have a nice day.

Nell


[Capture.PNG]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org><mailto:R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo
--
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia


	[[alternative HTML version deleted]]


From r-sig-geo at forreststevens.com  Thu Apr 14 07:37:01 2016
From: r-sig-geo at forreststevens.com (Forrest Stevens)
Date: Thu, 14 Apr 2016 05:37:01 +0000
Subject: [R-sig-Geo] How to reduce the buffering time with the function
 "buffer" (package raster)
In-Reply-To: <CY1PR0501MB1772FE403FAFCFCBAE00AFC199960@CY1PR0501MB1772.namprd05.prod.outlook.com>
References: <CY1PR0501MB1772C3ADEB76DE9BF66FA42299940@CY1PR0501MB1772.namprd05.prod.outlook.com>
	<CAEBQMM=QON_LKAC8z9UMvUwBSu3+q3EcJzNKPkmn==jvS+9cCQ@mail.gmail.com>
	<CY1PR0501MB1772661FD5CC5C18111F3DB999940@CY1PR0501MB1772.namprd05.prod.outlook.com>
	<CAEBQMMmDZXP7K+6U8AAYrb5BOpPaVuc5_GSF9cQrdA8RciGDkA@mail.gmail.com>
	<CY1PR0501MB177226E5AECCB30C7DA2086599950@CY1PR0501MB1772.namprd05.prod.outlook.com>
	<CAAcGz9_Ffof2x9+LfQnThZF14y-0VOk9_dUF5hmQmk=+fSMzTA@mail.gmail.com>
	<CY1PR0501MB1772FE403FAFCFCBAE00AFC199960@CY1PR0501MB1772.namprd05.prod.outlook.com>
Message-ID: <CAEBQMM=+jQVff5Lhs0r==tr+-SnNmHFo8=j7kpaSG8FJLZDJFw@mail.gmail.com>

So you're correct, the buffer() and distance() functions you're using will
take a long period of time.  The code below illustrates the shortcut that
I've used in the past when buffering only by the limit of one pixel, since
it uses queens-case connectance and distance between cell-centers based on
that connectance rule. This uses the gridDistance() function which is much
faster than calculating straight line distances. You can see that the
distance-based calculation takes under 40 seconds. But do notice that the
buffer it creates by setting the threshold is around both classes and is
indiscriminate of the nearest class:

library(raster)

clip_buff <- raster("clip_study_area_2010.tif")

system.time(d <- gridDistance(clip_buff, c(2,3)))
#   user  system elapsed
#  37.36   11.00   48.41

rf[(rf != 2 & rf != 3)] <- NA

## Set buffer to 10m just for fun and assign
## value of 4 to that buffered region:
rf[ d > 0 & d <= 10 ] <- 4
plot(rf)

If you want to buffer by more than one pixel dimension then you'll probably
want straight line distances and I'd suggest using GDAL and using the
gdal_proximity utility via a system() call. Alternatively, you could look
into other utilities that have better-optimized raster-based distance
tools. Hopefully this gives you some ideas on how to proceed?

Sincerely,
Forrest


On Wed, Apr 13, 2016 at 9:18 PM Nelly Reduan <nell.redu at hotmail.fr> wrote:

> I put a cropped raster with 3581676 cells in the link below:
>
>
> https://www.dropbox.com/sh/ewaz4yncdqt7kxj/AAAEHyuWyHzBE7gSINA1oayTa?dl=0
>
> Here is my code to built the buffers:
>
> rf <- clip_buff
>
> rf [(rf != 2 & rf != 3)] <- NA
>
> plot(rf)
>
> system.time(corr <- buffer(rf, 10))
>
> system.time(dist_rf <- distance(rf))
>
>
> I stopped the code with the functions "buffer" and "distance" after two
> hours.
>
>
> Thanks a lot for your time.
>
> Have a nice day.
>
> Nell
>
>
>
>
> ------------------------------
> *De :* Michael Sumner <mdsumner at gmail.com>
> *Envoy? :* mardi 12 avril 2016 20:36
>
> *? :* Nelly Reduan; Forrest Stevens; r-sig-geo at r-project.org
> *Objet :* Re: [R-sig-Geo] How to reduce the buffering time with the
> function "buffer" (package raster)
>
> I think we still haven't seen a print of the raster object?
>
> It may be a tiled file on disk? Try readAll to pull into memory, if it is
> tiled and read in on demand via gdal tools like extract will be very slow
> since access is done line by line.
>
> But just guessing, please give full details and ideally a reproducible
> example.
>
> Cheers, Mije
>
> On Wed, 13 Apr 2016, 02:33 Nelly Reduan <nell.redu at hotmail.fr> wrote:
>
>> Yes, I tested the functions "distance" and "buffer" by using a cropped
>> raster with around 5 million cells. But my original raster has 48096864
>> cells. Ideally, I would like to build the buffers from my original raster.
>> Here are some characteristics of the original raster:
>>
>>
>> class       : RasterLayer
>>
>> dimensions  : 4876, 9864, 48096864  (nrow, ncol, ncell)
>>
>> extent      : 188384.5, 484304.5, 4914481, 5060761  (xmin, xmax, ymin,
>> ymax)
>>
>> coord. ref. : +proj=tmerc +lat_0=0 +lon_0=-73.5 +k=0.9999 +x_0=304800
>> +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs
>>
>>
>> Thanks a lot for your help.
>>
>> Have a nice day.
>>
>> Nell
>>
>>
>>
>> ________________________________
>> De : Forrest Stevens <r-sig-geo at forreststevens.com>
>> Envoy? : lundi 11 avril 2016 18:55
>> ? : Nelly Reduan; Forrest Stevens; r-sig-geo at r-project.org
>> Objet : Re: [R-sig-Geo] How to reduce the buffering time with the
>> function "buffer" (package raster)
>>
>> And this is for a raster with around 5 milliion cells? Your results
>> surprise me a bit, especially if the bottleneck is at the call to
>> buffer()/distance().  Your best bet is to wait for a response from Robert
>> Hijmans or someone else working on the package, they might have some other
>> tricks up their sleeves. In any case, I agree, 5+ hours is extremely
>> excessive.
>>
>> Sincerely,
>> Forrest
>>
>> On Mon, Apr 11, 2016 at 6:57 PM Nelly Reduan <nell.redu at hotmail.fr
>> <mailto:nell.redu at hotmail.fr>> wrote:
>>
>> Thank you very much Forrest for your answer. I don't think I have memory
>> problems (my computer has a 32 GB memory).
>>
>>
>> Here is my code to draw the 100-m buffers with the function "buffer"
>> (package raster):
>>
>> r1 <- r ## r is the original raster and has a resolution of 10m
>> r1[(r1[]!=2 & r1[]!=5)]=NA
>> plot(r1)
>> r2 <- buffer(r1, 10)
>>
>>
>> I also tested the function distance (package raster):
>>
>> r1 <- r ## r is the original raster and has a resolution of 10m
>> r1[(r1[]!=2 & r1[]!=5)]=NA
>> plot(r1)
>> r3 <- distance(r1)
>>
>>
>> In the two cases, I stopped the functions afer 5 hours as this was too
>> long ! For the moment, I haven't find solutions.
>>
>>
>> Thanks a lot for your time.
>>
>> Have a nice day.
>>
>> Nell
>>
>>
>>
>> ________________________________
>> De : Forrest Stevens <r-sig-geo at forreststevens.com<mailto:
>> r-sig-geo at forreststevens.com>>
>> Envoy? : lundi 11 avril 2016 09:09
>> ? : Nelly Reduan; r-sig-geo at r-project.org<mailto:r-sig-geo at r-project.org>
>> Objet : Re: [R-sig-Geo] How to reduce the buffering time with the
>> function "buffer" (package raster)
>>
>> Five million cells isn't all that many, how slow is too slow? Buffering a
>> raster of about 10 million cells on my laptop takes on the order of 20
>> seconds or so for a binary raster. Is it possible that you're fighting
>> memory problems?
>>
>> In the past when doing multiple ring buffers I've found it faster to
>> calculate a distance-to raster first, and then apply multiple logical
>> comparisons on the distance raster.  I don't know if this applies to your
>> situation or not but it's one trick that might help.
>>
>> Sincerely,
>> Forrest
>>
>> On Mon, Apr 11, 2016 at 10:58 AM Nelly Reduan <nell.redu at hotmail.fr
>> <mailto:nell.redu at hotmail.fr>> wrote:
>>
>> Hello,
>>
>>
>> I would like to build 100-m buffers (representing ecological corridors)
>> around land cover attributes in a raster layer and to assign a given value
>> (i.e., value of 13) to buffer cells.
>>
>>
>> To do this, I'm using the function "buffer" (package raster) to draw the
>> buffers around particular raster cells (i.e., cell values of 2 and 5). For
>> example, in the image below, the buffers are represented in blue (cell
>> values of 13) and the particular raster cells are represented in yellow
>> (cell values of 2).
>>
>>
>> The problem is that the time to run the function "buffer" is very low
>> because I have a raster of 5000000 cells. Does anyone know how I can reduce
>> the buffering time ?
>>
>>
>> Thanks a lot for your time.
>>
>> Have a nice day.
>>
>> Nell
>>
>>
>> [Capture.PNG]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
>

	[[alternative HTML version deleted]]


From bob at rudis.net  Thu Apr 14 14:23:16 2016
From: bob at rudis.net (boB Rudis)
Date: Thu, 14 Apr 2016 08:23:16 -0400
Subject: [R-sig-Geo] How to plot Geohash on a Map using R
In-Reply-To: <56D48CFA.1000007@uni-muenster.de>
References: <CADeUTLLxeR++yGk_d+mFtsZmnycESch_roMRPkbdEzuKd_c8tA@mail.gmail.com>
	<56D48CFA.1000007@uni-muenster.de>
Message-ID: <CAJ4QxaOPSC-0-zk_1Zx=i7M-__CWDjMY1C1mZyJ4k1fv5wdiqw@mail.gmail.com>

Two months later and Oliver Keyes took a suggestion I gave him
seriously and you now have a C++-backed super-fast geohashing package
to do what you need: https://github.com/Ironholds/geohash/

On Mon, Feb 29, 2016 at 1:24 PM, Edzer Pebesma
<edzer.pebesma at uni-muenster.de> wrote:
> Ravi, a student of mine worked on geohash support for R; see
>
> https://github.com/chk1/geohash
>
> On 29/02/16 18:58, Ravi Teja wrote:
>> Hi,
>>
>> I want to plot the following Geo-hashes on a map with labels as the
>> percentage against each Geohash.
>>
>> Geohash % distribution
>> ttngh 26.14%
>> ttnfu 17.67%
>> ttng5 12.31%
>> ttnfg 11.50%
>> ttnfv 14.10%
>> ttngk 7.33%
>> ttngm 2.14%
>> ttngj 6.06%
>> ttnft 1.32%
>> ttngs 0.75%
>> ttngn 0.27%
>> ttng7 0.20%
>> ttnge 0.15%
>> ttnfe 0.00%
>> ttnfs 0.04%
>> ttnfy 0.01%
>> Please let me know how this can be achieved.
>>
>> Thanks,
>> Ravi
>>
>>       [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Edzer Pebesma
> Institute for Geoinformatics  (ifgi),  University of M?nster
> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> Journal of Statistical Software:   http://www.jstatsoft.org/
> Computers & Geosciences:   http://elsevier.com/locate/cageo/
> Spatial Statistics Society http://www.spatialstatistics.info
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From mdsumner at gmail.com  Thu Apr 14 15:27:53 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 14 Apr 2016 13:27:53 +0000
Subject: [R-sig-Geo] How to plot Geohash on a Map using R
In-Reply-To: <CAJ4QxaOPSC-0-zk_1Zx=i7M-__CWDjMY1C1mZyJ4k1fv5wdiqw@mail.gmail.com>
References: <CADeUTLLxeR++yGk_d+mFtsZmnycESch_roMRPkbdEzuKd_c8tA@mail.gmail.com>
	<56D48CFA.1000007@uni-muenster.de>
	<CAJ4QxaOPSC-0-zk_1Zx=i7M-__CWDjMY1C1mZyJ4k1fv5wdiqw@mail.gmail.com>
Message-ID: <CAAcGz99TSxaGjwqk657LuEh6u=UPNv31pvtgMZ-f+8cgXPt1sA@mail.gmail.com>

On Thu, 14 Apr 2016 at 22:24 boB Rudis <bob at rudis.net> wrote:

> Two months later and Oliver Keyes took a suggestion I gave him
> seriously and you now have a C++-backed super-fast geohashing package
> to do what you need: https://github.com/Ironholds/geohash/
>
>
Though, be sure to wait for the next version on CRAN or install now
directly from GitHub:

devtools::install_github('Ironholds/geohash')

I just encountered a decode bug and see it was fixed ~40 minutes ago.

Thanks!



On Mon, Feb 29, 2016 at 1:24 PM, Edzer Pebesma
> <edzer.pebesma at uni-muenster.de> wrote:
> > Ravi, a student of mine worked on geohash support for R; see
> >
> > https://github.com/chk1/geohash
> >
> > On 29/02/16 18:58, Ravi Teja wrote:
> >> Hi,
> >>
> >> I want to plot the following Geo-hashes on a map with labels as the
> >> percentage against each Geohash.
> >>
> >> Geohash % distribution
> >> ttngh 26.14%
> >> ttnfu 17.67%
> >> ttng5 12.31%
> >> ttnfg 11.50%
> >> ttnfv 14.10%
> >> ttngk 7.33%
> >> ttngm 2.14%
> >> ttngj 6.06%
> >> ttnft 1.32%
> >> ttngs 0.75%
> >> ttngn 0.27%
> >> ttng7 0.20%
> >> ttnge 0.15%
> >> ttnfe 0.00%
> >> ttnfs 0.04%
> >> ttnfy 0.01%
> >> Please let me know how this can be achieved.
> >>
> >> Thanks,
> >> Ravi
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at r-project.org
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >
> > --
> > Edzer Pebesma
> > Institute for Geoinformatics  (ifgi),  University of M?nster
> > Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> > Journal of Statistical Software:   http://www.jstatsoft.org/
> > Computers & Geosciences:   http://elsevier.com/locate/cageo/
> > Spatial Statistics Society http://www.spatialstatistics.info
> >
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Thu Apr 14 15:54:16 2016
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 14 Apr 2016 14:54:16 +0100
Subject: [R-sig-Geo] Drawing the maximum-area rectangle in a non-convex
	polygon
In-Reply-To: <CANVKczPJoNP4yzzOwrfSX8365KaDKw0uBdjQm0NP_gwhWEvEHA@mail.gmail.com>
References: <CAEo23y7cPO9JCWUcKFhbkzFfUJU66bMKEvrPeMZkeg13tNTepA@mail.gmail.com>
	<CANVKczPG+ej0bHsXh2xKf=eJEUk3ksyrd-wOLjdadPdRj1sz2Q@mail.gmail.com>
	<CAEo23y7k1ME8HR0J0TR8x+Np8G4Xv3mfE1T_TvUaO+tFfk9VSg@mail.gmail.com>
	<CANVKczPJoNP4yzzOwrfSX8365KaDKw0uBdjQm0NP_gwhWEvEHA@mail.gmail.com>
Message-ID: <CANVKczMbMwsE_bzEq+5AoDX9QX3=5mtGBX29DAK0OYY3gxSRng@mail.gmail.com>

I've implemented this as a package now. Its on my gitlab account:

https://gitlab.com/b-rowlingson/maxrectangle

and you can install it with devtools.

And here's the example

Create a new JS context:

##' ctx = initjs()

Make a polygon:

##' th = seq(0,2*pi,len=11)[-11]
##' r = runif(10)
##' xy = cbind(r*cos(th), r*sin(th))
##' xy = rbind(xy, xy[1,])

Plot it:

##' plot(xy, type="l")

Call the JS:

##' lr = find_lr(ctx, xy)

Convert the return value and plot:

##' pp = plotrect(lr[[1]])
##' lines(pp)

At the moment the options to the JS, which sets things like number of
iterations and thresholds for deciding its found the biggest
rectangle, are ignored. So often you'll get a rectangle and go "Hey,
it could be a bit bigger!" which you might not get if you could tweak
the options a bit. If anyone wants to write code to pass the options
into the JS, pull requests are welcome.

I'm not sure what the license on the coffee script code is, I think
its BSD, which means its okay to use this like this. Will investigate.

Incidentally, the V8 package is a very slick interface to JS from R. Impressed.



Barry


On Wed, Apr 13, 2016 at 12:51 PM, Barry Rowlingson
<b.rowlingson at lancaster.ac.uk> wrote:
> On Tue, Apr 12, 2016 at 10:48 PM, Tiernan Martin
> <tiernanmartin at gmail.com> wrote:
>> Hi Barry ?
>>
>> Are you referring to the javascript code detailed here:
>> http://d3plus.org/assets/posts/largestRect/src/largestRect.coffee ?
>>
>> I don't know much about running javascript in R, but I would be willing to
>> give it a shot for this project. However, since this would be my first time
>> trying to run JS code in R (and given that the algorithm itself isn't
>> exactly a simple one) I thought I would start by querying the R user
>> community to see if there's already an R implementation of something
>> similar. It had also occurred to me that I could attempt to reimplement the
>> JS code using R functions, but that project quickly took me beyond my R
>> skill set.
>
>  Check out the V8 and js packages. That script you linked to is
> actually CoffeeScript, but that's a thin shell around Javscript and
> "transpiling" to JS is covered in the vignettes of the V8 and js
> packages somewhere. Then all you need to do (hah!) is load the d3
> javascript library into a V8 context, pass some parameters, and run...
> Simple... ummm... maybe.
>
>
>> It certainly seems to be the sort of spatial analysis problem that could be
>> applicable to lots of different projects, so I'm hoping to get some
>> feedback from folks with deeper understanding of programming and R ? or
>> simply to have someone point out a nicely packaged set of functions that
>> could do this analysis.
>
>  I've had a quick look at the CoffeeScript and while it could be
> converted to R there's a lot of looping and I suspect it might be
> painfully slow unless you spend lots of time to consider the algorithm
> so you can write it in properly idiomatic R. It might even benefit you
> to rewrite it in C or C++....
>
> Barry


From HodgessE at uhd.edu  Thu Apr 14 17:11:56 2016
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Thu, 14 Apr 2016 15:11:56 +0000
Subject: [R-sig-Geo] installing rgdal when gdal is in a non-standard location
Message-ID: <FF9DB805FC41CC4E95825A50F6806302B49EE808@columbia.uhd.campus>

Hello!

I'm trying to install rgdal and I have already installed gdal.  gdal is in a non-standard location, since I don't have administrative rights on this system.

I've seen how to use the configure.args with proj, but don't see anything for gdal.

Sorry for the dumb question!

Thanks,
Erin


	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Thu Apr 14 17:57:42 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 14 Apr 2016 17:57:42 +0200
Subject: [R-sig-Geo] installing rgdal when gdal is in a non-standard
 location
In-Reply-To: <FF9DB805FC41CC4E95825A50F6806302B49EE808@columbia.uhd.campus>
References: <FF9DB805FC41CC4E95825A50F6806302B49EE808@columbia.uhd.campus>
Message-ID: <alpine.LFD.2.20.1604141754380.5976@reclus.nhh.no>

On Thu, 14 Apr 2016, Hodgess, Erin wrote:

> Hello!
>
> I'm trying to install rgdal and I have already installed gdal.  gdal is 
> in a non-standard location, since I don't have administrative rights on 
> this system.
>
> I've seen how to use the configure.args with proj, but don't see 
> anything for gdal.

You'll need something like:

--with-gdal-config=/Library/Frameworks/GDAL.framework/unix/bin/gdal-config
  --with-proj-include=/Library/Frameworks/PROJ.framework/unix/include
  --with-proj-lib=/Library/Frameworks/PROJ.framework/unix/lib

(these values were for OSX some time ago, but the three values should be 
enough). For GDAL, the path to gdal-config is all that is needed. This is 
from system.file("README", package="rgdal"), but as you don't have rgdal 
installed, it's harder to find.

Hope this helps,

Roger

>
> Sorry for the dumb question!
>
> Thanks,
> Erin
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


From HodgessE at uhd.edu  Thu Apr 14 20:01:40 2016
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Thu, 14 Apr 2016 18:01:40 +0000
Subject: [R-sig-Geo] still having trouble with rgdal, please
Message-ID: <FF9DB805FC41CC4E95825A50F6806302B49EEAA1@columbia.uhd.campus>

First of all, thanks to Roger Bivand for his great suggestions!  I am making gradual progress.

However, not all is well yet.  One of my files from the gdal still seems to be missing:


> install.packages("rgdal",lib="/work/01260/ehodgess/Rlibs",configure.args=c('--with-gdal-config=/work/01260/ehodgess/gdal/bin/gdal-config --with-proj-include=/work/01260/ehodgess/proj4/include --with-proj-lib=/work/01260/ehodgess/proj4/lib'),depen=TRUE)
trying URL 'http://cran.revolutionanalytics.com/src/contrib/rgdal_1.1-8.tar.gz'
Content type 'application/octet-stream' length 1649879 bytes (1.6 MB)
==================================================
downloaded 1.6 MB

* installing *source* package 'rgdal' ...
** package 'rgdal' successfully unpacked and MD5 sums checked
configure: CC: gcc -std=gnu99
configure: CXX: g++
configure: rgdal: 1.1-8
checking for /usr/bin/svnversion... yes
configure: svn revision: 616
configure: gdal-config set to /work/01260/ehodgess/gdal/bin/gdal-config
checking gdal-config exists... yes
checking gdal-config executable... yes
checking gdal-config usability... yes
configure: GDAL: 2.0.2
checking GDAL version >= 1.6.3... yes
configure: experimental conditional use of GDAL2


a bunch of good stuff....


g++ -shared -L/usr/local/lib64 -o rgdal.so OGR_write.o gdal-bindings.o init.o local_stubs.o ogr_geom.o ogr_polygons.o ogr_proj.o ogrdrivers.o ogrsource.o projectit.o -L/work/01260/ehodgess/gdal/lib -lgdal -L/work/01260/ehodgess/proj4/lib -lproj
installing to /work/01260/ehodgess/Rlibs/rgdal/libs
** R
** data
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded
Error in dyn.load(file, DLLpath = DLLpath, ...) :
  unable to load shared object '/work/01260/ehodgess/Rlibs/rgdal/libs/rgdal.so':
  libgdal.so.20: cannot open shared object file: No such file or directory
Error: loading failed
Execution halted
ERROR: loading failed
* removing '/work/01260/ehodgess/Rlibs/rgdal'

The downloaded source packages are in
        '/tmp/RtmpXX2VTF/downloaded_packages'
Warning message:
In install.packages("rgdal", lib = "/work/01260/ehodgess/Rlibs",  :
  installation of package 'rgdal' had non-zero exit status
> system("echo $PATH")
/work/01260/ehodgess/custom-R-3.2.2/R-3.2.2/bin:/opt/apps/xalt/0.6/bin:/opt/apps/intel15/mvapich2/2.1/bin:/opt/apps/intel/15/composer_xe_2015.2.164/bin/intel64:
/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/opt/apps/xsede/gsi-openssh-5.7/bin:/usr/X11R6/bin:/opt/ofed/bin:/opt/ofed/sbin:.:/work/01260/ehodgess/gdal/bin:
/work/01260/ehodgess/gdal/lib
>

So it's saying that libgdal.so.20 is not found.  However, it is in gdal/lib, which is in the path.   (See last line).

Is there something else that I should be putting into the install.packages function, please?  I've tried all kinds of things (putting a copy of libgdal.so.20 into Rlibs, etc.), but no good.


Thanks,
Erin



Erin M. Hodgess, Ph.D.
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: hodgesse at uhd.edu<mailto:hodgesse at uhd.edu>


	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Thu Apr 14 20:47:31 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 14 Apr 2016 20:47:31 +0200
Subject: [R-sig-Geo] still having trouble with rgdal, please
In-Reply-To: <FF9DB805FC41CC4E95825A50F6806302B49EEAA1@columbia.uhd.campus>
References: <FF9DB805FC41CC4E95825A50F6806302B49EEAA1@columbia.uhd.campus>
Message-ID: <alpine.LFD.2.20.1604142041070.8453@reclus.nhh.no>

On Thu, 14 Apr 2016, Hodgess, Erin wrote:

> First of all, thanks to Roger Bivand for his great suggestions!  I am 
> making gradual progress.
>
> However, not all is well yet.  One of my files from the gdal still seems 
> to be missing:

Please read:

http://tldp.org/HOWTO/Program-Library-HOWTO/shared-libraries.html

and note that while you as non-super-user cannot use ldconfig to tell the 
system to look in the right place for libgdal.so (it was found during 
compilation and linking), you can set the environment 
variable LD_LIBRARY_PATH despite the weaknesses that this has compared to 
using ldconfig as super user. Running Sys.getenv("LD_LIBRARY_PATH") in R 
shows you that R sets it up for its own purposes anyway (mostly for the 
Java runtime engine).

Hope this helps,

Roger

>
>
>> install.packages("rgdal",lib="/work/01260/ehodgess/Rlibs",configure.args=c('--with-gdal-config=/work/01260/ehodgess/gdal/bin/gdal-config --with-proj-include=/work/01260/ehodgess/proj4/include --with-proj-lib=/work/01260/ehodgess/proj4/lib'),depen=TRUE)
> trying URL 'http://cran.revolutionanalytics.com/src/contrib/rgdal_1.1-8.tar.gz'
> Content type 'application/octet-stream' length 1649879 bytes (1.6 MB)
> ==================================================
> downloaded 1.6 MB
>
> * installing *source* package 'rgdal' ...
> ** package 'rgdal' successfully unpacked and MD5 sums checked
> configure: CC: gcc -std=gnu99
> configure: CXX: g++
> configure: rgdal: 1.1-8
> checking for /usr/bin/svnversion... yes
> configure: svn revision: 616
> configure: gdal-config set to /work/01260/ehodgess/gdal/bin/gdal-config
> checking gdal-config exists... yes
> checking gdal-config executable... yes
> checking gdal-config usability... yes
> configure: GDAL: 2.0.2
> checking GDAL version >= 1.6.3... yes
> configure: experimental conditional use of GDAL2
>
>
> a bunch of good stuff....
>
>
> g++ -shared -L/usr/local/lib64 -o rgdal.so OGR_write.o gdal-bindings.o init.o local_stubs.o ogr_geom.o ogr_polygons.o ogr_proj.o ogrdrivers.o ogrsource.o projectit.o -L/work/01260/ehodgess/gdal/lib -lgdal -L/work/01260/ehodgess/proj4/lib -lproj
> installing to /work/01260/ehodgess/Rlibs/rgdal/libs
> ** R
> ** data
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** installing vignettes
> ** testing if installed package can be loaded
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>  unable to load shared object '/work/01260/ehodgess/Rlibs/rgdal/libs/rgdal.so':
>  libgdal.so.20: cannot open shared object file: No such file or directory
> Error: loading failed
> Execution halted
> ERROR: loading failed
> * removing '/work/01260/ehodgess/Rlibs/rgdal'
>
> The downloaded source packages are in
>        '/tmp/RtmpXX2VTF/downloaded_packages'
> Warning message:
> In install.packages("rgdal", lib = "/work/01260/ehodgess/Rlibs",  :
>  installation of package 'rgdal' had non-zero exit status
>> system("echo $PATH")
> /work/01260/ehodgess/custom-R-3.2.2/R-3.2.2/bin:/opt/apps/xalt/0.6/bin:/opt/apps/intel15/mvapich2/2.1/bin:/opt/apps/intel/15/composer_xe_2015.2.164/bin/intel64:
> /usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/opt/apps/xsede/gsi-openssh-5.7/bin:/usr/X11R6/bin:/opt/ofed/bin:/opt/ofed/sbin:.:/work/01260/ehodgess/gdal/bin:
> /work/01260/ehodgess/gdal/lib
>>
>
> So it's saying that libgdal.so.20 is not found.  However, it is in gdal/lib, which is in the path.   (See last line).
>
> Is there something else that I should be putting into the install.packages function, please?  I've tried all kinds of things (putting a copy of libgdal.so.20 into Rlibs, etc.), but no good.
>
>
> Thanks,
> Erin
>
>
>
> Erin M. Hodgess, Ph.D.
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgesse at uhd.edu<mailto:hodgesse at uhd.edu>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


From eamon.caddigan at gmail.com  Fri Apr 15 02:35:28 2016
From: eamon.caddigan at gmail.com (Eamon Caddigan)
Date: Thu, 14 Apr 2016 20:35:28 -0400
Subject: [R-sig-Geo] Extending sp's SpatialPoints with altitude information
Message-ID: <CAD=p34CDHYpJSei_F12CV_zZT89dawfoSPHUhr-CgsxbN4Ovsw@mail.gmail.com>

Hi all,

I am looking to extend the SpatialPoints and SpatialPointsDataFrame classes
to include altitude information. Somebody recommended I check in with this
group for pointers before getting too far along on this.

I've looked around and haven't seen any other efforts to tackle this
specific problem, although I have seen the sp vignette about extending
classes. Am I missing something? Is this a bad idea?

Thanks,
Eamon Caddigan

	[[alternative HTML version deleted]]


From HodgessE at uhd.edu  Fri Apr 15 02:38:42 2016
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Fri, 15 Apr 2016 00:38:42 +0000
Subject: [R-sig-Geo] still having trouble with rgdal, please
In-Reply-To: <alpine.LFD.2.20.1604142041070.8453@reclus.nhh.no>
References: <FF9DB805FC41CC4E95825A50F6806302B49EEAA1@columbia.uhd.campus>,
	<alpine.LFD.2.20.1604142041070.8453@reclus.nhh.no>
Message-ID: <FF9DB805FC41CC4E95825A50F6806302B49EEE1D@columbia.uhd.campus>

The LD_LIBRARY_PATH worked like a charm!

Thanks again!

Sincerely,
Erin

________________________________________
From: Roger Bivand [Roger.Bivand at nhh.no]
Sent: Thursday, April 14, 2016 1:47 PM
To: Hodgess, Erin
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] still having trouble with rgdal, please

On Thu, 14 Apr 2016, Hodgess, Erin wrote:

> First of all, thanks to Roger Bivand for his great suggestions!  I am
> making gradual progress.
>
> However, not all is well yet.  One of my files from the gdal still seems
> to be missing:

Please read:

http://tldp.org/HOWTO/Program-Library-HOWTO/shared-libraries.html

and note that while you as non-super-user cannot use ldconfig to tell the
system to look in the right place for libgdal.so (it was found during
compilation and linking), you can set the environment
variable LD_LIBRARY_PATH despite the weaknesses that this has compared to
using ldconfig as super user. Running Sys.getenv("LD_LIBRARY_PATH") in R
shows you that R sets it up for its own purposes anyway (mostly for the
Java runtime engine).

Hope this helps,

Roger

>
>
>> install.packages("rgdal",lib="/work/01260/ehodgess/Rlibs",configure.args=c('--with-gdal-config=/work/01260/ehodgess/gdal/bin/gdal-config --with-proj-include=/work/01260/ehodgess/proj4/include --with-proj-lib=/work/01260/ehodgess/proj4/lib'),depen=TRUE)
> trying URL 'http://cran.revolutionanalytics.com/src/contrib/rgdal_1.1-8.tar.gz'
> Content type 'application/octet-stream' length 1649879 bytes (1.6 MB)
> ==================================================
> downloaded 1.6 MB
>
> * installing *source* package 'rgdal' ...
> ** package 'rgdal' successfully unpacked and MD5 sums checked
> configure: CC: gcc -std=gnu99
> configure: CXX: g++
> configure: rgdal: 1.1-8
> checking for /usr/bin/svnversion... yes
> configure: svn revision: 616
> configure: gdal-config set to /work/01260/ehodgess/gdal/bin/gdal-config
> checking gdal-config exists... yes
> checking gdal-config executable... yes
> checking gdal-config usability... yes
> configure: GDAL: 2.0.2
> checking GDAL version >= 1.6.3... yes
> configure: experimental conditional use of GDAL2
>
>
> a bunch of good stuff....
>
>
> g++ -shared -L/usr/local/lib64 -o rgdal.so OGR_write.o gdal-bindings.o init.o local_stubs.o ogr_geom.o ogr_polygons.o ogr_proj.o ogrdrivers.o ogrsource.o projectit.o -L/work/01260/ehodgess/gdal/lib -lgdal -L/work/01260/ehodgess/proj4/lib -lproj
> installing to /work/01260/ehodgess/Rlibs/rgdal/libs
> ** R
> ** data
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** installing vignettes
> ** testing if installed package can be loaded
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>  unable to load shared object '/work/01260/ehodgess/Rlibs/rgdal/libs/rgdal.so':
>  libgdal.so.20: cannot open shared object file: No such file or directory
> Error: loading failed
> Execution halted
> ERROR: loading failed
> * removing '/work/01260/ehodgess/Rlibs/rgdal'
>
> The downloaded source packages are in
>        '/tmp/RtmpXX2VTF/downloaded_packages'
> Warning message:
> In install.packages("rgdal", lib = "/work/01260/ehodgess/Rlibs",  :
>  installation of package 'rgdal' had non-zero exit status
>> system("echo $PATH")
> /work/01260/ehodgess/custom-R-3.2.2/R-3.2.2/bin:/opt/apps/xalt/0.6/bin:/opt/apps/intel15/mvapich2/2.1/bin:/opt/apps/intel/15/composer_xe_2015.2.164/bin/intel64:
> /usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/opt/apps/xsede/gsi-openssh-5.7/bin:/usr/X11R6/bin:/opt/ofed/bin:/opt/ofed/sbin:.:/work/01260/ehodgess/gdal/bin:
> /work/01260/ehodgess/gdal/lib
>>
>
> So it's saying that libgdal.so.20 is not found.  However, it is in gdal/lib, which is in the path.   (See last line).
>
> Is there something else that I should be putting into the install.packages function, please?  I've tried all kinds of things (putting a copy of libgdal.so.20 into Rlibs, etc.), but no good.
>
>
> Thanks,
> Erin
>
>
>
> Erin M. Hodgess, Ph.D.
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgesse at uhd.edu<mailto:hodgesse at uhd.edu>
>
>
>       [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

--
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


From mdsumner at gmail.com  Fri Apr 15 03:30:06 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 15 Apr 2016 01:30:06 +0000
Subject: [R-sig-Geo] Extending sp's SpatialPoints with altitude
	information
In-Reply-To: <CAD=p34CDHYpJSei_F12CV_zZT89dawfoSPHUhr-CgsxbN4Ovsw@mail.gmail.com>
References: <CAD=p34CDHYpJSei_F12CV_zZT89dawfoSPHUhr-CgsxbN4Ovsw@mail.gmail.com>
Message-ID: <CAAcGz98Zw9DgQTF9PRHVwu_b8smOubSBhMsxJJRybz+2WCbLxA@mail.gmail.com>

On Fri, 15 Apr 2016 at 10:36 Eamon Caddigan <eamon.caddigan at gmail.com>
wrote:

> Hi all,
>
> I am looking to extend the SpatialPoints and SpatialPointsDataFrame classes
> to include altitude information. Somebody recommended I check in with this
> group for pointers before getting too far along on this.
>
>
It's possible for Points in sp, but not for polygons or lines.

library(sp)
x <- matrix(rnorm(27), ncol = 3)
SpatialPoints(x)

But, the general support outside this in sp is very limited once you break
out of the plane.

I'm working on tools to make this much easier, and to translate from sp to
other forms and back. If you'd like to expand on what you're doing I'm
happy to help. It's possible to do this easily for lines and polygons, and
translate to rgl and ggplot2 and other forms, but it's best to use
relational tables IMO and that gets you outside the playing field pretty
quickly.

See here for some early thoughts, it's still very much in-progress and
design:

http://mdsumner.github.io/2015/12/28/gis3d.html

http://mdsumner.github.io/2016/03/03/polygons-R.html

Cheers, Mike.




> I've looked around and haven't seen any other efforts to tackle this
> specific problem, although I have seen the sp vignette about extending
> classes. Am I missing something? Is this a bad idea?
>
> Thanks,
> Eamon Caddigan
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From HodgessE at uhd.edu  Fri Apr 15 14:41:06 2016
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Fri, 15 Apr 2016 12:41:06 +0000
Subject: [R-sig-Geo] something potentially fun/useful
Message-ID: <FF9DB805FC41CC4E95825A50F6806302B49F9470@columbia.uhd.campus>

Hello!

I hope this is ok to post this here.  There will be a special session on High Performance Computing in Geostatistics at the INASE conference in Riga, Latvia in May 28 - 30.  It will appear later today on the website.  www.inase.org<http://www.inase.org>

Thanks,
Erin
PS  I am the organizer; please do feel free to contact me at hodgesse at uhd.edu



	[[alternative HTML version deleted]]


From baerroger at outlook.com  Fri Apr 15 20:35:11 2016
From: baerroger at outlook.com (=?iso-8859-1?B?Um9nZXIgQuRy?=)
Date: Fri, 15 Apr 2016 20:35:11 +0200
Subject: [R-sig-Geo] GISRC environment variable using initGRASS
Message-ID: <DUB129-W573D763DAB1ABA9C09EF8BA5680@phx.gbl>

I am currently using the R package "rgrass7" (Version: 0.1-6)?in order to command GRASS GIS (Windows7, OSGEO4W installation). ?

I use R in order to start a GRASS environment and to script my geoprocessing. Both is working fine. However, I have problems with storing and calling the GRASS gisenv variables.?
Every time when I call "initGRASS" a file called "junk" is created containing GRASS gisenv variables.


Looking at the source of the initGRASS function the section below puzzeled me somehow:

?59 ? Sys.setenv(GISRC = paste(Sys.getenv("HOME"), "\\.grassrc7",?
?60 ? ? sep = ""))
?61 ? if (file.exists(Sys.getenv("GISRC")) && !override)?
?62 ? ? stop("A GISRC file already exists; to override, set override=TRUE")
?63 ?Sys.setenv(GISRC = "junk")
?64 ?cat("GISDBASE:", getwd(), "\n", file = Sys.getenv("GISRC"))
?65 ?cat("LOCATION_NAME: <UNKNOWN>", "\n", file = Sys.getenv("GISRC"),?
?66 ? ? append = TRUE)
?67 ?cat("MAPSET: <UNKNOWN>", "\n", file = Sys.getenv("GISRC"),?
?68 ? ? append = TRUE)
?69 ?gisrc <- ifelse(use_g.dirseps.exe, system(paste("g.dirseps.exe -g",?
?70 ? ? shQuote(Sys.getenv("GISRC"))), intern = TRUE), Sys.getenv("GISRC"))
?71 ? assign("addEXE", .addexe(), envir = .GRASS_CACHE)
? 72 ?Sys.setenv(GISRC = gisrc)

First, why is initGRASS using ".grassrc7" for storing the GISRC file??
InitGRASS is looking for the GISRC file under ".grassrc7" (line 59). However, in the?package documentation [1], the GISRC file is called ".gisrc". Moreover, the?GRASS documentation?says that the GISRC file is stored under "/.grass7/rc"

Second, what is the purpose of assigning "junk" to the GISRC environment variable??
GISRC is set to "junk" (line 63) and then the GISRC value ("junk") is assigned again back to system variable GISRC. Unless I misinterpreded the code, it does not make much sense to me. Shouldn't the enviroment varibales not be written (line 64 - 68) to ".grassrc7" rather than to "junk"?



I would appreciate any support or hints!

Regards,
Roger

[1] http://https//cran.r-project.org/web/packages/rgrass7/rgrass7.pdf
[2]?http://grass.osgeo.org/grass70/manuals/variables.html
 		 	   		  

From Roger.Bivand at nhh.no  Fri Apr 15 20:58:15 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 15 Apr 2016 20:58:15 +0200
Subject: [R-sig-Geo] GISRC environment variable using initGRASS
In-Reply-To: <DUB129-W573D763DAB1ABA9C09EF8BA5680@phx.gbl>
References: <DUB129-W573D763DAB1ABA9C09EF8BA5680@phx.gbl>
Message-ID: <alpine.LFD.2.20.1604152046460.24113@reclus.nhh.no>

On Fri, 15 Apr 2016, Roger B?r wrote:

> I am currently using the R package "rgrass7" (Version: 0.1-6) in order 
> to command GRASS GIS (Windows7, OSGEO4W installation).
>
> I use R in order to start a GRASS environment and to script my 
> geoprocessing. Both is working fine. However, I have problems with 
> storing and calling the GRASS gisenv variables. Every time when I call 
> "initGRASS" a file called "junk" is created containing GRASS gisenv 
> variables.
>

What the file is called is probably immaterial.

>
> Looking at the source of the initGRASS function the section below 
> puzzeled me somehow:
>
> ?59 ? Sys.setenv(GISRC = paste(Sys.getenv("HOME"), "\\.grassrc7",?
> ?60 ? ? sep = ""))

This is setting GISRC to a value

> ?61 ? if (file.exists(Sys.getenv("GISRC")) && !override)?
> ?62 ? ? stop("A GISRC file already exists; to override, set override=TRUE")
> ?63 ?Sys.setenv(GISRC = "junk")

This is setting it again in the working directory - I don't recall why - 
probably frustration years ago with Windows.

> ?64 ?cat("GISDBASE:", getwd(), "\n", file = Sys.getenv("GISRC"))
> ?65 ?cat("LOCATION_NAME: <UNKNOWN>", "\n", file = Sys.getenv("GISRC"),?
> ?66 ? ? append = TRUE)
> ?67 ?cat("MAPSET: <UNKNOWN>", "\n", file = Sys.getenv("GISRC"),?
> ?68 ? ? append = TRUE)
> ?69 ?gisrc <- ifelse(use_g.dirseps.exe, system(paste("g.dirseps.exe -g",?
> ?70 ? ? shQuote(Sys.getenv("GISRC"))), intern = TRUE), Sys.getenv("GISRC"))
> ?71 ? assign("addEXE", .addexe(), envir = .GRASS_CACHE)
> ? 72 ?Sys.setenv(GISRC = gisrc)
>

And this sets it again. It is set, otherwise GRASS wouldn't work; 
programmatically you'd have to use Sys.getenv("GISRC") to get the value. 
Please provide a use case where this matters, and consider moving this 
thread to the statsgrass list.

Hope this helps (doesn't clarify, but that's legacy Windows),

Roger

> First, why is initGRASS using ".grassrc7" for storing the GISRC file??
> InitGRASS is looking for the GISRC file under ".grassrc7" (line 59). However, in the?package documentation [1], the GISRC file is called ".gisrc". Moreover, the?GRASS documentation?says that the GISRC file is stored under "/.grass7/rc"
>
> Second, what is the purpose of assigning "junk" to the GISRC environment variable??
> GISRC is set to "junk" (line 63) and then the GISRC value ("junk") is assigned again back to system variable GISRC. Unless I misinterpreded the code, it does not make much sense to me. Shouldn't the enviroment varibales not be written (line 64 - 68) to ".grassrc7" rather than to "junk"?
>
>
>
> I would appreciate any support or hints!
>
> Regards,
> Roger
>
> [1] http://https//cran.r-project.org/web/packages/rgrass7/rgrass7.pdf
> [2]?http://grass.osgeo.org/grass70/manuals/variables.html
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412

From eamon.caddigan at gmail.com  Fri Apr 15 21:06:04 2016
From: eamon.caddigan at gmail.com (Eamon Caddigan)
Date: Fri, 15 Apr 2016 15:06:04 -0400
Subject: [R-sig-Geo] Extending sp's SpatialPoints with altitude
	information
In-Reply-To: <CAAcGz98Zw9DgQTF9PRHVwu_b8smOubSBhMsxJJRybz+2WCbLxA@mail.gmail.com>
References: <CAD=p34CDHYpJSei_F12CV_zZT89dawfoSPHUhr-CgsxbN4Ovsw@mail.gmail.com>
	<CAAcGz98Zw9DgQTF9PRHVwu_b8smOubSBhMsxJJRybz+2WCbLxA@mail.gmail.com>
Message-ID: <CAD=p34DDG-W4Rbpy25EyumNkR7aQOftaW0wmbcBTfdOtvuDY7Q@mail.gmail.com>

On Thu, Apr 14, 2016 at 9:30 PM, Michael Sumner <mdsumner at gmail.com> wrote:
>
> On Fri, 15 Apr 2016 at 10:36 Eamon Caddigan <eamon.caddigan at gmail.com>
> wrote:
>
>> Hi all,
>>
>> I am looking to extend the SpatialPoints and SpatialPointsDataFrame
>> classes
>> to include altitude information. Somebody recommended I check in with this
>> group for pointers before getting too far along on this.
>>
>>
> It's possible for Points in sp, but not for polygons or lines.
>
> library(sp)
> x <- matrix(rnorm(27), ncol = 3)
> SpatialPoints(x)
>
> But, the general support outside this in sp is very limited once you break
> out of the plane.
>

Thanks Mike!

I had no idea that coordinates() handled three-dimensional matrices
already. In that case, it looks like I don't have to do anything at all
(for now).



> I'm working on tools to make this much easier, and to translate from sp to
> other forms and back.
>

I look forward to seeing what comes out of this!

-Eamon

	[[alternative HTML version deleted]]


From englishchristophera at gmail.com  Fri Apr 15 23:04:34 2016
From: englishchristophera at gmail.com (chris english)
Date: Sat, 16 Apr 2016 00:04:34 +0300
Subject: [R-sig-Geo] Extending sp's SpatialPoints with altitude
	information
In-Reply-To: <CAD=p34DDG-W4Rbpy25EyumNkR7aQOftaW0wmbcBTfdOtvuDY7Q@mail.gmail.com>
References: <CAD=p34CDHYpJSei_F12CV_zZT89dawfoSPHUhr-CgsxbN4Ovsw@mail.gmail.com>
	<CAAcGz98Zw9DgQTF9PRHVwu_b8smOubSBhMsxJJRybz+2WCbLxA@mail.gmail.com>
	<CAD=p34DDG-W4Rbpy25EyumNkR7aQOftaW0wmbcBTfdOtvuDY7Q@mail.gmail.com>
Message-ID: <CAASFQpRwBD0S8DQuFXaN1ogLAerUXDU9ywG0SmWzgCRbYYZT5w@mail.gmail.com>

Mike,

Reading this discussion lead me to finally visiting your github and reading
gris read.md. And of course installing it. I understand mostly where you
are going in the Needs section and were I to recommend a new, fast friend,
it would be Sandro Santilli, strk at keybit.net (http://strk.keybit.net), who
agonized over (I presume) and implemented topology in PostGIS. While this
is not R, the decisions and rigor are informative. Perhaps you are fast
friends already.

I really appreciate allowing mixed objects in gris that seems informed by
spatstat rather more than sp and friends where one feels shackled to a
given representation of line or point or polygon & etc..  In an analysis of
eyetracking data which was initially informed by a mapping perspective (sp,
trajectories, trips), I have essentially had to rewrite sp to to dispense
with sp and many constraints imposed. Those constraints were theoretically
valid but constraining none the less when trying to implement some system
of proposed algorithms that took no heed of sp's object constraints.

When the eyetracking thing is finally put to bed and I get an rgl
compatible laptop that is not my wife's laptop (as things currently stand),
and when I'm a tad better at r, I'd be happy to help with the evolution of
this 3d.

Chris

On Fri, Apr 15, 2016 at 10:06 PM, Eamon Caddigan <eamon.caddigan at gmail.com>
wrote:

> On Thu, Apr 14, 2016 at 9:30 PM, Michael Sumner <mdsumner at gmail.com>
> wrote:
> >
> > On Fri, 15 Apr 2016 at 10:36 Eamon Caddigan <eamon.caddigan at gmail.com>
> > wrote:
> >
> >> Hi all,
> >>
> >> I am looking to extend the SpatialPoints and SpatialPointsDataFrame
> >> classes
> >> to include altitude information. Somebody recommended I check in with
> this
> >> group for pointers before getting too far along on this.
> >>
> >>
> > It's possible for Points in sp, but not for polygons or lines.
> >
> > library(sp)
> > x <- matrix(rnorm(27), ncol = 3)
> > SpatialPoints(x)
> >
> > But, the general support outside this in sp is very limited once you
> break
> > out of the plane.
> >
>
> Thanks Mike!
>
> I had no idea that coordinates() handled three-dimensional matrices
> already. In that case, it looks like I don't have to do anything at all
> (for now).
>
>
>
> > I'm working on tools to make this much easier, and to translate from sp
> to
> > other forms and back.
> >
>
> I look forward to seeing what comes out of this!
>
> -Eamon
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Sat Apr 16 00:15:14 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 15 Apr 2016 22:15:14 +0000
Subject: [R-sig-Geo] Extending sp's SpatialPoints with altitude
	information
In-Reply-To: <CAASFQpRwBD0S8DQuFXaN1ogLAerUXDU9ywG0SmWzgCRbYYZT5w@mail.gmail.com>
References: <CAD=p34CDHYpJSei_F12CV_zZT89dawfoSPHUhr-CgsxbN4Ovsw@mail.gmail.com>
	<CAAcGz98Zw9DgQTF9PRHVwu_b8smOubSBhMsxJJRybz+2WCbLxA@mail.gmail.com>
	<CAD=p34DDG-W4Rbpy25EyumNkR7aQOftaW0wmbcBTfdOtvuDY7Q@mail.gmail.com>
	<CAASFQpRwBD0S8DQuFXaN1ogLAerUXDU9ywG0SmWzgCRbYYZT5w@mail.gmail.com>
Message-ID: <CAAcGz99Yz=5MhEE2FgdSNL2bAHntxviddwkarQ2VWf0MbStpug@mail.gmail.com>

On Sat, 16 Apr 2016 at 07:04 chris english <englishchristophera at gmail.com>
wrote:

> Mike,
>
> Reading this discussion lead me to finally visiting your github and
> reading gris read.md. And of course installing it. I understand mostly
> where you are going in the Needs section and were I to recommend a new,
> fast friend, it would be Sandro Santilli, strk at keybit.net (
> http://strk.keybit.net), who agonized over (I presume) and implemented
> topology in PostGIS. While this is not R, the decisions and rigor are
> informative. Perhaps you are fast friends already.
>
>
Thanks for the link, I know that PostGIS has some of this but I haven't
explored it. I've mostly gone on what is in "PostGIS in Action" - I need to
get familiar with that db - I just don't see it as "the solution" for R -
we can have a light-weight toolkit in R itself, and leverage heavy external
libraries only when desired.


> I really appreciate allowing mixed objects in gris that seems informed by
> spatstat rather more than sp and friends where one feels shackled to a
> given representation of line or point or polygon & etc..  In an analysis of
> eyetracking data which was initially informed by a mapping perspective (sp,
> trajectories, trips), I have essentially had to rewrite sp to to dispense
> with sp and many constraints imposed. Those constraints were theoretically
> valid but constraining none the less when trying to implement some system
> of proposed algorithms that took no heed of sp's object constraints.
>
>
Mostly I'm informed by the use of www.Manifold.net and the now-defunct
Eonfusion.  MapInfo .tab and .mif formats also allow mixed topology, but I
never used MapInfo. Eonfusion was so radical it's very hard to describe
briefly, but essentially all storage is via relational tables - vertices,
primitives, and objects. All tables can have any attributes (or none) and
all operations have default choices of which attributes are used (i.e. x,
y, z, time or lon, lat, z, time - or whatever you want to call them). It's
very natural once you are familiar with it. Attribute flexibility on
vertices means  you can manually set whatever you want. I.e. calculate then
triangulate in theta/phi, then process which triangles are "on top", and
voila you have a viewshed analysis. Manifold is stuck in 2D for now but the
editing tools, use of selections, natural use of layers not tied to files,
constrained triangulations, and general slickness and price put it way
ahead of other options IMO even before the new Radian engine is released.


> When the eyetracking thing is finally put to bed and I get an rgl
> compatible laptop that is not my wife's laptop (as things currently stand),
> and when I'm a tad better at r, I'd be happy to help with the evolution of
> this 3d.
>
>
That sounds great, I'm keen to find out what you are doing. That is another
very good point in the "spatial is not special" spectrum. "Spatial" is
really everything, maps are just one kind of "projection", long-lat, x-y-z,
and time are inherent to many things but not everything. Topology exists in
all kinds of  applications. Date time metadata on numeric is a "projection"
for example.

I'd like to see a really general framework where geometry and topology are
the basis and things like sp (and now sfr) can be built on it. I see it as
inevitable that dplyr or its successor is where that's going to happen -
seamless back-ending with a data base is just one reason -  and with ggvis
to replace ggplot2 it will be the go-to tool for visualization and
user-interaction with spatial data. Hopefully the ongoing modernization of
PROJ.4 will also assist in that being just a choice in a
"projection-engine" family.

At the moment I'm concentrating on  https://github.com/mdsumner/spbabel
 which shows some of the ways to nest spatial data in data frames  (via
tidyr) , in a two-level way analogous to sp objects and an "inside-out" way
that's a better match for gris (nested data frames and the ggplot2::fortify
approach can't do this but it's a requirement for topological structures
including triangulation).  It's all in-dev and unstable for now.

Finally, all of my work in this area relies on the tools in dplyr - for
table manipulations - and RTriangle - for constrained triangulation.

Cheers, Mike.



Chris
> On Fri, Apr 15, 2016 at 10:06 PM, Eamon Caddigan <eamon.caddigan at gmail.com
> > wrote:
>
>> On Thu, Apr 14, 2016 at 9:30 PM, Michael Sumner <mdsumner at gmail.com>
>> wrote:
>> >
>> > On Fri, 15 Apr 2016 at 10:36 Eamon Caddigan <eamon.caddigan at gmail.com>
>> > wrote:
>> >
>> >> Hi all,
>> >>
>> >> I am looking to extend the SpatialPoints and SpatialPointsDataFrame
>> >> classes
>> >> to include altitude information. Somebody recommended I check in with
>> this
>> >> group for pointers before getting too far along on this.
>> >>
>> >>
>> > It's possible for Points in sp, but not for polygons or lines.
>> >
>> > library(sp)
>> > x <- matrix(rnorm(27), ncol = 3)
>> > SpatialPoints(x)
>> >
>> > But, the general support outside this in sp is very limited once you
>> break
>> > out of the plane.
>> >
>>
>> Thanks Mike!
>>
>> I had no idea that coordinates() handled three-dimensional matrices
>> already. In that case, it looks like I don't have to do anything at all
>> (for now).
>>
>>
>>
>> > I'm working on tools to make this much easier, and to translate from sp
>> to
>> > other forms and back.
>> >
>>
>> I look forward to seeing what comes out of this!
>>
>> -Eamon
>>
>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> --
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From englishchristophera at gmail.com  Sat Apr 16 06:39:10 2016
From: englishchristophera at gmail.com (chris english)
Date: Sat, 16 Apr 2016 07:39:10 +0300
Subject: [R-sig-Geo] Extending sp's SpatialPoints with altitude
	information
In-Reply-To: <CAAcGz99Yz=5MhEE2FgdSNL2bAHntxviddwkarQ2VWf0MbStpug@mail.gmail.com>
References: <CAD=p34CDHYpJSei_F12CV_zZT89dawfoSPHUhr-CgsxbN4Ovsw@mail.gmail.com>
	<CAAcGz98Zw9DgQTF9PRHVwu_b8smOubSBhMsxJJRybz+2WCbLxA@mail.gmail.com>
	<CAD=p34DDG-W4Rbpy25EyumNkR7aQOftaW0wmbcBTfdOtvuDY7Q@mail.gmail.com>
	<CAASFQpRwBD0S8DQuFXaN1ogLAerUXDU9ywG0SmWzgCRbYYZT5w@mail.gmail.com>
	<CAAcGz99Yz=5MhEE2FgdSNL2bAHntxviddwkarQ2VWf0MbStpug@mail.gmail.com>
Message-ID: <CAASFQpTtvGtDPzOa=aVn9+qNsJBHDUU6_csR5a3b-YipcjJWOg@mail.gmail.com>

Eonfusion sounds interestingly reminiscent of Ted Nelson's Project Xanadu,
though finding a nearly working version is a very rare bird in the wild.

Chris

On Sat, Apr 16, 2016 at 1:15 AM, Michael Sumner <mdsumner at gmail.com> wrote:

>
>
> On Sat, 16 Apr 2016 at 07:04 chris english <englishchristophera at gmail.com>
> wrote:
>
>> Mike,
>>
>> Reading this discussion lead me to finally visiting your github and
>> reading gris read.md. And of course installing it. I understand mostly
>> where you are going in the Needs section and were I to recommend a new,
>> fast friend, it would be Sandro Santilli, strk at keybit.net (
>> http://strk.keybit.net), who agonized over (I presume) and implemented
>> topology in PostGIS. While this is not R, the decisions and rigor are
>> informative. Perhaps you are fast friends already.
>>
>>
> Thanks for the link, I know that PostGIS has some of this but I haven't
> explored it. I've mostly gone on what is in "PostGIS in Action" - I need to
> get familiar with that db - I just don't see it as "the solution" for R -
> we can have a light-weight toolkit in R itself, and leverage heavy external
> libraries only when desired.
>
>
>> I really appreciate allowing mixed objects in gris that seems informed by
>> spatstat rather more than sp and friends where one feels shackled to a
>> given representation of line or point or polygon & etc..  In an analysis of
>> eyetracking data which was initially informed by a mapping perspective (sp,
>> trajectories, trips), I have essentially had to rewrite sp to to dispense
>> with sp and many constraints imposed. Those constraints were theoretically
>> valid but constraining none the less when trying to implement some system
>> of proposed algorithms that took no heed of sp's object constraints.
>>
>>
> Mostly I'm informed by the use of www.Manifold.net and the now-defunct
> Eonfusion.  MapInfo .tab and .mif formats also allow mixed topology, but I
> never used MapInfo. Eonfusion was so radical it's very hard to describe
> briefly, but essentially all storage is via relational tables - vertices,
> primitives, and objects. All tables can have any attributes (or none) and
> all operations have default choices of which attributes are used (i.e. x,
> y, z, time or lon, lat, z, time - or whatever you want to call them). It's
> very natural once you are familiar with it. Attribute flexibility on
> vertices means  you can manually set whatever you want. I.e. calculate then
> triangulate in theta/phi, then process which triangles are "on top", and
> voila you have a viewshed analysis. Manifold is stuck in 2D for now but the
> editing tools, use of selections, natural use of layers not tied to files,
> constrained triangulations, and general slickness and price put it way
> ahead of other options IMO even before the new Radian engine is released.
>
>
>> When the eyetracking thing is finally put to bed and I get an rgl
>> compatible laptop that is not my wife's laptop (as things currently stand),
>> and when I'm a tad better at r, I'd be happy to help with the evolution of
>> this 3d.
>>
>>
> That sounds great, I'm keen to find out what you are doing. That is
> another very good point in the "spatial is not special" spectrum. "Spatial"
> is really everything, maps are just one kind of "projection", long-lat,
> x-y-z, and time are inherent to many things but not everything. Topology
> exists in all kinds of  applications. Date time metadata on numeric is a
> "projection" for example.
>
> I'd like to see a really general framework where geometry and topology are
> the basis and things like sp (and now sfr) can be built on it. I see it as
> inevitable that dplyr or its successor is where that's going to happen -
> seamless back-ending with a data base is just one reason -  and with ggvis
> to replace ggplot2 it will be the go-to tool for visualization and
> user-interaction with spatial data. Hopefully the ongoing modernization of
> PROJ.4 will also assist in that being just a choice in a
> "projection-engine" family.
>
> At the moment I'm concentrating on  https://github.com/mdsumner/spbabel
>  which shows some of the ways to nest spatial data in data frames  (via
> tidyr) , in a two-level way analogous to sp objects and an "inside-out"
> way that's a better match for gris (nested data frames and the
> ggplot2::fortify approach can't do this but it's a requirement for
> topological structures including triangulation).  It's all in-dev and
> unstable for now.
>
> Finally, all of my work in this area relies on the tools in dplyr - for
> table manipulations - and RTriangle - for constrained triangulation.
>
> Cheers, Mike.
>
>
>
> Chris
>> On Fri, Apr 15, 2016 at 10:06 PM, Eamon Caddigan <
>> eamon.caddigan at gmail.com> wrote:
>>
>>> On Thu, Apr 14, 2016 at 9:30 PM, Michael Sumner <mdsumner at gmail.com>
>>> wrote:
>>> >
>>> > On Fri, 15 Apr 2016 at 10:36 Eamon Caddigan <eamon.caddigan at gmail.com>
>>> > wrote:
>>> >
>>> >> Hi all,
>>> >>
>>> >> I am looking to extend the SpatialPoints and SpatialPointsDataFrame
>>> >> classes
>>> >> to include altitude information. Somebody recommended I check in with
>>> this
>>> >> group for pointers before getting too far along on this.
>>> >>
>>> >>
>>> > It's possible for Points in sp, but not for polygons or lines.
>>> >
>>> > library(sp)
>>> > x <- matrix(rnorm(27), ncol = 3)
>>> > SpatialPoints(x)
>>> >
>>> > But, the general support outside this in sp is very limited once you
>>> break
>>> > out of the plane.
>>> >
>>>
>>> Thanks Mike!
>>>
>>> I had no idea that coordinates() handled three-dimensional matrices
>>> already. In that case, it looks like I don't have to do anything at all
>>> (for now).
>>>
>>>
>>>
>>> > I'm working on tools to make this much easier, and to translate from
>>> sp to
>>> > other forms and back.
>>> >
>>>
>>> I look forward to seeing what comes out of this!
>>>
>>> -Eamon
>>>
>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
>

	[[alternative HTML version deleted]]


From morera.virginia at gmail.com  Sat Apr 16 12:31:20 2016
From: morera.virginia at gmail.com (Virginia Morera Pujol)
Date: Sat, 16 Apr 2016 12:31:20 +0200
Subject: [R-sig-Geo] Correlation between covariates and intercept (spatstat)
Message-ID: <CAJ3XaKfSnQzJzXqSXbmsEAZJa4=da5OvESe8ZbofNM0Qz0vL-w@mail.gmail.com>

Hello all,

In trying a spatial model with spatstat I am running into a conceptual
problem. It might be more of a general modelling doubt than a specific
spatial problem, but I hope someone can help.

I am running a ppm() model that includes two covariates (as pixel images),
one is primary productivity at sea, and the other is distance to a point
that is not included in the pattern window. That means there is no 0 value,
the range of values goes from 400 to 1400 approx.  When I run the model and
look at the var-covar matrix using 'vcov(model, what = "corr")' , there is
a very strong correlation (around -0.85) between the intercept and this
covariate. I am not sure that this is a problem, but I have tried a couple
of things just in case:

1/ centering the covariate values around the mean just changes the sign of
the correlation (from -0.85 to +0.85 approx).

2/ normalizing the covariate values, so the values go from 0 to 1 makes the
correlation between this covariate and the intercept almost 1 (0.99) It
also makes the effect of this covariate three orders of magnitude higher
than the effect of the other covariate, which didn't happen before and was
not expected from the data.

Any advice? Thanks in advance!

Virginia Morera
PhD Student
Department of Animal Biology
University of Barcelona

Aquest correu electr?nic i els annexos poden contenir informaci?
confidencial o protegida legalment i est? adre?at exclusivament a la
persona o entitat destinat?ria. Si no sou  el destinatari final o la
persona encarregada de rebre?l, no esteu autoritzat a llegir-lo,
retenir-lo, modificar-lo, distribuir-lo, copiar-lo ni a revelar-ne el
contingut. Si heu rebut aquest correu electr?nic per error, us preguem que
n?informeu al remitent i que elimineu del sistema el missatge i el material
annex que pugui contenir. Gr?cies per la vostra col?laboraci?.

Este correo electr?nico y sus anexos pueden contener informaci?n
confidencial o legalmente protegida y est? exclusivamente dirigido a la
persona o entidad destinataria. Si usted no es el destinatario final o la
persona encargada de recibirlo, no est? autorizado a leerlo, retenerlo,
modificarlo, distribuirlo, copiarlo ni a revelar su contenido. Si ha
recibido este mensaje electr?nico por error, le rogamos que informe al
remitente y elimine del sistema el mensaje y el material anexo que pueda
contener. Gracias por su colaboraci?n.

This email message and any documents attached to it may contain
confidential or legally protected material and are intended solely for the
use of the individual or organization to whom they are addressed. We remind
you that if you are not the intended recipient of this email message or the
person responsible for processing it, then you are not authorized to read,
save, modify, send, copy or disclose any of its contents. If you have
received this email message by mistake, we kindly ask you to inform the
sender of this and to eliminate both the message and any attachments it
carries from your account.Thank you for your collaboration.

	[[alternative HTML version deleted]]


From englishchristophera at gmail.com  Sat Apr 16 19:16:05 2016
From: englishchristophera at gmail.com (chris english)
Date: Sat, 16 Apr 2016 20:16:05 +0300
Subject: [R-sig-Geo] something potentially fun/useful
In-Reply-To: <FF9DB805FC41CC4E95825A50F6806302B49F9470@columbia.uhd.campus>
References: <FF9DB805FC41CC4E95825A50F6806302B49F9470@columbia.uhd.campus>
Message-ID: <CAASFQpSJMWOv3Qrv7=0-7jY90PaJWO3LLmNKp9_hjhk5hCxSXg@mail.gmail.com>

Hi Erin,
Edzer added an Events section to r-spatial where you'd also want to
announce your event (though I send you to the start of the discussion):

https://mail.google.com/mail/u/0/?tab=wm#inbox/15399316b48ef012

and it will be fun, useful, and highly interesting.
Chris

On Fri, Apr 15, 2016 at 3:41 PM, Hodgess, Erin <HodgessE at uhd.edu> wrote:

> Hello!
>
> I hope this is ok to post this here.  There will be a special session on
> High Performance Computing in Geostatistics at the INASE conference in
> Riga, Latvia in May 28 - 30.  It will appear later today on the website.
> www.inase.org<http://www.inase.org>
>
> Thanks,
> Erin
> PS  I am the organizer; please do feel free to contact me at
> hodgesse at uhd.edu
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From baerroger at outlook.com  Sat Apr 16 19:47:34 2016
From: baerroger at outlook.com (=?iso-8859-1?B?Um9nZXIgQuRy?=)
Date: Sat, 16 Apr 2016 19:47:34 +0200
Subject: [R-sig-Geo] GISRC environment variable using initGRASS
In-Reply-To: <alpine.LFD.2.20.1604152046460.24113@reclus.nhh.no>
References: <DUB129-W573D763DAB1ABA9C09EF8BA5680@phx.gbl>,
	<alpine.LFD.2.20.1604152046460.24113@reclus.nhh.no>
Message-ID: <DUB129-W37F72276A9CB4D0E442F5BA5690@phx.gbl>

Thanks for the support!Please see below my comments.

> Date: Fri, 15 Apr 2016 20:58:15 +0200
> From: Roger.Bivand at nhh.no
> To: baerroger at outlook.com
> CC: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] GISRC environment variable using initGRASS
> 
> On Fri, 15 Apr 2016, Roger B?r wrote:
> 
> > I am currently using the R package "rgrass7" (Version: 0.1-6) in order 
> > to command GRASS GIS (Windows7, OSGEO4W installation).
> >
> > I use R in order to start a GRASS environment and to script my 
> > geoprocessing. Both is working fine. However, I have problems with 
> > storing and calling the GRASS gisenv variables. Every time when I call 
> > "initGRASS" a file called "junk" is created containing GRASS gisenv 
> > variables.
> >
> 
> What the file is called is probably immaterial.
> 
> >
> > Looking at the source of the initGRASS function the section below 
> > puzzeled me somehow:
> >
> >  59   Sys.setenv(GISRC = paste(Sys.getenv("HOME"), "\\.grassrc7", 
> >  60     sep = ""))
> 
> This is setting GISRC to a value

 Yes. The absolute path to the file (containing settings for GISDBASE, LOCATION_NAME and MAPSET) 

> >  61   if (file.exists(Sys.getenv("GISRC")) && !override) 
> >  62     stop("A GISRC file already exists; to override, set override=TRUE")
> >  63  Sys.setenv(GISRC = "junk")
> 
> This is setting it again in the working directory - I don't recall why - 
> probably frustration years ago with Windows.

I really do not understand the "junk" (line 63). Because GISRC is set to "junk" the subsequent lines of code will write the GISRC environment variables to a newly created file called "junk" in the home folder. 
Shouldn't this line not rather be omitted? 
(The GRASS environment variables would then be written to ".grassrc7", which in my opinion would be correct)

> 
> >  64  cat("GISDBASE:", getwd(), "\n", file = Sys.getenv("GISRC"))
> >  65  cat("LOCATION_NAME: <UNKNOWN>", "\n", file = Sys.getenv("GISRC"), 
> >  66     append = TRUE)
> >  67  cat("MAPSET: <UNKNOWN>", "\n", file = Sys.getenv("GISRC"), 
> >  68     append = TRUE)
> >  69  gisrc <- ifelse(use_g.dirseps.exe, system(paste("g.dirseps.exe -g", 
> >  70     shQuote(Sys.getenv("GISRC"))), intern = TRUE), Sys.getenv("GISRC"))
> >  71   assign("addEXE", .addexe(), envir = .GRASS_CACHE)
> >   72  Sys.setenv(GISRC = gisrc)
> >
> 
> And this sets it again. It is set, otherwise GRASS wouldn't work; 
> programmatically you'd have to use Sys.getenv("GISRC") to get the value. 
> Please provide a use case where this matters, and consider moving this 
> thread to the statsgrass list.

Sorry, I do not understand what you mean with "provide a use case where this matters". What do you mean with "this"?
I added the thread to the grass-stat list (and will remove r-sig from the cc the next time).
Roger

> 
> Hope this helps (doesn't clarify, but that's legacy Windows),
> 
> Roger
> 
> > First, why is initGRASS using ".grassrc7" for storing the GISRC file? 
> > InitGRASS is looking for the GISRC file under ".grassrc7" (line 59). However, in the package documentation [1], the GISRC file is called ".gisrc". Moreover, the GRASS documentation says that the GISRC file is stored under "/.grass7/rc"
> >
> > Second, what is the purpose of assigning "junk" to the GISRC environment variable? 
> > GISRC is set to "junk" (line 63) and then the GISRC value ("junk") is assigned again back to system variable GISRC. Unless I misinterpreded the code, it does not make much sense to me. Shouldn't the enviroment varibales not be written (line 64 - 68) to ".grassrc7" rather than to "junk"?
> >
> >
> >
> > I would appreciate any support or hints!
> >
> > Regards,
> > Roger
> >
> > [1] http://https//cran.r-project.org/web/packages/rgrass7/rgrass7.pdf
> > [2] http://grass.osgeo.org/grass70/manuals/variables.html
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> 
> -- 
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
> http://depsy.org/person/434412
 		 	   		  
	[[alternative HTML version deleted]]


From adrian.baddeley at curtin.edu.au  Sun Apr 17 12:36:31 2016
From: adrian.baddeley at curtin.edu.au (Adrian Baddeley)
Date: Sun, 17 Apr 2016 10:36:31 +0000
Subject: [R-sig-Geo] Correlation between covariates and intercept (spatstat)
In-Reply-To: <mailman.3.1460887202.3820.r-sig-geo@r-project.org>
References: <mailman.3.1460887202.3820.r-sig-geo@r-project.org>
Message-ID: <HK2PR02MB145906357FDC730517B1288BA46A0@HK2PR02MB1459.apcprd02.prod.outlook.com>

Virginia Morera Pujol <morera.virginia at gmail.com> writes:

> In trying a spatial model with spatstat I am running into a conceptual
> problem. It might be more of a general modelling doubt than a specific
> spatial problem, but I hope someone can help.

> I am running a ppm() model that includes two covariates (as pixel images),
> one is primary productivity at sea, and the other is distance to a point
> that is not included in the pattern window. That means there is no 0 value,
> the range of values goes from 400 to 1400 approx.  When I run the model and
> look at the var-covar matrix using 'vcov(model, what = "corr")' , there is
> a very strong correlation (around -0.85) between the intercept and this
> covariate. I am not sure that this is a problem, but [...]

This is about the correlation between *estimates* of the model coefficients - in this case, the correlation between the estimated intercept and the estimated coefficient of the distance covariate. Extremely high correlations could cause problems with the identifiability of the model, but this is probably not a problem here. Moderately high correlations suggest that the t-tests for individual parameters (given in the printout for the model) are not independent. If we want to select the 'significant' covariates, we shouldn't use the model printout to discard more than one variable at a time. 

>  I have tried a couple of things just in case:

> 1/ centering the covariate values around the mean just changes the sign of
> the correlation (from -0.85 to +0.85 approx).

> 2/ normalizing the covariate values, so the values go from 0 to 1 makes the
> correlation between this covariate and the intercept almost 1 (0.99) It
> also makes the effect of this covariate three orders of magnitude higher
> than the effect of the other covariate, which didn't happen before and was
> not expected from the data.

Such transformations will change the correlation. Roughly speaking, that's because when you add a constant to the distance covariate, you are adding a multiple of the intercept onto the covariate. 

When you say the 'effect' of the covariate has increased, do you mean the coefficient of the covariate has increased, or the *effect term* (= coefficient x covariate value) has increased? I'd be surprised if this happens - the models should be equivalent as regards their fitted intensity, etc.

Adrian Baddeley


Prof Adrian Baddeley DSc FAA
Department of Mathematics and Statistics
Curtin University, Perth, Western Australia


From luca.candeloro at gmail.com  Sun Apr 17 14:39:05 2016
From: luca.candeloro at gmail.com (Luca Candeloro)
Date: Sun, 17 Apr 2016 14:39:05 +0200
Subject: [R-sig-Geo] Questions about spatio-temporal modelling
Message-ID: <CAHF6YnkrjzYY6jpOndrjGtqSzUTR+9vW24=4mn70tO_tFbnDkw@mail.gmail.com>

Starting from environmental and metereological data, I have defined an
annual count variable (number of favourable events, raster type object).
The purpose of the analysis is to predict the next year favourable events
raster, given the time series (last 15 years).
Working at the pixel level, it would be possible to make a Poisson
regression, but treating pixels independently, would loose spatial
effects...
Which is, in your opinion, the best approach?
Is there a spatio-temporal model for this kind of data that could usefully
combine spatial effect  with time series analysis?
Thanks for any suggestions

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Apr 18 08:49:01 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 18 Apr 2016 08:49:01 +0200
Subject: [R-sig-Geo] Questions about spatio-temporal modelling
In-Reply-To: <CAHF6YnkrjzYY6jpOndrjGtqSzUTR+9vW24=4mn70tO_tFbnDkw@mail.gmail.com>
References: <CAHF6YnkrjzYY6jpOndrjGtqSzUTR+9vW24=4mn70tO_tFbnDkw@mail.gmail.com>
Message-ID: <CAJuCY5z0SbcZxA+_qhpEVeEKShDvuUtJYneXBbGsieMH_wtrOw@mail.gmail.com>

Dear Luca,

Have a look at Blangiarde & Cameletti (2015) Spatial and
Spatio-temporal Bayesian Models with R - INLA ISBN: 978-1-118-32655-8
They describe how you can tackle this problem with mixed models with
correlated random effects.

Best regards,
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2016-04-17 14:39 GMT+02:00 Luca Candeloro <luca.candeloro at gmail.com>:
> Starting from environmental and metereological data, I have defined an
> annual count variable (number of favourable events, raster type object).
> The purpose of the analysis is to predict the next year favourable events
> raster, given the time series (last 15 years).
> Working at the pixel level, it would be possible to make a Poisson
> regression, but treating pixels independently, would loose spatial
> effects...
> Which is, in your opinion, the best approach?
> Is there a spatio-temporal model for this kind of data that could usefully
> combine spatial effect  with time series analysis?
> Thanks for any suggestions
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From morera.virginia at gmail.com  Mon Apr 18 09:24:19 2016
From: morera.virginia at gmail.com (Virginia Morera Pujol)
Date: Mon, 18 Apr 2016 09:24:19 +0200
Subject: [R-sig-Geo] Correlation between covariates and intercept
	(spatstat)
In-Reply-To: <HK2PR02MB145906357FDC730517B1288BA46A0@HK2PR02MB1459.apcprd02.prod.outlook.com>
References: <mailman.3.1460887202.3820.r-sig-geo@r-project.org>
	<HK2PR02MB145906357FDC730517B1288BA46A0@HK2PR02MB1459.apcprd02.prod.outlook.com>
Message-ID: <CAJ3XaKd=tjZTBVMjFD041qWpoK+bAA-BD6UZMqXzv9EEk9S8qg@mail.gmail.com>

Hello,

You are right, what changes is the coefficient of the covariate, but it's
effect (coef+covariate value) is the same in both models, and selecting the
"significant covariates" won't be much of a problem as I only have 2
covariates in my model.

Thank you very much for your kind help!

Virginia Morera
PhD Student
Department of Animal Biology
University of Barcelona

Aquest correu electr?nic i els annexos poden contenir informaci?
confidencial o protegida legalment i est? adre?at exclusivament a la
persona o entitat destinat?ria. Si no sou  el destinatari final o la
persona encarregada de rebre?l, no esteu autoritzat a llegir-lo,
retenir-lo, modificar-lo, distribuir-lo, copiar-lo ni a revelar-ne el
contingut. Si heu rebut aquest correu electr?nic per error, us preguem que
n?informeu al remitent i que elimineu del sistema el missatge i el material
annex que pugui contenir. Gr?cies per la vostra col?laboraci?.

Este correo electr?nico y sus anexos pueden contener informaci?n
confidencial o legalmente protegida y est? exclusivamente dirigido a la
persona o entidad destinataria. Si usted no es el destinatario final o la
persona encargada de recibirlo, no est? autorizado a leerlo, retenerlo,
modificarlo, distribuirlo, copiarlo ni a revelar su contenido. Si ha
recibido este mensaje electr?nico por error, le rogamos que informe al
remitente y elimine del sistema el mensaje y el material anexo que pueda
contener. Gracias por su colaboraci?n.

This email message and any documents attached to it may contain
confidential or legally protected material and are intended solely for the
use of the individual or organization to whom they are addressed. We remind
you that if you are not the intended recipient of this email message or the
person responsible for processing it, then you are not authorized to read,
save, modify, send, copy or disclose any of its contents. If you have
received this email message by mistake, we kindly ask you to inform the
sender of this and to eliminate both the message and any attachments it
carries from your account.Thank you for your collaboration.

2016-04-17 12:36 GMT+02:00 Adrian Baddeley <adrian.baddeley at curtin.edu.au>:

> Virginia Morera Pujol <morera.virginia at gmail.com> writes:
>
> > In trying a spatial model with spatstat I am running into a conceptual
> > problem. It might be more of a general modelling doubt than a specific
> > spatial problem, but I hope someone can help.
>
> > I am running a ppm() model that includes two covariates (as pixel
> images),
> > one is primary productivity at sea, and the other is distance to a point
> > that is not included in the pattern window. That means there is no 0
> value,
> > the range of values goes from 400 to 1400 approx.  When I run the model
> and
> > look at the var-covar matrix using 'vcov(model, what = "corr")' , there
> is
> > a very strong correlation (around -0.85) between the intercept and this
> > covariate. I am not sure that this is a problem, but [...]
>
> This is about the correlation between *estimates* of the model
> coefficients - in this case, the correlation between the estimated
> intercept and the estimated coefficient of the distance covariate.
> Extremely high correlations could cause problems with the identifiability
> of the model, but this is probably not a problem here. Moderately high
> correlations suggest that the t-tests for individual parameters (given in
> the printout for the model) are not independent. If we want to select the
> 'significant' covariates, we shouldn't use the model printout to discard
> more than one variable at a time.
>
> >  I have tried a couple of things just in case:
>
> > 1/ centering the covariate values around the mean just changes the sign
> of
> > the correlation (from -0.85 to +0.85 approx).
>
> > 2/ normalizing the covariate values, so the values go from 0 to 1 makes
> the
> > correlation between this covariate and the intercept almost 1 (0.99) It
> > also makes the effect of this covariate three orders of magnitude higher
> > than the effect of the other covariate, which didn't happen before and
> was
> > not expected from the data.
>
> Such transformations will change the correlation. Roughly speaking, that's
> because when you add a constant to the distance covariate, you are adding a
> multiple of the intercept onto the covariate.
>
> When you say the 'effect' of the covariate has increased, do you mean the
> coefficient of the covariate has increased, or the *effect term* (=
> coefficient x covariate value) has increased? I'd be surprised if this
> happens - the models should be equivalent as regards their fitted
> intensity, etc.
>
> Adrian Baddeley
>
>
> Prof Adrian Baddeley DSc FAA
> Department of Mathematics and Statistics
> Curtin University, Perth, Western Australia
>

	[[alternative HTML version deleted]]


From matzke at nimbios.org  Sun Apr 17 06:37:32 2016
From: matzke at nimbios.org (Nick Matzke)
Date: Sun, 17 Apr 2016 14:37:32 +1000
Subject: [R-sig-Geo] [R-sig-phylo] BiSSE/MacroCAIC on Non-Ultrametric
	Tree with Polytomies?
In-Reply-To: <CAE58x0B4nCPK5UaBHz4dP1moyhFpACNDfhCZaDexs232r4ZAhA@mail.gmail.com>
References: <CAE58x0Cs3tgk7UkHmQ9La4z2O_GOsOL6_Nx1r2LfRoGN0J+9Rg@mail.gmail.com>
	<CADjhXeBh8vbcaEhWAe1AA_zuMndY-=dc6AB4=5hguMAbzYOmZQ@mail.gmail.com>
	<CAE58x0B4nCPK5UaBHz4dP1moyhFpACNDfhCZaDexs232r4ZAhA@mail.gmail.com>
Message-ID: <CAJdu7BD6sKKOcw9x_Pj-S-XqFgfQ7QayjEujjw8_xUumd2sT_Q@mail.gmail.com>

Hi again...brief thought -- I am so used to thinking about diversification
in terms of speciation and extinction rates in units of time, it's hard to
think about how a study of correlation between a trait and
diversification/species richness would work without a time-scaled tree.
However, there are some methods that use tree-balance statistics, and thus
only require topology -- see work by Brian Moore. I think they require
pretty dramatic differences between sister groups to infer rate shifts
though.  Cheers!
Nick



On Fri, Apr 15, 2016 at 6:59 AM, Brian A. Gill <gillbriana at gmail.com> wrote:

> Hi David and Joe.
>
> Thanks for your input/questions.
>
> David: My tree is non-ultrametric because it is undated tree of extant
> taxa. It does not include taxa from the fossil record. Making a dated tree
> seems like a good option, but what about the option of using NonParametric
> Rate Smoothing (NPRS) or some other conversion to make my existing tree
> ultrametric? I see this approach in some studies.
>
> Alternatively, sister-clade comparisons could be an option, but it seems
> like they are old and not powerful. Based on my tree topology and the
> number of taxa, I'm not sure I have enough contrasts for a robust test.
>
> Joe: For BiSSE, the discrete binary predictor is assumed to evolve
> according to a Markov model along the tree. The model is then used to
> estimate speciation, extinction, and character transition rates. For
> MacroCAIC, I assume the a discrete binary trait would be modeled in a
> similar way to determine the states of internal nodes on the tree.
>
> So, thinking about evolution of a discrete trait by a Markov process on a
> non-ultrametric tree, it seems for BiSSE having non-contemporaneous
> lineages would inappropriately inflate the extinction parameter. For
> MacroCAIC, I can't think of a reason why a non-ultrametric tree would be
> problematic other than how differences in lengths of branches based on
> relative divergence vs. absolute time might affect estimates of states at
> internal nodes. If this is the case, does that mean that other procedures
> using Markov transition matrices cannot be used on trees with relative
> divergence for branch lengths (e.g. stochastic character mapping)?
>
> Thanks for all the help.
>
>
> Brian
>
>
>
>
>
>
>
> On Thu, Apr 14, 2016 at 8:26 AM, David Bapst <dwbapst at gmail.com> wrote:
>
> > Brian-
> >
> > Is your tree non-ultrametric because it contains extinct taxa from the
> > fossil record, or is it simply an undated tree of extant taxa?
> >
> > To my knowledge, there isn't yet a satisfactory solution to the first
> > (no BISSE for paleo-phylogenies) but if the second then, it seems the
> > best route would be to date it and use the methods developed for
> > ultrametric trees.
> >
> > Cheers,
> > -Dave
> >
> > On Wed, Apr 13, 2016 at 3:09 PM, Brian A. Gill <gillbriana at gmail.com>
> > wrote:
> > > Hi Everyone.
> > >
> > > I'm trying to look at the association between a discrete binary
> predictor
> > > (Latitude: Colorado/Ecuador) and a continuous response (species
> > richness).
> > >
> > > My phylogeny is a 50% majority rule consensus tree made in MrBayes. The
> > > tree has polytomies and is not ultrametric.
> > >
> > > I've found the methods below for looking at the influence of a discrete
> > > binary trait on richness, but I'm not sure if my tree is suitable or if
> > > there is a better approach.
> > >
> > > 1) Diversitree package BiSSE
> > > 2) Caper package using MacroCAIC
> > >
> > > Any suggestions would be greatly appreciated.
> > >
> > > Thank You.
> > >
> > >
> > > Brian
> > >
> > > --
> > > Brian A. Gill
> > >
> > > VISIT MY WEBSITE:
> > > http://gillbriana.wix.com/brian-gill
> > >
> > > FOLLOW ME ON TWITTER:
> > > @CSUBrianGill
> > >
> > > Colorado State University Biology
> > > 1878 Campus Delivery
> > > Fort Collins, CO 80523
> > > United States of America
> > >
> > > 970-215-7037
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-phylo mailing list - R-sig-phylo at r-project.org
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-phylo
> > > Searchable archive at
> > http://www.mail-archive.com/r-sig-phylo at r-project.org/
> >
> >
> >
> > --
> > David W. Bapst, PhD
> > Adjunct Asst. Professor, Geology and Geol. Eng.
> > South Dakota School of Mines and Technology
> > 501 E. St. Joseph
> > Rapid City, SD 57701
> >
> > http://webpages.sdsmt.edu/~dbapst/
> > http://cran.r-project.org/web/packages/paleotree/index.html
> >
>
>
>
> --
> Brian A. Gill
>
> VISIT MY WEBSITE:
> http://gillbriana.wix.com/brian-gill
>
> FOLLOW ME ON TWITTER:
> @CSUBrianGill
>
> Colorado State University Biology
> 1878 Campus Delivery
> Fort Collins, CO 80523
> United States of America
>
> 970-215-7037
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-phylo mailing list - R-sig-phylo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-phylo
> Searchable archive at
> http://www.mail-archive.com/r-sig-phylo at r-project.org/
>

	[[alternative HTML version deleted]]


From janka.vanschoenwinkel at uhasselt.be  Tue Apr 19 10:45:24 2016
From: janka.vanschoenwinkel at uhasselt.be (Janka VANSCHOENWINKEL)
Date: Tue, 19 Apr 2016 10:45:24 +0200
Subject: [R-sig-Geo] Translate a net-cdf file with different years to
	polygon regions.
Message-ID: <CAHymutKcpgJoWExtVVLFsSJ8VG23-b1jumMrMivMk2ZO5Lu6Jg@mail.gmail.com>

*DATA*

I have a net-cdf file which has raster of 0.5 on 0.5 degrees. You can
easily download it here
<https://crudata.uea.ac.uk/cru/data/hrg/cru_ts_3.23/cruts.1506241137.v3.23/pet/>
and
search for *cru_ts3.23.2001.2010.pet.dat.nc.gz *(it is also downloadable as
a dat.file if this is more handy to work with)
 (Or simply download the net-cdf file directly through:
cru_ts3.23.2001.2010.pet.dat.nc.gz
<https://crudata.uea.ac.uk/cru/data/hrg/cru_ts_3.23/cruts.1506241137.v3.23/pet/cru_ts3.23.2001.2010.pet.dat.nc.gz>
).

I opened the file in ArcMap as well and found that the coordinate system
used is: GCS_WGS_1984. The net-cdf file contains monthly data from 2001-2010

Download from this website
<http://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units/nuts>
the
following ZIP file: *NUTS_2006_60M_SH.zip* and save all the *NUTS_RG_60M_2006
files *in a folder where you can easily find the back. In what follows I
refer to this as "NUTS3".

*WHAT I WANT*

- I want to add the information from the raster files to the NUTS3
shapefile (which are polygons and no rasters) in order to obtain a table
per nuts3 region for each monthtly variable.


*WHERE I AM STUCK*

The file appears to be very difficult to work with in ArcGis. Also, I will
have to repeat this process a number of times for different variables. So I
would like to have one code in R that I can run.

I have a number of separate codes to do the following:
- translate the net-cdf file to a cvs file with longitude and latitude as
identifiers (see below under 1)
- translate a cvs file with accompanying empty raster file to nuts3
regions. (this is a code that I have used before when I had a cvs file and
a raster). (see below under 2).

However, I don't have a raster file now. Well, technically I do (since the
net-ncf file is a raster) but I don't know how to use it in this format.

Can somebody help me to link the codes below or suggest a different code to
obtain what I want?

Thanks a lot!

Janka




*1) With the following code, I can make a cvs file and extract all the data
in table format.*

library(fields)
library(chron)

library(ncdf4)
ncname<-"cru_ts3.22.2001.2010.pet.dat"
ncname<-"cru_ts3.23.1991.2000.pet.dat"
ncfname <- paste(ncname, ".nc", sep = "")
dname <- "pet"
ncin <- nc_open(ncfname)
print(ncin)

lon <- ncvar_get(ncin, "lon")
nlon <- dim(lon)
head(lon)

lat <- ncvar_get(ncin, "lat", verbose = F)
nlat <- dim(lat)
head(lat)

print(c(nlon, nlat))


t <- ncvar_get(ncin, "time")
tunits <- ncatt_get(ncin, "time", "units")
nt <- dim(t)

tmp.array <- ncvar_get(ncin, dname)
dlname <- ncatt_get(ncin, dname, "long_name")
dunits <- ncatt_get(ncin, dname, "units")
fillvalue <- ncatt_get(ncin, dname, "_FillValue")
dim(tmp.array)

title <- ncatt_get(ncin, 0, "title")
institution <- ncatt_get(ncin, 0, "institution")
datasource <- ncatt_get(ncin, 0, "source")
references <- ncatt_get(ncin, 0, "references")
history <- ncatt_get(ncin, 0, "history")
Conventions <- ncatt_get(ncin, 0, "Conventions")



nc_close(ncin)

# split the time units string into fields
tustr <- strsplit(tunits$value, " ")
tdstr <- strsplit(unlist(tustr)[3], "-")
tmonth = as.integer(unlist(tdstr)[2])
tday = as.integer(unlist(tdstr)[3])
tyear = as.integer(unlist(tdstr)[1])
chron(t, origin = c(tmonth, tday, tyear))



tmp.array[tmp.array == fillvalue$value] <- NA

length(na.omit(as.vector(tmp.array[, , 1])))

m <- 1
tmp.slice <- tmp.array[, , m]
library(RColorBrewer)
image(lon, lat, tmp.slice, col = rev(brewer.pal(10, "RdBu")))

grid <- expand.grid(lon = lon, lat = lat)
cutpts <- c(-50, -40, -30, -20, -10, 0, 10, 20, 30, 40, 50)
levelplot(tmp.slice ~ lon * lat, data = grid, at = cutpts, cuts = 11,
pretty = T,
          col.regions = (rev(brewer.pal(10, "RdBu"))))


lonlat <- expand.grid(lon, lat)
tmp.vec <- as.vector(tmp.slice)
length(tmp.vec)

tmp.df01 <- data.frame(cbind(lonlat, tmp.vec))
names(tmp.df01) <- c("lon", "lat", paste(dname, as.character(m), sep = "_"))
head(na.omit(tmp.df01), 20)

csvfile <- "cru_tmp_1.csv"
write.table(na.omit(tmp.df01), csvfile, row.names = FALSE, sep = ",")


tmp.vec.long <- as.vector(tmp.array)
length(tmp.vec.long)

tmp.mat <- matrix(tmp.vec.long, nrow = nlon * nlat, ncol = nt)
dim(tmp.mat)

head(na.omit(tmp.mat))

lonlat <- expand.grid(lon, lat)
tmp.df02 <- data.frame(cbind(lonlat, tmp.mat))

names(tmp.df02) <- c("lon","lat","pet_jan_2001",
                     "pet_feb_2001",
                     "pet_mar_2001",
                     "pet_apr_2001",
                     "pet_may_2001",
                     "pet_jun_2001",
                     "pet_jul_2001",
                     "pet_aug_2001",
                     "pet_sep_2001",
                     "pet_oct_2001",
                     "pet_nov_2001",
                     "pet_dec_2001",
                     "pet_jan_2002",
                     "pet_feb_2002",
                     "pet_mar_2002",
                     "pet_apr_2002",
                     "pet_may_2002",
                     "pet_jun_2002",
                     "pet_jul_2002",
                     "pet_aug_2002",
                     "pet_sep_2002",
                     "pet_oct_2002",
                     "pet_nov_2002",
                     "pet_dec_2002",
                     "pet_jan_2003",
                     "pet_feb_2003",
                     "pet_mar_2003",
                     "pet_apr_2003",
                     "pet_may_2003",
                     "pet_jun_2003",
                     "pet_jul_2003",
                     "pet_aug_2003",
                     "pet_sep_2003",
                     "pet_oct_2003",
                     "pet_nov_2003",
                     "pet_dec_2003",
                     "pet_jan_2004",
                     "pet_feb_2004",
                     "pet_mar_2004",
                     "pet_apr_2004",
                     "pet_may_2004",
                     "pet_jun_2004",
                     "pet_jul_2004",
                     "pet_aug_2004",
                     "pet_sep_2004",
                     "pet_oct_2004",
                     "pet_nov_2004",
                     "pet_dec_2004",
                     "pet_jan_2005",
                     "pet_feb_2005",
                     "pet_mar_2005",
                     "pet_apr_2005",
                     "pet_may_2005",
                     "pet_jun_2005",
                     "pet_jul_2005",
                     "pet_aug_2005",
                     "pet_sep_2005",
                     "pet_oct_2005",
                     "pet_nov_2005",
                     "pet_dec_2005",
                     "pet_jan_2006",
                     "pet_feb_2006",
                     "pet_mar_2006",
                     "pet_apr_2006",
                     "pet_may_2006",
                     "pet_jun_2006",
                     "pet_jul_2006",
                     "pet_aug_2006",
                     "pet_sep_2006",
                     "pet_oct_2006",
                     "pet_nov_2006",
                     "pet_dec_2006",
                     "pet_jan_2007",
                     "pet_feb_2007",
                     "pet_mar_2007",
                     "pet_apr_2007",
                     "pet_may_2007",
                     "pet_jun_2007",
                     "pet_jul_2007",
                     "pet_aug_2007",
                     "pet_sep_2007",
                     "pet_oct_2007",
                     "pet_nov_2007",
                     "pet_dec_2007",
                     "pet_jan_2008",
                     "pet_feb_2008",
                     "pet_mar_2008",
                     "pet_apr_2008",
                     "pet_may_2008",
                     "pet_jun_2008",
                     "pet_jul_2008",
                     "pet_aug_2008",
                     "pet_sep_2008",
                     "pet_oct_2008",
                     "pet_nov_2008",
                     "pet_dec_2008",
                     "pet_jan_2009",
                     "pet_feb_2009",
                     "pet_mar_2009",
                     "pet_apr_2009",
                     "pet_may_2009",
                     "pet_jun_2009",
                     "pet_jul_2009",
                     "pet_aug_2009",
                     "pet_sep_2009",
                     "pet_oct_2009",
                     "pet_nov_2009",
                     "pet_dec_2009",
                     "pet_jan_2010",
                     "pet_feb_2010",
                     "pet_mar_2010",
                     "pet_apr_2010",
                     "pet_may_2010",
                     "pet_jun_2010",
                     "pet_jul_2010",
                     "pet_aug_2010",
                     "pet_sep_2010",
                     "pet_oct_2010",
                     "pet_nov_2010",
                     "pet_dec_2010")


options(width = 110)
head(na.omit(tmp.df02, 20))

dim(na.omit(tmp.df02))

csvfile <- "cru_tmp_2.csv"
write.table(na.omit(tmp.df02), csvfile, row.names = FALSE, sep = ",")



*2) translate a cvs-file with accompanying raster file to polygon regions.*

The  "filename.txt" file should contain the variables: lon, latitude, and
all the monthly_yearly variables extracted from point 1 above.

The grid shapefile (*grid_025dd.shp*) can be found through the following
link but it is only an example and not the correct grid for the problem
above :
https://drive.google.com/folderview?id=0By9u5m3kxn9yfjZtdFZLcW82SWpzT1VwZXE1a3FtRGtSdEl1c1NvY205TGpack9xSFc2T2s&usp=sharing

# upload data
mydata<-read.table("filename.txt", header=TRUE,sep=",",dec=".")


# upload empty raster
library(rgdal)
# 40 seconds
grid <- readOGR(".", layer = "grid_025dd")


# concatenate data in R
# 2 seconds
mydata$lonlat<-do.call(paste, c(mydata[c("lon", "lat")], sep=""))
grid at data$lonlat<-do.call(paste, c(grid at data[c("LONGITUDE", "LATITUDE")],
sep=""))

# use common variable lonlat to merge data in raster

###### prepare shapefile #####
library(rgdal)        ## Load geographic info
library(maps)         ## Projections
library(maptools)     ## Data management
#library(sm)           ## Data management
library(spdep)        ## Spatial autocorrelation
library(gstat)        ## Geostatistics
library(splancs)      ## Kernel Density
library(spatstat)     ## Geostatistics
library(pgirmess)     ## Spatial autocorrelation
library(RColorBrewer) ## Visualization
library(classInt)     ## Class intervals
library(spgwr)        ## GWR

# Match polygons with data
idx <- match(grid$lonlat, mydata$lonlat)
# Places without information
idxNA <- which(is.na(idx))
# Information to be added to the SpatialPolygons object
dat2add <- mydata[idx, ]
# spCbind uses row names to match polygons with data
# First, extract polygon IDs
IDs <- sapply(grid at polygons, function(x)x at ID)
# and join with the SpatialPolygons
row.names(dat2add) <- IDs
datPols <- spCbind(grid, dat2add)
# Drop those places without information
datPols <- datPols[-idxNA, ]
# write new shapefile
# 7 seconds
writeOGR(datPols, dsn = ".", layer ='sm2000eu28', driver = 'ESRI Shapefile')
# read new shapefile
# 51 seconds
data <- readOGR(".", layer="sm2000eu28")

############################
# intersect nuts with grid #
############################

library(rgdal)
nuts <- readOGR(".", layer = "NUTS_RG_60M_2006")

library(rgeos)
proj4string(data) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84")


#
grid <- data
grid at data$lonlat <- NULL
grid at data$lonlat_1 <- NULL
grid at data$ID <- NULL
grid at data$lat <- NULL
grid at data$lon <- NULL
grid at data$ELEVATION <- NULL
grid at data$DAYS_RAIN_ <- NULL


# First find out which grid cells intersect your NUTS polygons
grid_nuts <- gIntersects(grid,nuts,byid = TRUE)

# use the apply() function to calculate the mean, min, and max of your
value.
# The loop makes

for(i in names(grid at data)){
  nuts at data[[paste(i, 'average_value', sep="_")]] <-
apply(grid_nuts,1,function(x) mean(grid at data[[i]][x]))
  nuts at data[[paste(i, 'min_value', sep="_")]] <-
apply(grid_nuts,1,function(x) min(grid at data[[i]][x]))
  nuts at data[[paste(i, 'max_value', sep="_")]] <-
apply(grid_nuts,1,function(x) max(grid at data[[i]][x]))
}

write.table(nuts at data, "nuts_sm2000eu28_unweighted.txt", sep="\t")

	[[alternative HTML version deleted]]


From jstachel at sfwmd.gov  Tue Apr 19 14:23:04 2016
From: jstachel at sfwmd.gov (Stachelek, Joseph)
Date: Tue, 19 Apr 2016 12:23:04 +0000
Subject: [R-sig-Geo] Translate a net-cdf file with different years
	to	polygon regions.
In-Reply-To: <CAHymutKcpgJoWExtVVLFsSJ8VG23-b1jumMrMivMk2ZO5Lu6Jg@mail.gmail.com>
References: <CAHymutKcpgJoWExtVVLFsSJ8VG23-b1jumMrMivMk2ZO5Lu6Jg@mail.gmail.com>
Message-ID: <D51374C4B889BC47B3C5286047C86DA1A02C3A20@whqembx03p.ad.sfwmd.gov>

Hi Janka,

I think you can simplify your code a lot by opening your nc file directly using the `raster` package rather than messing with `nc_open` calls.

```
ncin <- raster::raster(paste(ncname, ".nc", sep = ""))
```

Then you might use `raster::extract()` to pull the values associated with your polygons. Also, I would recommend posting a link to a gist (https://gist.github.com/) rather than pasting such a long script into your email.

Joe

-----Original Message-----
From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Janka VANSCHOENWINKEL
Sent: Tuesday, April 19, 2016 4:45 AM
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] Translate a net-cdf file with different years to polygon regions.

*DATA*

I have a net-cdf file which has raster of 0.5 on 0.5 degrees. You can
easily download it here
<https://crudata.uea.ac.uk/cru/data/hrg/cru_ts_3.23/cruts.1506241137.v3.23/pet/>
and
search for *cru_ts3.23.2001.2010.pet.dat.nc.gz *(it is also downloadable as
a dat.file if this is more handy to work with)
 (Or simply download the net-cdf file directly through:
cru_ts3.23.2001.2010.pet.dat.nc.gz
<https://crudata.uea.ac.uk/cru/data/hrg/cru_ts_3.23/cruts.1506241137.v3.23/pet/cru_ts3.23.2001.2010.pet.dat.nc.gz>
).

I opened the file in ArcMap as well and found that the coordinate system
used is: GCS_WGS_1984. The net-cdf file contains monthly data from 2001-2010

Download from this website
<http://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units/nuts>
the
following ZIP file: *NUTS_2006_60M_SH.zip* and save all the *NUTS_RG_60M_2006
files *in a folder where you can easily find the back. In what follows I
refer to this as "NUTS3".

*WHAT I WANT*

- I want to add the information from the raster files to the NUTS3
shapefile (which are polygons and no rasters) in order to obtain a table
per nuts3 region for each monthtly variable.


*WHERE I AM STUCK*

The file appears to be very difficult to work with in ArcGis. Also, I will
have to repeat this process a number of times for different variables. So I
would like to have one code in R that I can run.

I have a number of separate codes to do the following:
- translate the net-cdf file to a cvs file with longitude and latitude as
identifiers (see below under 1)
- translate a cvs file with accompanying empty raster file to nuts3
regions. (this is a code that I have used before when I had a cvs file and
a raster). (see below under 2).

However, I don't have a raster file now. Well, technically I do (since the
net-ncf file is a raster) but I don't know how to use it in this format.

Can somebody help me to link the codes below or suggest a different code to
obtain what I want?

Thanks a lot!

Janka




*1) With the following code, I can make a cvs file and extract all the data
in table format.*

library(fields)
library(chron)

library(ncdf4)
ncname<-"cru_ts3.22.2001.2010.pet.dat"
ncname<-"cru_ts3.23.1991.2000.pet.dat"
ncfname <- paste(ncname, ".nc", sep = "")
dname <- "pet"
ncin <- nc_open(ncfname)
print(ncin)

lon <- ncvar_get(ncin, "lon")
nlon <- dim(lon)
head(lon)

lat <- ncvar_get(ncin, "lat", verbose = F)
nlat <- dim(lat)
head(lat)

print(c(nlon, nlat))


t <- ncvar_get(ncin, "time")
tunits <- ncatt_get(ncin, "time", "units")
nt <- dim(t)

tmp.array <- ncvar_get(ncin, dname)
dlname <- ncatt_get(ncin, dname, "long_name")
dunits <- ncatt_get(ncin, dname, "units")
fillvalue <- ncatt_get(ncin, dname, "_FillValue")
dim(tmp.array)

title <- ncatt_get(ncin, 0, "title")
institution <- ncatt_get(ncin, 0, "institution")
datasource <- ncatt_get(ncin, 0, "source")
references <- ncatt_get(ncin, 0, "references")
history <- ncatt_get(ncin, 0, "history")
Conventions <- ncatt_get(ncin, 0, "Conventions")



nc_close(ncin)

# split the time units string into fields
tustr <- strsplit(tunits$value, " ")
tdstr <- strsplit(unlist(tustr)[3], "-")
tmonth = as.integer(unlist(tdstr)[2])
tday = as.integer(unlist(tdstr)[3])
tyear = as.integer(unlist(tdstr)[1])
chron(t, origin = c(tmonth, tday, tyear))



tmp.array[tmp.array == fillvalue$value] <- NA

length(na.omit(as.vector(tmp.array[, , 1])))

m <- 1
tmp.slice <- tmp.array[, , m]
library(RColorBrewer)
image(lon, lat, tmp.slice, col = rev(brewer.pal(10, "RdBu")))

grid <- expand.grid(lon = lon, lat = lat)
cutpts <- c(-50, -40, -30, -20, -10, 0, 10, 20, 30, 40, 50)
levelplot(tmp.slice ~ lon * lat, data = grid, at = cutpts, cuts = 11,
pretty = T,
          col.regions = (rev(brewer.pal(10, "RdBu"))))


lonlat <- expand.grid(lon, lat)
tmp.vec <- as.vector(tmp.slice)
length(tmp.vec)

tmp.df01 <- data.frame(cbind(lonlat, tmp.vec))
names(tmp.df01) <- c("lon", "lat", paste(dname, as.character(m), sep = "_"))
head(na.omit(tmp.df01), 20)

csvfile <- "cru_tmp_1.csv"
write.table(na.omit(tmp.df01), csvfile, row.names = FALSE, sep = ",")


tmp.vec.long <- as.vector(tmp.array)
length(tmp.vec.long)

tmp.mat <- matrix(tmp.vec.long, nrow = nlon * nlat, ncol = nt)
dim(tmp.mat)

head(na.omit(tmp.mat))

lonlat <- expand.grid(lon, lat)
tmp.df02 <- data.frame(cbind(lonlat, tmp.mat))

names(tmp.df02) <- c("lon","lat","pet_jan_2001",
                     "pet_feb_2001",
                     "pet_mar_2001",
                     "pet_apr_2001",
                     "pet_may_2001",
                     "pet_jun_2001",
                     "pet_jul_2001",
                     "pet_aug_2001",
                     "pet_sep_2001",
                     "pet_oct_2001",
                     "pet_nov_2001",
                     "pet_dec_2001",
                     "pet_jan_2002",
                     "pet_feb_2002",
                     "pet_mar_2002",
                     "pet_apr_2002",
                     "pet_may_2002",
                     "pet_jun_2002",
                     "pet_jul_2002",
                     "pet_aug_2002",
                     "pet_sep_2002",
                     "pet_oct_2002",
                     "pet_nov_2002",
                     "pet_dec_2002",
                     "pet_jan_2003",
                     "pet_feb_2003",
                     "pet_mar_2003",
                     "pet_apr_2003",
                     "pet_may_2003",
                     "pet_jun_2003",
                     "pet_jul_2003",
                     "pet_aug_2003",
                     "pet_sep_2003",
                     "pet_oct_2003",
                     "pet_nov_2003",
                     "pet_dec_2003",
                     "pet_jan_2004",
                     "pet_feb_2004",
                     "pet_mar_2004",
                     "pet_apr_2004",
                     "pet_may_2004",
                     "pet_jun_2004",
                     "pet_jul_2004",
                     "pet_aug_2004",
                     "pet_sep_2004",
                     "pet_oct_2004",
                     "pet_nov_2004",
                     "pet_dec_2004",
                     "pet_jan_2005",
                     "pet_feb_2005",
                     "pet_mar_2005",
                     "pet_apr_2005",
                     "pet_may_2005",
                     "pet_jun_2005",
                     "pet_jul_2005",
                     "pet_aug_2005",
                     "pet_sep_2005",
                     "pet_oct_2005",
                     "pet_nov_2005",
                     "pet_dec_2005",
                     "pet_jan_2006",
                     "pet_feb_2006",
                     "pet_mar_2006",
                     "pet_apr_2006",
                     "pet_may_2006",
                     "pet_jun_2006",
                     "pet_jul_2006",
                     "pet_aug_2006",
                     "pet_sep_2006",
                     "pet_oct_2006",
                     "pet_nov_2006",
                     "pet_dec_2006",
                     "pet_jan_2007",
                     "pet_feb_2007",
                     "pet_mar_2007",
                     "pet_apr_2007",
                     "pet_may_2007",
                     "pet_jun_2007",
                     "pet_jul_2007",
                     "pet_aug_2007",
                     "pet_sep_2007",
                     "pet_oct_2007",
                     "pet_nov_2007",
                     "pet_dec_2007",
                     "pet_jan_2008",
                     "pet_feb_2008",
                     "pet_mar_2008",
                     "pet_apr_2008",
                     "pet_may_2008",
                     "pet_jun_2008",
                     "pet_jul_2008",
                     "pet_aug_2008",
                     "pet_sep_2008",
                     "pet_oct_2008",
                     "pet_nov_2008",
                     "pet_dec_2008",
                     "pet_jan_2009",
                     "pet_feb_2009",
                     "pet_mar_2009",
                     "pet_apr_2009",
                     "pet_may_2009",
                     "pet_jun_2009",
                     "pet_jul_2009",
                     "pet_aug_2009",
                     "pet_sep_2009",
                     "pet_oct_2009",
                     "pet_nov_2009",
                     "pet_dec_2009",
                     "pet_jan_2010",
                     "pet_feb_2010",
                     "pet_mar_2010",
                     "pet_apr_2010",
                     "pet_may_2010",
                     "pet_jun_2010",
                     "pet_jul_2010",
                     "pet_aug_2010",
                     "pet_sep_2010",
                     "pet_oct_2010",
                     "pet_nov_2010",
                     "pet_dec_2010")


options(width = 110)
head(na.omit(tmp.df02, 20))

dim(na.omit(tmp.df02))

csvfile <- "cru_tmp_2.csv"
write.table(na.omit(tmp.df02), csvfile, row.names = FALSE, sep = ",")



*2) translate a cvs-file with accompanying raster file to polygon regions.*

The  "filename.txt" file should contain the variables: lon, latitude, and
all the monthly_yearly variables extracted from point 1 above.

The grid shapefile (*grid_025dd.shp*) can be found through the following
link but it is only an example and not the correct grid for the problem
above :
https://drive.google.com/folderview?id=0By9u5m3kxn9yfjZtdFZLcW82SWpzT1VwZXE1a3FtRGtSdEl1c1NvY205TGpack9xSFc2T2s&usp=sharing

# upload data
mydata<-read.table("filename.txt", header=TRUE,sep=",",dec=".")


# upload empty raster
library(rgdal)
# 40 seconds
grid <- readOGR(".", layer = "grid_025dd")


# concatenate data in R
# 2 seconds
mydata$lonlat<-do.call(paste, c(mydata[c("lon", "lat")], sep=""))
grid at data$lonlat<-do.call(paste, c(grid at data[c("LONGITUDE", "LATITUDE")],
sep=""))

# use common variable lonlat to merge data in raster

###### prepare shapefile #####
library(rgdal)        ## Load geographic info
library(maps)         ## Projections
library(maptools)     ## Data management
#library(sm)           ## Data management
library(spdep)        ## Spatial autocorrelation
library(gstat)        ## Geostatistics
library(splancs)      ## Kernel Density
library(spatstat)     ## Geostatistics
library(pgirmess)     ## Spatial autocorrelation
library(RColorBrewer) ## Visualization
library(classInt)     ## Class intervals
library(spgwr)        ## GWR

# Match polygons with data
idx <- match(grid$lonlat, mydata$lonlat)
# Places without information
idxNA <- which(is.na(idx))
# Information to be added to the SpatialPolygons object
dat2add <- mydata[idx, ]
# spCbind uses row names to match polygons with data
# First, extract polygon IDs
IDs <- sapply(grid at polygons, function(x)x at ID)
# and join with the SpatialPolygons
row.names(dat2add) <- IDs
datPols <- spCbind(grid, dat2add)
# Drop those places without information
datPols <- datPols[-idxNA, ]
# write new shapefile
# 7 seconds
writeOGR(datPols, dsn = ".", layer ='sm2000eu28', driver = 'ESRI Shapefile')
# read new shapefile
# 51 seconds
data <- readOGR(".", layer="sm2000eu28")

############################
# intersect nuts with grid #
############################

library(rgdal)
nuts <- readOGR(".", layer = "NUTS_RG_60M_2006")

library(rgeos)
proj4string(data) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84")


#
grid <- data
grid at data$lonlat <- NULL
grid at data$lonlat_1 <- NULL
grid at data$ID <- NULL
grid at data$lat <- NULL
grid at data$lon <- NULL
grid at data$ELEVATION <- NULL
grid at data$DAYS_RAIN_ <- NULL


# First find out which grid cells intersect your NUTS polygons
grid_nuts <- gIntersects(grid,nuts,byid = TRUE)

# use the apply() function to calculate the mean, min, and max of your
value.
# The loop makes

for(i in names(grid at data)){
  nuts at data[[paste(i, 'average_value', sep="_")]] <-
apply(grid_nuts,1,function(x) mean(grid at data[[i]][x]))
  nuts at data[[paste(i, 'min_value', sep="_")]] <-
apply(grid_nuts,1,function(x) min(grid at data[[i]][x]))
  nuts at data[[paste(i, 'max_value', sep="_")]] <-
apply(grid_nuts,1,function(x) max(grid at data[[i]][x]))
}

write.table(nuts at data, "nuts_sm2000eu28_unweighted.txt", sep="\t")

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


We value your opinion. Please take a few minutes to shar...{{dropped:5}}


From jstachel at sfwmd.gov  Tue Apr 19 14:42:51 2016
From: jstachel at sfwmd.gov (Stachelek, Joseph)
Date: Tue, 19 Apr 2016 12:42:51 +0000
Subject: [R-sig-Geo] Translate a net-cdf file with different years
	to	polygon regions.
In-Reply-To: <D51374C4B889BC47B3C5286047C86DA1A02C3A20@whqembx03p.ad.sfwmd.gov>
References: <CAHymutKcpgJoWExtVVLFsSJ8VG23-b1jumMrMivMk2ZO5Lu6Jg@mail.gmail.com>
	<D51374C4B889BC47B3C5286047C86DA1A02C3A20@whqembx03p.ad.sfwmd.gov>
Message-ID: <D51374C4B889BC47B3C5286047C86DA1A02C3A70@whqembx03p.ad.sfwmd.gov>

Since your nc file contains multiple layers, you will want to use `raster::stack()` rather than `raster::raster()`.


-----Original Message-----
From: Stachelek, Joseph
Sent: Tuesday, April 19, 2016 8:23 AM
To: 'Janka VANSCHOENWINKEL' <janka.vanschoenwinkel at uhasselt.be>; r-sig-geo at r-project.org
Subject: RE: [R-sig-Geo] Translate a net-cdf file with different years to polygon regions.

Hi Janka,

I think you can simplify your code a lot by opening your nc file directly using the `raster` package rather than messing with `nc_open` calls.

```
ncin <- raster::raster(paste(ncname, ".nc", sep = ""))
```

Then you might use `raster::extract()` to pull the values associated with your polygons. Also, I would recommend posting a link to a gist (https://gist.github.com/) rather than pasting such a long script into your email.

Joe

-----Original Message-----
From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Janka VANSCHOENWINKEL
Sent: Tuesday, April 19, 2016 4:45 AM
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] Translate a net-cdf file with different years to polygon regions.

*DATA*

I have a net-cdf file which has raster of 0.5 on 0.5 degrees. You can
easily download it here
<https://crudata.uea.ac.uk/cru/data/hrg/cru_ts_3.23/cruts.1506241137.v3.23/pet/>
and
search for *cru_ts3.23.2001.2010.pet.dat.nc.gz *(it is also downloadable as
a dat.file if this is more handy to work with)
 (Or simply download the net-cdf file directly through:
cru_ts3.23.2001.2010.pet.dat.nc.gz
<https://crudata.uea.ac.uk/cru/data/hrg/cru_ts_3.23/cruts.1506241137.v3.23/pet/cru_ts3.23.2001.2010.pet.dat.nc.gz>
).

I opened the file in ArcMap as well and found that the coordinate system
used is: GCS_WGS_1984. The net-cdf file contains monthly data from 2001-2010

Download from this website
<http://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units/nuts>
the
following ZIP file: *NUTS_2006_60M_SH.zip* and save all the *NUTS_RG_60M_2006
files *in a folder where you can easily find the back. In what follows I
refer to this as "NUTS3".

*WHAT I WANT*

- I want to add the information from the raster files to the NUTS3
shapefile (which are polygons and no rasters) in order to obtain a table
per nuts3 region for each monthtly variable.


*WHERE I AM STUCK*

The file appears to be very difficult to work with in ArcGis. Also, I will
have to repeat this process a number of times for different variables. So I
would like to have one code in R that I can run.

I have a number of separate codes to do the following:
- translate the net-cdf file to a cvs file with longitude and latitude as
identifiers (see below under 1)
- translate a cvs file with accompanying empty raster file to nuts3
regions. (this is a code that I have used before when I had a cvs file and
a raster). (see below under 2).

However, I don't have a raster file now. Well, technically I do (since the
net-ncf file is a raster) but I don't know how to use it in this format.

Can somebody help me to link the codes below or suggest a different code to
obtain what I want?

Thanks a lot!

Janka




*1) With the following code, I can make a cvs file and extract all the data
in table format.*

library(fields)
library(chron)

library(ncdf4)
ncname<-"cru_ts3.22.2001.2010.pet.dat"
ncname<-"cru_ts3.23.1991.2000.pet.dat"
ncfname <- paste(ncname, ".nc", sep = "")
dname <- "pet"
ncin <- nc_open(ncfname)
print(ncin)

lon <- ncvar_get(ncin, "lon")
nlon <- dim(lon)
head(lon)

lat <- ncvar_get(ncin, "lat", verbose = F)
nlat <- dim(lat)
head(lat)

print(c(nlon, nlat))


t <- ncvar_get(ncin, "time")
tunits <- ncatt_get(ncin, "time", "units")
nt <- dim(t)

tmp.array <- ncvar_get(ncin, dname)
dlname <- ncatt_get(ncin, dname, "long_name")
dunits <- ncatt_get(ncin, dname, "units")
fillvalue <- ncatt_get(ncin, dname, "_FillValue")
dim(tmp.array)

title <- ncatt_get(ncin, 0, "title")
institution <- ncatt_get(ncin, 0, "institution")
datasource <- ncatt_get(ncin, 0, "source")
references <- ncatt_get(ncin, 0, "references")
history <- ncatt_get(ncin, 0, "history")
Conventions <- ncatt_get(ncin, 0, "Conventions")



nc_close(ncin)

# split the time units string into fields
tustr <- strsplit(tunits$value, " ")
tdstr <- strsplit(unlist(tustr)[3], "-")
tmonth = as.integer(unlist(tdstr)[2])
tday = as.integer(unlist(tdstr)[3])
tyear = as.integer(unlist(tdstr)[1])
chron(t, origin = c(tmonth, tday, tyear))



tmp.array[tmp.array == fillvalue$value] <- NA

length(na.omit(as.vector(tmp.array[, , 1])))

m <- 1
tmp.slice <- tmp.array[, , m]
library(RColorBrewer)
image(lon, lat, tmp.slice, col = rev(brewer.pal(10, "RdBu")))

grid <- expand.grid(lon = lon, lat = lat)
cutpts <- c(-50, -40, -30, -20, -10, 0, 10, 20, 30, 40, 50)
levelplot(tmp.slice ~ lon * lat, data = grid, at = cutpts, cuts = 11,
pretty = T,
          col.regions = (rev(brewer.pal(10, "RdBu"))))


lonlat <- expand.grid(lon, lat)
tmp.vec <- as.vector(tmp.slice)
length(tmp.vec)

tmp.df01 <- data.frame(cbind(lonlat, tmp.vec))
names(tmp.df01) <- c("lon", "lat", paste(dname, as.character(m), sep = "_"))
head(na.omit(tmp.df01), 20)

csvfile <- "cru_tmp_1.csv"
write.table(na.omit(tmp.df01), csvfile, row.names = FALSE, sep = ",")


tmp.vec.long <- as.vector(tmp.array)
length(tmp.vec.long)

tmp.mat <- matrix(tmp.vec.long, nrow = nlon * nlat, ncol = nt)
dim(tmp.mat)

head(na.omit(tmp.mat))

lonlat <- expand.grid(lon, lat)
tmp.df02 <- data.frame(cbind(lonlat, tmp.mat))

names(tmp.df02) <- c("lon","lat","pet_jan_2001",
                     "pet_feb_2001",
                     "pet_mar_2001",
                     "pet_apr_2001",
                     "pet_may_2001",
                     "pet_jun_2001",
                     "pet_jul_2001",
                     "pet_aug_2001",
                     "pet_sep_2001",
                     "pet_oct_2001",
                     "pet_nov_2001",
                     "pet_dec_2001",
                     "pet_jan_2002",
                     "pet_feb_2002",
                     "pet_mar_2002",
                     "pet_apr_2002",
                     "pet_may_2002",
                     "pet_jun_2002",
                     "pet_jul_2002",
                     "pet_aug_2002",
                     "pet_sep_2002",
                     "pet_oct_2002",
                     "pet_nov_2002",
                     "pet_dec_2002",
                     "pet_jan_2003",
                     "pet_feb_2003",
                     "pet_mar_2003",
                     "pet_apr_2003",
                     "pet_may_2003",
                     "pet_jun_2003",
                     "pet_jul_2003",
                     "pet_aug_2003",
                     "pet_sep_2003",
                     "pet_oct_2003",
                     "pet_nov_2003",
                     "pet_dec_2003",
                     "pet_jan_2004",
                     "pet_feb_2004",
                     "pet_mar_2004",
                     "pet_apr_2004",
                     "pet_may_2004",
                     "pet_jun_2004",
                     "pet_jul_2004",
                     "pet_aug_2004",
                     "pet_sep_2004",
                     "pet_oct_2004",
                     "pet_nov_2004",
                     "pet_dec_2004",
                     "pet_jan_2005",
                     "pet_feb_2005",
                     "pet_mar_2005",
                     "pet_apr_2005",
                     "pet_may_2005",
                     "pet_jun_2005",
                     "pet_jul_2005",
                     "pet_aug_2005",
                     "pet_sep_2005",
                     "pet_oct_2005",
                     "pet_nov_2005",
                     "pet_dec_2005",
                     "pet_jan_2006",
                     "pet_feb_2006",
                     "pet_mar_2006",
                     "pet_apr_2006",
                     "pet_may_2006",
                     "pet_jun_2006",
                     "pet_jul_2006",
                     "pet_aug_2006",
                     "pet_sep_2006",
                     "pet_oct_2006",
                     "pet_nov_2006",
                     "pet_dec_2006",
                     "pet_jan_2007",
                     "pet_feb_2007",
                     "pet_mar_2007",
                     "pet_apr_2007",
                     "pet_may_2007",
                     "pet_jun_2007",
                     "pet_jul_2007",
                     "pet_aug_2007",
                     "pet_sep_2007",
                     "pet_oct_2007",
                     "pet_nov_2007",
                     "pet_dec_2007",
                     "pet_jan_2008",
                     "pet_feb_2008",
                     "pet_mar_2008",
                     "pet_apr_2008",
                     "pet_may_2008",
                     "pet_jun_2008",
                     "pet_jul_2008",
                     "pet_aug_2008",
                     "pet_sep_2008",
                     "pet_oct_2008",
                     "pet_nov_2008",
                     "pet_dec_2008",
                     "pet_jan_2009",
                     "pet_feb_2009",
                     "pet_mar_2009",
                     "pet_apr_2009",
                     "pet_may_2009",
                     "pet_jun_2009",
                     "pet_jul_2009",
                     "pet_aug_2009",
                     "pet_sep_2009",
                     "pet_oct_2009",
                     "pet_nov_2009",
                     "pet_dec_2009",
                     "pet_jan_2010",
                     "pet_feb_2010",
                     "pet_mar_2010",
                     "pet_apr_2010",
                     "pet_may_2010",
                     "pet_jun_2010",
                     "pet_jul_2010",
                     "pet_aug_2010",
                     "pet_sep_2010",
                     "pet_oct_2010",
                     "pet_nov_2010",
                     "pet_dec_2010")


options(width = 110)
head(na.omit(tmp.df02, 20))

dim(na.omit(tmp.df02))

csvfile <- "cru_tmp_2.csv"
write.table(na.omit(tmp.df02), csvfile, row.names = FALSE, sep = ",")



*2) translate a cvs-file with accompanying raster file to polygon regions.*

The  "filename.txt" file should contain the variables: lon, latitude, and
all the monthly_yearly variables extracted from point 1 above.

The grid shapefile (*grid_025dd.shp*) can be found through the following
link but it is only an example and not the correct grid for the problem
above :
https://drive.google.com/folderview?id=0By9u5m3kxn9yfjZtdFZLcW82SWpzT1VwZXE1a3FtRGtSdEl1c1NvY205TGpack9xSFc2T2s&usp=sharing

# upload data
mydata<-read.table("filename.txt", header=TRUE,sep=",",dec=".")


# upload empty raster
library(rgdal)
# 40 seconds
grid <- readOGR(".", layer = "grid_025dd")


# concatenate data in R
# 2 seconds
mydata$lonlat<-do.call(paste, c(mydata[c("lon", "lat")], sep=""))
grid at data$lonlat<-do.call(paste, c(grid at data[c("LONGITUDE", "LATITUDE")],
sep=""))

# use common variable lonlat to merge data in raster

###### prepare shapefile #####
library(rgdal)        ## Load geographic info
library(maps)         ## Projections
library(maptools)     ## Data management
#library(sm)           ## Data management
library(spdep)        ## Spatial autocorrelation
library(gstat)        ## Geostatistics
library(splancs)      ## Kernel Density
library(spatstat)     ## Geostatistics
library(pgirmess)     ## Spatial autocorrelation
library(RColorBrewer) ## Visualization
library(classInt)     ## Class intervals
library(spgwr)        ## GWR

# Match polygons with data
idx <- match(grid$lonlat, mydata$lonlat)
# Places without information
idxNA <- which(is.na(idx))
# Information to be added to the SpatialPolygons object
dat2add <- mydata[idx, ]
# spCbind uses row names to match polygons with data
# First, extract polygon IDs
IDs <- sapply(grid at polygons, function(x)x at ID)
# and join with the SpatialPolygons
row.names(dat2add) <- IDs
datPols <- spCbind(grid, dat2add)
# Drop those places without information
datPols <- datPols[-idxNA, ]
# write new shapefile
# 7 seconds
writeOGR(datPols, dsn = ".", layer ='sm2000eu28', driver = 'ESRI Shapefile')
# read new shapefile
# 51 seconds
data <- readOGR(".", layer="sm2000eu28")

############################
# intersect nuts with grid #
############################

library(rgdal)
nuts <- readOGR(".", layer = "NUTS_RG_60M_2006")

library(rgeos)
proj4string(data) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84")


#
grid <- data
grid at data$lonlat <- NULL
grid at data$lonlat_1 <- NULL
grid at data$ID <- NULL
grid at data$lat <- NULL
grid at data$lon <- NULL
grid at data$ELEVATION <- NULL
grid at data$DAYS_RAIN_ <- NULL


# First find out which grid cells intersect your NUTS polygons
grid_nuts <- gIntersects(grid,nuts,byid = TRUE)

# use the apply() function to calculate the mean, min, and max of your
value.
# The loop makes

for(i in names(grid at data)){
  nuts at data[[paste(i, 'average_value', sep="_")]] <-
apply(grid_nuts,1,function(x) mean(grid at data[[i]][x]))
  nuts at data[[paste(i, 'min_value', sep="_")]] <-
apply(grid_nuts,1,function(x) min(grid at data[[i]][x]))
  nuts at data[[paste(i, 'max_value', sep="_")]] <-
apply(grid_nuts,1,function(x) max(grid at data[[i]][x]))
}

write.table(nuts at data, "nuts_sm2000eu28_unweighted.txt", sep="\t")

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


We value your opinion. Please take a few minutes to shar...{{dropped:5}}


From diego.pavonjordan at gmail.com  Wed Apr 20 08:45:12 2016
From: diego.pavonjordan at gmail.com (Diego Pavon)
Date: Wed, 20 Apr 2016 09:45:12 +0300
Subject: [R-sig-Geo] how to calculate centroid (or centre of gravity) of a
 population (count data)
Message-ID: <CAD93_Fq=usykO-kZKRTUv9grK_ce_E-USH1w1fs2RjYZRmhqMQ@mail.gmail.com>

Dear all

I am working with count data and I want to assess whether the centre of
gravity of the population (centroid or mean latitude?) has change over
time, indicating some redistribution or shift ongoing. To simplify, let's
say that I have ca. 2000 sites censused in two consecutive years (same
sites censused both years - all sites) and the abundance (count) of the
species registered.

I first thought about doing a kernelUD (package adehabitatHR) but
apparently this only takes into account the location of the sites to
calculate the kernel and then the centroids. Thus, since I have the exact
same sites in both years, the centroids for year 1 and year 2 are the same.
In my case, what I would like to do is to calculate that centroid but
taking into account the counts, because a site that had 3 individuals in
both years can't have the same weight than a site that hosted 3000
individuals when calculating the centroids.

So, what I would like to have is the centroid (or centre of gravity) of the
counts not of the sites surveyed (which is what adehabitatHR does,a s far
as I understood).

Do you have any suggestions which package other than adehabitatXX to use
for this purpose? Or if this can be done with adehabitat?

Thank you very much for your help.

Diego


















-- 
*Diego Pav?n Jord?n*

*Finnish Museum of Natural History*
*PO BOX 17 *

*Helsinki. Finland*



*0445061210https://tuhat.halvi.helsinki.fi/portal/en/persons/diego-pavon-jordan%288d5db37c-eddd-4fca-92cd-9c9956a42b4a%29.html
<https://tuhat.halvi.helsinki.fi/portal/en/persons/diego-pavon-jordan%288d5db37c-eddd-4fca-92cd-9c9956a42b4a%29.html>http://www.linkedin.com/profile/view?id=170617924&trk=nav_responsive_tab_profile
<http://www.linkedin.com/profile/view?id=170617924&trk=nav_responsive_tab_profile>https://helsinki.academia.edu/DiegoPavon
<https://helsinki.academia.edu/DiegoPavon>*

	[[alternative HTML version deleted]]


From youba.ndiaye at dijon.inra.fr  Wed Apr 20 10:21:04 2016
From: youba.ndiaye at dijon.inra.fr (Youba Ndiaye)
Date: Wed, 20 Apr 2016 10:21:04 +0200
Subject: [R-sig-Geo] Help: impact measures in spatial panel durbin model
Message-ID: <20160420102104.Horde.ZdntjjY3CNxLklVe9gs6zA3@webmail.dijon.inra.fr>

Dear all,

I'm a Ph.D student? and I'm working on spatial econometrics approach.

I want to implement?a static spatial durbin model??in R? with "splm"
function. But the particular case of my model is that my durbin model is
partial such as: ?
y = rho.Wy + X.beta + WZ.theta + epsilon? ?

X and Z are vectors?of explanatory variables with respectively (N,k) and
(N, m) dimensions. k>m. In orders words, the Z is a spatially lagged subset
of X.

My aim is to calculate properly impact measures of this model in R.

Thank You?in advance.
Best regards.
Youba.

	[[alternative HTML version deleted]]


From marcelino.delacruz at upm.es  Wed Apr 20 10:36:59 2016
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Wed, 20 Apr 2016 10:36:59 +0200
Subject: [R-sig-Geo] how to calculate centroid (or centre of gravity) of
 a population (count data)
In-Reply-To: <CAD93_Fq=usykO-kZKRTUv9grK_ce_E-USH1w1fs2RjYZRmhqMQ@mail.gmail.com>
References: <CAD93_Fq=usykO-kZKRTUv9grK_ce_E-USH1w1fs2RjYZRmhqMQ@mail.gmail.com>
Message-ID: <57173FAB.50900@upm.es>

Hi Diego,

it seems to me that what you want to compute are weighted centroids.

Here some advice is given (it is for polygons but you can get the idea):

https://stat.ethz.ch/pipermail/r-sig-geo/2016-February/024107.html

Cheers,

Marcelino



El 20/04/2016 a las 8:45, Diego Pavon escribi?:
> Dear all
>
> I am working with count data and I want to assess whether the centre of
> gravity of the population (centroid or mean latitude?) has change over
> time, indicating some redistribution or shift ongoing. To simplify, let's
> say that I have ca. 2000 sites censused in two consecutive years (same
> sites censused both years - all sites) and the abundance (count) of the
> species registered.
>
> I first thought about doing a kernelUD (package adehabitatHR) but
> apparently this only takes into account the location of the sites to
> calculate the kernel and then the centroids. Thus, since I have the exact
> same sites in both years, the centroids for year 1 and year 2 are the same.
> In my case, what I would like to do is to calculate that centroid but
> taking into account the counts, because a site that had 3 individuals in
> both years can't have the same weight than a site that hosted 3000
> individuals when calculating the centroids.
>
> So, what I would like to have is the centroid (or centre of gravity) of the
> counts not of the sites surveyed (which is what adehabitatHR does,a s far
> as I understood).
>
> Do you have any suggestions which package other than adehabitatXX to use
> for this purpose? Or if this can be done with adehabitat?
>
> Thank you very much for your help.
>
> Diego
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>


From r.turner at auckland.ac.nz  Wed Apr 20 12:00:34 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 20 Apr 2016 22:00:34 +1200
Subject: [R-sig-Geo] [FORGED] how to calculate centroid (or centre of
 gravity) of a population (count data)
In-Reply-To: <CAD93_Fq=usykO-kZKRTUv9grK_ce_E-USH1w1fs2RjYZRmhqMQ@mail.gmail.com>
References: <CAD93_Fq=usykO-kZKRTUv9grK_ce_E-USH1w1fs2RjYZRmhqMQ@mail.gmail.com>
Message-ID: <57175342.6070104@auckland.ac.nz>


Maybe I'm being naive, or missing the point, or something.  But I would
presume that your data are something like:

x_1, x_2, ..., x_n # x-coordinates of the locations --- say, stored as x
y_1, y_2, ..., y_n # y-coordinates of the locations --- say, stored as y
k_1, k_2, ..., k_n # counts at the given locations --- say, stored as k

This is interpreted as meaning that (x_i,y_i) is the centroid of the 
i-th region, in which count k_i was obtained.

If so, can you not just calculate:

xc <- sum(k*x)/sum(k)
yc <- sum(k*y)/sum(k)

???

What am I not understanding?

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

On 20/04/16 18:45, Diego Pavon wrote:
> Dear all
>
> I am working with count data and I want to assess whether the centre of
> gravity of the population (centroid or mean latitude?) has change over
> time, indicating some redistribution or shift ongoing. To simplify, let's
> say that I have ca. 2000 sites censused in two consecutive years (same
> sites censused both years - all sites) and the abundance (count) of the
> species registered.
>
> I first thought about doing a kernelUD (package adehabitatHR) but
> apparently this only takes into account the location of the sites to
> calculate the kernel and then the centroids. Thus, since I have the exact
> same sites in both years, the centroids for year 1 and year 2 are the same.
> In my case, what I would like to do is to calculate that centroid but
> taking into account the counts, because a site that had 3 individuals in
> both years can't have the same weight than a site that hosted 3000
> individuals when calculating the centroids.
>
> So, what I would like to have is the centroid (or centre of gravity) of the
> counts not of the sites surveyed (which is what adehabitatHR does,a s far
> as I understood).
>
> Do you have any suggestions which package other than adehabitatXX to use
> for this purpose? Or if this can be done with adehabitat?
>
> Thank you very much for your help.


From Roger.Bivand at nhh.no  Wed Apr 20 12:05:16 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 20 Apr 2016 12:05:16 +0200
Subject: [R-sig-Geo] Help: impact measures in spatial panel durbin model
In-Reply-To: <20160420102104.Horde.ZdntjjY3CNxLklVe9gs6zA3@webmail.dijon.inra.fr>
References: <20160420102104.Horde.ZdntjjY3CNxLklVe9gs6zA3@webmail.dijon.inra.fr>
Message-ID: <alpine.LFD.2.20.1604201154150.23675@reclus.nhh.no>

On Wed, 20 Apr 2016, Youba Ndiaye wrote:

> Dear all,
>
> I'm a Ph.D student? and I'm working on spatial econometrics approach.
>
> I want to implement?a static spatial durbin model??in R? with "splm"
> function. But the particular case of my model is that my durbin model is
> partial such as: ?
> y = rho.Wy + X.beta + WZ.theta + epsilon? ?
>
> X and Z are vectors?of explanatory variables with respectively (N,k) and
> (N, m) dimensions. k>m. In orders words, the Z is a spatially lagged subset
> of X.
>
> My aim is to calculate properly impact measures of this model in R.

All of the impacts methods expect k=m. A sketch of a possible approach is:

library(spdep)
example(columbus)
lw <- nb2listw(col.gal.nb)
f <- CRIME ~ INC + HOVAL + I(lag(lw, HOVAL))
mod <- lagsarlm(f, data=columbus, lw)
summary(mod)

by constructing the (dense) S(W)_r matrices differently for the non-Durbin 
and Durbin variables:

iIrW <- invIrW(lw, mod$rho)
S_INC <- iIrW %*% (mod$coefficients[2]*diag(nrow(columbus)))
S_HOVAL <- iIrW %*% ((mod$coefficients[3]*diag(nrow(columbus))) -
   (mod$coefficients[4]*listw2mat(lw)))

Then you can get the direct and total impacts in the usual way:

dir_INC <- sum(diag(S_INC))/nrow(columbus)
dir_HOVAL <- sum(diag(S_HOVAL))/nrow(columbus)
tot_INC <- sum(c(S_INC))/nrow(columbus)
tot_HOVAL <- sum(c(S_HOVAL))/nrow(columbus)

with indir_* = tot_* - dir_*.

No inference tools are available, though.

It might be possible to inject zero WZ coefficient values and covariances 
for non-included WX variables in order to use the standard impacts 
methods, but you need strong reasons apriori to assume that they are zero; 
going with regular Durbin will be likely to be more robust, and will give 
a clear test of the insignificance of the indirect impacts.

Hope this helps,

Roger

>
> Thank You?in advance.
> Best regards.
> Youba.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412

From tiagoandremarques at gmail.com  Wed Apr 20 12:19:04 2016
From: tiagoandremarques at gmail.com (Tiago Marques)
Date: Wed, 20 Apr 2016 11:19:04 +0100
Subject: [R-sig-Geo] how to calculate centroid (or centre of gravity) of
 a population (count data)
In-Reply-To: <57173FAB.50900@upm.es>
References: <CAD93_Fq=usykO-kZKRTUv9grK_ce_E-USH1w1fs2RjYZRmhqMQ@mail.gmail.com>
	<57173FAB.50900@upm.es>
Message-ID: <57175798.1070708@gmail.com>

Hi Diego,

A perhaps dumb yet straightforward way of doing it is to replicate each 
point the number of times of its corresponding count, this will get you 
the right unbiased centroid, essentially  a weighted average as 
Marcelino suggests, assuming that the weight you use is proportional to 
the count. It's like saying that each bird contributes once to the 
centroid location, instead of each point contributing once.

Note that just by using your suggested kernelUD you don't really get the 
centroid of the points (I think, never used it myself actually), I 
suspect you simply get a kernel estimate of the bivariate distribution 
of the points in space. Going from that to an actual centroid is 
possible but non necessarily straightforward.

The answer to your specific question is much simpler than that: in 2D, 
simple calculate the means of the X and Y coordinates, multiply each 
coordinate by a weight, the count - that would be an alternative to what 
I suggested above - and there is your centroid.

Note that this gets you the right mean centroid, but not necessarily the 
right variance for that centroid estimate. Also, you might want to think 
about if that is the right weight. But those are all questions beyond 
your original question ;)

cheers

Tiago

?s 09:36 de 20/04/2016, Marcelino de la Cruz escreveu:
> Hi Diego,
>
> it seems to me that what you want to compute are weighted centroids.
>
> Here some advice is given (it is for polygons but you can get the idea):
>
> https://stat.ethz.ch/pipermail/r-sig-geo/2016-February/024107.html
>
> Cheers,
>
> Marcelino
>
>
>
> El 20/04/2016 a las 8:45, Diego Pavon escribi?:
>> Dear all
>>
>> I am working with count data and I want to assess whether the centre of
>> gravity of the population (centroid or mean latitude?) has change over
>> time, indicating some redistribution or shift ongoing. To simplify, 
>> let's
>> say that I have ca. 2000 sites censused in two consecutive years (same
>> sites censused both years - all sites) and the abundance (count) of the
>> species registered.
>>
>> I first thought about doing a kernelUD (package adehabitatHR) but
>> apparently this only takes into account the location of the sites to
>> calculate the kernel and then the centroids. Thus, since I have the 
>> exact
>> same sites in both years, the centroids for year 1 and year 2 are the 
>> same.
>> In my case, what I would like to do is to calculate that centroid but
>> taking into account the counts, because a site that had 3 individuals in
>> both years can't have the same weight than a site that hosted 3000
>> individuals when calculating the centroids.
>>
>> So, what I would like to have is the centroid (or centre of gravity) 
>> of the
>> counts not of the sites surveyed (which is what adehabitatHR does,a s 
>> far
>> as I understood).
>>
>> Do you have any suggestions which package other than adehabitatXX to use
>> for this purpose? Or if this can be done with adehabitat?
>>
>> Thank you very much for your help.
>>
>> Diego
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


---
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus


From diego.pavonjordan at gmail.com  Wed Apr 20 13:08:58 2016
From: diego.pavonjordan at gmail.com (Diego Pavon)
Date: Wed, 20 Apr 2016 14:08:58 +0300
Subject: [R-sig-Geo] how to calculate centroid (or centre of gravity) of
 a population (count data)
In-Reply-To: <57175798.1070708@gmail.com>
References: <CAD93_Fq=usykO-kZKRTUv9grK_ce_E-USH1w1fs2RjYZRmhqMQ@mail.gmail.com>
	<57173FAB.50900@upm.es> <57175798.1070708@gmail.com>
Message-ID: <CAD93_FpYhU2HNRcmEPqNwfW5k0-_oi1mNCv2Ef_Ye-1c5HnsKQ@mail.gmail.com>

Thanks Marcelino, Rolf and Tiago for your quick responses.

I think that the suggested method by Rolf and Tiago, which is also found in
the link provided by Marcelino works fine with my data. Yes, Rolf, it was
as simple as that :)

So,  I multiplied the X_i and Y_i coordinates of each of the 2000 sites by
the count in each site (C_i) and then divided by the total number of counts
(sum of all counts across all sites).
Tiago had, however, interesting points that I will need to address as well.

Thank you very much for your help.

Best

Diego



2016-04-20 13:19 GMT+03:00 Tiago Marques <tiagoandremarques at gmail.com>:

> Hi Diego,
>
> A perhaps dumb yet straightforward way of doing it is to replicate each
> point the number of times of its corresponding count, this will get you the
> right unbiased centroid, essentially  a weighted average as Marcelino
> suggests, assuming that the weight you use is proportional to the count.
> It's like saying that each bird contributes once to the centroid location,
> instead of each point contributing once.
>
> Note that just by using your suggested kernelUD you don't really get the
> centroid of the points (I think, never used it myself actually), I suspect
> you simply get a kernel estimate of the bivariate distribution of the
> points in space. Going from that to an actual centroid is possible but non
> necessarily straightforward.
>
> The answer to your specific question is much simpler than that: in 2D,
> simple calculate the means of the X and Y coordinates, multiply each
> coordinate by a weight, the count - that would be an alternative to what I
> suggested above - and there is your centroid.
>
> Note that this gets you the right mean centroid, but not necessarily the
> right variance for that centroid estimate. Also, you might want to think
> about if that is the right weight. But those are all questions beyond your
> original question ;)
>
> cheers
>
> Tiago
>
>
> ?s 09:36 de 20/04/2016, Marcelino de la Cruz escreveu:
>
>> Hi Diego,
>>
>> it seems to me that what you want to compute are weighted centroids.
>>
>> Here some advice is given (it is for polygons but you can get the idea):
>>
>> https://stat.ethz.ch/pipermail/r-sig-geo/2016-February/024107.html
>>
>> Cheers,
>>
>> Marcelino
>>
>>
>>
>> El 20/04/2016 a las 8:45, Diego Pavon escribi?:
>>
>>> Dear all
>>>
>>> I am working with count data and I want to assess whether the centre of
>>> gravity of the population (centroid or mean latitude?) has change over
>>> time, indicating some redistribution or shift ongoing. To simplify, let's
>>> say that I have ca. 2000 sites censused in two consecutive years (same
>>> sites censused both years - all sites) and the abundance (count) of the
>>> species registered.
>>>
>>> I first thought about doing a kernelUD (package adehabitatHR) but
>>> apparently this only takes into account the location of the sites to
>>> calculate the kernel and then the centroids. Thus, since I have the exact
>>> same sites in both years, the centroids for year 1 and year 2 are the
>>> same.
>>> In my case, what I would like to do is to calculate that centroid but
>>> taking into account the counts, because a site that had 3 individuals in
>>> both years can't have the same weight than a site that hosted 3000
>>> individuals when calculating the centroids.
>>>
>>> So, what I would like to have is the centroid (or centre of gravity) of
>>> the
>>> counts not of the sites surveyed (which is what adehabitatHR does,a s far
>>> as I understood).
>>>
>>> Do you have any suggestions which package other than adehabitatXX to use
>>> for this purpose? Or if this can be done with adehabitat?
>>>
>>> Thank you very much for your help.
>>>
>>> Diego
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
> ---
> Este e-mail foi verificado em termos de v?rus pelo software antiv?rus
> Avast.
> https://www.avast.com/antivirus
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
*Diego Pav?n Jord?n*

*Finnish Museum of Natural History*
*PO BOX 17 *

*Helsinki. Finland*



*0445061210https://tuhat.halvi.helsinki.fi/portal/en/persons/diego-pavon-jordan%288d5db37c-eddd-4fca-92cd-9c9956a42b4a%29.html
<https://tuhat.halvi.helsinki.fi/portal/en/persons/diego-pavon-jordan%288d5db37c-eddd-4fca-92cd-9c9956a42b4a%29.html>http://www.linkedin.com/profile/view?id=170617924&trk=nav_responsive_tab_profile
<http://www.linkedin.com/profile/view?id=170617924&trk=nav_responsive_tab_profile>https://helsinki.academia.edu/DiegoPavon
<https://helsinki.academia.edu/DiegoPavon>*

	[[alternative HTML version deleted]]


From youba.ndiaye at dijon.inra.fr  Wed Apr 20 15:17:25 2016
From: youba.ndiaye at dijon.inra.fr (Youba Ndiaye)
Date: Wed, 20 Apr 2016 15:17:25 +0200
Subject: [R-sig-Geo] Help: impact measures in spatial panel durbin model
In-Reply-To: <alpine.LFD.2.20.1604201154150.23675@reclus.nhh.no>
References: <20160420102104.Horde.ZdntjjY3CNxLklVe9gs6zA3@webmail.dijon.inra.fr>
	<alpine.LFD.2.20.1604201154150.23675@reclus.nhh.no>
Message-ID: <20160420151725.Horde.UIidS5v_AdEzJ3Nx6Y83Tw1@webmail.dijon.inra.fr>

  Thanks a lot. That's very helpful

Best regards.
Youba.

Roger Bivand <Roger.Bivand at nhh.no> a ?crit?:

> On Wed, 20 Apr 2016, Youba Ndiaye wrote:
>
>> Dear all,
>>
>> I'm a Ph.D student? and I'm working on spatial econometrics approach.
>>
>> I want to implement?a static spatial durbin model??in R? with "splm"
>> function. But the particular case of my model is that my durbin model is
>> partial such as: ?
>> y = rho.Wy + X.beta + WZ.theta + epsilon? ?
>>
>> X and Z are vectors?of explanatory variables with respectively (N,k)
and
>> (N, m) dimensions. k>m. In orders words, the Z is a spatially lagged
>> subset
>> of X.
>>
>> My aim is to calculate properly impact measures of this model in R.
>
> All of the impacts methods expect k=m. A sketch of a possible approach
is:
>
> library(spdep)
> example(columbus)
> lw <- nb2listw(col.gal.nb)
> f <- CRIME ~ INC + HOVAL + I(lag(lw, HOVAL))
> mod <- lagsarlm(f, data=columbus, lw)
> summary(mod)
>
> by constructing the (dense) S(W)_r matrices differently for the
> non-Durbin and Durbin variables:
>
> iIrW <- invIrW(lw, mod$rho)
> S_INC <- iIrW %*% (mod$coefficients[2]*diag(nrow(columbus)))
> S_HOVAL <- iIrW %*% ((mod$coefficients[3]*diag(nrow(columbus))) -
> (mod$coefficients[4]*listw2mat(lw)))
>
> Then you can get the direct and total impacts in the usual way:
>
> dir_INC <- sum(diag(S_INC))/nrow(columbus)
> dir_HOVAL <- sum(diag(S_HOVAL))/nrow(columbus)
> tot_INC <- sum(c(S_INC))/nrow(columbus)
> tot_HOVAL <- sum(c(S_HOVAL))/nrow(columbus)
>
> with indir_* = tot_* - dir_*.
>
> No inference tools are available, though.
>
> It might be possible to inject zero WZ coefficient values and
> covariances for non-included WX variables in order to use the standard
> impacts methods, but you need strong reasons apriori to assume that they
> are zero; going with regular Durbin will be likely to be more robust,
> and will give a clear test of the insignificance of the indirect impacts.
>
> Hope this helps,
>
> Roger
>
>> Thank You?in advance.
>> Best regards.
>> Youba.
>>
>> ? ? ? ? [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
> http://orcid.org/0000-0003-2392-6140
>
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=enhttp://depsy.org/person/434412

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Thu Apr 21 09:19:22 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 21 Apr 2016 09:19:22 +0200
Subject: [R-sig-Geo] Links to Zika virus paper
Message-ID: <alpine.LFD.2.20.1604210910190.32527@reclus.nhh.no>

Why we do what we do:

Congratulations to Robert Hijmans and others maintaining the dismo 
package:

https://cran.r-project.org/web/packages/dismo/index.html

which is the computational basis for:

http://elifesciences.org/content/5/e15272v1

and reported on in:

http://www.bbc.com/news/health-36090650

this morning.

Roger

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


From jcarcamo03 at gmail.com  Thu Apr 21 10:37:18 2016
From: jcarcamo03 at gmail.com (=?UTF-8?Q?Jorge_C=C3=A1rcamo?=)
Date: Thu, 21 Apr 2016 10:37:18 +0200
Subject: [R-sig-Geo] sarprobit question
Message-ID: <CAAcGTKBf1y_5WhCbNR28CHNckyrHsaDNNb6eX1tQgx3Jntak0w@mail.gmail.com>

Good day everyone.

I have been trying to conduct a Spatial Autoregressive probit model in R.
To do so, I added the shapefile (points) that contains all my information
into R, and from it I constructed the spatial weighted matrix by specifying
k=3 nearest neighbors.
    tbe <- readShapePoints('tech_full.shp',
proj4string=CRS("+init=epsg:32719"))
    coortbe <- coordinates(tbe)
    col.knn1 <- knearneigh(coortbe, k=3)
    plot(knn2nb(col.knn1), coortbe, add=TRUE)
    neig <- knn2nb(col.knn1,row.names=tbe$Number)
    listw <- nb2listw(neig, style = "W")
    W <- as(as_dgRMatrix_listw(listw), "CsparseMatrix")

Until this point, R does not give me any warnings or error messages.
Immediately, I execute the following code to fit the spatial AR probit
model (package: 'spatialprobit')

    sarprobit.fit1 <- sarprobit(NV25 ~ SD46 + SD45 + PC18 + PC22 + SS13t +
Age + Gender + sra + sla + saa + uwue, data = tbe, W)

the following error appears:

>Error: Matrices must have same dimensions in .Arith.Csparse(e1, e2,
.Generic, class. = "dgCMatrix")*

Looking into W I found: i=306, p=103. Moreover, tbe has 102 observations.

I first thought that this p=103 was the error, however I did the following:

    wnew <-W[-1,]
    sarprobit.fit1 <- sarprobit(NV25 ~ SD46 + SD45 + PC18 + PC22 + SS13t +
Age + Gender + sra + sla + saa + uwue, data = tbe, wnew)

Now, the following error appears:

>Error in sar_probit_mcmc(y, X, W, ...) :
  sarprobit: spatial weights matrix W must be a sparse matrix with zeros in
the main diagonal

I tried other software, such as GeoDa. However, since my dependent variable
is binary, I did not found on it a proper model for my data.

My question is, did someone deal with this error? and if so, how did you
manage to solve it? I looked in google for this error but did not have any
luck.

Best,

Jorge

*Ing. Jorge Alfredo C?rcamo, M. Sc., Ph. D. (c)*

	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Thu Apr 21 10:43:27 2016
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 21 Apr 2016 09:43:27 +0100
Subject: [R-sig-Geo] Links to Zika virus paper
In-Reply-To: <alpine.LFD.2.20.1604210910190.32527@reclus.nhh.no>
References: <alpine.LFD.2.20.1604210910190.32527@reclus.nhh.no>
Message-ID: <CANVKczMK_pQ_F4MVaW7RYXMa7uUFE6f0OQWRdR9BBhu76=E3xw@mail.gmail.com>

On Thu, Apr 21, 2016 at 8:19 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> Why we do what we do:
>
> Congratulations to Robert Hijmans and others maintaining the dismo package:
>
> https://cran.r-project.org/web/packages/dismo/index.html
>
> which is the computational basis for:
>
> http://elifesciences.org/content/5/e15272v1
>
> and reported on in:
>
> http://www.bbc.com/news/health-36090650

 Great stuff, but sadly I don't see the either R itself or the dismo
package cited in the journal article - the one mention of dismo gets a
reference to a paper (Elith, J., J. R. Leathwick & T. Hastie (2008)  A
working guide to boosted regression trees. J Anim Ecol, 77, 802-13)
and nothing else.

  *sigh*

Barry


From twah at gmx.ch  Thu Apr 21 13:10:35 2016
From: twah at gmx.ch (twah at gmx.ch)
Date: Thu, 21 Apr 2016 13:10:35 +0200
Subject: [R-sig-Geo] spTransform / SpatialPixelsDataFrame
Message-ID: <5718B52B.4050008@gmx.ch>

Hello

I would like to reproject a SpatialPixelsDataFrame, changing the CRS. I 
am trying to use the command "spTransform" from the package "sp". 
Unfortunately, the command results in a SpatialPointsDataFrame, which is 
not desired. My SpatialPixelsDataFrame has proj4string

+init=epsg:21781 +proj=somerc +lat_0=46.95240555555556
+lon_0=7.439583333333333 +k_0=1 +x_0=600000 +y_0=200000 +ellps=bessel 
+towgs84=674.4,15.1,405.3,0,0,0,0
+units=m +no_defs

The command which results in a SpatialPointsDataFrame is:

SPDF2<-spTransform(SPDF1,CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 
+towgs84=0,0,0"))

An object transformation through

SPDF3<-as(SPDF2,"SpatialPixelsDataFrame")

results in an error, possibly since in the underlying problem the SPDF2 
is a subset for a particular layer, so it is not a full grid.

Can someone help?

Thanks.


From bob at rudis.net  Thu Apr 21 13:29:40 2016
From: bob at rudis.net (boB Rudis)
Date: Thu, 21 Apr 2016 07:29:40 -0400
Subject: [R-sig-Geo] Links to Zika virus paper
In-Reply-To: <CANVKczMK_pQ_F4MVaW7RYXMa7uUFE6f0OQWRdR9BBhu76=E3xw@mail.gmail.com>
References: <alpine.LFD.2.20.1604210910190.32527@reclus.nhh.no>
	<CANVKczMK_pQ_F4MVaW7RYXMa7uUFE6f0OQWRdR9BBhu76=E3xw@mail.gmail.com>
Message-ID: <CAJ4QxaOagt93mC=2PgE4HxGDwFPGrc-G73L_yNMJ+8NTwgbURQ@mail.gmail.com>

Agreed it was great to see "Each of the 300 individual models was
fitted using the gbm.step subroutine in the dismo package in the R
statistical programming environment (Elith et al. 2008)" in there and
also agreed that the following should have made it into the citations
(assuming only library(dismo) was done which is a terrible assumption
:-). Many thanks to Roger, Edzer (et al) as well. Critial,
foundational work which made this paper possible.

@Manual{R-base,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2016},
  url = {https://www.R-project.org/},
}
@Manual{R-dismo,
  title = {dismo: Species Distribution Modeling},
  author = {Robert J. Hijmans and Steven Phillips and John Leathwick
and Jane Elith},
  year = {2015},
  note = {R package version 1.0-12},
  url = {https://CRAN.R-project.org/package=dismo},
}
@Manual{R-raster,
  title = {raster: Geographic Data Analysis and Modeling},
  author = {Robert J. Hijmans},
  year = {2015},
  note = {R package version 2.5-2},
  url = {https://CRAN.R-project.org/package=raster},
}
@Manual{R-sp,
  title = {sp: Classes and Methods for Spatial Data},
  author = {Edzer Pebesma and Roger Bivand},
  year = {2015},
  note = {R package version 1.2-1},
  url = {https://CRAN.R-project.org/package=sp},
}

On Thu, Apr 21, 2016 at 4:43 AM, Barry Rowlingson
<b.rowlingson at lancaster.ac.uk> wrote:
> On Thu, Apr 21, 2016 at 8:19 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> Why we do what we do:
>>
>> Congratulations to Robert Hijmans and others maintaining the dismo package:
>>
>> https://cran.r-project.org/web/packages/dismo/index.html
>>
>> which is the computational basis for:
>>
>> http://elifesciences.org/content/5/e15272v1
>>
>> and reported on in:
>>
>> http://www.bbc.com/news/health-36090650
>
>  Great stuff, but sadly I don't see the either R itself or the dismo
> package cited in the journal article - the one mention of dismo gets a
> reference to a paper (Elith, J., J. R. Leathwick & T. Hastie (2008)  A
> working guide to boosted regression trees. J Anim Ecol, 77, 802-13)
> and nothing else.
>
>   *sigh*
>
> Barry
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Thu Apr 21 13:29:19 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 21 Apr 2016 13:29:19 +0200
Subject: [R-sig-Geo] spTransform / SpatialPixelsDataFrame
In-Reply-To: <5718B52B.4050008@gmx.ch>
References: <5718B52B.4050008@gmx.ch>
Message-ID: <alpine.LFD.2.20.1604211326110.32527@reclus.nhh.no>

On Thu, 21 Apr 2016, twah at gmx.ch wrote:

> Hello
>
> I would like to reproject a SpatialPixelsDataFrame, changing the CRS. I am 
> trying to use the command "spTransform" from the package "sp". Unfortunately, 
> the command results in a SpatialPointsDataFrame, which is not desired. My 
> SpatialPixelsDataFrame has proj4string
>
> +init=epsg:21781 +proj=somerc +lat_0=46.95240555555556
> +lon_0=7.439583333333333 +k_0=1 +x_0=600000 +y_0=200000 +ellps=bessel 
> +towgs84=674.4,15.1,405.3,0,0,0,0
> +units=m +no_defs
>
> The command which results in a SpatialPointsDataFrame is:
>
> SPDF2<-spTransform(SPDF1,CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 
> +towgs84=0,0,0"))
>
> An object transformation through
>
> SPDF3<-as(SPDF2,"SpatialPixelsDataFrame")
>
> results in an error, possibly since in the underlying problem the SPDF2 is a 
> subset for a particular layer, so it is not a full grid.
>
> Can someone help?

You cannot in general project grids, because the spacings between cell 
centre points will no longer be fixed. You can convert to a raster object 
and *warp* that grid to a new grid in the new projection with regularly 
spaced points, but with output cell centre points that do not match the 
projected points. Often, interpolation is needed to decide which value 
should be assigned to the output grid cells.

Roger

>
> Thanks.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


From roman.lustrik at gmail.com  Thu Apr 21 14:00:14 2016
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Thu, 21 Apr 2016 14:00:14 +0200
Subject: [R-sig-Geo] Links to Zika virus paper
In-Reply-To: <CAJ4QxaOagt93mC=2PgE4HxGDwFPGrc-G73L_yNMJ+8NTwgbURQ@mail.gmail.com>
References: <alpine.LFD.2.20.1604210910190.32527@reclus.nhh.no>
	<CANVKczMK_pQ_F4MVaW7RYXMa7uUFE6f0OQWRdR9BBhu76=E3xw@mail.gmail.com>
	<CAJ4QxaOagt93mC=2PgE4HxGDwFPGrc-G73L_yNMJ+8NTwgbURQ@mail.gmail.com>
Message-ID: <CAHT1vpjBL4DZDzxmjTq_vKUby4hTR1LUveeSARFh9f+--axNxA@mail.gmail.com>

Bob opens up an interesting topic, perhaps not really fit for this mailing
list, of which packages to cite. Most packages load dependencies. Should
these dependencies be cited? How do you handle this issue in citing
packages?

Cheers,
Roman

On Thu, Apr 21, 2016 at 1:29 PM, boB Rudis <bob at rudis.net> wrote:

> Agreed it was great to see "Each of the 300 individual models was
> fitted using the gbm.step subroutine in the dismo package in the R
> statistical programming environment (Elith et al. 2008)" in there and
> also agreed that the following should have made it into the citations
> (assuming only library(dismo) was done which is a terrible assumption
> :-). Many thanks to Roger, Edzer (et al) as well. Critial,
> foundational work which made this paper possible.
>
> @Manual{R-base,
>   title = {R: A Language and Environment for Statistical Computing},
>   author = {{R Core Team}},
>   organization = {R Foundation for Statistical Computing},
>   address = {Vienna, Austria},
>   year = {2016},
>   url = {https://www.R-project.org/},
> }
> @Manual{R-dismo,
>   title = {dismo: Species Distribution Modeling},
>   author = {Robert J. Hijmans and Steven Phillips and John Leathwick
> and Jane Elith},
>   year = {2015},
>   note = {R package version 1.0-12},
>   url = {https://CRAN.R-project.org/package=dismo},
> }
> @Manual{R-raster,
>   title = {raster: Geographic Data Analysis and Modeling},
>   author = {Robert J. Hijmans},
>   year = {2015},
>   note = {R package version 2.5-2},
>   url = {https://CRAN.R-project.org/package=raster},
> }
> @Manual{R-sp,
>   title = {sp: Classes and Methods for Spatial Data},
>   author = {Edzer Pebesma and Roger Bivand},
>   year = {2015},
>   note = {R package version 1.2-1},
>   url = {https://CRAN.R-project.org/package=sp},
> }
>
> On Thu, Apr 21, 2016 at 4:43 AM, Barry Rowlingson
> <b.rowlingson at lancaster.ac.uk> wrote:
> > On Thu, Apr 21, 2016 at 8:19 AM, Roger Bivand <Roger.Bivand at nhh.no>
> wrote:
> >> Why we do what we do:
> >>
> >> Congratulations to Robert Hijmans and others maintaining the dismo
> package:
> >>
> >> https://cran.r-project.org/web/packages/dismo/index.html
> >>
> >> which is the computational basis for:
> >>
> >> http://elifesciences.org/content/5/e15272v1
> >>
> >> and reported on in:
> >>
> >> http://www.bbc.com/news/health-36090650
> >
> >  Great stuff, but sadly I don't see the either R itself or the dismo
> > package cited in the journal article - the one mention of dismo gets a
> > reference to a paper (Elith, J., J. R. Leathwick & T. Hastie (2008)  A
> > working guide to boosted regression trees. J Anim Ecol, 77, 802-13)
> > and nothing else.
> >
> >   *sigh*
> >
> > Barry
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
In God we trust, all others bring data.

	[[alternative HTML version deleted]]


From bob at rudis.net  Thu Apr 21 14:12:17 2016
From: bob at rudis.net (boB Rudis)
Date: Thu, 21 Apr 2016 08:12:17 -0400
Subject: [R-sig-Geo] Links to Zika virus paper
In-Reply-To: <CAHT1vpjBL4DZDzxmjTq_vKUby4hTR1LUveeSARFh9f+--axNxA@mail.gmail.com>
References: <alpine.LFD.2.20.1604210910190.32527@reclus.nhh.no>
	<CANVKczMK_pQ_F4MVaW7RYXMa7uUFE6f0OQWRdR9BBhu76=E3xw@mail.gmail.com>
	<CAJ4QxaOagt93mC=2PgE4HxGDwFPGrc-G73L_yNMJ+8NTwgbURQ@mail.gmail.com>
	<CAHT1vpjBL4DZDzxmjTq_vKUby4hTR1LUveeSARFh9f+--axNxA@mail.gmail.com>
Message-ID: <CAJ4QxaNemNXQrhDueDvcY28eYb3JwaydpMp-7VYvBELo7wLPew@mail.gmail.com>

I will try to handle any other replies off-list to keep the list
on-topic, but wanted to reinforce my opine on this topic. My co-author
& I believed so strongly in the need to ensure R & R package author
work was properly acknowledged that we managed to get Wiley to allow 2
pages of package citations in our book, Data-Driven Security.
Virtually everything (with a small fraction of exceptions) I produce
in my cybersecurity research  is owed to a cadre of coders &|
scientists who have contributed R packages to make it possible. #ty.
Y'all rock ;-)

On Thu, Apr 21, 2016 at 8:00 AM, Roman Lu?trik <roman.lustrik at gmail.com> wrote:
> Bob opens up an interesting topic, perhaps not really fit for this mailing
> list, of which packages to cite. Most packages load dependencies. Should
> these dependencies be cited? How do you handle this issue in citing
> packages?
>
> Cheers,
> Roman
>
> On Thu, Apr 21, 2016 at 1:29 PM, boB Rudis <bob at rudis.net> wrote:
>>
>> Agreed it was great to see "Each of the 300 individual models was
>> fitted using the gbm.step subroutine in the dismo package in the R
>> statistical programming environment (Elith et al. 2008)" in there and
>> also agreed that the following should have made it into the citations
>> (assuming only library(dismo) was done which is a terrible assumption
>> :-). Many thanks to Roger, Edzer (et al) as well. Critial,
>> foundational work which made this paper possible.
>>
>> @Manual{R-base,
>>   title = {R: A Language and Environment for Statistical Computing},
>>   author = {{R Core Team}},
>>   organization = {R Foundation for Statistical Computing},
>>   address = {Vienna, Austria},
>>   year = {2016},
>>   url = {https://www.R-project.org/},
>> }
>> @Manual{R-dismo,
>>   title = {dismo: Species Distribution Modeling},
>>   author = {Robert J. Hijmans and Steven Phillips and John Leathwick
>> and Jane Elith},
>>   year = {2015},
>>   note = {R package version 1.0-12},
>>   url = {https://CRAN.R-project.org/package=dismo},
>> }
>> @Manual{R-raster,
>>   title = {raster: Geographic Data Analysis and Modeling},
>>   author = {Robert J. Hijmans},
>>   year = {2015},
>>   note = {R package version 2.5-2},
>>   url = {https://CRAN.R-project.org/package=raster},
>> }
>> @Manual{R-sp,
>>   title = {sp: Classes and Methods for Spatial Data},
>>   author = {Edzer Pebesma and Roger Bivand},
>>   year = {2015},
>>   note = {R package version 1.2-1},
>>   url = {https://CRAN.R-project.org/package=sp},
>> }
>>
>> On Thu, Apr 21, 2016 at 4:43 AM, Barry Rowlingson
>> <b.rowlingson at lancaster.ac.uk> wrote:
>> > On Thu, Apr 21, 2016 at 8:19 AM, Roger Bivand <Roger.Bivand at nhh.no>
>> > wrote:
>> >> Why we do what we do:
>> >>
>> >> Congratulations to Robert Hijmans and others maintaining the dismo
>> >> package:
>> >>
>> >> https://cran.r-project.org/web/packages/dismo/index.html
>> >>
>> >> which is the computational basis for:
>> >>
>> >> http://elifesciences.org/content/5/e15272v1
>> >>
>> >> and reported on in:
>> >>
>> >> http://www.bbc.com/news/health-36090650
>> >
>> >  Great stuff, but sadly I don't see the either R itself or the dismo
>> > package cited in the journal article - the one mention of dismo gets a
>> > reference to a paper (Elith, J., J. R. Leathwick & T. Hastie (2008)  A
>> > working guide to boosted regression trees. J Anim Ecol, 77, 802-13)
>> > and nothing else.
>> >
>> >   *sigh*
>> >
>> > Barry
>> >
>> > _______________________________________________
>> > R-sig-Geo mailing list
>> > R-sig-Geo at r-project.org
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
>
> --
> In God we trust, all others bring data.


From Virgilio.Gomez at uclm.es  Thu Apr 21 16:58:11 2016
From: Virgilio.Gomez at uclm.es (VIRGILIO GOMEZ RUBIO)
Date: Thu, 21 Apr 2016 14:58:11 +0000
Subject: [R-sig-Geo] sarprobit question
In-Reply-To: <CAAcGTKBf1y_5WhCbNR28CHNckyrHsaDNNb6eX1tQgx3Jntak0w@mail.gmail.com>
References: <CAAcGTKBf1y_5WhCbNR28CHNckyrHsaDNNb6eX1tQgx3Jntak0w@mail.gmail.com>
Message-ID: <903D7FCB-3C1E-4F39-A0FD-069072AB7D78@uclm.es>

Hi,

> I first thought that this p=103 was the error, however I did the following:
> 
>    wnew <-W[-1,]

You need to remove one row AND one column to have a 102x102 matrix. In the code above you are just removing one row. I believe that the error is there. But you should check why you W is 103x103 if you only have 102 data points?

Best,

Virgilio


From jcarcamo03 at gmail.com  Fri Apr 22 09:50:20 2016
From: jcarcamo03 at gmail.com (=?UTF-8?Q?Jorge_C=C3=A1rcamo?=)
Date: Fri, 22 Apr 2016 09:50:20 +0200
Subject: [R-sig-Geo] sarprobit question
In-Reply-To: <903D7FCB-3C1E-4F39-A0FD-069072AB7D78@uclm.es>
References: <CAAcGTKBf1y_5WhCbNR28CHNckyrHsaDNNb6eX1tQgx3Jntak0w@mail.gmail.com>
	<903D7FCB-3C1E-4F39-A0FD-069072AB7D78@uclm.es>
Message-ID: <CAAcGTKA8hrLqXhLBQrVuiEFY9-4J33f-Xv==Kw1oKqV1BUWY1Q@mail.gmail.com>

Dear Virgilio,

Thank you very much for your answer. Effectively, your observation is
correct, after I drop a column the command works.

I will take a look at the commands to understand why is creating this
W=103x103 matrix. Do you have some suggestions?

Once again, thank you very much for your quick reply.

Best,

Jorge

*Ing. Jorge Alfredo C?rcamo, M. Sc., Ph. D. (c)*


On Thu, Apr 21, 2016 at 4:58 PM, VIRGILIO GOMEZ RUBIO <
Virgilio.Gomez at uclm.es> wrote:

> Hi,
>
> > I first thought that this p=103 was the error, however I did the
> following:
> >
> >    wnew <-W[-1,]
>
> You need to remove one row AND one column to have a 102x102 matrix. In the
> code above you are just removing one row. I believe that the error is
> there. But you should check why you W is 103x103 if you only have 102 data
> points?
>
> Best,
>
> Virgilio
>
>

	[[alternative HTML version deleted]]


From Virgilio.Gomez at uclm.es  Fri Apr 22 13:13:35 2016
From: Virgilio.Gomez at uclm.es (VIRGILIO GOMEZ RUBIO)
Date: Fri, 22 Apr 2016 11:13:35 +0000
Subject: [R-sig-Geo] sarprobit question
In-Reply-To: <CAAcGTKA8hrLqXhLBQrVuiEFY9-4J33f-Xv==Kw1oKqV1BUWY1Q@mail.gmail.com>
References: <CAAcGTKBf1y_5WhCbNR28CHNckyrHsaDNNb6eX1tQgx3Jntak0w@mail.gmail.com>
	<903D7FCB-3C1E-4F39-A0FD-069072AB7D78@uclm.es>
	<CAAcGTKA8hrLqXhLBQrVuiEFY9-4J33f-Xv==Kw1oKqV1BUWY1Q@mail.gmail.com>
Message-ID: <4BF8B532-4003-4A01-A089-325F9A7A6B5B@uclm.es>

Hi,

> Thank you very much for your answer. Effectively, your observation is correct, after I drop a column the command works.
> 

Please, note that dropping the column will give you a 102x102 but, as Obi-Wan Kenobi would say, "this is not the matrix you are looking for?. :) What I mean is that you probably will get a wrong adjacency matrix. :)

> I will take a look at the commands to understand why is creating this W=103x103 matrix. Do you have some suggestions?

If you provide a reproducible example (i.e., code plus data) I could look into it. Feel free to contact me off list.

Best,

Virgilio

From b.rowlingson at lancaster.ac.uk  Fri Apr 22 15:50:18 2016
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 22 Apr 2016 14:50:18 +0100
Subject: [R-sig-Geo] OSGeo UK event
Message-ID: <CANVKczMaBw1F5=Luk5BsF4GcnxcBVZrAEWnPgSwt8w+n-LsDUw@mail.gmail.com>

The UK Chapter of OSGeo is holding a FOSS4GUK conference in Southampton in June.

I am quite confident there will be at least one workshop on mapping in
R there. We're taking proposals for talks and workshops, and also
early bird tickets - the web site is here:

 http://uk.osgeo.org/foss4guk2016/

Currently the web page is mostly a list of sponsors - check out those
big names! Programme announcement will be early May.

Should be a good event, something like the OSGIS-UK meetings that we
had in Nottingham prior to the massive FOSS4G 2013 Global event.

Would be great to see MORE R at this, so please consider making a
presentation proposal, and see you there!


Barry


From didier.leibovici at nottingham.ac.uk  Fri Apr 22 16:22:25 2016
From: didier.leibovici at nottingham.ac.uk (Dr Didier G. Leibovici)
Date: Fri, 22 Apr 2016 15:22:25 +0100
Subject: [R-sig-Geo] rgrass7 and snow
In-Reply-To: <CAGfc75=y901cbM1b90C5jwR_iQ5Zq_EOyFhBquAABbtXKvnJFA@mail.gmail.com>
References: <CAGfc75kOhMzWuXe_jm+A81-MoiSdRanoXViAycvKGoPLuRzwfw@mail.gmail.com>
	<m2mvv87b5l.fsf@krugs.de>
	<CAGfc75mgjHT94aZm7bEFkLO5628K-8-UR--Z-FQbpndX3tsSsA@mail.gmail.com>
	<m2lhaoe9sh.fsf@krugs.de>
	<CAGfc75kGAjR6xWHN+uX_U6xW6jjogVvOsgGGoVwKGeh=8uoa5A@mail.gmail.com>
	<CAGfc75=30WjKr1+77GCG=vpjnvYymKSddPKUpUZ-MYpTxP=mkg@mail.gmail.com>
	<m28u6nc9cd.fsf@krugs.de>
	<CAGfc75=y901cbM1b90C5jwR_iQ5Zq_EOyFhBquAABbtXKvnJFA@mail.gmail.com>
Message-ID: <571A33A1.3090202@nottingham.ac.uk>

Hi,

we are trying to use 'grass' in parallel programming with 'snow'

The code does multiple simulations of a r.viewshed resampling the points 
generating the viewshed.
(I guess the other solution would be to have an equivalent of r.viewshed 
in an R library or script) ...
I think the problems are to do with the gisDbase ...

Testing with 2 clusters we start with:
 >  clusterCall(cl,initGRASS,"/usr/lib/grass70",home=getwd(), 
gisDbase="GRASS_TEMP", override=TRUE )
[[1]]
gisdbase    GRASS_TEMP
location    file5edb6bf06d70
mapset      file5edb4b0cda81
rows        1
columns     1
north       1
south       0
west        0
east        1
nsres       1
ewres       1
projection  NA

[[2]]
gisdbase    GRASS_TEMP
location    file5edb6bf06d70
mapset      file5edb4b0cda81

then read a DEM
clusterCall(cl,execGRASS,"r.in.gdal", flags="o", 
parameters=list(input=baseDemFilename, output="DEM"))
   clusterCall(cl,execGRASS, "g.region", parameters=list(raster="DEM"))

and then loop on the sampled points ... involving
  execGRASS("r.viewshed", parameters = list(input = "DEM", output = 
"cumulativeViewshed", max_distance=maxDistance, coordinates = 
as.integer(coords[i,])), flags = c("overwrite" , "b","quiet"))

  and cumulating the viewshed (reading the ouput using 
readRAST("cumulativeViewshed")), all this (loop over the points)within a 
function simul() called
by a
  parSapply(cl,1:nDsimul,simul)


Here is the error
Error in checkForRemoteErrors(val) :
   2 nodes produced errors; first error: no such file: 
GRASS_TEMP/file5edb6bf06d70/file5edb4b0cda81/.tmp/geoprocessing/cumulativeViewshed
Calls: parSapply ... clusterApply -> staticClusterApply -> 
checkForRemoteErrors

any idea?

thanks,

DIdier

-- 
Dr Didier G. Leibovici
    d-d'ye    ley-bow-v-c
Senior Research Fellow
Geocomputational Modelling & Geospatial Statistics
Nottingham Geospatial Institute
University of Nottingham, UK
+44 (0)115 84 13924
http://www.nottingham.ac.uk/ngi/people/didier.leibovici
Google+ didier.leibovici at gmail.com
Skype didierleibovici


	[[alternative HTML version deleted]]


From r.m.krug at gmail.com  Fri Apr 22 17:21:54 2016
From: r.m.krug at gmail.com (Rainer M Krug)
Date: Fri, 22 Apr 2016 17:21:54 +0200
Subject: [R-sig-Geo] rgrass7 and snow
In-Reply-To: <571A33A1.3090202@nottingham.ac.uk>
References: <CAGfc75kOhMzWuXe_jm+A81-MoiSdRanoXViAycvKGoPLuRzwfw@mail.gmail.com>
	<m2mvv87b5l.fsf@krugs.de>
	<CAGfc75mgjHT94aZm7bEFkLO5628K-8-UR--Z-FQbpndX3tsSsA@mail.gmail.com>
	<m2lhaoe9sh.fsf@krugs.de>
	<CAGfc75kGAjR6xWHN+uX_U6xW6jjogVvOsgGGoVwKGeh=8uoa5A@mail.gmail.com>
	<CAGfc75=30WjKr1+77GCG=vpjnvYymKSddPKUpUZ-MYpTxP=mkg@mail.gmail.com>
	<m28u6nc9cd.fsf@krugs.de>
	<CAGfc75=y901cbM1b90C5jwR_iQ5Zq_EOyFhBquAABbtXKvnJFA@mail.gmail.com>
	<571A33A1.3090202@nottingham.ac.uk>
Message-ID: <CAGhLh6Ea52J30xtrqf6fPT+ieMtaHgfFxz-3BCSV-8jWHeVYoQ@mail.gmail.com>

Le vendredi 22 avril 2016, Dr Didier G. Leibovici <
didier.leibovici at nottingham.ac.uk> a ?crit :

> Hi,
>
> we are trying to use 'grass' in parallel programming with 'snow'
>
> The code does multiple simulations of a r.viewshed resampling the points
> generating the viewshed.
> (I guess the other solution would be to have an equivalent of r.viewshed
> in an R library or script) ...
> I think the problems are to do with the gisDbase ...
>
> Testing with 2 clusters we start with:
>  >  clusterCall(cl,initGRASS,"/usr/lib/grass70",home=getwd(),
> gisDbase="GRASS_TEMP", override=TRUE )
> [[1]]
> gisdbase    GRASS_TEMP
> location    file5edb6bf06d70
> mapset      file5edb4b0cda81
> rows        1
> columns     1
> north       1
> south       0
> west        0
> east        1
> nsres       1
> ewres       1
> projection  NA
>
> [[2]]
> gisdbase    GRASS_TEMP
> location    file5edb6bf06d70
> mapset      file5edb4b0cda81
>
> then read a DEM
> clusterCall(cl,execGRASS,"r.in.gdal", flags="o",
> parameters=list(input=baseDemFilename, output="DEM"))
>    clusterCall(cl,execGRASS, "g.region", parameters=list(raster="DEM"))
>
> and then loop on the sampled points ... involving
>   execGRASS("r.viewshed", parameters = list(input = "DEM", output =
> "cumulativeViewshed", max_distance=maxDistance, coordinates =
> as.integer(coords[i,])), flags = c("overwrite" , "b","quiet"))
>
>   and cumulating the viewshed (reading the ouput using
> readRAST("cumulativeViewshed")), all this (loop over the points)within a
> function simul() called
> by a
>   parSapply(cl,1:nDsimul,simul)
>
>
> Here is the error
> Error in checkForRemoteErrors(val) :
>    2 nodes produced errors; first error: no such file:
>
> GRASS_TEMP/file5edb6bf06d70/file5edb4b0cda81/.tmp/geoprocessing/cumulativeViewshed
> Calls: parSapply ... clusterApply -> staticClusterApply ->
> checkForRemoteErrors
>
> any idea?


The problem is likely that you are working in parallel in the same map set.
I would suggest to use a separate Mauser for each parallel task to write
to, read from a different map set which no parallel task is writing to, and
finally, after all threads are finished, you can collect the results from
each thread in one map set and delete the temporary map sets.

Cheers,

Rainer

>
> thanks,
>
> DIdier
>
> --
> Dr Didier G. Leibovici
>     d-d'ye    ley-bow-v-c
> Senior Research Fellow
> Geocomputational Modelling & Geospatial Statistics
> Nottingham Geospatial Institute
> University of Nottingham, UK
> +44 (0)115 84 13924
> http://www.nottingham.ac.uk/ngi/people/didier.leibovici
> Google+ didier.leibovici at gmail.com <javascript:;>
> Skype didierleibovici
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org <javascript:;>
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology,
UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax (F):       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

	[[alternative HTML version deleted]]


From didier.leibovici at nottingham.ac.uk  Fri Apr 22 17:42:56 2016
From: didier.leibovici at nottingham.ac.uk (Dr Didier G. Leibovici)
Date: Fri, 22 Apr 2016 16:42:56 +0100
Subject: [R-sig-Geo] rgrass7 and snow
In-Reply-To: <CAGhLh6Ea52J30xtrqf6fPT+ieMtaHgfFxz-3BCSV-8jWHeVYoQ@mail.gmail.com>
References: <CAGfc75kOhMzWuXe_jm+A81-MoiSdRanoXViAycvKGoPLuRzwfw@mail.gmail.com>
	<m2mvv87b5l.fsf@krugs.de>
	<CAGfc75mgjHT94aZm7bEFkLO5628K-8-UR--Z-FQbpndX3tsSsA@mail.gmail.com>
	<m2lhaoe9sh.fsf@krugs.de>
	<CAGfc75kGAjR6xWHN+uX_U6xW6jjogVvOsgGGoVwKGeh=8uoa5A@mail.gmail.com>
	<CAGfc75=30WjKr1+77GCG=vpjnvYymKSddPKUpUZ-MYpTxP=mkg@mail.gmail.com>
	<m28u6nc9cd.fsf@krugs.de>
	<CAGfc75=y901cbM1b90C5jwR_iQ5Zq_EOyFhBquAABbtXKvnJFA@mail.gmail.com>
	<571A33A1.3090202@nottingham.ac.uk>
	<CAGhLh6Ea52J30xtrqf6fPT+ieMtaHgfFxz-3BCSV-8jWHeVYoQ@mail.gmail.com>
Message-ID: <571A4680.3040304@nottingham.ac.uk>



On 22/04/2016 16:21, Rainer M Krug wrote:
>
>
> Le vendredi 22 avril 2016, Dr Didier G. Leibovici 
> <didier.leibovici at nottingham.ac.uk 
> <mailto:didier.leibovici at nottingham.ac.uk>> a ?crit :
>
>     Hi,
>
>     we are trying to use 'grass' in parallel programming with 'snow'
>
>     The code does multiple simulations of a r.viewshed resampling the
>     points
>     generating the viewshed.
>     (I guess the other solution would be to have an equivalent of
>     r.viewshed
>     in an R library or script) ...
>     I think the problems are to do with the gisDbase ...
>
>     Testing with 2 clusters we start with:
>      >  clusterCall(cl,initGRASS,"/usr/lib/grass70",home=getwd(),
>     gisDbase="GRASS_TEMP", override=TRUE )
>     [[1]]
>     gisdbase    GRASS_TEMP
>     location    file5edb6bf06d70
>     mapset      file5edb4b0cda81
>     rows        1
>     columns     1
>     north       1
>     south       0
>     west        0
>     east        1
>     nsres       1
>     ewres       1
>     projection  NA
>
>     [[2]]
>     gisdbase    GRASS_TEMP
>     location    file5edb6bf06d70
>     mapset      file5edb4b0cda81
>
>     then read a DEM
>     clusterCall(cl,execGRASS,"r.in.gdal", flags="o",
>     parameters=list(input=baseDemFilename, output="DEM"))
>        clusterCall(cl,execGRASS, "g.region",
>     parameters=list(raster="DEM"))
>
>     and then loop on the sampled points ... involving
>       execGRASS("r.viewshed", parameters = list(input = "DEM", output =
>     "cumulativeViewshed", max_distance=maxDistance, coordinates =
>     as.integer(coords[i,])), flags = c("overwrite" , "b","quiet"))
>
>       and cumulating the viewshed (reading the ouput using
>     readRAST("cumulativeViewshed")), all this (loop over the
>     points)within a
>     function simul() called
>     by a
>       parSapply(cl,1:nDsimul,simul)
>
>
>     Here is the error
>     Error in checkForRemoteErrors(val) :
>        2 nodes produced errors; first error: no such file:
>     GRASS_TEMP/file5edb6bf06d70/file5edb4b0cda81/.tmp/geoprocessing/cumulativeViewshed
>     Calls: parSapply ... clusterApply -> staticClusterApply ->
>     checkForRemoteErrors
>
>     any idea?
>
>
> The problem is likely that you are working in parallel in the same map 
> set. I would suggest to use a separate Mauser for each parallel task 
> to write to, read from a different map set which no parallel task is 
> writing to, and finally, after all threads are finished, you can 
> collect the results from each thread in one map set and delete the 
> temporary map sets.
>
> Cheers,
>
> Rainer
Yes all the problem is there for each cluster to work on a separate 
GRASS_TEMP
( we have verified that it was running with I cl only!)
Can we generate randomly the location or mapset so they will not 
collapse onto the same?

DIdier
>
>
>     thanks,
>
>     DIdier
>
>     --
>     Dr Didier G. Leibovici
>         d-d'ye    ley-bow-v-c
>     Senior Research Fellow
>     Geocomputational Modelling & Geospatial Statistics
>     Nottingham Geospatial Institute
>     University of Nottingham, UK
>     +44 (0)115 84 13924
>     http://www.nottingham.ac.uk/ngi/people/didier.leibovici
>     Google+ didier.leibovici at gmail.com <javascript:;>
>     Skype didierleibovici
>
>
>             [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-Geo mailing list
>     R-sig-Geo at r-project.org <javascript:;>
>     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
> -- 
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation 
> Biology, UCT), Dipl. Phys. (Germany)
>
> Centre of Excellence for Invasion Biology
> Stellenbosch University
> South Africa
>
> Tel :       +33 - (0)9 53 10 27 44
> Cell:       +33 - (0)6 85 62 59 98
> Fax (F):       +33 - (0)9 58 10 27 44
>
> Fax (D):    +49 - (0)3 21 21 25 22 44
>
> email: Rainer at krugs.de <mailto:Rainer at krugs.de>
>
> Skype:      RMkrug
>

-- 
Dr Didier G. Leibovici
    d-d'ye    ley-bow-v-c
Senior Research Fellow
Geocomputational Modelling & Geospatial Statistics
Nottingham Geospatial Institute
University of Nottingham, UK
+44 (0)115 84 13924
http://www.nottingham.ac.uk/ngi/people/didier.leibovici
Google+ didier.leibovici at gmail.com
Skype didierleibovici


	[[alternative HTML version deleted]]


From Rainer at krugs.de  Fri Apr 22 18:37:19 2016
From: Rainer at krugs.de (Rainer M Krug)
Date: Fri, 22 Apr 2016 18:37:19 +0200
Subject: [R-sig-Geo] rgrass7 and snow
In-Reply-To: <571A4680.3040304@nottingham.ac.uk> (Didier G. Leibovici's
	message of "Fri, 22 Apr 2016 16:42:56 +0100")
References: <CAGfc75kOhMzWuXe_jm+A81-MoiSdRanoXViAycvKGoPLuRzwfw@mail.gmail.com>
	<m2mvv87b5l.fsf@krugs.de>
	<CAGfc75mgjHT94aZm7bEFkLO5628K-8-UR--Z-FQbpndX3tsSsA@mail.gmail.com>
	<m2lhaoe9sh.fsf@krugs.de>
	<CAGfc75kGAjR6xWHN+uX_U6xW6jjogVvOsgGGoVwKGeh=8uoa5A@mail.gmail.com>
	<CAGfc75=30WjKr1+77GCG=vpjnvYymKSddPKUpUZ-MYpTxP=mkg@mail.gmail.com>
	<m28u6nc9cd.fsf@krugs.de>
	<CAGfc75=y901cbM1b90C5jwR_iQ5Zq_EOyFhBquAABbtXKvnJFA@mail.gmail.com>
	<571A33A1.3090202@nottingham.ac.uk>
	<CAGhLh6Ea52J30xtrqf6fPT+ieMtaHgfFxz-3BCSV-8jWHeVYoQ@mail.gmail.com>
	<571A4680.3040304@nottingham.ac.uk>
Message-ID: <m260v9k3b4.fsf@krugs.de>

"Dr Didier G. Leibovici" <didier.leibovici at nottingham.ac.uk> writes:

> On 22/04/2016 16:21, Rainer M Krug wrote:
>
>
>  Le vendredi 22 avril 2016, Dr Didier G. Leibovici <didier.leibovici at nottingham.ac.uk> a ?crit :
>
>
>  Hi,
>
>  we are trying to use 'grass' in parallel programming with 'snow'
>
>  The code does multiple simulations of a r.viewshed resampling the points
>  generating the viewshed.
>  (I guess the other solution would be to have an equivalent of r.viewshed
>  in an R library or script) ...
>  I think the problems are to do with the gisDbase ...
>
>  Testing with 2 clusters we start with:
>  > clusterCall(cl,initGRASS,"/usr/lib/grass70",home=getwd(),
>  gisDbase="GRASS_TEMP", override=TRUE )
>  [[1]]
>  gisdbase GRASS_TEMP
>  location file5edb6bf06d70
>  mapset file5edb4b0cda81
>  rows 1
>  columns 1
>  north 1
>  south 0
>  west 0
>  east 1
>  nsres 1
>  ewres 1
>  projection NA
>
>  [[2]]
>  gisdbase GRASS_TEMP
>  location file5edb6bf06d70
>  mapset file5edb4b0cda81
>
>  then read a DEM
>  clusterCall(cl,execGRASS,"r.in.gdal", flags="o",
>  parameters=list(input=baseDemFilename, output="DEM"))
>  clusterCall(cl,execGRASS, "g.region", parameters=list(raster="DEM"))
>
>  and then loop on the sampled points ... involving
>  execGRASS("r.viewshed", parameters = list(input = "DEM", output =
>  "cumulativeViewshed", max_distance=maxDistance, coordinates =
>  as.integer(coords[i,])), flags = c("overwrite" , "b","quiet"))
>
>  and cumulating the viewshed (reading the ouput using
>  readRAST("cumulativeViewshed")), all this (loop over the points)within a
>  function simul() called
>  by a
>  parSapply(cl,1:nDsimul,simul)
>
>  Here is the error
>  Error in checkForRemoteErrors(val) :
>  2 nodes produced errors; first error: no such file:
>  GRASS_TEMP/file5edb6bf06d70/file5edb4b0cda81/.tmp/geoprocessing/cumulativeViewshed
>  Calls: parSapply ... clusterApply -> staticClusterApply ->
>  checkForRemoteErrors
>
>  any idea?
>
>  The problem is likely that you are working in parallel in the same map set. I would suggest to use a separate Mauser for each parallel task to write to,
>  read from a different map set which no parallel task is writing to, and finally, after all threads are finished, you can collect the results from each thread
>  in one map set and delete the temporary map sets. 
>
>
>  Cheers, 
>
>
>  Rainer 
>
>
> Yes all the problem is there for each cluster to work on a separate GRASS_TEMP
> ( we have verified that it was running with I cl only!)
> Can we generate randomly the location or mapset so they will not collapse onto the same?

I used a setup for parallel processing (simulating spread under
different scenarios), where I had

1) one locaction in which everything happened, which contained:
2) one mapset which was read-only for each parallel task
3) one mapset for each task in which the results were written; this was
a folder, which was created for each parallel task
4) one mapset into which the individual simulation tasks were analysed into.

So finally, I had a mapset for each simulation, and one in which the
analysis was.

So yes, why shouldn't you be able to create a mapset per task? You can
do it during the initialization by using GRASS.

Hope this helps,

Rainer



>
> DIdier
>
>
>  thanks,
>
>  DIdier
>
>  --
>  Dr Didier G. Leibovici
>  d-d'ye ley-bow-v-c
>  Senior Research Fellow
>  Geocomputational Modelling & Geospatial Statistics
>  Nottingham Geospatial Institute
>  University of Nottingham, UK
>  +44 (0)115 84 13924
>  http://www.nottingham.ac.uk/ngi/people/didier.leibovici
>  Google+ didier.leibovici at gmail.com
>  Skype didierleibovici
>
>  [[alternative HTML version deleted]]
>
>  _______________________________________________
>  R-sig-Geo mailing list
>  R-sig-Geo at r-project.org
>  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>  -- 
>  Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>
>  Centre of Excellence for Invasion Biology
>  Stellenbosch University
>  South Africa
>
>  Tel : +33 - (0)9 53 10 27 44
>  Cell: +33 - (0)6 85 62 59 98
>  Fax (F): +33 - (0)9 58 10 27 44
>
>  Fax (D): +49 - (0)3 21 21 25 22 44
>
>  email: Rainer at krugs.de
>
>  Skype: RMkrug

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160422/4a387e4b/attachment.bin>

From didier.leibovici at nottingham.ac.uk  Fri Apr 22 19:03:07 2016
From: didier.leibovici at nottingham.ac.uk (Dr Didier G. Leibovici)
Date: Fri, 22 Apr 2016 18:03:07 +0100
Subject: [R-sig-Geo] rgrass7 and snow
In-Reply-To: <m260v9k3b4.fsf@krugs.de>
References: <CAGfc75kOhMzWuXe_jm+A81-MoiSdRanoXViAycvKGoPLuRzwfw@mail.gmail.com>
	<m2mvv87b5l.fsf@krugs.de>
	<CAGfc75mgjHT94aZm7bEFkLO5628K-8-UR--Z-FQbpndX3tsSsA@mail.gmail.com>
	<m2lhaoe9sh.fsf@krugs.de>
	<CAGfc75kGAjR6xWHN+uX_U6xW6jjogVvOsgGGoVwKGeh=8uoa5A@mail.gmail.com>
	<CAGfc75=30WjKr1+77GCG=vpjnvYymKSddPKUpUZ-MYpTxP=mkg@mail.gmail.com>
	<m28u6nc9cd.fsf@krugs.de>
	<CAGfc75=y901cbM1b90C5jwR_iQ5Zq_EOyFhBquAABbtXKvnJFA@mail.gmail.com>
	<571A33A1.3090202@nottingham.ac.uk>
	<CAGhLh6Ea52J30xtrqf6fPT+ieMtaHgfFxz-3BCSV-8jWHeVYoQ@mail.gmail.com>
	<571A4680.3040304@nottingham.ac.uk> <m260v9k3b4.fsf@krugs.de>
Message-ID: <571A594B.5040501@nottingham.ac.uk>

can you paste the call to create n mapsets. thanks


On 22/04/2016 17:37, Rainer M Krug wrote:
> "Dr Didier G. Leibovici" <didier.leibovici at nottingham.ac.uk> writes:
>
>> On 22/04/2016 16:21, Rainer M Krug wrote:
>>
>>
>>   Le vendredi 22 avril 2016, Dr Didier G. Leibovici <didier.leibovici at nottingham.ac.uk> a ?crit :
>>
>>
>>   Hi,
>>
>>   we are trying to use 'grass' in parallel programming with 'snow'
>>
>>   The code does multiple simulations of a r.viewshed resampling the points
>>   generating the viewshed.
>>   (I guess the other solution would be to have an equivalent of r.viewshed
>>   in an R library or script) ...
>>   I think the problems are to do with the gisDbase ...
>>
>>   Testing with 2 clusters we start with:
>>   > clusterCall(cl,initGRASS,"/usr/lib/grass70",home=getwd(),
>>   gisDbase="GRASS_TEMP", override=TRUE )
>>   [[1]]
>>   gisdbase GRASS_TEMP
>>   location file5edb6bf06d70
>>   mapset file5edb4b0cda81
>>   rows 1
>>   columns 1
>>   north 1
>>   south 0
>>   west 0
>>   east 1
>>   nsres 1
>>   ewres 1
>>   projection NA
>>
>>   [[2]]
>>   gisdbase GRASS_TEMP
>>   location file5edb6bf06d70
>>   mapset file5edb4b0cda81
>>
>>   then read a DEM
>>   clusterCall(cl,execGRASS,"r.in.gdal", flags="o",
>>   parameters=list(input=baseDemFilename, output="DEM"))
>>   clusterCall(cl,execGRASS, "g.region", parameters=list(raster="DEM"))
>>
>>   and then loop on the sampled points ... involving
>>   execGRASS("r.viewshed", parameters = list(input = "DEM", output =
>>   "cumulativeViewshed", max_distance=maxDistance, coordinates =
>>   as.integer(coords[i,])), flags = c("overwrite" , "b","quiet"))
>>
>>   and cumulating the viewshed (reading the ouput using
>>   readRAST("cumulativeViewshed")), all this (loop over the points)within a
>>   function simul() called
>>   by a
>>   parSapply(cl,1:nDsimul,simul)
>>
>>   Here is the error
>>   Error in checkForRemoteErrors(val) :
>>   2 nodes produced errors; first error: no such file:
>>   GRASS_TEMP/file5edb6bf06d70/file5edb4b0cda81/.tmp/geoprocessing/cumulativeViewshed
>>   Calls: parSapply ... clusterApply -> staticClusterApply ->
>>   checkForRemoteErrors
>>
>>   any idea?
>>
>>   The problem is likely that you are working in parallel in the same map set. I would suggest to use a separate Mauser for each parallel task to write to,
>>   read from a different map set which no parallel task is writing to, and finally, after all threads are finished, you can collect the results from each thread
>>   in one map set and delete the temporary map sets.
>>
>>
>>   Cheers,
>>
>>
>>   Rainer
>>
>>
>> Yes all the problem is there for each cluster to work on a separate GRASS_TEMP
>> ( we have verified that it was running with I cl only!)
>> Can we generate randomly the location or mapset so they will not collapse onto the same?
> I used a setup for parallel processing (simulating spread under
> different scenarios), where I had
>
> 1) one locaction in which everything happened, which contained:
> 2) one mapset which was read-only for each parallel task
> 3) one mapset for each task in which the results were written; this was
> a folder, which was created for each parallel task
> 4) one mapset into which the individual simulation tasks were analysed into.
>
> So finally, I had a mapset for each simulation, and one in which the
> analysis was.
>
> So yes, why shouldn't you be able to create a mapset per task? You can
> do it during the initialization by using GRASS.
>
> Hope this helps,
>
> Rainer
>
>
>
>> DIdier
>>
>>
>>   thanks,
>>
>>   DIdier
>>
>>   --
>>   Dr Didier G. Leibovici
>>   d-d'ye ley-bow-v-c
>>   Senior Research Fellow
>>   Geocomputational Modelling & Geospatial Statistics
>>   Nottingham Geospatial Institute
>>   University of Nottingham, UK
>>   +44 (0)115 84 13924
>>   http://www.nottingham.ac.uk/ngi/people/didier.leibovici
>>   Google+ didier.leibovici at gmail.com
>>   Skype didierleibovici
>>
>>   [[alternative HTML version deleted]]
>>
>>   _______________________________________________
>>   R-sig-Geo mailing list
>>   R-sig-Geo at r-project.org
>>   https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>>   --
>>   Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>>
>>   Centre of Excellence for Invasion Biology
>>   Stellenbosch University
>>   South Africa
>>
>>   Tel : +33 - (0)9 53 10 27 44
>>   Cell: +33 - (0)6 85 62 59 98
>>   Fax (F): +33 - (0)9 58 10 27 44
>>
>>   Fax (D): +49 - (0)3 21 21 25 22 44
>>
>>   email: Rainer at krugs.de
>>
>>   Skype: RMkrug

-- 
Dr Didier G. Leibovici
    d-d'ye    ley-bow-v-c
Senior Research Fellow
Geocomputational Modelling & Geospatial Statistics
Nottingham Geospatial Institute
University of Nottingham, UK
+44 (0)115 84 13924
http://www.nottingham.ac.uk/ngi/people/didier.leibovici
Google+ didier.leibovici at gmail.com
Skype didierleibovici


	[[alternative HTML version deleted]]


From Rainer at krugs.de  Fri Apr 22 19:27:38 2016
From: Rainer at krugs.de (Rainer M Krug)
Date: Fri, 22 Apr 2016 19:27:38 +0200
Subject: [R-sig-Geo] rgrass7 and snow
In-Reply-To: <571A594B.5040501@nottingham.ac.uk> (Didier G. Leibovici's
	message of "Fri, 22 Apr 2016 18:03:07 +0100")
References: <CAGfc75kOhMzWuXe_jm+A81-MoiSdRanoXViAycvKGoPLuRzwfw@mail.gmail.com>
	<m2mvv87b5l.fsf@krugs.de>
	<CAGfc75mgjHT94aZm7bEFkLO5628K-8-UR--Z-FQbpndX3tsSsA@mail.gmail.com>
	<m2lhaoe9sh.fsf@krugs.de>
	<CAGfc75kGAjR6xWHN+uX_U6xW6jjogVvOsgGGoVwKGeh=8uoa5A@mail.gmail.com>
	<CAGfc75=30WjKr1+77GCG=vpjnvYymKSddPKUpUZ-MYpTxP=mkg@mail.gmail.com>
	<m28u6nc9cd.fsf@krugs.de>
	<CAGfc75=y901cbM1b90C5jwR_iQ5Zq_EOyFhBquAABbtXKvnJFA@mail.gmail.com>
	<571A33A1.3090202@nottingham.ac.uk>
	<CAGhLh6Ea52J30xtrqf6fPT+ieMtaHgfFxz-3BCSV-8jWHeVYoQ@mail.gmail.com>
	<571A4680.3040304@nottingham.ac.uk> <m260v9k3b4.fsf@krugs.de>
	<571A594B.5040501@nottingham.ac.uk>
Message-ID: <m21t5xk0z9.fsf@krugs.de>

"Dr Didier G. Leibovici" <didier.leibovici at nottingham.ac.uk> writes:

> can you paste the call to create n mapsets. thanks

You can create a mapset with

g.mapset -c mapset=THE_NAME_OF_THE_MAPSET

You can do this in a loop in an R script, or bash script - whatever you
are more familiar with.


Rainer


>
> On 22/04/2016 17:37, Rainer M Krug wrote:
>
>
>  "Dr Didier G. Leibovici" <didier.leibovici at nottingham.ac.uk> writes:
>
>  On 22/04/2016 16:21, Rainer M Krug wrote:
>
>
>  Le vendredi 22 avril 2016, Dr Didier G. Leibovici <didier.leibovici at nottingham.ac.uk> a ?crit :
>
>
>  Hi,
>
>  we are trying to use 'grass' in parallel programming with 'snow'
>
>  The code does multiple simulations of a r.viewshed resampling the points
>  generating the viewshed.
>  (I guess the other solution would be to have an equivalent of r.viewshed
>  in an R library or script) ...
>  I think the problems are to do with the gisDbase ...
>
>  Testing with 2 clusters we start with:
>  > clusterCall(cl,initGRASS,"/usr/lib/grass70",home=getwd(),
>  gisDbase="GRASS_TEMP", override=TRUE )
>  [[1]]
>  gisdbase GRASS_TEMP
>  location file5edb6bf06d70
>  mapset file5edb4b0cda81
>  rows 1
>  columns 1
>  north 1
>  south 0
>  west 0
>  east 1
>  nsres 1
>  ewres 1
>  projection NA
>
>  [[2]]
>  gisdbase GRASS_TEMP
>  location file5edb6bf06d70
>  mapset file5edb4b0cda81
>
>  then read a DEM
>  clusterCall(cl,execGRASS,"r.in.gdal", flags="o",
>  parameters=list(input=baseDemFilename, output="DEM"))
>  clusterCall(cl,execGRASS, "g.region", parameters=list(raster="DEM"))
>
>  and then loop on the sampled points ... involving
>  execGRASS("r.viewshed", parameters = list(input = "DEM", output =
>  "cumulativeViewshed", max_distance=maxDistance, coordinates =
>  as.integer(coords[i,])), flags = c("overwrite" , "b","quiet"))
>
>  and cumulating the viewshed (reading the ouput using
>  readRAST("cumulativeViewshed")), all this (loop over the points)within a
>  function simul() called
>  by a
>  parSapply(cl,1:nDsimul,simul)
>
>  Here is the error
>  Error in checkForRemoteErrors(val) :
>  2 nodes produced errors; first error: no such file:
>  GRASS_TEMP/file5edb6bf06d70/file5edb4b0cda81/.tmp/geoprocessing/cumulativeViewshed
>  Calls: parSapply ... clusterApply -> staticClusterApply ->
>  checkForRemoteErrors
>
>  any idea?
>
>  The problem is likely that you are working in parallel in the same map set. I would suggest to use a separate Mauser for each parallel task to write to,
>  read from a different map set which no parallel task is writing to, and finally, after all threads are finished, you can collect the results from each thread
>  in one map set and delete the temporary map sets. 
>
>
>  Cheers, 
>
>
>  Rainer 
>
>
> Yes all the problem is there for each cluster to work on a separate GRASS_TEMP
> ( we have verified that it was running with I cl only!)
> Can we generate randomly the location or mapset so they will not collapse onto the same?
>
>
>
> I used a setup for parallel processing (simulating spread under
> different scenarios), where I had
>
> 1) one locaction in which everything happened, which contained:
> 2) one mapset which was read-only for each parallel task
> 3) one mapset for each task in which the results were written; this was
> a folder, which was created for each parallel task
> 4) one mapset into which the individual simulation tasks were analysed into.
>
> So finally, I had a mapset for each simulation, and one in which the
> analysis was.
>
> So yes, why shouldn't you be able to create a mapset per task? You can
> do it during the initialization by using GRASS.
>
> Hope this helps,
>
> Rainer
>
>
>
>  
> DIdier
>
>
>  thanks,
>
>  DIdier
>
>  --
>  Dr Didier G. Leibovici
>  d-d'ye ley-bow-v-c
>  Senior Research Fellow
>  Geocomputational Modelling & Geospatial Statistics
>  Nottingham Geospatial Institute
>  University of Nottingham, UK
>  +44 (0)115 84 13924
>  http://www.nottingham.ac.uk/ngi/people/didier.leibovici
>  Google+ didier.leibovici at gmail.com
>  Skype didierleibovici
>
>  [[alternative HTML version deleted]]
>
>  _______________________________________________
>  R-sig-Geo mailing list
>  R-sig-Geo at r-project.org
>  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>  -- 
>  Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>
>  Centre of Excellence for Invasion Biology
>  Stellenbosch University
>  South Africa
>
>  Tel : +33 - (0)9 53 10 27 44
>  Cell: +33 - (0)6 85 62 59 98
>  Fax (F): +33 - (0)9 58 10 27 44
>
>  Fax (D): +49 - (0)3 21 21 25 22 44
>
>  email: Rainer at krugs.de
>
>  Skype: RMkrug

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160422/5f0c8048/attachment.bin>

From didier.leibovici at nottingham.ac.uk  Fri Apr 22 19:56:41 2016
From: didier.leibovici at nottingham.ac.uk (Dr Didier G. Leibovici)
Date: Fri, 22 Apr 2016 18:56:41 +0100
Subject: [R-sig-Geo] rgrass7 and snow
In-Reply-To: <m21t5xk0z9.fsf@krugs.de>
References: <CAGfc75kOhMzWuXe_jm+A81-MoiSdRanoXViAycvKGoPLuRzwfw@mail.gmail.com>
	<m2mvv87b5l.fsf@krugs.de>
	<CAGfc75mgjHT94aZm7bEFkLO5628K-8-UR--Z-FQbpndX3tsSsA@mail.gmail.com>
	<m2lhaoe9sh.fsf@krugs.de>
	<CAGfc75kGAjR6xWHN+uX_U6xW6jjogVvOsgGGoVwKGeh=8uoa5A@mail.gmail.com>
	<CAGfc75=30WjKr1+77GCG=vpjnvYymKSddPKUpUZ-MYpTxP=mkg@mail.gmail.com>
	<m28u6nc9cd.fsf@krugs.de>
	<CAGfc75=y901cbM1b90C5jwR_iQ5Zq_EOyFhBquAABbtXKvnJFA@mail.gmail.com>
	<571A33A1.3090202@nottingham.ac.uk>
	<CAGhLh6Ea52J30xtrqf6fPT+ieMtaHgfFxz-3BCSV-8jWHeVYoQ@mail.gmail.com>
	<571A4680.3040304@nottingham.ac.uk> <m260v9k3b4.fsf@krugs.de>
	<571A594B.5040501@nottingham.ac.uk> <m21t5xk0z9.fsf@krugs.de>
Message-ID: <571A65D9.2050105@nottingham.ac.uk>

Yes but then how the clusters use a different one i.e. how did you write 
your initGRASS()

thanks


On 22/04/2016 18:27, Rainer M Krug wrote:
> "Dr Didier G. Leibovici" <didier.leibovici at nottingham.ac.uk> writes:
>
>> can you paste the call to create n mapsets. thanks
> You can create a mapset with
>
> g.mapset -c mapset=THE_NAME_OF_THE_MAPSET
>
> You can do this in a loop in an R script, or bash script - whatever you
> are more familiar with.
>
>
> Rainer
>
>
>> On 22/04/2016 17:37, Rainer M Krug wrote:
>>
>>
>>   "Dr Didier G. Leibovici" <didier.leibovici at nottingham.ac.uk> writes:
>>
>>   On 22/04/2016 16:21, Rainer M Krug wrote:
>>
>>
>>   Le vendredi 22 avril 2016, Dr Didier G. Leibovici <didier.leibovici at nottingham.ac.uk> a ?crit :
>>
>>
>>   Hi,
>>
>>   we are trying to use 'grass' in parallel programming with 'snow'
>>
>>   The code does multiple simulations of a r.viewshed resampling the points
>>   generating the viewshed.
>>   (I guess the other solution would be to have an equivalent of r.viewshed
>>   in an R library or script) ...
>>   I think the problems are to do with the gisDbase ...
>>
>>   Testing with 2 clusters we start with:
>>   > clusterCall(cl,initGRASS,"/usr/lib/grass70",home=getwd(),
>>   gisDbase="GRASS_TEMP", override=TRUE )
>>   [[1]]
>>   gisdbase GRASS_TEMP
>>   location file5edb6bf06d70
>>   mapset file5edb4b0cda81
>>   rows 1
>>   columns 1
>>   north 1
>>   south 0
>>   west 0
>>   east 1
>>   nsres 1
>>   ewres 1
>>   projection NA
>>
>>   [[2]]
>>   gisdbase GRASS_TEMP
>>   location file5edb6bf06d70
>>   mapset file5edb4b0cda81
>>
>>   then read a DEM
>>   clusterCall(cl,execGRASS,"r.in.gdal", flags="o",
>>   parameters=list(input=baseDemFilename, output="DEM"))
>>   clusterCall(cl,execGRASS, "g.region", parameters=list(raster="DEM"))
>>
>>   and then loop on the sampled points ... involving
>>   execGRASS("r.viewshed", parameters = list(input = "DEM", output =
>>   "cumulativeViewshed", max_distance=maxDistance, coordinates =
>>   as.integer(coords[i,])), flags = c("overwrite" , "b","quiet"))
>>
>>   and cumulating the viewshed (reading the ouput using
>>   readRAST("cumulativeViewshed")), all this (loop over the points)within a
>>   function simul() called
>>   by a
>>   parSapply(cl,1:nDsimul,simul)
>>
>>   Here is the error
>>   Error in checkForRemoteErrors(val) :
>>   2 nodes produced errors; first error: no such file:
>>   GRASS_TEMP/file5edb6bf06d70/file5edb4b0cda81/.tmp/geoprocessing/cumulativeViewshed
>>   Calls: parSapply ... clusterApply -> staticClusterApply ->
>>   checkForRemoteErrors
>>
>>   any idea?
>>
>>   The problem is likely that you are working in parallel in the same map set. I would suggest to use a separate Mauser for each parallel task to write to,
>>   read from a different map set which no parallel task is writing to, and finally, after all threads are finished, you can collect the results from each thread
>>   in one map set and delete the temporary map sets.
>>
>>
>>   Cheers,
>>
>>
>>   Rainer
>>
>>
>> Yes all the problem is there for each cluster to work on a separate GRASS_TEMP
>> ( we have verified that it was running with I cl only!)
>> Can we generate randomly the location or mapset so they will not collapse onto the same?
>>
>>
>>
>> I used a setup for parallel processing (simulating spread under
>> different scenarios), where I had
>>
>> 1) one locaction in which everything happened, which contained:
>> 2) one mapset which was read-only for each parallel task
>> 3) one mapset for each task in which the results were written; this was
>> a folder, which was created for each parallel task
>> 4) one mapset into which the individual simulation tasks were analysed into.
>>
>> So finally, I had a mapset for each simulation, and one in which the
>> analysis was.
>>
>> So yes, why shouldn't you be able to create a mapset per task? You can
>> do it during the initialization by using GRASS.
>>
>> Hope this helps,
>>
>> Rainer
>>
>>
>>
>>   
>> DIdier
>>
>>
>>   thanks,
>>
>>   DIdier
>>
>>   --
>>   Dr Didier G. Leibovici
>>   d-d'ye ley-bow-v-c
>>   Senior Research Fellow
>>   Geocomputational Modelling & Geospatial Statistics
>>   Nottingham Geospatial Institute
>>   University of Nottingham, UK
>>   +44 (0)115 84 13924
>>   http://www.nottingham.ac.uk/ngi/people/didier.leibovici
>>   Google+ didier.leibovici at gmail.com
>>   Skype didierleibovici
>>
>>   [[alternative HTML version deleted]]
>>
>>   _______________________________________________
>>   R-sig-Geo mailing list
>>   R-sig-Geo at r-project.org
>>   https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>>   --
>>   Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>>
>>   Centre of Excellence for Invasion Biology
>>   Stellenbosch University
>>   South Africa
>>
>>   Tel : +33 - (0)9 53 10 27 44
>>   Cell: +33 - (0)6 85 62 59 98
>>   Fax (F): +33 - (0)9 58 10 27 44
>>
>>   Fax (D): +49 - (0)3 21 21 25 22 44
>>
>>   email: Rainer at krugs.de
>>
>>   Skype: RMkrug

-- 
Dr Didier G. Leibovici
    d-d'ye    ley-bow-v-c
Senior Research Fellow
Geocomputational Modelling & Geospatial Statistics
Nottingham Geospatial Institute
University of Nottingham, UK
+44 (0)115 84 13924
http://www.nottingham.ac.uk/ngi/people/didier.leibovici
Google+ didier.leibovici at gmail.com
Skype didierleibovici


	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Fri Apr 22 20:50:33 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 22 Apr 2016 20:50:33 +0200
Subject: [R-sig-Geo] rgrass7 and snow
In-Reply-To: <571A65D9.2050105@nottingham.ac.uk>
References: <CAGfc75kOhMzWuXe_jm+A81-MoiSdRanoXViAycvKGoPLuRzwfw@mail.gmail.com>
	<m2mvv87b5l.fsf@krugs.de>
	<CAGfc75mgjHT94aZm7bEFkLO5628K-8-UR--Z-FQbpndX3tsSsA@mail.gmail.com>
	<m2lhaoe9sh.fsf@krugs.de>
	<CAGfc75kGAjR6xWHN+uX_U6xW6jjogVvOsgGGoVwKGeh=8uoa5A@mail.gmail.com>
	<CAGfc75=30WjKr1+77GCG=vpjnvYymKSddPKUpUZ-MYpTxP=mkg@mail.gmail.com>
	<m28u6nc9cd.fsf@krugs.de>
	<CAGfc75=y901cbM1b90C5jwR_iQ5Zq_EOyFhBquAABbtXKvnJFA@mail.gmail.com>
	<571A33A1.3090202@nottingham.ac.uk>
	<CAGhLh6Ea52J30xtrqf6fPT+ieMtaHgfFxz-3BCSV-8jWHeVYoQ@mail.gmail.com>
	<571A4680.3040304@nottingham.ac.uk> <m260v9k3b4.fsf@krugs.de>
	<571A594B.5040501@nottingham.ac.uk> <m21t5xk0z9.fsf@krugs.de>
	<571A65D9.2050105@nottingham.ac.uk>
Message-ID: <alpine.LFD.2.20.1604222038020.9742@reclus.nhh.no>

On Fri, 22 Apr 2016, Dr Didier G. Leibovici wrote:

> Yes but then how the clusters use a different one i.e. how did you write 
> your initGRASS()

I think that if you play around with execGRASS(), you'll find that your 
temporary location has a PERMANENT mapset, and a working mapset. Look at 
the directory to which you pointed home=; those two directories should be 
present. Maybe use list.files(). Then use execGRASS("g.mapset", 
mapset="<new0>", flags="c") to create one and switch to it. I guess you'd 
need as many new mapsets as cores, and a vector of mapset names. Remember 
that you can use g.mapsets to see or change your mapset search path, and 
you can use the @mapset notation for any vector or raster, so the nodes 
can each have their own spaces. Maybe use g.copy to copy data out to nodes 
to avoid race conditions if reading from the same GRASS database file by 
multiple nodes.

It would be useful to have an example of what you need to do, simulation 
being fairly obvious, but I think r.in.gdal will be problematic, better to 
read once and copy out to the simulation mapsets by repeated g.copy. The 
more limited the use of initGRASS on each core, probably the better.

Hope this helps,

Roger

>
> thanks
>
>
> On 22/04/2016 18:27, Rainer M Krug wrote:
>> "Dr Didier G. Leibovici" <didier.leibovici at nottingham.ac.uk> writes:
>>
>>> can you paste the call to create n mapsets. thanks
>> You can create a mapset with
>>
>> g.mapset -c mapset=THE_NAME_OF_THE_MAPSET
>>
>> You can do this in a loop in an R script, or bash script - whatever you
>> are more familiar with.
>>
>>
>> Rainer
>>
>>
>>> On 22/04/2016 17:37, Rainer M Krug wrote:
>>>
>>>
>>>   "Dr Didier G. Leibovici" <didier.leibovici at nottingham.ac.uk> writes:
>>>
>>>   On 22/04/2016 16:21, Rainer M Krug wrote:
>>>
>>>
>>>   Le vendredi 22 avril 2016, Dr Didier G. Leibovici <didier.leibovici at nottingham.ac.uk> a ?crit :
>>>
>>>
>>>   Hi,
>>>
>>>   we are trying to use 'grass' in parallel programming with 'snow'
>>>
>>>   The code does multiple simulations of a r.viewshed resampling the points
>>>   generating the viewshed.
>>>   (I guess the other solution would be to have an equivalent of r.viewshed
>>>   in an R library or script) ...
>>>   I think the problems are to do with the gisDbase ...
>>>
>>>   Testing with 2 clusters we start with:
>>>   > clusterCall(cl,initGRASS,"/usr/lib/grass70",home=getwd(),
>>>   gisDbase="GRASS_TEMP", override=TRUE )
>>>   [[1]]
>>>   gisdbase GRASS_TEMP
>>>   location file5edb6bf06d70
>>>   mapset file5edb4b0cda81
>>>   rows 1
>>>   columns 1
>>>   north 1
>>>   south 0
>>>   west 0
>>>   east 1
>>>   nsres 1
>>>   ewres 1
>>>   projection NA
>>>
>>>   [[2]]
>>>   gisdbase GRASS_TEMP
>>>   location file5edb6bf06d70
>>>   mapset file5edb4b0cda81
>>>
>>>   then read a DEM
>>>   clusterCall(cl,execGRASS,"r.in.gdal", flags="o",
>>>   parameters=list(input=baseDemFilename, output="DEM"))
>>>   clusterCall(cl,execGRASS, "g.region", parameters=list(raster="DEM"))
>>>
>>>   and then loop on the sampled points ... involving
>>>   execGRASS("r.viewshed", parameters = list(input = "DEM", output =
>>>   "cumulativeViewshed", max_distance=maxDistance, coordinates =
>>>   as.integer(coords[i,])), flags = c("overwrite" , "b","quiet"))
>>>
>>>   and cumulating the viewshed (reading the ouput using
>>>   readRAST("cumulativeViewshed")), all this (loop over the points)within a
>>>   function simul() called
>>>   by a
>>>   parSapply(cl,1:nDsimul,simul)
>>>
>>>   Here is the error
>>>   Error in checkForRemoteErrors(val) :
>>>   2 nodes produced errors; first error: no such file:
>>>   GRASS_TEMP/file5edb6bf06d70/file5edb4b0cda81/.tmp/geoprocessing/cumulativeViewshed
>>>   Calls: parSapply ... clusterApply -> staticClusterApply ->
>>>   checkForRemoteErrors
>>>
>>>   any idea?
>>>
>>>   The problem is likely that you are working in parallel in the same map set. I would suggest to use a separate Mauser for each parallel task to write to,
>>>   read from a different map set which no parallel task is writing to, and finally, after all threads are finished, you can collect the results from each thread
>>>   in one map set and delete the temporary map sets.
>>>
>>>
>>>   Cheers,
>>>
>>>
>>>   Rainer
>>>
>>>
>>> Yes all the problem is there for each cluster to work on a separate GRASS_TEMP
>>> ( we have verified that it was running with I cl only!)
>>> Can we generate randomly the location or mapset so they will not collapse onto the same?
>>>
>>>
>>>
>>> I used a setup for parallel processing (simulating spread under
>>> different scenarios), where I had
>>>
>>> 1) one locaction in which everything happened, which contained:
>>> 2) one mapset which was read-only for each parallel task
>>> 3) one mapset for each task in which the results were written; this was
>>> a folder, which was created for each parallel task
>>> 4) one mapset into which the individual simulation tasks were analysed into.
>>>
>>> So finally, I had a mapset for each simulation, and one in which the
>>> analysis was.
>>>
>>> So yes, why shouldn't you be able to create a mapset per task? You can
>>> do it during the initialization by using GRASS.
>>>
>>> Hope this helps,
>>>
>>> Rainer
>>>
>>>
>>>
>>> 
>>> DIdier
>>>
>>>
>>>   thanks,
>>>
>>>   DIdier
>>>
>>>   --
>>>   Dr Didier G. Leibovici
>>>   d-d'ye ley-bow-v-c
>>>   Senior Research Fellow
>>>   Geocomputational Modelling & Geospatial Statistics
>>>   Nottingham Geospatial Institute
>>>   University of Nottingham, UK
>>>   +44 (0)115 84 13924
>>>   http://www.nottingham.ac.uk/ngi/people/didier.leibovici
>>>   Google+ didier.leibovici at gmail.com
>>>   Skype didierleibovici
>>>
>>>   [[alternative HTML version deleted]]
>>>
>>>   _______________________________________________
>>>   R-sig-Geo mailing list
>>>   R-sig-Geo at r-project.org
>>>   https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>>   --
>>>   Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>>>
>>>   Centre of Excellence for Invasion Biology
>>>   Stellenbosch University
>>>   South Africa
>>>
>>>   Tel : +33 - (0)9 53 10 27 44
>>>   Cell: +33 - (0)6 85 62 59 98
>>>   Fax (F): +33 - (0)9 58 10 27 44
>>>
>>>   Fax (D): +49 - (0)3 21 21 25 22 44
>>>
>>>   email: Rainer at krugs.de
>>>
>>>   Skype: RMkrug
>
> -- 
> Dr Didier G. Leibovici
>    d-d'ye    ley-bow-v-c
> Senior Research Fellow
> Geocomputational Modelling & Geospatial Statistics
> Nottingham Geospatial Institute
> University of Nottingham, UK
> +44 (0)115 84 13924
> http://www.nottingham.ac.uk/ngi/people/didier.leibovici
> Google+ didier.leibovici at gmail.com
> Skype didierleibovici
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412

From afischbach at usgs.gov  Fri Apr 22 22:14:12 2016
From: afischbach at usgs.gov (Fischbach, Anthony)
Date: Fri, 22 Apr 2016 12:14:12 -0800
Subject: [R-sig-Geo] coercing marmap bathy object to raster spanning the
	antimeridian
Message-ID: <CA+ZRYj8wi1tb9Hq0YzOQ=amhdqyijh+G4HsaYfGCx3Vomt5QsQ@mail.gmail.com>

Projecting a bathymetric dataset spanning the antimeridian as a raster
fails for negative longitudes.

This example is from the marmap vignette.

> aleu <- getNOAA.bathy(165, -145, 50, 65, resolution = 5, antimeridian =
TRUE)
> summary(aleu)
Bathymetric data of class 'bathy', with 599 rows and 180 columns
Latitudinal range: 50.04 to 64.96 (50.04 N to 64.96 N)
Longitudinal range: 165.04 to 214.96 (165.04 E to 145.04 W)
Cell size: 5 minute(s)

Depth statistics:
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
  -7560   -3836    -335   -1832      -7    4374
...
> aleu.r.geo<-marmap::as.raster(aleu)  ## Coerce to a raster
> aleu.r.geo  ## Summary of raster shows that all coordinates longitudes
are positive.
class       : RasterLayer
dimensions  : 180, 599, 107820  (nrow, ncol, ncell)
resolution  : 0.08333333, 0.08287037  (x, y)
extent      : 165.0417, 214.9583, 50.04167, 64.95833  (xmin, xmax, ymin,
ymax)
coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
data source : in memory
names       : layer
values      : -7560, 4374  (min, max)

## Here is my trouble:  I wish to project the rater bathymetry to a local
coordinate system.
> prj.StudyArea <- CRS(" +proj=aeqd +lat_0=55 +lon_0=-170 +x_0=0 +y_0=0
+datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0 ")  #Azimuthal
Equadistant -170, 55
> aleu.r<-projectRaster(from=aleu.r.geo, res=20000, crs=prj.StudyArea,
method="bilinear", over=FALSE)
> aleu.r
class       : RasterLayer
dimensions  : 104, 185, 19240  (nrow, ncol, ncell)
resolution  : 20000, 20000  (x, y)
extent      : -1854207, 1845793, -652276.3, 1427724  (xmin, xmax, ymin,
ymax)
coord. ref. : +proj=aeqd +lat_0=55 +lon_0=-170 +x_0=0 +y_0=0 +datum=WGS84
+units=m +no_defs +ellps=WGS84 +towgs84=0,0,0
data source : in memory
names       : layer
values      : -7343.845, 1255.485  (min, max)

The summary of the projected raster (aleu.r) indicates x coordinates
spanning my study area (from negative to positive values in the
prj.StudyArea CRS).
Yet, a plot of the project raster reveals that the eastern half (the region
east of the antimeridian) is missing.
> plot(aleu.r) ## Plot image pasted below.

Is there a trick to getting this right, without introducing missing data at
the antimeridian?
[image: Inline image 1]

Anthony Fischbach, Wildlife Biologist
http://alaska.usgs.gov/science/biology/walrus/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160422/d45fcf98/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 28957 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160422/d45fcf98/attachment.png>

From Andy.Bunn at wwu.edu  Mon Apr 25 05:07:03 2016
From: Andy.Bunn at wwu.edu (Andy Bunn)
Date: Mon, 25 Apr 2016 03:07:03 +0000
Subject: [R-sig-Geo] Data sets for teaching spatial analysis in R
Message-ID: <D342C6B5.52147%andy.bunn@wwu.edu>

Hi all, I'm teaching a five week unit for environmental science grad students on spatial analysis in R. It's kind of a blitz of methods to let them see the kinds of analyses that are commonly used in spatial analysis. We cover spatial autocorrelation, point patterns, interpolation, and spatial regression. They work through examples in R throughout and I like to provide them with an interesting variety of data sets to work with - e.g., we use the Meuse River data quite a bit and read from Bivand et al. 2013 - so we use some of the data from that as well.  I'd love to hear about data sets that some of you might use to teach spatial in R. I have students in the class that have interests ranging from marine ecology, to toxicology, to wildlife. So a great blend of students and interests.

Many thanks for tips,

-Andy

	[[alternative HTML version deleted]]


From f.rodriguez.sanc at gmail.com  Mon Apr 25 11:54:47 2016
From: f.rodriguez.sanc at gmail.com (Francisco Rodriguez Sanchez)
Date: Mon, 25 Apr 2016 11:54:47 +0200
Subject: [R-sig-Geo] Data sets for teaching spatial analysis in R
In-Reply-To: <D342C6B5.52147%andy.bunn@wwu.edu>
References: <D342C6B5.52147%andy.bunn@wwu.edu>
Message-ID: <571DE967.7000605@gmail.com>

Interesting course!

What about Barro Colorado Island Tree Counts? 
http://cc.oulu.fi/~jarioksa/softhelp/vegan/html/BCI.html

Cheers

Paco

El 25/04/2016 a las 05:07, Andy Bunn escribi?:
> Hi all, I'm teaching a five week unit for environmental science grad students on spatial analysis in R. It's kind of a blitz of methods to let them see the kinds of analyses that are commonly used in spatial analysis. We cover spatial autocorrelation, point patterns, interpolation, and spatial regression. They work through examples in R throughout and I like to provide them with an interesting variety of data sets to work with - e.g., we use the Meuse River data quite a bit and read from Bivand et al. 2013 - so we use some of the data from that as well.  I'd love to hear about data sets that some of you might use to teach spatial in R. I have students in the class that have interests ranging from marine ecology, to toxicology, to wildlife. So a great blend of students and interests.
>
> Many thanks for tips,
>
> -Andy
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Dr Francisco Rodriguez-Sanchez
Integrative Ecology Group
Estacion Biologica de Do?ana - CSIC
Avda. Americo Vespucio s/n
41092 Sevilla (Spain)
http://bit.ly/frod_san


From azm at uow.edu.au  Mon Apr 25 12:30:27 2016
From: azm at uow.edu.au (Andrew Zammit Mangion)
Date: Mon, 25 Apr 2016 10:30:27 +0000
Subject: [R-sig-Geo] Data sets for teaching spatial analysis in R
In-Reply-To: <D342C6B5.52147%andy.bunn@wwu.edu>
References: <D342C6B5.52147%andy.bunn@wwu.edu>
Message-ID: <1461580257944.99227@uow.edu.au>

Hi Andy,
 I have put a couple of dozen datasets either that I've worked on or that I found interesting here

https://hpc.niasra.uow.edu.au/ckan/organization/cei

Most of these are classics, some of which can be found in R packages, and all are spatial or spatio-temporal in nature. I have supplied a description and reference for each dataset and these are available under a Creative Commons (CC) license.  Hope it's of use.

Regards,
Andrew

-----------------------------------------------------------------------------
Andrew Zammit Mangion, Statistical Computing Scientist, 
Centre for Environmental Informatics, National Institute for Applied Statistics Research Australia (NIASRA), School of Mathematics and Applied Statistics, 
University of Wollongong NSW 2522, 
Australia Office telephone:
Within Australia... (02) 4221 5112 
International... +61 2 4221 5112
E-mail: azm at uow.edu.au
------------------------------------------------------------------------------
________________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of Andy Bunn <Andy.Bunn at wwu.edu>
Sent: 25 April 2016 13:07
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] Data sets for teaching spatial analysis in R

Hi all, I'm teaching a five week unit for environmental science grad students on spatial analysis in R. It's kind of a blitz of methods to let them see the kinds of analyses that are commonly used in spatial analysis. We cover spatial autocorrelation, point patterns, interpolation, and spatial regression. They work through examples in R throughout and I like to provide them with an interesting variety of data sets to work with - e.g., we use the Meuse River data quite a bit and read from Bivand et al. 2013 - so we use some of the data from that as well.  I'd love to hear about data sets that some of you might use to teach spatial in R. I have students in the class that have interests ranging from marine ecology, to toxicology, to wildlife. So a great blend of students and interests.

Many thanks for tips,

-Andy

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

From juta.kawalerowicz at nuffield.ox.ac.uk  Mon Apr 25 13:35:59 2016
From: juta.kawalerowicz at nuffield.ox.ac.uk (Juta Kawalerowicz)
Date: Mon, 25 Apr 2016 13:35:59 +0200
Subject: [R-sig-Geo] spatialpoints: each dot represents 100 individuals?
Message-ID: <CAHMizkMA8kKL8E5YBdtWJ7O_Mn1mEZUNw+h35X13Mvp4BDehtQ@mail.gmail.com>

Hi,

I have a dataset with couple of million of points (individuals) and
would like to do some mapping (I have the coordinates of each point)
but given the number of observation I think it may be usuful to plot
dots which represent 100 individuals (of a given group). Does anyone
know a good way to aggregate up spatialpoints? Any suggestions would
be much appreciated!

Best wishes,
Juta


From santiago.begueria at csic.es  Mon Apr 25 13:52:32 2016
From: santiago.begueria at csic.es (=?utf-8?Q?Santiago_Beguer=C3=ADa?=)
Date: Mon, 25 Apr 2016 13:52:32 +0200
Subject: [R-sig-Geo] spatialpoints: each dot represents 100 individuals?
In-Reply-To: <CAHMizkMA8kKL8E5YBdtWJ7O_Mn1mEZUNw+h35X13Mvp4BDehtQ@mail.gmail.com>
References: <CAHMizkMA8kKL8E5YBdtWJ7O_Mn1mEZUNw+h35X13Mvp4BDehtQ@mail.gmail.com>
Message-ID: <CE447E4A-177B-446C-8288-0A10D9CF9999@csic.es>

Hi Juta,

Do you need to represent the aggregated data as points necessarily? Otherwise, I have used the stat_hexbin representation from ggplot2 for that very purpose, see for instance:

http://santiago.begueria.es/wordpress/wp-content/uploads/2015/06/Figure_01.png

Cheers,

Stg

> El 25 abr 2016, a las 13:35, Juta Kawalerowicz <juta.kawalerowicz at nuffield.ox.ac.uk> escribi?:
> 
> Hi,
> 
> I have a dataset with couple of million of points (individuals) and
> would like to do some mapping (I have the coordinates of each point)
> but given the number of observation I think it may be usuful to plot
> dots which represent 100 individuals (of a given group). Does anyone
> know a good way to aggregate up spatialpoints? Any suggestions would
> be much appreciated!
> 
> Best wishes,
> Juta
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From tim.appelhans at gmail.com  Mon Apr 25 13:55:48 2016
From: tim.appelhans at gmail.com (Tim Appelhans)
Date: Mon, 25 Apr 2016 13:55:48 +0200
Subject: [R-sig-Geo] spatialpoints: each dot represents 100 individuals?
In-Reply-To: <CAHMizkMA8kKL8E5YBdtWJ7O_Mn1mEZUNw+h35X13Mvp4BDehtQ@mail.gmail.com>
References: <CAHMizkMA8kKL8E5YBdtWJ7O_Mn1mEZUNw+h35X13Mvp4BDehtQ@mail.gmail.com>
Message-ID: <571E05C4.20708@gmail.com>

Hi Juta,
in case you want to do web-mapping, library("mapview") should be able to 
handle a couple of million (in the sense that a couple means approx. 2).

Cheers
Tim

On 25.04.2016 13:35, Juta Kawalerowicz wrote:
> Hi,
>
> I have a dataset with couple of million of points (individuals) and
> would like to do some mapping (I have the coordinates of each point)
> but given the number of observation I think it may be usuful to plot
> dots which represent 100 individuals (of a given group). Does anyone
> know a good way to aggregate up spatialpoints? Any suggestions would
> be much appreciated!
>
> Best wishes,
> Juta
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
#####################################
Tim Appelhans
Department of Geography
Environmental Informatics
Philipps Universit?t Marburg
Deutschhausstra?e 12
Raum 00A08
35032 Marburg (Paketpost: 35037 Marburg)
Germany

Tel +49 (0) 6421 28-25957

http://environmentalinformatics-marburg.de/


From konno_kazuma at mailplus.pl  Mon Apr 25 14:26:56 2016
From: konno_kazuma at mailplus.pl (=?UTF-8?Q?Kamil_Konowalik?=)
Date: Mon, 25 Apr 2016 14:26:56 +0200
Subject: [R-sig-Geo]
	=?utf-8?q?spatialpoints=3A_each_dot_represents_100_in?=
	=?utf-8?q?dividuals=3F?=
Message-ID: <4a5bec7d.50852bf5.571e0d10.3994a@mailplus.pl>

Hi Juta,
some time ago I came across that approach proposed by Dan Warren on his blog: 
http://enmtools.blogspot.com/2015/10/handy-little-snippet-of-r-code-for.html
Maybe this will be useful for you as well? 
Santiago this figure looks quite nice. Do you have the R code to generate it? I found the description of that function but I will understand it better if I'll have the example and I didn't used ggplot2 for maps so far. 
Best regards,
Kamil

Dnia 25 kwietnia 2016 13:52 Santiago Beguer?a <santiago.begueria at csic.es> napisa?(a):

> Hi Juta,
> 
> Do you need to represent the aggregated data as points necessarily? Otherwise, I have used the stat_hexbin representation from ggplot2 for that very purpose, see for instance:
> 
> http://santiago.begueria.es/wordpress/wp-content/uploads/2015/06/Figure_01.png
> 
> Cheers,
> 
> Stg
> 
> > El 25 abr 2016, a las 13:35, Juta Kawalerowicz <juta.kawalerowicz at nuffield.ox.ac.uk> escribi?:
> > 
> > Hi,
> > 
> > I have a dataset with couple of million of points (individuals) and
> > would like to do some mapping (I have the coordinates of each point)
> > but given the number of observation I think it may be usuful to plot
> > dots which represent 100 individuals (of a given group). Does anyone
> > know a good way to aggregate up spatialpoints? Any suggestions would
> > be much appreciated!
> > 
> > Best wishes,
> > Juta
> > 
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From edzer.pebesma at uni-muenster.de  Mon Apr 25 14:44:49 2016
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 25 Apr 2016 14:44:49 +0200
Subject: [R-sig-Geo] spatialpoints: each dot represents 100 individuals?
In-Reply-To: <CE447E4A-177B-446C-8288-0A10D9CF9999@csic.es>
References: <CAHMizkMA8kKL8E5YBdtWJ7O_Mn1mEZUNw+h35X13Mvp4BDehtQ@mail.gmail.com>
	<CE447E4A-177B-446C-8288-0A10D9CF9999@csic.es>
Message-ID: <571E1141.5020005@uni-muenster.de>

Do these hexagons represent areas with equal area?

On 25/04/16 13:52, Santiago Beguer?a wrote:
> Hi Juta,
> 
> Do you need to represent the aggregated data as points necessarily? Otherwise, I have used the stat_hexbin representation from ggplot2 for that very purpose, see for instance:
> 
> http://santiago.begueria.es/wordpress/wp-content/uploads/2015/06/Figure_01.png
> 
> Cheers,
> 
> Stg
> 
>> El 25 abr 2016, a las 13:35, Juta Kawalerowicz <juta.kawalerowicz at nuffield.ox.ac.uk> escribi?:
>>
>> Hi,
>>
>> I have a dataset with couple of million of points (individuals) and
>> would like to do some mapping (I have the coordinates of each point)
>> but given the number of observation I think it may be usuful to plot
>> dots which represent 100 individuals (of a given group). Does anyone
>> know a good way to aggregate up spatialpoints? Any suggestions would
>> be much appreciated!
>>
>> Best wishes,
>> Juta
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics  (ifgi),  University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160425/613c50b0/attachment.bin>

From juta.kawalerowicz at nuffield.ox.ac.uk  Mon Apr 25 15:00:34 2016
From: juta.kawalerowicz at nuffield.ox.ac.uk (Juta Kawalerowicz)
Date: Mon, 25 Apr 2016 15:00:34 +0200
Subject: [R-sig-Geo] spatialpoints: each dot represents 100 individuals?
In-Reply-To: <74bd687f-a8d4-47a7-bfde-cde61381d798@HUB05.ad.oak.ox.ac.uk>
References: <CAHMizkMA8kKL8E5YBdtWJ7O_Mn1mEZUNw+h35X13Mvp4BDehtQ@mail.gmail.com>
	<CE447E4A-177B-446C-8288-0A10D9CF9999@csic.es>
	<74bd687f-a8d4-47a7-bfde-cde61381d798@HUB05.ad.oak.ox.ac.uk>
Message-ID: <CAHMizkNa=+aBdhEc+JJJag4nBjgAc8u7cuMC3riTP2Y8Ca6DkQ@mail.gmail.com>

Hi and thanks for all suggestions - not I have like 9 million
individuals (Swedish population registry data, it's magical) and
wanted to have a look at patterns of residential segregation. A while
back there was this cool map by
http://www.nytimes.com/interactive/2015/07/08/us/census-race-map.html
where each dot represented say 100 people (this actually depends on
how much you zoom in) and I was wondering about what would be the
conventional way of doing this thing.

Juta

On Mon, Apr 25, 2016 at 2:44 PM, Edzer Pebesma
<edzer.pebesma at uni-muenster.de> wrote:
> Do these hexagons represent areas with equal area?
>
> On 25/04/16 13:52, Santiago Beguer?a wrote:
>> Hi Juta,
>>
>> Do you need to represent the aggregated data as points necessarily? Otherwise, I have used the stat_hexbin representation from ggplot2 for that very purpose, see for instance:
>>
>> http://santiago.begueria.es/wordpress/wp-content/uploads/2015/06/Figure_01.png
>>
>> Cheers,
>>
>> Stg
>>
>>> El 25 abr 2016, a las 13:35, Juta Kawalerowicz <juta.kawalerowicz at nuffield.ox.ac.uk> escribi?:
>>>
>>> Hi,
>>>
>>> I have a dataset with couple of million of points (individuals) and
>>> would like to do some mapping (I have the coordinates of each point)
>>> but given the number of observation I think it may be usuful to plot
>>> dots which represent 100 individuals (of a given group). Does anyone
>>> know a good way to aggregate up spatialpoints? Any suggestions would
>>> be much appreciated!
>>>
>>> Best wishes,
>>> Juta
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Edzer Pebesma
> Institute for Geoinformatics  (ifgi),  University of M?nster
> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> Journal of Statistical Software:   http://www.jstatsoft.org/
> Computers & Geosciences:   http://elsevier.com/locate/cageo/
> Spatial Statistics Society http://www.spatialstatistics.info
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From santiago.begueria at csic.es  Mon Apr 25 15:00:45 2016
From: santiago.begueria at csic.es (=?utf-8?Q?Santiago_Beguer=C3=ADa?=)
Date: Mon, 25 Apr 2016 15:00:45 +0200
Subject: [R-sig-Geo] spatialpoints: each dot represents 100 individuals?
In-Reply-To: <571E1141.5020005@uni-muenster.de>
References: <CAHMizkMA8kKL8E5YBdtWJ7O_Mn1mEZUNw+h35X13Mvp4BDehtQ@mail.gmail.com>
	<CE447E4A-177B-446C-8288-0A10D9CF9999@csic.es>
	<571E1141.5020005@uni-muenster.de>
Message-ID: <209D3465-1C4C-4848-A3A7-93401EF6002C@csic.es>

Good question. Not on my example, I don?t think so. It will depend on the projection of your data, I guess.

Stg

> El 25 abr 2016, a las 14:44, Edzer Pebesma <edzer.pebesma at uni-muenster.de> escribi?:
> 
> Do these hexagons represent areas with equal area?
> 
> On 25/04/16 13:52, Santiago Beguer?a wrote:
>> Hi Juta,
>> 
>> Do you need to represent the aggregated data as points necessarily? Otherwise, I have used the stat_hexbin representation from ggplot2 for that very purpose, see for instance:
>> 
>> http://santiago.begueria.es/wordpress/wp-content/uploads/2015/06/Figure_01.png
>> 
>> Cheers,
>> 
>> Stg
>> 
>>> El 25 abr 2016, a las 13:35, Juta Kawalerowicz <juta.kawalerowicz at nuffield.ox.ac.uk> escribi?:
>>> 
>>> Hi,
>>> 
>>> I have a dataset with couple of million of points (individuals) and
>>> would like to do some mapping (I have the coordinates of each point)
>>> but given the number of observation I think it may be usuful to plot
>>> dots which represent 100 individuals (of a given group). Does anyone
>>> know a good way to aggregate up spatialpoints? Any suggestions would
>>> be much appreciated!
>>> 
>>> Best wishes,
>>> Juta
>>> 
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
> 
> -- 
> Edzer Pebesma
> Institute for Geoinformatics  (ifgi),  University of M?nster
> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> Journal of Statistical Software:   http://www.jstatsoft.org/
> Computers & Geosciences:   http://elsevier.com/locate/cageo/
> Spatial Statistics Society http://www.spatialstatistics.info
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From santiago.begueria at csic.es  Mon Apr 25 16:07:48 2016
From: santiago.begueria at csic.es (=?utf-8?Q?Santiago_Beguer=C3=ADa?=)
Date: Mon, 25 Apr 2016 16:07:48 +0200
Subject: [R-sig-Geo] spatialpoints: each dot represents 100 individuals?
In-Reply-To: <4a5bec7d.50852bf5.571e0d10.3994a@mailplus.pl>
References: <4a5bec7d.50852bf5.571e0d10.3994a@mailplus.pl>
Message-ID: <2E7DCEC3-8EFC-4EE6-B2CD-F1F16DED9ACB@csic.es>

Hi Kamil,

I just wrote a little post explaining how to do the bin hex map. It?s really easy.

http://santiago.begueria.es/2016/04/mapping-with-ggplot2-hexbin-maps/ <http://santiago.begueria.es/2016/04/mapping-with-ggplot2-hexbin-maps/>

Cheers,

Stg

> El 25 abr 2016, a las 14:26, Kamil Konowalik <konno_kazuma at mailplus.pl> escribi?:
> 
> Hi Juta,
> some time ago I came across that approach proposed by Dan Warren on his blog: 
> http://enmtools.blogspot.com/2015/10/handy-little-snippet-of-r-code-for.html
> Maybe this will be useful for you as well? 
> Santiago this figure looks quite nice. Do you have the R code to generate it? I found the description of that function but I will understand it better if I'll have the example and I didn't used ggplot2 for maps so far. 
> Best regards,
> Kamil
> 
> Dnia 25 kwietnia 2016 13:52 Santiago Beguer?a <santiago.begueria at csic.es> napisa?(a):
> 
>> Hi Juta,
>> 
>> Do you need to represent the aggregated data as points necessarily? Otherwise, I have used the stat_hexbin representation from ggplot2 for that very purpose, see for instance:
>> 
>> http://santiago.begueria.es/wordpress/wp-content/uploads/2015/06/Figure_01.png
>> 
>> Cheers,
>> 
>> Stg
>> 
>>> El 25 abr 2016, a las 13:35, Juta Kawalerowicz <juta.kawalerowicz at nuffield.ox.ac.uk> escribi?:
>>> 
>>> Hi,
>>> 
>>> I have a dataset with couple of million of points (individuals) and
>>> would like to do some mapping (I have the coordinates of each point)
>>> but given the number of observation I think it may be usuful to plot
>>> dots which represent 100 individuals (of a given group). Does anyone
>>> know a good way to aggregate up spatialpoints? Any suggestions would
>>> be much appreciated!
>>> 
>>> Best wishes,
>>> Juta
>>> 
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


	[[alternative HTML version deleted]]


From dexter.locke at gmail.com  Mon Apr 25 18:28:51 2016
From: dexter.locke at gmail.com (Dexter Locke)
Date: Mon, 25 Apr 2016 12:28:51 -0400
Subject: [R-sig-Geo] test spatial autocorrelation of level 2 residuals in
	lme()
Message-ID: <CAA=SVwEQz2Cfy_UGVkyQujsG16LZPxLPWyw2joJN1+DpYcw9Hg@mail.gmail.com>

Apologies for cross-posting, its unclear if this is a spatial or a mixed
models question. Maybe its both?

I am interested in extracting the residuals from level 2 of a mixed model
(created using lme()), building a spatial weights matrix, and then testing
for spatial autocorrelation using Moran's I.

While I have found methods of incorporating spatial effects into a mixed
model using corStruct, I am interested in first evaluating *if* that is an
appropriate model for a given dataset by examining the level 2 residuals'
spatial patterning - or lack thereof.

Which slot contains the residuals for level 2 and how are they ordered?

Best,
Dexter

	[[alternative HTML version deleted]]


From afischbach at usgs.gov  Mon Apr 25 22:06:59 2016
From: afischbach at usgs.gov (Fischbach, Anthony)
Date: Mon, 25 Apr 2016 12:06:59 -0800
Subject: [R-sig-Geo] Fwd: Fwd: coercing marmap bathy object to raster
	spanning the antimeridian
In-Reply-To: <CA+ZRYj-=jSVfy3eJH9hmaC6Y2mf73XTFn6zqQ+6xyZyQt1QM1A@mail.gmail.com>
References: <CA+ZRYj8wi1tb9Hq0YzOQ=amhdqyijh+G4HsaYfGCx3Vomt5QsQ@mail.gmail.com>
	<4C74E6A9-6C49-4909-8A8F-BA13A51CA2D1@gmail.com>
	<etPan.571cc010.1bd9f3e7.10a7e@hepatus.local>
	<CA+ZRYj-=jSVfy3eJH9hmaC6Y2mf73XTFn6zqQ+6xyZyQt1QM1A@mail.gmail.com>
Message-ID: <CA+ZRYj8Ag2Cc+MrXJHYiYdTjK_c2WHEv5SZ-t_hndWXpg8WnXA@mail.gmail.com>

Thanks to guidance from Benoit Simon-Bouhet, I see that by setting the
projectRaster flag over to TRUE

   aleu.r.geo<-marmap::as.raster(aleu, over=TRUE)

and using a projection with the longitude of origin set to be 190;  I get
the desired raster that extends across the antimeridian even when projected
to the azimuthal equidistant projection.

   prj.StudyArea <- CRS("+proj=aeqd +lat_0=55 +lon_0=*190"*)
 #Azimuthal Equidistant -170, 55

	[[alternative HTML version deleted]]


From adrian.baddeley at curtin.edu.au  Tue Apr 26 04:36:43 2016
From: adrian.baddeley at curtin.edu.au (Adrian Baddeley)
Date: Tue, 26 Apr 2016 02:36:43 +0000
Subject: [R-sig-Geo] [R-sig-geo] Data sets for teaching spatial analysis
	in R
Message-ID: <D344F3FA.1AFC%Adrian.Baddeley@curtin.edu.au>


Andy Bunn <Andy.Bunn at wwu.edu> writes:

> I'd love to hear about data sets that some of you might use to teach
>spatial in R. 

For spatial point patterns, the ?spatstat' package contains over 50
datasets, with documentation and examples. They are also presented and
discussed in the ?spatstat book? <www.spatstat.org/book/
<http://www.spatstat.org/book/>>

Adrian Baddeley


From Virgilio.Gomez at uclm.es  Tue Apr 26 12:03:21 2016
From: Virgilio.Gomez at uclm.es (VIRGILIO GOMEZ RUBIO)
Date: Tue, 26 Apr 2016 10:03:21 +0000
Subject: [R-sig-Geo] sarprobit question
In-Reply-To: <CAAcGTKA8hrLqXhLBQrVuiEFY9-4J33f-Xv==Kw1oKqV1BUWY1Q@mail.gmail.com>
References: <CAAcGTKBf1y_5WhCbNR28CHNckyrHsaDNNb6eX1tQgx3Jntak0w@mail.gmail.com>
	<903D7FCB-3C1E-4F39-A0FD-069072AB7D78@uclm.es>
	<CAAcGTKA8hrLqXhLBQrVuiEFY9-4J33f-Xv==Kw1oKqV1BUWY1Q@mail.gmail.com>
Message-ID: <65714420-F2C3-47A4-810E-136A7F5FDE12@uclm.es>

Dear Jorge,

> 
> I will take a look at the commands to understand why is creating this W=103x103 matrix. Do you have some suggestions?
> 

You probably have 103 points instead of 102 for some reason? That is what I would check first.

Best,

Virgilio


From jcarcamo03 at gmail.com  Tue Apr 26 12:17:16 2016
From: jcarcamo03 at gmail.com (=?UTF-8?Q?Jorge_C=C3=A1rcamo?=)
Date: Tue, 26 Apr 2016 12:17:16 +0200
Subject: [R-sig-Geo] sarprobit question
In-Reply-To: <65714420-F2C3-47A4-810E-136A7F5FDE12@uclm.es>
References: <CAAcGTKBf1y_5WhCbNR28CHNckyrHsaDNNb6eX1tQgx3Jntak0w@mail.gmail.com>
	<903D7FCB-3C1E-4F39-A0FD-069072AB7D78@uclm.es>
	<CAAcGTKA8hrLqXhLBQrVuiEFY9-4J33f-Xv==Kw1oKqV1BUWY1Q@mail.gmail.com>
	<65714420-F2C3-47A4-810E-136A7F5FDE12@uclm.es>
Message-ID: <CAAcGTKDvORV_qwsqrJvk01_mioktpzBGoqS6MwUD3aDifHaUKQ@mail.gmail.com>

Dear Virigilio,

Many thanks for your suggestion. I also think that my problem is within my
data and not with my commands. I used the same commands with the columbus
dataset and it run smoothly. The only difference is that columbus dataset
are polygons and I am working with point dataset. The funny thing is that a
friend of mine give me another point dataset, when I tried to run the
commands it gives me the same error message, even if I drop one column and
one row.

I will prepare a subset of this dataset and the script to reproduce the
commands. However, I am hoping to do that this week, since I have to
prepare and give a presentation tomorrow.

Once again, many thanks for your kind help and attention.

Jorge

*Ing. Jorge Alfredo C?rcamo, M. Sc., Ph. D. (c)*


On Tue, Apr 26, 2016 at 12:03 PM, VIRGILIO GOMEZ RUBIO <
Virgilio.Gomez at uclm.es> wrote:

> Dear Jorge,
>
> >
> > I will take a look at the commands to understand why is creating this
> W=103x103 matrix. Do you have some suggestions?
> >
>
> You probably have 103 points instead of 102 for some reason? That is what
> I would check first.
>
> Best,
>
> Virgilio
>
>

	[[alternative HTML version deleted]]


From vinhdizzo at gmail.com  Tue Apr 26 20:18:26 2016
From: vinhdizzo at gmail.com (Vinh Nguyen)
Date: Tue, 26 Apr 2016 11:18:26 -0700
Subject: [R-sig-Geo] best practice for reading large shapefiles?
Message-ID: <CA+2DmwgSHcNikbSENoUa2dgHD_sqSAGu7k=N_4EBmyB9YM8_cQ@mail.gmail.com>

Hi,

I have a very large shapefile that I would like to read into R
(dbf=5.6gb and shp=2.3gb).

For reference, I downloaded the 30 shapefiles of the [Public Land
Survey System](http://www.geocommunicator.gov/GeoComm/lsis_home/home/)
and combined them into a single national file via gdal (ogr2ogr) as
described [here](http://www.northrivergeographic.com/ogr2ogr-merge-shapefiles);
I originally attempted to combine the files in R as described
[here](https://stat.ethz.ch/pipermail/r-sig-geo/2011-May/011814.html),
but ran out of memory about 80% in, but luckily discovered ogr2ogr.

I'm reading in the combined file in R via readOGR, and it's been over
an hour and R appears to hang.  When I check the task manager, the R
session currently consumes <10% CPU and 245MB.  Not sure if any
productive activity is going on, so I'm just waiting it out.
[This](http://r-sig-geo.2731867.n2.nabble.com/Long-time-to-load-shapefiles-td7584869.html)
thread describes that readOGR can be slow for large shapefiles, and
suggested that the SpatialDataFrame be saved in an R format.  My
problem is getting the entire shapefile read in the first place before
I could save it as an R object.

Does anyone have any suggestions for reading this large shapefile into
R?  Thank you for your help.

-- Vinh


From vinhdizzo at gmail.com  Tue Apr 26 21:11:17 2016
From: vinhdizzo at gmail.com (Vinh Nguyen)
Date: Tue, 26 Apr 2016 12:11:17 -0700
Subject: [R-sig-Geo] best practice for reading large shapefiles?
In-Reply-To: <CA+2DmwgSHcNikbSENoUa2dgHD_sqSAGu7k=N_4EBmyB9YM8_cQ@mail.gmail.com>
References: <CA+2DmwgSHcNikbSENoUa2dgHD_sqSAGu7k=N_4EBmyB9YM8_cQ@mail.gmail.com>
Message-ID: <CA+2DmwjSqZLkhFTf8rvOSjd0sY1wMPeDXMiZrT3VuAjniuQHRA@mail.gmail.com>

Would loading the shapefile into postgresql first and then use readOGR
to read from postgres be a recommended approach?  That is, would the
bottleneck still occur?  Thank you.

-- Vinh


On Tue, Apr 26, 2016 at 11:18 AM, Vinh Nguyen <vinhdizzo at gmail.com> wrote:
> Hi,
>
> I have a very large shapefile that I would like to read into R
> (dbf=5.6gb and shp=2.3gb).
>
> For reference, I downloaded the 30 shapefiles of the [Public Land
> Survey System](http://www.geocommunicator.gov/GeoComm/lsis_home/home/)
> and combined them into a single national file via gdal (ogr2ogr) as
> described [here](http://www.northrivergeographic.com/ogr2ogr-merge-shapefiles);
> I originally attempted to combine the files in R as described
> [here](https://stat.ethz.ch/pipermail/r-sig-geo/2011-May/011814.html),
> but ran out of memory about 80% in, but luckily discovered ogr2ogr.
>
> I'm reading in the combined file in R via readOGR, and it's been over
> an hour and R appears to hang.  When I check the task manager, the R
> session currently consumes <10% CPU and 245MB.  Not sure if any
> productive activity is going on, so I'm just waiting it out.
> [This](http://r-sig-geo.2731867.n2.nabble.com/Long-time-to-load-shapefiles-td7584869.html)
> thread describes that readOGR can be slow for large shapefiles, and
> suggested that the SpatialDataFrame be saved in an R format.  My
> problem is getting the entire shapefile read in the first place before
> I could save it as an R object.
>
> Does anyone have any suggestions for reading this large shapefile into
> R?  Thank you for your help.
>
> -- Vinh


From Roger.Bivand at nhh.no  Tue Apr 26 22:12:16 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 26 Apr 2016 22:12:16 +0200
Subject: [R-sig-Geo] best practice for reading large shapefiles?
In-Reply-To: <CA+2DmwjSqZLkhFTf8rvOSjd0sY1wMPeDXMiZrT3VuAjniuQHRA@mail.gmail.com>
References: <CA+2DmwgSHcNikbSENoUa2dgHD_sqSAGu7k=N_4EBmyB9YM8_cQ@mail.gmail.com>
	<CA+2DmwjSqZLkhFTf8rvOSjd0sY1wMPeDXMiZrT3VuAjniuQHRA@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1604262204390.25393@reclus.nhh.no>

On Tue, 26 Apr 2016, Vinh Nguyen wrote:

> Would loading the shapefile into postgresql first and then use readOGR
> to read from postgres be a recommended approach?  That is, would the
> bottleneck still occur?  Thank you.

Most likely, as both use the respective OGR drivers. With data this size, 
you'll need a competent platform (probably Linux, say 128GB RAM) as 
everything is in memory. I find it hard to grasp what the point of doing 
this might be - visualization won't work as none of the considerable 
detail certainly in these files will be visible. Can you put the lot into 
an SQLite file and access the attributes as SQL queries? I don't see the 
analysis or statistics here.

Roger

>
> -- Vinh
>
>
> On Tue, Apr 26, 2016 at 11:18 AM, Vinh Nguyen <vinhdizzo at gmail.com> wrote:
>> Hi,
>>
>> I have a very large shapefile that I would like to read into R
>> (dbf=5.6gb and shp=2.3gb).
>>
>> For reference, I downloaded the 30 shapefiles of the [Public Land
>> Survey System](http://www.geocommunicator.gov/GeoComm/lsis_home/home/)
>> and combined them into a single national file via gdal (ogr2ogr) as
>> described [here](http://www.northrivergeographic.com/ogr2ogr-merge-shapefiles);
>> I originally attempted to combine the files in R as described
>> [here](https://stat.ethz.ch/pipermail/r-sig-geo/2011-May/011814.html),
>> but ran out of memory about 80% in, but luckily discovered ogr2ogr.
>>
>> I'm reading in the combined file in R via readOGR, and it's been over
>> an hour and R appears to hang.  When I check the task manager, the R
>> session currently consumes <10% CPU and 245MB.  Not sure if any
>> productive activity is going on, so I'm just waiting it out.
>> [This](http://r-sig-geo.2731867.n2.nabble.com/Long-time-to-load-shapefiles-td7584869.html)
>> thread describes that readOGR can be slow for large shapefiles, and
>> suggested that the SpatialDataFrame be saved in an R format.  My
>> problem is getting the entire shapefile read in the first place before
>> I could save it as an R object.
>>
>> Does anyone have any suggestions for reading this large shapefile into
>> R?  Thank you for your help.
>>
>> -- Vinh
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


From vinhdizzo at gmail.com  Tue Apr 26 22:33:35 2016
From: vinhdizzo at gmail.com (Vinh Nguyen)
Date: Tue, 26 Apr 2016 13:33:35 -0700
Subject: [R-sig-Geo] best practice for reading large shapefiles?
In-Reply-To: <alpine.LFD.2.20.1604262204390.25393@reclus.nhh.no>
References: <CA+2DmwgSHcNikbSENoUa2dgHD_sqSAGu7k=N_4EBmyB9YM8_cQ@mail.gmail.com>
	<CA+2DmwjSqZLkhFTf8rvOSjd0sY1wMPeDXMiZrT3VuAjniuQHRA@mail.gmail.com>
	<alpine.LFD.2.20.1604262204390.25393@reclus.nhh.no>
Message-ID: <CA+2DmwjEst4th-5SQQHXQ0ok1NaEy4ZQ7xz91Z2xVHva0TeY1A@mail.gmail.com>

On Tue, Apr 26, 2016 at 1:12 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Tue, 26 Apr 2016, Vinh Nguyen wrote:
>
>> Would loading the shapefile into postgresql first and then use readOGR
>> to read from postgres be a recommended approach?  That is, would the
>> bottleneck still occur?  Thank you.
>
>
> Most likely, as both use the respective OGR drivers. With data this size,
> you'll need a competent platform (probably Linux, say 128GB RAM) as
> everything is in memory. I find it hard to grasp what the point of doing
> this might be - visualization won't work as none of the considerable detail
> certainly in these files will be visible. Can you put the lot into an SQLite
> file and access the attributes as SQL queries? I don't see the analysis or
> statistics here.
>

- I can't tell from your response whether you are recommending PostGIS
is a recommended approach or not.  Could you clarify?

- I am working on a Windows server with 64gb ram, so not too weak,
especially for some files that are a few gb in size.  Again, not sure
if the job just halted or it's still running, but just rather slow.
I've killed it for now as the memory usage still has not grown after a
few hours.

- Yes, the shapes are quite granular and many in quantity.  The use
case was not to visualize them all at once.  Wanted a master file so
that when I get a data set of interest, I could intersect the two and
then subset the areas of interest (eg, within a state or county).
Then visualize/analyze from there.  The master shapefile was meant to
make it easy (reading in one file) as opposed to deciding which
shapefile to read in depending on the project.

- I just looked back at the 30 PLSS zip files, and they provide shapes
for 3 levels of granularity.  I went with the smallest.  I just
realized that the mid-size one would be sufficient for now, which
results in dbf=138mb and shp=501mb.  Attempting to read this in now (~
30 minutes), which I assume will read in fine after some time.  Will
respond to this thread if this is not the case.

Thanks for responding Roger.

-- Vinh


From reudenbach at uni-marburg.de  Wed Apr 27 00:24:38 2016
From: reudenbach at uni-marburg.de (Chris Reudenbach)
Date: Wed, 27 Apr 2016 00:24:38 +0200
Subject: [R-sig-Geo] best practice for reading large shapefiles?
In-Reply-To: <CA+2DmwjEst4th-5SQQHXQ0ok1NaEy4ZQ7xz91Z2xVHva0TeY1A@mail.gmail.com>
References: <CA+2DmwgSHcNikbSENoUa2dgHD_sqSAGu7k=N_4EBmyB9YM8_cQ@mail.gmail.com>
	<CA+2DmwjSqZLkhFTf8rvOSjd0sY1wMPeDXMiZrT3VuAjniuQHRA@mail.gmail.com>
	<alpine.LFD.2.20.1604262204390.25393@reclus.nhh.no>
	<CA+2DmwjEst4th-5SQQHXQ0ok1NaEy4ZQ7xz91Z2xVHva0TeY1A@mail.gmail.com>
Message-ID: <571FEAA6.9070202@uni-marburg.de>

Vinh

Even if it might be in this list OT, IMHO R is not the best tool for 
dealing with this amount of vector data. Actually I agree completely 
with Roger's remarks and corresponding to the "competent platform" you 
also may think about using software for big data...

As Roger already has clarified: The recommendation what might be best 
depends highly  on your questions and issues or on the type of analysis 
you need to run and cannot be answered straightforward.

I think Edzer can clarify up to which size sp object are still "usable", 
following my experience  i would guess something like 500K polygons 1M 
lines and up to 5M points but it is highly dependent on the number of 
attributes. So you are far beyond this.


If you want to deal with this amount of spatial vector data using R, it 
is highly reasonable to have a look at one of the mature GIS packages 
like GRASS or QGIS. You can use them via their APIs.
Nevertheless you easily can put it in postgres/postgis and perform all 
operations/analysis using the spatial capabilities and build in 
functions of postgis if you are an experienced PostGis user.

cheers
Chris


Am 26.04.2016 um 22:33 schrieb Vinh Nguyen:
> On Tue, Apr 26, 2016 at 1:12 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> On Tue, 26 Apr 2016, Vinh Nguyen wrote:
>>
>>> Would loading the shapefile into postgresql first and then use readOGR
>>> to read from postgres be a recommended approach?  That is, would the
>>> bottleneck still occur?  Thank you.
>>
>> Most likely, as both use the respective OGR drivers. With data this size,
>> you'll need a competent platform (probably Linux, say 128GB RAM) as
>> everything is in memory. I find it hard to grasp what the point of doing
>> this might be - visualization won't work as none of the considerable detail
>> certainly in these files will be visible. Can you put the lot into an SQLite
>> file and access the attributes as SQL queries? I don't see the analysis or
>> statistics here.
>>
> - I can't tell from your response whether you are recommending PostGIS
> is a recommended approach or not.  Could you clarify?
>
> - I am working on a Windows server with 64gb ram, so not too weak,
> especially for some files that are a few gb in size.  Again, not sure
> if the job just halted or it's still running, but just rather slow.
> I've killed it for now as the memory usage still has not grown after a
> few hours.
>
> - Yes, the shapes are quite granular and many in quantity.  The use
> case was not to visualize them all at once.  Wanted a master file so
> that when I get a data set of interest, I could intersect the two and
> then subset the areas of interest (eg, within a state or county).
> Then visualize/analyze from there.  The master shapefile was meant to
> make it easy (reading in one file) as opposed to deciding which
> shapefile to read in depending on the project.
>
> - I just looked back at the 30 PLSS zip files, and they provide shapes
> for 3 levels of granularity.  I went with the smallest.  I just
> realized that the mid-size one would be sufficient for now, which
> results in dbf=138mb and shp=501mb.  Attempting to read this in now (~
> 30 minutes), which I assume will read in fine after some time.  Will
> respond to this thread if this is not the case.
>
> Thanks for responding Roger.
>
> -- Vinh
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


-- 
Dr Christoph Reudenbach, Philipps-University of Marburg, Faculty of 
Geography, GIS and Environmental Modeling, Deutschhausstr. 10, D-35032 
Marburg, fon: ++49.(0)6421.2824296, fax: ++49.(0)6421.2828950, web: 
gis-ma.org, giswerk.org, moc.environmentalinformatics-marburg.de


From tech_dev at wildintellect.com  Wed Apr 27 03:16:56 2016
From: tech_dev at wildintellect.com (Alex Mandel)
Date: Tue, 26 Apr 2016 18:16:56 -0700
Subject: [R-sig-Geo] best practice for reading large shapefiles?
In-Reply-To: <571FEAA6.9070202@uni-marburg.de>
References: <CA+2DmwgSHcNikbSENoUa2dgHD_sqSAGu7k=N_4EBmyB9YM8_cQ@mail.gmail.com>
	<CA+2DmwjSqZLkhFTf8rvOSjd0sY1wMPeDXMiZrT3VuAjniuQHRA@mail.gmail.com>
	<alpine.LFD.2.20.1604262204390.25393@reclus.nhh.no>
	<CA+2DmwjEst4th-5SQQHXQ0ok1NaEy4ZQ7xz91Z2xVHva0TeY1A@mail.gmail.com>
	<571FEAA6.9070202@uni-marburg.de>
Message-ID: <57201308.4090405@wildintellect.com>

So the trick I use is to load vector data into PostGIS or Spatialite.
Then do basic spatial filtering with queries in those DB (SQL). Once
I've subset and manipulated what I want, either create a new Table or
View with the results. Then read those results in R.

The bottleneck you have is likely the reading of everything into memory
in R, which usually takes more memory than the original file size. So
changing sources won't help, only subsetting prior to loading will help.

Enjoy,
Alex

On 04/26/2016 03:24 PM, Chris Reudenbach wrote:
> Vinh
> 
> Even if it might be in this list OT, IMHO R is not the best tool for
> dealing with this amount of vector data. Actually I agree completely
> with Roger's remarks and corresponding to the "competent platform" you
> also may think about using software for big data...
> 
> As Roger already has clarified: The recommendation what might be best
> depends highly  on your questions and issues or on the type of analysis
> you need to run and cannot be answered straightforward.
> 
> I think Edzer can clarify up to which size sp object are still "usable",
> following my experience  i would guess something like 500K polygons 1M
> lines and up to 5M points but it is highly dependent on the number of
> attributes. So you are far beyond this.
> 
> 
> If you want to deal with this amount of spatial vector data using R, it
> is highly reasonable to have a look at one of the mature GIS packages
> like GRASS or QGIS. You can use them via their APIs.
> Nevertheless you easily can put it in postgres/postgis and perform all
> operations/analysis using the spatial capabilities and build in
> functions of postgis if you are an experienced PostGis user.
> 
> cheers
> Chris
> 
> 
> Am 26.04.2016 um 22:33 schrieb Vinh Nguyen:
>> On Tue, Apr 26, 2016 at 1:12 PM, Roger Bivand <Roger.Bivand at nhh.no>
>> wrote:
>>> On Tue, 26 Apr 2016, Vinh Nguyen wrote:
>>>
>>>> Would loading the shapefile into postgresql first and then use readOGR
>>>> to read from postgres be a recommended approach?  That is, would the
>>>> bottleneck still occur?  Thank you.
>>>
>>> Most likely, as both use the respective OGR drivers. With data this
>>> size,
>>> you'll need a competent platform (probably Linux, say 128GB RAM) as
>>> everything is in memory. I find it hard to grasp what the point of doing
>>> this might be - visualization won't work as none of the considerable
>>> detail
>>> certainly in these files will be visible. Can you put the lot into an
>>> SQLite
>>> file and access the attributes as SQL queries? I don't see the
>>> analysis or
>>> statistics here.
>>>
>> - I can't tell from your response whether you are recommending PostGIS
>> is a recommended approach or not.  Could you clarify?
>>
>> - I am working on a Windows server with 64gb ram, so not too weak,
>> especially for some files that are a few gb in size.  Again, not sure
>> if the job just halted or it's still running, but just rather slow.
>> I've killed it for now as the memory usage still has not grown after a
>> few hours.
>>
>> - Yes, the shapes are quite granular and many in quantity.  The use
>> case was not to visualize them all at once.  Wanted a master file so
>> that when I get a data set of interest, I could intersect the two and
>> then subset the areas of interest (eg, within a state or county).
>> Then visualize/analyze from there.  The master shapefile was meant to
>> make it easy (reading in one file) as opposed to deciding which
>> shapefile to read in depending on the project.
>>
>> - I just looked back at the 30 PLSS zip files, and they provide shapes
>> for 3 levels of granularity.  I went with the smallest.  I just
>> realized that the mid-size one would be sufficient for now, which
>> results in dbf=138mb and shp=501mb.  Attempting to read this in now (~
>> 30 minutes), which I assume will read in fine after some time.  Will
>> respond to this thread if this is not the case.
>>
>> Thanks for responding Roger.
>>
>> -- Vinh
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> 
>


From edzer.pebesma at uni-muenster.de  Wed Apr 27 08:18:26 2016
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 27 Apr 2016 08:18:26 +0200
Subject: [R-sig-Geo] best practice for reading large shapefiles?
In-Reply-To: <CA+2DmwjEst4th-5SQQHXQ0ok1NaEy4ZQ7xz91Z2xVHva0TeY1A@mail.gmail.com>
References: <CA+2DmwgSHcNikbSENoUa2dgHD_sqSAGu7k=N_4EBmyB9YM8_cQ@mail.gmail.com>
	<CA+2DmwjSqZLkhFTf8rvOSjd0sY1wMPeDXMiZrT3VuAjniuQHRA@mail.gmail.com>
	<alpine.LFD.2.20.1604262204390.25393@reclus.nhh.no>
	<CA+2DmwjEst4th-5SQQHXQ0ok1NaEy4ZQ7xz91Z2xVHva0TeY1A@mail.gmail.com>
Message-ID: <572059B2.6050105@uni-muenster.de>



On 26/04/16 22:33, Vinh Nguyen wrote:
> On Tue, Apr 26, 2016 at 1:12 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> On Tue, 26 Apr 2016, Vinh Nguyen wrote:
>>
>>> Would loading the shapefile into postgresql first and then use readOGR
>>> to read from postgres be a recommended approach?  That is, would the
>>> bottleneck still occur?  Thank you.
>>
>>
>> Most likely, as both use the respective OGR drivers. With data this size,
>> you'll need a competent platform (probably Linux, say 128GB RAM) as
>> everything is in memory. I find it hard to grasp what the point of doing
>> this might be - visualization won't work as none of the considerable detail
>> certainly in these files will be visible. Can you put the lot into an SQLite
>> file and access the attributes as SQL queries? I don't see the analysis or
>> statistics here.
>>
> 
> - I can't tell from your response whether you are recommending PostGIS
> is a recommended approach or not.  Could you clarify?

Roger said the bottleneck would most likely still occur, but couldn't
make much of a recommendation because you had not revealed the purpose
of reading this data in R.

> 
> - I am working on a Windows server with 64gb ram, so not too weak,
> especially for some files that are a few gb in size.  Again, not sure
> if the job just halted or it's still running, but just rather slow.
> I've killed it for now as the memory usage still has not grown after a
> few hours.

Messages that certain things do not work are often helpful, leading to
improvement in the software. With your report, however, we can't do
really much.

> 
> - Yes, the shapes are quite granular and many in quantity.  The use
> case was not to visualize them all at once.  Wanted a master file so
> that when I get a data set of interest, I could intersect the two and
> then subset the areas of interest (eg, within a state or county).
> Then visualize/analyze from there.  The master shapefile was meant to
> make it easy (reading in one file) as opposed to deciding which
> shapefile to read in depending on the project.

Using PostGIS for this use case may make sense, since PostGIS creates
and stores spatial indexes with its geometry data, and does everything
in database, rather than in memory. In R, you'd probably do
intersections with rgeos::gIntersects, which creates a spatial index on
the fly but doesn't store this index. Only experimentation can tell you
the magnitude of this difference.

> 
> - I just looked back at the 30 PLSS zip files, and they provide shapes
> for 3 levels of granularity.  I went with the smallest.  I just
> realized that the mid-size one would be sufficient for now, which
> results in dbf=138mb and shp=501mb.  Attempting to read this in now (~
> 30 minutes), which I assume will read in fine after some time.  Will
> respond to this thread if this is not the case.
> 
(see my 2nd comment)

Best regards,
-- 
Edzer Pebesma
Institute for Geoinformatics  (ifgi),  University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160427/5ef0449d/attachment.bin>

From kent3737 at gmail.com  Wed Apr 27 12:53:52 2016
From: kent3737 at gmail.com (Kent Johnson)
Date: Wed, 27 Apr 2016 06:53:52 -0400
Subject: [R-sig-Geo] spatialpoints: each dot represents 100 individuals?
Message-ID: <CAPP0wyjnOtSGJ-AzKbRBnNA4R_n_JPt3cqFBvOA6o=8DeJ+iMQ@mail.gmail.com>

>
> From: Juta Kawalerowicz <juta.kawalerowicz at nuffield.ox.ac.uk>
> To: Edzer Pebesma <edzer.pebesma at uni-muenster.de>
> Hi and thanks for all suggestions - not I have like 9 million
> individuals (Swedish population registry data, it's magical) and
> wanted to have a look at patterns of residential segregation. A while
> back there was this cool map by
> http://www.nytimes.com/interactive/2015/07/08/us/census-race-map.html
> where each dot represented say 100 people (this actually depends on
> how much you zoom in) and I was wondering about what would be the
> conventional way of doing this thing.
>
> Juta
>

I think the conventional way to do this is to randomly distribute the dots
across small regions, e.g. in the US to draw dots in each census block. An
example with a detailed description of the method is here:
http://www.coopercenter.org/demographics/Racial-Dot-Map

Kent

	[[alternative HTML version deleted]]


From rubenfcasal at gmail.com  Wed Apr 27 23:13:42 2016
From: rubenfcasal at gmail.com (rubenfcasal)
Date: Wed, 27 Apr 2016 23:13:42 +0200
Subject: [R-sig-Geo] spatialpoints: each dot represents 100 individuals?
In-Reply-To: <CAHMizkMA8kKL8E5YBdtWJ7O_Mn1mEZUNw+h35X13Mvp4BDehtQ@mail.gmail.com>
References: <CAHMizkMA8kKL8E5YBdtWJ7O_Mn1mEZUNw+h35X13Mvp4BDehtQ@mail.gmail.com>
Message-ID: <57212B86.9090205@gmail.com>

Alternatively, you might also consider data binning (implemented in 
several packages: KernSmooth, ks, sm, npsp ,...). This technique is 
commonly used in nonparametric statistics to reduce the computational 
time (see e.g. Wand, M. P. (1994), Fast Computation of Multivariate 
Kernel Estimators, Journal of Computational and Graphical Statistics, 3, 
433-445).

For instance, using the npsp package (maintained by me...), you could do 
something like this:

library(npsp)

bin <- binning(earthquakes[, c("lon", "lat")], nbin = c(50,50))

# ?bin$binw? will contain the binning weights (aggregations) at 
locations ?coords(bin)?

simage(bin)

Additionally, you could estimate (nonparametrically) the spatial density:

h <- h.cv(bin, ncv = 2)$h

den <- np.den(bin, h = h)

plot(den, log = FALSE, main = 'Estimated density')

Best regards,

Ruben.


El 25/04/2016 a las 13:35, Juta Kawalerowicz escribi?:
> Hi,
>
> I have a dataset with couple of million of points (individuals) and
> would like to do some mapping (I have the coordinates of each point)
> but given the number of observation I think it may be usuful to plot
> dots which represent 100 individuals (of a given group). Does anyone
> know a good way to aggregate up spatialpoints? Any suggestions would
> be much appreciated!
>
> Best wishes,
> Juta
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


	[[alternative HTML version deleted]]


From isaquedanielre at hotmail.com  Thu Apr 28 18:34:48 2016
From: isaquedanielre at hotmail.com (Isaque Daniel)
Date: Thu, 28 Apr 2016 16:34:48 +0000
Subject: [R-sig-Geo] How can I apply function using stackApply or Calc,
 and save the results as raster object in R?
Message-ID: <COL127-W29FCDC35193F4A7EF67DF9C9650@phx.gbl>

Hi everyone, 
I have been working in a list of function to process MODIS vegetation
 index timeseries and return crop cycle paramenters. It's for PhD thesis
 and I'll process all South America, so I need to use all forms to 
reduce the time to process.




I found the rasterEngine from the spatial.tools package to use 
paralell processing to speed up the process. but, before that I prepare 
some of the functions to compute by pixel over the raster stack my 
variables measures. 




I develop the functions which will produce 7 different outputs, I 
tried tu use my function "CropAnalysis" to compute by each pixel, in the
 code in the post I try to save a raster brick with 2 layers (each one 
with one of variables produced by the function "CropAnalysis"). 




My code dont save the results in two raster layers. 





Attached are the data (one small portion) and the code, any idea? 





My data:
Modis stack https://www.dropbox.com/s/uesgzv125e3v3e6/stackimagesNDVI.tif?dl=0

# My code
library(stringr)
library(rgdal)
library(raster)


# loading the data 
limit <- 3000 # minimum value betweem maximum and minimum to be crop
ndates <- 2 # time difference between maximum and minimum to be crop
min_diff <- 3000 # threshold for the maximum value (this is the minimum value to test)
min_val <- 1500 # minimum value for the minimum pixel values be trustfull (threshold)
max_phase_duration <- 7  # the maximum interval over the maximum value between the two adjacent minimum values
number_of_crop_cycles <- 3  # definition of number of crop cycles per croo year

imgStacked <- brick('stackimagesNDVI.tif')

CropAnalysis <- function (pixel, ...){
   pixel <- as.vector(pixel)

   # test : if is No data the return is 
   if (is.na(pixel)) {-1}
     else{

     # delta (valor i - valor i+1)
     delta <- pixel[2:length(pixel)] - pixel[1:(length(pixel)-1)]

     # maximum and minimum point
     ptma<-NULL
     ptmi <- NULL

     # verifing why the first time point is not signed???? T or F
     if (pixel[2] > pixel [1]) {ptmi <- 1}
     if (pixel[2] < pixel [1]) {ptma <- 1}

     # computing the slope of the line change from positive to negative 
     for (j in 1:(length(delta)-1))
     {
     if (delta[j]>0 && delta[j+1]<0 )
     {
      ptma<- c(ptma,j+1)   # point of maximum
     }

     if (delta[j]<0 && delta[j+1]>0)
    {
     ptmi<- c(ptmi,j+1)   # point of minimum
    }
   }
   # verifing why the first time point is not signed???? T or F
   if (pixel[(length(pixel))] > pixel [(length(pixel)-1)])  {ptma <- c(ptma,length(pixel))} 
   if (pixel[(length(pixel))] < pixel [(length(pixel)-1)])  {ptmi <- c(ptmi,length(pixel))}

   # variables for save the measures for crop cycle
   max_points <- as.numeric(rep(0, number_of_crop_cycles))  # number of maximum peaks after test if is a crop pixel
   length_max_period <- as.numeric(rep(NA, number_of_crop_cycles))  # variation of number of dates between the minimum points around of maximum point 
   max_valids <- NULL

   # agricultural detection 
   for (j in 1:length(ptma))
   {
    index <- ptma[j]
    # logical tests to verify the presence of crop
    # from each maximum value, check if:
    # 1st - the maximum position had the before minimum value far or equal than "ndatas" variable
    # 2nd - the maximum position had the after minimum value far or equal than ndatas variable
    # 3th - the value of maximum is equal or great than "val_min" variable (threshold)
    # 4th - the difference between the maximum value and the two minimum values (in the "ndates") distance is equal or bigher than "limit" variable (threshold value of increase Vegetation index)
    # 5th - the minimum values bigher tha minimum limit variable 
    # 6th - check to exclude sugarcane from anual crop cicle 
    if(!is.na(((ptmi[ptmi < index][length(ptmi[ptmi < index])]+ndates) <= index  && # 1st test
      index <= (ptmi[ptmi > index][1]-ndates)) && # 2sd test
     (pixel[index] >= limit) && # 3th test
     ((pixel[index]-pixel[ptmi[ptmi < index]][length(pixel[ptmi[ptmi < index]])] >= min_diff) && (pixel[index]-pixel[ptmi[ptmi > index]][1] > min_diff)) && # 4th test
     (pixel[ptmi[ptmi < index]][length(pixel[ptmi[ptmi < index]])] && pixel[ptmi[ptmi > index]][1] >= min_val) && # 5th
     ((ptmi[ptmi < index][length(ptmi[ptmi < index])] <= index-(max_phase_duration-3) && index-(max_phase_duration-3)>= 1) |  (ptmi[ptmi > index][1] >= index+(max_phase_duration-3))))) # 6th
     {
      # computing the valid maximum values to avoid the "fake" crop pattern (small difference between min and max) and using this "position_data" to save the values in the vectors in the right order
      max_valids <- c(max_valids, index)
      position_data <- which(max_valids==index)
      # saving the points of maximum per pixel over the time series
      max_points[position_data] <- index

      # calculating the crop cycle length
      length_max_period[position_data] <- (index-ptmi[ptmi < index][length(ptmi[ptmi < index])])+(ptmi[ptmi > index][1]-index)
      }

     }
    # replacing the NA data (NA is the default value and show possible cropseasons whitout crops)
     #max_points[is.na(max_points)]<-0

     # join the values in a unique number: i.e = c(5,16, 0) -> 99051600 ( 99 = to avoid the difference of length of pixel value in cases of numbers lower than 10; all valid number using flag 0)
     max_points <- as.integer(paste('99',paste(formatC(max_points, flag=0, digits = 1,format = 'd'),collapse = ''),sep=""))

     length_max_period <- as.integer(paste('99',paste(formatC(length_max_period, flag=0, digits = 1,format = 'd'),collapse = '')),sep="")

      }
    }
        # using stackApply 


data_process <- stackApply(imgStacked, indices=c(rep(1,nlayers(imgStacked)),rep(2,nlayers(imgStacked))), fun=CropAnalysis) 


The error message:


Error in length_max_period[position_data] <- (index - ptmi[ptmi 
< index [length(ptmi[ptmi <  : replacement has length zero


In addition: Warning messages:


1: In stackApply(imgStacked, indices = c(rep(1, nlayers(imgStacked)),
  : number of items to replace is not a multiple of replacement length


2: In if (is.na(pixel)) { : the condition has length > 1 and only the first element will be used




# using calc
data_process<-calc(x=imgStacked, fun=CropAnalysis, forcefun=TRUE, forceapply=TRUE)


The error message:


Error in colnames<-(*tmp*, value = "layer") : length of 'dimnames' [2] not equal to array extent 


In addition: Warning messages:


1: In if (is.na(pixel)) { : the condition has length > 1 and only the first element will be used


2: In if (is.na(pixel)) { :the condition has length > 1 and only the first element will be used


3: In fun(tstdat) : NAs introduced by coercion to integer range


4: In fun(tstdat) : NAs introduced by coercion


5: In if (is.na(pixel)) { :the condition has length > 1 and only the first element will be used


6: In fun(x) : NAs introduced by coercion to integer range


7: In fun(x) : NAs introduced by coercion


8: In matrix(values, nrow = ncell(x), ncol = nlayers(x)) : data length exceeds size of matrix




------------------------------------------------------------------------------------------------------------------Agronomist engineerMaster in Remote Sensing - National  Institute for Space Research (INPE) - BrazilPHD Student in Transport - Bras?lia University (UNB)  		 	   		  
	[[alternative HTML version deleted]]


From marine.regis at hotmail.fr  Thu Apr 28 22:33:07 2016
From: marine.regis at hotmail.fr (Marine Regis)
Date: Thu, 28 Apr 2016 20:33:07 +0000
Subject: [R-sig-Geo] Error in checkForRemoteErrors(val) with
	sfClusterApplyLB()
Message-ID: <AMSPR07MB470C2DDAF57AC34FCFAA754E2650@AMSPR07MB470.eurprd07.prod.outlook.com>

Hello,



I'm trying to run a code that uses the snowfall package. Here is the structure of my code.



sfInit(parallel=T, cpus = 5, slaveOutfile="ErrorMessage.txt")

sfExportAll()

sfLibrary(rgdal)

sfLibrary(raster)

sfLibrary(sp)

sfLibrary(rgeos)

sfLibrary(snowfall)



system.time( sfClusterApplyLB(1:10, function(k) {

  sfCat(paste("Iteration ", k), sep="\n")

if (......) {

} else {

if (class(ob1)=="SpatialCollections") {

        ob2 <- ob1 at lineobj

      } else if (class(ob1)=="SpatialLines") {

        ob2 <- ob1

      }

ob3 <- data.frame(length_m=sapply(1:length(ob2), function(l) gLength(ob2 [l, ])))

.....

}

.....

}

sfStop()



The problem is that the code returns the error message:

Error in checkForRemoteErrors(val) :

  one node produced an error: object 'ob2' not found



>From the debugging function "sfCat", I also get these warning messages:



Warning messages:

1: In searchCommandline(parallel, cpus = cpus, type = type, socketHosts = socketHosts,  :

  Unknown option on commandline: --file

2: In searchCommandline(parallel, cpus = cpus, type = type, socketHosts = socketHosts,  :

  Unknown option on commandline: MASTER

3: In searchCommandline(parallel, cpus = cpus, type = type, socketHosts = socketHosts,  :

  Unknown option on commandline: PORT

4: In searchCommandline(parallel, cpus = cpus, type = type, socketHosts = socketHosts,  :

  Unknown option on commandline: OUT

5: In searchCommandline(parallel, cpus = cpus, type = type, socketHosts = socketHosts,  :

  Unknown option on commandline: SNOWLIB

 socketHosts,  :

  Unknown option on commandline: SNOWLIB

tion on commandline: SNOWLIB


The code works when I use a simple loop for(k in 1:10) {} instead of sfClusterApplyLB(1:10, function(k) {}.



Why do I obtain this error message ? I am completely novice in using snowfall package. So any advices are appreciated.



Thanks a lot for your time.


Marine


	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Fri Apr 29 09:45:32 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 29 Apr 2016 09:45:32 +0200
Subject: [R-sig-Geo] Error in checkForRemoteErrors(val) with
 sfClusterApplyLB()
In-Reply-To: <AMSPR07MB470C2DDAF57AC34FCFAA754E2650@AMSPR07MB470.eurprd07.prod.outlook.com>
References: <AMSPR07MB470C2DDAF57AC34FCFAA754E2650@AMSPR07MB470.eurprd07.prod.outlook.com>
Message-ID: <alpine.LFD.2.20.1604290938520.747@reclus.nhh.no>

On Thu, 28 Apr 2016, Marine Regis wrote:

> Hello,
>
> I'm trying to run a code that uses the snowfall package. Here is the 
> structure of my code.

Avoid snowfall unless you know that the code runs in general. The problem 
seems to be with your if conditions - you assume that ob1 is either a 
SpatialCollections object and has a lineobj slot, or that ob1 is a 
SpatialLines object, in both cases yielding ob2 as a SpatialLines object.

You do not check that ob1 is neither SpatialLines nor SpatialCollections, 
or if SpatialCollections that it has a lineobj slot. You need a further 
step where ob2 is initialised as NULL, and tested after the attempts to 
assign lines, branching on is.null(ob2).

Your data are likely not the same as those of the authors of the code you 
are trying to run, and they didn't write to take account of situations 
they didn't encounter.

Roger

>
> sfInit(parallel=T, cpus = 5, slaveOutfile="ErrorMessage.txt")
>
> sfExportAll()
>
> sfLibrary(rgdal)
>
> sfLibrary(raster)
>
> sfLibrary(sp)
>
> sfLibrary(rgeos)
>
> sfLibrary(snowfall)
>
>
>
> system.time( sfClusterApplyLB(1:10, function(k) {
>
>  sfCat(paste("Iteration ", k), sep="\n")
>
> if (......) {
>
> } else {
>
> if (class(ob1)=="SpatialCollections") {
>
>        ob2 <- ob1 at lineobj
>
>      } else if (class(ob1)=="SpatialLines") {
>
>        ob2 <- ob1
>
>      }
>
> ob3 <- data.frame(length_m=sapply(1:length(ob2), function(l) gLength(ob2 [l, ])))
>
> .....
>
> }
>
> .....
>
> }
>
> sfStop()
>
>
>
> The problem is that the code returns the error message:
>
> Error in checkForRemoteErrors(val) :
>
>  one node produced an error: object 'ob2' not found
>
>
>
>> From the debugging function "sfCat", I also get these warning messages:
>
>
>
> Warning messages:
>
> 1: In searchCommandline(parallel, cpus = cpus, type = type, socketHosts = socketHosts,  :
>
>  Unknown option on commandline: --file
>
> 2: In searchCommandline(parallel, cpus = cpus, type = type, socketHosts = socketHosts,  :
>
>  Unknown option on commandline: MASTER
>
> 3: In searchCommandline(parallel, cpus = cpus, type = type, socketHosts = socketHosts,  :
>
>  Unknown option on commandline: PORT
>
> 4: In searchCommandline(parallel, cpus = cpus, type = type, socketHosts = socketHosts,  :
>
>  Unknown option on commandline: OUT
>
> 5: In searchCommandline(parallel, cpus = cpus, type = type, socketHosts = socketHosts,  :
>
>  Unknown option on commandline: SNOWLIB
>
> socketHosts,  :
>
>  Unknown option on commandline: SNOWLIB
>
> tion on commandline: SNOWLIB
>
>
> The code works when I use a simple loop for(k in 1:10) {} instead of sfClusterApplyLB(1:10, function(k) {}.
>
>
>
> Why do I obtain this error message ? I am completely novice in using snowfall package. So any advices are appreciated.
>
>
>
> Thanks a lot for your time.
>
>
> Marine
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


From janka.vanschoenwinkel at uhasselt.be  Fri Apr 29 14:23:06 2016
From: janka.vanschoenwinkel at uhasselt.be (Janka VANSCHOENWINKEL)
Date: Fri, 29 Apr 2016 14:23:06 +0200
Subject: [R-sig-Geo] Translate a net-cdf file with different years to
 polygon regions.
In-Reply-To: <D51374C4B889BC47B3C5286047C86DA1A02C3A70@whqembx03p.ad.sfwmd.gov>
References: <CAHymutKcpgJoWExtVVLFsSJ8VG23-b1jumMrMivMk2ZO5Lu6Jg@mail.gmail.com>
	<D51374C4B889BC47B3C5286047C86DA1A02C3A20@whqembx03p.ad.sfwmd.gov>
	<D51374C4B889BC47B3C5286047C86DA1A02C3A70@whqembx03p.ad.sfwmd.gov>
Message-ID: <CAHymutLi97xoegT8qyYD3Tz7+LwFt9DfGJoMH81dSO3KL9yh4A@mail.gmail.com>

Hi Joseph,

Thank you very much for the hint.

If I may ask you, could you please help me a little bit further. I am not
familiar with these packages and I do not see how to overlap the point data
or the netcdf data with the nuts3 polygons.

Basically, I have too options:

1) use the cvs-points (with lon, lat, and the data variable) to see which
points are located in which nuts3 regions and then save these results. (but
then my previous codes still applies)

2) use the original netcdf file and overlay it with the nuts3 polygon
shapefile (this was your hint, but I don't know how to start with this).

Thank you very much for your answer!



2016-04-19 14:42 GMT+02:00 Stachelek, Joseph <jstachel at sfwmd.gov>:

> Since your nc file contains multiple layers, you will want to use
> `raster::stack()` rather than `raster::raster()`.
>
>
> -----Original Message-----
> From: Stachelek, Joseph
> Sent: Tuesday, April 19, 2016 8:23 AM
> To: 'Janka VANSCHOENWINKEL' <janka.vanschoenwinkel at uhasselt.be>;
> r-sig-geo at r-project.org
> Subject: RE: [R-sig-Geo] Translate a net-cdf file with different years to
> polygon regions.
>
> Hi Janka,
>
> I think you can simplify your code a lot by opening your nc file directly
> using the `raster` package rather than messing with `nc_open` calls.
>
> ```
> ncin <- raster::raster(paste(ncname, ".nc", sep = ""))
> ```
>
> Then you might use `raster::extract()` to pull the values associated with
> your polygons. Also, I would recommend posting a link to a gist (
> https://gist.github.com/) rather than pasting such a long script into
> your email.
>
> Joe
>
> -----Original Message-----
> From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of
> Janka VANSCHOENWINKEL
> Sent: Tuesday, April 19, 2016 4:45 AM
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] Translate a net-cdf file with different years to
> polygon regions.
>
> *DATA*
>
> I have a net-cdf file which has raster of 0.5 on 0.5 degrees. You can
> easily download it here
> <
> https://crudata.uea.ac.uk/cru/data/hrg/cru_ts_3.23/cruts.1506241137.v3.23/pet/
> >
> and
> search for *cru_ts3.23.2001.2010.pet.dat.nc.gz *(it is also downloadable as
> a dat.file if this is more handy to work with)
>  (Or simply download the net-cdf file directly through:
> cru_ts3.23.2001.2010.pet.dat.nc.gz
> <
> https://crudata.uea.ac.uk/cru/data/hrg/cru_ts_3.23/cruts.1506241137.v3.23/pet/cru_ts3.23.2001.2010.pet.dat.nc.gz
> >
> ).
>
> I opened the file in ArcMap as well and found that the coordinate system
> used is: GCS_WGS_1984. The net-cdf file contains monthly data from
> 2001-2010
>
> Download from this website
> <
> http://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units/nuts
> >
> the
> following ZIP file: *NUTS_2006_60M_SH.zip* and save all the
> *NUTS_RG_60M_2006
> files *in a folder where you can easily find the back. In what follows I
> refer to this as "NUTS3".
>
> *WHAT I WANT*
>
> - I want to add the information from the raster files to the NUTS3
> shapefile (which are polygons and no rasters) in order to obtain a table
> per nuts3 region for each monthtly variable.
>
>
> *WHERE I AM STUCK*
>
> The file appears to be very difficult to work with in ArcGis. Also, I will
> have to repeat this process a number of times for different variables. So I
> would like to have one code in R that I can run.
>
> I have a number of separate codes to do the following:
> - translate the net-cdf file to a cvs file with longitude and latitude as
> identifiers (see below under 1)
> - translate a cvs file with accompanying empty raster file to nuts3
> regions. (this is a code that I have used before when I had a cvs file and
> a raster). (see below under 2).
>
> However, I don't have a raster file now. Well, technically I do (since the
> net-ncf file is a raster) but I don't know how to use it in this format.
>
> Can somebody help me to link the codes below or suggest a different code to
> obtain what I want?
>
> Thanks a lot!
>
> Janka
>
>
>
>
> *1) With the following code, I can make a cvs file and extract all the data
> in table format.*
>
> library(fields)
> library(chron)
>
> library(ncdf4)
> ncname<-"cru_ts3.22.2001.2010.pet.dat"
> ncname<-"cru_ts3.23.1991.2000.pet.dat"
> ncfname <- paste(ncname, ".nc", sep = "")
> dname <- "pet"
> ncin <- nc_open(ncfname)
> print(ncin)
>
> lon <- ncvar_get(ncin, "lon")
> nlon <- dim(lon)
> head(lon)
>
> lat <- ncvar_get(ncin, "lat", verbose = F)
> nlat <- dim(lat)
> head(lat)
>
> print(c(nlon, nlat))
>
>
> t <- ncvar_get(ncin, "time")
> tunits <- ncatt_get(ncin, "time", "units")
> nt <- dim(t)
>
> tmp.array <- ncvar_get(ncin, dname)
> dlname <- ncatt_get(ncin, dname, "long_name")
> dunits <- ncatt_get(ncin, dname, "units")
> fillvalue <- ncatt_get(ncin, dname, "_FillValue")
> dim(tmp.array)
>
> title <- ncatt_get(ncin, 0, "title")
> institution <- ncatt_get(ncin, 0, "institution")
> datasource <- ncatt_get(ncin, 0, "source")
> references <- ncatt_get(ncin, 0, "references")
> history <- ncatt_get(ncin, 0, "history")
> Conventions <- ncatt_get(ncin, 0, "Conventions")
>
>
>
> nc_close(ncin)
>
> # split the time units string into fields
> tustr <- strsplit(tunits$value, " ")
> tdstr <- strsplit(unlist(tustr)[3], "-")
> tmonth = as.integer(unlist(tdstr)[2])
> tday = as.integer(unlist(tdstr)[3])
> tyear = as.integer(unlist(tdstr)[1])
> chron(t, origin = c(tmonth, tday, tyear))
>
>
>
> tmp.array[tmp.array == fillvalue$value] <- NA
>
> length(na.omit(as.vector(tmp.array[, , 1])))
>
> m <- 1
> tmp.slice <- tmp.array[, , m]
> library(RColorBrewer)
> image(lon, lat, tmp.slice, col = rev(brewer.pal(10, "RdBu")))
>
> grid <- expand.grid(lon = lon, lat = lat)
> cutpts <- c(-50, -40, -30, -20, -10, 0, 10, 20, 30, 40, 50)
> levelplot(tmp.slice ~ lon * lat, data = grid, at = cutpts, cuts = 11,
> pretty = T,
>           col.regions = (rev(brewer.pal(10, "RdBu"))))
>
>
> lonlat <- expand.grid(lon, lat)
> tmp.vec <- as.vector(tmp.slice)
> length(tmp.vec)
>
> tmp.df01 <- data.frame(cbind(lonlat, tmp.vec))
> names(tmp.df01) <- c("lon", "lat", paste(dname, as.character(m), sep =
> "_"))
> head(na.omit(tmp.df01), 20)
>
> csvfile <- "cru_tmp_1.csv"
> write.table(na.omit(tmp.df01), csvfile, row.names = FALSE, sep = ",")
>
>
> tmp.vec.long <- as.vector(tmp.array)
> length(tmp.vec.long)
>
> tmp.mat <- matrix(tmp.vec.long, nrow = nlon * nlat, ncol = nt)
> dim(tmp.mat)
>
> head(na.omit(tmp.mat))
>
> lonlat <- expand.grid(lon, lat)
> tmp.df02 <- data.frame(cbind(lonlat, tmp.mat))
>
> names(tmp.df02) <- c("lon","lat","pet_jan_2001",
>                      "pet_feb_2001",
>                      "pet_mar_2001",
>                      "pet_apr_2001",
>                      "pet_may_2001",
>                      "pet_jun_2001",
>                      "pet_jul_2001",
>                      "pet_aug_2001",
>                      "pet_sep_2001",
>                      "pet_oct_2001",
>                      "pet_nov_2001",
>                      "pet_dec_2001",
>                      "pet_jan_2002",
>                      "pet_feb_2002",
>                      "pet_mar_2002",
>                      "pet_apr_2002",
>                      "pet_may_2002",
>                      "pet_jun_2002",
>                      "pet_jul_2002",
>                      "pet_aug_2002",
>                      "pet_sep_2002",
>                      "pet_oct_2002",
>                      "pet_nov_2002",
>                      "pet_dec_2002",
>                      "pet_jan_2003",
>                      "pet_feb_2003",
>                      "pet_mar_2003",
>                      "pet_apr_2003",
>                      "pet_may_2003",
>                      "pet_jun_2003",
>                      "pet_jul_2003",
>                      "pet_aug_2003",
>                      "pet_sep_2003",
>                      "pet_oct_2003",
>                      "pet_nov_2003",
>                      "pet_dec_2003",
>                      "pet_jan_2004",
>                      "pet_feb_2004",
>                      "pet_mar_2004",
>                      "pet_apr_2004",
>                      "pet_may_2004",
>                      "pet_jun_2004",
>                      "pet_jul_2004",
>                      "pet_aug_2004",
>                      "pet_sep_2004",
>                      "pet_oct_2004",
>                      "pet_nov_2004",
>                      "pet_dec_2004",
>                      "pet_jan_2005",
>                      "pet_feb_2005",
>                      "pet_mar_2005",
>                      "pet_apr_2005",
>                      "pet_may_2005",
>                      "pet_jun_2005",
>                      "pet_jul_2005",
>                      "pet_aug_2005",
>                      "pet_sep_2005",
>                      "pet_oct_2005",
>                      "pet_nov_2005",
>                      "pet_dec_2005",
>                      "pet_jan_2006",
>                      "pet_feb_2006",
>                      "pet_mar_2006",
>                      "pet_apr_2006",
>                      "pet_may_2006",
>                      "pet_jun_2006",
>                      "pet_jul_2006",
>                      "pet_aug_2006",
>                      "pet_sep_2006",
>                      "pet_oct_2006",
>                      "pet_nov_2006",
>                      "pet_dec_2006",
>                      "pet_jan_2007",
>                      "pet_feb_2007",
>                      "pet_mar_2007",
>                      "pet_apr_2007",
>                      "pet_may_2007",
>                      "pet_jun_2007",
>                      "pet_jul_2007",
>                      "pet_aug_2007",
>                      "pet_sep_2007",
>                      "pet_oct_2007",
>                      "pet_nov_2007",
>                      "pet_dec_2007",
>                      "pet_jan_2008",
>                      "pet_feb_2008",
>                      "pet_mar_2008",
>                      "pet_apr_2008",
>                      "pet_may_2008",
>                      "pet_jun_2008",
>                      "pet_jul_2008",
>                      "pet_aug_2008",
>                      "pet_sep_2008",
>                      "pet_oct_2008",
>                      "pet_nov_2008",
>                      "pet_dec_2008",
>                      "pet_jan_2009",
>                      "pet_feb_2009",
>                      "pet_mar_2009",
>                      "pet_apr_2009",
>                      "pet_may_2009",
>                      "pet_jun_2009",
>                      "pet_jul_2009",
>                      "pet_aug_2009",
>                      "pet_sep_2009",
>                      "pet_oct_2009",
>                      "pet_nov_2009",
>                      "pet_dec_2009",
>                      "pet_jan_2010",
>                      "pet_feb_2010",
>                      "pet_mar_2010",
>                      "pet_apr_2010",
>                      "pet_may_2010",
>                      "pet_jun_2010",
>                      "pet_jul_2010",
>                      "pet_aug_2010",
>                      "pet_sep_2010",
>                      "pet_oct_2010",
>                      "pet_nov_2010",
>                      "pet_dec_2010")
>
>
> options(width = 110)
> head(na.omit(tmp.df02, 20))
>
> dim(na.omit(tmp.df02))
>
> csvfile <- "cru_tmp_2.csv"
> write.table(na.omit(tmp.df02), csvfile, row.names = FALSE, sep = ",")
>
>
>
> *2) translate a cvs-file with accompanying raster file to polygon regions.*
>
> The  "filename.txt" file should contain the variables: lon, latitude, and
> all the monthly_yearly variables extracted from point 1 above.
>
> The grid shapefile (*grid_025dd.shp*) can be found through the following
> link but it is only an example and not the correct grid for the problem
> above :
>
> https://drive.google.com/folderview?id=0By9u5m3kxn9yfjZtdFZLcW82SWpzT1VwZXE1a3FtRGtSdEl1c1NvY205TGpack9xSFc2T2s&usp=sharing
>
> # upload data
> mydata<-read.table("filename.txt", header=TRUE,sep=",",dec=".")
>
>
> # upload empty raster
> library(rgdal)
> # 40 seconds
> grid <- readOGR(".", layer = "grid_025dd")
>
>
> # concatenate data in R
> # 2 seconds
> mydata$lonlat<-do.call(paste, c(mydata[c("lon", "lat")], sep=""))
> grid at data$lonlat<-do.call(paste, c(grid at data[c("LONGITUDE", "LATITUDE")],
> sep=""))
>
> # use common variable lonlat to merge data in raster
>
> ###### prepare shapefile #####
> library(rgdal)        ## Load geographic info
> library(maps)         ## Projections
> library(maptools)     ## Data management
> #library(sm)           ## Data management
> library(spdep)        ## Spatial autocorrelation
> library(gstat)        ## Geostatistics
> library(splancs)      ## Kernel Density
> library(spatstat)     ## Geostatistics
> library(pgirmess)     ## Spatial autocorrelation
> library(RColorBrewer) ## Visualization
> library(classInt)     ## Class intervals
> library(spgwr)        ## GWR
>
> # Match polygons with data
> idx <- match(grid$lonlat, mydata$lonlat)
> # Places without information
> idxNA <- which(is.na(idx))
> # Information to be added to the SpatialPolygons object
> dat2add <- mydata[idx, ]
> # spCbind uses row names to match polygons with data
> # First, extract polygon IDs
> IDs <- sapply(grid at polygons, function(x)x at ID)
> # and join with the SpatialPolygons
> row.names(dat2add) <- IDs
> datPols <- spCbind(grid, dat2add)
> # Drop those places without information
> datPols <- datPols[-idxNA, ]
> # write new shapefile
> # 7 seconds
> writeOGR(datPols, dsn = ".", layer ='sm2000eu28', driver = 'ESRI
> Shapefile')
> # read new shapefile
> # 51 seconds
> data <- readOGR(".", layer="sm2000eu28")
>
> ############################
> # intersect nuts with grid #
> ############################
>
> library(rgdal)
> nuts <- readOGR(".", layer = "NUTS_RG_60M_2006")
>
> library(rgeos)
> proj4string(data) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84")
>
>
> #
> grid <- data
> grid at data$lonlat <- NULL
> grid at data$lonlat_1 <- NULL
> grid at data$ID <- NULL
> grid at data$lat <- NULL
> grid at data$lon <- NULL
> grid at data$ELEVATION <- NULL
> grid at data$DAYS_RAIN_ <- NULL
>
>
> # First find out which grid cells intersect your NUTS polygons
> grid_nuts <- gIntersects(grid,nuts,byid = TRUE)
>
> # use the apply() function to calculate the mean, min, and max of your
> value.
> # The loop makes
>
> for(i in names(grid at data)){
>   nuts at data[[paste(i, 'average_value', sep="_")]] <-
> apply(grid_nuts,1,function(x) mean(grid at data[[i]][x]))
>   nuts at data[[paste(i, 'min_value', sep="_")]] <-
> apply(grid_nuts,1,function(x) min(grid at data[[i]][x]))
>   nuts at data[[paste(i, 'max_value', sep="_")]] <-
> apply(grid_nuts,1,function(x) max(grid at data[[i]][x]))
> }
>
> write.table(nuts at data, "nuts_sm2000eu28_unweighted.txt", sep="\t")
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> We value your opinion. Please take a few minutes to share your comments on
> the service you received from the District by clicking on this link<
> http://my.sfwmd.gov/portal/page/portal/pg_grp_surveysystem/survey%20ext?pid=1653
> >.
>



-- 

[image: Logo UHasselt] Mevrouw Janka Vanschoenwinkel
*Doctoraatsbursaal - PhD *
Milieueconomie - Environmental economics

T +32(0)11 26 86 96 | GSM +32(0)476 28 21 40

www.uhasselt.be/eec

Universiteit Hasselt | Campus Diepenbeek
Agoralaan Gebouw D | B-3590 Diepenbeek
Kantoor F11

Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt


[image: Music For Life]  Maak van UHasselt de #warmsteunief |
www.uhasselt.be/musicforlife


P Please consider the environment before printing this e-mail

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Fri Apr 29 14:42:19 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 29 Apr 2016 12:42:19 +0000
Subject: [R-sig-Geo] Translate a net-cdf file with different years to
 polygon regions.
In-Reply-To: <CAHymutLi97xoegT8qyYD3Tz7+LwFt9DfGJoMH81dSO3KL9yh4A@mail.gmail.com>
References: <CAHymutKcpgJoWExtVVLFsSJ8VG23-b1jumMrMivMk2ZO5Lu6Jg@mail.gmail.com>
	<D51374C4B889BC47B3C5286047C86DA1A02C3A20@whqembx03p.ad.sfwmd.gov>
	<D51374C4B889BC47B3C5286047C86DA1A02C3A70@whqembx03p.ad.sfwmd.gov>
	<CAHymutLi97xoegT8qyYD3Tz7+LwFt9DfGJoMH81dSO3KL9yh4A@mail.gmail.com>
Message-ID: <CAAcGz9-x7E6B_BHLcCdE5A1t28=tqGR9j4oFF=SUvJJ-BYGWhA@mail.gmail.com>

On Fri, 29 Apr 2016 at 22:23 Janka VANSCHOENWINKEL <
janka.vanschoenwinkel at uhasselt.be> wrote:

> Hi Joseph,
>
> Thank you very much for the hint.
>
> If I may ask you, could you please help me a little bit further. I am not
> familiar with these packages and I do not see how to overlap the point data
> or the netcdf data with the nuts3 polygons.
>
> Basically, I have too options:
>
> 1) use the cvs-points (with lon, lat, and the data variable) to see which
> points are located in which nuts3 regions and then save these results. (but
> then my previous codes still applies)
>
> 2) use the original netcdf file and overlay it with the nuts3 polygon
> shapefile (this was your hint, but I don't know how to start with this).
>
>
Something like this will do it:

library(raster)
require(rgdal)
require(ncdf4)

st <- stack("thencfile.nc")  ## might need varname = "sst" or similar

poly <- shapefile("theshpfile.shp")

extract(st, poly, fun = "mean")  ## and maybe na.rm = TRUE

If you don't want the mean, you can just leave out the fun argument and
you'll get all the pixel values for every time step in a big list, which
may not be obviously helpful but it's all useable with generic R.

I can't quite bring myself to get your files and try it, so please try and
report details.

Cheers, Mike.


> Thank you very much for your answer!
>
>
>
> 2016-04-19 14:42 GMT+02:00 Stachelek, Joseph <jstachel at sfwmd.gov>:
>
> > Since your nc file contains multiple layers, you will want to use
> > `raster::stack()` rather than `raster::raster()`.
> >
> >
> > -----Original Message-----
> > From: Stachelek, Joseph
> > Sent: Tuesday, April 19, 2016 8:23 AM
> > To: 'Janka VANSCHOENWINKEL' <janka.vanschoenwinkel at uhasselt.be>;
> > r-sig-geo at r-project.org
> > Subject: RE: [R-sig-Geo] Translate a net-cdf file with different years to
> > polygon regions.
> >
> > Hi Janka,
> >
> > I think you can simplify your code a lot by opening your nc file directly
> > using the `raster` package rather than messing with `nc_open` calls.
> >
> > ```
> > ncin <- raster::raster(paste(ncname, ".nc", sep = ""))
> > ```
> >
> > Then you might use `raster::extract()` to pull the values associated with
> > your polygons. Also, I would recommend posting a link to a gist (
> > https://gist.github.com/) rather than pasting such a long script into
> > your email.
> >
> > Joe
> >
> > -----Original Message-----
> > From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of
> > Janka VANSCHOENWINKEL
> > Sent: Tuesday, April 19, 2016 4:45 AM
> > To: r-sig-geo at r-project.org
> > Subject: [R-sig-Geo] Translate a net-cdf file with different years to
> > polygon regions.
> >
> > *DATA*
> >
> > I have a net-cdf file which has raster of 0.5 on 0.5 degrees. You can
> > easily download it here
> > <
> >
> https://crudata.uea.ac.uk/cru/data/hrg/cru_ts_3.23/cruts.1506241137.v3.23/pet/
> > >
> > and
> > search for *cru_ts3.23.2001.2010.pet.dat.nc.gz *(it is also downloadable
> as
> > a dat.file if this is more handy to work with)
> >  (Or simply download the net-cdf file directly through:
> > cru_ts3.23.2001.2010.pet.dat.nc.gz
> > <
> >
> https://crudata.uea.ac.uk/cru/data/hrg/cru_ts_3.23/cruts.1506241137.v3.23/pet/cru_ts3.23.2001.2010.pet.dat.nc.gz
> > >
> > ).
> >
> > I opened the file in ArcMap as well and found that the coordinate system
> > used is: GCS_WGS_1984. The net-cdf file contains monthly data from
> > 2001-2010
> >
> > Download from this website
> > <
> >
> http://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units/nuts
> > >
> > the
> > following ZIP file: *NUTS_2006_60M_SH.zip* and save all the
> > *NUTS_RG_60M_2006
> > files *in a folder where you can easily find the back. In what follows I
> > refer to this as "NUTS3".
> >
> > *WHAT I WANT*
> >
> > - I want to add the information from the raster files to the NUTS3
> > shapefile (which are polygons and no rasters) in order to obtain a table
> > per nuts3 region for each monthtly variable.
> >
> >
> > *WHERE I AM STUCK*
> >
> > The file appears to be very difficult to work with in ArcGis. Also, I
> will
> > have to repeat this process a number of times for different variables.
> So I
> > would like to have one code in R that I can run.
> >
> > I have a number of separate codes to do the following:
> > - translate the net-cdf file to a cvs file with longitude and latitude as
> > identifiers (see below under 1)
> > - translate a cvs file with accompanying empty raster file to nuts3
> > regions. (this is a code that I have used before when I had a cvs file
> and
> > a raster). (see below under 2).
> >
> > However, I don't have a raster file now. Well, technically I do (since
> the
> > net-ncf file is a raster) but I don't know how to use it in this format.
> >
> > Can somebody help me to link the codes below or suggest a different code
> to
> > obtain what I want?
> >
> > Thanks a lot!
> >
> > Janka
> >
> >
> >
> >
> > *1) With the following code, I can make a cvs file and extract all the
> data
> > in table format.*
> >
> > library(fields)
> > library(chron)
> >
> > library(ncdf4)
> > ncname<-"cru_ts3.22.2001.2010.pet.dat"
> > ncname<-"cru_ts3.23.1991.2000.pet.dat"
> > ncfname <- paste(ncname, ".nc", sep = "")
> > dname <- "pet"
> > ncin <- nc_open(ncfname)
> > print(ncin)
> >
> > lon <- ncvar_get(ncin, "lon")
> > nlon <- dim(lon)
> > head(lon)
> >
> > lat <- ncvar_get(ncin, "lat", verbose = F)
> > nlat <- dim(lat)
> > head(lat)
> >
> > print(c(nlon, nlat))
> >
> >
> > t <- ncvar_get(ncin, "time")
> > tunits <- ncatt_get(ncin, "time", "units")
> > nt <- dim(t)
> >
> > tmp.array <- ncvar_get(ncin, dname)
> > dlname <- ncatt_get(ncin, dname, "long_name")
> > dunits <- ncatt_get(ncin, dname, "units")
> > fillvalue <- ncatt_get(ncin, dname, "_FillValue")
> > dim(tmp.array)
> >
> > title <- ncatt_get(ncin, 0, "title")
> > institution <- ncatt_get(ncin, 0, "institution")
> > datasource <- ncatt_get(ncin, 0, "source")
> > references <- ncatt_get(ncin, 0, "references")
> > history <- ncatt_get(ncin, 0, "history")
> > Conventions <- ncatt_get(ncin, 0, "Conventions")
> >
> >
> >
> > nc_close(ncin)
> >
> > # split the time units string into fields
> > tustr <- strsplit(tunits$value, " ")
> > tdstr <- strsplit(unlist(tustr)[3], "-")
> > tmonth = as.integer(unlist(tdstr)[2])
> > tday = as.integer(unlist(tdstr)[3])
> > tyear = as.integer(unlist(tdstr)[1])
> > chron(t, origin = c(tmonth, tday, tyear))
> >
> >
> >
> > tmp.array[tmp.array == fillvalue$value] <- NA
> >
> > length(na.omit(as.vector(tmp.array[, , 1])))
> >
> > m <- 1
> > tmp.slice <- tmp.array[, , m]
> > library(RColorBrewer)
> > image(lon, lat, tmp.slice, col = rev(brewer.pal(10, "RdBu")))
> >
> > grid <- expand.grid(lon = lon, lat = lat)
> > cutpts <- c(-50, -40, -30, -20, -10, 0, 10, 20, 30, 40, 50)
> > levelplot(tmp.slice ~ lon * lat, data = grid, at = cutpts, cuts = 11,
> > pretty = T,
> >           col.regions = (rev(brewer.pal(10, "RdBu"))))
> >
> >
> > lonlat <- expand.grid(lon, lat)
> > tmp.vec <- as.vector(tmp.slice)
> > length(tmp.vec)
> >
> > tmp.df01 <- data.frame(cbind(lonlat, tmp.vec))
> > names(tmp.df01) <- c("lon", "lat", paste(dname, as.character(m), sep =
> > "_"))
> > head(na.omit(tmp.df01), 20)
> >
> > csvfile <- "cru_tmp_1.csv"
> > write.table(na.omit(tmp.df01), csvfile, row.names = FALSE, sep = ",")
> >
> >
> > tmp.vec.long <- as.vector(tmp.array)
> > length(tmp.vec.long)
> >
> > tmp.mat <- matrix(tmp.vec.long, nrow = nlon * nlat, ncol = nt)
> > dim(tmp.mat)
> >
> > head(na.omit(tmp.mat))
> >
> > lonlat <- expand.grid(lon, lat)
> > tmp.df02 <- data.frame(cbind(lonlat, tmp.mat))
> >
> > names(tmp.df02) <- c("lon","lat","pet_jan_2001",
> >                      "pet_feb_2001",
> >                      "pet_mar_2001",
> >                      "pet_apr_2001",
> >                      "pet_may_2001",
> >                      "pet_jun_2001",
> >                      "pet_jul_2001",
> >                      "pet_aug_2001",
> >                      "pet_sep_2001",
> >                      "pet_oct_2001",
> >                      "pet_nov_2001",
> >                      "pet_dec_2001",
> >                      "pet_jan_2002",
> >                      "pet_feb_2002",
> >                      "pet_mar_2002",
> >                      "pet_apr_2002",
> >                      "pet_may_2002",
> >                      "pet_jun_2002",
> >                      "pet_jul_2002",
> >                      "pet_aug_2002",
> >                      "pet_sep_2002",
> >                      "pet_oct_2002",
> >                      "pet_nov_2002",
> >                      "pet_dec_2002",
> >                      "pet_jan_2003",
> >                      "pet_feb_2003",
> >                      "pet_mar_2003",
> >                      "pet_apr_2003",
> >                      "pet_may_2003",
> >                      "pet_jun_2003",
> >                      "pet_jul_2003",
> >                      "pet_aug_2003",
> >                      "pet_sep_2003",
> >                      "pet_oct_2003",
> >                      "pet_nov_2003",
> >                      "pet_dec_2003",
> >                      "pet_jan_2004",
> >                      "pet_feb_2004",
> >                      "pet_mar_2004",
> >                      "pet_apr_2004",
> >                      "pet_may_2004",
> >                      "pet_jun_2004",
> >                      "pet_jul_2004",
> >                      "pet_aug_2004",
> >                      "pet_sep_2004",
> >                      "pet_oct_2004",
> >                      "pet_nov_2004",
> >                      "pet_dec_2004",
> >                      "pet_jan_2005",
> >                      "pet_feb_2005",
> >                      "pet_mar_2005",
> >                      "pet_apr_2005",
> >                      "pet_may_2005",
> >                      "pet_jun_2005",
> >                      "pet_jul_2005",
> >                      "pet_aug_2005",
> >                      "pet_sep_2005",
> >                      "pet_oct_2005",
> >                      "pet_nov_2005",
> >                      "pet_dec_2005",
> >                      "pet_jan_2006",
> >                      "pet_feb_2006",
> >                      "pet_mar_2006",
> >                      "pet_apr_2006",
> >                      "pet_may_2006",
> >                      "pet_jun_2006",
> >                      "pet_jul_2006",
> >                      "pet_aug_2006",
> >                      "pet_sep_2006",
> >                      "pet_oct_2006",
> >                      "pet_nov_2006",
> >                      "pet_dec_2006",
> >                      "pet_jan_2007",
> >                      "pet_feb_2007",
> >                      "pet_mar_2007",
> >                      "pet_apr_2007",
> >                      "pet_may_2007",
> >                      "pet_jun_2007",
> >                      "pet_jul_2007",
> >                      "pet_aug_2007",
> >                      "pet_sep_2007",
> >                      "pet_oct_2007",
> >                      "pet_nov_2007",
> >                      "pet_dec_2007",
> >                      "pet_jan_2008",
> >                      "pet_feb_2008",
> >                      "pet_mar_2008",
> >                      "pet_apr_2008",
> >                      "pet_may_2008",
> >                      "pet_jun_2008",
> >                      "pet_jul_2008",
> >                      "pet_aug_2008",
> >                      "pet_sep_2008",
> >                      "pet_oct_2008",
> >                      "pet_nov_2008",
> >                      "pet_dec_2008",
> >                      "pet_jan_2009",
> >                      "pet_feb_2009",
> >                      "pet_mar_2009",
> >                      "pet_apr_2009",
> >                      "pet_may_2009",
> >                      "pet_jun_2009",
> >                      "pet_jul_2009",
> >                      "pet_aug_2009",
> >                      "pet_sep_2009",
> >                      "pet_oct_2009",
> >                      "pet_nov_2009",
> >                      "pet_dec_2009",
> >                      "pet_jan_2010",
> >                      "pet_feb_2010",
> >                      "pet_mar_2010",
> >                      "pet_apr_2010",
> >                      "pet_may_2010",
> >                      "pet_jun_2010",
> >                      "pet_jul_2010",
> >                      "pet_aug_2010",
> >                      "pet_sep_2010",
> >                      "pet_oct_2010",
> >                      "pet_nov_2010",
> >                      "pet_dec_2010")
> >
> >
> > options(width = 110)
> > head(na.omit(tmp.df02, 20))
> >
> > dim(na.omit(tmp.df02))
> >
> > csvfile <- "cru_tmp_2.csv"
> > write.table(na.omit(tmp.df02), csvfile, row.names = FALSE, sep = ",")
> >
> >
> >
> > *2) translate a cvs-file with accompanying raster file to polygon
> regions.*
> >
> > The  "filename.txt" file should contain the variables: lon, latitude, and
> > all the monthly_yearly variables extracted from point 1 above.
> >
> > The grid shapefile (*grid_025dd.shp*) can be found through the following
> > link but it is only an example and not the correct grid for the problem
> > above :
> >
> >
> https://drive.google.com/folderview?id=0By9u5m3kxn9yfjZtdFZLcW82SWpzT1VwZXE1a3FtRGtSdEl1c1NvY205TGpack9xSFc2T2s&usp=sharing
> >
> > # upload data
> > mydata<-read.table("filename.txt", header=TRUE,sep=",",dec=".")
> >
> >
> > # upload empty raster
> > library(rgdal)
> > # 40 seconds
> > grid <- readOGR(".", layer = "grid_025dd")
> >
> >
> > # concatenate data in R
> > # 2 seconds
> > mydata$lonlat<-do.call(paste, c(mydata[c("lon", "lat")], sep=""))
> > grid at data$lonlat<-do.call(paste, c(grid at data[c("LONGITUDE",
> "LATITUDE")],
> > sep=""))
> >
> > # use common variable lonlat to merge data in raster
> >
> > ###### prepare shapefile #####
> > library(rgdal)        ## Load geographic info
> > library(maps)         ## Projections
> > library(maptools)     ## Data management
> > #library(sm)           ## Data management
> > library(spdep)        ## Spatial autocorrelation
> > library(gstat)        ## Geostatistics
> > library(splancs)      ## Kernel Density
> > library(spatstat)     ## Geostatistics
> > library(pgirmess)     ## Spatial autocorrelation
> > library(RColorBrewer) ## Visualization
> > library(classInt)     ## Class intervals
> > library(spgwr)        ## GWR
> >
> > # Match polygons with data
> > idx <- match(grid$lonlat, mydata$lonlat)
> > # Places without information
> > idxNA <- which(is.na(idx))
> > # Information to be added to the SpatialPolygons object
> > dat2add <- mydata[idx, ]
> > # spCbind uses row names to match polygons with data
> > # First, extract polygon IDs
> > IDs <- sapply(grid at polygons, function(x)x at ID)
> > # and join with the SpatialPolygons
> > row.names(dat2add) <- IDs
> > datPols <- spCbind(grid, dat2add)
> > # Drop those places without information
> > datPols <- datPols[-idxNA, ]
> > # write new shapefile
> > # 7 seconds
> > writeOGR(datPols, dsn = ".", layer ='sm2000eu28', driver = 'ESRI
> > Shapefile')
> > # read new shapefile
> > # 51 seconds
> > data <- readOGR(".", layer="sm2000eu28")
> >
> > ############################
> > # intersect nuts with grid #
> > ############################
> >
> > library(rgdal)
> > nuts <- readOGR(".", layer = "NUTS_RG_60M_2006")
> >
> > library(rgeos)
> > proj4string(data) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84")
> >
> >
> > #
> > grid <- data
> > grid at data$lonlat <- NULL
> > grid at data$lonlat_1 <- NULL
> > grid at data$ID <- NULL
> > grid at data$lat <- NULL
> > grid at data$lon <- NULL
> > grid at data$ELEVATION <- NULL
> > grid at data$DAYS_RAIN_ <- NULL
> >
> >
> > # First find out which grid cells intersect your NUTS polygons
> > grid_nuts <- gIntersects(grid,nuts,byid = TRUE)
> >
> > # use the apply() function to calculate the mean, min, and max of your
> > value.
> > # The loop makes
> >
> > for(i in names(grid at data)){
> >   nuts at data[[paste(i, 'average_value', sep="_")]] <-
> > apply(grid_nuts,1,function(x) mean(grid at data[[i]][x]))
> >   nuts at data[[paste(i, 'min_value', sep="_")]] <-
> > apply(grid_nuts,1,function(x) min(grid at data[[i]][x]))
> >   nuts at data[[paste(i, 'max_value', sep="_")]] <-
> > apply(grid_nuts,1,function(x) max(grid at data[[i]][x]))
> > }
> >
> > write.table(nuts at data, "nuts_sm2000eu28_unweighted.txt", sep="\t")
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> >
> > We value your opinion. Please take a few minutes to share your comments
> on
> > the service you received from the District by clicking on this link<
> >
> http://my.sfwmd.gov/portal/page/portal/pg_grp_surveysystem/survey%20ext?pid=1653
> > >.
> >
>
>
>
> --
>
> [image: Logo UHasselt] Mevrouw Janka Vanschoenwinkel
> *Doctoraatsbursaal - PhD *
> Milieueconomie - Environmental economics
>
> T +32(0)11 26 86 96 | GSM +32(0)476 28 21 40
>
> www.uhasselt.be/eec
>
> Universiteit Hasselt | Campus Diepenbeek
> Agoralaan Gebouw D | B-3590 Diepenbeek
> Kantoor F11
>
> Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt
>
>
> [image: Music For Life]  Maak van UHasselt de #warmsteunief |
> www.uhasselt.be/musicforlife
>
>
> P Please consider the environment before printing this e-mail
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From janka.vanschoenwinkel at uhasselt.be  Fri Apr 29 15:03:46 2016
From: janka.vanschoenwinkel at uhasselt.be (Janka VANSCHOENWINKEL)
Date: Fri, 29 Apr 2016 15:03:46 +0200
Subject: [R-sig-Geo] Translate a net-cdf file with different years to
 polygon regions.
In-Reply-To: <CAAcGz9-x7E6B_BHLcCdE5A1t28=tqGR9j4oFF=SUvJJ-BYGWhA@mail.gmail.com>
References: <CAHymutKcpgJoWExtVVLFsSJ8VG23-b1jumMrMivMk2ZO5Lu6Jg@mail.gmail.com>
	<D51374C4B889BC47B3C5286047C86DA1A02C3A20@whqembx03p.ad.sfwmd.gov>
	<D51374C4B889BC47B3C5286047C86DA1A02C3A70@whqembx03p.ad.sfwmd.gov>
	<CAHymutLi97xoegT8qyYD3Tz7+LwFt9DfGJoMH81dSO3KL9yh4A@mail.gmail.com>
	<CAAcGz9-x7E6B_BHLcCdE5A1t28=tqGR9j4oFF=SUvJJ-BYGWhA@mail.gmail.com>
Message-ID: <CAHymutLkmHER46BP40Nup8WT52FTuDxuJbnwStzCa+_jx_7bnA@mail.gmail.com>

Thanks Mike,

I am running it now but the output is not yet there.

In mean time, I want to make clear that there are multiple points of the
same period per nuts3-polygon. So when I was speaking about the average, I
meant the average of all those points from the same periods, that are
located in the same polygon. So I do want to have information per period.

Thanks,

Janka

2016-04-29 14:42 GMT+02:00 Michael Sumner <mdsumner at gmail.com>:

>
>
> On Fri, 29 Apr 2016 at 22:23 Janka VANSCHOENWINKEL <
> janka.vanschoenwinkel at uhasselt.be> wrote:
>
>> Hi Joseph,
>>
>> Thank you very much for the hint.
>>
>> If I may ask you, could you please help me a little bit further. I am not
>> familiar with these packages and I do not see how to overlap the point
>> data
>> or the netcdf data with the nuts3 polygons.
>>
>> Basically, I have too options:
>>
>> 1) use the cvs-points (with lon, lat, and the data variable) to see which
>> points are located in which nuts3 regions and then save these results.
>> (but
>> then my previous codes still applies)
>>
>> 2) use the original netcdf file and overlay it with the nuts3 polygon
>> shapefile (this was your hint, but I don't know how to start with this).
>>
>>
> Something like this will do it:
>
> library(raster)
> require(rgdal)
> require(ncdf4)
>
> st <- stack("thencfile.nc")  ## might need varname = "sst" or similar
>
> poly <- shapefile("theshpfile.shp")
>
> extract(st, poly, fun = "mean")  ## and maybe na.rm = TRUE
>
> If you don't want the mean, you can just leave out the fun argument and
> you'll get all the pixel values for every time step in a big list, which
> may not be obviously helpful but it's all useable with generic R.
>
> I can't quite bring myself to get your files and try it, so please try and
> report details.
>
> Cheers, Mike.
>
>
>> Thank you very much for your answer!
>>
>>
>>
>> 2016-04-19 14:42 GMT+02:00 Stachelek, Joseph <jstachel at sfwmd.gov>:
>>
>> > Since your nc file contains multiple layers, you will want to use
>> > `raster::stack()` rather than `raster::raster()`.
>> >
>> >
>> > -----Original Message-----
>> > From: Stachelek, Joseph
>> > Sent: Tuesday, April 19, 2016 8:23 AM
>> > To: 'Janka VANSCHOENWINKEL' <janka.vanschoenwinkel at uhasselt.be>;
>> > r-sig-geo at r-project.org
>> > Subject: RE: [R-sig-Geo] Translate a net-cdf file with different years
>> to
>> > polygon regions.
>> >
>> > Hi Janka,
>> >
>> > I think you can simplify your code a lot by opening your nc file
>> directly
>> > using the `raster` package rather than messing with `nc_open` calls.
>> >
>> > ```
>> > ncin <- raster::raster(paste(ncname, ".nc", sep = ""))
>> > ```
>> >
>> > Then you might use `raster::extract()` to pull the values associated
>> with
>> > your polygons. Also, I would recommend posting a link to a gist (
>> > https://gist.github.com/) rather than pasting such a long script into
>> > your email.
>> >
>> > Joe
>> >
>> > -----Original Message-----
>> > From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of
>> > Janka VANSCHOENWINKEL
>> > Sent: Tuesday, April 19, 2016 4:45 AM
>> > To: r-sig-geo at r-project.org
>> > Subject: [R-sig-Geo] Translate a net-cdf file with different years to
>> > polygon regions.
>> >
>> > *DATA*
>> >
>> > I have a net-cdf file which has raster of 0.5 on 0.5 degrees. You can
>> > easily download it here
>> > <
>> >
>> https://crudata.uea.ac.uk/cru/data/hrg/cru_ts_3.23/cruts.1506241137.v3.23/pet/
>> > >
>> > and
>> > search for *cru_ts3.23.2001.2010.pet.dat.nc.gz *(it is also
>> downloadable as
>> > a dat.file if this is more handy to work with)
>> >  (Or simply download the net-cdf file directly through:
>> > cru_ts3.23.2001.2010.pet.dat.nc.gz
>> > <
>> >
>> https://crudata.uea.ac.uk/cru/data/hrg/cru_ts_3.23/cruts.1506241137.v3.23/pet/cru_ts3.23.2001.2010.pet.dat.nc.gz
>> > >
>> > ).
>> >
>> > I opened the file in ArcMap as well and found that the coordinate system
>> > used is: GCS_WGS_1984. The net-cdf file contains monthly data from
>> > 2001-2010
>> >
>> > Download from this website
>> > <
>> >
>> http://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units/nuts
>> > >
>> > the
>> > following ZIP file: *NUTS_2006_60M_SH.zip* and save all the
>> > *NUTS_RG_60M_2006
>> > files *in a folder where you can easily find the back. In what follows I
>> > refer to this as "NUTS3".
>> >
>> > *WHAT I WANT*
>> >
>> > - I want to add the information from the raster files to the NUTS3
>> > shapefile (which are polygons and no rasters) in order to obtain a table
>> > per nuts3 region for each monthtly variable.
>> >
>> >
>> > *WHERE I AM STUCK*
>> >
>> > The file appears to be very difficult to work with in ArcGis. Also, I
>> will
>> > have to repeat this process a number of times for different variables.
>> So I
>> > would like to have one code in R that I can run.
>> >
>> > I have a number of separate codes to do the following:
>> > - translate the net-cdf file to a cvs file with longitude and latitude
>> as
>> > identifiers (see below under 1)
>> > - translate a cvs file with accompanying empty raster file to nuts3
>> > regions. (this is a code that I have used before when I had a cvs file
>> and
>> > a raster). (see below under 2).
>> >
>> > However, I don't have a raster file now. Well, technically I do (since
>> the
>> > net-ncf file is a raster) but I don't know how to use it in this format.
>> >
>> > Can somebody help me to link the codes below or suggest a different
>> code to
>> > obtain what I want?
>> >
>> > Thanks a lot!
>> >
>> > Janka
>> >
>> >
>> >
>> >
>> > *1) With the following code, I can make a cvs file and extract all the
>> data
>> > in table format.*
>> >
>> > library(fields)
>> > library(chron)
>> >
>> > library(ncdf4)
>> > ncname<-"cru_ts3.22.2001.2010.pet.dat"
>> > ncname<-"cru_ts3.23.1991.2000.pet.dat"
>> > ncfname <- paste(ncname, ".nc", sep = "")
>> > dname <- "pet"
>> > ncin <- nc_open(ncfname)
>> > print(ncin)
>> >
>> > lon <- ncvar_get(ncin, "lon")
>> > nlon <- dim(lon)
>> > head(lon)
>> >
>> > lat <- ncvar_get(ncin, "lat", verbose = F)
>> > nlat <- dim(lat)
>> > head(lat)
>> >
>> > print(c(nlon, nlat))
>> >
>> >
>> > t <- ncvar_get(ncin, "time")
>> > tunits <- ncatt_get(ncin, "time", "units")
>> > nt <- dim(t)
>> >
>> > tmp.array <- ncvar_get(ncin, dname)
>> > dlname <- ncatt_get(ncin, dname, "long_name")
>> > dunits <- ncatt_get(ncin, dname, "units")
>> > fillvalue <- ncatt_get(ncin, dname, "_FillValue")
>> > dim(tmp.array)
>> >
>> > title <- ncatt_get(ncin, 0, "title")
>> > institution <- ncatt_get(ncin, 0, "institution")
>> > datasource <- ncatt_get(ncin, 0, "source")
>> > references <- ncatt_get(ncin, 0, "references")
>> > history <- ncatt_get(ncin, 0, "history")
>> > Conventions <- ncatt_get(ncin, 0, "Conventions")
>> >
>> >
>> >
>> > nc_close(ncin)
>> >
>> > # split the time units string into fields
>> > tustr <- strsplit(tunits$value, " ")
>> > tdstr <- strsplit(unlist(tustr)[3], "-")
>> > tmonth = as.integer(unlist(tdstr)[2])
>> > tday = as.integer(unlist(tdstr)[3])
>> > tyear = as.integer(unlist(tdstr)[1])
>> > chron(t, origin = c(tmonth, tday, tyear))
>> >
>> >
>> >
>> > tmp.array[tmp.array == fillvalue$value] <- NA
>> >
>> > length(na.omit(as.vector(tmp.array[, , 1])))
>> >
>> > m <- 1
>> > tmp.slice <- tmp.array[, , m]
>> > library(RColorBrewer)
>> > image(lon, lat, tmp.slice, col = rev(brewer.pal(10, "RdBu")))
>> >
>> > grid <- expand.grid(lon = lon, lat = lat)
>> > cutpts <- c(-50, -40, -30, -20, -10, 0, 10, 20, 30, 40, 50)
>> > levelplot(tmp.slice ~ lon * lat, data = grid, at = cutpts, cuts = 11,
>> > pretty = T,
>> >           col.regions = (rev(brewer.pal(10, "RdBu"))))
>> >
>> >
>> > lonlat <- expand.grid(lon, lat)
>> > tmp.vec <- as.vector(tmp.slice)
>> > length(tmp.vec)
>> >
>> > tmp.df01 <- data.frame(cbind(lonlat, tmp.vec))
>> > names(tmp.df01) <- c("lon", "lat", paste(dname, as.character(m), sep =
>> > "_"))
>> > head(na.omit(tmp.df01), 20)
>> >
>> > csvfile <- "cru_tmp_1.csv"
>> > write.table(na.omit(tmp.df01), csvfile, row.names = FALSE, sep = ",")
>> >
>> >
>> > tmp.vec.long <- as.vector(tmp.array)
>> > length(tmp.vec.long)
>> >
>> > tmp.mat <- matrix(tmp.vec.long, nrow = nlon * nlat, ncol = nt)
>> > dim(tmp.mat)
>> >
>> > head(na.omit(tmp.mat))
>> >
>> > lonlat <- expand.grid(lon, lat)
>> > tmp.df02 <- data.frame(cbind(lonlat, tmp.mat))
>> >
>> > names(tmp.df02) <- c("lon","lat","pet_jan_2001",
>> >                      "pet_feb_2001",
>> >                      "pet_mar_2001",
>> >                      "pet_apr_2001",
>> >                      "pet_may_2001",
>> >                      "pet_jun_2001",
>> >                      "pet_jul_2001",
>> >                      "pet_aug_2001",
>> >                      "pet_sep_2001",
>> >                      "pet_oct_2001",
>> >                      "pet_nov_2001",
>> >                      "pet_dec_2001",
>> >                      "pet_jan_2002",
>> >                      "pet_feb_2002",
>> >                      "pet_mar_2002",
>> >                      "pet_apr_2002",
>> >                      "pet_may_2002",
>> >                      "pet_jun_2002",
>> >                      "pet_jul_2002",
>> >                      "pet_aug_2002",
>> >                      "pet_sep_2002",
>> >                      "pet_oct_2002",
>> >                      "pet_nov_2002",
>> >                      "pet_dec_2002",
>> >                      "pet_jan_2003",
>> >                      "pet_feb_2003",
>> >                      "pet_mar_2003",
>> >                      "pet_apr_2003",
>> >                      "pet_may_2003",
>> >                      "pet_jun_2003",
>> >                      "pet_jul_2003",
>> >                      "pet_aug_2003",
>> >                      "pet_sep_2003",
>> >                      "pet_oct_2003",
>> >                      "pet_nov_2003",
>> >                      "pet_dec_2003",
>> >                      "pet_jan_2004",
>> >                      "pet_feb_2004",
>> >                      "pet_mar_2004",
>> >                      "pet_apr_2004",
>> >                      "pet_may_2004",
>> >                      "pet_jun_2004",
>> >                      "pet_jul_2004",
>> >                      "pet_aug_2004",
>> >                      "pet_sep_2004",
>> >                      "pet_oct_2004",
>> >                      "pet_nov_2004",
>> >                      "pet_dec_2004",
>> >                      "pet_jan_2005",
>> >                      "pet_feb_2005",
>> >                      "pet_mar_2005",
>> >                      "pet_apr_2005",
>> >                      "pet_may_2005",
>> >                      "pet_jun_2005",
>> >                      "pet_jul_2005",
>> >                      "pet_aug_2005",
>> >                      "pet_sep_2005",
>> >                      "pet_oct_2005",
>> >                      "pet_nov_2005",
>> >                      "pet_dec_2005",
>> >                      "pet_jan_2006",
>> >                      "pet_feb_2006",
>> >                      "pet_mar_2006",
>> >                      "pet_apr_2006",
>> >                      "pet_may_2006",
>> >                      "pet_jun_2006",
>> >                      "pet_jul_2006",
>> >                      "pet_aug_2006",
>> >                      "pet_sep_2006",
>> >                      "pet_oct_2006",
>> >                      "pet_nov_2006",
>> >                      "pet_dec_2006",
>> >                      "pet_jan_2007",
>> >                      "pet_feb_2007",
>> >                      "pet_mar_2007",
>> >                      "pet_apr_2007",
>> >                      "pet_may_2007",
>> >                      "pet_jun_2007",
>> >                      "pet_jul_2007",
>> >                      "pet_aug_2007",
>> >                      "pet_sep_2007",
>> >                      "pet_oct_2007",
>> >                      "pet_nov_2007",
>> >                      "pet_dec_2007",
>> >                      "pet_jan_2008",
>> >                      "pet_feb_2008",
>> >                      "pet_mar_2008",
>> >                      "pet_apr_2008",
>> >                      "pet_may_2008",
>> >                      "pet_jun_2008",
>> >                      "pet_jul_2008",
>> >                      "pet_aug_2008",
>> >                      "pet_sep_2008",
>> >                      "pet_oct_2008",
>> >                      "pet_nov_2008",
>> >                      "pet_dec_2008",
>> >                      "pet_jan_2009",
>> >                      "pet_feb_2009",
>> >                      "pet_mar_2009",
>> >                      "pet_apr_2009",
>> >                      "pet_may_2009",
>> >                      "pet_jun_2009",
>> >                      "pet_jul_2009",
>> >                      "pet_aug_2009",
>> >                      "pet_sep_2009",
>> >                      "pet_oct_2009",
>> >                      "pet_nov_2009",
>> >                      "pet_dec_2009",
>> >                      "pet_jan_2010",
>> >                      "pet_feb_2010",
>> >                      "pet_mar_2010",
>> >                      "pet_apr_2010",
>> >                      "pet_may_2010",
>> >                      "pet_jun_2010",
>> >                      "pet_jul_2010",
>> >                      "pet_aug_2010",
>> >                      "pet_sep_2010",
>> >                      "pet_oct_2010",
>> >                      "pet_nov_2010",
>> >                      "pet_dec_2010")
>> >
>> >
>> > options(width = 110)
>> > head(na.omit(tmp.df02, 20))
>> >
>> > dim(na.omit(tmp.df02))
>> >
>> > csvfile <- "cru_tmp_2.csv"
>> > write.table(na.omit(tmp.df02), csvfile, row.names = FALSE, sep = ",")
>> >
>> >
>> >
>> > *2) translate a cvs-file with accompanying raster file to polygon
>> regions.*
>> >
>> > The  "filename.txt" file should contain the variables: lon, latitude,
>> and
>> > all the monthly_yearly variables extracted from point 1 above.
>> >
>> > The grid shapefile (*grid_025dd.shp*) can be found through the following
>> > link but it is only an example and not the correct grid for the problem
>> > above :
>> >
>> >
>> https://drive.google.com/folderview?id=0By9u5m3kxn9yfjZtdFZLcW82SWpzT1VwZXE1a3FtRGtSdEl1c1NvY205TGpack9xSFc2T2s&usp=sharing
>> >
>> > # upload data
>> > mydata<-read.table("filename.txt", header=TRUE,sep=",",dec=".")
>> >
>> >
>> > # upload empty raster
>> > library(rgdal)
>> > # 40 seconds
>> > grid <- readOGR(".", layer = "grid_025dd")
>> >
>> >
>> > # concatenate data in R
>> > # 2 seconds
>> > mydata$lonlat<-do.call(paste, c(mydata[c("lon", "lat")], sep=""))
>> > grid at data$lonlat<-do.call(paste, c(grid at data[c("LONGITUDE",
>> "LATITUDE")],
>> > sep=""))
>> >
>> > # use common variable lonlat to merge data in raster
>> >
>> > ###### prepare shapefile #####
>> > library(rgdal)        ## Load geographic info
>> > library(maps)         ## Projections
>> > library(maptools)     ## Data management
>> > #library(sm)           ## Data management
>> > library(spdep)        ## Spatial autocorrelation
>> > library(gstat)        ## Geostatistics
>> > library(splancs)      ## Kernel Density
>> > library(spatstat)     ## Geostatistics
>> > library(pgirmess)     ## Spatial autocorrelation
>> > library(RColorBrewer) ## Visualization
>> > library(classInt)     ## Class intervals
>> > library(spgwr)        ## GWR
>> >
>> > # Match polygons with data
>> > idx <- match(grid$lonlat, mydata$lonlat)
>> > # Places without information
>> > idxNA <- which(is.na(idx))
>> > # Information to be added to the SpatialPolygons object
>> > dat2add <- mydata[idx, ]
>> > # spCbind uses row names to match polygons with data
>> > # First, extract polygon IDs
>> > IDs <- sapply(grid at polygons, function(x)x at ID)
>> > # and join with the SpatialPolygons
>> > row.names(dat2add) <- IDs
>> > datPols <- spCbind(grid, dat2add)
>> > # Drop those places without information
>> > datPols <- datPols[-idxNA, ]
>> > # write new shapefile
>> > # 7 seconds
>> > writeOGR(datPols, dsn = ".", layer ='sm2000eu28', driver = 'ESRI
>> > Shapefile')
>> > # read new shapefile
>> > # 51 seconds
>> > data <- readOGR(".", layer="sm2000eu28")
>> >
>> > ############################
>> > # intersect nuts with grid #
>> > ############################
>> >
>> > library(rgdal)
>> > nuts <- readOGR(".", layer = "NUTS_RG_60M_2006")
>> >
>> > library(rgeos)
>> > proj4string(data) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84")
>> >
>> >
>> > #
>> > grid <- data
>> > grid at data$lonlat <- NULL
>> > grid at data$lonlat_1 <- NULL
>> > grid at data$ID <- NULL
>> > grid at data$lat <- NULL
>> > grid at data$lon <- NULL
>> > grid at data$ELEVATION <- NULL
>> > grid at data$DAYS_RAIN_ <- NULL
>> >
>> >
>> > # First find out which grid cells intersect your NUTS polygons
>> > grid_nuts <- gIntersects(grid,nuts,byid = TRUE)
>> >
>> > # use the apply() function to calculate the mean, min, and max of your
>> > value.
>> > # The loop makes
>> >
>> > for(i in names(grid at data)){
>> >   nuts at data[[paste(i, 'average_value', sep="_")]] <-
>> > apply(grid_nuts,1,function(x) mean(grid at data[[i]][x]))
>> >   nuts at data[[paste(i, 'min_value', sep="_")]] <-
>> > apply(grid_nuts,1,function(x) min(grid at data[[i]][x]))
>> >   nuts at data[[paste(i, 'max_value', sep="_")]] <-
>> > apply(grid_nuts,1,function(x) max(grid at data[[i]][x]))
>> > }
>> >
>> > write.table(nuts at data, "nuts_sm2000eu28_unweighted.txt", sep="\t")
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-Geo mailing list
>> > R-sig-Geo at r-project.org
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >
>> >
>> > We value your opinion. Please take a few minutes to share your comments
>> on
>> > the service you received from the District by clicking on this link<
>> >
>> http://my.sfwmd.gov/portal/page/portal/pg_grp_surveysystem/survey%20ext?pid=1653
>> > >.
>> >
>>
>>
>>
>> --
>>
>> [image: Logo UHasselt] Mevrouw Janka Vanschoenwinkel
>> *Doctoraatsbursaal - PhD *
>> Milieueconomie - Environmental economics
>>
>> T +32(0)11 26 86 96 | GSM +32(0)476 28 21 40
>>
>> www.uhasselt.be/eec
>>
>> Universiteit Hasselt | Campus Diepenbeek
>> Agoralaan Gebouw D | B-3590 Diepenbeek
>> Kantoor F11
>>
>> Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt
>>
>>
>> [image: Music For Life]  Maak van UHasselt de #warmsteunief |
>> www.uhasselt.be/musicforlife
>>
>>
>> P Please consider the environment before printing this e-mail
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
>


-- 

[image: Logo UHasselt] Mevrouw Janka Vanschoenwinkel
*Doctoraatsbursaal - PhD *
Milieueconomie - Environmental economics

T +32(0)11 26 86 96 | GSM +32(0)476 28 21 40

www.uhasselt.be/eec

Universiteit Hasselt | Campus Diepenbeek
Agoralaan Gebouw D | B-3590 Diepenbeek
Kantoor F11

Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt


[image: Music For Life]  Maak van UHasselt de #warmsteunief |
www.uhasselt.be/musicforlife


P Please consider the environment before printing this e-mail

	[[alternative HTML version deleted]]


From genoveva.gonzalez-mirelis at imr.no  Sat Apr 30 12:32:54 2016
From: genoveva.gonzalez-mirelis at imr.no (Gonzalez-Mirelis Genoveva)
Date: Sat, 30 Apr 2016 10:32:54 +0000
Subject: [R-sig-Geo] problem with predict() in package raster and factor
	variables
Message-ID: <1462012372564.1868@imr.no>

Dear list,
I am trying to use the function predict() (in package raster), where I supply: the new data as a RasterBrick, the model (as fit in previous steps and using a different dataset), and a few more arguments including the levels of my only one categorical value. Here is the code I'm using:

 r1 <- predict(subbrick,
              CIF.pa,
              type="response", OOB=T, factors=f)

But I keep getting the following error:

Error in checkData(oldData, RET) :

  Classes of new data do not match original data

Here are more details:

> CIF.pa

         Random Forest using Conditional Inference Trees

Number of trees:  1000

Response:  PA
Inputs:  bathy20_1, TerClass, Smax_ann, Smean_ann, Smin_ann, SPDmax_ann, SPDmean_ann, Tmax_ann, Tmean_ann, Tmin_ann
Number of observations:  986

Where 'TerClass' is a categorical variable.

Here is the data used to train CIF.pa:


> str(v)

'data.frame':   1257 obs. of  15 variables:

 $ RefNo      : int  16 16 16 16 17 17 17 17 18 18 ...

 $ PointID    : int  1 2 3 4 5 6 7 8 9 10 ...

 $ Count      : int  0 0 0 0 0 0 0 0 0 0 ...

 $ PA         : int  0 0 0 0 0 0 0 0 0 0 ...

 $ split      : chr  "T" "T" "T" "T" ...

 $ bathy20_1  : num  256 260 252 266 281 ...

 $ TerClass   : num  2 2 1 1 1 2 1 1 3 3 ...

 $ Smax_ann   : num  35.1 35.1 35.1 35.1 35.1 ...

 $ Smean_ann  : num  35.1 35.1 35.1 35.1 35.1 ...

 $ Smin_ann   : num  34.9 34.9 34.9 34.9 35 ...

 $ SPDmax_ann : num  0.379 0.376 0.378 0.372 0.352 ...

 $ SPDmean_ann: num  0.14 0.137 0.14 0.132 0.12 ...

 $ Tmax_ann   : num  6.97 6.92 7.04 6.87 6.68 ...

 $ Tmean_ann  : num  5.76 5.73 5.79 5.71 5.54 ...

 $ Tmin_ann   : num  4.41 4.32 4.52 4.25 4.07 ...



But actually, I used a subset of v to train the model, that where v$split=='T'

Below are the values and class for TerClass for that subset



> unique(v[v$split=='T',7])

[1] 2 1 3 4 6 5

> class(v$TerClass)

[1] "numeric"

And below are the values and class for the corresponding layer of the RasterBrick:

> unique(values(subbrick$TerClass))

[1] 3 1 2 4 5 6

> class(values(subbrick$TerClass))

[1] "numeric"

And finally, here is what f looks like:


> f
$TerClass
[1] 2 1 3 4 6 5

> class(f)
[1] "list"


As far as I can see the classes in OldData and NewData should be the same, but the error persists. Any ideas on what I could be missing?

Unfortunately I am unable to reproduce the problem (I only encounter it when using my data), but any help will be hugely appreciated

Also, I am aware that I asked this question before (Apr 04, 2013; 1:22pm). Unfortunately I haven't gotten very far since then!

Many thanks in advance for any pointers.

Genoveva


