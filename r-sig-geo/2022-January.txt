From b@@||e@|enorm@nd @end|ng |rom protonm@||@com  Mon Jan  3 01:49:33 2022
From: b@@||e@|enorm@nd @end|ng |rom protonm@||@com (basile.lenormand)
Date: Mon, 03 Jan 2022 00:49:33 +0000
Subject: [R-sig-Geo] leaflet in shiny error message
Message-ID: <qdUNnkgf98u86-_wu1ShZGxNiyWu1JqtBlahiHURDE7-TEoaUaf9d42M7qZiV5aP_9j-oAp4Mj7XPSHDnAtT3M3pNFECucT0-oGFvZD6x4U=@protonmail.com>

Hello everyone!

I am trying to create a shiny app with leaflet stuff in it. I have a problem when I am displaying the application, I got this error message :

"Error in dispatch: argument "map" is missing, with no default".

I searched some clues on the net, I found some examples which are working but I do not get where I going wrong. I double checked the brackets, try to change the name of the map, put the name of the spatial data frame that I am using, etc.

If someone can give me some clues I will be really glad.
Have a great day,
thank you for your time,
Basile.

Here is my code:

ui <- fluidPage(
titlePanel(""),

sidebarLayout(
sidebarPanel(
helpText(""),

selectInput("var",
label = "Choose a variable to display",
choices = spdf$koppen,
selected = ""
),
sliderInput("range", "surface br?l?e en hectare", min(spdf$V11), max(spdf$V11),
value = range(df$V11), step = 2500
),
sliderInput("range", "Nombre d'incendie", min(spdf$n), max(spdf$n),
value = range(df$V11), step = 2
),
checkboxInput("legend", "Show legend", TRUE)),
mainPanel(leafletOutput("map"))
)
)

server <- function(input, output, session) {
output$map <- renderLeaflet({
leaflet(df) %>%
addTiles(group = "OSM") %>%
addProviderTiles("Esri.NatGeoWorldMap", group="ESRI") %>%
addProviderTiles("CartoDB.DarkMatter", group= "CartoDB") %>%
#fitBounds(~min(long), ~min(lat), ~max(long), ~max(lat))%>%
addPolygons(
data=spdf,
fillColor = "viridis",
weight = 0,
opacity = 1,
color = "white",
dashArray = "3",
fillOpacity = 0.7)#%>%
setView(lat= 44.2, lng=5.9, zoom=5)
})
}
shinyApp(ui, server)

Sent with [ProtonMail](https://protonmail.com) Secure Email.
	[[alternative HTML version deleted]]


From b|@|ev||@t @end|ng |rom gm@||@com  Mon Jan  3 09:22:19 2022
From: b|@|ev||@t @end|ng |rom gm@||@com (=?UTF-8?Q?Bede-Fazekas_=c3=81kos?=)
Date: Mon, 3 Jan 2022 09:22:19 +0100
Subject: [R-sig-Geo] leaflet in shiny error message
In-Reply-To: <qdUNnkgf98u86-_wu1ShZGxNiyWu1JqtBlahiHURDE7-TEoaUaf9d42M7qZiV5aP_9j-oAp4Mj7XPSHDnAtT3M3pNFECucT0-oGFvZD6x4U=@protonmail.com>
References: <qdUNnkgf98u86-_wu1ShZGxNiyWu1JqtBlahiHURDE7-TEoaUaf9d42M7qZiV5aP_9j-oAp4Mj7XPSHDnAtT3M3pNFECucT0-oGFvZD6x4U=@protonmail.com>
Message-ID: <0b88935c-a7dc-1325-6510-795ec523c394@gmail.com>

Dear Basile,

the %>% operator is accidentally commented out! Change
fillOpacity = 0.7)#%>%
to
fillOpacity = 0.7) %>%
and then setView() will get its first parameter called "map".

HTH,
?kos Bede-Fazekas
Centre for Ecological Research, Hungary

2022.01.03. 1:49 keltez?ssel, basile.lenormand via R-sig-Geo ?rta:
> Hello everyone!
>
> I am trying to create a shiny app with leaflet stuff in it. I have a problem when I am displaying the application, I got this error message :
>
> "Error in dispatch: argument "map" is missing, with no default".
>
> I searched some clues on the net, I found some examples which are working but I do not get where I going wrong. I double checked the brackets, try to change the name of the map, put the name of the spatial data frame that I am using, etc.
>
> If someone can give me some clues I will be really glad.
> Have a great day,
> thank you for your time,
> Basile.
>
> Here is my code:
>
> ui <- fluidPage(
> titlePanel(""),
>
> sidebarLayout(
> sidebarPanel(
> helpText(""),
>
> selectInput("var",
> label = "Choose a variable to display",
> choices = spdf$koppen,
> selected = ""
> ),
> sliderInput("range", "surface br?l?e en hectare", min(spdf$V11), max(spdf$V11),
> value = range(df$V11), step = 2500
> ),
> sliderInput("range", "Nombre d'incendie", min(spdf$n), max(spdf$n),
> value = range(df$V11), step = 2
> ),
> checkboxInput("legend", "Show legend", TRUE)),
> mainPanel(leafletOutput("map"))
> )
> )
>
> server <- function(input, output, session) {
> output$map <- renderLeaflet({
> leaflet(df) %>%
> addTiles(group = "OSM") %>%
> addProviderTiles("Esri.NatGeoWorldMap", group="ESRI") %>%
> addProviderTiles("CartoDB.DarkMatter", group= "CartoDB") %>%
> #fitBounds(~min(long), ~min(lat), ~max(long), ~max(lat))%>%
> addPolygons(
> data=spdf,
> fillColor = "viridis",
> weight = 0,
> opacity = 1,
> color = "white",
> dashArray = "3",
> fillOpacity = 0.7)#%>%
> setView(lat= 44.2, lng=5.9, zoom=5)
> })
> }
> shinyApp(ui, server)
>
> Sent with [ProtonMail](https://protonmail.com) Secure Email.
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From b@@||e@|enorm@nd @end|ng |rom protonm@||@com  Mon Jan  3 11:18:31 2022
From: b@@||e@|enorm@nd @end|ng |rom protonm@||@com (basile.lenormand)
Date: Mon, 03 Jan 2022 10:18:31 +0000
Subject: [R-sig-Geo] leaflet in shiny error message
In-Reply-To: <0b88935c-a7dc-1325-6510-795ec523c394@gmail.com>
References: <qdUNnkgf98u86-_wu1ShZGxNiyWu1JqtBlahiHURDE7-TEoaUaf9d42M7qZiV5aP_9j-oAp4Mj7XPSHDnAtT3M3pNFECucT0-oGFvZD6x4U=@protonmail.com>
 <0b88935c-a7dc-1325-6510-795ec523c394@gmail.com>
Message-ID: <yP-33A-FB1difY7mHUJ7XrnOywYf0ZpNkz47V9f9TftdsNyBzxuyprMybeusTvjb3mbu5juhKpE1ON76kK6JaY3-eoZDyLiBSb7X_zLOcvg=@protonmail.com>

Thank you ?kos!
It works!
Have a great day!
Basile.


Sent with ProtonMail Secure Email.

??????? Original Message ???????
On Monday 3 January 2022 09:22, Bede-Fazekas ?kos <bfalevlist at gmail.com> wrote:

> Dear Basile,
>
> the %>% operator is accidentally commented out! Change
> fillOpacity = 0.7)#%>%
> to
> fillOpacity = 0.7) %>%
> and then setView() will get its first parameter called "map".
>
> HTH,
> ?kos Bede-Fazekas
> Centre for Ecological Research, Hungary
>
> 2022.01.03. 1:49 keltez?ssel, basile.lenormand via R-sig-Geo ?rta:
>
> > Hello everyone!
> > I am trying to create a shiny app with leaflet stuff in it. I have a problem when I am displaying the application, I got this error message :
> > "Error in dispatch: argument "map" is missing, with no default".
> > I searched some clues on the net, I found some examples which are working but I do not get where I going wrong. I double checked the brackets, try to change the name of the map, put the name of the spatial data frame that I am using, etc.
> > If someone can give me some clues I will be really glad.
> > Have a great day,
> > thank you for your time,
> > Basile.
> > Here is my code:
> > ui <- fluidPage(
> > titlePanel(""),
> > sidebarLayout(
> > sidebarPanel(
> > helpText(""),
> > selectInput("var",
> > label = "Choose a variable to display",
> > choices = spdf$koppen,
> > selected = ""
> > ),
> > sliderInput("range", "surface br?l?e en hectare", min(spdf$V11), max(spdf$V11),
> > value = range(df$V11), step = 2500
> > ),
> > sliderInput("range", "Nombre d'incendie", min(spdf$n), max(spdf$n),
> > value = range(df$V11), step = 2
> > ),
> > checkboxInput("legend", "Show legend", TRUE)),
> > mainPanel(leafletOutput("map"))
> > )
> > )
> > server <- function(input, output, session) {
> > output$map <- renderLeaflet({
> > leaflet(df) %>%
> > addTiles(group = "OSM") %>%
> > addProviderTiles("Esri.NatGeoWorldMap", group="ESRI") %>%
> > addProviderTiles("CartoDB.DarkMatter", group= "CartoDB") %>%
> > #fitBounds(~min(long), ~min(lat), ~max(long), ~max(lat))%>%
> > addPolygons(
> > data=spdf,
> > fillColor = "viridis",
> > weight = 0,
> > opacity = 1,
> > color = "white",
> > dashArray = "3",
> > fillOpacity = 0.7)#%>%
> > setView(lat= 44.2, lng=5.9, zoom=5)
> > })
> > }
> > shinyApp(ui, server)
> > Sent with ProtonMail Secure Email.
> > [[alternative HTML version deleted]]
> >
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From b@@||e@|enorm@nd @end|ng |rom protonm@||@com  Mon Jan  3 13:35:49 2022
From: b@@||e@|enorm@nd @end|ng |rom protonm@||@com (basile.lenormand)
Date: Mon, 03 Jan 2022 12:35:49 +0000
Subject: [R-sig-Geo] reactive map on shiny
Message-ID: <SinqyrbY1BCpFM0HR_VwzvQzXM4s3QpMnrK3mqj_85NbDVh5M5UbeT-bXjBgsfe1t7BgFmYkSb8B8KoSzmp7lp202z7rvVB-8x2fKooIXqA=@protonmail.com>

It is me again, sorry I am a bit lost.

I am trying to make my polygones reacting to my widgets. But I do not find how to make polygones react to sliders. I reached to do it for the second slider, but not for the others widgets. I do not reach to display the checkbox legend neither.

I do not understand when I have to use reactives, also I do not find the function that plot the output of the widget for the observer on the map. Do I have to use renderPlot?

If you got some time I would be pleased,
have a great day,
Basile

Here is my code:

ui <- bootstrapPage(
titlePanel("Incendie en PACA ? l'?chelle des communes"),
sidebarLayout(

sidebarPanel(
helpText("Cr?ez votre propre visualisation du risque"),
selectInput("climate",
label = "Choose a variable to display",
choices = spdf$koppen,
selected = "Csa_Clipped"),
sliderInput("range1", "surface br?l?e en hectare", min(spdf$V11), max(spdf$V11),
value = range(spdf$V11), step = 2500),
sliderInput("range2", "Nombre d'incendie", min(spdf$n), max(spdf$n),
value = range(spdf$n), step = 2),
checkboxInput("legend", "Show legend", TRUE)),

mainPanel(
textOutput("selected_var"),
leafletOutput("map",width = 600, height = 300)),
)
)

server <- function(input, output, session) {

output$map <-renderLeaflet({
leaflet() %>%
addTiles(group = "OSM") %>%
#fitBounds(~min(long), ~min(lat), ~max(long), ~max(lat))%>%
addPolygons(
data=my_summary_84,
fillColor =~colorQuantile("YlOrRd", spdfV11),
fillOpacity = 0.7,
popup = ~Nom_Commun) %>%
setView(lat= 44.2, lng=5.9, zoom=5)
})

df_filtered <- reactive({
spdf[spdf >= input$range2, ]
})

observe({
leafletProxy(mapId = "map", data = df_filtered()) %>%
clearShapes() %>% ## clear previous markers
addPolygons()
})

}
shinyApp(ui, server)

Sent with [ProtonMail](https://protonmail.com) Secure Email.
	[[alternative HTML version deleted]]


From m@rt|n@hu|eny| @end|ng |rom gm@||@com  Mon Jan  3 17:04:07 2022
From: m@rt|n@hu|eny| @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_Hul=C3=A9nyi?=)
Date: Mon, 3 Jan 2022 17:04:07 +0100
Subject: [R-sig-Geo] Question about spatial filtering
Message-ID: <CAOfb+wpC7_B4yeidy8uVhTbWnEX=Bfnqrom2vF0e6rtQ3aZTVQ@mail.gmail.com>

Dear all,

I am thinking of applying spatial filetring to panel data model. Therefore
I would like to ask if you might know of some packages/codes or any other
resources for panel data that I could apply for my analysis.

Best,

Martin Hulenyi

	[[alternative HTML version deleted]]


From Roger@B|v@nd @end|ng |rom nhh@no  Tue Jan  4 11:07:19 2022
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Tue, 4 Jan 2022 11:07:19 +0100 (CET)
Subject: [R-sig-Geo] Question about spatial filtering
In-Reply-To: <CAOfb+wpC7_B4yeidy8uVhTbWnEX=Bfnqrom2vF0e6rtQ3aZTVQ@mail.gmail.com>
References: <CAOfb+wpC7_B4yeidy8uVhTbWnEX=Bfnqrom2vF0e6rtQ3aZTVQ@mail.gmail.com>
Message-ID: <74593848-f7e7-5c69-f768-4a273d532751@reclus2.nhh.no>

On Mon, 3 Jan 2022, Martin Hul?nyi wrote:

> Dear all,
>
> I am thinking of applying spatial filetring to panel data model. Therefore
> I would like to ask if you might know of some packages/codes or any other
> resources for panel data that I could apply for my analysis.

It might be worth looking at the spmoran package (not panel, but under 
active development). You can also look at adespatial for PCNM. In general, 
the eigenvectors for the time-invariant neighbour object are also 
time-invariant, unless your panel model is dynamic. Also find examples in 
the literature and see whether they provide references or links to 
software, for example but without direct software references:
https://research.vu.nl/ws/portalfiles/portal/73350412/06049, 
https://doi.org/10.1177%2F0160017610386482. 
https://scholar.google.no/scholar?oi=bibs&hl=en&cites=15767057313182942537&as_sdt=5 
gives citations of Patuelli et al. (2011).

Hope this helps,

Roger

>
> Best,
>
> Martin Hulenyi
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&amp;data=04%7C01%7CRoger.Bivand%40nhh.no%7C6c9307111ec74c16969508d9ced2d73b%7C33a15b2f849941998d56f20b5aa91af2%7C0%7C0%7C637768228115992524%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=jqOHHKrl6SxZ441roWZNQKU5hTtS76nZFJ%2FEL56xGRI%3D&amp;reserved=0
>

-- 
Roger Bivand
Emeritus Professor
Department of Economics, Norwegian School of Economics,
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From e@te@rn@88 @end|ng |rom gm@||@com  Tue Jan  4 18:15:07 2022
From: e@te@rn@88 @end|ng |rom gm@||@com (Erin Stearns)
Date: Tue, 4 Jan 2022 12:15:07 -0500
Subject: [R-sig-Geo] EBlocal() returning NaN values
Message-ID: <CAFf5Nh-p-2JAarFg9Mrt8yZ5r=0CzhGjZHPKYP5BmU3dJh+uhg@mail.gmail.com>

 Hello R-sig-Geo friends & happy 2022!

Running EBlocal() on US county sf dataset and getting NaN values where
Empirical Bayes and a BYM model are returning values and I do not
understand why. Additionally, does anyone know how to examine the parameters
attribute list from the output of the EBlocal() function? I have not been
able to look at this and perhaps that would be informative.


*Function call:*
seb_icu <- EBlocal(thedata$icu_bed_avg, thedata$over18pop, nb = nb,
zero.policy = TRUE)

*Environment details:*
  OS: Windows 10 x64
  R Version: 4.1.1
     spdep version: 1.1-11
     sf version   : 1.0-3

Full dataset and code to reproduce can be found for download here.
<https://app.box.com/s/r26ta0gl9avwlwm65ivtze7j97hyw8i7>

Thank you in advance for your help!

Best,
Erin

	[[alternative HTML version deleted]]


From Roger@B|v@nd @end|ng |rom nhh@no  Wed Jan  5 21:14:27 2022
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Wed, 5 Jan 2022 21:14:27 +0100 (CET)
Subject: [R-sig-Geo] EBlocal() returning NaN values
In-Reply-To: <CAFf5Nh-p-2JAarFg9Mrt8yZ5r=0CzhGjZHPKYP5BmU3dJh+uhg@mail.gmail.com>
References: <CAFf5Nh-p-2JAarFg9Mrt8yZ5r=0CzhGjZHPKYP5BmU3dJh+uhg@mail.gmail.com>
Message-ID: <ad53527d-837-942b-2887-6bff7a8dcf56@reclus2.nhh.no>

On Tue, 4 Jan 2022, Erin Stearns wrote:

> Hello R-sig-Geo friends & happy 2022!
>
> Running EBlocal() on US county sf dataset and getting NaN values where
> Empirical Bayes and a BYM model are returning values and I do not
> understand why. Additionally, does anyone know how to examine the parameters
> attribute list from the output of the EBlocal() function? I have not been
> able to look at this and perhaps that would be informative.
>

Yes, you are right:

summary(attr(seb_icu, "parameters")$a)
summary(attr(seb_icu, "parameters")$m)

which(attr(seb_icu, "parameters")$a == 0 &
  attr(seb_icu, "parameters")$m == 0)
which(is.nan(seb_icu$est))

showing that the NaNs are caused by a division by zero:

est <- m.i + (xi - m.i) * (a.i / (a.i + (m.i/ni)))

In fact, if m.i and C.i (see Marshall's paper) are both zero, a.i becomes 
zero, and leads to the division by zero. The underlying reason is that 
Marshall never tested a setting where many ri are zero, so the count of 
cases in a small neighbourhood of neighbouring counties was almost never 
zero:

> table(thedata$icu_bed_avg == 0)

FALSE  TRUE
  1437  1783

Had tests been done on > 50% cases, the problem would have been detected, 
but probably not resolved, as the issue is with entitation - .

The same counties have NaNs if those with no neighbours are dropped (less 
the no-neighbour counties), so this is not caused by assuming that the 
lagged value of an entity with no neighbours is zero.

To get closer to the original paper, probably counties should be 
aggregated to reduce the number with no cases, and so meet the underlying 
assumptions.

Hope this helps,

Roger

>
> *Function call:*
> seb_icu <- EBlocal(thedata$icu_bed_avg, thedata$over18pop, nb = nb,
> zero.policy = TRUE)
>
> *Environment details:*
>  OS: Windows 10 x64
>  R Version: 4.1.1
>     spdep version: 1.1-11
>     sf version   : 1.0-3
>
> Full dataset and code to reproduce can be found for download here.
> <https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fapp.box.com%2Fs%2Fr26ta0gl9avwlwm65ivtze7j97hyw8i7&amp;data=04%7C01%7CRoger.Bivand%40nhh.no%7Ca717ef6fd6574eb6a40a08d9cfa5d91d%7C33a15b2f849941998d56f20b5aa91af2%7C0%7C0%7C637769134198352241%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=LJEJ3SgKe0wEzD21Re3%2B4Jfl5LpSD6SpDFYPzsFP7HE%3D&amp;reserved=0>
>
> Thank you in advance for your help!
>
> Best,
> Erin
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&amp;data=04%7C01%7CRoger.Bivand%40nhh.no%7Ca717ef6fd6574eb6a40a08d9cfa5d91d%7C33a15b2f849941998d56f20b5aa91af2%7C0%7C0%7C637769134198352241%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=l%2B5AwZrspCXeHPlJh1C61SSMHv6p7UacEYMvqSK4Gaw%3D&amp;reserved=0
>

-- 
Roger Bivand
Emeritus Professor
Department of Economics, Norwegian School of Economics,
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway.
e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From g|u@eppe@@m@tu||| @end|ng |rom gm@||@com  Thu Jan 20 16:22:22 2022
From: g|u@eppe@@m@tu||| @end|ng |rom gm@||@com (Giuseppe Amatulli)
Date: Thu, 20 Jan 2022 10:22:22 -0500
Subject: [R-sig-Geo] Course: Geocomputation and Machine Learning for
 Environmental Applications.
Message-ID: <CAKoiDH+wWXttGibtfUp2+GHw_t6coy2e_Zv0NNDS-Z0Fb=vbtA@mail.gmail.com>

Dear Colleagues,

In view of enhancing computation skills in the geographic domain, Spatial
Ecology <http://spatial-ecology.net/>  is organising a two-month training
course: Geocomputation and Machine Learning for Environmental Applications
<http://spatial-ecology.net/geocomp_ml_2022-announcement/>.

The course will be offered on-line with a supplementary 5-day in-person
segment at the University of Basilicata, in the magnificent town of Matera
<https://www.google.com/maps/place/75100+Matera,+Province+of+Matera,+Italy/@40.6646012,16.5651092,13z/data=!3m1!4b1!4m5!3m4!1s0x13477ee2482b152b:0x8f6a4ae10da9360!8m2!3d40.666379!4d16.6043199>,
Italy. This is a wonderful opportunity for PhD students, Post-Docs and
professionals to acquire advanced computational skills with a Linux
computer.

Please forward to announce this opportunity within your network.

Sincerely, Giuseppe Amatulli  & Spatial Ecology ? Team

*Geocomputation and Machine Learning for Environmental Applications
<http://spatial-ecology.net/geocomp_ml_2022-announcement/>.** (April, May,
June, 2022)*

In this course, students will be introduced to an array of powerful
open-source geocomputation tools and machine learning methodologies under
Linux environment. Students who have never been exposed to programming
under Linux are expected to reach the stage where they feel confident in
using very advanced open source data processing routines. Students with a
precedent programming background will find the course beneficial in
enhancing their programming skills for better modelling and coding
proficiency. Our dual teaching aim is to equip attendees with powerful
tools as well as rendering their abilities of continuing independent
development afterwards. The acquired skills will be beneficial, not only
for GIS related application, but also for general data processing and
applied statistical computing in a number of fields. These essentially lay
the foundation for career development as a data scientist in the geographic
domain.

More information and registration:

www.spatial-ecology.net
twitter: @BigDataEcology

-- 
Giuseppe Amatulli, Ph.D.

Research scientist at
School of the Environment
Yale University
New Haven, CT, USA - 06511
Tweeter: @BigDataEcology
Teaching: http://spatial-ecology.net
Work:  https://environment.yale.edu/profile/giuseppe-amatulli/

	[[alternative HTML version deleted]]


From t|m@how@rd @end|ng |rom dec@ny@gov  Thu Jan 20 17:43:00 2022
From: t|m@how@rd @end|ng |rom dec@ny@gov (Howard, Tim G (DEC))
Date: Thu, 20 Jan 2022 16:43:00 +0000
Subject: [R-sig-Geo] model predict in subset: compare terra and stars
In-Reply-To: <SA1PR09MB7792E6C83E36C1F40A9972B7A85A9@SA1PR09MB7792.namprd09.prod.outlook.com>
References: <SA1PR09MB7792E6C83E36C1F40A9972B7A85A9@SA1PR09MB7792.namprd09.prod.outlook.com>
Message-ID: <SA1PR09MB77927876E20B5457EEFA47DAA85A9@SA1PR09MB7792.namprd09.prod.outlook.com>

Dear all - 
Classically, if I want to create a spatial model and make a prediction for an area within the extent of my raster stack my approach would be to crop all predictor rasters to the area of interest and run the predict on that cropped set. The stars package opens up another option: to apply the crop/mask to the proxy object, which then will extract only the relevant cells from the full rasters when writing (or plotting) the result. At least that's how I understand it. 

The following example has both approaches and their timings. I borrowed heavily from https://r-spatial.github.io/stars/articles/stars7.html , other stars articles, and from the terra help pages! Questions below the example.

```
library(terra)
library(stars)
library(sf)
library(microbenchmark)

## setup
tif = system.file("tif/L7_ETMs.tif", package = "stars")
L7_orig = read_stars(tif, proxy = TRUE) %>% split()
# create a shape within which we will want to make the prediction
circle = st_sfc(st_buffer(st_point(c(293749.5, 9115745)), 600), crs = st_crs(L7_orig))
# simple set of points for training the model 
trainCoords <- data.frame(
? X = c(290050, 290100, 291700, 293000, 294500, 294600, 298000,
??????? 289500, 290100, 292500, 294000, 296000, 293600, 294800),
? Y = c(9117000, 9118500, 9117100, 9118000, 9112890, 9111700, 9120000,
??????? 9112700, 9114000, 9115700, 9118100, 9120000, 9111650, 9116000))

trainPts <- st_as_sf(x = trainCoords, coords = c("X","Y"), crs = st_crs(L7_orig))
trainAttr <- st_drop_geometry(st_as_sf(st_extract(L7_orig, trainPts)))
names(trainAttr) <- c("X1","X2","X3","X4","X5","X6")
trainAttr$pa <- c(rep(1,7), rep(0,7)) #add presence-absence attribute

# time both approaches
mbm <- microbenchmark("starsMethod" = {
? L7_orig_inside = read_stars(tif, proxy = TRUE) %>% split()
? st_model <- glm(formula=pa~.,data = trainAttr)
? L7_crop <- L7_orig_inside[circle]
? st_out = predict(L7_crop, st_model)
?# st_out is still a proxy with processing steps, writing it out forces those steps to be applied
? write_stars(st_out, file.path(tempdir(),"stars_prediction.tif"),overwrite = TRUE)
},
"terraMethod" = {
? ras = terra::rast(tif)
? # crop, mask, write out to temp dir
? c_ras <- terra::crop(ras, circle)
? msk <- rasterize(vect(circle), c_ras)
? maskRas <- file.path(tempdir(),"L7_ETMs_crop.tif")
? m_ras <- terra::mask(c_ras, msk, filename = maskRas, overwrite = TRUE)
? model <- glm(formula=pa~.,data = trainAttr)
? # read the cropped raster for predict (already in RAM, but this would be protocol)
? mras <- rast(maskRas)
? names(mras) <- c("X1","X2","X3","X4","X5","X6")
? terra_out <- predict(mras, model, filename = file.path(tempdir(),"terra_prediction.tif"), overwrite = TRUE)
}, times = 10)

# > mbm
# Unit: milliseconds
# expr????? min?????? lq???? mean?? median?????? uq????? max neval
# starsMethod 411.8035 442.4342 701.2864 505.4522 630.8252 1699.737??? 10
# terraMethod? 94.0480? 99.4800 560.6102 106.9317 132.1853 4207.067??? 1
```

As run above, using stars proxies takes a fair amount longer than cropping, saving, and predicting on the cropped rasters. I have found this to be the case for larger (more real-life) examples as well, to the level that for larger data sets and more predictors, I run out of RAM using stars proxies and that approach fails. 

Questions:
1. Am I missing something? Is there a more efficient way for running a model and predicting within a smaller area than the full extent of your predictors?
2. On the surface of things, I would have expected the proxy approach to be faster, especially if using COG rasters (which allow read by chunk, not line). I'm not seeing that here, nor with larger datasets. Any thoughts on the potential bottlenecks?

Thanks in advance, 
Tim



From r@h|jm@n@ @end|ng |rom gm@||@com  Fri Jan 21 07:21:14 2022
From: r@h|jm@n@ @end|ng |rom gm@||@com (Robert J. Hijmans)
Date: Thu, 20 Jan 2022 22:21:14 -0800
Subject: [R-sig-Geo] model predict in subset: compare terra and stars
In-Reply-To: <SA1PR09MB77927876E20B5457EEFA47DAA85A9@SA1PR09MB7792.namprd09.prod.outlook.com>
References: <SA1PR09MB7792E6C83E36C1F40A9972B7A85A9@SA1PR09MB7792.namprd09.prod.outlook.com>
 <SA1PR09MB77927876E20B5457EEFA47DAA85A9@SA1PR09MB7792.namprd09.prod.outlook.com>
Message-ID: <CANtt_hyYTg7eB46WrE_sNeJ6jadAEnqenQ9sJMzDAjeoOPJ03A@mail.gmail.com>

Hello everybody,
I cannot answer Tim's questions, but here is a way to do the terra bit much
faster, by not writing intermediate steps to disk.
Cheers, Robert

library(terra)
library(stars)
library(sf)
library(microbenchmark)

## setup
tif = system.file("tif/L7_ETMs.tif", package = "stars")
L7_orig = read_stars(tif, proxy = TRUE) %>% split()
# create a shape within which we will want to make the prediction
circle = st_sfc(st_buffer(st_point(c(293749.5, 9115745)), 600), crs =
st_crs(L7_orig))
# simple set of points for training the model
trainCoords <- data.frame(
  X = c(290050, 290100, 291700, 293000, 294500, 294600, 298000,
        289500, 290100, 292500, 294000, 296000, 293600, 294800),
  Y = c(9117000, 9118500, 9117100, 9118000, 9112890, 9111700, 9120000,
        9112700, 9114000, 9115700, 9118100, 9120000, 9111650, 9116000))

# model for stars
trainPts <- st_as_sf(x = trainCoords, coords = c("X","Y"), crs =
st_crs(L7_orig))
trainAttr <- st_drop_geometry(st_as_sf(st_extract(L7_orig, trainPts)))
names(trainAttr) <- c("X1","X2","X3","X4","X5","X6")
trainAttr$pa <- c(rep(1,7), rep(0,7)) #add presence-absence attribute
st_model <- glm(formula=pa~.,data = trainAttr)

# model for terra
ras = terra::rast(tif)
trainAttr2 <- extract(ras, trainCoords)[,-1]
trainAttr2$pa <- c(rep(1,7), rep(0,7))
model <- glm(formula=pa~.,data = trainAttr2)
vcircle <- vect(circle)

# time both approaches
mbm <- microbenchmark("starsMethod" = {
  L7_orig_inside = read_stars(tif, proxy = TRUE) %>% split()
  L7_crop <- L7_orig_inside[circle]
  st_out = predict(L7_crop, st_model)
 # st_out is still a proxy with processing steps, writing it out forces
those steps to be applied
  write_stars(st_out, file.path(tempdir(),"stars_prediction.tif"),overwrite
= TRUE)
},
"terraMethod" = {
  ras = terra::rast(tif)
  cras <- terra::crop(ras, vcircle)
  mras <- terra::mask(cras, vcircle)
  terra_out <- predict(mras, model, filename =
file.path(tempdir(),"terra_prediction.tif"), overwrite = TRUE)
}, times = 10)

mbm
#Unit: milliseconds
#        expr      min       lq      mean   median       uq      max neval
# starsMethod 225.4070 227.4722 230.86188 231.4848 233.9374 237.5687    10
# terraMethod  93.9507  96.0912  99.59111 100.0375 103.5670 104.1225    10


With terra you can use a window ("lazy crop")
  window(ras) <- ext(vcircle)
  mras <- terra::mask(ras, vcircle)
  # but this seems faster
  cras <- terra::crop(ras, vcircle)
  mras <- terra::mask(cras, vcircle)


On Thu, Jan 20, 2022 at 8:43 AM Howard, Tim G (DEC) via R-sig-Geo <
r-sig-geo at r-project.org> wrote:

> Dear all -
> Classically, if I want to create a spatial model and make a prediction for
> an area within the extent of my raster stack my approach would be to crop
> all predictor rasters to the area of interest and run the predict on that
> cropped set. The stars package opens up another option: to apply the
> crop/mask to the proxy object, which then will extract only the relevant
> cells from the full rasters when writing (or plotting) the result. At least
> that's how I understand it.
>
> The following example has both approaches and their timings. I borrowed
> heavily from https://r-spatial.github.io/stars/articles/stars7.html ,
> other stars articles, and from the terra help pages! Questions below the
> example.
>
> ```
> library(terra)
> library(stars)
> library(sf)
> library(microbenchmark)
>
> ## setup
> tif = system.file("tif/L7_ETMs.tif", package = "stars")
> L7_orig = read_stars(tif, proxy = TRUE) %>% split()
> # create a shape within which we will want to make the prediction
> circle = st_sfc(st_buffer(st_point(c(293749.5, 9115745)), 600), crs =
> st_crs(L7_orig))
> # simple set of points for training the model
> trainCoords <- data.frame(
>   X = c(290050, 290100, 291700, 293000, 294500, 294600, 298000,
>         289500, 290100, 292500, 294000, 296000, 293600, 294800),
>   Y = c(9117000, 9118500, 9117100, 9118000, 9112890, 9111700, 9120000,
>         9112700, 9114000, 9115700, 9118100, 9120000, 9111650, 9116000))
>
> trainPts <- st_as_sf(x = trainCoords, coords = c("X","Y"), crs =
> st_crs(L7_orig))
> trainAttr <- st_drop_geometry(st_as_sf(st_extract(L7_orig, trainPts)))
> names(trainAttr) <- c("X1","X2","X3","X4","X5","X6")
> trainAttr$pa <- c(rep(1,7), rep(0,7)) #add presence-absence attribute
>
> # time both approaches
> mbm <- microbenchmark("starsMethod" = {
>   L7_orig_inside = read_stars(tif, proxy = TRUE) %>% split()
>   st_model <- glm(formula=pa~.,data = trainAttr)
>   L7_crop <- L7_orig_inside[circle]
>   st_out = predict(L7_crop, st_model)
>  # st_out is still a proxy with processing steps, writing it out forces
> those steps to be applied
>   write_stars(st_out,
> file.path(tempdir(),"stars_prediction.tif"),overwrite = TRUE)
> },
> "terraMethod" = {
>   ras = terra::rast(tif)
>   # crop, mask, write out to temp dir
>   c_ras <- terra::crop(ras, circle)
>   msk <- rasterize(vect(circle), c_ras)
>   maskRas <- file.path(tempdir(),"L7_ETMs_crop.tif")
>   m_ras <- terra::mask(c_ras, msk, filename = maskRas, overwrite = TRUE)
>   model <- glm(formula=pa~.,data = trainAttr)
>   # read the cropped raster for predict (already in RAM, but this would be
> protocol)
>   mras <- rast(maskRas)
>   names(mras) <- c("X1","X2","X3","X4","X5","X6")
>   terra_out <- predict(mras, model, filename =
> file.path(tempdir(),"terra_prediction.tif"), overwrite = TRUE)
> }, times = 10)
>
> # > mbm
> # Unit: milliseconds
> # expr      min       lq     mean   median       uq      max neval
> # starsMethod 411.8035 442.4342 701.2864 505.4522 630.8252 1699.737    10
> # terraMethod  94.0480  99.4800 560.6102 106.9317 132.1853 4207.067    1
> ```
>
> As run above, using stars proxies takes a fair amount longer than
> cropping, saving, and predicting on the cropped rasters. I have found this
> to be the case for larger (more real-life) examples as well, to the level
> that for larger data sets and more predictors, I run out of RAM using stars
> proxies and that approach fails.
>
> Questions:
> 1. Am I missing something? Is there a more efficient way for running a
> model and predicting within a smaller area than the full extent of your
> predictors?
> 2. On the surface of things, I would have expected the proxy approach to
> be faster, especially if using COG rasters (which allow read by chunk, not
> line). I'm not seeing that here, nor with larger datasets. Any thoughts on
> the potential bottlenecks?
>
> Thanks in advance,
> Tim
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From t|m@how@rd @end|ng |rom dec@ny@gov  Fri Jan 21 13:41:50 2022
From: t|m@how@rd @end|ng |rom dec@ny@gov (Howard, Tim G (DEC))
Date: Fri, 21 Jan 2022 12:41:50 +0000
Subject: [R-sig-Geo] model predict in subset: compare terra and stars
In-Reply-To: <CANtt_hyYTg7eB46WrE_sNeJ6jadAEnqenQ9sJMzDAjeoOPJ03A@mail.gmail.com>
References: <SA1PR09MB7792E6C83E36C1F40A9972B7A85A9@SA1PR09MB7792.namprd09.prod.outlook.com>
 <SA1PR09MB77927876E20B5457EEFA47DAA85A9@SA1PR09MB7792.namprd09.prod.outlook.com>
 <CANtt_hyYTg7eB46WrE_sNeJ6jadAEnqenQ9sJMzDAjeoOPJ03A@mail.gmail.com>
Message-ID: <SA1PR09MB77923EA140942753F8AE1B3BA85B9@SA1PR09MB7792.namprd09.prod.outlook.com>

Robert, 
Thank you for the reply and the tips. That's a big improvement! I'll have cases where the masked raster stack (mras) won't fit in RAM so that's why I was explicitly writing out the intermediate products. I'll explore this in that context. 

I've actually wondered if that was the issue on the stars side - too much RAM overhead somehow. 

Thanks again,
Best, 
Tim

>>>>>>>>
From: Robert J. Hijmans <r.hijmans at gmail.com> 
Sent: Friday, January 21, 2022 1:21 AM
To: Howard, Tim G (DEC) <tim.howard at dec.ny.gov>
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] model predict in subset: compare terra and stars


Hello everybody,? 
I cannot answer Tim's questions, but here is a way to do the terra bit much faster, by not writing intermediate steps to disk.
Cheers, Robert

library(terra)
library(stars)
library(sf)
library(microbenchmark)

## setup
tif = system.file("tif/L7_ETMs.tif", package = "stars")
L7_orig = read_stars(tif, proxy = TRUE) %>% split()
# create a shape within which we will want to make the prediction
circle = st_sfc(st_buffer(st_point(c(293749.5, 9115745)), 600), crs = st_crs(L7_orig))
# simple set of points for training the model
trainCoords <- data.frame(
? X = c(290050, 290100, 291700, 293000, 294500, 294600, 298000,
? ? ? ? 289500, 290100, 292500, 294000, 296000, 293600, 294800),
? Y = c(9117000, 9118500, 9117100, 9118000, 9112890, 9111700, 9120000,
? ? ? ? 9112700, 9114000, 9115700, 9118100, 9120000, 9111650, 9116000))

# model for stars
trainPts <- st_as_sf(x = trainCoords, coords = c("X","Y"), crs = st_crs(L7_orig))
trainAttr <- st_drop_geometry(st_as_sf(st_extract(L7_orig, trainPts)))
names(trainAttr) <- c("X1","X2","X3","X4","X5","X6")
trainAttr$pa <- c(rep(1,7), rep(0,7)) #add presence-absence attribute
st_model <- glm(formula=pa~.,data = trainAttr)

# model for terra 
ras = terra::rast(tif) 
trainAttr2 <- extract(ras, trainCoords)[,-1]
trainAttr2$pa <- c(rep(1,7), rep(0,7))
model <- glm(formula=pa~.,data = trainAttr2)
vcircle <- vect(circle)

# time both approaches
mbm <- microbenchmark("starsMethod" = {
? L7_orig_inside = read_stars(tif, proxy = TRUE) %>% split()
? L7_crop <- L7_orig_inside[circle]
? st_out = predict(L7_crop, st_model)
?# st_out is still a proxy with processing steps, writing it out forces those steps to be applied
? write_stars(st_out, file.path(tempdir(),"stars_prediction.tif"),overwrite = TRUE)
},
"terraMethod" = {
? ras = terra::rast(tif)
? cras <- terra::crop(ras, vcircle)
? mras <- terra::mask(cras, vcircle)
? terra_out <- predict(mras, model, filename = file.path(tempdir(),"terra_prediction.tif"), overwrite = TRUE)
}, times = 10)

mbm
#Unit: milliseconds
# ? ? ? ?expr ? ? ?min ? ? ? lq ? ? ?mean ? median ? ? ? uq ? ? ?max neval
# starsMethod 225.4070 227.4722 230.86188 231.4848 233.9374 237.5687 ? ?10
# terraMethod ?93.9507 ?96.0912 ?99.59111 100.0375 103.5670 104.1225 ? ?10

With terra you can use a window ("lazy crop")
? window(ras) <- ext(vcircle)
? mras <- terra::mask(ras, vcircle)
? # but this seems faster
? cras <- terra::crop(ras, vcircle)
? mras <- terra::mask(cras, vcircle)


On Thu, Jan 20, 2022 at 8:43 AM Howard, Tim G (DEC) via R-sig-Geo <mailto:r-sig-geo at r-project.org> wrote:
Dear all - 
Classically, if I want to create a spatial model and make a prediction for an area within the extent of my raster stack my approach would be to crop all predictor rasters to the area of interest and run the predict on that cropped set. The stars package opens up another option: to apply the crop/mask to the proxy object, which then will extract only the relevant cells from the full rasters when writing (or plotting) the result. At least that's how I understand it. 

The following example has both approaches and their timings. I borrowed heavily from stars article 7, other stars articles, and from the terra help pages! Questions below the example.

```
library(terra)
library(stars)
library(sf)
library(microbenchmark)

## setup
tif = system.file("tif/L7_ETMs.tif", package = "stars")
L7_orig = read_stars(tif, proxy = TRUE) %>% split()
# create a shape within which we will want to make the prediction
circle = st_sfc(st_buffer(st_point(c(293749.5, 9115745)), 600), crs = st_crs(L7_orig))
# simple set of points for training the model 
trainCoords <- data.frame(
? X = c(290050, 290100, 291700, 293000, 294500, 294600, 298000,
??????? 289500, 290100, 292500, 294000, 296000, 293600, 294800),
? Y = c(9117000, 9118500, 9117100, 9118000, 9112890, 9111700, 9120000,
??????? 9112700, 9114000, 9115700, 9118100, 9120000, 9111650, 9116000))

trainPts <- st_as_sf(x = trainCoords, coords = c("X","Y"), crs = st_crs(L7_orig))
trainAttr <- st_drop_geometry(st_as_sf(st_extract(L7_orig, trainPts)))
names(trainAttr) <- c("X1","X2","X3","X4","X5","X6")
trainAttr$pa <- c(rep(1,7), rep(0,7)) #add presence-absence attribute

# time both approaches
mbm <- microbenchmark("starsMethod" = {
? L7_orig_inside = read_stars(tif, proxy = TRUE) %>% split()
? st_model <- glm(formula=pa~.,data = trainAttr)
? L7_crop <- L7_orig_inside[circle]
? st_out = predict(L7_crop, st_model)
?# st_out is still a proxy with processing steps, writing it out forces those steps to be applied
? write_stars(st_out, file.path(tempdir(),"stars_prediction.tif"),overwrite = TRUE)
},
"terraMethod" = {
? ras = terra::rast(tif)
? # crop, mask, write out to temp dir
? c_ras <- terra::crop(ras, circle)
? msk <- rasterize(vect(circle), c_ras)
? maskRas <- file.path(tempdir(),"L7_ETMs_crop.tif")
? m_ras <- terra::mask(c_ras, msk, filename = maskRas, overwrite = TRUE)
? model <- glm(formula=pa~.,data = trainAttr)
? # read the cropped raster for predict (already in RAM, but this would be protocol)
? mras <- rast(maskRas)
? names(mras) <- c("X1","X2","X3","X4","X5","X6")
? terra_out <- predict(mras, model, filename = file.path(tempdir(),"terra_prediction.tif"), overwrite = TRUE)
}, times = 10)

# > mbm
# Unit: milliseconds
# expr????? min?????? lq???? mean?? median?????? uq????? max neval
# starsMethod 411.8035 442.4342 701.2864 505.4522 630.8252 1699.737??? 10
# terraMethod? 94.0480? 99.4800 560.6102 106.9317 132.1853 4207.067??? 1
```

As run above, using stars proxies takes a fair amount longer than cropping, saving, and predicting on the cropped rasters. I have found this to be the case for larger (more real-life) examples as well, to the level that for larger data sets and more predictors, I run out of RAM using stars proxies and that approach fails. 

Questions:
1. Am I missing something? Is there a more efficient way for running a model and predicting within a smaller area than the full extent of your predictors?
2. On the surface of things, I would have expected the proxy approach to be faster, especially if using COG rasters (which allow read by chunk, not line). I'm not seeing that here, nor with larger datasets. Any thoughts on the potential bottlenecks?

Thanks in advance, 
Tim


From murr@y@e||ord @end|ng |rom ot@go@@c@nz  Sun Jan 23 06:06:26 2022
From: murr@y@e||ord @end|ng |rom ot@go@@c@nz (Murray Efford)
Date: Sun, 23 Jan 2022 05:06:26 +0000
Subject: [R-sig-Geo] Distance from point(s) to polygon(s) in terra?
Message-ID: <SY4PR01MB56588826533F8B3E888C4CEBAC5D9@SY4PR01MB5658.ausprd01.prod.outlook.com>

I'm trying to simplify my R spatial code to use only terra functions, and I'm almost there. The one function I'm missing is a replacement for rgeos::gDistance for point-polygon distances. I'd be grateful for any ideas.
Murray

From bh@@k@r@ko|k@t@ @end|ng |rom gm@||@com  Thu Jan 27 19:04:57 2022
From: bh@@k@r@ko|k@t@ @end|ng |rom gm@||@com (Bhaskar Mitra)
Date: Thu, 27 Jan 2022 11:04:57 -0700
Subject: [R-sig-Geo] Request for advice on downscaling
Message-ID: <CAEGXkYX1bnOi_22obrGB833pcHLtHFXpgdOXU5G21JEUtNuoCQ@mail.gmail.com>

Hello Everyone,

Please pardon my ignorance, but as I am new to spatial analysis,
I am writing for some guidance to approach a particular spatial analysis
problem
and would really appreciate it if I could get some advice in that regard.

I have a large shapefile and within that shapefile, it is subdivided into
several grids. I have the population data for each of the subgrids and I
would like to partition (or downscale) one large number across the subgrids
, weighted by population.

Can anyone suggest some useful approach or particular R package that
can help me address the problem.

Thanks for your time,

Sincerely,
Bhaskar Mitra

	[[alternative HTML version deleted]]


From r|k|erre|r@@|ve@ @end|ng |rom gm@||@com  Sun Jan 30 16:51:51 2022
From: r|k|erre|r@@|ve@ @end|ng |rom gm@||@com (Rik Ferreira)
Date: Sun, 30 Jan 2022 12:51:51 -0300
Subject: [R-sig-Geo] How to export a GeoTIFF 8 bit raster
Message-ID: <CAKnqGuQJafTiTT5bugr0293JBaWYR4o1P1pzAE_g869yjCLrSQ@mail.gmail.com>

Hello!

How a raster image can be exported as a 8 bit GeoTIFF image?

I'm downloading a 8 bit image from this link:
http://geoinfo.cnps.embrapa.br/documents/2918/download, cropping it with a
vector mask, treating it, and exporting it with terra package (writeRaster
function).

However, the original image is a GeoTIFF with 8 bit depth but the output
image (terra package, writeRaster function) is a 32 bit image.

I can control it with `gdal = "NBITS=8"` argument to writeRaster but i get
such warning:

Warning message:
> In x at ptr$writeRaster(opt) :
>   GDAL Message 6:
> /mnt/HDD/STORAGE/r-projects/raster-bit-depth/output/recorte.tif: Only
> NBITS=16 is supported for data type Float32
>

How can I export this raster as a 8 bit GeoTIFF image with terra package?

-- 
Rik Ferreira Alves
Graduando em Geografia - Unimontes
https://rikferreira.netlify.app/

	[[alternative HTML version deleted]]


