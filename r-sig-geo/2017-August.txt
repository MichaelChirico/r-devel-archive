From davidhill222 at yahoo.com  Tue Aug  1 02:16:50 2017
From: davidhill222 at yahoo.com (David Hill)
Date: Tue, 1 Aug 2017 00:16:50 +0000 (UTC)
Subject: [R-sig-Geo] Correlation between Raster Files
References: <1048325879.4140591.1501546610455.ref@mail.yahoo.com>
Message-ID: <1048325879.4140591.1501546610455@mail.yahoo.com>

Hi Everyone,
I am a newbie is spatial statistics (but I know some R) ?and I apologize if my question has been posted before.
I live in Kenya and I have a set of raster files (matrices) containing some spatial data (for instance :yearly precipitation per square degree) and this data changes with every year.
So I would like to find the correlation between these (raster files) matrices. These matrices are rather small (200X400) and each element.
Thank you.
Any suggestion is welcome!
David

	[[alternative HTML version deleted]]


From sarosama at feps.edu.eg  Tue Aug  1 07:28:06 2017
From: sarosama at feps.edu.eg (sara osama)
Date: Tue, 1 Aug 2017 08:28:06 +0300
Subject: [R-sig-Geo] Test for spatial stationarity
Message-ID: <CAJsLiQRzwHK_BYZnoLmQkM2KvkG=SMaTQYOd7i-T8bj8E=_=pw@mail.gmail.com>

Dear all
Hope this email finds you well. I want to ask if there is a formal test for
spatial stationarity like the one for temporal stationarity.  I have
searched a lot, but I could not find a formal test by which we can conclude
about stationarity in spatial data.
I would be grateful if anyone can help me with this.
Best
Sara

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Tue Aug  1 09:19:12 2017
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 1 Aug 2017 09:19:12 +0200
Subject: [R-sig-Geo] Test for spatial stationarity
In-Reply-To: <CAJsLiQRzwHK_BYZnoLmQkM2KvkG=SMaTQYOd7i-T8bj8E=_=pw@mail.gmail.com>
References: <CAJsLiQRzwHK_BYZnoLmQkM2KvkG=SMaTQYOd7i-T8bj8E=_=pw@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1708010904310.29656@reclus.nhh.no>

On Tue, 1 Aug 2017, sara osama wrote:

> Dear all
> Hope this email finds you well. I want to ask if there is a formal test 
> for spatial stationarity like the one for temporal stationarity.  I have 
> searched a lot, but I could not find a formal test by which we can 
> conclude about stationarity in spatial data.

Sara:

Could you please clarify what you mean by "spatial data"? Do you mean 
point observations of a continuous spatial process - say to make 
predictions for unobserved locations, as in kriging? In this case, there 
is a formal literature discussing stationarity, although I'm not aware of 
formal tests (practically one might compare predictions made using models 
that assume stationarity and those that do not, to see whether the 
assumption changes the output; if it does, probably stationarity is not 
present as assumed).

In the point process literature (point patterns), there are also results, 
but they are often handled by relaxing assumptions about the homogeneity 
of the underlying surface (introducing covariates influencing the 
process).

For lattice (aggregated, polygon) data, there are tests based on 
geographically weighted regression, but these lack power if the bandwidth 
is inappropriate and/or the underlying model is mis-specified. They are 
not univariate tests, and may best be seen as exploratory. There may be 
other literatures, look for work for example by Werner Mueller and 
co-authors.

Hope this helps,

Roger


> I would be grateful if anyone can help me with this.
> Best
> Sara
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From javiermoreira at gmail.com  Tue Aug  1 11:31:38 2017
From: javiermoreira at gmail.com (Javier Moreira)
Date: Tue, 1 Aug 2017 06:31:38 -0300
Subject: [R-sig-Geo] testing nlme models for spatial correlation
Message-ID: <CAEyHP-0m6LR9VPbbVza6PZvy1G_OnV65gvSz2q6peV0CBEwfQA@mail.gmail.com>

hi,
im trying to generate different models to account for spatial correlation.
Im using nlme package, and mixed models, in order to compare two models,
one that doesnt include the spatial correlation and one that does.

Its a nested design, one that has 4 leves,
BLOQUE/ AMBIENTE/ TRATAMIENTO/ SUBMUESTREO
Its a harvest set data, with multiple point of data/ treatment, so the last
level account for another term in the error for "sub-muestreo".

My first problem its, when i try to add de correlation term to the model, i
cant, when the random effects are taken to the level /SUBMUESTREO, and i
have to leave it to the level of TRATAMIENTO.
When i do that, i have 2 differences between models, the term accounting
for sub-muestreo, and the spatial correlation.

#MODELO 2##
attach(base_modelo3)
str(base_modelo3)
data1=base_modelo3
str(data1)
data1=groupedData(REND.~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
data=data1, units=list(y="(ton/ha)"))
data1$TRATAMIENTO =factor(data1$TRATAMIENTO)
data1$BLOQUE =factor(data1$BLOQUE)
data1$AMBIENTE =factor(data1$AMBIENTE)

modelo2_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
                random=~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
                weights=varComb(varIdent(form=~1|TRATAMIENTO)),
                data=data1,
                control=lmeControl(niterEM=150,msMaxIter=200))
summary(modelo2_MM)
anova(modelo2_MM)

##MODELO 4##

modelo4_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
                random=~1|BLOQUE/AMBIENTE/TRATAMIENTO,
                weights=varComb(varIdent(form=~1|TRATAMIENTO)),
                correlation=corExp(form=~X+Y,nugget=T),
                data=data1,
                control=lmeControl(niterEM=150,msMaxIter=200))
summary(modelo4_MM)
anova(modelo4_MM)

My second problem is, that i need to get the specific parameter for the
error term that belongs to the spatial correlation, in order to map it. For
what i watch, what lme does is send it to the general error, and so, what i
could do is make the differences between the residuals of these two models.
so, its essetial to get the exact same model, except for the correlation
structure.
If anybody knows how to get the specific term of error accounting for the
correlation, it would be wonderful.

E24=residuals(modelo24_3,type = "response")
E40=residuals(modelo4_MM,type = "response")
EE=E24-E40
post=data.frame(E24,E40,EE,data1$X,data1$Y)

coordinates(post)<-c("data1.X","data1.Y")
coor_post<-coordinates(post)

bubble(post,"E24",main="residuos modelo 2")
bubble(post,"E40",main="residuos modelo 4")
bubble(post,"EE",main="Est.espacial removida por Modelo 4")

thanks!

-- 
Javier Moreira de Souza
Ingeniero Agr?nomo
099 406 006

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Aug  1 13:10:42 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 1 Aug 2017 13:10:42 +0200
Subject: [R-sig-Geo] testing nlme models for spatial correlation
In-Reply-To: <CAEyHP-0m6LR9VPbbVza6PZvy1G_OnV65gvSz2q6peV0CBEwfQA@mail.gmail.com>
References: <CAEyHP-0m6LR9VPbbVza6PZvy1G_OnV65gvSz2q6peV0CBEwfQA@mail.gmail.com>
Message-ID: <CAJuCY5xTAXB5X+6upaHOFh1CM2bw9huG=qSat1EvCpYvc3u6gw@mail.gmail.com>

Dear Javier,

The correlation structure in nlme only works on the residuals within the
finest level of random effect. Observations in different random effect are
independent.

Have a look at the INLA package (http://www.r-inla.org). INLA allows for
correlated random effects. So you have spatial correlation among the random
effects (instead of among residuals). INLA has options for correlations
along a 2D regular grid, a neighbourhood graph or a mesh. If you want an
book on this, I recommend Zuur et al (2017) Beginner's Guide to Spatial,
Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA.

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-08-01 11:31 GMT+02:00 Javier Moreira <javiermoreira at gmail.com>:

> hi,
> im trying to generate different models to account for spatial correlation.
> Im using nlme package, and mixed models, in order to compare two models,
> one that doesnt include the spatial correlation and one that does.
>
> Its a nested design, one that has 4 leves,
> BLOQUE/ AMBIENTE/ TRATAMIENTO/ SUBMUESTREO
> Its a harvest set data, with multiple point of data/ treatment, so the last
> level account for another term in the error for "sub-muestreo".
>
> My first problem its, when i try to add de correlation term to the model, i
> cant, when the random effects are taken to the level /SUBMUESTREO, and i
> have to leave it to the level of TRATAMIENTO.
> When i do that, i have 2 differences between models, the term accounting
> for sub-muestreo, and the spatial correlation.
>
> #MODELO 2##
> attach(base_modelo3)
> str(base_modelo3)
> data1=base_modelo3
> str(data1)
> data1=groupedData(REND.~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
> data=data1, units=list(y="(ton/ha)"))
> data1$TRATAMIENTO =factor(data1$TRATAMIENTO)
> data1$BLOQUE =factor(data1$BLOQUE)
> data1$AMBIENTE =factor(data1$AMBIENTE)
>
> modelo2_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
>                 random=~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
>                 weights=varComb(varIdent(form=~1|TRATAMIENTO)),
>                 data=data1,
>                 control=lmeControl(niterEM=150,msMaxIter=200))
> summary(modelo2_MM)
> anova(modelo2_MM)
>
> ##MODELO 4##
>
> modelo4_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
>                 random=~1|BLOQUE/AMBIENTE/TRATAMIENTO,
>                 weights=varComb(varIdent(form=~1|TRATAMIENTO)),
>                 correlation=corExp(form=~X+Y,nugget=T),
>                 data=data1,
>                 control=lmeControl(niterEM=150,msMaxIter=200))
> summary(modelo4_MM)
> anova(modelo4_MM)
>
> My second problem is, that i need to get the specific parameter for the
> error term that belongs to the spatial correlation, in order to map it. For
> what i watch, what lme does is send it to the general error, and so, what i
> could do is make the differences between the residuals of these two models.
> so, its essetial to get the exact same model, except for the correlation
> structure.
> If anybody knows how to get the specific term of error accounting for the
> correlation, it would be wonderful.
>
> E24=residuals(modelo24_3,type = "response")
> E40=residuals(modelo4_MM,type = "response")
> EE=E24-E40
> post=data.frame(E24,E40,EE,data1$X,data1$Y)
>
> coordinates(post)<-c("data1.X","data1.Y")
> coor_post<-coordinates(post)
>
> bubble(post,"E24",main="residuos modelo 2")
> bubble(post,"E40",main="residuos modelo 4")
> bubble(post,"EE",main="Est.espacial removida por Modelo 4")
>
> thanks!
>
> --
> Javier Moreira de Souza
> Ingeniero Agr?nomo
> 099 406 006
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From javiermoreira at gmail.com  Tue Aug  1 16:36:45 2017
From: javiermoreira at gmail.com (Javier Moreira)
Date: Tue, 1 Aug 2017 11:36:45 -0300
Subject: [R-sig-Geo] testing nlme models for spatial correlation
In-Reply-To: <CAJuCY5xTAXB5X+6upaHOFh1CM2bw9huG=qSat1EvCpYvc3u6gw@mail.gmail.com>
References: <CAEyHP-0m6LR9VPbbVza6PZvy1G_OnV65gvSz2q6peV0CBEwfQA@mail.gmail.com>
 <CAJuCY5xTAXB5X+6upaHOFh1CM2bw9huG=qSat1EvCpYvc3u6gw@mail.gmail.com>
Message-ID: <CAEyHP-3NSXwUaX=C1d3m4KhHFzVJwn79C_AvdMt=BaoR4nYB-g@mail.gmail.com>

Thanks Thierry,
I would check that info.
Any ideas why if i choose the finest level of random effects as
/SUBMUESTREO and run model 4 (with correlation) wont let me?
If i undesrtand you wel, you adress more the second question i made, im all
right?
Thanks!

El 1 ago. 2017 8:10 a. m., "Thierry Onkelinx" <thierry.onkelinx at inbo.be>
escribi?:

Dear Javier,

The correlation structure in nlme only works on the residuals within the
finest level of random effect. Observations in different random effect are
independent.

Have a look at the INLA package (http://www.r-inla.org). INLA allows for
correlated random effects. So you have spatial correlation among the random
effects (instead of among residuals). INLA has options for correlations
along a 2D regular grid, a neighbourhood graph or a mesh. If you want an
book on this, I recommend Zuur et al (2017) Beginner's Guide to Spatial,
Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA.

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-08-01 11:31 GMT+02:00 Javier Moreira <javiermoreira at gmail.com>:

> hi,
> im trying to generate different models to account for spatial correlation.
> Im using nlme package, and mixed models, in order to compare two models,
> one that doesnt include the spatial correlation and one that does.
>
> Its a nested design, one that has 4 leves,
> BLOQUE/ AMBIENTE/ TRATAMIENTO/ SUBMUESTREO
> Its a harvest set data, with multiple point of data/ treatment, so the last
> level account for another term in the error for "sub-muestreo".
>
> My first problem its, when i try to add de correlation term to the model, i
> cant, when the random effects are taken to the level /SUBMUESTREO, and i
> have to leave it to the level of TRATAMIENTO.
> When i do that, i have 2 differences between models, the term accounting
> for sub-muestreo, and the spatial correlation.
>
> #MODELO 2##
> attach(base_modelo3)
> str(base_modelo3)
> data1=base_modelo3
> str(data1)
> data1=groupedData(REND.~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
> data=data1, units=list(y="(ton/ha)"))
> data1$TRATAMIENTO =factor(data1$TRATAMIENTO)
> data1$BLOQUE =factor(data1$BLOQUE)
> data1$AMBIENTE =factor(data1$AMBIENTE)
>
> modelo2_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
>                 random=~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
>                 weights=varComb(varIdent(form=~1|TRATAMIENTO)),
>                 data=data1,
>                 control=lmeControl(niterEM=150,msMaxIter=200))
> summary(modelo2_MM)
> anova(modelo2_MM)
>
> ##MODELO 4##
>
> modelo4_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
>                 random=~1|BLOQUE/AMBIENTE/TRATAMIENTO,
>                 weights=varComb(varIdent(form=~1|TRATAMIENTO)),
>                 correlation=corExp(form=~X+Y,nugget=T),
>                 data=data1,
>                 control=lmeControl(niterEM=150,msMaxIter=200))
> summary(modelo4_MM)
> anova(modelo4_MM)
>
> My second problem is, that i need to get the specific parameter for the
> error term that belongs to the spatial correlation, in order to map it. For
> what i watch, what lme does is send it to the general error, and so, what i
> could do is make the differences between the residuals of these two models.
> so, its essetial to get the exact same model, except for the correlation
> structure.
> If anybody knows how to get the specific term of error accounting for the
> correlation, it would be wonderful.
>
> E24=residuals(modelo24_3,type = "response")
> E40=residuals(modelo4_MM,type = "response")
> EE=E24-E40
> post=data.frame(E24,E40,EE,data1$X,data1$Y)
>
> coordinates(post)<-c("data1.X","data1.Y")
> coor_post<-coordinates(post)
>
> bubble(post,"E24",main="residuos modelo 2")
> bubble(post,"E40",main="residuos modelo 4")
> bubble(post,"EE",main="Est.espacial removida por Modelo 4")
>
> thanks!
>
> --
> Javier Moreira de Souza
> Ingeniero Agr?nomo
> 099 406 006
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Aug  1 16:42:13 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 1 Aug 2017 16:42:13 +0200
Subject: [R-sig-Geo] testing nlme models for spatial correlation
In-Reply-To: <CAEyHP-3NSXwUaX=C1d3m4KhHFzVJwn79C_AvdMt=BaoR4nYB-g@mail.gmail.com>
References: <CAEyHP-0m6LR9VPbbVza6PZvy1G_OnV65gvSz2q6peV0CBEwfQA@mail.gmail.com>
 <CAJuCY5xTAXB5X+6upaHOFh1CM2bw9huG=qSat1EvCpYvc3u6gw@mail.gmail.com>
 <CAEyHP-3NSXwUaX=C1d3m4KhHFzVJwn79C_AvdMt=BaoR4nYB-g@mail.gmail.com>
Message-ID: <CAJuCY5zTAaP9x6_ekEY8AQ1ZpveONc5aHJytp=R+YkiKtLGXtw@mail.gmail.com>

Dear Javier,

Your problem is hard to understand without a reproducible example. You only
gives the code, not the data nor the error message.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-08-01 16:36 GMT+02:00 Javier Moreira <javiermoreira at gmail.com>:

> Thanks Thierry,
> I would check that info.
> Any ideas why if i choose the finest level of random effects as
> /SUBMUESTREO and run model 4 (with correlation) wont let me?
> If i undesrtand you wel, you adress more the second question i made, im
> all right?
> Thanks!
>
>
> El 1 ago. 2017 8:10 a. m., "Thierry Onkelinx" <thierry.onkelinx at inbo.be>
> escribi?:
>
> Dear Javier,
>
> The correlation structure in nlme only works on the residuals within the
> finest level of random effect. Observations in different random effect are
> independent.
>
> Have a look at the INLA package (http://www.r-inla.org). INLA allows for
> correlated random effects. So you have spatial correlation among the random
> effects (instead of among residuals). INLA has options for correlations
> along a 2D regular grid, a neighbourhood graph or a mesh. If you want an
> book on this, I recommend Zuur et al (2017) Beginner's Guide to Spatial,
> Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA.
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2017-08-01 11:31 GMT+02:00 Javier Moreira <javiermoreira at gmail.com>:
>
>> hi,
>> im trying to generate different models to account for spatial correlation.
>> Im using nlme package, and mixed models, in order to compare two models,
>> one that doesnt include the spatial correlation and one that does.
>>
>> Its a nested design, one that has 4 leves,
>> BLOQUE/ AMBIENTE/ TRATAMIENTO/ SUBMUESTREO
>> Its a harvest set data, with multiple point of data/ treatment, so the
>> last
>> level account for another term in the error for "sub-muestreo".
>>
>> My first problem its, when i try to add de correlation term to the model,
>> i
>> cant, when the random effects are taken to the level /SUBMUESTREO, and i
>> have to leave it to the level of TRATAMIENTO.
>> When i do that, i have 2 differences between models, the term accounting
>> for sub-muestreo, and the spatial correlation.
>>
>> #MODELO 2##
>> attach(base_modelo3)
>> str(base_modelo3)
>> data1=base_modelo3
>> str(data1)
>> data1=groupedData(REND.~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
>> data=data1, units=list(y="(ton/ha)"))
>> data1$TRATAMIENTO =factor(data1$TRATAMIENTO)
>> data1$BLOQUE =factor(data1$BLOQUE)
>> data1$AMBIENTE =factor(data1$AMBIENTE)
>>
>> modelo2_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
>>                 random=~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
>>                 weights=varComb(varIdent(form=~1|TRATAMIENTO)),
>>                 data=data1,
>>                 control=lmeControl(niterEM=150,msMaxIter=200))
>> summary(modelo2_MM)
>> anova(modelo2_MM)
>>
>> ##MODELO 4##
>>
>> modelo4_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
>>                 random=~1|BLOQUE/AMBIENTE/TRATAMIENTO,
>>                 weights=varComb(varIdent(form=~1|TRATAMIENTO)),
>>                 correlation=corExp(form=~X+Y,nugget=T),
>>                 data=data1,
>>                 control=lmeControl(niterEM=150,msMaxIter=200))
>> summary(modelo4_MM)
>> anova(modelo4_MM)
>>
>> My second problem is, that i need to get the specific parameter for the
>> error term that belongs to the spatial correlation, in order to map it.
>> For
>> what i watch, what lme does is send it to the general error, and so, what
>> i
>> could do is make the differences between the residuals of these two
>> models.
>> so, its essetial to get the exact same model, except for the correlation
>> structure.
>> If anybody knows how to get the specific term of error accounting for the
>> correlation, it would be wonderful.
>>
>> E24=residuals(modelo24_3,type = "response")
>> E40=residuals(modelo4_MM,type = "response")
>> EE=E24-E40
>> post=data.frame(E24,E40,EE,data1$X,data1$Y)
>>
>> coordinates(post)<-c("data1.X","data1.Y")
>> coor_post<-coordinates(post)
>>
>> bubble(post,"E24",main="residuos modelo 2")
>> bubble(post,"E40",main="residuos modelo 4")
>> bubble(post,"EE",main="Est.espacial removida por Modelo 4")
>>
>> thanks!
>>
>> --
>> Javier Moreira de Souza
>> Ingeniero Agr?nomo
>> 099 406 006
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
>

	[[alternative HTML version deleted]]


From javiermoreira at gmail.com  Tue Aug  1 17:03:04 2017
From: javiermoreira at gmail.com (Javier Moreira)
Date: Tue, 1 Aug 2017 12:03:04 -0300
Subject: [R-sig-Geo] testing nlme models for spatial correlation
In-Reply-To: <CAJuCY5zTAaP9x6_ekEY8AQ1ZpveONc5aHJytp=R+YkiKtLGXtw@mail.gmail.com>
References: <CAEyHP-0m6LR9VPbbVza6PZvy1G_OnV65gvSz2q6peV0CBEwfQA@mail.gmail.com>
 <CAJuCY5xTAXB5X+6upaHOFh1CM2bw9huG=qSat1EvCpYvc3u6gw@mail.gmail.com>
 <CAEyHP-3NSXwUaX=C1d3m4KhHFzVJwn79C_AvdMt=BaoR4nYB-g@mail.gmail.com>
 <CAJuCY5zTAaP9x6_ekEY8AQ1ZpveONc5aHJytp=R+YkiKtLGXtw@mail.gmail.com>
Message-ID: <CAEyHP-1RdXsGT2xeLFVQnw2z6zZ3HEN9je0qV+4giuxQEnV-XQ@mail.gmail.com>

??Sorry, the error is

Error in corFactor.corSpatial(object) :
  NA/NaN/Inf in foreign function call (arg 1)
In addition: Warning messages:
1: In min(unlist(attr(object, "covariate"))) :
  no non-missing arguments to min; returning Inf
2: In min(unlist(attr(object, "covariate"))) :
  no non-missing arguments to min; returning Inf

and i attach the data to this mail.
?
 base_modelo3.csv
<https://drive.google.com/file/d/0B6YImu-ZATe4bEFKTlAxci1PNW8/view?usp=drive_web>
?
thanks!

2017-08-01 11:42 GMT-03:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:

> Dear Javier,
>
> Your problem is hard to understand without a reproducible example. You
> only gives the code, not the data nor the error message.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2017-08-01 16:36 GMT+02:00 Javier Moreira <javiermoreira at gmail.com>:
>
>> Thanks Thierry,
>> I would check that info.
>> Any ideas why if i choose the finest level of random effects as
>> /SUBMUESTREO and run model 4 (with correlation) wont let me?
>> If i undesrtand you wel, you adress more the second question i made, im
>> all right?
>> Thanks!
>>
>>
>> El 1 ago. 2017 8:10 a. m., "Thierry Onkelinx" <thierry.onkelinx at inbo.be>
>> escribi?:
>>
>> Dear Javier,
>>
>> The correlation structure in nlme only works on the residuals within the
>> finest level of random effect. Observations in different random effect are
>> independent.
>>
>> Have a look at the INLA package (http://www.r-inla.org). INLA allows for
>> correlated random effects. So you have spatial correlation among the random
>> effects (instead of among residuals). INLA has options for correlations
>> along a 2D regular grid, a neighbourhood graph or a mesh. If you want an
>> book on this, I recommend Zuur et al (2017) Beginner's Guide to Spatial,
>> Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA.
>>
>> Best regards,
>>
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2017-08-01 11:31 GMT+02:00 Javier Moreira <javiermoreira at gmail.com>:
>>
>>> hi,
>>> im trying to generate different models to account for spatial
>>> correlation.
>>> Im using nlme package, and mixed models, in order to compare two models,
>>> one that doesnt include the spatial correlation and one that does.
>>>
>>> Its a nested design, one that has 4 leves,
>>> BLOQUE/ AMBIENTE/ TRATAMIENTO/ SUBMUESTREO
>>> Its a harvest set data, with multiple point of data/ treatment, so the
>>> last
>>> level account for another term in the error for "sub-muestreo".
>>>
>>> My first problem its, when i try to add de correlation term to the
>>> model, i
>>> cant, when the random effects are taken to the level /SUBMUESTREO, and i
>>> have to leave it to the level of TRATAMIENTO.
>>> When i do that, i have 2 differences between models, the term accounting
>>> for sub-muestreo, and the spatial correlation.
>>>
>>> #MODELO 2##
>>> attach(base_modelo3)
>>> str(base_modelo3)
>>> data1=base_modelo3
>>> str(data1)
>>> data1=groupedData(REND.~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
>>> data=data1, units=list(y="(ton/ha)"))
>>> data1$TRATAMIENTO =factor(data1$TRATAMIENTO)
>>> data1$BLOQUE =factor(data1$BLOQUE)
>>> data1$AMBIENTE =factor(data1$AMBIENTE)
>>>
>>> modelo2_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
>>>                 random=~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
>>>                 weights=varComb(varIdent(form=~1|TRATAMIENTO)),
>>>                 data=data1,
>>>                 control=lmeControl(niterEM=150,msMaxIter=200))
>>> summary(modelo2_MM)
>>> anova(modelo2_MM)
>>>
>>> ##MODELO 4##
>>>
>>> modelo4_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
>>>                 random=~1|BLOQUE/AMBIENTE/TRATAMIENTO,
>>>                 weights=varComb(varIdent(form=~1|TRATAMIENTO)),
>>>                 correlation=corExp(form=~X+Y,nugget=T),
>>>                 data=data1,
>>>                 control=lmeControl(niterEM=150,msMaxIter=200))
>>> summary(modelo4_MM)
>>> anova(modelo4_MM)
>>>
>>> My second problem is, that i need to get the specific parameter for the
>>> error term that belongs to the spatial correlation, in order to map it.
>>> For
>>> what i watch, what lme does is send it to the general error, and so,
>>> what i
>>> could do is make the differences between the residuals of these two
>>> models.
>>> so, its essetial to get the exact same model, except for the correlation
>>> structure.
>>> If anybody knows how to get the specific term of error accounting for the
>>> correlation, it would be wonderful.
>>>
>>> E24=residuals(modelo24_3,type = "response")
>>> E40=residuals(modelo4_MM,type = "response")
>>> EE=E24-E40
>>> post=data.frame(E24,E40,EE,data1$X,data1$Y)
>>>
>>> coordinates(post)<-c("data1.X","data1.Y")
>>> coor_post<-coordinates(post)
>>>
>>> bubble(post,"E24",main="residuos modelo 2")
>>> bubble(post,"E40",main="residuos modelo 4")
>>> bubble(post,"EE",main="Est.espacial removida por Modelo 4")
>>>
>>> thanks!
>>>
>>> --
>>> Javier Moreira de Souza
>>> Ingeniero Agr?nomo
>>> 099 406 006
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>>
>>
>


-- 
Javier Moreira de Souza
Ingeniero Agr?nomo
099 406 006

	[[alternative HTML version deleted]]


From sgwinder at alaska.edu  Tue Aug  1 22:06:57 2017
From: sgwinder at alaska.edu (Sama Winder)
Date: Tue, 1 Aug 2017 12:06:57 -0800
Subject: [R-sig-Geo] spGLM unexpectedly large sill values
Message-ID: <CAJ+Q0PRWPwYZ0OkENpdXEYfiU3wpk66tphcFdJfq2kyQ-3+O5w@mail.gmail.com>

Hi all,

I am running several fairly complicated presence/absence (binary)
models, each of which includes ~700 data points and between 8 and 13
predictor variables (a mix of continuous and factor variables).

I'm using logistic regression, and first fit these without spatial
effects using glm(). Since we're concerned about residual spatial
autocorrelation, I also added spatial effects (with an exponential
correlation structure) in spGLM. After a few attempts and many
(500,000) iterations, these appear to be converging quite nicely.

However, the sigma^2 values are much bigger than we expected (35, 50,
100). As a result (I suspect), my parameter coefficients are also much
more extreme than they were in the non-spatial models.   For example,
without the spatial term my coefficients ranged from about -1.5 to
1.5, and now they range from -5 to 7. Since this is on the logistic
scale, these result in nearly perfect 0 or 1 predicted probabilities.

This feels like something has gone wrong, but I'm having trouble
placing my finger on exactly what. If not, what is the interpretation?
(As a side note, the phi values are within the range we expected).

Any insights would be greatly appreciated!

Thanks,
Sama

Sama Winder
MS Statistics
University of Alaska, Fairbanks


From patrick.schratz at gmail.com  Tue Aug  1 23:15:32 2017
From: patrick.schratz at gmail.com (Patrick Schratz)
Date: Tue, 1 Aug 2017 23:15:32 +0200
Subject: [R-sig-Geo] spGLM unexpectedly large sill values
In-Reply-To: <CAJ+Q0PRWPwYZ0OkENpdXEYfiU3wpk66tphcFdJfq2kyQ-3+O5w@mail.gmail.com>
References: <CAJ+Q0PRWPwYZ0OkENpdXEYfiU3wpk66tphcFdJfq2kyQ-3+O5w@mail.gmail.com>
Message-ID: <a44147c5-d36b-461b-a165-28ec2ab5a8c7@Spark>

Hi Sama,

This post probably better belongs to?https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models.

Personally, I have no experience with spGLM. In our group we always use mgcv::glmmPQL.

We check the effect of the included spatial correlation structure by fitting semivariograms of the model residuals of the glm (without correlation structure) and the glmm (with correlation structure).
It is normal that the coefficients change but I can not comment on whether your magnitude of the coefficient change is suspicious or not.

However, if the predictive accuracy changes than I would assume that something has gone wrong because pred. acc. should not be affected by the inclusion of an spatial correlation structure (afaik).

I might take a look into ?spGLM? in the next days.

In any case, this post is more a comment than an answer.
Maybe someone else with more experience can help here.

Cheers, Pat

On 1. Aug 2017, 22:07 +0200, Sama Winder <sgwinder at alaska.edu>, wrote:
> Hi all,
>
> I am running several fairly complicated presence/absence (binary)
> models, each of which includes ~700 data points and between 8 and 13
> predictor variables (a mix of continuous and factor variables).
>
> I'm using logistic regression, and first fit these without spatial
> effects using glm(). Since we're concerned about residual spatial
> autocorrelation, I also added spatial effects (with an exponential
> correlation structure) in spGLM. After a few attempts and many
> (500,000) iterations, these appear to be converging quite nicely.
>
> However, the sigma^2 values are much bigger than we expected (35, 50,
> 100). As a result (I suspect), my parameter coefficients are also much
> more extreme than they were in the non-spatial models. For example,
> without the spatial term my coefficients ranged from about -1.5 to
> 1.5, and now they range from -5 to 7. Since this is on the logistic
> scale, these result in nearly perfect 0 or 1 predicted probabilities.
>
> This feels like something has gone wrong, but I'm having trouble
> placing my finger on exactly what. If not, what is the interpretation?
> (As a side note, the phi values are within the range we expected).
>
> Any insights would be greatly appreciated!
>
> Thanks,
> Sama
>
> Sama Winder
> MS Statistics
> University of Alaska, Fairbanks
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From patrick.schratz at gmail.com  Wed Aug  2 00:18:58 2017
From: patrick.schratz at gmail.com (Patrick Schratz)
Date: Wed, 2 Aug 2017 00:18:58 +0200
Subject: [R-sig-Geo] spGLM unexpectedly large sill values
In-Reply-To: <CAJ+Q0PRWPwYZ0OkENpdXEYfiU3wpk66tphcFdJfq2kyQ-3+O5w@mail.gmail.com>
References: <CAJ+Q0PRWPwYZ0OkENpdXEYfiU3wpk66tphcFdJfq2kyQ-3+O5w@mail.gmail.com>
Message-ID: <6b5860d2-2e8b-4376-8ade-f387c72ac3e7@Spark>

Correction: MASS::glmmPQL, not mgcv::


On 1. Aug 2017, 22:07 +0200, Sama Winder <sgwinder at alaska.edu>, wrote:
> Hi all,
>
> I am running several fairly complicated presence/absence (binary)
> models, each of which includes ~700 data points and between 8 and 13
> predictor variables (a mix of continuous and factor variables).
>
> I'm using logistic regression, and first fit these without spatial
> effects using glm(). Since we're concerned about residual spatial
> autocorrelation, I also added spatial effects (with an exponential
> correlation structure) in spGLM. After a few attempts and many
> (500,000) iterations, these appear to be converging quite nicely.
>
> However, the sigma^2 values are much bigger than we expected (35, 50,
> 100). As a result (I suspect), my parameter coefficients are also much
> more extreme than they were in the non-spatial models. For example,
> without the spatial term my coefficients ranged from about -1.5 to
> 1.5, and now they range from -5 to 7. Since this is on the logistic
> scale, these result in nearly perfect 0 or 1 predicted probabilities.
>
> This feels like something has gone wrong, but I'm having trouble
> placing my finger on exactly what. If not, what is the interpretation?
> (As a side note, the phi values are within the range we expected).
>
> Any insights would be greatly appreciated!
>
> Thanks,
> Sama
>
> Sama Winder
> MS Statistics
> University of Alaska, Fairbanks
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From sgwinder at alaska.edu  Wed Aug  2 00:54:34 2017
From: sgwinder at alaska.edu (Sama Winder)
Date: Tue, 1 Aug 2017 14:54:34 -0800
Subject: [R-sig-Geo] spGLM unexpectedly large sill values
In-Reply-To: <6b5860d2-2e8b-4376-8ade-f387c72ac3e7@Spark>
References: <CAJ+Q0PRWPwYZ0OkENpdXEYfiU3wpk66tphcFdJfq2kyQ-3+O5w@mail.gmail.com>
 <6b5860d2-2e8b-4376-8ade-f387c72ac3e7@Spark>
Message-ID: <CAJ+Q0PQhJrBiyosJ_PUh2uGkf2ckk8OOyPNZ3_M_0Kb+Ov9-vQ@mail.gmail.com>

Thanks Pat.

I will check out glmmPQL to see if I get similar results as I do in
spBayes::spGLM, since that could certainly be instructive.

Could you tell me more about how you fit the semivariograms?
Specifically, which residuals do you use, and then which semivariogram
function? I have explored this a bit but ran into a few threads
suggesting that semivariograms were more appropriate for normal data
and linear trends and never came to a solution I was happy with.

And, if I don't hear back from anyone else perhaps I will try the
r-sig-mixed-models group.

Thanks!
Sama

On Tue, Aug 1, 2017 at 2:18 PM, Patrick Schratz
<patrick.schratz at gmail.com> wrote:
> Correction: MASS::glmmPQL, not mgcv::
>
>
> On 1. Aug 2017, 22:07 +0200, Sama Winder <sgwinder at alaska.edu>, wrote:
>
> Hi all,
>
> I am running several fairly complicated presence/absence (binary)
> models, each of which includes ~700 data points and between 8 and 13
> predictor variables (a mix of continuous and factor variables).
>
> I'm using logistic regression, and first fit these without spatial
> effects using glm(). Since we're concerned about residual spatial
> autocorrelation, I also added spatial effects (with an exponential
> correlation structure) in spGLM. After a few attempts and many
> (500,000) iterations, these appear to be converging quite nicely.
>
> However, the sigma^2 values are much bigger than we expected (35, 50,
> 100). As a result (I suspect), my parameter coefficients are also much
> more extreme than they were in the non-spatial models. For example,
> without the spatial term my coefficients ranged from about -1.5 to
> 1.5, and now they range from -5 to 7. Since this is on the logistic
> scale, these result in nearly perfect 0 or 1 predicted probabilities.
>
> This feels like something has gone wrong, but I'm having trouble
> placing my finger on exactly what. If not, what is the interpretation?
> (As a side note, the phi values are within the range we expected).
>
> Any insights would be greatly appreciated!
>
> Thanks,
> Sama
>
> Sama Winder
> MS Statistics
> University of Alaska, Fairbanks
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From thierry.onkelinx at inbo.be  Wed Aug  2 10:52:40 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 2 Aug 2017 10:52:40 +0200
Subject: [R-sig-Geo] testing nlme models for spatial correlation
In-Reply-To: <CAEyHP-1RdXsGT2xeLFVQnw2z6zZ3HEN9je0qV+4giuxQEnV-XQ@mail.gmail.com>
References: <CAEyHP-0m6LR9VPbbVza6PZvy1G_OnV65gvSz2q6peV0CBEwfQA@mail.gmail.com>
 <CAJuCY5xTAXB5X+6upaHOFh1CM2bw9huG=qSat1EvCpYvc3u6gw@mail.gmail.com>
 <CAEyHP-3NSXwUaX=C1d3m4KhHFzVJwn79C_AvdMt=BaoR4nYB-g@mail.gmail.com>
 <CAJuCY5zTAaP9x6_ekEY8AQ1ZpveONc5aHJytp=R+YkiKtLGXtw@mail.gmail.com>
 <CAEyHP-1RdXsGT2xeLFVQnw2z6zZ3HEN9je0qV+4giuxQEnV-XQ@mail.gmail.com>
Message-ID: <CAJuCY5zhxwf-BAOTskPiZP6wpbKTqGo4AzMsiu0O97q6OxxCeg@mail.gmail.com>

Dear Javier,

It looks like you have only one observation for each combination of BLOQUE/
AMBIENTE/ TRATAMIENTO/ SUBMUESTREO. That is an observation level random
effect (OLRE) which doesn't make sense with a Gaussian distribution. The
ORLE and the residual would model the exact same thing. Model2 doesn't make
sense.

Two other problems: BLOQUE has only 3 levels and AMBIENTE and TRAITAMIENTO
are both used in the fixed and the random part. See
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#should-i-treat-factor-xxx-as-fixed-or-random.
AMBIENTE and TRAITAMIENTO are rather crossed than nested. See
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#nested-or-crossed
and https://www.muscardinus.be/2017/07/lme4-random-effects/

I can't reproduce the error you get on model4. The output seems reasonable,
although it has the same problems as model2.

Your dataset is suitable for the SPDE approach in INLA.

I would recommend that you consult a (local) statistician.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-08-01 17:03 GMT+02:00 Javier Moreira <javiermoreira at gmail.com>:

> ??Sorry, the error is
>
> Error in corFactor.corSpatial(object) :
>   NA/NaN/Inf in foreign function call (arg 1)
> In addition: Warning messages:
> 1: In min(unlist(attr(object, "covariate"))) :
>   no non-missing arguments to min; returning Inf
> 2: In min(unlist(attr(object, "covariate"))) :
>   no non-missing arguments to min; returning Inf
>
> and i attach the data to this mail.
> ?
>  base_modelo3.csv
> <https://drive.google.com/file/d/0B6YImu-ZATe4bEFKTlAxci1PNW8/view?usp=drive_web>
> ?
> thanks!
>
> 2017-08-01 11:42 GMT-03:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>
>> Dear Javier,
>>
>> Your problem is hard to understand without a reproducible example. You
>> only gives the code, not the data nor the error message.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2017-08-01 16:36 GMT+02:00 Javier Moreira <javiermoreira at gmail.com>:
>>
>>> Thanks Thierry,
>>> I would check that info.
>>> Any ideas why if i choose the finest level of random effects as
>>> /SUBMUESTREO and run model 4 (with correlation) wont let me?
>>> If i undesrtand you wel, you adress more the second question i made, im
>>> all right?
>>> Thanks!
>>>
>>>
>>> El 1 ago. 2017 8:10 a. m., "Thierry Onkelinx" <thierry.onkelinx at inbo.be>
>>> escribi?:
>>>
>>> Dear Javier,
>>>
>>> The correlation structure in nlme only works on the residuals within the
>>> finest level of random effect. Observations in different random effect are
>>> independent.
>>>
>>> Have a look at the INLA package (http://www.r-inla.org). INLA allows
>>> for correlated random effects. So you have spatial correlation among the
>>> random effects (instead of among residuals). INLA has options for
>>> correlations along a 2D regular grid, a neighbourhood graph or a mesh. If
>>> you want an book on this, I recommend Zuur et al (2017) Beginner's Guide to
>>> Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA.
>>>
>>> Best regards,
>>>
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> 2017-08-01 11:31 GMT+02:00 Javier Moreira <javiermoreira at gmail.com>:
>>>
>>>> hi,
>>>> im trying to generate different models to account for spatial
>>>> correlation.
>>>> Im using nlme package, and mixed models, in order to compare two models,
>>>> one that doesnt include the spatial correlation and one that does.
>>>>
>>>> Its a nested design, one that has 4 leves,
>>>> BLOQUE/ AMBIENTE/ TRATAMIENTO/ SUBMUESTREO
>>>> Its a harvest set data, with multiple point of data/ treatment, so the
>>>> last
>>>> level account for another term in the error for "sub-muestreo".
>>>>
>>>> My first problem its, when i try to add de correlation term to the
>>>> model, i
>>>> cant, when the random effects are taken to the level /SUBMUESTREO, and i
>>>> have to leave it to the level of TRATAMIENTO.
>>>> When i do that, i have 2 differences between models, the term accounting
>>>> for sub-muestreo, and the spatial correlation.
>>>>
>>>> #MODELO 2##
>>>> attach(base_modelo3)
>>>> str(base_modelo3)
>>>> data1=base_modelo3
>>>> str(data1)
>>>> data1=groupedData(REND.~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
>>>> data=data1, units=list(y="(ton/ha)"))
>>>> data1$TRATAMIENTO =factor(data1$TRATAMIENTO)
>>>> data1$BLOQUE =factor(data1$BLOQUE)
>>>> data1$AMBIENTE =factor(data1$AMBIENTE)
>>>>
>>>> modelo2_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
>>>>                 random=~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
>>>>                 weights=varComb(varIdent(form=~1|TRATAMIENTO)),
>>>>                 data=data1,
>>>>                 control=lmeControl(niterEM=150,msMaxIter=200))
>>>> summary(modelo2_MM)
>>>> anova(modelo2_MM)
>>>>
>>>> ##MODELO 4##
>>>>
>>>> modelo4_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
>>>>                 random=~1|BLOQUE/AMBIENTE/TRATAMIENTO,
>>>>                 weights=varComb(varIdent(form=~1|TRATAMIENTO)),
>>>>                 correlation=corExp(form=~X+Y,nugget=T),
>>>>                 data=data1,
>>>>                 control=lmeControl(niterEM=150,msMaxIter=200))
>>>> summary(modelo4_MM)
>>>> anova(modelo4_MM)
>>>>
>>>> My second problem is, that i need to get the specific parameter for the
>>>> error term that belongs to the spatial correlation, in order to map it.
>>>> For
>>>> what i watch, what lme does is send it to the general error, and so,
>>>> what i
>>>> could do is make the differences between the residuals of these two
>>>> models.
>>>> so, its essetial to get the exact same model, except for the correlation
>>>> structure.
>>>> If anybody knows how to get the specific term of error accounting for
>>>> the
>>>> correlation, it would be wonderful.
>>>>
>>>> E24=residuals(modelo24_3,type = "response")
>>>> E40=residuals(modelo4_MM,type = "response")
>>>> EE=E24-E40
>>>> post=data.frame(E24,E40,EE,data1$X,data1$Y)
>>>>
>>>> coordinates(post)<-c("data1.X","data1.Y")
>>>> coor_post<-coordinates(post)
>>>>
>>>> bubble(post,"E24",main="residuos modelo 2")
>>>> bubble(post,"E40",main="residuos modelo 4")
>>>> bubble(post,"EE",main="Est.espacial removida por Modelo 4")
>>>>
>>>> thanks!
>>>>
>>>> --
>>>> Javier Moreira de Souza
>>>> Ingeniero Agr?nomo
>>>> 099 406 006
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>>
>>>
>>
>
>
> --
> Javier Moreira de Souza
> Ingeniero Agr?nomo
> 099 406 006
>
>
>

	[[alternative HTML version deleted]]


From rafa.pereira.br at gmail.com  Wed Aug  2 12:53:56 2017
From: rafa.pereira.br at gmail.com (Rafael Pereira)
Date: Wed, 2 Aug 2017 11:53:56 +0100
Subject: [R-sig-Geo] bivariate spatial correlation in R
In-Reply-To: <alpine.LFD.2.20.1707312250480.10503@reclus.nhh.no>
References: <CAA42DGnbWzkOfhMWttTkjaMEdOyDKLkZ=DDDYjywJrhFrKgjtw@mail.gmail.com>
 <alpine.LFD.2.20.1707242012390.6677@reclus.nhh.no>
 <CAA42DGm1dhzEvN9vYyRfKS7XuPVnXFgVBfRHWFLGS29H4R65Cw@mail.gmail.com>
 <alpine.LFD.2.20.1707261152010.18617@reclus.nhh.no>
 <CAA42DGkhtyTHpW3ZoFAOHdDcjY6iK0LZpZFdkvnmihieujzbGg@mail.gmail.com>
 <6124293B00A50295.e0f9c23d-4edb-4035-aab0-756e53b6db82@mail.outlook.com>
 <CAA42DGk8agiCMPp5FLwSrd1wszaVcNHd5uB6fCkdT9rb8QHLOw@mail.gmail.com>
 <alpine.LFD.2.20.1707312250480.10503@reclus.nhh.no>
Message-ID: <CAA42DGmVuch59mUwQa9_i3rfPtvqh4TByhnnCxBRxxT6_qSFZg@mail.gmail.com>

Roger,


Thank you for your response.


I recognize the data is not ideal and the analysis has limitations because
of the lack of information on population displacements that might have
occurred over the years. Nonetheless, there are plenty of data + literature
showing how the spatial distribution of income classes and land use
patterns is fairly stable over time in this city, particularly for a short
timescales like in this analysis. Having said this, I believe these two
questions (1) what socioeconomic classes have gained more accessibility?
and (2) ?were wealthier areas in 2010 able to attract more changes to
accessibility?? in the end ask the same thing but with different phrasings,
though your phrasing (2) is more precise/correct.



On the more technical discussion, I see your point that spatial AND
temporal correlation in my data would make permutation bootstrap
inappropriate to generate significance levels, thus making bivariate
Moran?s I biased. Thank you very much for the clarifications! This has been
very helpful and I will have a closer look at which spatial regression
models are more appropriate for my analysis.


On a side note, do you think the function to calculate bivariate Moran?s I
is correct?  And could it be incorporated in the next version of spdep? If
so, please give credit to Rog?rio Barbosa, the researcher who proposed the
code in Stack Overflow.

best,

Rafael HM Pereira
http://urbandemographics.blogspot.com


On Mon, Jul 31, 2017 at 10:52 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> Rafael,
>
> I'm sorry, but there is no way you can logically "analyze who benefits the
> recent changes in the transport system in terms of access to jobs" from the
> data you have.
>
> Even if you had aggregate household income data for 2014 and 2017 (not for
> 2010 only), you would not know whether wealthier families had not dispaced
> poorer families as accessibility improved. You need individual data, either
> survey or register, preferably panel, to show that changes in accessibility
> change the economic welfare of households controlling for movement of
> households. The timestamps on the data make any attempt to do this very
> risky; the real findings from a hypothetical surevey-based panel might be
> completely different, especially if poorer households were displaced (also
> indirectly, through rising house prices driven by improved accessibility).
> Gauging the welfare effects of transport investments is very hard to
> instrument.
>
> The closest I could get was to map deciles of the change in access (more
> negatives than positives) and compare the aspatial income distributions:
>
> library(spdep)
> library(rgdal)
> map <- readOGR(dsn=".", layer="test_map")
> library(classInt)
> cI <- classIntervals(map$diffaccess, n=10, style="quantile")
> library(RColorBrewer)
> ybrpal <- brewer.pal(6, "YlOrBr")
> fC <- findColours(cI, ybrpal)
> qtm(map, fill="diffaccess", fill.breaks=cI$brks, format="Europe2")
> map$faccess <- factor(findInterval(map$diffaccess, cI$brks,
>   all.inside=TRUE), labels=names(attr(fC, "table")))
> qtm(map, fill="diffaccess", fill.breaks=cI$brks, format="Europe2")
> acc_income <- split(map$income, map$faccess)
> do.call("rbind", lapply(acc_income, summary))
> dens <- lapply(acc_income, density)
> plot(1, ylab="", xlab="", type="n", xlim=c(-2000, 11000), ylim=c(0,
>   0.002))
> for (i in seq(along=dens)) lines(dens[[i]], col=i)
> legend("topright", legend=names(dens), col=1:length(dens), lty=1, bty="n")
>
> These density curves really do not suggest any clear relationship, other
> than that some areas with increased accessibility had higher incomes in
> 2010.
>
> You can examine the reverse relationship - were aggregate areas that were
> more wealthy in 2010 able to attract more changes to accessibility? The
> answer seems to be yes, they were able to do this:
>
> nb <- poly2nb(map)
> lw <- nb2listw(nb, style = "W", zero.policy = T)
> lm.morantest(lm(diffaccess ~ I(income/1000), map), lw)
> # SLX model
> summary(lmSLX(diffaccess ~ I(income/1000), map, lw))
> lm.morantest(lmSLX(diffaccess ~ I(income/1000), map, lw), lw)
> # Spatial Durbin error model - SDEM
> obj <- errorsarlm(diffaccess ~ I(income/1000), map, lw, etype="emixed")
> summary(impacts(obj))
> summary(impacts(lmSLX(diffaccess ~ I(income/1000), map, lw)))
> LR.sarlm(lmSLX(diffaccess ~ I(income/1000), map, lw), obj)
>
> It would be possible to run lm.morantest.sad() on the output of the SDEM
> model taking global spatial autocorrelation into account. If you need that,
> follow up in this thread.
>
> Bivariate Moran's I should not be used in this case, but could be used in
> other cases - use in change over time is troubling because randomisation
> will not be a good guide as t=1 and t=2 are subject to temporal as well as
> spatial autocorrelation, so you cannot use permutation bootstrap to find a
> usable measure of significance.
>
> Hope this clarifies, and thanks for the code.
>
> Roger
>
> On Sun, 30 Jul 2017, Rafael Pereira wrote:
>
> Roger,
>>
>> Population and income data are single point in time and come from the 2010
>> Census.
>>
>> Accessibility variables in 2014 and 2017 show the proportion of jobs
>> accessible by public transport under 60 minutes. The variable diffaccess
>> shows the difference between these two. It's in percentage points
>> (access2017 - access2014)
>>
>> best,
>>
>> Rafael H M Pereira
>> urbandemographics.blogspot.com
>>
>> On Sun, Jul 30, 2017 at 7:41 AM, Roger Bivand <Roger.Bivand at nhh.no>
>> wrote:
>>
>> Thanks, I'll get back when able, offline now. What are the units of
>>> observation, and are aggregate household incomes observed only once?
>>>
>>> Roger
>>>
>>> Roger Bivand
>>> Norwegian School of Economics
>>> Bergen, Norway
>>>
>>>
>>>
>>> Fra: Rafael Pereira
>>> Sendt: s?ndag 30. juli, 00.39
>>> Emne: Re: [R-sig-Geo] bivariate spatial correlation in R
>>> Kopi: Rog?rio Barbosa, r-sig-geo at r-project.org
>>>
>>>
>>> Hi all, here is a reproducible example to calculate in R bivariate
>>> Moran's
>>> I and LISA clusters. This example is based on a this answer provided in
>>> SO*
>>> and it uses a toy model of my data. The R script and the shape file with
>>> the data are available on this link. https://gist.github.com/
>>> rafapereirabr/5348193abf779625f5e8c5090776a228 What this example does is
>>> to estimate the spatial association between household income per capita
>>> and
>>> the gains in accessibility to jobs. The aim is to analyze who benefits
>>> the
>>> recent changes in the transport system in terms of access to jobs. So the
>>> idea is not to find causal relationships, but spatial association between
>>> areas of high/low income who had high/low gains in accessibility. The
>>> variables in the data show info on the proportion of jobs accessible in
>>> both years 2014 and 2017 (access2014, access2017) and the difference
>>> between the two years in percentage points (diffaccess). Roger, I know
>>> you
>>> have shown to be a bit sceptical about this application of bivariate
>>> Moran's I. Do you still think a spatial regression would be more
>>> appropriate? Also, I would be glad to hear if others have comments on the
>>> code. This function is not implemented in any package so it would be
>>> great
>>> to have some feedback. Rafael H M Pereira urbandemographics.blogspot.com
>>> * https://stackoverflow.com/questions/45177590/map-of-
>>> bivariate-spatial-correlation-in-r-bivariate-lisa On Wed, Jul 26, 2017
>>> at
>>> 11:07 AM, Roger Bivand wrote: > On Wed, 26 Jul 2017, Rafael Pereira
>>> wrote:
>>>
>>>> Roger, >> >> This example was provided only for the sake or making the
>>>>>
>>>> code easily >> reproducible for others and I'm more interested in how
>>> the
>>> bi-variate >> Moran >> could be implemented in R, but your comments are
>>> very much welcomed and >> I've made changes to the question. >> >> My
>>> actual case study looks at bi-variate spatial correlation between (a) >>
>>> average household income per capita and (b) proportion of jobs in the
>>> city
>>>
>>>> that are accessible under 60 minutes by transit. I don't think I could
>>>>>
>>>> use >> rates in this case but I will normalize the variables using >>
>>> scale(data$variable). >> > > Please provide a reproducible example,
>>> either
>>> with a link to a data > subset, or using a builtin data set. My guess is
>>> that you do not need > bi-variate spatial correlation at all, but rather
>>> a
>>> spatial regression. > > The "causal" variable would then the the
>>> proportion
>>> of jobs accessible > within 60 minutes by transit, though this is
>>> extremely
>>> blunt, and lots of > other covariates (demography, etc.) impact average
>>> household income per > capita (per block/tract?). Since there are many
>>> missing variables in your > specification, any spatial correlation would
>>> be
>>> most closely associated > with them (demography, housing costs,
>>> education,
>>> etc.), and the choice of > units of measurement would dominate the
>>> outcome.
>>>
>>>> This is also why bi-variate spatial correlation is seldom a good idea,
>>>>>
>>>> I > believe. It can be done, but most likely shouldn't, unless it can
>>> be >
>>> motivated properly. > > By the way, the weighted and FDR-corrected SAD
>>> local Moran's I p-values of > the black/white ratio for Oregon (your toy
>>> example) did deliver the goods - > if you zoom in in mapview::mapview,
>>> you
>>> can see that it detects a rate > hotspot between the rivers. > > Roger >
>>> >
>>>
>>>> best, >> >> Rafael H M Pereira >> >> On Mon, Jul 24, 2017 at 7:56 PM,
>>>>>>
>>>>> Roger Bivand >> wrote: >> >> On Mon, 24 Jul 2017, Rafael Pereira
>>> wrote: >>>
>>>
>>>> Hi all, >>> >>>> >>>> I would like to ask whether some you conducted
>>>>>>
>>>>> bi-variate spatial >>>> correlation in R. >>>> >>>> I know the
>>> bi-variate
>>> Moran's I is not implemented in the spdep library. >>>> I left a question
>>> on SO but also wanted to hear if anyone if the >>>> mainlist >>>> have
>>> come
>>> across this. >>>> https://stackoverflow.com/questions/45177590/map-of-
>>> bivariat >>>> e-spatial-correlation-in-r-bivariate-lisa >>>> >>>> I also
>>> know Roger Bivand has implemented the L index proposed by Lee >>>> (2001)
>>>
>>>> in spdep, but I'm not I'm not sure whether the L local correlation
>>>>>>> coefficients can be interpreted the same way as the local Moran's I
>>>>>>> coefficients. I couldn't find any reference commenting on this issue.
>>>>>>>
>>>>>> I >>>> would very much appreciate your thoughts this. >>>> >>>> >>>
>>> In the
>>> SO question, and in the follow-up, your presumably throw-away >>> example
>>> makes fundamental mistakes. The code in spdep by Virgilio >>> G?mez-Rubio
>>> is for uni- and bivariate L, and produces point values of >>> local >>>
>>> L.
>>> This isn't the main problem, which is rather that you are not taking >>>
>>> account of the underlying population counts, nor shrinking any estimates
>>>
>>>> of >>> significance to accommodate population sizes. Population sizes
>>>>>>
>>>>> vary from >>> 0 >>> to 11858, with the lower quartile at 3164 and upper
>>> 5698: >>> plot(ecdf(oregon.tract$pop2000)). Should you be comparing
>>> rates
>>> in >>> stead? >>> These are also compositional variables (sum to pop2000,
>>> or 1 if rates) >>> with >>> the other missing components. You would
>>> probably be better served by >>> tools >>> examining spatial segregation,
>>> such as for example the seg package. >>> >>> The 0 count populations
>>> cause
>>> problems for an unofficial alternative, the >>> black/white ratio: >>>
>>> >>>
>>> oregon.tract1 0,] >>> oregon.tract1$rat >> nb >> lw >> >>> which should
>>> still be adjusted by weighting: >>> >>> lm0 >> >>> I'm not advising this,
>>> but running localmoran.sad on this model output >>> yields SAD p-values <
>>> 0.05 after FDR correction only in contiguous tracts >>> on the Washington
>>> state line in Portland between the Columbia and >>> Williamette rivers.
>>> So
>>> do look at the variables you are using before >>> rushing into things.
>>> >>>
>>>
>>>> Hope this clarifies, >>> >>> Roger >>> >>> >>> best, >>>> >>>> Rafael
>>>>>>
>>>>> HM Pereira >>>> http://urbandemographics.blogspot.com >>>> >>>>
>>> [[alternative HTML version deleted]] >>>> >>>>
>>> _______________________________________________ >>>> R-sig-Geo mailing
>>> list >>>> R-sig-Geo at r-project.org >>>> https://stat.ethz.ch/mailman/
>>> listinfo/r-sig-geo >>>> >>>> >>>> -- >>> Roger Bivand >>> Department of
>>> Economics, Norwegian School of Economics, >>> Helleveien 30, N-5045
>>> Bergen,
>>> Norway. >>> voice: +47 55 95 93 55 <+47%2055%2095%2093%2055>; e-mail:
>>> Roger.Bivand at nhh.no >>> Editor-in-Chief of The R Journal,
>>> https://journal.r-project.org/ >>> index.html >>>
>>> http://orcid.org/0000-0003-2392-6140 >>> https://scholar.google.no/
>>> citations?user=AWeghB0AAAAJ&hl=en >>> >> >> [[alternative HTML version
>>> deleted]] >> >> _______________________________________________ >>
>>> R-sig-Geo mailing list >> R-sig-Geo at r-project.org >>
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo >> > > -- > Roger Bivand
>>>
>>>> Department of Economics, Norwegian School of Economics, > Helleveien 30,
>>>>
>>> N-5045 Bergen, Norway. > voice: +47 55 95 93 55
>>> <+47%2055%2095%2093%2055>;
>>> e-mail: Roger.Bivand at nhh.no > Editor-in-Chief of The R Journal,
>>> https://journal.r-project.org/index.html > http://orcid.org/0000-0003-
>>> 2392-6140 > https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>> >
>>> [[alternative HTML version deleted]] ______________________________
>>> _________________
>>> R-sig-Geo mailing list R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>>
>>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
> Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>

	[[alternative HTML version deleted]]


From javiermoreira at gmail.com  Wed Aug  2 16:00:49 2017
From: javiermoreira at gmail.com (Javier Moreira)
Date: Wed, 2 Aug 2017 11:00:49 -0300
Subject: [R-sig-Geo] testing nlme models for spatial correlation
In-Reply-To: <CAJuCY5zhxwf-BAOTskPiZP6wpbKTqGo4AzMsiu0O97q6OxxCeg@mail.gmail.com>
References: <CAEyHP-0m6LR9VPbbVza6PZvy1G_OnV65gvSz2q6peV0CBEwfQA@mail.gmail.com>
 <CAJuCY5xTAXB5X+6upaHOFh1CM2bw9huG=qSat1EvCpYvc3u6gw@mail.gmail.com>
 <CAEyHP-3NSXwUaX=C1d3m4KhHFzVJwn79C_AvdMt=BaoR4nYB-g@mail.gmail.com>
 <CAJuCY5zTAaP9x6_ekEY8AQ1ZpveONc5aHJytp=R+YkiKtLGXtw@mail.gmail.com>
 <CAEyHP-1RdXsGT2xeLFVQnw2z6zZ3HEN9je0qV+4giuxQEnV-XQ@mail.gmail.com>
 <CAJuCY5zhxwf-BAOTskPiZP6wpbKTqGo4AzMsiu0O97q6OxxCeg@mail.gmail.com>
Message-ID: <CAEyHP-3951Sz=6eY4DEAsEZ0CKL8wRoXdm4kKVs6A=3ac__5Sg@mail.gmail.com>

Thanks,
I try the random effects to the level of TRATAMIENTO, and works fine.
For the cross or nested, what hapens is, if you dont use all the 3 randoms
the degrees of freedom arent correct.
Thanks for your time.



El 2 ago. 2017 5:52 a. m., "Thierry Onkelinx" <thierry.onkelinx at inbo.be>
escribi?:

> Dear Javier,
>
> It looks like you have only one observation for each combination of BLOQUE/
> AMBIENTE/ TRATAMIENTO/ SUBMUESTREO. That is an observation level random
> effect (OLRE) which doesn't make sense with a Gaussian distribution. The
> ORLE and the residual would model the exact same thing. Model2 doesn't make
> sense.
>
> Two other problems: BLOQUE has only 3 levels and AMBIENTE and TRAITAMIENTO
> are both used in the fixed and the random part. See
> http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#
> should-i-treat-factor-xxx-as-fixed-or-random. AMBIENTE and TRAITAMIENTO
> are rather crossed than nested. See http://bbolker.github.io/
> mixedmodels-misc/glmmFAQ.html#nested-or-crossed and
> https://www.muscardinus.be/2017/07/lme4-random-effects/
>
> I can't reproduce the error you get on model4. The output seems
> reasonable, although it has the same problems as model2.
>
> Your dataset is suitable for the SPDE approach in INLA.
>
> I would recommend that you consult a (local) statistician.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2017-08-01 17:03 GMT+02:00 Javier Moreira <javiermoreira at gmail.com>:
>
>> ??Sorry, the error is
>>
>> Error in corFactor.corSpatial(object) :
>>   NA/NaN/Inf in foreign function call (arg 1)
>> In addition: Warning messages:
>> 1: In min(unlist(attr(object, "covariate"))) :
>>   no non-missing arguments to min; returning Inf
>> 2: In min(unlist(attr(object, "covariate"))) :
>>   no non-missing arguments to min; returning Inf
>>
>> and i attach the data to this mail.
>> ?
>>  base_modelo3.csv
>> <https://drive.google.com/file/d/0B6YImu-ZATe4bEFKTlAxci1PNW8/view?usp=drive_web>
>> ?
>> thanks!
>>
>> 2017-08-01 11:42 GMT-03:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>>
>>> Dear Javier,
>>>
>>> Your problem is hard to understand without a reproducible example. You
>>> only gives the code, not the data nor the error message.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> 2017-08-01 16:36 GMT+02:00 Javier Moreira <javiermoreira at gmail.com>:
>>>
>>>> Thanks Thierry,
>>>> I would check that info.
>>>> Any ideas why if i choose the finest level of random effects as
>>>> /SUBMUESTREO and run model 4 (with correlation) wont let me?
>>>> If i undesrtand you wel, you adress more the second question i made, im
>>>> all right?
>>>> Thanks!
>>>>
>>>>
>>>> El 1 ago. 2017 8:10 a. m., "Thierry Onkelinx" <thierry.onkelinx at inbo.be>
>>>> escribi?:
>>>>
>>>> Dear Javier,
>>>>
>>>> The correlation structure in nlme only works on the residuals within
>>>> the finest level of random effect. Observations in different random effect
>>>> are independent.
>>>>
>>>> Have a look at the INLA package (http://www.r-inla.org). INLA allows
>>>> for correlated random effects. So you have spatial correlation among the
>>>> random effects (instead of among residuals). INLA has options for
>>>> correlations along a 2D regular grid, a neighbourhood graph or a mesh. If
>>>> you want an book on this, I recommend Zuur et al (2017) Beginner's Guide to
>>>> Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA.
>>>>
>>>> Best regards,
>>>>
>>>>
>>>> ir. Thierry Onkelinx
>>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>>> and Forest
>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>> Kliniekstraat 25
>>>> 1070 Anderlecht
>>>> Belgium
>>>>
>>>> To call in the statistician after the experiment is done may be no more
>>>> than asking him to perform a post-mortem examination: he may be able to say
>>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does
>>>> not ensure that a reasonable answer can be extracted from a given body of
>>>> data. ~ John Tukey
>>>>
>>>> 2017-08-01 11:31 GMT+02:00 Javier Moreira <javiermoreira at gmail.com>:
>>>>
>>>>> hi,
>>>>> im trying to generate different models to account for spatial
>>>>> correlation.
>>>>> Im using nlme package, and mixed models, in order to compare two
>>>>> models,
>>>>> one that doesnt include the spatial correlation and one that does.
>>>>>
>>>>> Its a nested design, one that has 4 leves,
>>>>> BLOQUE/ AMBIENTE/ TRATAMIENTO/ SUBMUESTREO
>>>>> Its a harvest set data, with multiple point of data/ treatment, so the
>>>>> last
>>>>> level account for another term in the error for "sub-muestreo".
>>>>>
>>>>> My first problem its, when i try to add de correlation term to the
>>>>> model, i
>>>>> cant, when the random effects are taken to the level /SUBMUESTREO, and
>>>>> i
>>>>> have to leave it to the level of TRATAMIENTO.
>>>>> When i do that, i have 2 differences between models, the term
>>>>> accounting
>>>>> for sub-muestreo, and the spatial correlation.
>>>>>
>>>>> #MODELO 2##
>>>>> attach(base_modelo3)
>>>>> str(base_modelo3)
>>>>> data1=base_modelo3
>>>>> str(data1)
>>>>> data1=groupedData(REND.~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
>>>>> data=data1, units=list(y="(ton/ha)"))
>>>>> data1$TRATAMIENTO =factor(data1$TRATAMIENTO)
>>>>> data1$BLOQUE =factor(data1$BLOQUE)
>>>>> data1$AMBIENTE =factor(data1$AMBIENTE)
>>>>>
>>>>> modelo2_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
>>>>>                 random=~1|BLOQUE/AMBIENTE/TRATAMIENTO/SUBMUESTREO,
>>>>>                 weights=varComb(varIdent(form=~1|TRATAMIENTO)),
>>>>>                 data=data1,
>>>>>                 control=lmeControl(niterEM=150,msMaxIter=200))
>>>>> summary(modelo2_MM)
>>>>> anova(modelo2_MM)
>>>>>
>>>>> ##MODELO 4##
>>>>>
>>>>> modelo4_MM<-lme(REND.~1+TRATAMIENTO*AMBIENTE,
>>>>>                 random=~1|BLOQUE/AMBIENTE/TRATAMIENTO,
>>>>>                 weights=varComb(varIdent(form=~1|TRATAMIENTO)),
>>>>>                 correlation=corExp(form=~X+Y,nugget=T),
>>>>>                 data=data1,
>>>>>                 control=lmeControl(niterEM=150,msMaxIter=200))
>>>>> summary(modelo4_MM)
>>>>> anova(modelo4_MM)
>>>>>
>>>>> My second problem is, that i need to get the specific parameter for the
>>>>> error term that belongs to the spatial correlation, in order to map
>>>>> it. For
>>>>> what i watch, what lme does is send it to the general error, and so,
>>>>> what i
>>>>> could do is make the differences between the residuals of these two
>>>>> models.
>>>>> so, its essetial to get the exact same model, except for the
>>>>> correlation
>>>>> structure.
>>>>> If anybody knows how to get the specific term of error accounting for
>>>>> the
>>>>> correlation, it would be wonderful.
>>>>>
>>>>> E24=residuals(modelo24_3,type = "response")
>>>>> E40=residuals(modelo4_MM,type = "response")
>>>>> EE=E24-E40
>>>>> post=data.frame(E24,E40,EE,data1$X,data1$Y)
>>>>>
>>>>> coordinates(post)<-c("data1.X","data1.Y")
>>>>> coor_post<-coordinates(post)
>>>>>
>>>>> bubble(post,"E24",main="residuos modelo 2")
>>>>> bubble(post,"E40",main="residuos modelo 4")
>>>>> bubble(post,"EE",main="Est.espacial removida por Modelo 4")
>>>>>
>>>>> thanks!
>>>>>
>>>>> --
>>>>> Javier Moreira de Souza
>>>>> Ingeniero Agr?nomo
>>>>> 099 406 006
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at r-project.org
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>
>>>>
>>>>
>>>
>>
>>
>> --
>> Javier Moreira de Souza
>> Ingeniero Agr?nomo
>> 099 406 006
>>
>>
>>
>

	[[alternative HTML version deleted]]


From adomalik at sfu.ca  Wed Aug  2 20:25:22 2017
From: adomalik at sfu.ca (Alice Domalik)
Date: Wed, 2 Aug 2017 11:25:22 -0700 (PDT)
Subject: [R-sig-Geo] average bearing of animal movement data
Message-ID: <929817145.19837927.1501698322422.JavaMail.zimbra@sfu.ca>

Hi there, 

I have seabird tracking data and I have used both the packages 'trip' and 'move' to calculate the max distance travelled (using the function 'homedist' in 'trip', and 'distanceSummary' in 'move'). 
I would also like to describe the bearing of each animal when it is at its maximum displacement from the colony. I am wondering if anyone knows any packages that can calculate this. Alternatively, if someone knows how I can extract the coordinates of the location of maximum displacement. 

thanks so much! 

	[[alternative HTML version deleted]]


From javier.garcia at ehu.eus  Thu Aug  3 02:19:31 2017
From: javier.garcia at ehu.eus (=?iso-8859-1?Q?Javier_Garc=EDa?=)
Date: Thu, 3 Aug 2017 02:19:31 +0200
Subject: [R-sig-Geo] Computational problems with errorsarlm
Message-ID: <000001d30bee$2dd78f60$8986ae20$@ehu.eus>

Hello everybody:

 

I am trying to estimate a spatial error model, but I am facing to several
problems

 

1)  Running errorsarlm function the following message appears:

 

Warning messages:

1: In errorsarlm(y ~ z1 + z2 + z3 + z4 + z5 + z6 + z7 + z8 +  :

  inversion of asymptotic covariance matrix failed for tol.solve = 1e-10 

  n?mero de condici?n rec?proco = 3.80991e-16 - using numerical Hessian.

2: In sqrt(fdHess[1, 1]) : Se han producido NaNs

 

 

Getting the following results:

 

Approximate (numerical Hessian) standard error: NaN

    z-value: NaN, p-value: NA

Wald statistic: NaN, p-value: NA

 

 

This can be easily ?solved? changing tol.solve from 1.0e-10 to, for example,
1.0e-20. Doing this I get  the following results

 

Asymptotic standard error: 14.053

    z-value: -44.177, p-value: < 2.22e-16

Wald statistic: 1951.6, p-value: < 2.22e-16

 

2)  However, I have a more serious problema: the estimate of lambda does not
make any sense

 

Lambda: -620.82, LR test value: 333.5, p-value: < 2.22e-16

 

Any idea about what it is happening? I am using a big dataset with 2800
observations (houses), 14 variables, and the spatial weight matrix has been
constructed ?by hand? with the inverse of the inter-areas distances .
Moreover, several observations belong to the same area (in total we have
only 10 areas). As the intra-area distance is unknown but cannot be
considered zero, I calculate it as 1/(0.1*dist_min), being dist_min the
distance between the corresponding area and the nearest one (idea borrowed
from Pattanayak and Butry (2005) ?Spatial complementarity of forest and
farms: accounting for ecosystem services?, American Journal of Agricultural
Economics). Could be due to my particular spatial weight matrix? Any
alternative? 

 

 

Cheers

Javi

 

	


JAVIER GARC?A 

 

Departamento de Econom?a Aplicada III (Econometr?a y Estad?stica)

Facultad de Econom?a y Empresa (Secci?n Sarriko)
Avda. Lehendakari Aguirre 83

48015 BILBAO
T.: +34 601 7126 F.: +34 601 3754
 <http://www.ehu.es/> www.ehu.es 

http://www.unibertsitate-hedakuntza.ehu.es/p268-content/es/contenidos/inform
acion/manual_id_corp/es_manual/images/firma_email_upv_euskampus_bilingue.gif

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20170803/8ce7f640/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.gif
Type: image/gif
Size: 6359 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20170803/8ce7f640/attachment.gif>

From b.rowlingson at lancaster.ac.uk  Thu Aug  3 09:27:06 2017
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 3 Aug 2017 08:27:06 +0100
Subject: [R-sig-Geo] average bearing of animal movement data
In-Reply-To: <929817145.19837927.1501698322422.JavaMail.zimbra@sfu.ca>
References: <929817145.19837927.1501698322422.JavaMail.zimbra@sfu.ca>
Message-ID: <CANVKczO6-g2pMNTU6NsC4ty1XZgw_snTO6SCXcLRcrRaGW5F0g@mail.gmail.com>

You can convert a "trip" object to a SpatialPointsDataFrame with
as("SpatialPointsDataFrame",my_trip). Then you can use functions like
"spDistsN1" from sp to compute the distance from "home" to each point,
find the maximum, and then use "bearing" from the "geosphere" package
to get the bearing for that row.

A complication I see is that this will only return the maximum
distance to a vertex point on the trip. For a trip in two flat
dimensions the maximum distance will always be a vertex point on the
trip but I think on a sphere its possible for great circles between
two points to have a location on the circle that is further from a
given point than either of the end points. But I can't get my head
quite round the 3d triangular geometry this early in the morning. For
small steps in a trip where you can approximate the geometry as flat
this is not a problem.

In contrast, the minimum distance from a trip to a "home" point is
rarely a vertex point on the trip because its possible for the trip
path to go very close to the home point in question. e.g a trip from
(10,0) to (-10,0) goes right through (0,0) but its points are both 10
units away.

Barry




On Wed, Aug 2, 2017 at 7:25 PM, Alice Domalik <adomalik at sfu.ca> wrote:
> Hi there,
>
> I have seabird tracking data and I have used both the packages 'trip' and 'move' to calculate the max distance travelled (using the function 'homedist' in 'trip', and 'distanceSummary' in 'move').
> I would also like to describe the bearing of each animal when it is at its maximum displacement from the colony. I am wondering if anyone knows any packages that can calculate this. Alternatively, if someone knows how I can extract the coordinates of the location of maximum displacement.
>
> thanks so much!
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Thu Aug  3 09:31:09 2017
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 3 Aug 2017 07:31:09 +0000
Subject: [R-sig-Geo] Computational problems with errorsarlm
In-Reply-To: <000001d30bee$2dd78f60$8986ae20$@ehu.eus>
References: <000001d30bee$2dd78f60$8986ae20$@ehu.eus>
Message-ID: <6124293B00A50295.1ef99ca4-8f3f-4166-adc9-8b14e844bad8@mail.outlook.com>

Definitely your weights matrix. The matrix must be known and fixed. You should not try to use errorsarlm with only very few spatially identified grouped observations. Only use a multilevel approach, such as that in the HSAR package, see articles referenced there, or in an online  article in Spatial Statistics by Zhe Sha and coauthors at:
https://doi.org/10.1016/j.spasta.2017.01.002


Roger Bivand
Norwegian School of Economics
Bergen, Norway



Fra: Javier Garc?a
Sendt: torsdag 3. august, 02.19
Emne: [R-sig-Geo] Computational problems with errorsarlm
Til: r-sig-geo at r-project.org


Hello everybody:

I am trying to estimate a spatial error model, but I am facing to several problems

1)  Running errorsarlm function the following message appears:

Warning messages:
1: In errorsarlm(y ~ z1 + z2 + z3 + z4 + z5 + z6 + z7 + z8 +  :
  inversion of asymptotic covariance matrix failed for tol.solve = 1e-10
  n?mero de condici?n rec?proco = 3.80991e-16 - using numerical Hessian.
2: In sqrt(fdHess[1, 1]) : Se han producido NaNs


Getting the following results:

Approximate (numerical Hessian) standard error: NaN
    z-value: NaN, p-value: NA
Wald statistic: NaN, p-value: NA


This can be easily ?solved? changing tol.solve from 1.0e-10 to, for example, 1.0e-20. Doing this I get  the following results

Asymptotic standard error: 14.053
    z-value: -44.177, p-value: < 2.22e-16
Wald statistic: 1951.6, p-value: < 2.22e-16

2)  However, I have a more serious problema: the estimate of lambda does not make any sense

Lambda: -620.82, LR test value: 333.5, p-value: < 2.22e-16

Any idea about what it is happening? I am using a big dataset with 2800 observations (houses), 14 variables, and the spatial weight matrix has been constructed ?by hand? with the inverse of the inter-areas distances . Moreover, several observations belong to the same area (in total we have only 10 areas). As the intra-area distance is unknown but cannot be considered zero, I calculate it as 1/(0.1*dist_min), being dist_min the distance between the corresponding area and the nearest one (idea borrowed from Pattanayak and Butry (2005) ?Spatial complementarity of forest and farms: accounting for ecosystem services?, American Journal of Agricultural Economics). Could be due to my particular spatial weight matrix? Any alternative?


Cheers
Javi

JAVIER GARC?A





Departamento de Econom?a Aplicada III (Econometr?a y Estad?stica)


Facultad de Econom?a y Empresa (Secci?n Sarriko)


Avda. Lehendakari Aguirre


[http://www.unibertsitate-hedakuntza.ehu.es/p268-content/es/contenidos/informacion/manual_id_corp/es_manual/images/firma_email_upv_euskampus_bilingue.gif]



83


48015 BILBAO


T.: +34 601 7126




F.: +34 601 3754


www.ehu.es<http://www.ehu.es/>








-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20170803/d61108c3/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.gif
Type: image/gif
Size: 6359 bytes
Desc: image001.gif
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20170803/d61108c3/attachment.gif>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.gif
Type: image/gif
Size: 6359 bytes
Desc: image001.gif
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20170803/d61108c3/attachment-0001.gif>

From mdsumner at gmail.com  Thu Aug  3 10:00:45 2017
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 03 Aug 2017 08:00:45 +0000
Subject: [R-sig-Geo] average bearing of animal movement data
In-Reply-To: <CANVKczO6-g2pMNTU6NsC4ty1XZgw_snTO6SCXcLRcrRaGW5F0g@mail.gmail.com>
References: <929817145.19837927.1501698322422.JavaMail.zimbra@sfu.ca>
 <CANVKczO6-g2pMNTU6NsC4ty1XZgw_snTO6SCXcLRcrRaGW5F0g@mail.gmail.com>
Message-ID: <CAAcGz9-=NjN2t8KkzJ7FPK4uP7ZpTidA38=Ddx+_FUunJQOJmA@mail.gmail.com>

Also, trip is really outdated and dopey and homedist is likely not working
properly, very happy to help find he answers here there are many options.

Cheers, Mike at tripIsMyFault.org


On Thu, 3 Aug 2017, 17:27 Barry Rowlingson, <b.rowlingson at lancaster.ac.uk>
wrote:

> You can convert a "trip" object to a SpatialPointsDataFrame with
> as("SpatialPointsDataFrame",my_trip). Then you can use functions like
> "spDistsN1" from sp to compute the distance from "home" to each point,
> find the maximum, and then use "bearing" from the "geosphere" package
> to get the bearing for that row.
>
> A complication I see is that this will only return the maximum
> distance to a vertex point on the trip. For a trip in two flat
> dimensions the maximum distance will always be a vertex point on the
> trip but I think on a sphere its possible for great circles between
> two points to have a location on the circle that is further from a
> given point than either of the end points. But I can't get my head
> quite round the 3d triangular geometry this early in the morning. For
> small steps in a trip where you can approximate the geometry as flat
> this is not a problem.
>
>
>
> In contrast, the minimum distance from a trip to a "home" point is
> rarely a vertex point on the trip because its possible for the trip
> path to go very close to the home point in question. e.g a trip from
> (10,0) to (-10,0) goes right through (0,0) but its points are both 10
> units away.
>
> Barry
>
>
>
>
> On Wed, Aug 2, 2017 at 7:25 PM, Alice Domalik <adomalik at sfu.ca> wrote:
> > Hi there,
> >
> > I have seabird tracking data and I have used both the packages 'trip'
> and 'move' to calculate the max distance travelled (using the function
> 'homedist' in 'trip', and 'distanceSummary' in 'move').
> > I would also like to describe the bearing of each animal when it is at
> its maximum displacement from the colony. I am wondering if anyone knows
> any packages that can calculate this. Alternatively, if someone knows how I
> can extract the coordinates of the location of maximum displacement.
> >
> > thanks so much!
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Thu Aug  3 11:13:22 2017
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 3 Aug 2017 11:13:22 +0200
Subject: [R-sig-Geo] bivariate spatial correlation in R
In-Reply-To: <CAA42DGmVuch59mUwQa9_i3rfPtvqh4TByhnnCxBRxxT6_qSFZg@mail.gmail.com>
References: <CAA42DGnbWzkOfhMWttTkjaMEdOyDKLkZ=DDDYjywJrhFrKgjtw@mail.gmail.com>
 <alpine.LFD.2.20.1707242012390.6677@reclus.nhh.no>
 <CAA42DGm1dhzEvN9vYyRfKS7XuPVnXFgVBfRHWFLGS29H4R65Cw@mail.gmail.com>
 <alpine.LFD.2.20.1707261152010.18617@reclus.nhh.no>
 <CAA42DGkhtyTHpW3ZoFAOHdDcjY6iK0LZpZFdkvnmihieujzbGg@mail.gmail.com>
 <6124293B00A50295.e0f9c23d-4edb-4035-aab0-756e53b6db82@mail.outlook.com>
 <CAA42DGk8agiCMPp5FLwSrd1wszaVcNHd5uB6fCkdT9rb8QHLOw@mail.gmail.com>
 <alpine.LFD.2.20.1707312250480.10503@reclus.nhh.no>
 <CAA42DGmVuch59mUwQa9_i3rfPtvqh4TByhnnCxBRxxT6_qSFZg@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1708031059430.32106@reclus.nhh.no>

On Wed, 2 Aug 2017, Rafael Pereira wrote:

> Roger,
>
>
> Thank you for your response.
>
>
> I recognize the data is not ideal and the analysis has limitations because
> of the lack of information on population displacements that might have
> occurred over the years. Nonetheless, there are plenty of data + literature
> showing how the spatial distribution of income classes and land use
> patterns is fairly stable over time in this city, particularly for a short
> timescales like in this analysis. Having said this, I believe these two
> questions (1) what socioeconomic classes have gained more accessibility?
> and (2) ?were wealthier areas in 2010 able to attract more changes to
> accessibility?? in the end ask the same thing but with different phrasings,
> though your phrasing (2) is more precise/correct.
>
>
>
> On the more technical discussion, I see your point that spatial AND
> temporal correlation in my data would make permutation bootstrap
> inappropriate to generate significance levels, thus making bivariate
> Moran?s I biased. Thank you very much for the clarifications! This has been
> very helpful and I will have a closer look at which spatial regression
> models are more appropriate for my analysis.
>
>
> On a side note, do you think the function to calculate bivariate Moran?s I
> is correct?  And could it be incorporated in the next version of spdep? If
> so, please give credit to Rog?rio Barbosa, the researcher who proposed the
> code in Stack Overflow.

Perhaps, but SO is usually ephemeral (nobody takes responsibility for 
documenting code and fixing bugs found later). I don't see any tests, 
documentation or accommodation of what spdep expects for edge cases - the 
function as it stands would need a lot of work to protect users from 
obvious blunders. There are no references to literature, nor to proven 
test cases which this implementation should match. We have an 
implementation of Lee (2001), but this is not the same, right? Which 
article gives the formal statistical development of the bivariate local 
Moran's I? Do we know that conditional simulation (permutation bootstrap) 
is valid in some cases, if so which? Is there a development of parametric 
bootstrap?

Roger

>
> best,
>
> Rafael HM Pereira
> http://urbandemographics.blogspot.com
>
>
> On Mon, Jul 31, 2017 at 10:52 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> Rafael,
>>
>> I'm sorry, but there is no way you can logically "analyze who benefits the
>> recent changes in the transport system in terms of access to jobs" from the
>> data you have.
>>
>> Even if you had aggregate household income data for 2014 and 2017 (not for
>> 2010 only), you would not know whether wealthier families had not dispaced
>> poorer families as accessibility improved. You need individual data, either
>> survey or register, preferably panel, to show that changes in accessibility
>> change the economic welfare of households controlling for movement of
>> households. The timestamps on the data make any attempt to do this very
>> risky; the real findings from a hypothetical surevey-based panel might be
>> completely different, especially if poorer households were displaced (also
>> indirectly, through rising house prices driven by improved accessibility).
>> Gauging the welfare effects of transport investments is very hard to
>> instrument.
>>
>> The closest I could get was to map deciles of the change in access (more
>> negatives than positives) and compare the aspatial income distributions:
>>
>> library(spdep)
>> library(rgdal)
>> map <- readOGR(dsn=".", layer="test_map")
>> library(classInt)
>> cI <- classIntervals(map$diffaccess, n=10, style="quantile")
>> library(RColorBrewer)
>> ybrpal <- brewer.pal(6, "YlOrBr")
>> fC <- findColours(cI, ybrpal)
>> qtm(map, fill="diffaccess", fill.breaks=cI$brks, format="Europe2")
>> map$faccess <- factor(findInterval(map$diffaccess, cI$brks,
>>   all.inside=TRUE), labels=names(attr(fC, "table")))
>> qtm(map, fill="diffaccess", fill.breaks=cI$brks, format="Europe2")
>> acc_income <- split(map$income, map$faccess)
>> do.call("rbind", lapply(acc_income, summary))
>> dens <- lapply(acc_income, density)
>> plot(1, ylab="", xlab="", type="n", xlim=c(-2000, 11000), ylim=c(0,
>>   0.002))
>> for (i in seq(along=dens)) lines(dens[[i]], col=i)
>> legend("topright", legend=names(dens), col=1:length(dens), lty=1, bty="n")
>>
>> These density curves really do not suggest any clear relationship, other
>> than that some areas with increased accessibility had higher incomes in
>> 2010.
>>
>> You can examine the reverse relationship - were aggregate areas that were
>> more wealthy in 2010 able to attract more changes to accessibility? The
>> answer seems to be yes, they were able to do this:
>>
>> nb <- poly2nb(map)
>> lw <- nb2listw(nb, style = "W", zero.policy = T)
>> lm.morantest(lm(diffaccess ~ I(income/1000), map), lw)
>> # SLX model
>> summary(lmSLX(diffaccess ~ I(income/1000), map, lw))
>> lm.morantest(lmSLX(diffaccess ~ I(income/1000), map, lw), lw)
>> # Spatial Durbin error model - SDEM
>> obj <- errorsarlm(diffaccess ~ I(income/1000), map, lw, etype="emixed")
>> summary(impacts(obj))
>> summary(impacts(lmSLX(diffaccess ~ I(income/1000), map, lw)))
>> LR.sarlm(lmSLX(diffaccess ~ I(income/1000), map, lw), obj)
>>
>> It would be possible to run lm.morantest.sad() on the output of the SDEM
>> model taking global spatial autocorrelation into account. If you need that,
>> follow up in this thread.
>>
>> Bivariate Moran's I should not be used in this case, but could be used in
>> other cases - use in change over time is troubling because randomisation
>> will not be a good guide as t=1 and t=2 are subject to temporal as well as
>> spatial autocorrelation, so you cannot use permutation bootstrap to find a
>> usable measure of significance.
>>
>> Hope this clarifies, and thanks for the code.
>>
>> Roger
>>
>> On Sun, 30 Jul 2017, Rafael Pereira wrote:
>>
>> Roger,
>>>
>>> Population and income data are single point in time and come from the 2010
>>> Census.
>>>
>>> Accessibility variables in 2014 and 2017 show the proportion of jobs
>>> accessible by public transport under 60 minutes. The variable diffaccess
>>> shows the difference between these two. It's in percentage points
>>> (access2017 - access2014)
>>>
>>> best,
>>>
>>> Rafael H M Pereira
>>> urbandemographics.blogspot.com
>>>
>>> On Sun, Jul 30, 2017 at 7:41 AM, Roger Bivand <Roger.Bivand at nhh.no>
>>> wrote:
>>>
>>> Thanks, I'll get back when able, offline now. What are the units of
>>>> observation, and are aggregate household incomes observed only once?
>>>>
>>>> Roger
>>>>
>>>> Roger Bivand
>>>> Norwegian School of Economics
>>>> Bergen, Norway
>>>>
>>>>
>>>>
>>>> Fra: Rafael Pereira
>>>> Sendt: s?ndag 30. juli, 00.39
>>>> Emne: Re: [R-sig-Geo] bivariate spatial correlation in R
>>>> Kopi: Rog?rio Barbosa, r-sig-geo at r-project.org
>>>>
>>>>
>>>> Hi all, here is a reproducible example to calculate in R bivariate
>>>> Moran's
>>>> I and LISA clusters. This example is based on a this answer provided in
>>>> SO*
>>>> and it uses a toy model of my data. The R script and the shape file with
>>>> the data are available on this link. https://gist.github.com/
>>>> rafapereirabr/5348193abf779625f5e8c5090776a228 What this example does is
>>>> to estimate the spatial association between household income per capita
>>>> and
>>>> the gains in accessibility to jobs. The aim is to analyze who benefits
>>>> the
>>>> recent changes in the transport system in terms of access to jobs. So the
>>>> idea is not to find causal relationships, but spatial association between
>>>> areas of high/low income who had high/low gains in accessibility. The
>>>> variables in the data show info on the proportion of jobs accessible in
>>>> both years 2014 and 2017 (access2014, access2017) and the difference
>>>> between the two years in percentage points (diffaccess). Roger, I know
>>>> you
>>>> have shown to be a bit sceptical about this application of bivariate
>>>> Moran's I. Do you still think a spatial regression would be more
>>>> appropriate? Also, I would be glad to hear if others have comments on the
>>>> code. This function is not implemented in any package so it would be
>>>> great
>>>> to have some feedback. Rafael H M Pereira urbandemographics.blogspot.com
>>>> * https://stackoverflow.com/questions/45177590/map-of-
>>>> bivariate-spatial-correlation-in-r-bivariate-lisa On Wed, Jul 26, 2017
>>>> at
>>>> 11:07 AM, Roger Bivand wrote: > On Wed, 26 Jul 2017, Rafael Pereira
>>>> wrote:
>>>>
>>>>> Roger, >> >> This example was provided only for the sake or making the
>>>>>>
>>>>> code easily >> reproducible for others and I'm more interested in how
>>>> the
>>>> bi-variate >> Moran >> could be implemented in R, but your comments are
>>>> very much welcomed and >> I've made changes to the question. >> >> My
>>>> actual case study looks at bi-variate spatial correlation between (a) >>
>>>> average household income per capita and (b) proportion of jobs in the
>>>> city
>>>>
>>>>> that are accessible under 60 minutes by transit. I don't think I could
>>>>>>
>>>>> use >> rates in this case but I will normalize the variables using >>
>>>> scale(data$variable). >> > > Please provide a reproducible example,
>>>> either
>>>> with a link to a data > subset, or using a builtin data set. My guess is
>>>> that you do not need > bi-variate spatial correlation at all, but rather
>>>> a
>>>> spatial regression. > > The "causal" variable would then the the
>>>> proportion
>>>> of jobs accessible > within 60 minutes by transit, though this is
>>>> extremely
>>>> blunt, and lots of > other covariates (demography, etc.) impact average
>>>> household income per > capita (per block/tract?). Since there are many
>>>> missing variables in your > specification, any spatial correlation would
>>>> be
>>>> most closely associated > with them (demography, housing costs,
>>>> education,
>>>> etc.), and the choice of > units of measurement would dominate the
>>>> outcome.
>>>>
>>>>> This is also why bi-variate spatial correlation is seldom a good idea,
>>>>>>
>>>>> I > believe. It can be done, but most likely shouldn't, unless it can
>>>> be >
>>>> motivated properly. > > By the way, the weighted and FDR-corrected SAD
>>>> local Moran's I p-values of > the black/white ratio for Oregon (your toy
>>>> example) did deliver the goods - > if you zoom in in mapview::mapview,
>>>> you
>>>> can see that it detects a rate > hotspot between the rivers. > > Roger >
>>>>>
>>>>
>>>>> best, >> >> Rafael H M Pereira >> >> On Mon, Jul 24, 2017 at 7:56 PM,
>>>>>>>
>>>>>> Roger Bivand >> wrote: >> >> On Mon, 24 Jul 2017, Rafael Pereira
>>>> wrote: >>>
>>>>
>>>>> Hi all, >>> >>>> >>>> I would like to ask whether some you conducted
>>>>>>>
>>>>>> bi-variate spatial >>>> correlation in R. >>>> >>>> I know the
>>>> bi-variate
>>>> Moran's I is not implemented in the spdep library. >>>> I left a question
>>>> on SO but also wanted to hear if anyone if the >>>> mainlist >>>> have
>>>> come
>>>> across this. >>>> https://stackoverflow.com/questions/45177590/map-of-
>>>> bivariat >>>> e-spatial-correlation-in-r-bivariate-lisa >>>> >>>> I also
>>>> know Roger Bivand has implemented the L index proposed by Lee >>>> (2001)
>>>>
>>>>> in spdep, but I'm not I'm not sure whether the L local correlation
>>>>>>>> coefficients can be interpreted the same way as the local Moran's I
>>>>>>>> coefficients. I couldn't find any reference commenting on this issue.
>>>>>>>>
>>>>>>> I >>>> would very much appreciate your thoughts this. >>>> >>>> >>>
>>>> In the
>>>> SO question, and in the follow-up, your presumably throw-away >>> example
>>>> makes fundamental mistakes. The code in spdep by Virgilio >>> G?mez-Rubio
>>>> is for uni- and bivariate L, and produces point values of >>> local >>>
>>>> L.
>>>> This isn't the main problem, which is rather that you are not taking >>>
>>>> account of the underlying population counts, nor shrinking any estimates
>>>>
>>>>> of >>> significance to accommodate population sizes. Population sizes
>>>>>>>
>>>>>> vary from >>> 0 >>> to 11858, with the lower quartile at 3164 and upper
>>>> 5698: >>> plot(ecdf(oregon.tract$pop2000)). Should you be comparing
>>>> rates
>>>> in >>> stead? >>> These are also compositional variables (sum to pop2000,
>>>> or 1 if rates) >>> with >>> the other missing components. You would
>>>> probably be better served by >>> tools >>> examining spatial segregation,
>>>> such as for example the seg package. >>> >>> The 0 count populations
>>>> cause
>>>> problems for an unofficial alternative, the >>> black/white ratio: >>>
>>>>>>>
>>>> oregon.tract1 0,] >>> oregon.tract1$rat >> nb >> lw >> >>> which should
>>>> still be adjusted by weighting: >>> >>> lm0 >> >>> I'm not advising this,
>>>> but running localmoran.sad on this model output >>> yields SAD p-values <
>>>> 0.05 after FDR correction only in contiguous tracts >>> on the Washington
>>>> state line in Portland between the Columbia and >>> Williamette rivers.
>>>> So
>>>> do look at the variables you are using before >>> rushing into things.
>>>>>>>
>>>>
>>>>> Hope this clarifies, >>> >>> Roger >>> >>> >>> best, >>>> >>>> Rafael
>>>>>>>
>>>>>> HM Pereira >>>> http://urbandemographics.blogspot.com >>>> >>>>
>>>> [[alternative HTML version deleted]] >>>> >>>>
>>>> _______________________________________________ >>>> R-sig-Geo mailing
>>>> list >>>> R-sig-Geo at r-project.org >>>> https://stat.ethz.ch/mailman/
>>>> listinfo/r-sig-geo >>>> >>>> >>>> -- >>> Roger Bivand >>> Department of
>>>> Economics, Norwegian School of Economics, >>> Helleveien 30, N-5045
>>>> Bergen,
>>>> Norway. >>> voice: +47 55 95 93 55 <+47%2055%2095%2093%2055>; e-mail:
>>>> Roger.Bivand at nhh.no >>> Editor-in-Chief of The R Journal,
>>>> https://journal.r-project.org/ >>> index.html >>>
>>>> http://orcid.org/0000-0003-2392-6140 >>> https://scholar.google.no/
>>>> citations?user=AWeghB0AAAAJ&hl=en >>> >> >> [[alternative HTML version
>>>> deleted]] >> >> _______________________________________________ >>
>>>> R-sig-Geo mailing list >> R-sig-Geo at r-project.org >>
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo >> > > -- > Roger Bivand
>>>>
>>>>> Department of Economics, Norwegian School of Economics, > Helleveien 30,
>>>>>
>>>> N-5045 Bergen, Norway. > voice: +47 55 95 93 55
>>>> <+47%2055%2095%2093%2055>;
>>>> e-mail: Roger.Bivand at nhh.no > Editor-in-Chief of The R Journal,
>>>> https://journal.r-project.org/index.html > http://orcid.org/0000-0003-
>>>> 2392-6140 > https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>>>>
>>>> [[alternative HTML version deleted]] ______________________________
>>>> _________________
>>>> R-sig-Geo mailing list R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>
>>>>
>>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>> Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
>> http://orcid.org/0000-0003-2392-6140
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From kranstauber at orn.mpg.de  Thu Aug  3 11:14:01 2017
From: kranstauber at orn.mpg.de (Bart)
Date: Thu, 3 Aug 2017 11:14:01 +0200
Subject: [R-sig-Geo] average bearing of animal movement data
In-Reply-To: <CAAcGz9-=NjN2t8KkzJ7FPK4uP7ZpTidA38=Ddx+_FUunJQOJmA@mail.gmail.com>
References: <929817145.19837927.1501698322422.JavaMail.zimbra@sfu.ca>
 <CANVKczO6-g2pMNTU6NsC4ty1XZgw_snTO6SCXcLRcrRaGW5F0g@mail.gmail.com>
 <CAAcGz9-=NjN2t8KkzJ7FPK4uP7ZpTidA38=Ddx+_FUunJQOJmA@mail.gmail.com>
Message-ID: <bb5bad02-655f-fb64-9f61-44afb87dc751@orn.mpg.de>

Dear Alice,

Since Move inherits a SpatialPointsDataFrame the finding the location 
furthers away can be done as follows (under the assumption the data are 
longlat and the caveat pointed out by Barry):

 > require(move)
 > data(leroy)
 > which.max(spDistsN1(leroy, c(-40,40), longlat=T))
[1] 600

Best

Bart


On 03.08.2017 10:00, Michael Sumner wrote:
> Also, trip is really outdated and dopey and homedist is likely not working
> properly, very happy to help find he answers here there are many options.
>
> Cheers, Mike at tripIsMyFault.org
>
>
> On Thu, 3 Aug 2017, 17:27 Barry Rowlingson, <b.rowlingson at lancaster.ac.uk>
> wrote:
>
>> You can convert a "trip" object to a SpatialPointsDataFrame with
>> as("SpatialPointsDataFrame",my_trip). Then you can use functions like
>> "spDistsN1" from sp to compute the distance from "home" to each point,
>> find the maximum, and then use "bearing" from the "geosphere" package
>> to get the bearing for that row.
>>
>> A complication I see is that this will only return the maximum
>> distance to a vertex point on the trip. For a trip in two flat
>> dimensions the maximum distance will always be a vertex point on the
>> trip but I think on a sphere its possible for great circles between
>> two points to have a location on the circle that is further from a
>> given point than either of the end points. But I can't get my head
>> quite round the 3d triangular geometry this early in the morning. For
>> small steps in a trip where you can approximate the geometry as flat
>> this is not a problem.
>>
>>
>>
>> In contrast, the minimum distance from a trip to a "home" point is
>> rarely a vertex point on the trip because its possible for the trip
>> path to go very close to the home point in question. e.g a trip from
>> (10,0) to (-10,0) goes right through (0,0) but its points are both 10
>> units away.
>>
>> Barry
>>
>>
>>
>>
>> On Wed, Aug 2, 2017 at 7:25 PM, Alice Domalik <adomalik at sfu.ca> wrote:
>>> Hi there,
>>>
>>> I have seabird tracking data and I have used both the packages 'trip'
>> and 'move' to calculate the max distance travelled (using the function
>> 'homedist' in 'trip', and 'distanceSummary' in 'move').
>>> I would also like to describe the bearing of each animal when it is at
>> its maximum displacement from the colony. I am wondering if anyone knows
>> any packages that can calculate this. Alternatively, if someone knows how I
>> can extract the coordinates of the location of maximum displacement.
>>> thanks so much!
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>


From basille.web at ase-research.org  Thu Aug  3 17:22:58 2017
From: basille.web at ase-research.org (Mathieu Basille)
Date: Thu, 3 Aug 2017 11:22:58 -0400
Subject: [R-sig-Geo] average bearing of animal movement data
In-Reply-To: <929817145.19837927.1501698322422.JavaMail.zimbra@sfu.ca>
References: <929817145.19837927.1501698322422.JavaMail.zimbra@sfu.ca>
Message-ID: <f84b2b38-4e93-6c45-937f-fdabed9fdc7a@ase-research.org>

An alternative solution would be to use adehabitatLT to prepare your
trajectories. If you set them to start at the colony (i.e. the first
location is at the colony), then you have nothing to do:

- ltraj objects provide the squared net displacement (R2n), which you can
use to find the furthest point from the colony (max R2n);

- ltraj objects provide absolute and relative bearings for each point, and
you already have the coordinates associated to it.

Hope this helps,
Mathieu.


On 08/02/2017 02:25 PM, Alice Domalik wrote:
> Hi there, 
> 
> I have seabird tracking data and I have used both the packages 'trip' and 'move' to calculate the max distance travelled (using the function 'homedist' in 'trip', and 'distanceSummary' in 'move'). 
> I would also like to describe the bearing of each animal when it is at its maximum displacement from the colony. I am wondering if anyone knows any packages that can calculate this. Alternatively, if someone knows how I can extract the coordinates of the location of maximum displacement. 
> 
> thanks so much! 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 

Mathieu Basille

basille at ufl.edu | http://ase-research.org/basille
+1 954-577-6314 | University of Florida FLREC

  ? Le tout est de tout dire, et je manque de mots
  Et je manque de temps, et je manque d'audace. ?
  ? Paul ?luard


-- 

Mathieu Basille

basille at ufl.edu | http://ase-research.org/basille
+1 954-577-6314 | University of Florida FLREC

  ? Le tout est de tout dire, et je manque de mots
  Et je manque de temps, et je manque d'audace. ?
  ? Paul ?luard


From vkuperman at yahoo.com  Thu Aug  3 23:21:43 2017
From: vkuperman at yahoo.com (Victor Kuperman)
Date: Thu, 3 Aug 2017 21:21:43 +0000 (UTC)
Subject: [R-sig-Geo] Problem with localG in spdep
References: <2047512125.3170449.1501795303031.ref@mail.yahoo.com>
Message-ID: <2047512125.3170449.1501795303031@mail.yahoo.com>

Dear all,
I am new to using R for analyzing geographic data, so any input would be appreciated. My goal is to obtain the G* (local G) Getis-Ord statistic to a metric that is calculated for every US state and Canadian province (except islands, i.e. Hawaii and Prince Edward Island). The metric is standardized and its value range is [-2, 2]. Using spdep, I created a neighbors list from the US + Canada polygon data, and then generated a binary weight matrix.

state_nb <- poly2nb(region_nb)
weights = nb2listw(state_nb, style="B", zero.policy=F)

Upon examination, both the neighbors and the weights seem to be appropriate to the geographic boundary data. As the next step, I am using a localG() with the metric of interest and the weights computed above.

lG = localG(x = metric, listw = weights, zero.policy=NULL, spChk = F)

The resulting statistic, however, shows a weak negative correlation with the original metric. This outcome is implausible, I think, and I can't quite figure out what may have caused it. Any suggestions are appreciated. If more data is necessary to answer this, I'll be happy to provide it. I am new to this and only just learning the rules.

Thank you!
Victor 


	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Fri Aug  4 08:22:21 2017
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 4 Aug 2017 06:22:21 +0000
Subject: [R-sig-Geo] Problem with localG in spdep
In-Reply-To: <2047512125.3170449.1501795303031@mail.yahoo.com>
References: <2047512125.3170449.1501795303031.ref@mail.yahoo.com>,
 <2047512125.3170449.1501795303031@mail.yahoo.com>
Message-ID: <6124293B00A50295.c751b9cd-103b-40a1-9286-ab60eb813cac@mail.outlook.com>

Please provide a reproducible example, either with built-in data or downloadable data, and code, adding your sessionInfo() output. Otherwize all else is guesswork. The function reproduces the examples from Getis & Ord, so it's your data or weights. Just because your data don't yield the answer you want, concluding that the function is broken is unwarranted.

Roger Bivand
Norwegian School of Economics
Bergen, Norway



Fra: Victor Kuperman via R-sig-Geo
Sendt: torsdag 3. august, 23.26
Emne: [R-sig-Geo] Problem with localG in spdep
Til: r-sig-geo at r-project.org


Dear all, I am new to using R for analyzing geographic data, so any input would be appreciated. My goal is to obtain the G* (local G) Getis-Ord statistic to a metric that is calculated for every US state and Canadian province (except islands, i.e. Hawaii and Prince Edward Island). The metric is standardized and its value range is [-2, 2]. Using spdep, I created a neighbors list from the US + Canada polygon data, and then generated a binary weight matrix. state_nb

	[[alternative HTML version deleted]]


From duan.scut.cn at gmail.com  Fri Aug  4 16:06:32 2017
From: duan.scut.cn at gmail.com (duan.scut.cn at gmail.com)
Date: Fri, 4 Aug 2017 23:06:32 +0900
Subject: [R-sig-Geo] R-help: How to draw the same legend (one legend) for
	the multiple spatial figures?
Message-ID: <201708042306278605579@gmail.com>

Dear all, I have ploted several spatial figures, but every one have legend and some of them are different. But I want to plot only one legend for these figures? So could you help me how to make it? I have the following lines for each figure:
  # draw figure
 ##  Open a new default device.
#get( getOption( "device" ) )()
##  Set up plotting in two rows and three columns, plotting along rows first.
 #par( mfrow = c( 3, 3 ) )
my.palette <- brewer.pal(n = 7, name = "OrRd") # set the color styles
##  The first plot is located in row 1, column 1:
a<-spplot(nc1,sp.layout = list("sp.lines", as(lev, "SpatialLines")),main="All",col.regions=my.palette, cuts = 6, col = "transparent",scales=list(draw = TRUE),par.settings=list(fontsize=list(text=17)))
#plot( rnorm( n = 10 ), col = "red", main = "plot 1", cex.lab = 1.1 )
##  The second plot is located in row 1, column 2:
b<-spplot(nc2,sp.layout = list("sp.lines", as(lev, "SpatialLines")),main="CC",col.regions=my.palette, cuts = 6, col = "transparent",scales=list(draw = TRUE),par.settings=list(fontsize=list(text=17)))
##  The third plot is located in row 1, column 3:
c<-spplot(nc3,sp.layout = list("sp.lines", as(lev, "SpatialLines")),main="GF",col.regions=my.palette, cuts = 6, col = "transparent",scales=list(draw = TRUE),par.settings=list(fontsize=list(text=17)))
##  The fourth plot is located in row 2, column 1:
d<-spplot(nc4,sp.layout = list("sp.lines", as(lev, "SpatialLines")),main="HA",col.regions=my.palette, cuts = 6, col = "transparent",scales=list(draw = TRUE),par.settings=list(fontsize=list(text=17)))
##  The fifth plot is located in row 2, column 2:
e<-spplot(nc5,sp.layout = list("sp.lines", as(lev, "SpatialLines")),main="MI",col.regions=my.palette, cuts = 6, col = "transparent",scales=list(draw = TRUE),par.settings=list(fontsize=list(text=17)))
##  The sixth plot is located in row 2, column 3:
f<-spplot(nc6,sp.layout = list("sp.lines", as(lev, "SpatialLines")),main="MP",col.regions=my.palette, cuts = 6, col = "transparent",scales=list(draw = TRUE),par.settings=list(fontsize=list(text=17)))
##  The seventh plot is located in row 3, column 1:
g<-spplot(nc7,sp.layout = list("sp.lines", as(china, "SpatialLines")),main="MR",col.regions=my.palette, cuts = 6, col = "transparent",scales=list(draw = TRUE),par.settings=list(fontsize=list(text=17)))

       Of them, nc1-nc7 are the raster data.
     Thanks a lot!

Wei
      



duan.scut.cn at gmail.com

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Fri Aug  4 21:04:57 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 4 Aug 2017 19:04:57 +0000
Subject: [R-sig-Geo] writeOGR layer options for the KML driver?
Message-ID: <CCF64B04-4FF8-4AB9-90DE-AADE6B22AF38@contoso.com>

Hi,

Where can I find documentation for available layer_options (if any) for the writeOGR KML driver?

Specifically, I want to be able to specify the line color when writing a SpatialLines or SpatialLinesDataFrame object to a KML file for viewing in Google Earth.
(also specifyng a fill color and fill transparency would be nice, but I can certainly do without it)

I see that the plotKML package has a kml() function. I'll send a separate email asking for assistance with it.

Thanks
-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062



From macqueen1 at llnl.gov  Fri Aug  4 21:05:50 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 4 Aug 2017 19:05:50 +0000
Subject: [R-sig-Geo] Help with plotKML::kml() ?
Message-ID: <E8DC6EC4-7A20-460F-AE8E-C241F0011E0C@contoso.com>

Can I get some help with the
   plotKML::kml()
function? I'm looking at various documentation and having trouble finding what I need.

Suppose "foo" is a SpatialPolygonsDataFrame object with a lat/long coordinate reference system. Then in R I can do, for example,

  plot(foo, col='yellow', border='red')

I want to write a KML file that will display the polygon in Google Earth with the same colors.

  plotKML::kml(foo, colour='yellow')

gets the fill, but I can't find how to set the border color.

I'd also like to be able to specify no fill, border only.

Thanks
-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062



From Roger.Bivand at nhh.no  Fri Aug  4 21:48:53 2017
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 4 Aug 2017 21:48:53 +0200
Subject: [R-sig-Geo] writeOGR layer options for the KML driver?
In-Reply-To: <CCF64B04-4FF8-4AB9-90DE-AADE6B22AF38@contoso.com>
References: <CCF64B04-4FF8-4AB9-90DE-AADE6B22AF38@contoso.com>
Message-ID: <alpine.LFD.2.20.1708042145350.12306@reclus.nhh.no>

On Fri, 4 Aug 2017, MacQueen, Don wrote:

> Hi,
>
> Where can I find documentation for available layer_options (if any) for 
> the writeOGR KML driver?

http://www.gdal.org/drv_kml.html

for the KML driver,

http://www.gdal.org/drv_libkml.html

for the LIBKML driver. I an uncertain about their ability to do what you 
need.

Roger

>
> Specifically, I want to be able to specify the line color when writing a 
> SpatialLines or SpatialLinesDataFrame object to a KML file for viewing 
> in Google Earth. (also specifyng a fill color and fill transparency 
> would be nice, but I can certainly do without it)
>
> I see that the plotKML package has a kml() function. I'll send a 
> separate email asking for assistance with it.
>
> Thanks
> -Don
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From payneb at post.bgu.ac.il  Sun Aug  6 11:53:31 2017
From: payneb at post.bgu.ac.il (Brandon Payne)
Date: Sun, 06 Aug 2017 12:53:31 +0300
Subject: [R-sig-Geo] How to draw the same legend (one legend) for	the
 multiple spatial figures?
In-Reply-To: <mailman.3.1501927202.10496.r-sig-geo@r-project.org>
References: <mailman.3.1501927202.10496.r-sig-geo@r-project.org>
Message-ID: <m2wp6hyqck.fsf@post.bgu.ac.il>

How to draw the same legend (one legend) for	the
      multiple spatial figures?

I would put the legend next to the upper-most plot and
wrap the whole thing in a single

/figure

so that it would be more obvious that the same legend applied to all.


From rafa.pereira.br at gmail.com  Sun Aug  6 13:51:50 2017
From: rafa.pereira.br at gmail.com (Rafael Pereira)
Date: Sun, 6 Aug 2017 12:51:50 +0100
Subject: [R-sig-Geo] bivariate spatial correlation in R
In-Reply-To: <alpine.LFD.2.20.1708031059430.32106@reclus.nhh.no>
References: <CAA42DGnbWzkOfhMWttTkjaMEdOyDKLkZ=DDDYjywJrhFrKgjtw@mail.gmail.com>
 <alpine.LFD.2.20.1707242012390.6677@reclus.nhh.no>
 <CAA42DGm1dhzEvN9vYyRfKS7XuPVnXFgVBfRHWFLGS29H4R65Cw@mail.gmail.com>
 <alpine.LFD.2.20.1707261152010.18617@reclus.nhh.no>
 <CAA42DGkhtyTHpW3ZoFAOHdDcjY6iK0LZpZFdkvnmihieujzbGg@mail.gmail.com>
 <6124293B00A50295.e0f9c23d-4edb-4035-aab0-756e53b6db82@mail.outlook.com>
 <CAA42DGk8agiCMPp5FLwSrd1wszaVcNHd5uB6fCkdT9rb8QHLOw@mail.gmail.com>
 <alpine.LFD.2.20.1707312250480.10503@reclus.nhh.no>
 <CAA42DGmVuch59mUwQa9_i3rfPtvqh4TByhnnCxBRxxT6_qSFZg@mail.gmail.com>
 <alpine.LFD.2.20.1708031059430.32106@reclus.nhh.no>
Message-ID: <CAA42DG=+nVq58if=AmSmZoCNOXukk=ojQGWEefzq95bC8v5-dw@mail.gmail.com>

Hi Roger,

you're correct in pointing out that the code would much more work to be
incorporated in the spdep library. This is something that Rogerio and I are
considering to do in the next few months as both of us find more time in
our agendas.

Thank you again for the discussion. The amount of work and attention you
put into this community is exceptional for someone as busy as you are and
this is much appreciated!

best,

Rafa

On Thu, Aug 3, 2017 at 10:13 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Wed, 2 Aug 2017, Rafael Pereira wrote:
>
> Roger,
>>
>>
>> Thank you for your response.
>>
>>
>> I recognize the data is not ideal and the analysis has limitations because
>> of the lack of information on population displacements that might have
>> occurred over the years. Nonetheless, there are plenty of data +
>> literature
>> showing how the spatial distribution of income classes and land use
>> patterns is fairly stable over time in this city, particularly for a short
>> timescales like in this analysis. Having said this, I believe these two
>> questions (1) what socioeconomic classes have gained more accessibility?
>> and (2) ?were wealthier areas in 2010 able to attract more changes to
>> accessibility?? in the end ask the same thing but with different
>> phrasings,
>> though your phrasing (2) is more precise/correct.
>>
>>
>>
>> On the more technical discussion, I see your point that spatial AND
>> temporal correlation in my data would make permutation bootstrap
>> inappropriate to generate significance levels, thus making bivariate
>> Moran?s I biased. Thank you very much for the clarifications! This has
>> been
>> very helpful and I will have a closer look at which spatial regression
>> models are more appropriate for my analysis.
>>
>>
>> On a side note, do you think the function to calculate bivariate Moran?s I
>> is correct?  And could it be incorporated in the next version of spdep? If
>> so, please give credit to Rog?rio Barbosa, the researcher who proposed the
>> code in Stack Overflow.
>>
>
> Perhaps, but SO is usually ephemeral (nobody takes responsibility for
> documenting code and fixing bugs found later). I don't see any tests,
> documentation or accommodation of what spdep expects for edge cases - the
> function as it stands would need a lot of work to protect users from
> obvious blunders. There are no references to literature, nor to proven test
> cases which this implementation should match. We have an implementation of
> Lee (2001), but this is not the same, right? Which article gives the formal
> statistical development of the bivariate local Moran's I? Do we know that
> conditional simulation (permutation bootstrap) is valid in some cases, if
> so which? Is there a development of parametric bootstrap?
>
>
> Roger
>
>
>> best,
>>
>> Rafael HM Pereira
>> http://urbandemographics.blogspot.com
>>
>>
>> On Mon, Jul 31, 2017 at 10:52 PM, Roger Bivand <Roger.Bivand at nhh.no>
>> wrote:
>>
>> Rafael,
>>>
>>> I'm sorry, but there is no way you can logically "analyze who benefits
>>> the
>>> recent changes in the transport system in terms of access to jobs" from
>>> the
>>> data you have.
>>>
>>> Even if you had aggregate household income data for 2014 and 2017 (not
>>> for
>>> 2010 only), you would not know whether wealthier families had not
>>> dispaced
>>> poorer families as accessibility improved. You need individual data,
>>> either
>>> survey or register, preferably panel, to show that changes in
>>> accessibility
>>> change the economic welfare of households controlling for movement of
>>> households. The timestamps on the data make any attempt to do this very
>>> risky; the real findings from a hypothetical surevey-based panel might be
>>> completely different, especially if poorer households were displaced
>>> (also
>>> indirectly, through rising house prices driven by improved
>>> accessibility).
>>> Gauging the welfare effects of transport investments is very hard to
>>> instrument.
>>>
>>> The closest I could get was to map deciles of the change in access (more
>>> negatives than positives) and compare the aspatial income distributions:
>>>
>>> library(spdep)
>>> library(rgdal)
>>> map <- readOGR(dsn=".", layer="test_map")
>>> library(classInt)
>>> cI <- classIntervals(map$diffaccess, n=10, style="quantile")
>>> library(RColorBrewer)
>>> ybrpal <- brewer.pal(6, "YlOrBr")
>>> fC <- findColours(cI, ybrpal)
>>> qtm(map, fill="diffaccess", fill.breaks=cI$brks, format="Europe2")
>>> map$faccess <- factor(findInterval(map$diffaccess, cI$brks,
>>>   all.inside=TRUE), labels=names(attr(fC, "table")))
>>> qtm(map, fill="diffaccess", fill.breaks=cI$brks, format="Europe2")
>>> acc_income <- split(map$income, map$faccess)
>>> do.call("rbind", lapply(acc_income, summary))
>>> dens <- lapply(acc_income, density)
>>> plot(1, ylab="", xlab="", type="n", xlim=c(-2000, 11000), ylim=c(0,
>>>   0.002))
>>> for (i in seq(along=dens)) lines(dens[[i]], col=i)
>>> legend("topright", legend=names(dens), col=1:length(dens), lty=1,
>>> bty="n")
>>>
>>> These density curves really do not suggest any clear relationship, other
>>> than that some areas with increased accessibility had higher incomes in
>>> 2010.
>>>
>>> You can examine the reverse relationship - were aggregate areas that were
>>> more wealthy in 2010 able to attract more changes to accessibility? The
>>> answer seems to be yes, they were able to do this:
>>>
>>> nb <- poly2nb(map)
>>> lw <- nb2listw(nb, style = "W", zero.policy = T)
>>> lm.morantest(lm(diffaccess ~ I(income/1000), map), lw)
>>> # SLX model
>>> summary(lmSLX(diffaccess ~ I(income/1000), map, lw))
>>> lm.morantest(lmSLX(diffaccess ~ I(income/1000), map, lw), lw)
>>> # Spatial Durbin error model - SDEM
>>> obj <- errorsarlm(diffaccess ~ I(income/1000), map, lw, etype="emixed")
>>> summary(impacts(obj))
>>> summary(impacts(lmSLX(diffaccess ~ I(income/1000), map, lw)))
>>> LR.sarlm(lmSLX(diffaccess ~ I(income/1000), map, lw), obj)
>>>
>>> It would be possible to run lm.morantest.sad() on the output of the SDEM
>>> model taking global spatial autocorrelation into account. If you need
>>> that,
>>> follow up in this thread.
>>>
>>> Bivariate Moran's I should not be used in this case, but could be used in
>>> other cases - use in change over time is troubling because randomisation
>>> will not be a good guide as t=1 and t=2 are subject to temporal as well
>>> as
>>> spatial autocorrelation, so you cannot use permutation bootstrap to find
>>> a
>>> usable measure of significance.
>>>
>>> Hope this clarifies, and thanks for the code.
>>>
>>> Roger
>>>
>>> On Sun, 30 Jul 2017, Rafael Pereira wrote:
>>>
>>> Roger,
>>>
>>>>
>>>> Population and income data are single point in time and come from the
>>>> 2010
>>>> Census.
>>>>
>>>> Accessibility variables in 2014 and 2017 show the proportion of jobs
>>>> accessible by public transport under 60 minutes. The variable diffaccess
>>>> shows the difference between these two. It's in percentage points
>>>> (access2017 - access2014)
>>>>
>>>> best,
>>>>
>>>> Rafael H M Pereira
>>>> urbandemographics.blogspot.com
>>>>
>>>> On Sun, Jul 30, 2017 at 7:41 AM, Roger Bivand <Roger.Bivand at nhh.no>
>>>> wrote:
>>>>
>>>> Thanks, I'll get back when able, offline now. What are the units of
>>>>
>>>>> observation, and are aggregate household incomes observed only once?
>>>>>
>>>>> Roger
>>>>>
>>>>> Roger Bivand
>>>>> Norwegian School of Economics
>>>>> Bergen, Norway
>>>>>
>>>>>
>>>>>
>>>>> Fra: Rafael Pereira
>>>>> Sendt: s?ndag 30. juli, 00.39
>>>>> Emne: Re: [R-sig-Geo] bivariate spatial correlation in R
>>>>> Kopi: Rog?rio Barbosa, r-sig-geo at r-project.org
>>>>>
>>>>>
>>>>> Hi all, here is a reproducible example to calculate in R bivariate
>>>>> Moran's
>>>>> I and LISA clusters. This example is based on a this answer provided in
>>>>> SO*
>>>>> and it uses a toy model of my data. The R script and the shape file
>>>>> with
>>>>> the data are available on this link. https://gist.github.com/
>>>>> rafapereirabr/5348193abf779625f5e8c5090776a228 What this example does
>>>>> is
>>>>> to estimate the spatial association between household income per capita
>>>>> and
>>>>> the gains in accessibility to jobs. The aim is to analyze who benefits
>>>>> the
>>>>> recent changes in the transport system in terms of access to jobs. So
>>>>> the
>>>>> idea is not to find causal relationships, but spatial association
>>>>> between
>>>>> areas of high/low income who had high/low gains in accessibility. The
>>>>> variables in the data show info on the proportion of jobs accessible in
>>>>> both years 2014 and 2017 (access2014, access2017) and the difference
>>>>> between the two years in percentage points (diffaccess). Roger, I know
>>>>> you
>>>>> have shown to be a bit sceptical about this application of bivariate
>>>>> Moran's I. Do you still think a spatial regression would be more
>>>>> appropriate? Also, I would be glad to hear if others have comments on
>>>>> the
>>>>> code. This function is not implemented in any package so it would be
>>>>> great
>>>>> to have some feedback. Rafael H M Pereira
>>>>> urbandemographics.blogspot.com
>>>>> * https://stackoverflow.com/questions/45177590/map-of-
>>>>> bivariate-spatial-correlation-in-r-bivariate-lisa On Wed, Jul 26, 2017
>>>>> at
>>>>> 11:07 AM, Roger Bivand wrote: > On Wed, 26 Jul 2017, Rafael Pereira
>>>>> wrote:
>>>>>
>>>>> Roger, >> >> This example was provided only for the sake or making the
>>>>>>
>>>>>>>
>>>>>>> code easily >> reproducible for others and I'm more interested in how
>>>>>>
>>>>> the
>>>>> bi-variate >> Moran >> could be implemented in R, but your comments are
>>>>> very much welcomed and >> I've made changes to the question. >> >> My
>>>>> actual case study looks at bi-variate spatial correlation between (a)
>>>>> >>
>>>>> average household income per capita and (b) proportion of jobs in the
>>>>> city
>>>>>
>>>>> that are accessible under 60 minutes by transit. I don't think I could
>>>>>>
>>>>>>>
>>>>>>> use >> rates in this case but I will normalize the variables using >>
>>>>>>
>>>>> scale(data$variable). >> > > Please provide a reproducible example,
>>>>> either
>>>>> with a link to a data > subset, or using a builtin data set. My guess
>>>>> is
>>>>> that you do not need > bi-variate spatial correlation at all, but
>>>>> rather
>>>>> a
>>>>> spatial regression. > > The "causal" variable would then the the
>>>>> proportion
>>>>> of jobs accessible > within 60 minutes by transit, though this is
>>>>> extremely
>>>>> blunt, and lots of > other covariates (demography, etc.) impact average
>>>>> household income per > capita (per block/tract?). Since there are many
>>>>> missing variables in your > specification, any spatial correlation
>>>>> would
>>>>> be
>>>>> most closely associated > with them (demography, housing costs,
>>>>> education,
>>>>> etc.), and the choice of > units of measurement would dominate the
>>>>> outcome.
>>>>>
>>>>> This is also why bi-variate spatial correlation is seldom a good idea,
>>>>>>
>>>>>>>
>>>>>>> I > believe. It can be done, but most likely shouldn't, unless it can
>>>>>>
>>>>> be >
>>>>> motivated properly. > > By the way, the weighted and FDR-corrected SAD
>>>>> local Moran's I p-values of > the black/white ratio for Oregon (your
>>>>> toy
>>>>> example) did deliver the goods - > if you zoom in in mapview::mapview,
>>>>> you
>>>>> can see that it detects a rate > hotspot between the rivers. > > Roger
>>>>> >
>>>>>
>>>>>>
>>>>>>
>>>>> best, >> >> Rafael H M Pereira >> >> On Mon, Jul 24, 2017 at 7:56 PM,
>>>>>>
>>>>>>>
>>>>>>>> Roger Bivand >> wrote: >> >> On Mon, 24 Jul 2017, Rafael Pereira
>>>>>>>
>>>>>> wrote: >>>
>>>>>
>>>>> Hi all, >>> >>>> >>>> I would like to ask whether some you conducted
>>>>>>
>>>>>>>
>>>>>>>> bi-variate spatial >>>> correlation in R. >>>> >>>> I know the
>>>>>>>
>>>>>> bi-variate
>>>>> Moran's I is not implemented in the spdep library. >>>> I left a
>>>>> question
>>>>> on SO but also wanted to hear if anyone if the >>>> mainlist >>>> have
>>>>> come
>>>>> across this. >>>> https://stackoverflow.com/questions/45177590/map-of-
>>>>> bivariat >>>> e-spatial-correlation-in-r-bivariate-lisa >>>> >>>> I
>>>>> also
>>>>> know Roger Bivand has implemented the L index proposed by Lee >>>>
>>>>> (2001)
>>>>>
>>>>> in spdep, but I'm not I'm not sure whether the L local correlation
>>>>>>
>>>>>>> coefficients can be interpreted the same way as the local Moran's I
>>>>>>>>> coefficients. I couldn't find any reference commenting on this
>>>>>>>>> issue.
>>>>>>>>>
>>>>>>>>> I >>>> would very much appreciate your thoughts this. >>>> >>>> >>>
>>>>>>>>
>>>>>>> In the
>>>>> SO question, and in the follow-up, your presumably throw-away >>>
>>>>> example
>>>>> makes fundamental mistakes. The code in spdep by Virgilio >>>
>>>>> G?mez-Rubio
>>>>> is for uni- and bivariate L, and produces point values of >>> local >>>
>>>>> L.
>>>>> This isn't the main problem, which is rather that you are not taking
>>>>> >>>
>>>>> account of the underlying population counts, nor shrinking any
>>>>> estimates
>>>>>
>>>>> of >>> significance to accommodate population sizes. Population sizes
>>>>>>
>>>>>>>
>>>>>>>> vary from >>> 0 >>> to 11858, with the lower quartile at 3164 and
>>>>>>> upper
>>>>>>>
>>>>>> 5698: >>> plot(ecdf(oregon.tract$pop2000)). Should you be comparing
>>>>> rates
>>>>> in >>> stead? >>> These are also compositional variables (sum to
>>>>> pop2000,
>>>>> or 1 if rates) >>> with >>> the other missing components. You would
>>>>> probably be better served by >>> tools >>> examining spatial
>>>>> segregation,
>>>>> such as for example the seg package. >>> >>> The 0 count populations
>>>>> cause
>>>>> problems for an unofficial alternative, the >>> black/white ratio: >>>
>>>>>
>>>>>>
>>>>>>>> oregon.tract1 0,] >>> oregon.tract1$rat >> nb >> lw >> >>> which
>>>>> should
>>>>> still be adjusted by weighting: >>> >>> lm0 >> >>> I'm not advising
>>>>> this,
>>>>> but running localmoran.sad on this model output >>> yields SAD
>>>>> p-values <
>>>>> 0.05 after FDR correction only in contiguous tracts >>> on the
>>>>> Washington
>>>>> state line in Portland between the Columbia and >>> Williamette rivers.
>>>>> So
>>>>> do look at the variables you are using before >>> rushing into things.
>>>>>
>>>>>>
>>>>>>>>
>>>>> Hope this clarifies, >>> >>> Roger >>> >>> >>> best, >>>> >>>> Rafael
>>>>>>
>>>>>>>
>>>>>>>> HM Pereira >>>> http://urbandemographics.blogspot.com >>>> >>>>
>>>>>>>
>>>>>> [[alternative HTML version deleted]] >>>> >>>>
>>>>> _______________________________________________ >>>> R-sig-Geo mailing
>>>>> list >>>> R-sig-Geo at r-project.org >>>> https://stat.ethz.ch/mailman/
>>>>> listinfo/r-sig-geo >>>> >>>> >>>> -- >>> Roger Bivand >>> Department of
>>>>> Economics, Norwegian School of Economics, >>> Helleveien 30, N-5045
>>>>> Bergen,
>>>>> Norway. >>> voice: +47 55 95 93 55 <+47%2055%2095%2093%2055>; e-mail:
>>>>> Roger.Bivand at nhh.no >>> Editor-in-Chief of The R Journal,
>>>>> https://journal.r-project.org/ >>> index.html >>>
>>>>> http://orcid.org/0000-0003-2392-6140 >>> https://scholar.google.no/
>>>>> citations?user=AWeghB0AAAAJ&hl=en >>> >> >> [[alternative HTML version
>>>>> deleted]] >> >> _______________________________________________ >>
>>>>> R-sig-Geo mailing list >> R-sig-Geo at r-project.org >>
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo >> > > -- > Roger
>>>>> Bivand
>>>>>
>>>>> Department of Economics, Norwegian School of Economics, > Helleveien
>>>>>> 30,
>>>>>>
>>>>>> N-5045 Bergen, Norway. > voice: +47 55 95 93 55
>>>>> <+47%2055%2095%2093%2055>;
>>>>> e-mail: Roger.Bivand at nhh.no > Editor-in-Chief of The R Journal,
>>>>> https://journal.r-project.org/index.html > http://orcid.org/0000-0003-
>>>>> 2392-6140 > https://scholar.google.no/cita
>>>>> tions?user=AWeghB0AAAAJ&hl=en
>>>>>
>>>>>>
>>>>>> [[alternative HTML version deleted]] ______________________________
>>>>> _________________
>>>>> R-sig-Geo mailing list R-sig-Geo at r-project.org
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>>>>
>>>>>
>>>>>
>>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics,
>>> Helleveien 30, N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>>> Editor-in-Chief of The R Journal, https://journal.r-project.org/
>>> index.html
>>> http://orcid.org/0000-0003-2392-6140
>>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>>
>>>
>>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
> Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>

	[[alternative HTML version deleted]]


From bfalevlist at gmail.com  Sun Aug  6 14:13:07 2017
From: bfalevlist at gmail.com (=?UTF-8?Q?Bede-Fazekas_=c3=81kos?=)
Date: Sun, 6 Aug 2017 14:13:07 +0200
Subject: [R-sig-Geo] How to draw the same legend (one legend) for the
 multiple spatial figures?
In-Reply-To: <m2wp6hyqck.fsf@post.bgu.ac.il>
References: <mailman.3.1501927202.10496.r-sig-geo@r-project.org>
 <m2wp6hyqck.fsf@post.bgu.ac.il>
Message-ID: <2967590e-83e7-8d26-9191-9086a0498900@gmail.com>

Dear Brandon and Wei,
I don't know the answer to your question but a somewhat similar solution 
is when you plot a separate legend using lattice::draw.key() and disable 
sp::spplot()'s built-in legend using argument "auto.key = FALSE".
An example:

# loading libraries
library(lattice)
library(sp)
library(gridExtra)
library(grid)

# drawing legend
no_of_categories <- 10
cutpoints <- seq(from = 0 - 0.0001, to = 1 + 0.0001, length.out = 
no_of_categories + 1)
legend_text <- apply(X = cbind(round(cutpoints [1:no_of_categories], 1), 
round(cutpoints [2:(no_of_categories + 1)], 1)), MARGIN = 1, FUN = 
function(number) {return(paste(format(x = number, digits = 2), collapse 
= " - "))})
legend_colors <- colorRampPalette(c("red", "orange", "yellow", 
"lightgreen", "darkgreen"))(no_of_categories)
legend <- draw.key(key = list(reverse.rows = TRUE, space = "right", 
rectangles = list(col = legend_colors, border = FALSE), text = 
list(legend_text)), draw = FALSE)
dev.off()

# drawing maps
maps <- list()
for (column_name in colnames(sp_object at data)) {
     map <- spplot(obj = sp_object, zcol = column_name, auto.key = 
FALSE, col.regions = legend_colors, cuts = cutpoints)
     maps <- append(maps , list(map))
}
maps <- append(maps , list(legend))

# plotting the map-legend composite to a png file
layout <- rbind(c(1,2), c(3,4), c(5,6)) # let's say we have 5 maps and a 
legend
composite <- do.call(arrangeGrob, c(maps, list(layout_matrix = layout), 
list(widths = c(1, 1))))
png(width = 1000, height = 1000, filename = "map.png"))
     grid.newpage()
     grid.draw(composite)
dev.off()

Hope this helps,
?kos Bede-Fazekas
Hungarian Academy of Sciences

2017.08.06. 11:53 keltez?ssel, Brandon Payne ?rta:
> How to draw the same legend (one legend) for	the
>        multiple spatial figures?
>
> I would put the legend next to the upper-most plot and
> wrap the whole thing in a single
>
> /figure
>
> so that it would be more obvious that the same legend applied to all.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From florian.detsch at staff.uni-marburg.de  Mon Aug  7 10:04:22 2017
From: florian.detsch at staff.uni-marburg.de (Florian Detsch)
Date: Mon, 7 Aug 2017 10:04:22 +0200
Subject: [R-sig-Geo] How to draw the same legend (one legend) for the
 multiple spatial figures?
In-Reply-To: <2967590e-83e7-8d26-9191-9086a0498900@gmail.com>
References: <mailman.3.1501927202.10496.r-sig-geo@r-project.org>
 <m2wp6hyqck.fsf@post.bgu.ac.il>
 <2967590e-83e7-8d26-9191-9086a0498900@gmail.com>
Message-ID: <8232e939-8ab0-cf92-c182-ac410018c0f5@staff.uni-marburg.de>

Dear Wei,

probably the most straightforward way to combine multiple trellis plots 
into one is via latticeExtra::c.trellis(). Be aware, however, that the 
desired range of z-values (from which your legend will ultimately be 
created) needs to be assigned manually to each sub-plot using 'at'. Here 
is a minimal example based on the meuse.grid 'SpatialPixelsDataFrame' 
from sp, which works the same eg for 'Raster*' objects.

-----

## sample data
library(sp)
data("meuse.grid")
gridded(meuse.grid) = ~ x + y
meuse.grid$dist2 = meuse.grid$dist^2

p1 = spplot(meuse.grid, zcol = "dist", at = seq(0, 1, .01),
             sp.layout = list("sp.text", c(179000, 333250), "a) dist"),
             colorkey = list(height = .5), scales = list(draw = TRUE))
p2 = spplot(meuse.grid, zcol = "dist2", at = seq(0, 1, .01),
             sp.layout = list("sp.text", c(179000, 333250), "b) dist2"))

## combine plots using latticeExtra::c.trellis
update(c(p1, p2), layout = c(1, 2), as.table = TRUE) # 1 column, 2 rows
update(c(p1, p2)) # 1 row, 2 columns

-----

In order to combine numerous plots into one (eg stored in a 'list'), you 
can take inspiration from the Reduce()-based approach in 
Orcs::latticeCombineGrid() (see 
https://github.com/fdetsch/Orcs/blob/master/R/latticeCombineGrid.R; 
credit goes to Tim Appelhans), among others.

Best,
Florian


On 06.08.2017 14:13, Bede-Fazekas ?kos wrote:
> Dear Brandon and Wei,
> I don't know the answer to your question but a somewhat similar 
> solution is when you plot a separate legend using lattice::draw.key() 
> and disable sp::spplot()'s built-in legend using argument "auto.key = 
> FALSE".
> An example:
>
> # loading libraries
> library(lattice)
> library(sp)
> library(gridExtra)
> library(grid)
>
> # drawing legend
> no_of_categories <- 10
> cutpoints <- seq(from = 0 - 0.0001, to = 1 + 0.0001, length.out = 
> no_of_categories + 1)
> legend_text <- apply(X = cbind(round(cutpoints [1:no_of_categories], 
> 1), round(cutpoints [2:(no_of_categories + 1)], 1)), MARGIN = 1, FUN = 
> function(number) {return(paste(format(x = number, digits = 2), 
> collapse = " - "))})
> legend_colors <- colorRampPalette(c("red", "orange", "yellow", 
> "lightgreen", "darkgreen"))(no_of_categories)
> legend <- draw.key(key = list(reverse.rows = TRUE, space = "right", 
> rectangles = list(col = legend_colors, border = FALSE), text = 
> list(legend_text)), draw = FALSE)
> dev.off()
>
> # drawing maps
> maps <- list()
> for (column_name in colnames(sp_object at data)) {
>     map <- spplot(obj = sp_object, zcol = column_name, auto.key = 
> FALSE, col.regions = legend_colors, cuts = cutpoints)
>     maps <- append(maps , list(map))
> }
> maps <- append(maps , list(legend))
>
> # plotting the map-legend composite to a png file
> layout <- rbind(c(1,2), c(3,4), c(5,6)) # let's say we have 5 maps and 
> a legend
> composite <- do.call(arrangeGrob, c(maps, list(layout_matrix = 
> layout), list(widths = c(1, 1))))
> png(width = 1000, height = 1000, filename = "map.png"))
>     grid.newpage()
>     grid.draw(composite)
> dev.off()
>
> Hope this helps,
> ?kos Bede-Fazekas
> Hungarian Academy of Sciences
>
> 2017.08.06. 11:53 keltez?ssel, Brandon Payne ?rta:
>> How to draw the same legend (one legend) for    the
>>        multiple spatial figures?
>>
>> I would put the legend next to the upper-most plot and
>> wrap the whole thing in a single
>>
>> /figure
>>
>> so that it would be more obvious that the same legend applied to all.
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Dr. Florian Detsch
Environmental Informatics
Department of Geography
Philipps-Universit?t Marburg
Deutschhausstra?e 12
35032 (parcel post: 35037) Marburg, Germany

Phone: +49 (0) 6421 28-25323
Web: http://www.uni-marburg.de/fb19/fachgebiete/umweltinformatik/detschf/index.html


From tom.hengl at gmail.com  Mon Aug  7 18:50:23 2017
From: tom.hengl at gmail.com (Tomislav Hengl)
Date: Mon, 7 Aug 2017 18:50:23 +0200
Subject: [R-sig-Geo] help with plotKML::kml()
In-Reply-To: <1417022B-6247-4C13-BE01-F303BB8EDA0C@llnl.gov>
References: <1417022B-6247-4C13-BE01-F303BB8EDA0C@llnl.gov>
Message-ID: <43fe9b29-b174-058b-3656-7e265b6d0a83@gmail.com>


I think I set the color of the polygon line "white" which is the KML 
default, so you can only change the color of polygons (fill); see:

https://github.com/cran/plotKML/blob/master/R/layer.SpatialPolygons.R#L112

To change colors per polygon you should run:

data(eberg_zones)
legend = get("colour_scale_factor", envir = plotKML.opts)
kml_open("eberg_zones.kml")
kml_layer(eberg_zones, colour=ZONES, colour_scale=legend)
kml_close("eberg_zones.kml")

See also: http://gsif.isric.org/doku.php/wiki:tutorial_plotkml

Polygon outlines 
(https://developers.google.com/kml/documentation/kmlreference#polystyle) 
could also be changed but not via plotKML.

HTH,


On 07-08-17 17:46, MacQueen, Don wrote:
> Hi Tomislav,
> 
> I am using the kml() function in the plotKML package to write a SpatialPolygonsDataFrame object to a kml file, and would like to know if it is possible to specify the fill color and border color separately. I have been looking at documentation and been unable to find a way. I would appreciate any suggestions.
> 
> 
> Suppose "foo" is a SpatialPolygonsDataFrame object with a lat/long coordinate reference system. Then in R I can do, for example,
> 
>    plot(foo, col='yellow', border='red', lwd=2)
> 
> I would like to write a KML file that will display the polygon in Google Earth in a similar manner.
> 
> I have found that
>     plotKML::kml(foo, colour='yellow')
> controls the fill color, but I can't find how to set the border color.
> 
> Ideally, I'd also like to be able specify border only, no fill, and also line widths for the border.
> 
> For example, the kml file might have in it something like:
> <Style id="blue">
>      <PolyStyle>
>      <color>4DFF0000</color>
>      <fill>1</fill>
>      <outline>1</outline>
>      </PolyStyle>
>      <LineStyle>
>      <color>FFFF0000</color>
>      <width>2</width>
>      </LineStyle>
> </Style>
> 
> 
> Thanks
> -Don
>


From payneb at post.bgu.ac.il  Tue Aug  8 16:23:03 2017
From: payneb at post.bgu.ac.il (Brandon Payne)
Date: Tue, 8 Aug 2017 14:23:03 +0000
Subject: [R-sig-Geo] $columns that I added to a data frame don't have attr(*,
	"label")
Message-ID: <CAN4m+BJB6pkn9Vy+geUMQ+0L89XWx0+Yi1CM5kpouNXbe_sHwQ@mail.gmail.com>

How can I make $size and $stock
(that I made)

have attr()   like the $columns that came with the data

$ CLUSTER         :Classes 'labelled', 'integer'  atomic [1:90435] 4 4 4 4
4 4 4 4 4 4 ...
  .. ..- attr(*, "label")= Named chr "Socio-economic level of locality"
  .. .. ..- attr(*, "names")= chr "CLUSTER"
 $ size            : chr  "largest" "largest" "largest" "largest" ...
 $ stock           : num  596 596 596 596 596 ...

	[[alternative HTML version deleted]]


From jecogeo at gmail.com  Wed Aug  9 04:42:05 2017
From: jecogeo at gmail.com (Jefferson Ferreira-Ferreira)
Date: Tue, 8 Aug 2017 22:42:05 -0400
Subject: [R-sig-Geo] Regression with rasters using calc::raster
Message-ID: <CAFFT+Y6UrL5TmqavQ+19M9YRaDCmoz=RJui5DmZPm9rsE9=EWA@mail.gmail.com>

Dears,

I'm trying to fit the Firth's Penalized MLE GLM implemented in logistf
package to a set of rasters but I'm facing errors and problems I couldn't
realize until now.

# Lets generate 2 rasters reproducing what I'm facing
r <- raster(nrow=10, ncol=10)

# binary response raster-variable with 9 bands
s1 <- lapply(1:9, function(i) setValues(r, sample(0:1,ncell(r),replace =
T)))
s1 <- stack(s1)

# one explanatory raster-variable
val <- sample(0:60,ncell(r),replace = T)
s2 <- raster(nrow=10, ncol=10,vals=val)

plot(s1)
plot(s2)

# a second explanatory variable. Nine values
exp_2 <- c(27.00,30.02,31.07,32.72,33.73,35.12,35.65,36.06,38.32)

Now, I want to fit a model using Firth's Penalized MLE GLM implemented in
logistf (i have reasons for this not reproduced here) using calc from
raster package. That's where the mystery lives.

The rationale is each cell in:
s1/layer1 ~ 27.00 + corresponding cell in s2 + 27.00:corresponding cell in
s2
s1/layer2 ~ 30.02 + corresponding cell in s2 + 30.02:corresponding cell in
s2
s1/layer3 ~ 31.07 + corresponding cell in s2 + 31.07:corresponding cell in
s2
... and so on for all 9 bands of my response raster-variable, which are
paired with values from exp_2.

# I tried something like this:
fun <- function(x) { logistf(x ~ exp_2 + s2 + exp_2:s2)$coefficients }
coefs <- calc(s1,fun)

But it was clear it wouldn't work. The tricky part is to tell R I want each
value of exp_2 to be used with each rasterlayer of s1 for this model.

Any idea would be appreciated. Ideas?
Thanks in advance

*Jefferson Ferreira-Ferreira, **PhD (abd)*

*Geographer*



*Ecosystem Dynamics Observatory <http://tscanada.wix.com/ecodyn> -
EcoDyn/UNESP*
*Department of **Geography *
*Institute of Geosciences and Exact Sciences** (IGCE)*
*S?o Paulo State University (UNESP)*
*Rio Claro, SP - Brazil*

	[[alternative HTML version deleted]]


From javier.garcia at ehu.eus  Sun Aug 13 03:35:31 2017
From: javier.garcia at ehu.eus (=?iso-8859-1?Q?Javier_Garc=EDa?=)
Date: Sun, 13 Aug 2017 03:35:31 +0200
Subject: [R-sig-Geo] How to test spatial dependence in errorsarlm
Message-ID: <000001d313d4$7492d250$5db876f0$@ehu.eus>

Hello everybody:

 

I have estimated a spatial error model and now I would like to test whether
that model has really ?deleted? the spatial dependence. For the spatial lag
model and for the Durbin model the function lagsarlm gives the LM test for
residual autocorrelation test value, but the function errorsarlm does not.
Does anyone know how to do it in R?

 

Thanks a lot in advance.

 

Javi

 

	


JAVIER GARC?A 

 

Departamento de Econom?a Aplicada III (Econometr?a y Estad?stica)

Facultad de Econom?a y Empresa (Secci?n Sarriko)
Avda. Lehendakari Aguirre 83

48015 BILBAO
T.: +34 601 7126 F.: +34 601 3754
 <http://www.ehu.es/> www.ehu.es 

http://www.unibertsitate-hedakuntza.ehu.es/p268-content/es/contenidos/inform
acion/manual_id_corp/es_manual/images/firma_email_upv_euskampus_bilingue.gif

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20170813/1d477745/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.gif
Type: image/gif
Size: 6359 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20170813/1d477745/attachment.gif>

From javier.garcia at ehu.eus  Sun Aug 13 04:00:25 2017
From: javier.garcia at ehu.eus (=?iso-8859-1?Q?Javier_Garc=EDa?=)
Date: Sun, 13 Aug 2017 04:00:25 +0200
Subject: [R-sig-Geo] Heteroscedasticity in Spatial Error Model
Message-ID: <000901d313d7$edf21cc0$c9d65640$@ehu.eus>

Hello again:

 

Please, could anyone tell me how to estimate robust standard errors for a
spatial error model? The residuals of my model show heteroscedasticity
evidence, but the functions I have looked at only work with lm type objects.

 

Thanks a lot in advance.

 

Javi

 

	


JAVIER GARC?A 

 

Departamento de Econom?a Aplicada III (Econometr?a y Estad?stica)

Facultad de Econom?a y Empresa (Secci?n Sarriko)
Avda. Lehendakari Aguirre 83

48015 BILBAO
T.: +34 601 7126 F.: +34 601 3754
 <http://www.ehu.es/> www.ehu.es 

http://www.unibertsitate-hedakuntza.ehu.es/p268-content/es/contenidos/inform
acion/manual_id_corp/es_manual/images/firma_email_upv_euskampus_bilingue.gif

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20170813/5a8e3162/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.gif
Type: image/gif
Size: 6359 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20170813/5a8e3162/attachment.gif>

From Roger.Bivand at nhh.no  Sun Aug 13 12:44:47 2017
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 13 Aug 2017 12:44:47 +0200
Subject: [R-sig-Geo] How to test spatial dependence in errorsarlm
In-Reply-To: <000001d313d4$7492d250$5db876f0$@ehu.eus>
References: <000001d313d4$7492d250$5db876f0$@ehu.eus>
Message-ID: <alpine.LFD.2.20.1708131239230.31539@reclus.nhh.no>

On Sun, 13 Aug 2017, Javier Garc?a wrote:

> Hello everybody:
>
>
>
> I have estimated a spatial error model and now I would like to test whether
> that model has really ?deleted? the spatial dependence. For the spatial lag
> model and for the Durbin model the function lagsarlm gives the LM test for
> residual autocorrelation test value, but the function errorsarlm does not.
> Does anyone know how to do it in R?
>

As you should be aware from the literature, the only LM test that has been 
written (the maths) is a test for residual error autocorrelation for 
spatial lag models. Doing it in R will not help until someone (you?) does 
the maths. Computing a value is easy, but knowing what to infer from it is 
hard. By definition, if your model is well-specified, the residual 
autocorrelation is fully captured by its coefficient. I suspect that your 
model suffers from mis-specification problems.

Roger

>
>
> Thanks a lot in advance.
>
>
>
> Javi
>
>
>
>
>
>
> JAVIER GARC?A
>
>
>
> Departamento de Econom?a Aplicada III (Econometr?a y Estad?stica)
>
> Facultad de Econom?a y Empresa (Secci?n Sarriko)
> Avda. Lehendakari Aguirre 83
>
> 48015 BILBAO
> T.: +34 601 7126 F.: +34 601 3754
> <http://www.ehu.es/> www.ehu.es
>
> http://www.unibertsitate-hedakuntza.ehu.es/p268-content/es/contenidos/inform
> acion/manual_id_corp/es_manual/images/firma_email_upv_euskampus_bilingue.gif
>
>
>
>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From Roger.Bivand at nhh.no  Sun Aug 13 12:49:13 2017
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 13 Aug 2017 12:49:13 +0200
Subject: [R-sig-Geo] Heteroscedasticity in Spatial Error Model
In-Reply-To: <000901d313d7$edf21cc0$c9d65640$@ehu.eus>
References: <000901d313d7$edf21cc0$c9d65640$@ehu.eus>
Message-ID: <alpine.LFD.2.20.1708131245080.31539@reclus.nhh.no>

On Sun, 13 Aug 2017, Javier Garc?a wrote:

> Hello again:
>
>
>
> Please, could anyone tell me how to estimate robust standard errors for a
> spatial error model? The residuals of my model show heteroscedasticity
> evidence, but the functions I have looked at only work with lm type objects.
>

The documented approaches use GM rather than ML for fitting - see the 
sphet package and https://www.jstatsoft.org/index.php/jss/issue/view/v063. 
You should really try to remove the sources of model mis-specification 
instead of spreading coefficient standard errors by guesswork. The may 
stem from MAUP, missing covariates and/or wrong functional forms.

Roger

>
>
> Thanks a lot in advance.
>
>
>
> Javi
>
>
>
>
>
>
> JAVIER GARC?A
>
>
>
> Departamento de Econom?a Aplicada III (Econometr?a y Estad?stica)
>
> Facultad de Econom?a y Empresa (Secci?n Sarriko)
> Avda. Lehendakari Aguirre 83
>
> 48015 BILBAO
> T.: +34 601 7126 F.: +34 601 3754
> <http://www.ehu.es/> www.ehu.es
>
> http://www.unibertsitate-hedakuntza.ehu.es/p268-content/es/contenidos/inform
> acion/manual_id_corp/es_manual/images/firma_email_upv_euskampus_bilingue.gif
>
>
>
>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From javier.garcia at ehu.eus  Mon Aug 14 04:18:29 2017
From: javier.garcia at ehu.eus (=?iso-8859-1?Q?Javier_Garc=EDa?=)
Date: Mon, 14 Aug 2017 04:18:29 +0200
Subject: [R-sig-Geo] How to test spatial dependence in errorsarlm
In-Reply-To: <alpine.LFD.2.20.1708131239230.31539@reclus.nhh.no>
References: <000001d313d4$7492d250$5db876f0$@ehu.eus>
 <alpine.LFD.2.20.1708131239230.31539@reclus.nhh.no>
Message-ID: <000901d314a3$9f1080c0$dd318240$@ehu.eus>

So testing for spatial dependence on the residuals by means of the
lm.LMtests (option LMerr, the only that works with residuals) is wrong,
isn't it? I had read in some forum that this was a posible way to test it...

In my case the Moran test and the LM tests (both LMerr and LMlag, and also
their robust versions) are strongly rejected (p-values between 4.307e-06
and 2.2e-16). As the rejection is stronger for the spatial error model, my
suspicion was that this could be the best model to capture the spatial
dependence (in fact the log-likelihood is bigger for the spatial error
model, and the AIC lower). However, how can I know whether the spatial error
model is a good option if I cannot test the absence of spatial dependence in
the residuals? And how can I know, as you suspect, whether I have a
misspecification problem? Moreover, I also estimated the Durbin model, and
in this case the LM test on the residuals suggests no spatial dependence
(for the spatial lag model I get the opposite conclusion), but due to the
nature of my regression I don't think that this model is suitable (the
regressors are characteristics of houses such as size, number of rooms,
etc).

Thanks a lot for your time.
Best
Javi     

-----Mensaje original-----
De: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Enviado el: domingo, 13 de agosto de 2017 12:45
Para: Javier Garc?a
CC: r-sig-geo at r-project.org
Asunto: Re: [R-sig-Geo] How to test spatial dependence in errorsarlm

On Sun, 13 Aug 2017, Javier Garc?a wrote:

> Hello everybody:
>
>
>
> I have estimated a spatial error model and now I would like to test 
> whether that model has really ?deleted? the spatial dependence. For 
> the spatial lag model and for the Durbin model the function lagsarlm 
> gives the LM test for residual autocorrelation test value, but the
function errorsarlm does not.
> Does anyone know how to do it in R?
>

As you should be aware from the literature, the only LM test that has been
written (the maths) is a test for residual error autocorrelation for spatial
lag models. Doing it in R will not help until someone (you?) does the maths.
Computing a value is easy, but knowing what to infer from it is hard. By
definition, if your model is well-specified, the residual autocorrelation is
fully captured by its coefficient. I suspect that your model suffers from
mis-specification problems.

Roger

>
>
> Thanks a lot in advance.
>
>
>
> Javi
>
>
>
>
>
>
> JAVIER GARC?A
>
>
>
> Departamento de Econom?a Aplicada III (Econometr?a y Estad?stica)
>
> Facultad de Econom?a y Empresa (Secci?n Sarriko)
> Avda. Lehendakari Aguirre 83
>
> 48015 BILBAO
> T.: +34 601 7126 F.: +34 601 3754
> <http://www.ehu.es/> www.ehu.es
>
>
http://www.unibertsitate-hedakuntza.ehu.es/p268-content/es/contenidos/inform
>
acion/manual_id_corp/es_manual/images/firma_email_upv_euskampus_bilingue.gif
>
>
>
>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From Roger.Bivand at nhh.no  Mon Aug 14 09:43:05 2017
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 14 Aug 2017 09:43:05 +0200
Subject: [R-sig-Geo] How to test spatial dependence in errorsarlm
In-Reply-To: <000901d314a3$9f1080c0$dd318240$@ehu.eus>
References: <000001d313d4$7492d250$5db876f0$@ehu.eus>
 <alpine.LFD.2.20.1708131239230.31539@reclus.nhh.no>
 <000901d314a3$9f1080c0$dd318240$@ehu.eus>
Message-ID: <alpine.LFD.2.20.1708140927590.3454@reclus.nhh.no>

On Mon, 14 Aug 2017, Javier Garc?a wrote:

> So testing for spatial dependence on the residuals by means of the
> lm.LMtests (option LMerr, the only that works with residuals) is wrong,
> isn't it? I had read in some forum that this was a posible way to test it...

There was some speculation that these tests might be used on an lm fit of 
the (I - \lambda W) y ~ (I - \lambda W) X model. These speculations have 
never been checked rigorously, so nobody knows whether they are of any 
value, probably not, and certainly we know nothing of their inferential 
basis.

>
> In my case the Moran test and the LM tests (both LMerr and LMlag, and 
> also their robust versions) are strongly rejected (p-values between 
> 4.307e-06 and 2.2e-16). As the rejection is stronger for the spatial 
> error model, my suspicion was that this could be the best model to 
> capture the spatial dependence (in fact the log-likelihood is bigger for 
> the spatial error model, and the AIC lower). However, how can I know 
> whether the spatial error model is a good option if I cannot test the 
> absence of spatial dependence in the residuals?

You by definition fix X and W as known, exogeneous, quantities. If X (and 
functional forms) and/or W do not meet these requirements, there is little 
good guidance. It depends on what you want: predict house prices where 
they are not observed; estimate \beta values; estimate the impact of a 
unit change in an X variable on house prices (y); whatever. A best-fit 
model suggests that you want to predict, but isn't necessary for impacts 
or betas if you trust X (and its functional forms) and W.

> And how can I know, as you suspect, whether I have a
> misspecification problem?

See a good deal of work by Daniel McMillen on these issues.

> Moreover, I also estimated the Durbin model, and in this case the LM 
> test on the residuals suggests no spatial dependence (for the spatial 
> lag model I get the opposite conclusion), but due to the nature of my 
> regression I don't think that this model is suitable (the regressors are 
> characteristics of houses such as size, number of rooms, etc).

This suggests that SLX or SDEM (see LeSage 2014 and SLX articles for a 
discussion) may address many of the issues of spatial autocorrelation by 
including (selected) WX. The Durbin versions of spdep functions do not 
(yet) let you choose which WX to include, always including all X - this is 
on my medium-term to-do list.

Roger

>
> Thanks a lot for your time.
> Best
> Javi
>
> -----Mensaje original-----
> De: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Enviado el: domingo, 13 de agosto de 2017 12:45
> Para: Javier Garc?a
> CC: r-sig-geo at r-project.org
> Asunto: Re: [R-sig-Geo] How to test spatial dependence in errorsarlm
>
> On Sun, 13 Aug 2017, Javier Garc?a wrote:
>
>> Hello everybody:
>>
>>
>>
>> I have estimated a spatial error model and now I would like to test
>> whether that model has really ?deleted? the spatial dependence. For
>> the spatial lag model and for the Durbin model the function lagsarlm
>> gives the LM test for residual autocorrelation test value, but the
> function errorsarlm does not.
>> Does anyone know how to do it in R?
>>
>
> As you should be aware from the literature, the only LM test that has been
> written (the maths) is a test for residual error autocorrelation for spatial
> lag models. Doing it in R will not help until someone (you?) does the maths.
> Computing a value is easy, but knowing what to infer from it is hard. By
> definition, if your model is well-specified, the residual autocorrelation is
> fully captured by its coefficient. I suspect that your model suffers from
> mis-specification problems.
>
> Roger
>
>>
>>
>> Thanks a lot in advance.
>>
>>
>>
>> Javi
>>
>>
>>
>>
>>
>>
>> JAVIER GARC?A
>>
>>
>>
>> Departamento de Econom?a Aplicada III (Econometr?a y Estad?stica)
>>
>> Facultad de Econom?a y Empresa (Secci?n Sarriko)
>> Avda. Lehendakari Aguirre 83
>>
>> 48015 BILBAO
>> T.: +34 601 7126 F.: +34 601 3754
>> <http://www.ehu.es/> www.ehu.es
>>
>>
> http://www.unibertsitate-hedakuntza.ehu.es/p268-content/es/contenidos/inform
>>
> acion/manual_id_corp/es_manual/images/firma_email_upv_euskampus_bilingue.gif
>>
>>
>>
>>
>>
>>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From himalayanhari at gmail.com  Mon Aug 14 20:07:42 2017
From: himalayanhari at gmail.com (Hari Sharma)
Date: Tue, 15 Aug 2017 02:07:42 +0800
Subject: [R-sig-Geo] layer to change nodata values
Message-ID: <037CD80C-F7EF-4F9B-87AC-E43A31048530@gmail.com>

Hi all,
> I downloaded global water surface layer from Pekel et al., 2016. The data (band values) has 0 to 255. 0 = 0 water, 1 = 1%, 2= 2%?.100=100% water and after then 255 (which is no data according to paper). I want to keep this values from 0 to 100 only in the raster and want to change values 255 into nodata. How can I make r code? I have following code but I am not sure it is good not?

a <- raster(?waterlayer.tif)
max <- 100
a[a >= max] <- NA

Hari Sharma
Taiwan




	[[alternative HTML version deleted]]


From momeni.iman at gmail.com  Tue Aug 15 15:07:08 2017
From: momeni.iman at gmail.com (Iman Momeni)
Date: Tue, 15 Aug 2017 15:07:08 +0200
Subject: [R-sig-Geo] Correlation between a nominal and a continious rasters
Message-ID: <CAMpq0sfHER9zB1dExUsToANHd9ttAfMbZDTWmufVyHOtLoRtKg@mail.gmail.com>

?

Hi all

I need to find how much two *raster* variables are correlated. One of these
variables is categorical (*nominal* such as land-cover) and the other one
is *continuous*.

I also need to do the same analysis for a *Binary raster layer* (0,1)
and a *continuous
raster layer*.  Could you please give me some bits of advice about the best
methods in this regard in R?

Excuse me if you find my question so elementary because I?m new in R.



Best regards

Iman

	[[alternative HTML version deleted]]


From fukutugu at yahoo.co.jp  Thu Aug 17 13:32:35 2017
From: fukutugu at yahoo.co.jp (=?UTF-8?B?5bCP5bed56aP5Zej?=)
Date: Thu, 17 Aug 2017 20:32:35 +0900
Subject: [R-sig-Geo] How can I read a path containing multibyte characters
 using the read_sf () function?
Message-ID: <CAJ0_Ro02awgJ+=UnK+aVQvOaV7yDc15Ur9F3T47cV_yh2JdhZQ@mail.gmail.com>

Dears,

How can I read data containing multibyte characters in windows
using the read_sf () function?

library(sf)
nc <- st_read(system.file("shape/nc.shp", package="sf"))
write_sf(nc, dsn=enc2utf8("???"), layer="test", driver="ESRI Shapefile")
dsn = enc2utf8("???/test.shp")
read_sf(dsn)

ERROR:
Cannot open data source C:\Users*****\nc\???
Error in CPL_read_ogr(dsn, layer, as.character(options), quiet, type, :
Open failed.

best,
Ogawa


From istazahn at gmail.com  Thu Aug 17 22:10:56 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 17 Aug 2017 16:10:56 -0400
Subject: [R-sig-Geo] How can I read a path containing multibyte
 characters using the read_sf () function?
In-Reply-To: <CAJ0_Ro02awgJ+=UnK+aVQvOaV7yDc15Ur9F3T47cV_yh2JdhZQ@mail.gmail.com>
References: <CAJ0_Ro02awgJ+=UnK+aVQvOaV7yDc15Ur9F3T47cV_yh2JdhZQ@mail.gmail.com>
Message-ID: <CA+vqiLFr-DUgtHR0kvnydkm==iQrgekN-EeK65=-C=WCVQYPuA@mail.gmail.com>

Hi Ogawa,

I can reproduce the error on Windows, though the error message isn't
very useful. The useful part is the part that comes after that, the
part you didn't include in your question:

In addition: Warning message:
In normalizePath(path.expand(path), winslash, mustWork) :
  path[1]="<U+30C7><U+30FC><U+30BF>/test.shp": The filename, directory
name, or volume label syntax is incorrect

Taking the extrodanary step of googling for the problem I find a bug
report as the first result in
https://www.google.com/search?q=R+normalizePath(path.expand(path)%2C+winslash%2C+mustWork)+utf-8+windows

The upshot from that bug report is that you can either
a) stop using windows (it works on Mac and Linux),
b) use the development version of R where this issue is now fixed on
Windows, or
c) wait for R 3.5 to be released.

With tongue only partially in cheek I suggest that a) is your best option.

Best,
Ista

On Thu, Aug 17, 2017 at 7:32 AM, ???? <fukutugu at yahoo.co.jp> wrote:
> Dears,
>
> How can I read data containing multibyte characters in windows
> using the read_sf () function?
>
> library(sf)
> nc <- st_read(system.file("shape/nc.shp", package="sf"))
> write_sf(nc, dsn=enc2utf8("???"), layer="test", driver="ESRI Shapefile")
> dsn = enc2utf8("???/test.shp")
> read_sf(dsn)
>
> ERROR:
> Cannot open data source C:\Users*****\nc\???
> Error in CPL_read_ogr(dsn, layer, as.character(options), quiet, type, :
> Open failed.
>
> best,
> Ogawa
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From asrovai at gmail.com  Fri Aug 18 22:34:36 2017
From: asrovai at gmail.com (Andre Rovai)
Date: Fri, 18 Aug 2017 15:34:36 -0500
Subject: [R-sig-Geo] How to extract values from adjacent raster cells that
 are not touched by SpatialLines?
Message-ID: <CABj7FA2K3010F3tE+MEBWCKmH5Cc2txi103_aA0KXeJbaGe_UA@mail.gmail.com>

r-sig-geo at r-project.org

Hi all,

I've been trying to extract values from a single attribute raster (area, in
m2) that overlaps with different lines (that is, a .shp SpatialLines).

I am using the extract() function but it only extracts values from
cells that are touched (that is, crossed) by the lines.  The problem is
that my raster has adjacent cells both right and left of the cell that
is actually touched by the lines.  Thus, when I add up the extracted values
a significant amount of area (m2) is lost due to cells that were not
touched by the line and therefore values were not extracted.

I tried to work it around by:

Step 1 - first aggregating my raster to a lower resolution (i.e. increasing
the fact argument) and then
Step 2 - rasterizing the lines using this aggregated raster (created in
step 1) as a mold to make sure the rasterized lines would get thick enough
to cover the horizontal spread of cells in my original resolution raster.
Step 3 - Then I resample the rasterized lines (created in step 2) back to
the original resolution I started with.
Step 4 - Finally, extracted the values from the resampled rasterized lines
(created in step 3).

However, it didn't quite work as now the total area (m2) varies according
to the fact="" value I use when first aggregating the raster (in step 1).

I also tried using crop() and mask() but had no success as well.

I really appreciate if anyone has already dealt with a similar problem and
can help me out here.  Here are the codes I've been running to try to get
it to work:


# input raster file

g.025 <- raster("ras.asc")

g.1 <- aggregate(g.025, fact=2, fun=sum)



# input SpatialLines

Spline1 <- readOGR("/Users/xxxxx.shp")

Spline2 <- readOGR("/Users/xxxxx.shp")

Spline3 <- readOGR("/Users/xxxxx.shp")



# rasterizing using low resolution raster (aggregated)

c1 <- rasterize(Spline1, g.1, field=Spline1$type, fun=sum)

c2 <- rasterize(Spline2, g.1, field=Spline2$type, fun=sum)

c3 <- rasterize(Spline3, g.1, field=Spline3$type, fun=sum)



# resampling back to higher resolution

c1 <- resample(c1, g.025)

c2 <- resample(c2, g.025)

c3 <- resample(c3, g.025)



# preparing to extract area (m2) values from raster ?g.025?

c1tab <- as.data.frame(c1, xy=T)

c2tab <- as.data.frame(c2, xy=T)

c3tab <- as.data.frame(c3, xy=T)

c1tab <- c1tab[which(is.na(c1tab$layer)!=T),]

c2tab <- c2tab[which(is.na(c2tab$layer)!=T),]

c3tab <- c3tab[which(is.na(c3tab$layer)!=T),]



# extracting area (m2) values from raster ?g.025?

c1tab[,4] <- extract(g.025, c1tab[,1:2])

c2tab[,4] <- extract(g.025, c2tab[,1:2])

c3tab[,4] <- extract(g.025, c3tab[,1:2])

names(c1tab)[4] <- "area_m2"

names(c2tab)[4] <- "area_m2"

names(c3tab)[4] <- "area_m2"



# sum total area (m2)

c1_area <- sum(c1tab$area_m2)

c2_area <- sum(c2tab$area_m2)

c3_area <- sum(c3tab$area_m2)

tot_area <- sum(c1_area, c2_area, c3_area)


Thanks!

Andre Rovai
Department of Oceanography and Coastal Sciences
Louisiana State University

	[[alternative HTML version deleted]]


From santiago.snchez at gmail.com  Sat Aug 19 20:52:13 2017
From: santiago.snchez at gmail.com (=?UTF-8?Q?Santiago_S=C3=A1nchez?=)
Date: Sat, 19 Aug 2017 18:52:13 +0000
Subject: [R-sig-Geo] How to extract values from adjacent raster cells
 that are not touched by SpatialLines?
Message-ID: <CAH5Y-yO86NExVa7-GBxOkXW6DNWtF8dwXUX+X1kskCsLvuHfew@mail.gmail.com>

Hi Andre,

I'm not completely sure if this is what you are looking for, but here is a
worked example on how to get cell indices (thus, data) from neighbouring
cells. Essentially, I'm using the adjancency() function from raster,
reducing to unrepeated cells, and excluding the ones that fall under a line
object.

library(raster)
r <- raster(ncol=10,nrow=10) # generate a raster object
r[] <- 0 # populate values with 0's
p <- rasterToPolygons(r) # get a polygon for each cell (for visual purposes)

# make a line object (SpatialLines)
x <- c(-124.66110, -93.04031, -52.37858, 24.44486, 15.98469, 52.12075,
88.49592)
y <- c(-46.021148, -27.197684, -6.804443, 10.113111, 28.375197, 8.851744,
-12.463264)
xy <- data.frame(cbind(x,y))
spl <- SpatialLines(list(Lines(list(Line(xy)), ID=1)))

# get adjacent cells
lcells <- cellFromLine(r, spl)[[1]] # cells from line
r[lcells] <- 1 # mark line cells with 1
ad <- adjacent(r, lcells, 4) # this gives you a matrix with adjacent cells,
                                          # you can specify 8 or 16
neighbouring cells,
                                          # here I'm using 4
# sorting and removing duplicates
ad <- sort(as.vector(ad))
ad <- ad[!duplicated(ad)]
ad2 <- ad[ ! ad %in% lcells ]
r[ad2] <- 2

# to visualize the example:
plot(r)
plot(p, add=T)
plot(spl, add=T, col="red")

# Obviously, you con extract the values of adjacent cells simply with:
r[ad2]
[1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2


Hope this helps,
Santiago

-- 
==========================
Santiago Sanchez-Ramirez, PhD
Postdoctoral Associate
Ecology and Evolutionary Biology
University of Toronto
==========================

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Tue Aug 22 11:40:00 2017
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 22 Aug 2017 11:40:00 +0200
Subject: [R-sig-Geo] useR! spatial presentations
Message-ID: <alpine.LFD.2.20.1708221138550.19560@reclus.nhh.no>

A useful listing of video links fro useR! in Brussels on spatial topics:

https://gist.github.com/anonymous/3d5b56cb16526db96dcaa0a579980187

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From btupper at bigelow.org  Tue Aug 22 14:39:07 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Tue, 22 Aug 2017 08:39:07 -0400
Subject: [R-sig-Geo] useR! spatial presentations
In-Reply-To: <alpine.LFD.2.20.1708221138550.19560@reclus.nhh.no>
References: <alpine.LFD.2.20.1708221138550.19560@reclus.nhh.no>
Message-ID: <5746884A-1F40-477B-9688-F83BD0DDD0A9@bigelow.org>

A gold mine!  Thanks for sharing these.


> On Aug 22, 2017, at 5:40 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> 
> A useful listing of video links fro useR! in Brussels on spatial topics:
> 
> https://gist.github.com/anonymous/3d5b56cb16526db96dcaa0a579980187
> 
> -- 
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
> Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecocast Reports: http://seascapemodeling.org/ecocast.html
Tick Reports: https://report.bigelow.org/tick/
Jellyfish Reports: https://jellyfish.bigelow.org/jellyfish/


From Roger.Bivand at nhh.no  Tue Aug 22 15:05:44 2017
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 22 Aug 2017 15:05:44 +0200
Subject: [R-sig-Geo] useR! spatial presentations
In-Reply-To: <5746884A-1F40-477B-9688-F83BD0DDD0A9@bigelow.org>
References: <alpine.LFD.2.20.1708221138550.19560@reclus.nhh.no>
 <5746884A-1F40-477B-9688-F83BD0DDD0A9@bigelow.org>
Message-ID: <alpine.LFD.2.20.1708221459030.24030@reclus.nhh.no>

Edzer spotted:

https://twitter.com/Geospex/status/899670406944231424

and I copied the link here - thanks to Geospex/anonymous ...

On Tue, 22 Aug 2017, Ben Tupper wrote:

> A gold mine!  Thanks for sharing these.
>
>
>> On Aug 22, 2017, at 5:40 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>
>> A useful listing of video links fro useR! in Brussels on spatial topics:
>>
>> https://gist.github.com/anonymous/3d5b56cb16526db96dcaa0a579980187
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>> Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
>> http://orcid.org/0000-0003-2392-6140
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> Ecocast Reports: http://seascapemodeling.org/ecocast.html
> Tick Reports: https://report.bigelow.org/tick/
> Jellyfish Reports: https://jellyfish.bigelow.org/jellyfish/
>
>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From btupper at bigelow.org  Tue Aug 22 15:18:12 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Tue, 22 Aug 2017 09:18:12 -0400
Subject: [R-sig-Geo] useR! spatial presentations
In-Reply-To: <alpine.LFD.2.20.1708221459030.24030@reclus.nhh.no>
References: <alpine.LFD.2.20.1708221138550.19560@reclus.nhh.no>
 <5746884A-1F40-477B-9688-F83BD0DDD0A9@bigelow.org>
 <alpine.LFD.2.20.1708221459030.24030@reclus.nhh.no>
Message-ID: <196017F8-60F2-4122-B747-E787AE413C91@bigelow.org>

Mike Treglia's comment, "Spatial stuff in #rstats is moving so fast! tough to keep up... but a good problem I guess" is spot on. I feel like I need to wear a bicycle helmet, elbow and knee pads, a seat belt and maybe a few pillows strapped on every time I sit down with the stuff.


> On Aug 22, 2017, at 9:05 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> 
> Edzer spotted:
> 
> https://twitter.com/Geospex/status/899670406944231424
> 
> and I copied the link here - thanks to Geospex/anonymous ...
> 
> On Tue, 22 Aug 2017, Ben Tupper wrote:
> 
>> A gold mine!  Thanks for sharing these.
>> 
>> 
>>> On Aug 22, 2017, at 5:40 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>> 
>>> A useful listing of video links fro useR! in Brussels on spatial topics:
>>> 
>>> https://gist.github.com/anonymous/3d5b56cb16526db96dcaa0a579980187
>>> 
>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics,
>>> Helleveien 30, N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>>> Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
>>> http://orcid.org/0000-0003-2392-6140
>>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>> 
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org
>> 
>> Ecocast Reports: http://seascapemodeling.org/ecocast.html
>> Tick Reports: https://report.bigelow.org/tick/
>> Jellyfish Reports: https://jellyfish.bigelow.org/jellyfish/
>> 
>> 
>> 
>> 
> 
> -- 
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
> Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecocast Reports: http://seascapemodeling.org/ecocast.html
Tick Reports: https://report.bigelow.org/tick/
Jellyfish Reports: https://jellyfish.bigelow.org/jellyfish/


From bedilue at gmail.com  Thu Aug 24 06:33:30 2017
From: bedilue at gmail.com (Bedilu Ejigu)
Date: Thu, 24 Aug 2017 07:33:30 +0300
Subject: [R-sig-Geo] spGLM
Message-ID: <CAOm+BKew3iSos3z6DWy4EJGPqNuxOQ9H2-ham66x9-ws7emdfA@mail.gmail.com>

 When I run a spatial model in R using spGLM function from spBayes package,
the following error message popup.

Error in spGLM(ane ~ 1, family = "binomial", data = FemaleAug, coords
= coord,  :
  error: either the coords have more than two columns or then number
of rows is different than
          data used in the model formula


But, the number of  columns in for coords are two, and the number of
rows also similar  with the dataset used in the model

> dim(coord)[1] 15233     2> dim(FemaleAug)[1] 15233    11

*_______________________________________________*



<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From finleya at msu.edu  Thu Aug 24 15:54:06 2017
From: finleya at msu.edu (Andrew Finley)
Date: Thu, 24 Aug 2017 09:54:06 -0400
Subject: [R-sig-Geo] spGLM
In-Reply-To: <CAOm+BKew3iSos3z6DWy4EJGPqNuxOQ9H2-ham66x9-ws7emdfA@mail.gmail.com>
References: <CAOm+BKew3iSos3z6DWy4EJGPqNuxOQ9H2-ham66x9-ws7emdfA@mail.gmail.com>
Message-ID: <23fe8573-154d-69d3-b699-0d51e113c5bb@msu.edu>

Hi Bedilu,

Thanks for the post. Given your description, you should not be getting 
that error. Would you mind emailing me directly an example with data 
that reproduces the error?

Thanks-
Andy

On 08/24/2017 12:33 AM, Bedilu Ejigu wrote:
>   When I run a spatial model in R using spGLM function from spBayes package,
> the following error message popup.
> 
> Error in spGLM(ane ~ 1, family = "binomial", data = FemaleAug, coords
> = coord,  :
>    error: either the coords have more than two columns or then number
> of rows is different than
>            data used in the model formula
> 
> 
> But, the number of  columns in for coords are two, and the number of
> rows also similar  with the dataset used in the model
> 
>> dim(coord)[1] 15233     2> dim(FemaleAug)[1] 15233    11
> 
> *_______________________________________________*
> 
> 
> 
> <https://urldefense.proofpoint.com/v2/url?u=https-3A__www.avast.com_sig-2Demail-3Futm-5Fmedium-3Demail-26utm-5Fsource-3Dlink-26utm-5Fcampaign-3Dsig-2Demail-26utm-5Fcontent-3Dwebmail-26utm-5Fterm-3Dicon&d=DwICAg&c=nE__W8dFE-shTxStwXtp0A&r=vOgWsEpXC-0Xwo-gVRww3A&m=PJ3MQSOol3LkkKQUUYhaakIn9sHbYI1BvcPIdqRqgdI&s=TkyWuUAovom0L7MuZNEJ-3vBzLo0zHdYA04P_XwGR5I&e= >
> Virus-free.
> www.avast.com
> <https://urldefense.proofpoint.com/v2/url?u=https-3A__www.avast.com_sig-2Demail-3Futm-5Fmedium-3Demail-26utm-5Fsource-3Dlink-26utm-5Fcampaign-3Dsig-2Demail-26utm-5Fcontent-3Dwebmail-26utm-5Fterm-3Dlink&d=DwICAg&c=nE__W8dFE-shTxStwXtp0A&r=vOgWsEpXC-0Xwo-gVRww3A&m=PJ3MQSOol3LkkKQUUYhaakIn9sHbYI1BvcPIdqRqgdI&s=BfdbRCOLnk-n-yL_fJCSiI0Ek0jyFindH4HfroFg_BE&e= >
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dsig-2Dgeo&d=DwICAg&c=nE__W8dFE-shTxStwXtp0A&r=vOgWsEpXC-0Xwo-gVRww3A&m=PJ3MQSOol3LkkKQUUYhaakIn9sHbYI1BvcPIdqRqgdI&s=99t4yTictDFtDmoddyYrTfGsS4HVtiR38GYMKohfFxM&e=
> 

-- 
Andrew Finley, PhD
Natural Resources Building
Michigan State University
East Lansing, MI 48824-1222
Phone: 517-898-5970
Skype: finle014
Fax: 517-432-1143
Web: http://blue.for.msu.edu


From manuel.schneider at agroscope.admin.ch  Thu Aug 24 17:00:22 2017
From: manuel.schneider at agroscope.admin.ch (manuel.schneider at agroscope.admin.ch)
Date: Thu, 24 Aug 2017 15:00:22 +0000
Subject: [R-sig-Geo] Slow writing of point features to SpatialLite-DB or
	Geopackage
Message-ID: <EEFB79841DF60B4FB2B1C68614C88518030948A7@sb00106a.adb.intra.admin.ch>

Dear list

I am searching alternatives to ESRI shapefiles for the storage of GPS data, i.e. tagged point features, and came across SpatialLite or Geopackage. Unfortunately writing to both formats is very slow compared to shapefiles making practical use impossible.

library(sf)
library(rgdal)
library(RSQLite)

n<- 1000
d <-data.frame(a=1:n, X=rnorm(n,1,1), Y=rnorm(n,1,1))
mp1 <- st_as_sf(d, coords=c("X","Y"))

t1 <- system.time(st_write(mp1, dsn = 'C:/Temp/data1.shp', driver = 'ESRI Shapefile'))
t2 <- system.time(st_write(mp1, dsn = 'C:/Temp/test.sqlite', layer = 'data1', driver = 'SQLite'))
t3 <- system.time(st_write(mp1, "C:/Temp/data1.gpkg"))

rbind(t1,t2,t3)[,1:3]

   user.self sys.self elapsed
t1      0.03     0.03    0.09
t2      0.53     5.04   29.33
t3      0.48     4.29   32.19

As n increases, processing time explodes for SpatialLite and Geopackage, and I usually have a couple of 10000 points to store. Any experiences of others would be highly appreciated.
Many thanks
Manuel


------
R version 3.4.1 (2017-06-30)
Platform: i386-w64-mingw32/i386 (32-bit)
Running under: Windows 7 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=German_Switzerland.1252  LC_CTYPE=German_Switzerland.1252   
[3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C                       
[5] LC_TIME=German_Switzerland.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] sf_0.5-3    RSQLite_2.0 rgdal_1.2-8 sp_1.2-5   

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.12    lattice_0.20-35 digest_0.6.12   grid_3.4.1      DBI_0.7        
 [6] magrittr_1.5    units_0.4-5     rlang_0.1.2     blob_1.1.0      tools_3.4.1    
[11] udunits2_0.13   bit64_0.9-7     bit_1.1-12      compiler_3.4.1  memoise_1.1.0  
[16] tibble_1.3.4  


From Roger.Bivand at nhh.no  Thu Aug 24 17:23:23 2017
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 24 Aug 2017 17:23:23 +0200
Subject: [R-sig-Geo] Slow writing of point features to SpatialLite-DB or
 Geopackage
In-Reply-To: <EEFB79841DF60B4FB2B1C68614C88518030948A7@sb00106a.adb.intra.admin.ch>
References: <EEFB79841DF60B4FB2B1C68614C88518030948A7@sb00106a.adb.intra.admin.ch>
Message-ID: <alpine.LFD.2.20.1708241715320.11794@reclus.nhh.no>

On Thu, 24 Aug 2017, manuel.schneider at agroscope.admin.ch wrote:

> Dear list
>
> I am searching alternatives to ESRI shapefiles for the storage of GPS data, i.e. tagged point features, and came across SpatialLite or Geopackage. Unfortunately writing to both formats is very slow compared to shapefiles making practical use impossible.
>
> library(sf)
> library(rgdal)
> library(RSQLite)
>
> n<- 1000
> d <-data.frame(a=1:n, X=rnorm(n,1,1), Y=rnorm(n,1,1))
> mp1 <- st_as_sf(d, coords=c("X","Y"))
>
> t1 <- system.time(st_write(mp1, dsn = 'C:/Temp/data1.shp', driver = 'ESRI Shapefile'))
> t2 <- system.time(st_write(mp1, dsn = 'C:/Temp/test.sqlite', layer = 'data1', driver = 'SQLite'))
> t3 <- system.time(st_write(mp1, "C:/Temp/data1.gpkg"))
>
> rbind(t1,t2,t3)[,1:3]
>
>   user.self sys.self elapsed
> t1      0.03     0.03    0.09
> t2      0.53     5.04   29.33
> t3      0.48     4.29   32.19
>
> As n increases, processing time explodes for SpatialLite and Geopackage, 
> and I usually have a couple of 10000 points to store. Any experiences of 
> others would be highly appreciated.

Fedora 26 64-bit:

n 1000

> rbind(t1,t2,t3)[,1:3]
    user.self sys.self elapsed
t1     0.007    0.001   0.010
t2     0.067    0.035   0.103
t3     0.029    0.042   0.073

n 25000

> rbind(t1,t2,t3)[,1:3]
    user.self sys.self elapsed
t1     0.120    0.032   0.153
t2     0.412    0.829   1.247
t3     0.645    0.834   1.487

R version 3.4.1 (2017-06-30)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Fedora 26 (Workstation Edition)
other attached packages:
[1] sf_0.5-3

loaded via a namespace (and not attached):
[1] compiler_3.4.1 magrittr_1.5   tools_3.4.1    DBI_0.7
   units_0.4-5
[6] Rcpp_0.12.12   udunits2_0.13  grid_3.4.1

There is no need to load rgdal or RSQLite, neither are needed or used. For 
portability use tempdir():

t1 <- system.time(st_write(mp1, dsn = paste0(td, 'data1.shp')))
t2 <- system.time(st_write(mp1, dsn = paste0(td, 'test.sqlite'), layer = 
'data1', driver = 'SQLite'))
t3 <- system.time(st_write(mp1, paste0(td, 'data1.gpkg')))

Maybe an order of magnitude difference because the databases need 
initialising, but nothing like your scale; does 32/64 bit make a 
difference?

I'm assuming that you installed sf as a Windows binary from CRAN?

Consider using a github issue when others have tried tis out on other 
platforms.

Roger

> Many thanks
> Manuel
>
>
> ------
> R version 3.4.1 (2017-06-30)
> Platform: i386-w64-mingw32/i386 (32-bit)
> Running under: Windows 7 (build 7601) Service Pack 1
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=German_Switzerland.1252  LC_CTYPE=German_Switzerland.1252
> [3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Switzerland.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] sf_0.5-3    RSQLite_2.0 rgdal_1.2-8 sp_1.2-5
>
> loaded via a namespace (and not attached):
> [1] Rcpp_0.12.12    lattice_0.20-35 digest_0.6.12   grid_3.4.1      DBI_0.7
> [6] magrittr_1.5    units_0.4-5     rlang_0.1.2     blob_1.1.0      tools_3.4.1
> [11] udunits2_0.13   bit64_0.9-7     bit_1.1-12      compiler_3.4.1  memoise_1.1.0
> [16] tibble_1.3.4
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From loic.dutrieux at conabio.gob.mx  Thu Aug 24 23:44:59 2017
From: loic.dutrieux at conabio.gob.mx (=?UTF-8?Q?Lo=c3=afc_Dutrieux?=)
Date: Thu, 24 Aug 2017 16:44:59 -0500
Subject: [R-sig-Geo] Slow writing of point features to SpatialLite-DB or
 Geopackage
In-Reply-To: <alpine.LFD.2.20.1708241715320.11794@reclus.nhh.no>
References: <EEFB79841DF60B4FB2B1C68614C88518030948A7@sb00106a.adb.intra.admin.ch>
 <alpine.LFD.2.20.1708241715320.11794@reclus.nhh.no>
Message-ID: <4bb04a18-9948-4cc5-0e6e-e8b141e8c606@conabio.gob.mx>



On 24/08/17 10:23, Roger Bivand wrote:
> On Thu, 24 Aug 2017, manuel.schneider at agroscope.admin.ch wrote:
> 
>> Dear list
>>
>> I am searching alternatives to ESRI shapefiles for the storage of GPS 
>> data, i.e. tagged point features, and came across SpatialLite or 
>> Geopackage. Unfortunately writing to both formats is very slow 
>> compared to shapefiles making practical use impossible.
>>
>> library(sf)
>> library(rgdal)
>> library(RSQLite)
>>
>> n<- 1000
>> d <-data.frame(a=1:n, X=rnorm(n,1,1), Y=rnorm(n,1,1))
>> mp1 <- st_as_sf(d, coords=c("X","Y"))
>>
>> t1 <- system.time(st_write(mp1, dsn = 'C:/Temp/data1.shp', driver = 
>> 'ESRI Shapefile'))
>> t2 <- system.time(st_write(mp1, dsn = 'C:/Temp/test.sqlite', layer = 
>> 'data1', driver = 'SQLite'))
>> t3 <- system.time(st_write(mp1, "C:/Temp/data1.gpkg"))
>>
>> rbind(t1,t2,t3)[,1:3]
>>
>>   user.self sys.self elapsed
>> t1      0.03     0.03    0.09
>> t2      0.53     5.04   29.33
>> t3      0.48     4.29   32.19
>>
>> As n increases, processing time explodes for SpatialLite and 
>> Geopackage, and I usually have a couple of 10000 points to store. Any 
>> experiences of others would be highly appreciated.
> 
> Fedora 26 64-bit:
> 
> n 1000
> 
>> rbind(t1,t2,t3)[,1:3]
>     user.self sys.self elapsed
> t1     0.007    0.001   0.010
> t2     0.067    0.035   0.103
> t3     0.029    0.042   0.073
> 
> n 25000
> 
>> rbind(t1,t2,t3)[,1:3]
>     user.self sys.self elapsed
> t1     0.120    0.032   0.153
> t2     0.412    0.829   1.247
> t3     0.645    0.834   1.487
> 
> R version 3.4.1 (2017-06-30)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Fedora 26 (Workstation Edition)
> other attached packages:
> [1] sf_0.5-3
> 
> loaded via a namespace (and not attached):
> [1] compiler_3.4.1 magrittr_1.5   tools_3.4.1    DBI_0.7
>    units_0.4-5
> [6] Rcpp_0.12.12   udunits2_0.13  grid_3.4.1
> 

I also get large differences on ubuntu 16.04 64-bits with ssd; 
particularly when writing a second layer to an existing geopackage

library(sf)

n <- 1000
d <- data.frame(a=1:n, X=rnorm(n,1,1), Y=rnorm(n,1,1))
mp1 <- st_as_sf(d, coords=c("X","Y"))

td <- tempdir()
file.remove(list.files(td, full.names = TRUE))

t1 <- system.time(st_write(mp1, dsn = file.path(td, 'data1.shp'), driver 
= 'ESRI Shapefile'))
t2 <- system.time(st_write(mp1, dsn = file.path(td, 'data2.sqlite'), 
layer = 'layer1', driver = 'SQLite'))
t3 <- system.time(st_write(mp1, dsn = file.path(td, 'data2.sqlite'), 
layer = 'layer2', driver = 'SQLite'))
t4 <- system.time(st_write(mp1, dsn = file.path(td, 'data3.gpkg'), layer 
= 'layer1'))
t5 <- system.time(st_write(mp1, dsn = file.path(td, 'data3.gpkg'), layer 
= 'layer2'))

rbind(t1,t2,t3,t4,t5)[,1:3]

    user.self sys.self elapsed
t1     0.012    0.000   0.010
t2     0.180    0.456   8.993
t3     0.220    0.460  10.637
t4     0.016    0.064   0.082
t5     0.200    0.472   9.199

R version 3.4.0 (2017-04-21)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.2 LTS

other attached packages:
[1] sf_0.5-3     raster_2.5-8 sp_1.2-4

loaded via a namespace (and not attached):
  [1] compiler_3.4.0  magrittr_1.5    DBI_0.6-1       tools_3.4.0 
units_0.4-5     yaml_2.1.14     Rcpp_0.12.10    udunits2_0.13 
grid_3.4.0      lattice_0.20-35

Cheers,
Lo?c

> There is no need to load rgdal or RSQLite, neither are needed or used. 
> For portability use tempdir():
> 
> t1 <- system.time(st_write(mp1, dsn = paste0(td, 'data1.shp')))
> t2 <- system.time(st_write(mp1, dsn = paste0(td, 'test.sqlite'), layer = 
> 'data1', driver = 'SQLite'))
> t3 <- system.time(st_write(mp1, paste0(td, 'data1.gpkg')))
> 
> Maybe an order of magnitude difference because the databases need 
> initialising, but nothing like your scale; does 32/64 bit make a 
> difference?
> 
> I'm assuming that you installed sf as a Windows binary from CRAN?
> 
> Consider using a github issue when others have tried tis out on other 
> platforms.
> 
> Roger
> 
>> Many thanks
>> Manuel
>>
>>
>> ------
>> R version 3.4.1 (2017-06-30)
>> Platform: i386-w64-mingw32/i386 (32-bit)
>> Running under: Windows 7 (build 7601) Service Pack 1
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=German_Switzerland.1252  LC_CTYPE=German_Switzerland.1252
>> [3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
>> [5] LC_TIME=German_Switzerland.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] sf_0.5-3    RSQLite_2.0 rgdal_1.2-8 sp_1.2-5
>>
>> loaded via a namespace (and not attached):
>> [1] Rcpp_0.12.12    lattice_0.20-35 digest_0.6.12   grid_3.4.1      
>> DBI_0.7
>> [6] magrittr_1.5    units_0.4-5     rlang_0.1.2     blob_1.1.0      
>> tools_3.4.1
>> [11] udunits2_0.13   bit64_0.9-7     bit_1.1-12      compiler_3.4.1  
>> memoise_1.1.0
>> [16] tibble_1.3.4
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From vijaylulla at gmail.com  Fri Aug 25 01:57:23 2017
From: vijaylulla at gmail.com (Vijay Lulla)
Date: Thu, 24 Aug 2017 19:57:23 -0400
Subject: [R-sig-Geo] Slow writing of point features to SpatialLite-DB or
	Geopackage
In-Reply-To: <4bb04a18-9948-4cc5-0e6e-e8b141e8c606@conabio.gob.mx>
References: <EEFB79841DF60B4FB2B1C68614C88518030948A7@sb00106a.adb.intra.admin.ch>
 <alpine.LFD.2.20.1708241715320.11794@reclus.nhh.no>
 <4bb04a18-9948-4cc5-0e6e-e8b141e8c606@conabio.gob.mx>
Message-ID: <CAKkiGbs9ds8BbH5=wiVY5uatHzEUmt4Aid1BYeJGGTuLDYAQJw@mail.gmail.com>

According to http://gdal.org/drv_sqlite.html you can unset
OGR_SQLITE_SYNCHRONOUS and it should improve performance.  So, use

Sys.setenv(OGR_SQLITE_SYNCHRONOUS="OFF")

in your script/session before you wish to call writes.?  The SQLite and
GPKG writes are still 11x and 13x respectively slower than shapefile writes
but not terribly bad.  Below is what resulted in these numbers.  Output
from my .Rout file follows:

> library(sf)
Linking to GEOS 3.5.1, GDAL 2.2.0, proj.4 4.9.2
> library(rbenchmark)
>
> n <- 1000
> d <- data.frame(a=seq_len(n),x=rnorm(n,1,1),y=rnorm(n,1,1))
> mp1 <- st_as_sf(d,coords=c('x','y'))
>
> td <- tempdir()
> file.remove(list.files(td,full.names=TRUE))
logical(0)
> stwrite <- function(dat, dsn, ...) {
+   if (file.exists(dsn)) unlink(dsn)
+   st_write(dat,dsn=dsn, ...)
+ }
>
> Sys.setenv(OGR_SQLITE_SYNCHRONOUS="OFF")
>
> benchmark(
+   stwrite(mp1, dsn=file.path(td,'data1.shp'), driver='ESRI Shapefile'),
+   stwrite(mp1, dsn=file.path(td,'data2.sqlite'), layer="layer1",
driver='SQLite'),
+   stwrite(mp1, dsn=file.path(td,'data2.sqlite'), layer="layer2",
driver='SQLite'),
+   stwrite(mp1, dsn=file.path(td,'data3.gpkg'), layer="layer1"),
+   stwrite(mp1, dsn=file.path(td,'data3.gpkg'), layer="layer2"),
+   replications=5
+ )


test
1              stwrite(mp1, dsn = file.path(td, "data1.shp"), driver =
"ESRI Shapefile")
2 stwrite(mp1, dsn = file.path(td, "data2.sqlite"), layer = "layer1",
driver = "SQLite")
3 stwrite(mp1, dsn = file.path(td, "data2.sqlite"), layer = "layer2",
driver = "SQLite")
4                      stwrite(mp1, dsn = file.path(td, "data3.gpkg"),
layer = "layer1")
5                      stwrite(mp1, dsn = file.path(td, "data3.gpkg"),
layer = "layer2")
  replications elapsed relative user.self sys.self user.child sys.child
1            5   0.034    1.000     0.028    0.008          0         0
2            5   0.374   11.000     0.060    0.312          0         0
3            5   0.359   10.559     0.084    0.272          0         0
4            5   0.454   13.353     0.192    0.260          0         0
5            5   0.451   13.265     0.172    0.280          0         0
> sessionInfo()
R version 3.4.1 (2017-06-30)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.3 LTS

Matrix products: default
BLAS: /usr/lib/libblas/libblas.so.3.6.0
LAPACK: /usr/lib/lapack/liblapack.so.3.6.0

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] tools     stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] rbenchmark_1.0.0 sf_0.5-4

loaded via a namespace (and not attached):
[1] compiler_3.4.1 magrittr_1.5   DBI_0.7        units_0.4-5
Rcpp_0.12.12
[6] udunits2_0.13  grid_3.4.1
>
>
> proc.time()
   user  system elapsed
  1.436   1.340   2.791




On Thu, Aug 24, 2017 at 5:44 PM, Lo?c Dutrieux <loic.dutrieux at conabio.gob.mx
> wrote:

>
>
> On 24/08/17 10:23, Roger Bivand wrote:
>
>> On Thu, 24 Aug 2017, manuel.schneider at agroscope.admin.ch wrote:
>>
>> Dear list
>>>
>>> I am searching alternatives to ESRI shapefiles for the storage of GPS
>>> data, i.e. tagged point features, and came across SpatialLite or
>>> Geopackage. Unfortunately writing to both formats is very slow compared to
>>> shapefiles making practical use impossible.
>>>
>>> library(sf)
>>> library(rgdal)
>>> library(RSQLite)
>>>
>>> n<- 1000
>>> d <-data.frame(a=1:n, X=rnorm(n,1,1), Y=rnorm(n,1,1))
>>> mp1 <- st_as_sf(d, coords=c("X","Y"))
>>>
>>> t1 <- system.time(st_write(mp1, dsn = 'C:/Temp/data1.shp', driver =
>>> 'ESRI Shapefile'))
>>> t2 <- system.time(st_write(mp1, dsn = 'C:/Temp/test.sqlite', layer =
>>> 'data1', driver = 'SQLite'))
>>> t3 <- system.time(st_write(mp1, "C:/Temp/data1.gpkg"))
>>>
>>> rbind(t1,t2,t3)[,1:3]
>>>
>>>   user.self sys.self elapsed
>>> t1      0.03     0.03    0.09
>>> t2      0.53     5.04   29.33
>>> t3      0.48     4.29   32.19
>>>
>>> As n increases, processing time explodes for SpatialLite and Geopackage,
>>> and I usually have a couple of 10000 points to store. Any experiences of
>>> others would be highly appreciated.
>>>
>>
>> Fedora 26 64-bit:
>>
>> n 1000
>>
>> rbind(t1,t2,t3)[,1:3]
>>>
>>     user.self sys.self elapsed
>> t1     0.007    0.001   0.010
>> t2     0.067    0.035   0.103
>> t3     0.029    0.042   0.073
>>
>> n 25000
>>
>> rbind(t1,t2,t3)[,1:3]
>>>
>>     user.self sys.self elapsed
>> t1     0.120    0.032   0.153
>> t2     0.412    0.829   1.247
>> t3     0.645    0.834   1.487
>>
>> R version 3.4.1 (2017-06-30)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Fedora 26 (Workstation Edition)
>> other attached packages:
>> [1] sf_0.5-3
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.4.1 magrittr_1.5   tools_3.4.1    DBI_0.7
>>    units_0.4-5
>> [6] Rcpp_0.12.12   udunits2_0.13  grid_3.4.1
>>
>>
> I also get large differences on ubuntu 16.04 64-bits with ssd;
> particularly when writing a second layer to an existing geopackage
>
> library(sf)
>
> n <- 1000
> d <- data.frame(a=1:n, X=rnorm(n,1,1), Y=rnorm(n,1,1))
> mp1 <- st_as_sf(d, coords=c("X","Y"))
>
> td <- tempdir()
> file.remove(list.files(td, full.names = TRUE))
>
> t1 <- system.time(st_write(mp1, dsn = file.path(td, 'data1.shp'), driver =
> 'ESRI Shapefile'))
> t2 <- system.time(st_write(mp1, dsn = file.path(td, 'data2.sqlite'), layer
> = 'layer1', driver = 'SQLite'))
> t3 <- system.time(st_write(mp1, dsn = file.path(td, 'data2.sqlite'), layer
> = 'layer2', driver = 'SQLite'))
> t4 <- system.time(st_write(mp1, dsn = file.path(td, 'data3.gpkg'), layer =
> 'layer1'))
> t5 <- system.time(st_write(mp1, dsn = file.path(td, 'data3.gpkg'), layer =
> 'layer2'))
>
> rbind(t1,t2,t3,t4,t5)[,1:3]
>
>    user.self sys.self elapsed
> t1     0.012    0.000   0.010
> t2     0.180    0.456   8.993
> t3     0.220    0.460  10.637
> t4     0.016    0.064   0.082
> t5     0.200    0.472   9.199
>
> R version 3.4.0 (2017-04-21)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 16.04.2 LTS
>
> other attached packages:
> [1] sf_0.5-3     raster_2.5-8 sp_1.2-4
>
> loaded via a namespace (and not attached):
>  [1] compiler_3.4.0  magrittr_1.5    DBI_0.6-1       tools_3.4.0
> units_0.4-5     yaml_2.1.14     Rcpp_0.12.10    udunits2_0.13 grid_3.4.0
>   lattice_0.20-35
>
> Cheers,
> Lo?c
>
>
> There is no need to load rgdal or RSQLite, neither are needed or used. For
>> portability use tempdir():
>>
>> t1 <- system.time(st_write(mp1, dsn = paste0(td, 'data1.shp')))
>> t2 <- system.time(st_write(mp1, dsn = paste0(td, 'test.sqlite'), layer =
>> 'data1', driver = 'SQLite'))
>> t3 <- system.time(st_write(mp1, paste0(td, 'data1.gpkg')))
>>
>> Maybe an order of magnitude difference because the databases need
>> initialising, but nothing like your scale; does 32/64 bit make a difference?
>>
>> I'm assuming that you installed sf as a Windows binary from CRAN?
>>
>> Consider using a github issue when others have tried tis out on other
>> platforms.
>>
>> Roger
>>
>> Many thanks
>>> Manuel
>>>
>>>
>>> ------
>>> R version 3.4.1 (2017-06-30)
>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>> Running under: Windows 7 (build 7601) Service Pack 1
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1] LC_COLLATE=German_Switzerland.1252  LC_CTYPE=German_Switzerland.1252
>>> [3] LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
>>> [5] LC_TIME=German_Switzerland.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] sf_0.5-3    RSQLite_2.0 rgdal_1.2-8 sp_1.2-5
>>>
>>> loaded via a namespace (and not attached):
>>> [1] Rcpp_0.12.12    lattice_0.20-35 digest_0.6.12   grid_3.4.1
>>> DBI_0.7
>>> [6] magrittr_1.5    units_0.4-5     rlang_0.1.2     blob_1.1.0
>>> tools_3.4.1
>>> [11] udunits2_0.13   bit64_0.9-7     bit_1.1-12      compiler_3.4.1
>>> memoise_1.1.0
>>> [16] tibble_1.3.4
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From eduardodiez at gmx.com  Sat Aug 26 22:41:37 2017
From: eduardodiez at gmx.com (Eduardo Diez)
Date: Sat, 26 Aug 2017 17:41:37 -0300
Subject: [R-sig-Geo] Raster: merge cells with sorrounding zone by area
Message-ID: <CANK5cGwiqkBBt0EMxELO--a09AHxYB9vLKav_H-ZSor-AJYqgw@mail.gmail.com>

Dear group,
I usually work defining zones within agriculture fields taking into account
environmental layers. I have gridded data within the boundaries of the
field and cluster it to create management zones (between 3 and 6). Many
times i end up having in some groups or single cells of zone "x" within
zone "y". This results in spatially discontinuous zones. For visual (and
also practical) purposes i would like to get rid of these isolated patches
that are below a defined area size. That is, change the value of the
"isolated" cells for the one of the zone that surrounds them.
Example (sorry if i'm nor very good at making reproducible examples):

library(raster)
ext <- extent(732081.2, 732570.8, 6475458, 6475975)
r1 <- raster(ext, resolution = 50, crs = CRS("+init=epsg:32720"))
r1[1:33] <- 1
r1[34:66] <- 2
r1[67:100] <- 3
# Create "isolated" patches
r1[c(12, 17:18)] <- 2
r1[c(45:46,55)] <- 3
r1[c(77:78,86:87)] <- 1

The idea would be to define a minimum area threshold -in my example 11000
m2- that would detect groups of cells below that size and assign them the
value of the grater zone around it (around meaning 'rook' contiguity). This
would result in the original raster before the comment.

Thanks in advance,
Best

	[[alternative HTML version deleted]]


From alessandrosamuel at yahoo.com.br  Mon Aug 28 01:47:22 2017
From: alessandrosamuel at yahoo.com.br (Alessandro Samuel-Rosa)
Date: Sun, 27 Aug 2017 23:47:22 -0000
Subject: [R-sig-Geo] New version of package spsann (2.1-0) -- optimization
 of sample configurations using spatial simulated annealing
Message-ID: <68959c46-5719-82b6-dcac-5e375d1696ca@yahoo.com.br>

Dear all,

I am happy to announce that a new version of the *spsann* package is now
on CRAN.

The *spsann* package has methods to optimize sample configurations using
spatial simulated annealing. Multiple objective functions are
implemented for various purposes, such as variogram estimation, spatial
trend estimation and spatial interpolation. A general purpose spatial
simulated annealing function enables the user to define his/her own
objective function. A solution for solving multi-objective optimization
problems are available as well.

Now you can use *spsann* to augment an existing sample configuration,
that is, add new sampling points to a spatial sample configuration
generated using *spsann* or any other means. To do so, when using one of
the functions from the family of optim...() functions, you must pass to
the function argument points an object of class list containing two
named sub-arguments: fixed, a matrix or data frame with the coordinates
of the existing sample configuration -- kept fixed during the
optimization --, and free, the number of sample points that should be
added to the existing sample configuration -- free to move around during
the optimization.

The latest application of the *spsann* package was for the optimization
of the locations of rain-gauges to increase the accuracy of predictions
of rainfall fields in an area north-east of the city of Manchester,
United Kingdom. More information is available in the paper published by
Alexandre Wadoux
<http://www.wur.nl/en/Persons/Alexandre-AMJC-Alexandre-Wadoux-MSc.htm>
and collaborators which you can download from
https://doi.org/10.1016/j.advwatres.2017.06.005.

With best regards,

-- 

Alessandro Samuel-Rosa

/Estagi?rio P?s-doutoral (2016-17)
Universidade Federal de Santa Maria

Visite meu website <http://samuel-rosa.github.io>!
/

------------------------------------------------------------------------

*Fe-BR: Base de Dados Brasileira de Ferro do Solo
* Uma base de dados de ferro do solo centralizada, p?blica e gratuita,
com cobertura nacional.

Visite www.ufsm.br/febr <http://coral.ufsm.br/febr/contribute.html> e
veja como contribuir.


	[[alternative HTML version deleted]]


From Jin.Li at ga.gov.au  Mon Aug 28 06:32:57 2017
From: Jin.Li at ga.gov.au (Li Jin)
Date: Mon, 28 Aug 2017 04:32:57 +0000
Subject: [R-sig-Geo] A new R package - spm: Spatial Predictive Modelling,
 is now available on the CRAN [SEC=UNCLASSIFIED]
Message-ID: <aeb62f25905e4e1ebefe88db48bb1b22@win-exch-prod01.prod.lan>

Hi All,

Just thought you might be interested in a recently released R package, spm: Spatial Predictive Modelling. 

It aims to introduce some novel, accurate, hybrid geostatistical and machine learning methods for spatial predictive modelling. It currently contains two commonly used geostatistical methods, two machine learning methods, four hybrid methods and two averaging methods.

For each method, two functions are provided. One function is for assessing the predictive errors and accuracy of the method based on cross-validation. The other one is for generating spatial predictions using the method. They all use data.frame as input data. Moreover, two functions are provided for accuracy assessment. These functions attempt to simplify and streamline the model evaluation and model application processes, which may assist users to apply these methods to their data to improve modelling efficiency as well as predictive accuracy.

It can be downloaded from CRAN now.  

Any feedback and comments are much appreciated! 

Kind regards,

Jin Li, PhD | Spatial Modeller / Computational Statistician
National Earth and Marine Observations | Environmental Geoscience Division?
t:? +61 2 6249 9899??? www.ga.gov.au



Geoscience Australia Disclaimer: This e-mail (and files transmitted with it) is intended only for the person or entity to which it is addressed. If you are not the intended recipient, then you have received this e-mail by mistake and any use, dissemination, forwarding, printing or copying of this e-mail and its file attachments is prohibited. The security of emails transmitted cannot be guaranteed; by forwarding or replying to this email, you acknowledge and accept these risks.


From mspinola10 at gmail.com  Tue Aug 29 17:03:57 2017
From: mspinola10 at gmail.com (=?UTF-8?Q?Manuel_Sp=C3=ADnola?=)
Date: Tue, 29 Aug 2017 09:03:57 -0600
Subject: [R-sig-Geo] Compatibility between sf and raster
Message-ID: <CABkCotQwguCFrkTW5A2d8+FT768tLH1D+OnZtF3z3jgQGUwdag@mail.gmail.com>

Dear list members,

Is there any plan to make compatible the sf and the raster packages?

library(sf)
library(raster)

> nc <- st_read(system.file("shape/nc.shp", package="sf"))
Reading layer `nc' from data source
`/Library/Frameworks/R.framework/Versions/3.4/Resources/library/sf/shape/nc.shp'
using driver `ESRI Shapefile'
Simple feature collection with 100 features and 14 fields
geometry type:  MULTIPOLYGON
dimension:      XY
bbox:           xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax:
36.58965
epsg (SRID):    4267
proj4string:    +proj=longlat +datum=NAD27 +no_defs

> raster(nc)
Error in (function (classes, fdef, mtable)  :
  unable to find an inherited method for function ?raster? for signature
?"sf"?



-- 
*Manuel Sp?nola, Ph.D.*
Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
Universidad Nacional
Apartado 1350-3000
Heredia
COSTA RICA
mspinola at una.cr <mspinola at una.ac.cr>
mspinola10 at gmail.com
Tel?fono: (506) 8706 - 4662
Personal website: Lobito de r?o <https://sites.google.com/site/lobitoderio/>
Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>

	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Tue Aug 29 18:22:20 2017
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 29 Aug 2017 18:22:20 +0200
Subject: [R-sig-Geo] Compatibility between sf and raster
In-Reply-To: <CABkCotQwguCFrkTW5A2d8+FT768tLH1D+OnZtF3z3jgQGUwdag@mail.gmail.com>
References: <CABkCotQwguCFrkTW5A2d8+FT768tLH1D+OnZtF3z3jgQGUwdag@mail.gmail.com>
Message-ID: <02484c34-3fce-1661-a27b-5961e68b58f6@uni-muenster.de>

Right now you'll have to be satisfied with doing

raster(as(nc, "Spatial"))

there is a follow-up project to sf, called stars [1], which will try to
look beyond raster, rather than redo raster or make raster and sf
compatible. Stars will consider compatibility with raster, but don't
hold your breath.

stars development will start soon.

[1] https://github.com/r-spatial/stars

On 29/08/17 17:03, Manuel Sp?nola wrote:
> Dear list members,
> 
> Is there any plan to make compatible the sf and the raster packages?
> 
> library(sf)
> library(raster)
> 
>> nc <- st_read(system.file("shape/nc.shp", package="sf"))
> Reading layer `nc' from data source
> `/Library/Frameworks/R.framework/Versions/3.4/Resources/library/sf/shape/nc.shp'
> using driver `ESRI Shapefile'
> Simple feature collection with 100 features and 14 fields
> geometry type:  MULTIPOLYGON
> dimension:      XY
> bbox:           xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax:
> 36.58965
> epsg (SRID):    4267
> proj4string:    +proj=longlat +datum=NAD27 +no_defs
> 
>> raster(nc)
> Error in (function (classes, fdef, mtable)  :
>   unable to find an inherited method for function ?raster? for signature
> ?"sf"?
> 
> 
> 

-- 
Edzer Pebesma
Institute for Geoinformatics  (ifgi),  University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20170829/95124a2c/attachment.sig>

From mspinola10 at gmail.com  Tue Aug 29 18:43:08 2017
From: mspinola10 at gmail.com (=?UTF-8?Q?Manuel_Sp=C3=ADnola?=)
Date: Tue, 29 Aug 2017 10:43:08 -0600
Subject: [R-sig-Geo] Compatibility between sf and raster
In-Reply-To: <02484c34-3fce-1661-a27b-5961e68b58f6@uni-muenster.de>
References: <CABkCotQwguCFrkTW5A2d8+FT768tLH1D+OnZtF3z3jgQGUwdag@mail.gmail.com>
 <02484c34-3fce-1661-a27b-5961e68b58f6@uni-muenster.de>
Message-ID: <CABkCotR-LOL+Rung0-cnL6b6oDziR-tkXB8EwnhV=XXzW18CDQ@mail.gmail.com>

Thank you very much Edzer.

Manuel

2017-08-29 10:22 GMT-06:00 Edzer Pebesma <edzer.pebesma at uni-muenster.de>:

> Right now you'll have to be satisfied with doing
>
> raster(as(nc, "Spatial"))
>
> there is a follow-up project to sf, called stars [1], which will try to
> look beyond raster, rather than redo raster or make raster and sf
> compatible. Stars will consider compatibility with raster, but don't
> hold your breath.
>
> stars development will start soon.
>
> [1] https://github.com/r-spatial/stars
>
> On 29/08/17 17:03, Manuel Sp?nola wrote:
> > Dear list members,
> >
> > Is there any plan to make compatible the sf and the raster packages?
> >
> > library(sf)
> > library(raster)
> >
> >> nc <- st_read(system.file("shape/nc.shp", package="sf"))
> > Reading layer `nc' from data source
> > `/Library/Frameworks/R.framework/Versions/3.4/
> Resources/library/sf/shape/nc.shp'
> > using driver `ESRI Shapefile'
> > Simple feature collection with 100 features and 14 fields
> > geometry type:  MULTIPOLYGON
> > dimension:      XY
> > bbox:           xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax:
> > 36.58965
> > epsg (SRID):    4267
> > proj4string:    +proj=longlat +datum=NAD27 +no_defs
> >
> >> raster(nc)
> > Error in (function (classes, fdef, mtable)  :
> >   unable to find an inherited method for function ?raster? for signature
> > ?"sf"?
> >
> >
> >
>
> --
> Edzer Pebesma
> Institute for Geoinformatics  (ifgi),  University of M?nster
> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> Journal of Statistical Software:   http://www.jstatsoft.org/
> Computers & Geosciences:   http://elsevier.com/locate/cageo/
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
*Manuel Sp?nola, Ph.D.*
Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
Universidad Nacional
Apartado 1350-3000
Heredia
COSTA RICA
mspinola at una.cr <mspinola at una.ac.cr>
mspinola10 at gmail.com
Tel?fono: (506) 8706 - 4662
Personal website: Lobito de r?o <https://sites.google.com/site/lobitoderio/>
Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>

	[[alternative HTML version deleted]]


From SWalbridge at esri.com  Wed Aug 30 02:52:04 2017
From: SWalbridge at esri.com (Shaun Walbridge)
Date: Wed, 30 Aug 2017 00:52:04 +0000
Subject: [R-sig-Geo] Esri Workshop: Working with R and ArcGIS
Message-ID: <F0DB5DA7-1F13-493D-A83D-94C28DC8FEC5@esri.com>

This Thursday, August 31st, Esri is hosting an online workshop
detailing how ArcGIS can be used in conjunction with R, using
the arcgisbinding package:

??https://www.esri.com/training/catalog/596e5ab6b826875993ba4fd9/

There are three time slots available, the bottom of the linked page
includes the times in your local timezone. The project is hosted on
GitHub, and issues can be reported at:

??https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_R-2DArcGIS_r-2Dbridge&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=fCPRb7QX-vd5bnO9gIJHCiX852SVUtyYX--xtCKtpfk&m=HBU0MtamSu15VKRZjrtOizUo-OW9rZkyR372GjFTILE&s=GM4EUPpwjU6uvxqwZhk-cmewnmBRZycv9sZCQ11-9xs&e= 

Cheers,
Shaun




From Nathen.Harp at dot.ny.gov  Wed Aug 30 17:01:26 2017
From: Nathen.Harp at dot.ny.gov (Harp, Nathen (DOT))
Date: Wed, 30 Aug 2017 15:01:26 +0000
Subject: [R-sig-Geo] online workshop
Message-ID: <DM5PR09MB13210376518706919FE87AF0D19C0@DM5PR09MB1321.namprd09.prod.outlook.com>

This Thursday, August 31st, Esri is hosting an online workshop
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: text/calendar
Size: 1536 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20170830/751da474/attachment.ics>

From dlucero at health.nyc.gov  Wed Aug 30 17:59:39 2017
From: dlucero at health.nyc.gov (David Lucero)
Date: Wed, 30 Aug 2017 15:59:39 +0000
Subject: [R-sig-Geo] online workshop
In-Reply-To: <DM5PR09MB13210376518706919FE87AF0D19C0@DM5PR09MB1321.namprd09.prod.outlook.com>
References: <DM5PR09MB13210376518706919FE87AF0D19C0@DM5PR09MB1321.namprd09.prod.outlook.com>
Message-ID: <56FEBDD9-ED7E-4D2D-86AA-2BAD709CAABC@health.nyc.gov>

Can you please provide a link? I was unable to find any free workshops.

Thanks, David
d:3473962786 | c:6468300383
typed with thumbs, pls excuse typos/autocorrections

El ago. 30, 2017, a las 11:02 AM, Harp, Nathen (DOT) <Nathen.Harp at dot.ny.gov<mailto:Nathen.Harp at dot.ny.gov>> escribi?:

This Thursday, August 31st, Esri is hosting an online workshop
_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo
<meeting.ics>
Sent from the New York City Department of Health & Mental Hygiene. This email and any files transmitted with it may contain confidential information and are intended solely for the use of the individual or entity to whom they are addressed. This footnote also confirms that this email message has been swept for the presence of computer viruses.

	[[alternative HTML version deleted]]


From mdhyslop at mtu.edu  Wed Aug 30 18:09:14 2017
From: mdhyslop at mtu.edu (Mike Hyslop)
Date: Wed, 30 Aug 2017 12:09:14 -0400
Subject: [R-sig-Geo] online workshop
In-Reply-To: <56FEBDD9-ED7E-4D2D-86AA-2BAD709CAABC@health.nyc.gov>
References: <DM5PR09MB13210376518706919FE87AF0D19C0@DM5PR09MB1321.namprd09.prod.outlook.com>
 <56FEBDD9-ED7E-4D2D-86AA-2BAD709CAABC@health.nyc.gov>
Message-ID: <CANh-8FhdhYwi2YG6PV8O3MESYQFySs67Es2ZFpfapVUyd75UeA@mail.gmail.com>

This Thursday, August 31st, Esri is hosting an online workshop
detailing how ArcGIS can be used in conjunction with R, using
the arcgisbinding package:

  https://www.esri.com/training/catalog/596e5ab6b826875993ba4fd9/

There are three time slots available, the bottom of the linked page
includes the times in your local timezone. The project is hosted on
GitHub, and issues can be reported at:

  https://urldefense.proofpoint.com/v2/url?u=https-
3A__github.com_R-2DArcGIS_r-2Dbridge&d=DwIGaQ&c=n6-cguzQvX_tUIrZOS_4Og&r=
fCPRb7QX-vd5bnO9gIJHCiX852SVUtyYX--xtCKtpfk&m=HBU0MtamSu15VKRZjrtOizUo-
OW9rZkyR372GjFTILE&s=GM4EUPpwjU6uvxqwZhk-cmewnmBRZycv9sZCQ11-9xs&e=

Michael D. Hyslop  <mdhyslop at mtu.edu>  906/487-2308
Principal Lecturer
Master of Geographic Information Science Program Director
School of Forest Resources & Environmental Science
Michigan Technological University
Houghton, MI, 49931      http://forest.mtu.edu/faculty/hyslop/


On Wed, Aug 30, 2017 at 11:59 AM, David Lucero <dlucero at health.nyc.gov>
wrote:

> Can you please provide a link? I was unable to find any free workshops.
>
> Thanks, David
> d:3473962786 | c:6468300383
> typed with thumbs, pls excuse typos/autocorrections
>
> El ago. 30, 2017, a las 11:02 AM, Harp, Nathen (DOT) <
> Nathen.Harp at dot.ny.gov<mailto:Nathen.Harp at dot.ny.gov>> escribi?:
>
> This Thursday, August 31st, Esri is hosting an online workshop
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> <meeting.ics>
> Sent from the New York City Department of Health & Mental Hygiene. This
> email and any files transmitted with it may contain confidential
> information and are intended solely for the use of the individual or entity
> to whom they are addressed. This footnote also confirms that this email
> message has been swept for the presence of computer viruses.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From jean-luc.dupouey at inra.fr  Wed Aug 30 22:05:41 2017
From: jean-luc.dupouey at inra.fr (Jean-Luc Dupouey)
Date: Wed, 30 Aug 2017 22:05:41 +0200
Subject: [R-sig-Geo] reading Geoconcept files ?
Message-ID: <01df8a47-a89f-0b27-b971-63881e8ea90b@inra.fr>

Dear all,

is it possible to read Geoconcept files (.gcm and .GCR) in R? 
ogrDrivers()$name indicates that a Geoconcept driver exists, but I was 
not able to read any data. I get a "Cannot open data source" error:

 > ogrDrivers()[ogrDrivers()$name=="Geoconcept",]
          name  long_name write  copy isVector
11 Geoconcept Geoconcept  TRUE FALSE     TRUE
 >
 > list.files(path=".",pattern="nvcarte.*")
[1] "nvcarte.GCM" "nvcarte.GCR"
 >
 > readOGR(dsn=".",layer="nvcarte")
Error in ogrInfo(dsn = dsn, layer = layer, encoding = encoding, 
use_iconv = use_iconv,  :
   Cannot open data source

Did anyone successfully use this driver? What is the syntax?

Thank you for your help,

Jean-Luc Dupouey

-- 
INRA
Forest Ecology and Ecophysiology Unit
F-54280 Champenoux
France
mail : jean-luc.dupouey at inra.fr


From Roger.Bivand at nhh.no  Thu Aug 31 11:11:14 2017
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 31 Aug 2017 11:11:14 +0200
Subject: [R-sig-Geo] reading Geoconcept files ?
In-Reply-To: <01df8a47-a89f-0b27-b971-63881e8ea90b@inra.fr>
References: <01df8a47-a89f-0b27-b971-63881e8ea90b@inra.fr>
Message-ID: <alpine.LFD.2.20.1708311106410.5561@reclus.nhh.no>

On Wed, 30 Aug 2017, Jean-Luc Dupouey wrote:

> Dear all,
>
> is it possible to read Geoconcept files (.gcm and .GCR) in R? 
> ogrDrivers()$name indicates that a Geoconcept driver exists, but I was not 
> able to read any data. I get a "Cannot open data source" error:

See:

http://www.gdal.org/drv_geoconcept.html

and note that it only supports *.gxt or *.txt formats. For these, try 
ogrListLayers() first on the file name as dsn=.

Roger

>
>>  ogrDrivers()[ogrDrivers()$name=="Geoconcept",]
>         name  long_name write  copy isVector
> 11 Geoconcept Geoconcept  TRUE FALSE     TRUE
>>
>>  list.files(path=".",pattern="nvcarte.*")
> [1] "nvcarte.GCM" "nvcarte.GCR"
>>
>>  readOGR(dsn=".",layer="nvcarte")
> Error in ogrInfo(dsn = dsn, layer = layer, encoding = encoding, use_iconv = 
> use_iconv,  :
>   Cannot open data source
>
> Did anyone successfully use this driver? What is the syntax?
>
> Thank you for your help,
>
> Jean-Luc Dupouey
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From e0425926 at student.tuwien.ac.at  Thu Aug 31 12:52:25 2017
From: e0425926 at student.tuwien.ac.at (Kevin Stadler)
Date: Thu, 31 Aug 2017 12:52:25 +0200
Subject: [R-sig-Geo] Introducing: an R package for calling functions
 within a running instance of QGIS (ALPHA)
In-Reply-To: <CALufGKKcdFbAaSv==xfMG-JbBrCnsA1huS3Vh5rNeUN+EWoAcA@mail.gmail.com>
References: <CALufGKKcdFbAaSv==xfMG-JbBrCnsA1huS3Vh5rNeUN+EWoAcA@mail.gmail.com>
Message-ID: <CALufGKJUbQwfyWkUe4zsxvDyU14-vqKLpbPnJ7r=PcBtOO-mJQ@mail.gmail.com>

As my Google Summer of Code project is coming to an end, here's some
updates on the R package:

1. we renamed the package to 'qgisremote', so the repository and
documentation are now available from here:
https://gitlab.com/qgisapi/qgisremote
https://qgisapi.gitlab.io/qgisremote/
The corresponding QGIS plugin can still be found at its old address --
it has also been greatly expanded, so if you've installed a previous
version of it be sure to update both the R package and the plugin,
otherwise new features will most likely not work:
https://gitlab.com/qgisapi/networkapi

2. thanks to the feedback and comments I received from this mailing
list, I've both fixed numerous issues as well as added new
functionality that several people asked about, especially regarding
simple manipulations of QGIS rendering options from R. The package now
has dedicated functions for getting and setting styles in QGIS' XML
specification format, as well as some helper functions that simplify
very basic style spec manipulation tasks. To get a quick idea of how
the functions work, see the renderer article here:
https://qgisapi.gitlab.io/qgisremote/articles/renderers.html

I hope the package (and QGIS plugin) will be useful to some of you,
Best!
Kevin

On 14 July 2017 at 15:46, Kevin Stadler <e0425926 at student.tuwien.ac.at> wrote:
> Hello,
>
> as part of my Google Summer of Code project I am currently developing
> a QGIS plugin that allows controlling a running QGIS instance through
> a HTTP interface -- and an R package making use of this 'Network API'
> along with it.
>
> This package is quite different from the existing RQGIS in that it
> connects to a running instance of QGIS, meaning that programmatic
> control from within R + user interaction can be combined (the QGIS
> instance being controlled does not even have to run on the same
> machine).
>
> Both components (QGIS plugin and R package) are still deep in alpha
> stages, however for those interested there is now sufficient
> documentation to give testing a shot, and I would welcome all feedback
> and suggestions. This simple example tutorial vignette should give you
> an idea of how the package works:
> http://qgisapi.gitlab.io/rqgisapi/articles/tutorial.html
>
> Instructions for installing the two components can be found here:
> https://gitlab.com/qgisapi/networkapi#testing
> and here:
> http://qgisapi.gitlab.io/rqgisapi/#installation
>
>
> I will be expanding the package as well developing example use cases
> in the form of Rmarkdown and JuPyteR notebooks until the end of the
> summer, so I'd be happy to receive requests for QGIS functionality
> that you'd like to see exposed to R (access to processing functions in
> particular is not implemented at the moment). If there is more
> interest I'd be happy to keep posting regular updates about new
> features to this list too.
>
> Best!
> Kevin


From cpscesar at gmail.com  Thu Aug 31 14:54:30 2017
From: cpscesar at gmail.com (=?UTF-8?Q?C=C3=A9sar_Soares?=)
Date: Thu, 31 Aug 2017 09:54:30 -0300
Subject: [R-sig-Geo] CARBayesST - Diagnostic
Message-ID: <CAO-G=TEYNwVPPt1U0tBD4-RWrGTx-rrhyJKhJCWBhU35CSWX3g@mail.gmail.com>

Hi everybody, Im new in this list, so if I am sending something that is not
allowed, please, tell me and I already apologize.
My issue is: I am doing a panel data analysis using CARBayesST to fit
a spatio-temporal
generalised linear mixed model to my data, with a spatio-temporal
autoregressive process (ST.CARar function). Thus, I want to know how to
diagnose the fit of my model. If someone could indicate a website, post or
document I will appreciate.


Sincerely,

C?sar

	[[alternative HTML version deleted]]


From kat.emidio at gmail.com  Thu Aug 31 17:21:42 2017
From: kat.emidio at gmail.com (=?UTF-8?Q?K=C3=A1tia_Emidio?=)
Date: Thu, 31 Aug 2017 11:21:42 -0400
Subject: [R-sig-Geo] creating subregions in circular window
Message-ID: <CABFLJO=Tfbq_tv2m33Qn2JOwdrA4NEbyxF591M75mc14THnGRg@mail.gmail.com>

Dear all,
I'm looking for a way of divide a circular window in some arcs, using de
radius and angle, like 08 arcs and radius=15m. I need to use it as a
spatial window after...
Thanks

-- 
K?tia Em?dio da Silva DSc
Eng. Florestal
Manaus/AM



Forestry Engineer
Manaus/AM-Brazil

	[[alternative HTML version deleted]]


From milujisb at gmail.com  Thu Aug 31 21:22:33 2017
From: milujisb at gmail.com (Miluji Sb)
Date: Thu, 31 Aug 2017 21:22:33 +0200
Subject: [R-sig-Geo] Aggregation to
Message-ID: <CAMLwc7OMCN6hjiGdnAYJKC6k8cjuwhOudJnnEgvqqEMCaJrYhg@mail.gmail.com>

I have a set of coordinates:

temp <- dput(head(gcp,10))
structure(list(lon = c(-180, -180, -179, -179, -178, -178, -177,
-176, -176, -175), lat = c(67, 68, 67, 68, 67, 68, 67, 66, 67,
66)), datalabel = "", time.stamp = "11 Aug 2017 16:10", .Names = c("lon",
"lat"), formats = c("%9.0g", "%9.0g"), types = c(255L, 255L), val.labels =
c("",
""), var.labels = c("lon", "lat"), version = 12L, row.names = c("1",
"2", "3", "4", "5", "6", "7", "8", "9", "10"), class = "data.frame")

These are at 1 degree, I would like to aggregate them to 2.5 degree to use
them to extract data from a netcdf file (which is at 2.5 degree). This is
what I have done:

rasterDF <- rasterFromXYZ(gcp)
gcp2_5 <- aggregate(rasterDF,fact=2.5, fun=sum)

However, this seems to return aggregated coordinates at 2 degree.

class       : RasterLayer
dimensions  : 67, 180, 12060  (nrow, ncol, ncell)
resolution  : 2, 2  (x, y)
extent      : -180.5, 179.5, -54.5, 79.5  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0

What am I doing wrong? Is there another way? Thank you.

Sincerely,

Milu

	[[alternative HTML version deleted]]


From loic.dutrieux at conabio.gob.mx  Thu Aug 31 21:57:42 2017
From: loic.dutrieux at conabio.gob.mx (=?UTF-8?Q?Lo=c3=afc_Dutrieux?=)
Date: Thu, 31 Aug 2017 14:57:42 -0500
Subject: [R-sig-Geo] Aggregation to
In-Reply-To: <CAMLwc7OMCN6hjiGdnAYJKC6k8cjuwhOudJnnEgvqqEMCaJrYhg@mail.gmail.com>
References: <CAMLwc7OMCN6hjiGdnAYJKC6k8cjuwhOudJnnEgvqqEMCaJrYhg@mail.gmail.com>
Message-ID: <979b9af0-44b2-3be9-d8a8-784ea29c368d@conabio.gob.mx>



On 31/08/17 14:22, Miluji Sb wrote:
> I have a set of coordinates:
> 
> temp <- dput(head(gcp,10))
> structure(list(lon = c(-180, -180, -179, -179, -178, -178, -177,
> -176, -176, -175), lat = c(67, 68, 67, 68, 67, 68, 67, 66, 67,
> 66)), datalabel = "", time.stamp = "11 Aug 2017 16:10", .Names = c("lon",
> "lat"), formats = c("%9.0g", "%9.0g"), types = c(255L, 255L), val.labels =
> c("",
> ""), var.labels = c("lon", "lat"), version = 12L, row.names = c("1",
> "2", "3", "4", "5", "6", "7", "8", "9", "10"), class = "data.frame")
> 
> These are at 1 degree, I would like to aggregate them to 2.5 degree to use
> them to extract data from a netcdf file (which is at 2.5 degree). This is
> what I have done:
> 
> rasterDF <- rasterFromXYZ(gcp)
> gcp2_5 <- aggregate(rasterDF,fact=2.5, fun=sum)

The aggregation factor in raster::aggregate has to be an integer (2, 3, 
etc). Perhaps raster::resample is what you're looking for then. When 
using 'bilinear', resample actually aggregates to the nearest multiple 
of the original raster's resolution (2 degrees in your case), and 
finishes with some interpolation.

Cheers,
Lo?c

> 
> However, this seems to return aggregated coordinates at 2 degree.
> 
> class       : RasterLayer
> dimensions  : 67, 180, 12060  (nrow, ncol, ncell)
> resolution  : 2, 2  (x, y)
> extent      : -180.5, 179.5, -54.5, 79.5  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> 
> What am I doing wrong? Is there another way? Thank you.
> 
> Sincerely,
> 
> Milu
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> Email secured by Check Point
>


From jthayn at ilstu.edu  Thu Aug 31 22:06:57 2017
From: jthayn at ilstu.edu (Thayn, Jonathan)
Date: Thu, 31 Aug 2017 20:06:57 +0000
Subject: [R-sig-Geo] Order a SpatialLine passes through a SpatialPolygons
Message-ID: <959F8B6F-B65F-46BA-B550-F4B284301802@ilstu.edu>

I?m trying to write a function that returns the polygons through which a line passes, but I want the polygons to be listed in order. For example, in the code below, I get a list of polygons over which the lines passes, but the polygons are listed in numeric order, not spatial order. I would like the polygons to be listed as 21, 24, 25, 26, and 22 (the reverse would be fine to). Any ideas.


library(spdep)
example(columbus)
plot(columbus)
coords <- coordinates(columbus)
text(coords,labels=1:49)

the.line <- SpatialLines(list(Lines(Line(coords[c(21,22),]),ID="A")))
plot(the.line,col="red",add=T)

which(!is.na(over(columbus,the.line)))



Jonathan B. Thayn, Ph.D.

Associate Professor
Department of Geography ? Geology
Illinois State University
Felmley Hall of Science, Rm 200A
Normal, IL 61790

jthayn at ilstu.edu<mailto:jthayn at ilstu.edu>
my.ilstu.edu/~jthayn<http://my.ilstu.edu/~jthayn>





	[[alternative HTML version deleted]]


