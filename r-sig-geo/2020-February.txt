From g@b|k|m01 @end|ng |rom gm@||@com  Sat Feb  1 19:25:24 2020
From: g@b|k|m01 @end|ng |rom gm@||@com (Gabriel Cotlier)
Date: Sat, 1 Feb 2020 20:25:24 +0200
Subject: [R-sig-Geo] question on writing shapefiles from OSM data
Message-ID: <CAAKwTDH1FzG7ayCZyiZFDdpgoQWr3EQa8ghf51UXtbaouSOsGw@mail.gmail.com>

Dear users,
I would like to download OSM data and convert it to shapefile and change
coordinates to same as Landsat data.
I'm following the code bellow.
Is this the correct way for saving/writing to swapfile the OSM data?
Thanks a lot for your response.
Best,

library(osmar)
library(osmdata)
library(OpenStreetMap)
library(tmap)

# Paris administrative borders ID
id<-c(7444)
dat2 <- opq_osm_id (type = "relation", id = id) %>%
  opq_string () %>%
  osmdata_sf ()
qtm(dat2$osm_multipolygons)

library(sf)
st_write(dat2$osm_multipolygons, "s.shp")
# change coordinate system to Landsat data
landst_crs= "+proj=utm +zone=36 +datum=WGS84 +units=m +no_defs +ellps=WGS84
+towgs84=0,0,0"
s=readOGR('/Users/gcotlier/Desktop/s.shp')
S <- spTransform(s, CRS(landst_crs))
writeOGR( obj = S, dsn = '/Users/gcotlier/Desktop',layer = "S1", driver =
"ESRI Shapefile")
S1=readOGR('/Users/gcotlier/Desktop/S1.shp')
plot(S1)

	[[alternative HTML version deleted]]


From Roger@B|v@nd @end|ng |rom nhh@no  Sun Feb  2 15:21:08 2020
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Sun, 2 Feb 2020 15:21:08 +0100
Subject: [R-sig-Geo] question on writing shapefiles from OSM data
In-Reply-To: <CAAKwTDH1FzG7ayCZyiZFDdpgoQWr3EQa8ghf51UXtbaouSOsGw@mail.gmail.com>
References: <CAAKwTDH1FzG7ayCZyiZFDdpgoQWr3EQa8ghf51UXtbaouSOsGw@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.2002021511210.1749822@reclus.nhh.no>

On Sat, 1 Feb 2020, Gabriel Cotlier wrote:

> Dear users,
> I would like to download OSM data and convert it to shapefile and change
> coordinates to same as Landsat data.
> I'm following the code bellow.
> Is this the correct way for saving/writing to swapfile the OSM data?

Since you are using the sf package, why not use it for the other 
operations? There is no need to involve sp or rgdal unless you want to for 
some other reason. Maybe you are copying from an old blog or SO source? 
Have you visited: https://www.r-spatial.org/ with plenty of posts on 
migrating to sf?

With regard to coordinate operations, you (and everybody else) will need 
to find out how to define CRS without using Proj.4 strings; this change is 
coming soon! Yours looks like EPSG:32636. Both sf and sp will be moving 
very soon to WKT2-2019 from Proj.4 strings (Proj.4 strings will still be 
available, but datums and other specification components may simply drop 
out without warning because of changes in PROJ and GDAL).

Finally, stop using shapefiles and change to GeoPackage straight away, 
there is no reason to continue to use a format past its end-of-life.

Roger

> Thanks a lot for your response.
> Best,
>
> library(osmar)
> library(osmdata)
> library(OpenStreetMap)
> library(tmap)
>
> # Paris administrative borders ID
> id<-c(7444)
> dat2 <- opq_osm_id (type = "relation", id = id) %>%
>  opq_string () %>%
>  osmdata_sf ()
> qtm(dat2$osm_multipolygons)
>
> library(sf)
> st_write(dat2$osm_multipolygons, "s.shp")
> # change coordinate system to Landsat data
> landst_crs= "+proj=utm +zone=36 +datum=WGS84 +units=m +no_defs +ellps=WGS84
> +towgs84=0,0,0"
> s=readOGR('/Users/gcotlier/Desktop/s.shp')
> S <- spTransform(s, CRS(landst_crs))
> writeOGR( obj = S, dsn = '/Users/gcotlier/Desktop',layer = "S1", driver =
> "ESRI Shapefile")
> S1=readOGR('/Users/gcotlier/Desktop/S1.shp')
> plot(S1)
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From m|re|@_be|o|u @end|ng |rom y@hoo@com  Mon Feb  3 13:57:06 2020
From: m|re|@_be|o|u @end|ng |rom y@hoo@com (Mirela Beloiu)
Date: Mon, 3 Feb 2020 12:57:06 +0000 (UTC)
Subject: [R-sig-Geo] How to check & interpret an MCMCglmm ordinal model in R?
References: <1337581491.1501353.1580734626762.ref@mail.yahoo.com>
Message-ID: <1337581491.1501353.1580734626762@mail.yahoo.com>

Dear users,
I'm trying to explain changes in tree vitality from 1 to 3 (1=green, 2=damage, 3=dry) using precipitation, diameter and tree species in an MCMCglmm model. I am struggling with two questions:1. How do I check if the model is correct??2. How do I interpret the summary of the MCMCglmm model in relation to my response variable (the three groups 1,2 and 3)?
Data and R script can be found here?https://drive.google.com/drive/folders/1LmgEAssR5FfFw1CkYjygsaawg84dDAwk?usp=sharing?.?Details are posted here.
###MCMCglmm model, family= ordinal

    prior1<-list(R=list(V=diag(1),nu=0.002))
    m1 <-MCMCglmm(VIT_2018~ pp18 +DBH+Species, 
                                 family = "ordinal", data = comsp,prior=prior1,pr = TRUE, 
                                 nitt = 60000, burnin =30000, thin = 50)
    summary(m1)
    Iterations = 30001:59951
     Thinning interval  = 50
     Sample size  = 600 
     DIC: -146008.7 
     R-structure:  ~units
          post.mean l-95% CI u-95% CI eff.samp
    units      2697     1016     5304    6.075
     Location effects: VIT_2018 ~ pp18 + DBH + Species 
                            post.mean  l-95% CI  u-95% CI eff.samp   pMCMC   
    (Intercept)              60.64229  31.71644  92.78733    11.49 < 0.002 **
    pp18                     -0.07020  -0.11518  -0.03556    15.47 < 0.002 **
    DBH                       0.17357  -0.01797   0.37281    58.26 0.06000 . 
    SpeciesBetula pendula   -12.88510 -29.42191   1.87807    58.40 0.08667 . 
    SpeciesCarpinus betulus  15.57570   0.96439  30.89528    45.04 0.02000 * 
    SpeciesCorylus avellana  -3.81337 -18.31965  13.12771   600.00 0.59000   
    SpeciesCrataegus spec.  -14.90077 -36.86880   4.24729   286.00 0.10333   
    SpeciesFagus sylvatica  -15.03559 -29.04547  -2.07809    60.56 0.00667 **
    SpeciesFrangula alnus    20.10817  -0.10598  38.66354    73.88 0.01333 * 
    SpeciesQuercus spec.     -9.09458 -24.52595   6.42502   293.33 0.26000   
    SpeciesSambucus nigra    24.29894   2.58339  46.29901    49.66 0.02333 * 
    SpeciesSorbus aucuparia  39.56930  22.97282  63.15175    10.13 < 0.002 **
    ---
    Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
     Cutpoints: 
                             post.mean l-95% CI u-95% CI eff.samp
    cutpoint.traitVIT_2018.1     80.46    55.38    117.9    4.204
#### Estimating Credible Intervals
    HPDinterval(mcmc(randomprior1$Sol[,"(Intercept)"]))
    #        lower    upper
    #var1 31.71644 92.78733
    #attr(,"Probability")
    #[1] 0.95
Any suggestions/ideas would be really helpful. Thank you for your time and help!

Mirela

	[[alternative HTML version deleted]]


From me|gr@e@er @end|ng |rom gm@||@com  Wed Feb  5 16:06:08 2020
From: me|gr@e@er @end|ng |rom gm@||@com (Melanie Graeser)
Date: Wed, 5 Feb 2020 16:06:08 +0100
Subject: [R-sig-Geo] Geocoding addresses restricted to one country
Message-ID: <CAOav87UcUi1mOBt9N7Pw4ctN7Xu1eFh7VbeMcgwJ9ab_FoDSuQ@mail.gmail.com>

Dear users,

I am trying to geocode locations of firms in Liberia from a vector of
addresses. My problem is that many addresses are not geocoded in
Liberia, but instead all over the world. I would like to restrict the
API geocoding response to only show results that are in Liberia. I am
using the Google API and library(ggmap). My code is the following:

register_google(key = "myAPIkey")

test <- mutate_geocode(nec07, Address) # nec07 is my df of firms,
Address is a vector of firm addresses

test1<-test %>% drop_na(lon) # dropping all NAs where geocoding
returned no result to be able to create sf object to see if locations
are correctly geocoded

test1_sf <- st_as_sf(test1, coords = c("lon", "lat"), crs = 4326)

mapview(test1_sf) # Only 2000 out of 5000 firms are geocoded in
Liberia, the rest in other countries

I would be very grateful if you know of any options to restrict
geocoding to return locations only in Liberia.

Many thanks in advance!

Melanie

-- 
Melanie Gr?ser
*Research Associate*
*Vienna University of Economics and Business*


From br@dn|@@en915 @end|ng |rom gm@||@com  Wed Feb  5 16:40:36 2020
From: br@dn|@@en915 @end|ng |rom gm@||@com (Brad Nissen)
Date: Wed, 5 Feb 2020 09:40:36 -0600
Subject: [R-sig-Geo] Why do kde estimates from ks and adehabitatHR packages
 in R produce different results? (with same bandwidth and grid)
Message-ID: <CABPHv2N-0UDtVq0jer2r4ThaqgLYsawGS7s6ScXRjjyuqtJCvQ@mail.gmail.com>

Hi All,

I have a series of VHF radio-telemetry data from animals that I am hoping
to be able analyze in R. I have done my research on the different packages
available for this, and I believe that utilizing the package ks to select a
plug-in bandwidth method for all individuals will be most appropriate,
based on previous research with my study species. This is reinforced in
section 4.3 of this spatial ecology book
<https://ecosystems.psu.edu/research/labs/walter-lab/manual/home-range-estimation/link-to-pdf>
and
in this paper by Millspaugh et al (2006)
<https://wildlife.onlinelibrary.wiley.com/doi/pdf/10.2193/0022-541X%282006%2970%5B384%3AAORSUU%5D2.0.CO%3B2>
.

I have written two R functions, initially to check that I got similar
results, and then hopefully select one to analyze the home ranges of my
study animals. My results from the two functions were not as similar as I
hoped, and that is what brings me to this forum - to figure out why. The
first function relies entirely on the ks package, by using the kde()
function and a pre-defined grid expanded by a factor of the bandwidth to
get the volume of the Utilization distribution (UD). The UD was then sorted
by high to low density. I calculated the size of a grid cell, then
calculated the cumulative sum of the grid cell volumes. I then took the
number of cells in this list needed to give a cumulative volume of 0.95 or
0.50 (depending on if I am interested in the 95% or 50% kde area) and then
multiplied that number of cells by the cell size to get the area. Perhaps
there is a flaw in my logic here that I am not seeing, if so please alert
me.

The annotated R code for that function is here:

kde_ks.hpi <- function(filename, percentage, gridsize, multiplier){
    data <- read.csv(file = filename)
    x <- as.data.frame(data$X)
    y <- as.data.frame(data$Y)
    loc <- cbind(x,y)
    data.h <-Hpi(loc)
    x.grid.size<- (gridsize) #Set grid size as no. of nodes in the x
direction
    band.mult<- (multiplier)
    x=seq(min(loc[,1])-band.mult*sqrt(data.h[1,1]), max(loc[,1]) +
band.mult *sqrt(data.h[1,1]), length.out=x.grid.size)
    y=seq(min(loc[,2])-band.mult*sqrt(data.h[2,2]), max(loc[,2])+
band.mult*sqrt(data.h[2,2]), by=(x[2]-x[1])) #sets out nodes in y axis,
spaced the same as x axis
    eval.pts <-expand.grid(x,y)
    UD <-kde(loc,H=data.h,eval.points=eval.pts)
    output<-
data.frame(cbind(UD$eval.points[,1],UD$eval.points[,2],UD$estimate))
    colnames(output)<- c("xcoord","ycoord","UD_ht")
    cell.area <- (x[2]-x[1])*(y[2]-y[1])
    grid.vol <- sum(cell.area*output[,3]) #check that grid UD vol is >=0.99
    vol<-output[,3]/sum(output[,3]) #standardize volume to add to 1
    output<-data.frame(cbind(output,vol))
    output<-output[order(-output$vol),] #sort by descending volume
    cumV<-cumsum(output$vol) #calculate cumulative UD volume
    output<-data.frame(cbind(output,cumV)) #add cumulative vol to output
    sub.UD<-subset(output,output$cumV<=(percentage/100)) #subset output by
percent vol
    cellcount <- nrow(sub.UD)
    area <- cellcount*cell.area
    KDE <- data.frame(c(area,grid.vol))
    KDE
    }

So as an example -
kde_ks.hpi("C01 .csv", percentage=50,gridsize =150,multiplier =3) #I will
attach a stripped down version of this data file if anyone is interested in
reproducing my results.

In this case - I found a 99% home range area of 3958 meter^2 for this
individual.

My second function is largely based on code that I found from the Spatial
Ecology textbook that I referenced above. This code transforms the
bandwidth and kde from the ks package with rasters to utilize functions in
the adehabitatHR function to easily get UD volumes and areas. The
difference between my code and the one in the book is that I define the
grid using the same methods as the first function. Yet, I don't get the
same results, despite using the same grid and bandwidth as I did in the
previous function. Below is the annotated code for that function:

CRS.SC <http://crs.sc/> <- CRS("+init=epsg:32616") #define study area
projection first

kde_ade.ks.hpi <- function(filename, percentage, gridsize, multiplier){
  data <- read.csv(file = filename) #read in data
  x <- as.data.frame(data$X)
  y <- as.data.frame(data$Y)
  xy <- c(x,y)
  loc <- cbind(x,y)
  data.h <-Hpi(loc) #define bandwidth using plug-in method
  data.proj <- SpatialPointsDataFrame(xy,data, proj4string = CRS.SC
<http://crs.sc/>)
  boundingVals <- data.proj at bbox #get the bounding values of the animal
locations
  band.mult <- (multiplier) #define the value used to expand the evaluation
grid
  y.expand <- band.mult*sqrt(data.h[2,2]) #set the value used to expand the
grid by a function of the multiplier and the bandwidth
  x.expand <- band.mult*sqrt(data.h[1,1]) #note that this expansion is
different in the x and y direction
  deltaX <- as.integer(((boundingVals[1,2]) - (boundingVals[1,1])) +
(2*x.expand)) #get the total length of the grid axis
  deltaY <- as.integer(((boundingVals[2,2]) - (boundingVals[2,1])) +
(2*y.expand))
  x.grid.size <- (gridsize) #set the number of grid nodes in the X direction
  gridRes <- deltaX/x.grid.size #determine the grid resolution, (i.e the
size of one side of a cell)
  y.grid.size <- deltaY/gridRes #determine the number of nodes in the Y
direction using the same cell size as the x axis
  boundingVals[2,1] <- boundingVals[2,1] - y.expand #min Y - expand the in
each direction grid by the previously determined value
  boundingVals[2,2] <- boundingVals[2,2] + y.expand #max Y
  boundingVals[1,1] <- boundingVals[1,1] - x.expand #min X
  boundingVals[1,2] <- boundingVals[1,2] + x.expand #max X
  gridTopo <- GridTopology((boundingVals[,1]),
c(gridRes,gridRes),c(x.grid.size,y.grid.size)) #Grid Topology object is
basis for sampling grid (offset, cellsize, dim)
  sampGrid <- SpatialGrid(gridTopo, proj4string = CRS.SC
<http://crs.sc/>) #Using
the Grid Topology and projection create a SpatialGrid class
  sampSP <- as(sampGrid, "SpatialPixels") #Cast over to Spatial Pixels
  sampRaster <- raster(sampGrid) #convert the SpatialGrid class to a raster
  sampRaster[] <- 1 #set all the raster values to 1 such as to make a data
mask
  evalPoints <- xyFromCell(sampRaster, 1:ncell(sampRaster)) #Get the center
points of the mask raster with values set to 1
  hpikde <- kde(x=loc, H=data.h, eval.points=evalPoints) #Create the KDE
using the evaluation points
  hpikde.raster <- raster(sampRaster) #Create a template raster based upon
the mask and then assign the values from the kde to the template
  hpikde.raster <- setValues(hpikde.raster,hpikde$estimate)
  hpikde.px <- as(hpikde.raster,"SpatialPixelsDataFrame") #Cast over to
SPxDF
  hpikde.ud <- new("estUD", hpikde.px) #create new estUD using the SPxDF
  hpikde.ud at vol = FALSE #Assign values to a couple slots of the estUD
  hpikde.ud at h$meth = "Plug-in Bandwidth"
  hpikde.ud.vol <- getvolumeUD(hpikde.ud, standardize=TRUE) #Convert the UD
values to volume using getvolumeUD from adehabitatHR and cast over to a
raster
  hpikde.ud.vol.raster <- raster(hpikde.ud.vol)
  hpikde.vol <- getverticeshr(hpikde.ud, percent = percentage,ida = NULL,
unin = "m", unout = "m2", standardize=TRUE) #Here we generate volume
contours using the UD
  hpikde.vol$area #Determine UD area at that contour
}

So for example:
> kde_ade.ks.hpi(filename = "C01 .csv",
percentage=50,gridsize=150,multiplier=3)
[1] 3965.43

So in this case - I found a 50% kde home range area of 3965 meter^2 for
this individual. Not really that big a difference from the other value of
3958 m^2- but I would love to know where it comes from, as it the
difference between the two functions can vary based on how I define the
grid, multiplier, or percentage. At 99% the same data set produces a value
of 67182 m^2 and 67453 m^2 for the first and second methods, respectively.
In this case the second method produces a larger value both times, but when
I try this with a different animal, the first method gives me larger areas.
What is going on here, why is there a difference? Is one method better than
another? What do you all recommend for moving forward?

I am hoping to use these functions and alter them to produce shapefiles
that I can then map in GIS, once my methodology is settled.

Thank you very much for your time,

Brad Nissen

*--May the forest be with you! *

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20200205/3e26c5a6/attachment.html>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: C01 .csv
Type: application/vnd.ms-excel
Size: 2081 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20200205/3e26c5a6/attachment.xlb>

From m@tmo@er @end|ng |rom wu@@c@@t  Wed Feb  5 17:02:19 2020
From: m@tmo@er @end|ng |rom wu@@c@@t (Mathias Moser)
Date: Wed, 05 Feb 2020 17:02:19 +0100
Subject: [R-sig-Geo] Geocoding addresses restricted to one country
In-Reply-To: <CAOav87UcUi1mOBt9N7Pw4ctN7Xu1eFh7VbeMcgwJ9ab_FoDSuQ@mail.gmail.com>
References: <CAOav87UcUi1mOBt9N7Pw4ctN7Xu1eFh7VbeMcgwJ9ab_FoDSuQ@mail.gmail.com>
Message-ID: <345f6acda84ac6411449ac7e11e58d05b9450c7b.camel@wu.ac.at>

The Google API accepts two parameters which influence the selection of
matches [1]: "region" uses domains (.lr in case of Liberia) and
"bounds" uses a bounding box (long/lat coords) to prioritize certain
results. 

While geocode()/mutate_geocode() do not expose these explicitly they
can probably be added using the "inject" parameter as key-value pairs
(see help(geocode)).

Hth, Mathias

-- 
Mathias Moser

Institute for Economic Geography & GIScience
WU Vienna

[1] 
https://developers.google.com/maps/documentation/geocoding/intro#geocoding

On Wed, 2020-02-05 at 16:06 +0100, Melanie Graeser wrote:
> Dear users,
> 
> I am trying to geocode locations of firms in Liberia from a vector of
> addresses. My problem is that many addresses are not geocoded in
> Liberia, but instead all over the world. I would like to restrict the
> API geocoding response to only show results that are in Liberia. I am
> using the Google API and library(ggmap). My code is the following:
> 
> register_google(key = "myAPIkey")
> 
> test <- mutate_geocode(nec07, Address) # nec07 is my df of firms,
> Address is a vector of firm addresses
> 
> test1<-test %>% drop_na(lon) # dropping all NAs where geocoding
> returned no result to be able to create sf object to see if locations
> are correctly geocoded
> 
> test1_sf <- st_as_sf(test1, coords = c("lon", "lat"), crs = 4326)
> 
> mapview(test1_sf) # Only 2000 out of 5000 firms are geocoded in
> Liberia, the rest in other countries
> 
> I would be very grateful if you know of any options to restrict
> geocoding to return locations only in Liberia.
> 
> Many thanks in advance!
> 
> Melanie
> 
>


From th|_ve|o@o @end|ng |rom y@hoo@com@br  Thu Feb  6 03:11:37 2020
From: th|_ve|o@o @end|ng |rom y@hoo@com@br (Thiago V. dos Santos)
Date: Thu, 6 Feb 2020 02:11:37 +0000 (UTC)
Subject: [R-sig-Geo] How to find distance between grid cell and point that
 lies in specified radius?
References: <870824852.137048.1580955097570.ref@mail.yahoo.com>
Message-ID: <870824852.137048.1580955097570@mail.yahoo.com>

Hello all,

I am trying to implement a function in R to perform the Cressman scheme (which corrects the values of a gridded field, say precipitation, based on the closest observations available).

It looks like it hasn't been done yet, but please let me know if you are aware of any R package that implements the Cressman scheme.

I have a raster and a spatial points layer (which I will call "stations"). A toy example is provided below:

```
library(raster)


# create random raster
r <- raster(nrows=9, ncols=18, xmn=5153337, xmx=6570069, ymn=7462732,?
? ? ? ? ? ? ymx=8060416, crs = CRS("+proj=poly +lat_0=0 +lon_0=-54 +x_0=5000000 +y_0=10000000 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs"))
r[] <- runif(ncell(r))


# create spatial points
pts <- sampleRandom(r, 10, na.rm = TRUE, sp = TRUE)


# display everything
plot(r)
plot(pts, add=T, col="red", pch=16)
```

The starting point of my analysis would be:

1) for each grid cell in the raster, identify the station(s) that lie *within a radius of influence* (say 30 km);

2) for each station lying under the radius of influence, calculate a distance-weighted expression that will be used later to correct the raster values. Its formula is:

W = (R2 - r2)/(R2 + r2)?

where R = influence radius and r = distance between the station and the grid cell.

3) Based on the weighted correction factor W calculated above, update the value of the grid cell using the expression W * (gridpoint - station). The actual expression is a bit more sophisticated, but I want to get the general method here.

Based on some research, it looks like this could be done with sf. But since I don't have any experience with that package, would someone more familiar please point out some functions in sf or even other packages that could be helpful to solve my problem?

Thanks in advance,
?-- Thiago V. dos Santos

Postdoctoral Research Fellow
Department of Climate and Space Science and Engineering
University of Michigan


From nev||@@mo@ @end|ng |rom gm@||@com  Fri Feb  7 05:34:05 2020
From: nev||@@mo@ @end|ng |rom gm@||@com (nevil amos)
Date: Fri, 7 Feb 2020 15:34:05 +1100
Subject: [R-sig-Geo] Cannot view custom tiles made in package tiler in r
 leaflet - either locally or from github pages server.
Message-ID: <CAN9eD7nVw9eir_3E4LePSVYAq9NaMtr+FFj=mHV3Etdk=UKM2w@mail.gmail.com>

I wish to create tiled version of a large number of custom rasters for
viewing in shiny/leaflet apps ( to speed viewing of rasters)

I have produced tiles using  package tiler, these can be viewed in the
preview.html, but when uploaded to github pages  as described in the
introduction to tiler they do not show up when added as tiles in leaflet.

It is difficult to make a reproducible code here - since the tiles have to
be loaded to be served from the web.

However below I include the code used 1. to produce the tiles and 2, to
view the tiles in my github pages.

I have tried the suggestion of using {-y} in the sever path for TMS, this
makes no difference the background map is displayed but the custom tiles
are not.

Raster used from the package as an example in reality I need to serve many
10000x6000 cell geotiffs.

Example code:

library(tiler)
libary(leaflet)
# make tiles in zoom levels 1:6 these tiles have then been uploaded to
github to serve from repository:
#

tile_dir<-"us48lr"
map <- system.file("maps/map_wgs84.tif", package = "tiler")
tile(map,tile_dir , "0-6")
view_tiles(tile_dir)


#no TMS related modifications
tiles <- "https://nevilamos.github.io/TileTest/us48lr/{z}/{x}/{y}.png"
leaflet(
  options = leafletOptions(minZoom = 0, maxZoom = 7), width = "100%") %>%
  addProviderTiles("Stamen.Toner") %>%
  addTiles(urlTemplate=tiles, options = tileOptions(opacity = 0.8)) %>%
setView(-100, 40, 3)

#No tiles displayed


# {-y} and tileOptions(tms=T)
tiles <- "https://nevilamos.github.io/TileTest/us48lr/{z}/{x}/{-y}.png"
leaflet(
  options = leafletOptions(minZoom = 0, maxZoom = 7), width = "100%") %>%
  addProviderTiles("Stamen.Toner") %>%
  addTiles(urlTemplate=tiles, options = tileOptions(opacity = 0.8,tms=T))
%>% setView(-100, 40, 3)

#No tiles displayed

	[[alternative HTML version deleted]]


From btupper @end|ng |rom b|ge|ow@org  Thu Feb  6 19:36:40 2020
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Thu, 6 Feb 2020 13:36:40 -0500
Subject: [R-sig-Geo] 
 How to find distance between grid cell and point that
 lies in specified radius?
In-Reply-To: <870824852.137048.1580955097570@mail.yahoo.com>
References: <870824852.137048.1580955097570.ref@mail.yahoo.com>
 <870824852.137048.1580955097570@mail.yahoo.com>
Message-ID: <CALrbzg1keupL240U8mZdPzvXR_aEONjvdKw1pJSYKnBE0FOdig@mail.gmail.com>

Hi,

I think you'll enjoy sf once you get going with it.

I am not familiar with the Cressman scheme, but you maybe able to do
step 1 with raster (either pointDistance() or distanceFromPoints() - I
can't quite recall).  In sf you could something like this..

library(raster)
library(sf)
library(units)
library(dplyr)

crs <- "+proj=poly +lat_0=0 +lon_0=-54 +x_0=5000000 +y_0=10000000
+ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs"
r <- raster(nrows=9, ncols=18,
            xmn=5153337, xmx=6570069,
            ymn=7462732,ymx=8060416,
            crs = crs)
r[] <- runif(ncell(r))

xy <- raster::xyFromCell(r, seq_len(ncell(r)))
xy <- lapply(seq_len(nrow(xy)), function(i) sf::st_point(xy[i,]))
xy <- sf::st_sfc(xy, crs = crs)

pts <- sampleRandom(r, 10, na.rm = TRUE, sp = TRUE) %>%
  sf::st_as_sfc()

d <- sf::st_distance(xy, pts)
threshold <- units::set_units(100000, m)
d_within <- d <= threshold


d will be a [ncell x npoints] numeric matrix of distance from cell
locations to points
d_within will be a matrix [ncell x npoints] of logicals flagging which
are within your threshold (I used 100km)

Hope that helps start you off.

Cheers,
Ben



On Wed, Feb 5, 2020 at 9:12 PM Thiago V. dos Santos via R-sig-Geo
<r-sig-geo at r-project.org> wrote:
>
> Hello all,
>
> I am trying to implement a function in R to perform the Cressman scheme (which corrects the values of a gridded field, say precipitation, based on the closest observations available).
>
> It looks like it hasn't been done yet, but please let me know if you are aware of any R package that implements the Cressman scheme.
>
> I have a raster and a spatial points layer (which I will call "stations"). A toy example is provided below:
>
> ```
> library(raster)
>
>
> # create random raster
> r <- raster(nrows=9, ncols=18, xmn=5153337, xmx=6570069, ymn=7462732,
>             ymx=8060416, crs = CRS("+proj=poly +lat_0=0 +lon_0=-54 +x_0=5000000 +y_0=10000000 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs"))
> r[] <- runif(ncell(r))
>
>
> # create spatial points
> pts <- sampleRandom(r, 10, na.rm = TRUE, sp = TRUE)
>
>
> # display everything
> plot(r)
> plot(pts, add=T, col="red", pch=16)
> ```
>
> The starting point of my analysis would be:
>
> 1) for each grid cell in the raster, identify the station(s) that lie *within a radius of influence* (say 30 km);
>
> 2) for each station lying under the radius of influence, calculate a distance-weighted expression that will be used later to correct the raster values. Its formula is:
>
> W = (R2 - r2)/(R2 + r2)
>
> where R = influence radius and r = distance between the station and the grid cell.
>
> 3) Based on the weighted correction factor W calculated above, update the value of the grid cell using the expression W * (gridpoint - station). The actual expression is a bit more sophisticated, but I want to get the general method here.
>
> Based on some research, it looks like this could be done with sf. But since I don't have any experience with that package, would someone more familiar please point out some functions in sf or even other packages that could be helpful to solve my problem?
>
> Thanks in advance,
>  -- Thiago V. dos Santos
>
> Postdoctoral Research Fellow
> Department of Climate and Space Science and Engineering
> University of Michigan
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Ben Tupper
Bigelow Laboratory for Ocean Science
West Boothbay Harbor, Maine
http://www.bigelow.org/
https://eco.bigelow.org


From ju||eey@w @end|ng |rom y@hoo@c@  Mon Feb 10 19:44:31 2020
From: ju||eey@w @end|ng |rom y@hoo@c@ (Julie Lee-Yaw)
Date: Mon, 10 Feb 2020 18:44:31 +0000 (UTC)
Subject: [R-sig-Geo] reading an ESRI grid into R
References: <1251214852.879896.1581360271306.ref@mail.yahoo.com>
Message-ID: <1251214852.879896.1581360271306@mail.yahoo.com>

Hi I'm using the raster package to load a DEM from here:
http://www.cec.org/tools-and-resources/map-files/elevation-2007

The data appear to be stored as an ESRI grid (adf) and I have no experience with this format.
>From what I can tell this format is similar to a shp file with different files storing different things pertaining to the grid.
I'm using the raster command (raster package) to read the w001001.adf file:

dem<-raster("./Elevation_GRID/NA_Elevation/data/NA_Elevation/na_elevation/w001001.adf")

The produces what looks like a raster with values. Is that all I need to do or should I be reading these data another way?
Thanks
Julie


	[[alternative HTML version deleted]]


From md@umner @end|ng |rom gm@||@com  Mon Feb 10 20:48:01 2020
From: md@umner @end|ng |rom gm@||@com (Michael Sumner)
Date: Tue, 11 Feb 2020 06:48:01 +1100
Subject: [R-sig-Geo] reading an ESRI grid into R
In-Reply-To: <1251214852.879896.1581360271306@mail.yahoo.com>
References: <1251214852.879896.1581360271306.ref@mail.yahoo.com>
 <1251214852.879896.1581360271306@mail.yahoo.com>
Message-ID: <CAAcGz9_c0zMApdaB5-WRu6sBX5Ly-Qz-N1MkMMycaOSw8kGAqg@mail.gmail.com>

What you've done is perfectly fine. The raster() function invokes the GDAL
library to do the read, via the rgdal package. It doesn't read any data at
first, so dem is just a metadata shell that raster works with - if you plot
or crop or extract that triggers the actual data read as needed.

You might also try the stars package, to keep it lazy and not read all the
data at first start with the proxy argument:

dem_stars <-
stars::read_stars("./Elevation_GRID/NA_Elevation/data/NA_Elevation/na_elevation/w001001.adf",
proxy = TRUE)

This also uses GDAL but does it with code internal to the sf package. These
are pretty much analogous, but stars can do more when grids are more
general.

The GDAL details for this format are here
https://gdal.org/drivers/raster/arcinfo_grid_format.html

Cheers, Mike

On Tue, Feb 11, 2020 at 5:44 AM Julie Lee-Yaw via R-sig-Geo <
r-sig-geo at r-project.org> wrote:

> Hi I'm using the raster package to load a DEM from here:
> http://www.cec.org/tools-and-resources/map-files/elevation-2007
>
> The data appear to be stored as an ESRI grid (adf) and I have no
> experience with this format.
> From what I can tell this format is similar to a shp file with different
> files storing different things pertaining to the grid.
> I'm using the raster command (raster package) to read the w001001.adf file:
>
>
> dem<-raster("./Elevation_GRID/NA_Elevation/data/NA_Elevation/na_elevation/w001001.adf")
>
> The produces what looks like a raster with values. Is that all I need to
> do or should I be reading these data another way?
> Thanks
> Julie
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


-- 
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com

	[[alternative HTML version deleted]]


From john@ro@ @end|ng |rom gm@||@com  Thu Feb 13 14:42:04 2020
From: john@ro@ @end|ng |rom gm@||@com (Jonathan Rosenblatt)
Date: Thu, 13 Feb 2020 15:42:04 +0200
Subject: [R-sig-Geo] Fwd: Copernicus DIAS
In-Reply-To: <CAAJgi5wAfRd9rM5d9KiTYfB54w17+ZSQk16KF0B3=xWnzJ=vBA@mail.gmail.com>
References: <CAAJgi5wAfRd9rM5d9KiTYfB54w17+ZSQk16KF0B3=xWnzJ=vBA@mail.gmail.com>
Message-ID: <CAAJgi5wpEKe94756LFYNqh=VZCqcya3HZDCssLT4niEKmdqVQA@mail.gmail.com>

Dear all

I wonder: I encountered only 1 package that imports data from the MASSIVE
Copernicus database (https://github.com/antoinestevens/copernicus).
Is there any particular reason there are no "canonical" packages to import
from Copernicus? Is it because DIAS services like Wekeo and Sobloo make any
such package unnecessary? Is it because the data is too large for R to
handle without a propose server?

Thank you in advance



-- 
--
Jonathan Rosenblatt
Dept. of Industrial Engineering and Management
Ben Gurion University of the Negev
www.john-ros.com



-- 
Jonathan Rosenblatt
www.john-ros.com

	[[alternative HTML version deleted]]


From m@ur|z|o@m@rch| @end|ng |rom |bbr@cnr@|t  Tue Feb 18 15:08:05 2020
From: m@ur|z|o@m@rch| @end|ng |rom |bbr@cnr@|t (maurizio marchi)
Date: Tue, 18 Feb 2020 15:08:05 +0100
Subject: [R-sig-Geo] Strange spatial reference system netCDF [stars and sf
 functions not working now]
In-Reply-To: <mailman.27870.3.1577876402.59805.r-sig-geo@r-project.org>
References: <mailman.27870.3.1577876402.59805.r-sig-geo@r-project.org>
Message-ID: <5f8c38b6-d94b-de01-8672-3cd4d9afcfe6@ibbr.cnr.it>

Dear all,
Thanks for your time. Unfortunately the solution the community (i.e. 
Edzer Pebesma, https://github.com/r-spatial/stars/issues/175) is not 
working anymore. Does anyone knows why the code is now broken? Here the 
output of the old R code...

/f<-"tasmax_rcp85_land-rcm_eur_12km_01_mon_198012-208011.nc"//
//library(stars)//
//? Loading required package: abind//
//? Loading required package: sf//
//? Linking to GEOS 3.8.0, GDAL 3.0.2, PROJ 6.2.1//
//r<-read_ncdf(f, ncsub = cbind(start = c(1, 1, 1, 1), count = c(418, 
406, 3, 1)), eps=1e-3)//
//? no 'var' specified, using tasmax//
//? other available variables://
//? rotated_latitude_longitude, ensemble_member, time, time_bnds, 
grid_latitude, grid_latitude_bnds, grid_longitude, grid_longitude_bnds, 
ensemble_member_id, month_number, year, yyyymm//
//? Error in UseMethod("GPFN") : //
//? no applicable method for 'GPFN' applied to an object of class 
"rotated_latitude_longitude"//
//rx<-read_stars(f, proxy = TRUE) # only for the crs!//
//? Warning messages://
//? 1: In CPL_read_gdal(as.character(x), as.character(options), 
as.character(driver),? ://
//??? GDAL Message 1: The dataset has several variables that could be 
identified as vector fields, but not all share the same primary 
dimension. Consequently they will be ignored.//
//? 2: In CPL_read_gdal(as.character(x), as.character(options), 
as.character(driver),? ://
//??? GDAL Message 1: dimension #1 (time) is not a Time dimension.//
//? 3: In CPL_read_gdal(as.character(x), as.character(options), 
as.character(driver),? ://
//??? GDAL Message 1: dimension #0 (ensemble_member) is not a Time 
dimension.//
//st_crs(r)<-st_crs(rx)//
//? Warning messages://
//? 1: In CPL_crs_from_proj4string(x) ://
//??? GDAL Error 1: PROJ: proj_as_wkt: DerivedGeographicCRS can only be 
exported to WKT2//
//? 2: In CPL_crs_from_proj4string(x) ://
//??? GDAL Error 1: PROJ: proj_as_wkt: DerivedGeographicCRS can only be 
exported to WKT2//
//r0 = stars:::st_transform_proj.stars(r, 4326)//
//? Error: invalid crs: , reason: generic error of unknown origin//
//? proj_create: unrecognized format / unknown name//
//r0//
//Error: object 'r0' not found//
/
All my bests
-- 
*Maurizio Marchi,
PhD Forest Science - Ecological Mathematics*
Researcher
CNR - Institute of Biosciences and BioResources (IBBR), Florence 
division (Italy)
SkypeID: maurizioxyz
http://ibbr.cnr.it/ibbr/info/people/maurizio-marchi
#####------#####
EUFGIS National Focal Point for Italy (www.eufgis.org)
Scopus Author ID: 57188626512
ResearcherID: T-3813-2019
http://b4est.eu/ project
/...CPUs don't need to sleep.../

	[[alternative HTML version deleted]]


From Roger@B|v@nd @end|ng |rom nhh@no  Tue Feb 18 22:58:08 2020
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Tue, 18 Feb 2020 22:58:08 +0100
Subject: [R-sig-Geo] 
 Strange spatial reference system netCDF [stars and sf
 functions not working now]
In-Reply-To: <5f8c38b6-d94b-de01-8672-3cd4d9afcfe6@ibbr.cnr.it>
References: <mailman.27870.3.1577876402.59805.r-sig-geo@r-project.org>
 <5f8c38b6-d94b-de01-8672-3cd4d9afcfe6@ibbr.cnr.it>
Message-ID: <alpine.LFD.2.21.2002182255170.476782@reclus.nhh.no>

On Tue, 18 Feb 2020, maurizio marchi wrote:

> Dear all,
> Thanks for your time. Unfortunately the solution the community (i.e.
> Edzer Pebesma, https://github.com/r-spatial/stars/issues/175) is not
> working anymore. Does anyone knows why the code is now broken? Here the
> output of the old R code...
>
> /f<-"tasmax_rcp85_land-rcm_eur_12km_01_mon_198012-208011.nc"//
> //library(stars)//
> //? Loading required package: abind//
> //? Loading required package: sf//
> //? Linking to GEOS 3.8.0, GDAL 3.0.2, PROJ 6.2.1//

This seems to be the "smoking gun" - when the code last ran without error, 
which versions of GDAL and PROJ were you using? See below for the 
PROJ-related error message.

> //r<-read_ncdf(f, ncsub = cbind(start = c(1, 1, 1, 1), count = c(418,
> 406, 3, 1)), eps=1e-3)//
> //? no 'var' specified, using tasmax//
> //? other available variables://
> //? rotated_latitude_longitude, ensemble_member, time, time_bnds,
> grid_latitude, grid_latitude_bnds, grid_longitude, grid_longitude_bnds,
> ensemble_member_id, month_number, year, yyyymm//
> //? Error in UseMethod("GPFN") : //
> //? no applicable method for 'GPFN' applied to an object of class
> "rotated_latitude_longitude"//
> //rx<-read_stars(f, proxy = TRUE) # only for the crs!//
> //? Warning messages://
> //? 1: In CPL_read_gdal(as.character(x), as.character(options),
> as.character(driver),? ://
> //??? GDAL Message 1: The dataset has several variables that could be
> identified as vector fields, but not all share the same primary
> dimension. Consequently they will be ignored.//
> //? 2: In CPL_read_gdal(as.character(x), as.character(options),
> as.character(driver),? ://
> //??? GDAL Message 1: dimension #1 (time) is not a Time dimension.//
> //? 3: In CPL_read_gdal(as.character(x), as.character(options),
> as.character(driver),? ://
> //??? GDAL Message 1: dimension #0 (ensemble_member) is not a Time
> dimension.//
> //st_crs(r)<-st_crs(rx)//
> //? Warning messages://
> //? 1: In CPL_crs_from_proj4string(x) ://
> //??? GDAL Error 1: PROJ: proj_as_wkt: DerivedGeographicCRS can only be
> exported to WKT2//
> //? 2: In CPL_crs_from_proj4string(x) ://
> //??? GDAL Error 1: PROJ: proj_as_wkt: DerivedGeographicCRS can only be
> exported to WKT2//

... here ... is the use of code that will vary by GDAL and PROJ versions.

Roger


> //r0 = stars:::st_transform_proj.stars(r, 4326)//
> //? Error: invalid crs: , reason: generic error of unknown origin//
> //? proj_create: unrecognized format / unknown name//
> //r0//
> //Error: object 'r0' not found//
> /
> All my bests
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From rob00x @end|ng |rom gm@||@com  Wed Feb 19 12:25:03 2020
From: rob00x @end|ng |rom gm@||@com (Robin Lovelace)
Date: Wed, 19 Feb 2020 11:25:03 +0000
Subject: [R-sig-Geo] Spatilal Network Hackathon
Message-ID: <CAF16KkW+uSjHx0t61heJLJFdR7kGa8Pzuw4v2Tn2_75gSx+c3g@mail.gmail.com>

Dear all,

We are happy to invite you to join a hackathon on spatial networks on the*
27th of May at the University of Milan - Bicocca from 9AM to 5PM. *The
hackathon is an official satellite event of the European R Users Meeting
(ERUM) <https://2020.erum.io/> conference, that will be organized in Milan
from 27th to 30th of May. The hackathon will be focussed on developing and
testing of the new R package for spatial networks: sfnetworks.

Anyone with an interest in spatial networks and open source software is
invited, especially if you have experience with real world spatial network
data that could be used in documentation or experience developing software
for working with spatial or graph datasets (particularly R packages).

The event is free and you can get a ticket at the following link:
https://www.eventbrite.co.uk/e/erum2020-satellite-event-hackathon-on-spatial-networks-tickets-90976873277
You can read a more detailed description of the event at the following
link: https://2020.erum.io/program/hackathon/

*Summary*:

   - *What*: A hackathon on spatial networks where we will present our new
   R package and discuss with the participants the problems they face working
   with spatial networks.
   - *Who*: Everyone working on or interested in spatial networks can join
   the hackathon. The only minimal requirement is a basic knowledge of sf
   and igraph packages. We will provide a few vignettes explaining how our
   package works, so you don't need to be an expert in the field.
   - *When*: 27th of May, from 9AM to 5PM
   - *Where*: University of Milan - Bicocca, the same building of the
   ERUM2020 conference. We will specify the venue of the event as soon as
   possible. You can also find more information on how to reach the venue
   here <https://2020.erum.io/venue/>.

Best wishes, Lorena Abad, Andrea Gilardi, Robin Lovelace, Lucan van der
Meer.

	[[alternative HTML version deleted]]


From p@u|o@||ore@@m@|| @end|ng |rom gm@||@com  Wed Feb 19 15:05:42 2020
From: p@u|o@||ore@@m@|| @end|ng |rom gm@||@com (Paulo Flores Ribeiro)
Date: Wed, 19 Feb 2020 14:05:42 +0000
Subject: [R-sig-Geo] using the same legend for different scenarios in sf
 plots
Message-ID: <07fc4c88-1d88-3d8f-fef7-335f2ab5bbf5@gmail.com>

Hello,
I want to compare the spatial distribution of a variable in 7 different 
scenarios by running the same plot code successively 7 times (within sf 
package), each time changing the values of the variable for each 
scenario. In each run, I copy-paste the map into a word document. In the 
end, I want to visually compare the 7 maps, but for that I need the 
scale range of the legend values to be the same on the seven maps 
(including the colour ramp).
How to force the scale interval (and the corresponding colour ramp) to 
be the same on the seven maps, within the sf package?
Thanks,
PauloFR


	[[alternative HTML version deleted]]


From edzer@pebe@m@ @end|ng |rom un|-muen@ter@de  Wed Feb 19 15:10:12 2020
From: edzer@pebe@m@ @end|ng |rom un|-muen@ter@de (Edzer Pebesma)
Date: Wed, 19 Feb 2020 15:10:12 +0100
Subject: [R-sig-Geo] using the same legend for different scenarios in sf
 plots
In-Reply-To: <07fc4c88-1d88-3d8f-fef7-335f2ab5bbf5@gmail.com>
References: <07fc4c88-1d88-3d8f-fef7-335f2ab5bbf5@gmail.com>
Message-ID: <8e284d83-90a0-cf4e-7af9-c9cd7396be17@uni-muenster.de>

With the breaks argument you can specify the numbers at which colors break.

On 2/19/20 3:05 PM, Paulo Flores Ribeiro wrote:
> Hello,
> I want to compare the spatial distribution of a variable in 7 different 
> scenarios by running the same plot code successively 7 times (within sf 
> package), each time changing the values of the variable for each 
> scenario. In each run, I copy-paste the map into a word document. In the 
> end, I want to visually compare the 7 maps, but for that I need the 
> scale range of the legend values to be the same on the seven maps 
> (including the colour ramp).
> How to force the scale interval (and the corresponding colour ramp) to 
> be the same on the seven maps, within the sf package?
> Thanks,
> PauloFR
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48149 Muenster, Germany
Phone: +49 251 8333081

-------------- next part --------------
A non-text attachment was scrubbed...
Name: pEpkey.asc
Type: application/pgp-keys
Size: 3110 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20200219/7b2afe2a/attachment.bin>

From p@u|o@||ore@@m@|| @end|ng |rom gm@||@com  Wed Feb 19 16:05:16 2020
From: p@u|o@||ore@@m@|| @end|ng |rom gm@||@com (Paulo Flores Ribeiro)
Date: Wed, 19 Feb 2020 15:05:16 +0000
Subject: [R-sig-Geo] using the same legend for different scenarios in sf
 plots
In-Reply-To: <8e284d83-90a0-cf4e-7af9-c9cd7396be17@uni-muenster.de>
References: <07fc4c88-1d88-3d8f-fef7-335f2ab5bbf5@gmail.com>
 <8e284d83-90a0-cf4e-7af9-c9cd7396be17@uni-muenster.de>
Message-ID: <12126b46-58f5-0c3b-1038-da7a508f972b@gmail.com>

Thanks, Edzer. I used ?breaks = seq (from = 0, to = 0.4, by = 0.01)? and 
it works beautifully!
Best regards,
PauloFR

?s 14:10 de 19-02-2020, Edzer Pebesma escreveu:
> With the breaks argument you can specify the numbers at which colors break.
>
> On 2/19/20 3:05 PM, Paulo Flores Ribeiro wrote:
>> Hello,
>> I want to compare the spatial distribution of a variable in 7 different
>> scenarios by running the same plot code successively 7 times (within sf
>> package), each time changing the values of the variable for each
>> scenario. In each run, I copy-paste the map into a word document. In the
>> end, I want to visually compare the 7 maps, but for that I need the
>> scale range of the legend values to be the same on the seven maps
>> (including the colour ramp).
>> How to force the scale interval (and the corresponding colour ramp) to
>> be the same on the seven maps, within the sf package?
>> Thanks,
>> PauloFR
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From m@ur|z|o@m@rch| @end|ng |rom |bbr@cnr@|t  Wed Feb 19 18:02:58 2020
From: m@ur|z|o@m@rch| @end|ng |rom |bbr@cnr@|t (Maurizio Marchi)
Date: Wed, 19 Feb 2020 18:02:58 +0100
Subject: [R-sig-Geo] 
 Strange spatial reference system netCDF [stars and sf
 functions not working now]
Message-ID: <F7F6CB2B-4CB7-424B-974D-149A944451A8@ibbr.cnr.it>

I?m sorry for being the smoking gun but looking at the issue climatological data seems to be difficult to be handled in R...
Yes the issue is connected to the GDAL version. I can?t remember exactly but I?m sure it wasn?t the versions I have now and posted before...
I did a trick using proj4 package and some handmade stuff but not really GIS ;) However my code was not working on other systems so I?m far away from a real solution...
But the main question is Why RCM are delivered in this awful CRS!? 
All my bests 

-- 
Maurizio Marchi,
PhD Forest Science - Ecological Mathematics 
Researcher
CNR - Institute of Biosciences and BioResources (IBBR), Florence division (Italy)
SkypeID: maurizioxyz
http://www.ibbr.cnr.it/ibbr/info/people/maurizio-marchi
#####------#####
Annals of Silvicultural Research Associated Editor
EUFGIS National Focal Point for Italy (www.eufgis.org)
Scopus Author ID: 57188626512
ResearcherID: T-3813-2019
http://b4est.eu/ project
	[[alternative HTML version deleted]]


From |@cundo@munoz @end|ng |rom c|r@d@|r  Thu Feb 20 14:27:28 2020
From: |@cundo@munoz @end|ng |rom c|r@d@|r (=?UTF-8?Q?Facundo_Mu=c3=b1oz?=)
Date: Thu, 20 Feb 2020 14:27:28 +0100
Subject: [R-sig-Geo] using the same legend for different scenarios in sf
 plots
In-Reply-To: <12126b46-58f5-0c3b-1038-da7a508f972b@gmail.com>
References: <07fc4c88-1d88-3d8f-fef7-335f2ab5bbf5@gmail.com>
 <8e284d83-90a0-cf4e-7af9-c9cd7396be17@uni-muenster.de>
 <12126b46-58f5-0c3b-1038-da7a508f972b@gmail.com>
Message-ID: <87471e47-39ed-a3f3-d472-24201997532d@cirad.fr>

In addition to Edzer's answer, I'd suggest considering producing a
single faceted plot with the 7 maps with a common legend, which might be
a more straightforward way to present a comparison of scenarios.

See, for instance, an example at
https://umr-astre.pages.mia.inra.fr/presentations/2019_rfsa_lsd/#21

?acu.-


On 19/02/2020 16:05, Paulo Flores Ribeiro wrote:
> Thanks, Edzer. I used ?breaks = seq (from = 0, to = 0.4, by = 0.01)? and 
> it works beautifully!
> Best regards,
> PauloFR
>
> ?s 14:10 de 19-02-2020, Edzer Pebesma escreveu:
>> With the breaks argument you can specify the numbers at which colors break.
>>
>> On 2/19/20 3:05 PM, Paulo Flores Ribeiro wrote:
>>> Hello,
>>> I want to compare the spatial distribution of a variable in 7 different
>>> scenarios by running the same plot code successively 7 times (within sf
>>> package), each time changing the values of the variable for each
>>> scenario. In each run, I copy-paste the map into a word document. In the
>>> end, I want to visually compare the 7 maps, but for that I need the
>>> scale range of the legend values to be the same on the seven maps
>>> (including the colour ramp).
>>> How to force the scale interval (and the corresponding colour ramp) to
>>> be the same on the seven maps, within the sf package?
>>> Thanks,
>>> PauloFR
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From p@u|o@||ore@@m@|| @end|ng |rom gm@||@com  Thu Feb 20 17:10:14 2020
From: p@u|o@||ore@@m@|| @end|ng |rom gm@||@com (Paulo Flores Ribeiro)
Date: Thu, 20 Feb 2020 16:10:14 +0000
Subject: [R-sig-Geo] using the same legend for different scenarios in sf
 plots
In-Reply-To: <87471e47-39ed-a3f3-d472-24201997532d@cirad.fr>
References: <07fc4c88-1d88-3d8f-fef7-335f2ab5bbf5@gmail.com>
 <8e284d83-90a0-cf4e-7af9-c9cd7396be17@uni-muenster.de>
 <12126b46-58f5-0c3b-1038-da7a508f972b@gmail.com>
 <87471e47-39ed-a3f3-d472-24201997532d@cirad.fr>
Message-ID: <84fd73f4-ad31-37af-55b9-768847171509@gmail.com>

Thank you, Facundo. Nice graphs, by the way.
Cheers,
PauloFR

?s 13:27 de 20-02-2020, Facundo Mu?oz escreveu:
> In addition to Edzer's answer, I'd suggest considering producing a
> single faceted plot with the 7 maps with a common legend, which might be
> a more straightforward way to present a comparison of scenarios.
>
> See, for instance, an example at
> https://umr-astre.pages.mia.inra.fr/presentations/2019_rfsa_lsd/#21
>
> ?acu.-
>
>
> On 19/02/2020 16:05, Paulo Flores Ribeiro wrote:
>> Thanks, Edzer. I used ?breaks = seq (from = 0, to = 0.4, by = 0.01)? and
>> it works beautifully!
>> Best regards,
>> PauloFR
>>
>> ?s 14:10 de 19-02-2020, Edzer Pebesma escreveu:
>>> With the breaks argument you can specify the numbers at which colors break.
>>>
>>> On 2/19/20 3:05 PM, Paulo Flores Ribeiro wrote:
>>>> Hello,
>>>> I want to compare the spatial distribution of a variable in 7 different
>>>> scenarios by running the same plot code successively 7 times (within sf
>>>> package), each time changing the values of the variable for each
>>>> scenario. In each run, I copy-paste the map into a word document. In the
>>>> end, I want to visually compare the 7 maps, but for that I need the
>>>> scale range of the legend values to be the same on the seven maps
>>>> (including the colour ramp).
>>>> How to force the scale interval (and the corresponding colour ramp) to
>>>> be the same on the seven maps, within the sf package?
>>>> Thanks,
>>>> PauloFR
>>>>
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From @|ex@ndre@@nto@br @end|ng |rom y@hoo@com@br  Fri Feb 21 00:20:21 2020
From: @|ex@ndre@@nto@br @end|ng |rom y@hoo@com@br (ASANTOS)
Date: Thu, 20 Feb 2020 19:20:21 -0400
Subject: [R-sig-Geo] Circular/square sample function for extract coordinates
 and marks in *ppp object
References: <fe5dc077-9884-93ba-c1b2-bc37f175b296.ref@yahoo.com.br>
Message-ID: <fe5dc077-9884-93ba-c1b2-bc37f175b296@yahoo.com.br>

Dear r-sig-geo members,

I've to know if there is a function for sample for extract coordinates 
and marks of a marked planar point pattern object? In my example:

library(spatstat)

## Using a longleaf data set
longleaf
#Marked planar point pattern: 584 points
#marks are numeric, of storage type??? ???double???
#window: rectangle = [0, 200] x [0, 200] metres

There is the spsample(x, n, "random") for example, but this function 
sample random points inside longleaf$window area and doesn't work for marks.

I've like a function that extract longleaf points coordinates and marks 
inside a circular area (eg. 1 metres) or square area (eg. 1 metes h x w) 
around n random sample points and a data frame or better a new marked 
planar point patter object as output.

Is there this type of function implemented in R?

Thanks in advanced,

Alexandre

-- 
Alexandre dos Santos
Geotechnologies and Spatial Statistics applied to Forest Entomology
Instituto Federal de Mato Grosso (IFMT) - Campus Caceres
Caixa Postal 244 (PO Box)
Avenida dos Ramires, s/n - Distrito Industrial
Caceres - MT - CEP 78.200-000 (ZIP code)
Phone: (+55) 65 99686-6970 / (+55) 65 3221-2674
Lattes CV: http://lattes.cnpq.br/1360403201088680
OrcID: orcid.org/0000-0001-8232-6722
ResearchGate: www.researchgate.net/profile/Alexandre_Santos10
Publons: https://publons.com/researcher/3085587/alexandre-dos-santos/
--


From cm@ch|ng@|dze @end|ng |rom gm@||@com  Tue Feb 25 15:34:03 2020
From: cm@ch|ng@|dze @end|ng |rom gm@||@com (Chiedza Machingaidze)
Date: Wed, 26 Feb 2020 01:34:03 +1100
Subject: [R-sig-Geo] Error using predict.sarlm
Message-ID: <CABgUnxBHqbqbuKW35P_M=OKrQGNFFmE8Gn-Vt5RS+PYNF4akBg@mail.gmail.com>

I am running the following code:
Error in predict.sarlm(m1s, newdata = " geodata ", listw = shpw )

and getting the following error:
Error in predict.sarlm(m1s, newdata = "geodata", listw = shpw,  :
  newdata should have region.id as row.names

I did a search and found a post about the same problem:
http://r-sig-geo.2731867.n2.nabble.com/Error-while-using-predict-sarlm-td7592817.html


So, per the post, I have ensured that region.id matches row names:
> str(attr( geodatanb , "region.id"))
 chr [1:74] "1" "2" "3" "4" "5" "6" "7" "8" "9" "10" "11" "12" "13" "14"
"15" "16" "17" "18" "19" "20" "21" "22" "23" "24" "25" "26" "27" "28" "29"
"30" "31" "32" "33" ...
> str(row.names(generalrateforpred))
 chr [1:74] "1" "2" "3" "4" "5" "6" "7" "8" "9" "10" "11" "12" "13" "14"
"15" "16" "17" "18" "19" "20" "21" "22" "23" "24" "25" "26" "27" "28" "29"
"30" "31" "32" "33" ...
all(row.names(geodata at data) %in% attr( geodatanb, "region.id"))
[1] TRUE

Unfortunately, I'm still getting the error.

Could anyone offer any further assistance?

Thank you,
Chi

	[[alternative HTML version deleted]]


From b@row||ng@on @end|ng |rom gm@||@com  Tue Feb 25 16:39:08 2020
From: b@row||ng@on @end|ng |rom gm@||@com (Barry Rowlingson)
Date: Tue, 25 Feb 2020 15:39:08 +0000
Subject: [R-sig-Geo] Peter Diggle Birthday Conference
Message-ID: <CANVKczO8OMg0XQFjHZYsykzrRcnZXaTpF6OHDAsCmZt0ZMft+Q@mail.gmail.com>

Hope nobody thinks I'm spamming the list but I'd like to promote the
conference that we are holding in April in honour of Prof Diggle's 70th
birthday (actually yesterday).

I've worked with him for nearly 30 years, and I wrote the first version of
`splancs` for `S` by interfacing to his Fortran code. Some of this code is
still in the R version of splancs today.

We've got a lot of spatial statistics talks, a smattering of longitudinal
data, and a couple of parties scheduled. Our invited speakers include the
current president of the Royal Statistical Society.

Talk titles (click for full abstracts) are here:
  http://www.developingstatistics.org/programme/talks/

Registration details are here:
 http://www.developingstatistics.org/registration/

Hope to see some of you there in April!

Barry

	[[alternative HTML version deleted]]


From Roger@B|v@nd @end|ng |rom nhh@no  Tue Feb 25 19:18:35 2020
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Tue, 25 Feb 2020 19:18:35 +0100
Subject: [R-sig-Geo] Error using predict.sarlm
In-Reply-To: <CABgUnxBHqbqbuKW35P_M=OKrQGNFFmE8Gn-Vt5RS+PYNF4akBg@mail.gmail.com>
References: <CABgUnxBHqbqbuKW35P_M=OKrQGNFFmE8Gn-Vt5RS+PYNF4akBg@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.2002251914050.2005451@reclus.nhh.no>

On Tue, 25 Feb 2020, Chiedza Machingaidze wrote:

> I am running the following code:
> Error in predict.sarlm(m1s, newdata = " geodata ", listw = shpw )
>
> and getting the following error:
> Error in predict.sarlm(m1s, newdata = "geodata", listw = shpw,  :
>  newdata should have region.id as row.names

Please try to provide a reproducible example, such as:

data(oldcol, package="spdep")
lw <- spdep::nb2listw(COL.nb)
COL.mix.eig <- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD, lw, Dubin=TRUE)
predict(COL.mix.eig, newdata="COL.OLD", listw=lw)
#Error in predict.sarlm(COL.mix.eig, newdata = "COL.OLD", listw = lw) :
#  newdata should have region.id as row.names

If this corresponds to your case, why is the newdata= object in quotation 
marks?

Please try to post plain text only, HTML makes it harder to read code.

Hope this clarifies,

Roger

>
> I did a search and found a post about the same problem:
> http://r-sig-geo.2731867.n2.nabble.com/Error-while-using-predict-sarlm-td7592817.html
>
>
> So, per the post, I have ensured that region.id matches row names:
>> str(attr( geodatanb , "region.id"))
> chr [1:74] "1" "2" "3" "4" "5" "6" "7" "8" "9" "10" "11" "12" "13" "14"
> "15" "16" "17" "18" "19" "20" "21" "22" "23" "24" "25" "26" "27" "28" "29"
> "30" "31" "32" "33" ...
>> str(row.names(generalrateforpred))
> chr [1:74] "1" "2" "3" "4" "5" "6" "7" "8" "9" "10" "11" "12" "13" "14"
> "15" "16" "17" "18" "19" "20" "21" "22" "23" "24" "25" "26" "27" "28" "29"
> "30" "31" "32" "33" ...
> all(row.names(geodata at data) %in% attr( geodatanb, "region.id"))
> [1] TRUE
>
> Unfortunately, I'm still getting the error.
>
> Could anyone offer any further assistance?
>
> Thank you,
> Chi
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


