From tkobayas at indiana.edu  Wed Jan  2 05:07:19 2008
From: tkobayas at indiana.edu (Takatsugu Kobayashi)
Date: Tue, 01 Jan 2008 23:07:19 -0500
Subject: [R-sig-Geo] adding new values to readShapePoly() object
Message-ID: <1199246839.16172.20.camel@SuseLinux.gateway.2wire.net>

Hi

Please forgive me if I am asking a simple question. 

I would like to add values in a column vector to readShapePoly() object
and show a map based on these values using spplot() or addPoly().

Basically, my raw data are employment census data with the coordinates
(X,Y). 

tmp1 <- read.csv("tmp1.csv",header=T)

names(tmp1)
 [1] "TAZ"                "X"                  "Y"                 
 [4] "X_UTM"              "Y_UTM"              "Perimeter"         
 [7] "Area"               "in.n"               "D_mean.dist"       
[10] "D_median.dist"      "D_mean.mean.time"   "D_mean.median.time"
[13] "out.n"              "O_mean.dist"        "O_median.dist"     
[16] "O_mean.mean.time"   "O_mean.median.time" 


map <- readShapePoly("Akron",proj4string=CRS("+proj=longlat
+datum=NAD27"))
names(map)


 [1] "SOURCELYR" "SHAPECODE" "COUNTY"    "SHORTLAB"  "LONGLAB"
"X"        
 [7] "Y"         "X_UTM"     "Y_UTM"     "Perimeter" "Area"     

tmp1/tmp2 and map have the same nrows and the same coordinates (X,Y). 

Any suggestions? Should I modify .dbf files before loading .shp files?
Or are there functions like join_table in ArcGIS? Or should I convert
tmp1 into a polypoint object and overlay it on map?

Thank you very much.

Takatsugu



From Roger.Bivand at nhh.no  Wed Jan  2 21:44:27 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 2 Jan 2008 21:44:27 +0100 (CET)
Subject: [R-sig-Geo] adding new values to readShapePoly() object
In-Reply-To: <1199246839.16172.20.camel@SuseLinux.gateway.2wire.net>
References: <1199246839.16172.20.camel@SuseLinux.gateway.2wire.net>
Message-ID: <Pine.LNX.4.64.0801022138290.13418@reclus.nhh.no>

On Tue, 1 Jan 2008, Takatsugu Kobayashi wrote:

> Hi
>
> Please forgive me if I am asking a simple question.
>
> I would like to add values in a column vector to readShapePoly() object
> and show a map based on these values using spplot() or addPoly().
>
> Basically, my raw data are employment census data with the coordinates
> (X,Y).
>
> tmp1 <- read.csv("tmp1.csv",header=T)
>
> names(tmp1)
> [1] "TAZ"                "X"                  "Y"
> [4] "X_UTM"              "Y_UTM"              "Perimeter"
> [7] "Area"               "in.n"               "D_mean.dist"
> [10] "D_median.dist"      "D_mean.mean.time"   "D_mean.median.time"
> [13] "out.n"              "O_mean.dist"        "O_median.dist"
> [16] "O_mean.mean.time"   "O_mean.median.time"
>
>
> map <- readShapePoly("Akron",proj4string=CRS("+proj=longlat
> +datum=NAD27"))
> names(map)
>
>
> [1] "SOURCELYR" "SHAPECODE" "COUNTY"    "SHORTLAB"  "LONGLAB"
> "X"
> [7] "Y"         "X_UTM"     "Y_UTM"     "Perimeter" "Area"
>
> tmp1/tmp2 and map have the same nrows and the same coordinates (X,Y).
>
> Any suggestions? Should I modify .dbf files before loading .shp files?

Look at ?"spCbind-methods", these methods are in the maptools package. The 
key thing is to make sure that the row names of tmp1 and tmp1 match those 
of slot(map, "data"), which is also a data frame. They will be re-ordered 
if need be, but must agree. You will see that match() is used in the 
example on the help page. In the example, the IDvar= argument is used in 
readShapePoly(), but you can also use spChFIDs-methods for changing the 
IDs.

Roger


> Or are there functions like join_table in ArcGIS? Or should I convert
> tmp1 into a polypoint object and overlay it on map?
>
> Thank you very much.
>
> Takatsugu
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From jgalkows at akamai.com  Thu Jan  3 00:34:49 2008
From: jgalkows at akamai.com (Galkowski, Jan)
Date: Wed, 2 Jan 2008 18:34:49 -0500
Subject: [R-sig-Geo] snippet of code for Voronoi edge presentation
Message-ID: <76EB4827B2104D40AE7E43AA5D8582EA52DAD8@MAVS1.kendall.corp.akamai.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080102/aae09a75/attachment.pl>

From Roger.Bivand at nhh.no  Thu Jan  3 12:56:06 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 3 Jan 2008 12:56:06 +0100 (CET)
Subject: [R-sig-Geo] spdep 0-4.13
Message-ID: <Pine.LNX.4.64.0801031244510.18473@reclus.nhh.no>

A new release of spdep has been published on CRAN and will spread to a 
mirror near you soon. It includes faster sparse matrix computation in 
maximum likelihood model fitting, and code for exact global and local 
Moran's I tests contributed by Markus Reder.

Please note two issues: spdep now depends on the spam package (another 
sparse matrix implementation), so that just updating spdep will not be 
enough, and spam needs to be installed too, unless you already have it 
(users of the fields package will probably have it if you update 
regularly).

The second issue is that the ade4 package is currently unable to load 
spdep in functions that need this dependence, because of spdep's new 
dependence on spam. We are working on this, and a suggested fix for spam 
has been sent to its maintainer. So ade4 users who do not need extra spdep 
functionality may choose not to update spdep until this issue has been 
resolved.

Please let me know of any difficulties,

Happy New Year!

Roger

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From jgalkows at akamai.com  Fri Jan  4 01:43:30 2008
From: jgalkows at akamai.com (Galkowski, Jan)
Date: Thu, 3 Jan 2008 19:43:30 -0500
Subject: [R-sig-Geo] snippet of code for Voronoi edge presentation
Message-ID: <76EB4827B2104D40AE7E43AA5D8582EA52E2B6@MAVS1.kendall.corp.akamai.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080103/04b522d6/attachment.pl>

From epost.ksyge at markus-kindler.de  Sat Jan  5 19:46:18 2008
From: epost.ksyge at markus-kindler.de (Monika)
Date: Sat, 05 Jan 2008 20:46:18 +0200
Subject: Antwort auf deine Anzeige bei Kijiji mit dem Titel "Geile 3 Loch Stute für TG"
Message-ID: <26B9FC0E.4CACFECD@markus-kindler.de>

---
Message-ID: jykp - YNUP - 2776
---
Servus!

Habe mich ?ber deine Antwort auf meine Kontaktanzeige sehr gefreut.
Wie schon in meinem Anzeigentext geschrieben, erwarte ich nur ein kleines
Taschengeld bei einem heissen Sexdate.

Wenn Du tats?chlich noch Interesse an einem geiles Sexdate mit mir hast,
hinterlasse mir eine Nachricht mit deinem TG Angebot bei:
http://www.hobbyhurenkontakte.tk/

Mein Benutzername dort ist: Monika-fuer-TG

Bitte vergesse auch nicht deine Telefonnummer mit anzugeben. Ich werde dich
dann anrufen zwecks Vereinbarung eines Treffens. In Ordnung?


Also, ich warte auf eine Nachricht in meiner Mailbox bei
http://www.hobbyhurenkontakte.tk/



Ganz liebe Gr??e

Monika



From stefan.duke at gmail.com  Sat Jan  5 22:38:19 2008
From: stefan.duke at gmail.com (stefan lhachimi)
Date: Sat, 5 Jan 2008 22:38:19 +0100
Subject: [R-sig-Geo] delete region from shapefile / map only certain regions
Message-ID: <a211af3b0801051338x33dc65e3y26be5269070f20ea@mail.gmail.com>

Hello,
I have two qeustions about shape files:

First, I have a shp.file for all counties in Germany. Funnily enough,
two counties are just lakes for which
    I do not have covariates. Is there a possibilty delete them, so
they don't show on the map and do not affect my analysis.


Second, is it possible just to plot parts of the map, given some
condition (say, part of a state or a larger region)?

I hope these question are not too trivial, but I couldn't find
anything adequate in the mailing list.
Happy new Year,
Stefan



From rhurlin at gwdg.de  Sun Jan  6 11:35:54 2008
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Sun, 06 Jan 2008 11:35:54 +0100
Subject: [R-sig-Geo] delete region from shapefile / map only certain
	regions
In-Reply-To: <a211af3b0801051338x33dc65e3y26be5269070f20ea@mail.gmail.com>
References: <a211af3b0801051338x33dc65e3y26be5269070f20ea@mail.gmail.com>
Message-ID: <4780AF0A.1060103@gwdg.de>

Hello Stefan,

answering only to your first question.

On 05.01.2008 22:38 (UTC+1), stefan lhachimi wrote:
> Hello,
> I have two qeustions about shape files:
> 
> First, I have a shp.file for all counties in Germany. Funnily enough,
> two counties are just lakes for which
>     I do not have covariates. Is there a possibilty delete them, so
> they don't show on the map and do not affect my analysis.

I am not sure what you mean with 'lakes'. Is it possible, that this 
polygons describe the mini counties (~ cities with municipal laws like 
counties) 'Hamburg' and 'Bremen' both in the northern part of Germany? 
If so, I would suggest to not delete them.

Hope this helps,
Rainer


> Second, is it possible just to plot parts of the map, given some
> condition (say, part of a state or a larger region)?
> 
> I hope these question are not too trivial, but I couldn't find
> anything adequate in the mailing list.
> Happy new Year,
> Stefan



From stefan.duke at gmail.com  Sun Jan  6 12:15:04 2008
From: stefan.duke at gmail.com (stefan lhachimi)
Date: Sun, 6 Jan 2008 12:15:04 +0100
Subject: [R-sig-Geo] delete region from shapefile / map only certain
	regions
In-Reply-To: <4780AF0A.1060103@gwdg.de>
References: <a211af3b0801051338x33dc65e3y26be5269070f20ea@mail.gmail.com>
	<4780AF0A.1060103@gwdg.de>
Message-ID: <a211af3b0801060315t58d5628vd024a5dacb36076@mail.gmail.com>

Thanks for your email. But according to official Germany kartography
standards (that is where I have the files from). The Bodensee is split
into to separate counties (and really just he Bodensee, not the part
of the Bodensee and part of a neighbouring landmass). For the
statistical analyis I have in mind (mortality), these observations do
not make sense and distort the analysis.
Best,
Stefan


On Jan 6, 2008 11:35 AM, Rainer Hurling <rhurlin at gwdg.de> wrote:
> Hello Stefan,
>
> answering only to your first question.
>
> On 05.01.2008 22:38 (UTC+1), stefan lhachimi wrote:
> > Hello,
> > I have two qeustions about shape files:
> >
> > First, I have a shp.file for all counties in Germany. Funnily enough,
> > two counties are just lakes for which
> >     I do not have covariates. Is there a possibilty delete them, so
> > they don't show on the map and do not affect my analysis.
>
> I am not sure what you mean with 'lakes'. Is it possible, that this
> polygons describe the mini counties (~ cities with municipal laws like
> counties) 'Hamburg' and 'Bremen' both in the northern part of Germany?
> If so, I would suggest to not delete them.
>
> Hope this helps,
> Rainer
>
>
>
> > Second, is it possible just to plot parts of the map, given some
> > condition (say, part of a state or a larger region)?
> >
> > I hope these question are not too trivial, but I couldn't find
> > anything adequate in the mailing list.
> > Happy new Year,
> > Stefan
>



From Roger.Bivand at nhh.no  Sun Jan  6 20:15:28 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 6 Jan 2008 20:15:28 +0100 (CET)
Subject: [R-sig-Geo] delete region from shapefile / map only certain
 regions
In-Reply-To: <a211af3b0801051338x33dc65e3y26be5269070f20ea@mail.gmail.com>
References: <a211af3b0801051338x33dc65e3y26be5269070f20ea@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0801062009540.7522@reclus.nhh.no>

On Sat, 5 Jan 2008, stefan lhachimi wrote:

> Hello,
> I have two qeustions about shape files:
>
> First, I have a shp.file for all counties in Germany. Funnily enough,
> two counties are just lakes for which
>    I do not have covariates. Is there a possibilty delete them, so
> they don't show on the map and do not affect my analysis.

If you use readShapePoly() in maptools, they will be read into a 
SpatialPolygonsDataFrame object. You subset it using "[" as other data 
frame objects - see the examples in ?readShapePoly, and more class 
documentation in the sp package. Create a logical vector to do the 
subsetting.

>
>
> Second, is it possible just to plot parts of the map, given some
> condition (say, part of a state or a larger region)?
>

Either subset in the same way (counties in a land, for example), or use 
the xlim= and ylim= arguments to the plot() or spplot() methods for the 
class, depending on what you need. For plot(), you need to set the class 
intervals for colour filling yourself, for spplot() you can set up a 
legend and class intervals automatically.

Hope this helps,

Roger

> I hope these question are not too trivial, but I couldn't find
> anything adequate in the mailing list.
> Happy new Year,
> Stefan
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Mon Jan  7 15:44:07 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 7 Jan 2008 15:44:07 +0100 (CET)
Subject: [R-sig-Geo] spdep 0-4.13
In-Reply-To: <Pine.LNX.4.64.0801031244510.18473@reclus.nhh.no>
References: <Pine.LNX.4.64.0801031244510.18473@reclus.nhh.no>
Message-ID: <Pine.LNX.4.64.0801071541420.12731@reclus.nhh.no>

On Thu, 3 Jan 2008, Roger Bivand wrote:

> A new release of spdep has been published on CRAN and will spread to a
> mirror near you soon. It includes faster sparse matrix computation in
> maximum likelihood model fitting, and code for exact global and local
> Moran's I tests contributed by Markus Reder.
>
> Please note two issues: spdep now depends on the spam package (another
> sparse matrix implementation), so that just updating spdep will not be
> enough, and spam needs to be installed too, unless you already have it
> (users of the fields package will probably have it if you update
> regularly).
>
> The second issue is that the ade4 package is currently unable to load
> spdep in functions that need this dependence, because of spdep's new
> dependence on spam. We are working on this, and a suggested fix for spam
> has been sent to its maintainer. So ade4 users who do not need extra spdep
> functionality may choose not to update spdep until this issue has been
> resolved.

The rapid release of spam_0.13-2 by Reinhard Furrer (many thanks!) has 
resolved the ade4 problem, so updating to the latest spdep is now OK also 
for ade4 users.

Roger

>
> Please let me know of any difficulties,
>
> Happy New Year!
>
> Roger
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From pjeodxo at boaaaa.com  Mon Jan  7 02:11:23 2008
From: pjeodxo at boaaaa.com (Julio Steele)
Date: Mon, 6 Jan 2008 21:11:23 -0400
Subject: [R-sig-Geo] Steele
Message-ID: <01c850a8$b0bd8f80$02095bc8@pjeodxo>

Look at our US FDA approved prescription drugs through our fully licensed
pharmacy. orders are overviewed by licensed accredited medication department.

http://tetavq.blu.livefilestore.com/y1ptoaIg7He5wPJJDDo5cH6fvDYIXeygm-YRolKlyXVawPX3exiJcd8krrMkQ_GYUiY-GjFmQ6vx3TcZD8y5tGH2YHG_Ngkxh6M/xpqimle.html

to have looked at your words, in real world  says the report,  discretion in relation  his stunningly clever use of Command, about creating "super children" contribute to



From buddha_314 at yahoo.com  Tue Jan  8 17:59:18 2008
From: buddha_314 at yahoo.com (Brian Dolan)
Date: Tue, 8 Jan 2008 08:59:18 -0800 (PST)
Subject: [R-sig-Geo] PostGIS, R and WKT
Message-ID: <530556.31845.qm@web36411.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080108/720d56b7/attachment.pl>

From e.pebesma at gmail.com  Tue Jan  8 18:17:50 2008
From: e.pebesma at gmail.com (Edzer Pebesma)
Date: Tue, 08 Jan 2008 18:17:50 +0100
Subject: [R-sig-Geo] PostGIS, R and WKT
In-Reply-To: <530556.31845.qm@web36411.mail.mud.yahoo.com>
References: <530556.31845.qm@web36411.mail.mud.yahoo.com>
Message-ID: <4783B03E.30705@uni-muenster.de>

Brian You should try to use the readOGR function in package rgdal, which 
has a PostGIS driver. Examples are on 
http://wiki.intamap.org/index.php/PostGIS

Best wishes,
--
Edzer

Brian Dolan schrieb:
> Hello,
>
> I'm sure this is a well-understood problem.  I appreciate your patience.
>
> I am attempting to use R as a visualization tool, pulling the data from my postgresql/postgis system.  I have followed the examples from this page:
>
> http://www.bostongis.com/?content_name=postgis_tut01#20
>
> All the software is working correctly, including RODBC so that I may issue queries to my database from within R.  My question is, what is a good method for plotting the results of a sql query?  For instance, "select * from towns" returns a column called the_geom, which is, I understand in Well Known Binary.  If simply wish to plot the borders of the towns in R, I suppose I have to convert this to a spatial polygon.  But honestly, I can't seem to figure this out.  Nor can I find references on line that take WKB or WKT and plot this coordinates in R.
>
> So, I'm sure there is something fundamental that I am missing.  I look forward to learning from your suggestions!
>
> -brian 
> buddha_314 at yahoo.com
>
>
>
>  
> ~~~ 
> may all your sequences converge
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From tkobayas at indiana.edu  Thu Jan 10 03:39:21 2008
From: tkobayas at indiana.edu (Takatsugu Kobayashi)
Date: Wed, 09 Jan 2008 21:39:21 -0500
Subject: [R-sig-Geo] GDA: set up
Message-ID: <47858559.7000501@indiana.edu>

Hi,

I am trying to install rgdal package on my local directory in my school 
server. I uploaded gdal-1.5.0, built and compiled it on my local directory.

After ./configure I got:
GDAL is now configured for x86_64-unknown-linux-gnu

  Installation directory:    /usr/local
  C compiler:                gcc -g -O2
  C++ compiler:              g++ -g -O2

  LIBTOOL support:           yes

  LIBZ support:              external
  GRASS support:             no
  CFITSIO support:           no
  PCRaster support:          internal
  NETCDF support:            no
  LIBPNG support:            internal
  LIBTIFF support:           internal (BigTIFF=yes)
  LIBGEOTIFF support:        internal
  LIBJPEG support:           internal
  LIBGIF support:            internal
  OGDI support:              no
  HDF4 support:              no
  HDF5 support:              no
  KAKADU support:            no
  JASPER support:            no
  ECW support:               no
  MrSID support:             no
  GRIB support:              no
  CURL support (wms/wcs/...):no
  POSTGRESQL support:        no
  MySQL support:             no
  XERCES support:            no
  Expat support:             yes
  ODBC support:              no
  PGEO support:              no
  OCI support:               no
  SDE support:               no
  DODS support:              no
  SQLite support:            no
  DWGdirect support          no
  PANORAMA GIS support:      no
  INFORMIX DataBlade support:no
  GEOS support:              no


  Old-gen python          no
  SWIG Bindings:          no

  Statically link PROJ.4:    no
  enable OGR building:       yes
  enable pthread support:    no
  hide internal symbols:     no

Then I moved on to do make and make install, and then launched R on the 
same local directory and ran install.packages('rgdal'). I couldn't 
install rgdal because gdal-config wasn't found. The error message showed:

--configure-args='--with-gdal-config=/usr/local/bin/gdal-config' echo 
with appropriate values for your installation.

So I am guessing change '/usr/local/bin/gdal-config/ to 
'/usr/local/gdal-1.5.0/bin/gdal-config'.

I appreciate if someone knows how to set up gdal on unix.

Thanks.

Takar



From Roger.Bivand at nhh.no  Thu Jan 10 08:33:49 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 10 Jan 2008 08:33:49 +0100 (CET)
Subject: [R-sig-Geo] GDA: set up
In-Reply-To: <47858559.7000501@indiana.edu>
References: <47858559.7000501@indiana.edu>
Message-ID: <Pine.LNX.4.64.0801100828010.28769@reclus.nhh.no>

On Wed, 9 Jan 2008, Takatsugu Kobayashi wrote:

> Hi,
>
> I am trying to install rgdal package on my local directory in my school
> server. I uploaded gdal-1.5.0, built and compiled it on my local directory.

This is not clear. Please 1) say what the ./configure you entered was 
exactly, then 2) try to run gdal-config after make, make install, and 3) 
try to run gdalinfo --version.

My guess is that the problem is "my local directory", plus finding the 
GDAL shared object. You can compile GDAL where you like, in principle, but 
are you both compiling and running on the server? Once GDAL works and 
gdal-config can be found (and the gdal shared object(s) are in the 
ld.so list), rgdal will install.

Roger

>
> After ./configure I got:
> GDAL is now configured for x86_64-unknown-linux-gnu
>
>  Installation directory:    /usr/local
>  C compiler:                gcc -g -O2
>  C++ compiler:              g++ -g -O2
>
>  LIBTOOL support:           yes
>
>  LIBZ support:              external
>  GRASS support:             no
>  CFITSIO support:           no
>  PCRaster support:          internal
>  NETCDF support:            no
>  LIBPNG support:            internal
>  LIBTIFF support:           internal (BigTIFF=yes)
>  LIBGEOTIFF support:        internal
>  LIBJPEG support:           internal
>  LIBGIF support:            internal
>  OGDI support:              no
>  HDF4 support:              no
>  HDF5 support:              no
>  KAKADU support:            no
>  JASPER support:            no
>  ECW support:               no
>  MrSID support:             no
>  GRIB support:              no
>  CURL support (wms/wcs/...):no
>  POSTGRESQL support:        no
>  MySQL support:             no
>  XERCES support:            no
>  Expat support:             yes
>  ODBC support:              no
>  PGEO support:              no
>  OCI support:               no
>  SDE support:               no
>  DODS support:              no
>  SQLite support:            no
>  DWGdirect support          no
>  PANORAMA GIS support:      no
>  INFORMIX DataBlade support:no
>  GEOS support:              no
>
>
>  Old-gen python          no
>  SWIG Bindings:          no
>
>  Statically link PROJ.4:    no
>  enable OGR building:       yes
>  enable pthread support:    no
>  hide internal symbols:     no
>
> Then I moved on to do make and make install, and then launched R on the
> same local directory and ran install.packages('rgdal'). I couldn't
> install rgdal because gdal-config wasn't found. The error message showed:
>
> --configure-args='--with-gdal-config=/usr/local/bin/gdal-config' echo
> with appropriate values for your installation.
>
> So I am guessing change '/usr/local/bin/gdal-config/ to
> '/usr/local/gdal-1.5.0/bin/gdal-config'.
>
> I appreciate if someone knows how to set up gdal on unix.
>
> Thanks.
>
> Takar
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From debarchana.ghosh at gmail.com  Fri Jan 11 01:30:19 2008
From: debarchana.ghosh at gmail.com (Debarchana Ghosh)
Date: Thu, 10 Jan 2008 18:30:19 -0600
Subject: [R-sig-Geo] Problem with spatial error model - discontinuous
	polygons
Message-ID: <d1b8ff630801101630l4fb473cbwf875d1984ef6dba6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080110/2ba5b4b2/attachment.pl>

From Roger.Bivand at nhh.no  Fri Jan 11 09:05:43 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 11 Jan 2008 09:05:43 +0100 (CET)
Subject: [R-sig-Geo] Problem with spatial error model - discontinuous
 polygons
In-Reply-To: <d1b8ff630801101630l4fb473cbwf875d1984ef6dba6@mail.gmail.com>
References: <d1b8ff630801101630l4fb473cbwf875d1984ef6dba6@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0801110903060.31698@reclus.nhh.no>

On Thu, 10 Jan 2008, Debarchana Ghosh wrote:

> Hi,
>
> I'm trying to run a spatial error model using the spdep package. I'm working
> on a windows machine with 2GB ram.
>
> baseshpPIN<-readShapePoly("tricounty_2005.shp", IDvar="PIN", verbose=TRUE)
>
> ## The shape has lots of discontinuous polygons
>
> basenb<-poly2nb(baseshpPIN, row.names=PIN)
>
> adrweights<-nb2listw(basenb, style="W", zero.policy=TRUE)
>
> modnetwork.errormod<-errorsarlm(SALE_VALUE~., data=modnetwork, adrweights)
> Error in errorsarlm(SALE_VALUE ~ ., data = modnetwork, adrweights) :
>        NAs in lagged dependent variable
> In addition: Warning message:
> NAs in lagged values in: lag.listw(listw, y, zero.policy = zero.policy)
>
> When I tried to Moran's I test, it gave similar errors. How can I solve this
> problem? Is there any wrong with the listw object (adrweights)?

Add the zero.policy=TRUE argument to each subsequent command too.

This is in ?errorsarlm:

"zero.policy: if TRUE assign zero to the lagged value of zones without
           neighbours, if FALSE (default) assign NA - causing
           'errorsarlm()' to terminate with an error"

Roger

>
> I'll appreciate any help.
>
> Thanks,
> Debs.
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From stefan.duke at gmail.com  Fri Jan 11 16:30:25 2008
From: stefan.duke at gmail.com (stefan lhachimi)
Date: Fri, 11 Jan 2008 16:30:25 +0100
Subject: [R-sig-Geo] delete region from shapefile / map only certain
	regions
In-Reply-To: <Pine.LNX.4.64.0801062009540.7522@reclus.nhh.no>
References: <a211af3b0801051338x33dc65e3y26be5269070f20ea@mail.gmail.com>
	<Pine.LNX.4.64.0801062009540.7522@reclus.nhh.no>
Message-ID: <a211af3b0801110730k59cbf3e2tced3e19cc359d188@mail.gmail.com>

Hi,
it worked perfectly!
Thanks a lot and sorry for the late response.
Best,
Stefan

On Jan 6, 2008 8:15 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Sat, 5 Jan 2008, stefan lhachimi wrote:
>
> > Hello,
> > I have two qeustions about shape files:
> >
> > First, I have a shp.file for all counties in Germany. Funnily enough,
> > two counties are just lakes for which
> >    I do not have covariates. Is there a possibilty delete them, so
> > they don't show on the map and do not affect my analysis.
>
> If you use readShapePoly() in maptools, they will be read into a
> SpatialPolygonsDataFrame object. You subset it using "[" as other data
> frame objects - see the examples in ?readShapePoly, and more class
> documentation in the sp package. Create a logical vector to do the
> subsetting.
>
> >
> >
> > Second, is it possible just to plot parts of the map, given some
> > condition (say, part of a state or a larger region)?
> >
>
> Either subset in the same way (counties in a land, for example), or use
> the xlim= and ylim= arguments to the plot() or spplot() methods for the
> class, depending on what you need. For plot(), you need to set the class
> intervals for colour filling yourself, for spplot() you can set up a
> legend and class intervals automatically.
>
> Hope this helps,
>
> Roger
>
> > I hope these question are not too trivial, but I couldn't find
> > anything adequate in the mailing list.
> > Happy new Year,
> > Stefan
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>



From milton_ruser at yahoo.com.br  Fri Jan 11 17:15:23 2008
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Fri, 11 Jan 2008 08:15:23 -0800 (PST)
Subject: [R-sig-Geo] clipping a large image on R
Message-ID: <210732.4080.qm@web56013.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080111/aa7ecde4/attachment.pl>

From debarchana.ghosh at gmail.com  Fri Jan 11 17:33:46 2008
From: debarchana.ghosh at gmail.com (Debarchana Ghosh)
Date: Fri, 11 Jan 2008 10:33:46 -0600
Subject: [R-sig-Geo] Problem with spatial error model - discontinuous
	polygons - memory problem
Message-ID: <d1b8ff630801110833g41c6e6dfhc11da71a42544149@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080111/111e0cd2/attachment.pl>

From hb at stat.berkeley.edu  Fri Jan 11 18:18:20 2008
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Fri, 11 Jan 2008 09:18:20 -0800
Subject: [R-sig-Geo] [R] clipping a large image on R
In-Reply-To: <210732.4080.qm@web56013.mail.re3.yahoo.com>
References: <210732.4080.qm@web56013.mail.re3.yahoo.com>
Message-ID: <59d7961d0801110918s37bd3d63y45967037d1032bf@mail.gmail.com>

Try the EBImage package (utilizes ImageMagick and is available via
Bioconductor.org) - not sure if it well help though.  If not, try to
clip the larger image by calling ImageMagick outside R.

/HB

On 11/01/2008, Milton Cezar Ribeiro <milton_ruser at yahoo.com.br> wrote:
> Dear all,
>
> I have a so large image (43,000 x 18,000 pixels) and I need clip this image with a smallest one (1000x1000 pixels). I can read the second image using rgdal package. But the first image can?t be read on my system because if memory limitation (I have about 2GB availabe).
>
> So I would like hear from you if anyone have some suggestin in this regards. I have also ArcGis 8.6 ans Erdas 8.3 running on my system and I can read the largest file without problem. But I dont know how clip the large image to keep only those pixels that math to he smallest image coordinates.
>
> kind regards, miltinho
>
>
>
>  para armazenamento!
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>



From debarchana.ghosh at gmail.com  Fri Jan 11 18:18:54 2008
From: debarchana.ghosh at gmail.com (Debarchana Ghosh)
Date: Fri, 11 Jan 2008 11:18:54 -0600
Subject: [R-sig-Geo] construct neighbor list from polygon list with user
	defined distance thresholds, as found in GeoDa?
Message-ID: <d1b8ff630801110918w7772d418k517763c7612c5565@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080111/b8027844/attachment.pl>

From Roger.Bivand at nhh.no  Fri Jan 11 18:36:00 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 11 Jan 2008 18:36:00 +0100 (CET)
Subject: [R-sig-Geo] Problem with spatial error model - discontinuous
 polygons - memory problem
In-Reply-To: <d1b8ff630801110833g41c6e6dfhc11da71a42544149@mail.gmail.com>
References: <d1b8ff630801110833g41c6e6dfhc11da71a42544149@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0801111815150.644@reclus.nhh.no>

On Fri, 11 Jan 2008, Debarchana Ghosh wrote:

> I tried the following but I still can't get to increase the memory.
>
> I'm working on 64-bit windows machine with 16 GB RAM. However I can't get to
> use the RAM properly.
>
>> test<-errorsarlm(SALE_VALUE~., data=modnetwork, adrweights,
> zero.policy=TRUE)
> Error: cannot allocate vector of size 2.1 Gb
>> help(memory.size)
>> memory.size(max = FALSE)
> [1] 168.1048
>> memory.size(max = TRUE)
> [1] 204.4375
>> memory.limit(size = NA)
> [1] 3583.875
>> memory.limit(size = 4095.00)
> NULL
>
> How can I increase the memory size in R to utilize the 16 GB RAM.

(16GB is wasted on Windows IMHO)

Not on Windows - there are tips on the R for Windows FAQ for running the 
32-bit R binary with maximum memomy for a 32-bit platform. There are no 
gcc Windows 64-bit compilers available yet, so there is no 64-bit Windows 
binary. 64-bit service is available on OSX (experimental but including 
x86_64 at http://r.research.att.com/) and Unix/Linux (which are what the 
developeRs mostly use).

The main difficulty seems to be that the Win32 API (and ABI) was quite 
well known, while reconstructing what M$ has done with the Win64 API and 
ABI is still taking time. The MinGW developers are working on it, but 
because few applications actually need it (there are better alternatives), 
progress is slow, and Win32 binaries run on Win64 on x86_64.

In any case, finding the eigenvalues of an nxn matrix (and operating on 
such matrices) is not really necessary, since sparse matrix routes are 
provided. See the method= argument documented in ?errorsarlm - "spam" is 
somewhat faster than "Matrix" in preliminary trials.

Roger

>
> Thanks for all your help.
>
> Debs.
>
>
> On Jan 11, 2008 2:05 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Thu, 10 Jan 2008, Debarchana Ghosh wrote:
>>
>>> Hi,
>>>
>>> I'm trying to run a spatial error model using the spdep package. I'm
>> working
>>> on a windows machine with 2GB ram.
>>>
>>> baseshpPIN<-readShapePoly("tricounty_2005.shp", IDvar="PIN",
>> verbose=TRUE)
>>>
>>> ## The shape has lots of discontinuous polygons
>>>
>>> basenb<-poly2nb(baseshpPIN, row.names=PIN)
>>>
>>> adrweights<-nb2listw(basenb, style="W", zero.policy=TRUE)
>>>
>>> modnetwork.errormod<-errorsarlm(SALE_VALUE~., data=modnetwork,
>> adrweights)
>>> Error in errorsarlm(SALE_VALUE ~ ., data = modnetwork, adrweights) :
>>>        NAs in lagged dependent variable
>>> In addition: Warning message:
>>> NAs in lagged values in: lag.listw(listw, y, zero.policy = zero.policy)
>>>
>>> When I tried to Moran's I test, it gave similar errors. How can I solve
>> this
>>> problem? Is there any wrong with the listw object (adrweights)?
>>
>> Add the zero.policy=TRUE argument to each subsequent command too.
>>
>> This is in ?errorsarlm:
>>
>> "zero.policy: if TRUE assign zero to the lagged value of zones without
>>           neighbours, if FALSE (default) assign NA - causing
>>           'errorsarlm()' to terminate with an error"
>>
>> Roger
>>
>>>
>>> I'll appreciate any help.
>>>
>>> Thanks,
>>> Debs.
>>>
>>>
>>>
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Fri Jan 11 18:47:23 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 11 Jan 2008 18:47:23 +0100 (CET)
Subject: [R-sig-Geo] [R] clipping a large image on R
In-Reply-To: <59d7961d0801110918s37bd3d63y45967037d1032bf@mail.gmail.com>
References: <210732.4080.qm@web56013.mail.re3.yahoo.com>
	<59d7961d0801110918s37bd3d63y45967037d1032bf@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0801111836300.644@reclus.nhh.no>

On Fri, 11 Jan 2008, Henrik Bengtsson wrote:

> Try the EBImage package (utilizes ImageMagick and is available via
> Bioconductor.org) - not sure if it well help though.  If not, try to
> clip the larger image by calling ImageMagick outside R.

First, please only write to one list at a time - this reply to both to 
continue thread.

Please read the documentation in the rgdal package properly, then on the 
format (unknown) that your data are in on www.gdal.org if necessary. Use 
the arguments to readGDAL() or asSGDF_GROD() in ?readGDAL, and/or 
getRasterData() or getRasterTable() in ?"GDALRasterBand-class", most 
likely offset= to offset the origin in rows and columns, and region.dim= 
to set the numbers of rows and columns to access.

You should be able to work out the ones you need from the smaller image 
that you can read. The GDALinfo() function should give you enough 
information on the larger file to help set up offset= and region.dim= - if 
resampling is needed, use output.dim= as well. If you have multiple bands, 
you can choose those too.

Roger

>
> /HB
>
> On 11/01/2008, Milton Cezar Ribeiro <milton_ruser at yahoo.com.br> wrote:
>> Dear all,
>>
>> I have a so large image (43,000 x 18,000 pixels) and I need clip this 
>> image with a smallest one (1000x1000 pixels). I can read the second 
>> image using rgdal package. But the first image can?t be read on my 
>> system because if memory limitation (I have about 2GB availabe).
>>
>> So I would like hear from you if anyone have some suggestin in this regards. I have also ArcGis 8.6 ans Erdas 8.3 running on my system and I can read the largest file without problem. But I dont know how clip the large image to keep only those pixels that math to he smallest image coordinates.
>>
>> kind regards, miltinho
>>
>>
>>
>>  para armazenamento!
>>
>>         [[alternative HTML version deleted]]
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From Roger.Bivand at nhh.no  Fri Jan 11 19:00:30 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 11 Jan 2008 19:00:30 +0100 (CET)
Subject: [R-sig-Geo] construct neighbor list from polygon list with user
 defined distance thresholds, as found in GeoDa?
In-Reply-To: <d1b8ff630801110918w7772d418k517763c7612c5565@mail.gmail.com>
References: <d1b8ff630801110918w7772d418k517763c7612c5565@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0801111847470.644@reclus.nhh.no>

On Fri, 11 Jan 2008, Debarchana Ghosh wrote:

> Hi,
>
> After reading a ESRI shape file I want to create a neighbor list (class nb)
> from the polygon list by defining a distance thresholds for example 2500m.
> This is a option in GeoDa weights creation. However I couldn't find any
> function in R to do this. The function poly2nb is based on the 'Queen'
> contiguity method.

Looking at the HTML help for the package ought to get you there, 
alternatively scrolling through help(package=spdep)

RSiteSearch("distance neighbours, restrict=c("functions", "docs")")

gets you there first hit (please recall that the spdep author tries to use 
conservative British English - hence neighbour, randomisation, etc.). 
Other spellings can be abbreviated:

RSiteSearch("distance neigh*", restrict=c("functions"))

gets 7th hit to:

?dnearneigh, that is.

If you need alternatives that are not in spdep (such as mean spanning 
tree), look at packages like ade4 (see the search results for ideas).

Roger

>
> Thanks for your help.
> Debs.
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From reprieving at lugnutcollectibles.com  Fri Jan 11 22:17:18 2008
From: reprieving at lugnutcollectibles.com (Celia Miller)
Date: Fri, 11 Jan 2008 16:17:18 -0500
Subject: [R-sig-Geo] Ado6e Kreative Sui+e 3 for MAC\XP\Vlsta 269,
	Retail 1799 (save 1529)
Message-ID: <000201c85496$bd6e2900$0100007f@wxqfki>

corel wordperfect office x3 standard - 49
readiris pro 11.5 for mac - 39

v!sit "luckydayoem .com" in Internet Exp!orer microsoft onenote pro 2003 - 29

adobe encore dvd 2 - 49
google sketchup pro 6 for mac - 59
cadlink signlab vinyl 7.1 - 69
creative suite premium 2 - 149
intuit quickbooks premier edition 2007 - 79
autodesk autocad electrical 2006 - 99
crystal xcelsius professional v4.5 - 59
graphisoft archicad 9.0 r1 international - 69
sony sound forge 9.0 - 49



From stefan.duke at gmail.com  Sat Jan 12 21:11:33 2008
From: stefan.duke at gmail.com (stefan lhachimi)
Date: Sat, 12 Jan 2008 21:11:33 +0100
Subject: [R-sig-Geo] save polygon as a shape file
Message-ID: <a211af3b0801121211s2a3f0dc9td0eb94f776d0fe41@mail.gmail.com>

Hello,

I loaded a .shp-file and used a subset command while converting it
into a polygon to eliminate certain regions:

map.kreise<-readShapePoly("vg250krs",IDvar="KRS_ID",verbos=TRUE)
map.kreise.boden <-polygons(map.kreise)[x$BODENSEE==0]

Now I want to save the new object map.kreise.boden as a shp-file again
(I want to usethe new shp-file without certain regions into GEODA).
The writePolyShape-command does not work. It gives me the following
error message:

 writePolyShape(map.kreise.boden, "mapohnebodensee")
Fehler in as(x, "data.frame") :
  no method or default for coercing "SpatialPolygons" to "data.frame"

Any help is appreciated.
Best,
Stefan



From Roger.Bivand at nhh.no  Sat Jan 12 21:27:09 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 12 Jan 2008 21:27:09 +0100 (CET)
Subject: [R-sig-Geo] save polygon as a shape file
In-Reply-To: <a211af3b0801121211s2a3f0dc9td0eb94f776d0fe41@mail.gmail.com>
References: <a211af3b0801121211s2a3f0dc9td0eb94f776d0fe41@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0801122117450.4088@reclus.nhh.no>

On Sat, 12 Jan 2008, stefan lhachimi wrote:

> Hello,
>
> I loaded a .shp-file and used a subset command while converting it
> into a polygon to eliminate certain regions:
>
> map.kreise<-readShapePoly("vg250krs",IDvar="KRS_ID",verbos=TRUE)
> map.kreise.boden <-polygons(map.kreise)[x$BODENSEE==0]

Why polygons()? It returns a SpatialPolygons object. To select the 
polygons and the data frame rows, you need:

map.kreise.boden <- map.kreise[x$BODENSEE==0,]

(note the extra comma) where:

writePolyShape(map.kreise.boden, "mapohnebodensee")

will just work. A shapefile cannot only have geometries, it must have 
attribute data. The documentation does say that the first argument to 
writePolyShape should be a SpatialPolygonsDataFrame, and you can check 
with:

class(map.kreise.boden)

Roger

>
> Now I want to save the new object map.kreise.boden as a shp-file again
> (I want to usethe new shp-file without certain regions into GEODA).
> The writePolyShape-command does not work. It gives me the following
> error message:
>
> writePolyShape(map.kreise.boden, "mapohnebodensee")
> Fehler in as(x, "data.frame") :
>  no method or default for coercing "SpatialPolygons" to "data.frame"
>
> Any help is appreciated.
> Best,
> Stefan
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From tkobayas at indiana.edu  Sat Jan 12 22:45:20 2008
From: tkobayas at indiana.edu (Takatsugu Kobayashi)
Date: Sat, 12 Jan 2008 16:45:20 -0500
Subject: [R-sig-Geo] Creating another grid from n*n grid
Message-ID: <478934F0.6040509@indiana.edu>

Hi,

(As an exercise)I am trying to create a SpatialPolygons object from n*n 
grid. By reading the material (from vignette{'sp'), I managed to convert 
grid to polygons. Now I would like plot this polygons, and here is what 
I have done so far:

Step1: Create a 9*9 grid
n<-9 # number of cells in each axis
x <- 1:n+1
y <- 1:n+1
r.grid <- makeGrid(x,y)

Step2: Convert the grid to SpatialPolygon
Srs <- list()
for (i in 1:n^2)
{
x.coord <- c(r.grid$X[(1+4*(i-1)):(1+4*(i-1)+3)],r.grid$X[(1+4*(i-1))])
y.coord <- c(r.grid$Y[(1+4*(i-1)):(1+4*(i-1)+3)],r.grid$Y[(1+4*(i-1))])
subPoly <- Polygon(cbind(x.coord, y.coord),hole=FALSE)
Srs[[i]] <- Polygons(list(subPoly), paste("SP",i,sep=''))
}

SpP <- SpatialPolygons(list(Srs),1:n^2)
Error in is.vector(X) : cannot get a slot ("Polygons") from an object of 
type "list"

I am trying to what the following message tells me. class(Srs) returns 
"list" as class and Src has an object of class "Polygons" as follows:

[[81]]
An object of class ?Polygons?
Slot "Polygons":
[[1]]
An object of class ?Polygon?
Slot "labpt":
[1] 9.5 9.5

Slot "area":
[1] 1

Slot "hole":
[1] FALSE

Slot "ringDir":
[1] 1

Slot "coords":
x.coord y.coord
[1,] 9 9
[2,] 9 10
[3,] 10 10
[4,] 10 9
[5,] 9 9

Slot "plotOrder":
[1] 1

Slot "labpt":
[1] 9.5 9.5

Slot "ID":
[1] "SP81"

Slot "area":
[1] 1

I am sure I am doing fundamental mistakes here. As I am thinking to 
increase n later, I wouldn't want to type Srs[[1]..... by hand.

Also, I am going to convert this polygons into shapefile to get an 
polygon-adjacency matrix through GeoDA. I have reading a few threads 
about a polygon adjacency matrix in R, but it seems GeoDA is a way to 
go? For my case, I would assign 1 if 2 polygons share multiple 
coordinates and store neighbors in list if this is a good way to do in R.

Sorry for this very fundamental question, but I appreciate help.

Thank you.

Taka



From tkobayas at indiana.edu  Sat Jan 12 22:47:31 2008
From: tkobayas at indiana.edu (Takatsugu Kobayashi)
Date: Sat, 12 Jan 2008 16:47:31 -0500
Subject: [R-sig-Geo] construct neighbor list from polygon list with user
 defined distance thresholds, as found in GeoDa?
In-Reply-To: <d1b8ff630801110918w7772d418k517763c7612c5565@mail.gmail.com>
References: <d1b8ff630801110918w7772d418k517763c7612c5565@mail.gmail.com>
Message-ID: <47893573.6070409@indiana.edu>

?dnearneigh in spdep package is the one I can think of.

Taka

Debarchana Ghosh wrote:
> Hi,
>
> After reading a ESRI shape file I want to create a neighbor list (class nb)
> from the polygon list by defining a distance thresholds for example 2500m.
> This is a option in GeoDa weights creation. However I couldn't find any
> function in R to do this. The function poly2nb is based on the 'Queen'
> contiguity method.
>
> Thanks for your help.
> Debs.
>
>
>
>



From tkobayas at indiana.edu  Sat Jan 12 22:54:56 2008
From: tkobayas at indiana.edu (Takatsugu Kobayashi)
Date: Sat, 12 Jan 2008 16:54:56 -0500
Subject: [R-sig-Geo] construct neighbor list from polygon list with user
 defined distance thresholds, as found in GeoDa?
In-Reply-To: <d1b8ff630801110918w7772d418k517763c7612c5565@mail.gmail.com>
References: <d1b8ff630801110918w7772d418k517763c7612c5565@mail.gmail.com>
Message-ID: <47893730.4070003@indiana.edu>

Also, look at this thread: 
https://stat.ethz.ch/pipermail/r-sig-geo/2005-July/000502.html

Debarchana Ghosh wrote:
> Hi,
>
> After reading a ESRI shape file I want to create a neighbor list (class nb)
> from the polygon list by defining a distance thresholds for example 2500m.
> This is a option in GeoDa weights creation. However I couldn't find any
> function in R to do this. The function poly2nb is based on the 'Queen'
> contiguity method.
>
> Thanks for your help.
> Debs.
>
>
>
>



From Roger.Bivand at nhh.no  Sun Jan 13 14:37:20 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 13 Jan 2008 14:37:20 +0100 (CET)
Subject: [R-sig-Geo] Creating another grid from n*n grid
In-Reply-To: <478934F0.6040509@indiana.edu>
References: <478934F0.6040509@indiana.edu>
Message-ID: <Pine.LNX.4.64.0801131414300.28089@reclus.nhh.no>

On Sat, 12 Jan 2008, Takatsugu Kobayashi wrote:

> Hi,
>
> (As an exercise)I am trying to create a SpatialPolygons object from n*n
> grid. By reading the material (from vignette{'sp'), I managed to convert
> grid to polygons. Now I would like plot this polygons, and here is what
> I have done so far:
>
> Step1: Create a 9*9 grid
> n<-9 # number of cells in each axis
> x <- 1:n+1
> y <- 1:n+1
> r.grid <- makeGrid(x,y)

Trying to reproduce your case, there is a problem:

> library(sp)
> n<-9
> x <- (1:n)+1
> y <- (1:n)+1
> r.grid <- makeGrid(x,y)
Error: could not find function "makeGrid"

(It seems to be in PBSmapping).
Doing things directly might be easier:

library(sp)
grd <- GridTopology(c(2,2), c(1,1), c(9,9))
SP <- as(grd, "SpatialPolygons")
plot(SP, axes=TRUE)

See ?GridTopology and ?as.SpatialPolygons.GridTopology, the latter is the 
first line in help(package=sp) - though other names in that listing are 
less intuitive.

Looking at:

getMethod("coerce", c("GridTopology", "SpatialPolygons"))

sp:::as.SpatialPolygons.GridTopology

shows what is going on, and:

sp:::as.SpatialPolygons.PolygonsList

and

SpatialPolygons

the actual code building the SpatialPolygons object. In your exercise, you 
could say debug(SpatialPolygons), which I think would show that the extra 
list() is unnecessary. See if you can get your exercise to give the same 
results as coercing from a GridTopology object to a SpatialPolygons 
object, this is a very typical and effective way to find out how things 
work.

There was correspondence on the list last year with sample code for 
coercing a PolySet object to SpatialPolygons - would it be useful to put 
such a function into the maptools package?

Roger

>
> Step2: Convert the grid to SpatialPolygon
> Srs <- list()
> for (i in 1:n^2)
> {
> x.coord <- c(r.grid$X[(1+4*(i-1)):(1+4*(i-1)+3)],r.grid$X[(1+4*(i-1))])
> y.coord <- c(r.grid$Y[(1+4*(i-1)):(1+4*(i-1)+3)],r.grid$Y[(1+4*(i-1))])
> subPoly <- Polygon(cbind(x.coord, y.coord),hole=FALSE)
> Srs[[i]] <- Polygons(list(subPoly), paste("SP",i,sep=''))
> }
>
> SpP <- SpatialPolygons(list(Srs),1:n^2)
> Error in is.vector(X) : cannot get a slot ("Polygons") from an object of
> type "list"
>
> I am trying to what the following message tells me. class(Srs) returns
> "list" as class and Src has an object of class "Polygons" as follows:
>
> [[81]]
> An object of class ?Polygons?
> Slot "Polygons":
> [[1]]
> An object of class ?Polygon?
> Slot "labpt":
> [1] 9.5 9.5
>
> Slot "area":
> [1] 1
>
> Slot "hole":
> [1] FALSE
>
> Slot "ringDir":
> [1] 1
>
> Slot "coords":
> x.coord y.coord
> [1,] 9 9
> [2,] 9 10
> [3,] 10 10
> [4,] 10 9
> [5,] 9 9
>
> Slot "plotOrder":
> [1] 1
>
> Slot "labpt":
> [1] 9.5 9.5
>
> Slot "ID":
> [1] "SP81"
>
> Slot "area":
> [1] 1
>
> I am sure I am doing fundamental mistakes here. As I am thinking to
> increase n later, I wouldn't want to type Srs[[1]..... by hand.
>
> Also, I am going to convert this polygons into shapefile to get an
> polygon-adjacency matrix through GeoDA. I have reading a few threads
> about a polygon adjacency matrix in R, but it seems GeoDA is a way to
> go? For my case, I would assign 1 if 2 polygons share multiple
> coordinates and store neighbors in list if this is a good way to do in R.
>
> Sorry for this very fundamental question, but I appreciate help.
>
> Thank you.
>
> Taka
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From debarchana.ghosh at gmail.com  Mon Jan 14 21:33:59 2008
From: debarchana.ghosh at gmail.com (Debarchana Ghosh)
Date: Mon, 14 Jan 2008 14:33:59 -0600
Subject: [R-sig-Geo] CHOLMOD and GetClass error when running errorsarlmfrom
	spdep package with method = Matrix or SparseM
Message-ID: <d1b8ff630801141233y1216b700o7c4476c32a5a11b5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080114/1f5809aa/attachment.pl>

From Roger.Bivand at nhh.no  Mon Jan 14 22:24:50 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 14 Jan 2008 22:24:50 +0100 (CET)
Subject: [R-sig-Geo] CHOLMOD and GetClass error when running
 errorsarlmfrom spdep package with method = Matrix or SparseM
In-Reply-To: <d1b8ff630801141233y1216b700o7c4476c32a5a11b5@mail.gmail.com>
References: <d1b8ff630801141233y1216b700o7c4476c32a5a11b5@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0801142150300.2767@reclus.nhh.no>

On Mon, 14 Jan 2008, Debarchana Ghosh wrote:

> Hi,
>
> I'm working on Windows with 2GB RAM.
>
> I'm trying to run the errorsarlm with 28 predictor variables and 16,854
> records. The listw object is created by the dnearneigh function with upper
> limit of distance as 2500m. Following are the sequence of codes.

Quote:

CHOLMOD error: out of memory

seems quite clear. How dense is your weights matrix - just say:

print(wts2500)

If it is such that some observations have many neighbours, the matrix will 
still be large. Users have run with n > 30,000, so 16,000 is feasible, but 
your case may be special - distance is not an ideal criterion.

Roger

>
> ## Read polygon shape file
> adrbaseshp<-readShapePoly("tricounty_2005_12JAN_WORKING.shp", IDvar="ID",
> verbose=TRUE)
>
> ### creating neighbor list
> coords<-coordinates(adrbaseshp)
> rn<-sapply(slot(adrbaseshp, "polygons"), function(x) slot(x, "ID"))
> nb2500<-dnearneigh(coords, 0, 2500, row.names=rn)
>
> ## neighbor to weigth matrix
> wts2500<-nb2listw(nb2500, zero.policy=TRUE)
>
> ## lagrange diagnostics
> adr_rd_ols.lagrange<-lm.LMtests(adr_rd_ols.lm, wts2500, test="all",
> zero.policy=TRUE)
>
> # Spatial error model package spdep
> ##  To work around the memory problem I used method="Matrix" (suggested by
> Roger Bivand)
>
> adr_rd.saerror<-errorsarlm(LN_PRICE~., data=adr_rd_ols, wts2500,
> zero.policy=TRUE, method="Matrix")
>
> ## It gave me the following error which I can't understand
> ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> CHOLMOD error: out of memory
> Error in asMethod(object) : no function to return from, jumping to top level
> In addition: Warning messages:
> 1: NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> 2: NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> 3: NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> CHOLMOD error: out of memory
> Error in switch(.Generic, "+" = , "-" = .Call(Tsparse_to_Csparse,
> new("dgTMatrix",  :
>        no function to return from, jumping to top level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> CHOLMOD error: out of memory
> Error in switch(.Generic, "+" = , "-" = .Call(Tsparse_to_Csparse,
> new("dgTMatrix",  :
>        no function to return from, jumping to top level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> CHOLMOD error: out of memory
> Error in switch(.Generic, "+" = , "-" = .Call(Tsparse_to_Csparse,
> new("dgTMatrix",  :
>        no function to return from, jumping to top level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> CHOLMOD error: out of memory
> Error in switch(.Generic, "+" = , "-" = .Call(Tsparse_to_Csparse,
> new("dgTMatrix",  :
>        no function to return from, jumping to top level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> CHOLMOD error: out of memory
> Error in switch(.Generic, "+" = , "-" = .Call(Tsparse_to_Csparse,
> new("dgTMatrix",  :
>        no function to return from, jumping to top level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> CHOLMOD error: out of memory
> Error in switch(.Generic, "+" = , "-" = .Call(Tsparse_to_Csparse,
> new("dgTMatrix",  :
>        no function to return from, jumping to top level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> CHOLMOD error: out of memory
> Error in switch(.Generic, "+" = , "-" = .Call(Tsparse_to_Csparse,
> new("dgTMatrix",  :
>        no function to return from, jumping to top level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> CHOLMOD error: out of memory
> Error in switch(.Generic, "+" = , "-" = .Call(Tsparse_to_Csparse,
> new("dgTMatrix",  :
>        no function to return from, jumping to top level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> CHOLMOD error: out of memory
> Error in switch(.Generic, "+" = , "-" = .Call(Tsparse_to_Csparse,
> new("dgTMatrix",  :
>        no function to return from, jumping to top level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> CHOLMOD error: out of memory
> Error in switch(.Generic, "+" = , "-" = .Call(Tsparse_to_Csparse,
> new("dgTMatrix",  :
>        no function to return from, jumping to top level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in initialize(value, ...) : no function to return from, jumping to top
> level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in initialize(value, ...) : no function to return from, jumping to top
> level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in initialize(value, ...) : no function to return from, jumping to top
> level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in initialize(value, ...) : no function to return from, jumping to top
> level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in initialize(value, ...) : no function to return from, jumping to top
> level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in initialize(value, ...) : no function to return from, jumping to top
> level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in initialize(value, ...) : no function to return from, jumping to top
> level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in initialize(value, ...) : no function to return from, jumping to top
> level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in initialize(value, ...) : no function to return from, jumping to top
> level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in initialize(value, ...) : no function to return from, jumping to top
> level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in initialize(value, ...) : no function to return from, jumping to top
> level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in initialize(value, ...) : no function to return from, jumping to top
> level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in initialize(value, ...) : no function to return from, jumping to top
> level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in initialize(value, ...) : no function to return from, jumping to top
> level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in initialize(value, ...) : no function to return from, jumping to top
> level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in initialize(value, ...) : no function to return from, jumping to top
> level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in initialize(value, ...) : no function to return from, jumping to top
> level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in initialize(value, ...) : no function to return from, jumping to top
> level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in initialize(value, ...) : no function to return from, jumping to top
> level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in initialize(value, ...) : no function to return from, jumping to top
> level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in `slot<-`(.Object, slotName, check = FALSE, slotVal) :
>        no function to return from, jumping to top level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in `slot<-`(.Object, slotName, check = FALSE, slotVal) :
>        no function to return from, jumping to top level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in `slot<-`(.Object, slotName, check = FALSE, slotVal) :
>        no function to return from, jumping to top level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> Error in `slot<-`(.Object, slotName, check = FALSE, slotVal) :
>        no function to return from, jumping to top level
> In addition: Warning message:
> NA/Inf replaced by maximum positive value in: optimize(sar.error.f.M,
> interval = interval, maximum = TRUE,
> ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>
> I also tried the following
>
> adr_rd.saerror<-errorsarlm(LN_PRICE~., data=adr_rd_ols, wts2500,
> zero.policy=TRUE, method="SparseM")
>
> I got the following
>
> Error in getClass(Class, where = topenv(parent.frame())) :
>        "matrix.csr" is not a defined class
> In addition: Warning message:
> 'asMatrixCsrListw' is deprecated.
> Use 'as_dgRMatrix_listw' instead.
> See help("Deprecated") and help("spdep-deprecated").
>
> Again, I don't understand the error. How should I run the errorsarlm
> function?
>
> Thanks in advance.
> Debs.
>
> --
>
>
> Debarchana Ghosh
> PHD Candidate | Research Assistant
> Department of Geography
> University of Minnesota.
> PH: 8143607580
> www.tc.umn.edu/~ghos0033/ <http://www.tc.umn.edu/%7Eghos0033/>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From andrew.niccolai at yale.edu  Mon Jan 14 23:42:55 2008
From: andrew.niccolai at yale.edu (Andrew Niccolai)
Date: Mon, 14 Jan 2008 17:42:55 -0500
Subject: [R-sig-Geo] Comparison between two marked point pattern data sets
In-Reply-To: <Pine.LNX.4.64.0801142150300.2767@reclus.nhh.no>
References: <d1b8ff630801141233y1216b700o7c4476c32a5a11b5@mail.gmail.com>
	<Pine.LNX.4.64.0801142150300.2767@reclus.nhh.no>
Message-ID: <001101c856fe$cdeb4910$69c1db30$@niccolai@yale.edu>

Dear Spatial R group,

I disclose that I have been more active in image segmentation than spatial
statistics of late so please bear with me if this question is too pedantic.
I have a field collected marked point pattern of tree crown size classes.
The point data consists of the X,Y coordinates of the center of the tree
crown projected onto CT State Plane Datum and the estimated crown size class
(described as a radius measured in feet).  There are 8 possible size
classes: 4, 6, 8, 10, 12, 14, 16 and 20 feet.  I have produced a marked
point pattern data set with the same crown size class attribute from an
automatic crown detection algorithm using remotely sensed data.  I would
like to test how similar (or different if that turns out to be the case) the
two marked point patterns are to each other, ie, how well the size class
spatial location and distributions match.  I know this is not a perfect
match as there are 516 field measured points and 568 remotely sensed points.
However, I am looking for a metric to assess how closely the simulated size
class distribution patterns emulate the field measured patterns.

Any suggestions are truly appreciated.
Thanks,

Andrew Niccolai
Doctoral Candidate
Yale University
office (203) 432-5144
cell (860) 402-6079



From sznelwar at uol.com.br  Tue Jan 15 00:29:01 2008
From: sznelwar at uol.com.br (Mauro Sznelwar)
Date: Mon, 14 Jan 2008 21:29:01 -0200
Subject: [R-sig-Geo] Convert LL to UTM
Message-ID: <011301c85705$3f577b90$bd1c57c9@mauro>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080114/f41d7144/attachment.pl>

From cfarmer at uvic.ca  Tue Jan 15 00:42:00 2008
From: cfarmer at uvic.ca (Carson Farmer)
Date: Mon, 14 Jan 2008 15:42:00 -0800
Subject: [R-sig-Geo] Spatially Constrained Clustering
In-Reply-To: <mailman.5.1200308401.26749.r-sig-geo@stat.math.ethz.ch>
References: <mailman.5.1200308401.26749.r-sig-geo@stat.math.ethz.ch>
Message-ID: <478BF348.3080309@uvic.ca>

Hello List,

I am trying to find an R package that will accommodate spatially 
constrained clustering.  While I have been unable to find a package that 
is explicitly designed to do spatially constrained clustering, I was 
wondering if anyone had found a package that would do constrained 
clustering of any kind, and adapted this to spatial constraints?
I have searched the R site extensively, and googled all night long, but 
to no avail! I HAVE found this post:
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/56819.html
but the replies did not help much.  They lead to several packages which 
perform spatial clustering (such that significant clusters of say a 
disease are located within a study region), however, what I would like 
to do is partition a spatial (grid) dataset based on multiple variables, 
taking into account their spatial locations (i.e. clustering is based on 
the variables, but constrained so that clusters are spatially 
contiguous).  I'm thinking mclust is probably the best way to go, but 
I'm not sure where to start.

Any suggestions would be greatly appreciated.

Thanks,

Carson



From Dale_Steele at brown.EDU  Tue Jan 15 01:33:40 2008
From: Dale_Steele at brown.EDU (Dale Steele)
Date: Mon, 14 Jan 2008 19:33:40 -0500
Subject: [R-sig-Geo] Convert LL to UTM
In-Reply-To: <011301c85705$3f577b90$bd1c57c9@mauro>
References: <011301c85705$3f577b90$bd1c57c9@mauro>
Message-ID: <72e8303a0801141633g69f2cccdq2703b68be00ba041@mail.gmail.com>

require(PBSmapping)
?convUL

for example ...

points <- data.frame(cbind(data$idnum, data$long, data$lat, data$var))
colnames(points) <- c("EID", "X", "Y", "var")
attr(points, "projection") <- "LL"
   ## Define as EventData
points <- as.EventData(points)
  ## Transform to UTM (Euclidean) coordinates, uses package PBSmapping
 convUL(points, km=TRUE)

On Jan 14, 2008 6:29 PM, Mauro Sznelwar <sznelwar at uol.com.br> wrote:
>  How can I do to transform geographic coordinates in UTM, I want to transform a column of latitude and longitude in decimal geographic coordenates to UTM. I know pages that convert  each value, but I want to do a whole variable (column)!
> Mauro Sznelwar - MSc Student of S?o Paulo University, Brazil, in the fields of Geoprocessing
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>



From dylan.beaudette at gmail.com  Tue Jan 15 01:48:18 2008
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Mon, 14 Jan 2008 16:48:18 -0800
Subject: [R-sig-Geo] Convert LL to UTM
In-Reply-To: <72e8303a0801141633g69f2cccdq2703b68be00ba041@mail.gmail.com>
References: <011301c85705$3f577b90$bd1c57c9@mauro>
	<72e8303a0801141633g69f2cccdq2703b68be00ba041@mail.gmail.com>
Message-ID: <200801141648.18730.dylan.beaudette@gmail.com>

or see the Proj4 library and utilities- outside of R

Dylan

On Monday 14 January 2008, Dale Steele wrote:
> require(PBSmapping)
> ?convUL
>
> for example ...
>
> points <- data.frame(cbind(data$idnum, data$long, data$lat, data$var))
> colnames(points) <- c("EID", "X", "Y", "var")
> attr(points, "projection") <- "LL"
>    ## Define as EventData
> points <- as.EventData(points)
>   ## Transform to UTM (Euclidean) coordinates, uses package PBSmapping
>  convUL(points, km=TRUE)
>
> On Jan 14, 2008 6:29 PM, Mauro Sznelwar <sznelwar at uol.com.br> wrote:
> >  How can I do to transform geographic coordinates in UTM, I want to
> > transform a column of latitude and longitude in decimal geographic
> > coordenates to UTM. I know pages that convert  each value, but I want to
> > do a whole variable (column)! Mauro Sznelwar - MSc Student of S?o Paulo
> > University, Brazil, in the fields of Geoprocessing [[alternative HTML
> > version deleted]]
> >
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341



From ggrothendieck at gmail.com  Tue Jan 15 01:36:52 2008
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 14 Jan 2008 19:36:52 -0500
Subject: [R-sig-Geo] Convert LL to UTM
In-Reply-To: <011301c85705$3f577b90$bd1c57c9@mauro>
References: <011301c85705$3f577b90$bd1c57c9@mauro>
Message-ID: <971536df0801141636w4de49993pba86cd33647a0908@mail.gmail.com>

Check out:

https://stat.ethz.ch/pipermail/r-sig-geo/2007-March/001804.html

On Jan 14, 2008 6:29 PM, Mauro Sznelwar <sznelwar at uol.com.br> wrote:
>  How can I do to transform geographic coordinates in UTM, I want to transform a column of latitude and longitude in decimal geographic coordenates to UTM. I know pages that convert  each value, but I want to do a whole variable (column)!
> Mauro Sznelwar - MSc Student of S?o Paulo University, Brazil, in the fields of Geoprocessing



From gavin.simpson at ucl.ac.uk  Tue Jan 15 09:07:20 2008
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 15 Jan 2008 08:07:20 +0000
Subject: [R-sig-Geo] Spatially Constrained Clustering
In-Reply-To: <478BF348.3080309@uvic.ca>
References: <mailman.5.1200308401.26749.r-sig-geo@stat.math.ethz.ch>
	<478BF348.3080309@uvic.ca>
Message-ID: <1200384440.2771.5.camel@localhost.localdomain>

Carson,

If you don't get any other firm answers, take a look at this work in
progress of Steve Juggins:
http://www.campus.ncl.ac.uk/staff/Stephen.Juggins/analysis.htm

He hacked the source of hclust (and the underlying Fortran) to do
constrained clustering using hclust's methods. This was for a single
constraint so we can keep samples in time together, but I'm sure by
studying the code, if you know Fortran (and I don't) and compare the
minor changes Steve made to the code for hclust, you might be able to
hack it to do what you want.

HTH

G

On Mon, 2008-01-14 at 15:42 -0800, Carson Farmer wrote:
> Hello List,
> 
> I am trying to find an R package that will accommodate spatially 
> constrained clustering.  While I have been unable to find a package that 
> is explicitly designed to do spatially constrained clustering, I was 
> wondering if anyone had found a package that would do constrained 
> clustering of any kind, and adapted this to spatial constraints?
> I have searched the R site extensively, and googled all night long, but 
> to no avail! I HAVE found this post:
> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/56819.html
> but the replies did not help much.  They lead to several packages which 
> perform spatial clustering (such that significant clusters of say a 
> disease are located within a study region), however, what I would like 
> to do is partition a spatial (grid) dataset based on multiple variables, 
> taking into account their spatial locations (i.e. clustering is based on 
> the variables, but constrained so that clusters are spatially 
> contiguous).  I'm thinking mclust is probably the best way to go, but 
> I'm not sure where to start.
> 
> Any suggestions would be greatly appreciated.
> 
> Thanks,
> 
> Carson
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From nonconcur at cstoneland.com  Tue Jan 15 09:28:35 2008
From: nonconcur at cstoneland.com (Thomas Ellis)
Date: Tue, 15 Jan 2008 21:28:35 +1300
Subject: [R-sig-Geo] Ado6e Kreative Sui+e 3 for MAC\XP\Vlsta 269,
	Retail 1799 (save 1529)
Message-ID: <000501c8574f$f553c580$0100007f@irggk>

v!sit 'ezmicrosoftnow. com' in Internet browser ms xp professional with sp2 - 49
cakewalk project 5 - 59
symantec norton 360 - 29
microsoft exchange server enterprise 2003 - 59
corel wordperfect office standard edition 12 - 49
final draft 7 - 39
luxology modo 301 for mac - 129
borland developer studio 2006 - 149
adobe indesign cs3 - 79
mcafee desktop firewall 8.0.493 - 39
roxio digitalmedia studio deluxe suite 7.0 - 49
ulead photoimpact 12 - 79
adobe illustrator cs3 - 69
acronis true image enterprise server 9.1.3666 - 79
ulead photoimpact 12 - 79



From Roger.Bivand at nhh.no  Tue Jan 15 11:56:31 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 15 Jan 2008 11:56:31 +0100 (CET)
Subject: [R-sig-Geo] Convert LL to UTM
In-Reply-To: <200801141648.18730.dylan.beaudette@gmail.com>
References: <011301c85705$3f577b90$bd1c57c9@mauro>
	<72e8303a0801141633g69f2cccdq2703b68be00ba041@mail.gmail.com>
	<200801141648.18730.dylan.beaudette@gmail.com>
Message-ID: <Pine.LNX.4.64.0801151151260.7606@reclus.nhh.no>

On Mon, 14 Jan 2008, Dylan Beaudette wrote:

> or see the Proj4 library and utilities- outside of R

I.e.:

function project() in the rgdal package. Mauro wrote to me off-list ten 
days ago and got a reply:

"Please read the help page for the project function (?project) in the 
rgdal package carefully. There are no variables being projected, only a 
matrix of point coordinates. The function you quote was for a completely 
different situation. If your input data are not points in geographical 
coordinates, see ?"spTransform-methods".

Please also write to the R-sig-geo rather than to me directly - 
maintainers can help with bugs in software, but the list will give faster 
and perhaps better response."

At least he read the second paragraph, but probably not the first. I agree 
that reading the proj4 documentation would help too, but so far we don't 
know enough - only that the input coordinates seem to be geographical.

Roger

>
> Dylan
>
> On Monday 14 January 2008, Dale Steele wrote:
>> require(PBSmapping)
>> ?convUL
>>
>> for example ...
>>
>> points <- data.frame(cbind(data$idnum, data$long, data$lat, data$var))
>> colnames(points) <- c("EID", "X", "Y", "var")
>> attr(points, "projection") <- "LL"
>>    ## Define as EventData
>> points <- as.EventData(points)
>>   ## Transform to UTM (Euclidean) coordinates, uses package PBSmapping
>>  convUL(points, km=TRUE)
>>
>> On Jan 14, 2008 6:29 PM, Mauro Sznelwar <sznelwar at uol.com.br> wrote:
>>>  How can I do to transform geographic coordinates in UTM, I want to
>>> transform a column of latitude and longitude in decimal geographic
>>> coordenates to UTM. I know pages that convert  each value, but I want to
>>> do a whole variable (column)! Mauro Sznelwar - MSc Student of S?o Paulo
>>> University, Brazil, in the fields of Geoprocessing [[alternative HTML
>>> version deleted]]
>>>
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From eliaskrainski at yahoo.com.br  Tue Jan 15 14:51:48 2008
From: eliaskrainski at yahoo.com.br (Elias T. Krainski)
Date: Tue, 15 Jan 2008 10:51:48 -0300 (ART)
Subject: [R-sig-Geo] Spatially Constrained Clustering
In-Reply-To: <478BF348.3080309@uvic.ca>
Message-ID: <569895.79461.qm@web50604.mail.re2.yahoo.com>

Hello Carson,

See the SKATER software at
http://www.est.ufmg.br/leste/skater.htm
The SKATER is a Spatial 'K'luster Analisys by Tree
Edge Removal. In future, this method also be available
in R.

Best,
Elias.

--- Carson Farmer <cfarmer at uvic.ca> escreveu:

> Hello List,
> 
> I am trying to find an R package that will
> accommodate spatially 
> constrained clustering.  While I have been unable to
> find a package that 
> is explicitly designed to do spatially constrained
> clustering, I was 
> wondering if anyone had found a package that would
> do constrained 
> clustering of any kind, and adapted this to spatial
> constraints?
> I have searched the R site extensively, and googled
> all night long, but 
> to no avail! I HAVE found this post:
>
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/56819.html
> but the replies did not help much.  They lead to
> several packages which 
> perform spatial clustering (such that significant
> clusters of say a 
> disease are located within a study region), however,
> what I would like 
> to do is partition a spatial (grid) dataset based on
> multiple variables, 
> taking into account their spatial locations (i.e.
> clustering is based on 
> the variables, but constrained so that clusters are
> spatially 
> contiguous).  I'm thinking mclust is probably the
> best way to go, but 
> I'm not sure where to start.
> 
> Any suggestions would be greatly appreciated.
> 
> Thanks,
> 
> Carson
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 


Elias T. Krainski



From giohappy at gmail.com  Tue Jan 15 15:27:58 2008
From: giohappy at gmail.com (G. Allegri)
Date: Tue, 15 Jan 2008 15:27:58 +0100
Subject: [R-sig-Geo] regression kriging in gstat with skewed distributions
Message-ID: <e12429640801150627q7266a599g77a3df9744edb153@mail.gmail.com>

I'm trying to realize e regression kriging with gstat package on my
soil samples data. The response variable (ECe measuere) and covariates
appear positvely skewed.
As Tomislav Hengl suggests in its "framework for RK" [1], a logistic
transformation is proposed as a generic way to reduce the skeweness by
using the physical limits of the data.
Is it really a transformation that can be applied in the generic case
of skewed datas? I mean,in my case I have non-normal residuals (from
original data regression), and I'm trying to transform the residuals
(and not the original values) to do SK on them . Is this approach
correct?

A related question is how to do normal score transformations (for my
residuals) in R and gstat. I know gstat doesn't manage transformations
and back-transformations, so it should be done previously in R... but
I can't find any package that permit it in a straisghtforward way.
I've found something with qqnorm(ppoints(data)) and the approx()
function. Is that all?

Giovanni


[1] "A generic framework for spatial prediction of soil variables
based on regressionkriging" Geoderma 122 (1?2), 75?93.



From vacates at patiencegroup.com  Tue Jan 15 19:25:16 2008
From: vacates at patiencegroup.com (vacates at patiencegroup.com)
Date: Tue, 15 Jan 2008 19:25:16 +0100
Subject: [R-sig-Geo] I Would Dream
Message-ID: <478CFA8C.7030508@patiencegroup.com>

Kisses Through E-mail http://86.123.21.76/



From giohappy at gmail.com  Wed Jan 16 11:04:53 2008
From: giohappy at gmail.com (G. Allegri)
Date: Wed, 16 Jan 2008 11:04:53 +0100
Subject: [R-sig-Geo] R from cgi and Xvfb
Message-ID: <e12429640801160204h3532ddb9t624b4f6ef658c975@mail.gmail.com>

Hi everyone.
I'm sorry for the question maybe OT.
I'm trying to use R and Python to run some scripts via web interface.
I've successfully setup mod_python for Apache and the rpy module.
R needs X11 to use png() and jpeg() devices, so I have installed Xvfb
(X virtual framebuffer). I works correctly: if I set the DISPLAY
variable to point to this X server, rpy can create png files correctly
from command-line, but it doesn't work when the python script is run
from web browser.
I restarted Apache after setting the DISPLAY variable, but the
Traceback gives me always the same error, about being not able to open
the X11 device?

Does anyone have made it work right?
How can tell Apache to run R script and forwarding X requests to my Xvfb.

Thanks,
Giovanni



From hengl at science.uva.nl  Wed Jan 16 11:08:28 2008
From: hengl at science.uva.nl (Tomislav Hengl)
Date: Wed, 16 Jan 2008 11:08:28 +0100
Subject: [R-sig-Geo] regression kriging in gstat with skewed
	distributions
In-Reply-To: <e12429640801150627q7266a599g77a3df9744edb153@mail.gmail.com>
Message-ID: <001401c85827$bdac65a0$3a871291@pcibed193>


Dear Giovanni,

Logit transformation can be automatically applied to any variables which has a lower and upper
physical limits (e.g. 0-100%). In R, you can transform a variable to logits by e.g.:

> points = read.dbf("points.dbf")
> points$SANDt = log((points$SAND/100)/(1-(points$SAND/100)))

After you interpolate your variable, you can back-transform the values by using:

> SAND.rk = krige(fsand$call$formula, points[sel,], SPC, sand.rvgm)

> SAND.rk$pred=exp(SAND.rk$var1.pred)/(1+exp(SAND.rk$var1.pred))*100

The prediction variance can not be back-transformed, but you can use the normalized prediction
variance by dividing it with the sampled variance. See also section 4.2.1 of my lecture notes
(http://geostat.pedometrics.org/).

There are many transformations that can be applied to force a normality of your target variable (see
e.g. http://en.wikipedia.org/wiki/Data_transformation_(statistics) ). The most generic
transformation is to work with the probability density function values (see e.g.
http://dx.doi.org/10.1016/j.jneumeth.2006.11.004 ), this way you do not have to think about how the
histogram looks at all. But then the interpretation of the regression plots becomes rather
difficult. 

In any case, you should apply the transformation already to the target variable because also a
requirement for linear regression is that the residuals are normally distributed around the
regression line.


see also:
FITTING DISTRIBUTIONS WITH R (by Vito Ricci)
http://cran.r-project.org/doc/contrib/Ricci-distributions-en.pdf


Tom Hengl
http://spatial-analyst.net 


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
G. Allegri
Sent: dinsdag 15 januari 2008 15:28
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] regression kriging in gstat with skewed distributions

I'm trying to realize e regression kriging with gstat package on my
soil samples data. The response variable (ECe measuere) and covariates
appear positvely skewed.
As Tomislav Hengl suggests in its "framework for RK" [1], a logistic
transformation is proposed as a generic way to reduce the skeweness by
using the physical limits of the data.
Is it really a transformation that can be applied in the generic case
of skewed datas? I mean,in my case I have non-normal residuals (from
original data regression), and I'm trying to transform the residuals
(and not the original values) to do SK on them . Is this approach
correct?

A related question is how to do normal score transformations (for my
residuals) in R and gstat. I know gstat doesn't manage transformations
and back-transformations, so it should be done previously in R... but
I can't find any package that permit it in a straisghtforward way.
I've found something with qqnorm(ppoints(data)) and the approx()
function. Is that all?

Giovanni


[1] "A generic framework for spatial prediction of soil variables
based on regressionkriging" Geoderma 122 (1?2), 75?93.

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From giohappy at gmail.com  Wed Jan 16 14:00:21 2008
From: giohappy at gmail.com (G. Allegri)
Date: Wed, 16 Jan 2008 14:00:21 +0100
Subject: [R-sig-Geo] regression kriging in gstat with skewed
	distributions
In-Reply-To: <001401c85827$bdac65a0$3a871291@pcibed193>
References: <e12429640801150627q7266a599g77a3df9744edb153@mail.gmail.com>
	<001401c85827$bdac65a0$3a871291@pcibed193>
Message-ID: <e12429640801160500w65990532rbaf59f5185bc4d5e@mail.gmail.com>

Thank you Tomislav.
I will try the logit transformation, but an interesting evaluation is
to confront the results reached with a normal score transformation.
Wouldn't this one be better suited for a generic transformation
method?
I know that GSLIB already manages it, but in R I don't know how to do
it. qqnorm(ppoints(my_data)) seems to transform, but
back-transormation is not documented.

Giovanni

2008/1/16, Tomislav Hengl <hengl at science.uva.nl>:
>
> Dear Giovanni,
>
> Logit transformation can be automatically applied to any variables which has a lower and upper
> physical limits (e.g. 0-100%). In R, you can transform a variable to logits by e.g.:
>
> > points = read.dbf("points.dbf")
> > points$SANDt = log((points$SAND/100)/(1-(points$SAND/100)))
>
> After you interpolate your variable, you can back-transform the values by using:
>
> > SAND.rk = krige(fsand$call$formula, points[sel,], SPC, sand.rvgm)
>
> > SAND.rk$pred=exp(SAND.rk$var1.pred)/(1+exp(SAND.rk$var1.pred))*100
>
> The prediction variance can not be back-transformed, but you can use the normalized prediction
> variance by dividing it with the sampled variance. See also section 4.2.1 of my lecture notes
> (http://geostat.pedometrics.org/).
>
> There are many transformations that can be applied to force a normality of your target variable (see
> e.g. http://en.wikipedia.org/wiki/Data_transformation_(statistics) ). The most generic
> transformation is to work with the probability density function values (see e.g.
> http://dx.doi.org/10.1016/j.jneumeth.2006.11.004 ), this way you do not have to think about how the
> histogram looks at all. But then the interpretation of the regression plots becomes rather
> difficult.
>
> In any case, you should apply the transformation already to the target variable because also a
> requirement for linear regression is that the residuals are normally distributed around the
> regression line.
>
>
> see also:
> FITTING DISTRIBUTIONS WITH R (by Vito Ricci)
> http://cran.r-project.org/doc/contrib/Ricci-distributions-en.pdf
>
>
> Tom Hengl
> http://spatial-analyst.net
>
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
> G. Allegri
> Sent: dinsdag 15 januari 2008 15:28
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] regression kriging in gstat with skewed distributions
>
> I'm trying to realize e regression kriging with gstat package on my
> soil samples data. The response variable (ECe measuere) and covariates
> appear positvely skewed.
> As Tomislav Hengl suggests in its "framework for RK" [1], a logistic
> transformation is proposed as a generic way to reduce the skeweness by
> using the physical limits of the data.
> Is it really a transformation that can be applied in the generic case
> of skewed datas? I mean,in my case I have non-normal residuals (from
> original data regression), and I'm trying to transform the residuals
> (and not the original values) to do SK on them . Is this approach
> correct?
>
> A related question is how to do normal score transformations (for my
> residuals) in R and gstat. I know gstat doesn't manage transformations
> and back-transformations, so it should be done previously in R... but
> I can't find any package that permit it in a straisghtforward way.
> I've found something with qqnorm(ppoints(data)) and the approx()
> function. Is that all?
>
> Giovanni
>
>
> [1] "A generic framework for spatial prediction of soil variables
> based on regressionkriging" Geoderma 122 (1?2), 75?93.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>



From moliveira at GEOSTATS.com  Wed Jan 16 14:00:29 2008
From: moliveira at GEOSTATS.com (Marcelo Oliveira)
Date: Wed, 16 Jan 2008 08:00:29 -0500
Subject: [R-sig-Geo] 4. R from cgi and Xvfb (G. Allegri)
References: <mailman.9.1200481202.28806.r-sig-geo@stat.math.ethz.ch>
Message-ID: <106F9C96E2CC5D4382760C42E3751A962A4F5E@drake.GEOSTATS.com>

Giovanni,

This issue could be related to user permissions.  See if you can get
Apache running under a user with display access rights.

Good Luck,

Marcelo

-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
r-sig-geo-request at stat.math.ethz.ch
Sent: Wednesday, January 16, 2008 6:00 AM
To: r-sig-geo at stat.math.ethz.ch
Subject: R-sig-Geo Digest, Vol 53, Issue 14

Send R-sig-Geo mailing list submissions to
	r-sig-geo at stat.math.ethz.ch

To subscribe or unsubscribe via the World Wide Web, visit
	https://stat.ethz.ch/mailman/listinfo/r-sig-geo
or, via email, send a message with subject or body 'help' to
	r-sig-geo-request at stat.math.ethz.ch

You can reach the person managing the list at
	r-sig-geo-owner at stat.math.ethz.ch

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-Geo digest..."


Today's Topics:

   1. Re: Spatially Constrained Clustering (Elias T. Krainski)
   2. regression kriging in gstat with skewed distributions (G. Allegri)
   3. I Would Dream (vacates at patiencegroup.com)
   4. R from cgi and Xvfb (G. Allegri)
   5. Re: regression kriging in gstat with skewed	distributions
      (Tomislav Hengl)


----------------------------------------------------------------------

Message: 1
Date: Tue, 15 Jan 2008 10:51:48 -0300 (ART)
From: "Elias T. Krainski" <eliaskrainski at yahoo.com.br>
Subject: Re: [R-sig-Geo] Spatially Constrained Clustering
To: r-sig-geo at stat.math.ethz.ch
Message-ID: <569895.79461.qm at web50604.mail.re2.yahoo.com>
Content-Type: text/plain; charset=iso-8859-1

Hello Carson,

See the SKATER software at
http://www.est.ufmg.br/leste/skater.htm
The SKATER is a Spatial 'K'luster Analisys by Tree
Edge Removal. In future, this method also be available
in R.

Best,
Elias.

--- Carson Farmer <cfarmer at uvic.ca> escreveu:

> Hello List,
> 
> I am trying to find an R package that will
> accommodate spatially 
> constrained clustering.  While I have been unable to
> find a package that 
> is explicitly designed to do spatially constrained
> clustering, I was 
> wondering if anyone had found a package that would
> do constrained 
> clustering of any kind, and adapted this to spatial
> constraints?
> I have searched the R site extensively, and googled
> all night long, but 
> to no avail! I HAVE found this post:
>
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/56819.html
> but the replies did not help much.  They lead to
> several packages which 
> perform spatial clustering (such that significant
> clusters of say a 
> disease are located within a study region), however,
> what I would like 
> to do is partition a spatial (grid) dataset based on
> multiple variables, 
> taking into account their spatial locations (i.e.
> clustering is based on 
> the variables, but constrained so that clusters are
> spatially 
> contiguous).  I'm thinking mclust is probably the
> best way to go, but 
> I'm not sure where to start.
> 
> Any suggestions would be greatly appreciated.
> 
> Thanks,
> 
> Carson
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 


Elias T. Krainski



------------------------------

Message: 2
Date: Tue, 15 Jan 2008 15:27:58 +0100
From: "G. Allegri" <giohappy at gmail.com>
Subject: [R-sig-Geo] regression kriging in gstat with skewed
	distributions
To: r-sig-geo at stat.math.ethz.ch
Message-ID:
	<e12429640801150627q7266a599g77a3df9744edb153 at mail.gmail.com>
Content-Type: text/plain; charset=WINDOWS-1252

I'm trying to realize e regression kriging with gstat package on my
soil samples data. The response variable (ECe measuere) and covariates
appear positvely skewed.
As Tomislav Hengl suggests in its "framework for RK" [1], a logistic
transformation is proposed as a generic way to reduce the skeweness by
using the physical limits of the data.
Is it really a transformation that can be applied in the generic case
of skewed datas? I mean,in my case I have non-normal residuals (from
original data regression), and I'm trying to transform the residuals
(and not the original values) to do SK on them . Is this approach
correct?

A related question is how to do normal score transformations (for my
residuals) in R and gstat. I know gstat doesn't manage transformations
and back-transformations, so it should be done previously in R... but
I can't find any package that permit it in a straisghtforward way.
I've found something with qqnorm(ppoints(data)) and the approx()
function. Is that all?

Giovanni


[1] "A generic framework for spatial prediction of soil variables
based on regressionkriging" Geoderma 122 (1?2), 75?93.



------------------------------

Message: 3
Date: Tue, 15 Jan 2008 19:25:16 +0100
From: <vacates at patiencegroup.com>
Subject: [R-sig-Geo] I Would Dream
To: r-sig-geo at stat.math.ethz.ch
Message-ID: <478CFA8C.7030508 at patiencegroup.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

Kisses Through E-mail http://86.123.21.76/



------------------------------

Message: 4
Date: Wed, 16 Jan 2008 11:04:53 +0100
From: "G. Allegri" <giohappy at gmail.com>
Subject: [R-sig-Geo] R from cgi and Xvfb
To: r-sig-geo at stat.math.ethz.ch
Message-ID:
	<e12429640801160204h3532ddb9t624b4f6ef658c975 at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

Hi everyone.
I'm sorry for the question maybe OT.
I'm trying to use R and Python to run some scripts via web interface.
I've successfully setup mod_python for Apache and the rpy module.
R needs X11 to use png() and jpeg() devices, so I have installed Xvfb
(X virtual framebuffer). I works correctly: if I set the DISPLAY
variable to point to this X server, rpy can create png files correctly
from command-line, but it doesn't work when the python script is run
from web browser.
I restarted Apache after setting the DISPLAY variable, but the
Traceback gives me always the same error, about being not able to open
the X11 device?

Does anyone have made it work right?
How can tell Apache to run R script and forwarding X requests to my
Xvfb.

Thanks,
Giovanni



------------------------------

Message: 5
Date: Wed, 16 Jan 2008 11:08:28 +0100
From: "Tomislav Hengl" <hengl at science.uva.nl>
Subject: Re: [R-sig-Geo] regression kriging in gstat with skewed
	distributions
To: "'G. Allegri'" <giohappy at gmail.com>
Cc: r-sig-geo at stat.math.ethz.ch
Message-ID: <001401c85827$bdac65a0$3a871291 at pcibed193>
Content-Type: text/plain;	charset="windows-1250"


Dear Giovanni,

Logit transformation can be automatically applied to any variables which
has a lower and upper
physical limits (e.g. 0-100%). In R, you can transform a variable to
logits by e.g.:

> points = read.dbf("points.dbf")
> points$SANDt = log((points$SAND/100)/(1-(points$SAND/100)))

After you interpolate your variable, you can back-transform the values
by using:

> SAND.rk = krige(fsand$call$formula, points[sel,], SPC, sand.rvgm)

> SAND.rk$pred=exp(SAND.rk$var1.pred)/(1+exp(SAND.rk$var1.pred))*100

The prediction variance can not be back-transformed, but you can use the
normalized prediction
variance by dividing it with the sampled variance. See also section
4.2.1 of my lecture notes
(http://geostat.pedometrics.org/).

There are many transformations that can be applied to force a normality
of your target variable (see
e.g. http://en.wikipedia.org/wiki/Data_transformation_(statistics) ).
The most generic
transformation is to work with the probability density function values
(see e.g.
http://dx.doi.org/10.1016/j.jneumeth.2006.11.004 ), this way you do not
have to think about how the
histogram looks at all. But then the interpretation of the regression
plots becomes rather
difficult. 

In any case, you should apply the transformation already to the target
variable because also a
requirement for linear regression is that the residuals are normally
distributed around the
regression line.


see also:
FITTING DISTRIBUTIONS WITH R (by Vito Ricci)
http://cran.r-project.org/doc/contrib/Ricci-distributions-en.pdf


Tom Hengl
http://spatial-analyst.net 


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
G. Allegri
Sent: dinsdag 15 januari 2008 15:28
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] regression kriging in gstat with skewed
distributions

I'm trying to realize e regression kriging with gstat package on my
soil samples data. The response variable (ECe measuere) and covariates
appear positvely skewed.
As Tomislav Hengl suggests in its "framework for RK" [1], a logistic
transformation is proposed as a generic way to reduce the skeweness by
using the physical limits of the data.
Is it really a transformation that can be applied in the generic case
of skewed datas? I mean,in my case I have non-normal residuals (from
original data regression), and I'm trying to transform the residuals
(and not the original values) to do SK on them . Is this approach
correct?

A related question is how to do normal score transformations (for my
residuals) in R and gstat. I know gstat doesn't manage transformations
and back-transformations, so it should be done previously in R... but
I can't find any package that permit it in a straisghtforward way.
I've found something with qqnorm(ppoints(data)) and the approx()
function. Is that all?

Giovanni


[1] "A generic framework for spatial prediction of soil variables
based on regressionkriging" Geoderma 122 (1?2), 75?93.

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



------------------------------

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


End of R-sig-Geo Digest, Vol 53, Issue 14



From giohappy at gmail.com  Wed Jan 16 14:15:15 2008
From: giohappy at gmail.com (G. Allegri)
Date: Wed, 16 Jan 2008 14:15:15 +0100
Subject: [R-sig-Geo] 4. R from cgi and Xvfb (G. Allegri)
In-Reply-To: <106F9C96E2CC5D4382760C42E3751A962A4F5E@drake.GEOSTATS.com>
References: <mailman.9.1200481202.28806.r-sig-geo@stat.math.ethz.ch>
	<106F9C96E2CC5D4382760C42E3751A962A4F5E@drake.GEOSTATS.com>
Message-ID: <e12429640801160515m607e0387ufb840dc1ecff12c6@mail.gmail.com>

Thanks Marcelo,
I've tried using the suexec module in apache2 (it permits to change
userid and groupid on the base of the scripts called), but from
documentation appears to work only for CGI and SSI, not with
mod_python.
So, I change mailing-list, since the problem is almost OT now in this one :-)

Giovanni

2008/1/16, Marcelo Oliveira <moliveira at geostats.com>:
> Giovanni,
>
> This issue could be related to user permissions.  See if you can get
> Apache running under a user with display access rights.
>
> Good Luck,
>
> Marcelo
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
> r-sig-geo-request at stat.math.ethz.ch
> Sent: Wednesday, January 16, 2008 6:00 AM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: R-sig-Geo Digest, Vol 53, Issue 14
>
> Send R-sig-Geo mailing list submissions to
>         r-sig-geo at stat.math.ethz.ch
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> or, via email, send a message with subject or body 'help' to
>         r-sig-geo-request at stat.math.ethz.ch
>
> You can reach the person managing the list at
>         r-sig-geo-owner at stat.math.ethz.ch
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-Geo digest..."
>
>
> Today's Topics:
>
>    1. Re: Spatially Constrained Clustering (Elias T. Krainski)
>    2. regression kriging in gstat with skewed distributions (G. Allegri)
>    3. I Would Dream (vacates at patiencegroup.com)
>    4. R from cgi and Xvfb (G. Allegri)
>    5. Re: regression kriging in gstat with skewed       distributions
>       (Tomislav Hengl)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Tue, 15 Jan 2008 10:51:48 -0300 (ART)
> From: "Elias T. Krainski" <eliaskrainski at yahoo.com.br>
> Subject: Re: [R-sig-Geo] Spatially Constrained Clustering
> To: r-sig-geo at stat.math.ethz.ch
> Message-ID: <569895.79461.qm at web50604.mail.re2.yahoo.com>
> Content-Type: text/plain; charset=iso-8859-1
>
> Hello Carson,
>
> See the SKATER software at
> http://www.est.ufmg.br/leste/skater.htm
> The SKATER is a Spatial 'K'luster Analisys by Tree
> Edge Removal. In future, this method also be available
> in R.
>
> Best,
> Elias.
>
> --- Carson Farmer <cfarmer at uvic.ca> escreveu:
>
> > Hello List,
> >
> > I am trying to find an R package that will
> > accommodate spatially
> > constrained clustering.  While I have been unable to
> > find a package that
> > is explicitly designed to do spatially constrained
> > clustering, I was
> > wondering if anyone had found a package that would
> > do constrained
> > clustering of any kind, and adapted this to spatial
> > constraints?
> > I have searched the R site extensively, and googled
> > all night long, but
> > to no avail! I HAVE found this post:
> >
> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/56819.html
> > but the replies did not help much.  They lead to
> > several packages which
> > perform spatial clustering (such that significant
> > clusters of say a
> > disease are located within a study region), however,
> > what I would like
> > to do is partition a spatial (grid) dataset based on
> > multiple variables,
> > taking into account their spatial locations (i.e.
> > clustering is based on
> > the variables, but constrained so that clusters are
> > spatially
> > contiguous).  I'm thinking mclust is probably the
> > best way to go, but
> > I'm not sure where to start.
> >
> > Any suggestions would be greatly appreciated.
> >
> > Thanks,
> >
> > Carson
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
>
> Elias T. Krainski
>
>
>
> ------------------------------
>
> Message: 2
> Date: Tue, 15 Jan 2008 15:27:58 +0100
> From: "G. Allegri" <giohappy at gmail.com>
> Subject: [R-sig-Geo] regression kriging in gstat with skewed
>         distributions
> To: r-sig-geo at stat.math.ethz.ch
> Message-ID:
>         <e12429640801150627q7266a599g77a3df9744edb153 at mail.gmail.com>
> Content-Type: text/plain; charset=WINDOWS-1252
>
> I'm trying to realize e regression kriging with gstat package on my
> soil samples data. The response variable (ECe measuere) and covariates
> appear positvely skewed.
> As Tomislav Hengl suggests in its "framework for RK" [1], a logistic
> transformation is proposed as a generic way to reduce the skeweness by
> using the physical limits of the data.
> Is it really a transformation that can be applied in the generic case
> of skewed datas? I mean,in my case I have non-normal residuals (from
> original data regression), and I'm trying to transform the residuals
> (and not the original values) to do SK on them . Is this approach
> correct?
>
> A related question is how to do normal score transformations (for my
> residuals) in R and gstat. I know gstat doesn't manage transformations
> and back-transformations, so it should be done previously in R... but
> I can't find any package that permit it in a straisghtforward way.
> I've found something with qqnorm(ppoints(data)) and the approx()
> function. Is that all?
>
> Giovanni
>
>
> [1] "A generic framework for spatial prediction of soil variables
> based on regressionkriging" Geoderma 122 (1?2), 75?93.
>
>
>
> ------------------------------
>
> Message: 3
> Date: Tue, 15 Jan 2008 19:25:16 +0100
> From: <vacates at patiencegroup.com>
> Subject: [R-sig-Geo] I Would Dream
> To: r-sig-geo at stat.math.ethz.ch
> Message-ID: <478CFA8C.7030508 at patiencegroup.com>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> Kisses Through E-mail http://86.123.21.76/
>
>
>
> ------------------------------
>
> Message: 4
> Date: Wed, 16 Jan 2008 11:04:53 +0100
> From: "G. Allegri" <giohappy at gmail.com>
> Subject: [R-sig-Geo] R from cgi and Xvfb
> To: r-sig-geo at stat.math.ethz.ch
> Message-ID:
>         <e12429640801160204h3532ddb9t624b4f6ef658c975 at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
>
> Hi everyone.
> I'm sorry for the question maybe OT.
> I'm trying to use R and Python to run some scripts via web interface.
> I've successfully setup mod_python for Apache and the rpy module.
> R needs X11 to use png() and jpeg() devices, so I have installed Xvfb
> (X virtual framebuffer). I works correctly: if I set the DISPLAY
> variable to point to this X server, rpy can create png files correctly
> from command-line, but it doesn't work when the python script is run
> from web browser.
> I restarted Apache after setting the DISPLAY variable, but the
> Traceback gives me always the same error, about being not able to open
> the X11 device?
>
> Does anyone have made it work right?
> How can tell Apache to run R script and forwarding X requests to my
> Xvfb.
>
> Thanks,
> Giovanni
>
>
>
> ------------------------------
>
> Message: 5
> Date: Wed, 16 Jan 2008 11:08:28 +0100
> From: "Tomislav Hengl" <hengl at science.uva.nl>
> Subject: Re: [R-sig-Geo] regression kriging in gstat with skewed
>         distributions
> To: "'G. Allegri'" <giohappy at gmail.com>
> Cc: r-sig-geo at stat.math.ethz.ch
> Message-ID: <001401c85827$bdac65a0$3a871291 at pcibed193>
> Content-Type: text/plain;       charset="windows-1250"
>
>
> Dear Giovanni,
>
> Logit transformation can be automatically applied to any variables which
> has a lower and upper
> physical limits (e.g. 0-100%). In R, you can transform a variable to
> logits by e.g.:
>
> > points = read.dbf("points.dbf")
> > points$SANDt = log((points$SAND/100)/(1-(points$SAND/100)))
>
> After you interpolate your variable, you can back-transform the values
> by using:
>
> > SAND.rk = krige(fsand$call$formula, points[sel,], SPC, sand.rvgm)
>
> > SAND.rk$pred=exp(SAND.rk$var1.pred)/(1+exp(SAND.rk$var1.pred))*100
>
> The prediction variance can not be back-transformed, but you can use the
> normalized prediction
> variance by dividing it with the sampled variance. See also section
> 4.2.1 of my lecture notes
> (http://geostat.pedometrics.org/).
>
> There are many transformations that can be applied to force a normality
> of your target variable (see
> e.g. http://en.wikipedia.org/wiki/Data_transformation_(statistics) ).
> The most generic
> transformation is to work with the probability density function values
> (see e.g.
> http://dx.doi.org/10.1016/j.jneumeth.2006.11.004 ), this way you do not
> have to think about how the
> histogram looks at all. But then the interpretation of the regression
> plots becomes rather
> difficult.
>
> In any case, you should apply the transformation already to the target
> variable because also a
> requirement for linear regression is that the residuals are normally
> distributed around the
> regression line.
>
>
> see also:
> FITTING DISTRIBUTIONS WITH R (by Vito Ricci)
> http://cran.r-project.org/doc/contrib/Ricci-distributions-en.pdf
>
>
> Tom Hengl
> http://spatial-analyst.net
>
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
> G. Allegri
> Sent: dinsdag 15 januari 2008 15:28
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] regression kriging in gstat with skewed
> distributions
>
> I'm trying to realize e regression kriging with gstat package on my
> soil samples data. The response variable (ECe measuere) and covariates
> appear positvely skewed.
> As Tomislav Hengl suggests in its "framework for RK" [1], a logistic
> transformation is proposed as a generic way to reduce the skeweness by
> using the physical limits of the data.
> Is it really a transformation that can be applied in the generic case
> of skewed datas? I mean,in my case I have non-normal residuals (from
> original data regression), and I'm trying to transform the residuals
> (and not the original values) to do SK on them . Is this approach
> correct?
>
> A related question is how to do normal score transformations (for my
> residuals) in R and gstat. I know gstat doesn't manage transformations
> and back-transformations, so it should be done previously in R... but
> I can't find any package that permit it in a straisghtforward way.
> I've found something with qqnorm(ppoints(data)) and the approx()
> function. Is that all?
>
> Giovanni
>
>
> [1] "A generic framework for spatial prediction of soil variables
> based on regressionkriging" Geoderma 122 (1?2), 75?93.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> End of R-sig-Geo Digest, Vol 53, Issue 14
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From ahimsa at camposarceiz.com  Wed Jan 16 15:18:12 2008
From: ahimsa at camposarceiz.com (ahimsa campos-arceiz)
Date: Wed, 16 Jan 2008 23:18:12 +0900
Subject: [R-sig-Geo] LL into national grid system,
	discrepancy between spTransform and Geocalc
Message-ID: <45e920ef0801160618s5d23ddd3l58237f100c650660@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080116/2b1293d1/attachment.pl>

From p.hiemstra at geo.uu.nl  Wed Jan 16 15:45:08 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Wed, 16 Jan 2008 15:45:08 +0100
Subject: [R-sig-Geo] 4. R from cgi and Xvfb (G. Allegri)
In-Reply-To: <e12429640801160515m607e0387ufb840dc1ecff12c6@mail.gmail.com>
References: <mailman.9.1200481202.28806.r-sig-geo@stat.math.ethz.ch>	<106F9C96E2CC5D4382760C42E3751A962A4F5E@drake.GEOSTATS.com>
	<e12429640801160515m607e0387ufb840dc1ecff12c6@mail.gmail.com>
Message-ID: <478E1874.3030905@geo.uu.nl>

Hi Giovanni,

You could consider using 'bitmap()' instead of png(). I seem to remember 
that the first uses postscript devices and does not need X11. Another 
options would be to use the Cairo package, 'Cairo' initializes a new 
graphics device that uses the cairo graphics library for rendering. See 
?bitmap and ?Cairo.

Hope this helps,

Paul

G. Allegri wrote:
> Thanks Marcelo,
> I've tried using the suexec module in apache2 (it permits to change
> userid and groupid on the base of the scripts called), but from
> documentation appears to work only for CGI and SSI, not with
> mod_python.
> So, I change mailing-list, since the problem is almost OT now in this one :-)
>
> Giovanni
>
> 2008/1/16, Marcelo Oliveira <moliveira at geostats.com>:
>   
>> Giovanni,
>>
>> This issue could be related to user permissions.  See if you can get
>> Apache running under a user with display access rights.
>>
>> Good Luck,
>>
>> Marcelo
>>
>> -----Original Message-----
>> From: r-sig-geo-bounces at stat.math.ethz.ch
>> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
>> r-sig-geo-request at stat.math.ethz.ch
>> Sent: Wednesday, January 16, 2008 6:00 AM
>> To: r-sig-geo at stat.math.ethz.ch
>> Subject: R-sig-Geo Digest, Vol 53, Issue 14
>>
>> Send R-sig-Geo mailing list submissions to
>>         r-sig-geo at stat.math.ethz.ch
>>
>> To subscribe or unsubscribe via the World Wide Web, visit
>>         https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> or, via email, send a message with subject or body 'help' to
>>         r-sig-geo-request at stat.math.ethz.ch
>>
>> You can reach the person managing the list at
>>         r-sig-geo-owner at stat.math.ethz.ch
>>
>> When replying, please edit your Subject line so it is more specific
>> than "Re: Contents of R-sig-Geo digest..."
>>
>>
>> Today's Topics:
>>
>>    1. Re: Spatially Constrained Clustering (Elias T. Krainski)
>>    2. regression kriging in gstat with skewed distributions (G. Allegri)
>>    3. I Would Dream (vacates at patiencegroup.com)
>>    4. R from cgi and Xvfb (G. Allegri)
>>    5. Re: regression kriging in gstat with skewed       distributions
>>       (Tomislav Hengl)
>>
>>
>> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Tue, 15 Jan 2008 10:51:48 -0300 (ART)
>> From: "Elias T. Krainski" <eliaskrainski at yahoo.com.br>
>> Subject: Re: [R-sig-Geo] Spatially Constrained Clustering
>> To: r-sig-geo at stat.math.ethz.ch
>> Message-ID: <569895.79461.qm at web50604.mail.re2.yahoo.com>
>> Content-Type: text/plain; charset=iso-8859-1
>>
>> Hello Carson,
>>
>> See the SKATER software at
>> http://www.est.ufmg.br/leste/skater.htm
>> The SKATER is a Spatial 'K'luster Analisys by Tree
>> Edge Removal. In future, this method also be available
>> in R.
>>
>> Best,
>> Elias.
>>
>> --- Carson Farmer <cfarmer at uvic.ca> escreveu:
>>
>>     
>>> Hello List,
>>>
>>> I am trying to find an R package that will
>>> accommodate spatially
>>> constrained clustering.  While I have been unable to
>>> find a package that
>>> is explicitly designed to do spatially constrained
>>> clustering, I was
>>> wondering if anyone had found a package that would
>>> do constrained
>>> clustering of any kind, and adapted this to spatial
>>> constraints?
>>> I have searched the R site extensively, and googled
>>> all night long, but
>>> to no avail! I HAVE found this post:
>>>
>>>       
>> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/56819.html
>>     
>>> but the replies did not help much.  They lead to
>>> several packages which
>>> perform spatial clustering (such that significant
>>> clusters of say a
>>> disease are located within a study region), however,
>>> what I would like
>>> to do is partition a spatial (grid) dataset based on
>>> multiple variables,
>>> taking into account their spatial locations (i.e.
>>> clustering is based on
>>> the variables, but constrained so that clusters are
>>> spatially
>>> contiguous).  I'm thinking mclust is probably the
>>> best way to go, but
>>> I'm not sure where to start.
>>>
>>> Any suggestions would be greatly appreciated.
>>>
>>> Thanks,
>>>
>>> Carson
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>       
>> Elias T. Krainski
>>
>>
>>
>> ------------------------------
>>
>> Message: 2
>> Date: Tue, 15 Jan 2008 15:27:58 +0100
>> From: "G. Allegri" <giohappy at gmail.com>
>> Subject: [R-sig-Geo] regression kriging in gstat with skewed
>>         distributions
>> To: r-sig-geo at stat.math.ethz.ch
>> Message-ID:
>>         <e12429640801150627q7266a599g77a3df9744edb153 at mail.gmail.com>
>> Content-Type: text/plain; charset=WINDOWS-1252
>>
>> I'm trying to realize e regression kriging with gstat package on my
>> soil samples data. The response variable (ECe measuere) and covariates
>> appear positvely skewed.
>> As Tomislav Hengl suggests in its "framework for RK" [1], a logistic
>> transformation is proposed as a generic way to reduce the skeweness by
>> using the physical limits of the data.
>> Is it really a transformation that can be applied in the generic case
>> of skewed datas? I mean,in my case I have non-normal residuals (from
>> original data regression), and I'm trying to transform the residuals
>> (and not the original values) to do SK on them . Is this approach
>> correct?
>>
>> A related question is how to do normal score transformations (for my
>> residuals) in R and gstat. I know gstat doesn't manage transformations
>> and back-transformations, so it should be done previously in R... but
>> I can't find any package that permit it in a straisghtforward way.
>> I've found something with qqnorm(ppoints(data)) and the approx()
>> function. Is that all?
>>
>> Giovanni
>>
>>
>> [1] "A generic framework for spatial prediction of soil variables
>> based on regressionkriging" Geoderma 122 (1?2), 75?93.
>>
>>
>>
>> ------------------------------
>>
>> Message: 3
>> Date: Tue, 15 Jan 2008 19:25:16 +0100
>> From: <vacates at patiencegroup.com>
>> Subject: [R-sig-Geo] I Would Dream
>> To: r-sig-geo at stat.math.ethz.ch
>> Message-ID: <478CFA8C.7030508 at patiencegroup.com>
>> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>
>> Kisses Through E-mail http://86.123.21.76/
>>
>>
>>
>> ------------------------------
>>
>> Message: 4
>> Date: Wed, 16 Jan 2008 11:04:53 +0100
>> From: "G. Allegri" <giohappy at gmail.com>
>> Subject: [R-sig-Geo] R from cgi and Xvfb
>> To: r-sig-geo at stat.math.ethz.ch
>> Message-ID:
>>         <e12429640801160204h3532ddb9t624b4f6ef658c975 at mail.gmail.com>
>> Content-Type: text/plain; charset=ISO-8859-1
>>
>> Hi everyone.
>> I'm sorry for the question maybe OT.
>> I'm trying to use R and Python to run some scripts via web interface.
>> I've successfully setup mod_python for Apache and the rpy module.
>> R needs X11 to use png() and jpeg() devices, so I have installed Xvfb
>> (X virtual framebuffer). I works correctly: if I set the DISPLAY
>> variable to point to this X server, rpy can create png files correctly
>> from command-line, but it doesn't work when the python script is run
>> from web browser.
>> I restarted Apache after setting the DISPLAY variable, but the
>> Traceback gives me always the same error, about being not able to open
>> the X11 device?
>>
>> Does anyone have made it work right?
>> How can tell Apache to run R script and forwarding X requests to my
>> Xvfb.
>>
>> Thanks,
>> Giovanni
>>
>>
>>
>> ------------------------------
>>
>> Message: 5
>> Date: Wed, 16 Jan 2008 11:08:28 +0100
>> From: "Tomislav Hengl" <hengl at science.uva.nl>
>> Subject: Re: [R-sig-Geo] regression kriging in gstat with skewed
>>         distributions
>> To: "'G. Allegri'" <giohappy at gmail.com>
>> Cc: r-sig-geo at stat.math.ethz.ch
>> Message-ID: <001401c85827$bdac65a0$3a871291 at pcibed193>
>> Content-Type: text/plain;       charset="windows-1250"
>>
>>
>> Dear Giovanni,
>>
>> Logit transformation can be automatically applied to any variables which
>> has a lower and upper
>> physical limits (e.g. 0-100%). In R, you can transform a variable to
>> logits by e.g.:
>>
>>     
>>> points = read.dbf("points.dbf")
>>> points$SANDt = log((points$SAND/100)/(1-(points$SAND/100)))
>>>       
>> After you interpolate your variable, you can back-transform the values
>> by using:
>>
>>     
>>> SAND.rk = krige(fsand$call$formula, points[sel,], SPC, sand.rvgm)
>>>       
>>> SAND.rk$pred=exp(SAND.rk$var1.pred)/(1+exp(SAND.rk$var1.pred))*100
>>>       
>> The prediction variance can not be back-transformed, but you can use the
>> normalized prediction
>> variance by dividing it with the sampled variance. See also section
>> 4.2.1 of my lecture notes
>> (http://geostat.pedometrics.org/).
>>
>> There are many transformations that can be applied to force a normality
>> of your target variable (see
>> e.g. http://en.wikipedia.org/wiki/Data_transformation_(statistics) ).
>> The most generic
>> transformation is to work with the probability density function values
>> (see e.g.
>> http://dx.doi.org/10.1016/j.jneumeth.2006.11.004 ), this way you do not
>> have to think about how the
>> histogram looks at all. But then the interpretation of the regression
>> plots becomes rather
>> difficult.
>>
>> In any case, you should apply the transformation already to the target
>> variable because also a
>> requirement for linear regression is that the residuals are normally
>> distributed around the
>> regression line.
>>
>>
>> see also:
>> FITTING DISTRIBUTIONS WITH R (by Vito Ricci)
>> http://cran.r-project.org/doc/contrib/Ricci-distributions-en.pdf
>>
>>
>> Tom Hengl
>> http://spatial-analyst.net
>>
>>
>> -----Original Message-----
>> From: r-sig-geo-bounces at stat.math.ethz.ch
>> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
>> G. Allegri
>> Sent: dinsdag 15 januari 2008 15:28
>> To: r-sig-geo at stat.math.ethz.ch
>> Subject: [R-sig-Geo] regression kriging in gstat with skewed
>> distributions
>>
>> I'm trying to realize e regression kriging with gstat package on my
>> soil samples data. The response variable (ECe measuere) and covariates
>> appear positvely skewed.
>> As Tomislav Hengl suggests in its "framework for RK" [1], a logistic
>> transformation is proposed as a generic way to reduce the skeweness by
>> using the physical limits of the data.
>> Is it really a transformation that can be applied in the generic case
>> of skewed datas? I mean,in my case I have non-normal residuals (from
>> original data regression), and I'm trying to transform the residuals
>> (and not the original values) to do SK on them . Is this approach
>> correct?
>>
>> A related question is how to do normal score transformations (for my
>> residuals) in R and gstat. I know gstat doesn't manage transformations
>> and back-transformations, so it should be done previously in R... but
>> I can't find any package that permit it in a straisghtforward way.
>> I've found something with qqnorm(ppoints(data)) and the approx()
>> function. Is that all?
>>
>> Giovanni
>>
>>
>> [1] "A generic framework for spatial prediction of soil variables
>> based on regressionkriging" Geoderma 122 (1?2), 75?93.
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>>
>> ------------------------------
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>> End of R-sig-Geo Digest, Vol 53, Issue 14
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>     
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul



From giohappy at gmail.com  Wed Jan 16 16:14:40 2008
From: giohappy at gmail.com (G. Allegri)
Date: Wed, 16 Jan 2008 16:14:40 +0100
Subject: [R-sig-Geo] 4. R from cgi and Xvfb (G. Allegri)
In-Reply-To: <478E1874.3030905@geo.uu.nl>
References: <mailman.9.1200481202.28806.r-sig-geo@stat.math.ethz.ch>
	<106F9C96E2CC5D4382760C42E3751A962A4F5E@drake.GEOSTATS.com>
	<e12429640801160515m607e0387ufb840dc1ecff12c6@mail.gmail.com>
	<478E1874.3030905@geo.uu.nl>
Message-ID: <e12429640801160714p24211bf9y18e16d404a032d82@mail.gmail.com>

I've tried using bitmap(), but it returns this taceback:

[Wed Jan 16 16:10:05 2008] [error] [client 127.0.0.1] GPL Ghostscript
SVN PRE-RELEASE
[Wed Jan 16 16:10:05 2008] [error] [client 127.0.0.1] 8.61
[Wed Jan 16 16:10:05 2008] [error] [client 127.0.0.1] :
[Wed Jan 16 16:10:05 2008] [error] [client 127.0.0.1] **** Could not
open the file prova.png .
[Wed Jan 16 16:10:05 2008] [error] [client 127.0.0.1] GPL Ghostscript
SVN PRE-RELEASE
[Wed Jan 16 16:10:05 2008] [error] [client 127.0.0.1] 8.61
[Wed Jan 16 16:10:05 2008] [error] [client 127.0.0.1] :
[Wed Jan 16 16:10:05 2008] [error] [client 127.0.0.1] Unrecoverable
error, exit code 1

I think ghostscript is trying to access the postcript file, but isn't
able. It works perfectly out of Apache...

I try with Cairo... my last try!

2008/1/16, Paul Hiemstra <p.hiemstra at geo.uu.nl>:
> Hi Giovanni,
>
> You could consider using 'bitmap()' instead of png(). I seem to remember
> that the first uses postscript devices and does not need X11. Another
> options would be to use the Cairo package, 'Cairo' initializes a new
> graphics device that uses the cairo graphics library for rendering. See
> ?bitmap and ?Cairo.
>
> Hope this helps,
>
> Paul
>
> G. Allegri wrote:
> > Thanks Marcelo,
> > I've tried using the suexec module in apache2 (it permits to change
> > userid and groupid on the base of the scripts called), but from
> > documentation appears to work only for CGI and SSI, not with
> > mod_python.
> > So, I change mailing-list, since the problem is almost OT now in this one :-)
> >
> > Giovanni
> >
> > 2008/1/16, Marcelo Oliveira <moliveira at geostats.com>:
> >
> >> Giovanni,
> >>
> >> This issue could be related to user permissions.  See if you can get
> >> Apache running under a user with display access rights.
> >>
> >> Good Luck,
> >>
> >> Marcelo
> >>
> >> -----Original Message-----
> >> From: r-sig-geo-bounces at stat.math.ethz.ch
> >> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
> >> r-sig-geo-request at stat.math.ethz.ch
> >> Sent: Wednesday, January 16, 2008 6:00 AM
> >> To: r-sig-geo at stat.math.ethz.ch
> >> Subject: R-sig-Geo Digest, Vol 53, Issue 14
> >>
> >> Send R-sig-Geo mailing list submissions to
> >>         r-sig-geo at stat.math.ethz.ch
> >>
> >> To subscribe or unsubscribe via the World Wide Web, visit
> >>         https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >> or, via email, send a message with subject or body 'help' to
> >>         r-sig-geo-request at stat.math.ethz.ch
> >>
> >> You can reach the person managing the list at
> >>         r-sig-geo-owner at stat.math.ethz.ch
> >>
> >> When replying, please edit your Subject line so it is more specific
> >> than "Re: Contents of R-sig-Geo digest..."
> >>
> >>
> >> Today's Topics:
> >>
> >>    1. Re: Spatially Constrained Clustering (Elias T. Krainski)
> >>    2. regression kriging in gstat with skewed distributions (G. Allegri)
> >>    3. I Would Dream (vacates at patiencegroup.com)
> >>    4. R from cgi and Xvfb (G. Allegri)
> >>    5. Re: regression kriging in gstat with skewed       distributions
> >>       (Tomislav Hengl)
> >>
> >>
> >> ----------------------------------------------------------------------
> >>
> >> Message: 1
> >> Date: Tue, 15 Jan 2008 10:51:48 -0300 (ART)
> >> From: "Elias T. Krainski" <eliaskrainski at yahoo.com.br>
> >> Subject: Re: [R-sig-Geo] Spatially Constrained Clustering
> >> To: r-sig-geo at stat.math.ethz.ch
> >> Message-ID: <569895.79461.qm at web50604.mail.re2.yahoo.com>
> >> Content-Type: text/plain; charset=iso-8859-1
> >>
> >> Hello Carson,
> >>
> >> See the SKATER software at
> >> http://www.est.ufmg.br/leste/skater.htm
> >> The SKATER is a Spatial 'K'luster Analisys by Tree
> >> Edge Removal. In future, this method also be available
> >> in R.
> >>
> >> Best,
> >> Elias.
> >>
> >> --- Carson Farmer <cfarmer at uvic.ca> escreveu:
> >>
> >>
> >>> Hello List,
> >>>
> >>> I am trying to find an R package that will
> >>> accommodate spatially
> >>> constrained clustering.  While I have been unable to
> >>> find a package that
> >>> is explicitly designed to do spatially constrained
> >>> clustering, I was
> >>> wondering if anyone had found a package that would
> >>> do constrained
> >>> clustering of any kind, and adapted this to spatial
> >>> constraints?
> >>> I have searched the R site extensively, and googled
> >>> all night long, but
> >>> to no avail! I HAVE found this post:
> >>>
> >>>
> >> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/56819.html
> >>
> >>> but the replies did not help much.  They lead to
> >>> several packages which
> >>> perform spatial clustering (such that significant
> >>> clusters of say a
> >>> disease are located within a study region), however,
> >>> what I would like
> >>> to do is partition a spatial (grid) dataset based on
> >>> multiple variables,
> >>> taking into account their spatial locations (i.e.
> >>> clustering is based on
> >>> the variables, but constrained so that clusters are
> >>> spatially
> >>> contiguous).  I'm thinking mclust is probably the
> >>> best way to go, but
> >>> I'm not sure where to start.
> >>>
> >>> Any suggestions would be greatly appreciated.
> >>>
> >>> Thanks,
> >>>
> >>> Carson
> >>>
> >>> _______________________________________________
> >>> R-sig-Geo mailing list
> >>> R-sig-Geo at stat.math.ethz.ch
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>>
> >>>
> >> Elias T. Krainski
> >>
> >>
> >>
> >> ------------------------------
> >>
> >> Message: 2
> >> Date: Tue, 15 Jan 2008 15:27:58 +0100
> >> From: "G. Allegri" <giohappy at gmail.com>
> >> Subject: [R-sig-Geo] regression kriging in gstat with skewed
> >>         distributions
> >> To: r-sig-geo at stat.math.ethz.ch
> >> Message-ID:
> >>         <e12429640801150627q7266a599g77a3df9744edb153 at mail.gmail.com>
> >> Content-Type: text/plain; charset=WINDOWS-1252
> >>
> >> I'm trying to realize e regression kriging with gstat package on my
> >> soil samples data. The response variable (ECe measuere) and covariates
> >> appear positvely skewed.
> >> As Tomislav Hengl suggests in its "framework for RK" [1], a logistic
> >> transformation is proposed as a generic way to reduce the skeweness by
> >> using the physical limits of the data.
> >> Is it really a transformation that can be applied in the generic case
> >> of skewed datas? I mean,in my case I have non-normal residuals (from
> >> original data regression), and I'm trying to transform the residuals
> >> (and not the original values) to do SK on them . Is this approach
> >> correct?
> >>
> >> A related question is how to do normal score transformations (for my
> >> residuals) in R and gstat. I know gstat doesn't manage transformations
> >> and back-transformations, so it should be done previously in R... but
> >> I can't find any package that permit it in a straisghtforward way.
> >> I've found something with qqnorm(ppoints(data)) and the approx()
> >> function. Is that all?
> >>
> >> Giovanni
> >>
> >>
> >> [1] "A generic framework for spatial prediction of soil variables
> >> based on regressionkriging" Geoderma 122 (1?2), 75?93.
> >>
> >>
> >>
> >> ------------------------------
> >>
> >> Message: 3
> >> Date: Tue, 15 Jan 2008 19:25:16 +0100
> >> From: <vacates at patiencegroup.com>
> >> Subject: [R-sig-Geo] I Would Dream
> >> To: r-sig-geo at stat.math.ethz.ch
> >> Message-ID: <478CFA8C.7030508 at patiencegroup.com>
> >> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
> >>
> >> Kisses Through E-mail http://86.123.21.76/
> >>
> >>
> >>
> >> ------------------------------
> >>
> >> Message: 4
> >> Date: Wed, 16 Jan 2008 11:04:53 +0100
> >> From: "G. Allegri" <giohappy at gmail.com>
> >> Subject: [R-sig-Geo] R from cgi and Xvfb
> >> To: r-sig-geo at stat.math.ethz.ch
> >> Message-ID:
> >>         <e12429640801160204h3532ddb9t624b4f6ef658c975 at mail.gmail.com>
> >> Content-Type: text/plain; charset=ISO-8859-1
> >>
> >> Hi everyone.
> >> I'm sorry for the question maybe OT.
> >> I'm trying to use R and Python to run some scripts via web interface.
> >> I've successfully setup mod_python for Apache and the rpy module.
> >> R needs X11 to use png() and jpeg() devices, so I have installed Xvfb
> >> (X virtual framebuffer). I works correctly: if I set the DISPLAY
> >> variable to point to this X server, rpy can create png files correctly
> >> from command-line, but it doesn't work when the python script is run
> >> from web browser.
> >> I restarted Apache after setting the DISPLAY variable, but the
> >> Traceback gives me always the same error, about being not able to open
> >> the X11 device?
> >>
> >> Does anyone have made it work right?
> >> How can tell Apache to run R script and forwarding X requests to my
> >> Xvfb.
> >>
> >> Thanks,
> >> Giovanni
> >>
> >>
> >>
> >> ------------------------------
> >>
> >> Message: 5
> >> Date: Wed, 16 Jan 2008 11:08:28 +0100
> >> From: "Tomislav Hengl" <hengl at science.uva.nl>
> >> Subject: Re: [R-sig-Geo] regression kriging in gstat with skewed
> >>         distributions
> >> To: "'G. Allegri'" <giohappy at gmail.com>
> >> Cc: r-sig-geo at stat.math.ethz.ch
> >> Message-ID: <001401c85827$bdac65a0$3a871291 at pcibed193>
> >> Content-Type: text/plain;       charset="windows-1250"
> >>
> >>
> >> Dear Giovanni,
> >>
> >> Logit transformation can be automatically applied to any variables which
> >> has a lower and upper
> >> physical limits (e.g. 0-100%). In R, you can transform a variable to
> >> logits by e.g.:
> >>
> >>
> >>> points = read.dbf("points.dbf")
> >>> points$SANDt = log((points$SAND/100)/(1-(points$SAND/100)))
> >>>
> >> After you interpolate your variable, you can back-transform the values
> >> by using:
> >>
> >>
> >>> SAND.rk = krige(fsand$call$formula, points[sel,], SPC, sand.rvgm)
> >>>
> >>> SAND.rk$pred=exp(SAND.rk$var1.pred)/(1+exp(SAND.rk$var1.pred))*100
> >>>
> >> The prediction variance can not be back-transformed, but you can use the
> >> normalized prediction
> >> variance by dividing it with the sampled variance. See also section
> >> 4.2.1 of my lecture notes
> >> (http://geostat.pedometrics.org/).
> >>
> >> There are many transformations that can be applied to force a normality
> >> of your target variable (see
> >> e.g. http://en.wikipedia.org/wiki/Data_transformation_(statistics) ).
> >> The most generic
> >> transformation is to work with the probability density function values
> >> (see e.g.
> >> http://dx.doi.org/10.1016/j.jneumeth.2006.11.004 ), this way you do not
> >> have to think about how the
> >> histogram looks at all. But then the interpretation of the regression
> >> plots becomes rather
> >> difficult.
> >>
> >> In any case, you should apply the transformation already to the target
> >> variable because also a
> >> requirement for linear regression is that the residuals are normally
> >> distributed around the
> >> regression line.
> >>
> >>
> >> see also:
> >> FITTING DISTRIBUTIONS WITH R (by Vito Ricci)
> >> http://cran.r-project.org/doc/contrib/Ricci-distributions-en.pdf
> >>
> >>
> >> Tom Hengl
> >> http://spatial-analyst.net
> >>
> >>
> >> -----Original Message-----
> >> From: r-sig-geo-bounces at stat.math.ethz.ch
> >> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
> >> G. Allegri
> >> Sent: dinsdag 15 januari 2008 15:28
> >> To: r-sig-geo at stat.math.ethz.ch
> >> Subject: [R-sig-Geo] regression kriging in gstat with skewed
> >> distributions
> >>
> >> I'm trying to realize e regression kriging with gstat package on my
> >> soil samples data. The response variable (ECe measuere) and covariates
> >> appear positvely skewed.
> >> As Tomislav Hengl suggests in its "framework for RK" [1], a logistic
> >> transformation is proposed as a generic way to reduce the skeweness by
> >> using the physical limits of the data.
> >> Is it really a transformation that can be applied in the generic case
> >> of skewed datas? I mean,in my case I have non-normal residuals (from
> >> original data regression), and I'm trying to transform the residuals
> >> (and not the original values) to do SK on them . Is this approach
> >> correct?
> >>
> >> A related question is how to do normal score transformations (for my
> >> residuals) in R and gstat. I know gstat doesn't manage transformations
> >> and back-transformations, so it should be done previously in R... but
> >> I can't find any package that permit it in a straisghtforward way.
> >> I've found something with qqnorm(ppoints(data)) and the approx()
> >> function. Is that all?
> >>
> >> Giovanni
> >>
> >>
> >> [1] "A generic framework for spatial prediction of soil variables
> >> based on regressionkriging" Geoderma 122 (1?2), 75?93.
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at stat.math.ethz.ch
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >>
> >>
> >> ------------------------------
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at stat.math.ethz.ch
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >>
> >> End of R-sig-Geo Digest, Vol 53, Issue 14
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at stat.math.ethz.ch
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >>
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
>
> --
> Drs. Paul Hiemstra
> Department of Physical Geography
> Faculty of Geosciences
> University of Utrecht
> Heidelberglaan 2
> P.O. Box 80.115
> 3508 TC Utrecht
> Phone:  +31302535773
> Fax:    +31302531145
> http://intamap.geo.uu.nl/~paul
>
>



From macq at llnl.gov  Wed Jan 16 16:35:05 2008
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 16 Jan 2008 07:35:05 -0800
Subject: [R-sig-Geo] R from cgi and Xvfb
In-Reply-To: <e12429640801160204h3532ddb9t624b4f6ef658c975@mail.gmail.com>
References: <e12429640801160204h3532ddb9t624b4f6ef658c975@mail.gmail.com>
Message-ID: <p06230904c3b3d4715cd5@[128.115.92.33]>

Have you looked into the GDD package?

-Don

At 11:04 AM +0100 1/16/08, G. Allegri wrote:
>Hi everyone.
>I'm sorry for the question maybe OT.
>I'm trying to use R and Python to run some scripts via web interface.
>I've successfully setup mod_python for Apache and the rpy module.
>R needs X11 to use png() and jpeg() devices, so I have installed Xvfb
>(X virtual framebuffer). I works correctly: if I set the DISPLAY
>variable to point to this X server, rpy can create png files correctly
>from command-line, but it doesn't work when the python script is run
>from web browser.
>I restarted Apache after setting the DISPLAY variable, but the
>Traceback gives me always the same error, about being not able to open
>the X11 device?
>
>Does anyone have made it work right?
>How can tell Apache to run R script and forwarding X requests to my Xvfb.
>
>Thanks,
>Giovanni
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at stat.math.ethz.ch
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
925-423-1062



From giohappy at gmail.com  Wed Jan 16 17:02:57 2008
From: giohappy at gmail.com (G. Allegri)
Date: Wed, 16 Jan 2008 17:02:57 +0100
Subject: [R-sig-Geo] R from cgi and Xvfb
In-Reply-To: <p06230904c3b3d4715cd5@128.115.92.33>
References: <e12429640801160204h3532ddb9t624b4f6ef658c975@mail.gmail.com>
	<p06230904c3b3d4715cd5@128.115.92.33>
Message-ID: <e12429640801160802k2e913877x5c1a2aae52e2db13@mail.gmail.com>

GDD... I had troubles compiling thi package, and I can't solve it. It
tries to create some objects it cannot, but headers and dependencies
semm allright.
I try again

2008/1/16, Don MacQueen <macq at llnl.gov>:
> Have you looked into the GDD package?
>
> -Don
>
> At 11:04 AM +0100 1/16/08, G. Allegri wrote:
> >Hi everyone.
> >I'm sorry for the question maybe OT.
> >I'm trying to use R and Python to run some scripts via web interface.
> >I've successfully setup mod_python for Apache and the rpy module.
> >R needs X11 to use png() and jpeg() devices, so I have installed Xvfb
> >(X virtual framebuffer). I works correctly: if I set the DISPLAY
> >variable to point to this X server, rpy can create png files correctly
> >from command-line, but it doesn't work when the python script is run
> >from web browser.
> >I restarted Apache after setting the DISPLAY variable, but the
> >Traceback gives me always the same error, about being not able to open
> >the X11 device?
> >
> >Does anyone have made it work right?
> >How can tell Apache to run R script and forwarding X requests to my Xvfb.
> >
> >Thanks,
> >Giovanni
> >
> >_______________________________________________
> >R-sig-Geo mailing list
> >R-sig-Geo at stat.math.ethz.ch
> >https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> --
> --------------------------------------
> Don MacQueen
> Environmental Protection Department
> Lawrence Livermore National Laboratory
> Livermore, CA, USA
> 925-423-1062
> --------------------------------------
>



From Roger.Bivand at nhh.no  Wed Jan 16 19:07:41 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 16 Jan 2008 19:07:41 +0100 (CET)
Subject: [R-sig-Geo] LL into national grid system,
 discrepancy between spTransform and Geocalc
In-Reply-To: <45e920ef0801160618s5d23ddd3l58237f100c650660@mail.gmail.com>
References: <45e920ef0801160618s5d23ddd3l58237f100c650660@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0801161854450.13650@reclus.nhh.no>

On Wed, 16 Jan 2008, ahimsa campos-arceiz wrote:

> Dear sig-geo listeRs,
>
> I've been using an old version of the program geocalc (The geographic
> calculator) to transform my field GPS data from the original WGS84 lat-long
> to the local National_grid_system (Kandawala, in Sri Lanka)
>
> I recently decided to update myself and try to use spTransform from the
> library rgdal. It took me some time to figure out how to define Kandawala's
> CRS. Once I that I (apparently) got it, I found that the resulting data show
> a discrepancy with the results from geocalc. This difference is a constant
> of 216 and 43 m for the x and y axis, respectively. I guess there might
> something in my configuration.
>
> I will appreciate if anybody can help me to identify the origin of this
> difference or suggest a better way to proceed. Below is my script, with a
> few points as example, plus some documentation.

Thank you for a very complete and helpful question!

The answer is very close, in the +towgs84= argument. The input data are in 
WGS84, and your output data are also, but should not be - although the 
ellipse is changed, the datum isn't. Your table below gives one set of 
values:

my.kandawala1 <- paste(my.kandawala, "+towgs84=-98.3,787,85,0,0,0,0")
k.points <- spTransform(SP_wgs84.LL, CRS(my.kandawala1))
> k.points
SpatialPoints:
             X        Y
[1,] 246809.7 111593.8
[2,] 246820.7 111656.9
[3,] 246821.8 111713.3
[4,] 246837.3 111728.8
Coordinate Reference System (CRS) arguments: +proj=tmerc +ellps=evrst30
+lat_0=7.000480277777778 +lon_0=80.771711111111130 +k=0.9999238418
+x_0=200000.000 +y_0=200000.00 +towgs84=-98.3,787,85,0,0,0,0
> cbind(X2, Y2)
            X2       Y2
[1,] 246811.2 111592.8
[2,] 246822.3 111655.8
[3,] 246823.3 111712.2
[4,] 246838.8 111727.7

which is very close. The rgdal package includes the current EPSG list of 
coordinate reference systems, and doing:

> EPSG <- make_EPSG()

to load the list into a data frame, and searching with grep gives slightly 
different values:

> EPSG[grep("Kandawala", EPSG$note),]
     code        note
163 4244 # Kandawala

prj4
163 +proj=longlat +a=6377276.345 +b=6356075.41314024 
+towgs84=-97,787,86,0,0,0,0 +no_defs

so:

> my.kandawala1 <- paste(my.kandawala, "+towgs84=-97,787,86,0,0,0,0")
> k.points <- spTransform(SP_wgs84.LL, CRS(my.kandawala1))
> k.points
SpatialPoints:
             X        Y
[1,] 246811.0 111592.9
[2,] 246822.0 111655.9
[3,] 246823.1 111712.3
[4,] 246838.6 111727.8
Coordinate Reference System (CRS) arguments: +proj=tmerc +ellps=evrst30
+lat_0=7.000480277777778 +lon_0=80.771711111111130 +k=0.9999238418
+x_0=200000.000 +y_0=200000.00 +towgs84=-97,787,86,0,0,0,0
> cbind(X2, Y2)
            X2       Y2
[1,] 246811.2 111592.8
[2,] 246822.3 111655.8
[3,] 246823.3 111712.2
[4,] 246838.8 111727.7

is only out by some tens of centimetres.

Finding the +towgs84= is typically hard, with the best source the APRS 
Grids & Datums columns (http://www.asprs.org/resources/GRIDS/), but 
unfortunately Sri Lanka isn't covered (yet). The column is excellently 
written (also humorous), and all users of spatial data needing to use 
legacy maps would benefit from browsing there.

Hope this helps!

Roger

>
> Thank you very much,
>
> Ahimsa
>
>
> #=== start script
>
> #=== data ====
> # GPS points recorded in the field (Sri Lanka) using lat-long WGS84
> ID <- c(1:4)
> X <- c(81.19672, 81.19682, 81.19683, 81.19697)
> Y <- c(6.20115, 6.20172, 6.20223, 6.20237)
> wgs84.LL <- data.frame(ID,X,Y)
>
> # the same data after transforming it using geocalc
> X2 <- c(246811.2398, 246822.2554, 246823.3166, 246838.7971)
> Y2 <- c(111592.7887, 111655.8285, 111712.2253, 111727.7191)
> kand <- data.frame(X2,Y2)
> # (below are the details of geocalc version and proj data)
>
>
> #=== transformation process ===
> # I create spatial data,
> library(rgdal)
> SP_wgs84.LL <- SpatialPoints(cbind(X,Y), proj4string=CRS("+proj=longlat
> +datum=WGS84"))
>
> # I define Sri Lankan National grid CRS,
> my.kandawala <- "+proj=tmerc +ellps=evrst30 +lat_0=7.000480277777778 +lon_0=
> 80.771711111111130 +k=0.9999238418 +x_0=200000.000 +y_0=200000.00"
>
> # and then I change the projection:
> k.points <- spTransform(SP_wgs84.LL, CRS(test))
> k.points
>
> #=== comparing the points from geocalc and spTransform:
> kand - as.data.frame(k.points)
> # there is a difference of ~216m and ~43m on the x and y axis, respectively
>
> #============== end script
>
> Documentation
>
> About Geocalc:
> I'm using Geocalc, the geographic calculator version 3.05 (1992-1994). The
> original points in degrees (dd.ddddd) and configured as "system=Geodetic",
> "Datum=186 WGS 1984" are converted into a user defined Kandawala Datum. The
> details of this datum are stored in a DAT file. These are the contents in
> such file:
>
> 1000 Zone_1 0 4 0 4 85 0 200000.000000000000000 200000.000000000000000
> 80.771711111111130 7.000480277777778 0.999923840000000
>
>
> # Kandawala in ArcGIS
> ArcGIS contains a prj file named kandawala. These are its contents:
>
> GEOGCS["GCS_Kandawala",DATUM["D_Kandawala",SPHEROID["Everest_1830",
> 6377276.345,300.8017]],PRIMEM["Greenwich",0],UNIT["Degree",
> 0.017453292519943295]]
>
> # I found more details about Kandawala on the web:
>
> http://www.mail-archive.com/mapinfo-l at csn.net/msg01850.html
>
> # kandawala data
>
> #     FUGRO SURVEY - GEO Version 2.38.01
>
> #      GEODESY 1
> #      Datum                 :  Kandawala
> #      Spheroid              :  Everest 1830C
> #      Semi Major Axis       :  6377276.345 m
> #      Inverse Flattening    :  300.801700000
> #      Projection            :  Transverse Mercator (UTM)
> #      Latitude  Origin      :    7? 00' 01.7290" N
> #      Longitude Origin      :   80? 46' 18.1600" E
> #      False Easting         :       200000.000 m
> #      False Northing        :       200000.000 m
> #      Central Scale Factor  :  0.9999238418
>
>
> # PARAMETERS FOR CONVERSION FROM WGS 84
> #                               Kandawala      WGS 84       Geod 1 to Geod 2
> #      dX                    :   98.300   m      0.000   m    -98.300   m
> #      dY                    : -787.500   m      0.000   m    787.500   m
> #      dZ                    :  -85.000   m      0.000   m     85.000   m
> #      rX                    :    0.0000  "      0.0000  "      0.0000  "
> #      rY                    :    0.0000  "      0.0000  "      0.0000  "
> #      rZ                    :    0.0000  "      0.0000  "      0.0000  "
> #      dS                    :    1.00000 ppm    0.00000 ppm   -1.00000 ppm
>
> #      TRANSFORMATIONS
> #      Station   Name        :  PW-5
> #                Datum       :  Kandawala            :  WGS 84
> #                Projection  :  Transverse Mercator  :  Transverse Mercator
> #                Latitude    :    6? 57' 09.3865" N  :    6? 57' 10.5800" N
> #                Longitude   :   79? 50' 37.0926" E  :   79? 50' 44.7687" E
> #                Height      :            8.097 m    :          -93.704 m
> #                Easting     :        97459.221 m    :       372492.852 m
> #                Northing    :       194807.060 m    :       768701.916 m
> #                PSF         :     1.0000539617      :     0.9998012206
> #                Convergence : -  0? 06' 44.47"      :  -  0? 08' 23.08"
>
>
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From giohappy at gmail.com  Thu Jan 17 15:50:06 2008
From: giohappy at gmail.com (G. Allegri)
Date: Thu, 17 Jan 2008 15:50:06 +0100
Subject: [R-sig-Geo] 4. R from cgi and Xvfb (G. Allegri)
In-Reply-To: <e12429640801160714p24211bf9y18e16d404a032d82@mail.gmail.com>
References: <mailman.9.1200481202.28806.r-sig-geo@stat.math.ethz.ch>
	<106F9C96E2CC5D4382760C42E3751A962A4F5E@drake.GEOSTATS.com>
	<e12429640801160515m607e0387ufb840dc1ecff12c6@mail.gmail.com>
	<478E1874.3030905@geo.uu.nl>
	<e12429640801160714p24211bf9y18e16d404a032d82@mail.gmail.com>
Message-ID: <e12429640801170650y1ca1bf32wdee6695f15c82993@mail.gmail.com>

I've solved using Cairo library. For now it's enough, then I'll try to
solve with Xvfb solution...
Thanks to all!

Giovanni

2008/1/16, G. Allegri <giohappy at gmail.com>:
> I've tried using bitmap(), but it returns this taceback:
>
> [Wed Jan 16 16:10:05 2008] [error] [client 127.0.0.1] GPL Ghostscript
> SVN PRE-RELEASE
> [Wed Jan 16 16:10:05 2008] [error] [client 127.0.0.1] 8.61
> [Wed Jan 16 16:10:05 2008] [error] [client 127.0.0.1] :
> [Wed Jan 16 16:10:05 2008] [error] [client 127.0.0.1] **** Could not
> open the file prova.png .
> [Wed Jan 16 16:10:05 2008] [error] [client 127.0.0.1] GPL Ghostscript
> SVN PRE-RELEASE
> [Wed Jan 16 16:10:05 2008] [error] [client 127.0.0.1] 8.61
> [Wed Jan 16 16:10:05 2008] [error] [client 127.0.0.1] :
> [Wed Jan 16 16:10:05 2008] [error] [client 127.0.0.1] Unrecoverable
> error, exit code 1
>
> I think ghostscript is trying to access the postcript file, but isn't
> able. It works perfectly out of Apache...
>
> I try with Cairo... my last try!
>
> 2008/1/16, Paul Hiemstra <p.hiemstra at geo.uu.nl>:
> > Hi Giovanni,
> >
> > You could consider using 'bitmap()' instead of png(). I seem to remember
> > that the first uses postscript devices and does not need X11. Another
> > options would be to use the Cairo package, 'Cairo' initializes a new
> > graphics device that uses the cairo graphics library for rendering. See
> > ?bitmap and ?Cairo.
> >
> > Hope this helps,
> >
> > Paul
> >
> > G. Allegri wrote:
> > > Thanks Marcelo,
> > > I've tried using the suexec module in apache2 (it permits to change
> > > userid and groupid on the base of the scripts called), but from
> > > documentation appears to work only for CGI and SSI, not with
> > > mod_python.
> > > So, I change mailing-list, since the problem is almost OT now in this one :-)
> > >
> > > Giovanni
> > >
> > > 2008/1/16, Marcelo Oliveira <moliveira at geostats.com>:
> > >
> > >> Giovanni,
> > >>
> > >> This issue could be related to user permissions.  See if you can get
> > >> Apache running under a user with display access rights.
> > >>
> > >> Good Luck,
> > >>
> > >> Marcelo
> > >>
> > >> -----Original Message-----
> > >> From: r-sig-geo-bounces at stat.math.ethz.ch
> > >> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
> > >> r-sig-geo-request at stat.math.ethz.ch
> > >> Sent: Wednesday, January 16, 2008 6:00 AM
> > >> To: r-sig-geo at stat.math.ethz.ch
> > >> Subject: R-sig-Geo Digest, Vol 53, Issue 14
> > >>
> > >> Send R-sig-Geo mailing list submissions to
> > >>         r-sig-geo at stat.math.ethz.ch
> > >>
> > >> To subscribe or unsubscribe via the World Wide Web, visit
> > >>         https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > >> or, via email, send a message with subject or body 'help' to
> > >>         r-sig-geo-request at stat.math.ethz.ch
> > >>
> > >> You can reach the person managing the list at
> > >>         r-sig-geo-owner at stat.math.ethz.ch
> > >>
> > >> When replying, please edit your Subject line so it is more specific
> > >> than "Re: Contents of R-sig-Geo digest..."
> > >>
> > >>
> > >> Today's Topics:
> > >>
> > >>    1. Re: Spatially Constrained Clustering (Elias T. Krainski)
> > >>    2. regression kriging in gstat with skewed distributions (G. Allegri)
> > >>    3. I Would Dream (vacates at patiencegroup.com)
> > >>    4. R from cgi and Xvfb (G. Allegri)
> > >>    5. Re: regression kriging in gstat with skewed       distributions
> > >>       (Tomislav Hengl)
> > >>
> > >>
> > >> ----------------------------------------------------------------------
> > >>
> > >> Message: 1
> > >> Date: Tue, 15 Jan 2008 10:51:48 -0300 (ART)
> > >> From: "Elias T. Krainski" <eliaskrainski at yahoo.com.br>
> > >> Subject: Re: [R-sig-Geo] Spatially Constrained Clustering
> > >> To: r-sig-geo at stat.math.ethz.ch
> > >> Message-ID: <569895.79461.qm at web50604.mail.re2.yahoo.com>
> > >> Content-Type: text/plain; charset=iso-8859-1
> > >>
> > >> Hello Carson,
> > >>
> > >> See the SKATER software at
> > >> http://www.est.ufmg.br/leste/skater.htm
> > >> The SKATER is a Spatial 'K'luster Analisys by Tree
> > >> Edge Removal. In future, this method also be available
> > >> in R.
> > >>
> > >> Best,
> > >> Elias.
> > >>
> > >> --- Carson Farmer <cfarmer at uvic.ca> escreveu:
> > >>
> > >>
> > >>> Hello List,
> > >>>
> > >>> I am trying to find an R package that will
> > >>> accommodate spatially
> > >>> constrained clustering.  While I have been unable to
> > >>> find a package that
> > >>> is explicitly designed to do spatially constrained
> > >>> clustering, I was
> > >>> wondering if anyone had found a package that would
> > >>> do constrained
> > >>> clustering of any kind, and adapted this to spatial
> > >>> constraints?
> > >>> I have searched the R site extensively, and googled
> > >>> all night long, but
> > >>> to no avail! I HAVE found this post:
> > >>>
> > >>>
> > >> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/56819.html
> > >>
> > >>> but the replies did not help much.  They lead to
> > >>> several packages which
> > >>> perform spatial clustering (such that significant
> > >>> clusters of say a
> > >>> disease are located within a study region), however,
> > >>> what I would like
> > >>> to do is partition a spatial (grid) dataset based on
> > >>> multiple variables,
> > >>> taking into account their spatial locations (i.e.
> > >>> clustering is based on
> > >>> the variables, but constrained so that clusters are
> > >>> spatially
> > >>> contiguous).  I'm thinking mclust is probably the
> > >>> best way to go, but
> > >>> I'm not sure where to start.
> > >>>
> > >>> Any suggestions would be greatly appreciated.
> > >>>
> > >>> Thanks,
> > >>>
> > >>> Carson
> > >>>
> > >>> _______________________________________________
> > >>> R-sig-Geo mailing list
> > >>> R-sig-Geo at stat.math.ethz.ch
> > >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > >>>
> > >>>
> > >> Elias T. Krainski
> > >>
> > >>
> > >>
> > >> ------------------------------
> > >>
> > >> Message: 2
> > >> Date: Tue, 15 Jan 2008 15:27:58 +0100
> > >> From: "G. Allegri" <giohappy at gmail.com>
> > >> Subject: [R-sig-Geo] regression kriging in gstat with skewed
> > >>         distributions
> > >> To: r-sig-geo at stat.math.ethz.ch
> > >> Message-ID:
> > >>         <e12429640801150627q7266a599g77a3df9744edb153 at mail.gmail.com>
> > >> Content-Type: text/plain; charset=WINDOWS-1252
> > >>
> > >> I'm trying to realize e regression kriging with gstat package on my
> > >> soil samples data. The response variable (ECe measuere) and covariates
> > >> appear positvely skewed.
> > >> As Tomislav Hengl suggests in its "framework for RK" [1], a logistic
> > >> transformation is proposed as a generic way to reduce the skeweness by
> > >> using the physical limits of the data.
> > >> Is it really a transformation that can be applied in the generic case
> > >> of skewed datas? I mean,in my case I have non-normal residuals (from
> > >> original data regression), and I'm trying to transform the residuals
> > >> (and not the original values) to do SK on them . Is this approach
> > >> correct?
> > >>
> > >> A related question is how to do normal score transformations (for my
> > >> residuals) in R and gstat. I know gstat doesn't manage transformations
> > >> and back-transformations, so it should be done previously in R... but
> > >> I can't find any package that permit it in a straisghtforward way.
> > >> I've found something with qqnorm(ppoints(data)) and the approx()
> > >> function. Is that all?
> > >>
> > >> Giovanni
> > >>
> > >>
> > >> [1] "A generic framework for spatial prediction of soil variables
> > >> based on regressionkriging" Geoderma 122 (1?2), 75?93.
> > >>
> > >>
> > >>
> > >> ------------------------------
> > >>
> > >> Message: 3
> > >> Date: Tue, 15 Jan 2008 19:25:16 +0100
> > >> From: <vacates at patiencegroup.com>
> > >> Subject: [R-sig-Geo] I Would Dream
> > >> To: r-sig-geo at stat.math.ethz.ch
> > >> Message-ID: <478CFA8C.7030508 at patiencegroup.com>
> > >> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
> > >>
> > >> Kisses Through E-mail http://86.123.21.76/
> > >>
> > >>
> > >>
> > >> ------------------------------
> > >>
> > >> Message: 4
> > >> Date: Wed, 16 Jan 2008 11:04:53 +0100
> > >> From: "G. Allegri" <giohappy at gmail.com>
> > >> Subject: [R-sig-Geo] R from cgi and Xvfb
> > >> To: r-sig-geo at stat.math.ethz.ch
> > >> Message-ID:
> > >>         <e12429640801160204h3532ddb9t624b4f6ef658c975 at mail.gmail.com>
> > >> Content-Type: text/plain; charset=ISO-8859-1
> > >>
> > >> Hi everyone.
> > >> I'm sorry for the question maybe OT.
> > >> I'm trying to use R and Python to run some scripts via web interface.
> > >> I've successfully setup mod_python for Apache and the rpy module.
> > >> R needs X11 to use png() and jpeg() devices, so I have installed Xvfb
> > >> (X virtual framebuffer). I works correctly: if I set the DISPLAY
> > >> variable to point to this X server, rpy can create png files correctly
> > >> from command-line, but it doesn't work when the python script is run
> > >> from web browser.
> > >> I restarted Apache after setting the DISPLAY variable, but the
> > >> Traceback gives me always the same error, about being not able to open
> > >> the X11 device?
> > >>
> > >> Does anyone have made it work right?
> > >> How can tell Apache to run R script and forwarding X requests to my
> > >> Xvfb.
> > >>
> > >> Thanks,
> > >> Giovanni
> > >>
> > >>
> > >>
> > >> ------------------------------
> > >>
> > >> Message: 5
> > >> Date: Wed, 16 Jan 2008 11:08:28 +0100
> > >> From: "Tomislav Hengl" <hengl at science.uva.nl>
> > >> Subject: Re: [R-sig-Geo] regression kriging in gstat with skewed
> > >>         distributions
> > >> To: "'G. Allegri'" <giohappy at gmail.com>
> > >> Cc: r-sig-geo at stat.math.ethz.ch
> > >> Message-ID: <001401c85827$bdac65a0$3a871291 at pcibed193>
> > >> Content-Type: text/plain;       charset="windows-1250"
> > >>
> > >>
> > >> Dear Giovanni,
> > >>
> > >> Logit transformation can be automatically applied to any variables which
> > >> has a lower and upper
> > >> physical limits (e.g. 0-100%). In R, you can transform a variable to
> > >> logits by e.g.:
> > >>
> > >>
> > >>> points = read.dbf("points.dbf")
> > >>> points$SANDt = log((points$SAND/100)/(1-(points$SAND/100)))
> > >>>
> > >> After you interpolate your variable, you can back-transform the values
> > >> by using:
> > >>
> > >>
> > >>> SAND.rk = krige(fsand$call$formula, points[sel,], SPC, sand.rvgm)
> > >>>
> > >>> SAND.rk$pred=exp(SAND.rk$var1.pred)/(1+exp(SAND.rk$var1.pred))*100
> > >>>
> > >> The prediction variance can not be back-transformed, but you can use the
> > >> normalized prediction
> > >> variance by dividing it with the sampled variance. See also section
> > >> 4.2.1 of my lecture notes
> > >> (http://geostat.pedometrics.org/).
> > >>
> > >> There are many transformations that can be applied to force a normality
> > >> of your target variable (see
> > >> e.g. http://en.wikipedia.org/wiki/Data_transformation_(statistics) ).
> > >> The most generic
> > >> transformation is to work with the probability density function values
> > >> (see e.g.
> > >> http://dx.doi.org/10.1016/j.jneumeth.2006.11.004 ), this way you do not
> > >> have to think about how the
> > >> histogram looks at all. But then the interpretation of the regression
> > >> plots becomes rather
> > >> difficult.
> > >>
> > >> In any case, you should apply the transformation already to the target
> > >> variable because also a
> > >> requirement for linear regression is that the residuals are normally
> > >> distributed around the
> > >> regression line.
> > >>
> > >>
> > >> see also:
> > >> FITTING DISTRIBUTIONS WITH R (by Vito Ricci)
> > >> http://cran.r-project.org/doc/contrib/Ricci-distributions-en.pdf
> > >>
> > >>
> > >> Tom Hengl
> > >> http://spatial-analyst.net
> > >>
> > >>
> > >> -----Original Message-----
> > >> From: r-sig-geo-bounces at stat.math.ethz.ch
> > >> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
> > >> G. Allegri
> > >> Sent: dinsdag 15 januari 2008 15:28
> > >> To: r-sig-geo at stat.math.ethz.ch
> > >> Subject: [R-sig-Geo] regression kriging in gstat with skewed
> > >> distributions
> > >>
> > >> I'm trying to realize e regression kriging with gstat package on my
> > >> soil samples data. The response variable (ECe measuere) and covariates
> > >> appear positvely skewed.
> > >> As Tomislav Hengl suggests in its "framework for RK" [1], a logistic
> > >> transformation is proposed as a generic way to reduce the skeweness by
> > >> using the physical limits of the data.
> > >> Is it really a transformation that can be applied in the generic case
> > >> of skewed datas? I mean,in my case I have non-normal residuals (from
> > >> original data regression), and I'm trying to transform the residuals
> > >> (and not the original values) to do SK on them . Is this approach
> > >> correct?
> > >>
> > >> A related question is how to do normal score transformations (for my
> > >> residuals) in R and gstat. I know gstat doesn't manage transformations
> > >> and back-transformations, so it should be done previously in R... but
> > >> I can't find any package that permit it in a straisghtforward way.
> > >> I've found something with qqnorm(ppoints(data)) and the approx()
> > >> function. Is that all?
> > >>
> > >> Giovanni
> > >>
> > >>
> > >> [1] "A generic framework for spatial prediction of soil variables
> > >> based on regressionkriging" Geoderma 122 (1?2), 75?93.
> > >>
> > >> _______________________________________________
> > >> R-sig-Geo mailing list
> > >> R-sig-Geo at stat.math.ethz.ch
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > >>
> > >>
> > >>
> > >> ------------------------------
> > >>
> > >> _______________________________________________
> > >> R-sig-Geo mailing list
> > >> R-sig-Geo at stat.math.ethz.ch
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > >>
> > >>
> > >> End of R-sig-Geo Digest, Vol 53, Issue 14
> > >>
> > >> _______________________________________________
> > >> R-sig-Geo mailing list
> > >> R-sig-Geo at stat.math.ethz.ch
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > >>
> > >>
> > >
> > > _______________________________________________
> > > R-sig-Geo mailing list
> > > R-sig-Geo at stat.math.ethz.ch
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > >
> >
> >
> > --
> > Drs. Paul Hiemstra
> > Department of Physical Geography
> > Faculty of Geosciences
> > University of Utrecht
> > Heidelberglaan 2
> > P.O. Box 80.115
> > 3508 TC Utrecht
> > Phone:  +31302535773
> > Fax:    +31302531145
> > http://intamap.geo.uu.nl/~paul
> >
> >
>



From pandit.ram at gmail.com  Thu Jan 17 20:17:23 2008
From: pandit.ram at gmail.com (Ram Pandit)
Date: Thu, 17 Jan 2008 13:17:23 -0600
Subject: [R-sig-Geo] Different results for same model in GEODA and R ?
Message-ID: <4ec06e730801171117y332fd89by56fd1414e2a032b4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080117/19477e9b/attachment.pl>

From obtect at smellwellmedia.com  Thu Jan 17 21:01:42 2008
From: obtect at smellwellmedia.com (Terry Robinson)
Date: Thu, 17 Jan 2008 20:01:42 +0000
Subject: [R-sig-Geo] Ado6e Akrobat Pro 8 for MAC\XP\Vlsta 79,
	Retail 599 (save 520)
Message-ID: <000501c85943$103a5b80$0100007f@wdimkg>

type mycheapmicrosoft . com in Internet browser
creative suite standard - 99
autodesk autocad electrical 2006 - 99
adobe photoshop cs2 v 9.0 - 69
adobe photoshop cs2 v 9.0 - 69
adobe after effects 7.0 standard - 59
crystal xcelsius professional v4.5 - 59
adobe after effects 7.0 standard - 59
acronis true image enterprise server 9.1.3666 - 79
zend studio - 49
coreldraw graphics suite 12 - 49
creative suite premium 2 - 149
adobe atmosphere 1.0 - 29
sonic scenarist 3.0 - 49
solid edge v17 - 69
endnote x1 for mac - 59



From tyl at plecpa.com  Thu Jan 17 21:55:35 2008
From: tyl at plecpa.com (tyl at plecpa.com)
Date: Thu, 17 Jan 2008 15:55:35 -0500
Subject: [R-sig-Geo] Your Friend and Lover
Message-ID: <478FC0C7.2010702@plecpa.com>

Love Remains http://201.215.148.87/



From Roger.Bivand at nhh.no  Thu Jan 17 22:12:07 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 17 Jan 2008 22:12:07 +0100 (CET)
Subject: [R-sig-Geo] Different results for same model in GEODA and R ?
In-Reply-To: <4ec06e730801171117y332fd89by56fd1414e2a032b4@mail.gmail.com>
References: <4ec06e730801171117y332fd89by56fd1414e2a032b4@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0801172150320.17118@reclus.nhh.no>

On Thu, 17 Jan 2008, Ram Pandit wrote:

> Dear all,
>
> I have found different results while using GEODA (spatial lag and error
> models) and spdep (lagsarlm and errorsarlm) models for the same data and
> same weight matrix.

Without making available your complete data set, your claim is worthless, 
because nobody can reproduce it - and not quoting the complete exact R 
code (history() of the whole session), and adding screen dumps (PrtScr) of 
GeoDa for all the steps taken. All such claims so far (and re. SpaceStat) 
over almost 10 years have been user misunderstandings or mistakes, and 
have been settled in threads on this list and the openspace list.

Please make a bundle of all the files needed to reproduce the problem and 
put them on a webserver, indicating where they can be picked up (or if 
sensitive attach them to an email to me off-list).

Step 1. See if a regular linear model can be reproduced - if not, you do 
not have the same data in both systems;

Step 2. See if the summary numbers for the neighbours agree, if not, the 
GAL files are not being represented in the same way;

Step 3. See if the weights agree (not so easy, but using a different 
variable with no autocorrelation, say a random variate, try a univariate 
Moran)

Question: do you have any missing values, and if so how are they 
represented?

I replied to this questioner off-list earlier without receiving an 
acknowledgement, seems to be in a hurry, and still has not been polite 
enough to give an affiliation. Please indicate your status (Professor of 
statistics, master's student in real estate, ...), it does help those who 
answer grasp why you might not understand.

Seriously, there is an enormous difference in the pleasure of answering to 
a well constructed question with a reproducable example, and the 
frustration of trying to arrest unsubstantiated and non-reproducable 
"reports" like this, which in my experience are very likely to be user 
error, and which certainly could have been checked more thoroughly.

Roger



> GEODA indicated strong spatial lag and error dependency
> by Moran's I and LR tests and highly significant coefficients of lagged
> dependent variable and the lambda. However, in lagsarlm and errorsarlm
> models in R I found both Rho and Lambda are insignificant by the LR tests
> and also insignificant Moran's Is. Also the magnitude of coefficient
> estimate differs for other model variables in these two applications.
>
> What might have caused these differences? Is the parameter estimation by MLE
> in GEODA and GLS (except Rho, which perhaps by MLE) in R made this
> difference. Why moran's I is significant in one (GEODA) but not in other
> (R)? What i am missing here?
>
> Any clue and suggestion would be helpful to find this difference.  Following
> is the data description and sample model results:
> I have used country based data from 124 countries with some islands on it.
> Created a gal file in GEODA and run simultaneous models in GEODA and R.
>
> 1.  sample GEODA out put for a model:
>
> DIAGNOSTICS FOR SPATIAL DEPENDENCE
> FOR WEIGHT MATRIX : gdpgi07.GAL  (row-standardized weights)
> TEST                          MI/DF      VALUE          PROB
> Moran's I (error)           0.266382     4.1677032      0.0000308
> Lagrange Multiplier (lag)       1       20.7711707      0.0000052
> Robust LM (lag)                 1        9.7078520      0.0018348
> Lagrange Multiplier (error)     1       13.0279696      0.0003069
> Robust LM (error)               1        1.9646508      0.1610168
> Lagrange Multiplier (SARMA)     2       22.7358216      0.0000116
>
> sample spatial lag model output for the same model in GEODA:
> -----------------------------------------------------------------------
>    Variable    Coefficient     Std.Error    z-value      Probability
> -----------------------------------------------------------------------
>       W_Y     0.5758454     0.05216534       11.03885    0.0000000
>    CONSTANT     -43.92029       21.60366      -2.033003    0.0420521
>         X1     0.3878955      0.0528817       7.335156    0.0000000
>        X2     0.8597154      0.8199795        1.04846    0.2944269
>    -----------------------------------------------------------------------
>
> DIAGNOSTICS FOR SPATIAL DEPENDENCE
> SPATIAL LAG DEPENDENCE FOR WEIGHT MATRIX : gdpgi07.GAL
> TEST                                     DF     VALUE         PROB
> Likelihood Ratio Test                    1       37.85142     0.0000000
>
> 2. Following is the R results for the same model:
>
> moran.test(Y,gdpgi07.queen,randomisation=FALSE,zero.policy=TRUE
> ,alternative="two.sided")
>
> Moran's I test under normality
>
> data:  Y
> weights: gdpgi07.queen
>
> Moran I statistic standard deviate = -1.1922, p-value = 0.2332
> alternative hypothesis: two.sided
> sample estimates:
> Moran I statistic       Expectation          Variance
>     -0.103175115      -0.008849558       0.006259578
>
>
>       Global Moran's I for regression residuals
>
> data:
> model: lm(formula = Y ~X1 + X2 +.......)
> weights: gdpgi07.queen
>
> Moran I statistic standard deviate = -0.7751, p-value = 0.4383
> alternative hypothesis: two.sided
> sample estimates:
> Observed Moran's I        Expectation           Variance
>      -0.067836924       -0.006025453        0.006359538
>
> Spatial lag model results:
> model.lag<-lagsarlm(Y~X1+X2+......................,data=gdpgi,gdpgi07.queen,
> zero.policy=TRUE)
> summary(amph1.lag)
> Type: lag
> Regions with no neighbours included:
> 199 98 183 216 99 157 105 143 118 12
> Coefficients: (asymptotic standard errors)
>               Estimate  Std. Error z value  Pr(>|z|)
> (Intercept) -59.5478780  25.4744792 -2.3376   0.01941
> X1           0.4084015   0.0611086  6.6832 2.338e-11
> X2          2.2414218   0.9592832  2.3366   0.01946
>
> Rho: -0.056746 LR test value: 0.51535 p-value: 0.47283
>
> thank you in advance.
>
> Ram
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From milton_ruser at yahoo.com.br  Fri Jan 18 00:11:51 2008
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Thu, 17 Jan 2008 15:11:51 -0800 (PST)
Subject: [R-sig-Geo] changing a polygon feature of position.
Message-ID: <74626.88431.qm@web56007.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080117/377ceb67/attachment.pl>

From synerbox.com at familyandmedia.com  Fri Jan 18 07:51:41 2008
From: synerbox.com at familyandmedia.com (Steven Williams)
Date: Fri, 18 Jan 2008 08:51:41 +0200
Subject: [R-sig-Geo] Microsoft Office 2007 Enterprise for 79,
	Retails @ 899 (You Save 819)
Message-ID: <000a01c8599e$a8b1f980$0100007f@hsknpj>

zend studio - 49
corel painter ix for mac - 39

Type 'nmoresoft. com' in Internet Explorer
(w/o spaces and quotes)

readiris pro 11.5 for mac - 39
cakewalk sonar 6 producer edition - 69
cadlink signlab vinyl 7.1 - 69
virtual pc 7.0 for mac - 49
parallels desktop 3.0 for mac - 29
autodesk autocad 2008 - 129
adobe golive cs2 - 49
intuit quicken premier 2008 - 29
ms xp professional with sp2 - 49
media tools professional 5 - 39

Return up to 76-0%!



From thebeaters.com at knightpoint.com  Fri Jan 18 10:19:57 2008
From: thebeaters.com at knightpoint.com (Joseph Taylor)
Date: Fri, 18 Jan 2008 18:19:57 +0900
Subject: [R-sig-Geo] Microsoft Vista Ultimate for 89,
	Retails @ 399 (You Save 310)
Message-ID: <000401c859b3$5e874300$0100007f@gdjsbj>

quarkxpress passport 7.3 - 79
2003 microsoft office professional with business contact manager for outlook - 69

Type 'nmoresoft. com' in |nternet Explorer
(w/o spaces and quotes)

intuit quicken home and business 2008 - 39
mcafee desktop firewall 8.0.493 - 39
autodesk architectural studio 3.0 - 39
sony acid pro 6 - 59
adobe fireworks cs3 - 59
webeasy pro 6.0 - 39
symantec norton 360 - 29
2003 microsoft office professional with business contact manager for outlook - 69
mindjet mindmanager 7 for mac - 39
microsoft vista ultimate - 89

Return up to 74-0%!



From tkobayas at indiana.edu  Fri Jan 18 10:47:51 2008
From: tkobayas at indiana.edu (Takatsugu Kobayashi)
Date: Fri, 18 Jan 2008 04:47:51 -0500
Subject: [R-sig-Geo] Polygon perimeter calculation in PBSmapping?
Message-ID: <479075C7.4060908@indiana.edu>

Hi,

I created a grid of cells of varying sizes using makeGrid() in sp. I 
could calculated the areas of these cells of varying sizes using 
calcArea() and combinePolys() in PBSmapping. I wonder if there is a 
function with which to compute the perimeter length. Or should I convert 
polygons to polylines and use calcLengths()?

Thank you very much.

Taka



From Roger.Bivand at nhh.no  Fri Jan 18 14:39:29 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 18 Jan 2008 14:39:29 +0100 (CET)
Subject: [R-sig-Geo] changing a polygon feature of position.
In-Reply-To: <74626.88431.qm@web56007.mail.re3.yahoo.com>
References: <74626.88431.qm@web56007.mail.re3.yahoo.com>
Message-ID: <Pine.LNX.4.64.0801181432360.20201@reclus.nhh.no>

On Thu, 17 Jan 2008, Milton Cezar Ribeiro wrote:

> Hi there,
>
> I have a shapefile with several non-contiguos polygons, and I identifyed 
> the centroid of each one. I modified some midpoints of polygons and now 
> I need to place those polygon which had its midpoints changed in a way 
> that the new centroid position come to be aproximately the new 
> midpoints.
>
> In other words, can I change de position of polygons of interest, 
> shifting the x and y midpoints?

Yes, although it will be a bit messy. First subset the input polygons so 
that your SpatialPolygons or SpatialPolygonsDataFrame object only has the 
polygon(s) to be manipulated in a particular way. Then find the new 
mid-point, and use the elide() methods in maptools, argument shift=c(), to 
move the midpoint from the old to the new, and the polygon will be 
shifted. Repeat for all the different shifting operations.

So what you need for the shift= arguments are the offsets in x and y 
directions between the old and new positions, and elide will move the 
polygon coordinates.

Roger

>
> Kind regards,
>
> Miltinho.
> Brazil
>
>
>
> para armazenamento!
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From webmaster at bonsplans.cn  Fri Jan 18 18:31:04 2008
From: webmaster at bonsplans.cn (Jouez et Gagnez)
Date: Fri, 18 Jan 2008 12:31:04 -0500
Subject: [R-sig-Geo] Amusez vous et choisissez vos cadeaux!
Message-ID: <E1JFv3Y-000661-Kz@felucia.privatedns.com>


 <http://jbala.ws/lists/lt.php?id=MkxbAgUDBx0FTgEAUlFR>


--
Pour vous d?sabonner ? cette liste, visitez http://jbala.ws/lists/lt.php?id=MkxbAgUDCB0FTgEAUlFR

Pour mettre vos pr?f?rences ? jour, visitez http://jbala.ws/lists/lt.php?id=MkxbAgUDCR0FTgEAUlFR
Faire suivre un message a quelqun http://jbala.ws/lists/lt.php?id=MkxbAgUAAB0FTgEAUlFR


--
Powered by PHPlist, www.phplist.com --



From joe at irishmail.com  Sat Jan 19 00:52:21 2008
From: joe at irishmail.com (Myles Gallagher)
Date: Sat, 19 Jan 2008 08:52:21 +0900
Subject: [R-sig-Geo] Private Investigation
Message-ID: <200801182352.m0INqLkV004555@www2.clickis.net>

Goodday,
 
My name is Myles Gallagher, I am a senior partner in the Technical Advisory Board of Allied Irish Bank Group (Senior Security Specialist). We are conducting a standard process investigation on behalf of "AIB Group", the International Banking conglomerate.
This investigation involves a client who shares the same surname with you and also the circumstances surrounding investments made by this client at "AIB Group", the Private Banking arm of Allied Irish Bank. The client died in testate and nominated no successor in title over the investments made with the bank. I would respectfully request that you keep the contents of this mail private and respect the integrity of the information you come by as a result of this mail.
 
I contact you independently of our investigation and no one is informed of this communication. I would like to intimate you with certain facts that I believe would be of interest to you. You share similar details to the late fellow; I am prepared to place you in a position to instruct the firm to release the deposit to you as the closest surviving relation. Upon receipt of the deposit, I am prepared to share the money with you, that is, I will simply nominate you as the next of kin and have them release the deposit to you. We share the proceeds 50/50.
I would have gone ahead to ask the funds be released to me, but that would have drawn a straight line to me and my involvement in claiming the deposit. But on the other hand, you with the same very name as the depositor's would easily pass as the beneficiary with right to claim. I assure you that I could have the deposit released to you within few working days.
 
I am aware of the consequences of this proposal. I ask that if you find no interest in this project that you should discard this mail. I ask that you do not be vindictive and destructive. If my offer is of no appeal to you, delete this message and forget I ever contacted you. Do not destroy my career because you do not approve of my proposal. You may not know this but people like myself who have made tidy sums out of comparable situations run the whole private banking sector. I am not a criminal and what I do, I do not find against good conscience, this may be hard for you to understand, but the dynamics of my industry dictates that I make this move. Such opportunities only come ones in a lifetime. I cannot let this chance pass me by, for once, I have found myself in total control of my destiny. These chances won't pass me by. I ask that you do not destroy my chance, if you will not work with me let me know and let me move on with my life but do not destroy me. I am a family!
  man and this is an opportunity to provide them with new opportunities.
 
There is a reward for this project and it is a task well worth undertaking. I have evaluated the risks and the only risk I have here is from you refusing to work with me. I am the only one who knows of this situation, good fortune has blessed you with a name that has planted you into the center of relevance in my life. Lets share the blessing. If you find yourself able to work with me, contact me through my email account below. If you give me positive signals, I will initiate this process towards a conclusion.
 
I send you this mail not without a measure of fear as to what the consequences, but I know within me that nothing ventured is nothing gained and that success and riches never come easy or on a platter of gold.
This is the one truth I have learned from my private banking clients. Do not betray my confidence. If we can be of one accord, we should plan a meeting soon.
 
Kind regards,
 
Myles Gallagher
mylesgallaghers at hotmail.com



From webmaster at bonsplans.cn  Sat Jan 19 03:49:27 2008
From: webmaster at bonsplans.cn (Tentez votre chance)
Date: Fri, 18 Jan 2008 21:49:27 -0500
Subject: [R-sig-Geo] Serez -vous notre prochain gagnant?
Message-ID: <E1JG3lv-0002Pj-2v@felucia.privatedns.com>




--
Pour vous d?sabonner ? cette liste, visitez http://jbala.ws/lists/lt.php?id=MkxTBQQHCVRIAU8AVlJTBg%3D%3D

Pour mettre vos pr?f?rences ? jour, visitez http://jbala.ws/lists/lt.php?id=MkxTBQQHCVdIAU8AVlJTBg%3D%3D
Faire suivre un message a quelqun http://jbala.ws/lists/lt.php?id=MkxTBQQHCVZIAU8AVlJTBg%3D%3D


--
Powered by PHPlist, www.phplist.com --



From Roger.Bivand at nhh.no  Sat Jan 19 15:56:12 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 19 Jan 2008 15:56:12 +0100 (CET)
Subject: [R-sig-Geo] Change in posting policy for R-sig-geo
Message-ID: <Pine.LNX.4.64.0801191549450.27264@reclus.nhh.no>

All of the R-lists, including R-sig-geo, have been having increasing 
trouble with spam. In trying to reduce to the minimum the distribution of 
spam on the lists, new filtering policies have been adopted, which we 
hope will help.

With effect from today, only subscribed members will be allowed to post to 
this list. The text on the list server page has been changed to reflect 
this. I am sorry that this step has been made necessary, as some posts 
from non-members (roughly one in 50) had been valid, and will now be 
rejected automatically.

And now back to real work ...

Roger

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From tkobayas at indiana.edu  Sat Jan 19 21:56:52 2008
From: tkobayas at indiana.edu (Takatsugu Kobayashi)
Date: Sat, 19 Jan 2008 15:56:52 -0500
Subject: [R-sig-Geo] overlay points and polygons and show maps
Message-ID: <47926414.1030000@indiana.edu>

Hi,

I am trying to show grid cells with colors. Colors depends on the number 
of points falling within grid cells. Here is what I did;


rm(list=ls(all=T))
library(sp)
library(maptools)
library(PBSmapping)

### Define parameters for a grid
start.point <- -5
cco <- c(start.point,start.point)
csize <- c(1,1)
n <- abs(cco[1]*2)+1
cnum <- c(n,n)
grd <- GridTopology(cco, csize, cnum)
r.grd <- as(grd, "SpatialPolygons")
r.grd.ps <- SpatialPolygons2PolySet(r.grd)

### Plot random points
x <- rnorm(10000)
y <- rnorm(10000)
events <- as.EventData(data.frame(EID = 1:10000, X=x, Y=y))

### Count # of points within cells
n_in_cells <- findPolys(events, r.grd.ps)
n_cells <- aggregate(n_in_cells, list(n_in_cells[,2]), sum)[,c(1,4)]

Then I would like to add n_cells to r.grd.ps, and show maps with colored 
cells using plotPolys(). Any suggestions?

Thank you very much

tk



From Roger.Bivand at nhh.no  Sun Jan 20 14:39:36 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 20 Jan 2008 14:39:36 +0100 (CET)
Subject: [R-sig-Geo] overlay points and polygons and show maps
In-Reply-To: <47926414.1030000@indiana.edu>
References: <47926414.1030000@indiana.edu>
Message-ID: <Pine.LNX.4.64.0801201412220.19779@reclus.nhh.no>

On Sat, 19 Jan 2008, Takatsugu Kobayashi wrote:

(Please note that the PBSmapping maintainer and authors are not subscribed 
to this list, so several of your questions about the use of PBSmapping 
functions have not been answered here; I have added a CC to the 
maintainer).

> Hi,
>
> I am trying to show grid cells with colors. Colors depends on the number
> of points falling within grid cells. Here is what I did;
>
>
> rm(list=ls(all=T))
> library(sp)
> library(maptools)
> library(PBSmapping)
>
> ### Define parameters for a grid
> start.point <- -5
> cco <- c(start.point,start.point)
> csize <- c(1,1)
> n <- abs(cco[1]*2)+1
> cnum <- c(n,n)
> grd <- GridTopology(cco, csize, cnum)
> r.grd <- as(grd, "SpatialPolygons")
> r.grd.ps <- SpatialPolygons2PolySet(r.grd)
>
> ### Plot random points
> x <- rnorm(10000)
> y <- rnorm(10000)
> events <- as.EventData(data.frame(EID = 1:10000, X=x, Y=y))
>
> ### Count # of points within cells
> n_in_cells <- findPolys(events, r.grd.ps)
> n_cells <- aggregate(n_in_cells, list(n_in_cells[,2]), sum)[,c(1,4)]
>
> Then I would like to add n_cells to r.grd.ps, and show maps with colored
> cells using plotPolys(). Any suggestions?

If an sp solution is of interest:

library(sp)
start.point <- -5
cco <- c(start.point,start.point)
csize <- c(1,1)
n <- abs(cco[1]*2)+1
cnum <- c(n,n)
grd <- GridTopology(cco, csize, cnum)
r.grd <- as(grd, "SpatialPolygons")

set.seed(1)
x <- rnorm(10000)
y <- rnorm(10000)
xy <- SpatialPoints(cbind(x, y))

o1 <- overlay(xy, r.grd)
res <- numeric(prod(cnum))
tres <- table(o1)
ntres <- as.integer(names(tres))
res[ntres] <- tres
IDs <- sapply(slot(r.grd, "polygons"), function(x) slot(x, "ID"))
resdf <- data.frame(cnt=res, row.names=IDs)
r.grd.df <- SpatialPolygonsDataFrame(r.grd, resdf)
spts <- list("sp.points", xy, pch=".", col="black")
spplot(r.grd.df, "cnt", sp.layout=spts)

or

g.grd <- SpatialGrid(grd)
o2 <- overlay(g.grd, xy)
res <- numeric(prod(cnum))
tres <- table(o1)
ntres <- as.integer(names(tres))
res[ntres] <- tres
g.grd.df <- SpatialGridDataFrame(grd, data=data.frame(cnt=res))
spts <- list("sp.points", xy, pch=".", col="black")
spplot(g.grd.df, "cnt", sp.layout=spts)

avoiding casting to polygons, and side-stepping the ID key needed to 
construct a SpatialPolygonsDataFrame.

Hope this helps,

Roger


>
> Thank you very much
>
> tk
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From luca_moiana at hotmail.com  Mon Jan 21 14:09:48 2008
From: luca_moiana at hotmail.com (Luca Moiana)
Date: Mon, 21 Jan 2008 13:09:48 +0000
Subject: [R-sig-Geo] ggwr and memory problems
Message-ID: <BAY106-W2006AAC4B9190E9FAC37AB8E3D0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080121/a24f0426/attachment.pl>

From Roger.Bivand at nhh.no  Mon Jan 21 14:38:18 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 21 Jan 2008 14:38:18 +0100 (CET)
Subject: [R-sig-Geo] ggwr and memory problems
In-Reply-To: <BAY106-W2006AAC4B9190E9FAC37AB8E3D0@phx.gbl>
References: <BAY106-W2006AAC4B9190E9FAC37AB8E3D0@phx.gbl>
Message-ID: <Pine.LNX.4.64.0801211423420.29280@reclus.nhh.no>

On Mon, 21 Jan 2008, Luca Moiana wrote:

> Dear List,
>
> Here is my problem:
>
> I wanna run a ggwr on a 9000 records Spatial Points Data Frame using R 
> on a Windows Machine (Dual processor, 4 GB RAM).

Have you tuned Windows memory use as discussed in the R for Windows FAQ - 
section 2.9? The binaries are 32-bit, and need to be told how much memory 
to use when trying to carry out memory intensive work.

>
> When I try to calculate bandwidth using:
>
> Sdati14400test.sel
> <- ggwr.sel(E14400 ~ V211 + V213 + V240 + V313 + V321 + V322 + V331511 +
> LnMPI25l.max + B:A, family = poisson(link = log), data = Sdati14400test,
> coords=Sdati14400test.coords, adapt = FALSE, gweight = gwr.gauss, verbose =
> TRUE, longlat = FALSE)
>
> I get a memory allocation error saying that the software is not able to 
> allocate a 749 Mb memory.
>
> Any suggestion??

It isn't strictly necessary to use all the observations to find the 
bandwidth - take a couple of 5% samples and see if the results differ 
much.

>
> I can also switch and use the same machine with a 64bit Ubuntu SO.
>

You can try that, but consider dividing the fit.points up into chunks, and 
running several R processes when actually fitting the ggwr model. The data 
points stay the same, but fit subsets of the fit.points in separate 
processes.

ggwr() has not (yet) been adapted for using a cluster, but gwr() has and a 
snow socket cluster will run happily on Linux there, and since it is run 
within the function, it concatenates the results before returning. If this 
would be useful of ggwr(), consider taking a look at the code.

Roger

>
> THANK A LOT
>
>
>
> Luca Moiana
>
>
> _________________________________________________________________
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From luca_moiana at hotmail.com  Mon Jan 21 15:01:00 2008
From: luca_moiana at hotmail.com (Luca Moiana)
Date: Mon, 21 Jan 2008 14:01:00 +0000
Subject: [R-sig-Geo] ggwr and memory problems
In-Reply-To: <Pine.LNX.4.64.0801211423420.29280@reclus.nhh.no>
References: <BAY106-W2006AAC4B9190E9FAC37AB8E3D0@phx.gbl>
	<Pine.LNX.4.64.0801211423420.29280@reclus.nhh.no>
Message-ID: <BAY106-W1171218B77A3CD5F14F2B88E3D0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080121/c4ec1aaf/attachment.pl>

From Roger.Bivand at nhh.no  Mon Jan 21 15:11:29 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 21 Jan 2008 15:11:29 +0100 (CET)
Subject: [R-sig-Geo] ggwr and memory problems
In-Reply-To: <BAY106-W1171218B77A3CD5F14F2B88E3D0@phx.gbl>
References: <BAY106-W2006AAC4B9190E9FAC37AB8E3D0@phx.gbl>
	<Pine.LNX.4.64.0801211423420.29280@reclus.nhh.no>
	<BAY106-W1171218B77A3CD5F14F2B88E3D0@phx.gbl>
Message-ID: <Pine.LNX.4.64.0801211505020.29280@reclus.nhh.no>

On Mon, 21 Jan 2008, Luca Moiana wrote:

>
>
>
>> Date: Mon, 21 Jan 2008 14:38:18 +0100
>> From: Roger.Bivand at nhh.no
>> To: luca_moiana at hotmail.com
>> CC: r-sig-geo at stat.math.ethz.ch
>> Subject: Re: [R-sig-Geo] ggwr and memory problems
>>
>> On Mon, 21 Jan 2008, Luca Moiana wrote:
>>
>>> Dear List,
>>>
>>> Here is my problem:
>>>
>>> I wanna run a ggwr on a 9000 records Spatial Points Data Frame using R
>>> on a Windows Machine (Dual processor, 4 GB RAM).
>>
>> Have you tuned Windows memory use as discussed in the R for Windows FAQ -
>> section 2.9? The binaries are 32-bit, and need to be told how much memory
>> to use when trying to carry out memory intensive work.
>
> We tried this but didn't change anything.

OK. It may run on Linux, because the memory allocation there accepts many 
small free patches but Windows wants a single free chunk the size of the 
request.

>
>
>>
>>>
>>> When I try to calculate bandwidth using:
>>>
>>> Sdati14400test.sel
>>> <- ggwr.sel(E14400 ~ V211 + V213 + V240 + V313 + V321 + V322 + V331511 +
>>> LnMPI25l.max + B:A, family = poisson(link = log), data = Sdati14400test,
>>> coords=Sdati14400test.coords, adapt = FALSE, gweight = gwr.gauss, verbose =
>>> TRUE, longlat = FALSE)
>>>
>>> I get a memory allocation error saying that the software is not able to
>>> allocate a 749 Mb memory.
>>>
>>> Any suggestion??
>>
>> It isn't strictly necessary to use all the observations to find the
>> bandwidth - take a couple of 5% samples and see if the results differ
>> much.
>
> I didn't know that and I would try, but then I'll have memory problems when I try to run ggwr??
> Is there a command to obtain a random 5% sample??
>

Try subsetting the data= argument object: df[o,] with the output of o <- 
sample(). Remember to say set.seed(whatever) to be able to repeat if need 
be.

>
>>
>>>
>>> I can also switch and use the same machine with a 64bit Ubuntu SO.
>>>
>>
>> You can try that, but consider dividing the fit.points up into chunks, and
>> running several R processes when actually fitting the ggwr model. The data
>> points stay the same, but fit subsets of the fit.points in separate
>> processes.
>
> I don't have fit.points cause I'm working on the entire Lombardy Region 
> (Northern Italy) and I'd like to compare the model from ggwr with glm 
> models a colleague obtained from a regular glm.

If no fit.points are given, the data points are copied across as fit 
points internally. You are free to subset the data.points into many 
fit.points, and concatenate the output objects afterwards. This should 
remove the difficulty.

Roger

>
> MANY THANKS
>
>
>>
>> ggwr() has not (yet) been adapted for using a cluster, but gwr() has and a
>> snow socket cluster will run happily on Linux there, and since it is run
>> within the function, it concatenates the results before returning. If this
>> would be useful of ggwr(), consider taking a look at the code.
>>
>> Roger
>>
>>>
>>> THANK A LOT
>>>
>>>
>>>
>>> Luca Moiana
>>>
>>>
>>> _________________________________________________________________
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>
> _________________________________________________________________
> Express yourself instantly with MSN Messenger! Download today it's FREE!
> http://messenger.msn.click-url.com/go/onm00200471ave/direct/01/

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From tkobayas at indiana.edu  Mon Jan 21 23:20:40 2008
From: tkobayas at indiana.edu (Takatsugu Kobayashi)
Date: Mon, 21 Jan 2008 17:20:40 -0500
Subject: [R-sig-Geo] Polygon perimeter calculation in PBSmapping?
	[SOLVED]
In-Reply-To: <479075C7.4060908@indiana.edu>
References: <479075C7.4060908@indiana.edu>
Message-ID: <47951AB8.6000307@indiana.edu>

I figured out by reading vignette('sp') and a PBSmapping manual.  Thanks.

Takatsugu Kobayashi wrote:
> Hi,
>
> I created a grid of cells of varying sizes using makeGrid() in sp. I 
> could calculated the areas of these cells of varying sizes using 
> calcArea() and combinePolys() in PBSmapping. I wonder if there is a 
> function with which to compute the perimeter length. Or should I convert 
> polygons to polylines and use calcLengths()?
>
> Thank you very much.
>
> Taka
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From tkobayas at indiana.edu  Tue Jan 22 06:21:28 2008
From: tkobayas at indiana.edu (Takatsugu Kobayashi)
Date: Tue, 22 Jan 2008 00:21:28 -0500
Subject: [R-sig-Geo] bitmap plots in loop
Message-ID: <47957D58.800@indiana.edu>

hi,

I have read a couple of threads about png and jpg not being supported in 
R CMD BATCH. So I decided to use bitmap() instead. I would like to 
repeat printing jobs 1000 times. I only got empty png files. Doesn't 
this loop open bitmap, plot, close bitmap everytime?

rm(list=ls(all=T))

### Include necessary packages
library(sp)
library(maptools)

pts <- c(2,3,4,5,6,7,8,9,10)
for (iter in 1:length(pts))
{
### Define parameters for a grid
start.point <- -pts
cco <- c(start.point,start.point)
csize <- c(1,1)
n <- abs(cco[1]*2)+1
cnum <- c(n,n)
grd <- GridTopology(cco, csize, cnum)
r.grd <- as(grd, "SpatialPolygons")

### Assign some values to grid cells
ID <- sapply(slot(r.grd, "polygons"), function(x) slot(x, "ID"))
resdf <- data.frame(com.time=runif(n^2), row.names=ID)
r.grd.df <- SpatialPolygonsDataFrame(r.grd, resdf)

### save bitmap images s
bitmap(file=paste('output/gridcell',iter,'_new.png',sep=''),type='png256', 
width=5, height=5)
spplot(r.grd.df)
dev.off()
}

I appreciate your help.

Taka



From Roger.Bivand at nhh.no  Tue Jan 22 09:15:48 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 22 Jan 2008 09:15:48 +0100 (CET)
Subject: [R-sig-Geo] bitmap plots in loop
In-Reply-To: <47957D58.800@indiana.edu>
References: <47957D58.800@indiana.edu>
Message-ID: <Pine.LNX.4.64.0801220913560.2523@reclus.nhh.no>

On Tue, 22 Jan 2008, Takatsugu Kobayashi wrote:

> hi,
>
> I have read a couple of threads about png and jpg not being supported in
> R CMD BATCH. So I decided to use bitmap() instead. I would like to
> repeat printing jobs 1000 times. I only got empty png files. Doesn't
> this loop open bitmap, plot, close bitmap everytime?
>
> rm(list=ls(all=T))
>
> ### Include necessary packages
> library(sp)
> library(maptools)
>
> pts <- c(2,3,4,5,6,7,8,9,10)
> for (iter in 1:length(pts))
> {
> ### Define parameters for a grid
> start.point <- -pts
> cco <- c(start.point,start.point)
> csize <- c(1,1)
> n <- abs(cco[1]*2)+1
> cnum <- c(n,n)
> grd <- GridTopology(cco, csize, cnum)
> r.grd <- as(grd, "SpatialPolygons")
>
> ### Assign some values to grid cells
> ID <- sapply(slot(r.grd, "polygons"), function(x) slot(x, "ID"))
> resdf <- data.frame(com.time=runif(n^2), row.names=ID)
> r.grd.df <- SpatialPolygonsDataFrame(r.grd, resdf)
>
> ### save bitmap images s
> bitmap(file=paste('output/gridcell',iter,'_new.png',sep=''),type='png256',
> width=5, height=5)
> spplot(r.grd.df)

This is lattice graphics, and must be

print(spplot(r.grd.df))

R FAQ 7.22

Roger


> dev.off()
> }
>
> I appreciate your help.
>
> Taka
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From luca_moiana at hotmail.com  Tue Jan 22 13:12:13 2008
From: luca_moiana at hotmail.com (Luca Moiana)
Date: Tue, 22 Jan 2008 12:12:13 +0000
Subject: [R-sig-Geo] AGAIN ON GGWR
In-Reply-To: <Pine.LNX.4.64.0801211505020.29280@reclus.nhh.no>
References: <BAY106-W2006AAC4B9190E9FAC37AB8E3D0@phx.gbl>
	<Pine.LNX.4.64.0801211423420.29280@reclus.nhh.no>
	<BAY106-W1171218B77A3CD5F14F2B88E3D0@phx.gbl> 
	<Pine.LNX.4.64.0801211505020.29280@reclus.nhh.no>
Message-ID: <BAY106-W39F428BD4FF1B90F865D5F8E3E0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080122/c2ea75e3/attachment.pl>

From Roger.Bivand at nhh.no  Tue Jan 22 15:10:21 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 22 Jan 2008 15:10:21 +0100 (CET)
Subject: [R-sig-Geo] AGAIN ON GGWR
In-Reply-To: <BAY106-W39F428BD4FF1B90F865D5F8E3E0@phx.gbl>
References: <BAY106-W2006AAC4B9190E9FAC37AB8E3D0@phx.gbl>
	<Pine.LNX.4.64.0801211423420.29280@reclus.nhh.no>
	<BAY106-W1171218B77A3CD5F14F2B88E3D0@phx.gbl>
	<Pine.LNX.4.64.0801211505020.29280@reclus.nhh.no>
	<BAY106-W39F428BD4FF1B90F865D5F8E3E0@phx.gbl>
Message-ID: <Pine.LNX.4.64.0801221451340.3175@reclus.nhh.no>

On Tue, 22 Jan 2008, Luca Moiana wrote:

> Hello Everyone,

(Please use a better email client, one that only uses plain text, does not 
use HTML, and does not break lines in the wrong places or add empty 
lines).

>
> Following yesterday?s suggestions I wrote this code:
>
> ##Creation of Spatial Points Data Frame
> x <- as.matrix(subsample$E)
> y <- as.matrix (subsample$N)
> S <- SpatialPoints (cbind(x,y))
> S <- SpatialPoints (list (x,y))
> S <- SpatialPoints (data.frame (x,y))
> data <- (subsample)

Do not assign to data, there is a function called that.

> Sdati14400 <- SpatialPointsDataFrame(S, data)
> ##Random sample for bandwidth (5%)
> subsample <- dati14400 [sample(1:nrow(dati14400), 488, replace=F),]
>
> ##Bandwidth value
>
> Sdati14400test.sel <- ggwr.sel(E14400 ~ V211 + V213 + V240 + V313 + V321 
> + V322 + V331511 + LnMPI25l_max + B:A, family = poisson(link = log), 
> data = Sdati14400, coords=Sdati14400.coords, adapt = FALSE, gweight = 
> gwr.gauss, verbose = TRUE, longlat = FALSE)

I don't follow, what is Sdati14400? and Sdati14400.coords? Please try 
without so many variables, simplify until you understand what is 
happening. longlat = FALSE, but below it is TRUE?

>
> ##GGwr
>
> Sdati14400.ggwr <- ggwr(E14400 ~ V211 + V213 + V313 + V321 + V322 + 
> V331511 + LnMPI25l_max + B:A, data = Sdati14400, 
> coords=Sdati14400 at coords, bandwidth=Sdati14400test.sel, gweight = 
> gwr.gauss, adapt = 1, family = poisson(link = log), longlat = TRUE)
>
> Form the Bandwidth calculation I got this message: Warning in glm.fit(x 
> = X, y = Y, weights = weights, start = start, etastart = etastart, : 
> fitted rates numerically 0 occurred

Warnings in CV search for bandwidths are not a problem, because the search 
algorithm will occasionally try unsuitable values, which get trapped, and 
the search restarted from the last valid value.

>
> Skipped and calculated ggwr to get to this results:
>
> Call:
>
> ggwr(formula = E14400 ~ V211 + V213 + V313 + V321 + V322 + V331511 + 
> LnMPI25l_max + B:A, data = Sdati14400, coords = Sdati14400 at coords, 
> bandwidth = Sdati14400test.sel, gweight = gwr.gauss, adapt = 1,

This places a Gaussian kernel over each point, but includes all points. In 
addition, you did want to fit over all your points, didn't you? You can do 
this if you like, but why?

> family = poisson(link = log), longlat = TRUE)
> Kernel function: gwr.gauss
> Adaptive quantile: 1 (about 488 of 488)
> Summary of GWR coefficient estimates:
>                  Min.   1st Qu. Median   3rd Qu.      Max.    Global
> X.Intercept.   -8.0040 -6.8270   -6.5200   -6.3300 -5.9980   -6.6016
> V211           -3.5370   -2.9440 -2.6340   -2.3250   -1.9590 -2.6024
> V213         -212.0000 -203.8000 -199.3000 -193.1000 -177.1000 -198.6228
> V313            0.1216    0.2915  0.3675  0.4515    0.6626    0.3766
> V321           -5.3780   -4.7580   -4.3820 -4.0840   -3.4480   -4.3489
> V322          -24.1100  -22.7300  -22.0400 -21.4800  -20.8800  -21.9145
> V331511      -110.8000  -92.7700  -70.7300 -56.5300  -49.0700  -68.8769
> LnMPI25l_max    0.3357    0.3532    0.3673   0.3850    0.4546    0.3709
> B.A             5.3070    5.8140    6.2040   6.4940    6.9850    6.1363
>
> Is that correct or you have other suggestions???

I think the onus is on you to answer this, correct depends on what you 
need. I doubt whether this tells you very much. Also, plot pairs() of the 
local coefficients to see if you have induced local collinearity - see 
Wheeler & Tiefelsdorf (2005) referenced in the package help pages.

>
> Other question, I used variables, coming from a colleague GLM analysis, 
> any suggestions on how to choose the variables and use directly ggwr??
>

A formula is a formula, choose as you wish, but best with a substantive 
reasoning behind the choice of variable and its functional form.

Roger

>
>
> THANKS A
> LOT
>
>
>
> Luca Moiana
>
> PhD
> Candidate ? Enrivornmental Science Department
>
> University of
> Milan-Bicocca
>
>
>
>> Date: Mon, 21 Jan 2008 15:11:29 +0100
>> From: Roger.Bivand at nhh.no
>> To: luca_moiana at hotmail.com
>> CC: r-sig-geo at stat.math.ethz.ch
>> Subject: RE: [R-sig-Geo] ggwr and memory problems
>>
>> On Mon, 21 Jan 2008, Luca Moiana wrote:
>>
>>>
>>>
>>>
>>>> Date: Mon, 21 Jan 2008 14:38:18 +0100
>>>> From: Roger.Bivand at nhh.no
>>>> To: luca_moiana at hotmail.com
>>>> CC: r-sig-geo at stat.math.ethz.ch
>>>> Subject: Re: [R-sig-Geo] ggwr and memory problems
>>>>
>>>> On Mon, 21 Jan 2008, Luca Moiana wrote:
>>>>
>>>>> Dear List,
>>>>>
>>>>> Here is my problem:
>>>>>
>>>>> I wanna run a ggwr on a 9000 records Spatial Points Data Frame using R
>>>>> on a Windows Machine (Dual processor, 4 GB RAM).
>>>>
>>>> Have you tuned Windows memory use as discussed in the R for Windows FAQ -
>>>> section 2.9? The binaries are 32-bit, and need to be told how much memory
>>>> to use when trying to carry out memory intensive work.
>>>
>>> We tried this but didn't change anything.
>>
>> OK. It may run on Linux, because the memory allocation there accepts many
>> small free patches but Windows wants a single free chunk the size of the
>> request.
>>
>>>
>>>
>>>>
>>>>>
>>>>> When I try to calculate bandwidth using:
>>>>>
>>>>> Sdati14400test.sel
>>>>> <- ggwr.sel(E14400 ~ V211 + V213 + V240 + V313 + V321 + V322 + V331511 +
>>>>> LnMPI25l.max + B:A, family = poisson(link = log), data = Sdati14400test,
>>>>> coords=Sdati14400test.coords, adapt = FALSE, gweight = gwr.gauss, verbose =
>>>>> TRUE, longlat = FALSE)
>>>>>
>>>>> I get a memory allocation error saying that the software is not able to
>>>>> allocate a 749 Mb memory.
>>>>>
>>>>> Any suggestion??
>>>>
>>>> It isn't strictly necessary to use all the observations to find the
>>>> bandwidth - take a couple of 5% samples and see if the results differ
>>>> much.
>>>
>>> I didn't know that and I would try, but then I'll have memory problems when I try to run ggwr??
>>> Is there a command to obtain a random 5% sample??
>>>
>>
>> Try subsetting the data= argument object: df[o,] with the output of o <-
>> sample(). Remember to say set.seed(whatever) to be able to repeat if need
>> be.
>>
>>>
>>>>
>>>>>
>>>>> I can also switch and use the same machine with a 64bit Ubuntu SO.
>>>>>
>>>>
>>>> You can try that, but consider dividing the fit.points up into chunks, and
>>>> running several R processes when actually fitting the ggwr model. The data
>>>> points stay the same, but fit subsets of the fit.points in separate
>>>> processes.
>>>
>>> I don't have fit.points cause I'm working on the entire Lombardy Region
>>> (Northern Italy) and I'd like to compare the model from ggwr with glm
>>> models a colleague obtained from a regular glm.
>>
>> If no fit.points are given, the data points are copied across as fit
>> points internally. You are free to subset the data.points into many
>> fit.points, and concatenate the output objects afterwards. This should
>> remove the difficulty.
>>
>> Roger
>>
>>>
>>> MANY THANKS
>>>
>>>
>>>>
>>>> ggwr() has not (yet) been adapted for using a cluster, but gwr() has and a
>>>> snow socket cluster will run happily on Linux there, and since it is run
>>>> within the function, it concatenates the results before returning. If this
>>>> would be useful of ggwr(), consider taking a look at the code.
>>>>
>>>> Roger
>>>>
>>>>>
>>>>> THANK A LOT
>>>>>
>>>>>
>>>>>
>>>>> Luca Moiana
>>>>>
>>>>>
>>>>> _________________________________________________________________
>>>>>
>>>>>
>>>>> 	[[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>>>
>>>> --
>>>> Roger Bivand
>>>> Economic Geography Section, Department of Economics, Norwegian School of
>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>> e-mail: Roger.Bivand at nhh.no
>>>>
>>>
>>> _________________________________________________________________
>>> Express yourself instantly with MSN Messenger! Download today it's FREE!
>>> http://messenger.msn.click-url.com/go/onm00200471ave/direct/01/
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>
> _________________________________________________________________
> Express yourself instantly with MSN Messenger! Download today it's FREE!
> http://messenger.msn.click-url.com/go/onm00200471ave/direct/01/

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From milton_ruser at yahoo.com.br  Tue Jan 22 22:29:30 2008
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Tue, 22 Jan 2008 13:29:30 -0800 (PST)
Subject: [R-sig-Geo] plotting only polygons with points inside.
Message-ID: <54439.1623.qm@web56005.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080122/1f524eb5/attachment.pl>

From stefan.duke at gmail.com  Tue Jan 22 22:31:21 2008
From: stefan.duke at gmail.com (stefan lhachimi)
Date: Tue, 22 Jan 2008 22:31:21 +0100
Subject: [R-sig-Geo] save polygon as a shape file
In-Reply-To: <Pine.LNX.4.64.0801122117450.4088@reclus.nhh.no>
References: <a211af3b0801121211s2a3f0dc9td0eb94f776d0fe41@mail.gmail.com>
	<Pine.LNX.4.64.0801122117450.4088@reclus.nhh.no>
Message-ID: <a211af3b0801221331p64b3a4aga44399e9deeeb06@mail.gmail.com>

Thanks! That worked great.
 I am also able now to merge new data into the map with the merge
command (I went to great length to show data in a map, always fearing
that its not matched properly). I guess this is kind of trivial if you
know your way around. But I never got a introduction to spatial
methods in R. So I am bascially trying around. It is rather difficult
to distinguish between the different classes for spatial objects.
Thanks again,
Stefan


On Jan 12, 2008 9:27 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Sat, 12 Jan 2008, stefan lhachimi wrote:
>
> > Hello,
> >
> > I loaded a .shp-file and used a subset command while converting it
> > into a polygon to eliminate certain regions:
> >
> > map.kreise<-readShapePoly("vg250krs",IDvar="KRS_ID",verbos=TRUE)
> > map.kreise.boden <-polygons(map.kreise)[x$BODENSEE==0]
>
> Why polygons()? It returns a SpatialPolygons object. To select the
> polygons and the data frame rows, you need:
>
> map.kreise.boden <- map.kreise[x$BODENSEE==0,]
>
> (note the extra comma) where:
>
> writePolyShape(map.kreise.boden, "mapohnebodensee")
>
> will just work. A shapefile cannot only have geometries, it must have
> attribute data. The documentation does say that the first argument to
> writePolyShape should be a SpatialPolygonsDataFrame, and you can check
> with:
>
> class(map.kreise.boden)
>
> Roger
>
> >
> > Now I want to save the new object map.kreise.boden as a shp-file again
> > (I want to usethe new shp-file without certain regions into GEODA).
> > The writePolyShape-command does not work. It gives me the following
> > error message:
> >
> > writePolyShape(map.kreise.boden, "mapohnebodensee")
> > Fehler in as(x, "data.frame") :
> >  no method or default for coercing "SpatialPolygons" to "data.frame"
> >
> > Any help is appreciated.
> > Best,
> > Stefan
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>



From Thomas.Adams at noaa.gov  Wed Jan 23 05:28:45 2008
From: Thomas.Adams at noaa.gov (Thomas.Adams at noaa.gov)
Date: Tue, 22 Jan 2008 23:28:45 -0500
Subject: [R-sig-Geo] spgrass6 build error on Mac OS X
Message-ID: <3a49e93f3274429c.47967c2d@noaa.gov>

List,

I am attempting to build spgrass6 on MacOS X 10.5.1 (Leopard) on a 2.33. GHz Intel Core Duo MacBook Pro. Using the Mac OS X Cocoa GUI, I am trying to install spgrass6 from source. I have gdal installed fine; when I run gdal-config at a term window prompt, I get:

Macintosh-2:bin teaiii$ gdal-config
Usage: gdal-config [OPTIONS]
Options:
	[--prefix[=DIR]]
	[--libs]
	[--dep-libs]
	[--cflags]
	[--version]
	[--ogr-enabled]
	[--formats]

I have "Install dependencies" checked, so rgdal is downloaded and attempts to build first. (No MacOS X binaries are available). So, I get:

/Library/Frameworks/R.framework/Resources/library
* Installing *source* package 'rgdal' ...
gdal-config: gdal-config
checking for gcc... gcc -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -std=gnu99
checking for C compiler default output file name... a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables... 
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -std=gnu99 accepts -g... yes
checking for gcc -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -std=gnu99 option to accept ANSI C... none needed
checking how to run the C preprocessor... gcc -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -std=gnu99 -E
checking for egrep... grep -E
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking proj_api.h usability... yes
checking proj_api.h presence... yes
checking for proj_api.h... yes
checking for pj_init_plus in -lproj... yes
Package CPP flags: -I/usr/local/include
Package LIBS: -L/usr/local/lib -lgdal
configure: creating ./config.status
config.status: creating src/Makevars
** libs
** arch - i386
g++ -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/i386 -I/usr/local/include -msse3    -fPIC  -g -O2 -march=nocona -c OGR_write.cpp -o OGR_write.o
g++ -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/i386 -I/usr/local/include -msse3    -fPIC  -g -O2 -march=nocona -c gdal-bindings.cpp -o gdal-bindings.o
g++ -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/i386 -I/usr/local/include -msse3    -fPIC  -g -O2 -march=nocona -c ogr_geom.cpp -o ogr_geom.o
g++ -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/i386 -I/usr/local/include -msse3    -fPIC  -g -O2 -march=nocona -c ogr_proj.cpp -o ogr_proj.o
g++ -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/i386 -I/usr/local/include -msse3    -fPIC  -g -O2 -march=nocona -c ogrdrivers.cpp -o ogrdrivers.o
g++ -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/i386 -I/usr/local/include -msse3    -fPIC  -g -O2 -march=nocona -c ogrsource.cpp -o ogrsource.o
g++ -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/i386 -I/usr/local/include -msse3    -fPIC  -g -O2 -march=nocona -c projectit.cpp -o projectit.o
g++ -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -dynamiclib -Wl,-headerpad_max_install_names -Wl,-macosx_version_min -Wl,10.4 -undefined dynamic_lookup -single_module -multiply_defined suppress -L/usr/local/lib -o rgdal.so OGR_write.o gdal-bindings.o ogr_geom.o ogr_proj.o ogrdrivers.o ogrsource.o projectit.o -L/usr/local/lib -lgdal -lproj  -F/Library/Frameworks/R.framework/.. -framework R 
** Removing '/Library/Frameworks/R.framework/Resources/library/rgdal'
/usr/bin/libtool: for architecture ppc7400 object: /usr/lib/gcc/i686-apple-darwin8/4.0.1/libstdc++.dylib malformed object (unknown load command 7)
/usr/bin/libtool: for architecture: (null) file: -lstdc++ is not an object file (not allowed in a library)
/usr/bin/libtool: for architecture i386 object: /usr/lib/gcc/i686-apple-darwin8/4.0.1/libstdc++.dylib malformed object (unknown load command 8)
/usr/bin/libtool: for architecture ppc7400 object: /usr/lib/gcc/i686-apple-darwin8/4.0.1/../../../libSystem.dylib malformed object (unknown load command 7)
/usr/bin/libtool: for architecture: (null) file: -lSystem is not an object file (not allowed in a library)
/usr/bin/libtool: for architecture ppc64 object: /usr/lib/gcc/i686-apple-darwin8/4.0.1/../../../libSystem.dylib malformed object (unknown load command 7)
make: *** [rgdal.so] Error 1
chmod: /Library/Frameworks/R.framework/Resources/library/rgdal/libs/i386/*: No such file or directory
ERROR: compilation failed for package 'rgdal'

The downloaded packages are in
	/private/var/folders/nB/nBmBWJwdFiCTlNzaoS98rk+++TI/-Tmp-/RtmpYsVNHr/downloaded_packages
/Library/Frameworks/R.framework/Resources/library
* Installing *source* package 'spgrass6' ...
** R
** inst
** preparing package for lazy loading
Loading required package: sp
Loading required package: maptools
Loading required package: foreign
Error: package 'rgdal' required by 'spgrass6' could not be found
Execution halted
ERROR: lazy loading failed for package 'spgrass6'
** Removing '/Library/Frameworks/R.framework/Resources/library/spgrass6'

I'm not sure what to do next. Any suggestions?

Regards,
Tom



From Roger.Bivand at nhh.no  Wed Jan 23 08:43:55 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 23 Jan 2008 08:43:55 +0100 (CET)
Subject: [R-sig-Geo] spgrass6 build error on Mac OS X
In-Reply-To: <3a49e93f3274429c.47967c2d@noaa.gov>
References: <3a49e93f3274429c.47967c2d@noaa.gov>
Message-ID: <Pine.LNX.4.64.0801230828430.5617@reclus.nhh.no>

On Tue, 22 Jan 2008, Thomas.Adams at noaa.gov wrote:

> List,
>
> I am attempting to build spgrass6 on MacOS X 10.5.1 (Leopard) on a 2.33. 
> GHz Intel Core Duo MacBook Pro. Using the Mac OS X Cocoa GUI, I am 
> trying to install spgrass6 from source. I have gdal installed fine; when 
> I run gdal-config at a term window prompt, I get:
>
> Macintosh-2:bin teaiii$ gdal-config
> Usage: gdal-config [OPTIONS]
> Options:
> 	[--prefix[=DIR]]
> 	[--libs]
> 	[--dep-libs]
> 	[--cflags]
> 	[--version]
> 	[--ogr-enabled]
> 	[--formats]
>
> I have "Install dependencies" checked, so rgdal is downloaded and 
> attempts to build first. (No MacOS X binaries are available). So, I get:


I do not have any useful experience with any OSX systems (there are so 
many and they change so fast), so this is guesswork. Please verify that 
GDAL actually works, since gdal-config is a shell script. Does gdalinfo 
--version work? Does GRASS 6 build and work against GDAL?

Do other R source packages install correctly, that is, is the correct 
build train being chosen? Can you for example install maptools from 
source? Or a source package including c++ code? Is gcc 4.0.1 the version 
you should be using? Should it be looking for the PPC libraries given that 
you are building on i386? Is this a symptom that you are trying to 
build a univeral binary package without the correct tool train? Please try 
to avoid using the GUI for installation if possible, you may have better 
control without it. Does:

R_ARCH=/i386 R CMD INSTALL foo_1.0.tar.gz

in the OSX FAQ mean anything?

If this doesn't help, please try asking on the R-sig-mac list, hopefully 
reporting back here when the issue is resolved.

Roger

>
> /Library/Frameworks/R.framework/Resources/library
> * Installing *source* package 'rgdal' ...
> gdal-config: gdal-config
> checking for gcc... gcc -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -std=gnu99
> checking for C compiler default output file name... a.out
> checking whether the C compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -std=gnu99 accepts -g... yes
> checking for gcc -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -std=gnu99 option to accept ANSI C... none needed
> checking how to run the C preprocessor... gcc -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -std=gnu99 -E
> checking for egrep... grep -E
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking proj_api.h usability... yes
> checking proj_api.h presence... yes
> checking for proj_api.h... yes
> checking for pj_init_plus in -lproj... yes
> Package CPP flags: -I/usr/local/include
> Package LIBS: -L/usr/local/lib -lgdal
> configure: creating ./config.status
> config.status: creating src/Makevars
> ** libs
> ** arch - i386
> g++ -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/i386 -I/usr/local/include -msse3    -fPIC  -g -O2 -march=nocona -c OGR_write.cpp -o OGR_write.o
> g++ -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/i386 -I/usr/local/include -msse3    -fPIC  -g -O2 -march=nocona -c gdal-bindings.cpp -o gdal-bindings.o
> g++ -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/i386 -I/usr/local/include -msse3    -fPIC  -g -O2 -march=nocona -c ogr_geom.cpp -o ogr_geom.o
> g++ -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/i386 -I/usr/local/include -msse3    -fPIC  -g -O2 -march=nocona -c ogr_proj.cpp -o ogr_proj.o
> g++ -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/i386 -I/usr/local/include -msse3    -fPIC  -g -O2 -march=nocona -c ogrdrivers.cpp -o ogrdrivers.o
> g++ -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/i386 -I/usr/local/include -msse3    -fPIC  -g -O2 -march=nocona -c ogrsource.cpp -o ogrsource.o
> g++ -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/i386 -I/usr/local/include -msse3    -fPIC  -g -O2 -march=nocona -c projectit.cpp -o projectit.o
> g++ -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -mmacosx-version-min=10.4 -dynamiclib -Wl,-headerpad_max_install_names -Wl,-macosx_version_min -Wl,10.4 -undefined dynamic_lookup -single_module -multiply_defined suppress -L/usr/local/lib -o rgdal.so OGR_write.o gdal-bindings.o ogr_geom.o ogr_proj.o ogrdrivers.o ogrsource.o projectit.o -L/usr/local/lib -lgdal -lproj  -F/Library/Frameworks/R.framework/.. -framework R
> ** Removing '/Library/Frameworks/R.framework/Resources/library/rgdal'
> /usr/bin/libtool: for architecture ppc7400 object: /usr/lib/gcc/i686-apple-darwin8/4.0.1/libstdc++.dylib malformed object (unknown load command 7)
> /usr/bin/libtool: for architecture: (null) file: -lstdc++ is not an object file (not allowed in a library)
> /usr/bin/libtool: for architecture i386 object: /usr/lib/gcc/i686-apple-darwin8/4.0.1/libstdc++.dylib malformed object (unknown load command 8)
> /usr/bin/libtool: for architecture ppc7400 object: /usr/lib/gcc/i686-apple-darwin8/4.0.1/../../../libSystem.dylib malformed object (unknown load command 7)
> /usr/bin/libtool: for architecture: (null) file: -lSystem is not an object file (not allowed in a library)
> /usr/bin/libtool: for architecture ppc64 object: /usr/lib/gcc/i686-apple-darwin8/4.0.1/../../../libSystem.dylib malformed object (unknown load command 7)
> make: *** [rgdal.so] Error 1
> chmod: /Library/Frameworks/R.framework/Resources/library/rgdal/libs/i386/*: No such file or directory
> ERROR: compilation failed for package 'rgdal'
>
> The downloaded packages are in
> 	/private/var/folders/nB/nBmBWJwdFiCTlNzaoS98rk+++TI/-Tmp-/RtmpYsVNHr/downloaded_packages
> /Library/Frameworks/R.framework/Resources/library
> * Installing *source* package 'spgrass6' ...
> ** R
> ** inst
> ** preparing package for lazy loading
> Loading required package: sp
> Loading required package: maptools
> Loading required package: foreign
> Error: package 'rgdal' required by 'spgrass6' could not be found
> Execution halted
> ERROR: lazy loading failed for package 'spgrass6'
> ** Removing '/Library/Frameworks/R.framework/Resources/library/spgrass6'
>
> I'm not sure what to do next. Any suggestions?
>
> Regards,
> Tom
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Wed Jan 23 08:53:08 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 23 Jan 2008 08:53:08 +0100 (CET)
Subject: [R-sig-Geo] plotting only polygons with points inside.
In-Reply-To: <54439.1623.qm@web56005.mail.re3.yahoo.com>
References: <54439.1623.qm@web56005.mail.re3.yahoo.com>
Message-ID: <Pine.LNX.4.64.0801230844390.5617@reclus.nhh.no>

On Tue, 22 Jan 2008, Milton Cezar Ribeiro wrote:

> Dear all,
>
> Following a code suggested by Roger Bivand (thanks Roger!), I made a 
> little modification to my own case.
>
> My questions are: (1) how can I plot only those polygons where I have 
> "cnt">0;

subset the SpataialPolygonsDataFrame object with "[", and plot this object 
with add=TRUE;

> (2) how can I define classes of "cnt" (like 1-5; >5 to 20; >20-100) and 
> choose a color for each level of cnt?

Have a look at the classInt package, fixed style. Using cut() (creates 
an *un*ordered factor with indices increasing in encountered levels) is 
less satisfactory than findInterval() - essentially you need a vector of 
colours, a vector of breaks, and

col=cols[findInterval(x, brks, all.inside=TRUE)]

should get you there.

> (3) just suppose that my points have an attribute like species name, how 
> can I generate a new collum like cnt_species with the number of species 
> on each polygon?

Done below (if I understand you correctly), see summary(r.grd.df) - cnt is 
the new variable with one value per spatial entity. Choose a more suitable 
name than cnt when making the data frame.

Roger

>
> Below follow the code wrote by Roger Bivand.
>
> Thanks in advance
>
> Miltinho
>
> ===
> library(sp)
> start.point <- -5
> cco <- c(start.point,start.point)
> csize <- c(1,1)
> n <- abs(cco[1]*2)+1
> cnum <- c(n,n)
> grd <- GridTopology(cco, csize, cnum)
> r.grd <- as(grd, "SpatialPolygons")
>
> set.seed(1)
> x <- rnorm(10000)
> y <- rnorm(10000)
> xy <- SpatialPoints(cbind(x, y))
>
> o1 <- overlay(xy, r.grd)
> res <- numeric(prod(cnum))
> tres <- table(o1)
> ntres <- as.integer(names(tres))
> res[ntres] <- tres
> IDs <- sapply(slot(r.grd, "polygons"), function(x) slot(x, "ID"))
> resdf <- data.frame(cnt=res, row.names=IDs)
> r.grd.df <- SpatialPolygonsDataFrame(r.grd, resdf)
> spts <- list("sp.points", xy, pch=".", col="black")
> spplot(r.grd.df, "cnt", sp.layout=spts)
>
>
>
> para armazenamento!
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From tmj at visi.com  Wed Jan 23 10:54:53 2008
From: tmj at visi.com (Thomas Juntunen)
Date: Wed, 23 Jan 2008 03:54:53 -0600
Subject: [R-sig-Geo] spgrass6 build error on Mac OS X
In-Reply-To: <3a49e93f3274429c.47967c2d@noaa.gov>
References: <3a49e93f3274429c.47967c2d@noaa.gov>
Message-ID: <20080123035453296121.f1158b0f@visi.com>

On Tue, 22 Jan 2008 23:28:45 -0500, Thomas.Adams at noaa.gov wrote:

> I am attempting to build spgrass6 on MacOS X 10.5.1 (Leopard) on a 2.33. GHz 
> Intel Core Duo MacBook Pro.
[...]
> I have "Install dependencies" checked, so rgdal is downloaded and attempts to 
> build first. (No MacOS X binaries are available).

William Kyngesburye provides many UNIX frameworks as OS X binaries on his web 
site:
http://www.kyngchaos.com/wiki/software:frameworks

As of this writing he still has rgdal for R 2.5. He also has advice for 
compiling under OS X.


> ** libs
> ** arch - i386
> g++ -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk 
> -mmacosx-version-min=10.4 -no-cpp-precomp 
> -I/Library/Frameworks/R.framework/Resources/include 
> -I/Library/Frameworks/R.framework/Resources/include/i386 -I/usr/local/include 
> -msse3    -fPIC  -g -O2 -march=nocona -c OGR_write.cpp -o OGR_write.o

[...]

> g++ -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk 
> -mmacosx-version-min=10.4 -dynamiclib -Wl,-headerpad_max_install_names 
> -Wl,-macosx_version_min -Wl,10.4 -undefined dynamic_lookup -single_module 
> -multiply_defined suppress -L/usr/local/lib -o rgdal.so OGR_write.o 
> gdal-bindings.o ogr_geom.o ogr_proj.o ogrdrivers.o ogrsource.o projectit.o 
> -L/usr/local/lib -lgdal -lproj  -F/Library/Frameworks/R.framework/.. 
> -framework R 
> ** Removing '/Library/Frameworks/R.framework/Resources/library/rgdal'
> /usr/bin/libtool: for architecture ppc7400 object: 
> /usr/lib/gcc/i686-apple-darwin8/4.0.1/libstdc++.dylib malformed object 
> (unknown load command 7)
> /usr/bin/libtool: for architecture: (null) file: -lstdc++ is not an object 
> file (not allowed in a library)
> /usr/bin/libtool: for architecture i386 object: 
> /usr/lib/gcc/i686-apple-darwin8/4.0.1/libstdc++.dylib malformed object 
> (unknown load command 8)
> /usr/bin/libtool: for architecture ppc7400 object: 
> /usr/lib/gcc/i686-apple-darwin8/4.0.1/../../../libSystem.dylib malformed 
> object (unknown load command 7)
> /usr/bin/libtool: for architecture: (null) file: -lSystem is not an object 
> file (not allowed in a library)
> /usr/bin/libtool: for architecture ppc64 object: 
> /usr/lib/gcc/i686-apple-darwin8/4.0.1/../../../libSystem.dylib malformed 
> object (unknown load command 7)
> make: *** [rgdal.so] Error 1
> chmod: /Library/Frameworks/R.framework/Resources/library/rgdal/libs/i386/*: 
> No such file or directory
> ERROR: compilation failed for package 'rgdal'

It appears to be an architecture mismatch. Did you upgrade from 10.4.x to 
10.5.1 but not upgrade XTools? My MacBookPro with 10.5.1 and XTools 3 has 
/Developer/SDKs/MacOSX10.5.sdk as well as the older 10.4u.

HTH,
Thomas Juntunen



From knussear at usgs.gov  Wed Jan 23 14:13:18 2008
From: knussear at usgs.gov (Ken Nussear)
Date: Wed, 23 Jan 2008 05:13:18 -0800
Subject: [R-sig-Geo] spgrass6 build error on Mac OS X
In-Reply-To: <mailman.9.1201086002.25376.r-sig-geo@stat.math.ethz.ch>
References: <mailman.9.1201086002.25376.r-sig-geo@stat.math.ethz.ch>
Message-ID: <2BE7F14B-AEE9-43A3-B160-3A8C82B1002D@usgs.gov>

I picked up an rgdal binary from kyngchaos here just yesterday...

http://www.kyngchaos.com/files/software/unixport/rgdal-0.5.15-1.zip

and was able install the binary, and then install spgrass6 from  
source  no problem, running R 2.6.1 and R gui 1.23 - devel (4901) and  
Mac OS 10.5.1


Ken


>
>
> Message: 8
> Date: Wed, 23 Jan 2008 03:54:53 -0600
> From: Thomas Juntunen <tmj at visi.com>
> Subject: Re: [R-sig-Geo] spgrass6 build error on Mac OS X
> To: Thomas.Adams at noaa.gov
> Cc: r-sig-geo at stat.math.ethz.ch
> Message-ID: <20080123035453296121.f1158b0f at visi.com>
> Content-Type: text/plain; charset=us-ascii
>
> On Tue, 22 Jan 2008 23:28:45 -0500, Thomas.Adams at noaa.gov wrote:
>
>> I am attempting to build spgrass6 on MacOS X 10.5.1 (Leopard) on a  
>> 2.33. GHz
>> Intel Core Duo MacBook Pro.
> [...]
>> I have "Install dependencies" checked, so rgdal is downloaded and  
>> attempts to
>> build first. (No MacOS X binaries are available).
>
> William Kyngesburye provides many UNIX frameworks as OS X binaries  
> on his web
> site:
> http://www.kyngchaos.com/wiki/software:frameworks
>
> As of this writing he still has rgdal for R 2.5. He also has advice  
> for
> compiling under OS X.
>
>
>> ** libs
>>
> *****************************************



>



From roland.kaiser at sbg.ac.at  Wed Jan 23 15:13:27 2008
From: roland.kaiser at sbg.ac.at (Roland Kaiser)
Date: Wed, 23 Jan 2008 15:13:27 +0100
Subject: [R-sig-Geo] spgrass6 build error on Mac OS X
In-Reply-To: <2BE7F14B-AEE9-43A3-B160-3A8C82B1002D@usgs.gov>
References: <mailman.9.1201086002.25376.r-sig-geo@stat.math.ethz.ch>
	<2BE7F14B-AEE9-43A3-B160-3A8C82B1002D@usgs.gov>
Message-ID: <1ED19259-B0B5-4459-8C71-E004A1F513DB@sbg.ac.at>

I did the following to get it run on Tiger (R version 2.6.1  
(2007-11-26)):

Installed
GDAL 1.5 Framework from kyngchaos
PROJ 4.6 Framework from kyngchaos
additionally compiled PROJ 4.6.0 from source
and used /usr/local/lib as path to libproj.a

I'm not quite sure if mixing installations is correct usage,
but I didn't get it compile using PROJ 4.6 Framework alone
because libproj.a seems to be missing.

The following did the job without problems:

R CMD INSTALL /Users/roli/Desktop/rgdal_0.5-22.tar.gz --configure- 
args='--with-gdal-config=/Library/Frameworks/GDAL.framework/Versions/ 
1.5/Programs/gdal-config --with-proj-include=/Library/Frameworks/ 
PROJ.framework/Versions/4.6/unix/include --with-proj-lib=/usr/local/lib'

R CMD INSTALL /Users/roli/Desktop/spgrass6_0.4-4.tar.gz

I hope this help?

Roland

Am 23.01.2008 um 14:13 schrieb Ken Nussear:

> I picked up an rgdal binary from kyngchaos here just yesterday...
>
> http://www.kyngchaos.com/files/software/unixport/rgdal-0.5.15-1.zip
>
> and was able install the binary, and then install spgrass6 from
> source  no problem, running R 2.6.1 and R gui 1.23 - devel (4901) and
> Mac OS 10.5.1
>
>
> Ken
>
>
>>
>>
>> Message: 8
>> Date: Wed, 23 Jan 2008 03:54:53 -0600
>> From: Thomas Juntunen <tmj at visi.com>
>> Subject: Re: [R-sig-Geo] spgrass6 build error on Mac OS X
>> To: Thomas.Adams at noaa.gov
>> Cc: r-sig-geo at stat.math.ethz.ch
>> Message-ID: <20080123035453296121.f1158b0f at visi.com>
>> Content-Type: text/plain; charset=us-ascii
>>
>> On Tue, 22 Jan 2008 23:28:45 -0500, Thomas.Adams at noaa.gov wrote:
>>
>>> I am attempting to build spgrass6 on MacOS X 10.5.1 (Leopard) on a
>>> 2.33. GHz
>>> Intel Core Duo MacBook Pro.
>> [...]
>>> I have "Install dependencies" checked, so rgdal is downloaded and
>>> attempts to
>>> build first. (No MacOS X binaries are available).
>>
>> William Kyngesburye provides many UNIX frameworks as OS X binaries
>> on his web
>> site:
>> http://www.kyngchaos.com/wiki/software:frameworks
>>
>> As of this writing he still has rgdal for R 2.5. He also has advice
>> for
>> compiling under OS X.
>>
>>
>>> ** libs
>>>
>> *****************************************
>
>
>
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From pandit.ram at gmail.com  Wed Jan 23 19:27:19 2008
From: pandit.ram at gmail.com (Ram Pandit)
Date: Wed, 23 Jan 2008 12:27:19 -0600
Subject: [R-sig-Geo] Different results for same model in GEODA and R?
	[RESOLVED]
Message-ID: <4ec06e730801231027x647f58c8ycbd3dfc011f2155b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080123/879f6515/attachment.pl>

From stefan.duke at gmail.com  Wed Jan 23 23:22:55 2008
From: stefan.duke at gmail.com (stefan lhachimi)
Date: Wed, 23 Jan 2008 23:22:55 +0100
Subject: [R-sig-Geo] merging data with SpatialPolygonsDataFrame
Message-ID: <a211af3b0801231422p190dda72r997d31b2a8eb076e@mail.gmail.com>

Hello,
I am having a spatial object by reading a shp-file by the
readShapePoly command. I now want to add data into the
SpatialPolygonsDataFrame from an external source (its a dataframe
which has a common key SHN_N). I am using the merge command, which I
thought works fine, unitl I realized that "map.kreise" now became just
a data.frame.
My greatest fear in working with spatial objects is that, if I don't
have them in one object, I end up plotting a value for the wrong
region. So is there a way to use merge or what is the most appropriate
way to combine data?

map.kreise<-readShapePoly("vg250krs",IDvar="KRS_ID",verbos=TRUE) #
reads the shape file
map.kreise<-merge(map.kreise,INC,sort = FALSE,by.map.kreise="SHN_N",
by.INC="SHN_N",all.map.kreise=T,all.INC=T)

Thanks a lot in advance,
Stefan



From Roger.Bivand at nhh.no  Thu Jan 24 09:14:48 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 24 Jan 2008 09:14:48 +0100 (CET)
Subject: [R-sig-Geo] merging data with SpatialPolygonsDataFrame
In-Reply-To: <a211af3b0801231422p190dda72r997d31b2a8eb076e@mail.gmail.com>
References: <a211af3b0801231422p190dda72r997d31b2a8eb076e@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0801240857490.6025@reclus.nhh.no>

On Wed, 23 Jan 2008, stefan lhachimi wrote:

> Hello,
> I am having a spatial object by reading a shp-file by the
> readShapePoly command. I now want to add data into the
> SpatialPolygonsDataFrame from an external source (its a dataframe
> which has a common key SHN_N). I am using the merge command, which I
> thought works fine, unitl I realized that "map.kreise" now became just
> a data.frame.

merge() is a "false friend", because a SpatialPolygonsDataFrame can be 
coerced to a data.frame, which is what merge() does without asking.

It may be best to say corece first, merge() the two data.frames, and 
rebuild the SpatialPolygonsDataFrame with SpatialPolygonsDataFrame().

map.kreise.df <- as(map.kreise, "data.frame")
map.kreise.df1 <- merge(map.kreise.df, INC, sort=FALSE, by.x="SHN_N",
   by.y="SHN_N", all.x=TRUE, all.y=TRUE)
map.kreise1 <- SpatialPolygonsDataFrame(as(map.kreise, "SpatialPolygons"),
   data=map.kreise.df1)

which may fail if INC and map.kreise.df have different row.names. The 
argument match.ID= (default TRUE) to SpatialPolygonsDataFrame matches the 
polygon IDs to the data= row.names - they must agree exactly though the 
data frame rows will be re-ordered to match the polygons if only the 
orders differ. Your concern here is real, which is why the argument is 
there.

If you don't need merge to manipulate the data frames, you can go straight 
for:

all.equal(row.names(INC), row.names(as(map.kreise, "data.frame"))
map.kreise1 <- spCbind(map.kreise, INC)

if the row.names of INC match the polygon IDs, and thus the row.names of
as(map.kreise, "data.frame"), see ?spCbind in maptools, and the example 
included there.

Hope this helps,

Roger


> My greatest fear in working with spatial objects is that, if I don't
> have them in one object, I end up plotting a value for the wrong
> region. So is there a way to use merge or what is the most appropriate
> way to combine data?
>
> map.kreise<-readShapePoly("vg250krs",IDvar="KRS_ID",verbos=TRUE) #
> reads the shape file
> map.kreise<-merge(map.kreise,INC,sort = FALSE,by.map.kreise="SHN_N",
> by.INC="SHN_N",all.map.kreise=T,all.INC=T)
>
> Thanks a lot in advance,
> Stefan
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From jefunes at gmail.com  Thu Jan 24 16:25:49 2008
From: jefunes at gmail.com (Jose Funes)
Date: Thu, 24 Jan 2008 10:25:49 -0500
Subject: [R-sig-Geo] Regression kriging
Message-ID: <8e01f5830801240725m705d7bafq34993457bfc72ed5@mail.gmail.com>

Hi,

I have used regression kriging to model abundance of an invasive
species. After performing a stepwise regression of the model, I fitted
a theoretical variogram to a empirical variogram of the residuals. My
question is how to obtain the parameter estimate of the model after
kriging the residuals. Do the parameters of the regression model
differ after kriging the residuals? if so, how can I get them from the
R output?

Looking forward to hearing from you, thanks

Jose Funes



From dylan.beaudette at gmail.com  Thu Jan 24 20:18:33 2008
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Thu, 24 Jan 2008 11:18:33 -0800
Subject: [R-sig-Geo] merging data with SpatialPolygonsDataFrame
In-Reply-To: <Pine.LNX.4.64.0801240857490.6025@reclus.nhh.no>
References: <a211af3b0801231422p190dda72r997d31b2a8eb076e@mail.gmail.com>
	<Pine.LNX.4.64.0801240857490.6025@reclus.nhh.no>
Message-ID: <200801241118.34009.dylan.beaudette@gmail.com>

On Thursday 24 January 2008, Roger Bivand wrote:
> On Wed, 23 Jan 2008, stefan lhachimi wrote:
> > Hello,
> > I am having a spatial object by reading a shp-file by the
> > readShapePoly command. I now want to add data into the
> > SpatialPolygonsDataFrame from an external source (its a dataframe
> > which has a common key SHN_N). I am using the merge command, which I
> > thought works fine, unitl I realized that "map.kreise" now became just
> > a data.frame.
>
> merge() is a "false friend", because a SpatialPolygonsDataFrame can be
> coerced to a data.frame, which is what merge() does without asking.
>
> It may be best to say corece first, merge() the two data.frames, and
> rebuild the SpatialPolygonsDataFrame with SpatialPolygonsDataFrame().
>
> map.kreise.df <- as(map.kreise, "data.frame")
> map.kreise.df1 <- merge(map.kreise.df, INC, sort=FALSE, by.x="SHN_N",
>    by.y="SHN_N", all.x=TRUE, all.y=TRUE)
> map.kreise1 <- SpatialPolygonsDataFrame(as(map.kreise, "SpatialPolygons"),
>    data=map.kreise.df1)
>
> which may fail if INC and map.kreise.df have different row.names. The
> argument match.ID= (default TRUE) to SpatialPolygonsDataFrame matches the
> polygon IDs to the data= row.names - they must agree exactly though the
> data frame rows will be re-ordered to match the polygons if only the
> orders differ. Your concern here is real, which is why the argument is
> there.
>
> If you don't need merge to manipulate the data frames, you can go straight
> for:
>
> all.equal(row.names(INC), row.names(as(map.kreise, "data.frame"))
> map.kreise1 <- spCbind(map.kreise, INC)
>
> if the row.names of INC match the polygon IDs, and thus the row.names of
> as(map.kreise, "data.frame"), see ?spCbind in maptools, and the example
> included there.
>
> Hope this helps,
>
> Roger
>
> > My greatest fear in working with spatial objects is that, if I don't
> > have them in one object, I end up plotting a value for the wrong
> > region. So is there a way to use merge or what is the most appropriate
> > way to combine data?
> >
> > map.kreise<-readShapePoly("vg250krs",IDvar="KRS_ID",verbos=TRUE) #
> > reads the shape file
> > map.kreise<-merge(map.kreise,INC,sort = FALSE,by.map.kreise="SHN_N",
> > by.INC="SHN_N",all.map.kreise=T,all.INC=T)
> >
> > Thanks a lot in advance,
> > Stefan
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo


Hi Roger. Thanks for contributing some answers to this. 

I was recently working with a colleague on developing some sample exercises 
for new students. Since joining new attribute data to a GIS layer's table is 
a very common operation we included some samples on how to do this within R. 
You have hinted at some possible ways to do it above, but do you have a 'best 
practices' approach to doing this using 'sp' methods and objects?

For example:

# contains an attribute col named 'veg_code'
veg <- readOGR(something.shp)

# code meanings: indexed by 'veg_code'
codes <- read.dbf(table.dbf)

# what is the best way to join up the attributes in 'veg' with the rows 
in 'codes' ?


As of now we are using merge to replace the dataframe slot of the original 
file. We first re-order the results from merge to match the original row 
ordering:


# an example file:
veg <- readOGR(dsn='ArcGISLabData/BrownsPond/', layer='vegevector')

# some example codes
veg_codes <- data.frame(code=1:4, meaning=c('code 1','code 2','code 3','code 
4'))

# join the original data table with the veg codes table
combined <- merge(x=veg at data, y=veg_codes, by.x='CODE', by.y='code')


# overwrite the original data frame with the combined version
# note that the original order needs to be restored
# since the original data was sorted on 'ID', we can use that to restore
# the correct order in the 'combined' dataframe:
v at data <- combined[order(combined$ID),]


In summary, is there a safer or preferred way to do this?

thanks,

Dylan









-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341



From Roger.Bivand at nhh.no  Thu Jan 24 20:46:18 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 24 Jan 2008 20:46:18 +0100 (CET)
Subject: [R-sig-Geo] merging data with SpatialPolygonsDataFrame
In-Reply-To: <200801241118.34009.dylan.beaudette@gmail.com>
References: <a211af3b0801231422p190dda72r997d31b2a8eb076e@mail.gmail.com>
	<Pine.LNX.4.64.0801240857490.6025@reclus.nhh.no>
	<200801241118.34009.dylan.beaudette@gmail.com>
Message-ID: <Pine.LNX.4.64.0801242027320.7165@reclus.nhh.no>

On Thu, 24 Jan 2008, Dylan Beaudette wrote:

>
> Hi Roger. Thanks for contributing some answers to this.
>
> I was recently working with a colleague on developing some sample exercises
> for new students. Since joining new attribute data to a GIS layer's table is
> a very common operation we included some samples on how to do this within R.
> You have hinted at some possible ways to do it above, but do you have a 'best
> practices' approach to doing this using 'sp' methods and objects?
>
> For example:
>
> # contains an attribute col named 'veg_code'
> veg <- readOGR(something.shp)
>
> # code meanings: indexed by 'veg_code'
> codes <- read.dbf(table.dbf)
>
> # what is the best way to join up the attributes in 'veg' with the rows
> in 'codes' ?

Hi Dylan,

This is a different question, but I won't break it out of this thread yet.

You are doing look-up on codes to give labels to veg$veg_code, right?

veg$veg_code are integer indices to codes$V1 (say V1, I don't know what it 
is). If length(unique(veg$veg_code)) == length(codes$V1), and 
sort(unique(veg$veg_code)) is 1:length(codes$V1), you should think of the 
factor as your friend:

veg$veg_code_factor <- factor(veg$veg_code, labels=as.character(codes$V1))

If not, you need another layer using perhaps order() or match() on the 
matching substring of codes$V1 to find out which value of veg$veg_code 
should have which label in as.character(codes$V1). Alternatively use the 
levels= argument to factor().

Something like:

set.seed(1)
veg_code <- rpois(100, 4)
table(veg_code)
V1 <- paste("code", 0:10)
V1
levs <- 0:10
veg_code_factor <- factor(veg_code, levels=levs, labels=V1)
table(veg_code_factor, veg_code)

No merging or messing with veg itself is needed, apart from adding a 
single extra factor column. The factor abstraction is a great strength of 
the S language.

Have I misunderstood you?

Roger


>
>
> As of now we are using merge to replace the dataframe slot of the original
> file. We first re-order the results from merge to match the original row
> ordering:
>
>
> # an example file:
> veg <- readOGR(dsn='ArcGISLabData/BrownsPond/', layer='vegevector')
>
> # some example codes
> veg_codes <- data.frame(code=1:4, meaning=c('code 1','code 2','code 3','code
> 4'))
>
> # join the original data table with the veg codes table
> combined <- merge(x=veg at data, y=veg_codes, by.x='CODE', by.y='code')
>
>
> # overwrite the original data frame with the combined version
> # note that the original order needs to be restored
> # since the original data was sorted on 'ID', we can use that to restore
> # the correct order in the 'combined' dataframe:
> v at data <- combined[order(combined$ID),]
>
>
> In summary, is there a safer or preferred way to do this?
>
> thanks,
>
> Dylan
>
>
>
>
>
>
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From dylan.beaudette at gmail.com  Thu Jan 24 23:57:34 2008
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Thu, 24 Jan 2008 14:57:34 -0800
Subject: [R-sig-Geo] merging data with SpatialPolygonsDataFrame
In-Reply-To: <Pine.LNX.4.64.0801242027320.7165@reclus.nhh.no>
References: <a211af3b0801231422p190dda72r997d31b2a8eb076e@mail.gmail.com>
	<200801241118.34009.dylan.beaudette@gmail.com>
	<Pine.LNX.4.64.0801242027320.7165@reclus.nhh.no>
Message-ID: <200801241457.34070.dylan.beaudette@gmail.com>

On Thursday 24 January 2008, Roger Bivand wrote:
> On Thu, 24 Jan 2008, Dylan Beaudette wrote:
> > Hi Roger. Thanks for contributing some answers to this.
> >
> > I was recently working with a colleague on developing some sample
> > exercises for new students. Since joining new attribute data to a GIS
> > layer's table is a very common operation we included some samples on how
> > to do this within R. You have hinted at some possible ways to do it
> > above, but do you have a 'best practices' approach to doing this using
> > 'sp' methods and objects?
> >
> > For example:
> >
> > # contains an attribute col named 'veg_code'
> > veg <- readOGR(something.shp)
> >
> > # code meanings: indexed by 'veg_code'
> > codes <- read.dbf(table.dbf)
> >
> > # what is the best way to join up the attributes in 'veg' with the rows
> > in 'codes' ?
>
> Hi Dylan,
>
> This is a different question, but I won't break it out of this thread yet.
>
> You are doing look-up on codes to give labels to veg$veg_code, right?
>
> veg$veg_code are integer indices to codes$V1 (say V1, I don't know what it
> is). If length(unique(veg$veg_code)) == length(codes$V1), and
> sort(unique(veg$veg_code)) is 1:length(codes$V1), you should think of the
> factor as your friend:
>
> veg$veg_code_factor <- factor(veg$veg_code, labels=as.character(codes$V1))
>
> If not, you need another layer using perhaps order() or match() on the
> matching substring of codes$V1 to find out which value of veg$veg_code
> should have which label in as.character(codes$V1). Alternatively use the
> levels= argument to factor().
>
> Something like:
>
> set.seed(1)
> veg_code <- rpois(100, 4)
> table(veg_code)
> V1 <- paste("code", 0:10)
> V1
> levs <- 0:10
> veg_code_factor <- factor(veg_code, levels=levs, labels=V1)
> table(veg_code_factor, veg_code)
>
> No merging or messing with veg itself is needed, apart from adding a
> single extra factor column. The factor abstraction is a great strength of
> the S language.
>
> Have I misunderstood you?
>
> Roger

I think so. 

I was (trying to) describe the process of joining, either 1:1 or many:1, the 
att table associated with an sp object and some other data frame.

merge() seems to work fine, but the order of the rows are different from the 
original data frame attached to the sp object.

My question was on the best way to 'update' the data frame attached to an sp 
object, based on the results from a merge() with some other data.

does that help?

cheers,

Dylan


> > As of now we are using merge to replace the dataframe slot of the
> > original file. We first re-order the results from merge to match the
> > original row ordering:
> >
> >
> > # an example file:
> > veg <- readOGR(dsn='ArcGISLabData/BrownsPond/', layer='vegevector')
> >
> > # some example codes
> > veg_codes <- data.frame(code=1:4, meaning=c('code 1','code 2','code
> > 3','code 4'))
> >
> > # join the original data table with the veg codes table
> > combined <- merge(x=veg at data, y=veg_codes, by.x='CODE', by.y='code')
> >
> >
> > # overwrite the original data frame with the combined version
> > # note that the original order needs to be restored
> > # since the original data was sorted on 'ID', we can use that to restore
> > # the correct order in the 'combined' dataframe:
> > v at data <- combined[order(combined$ID),]
> >
> >
> > In summary, is there a safer or preferred way to do this?
> >
> > thanks,
> >
> > Dylan



-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341



From tkobayas at indiana.edu  Fri Jan 25 06:15:47 2008
From: tkobayas at indiana.edu (Takatsugu Kobayashi)
Date: Fri, 25 Jan 2008 00:15:47 -0500
Subject: [R-sig-Geo] while loop help
Message-ID: <47997083.2060300@indiana.edu>

Hi, I must apologize both for this lengthy thread and for posting a 
thread based on the same example I have been using. 

I successfully created a code that re-arrange 10*10 grid cells of the 
same size into new grid cells of varying sizes.  Now I am attempting to 
create grid cells of the same size that are larger than the orignal 
10*10 grid cells, which means the total number of cells is a lot less 
than 100.  So If I would like to re-arrange a 10*10 grid cells by 
combining 4 cells, the number of new grid cells will be 25.

The function I created below stops with errors. It stops when a single 
cell is isolated after its cell's 1st order nearest neighbors are 
already taken.  I guess I could come up with a mathematical way of 
avoiding it, but I just wanted to loop it until no single cells are 
isolated, which means all new cells have the size equal to n.nb (the 
number of cells to be combined).

I would like to use the function below in a while loop or repeat loop, 
and when single cells are isolated I want to tell a code to start over 
the while loop from the beginning.  Because when I set the number of 
cells to be combined to 4, there are 25 sets of new grid cells (100/4), 
I know there is a solution rather than a code being trapped in an 
infinite looping.

So my question is how can I set up a code such that it starts over when 
errors occur?

Again, I am sorry for this lengthy thread. 

Thank you.

Taka

### Include necessary packages
library(sp)
library(maptools)
library(PBSmapping)


### Define parameters for a grid
start.point <- -0
cco <- c(start.point,start.point)
csize <- c(1,1)
n <- 10 #abs(cco[1]*2)+1
cnum <- c(n,n)
grd <- GridTopology(cco, csize, cnum)
r.grd <- as(grd, "SpatialPolygons")
r.grd.ps <- SpatialPolygons2PolySet(r.grd)


### Subset the grid into n*n single cells
### I use r.grd.ps over r.grd because I did not know how to clip out 
Slot "coords" from SpatialPolygons
### I tried lapply(slot(r.grd, "polygons"), function(x) slot(x, 
"coords")), but cannot obtain this slot

subPoly <- list()
coords <- list()
for (i in 1:n^2)
 {
  beg <- 5*i-4; end <- 5*i
  sP <- r.grd.ps[beg:end,]
  subPoly[[i]] <- sP
  cds <- calcCentroid(sP)
  coords[[i]] <- cbind(cds$X, cds$Y)
 }


### 1st order continuity neighbors
knn.nb <- list()
res <- vector("numeric",length=n^2)

for (ki in 1:n^2)
 for (ji in 1:n^2)
  {{
   ## Find the cells whose boundaries share with jth cell
   res[ji] <- 
length(which(subPoly[[ki]][1:4,4]%in%subPoly[[ji]][1:4,4]&subPoly[[ki]][1:4,5]%in%subPoly[[ji]][1:4,5]))  

   res[ki] <- 0
   ## Identify which cells are k-nearest neighbors excluding the 
reference zone
   knn.nb[[ki]] <- which(res>1)  
  }}


### Clip individual polygons and merge some of them based on adjacency 
weights
## Fixed number of cells to be combined excluding the jth cell
n.nb <- 3

maup <- function (knn.nb, n.nb)
{
## j for subPoly ID: input
j <- 1
## k for randomPoly ID: output
k <- 1
## A vector of subPoly IDs
sample.cell <- 1:n^2
## A list in which to store combined Polygons
randomPoly <- list()
## A vector of cell areas: for making sure all cells have the size of 
n.nb =4
areaPoly <-numeric(n^2/n.nb)

  while (all(areaPoly != n.nb))
        {
         ## Retrieve at most 5 contiguous neighbors
         j <- min(which(!is.nan(sample.cell)))
 
         ## Pick one nearest neighbor of jth cell randomly, including 
the jth cell
         d1.id <- which(!is.nan(knn.nb[[j]]))
         d1 <- knn.nb[[j]][d1.id]
         d1.rand <- round(runif(1,0.5,length(d1)))
         d1 <-  d1[d1.rand]
         nb.list <- append(j, d1)

         for (k.nb in 2:n.nb)
             {
              ## Pick one nearest neighbor of j+1th cell randomly
              ## Repeat till n.nb and append every cells chosen
              ## d as nearest neighbors
              d_id <- nb.list[k.nb]
              d_k_id <- which(!is.nan(knn.nb[[d_id]]))
              d_k <- knn.nb[[d_id]][d_k_id]
              non_overlap_id <- which(d_k%in%nb.list)
              d_k <- d_k[-non_overlap_id]
              dk.rand <- round(runif(1,0.5,length(d_k)))
              dk <- d_k[dk.rand]
              nb.list <- append(nb.list, dk)
             }

        ## Remove cells that are already taken
        sample.cell[nb.list] <- NaN
   
        for (ord in 1: n^2)
            {
             id.check <- which(knn.nb[[ord]]%in%nb.list)
             if (length(id.check)>0)
                {  
                knn.nb[[ord]][id.check] <- NaN
                }   
            }


        ## JoinPolys allows to join two of the same polysets
        joinedPoly <- joinPolys(subPoly[[j]],subPoly[[nb.list[2]]],"UNION")
   
        for (pl in 3:(n.nb+1)) # +1 means the jth cell
            {      
             joinedPoly <- 
joinPolys(joinedPoly,subPoly[[nb.list[pl]]],"UNION")       
            }

        ## PID should be single and unique
        randomPoly[[k]] <- combinePolys(joinedPoly)
        randomPoly[[k]]$PID <- k

      areaPoly[k] <- calcArea(randomPoly[[k]])[,3]
 
      k <- k+1
      }
}



From marco.helbich at gmx.at  Fri Jan 25 12:15:13 2008
From: marco.helbich at gmx.at (Marco Helbich)
Date: Fri, 25 Jan 2008 12:15:13 +0100
Subject: [R-sig-Geo] R-sig-Geo Digest, Vol 53, Issue 23
References: <mailman.11.1201258802.13650.r-sig-geo@stat.math.ethz.ch>
Message-ID: <002001c85f43$8e838290$0300a8c0@mirk>

Dear Jose,

a few weeks ago, I read something about it... perhaps you will be able to 
find your answers here:
http://bookshop.europa.eu/uri?target=EUB:NOTICE:LBNA22904:EN:HTML

the pdf explains regression kriging by means of an example.

I hope it helps

Best regards
Marco
-- 
Marco Helbich
Institute for Urban and Regional Research
Austrian Academy of Sciences
Postgasse 7/4/2, A-1010 Vienna, Austria (EU)
Tel. + 43 (1) 51 581 - 3536
e-mail: marco.helbich(at)oeaw.ac.at

>
> Message: 1
> Date: Thu, 24 Jan 2008 10:25:49 -0500
> From: "Jose Funes" <jefunes at gmail.com>
> Subject: [R-sig-Geo] Regression kriging
> To: r-sig-geo at stat.math.ethz.ch
> Message-ID:
> <8e01f5830801240725m705d7bafq34993457bfc72ed5 at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
>
> Hi,
>
> I have used regression kriging to model abundance of an invasive
> species. After performing a stepwise regression of the model, I fitted
> a theoretical variogram to a empirical variogram of the residuals. My
> question is how to obtain the parameter estimate of the model after
> kriging the residuals. Do the parameters of the regression model
> differ after kriging the residuals? if so, how can I get them from the
> R output?
>
> Looking forward to hearing from you, thanks
>
> Jose Funes
>



From Roger.Bivand at nhh.no  Fri Jan 25 17:57:08 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 25 Jan 2008 17:57:08 +0100 (CET)
Subject: [R-sig-Geo] merging data with SpatialPolygonsDataFrame
In-Reply-To: <200801241457.34070.dylan.beaudette@gmail.com>
References: <a211af3b0801231422p190dda72r997d31b2a8eb076e@mail.gmail.com>
	<200801241118.34009.dylan.beaudette@gmail.com>
	<Pine.LNX.4.64.0801242027320.7165@reclus.nhh.no>
	<200801241457.34070.dylan.beaudette@gmail.com>
Message-ID: <Pine.LNX.4.64.0801251644240.12880@reclus.nhh.no>

On Thu, 24 Jan 2008, Dylan Beaudette wrote:

> On Thursday 24 January 2008, Roger Bivand wrote:
>> On Thu, 24 Jan 2008, Dylan Beaudette wrote:
>>> Hi Roger. Thanks for contributing some answers to this.
>>>
>>> I was recently working with a colleague on developing some sample
>>> exercises for new students. Since joining new attribute data to a GIS
>>> layer's table is a very common operation we included some samples on how
>>> to do this within R. You have hinted at some possible ways to do it
>>> above, but do you have a 'best practices' approach to doing this using
>>> 'sp' methods and objects?
>>>
>>> For example:
>>>
>>> # contains an attribute col named 'veg_code'
>>> veg <- readOGR(something.shp)
>>>
>>> # code meanings: indexed by 'veg_code'
>>> codes <- read.dbf(table.dbf)
>>>
>>> # what is the best way to join up the attributes in 'veg' with the rows
>>> in 'codes' ?
>>
>> Hi Dylan,
>>
>> This is a different question, but I won't break it out of this thread yet.
>>
>> You are doing look-up on codes to give labels to veg$veg_code, right?
>>
>> veg$veg_code are integer indices to codes$V1 (say V1, I don't know what it
>> is). If length(unique(veg$veg_code)) == length(codes$V1), and
>> sort(unique(veg$veg_code)) is 1:length(codes$V1), you should think of the
>> factor as your friend:
>>
>> veg$veg_code_factor <- factor(veg$veg_code, labels=as.character(codes$V1))
>>
>> If not, you need another layer using perhaps order() or match() on the
>> matching substring of codes$V1 to find out which value of veg$veg_code
>> should have which label in as.character(codes$V1). Alternatively use the
>> levels= argument to factor().
>>
>> Something like:
>>
>> set.seed(1)
>> veg_code <- rpois(100, 4)
>> table(veg_code)
>> V1 <- paste("code", 0:10)
>> V1
>> levs <- 0:10
>> veg_code_factor <- factor(veg_code, levels=levs, labels=V1)
>> table(veg_code_factor, veg_code)
>>
>> No merging or messing with veg itself is needed, apart from adding a
>> single extra factor column. The factor abstraction is a great strength of
>> the S language.
>>
>> Have I misunderstood you?
>>
>> Roger
>
> I think so.
>
> I was (trying to) describe the process of joining, either 1:1 or many:1, the
> att table associated with an sp object and some other data frame.
>
> merge() seems to work fine, but the order of the rows are different from the
> original data frame attached to the sp object.

My experience is that merge() is often a false friend, because of object 
coercion and sorting, as you suggest. The rules for SpatialLinesDataFrame 
and SpatialPolygonsDataFrame are simple, and SpatialPointsDataFrame (and 
by extension SpatialPixelsDataFrame) can be made as simple. The first two
constructor functions take a match.ID= argument, default TRUE, which 
matches the geometry ID - the ID slot in the component Lines or Polygons 
objects - to the data.frame row.name. For SpatialPointsDataFrame(), the 
same argument exists, but is only used if the coordinate matrix has row 
names to be matched to the data.frame row names. If it has been used, the 
data slot row names are the geometry IDs.

>From there, it gets harder. merge() takes lots of arguments, and a lot of 
trial and error is needed to reach a satisfactory result, that is a single 
data frame with row names matching the geometry IDs (not necessarily in 
the right order, but the same set of IDs).

>
> My question was on the best way to 'update' the data frame attached to an sp
> object, based on the results from a merge() with some other data.
>

For one to one, there isn't really an alternative to extracting the data 
slot, do the merge, check the geometry IDs against the output data frame 
row names, and re-construct the object. That is, essentially where this 
thread began.

If there is less data than geometries, merge() should fill out with NAs. 
If there is more data than geometries, the output data frame will need 
subsetting. Both match(), order(), and %in% are very handy here.

For one geometry list to many - see reshape() first, for example to 
flatten a "tall" set of space/time observations so that the time values 
become new attribute columns. This could be met stations stacked by 
station and date, which need widening to stations by date*attributes

If need be, the IDs of the geometries can be changed too, see 
?"spChFIDs-methods" in maptools.

Any closer?

Roger

> does that help?
>
> cheers,
>
> Dylan
>
>
>>> As of now we are using merge to replace the dataframe slot of the
>>> original file. We first re-order the results from merge to match the
>>> original row ordering:
>>>
>>>
>>> # an example file:
>>> veg <- readOGR(dsn='ArcGISLabData/BrownsPond/', layer='vegevector')
>>>
>>> # some example codes
>>> veg_codes <- data.frame(code=1:4, meaning=c('code 1','code 2','code
>>> 3','code 4'))
>>>
>>> # join the original data table with the veg codes table
>>> combined <- merge(x=veg at data, y=veg_codes, by.x='CODE', by.y='code')
>>>
>>>
>>> # overwrite the original data frame with the combined version
>>> # note that the original order needs to be restored
>>> # since the original data was sorted on 'ID', we can use that to restore
>>> # the correct order in the 'combined' dataframe:
>>> v at data <- combined[order(combined$ID),]
>>>
>>>
>>> In summary, is there a safer or preferred way to do this?
>>>
>>> thanks,
>>>
>>> Dylan
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Thomas.Adams at noaa.gov  Fri Jan 25 17:59:21 2008
From: Thomas.Adams at noaa.gov (Thomas Adams)
Date: Fri, 25 Jan 2008 11:59:21 -0500
Subject: [R-sig-Geo] spgrass6 build error on Mac OS X
In-Reply-To: <20080123035453296121.f1158b0f@visi.com>
References: <3a49e93f3274429c.47967c2d@noaa.gov>
	<20080123035453296121.f1158b0f@visi.com>
Message-ID: <479A1569.7070307@noaa.gov>

Thomas,

Thanks to you and Roger for replies to my problem. It looks that you may 
be right about the /Developer/SDKs/MacOSX10.5.sdk. I -thought- I had 
updated the developer tools, but apparently not. I don't have the DVD 
install disk with me, so this evening I'll make the install of the 
correct developer tools and give the rgdal install another try and 
report back.

Thanks again for your help!

Regards,
Tom

Thomas Juntunen wrote:
> On Tue, 22 Jan 2008 23:28:45 -0500, Thomas.Adams at noaa.gov wrote:
>
>   
>> I am attempting to build spgrass6 on MacOS X 10.5.1 (Leopard) on a 2.33. GHz 
>> Intel Core Duo MacBook Pro.
>>     
> [...]
>   
>> I have "Install dependencies" checked, so rgdal is downloaded and attempts to 
>> build first. (No MacOS X binaries are available).
>>     
>
> William Kyngesburye provides many UNIX frameworks as OS X binaries on his web 
> site:
> http://www.kyngchaos.com/wiki/software:frameworks
>
> As of this writing he still has rgdal for R 2.5. He also has advice for 
> compiling under OS X.
>
>
>   
>> ** libs
>> ** arch - i386
>> g++ -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk 
>> -mmacosx-version-min=10.4 -no-cpp-precomp 
>> -I/Library/Frameworks/R.framework/Resources/include 
>> -I/Library/Frameworks/R.framework/Resources/include/i386 -I/usr/local/include 
>> -msse3    -fPIC  -g -O2 -march=nocona -c OGR_write.cpp -o OGR_write.o
>>     
>
> [...]
>
>   
>> g++ -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk 
>> -mmacosx-version-min=10.4 -dynamiclib -Wl,-headerpad_max_install_names 
>> -Wl,-macosx_version_min -Wl,10.4 -undefined dynamic_lookup -single_module 
>> -multiply_defined suppress -L/usr/local/lib -o rgdal.so OGR_write.o 
>> gdal-bindings.o ogr_geom.o ogr_proj.o ogrdrivers.o ogrsource.o projectit.o 
>> -L/usr/local/lib -lgdal -lproj  -F/Library/Frameworks/R.framework/.. 
>> -framework R 
>> ** Removing '/Library/Frameworks/R.framework/Resources/library/rgdal'
>> /usr/bin/libtool: for architecture ppc7400 object: 
>> /usr/lib/gcc/i686-apple-darwin8/4.0.1/libstdc++.dylib malformed object 
>> (unknown load command 7)
>> /usr/bin/libtool: for architecture: (null) file: -lstdc++ is not an object 
>> file (not allowed in a library)
>> /usr/bin/libtool: for architecture i386 object: 
>> /usr/lib/gcc/i686-apple-darwin8/4.0.1/libstdc++.dylib malformed object 
>> (unknown load command 8)
>> /usr/bin/libtool: for architecture ppc7400 object: 
>> /usr/lib/gcc/i686-apple-darwin8/4.0.1/../../../libSystem.dylib malformed 
>> object (unknown load command 7)
>> /usr/bin/libtool: for architecture: (null) file: -lSystem is not an object 
>> file (not allowed in a library)
>> /usr/bin/libtool: for architecture ppc64 object: 
>> /usr/lib/gcc/i686-apple-darwin8/4.0.1/../../../libSystem.dylib malformed 
>> object (unknown load command 7)
>> make: *** [rgdal.so] Error 1
>> chmod: /Library/Frameworks/R.framework/Resources/library/rgdal/libs/i386/*: 
>> No such file or directory
>> ERROR: compilation failed for package 'rgdal'
>>     
>
> It appears to be an architecture mismatch. Did you upgrade from 10.4.x to 
> 10.5.1 but not upgrade XTools? My MacBookPro with 10.5.1 and XTools 3 has 
> /Developer/SDKs/MacOSX10.5.sdk as well as the older 10.4u.
>
> HTH,
> Thomas Juntunen
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Thomas E Adams
National Weather Service
Ohio River Forecast Center
1901 South State Route 134
Wilmington, OH 45177

EMAIL:	thomas.adams at noaa.gov

VOICE:	937-383-0528
FAX:	937-383-0033



From dylan.beaudette at gmail.com  Fri Jan 25 22:05:34 2008
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Fri, 25 Jan 2008 13:05:34 -0800
Subject: [R-sig-Geo] merging data with SpatialPolygonsDataFrame
In-Reply-To: <Pine.LNX.4.64.0801251644240.12880@reclus.nhh.no>
References: <a211af3b0801231422p190dda72r997d31b2a8eb076e@mail.gmail.com>
	<200801241457.34070.dylan.beaudette@gmail.com>
	<Pine.LNX.4.64.0801251644240.12880@reclus.nhh.no>
Message-ID: <200801251305.34150.dylan.beaudette@gmail.com>

On Friday 25 January 2008, Roger Bivand wrote:
> On Thu, 24 Jan 2008, Dylan Beaudette wrote:
> > On Thursday 24 January 2008, Roger Bivand wrote:
> >> On Thu, 24 Jan 2008, Dylan Beaudette wrote:
> >>> Hi Roger. Thanks for contributing some answers to this.
> >>>
> >>> I was recently working with a colleague on developing some sample
> >>> exercises for new students. Since joining new attribute data to a GIS
> >>> layer's table is a very common operation we included some samples on
> >>> how to do this within R. You have hinted at some possible ways to do it
> >>> above, but do you have a 'best practices' approach to doing this using
> >>> 'sp' methods and objects?
> >>>
> >>> For example:
> >>>
> >>> # contains an attribute col named 'veg_code'
> >>> veg <- readOGR(something.shp)
> >>>
> >>> # code meanings: indexed by 'veg_code'
> >>> codes <- read.dbf(table.dbf)
> >>>
> >>> # what is the best way to join up the attributes in 'veg' with the rows
> >>> in 'codes' ?
> >>
> >> Hi Dylan,
> >>
> >> This is a different question, but I won't break it out of this thread
> >> yet.
> >>
> >> You are doing look-up on codes to give labels to veg$veg_code, right?
> >>
> >> veg$veg_code are integer indices to codes$V1 (say V1, I don't know what
> >> it is). If length(unique(veg$veg_code)) == length(codes$V1), and
> >> sort(unique(veg$veg_code)) is 1:length(codes$V1), you should think of
> >> the factor as your friend:
> >>
> >> veg$veg_code_factor <- factor(veg$veg_code,
> >> labels=as.character(codes$V1))
> >>
> >> If not, you need another layer using perhaps order() or match() on the
> >> matching substring of codes$V1 to find out which value of veg$veg_code
> >> should have which label in as.character(codes$V1). Alternatively use the
> >> levels= argument to factor().
> >>
> >> Something like:
> >>
> >> set.seed(1)
> >> veg_code <- rpois(100, 4)
> >> table(veg_code)
> >> V1 <- paste("code", 0:10)
> >> V1
> >> levs <- 0:10
> >> veg_code_factor <- factor(veg_code, levels=levs, labels=V1)
> >> table(veg_code_factor, veg_code)
> >>
> >> No merging or messing with veg itself is needed, apart from adding a
> >> single extra factor column. The factor abstraction is a great strength
> >> of the S language.
> >>
> >> Have I misunderstood you?
> >>
> >> Roger
> >
> > I think so.
> >
> > I was (trying to) describe the process of joining, either 1:1 or many:1,
> > the att table associated with an sp object and some other data frame.
> >
> > merge() seems to work fine, but the order of the rows are different from
> > the original data frame attached to the sp object.

Thanks for the detailed response Roger.

> My experience is that merge() is often a false friend, because of object
> coercion and sorting, as you suggest. The rules for SpatialLinesDataFrame
> and SpatialPolygonsDataFrame are simple, and SpatialPointsDataFrame (and
> by extension SpatialPixelsDataFrame) can be made as simple. The first two
> constructor functions take a match.ID= argument, default TRUE, which
> matches the geometry ID - the ID slot in the component Lines or Polygons
> objects - to the data.frame row.name. For SpatialPointsDataFrame(), the
> same argument exists, but is only used if the coordinate matrix has row
> names to be matched to the data.frame row names. If it has been used, the
> data slot row names are the geometry IDs.
>
> From there, it gets harder. merge() takes lots of arguments, and a lot of
> trial and error is needed to reach a satisfactory result, that is a single
> data frame with row names matching the geometry IDs (not necessarily in
> the right order, but the same set of IDs).
>
> > My question was on the best way to 'update' the data frame attached to an
> > sp object, based on the results from a merge() with some other data.
>
> For one to one, there isn't really an alternative to extracting the data
> slot, do the merge, check the geometry IDs against the output data frame
> row names, and re-construct the object. That is, essentially where this
> thread began.
>
> If there is less data than geometries, merge() should fill out with NAs.
> If there is more data than geometries, the output data frame will need
> subsetting. Both match(), order(), and %in% are very handy here.
>
> For one geometry list to many - see reshape() first, for example to
> flatten a "tall" set of space/time observations so that the time values
> become new attribute columns. This could be met stations stacked by
> station and date, which need widening to stations by date*attributes
>
> If need be, the IDs of the geometries can be changed too, see
> ?"spChFIDs-methods" in maptools.
>
> Any closer?

I think that you have answered my questions and reaffirmed my thoughts on how 
to proceed. I am mostly interested in 1:1 and 1:many joins (geom:attr), and I 
think that the following approach should work in the general case:

# read vector data:
v <- readOGR(dsn='...', layer='...')

# safer approach to 1:1 or 1:many (geom:atts) joins
# add a sorting id for later use
v at data$sorting_id <- 1:nrow(v at data)

# make a copy of the original table
orig.table <- v at data

# make the table with 'joined' data
new.table <- merge(x=orig.table, y=veg_codes, by.x='CODE', by.y='code')

# re-order this table based on the original row order
new.table.ordered <- new.table[order(new.table$sorting_id), ]

# restore the origina row names
row.names(new.table.ordered) <- row.names(orig.table)

# replace the data table
v at data <- new.table.ordered


This should ensure that the merged rows are in the original order, and have 
the original row.names.

Does that sound correct?

Thanks,

Dylan



> Roger
>
> > does that help?
> >
> > cheers,
> >
> > Dylan
> >
> >>> As of now we are using merge to replace the dataframe slot of the
> >>> original file. We first re-order the results from merge to match the
> >>> original row ordering:
> >>>
> >>>
> >>> # an example file:
> >>> veg <- readOGR(dsn='ArcGISLabData/BrownsPond/', layer='vegevector')
> >>>
> >>> # some example codes
> >>> veg_codes <- data.frame(code=1:4, meaning=c('code 1','code 2','code
> >>> 3','code 4'))
> >>>
> >>> # join the original data table with the veg codes table
> >>> combined <- merge(x=veg at data, y=veg_codes, by.x='CODE', by.y='code')
> >>>
> >>>
> >>> # overwrite the original data frame with the combined version
> >>> # note that the original order needs to be restored
> >>> # since the original data was sorted on 'ID', we can use that to
> >>> restore # the correct order in the 'combined' dataframe:
> >>> v at data <- combined[order(combined$ID),]
> >>>
> >>>
> >>> In summary, is there a safer or preferred way to do this?
> >>>
> >>> thanks,
> >>>
> >>> Dylan



-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341



From milton_ruser at yahoo.com.br  Fri Jan 25 22:39:06 2008
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Fri, 25 Jan 2008 13:39:06 -0800 (PST)
Subject: [R-sig-Geo] Res:  merging data with SpatialPolygonsDataFrame
Message-ID: <560104.63578.qm@web56011.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080125/961a0a4b/attachment.pl>

From tkobayas at indiana.edu  Sat Jan 26 06:24:01 2008
From: tkobayas at indiana.edu (Takatsugu Kobayashi)
Date: Sat, 26 Jan 2008 00:24:01 -0500
Subject: [R-sig-Geo] while loop help: SOLVED
In-Reply-To: <47997083.2060300@indiana.edu>
References: <47997083.2060300@indiana.edu>
Message-ID: <479AC3F1.7080906@indiana.edu>

I figured it out. Thanks for taking a look. thanks

Takatsugu Kobayashi wrote:
> Hi, I must apologize both for this lengthy thread and for posting a 
> thread based on the same example I have been using. 
>
> I successfully created a code that re-arrange 10*10 grid cells of the 
> same size into new grid cells of varying sizes.  Now I am attempting to 
> create grid cells of the same size that are larger than the orignal 
> 10*10 grid cells, which means the total number of cells is a lot less 
> than 100.  So If I would like to re-arrange a 10*10 grid cells by 
> combining 4 cells, the number of new grid cells will be 25.
>
> The function I created below stops with errors. It stops when a single 
> cell is isolated after its cell's 1st order nearest neighbors are 
> already taken.  I guess I could come up with a mathematical way of 
> avoiding it, but I just wanted to loop it until no single cells are 
> isolated, which means all new cells have the size equal to n.nb (the 
> number of cells to be combined).
>
> I would like to use the function below in a while loop or repeat loop, 
> and when single cells are isolated I want to tell a code to start over 
> the while loop from the beginning.  Because when I set the number of 
> cells to be combined to 4, there are 25 sets of new grid cells (100/4), 
> I know there is a solution rather than a code being trapped in an 
> infinite looping.
>
> So my question is how can I set up a code such that it starts over when 
> errors occur?
>
> Again, I am sorry for this lengthy thread. 
>
> Thank you.
>
> Taka
>
> ### Include necessary packages
> library(sp)
> library(maptools)
> library(PBSmapping)
>
>
> ### Define parameters for a grid
> start.point <- -0
> cco <- c(start.point,start.point)
> csize <- c(1,1)
> n <- 10 #abs(cco[1]*2)+1
> cnum <- c(n,n)
> grd <- GridTopology(cco, csize, cnum)
> r.grd <- as(grd, "SpatialPolygons")
> r.grd.ps <- SpatialPolygons2PolySet(r.grd)
>
>
> ### Subset the grid into n*n single cells
> ### I use r.grd.ps over r.grd because I did not know how to clip out 
> Slot "coords" from SpatialPolygons
> ### I tried lapply(slot(r.grd, "polygons"), function(x) slot(x, 
> "coords")), but cannot obtain this slot
>
> subPoly <- list()
> coords <- list()
> for (i in 1:n^2)
>  {
>   beg <- 5*i-4; end <- 5*i
>   sP <- r.grd.ps[beg:end,]
>   subPoly[[i]] <- sP
>   cds <- calcCentroid(sP)
>   coords[[i]] <- cbind(cds$X, cds$Y)
>  }
>
>
> ### 1st order continuity neighbors
> knn.nb <- list()
> res <- vector("numeric",length=n^2)
>
> for (ki in 1:n^2)
>  for (ji in 1:n^2)
>   {{
>    ## Find the cells whose boundaries share with jth cell
>    res[ji] <- 
> length(which(subPoly[[ki]][1:4,4]%in%subPoly[[ji]][1:4,4]&subPoly[[ki]][1:4,5]%in%subPoly[[ji]][1:4,5]))  
>
>    res[ki] <- 0
>    ## Identify which cells are k-nearest neighbors excluding the 
> reference zone
>    knn.nb[[ki]] <- which(res>1)  
>   }}
>
>
> ### Clip individual polygons and merge some of them based on adjacency 
> weights
> ## Fixed number of cells to be combined excluding the jth cell
> n.nb <- 3
>
> maup <- function (knn.nb, n.nb)
> {
> ## j for subPoly ID: input
> j <- 1
> ## k for randomPoly ID: output
> k <- 1
> ## A vector of subPoly IDs
> sample.cell <- 1:n^2
> ## A list in which to store combined Polygons
> randomPoly <- list()
> ## A vector of cell areas: for making sure all cells have the size of 
> n.nb =4
> areaPoly <-numeric(n^2/n.nb)
>
>   while (all(areaPoly != n.nb))
>         {
>          ## Retrieve at most 5 contiguous neighbors
>          j <- min(which(!is.nan(sample.cell)))
>  
>          ## Pick one nearest neighbor of jth cell randomly, including 
> the jth cell
>          d1.id <- which(!is.nan(knn.nb[[j]]))
>          d1 <- knn.nb[[j]][d1.id]
>          d1.rand <- round(runif(1,0.5,length(d1)))
>          d1 <-  d1[d1.rand]
>          nb.list <- append(j, d1)
>
>          for (k.nb in 2:n.nb)
>              {
>               ## Pick one nearest neighbor of j+1th cell randomly
>               ## Repeat till n.nb and append every cells chosen
>               ## d as nearest neighbors
>               d_id <- nb.list[k.nb]
>               d_k_id <- which(!is.nan(knn.nb[[d_id]]))
>               d_k <- knn.nb[[d_id]][d_k_id]
>               non_overlap_id <- which(d_k%in%nb.list)
>               d_k <- d_k[-non_overlap_id]
>               dk.rand <- round(runif(1,0.5,length(d_k)))
>               dk <- d_k[dk.rand]
>               nb.list <- append(nb.list, dk)
>              }
>
>         ## Remove cells that are already taken
>         sample.cell[nb.list] <- NaN
>    
>         for (ord in 1: n^2)
>             {
>              id.check <- which(knn.nb[[ord]]%in%nb.list)
>              if (length(id.check)>0)
>                 {  
>                 knn.nb[[ord]][id.check] <- NaN
>                 }   
>             }
>
>
>         ## JoinPolys allows to join two of the same polysets
>         joinedPoly <- joinPolys(subPoly[[j]],subPoly[[nb.list[2]]],"UNION")
>    
>         for (pl in 3:(n.nb+1)) # +1 means the jth cell
>             {      
>              joinedPoly <- 
> joinPolys(joinedPoly,subPoly[[nb.list[pl]]],"UNION")       
>             }
>
>         ## PID should be single and unique
>         randomPoly[[k]] <- combinePolys(joinedPoly)
>         randomPoly[[k]]$PID <- k
>
>       areaPoly[k] <- calcArea(randomPoly[[k]])[,3]
>  
>       k <- k+1
>       }
> }
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From marco.helbich at gmx.at  Sat Jan 26 19:02:21 2008
From: marco.helbich at gmx.at (Marco Helbich)
Date: Sat, 26 Jan 2008 19:02:21 +0100
Subject: [R-sig-Geo] kernel density estimation to google earth
Message-ID: <006301c86045$9924e100$0300a8c0@mirk>

Dear List,

I've calculated a kernel density estimation (splancs function) and now I 
want to export the result as a kml-file to open it in the google earth 
viewer, but I get stuck at converting the SpatialGridDataFrame to a 
SpatialPixelDataFrame...

here (http://www.zshare.net/download/689742375ef5fb/) you can download some 
testdata and my R-code so far:

###########
data.shp <- readOGR("C:/", layer="events")
prj <- data.shp@ proj4string@ projargs
dat <- data.shp
str(dat)
poly.shp <- readOGR("C:/", layer="hull")
str(poly.shp)

dat.SP <- as(dat, "SpatialPoints")
str(dat.SP)
pp_poi <- as.points(dat.SP at coords[,1], dat.SP at coords[,2])
poly <- 
getPolygonCoordsSlot(getPolygonsPolygonsSlot(getSpPpolygonsSlot(poly.shp)[[1]])[[1]])
polymap(poly)
points(pp_poi)

grd <- GridTopology(cellcentre.offset=c(590511, 396191), cellsize=c(2000, 
2000),
  cells.dim=c(30,25))
kbw2000 <- spkernel2d(pp_poi, poly, h0=2000, grd)
spplot(SpatialGridDataFrame(grd, data=data.frame(kbw2000)), 
col.regions=terrain.colors(16))

test <- SpatialGridDataFrame(grd, data=data.frame(kbw2000))
proj4string(test) <- CRS(prj)
str(test)
test1 <- spTransform(test, CRS("+proj=longlat +datum=WGS84"))

## here I got following error message:
# validityMethod(as(object, superClass)): Geographical CRS given to 
non-conformant data
test2 <- spsample(test1, type="regular", cellsize=c(2000,2000))

# export the SpatialPixelDataFrame (Code (not testet) from the help-file)
tf <- tempfile()
SGxx <- GE_SpatialGrid(test2)
png(file=paste(tf, ".png", sep=""), width=SGxx$width, height=SGxx$height,
  bg="transparent")
par(mar=c(0,0,0,0), xaxs="i", yaxs="i")
plot(x, xlim=SGxx$xlim, ylim=SGxx$ylim, setParUsrBB=TRUE)
dev.off()
kmlOverlay(SGxx, paste(tf, ".kml", sep=""), paste(tf, ".png", sep=""))
###########

I appreciate every hint! Thanks.
Marco

-- 
Marco Helbich
Institute for Urban and Regional Research
Austrian Academy of Sciences
Postgasse 7/4/2, A-1010 Vienna, Austria (EU)
e-mail: marco.helbich(at)oeaw.ac.at



From Roger.Bivand at nhh.no  Sat Jan 26 20:56:17 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 26 Jan 2008 20:56:17 +0100 (CET)
Subject: [R-sig-Geo] kernel density estimation to google earth
In-Reply-To: <006301c86045$9924e100$0300a8c0@mirk>
References: <006301c86045$9924e100$0300a8c0@mirk>
Message-ID: <Pine.LNX.4.64.0801262053001.16427@reclus.nhh.no>

On Sat, 26 Jan 2008, Marco Helbich wrote:

> Dear List,
>
> I've calculated a kernel density estimation (splancs function) and now I
> want to export the result as a kml-file to open it in the google earth
> viewer, but I get stuck at converting the SpatialGridDataFrame to a
> SpatialPixelDataFrame...
>
> here (http://www.zshare.net/download/689742375ef5fb/) you can download some
> testdata and my R-code so far:
>
> ###########
> data.shp <- readOGR("C:/", layer="events")
> prj <- data.shp@ proj4string@ projargs
> dat <- data.shp
> str(dat)
> poly.shp <- readOGR("C:/", layer="hull")
> str(poly.shp)
>
> dat.SP <- as(dat, "SpatialPoints")
> str(dat.SP)
> pp_poi <- as.points(dat.SP at coords[,1], dat.SP at coords[,2])
> poly <-
> getPolygonCoordsSlot(getPolygonsPolygonsSlot(getSpPpolygonsSlot(poly.shp)[[1]])[[1]])
> polymap(poly)
> points(pp_poi)
>
> grd <- GridTopology(cellcentre.offset=c(590511, 396191), cellsize=c(2000,
> 2000),
>  cells.dim=c(30,25))

Here cellsize= is in metres, cells.dim= the numbers of columns and rows.

> kbw2000 <- spkernel2d(pp_poi, poly, h0=2000, grd)
> spplot(SpatialGridDataFrame(grd, data=data.frame(kbw2000)),
> col.regions=terrain.colors(16))
>
> test <- SpatialGridDataFrame(grd, data=data.frame(kbw2000))
> proj4string(test) <- CRS(prj)
> str(test)
> test1 <- spTransform(test, CRS("+proj=longlat +datum=WGS84"))
>
> ## here I got following error message:
> # validityMethod(as(object, superClass)): Geographical CRS given to
> non-conformant data
> test2 <- spsample(test1, type="regular", cellsize=c(2000,2000))

But test1 is now in geographical coordinates, so 2K degrees is a bit 
extreme, and the validation mechanism traps you. I'm not sure what your 
cellsize and cell.dims should be here in longlat.

>
> # export the SpatialPixelDataFrame (Code (not testet) from the help-file)
> tf <- tempfile()
> SGxx <- GE_SpatialGrid(test2)
> png(file=paste(tf, ".png", sep=""), width=SGxx$width, height=SGxx$height,
>  bg="transparent")
> par(mar=c(0,0,0,0), xaxs="i", yaxs="i")
> plot(x, xlim=SGxx$xlim, ylim=SGxx$ylim, setParUsrBB=TRUE)

There is no x defined here.

Roger

> dev.off()
> kmlOverlay(SGxx, paste(tf, ".kml", sep=""), paste(tf, ".png", sep=""))
> ###########
>
> I appreciate every hint! Thanks.
> Marco
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Sat Jan 26 21:11:09 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 26 Jan 2008 21:11:09 +0100 (CET)
Subject: [R-sig-Geo] merging data with SpatialPolygonsDataFrame
In-Reply-To: <200801251305.34150.dylan.beaudette@gmail.com>
References: <a211af3b0801231422p190dda72r997d31b2a8eb076e@mail.gmail.com>
	<200801241457.34070.dylan.beaudette@gmail.com>
	<Pine.LNX.4.64.0801251644240.12880@reclus.nhh.no>
	<200801251305.34150.dylan.beaudette@gmail.com>
Message-ID: <Pine.LNX.4.64.0801262057280.16427@reclus.nhh.no>

On Fri, 25 Jan 2008, Dylan Beaudette wrote:

> On Friday 25 January 2008, Roger Bivand wrote:
>> On Thu, 24 Jan 2008, Dylan Beaudette wrote:
>>> On Thursday 24 January 2008, Roger Bivand wrote:
>>>> On Thu, 24 Jan 2008, Dylan Beaudette wrote:
>>>>> Hi Roger. Thanks for contributing some answers to this.
>>>>>
>>>>> I was recently working with a colleague on developing some sample
>>>>> exercises for new students. Since joining new attribute data to a GIS
>>>>> layer's table is a very common operation we included some samples on
>>>>> how to do this within R. You have hinted at some possible ways to do it
>>>>> above, but do you have a 'best practices' approach to doing this using
>>>>> 'sp' methods and objects?
>>>>>
>>>>> For example:
>>>>>
>>>>> # contains an attribute col named 'veg_code'
>>>>> veg <- readOGR(something.shp)
>>>>>
>>>>> # code meanings: indexed by 'veg_code'
>>>>> codes <- read.dbf(table.dbf)
>>>>>
>>>>> # what is the best way to join up the attributes in 'veg' with the rows
>>>>> in 'codes' ?
>>>>
>>>> Hi Dylan,
>>>>
>>>> This is a different question, but I won't break it out of this thread
>>>> yet.
>>>>
>>>> You are doing look-up on codes to give labels to veg$veg_code, right?
>>>>
>>>> veg$veg_code are integer indices to codes$V1 (say V1, I don't know what
>>>> it is). If length(unique(veg$veg_code)) == length(codes$V1), and
>>>> sort(unique(veg$veg_code)) is 1:length(codes$V1), you should think of
>>>> the factor as your friend:
>>>>
>>>> veg$veg_code_factor <- factor(veg$veg_code,
>>>> labels=as.character(codes$V1))
>>>>
>>>> If not, you need another layer using perhaps order() or match() on the
>>>> matching substring of codes$V1 to find out which value of veg$veg_code
>>>> should have which label in as.character(codes$V1). Alternatively use the
>>>> levels= argument to factor().
>>>>
>>>> Something like:
>>>>
>>>> set.seed(1)
>>>> veg_code <- rpois(100, 4)
>>>> table(veg_code)
>>>> V1 <- paste("code", 0:10)
>>>> V1
>>>> levs <- 0:10
>>>> veg_code_factor <- factor(veg_code, levels=levs, labels=V1)
>>>> table(veg_code_factor, veg_code)
>>>>
>>>> No merging or messing with veg itself is needed, apart from adding a
>>>> single extra factor column. The factor abstraction is a great strength
>>>> of the S language.
>>>>
>>>> Have I misunderstood you?
>>>>
>>>> Roger
>>>
>>> I think so.
>>>
>>> I was (trying to) describe the process of joining, either 1:1 or many:1,
>>> the att table associated with an sp object and some other data frame.
>>>
>>> merge() seems to work fine, but the order of the rows are different from
>>> the original data frame attached to the sp object.
>
> Thanks for the detailed response Roger.
>
>> My experience is that merge() is often a false friend, because of object
>> coercion and sorting, as you suggest. The rules for SpatialLinesDataFrame
>> and SpatialPolygonsDataFrame are simple, and SpatialPointsDataFrame (and
>> by extension SpatialPixelsDataFrame) can be made as simple. The first two
>> constructor functions take a match.ID= argument, default TRUE, which
>> matches the geometry ID - the ID slot in the component Lines or Polygons
>> objects - to the data.frame row.name. For SpatialPointsDataFrame(), the
>> same argument exists, but is only used if the coordinate matrix has row
>> names to be matched to the data.frame row names. If it has been used, the
>> data slot row names are the geometry IDs.
>>
>> From there, it gets harder. merge() takes lots of arguments, and a lot of
>> trial and error is needed to reach a satisfactory result, that is a single
>> data frame with row names matching the geometry IDs (not necessarily in
>> the right order, but the same set of IDs).
>>
>>> My question was on the best way to 'update' the data frame attached to an
>>> sp object, based on the results from a merge() with some other data.
>>
>> For one to one, there isn't really an alternative to extracting the data
>> slot, do the merge, check the geometry IDs against the output data frame
>> row names, and re-construct the object. That is, essentially where this
>> thread began.
>>
>> If there is less data than geometries, merge() should fill out with NAs.
>> If there is more data than geometries, the output data frame will need
>> subsetting. Both match(), order(), and %in% are very handy here.
>>
>> For one geometry list to many - see reshape() first, for example to
>> flatten a "tall" set of space/time observations so that the time values
>> become new attribute columns. This could be met stations stacked by
>> station and date, which need widening to stations by date*attributes
>>
>> If need be, the IDs of the geometries can be changed too, see
>> ?"spChFIDs-methods" in maptools.
>>
>> Any closer?
>
> I think that you have answered my questions and reaffirmed my thoughts 
> on how to proceed. I am mostly interested in 1:1 and 1:many joins 
> (geom:attr), and I think that the following approach should work in the 
> general case:
>
> # read vector data:
> v <- readOGR(dsn='...', layer='...')
>
> # safer approach to 1:1 or 1:many (geom:atts) joins
> # add a sorting id for later use
> v at data$sorting_id <- 1:nrow(v at data)

v$sorting_id <- 1:nrow(as(v, "data.frame"))

is cleaner, there is absolutely no need to access the slot directly with 
the @ operator. Almost all R functions do lazy evaluation, so do not 
create new objects unless needed.

If you are using SpatialLines* or SpatialPolygons*, this is better, 
because it uses the geometry IDs (for v SpatialPolygons*):

v$sorting_id <- sapply(slot(v, "polygons"), function(x) slot(x, "ID"))

>
> # make a copy of the original table
> orig.table <- v at data

orig.table <- as(v, "data.frame")

>
> # make the table with 'joined' data
> new.table <- merge(x=orig.table, y=veg_codes, by.x='CODE', by.y='code')
>

maybe sort=FALSE, you can also try by.x=0, which are the geometry IDs


> # re-order this table based on the original row order
> new.table.ordered <- new.table[order(new.table$sorting_id), ]
>
> # restore the origina row names
> row.names(new.table.ordered) <- row.names(orig.table)

First check the identity of the two, recalling that character strings may 
be cast to factors when constructing data frames.

>
> # replace the data table
> v at data <- new.table.ordered

Rather not, make a v1 and leave the input v in peace. Reading history 
files a couple of days later where objects get overwritten is ten times 
harder than creating new objects and if need be deleting old ones. I find 
that copying and pasting out-of-order history files can lead to lots of 
confusion if object names are overwritten.

>
>
> This should ensure that the merged rows are in the original order, and have
> the original row.names.

Use of all.equal() and identical() on the IDs, row names, etc., is still 
very comforting. Think locales, and you can see what might creep in when 
swapping data with others - just checking takes little time compared to 
recovering from an overconfident assumption that the data and the 
geometries are correctly attached.

It can be done through databases too, the aRT R/Terralib interface offers 
stronger control, and similar effects can be had with OGR/PostGIS.

Best wishes,

Roger

>
> Does that sound correct?
>
> Thanks,
>
> Dylan
>
>
>
>> Roger
>>
>>> does that help?
>>>
>>> cheers,
>>>
>>> Dylan
>>>
>>>>> As of now we are using merge to replace the dataframe slot of the
>>>>> original file. We first re-order the results from merge to match the
>>>>> original row ordering:
>>>>>
>>>>>
>>>>> # an example file:
>>>>> veg <- readOGR(dsn='ArcGISLabData/BrownsPond/', layer='vegevector')
>>>>>
>>>>> # some example codes
>>>>> veg_codes <- data.frame(code=1:4, meaning=c('code 1','code 2','code
>>>>> 3','code 4'))
>>>>>
>>>>> # join the original data table with the veg codes table
>>>>> combined <- merge(x=veg at data, y=veg_codes, by.x='CODE', by.y='code')
>>>>>
>>>>>
>>>>> # overwrite the original data frame with the combined version
>>>>> # note that the original order needs to be restored
>>>>> # since the original data was sorted on 'ID', we can use that to
>>>>> restore # the correct order in the 'combined' dataframe:
>>>>> v at data <- combined[order(combined$ID),]
>>>>>
>>>>>
>>>>> In summary, is there a safer or preferred way to do this?
>>>>>
>>>>> thanks,
>>>>>
>>>>> Dylan
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From hengl at science.uva.nl  Sun Jan 27 13:27:31 2008
From: hengl at science.uva.nl (Tomislav Hengl)
Date: Sun, 27 Jan 2008 13:27:31 +0100 (CET)
Subject: [R-sig-Geo] kernel density estimation to google earth
In-Reply-To: <006301c86045$9924e100$0300a8c0@mirk>
References: <006301c86045$9924e100$0300a8c0@mirk>
Message-ID: <49741.77.164.33.209.1201436851.squirrel@webmail.science.uva.nl>


# Modified by T. Hengl (http://spatial-analyst.net)
# 27.01.2008

library(rgdal)
library(maptools)
library(splancs)

# Import the points and study area:

data.shp <- readOGR("C:/", layer="events")
str(data.shp)

poly.shp <- readOGR("C:/", layer="hull")
str(poly.shp)

poly <-
getPolygonCoordsSlot(getPolygonsPolygonsSlot(getSpPpolygonsSlot(poly.shp)[[1]])[[1]])
grd <-
GridTopology(cellcentre.offset=c(round(poly.shp at bbox["r1","min"],0),
round(poly.shp at bbox["r2","min"],0)), cellsize=c(2000,2000),
cells.dim=c(30,25))

# Run the 2D kernel smoother:

kbw2000 <- spkernel2d(data.shp, poly, h0=2000, grd)
hist(kbw2000)

# Pack and plot a SpatialGridDataFrame:

kbw2000.grd <- SpatialGridDataFrame(grd, data=data.frame(kbw2000))
proj4string(kbw2000.grd) <- data.shp at proj4string
spplot(kbw2000.grd, col.regions=terrain.colors(16),
sp.layout=list("sp.points",pch="+",cex=1.2,col="black",data.shp))

# Export to KML
# First, reproject the grid to longlat:

kbw2000.ll <- spTransform(kbw2000.grd, CRS("+proj=longlat +datum=WGS84"))
str(kbw2000.ll)

# The cell size you need to determine yourself!!

width =
(kbw2000.grd at bbox["coords.x1","max"]-kbw2000.grd at bbox["coords.x1","min"])/2000
height =
(kbw2000.grd at bbox["coords.x2","max"]-kbw2000.grd at bbox["coords.x2","min"])/2000
geogrd.cell = (kbw2000.ll at bbox["s1","max"]-kbw2000.ll at bbox["s1","min"])/width

# Define a new grid:

geogrd = spsample(kbw2000.ll, type="regular",
cellsize=c(geogrd.cell,geogrd.cell))
gridded(geogrd) = TRUE

gridparameters(geogrd)
# cellcentre.offset   cellsize cells.dim
# x1          15.90165 0.02636685        30
# x2          47.95541 0.02636685        16

# This is an empty grid without any topology (only grid nodes are defined)
and coordinate
# system definition. To create topology, we coerce a dummy variable (1s),
then
# specify that the layer has a full topology:

nogrids = geogrd at grid@cells.dim["x1"]*geogrd at grid@cells.dim["x2"]
geogrd = SpatialGridDataFrame(geogrd at grid, data=data.frame(rep(1,
nogrids)), proj4string=kbw2000.ll at proj4string)

# and estimate the values of the reprojected map at new grid locations
using the bilinear resampling:
# this can be time-consuming for large grids!!!

library(gstat)
kbw2000.llgrd = krige(kbw2000~1, kbw2000.ll, geogrd, nmax=4)

# Optional, convert the original shape to latlong coordinates:

data.ll <- spTransform(data.shp, CRS("+proj=longlat +datum=WGS84"))
spplot(kbw2000.llgrd["var1.pred"], col.regions=terrain.colors(16),
scales=list(draw=TRUE),
sp.layout=list("sp.points",pch="+",cex=1.2,col="black",data.ll))

# The final grid map can be exported to KML format using the maptools
package and kmlOverlay method:

kbw2000.kml = GE_SpatialGrid(kbw2000.llgrd)

tf <- tempfile()
png(file=paste(tf, ".png", sep=""), width=kbw2000.kml$width,
height=kbw2000.kml$height, bg="transparent")

par(mar=c(0,0,0,0), xaxs="i", yaxs="i")
image(as.image.SpatialGridDataFrame(kbw2000.llgrd[1]), col=bpy.colors(),
xlim=kbw2000.kml$xlim, ylim=kbw2000.kml$ylim)
plot(data.ll, pch="+", cex=1.2, add=TRUE, bg="transparent")

kmlOverlay(kbw2000.kml, paste(tf, ".kml", sep=""), paste(tf, ".png", sep=""))
dev.off()

# see also:
# Hengl, T., 2007. A Practical Guide to Geostatistical Mapping of 
Environmental Variables. EUR 22904 EN Scientific and Technical Research
series, Office for Official Publications of the European Communities,
Luxemburg, 143 pp.


> Dear List,
>
> I've calculated a kernel density estimation (splancs function) and now I
> want to export the result as a kml-file to open it in the google earth
> viewer, but I get stuck at converting the SpatialGridDataFrame to a
> SpatialPixelDataFrame...
>
> here (http://www.zshare.net/download/689742375ef5fb/) you can download
> some
> testdata and my R-code so far:
>
> ###########
> data.shp <- readOGR("C:/", layer="events")
> prj <- data.shp@ proj4string@ projargs
> dat <- data.shp
> str(dat)
> poly.shp <- readOGR("C:/", layer="hull")
> str(poly.shp)
>
> dat.SP <- as(dat, "SpatialPoints")
> str(dat.SP)
> pp_poi <- as.points(dat.SP at coords[,1], dat.SP at coords[,2])
> poly <-
> getPolygonCoordsSlot(getPolygonsPolygonsSlot(getSpPpolygonsSlot(poly.shp)[[1]])[[1]])
> polymap(poly)
> points(pp_poi)
>
> grd <- GridTopology(cellcentre.offset=c(590511, 396191), cellsize=c(2000,
> 2000),
>   cells.dim=c(30,25))
> kbw2000 <- spkernel2d(pp_poi, poly, h0=2000, grd)
> spplot(SpatialGridDataFrame(grd, data=data.frame(kbw2000)),
> col.regions=terrain.colors(16))
>
> test <- SpatialGridDataFrame(grd, data=data.frame(kbw2000))
> proj4string(test) <- CRS(prj)
> str(test)
> test1 <- spTransform(test, CRS("+proj=longlat +datum=WGS84"))
>
> ## here I got following error message:
> # validityMethod(as(object, superClass)): Geographical CRS given to
> non-conformant data
> test2 <- spsample(test1, type="regular", cellsize=c(2000,2000))
>
> # export the SpatialPixelDataFrame (Code (not testet) from the help-file)
> tf <- tempfile()
> SGxx <- GE_SpatialGrid(test2)
> png(file=paste(tf, ".png", sep=""), width=SGxx$width, height=SGxx$height,
>   bg="transparent")
> par(mar=c(0,0,0,0), xaxs="i", yaxs="i")
> plot(x, xlim=SGxx$xlim, ylim=SGxx$ylim, setParUsrBB=TRUE)
> dev.off()
> kmlOverlay(SGxx, paste(tf, ".kml", sep=""), paste(tf, ".png", sep=""))
> ###########
>
> I appreciate every hint! Thanks.
> Marco
>
> --
> Marco Helbich
> Institute for Urban and Regional Research
> Austrian Academy of Sciences
> Postgasse 7/4/2, A-1010 Vienna, Austria (EU)
> e-mail: marco.helbich(at)oeaw.ac.at
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: file7b0208e.kml
Type: application/vnd.google-earth.kml+xml
Size: 423 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080127/852e8171/attachment.bin>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: file7b0208e.png
Type: image/png
Size: 2964 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080127/852e8171/attachment.png>

From Roger.Bivand at nhh.no  Sun Jan 27 15:06:32 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 27 Jan 2008 15:06:32 +0100 (CET)
Subject: [R-sig-Geo] kernel density estimation to google earth
In-Reply-To: <49741.77.164.33.209.1201436851.squirrel@webmail.science.uva.nl>
References: <006301c86045$9924e100$0300a8c0@mirk>
	<49741.77.164.33.209.1201436851.squirrel@webmail.science.uva.nl>
Message-ID: <Pine.LNX.4.64.0801271504180.7925@reclus.nhh.no>

On Sun, 27 Jan 2008, Tomislav Hengl wrote:

>
> # Modified by T. Hengl (http://spatial-analyst.net)
> # 27.01.2008

Thanks, very clear - the kernel values at the grid of projected points are 
not an a grid in geographical coordinates, and need to be interpolated 
(warped) to a grid in geographical coordinates. The alternative is to make 
the kernel function use Great Circle distances.

Roger

>
> library(rgdal)
> library(maptools)
> library(splancs)
>
> # Import the points and study area:
>
> data.shp <- readOGR("C:/", layer="events")
> str(data.shp)
>
> poly.shp <- readOGR("C:/", layer="hull")
> str(poly.shp)
>
> poly <-
> getPolygonCoordsSlot(getPolygonsPolygonsSlot(getSpPpolygonsSlot(poly.shp)[[1]])[[1]])
> grd <-
> GridTopology(cellcentre.offset=c(round(poly.shp at bbox["r1","min"],0),
> round(poly.shp at bbox["r2","min"],0)), cellsize=c(2000,2000),
> cells.dim=c(30,25))
>
> # Run the 2D kernel smoother:
>
> kbw2000 <- spkernel2d(data.shp, poly, h0=2000, grd)
> hist(kbw2000)
>
> # Pack and plot a SpatialGridDataFrame:
>
> kbw2000.grd <- SpatialGridDataFrame(grd, data=data.frame(kbw2000))
> proj4string(kbw2000.grd) <- data.shp at proj4string
> spplot(kbw2000.grd, col.regions=terrain.colors(16),
> sp.layout=list("sp.points",pch="+",cex=1.2,col="black",data.shp))
>
> # Export to KML
> # First, reproject the grid to longlat:
>
> kbw2000.ll <- spTransform(kbw2000.grd, CRS("+proj=longlat +datum=WGS84"))
> str(kbw2000.ll)
>
> # The cell size you need to determine yourself!!
>
> width =
> (kbw2000.grd at bbox["coords.x1","max"]-kbw2000.grd at bbox["coords.x1","min"])/2000
> height =
> (kbw2000.grd at bbox["coords.x2","max"]-kbw2000.grd at bbox["coords.x2","min"])/2000
> geogrd.cell = (kbw2000.ll at bbox["s1","max"]-kbw2000.ll at bbox["s1","min"])/width
>
> # Define a new grid:
>
> geogrd = spsample(kbw2000.ll, type="regular",
> cellsize=c(geogrd.cell,geogrd.cell))
> gridded(geogrd) = TRUE
>
> gridparameters(geogrd)
> # cellcentre.offset   cellsize cells.dim
> # x1          15.90165 0.02636685        30
> # x2          47.95541 0.02636685        16
>
> # This is an empty grid without any topology (only grid nodes are defined)
> and coordinate
> # system definition. To create topology, we coerce a dummy variable (1s),
> then
> # specify that the layer has a full topology:
>
> nogrids = geogrd at grid@cells.dim["x1"]*geogrd at grid@cells.dim["x2"]
> geogrd = SpatialGridDataFrame(geogrd at grid, data=data.frame(rep(1,
> nogrids)), proj4string=kbw2000.ll at proj4string)
>
> # and estimate the values of the reprojected map at new grid locations
> using the bilinear resampling:
> # this can be time-consuming for large grids!!!
>
> library(gstat)
> kbw2000.llgrd = krige(kbw2000~1, kbw2000.ll, geogrd, nmax=4)
>
> # Optional, convert the original shape to latlong coordinates:
>
> data.ll <- spTransform(data.shp, CRS("+proj=longlat +datum=WGS84"))
> spplot(kbw2000.llgrd["var1.pred"], col.regions=terrain.colors(16),
> scales=list(draw=TRUE),
> sp.layout=list("sp.points",pch="+",cex=1.2,col="black",data.ll))
>
> # The final grid map can be exported to KML format using the maptools
> package and kmlOverlay method:
>
> kbw2000.kml = GE_SpatialGrid(kbw2000.llgrd)
>
> tf <- tempfile()
> png(file=paste(tf, ".png", sep=""), width=kbw2000.kml$width,
> height=kbw2000.kml$height, bg="transparent")
>
> par(mar=c(0,0,0,0), xaxs="i", yaxs="i")
> image(as.image.SpatialGridDataFrame(kbw2000.llgrd[1]), col=bpy.colors(),
> xlim=kbw2000.kml$xlim, ylim=kbw2000.kml$ylim)
> plot(data.ll, pch="+", cex=1.2, add=TRUE, bg="transparent")
>
> kmlOverlay(kbw2000.kml, paste(tf, ".kml", sep=""), paste(tf, ".png", sep=""))
> dev.off()
>
> # see also:
> # Hengl, T., 2007. A Practical Guide to Geostatistical Mapping of
> Environmental Variables. EUR 22904 EN Scientific and Technical Research
> series, Office for Official Publications of the European Communities,
> Luxemburg, 143 pp.
>
>
>> Dear List,
>>
>> I've calculated a kernel density estimation (splancs function) and now I
>> want to export the result as a kml-file to open it in the google earth
>> viewer, but I get stuck at converting the SpatialGridDataFrame to a
>> SpatialPixelDataFrame...
>>
>> here (http://www.zshare.net/download/689742375ef5fb/) you can download
>> some
>> testdata and my R-code so far:
>>
>> ###########
>> data.shp <- readOGR("C:/", layer="events")
>> prj <- data.shp@ proj4string@ projargs
>> dat <- data.shp
>> str(dat)
>> poly.shp <- readOGR("C:/", layer="hull")
>> str(poly.shp)
>>
>> dat.SP <- as(dat, "SpatialPoints")
>> str(dat.SP)
>> pp_poi <- as.points(dat.SP at coords[,1], dat.SP at coords[,2])
>> poly <-
>> getPolygonCoordsSlot(getPolygonsPolygonsSlot(getSpPpolygonsSlot(poly.shp)[[1]])[[1]])
>> polymap(poly)
>> points(pp_poi)
>>
>> grd <- GridTopology(cellcentre.offset=c(590511, 396191), cellsize=c(2000,
>> 2000),
>>   cells.dim=c(30,25))
>> kbw2000 <- spkernel2d(pp_poi, poly, h0=2000, grd)
>> spplot(SpatialGridDataFrame(grd, data=data.frame(kbw2000)),
>> col.regions=terrain.colors(16))
>>
>> test <- SpatialGridDataFrame(grd, data=data.frame(kbw2000))
>> proj4string(test) <- CRS(prj)
>> str(test)
>> test1 <- spTransform(test, CRS("+proj=longlat +datum=WGS84"))
>>
>> ## here I got following error message:
>> # validityMethod(as(object, superClass)): Geographical CRS given to
>> non-conformant data
>> test2 <- spsample(test1, type="regular", cellsize=c(2000,2000))
>>
>> # export the SpatialPixelDataFrame (Code (not testet) from the help-file)
>> tf <- tempfile()
>> SGxx <- GE_SpatialGrid(test2)
>> png(file=paste(tf, ".png", sep=""), width=SGxx$width, height=SGxx$height,
>>   bg="transparent")
>> par(mar=c(0,0,0,0), xaxs="i", yaxs="i")
>> plot(x, xlim=SGxx$xlim, ylim=SGxx$ylim, setParUsrBB=TRUE)
>> dev.off()
>> kmlOverlay(SGxx, paste(tf, ".kml", sep=""), paste(tf, ".png", sep=""))
>> ###########
>>
>> I appreciate every hint! Thanks.
>> Marco
>>
>> --
>> Marco Helbich
>> Institute for Urban and Regional Research
>> Austrian Academy of Sciences
>> Postgasse 7/4/2, A-1010 Vienna, Austria (EU)
>> e-mail: marco.helbich(at)oeaw.ac.at
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From edzer.pebesma at uni-muenster.de  Sun Jan 27 20:17:17 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 27 Jan 2008 20:17:17 +0100
Subject: [R-sig-Geo] Regression kriging
In-Reply-To: <8e01f5830801240725m705d7bafq34993457bfc72ed5@mail.gmail.com>
References: <8e01f5830801240725m705d7bafq34993457bfc72ed5@mail.gmail.com>
Message-ID: <479CD8BD.7050105@uni-muenster.de>

Jose, is your model linear, or are you using a generalized linear model?

The questions is not so much: model parameters before or after kriging
residuals, but rather: model parameters under the assumption of
independent observations (the usual regression approach), or model
parameters under the assumption of spatially dependent observations (the
geostatistical, or generalized linear regression approach). In the case
you are using a GLM, the report mentioned earlier on regression kriging
(another name for universal kriging) may not be very helpful, as it
deals with linear models.
--
Edzer

Jose Funes wrote:
> Hi,
>
> I have used regression kriging to model abundance of an invasive
> species. After performing a stepwise regression of the model, I fitted
> a theoretical variogram to a empirical variogram of the residuals. My
> question is how to obtain the parameter estimate of the model after
> kriging the residuals. Do the parameters of the regression model
> differ after kriging the residuals? if so, how can I get them from the
> R output?
>
> Looking forward to hearing from you, thanks
>
> Jose Funes
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From giohappy at gmail.com  Mon Jan 28 00:30:53 2008
From: giohappy at gmail.com (G. Allegri)
Date: Mon, 28 Jan 2008 00:30:53 +0100
Subject: [R-sig-Geo] kernel density estimation to google earth
In-Reply-To: <Pine.LNX.4.64.0801271504180.7925@reclus.nhh.no>
References: <006301c86045$9924e100$0300a8c0@mirk>
	<49741.77.164.33.209.1201436851.squirrel@webmail.science.uva.nl>
	<Pine.LNX.4.64.0801271504180.7925@reclus.nhh.no>
Message-ID: <e12429640801271530g5e4c5ef6h690208d086054aad@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080128/28f5b0d0/attachment.pl>

From Roger.Bivand at nhh.no  Mon Jan 28 10:51:27 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 28 Jan 2008 10:51:27 +0100 (CET)
Subject: [R-sig-Geo] kernel density estimation to google earth
In-Reply-To: <e12429640801271530g5e4c5ef6h690208d086054aad@mail.gmail.com>
References: <006301c86045$9924e100$0300a8c0@mirk> 
	<49741.77.164.33.209.1201436851.squirrel@webmail.science.uva.nl> 
	<Pine.LNX.4.64.0801271504180.7925@reclus.nhh.no>
	<e12429640801271530g5e4c5ef6h690208d086054aad@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0801281038300.12703@reclus.nhh.no>

On Mon, 28 Jan 2008, G. Allegri wrote:

> Thanks, a really interesting post.
> May I ask a stupid question? Where are the following function documented?
>
> getPolygonCoordsSlot(getPolygonsPolygonsSlot(getSpPpolygonsSlot(poly.shp
> )[[1]])[[1]])
>
> They are in the sp package but I can't find references but in some posts on
> this ML.

They are deprecated (will be defunct soon); this is why they generate 
warnings. This is because using slot() is much cleaner, easier to 
maintain, and is automatically documented. Say you want the coordinates of 
a "Polygon" object:

getSlots("Polygon")

tells you what they are called, and:

slot(x, "coords")

retrieves them. So an up-to-date version of the above is:

> getPolygonCoordsSlot(getPolygonsPolygonsSlot(getSpPpolygonsSlot(poly.shp
> )[[1]])[[1]])

slot(slot(slot(poly.shp, "polygons")[[1]], "Polygons")[[1]], "coords")

or equivalently:

poly.shp_1 <- slot(poly.shp, "polygons")[[1]]
poly.shp_1_1 <- slot(poly.shp_1, "Polygons")[[1]]
crds_1_1 <- slot(poly.shp_1_1, "coords")

where all you need are slot() and the names of the slots, rather than very 
long and rather arbitrary names for wrapper functions for slot().

In the code below, note that use of "@" should be avoided in user-level 
code, and that bbox() methods retrieve the bounding box of a Spatial* 
object cleanly.

Roger

>
> Thanks,
> Giovanni
>
> 2008/1/27, Roger Bivand <Roger.Bivand at nhh.no>:
>>
>> On Sun, 27 Jan 2008, Tomislav Hengl wrote:
>>
>>>
>>> # Modified by T. Hengl (http://spatial-analyst.net)
>>> # 27.01.2008
>>
>> Thanks, very clear - the kernel values at the grid of projected points are
>> not an a grid in geographical coordinates, and need to be interpolated
>> (warped) to a grid in geographical coordinates. The alternative is to make
>> the kernel function use Great Circle distances.
>>
>> Roger
>>
>>>
>>> library(rgdal)
>>> library(maptools)
>>> library(splancs)
>>>
>>> # Import the points and study area:
>>>
>>> data.shp <- readOGR("C:/", layer="events")
>>> str(data.shp)
>>>
>>> poly.shp <- readOGR("C:/", layer="hull")
>>> str(poly.shp)
>>>
>>> poly <-
>>> getPolygonCoordsSlot(getPolygonsPolygonsSlot(getSpPpolygonsSlot(poly.shp
>> )[[1]])[[1]])
>>> grd <-
>>> GridTopology(cellcentre.offset=c(round(poly.shp at bbox["r1","min"],0),
>>> round(poly.shp at bbox["r2","min"],0)), cellsize=c(2000,2000),
>>> cells.dim=c(30,25))
>>>
>>> # Run the 2D kernel smoother:
>>>
>>> kbw2000 <- spkernel2d(data.shp, poly, h0=2000, grd)
>>> hist(kbw2000)
>>>
>>> # Pack and plot a SpatialGridDataFrame:
>>>
>>> kbw2000.grd <- SpatialGridDataFrame(grd, data=data.frame(kbw2000))
>>> proj4string(kbw2000.grd) <- data.shp at proj4string
>>> spplot(kbw2000.grd, col.regions=terrain.colors(16),
>>> sp.layout=list("sp.points",pch="+",cex=1.2,col="black",data.shp))
>>>
>>> # Export to KML
>>> # First, reproject the grid to longlat:
>>>
>>> kbw2000.ll <- spTransform(kbw2000.grd, CRS("+proj=longlat
>> +datum=WGS84"))
>>> str(kbw2000.ll)
>>>
>>> # The cell size you need to determine yourself!!
>>>
>>> width =
>>> (kbw2000.grd at bbox["coords.x1","max"]-kbw2000.grd at bbox["coords.x1
>> ","min"])/2000
>>> height =
>>> (kbw2000.grd at bbox["coords.x2","max"]-kbw2000.grd at bbox["coords.x2
>> ","min"])/2000
>>> geogrd.cell = (kbw2000.ll at bbox["s1","max"]-kbw2000.ll at bbox
>> ["s1","min"])/width
>>>
>>> # Define a new grid:
>>>
>>> geogrd = spsample(kbw2000.ll, type="regular",
>>> cellsize=c(geogrd.cell,geogrd.cell))
>>> gridded(geogrd) = TRUE
>>>
>>> gridparameters(geogrd)
>>> # cellcentre.offset   cellsize cells.dim
>>> # x1          15.90165 0.02636685        30
>>> # x2          47.95541 0.02636685        16
>>>
>>> # This is an empty grid without any topology (only grid nodes are
>> defined)
>>> and coordinate
>>> # system definition. To create topology, we coerce a dummy variable
>> (1s),
>>> then
>>> # specify that the layer has a full topology:
>>>
>>> nogrids = geogrd at grid@cells.dim["x1"]*geogrd at grid@cells.dim["x2"]
>>> geogrd = SpatialGridDataFrame(geogrd at grid, data=data.frame(rep(1,
>>> nogrids)), proj4string=kbw2000.ll at proj4string)
>>>
>>> # and estimate the values of the reprojected map at new grid locations
>>> using the bilinear resampling:
>>> # this can be time-consuming for large grids!!!
>>>
>>> library(gstat)
>>> kbw2000.llgrd = krige(kbw2000~1, kbw2000.ll, geogrd, nmax=4)
>>>
>>> # Optional, convert the original shape to latlong coordinates:
>>>
>>> data.ll <- spTransform(data.shp, CRS("+proj=longlat +datum=WGS84"))
>>> spplot(kbw2000.llgrd["var1.pred"], col.regions=terrain.colors(16),
>>> scales=list(draw=TRUE),
>>> sp.layout=list("sp.points",pch="+",cex=1.2,col="black",data.ll))
>>>
>>> # The final grid map can be exported to KML format using the maptools
>>> package and kmlOverlay method:
>>>
>>> kbw2000.kml = GE_SpatialGrid(kbw2000.llgrd)
>>>
>>> tf <- tempfile()
>>> png(file=paste(tf, ".png", sep=""), width=kbw2000.kml$width,
>>> height=kbw2000.kml$height, bg="transparent")
>>>
>>> par(mar=c(0,0,0,0), xaxs="i", yaxs="i")
>>> image(as.image.SpatialGridDataFrame(kbw2000.llgrd[1]), col=bpy.colors(),
>>> xlim=kbw2000.kml$xlim, ylim=kbw2000.kml$ylim)
>>> plot(data.ll, pch="+", cex=1.2, add=TRUE, bg="transparent")
>>>
>>> kmlOverlay(kbw2000.kml, paste(tf, ".kml", sep=""), paste(tf, ".png",
>> sep=""))
>>> dev.off()
>>>
>>> # see also:
>>> # Hengl, T., 2007. A Practical Guide to Geostatistical Mapping of
>>> Environmental Variables. EUR 22904 EN Scientific and Technical Research
>>> series, Office for Official Publications of the European Communities,
>>> Luxemburg, 143 pp.
>>>
>>>
>>>> Dear List,
>>>>
>>>> I've calculated a kernel density estimation (splancs function) and now
>> I
>>>> want to export the result as a kml-file to open it in the google earth
>>>> viewer, but I get stuck at converting the SpatialGridDataFrame to a
>>>> SpatialPixelDataFrame...
>>>>
>>>> here (http://www.zshare.net/download/689742375ef5fb/) you can download
>>>> some
>>>> testdata and my R-code so far:
>>>>
>>>> ###########
>>>> data.shp <- readOGR("C:/", layer="events")
>>>> prj <- data.shp@ proj4string@ projargs
>>>> dat <- data.shp
>>>> str(dat)
>>>> poly.shp <- readOGR("C:/", layer="hull")
>>>> str(poly.shp)
>>>>
>>>> dat.SP <- as(dat, "SpatialPoints")
>>>> str(dat.SP)
>>>> pp_poi <- as.points(dat.SP at coords[,1], dat.SP at coords[,2])
>>>> poly <-
>>>> getPolygonCoordsSlot(getPolygonsPolygonsSlot(getSpPpolygonsSlot(
>> poly.shp)[[1]])[[1]])
>>>> polymap(poly)
>>>> points(pp_poi)
>>>>
>>>> grd <- GridTopology(cellcentre.offset=c(590511, 396191),
>> cellsize=c(2000,
>>>> 2000),
>>>>   cells.dim=c(30,25))
>>>> kbw2000 <- spkernel2d(pp_poi, poly, h0=2000, grd)
>>>> spplot(SpatialGridDataFrame(grd, data=data.frame(kbw2000)),
>>>> col.regions=terrain.colors(16))
>>>>
>>>> test <- SpatialGridDataFrame(grd, data=data.frame(kbw2000))
>>>> proj4string(test) <- CRS(prj)
>>>> str(test)
>>>> test1 <- spTransform(test, CRS("+proj=longlat +datum=WGS84"))
>>>>
>>>> ## here I got following error message:
>>>> # validityMethod(as(object, superClass)): Geographical CRS given to
>>>> non-conformant data
>>>> test2 <- spsample(test1, type="regular", cellsize=c(2000,2000))
>>>>
>>>> # export the SpatialPixelDataFrame (Code (not testet) from the
>> help-file)
>>>> tf <- tempfile()
>>>> SGxx <- GE_SpatialGrid(test2)
>>>> png(file=paste(tf, ".png", sep=""), width=SGxx$width,
>> height=SGxx$height,
>>>>   bg="transparent")
>>>> par(mar=c(0,0,0,0), xaxs="i", yaxs="i")
>>>> plot(x, xlim=SGxx$xlim, ylim=SGxx$ylim, setParUsrBB=TRUE)
>>>> dev.off()
>>>> kmlOverlay(SGxx, paste(tf, ".kml", sep=""), paste(tf, ".png", sep=""))
>>>> ###########
>>>>
>>>> I appreciate every hint! Thanks.
>>>> Marco
>>>>
>>>> --
>>>> Marco Helbich
>>>> Institute for Urban and Regional Research
>>>> Austrian Academy of Sciences
>>>> Postgasse 7/4/2, A-1010 Vienna, Austria (EU)
>>>> e-mail: marco.helbich(at)oeaw.ac.at
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From didier.leibovici at nottingham.ac.uk  Mon Jan 28 18:24:20 2008
From: didier.leibovici at nottingham.ac.uk (Didier Leibovici)
Date: Mon, 28 Jan 2008 17:24:20 +0000
Subject: [R-sig-Geo] sp basics !
Message-ID: <479E0FC4.5020201@nottingham.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080128/e024e8f0/attachment.pl>

From h.wickham at gmail.com  Mon Jan 28 18:50:20 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 28 Jan 2008 11:50:20 -0600
Subject: [R-sig-Geo] Calculating map orientations
Message-ID: <f8e6ff050801280950x592c9b06y5d665d0b37056b2e@mail.gmail.com>

Hi all,

I was wondering if anyone knows how the default orientations are
calculated in the mapproj package.  I need this for
my ggplot2 package because when you are drawing maps with multiple
layers of data you (obviously) have to calculate the orientation over
all data, not just the data points in a single layer.  You can see
some of the problems I'm having at
http://had.co.nz/ggplot2/coord_map.html

I tried emailing the maintainer of the mapproj package but didn't get a reply.

Hadley

-- 
http://had.co.nz/



From edzer.pebesma at uni-muenster.de  Mon Jan 28 19:15:22 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 28 Jan 2008 19:15:22 +0100
Subject: [R-sig-Geo] sp basics !
In-Reply-To: <479E0FC4.5020201@nottingham.ac.uk>
References: <479E0FC4.5020201@nottingham.ac.uk>
Message-ID: <479E1BBA.3010005@uni-muenster.de>

Hi Didier,

no, right now there's no such distance function in R, afaik. I must 
admit that it would be nice.
--
Edzer

Didier Leibovici wrote:
> Hi all,
> I am still novice in using sp and/or Maptools and  I find difficult to 
> locate basic tutorials and general description ...
> I am probably some good source of info?
>
> My problem is very simple and I brlieve it covers some basic handling of 
> "GIS" data desirable in geoR:
>
> I would like to read some shapefiles of polygons( I know how to do that)
> and loop through all the polygons to be able to compute the shortest 
> distance to one another (fix) polygon
> e.g. distance to the sea or to a montain
> -I had at one point a polylist but probably I need to have "consistant" 
> polygon for each element of the list ?
> -is there any distance method supported by a class "polygon" which can 
> compute the distance to another geometry?
>
> thanks
>
>



From dylan.beaudette at gmail.com  Mon Jan 28 19:21:55 2008
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Mon, 28 Jan 2008 10:21:55 -0800
Subject: [R-sig-Geo] sp basics !
In-Reply-To: <479E1BBA.3010005@uni-muenster.de>
References: <479E0FC4.5020201@nottingham.ac.uk>
	<479E1BBA.3010005@uni-muenster.de>
Message-ID: <200801281021.55574.dylan.beaudette@gmail.com>

On Monday 28 January 2008, Edzer Pebesma wrote:
> Hi Didier,
>
> no, right now there's no such distance function in R, afaik. I must
> admit that it would be nice.
> --
> Edzer
>
> Didier Leibovici wrote:
> > Hi all,
> > I am still novice in using sp and/or Maptools and  I find difficult to
> > locate basic tutorials and general description ...
> > I am probably some good source of info?
> >
> > My problem is very simple and I brlieve it covers some basic handling of
> > "GIS" data desirable in geoR:
> >
> > I would like to read some shapefiles of polygons( I know how to do that)
> > and loop through all the polygons to be able to compute the shortest
> > distance to one another (fix) polygon
> > e.g. distance to the sea or to a montain
> > -I had at one point a polylist but probably I need to have "consistant"
> > polygon for each element of the list ?
> > -is there any distance method supported by a class "polygon" which can
> > compute the distance to another geometry?
> >
> > thanks
>

Not sure if it is exactly the same, but you might check the spatstat package:

http://www.spatstat.org/spatstat/current/Quickref.pdf

cheers,

Dylan


-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341



From Roger.Bivand at nhh.no  Mon Jan 28 19:52:30 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 28 Jan 2008 19:52:30 +0100 (CET)
Subject: [R-sig-Geo] sp basics !
In-Reply-To: <479E0FC4.5020201@nottingham.ac.uk>
References: <479E0FC4.5020201@nottingham.ac.uk>
Message-ID: <Pine.LNX.4.64.0801281831130.12703@reclus.nhh.no>

Hi Didier,

On Mon, 28 Jan 2008, Didier Leibovici wrote:

> Hi all,
> I am still novice in using sp and/or Maptools and  I find difficult to
> locate basic tutorials and general description ...
> I am probably some good source of info?
>

The most recent public ones are from the Imperial College course:

http://www.bias-project.org.uk/ASDARcourse/

> My problem is very simple and I brlieve it covers some basic handling of
> "GIS" data desirable in geoR:

(where this isn't geoR the package? - to avoid confusion, maybe 
R-spatial?)

>
> I would like to read some shapefiles of polygons( I know how to do that)
> and loop through all the polygons to be able to compute the shortest
> distance to one another (fix) polygon
> e.g. distance to the sea or to a montain

Is this distance as in Euclidean, or is it Great Circle? How precise do 
you need to be? Will you accept the boundary points of one as points to 
the boundary of the other as a line? Have a look at the spatstat internal 
function distppll(), which is used there for point pattern analysis within 
a window, but works well for this version of points to line and Euclidean 
distance. Watch the l= argument, it is in segments and has x0, y0, x1, y1 
columns for each segment. This is messy, but:

library(spdep)
example(eire)
# to load a small data set, Irish counties

eire$all <- rep(1, 26)
eire_per <- unionSpatialPolygons(eire, eire$all)
# to make a perimeter to measure to

sapply(slot(eire_per, "polygons"), function(x) length(slot(x,
   "Polygons")))
sapply(slot(eire_per, "polygons"), function(x) sapply(slot(x, "Polygons"),
   slot, "area"))
# to see which bit of Co. Mayo is the island - since it is the second,
# choose [[1]]

ll <- slot(slot(slot(eire_per, "polygons")[[1]], "Polygons")[[1]],
   "coords")
# get the perimeter coordinates

pls <- slot(eire, "polygons")
lgths <- sapply(pls, function(x) length(slot(x, "Polygons")))
sapply(slot(pls[[which(lgths == 2)]], "Polygons"), slot, "area")
# to see which bit of Co. Mayo is the island, same diagnosis, we
# can use [[1]] in the work loop

lll <- cbind(ll[-nrow(ll),,drop=FALSE], ll[-1,,drop=FALSE])
# to set up the segments from the perimeter coordinates

res <- vector(mode="list", length=length(pls))
for (i in seq(along=res)) {
   crds <- slot(slot(pls[[i]], "Polygons")[[1]], "coords")
   res[[i]] <- apply(distppll(p=crds, l=lll), 1, min)
}
# actually do the work
res

gets you the shortest distances to each point on the boundary of each 
county. Note that Donegal has 0 distance for all points, because there are 
no boundary points along its land border, though there could have been.

> -I had at one point a polylist but probably I need to have "consistant"
> polygon for each element of the list ?

Using distppll() here is low level, so it just loops over points for each 
segment (or vice-versa), not picky about topology. But the S4 
SpatialPolygons are easier to chuck around, because we know definitely 
what is inside them. "polylist" objects were S3.

> -is there any distance method supported by a class "polygon" which can
> compute the distance to another geometry?

No, though if someone felt like trying out an OGR virtual driver and GEOM, 
there are robust methods for classes out there. Or you could push the sata 
out to PostGIS, modern MySQL, or any supported database and Terralib using 
the aRT interface. At least one of these may support geographical 
coordinates, i.e. Great Circle distances.

If you make any progress with alternatives, please let us know.

Hope this helps,

Roger

>
> thanks
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From andrew.niccolai at yale.edu  Tue Jan 29 14:21:25 2008
From: andrew.niccolai at yale.edu (Andrew Niccolai)
Date: Tue, 29 Jan 2008 08:21:25 -0500
Subject: [R-sig-Geo] Tesselation proportional to size
In-Reply-To: <Pine.LNX.4.64.0801281038300.12703@reclus.nhh.no>
References: <006301c86045$9924e100$0300a8c0@mirk>
	<49741.77.164.33.209.1201436851.squirrel@webmail.science.uva.nl>
	<Pine.LNX.4.64.0801271504180.7925@reclus.nhh.no>	<e12429640801271530g5e4c5ef6h690208d086054aad@mail.gmail.com>
	<Pine.LNX.4.64.0801281038300.12703@reclus.nhh.no>
Message-ID: <001001c86279$dc2e3600$948aa200$@niccolai@yale.edu>

Hi Spatial-R users,

Does anyone know of a function or some code that will tessellate a set of
delauney triangles proportional to the size of the marks in a point pattern?
The only thing that I can find is a tessellation based on bisecting the
length of the line connecting two points.  

Andrew Niccolai
Doctoral Candidate
Yale School of Forestry



From giohappy at gmail.com  Tue Jan 29 20:17:42 2008
From: giohappy at gmail.com (G. Allegri)
Date: Tue, 29 Jan 2008 20:17:42 +0100
Subject: [R-sig-Geo] Regression kriging
In-Reply-To: <479CD8BD.7050105@uni-muenster.de>
References: <8e01f5830801240725m705d7bafq34993457bfc72ed5@mail.gmail.com>
	<479CD8BD.7050105@uni-muenster.de>
Message-ID: <e12429640801291117j4f31de22iae9d03bbeb6d4218@mail.gmail.com>

Dear Edzer,
I've "medidated" on the answer you gave to Jose. Two considerations have raise:

 1 - when you say that the approach of GLM is a way to consider
spatial dependence. I'm not sure about this. GLM are a way to account
for link functions between the dependent variables and covariates (ex.
Poisson family for count datas), but they don't take account,
implicitly, of sptial correlation. Am I wrong?
Rather (generalized) mixed models are a counterpart to geostatical methods are.

2 - A task of my research is to find the "best" relations between a
set of covariates, to make a simple multicriteria analysis,
overlapping different map layers thorugh map algebra. In this case,
the common geostatistical methods don't help me much. I'm considering
to use multivariate regression, but keeping in count of spatial
correlation. What's the best approach? I've thought to Mixed Models,
but another way could be using GLS estimation, based on the residauls
covariance. What's your suggestion?

Giovanni

PS I think it could be an answer to Jose too...




2008/1/27, Edzer Pebesma <edzer.pebesma at uni-muenster.de>:
> Jose, is your model linear, or are you using a generalized linear model?
>
> The questions is not so much: model parameters before or after kriging
> residuals, but rather: model parameters under the assumption of
> independent observations (the usual regression approach), or model
> parameters under the assumption of spatially dependent observations (the
> geostatistical, or generalized linear regression approach). In the case
> you are using a GLM, the report mentioned earlier on regression kriging
> (another name for universal kriging) may not be very helpful, as it
> deals with linear models.
> --
> Edzer
>
> Jose Funes wrote:
> > Hi,
> >
> > I have used regression kriging to model abundance of an invasive
> > species. After performing a stepwise regression of the model, I fitted
> > a theoretical variogram to a empirical variogram of the residuals. My
> > question is how to obtain the parameter estimate of the model after
> > kriging the residuals. Do the parameters of the regression model
> > differ after kriging the residuals? if so, how can I get them from the
> > R output?
> >
> > Looking forward to hearing from you, thanks
> >
> > Jose Funes
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From hengl at science.uva.nl  Wed Jan 30 10:13:55 2008
From: hengl at science.uva.nl (Tomislav Hengl)
Date: Wed, 30 Jan 2008 10:13:55 +0100
Subject: [R-sig-Geo] FYI: Merging GIS and statistics --- RSAGA
Message-ID: <001201c86320$708d4970$3a871291@pcibed193>



Dear all,

I just started running analysis with the RSAGA package
(http://cran.r-project.org/src/contrib/Descriptions/RSAGA.html), i.e. the R scripting link to SAGA
GIS (by Olaf Conrad and colleagues, over 120 modules), that was suggested to me by Paulo van Breugel
and I think that this could really be the missing link between statistics and GIS. My experiences so
far are very positive --- especially if you work with large grids, because SAGA is quite fast for
calculations. Here are some examples from Geomorphometry / Digital Soil Mapping:

0. Getting started:

****************************************************************************
# Download the SAGA 2.0.1 binaries (http://sourceforge.net/projects/saga-gis/) and unzip them to a
local directory e.g. "C:/Progra~1/saga_vc"; # Start R and install the RSAGA package; # load the
library and set the directory where the SAGA binaries sit:

library(RSAGA)
rsaga.env(path="C:/Progra~1/saga_vc")

# To get the exact names of parameters look for a name in the "/modules" directory and then use:

rsaga.get.modules("geostatistics_kriging")
rsaga.get.usage("geostatistics_kriging", 2)

****************************************************************************

1. Error propagation and geomorphometry (both can be run via R now):

****************************************************************************

# Import the point measurements of heights to generate a DEM:

elevations <- read.delim("elevations.txt") coordinates(elevations)=~X+Y
spplot(elevations)

# Import the grid definition:

gridmaps = readGDAL("SMU1.asc")
gridmaps$SMU1 = gridmaps$band1

# Derive area in km^2:

maparea =
(gridmaps at bbox["x","max"]-gridmaps at bbox["x","min"])*(gridmaps at bbox["y","max"]-gridmaps at bbox["y","min
"])/1e+06

# Fit a variogram for elevations and produce 50 realizations of a DEM using Sequential Gaussian
Simulations:

elevations.or = variogram(Z~1, elevations) 
elevations.ovgm = fit.variogram(elevations.or, vgm(1, "Sph", 1000, 1)) 
plot(elevations.or, elevations.ovgm, plot.nu=F, pch="+")

DEM.sim = krige(Z~1, elevations, gridmaps, elevations.ovgm, nmax=40, nsim=50)

# Visualize the simulated DEMs in R:

for (i in 1:length(DEM.sim at data)) {
      image(as.image.SpatialGridDataFrame(DEM.sim[i]), col=terrain.colors(16), asp=1) }

# Write the simulated DEMs in ArcInfo ASCII format:

for (i in 1:length(DEM.sim at data)) {
      write.asciigrid(DEM.sim[i], c(paste("DEM",as.character(i),".asc",sep="")))
}

# Now, derive SLOPE maps in SAGA 50 times:
# ESRI wrapper is used to get the maps directly in ArcInfo ASCII format;

for (i in 1:length(DEM.sim at data)) {
   rsaga.esri.wrapper(rsaga.slope, method="poly2zevenbergen",
in.dem=c(paste("DEM",as.character(i),sep="")), out.slope=c(paste("SLOPE",as.character(i),sep="")),
prec=3, condensed.res=FALSE, intern=FALSE, show.output.on.console=FALSE) }

# Optional: generate a DEM using the Thin Plate Spline (local) interpolation in SAGA:

writeOGR(elevations, "elevations.shp", "elevations", "ESRI Shapefile") 

rsaga.get.usage("grid_spline", 1) rsaga.geoprocessor(lib="grid_spline", module=1,
param=list(GRID="DEMtps.sgrd", SHAPES="elevations.shp", FIELD=1, RADIUS=sqrt(maparea)*1000/3,
SELECT=1, MAXPOINTS=30, TARGET=2, GRID_GRID="DEM1.sgrd")) rsaga.sgrd.to.esri(in.sgrds="DEMtps.sgrd",
out.grids="DEMtps.asc", out.path="D:/GEOSTAT/maps/RSAGA", prec=1)


****************************************************************************

2. Spatial interpolation 
Especially suitable for large maps (R+gstat often fail due to memory limit problems):

****************************************************************************
# Export the predictors to SAGA format:

predict.list = gl(n=9, k=1,
labels=c("DEM","SLOPE","PLANC","TWI","SINS","SMU1","SMU3","SMU4","SMU9"))
rsaga.esri.to.sgrd(in.grids=levels(predict.list),
out.sgrds=set.file.extension(levels(predict.list),".sgrd"), in.path="D:/GEOSTAT/maps/RSAGA")

# predict values in SAGA using only regression model:

rsaga.get.usage("geostatistics_grid", 4) rsaga.geoprocessor(lib="geostatistics_grid", module=4,
param=list(GRIDS="DEM.sgrd;SLOPE.sgrd;PLANC.sgrd;TWI.sgrd;SINS.sgrd;SMU1.sgrd;SMU3.sgrd;SMU4.sgrd;SM
U9.sgrd", SHAPES="baranja.shp", ATTRIBUTE=0, TABLE="regout.dbf", RESIDUAL="solum_res.shp",
REGRESSION="SOLUM_reg.sgrd", INTERPOL=0))

# Ordinary kriging:

rsaga.get.usage("geostatistics_kriging", 1) rsaga.geoprocessor(lib="geostatistics_kriging",
module=1, param=list(GRID="SOLUM_ok.sgrd", VARIANCE="SOLUM_okvar.sgrd", SHAPES="baranja.shp",
FIELD=0, MODEL=1, NUGGET=0, SILL=200, RANGE=500, TARGET=2, GRID_GRID="SLOPE.sgrd"))

# Regression-kriging:

rsaga.get.usage("geostatistics_kriging", 3) rsaga.geoprocessor(lib="geostatistics_kriging",
module=3,
param=list(GRIDS="DEM.sgrd;SLOPE.sgrd;PLANC.sgrd;TWI.sgrd;SINS.sgrd;SMU1.sgrd;SMU3.sgrd;SMU4.sgrd;SM
U9.sgrd", GRID="SOLUM_rk.sgrd", SHAPES="baranja.shp", FIELD=0, MODEL=1, NUGGET=0, SILL=200,
RANGE=500, INTERPOL=0)) 
# Does not work yet. Possibly a bug in the saga_cmd.exe?

****************************************************************************

The complete script and datasets are available at:

http://spatial-analyst.net/GRK/examplesRSAGA.zip   (400 KB)

So the only real problem is the import/export from R to SAGA, which I guess could be solved very
easily if the next version of rgdal would support SAGA format.


Tom Hengl
http://spatial-analyst.net



From Roger.Bivand at nhh.no  Wed Jan 30 10:59:23 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 30 Jan 2008 10:59:23 +0100 (CET)
Subject: [R-sig-Geo] FYI: Merging GIS and statistics --- RSAGA
In-Reply-To: <001201c86320$708d4970$3a871291@pcibed193>
References: <001201c86320$708d4970$3a871291@pcibed193>
Message-ID: <Pine.LNX.4.64.0801301033040.19310@reclus.nhh.no>

On Wed, 30 Jan 2008, Tomislav Hengl wrote:

>
>
> Dear all,
>
> I just started running analysis with the RSAGA package 
> (http://cran.r-project.org/src/contrib/Descriptions/RSAGA.html), i.e. 
> the R scripting link to SAGA GIS (by Olaf Conrad and colleagues, over 
> 120 modules), that was suggested to me by Paulo van Breugel and I think 
> that this could really be the missing link between statistics and GIS.

No, there are always more missing links, never a silver bullet. SAGA is 
hard to install from source, and it appears that there is not much 
activity on the SF CVS, and few install instructions. It seems to have 
multiple interface dependencies which Linux users will find hard to 
satisfy. It may work as a Windows binary install. The RSAGA maintainer 
does not seem to read this list - my feeling is that SAGA lives in a world 
of its own.

Re. memory problems on Windows, please see the R for Windows FAQ, and 
remember firstly that there is no R for 64-bit windows yet, and that 
Windows memory management (despite much work being done within R to try to 
alleviate things), is inferior to OSX and Linux, because all requests have 
to be met in one chunk. If you want 300MB, Windows will turn you down if 
there isn't a single chunk of that size free, while the alternatives 
collect the chunks they have and hand off addresses making it look like 
continuous memory to the application (if I understand correctly). This 
means that some tasks fail under Windows but succeed under other OS on the 
same hardware.

If SAGA can make a source library for reading and writing its raster file 
formats available to GDAL, and maybe help write a driver, SAGA access 
through rgdal will happen automatically. Lots of other projects do this, 
for example, the PCRaster format is included as source in the GDAL source. 
Were SAGA to split out the raster I/O as a library and provide a copy to 
GDAL, your question would be answered. SAGA does use GDAL for interfacing 
other formats, and would be a "good citizen" if they reciprocated.

I don't see the SAGA format documented (there doesn't seem to be much 
documentation for programmers), but if you know what it is, you can use 
readBin() and writeBin() in R to construct a portable interface.

SAGA may be a good idea, but there are plenty of very viable alternatives.

Roger

> My experiences so far are very positive --- especially if you work with 
> large grids, because SAGA is quite fast for calculations. Here are some 
> examples from Geomorphometry / Digital Soil Mapping:
>
> 0. Getting started:
>
> **************************************************************************** 
> # Download the SAGA 2.0.1 binaries 
> (http://sourceforge.net/projects/saga-gis/) and unzip them to a local 
> directory e.g. "C:/Progra~1/saga_vc"; # Start R and install the RSAGA 
> package; # load the library and set the directory where the SAGA 
> binaries sit:
>
> library(RSAGA)
> rsaga.env(path="C:/Progra~1/saga_vc")
>
> # To get the exact names of parameters look for a name in the "/modules" directory and then use:
>
> rsaga.get.modules("geostatistics_kriging")
> rsaga.get.usage("geostatistics_kriging", 2)
>
> ****************************************************************************
>
> 1. Error propagation and geomorphometry (both can be run via R now):
>
> ****************************************************************************
>
> # Import the point measurements of heights to generate a DEM:
>
> elevations <- read.delim("elevations.txt") coordinates(elevations)=~X+Y
> spplot(elevations)
>
> # Import the grid definition:
>
> gridmaps = readGDAL("SMU1.asc")
> gridmaps$SMU1 = gridmaps$band1
>
> # Derive area in km^2:
>
> maparea =
> (gridmaps at bbox["x","max"]-gridmaps at bbox["x","min"])*(gridmaps at bbox["y","max"]-gridmaps at bbox["y","min
> "])/1e+06
>
> # Fit a variogram for elevations and produce 50 realizations of a DEM using Sequential Gaussian
> Simulations:
>
> elevations.or = variogram(Z~1, elevations)
> elevations.ovgm = fit.variogram(elevations.or, vgm(1, "Sph", 1000, 1))
> plot(elevations.or, elevations.ovgm, plot.nu=F, pch="+")
>
> DEM.sim = krige(Z~1, elevations, gridmaps, elevations.ovgm, nmax=40, nsim=50)
>
> # Visualize the simulated DEMs in R:
>
> for (i in 1:length(DEM.sim at data)) {
>      image(as.image.SpatialGridDataFrame(DEM.sim[i]), col=terrain.colors(16), asp=1) }
>
> # Write the simulated DEMs in ArcInfo ASCII format:
>
> for (i in 1:length(DEM.sim at data)) {
>      write.asciigrid(DEM.sim[i], c(paste("DEM",as.character(i),".asc",sep="")))
> }
>
> # Now, derive SLOPE maps in SAGA 50 times:
> # ESRI wrapper is used to get the maps directly in ArcInfo ASCII format;
>
> for (i in 1:length(DEM.sim at data)) {
>   rsaga.esri.wrapper(rsaga.slope, method="poly2zevenbergen",
> in.dem=c(paste("DEM",as.character(i),sep="")), out.slope=c(paste("SLOPE",as.character(i),sep="")),
> prec=3, condensed.res=FALSE, intern=FALSE, show.output.on.console=FALSE) }
>
> # Optional: generate a DEM using the Thin Plate Spline (local) interpolation in SAGA:
>
> writeOGR(elevations, "elevations.shp", "elevations", "ESRI Shapefile")
>
> rsaga.get.usage("grid_spline", 1) rsaga.geoprocessor(lib="grid_spline", module=1,
> param=list(GRID="DEMtps.sgrd", SHAPES="elevations.shp", FIELD=1, RADIUS=sqrt(maparea)*1000/3,
> SELECT=1, MAXPOINTS=30, TARGET=2, GRID_GRID="DEM1.sgrd")) rsaga.sgrd.to.esri(in.sgrds="DEMtps.sgrd",
> out.grids="DEMtps.asc", out.path="D:/GEOSTAT/maps/RSAGA", prec=1)
>
>
> ****************************************************************************
>
> 2. Spatial interpolation
> Especially suitable for large maps (R+gstat often fail due to memory limit problems):
>
> ****************************************************************************
> # Export the predictors to SAGA format:
>
> predict.list = gl(n=9, k=1,
> labels=c("DEM","SLOPE","PLANC","TWI","SINS","SMU1","SMU3","SMU4","SMU9"))
> rsaga.esri.to.sgrd(in.grids=levels(predict.list),
> out.sgrds=set.file.extension(levels(predict.list),".sgrd"), in.path="D:/GEOSTAT/maps/RSAGA")
>
> # predict values in SAGA using only regression model:
>
> rsaga.get.usage("geostatistics_grid", 4) rsaga.geoprocessor(lib="geostatistics_grid", module=4,
> param=list(GRIDS="DEM.sgrd;SLOPE.sgrd;PLANC.sgrd;TWI.sgrd;SINS.sgrd;SMU1.sgrd;SMU3.sgrd;SMU4.sgrd;SM
> U9.sgrd", SHAPES="baranja.shp", ATTRIBUTE=0, TABLE="regout.dbf", RESIDUAL="solum_res.shp",
> REGRESSION="SOLUM_reg.sgrd", INTERPOL=0))
>
> # Ordinary kriging:
>
> rsaga.get.usage("geostatistics_kriging", 1) rsaga.geoprocessor(lib="geostatistics_kriging",
> module=1, param=list(GRID="SOLUM_ok.sgrd", VARIANCE="SOLUM_okvar.sgrd", SHAPES="baranja.shp",
> FIELD=0, MODEL=1, NUGGET=0, SILL=200, RANGE=500, TARGET=2, GRID_GRID="SLOPE.sgrd"))
>
> # Regression-kriging:
>
> rsaga.get.usage("geostatistics_kriging", 3) rsaga.geoprocessor(lib="geostatistics_kriging",
> module=3,
> param=list(GRIDS="DEM.sgrd;SLOPE.sgrd;PLANC.sgrd;TWI.sgrd;SINS.sgrd;SMU1.sgrd;SMU3.sgrd;SMU4.sgrd;SM
> U9.sgrd", GRID="SOLUM_rk.sgrd", SHAPES="baranja.shp", FIELD=0, MODEL=1, NUGGET=0, SILL=200,
> RANGE=500, INTERPOL=0))
> # Does not work yet. Possibly a bug in the saga_cmd.exe?
>
> ****************************************************************************
>
> The complete script and datasets are available at:
>
> http://spatial-analyst.net/GRK/examplesRSAGA.zip   (400 KB)
>
> So the only real problem is the import/export from R to SAGA, which I guess could be solved very
> easily if the next version of rgdal would support SAGA format.
>
>
> Tom Hengl
> http://spatial-analyst.net
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From johan.vandewauw at gmail.com  Wed Jan 30 11:35:21 2008
From: johan.vandewauw at gmail.com (Johan Van de Wauw)
Date: Wed, 30 Jan 2008 11:35:21 +0100
Subject: [R-sig-Geo] FYI: Merging GIS and statistics --- RSAGA
In-Reply-To: <Pine.LNX.4.64.0801301033040.19310@reclus.nhh.no>
References: <001201c86320$708d4970$3a871291@pcibed193>
	<Pine.LNX.4.64.0801301033040.19310@reclus.nhh.no>
Message-ID: <791a12030801300235p58e5a1bat6d73919c6bd50b81@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080130/cd5c3748/attachment.pl>

From Roger.Bivand at nhh.no  Wed Jan 30 11:48:20 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 30 Jan 2008 11:48:20 +0100 (CET)
Subject: [R-sig-Geo] FYI: Merging GIS and statistics --- RSAGA
In-Reply-To: <791a12030801300235p58e5a1bat6d73919c6bd50b81@mail.gmail.com>
References: <001201c86320$708d4970$3a871291@pcibed193> 
	<Pine.LNX.4.64.0801301033040.19310@reclus.nhh.no>
	<791a12030801300235p58e5a1bat6d73919c6bd50b81@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0801301143570.20220@reclus.nhh.no>

On Wed, 30 Jan 2008, Johan Van de Wauw wrote:

> On Jan 30, 2008 10:59 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
> If SAGA can make a source library for reading and writing its raster file
>> formats available to GDAL, and maybe help write a driver, SAGA access
>> through rgdal will happen automatically. Lots of other projects do this,
>> for example, the PCRaster format is included as source in the GDAL source.
>> Were SAGA to split out the raster I/O as a library and provide a copy to
>> GDAL, your question would be answered. SAGA does use GDAL for interfacing
>> other formats, and would be a "good citizen" if they reciprocated.
>>
>
> In fact, there is a module that imports and exports to GDAL in SAGA. It's
> code is rather simple, and I believe that bringing it to GDAL should not be
> a major issue. The SAGA format is nothing else than yet another binary
> gridfile with some kind of world-file attached to it. I've had the idea to
> bring this format in gdal for quite some time (in fact I once wrote a now
> obsolete export to gdal module for SAGA which I never released because I
> still wanted to tweak it(and the hyperfocus was gone...)). I'll cross-check
> with the saga-developers to see if somebody else is working on a
> gdal-implementation, and I might give it a try.

Please do - or if it is a BIL or similar, just saying which existing GDAL 
driver also works for SAGA would be great. If it is very similar, it might 
be enough to tweak a copy of an existing GDAL format.

>
> In the meantime I use R and SAGA frequently, and I just export to geotiff,
> which both programs read and write well. I didn't try RSAGA yet, but I see
> no reason why that's not possible.
>

That's very helpful. Could you please say whether the coordinate reference 
systems are recognised correctly on both sides, and if you need any extra 
arguments to write (presumably) using functions from the rgdal package?

Roger

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From dylan.beaudette at gmail.com  Wed Jan 30 17:21:17 2008
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Wed, 30 Jan 2008 08:21:17 -0800
Subject: [R-sig-Geo] FYI: Merging GIS and statistics --- RSAGA
In-Reply-To: <001201c86320$708d4970$3a871291@pcibed193>
References: <001201c86320$708d4970$3a871291@pcibed193>
Message-ID: <200801300821.17858.dylan.beaudette@gmail.com>

On Wednesday 30 January 2008 01:13:55 am Tomislav Hengl wrote:
> Dear all,
>
> I just started running analysis with the RSAGA package
> (http://cran.r-project.org/src/contrib/Descriptions/RSAGA.html), i.e. the R
> scripting link to SAGA GIS (by Olaf Conrad and colleagues, over 120
> modules), that was suggested to me by Paulo van Breugel and I think that
> this could really be the missing link between statistics and GIS. My
> experiences so far are very positive --- especially if you work with large
> grids, because SAGA is quite fast for calculations. Here are some examples
> from Geomorphometry / Digital Soil Mapping:
>
> 0. Getting started:
>
> ***************************************************************************
>* # Download the SAGA 2.0.1 binaries
> (http://sourceforge.net/projects/saga-gis/) and unzip them to a local
> directory e.g. "C:/Progra~1/saga_vc"; # Start R and install the RSAGA
> package; # load the library and set the directory where the SAGA binaries
> sit:
>
> library(RSAGA)
> rsaga.env(path="C:/Progra~1/saga_vc")
>
> # To get the exact names of parameters look for a name in the "/modules"
> directory and then use:
>
> rsaga.get.modules("geostatistics_kriging")
> rsaga.get.usage("geostatistics_kriging", 2)
>
> ***************************************************************************
>*
>
> 1. Error propagation and geomorphometry (both can be run via R now):
>
> ***************************************************************************
>*
>
> # Import the point measurements of heights to generate a DEM:
>
> elevations <- read.delim("elevations.txt") coordinates(elevations)=~X+Y
> spplot(elevations)
>
> # Import the grid definition:
>
> gridmaps = readGDAL("SMU1.asc")
> gridmaps$SMU1 = gridmaps$band1
>
> # Derive area in km^2:
>
> maparea =
> (gridmaps at bbox["x","max"]-gridmaps at bbox["x","min"])*(gridmaps at bbox["y","max
>"]-gridmaps at bbox["y","min "])/1e+06
>
> # Fit a variogram for elevations and produce 50 realizations of a DEM using
> Sequential Gaussian Simulations:
>
> elevations.or = variogram(Z~1, elevations)
> elevations.ovgm = fit.variogram(elevations.or, vgm(1, "Sph", 1000, 1))
> plot(elevations.or, elevations.ovgm, plot.nu=F, pch="+")
>
> DEM.sim = krige(Z~1, elevations, gridmaps, elevations.ovgm, nmax=40,
> nsim=50)
>
> # Visualize the simulated DEMs in R:
>
> for (i in 1:length(DEM.sim at data)) {
>       image(as.image.SpatialGridDataFrame(DEM.sim[i]),
> col=terrain.colors(16), asp=1) }
>
> # Write the simulated DEMs in ArcInfo ASCII format:
>
> for (i in 1:length(DEM.sim at data)) {
>       write.asciigrid(DEM.sim[i],
> c(paste("DEM",as.character(i),".asc",sep=""))) }
>
> # Now, derive SLOPE maps in SAGA 50 times:
> # ESRI wrapper is used to get the maps directly in ArcInfo ASCII format;
>
> for (i in 1:length(DEM.sim at data)) {
>    rsaga.esri.wrapper(rsaga.slope, method="poly2zevenbergen",
> in.dem=c(paste("DEM",as.character(i),sep="")),
> out.slope=c(paste("SLOPE",as.character(i),sep="")), prec=3,
> condensed.res=FALSE, intern=FALSE, show.output.on.console=FALSE) }
>
> # Optional: generate a DEM using the Thin Plate Spline (local)
> interpolation in SAGA:
>
> writeOGR(elevations, "elevations.shp", "elevations", "ESRI Shapefile")
>
> rsaga.get.usage("grid_spline", 1) rsaga.geoprocessor(lib="grid_spline",
> module=1, param=list(GRID="DEMtps.sgrd", SHAPES="elevations.shp", FIELD=1,
> RADIUS=sqrt(maparea)*1000/3, SELECT=1, MAXPOINTS=30, TARGET=2,
> GRID_GRID="DEM1.sgrd")) rsaga.sgrd.to.esri(in.sgrds="DEMtps.sgrd",
> out.grids="DEMtps.asc", out.path="D:/GEOSTAT/maps/RSAGA", prec=1)
>
>
> ***************************************************************************
>*
>
> 2. Spatial interpolation
> Especially suitable for large maps (R+gstat often fail due to memory limit
> problems):
>
> ***************************************************************************
>* # Export the predictors to SAGA format:
>
> predict.list = gl(n=9, k=1,
> labels=c("DEM","SLOPE","PLANC","TWI","SINS","SMU1","SMU3","SMU4","SMU9"))
> rsaga.esri.to.sgrd(in.grids=levels(predict.list),
> out.sgrds=set.file.extension(levels(predict.list),".sgrd"),
> in.path="D:/GEOSTAT/maps/RSAGA")
>
> # predict values in SAGA using only regression model:
>
> rsaga.get.usage("geostatistics_grid", 4)
> rsaga.geoprocessor(lib="geostatistics_grid", module=4,
> param=list(GRIDS="DEM.sgrd;SLOPE.sgrd;PLANC.sgrd;TWI.sgrd;SINS.sgrd;SMU1.sg
>rd;SMU3.sgrd;SMU4.sgrd;SM U9.sgrd", SHAPES="baranja.shp", ATTRIBUTE=0,
> TABLE="regout.dbf", RESIDUAL="solum_res.shp", REGRESSION="SOLUM_reg.sgrd",
> INTERPOL=0))
>
> # Ordinary kriging:
>
> rsaga.get.usage("geostatistics_kriging", 1)
> rsaga.geoprocessor(lib="geostatistics_kriging", module=1,
> param=list(GRID="SOLUM_ok.sgrd", VARIANCE="SOLUM_okvar.sgrd",
> SHAPES="baranja.shp", FIELD=0, MODEL=1, NUGGET=0, SILL=200, RANGE=500,
> TARGET=2, GRID_GRID="SLOPE.sgrd"))
>
> # Regression-kriging:
>
> rsaga.get.usage("geostatistics_kriging", 3)
> rsaga.geoprocessor(lib="geostatistics_kriging", module=3,
> param=list(GRIDS="DEM.sgrd;SLOPE.sgrd;PLANC.sgrd;TWI.sgrd;SINS.sgrd;SMU1.sg
>rd;SMU3.sgrd;SMU4.sgrd;SM U9.sgrd", GRID="SOLUM_rk.sgrd",
> SHAPES="baranja.shp", FIELD=0, MODEL=1, NUGGET=0, SILL=200, RANGE=500,
> INTERPOL=0))
> # Does not work yet. Possibly a bug in the saga_cmd.exe?
>
> ***************************************************************************
>*
>
> The complete script and datasets are available at:
>
> http://spatial-analyst.net/GRK/examplesRSAGA.zip   (400 KB)
>
> So the only real problem is the import/export from R to SAGA, which I guess
> could be solved very easily if the next version of rgdal would support SAGA
> format.
>
>

This is all very interesting, but doesn't the GRASS-R combination already do 
these things- and quite well ? As far as I can tell GRASS can handle the 
massive grid operations, and R+gstat can do the statistical modeling, etc.

But maybe I should check out SAGA again- it wouldn't compile last time...

Thanks for the post,


-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341



From Agustin.Lobo at ija.csic.es  Wed Jan 30 17:55:58 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Wed, 30 Jan 2008 17:55:58 +0100
Subject: [R-sig-Geo] FYI: Merging GIS and statistics --- RSAGA
In-Reply-To: <001201c86320$708d4970$3a871291@pcibed193>
References: <001201c86320$708d4970$3a871291@pcibed193>
Message-ID: <47A0AC1E.6070709@ija.csic.es>

Good job! This is more or less like the R-GRASS link, but SAGA
does different things, so it's good having this additional tool available.
Anyway, I do not think that these links are the real solution, which
should be being able to display R spatial objects on a geographical
display in which the information could be interactively consulted
and overlayed with other geographic information. So the work is
perhaps more on the GIS side, which should be able to represent
R spatial objects, or provide R with a real geographical display.

Going back and forth with geotif rasters and/or shp vectors soon becomes 
inconvenient.

Agus

Tomislav Hengl escribi?:
> 
> Dear all,
> 
> I just started running analysis with the RSAGA package
> (http://cran.r-project.org/src/contrib/Descriptions/RSAGA.html), i.e. the R scripting link to SAGA
> GIS (by Olaf Conrad and colleagues, over 120 modules), that was suggested to me by Paulo van Breugel
> and I think that this could really be the missing link between statistics and GIS. My experiences so
> far are very positive --- especially if you work with large grids, because SAGA is quite fast for
> calculations. Here are some examples from Geomorphometry / Digital Soil Mapping:
> 
> 0. Getting started:
> 
> ****************************************************************************
> # Download the SAGA 2.0.1 binaries (http://sourceforge.net/projects/saga-gis/) and unzip them to a
> local directory e.g. "C:/Progra~1/saga_vc"; # Start R and install the RSAGA package; # load the
> library and set the directory where the SAGA binaries sit:
> 
> library(RSAGA)
> rsaga.env(path="C:/Progra~1/saga_vc")
> 
> # To get the exact names of parameters look for a name in the "/modules" directory and then use:
> 
> rsaga.get.modules("geostatistics_kriging")
> rsaga.get.usage("geostatistics_kriging", 2)
> 
> ****************************************************************************
> 
> 1. Error propagation and geomorphometry (both can be run via R now):
> 
> ****************************************************************************
> 
> # Import the point measurements of heights to generate a DEM:
> 
> elevations <- read.delim("elevations.txt") coordinates(elevations)=~X+Y
> spplot(elevations)
> 
> # Import the grid definition:
> 
> gridmaps = readGDAL("SMU1.asc")
> gridmaps$SMU1 = gridmaps$band1
> 
> # Derive area in km^2:
> 
> maparea =
> (gridmaps at bbox["x","max"]-gridmaps at bbox["x","min"])*(gridmaps at bbox["y","max"]-gridmaps at bbox["y","min
> "])/1e+06
> 
> # Fit a variogram for elevations and produce 50 realizations of a DEM using Sequential Gaussian
> Simulations:
> 
> elevations.or = variogram(Z~1, elevations) 
> elevations.ovgm = fit.variogram(elevations.or, vgm(1, "Sph", 1000, 1)) 
> plot(elevations.or, elevations.ovgm, plot.nu=F, pch="+")
> 
> DEM.sim = krige(Z~1, elevations, gridmaps, elevations.ovgm, nmax=40, nsim=50)
> 
> # Visualize the simulated DEMs in R:
> 
> for (i in 1:length(DEM.sim at data)) {
>       image(as.image.SpatialGridDataFrame(DEM.sim[i]), col=terrain.colors(16), asp=1) }
> 
> # Write the simulated DEMs in ArcInfo ASCII format:
> 
> for (i in 1:length(DEM.sim at data)) {
>       write.asciigrid(DEM.sim[i], c(paste("DEM",as.character(i),".asc",sep="")))
> }
> 
> # Now, derive SLOPE maps in SAGA 50 times:
> # ESRI wrapper is used to get the maps directly in ArcInfo ASCII format;
> 
> for (i in 1:length(DEM.sim at data)) {
>    rsaga.esri.wrapper(rsaga.slope, method="poly2zevenbergen",
> in.dem=c(paste("DEM",as.character(i),sep="")), out.slope=c(paste("SLOPE",as.character(i),sep="")),
> prec=3, condensed.res=FALSE, intern=FALSE, show.output.on.console=FALSE) }
> 
> # Optional: generate a DEM using the Thin Plate Spline (local) interpolation in SAGA:
> 
> writeOGR(elevations, "elevations.shp", "elevations", "ESRI Shapefile") 
> 
> rsaga.get.usage("grid_spline", 1) rsaga.geoprocessor(lib="grid_spline", module=1,
> param=list(GRID="DEMtps.sgrd", SHAPES="elevations.shp", FIELD=1, RADIUS=sqrt(maparea)*1000/3,
> SELECT=1, MAXPOINTS=30, TARGET=2, GRID_GRID="DEM1.sgrd")) rsaga.sgrd.to.esri(in.sgrds="DEMtps.sgrd",
> out.grids="DEMtps.asc", out.path="D:/GEOSTAT/maps/RSAGA", prec=1)
> 
> 
> ****************************************************************************
> 
> 2. Spatial interpolation 
> Especially suitable for large maps (R+gstat often fail due to memory limit problems):
> 
> ****************************************************************************
> # Export the predictors to SAGA format:
> 
> predict.list = gl(n=9, k=1,
> labels=c("DEM","SLOPE","PLANC","TWI","SINS","SMU1","SMU3","SMU4","SMU9"))
> rsaga.esri.to.sgrd(in.grids=levels(predict.list),
> out.sgrds=set.file.extension(levels(predict.list),".sgrd"), in.path="D:/GEOSTAT/maps/RSAGA")
> 
> # predict values in SAGA using only regression model:
> 
> rsaga.get.usage("geostatistics_grid", 4) rsaga.geoprocessor(lib="geostatistics_grid", module=4,
> param=list(GRIDS="DEM.sgrd;SLOPE.sgrd;PLANC.sgrd;TWI.sgrd;SINS.sgrd;SMU1.sgrd;SMU3.sgrd;SMU4.sgrd;SM
> U9.sgrd", SHAPES="baranja.shp", ATTRIBUTE=0, TABLE="regout.dbf", RESIDUAL="solum_res.shp",
> REGRESSION="SOLUM_reg.sgrd", INTERPOL=0))
> 
> # Ordinary kriging:
> 
> rsaga.get.usage("geostatistics_kriging", 1) rsaga.geoprocessor(lib="geostatistics_kriging",
> module=1, param=list(GRID="SOLUM_ok.sgrd", VARIANCE="SOLUM_okvar.sgrd", SHAPES="baranja.shp",
> FIELD=0, MODEL=1, NUGGET=0, SILL=200, RANGE=500, TARGET=2, GRID_GRID="SLOPE.sgrd"))
> 
> # Regression-kriging:
> 
> rsaga.get.usage("geostatistics_kriging", 3) rsaga.geoprocessor(lib="geostatistics_kriging",
> module=3,
> param=list(GRIDS="DEM.sgrd;SLOPE.sgrd;PLANC.sgrd;TWI.sgrd;SINS.sgrd;SMU1.sgrd;SMU3.sgrd;SMU4.sgrd;SM
> U9.sgrd", GRID="SOLUM_rk.sgrd", SHAPES="baranja.shp", FIELD=0, MODEL=1, NUGGET=0, SILL=200,
> RANGE=500, INTERPOL=0)) 
> # Does not work yet. Possibly a bug in the saga_cmd.exe?
> 
> ****************************************************************************
> 
> The complete script and datasets are available at:
> 
> http://spatial-analyst.net/GRK/examplesRSAGA.zip   (400 KB)
> 
> So the only real problem is the import/export from R to SAGA, which I guess could be solved very
> easily if the next version of rgdal would support SAGA format.
> 
> 
> Tom Hengl
> http://spatial-analyst.net
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From mrufino at cripsul.ipimar.pt  Wed Jan 30 18:08:37 2008
From: mrufino at cripsul.ipimar.pt (Marta Rufino)
Date: Wed, 30 Jan 2008 17:08:37 +0000
Subject: [R-sig-Geo] review on autocorrelation methods
In-Reply-To: <mailman.9.1201690802.26785.r-sig-geo@stat.math.ethz.ch>
References: <mailman.9.1201690802.26785.r-sig-geo@stat.math.ethz.ch>
Message-ID: <47A0AF15.1070303@cripsul.ipimar.pt>

Hello,

There is recent article about 'methods to account for spatial 
auto-correlation in the analysis of species distribution data", which I 
think it might clarify on some of the points being adressed and it is 
interesting to bring up to this  discussion list.
The authors compare several spatial models, using simulated data, etc. 
And also review the current knowledge on spatial autocorrelation, 
according top their vue (off-course :-)) (which is interesting also).

Dormann et al 2007. Methods to account for spatial auto-correlation in 
the analysis of species distributional data: a review" Ecography.

Hope this helps,
Best wishes,
Marta



> Date: Tue, 29 Jan 2008 20:17:42 +0100
> From: "G. Allegri" <giohappy at gmail.com>
> Subject: Re: [R-sig-Geo] Regression kriging
> To: "Edzer Pebesma" <edzer.pebesma at uni-muenster.de>
> Cc: r-sig-geo at stat.math.ethz.ch, Jose Funes <jefunes at gmail.com>
> Message-ID:
> 	<e12429640801291117j4f31de22iae9d03bbeb6d4218 at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
>
> Dear Edzer,
> I've "medidated" on the answer you gave to Jose. Two considerations have raise:
>
>  1 - when you say that the approach of GLM is a way to consider
> spatial dependence. I'm not sure about this. GLM are a way to account
> for link functions between the dependent variables and covariates (ex.
> Poisson family for count datas), but they don't take account,
> implicitly, of sptial correlation. Am I wrong?
> Rather (generalized) mixed models are a counterpart to geostatical methods are.
>
> 2 - A task of my research is to find the "best" relations between a
> set of covariates, to make a simple multicriteria analysis,
> overlapping different map layers thorugh map algebra. In this case,
> the common geostatistical methods don't help me much. I'm considering
> to use multivariate regression, but keeping in count of spatial
> correlation. What's the best approach? I've thought to Mixed Models,
> but another way could be using GLS estimation, based on the residauls
> covariance. What's your suggestion?
>
> Giovanni
>
> PS I think it could be an answer to Jose too...
>
>
>
>
> 2008/1/27, Edzer Pebesma <edzer.pebesma at uni-muenster.de>:
>



From b.rowlingson at lancaster.ac.uk  Wed Jan 30 18:51:28 2008
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 30 Jan 2008 17:51:28 +0000
Subject: [R-sig-Geo] FYI: Merging GIS and statistics --- RSAGA
In-Reply-To: <47A0AC1E.6070709@ija.csic.es>
References: <001201c86320$708d4970$3a871291@pcibed193>
	<47A0AC1E.6070709@ija.csic.es>
Message-ID: <47A0B920.4030302@lancaster.ac.uk>

Agustin Lobo wrote:
> So the work is
> perhaps more on the GIS side, which should be able to represent
> R spatial objects, or provide R with a real geographical display.

  Now this could be done with a GDAL/OGR driver for R-spatial objects 
(stored in .RData files). Then you could use any GIS with GDAL/OGR 
capabilities to make pretty maps with R objects.

  I'm not really au fait with writing and linking GDAL/OGR drivers, but 
the code would have to link with libR and require the sp package... Fun. 
Anyone up for it?

Barry



From igr at stanford.edu  Wed Jan 30 20:50:46 2008
From: igr at stanford.edu (Ian Robertson)
Date: Wed, 30 Jan 2008 11:50:46 -0800
Subject: [R-sig-Geo] memory limitations to markstat
Message-ID: <47A0D516.1070300@stanford.edu>

Hello all,

I have been running into memory-related problems trying to use markstat 
(with 'table' as its supplied function) to assemble tabulations of 
categorical marks within fixed distances around about 5000 points. 
Experimenting with random data suggests that my default memory settings 
allow markstat to handle around 3200 points. At 3225 points, I get the 
message "Error: cannot allocate vector of size 317.4 Mb". Does anyone 
know what vector R is trying to store? Can anyone suggest a work around? 
Here is some illustrative code based on random data:

library(spatstat)
npoints <- 3200 #works
#npoints <- 3225 #fails
east <- runif(npoints, 1, 100)
north <- runif(npoints, 1, 100)
mark <- ceiling(runif(npoints, 0, 4))
ppo1 <- ppp(east, north, c(0, 100), c(0, 100), marks=factor(mark))
mTab <- markstat(ppo1, R=5, table, exclude=T)

I imagine that the various K-function tools in spatstat have to be 
making tabulations similar to what I have attempted to do with markstat. 
I have experimented with Kdot, forcing it to do a similar amount of work 
by making all the marks the same. Kdot can handle at least 5000 points 
(but not 5500) but since it doesn't return any mark-tabulations, I don't 
think it will help me.

npoints <- 5000 #works
npoints <- 5500 #fails
east <- runif(npoints, 1, 100)
north <- runif(npoints, 1, 100)
mark <- rep(1, npoints)
ppo1 <- ppp(east, north, c(0, 100), c(0, 100), marks=factor(mark))
kd1 <- Kdot(ppo1, "1")
 
I expect I could divide my study area into several appropriately 
overlapping sections, apply markstat to each, and then reassemble a 
single set of tabulations by selecting the largest 'neighbourhood set' 
available for any cases that get tabulated in more than one section. 
This seems pretty messy, but may be the way to go--short of doing the 
work in GRASS.

Many thanks in advance for any help or advice.

Ian Robertson



From Roger.Bivand at nhh.no  Wed Jan 30 21:33:25 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 30 Jan 2008 21:33:25 +0100 (CET)
Subject: [R-sig-Geo] memory limitations to markstat
In-Reply-To: <47A0D516.1070300@stanford.edu>
References: <47A0D516.1070300@stanford.edu>
Message-ID: <Pine.LNX.4.64.0801302111450.20826@reclus.nhh.no>

On Wed, 30 Jan 2008, Ian Robertson wrote:

> Hello all,
>
> I have been running into memory-related problems trying to use markstat
> (with 'table' as its supplied function) to assemble tabulations of
> categorical marks within fixed distances around about 5000 points.
> Experimenting with random data suggests that my default memory settings
> allow markstat to handle around 3200 points. At 3225 points, I get the
> message "Error: cannot allocate vector of size 317.4 Mb". Does anyone
> know what vector R is trying to store? Can anyone suggest a work around?
> Here is some illustrative code based on random data:
>
> library(spatstat)
> npoints <- 3200 #works
> #npoints <- 3225 #fails
> east <- runif(npoints, 1, 100)
> north <- runif(npoints, 1, 100)
> mark <- ceiling(runif(npoints, 0, 4))
> ppo1 <- ppp(east, north, c(0, 100), c(0, 100), marks=factor(mark))
> mTab <- markstat(ppo1, R=5, table, exclude=T)

Very useful example. If you say:

debug(applynbd)

and run markstat(), you see that it operates with at least four n by n 
matrices, which get stacked in an array. I think your error exit is when 
the big a is being created. It does not use quadtrees or similar data 
structures. Kdot() uses a different internal infrastructure.

If you are willing to try an alternative, I can let you try an unreleased 
ANN tree-based package which has a heuristic distance cutoff (it uses 
k-nearest neighbours, so k has to be adaptive in the inverse of density). 
If your distances are small relative to the total, this should work.
Please say if you prefer a source or Windows binary package. Work is going 
on to bring together several ports of ANN, but isn't ready yet.

If a quicker and dirtier solution is acceptable, try:

library(maptools)
ppo1a <- as(ppo1, "SpatialPointsDataFrame")
summary(ppo1a)
d5nb <- dnearneigh(coordinates(ppo1a), 0, 5)
mt <- sapply(d5nb, function(x) table(ppo1a$marks[x]))
str(mt)

mt will need transposing. Because dnearneigh() doesn't use a full or 
triangular distance matrix, just distances for points one by one, its 
memory footprint is small. d5nb is a list of neighbours within distance 5, 
so can be used with sapply and lapply.

Hope this helps,

Roger

>
> I imagine that the various K-function tools in spatstat have to be
> making tabulations similar to what I have attempted to do with markstat.
> I have experimented with Kdot, forcing it to do a similar amount of work
> by making all the marks the same. Kdot can handle at least 5000 points
> (but not 5500) but since it doesn't return any mark-tabulations, I don't
> think it will help me.
>
> npoints <- 5000 #works
> npoints <- 5500 #fails
> east <- runif(npoints, 1, 100)
> north <- runif(npoints, 1, 100)
> mark <- rep(1, npoints)
> ppo1 <- ppp(east, north, c(0, 100), c(0, 100), marks=factor(mark))
> kd1 <- Kdot(ppo1, "1")
>
> I expect I could divide my study area into several appropriately
> overlapping sections, apply markstat to each, and then reassemble a
> single set of tabulations by selecting the largest 'neighbourhood set'
> available for any cases that get tabulated in more than one section.
> This seems pretty messy, but may be the way to go--short of doing the
> work in GRASS.
>
> Many thanks in advance for any help or advice.
>
> Ian Robertson
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From igr at stanford.edu  Thu Jan 31 18:13:08 2008
From: igr at stanford.edu (Ian Robertson)
Date: Thu, 31 Jan 2008 09:13:08 -0800
Subject: [R-sig-Geo] memory limitations to markstat
In-Reply-To: <Pine.LNX.4.64.0801302111450.20826@reclus.nhh.no>
References: <47A0D516.1070300@stanford.edu>
	<Pine.LNX.4.64.0801302111450.20826@reclus.nhh.no>
Message-ID: <47A201A4.2040506@stanford.edu>

Hello Roger,

Many thanks indeed for the useful observations about the reasons for 
memory limitations in markstat, and a solution using maptools and 
spdep--this does what I want to quite nicely. I would also be quite 
interested in experimenting with the unreleased package you mention; I 
would prefer the Windows binary, please.

Best,

Ian Robertson

Roger Bivand wrote:
> Very useful example. If you say:
>
> debug(applynbd)
>
> and run markstat(), you see that it operates with at least four n by n 
> matrices, which get stacked in an array. I think your error exit is 
> when the big a is being created. It does not use quadtrees or similar 
> data structures. Kdot() uses a different internal infrastructure.
>
> If you are willing to try an alternative, I can let you try an 
> unreleased ANN tree-based package which has a heuristic distance 
> cutoff (it uses k-nearest neighbours, so k has to be adaptive in the 
> inverse of density). If your distances are small relative to the 
> total, this should work.
> Please say if you prefer a source or Windows binary package. Work is 
> going on to bring together several ports of ANN, but isn't ready yet.
>
> If a quicker and dirtier solution is acceptable, try:
>
> library(maptools)
> ppo1a <- as(ppo1, "SpatialPointsDataFrame")
> summary(ppo1a)
> d5nb <- dnearneigh(coordinates(ppo1a), 0, 5)
> mt <- sapply(d5nb, function(x) table(ppo1a$marks[x]))
> str(mt)
>
> mt will need transposing. Because dnearneigh() doesn't use a full or 
> triangular distance matrix, just distances for points one by one, its 
> memory footprint is small. d5nb is a list of neighbours within 
> distance 5, so can be used with sapply and lapply.
>
> Hope this helps,
>
> Roger



From giohappy at gmail.com  Thu Jan 31 19:35:08 2008
From: giohappy at gmail.com (G. Allegri)
Date: Thu, 31 Jan 2008 19:35:08 +0100
Subject: [R-sig-Geo] spatial regression with generalized least squares
Message-ID: <e12429640801311035s68e05849x70fa6aa9cbe0146d@mail.gmail.com>

I have a question about using GLS estimation within the Regression
Kriging framework.
In Rossiter and Hengl texts it is stated that it makes not so much
difference, in many practical situations, using OLS rather then GLS.
I'd like to test it in my work.
What's the more feasible way to adobt it in R?
The RK method suggests to use iteratively the regression coefficient
estimates using the covariance matrix derived from the residual
covariance modelling.

1 - How to automate this iteration scheme? I'm not so expert in R scripting...
2 - Could gls, from the nlme package, be used?

Giovanni



