From roland.kaiser at sbg.ac.at  Fri Feb  1 00:19:03 2008
From: roland.kaiser at sbg.ac.at (Roland Kaiser)
Date: Fri, 1 Feb 2008 00:19:03 +0100
Subject: [R-sig-Geo] png() and pdf() alignment problems
Message-ID: <023849A8-923A-4234-AF78-631659AF0558@sbg.ac.at>

Hi all!

My aim is to print a thematic map containing
vector output and an image backdrop (six orthophoto tiles).
The size of one image tile is 2500 rows and 2500 columns.
The are six tiles to be printed.

Of course this is far to much for sending the job to a pdf() device.
The raster image would consist of 37500000 squares,
each representing a raster cell.

So my a attempt was to separate vector and image output,
and overlay it afterwards.

Doing so I found that png() and pdf() do not register corectly.

The following script shows that a custom device size (not square)
can be responsible for the missing preccesion.

require(grDevices)
x <- y <- seq(-4*pi, 4*pi, len=27)
r <- sqrt(outer(x^2, y^2, "+"))
z <- cos(r^2)*exp(-r/6), col=gray((0:32)/32)

# example1
# standard device size
pdf("pdf_fit.pdf")
image(z)
dev.off()
png("png_fit.png", res = 96)
image(z)
dev.off()

# both files overlay with high precision
# as known from R grtaphics output
# see attached example example1.pdf

# example2
# custom device size
pdf("pdf.pdf", width = 8, height = 4)
image(z)
dev.off()
png("png.png", width = 8, height = 4, units = "in", res = 96)
image(z)
dev.off()

# png output is somewhat larger
# and aligning them is a bit nasty
# see attached example example2.pdf

I attached the two files
showing the overlay of the examples above.

Is there anything I'm missing?

Thanks for any advice,

Roland
-------------- next part --------------
A non-text attachment was scrubbed...
Name: example1.pdf
Type: application/pdf
Size: 65735 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080201/4a7928d7/attachment.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: example2.pdf
Type: application/pdf
Size: 56994 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080201/4a7928d7/attachment-0001.pdf>

From adrian at maths.uwa.edu.au  Fri Feb  1 04:45:27 2008
From: adrian at maths.uwa.edu.au (adrian at maths.uwa.edu.au)
Date: Fri, 1 Feb 2008 12:45:27 +0900 (WST)
Subject: [R-sig-Geo] memory limitations to markstat
Message-ID: <59713.130.95.98.17.1201837527.squirrel@130.95.98.17>

Ian Robertson <igr at stanford.edu> writes:

> I have been running into memory-related problems trying to use markstat
> (with 'table' as its supplied function) to assemble tabulations of
> categorical marks within fixed distances around about 5000 points.
> Experimenting with random data suggests that my default memory settings
> allow markstat to handle around 3200 points. At 3225 points, I get the
> message "Error: cannot allocate vector of size 317.4 Mb". Does anyone
> know what vector R is trying to store? Can anyone suggest a work around?

>I imagine that the various K-function tools in spatstat have to be
> making tabulations similar to what I have attempted to do with markstat.
> I have experimented with Kdot, forcing it to do a similar amount of work
> by making all the marks the same. Kdot can handle at least 5000 points
> (but not 5500) but since it doesn't return any mark-tabulations, I don't
> think it will help me.

We're talking about the package 'spatstat'.

Although `markstat' and the K-function tools (Kest, Kdot, Kcross etc)
perform somewhat similar calculations, they are based on different
objectives. The K-function tools are designed to calculate a specific
summary of the r-neighbourhood (the points within distance r of the
current point) for ALL values of r. On the other hand 'markstat' is
designed to calculate ANY summary of the r-neighbourhood for a FIXED value
of r.
Also the K-functions are designed for speed while `markstat' is
designed for complete flexibility (the desired summary operation to be
applied to each r-neighbourhood can be specified by an R function). The
K-functions use C code routines to identify the r-neighbourhoods and
fairly efficient code (Kest has been tested on patterns of 1 million
points). `markstat' creates a huge n x n matrix of all pairwise distances,
and uses `apply' to compute the desired summary values.

> Here's some illustrative code:
> library(spatstat)
> npoints <- 3200 #works
> #npoints <- 3225 #fails
> east <- runif(npoints, 1, 100)
> north <- runif(npoints, 1, 100)
> mark <- ceiling(runif(npoints, 0, 4))
> ppo1 <- ppp(east, north, c(0, 100), c(0, 100), marks=factor(mark))
> mTab <- markstat(ppo1, R=5, table, exclude=T)

If I understand correctly, you want to generate a large table in which the
columns represent the points in the data pattern, the rows represent the
possible mark values, and the entries are frequencies. Thus a column with
entries 0, 2, 1, 0 means that there were 2 points with mark = 2 and 1
point with mark=3 in the r-neighbourhood of the point in question.

The nearest existing equivalent in spatstat is Kcross (at least this is
the function that has to compute how many points of type j there are
within an r-neighbourhood of each point).

I will implement a function `marktable' that does what you want, and add
it to the next version of spatstat (1.12-6) that should be released this
weekend.

regards
Adrian Baddeley



From igr at stanford.edu  Fri Feb  1 05:15:27 2008
From: igr at stanford.edu (Ian Robertson)
Date: Thu, 31 Jan 2008 20:15:27 -0800
Subject: [R-sig-Geo] memory limitations to markstat
In-Reply-To: <59713.130.95.98.17.1201837527.squirrel@130.95.98.17>
References: <59713.130.95.98.17.1201837527.squirrel@130.95.98.17>
Message-ID: <47A29CDF.6080309@stanford.edu>

Adrian, many thanks. A 'marktable' function, as you describe it, would 
do what I have been doing with the combination of markstat and 
table--but presumably on much larger sets of points. Sounds like a 
useful addition!

Cheers,

Ian Robertson

adrian at maths.uwa.edu.au wrote:
> If I understand correctly, you want to generate a large table in which the
> columns represent the points in the data pattern, the rows represent the
> possible mark values, and the entries are frequencies. Thus a column with
> entries 0, 2, 1, 0 means that there were 2 points with mark = 2 and 1
> point with mark=3 in the r-neighbourhood of the point in question.
>
> The nearest existing equivalent in spatstat is Kcross (at least this is
> the function that has to compute how many points of type j there are
> within an r-neighbourhood of each point).
>
> I will implement a function `marktable' that does what you want, and add
> it to the next version of spatstat (1.12-6) that should be released this
> weekend.
>
> regards
> Adrian Baddeley
>



From adrian at maths.uwa.edu.au  Fri Feb  1 05:44:42 2008
From: adrian at maths.uwa.edu.au (adrian at maths.uwa.edu.au)
Date: Fri, 1 Feb 2008 13:44:42 +0900 (WST)
Subject: [R-sig-Geo] marktable function
In-Reply-To: <mailman.11.1201777202.8726.r-sig-geo@stat.math.ethz.ch>
References: <mailman.11.1201777202.8726.r-sig-geo@stat.math.ethz.ch>
Message-ID: <38657.130.95.98.17.1201841082.squirrel@130.95.98.17>

Here's a function that tabulates, for each point in a multitype point
pattern, the number of other points of each type within an R-neighbourhood
of the current point.

require(spatstat)

marktable <- function(X,R) {
    verifyclass(X, "ppp")
    stopifnot(is.marked(X))
    npoints <- X$n
    m <- marks(X)
    p <- closepairs(X, R)
    i <- factor(p$i, levels=1:npoints))
    mj <- m[p$j]
    table(point=i, mark=mj)
}

I've tested it on a pattern of 10,000 points in the unit square with
neighbourhood radius R = 0.1, giving an average of 314 neighbours for each
point (i.e. a total of 3.14 million pairs to be counted). It runs out of
space when the number of pairs to be counted exceeds about 10 million.

This function will be added to the next release of spatstat (1.12-6)

Adrian Baddeley



From loecher at eden.rutgers.edu  Fri Feb  1 19:45:24 2008
From: loecher at eden.rutgers.edu (Markus Loecher)
Date: Fri, 1 Feb 2008 13:45:24 -0500 (EST)
Subject: [R-sig-Geo] maximum empty rectangle within polygon
Message-ID: <24018569.39711201891521226.JavaMail.tomcat@terraza>

Dear all,
excuse me if this question has been asked before (I actually did not find a searchable interface for the sig-geo archives).
Is there an R function that computes the largest rectangle that "fits" into a given polygon ?
This is a bit the dual of the (much easier) problem of computing the MBR (minimum bounding rectangle)

Thanks !

Markus



From Roger.Bivand at nhh.no  Fri Feb  1 20:14:46 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 1 Feb 2008 20:14:46 +0100 (CET)
Subject: [R-sig-Geo] maximum empty rectangle within polygon
In-Reply-To: <24018569.39711201891521226.JavaMail.tomcat@terraza>
References: <24018569.39711201891521226.JavaMail.tomcat@terraza>
Message-ID: <Pine.LNX.4.64.0802012006450.4633@reclus.nhh.no>

On Fri, 1 Feb 2008, Markus Loecher wrote:

> Dear all, excuse me if this question has been asked before (I actually 
> did not find a searchable interface for the sig-geo archives).

Using RSiteSearch(), or going to http://finzi.psych.upenn.edu/search.html 
searches the R-sig-geo list archives.

> Is there an R function that computes the largest rectangle that "fits" 
> into a given polygon ? This is a bit the dual of the (much easier) 
> problem of computing the MBR (minimum bounding rectangle)
>

I guess you are thinking of a rectangle aligned on the coordinate system 
axes? As far as I know, nothing there, although looking at the wide range 
of functions found in spatstat might reveal something.

Roger

> Thanks !
>
> Markus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From adrian at maths.uwa.edu.au  Mon Feb  4 08:43:20 2008
From: adrian at maths.uwa.edu.au (adrian at maths.uwa.edu.au)
Date: Mon, 4 Feb 2008 16:43:20 +0900 (WST)
Subject: [R-sig-Geo] distances between polygons
Message-ID: <54281.130.95.98.17.1202111000.squirrel@130.95.98.17>


Didier Leibovici <didier.leibovici at nottingham.ac.uk> wrote:

> Subject: [R-sig-Geo] sp basics !
> I would like to read some shapefiles of polygons( I know how to do that)
> and loop through all the polygons to be able to compute the shortest
> distance to one another (fix) polygon
> e.g. distance to the sea or to a montain
> -I had at one point a polylist but probably I need to have "consistant"
> polygon for each element of the list ?
> -is there any distance method supported by a class "polygon" which can
> compute the distance to another geometry?

This is possible in package 'spatstat' version 1.12-6 (just released; not
yet on CRAN).

First convert your polygons to lists of edges (objects of class "psp") in
spatstat. Then use
         D <- crossdist.psp(A, B, type="separation")
to compute the matrix of shortest distances between an edge in list A and
an edge in list B. Finally take the minimum of the non-diagonal entries in
the matrix D
         diag(D) <- Inf
         dmin <- min(D)
to determine the shortest distance from polygon A to polygon B.

Adrian Baddeley



From rduarte at ipimar.pt  Mon Feb  4 12:23:08 2008
From: rduarte at ipimar.pt (Rafael Duarte)
Date: Mon, 04 Feb 2008 11:23:08 +0000
Subject: [R-sig-Geo] Subsetting shapefile type PolyLine
Message-ID: <47A6F59C.6000607@ipimar.pt>

Dear all,

I am very new to SIG.
This is probably a very simple question but I could not find an answer 
searching the web and the R-SIG emails archive.

I have an ESRI shapefile with a coast and bathymetric lines. In the dbf 
file I have a column ?ELEVATION? that gives this information.

I import the shapefile with:

require(maptools)
teste2 <- read.shape("bat_lin")
Shapefile type: PolyLine, (3), # of Shapes: 981

Now I plot this information:
plot(teste2)

But my problem is that I want to plot a subset of bathymetric lines: 
ELEVATION = 100, for example.

I tried to follow the example given in maptools: subset.
I tried to use functions: Map2lines.
But I could not find a solution to plot only a subset of bathymetric lines.

Many thanks for any help.

Rafael


-- 
Rafael Duarte
Marine Resources Department - DRM
IPIMAR -  National Research Institute for Agriculture and Fisheries
Av. Bras?lia, 1449-006 Lisbon  -  Portugal
Tel:+351 21 302 7000      Fax:+351 21 301 5948
e-mail: rduarte at ipimar.pt



From a.bevan at ucl.ac.uk  Mon Feb  4 13:16:07 2008
From: a.bevan at ucl.ac.uk (Andrew Bevan)
Date: Mon, 4 Feb 2008 12:16:07 +0000
Subject: [R-sig-Geo] block kriging of skewed distributions
Message-ID: <4A1E151B-CD50-4928-8662-5A9348427186@ucl.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080204/8127e4e2/attachment.pl>

From vkepoglu at gmail.com  Mon Feb  4 15:04:10 2008
From: vkepoglu at gmail.com (volkan kepoglu)
Date: Mon, 4 Feb 2008 16:04:10 +0200
Subject: [R-sig-Geo] R to Python - rpy - definition of window pattern,
	related with 'spatstat library - help needed
Message-ID: <8b5938320802040604u1e191cc1r758396a912535e25@mail.gmail.com>

I am new in R and Python. I write a couple of lines. The code does the
followings; Read point shp file, Compute a kernel smoothed intensity
function from a point pattern; density function, and convert pixel
image to spatialgriddataframe and export spatialgriddataframe to tif
raster format.

the code is running in R. I am trying to use the code in python, but
could not. Could you help me?

my original R code;

library(maptools)
shpPoint <- readShapePoints ("exmPnt.shp")
library(spatstat)
w <- as.owin(c((shpPoint at bbox["coords.x1","min"]),
(shpPoint at bbox["coords.x1","max"]),
(shpPoint at bbox["coords.x2","min"]),
(shpPoint at bbox["coords.x2","max"])))
MYpppFormat <- as.ppp(shpPoint at coords, w)
z <- density.ppp(MYpppFormat, edge=TRUE)
plot(z, main="Kernel smoothed intensity of point pattern")
plot(shpPoint, add=TRUE)
z_sgdf <- as.SpatialGridDataFrame.im(z)
outfilename <- tempfile(pattern="file", tmpdir = tempdir())
writeGDAL(z_sgdf, outfilename, drivername = "GTiff")
file.rename (outfilename, "exmPnt_density.tif")

conversion of R code to Python with Rpy;

from rpy import *
r.library('maptools')
shpPoint = r.readShapePoints ("exmPnt.shp")
r.library('spatstat')

# rest of them could not be converted to Rpy
w = r.as_owin(r.c((r.bbox(shpPoint)["coords.x1","min"]),
(r.bbox(shpPoint)["coords.x1","max"]),
(r.bbox(shpPoint)["coords.x2","min"]),
(r.bbox(shpPoint)["coords.x2","max"])))
MYpppFormat = r.as_ppp(shpPoint at coords, w)

# possible conversion, not tried.
z = r.density_ppp(MYpppFormat, edge=TRUE)
r.plot(z, main="Kernel smoothed intensity of point pattern")
r.plot(shpPoint, add=TRUE)
z_sgdf = r.as_SpatialGridDataFrame_im(z)
r.library('rgdal')
outfilename = r.tempfile(pattern="file", tmpdir = r.tempdir())
r.writeGDAL(z_sgdf, outfilename, drivername = "GTiff")
r.file.rename (outfilename, "exmPnt_density.tif")

IN R, working;
> w <- as.owin(c((shpPoint at bbox["coords.x1","min"]), (shpPoint at bbox["coords.x1","max"]), (shpPoint at bbox["coords.x2","min"]), (shpPoint at bbox["coords.x2","max"])))
> w
window: rectangle = [575490, 619430] x [4890400, 4934800] units

IN PYTHON, giving the following error;
>>> set_default_mode(NO_CONVERSION)
>>> w = r.as_owin(r.cbind((r.bbox(shpPoint)["coords.x1","min"]),
(r.bbox(shpPoint)["coords.x1","max"]),
(r.bbox(shpPoint)["coords.x2","min"]),
(r.bbox(shpPoint)["coords.x2","max"])))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: sequence index must be integer, not 'tuple'
>>> set_default_mode(BASIC_CONVERSION)
>>> w = r.as_owin(r.cbind((r.bbox(shpPoint)["coords.x1","min"]),
(r.bbox(shpPoint)["coords.x1","max"]),
(r.bbox(shpPoint)["coords.x2","min"]),
(r.bbox(shpPoint)["coords.x2","max"])))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
IndexError: each subindex must be either a slice, an integer,
Ellipsis, or NewAxis
>>>

What should I do?

Thanks,
Volkan Kepoglu
PHD Candidate,
Department of GGIT in METU,
Ankara, Turkey.



From milton_ruser at yahoo.com.br  Mon Feb  4 15:33:56 2008
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Mon, 4 Feb 2008 06:33:56 -0800 (PST)
Subject: [R-sig-Geo] Res:  Subsetting shapefile type PolyLine
Message-ID: <989925.75557.qm@web56008.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080204/44620e5d/attachment.pl>

From Roger.Bivand at nhh.no  Mon Feb  4 15:44:54 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 4 Feb 2008 15:44:54 +0100 (CET)
Subject: [R-sig-Geo] R to Python - rpy - definition of window pattern,
 related with 'spatstat library - help needed
In-Reply-To: <8b5938320802040604u1e191cc1r758396a912535e25@mail.gmail.com>
References: <8b5938320802040604u1e191cc1r758396a912535e25@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0802041517550.7596@reclus.nhh.no>

On Mon, 4 Feb 2008, volkan kepoglu wrote:

> I am new in R and Python. I write a couple of lines. The code does the
> followings; Read point shp file, Compute a kernel smoothed intensity
> function from a point pattern; density function, and convert pixel
> image to spatialgriddataframe and export spatialgriddataframe to tif
> raster format.
>
> the code is running in R. I am trying to use the code in python, but
> could not. Could you help me?

Cross-posting isn't a brilliant idea, by the way. I'm only replying to the 
R-sig-geo list; please summarise separately to other lists that you 
included to close the threads in a responsible way.

Do as much as possible on the R side, do not try to cross the R/python 
interface with anything other than very simple objects (scalar, numeric 
vector), unless you really enjoy debugging (and since you are writing to 
multiple lists, you probably don't enjoy debugging). Just keep things very 
simple!

>
> my original R code;

was not optimal anyway. Please use a canned file for your example:

library(maptools)
shpPoint <- readShapePoints(system.file("shapes/baltim.shp",
   package="maptools")[1])
bbox(shpPoint)
library(spatstat)
MYpppFormat <- as(shpPoint["STATION"], "ppp")
summary(MYpppFormat)
# note that window matches bounding box
z <- density.ppp(MYpppFormat)
# consider setting the bandwidth
z_sgdf <- as(z, "SpatialGridDataFrame")
outfilename <- paste(tempdir(), "exmPnt_density.tif",
   sep=.Platform$file.sep)
library(rgdal)
writeGDAL(z_sgdf, outfilename, drivername = "GTiff")

The only things that need to go over the interface are the input shapefile 
and output GTiff names, and possibly the bandwidth sigma. Try first as an 
os.system() call to a script running R, and move towards integrating 
tighter things that can be moved across the interface without falling 
over. I have a feeling that

shpPoint = r.readShapePoints ("exmPnt.shp")

has lost its class when it goes back across. I'm afraid you may get into a 
lot of r.assign() and r.get(). Best write a wrapper function taking the 
things you can pass, and leave everything else on the R side.

If anyone has implemented reflected sp objects in python, please say so!

Roger

>
> library(maptools)
> shpPoint <- readShapePoints ("exmPnt.shp")
> library(spatstat)
> w <- as.owin(c((shpPoint at bbox["coords.x1","min"]),
> (shpPoint at bbox["coords.x1","max"]),
> (shpPoint at bbox["coords.x2","min"]),
> (shpPoint at bbox["coords.x2","max"])))
> MYpppFormat <- as.ppp(shpPoint at coords, w)
> z <- density.ppp(MYpppFormat, edge=TRUE)
> plot(z, main="Kernel smoothed intensity of point pattern")
> plot(shpPoint, add=TRUE)
> z_sgdf <- as.SpatialGridDataFrame.im(z)
> outfilename <- tempfile(pattern="file", tmpdir = tempdir())
> writeGDAL(z_sgdf, outfilename, drivername = "GTiff")
> file.rename (outfilename, "exmPnt_density.tif")
>
> conversion of R code to Python with Rpy;
>
> from rpy import *
> r.library('maptools')
> shpPoint = r.readShapePoints ("exmPnt.shp")
> r.library('spatstat')
>
> # rest of them could not be converted to Rpy
> w = r.as_owin(r.c((r.bbox(shpPoint)["coords.x1","min"]),
> (r.bbox(shpPoint)["coords.x1","max"]),
> (r.bbox(shpPoint)["coords.x2","min"]),
> (r.bbox(shpPoint)["coords.x2","max"])))
> MYpppFormat = r.as_ppp(shpPoint at coords, w)
>
> # possible conversion, not tried.
> z = r.density_ppp(MYpppFormat, edge=TRUE)
> r.plot(z, main="Kernel smoothed intensity of point pattern")
> r.plot(shpPoint, add=TRUE)
> z_sgdf = r.as_SpatialGridDataFrame_im(z)
> r.library('rgdal')
> outfilename = r.tempfile(pattern="file", tmpdir = r.tempdir())
> r.writeGDAL(z_sgdf, outfilename, drivername = "GTiff")
> r.file.rename (outfilename, "exmPnt_density.tif")
>
> IN R, working;
>> w <- as.owin(c((shpPoint at bbox["coords.x1","min"]), (shpPoint at bbox["coords.x1","max"]), (shpPoint at bbox["coords.x2","min"]), (shpPoint at bbox["coords.x2","max"])))
>> w
> window: rectangle = [575490, 619430] x [4890400, 4934800] units
>
> IN PYTHON, giving the following error;
>>>> set_default_mode(NO_CONVERSION)
>>>> w = r.as_owin(r.cbind((r.bbox(shpPoint)["coords.x1","min"]),
> (r.bbox(shpPoint)["coords.x1","max"]),
> (r.bbox(shpPoint)["coords.x2","min"]),
> (r.bbox(shpPoint)["coords.x2","max"])))
> Traceback (most recent call last):
>  File "<stdin>", line 1, in <module>
> TypeError: sequence index must be integer, not 'tuple'
>>>> set_default_mode(BASIC_CONVERSION)
>>>> w = r.as_owin(r.cbind((r.bbox(shpPoint)["coords.x1","min"]),
> (r.bbox(shpPoint)["coords.x1","max"]),
> (r.bbox(shpPoint)["coords.x2","min"]),
> (r.bbox(shpPoint)["coords.x2","max"])))
> Traceback (most recent call last):
>  File "<stdin>", line 1, in <module>
> IndexError: each subindex must be either a slice, an integer,
> Ellipsis, or NewAxis
>>>>
>
> What should I do?
>
> Thanks,
> Volkan Kepoglu
> PHD Candidate,
> Department of GGIT in METU,
> Ankara, Turkey.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From rduarte at ipimar.pt  Mon Feb  4 16:34:02 2008
From: rduarte at ipimar.pt (Rafael Duarte)
Date: Mon, 04 Feb 2008 15:34:02 +0000
Subject: [R-sig-Geo] Res:  Subsetting shapefile type PolyLine
In-Reply-To: <989925.75557.qm@web56008.mail.re3.yahoo.com>
References: <989925.75557.qm@web56008.mail.re3.yahoo.com>
Message-ID: <47A7306A.8020301@ipimar.pt>

Obrigado Milton.

But:
teste2[teste2$ELEVATION == 100]

gives me an empty list. And I have data of Elevation = 100.

I also tried
teste2[teste2$ELEVATION >= 100]

teste2[teste2$ELEVATION == "100"]

But always an empty list and no plot.










Milton Cezar Ribeiro wrote:

> Hi Rafael
> i think that it could help you
> teste2.elev100<-teste2[teste2$ELEVATION=100]
> plot(teste2,axes=T)
> plot(teste2.elev100,col=2,add=T)
> Boa sorte.
> Miltinho
> Brazil
> ----- Mensagem original ----
> De: Rafael Duarte <rduarte at ipimar.pt>
> Para: r-sig-geo at stat.math.ethz.ch
> Enviadas: Segunda-feira, 4 de Fevereiro de 2008 8:23:08
> Assunto: [R-sig-Geo] Subsetting shapefile type PolyLine
>
> Dear all,
>
> I am very new to SIG.
> This is probably a very simple question but I could not find an answer
> searching the web and the R-SIG emails archive.
>
> I have an ESRI shapefile with a coast and bathymetric lines. In the dbf
> file I have a column ?ELEVATION? that gives this information.
>
> I import the shapefile with:
>
> require(maptools)
> teste2 <- read.shape("bat_lin")
> Shapefile type: PolyLine, (3), # of Shapes: 981
>
> Now I plot this information:
> plot(teste2)
>
> But my problem is that I want to plot a subset of bathymetric lines:
> ELEVATION = 100, for example.
>
> I tried to follow the example given in maptools: subset.
> I tried to use functions: Map2lines.
> But I could not find a solution to plot only a subset of bathymetric 
> lines.
>
> Many thanks for any help.
>
> Rafael
>
>
> -- 
> Rafael Duarte
> Marine Resources Department - DRM
> IPIMAR - National Research Institute for Agriculture and Fisheries
> Av. Bras?lia, 1449-006 Lisbon - Portugal
> Tel:+351 21 302 7000 Fax:+351 21 301 5948
> e-mail: rduarte at ipimar.pt <mailto:rduarte at ipimar.pt>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch <mailto:R-sig-Geo at stat.math.ethz.ch>
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> ------------------------------------------------------------------------
> Abra sua conta no Yahoo! Mail 
> <http://br.rd.yahoo.com/mail/taglines/mail/*http://br.mail.yahoo.com/>, 
> o ?nico sem limite de espa?o para armazenamento!



From Roger.Bivand at nhh.no  Mon Feb  4 18:26:18 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 4 Feb 2008 18:26:18 +0100 (CET)
Subject: [R-sig-Geo] Res:  Subsetting shapefile type PolyLine
In-Reply-To: <47A7306A.8020301@ipimar.pt>
References: <989925.75557.qm@web56008.mail.re3.yahoo.com>
	<47A7306A.8020301@ipimar.pt>
Message-ID: <Pine.LNX.4.64.0802041643020.7596@reclus.nhh.no>

On Mon, 4 Feb 2008, Rafael Duarte wrote:

> Obrigado Milton.
>
> But:
> teste2[teste2$ELEVATION == 100]
>
> gives me an empty list. And I have data of Elevation = 100.
>
> I also tried
> teste2[teste2$ELEVATION >= 100]
>
> teste2[teste2$ELEVATION == "100"]
>
> But always an empty list and no plot.
>

Very close, with:

getinfo.shape("bat_lin")
teste2 <- readShapeLines("bat_lin")

names(teste2)

should show ELEVATION - then the help should also work. I think that the 
original teste2 would say that its class() was "Map" - for the selection 
with [ to work, it should be a SpatialLinesDataFrame.

read.shape is part of the infrastructure, and users are really advised to 
move to sp classes, and either readShape*(), or (even better) readOGR() in 
the rgdal package, for which you don't need to know in advance what kind 
of shapefile you are reading.

Hope this helps,

Roger

>
>
> Milton Cezar Ribeiro wrote:
>
>> Hi Rafael
>> i think that it could help you
>> teste2.elev100<-teste2[teste2$ELEVATION=100]
>> plot(teste2,axes=T)
>> plot(teste2.elev100,col=2,add=T)
>> Boa sorte.
>> Miltinho
>> Brazil
>> ----- Mensagem original ----
>> De: Rafael Duarte <rduarte at ipimar.pt>
>> Para: r-sig-geo at stat.math.ethz.ch
>> Enviadas: Segunda-feira, 4 de Fevereiro de 2008 8:23:08
>> Assunto: [R-sig-Geo] Subsetting shapefile type PolyLine
>>
>> Dear all,
>>
>> I am very new to SIG.
>> This is probably a very simple question but I could not find an answer
>> searching the web and the R-SIG emails archive.
>>
>> I have an ESRI shapefile with a coast and bathymetric lines. In the dbf
>> file I have a column ?ELEVATION? that gives this information.
>>
>> I import the shapefile with:
>>
>> require(maptools)
>> teste2 <- read.shape("bat_lin")
>> Shapefile type: PolyLine, (3), # of Shapes: 981
>>
>> Now I plot this information:
>> plot(teste2)
>>
>> But my problem is that I want to plot a subset of bathymetric lines:
>> ELEVATION = 100, for example.
>>
>> I tried to follow the example given in maptools: subset.
>> I tried to use functions: Map2lines.
>> But I could not find a solution to plot only a subset of bathymetric
>> lines.
>>
>> Many thanks for any help.
>>
>> Rafael
>>
>>
>> --
>> Rafael Duarte
>> Marine Resources Department - DRM
>> IPIMAR - National Research Institute for Agriculture and Fisheries
>> Av. Bras?lia, 1449-006 Lisbon - Portugal
>> Tel:+351 21 302 7000 Fax:+351 21 301 5948
>> e-mail: rduarte at ipimar.pt <mailto:rduarte at ipimar.pt>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch <mailto:R-sig-Geo at stat.math.ethz.ch>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>> ------------------------------------------------------------------------
>> Abra sua conta no Yahoo! Mail
>> <http://br.rd.yahoo.com/mail/taglines/mail/*http://br.mail.yahoo.com/>,
>> o ?nico sem limite de espa?o para armazenamento!
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From amsantac at hotmail.com  Mon Feb  4 19:05:41 2008
From: amsantac at hotmail.com (=?iso-8859-1?Q?Al=ED_Santacruz?=)
Date: Mon, 4 Feb 2008 13:05:41 -0500
Subject: [R-sig-Geo] FYI: Merging GIS and statistics --- RSAGA
In-Reply-To: <001201c86320$708d4970$3a871291@pcibed193>
References: <001201c86320$708d4970$3a871291@pcibed193>
Message-ID: <BAY120-W29C2E140E80D0B647AD49AC9330@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080204/40fe44ca/attachment.pl>

From Roger.Bivand at nhh.no  Mon Feb  4 19:29:37 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 4 Feb 2008 19:29:37 +0100 (CET)
Subject: [R-sig-Geo] FYI: Merging GIS and statistics --- RSAGA
In-Reply-To: <BAY120-W29C2E140E80D0B647AD49AC9330@phx.gbl>
References: <001201c86320$708d4970$3a871291@pcibed193>
	<BAY120-W29C2E140E80D0B647AD49AC9330@phx.gbl>
Message-ID: <Pine.LNX.4.64.0802041915160.7596@reclus.nhh.no>

On Mon, 4 Feb 2008, Al? Santacruz wrote:

>
>
> Hi,
>
> I am trying to use the Grid Calculator in SAGA, through RSAGA but I have 
> problems with the parameter FORMUL,
>
> I can?t get the function "a/b" works,
>
> the functions "a+b", or "a-b", or "a*b" works, but "a/b" does not,
>
> Any help is appreciated,
>
> see the code below for the errors reported,
>
> thanks,
>
> Ali Santacruz
> M.Sc. Geomatics.
> National University of Colombia,
> Bogota, Colombia
> E-mail: amsantac at unal.edu.co
>
>
> ## this formula does not work:
>> rsaga.geoprocessor("grid_calculus", 1, 
>> list(INPUT="dem.sgrd;brillo.sgrd", RESULT="out2", 
>> FORMUL="a/b"))
>> C:\Users\geomatica\Desktop
>> C:\Users\geomatica\Documents\R\win-library\2.6\RSAGA\saga_vc\saga_cmd.exe
>> grid_calculus 1 -silent -INPUT dem.sgrd;brillo.sgrd -RESULT out2 
>> -FORMUL a\b
           ^^^^

A very smokey smoking gun, isn't it? The interface is converting all 
forward slash to backslash (Windows *does* respect forward slash in file 
path names, so this isn't strictly needed), so you'll have to try to 
escape the value until you see a/b coming through. I'm in doubt whether 
you'll have any luck, though:

...
     if (beep.off & .Platform$OS.type=="windows") {
         command = gsub("/","\\",command,fixed=TRUE)
                        ^^^^^^^^
         batch = c("net stop beep",command)
         batchfilename = paste(tempfile(),".bat",sep="")
         batchfile = file(batchfilename,"wt")
         writeLines(batch,con=batchfile)
         close(batchfile)
         command = batchfilename
     }
...

in R/RSAGA-core.R, which converts everything whether a file path or not.

Roger

PS. Is the RSAGA maintainer subscribed to this list?


> SAGA CMD 2.0
> Copyright (C) 2005 by Olaf Conradunder GNU General Public License (GPL)library path:   C:/Users/geomatica/Documents/R/win-library/2.6/RSAGA/saga_vc/moduleslibrary name:   grid_calculusmodule name:    Grid Calculator
> Load grid: dem.sgrd...
> Load grid: brillo.sgrd...
> Parameters:[Grid system] Grid system: 0.008462; 1506x 1585y; -79.300459x -4.492490y[Grid list] Grids: 2 objects (dem.sgrd, brillo.sgrd))[Grid] Result: new[Text] Formula: a\bError at character #0 of the function: a\b
>
> function not found
> error: executing module [Grid Calculator]
>
> # this formula does not work either:
>> rsaga.geoprocessor("grid_calculus", 1, list(INPUT="dem.sgrd;brillo.sgrd", RESULT="out2", FORMUL="a\b"))
> C:\Users\geomatica\Desktop>C:\Users\geomatica\Documents\R\win-library\2.6\RSAGA\saga_vc\saga_cmd.exe grid_calculus 1 -silent -INPUT dem.sgrd;brillo.sgrd -RESULT out2 -FORMUL
> SAGA CMD 2.0
> Copyright (C) 2005 by Olaf Conradunder GNU General Public License (GPL)library path:   C:/Users/geomatica/Documents/R/win-library/2.6/RSAGA/saga_vc/moduleslibrary name:   grid_calculusmodule name:    Grid Calculator
> Load grid: dem.sgrd...
> Load grid: brillo.sgrd...
> Parameters:[Grid system] Grid system: 0.008462; 1506x 1585y; -79.300459x -4.492490y[Grid list] Grids: 2 objects (dem.sgrd, brillo.sgrd))[Grid] Result: new[Text] Formula: Error at character #0 of the function:
>
> function not found
> error: executing module [Grid Calculator]
>
>
> # this formula works:
>
>> rsaga.geoprocessor("grid_calculus", 1, list(INPUT="dem.sgrd;brillo.sgrd", RESULT="out2", FORMUL="a+b"))C:\Users\geomatica\Desktop>C:\Users\geomatica\Documents\R\win-library\2.6\RSAGA\saga_vc\saga_cmd.exe grid_calculus 1 -silent -INPUT dem.sgrd;brillo.sgrd -RESULT out2 -FORMUL a+b
> SAGA CMD 2.0
> Copyright (C) 2005 by Olaf Conradunder GNU General Public License (GPL)library path:   C:/Users/geomatica/Documents/R/win-library/2.6/RSAGA/saga_vc/moduleslibrary name:   grid_calculusmodule name:    Grid Calculator
> Load grid: dem.sgrd...
> Load grid: brillo.sgrd...
> Parameters:[Grid system] Grid system: 0.008462; 1506x 1585y; -79.300459x -4.492490y[Grid list] Grids: 2 objects (dem.sgrd, brillo.sgrd))[Grid] Result: new[Text] Formula: a+bSave grid: out2...
>
>> rsaga.geoprocessor("grid_calculus", 1, list(INPUT="dem.sgrd;brillo.sgrd", RESULT="out2"))C:\Users\geomatica\Desktop>C:\Users\geomatica\Documents\R\win-library\2.6\RSAGA\saga_vc\saga_cmd.exe grid_calculus 1 -silent -INPUT dem.sgrd;brillo.sgrd -RESULT out2
> SAGA CMD 2.0
> Copyright (C) 2005 by Olaf Conradunder GNU General Public License (GPL)library path:   C:/Users/geomatica/Documents/R/win-library/2.6/RSAGA/saga_vc/moduleslibrary name:   grid_calculusmodule name:    Grid Calculator
> Load grid: dem.sgrd...
> Load grid: brillo.sgrd...
> Parameters:[Grid system] Grid system: 0.008462; 1506x 1585y; -79.300459x -4.492490y[Grid list] Grids: 2 objects (dem.sgrd, brillo.sgrd))[Grid] Result: new[Text] Formula: (a - b) / (a + b)Save grid: out2...
>
>
>> sessionInfo()R version 2.6.1 (2007-11-26) i386-pc-mingw32
> locale:LC_COLLATE=Spanish_Colombia.1252;LC_CTYPE=Spanish_Colombia.1252;LC_MONETARY=Spanish_Colombia.1252;LC_NUMERIC=C;LC_TIME=Spanish_Colombia.1252
> attached base packages:[1] stats     graphics  grDevices utils     datasets  methods   base
> other attached packages:[1] RSAGA_0.9-1
> loaded via a namespace (and not attached):[1] rcompgen_0.1-17 tools_2.6.1
>
>> From: hengl at science.uva.nl> To: r-sig-geo at stat.math.ethz.ch> Date: Wed, 30 Jan 2008 10:13:55 +0100> Subject: [R-sig-Geo] FYI: Merging GIS and statistics --- RSAGA> > > > Dear all,> > I just started running analysis with the RSAGA package> (http://cran.r-project.org/src/contrib/Descriptions/RSAGA.html), i.e. the R scripting link to SAGA> GIS (by Olaf Conrad and colleagues, over 120 modules), that was suggested to me by Paulo van Breugel> and I think that this could really be the missing link between statistics and GIS. My experiences so> far are very positive --- especially if you work with large grids, because SAGA is quite fast for> calculations. Here are some examples from Geomorphometry / Digital Soil Mapping:> > 0. Getting started:> > ****************************************************************************> # Download the SAGA 2.0.1 binaries (http://sourceforge.net/projects/saga-gis/) and unzip them to a> local directory e.g. "C:/Progra~1/saga_vc"; # Start R and install the RSAGA package; # load the> library and set the directory where the SAGA binaries sit:> > library(RSAGA)> rsaga.env(path="C:/Progra~1/saga_vc")> > # To get the exact names of parameters look for a name in the "/modules" directory and then use:> > rsaga.get.modules("geostatistics_kriging")> rsaga.get.usage("geostatistics_kriging", 2)> > ****************************************************************************> > 1. Error propagation and geomorphometry (both can be run via R now):> > ****************************************************************************> > # Import the point measurements of heights to generate a DEM:> > elevations <- read.delim("elevations.txt") coordinates(elevations)=~X+Y> spplot(elevations)> > # Import the grid definition:> > gridmaps = readGDAL("SMU1.asc")> gridmaps$SMU1 = gridmaps$band1> > # Derive area in km^2:> > maparea => (gridmaps at bbox["x","max"]-gridmaps at bbox["x","min"])*(gridmaps at bbox["y","max"]-gridmaps at bbox["y","min> "])/1e+06> > # Fit a variogram for elevations and produce 50 realizations of a DEM using Sequential Gaussian> Simulations:> > elevations.or = variogram(Z~1, elevations) > elevations.ovgm = fit.variogram(elevations.or, vgm(1, "Sph", 1000, 1)) > plot(elevations.or, elevations.ovgm, plot.nu=F, pch="+")> > DEM.sim = krige(Z~1, elevations, gridmaps, elevations.ovgm, nmax=40, nsim=50)> > # Visualize the simulated DEMs in R:> > for (i in 1:length(DEM.sim at data)) {> image(as.image.SpatialGridDataFrame(DEM.sim[i]), col=terrain.colors(16), asp=1) }> > # Write the simulated DEMs in ArcInfo ASCII format:> > for (i in 1:length(DEM.sim at data)) {> write.asciigrid(DEM.sim[i], c(paste("DEM",as.character(i),".asc",sep="")))> }> > # Now, derive SLOPE maps in SAGA 50 times:> # ESRI wrapper is used to get the maps directly in ArcInfo ASCII format;> > for (i in 1:length(DEM.sim at data)) {> rsaga.esri.wrapper(rsaga.slope, method="poly2zevenbergen",> in.dem=c(paste("DEM",as.character(i),sep="")), out.slope=c(paste("SLOPE",as.character(i),sep="")),> prec=3, condensed.res=FALSE, intern=FALSE, show.output.on.console=FALSE) }> > # Optional: generate a DEM using the Thin Plate Spline (local) interpolation in SAGA:> > writeOGR(elevations, "elevations.shp", "elevations", "ESRI Shapefile") > > rsaga.get.usage("grid_spline", 1) rsaga.geoprocessor(lib="grid_spline", module=1,> param=list(GRID="DEMtps.sgrd", SHAPES="elevations.shp", FIELD=1, RADIUS=sqrt(maparea)*1000/3,> SELECT=1, MAXPOINTS=30, TARGET=2, GRID_GRID="DEM1.sgrd")) rsaga.sgrd.to.esri(in.sgrds="DEMtps.sgrd",> out.grids="DEMtps.asc", out.path="D:/GEOSTAT/maps/RSAGA", prec=1)> > > ****************************************************************************> > 2. Spatial interpolation > Especially suitable for large maps (R+gstat often fail due to memory limit problems):> > ****************************************************************************> # Export the predictors to SAGA format:> > predict.list = gl(n=9, k=1,> labels=c("DEM","SLOPE","PLANC","TWI","SINS","SMU1","SMU3","SMU4","SMU9"))> rsaga.esri.to.sgrd(in.grids=levels(predict.list),> out.sgrds=set.file.extension(levels(predict.list),".sgrd"), in.path="D:/GEOSTAT/maps/RSAGA")> > # predict values in SAGA using only regression model:> > rsaga.get.usage("geostatistics_grid", 4) rsaga.geoprocessor(lib="geostatistics_grid", module=4,> param=list(GRIDS="DEM.sgrd;SLOPE.sgrd;PLANC.sgrd;TWI.sgrd;SINS.sgrd;SMU1.sgrd;SMU3.sgrd;SMU4.sgrd;SM> U9.sgrd", SHAPES="baranja.shp", ATTRIBUTE=0, TABLE="regout.dbf", RESIDUAL="solum_res.shp",> REGRESSION="SOLUM_reg.sgrd", INTERPOL=0))> > # Ordinary kriging:> > rsaga.get.usage("geostatistics_kriging", 1) rsaga.geoprocessor(lib="geostatistics_kriging",> module=1, param=list(GRID="SOLUM_ok.sgrd", VARIANCE="SOLUM_okvar.sgrd", SHAPES="baranja.shp",> FIELD=0, MODEL=1, NUGGET=0, SILL=200, RANGE=500, TARGET=2, GRID_GRID="SLOPE.sgrd"))> > # Regression-kriging:> > rsaga.get.usage("geostatistics_kriging", 3) rsaga.geoprocessor(lib="geostatistics_kriging",> module=3,> param=list(GRIDS="DEM.sgrd;SLOPE.sgrd;PLANC.sgrd;TWI.sgrd;SINS.sgrd;SMU1.sgrd;SMU3.sgrd;SMU4.sgrd;SM> U9.sgrd", GRID="SOLUM_rk.sgrd", SHAPES="baranja.shp", FIELD=0, MODEL=1, NUGGET=0, SILL=200,> RANGE=500, INTERPOL=0)) > # Does not work yet. Possibly a bug in the saga_cmd.exe?> > ****************************************************************************> > The complete script and datasets are available at:> > http://spatial-analyst.net/GRK/examplesRSAGA.zip (400 KB)> > So the only real problem is the import/export from R to SAGA, which I guess could be solved very> easily if the next version of rgdal would support SAGA format.> > > Tom Hengl> http://spatial-analyst.net> > _______________________________________________> R-sig-Geo mailing list> R-sig-Geo at stat.math.ethz.ch> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> _________________________________________________________________
>
>
> e=wlmailtagline
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From milton_ruser at yahoo.com.br  Mon Feb  4 20:41:17 2008
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Mon, 4 Feb 2008 11:41:17 -0800 (PST)
Subject: [R-sig-Geo] converting shapefile/polygon to psp
Message-ID: <616925.46578.qm@web56009.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080204/48629bb4/attachment.pl>

From Roger.Bivand at nhh.no  Mon Feb  4 21:03:25 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 4 Feb 2008 21:03:25 +0100 (CET)
Subject: [R-sig-Geo] converting shapefile/polygon to psp
In-Reply-To: <616925.46578.qm@web56009.mail.re3.yahoo.com>
References: <616925.46578.qm@web56009.mail.re3.yahoo.com>
Message-ID: <Pine.LNX.4.64.0802042055170.7596@reclus.nhh.no>

On Mon, 4 Feb 2008, Milton Cezar Ribeiro wrote:

> Dear all,
>
> I have some shapefiles which contents are polygons and I would like to 
> convert it to psp (spatstat) format, and after run crossdist.psp. I 
> tryed several times without success. Any idea?

Look at the coercion function in maptools from SpatialPolygons to owin; 
see what needs to be changed to match psp; debug; contribute?

Note that touching polygons fail the topology test in spatstat, as they 
should. Seeing how a psp works should't be hard, it is effectively as 
described in:

https://stat.ethz.ch/pipermail/r-sig-geo/2008-January/003075

for making the lll matrix for distppll(), but as a data frame. You could 
use the marks to record which Polygons/Polygon object the segments belong 
to.

Roger

>
> Miltinho
>
>
>
> para armazenamento!
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From giohappy at gmail.com  Mon Feb  4 21:16:10 2008
From: giohappy at gmail.com (G. Allegri)
Date: Mon, 4 Feb 2008 21:16:10 +0100
Subject: [R-sig-Geo] R to Python - rpy - definition of window pattern,
	related with 'spatstat library - help needed
In-Reply-To: <Pine.LNX.4.64.0802041517550.7596@reclus.nhh.no>
References: <8b5938320802040604u1e191cc1r758396a912535e25@mail.gmail.com>
	<Pine.LNX.4.64.0802041517550.7596@reclus.nhh.no>
Message-ID: <e12429640802041216w380a28fbud58e62da7bdd682f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080204/4610f0f8/attachment.pl>

From milton_ruser at yahoo.com.br  Mon Feb  4 22:01:31 2008
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Mon, 4 Feb 2008 13:01:31 -0800 (PST)
Subject: [R-sig-Geo] Res:  converting shapefile/polygon to psp
Message-ID: <34295.57348.qm@web56015.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080204/d4613199/attachment.pl>

From Roger.Bivand at nhh.no  Mon Feb  4 22:26:40 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 4 Feb 2008 22:26:40 +0100 (CET)
Subject: [R-sig-Geo] Res:  converting shapefile/polygon to psp
In-Reply-To: <34295.57348.qm@web56015.mail.re3.yahoo.com>
References: <34295.57348.qm@web56015.mail.re3.yahoo.com>
Message-ID: <Pine.LNX.4.64.0802042220070.7596@reclus.nhh.no>

On Mon, 4 Feb 2008, Milton Cezar Ribeiro wrote:

> Dear Roger,

I am not sure if I really need to convert my polygons to psp format.

In fact I have a shapefile with polygons and a pair of points 
(x0,y0,x1,y1) and what I need is:
   (1) to checkout if the lines defined by (x0,y0,x1,y1) cross or not any
   polygon and (2) to identify which polygons were crossed by this line.

> I obtained these (x0,y0,x1,y1) coordinates by computing the shortest
> distance between all polygons pairwise. Now I need to eliminate the 
> "lines" which cross over polygons, and keep only those lines that "link" 
> polygons without a overlap relationship betteen lines and polygons.

If a rough-and-ready approximation is OK, start with unrolling the 
coordinates on the line and overlay them over the polygons:

library(maptools)
xx <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1],
   IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
plot(xx, axes=TRUE)
pt0 <- c(-84, 34)
pt1 <- c(-77, 37)
lines(rbind(pt0, pt1))
xl <- seq(pt0[1], pt1[1], length.out=250)
yl <- seq(pt0[2], pt1[2], length.out=250)
lines(xl, yl, col="red")
SP <- SpatialPoints(cbind(xl, yl))
io <- overlay(SP, xx)
iot <- unique(na.omit(io))
plot(xx, add=TRUE, col=c("transparent", "yellow")[(1:100 %in% iot)+1])
lines(xl, yl, col="red")

gets you something, and by increasing length.out, you can get more 
precision.

xx$NAME[iot]

lists the names too.

Hope this helps,

Roger


> I understand that it is a topological question, but I don?t know how to 
> deal it on sp/maptools.

> Case you have other ideas, please, let me know.

Regards a lot,

miltinho


----- Mensagem original ----
De: Roger Bivand <Roger.Bivand at nhh.no>
Para: Milton Cezar Ribeiro <milton_ruser at yahoo.com.br>
Cc: r-sig-geo at stat.math.ethz.ch
Enviadas: Segunda-feira, 4 de Fevereiro de 2008 17:03:25
Assunto: Re: [R-sig-Geo] converting shapefile/polygon to psp

On Mon, 4 Feb 2008, Milton Cezar Ribeiro wrote:

> Dear all,
>
> I have some shapefiles which contents are polygons and I would like to 
> convert it to psp (spatstat) format, and after run crossdist.psp. I 
> tryed several times without success. Any idea?

Look at the coercion function in maptools from SpatialPolygons to owin; 
see what needs to be changed to match psp; debug; contribute?

Note that touching polygons fail the topology test in spatstat, as they 
should. Seeing how a psp works should't be hard, it is effectively as 
described in:

https://stat.ethz.ch/pipermail/r-sig-geo/2008-January/003075

for making the lll matrix for distppll(), but as a data frame. You could 
use the marks to record which Polygons/Polygon object the segments belong 
to.

Roger

>
> Miltinho
>
>
>
> para armazenamento!
>
>     [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


       Abra sua conta no Yahoo! Mail, o ?nico sem limite de espa?o para armazenamento!
http://br.mail.yahoo.com/

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From p.vanbreugel at gmail.com  Tue Feb  5 14:03:39 2008
From: p.vanbreugel at gmail.com (Paulo van Breugel)
Date: Tue, 05 Feb 2008 16:03:39 +0300
Subject: [R-sig-Geo] FYI: Merging GIS and statistics --- RSAGA
In-Reply-To: <mailman.9.1202209202.26293.r-sig-geo@stat.math.ethz.ch>
References: <mailman.9.1202209202.26293.r-sig-geo@stat.math.ethz.ch>
Message-ID: <47A85EAB.5030805@gmail.com>

Hi I encountered that problem and got in contact with the RSAGA 
maintainer about this problem. He suggested the following (temporary) 
solutions, which works for me:

rsaga.geoprocessor("grid_calculus", 1, list(INPUT="dem.sgrd;brillo.sgrd", RESULT="out2", FORMUL="a/b"),beep.off = FALSE)

In other words, include the beep.off argument, but set it to FALSE 
(defaults to TRUE). Hope this helps, Paulo Message: 8 Date: Mon, 4 Feb 
2008 13:05:41 -0500 From: Al? Santacruz <amsantac at hotmail.com> Subject: 
Re: [R-sig-Geo] FYI: Merging GIS and statistics --- RSAGA To: Tomislav 
Hengl <hengl at science.uva.nl>, <r-sig-geo at stat.math.ethz.ch> Message-ID: 
<BAY120-W29C2E140E80D0B647AD49AC9330 at phx.gbl> Content-Type: text/plain 
Hi, I am trying to use the Grid Calculator in SAGA, through RSAGA but I 
have problems with the parameter FORMUL, I can?t get the function "a/b" 
works, the functions "a+b", or "a-b", or "a*b" works, but "a/b" does 
not, Any help is appreciated, see the code below for the errors 
reported, thanks, Ali Santacruz M.Sc. Geomatics. National University of 
Colombia, Bogota, Colombia E-mail: amsantac at unal.edu.co

------------------------------

Message: 9
Date: Mon, 4 Feb 2008 19:29:37 +0100 (CET)
From: Roger Bivand <Roger.Bivand at nhh.no>
Subject: Re: [R-sig-Geo] FYI: Merging GIS and statistics --- RSAGA
To: Al? Santacruz <amsantac at hotmail.com>
Cc: r-sig-geo at stat.math.ethz.ch
Message-ID: <Pine.LNX.4.64.0802041915160.7596 at reclus.nhh.no>
Content-Type: text/plain; charset="iso-8859-1"

On Mon, 4 Feb 2008, Al? Santacruz wrote:


> >
> >
> > Hi,
> >
> > I am trying to use the Grid Calculator in SAGA, through RSAGA but I have 
> > problems with the parameter FORMUL,
> >
> > I can?t get the function "a/b" works,
> >
> > the functions "a+b", or "a-b", or "a*b" works, but "a/b" does not,
> >
> > Any help is appreciated,
> >
> > see the code below for the errors reported,
> >
> > thanks,
> >
> > Ali Santacruz
> > M.Sc. Geomatics.
> > National University of Colombia,
> > Bogota, Colombia
> > E-mail: amsantac at unal.edu.co
> >
> >
> > ## this formula does not work:
>   
>> >> rsaga.geoprocessor("grid_calculus", 1, 
>> >> list(INPUT="dem.sgrd;brillo.sgrd", RESULT="out2", 
>> >> FORMUL="a/b"))
>> >> C:\Users\geomatica\Desktop
>> >> C:\Users\geomatica\Documents\R\win-library\2.6\RSAGA\saga_vc\saga_cmd.exe
>> >> grid_calculus 1 -silent -INPUT dem.sgrd;brillo.sgrd -RESULT out2 
>> >> -FORMUL a\b
>>     
           ^^^^

A very smokey smoking gun, isn't it? The interface is converting all 
forward slash to backslash (Windows *does* respect forward slash in file 
path names, so this isn't strictly needed), so you'll have to try to 
escape the value until you see a/b coming through. I'm in doubt whether 
you'll have any luck, though:

...
     if (beep.off & .Platform$OS.type=="windows") {
         command = gsub("/","\\",command,fixed=TRUE)
                        ^^^^^^^^
         batch = c("net stop beep",command)
         batchfilename = paste(tempfile(),".bat",sep="")
         batchfile = file(batchfilename,"wt")
         writeLines(batch,con=batchfile)
         close(batchfile)
         command = batchfilename
     }
...

in R/RSAGA-core.R, which converts everything whether a file path or not.

Roger

PS. Is the RSAGA maintainer subscribed to this list?



> >



From adrian at maths.uwa.edu.au  Wed Feb  6 02:10:02 2008
From: adrian at maths.uwa.edu.au (adrian at maths.uwa.edu.au)
Date: Wed, 6 Feb 2008 10:10:02 +0900 (WST)
Subject: [R-sig-Geo] converting shapefile/polygon to psp
Message-ID: <3009.130.116.32.101.1202260202.squirrel@130.116.32.101>

On Mon, 4 Feb 2008, Milton Cezar Ribeiro wrote:

> I have some shapefiles which contents are polygons and I would like to
> convert it to psp (spatstat) format, and after run crossdist.psp. I
> tryed several times without success. Any idea?

First convert the shapefile to an object of class "owin" (in spatstat)
using the coercion functions in 'maptools' or 'sp'.

Once you have an owin object, use as.psp() in 'spatstat' to convert the
polygon to a list of edges.

Adrian Baddeley



From Ingo.Holz at uni-hohenheim.de  Wed Feb  6 09:16:03 2008
From: Ingo.Holz at uni-hohenheim.de (Ingo Holz)
Date: Wed, 06 Feb 2008 09:16:03 +0100
Subject: [R-sig-Geo] subregion of a SpatialGridDataFrame
Message-ID: <47A97AD3.15933.5B17F2@ingoholz.uni-hohenheim.de>

Hi,

 this sounds like a stupid question, however:

 I have a SpatialGridDataFrame (SGDF) and want to cut a rectangular 
subregion from this SGDF to a new sub-region-SGDF.

 Is it possible to define a new bounding-box with two points and cut the 
subregion out of the SGDF?

Ingo



From edzer.pebesma at uni-muenster.de  Wed Feb  6 09:42:46 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 06 Feb 2008 09:42:46 +0100
Subject: [R-sig-Geo] subregion of a SpatialGridDataFrame
In-Reply-To: <47A97AD3.15933.5B17F2@ingoholz.uni-hohenheim.de>
References: <47A97AD3.15933.5B17F2@ingoholz.uni-hohenheim.de>
Message-ID: <47A97306.4030405@uni-muenster.de>

Ingo Holz wrote:
> Hi,
>
>  this sounds like a stupid question, however:
>
>  I have a SpatialGridDataFrame (SGDF) and want to cut a rectangular 
> subregion from this SGDF to a new sub-region-SGDF.
>
>  Is it possible to define a new bounding-box with two points and cut the 
> subregion out of the SGDF?
>
> Ingo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   
 > data(meuse.grid)
 > coordinates(meuse.grid)=~x+y
 > meuse.grid=as(meuse.grid, "SpatialGridDataFrame")
Error in as(meuse.grid, "SpatialGridDataFrame") :
  no method or default for coercing "SpatialPointsDataFrame" to 
"SpatialGridDataFrame"
# this surprised me, but the following does work:
 > meuse.grid=as(meuse.grid, "SpatialPixelsDataFrame")
 > meuse.grid=as(meuse.grid, "SpatialGridDataFrame")
 > image(meuse.grid[40:60,20:50,1])

# meaning the first index selects rows (top to bottom), and the second 
columns; the third attribute

 > bbox(meuse.grid[40:60,20:50,1])
     min    max
x 179200 180440
y 331360 332200
 > x1 = bbox(meuse.grid[40:60,20:50,1])[1,1]
 > x2 = bbox(meuse.grid[40:60,20:50,1])[1,2]
 > y1 = bbox(meuse.grid[40:60,20:50,1])[2,1]
 > y2 = bbox(meuse.grid[40:60,20:50,1])[2,2]
 > p = Polygon(cbind(c(x1,x2,x2,x1,x1),c(y1,y1,y2,y2,y1)))  
 > sps = SpatialPolygons(list(Polygons(list(p),"bbox")))
 > meuse.grid=as(meuse.grid,"SpatialPixelsDataFrame")
 > image(meuse.grid[!is.na(overlay(meuse.grid,sps)),1])

# this second form needs the grid represented as pixels, as the overlay 
considers each grid cell, and retuns a vector the length of the number 
of pixels. The image should be identical to the former.
--
Edzer



From p.hiemstra at geo.uu.nl  Wed Feb  6 14:11:39 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Wed, 06 Feb 2008 14:11:39 +0100
Subject: [R-sig-Geo] subregion of a SpatialGridDataFrame
In-Reply-To: <47A97306.4030405@uni-muenster.de>
References: <47A97AD3.15933.5B17F2@ingoholz.uni-hohenheim.de>
	<47A97306.4030405@uni-muenster.de>
Message-ID: <47A9B20B.7060703@geo.uu.nl>

Hi,

Loading the grid and telling R that it is a grid can also be done by:

library(gstat)
data(meuse.grid)
gridded(meuse.grid) =~x+y # Now it is a SPixelDF
# The former is shorthand for:
# coordinates(meuse.grid) =~x+y
# gridded(meuse.grid) = TRUE
fullgrid(meuse.grid) = TRUE # Make it a SGridDF

cheers,
Paul


Edzer Pebesma wrote:
> Ingo Holz wrote:
>   
>> Hi,
>>
>>  this sounds like a stupid question, however:
>>
>>  I have a SpatialGridDataFrame (SGDF) and want to cut a rectangular 
>> subregion from this SGDF to a new sub-region-SGDF.
>>
>>  Is it possible to define a new bounding-box with two points and cut the 
>> subregion out of the SGDF?
>>
>> Ingo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>   
>>     
>  > data(meuse.grid)
>  > coordinates(meuse.grid)=~x+y
>  > meuse.grid=as(meuse.grid, "SpatialGridDataFrame")
> Error in as(meuse.grid, "SpatialGridDataFrame") :
>   no method or default for coercing "SpatialPointsDataFrame" to 
> "SpatialGridDataFrame"
> # this surprised me, but the following does work:
>  > meuse.grid=as(meuse.grid, "SpatialPixelsDataFrame")
>  > meuse.grid=as(meuse.grid, "SpatialGridDataFrame")
>  > image(meuse.grid[40:60,20:50,1])
>
> # meaning the first index selects rows (top to bottom), and the second 
> columns; the third attribute
>
>  > bbox(meuse.grid[40:60,20:50,1])
>      min    max
> x 179200 180440
> y 331360 332200
>  > x1 = bbox(meuse.grid[40:60,20:50,1])[1,1]
>  > x2 = bbox(meuse.grid[40:60,20:50,1])[1,2]
>  > y1 = bbox(meuse.grid[40:60,20:50,1])[2,1]
>  > y2 = bbox(meuse.grid[40:60,20:50,1])[2,2]
>  > p = Polygon(cbind(c(x1,x2,x2,x1,x1),c(y1,y1,y2,y2,y1)))  
>  > sps = SpatialPolygons(list(Polygons(list(p),"bbox")))
>  > meuse.grid=as(meuse.grid,"SpatialPixelsDataFrame")
>  > image(meuse.grid[!is.na(overlay(meuse.grid,sps)),1])
>
> # this second form needs the grid represented as pixels, as the overlay 
> considers each grid cell, and retuns a vector the length of the number 
> of pixels. The image should be identical to the former.
> --
> Edzer
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul



From amsantac at hotmail.com  Wed Feb  6 16:27:09 2008
From: amsantac at hotmail.com (=?iso-8859-1?Q?Al=ED_Santacruz?=)
Date: Wed, 6 Feb 2008 10:27:09 -0500
Subject: [R-sig-Geo] FYI: Merging GIS and statistics --- RSAGA
In-Reply-To: <47A85EAB.5030805@gmail.com>
References: <mailman.9.1202209202.26293.r-sig-geo@stat.math.ethz.ch>
	<47A85EAB.5030805@gmail.com>
Message-ID: <BAY120-W40601E6D6FAF71BFEB7957C92D0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080206/5ad5944a/attachment.pl>

From paulojus at c3sl.ufpr.br  Wed Feb  6 17:55:02 2008
From: paulojus at c3sl.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Wed, 6 Feb 2008 14:55:02 -0200 (BRST)
Subject: [R-sig-Geo] BJPS Special Issue on Statistical Image and Signal
	Processing (fwd)
Message-ID: <Pine.LNX.4.58.0802061454020.10430@talisker.c3sl.ufpr.br>


Brazilian Journal of Probability and Statistics
Special Issue on Statistical Image and Signal Processing

An image is worth a thousand words, and the information images provide
influences the most important decisions we take every instant of our
lives. Signals carry information, and our society is known as the
Information Society. Statistics has much to do about image and
signals, and this special issue aims at providing a forum for recent
advances on this fertile area.

This special issue is an opportunity to gather recent results in these
broad areas of image and signal processing and analysis, that stems
from models for forthcoming imaging devices to high-level techniques
for image and video storage and retrieval. This is a multidisciplinary
research field, with important connections with signal processing,
statistics, computer vision and robotics, to name only a few, and a
wide spectrum of applications, e.g., remote sensing, surveillance and
medical and industrial imaging.

Topics of interest include, but are not limited to innovative results in
    * statistical models in image and signal processing, new sensors
and technologies
    * inference on images and signals: parametric, semiparametric and
nonparametric
    * statistical techniques for handling large and huge databases,
and KDD (knowledge discovery in databases) for visual information
    * statistical techniques for rendering and visualization (NPR -
non photorealistic rendering, etc.)
    * resampling methods in image and signal analysis
    * statistical shape analysis
    * statistics in bioinformatics

These topics aim at covering all the stages of the visual information
processing chain, from image formation to image understanding, and at
covering all possible techniques and models, from signal processing to
hybrid artificial intelligence techniques.

Authors should follow the BJPS manuscript format described at the
journal site http://www.redeabe.org.br/bjps.htm. Prospective authors
should send an electronic copy of their complete manuscript to
bjps2008 at gmail.com, according to the following timetable:

Manuscript due: April 30, 2008
Expected editorial decisions: December 2008
Expected publication date: Second semester of 2009

Guest editor: Alejandro C. Frery, Instituto de Computa??o,
Universidade Federal de Alagoas, Brazil.

Guest co-editor: Francisco Cribari-Neto, Departamento de Estat?stica,
Universidade Federal de Pernambuco, Brazil

The Brazilian Journal of Probability and Statistics has been
publishing high level research papers in applied probability, applied
statistics, computational statistics, mathematical statistics,
probability theory and stochastic processes for more than twenty
years. It is indexed by the following services: Current Index to
Statistics, Mathematical Reviews and Zentralblatt f?r Mathematik.

For information about the Journal, see http://www.redeabe.org.br/bjps.htm.

-
Alejandro C. Frery
Macei?, AL - Brazil

Quod Natura no dat, Helmantica non praestat




Paulo Justiniano Ribeiro Jr
LEG (Laboratorio de Estatistica e Geoinformacao)
Universidade Federal do Parana
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 3361 3573
Fax: (+55) 41 3361 3141
e-mail: paulojus AT  ufpr  br
http://www.leg.ufpr.br/~paulojus

-------------------------------------------------------------------------
53a Reuniao Anual da Regiao Brasileira da Soc. Internacional de Biometria
14 a 16/05/2008, UFLA, Lavras,MG
http://www.rbras.org.br/rbras53



From mrufino at cripsul.ipimar.pt  Wed Feb  6 19:19:39 2008
From: mrufino at cripsul.ipimar.pt (Marta Rufino)
Date: Wed, 06 Feb 2008 18:19:39 +0000
Subject: [R-sig-Geo] cross-validation
Message-ID: <47A9FA3B.4090901@cripsul.ipimar.pt>

Dear list members,

Is it possible to do cross-validation on multivariate kriging?
i.e. apply krige.cv to multivariate kriging in gstat?

thank you very much,
Best wishes,
Marta



From edzer.pebesma at uni-muenster.de  Wed Feb  6 19:38:33 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 06 Feb 2008 19:38:33 +0100
Subject: [R-sig-Geo] cross-validation
In-Reply-To: <47A9FA3B.4090901@cripsul.ipimar.pt>
References: <47A9FA3B.4090901@cripsul.ipimar.pt>
Message-ID: <47A9FEA9.8080300@uni-muenster.de>

Yes, Martha; function gstat.cv works on multivariable objects; do read 
it's documentation.

Best regards,
--
Edzer

Marta Rufino wrote:
> Dear list members,
>
> Is it possible to do cross-validation on multivariate kriging?
> i.e. apply krige.cv to multivariate kriging in gstat?
>
> thank you very much,
> Best wishes,
> Marta
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From mrufino at cripsul.ipimar.pt  Wed Feb  6 20:12:48 2008
From: mrufino at cripsul.ipimar.pt (Marta Rufino)
Date: Wed, 06 Feb 2008 19:12:48 +0000
Subject: [R-sig-Geo] cross-validation
In-Reply-To: <47A9FEA9.8080300@uni-muenster.de>
References: <47A9FA3B.4090901@cripsul.ipimar.pt>
	<47A9FEA9.8080300@uni-muenster.de>
Message-ID: <47AA06B0.8090709@cripsul.ipimar.pt>

Hello,

yes, I know it is suppose to do it, but I could not find how, because it 
gives me an error... for example:

require(gstat); require(lattice)
data(meuse)
coordinates(meuse) = ~x + y
data(meuse.grid)
gridded(meuse.grid) = ~x + y

meuse.g <- gstat(id = "zn", formula = log(zinc) ~ 1, data = meuse)
meuse.g <- gstat(meuse.g, "cu", log(copper) ~ 1, meuse)

meuse.g <- gstat(meuse.g, model = vgm(1, "Sph", 900, 1), fill.all = T)
x <- variogram(meuse.g, cutoff = 1000)
meuse.fit = fit.lmc(x, meuse.g)
plot(x, model = meuse.fit)
z <- predict(meuse.fit, newdata = meuse.grid)
spplot(z) #map
gstat.cv(meuse.g) #does not work...
gstat.cv(meuse.g, remove.all=T) #either
gstat.cv(meuse.g, all.residuals=T) #either
gstat.cv(object=meuse.g, formula = log(zinc) ~ 1, data = meuse, model = 
vgm(1, "Sph", 900, 1), nmax=40, verbose=F) #either :-(

#                             
# Intrinsic Correlation found. Good.
# [using ordinary cokriging]

# "chfactor.c", line 130: singular matrix in function LDLfactor()
# Error in predict.gstat(object, newdata = data[sel, ], ...) :
#         LDLfactor

Maybe an example on the help file would be nice (eheheh).. I
What am I missing?


Thank you very much in advance,
Marta



From p.hiemstra at geo.uu.nl  Wed Feb  6 22:54:22 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Wed, 06 Feb 2008 22:54:22 +0100
Subject: [R-sig-Geo] cross-validation
In-Reply-To: <47AA06B0.8090709@cripsul.ipimar.pt>
References: <47A9FA3B.4090901@cripsul.ipimar.pt>	<47A9FEA9.8080300@uni-muenster.de>
	<47AA06B0.8090709@cripsul.ipimar.pt>
Message-ID: <47AA2C8E.6080606@geo.uu.nl>

Hi,

You should check if you have duplicate observations, duplicate 
observations lead to a singular matrix. Use the function zerodist() to 
check where the observations are and remove.duplicates() to remove them.

cheers,
Paul

Marta Rufino schreef:
> Hello,
>
> yes, I know it is suppose to do it, but I could not find how, because it 
> gives me an error... for example:
>
> require(gstat); require(lattice)
> data(meuse)
> coordinates(meuse) = ~x + y
> data(meuse.grid)
> gridded(meuse.grid) = ~x + y
>
> meuse.g <- gstat(id = "zn", formula = log(zinc) ~ 1, data = meuse)
> meuse.g <- gstat(meuse.g, "cu", log(copper) ~ 1, meuse)
>
> meuse.g <- gstat(meuse.g, model = vgm(1, "Sph", 900, 1), fill.all = T)
> x <- variogram(meuse.g, cutoff = 1000)
> meuse.fit = fit.lmc(x, meuse.g)
> plot(x, model = meuse.fit)
> z <- predict(meuse.fit, newdata = meuse.grid)
> spplot(z) #map
> gstat.cv(meuse.g) #does not work...
> gstat.cv(meuse.g, remove.all=T) #either
> gstat.cv(meuse.g, all.residuals=T) #either
> gstat.cv(object=meuse.g, formula = log(zinc) ~ 1, data = meuse, model = 
> vgm(1, "Sph", 900, 1), nmax=40, verbose=F) #either :-(
>
> #                             
> # Intrinsic Correlation found. Good.
> # [using ordinary cokriging]
>
> # "chfactor.c", line 130: singular matrix in function LDLfactor()
> # Error in predict.gstat(object, newdata = data[sel, ], ...) :
> #         LDLfactor
>
> Maybe an example on the help file would be nice (eheheh).. I
> What am I missing?
>
>
> Thank you very much in advance,
> Marta
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:     +31302535773
Fax:    +31302531145
http://intamap.geo.uu.nl/~paul



From ilonan at interchange.ubc.ca  Wed Feb  6 23:21:46 2008
From: ilonan at interchange.ubc.ca (Ilona Naujokaitis-Lewis)
Date: Wed, 06 Feb 2008 14:21:46 -0800
Subject: [R-sig-Geo] overlay fx, consistent topology,
	sample a point on a 'patch edge'
Message-ID: <004201c8690e$a92d0e20$e0f1bd80@forestry.ubc.ca>

NO

Dear list-serve,
Thanks in advance to all those who help out with the inquiries, it is has
helped me numerous times. Here go my questions...

I am trying to vary existing landscapes which are composed of habitat
(patches) and non-habitat. My goals are to vary the number of patches in a
landscape, and the size of each patch. 

My landscape files are originally raster files, which I have converted to
ascii format. When importing into R, they are of class SpatialGridDataFrame,
are fully gridded. Each cell is represented by a 0: non-habitat, or a value
ranging between >0 and <=1, which represents varying degrees of habitat
quality. Patches are simply identified where adjoining cells are
>0.

The approach I have taken is to create a mask of my ascii landscape file so
that already existing patches are masked. This allows me to sample a point
in the region of my landscape that is identified as non-habitat. I then
apply the dilate function to essentially 'grow' a patch.

I have followed the code from the following link:
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/115868.html
The only difference is that once I have effected the dilate function, which
is of class 'owin', I then:
1) coerce "owin" to "im" object class
2) coerce "im" object class to a SpatialGridDataframe

My problems are:
1. How to overlay my final 2 layers:  1) dilated object (object class
SpatialGridDataFrame) and 2) original landscape patch layer (also object
class SpatialGridDataFrame). I need the resulting object to be an object of
class SpatialGridDataFrame with only 1 band consisting of original patches,
the new patches, and non-habitat so I can perform additional data
manipulations. The overlay function does not appear to work with 2 objects
of this class. Any alternative suggestions? 

2. My dilated points object (SGDF) does not have topology identical to the
original layer - I think I need them to be the same for the overlay process,
and if yes, how do I change this. The cell size remains the same but the
offset and cell dimension are not identical.
For example:
	> getGridTopology(dilate_SGDF)
  	                  X1  X2
	cellcentre.offset 1050 890
	cellsize            20  20
	cells.dim           15  11
	> getGridTopology(original_layer)
        	             x   y
	cellcentre.offset 1030 870
	cellsize            20  20
	cells.dim           16  12

3. I would like to sample on the patch edge and use the dilate or erode
functions to increase or decrease the size of a patch. How can I force the
sampling of a spatial point, which becomes the centre for the dilate/erode
function, to fall on a patch edge. In other words, if I was to look at the
landscape file in ascii format I would need to sample a grid cell that has a
value of >0, but where at least 1 of the cells surrounding this point, in
all orthogonal directions, has a value = 0. 

4. How to constrain the newly added patches so that they does not overlap
with existing patches.

5. How to add patches of different sizes -perhaps I can simply add a loop to
my code?

I am using Windows XP and R.2.6.1. Any help on these issues would be greatly
appreciated. Thanks in advance for your help on these multiple but related
issues. I do appreciate the time that people take in responding to these
inquiries.

Best,
ilona

Ilona Naujokaitis-Lewis
Centre for Applied Conservation Research
Forest Sciences Department
University of British Columbia
3041-2424 Main Mall
Vancouver, BC V6T 1Z4
 
phone: 604 822.4382
email: ilonan at interchange.ubc.ca



From edzer.pebesma at uni-muenster.de  Thu Feb  7 11:09:55 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 07 Feb 2008 11:09:55 +0100
Subject: [R-sig-Geo] cross-validation
In-Reply-To: <47AA2C8E.6080606@geo.uu.nl>
References: <47A9FA3B.4090901@cripsul.ipimar.pt>	<47A9FEA9.8080300@uni-muenster.de>
	<47AA06B0.8090709@cripsul.ipimar.pt> <47AA2C8E.6080606@geo.uu.nl>
Message-ID: <47AAD8F3.5030107@uni-muenster.de>

That was not the problem, the problem was that you used meuse.g instead 
of meuse.fit to pass on to gstat.cv. For meuse.g, you have perfect 
correlation between Cu and Zn, so that collocated observations (meaning 
a Zn and a Cu observation at each obs location) act as a duplicate in 
univarite kriging.

Try:

out = gstat.cv(object=meuse.fit, nmax=40, verbose=F, nfold=5)
--
Edzer

Paul Hiemstra wrote:
> Hi,
>
> You should check if you have duplicate observations, duplicate 
> observations lead to a singular matrix. Use the function zerodist() to 
> check where the observations are and remove.duplicates() to remove them.
>
> cheers,
> Paul
>
> Marta Rufino schreef:
>> Hello,
>>
>> yes, I know it is suppose to do it, but I could not find how, because 
>> it gives me an error... for example:
>>
>> require(gstat); require(lattice)
>> data(meuse)
>> coordinates(meuse) = ~x + y
>> data(meuse.grid)
>> gridded(meuse.grid) = ~x + y
>>
>> meuse.g <- gstat(id = "zn", formula = log(zinc) ~ 1, data = meuse)
>> meuse.g <- gstat(meuse.g, "cu", log(copper) ~ 1, meuse)
>>
>> meuse.g <- gstat(meuse.g, model = vgm(1, "Sph", 900, 1), fill.all = T)
>> x <- variogram(meuse.g, cutoff = 1000)
>> meuse.fit = fit.lmc(x, meuse.g)
>> plot(x, model = meuse.fit)
>> z <- predict(meuse.fit, newdata = meuse.grid)
>> spplot(z) #map
>> gstat.cv(meuse.g) #does not work...
>> gstat.cv(meuse.g, remove.all=T) #either
>> gstat.cv(meuse.g, all.residuals=T) #either
>> gstat.cv(object=meuse.g, formula = log(zinc) ~ 1, data = meuse, model 
>> = vgm(1, "Sph", 900, 1), nmax=40, verbose=F) #either :-(
>>
>> #                             # Intrinsic Correlation found. Good.
>> # [using ordinary cokriging]
>>
>> # "chfactor.c", line 130: singular matrix in function LDLfactor()
>> # Error in predict.gstat(object, newdata = data[sel, ], ...) :
>> #         LDLfactor
>>
>> Maybe an example on the help file would be nice (eheheh).. I
>> What am I missing?
>>
>>
>> Thank you very much in advance,
>> Marta
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>   
>
>



From mrufino at cripsul.ipimar.pt  Thu Feb  7 12:58:49 2008
From: mrufino at cripsul.ipimar.pt (Marta Rufino)
Date: Thu, 07 Feb 2008 11:58:49 +0000
Subject: [R-sig-Geo] cross-validation
In-Reply-To: <47AAD8F3.5030107@uni-muenster.de>
References: <47A9FA3B.4090901@cripsul.ipimar.pt>	<47A9FEA9.8080300@uni-muenster.de>
	<47AA06B0.8090709@cripsul.ipimar.pt>
	<47AA2C8E.6080606@geo.uu.nl> <47AAD8F3.5030107@uni-muenster.de>
Message-ID: <47AAF279.7010601@cripsul.ipimar.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080207/7b14595a/attachment.pl>

From edzer.pebesma at uni-muenster.de  Thu Feb  7 14:36:27 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 07 Feb 2008 14:36:27 +0100
Subject: [R-sig-Geo] overlay fx, consistent topology,
 sample a point on a 'patch edge'
In-Reply-To: <004201c8690e$a92d0e20$e0f1bd80@forestry.ubc.ca>
References: <004201c8690e$a92d0e20$e0f1bd80@forestry.ubc.ca>
Message-ID: <47AB095B.5000702@uni-muenster.de>

Ilona Naujokaitis-Lewis wrote:
> NO
>
> Dear list-serve,
> Thanks in advance to all those who help out with the inquiries, it is has
> helped me numerous times. Here go my questions...
>
> I am trying to vary existing landscapes which are composed of habitat
> (patches) and non-habitat. My goals are to vary the number of patches in a
> landscape, and the size of each patch. 
>
> My landscape files are originally raster files, which I have converted to
> ascii format. When importing into R, they are of class SpatialGridDataFrame,
> are fully gridded. Each cell is represented by a 0: non-habitat, or a value
> ranging between >0 and <=1, which represents varying degrees of habitat
> quality. Patches are simply identified where adjoining cells are
>   
>> 0.
>>     
>
> The approach I have taken is to create a mask of my ascii landscape file so
> that already existing patches are masked. This allows me to sample a point
> in the region of my landscape that is identified as non-habitat. I then
> apply the dilate function to essentially 'grow' a patch.
>
> I have followed the code from the following link:
> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/115868.html
> The only difference is that once I have effected the dilate function, which
> is of class 'owin', I then:
> 1) coerce "owin" to "im" object class
> 2) coerce "im" object class to a SpatialGridDataframe
>
> My problems are:
> 1. How to overlay my final 2 layers:  1) dilated object (object class
> SpatialGridDataFrame) and 2) original landscape patch layer (also object
> class SpatialGridDataFrame). I need the resulting object to be an object of
> class SpatialGridDataFrame with only 1 band consisting of original patches,
> the new patches, and non-habitat so I can perform additional data
> manipulations. The overlay function does not appear to work with 2 objects
> of this class. Any alternative suggestions? 
>   
Method overlay only combines objects of different class. If you have two 
grids and want to create a third, and all three have the same 
topology/number of cells, then simply use vectorized expressions like

grd$out = grd$dilated != grd$original
> 2. My dilated points object (SGDF) does not have topology identical to the
> original layer - I think I need them to be the same for the overlay process,
> and if yes, how do I change this. The cell size remains the same but the
> offset and cell dimension are not identical.
> For example:
> 	> getGridTopology(dilate_SGDF)
>   	                  X1  X2
> 	cellcentre.offset 1050 890
> 	cellsize            20  20
> 	cells.dim           15  11
> 	> getGridTopology(original_layer)
>         	             x   y
> 	cellcentre.offset 1030 870
> 	cellsize            20  20
> 	cells.dim           16  12
>   
You could coerce the "wrong" one into a SpatialPointsDataFrame and the 
use function (method) overlay with the good grid to get the right indexes.
--
Edzer



From edzer.pebesma at uni-muenster.de  Thu Feb  7 15:18:14 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 07 Feb 2008 15:18:14 +0100
Subject: [R-sig-Geo] cross-validation
In-Reply-To: <47AAF279.7010601@cripsul.ipimar.pt>
References: <47A9FA3B.4090901@cripsul.ipimar.pt>	<47A9FEA9.8080300@uni-muenster.de>
	<47AA06B0.8090709@cripsul.ipimar.pt>
	<47AA2C8E.6080606@geo.uu.nl> <47AAD8F3.5030107@uni-muenster.de>
	<47AAF279.7010601@cripsul.ipimar.pt>
Message-ID: <47AB1326.40807@uni-muenster.de>

Marta Rufino wrote:
> Great!
Hi Marta,

I now have in the example section of gstat.cv help:

# multivariable; thanks to M. Rufino:
meuse.g <- gstat(id = "zn", formula = log(zinc) ~ 1, data = meuse)
meuse.g <- gstat(meuse.g, "cu", log(copper) ~ 1, meuse)
meuse.g <- gstat(meuse.g, model = vgm(1, "Sph", 900, 1), fill.all = T)
x <- variogram(meuse.g, cutoff = 1000)
meuse.fit = fit.lmc(x, meuse.g)
out = gstat.cv(meuse.fit, nmax = 40, nfold = 5)
summary(out)
# mean error, ideally 0:
mean(out$residual)
# MSPE, ideally small
mean(out$residual^2)
# Mean square normalized error, ideally close to 1
mean(out$zscore^2)
# correlation observed and predicted, ideally 1
cor(out$observed, out$observed - out$residual)
# correlation predicted and residual, ideally 0
cor(out$observed - out$residual, out$residual)

I'm a bit hesitant to write a dedicated function for such simple 
calculations. In your function below, I object to the use of "expected", 
where you mean "desired". It's definitely not expected in the 
statistical sense.

The difficult questions about the cross validation results in 
geostatistics are usually "can we attribute the difference of a MSNE of 
1.1 from the idealized value of 1 attribute to sampling error, or is it 
an indication of a misfitting model?" In the latter case: "should we 
worry?" (only if kriging errors are of importance, many people ignore them).

Also, if the data are nicely spread, say the shortest distance is 100m 
(stay with the example above), then CV is never going to tell anything 
about the variogram for distances up to 100m.

Leave-on-out vs. n-fold? I believe Hastie, Tibshirani and Friedman 
promote the 10-fold. The idea was that leave-one-out may be too 
optimistic and not reveal model error, as refitted models are almost 
identical for moderately sized or large data sets, in each fold. 
Leave-one-out will have smaller RMSE than say 5-fold, but this is not an 
indication of a better model nor of a substantially better procedure, IMO.

Best wishes,
--
Edzer

>
> This works wonderfully...maybe would be nice if you add it to the 
> example in the help page :-)
>
> Further comments in /CV/... from the gstat.cv output, which 
> cross-validation measures should be considered when establishing the 
> performance of kriging, in relation to other methods, for example or 
> to compare among kriging modelling options?
>
> I.
> http://www.ic.arizona.edu/ic/math574/class_notes/meuse%20zinc%20vs%20logzinc%20using%20gstat.pdf
> "Cross validation produces multiple statistics,
> making changes to improve one statistic may make another worse. The 
> key statistics are (1)
> the mean error (expected value is zero), (2) mean square normalized 
> error (in gstat and
> several other software packages, the normalized error is called the 
> ?zscore?). The expected
> value of this statistic is one. (3) Ideally the correlation between 
> the predicted value and the
> observed value is one, however when using Ordinary kriging or 
> Universal kriging, the
> maximum correlation is somewhat less (because of the Lagrange 
> multipliers). (4) Ideally the
> correlation between the predicted value and the error (residual) is 
> zero but again the
> Lagrange multipliers have an effect. (5) Using Chebyshev?s Inequality 
> we can bound the"
>
> Thus, they state that the important checks to do with the CV, is ():
> 1) mean error (should ~0)
> 2) Mean squared normalized error (should ~1)
> 3) correlation between observed and predicted (should ~1)
> 4) correlation between predicted and residuals (should ~0)
>
> out = gstat.cv(object=meuse.fit, nmax=40, nfold=5)
> cv.results=function(x){ #function to organize CV results. x is the 
> result of kriging Crossvalidation
> print(bubble(x, c("residual"), main = "leave-one-out CV residuals"))
> x=data.frame(x)
> kk=data.frame(
> ME=c(0,mean(x$res)),
> MSNE=c(1,sqrt(sum(x$zscore^2)/length(x$res))),
> cor1=c(1,cor(x$obs, x[,1])) ,
> cor2=c(0,cor(x[,1], x$res)))
> row.names(kk)=c("expected", "estimated")
> return(kk)
> }
>
> cv.results(out)
>
>
> II
> On another web ref. 
> (http://www.itc.nl/personal/rossiter/teach/R/R_ck.pdf):
> "Diagnostic measures are the ME (bias), RMSE (precision), and Mean Squared
> Deviation Ratio (MSDR) of the residuals to the prediction errors; this
> should be 1 because the residuals from cross-validation should equal
> to prediction errors at each point that was held out. For the univariate
> case (OK) we can use the krige.cv cross-validation method of the gstat
> package."
> Which is calculated by:
>
> mean(out$res) # mean error
> sqrt(mean(out$res^2)) # RMSE
> mean(out$res^2/as.data.frame(out)[,2]) # MSDR, should be ~1 (it is 
> equivalent to predicted vs. sampled
>
>
> So, I consulted several text books about the subject, and there was 
> none providing a clear answer about the important measures to take int 
> account and which sort of cross-validation performs better (although I 
> heard that it is 10-fold CV). Does anyone has further information 
> about this subject?
>
> Which measures perform best?
> Does anyone has good references about the subject?
>
> Best wishes,
> Marta
>
>
> Edzer Pebesma wrote:
>> That was not the problem, the problem was that you used meuse.g 
>> instead of meuse.fit to pass on to gstat.cv. For meuse.g, you have 
>> perfect correlation between Cu and Zn, so that collocated 
>> observations (meaning a Zn and a Cu observation at each obs location) 
>> act as a duplicate in univarite kriging.
>>
>> Try:
>>
>> out = gstat.cv(object=meuse.fit, nmax=40, verbose=F, nfold=5)
>> -- 
>> Edzer
>>
>> Paul Hiemstra wrote:
>>> Hi,
>>>
>>> You should check if you have duplicate observations, duplicate 
>>> observations lead to a singular matrix. Use the function zerodist() 
>>> to check where the observations are and remove.duplicates() to 
>>> remove them.
>>>
>>> cheers,
>>> Paul
>>>
>>> Marta Rufino schreef:
>>>> Hello,
>>>>
>>>> yes, I know it is suppose to do it, but I could not find how, 
>>>> because it gives me an error... for example:
>>>>
>>>> require(gstat); require(lattice)
>>>> data(meuse)
>>>> coordinates(meuse) = ~x + y
>>>> data(meuse.grid)
>>>> gridded(meuse.grid) = ~x + y
>>>>
>>>> meuse.g <- gstat(id = "zn", formula = log(zinc) ~ 1, data = meuse)
>>>> meuse.g <- gstat(meuse.g, "cu", log(copper) ~ 1, meuse)
>>>>
>>>> meuse.g <- gstat(meuse.g, model = vgm(1, "Sph", 900, 1), fill.all = T)
>>>> x <- variogram(meuse.g, cutoff = 1000)
>>>> meuse.fit = fit.lmc(x, meuse.g)
>>>> plot(x, model = meuse.fit)
>>>> z <- predict(meuse.fit, newdata = meuse.grid)
>>>> spplot(z) #map
>>>> gstat.cv(meuse.g) #does not work...
>>>> gstat.cv(meuse.g, remove.all=T) #either
>>>> gstat.cv(meuse.g, all.residuals=T) #either
>>>> gstat.cv(object=meuse.g, formula = log(zinc) ~ 1, data = meuse, 
>>>> model = vgm(1, "Sph", 900, 1), nmax=40, verbose=F) #either :-(
>>>>
>>>> # # Intrinsic Correlation found. Good.
>>>> # [using ordinary cokriging]
>>>>
>>>> # "chfactor.c", line 130: singular matrix in function LDLfactor()
>>>> # Error in predict.gstat(object, newdata = data[sel, ], ...) :
>>>> # LDLfactor
>>>>
>>>> Maybe an example on the help file would be nice (eheheh).. I
>>>> What am I missing?
>>>>
>>>>
>>>> Thank you very much in advance,
>>>> Marta
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>
>>
>>
>
> -- 
> .......................................................................
> Marta M. Rufino (PhD)
>
> .....
> Instituto Nacional de Investiga??o Agr?ria e das Pescas (INIAP/IPIMAR),
> Centro Regional de Investiga??o Pesqueira do Sul (CRIPSul)
> Avenida 5 de Outubro s/n
> P-8700-305 Olh?o, Portugal
> +351 289 700 541
>
> ..... 
> Institut de Ci?ncies del Mar - CMIMA (CSIC)
> Passeig Mar?tim de la Barceloneta, 37-49      
> 08003 BARCELONA - Catalunya
> Spain 
>
>
>
>
>



From Roger.Bivand at nhh.no  Thu Feb  7 19:13:43 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 7 Feb 2008 19:13:43 +0100 (CET)
Subject: [R-sig-Geo] overlay fx, consistent topology,
 sample a point on a 'patch edge'
In-Reply-To: <47AB095B.5000702@uni-muenster.de>
References: <004201c8690e$a92d0e20$e0f1bd80@forestry.ubc.ca>
	<47AB095B.5000702@uni-muenster.de>
Message-ID: <Pine.LNX.4.64.0802071845241.22702@reclus.nhh.no>

On Thu, 7 Feb 2008, Edzer Pebesma wrote:

> Ilona Naujokaitis-Lewis wrote:
>> NO
>>
>> Dear list-serve,
>> Thanks in advance to all those who help out with the inquiries, it is has
>> helped me numerous times. Here go my questions...
>>
>> I am trying to vary existing landscapes which are composed of habitat
>> (patches) and non-habitat. My goals are to vary the number of patches in a
>> landscape, and the size of each patch.
>>
>> My landscape files are originally raster files, which I have converted to
>> ascii format. When importing into R, they are of class SpatialGridDataFrame,
>> are fully gridded. Each cell is represented by a 0: non-habitat, or a value
>> ranging between >0 and <=1, which represents varying degrees of habitat
>> quality. Patches are simply identified where adjoining cells are
>>
>>> 0.
>>>
>>
>> The approach I have taken is to create a mask of my ascii landscape file so
>> that already existing patches are masked. This allows me to sample a point
>> in the region of my landscape that is identified as non-habitat. I then
>> apply the dilate function to essentially 'grow' a patch.
>>
>> I have followed the code from the following link:
>> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/115868.html
>> The only difference is that once I have effected the dilate function, which
>> is of class 'owin', I then:
>> 1) coerce "owin" to "im" object class
>> 2) coerce "im" object class to a SpatialGridDataframe
>>
>> My problems are:
>> 1. How to overlay my final 2 layers:  1) dilated object (object class
>> SpatialGridDataFrame) and 2) original landscape patch layer (also object
>> class SpatialGridDataFrame). I need the resulting object to be an object of
>> class SpatialGridDataFrame with only 1 band consisting of original patches,
>> the new patches, and non-habitat so I can perform additional data
>> manipulations. The overlay function does not appear to work with 2 objects
>> of this class. Any alternative suggestions?
>>
> Method overlay only combines objects of different class. If you have two
> grids and want to create a third, and all three have the same
> topology/number of cells, then simply use vectorized expressions like
>
> grd$out = grd$dilated != grd$original

This is possible, but dilute.owin() not only extends the im object where 
the dilated region would cross the existing boundary, but also clips off 
parts not containing dilated cells. In this modified version:

dilate1.owin <- function (w, r, ..., include.bb=FALSE)
{
     verifyclass(w, "owin")
     if (r < 0)
         stop("r must be nonnegative")
     if (r == 0)
         return(w)
     if (w$type != "mask")
         w <- as.mask(w, ...)
     epsilon <- sqrt(w$xstep^2 + w$ystep^2)
     r <- max(r, epsilon)
     if (!include.bb) bb <- bounding.box(w)
     else bb <- w
     newbox <- owin(bb$xrange + c(-r, r), bb$yrange + c(-r, r))
     w <- rebound.owin(w, newbox)
     distant <- distmap(w)
     dil <- w
     dil$m <- (distant$v <= r)
     return(dil)
}

the input ranges are used, buffered out by the dilation range in each 
direction. So from the cited example:

> source("dilate1.owin")
> pts_owin_0.03 <- dilate1.owin(pts_owin, r=0.03, include.bb=TRUE)
> pts_owin_0.03
window: binary image mask
106 x 106 pixel array (ny, nx)
enclosing rectangle: [-0.03, 1.03] x [-0.03, 1.03] units
> x <- as.im(pts_owin_0.03)
> xx <- as(x, "SpatialGridDataFrame")
> xxx <- overlay(as(SGDF, "SpatialPixelsDataFrame"), xx)
> xx$orig[!is.na(xxx)] <- TRUE
> image(xx, "v")
> image(xx, "orig", col="black", add=TRUE)

gets you there more or less.

Roger

PS. The other questions are still open, the edge detection feels a bit 
like image analysis, say the biOps package for a range of filters to 
choose the cells on the edge of the patch (perhaps, untried).

>> 2. My dilated points object (SGDF) does not have topology identical to the
>> original layer - I think I need them to be the same for the overlay process,
>> and if yes, how do I change this. The cell size remains the same but the
>> offset and cell dimension are not identical.
>> For example:
>> > getGridTopology(dilate_SGDF)
>>   	                  X1  X2
>> 	cellcentre.offset 1050 890
>> 	cellsize            20  20
>> 	cells.dim           15  11
>> > getGridTopology(original_layer)
>>         	             x   y
>> 	cellcentre.offset 1030 870
>> 	cellsize            20  20
>> 	cells.dim           16  12
>>
> You could coerce the "wrong" one into a SpatialPointsDataFrame and the
> use function (method) overlay with the good grid to get the right indexes.
> --
> Edzer
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From mrufino at cripsul.ipimar.pt  Fri Feb  8 11:30:04 2008
From: mrufino at cripsul.ipimar.pt (Marta Rufino)
Date: Fri, 08 Feb 2008 10:30:04 +0000
Subject: [R-sig-Geo] cross-validation
In-Reply-To: <47AB1326.40807@uni-muenster.de>
References: <47A9FA3B.4090901@cripsul.ipimar.pt>	<47A9FEA9.8080300@uni-muenster.de>
	<47AA06B0.8090709@cripsul.ipimar.pt>
	<47AA2C8E.6080606@geo.uu.nl> <47AAD8F3.5030107@uni-muenster.de>
	<47AAF279.7010601@cripsul.ipimar.pt>
	<47AB1326.40807@uni-muenster.de>
Message-ID: <47AC2F2C.3070508@cripsul.ipimar.pt>


Excellent!

It was exactly this what I meant.
I also agree that it is not needed a function to calculate such simple 
stuff, but certainly would be desirable (and effective) to have it in 
the help file from krige.cv (to clarify the less statistically minded 
like myself :-))
I totally agree with 'desirable', instead of expected ;-)

About the 10-fold issue (thank you for the reference. It was exactly 
what I have heard about), maybe it would nice if the default was to do 
10-fold, because it is also substantially quicker to estimate. hihihi

In relation to the use of CV, I found an article that brought my 
attention to the subject again, where they compared the the mean 
estimated by kriging and sample mean through cross-validation, as a way 
to show how kriging is improving the estimates. (Sales MH, Souza JCM, 
Kyriakidis PC, Roberts DA, Vidal E (2007) Improving spatial distribution 
estimation of forest biomass with geostatistics: A case study for 
Rondonia, Brazil. Ecol Model 205:221-230). Thus this is one of the 
issues (for many users, I believe...) how to quantify/prove that kriging 
is actually doing better than other methods?
Does any one has any further alternatives?


Best wishes and thank you very much once again,
Marta


Edzer Pebesma wrote:
> Marta Rufino wrote:
>> Great!
> Hi Marta,
>
> I now have in the example section of gstat.cv help:
>
> # multivariable; thanks to M. Rufino:
> meuse.g <- gstat(id = "zn", formula = log(zinc) ~ 1, data = meuse)
> meuse.g <- gstat(meuse.g, "cu", log(copper) ~ 1, meuse)
> meuse.g <- gstat(meuse.g, model = vgm(1, "Sph", 900, 1), fill.all = T)
> x <- variogram(meuse.g, cutoff = 1000)
> meuse.fit = fit.lmc(x, meuse.g)
> out = gstat.cv(meuse.fit, nmax = 40, nfold = 5)
> summary(out)
> # mean error, ideally 0:
> mean(out$residual)
> # MSPE, ideally small
> mean(out$residual^2)
> # Mean square normalized error, ideally close to 1
> mean(out$zscore^2)
> # correlation observed and predicted, ideally 1
> cor(out$observed, out$observed - out$residual)
> # correlation predicted and residual, ideally 0
> cor(out$observed - out$residual, out$residual)
>
> I'm a bit hesitant to write a dedicated function for such simple 
> calculations. In your function below, I object to the use of 
> "expected", where you mean "desired". It's definitely not expected in 
> the statistical sense.
>
> The difficult questions about the cross validation results in 
> geostatistics are usually "can we attribute the difference of a MSNE 
> of 1.1 from the idealized value of 1 attribute to sampling error, or 
> is it an indication of a misfitting model?" In the latter case: 
> "should we worry?" (only if kriging errors are of importance, many 
> people ignore them).
>
> Also, if the data are nicely spread, say the shortest distance is 100m 
> (stay with the example above), then CV is never going to tell anything 
> about the variogram for distances up to 100m.
>
> Leave-on-out vs. n-fold? I believe Hastie, Tibshirani and Friedman 
> promote the 10-fold. The idea was that leave-one-out may be too 
> optimistic and not reveal model error, as refitted models are almost 
> identical for moderately sized or large data sets, in each fold. 
> Leave-one-out will have smaller RMSE than say 5-fold, but this is not 
> an indication of a better model nor of a substantially better 
> procedure, IMO.
>
> Best wishes,
> -- 
> Edzer
>
>>
>> This works wonderfully...maybe would be nice if you add it to the 
>> example in the help page :-)
>>
>> Further comments in /CV/... from the gstat.cv output, which 
>> cross-validation measures should be considered when establishing the 
>> performance of kriging, in relation to other methods, for example or 
>> to compare among kriging modelling options?
>>
>> I.
>> http://www.ic.arizona.edu/ic/math574/class_notes/meuse%20zinc%20vs%20logzinc%20using%20gstat.pdf 
>>
>> "Cross validation produces multiple statistics,
>> making changes to improve one statistic may make another worse. The 
>> key statistics are (1)
>> the mean error (expected value is zero), (2) mean square normalized 
>> error (in gstat and
>> several other software packages, the normalized error is called the 
>> ?zscore?). The expected
>> value of this statistic is one. (3) Ideally the correlation between 
>> the predicted value and the
>> observed value is one, however when using Ordinary kriging or 
>> Universal kriging, the
>> maximum correlation is somewhat less (because of the Lagrange 
>> multipliers). (4) Ideally the
>> correlation between the predicted value and the error (residual) is 
>> zero but again the
>> Lagrange multipliers have an effect. (5) Using Chebyshev?s Inequality 
>> we can bound the"
>>
>> Thus, they state that the important checks to do with the CV, is ():
>> 1) mean error (should ~0)
>> 2) Mean squared normalized error (should ~1)
>> 3) correlation between observed and predicted (should ~1)
>> 4) correlation between predicted and residuals (should ~0)
>>
>> out = gstat.cv(object=meuse.fit, nmax=40, nfold=5)
>> cv.results=function(x){ #function to organize CV results. x is the 
>> result of kriging Crossvalidation
>> print(bubble(x, c("residual"), main = "leave-one-out CV residuals"))
>> x=data.frame(x)
>> kk=data.frame(
>> ME=c(0,mean(x$res)),
>> MSNE=c(1,sqrt(sum(x$zscore^2)/length(x$res))),
>> cor1=c(1,cor(x$obs, x[,1])) ,
>> cor2=c(0,cor(x[,1], x$res)))
>> row.names(kk)=c("expected", "estimated")
>> return(kk)
>> }
>>
>> cv.results(out)
>>
>>
>> II
>> On another web ref. 
>> (http://www.itc.nl/personal/rossiter/teach/R/R_ck.pdf):
>> "Diagnostic measures are the ME (bias), RMSE (precision), and Mean 
>> Squared
>> Deviation Ratio (MSDR) of the residuals to the prediction errors; this
>> should be 1 because the residuals from cross-validation should equal
>> to prediction errors at each point that was held out. For the univariate
>> case (OK) we can use the krige.cv cross-validation method of the gstat
>> package."
>> Which is calculated by:
>>
>> mean(out$res) # mean error
>> sqrt(mean(out$res^2)) # RMSE
>> mean(out$res^2/as.data.frame(out)[,2]) # MSDR, should be ~1 (it is 
>> equivalent to predicted vs. sampled
>>
>>
>> So, I consulted several text books about the subject, and there was 
>> none providing a clear answer about the important measures to take 
>> int account and which sort of cross-validation performs better 
>> (although I heard that it is 10-fold CV). Does anyone has further 
>> information about this subject?
>>
>> Which measures perform best?
>> Does anyone has good references about the subject?
>>
>> Best wishes,
>> Marta
>>
>>
>> Edzer Pebesma wrote:
>>> That was not the problem, the problem was that you used meuse.g 
>>> instead of meuse.fit to pass on to gstat.cv. For meuse.g, you have 
>>> perfect correlation between Cu and Zn, so that collocated 
>>> observations (meaning a Zn and a Cu observation at each obs 
>>> location) act as a duplicate in univarite kriging.
>>>
>>> Try:
>>>
>>> out = gstat.cv(object=meuse.fit, nmax=40, verbose=F, nfold=5)
>>> -- 
>>> Edzer
>>>
>>> Paul Hiemstra wrote:
>>>> Hi,
>>>>
>>>> You should check if you have duplicate observations, duplicate 
>>>> observations lead to a singular matrix. Use the function zerodist() 
>>>> to check where the observations are and remove.duplicates() to 
>>>> remove them.
>>>>
>>>> cheers,
>>>> Paul
>>>>
>>>> Marta Rufino schreef:
>>>>> Hello,
>>>>>
>>>>> yes, I know it is suppose to do it, but I could not find how, 
>>>>> because it gives me an error... for example:
>>>>>
>>>>> require(gstat); require(lattice)
>>>>> data(meuse)
>>>>> coordinates(meuse) = ~x + y
>>>>> data(meuse.grid)
>>>>> gridded(meuse.grid) = ~x + y
>>>>>
>>>>> meuse.g <- gstat(id = "zn", formula = log(zinc) ~ 1, data = meuse)
>>>>> meuse.g <- gstat(meuse.g, "cu", log(copper) ~ 1, meuse)
>>>>>
>>>>> meuse.g <- gstat(meuse.g, model = vgm(1, "Sph", 900, 1), fill.all 
>>>>> = T)
>>>>> x <- variogram(meuse.g, cutoff = 1000)
>>>>> meuse.fit = fit.lmc(x, meuse.g)
>>>>> plot(x, model = meuse.fit)
>>>>> z <- predict(meuse.fit, newdata = meuse.grid)
>>>>> spplot(z) #map
>>>>> gstat.cv(meuse.g) #does not work...
>>>>> gstat.cv(meuse.g, remove.all=T) #either
>>>>> gstat.cv(meuse.g, all.residuals=T) #either
>>>>> gstat.cv(object=meuse.g, formula = log(zinc) ~ 1, data = meuse, 
>>>>> model = vgm(1, "Sph", 900, 1), nmax=40, verbose=F) #either :-(
>>>>>
>>>>> # # Intrinsic Correlation found. Good.
>>>>> # [using ordinary cokriging]
>>>>>
>>>>> # "chfactor.c", line 130: singular matrix in function LDLfactor()
>>>>> # Error in predict.gstat(object, newdata = data[sel, ], ...) :
>>>>> # LDLfactor
>>>>>
>>>>> Maybe an example on the help file would be nice (eheheh).. I
>>>>> What am I missing?
>>>>>
>>>>>
>>>>> Thank you very much in advance,
>>>>> Marta
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>
>>>
>>>
>>>
>>
>> -- 
>> .......................................................................
>> Marta M. Rufino (PhD)
>>
>> .....
>> Instituto Nacional de Investiga??o Agr?ria e das Pescas (INIAP/IPIMAR),
>> Centro Regional de Investiga??o Pesqueira do Sul (CRIPSul)
>> Avenida 5 de Outubro s/n
>> P-8700-305 Olh?o, Portugal
>> +351 289 700 541
>>
>> ..... Institut de Ci?ncies del Mar - CMIMA (CSIC)
>> Passeig Mar?tim de la Barceloneta, 37-49 08003 BARCELONA - Catalunya
>> Spain
>>
>>
>>
>
>
>

-- 
.......................................................................
Marta M. Rufino (PhD)

.....
Instituto Nacional de Investiga??o Agr?ria e das Pescas (INIAP/IPIMAR),
Centro Regional de Investiga??o Pesqueira do Sul (CRIPSul)
Avenida 5 de Outubro s/n
P-8700-305 Olh?o, Portugal
+351 289 700 541

..... 
Institut de Ci?ncies del Mar - CMIMA (CSIC)
Passeig Mar?tim de la Barceloneta, 37-49      
08003 BARCELONA - Catalunya
Spain



From milton_ruser at yahoo.com.br  Fri Feb  8 16:14:01 2008
From: milton_ruser at yahoo.com.br (Milton Cezar Ribeiro)
Date: Fri, 8 Feb 2008 07:14:01 -0800 (PST)
Subject: [R-sig-Geo] attribing x-coordinates to map cells
Message-ID: <469422.41554.qm@web56004.mail.re3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080208/b41e0004/attachment.pl>

From cavallini at faunalia.it  Fri Feb  8 16:17:42 2008
From: cavallini at faunalia.it (Paolo Cavallini)
Date: Fri, 08 Feb 2008 16:17:42 +0100
Subject: [R-sig-Geo] installing sp
Message-ID: <47AC7296.9000203@faunalia.it>

Sorry about my ignorance. I'm trying to install sp on a Debian testing
machine, but I get:
=======================================================
> install.packages(c("sp"), dependencies=TRUE,
repos="http://cran.cnr.berkeley.edu/")
Warning in install.packages(c("sp"), dependencies = TRUE, repos =
"http://cran.cnr.berkeley.edu/") :
  argument 'lib' is missing: using '/usr/local/lib/R/site-library'
provo con l'URL 'http://cran.cnr.berkeley.edu/src/contrib/sp_0.9-19.tar.gz'
Content type 'application/x-gzip' length 350803 bytes (342 Kb)
URL aperto
==================================================
downloaded 342 Kb

/usr/local/lib/R/site-library
* Installing *source* package 'sp' ...
** libs
gcc -std=gnu99 -I/usr/share/R/include -I/usr/share/R/include      -fpic
 -g -O2 -c gcdist.c -o gcdist.o
gcc -std=gnu99 -I/usr/share/R/include -I/usr/share/R/include      -fpic
 -g -O2 -c init.c -o init.o
gcc -std=gnu99 -I/usr/share/R/include -I/usr/share/R/include      -fpic
 -g -O2 -c pip2.c -o pip2.o
gcc -std=gnu99 -I/usr/share/R/include -I/usr/share/R/include      -fpic
 -g -O2 -c pip.c -o pip.o
gcc -std=gnu99 -I/usr/share/R/include -I/usr/share/R/include      -fpic
 -g -O2 -c Rcentroid.c -o Rcentroid.o
gcc -std=gnu99 -I/usr/share/R/include -I/usr/share/R/include      -fpic
 -g -O2 -c zerodist.c -o zerodist.o
gcc -std=gnu99 -shared  -o sp.so gcdist.o init.o pip2.o pip.o
Rcentroid.o zerodist.o   -L/usr/lib/R/lib -lR
** R
** data
** demo
** inst
** preparing package for lazy loading
Error in importIntoEnv(impenv, impnames, ns, impvars) :
  object ''panel.number'' is not exported by 'namespace:lattice'
Calls: <Anonymous> ... loadNamespace -> namespaceImportFrom -> importIntoEnv
Execution halted
ERROR: lazy loading failed for package 'sp'
** Removing '/usr/local/lib/R/site-library/sp'
** Restoring previous '/usr/local/lib/R/site-library/sp'
=======================================================
Any idea?
All the best.
pc
-- 
Paolo Cavallini, see: http://www.faunalia.it/pc



From jashonder at gmail.com  Fri Feb  8 16:27:22 2008
From: jashonder at gmail.com (John Shonder)
Date: Fri, 8 Feb 2008 10:27:22 -0500
Subject: [R-sig-Geo] Updating county map in maps package
Message-ID: <c226c9f70802080727l39514b80u3a42f35fc1f5f252@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080208/a11f594c/attachment.pl>

From cavallini at faunalia.it  Fri Feb  8 17:39:41 2008
From: cavallini at faunalia.it (Paolo Cavallini)
Date: Fri, 08 Feb 2008 17:39:41 +0100
Subject: [R-sig-Geo] maptools manual
In-Reply-To: <47AC7296.9000203@faunalia.it>
References: <47AC7296.9000203@faunalia.it>
Message-ID: <47AC85CD.5090508@faunalia.it>

The manual for maptools is cut (several lines are longer than the page
width, eg at page 39). Difficult to read...
All the best.
pc
-- 
Paolo Cavallini, see: http://www.faunalia.it/pc



From cavallini at faunalia.it  Fri Feb  8 18:10:12 2008
From: cavallini at faunalia.it (Paolo Cavallini)
Date: Fri, 08 Feb 2008 18:10:12 +0100
Subject: [R-sig-Geo] installing sp
In-Reply-To: <47AC7296.9000203@faunalia.it>
References: <47AC7296.9000203@faunalia.it>
Message-ID: <47AC8CF4.9060701@faunalia.it>

Paolo Cavallini ha scritto:
> Sorry about my ignorance. I'm trying to install sp on a Debian testing
> machine, but I get:
> =======================================================
>> install.packages(c("sp"), dependencies=TRUE,

Solved by purging all R installation, removing
/usr/local/lib/R/site-library and reinstalling.
Ugly, but it worked.
Sorry for bothering.
All the best.
pc
-- 
Paolo Cavallini, see: http://www.faunalia.it/pc



From loecher at eden.rutgers.edu  Fri Feb  8 20:19:03 2008
From: loecher at eden.rutgers.edu (Markus Loecher)
Date: Fri, 8 Feb 2008 14:19:03 -0500 (EST)
Subject: [R-sig-Geo] "paint" transparent rectangle over line plot
Message-ID: <15884479.13651202498340274.JavaMail.tomcat@aveo>

Dear list members,
I have created a psp object (spatstat library) and can draw these lines easily with the plotLines() function.
However, I want to create a "fading away" effect by drawing line by line in some temporal order and in between each drawing overpaint a rectangle with a low value for transparency.
Is that possible ?

Thanks !

Markus



From Roger.Bivand at nhh.no  Sat Feb  9 12:38:15 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 9 Feb 2008 12:38:15 +0100 (CET)
Subject: [R-sig-Geo] Updating county map in maps package
In-Reply-To: <c226c9f70802080727l39514b80u3a42f35fc1f5f252@mail.gmail.com>
References: <c226c9f70802080727l39514b80u3a42f35fc1f5f252@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0802091231430.28044@reclus.nhh.no>

On Fri, 8 Feb 2008, John Shonder wrote:

> Does anyone know how to update the map of US counties that is included with
> the maps package? The included map is outdated, and is missing several newer
> counties in various states. The cartographic boundary files from the 2000
> census are available at http://www.census.gov/geo/www/cob/bdy_files.html but
> I find no documentation on how to get these into the maps package.

See the two research reports referred to in for example the help page to 
map():

      Richard A. Becker, and Allan R. Wilks, "Maps in S", _AT&T Bell
      Laboratories Statistics Research Report [93.2], 1993._ <URL:
      http://public.research.att.com/areas/stat/doc/93.2.ps>

      Richard A. Becker, and Allan R. Wilks, "Constructing a
      Geographical Database", _AT&T Bell Laboratories Statistics
      Research Report [95.2], 1995._ <URL:
      http://public.research.att.com/areas/stat/doc/95.2.ps>

both of which are online. You need to break all of the polygons into x0,y0 
and x1,y1 line segments, and clean the topologies, building the databases 
from the input data. It appears that some of the contributed map data has 
not been broken down to elemental components, so there may be an easier 
way. Finding out which output geometries are which is an additional 
challenge.

It might be possible to output the segments or other intermediate text 
files from maptools, contributions welcome.

Roger

>
> I have had success reading the 2000 shape files with maptools, but for
> various reasons I find the maps package more convenient.
>
> I appreciate any assistance, thanks.
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Sat Feb  9 18:25:51 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 9 Feb 2008 18:25:51 +0100 (CET)
Subject: [R-sig-Geo] attribing x-coordinates to map cells
In-Reply-To: <469422.41554.qm@web56004.mail.re3.yahoo.com>
References: <469422.41554.qm@web56004.mail.re3.yahoo.com>
Message-ID: <Pine.LNX.4.64.0802091813140.28044@reclus.nhh.no>

On Fri, 8 Feb 2008, Milton Cezar Ribeiro wrote:

> Dear all,
>
> I have some ascii/grid files and I would like to save the x-coordinates into a new ascii/grid cells with the same dimentions that my input map. Below follow a temptative code.
>
> (file1 <-  paste(system.file(package = "adehabitat"),
>               "ascfiles/elevation.asc", sep = "/"))
> el <- import.asc(file1)
> image(el)
> ##el.xcoord<-  ### here is what I need

Roughly, using the sp SpatialGridDataFrame class:

library(adehabitat)
(file1 <-  paste(system.file(package = "adehabitat"),
                "ascfiles/elevation.asc", sep = "/"))
el <- import.asc(file1)
image(el)
library(sp)
cd <- dim(el)
cs <- rep(attr(el, "cellsize"), 2)
co <- c(attr(el, "xll"), attr(el, "yll"))
grd <- GridTopology(co, cs, cd)
SGDF <- SpatialGridDataFrame(grd,
   data=data.frame(asc=as.vector(el[,ncol(el):1])))
image(SGDF, "asc")
SGDF$x <- coordinates(SGDF)[,1]
co1 <- slot(slot(SGDF, "grid"), "cellcentre.offset")
el1 <- as.asc(as.matrix(SGDF["x"]), xll=co1[1], yll=co1[2],
   type="numeric")
image(el1)

If you only need the x coordinates of the non-missing cells, use the 
SpatialPixelsDataFrame class in addition. I guess that you could get there 
directly too.

Roger

>
> Kind regards,
>
> Miltinho
>
>
>
> para armazenamento!
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Sat Feb  9 19:30:35 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 9 Feb 2008 19:30:35 +0100 (CET)
Subject: [R-sig-Geo] attribing x-coordinates to map cells
In-Reply-To: <Pine.LNX.4.64.0802091813140.28044@reclus.nhh.no>
References: <469422.41554.qm@web56004.mail.re3.yahoo.com>
	<Pine.LNX.4.64.0802091813140.28044@reclus.nhh.no>
Message-ID: <Pine.LNX.4.64.0802091925540.28044@reclus.nhh.no>

On Sat, 9 Feb 2008, Roger Bivand wrote:

> On Fri, 8 Feb 2008, Milton Cezar Ribeiro wrote:
>
>> Dear all,
>>
>> I have some ascii/grid files and I would like to save the x-coordinates into a new ascii/grid cells with the same dimentions that my input map. Below follow a temptative code.
>>
>> (file1 <-  paste(system.file(package = "adehabitat"),
>>               "ascfiles/elevation.asc", sep = "/"))
>> el <- import.asc(file1)
>> image(el)
>> ##el.xcoord<-  ### here is what I need
>
> Roughly, using the sp SpatialGridDataFrame class:
>
> library(adehabitat)
> (file1 <-  paste(system.file(package = "adehabitat"),
>                "ascfiles/elevation.asc", sep = "/"))
> el <- import.asc(file1)
> image(el)
> library(sp)
> cd <- dim(el)
> cs <- rep(attr(el, "cellsize"), 2)
> co <- c(attr(el, "xll"), attr(el, "yll"))
> grd <- GridTopology(co, cs, cd)
> SGDF <- SpatialGridDataFrame(grd,
>   data=data.frame(asc=as.vector(el[,ncol(el):1])))
> image(SGDF, "asc")
> SGDF$x <- coordinates(SGDF)[,1]
> co1 <- slot(slot(SGDF, "grid"), "cellcentre.offset")
> el1 <- as.asc(as.matrix(SGDF["x"]), xll=co1[1], yll=co1[2],
>   type="numeric")
> image(el1)

A correction to coercion from SGDF to asc which wasn't obvious in the 
example, but is so if we convert the input data, rather than the 
coordinate values; here we need:

co1 <- slot(slot(SGDF, "grid"), "cellcentre.offset")
cs1 <- slot(slot(SGDF, "grid"), "cellsize")[1]
M <- as.matrix(SGDF["asc"])
el1 <- as.asc(M[,ncol(M):1], xll=co1[1], yll=co1[2], cellsize=cs1,
  type="numeric")
all.equal(el, el1)

Roger

>
> If you only need the x coordinates of the non-missing cells, use the
> SpatialPixelsDataFrame class in addition. I guess that you could get there
> directly too.
>
> Roger
>
>>
>> Kind regards,
>>
>> Miltinho
>>
>>
>>
>> para armazenamento!
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From jo.irisson at gmail.com  Sat Feb  9 22:04:44 2008
From: jo.irisson at gmail.com (jiho)
Date: Sat, 9 Feb 2008 22:04:44 +0100
Subject: [R-sig-Geo] Comparing spatial point patterns - Syrjala test
Message-ID: <E4BEA71D-D338-4B5E-8BB5-AEE22C8E1151@gmail.com>

Dear Lists,

At several stations distributed regularly in space[1], we sampled  
repeatedly (4 times) the abundance of organisms and measured  
environmental parameters. I now want to compare the spatial  
distribution of various species (and test wether they differ or not),  
or to compare the distribution of a particular organism with the  
distribution of some environmental variable.
Syrjala's test[2] seems to be appropriate for such comparisons. The  
hamming distance is also used (but it is not associated with a test).  
However, as far as I understand it, Syrjala's test only compares the  
distribution gathered during one sampling event, while I have four  
successive repeats and:
- I am interested in comparing if, on average, the distributions are  
the same
- I would prefer to keep the information regarding the variability of  
the abundances in time, rather than just comparing the means, since  
the abundances are quite variable.

Therefore I have two questions for all the knowledgeable R users on  
these lists:
- Is there a package in which Syrjala's test is implemented for R?
- Is there another way (a better way) to test for such differences?

Thank you very much in advance for your help.

[1] http://jo.irisson.free.fr/work/research_tetiaroa.html
[2] http://findarticles.com/p/articles/mi_m2120/is_n1_v77/ai_18066337/pg_7

Jean-Olivier Irisson
---
UMR 5244 CNRS-EPHE-UPVD, 52 av Paul Alduy, 66860 Perpignan Cedex, France
+336 21 05 19 90
http://jo.irisson.free.fr/work/



From milton.ruser at gmail.com  Sat Feb  9 22:39:30 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Sat, 9 Feb 2008 18:39:30 -0300
Subject: [R-sig-Geo] Comparing spatial point patterns - Syrjala test
In-Reply-To: <E4BEA71D-D338-4B5E-8BB5-AEE22C8E1151@gmail.com>
References: <E4BEA71D-D338-4B5E-8BB5-AEE22C8E1151@gmail.com>
Message-ID: <3aaf1a030802091339w17011db5yf26ee4f5431d5e6c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080209/d418aac3/attachment.pl>

From jo.irisson at gmail.com  Sun Feb 10 08:20:32 2008
From: jo.irisson at gmail.com (jiho)
Date: Sun, 10 Feb 2008 08:20:32 +0100
Subject: [R-sig-Geo] Comparing spatial point patterns - Syrjala test
In-Reply-To: <3aaf1a030802091339w17011db5yf26ee4f5431d5e6c@mail.gmail.com>
References: <E4BEA71D-D338-4B5E-8BB5-AEE22C8E1151@gmail.com>
	<3aaf1a030802091339w17011db5yf26ee4f5431d5e6c@mail.gmail.com>
Message-ID: <70b8e7670802092320k174250b5qde0919c4c95fbce@mail.gmail.com>

On Feb 9, 2008 10:39 PM, milton ruser <milton.ruser at gmail.com> wrote:
> I have no idea of how to solve this issue, but I suggest you write to the
> authors of spatstat package. I think they could help you very much. Another
> thing is that there was a threhead on this many times ago. May be that Alan
> Swanson cold also help you.
>
> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/51226.html

Thank you for your answer. Indeed I saw this email during my research
before posting my message. Unfortunately nobody answered it. I just
hoped that things may have improved in this area of R since then and
that potential authors, such as authors of the spatstat package, would
be reading these lists.
I will contact those people personally indeed.

Thanks again.

> > At several stations distributed regularly in space[1], we sampled
> > repeatedly (4 times) the abundance of organisms and measured
> > environmental parameters. I now want to compare the spatial
> > distribution of various species (and test wether they differ or not),
> > or to compare the distribution of a particular organism with the
> > distribution of some environmental variable.
> > Syrjala's test[2] seems to be appropriate for such comparisons. The
> > hamming distance is also used (but it is not associated with a test).
> > However, as far as I understand it, Syrjala's test only compares the
> > distribution gathered during one sampling event, while I have four
> > successive repeats and:
> > - I am interested in comparing if, on average, the distributions are
> > the same
> > - I would prefer to keep the information regarding the variability of
> > the abundances in time, rather than just comparing the means, since
> > the abundances are quite variable.
> >
> > Therefore I have two questions for all the knowledgeable R users on
> > these lists:
> > - Is there a package in which Syrjala's test is implemented for R?
> > - Is there another way (a better way) to test for such differences?
> >
> > Thank you very much in advance for your help.
> >
> > [1] http://jo.irisson.free.fr/work/research_tetiaroa.html
> > [2] http://findarticles.com/p/articles/mi_m2120/is_n1_v77/ai_18066337/pg_7

-- 
Jean-Olivier Irisson
UMR 5244 CNRS-EPHE-UPVD, 52 av Paul Alduy, 66860 Perpignan Cedex, France
+336 21 05 19 90
http://jo.irisson.free.fr/work/



From bayesianlogic at acm.org  Sun Feb 10 17:02:39 2008
From: bayesianlogic at acm.org (Jan Theodore Galkowski)
Date: Sun, 10 Feb 2008 11:02:39 -0500
Subject: [R-sig-Geo] Comparing spatial point patterns - Syrjala
In-Reply-To: <mailman.5.1202641201.8528.r-sig-geo@stat.math.ethz.ch>
References: <mailman.5.1202641201.8528.r-sig-geo@stat.math.ethz.ch>
Message-ID: <1202659359.30140.1236060985@webmail.messagingengine.com>

I'm also interested here in comparing spatial point patterns.  So, if
anyone finds any further R-based, or S-plus-based work on the matter, or
any more recent references, might you please include me in the
distribution list?  

Thanks much!

  - Jan

  
--
#
# Jan Theodore Galkowski
# Senior Software Engineer
# Akamai Technologies
# Cambridge, MA 02142
#
# jgalkows at akamai.com
# bayesianlogic at acm.org
#
# 607.239.1834 (m)
# 617.547.1221 (h)
# 617.444.4995 (w)
#



From milton.ruser at gmail.com  Sun Feb 10 18:20:23 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Sun, 10 Feb 2008 14:20:23 -0300
Subject: [R-sig-Geo] Comparing spatial point patterns - Syrjala
In-Reply-To: <1202659359.30140.1236060985@webmail.messagingengine.com>
References: <mailman.5.1202641201.8528.r-sig-geo@stat.math.ethz.ch>
	<1202659359.30140.1236060985@webmail.messagingengine.com>
Message-ID: <3aaf1a030802100920n6a302eeq330f00d773f1bf5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080210/5a42170c/attachment.pl>

From jo.irisson at gmail.com  Sun Feb 10 19:30:03 2008
From: jo.irisson at gmail.com (jiho)
Date: Sun, 10 Feb 2008 19:30:03 +0100
Subject: [R-sig-Geo] [R] Comparing spatial point patterns - Syrjala test
In-Reply-To: <1202659359.30140.1236060985@webmail.messagingengine.com>
References: <mailman.5.1202641201.8528.r-sig-geo@stat.math.ethz.ch>
	<1202659359.30140.1236060985@webmail.messagingengine.com>
Message-ID: <DDDEA575-82FC-4472-BF34-37973BB4EDFA@gmail.com>

Hi,

I went ahead and implemented something. However:
- I cannot garantie it gives correct results since, unfortunately, the  
data used in Syrjala 1996 is not published along with the paper. To  
avoid mistakes, I started by coding things in a fast and simple way  
and then tried to optimize the code. At least all versions given the  
same results.
- As expected, the test is still quite slow since it relies on  
permutations to compute the p.value. The successive optimizations  
allowed to go from 73 to 13 seconds on my machine, but 13 seconds is  
still a long time. Furthermore, I don't know how the different  
versions would scale according to the number of points (I only tested  
with one dataset). I'm not very good at "thinking vector" so if  
someone could look at this and further improve it, I would welcome  
patches. Maybe the only real solution would be to go the Fortran way  
and link some code to R, but I did not want to wander in such scary  
places ;)

The code and test data is here:
	http://cbetm.univ-perp.fr/irisson/svn/distribution_data/tetiaroa/trunk/data/lib_spatial.R
Warning: it probably uses non canonical S syntax, sorry for those with  
sensitive eyes.

On 2008-February-10  , at 17:02 , Jan Theodore Galkowski wrote:
> I'm also interested here in comparing spatial point patterns.  So, if
> anyone finds any further R-based, or S-plus-based work on the  
> matter, or
> any more recent references, might you please include me in the
> distribution list?
>
> Thanks much!


Begin forwarded message:
> From: jiho <jo.irisson at gmail.com>
> Subject: Comparing spatial point patterns - Syrjala test
>
> Dear Lists,
>
> At several stations distributed regularly in space[1], we sampled  
> repeatedly (4 times) the abundance of organisms and measured  
> environmental parameters. I now want to compare the spatial  
> distribution of various species (and test wether they differ or  
> not), or to compare the distribution of a particular organism with  
> the distribution of some environmental variable.
> Syrjala's test[2] seems to be appropriate for such comparisons. The  
> hamming distance is also used (but it is not associated with a  
> test). However, as far as I understand it, Syrjala's test only  
> compares the distribution gathered during one sampling event, while  
> I have four successive repeats and:
> - I am interested in comparing if, on average, the distributions are  
> the same
> - I would prefer to keep the information regarding the variability  
> of the abundances in time, rather than just comparing the means,  
> since the abundances are quite variable.
>
> Therefore I have two questions for all the knowledgeable R users on  
> these lists:
> - Is there a package in which Syrjala's test is implemented for R?
> - Is there another way (a better way) to test for such differences?
>
> Thank you very much in advance for your help.
>
> [1] http://jo.irisson.free.fr/work/research_tetiaroa.html
> [2] http://findarticles.com/p/articles/mi_m2120/is_n1_v77/ai_18066337/pg_7


JiHO
---
http://jo.irisson.free.fr/



From bayesianlogic at acm.org  Sun Feb 10 23:35:59 2008
From: bayesianlogic at acm.org (Jan Theodore Galkowski)
Date: Sun, 10 Feb 2008 17:35:59 -0500
Subject: [R-sig-Geo] Comparing spatial point patterns - Syrjala test
In-Reply-To: <DDDEA575-82FC-4472-BF34-37973BB4EDFA@gmail.com>
References: <mailman.5.1202641201.8528.r-sig-geo@stat.math.ethz.ch>
	<1202659359.30140.1236060985@webmail.messagingengine.com>
	<DDDEA575-82FC-4472-BF34-37973BB4EDFA@gmail.com>
Message-ID: <1202682959.31037.1236102977@webmail.messagingengine.com>

There is this,

  "Analysis of Variance for Replicated Spatial Point Patterns in
  Clinical Neuroanatomy",
  PETER J DIGGLE, NICHOLAS LANGE, and FRANCINE M BENES, September 1991
  JASA, 
  Vol 86, No 415, pp 618 625



From jo.irisson at gmail.com  Mon Feb 11 09:44:29 2008
From: jo.irisson at gmail.com (jiho)
Date: Mon, 11 Feb 2008 09:44:29 +0100
Subject: [R-sig-Geo] Comparing spatial point patterns - Syrjala test
In-Reply-To: <1202682959.31037.1236102977@webmail.messagingengine.com>
References: <mailman.5.1202641201.8528.r-sig-geo@stat.math.ethz.ch>
	<1202659359.30140.1236060985@webmail.messagingengine.com>
	<DDDEA575-82FC-4472-BF34-37973BB4EDFA@gmail.com>
	<1202682959.31037.1236102977@webmail.messagingengine.com>
Message-ID: <6C3B0C5A-70A3-4EBE-AE5A-2B7FBE65BFE9@gmail.com>

On 2008-February-10  , at 23:35 , Jan Theodore Galkowski wrote:
> There is this,
>
>  "Analysis of Variance for Replicated Spatial Point Patterns in
>  Clinical Neuroanatomy",
>  PETER J DIGGLE, NICHOLAS LANGE, and FRANCINE M BENES, September 1991
>  JASA,
>  Vol 86, No 415, pp 618 625


Thank you very much for this reference. However the problem it is  
dealing with is not really similar to the one I target. In this paper  
the authors assess the differences in positions of neurones in a 2D  
plane between three groups of patients, with replicates in each group.  
So the data of interest are the coordinates.
In my case, the positions of sampling stations are fixed (and on a  
grid if that helps [1]) and I want to assess the differences in  
abundances of two groups at these positions. So the data of interest  
are the abundances (normalized to remove the effect of total  
population sizes), and more specifically, the way the abundances are  
distributed on these points. Maybe the subject of this email is not  
correctly stated then. I am not a native english speaker and when it  
comes to technical terms, it is even worse.

Anyhow, I hope this email clarifies things.

[1] http://jo.irisson.free.fr/work/research/far.png

Jean-Olivier Irisson
---
UMR 5244 CNRS-EPHE-UPVD, 52 av Paul Alduy, 66860 Perpignan Cedex, France
+336 21 05 19 90
http://jo.irisson.free.fr/work/



From b.rowlingson at lancaster.ac.uk  Mon Feb 11 10:19:02 2008
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 11 Feb 2008 09:19:02 +0000
Subject: [R-sig-Geo] Comparing spatial point patterns - Syrjala test
In-Reply-To: <6C3B0C5A-70A3-4EBE-AE5A-2B7FBE65BFE9@gmail.com>
References: <mailman.5.1202641201.8528.r-sig-geo@stat.math.ethz.ch>	<1202659359.30140.1236060985@webmail.messagingengine.com>	<DDDEA575-82FC-4472-BF34-37973BB4EDFA@gmail.com>	<1202682959.31037.1236102977@webmail.messagingengine.com>
	<6C3B0C5A-70A3-4EBE-AE5A-2B7FBE65BFE9@gmail.com>
Message-ID: <47B01306.5030800@lancaster.ac.uk>

jiho wrote:

> Thank you very much for this reference. However the problem it is  
> dealing with is not really similar to the one I target. In this paper  
> the authors assess the differences in positions of neurones in a 2D  
> plane between three groups of patients, with replicates in each group.  
> So the data of interest are the coordinates.
> In my case, the positions of sampling stations are fixed (and on a  
> grid if that helps [1]) and I want to assess the differences in  
> abundances of two groups at these positions. So the data of interest  
> are the abundances (normalized to remove the effect of total  
> population sizes), and more specifically, the way the abundances are  
> distributed on these points. Maybe the subject of this email is not  
> correctly stated then. I am not a native english speaker and when it  
> comes to technical terms, it is even worse.
> 

  "Spatial Point Pattern Analysis" only refers to cases where the 
locations of the points are 'interesting', which usually means they are 
generated by a stochastic process - like tree locations in a natural 
forest rather than rows of trees in a plantation.

  Analysis of data that comes from spatial locations that are 
'uninteresting' are another branch of statistics altogether. It will 
probably end up being generalised linear modelling with 
spatially-correlated errors, and how you deal with the correlations is 
the interesting part.

  See if you can write down a model for your data and include a 
smoothly-varying spatial error term.... Then maybe we can find some R 
code to solve it. I don't think we'll find it in Spatstat, which I think 
is still exclusively spatial point pattern analysis. Have a look at 
geoRglm maybe...

Barry



From irisson at normalesup.org  Mon Feb 11 11:09:50 2008
From: irisson at normalesup.org (Jean-Olivier Irisson)
Date: Mon, 11 Feb 2008 11:09:50 +0100
Subject: [R-sig-Geo] Comparing abundances at fixed locations in space -
	Syrjala test
In-Reply-To: <47B01306.5030800@lancaster.ac.uk>
References: <mailman.5.1202641201.8528.r-sig-geo@stat.math.ethz.ch>	<1202659359.30140.1236060985@webmail.messagingengine.com>	<DDDEA575-82FC-4472-BF34-37973BB4EDFA@gmail.com>	<1202682959.31037.1236102977@webmail.messagingengine.com>
	<6C3B0C5A-70A3-4EBE-AE5A-2B7FBE65BFE9@gmail.com>
	<47B01306.5030800@lancaster.ac.uk>
Message-ID: <EADECA0B-2027-491B-92E7-978CF5348096@normalesup.org>


On 2008-February-11  , at 10:19 , Barry Rowlingson wrote:
> jiho wrote:
>> Thank you very much for this reference. However the problem it is   
>> dealing with is not really similar to the one I target. In this  
>> paper  the authors assess the differences in positions of neurones  
>> in a 2D  plane between three groups of patients, with replicates in  
>> each group.  So the data of interest are the coordinates.
>> In my case, the positions of sampling stations are fixed (and on a   
>> grid if that helps [1]) and I want to assess the differences in   
>> abundances of two groups at these positions. So the data of  
>> interest  are the abundances (normalized to remove the effect of  
>> total  population sizes), and more specifically, the way the  
>> abundances are  distributed on these points. Maybe the subject of  
>> this email is not  correctly stated then. I am not a native english  
>> speaker and when it  comes to technical terms, it is even worse.
>
> "Spatial Point Pattern Analysis" only refers to cases where the  
> locations of the points are 'interesting', which usually means they  
> are generated by a stochastic process - like tree locations in a  
> natural forest rather than rows of trees in a plantation.

Thanks for clarifying these terms. Indeed I am _not_ after spatial  
point pattern techniques. I changed the subject accordingly.

> Analysis of data that comes from spatial locations that are  
> 'uninteresting' are another branch of statistics altogether. It will  
> probably end up being generalised linear modelling with spatially- 
> correlated errors, and how you deal with the correlations is the  
> interesting part.
>
> See if you can write down a model for your data and include a  
> smoothly-varying spatial error term.... Then maybe we can find some  
> R code to solve it. I don't think we'll find it in Spatstat, which I  
> think is still exclusively spatial point pattern analysis. Have a  
> look at geoRglm maybe...

Thank you for the pointer. The vignette of geoRglm seems promising,  
though much is about prediction from a given model while I am most  
interested in which terms are in the model, i.e. which variables have  
a notable influence on the repartition of the organisms. My scenario  
seems simpler than those presented however, since the data are  
standardized by the sampling effort, meaning that the same Poisson law  
applies to all points.

A continuous variable than would represent the spatiality in this  
dataset could simply be the distance from the lower-left corner of the  
sampling grid for example, or the distance from the island around  
which the sampling grid is designed (such a distance would have a  
biological meaning since we expect the abundances to be inversely  
proportional to it). Is that something that could fit your definition  
of a "smoothly-varying spatial error term" or am I completely mistaken?

Your answer and the vignette of geoRglm highlight how little I know  
about all this (I am just a young biologist after all) and how much  
reading I need to do. The page of geoRglm has a nice list of  
publications:
	http://www.daimi.au.dk/~olefc/geoRglm/Intro/books.html
Could you (or someone else) direct me towards the best introductory  
text(s) on this matter please?

Thank you very much for your help.

Jean-Olivier Irisson
---
UMR 5244 CNRS-EPHE-UPVD, 52 av Paul Alduy, 66860 Perpignan Cedex, France
+336 21 05 19 90
http://jo.irisson.free.fr/work/



From b.rowlingson at lancaster.ac.uk  Mon Feb 11 11:46:37 2008
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 11 Feb 2008 10:46:37 +0000
Subject: [R-sig-Geo] Comparing abundances at fixed locations in space -
 Syrjala test
In-Reply-To: <EADECA0B-2027-491B-92E7-978CF5348096@normalesup.org>
References: <mailman.5.1202641201.8528.r-sig-geo@stat.math.ethz.ch>	<1202659359.30140.1236060985@webmail.messagingengine.com>	<DDDEA575-82FC-4472-BF34-37973BB4EDFA@gmail.com>	<1202682959.31037.1236102977@webmail.messagingengine.com>
	<6C3B0C5A-70A3-4EBE-AE5A-2B7FBE65BFE9@gmail.com>
	<47B01306.5030800@lancaster.ac.uk>
	<EADECA0B-2027-491B-92E7-978CF5348096@normalesup.org>
Message-ID: <47B0278D.7090203@lancaster.ac.uk>

Jean-Olivier Irisson wrote:

> Thank you for the pointer. The vignette of geoRglm seems promising, 
> though much is about prediction from a given model while I am most 
> interested in which terms are in the model, i.e. which variables have a 
> notable influence on the repartition of the organisms. My scenario seems 
> simpler than those presented however, since the data are standardized by 
> the sampling effort, meaning that the same Poisson law applies to all 
> points.

  I think you still need to fit a model, and then you can test how 
useful your covariates are with standard techniques.

> A continuous variable than would represent the spatiality in this 
> dataset could simply be the distance from the lower-left corner of the 
> sampling grid for example, or the distance from the island around which 
> the sampling grid is designed (such a distance would have a biological 
> meaning since we expect the abundances to be inversely proportional to 
> it). Is that something that could fit your definition of a 
> "smoothly-varying spatial error term" or am I completely mistaken?

  Think about fitting a straight line through some points. You find the 
line that best fits your points. Then you look at the residual 
differences between the line and your points. All the usual linear model 
theory about predictions and significance depends on those residuals 
being uncorrelated and independent. If you are fitting a straight line 
to a curve then that won't be true, and if you then say something about 
your straight line based on the linear model theory you'll be wrong.

  Now, you could fit a non-spatial generalised linear model to your data 
using glm() in R and then map the residuals. If the residual map shows 
structure, then there's something else going on that your model hasn't 
accounted for. Perhaps there is an obvious trend due to a covariate 
you've not included, such as elevation above sea level. You could then 
add this to your model. If the residual surface looks like random noise 
then you can use standard linear model theory to make conclusions about 
your covariate parameters.

  If the residual surface doesn't look like random noise then that's 
when you get into geoRglm functions which (I think) fit a GLM where the 
error surface (that's your residuals) is defined by a gaussian random 
field with a fitted covariance structure. Once that's done, the geoRglm 
code will tell you about your covariate parameter significance (I think! 
It's been a while since I've used it. Maybe Paulo and Ole can expand on 
this).

  So what I'd do is:

  * fit a simple GLM using glm.
  * Look at parameter estimates and significance.
  * Draw a map of residuals.
  * Then worry about spatial correlation.

  Oh, I'd also, if I were you, try and find a local statistician expert!

Barry



From jo.irisson at gmail.com  Mon Feb 11 12:26:04 2008
From: jo.irisson at gmail.com (jiho)
Date: Mon, 11 Feb 2008 12:26:04 +0100
Subject: [R-sig-Geo] Comparing abundances at fixed locations in space -
	Syrjala test
In-Reply-To: <47B0278D.7090203@lancaster.ac.uk>
References: <mailman.5.1202641201.8528.r-sig-geo@stat.math.ethz.ch>	<1202659359.30140.1236060985@webmail.messagingengine.com>	<DDDEA575-82FC-4472-BF34-37973BB4EDFA@gmail.com>	<1202682959.31037.1236102977@webmail.messagingengine.com>
	<6C3B0C5A-70A3-4EBE-AE5A-2B7FBE65BFE9@gmail.com>
	<47B01306.5030800@lancaster.ac.uk>
	<EADECA0B-2027-491B-92E7-978CF5348096@normalesup.org>
	<47B0278D.7090203@lancaster.ac.uk>
Message-ID: <F0F5EA4A-2C19-4D1D-AC41-439E127788AD@gmail.com>

I start by reposting my previous message which was sent from a  
different address and therefore probably did not reach the list. Sorry  
about this:

> On 2008-February-11  , at 10:19 , Barry Rowlingson wrote:
>> jiho wrote:
>>> Thank you very much for this reference. However the problem it is   
>>> dealing with is not really similar to the one I target. In this  
>>> paper  the authors assess the differences in positions of neurones  
>>> in a 2D  plane between three groups of patients, with replicates  
>>> in each group.  So the data of interest are the coordinates.
>>> In my case, the positions of sampling stations are fixed (and on  
>>> a  grid if that helps [1]) and I want to assess the differences  
>>> in  abundances of two groups at these positions. So the data of  
>>> interest  are the abundances (normalized to remove the effect of  
>>> total  population sizes), and more specifically, the way the  
>>> abundances are  distributed on these points. Maybe the subject of  
>>> this email is not  correctly stated then. I am not a native  
>>> english speaker and when it  comes to technical terms, it is even  
>>> worse.
>>
>> "Spatial Point Pattern Analysis" only refers to cases where the  
>> locations of the points are 'interesting', which usually means they  
>> are generated by a stochastic process - like tree locations in a  
>> natural forest rather than rows of trees in a plantation.
>
> Thanks for clarifying these terms. Indeed I am _not_ after spatial  
> point pattern techniques. I changed the subject accordingly.
>
>> Analysis of data that comes from spatial locations that are  
>> 'uninteresting' are another branch of statistics altogether. It  
>> will probably end up being generalised linear modelling with  
>> spatially-correlated errors, and how you deal with the correlations  
>> is the interesting part.
>>
>> See if you can write down a model for your data and include a  
>> smoothly-varying spatial error term.... Then maybe we can find some  
>> R code to solve it. I don't think we'll find it in Spatstat, which  
>> I think is still exclusively spatial point pattern analysis. Have a  
>> look at geoRglm maybe...
>
> Thank you for the pointer. The vignette of geoRglm seems promising,  
> though much is about prediction from a given model while I am most  
> interested in which terms are in the model, i.e. which variables  
> have a notable influence on the repartition of the organisms. My  
> scenario seems simpler than those presented however, since the data  
> are standardized by the sampling effort, meaning that the same  
> Poisson law applies to all points.
>
> A continuous variable than would represent the spatiality in this  
> dataset could simply be the distance from the lower-left corner of  
> the sampling grid for example, or the distance from the island  
> around which the sampling grid is designed (such a distance would  
> have a biological meaning since we expect the abundances to be  
> inversely proportional to it). Is that something that could fit your  
> definition of a "smoothly-varying spatial error term" or am I  
> completely mistaken?
>
> Your answer and the vignette of geoRglm highlight how little I know  
> about all this (I am just a young biologist after all) and how much  
> reading I need to do. The page of geoRglm has a nice list of  
> publications:
> 	http://www.daimi.au.dk/~olefc/geoRglm/Intro/books.html
> Could you (or someone else) direct me towards the best introductory  
> text(s) on this matter please?
>
> Thank you very much for your help.




Now for the current message:

On 2008-February-11  , at 11:46 , Barry Rowlingson wrote:
> Jean-Olivier Irisson wrote:
>> Thank you for the pointer. The vignette of geoRglm seems promising,
>> though much is about prediction from a given model while I am most
>> interested in which terms are in the model, i.e. which variables  
>> have a
>> notable influence on the repartition of the organisms. My scenario  
>> seems
>> simpler than those presented however, since the data are  
>> standardized by
>> the sampling effort, meaning that the same Poisson law applies to all
>> points.
>
>  I think you still need to fit a model, and then you can test how
> useful your covariates are with standard techniques.
>
>> A continuous variable than would represent the spatiality in this
>> dataset could simply be the distance from the lower-left corner of  
>> the
>> sampling grid for example, or the distance from the island around  
>> which
>> the sampling grid is designed (such a distance would have a  
>> biological
>> meaning since we expect the abundances to be inversely proportional  
>> to
>> it). Is that something that could fit your definition of a
>> "smoothly-varying spatial error term" or am I completely mistaken?
>
>  Think about fitting a straight line through some points. You find the
> line that best fits your points. Then you look at the residual
> differences between the line and your points. All the usual linear  
> model
> theory about predictions and significance depends on those residuals
> being uncorrelated and independent. If you are fitting a straight line
> to a curve then that won't be true, and if you then say something  
> about
> your straight line based on the linear model theory you'll be wrong.
>
>  Now, you could fit a non-spatial generalised linear model to your  
> data
> using glm() in R and then map the residuals. If the residual map shows
> structure, then there's something else going on that your model hasn't
> accounted for. Perhaps there is an obvious trend due to a covariate
> you've not included, such as elevation above sea level. You could then
> add this to your model. If the residual surface looks like random  
> noise
> then you can use standard linear model theory to make conclusions  
> about
> your covariate parameters.
>
>  If the residual surface doesn't look like random noise then that's
> when you get into geoRglm functions which (I think) fit a GLM where  
> the
> error surface (that's your residuals) is defined by a gaussian random
> field with a fitted covariance structure. Once that's done, the  
> geoRglm
> code will tell you about your covariate parameter significance (I  
> think!
> It's been a while since I've used it. Maybe Paulo and Ole can expand  
> on
> this).
>
>  So what I'd do is:
>
>  * fit a simple GLM using glm.
>  * Look at parameter estimates and significance.
>  * Draw a map of residuals.
>  * Then worry about spatial correlation.

Thank you very much for such a detailed explanation. This is very  
clear and helps me a lot. I already fitted a glm with spatial  
variables in it to inspect potential spatial effects but I never  
thought about mapping the residuals. I will refit the model excluding  
the spatial variables and check wether there is structure in the  
residuals as you advise. Then the inclusion of spatial variables may  
tell me something depending on their influence on the structure of the  
residuals.

>  Oh, I'd also, if I were you, try and find a local statistician  
> expert!

That would probably be the hardest part :/ Unfortunately there's no  
statistics department nearby and although we have biostatisticians in  
the lab, this is far from their field of activity. This lack of local  
expertise is becoming more and more of a problem but statisticians are  
a rare species!

Thank you again for your help. Sincerely,

Jean-Olivier Irisson
---
UMR 5244 CNRS-EPHE-UPVD, 52 av Paul Alduy, 66860 Perpignan Cedex, France
+336 21 05 19 90
http://jo.irisson.free.fr/work/



From tomp at infra.kth.se  Mon Feb 11 15:08:25 2008
From: tomp at infra.kth.se (Tom Petersen)
Date: Mon, 11 Feb 2008 15:08:25 +0100
Subject: [R-sig-Geo] spatial model with several observations per spatial unit
Message-ID: <1202738905.47b056d95e8a9@mail.infra.kth.se>

Dear list,
I wonder if anyone has experience of implementing a spatial model with a large
panel dataset?
Besides the spatial dimension, the data is grouped by firm and industry. So I
have several cross-sectional and time period observations in each spatial unit
(the industry effect is so far modelled with separate regression equations).
Does anybody have a piece of advise on how to progress with this
kind of data?
One possibility might be to implement a spatial SUR with one equation per time
period(?). I forgot to mention that there is also considerable time series
correlation in the data as well, as is common with economic data.
So far, I have used a non-spatial "two-step" GMM (Arellano-Bond type) with some
success, but of course without the cross-sectional correlation. Maybe it would
be possible to proceed with this method, but weighting the observations
differently. In this case, the cross-sectional (spatial) correlation must be
estimated somehow in the "first step", in order to get the regressor parameters
consistently estimated in the "second step". 
As is described above, the spatial correlation can be divided in "within area"
and "across areas" components, apart from the (autocorrelated) time series
component for each firm (and across firms, e.g. in the same spatial unit).

/Tom
============================
Tom Petersen
Transport and Location Analysis
Dept. of Transport and Economics
School of Architecture and the Built Environment
Teknikringen 78 B
KTH, SE-100 44 Stockholm
e: tomp at kth.se
t: +46 8 790 68 33 
m: +46 70 424 00 75



From paulojus at c3sl.ufpr.br  Mon Feb 11 20:47:00 2008
From: paulojus at c3sl.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Mon, 11 Feb 2008 17:47:00 -0200 (BRST)
Subject: [R-sig-Geo] Comparing abundances at fixed locations in space -
 Syrjala test
In-Reply-To: <47B0278D.7090203@lancaster.ac.uk>
References: <mailman.5.1202641201.8528.r-sig-geo@stat.math.ethz.ch>
	<1202659359.30140.1236060985@webmail.messagingengine.com>
	<DDDEA575-82FC-4472-BF34-37973BB4EDFA@gmail.com>
	<1202682959.31037.1236102977@webmail.messagingengine.com>
	<6C3B0C5A-70A3-4EBE-AE5A-2B7FBE65BFE9@gmail.com>
	<47B01306.5030800@lancaster.ac.uk>
	<EADECA0B-2027-491B-92E7-978CF5348096@normalesup.org>
	<47B0278D.7090203@lancaster.ac.uk>
Message-ID: <Pine.LNX.4.58.0802111744220.11404@talisker.c3sl.ufpr.br>

Just to add to Barry email that geoRglm code
can indeed be used just to access covariate effects, without necessarily
perform any spatial interpolation.
Typicallyin tis implementation this will be via Bayesian framework
obtaining samples from the posterior distribution of the coefficients.


Paulo Justiniano Ribeiro Jr
LEG (Laboratorio de Estatistica e Geoinformacao)
Universidade Federal do Parana
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 3361 3573
Fax: (+55) 41 3361 3141
e-mail: paulojus AT  ufpr  br
http://www.leg.ufpr.br/~paulojus

-------------------------------------------------------------------------
53a Reuniao Anual da Regiao Brasileira da Soc. Internacional de Biometria
14 a 16/05/2008, UFLA, Lavras,MG
http://www.rbras.org.br/rbras53
-------------------------------------------------------------------------


On Mon, 11 Feb 2008, Barry Rowlingson wrote:

> Jean-Olivier Irisson wrote:
>
> > Thank you for the pointer. The vignette of geoRglm seems promising,
> > though much is about prediction from a given model while I am most
> > interested in which terms are in the model, i.e. which variables have a
> > notable influence on the repartition of the organisms. My scenario seems
> > simpler than those presented however, since the data are standardized by
> > the sampling effort, meaning that the same Poisson law applies to all
> > points.
>
>   I think you still need to fit a model, and then you can test how
> useful your covariates are with standard techniques.
>
> > A continuous variable than would represent the spatiality in this
> > dataset could simply be the distance from the lower-left corner of the
> > sampling grid for example, or the distance from the island around which
> > the sampling grid is designed (such a distance would have a biological
> > meaning since we expect the abundances to be inversely proportional to
> > it). Is that something that could fit your definition of a
> > "smoothly-varying spatial error term" or am I completely mistaken?
>
>   Think about fitting a straight line through some points. You find the
> line that best fits your points. Then you look at the residual
> differences between the line and your points. All the usual linear model
> theory about predictions and significance depends on those residuals
> being uncorrelated and independent. If you are fitting a straight line
> to a curve then that won't be true, and if you then say something about
> your straight line based on the linear model theory you'll be wrong.
>
>   Now, you could fit a non-spatial generalised linear model to your data
> using glm() in R and then map the residuals. If the residual map shows
> structure, then there's something else going on that your model hasn't
> accounted for. Perhaps there is an obvious trend due to a covariate
> you've not included, such as elevation above sea level. You could then
> add this to your model. If the residual surface looks like random noise
> then you can use standard linear model theory to make conclusions about
> your covariate parameters.
>
>   If the residual surface doesn't look like random noise then that's
> when you get into geoRglm functions which (I think) fit a GLM where the
> error surface (that's your residuals) is defined by a gaussian random
> field with a fitted covariance structure. Once that's done, the geoRglm
> code will tell you about your covariate parameter significance (I think!
> It's been a while since I've used it. Maybe Paulo and Ole can expand on
> this).
>
>   So what I'd do is:
>
>   * fit a simple GLM using glm.
>   * Look at parameter estimates and significance.
>   * Draw a map of residuals.
>   * Then worry about spatial correlation.
>
>   Oh, I'd also, if I were you, try and find a local statistician expert!
>
> Barry
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From tomp at infra.kth.se  Mon Feb 11 23:29:26 2008
From: tomp at infra.kth.se (Tom Petersen)
Date: Mon, 11 Feb 2008 23:29:26 +0100
Subject: [R-sig-Geo] spatial model with several observations per spatial
	unit
In-Reply-To: <D316C48934DDC340AEC96EF223BC53C9138F49227B@ILS130.uopnet.plymouth.ac.uk>
References: <1202738905.47b056d95e8a9@mail.infra.kth.se>
	<D316C48934DDC340AEC96EF223BC53C9138F49227B@ILS130.uopnet.plymouth.ac.uk>
Message-ID: <1202768966.47b0cc466f021@mail.infra.kth.se>

I am not so familiar with this kind of models, but I have browsed through a
little on Brad Carlin's web page now. How big problems are realistic to model
with this approach? I have 945 spatial units and about 20,000 firms observed up
to 10 years each.
/Tom
============================
Tom Petersen
Transport- och lokaliseringsanalys
Skolan f?r arkitektur och samh?llsbyggnad
Teknikringen 78 B
KTH, 100 44 Stockholm
Tfn 08-790 68 33, 070-424 00 75



Citerar Paul Hewson <paul.hewson at plymouth.ac.uk>:

> Hello,
> Can you use a multivariate CAR for this?
> Best
> Paul
> -=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
> Paul Hewson
> Lecturer in Statistics
> University of Plymouth
> Drake Circus
> Plymouth PL4 8AA
> 
> tel ++44(0)1752 232778
> email paul.hewson at plymouth.ac.uk
> web http://www.plymouth.ac.uk/staff/phewson
> 
> ________________________________________
> From: r-sig-geo-bounces at stat.math.ethz.ch
> [r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Tom Petersen
> [tomp at infra.kth.se]
> Sent: 11 February 2008 14:08
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] spatial model with several observations per spatial
> unit
> 
> Dear list,
> I wonder if anyone has experience of implementing a spatial model with a
> large
> panel dataset?
> Besides the spatial dimension, the data is grouped by firm and industry. So
> I
> have several cross-sectional and time period observations in each spatial
> unit
> (the industry effect is so far modelled with separate regression equations).
> Does anybody have a piece of advise on how to progress with this
> kind of data?
> One possibility might be to implement a spatial SUR with one equation per
> time
> period(?). I forgot to mention that there is also considerable time series
> correlation in the data as well, as is common with economic data.
> So far, I have used a non-spatial "two-step" GMM (Arellano-Bond type) with
> some
> success, but of course without the cross-sectional correlation. Maybe it
> would
> be possible to proceed with this method, but weighting the observations
> differently. In this case, the cross-sectional (spatial) correlation must be
> estimated somehow in the "first step", in order to get the regressor
> parameters
> consistently estimated in the "second step".
> As is described above, the spatial correlation can be divided in "within
> area"
> and "across areas" components, apart from the (autocorrelated) time series
> component for each firm (and across firms, e.g. in the same spatial unit).
> 
> /Tom
> ============================
> Tom Petersen
> Transport and Location Analysis
> Dept. of Transport and Economics
> School of Architecture and the Built Environment
> Teknikringen 78 B
> KTH, SE-100 44 Stockholm
> e: tomp at kth.se
> t: +46 8 790 68 33
> m: +46 70 424 00 75
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From tkobayas at indiana.edu  Tue Feb 12 02:25:54 2008
From: tkobayas at indiana.edu (Takatsugu Kobayashi)
Date: Mon, 11 Feb 2008 20:25:54 -0500
Subject: [R-sig-Geo] Changing bar scale: spplot
Message-ID: <47B0F5A2.3050305@indiana.edu>

Hi,

I am reading sp and trellis manuals, but how can I change a bar scale? I 
am looking for something like zlim=c()

Thank you!

tk



From edzer.pebesma at uni-muenster.de  Tue Feb 12 10:13:35 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 12 Feb 2008 10:13:35 +0100
Subject: [R-sig-Geo] Changing bar scale: spplot
In-Reply-To: <47B0F5A2.3050305@indiana.edu>
References: <47B0F5A2.3050305@indiana.edu>
Message-ID: <47B1633F.5050607@uni-muenster.de>

I think it is the cuts=c() argument.
--
Edz

Takatsugu Kobayashi wrote:
> Hi,
>
> I am reading sp and trellis manuals, but how can I change a bar scale? I 
> am looking for something like zlim=c()
>
> Thank you!
>
> tk
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Roger.Bivand at nhh.no  Tue Feb 12 10:29:19 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 12 Feb 2008 10:29:19 +0100 (CET)
Subject: [R-sig-Geo] useR! 2008 - Call for papers
Message-ID: <Pine.LNX.4.64.0802121018280.28121@reclus.nhh.no>

useR! 2008, the R user conference, takes place at the Fakult?t Statistik, 
Technische Universit?t Dortmund, Germany from 2008-08-12 to 2008-08-14. 
Pre-conference tutorials will take place on August 11; details at:

http://www.statistik.uni-dortmund.de/useR-2008/

Once again, spatial data analysis is one of the topics represented at the 
meeting, and contributions would be very welcome!

There will also be a half-day tutorial on August 11 by Virgilio 
G?mez-Rubio on "Small Area Estimation with R", which may be of special 
interest to list participants; many of the other tutorials also look 
tempting.

Hoping to see you there!

Roger

PS: US residents may note the section on possible funding support on the 
website with separate deadlines.

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From a.ghisla at studenti.uninsubria.it  Tue Feb 12 17:06:27 2008
From: a.ghisla at studenti.uninsubria.it (Anne Ghisla)
Date: Tue, 12 Feb 2008 17:06:27 +0100
Subject: [R-sig-Geo] points-in-polygons calculation
Message-ID: <1202832387.7647.29.camel@galadriel>

Hi all,

during a spatial analysis I need to compute a point-in-polygon
calculation, and I chose findPolys() in PBSmapping package.

For the moment the script is built as follows:
- import the polygon shapefile with rgdal
- import the point shapefile with PBSmapping
- nested for cycles that
  - isolate each polygon (or region) through a superkey on the
attributes in data slot. The selected element is a homerange. It's then
converted in a PolySet, for next step
  - finds which points fall inside the homerange with findPolys()
  - picks up a defined value among the attributes of points and computes
mean of all values of the selected points, then writes it in a new
column of the attribute table

Can the for cycle be based on a unique key like PolygonsID? Among the
methods for sp classes I didn't find it. I found functions like
getPolygonsIDSlot but they have not to be used directly.

Any suggestions?

thank you in advance

Anne Ghisla
Universit? degli Studi dell'Insubria, Varese
-- 


0< ascii ribbon campaign - stop html mail - http://www.asciiribbon.org
-----------------------------------------------------------
Please consider the environment before printing this email
-----------------------------------------------------------
Per favore non mandatemi allegati in formati proprietari
Please do not send attachments in proprietary formats
(Word, Excel, PowerPoint, etc.)
Meglio usare formati standaridzzati e documentati
Better use standard open formats
(.odt, .txt, .html, .pdf, .shp, dump SQL)
http://www.gnu.org/philosophy/no-word-attachments.html
Standard UNI CEI ISO/IEC 26300:2007
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: Questa ? una parte del messaggio	firmata digitalmente
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080212/9125291c/attachment.bin>

From Roger.Bivand at nhh.no  Tue Feb 12 18:57:54 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 12 Feb 2008 18:57:54 +0100 (CET)
Subject: [R-sig-Geo] points-in-polygons calculation
In-Reply-To: <1202832387.7647.29.camel@galadriel>
References: <1202832387.7647.29.camel@galadriel>
Message-ID: <Pine.LNX.4.64.0802121845260.28121@reclus.nhh.no>

On Tue, 12 Feb 2008, Anne Ghisla wrote:

> Hi all,
>
> during a spatial analysis I need to compute a point-in-polygon
> calculation, and I chose findPolys() in PBSmapping package.
>
> For the moment the script is built as follows:
> - import the polygon shapefile with rgdal
> - import the point shapefile with PBSmapping
> - nested for cycles that
>  - isolate each polygon (or region) through a superkey on the
> attributes in data slot. The selected element is a homerange. It's then
> converted in a PolySet, for next step
>  - finds which points fall inside the homerange with findPolys()
>  - picks up a defined value among the attributes of points and computes
> mean of all values of the selected points, then writes it in a new
> column of the attribute table

Well, if you showed the code used for doing this, it might be easier to 
advise. Are you using the maptools function SpatialPolygons2PolySet()? You 
can then use the PID and SID values as you would otherwise in PBSmapping.

But it does strike me that it might be simpler just to read the points 
with rgdal, and use the overlay() method in sp to find which points belong 
to which polygons, all in one go. Using the output membership vector, you 
could simply run by() or aggregate on as(pts, "data.frame") to get your 
summaries per home range. The only reason for caution might be if the home 
range polygons overlap, in which case judicious use of lapply() on the 
"polygons" slot of the SpatialPolygons* might be needed, because some 
points might fall into multiple polygons.

The IDs of the Polygons in the SpatialPolygons* object SP are in:

sapply(slot(SP, "polygons"), function(x) slot(x, "ID"))

Hope this helps,

Roger

>
> Can the for cycle be based on a unique key like PolygonsID? Among the
> methods for sp classes I didn't find it. I found functions like
> getPolygonsIDSlot but they have not to be used directly.
>
> Any suggestions?
>
> thank you in advance
>
> Anne Ghisla
> Universit? degli Studi dell'Insubria, Varese
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From basille at biomserv.univ-lyon1.fr  Tue Feb 12 20:35:05 2008
From: basille at biomserv.univ-lyon1.fr (Mathieu Basille)
Date: Tue, 12 Feb 2008 20:35:05 +0100
Subject: [R-sig-Geo] SpatialPolygonsDataFrame visualization
Message-ID: <47B1F4E9.7030708@biomserv.univ-lyon1.fr>

Hello everyone,

I'm not very familiar with visualization of spatial objects in R, 
especially with the possibilities of the spplot function...

I have a SpatialPolygonsDataFrame and I'd like to obtain a map with a 
specific scale for each layer (not in the geographic space, but in the 
data), instead of the same one for every one. In my case, the layers 
represent different variables, not on the same scale (e.g. elevation and 
rain).

Additionally, I'd like to represent NA's with a particular color (say 
black so that we can see immediately where they occur).

I guess these 2 issues are somehow related, but I didn't manage to solve 
them. The help pages of spplot or xyplot didn't really help...

Any hint how to do that?
Thanks in advance,
Mathieu.


 > version
platform       i486-pc-linux-gnu
svn rev        43537
version.string R version 2.6.1 (2007-11-26)
sp: sp_0.9-19


-- 

????????????????????????????????????????????????
                                                 ]
  Mathieu BASILLE -- PhD Student                 ]
                                                 ]
  Laboratoire de Biom?trie et Biologie ?volutive ]
  Universit? Claude Bernard Lyon 1 - France      ]
   http://lbbe.univ-lyon1.fr/                    ]
                                                 ]
  My resume:                                     ]
   http://mathieu.basille.net/pro/               ]
  Habitat web-site:                              ]
   http://biomserv.univ-lyon1.fr/spip_habitat/   ]
________________________________________________]



From reeves at nceas.ucsb.edu  Wed Feb 13 00:33:05 2008
From: reeves at nceas.ucsb.edu (Rick Reeves)
Date: Tue, 12 Feb 2008 15:33:05 -0800
Subject: [R-sig-Geo] SpatialPolygonsDataFrame visualization
In-Reply-To: <47B1F4E9.7030708@biomserv.univ-lyon1.fr>
References: <47B1F4E9.7030708@biomserv.univ-lyon1.fr>
Message-ID: <47B22CB1.3030706@nceas.ucsb.edu>

Mathiu:

The attached use case might help: It is not exactly what you are looking 
for, but the last map
demonstrates use of the spplot function to create a 'display list' that 
plots vector and raster
data layers on a single map. Also some hints on creating a map scale and 
legend.

http://nceas.ucsb.edu/scicomp/GISSeminar/UseCases/MapProdWithRGraphics/OneMapProdWithRGraphics.html

Regards,
Rick Reeves

Mathieu Basille wrote:
> Hello everyone,
>
> I'm not very familiar with visualization of spatial objects in R, 
> especially with the possibilities of the spplot function...
>
> I have a SpatialPolygonsDataFrame and I'd like to obtain a map with a 
> specific scale for each layer (not in the geographic space, but in the 
> data), instead of the same one for every one. In my case, the layers 
> represent different variables, not on the same scale (e.g. elevation and 
> rain).
>
> Additionally, I'd like to represent NA's with a particular color (say 
> black so that we can see immediately where they occur).
>
> I guess these 2 issues are somehow related, but I didn't manage to solve 
> them. The help pages of spplot or xyplot didn't really help...
>
> Any hint how to do that?
> Thanks in advance,
> Mathieu.
>
>
>  > version
> platform       i486-pc-linux-gnu
> svn rev        43537
> version.string R version 2.6.1 (2007-11-26)
> sp: sp_0.9-19
>
>
>   
-------------- next part --------------
A non-text attachment was scrubbed...
Name: reeves.vcf
Type: text/x-vcard
Size: 339 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080212/2e7bda60/attachment.vcf>

From a.ghisla at studenti.uninsubria.it  Wed Feb 13 10:41:13 2008
From: a.ghisla at studenti.uninsubria.it (Anne Ghisla)
Date: Wed, 13 Feb 2008 10:41:13 +0100
Subject: [R-sig-Geo] points-in-polygons calculation
In-Reply-To: <Pine.LNX.4.64.0802121845260.28121@reclus.nhh.no>
References: <1202832387.7647.29.camel@galadriel>
	<Pine.LNX.4.64.0802121845260.28121@reclus.nhh.no>
Message-ID: <1202895673.6498.18.camel@galadriel>


Il giorno mar, 12/02/2008 alle 18.57 +0100, Roger Bivand ha scritto:

> Well, if you showed the code used for doing this, it might be easier to 
> advise. 
you're right. the code is in attachment. It's still a beta version, and
needs much improvement.
the attributes that identify an home range are year, period and ID
together. that's why the code contains three nested for cycles.

> But it does strike me that it might be simpler just to read the points 
> with rgdal, and use the overlay() method in sp to find which points belong 
> to which polygons, all in one go. Using the output membership vector, you 
> could simply run by() or aggregate on as(pts, "data.frame") to get your 
> summaries per home range. The only reason for caution might be if the home 
> range polygons overlap, in which case judicious use of lapply() on the 
> "polygons" slot of the SpatialPolygons* might be needed, because some 
> points might fall into multiple polygons.
in fact most polygons overlap, therefore I found easier to work on one
polygon at time with PBSmapping functions.

> The IDs of the Polygons in the SpatialPolygons* object SP are in:
> 
> sapply(slot(SP, "polygons"), function(x) slot(x, "ID"))

thank you for hints and explanations!

regards,
Anne

-------------- next part --------------

rm(list=ls())

require(rgdal) 
require(PBSmapping) 

polygons <- readOGR('path2shapefiledsn', 'shapefileName') # import con rgdal
points <- importShapefile('path2shapefileNameWithoutExt')  # import con pbsmapping 

[...]

# correspondence table. the energy values to be picked up for each homerange depend on the its time frame
rules <- read.table(\"$file\", header=TRUE, sep=\"\t\", dec=\".\") #per esempio
rules <- data.frame(
	year = c('2000','2002','2002','2004','2004','2006','2006'),
    seas = c('spr','spr','aut','spr','aut','spr','aut'),
	energy = c('EN_F1999','EN_F2001','EN_F2002','EN_F2003','EN_F2004','EN_F2005','EN_F2006')
)

for (y in as.character(unique(polygons$YEAR))) {
	for (p in as.character(unique(polygons$PERIOD))) {
		for (i in as.character(unique(polygons$ID))) {
			try(
				if (nrow(polygons[polygons$YEAR == y & polygons$PERIOD == p & polygons$ID == i,]@data) == 1) {
					poly.tmp <- polygons[polygons$YEAR == y & polygons$PERIOD == p & polygons$ID == i,]
					poly.PBS.tmp <- SpatialPolygons2PolySet(poly.tmp)
					intersection <- findPolys(points, poly.PBS.tmp)
					fld2 <- as.character(rules[rules$year == y & rules$seas == p,]$energy)
					energyHR <- mean(points[points$EID %in% intersection$EID,fld2],na.rm = TRUE)
					polygons at data[polygons$YEAR == y & polygons$MONTH == m & polygons$ID == i,"EN_HR"] <- energyHR
				}
				, silent = TRUE)
		}
	}
}
writeOGR(polygons, 'dsn', 'namefile', driver='ESRI Shapefile')

-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: Questa ? una parte del messaggio	firmata digitalmente
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080213/203e0697/attachment.bin>

From p.hiemstra at geo.uu.nl  Wed Feb 13 11:08:06 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Wed, 13 Feb 2008 11:08:06 +0100
Subject: [R-sig-Geo] Changing bar scale: spplot
In-Reply-To: <47B0F5A2.3050305@indiana.edu>
References: <47B0F5A2.3050305@indiana.edu>
Message-ID: <47B2C186.3060003@geo.uu.nl>

Takatsugu Kobayashi wrote:
> Hi,
>
> I am reading sp and trellis manuals, but how can I change a bar scale? I 
> am looking for something like zlim=c()
>
> Thank you!
>
> tk
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   
You can use the at parameter as in:

library(sp)
data(meuse.grid)
gridded(meuse.grid) = ~x+y
spplot(meuse.grid, "dist", at = seq(0, 1, by = 0.1))

cheers,
Paul

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul



From basille at biomserv.univ-lyon1.fr  Thu Feb 14 00:31:09 2008
From: basille at biomserv.univ-lyon1.fr (Mathieu Basille)
Date: Thu, 14 Feb 2008 00:31:09 +0100
Subject: [R-sig-Geo] SpatialPolygonsDataFrame visualization
In-Reply-To: <47B22CB1.3030706@nceas.ucsb.edu>
References: <47B1F4E9.7030708@biomserv.univ-lyon1.fr>
	<47B22CB1.3030706@nceas.ucsb.edu>
Message-ID: <47B37DBD.6020301@biomserv.univ-lyon1.fr>

Thanks Rick for the hints.

I have to admit, however, that it is so far a huge failure. I have been 
able to play a bit with the color key (arg 'colokey' that sets the 
position, the colors, the tick marks, height & width, etc.) and the 
color of one map (arg 'col.regions', for finite values of the layer), 
but I'm still unable to
1) have different scales for different layers (i.e. one color key per 
layer);
2) color NA with a non-contiguous color from other finite values. From 
my different tests, NA are always white (I wish I could fill them in red 
for example, with finite values in a gradient of grey).

In addition, I'm totally lost in the help pages of xyplot and levelplot 
(lattice), and the graph gallery of sp didn't help neither.

Any other resource or tutorial for this?
Thanks in advance,
Mathieu.


Rick Reeves a ?crit :
> Mathiu:
> 
> The attached use case might help: It is not exactly what you are looking 
> for, but the last map
> demonstrates use of the spplot function to create a 'display list' that 
> plots vector and raster
> data layers on a single map. Also some hints on creating a map scale and 
> legend.
> 
> http://nceas.ucsb.edu/scicomp/GISSeminar/UseCases/MapProdWithRGraphics/OneMapProdWithRGraphics.html 
> 
> 
> Regards,
> Rick Reeves
> 
> Mathieu Basille wrote:
>> Hello everyone,
>>
>> I'm not very familiar with visualization of spatial objects in R, 
>> especially with the possibilities of the spplot function...
>>
>> I have a SpatialPolygonsDataFrame and I'd like to obtain a map with a 
>> specific scale for each layer (not in the geographic space, but in the 
>> data), instead of the same one for every one. In my case, the layers 
>> represent different variables, not on the same scale (e.g. elevation 
>> and rain).
>>
>> Additionally, I'd like to represent NA's with a particular color (say 
>> black so that we can see immediately where they occur).
>>
>> I guess these 2 issues are somehow related, but I didn't manage to 
>> solve them. The help pages of spplot or xyplot didn't really help...
>>
>> Any hint how to do that?
>> Thanks in advance,
>> Mathieu.
>>
>>
>>  > version
>> platform       i486-pc-linux-gnu
>> svn rev        43537
>> version.string R version 2.6.1 (2007-11-26)
>> sp: sp_0.9-19


-- 

????????????????????????????????????????????????
                                                 ]
  Mathieu BASILLE -- PhD Student                 ]
                                                 ]
  Laboratoire de Biom?trie et Biologie ?volutive ]
  Universit? Claude Bernard Lyon 1 - France      ]
   http://lbbe.univ-lyon1.fr/                    ]
                                                 ]
  My resume:                                     ]
   http://mathieu.basille.net/pro/               ]
  Habitat web-site:                              ]
   http://biomserv.univ-lyon1.fr/spip_habitat/   ]
________________________________________________]



From Roger.Bivand at nhh.no  Thu Feb 14 09:18:02 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 14 Feb 2008 09:18:02 +0100 (CET)
Subject: [R-sig-Geo] SpatialPolygonsDataFrame visualization
In-Reply-To: <47B37DBD.6020301@biomserv.univ-lyon1.fr>
References: <47B1F4E9.7030708@biomserv.univ-lyon1.fr>
	<47B22CB1.3030706@nceas.ucsb.edu>
	<47B37DBD.6020301@biomserv.univ-lyon1.fr>
Message-ID: <Pine.LNX.4.64.0802140912070.6874@reclus.nhh.no>

On Thu, 14 Feb 2008, Mathieu Basille wrote:

> Thanks Rick for the hints.
>
> I have to admit, however, that it is so far a huge failure. I have been
> able to play a bit with the color key (arg 'colokey' that sets the
> position, the colors, the tick marks, height & width, etc.) and the
> color of one map (arg 'col.regions', for finite values of the layer),
> but I'm still unable to
> 1) have different scales for different layers (i.e. one color key per
> layer);

This suggests that you really should not be using lattice graphics, 
because they are specifically written for conditional plots, so 
necessarily on the same scale for comparision

> 2) color NA with a non-contiguous color from other finite values. From
> my different tests, NA are always white (I wish I could fill them in red
> for example, with finite values in a gradient of grey).
>
> In addition, I'm totally lost in the help pages of xyplot and levelplot
> (lattice), and the graph gallery of sp didn't help neither.
>
> Any other resource or tutorial for this?

There is Paul Murrell's R Graphics book (Chapman & Hall/CRC), and lattice 
author Deepayan Sarkar's forthcoming lattice book (Springer useR series), 
but lattice is, I think, not what you want if you want to control things 
yourself. Just use base graphics and build things up layer by layer.

Lattice is superb for what it is designed for, by the way, say 
conditioning earthquake location by depth as the classic example, or 
plotting anisotropic variograms by direction.

Roger

> Thanks in advance,
> Mathieu.
>
>
> Rick Reeves a ?crit :
>> Mathiu:
>>
>> The attached use case might help: It is not exactly what you are looking
>> for, but the last map
>> demonstrates use of the spplot function to create a 'display list' that
>> plots vector and raster
>> data layers on a single map. Also some hints on creating a map scale and
>> legend.
>>
>> http://nceas.ucsb.edu/scicomp/GISSeminar/UseCases/MapProdWithRGraphics/OneMapProdWithRGraphics.html
>>
>>
>> Regards,
>> Rick Reeves
>>
>> Mathieu Basille wrote:
>>> Hello everyone,
>>>
>>> I'm not very familiar with visualization of spatial objects in R,
>>> especially with the possibilities of the spplot function...
>>>
>>> I have a SpatialPolygonsDataFrame and I'd like to obtain a map with a
>>> specific scale for each layer (not in the geographic space, but in the
>>> data), instead of the same one for every one. In my case, the layers
>>> represent different variables, not on the same scale (e.g. elevation
>>> and rain).
>>>
>>> Additionally, I'd like to represent NA's with a particular color (say
>>> black so that we can see immediately where they occur).
>>>
>>> I guess these 2 issues are somehow related, but I didn't manage to
>>> solve them. The help pages of spplot or xyplot didn't really help...
>>>
>>> Any hint how to do that?
>>> Thanks in advance,
>>> Mathieu.
>>>
>>>
>>> > version
>>> platform       i486-pc-linux-gnu
>>> svn rev        43537
>>> version.string R version 2.6.1 (2007-11-26)
>>> sp: sp_0.9-19
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From p.hiemstra at geo.uu.nl  Thu Feb 14 09:43:47 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Thu, 14 Feb 2008 09:43:47 +0100
Subject: [R-sig-Geo] SpatialPolygonsDataFrame visualization
In-Reply-To: <47B37DBD.6020301@biomserv.univ-lyon1.fr>
References: <47B1F4E9.7030708@biomserv.univ-lyon1.fr>	<47B22CB1.3030706@nceas.ucsb.edu>
	<47B37DBD.6020301@biomserv.univ-lyon1.fr>
Message-ID: <47B3FF43.4090702@geo.uu.nl>

Hi,

You can have separate scales for separate lattice plots. Use scales = 
"free".

hth,
Paul

Mathieu Basille wrote:
> Thanks Rick for the hints.
>
> I have to admit, however, that it is so far a huge failure. I have been 
> able to play a bit with the color key (arg 'colokey' that sets the 
> position, the colors, the tick marks, height & width, etc.) and the 
> color of one map (arg 'col.regions', for finite values of the layer), 
> but I'm still unable to
> 1) have different scales for different layers (i.e. one color key per 
> layer);
> 2) color NA with a non-contiguous color from other finite values. From 
> my different tests, NA are always white (I wish I could fill them in red 
> for example, with finite values in a gradient of grey).
>
> In addition, I'm totally lost in the help pages of xyplot and levelplot 
> (lattice), and the graph gallery of sp didn't help neither.
>
> Any other resource or tutorial for this?
> Thanks in advance,
> Mathieu.
>
>
> Rick Reeves a ?crit :
>   
>> Mathiu:
>>
>> The attached use case might help: It is not exactly what you are looking 
>> for, but the last map
>> demonstrates use of the spplot function to create a 'display list' that 
>> plots vector and raster
>> data layers on a single map. Also some hints on creating a map scale and 
>> legend.
>>
>> http://nceas.ucsb.edu/scicomp/GISSeminar/UseCases/MapProdWithRGraphics/OneMapProdWithRGraphics.html 
>>
>>
>> Regards,
>> Rick Reeves
>>
>> Mathieu Basille wrote:
>>     
>>> Hello everyone,
>>>
>>> I'm not very familiar with visualization of spatial objects in R, 
>>> especially with the possibilities of the spplot function...
>>>
>>> I have a SpatialPolygonsDataFrame and I'd like to obtain a map with a 
>>> specific scale for each layer (not in the geographic space, but in the 
>>> data), instead of the same one for every one. In my case, the layers 
>>> represent different variables, not on the same scale (e.g. elevation 
>>> and rain).
>>>
>>> Additionally, I'd like to represent NA's with a particular color (say 
>>> black so that we can see immediately where they occur).
>>>
>>> I guess these 2 issues are somehow related, but I didn't manage to 
>>> solve them. The help pages of spplot or xyplot didn't really help...
>>>
>>> Any hint how to do that?
>>> Thanks in advance,
>>> Mathieu.
>>>
>>>
>>>  > version
>>> platform       i486-pc-linux-gnu
>>> svn rev        43537
>>> version.string R version 2.6.1 (2007-11-26)
>>> sp: sp_0.9-19
>>>       
>
>
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul



From jo.irisson at gmail.com  Thu Feb 14 11:05:07 2008
From: jo.irisson at gmail.com (jiho)
Date: Thu, 14 Feb 2008 11:05:07 +0100
Subject: [R-sig-Geo] Comparing abundances at fixed locations in space -
	Syrjala test
In-Reply-To: <47B0278D.7090203@lancaster.ac.uk>
References: <mailman.5.1202641201.8528.r-sig-geo@stat.math.ethz.ch>	<1202659359.30140.1236060985@webmail.messagingengine.com>	<DDDEA575-82FC-4472-BF34-37973BB4EDFA@gmail.com>	<1202682959.31037.1236102977@webmail.messagingengine.com>
	<6C3B0C5A-70A3-4EBE-AE5A-2B7FBE65BFE9@gmail.com>
	<47B01306.5030800@lancaster.ac.uk>
	<EADECA0B-2027-491B-92E7-978CF5348096@normalesup.org>
	<47B0278D.7090203@lancaster.ac.uk>
Message-ID: <C3C023BB-08CD-4BDF-9C0E-58E06475D162@gmail.com>

Hello,

On 2008-February-11  , at 11:46 , Barry Rowlingson wrote:
> [...]
>  Now, you could fit a non-spatial generalised linear model to your  
> data
> using glm() in R and then map the residuals. If the residual map shows
> structure, then there's something else going on that your model hasn't
> accounted for. Perhaps there is an obvious trend due to a covariate
> you've not included, such as elevation above sea level. You could then
> add this to your model. If the residual surface looks like random  
> noise
> then you can use standard linear model theory to make conclusions  
> about
> your covariate parameters.
>
>  If the residual surface doesn't look like random noise then that's
> when you get into geoRglm functions which (I think) fit a GLM where  
> the
> error surface (that's your residuals) is defined by a gaussian random
> field with a fitted covariance structure. Once that's done, the  
> geoRglm
> code will tell you about your covariate parameter significance (I  
> think!
> It's been a while since I've used it. Maybe Paulo and Ole can expand  
> on
> this).
>
>  So what I'd do is:
>
>  * fit a simple GLM using glm.
>  * Look at parameter estimates and significance.
>  * Draw a map of residuals.
>  * Then worry about spatial correlation.

Just to let you know how all this turned out. I started by fitting a  
regular glm (with poisson errors since I'm dealing with counts) trying  
to explain the abundances with environmental variables (wich are not  
spatial in essence but vary spatially). It did not explain much of the  
variability. I then added some explicitly spatial variables (location/ 
distance with respect to a point, latitude, longitude etc.) and after  
adding one of those most of the spatial variability is explained and  
the residuals don't show spatial patterns[1]. Of course the data does  
not show much spatial structure even at start and is highly variable  
but given the results of the model and the look of the residuals, I am  
still quite confident in saying that there was a spatial effect, and I  
can even interprete it biologically[2].

So thanks a lot for your detailed advice. The original question  
remains though:
	https://stat.ethz.ch/pipermail/r-sig-geo/2008-February/003138.html
I've explained some of the variability for the total abundance or for  
an assemblage of abundant species (a multivariate glm shows the same  
thing) but I would like to explicitly test wether the distribution of  
two species differ. Syrjala's test really looks like what I want to  
do. But either my implementation[3] is faulty (even two completely  
disjointed distributions are not significantly different) or it is  
meant to work on a much larger number of points to be efficient  
(Syrjala has 360 in the exemple presented in the paper). I think that,  
given that I have replicates of the same sampling, I should be able to  
gain some statistical power from this. Any advice would be welcome.

Thanks in advance.

[1] http://jo.irisson.free.fr/dropbox/spatial-residuals.pdf
The four columns represent data for the four successive sampling  
events. The first line shows the raw counts. There's not much spatial  
structure at the end but there are patterns of high abundance in  
rotation 1 and 2. The second line shows the residuals of the glm with  
only environmental factors which leaves much of the patterns in place.  
The third line is the residuals from a similar model with an added  
"location" factor which codes the windward/downwind situation of each  
point. It explains much of the spatial distribution of abundance,  
expect maybe for some points of rotation 1.

[2] For those interested in the details, the longitude or location  
with respect to the island both have an important and significant  
effect and show that the organisms are more abundant on the western or  
downwind side of the island, which is expected since water in enriched  
in nutrients at these locations.

[3] https://stat.ethz.ch/pipermail/r-sig-geo/2008-February/003143.html

Jean-Olivier Irisson
---
UMR 5244 CNRS-EPHE-UPVD, 52 av Paul Alduy, 66860 Perpignan Cedex, France
+336 21 05 19 90
http://jo.irisson.free.fr/work/



From Thierry.ONKELINX at inbo.be  Thu Feb 14 12:30:30 2008
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 14 Feb 2008 12:30:30 +0100
Subject: [R-sig-Geo] Comparing abundances at fixed locations in space
	-Syrjala test
In-Reply-To: <C3C023BB-08CD-4BDF-9C0E-58E06475D162@gmail.com>
References: <mailman.5.1202641201.8528.r-sig-geo@stat.math.ethz.ch>	<1202659359.30140.1236060985@webmail.messagingengine.com>	<DDDEA575-82FC-4472-BF34-37973BB4EDFA@gmail.com>	<1202682959.31037.1236102977@webmail.messagingengine.com><6C3B0C5A-70A3-4EBE-AE5A-2B7FBE65BFE9@gmail.com><47B01306.5030800@lancaster.ac.uk><EADECA0B-2027-491B-92E7-978CF5348096@normalesup.org><47B0278D.7090203@lancaster.ac.uk>
	<C3C023BB-08CD-4BDF-9C0E-58E06475D162@gmail.com>
Message-ID: <2E9C414912813E4EB981326983E0A104045488DA@inboexch.inbo.be>

Dear Jo,

Variograms are a good tool to inspect spatial autocorrelation in the
data / residuals. But 36 locations is a rather small sample for doing
that. So you might get unstable variograms.

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

Do not put your faith in what statistics say until you have carefully
considered what they do not say.  ~William W. Watt
A statistical analysis, properly conducted, is a delicate dissection of
uncertainties, a surgery of suppositions. ~M.J.Moroney

-----Oorspronkelijk bericht-----
Van: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens jiho
Verzonden: donderdag 14 februari 2008 11:05
Aan: Barry Rowlingson
CC: r-sig-geo at stat.math.ethz.ch
Onderwerp: Re: [R-sig-Geo] Comparing abundances at fixed locations in
space -Syrjala test

Hello,

On 2008-February-11  , at 11:46 , Barry Rowlingson wrote:
> [...]
>  Now, you could fit a non-spatial generalised linear model to your  
> data
> using glm() in R and then map the residuals. If the residual map shows
> structure, then there's something else going on that your model hasn't
> accounted for. Perhaps there is an obvious trend due to a covariate
> you've not included, such as elevation above sea level. You could then
> add this to your model. If the residual surface looks like random  
> noise
> then you can use standard linear model theory to make conclusions  
> about
> your covariate parameters.
>
>  If the residual surface doesn't look like random noise then that's
> when you get into geoRglm functions which (I think) fit a GLM where  
> the
> error surface (that's your residuals) is defined by a gaussian random
> field with a fitted covariance structure. Once that's done, the  
> geoRglm
> code will tell you about your covariate parameter significance (I  
> think!
> It's been a while since I've used it. Maybe Paulo and Ole can expand  
> on
> this).
>
>  So what I'd do is:
>
>  * fit a simple GLM using glm.
>  * Look at parameter estimates and significance.
>  * Draw a map of residuals.
>  * Then worry about spatial correlation.

Just to let you know how all this turned out. I started by fitting a  
regular glm (with poisson errors since I'm dealing with counts) trying  
to explain the abundances with environmental variables (wich are not  
spatial in essence but vary spatially). It did not explain much of the  
variability. I then added some explicitly spatial variables (location/ 
distance with respect to a point, latitude, longitude etc.) and after  
adding one of those most of the spatial variability is explained and  
the residuals don't show spatial patterns[1]. Of course the data does  
not show much spatial structure even at start and is highly variable  
but given the results of the model and the look of the residuals, I am  
still quite confident in saying that there was a spatial effect, and I  
can even interprete it biologically[2].

So thanks a lot for your detailed advice. The original question  
remains though:
	
https://stat.ethz.ch/pipermail/r-sig-geo/2008-February/003138.html
I've explained some of the variability for the total abundance or for  
an assemblage of abundant species (a multivariate glm shows the same  
thing) but I would like to explicitly test wether the distribution of  
two species differ. Syrjala's test really looks like what I want to  
do. But either my implementation[3] is faulty (even two completely  
disjointed distributions are not significantly different) or it is  
meant to work on a much larger number of points to be efficient  
(Syrjala has 360 in the exemple presented in the paper). I think that,  
given that I have replicates of the same sampling, I should be able to  
gain some statistical power from this. Any advice would be welcome.

Thanks in advance.

[1] http://jo.irisson.free.fr/dropbox/spatial-residuals.pdf
The four columns represent data for the four successive sampling  
events. The first line shows the raw counts. There's not much spatial  
structure at the end but there are patterns of high abundance in  
rotation 1 and 2. The second line shows the residuals of the glm with  
only environmental factors which leaves much of the patterns in place.  
The third line is the residuals from a similar model with an added  
"location" factor which codes the windward/downwind situation of each  
point. It explains much of the spatial distribution of abundance,  
expect maybe for some points of rotation 1.

[2] For those interested in the details, the longitude or location  
with respect to the island both have an important and significant  
effect and show that the organisms are more abundant on the western or  
downwind side of the island, which is expected since water in enriched  
in nutrients at these locations.

[3] https://stat.ethz.ch/pipermail/r-sig-geo/2008-February/003143.html

Jean-Olivier Irisson
---
UMR 5244 CNRS-EPHE-UPVD, 52 av Paul Alduy, 66860 Perpignan Cedex, France
+336 21 05 19 90
http://jo.irisson.free.fr/work/

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From tkobayas at indiana.edu  Sun Feb 17 07:31:05 2008
From: tkobayas at indiana.edu (Takatsugu Kobayashi)
Date: Sun, 17 Feb 2008 01:31:05 -0500
Subject: [R-sig-Geo] variance estimation in spgwr
Message-ID: <47B7D4A9.40900@indiana.edu>

Hi,

I am curious if spgwr or some other spatial packages estimate local 
variances. I am particularly interested if gwr residuals are locally 
siginificant or not.  In this case, I believe I should estimate local 
variances.  I though an alternative to spgwr is gam in mgcv.

Suppose I have xy coordinates and some values d1 and d2 attached to 
point(x,y). z1 is related to z2, but this relationship is not spatially 
stationary. So I would set this up using gam:

model1 <- gam(d1 ~ s(x, y, by=d2)) : I am not quite familiar with 
adaptive bandwidth selections in gam...

or using spgwr

bw <- gwr.sel(d1~d2, coords=cbind(x,y), apapt=T)
model2 <- gwr(d1~d2, coords=cbind(x,y), apapt=T, bandwidth=bw, 
hatmatrix=TRUE, lonlat =FALSE)

What I would like to know is 

d1(i)-hat{d1(i)}/hat{sigma(i)}
where i denotes the ith location in a map.

I did a bit of search and "lokern" pacakge came up, but this is only for 
bivarriate case and not particularly spatial-oriented.

Sorry for ambiguity of my question...  I appreciate if someone could 
give me some clues.....

thanks

tk



From Roger.Bivand at nhh.no  Sun Feb 17 15:33:30 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 17 Feb 2008 15:33:30 +0100 (CET)
Subject: [R-sig-Geo] variance estimation in spgwr
In-Reply-To: <47B7D4A9.40900@indiana.edu>
References: <47B7D4A9.40900@indiana.edu>
Message-ID: <Pine.LNX.4.64.0802171521060.6637@reclus.nhh.no>

On Sun, 17 Feb 2008, Takatsugu Kobayashi wrote:

> Hi,
>
> I am curious if spgwr or some other spatial packages estimate local
> variances. I am particularly interested if gwr residuals are locally
> siginificant or not.  In this case, I believe I should estimate local
> variances.  I though an alternative to spgwr is gam in mgcv.
>
> Suppose I have xy coordinates and some values d1 and d2 attached to
> point(x,y). z1 is related to z2, but this relationship is not spatially
> stationary. So I would set this up using gam:
>
> model1 <- gam(d1 ~ s(x, y, by=d2)) : I am not quite familiar with
> adaptive bandwidth selections in gam...
>
> or using spgwr
>
> bw <- gwr.sel(d1~d2, coords=cbind(x,y), apapt=T)
> model2 <- gwr(d1~d2, coords=cbind(x,y), apapt=T, bandwidth=bw,
> hatmatrix=TRUE, lonlat =FALSE)
>
> What I would like to know is
>
> d1(i)-hat{d1(i)}/hat{sigma(i)}
> where i denotes the ith location in a map.

The components for a sigma(i) are not currently returned by .GWR_int(), 
the workhorse function inside gwr(). The local RSS is calculated to get to 
the local coefficient of determination, so it could be returned in one 
form or other (but what would be a sensible residual degrees of freedom?). 
Whether you should trust the output is a completely different question.

If you want to infer, it is perhaps reasonable to look at Bayesian GWR, 
which would give you a distribution of the local residual, but even so, 
until the collinearity problem is resolved, caution is still the key thing 
to keep in focus (in my opinion).

Roger

>
> I did a bit of search and "lokern" pacakge came up, but this is only for
> bivarriate case and not particularly spatial-oriented.
>
> Sorry for ambiguity of my question...  I appreciate if someone could
> give me some clues.....
>
> thanks
>
> tk
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From cavallini at faunalia.it  Mon Feb 18 17:21:24 2008
From: cavallini at faunalia.it (Paolo Cavallini)
Date: Mon, 18 Feb 2008 17:21:24 +0100
Subject: [R-sig-Geo] problem in creating shp files
Message-ID: <47B9B084.8040103@faunalia.it>

Hi all.
write.pointShape(coordinates=coordinates(fix_data), df=as(fix_data,
"data.frame"), "sample")

gives correct shapefiles. With:

write.pointShape(coordinates=coordinates(fix_data), df=as(fix_data,
"data.frame"), "sample.shp")

the output is:

sample.shp
sample.shx
*sample.shp.dbf*

which of course is not correct. A trivial issue, of course.
All the best.
pc
-- 
Paolo Cavallini, see: http://www.faunalia.it/pc



From Roger.Bivand at nhh.no  Mon Feb 18 20:40:18 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 18 Feb 2008 20:40:18 +0100 (CET)
Subject: [R-sig-Geo] problem in creating shp files
In-Reply-To: <47B9B084.8040103@faunalia.it>
References: <47B9B084.8040103@faunalia.it>
Message-ID: <Pine.LNX.4.64.0802182038590.9995@reclus.nhh.no>

On Mon, 18 Feb 2008, Paolo Cavallini wrote:

> Hi all.
> write.pointShape(coordinates=coordinates(fix_data), df=as(fix_data,
> "data.frame"), "sample")
>
> gives correct shapefiles. With:
>
> write.pointShape(coordinates=coordinates(fix_data), df=as(fix_data,
> "data.frame"), "sample.shp")
>
> the output is:
>
> sample.shp
> sample.shx
> *sample.shp.dbf*
>
> which of course is not correct. A trivial issue, of course.

Yes, the help page did say without extension, and I did trust users to 
read it! Fixed in release submitted to CRAN, thanks,

Roger

> All the best.
> pc
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From MMSullivan at ric.edu  Tue Feb 19 13:58:36 2008
From: MMSullivan at ric.edu (Sullivan, Mary M)
Date: Tue, 19 Feb 2008 07:58:36 -0500
Subject: [R-sig-Geo] incorporating covariates
Message-ID: <38329C144184084CA2E572C51002D8FECEF847@mailsvr1.RICOL.EDU>

I will be using geoRglm for binary outcome data.  In addition to locations, there are 8 covariates.  I am having difficulty in finding support for incorporating the covariates into the analysis.  Can someone offer guidance?
 
Thanks.
 
 
Mary M. Sullivan, Ed. D. 
Professor of Mathematics and Educational Studies 
Rhode Island College 
600 Mt. Pleasant Ave. Providence, RI 02908 
401-456-9851
mmsullivan at ric.edu



From paulojus at c3sl.ufpr.br  Tue Feb 19 14:09:03 2008
From: paulojus at c3sl.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Tue, 19 Feb 2008 10:09:03 -0300 (BRT)
Subject: [R-sig-Geo] incorporating covariates
In-Reply-To: <38329C144184084CA2E572C51002D8FECEF847@mailsvr1.RICOL.EDU>
References: <38329C144184084CA2E572C51002D8FECEF847@mailsvr1.RICOL.EDU>
Message-ID: <Pine.LNX.4.58.0802191006500.2959@macalan.c3sl.ufpr.br>

Mary

You have to use the argument "trend" to specify the covariates in your
model typically as formula (although matrices/data-frames can also be
used)

For example:

likfit.glms(..., trend = ~ covar1 + covar2, ...)

Paulo Justiniano Ribeiro Jr
LEG (Laboratorio de Estatistica e Geoinformacao)
Universidade Federal do Parana
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 3361 3573
Fax: (+55) 41 3361 3141
e-mail: paulojus AT  ufpr  br
http://www.leg.ufpr.br/~paulojus

-------------------------------------------------------------------------
53a Reuniao Anual da Regiao Brasileira da Soc. Internacional de Biometria
14 a 16/05/2008, UFLA, Lavras,MG
http://www.rbras.org.br/rbras53
-------------------------------------------------------------------------


On Tue, 19 Feb 2008, Sullivan, Mary M wrote:

> I will be using geoRglm for binary outcome data.  In addition to locations, there are 8 covariates.  I am having difficulty in finding support for incorporating the covariates into the analysis.  Can someone offer guidance?
>
> Thanks.
>
>
> Mary M. Sullivan, Ed. D.
> Professor of Mathematics and Educational Studies
> Rhode Island College
> 600 Mt. Pleasant Ave. Providence, RI 02908
> 401-456-9851
> mmsullivan at ric.edu
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From rossiter at itc.nl  Tue Feb 19 14:39:07 2008
From: rossiter at itc.nl (David Rossiter)
Date: Tue, 19 Feb 2008 14:39:07 +0100
Subject: [R-sig-Geo] R/gstat UK with indicators
Message-ID: <5AF149DBB6DFE24AA3F4F53201E539AD01999CF7@itcnt24.itc.nl>

I am sure Edzer can answer this, but I post it to the list because it
may be of general interest.

If I compute an indicator:

> data(meuse)
> meuse$i.Pb.med <- meuse$lead < median(meuse$lead)

I can of course compute an indicator variogram and krige at new
locations:

> vi <- variogram(i.Pb.med ~1, meuse)
> plot(vi, pl=T)
> (vim <- fit.variogram(vi, vgm(0.17, "Sph", 600, 0.1)))
  model      psill    range
1   Nug 0.08772438   0.0000
2   Sph 0.18157082 691.2488
> plot(vi, pl=T, model=vim)
> ki <- krige(i.Pb.med ~1, meuse, newdata=meuse.grid, model=vm)
[using ordinary kriging]
> summary(ki$var1.pred)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
0.03628 0.33830 0.64020 0.58080 0.81610 0.95040 

I can also fit a logistic regression model to the indicator with a GLM:

> (gm <- glm(i.Pb.med ~ dist, family="binomial", data=meuse at data))
(Intercept)         dist  
     -2.562       11.662  
Degrees of Freedom: 154 Total (i.e. Null);  153 Residual
Null Deviance:      214.9   Residual Deviance: 131.2        AIC: 135.2 

Here the ~ in the formula is interpreted according to the link function.

I can compute residuals from the GLM, get the residual variogram, and
model it:

> meuse$glm.r <- residuals(gm)
> v <- variogram(glm.r ~ 1, meuse, cutoff=1000)	
> plot(v, pl=T)
> vm <- vgm(0.45, "Exp", 450, 0.6) # eyeball fit

But, what happens when I use the same formula in gstat?

First, just to compute the residual variogram:
> vr <- variogram(i.Pb.med ~ dist, meuse, cutoff=1000)
The two residual variograms are very different:

> max(v$gamma)
[1] 1.001015
> max(vr$gamma)
[1] 0.1741679

So clearly the formula (i.Pb.med ~ dist) is being interpreted as a
linear model, not a logit model.

Second, an attempt at kriging with external drift:

> ked <- krige(i.Pb.med ~ dist, loc=meuse, newdata=meuse.grid, model=vm)
[using universal kriging]

Since I could not specify a link function, it seems that a linear model
is being fit (not a logit model).

And we see very strange results for an indicator:

> summary(ked$var1.pred)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
-0.1235  0.2719  0.6550  0.6056  0.9139  1.4990 

So (after all that buildup), I just want to know if my interpretation is
correct, that gstat is not interpreting the formula in krige() or in
variogram() as a GLM, rather as a linear model, which doesn't make sense
with indicators.

Thank you,

D G Rossiter
Senior University Lecturer
Department of Earth Systems Analysis (DESA)
International Institute for Geo-Information Science and Earth
Observation (ITC)
Enschede, The Netherlands
Internet: http://www.itc.nl/personal/rossiter
 



From hengl at science.uva.nl  Wed Feb 20 08:19:04 2008
From: hengl at science.uva.nl (Tomislav Hengl)
Date: Wed, 20 Feb 2008 08:19:04 +0100 (CET)
Subject: [R-sig-Geo] R/gstat UK with indicators
In-Reply-To: <5AF149DBB6DFE24AA3F4F53201E539AD01999CF7@itcnt24.itc.nl>
References: <5AF149DBB6DFE24AA3F4F53201E539AD01999CF7@itcnt24.itc.nl>
Message-ID: <49377.77.164.33.209.1203491944.squirrel@webmail.science.uva.nl>


David,

Thanks for you note. It is a very clear example and I have experienced
this problem many times.

If I can be of any assistance, here are few discussion points that might
put some light on the whole thing.

Gstat does not support any stat models different than linear. This is
mainly because gstat implements the so-called "Kriging with External
Drift" algorithm (covariances of residuals extended with auxiliary
predictors). This algorithm is rather elegant and gives then equivalent
results as if you would first estimate linear regression by GLS and then
interpolate and sum the residuals. But the drawback of KED is that it only
works with linear models (multiple linear regression). As far as I know,
KED has been implemented in all software that can run universal kriging
interpolation with auxiliary predictors (maps).

The alternative is to run the so-called "Regression-kriging" approach
where you separately model the deterministic and stochastic part (as you
have also demonstrated; see also sec 2.1 of my lecture notes). However, I
think that there is a complete theory missing (maybe you should report on
this?)! For example, if you apply binomial link function, GAMs or
regression trees, I have a feeling that you should also consider the
spatio-correlation during the estimation of the model parameters. In the
case of multiple regression, covariance matrix is used to account for
spreading (clustering) of the points in the space. In your example, you
fit a GLM that completely ignores location of the points, so I have a
feeling that it is not statistically optimal.

We have also reported recently on interpolation of soil categories
(http://dx.doi.org/10.1016/j.geoderma.2007.04.022). We discovered that the
easiest thing to do is to actually have memberships instead of indicators
(it is also easier to fit variograms if you work with memberships). Then
the system is equivalent to regression-kriging (after logit
transformation), so then you do not have to worry about the link function
(see also section 4.3.3 and Fig. 4.15 of my lecture notes).

All the best,

Tom Hengl
http://spatial-analyst.net

Hengl, T., 2007. A Practical Guide to Geostatistical Mapping of
Environmental Variables. EUR 22904 EN Scientific and Technical Research
series, Office for Official Publications of the European Communities,
Luxemburg, 143 pp.
http://bookshop.europa.eu/uri?target=EUB:NOTICE:LBNA22904:EN:HTML




> I am sure Edzer can answer this, but I post it to the list because it
> may be of general interest.
>
> If I compute an indicator:
>
>> data(meuse)
>> meuse$i.Pb.med <- meuse$lead < median(meuse$lead)
>
> I can of course compute an indicator variogram and krige at new
> locations:
>
>> vi <- variogram(i.Pb.med ~1, meuse)
>> plot(vi, pl=T)
>> (vim <- fit.variogram(vi, vgm(0.17, "Sph", 600, 0.1)))
>   model      psill    range
> 1   Nug 0.08772438   0.0000
> 2   Sph 0.18157082 691.2488
>> plot(vi, pl=T, model=vim)
>> ki <- krige(i.Pb.med ~1, meuse, newdata=meuse.grid, model=vm)
> [using ordinary kriging]
>> summary(ki$var1.pred)
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> 0.03628 0.33830 0.64020 0.58080 0.81610 0.95040
>
> I can also fit a logistic regression model to the indicator with a GLM:
>
>> (gm <- glm(i.Pb.med ~ dist, family="binomial", data=meuse at data))
> (Intercept)         dist
>      -2.562       11.662
> Degrees of Freedom: 154 Total (i.e. Null);  153 Residual
> Null Deviance:      214.9   Residual Deviance: 131.2        AIC: 135.2
>
> Here the ~ in the formula is interpreted according to the link function.
>
> I can compute residuals from the GLM, get the residual variogram, and
> model it:
>
>> meuse$glm.r <- residuals(gm)
>> v <- variogram(glm.r ~ 1, meuse, cutoff=1000)
>> plot(v, pl=T)
>> vm <- vgm(0.45, "Exp", 450, 0.6) # eyeball fit
>
> But, what happens when I use the same formula in gstat?
>
> First, just to compute the residual variogram:
>> vr <- variogram(i.Pb.med ~ dist, meuse, cutoff=1000)
> The two residual variograms are very different:
>
>> max(v$gamma)
> [1] 1.001015
>> max(vr$gamma)
> [1] 0.1741679
>
> So clearly the formula (i.Pb.med ~ dist) is being interpreted as a
> linear model, not a logit model.
>
> Second, an attempt at kriging with external drift:
>
>> ked <- krige(i.Pb.med ~ dist, loc=meuse, newdata=meuse.grid, model=vm)
> [using universal kriging]
>
> Since I could not specify a link function, it seems that a linear model
> is being fit (not a logit model).
>
> And we see very strange results for an indicator:
>
>> summary(ked$var1.pred)
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> -0.1235  0.2719  0.6550  0.6056  0.9139  1.4990
>
> So (after all that buildup), I just want to know if my interpretation is
> correct, that gstat is not interpreting the formula in krige() or in
> variogram() as a GLM, rather as a linear model, which doesn't make sense
> with indicators.
>
> Thank you,
>
> D G Rossiter
> Senior University Lecturer
> Department of Earth Systems Analysis (DESA)
> International Institute for Geo-Information Science and Earth
> Observation (ITC)
> Enschede, The Netherlands
> Internet: http://www.itc.nl/personal/rossiter
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Roger.Bivand at nhh.no  Wed Feb 20 08:55:51 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 20 Feb 2008 08:55:51 +0100 (CET)
Subject: [R-sig-Geo] R/gstat UK with indicators
In-Reply-To: <49377.77.164.33.209.1203491944.squirrel@webmail.science.uva.nl>
References: <5AF149DBB6DFE24AA3F4F53201E539AD01999CF7@itcnt24.itc.nl>
	<49377.77.164.33.209.1203491944.squirrel@webmail.science.uva.nl>
Message-ID: <Pine.LNX.4.64.0802200838300.19112@reclus.nhh.no>

On Wed, 20 Feb 2008, Tomislav Hengl wrote:

>
> David,
>
> Thanks for you note. It is a very clear example and I have experienced
> this problem many times.
>
> If I can be of any assistance, here are few discussion points that might
> put some light on the whole thing.
>
> Gstat does not support any stat models different than linear. This is
> mainly because gstat implements the so-called "Kriging with External
> Drift" algorithm (covariances of residuals extended with auxiliary
> predictors). This algorithm is rather elegant and gives then equivalent
> results as if you would first estimate linear regression by GLS and then
> interpolate and sum the residuals. But the drawback of KED is that it only
> works with linear models (multiple linear regression). As far as I know,
> KED has been implemented in all software that can run universal kriging
> interpolation with auxiliary predictors (maps).
>
> The alternative is to run the so-called "Regression-kriging" approach
> where you separately model the deterministic and stochastic part (as you
> have also demonstrated; see also sec 2.1 of my lecture notes). However, I
> think that there is a complete theory missing (maybe you should report on
> this?)! For example, if you apply binomial link function, GAMs or
> regression trees, I have a feeling that you should also consider the
> spatio-correlation during the estimation of the model parameters. In the
> case of multiple regression, covariance matrix is used to account for
> spreading (clustering) of the points in the space. In your example, you
> fit a GLM that completely ignores location of the points, so I have a
> feeling that it is not statistically optimal.
>
> We have also reported recently on interpolation of soil categories
> (http://dx.doi.org/10.1016/j.geoderma.2007.04.022). We discovered that the
> easiest thing to do is to actually have memberships instead of indicators
> (it is also easier to fit variograms if you work with memberships). Then
> the system is equivalent to regression-kriging (after logit
> transformation), so then you do not have to worry about the link function
> (see also section 4.3.3 and Fig. 4.15 of my lecture notes).

Would it be possible to try several of the alternatives and see where they 
go? One possibility is the use of GLMM (the MASS variant glmmPQL()) as 
reported in Dormann et al. 2007 with tricks to include a spatial 
correlation term? Reference in:

https://stat.ethz.ch/pipermail/r-sig-geo/2008-January/003084.html

Is another to follow up Paulo Ribeiro's reply to a geoRglm question 
yesterday about using the trend= argument in setting up the controls for 
Binomial or Poisson kriging?

Further, I don't think that either spBayes or ramps get you there yet, but 
I would be surprised if at least some of the infrastructure isn't included 
already. Section 5.2 in Banerjee et al. is suggestive, and spBayes is by 
the book's authors.

As Tom says, this is all fairly speculative and fresh, but at least offers 
something for small data sets and people with lots of patience! The 
spBayes JSS paper suggests that their engine performs better than geoRglm, 
but I guess there are horses for courses. The JSS link:

http://www.jstatsoft.org/v19/i04

Hope this helps,

Roger

>
> All the best,
>
> Tom Hengl
> http://spatial-analyst.net
>
> Hengl, T., 2007. A Practical Guide to Geostatistical Mapping of
> Environmental Variables. EUR 22904 EN Scientific and Technical Research
> series, Office for Official Publications of the European Communities,
> Luxemburg, 143 pp.
> http://bookshop.europa.eu/uri?target=EUB:NOTICE:LBNA22904:EN:HTML
>
>
>
>
>> I am sure Edzer can answer this, but I post it to the list because it
>> may be of general interest.
>>
>> If I compute an indicator:
>>
>>> data(meuse)
>>> meuse$i.Pb.med <- meuse$lead < median(meuse$lead)
>>
>> I can of course compute an indicator variogram and krige at new
>> locations:
>>
>>> vi <- variogram(i.Pb.med ~1, meuse)
>>> plot(vi, pl=T)
>>> (vim <- fit.variogram(vi, vgm(0.17, "Sph", 600, 0.1)))
>>   model      psill    range
>> 1   Nug 0.08772438   0.0000
>> 2   Sph 0.18157082 691.2488
>>> plot(vi, pl=T, model=vim)
>>> ki <- krige(i.Pb.med ~1, meuse, newdata=meuse.grid, model=vm)
>> [using ordinary kriging]
>>> summary(ki$var1.pred)
>>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>> 0.03628 0.33830 0.64020 0.58080 0.81610 0.95040
>>
>> I can also fit a logistic regression model to the indicator with a GLM:
>>
>>> (gm <- glm(i.Pb.med ~ dist, family="binomial", data=meuse at data))
>> (Intercept)         dist
>>      -2.562       11.662
>> Degrees of Freedom: 154 Total (i.e. Null);  153 Residual
>> Null Deviance:      214.9   Residual Deviance: 131.2        AIC: 135.2
>>
>> Here the ~ in the formula is interpreted according to the link function.
>>
>> I can compute residuals from the GLM, get the residual variogram, and
>> model it:
>>
>>> meuse$glm.r <- residuals(gm)
>>> v <- variogram(glm.r ~ 1, meuse, cutoff=1000)
>>> plot(v, pl=T)
>>> vm <- vgm(0.45, "Exp", 450, 0.6) # eyeball fit
>>
>> But, what happens when I use the same formula in gstat?
>>
>> First, just to compute the residual variogram:
>>> vr <- variogram(i.Pb.med ~ dist, meuse, cutoff=1000)
>> The two residual variograms are very different:
>>
>>> max(v$gamma)
>> [1] 1.001015
>>> max(vr$gamma)
>> [1] 0.1741679
>>
>> So clearly the formula (i.Pb.med ~ dist) is being interpreted as a
>> linear model, not a logit model.
>>
>> Second, an attempt at kriging with external drift:
>>
>>> ked <- krige(i.Pb.med ~ dist, loc=meuse, newdata=meuse.grid, model=vm)
>> [using universal kriging]
>>
>> Since I could not specify a link function, it seems that a linear model
>> is being fit (not a logit model).
>>
>> And we see very strange results for an indicator:
>>
>>> summary(ked$var1.pred)
>>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>> -0.1235  0.2719  0.6550  0.6056  0.9139  1.4990
>>
>> So (after all that buildup), I just want to know if my interpretation is
>> correct, that gstat is not interpreting the formula in krige() or in
>> variogram() as a GLM, rather as a linear model, which doesn't make sense
>> with indicators.
>>
>> Thank you,
>>
>> D G Rossiter
>> Senior University Lecturer
>> Department of Earth Systems Analysis (DESA)
>> International Institute for Geo-Information Science and Earth
>> Observation (ITC)
>> Enschede, The Netherlands
>> Internet: http://www.itc.nl/personal/rossiter
>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From paulojus at c3sl.ufpr.br  Wed Feb 20 14:10:20 2008
From: paulojus at c3sl.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Wed, 20 Feb 2008 10:10:20 -0300 (BRT)
Subject: [R-sig-Geo] R/gstat UK with indicators
In-Reply-To: <Pine.LNX.4.64.0802200838300.19112@reclus.nhh.no>
References: <5AF149DBB6DFE24AA3F4F53201E539AD01999CF7@itcnt24.itc.nl>
	<49377.77.164.33.209.1203491944.squirrel@webmail.science.uva.nl>
	<Pine.LNX.4.64.0802200838300.19112@reclus.nhh.no>
Message-ID: <Pine.LNX.4.58.0802200956320.31065@macalan.c3sl.ufpr.br>

Dear Tom, Roger and Edzer

Here are my 2 cents:
I'm not surprised with the diferences Tom pointed, since this is also my
experience.
Taking residuas from a GLM is rather different from using indicator
variables. Also there may be even some differences depending on which
kind of GLM residuals you take.
Run a GLM and exploring the residuals e.g. via variograms, is something I
consider a routine practice, but it does not aways tell you the whole
story. Fitting a GLGM (generealised linear geostatitical model) can be
more conclusive since you can do infereces on the model parameters
and access the relevance of the spatial term more objectively.
This was the original motivation for geoRglm doing all the modelling at
once and not by two steps such as fitting a model without correlation and
then modelling residuals. This came with the extra burden of calibrating
the MCMC algorithms.
Later spBayes came to scene and indeed looks promissing proposing a more
general framework whereas geoRglm is rather specific to univariate
binomial and poison models.

As Roger says there is scope to play around with other alternatives like
the GLMM or maybe MCMCpack, but this is certainly not ready
"out-of-the-box" and code will need to be adapted for spatial purposes.


regards to all

Paulo Justiniano Ribeiro Jr
LEG (Laboratorio de Estatistica e Geoinformacao)
Universidade Federal do Parana
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 3361 3573
Fax: (+55) 41 3361 3141
e-mail: paulojus AT  ufpr  br
http://www.leg.ufpr.br/~paulojus

-------------------------------------------------------------------------
53a Reuniao Anual da Regiao Brasileira da Soc. Internacional de Biometria
14 a 16/05/2008, UFLA, Lavras,MG
http://www.rbras.org.br/rbras53
-------------------------------------------------------------------------


On Wed, 20 Feb 2008, Roger Bivand wrote:

> On Wed, 20 Feb 2008, Tomislav Hengl wrote:
>
> >
> > David,
> >
> > Thanks for you note. It is a very clear example and I have experienced
> > this problem many times.
> >
> > If I can be of any assistance, here are few discussion points that might
> > put some light on the whole thing.
> >
> > Gstat does not support any stat models different than linear. This is
> > mainly because gstat implements the so-called "Kriging with External
> > Drift" algorithm (covariances of residuals extended with auxiliary
> > predictors). This algorithm is rather elegant and gives then equivalent
> > results as if you would first estimate linear regression by GLS and then
> > interpolate and sum the residuals. But the drawback of KED is that it only
> > works with linear models (multiple linear regression). As far as I know,
> > KED has been implemented in all software that can run universal kriging
> > interpolation with auxiliary predictors (maps).
> >
> > The alternative is to run the so-called "Regression-kriging" approach
> > where you separately model the deterministic and stochastic part (as you
> > have also demonstrated; see also sec 2.1 of my lecture notes). However, I
> > think that there is a complete theory missing (maybe you should report on
> > this?)! For example, if you apply binomial link function, GAMs or
> > regression trees, I have a feeling that you should also consider the
> > spatio-correlation during the estimation of the model parameters. In the
> > case of multiple regression, covariance matrix is used to account for
> > spreading (clustering) of the points in the space. In your example, you
> > fit a GLM that completely ignores location of the points, so I have a
> > feeling that it is not statistically optimal.
> >
> > We have also reported recently on interpolation of soil categories
> > (http://dx.doi.org/10.1016/j.geoderma.2007.04.022). We discovered that the
> > easiest thing to do is to actually have memberships instead of indicators
> > (it is also easier to fit variograms if you work with memberships). Then
> > the system is equivalent to regression-kriging (after logit
> > transformation), so then you do not have to worry about the link function
> > (see also section 4.3.3 and Fig. 4.15 of my lecture notes).
>
> Would it be possible to try several of the alternatives and see where they
> go? One possibility is the use of GLMM (the MASS variant glmmPQL()) as
> reported in Dormann et al. 2007 with tricks to include a spatial
> correlation term? Reference in:
>
> https://stat.ethz.ch/pipermail/r-sig-geo/2008-January/003084.html
>
> Is another to follow up Paulo Ribeiro's reply to a geoRglm question
> yesterday about using the trend= argument in setting up the controls for
> Binomial or Poisson kriging?
>
> Further, I don't think that either spBayes or ramps get you there yet, but
> I would be surprised if at least some of the infrastructure isn't included
> already. Section 5.2 in Banerjee et al. is suggestive, and spBayes is by
> the book's authors.
>
> As Tom says, this is all fairly speculative and fresh, but at least offers
> something for small data sets and people with lots of patience! The
> spBayes JSS paper suggests that their engine performs better than geoRglm,
> but I guess there are horses for courses. The JSS link:
>
> http://www.jstatsoft.org/v19/i04
>
> Hope this helps,
>
> Roger
>
> >
> > All the best,
> >
> > Tom Hengl
> > http://spatial-analyst.net
> >
> > Hengl, T., 2007. A Practical Guide to Geostatistical Mapping of
> > Environmental Variables. EUR 22904 EN Scientific and Technical Research
> > series, Office for Official Publications of the European Communities,
> > Luxemburg, 143 pp.
> > http://bookshop.europa.eu/uri?target=EUB:NOTICE:LBNA22904:EN:HTML
> >
> >
> >
> >
> >> I am sure Edzer can answer this, but I post it to the list because it
> >> may be of general interest.
> >>
> >> If I compute an indicator:
> >>
> >>> data(meuse)
> >>> meuse$i.Pb.med <- meuse$lead < median(meuse$lead)
> >>
> >> I can of course compute an indicator variogram and krige at new
> >> locations:
> >>
> >>> vi <- variogram(i.Pb.med ~1, meuse)
> >>> plot(vi, pl=T)
> >>> (vim <- fit.variogram(vi, vgm(0.17, "Sph", 600, 0.1)))
> >>   model      psill    range
> >> 1   Nug 0.08772438   0.0000
> >> 2   Sph 0.18157082 691.2488
> >>> plot(vi, pl=T, model=vim)
> >>> ki <- krige(i.Pb.med ~1, meuse, newdata=meuse.grid, model=vm)
> >> [using ordinary kriging]
> >>> summary(ki$var1.pred)
> >>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> >> 0.03628 0.33830 0.64020 0.58080 0.81610 0.95040
> >>
> >> I can also fit a logistic regression model to the indicator with a GLM:
> >>
> >>> (gm <- glm(i.Pb.med ~ dist, family="binomial", data=meuse at data))
> >> (Intercept)         dist
> >>      -2.562       11.662
> >> Degrees of Freedom: 154 Total (i.e. Null);  153 Residual
> >> Null Deviance:      214.9   Residual Deviance: 131.2        AIC: 135.2
> >>
> >> Here the ~ in the formula is interpreted according to the link function.
> >>
> >> I can compute residuals from the GLM, get the residual variogram, and
> >> model it:
> >>
> >>> meuse$glm.r <- residuals(gm)
> >>> v <- variogram(glm.r ~ 1, meuse, cutoff=1000)
> >>> plot(v, pl=T)
> >>> vm <- vgm(0.45, "Exp", 450, 0.6) # eyeball fit
> >>
> >> But, what happens when I use the same formula in gstat?
> >>
> >> First, just to compute the residual variogram:
> >>> vr <- variogram(i.Pb.med ~ dist, meuse, cutoff=1000)
> >> The two residual variograms are very different:
> >>
> >>> max(v$gamma)
> >> [1] 1.001015
> >>> max(vr$gamma)
> >> [1] 0.1741679
> >>
> >> So clearly the formula (i.Pb.med ~ dist) is being interpreted as a
> >> linear model, not a logit model.
> >>
> >> Second, an attempt at kriging with external drift:
> >>
> >>> ked <- krige(i.Pb.med ~ dist, loc=meuse, newdata=meuse.grid, model=vm)
> >> [using universal kriging]
> >>
> >> Since I could not specify a link function, it seems that a linear model
> >> is being fit (not a logit model).
> >>
> >> And we see very strange results for an indicator:
> >>
> >>> summary(ked$var1.pred)
> >>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> >> -0.1235  0.2719  0.6550  0.6056  0.9139  1.4990
> >>
> >> So (after all that buildup), I just want to know if my interpretation is
> >> correct, that gstat is not interpreting the formula in krige() or in
> >> variogram() as a GLM, rather as a linear model, which doesn't make sense
> >> with indicators.
> >>
> >> Thank you,
> >>
> >> D G Rossiter
> >> Senior University Lecturer
> >> Department of Earth Systems Analysis (DESA)
> >> International Institute for Geo-Information Science and Earth
> >> Observation (ITC)
> >> Enschede, The Netherlands
> >> Internet: http://www.itc.nl/personal/rossiter
> >>
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at stat.math.ethz.ch
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From basille at biomserv.univ-lyon1.fr  Thu Feb 21 12:59:37 2008
From: basille at biomserv.univ-lyon1.fr (Mathieu Basille)
Date: Thu, 21 Feb 2008 12:59:37 +0100
Subject: [R-sig-Geo] SpatialPolygonsDataFrame visualization
In-Reply-To: <Pine.LNX.4.64.0802140912070.6874@reclus.nhh.no>
References: <47B1F4E9.7030708@biomserv.univ-lyon1.fr>
	<47B22CB1.3030706@nceas.ucsb.edu>
	<47B37DBD.6020301@biomserv.univ-lyon1.fr>
	<Pine.LNX.4.64.0802140912070.6874@reclus.nhh.no>
Message-ID: <47BD67A9.2010302@biomserv.univ-lyon1.fr>

Dear Roger, Rick, Paul and others on the list,

Thanks for the advice on the use of lattice. Indeed, lattice may not be 
the right approach here. The only one possibility that I could find was 
the use of the 'split' argument to print 1 by 1 the layers I want. 
However, it was not totally satisfactory for several reasons.

Finally, I ended up with a function based on the regular 'plot':

plotsp <- function (x, var = names(x), mar = if (length(var) > 1) c(0,
     0, 2, 0) else c(5.1, 4.1, 4.1, 2.1), mfrow = NULL)
{
     if (!inherits(x, "SpatialPolygonsDataFrame"))
         stop("object of class SpatialPolygonsDataFrame expected")
     if (is.null(mfrow))
         mfrow = n2mfrow(length(var))
     opar <- par(mfrow = mfrow, mar = mar)
     on.exit(par(opar))
     for (i in var) {
         plot(x, col = ifelse(is.na(x at data[, i]), "red", grey(1 -
             rank(as.numeric(x at data[, i]))/length(x at data[, i]))))
         title(i)
         box()
     }
}

This function plots the selected layers (all if none selected) in 
adjacent boxes with levels of grey, and with polygons in red when they 
are associated with NAs. It works on SpatialPolygonsDataFrame, with 
factors or numeric, but can probably be adapted for SpatialPixelsDataFrame.

It is not exactly what I wanted, since I don't have anymore the 
colorkey, but at least I can visualize at once the NA on several layers 
that represent different variables.

Thanks again for the hints,
Mathieu.



Roger Bivand a ?crit :
> On Thu, 14 Feb 2008, Mathieu Basille wrote:
> 
>> Thanks Rick for the hints.
>>
>> I have to admit, however, that it is so far a huge failure. I have been
>> able to play a bit with the color key (arg 'colokey' that sets the
>> position, the colors, the tick marks, height & width, etc.) and the
>> color of one map (arg 'col.regions', for finite values of the layer),
>> but I'm still unable to
>> 1) have different scales for different layers (i.e. one color key per
>> layer);
> 
> This suggests that you really should not be using lattice graphics, 
> because they are specifically written for conditional plots, so 
> necessarily on the same scale for comparision
> 
>> 2) color NA with a non-contiguous color from other finite values. From
>> my different tests, NA are always white (I wish I could fill them in red
>> for example, with finite values in a gradient of grey).
>>
>> In addition, I'm totally lost in the help pages of xyplot and levelplot
>> (lattice), and the graph gallery of sp didn't help neither.
>>
>> Any other resource or tutorial for this?
> 
> There is Paul Murrell's R Graphics book (Chapman & Hall/CRC), and 
> lattice author Deepayan Sarkar's forthcoming lattice book (Springer useR 
> series), but lattice is, I think, not what you want if you want to 
> control things yourself. Just use base graphics and build things up 
> layer by layer.
> 
> Lattice is superb for what it is designed for, by the way, say 
> conditioning earthquake location by depth as the classic example, or 
> plotting anisotropic variograms by direction.
> 
> Roger
> 
>> Thanks in advance,
>> Mathieu.
>>
>>
>> Rick Reeves a ?crit :
>>> Mathiu:
>>>
>>> The attached use case might help: It is not exactly what you are looking
>>> for, but the last map
>>> demonstrates use of the spplot function to create a 'display list' that
>>> plots vector and raster
>>> data layers on a single map. Also some hints on creating a map scale and
>>> legend.
>>>
>>> http://nceas.ucsb.edu/scicomp/GISSeminar/UseCases/MapProdWithRGraphics/OneMapProdWithRGraphics.html 
>>>
>>>
>>>
>>> Regards,
>>> Rick Reeves
>>>
>>> Mathieu Basille wrote:
>>>> Hello everyone,
>>>>
>>>> I'm not very familiar with visualization of spatial objects in R,
>>>> especially with the possibilities of the spplot function...
>>>>
>>>> I have a SpatialPolygonsDataFrame and I'd like to obtain a map with a
>>>> specific scale for each layer (not in the geographic space, but in the
>>>> data), instead of the same one for every one. In my case, the layers
>>>> represent different variables, not on the same scale (e.g. elevation
>>>> and rain).
>>>>
>>>> Additionally, I'd like to represent NA's with a particular color (say
>>>> black so that we can see immediately where they occur).
>>>>
>>>> I guess these 2 issues are somehow related, but I didn't manage to
>>>> solve them. The help pages of spplot or xyplot didn't really help...
>>>>
>>>> Any hint how to do that?
>>>> Thanks in advance,
>>>> Mathieu.
>>>>
>>>>
>>>> > version
>>>> platform       i486-pc-linux-gnu
>>>> svn rev        43537
>>>> version.string R version 2.6.1 (2007-11-26)
>>>> sp: sp_0.9-19
>>
>>
>>
> 


-- 

????????????????????????????????????????????????
                                                 ]
  Mathieu BASILLE -- PhD Student                 ]
                                                 ]
  Laboratoire de Biom?trie et Biologie ?volutive ]
  Universit? Claude Bernard Lyon 1 - France      ]
   http://lbbe.univ-lyon1.fr/                    ]
                                                 ]
  My resume:                                     ]
   http://mathieu.basille.net/pro/               ]
  Habitat web-site:                              ]
   http://biomserv.univ-lyon1.fr/spip_habitat/   ]
________________________________________________]



From Agustin.Lobo at ija.csic.es  Fri Feb 22 12:24:31 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Fri, 22 Feb 2008 12:24:31 +0100
Subject: [R-sig-Geo] shape of circles
Message-ID: <47BEB0EF.9080701@ija.csic.es>

Hi!

I have to create a shp of "circular" polygons
out of a file with x,y coordinates and radii.

I've found that disc() from package GRID makes
an owin object for each circle, but then how can
I convert to sp (from there to shp using writeOGR)?

Thanks

Agus
-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From b.rowlingson at lancaster.ac.uk  Fri Feb 22 13:20:18 2008
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 22 Feb 2008 12:20:18 +0000
Subject: [R-sig-Geo] shape of circles
In-Reply-To: <47BEB0EF.9080701@ija.csic.es>
References: <47BEB0EF.9080701@ija.csic.es>
Message-ID: <47BEBE02.8000904@lancaster.ac.uk>

Agustin Lobo wrote:
> Hi!
> 
> I have to create a shp of "circular" polygons
> out of a file with x,y coordinates and radii.
> 
> I've found that disc() from package GRID makes
> an owin object for each circle, but then how can
> I convert to sp (from there to shp using writeOGR)?

To generate n points on a circle centred at (x,y) of radius r you can do:

circle = 
function(x,y,r,n=100){t=seq(0,2*pi,len=n+1)[-1];return(cbind(r*sin(t),r*cos(t)))}

Increasing the n parameter makes the circle smoother. n=4 gives a 
square! Note this function doesn't generate duplicate points at start 
and finish.

  From here to sp should be trivial...

Barry



From Agustin.Lobo at ija.csic.es  Sat Feb 23 21:02:26 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Sat, 23 Feb 2008 21:02:26 +0100
Subject: [R-sig-Geo] shape of circles
In-Reply-To: <47BEBE02.8000904@lancaster.ac.uk>
References: <47BEB0EF.9080701@ija.csic.es> <47BEBE02.8000904@lancaster.ac.uk>
Message-ID: <47C07BD2.3010708@ija.csic.es>

Thanks!

This is what I've made. I'm sure it can be done
in a much more elegant way, but hopefully it will
be useful for other people.

"circles" <- function(x=presspUTM2 at coords[,1],y=presspUTM2 at coords[,2],
		r=rep(10,nrow(presspUTM2 at coords)), n=100, 					ID=presspUTM2 at data$ID, 
datos=presspUTM2 at data)
#According to message from b.rowlingson at lancaster.ac.uk
#Makes polygonal circles at x,y with radii r ready to be saved as shp:
#presspUTM2circles <- circles()
#writeOGR(presspUTM2circles, "J:/Lidia", "presspUTM2circles", 
driver="ESRI Shapefile")

{
   require(sp)
   lista <- vector(length=length(x),mode="list")
   names(lista) <- ID
   for (i in 1:length(x)){
     t=seq(0,2*pi,len=n+1)[-1]
     circunf <- cbind(r[i]*sin(t)+x[i],r[i]*cos(t)+y[i])
     circunf <- rbind(circunf,circunf[1,])
     Sr1 <- Polygon(cbind(circunf[,1], circunf[,2]))
     Sr1 <- Polygons(list(Sr1), ID[i])
     lista[i] <- Sr1
   }
   row.names(datos) <- ID
   Sr<- SpatialPolygons(lista,pO=1:length(x),CRS("+proj=tmerc +lat_0=0 
+lon_0=2.999999982811267 +k=0.999600 +x_0=500000 +y_0=0 +ellps=intl 
+units=m +no_defs"))
   SpatialPolygonsDataFrame(Sr, data=datos, match.ID = TRUE)
}


Barry Rowlingson escribi?:
> Agustin Lobo wrote:
>> Hi!
>>
>> I have to create a shp of "circular" polygons
>> out of a file with x,y coordinates and radii.
>>
>> I've found that disc() from package GRID makes
>> an owin object for each circle, but then how can
>> I convert to sp (from there to shp using writeOGR)?
> 
> To generate n points on a circle centred at (x,y) of radius r you can do:
> 
> circle = 
> function(x,y,r,n=100){t=seq(0,2*pi,len=n+1)[-1];return(cbind(r*sin(t),r*cos(t)))} 
> 
> 
> Increasing the n parameter makes the circle smoother. n=4 gives a 
> square! Note this function doesn't generate duplicate points at start 
> and finish.
> 
>  From here to sp should be trivial...
> 
> Barry
> 
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From mgallay01 at qub.ac.uk  Sun Feb 24 01:05:14 2008
From: mgallay01 at qub.ac.uk (Michal Gallay)
Date: 24 Feb 2008 00:05:14 +0000
Subject: [R-sig-Geo] Creating nb object with cell2nb
In-Reply-To: <47C07BD2.3010708@ija.csic.es>
References: <47BEB0EF.9080701@ija.csic.es> <47BEBE02.8000904@lancaster.ac.uk>
	<47C07BD2.3010708@ija.csic.es>
Message-ID: <Prayer.1.0.12.0802240005140.3299@amos.qub.ac.uk>

Dear R User's,

after attempting to create and 'nb' object with cell2nb
following errror had come up:

install.packages(spdep)
require(spdep)
cell2nb(10,10, type="rook")
Error in UseMethod("as.logical") : no applicable method for "as.logical"

I am using R-2.6.2.

I much appreciate your help.

Regards

Michal


--
Michal Gallay

Postgraduate Research Student
School of Geography, Archaeology and Palaeoecology
Queen's University
Belfast BT7 1NN
Northern Ireland

Tel: +44(0)2890 273929
Fax: +44(0)2890 973212
email: mgallay01 at qub.ac.uk
www: www.qub.ac.uk/geog



From macq at llnl.gov  Sun Feb 24 07:46:40 2008
From: macq at llnl.gov (Don MacQueen)
Date: Sat, 23 Feb 2008 22:46:40 -0800
Subject: [R-sig-Geo] Shortest path around obstacles (OT)
Message-ID: <p06240805c3e6bf8f15ae@[75.208.252.218]>

This question is basically off topic, since it isn't truly an R 
question, though it is certainly related to r-sig-geo. I ask here in 
the hopes that someone can suggest a direction for me to look.

I have a what is essentially a floor plan of a building (lines 
representing walls, breaks in the lines representing doors, and so 
on). I would like to have an algorithm that can calculate the 
shortest distance between any two points (actually, large numbers of 
pairs of points) that does not intersect any line (pass through any 
wall).

My real dream is to use these distances instead of Euclidean 
distances as input to a gaussian random fields algorithm such as 
those in the RandomFields package.

I've done some web-searching for libraries of geometric algorithms 
that might include this task, and have come across references to 
Dystra's algorithm, and some mention of line of sight calculations, 
as well as some algorithms for robotics (how the robot finds a path 
from here to there, passing around obstacles represented as 
polygons). So I have some leads.

None the less, I'd really appreciate any suggestions from the folks 
here on R-sig-geo.

Thanks
-Don
-- 
---------------------------------
Don MacQueen
Lawrence Livermore National Laboratory
Livermore, CA, USA
925-423-1062
macq at llnl.gov



From Roger.Bivand at nhh.no  Sun Feb 24 11:27:35 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 24 Feb 2008 11:27:35 +0100 (CET)
Subject: [R-sig-Geo] Creating nb object with cell2nb
In-Reply-To: <Prayer.1.0.12.0802240005140.3299@amos.qub.ac.uk>
References: <47BEB0EF.9080701@ija.csic.es> <47BEBE02.8000904@lancaster.ac.uk>
	<47C07BD2.3010708@ija.csic.es>
	<Prayer.1.0.12.0802240005140.3299@amos.qub.ac.uk>
Message-ID: <Pine.LNX.4.64.0802241107340.8272@reclus.nhh.no>

On Sun, 24 Feb 2008, Michal Gallay wrote:

> Dear R User's,

Please DO NOT reply on an earlier thread, changing the message subject, if 
you want to start a new thread. Please start a new thread from a fresh 
message (copy the list address to a fresh message)! This message is seen 
in the archives and on gmane (and everywhere else using threads as a 
continuation of the thread on shape of circles.

I'll continue in the thread for now, since it is here.

>
> after attempting to create and 'nb' object with cell2nb
> following errror had come up:
>
> install.packages(spdep)
> require(spdep)
> cell2nb(10,10, type="rook")
> Error in UseMethod("as.logical") : no applicable method for "as.logical"
>
> I am using R-2.6.2.

This has come up several times, both on and off list, and is related to 
NEWS for the 2.6.* release:

     o	Making functions primitive changes the semantics of S4
 	dispatch: these no longer dispatch on classes based on types
 	but do dispatch whenever the function in the base name space is
 	called.

 	This applies to as.complex(), as.integer(), as.logical(),
 	as.numeric(), as.raw(), expm1(), log(), log1p(), log2(),
 	log10(), gamma(), lgamma(), digamma() and trigamma(), as
 	well as the Math2 and Summary groups.

 	Because all members of the group generics are now primitive,
 	they are all S4 generic and setting an S4 group generic does
 	at last apply to all members and not just those already made
 	S4 generic.

 	as.double() and as.real() are identical to as.numeric(), and
 	now remain so even if S4 methods are set on any of them.
 	Since 'as.numeric' is the traditional name used in S4,
 	currently methods must be exported from a NAMESPACE for
 	'as.numeric' only.

It is also mentioned in Breaking news on http://www.R-project.org/Rgeo/, 
point 3. In fact, it can stem from a stale Matrix package in a library in 
.libPaths() - where R looks for pacjkages - or from a stale methods 
package in the same search path. If you say library(), I guess you will 
see something stale in a library. You may also have followed the (bad) 
advice in the R for Windows FAQ to "copy across" packages from a library 
for an earlier R installation on upgrading.

It is far safer to allow base and recommended R packages to live in the 
default library, and create your own library in a separate directory, 
using the R_LIBS environment variable (or .libPaths()) to add it to the 
library search path. When an incompatible upgrade of the R engine happens, 
you just fire up the new R, say update.packages(checkBuilt=TRUE), and 
relax. If any packages need freshening, this will be taken care of 
automatically.

This is also mentioned in:

https://stat.ethz.ch/pipermail/r-sig-geo/2007-November/002786.html

which gets you to:

https://stat.ethz.ch/pipermail/r-help/2007-October/142367.html

Roger


>
> I much appreciate your help.
>
> Regards
>
> Michal
>
>
> --
> Michal Gallay
>
> Postgraduate Research Student
> School of Geography, Archaeology and Palaeoecology
> Queen's University
> Belfast BT7 1NN
> Northern Ireland
>
> Tel: +44(0)2890 273929
> Fax: +44(0)2890 973212
> email: mgallay01 at qub.ac.uk
> www: www.qub.ac.uk/geog
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Sun Feb 24 11:36:35 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 24 Feb 2008 11:36:35 +0100 (CET)
Subject: [R-sig-Geo] R 2.6 spdep broken caused by changes in methods
Message-ID: <Pine.LNX.4.64.0802241127460.8272@reclus.nhh.no>

(was Creating nb object with cell2nb)

Users report problems with as.logical(), as.integer(), and other coercion 
methods in R 2.6 - these are not problems with spdep, but with stale parts 
of the users' installations.

It has come up several times, both on and off list, and is related to 
NEWS for the 2.6.* release:

     o   Making functions primitive changes the semantics of S4
         dispatch: these no longer dispatch on classes based on types
         but do dispatch whenever the function in the base name space is
         called.

         This applies to as.complex(), as.integer(), as.logical(),
         as.numeric(), as.raw(), expm1(), log(), log1p(), log2(),
         log10(), gamma(), lgamma(), digamma() and trigamma(), as
         well as the Math2 and Summary groups.

         Because all members of the group generics are now primitive,
         they are all S4 generic and setting an S4 group generic does
         at last apply to all members and not just those already made
         S4 generic.

         as.double() and as.real() are identical to as.numeric(), and
         now remain so even if S4 methods are set on any of them.
         Since 'as.numeric' is the traditional name used in S4,
         currently methods must be exported from a NAMESPACE for
         'as.numeric' only.

It is also mentioned in "Breaking news" on http://www.R-project.org/Rgeo/, 
point 3. In fact, it can stem from a stale Matrix package in a library in 
.libPaths() - where R looks for packages - or from a stale methods package 
in the same search path. If you say library(), I guess you will see 
something stale in a library, or two copies of methods, one in the 
installation library, one in your own library. You may also have followed 
the (bad) advice in the R for Windows FAQ to "copy across" packages from a 
library for an earlier R installation on upgrading.

It is far safer to allow base and recommended R packages to live in the 
default library, and create your own library in a separate directory, 
using the R_LIBS environment variable (or .libPaths()) to add it to the 
library search path. When an incompatible upgrade of the R engine happens, 
you just fire up the new R, say:

update.packages(checkBuilt=TRUE, ask=FALSE)

If any packages need freshening, this will be taken care of automatically.

This was covered fully in Prof. Brian Ripley's posting of October 4, 
2007, when R 2.6.0 was released:

https://stat.ethz.ch/pipermail/r-help/2007-October/142367.html

Roger


-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From h.wickham at gmail.com  Sun Feb 24 14:56:27 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 24 Feb 2008 07:56:27 -0600
Subject: [R-sig-Geo] Shortest path around obstacles (OT)
In-Reply-To: <p06240805c3e6bf8f15ae@75.208.252.218>
References: <p06240805c3e6bf8f15ae@75.208.252.218>
Message-ID: <f8e6ff050802240556p73e26708i5355552b272e6233@mail.gmail.com>

On Sun, Feb 24, 2008 at 12:46 AM, Don MacQueen <macq at llnl.gov> wrote:
> This question is basically off topic, since it isn't truly an R
>  question, though it is certainly related to r-sig-geo. I ask here in
>  the hopes that someone can suggest a direction for me to look.
>
>  I have a what is essentially a floor plan of a building (lines
>  representing walls, breaks in the lines representing doors, and so
>  on). I would like to have an algorithm that can calculate the
>  shortest distance between any two points (actually, large numbers of
>  pairs of points) that does not intersect any line (pass through any
>  wall).

This resource looks like a good start:
http://theory.stanford.edu/~amitp/GameProgramming/

I found this by googling for pathfinding (your task) and a-star (the
name of a pathfinding heuristic) , and if looks like there are many
other good resources on the same topic.

Hadley


-- 
http://had.co.nz/



From reeves at nceas.ucsb.edu  Sun Feb 24 19:46:59 2008
From: reeves at nceas.ucsb.edu (Rick Reeves)
Date: Sun, 24 Feb 2008 10:46:59 -0800
Subject: [R-sig-Geo] Shortest path around obstacles (OT)
In-Reply-To: <p06240805c3e6bf8f15ae@[75.208.252.218]>
References: <p06240805c3e6bf8f15ae@[75.208.252.218]>
Message-ID: <47C1BBA3.1060706@nceas.ucsb.edu>

Hi Don:

The GRASS GIS Module v.net.path will compute shortest path distances 
between points
associated with a vector line dataset. The short story here is that 
GRASS is a separate
open-source software package that integrates very closely with R (e.g, 
spatial data move
transparently between the two systems)

You might check out the GIS links on the attached page to get a 
bird's-eye view of GRASS:

http://nceas.ucsb.edu/scicomp/SoftwareLinks.html

You would have to be creative in your use of coordinate systems, but you 
could solve this
problem using GRASS GIS.

Regards,
Rick Reeves
Don MacQueen wrote:
> This question is basically off topic, since it isn't truly an R 
> question, though it is certainly related to r-sig-geo. I ask here in 
> the hopes that someone can suggest a direction for me to look.
>
> I have a what is essentially a floor plan of a building (lines 
> representing walls, breaks in the lines representing doors, and so 
> on). I would like to have an algorithm that can calculate the 
> shortest distance between any two points (actually, large numbers of 
> pairs of points) that does not intersect any line (pass through any 
> wall).
>
> My real dream is to use these distances instead of Euclidean 
> distances as input to a gaussian random fields algorithm such as 
> those in the RandomFields package.
>
> I've done some web-searching for libraries of geometric algorithms 
> that might include this task, and have come across references to 
> Dystra's algorithm, and some mention of line of sight calculations, 
> as well as some algorithms for robotics (how the robot finds a path 
> from here to there, passing around obstacles represented as 
> polygons). So I have some leads.
>
> None the less, I'd really appreciate any suggestions from the folks 
> here on R-sig-geo.
>
> Thanks
> -Don
>   
-------------- next part --------------
A non-text attachment was scrubbed...
Name: reeves.vcf
Type: text/x-vcard
Size: 339 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080224/2d15c73b/attachment.vcf>

From regmi_pujan at hotmail.com  Mon Feb 25 13:26:26 2008
From: regmi_pujan at hotmail.com (PUJAN RAJ REGMI)
Date: Mon, 25 Feb 2008 12:26:26 +0000
Subject: [R-sig-Geo] RGB Image Plotting!
Message-ID: <BAY113-W27EB2438DAE25E9117473484180@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080225/1e68f61f/attachment.pl>

From Roger.Bivand at nhh.no  Mon Feb 25 13:36:35 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 25 Feb 2008 13:36:35 +0100 (CET)
Subject: [R-sig-Geo] RGB Image Plotting!
In-Reply-To: <BAY113-W27EB2438DAE25E9117473484180@phx.gbl>
References: <BAY113-W27EB2438DAE25E9117473484180@phx.gbl>
Message-ID: <Pine.LNX.4.64.0802251334150.11931@reclus.nhh.no>

On Mon, 25 Feb 2008, PUJAN RAJ REGMI wrote:

> Dear Madam/ Sir I am New user of R. I am looking for the way to plot 
> true color image from matrix data of of order (m,n,3) as in MAT LAB 
> where 3 represent the three column matrix where red, green and blue 
> values of pixels are stored. I hope you understand my question. Looking 
> for your help for the same. Thanking you in advance Yours,

Please look at the help page and example for RGB2PCT() in the rgdal 
package. That should get you most of the way, using other functions in the 
package if need be to convert your input matrix to a three-band 
GDALReadOnlyDataset.

Hope this helps,

Roger

>
> Pujan Raj Regmi.Abroad Address: Studentenwijk Arenberg 22/408, 3001 Heverlee, Belgium.
> Cell Number: 0032-0486-530-340
> Home Address: Prabachan Marg-182/15, Baneshwor, Kathmandu, Nepal.
> Home Telephone Number: +977-1-4470900Alternative e-mail: regmi.pujan at student.kuleuven.be
>
>                                    regmi_pujan at yahoo.com
>
> _________________________________________________________________
> Helping your favorite cause is as easy as instant messaging.?You IM, we give.
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From hengl at science.uva.nl  Mon Feb 25 14:38:45 2008
From: hengl at science.uva.nl (Tomislav Hengl)
Date: Mon, 25 Feb 2008 14:38:45 +0100 (CET)
Subject: [R-sig-Geo] RGB Image Plotting!
In-Reply-To: <Pine.LNX.4.64.0802251334150.11931@reclus.nhh.no>
References: <BAY113-W27EB2438DAE25E9117473484180@phx.gbl>
	<Pine.LNX.4.64.0802251334150.11931@reclus.nhh.no>
Message-ID: <3100.139.191.230.222.1203946725.squirrel@webmail.science.uva.nl>


If you import the bands/images as integers [0-255], then you can visualize
them using e.g.:

library(colorspace)
library(rgdal)

vismaps = readGDAL("band_R.tif")
vismaps$red = vismaps$band1
vismaps$green = readGDAL("band_G.tif")$band1
vismaps$blue = readGDAL("band_B.tif")$band1

# Display as a RGB image:

RGBimg = SGDF2PCT(vismaps[c("red", "green", "blue")], ncolors=256,
adjust.bands=FALSE)

vismaps$idx <- RGBimg$idx
image(vismaps, "idx", col=RGBimg$ct)

see also http://spatial-analyst.net/VMM/R_whitening.zip


> On Mon, 25 Feb 2008, PUJAN RAJ REGMI wrote:
>
>> Dear Madam/ Sir I am New user of R. I am looking for the way to plot
>> true color image from matrix data of of order (m,n,3) as in MAT LAB
>> where 3 represent the three column matrix where red, green and blue
>> values of pixels are stored. I hope you understand my question. Looking
>> for your help for the same. Thanking you in advance Yours,
>
> Please look at the help page and example for RGB2PCT() in the rgdal
> package. That should get you most of the way, using other functions in the
> package if need be to convert your input matrix to a three-band
> GDALReadOnlyDataset.
>
> Hope this helps,
>
> Roger
>
>>
>> Pujan Raj Regmi.Abroad Address: Studentenwijk Arenberg 22/408, 3001
>> Heverlee, Belgium.
>> Cell Number: 0032-0486-530-340
>> Home Address: Prabachan Marg-182/15, Baneshwor, Kathmandu, Nepal.
>> Home Telephone Number: +977-1-4470900Alternative e-mail:
>> regmi.pujan at student.kuleuven.be
>>
>>                                    regmi_pujan at yahoo.com
>>
>> _________________________________________________________________
>> Helping your favorite cause is as easy as instant messaging. You IM, we
>> give.
>>
>> 	[[alternative HTML version deleted]]
>>
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From wilbersa at armonia-bo.org  Mon Feb 25 16:23:14 2008
From: wilbersa at armonia-bo.org (Rodrigo W. Soria Auza)
Date: Mon, 25 Feb 2008 16:23:14 +0100
Subject: [R-sig-Geo] random points
Message-ID: <47C2DD62.5020703@armonia-bo.org>

Hi all,
I'm trying to generate a surface of 'random points' over a defined area. 
By 'randon points' I mean points that are not closer than one km each 
other. I used runifpoints (from spatstat). however, this function 
generates strictly random points, with some of them much closer than I 
expected.
could someone help me with this?. I am not really an expert with R.

Thanks in advance,

Rodrigo



From b.rowlingson at lancaster.ac.uk  Mon Feb 25 16:44:13 2008
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 25 Feb 2008 15:44:13 +0000
Subject: [R-sig-Geo] random points
In-Reply-To: <47C2DD62.5020703@armonia-bo.org>
References: <47C2DD62.5020703@armonia-bo.org>
Message-ID: <47C2E24D.5040100@lancaster.ac.uk>

Rodrigo W. Soria Auza wrote:
> Hi all,
> I'm trying to generate a surface of 'random points' over a defined area. 
> By 'randon points' I mean points that are not closer than one km each 
> other. I used runifpoints (from spatstat). however, this function 
> generates strictly random points, with some of them much closer than I 
> expected.
> could someone help me with this?. I am not really an expert with R.
> 

  You could try rSSI from the spatstat package. This creates points 
sequentially, but if the next point is closer than 'r' units to any 
other points, it generates a different next point.

  There are other ways of simulating point patterns with this kind of 
inhibition, and I suspect spatstat has them! Look at help(rStrauss) as well.

Barry



From tyler.smith at mail.mcgill.ca  Mon Feb 25 18:25:02 2008
From: tyler.smith at mail.mcgill.ca (Tyler Smith)
Date: Mon, 25 Feb 2008 17:25:02 +0000 (UTC)
Subject: [R-sig-Geo] directional mantel correlogram
Message-ID: <slrnfs5uff.efl.tyler.smith@blackbart.sedgenet>

Hi,

First off, I'm just learning spatial statistics, so I apologise if I'm
not using the correct terminology.

I'm working on an ecological problem, and I'm trying to distinguish
between two models of community assembly. The first is a completely
intrinsic process, with no relationship between species and the
environment. As such, I expect this process should produce an
isotropic pattern. The alternative process links species abundances to
the underlying environmental gradient, which is spatially structured.
In this case I think the community composition should be anisotropic,
since it is based on an underlying spatial gradient.

It seems to me that I could evaluate this problem with a directional
mantel correlogram, using a measure of community similarity contrasted
against varying distance and direction classes. I found the mgram()
function in package ecodist that computes omnidirectional mantel
correlograms. I've extended this function by adding a second loop to
'mask' the distance matrix for each of the selected angles. I've
pasted my work below, along with a simple test case (which runs in a
minute or two on my machine).

Questions for r-geo gurus:

Is this an appropriate approach to the problem?
Is my implementation correct?

Thanks for your time and patience,

Tyler

dmgram <-
  function (species.d, space.xy, breaks, nclass, stepsize, 
  	   nperm = 1000, mrank = FALSE, nboot = 500, pboot = 0.9, 
	   cboot = 0.95, alternative = "two.sided", trace = FALSE, 
	   alpha = c(0, 45, 90, 135))
{
  space.d <- dist(space.xy)
  space.ang <- pw.angle(space.xy)
  species.d <- as.vector(species.d)
  space <- as.vector(space.d)

  ## calculate break points for specified angles, given that breaks
  ## are at the midway between successive angles
  
  ang.breaks <- numeric(length(alpha))

  for (i in 1:(length(alpha) - 1))
    ang.breaks[i] <- mean(alpha[i:(i+1 )])

  ang.breaks[length(ang.breaks)] <- mean(c(180 + alpha[1], 
  				    	   alpha[length(alpha)]))

  ## any angles between the last break point and 180 are flipped so
  ## that the first angle class is contiguous
  space.ang[space.ang > ang.breaks[length(ang.breaks)]] <- 
            space.ang[space.ang > ang.breaks[length(ang.breaks)]] - 180
  
  if (missing(breaks)) {
    if (missing(nclass)) {
      if (missing(stepsize)) {
	## reduce the calculated number of classes to account for
    	## additional angle categories
        nclass <- round(1 + 3.3 * log10(length(space.d))/length(alpha))
        stepsize <- (max(space.d) - min(space.d))/nclass
      }
      else {
        nclass <- round((max(space.d) - min(space.d))/stepsize)
      }
    }
    else {
      if (missing(stepsize)) {
        stepsize <- (max(space.d) - min(space.d))/nclass
      }
    }
    breaks <- seq(0, stepsize * nclass, stepsize)
  }
  else {
    nclass <- length(breaks) - 1
  }

  answer.m <- matrix(0, ncol = 7, nrow = nclass * length(alpha))
  dimnames(answer.m) <- list(NULL, c("lag", "ngroup", "mantelr", 
  		     		   "pval", "llim", "ulim","dir"))
  answer.m[, 4] <- rep(1, nrow(answer.m))

  for (j in 1:length(ang.breaks)) {
    if (j == 1) {
      amin <- -180  ## set the minimum value for the first angle class
    } else
      amin <- ang.breaks[j - 1]
    amax <- ang.breaks[j]
    space.aclass <- matrix(1, nrow = nrow(space.ang), 
    		    	      ncol = ncol(space.ang))

    space.aclass[space.ang <= amin] <- 0
    space.aclass[space.ang > amax] <- 0
    diag(space.aclass) <- 0
    space.aclass <- as.dist(space.aclass)
    ## space.aclass serves as a mask to zero out all distances that
    ## are not in the current angle class    

    for (i in 1:nclass) {
      row.num <- (j - 1) * nclass + i
      dmin <- breaks[i]
      dmax <- breaks[i + 1]
      answer.m[row.num, 1] <- (dmin + dmax)/2
      space.dclass <- rep(0, length(space.d))
      space.dclass[(space.d * space.aclass) <= dmin] <- 1
      space.dclass[(space.d * space.aclass) > dmax] <- 1
      ngroup <- length(space.dclass) - sum(space.dclass)
      answer.m[row.num, 2] <- ngroup
      if (ngroup > 0) {
        mant <- mantel(species.d ~ space.dclass, nperm = nperm, 
	     	mrank = mrank, nboot = nboot, pboot = pboot, 
		cboot = cboot)
        answer.m[row.num, 3] <- mant[1]
        if (alternative == "two.sided") 
          answer.m[row.num, 4] <- mant[4]
        else answer.m[row.num, 4] <- mant[2]
        answer.m[row.num, 5] <- mant[5]
        answer.m[row.num, 6] <- mant[6]
      }
      answer.m[row.num,7] <- alpha[j]
      if (trace) 
        cat(i, "\t", answer.m[i, 2], "\t", answer.m[i, 3], 
            "\n")
    }
  }
  
  results <- list(mgram = answer.m, resids = NA)
  class(results) <- "dmgram"
  results
}

pw.angle <- function(x) {
  res <- matrix(NA, nrow = nrow(x), ncol = nrow(x))
  for (i in 1:(nrow(x)-1))
    for (j in (i+1):nrow(x))
      res[i,j] <- atan((x[i,2] - x[j,2])/(x[i,1] - x[j,1])) * 180 / pi
  res[lower.tri(res)] <- t(res)[lower.tri(t(res))]
  diag(res) <- 0
  res[res < 0] = 180 + res[res < 0]
  return(res)
}

plot.dmgram <- function (x, pval = 0.05, xlab = "Distance", 
	       		ylab = "Mantel r", ...) {
  x <- x$mgram
  pval.v <- x[, 4]
  ang.v <- x[,7]
  ang.lev <- unique(ang.v)
  ang.num <- length(ang.lev)
  
  plot(x[,1], x[,3], type = 'n', xlab = xlab, ylab = ylab, ...)
  
  for (i in 1:ang.num) {
    points(x[x[,7] == ang.lev[i], 1], x[x[,7] == ang.lev[i], 3], 
    	     col = i, type = 'l')
    points(x[pval.v <= pval & ang.v == ang.lev[i], 1], 
             x[pval.v <= pval & ang.v == ang.lev[i], 3], 
	     pch = 16, col = i)
    points(x[pval.v > pval & ang.v == ang.lev[i], 1], 
    	     x[pval.v > pval & ang.v == ang.lev[i], 3], 
	     pch = 1, col = i)
  }
  invisible()
}

## test case for an artificial isotropic pattern:

coords <- cbind(rep(1:20, each = 20), rep(1:20, 20)) 
coords2 <- cbind(jitter(coords[,1], factor = 10), jitter(coords[,2], 
	   	   factor = 10))
coords.dist <- dist(coords)
coords2.dist <- dist(coords2)
dmangram.coords <- dmgram(coords2.dist, coords)

plot(dmangram.coords)



From Greg.Snow at imail.org  Mon Feb 25 19:25:28 2008
From: Greg.Snow at imail.org (Greg Snow)
Date: Mon, 25 Feb 2008 11:25:28 -0700
Subject: [R-sig-Geo] RGB Image Plotting!
In-Reply-To: <BAY113-W27EB2438DAE25E9117473484180@phx.gbl>
References: <BAY113-W27EB2438DAE25E9117473484180@phx.gbl>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBEE12CE@LP-EXCHVS07.CO.IHC.COM>

Look at the rimage package.  The imagematrix function should be able to take your array as it is (or maybe with after using aperm).  Then plot the result.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch 
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of 
> PUJAN RAJ REGMI
> Sent: Monday, February 25, 2008 5:26 AM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] RGB Image Plotting!
> 
> Dear Madam/ Sir
> I am New user of R. I am looking for the way to plot true 
> color image from matrix data of of order (m,n,3) as in MAT 
> LAB where 3 represent the three column matrix where red, 
> green and blue values of  pixels are stored. I hope you 
> understand my question. Looking for your help for the same.
> Thanking you in advance
> Yours,
> 
> Pujan Raj Regmi.Abroad Address: Studentenwijk Arenberg 
> 22/408, 3001 Heverlee, Belgium. 
> Cell Number: 0032-0486-530-340
> Home Address: Prabachan Marg-182/15, Baneshwor, Kathmandu, Nepal. 
> Home Telephone Number: +977-1-4470900Alternative e-mail: 
> regmi.pujan at student.kuleuven.be
> 
>                                     regmi_pujan at yahoo.com 
>  
> _________________________________________________________________
> Helping your favorite cause is as easy as instant messaging.?
> You IM, we give.
> 
> 	[[alternative HTML version deleted]]
> 
> 



From regmi_pujan at hotmail.com  Tue Feb 26 02:36:08 2008
From: regmi_pujan at hotmail.com (PUJAN RAJ REGMI)
Date: Tue, 26 Feb 2008 01:36:08 +0000
Subject: [R-sig-Geo] Rimage Package
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBEE12CE@LP-EXCHVS07.CO.IHC.COM>
References: <BAY113-W27EB2438DAE25E9117473484180@phx.gbl>
	<07E228A5BE53C24CAD490193A7381BBBEE12CE@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <BAY113-W322ED213927B442FDC7D7584190@phx.gbl>


Thanks a lot it gives me a wayout but I still want favour from you.  Could you please explain how can i prepared three mat file required for the following code?
imagematrix(mat, type=NULL, ncol=dim(mat)[1], nrow=dim(mat)[2], noclipping=FALSE)
I have three R files named as Redchannel, Greenchannel and Bluechannel with 93x 91 matrix where each coordinates have the reflectance values for each pixels. I tried with following way but it didnt work
[mat[93,91,1]=c(Redchannel)],[mat[93,91,1]=c(Greenchannel)],[mat[93,91,1]=c(Bluechannel)]
Looking forward to hearing form you
Thanking you in advance
Yours
Pujan
Belgium
_________________________________________________________________
Climb to the top of the charts!?Play the word scramble challenge with star power.

n


From adrian at maths.uwa.edu.au  Tue Feb 26 08:10:19 2008
From: adrian at maths.uwa.edu.au (adrian at maths.uwa.edu.au)
Date: Tue, 26 Feb 2008 16:10:19 +0900 (WST)
Subject: [R-sig-Geo] Course on analysing spatial point patterns
In-Reply-To: <mailman.11.1203937203.11666.r-sig-geo@stat.math.ethz.ch>
References: <mailman.11.1203937203.11666.r-sig-geo@stat.math.ethz.ch>
Message-ID: <50266.130.95.98.17.1204009819.squirrel@130.95.98.17>


A full set of course notes on
          'Analysing spatial point patterns in R'
is now available at
     <http://www.csiro.au/resources/pf16h.html>

The course is based on the package 'spatstat'. It includes a brief
introduction to R, a detailed introduction to the 'spatstat' package, and
a discussion of statistical methodology.

Adrian Baddeley



From giohappy at gmail.com  Tue Feb 26 17:39:13 2008
From: giohappy at gmail.com (G. Allegri)
Date: Tue, 26 Feb 2008 17:39:13 +0100
Subject: [R-sig-Geo] normal score and back...
Message-ID: <e12429640802260839hfbc84c5i7a3e90dfd35dee9d@mail.gmail.com>

I'm sorry for asking again, but I haven't found an exhaustive answer yet.
Is there a package or a function in R to execute normal score
transformation (and back?).

I know GSLIB is an alternative, but I would prefare to make the whole
work inside R...

Thanks,
Giovanni



From giohappy at gmail.com  Tue Feb 26 18:38:25 2008
From: giohappy at gmail.com (G. Allegri)
Date: Tue, 26 Feb 2008 18:38:25 +0100
Subject: [R-sig-Geo] normal score and back...
In-Reply-To: <e12429640802260839hfbc84c5i7a3e90dfd35dee9d@mail.gmail.com>
References: <e12429640802260839hfbc84c5i7a3e90dfd35dee9d@mail.gmail.com>
Message-ID: <e12429640802260938x57b866b9x36585bf397f600ae@mail.gmail.com>

I.ve approximated normal scores with the blom's method:
qnorm((rank(x)-0.375)/(sum(!is.na(x))+0.25))
but back-transormation using approx() doesn't work correctly, maybe
because of decimal values approximations.

Could you suggest me another way (then approx) to interpolate
(linearly) values to do back-t?

2008/2/26, G. Allegri <giohappy at gmail.com>:
> I'm sorry for asking again, but I haven't found an exhaustive answer yet.
>  Is there a package or a function in R to execute normal score
>  transformation (and back?).
>
>  I know GSLIB is an alternative, but I would prefare to make the whole
>  work inside R...
>
>  Thanks,
>  Giovanni
>



From Greg.Snow at imail.org  Tue Feb 26 18:57:34 2008
From: Greg.Snow at imail.org (Greg Snow)
Date: Tue, 26 Feb 2008 10:57:34 -0700
Subject: [R-sig-Geo] Rimage Package
In-Reply-To: <BAY113-W322ED213927B442FDC7D7584190@phx.gbl>
References: <BAY113-W27EB2438DAE25E9117473484180@phx.gbl>
	<07E228A5BE53C24CAD490193A7381BBBEE12CE@LP-EXCHVS07.CO.IHC.COM>
	<BAY113-W322ED213927B442FDC7D7584190@phx.gbl>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBF2A659@LP-EXCHVS07.CO.IHC.COM>

I think that you are already close.

Assuming that you have already read in Redchannel, Greenchannel, and Bluechannel and they are each a 93x91 matrix, then the following should work for you:

> mat <- array(0, c(93,91,3) )
> mat[,,1] <- Redchannel
> mat[,,2] <- Greenchannel
> mat[,,3] <- Bluechannel
>
> plot(imagematrix(mat))

This creates an array of the correct size filled with 0's, then you replace 1 layer at a time, the commas without numbers indicate that you want to replace the entire layer (all rows all columns).  There is also an abind package that may simplify this (but the above is fairly simple and matches with what you already tried).

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: PUJAN RAJ REGMI [mailto:regmi_pujan at hotmail.com] 
> Sent: Monday, February 25, 2008 6:36 PM
> To: Greg Snow; r-sig-geo at stat.math.ethz.ch
> Subject: Rimage Package
> 
> 
> Thanks a lot it gives me a wayout but I still want favour 
> from you.  Could you please explain how can i prepared three 
> mat file required for the following code?
> imagematrix(mat, type=NULL, ncol=dim(mat)[1], 
> nrow=dim(mat)[2], noclipping=FALSE) I have three R files 
> named as Redchannel, Greenchannel and Bluechannel with 93x 91 
> matrix where each coordinates have the reflectance values for 
> each pixels. I tried with following way but it didnt work 
> [mat[93,91,1]=c(Redchannel)],[mat[93,91,1]=c(Greenchannel)],[m
> at[93,91,1]=c(Bluechannel)]
> Looking forward to hearing form you
> Thanking you in advance
> Yours
> Pujan
> Belgium
> _________________________________________________________________
> Climb to the top of the charts!?Play the word scramble 
> challenge with star power.
> http://club.live.com/star_shuffle.aspx?icid=starshuffle_wlmail
> textlink_jan
> 



From regmi_pujan at hotmail.com  Wed Feb 27 01:52:27 2008
From: regmi_pujan at hotmail.com (PUJAN RAJ REGMI)
Date: Wed, 27 Feb 2008 00:52:27 +0000
Subject: [R-sig-Geo] Rimage Package
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBBF2A659@LP-EXCHVS07.CO.IHC.COM>
References: <BAY113-W27EB2438DAE25E9117473484180@phx.gbl>
	<07E228A5BE53C24CAD490193A7381BBBEE12CE@LP-EXCHVS07.CO.IHC.COM>
	<BAY113-W322ED213927B442FDC7D7584190@phx.gbl> 
	<07E228A5BE53C24CAD490193A7381BBBF2A659@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <BAY113-W130682CF9F1AC927858D94841A0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080227/cc9197c3/attachment.pl>

From adrian at maths.uwa.edu.au  Wed Feb 27 02:10:42 2008
From: adrian at maths.uwa.edu.au (adrian at maths.uwa.edu.au)
Date: Wed, 27 Feb 2008 10:10:42 +0900 (WST)
Subject: [R-sig-Geo]  random points
Message-ID: <3460.130.116.32.101.1204074642.squirrel@130.116.32.101>

Rodrigo W. Soria Auza <wilbersa at armonia-bo.org> writes:

> I'm trying to generate a surface of 'random points' over a defined area.
> By 'randon points' I mean points that are not closer than one km each
> other. I used runifpoints (from spatstat). however, this function
> generates strictly random points, with some of them much closer than I
> expected.

In the spatstat package you have several options:

     rstrat: divides the region into squares and places one random point
             in each square (or k random points)

     rsyst:  makes a square grid of points and gives it a random displacement

     rSSI:  places points at random, one-at-a-time,
            each new point being constrained to lie at least r units away
            from the previously existing points

     rStrauss (with gamma=0): places points at random subject to the
            condition that no two points lie closer than r units apart

If you need something more complicated that that, you could try the
package 'spsample'



Adrian Baddeley



From dylan.beaudette at gmail.com  Wed Feb 27 08:06:49 2008
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Tue, 26 Feb 2008 23:06:49 -0800
Subject: [R-sig-Geo] select random "blocks" from grid
Message-ID: <200802262306.49214.dylan.beaudette@gmail.com>

Hi,

Is there a simple approach to selecting random "blocks" using the sp classes 
and methods?

Say I have a 10x10 grid of polygons, and would like to randomly select 10 of 
these, and save  them to a new sp class (for later saving to GRASS, etc.). Is 
there a simple approach to this?

I have tried something along the lines of accessing the polygons directly:

s <- sample(1:100, size=10)

# doesn't work
grid at polygons[[s]]

# sort of works... but how can I 'upgrade' the result back to a complete set 
# of polygons which can be saved to GRASS?
apply(matrix(s), 1, function(i) grid at polygons[[i]])

Ultimately I would like to establish several randomly placed 100m x 100m 
squares within a square region. Setting up a grid, and selecting random cells 
seemed like a simple approach, but if there is a better one I would be happy 
to hear about it!

I suppose that I could hand-make something that generates random points, 
expands their geometry to 100x100 meters, and then tests to see if the 
resulting rectangle falls completely within the region of interest. This 
would work as a last resort-- surely there must be a cleaner approach within 
the existing framework (I hope!). 

Cheers,

Dylan



-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341



From Roger.Bivand at nhh.no  Wed Feb 27 08:56:46 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 27 Feb 2008 08:56:46 +0100 (CET)
Subject: [R-sig-Geo] select random "blocks" from grid
In-Reply-To: <200802262306.49214.dylan.beaudette@gmail.com>
References: <200802262306.49214.dylan.beaudette@gmail.com>
Message-ID: <Pine.LNX.4.64.0802270848100.20111@reclus.nhh.no>

On Tue, 26 Feb 2008, Dylan Beaudette wrote:

> Hi,
>
> Is there a simple approach to selecting random "blocks" using the sp classes
> and methods?
>
> Say I have a 10x10 grid of polygons, and would like to randomly select 10 of
> these, and save  them to a new sp class (for later saving to GRASS, etc.). Is
> there a simple approach to this?
>
> I have tried something along the lines of accessing the polygons directly:
>
> s <- sample(1:100, size=10)
>
> # doesn't work
> grid at polygons[[s]]

library(sp)
gt <- GridTopology(c(0.5, 0.5), c(1, 1), c(10,10))
SP <- as(as(SpatialGrid(gt), "SpatialPixels"), "SpatialPolygons")
class(SP)
plot(SP, axes=TRUE)
set.seed(1)
SP10 <- SP[sample(length(slot(SP, "polygons")), 10)]
class(SP10)
plot(SP10, col="green", add=TRUE)

The "[" methods are quite strong.


>
> # sort of works... but how can I 'upgrade' the result back to a complete set
> # of polygons which can be saved to GRASS?
> apply(matrix(s), 1, function(i) grid at polygons[[i]])
>
> Ultimately I would like to establish several randomly placed 100m x 100m
> squares within a square region. Setting up a grid, and selecting random cells
> seemed like a simple approach, but if there is a better one I would be happy
> to hear about it!

You could generate points and overlay on the polygons, but you might get 
two points in one polygon.

Hope this helps,

Roger


>
> I suppose that I could hand-make something that generates random points,
> expands their geometry to 100x100 meters, and then tests to see if the
> resulting rectangle falls completely within the region of interest. This
> would work as a last resort-- surely there must be a cleaner approach within
> the existing framework (I hope!).
>
> Cheers,
>
> Dylan
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From wilbersa at armonia-bo.org  Wed Feb 27 10:24:30 2008
From: wilbersa at armonia-bo.org (Rodrigo W. Soria Auza)
Date: Wed, 27 Feb 2008 10:24:30 +0100
Subject: [R-sig-Geo] random points
Message-ID: <47C52C4E.709@armonia-bo.org>

Guys,
Thanks for your answers,
Rodrigo



From r.m.krug at gmail.com  Wed Feb 27 14:09:33 2008
From: r.m.krug at gmail.com (Rainer M Krug)
Date: Wed, 27 Feb 2008 15:09:33 +0200
Subject: [R-sig-Geo] Plan to build Package to use GRASS from R
Message-ID: <fb7c7e870802270509o46b51112n24d9c38825ca2657@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080227/27e7b0ae/attachment.pl>

From serbin at wisc.edu  Wed Feb 27 16:57:25 2008
From: serbin at wisc.edu (Shawn P. Serbin)
Date: Wed, 27 Feb 2008 09:57:25 -0600
Subject: [R-sig-Geo] Plotting continuous data (gridded) clipped to shape
	boundary
Message-ID: <47C58865.6040604@wisc.edu>

All,

I was hoping there was someone (or several folks) who could assist me. I 
have spent some time lately trying to figure out a way to plot gridded 
data in Latitude and Longitude values with a map overlay and ultimately 
the gridded data would be clipped to the boundary of the map, i.e. a 
Wisconsin state boundary shapefile (either custom or from the maps 
package). The idea is to create code that can inject netCDF output and 
quickly create maps that can be used in presentations/publications.

I have cleared the first hurdle (well not really a hurdle) and have a 
pretty clean way of importing the netCDF files into R arrays, vectors, 
data.frames (I guess these would be considered Spatial.data.frames) 
which I can then manipulate.

The problem lies with the actual mapping. Now I can easily map the data 
in the Lattice package(s) and display a very nice, custom legend bar 
with contour overlays. However, when I try to use ?image? in the 
spatstat package either 1) I can only view the data on a standard grid 
(i.e. 0 to 1 in the x and y) or 2) I get an error message letting me 
know that ?expecting increasing x and y? or 3) ?x does not increase 
consistently?

Again, I have tried many mapping and spatial packages but have yet to 
find one that can handle the lat and long as well as clipping to a 
boundary. Now I have seen an example on the web where using image you 
can create a binary mask (i.e. meuse) but have yet to see how I can get 
this to work with a vector shapefile. If I could get this to work with 
plotting lat and long in image I think I would be good to go. 
Alternatively, if there is a package that can handle what I am looking 
to do then that would be great as well. It seems however that I am 
having difficulty getting the data in the correct format and / or using 
the correct plotting.

What I would like to do is something similar to the ?volcano? demo where 
I plot the gridded data (in native 8km grid cell resolution) then 
overlay contours of my chosen spacing and the clip the data to 
Wisconsin, with Lat and Long x and y and a legend bar.

Thanks in advance to any and all who are better at this than me!

Shawn



From dylan.beaudette at gmail.com  Wed Feb 27 20:28:51 2008
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Wed, 27 Feb 2008 11:28:51 -0800
Subject: [R-sig-Geo] select random "blocks" from grid
In-Reply-To: <Pine.LNX.4.64.0802270848100.20111@reclus.nhh.no>
References: <200802262306.49214.dylan.beaudette@gmail.com>
	<Pine.LNX.4.64.0802270848100.20111@reclus.nhh.no>
Message-ID: <200802271128.51327.dylan.beaudette@gmail.com>

On Tuesday 26 February 2008, Roger Bivand wrote:
> On Tue, 26 Feb 2008, Dylan Beaudette wrote:
> > Hi,
> >
> > Is there a simple approach to selecting random "blocks" using the sp
> > classes and methods?
> >
> > Say I have a 10x10 grid of polygons, and would like to randomly select 10
> > of these, and save  them to a new sp class (for later saving to GRASS,
> > etc.). Is there a simple approach to this?
> >
> > I have tried something along the lines of accessing the polygons
> > directly:
> >
> > s <- sample(1:100, size=10)
> >
> > # doesn't work
> > grid at polygons[[s]]
>
> library(sp)
> gt <- GridTopology(c(0.5, 0.5), c(1, 1), c(10,10))
> SP <- as(as(SpatialGrid(gt), "SpatialPixels"), "SpatialPolygons")
> class(SP)
> plot(SP, axes=TRUE)
> set.seed(1)
> SP10 <- SP[sample(length(slot(SP, "polygons")), 10)]
> class(SP10)
> plot(SP10, col="green", add=TRUE)
>
> The "[" methods are quite strong.
>
> > # sort of works... but how can I 'upgrade' the result back to a complete
> > set # of polygons which can be saved to GRASS?
> > apply(matrix(s), 1, function(i) grid at polygons[[i]])
> >
> > Ultimately I would like to establish several randomly placed 100m x 100m
> > squares within a square region. Setting up a grid, and selecting random
> > cells seemed like a simple approach, but if there is a better one I would
> > be happy to hear about it!
>
> You could generate points and overlay on the polygons, but you might get
> two points in one polygon.
>
> Hope this helps,
>
> Roger

Thanks for the help Roger.

I was able to accomplish a random selection of grid cells with your examples.

I was also able to create a simple function for randomly generating "blocks" 
of a given size, and distance from each other / edges with some spatstat 
tools [1].

1. http://casoilresource.lawr.ucdavis.edu/drupal/node/551

Cheers,
Dylan

> > I suppose that I could hand-make something that generates random points,
> > expands their geometry to 100x100 meters, and then tests to see if the
> > resulting rectangle falls completely within the region of interest. This
> > would work as a last resort-- surely there must be a cleaner approach
> > within the existing framework (I hope!).
> >
> > Cheers,
> >
> > Dylan



-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341



From nicolas.bergeron at sympatico.ca  Thu Feb 28 03:17:58 2008
From: nicolas.bergeron at sympatico.ca (Nicolas Bergeron)
Date: Wed, 27 Feb 2008 21:17:58 -0500
Subject: [R-sig-Geo] class ker (ks) --> conversion --> raster
Message-ID: <874pbtddt5.fsf@sympatico.ca>

Hi All,

I'm searching for the method to convert a class ker (library(ks)) to the format
raster. Can you suggest a possible solution?

This code produces the object of class ker:

# Modules
library(ks)

# xy
xy <- as.matrix(loc[loc$ID_animal == 2004021,c("x","y")])

# HPI-SCALE
HpiScale <- Hpi(x=xy, pilot="samse", pre="scale")
fhat.HpiScale <- kde(x=xy, H = HpiScale)

# Code for conversion
# Export {XY=long,lat, Z=fhat} --> GRASS (r.in.xyz)
XY <- data.frame(x=fhat.HpiScale[[2]][[1]],y=fhat.HpiScale[[2]][[2]])
Z <- fhat.HpiScale[[3]]

... suggestions will appreciate or  others methods to write a text file
of X,Y coordinates and Z value.

after that, in GRASS-GIS r.in.xyz

Thank's

-- 
Nicolas Bergeron



From Roger.Bivand at nhh.no  Thu Feb 28 08:29:08 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 28 Feb 2008 08:29:08 +0100 (CET)
Subject: [R-sig-Geo] Plan to build Package to use GRASS from R
In-Reply-To: <fb7c7e870802270509o46b51112n24d9c38825ca2657@mail.gmail.com>
References: <fb7c7e870802270509o46b51112n24d9c38825ca2657@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0802280823490.24777@reclus.nhh.no>

On Wed, 27 Feb 2008, Rainer M Krug wrote:

> Hi
>
> Sorry for crossposting, but I think this can be of interest for GRASS and R
> users.

Yes, please avoid cross-posting - the discussion ends up on many different 
lists and threading can break down if the threading implementation in mail 
clients and archives doesn't like cross-posting.

The only complete thread I have found is on Nabble at:

http://www.nabble.com/Plan-to-build-Package-to-use-GRASS-from-R-tt15712877.html#a15712877

for the grass-dev list.

In summary, the problems are mostly those of appropriately quoting shell 
commands through system() across platforms. Those interested should follow 
the discussion on grass-dev.

The correct lists could be either here, or the grass-stats list; could 
Rainer post a summary to both (hopefully in-thread) on conclusion?

Roger

>
> I am planning to write a package to make the use of GRASS from R easier. The
> idea is to wrap the system call to execute the GRASS command into an R
> command of the same name.
> e.g:
> r.to.vect <- function(..., intern=TRUE, ignore.stderr=FALSE)
>  {
>    comm <- paste( "r.to.vect ", ..., sep="" )
>    print(comm)
>    system( comm, intern=intern, ignore.stderr=ignore.stderr )
>  }
>
> My questions are:
>
> 1) Is this a good way of doing it, or is giving a named list to the function
> more usefull?
> 2) Is there a way to obtain easily all commands from GRASS and the
> parameters possible and required?
>
> Any ideas and comments welcome,
>
> Rainer
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From jgalkows at akamai.com  Thu Feb 28 19:58:49 2008
From: jgalkows at akamai.com (Galkowski, Jan)
Date: Thu, 28 Feb 2008 13:58:49 -0500
Subject: [R-sig-Geo] estimates for paths of travel given two time series,
	drawn from two corresponding spatial densities
Message-ID: <76EB4827B2104D40AE7E43AA5D8582EA011A9D32@MAVS1.kendall.corp.akamai.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080228/a97734c5/attachment.pl>

From loecher at eden.rutgers.edu  Thu Feb 28 21:00:28 2008
From: loecher at eden.rutgers.edu (Markus Loecher)
Date: Thu, 28 Feb 2008 15:00:28 -0500
Subject: [R-sig-Geo] makeGrid(PBSmapping)
Message-ID: <20080228195805.F18A632408E@annwn13.rutgers.edu>

Dear geo experts,
I am clearly misunderstanding the role of the projection argument in 
the wonderful utility makeGrid(PBSmapping).
I had hoped that by setting projection ="LL" the resulting grid would 
be equidistant in "real" space, and hence curvilinear in lat/lon space.
But the following code yields the identical, regular grid, 
irrespective of the projection argument:

	mypolys <- makeGrid(x= seq(-123,-122,length=10), y = seq(33, 34, 
length=10), byrow = FALSE, addSID = TRUE, projection = "LL")
	plotMap(mypolys)	
	mypolys <- makeGrid(x= seq(-123,-122,length=10), y = seq(33, 34, 
length=10), byrow = FALSE, addSID = TRUE, projection = 1)
	plotMap(mypolys)

Is there an easy way to create a rectangular grid in lat/lon space ? 
Should I first translate the points to UTM coordinates ?

Thanks!

Markus



From stefan.duke at gmail.com  Fri Feb 29 11:36:18 2008
From: stefan.duke at gmail.com (stefan lhachimi)
Date: Fri, 29 Feb 2008 11:36:18 +0100
Subject: [R-sig-Geo] Choice of Spatial weights
Message-ID: <a211af3b0802290236m53a12cd1h806a3106f508fb54@mail.gmail.com>

Dear all,

as a matter of curiosity does anybody know literature which discusses
what spatial weight to choose (e.g. k-nn, single or double
contiguity)? Or has anybod a good rule of thumb?
I found an article which proposes to try several specification and
take either the one with the highest lambda  or the one with the best
overall model fit (in a regression). But I think that is statistically
speaking that is not very satisfactory, in particular if the
application does not give any indication what weight to use.

Any hints?
Best,
Stefan



